0,1,label2,summary_sentences
"ar X
iv :1
80 2.
06 09
3v 4
[ cs
.L G",text,[0],[0]
"Residual networks (He et al., 2016) are deep neural networks in which, roughly, subnetworks determine how a feature transformation should differ from the identity, rather than how it should differ from zero.",1 Introduction,[0],[0]
"After enabling the winning entry in the ILSVRC 2015 classification task, they have become established as a central idea in deep networks.
",1 Introduction,[0],[0]
Hardt & Ma (2017) provided a theoretical analysis that shed light on residual networks.,1 Introduction,[0],[0]
"They showed that (a) any linear transformation with a positive determinant and a bounded condition number can be approximated by a “deep linear network” of the form f(x) = ΘLΘL−1...Θ1x, where,
for large L, each layer Θi is close to the identity, and (b) for networks that compose near-identity transformations this way, if the excess loss is large, then the gradient is steep.",1 Introduction,[0],[0]
"Bartlett et al. (2018) extended both results to the nonlinear case, showing that any smooth, bi-Lipschitz map can be represented as a composition of near-identity functions, and that a suboptimal loss in a composition of near-identity functions implies that the functional gradient of the loss with respect to a function in the composition cannot be small.",1 Introduction,[0],[0]
"These results are interesting because they suggest that, in many cases, this non-convex objective may be efficiently optimized through gradient descent if the layers stay close to the identity, possibly with the help of a regularizer.
",1 Introduction,[0],[0]
"This paper describes and analyzes such algorithms for linear regression with d input variables and d response variables with respect to the quadratic loss, the same setting analyzed by Hardt and Ma.",1 Introduction,[0],[0]
We abstract away sampling issues by analyzing an algorithm that performs gradient descent with respect to the population loss.,1 Introduction,[0],[0]
We focus on the case that the distribution on the input patterns is isotropic.,1 Introduction,[0],[0]
(The data may be transformed through a preprocessing step to satisfy this constraint.),1 Introduction,[0],[0]
"
",1 Introduction,[0],[0]
"The traditional analysis of convex optimization algorithms (see Boyd & Vandenberghe, 2004) provides a bound in terms of the quality of the initial solution, together with bounds on the eigenvalues of the Hessian of the loss.",1 Introduction,[0],[0]
"For the non-convex problem of this paper, we show that if gradient descent starts at the identity in each layer, and if the excess loss of that initial solution is bounded by a constant, then the Hessian remains well-conditioned enough throughout training for successful learning.",1 Introduction,[0],[0]
"Specifically, there is a constant c0 such that, if the excess loss of the identity (over the least squares linear map) is at most c0, then back-propagation initialized at the identity in each layer achieves loss within at most ǫ of optimal in time polynomial in log(1/ǫ), d, and L (Section 3).",1 Introduction,[0],[0]
"On the other hand, we show that there is a constant c1 and a least squares matrix Φ such that the identity has excess loss c1 with respect to Φ, but backpropagation with identity initialization fails to learn Φ (Section 6).
",1 Introduction,[0],[0]
"We also show that if the least squares matrix Φ is symmetric positive definite then gradient descent with identity initialization achieves excess loss at most ǫ in a number of steps bounded by a polynomial in log(d/ǫ), L and the condition number of Φ (Section 4).
",1 Introduction,[0],[0]
"In contrast, for any least squares matrix Φ that is symmetric but has a negative eigenvalue, we show that no such guarantee is possible for a wide variety of algorithms of this type: the excess loss is forever bounded below by the square of this negative eigenvalue.",1 Introduction,[0],[0]
"This holds for step-and-project algorithms, and also algorithms that initialize to the identity and regularize by early stopping or penalizing ∑
i ||Θi − I|| 2 F (Section 6).",1 Introduction,[0],[0]
"Both this and the previous impossibility result can be
proved using a least squares matrix Φ with a positive determinant and a good condition number.",1 Introduction,[0],[0]
"Recall that such Φ were proved by Hardt and Ma to have a good approximation as a product of near-identity matrices – we prove that gradient descent cannot learn them, even with the help of regularizers that reward near-identity representations.
",1 Introduction,[0],[0]
"In Section 5 we provide a convergence guarantee for a least squares matrix Φ that may not be symmetric, but satisfies the positivity condition u⊤Φu",1 Introduction,[0],[0]
> γ for some γ > 0,1 Introduction,[0],[0]
that appears in the bounds.,1 Introduction,[0],[0]
We call such matrices γ-positive.,1 Introduction,[0],[0]
Such Φ include rotations by acute angles.,1 Introduction,[0],[0]
"In this case, we consider an algorithm that regularizes in addition to a near-identity initialization.",1 Introduction,[0],[0]
"After the gradient update, the algorithm performs what we call power projection, projecting its hypothesis ΘLΘL−1...Θ1 onto the set of γ-positive matrices.",1 Introduction,[0],[0]
"Second, it “balances” Θ1, ...,ΘL so that, informally, they contribute equally to ΘLΘL−1...Θ1.",1 Introduction,[0],[0]
(See Section 5 for the details.),1 Introduction,[0],[0]
"We view this
regularizer as a theoretically tractable proxy for regularizers that promote positivity and balance between layers by adding penalties.
",1 Introduction,[0],[0]
"While, in practice, deep networks are non-linear, analysis of the linear case can provide a tractable way to gain insight through rigorous theoretical analysis (Saxe et al., 2013; Kawaguchi, 2016; Hardt & Ma, 2017).",1 Introduction,[0],[0]
We might view back-propagation in the non-linear case as an approximation to a procedure that locally modifies the function computed by each layer in a manner that reduces the loss as fast as possible.,1 Introduction,[0],[0]
"If a non-linear network is obtained by composing transformations, each of which is chosen from a Hilbert space of functions (as in Daniely et al. (2016)), then a step in “function space” corresponds to a step in an (infinite-dimensional) linear space of functions.
",1 Introduction,[0],[0]
Related work.,1 Introduction,[0],[0]
The motivation for this work comes from the papers of Hardt & Ma (2017) and Bartlett et al. (2018).,1 Introduction,[0],[0]
Saxe et al. (2013) studied the dynamics of a continuous-time process obtained by taking the step size of backpropagation applied to deep linear neural networks to zero.,1 Introduction,[0],[0]
Kawaguchi (2016) showed that deep linear neural networks have no suboptimal local minima.,1 Introduction,[0],[0]
"In the case that L = 2, the problem studied here has a similar structure as problems arising from low-rank approximation of matrices, especially as regards algorithms that approximate a matrix A by iteratively improving an approximation of the form UV .",1 Introduction,[0],[0]
"For an interesting survey on the rich literature on these algorithms, please see Ge et al. (2017a); successful algorithms have included a regularizer that promotes balance in the sizes of U and V .",1 Introduction,[0],[0]
"Taghvaei et al. (2017) studied the properties of critical points on the loss when learning deep linear neural networks in the presence of a weight decay regularizer; they studied networks that transform the input to the output through a process indexed by a continuous variable, instead of through discrete layers.",1 Introduction,[0],[0]
"Lee et al. (2016) showed that, given regularity conditions, for a random initialization, gradient descent converges to a local minimizer almost surely; while their paper yields useful insights, their regularity condition does not hold for our problem.",1 Introduction,[0],[0]
Many papers have analyzed learning of neural networks with non-linearities.,1 Introduction,[0],[0]
The papers most closely related to this work analyze algorithms based on gradient descent.,1 Introduction,[0],[0]
"Some of these (Andoni et al., 2014; Brutzkus & Globerson, 2017; Ge et al., 2017b; Li & Yuan, 2017; Zhong et al., 2017; Zhang et al., 2018; Brutzkus et al., 2018; Ge et al., 2018) analyze constant-depth networks.",1 Introduction,[0],[0]
Daniely (2017) showed that stochastic gradient descent learns a subclass of functions computed by log-depth networks in polynomial time; this class includes constant-degree polynomials with polynomially bounded coefficients.,1 Introduction,[0],[0]
"Other theoretical treatments of neural network learning algorithms include Lee et al. (1996); Arora et al. (2014); Livni et al. (2014); Janzamin et al. (2015); Safran & Shamir (2016); Zhang et al. (2016); Nguyen & Hein (2017); Zhang et al. (2017); Orhan & Pitkow (2018), although these are less closely related.
",1 Introduction,[0],[0]
Our three upper bound analyses combine a new upper bound on the operator norm of the Hessian of a deep linear network with the result of Hardt and Ma that gradients are lower bounded in terms of the loss for near-identity matrices.,1 Introduction,[0],[0]
They otherwise have different outlines.,1 Introduction,[0],[0]
The bound in terms of the loss of the initial solution proceeds by showing that the distance from each layer to the identity grows slowly enough that the loss is reduced before the layers stray far enough to harm the conditioning of the Hessian.,1 Introduction,[0],[0]
"The bound for symmetric positive definite matrices proceeds by showing that, in this case, all of the layers are the same, and each of their eigenvalues converges to the Lth root of a corresponding eigenvalue of Φ. As mentioned above, the bound for γ-positive matrices Φ is for an algorithm that achieves favorable conditioning through regularization.
",1 Introduction,[0],[0]
"We expect that the theoretical analysis reported here will inform the design of practical algorithms
for learning non-linear deep networks.",1 Introduction,[0],[0]
One potential avenue for this arises from the fact that the leverage provided by regularizing toward the identity appears to already be provided by a weaker policy of promoting the property that the composition of layers is (potentially asymmetric) positive definite.,1 Introduction,[0],[0]
"Also, balancing singular values of the layers of the network aided our analysis; an analogous balancing of Jacobians associated with various layers may improve conditioning in practice in the non-linear case.",1 Introduction,[0],[0]
"For a joint distribution P with support contained in ℜd × ℜd and g : ℜd → ℜd, define ℓP (g) = E(X,Y )∼P (||g(X)",2.1 Setting,[0],[0]
− Y || 2/2).,2.1 Setting,[0],[0]
"We focus on the case that, for (X,Y ) drawn from P , the marginal on X is isotropic, with",2.1 Setting,[0],[0]
EXX⊤ = Id.,2.1 Setting,[0],[0]
"For convenience, we assume that Y = ΦX for Φ ∈ ℜd×d.",2.1 Setting,[0],[0]
This assumption is without loss of generality: if Φ is the least squares matrix (so that f defined by f(X) = ΦX minimizes ℓP,2.1 Setting,[0],[0]
"(f) among linear functions), for any linear g we have
ℓP (g) =",2.1 Setting,[0],[0]
E‖g(X),2.1 Setting,[0],[0]
− f(X)‖ 2/2 + E‖f(X)−,2.1 Setting,[0],[0]
"Y ‖2/2
+ E",2.1 Setting,[0],[0]
((g(X),2.1 Setting,[0],[0]
− f(X))(f(X),2.1 Setting,[0],[0]
"− Y ))
= E‖g(X)",2.1 Setting,[0],[0]
− f(X)‖2/2 +,2.1 Setting,[0],[0]
"E‖f(X)− Y ‖2/2
= E‖g(X)",2.1 Setting,[0],[0]
− ΦX)‖2/2 + E‖ΦX,2.1 Setting,[0],[0]
"− Y ‖2/2,
since f is the projection of Y onto the set of linear functions ofX.",2.1 Setting,[0],[0]
"So assuming Y = ΦX corresponds to setting Φ as the least squares matrix and replacing the loss ℓP (g) by the excess loss
E‖g(X)",2.1 Setting,[0],[0]
− ΦX‖2/2 = E‖g(X),2.1 Setting,[0],[0]
− Y ‖2/2−,2.1 Setting,[0],[0]
E‖ΦX,2.1 Setting,[0],[0]
"− Y ‖2/2.
",2.1 Setting,[0],[0]
We study algorithms that learn linear mappings parameterized by deep networks.,2.1 Setting,[0],[0]
"The network with L layers and parameters Θ = (Θ1, . . .",2.1 Setting,[0],[0]
",ΘL) computes the parameterized function fΘ(x) = ΘLΘL−1 · · ·Θ1x, where",2.1 Setting,[0],[0]
"x ∈ ℜd and Θi ∈ ℜd×d.
",2.1 Setting,[0],[0]
"We use the notation Θi:j = ΘjΘj−1 · · ·Θi for i ≤ j, so that we can write fΘ(x) = Θ1:Lx = Θi+1:LΘiΘ1:i−1x.
",2.1 Setting,[0],[0]
"When there is no possibility of confusion, we will sometimes refer to loss ℓ(fΘ) simply as ℓ(Θ).",2.1 Setting,[0],[0]
"Because the distribution of X is isotropic, ℓ(Θ) = 12 ||Θ1:L − Φ|| 2 F with respect to least squares matrix Φ. When Θ is produced by an iterative algorithm, will we also refer to loss of the tth iterate by ℓ(t).
",2.1 Setting,[0],[0]
Definition 1.,2.1 Setting,[0],[0]
"For γ > 0, a matrix A ∈ ℜd×d is γ-positive if, for all unit length u, we have u⊤Au > γ.",2.1 Setting,[0],[0]
"We use ||A||F for the Frobenius norm of matrix A, ||A||2 for its operator norm, and σmin(A) for its least singular value.",2.2 Tools and background,[0],[0]
"For vector v, we use ||v|| for its Euclidian norm.
",2.2 Tools and background,[0],[0]
"For a matrix A and a matrix-valued function B, define DAB(A) to be the matrix with
(DAB(A))i,j = ∂vec(B(A))i ∂vec(A)j ,
where vec(A) is the column vector constructed by stacking the columns of A. We use Td,d to denote the d2 × d2 permutation matrix mapping vec(A) to vec(A⊤) for A ∈ ℜd×d.",2.2 Tools and background,[0],[0]
"For A ∈ ℜn×m and B ∈ ℜp×q, A⊗B denotes the Kronecker product, that is, the np×mq matrix of n×m blocks, with the i, jth block given by AijB.
We will need the gradient and Hessian of ℓ. (The gradient, which can be computed using backprop, is of course well known.)",2.2 Tools and background,[0],[0]
"The proof is in Appendix A.
Lemma 1.
DΘiℓ (fΘ)=(vec(Id))",2.2 Tools and background,[0],[0]
"⊤ (( Θ⊤1:i−1 ⊗ (Θ1:L−Φ) ⊤Θi+1:L ))
",2.2 Tools and background,[0],[0]
"= vec(G)⊤,
where G is the d× d matrix given by
G def = Θ⊤i+1:",2.2 Tools and background,[0],[0]
"L (Θ1:L − Φ)Θ ⊤ 1:i−1. (1)
",2.2 Tools and background,[0],[0]
"For i < j,
DΘjDΘiℓ (fΘ) =",2.2 Tools and background,[0],[0]
(Id2 ⊗ (vec(Id)) ⊤),2.2 Tools and background,[0],[0]
"(Id ⊗ Td,d ⊗ Id)
( vec(Θ⊤1:i−1)⊗ Id2 )
",2.2 Tools and background,[0],[0]
"((Θ⊤i+1:LΘj+1:L ⊗Θ ⊤ 1:j−1)Td,d + (Θ ⊤ i+1:j−1 ⊗ (Θ1:L − Φ) ⊤Θj+1:L)).
DΘiDΘiℓ (fΘ)",2.2 Tools and background,[0],[0]
=,2.2 Tools and background,[0],[0]
(Id2 ⊗ (vec(Id)) ⊤),2.2 Tools and background,[0],[0]
"(Id ⊗ Td,d ⊗ Id)
( vec(Θ⊤1:i−1)⊗ Id2 )
(
Θ⊤i+1:LΘi+1:L ⊗Θ ⊤ 1:i−1
)
",2.2 Tools and background,[0],[0]
"Td,d.",2.2 Tools and background,[0],[0]
"In this section, we prove an upper bound for gradient descent in terms of the loss of the initial solution.",3 Targets near the identity,[0],[0]
"First, set Θ(0) =",3.1 Procedure and upper bound,[0],[0]
"(I, I, ..., I), and then iteratively update
Θ (t+1)",3.1 Procedure and upper bound,[0],[0]
i = Θ,3.1 Procedure and upper bound,[0],[0]
(t),3.1 Procedure and upper bound,[0],[0]
"i − η(Θ (t) i+1:L)
⊤ (
Θ (t) 1:",3.1 Procedure and upper bound,[0],[0]
"L − Φ
)
",3.1 Procedure and upper bound,[0],[0]
"(Θ (t) 1:i−1) ⊤.
Theorem 1.",3.1 Procedure and upper bound,[0],[0]
"There are positive constants c1 and c2 and polynomials p1 and p2 such that, if ℓ(Θ (0) 1:L) ≤ c1, L ≥ c2, and η ≤ 1 p1(L,d,||Φ||2) , then the above gradient descent procedure achieves
ℓ(fΘ(t)) ≤ ǫ within t = p2
(
1 η
)",3.1 Procedure and upper bound,[0],[0]
"ln (
ℓ(0) ǫ
)
iterations.",3.1 Procedure and upper bound,[0],[0]
"The following lemma, which is implicit in the proof of Theorem 2.2 in Hardt & Ma (2017), shows that the gradient is steep if the loss is large and the singular values of the layers are not too small.
",3.2 Proof of Theorem 1,[0],[0]
Lemma 2 (Hardt & Ma 2017).,3.2 Proof of Theorem 1,[0],[0]
Let ∇Θℓ(Θ) be the gradient of ℓ(Θ) with respect to any flattening of Θ.,3.2 Proof of Theorem 1,[0],[0]
"If, for all layers i, σmin(Θi) ≥ 1− a, then ||∇Θℓ(Θ)|| 2 ≥ 4ℓ(Θ)L(1− a)2L.
Next, we show that, if Θ(t) and Θ(t+1) are both close to the identity, then the gradient is not changing very fast between them, so that rapid progress continues to be made.",3.2 Proof of Theorem 1,[0],[0]
"We prove this through an upper bound on the operator norm of the Hessian that holds uniformly over members of a ball around the identity, which in turn can be obtained through a bound on the Frobenius norm.",3.2 Proof of Theorem 1,[0],[0]
"The proof is in Appendix B.
Lemma 3.",3.2 Proof of Theorem 1,[0],[0]
"Choose an arbitrary Θ with ||Θi||2 ≤ 1 + z for all i, and least squares matrix Φ with ||Φ||2 ≤ (1 + z)
L.",3.2 Proof of Theorem 1,[0],[0]
"Let ∇2 be the Hessian of ℓ(fΘ) with respect to an arbitrary flattening of the parameters of Θ. We have
||∇2||F ≤ 3Ld 5(1 + z)2L.
Armed with Lemmas 2 and 3, let us now analyze gradient descent.",3.2 Proof of Theorem 1,[0],[0]
"Very roughly, our strategy will be to show that the distance from the identity to the various layers grows slowly enough for the leverage from Lemmas 2 and 3 to enable successful learning.",3.2 Proof of Theorem 1,[0],[0]
Let R(Θ) = maxi ||Θi − I||2.,3.2 Proof of Theorem 1,[0],[0]
"From the update, we have
||Θ (t+1)",3.2 Proof of Theorem 1,[0],[0]
i − I||2 ≤ ||Θ (t) i,3.2 Proof of Theorem 1,[0],[0]
"− I||2 + η||(Θ (t) i+1:L)
⊤ (
Θ (t) 1:L − Φ
)
(Θ (t) 1:i−1) ⊤||2
≤ ||Θ (t) i",3.2 Proof of Theorem 1,[0],[0]
− I||2,3.2 Proof of Theorem 1,[0],[0]
+ η(1,3.2 Proof of Theorem 1,[0],[0]
+R(Θ (t)))L||Θ (t) 1:L − Φ||2 ≤ ||Θ,3.2 Proof of Theorem 1,[0],[0]
(t),3.2 Proof of Theorem 1,[0],[0]
i,3.2 Proof of Theorem 1,[0],[0]
− I||2,3.2 Proof of Theorem 1,[0],[0]
+ η(1,3.2 Proof of Theorem 1,[0],[0]
"+R(Θ (t)))L||Θ (t) 1:L − Φ||F .
",3.2 Proof of Theorem 1,[0],[0]
If R(t) = maxs≤tR(Θ(s)),3.2 Proof of Theorem 1,[0],[0]
(so R(0) = 0) and ℓ(t) = 12 ||Θ (t) 1:,3.2 Proof of Theorem 1,[0],[0]
"L − Φ|| 2 F , this implies
R(t+ 1) ≤",3.2 Proof of Theorem 1,[0],[0]
R(t),3.2 Proof of Theorem 1,[0],[0]
+ η(1,3.2 Proof of Theorem 1,[0],[0]
+R(t))L √ 2ℓ(t).,3.2 Proof of Theorem 1,[0],[0]
"(2)
By Lemma 3, for all Θ on the line segment from Θ(t) to Θ(t+1), we have
||∇2Θ||2 ≤ ||∇ 2 Θ||F ≤",3.2 Proof of Theorem 1,[0],[0]
"3Ld 5 max{(1 +R(t+ 1))2L, ||Φ||22},
so that
ℓ(t+ 1) ≤ ℓ(t)− η||∇Θ(t)",3.2 Proof of Theorem 1,[0],[0]
||,3.2 Proof of Theorem 1,[0],[0]
"2 +
3 2",3.2 Proof of Theorem 1,[0],[0]
η2Ld5 max{(1,3.2 Proof of Theorem 1,[0],[0]
"+R(t+ 1))2L, ||Φ||22}||∇Θ(t) || 2.
",3.2 Proof of Theorem 1,[0],[0]
"Thus, if we ensure
η ≤ 1
3Ld5 max{(1 +R(t+ 1))2L, ||Φ||22} , (3)
we have ℓ(t+ 1) ≤ ℓ(t)− (η/2)||∇Θ(t) || 2, which, using Lemma 2, gives
ℓ(t+ 1) ≤ ( 1− 2ηL(1 −R(t))2L ) ℓ(t).",3.2 Proof of Theorem 1,[0],[0]
"(4)
Pick any c ≥ 1.",3.2 Proof of Theorem 1,[0],[0]
"Assume that L ≥ (4/3) ln c = c2, ℓ(Θ (0) 1:L) ≤
ln(c)2
8c10 = c1 and η ≤ 1
3Ld5 max{c4,||Φ||22} .
",3.2 Proof of Theorem 1,[0],[0]
"We claim that, for all t ≥ 0,
1. R(t) ≤ ηc √ 2ℓ(0) ∑ 0≤s<t exp ( − sηLc4 )
2.",3.2 Proof of Theorem 1,[0],[0]
"ℓ(t) ≤ ( exp (
−2tηL c4
))
",3.2 Proof of Theorem 1,[0],[0]
"ℓ(0).
",3.2 Proof of Theorem 1,[0],[0]
"The base case holds as R(0) = 0 and ℓ(0) = ℓ(0).
",3.2 Proof of Theorem 1,[0],[0]
"Before starting the inductive step, notice that for any t ≥ 0,
ηc √ 2ℓ(0) ∑
0≤s<t exp
(
− sηL
c4
)
≤ ηc √ 2ℓ(0)× 1
1− exp (
−ηL c4
)
≤ ηc √ 2ℓ(0)× 2c4
ηL (since ηLc4 ≤ 1)
= 2c5 √ 2ℓ(0)
L ≤
ln c
L ≤ 3/4
where the last two inequalities follow from the constraints on ℓ(0) and L.
Using (2),
R(t+ 1) ≤ R(t) + η(1",3.2 Proof of Theorem 1,[0],[0]
"+R(t))L √ 2ℓ(t)
≤",3.2 Proof of Theorem 1,[0],[0]
R(t),3.2 Proof of Theorem 1,[0],[0]
"+ η
(
1 + ln c
L
)L √
2ℓ(t)
≤ R(t) + ηc √ 2ℓ(t)
≤ R(t) + ηc √ 2ℓ(0) exp
(
− tηL
c4
)
≤ ηc √ 2ℓ(0)",3.2 Proof of Theorem 1,[0],[0]
"∑
0≤s<t+1 exp
(
− sηL
c4
)
.
",3.2 Proof of Theorem 1,[0],[0]
"Since R(t+ 1) ≤ ln cL , the choice of η satisfies (3), so
ℓ(t+ 1) ≤ ( 1− 2ηL(1 −R(t))2L ) ℓ(t).
",3.2 Proof of Theorem 1,[0],[0]
"Now consider (1−R(t))2L:
ln ( (1−R(t))2L )",3.2 Proof of Theorem 1,[0],[0]
"= 2L ln(1−R(t))
",3.2 Proof of Theorem 1,[0],[0]
≥ 2L(−2R(t)),3.2 Proof of Theorem 1,[0],[0]
since R(t) ∈,3.2 Proof of Theorem 1,[0],[0]
"[0, 3/4]
≥ 2L
(
−2 ln c
L
)
since R(t) ≤",3.2 Proof of Theorem 1,[0],[0]
ln,3.2 Proof of Theorem 1,[0],[0]
"c
L
(1−R(t))2L ≥ 1/c4.
",3.2 Proof of Theorem 1,[0],[0]
"Using this in the bound on ℓ(t+ 1):
ℓ(t+ 1) ≤",3.2 Proof of Theorem 1,[0],[0]
"( 1− 2ηL(1 −R(t))2L ) ℓ(t)
≤
(
1− 2ηL
c4
)
ℓ(t)
≤
(
exp
(
− 2ηL
c4
))",3.2 Proof of Theorem 1,[0],[0]
"(
exp
(
− 2tηL
c4
))
",3.2 Proof of Theorem 1,[0],[0]
"ℓ(0)
",3.2 Proof of Theorem 1,[0],[0]
"=
(
exp
(
− 2(t+ 1)ηL
c4
))
",3.2 Proof of Theorem 1,[0],[0]
"ℓ(0).
",3.2 Proof of Theorem 1,[0],[0]
"Solving ℓ(0) exp (
−2tηL c4
)
≤ ǫ for t and recalling that η < 1/c4 completes the proof of the theorem.",3.2 Proof of Theorem 1,[0],[0]
"In this section, we analyze the procedure of Section 3.1 when the least squares matrix Φ is symmetric and positive definite.
Theorem 2.",4 Symmetric positive definite targets,[0],[0]
"There is an absolute positive constant c3 such that, if Φ is symmetric and γ-positive with 0 <",4 Symmetric positive definite targets,[0],[0]
"γ < 1, and L ≥ c3 ln (||Φ||2/γ), then for all η ≤
1 L(1+||Φ||22) , gradient descent achieves
ℓ(fΘ(t))",4 Symmetric positive definite targets,[0],[0]
"≤ ǫ in poly(L, ||Φ||2/γ, 1/η) log(d/ǫ) iterations.
",4 Symmetric positive definite targets,[0],[0]
Note that a symmetric matrix is γ-positive when its minimum eigenvalue is at least γ.,4 Symmetric positive definite targets,[0],[0]
"Let Φ be a symmetric, real, γ-positive matrix with γ > 0, and let Θ(0),Θ(1), ... be the iterates of gradient descent with a step size 0 < η ≤ 1
L(1+||Φ||22) .
",4.1 Proof of Theorem 2,[0],[0]
Definition 2.,4.1 Proof of Theorem 2,[0],[0]
"Symmetric matrices A ⊆ ℜd×d are commuting normal matrices if there is a single unitary matrix U such that for all A ∈ A, U⊤AU is diagonal.
",4.1 Proof of Theorem 2,[0],[0]
"We will use the following well-known facts about commuting normal matrices.
",4.1 Proof of Theorem 2,[0],[0]
Lemma 4 (Horn & Johnson 2013),4.1 Proof of Theorem 2,[0],[0]
.,4.1 Proof of Theorem 2,[0],[0]
"If A ⊆ ℜd×d is a set of symmetric commuting normal matrices and A,B ∈ A, the following hold:
• AB = BA;
",4.1 Proof of Theorem 2,[0],[0]
"• for all scalars α and β, A ∪ {αA+ βB,AB} are commuting normal;
• there is a unitary matrix U such that U⊤AU and U⊤BU are real and diagonal;
• the multiset of singular values of A is the same as the multiset of magnitudes of its eigenvalues;
• ||A− I||2 is the largest value of |z",4.1 Proof of Theorem 2,[0],[0]
"− 1| for an eigenvalue z of A.
Lemma 5.",4.1 Proof of Theorem 2,[0],[0]
"The matrices {Φ} ∪ {Θ (t) i : i ∈ {1, ..., L}, t ∈ Z +} are commuting normal.",4.1 Proof of Theorem 2,[0],[0]
"For all t, Θ (t) 1 = ... = Θ (t) L .
Proof.",4.1 Proof of Theorem 2,[0],[0]
The proof is by induction.,4.1 Proof of Theorem 2,[0],[0]
"The base case follows from the fact that Φ and I are commuting normal.
",4.1 Proof of Theorem 2,[0],[0]
"For the induction step, the fact that
{Φ} ∪ {
Θ (s)",4.1 Proof of Theorem 2,[0],[0]
i :,4.1 Proof of Theorem 2,[0],[0]
"i ∈ {1, ..., L}, s ≤ t
} ∪ {
Θ (s+1)",4.1 Proof of Theorem 2,[0],[0]
i :,4.1 Proof of Theorem 2,[0],[0]
"i ∈ {1, ..., L}, s ≤ t
}
are commuting normal follows from Lemma 4.",4.1 Proof of Theorem 2,[0],[0]
"The update formula now reveals that Θ (t+1) 1 = ... = Θ (t+1) L .
",4.1 Proof of Theorem 2,[0],[0]
Now we are ready to analyze the dynamics of the learning process.,4.1 Proof of Theorem 2,[0],[0]
"Let Φ = U⊤DLU be a diagonalization of Φ. Let Γ = max{1, ||Φ||2}.",4.1 Proof of Theorem 2,[0],[0]
"We next describe a sense in which gradient descent learns each eigenvalue independently.
",4.1 Proof of Theorem 2,[0],[0]
Lemma 6.,4.1 Proof of Theorem 2,[0],[0]
"For each t, there is a real diagonal matrix D̂(t) such that, for all i, Θ (t)",4.1 Proof of Theorem 2,[0],[0]
"i = U ⊤D̂(t)U and
D̂(t+1) = D̂(t)",4.1 Proof of Theorem 2,[0],[0]
− η(D̂(t))L−1((D̂(t))L −DL).,4.1 Proof of Theorem 2,[0],[0]
"(5)
Proof.",4.1 Proof of Theorem 2,[0],[0]
Lemma 5 implies that there is a single real U such that Θ (t),4.1 Proof of Theorem 2,[0],[0]
"i = U ⊤D̂(t)U for all i. Applying Lemma 1, recalling that Θ (t) 1 = ...",4.1 Proof of Theorem 2,[0],[0]
"= Θ (t) L , and applying the fact that Θ (t) i and Φ commute, we get
Θ (t+1)",4.1 Proof of Theorem 2,[0],[0]
i = Θ,4.1 Proof of Theorem 2,[0],[0]
(t),4.1 Proof of Theorem 2,[0],[0]
"i − η(Θ (t) i )
",4.1 Proof of Theorem 2,[0],[0]
"L−1 (
(Θ (t) i )
",4.1 Proof of Theorem 2,[0],[0]
"L − Φ ) .
",4.1 Proof of Theorem 2,[0],[0]
"Replacing each matrix by its diagonalization, we get
U⊤D̂(t+1)U = U⊤D̂(t)U",4.1 Proof of Theorem 2,[0],[0]
"− η(U⊤(D̂(t))L−1U) ( U⊤(D̂(t))LU − U⊤DLU )
",4.1 Proof of Theorem 2,[0],[0]
"= U⊤D̂(t)U − ηU⊤(D̂(t))L−1 ( (D̂(t))L −DL ) U,
and left-multiplying by U and right-multiplying by U⊤ gives (5).
",4.1 Proof of Theorem 2,[0],[0]
We will now analyze the convergence of each D̂ (t) kk to Dkk separately.,4.1 Proof of Theorem 2,[0],[0]
"Let us focus for now on an arbitrary single index k, let λ = Dkk and λ̂",4.1 Proof of Theorem 2,[0],[0]
(t) =,4.1 Proof of Theorem 2,[0],[0]
"D̂ (t) kk .
",4.1 Proof of Theorem 2,[0],[0]
Recalling that ||Φ||2 ≤,4.1 Proof of Theorem 2,[0],[0]
"Γ, we have γ 1/L ≤ λ ≤",4.1 Proof of Theorem 2,[0],[0]
"Γ1/L. Also, Γ1/L = e 1 L ln Γ ≤ e1/a ≤ 1+2/a whenever a ≥ 1 and L ≥ a ln Γ. Similarly, γ1/L ≥ 1 − a whenever L ≥ a ln(1/γ).",4.1 Proof of Theorem 2,[0],[0]
"Thus, there are absolute constants c3 and c4 such that",4.1 Proof of Theorem 2,[0],[0]
|1−,4.1 Proof of Theorem 2,[0],[0]
"λ| ≤ c4 ln(Γ/γ)
L < 1 for all L ≥ c3 ln(Γ/γ).
",4.1 Proof of Theorem 2,[0],[0]
"We claim that, for all t, λ̂(t) lies between 1 and λ inclusive, so that |λ̂(t)",4.1 Proof of Theorem 2,[0],[0]
− λ| ≤ c4 ln(Γ/γ)L .,4.1 Proof of Theorem 2,[0],[0]
The base case holds because λ̂(t) = 1 and |1,4.1 Proof of Theorem 2,[0],[0]
− λ| ≤ c4 ln(Γ/γ)L .,4.1 Proof of Theorem 2,[0],[0]
Now let us work on the induction step.,4.1 Proof of Theorem 2,[0],[0]
"Applying (5) together with Lemma 1, we get
λ̂(t+1) = λ̂(t) +",4.1 Proof of Theorem 2,[0],[0]
η(λ̂(t))L−1(λL,4.1 Proof of Theorem 2,[0],[0]
− (λ̂(t))L).,4.1 Proof of Theorem 2,[0],[0]
"(6)
By the induction hypothesis, we just need to show that sign(λ̂(t+1)",4.1 Proof of Theorem 2,[0],[0]
− λ̂(t)),4.1 Proof of Theorem 2,[0],[0]
= sign(λ − λ̂(t)) and |λ̂(t+1),4.1 Proof of Theorem 2,[0],[0]
− λ̂(t)| ≤ |λ,4.1 Proof of Theorem 2,[0],[0]
"− λ̂(t)| (i.e., the step is in the correct direction, and does not “overshoot”).",4.1 Proof of Theorem 2,[0],[0]
"First, to see that the step is in the right direction, note that λL ≥ (λ̂(t))L if and only if λ ≥ (λ̂(t)), and the inductive hypothesis implies that λ̂(t), and therefore (λ̂(t))L−1, is non-negative.",4.1 Proof of Theorem 2,[0],[0]
To show that |λ̂(t+1),4.1 Proof of Theorem 2,[0],[0]
− λ̂(t)| ≤ |λ,4.1 Proof of Theorem 2,[0],[0]
"− λ̂(t)|, it suffices to show that η(λ̂(t))L−1 ∣ ∣ ∣ λL − (λ̂(t))L) ∣ ∣ ∣ ≤ |λ",4.1 Proof of Theorem 2,[0],[0]
"− λ̂(t)|,
which, in turn would be implied by η ≤
∣ ∣ ∣ ∣ 1 (λ̂(t))L−1( ∑L−1 i=0 (λ̂ (t))iλL−1−i) ∣ ∣ ∣ ∣ (since λL − (λ̂(t))L = (λ −
λ̂(t))",4.1 Proof of Theorem 2,[0],[0]
"∑L−1 i=0 (λ̂ (t))iλL−1−i), which follows from the inductive hypothesis and η ≤ 1 LΓ2 .",4.1 Proof of Theorem 2,[0],[0]
"We have proved that each λ̂(t) lies between λ and 1, so that |1−",4.1 Proof of Theorem 2,[0],[0]
λ̂(t)| ≤ |1−,4.1 Proof of Theorem 2,[0],[0]
"λ| ≤ c4 ln(Γ/γ).
",4.1 Proof of Theorem 2,[0],[0]
"Now, since the step is in the right direction, and does not overshoot,
|λ̂(t+1)",4.1 Proof of Theorem 2,[0],[0]
− λ| ≤ |λ̂(t) − λ| − η(λ̂(t))L−1|λL,4.1 Proof of Theorem 2,[0],[0]
"− (λ̂(t))L|
≤ |λ̂(t) − λ|
( 1− η(λ̂(t))L−1 ( L−1 ∑
i=0
(λ̂(t))iλL−1−i ))
≤ |λ̂(t)",4.1 Proof of Theorem 2,[0],[0]
"− λ| ( 1− ηLγ2 ) ,
since the fact that λ̂(t) lies between 1 and λ implies that λ̂(t) ≥ γ1/L. Thus, |λ̂(t) − λ| ≤ (
1− ηLγ2 )t c4",4.1 Proof of Theorem 2,[0],[0]
ln(Γ/γ).,4.1 Proof of Theorem 2,[0],[0]
"This implies that, for any ǫ ∈ (0, 1), for any absolute constant c5, there is a
constant c6 such that, after c6 1 ηLγ2 ln ( dL lnΓ γǫ )
steps, we have |λ̂(t)−λ| ≤ c5γ √ ǫ
LΓ √ d .Writing",4.1 Proof of Theorem 2,[0],[0]
"r = λ̂(t)−λ,
this implies, if c5 is small enough, that
((λ̂(t))L − λL)2 = ((λ+r)L−λL)2
≤ Γ2",4.1 Proof of Theorem 2,[0],[0]
"( ( 1+ r
λ
)L −1
)2
≤ Γ2 ( 2c5rL
λ
)2
≤ Γ2 ( 2c5rL
γ
)2
≤ ǫ
d .
",4.1 Proof of Theorem 2,[0],[0]
"Thus, after O (
1 ηLγ2
ln (
dL lnΓ γǫ
))
steps, (Dkk − D̂ (t) kk ) 2 ≤ ǫ/d for all k, and therefore ℓ(Θ(t))",4.1 Proof of Theorem 2,[0],[0]
"≤ ǫ,
completing the proof.",4.1 Proof of Theorem 2,[0],[0]
"We have seen that if the least squares matrix is symmetric, γ-positivity is sufficient for convergence of gradient descent.",5 Asymmetric positive definite matrices,[0],[0]
We shall see in Section 6 that positivity is also necessary for a broad family of gradient-based algorithms to converge to the optimal solution when the least squares matrix is symmetric.,5 Asymmetric positive definite matrices,[0],[0]
"Thus, in the symmetric case, positivity characterizes the success of gradient methods.
",5 Asymmetric positive definite matrices,[0],[0]
"In this section, we show that positivity suffices for the convergence of a gradient method even without the assumption that the least squares matrix is symmetric.
",5 Asymmetric positive definite matrices,[0],[0]
Note that the set of γ-positive (but not necessarily symmetric) matrices includes both rotations by an acute angle and “partial reflections” of the form ax + b refl(x) where refl(·) is a lengthpreserving reflection and 0 ≤,5 Asymmetric positive definite matrices,[0],[0]
|b| < a.,5 Asymmetric positive definite matrices,[0],[0]
"Since ( u⊤Au )⊤
= u⊤A⊤u, a matrix A is γ-positive if",5 Asymmetric positive definite matrices,[0],[0]
"and only if u⊤(A+A⊤)u ≥ 2γ for all unit length u, i.e. A+A⊤ is positive definite with eigenvalues at least 2γ.",5 Asymmetric positive definite matrices,[0],[0]
"The algorithm analyzed in this section uses a construction that is new, as far as we know, that we call a balanced factorization.",5.1 Balanced factorizations,[0],[0]
"This factorization may be of independent interest.
",5.1 Balanced factorizations,[0],[0]
Recall that a polar decomposition of a matrix A consists of a unitary matrix R and a positive semidefinite matrix P such that A = RP .,5.1 Balanced factorizations,[0],[0]
The principal Lth root of a complex number whose expression in polar coordinates is reθi is r1/Leθi/L.,5.1 Balanced factorizations,[0],[0]
"The principal Lth root of a matrix A is the matrix B such that BL = A, and each eigenvalue of B is the principal Lth root of the corresponding eigenvalue of A.
Definition 3.",5.1 Balanced factorizations,[0],[0]
"If A be a matrix with polar decomposition RP , then A has the balanced factorization A = A1, ..., AL where for each i,
Ai = R 1/LPi, with Pi = R (L−i)/LP 1/LR−(L−i)/L,
and each of the Lth roots is the principal Lth root.
",5.1 Balanced factorizations,[0],[0]
The motivation for balanced factorization is as follows.,5.1 Balanced factorizations,[0],[0]
"We want each factor to do a 1/L fraction of the total amount of rotation, and a 1/L fraction of the total amount of scaling.",5.1 Balanced factorizations,[0],[0]
"However, the scaling done by the ith factor should be done in directions that take account of the partial rotations done by the other factors.",5.1 Balanced factorizations,[0],[0]
"The following is the key property of the balanced factorization; its proof is in Appendix C.
Lemma 7.",5.1 Balanced factorizations,[0],[0]
"If σ1, ..., σd are the singular values of A, and A1, ..., AL is a balanced factorization of A, then the following hold: (a) A = ∏L
i=1Ai; (b) for each i ∈ {1, ..., L}, σ 1/L 1 , ..., σ 1/L d are the singular
values of Ai.",5.1 Balanced factorizations,[0],[0]
The following is the power projection algorithm.,5.2 Procedure and upper bound,[0],[0]
"It has a positivity parameter γ > 0, and uses H = {A : ∀u s.t. ||u||",5.2 Procedure and upper bound,[0],[0]
"= 1, u⊤Au ≥ γ} as its “hypothesis space”.",5.2 Procedure and upper bound,[0],[0]
"First, it initializes Θ(0)i = γ 1/LI for all i ∈ {1, ..., L}.",5.2 Procedure and upper bound,[0],[0]
"Then, for each t, it does the following.
",5.2 Procedure and upper bound,[0],[0]
• Gradient Step.,5.2 Procedure and upper bound,[0],[0]
"For each i ∈ {1, ..., L}, update:
Θ (t+1/2)",5.2 Procedure and upper bound,[0],[0]
i = Θ,5.2 Procedure and upper bound,[0],[0]
(t),5.2 Procedure and upper bound,[0],[0]
"i − η(Θ (t) i+1:L)
⊤ (
Θ (t) 1:",5.2 Procedure and upper bound,[0],[0]
"L − Φ
)
",5.2 Procedure and upper bound,[0],[0]
"(Θ (t) 1:i−1) ⊤.
• Power Project.",5.2 Procedure and upper bound,[0],[0]
Compute the projection Ψ(t+1/2) (w.r.t.,5.2 Procedure and upper bound,[0],[0]
"the Frobenius norm) of Θ (t+1/2) 1:L
onto H.
• Factor.",5.2 Procedure and upper bound,[0],[0]
"Let Θ (t+1) 1 , ...,Θ (t+1) L be the balanced factorization of Ψ (t+1/2), so that Ψ(t+1/2) =
Θ (t+1) 1:L .
",5.2 Procedure and upper bound,[0],[0]
Theorem 3.,5.2 Procedure and upper bound,[0],[0]
For any Φ such that u⊤Φu >,5.2 Procedure and upper bound,[0],[0]
"γ for all unit-length u, the power projection algorithm produces Θ(t) with ℓ(Θ(t))",5.2 Procedure and upper bound,[0],[0]
"≤ ǫ in poly(d, ||Φ||F , 1 γ ) log(1/ǫ) iterations.",5.2 Procedure and upper bound,[0],[0]
Lemma 8.,5.3 Proof of Theorem 3,[0],[0]
"For all t, Θ (t) 1:L ∈ H.
Proof.",5.3 Proof of Theorem 3,[0],[0]
"Θ (0) 1:L = γI ∈ H, and, for all t, Ψ (t+1/2) is obtained by projection onto H, and Θ (t+1) 1:L = Ψ(t+1/2).
",5.3 Proof of Theorem 3,[0],[0]
Definition 4.,5.3 Proof of Theorem 3,[0],[0]
The exponential of a matrix A is exp(A),5.3 Proof of Theorem 3,[0],[0]
"def = ∑∞
k=0 1 k!A k, and B is a logarithm of A if A = exp(B).
",5.3 Proof of Theorem 3,[0],[0]
Lemma 9 (Culver 1966).,5.3 Proof of Theorem 3,[0],[0]
"A real matrix has a real logarithm if and only if it is invertible and each Jordan block belonging to a negative eigenvalue occurs an even number of times.
",5.3 Proof of Theorem 3,[0],[0]
Lemma 10.,5.3 Proof of Theorem 3,[0],[0]
"For all t, Θ (t) 1:L has a real Lth root.
",5.3 Proof of Theorem 3,[0],[0]
Proof.,5.3 Proof of Theorem 3,[0],[0]
Since Θ (t) 1:L ∈ H implies u,5.3 Proof of Theorem 3,[0],[0]
⊤Θ(t)1,5.3 Proof of Theorem 3,[0],[0]
:Lu > 0,5.3 Proof of Theorem 3,[0],[0]
"for all u, Θ (t) 1:L does not have a negative eigenvalue and is invertible.",5.3 Proof of Theorem 3,[0],[0]
"By Lemma 9, Θ (t) 1:L has a real logarithm.",5.3 Proof of Theorem 3,[0],[0]
"Thus, its real Lth root can be constructed via exp(log(Θ (t) 1:L)/L).
",5.3 Proof of Theorem 3,[0],[0]
"The preceding lemma implies that the algorithm is well-defined, since all of the required roots can be calculated.
",5.3 Proof of Theorem 3,[0],[0]
Lemma 11.,5.3 Proof of Theorem 3,[0],[0]
"H is convex.
",5.3 Proof of Theorem 3,[0],[0]
Proof.,5.3 Proof of Theorem 3,[0],[0]
"Suppose A and B are in H and λ ∈ (0, 1).",5.3 Proof of Theorem 3,[0],[0]
"We have
u⊤(λA+ (1− λ)B)u = λu⊤Au+ (1− λ)u⊤Bu ≥ γ.
Lemma 12.",5.3 Proof of Theorem 3,[0],[0]
"For all A ∈ H, σmin(A) ≥ γ.
",5.3 Proof of Theorem 3,[0],[0]
Proof.,5.3 Proof of Theorem 3,[0],[0]
"Let u and v be singular vectors such that u⊤Av = σmin(A).
",5.3 Proof of Theorem 3,[0],[0]
"γ ≤ v⊤Av = σmin(A)v ⊤u ≤ σmin(A).
",5.3 Proof of Theorem 3,[0],[0]
Lemma 13.,5.3 Proof of Theorem 3,[0],[0]
"For all t, σmin(Θ (t) i )",5.3 Proof of Theorem 3,[0],[0]
"≥ γ 1/L.
Proof.",5.3 Proof of Theorem 3,[0],[0]
"First, σmin(Θ (0) i ) =",5.3 Proof of Theorem 3,[0],[0]
γ 1/L ≥ γ1/L. Now consider t > 0.,5.3 Proof of Theorem 3,[0],[0]
"Since Ψ(t−1/2) was projected into H, we have σmin(Ψ(t−1/2))",5.3 Proof of Theorem 3,[0],[0]
≥ γ.,5.3 Proof of Theorem 3,[0],[0]
"Lemma 7 then completes the proof.
",5.3 Proof of Theorem 3,[0],[0]
"Define U(t) = max {
maxs≤tmaxi ||Θ (s) i ||2, ||Φ|| 1/L 2
}
, B(t) = mins≤tmini σmin(Θ (s) i ), and recall that
ℓ(t) = ||Θ (t) 1:L − Φ|| 2 F .
",5.3 Proof of Theorem 3,[0],[0]
"Arguing as in the initial portion of Section 3.2, as long as
η ≤ 1
3Ld5U(t)2L (7)
we have ℓ(t + 1/2) ≤",5.3 Proof of Theorem 3,[0],[0]
( 1− ηLB(t)2L ) ℓ(t) (see Equation 4).,5.3 Proof of Theorem 3,[0],[0]
"Lemma 13 gives B(t) ≥ γ1/L, so ℓ(t+ 1/2) ≤",5.3 Proof of Theorem 3,[0],[0]
"( 1− ηLγ2 )
ℓ(t).",5.3 Proof of Theorem 3,[0],[0]
"Since Ψ(t+1/2) is the projection of Θ (t+1/2) 1:L onto a convex set H that
contains Φ, and Θ (t+1) 1:L = Ψ (t+1/2), (7) implies
ℓ(t+ 1) ≤ ℓ(t+ 1/2) ≤",5.3 Proof of Theorem 3,[0],[0]
( 1− ηLγ2 ) ℓ(t).,5.3 Proof of Theorem 3,[0],[0]
"(8)
Next, we prove an upper bound on U .
",5.3 Proof of Theorem 3,[0],[0]
Lemma 14.,5.3 Proof of Theorem 3,[0],[0]
"For all t, U(t) ≤ ( √
ℓ(t) + ||Φ||F
)1/L .
",5.3 Proof of Theorem 3,[0],[0]
Proof.,5.3 Proof of Theorem 3,[0],[0]
Recall that ℓ(t) = ||Θ (t) 1:L−Φ|| 2 F .,5.3 Proof of Theorem 3,[0],[0]
"By the triangle inequality, ||Θ (t) 1:L||F ≤",5.3 Proof of Theorem 3,[0],[0]
√ ℓ(t)+ ||Φ||F .,5.3 Proof of Theorem 3,[0],[0]
Thus ||Θ (t) 1:L||2 ≤ √ ℓ(t) + ||Φ||F .,5.3 Proof of Theorem 3,[0],[0]
"By Lemma 7, for all i, we have ||Θ (t)",5.3 Proof of Theorem 3,[0],[0]
i ||2 ≤ ( √ ℓ(t) + ||Φ||F )1/L .,5.3 Proof of Theorem 3,[0],[0]
"Since ||Φ||2 ≤ ||Φ||F , this completes the proof.
",5.3 Proof of Theorem 3,[0],[0]
Note that the triangle inequality implies that ℓ(0) ≤ ||Θ (0) 1:L|| 2 F + ||Φ|| 2 F ≤,5.3 Proof of Theorem 3,[0],[0]
γ 2d,5.3 Proof of Theorem 3,[0],[0]
+,5.3 Proof of Theorem 3,[0],[0]
||Φ||2F .,5.3 Proof of Theorem 3,[0],[0]
Since σmin(Φ) ≥,5.3 Proof of Theorem 3,[0],[0]
"γ, we have ||Φ|| 2 F ≥ γ 2d, so ℓ(t) ≤ 2||Φ||2F and U(t) ≤ (3||Φ||2) 1/L.",5.3 Proof of Theorem 3,[0],[0]
"Now, if we set η = 1 cLd5||Φ||2
F , for a large enough absolute constant c, then (7) is satisfied, so that (8) gives ℓ(t+1) ≤ (
1− γ 2
cd5||Φ||2 F
)
ℓ(t) and the power projection algorithm achieves ℓ(t+ 1) ≤ ǫ after
O
(
d5||Φ||2F γ2 log
(
ℓ(0)
ǫ
))
",5.3 Proof of Theorem 3,[0],[0]
"=O
(
d5||Φ||2F γ2 log
(
||Φ||2F ǫ
))
updates.",5.3 Proof of Theorem 3,[0],[0]
"In this section, we show that positive definite Φ are necessary for several gradient descent algorithms with different kinds of regularization to minimize the loss.",6 Failure,[0],[0]
"One family of algorithms that we will
analyze is parameterized by a function ψ mapping the number of inputs d and the number of layers L to a radius ψ(d, L), step sizes ηt and initialization parameter γ ≥ 0.",6 Failure,[0],[0]
"In particular, a ψ-step-and-project algorithm is any instantiation of the following algorithmic template.
",6 Failure,[0],[0]
Initialize each Θ (0),6 Failure,[0],[0]
"i = γ 1/LI for some γ ≥ 0 and iterate:
• Gradient Step.",6 Failure,[0],[0]
"For each i ∈ {1, ..., L}, update:
Θ (t+1/2)",6 Failure,[0],[0]
i = Θ,6 Failure,[0],[0]
(t),6 Failure,[0],[0]
"i − ηt(Θ (t) i+1:L)
⊤ (
Θ (t) 1:L − Φ
)
(Θ (t) 1:i−1) ⊤.
• Project.",6 Failure,[0],[0]
Set each Θt+1i,6 Failure,[0],[0]
"to the projection of Θ t+1/2 i onto {A : ||A− I||2 ≤ ψ(d, L)}.
",6 Failure,[0],[0]
We will also show that Penalty Regularized Gradient Descent which uses gradient descent with any step sizes ηt on the regularized objective ℓ(Θ) + κ 2 ∑ i ||I,6 Failure,[0],[0]
"−Θ|| 2 F also fails to minimize the loss.
",6 Failure,[0],[0]
"Both results use the simple observation that when Θ1:L and Φ are mutually diagonalizable then
||Θ1:L − Φ|| 2 F = ||U ⊤D̂U",6 Failure,[0],[0]
"− U⊤DU ||2F = d ∑
j=1
(D̂jj −Djj) 2,
where the Dii are the eigenvalues of Φ.
Theorem 4.",6 Failure,[0],[0]
If the least squares matrix Φ is symmetric then Penalty Regularized Gradient Descent produces hypotheses Θ (t) 1:L that are commuting normal with Φ.,6 Failure,[0],[0]
"In addition, if Φ has a negative eigenvalue −λ and L is even, then ℓ(Θ(t))",6 Failure,[0],[0]
"≥ λ2/2 for all t.
Proof.",6 Failure,[0],[0]
"For all t, Penalty Regularized Gradient Descent produces Θ (t+1) i = (1 − κ)Θ (t) i + κI",6 Failure,[0],[0]
− ηt(Θ (t) i+1:L) ⊤ ( Θ (t) 1:L −Φ ) (Θ (t) 1:i−1) ⊤.,6 Failure,[0],[0]
"Thus, by induction, the Θ(t)i are matrix polynomials of Φ, and therefore they are all commuting normal.",6 Failure,[0],[0]
As in Lemmas 5 and 6 each Θ (t) i is the same U ⊤D̃(t)U and Θ (t) 1,6 Failure,[0],[0]
:L = U ⊤(D̃(t))LU .,6 Failure,[0],[0]
"Since L is even, each (D̃(t))Ljj ≥ 0, so ℓ(Θ (t))",6 Failure,[0],[0]
"= 12 ||Θ (t) 1:L−Φ|| 2 F ≥ λ 2/2.
To analyze step-and-project algorithms, it is helpful to first characterize the project step (see also (Lefkimmiatis et al., 2013)).
",6 Failure,[0],[0]
Lemma 15.,6 Failure,[0],[0]
"Let X be a symmetric matrix and let U⊤DU be its diagonalization.
",6 Failure,[0],[0]
"For a > 0, let Y be the Frobenius norm projection of X onto Ba = {A : A is symmetric psd and ||A−I||2 ≤ a}.",6 Failure,[0],[0]
"Then Y = U
⊤D̃U where D̃ is obtained from D by projecting all of its diagonal elements onto [1− a, 1 + a].
",6 Failure,[0],[0]
"Thus {X,Y } are symmetric commuting normal matrices.
",6 Failure,[0],[0]
Proof.,6 Failure,[0],[0]
"First, if X ∈ Ba, then Y = X and we are done.",6 Failure,[0],[0]
Assume X 6∈ Ba.,6 Failure,[0],[0]
"Clearly U ⊤D̃U ∈ Ba, so we just need to show that any member of Ba is at least as far from X as U⊤D̃U is.",6 Failure,[0],[0]
"Let Λ be the multiset of eigenvalues of X (with repetitions) that are not in [1 − a, 1 + a], and for each λ ∈ Λ, let eλ be the adjustment to λ necessary to bring it to [1− a, 1 + a]; i.e., so that λ+ eλ is the projection of λ onto [1− a, 1 + a].
",6 Failure,[0],[0]
"If uλ is the eigenvector associated with λ, we have U ⊤D̃U −X = ∑ λ∈Λ eλuλu ⊤ λ , so that ||U ⊤D̃U",6 Failure,[0],[0]
− X||2F = ∑,6 Failure,[0],[0]
λ∈Λ,6 Failure,[0],[0]
e 2 λ.,6 Failure,[0],[0]
Let Z be an arbitrary member of Ba.,6 Failure,[0],[0]
We would like to show that ||Z,6 Failure,[0],[0]
− X|| 2 F ≥ ∑ λ∈Λ e 2 λ.,6 Failure,[0],[0]
"Since Z ∈ Ba, we have ||Z − I||2 ≤ a. ||Z",6 Failure,[0],[0]
− I||2 is the largest singular value of Z,6 Failure,[0],[0]
"− I so, for any unit length vector, in particular some uλ for λ ∈ Λ, |u ⊤ λ (Z",6 Failure,[0],[0]
− I)uλ| = |u ⊤ λ,6 Failure,[0],[0]
"Zuλ − 1| ≤ a, which implies u⊤λZuλ ∈",6 Failure,[0],[0]
"[1 − a, 1 + a].",6 Failure,[0],[0]
Since U is unitary U ⊤(X,6 Failure,[0],[0]
"− Z)U has the same eigenvalues as X − Z, and, since the Frobenius norm is a function of the eigenvalues, ||U⊤(X − Z)U ||F = ||X − Z||F .",6 Failure,[0],[0]
But since u⊤λZuλ ∈,6 Failure,[0],[0]
"[1 − a, 1 + a] for all λ ∈ Λ, just summing over the diagonal elements, we get ||U⊤(X − Z)U",6 Failure,[0],[0]
"||2F ≥ ∑ λ∈Λ e 2 λ, completing the proof.
",6 Failure,[0],[0]
Theorem 5.,6 Failure,[0],[0]
If the least squares matrix Φ is symmetric then ψ-step-and-project algorithms produce hypotheses Θ (t) 1:L that are commuting normal with Φ.,6 Failure,[0],[0]
"In addition, if Φ has a negative eigenvalue −λ and either L is even or ψ(L, d) ≤ 1, then ℓ(Θ(t))",6 Failure,[0],[0]
"≥ λ2/2 for all t.
Proof.",6 Failure,[0],[0]
"As in Lemmas 5 and 6, the Θ (t+1/2)",6 Failure,[0],[0]
i are identical and mutually diagonalizable with Φ. Lemma 15 shows that this is preserved by the projection step.,6 Failure,[0],[0]
Thus there is a real diagonal D̃(t) such that each Θ (t) i = U ⊤D(t)i,6 Failure,[0],[0]
"U , so Θ (t) 1:L = U ⊤(D̃(t))LU .",6 Failure,[0],[0]
"When L is even, each (D̃(t))L)j,j ≥ 0.",6 Failure,[0],[0]
"When ψ(d, L) ≤ 1",6 Failure,[0],[0]
"then the projection ensures that the elements of D̃(t) are non-negative, and thus each (D̃(t))L)j,j ≥ 0.",6 Failure,[0],[0]
"In either case, ℓ(Θ (t))",6 Failure,[0],[0]
"= 12 ||Θ (t) 1:L− Φ||2F ≥ λ 2/2.
",6 Failure,[0],[0]
"One choice of Φ that satisfies the requirements of Theorems 4 and 5 is Φ = diag(−λ, 1, 1, ..., 1).",6 Failure,[0],[0]
"For constant λ, the loss of Θ(0) = (I, I, ..., I) is a constant for this target.",6 Failure,[0],[0]
"Another choice is Φ = diag(−λ,−λ, 1, 1, ..., 1), which has a positive determinant.
",6 Failure,[0],[0]
Our proof of failure to minimize the loss exploits the fact that the layers are initialized to multiples of the identity.,6 Failure,[0],[0]
"Since the training process is a continuous function of the initial solution, this implies that any convergence to a good solution will be very slow if the initializations are sufficiently close to the identity.",6 Failure,[0],[0]
"We thank Yair Carmon, Nigel Duffy, Matt Feiszli, Roy Frostig, Vineet Gupta, Moritz Hardt, Tomer Koren, Antoine Saliou, Hanie Sedghi, Yoram Singer and Kunal Talwar for valuable conversations.
",Acknowledgements,[0],[0]
Peter Bartlett gratefully acknowledges the support of the NSF through grant IIS-1619362 and of the Australian Research Council through an Australian Laureate Fellowship (FL110100281) and through the Australian Research Council Centre of Excellence for Mathematical and Statistical Frontiers (ACEMS).,Acknowledgements,[0],[0]
"We rely on the following facts (Horn, 1986; Harville, 1997).
",A Proof of Lemma 1,[0],[0]
Lemma 16.,A Proof of Lemma 1,[0],[0]
"For compatible matrices (and, where m,n, p, q, r, s are mentioned, A ∈ ℜm×n, B ∈ ℜp×q, X ∈ ℜr×s):
A⊗ (B ⊗ E) =",A Proof of Lemma 1,[0],[0]
"(A⊗B)⊗E,
AC ⊗BD = (A⊗B)(C ⊗D),
(A⊗B)⊤ = A⊤ ⊗B⊤,
vec(AXB) = (B⊤ ⊗A)vec(X),
Tm,nvec(A) def = vec(A⊤),
Tn,mTm,n = Imn,
Tm,n = T ⊤ n,m,
T1,n = Tn,1 =",A Proof of Lemma 1,[0],[0]
"In,
DX(A(B(X)))",A Proof of Lemma 1,[0],[0]
"= DB(A(B(X)))DX (B(X)),
DX(A(X)B(X))",A Proof of Lemma 1,[0],[0]
= (B(X) ⊤ ⊗ Im)DXA(X),A Proof of Lemma 1,[0],[0]
+,A Proof of Lemma 1,[0],[0]
"(Iq ⊗A(X))DXB(X),
DX(A(X) T ) = Tn,mDX(A(X)),
DX(AXB)",A Proof of Lemma 1,[0],[0]
"= B ⊤ ⊗A,
DA(A⊗B) =",A Proof of Lemma 1,[0],[0]
"(In ⊗ Tq,m ⊗ Ip)(Imn ⊗ vec(B))
=",A Proof of Lemma 1,[0],[0]
"(Inq ⊗ Tm,p)(In ⊗ vec(B)⊗",A Proof of Lemma 1,[0],[0]
"Im),
DB(A⊗B) =",A Proof of Lemma 1,[0],[0]
"(In ⊗ Tq,m ⊗ Ip)(vec(A)⊗ Ipq)
= (Tp,q ⊗ Imn)(Iq ⊗ vec(A)⊗",A Proof of Lemma 1,[0],[0]
"Ip).
",A Proof of Lemma 1,[0],[0]
"Armed with Lemma 16, we now prove Lemma 1.",A Proof of Lemma 1,[0],[0]
"We have
DΘifΘ(x) = DΘi (Θi+1:LΘiΘ1:i−1x) =",A Proof of Lemma 1,[0],[0]
"(Θ1:i−1x) ⊤ ⊗Θi+1:L.
Again, from Lemma 16
DΘi ( DΘjfΘ(x) )",A Proof of Lemma 1,[0],[0]
"= DΘi
(
(Θ1:j−1x) ⊤ ⊗Θj+1:L
)
= DΘ1:j−1x
(
(Θ1:j−1x) ⊤ ⊗Θj+1:L
)
DΘi (Θ1:j−1x)
(by the chain rule, since i < j)
= DΘ1:j−1x
(
(
(Θ1:j−1x)⊗Θ ⊤ j+1:L
)⊤ ) (
(Θ1:i−1x) ⊤",A Proof of Lemma 1,[0],[0]
"⊗Θi+1:j−1
)
.",A Proof of Lemma 1,[0],[0]
"(9)
Define P = Θ1:j−1x and Q = Θj+1:L, so that P ∈ ℜd×1 and Q ∈ ℜd×d.",A Proof of Lemma 1,[0],[0]
"We have
DP
(
( P ⊗Q⊤ )⊤ )
= Td2,dDP
( P ⊗Q⊤ )
",A Proof of Lemma 1,[0],[0]
"= Td2,d(I1 ⊗ Td,d ⊗ Id)(Id ⊗ vec(Q T ))",A Proof of Lemma 1,[0],[0]
"= Td2,d(Td,d ⊗ Id)(Id ⊗ vec(Q ⊤)).
",A Proof of Lemma 1,[0],[0]
"Substituting back into (9), we get
DΘi ( DΘjfΘ(x) )",A Proof of Lemma 1,[0],[0]
"= Td2,d(Td,d ⊗ Id)(Id ⊗ vec(Θ ⊤ j+1:L))
",A Proof of Lemma 1,[0],[0]
"(
(Θ1:i−1x) ⊤",A Proof of Lemma 1,[0],[0]
"⊗Θi+1:j−1
)
.
",A Proof of Lemma 1,[0],[0]
"The product rule in Lemma 16 gives, for each i,
DΘiℓ (fΘ)",A Proof of Lemma 1,[0],[0]
"= E(DΘi(ℓ(fΘ(X)))
= E(DΘi( 1
2 (fΘ(X)− ΦX)
⊤(fΘ(X)",A Proof of Lemma 1,[0],[0]
"−ΦX)))
",A Proof of Lemma 1,[0],[0]
= E(((Θ1:L − Φ)X) ⊤DΘifΘ(X)),A Proof of Lemma 1,[0],[0]
"= E ( ((Θ1:L − Φ)X) ⊤ ( (Θ1:i−1X) ⊤ ⊗Θi+1:L ))
",A Proof of Lemma 1,[0],[0]
= E,A Proof of Lemma 1,[0],[0]
( (I1 ⊗,A Proof of Lemma 1,[0],[0]
"((Θ1:L − Φ)X) ⊤) ( (Θ1:i−1X) ⊤ ⊗Θi+1:L ))
",A Proof of Lemma 1,[0],[0]
"= E (( (Θ1:i−1X) ⊤ ⊗ ((Θ1:L −Φ)X) ⊤Θi+1:L ))
",A Proof of Lemma 1,[0],[0]
= E,A Proof of Lemma 1,[0],[0]
(( X⊤Θ⊤1:i−1 ) ⊗,A Proof of Lemma 1,[0],[0]
( X⊤(Θ1:L −Φ) ⊤Θi+1:,A Proof of Lemma 1,[0],[0]
L )),A Proof of Lemma 1,[0],[0]
"= E ( (X⊤ ⊗X⊤) (
Θ⊤1:i−1 ⊗ (Θ1:L − Φ) ⊤Θi+1:L
))
= E ((X ⊗X)vec(1))⊤ ( Θ⊤1:i−1 ⊗",A Proof of Lemma 1,[0],[0]
"(Θ1:L − Φ) ⊤Θi+1:L )
= E ( vec(XX⊤) )",A Proof of Lemma 1,[0],[0]
"⊤ (
Θ⊤1:i−1 ⊗ (Θ1:L − Φ) ⊤Θi+1:L
)
= (vec(Id))",A Proof of Lemma 1,[0],[0]
"T ( Θ⊤1:i−1 ⊗ (Θ1:L − Φ) ⊤Θi+1:L ) .
",A Proof of Lemma 1,[0],[0]
"Hence,
(DΘiℓ (fΘ))",A Proof of Lemma 1,[0],[0]
"⊤ =
(
Θ1:i−1 ⊗Θ ⊤ i+1:L(Θ1:L − Φ)
)
(vec(Id))
",A Proof of Lemma 1,[0],[0]
"= vec ( Θ⊤i+1:L(Θ1:L − Φ)IdΘ ⊤ 1:i−1 ) .
",A Proof of Lemma 1,[0],[0]
"Also, recalling that i < j, we have
DΘjDΘiℓ (fΘ)",A Proof of Lemma 1,[0],[0]
"= DΘj
( (vec(Id))",A Proof of Lemma 1,[0],[0]
T ( Θ⊤1:i−1 ⊗ (Θ1:L − Φ) ⊤Θi+1,A Proof of Lemma 1,[0],[0]
":L ))
",A Proof of Lemma 1,[0],[0]
= (Id2 ⊗ (vec(Id)),A Proof of Lemma 1,[0],[0]
"T )DΘj
(
Θ⊤1:i−1 ⊗",A Proof of Lemma 1,[0],[0]
"(Θ1:L − Φ) ⊤Θi+1:L
)
= (Id2 ⊗ (vec(Id))",A Proof of Lemma 1,[0],[0]
"T ) (Id ⊗ Td,d ⊗",A Proof of Lemma 1,[0],[0]
"Id)
( vec(Θ⊤1:i−1)⊗ Id2 ) DΘj",A Proof of Lemma 1,[0],[0]
( (Θ1:L − Φ) ⊤Θi+1,A Proof of Lemma 1,[0],[0]
":L ) .
",A Proof of Lemma 1,[0],[0]
"Continuing with the subproblem,
DΘj
(
(Θ1:L −Φ) ⊤Θi+1:",A Proof of Lemma 1,[0],[0]
"L
)
",A Proof of Lemma 1,[0],[0]
"= (Θ⊤i+1:L ⊗ Id)DΘj
( (Θ1:L − Φ) ⊤ )
",A Proof of Lemma 1,[0],[0]
+ (Id ⊗ (Θ1:,A Proof of Lemma 1,[0],[0]
L − Φ) ⊤)DΘj,A Proof of Lemma 1,[0],[0]
"(Θi+1:L)
= (Θ⊤i+1:L ⊗ Id)DΘj
( Θ⊤1:L )
+",A Proof of Lemma 1,[0],[0]
(Id ⊗ (Θ1:L − Φ) ⊤)DΘj,A Proof of Lemma 1,[0],[0]
"(Θi+1:L)
= (Θ⊤i+1:L ⊗ Id) ( Θj+1:L ⊗Θ ⊤ 1:j−1 ) DΘj (Θ ⊤ j )
+",A Proof of Lemma 1,[0],[0]
"(Id ⊗ (Θ1:L − Φ) ⊤) ( Θ⊤i+1:j−1 ⊗Θj+1:L )
= (Θ⊤i+1:L ⊗ Id) ( Θj+1:L ⊗Θ ⊤ 1:j−1 )",A Proof of Lemma 1,[0],[0]
"Td,d
+ (Id ⊗ (Θ1:L − Φ) ⊤)",A Proof of Lemma 1,[0],[0]
"( Θ⊤i+1:j−1 ⊗Θj+1:L )
=",A Proof of Lemma 1,[0],[0]
( Θ⊤i+1:LΘj+1:L ⊗Θ ⊤ 1:j−1 ),A Proof of Lemma 1,[0],[0]
"Td,d
+ ( Θ⊤i+1:j−1 ⊗ (Θ1:L − Φ) ⊤Θj+1:L ) .
",A Proof of Lemma 1,[0],[0]
"Finally,
DΘiDΘiℓ (fΘ) = DΘi
( (vec(Id)) T ( Θ⊤1:i−1 ⊗ (Θ1:",A Proof of Lemma 1,[0],[0]
"L − Φ) ⊤Θi+1:L ))
",A Proof of Lemma 1,[0],[0]
= (Id2 ⊗ (vec(Id)),A Proof of Lemma 1,[0],[0]
"T )DΘi
(
Θ⊤1:i−1 ⊗ (Θ1:",A Proof of Lemma 1,[0],[0]
L − Φ) ⊤Θi+1:,A Proof of Lemma 1,[0],[0]
"L
)
= (Id2 ⊗ (vec(Id)) T )",A Proof of Lemma 1,[0],[0]
"(Id ⊗ Td,d ⊗ Id)
( vec(Θ⊤1:i−1)⊗ Id2 ) DΘi",A Proof of Lemma 1,[0],[0]
( (Θ1:L − Φ) ⊤Θi+1,A Proof of Lemma 1,[0],[0]
":L )
and
DΘi
(
(Θ1:L − Φ) ⊤Θi+1:L
)
= (Θ⊤i+1:L ⊗ Id)DΘi
( (Θ1:L − Φ) ⊤ )
= (Θ⊤i+1:L ⊗ Id)DΘi
( Θ⊤1:L )
= (Θ⊤i+1:L ⊗ Id) ( Θi+1:L ⊗Θ ⊤ 1:i−1 ) DΘi(Θ ⊤ i ) =",A Proof of Lemma 1,[0],[0]
(Θ⊤i+1:L ⊗ Id) ( Θi+1:L ⊗Θ ⊤ 1:i−1 ),A Proof of Lemma 1,[0],[0]
"Td,d = (
Θ⊤i+1:LΘi+1:",A Proof of Lemma 1,[0],[0]
"L ⊗Θ ⊤ 1:i−1
)
",A Proof of Lemma 1,[0],[0]
"Td,d.",A Proof of Lemma 1,[0],[0]
"We have ||∇2||2F = 2 ∑
i<j
||DΘjDΘiℓ(fΘ)|| 2 F +
∑
i
||DΘiDΘiℓ(fΘ)|| 2 F .",B Proof of Lemma 3,[0],[0]
"(10)
Let’s start with the easier term.",B Proof of Lemma 3,[0],[0]
Choose Θ such that ||Θi − I||2 ≤ z,B Proof of Lemma 3,[0],[0]
"for all i. We have
||DΘiDΘiℓ (fΘ) ||F = ∣ ∣ ∣ ∣(Id2⊗(vec(Id)) ⊤) (Id⊗Td,d⊗Id)
( vec(Θ⊤1:i−1)⊗Id2 )
(
Θ⊤i+1:LΘi+1:L ⊗Θ ⊤ 1:i−1
)
",B Proof of Lemma 3,[0],[0]
"Td,d ∣ ∣ ∣ ∣
F
≤ ∣ ∣
∣
∣ ∣ ∣ (Id2 ⊗ (vec(Id)) ⊤) (Id ⊗ Td,d ⊗ Id) ∣ ∣ ∣ ∣ ∣ ∣
F
× ∣ ∣
∣
∣ ∣ ∣ ( vec(Θ⊤1:i−1)⊗Id2 )( Θ⊤i+1:LΘi+1:L⊗Θ ⊤ 1:i−1 )",B Proof of Lemma 3,[0],[0]
"Td,d ∣ ∣ ∣ ∣ ∣ ∣
F
= d3/2 ∣ ∣
∣
∣ ∣ ∣ ( vec(Θ⊤1:i−1)⊗ Id2 )
(
Θ⊤i+1:LΘi+1:",B Proof of Lemma 3,[0],[0]
"L ⊗Θ ⊤ 1:i−1
)
",B Proof of Lemma 3,[0],[0]
"Td,d
∣ ∣ ∣ ∣ ∣ ∣
F
≤ d3/2 ∣ ∣
∣
∣ ∣ ∣ ( vec(Θ⊤1:i−1)⊗ Id2 ) ∣ ∣ ∣ ∣ ∣ ∣
F
× ∣ ∣
∣
∣ ∣ ∣ ( Θ⊤i+1:LΘi+1:",B Proof of Lemma 3,[0],[0]
L ⊗Θ ⊤ 1:i−1 ),B Proof of Lemma 3,[0],[0]
"Td,d ∣ ∣ ∣ ∣ ∣ ∣
F
= d7/2 ∣ ∣
∣
∣ ∣
∣ vec(Θ⊤1:i−1)
∣ ∣ ∣ ∣ ∣ ∣
F
∣ ∣ ∣ ∣ ∣ ∣ ( Θ⊤i+1:LΘi+1:L⊗Θ ⊤ 1:i−1 )",B Proof of Lemma 3,[0],[0]
"Td,d ∣ ∣ ∣ ∣ ∣ ∣
F
= d7/2 ||Θ1:i−1||F
∣ ∣ ∣ ∣ ∣ ∣ ( Θ⊤i+1:LΘi+1:",B Proof of Lemma 3,[0],[0]
L ⊗Θ ⊤ 1:i−1 ),B Proof of Lemma 3,[0],[0]
"Td,d ∣ ∣ ∣ ∣ ∣ ∣
F
≤ d4 ||Θ1:i−1||2
∣ ∣ ∣ ∣ ∣ ∣ ( Θ⊤i+1:LΘi+1:L ⊗Θ ⊤ 1:i−1 )",B Proof of Lemma 3,[0],[0]
"Td,d ∣ ∣ ∣ ∣ ∣ ∣
F
≤ d4(1 + z)i−1 ∣ ∣
∣
∣ ∣ ∣ ( Θ⊤i+1:LΘi+1:L ⊗Θ ⊤ 1:i−1 )",B Proof of Lemma 3,[0],[0]
"Td,d ∣ ∣ ∣ ∣ ∣ ∣
F
= d4(1 + z)i−1 ∣ ∣
∣
∣ ∣ ∣ ( Θ⊤i+1:LΘi+1:L ⊗Θ ⊤ 1:i−1 ) ∣ ∣ ∣ ∣ ∣ ∣
F
= d4(1 + z)i−1 ∣ ∣
∣
∣ ∣
∣ Θ⊤i+1:LΘi+1:L
∣ ∣ ∣ ∣ ∣ ∣ F × ∣ ∣ ∣ ∣ ∣ ∣ Θ⊤1:i−1 ∣ ∣ ∣ ∣ ∣ ∣ F
≤",B Proof of Lemma 3,[0],[0]
"d5(1 + z)i−1 ∣ ∣
∣
∣ ∣
∣ Θ⊤i+1:LΘi+1:L
∣ ∣ ∣ ∣ ∣ ∣ 2 × ∣ ∣ ∣ ∣ ∣ ∣ Θ⊤1:i−1 ∣ ∣ ∣ ∣ ∣ ∣ 2
≤ d5(1 + z)2(L−1).
",B Proof of Lemma 3,[0],[0]
"Similarly,
||DΘjDΘiℓ (fΘ) ||F = ∣ ∣ ∣ ∣(Id2⊗(vec(I)) ⊤) (Id⊗Td,d⊗Id)
( vec(Θ⊤1:i−1)⊗Id2 )
(
(
Θ⊤i+1:LΘj+1:L ⊗Θ ⊤ 1:j−1
)
",B Proof of Lemma 3,[0],[0]
"Td,d
+ ( Θ⊤i+1:j−1 ⊗ (Θ1:L −Φ) ⊤Θj+1",B Proof of Lemma 3,[0],[0]
":L )
)
∣ ∣ ∣ ∣
F
≤ d4(1 + z)i−1 ∣ ∣ ∣ ∣
(
Θ⊤i+1:LΘj+1:L ⊗Θ ⊤ 1:j−1
)
",B Proof of Lemma 3,[0],[0]
"Td,d
+ ( Θ⊤i+1:j−1 ⊗ (Θ1:L −Φ) ⊤Θj+1",B Proof of Lemma 3,[0],[0]
":L ) ∣ ∣ ∣ ∣
F
≤ d4(1 + z)i−1",B Proof of Lemma 3,[0],[0]
"(∣ ∣
∣
∣ ∣ ∣ ( Θ⊤i+1:LΘj+1:L ⊗Θ ⊤ 1:j−1 )",B Proof of Lemma 3,[0],[0]
"Td,d ∣ ∣ ∣ ∣ ∣ ∣
F
+ ∣ ∣
∣
∣ ∣ ∣ ( Θ⊤i+1:j−1 ⊗ (Θ1:L − Φ) ⊤Θj+1",B Proof of Lemma 3,[0],[0]
":L )∣ ∣ ∣ ∣ ∣ ∣
F
)
≤ d4(1 + z)i−1",B Proof of Lemma 3,[0],[0]
"( d(1 + z)2L−1−i
+ ∣ ∣
∣
∣ ∣ ∣ ( Θ⊤i+1:j−1 ⊗ (Θ1:L − Φ) ⊤Θj+1",B Proof of Lemma 3,[0],[0]
":L )∣ ∣ ∣ ∣ ∣ ∣
F
)
= d4(1 + z)i−1",B Proof of Lemma 3,[0],[0]
"( d(1 + z)2L−1−i
+ ||Θi+1:j−1||F × ∣ ∣ ∣ ∣ ∣ ∣ (Θ1:L − Φ) ⊤Θj+1",B Proof of Lemma 3,[0],[0]
":L ∣ ∣ ∣ ∣ ∣ ∣
F
)
≤ d4(1 + z)i−1",B Proof of Lemma 3,[0],[0]
( d(1 + z)2L−1−i + 2d(1 + z)2L−1−i ),B Proof of Lemma 3,[0],[0]
"= 3d5(1 + z)2L−2.
",B Proof of Lemma 3,[0],[0]
"Putting these together with (10), we get ||∇2||2F ≤",B Proof of Lemma 3,[0],[0]
"L 29d10(1 + z)4L, so that
||∇2||F ≤ 3Ld 5(1 + z)2L.",B Proof of Lemma 3,[0],[0]
"Recall that a polar decomposition of a matrix A consists of a unitary matrix R and a positive semidefinite matrix P such that A = RP .
",C Proof of Lemma 7,[0],[0]
"Lemma 17 ((Horn & Johnson, 2013)).",C Proof of Lemma 7,[0],[0]
"A is a unitary matrix if and only if all of the (complex) eigenvalues z of A have magnitude 1.
",C Proof of Lemma 7,[0],[0]
"Lemma 18 ((Horn & Johnson, 2013))",C Proof of Lemma 7,[0],[0]
.,C Proof of Lemma 7,[0],[0]
"If A is unitary then A is normal.
",C Proof of Lemma 7,[0],[0]
"Lemma 19 ((Horn & Johnson, 2013))",C Proof of Lemma 7,[0],[0]
.,C Proof of Lemma 7,[0],[0]
"If A is normal with eigenvalues λ1, ..., λd, the singular values of A are |λ1|, ..., |λd|.
Lemma 20.",C Proof of Lemma 7,[0],[0]
"If A is unitary, then A1/L is unitary, and thus Ai/L is unitary for any non-negative integer i.
Lemma 21.",C Proof of Lemma 7,[0],[0]
"If A is invertible and normal with singular values σ1, ..., σd, then, for any positive integer L, the singular values of A1/L are σ 1/L 1 , ..., σ 1/L d .
",C Proof of Lemma 7,[0],[0]
Proof.,C Proof of Lemma 7,[0],[0]
"Follows from Lemma 19 together with the fact that raising a non-singular matrix to a power results in raising its eigenvalues to the same power.
",C Proof of Lemma 7,[0],[0]
"Lemma 22 ((Horn & Johnson, 2013))",C Proof of Lemma 7,[0],[0]
.,C Proof of Lemma 7,[0],[0]
"If A = RP is the polar decomposition of A, then the singular values of A are the same as the singular values of P .
",C Proof of Lemma 7,[0],[0]
Lemma 23.,C Proof of Lemma 7,[0],[0]
"If σ1, ..., σd are the principal components of A, and A = ∏L i=1Ai is a balanced factorization of A, then then σ 1/L 1 , ..., σ 1/L d are the principal components of Ai, for each i ∈ {1, ..., L}.
",C Proof of Lemma 7,[0],[0]
Proof.,C Proof of Lemma 7,[0],[0]
"The singular values of Ai = RiPi are the same as the singular values of Pi, which is similar to P 1/L, whose singular values are the Lth roots of the singular values of P , which are the same as the singular values of A.
Lemma 24.",C Proof of Lemma 7,[0],[0]
"If A1, ..., AL is a balanced factorization of A, then
A = L ∏
i=1
Ai.
Proof.",C Proof of Lemma 7,[0],[0]
"We have
A = RP
= R1/LR1−1/LP 1/LP 1−1/L = R1/LR1−1/LP 1/LR−(1−1/L)R1−1/LP 1−1/L = R1P1R 1−1/LP 1−1/L = A1R 1−1/LP 1−1/L = A1R 1/LR1−2/LP 1/LP 1−2/L
and so on.",C Proof of Lemma 7,[0],[0]
"We analyze algorithms for approximating a function f(x) = Φxmapping R to R using deep linear neural networks, i.e. that learn a function h parameterized by matrices Θ1, ...,ΘL and defined by h(x)",abstractText,[0],[0]
= ΘLΘL−1...Θ1x.,abstractText,[0],[0]
We focus on algorithms that learn through gradient descent on the population quadratic loss in the case that the distribution over the inputs is isotropic.,abstractText,[0],[0]
"We provide polynomial bounds on the number of iterations for gradient descent to approximate the least squares matrix Φ, in the case where the initial hypothesis Θ1 = ...",abstractText,[0],[0]
= ΘL = I has excess loss bounded by a small enough constant.,abstractText,[0],[0]
"On the other hand, we show that gradient descent fails to converge for Φ whose distance from the identity is a larger constant, and we show that some forms of regularization toward the identity in each layer do not help.",abstractText,[0],[0]
"If Φ is symmetric positive definite, we show that an algorithm that initializes Θi = I learns an ǫ-approximation of f using a number of updates polynomial in L, the condition number of Φ, and log(d/ǫ).",abstractText,[0],[0]
"In contrast, we show that if the least squares matrix Φ is symmetric and has a negative eigenvalue, then all members of a class of algorithms that perform gradient descent with identity initialization, and optionally regularize toward the identity in each layer, fail to converge.",abstractText,[0],[0]
"We analyze an algorithm for the case that Φ satisfies uΦu > 0 for all u, but may not be symmetric.",abstractText,[0],[0]
This algorithm uses two regularizers: one that maintains the invariant u⊤ΘLΘL−1...,abstractText,[0],[0]
Θ1u > 0,abstractText,[0],[0]
"for all u, and another that “balances” Θ1, ...,ΘL so that they have the same singular values.",abstractText,[0],[0]
"Single-task learning in computer vision has enjoyed much success in deep learning, with many single-task models now performing at or beyond human accuracies for a wide array of tasks.",1. Introduction,[0],[0]
"However, an ultimate visual system for full scene understanding must be able to perform many diverse perceptual tasks simultaneously and efficiently, especially within the limited compute environments of embedded systems
1Magic Leap, Inc. Correspondence to: Zhao Chen <zchen@magicleap.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
such as smartphones, wearable devices, and robots/drones.",1. Introduction,[0],[0]
"Such a system can be enabled by multitask learning, where one model shares weights across multiple tasks and makes multiple inferences in one forward pass.",1. Introduction,[0],[0]
"Such networks are not only scalable, but the shared features within these networks can induce more robust regularization and boost performance as a result.",1. Introduction,[0],[0]
"In the ideal limit, we can thus have the best of both worlds with multitask networks: more efficiency and higher performance.
",1. Introduction,[0],[0]
"In general, multitask networks are difficult to train; different tasks need to be properly balanced so network parameters converge to robust shared features that are useful across all tasks.",1. Introduction,[0],[0]
"Methods in multitask learning thus far have largely tried to find this balance by manipulating the forward pass of the network (e.g. through constructing explicit statistical relationships between features (Long & Wang, 2015) or optimizing multitask network architectures (Misra et al., 2016), etc.), but such methods ignore a key insight: task imbalances impede proper training because they manifest as imbalances between backpropagated gradients.",1. Introduction,[0],[0]
"A task that is too dominant during training, for example, will necessarily express that dominance by inducing gradients which have relatively large magnitudes.",1. Introduction,[0],[0]
"We aim to mitigate such issues at their root by directly modifying gradient magnitudes through tuning of the multitask loss function.
",1. Introduction,[0],[0]
"In practice, the multitask loss function is often assumed to be linear in the single task losses Li, L = ∑ i wiLi, where the sum runs over all T tasks.",1. Introduction,[0],[0]
"In our case, we propose an adaptive method, and so wi can vary at each training step t: wi = wi(t).",1. Introduction,[0],[0]
"This linear form of the loss function is convenient for implementing gradient balancing, as wi very directly and linearly couples to the backpropagated gradient magnitudes from each task.",1. Introduction,[0],[0]
The challenge is then to find the best value for each wi at each training step t that balances the contribution of each task for optimal model training.,1. Introduction,[0],[0]
"To optimize the weights wi(t) for gradient balancing, we propose a simple algorithm that penalizes the network when backpropagated gradients from any task are too large or too small.",1. Introduction,[0],[0]
"The correct balance is struck when tasks are training at similar rates; if task i is training relatively quickly, then its weight wi(t) should decrease relative to other task weights wj(t)|j 6=i to allow other tasks more influence on
training.",1. Introduction,[0],[0]
"Our algorithm is similar to batch normalization (Ioffe & Szegedy, 2015) with two main differences: (1) we normalize across tasks instead of across data batches, and (2) we use rate balancing as a desired objective to inform our normalization.",1. Introduction,[0],[0]
"We will show that such gradient normalization (hereafter referred to as GradNorm) boosts network performance while significantly curtailing overfitting.
",1. Introduction,[0],[0]
"Our main contributions to multitask learning are as follows:
1.",1. Introduction,[0],[0]
"An efficient algorithm for multitask loss balancing which directly tunes gradient magnitudes.
2.",1. Introduction,[0],[0]
"A method which matches or surpasses the performance of very expensive exhaustive grid search procedures, but which only requires tuning a single hyperparameter.
3.",1. Introduction,[0],[0]
A demonstration that direct gradient interaction provides a powerful way of controlling multitask learning.,1. Introduction,[0],[0]
"Multitask learning was introduced well before the advent of deep learning (Caruana, 1998; Bakker & Heskes, 2003), but the robust learned features within deep networks and their excellent single-task performance have spurned renewed interest.",2. Related Work,[0],[0]
"Although our primary application area is computer vision, multitask learning has applications in multiple other fields, from natural language processing (Collobert & Weston, 2008; Hashimoto et al., 2016; Søgaard & Goldberg, 2016) to speech synthesis (Seltzer & Droppo, 2013; Wu et al., 2015), from very domain-specific applications such as traffic prediction (Huang et al., 2014) to very general cross-domain work (Bilen & Vedaldi, 2017).",2. Related Work,[0],[0]
"Multitask learning has also been explored in the context of curriculum learning (Graves et al., 2017), where subsets of tasks are subsequently trained based on local rewards; we here explore the opposite approach, where tasks are jointly trained based on global rewards such as total loss decrease.
",2. Related Work,[0],[0]
"Multitask learning is very well-suited to the field of computer vision, where making multiple robust predictions is crucial for complete scene understanding.",2. Related Work,[0],[0]
"Deep networks have been used to solve various subsets of multiple vision tasks, from 3-task networks (Eigen & Fergus, 2015; Teichmann et al., 2016) to much larger subsets as in UberNet (Kokkinos, 2016).",2. Related Work,[0],[0]
"Often, single computer vision problems can even be framed as multitask problems, such as in Mask R-CNN for instance segmentation (He et al., 2017) or YOLO-9000 for object detection (Redmon & Farhadi, 2016).",2. Related Work,[0],[0]
Particularly of note is the rich and significant body of work on finding explicit ways to exploit task relationships within a multitask model.,2. Related Work,[0],[0]
"Clustering methods have shown success beyond deep models (Jacob et al., 2009; Kang et al., 2011), while constructs such as deep relationship networks (Long & Wang, 2015) and cross-stich networks (Misra et al., 2016)
give deep networks the capacity to search for meaningful relationships between tasks and to learn which features to share between them.",2. Related Work,[0],[0]
"Work in (Warde-Farley et al., 2014) and (Lu et al., 2016) use groupings amongst labels to search through possible architectures for learning.",2. Related Work,[0],[0]
"Perhaps the most relevant to the current work, (Kendall et al., 2017) uses a joint likelihood formulation to derive task weights based on the intrinsic uncertainty in each task.",2. Related Work,[0],[0]
"For a multitask loss function L(t) = ∑ wi(t)Li(t), we aim to learn the functions wi(t) with the following goals: (1) to place gradient norms for different tasks on a common scale through which we can reason about their relative magnitudes, and (2) to dynamically adjust gradient norms so different tasks train at similar rates.",3.1. Definitions and Preliminaries,[0],[0]
"To this end, we first define the relevant quantities, first with respect to the gradients we will be manipulating.
",3.1. Definitions and Preliminaries,[0],[0]
•,3.1. Definitions and Preliminaries,[0],[0]
W : The subset of the full network weights W ⊂ W where we actually apply GradNorm.,3.1. Definitions and Preliminaries,[0],[0]
"W is generally chosen as the last shared layer of weights to save on compute costs1.
",3.1. Definitions and Preliminaries,[0],[0]
• G(i)W (t) = ||∇Wwi(t)Li(t)||2: the L2 norm of the gradient of the weighted single-task loss wi(t)Li(t),3.1. Definitions and Preliminaries,[0],[0]
"with respect to the chosen weights W .
• GW (t) = Etask[G(i)W (t)]: the average gradient norm across all tasks at training time t.
We also define various training rates for each task i:
• L̃i(t) = Li(t)/Li(0): the loss ratio for task",3.1. Definitions and Preliminaries,[0],[0]
"i at time t. L̃i(t) is a measure of the inverse training rate of task i (i.e. lower values of L̃i(t) correspond to a faster training rate for task i)2.
• ri(t) = L̃i(t)/Etask[L̃i(t)]",3.1. Definitions and Preliminaries,[0],[0]
": the relative inverse training rate of task i.
With the above definitions in place, we now complete our description of the GradNorm algorithm.",3.1. Definitions and Preliminaries,[0],[0]
"As stated in Section 3.1, GradNorm should establish a common scale for gradient magnitudes, and also should balance
1In our experiments this choice of W causes GradNorm to increase training time by only ∼ 5% on NYUv2.
2Networks in this paper all had stable initializations and Li(0) could be used directly.",3.2. Balancing Gradients with GradNorm,[0],[0]
"When Li(0) is sharply dependent on initialization, we can use a theoretical initial loss instead.",3.2. Balancing Gradients with GradNorm,[0],[0]
"E.g. for Li the CE loss across C classes, we can use Li(0) = log(C).
training rates of different tasks.",3.2. Balancing Gradients with GradNorm,[0],[0]
"The common scale for gradients is most naturally the average gradient norm, GW (t), which establishes a baseline at each timestep t by which we can determine relative gradient sizes.",3.2. Balancing Gradients with GradNorm,[0],[0]
"The relative inverse training rate of task i, ri(t), can be used to rate balance our gradients.",3.2. Balancing Gradients with GradNorm,[0],[0]
"Concretely, the higher the value of ri(t), the higher the gradient magnitudes should be for task i in order to encourage the task to train more quickly.",3.2. Balancing Gradients with GradNorm,[0],[0]
"Therefore, our desired gradient norm for each task i is simply:
G (i) W (t) 7→ GW (t)× [ri(t)]",3.2. Balancing Gradients with GradNorm,[0],[0]
"α, (1)
where α is an additional hyperparameter.",3.2. Balancing Gradients with GradNorm,[0],[0]
α sets the strength of the restoring force which pulls tasks back to a common training rate.,3.2. Balancing Gradients with GradNorm,[0],[0]
"In cases where tasks are very different in their complexity, leading to dramatically different learning dynamics between tasks, a higher value of α should be used to enforce stronger training rate balancing.",3.2. Balancing Gradients with GradNorm,[0],[0]
"When tasks are more symmetric (e.g. the synthetic examples in Section 4), a lower value of α is appropriate.",3.2. Balancing Gradients with GradNorm,[0],[0]
Note that α = 0 will always try to pin the norms of backpropagated gradients from each task to be equal at W .,3.2. Balancing Gradients with GradNorm,[0],[0]
"See Section 5.4 for more details on the effects of tuning α.
",3.2. Balancing Gradients with GradNorm,[0],[0]
"Equation 1 gives a target for each task i’s gradient norms, and we update our loss weights wi(t) to move gradient
norms towards this target for each task.",3.2. Balancing Gradients with GradNorm,[0],[0]
"GradNorm is then implemented as an L1 loss function Lgrad between the actual and target gradient norms at each timestep for each task, summed over all tasks:
Lgrad(t;wi(t))",3.2. Balancing Gradients with GradNorm,[0],[0]
"= ∑ i ∣∣∣∣G(i)W (t)−GW (t)× [ri(t)]α∣∣∣∣ 1 (2)
where the summation runs through all T tasks.",3.2. Balancing Gradients with GradNorm,[0],[0]
"When differentiating this loss Lgrad, we treat the target gradient norm GW (t)× [ri(t)]α as a fixed constant to prevent loss weights wi(t) from spuriously drifting towards zero.",3.2. Balancing Gradients with GradNorm,[0],[0]
"Lgrad is then differentiated only with respect to the wi, as the wi(t) directly control gradient magnitudes per task.",3.2. Balancing Gradients with GradNorm,[0],[0]
The computed gradients ∇wiLgrad are then applied via standard update rules to update each wi (as shown in Figure 1).,3.2. Balancing Gradients with GradNorm,[0],[0]
The full GradNorm algorithm is summarized in Algorithm 1.,3.2. Balancing Gradients with GradNorm,[0],[0]
"Note that after every update step, we also renormalize the weights wi(t) so that ∑ i wi(t) = T in order to decouple gradient normalization from the global learning rate.",3.2. Balancing Gradients with GradNorm,[0],[0]
"To illustrate GradNorm on a simple, interpretable system, we construct a common scenario for multitask networks: training tasks which have similar loss functions but different loss scales.",4. A Toy Example,[0],[0]
"In such situations, if we naı̈vely pick wi(t) = 1
Algorithm 1 Training with GradNorm Initialize wi(0) = 1 ∀i Initialize network weightsW Pick value for α > 0 and pick the weightsW (usually the
final layer of weights which are shared between tasks) for t = 0",4. A Toy Example,[0],[0]
"to max train steps do
Input batch xi to compute Li(t) ∀i and L(t) = ∑ i wi(t)Li(t)",4. A Toy Example,[0],[0]
"[standard forward pass] Compute G(i)W (t) and ri(t) ∀i Compute GW (t) by averaging the G (i) W (t)
Compute Lgrad = ∑ i|G (i) W (t)−GW (t)× [ri(t)]α|1 Compute GradNorm gradients∇wiLgrad, keeping targets GW (t)× [ri(t)]α constant Compute standard gradients∇WL(t) Update wi(t) 7→ wi(t+ 1) using ∇wiLgrad UpdateW(t) 7→ W(t+ 1) using∇WL(t)",4. A Toy Example,[0],[0]
"[standard
backward pass] Renormalize wi(t+ 1) so that ∑ i wi(t+ 1) = T
end for
for all loss weights wi(t), the network training will be dominated by tasks with larger loss scales that backpropagate larger gradients.",4. A Toy Example,[0],[0]
"We will demonstrate that GradNorm overcomes this issue.
",4. A Toy Example,[0],[0]
"Consider T regression tasks trained using standard squared loss onto the functions
fi(x) =",4. A Toy Example,[0],[0]
"σi tanh((B + i)x), (3)
where tanh(·) acts element-wise.",4. A Toy Example,[0],[0]
"Inputs are dimension 250 and outputs dimension 100, while B and i are constant matrices with their elements generated IID from N (0, 10) and N (0, 3.5), respectively.",4. A Toy Example,[0],[0]
Each task therefore shares information in B but also contains task-specific information i.,4. A Toy Example,[0],[0]
The σi are the key parameters within this problem; they are fixed scalars which set the scales of the outputs fi.,4. A Toy Example,[0],[0]
A higher scale for fi induces a higher expected value of squared loss for that task.,4. A Toy Example,[0],[0]
"Such tasks are harder to learn due to the higher variances in their response values, but they also backpropagate larger gradients.",4. A Toy Example,[0],[0]
"This scenario generally leads to suboptimal training dynamics when the higher σi tasks dominate the training across all tasks.
",4. A Toy Example,[0],[0]
"To train our toy models, we use a 4-layer fully-connected ReLU-activated network with 100 neurons per layer as a common trunk.",4. A Toy Example,[0],[0]
A final affine transformation layer gives T final predictions (corresponding to T different tasks).,4. A Toy Example,[0],[0]
"To ensure valid analysis, we only compare models initialized to the same random values and fed data generated from the same fixed random seed.",4. A Toy Example,[0],[0]
"The asymmetry α is set low to 0.12 for these experiments, as the output functions fi are all of the same functional form and thus we expect the asymmetry between tasks to be minimal.
",4. A Toy Example,[0],[0]
"In these toy problems, we measure the task-normalized testtime loss to judge test-time performance, which is the sum of the test loss ratios for each task, ∑ i Li(t)/Li(0).",4. A Toy Example,[0],[0]
We do this because a simple sum of losses is an inadequate performance metric for multitask networks when different loss scales exist; higher loss scale tasks will factor disproportionately highly in the loss.,4. A Toy Example,[0],[0]
"There unfortunately exists no general single scalar which gives a meaningful measure of multitask performance in all scenarios, but our toy problem was specifically designed with tasks which are statistically identical except for their loss scales σi.",4. A Toy Example,[0],[0]
"There is therefore a clear measure of overall network performance, which is the sum of losses normalized by each task’s variance σ2i - equivalent (up to a scaling factor) to the sum of loss ratios.
",4. A Toy Example,[0],[0]
"For T = 2, we choose the values (σ0, σ1)",4. A Toy Example,[0],[0]
"= (1.0, 100.0) and show the results of training in the top panels of Figure 2.",4. A Toy Example,[0],[0]
"If we train with equal weightswi = 1, task 1 suppresses task 0 from learning due to task 1’s higher loss scale.",4. A Toy Example,[0],[0]
"However, gradient normalization increases w0(t) to counteract the larger gradients coming from T1, and the improved task balance results in better test-time performance.
",4. A Toy Example,[0],[0]
The possible benefits of gradient normalization become even clearer when the number of tasks increases.,4. A Toy Example,[0],[0]
"For T = 10, we sample the σi from a wide normal distribution and plot the results in the bottom panels of Figure 2.",4. A Toy Example,[0],[0]
GradNorm significantly improves test time performance over naı̈vely weighting each task the same.,4. A Toy Example,[0],[0]
"Similarly to the T = 2 case, for T = 10 the wi(t) grow larger for smaller σi tasks.
",4. A Toy Example,[0],[0]
"For both T = 2 and T = 10, GradNorm is more stable and outperforms the uncertainty weighting proposed by (Kendall et al., 2017).",4. A Toy Example,[0],[0]
"Uncertainty weighting, which enforces that wi(t) ∼ 1/Li(t), tends to grow the weights wi(t) too large and too quickly as the loss for each task drops.",4. A Toy Example,[0],[0]
"Although such networks train quickly at the onset, the training soon deteriorates.",4. A Toy Example,[0],[0]
"This issue is largely caused by the fact that uncertainty weighting allows wi(t) to change without constraint (compared to GradNorm which ensures∑ wi(t) = T always), which pushes the global learning rate up rapidly as the network trains.
",4. A Toy Example,[0],[0]
The traces for each wi(t) during a single GradNorm run are observed to be stable and convergent.,4. A Toy Example,[0],[0]
"In Section 5.3 we will see how the time-averaged weightsEt[wi(t)] lie close to the optimal static weights, suggesting GradNorm can greatly simplify the tedious grid search procedure.",4. A Toy Example,[0],[0]
"We use two variants of NYUv2 (Nathan Silberman & Fergus, 2012) as our main datasets.",5. Application to a Large Real-World Dataset,[0],[0]
"Please refer to the Supplementary Materials for additional results on a 9-task facial landmark dataset found in (Zhang et al., 2014).",5. Application to a Large Real-World Dataset,[0],[0]
"The standard NYUv2 dataset carries depth, surface normals, and semantic
segmentation labels (clustered into 13 distinct classes) for a variety of indoor scenes in different room types (bathrooms, living rooms, studies, etc.).",5. Application to a Large Real-World Dataset,[0],[0]
"NYUv2 is relatively small (795 training, 654 test images), but contains both regression and classification labels, making it a good choice to test the robustness of GradNorm across various tasks.
",5. Application to a Large Real-World Dataset,[0],[0]
"We augment the standard NYUv2 depth dataset with flips and additional frames from each video, resulting in 90,000 images complete with pixel-wise depth, surface normals, and room keypoint labels (segmentation labels are, unfortunately, not available for these additional frames).",5. Application to a Large Real-World Dataset,[0],[0]
"Keypoint labels are professionally annotated by humans, while surface normals are generated algorithmically.",5. Application to a Large Real-World Dataset,[0],[0]
The full dataset is then split by scene for a 90/10 train/test split.,5. Application to a Large Real-World Dataset,[0],[0]
See Figure 6 for examples.,5. Application to a Large Real-World Dataset,[0],[0]
"We will generally refer to these two datasets as NYUv2+seg and NYUv2+kpts, respectively.
",5. Application to a Large Real-World Dataset,[0],[0]
All inputs are downsampled to 320 x 320 pixels and outputs to 80 x 80 pixels.,5. Application to a Large Real-World Dataset,[0],[0]
"We use these resolutions following (Lee et al., 2017), which represents the state-of-the-art in room keypoint prediction and from which we also derive our VGG-style model architecture.",5. Application to a Large Real-World Dataset,[0],[0]
These resolutions also allow us to keep models relatively slim while not compromising semantic complexity in the ground truth output maps.,5. Application to a Large Real-World Dataset,[0],[0]
"We try two different models: (1) a SegNet (Badrinarayanan et al., 2015; Lee et al., 2017) network with a symmetric VGG16 (Simonyan & Zisserman, 2014) encoder/decoder,
and (2) an FCN (Long et al., 2015) network with a modified ResNet-50",5.1. Model and General Training Characteristics,[0],[0]
"(He et al., 2016) encoder and shallow ResNet decoder.",5.1. Model and General Training Characteristics,[0],[0]
"The VGG SegNet reuses maxpool indices to perform upsampling, while the ResNet FCN learns all upsampling filters.",5.1. Model and General Training Characteristics,[0],[0]
"The ResNet architecture is further thinned (both in its filters and activations) to contrast with the heavier, more complex VGG SegNet:",5.1. Model and General Training Characteristics,[0],[0]
stride-2 layers are moved earlier and all 2048-filter layers are replaced by 1024-filter layers.,5.1. Model and General Training Characteristics,[0],[0]
"Ultimately, the VGG SegNet has 29M parameters versus 15M for the thin ResNet.",5.1. Model and General Training Characteristics,[0],[0]
All model parameters are shared amongst all tasks until the final layer.,5.1. Model and General Training Characteristics,[0],[0]
"Although we will focus on the VGG SegNet in our more in-depth analysis, by designing and testing on two extremely different network topologies we will further demonstrate GradNorm’s robustness to the choice of base architecture.
",5.1. Model and General Training Characteristics,[0],[0]
"We use standard pixel-wise loss functions for each task: cross entropy for segmentation, squared loss for depth, and cosine similarity for normals.",5.1. Model and General Training Characteristics,[0],[0]
"As in (Lee et al., 2017), for room layout we generate Gaussian heatmaps for each of 48 room keypoint types and predict these heatmaps with a pixel-wise squared loss.",5.1. Model and General Training Characteristics,[0],[0]
"Note that all regression tasks are quadratic losses (our surface normal prediction uses a cosine loss which is quadratic to leading order), allowing us to use ri(t) for each task i as a direct proxy for each task’s relative inverse training rate.
",5.1. Model and General Training Characteristics,[0],[0]
All runs are trained at a batch size of 24 across 4 Titan X GTX 12GB GPUs and run at 30fps on a single GPU at inference.,5.1. Model and General Training Characteristics,[0],[0]
All NYUv2 runs begin with a learning rate of 2e5.,5.1. Model and General Training Characteristics,[0],[0]
"NYUv2+kpts runs last 80000 steps with a learning rate
decay of 0.2 every 25000 steps.",5.1. Model and General Training Characteristics,[0],[0]
NYUv2+seg runs last 20000 steps with a learning rate decay of 0.2 every 6000 steps.,5.1. Model and General Training Characteristics,[0],[0]
"Updating wi(t) is performed at a learning rate of 0.025 for both GradNorm and the uncertainty weighting ((Kendall et al., 2017)) baseline.",5.1. Model and General Training Characteristics,[0],[0]
"All optimizers are Adam, although we find that GradNorm is insensitive to the optimizer chosen.",5.1. Model and General Training Characteristics,[0],[0]
We implement GradNorm using TensorFlow v1.2.1.,5.1. Model and General Training Characteristics,[0],[0]
In Table 1 we display the performance of GradNorm on the NYUv2+seg dataset.,5.2. Main Results on NYUv2,[0],[0]
"We see that GradNorm α = 1.5 improves the performance of all three tasks with respect to the equal-weights baseline (where wi(t) = 1 for all t,i), and either surpasses or matches (within statistical noise) the best performance of single networks for each task.",5.2. Main Results on NYUv2,[0],[0]
"The GradNorm Static network uses static weights derived from a GradNorm network by calculating the time-averaged weights Et[wi(t)] for each task during a GradNorm training run, and retraining a network with weights fixed to those values.",5.2. Main Results on NYUv2,[0],[0]
GradNorm thus can also be used to extract good values for static weights.,5.2. Main Results on NYUv2,[0],[0]
"We pursue this idea further in Section 5.3 and show that these weights lie very close to the optimal weights extracted from exhaustive grid search.
",5.2. Main Results on NYUv2,[0],[0]
"To show how GradNorm can perform in the presence of a larger dataset, we also perform extensive experiments on the NYUv2+kpts dataset, which is augmented to a factor of 50x more data.",5.2. Main Results on NYUv2,[0],[0]
The results are shown in Table 2.,5.2. Main Results on NYUv2,[0],[0]
"As with the NYUv2+seg runs, GradNorm networks outperform other multitask methods, and either matches (within noise) or surpasses the performance of single-task networks.
",5.2. Main Results on NYUv2,[0],[0]
Figure 3 shows test and training loss curves for GradNorm (α = 1.5) and baselines on the larger NYUv2+kpts dataset for our VGG SegNet models.,5.2. Main Results on NYUv2,[0],[0]
"GradNorm improves test-time depth error by ∼ 5%, despite converging to a much higher training loss.",5.2. Main Results on NYUv2,[0],[0]
"GradNorm achieves this by aggressively rate balancing the network (enforced by a high asymmetry α = 1.5), and ultimately suppresses the depth weight wdepth(t) to lower than 0.10 (see Section 5.4 for more details).",5.2. Main Results on NYUv2,[0],[0]
"The same
trend exists for keypoint regression, and is a clear signal of network regularization.",5.2. Main Results on NYUv2,[0],[0]
"In contrast, uncertainty weighting (Kendall et al., 2017) always moves test and training error in the same direction, and thus is not a good regularizer.",5.2. Main Results on NYUv2,[0],[0]
"Only results for the VGG SegNet are shown here, but the Thin ResNet FCN produces consistent results.",5.2. Main Results on NYUv2,[0],[0]
"For our VGG SegNet, we train 100 networks from scratch with random task weights on NYUv2+kpts.",5.3. Gradient Normalization Finds Optimal Grid-Search Weights in One Pass,[0],[0]
Weights are sampled from a uniform distribution and renormalized to sum to T = 3.,5.3. Gradient Normalization Finds Optimal Grid-Search Weights in One Pass,[0],[0]
"For computational efficiency, we only train for 15000 iterations out of the normal 80000, and then compare the performance of that network to our GradNorm
α = 1.5 VGG SegNet network at the same 15000 steps.",5.3. Gradient Normalization Finds Optimal Grid-Search Weights in One Pass,[0],[0]
"The results are shown in Figure 4.
",5.3. Gradient Normalization Finds Optimal Grid-Search Weights in One Pass,[0],[0]
"Even after 100 networks trained, grid search still falls short of our GradNorm network.",5.3. Gradient Normalization Finds Optimal Grid-Search Weights in One Pass,[0],[0]
"Even more remarkably, there is a strong, negative correlation between network performance and task weight distance to our time-averaged GradNorm weights Et[wi(t)].",5.3. Gradient Normalization Finds Optimal Grid-Search Weights in One Pass,[0],[0]
"At an L2 distance of ∼ 3, grid search networks on average have almost double the errors per task compared to our GradNorm network.",5.3. Gradient Normalization Finds Optimal Grid-Search Weights in One Pass,[0],[0]
GradNorm has therefore found the optimal grid search weights in one single training run.,5.3. Gradient Normalization Finds Optimal Grid-Search Weights in One Pass,[0],[0]
The only hyperparameter in our algorithm is the asymmetry α.,5.4. Effects of tuning the asymmetry α,[0],[0]
"The optimal value of α for NYUv2 lies near α = 1.5, while in the highly symmetric toy example in Section 4 we used α = 0.12.",5.4. Effects of tuning the asymmetry α,[0],[0]
"This observation reinforces our characterization of α as an asymmetry parameter.
",5.4. Effects of tuning the asymmetry α,[0],[0]
"Tuning α leads to performance gains, but we found that for NYUv2, almost any value of 0",5.4. Effects of tuning the asymmetry α,[0],[0]
< α < 3 will improve network performance over an equal weights baseline (see Supplementary for details).,5.4. Effects of tuning the asymmetry α,[0],[0]
"Figure 5 shows that higher values of α tend to push the weights wi(t) further apart, which more aggressively reduces the influence of tasks which overfit or learn too quickly (in our case, depth).",5.4. Effects of tuning the asymmetry α,[0],[0]
"Remarkably, at α = 1.75 (not shown) wdepth(t) is suppressed to below 0.02 at no detriment to network performance on the depth task.",5.4. Effects of tuning the asymmetry α,[0],[0]
"Figure 6 shows visualizations of the VGG SegNet outputs on test set images along with the ground truth, for both the NYUv2+seg and NYUv2+kpts datasets.",5.5. Qualitative Results,[0],[0]
"Ground truth labels are juxtaposed with outputs from the equal weights network, 3 single networks, and our best GradNorm network.",5.5. Qualitative Results,[0],[0]
"Some
improvements are incremental, but GradNorm produces superior visual results in tasks for which there are significant quantitative improvements in Tables 1 and 2.",5.5. Qualitative Results,[0],[0]
"We introduced GradNorm, an efficient algorithm for tuning loss weights in a multi-task learning setting based on balancing the training rates of different tasks.",6. Conclusions,[0],[0]
"We demonstrated on both synthetic and real datasets that GradNorm improves multitask test-time performance in a variety of scenarios, and can accommodate various levels of asymmetry amongst the different tasks through the hyperparameter α.",6. Conclusions,[0],[0]
"Our empirical results indicate that GradNorm offers su-
perior performance over state-of-the-art multitask adaptive weighting methods and can match or surpass the performance of exhaustive grid search while being significantly less time-intensive.
",6. Conclusions,[0],[0]
"Looking ahead, algorithms such as GradNorm may have applications beyond multitask learning.",6. Conclusions,[0],[0]
"We hope to extend the GradNorm approach to work with class-balancing and sequence-to-sequence models, all situations where problems with conflicting gradient signals can degrade model performance.",6. Conclusions,[0],[0]
"We thus believe that our work not only provides a robust new algorithm for multitask learning, but also reinforces the powerful idea that gradient tuning is fundamental for training large, effective models on complex tasks.",6. Conclusions,[0],[0]
"Deep multitask networks, in which one neural network produces multiple predictive outputs, can offer better speed and performance than their single-task counterparts but are challenging to train properly.",abstractText,[0],[0]
We present a gradient normalization (GradNorm) algorithm that automatically balances training in deep multitask models by dynamically tuning gradient magnitudes.,abstractText,[0],[0]
"We show that for various network architectures, for both regression and classification tasks, and on both synthetic and real datasets, GradNorm improves accuracy and reduces overfitting across multiple tasks when compared to single-task networks, static baselines, and other adaptive multitask loss balancing techniques.",abstractText,[0],[0]
"GradNorm also matches or surpasses the performance of exhaustive grid search methods, despite only involving a single asymmetry hyperparameter α.",abstractText,[0],[0]
"Thus, what was once a tedious search process that incurred exponentially more compute for each task added can now be accomplished within a few training runs, irrespective of the number of tasks.",abstractText,[0],[0]
"Ultimately, we will demonstrate that gradient manipulation affords us great control over the training dynamics of multitask networks and may be one of the keys to unlocking the potential of multitask learning.",abstractText,[0],[0]
GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks,title,[0],[0]
"Deep neural networks have become the state-of-the-art systems for image recognition (He et al., 2016a; Huang et al., 2017b; Krizhevsky et al., 2012; Qiao et al., 2018; Simonyan & Zisserman, 2014; Szegedy et al., 2015; Wang et al., 2017; Zeiler & Fergus, 2013) as well as other vision tasks (Chen et al., 2015; Girshick et al., 2014; Long et al., 2015; Qiao et al., 2017; Ren et al., 2015; Shen et al., 2015; Xie & Tu, 2015).",1. Introduction,[0],[0]
"The architectures keep going deeper, e.g., from five convolutional layers (Krizhevsky et al., 2012) to 1001 layers (He et al., 2016b).",1. Introduction,[0],[0]
"The benefit of deep architectures is their strong learning capacities because each new layer can potentially introduce more non-linearities and typically uses larger receptive fields (Simonyan & Zisserman, 2014).",1. Introduction,[0],[0]
"In addition, adding certain types of layers (e.g. (He et al., 2016b)) will not harm the performance theoretically since they can just learn identity mapping.",1. Introduction,[0],[0]
"This makes stacking up layers more appealing in the network designs.
",1. Introduction,[0],[0]
1Johns Hopkins University 2Shanghai University 3Hikvision Research.,1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Siyuan Qiao <siyuan.qiao@jhu.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"Although deeper architectures usually lead to stronger learning capacities, cascading convolutional layers (e.g. VGG (Simonyan & Zisserman, 2014)) or blocks (e.g. ResNet (He et al., 2016a)) is not necessarily the only method to achieve this goal.",1. Introduction,[0],[0]
"In this paper, we present a new way to increase the depth of the networks as an alternative to stacking up convolutional layers or blocks.",1. Introduction,[0],[0]
Figure 2 provides an illustration that compares our proposed convolutional network that gradually updates the feature representations against the traditional convolutional network that computes its output simultaneously.,1. Introduction,[0],[0]
"By only adding an ordering to the channels without any additional computation, the later computed channels become deeper than the corresponding ones in the traditional convolutional network.",1. Introduction,[0],[0]
We refer to the neural networks with the proposed computation orderings on the channels as Gradually Updated Neural Networks (GUNN).,1. Introduction,[0],[0]
Figure 1 provides two examples of architecture designs based on cascading building blocks and GUNN.,1. Introduction,[0],[0]
"Without repeating the building blocks, GUNN increases the depths of the networks as well as their learning capacities.
",1. Introduction,[0],[0]
It is clear that converting plain networks to GUNN increases the depths of the networks without any additional computations.,1. Introduction,[0],[0]
"What is less obvious is that GUNN in fact eliminates the overlap singularities inherent in the loss landscapes of the cascading-based convolutional networks, which have been shown to adversely affect the training of deep neural networks as well as their performances (Wei et al., 2008;
Orhan & Pitkow, 2018).",1. Introduction,[0],[0]
"Overlap singularity is when internal neurons collapse into each other, i.e. they are unidentifiable by their activations.",1. Introduction,[0],[0]
"It happens in the networks, increases the training difficulties and degrades the performances (Orhan & Pitkow, 2018).",1. Introduction,[0],[0]
"However, if a plain network is converted to GUNN, the added computation orderings will break the symmetry between the neurons.",1. Introduction,[0],[0]
We prove that the internal neurons in GUNN are impossible to collapse into each other.,1. Introduction,[0],[0]
"As a result, the effective dimensionality can be kept during training and the model will be free from the degeneracy caused by collapsed neurons.",1. Introduction,[0],[0]
"Reflected in the training dynamics and the performances, this means that converting to GUNN will make the plain networks easier to train and perform better.",1. Introduction,[0],[0]
"Figure 3 compares the training dynamics of a 15-layer plain network on CIFAR-10 dataset (Krizhevsky & Hinton, 2009) before and after converted to GUNN.
",1. Introduction,[0],[0]
"In this paper, we test our proposed GUNN on highly competitive benchmark datasets, i.e. CIFAR (Krizhevsky & Hinton, 2009) and ImageNet (Russakovsky et al., 2015).",1. Introduction,[0],[0]
Experimental results demonstrate that our proposed GUNNbased networks achieve the state-of-the-art performances compared with the previous cascading-based architectures.,1. Introduction,[0],[0]
"The research focuses of image recognition have moved from feature designs (Dalal & Triggs, 2005; Lowe, 2004) to architecture designs (He et al., 2016a; Huang et al., 2017b; Krizhevsky et al., 2012; Sermanet et al., 2014; Simonyan
& Zisserman, 2014; Szegedy et al., 2015; Xie et al., 2017; Zeiler & Fergus, 2013) due to the recent success of the deep neural networks.",2. Related Work,[0],[0]
"Highway Networks (Srivastava et al., 2015) proposed architectures that can be trained end-to-end with more than 100 layers.",2. Related Work,[0],[0]
The main idea of Highway Networks is to use bypassing paths.,2. Related Work,[0],[0]
"This idea was further investigated in ResNet (He et al., 2016a), which simplifies the bypassing paths by using only identity mappings.",2. Related Work,[0],[0]
"As learning ultra-deep networks became possible, the depths of the models have increased tremendously.",2. Related Work,[0],[0]
"ResNet with pre-activation (He et al., 2016b) and ResNet with stochastic depth (Huang et al., 2016) even managed to train neural networks with more than 1000 layers.",2. Related Work,[0],[0]
"FractalNet (Larsson et al., 2016) argued that in addition to summation, concatenation also helps train a deep architecture.",2. Related Work,[0],[0]
"More recently, ResNeXt (Xie et al., 2017) used group convolutions in ResNet and outperformed the original ResNet.",2. Related Work,[0],[0]
"DenseNet (Huang et al., 2017b) proposed an architecture with dense connections by feature concatenation.",2. Related Work,[0],[0]
"Dual Path Net (Chen et al., 2017) finds a middle point between ResNet and DenseNet by concatenating them in two paths.",2. Related Work,[0],[0]
"Unlike the above cascading-based methods, GUNN eliminates the overlap singularities caused by the architecture symmetry.",2. Related Work,[0],[0]
"The detailed analyses can be found in Section 4.3.
",2. Related Work,[0],[0]
"Alternative to increasing the depth of the neural networks, another trend is to increase the widths of the networks.",2. Related Work,[0],[0]
"GoogleNet (Szegedy et al., 2015; 2016) proposed an Inception module to concatenate feature maps produced by different filters.",2. Related Work,[0],[0]
"Following ResNet (He et al., 2016a), the WideResNet (Zagoruyko & Komodakis, 2016) argued that compared with increasing the depth, increasing the width of the networks can be more effective in improving the performances.",2. Related Work,[0],[0]
"Besides varying the width and the depth, there are also other design strategies for deep neural networks (Hariharan et al., 2015; Kontschieder et al., 2015; Pezeshki et al., 2016; Rasmus et al., 2015; Yang & Ramanan, 2015).",2. Related Work,[0],[0]
"Deeply-Supervised Nets (Lee et al., 2014) used auxiliary classifiers to provide direct supervisions for the internal layers.",2. Related Work,[0],[0]
"Network in Network (Lin et al., 2013) adds micro perceptrons to the convolutional layers.",2. Related Work,[0],[0]
"We consider a feature transformation F : Rm×n → Rm×n, where n denotes the channel of the features and m denotes the feature location on the 2-D feature map.",3.1. Feature Update,[0],[0]
"For example, F can be a convolutional layer with n channels for both the input and the output.",3.1. Feature Update,[0],[0]
Let x ∈,3.1. Feature Update,[0],[0]
Rm×n be the input and y ∈,3.1. Feature Update,[0],[0]
"Rm×n be the output, we have
y = F(x) (1)
Suppose that F can be decomposed into channel-wise transformation Fc(·) that are independent with eath other, then for any location k and channel c we have
ykc = Fc(xr(k))",3.1. Feature Update,[0],[0]
"(2)
where xr(k) denotes the receptive field of the location k",3.1. Feature Update,[0],[0]
"and Fc denotes the transformation on channel c.
Let UC denote a feature update on channel set C, i.e.,
UC(x) :",3.1. Feature Update,[0],[0]
"y k c = Fc(xr(k)),∀c ∈ C, k ykc",3.1. Feature Update,[0],[0]
"= x k c ,∀c",3.1. Feature Update,[0],[0]
"∈ C, k
(3)
",3.1. Feature Update,[0],[0]
"Then, UC = F when C = {1, ..., n}.",3.1. Feature Update,[0],[0]
"By defining the feature update UC on channel set C, the commonly used one-layer CNN is a special case of feature updates where every channel is updated simultaneously.",3.2. Gradually Updated Neural Networks,[0],[0]
"However, we can also update the channels gradually.",3.2. Gradually Updated Neural Networks,[0],[0]
"For example, the proposed GUNN can be formulated by
GUNN(x) =",3.2. Gradually Updated Neural Networks,[0],[0]
(Ucl ◦ Uc(l−1),3.2. Gradually Updated Neural Networks,[0],[0]
"◦ ... ◦ Uc2 ◦ Uc1)(x)
",3.2. Gradually Updated Neural Networks,[0],[0]
"where l⋃
i=1
ci = {1, 2, ..., n} and ci ∩ cj = Φ, ∀i 6= j
(4) When l = 1, GUNN is equivalent to F .
",3.2. Gradually Updated Neural Networks,[0],[0]
"Note that the number of parameters and computation of GUNN are the same as those of the corresponding F for any partitions c1, ..., cl of {1, ..., n}.",3.2. Gradually Updated Neural Networks,[0],[0]
"However, by decomposing F into channel-wise transformations and sequentially applying them, the later computed channels are deeper than the previous ones.",3.2. Gradually Updated Neural Networks,[0],[0]
"As a result, the depth of the network can be increased, as well as the network’s learning capacity.",3.2. Gradually Updated Neural Networks,[0],[0]
"We consider the residual learning proposed by ResNet (He et al., 2016a) in our model.",3.3. Channel-wise Update by Residual Learning,[0],[0]
"Specifically, we consider the channel-wise transformation Fc : Rm×n → Rm×1 to be
Fc(x) = Gc(x) + xc (5)
",3.3. Channel-wise Update by Residual Learning,[0],[0]
Algorithm 1 Back-propagation for GUNN Input :U(·) =,3.3. Channel-wise Update by Residual Learning,[0],[0]
(Ucl ◦ Uc(l−1),3.3. Channel-wise Update by Residual Learning,[0],[0]
"◦ ... ◦ Uc1)(·), input x,
output y = U(x), gradients ∂L/∂y, and parameters Θ for U .
",3.3. Channel-wise Update by Residual Learning,[0],[0]
"Output :∂L/∂Θ, ∂L/∂x ∂L/∂x← ∂L/∂y for i←",3.3. Channel-wise Update by Residual Learning,[0],[0]
"l to 1 do
yc ←",3.3. Channel-wise Update by Residual Learning,[0],[0]
"xc, ∀c",3.3. Channel-wise Update by Residual Learning,[0],[0]
"∈ ci ∂L/∂y, ∂L/∂Θci ← BP(y, ∂L/∂x, Uci ,Θci) (∂L/∂x)c ← (∂L/∂y)c, ∀c ∈ ci (∂L/∂x)c ← (∂L/∂x)c + (∂L/∂y)c, ∀c",3.3. Channel-wise Update by Residual Learning,[0],[0]
"6∈ ci
end
where Gc is a convolutional neural network Gc : Rm×n → Rm×1.",3.3. Channel-wise Update by Residual Learning,[0],[0]
"The motivation of expressing F in a residual learning manner is to reduce overlap singularities (Orhan & Pitkow, 2018), which will be discussed in Section 4.",3.3. Channel-wise Update by Residual Learning,[0],[0]
Here we show the backpropagation algorithm for learning the parameters in GUNN that uses the same amount of computations and memory as in F .,3.4. Learning GUNN by Backpropagation,[0],[0]
"In Eq. 4, let the feature update Uci be parameterized by Θci .",3.4. Learning GUNN by Backpropagation,[0],[0]
"Let BP(x, ∂L/∂y, f,Θ) be the back-propagation algorithm for differentiable function y = f(x; Θ) with the loss L and the parameters Θ. Algorithm 1 presents the back-propagation algorithm for GUNN.",3.4. Learning GUNN by Backpropagation,[0],[0]
"Since Uci has the residual structures (He et al., 2016a), the last two steps can be merged into
(∂L/∂x)c ← (∂L/∂x)c + (∂L/∂y)c, ∀c (6)
which further simplifies the implementation.",3.4. Learning GUNN by Backpropagation,[0],[0]
It is easy to see that converting networks to GUNN-based does not increase the memory usage in feed-forwarding.,3.4. Learning GUNN by Backpropagation,[0],[0]
"Given Algorithm 1, converting networks to GUNN will not affect the memory in both the training and the evaluation.",3.4. Learning GUNN by Backpropagation,[0],[0]
Overlap singularities are inherent in the loss landscapes of some network architectures which are caused by the nonidentifiability of subsets of the neurons.,4. GUNN Eliminates Overlap Singularities,[0],[0]
"They are identified and discussed in previous work (Wei et al., 2008; Anandkumar & Ge, 2016; Orhan & Pitkow, 2018), and are shown to be harmful for the performances of deep networks.",4. GUNN Eliminates Overlap Singularities,[0],[0]
"Intuitively, overlap singularities exist in architectures where the internal neurons collapse into each other.",4. GUNN Eliminates Overlap Singularities,[0],[0]
"As a result, the models are degenerate and the effective dimensionality is reduced.",4. GUNN Eliminates Overlap Singularities,[0],[0]
"(Orhan & Pitkow, 2018) demonstrated through experiments that residual learning (see Eq. 5) helps to reduce the overlap singularities in deep networks, which partly explains the exceptional performances of ResNet (He et al., 2016a) compared with plain networks.",4. GUNN Eliminates Overlap Singularities,[0],[0]
"In the following, we first use linear transformation as an example to demonstrate
how GUNN-based networks break the overlap singularities.",4. GUNN Eliminates Overlap Singularities,[0],[0]
"Then, we generalize the results to ReLU DNN.",4. GUNN Eliminates Overlap Singularities,[0],[0]
"Finally, we compare GUNN with the previous state-of-the-art network architectures from the perspective of singularity elimination.",4. GUNN Eliminates Overlap Singularities,[0],[0]
Consider a linear function y = f(x) :,4.1. Overlap Singularities in Linear Transformations,[0],[0]
"Rn → Rn such that
yi = n∑ j=1 ωi,jxj , ∀i ∈ {1, .., n} (7)
Suppose that there exists a pair of collapsed neurons yp and yq (p < q).",4.1. Overlap Singularities in Linear Transformations,[0],[0]
"Then, for ∀x, yp = yq, and the equality holds after any number of gradient descents, i.e. ∆yp = ∆yq .
",4.1. Overlap Singularities in Linear Transformations,[0],[0]
Eq. 7 describes a plain network.,4.1. Overlap Singularities in Linear Transformations,[0],[0]
"The solution for the existence of yp and yq is that ωp,j = ωq,j ,∀j.",4.1. Overlap Singularities in Linear Transformations,[0],[0]
"This is the case that is mostly discussed previously, which happens in the networks and degrades the performances.
",4.1. Overlap Singularities in Linear Transformations,[0],[0]
"When we add the residual learning, Eq. 7 becomes
yi = xi + n∑ j=1 ωi,jxj , ∀i ∈ {1, .., n} (8)
Collapsed neurons require that ωp,p + 1 = ωq,p, ωq,q + 1 = ωp,q.",4.1. Overlap Singularities in Linear Transformations,[0],[0]
"This will make the collapse of yp and yq very hard when ω is initialized from a normal distribution N (0, √ 2/n) as in ResNet, but still possible.
",4.1. Overlap Singularities in Linear Transformations,[0],[0]
"Next, we convert Eq. 8 to GUNN, i.e.,
yi = xi + i−1∑ j=1 ωi,jyj + n∑ j=i ωi,jxj , ∀i ∈ {1, .., n} (9)
Suppose that yp and yq (p < q) collapse.",4.1. Overlap Singularities in Linear Transformations,[0],[0]
"Consider ∆y, the value difference at x after one step of gradient descent on ω with input x, ∂L/∂y and learning rate .",4.1. Overlap Singularities in Linear Transformations,[0],[0]
"When → 0,
∆yi = ∂L
∂yi ( i−1∑ j=1 y2j + n∑ j=i x2j )",4.1. Overlap Singularities in Linear Transformations,[0],[0]
"+ i−1∑ j=1 ωi,j∆yj (10)
",4.1. Overlap Singularities in Linear Transformations,[0],[0]
"As ∆yp = ∆yq,∀x, we have ωq,j = 0, ∀j : p",4.1. Overlap Singularities in Linear Transformations,[0],[0]
< j < q.,4.1. Overlap Singularities in Linear Transformations,[0],[0]
"But this condition will be broken in the next update; thus, q = p + 1.",4.1. Overlap Singularities in Linear Transformations,[0],[0]
"Then, we derive that yp = yq = 0.",4.1. Overlap Singularities in Linear Transformations,[0],[0]
But these will also be broken in the next step of gradient descent optimization.,4.1. Overlap Singularities in Linear Transformations,[0],[0]
"Hence, yp and yq cannot collapse into each other.",4.1. Overlap Singularities in Linear Transformations,[0],[0]
The complete proof can be found in the appendix.,4.1. Overlap Singularities in Linear Transformations,[0],[0]
"In practice, architectures are usually composed of several linear layers and non-linearity layers.",4.2. Overlap Singularities in ReLU DNN,[0],[0]
Analyzing all the possible architectures is beyond our scope.,4.2. Overlap Singularities in ReLU DNN,[0],[0]
"Here, we discuss the commonly used ReLU DNN, in which only linear transformations and ReLUs are used by simple layer cascading.
",4.2. Overlap Singularities in ReLU DNN,[0],[0]
"Following the notations in §3, we use y = G(x) + x, in which G(x) is a ReLU DNN.",4.2. Overlap Singularities in ReLU DNN,[0],[0]
"Note that G is continuous piecewise linear (PWL) function (Arora et al., 2018), which means that there exists a finite set of polyhedra whose union is Rn, and G is affine linear over each polyhedron.
",4.2. Overlap Singularities in ReLU DNN,[0],[0]
Suppose that we convert G(x)+x to GUNN and there exists a pair of collapsed neurons yp and yq (p < q).,4.2. Overlap Singularities in ReLU DNN,[0],[0]
"Then, the set of polyhedra for yp is the same as for yq.",4.2. Overlap Singularities in ReLU DNN,[0],[0]
Let P be a polyhedron for yp and yq defined above.,4.2. Overlap Singularities in ReLU DNN,[0],[0]
"Then, ∀x,P, i,
yi = xi + i−1∑ j=1 ωi,j(P)yj + n∑ j=i ωi,j(P)xj (11)
where ω(P) denotes the parameters for polyhedron P. Note that on each P, y is a function of x in the form of Eq. 9; hence, yp and yq cannot collapse into each other.",4.2. Overlap Singularities in ReLU DNN,[0],[0]
"Since the union of all polyhedra is Rn, we conclude that GUNN eliminates the overlap singularities in ReLU DNN.",4.2. Overlap Singularities in ReLU DNN,[0],[0]
"The previous two subsections consider the GUNN conversion where |ci| = 1,∀i (see Eq. 4).",4.3. Discussions and Comparisons,[0],[0]
But this will slow down the computation on GPU due to the data dependency.,4.3. Discussions and Comparisons,[0],[0]
"Without specialized hardware or library support, we decide to increase |ci| to > 10.",4.3. Discussions and Comparisons,[0],[0]
"The resulted models run at the speed between ResNeXt (Xie et al., 2017) and DenseNet (Huang et al., 2017b).",4.3. Discussions and Comparisons,[0],[0]
But this change introduces singularities into the channels from the same set ci.,4.3. Discussions and Comparisons,[0],[0]
"Then, the residual learning helps GUNN to reduce the singularities within the same set ci since we initialize the parameters from a normal distributionN (0, √ 2/n).",4.3. Discussions and Comparisons,[0],[0]
"We will compare the results of GUNN with and without residual learning in the experiments.
",4.3. Discussions and Comparisons,[0],[0]
We compare GUNN with the state-of-the-art architectures from the perspective of overlap singularities.,4.3. Discussions and Comparisons,[0],[0]
"ResNet (He et al., 2016a) and its variants use residual learning, which reduces but cannot eliminate the singularities.",4.3. Discussions and Comparisons,[0],[0]
"ResNeXt (Xie et al., 2017) uses group convolutions to break the symmetry between groups, which further helps to avoid neuron collapses.",4.3. Discussions and Comparisons,[0],[0]
"DenseNet (Huang et al., 2017b) concatenates the outputs of layers as the input to the next layer.",4.3. Discussions and Comparisons,[0],[0]
"DenseNet and GUNN both create dense connections, while DenseNet reuses the outputs by concatenating and GUNN by adding them back to the inputs.",4.3. Discussions and Comparisons,[0],[0]
But the channels within the same layer of DenseNet are still possible to collapse into each other since they are symmetric.,4.3. Discussions and Comparisons,[0],[0]
"In contrast, adding back makes residual learning possible in GUNN.",4.3. Discussions and Comparisons,[0],[0]
This makes residual learning indispensable in GUNN-based networks.,4.3. Discussions and Comparisons,[0],[0]
"In this section, we will present the details of our architectures for the CIFAR (Krizhevsky & Hinton, 2009) and ImageNet (Russakovsky et al., 2015) datasets.",5. Network Architectures,[0],[0]
"Since the proposed GUNN is a method for increasing the depths of the convolutional networks, specifying the architectures to be converted is equivalent to specifying the GUNN-based architectures.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"The architectures before conversion, the Simultaneously Updated Neural Networks (SUNN), become natural baselines for our proposed GUNN networks.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"We first study what baseline architectures can be converted.
",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"There are two assumptions about the feature transformation F (see Eq. 1): (1) the input and the output sizes are the same, and (2) F is channel-wise decomposable.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"To satisfy the first assumption, we will first use a convolutional layer with Batch Normalization (Ioffe & Szegedy, 2015) and ReLU (Nair & Hinton, 2010) to transform the feature space to a new space where the number of the channels is wanted.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"To satisfy the second assumption, instead of directly specifying the transform F , we focus on designing Fci , where ci is a subset of the channels (see Eq. 4).",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"To be consistent with the term update used in GUNN and SUNN, we refer to Fci as the update units for channels ci.
Bottleneck Update Units In the architectures proposed in this paper, we adopt bottleneck neural networks as shown in Figure 4 for the update units for both the SUNN and GUNN.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
Suppose that the update unit maps the input features of channel size nin to the output features of size nout.,5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
Each unit contains three convolutional layers.,5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
The first convolutional layer transforms the input features to K × nout using a 1× 1 convolutional layer.,5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"The second convolutional layer is of kernel size 3× 3, stride 1, and padding 1, outputting the features of size K × nout.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
The third layer computes the features of size nout using a 1 × 1 convolutional layer.,5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"The output is then added back to the input, following the residual architecture proposed in ResNet (He et al., 2016a).",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"We add batch normalization layer (Ioffe & Szegedy, 2015) and ReLU layer (Nair & Hinton, 2010) after the first and the second convolutional layers, while only adding batch
normalization layer after the third layer.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
Stacking up M update units also generates a new one.,5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"In total, we have two hyperparameters for designing an update unit: the expansion rate K and the number of the 3-layer update units M .
",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"One Resolution, One Representation Our architectures will have only one representation at one resolution besides the pooling layers and the convolutional layers that initialize the needed numbers of channels.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
Take the architecture in Table 1 as an example.,5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
There are two processes for each resolution.,5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"The first one is the transition process, which computes the initial features with the dimensions of the next resolution, then down samples it to 1/4 using a 2×2 average pooling.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
A convolutional operation is needed here because F is assumed to have the same input and output sizes.,5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
The next process is using GUNN to update this feature space gradually.,5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"Each channel will only be updated once, and all channels will be updated after this process.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"Unlike most of the previous networks, after this two processes, the feature transformations at this resolution are complete.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"There will be no more convolutional layers or blocks following this feature representation, i.e., one resolution, one representation.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"Then, the network will compute the initial features for the next resolution, or compute the final vector representation of the entire image by a global average pooling.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"By designing networks in this way, SUNN networks usually have about 20 layers before converting to GUNN-based networks.
",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"Channel Partitions With the clearly defined update units, we can easily build SUNN and GUNN layers by using the units to update the representations following Eq. 4.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
The hyperparameters for the SUNN/GUNN layer are the number of the channels N and the partition over those channels.,5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"In our proposed architectures, we evenly partition the channels into P segments.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"Then, we can useN and P to represent the configuration of a layer.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"Together with the hyperparameters in the update units, we have four hyperparameters to tune for one SUNN/GUNN layer, i.e. {N,P,K,M}.",5.1. Simultaneously Updated Neural Networks and Gradually Updated Neural Networks,[0],[0]
"We have implemented two neural networks based on GUNN to compete with the previous state-of-the-art methods on CIFAR datasets, i.e., GUNN-15 and GUNN-24.",5.2. Architectures for CIFAR,[0],[0]
Table 1 shows the big picture of GUNN-15.,5.2. Architectures for CIFAR,[0],[0]
"Here, we present the details of the hyperparameter settings for GUNN-15 and GUNN-24.",5.2. Architectures for CIFAR,[0],[0]
"For GUNN-15, we have three GUNN layers, Conv2, Conv3 and Conv4.",5.2. Architectures for CIFAR,[0],[0]
"The configuration for Conv2 is {N = 240, P = 20,K = 2,M = 1}, the configuration for Conv3 is {N = 300, P = 25,K = 2,M = 1}, and the configuration for Conv4 is {N = 360, P = 30,K = 2,M = 1}.",5.2. Architectures for CIFAR,[0],[0]
"For GUNN-24, based on GUNN-15, we change the number of output channels of Conv1 to 720, Trans1 to 900, Trans2 to 1080, and Trans3 to 1080.",5.2. Architectures for CIFAR,[0],[0]
"The hyperparameters are {N = 720, P = 20,K = 3,M = 2} for
Conv2, {N = 900, P = 25,K = 3,M = 2} for Conv3, and {N = 1080, P = 30,K = 3,M = 2} for Conv3.",5.2. Architectures for CIFAR,[0],[0]
The number of parameters of GUNN-15 is 1585746 for CIFAR10 and 1618236 for CIFAR-100.,5.2. Architectures for CIFAR,[0],[0]
The number of parameters of GUNN-24 is 29534106 for CIFAR-10 and 29631396 for CIFAR-100.,5.2. Architectures for CIFAR,[0],[0]
"The GUNN-15 is aimed to compete with the methods published in an early stage by using a much smaller model, while GUNN-24 is targeted at comparing with ResNeXt (Xie et al., 2017) and DenseNet (Huang et al., 2017b) to get the state-of-the-art performance.",5.2. Architectures for CIFAR,[0],[0]
We implement a neural network GUNN-18 to compete with the state-of-the-art neural networks on ImageNet with a similar number of parameters.,5.3. Architectures for ImageNet,[0],[0]
Table 2 shows the big picture of the neural network architecture of GUNN-18.,5.3. Architectures for ImageNet,[0],[0]
"Here, we present the detailed hyperparameters for the GUNN layers in GUNN-18.",5.3. Architectures for ImageNet,[0],[0]
"The GUNN layers include Conv2, Conv3, Conv4 and Conv5.",5.3. Architectures for ImageNet,[0],[0]
"The hyperparameters are {N = 400, P = 10,K = 2,M = 1} for Conv2,
{N = 800, P = 20,K = 2,M = 1} for Conv3, {N = 1600, P = 40,K = 2,M = 1} for Conv4 and {N = 2000, P = 50,K = 2,M = 1} for Conv5.",5.3. Architectures for ImageNet,[0],[0]
The number of parameters is 28909736.,5.3. Architectures for ImageNet,[0],[0]
"The GUNN-18 is targeted at competing with the previous state-of-the-art methods that have similar numbers of parameters, e.g., ResNet50 (Xie et al., 2017), ResNeXt-50 (Xie et al., 2017) and DenseNet-264 (Huang et al., 2017b).
",5.3. Architectures for ImageNet,[0],[0]
We also implement a wider GUNN-based neural networks Wide-GUNN-18 for better capacities.,5.3. Architectures for ImageNet,[0],[0]
"The hyperparameters are {N = 1200, P = 30,K = 2,M = 1} for Conv2, {N = 1600, P = 40,K = 2,M = 1} for Conv3, {N = 2000, P = 50,K = 2,M = 1} for Conv4 and {N = 2000, P = 50,K = 2,M = 1} for Conv5.",5.3. Architectures for ImageNet,[0],[0]
The number of parameters is 45624936.,5.3. Architectures for ImageNet,[0],[0]
"The Wide-GUNN-18 is targeted at competing with ResNet-101, ResNext-101, DPN (Chen et al., 2017) and SENet (Hu et al., 2017).",5.3. Architectures for ImageNet,[0],[0]
"In this section, we demonstrate the effectiveness of the proposed GUNN on several benchmark datasets.",6. Experiments,[0],[0]
"CIFAR CIFAR (Krizhevsky & Hinton, 2009) has two color image datasets: CIFAR-10 (C10) and CIFAR-100 (C100).",6.1. Benchmark Datasets,[0],[0]
Both datasets consist of natural images with the size of 32× 32 pixels.,6.1. Benchmark Datasets,[0],[0]
"The CIFAR-10 dataset has 10 categories, while the CIFAR-100 dataset has 100 categories.",6.1. Benchmark Datasets,[0],[0]
"For both of the datasets, the training and test set contain 50, 000 and 10, 000 images, respectively.",6.1. Benchmark Datasets,[0],[0]
"To fairly compare our method with the state-of-the-arts (He et al., 2016a; Huang et al., 2017b; 2016; Larsson et al., 2016; Lee et al., 2014; Lin et al., 2013; Romero et al., 2014; Springenberg et al., 2014; Srivastava et al., 2015; Xie et al., 2017), we use the same training and testing strategies, as well as the data processing methods.",6.1. Benchmark Datasets,[0],[0]
"Specifically, we adopt a commonly used data augmentation scheme, i.e., mirroring and shifting, for these two datasets.",6.1. Benchmark Datasets,[0],[0]
"We use channel means and standard derivations to normalize the images for data pre-processing.
",6.1. Benchmark Datasets,[0],[0]
"ImageNet The ImageNet dataset (Russakovsky et al., 2015) contains about 1.28 million color images for training and 50, 000 for validation.",6.1. Benchmark Datasets,[0],[0]
The dataset has 1000 categories.,6.1. Benchmark Datasets,[0],[0]
"We adopt the same data augmentation methods as in the state-of-the-art architectures (He et al., 2016a;b; Huang et al., 2017b; Xie et al., 2017) for training.",6.1. Benchmark Datasets,[0],[0]
"For testing, we use single-crop at the size of 224× 224.",6.1. Benchmark Datasets,[0],[0]
"Following the
state-of-the-arts (He et al., 2016a;b; Huang et al., 2017b; Xie et al., 2017), we report the validation error rates.",6.1. Benchmark Datasets,[0],[0]
We train all of our networks using stochastic gradient descents.,6.2. Training Details,[0],[0]
"On CIFAR-10/100 (Krizhevsky & Hinton, 2009), the initial learning rate is set to 0.1, the weight decay is set to 1e−4, and the momentum is set to 0.9 without dampening.",6.2. Training Details,[0],[0]
We train the models for 300 epochs.,6.2. Training Details,[0],[0]
The learning rate is divided by 10 at 150th epoch and 225th epoch.,6.2. Training Details,[0],[0]
"We set the batch size to 64, following (Huang et al., 2017b).",6.2. Training Details,[0],[0]
"All the results reported for CIFAR, regardless of the detailed configurations, were trained using 4 NVIDIA Titan X GPUs with the data parallelism.",6.2. Training Details,[0],[0]
"On ImageNet (Russakovsky et al., 2015), the learning rate is also set to 0.1 initially, and decreases following the schedule in DenseNet (Huang et al., 2017b).",6.2. Training Details,[0],[0]
The batch size is set to 256.,6.2. Training Details,[0],[0]
"The network parameters are also initialized following (He et al., 2016a).",6.2. Training Details,[0],[0]
We use 8 Tesla V100 GPUs with the data parallelism to get the reported results.,6.2. Training Details,[0],[0]
"Our results are directly comparable with ResNet, WideResNet, ResNeXt and DenseNet.",6.2. Training Details,[0],[0]
We train two models GUNN-15 and GUNN-24 for the CIFAR-10/100 dataset.,6.3. Results on CIFAR,[0],[0]
Table 3 shows the comparisons between our method and the previous state-of-the-art methods.,6.3. Results on CIFAR,[0],[0]
Our method GUNN achieves the best results in the test of both the single model and the ensemble test.,6.3. Results on CIFAR,[0],[0]
"Here, we use Snapshot Ensemble (Huang et al., 2017a).
",6.3. Results on CIFAR,[0],[0]
Baseline Methods,6.3. Results on CIFAR,[0],[0]
Here we present the details of baseline methods in Table 3.,6.3. Results on CIFAR,[0],[0]
"The performances of ResNet (He et al., 2016a) are reported in Stochastic Depth (Huang et al., 2016) for both C10 and C100.",6.3. Results on CIFAR,[0],[0]
"The WideResNet (Zagoruyko & Komodakis, 2016) WRN-40-10 is reported in their official code repository on GitHub.",6.3. Results on CIFAR,[0],[0]
"The ResNeXt in the third group is of configuration 16 × 64d, which has the best result reported in the paper (Xie et al., 2017).",6.3. Results on CIFAR,[0],[0]
"The DenseNet is of configuration DenseNet-BC (k = 40), which achieves the best performances on CIFAR-10/100.",6.3. Results on CIFAR,[0],[0]
"The Snapshot Ensemble (Huang et al., 2017a) uses 6 DenseNet-100 to ensemble during inference.",6.3. Results on CIFAR,[0],[0]
"We do not compare with methods that use more data augmentation (e.g. (Zhang et al., 2017)) or stronger regularizations (e.g. (Gastaldi, 2017)) for the fairness of comparison.
",6.3. Results on CIFAR,[0],[0]
"Ablation Study For ablation study, we compare GUNN with SUNN, i.e., the networks before the conversion.",6.3. Results on CIFAR,[0],[0]
"Table 5 shows the comparison results, which demonstrate the effectiveness of GUNN.",6.3. Results on CIFAR,[0],[0]
We also compare the performances of GUNN with and without residual learning.,6.3. Results on CIFAR,[0],[0]
"We evaluate the GUNN on the ImageNet classification task, and compare our performances with the state-of-the-art methods.",6.4. Results on ImageNet,[0],[0]
"These methods include VGGNet (Simonyan & Zisserman, 2014), ResNet (He et al., 2016a), ResNeXt (Xie
et al., 2017), DenseNet (Huang et al., 2017b), DPN (Chen et al., 2017) and SENet (Hu et al., 2017).",6.4. Results on ImageNet,[0],[0]
The comparisons are shown in Table 4.,6.4. Results on ImageNet,[0],[0]
"The results of ours, ResNeXt, and DenseNet are directly comparable as these methods use the same framework for training and testing networks.",6.4. Results on ImageNet,[0],[0]
"Table 4 groups the methods by their numbers of parameters, except VGGNet which has 1.38× 108 parameters.
",6.4. Results on ImageNet,[0],[0]
"The results presented in Table 4 demonstrate that with the similar number of parameters, GUNN can achieve comparable performances with the previous state-of-the-art methods.",6.4. Results on ImageNet,[0],[0]
"For GUNN-18, we also conduct an ablation experiment by comparing the corresponding SUNN with GUNN of the same configuration.",6.4. Results on ImageNet,[0],[0]
"Consistent with the experimental results on the CIFAR-10/100 dataset, the proposed GUNN improves the accuracy on ImageNet dataset.",6.4. Results on ImageNet,[0],[0]
"In this paper, we propose Gradually Updated Neural Network (GUNN), a novel, simple yet effective method to increase the depths of neural networks as an alternative to cascading layers.",7. Conclusions,[0],[0]
"GUNN is based on Convolutional Neural Networks (CNNs), but differs from CNNs in the way of computing outputs.",7. Conclusions,[0],[0]
The outputs of GUNN are computed gradually rather than simultaneously as in CNNs in order to increase the depth.,7. Conclusions,[0],[0]
"Essentially, GUNN assumes the input and the output are of the same size and adds a computation ordering to the channels.",7. Conclusions,[0],[0]
The added ordering increases the receptive fields and non-linearities of the later computed channels.,7. Conclusions,[0],[0]
"Moreover, it eliminates the overlap singularities inherent in the traditional convolutional networks.",7. Conclusions,[0],[0]
We test GUNN on the task of image recognition.,7. Conclusions,[0],[0]
"The evaluations are done in three highly competitive benchmarks, CIFAR10, CIFAR-100 and ImageNet.",7. Conclusions,[0],[0]
The experimental results demonstrate the effectiveness of the proposed GUNN on image recognition.,7. Conclusions,[0],[0]
"In the future, since the proposed GUNN can be used to replace CNNs in other neural networks, we will study the applications of GUNN in other visual tasks, such as object detection and semantic segmentation.",7. Conclusions,[0],[0]
"We thank Wanyu Huang, Huiyu Wang and Chenxi Liu for their insightful comments and suggestions.",Acknowledgments,[0],[0]
We gratefully acknowledge funding supports from NSF award CCF-1317376 and ONR N00014-15-1-2356.,Acknowledgments,[0],[0]
This work was also supported in part by the National Natural Science Foundation of China under Grant 61672336.,Acknowledgments,[0],[0]
Depth is one of the keys that make neural networks succeed in the task of large-scale image recognition.,abstractText,[0],[0]
The state-of-the-art network architectures usually increase the depths by cascading convolutional layers or building blocks.,abstractText,[0],[0]
"In this paper, we present an alternative method to increase the depth.",abstractText,[0],[0]
"Our method is by introducing computation orderings to the channels within convolutional layers or blocks, based on which we gradually compute the outputs in a channel-wise manner.",abstractText,[0],[0]
"The added orderings not only increase the depths and the learning capacities of the networks without any additional computation costs, but also eliminate the overlap singularities so that the networks are able to converge faster and perform better.",abstractText,[0],[0]
Experiments show that the networks based on our method achieve the state-of-the-art performances on CIFAR and ImageNet datasets.,abstractText,[0],[0]
Gradually Updated Neural Networks for Large-Scale Image Recognition,title,[0],[0]
"In recent years, there has been an explosion of interest in sequence labelling tasks.",1. Introduction,[0],[0]
"Connectionist Temporal Classification (CTC) loss (Graves et al., 2006) and Sequenceto-sequence (seq2seq) models (Cho et al., 2014; Sutskever et al., 2014) present powerful approaches to multiple applications, such as Automatic Speech Recognition (ASR) (Chan et al., 2016a; Hannun et al., 2014; Bahdanau et al.,
*Equal contribution 1Baidu Silicon Valley AI Lab, 1195 Bordeaux Dr, Sunnyvale, CA 94089, USA.",1. Introduction,[0],[0]
"Correspondence to: Hairong Liu <liuhairong@baidu.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
2016), machine translation (Sébastien et al., 2015), and parsing (Vinyals et al., 2015).",1. Introduction,[0],[0]
"These methods are based on 1) a fixed and carefully chosen set of basic units, such as words (Sutskever et al., 2014), phonemes (Chorowski et al., 2015) or characters (Chan et al., 2016a), and 2) a fixed and pre-determined decomposition of target sequences into these basic units.",1. Introduction,[0],[0]
"While these two preconditions greatly simplify the problems, especially the training processes, they are also strict and unnecessary constraints, which usually lead to suboptimal solutions.",1. Introduction,[0],[0]
"CTC models are especially harmed by fixed basic units in target space, because they build on the independence assumption between successive outputs in that space - an assumption which is often violated in practice.
",1. Introduction,[0],[0]
"The problem with fixed set of basic units is obvious: it is really hard, if not impossible, to determine the optimal set of basic units beforehand.",1. Introduction,[0],[0]
"For example, in English ASR, if we use words as basic units, we will need to deal with the large vocabulary-sized softmax, as well as rare words and data sparsity problem.",1. Introduction,[0],[0]
"On the other hand, if we use characters as basic units, the model is forced to learn the complex rules of English spelling and pronunciation.",1. Introduction,[0],[0]
"For example, the ""oh"" sound can be spelled in any of following ways, depending on the word it occurs in - { o, oa, oe, ow, ough, eau, oo, ew }.",1. Introduction,[0],[0]
"While CTC can easily model commonly co-occuring grams together, it is impossible to give roughly equal probability to many possible spellings when transcribing unseen words.",1. Introduction,[0],[0]
"Most speech recognition systems model phonemes, sub-phoneme units and senones e.g, (Xiong et al., 2016a) to get around these problems.",1. Introduction,[0],[0]
"Similarly, state-of-the-art neural machine translation systems use pre-segmented word pieces e.g, (Wu et al., 2016a) aiming to find the best of both worlds.
",1. Introduction,[0],[0]
"In reality, groups of characters are typically cohesive units for many tasks.",1. Introduction,[0],[0]
"For the ASR task, words can be decomposed into groups of characters that can be associated with sound (such as ‘tion’ and ‘eaux’).",1. Introduction,[0],[0]
"For the machine translation task, there may be values in decomposing words as root words and extensions (so that meaning may be shared explicitly between ‘paternal’ and ‘paternity’).",1. Introduction,[0],[0]
"Since this information is already available in the training data, it is perhaps, better to let the model figure it out by itself.",1. Introduction,[0],[0]
"At the same time, it raises another import question: how to de-
compose a target sequence into basic units?",1. Introduction,[0],[0]
"This is coupled with the problem of automatic selection of basic units, thus also better to let the model determine.",1. Introduction,[0],[0]
"Recently, there are some interesting attempts in these directions in the seq2seq framework.",1. Introduction,[0],[0]
"For example, Chan et al (Chan et al., 2016b) proposed the Latent Sequence Decomposition to decompose target sequences with variable length units as a function of both input sequence and the output sequence.
",1. Introduction,[0],[0]
"In this work, we propose Gram-CTC - a strictly more general version of CTC - to automatically seek the best set of basic units from the training data, called grams, and automatically decompose target sequences into sequences of grams.",1. Introduction,[0],[0]
"Just as sequence prediction with cross entropy training can be seen as special case of the CTC loss with a fixed alignment, CTC can be seen as a special case of Gram-CTC with a fixed decomposition of target sequences.",1. Introduction,[0],[0]
"Since it is a loss function, it can be applied to many seq2seq tasks to enable automatic selection of grams and decomposition of target sequences without modifying the underlying networks.",1. Introduction,[0],[0]
"Extensive experiments on multiple scales of data validate that Gram-CTC can improve CTC in terms of both performance and efficiency, and that using Gram-CTC the models outperform state-of-the-arts on standard speech benchmarks.",1. Introduction,[0],[0]
"The basic text units that previous works utilized for text prediction tasks (e.g,, automatic speech recognition, handwriting recognition, machine translation, and image captioning) can be generally divided into two categories: handcrafted ones and learning-based ones.
",2. Related Work,[0],[0]
Hand-crafted Basic Units.,2. Related Work,[0],[0]
"Fixed sets of characters (graphemes) (Graves et al., 2006; Amodei et al., 2015), word-pieces (Wu et al., 2016b; Collobert et al., 2016; Zweig et al., 2016a), words (Soltau et al., 2016; Sébastien et al., 2015), and phonemes (Lee and Hon, 1988; Sercu and Goel, 2016; Xiong et al., 2016b) have been widely used as basic units for text prediction, but all of them have drawbacks.",2. Related Work,[0],[0]
"Using these fixed deterministic decompositions of text sequences defines a prior, which is not necessarily optimal for end-to-end learning.
",2. Related Work,[0],[0]
• Word-segmented models remove the component of learning to spell and thus enable direct optimization towards reducing Word Error Rate (WER).,2. Related Work,[0],[0]
"However, these models suffer from having to handle a large vocabulary (1.7 million in (Soltau et al., 2016)), out-of-vocabulary words (Soltau et al., 2016; Sébastien et al., 2015) and data sparsity problems (Soltau et al., 2016).
",2. Related Work,[0],[0]
"• Using characters results in much smaller vocabularies (e.g, 26 for English and thousands for Chinese), but it requires much longer contexts compared to using words or word-pieces and poses the challenge of composing characters to words (Graves et al., 2006; Chan et al., 2015),
which is very noisy for languages like English.
",2. Related Work,[0],[0]
"• Word-pieces lie at the middle-ground of words and characters, providing a good trade-off between vocabulary size and context size, while the performance of using word pieces is sensitive to the choice of the word-piece set and its decomposition.
",2. Related Work,[0],[0]
"• For the ASR task, the use of phonemes was popular in the past few decades as it eases acoustic modeling (Lee and Hon, 1988) and good results were reported with phonemic models (Xiong et al., 2016b; Sercu and Goel, 2016).",2. Related Work,[0],[0]
"However, it introduces the uncertainties of mapping phonemes to words during decoding (Doss et al., 2003), which becomes less robust especially for accented speech data.
",2. Related Work,[0],[0]
Learning-based Basic Units.,2. Related Work,[0],[0]
"More recently, attempts have been made to learn basic unit sets automatically.",2. Related Work,[0],[0]
"(Luong and Manning, 2016) proposed a hybrid WordCharacter model which translates mostly at the word level and consults the character components for rare words.",2. Related Work,[0],[0]
"Chan et al (Chan et al., 2016b) proposed the Latent Sequence Decompositions framework to decomposes target sequences with variable length-ed basic units as a function of both input sequence and the output sequence.
",2. Related Work,[0],[0]
"There exist some earlier works on the “unit discovery” task (Cartwright and Brent, 1994; Goldwater et al., 2006).",2. Related Work,[0],[0]
"A standard problem with MLE solutions to this task is that there are degenerate solutions, i.e., predicting the full corpus with probability 1 at the start.",2. Related Work,[0],[0]
Often Bayesian priors or “minimum description length” constraints are used to remedy this.,2. Related Work,[0],[0]
"CTC (Graves et al., 2006) is a very popular method in seq2seq learning since it does not require the alignment information between inputs and outputs, which is usually expensive, if not impossible, to obtain.
",3.1. CTC,[0],[0]
"Since there is no alignment information, CTC marginalizes over all possible alignments.",3.1. CTC,[0],[0]
"That is, it tries to maximize p(l|x) =",3.1. CTC,[0],[0]
"∑ π p(π|x), where x is input, and π represent a valid alignment.",3.1. CTC,[0],[0]
"For example, if the size of input is 3, and the output is ‘hi’, whose length is 2, there are three possible alignments, ‘-hi’, ‘h-i’ and ‘hi-’, where ‘-’ represents blank.",3.1. CTC,[0],[0]
"For the details, please refer to the original paper (Graves et al., 2006).",3.1. CTC,[0],[0]
"In CTC, the basic units are fixed, which is not desirable in some applications.",3.2. From CTC to Gram-CTC,[0],[0]
"Here we generalize CTC by considering a sequence of basic units, called gram, as a whole, which is usually more reasonable in many applications.
",3.2. From CTC to Gram-CTC,[0],[0]
"Let G be a set of n-grams of the set of basic units C of the target sequence, and τ be the length of the longest gram in G. A Gram-CTC network has a softmax output layer with |G|+1 units, that is, the probability over all grams inG and one additional symbol, blank.",3.2. From CTC to Gram-CTC,[0],[0]
"To simplify the problem, we also assume C ⊆ G. 1
For an input sequence x of length T , let y = Nw(x) be the sequence of network outputs, and denote by ytk as the probability of the k-th gram at time t, where k is the index of grams in G′ = G ∪ {blank}, then we have
p(π|x)",3.2. From CTC to Gram-CTC,[0],[0]
"= T∏ t=1 ytπt ,∀π ∈ G ′T (1)
Just as in the case of CTC, here we refer to the elements of G′T as paths, and denote them by π, which represents a possible alignment between input and output.",3.2. From CTC to Gram-CTC,[0],[0]
"The difference is that for each word in the target sequence, it may be decomposed into different sequences of grams.",3.2. From CTC to Gram-CTC,[0],[0]
"For example, the word ‘hello’ can only be decomposed into the sequence [‘h’, ‘e’, ‘l’, ‘l’, ‘o’] for CTC (assume uni-gram CTC here), but it also can be decomposed into the sequence [‘he’, ‘ll’, ‘o’] if ‘he’ and ‘ll’ are in G.
For each π, we map it into a target sequence in the same way as CTC using the collapsing function that 1) removes all repeated labels from the path and then 2) removes all blanks.",3.2. From CTC to Gram-CTC,[0],[0]
"Note that essentially it is these rules which de-
1This is because there may be no valid decompositions for some target sequences if C 6⊆ G. Since Gram-CTC will figure out the ideal decomposition of target sequences into grams during training, this condition guarantees that there is at least one valid decomposition for every target sequence.
termine the transitions between the states of adjacent time steps in Figure 1.",3.2. From CTC to Gram-CTC,[0],[0]
This is a many-to-one mapping and we denote it by B. Note that other rules can be adopted here and the general idea presented in this paper does not depend on these specific rules.,3.2. From CTC to Gram-CTC,[0],[0]
"For a target sequence l, B−1(l) represents all paths mapped to l. Then, we have
p(l|x) = ∑
π∈B−1(l)
p(π|x) (2)
",3.2. From CTC to Gram-CTC,[0],[0]
"This equation allows for training sequence labeling models without any alignment information using CTC loss, because it marginalizes over all possible alignments during training.",3.2. From CTC to Gram-CTC,[0],[0]
"Gram-CTC uses the same effect to enable the model to marginalize over not only alignments, but also decompositions of the target sequence.
",3.2. From CTC to Gram-CTC,[0],[0]
"Note that for each target sequence l, the set B−1(l) has O(τ2) more paths than it does in CTC.",3.2. From CTC to Gram-CTC,[0],[0]
"This is because there are O(τ) times more valid states per time step, and each state may have a valid transition from O(τ) states in the previous time step.",3.2. From CTC to Gram-CTC,[0],[0]
"The original CTC method is thus, a special case of Gram-CTC when G = C and τ = 1.",3.2. From CTC to Gram-CTC,[0],[0]
"While the quadratic increase in the complexity of the algorithm is non trivial, we assert that it is a trivial increase in the overall training time of typical neural networks, where the computation time is dominated by the neural networks themselves.",3.2. From CTC to Gram-CTC,[0],[0]
"Additionally, the algorithm extends generally to any arbitrary G and need not have all possible n-grams up to length τ .",3.2. From CTC to Gram-CTC,[0],[0]
"To efficiently compute p(l|x), we also adopt the dynamic programming algorithm.",3.3. The Forward-Backward Algorithm,[0],[0]
"The essence here is identifying
the states of the problem, so that we may solve future states by reusing solutions to earlier states.",3.3. The Forward-Backward Algorithm,[0],[0]
"In our case, the state must contain all the information required to identify all valid extensions of an incomplete path π such that the collapsing function will eventually collapse the complete π back to l. For Gram-CTC, this can be done by collapsing all but the last element of the path π.",3.3. The Forward-Backward Algorithm,[0],[0]
"Therefore, the state is a tuple (l1:i, j), where the first item is a collapsed path, representing a prefix of the target label sequence, and j ∈ {0, . . .",3.3. The Forward-Backward Algorithm,[0],[0]
", τ} is the length of the last gram (li−j+1:i) used for making the prefix.",3.3. The Forward-Backward Algorithm,[0],[0]
j = 0 is valid and means that blank was used.,3.3. The Forward-Backward Algorithm,[0],[0]
"We denote the gram (li−j+1:i) by g j i (l), and the state (l1:i, j) as s j i (l).",3.3. The Forward-Backward Algorithm,[0],[0]
"For readability, we will further shorten sji (l) to s j i and g j",3.3. The Forward-Backward Algorithm,[0],[0]
i (l) to g j i .,3.3. The Forward-Backward Algorithm,[0],[0]
"For a state s, its corresponding gram is denoted by sg , and the positions of the first character and last character of sg are denoted by b(s) and e(s), respectively.",3.3. The Forward-Backward Algorithm,[0],[0]
"During dynamic programming, we are dealing with sequence of states, for a state sequence ζ, its corresponding gram sequences is unique, denoted by ζg .
",3.3. The Forward-Backward Algorithm,[0],[0]
Figure 1 illustrates partially the dynamic programming process for the target sequence ‘CAT’.,3.3. The Forward-Backward Algorithm,[0],[0]
Here we suppose G contains all possible uni-grams and bi-grams.,3.3. The Forward-Backward Algorithm,[0],[0]
"Thus, for each character in ‘CAT’, there are three possible states associated with it: 1) the current character, 2) the bi-gram ending in current character, and 3) the blank after current character.",3.3. The Forward-Backward Algorithm,[0],[0]
There is also one blank at beginning.,3.3. The Forward-Backward Algorithm,[0],[0]
"In total we have 10 states.
",3.3. The Forward-Backward Algorithm,[0],[0]
"Supposing the maximum length of grams inG is τ , we first scan l to get the set S of all possible states, such that for all sji ∈ S, its corresponding g j i ∈",3.3. The Forward-Backward Algorithm,[0],[0]
"G′. i ∈ {0, . . .",3.3. The Forward-Backward Algorithm,[0],[0]
", |l|}",3.3. The Forward-Backward Algorithm,[0],[0]
"and j ∈ {0, . . .",3.3. The Forward-Backward Algorithm,[0],[0]
", τ}.",3.3. The Forward-Backward Algorithm,[0],[0]
"For a target sequence l, define the forward variable αt(s) for any s ∈ S to the total probability of all valid paths prefixes that end at state s at time t.
αt(s) def = ∑ ζ|B(ζg)=l1:e(s),ζt=s t∏ t′=1 yt ′ ζt′g (3)
",3.3. The Forward-Backward Algorithm,[0],[0]
"Following this definition, we have the following rules for initialization
α1(s) =  y1b s = s 0 0 y1 gii
s = sii ∀i ∈ {1, . . .",3.3. The Forward-Backward Algorithm,[0],[0]
", τ} 0 otherwise
(4)
and recursion
αt(s) =  α̂it−1 ∗ ytb when s = s0i , [α̂i−jt−1 + αt−1(s)] ∗ ytgji when s = sji and g j",3.3. The Forward-Backward Algorithm,[0],[0]
i 6=,3.3. The Forward-Backward Algorithm,[0],[0]
"g j i−j , [α̂i−jt−1 + αt−1(s)− αt−1(s j i−j)] ∗ ytgji
when s = sji and g j i = g j i−j
(5)
where α̂it = ∑τ j=0",3.3. The Forward-Backward Algorithm,[0],[0]
αt(s j i ) and y t b is the probability of blank at time,3.3. The Forward-Backward Algorithm,[0],[0]
"t.
The total probability of the target sequence l is then expressed in the following way:
p(l|x) = τ∑ j=0",3.3. The Forward-Backward Algorithm,[0],[0]
"αT (s j |l|) (6)
similarly, we can define the backward variable βt(s) as:
βt(s) def = ∑ ζ|B(ζg)=lb(s):l,ζt=s T∏ t′=t yt ′ ζt′g (7)
",3.3. The Forward-Backward Algorithm,[0],[0]
"For the initialization and recursion of βt(s), we have
βT",3.3. The Forward-Backward Algorithm,[0],[0]
"(s) =  yTb s = s 0 T yT giT
s = siT ∀i ∈ {1, . .",3.3. The Forward-Backward Algorithm,[0],[0]
.,3.3. The Forward-Backward Algorithm,[0],[0]
", τ} 0 otherwise
(8)
and
βt(s) =  β̂it+1 ∗ ytb when s = s0i , [β̂i+jt+1 + βt+1(s)] ∗ ytgji when s = sji and g j i 6=",3.3. The Forward-Backward Algorithm,[0],[0]
"g j i+j , [β̂i+jt+1 + βt+1(s)− βt+1(s j i+j)] ∗ ytgji
when s = sji and g j i = g j i+j
(9) where β̂it = ∑τ j=0 βt(s j i+j)",3.3. The Forward-Backward Algorithm,[0],[0]
"Similar to CTC, we have the following expression:
p(l|x) = ∑ s∈S αt(s)βt(s)",3.4. BackPropagation,[0],[0]
"ytsg ∀t ∈ {1, . . .",3.4. BackPropagation,[0],[0]
",T} (10)
",3.4. BackPropagation,[0],[0]
"The derivative with regards to ytk is:
∂p(l|x) ∂ytk",3.4. BackPropagation,[0],[0]
"= 1 ytk 2 ∑ s∈lab(l,k) αt(s)βt(s) (11)
where lab(l, k) is the set of states in S whose corresponding gram is",3.4. BackPropagation,[0],[0]
k.,3.4. BackPropagation,[0],[0]
"This is because there may be multiple states corresponding to the same gram.
",3.4. BackPropagation,[0],[0]
"For the backpropagation, the most important formula is the partial derivative of loss with regard to the unnormalized output utk.
∂ ln p(l|x) ∂utk = ytk",3.4. BackPropagation,[0],[0]
"− 1 ytkZt ∑ s∈lab(l,k) αt(s)βt(s) (12)
where Zt def = ∑ s∈S
αt(s)βt(s)",3.4. BackPropagation,[0],[0]
"ytsg .
",3.4. BackPropagation,[0],[0]
(a) Training curves before (blue) and after (orange) auto-refinement of grams.,3.4. BackPropagation,[0],[0]
"(b) Training curves without (blue) and with (orange) joint-training
Gram-CTC C _",3.4. BackPropagation,[0],[0]
"AT
CTC _",3.4. BackPropagation,[0],[0]
C _,3.4. BackPropagation,[0],[0]
"A T _
Gram-CTC C - AT
CTC - C - A T -
(c) Joint-training Architecture
Figure 2.",3.4. BackPropagation,[0],[0]
(Figure 2a) compares the training curves before (blue) and after (orange) auto-refinement of grams.,3.4. BackPropagation,[0],[0]
"They look very similar, although the number of grams is greatly reduced after refinement, which makes training faster and potentially more robust due to less gram sparsity.",3.4. BackPropagation,[0],[0]
Figure (2b) Training curve of model with and without joint-training.,3.4. BackPropagation,[0],[0]
"The model corresponding to the orange training curve is jointly trained together with vanilla CTC, such models are often more stable during training.",3.4. BackPropagation,[0],[0]
Figure (2c) Typical joint-training model architecture - vanilla CTC loss is best applied a few levels lower than the Gram-CTC loss.,3.4. BackPropagation,[0],[0]
Here we describe additional techniques we found useful in practice to enable the Gram-CTC to work efficiently as well as effectively.,4. Methodology,[0],[0]
"Although Gram-CTC can automatically select useful grams, it is challenging to train with a large G.",4.1. Iterative Gram Selection,[0],[0]
The total number of possible grams is usually huge.,4.1. Iterative Gram Selection,[0],[0]
"For example, in English, we have 26 characters, then the total number of bi-grams is 262 = 676, the total number of tri-grams are 263 = 17576, . . .",4.1. Iterative Gram Selection,[0],[0]
", which grows exponentially and quickly becomes intractable.",4.1. Iterative Gram Selection,[0],[0]
"However, it is unnecessary to consider many grams, such as ‘aaaa’, which are obviously useless.
",4.1. Iterative Gram Selection,[0],[0]
"In our experiments, we first eliminate most of useless grams from the statistics of a huge corpus, that is, we count the frequency of each gram in the corpus and drop these grams with rare frequencies.",4.1. Iterative Gram Selection,[0],[0]
"Then, we train a model with Gram-CTC on all the remaining grams.",4.1. Iterative Gram Selection,[0],[0]
"By applying (decoding) the trained model on a large speech dataset, we get the real statistics of gram’s usage.",4.1. Iterative Gram Selection,[0],[0]
"Ultimately, we choose high frequency grams together with all uni-grams as our final gram set G. Table 1 shows the impact of iterative gram selection on WSJ (without LM).",4.1. Iterative Gram Selection,[0],[0]
Figure 2a shows its corresponding training curve.,4.1. Iterative Gram Selection,[0],[0]
"For details, please refer to Section 5.2.",4.1. Iterative Gram Selection,[0],[0]
"Gram-CTC needs to solve both decomposition and alignment tasks, which is a harder task for a model to learn than CTC.",4.2. Joint Training with Vanilla CTC,[0],[0]
"This is often manifested in unstable training curves, forcing us to lower the learning rate which in turn results
in models converging to a worse optima.",4.2. Joint Training with Vanilla CTC,[0],[0]
"To overcome this difficulty, we found it beneficial to train a model with both the Gram-CTC, as well as the vanilla CTC loss (similar to joint-training CTC together with CE loss as mentioned in (Sak et al., 2015)).",4.2. Joint Training with Vanilla CTC,[0],[0]
"Joint training of multiple objectives for sequence labelling has also been explored in previous works (Kim et al., 2016; Kim and Rush, 2016).
",4.2. Joint Training with Vanilla CTC,[0],[0]
"A typical joint-training model looks like Figure 2c, and the corresponding training curve is shown in Figure 2b.",4.2. Joint Training with Vanilla CTC,[0],[0]
The effect of joint-training are shown in Table 4 and Table 5 in the experiments.,4.2. Joint Training with Vanilla CTC,[0],[0]
"We test the Gram-CTC loss on the ASR task, while both CTC and the introduced Gram-CTC are generic techniques for other sequence labelling tasks.",5. Experiments,[0],[0]
"For all of the experiments, the model specification and training procedure are the same as in (Amodei et al., 2015) -",5. Experiments,[0],[0]
"The model is a recurrent neural network (RNN) with 2 two-dimensional convolutional input layers, followed by K forward (Fwd) or bidirectional (Bidi)",5. Experiments,[0],[0]
"Gated Recurrent layers, N cells each, and one fully connected layer before a softmax layer.",5. Experiments,[0],[0]
"In short hand, such a model is written as ‘2x2D Conv - KxN GRU’.",5. Experiments,[0],[0]
"The network is trained end-to-end with the CTC, GramCTC or a weighted combination of both.",5. Experiments,[0],[0]
"This combination is described in the earlier section.
",5. Experiments,[0],[0]
"In all experiments, audio data is is sampled at 16kHz.",5. Experiments,[0],[0]
"Linear FFT features are extracted with a hop size of 10ms and window size of 20ms, and are normalized so that each input feature has zero mean and unit variance.",5. Experiments,[0],[0]
The network inputs are thus spectral magnitude maps ranging from 0-8kHz with 161 features per 10ms frame.,5. Experiments,[0],[0]
"At each epoch, 40% of the utterances are randomly selected to add
background noise to.",5. Experiments,[0],[0]
The optimization method we use is stochastic gradient descent with Nesterov momentum.,5. Experiments,[0],[0]
"Learning hyperparameters (batch-size, learning-rate, momentum, and etc.) vary across different datasets and are tuned for each model by optimizing a hold-out set.",5. Experiments,[0],[0]
Typical values are a learning rate of 10−3 and momentum of 0.99.,5. Experiments,[0],[0]
Wall Street Journal (WSJ).,5.1. Data and Setup,[0],[0]
"This corpora consists primarily of read speech with texts drawn from a machinereadable corpus of Wall Street Journal news text, and contains about 80 hours speech data.",5.1. Data and Setup,[0],[0]
"We used the standard configuration of train si284 dataset for training, dev93 for validation and eval92 for testing.",5.1. Data and Setup,[0],[0]
"This is a relatively ‘clean’ task and often used for model prototyping (Miao et al., 2015; Bahdanau et al., 2016; Zhang et al., 2016; Chan et al., 2016b).
",5.1. Data and Setup,[0],[0]
Fisher-Switchboard.,5.1. Data and Setup,[0],[0]
"This is a commonly used English conversational telephone speech (CTS) corpora, which contains 2300 hours CTS data.",5.1. Data and Setup,[0],[0]
"Following the previous works (Zweig et al., 2016b; Povey et al., 2016; Xiong et al., 2016b; Sercu and Goel, 2016), evaluation is carried out on the NIST 2000 CTS test set, which comprises both Switchboard (SWB) and CallHome (CH) subsets.
10K Speech Dataset.",5.1. Data and Setup,[0],[0]
"We conduct large scale ASR experiments on a noisy internal dataset of 10,000 hours.",5.1. Data and Setup,[0],[0]
"This dataset contains speech collected from various scenarios, such as different background noises, far-field, different accents, and so on.",5.1. Data and Setup,[0],[0]
"Due to its inherent complexities, it is a very challenging task, and can thus validate the effectiveness of the proposed method for real-world application.",5.1. Data and Setup,[0],[0]
"We employ the WSJ dataset for demonstrating different strategies of selecting grams for Gram-CTC, since it is a widely used dataset and also small enough for rapid idea verification.",5.2. Gram Selection,[0],[0]
"However, because it is small, we cannot use large grams here due to data sparsity problem.",5.2. Gram Selection,[0],[0]
"Thus, the auto-refined gram set on WSJ is not optimal for other larger datasets, where larger grams could be effectively used, but the procedure of refinement is the same for them.
",5.2. Gram Selection,[0],[0]
"We first train a model using all uni-grams and bi-grams (29
uni-grams and 262 = 676 bi-grams, in total 705 grams), and then do decoding with the obtained model on another speech dataset to get the statistics of the usage of grams.",5.2. Gram Selection,[0],[0]
Top 100 bi-grams together with all 29 uni-grams (autorefined grams) are used for the second round of training.,5.2. Gram Selection,[0],[0]
"For comparison, we also present the result of the best handpicked grams, as well as the results on uni-grams.",5.2. Gram Selection,[0],[0]
"All the results are shown in Table 1.
",5.2. Gram Selection,[0],[0]
Some interesting observations can be found in Table 1.,5.2. Gram Selection,[0],[0]
"First, the performance of auto-refined grams is only slightly better than the combination of all uni-grams and all bigrams.",5.2. Gram Selection,[0],[0]
This is probably because WSJ is so small that gram learning suffers from the data sparsity problem here (similar to word-segmented models).,5.2. Gram Selection,[0],[0]
"The auto-refined gram set contains only a small subset of bi-grams, thus more robust.",5.2. Gram Selection,[0],[0]
"This is also why we only try bi-grams, not including higher-order grams.",5.2. Gram Selection,[0],[0]
"Second, the performance of best handpicked grams is worse than auto-refined grams.",5.2. Gram Selection,[0],[0]
This is desirable.,5.2. Gram Selection,[0],[0]
"It is time-consuming to handpick grams, especially when you consider high-order grams.",5.2. Gram Selection,[0],[0]
"The method of iterative gram selection is not only fast, but usually better.",5.2. Gram Selection,[0],[0]
"Third, the performance of Gram-CTC on auto-refined grams is only slightly better than CTC on uni-grams.",5.2. Gram Selection,[0],[0]
"This is because Gram-CTC is inherently difficult to train, since it needs to learn both decomposition and alignment.",5.2. Gram Selection,[0],[0]
WSJ is too small to provide enough data to train Gram-CTC.,5.2. Gram Selection,[0],[0]
"Using a large time stride for sequence labelling with RNNs can greatly boost the overall computation efficiency, since it effectively reduces the time steps for recurrent computation, thus speeds up the process of both forward inference and backward propagation.",5.3. Sequence Labelling in Large Stride,[0],[0]
"However, the largest stride that can be used is limited by the gram set we use.",5.3. Sequence Labelling in Large Stride,[0],[0]
The (unigram) CTC has to work in a high time resolution (small stride) in order to have enough number of frames to output every character.,5.3. Sequence Labelling in Large Stride,[0],[0]
"This is very inefficient as we know the same acoustic feature could correspond to several grams of different lengths (e.g., {‘i’, ‘igh’, ‘eye’}) .",5.3. Sequence Labelling in Large Stride,[0],[0]
"The larger the grams are, the larger stride we are potentially able to use.
",5.3. Sequence Labelling in Large Stride,[0],[0]
"DS2 (Amodei et al., 2015) employed non-overlapping bigram outputs to allow for a larger stride.",5.3. Sequence Labelling in Large Stride,[0],[0]
"This imposes an artificial constraint forcing the model to learn, not only the spelling of each word, but also how to split words into bigrams.",5.3. Sequence Labelling in Large Stride,[0],[0]
"For example, part is split as [pa, rt] but the word
apart is forced to be decomposed as [ap, ar, t].",5.3. Sequence Labelling in Large Stride,[0],[0]
GramCTC removes this constraint by allowing the model to decompose words into larger units into the most convenient or sensible decomposition.,5.3. Sequence Labelling in Large Stride,[0],[0]
"Comparison results show this change enables Gram-CTC to work much better than bigram CTC, as in Table 2.
",5.3. Sequence Labelling in Large Stride,[0],[0]
"In Table 2, we compare the performance of trained model and training efficiency on two strides, 2 and 4.",5.3. Sequence Labelling in Large Stride,[0],[0]
"For GramCTC, we use the auto-refined gram set from previous section.",5.3. Sequence Labelling in Large Stride,[0],[0]
"As expected, using stride 4 almost cuts the training time per epoch into half, compared to stride 2.",5.3. Sequence Labelling in Large Stride,[0],[0]
"From stride 2 to stride 4, the performance of uni-gram CTC drops quickly.",5.3. Sequence Labelling in Large Stride,[0],[0]
This is because small grams inherently need higher time resolutions.,5.3. Sequence Labelling in Large Stride,[0],[0]
"As for Gram-CTC, from stride 2 to stride 4, its performance decreases a little bit, while in experiments on the other datasets, Gram-CTC constantly works better in stride 4.",5.3. Sequence Labelling in Large Stride,[0],[0]
One possible explanation is that WSJ is too small for Gram-CTC to learn large grams well.,5.3. Sequence Labelling in Large Stride,[0],[0]
"In contrast, the performance of bi-gram CTC is not as good as that of Gram-CTC in either stride.",5.3. Sequence Labelling in Large Stride,[0],[0]
Figure 3 illustrates the max-decoding results of both CTC and Gram-CTC on nine utterances.,5.4. Decoding Examples,[0],[0]
"Here the label set for CTC is the set of all characters, and the label set for GramCTC is an auto-refined gram set containing all uni-grams and some high-frequency high-order grams.",5.4. Decoding Examples,[0],[0]
"Here Gram-
CTC uses stride 4 while CTC uses stride 2.
",5.4. Decoding Examples,[0],[0]
"From Figure 3, we can find that: 1) Gram-CTC does automatically find many intuitive and meaningful grams, such as ‘the’, ‘ng’, and ‘are’.",5.4. Decoding Examples,[0],[0]
2) It also decomposes the sentences into segments which are meaningful in term of pronunciation.,5.4. Decoding Examples,[0],[0]
"This decomposition resembles the phonetic decomposition, but in larger granularity and arguably more natural.",5.4. Decoding Examples,[0],[0]
"3) Since Gram-CTC predicts a chunk of characters (a gram) each time, each prediction utilizes larger context and these characters in the same predicted chunk are dependent, thus potentially more robust.",5.4. Decoding Examples,[0],[0]
"One example is the word ‘will’ in the last sentence in Figure 3. 4) Since the output of network is the probability over all grams, the decoding process is almost the same as CTC, still end-toend.",5.4. Decoding Examples,[0],[0]
This makes such decomposition superior to phonetic decomposition.,5.4. Decoding Examples,[0],[0]
"In summary, Gram-CTC combines the advantages of both CTC on characters and CTC on phonemes.",5.4. Decoding Examples,[0],[0]
"The model used here is [2x2D conv, 3x1280 Bidi GRU] with a CTC or Gram-CTC loss.",5.5.1. WSJ DATASET,[0],[0]
The results are shown in Table 3.,5.5.1. WSJ DATASET,[0],[0]
"For all models we trained, language model can greatly improve their performances, in term of WER.",5.5.1. WSJ DATASET,[0],[0]
"Though this dataset contains very limited amount of text data for learning gram selection and decomposition, Gram-
CTC can still improve the vanilla CTC notably.",5.5.1. WSJ DATASET,[0],[0]
The acoustic model trained here is composed of two 2D convolutions and six bi-directional GRU layer in 2048 dimension.,5.5.2. FISHER-SWITCHBOARD,[0],[0]
"The corresponding labels are used for training N-gram language models.
",5.5.2. FISHER-SWITCHBOARD,[0],[0]
• Switchboard,5.5.2. FISHER-SWITCHBOARD,[0],[0]
"English speech 97S62 • Fisher English speech Part 1 - 2004S13, 2004T19 • Fisher English speech Part 2 - 2005S13, 2005T19
We use a sample of the Switchboard-1 portion of the NIST 2002 dataset (2004S11 RT-02) for tuning language model hyper-parameters.",5.5.2. FISHER-SWITCHBOARD,[0],[0]
The evaluation is done on the NIST 2000 set.,5.5.2. FISHER-SWITCHBOARD,[0],[0]
This configuration forms a standard benchmark for evaluating ASR models.,5.5.2. FISHER-SWITCHBOARD,[0],[0]
"Results are in Table 4.
",5.5.2. FISHER-SWITCHBOARD,[0],[0]
We compare our model against best published results on in-domain data.,5.5.2. FISHER-SWITCHBOARD,[0],[0]
"These results can often be improved using out-of-domain data for training the language model, and sometimes the acoustic model as well.",5.5.2. FISHER-SWITCHBOARD,[0],[0]
"Together these techniques allow (Xiong et al., 2016b) to reach a WER of 5.9 on the SWBD set.",5.5.2. FISHER-SWITCHBOARD,[0],[0]
"Finally, we experiment on a large noisy dataset collected by ourself for building large-vocabulary Continuous Speech Recognition (LVCSR) systems.",5.5.3. 10K SPEECH DATASET,[0],[0]
"This dataset contains about 10000 hours speech in a diversity of scenarios, such as farfield, background noises, accents.",5.5.3. 10K SPEECH DATASET,[0],[0]
"In all cases, the model is [2x2D Conv, 3x2560 Fwd GRU, LA Conv] with only a change in the loss function.",5.5.3. 10K SPEECH DATASET,[0],[0]
"‘LA Conv’ refers to a look ahead convolution layer as seen in (Amodei et al., 2015) which works together with forward-only RNNs for deployment purpose.
",5.5.3. 10K SPEECH DATASET,[0],[0]
"As with the Fisher-Switchboard dataset, the optimal stride is 4 for Gram-CTC and 2 for vanilla CTC on this dataset.",5.5.3. 10K SPEECH DATASET,[0],[0]
"Thus, in both experiments, both Gram-CTC and vanilla
CTC + Gram-CTC are trained mush faster than vanilla CTC itself.",5.5.3. 10K SPEECH DATASET,[0],[0]
The result is shown in Table 5.,5.5.3. 10K SPEECH DATASET,[0],[0]
Gram-CTC performs better than CTC.,5.5.3. 10K SPEECH DATASET,[0],[0]
"After joint-training with vanilla CTC and alignment information through a CE loss, its performance is further boosted, which verifies joint-training helps training.",5.5.3. 10K SPEECH DATASET,[0],[0]
"In fact, with only a small additional cost of time, it effectively reduces the WER from 27.56% to 25.59% (without language model).",5.5.3. 10K SPEECH DATASET,[0],[0]
"In this paper, we have proposed the Gram-CTC loss to enable automatic decomposition of target sequences into learned grams.",6. Conclusions and Future Work,[0],[0]
We also present techniques to train the Gram-CTC in a clean and stable way.,6. Conclusions and Future Work,[0],[0]
"Our extensive experiments demonstrate the proposed Gram-CTC enables the models to run more efficiently than the vanilla CTC, by using larger stride, while obtaining better performance of sequence labelling.",6. Conclusions and Future Work,[0],[0]
"Comparison experiments on multiplescale datasets show the proposed Gram-CTC obtains stateof-the-art results on various ASR tasks.
",6. Conclusions and Future Work,[0],[0]
"An interesting observation is that the learning of GramCTC implicitly avoids the “degenerated solution” that occurring in the traditional “unit discovery” task, without involving any Bayesian priors or the “minimum description length” constraint.",6. Conclusions and Future Work,[0],[0]
"Using a small gram set that contains only short (up to 5 in our experiments) as well as highfrequency grams may explain the success here.
",6. Conclusions and Future Work,[0],[0]
"We will continue investigating techniques of improving the optimization of Gram-CTC loss, as well as the applications of Gram-CTC for other sequence labelling tasks.",6. Conclusions and Future Work,[0],[0]
Most existing sequence labelling models rely on a fixed decomposition of a target sequence into a sequence of basic units.,abstractText,[0],[0]
"These methods suffer from two major drawbacks: 1) the set of basic units is fixed, such as the set of words, characters or phonemes in speech recognition, and 2) the decomposition of target sequences is fixed.",abstractText,[0],[0]
These drawbacks usually result in sub-optimal performance of modeling sequences.,abstractText,[0],[0]
"In this paper, we extend the popular CTC loss criterion to alleviate these limitations, and propose a new loss function called Gram-CTC.",abstractText,[0],[0]
"While preserving the advantages of CTC, Gram-CTC automatically learns the best set of basic units (grams), as well as the most suitable decomposition of target sequences.",abstractText,[0],[0]
"Unlike CTC, Gram-CTC allows the model to output variable number of characters at each time step, which enables the model to capture longer term dependency and improves the computational efficiency.",abstractText,[0],[0]
"We demonstrate that the proposed Gram-CTC improves CTC in terms of both performance and efficiency on the large vocabulary speech recognition task at multiple scales of data, and that with Gram-CTC we can outperform the state-of-the-art on a standard speech benchmark.",abstractText,[0],[0]
Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence Labelling,title,[0],[0]
"Generative machine learning models have been used recently to produce extraordinary results, from realistic musical improvisation (Jaques et al., 2016), to changing facial expressions in images (Radford et al., 2015; Upchurch et al., 2016), to creating realistic looking artwork (Gatys et al., 2015).",1. Introduction,[0],[0]
"In large part, these generative models have been successful at representing data in continuous domains.",1. Introduction,[0],[0]
"Recently there is increased interest in training generative models to construct more complex, discrete data types such as arithmetic expressions (Kusner & Hernández-Lobato, 2016), source code (Gaunt et al., 2016; Riedel et al., 2016)
",1. Introduction,[0],[0]
*Equal contribution 1Alan Turing Institute 2University of Warwick 3University of Cambridge.,1. Introduction,[0],[0]
"Correspondence to: <mkusner@turing.ac.uk>, <bpaige@turing.ac.uk>, <jmh233@cam.ac.uk>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
and molecules (Gómez-Bombarelli et al., 2016b).
",1. Introduction,[0],[0]
"To train generative models for these tasks, these objects are often first represented as strings.",1. Introduction,[0],[0]
"This is in large part due to the fact that there exist powerful models for text sequence modeling such as Long Short Term Memory networks (LSTMs) (Hochreiter & Schmidhuber, 1997), Gated Recurrent Units (GRUs) (Cho et al., 2014), and Dynamic Convolutional Neural Networks (DCNNs) (Kalchbrenner et al., 2014).",1. Introduction,[0],[0]
"For instance, molecules can be represented by so-called SMILES strings (Weininger, 1988) and GómezBombarelli et al. (2016b) has recently developed a generative model for molecules based on SMILES strings that uses GRUs and DCNNs.",1. Introduction,[0],[0]
"This model is able to encode and decode molecules to and from a continuous latent space, allowing one to search this space for new molecules with desirable properties (Gómez-Bombarelli et al., 2016b).
",1. Introduction,[0],[0]
"However, one immediate difficulty in using strings to represent discrete objects is that the representation is very brittle: small changes in the string can lead to completely different objects, or often do not correspond to valid objects at all.",1. Introduction,[0],[0]
"Specifically, Gómez-Bombarelli et al. (2016b) described that while searching for new molecules, the probabilistic decoder — the distribution which maps from the continuous latent space into the space of molecular structures — would sometimes accidentally put high probability on strings which are not valid SMILES strings or do not encode plausible molecules.
",1. Introduction,[0],[0]
"To address this issue, we propose to directly incorporate knowledge about the structure of discrete data using a grammar.",1. Introduction,[0],[0]
"Grammars exist for a wide variety of discrete domains such as symbolic expressions (Allamanis et al., 2016), standard programming languages such as C (Kernighan et al., 1988), and chemical structures (James et al., 2015).",1. Introduction,[0],[0]
"For instance the set of syntactically valid SMILES strings is described using a context free grammar, which can be used for parsing and validation1.
",1. Introduction,[0],[0]
"Given a grammar, every valid discrete object can be described as a parse tree from the grammar.",1. Introduction,[0],[0]
"Thus, we propose the grammar variational autoencoder (GVAE) which encodes and decodes directly from and to these parse trees.",1. Introduction,[0],[0]
"Generating parse trees as opposed to strings ensures that
1http://opensmiles.org/spec/open-smiles-2-grammar.html
all outputs are valid based on the grammar.",1. Introduction,[0],[0]
"This frees the GVAE from learning syntactic rules and allows it to wholly focus on learning other ‘semantic’ properties.
",1. Introduction,[0],[0]
We demonstrate the GVAE on two tasks for generating discrete data: 1) generating simple arithmetic expressions and 2) generating valid molecules.,1. Introduction,[0],[0]
"We show not only does our model produce a higher proportion of valid outputs than a character based autoencoder, it also produces smoother latent representations.",1. Introduction,[0],[0]
"We also show that this learned latent space is effective for searching for arithmetic expressions that fit data, for finding better drug-like molecules, and for making accurate predictions about target properties.",1. Introduction,[0],[0]
We wish to learn both an encoder and a decoder for mapping data x to and from values z in a continuous space.,2.1. Variational autoencoder,[0],[0]
"The variational autoencoder (Kingma & Welling, 2014; Rezende et al., 2014) provides a formulation in which the encoding z is interpreted as a latent variable in a probabilistic generative model; a probabilistic decoder is defined by a likelihood function p
✓ (x|z) and parameterized by ✓.",2.1. Variational autoencoder,[0],[0]
"Alongside a prior distribution p(z) over the latent variables, the posterior distribution p
✓ (z|x) / p(z)p ✓ (x|z) can then be interpreted as a probabilistic encoder.
",2.1. Variational autoencoder,[0],[0]
"To admit efficient inference, the variational Bayes approach simultaneously learns both the parameters of p
✓ (x|z) as well as those of a posterior approximation q
(z|x).",2.1. Variational autoencoder,[0],[0]
"This is achieved by maximizing the evidence lower bound (ELBO)
",2.1. Variational autoencoder,[0],[0]
"L( , ✓;x) = E q (z|x)",2.1. Variational autoencoder,[0],[0]
"[log p✓(x, z) log q (z|x)] , (1)
with L( , ✓;x)  log p ✓ (x).",2.1. Variational autoencoder,[0],[0]
"So long as p ✓ (x|z) and q
(z|x) can be computed pointwise, and are differentiable with respect to their parameters, the ELBO can be maximized via gradient descent; this allows wide flexibility in choice of encoder and decoder models.",2.1. Variational autoencoder,[0],[0]
Typically these will take the form of exponential family distributions whose parameters are the weights of a multi-layer neural network.,2.1. Variational autoencoder,[0],[0]
"A context-free grammar (CFG) is traditionally defined as a 4-tuple G = (V,⌃, R, S): V is a finite set of non-terminal symbols; the alphabet ⌃ is a finite set of terminal symbols, disjoint from V ; R is a finite set of production rules; and S is a distinct non-terminal known as the start symbol.",2.2. Context-free grammars,[0],[0]
The rules R are formally described as ↵ !,2.2. Context-free grammars,[0],[0]
"for ↵ 2 V and 2 (V [ ⌃)⇤, with ⇤ denoting the Kleene closure.",2.2. Context-free grammars,[0],[0]
"In practice, these rules are defined as a set of mappings from a single left-hand side non-terminal in V to a sequence of terminal and/or non-terminal symbols, and can be interpreted as ‘replacement’ instructions.
",2.2. Context-free grammars,[0],[0]
"Repeatedly applying production rules beginning with a non-terminal symbol defines a tree, with symbols on the right-hand side of the production rule becoming child nodes for the left-hand side parent.",2.2. Context-free grammars,[0],[0]
"The grammar G thus defines a set of possible trees extending from each nonterminal symbol in V , produced by recursively applying rules in R to leaf nodes until all leaf nodes are terminal symbols in ⌃.",2.2. Context-free grammars,[0],[0]
The language of G is the set of all terminal symbol sequences that can be generated as leaf nodes in a tree.,2.2. Context-free grammars,[0],[0]
"Given a string in the language (i.e., a sequence of terminals), a parse tree is a tree rooted at S which has this sequence of terminal symbols as its leaf nodes.",2.2. Context-free grammars,[0],[0]
The ubiquity of context-free languages in computer science is due in part to the presence of efficient parsing algorithms to generate parse trees.,2.2. Context-free grammars,[0],[0]
"For more background on CFGs and automata theory, see e.g. Hopcroft et al. (2006).
",2.2. Context-free grammars,[0],[0]
Our work builds off the work of probabilistic context-free grammars (PCFGs).,2.2. Context-free grammars,[0],[0]
"A PCFG assigns probabilities to each production rule in the grammar, and thus defines a probability distribution over parse trees (Baker, 1979; Booth & Thompson, 1973).",2.2. Context-free grammars,[0],[0]
"A string can be generated by repeatedly sampling and applying production rules, beginning at the start symbol, until no non-terminals remain.",2.2. Context-free grammars,[0],[0]
"Modern approaches allow the probabilities used at each stage to depend on the state of the parse tree (Johnson et al., 2007).",2.2. Context-free grammars,[0],[0]
In this section we describe how a grammar can improve variational autoencoders (VAE) for discrete data.,3. Methods,[0],[0]
It will do so by drastically reducing the number of invalid outputs generated from the VAE.,3. Methods,[0],[0]
"We illustrate our approach on molecular data, however it will extend to any descrete data that can be described by a grammar.
",3. Methods,[0],[0]
"One glaring issue with a character-based VAE is that it may frequently map latent points to sequences that are not valid, hoping the VAE will infer from training data what constitutes a valid sequence.",3. Methods,[0],[0]
"Instead of implicitly encouraging the VAE to produce valid sequences, we propose to give the VAE explicit knowledge about how to produce valid sequences.",3. Methods,[0],[0]
We do this by using a grammar for the sequences: given a grammar we can take any valid sequence and parse it into a parse tree.,3. Methods,[0],[0]
A pre-order traversal on this parse tree yields a sequence of production rules.,3. Methods,[0],[0]
Applying these rules in order will yield the original sequence.,3. Methods,[0],[0]
Our approach then will be to learn a VAE that produces sequences of grammar production rules.,3. Methods,[0],[0]
"The benefit is that it is trivial to generate valid sequences of production rules, as the grammar describes the valid set of rules that can be selected at any point during the generation process.",3. Methods,[0],[0]
"Thus, our model is able to focus on learning semantic properties of sequence data without also having to learn syntactic constraints.",3. Methods,[0],[0]
We propose a grammar variational autoencoder (GVAE) that encodes/decodes in the space of grammar production rules.,3.1. An illustrative example,[0],[0]
"We describe how it works with a simple example.
Encoding.",3.1. An illustrative example,[0],[0]
"Consider a subset of the SMILES grammar as shown in Figure 1, box 1 .",3.1. An illustrative example,[0],[0]
These are the possible production rules that can be used for constructing a molecule.,3.1. An illustrative example,[0],[0]
Imagine we are given as input the SMILES string for benzene: ‘c1ccccc1’.,3.1. An illustrative example,[0],[0]
"Figure 1, box 3 shows this molecule.",3.1. An illustrative example,[0],[0]
To encode this molecule into a continuous latent representation we begin by using the SMILES grammar to parse this string into a parse tree (partially shown in box 2 ).,3.1. An illustrative example,[0],[0]
This tree describes how ‘c1ccccc1’ is generated by the grammar.,3.1. An illustrative example,[0],[0]
"We decompose this tree into a sequence of production rules by performing a pre-order traversal on the branches of the parse tree from left-to-right, shown in box 4 .",3.1. An illustrative example,[0],[0]
"We convert these rules into 1-hot indicator vectors, where each dimension corresponds to a rule in the SMILES grammar, box 5 .",3.1. An illustrative example,[0],[0]
"These 1-hot vectors are concatenated into the rows of a matrix X of dimension T (X)⇥K, where K is the number of production rules in the SMILES grammar, and T (X) is the number of production rules used to generate X.
We use a deep convolutional neural network to map the collection of 1-hot vectors X to a continuous latent vector z.",3.1. An illustrative example,[0],[0]
"The architecture of the encoding network is described in the supplementary material.
",3.1. An illustrative example,[0],[0]
Decoding.,3.1. An illustrative example,[0],[0]
We now describe how we map continuous vectors back to a sequence of production rules (and thus SMILES strings).,3.1. An illustrative example,[0],[0]
"Crucially we construct the decoder so that, at any time while we are decoding a sequence, the decoder will only be allowed to select a subset of production rules that are ‘valid’.",3.1. An illustrative example,[0],[0]
"This will cause the decoder to only produce valid parse sequences from the grammar.
",3.1. An illustrative example,[0],[0]
"We begin by passing the continuous vector z through a recurrent neural network which produces a set of unnormalized log probability vectors (or ‘logits’), shown in Figure 2, box 1 and 2 .",3.1. An illustrative example,[0],[0]
"Exactly like the 1-hot vectors produced by the encoder, each dimension of the logit vectors cor-
responds to a production rule in the grammar.",3.1. An illustrative example,[0],[0]
"We can again write these collection of logit vectors as a matrix F 2 RTmax⇥K , where T
max is the maximum number of timesteps (production rules) allowed by the decoder.",3.1. An illustrative example,[0],[0]
"During the rest of the decoding operations, we will use the rows of F to select a sequence of valid production rules.
",3.1. An illustrative example,[0],[0]
"To ensure that any sequence of production rules generated from the decoder is valid, we keep track of the state of the parsing using a last-in first-out (LIFO) stack.",3.1. An illustrative example,[0],[0]
"This is shown in Figure 2, box 3 .",3.1. An illustrative example,[0],[0]
"At the beginning, every valid parse from the grammar must start with the start symbol: smiles, which is placed on the stack.",3.1. An illustrative example,[0],[0]
"Next we pop off whatever non-terminal symbol that was placed last on the stack (in this case smiles), and we use it to mask out the invalid dimensions of the current logit vector.",3.1. An illustrative example,[0],[0]
"Formally, for every non-terminal ↵ we define a fixed binary mask vector m
↵ 2 [0, 1]K .",3.1. An illustrative example,[0],[0]
"This takes the value ‘1’ for all indices in 1, . . .",3.1. An illustrative example,[0],[0]
",K corresponding to production rules that have ↵ on their left-hand-side.
",3.1. An illustrative example,[0],[0]
"In the previous example, the only production rule in the grammar beginning with smiles is the first so we maskout every dimension except the first, shown in Figure 2, box 4 .",3.1. An illustrative example,[0],[0]
"We then sample from the remaining unmasked rules, using their values in the logit vector.",3.1. An illustrative example,[0],[0]
"To sample from this masked logit at any timestep t we form the following masked distribution:
p(x t = k|↵, z) = m↵,k exp(ftk)P K
j=1 m↵,k exp(ftj) , (2)
where f tk is the (t, k)-element of the logit matrix F. As only the first rule is unmasked we will select this rule smiles !",3.1. An illustrative example,[0],[0]
"chain as the first rule in our sequence, box 5 .",3.1. An illustrative example,[0],[0]
"Now the next rule must begin with chain, so we push it onto the stack (Figure 2, box 3 ).",3.1. An illustrative example,[0],[0]
"We sample this nonterminal and, as before, use it to mask out all of the rules that cannot be applied in the current logit vector.",3.1. An illustrative example,[0],[0]
We then sample a valid rule from this logit vector: chain!,3.1. An illustrative example,[0],[0]
"chain, branched atom.",3.1. An illustrative example,[0],[0]
"Just as before we push the non-terminals on the right-hand side of this rule onto the stack, adding the individual non-terminals in from right to left, such that the leftmost non-terminal is on the top of the stack.",3.1. An illustrative example,[0],[0]
"For the
Algorithm 1 Sampling from the decoder Input: Deterministic decoder output F 2 RTmax⇥K ,
masks m ↵ for each production rule ↵ Output: Sampled productions X from p(X|z)
1: Initialize empty stack S , and push the start symbol S onto the top; set t = 0 2: while S is nonempty do 3:",3.1. An illustrative example,[0],[0]
"Pop the last-pushed non-terminal ↵ from the stack S 4: Use Eq. (2) to sample a production rule R 5: Let x
t be the 1-hot vector corresponding to R 6: Let RHS(R) denote all non-terminals on the righthand side of rule R, ordered from right to left 7: for non-terminal in RHS(R) do 8: Push on to the stack S 9: end for
10: Set X [X>,x t ]",3.1. An illustrative example,[0],[0]
"> 11: Set t t+ 1 12: end while
next state we again pop the last rule placed on the stack and mask the current logit, etc.",3.1. An illustrative example,[0],[0]
"This process continues until the stack is empty or we reach the maximum number of logit vectors T
max .",3.1. An illustrative example,[0],[0]
We describe this decoding procedure formally in Algorithm 1.,3.1. An illustrative example,[0],[0]
"In practice, because sampling from the decoder often finishes before t reaches T
max , we introduce an additional ‘no-op’ rule to the grammar that we use to pad X until the number of rows equals T
max
.
",3.1. An illustrative example,[0],[0]
We note the explicit connection between the process in Algorithm 1 and parsing algorithms for pushdown automata.,3.1. An illustrative example,[0],[0]
"A pushdown automaton is a finite state machine which has access to a single stack for long-term storage, and are equivalent to context-free grammars in the sense that every CFG can be converted into a pushdown automaton, and vice-versa (Hopcroft et al., 2006).",3.1. An illustrative example,[0],[0]
"The decoding algorithm performs the sequence of actions taken by a nondeterministic pushdown automaton at each stage of a parsing algorithm; the nondeterminism is resolved by sampling according to the probabilities in the emitted logit vector.
Contrasting the character VAE.",3.1. An illustrative example,[0],[0]
"Notice that the key difference between this grammar VAE decoder and a
character-based VAE decoder is that at every point in the generated sequence, the character VAE can sample any possible character.",3.1. An illustrative example,[0],[0]
There is no stack or masking operation.,3.1. An illustrative example,[0],[0]
"The grammar VAE however is constrained to select syntactically-valid sequences.
",3.1. An illustrative example,[0],[0]
Syntactic vs. semantic validity.,3.1. An illustrative example,[0],[0]
It is important to note that the grammar encodes syntactically valid molecules but not necessarily semantically valid molecules.,3.1. An illustrative example,[0],[0]
This is mainly because of three reasons.,3.1. An illustrative example,[0],[0]
"First, certain molecules produced by the grammar may be very unstable molecules or not chemically-valid (for instance an oxygen atom cannot bond to 3 other atoms as it only has 2 free electrons for bonding, although it would be possible to generate this in a molecule from the grammar).",3.1. An illustrative example,[0],[0]
"Second, the SMILES language has non-context free aspects, e.g. a ringbond must be opened and closed by the same digit, starting with ‘1’ (as is the case for benzene ‘c1ccccc1’).",3.1. An illustrative example,[0],[0]
"The particular challenge for matching digits, in contrast to matching grouping symbols such as parentheses, is that they do not compose in a nested manner; for example, ‘C12(CCCCC1)CCCCC2’ is a valid molecule.",3.1. An illustrative example,[0],[0]
Keeping track of which digit to use for each ringbond is not context-free.,3.1. An illustrative example,[0],[0]
"Third, we note that the GVAE can output an undetermined sequence if there are still non-terminal symbols on the stack after processing all T max
logit vectors.",3.1. An illustrative example,[0],[0]
"While this could be fixed by a procedure that converts these non-terminals to terminals, for simplicity we mark these sequences as invalid.",3.1. An illustrative example,[0],[0]
"During training, each input SMILES encoded as a sequence of 1-hot vectors X 2 {0, 1}Tmax⇥K , also defines a sequence of T
max mask vectors.",3.2. Training,[0],[0]
"Each mask at timestep t = 1, . . .",3.2. Training,[0],[0]
", T
max is selected by the left-hand side of the production rule indicated in the 1-hot vector x
t .",3.2. Training,[0],[0]
"Given these masks we can compute the decoder’s mapping
p(X|z)",3.2. Training,[0],[0]
"= T (X)Y
t=1
p(x t |z,x1:(t 1)), (3)
with the individual probabilities at each timestep defined as in Eq. (2).",3.2. Training,[0],[0]
"We pad any remaining timesteps after T (X) up
Algorithm 2 Training the Grammar VAE Input: Dataset {X(i)}N
i=1
Output: Trained VAE model p ✓ (X|z), q (z|X) 1: while VAE not converged do 2: Select element: X 2 {X(i)}N
i=1 (or minibatch) 3:",3.2. Training,[0],[0]
"Encode: z ⇠ q
(z|X) 4: Decode: given z, compute logits F 2 RTmax⇥K 5: for t in [1, . . .",3.2. Training,[0],[0]
", T
max ] do 6: Compute p
✓
(x
t |z) via Eq.",3.2. Training,[0],[0]
"(2), with mask m x
t
and logits f t
7: end for 8: Update ✓, using estimates p
✓
(X|z), q (z|X), via gradient descent on the ELBO in Eq.",3.2. Training,[0],[0]
"(4)
9: end while
to T max with a ‘no-op’ rule, a one-hot vector indicating the parse tree is complete and no actions are to be taken.
",3.2. Training,[0],[0]
"In all our experiments, q(z|X) is a Gaussian distribution whose mean and variance parameters are the output of the encoder network, with an isotropic Gaussian prior p(z)",3.2. Training,[0],[0]
"= N (0, I)",3.2. Training,[0],[0]
.,3.2. Training,[0],[0]
"At training time, we sample a value of z from q(z|X) to compute the ELBO
L( , ✓;X) = E q (z|X)",3.2. Training,[0],[0]
"[log p✓(X, z) log q (z|X)] .",3.2. Training,[0],[0]
"(4)
Following Kingma & Welling (2014), we apply a noncentered parameterization on the encoding Gaussian distribution and optimize Eq.",3.2. Training,[0],[0]
"(4) using gradient descent, learning encoder and decoder neural network parameters and ✓.",3.2. Training,[0],[0]
Algorithm 2 summarizes the training procedure.,3.2. Training,[0],[0]
We show the usefulness of our proposed grammar variational autoencoder (GVAE)2 on two sequence optimization problems: 1) searching for an arithmetic expression that best fits a dataset and 2) finding new drug molecules.,4. Experiments,[0],[0]
"We begin by showing the latent space of the GVAE and a character variational autoencoder (CVAE), similar to that of Gómez-Bombarelli et al. (2016b)3, on each of the problems.",4. Experiments,[0],[0]
"We demonstrate that the GVAE learns a smooth, meaningful latent space for arithmetic equations and molecules.",4. Experiments,[0],[0]
"Given this we perform optimization in this latent space using Bayesian optimization, inspired by the technique of Gómez-Bombarelli et al. (2016b).",4. Experiments,[0],[0]
"We demonstrate that the GVAE improves upon a previous character variational autoencoder, by selecting an arithmetic expression that matches the data nearly perfectly, and by finding novel molecules with better drug properties.
2Code available at: https://github.com/mkusner/grammarVAE 3https://github.com/maxhodak/keras-molecules",4. Experiments,[0],[0]
We describe in detail the two sequence optimization problems we seek to solve.,4.1. Problems,[0],[0]
The first consists in optimizing the fit of an arithmetic expression.,4.1. Problems,[0],[0]
"We are given a set of 100,000 randomly generated univariate arithmetic expressions from the following grammar:
S !",4.1. Problems,[0],[0]
S ‘+ ’ T | S ‘⇤ ’ T | S ‘ / ’ T | T T !,4.1. Problems,[0],[0]
‘ ( ’ S ‘ ) ’,4.1. Problems,[0],[0]
| ‘ s i n ( ’ S ‘ ) ’,4.1. Problems,[0],[0]
| ‘ exp ( ’ S ‘ ) ’ T !,4.1. Problems,[0],[0]
"‘x ’ | ‘1 ’ | ‘2 ’ | ‘3 ’
where S and T are non-terminals and the symbol | separates the possible production rules generated from each non-terminal.",4.1. Problems,[0],[0]
"By parsing this grammar we can randomly generate strings of univariate arithmetic equations (functions of x) such as the following: sin(2), x/(3+ 1), 2+ x+ sin(1/2), and x/2 ⇤ exp(x)/exp(2 ⇤ x).",4.1. Problems,[0],[0]
We limit the length of every selected string to have at most 15 production rules.,4.1. Problems,[0],[0]
Given this dataset we train both the CVAE and GVAE to learn a latent space of arithmetic expressions.,4.1. Problems,[0],[0]
We propose to perform optimization in this latent space of expressions to find an expression that best fits a fixed dataset.,4.1. Problems,[0],[0]
A common measure of best fit is the test MSE between the predictions made by a selected expression and the true data.,4.1. Problems,[0],[0]
"In the generated expressions, the presence of exponential functions can result in very large MSE values.",4.1. Problems,[0],[0]
"For this reason, we use as target variable log(1 + MSE) instead of MSE.
",4.1. Problems,[0],[0]
"For the second optimization problem, we follow (GómezBombarelli et al., 2016b) and optimize the drug properties of molecules.",4.1. Problems,[0],[0]
"Our goal is to maximize the water-octanol partition coefficient (logP), an important metric in drug design that characterizes the drug-likeness of a molecule.",4.1. Problems,[0],[0]
"As in Gómez-Bombarelli et al. (2016b) we consider a penalized logP score that takes into account other molecular properties such as ring size and synthetic accessibility (Ertl & Schuffenhauer, 2009).",4.1. Problems,[0],[0]
"The training data for the CVAE and GVAE models are 250,000 SMILES strings (Weininger, 1988) extracted at random from the ZINC database by Gómez-Bombarelli et al. (2016b).",4.1. Problems,[0],[0]
We describe the context-free grammar for SMILES strings that we use to train our GVAE in the supplementary material.,4.1. Problems,[0],[0]
Arithmetic expressions.,4.2. Visualizing the latent space,[0],[0]
"To qualitatively evaluate the smoothness of the VAE embeddings for arithmetic expressions, we attempt interpolating between two arithmetic expressions, as in Bowman et al. (2016).",4.2. Visualizing the latent space,[0],[0]
This is done by encoding two equations and then performing linear interpolation in the latent space.,4.2. Visualizing the latent space,[0],[0]
Results comparing the character and grammar VAEs are shown in Table 1.,4.2. Visualizing the latent space,[0],[0]
"Although the character VAE smoothly interpolates between the text representation of equations, it passes through intermediate points which do not decode to valid equations.",4.2. Visualizing the latent space,[0],[0]
"In contrast, the grammar VAE also provides smooth interpolation and produces valid equations for any location in the latent space.",4.2. Visualizing the latent space,[0],[0]
"A further exploration of a 2-dimensional latent space is shown in the appendix.
Molecules.",4.2. Visualizing the latent space,[0],[0]
We are interested if the GVAE produces a coherent latent space of molecules.,4.2. Visualizing the latent space,[0],[0]
To assess this we begin by encoding a molecule.,4.2. Visualizing the latent space,[0],[0]
We then generate 2 random orthogonal unit vectors in latent space (scaled down to only search the neighborhood of the molecules).,4.2. Visualizing the latent space,[0],[0]
Moving in combinations of these directions defines a grid and at each point in the grid we decode the latent vector 1000 times.,4.2. Visualizing the latent space,[0],[0]
We select the molecule that appears most often as the representative molecule.,4.2. Visualizing the latent space,[0],[0]
Figure 3 shows this latent space search surrounding two different molecules.,4.2. Visualizing the latent space,[0],[0]
Compare this to Figures 13-15 in Gómez-Bombarelli et al. (2016b).,4.2. Visualizing the latent space,[0],[0]
"We note that in each plot of the GVAE the latent space is very smooth, in many cases moving from one grid point to another will only change a single atom in a molecule.",4.2. Visualizing the latent space,[0],[0]
"In the CVAE (Gómez-Bombarelli et al., 2016b) we do not observe such fine-grained smoothness.",4.2. Visualizing the latent space,[0],[0]
We now perform a series of experiments using the autoencoders to produce novel sequences with improved properties.,4.3. Bayesian optimization,[0],[0]
"For this, we follow the approach proposed by GómezBombarelli et al. (2016b) and after training the GVAE, we
train an additional model to predict properties of sequences from their latent representation.",4.3. Bayesian optimization,[0],[0]
"To propose promising new sequences, we can start from the latent vector of an encoded sequence and then use the output of this predictor (including its gradient) to move in the latent space direction most likely to improve the property.",4.3. Bayesian optimization,[0],[0]
"The resulting new latent points can then be decoded into corresponding sequences.
",4.3. Bayesian optimization,[0],[0]
"In practice, measuring the property of each new sequence could be an expensive process.",4.3. Bayesian optimization,[0],[0]
"For example, the sequence could represent an organic photovoltaic molecule and the property could be the result of an expensive quantum mechanical simulation used to estimate the molecule’s powerconversion efficiency (Hachmann et al., 2011).",4.3. Bayesian optimization,[0],[0]
The sequence could also represent a program or expression which may be computationally expensive to evaluate.,4.3. Bayesian optimization,[0],[0]
"Therefore, ideally, we would like the optimization process to perform only a reduced number of property evaluations.",4.3. Bayesian optimization,[0],[0]
"For this, we use Bayesian optimization methods, which choose the next point to evaluate by maximizing an acquisition function that quantifies the benefit of evaluating the property at a particular location (Shahriari et al., 2016).
",4.3. Bayesian optimization,[0],[0]
"After training the GVAE, we obtain a latent feature vector for each sequence in the training data, given by the mean of the variational encoding distributions.",4.3. Bayesian optimization,[0],[0]
"We use these vectors and their corresponding property estimates to train a sparse Gaussian process (SGP) model with 500 inducing points (Snelson & Ghahramani, 2005), which is used to make predictions for the properties of new points in latent space.",4.3. Bayesian optimization,[0],[0]
"After training the SGP, we then perform 5 iterations of batch Bayesian optimization using the expected improvement (EI) heuristic (Jones et al., 1998).",4.3. Bayesian optimization,[0],[0]
"On each iteration, we select a batch of 50 latent vectors by sequentially maximizing the EI acquisition function.",4.3. Bayesian optimization,[0],[0]
"We use the Kriging Believer Algorithm to account for pending evaluations in the batch selection process (Cressie, 1990).",4.3. Bayesian optimization,[0],[0]
"That is, after selecting each new data point in the batch, we add that data point as a new inducing point in the sparse GP model with associated target variable equal to the mean of the GP predictive distribution at that point.",4.3. Bayesian optimization,[0],[0]
"Once a new batch of 50 latent vectors is selected, each point in the batch is transformed into its corresponding sequence using the decoder network in the GVAE.",4.3. Bayesian optimization,[0],[0]
The properties of the newly generated sequences are then computed and the resulting data is added to the training set before retraining the SGP and starting the next BO iteration.,4.3. Bayesian optimization,[0],[0]
"Note that some of the new sequences will be invalid and consequently, it will not be possible to obtain their corresponding property estimate.",4.3. Bayesian optimization,[0],[0]
"In this case we fix the property to be equal to the worst value observed in the original training data.
",4.3. Bayesian optimization,[0],[0]
Arithmetic expressions.,4.3. Bayesian optimization,[0],[0]
Our goal is to see if we can find an arithmetic expression that best fits a fixed dataset.,4.3. Bayesian optimization,[0],[0]
"Specifically, we generate this dataset by selecting 1000
input values, x, that are linearly-spaced between 10 and 10.",4.3. Bayesian optimization,[0],[0]
We then pass these through our true function 1/3+ x+,4.3. Bayesian optimization,[0],[0]
sin(x ⇤ x),4.3. Bayesian optimization,[0],[0]
to generate the true target observations.,4.3. Bayesian optimization,[0],[0]
We use Bayesian optimization (BO) as described above search for this equation.,4.3. Bayesian optimization,[0],[0]
We run BO for 5 iterations and average across 10 repetitions of the process.,4.3. Bayesian optimization,[0],[0]
Table 2 (rows 1 & 2) shows the results obtained.,4.3. Bayesian optimization,[0],[0]
The third column in the table reports the fraction of arithmetic sequences found by BO that are valid.,4.3. Bayesian optimization,[0],[0]
The GVAE nearly always finds valid sequences.,4.3. Bayesian optimization,[0],[0]
"The only cases in which it does not is when there are still non-terminals on the stack of
the decoder upon reaching the maximum number of timesteps T
max , however this is rare.",4.3. Bayesian optimization,[0],[0]
"Additionally, the GVAE finds squences with better scores on average when compared with the CVAE.
",4.3. Bayesian optimization,[0],[0]
"Table 3 shows the top 3 expressions found by GVAE and CVAE during the BO search, together with their associated score values.",4.3. Bayesian optimization,[0],[0]
Figure 4 shows how the best expression found by GVAE and CVAE compare to the true function.,4.3. Bayesian optimization,[0],[0]
"We note that the CVAE has failed to find the sinusoidal portion of the true expression, while the difference between the GVAE expression and the true function is negligible.
Molecules.",4.3. Bayesian optimization,[0],[0]
We now consider the problem of finding new drug-like molecules.,4.3. Bayesian optimization,[0],[0]
"We perform 5 iterations of BO, and average results across 10 trials.",4.3. Bayesian optimization,[0],[0]
Table 2 (rows 3 & 4) shows the overall BO results.,4.3. Bayesian optimization,[0],[0]
"In this problem, the GVAE produces about twice more valid sequences than the CVAE.",4.3. Bayesian optimization,[0],[0]
The valid sequences produced by the GVAE also result in higher scores on average.,4.3. Bayesian optimization,[0],[0]
The best found SMILES strings by each method and their scores are shown in Table 4; the molecules themselves are plotted in Figure 5.,4.3. Bayesian optimization,[0],[0]
We now perform a series of experiments to evaluate the predictive performance of the latent representations found by each autoencoder.,4.4. Predictive performance of latent representation,[0],[0]
"For this, we use the sparse GP model used in the previous Bayesian optimization experiments and look at its predictive performance on a left-out test set with 10% of the data, where the data is formed by the latent representation of the available sequences (these are the inputs to the sparse GP model) and the associated properties of those sequences (these are the outputs in the sparse GP model).",4.4. Predictive performance of latent representation,[0],[0]
Table 5 show the average test RMSE and test loglikelihood for the GVAE and the CVAE across 10 different splits of the data for the expressions and for the molecules.,4.4. Predictive performance of latent representation,[0],[0]
This table shows that the GVAE produces latent features that yield much better predictive performance than those produced by the CVAE.,4.4. Predictive performance of latent representation,[0],[0]
"Parse trees have been used to learn continuous representations of text in recursive neural network models (Socher et al., 2013; Irsoy & Cardie, 2014; Paulus et al., 2014).",5. Related Work,[0],[0]
These models learn a vector at every non-terminal in the parse tree by recursively combining the vectors of child nodes.,5. Related Work,[0],[0]
"Recursive autoencoders learn these representations by minimizing the reconstruction error between true child vectors and those predicted by the parent (Socher et al., 2011a;b).",5. Related Work,[0],[0]
"Recently, Allamanis et al. (2016) learn representations for symbolic expressions from their parse trees.",5. Related Work,[0],[0]
"Importantly, all of these methods are discriminative and do not learn a generative latent space.",5. Related Work,[0],[0]
"Like our decoder, re-
current neural network grammars (Dyer et al., 2016) produce sequences through a linear traversal of the parse tree, but focus on the case where the underlying grammar is unknown and not context-free.",5. Related Work,[0],[0]
Maddison & Tarlow (2014) describe generative models of natural source code based on probabilistic context free grammars and neuro-probabilistic language models.,5. Related Work,[0],[0]
"However, these works are not geared towards learning a latent representation of the data.
",5. Related Work,[0],[0]
"Learning arithmetic expressions to fit data, often called symbolic regression, are generally based on genetic programming (Willis et al., 1997) or other computationally demanding evolutionary algorithms to propose candidate expressions (Schmidt & Lipson, 2009).",5. Related Work,[0],[0]
"Alternatives include running particle MCMC inference to estimate a Bayesian posterior over parse trees (Perov & Wood, 2016).
",5. Related Work,[0],[0]
"In molecular design, searching for new molecules is traditionally done by sifting through large databases of potential molecules and then subjecting them to a virtual screening process (Pyzer-Knapp et al., 2015; Gómez-Bombarelli et al., 2016a).",5. Related Work,[0],[0]
"These databases are too large to search via exhaustive enumeration, and require novel stochastic search algorithms tailored to the domain (Virshup et al., 2013; Rupakheti et al., 2015).",5. Related Work,[0],[0]
"Segler et al. (2017) fit a recurrent neural network to chemicals represented by SMILES strings, however their goal is more akin to density estimation; they learn a simulator which can sample proposals for novel molecules, but it is not otherwise used as part of an optimization or inference process itself.",5. Related Work,[0],[0]
"Our work most closely resembles Gómez-Bombarelli et al. (2016b) for novel molecule synthesis, in that we also learn a latent variable model which admits a continuous representation of the domain.",5. Related Work,[0],[0]
"However, both Segler et al. (2017) and Gómez-Bombarelli et al. (2016b) use character-level models for molecules.",5. Related Work,[0],[0]
"Empirically, it is clear that representing molecules and equations by way of their parse tree generated from a grammar outperforms text-based representations.",6. Discussion,[0],[0]
"We believe this approach will be broadly useful for representation learning, inference, and optimization in any domain which can be represented as text in a context-free language.",6. Discussion,[0],[0]
This work was supported by The Alan Turing Institute under the EPSRC grant EP/N510129/1.,Acknowledgements,[0],[0]
"Deep generative models have been wildly successful at learning coherent latent representations for continuous data such as natural images, artwork, and audio.",abstractText,[0],[0]
"However, generative modeling of discrete data such as arithmetic expressions and molecular structures still poses significant challenges.",abstractText,[0],[0]
"Crucially, state-of-the-art methods often produce outputs that are not valid.",abstractText,[0],[0]
"We make the key observation that frequently, discrete data can be represented as a parse tree from a context-free grammar.",abstractText,[0],[0]
"We propose a variational autoencoder which directly encodes from and decodes to these parse trees, ensuring the generated outputs are always syntactically valid.",abstractText,[0],[0]
"Surprisingly, we show that not only does our model more often generate valid outputs, it also learns a more coherent latent space in which nearby points decode to similar discrete outputs.",abstractText,[0],[0]
We demonstrate the effectiveness of our learned models by showing their improved performance in Bayesian optimization for symbolic regression and molecule generation.,abstractText,[0],[0]
Grammar Variational Autoencoder,title,[0],[0]
"Neural machine translation (NMT) is one of success stories of deep learning in natural language processing, with recent NMT systems outperforming traditional phrase-based approaches on many language pairs (Sennrich et al., 2016a).",1 Introduction,[0],[0]
"State-ofthe-art NMT systems rely on sequential encoderdecoders (Sutskever et al., 2014; Bahdanau et al., 2015) and lack any explicit modeling of syntax or any hierarchical structure of language.",1 Introduction,[0],[0]
"One potential reason for why we have not seen much benefit from using syntactic information in NMT is the lack of simple and effective methods for incorporating structured information in neural encoders,
including RNNs.",1 Introduction,[0],[0]
"Despite some successes, techniques explored so far either incorporate syntactic information in NMT models in a relatively indirect way (e.g., multi-task learning (Luong et al., 2015a; Nadejde et al., 2017; Eriguchi et al., 2017; Hashimoto and Tsuruoka, 2017)) or may be too restrictive in modeling the interface between syntax and the translation task (e.g., learning representations of linguistic phrases (Eriguchi et al., 2016)).",1 Introduction,[0],[0]
"Our goal is to provide the encoder with access to rich syntactic information but let it decide which aspects of syntax are beneficial for MT, without placing rigid constraints on the interaction between syntax and the translation task.",1 Introduction,[0],[0]
"This goal is in line with claims that rigid syntactic constraints typically hurt MT (Zollmann and Venugopal, 2006; Smith and Eisner, 2006; Chiang, 2010), and, though these claims have been made in the context of traditional MT systems, we believe they are no less valid for NMT.
",1 Introduction,[0],[0]
"Attention-based NMT systems (Bahdanau et al., 2015; Luong et al., 2015b) represent source sentence words as latent-feature vectors in the encoder and use these vectors when generating a translation.",1 Introduction,[0],[0]
"Our goal is to automatically incorporate information about syntactic neighborhoods of source words into these feature vectors, and, thus, potentially improve quality of the translation output.",1 Introduction,[0],[0]
"Since vectors correspond to words, it is natural for us to use dependency syntax.",1 Introduction,[0],[0]
"Dependency trees (see Figure 1) represent syntactic relations between words: for example, monkey is a subject of the predicate eats, and banana is its object.
",1 Introduction,[0],[0]
"In order to produce syntax-aware feature representations of words, we exploit graphconvolutional networks (GCNs) (Duvenaud et al., 2015; Defferrard et al., 2016; Kearnes et al., 2016; Kipf and Welling, 2016).",1 Introduction,[0],[0]
"GCNs can be regarded as computing a latent-feature representation of a node (i.e. a real-valued vector) based on its k-
1957 Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1957–1967
Copenhagen, Denmark, September 7–11, 2017.",1 Introduction,[0],[0]
"c©2017 Association for Computational Linguistics
th order neighborhood (i.e. nodes at most k hops aways from the node) (Gilmer et al., 2017).",1 Introduction,[0],[0]
They are generally simple and computationally inexpensive.,1 Introduction,[0],[0]
"We use Syntactic GCNs, a version of GCN operating on top of syntactic dependency trees, recently shown effective in the context of semantic role labeling (Marcheggiani and Titov, 2017).
",1 Introduction,[0],[0]
"Since syntactic GCNs produce representations at word level, it is straightforward to use them as encoders within the attention-based encoderdecoder framework.",1 Introduction,[0],[0]
"As NMT systems are trained end-to-end, GCNs end up capturing syntactic properties specifically relevant to the translation task.",1 Introduction,[0],[0]
"Though GCNs can take word embeddings as input, we will see that they are more effective when used as layers on top of recurrent neural network (RNN) or convolutional neural network (CNN) encoders (Gehring et al., 2016), enriching their states with syntactic information.",1 Introduction,[0],[0]
"A comparison to RNNs is the most challenging test for GCNs, as it has been shown that RNNs (e.g., LSTMs) are able to capture certain syntactic phenomena (e.g., subject-verb agreement) reasonably well on their own, without explicit treebank supervision (Linzen et al., 2016; Shi et al., 2016).",1 Introduction,[0],[0]
"Nevertheless, GCNs appear beneficial even in this challenging set-up: we obtain +1.2 and +0.7 BLEU point improvements from using syntactic GCNs on top of bidirectional RNNs for EnglishGerman and English-Czech, respectively.
",1 Introduction,[0],[0]
"In principle, GCNs are flexible enough to incorporate any linguistic structure as long as they can be represented as graphs (e.g., dependency-based semantic-role labeling representations (Surdeanu et al., 2008), AMR semantic graphs (Banarescu et al., 2012) and co-reference chains).",1 Introduction,[0],[0]
"For example, unlike recursive neural networks (Socher et al., 2013), GCNs do not require the graphs to be trees.",1 Introduction,[0],[0]
"However, in this work we solely focus on dependency syntax and leave more general investigation for future work.
",1 Introduction,[0],[0]
"Our main contributions can be summarized as follows:
• we introduce a method for incorporating structure into NMT using syntactic GCNs;
• we show that GCNs can be used along with RNN and CNN encoders;
• we show that incorporating structure is beneficial for machine translation on EnglishCzech and English-German.",1 Introduction,[0],[0]
Notation.,2 Background,[0],[0]
"We use x for vectors, x1:t for a sequence of t vectors, and X for matrices.",2 Background,[0],[0]
The i-th value of vector x is denoted by xi.,2 Background,[0],[0]
We use ◦ for vector concatenation.,2 Background,[0],[0]
"In NMT (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014b), given example translation pairs from a parallel corpus, a neural network is trained to directly estimate the conditional distribution p(y1:Ty |x1:Tx) of translating a source sentence",2.1 Neural Machine Translation,[0],[0]
x1:,2.1 Neural Machine Translation,[0],[0]
Tx (a sequence of Tx words) into a target sentence y1:Ty .,2.1 Neural Machine Translation,[0],[0]
"NMT models typically consist of an encoder, a decoder and some method for conditioning the decoder on the encoder, for example, an attention mechanism.",2.1 Neural Machine Translation,[0],[0]
We will now briefly describe the components that we use in this paper.,2.1 Neural Machine Translation,[0],[0]
An encoder is a function that takes as input the source sentence and produces a representation encoding its semantic content.,2.1.1 Encoders,[0],[0]
"We describe recurrent, convolutional and bag-of-words encoders.
",2.1.1 Encoders,[0],[0]
Recurrent.,2.1.1 Encoders,[0],[0]
"Recurrent neural networks (RNNs) (Elman, 1990) model sequential data.",2.1.1 Encoders,[0],[0]
They receive one input vector at each time step and update their hidden state to summarize all inputs up to that point.,2.1.1 Encoders,[0],[0]
"Given an input sequence x1:Tx = x1,x2, . . .",2.1.1 Encoders,[0],[0]
",xTx of word embeddings an RNN is defined recursively as follows:
",2.1.1 Encoders,[0],[0]
"RNN(x1:t) = f(xt,RNN(x1:t−1))
where f is a nonlinear function such as an LSTM (Hochreiter and Schmidhuber, 1997) or a GRU (Cho et al., 2014b).",2.1.1 Encoders,[0],[0]
"We will use the function RNN as an abstract mapping from an input sequence x1:T to final hidden state RNN(x1:Tx), regardless of the used nonlinearity.",2.1.1 Encoders,[0],[0]
"To not only summarize the past of a word, but also its future, a bidirectional RNN (Schuster and Paliwal, 1997; Irsoy and
Cardie, 2014) is often used.",2.1.1 Encoders,[0],[0]
"A bidirectional RNN reads the input sentence in two directions and then concatenates the states for each time step:
BIRNN(x1:Tx , t) = RNNF (x1:t)◦RNNB(xTx:t)
where RNNF and RNNB are the forward and backward RNNs, respectively.",2.1.1 Encoders,[0],[0]
"For further details we refer to the encoder of Bahdanau et al. (2015).
Convolutional.",2.1.1 Encoders,[0],[0]
"Convolutional Neural Networks (CNNs) apply a fixed-size window over the input sequence to capture the local context of each word (Gehring et al., 2016).",2.1.1 Encoders,[0],[0]
"One advantage of this approach over RNNs is that it allows for fast parallel computation, while sacrificing non-local context.",2.1.1 Encoders,[0],[0]
"To remedy the loss of context, multiple CNN layers can be stacked.",2.1.1 Encoders,[0],[0]
"Formally, given an input sequence x1:Tx , we define a CNN as follows:
",2.1.1 Encoders,[0],[0]
"CNN(x1:Tx , t) = f(xt−bw/2c, ..,xt, ..,xt+bw/2c)
where f is a nonlinear function, typically a linear transformation followed by ReLU, andw is the size of the window.
",2.1.1 Encoders,[0],[0]
Bag-of-Words.,2.1.1 Encoders,[0],[0]
In a bag-of-words (BoW) encoder every word is simply represented by its word embedding.,2.1.1 Encoders,[0],[0]
"To give the decoder some sense of word position, position embeddings (PE) may be added.",2.1.1 Encoders,[0],[0]
"There are different strategies for defining position embeddings, and in this paper we choose to learn a vector for each absolute word position up to a certain maximum length.",2.1.1 Encoders,[0],[0]
"We then represent the t-th word in a sequence as follows:
BOW(x1:Tx , t) = xt + pt
where xt is the word embedding and pt is the t-th position embedding.",2.1.1 Encoders,[0],[0]
A decoder produces the target sentence conditioned on the representation of the source sentence induced by the encoder.,2.1.2 Decoder,[0],[0]
"In Bahdanau et al. (2015) the decoder is implemented as an RNN conditioned on an additional input ci, the context vector, which is dynamically computed at each time step using an attention mechanism.
",2.1.2 Decoder,[0],[0]
"The probability of a target word yi is now a function of the decoder RNN state, the previous target word embedding, and the context vector.",2.1.2 Decoder,[0],[0]
The model is trained end-to-end for maximum log likelihood of the next target word given its context.,2.1.2 Decoder,[0],[0]
We will now describe the Graph Convolutional Networks (GCNs) of Kipf and Welling (2016).,2.2 Graph Convolutional Networks,[0],[0]
"For a comprehensive overview of alternative GCN architectures see Gilmer et al. (2017).
",2.2 Graph Convolutional Networks,[0],[0]
"A GCN is a multilayer neural network that operates directly on a graph, encoding information about the neighborhood of a node as a realvalued vector.",2.2 Graph Convolutional Networks,[0],[0]
"In each GCN layer, information flows along edges of the graph; in other words, each node receives messages from all its immediate neighbors.",2.2 Graph Convolutional Networks,[0],[0]
"When multiple GCN layers are stacked, information about larger neighborhoods gets integrated.",2.2 Graph Convolutional Networks,[0],[0]
"For example, in the second layer, a node will receive information from its immediate neighbors, but this information already includes information from their respective neighbors.",2.2 Graph Convolutional Networks,[0],[0]
"By choosing the number of GCN layers, we regulate the distance the information travels: with k layers a node receives information from neighbors at most k hops away.
",2.2 Graph Convolutional Networks,[0],[0]
"Formally, consider an undirected graph G = (V, E), where V is a set of n nodes, and E is a set of edges.",2.2 Graph Convolutional Networks,[0],[0]
"Every node is assumed to be connected to itself, i.e. ∀v ∈ V : (v, v) ∈ E .",2.2 Graph Convolutional Networks,[0],[0]
"Now, let X ∈ Rd×n be a matrix containing all n nodes with their features, where d is the dimensionality of the feature vectors.",2.2 Graph Convolutional Networks,[0],[0]
"In our case, X will contain word embeddings, but in general it can contain any kind of features.",2.2 Graph Convolutional Networks,[0],[0]
"For a 1-layer GCN, the new node representations are computed as follows:
hv = ρ ( ∑ u∈N (v) Wxu + b )
where W ∈ Rd×d is a weight matrix and b ∈ Rd a bias vector.1 ρ is an activation function, e.g. a ReLU.N (v) is the set of neighbors of v, which we assume here to always include v itself.",2.2 Graph Convolutional Networks,[0],[0]
"As stated before, to allow information to flow over multiple hops, we need to stack GCN layers.",2.2 Graph Convolutional Networks,[0],[0]
"The recursive computation is as follows:
h(j+1)v = ρ",2.2 Graph Convolutional Networks,[0],[0]
"( ∑ u∈N (v) W (j)h(j)u + b (j) )
where j indexes the layer, and h(0)v = xv.
1We dropped the normalization factor used by Kipf and Welling (2016), as it is not used in syntactic GCNs of Marcheggiani and Titov (2017).",2.2 Graph Convolutional Networks,[0],[0]
Marcheggiani and Titov (2017) generalize GCNs to operate on directed and labeled graphs.2,2.3 Syntactic GCNs,[0],[0]
"This makes it possible to use linguistic structures such as dependency trees, where directionality and edge labels play an important role.",2.3 Syntactic GCNs,[0],[0]
They also integrate edge-wise gates which let the model regulate contributions of individual dependency edges.,2.3 Syntactic GCNs,[0],[0]
"We will briefly describe these modifications.
Directionality.",2.3 Syntactic GCNs,[0],[0]
"In order to deal with directionality of edges, separate weight matrices are used for incoming and outgoing edges.",2.3 Syntactic GCNs,[0],[0]
"We follow the convention that in dependency trees heads point to their dependents, and thus outgoing edges are used for head-to-dependent connections, and incoming edges are used for dependent-to-head connections.",2.3 Syntactic GCNs,[0],[0]
"Modifying the recursive computation for directionality, we arrive at:
h(j+1)v = ρ",2.3 Syntactic GCNs,[0],[0]
"( ∑ u∈N (v) W (j) dir(u,v) h (j) u + b",2.3 Syntactic GCNs,[0],[0]
"(j) dir(u,v) )
",2.3 Syntactic GCNs,[0],[0]
"where dir(u, v) selects the weight matrix associated with the directionality of the edge connecting u and v (i.e. WIN for u-to-v, WOUT for v-to-u, and WLOOP for v-to-v).",2.3 Syntactic GCNs,[0],[0]
"Note that self loops are modeled separately,
so there are now three times as many parameters as in a non-directional GCN.
2For",2.3 Syntactic GCNs,[0],[0]
"an alternative approach to integrating labels and directions, see applications of GCNs to statistical relation learning (Schlichtkrull et al., 2017).
",2.3 Syntactic GCNs,[0],[0]
Labels.,2.3 Syntactic GCNs,[0],[0]
Making the GCN sensitive to labels is straightforward given the above modifications for directionality.,2.3 Syntactic GCNs,[0],[0]
"Instead of using separate matrices for each direction, separate matrices are now defined for each direction and label combination:
h(j+1)v = ρ ( ∑ u∈N (v) W (j) lab(u,v) h (j) u + b (j) lab(u,v) )
where we incorporate the directionality of an edge directly in its label.
",2.3 Syntactic GCNs,[0],[0]
"Importantly, to prevent over-parametrization, only bias terms are made label-specific, in other words: Wlab(u,v) = Wdir(u,v).",2.3 Syntactic GCNs,[0],[0]
"The resulting syntactic GCN is illustrated in Figure 2 (shown on top of a CNN, as we will explain in the subsequent section).
",2.3 Syntactic GCNs,[0],[0]
Edge-wise gating.,2.3 Syntactic GCNs,[0],[0]
"Syntactic GCNs also include gates, which can down-weight the contribution of individual edges.",2.3 Syntactic GCNs,[0],[0]
"They also allow the model to deal with noisy predicted structure, i.e. to ignore potentially erroneous syntactic edges.",2.3 Syntactic GCNs,[0],[0]
"For each edge, a scalar gate is calculated as follows:
g(j)u,v = σ",2.3 Syntactic GCNs,[0],[0]
"( h(j)u · ŵ (j) dir(u,v) + b̂ (j) lab(u,v) )",2.3 Syntactic GCNs,[0],[0]
"where σ is the logistic sigmoid function, and ŵ
(j) dir(u,v) ∈ R d and b̂(j)lab(u,v) ∈",2.3 Syntactic GCNs,[0],[0]
R are learned parameters for the gate.,2.3 Syntactic GCNs,[0],[0]
"The computation becomes:
h(j+1)v =ρ (∑ u∈N (v) g(j)u,v ( W (j) dir(u,v) h (j) u + b",2.3 Syntactic GCNs,[0],[0]
"(j) lab(u,v) ))",2.3 Syntactic GCNs,[0],[0]
"In this work we focus on exploiting structural information on the source side, i.e. in the encoder.",3 Graph Convolutional Encoders,[0],[0]
"We hypothesize that using an encoder that incorporates syntax will lead to more informative representations of words, and that these representations, when used as context vectors by the decoder, will lead to an improvement in translation quality.",3 Graph Convolutional Encoders,[0],[0]
"Consequently, in all our models, we use the decoder of Bahdanau et al. (2015) and keep this part of the model constant.",3 Graph Convolutional Encoders,[0],[0]
"As is now common practice, we do not use a maxout layer in the decoder, but apart from this we do not deviate from the original definition.",3 Graph Convolutional Encoders,[0],[0]
"In all models we make use of GRUs (Cho et al., 2014b) as our RNN units.
",3 Graph Convolutional Encoders,[0],[0]
"Our models vary in the encoder part, where we exploit the power of GCNs to induce syntacticallyaware representations.",3 Graph Convolutional Encoders,[0],[0]
"We now define a series of encoders of increasing complexity.
BoW + GCN.",3 Graph Convolutional Encoders,[0],[0]
"In our first and simplest model, we propose a bag-of-words encoder (with position embeddings, see §2.1.1), with a GCN on top.",3 Graph Convolutional Encoders,[0],[0]
"In other words, inputs h(0) are a sum of embeddings of a word and its position in a sentence.",3 Graph Convolutional Encoders,[0],[0]
"Since the original BoW encoder captures the linear ordering information only in a very crude way (through the position embeddings), the structural information provided by GCN should be highly beneficial.
",3 Graph Convolutional Encoders,[0],[0]
Convolutional + GCN.,3 Graph Convolutional Encoders,[0],[0]
"In our second model, we use convolutional neural networks to learn word representations.",3 Graph Convolutional Encoders,[0],[0]
"CNNs are fast, but by definition only use a limited window of context.",3 Graph Convolutional Encoders,[0],[0]
"Instead of the approach used by Gehring et al. (2016) (i.e. stacking multiple CNN layers on top of each other), we use a GCN to enrich the one-layer CNN representations.",3 Graph Convolutional Encoders,[0],[0]
Figure 2 shows this model.,3 Graph Convolutional Encoders,[0],[0]
"Note that, while the figure shows a CNN with a window size of 3, we will use a larger window size of 5 in our experiments.",3 Graph Convolutional Encoders,[0],[0]
"We expect this model to perform better than BoW + GCN, because of the additional local context captured by the CNN.
BiRNN + GCN.",3 Graph Convolutional Encoders,[0],[0]
"In our third and most powerful model, we employ bidirectional recurrent neural networks.",3 Graph Convolutional Encoders,[0],[0]
"In this model, we start by encoding the source sentence using a BiRNN (i.e. BiGRU), and use the resulting hidden states as input to a GCN.",3 Graph Convolutional Encoders,[0],[0]
"Instead of relying on linear order only, the GCN will allow the encoder to ‘teleport’ over parts of the input sentence, along dependency edges, con-
necting words that otherwise might be far apart.",3 Graph Convolutional Encoders,[0],[0]
"The model might not only benefit from this teleporting capability however; also the nature of the relations between words (i.e. dependency relation types) may be useful, and the GCN exploits this information (see §2.3 for details).
",3 Graph Convolutional Encoders,[0],[0]
"This is the most challenging setup for GCNs, as RNNs have been shown capable of capturing at least some degree of syntactic information without explicit supervision (Linzen et al., 2016), and hence they should be hard to improve on by incorporating treebank syntax.
",3 Graph Convolutional Encoders,[0],[0]
Marcheggiani and Titov (2017) did not observe improvements from using multiple GCN layers in semantic role labeling.,3 Graph Convolutional Encoders,[0],[0]
"However, we do expect that propagating information from further in the tree should be beneficial in principle.",3 Graph Convolutional Encoders,[0],[0]
"We hypothesize that the first layer is the most influential one, capturing most of the syntactic context, and that additional layers only modestly modify the representations.",3 Graph Convolutional Encoders,[0],[0]
"To ease optimization, we add a residual connection (He et al., 2016) between the GCN layers, when using more than one layer.",3 Graph Convolutional Encoders,[0],[0]
"Experiments are performed using the Neural Monkey toolkit3 (Helcl and Libovický, 2017), which implements the model of Bahdanau et al. (2015) in TensorFlow.",4 Experiments,[0],[0]
"We use the Adam optimizer (Kingma and Ba, 2015) with a learning rate of 0.001 (0.0002 for CNN models).4",4 Experiments,[0],[0]
The batch size is set to 80.,4 Experiments,[0],[0]
"Between layers we apply dropout with a probability of 0.2, and in experiments with GCNs5 we use the same value for edge dropout.",4 Experiments,[0],[0]
"We train for 45 epochs, evaluating the BLEU performance of the model every epoch on the validation set.",4 Experiments,[0],[0]
"For testing, we select the model with the highest validation BLEU.",4 Experiments,[0],[0]
L2 regularization is used with a value of 10−8.,4 Experiments,[0],[0]
All the model selection (incl. hyperparameter selections) was performed on the validation set.,4 Experiments,[0],[0]
"In all experiments we obtain translations using a greedy decoder, i.e. we select the output token with the highest probability at each time step.
",4 Experiments,[0],[0]
"We will describe an artificial experiment in §4.1 and MT experiments in §4.2.
",4 Experiments,[0],[0]
"3https://github.com/ufal/neuralmonkey 4Like Gehring et al. (2016) we note that Adam is too aggressive for CNN models, hence we use a lower learning rate.",4 Experiments,[0],[0]
5GCN code at https://github.com/bastings/neuralmonkey,4 Experiments,[0],[0]
Our goal here is to provide an intuition for the capabilities of GCNs.,4.1 Reordering artificial sequences,[0],[0]
We define a reordering task where randomly permuted sequences need to be put back into the original order.,4.1 Reordering artificial sequences,[0],[0]
"We encode the original order using edges, and test if GCNs can successfully exploit them.",4.1 Reordering artificial sequences,[0],[0]
Note that this task is not meant to provide a fair comparison to RNNs.,4.1 Reordering artificial sequences,[0],[0]
"The input (besides the edges) simply does not carry any information about the original ordering, so RNNs cannot possibly solve this task.
Data.",4.1 Reordering artificial sequences,[0],[0]
"From a vocabulary of 26 types, we generate random sequences of 3-10 tokens.",4.1 Reordering artificial sequences,[0],[0]
"We then randomly permute them, pointing every token to its original predecessor with a label sampled from a set of 5 labels.",4.1 Reordering artificial sequences,[0],[0]
"Additionally, we point every token to an arbitrary position in the sequence with a label from a distinct set of 5 ‘fake’ labels.",4.1 Reordering artificial sequences,[0],[0]
"We sample 25000 training and 1000 validation sequences.
",4.1 Reordering artificial sequences,[0],[0]
Model.,4.1 Reordering artificial sequences,[0],[0]
"We use the BiRNN + GCN model, i.e. a bidirectional GRU with a 1-layer GCN on top.",4.1 Reordering artificial sequences,[0],[0]
"We use 32, 64 and 128 units for embeddings, GRU units and GCN layers, respectively.
Results.",4.1 Reordering artificial sequences,[0],[0]
"After 6 epochs of training, the model learns to put permuted sequences back into order, reaching a validation BLEU of 99.2.",4.1 Reordering artificial sequences,[0],[0]
"Figure 3 shows that the mean values of the bias terms of gates (i.e. b̂) for real and fake edges are far apart, suggesting that the GCN learns to distinguish them.",4.1 Reordering artificial sequences,[0],[0]
"Interestingly, this illustrates why edge-wise gating is beneficial.",4.1 Reordering artificial sequences,[0],[0]
"A gate-less model would not understand which of the two outgoing arcs is fake and which is genuine, because only biases b would then be label-dependent.",4.1 Reordering artificial sequences,[0],[0]
"Consequently, it would only do a mediocre job in reordering.",4.1 Reordering artificial sequences,[0],[0]
"Although using label-specific matrices W would also help, this would not scale to the real scenario (see §2.3).",4.1 Reordering artificial sequences,[0],[0]
Data.,4.2 Machine Translation,[0],[0]
For our experiments we use the En-De and En-Cs News Commentary v11 data from the WMT16 translation task.6,4.2 Machine Translation,[0],[0]
For En-De we also train on the full WMT16 data set.,4.2 Machine Translation,[0],[0]
"As our validation set and test set we use newstest2015 and newstest2016, respectively.
",4.2 Machine Translation,[0],[0]
Pre-processing.,4.2 Machine Translation,[0],[0]
"The English sides of the corpora are tokenized and parsed into dependency
6http://www.statmt.org/wmt16/translation-task.html
trees by SyntaxNet,7 using the pre-trained Parsey McParseface model.8 The Czech and German sides are tokenized using the Moses tokenizer.9 Sentence pairs where either side is longer than 50 words are filtered out after tokenization.
",4.2 Machine Translation,[0],[0]
Vocabularies.,4.2 Machine Translation,[0],[0]
"For the English sides, we construct vocabularies from all words except those with a training set frequency smaller than three.",4.2 Machine Translation,[0],[0]
"For Czech and German, to deal with rare words and phenomena such as inflection and compounding, we learn byte-pair encodings (BPE) as described by Sennrich et al. (2016b).",4.2 Machine Translation,[0],[0]
"Given the size of our data set, and following Wu et al. (2016), we use 8000 BPE merges to obtain robust frequencies for our subword units (16000 merges for full data experiment).",4.2 Machine Translation,[0],[0]
"Data set statistics are summarized in Table 1 and vocabulary sizes in Table 2.
Hyperparameters.",4.2 Machine Translation,[0],[0]
"We use 256 units for word embeddings, 512 units for GRUs (800 for En-De full data set experiment), and 512 units for convolutional layers (or equivalently, 512 ‘channels’).",4.2 Machine Translation,[0],[0]
"The dimensionality of the GCN layers is equiva-
7https://github.com/tensorflow/models/tree/master/syntaxnet 8The used dependency parses can be reproduced by using
the syntaxnet/demo.sh shell script.",4.2 Machine Translation,[0],[0]
"9https://github.com/moses-smt/mosesdecoder
lent to the dimensionality of their input.",4.2 Machine Translation,[0],[0]
"We report results for 2-layer GCNs, as we find them most effective (see ablation studies below).
",4.2 Machine Translation,[0],[0]
Baselines.,4.2 Machine Translation,[0],[0]
"We provide three baselines, each with a different encoder: a bag-of-words encoder, a convolutional encoder with window size w = 5, and a BiRNN.",4.2 Machine Translation,[0],[0]
"See §2.1.1 for details.
",4.2 Machine Translation,[0],[0]
Evaluation.,4.2 Machine Translation,[0],[0]
"We report (cased) BLEU results (Papineni et al., 2002) using multi-bleu, as well as Kendall τ reordering scores.10",4.2 Machine Translation,[0],[0]
English-German.,4.2.1 Results,[0],[0]
Table 3 shows test results on English-German.,4.2.1 Results,[0],[0]
"Unsurprisingly, the bag-ofwords baseline performs the worst.",4.2.1 Results,[0],[0]
"We expected the BoW+GCN model to make easy gains over this baseline, which is indeed what happens.",4.2.1 Results,[0],[0]
"The CNN baseline reaches a higher BLEU4 score than the BoW models, but interestingly its BLEU1 score is lower than the BoW+GCN model.",4.2.1 Results,[0],[0]
"The CNN+GCN model improves over the CNN baseline by +1.9 and +1.1 for BLEU1 and BLEU4, respectively.",4.2.1 Results,[0],[0]
"The BiRNN, the strongest baseline, reaches a BLEU4 of 14.9.",4.2.1 Results,[0],[0]
"Interestingly, GCNs still manage to improve the result by +2.3 BLEU1 and +1.2 BLEU4 points.",4.2.1 Results,[0],[0]
"Finally, we observe a big jump in BLEU4 by using the full data set and beam search (beam 12).",4.2.1 Results,[0],[0]
"The BiRNN now reaches 23.3, while adding a GCN achieves a score of 23.9.
",4.2.1 Results,[0],[0]
English-Czech.,4.2.1 Results,[0],[0]
Table 4 shows test results on English-Czech.,4.2.1 Results,[0],[0]
"While it is difficult to obtain high absolute BLEU scores on this dataset, we can still see similar relative improvements.",4.2.1 Results,[0],[0]
"Again the BoW baseline scores worst, with the BoW+GCN easily beating that result.",4.2.1 Results,[0],[0]
"The CNN baseline scores BLEU4 of 8.1, but the CNN+GCN improves on that, this time by +1.0 and +0.6 for BLEU1 and BLEU4, respectively.",4.2.1 Results,[0],[0]
"Interestingly, BLEU1 scores for the BoW+GCN and CNN+GCN models are
10See Stanojević and Simaan (2015).",4.2.1 Results,[0],[0]
"TER (Snover et al., 2006) and BEER (Stanojević and Sima’an, 2014) metrics, even though omitted due to space considerations, are consistent with the reported results.
higher than both baselines so far.",4.2.1 Results,[0],[0]
"Finally, the BiRNN baseline scores a BLEU4 of 8.9, but it is again beaten by the BiRNN+GCN model with +1.9 BLEU1 and +0.7 BLEU4.
",4.2.1 Results,[0],[0]
Effect of GCN layers.,4.2.1 Results,[0],[0]
How many GCN layers do we need?,4.2.1 Results,[0],[0]
Every layer gives us an extra hop in the graph and expands the syntactic neighborhood of a word.,4.2.1 Results,[0],[0]
Table 5 shows validation BLEU performance as a function of the number of GCN layers.,4.2.1 Results,[0],[0]
"For English-German, using a 1-layer GCN improves BLEU-1, but surprisingly has little effect on BLEU4.",4.2.1 Results,[0],[0]
"Adding an additional layer gives improvements on both BLEU1 and BLEU4 of +1.3 and +0.73, respectively.",4.2.1 Results,[0],[0]
"For English-Czech, performance increases with each added GCN layer.
",4.2.1 Results,[0],[0]
Effect of sentence length.,4.2.1 Results,[0],[0]
We hypothesize that GCNs should be more beneficial for longer sentences: these are likely to contain long-distance syntactic dependencies which may not be adequately captured by RNNs but directly encoded in GCNs.,4.2.1 Results,[0],[0]
"To test this, we partition the validation data into five buckets and calculate BLEU for each of them.",4.2.1 Results,[0],[0]
Figure 4 shows that GCN-based models outperform their respective baselines rather uniformly across all buckets.,4.2.1 Results,[0],[0]
This is a surprising result.,4.2.1 Results,[0],[0]
"One explanation may be that syntactic parses are noisier for longer sentences, and this prevents us from obtaining extra improvements with GCNs.
",4.2.1 Results,[0],[0]
Discussion.,4.2.1 Results,[0],[0]
Results suggest that the syntaxaware representations provided by GCNs consistently lead to improved translation performance as measured by BLEU4 (as well as TER and BEER).,4.2.1 Results,[0],[0]
"Consistent gains in terms of Kendall tau and BLEU1 indicate that improvements correlate with better word order and lexical/BPE selection, two phenomena that depend crucially on syntax.",4.2.1 Results,[0],[0]
"We review various accounts to syntax in NMT as well as other convolutional encoders.
",5 Related Work,[0],[0]
Syntactic features and/or constraints.,5 Related Work,[0],[0]
"Sennrich and Haddow (2016) embed features such as POS-tags, lemmas and dependency labels and feed these into the network along with word embeddings.",5 Related Work,[0],[0]
Eriguchi et al. (2016) parse English sentences with an HPSG parser and use a Tree-LSTM to encode the internal nodes of the tree.,5 Related Work,[0],[0]
"In the decoder, word and node representations compete under the same attention mechanism.",5 Related Work,[0],[0]
"Stahlberg et al. (2016) use a pruned lattice from a hierarchical phrase-based model (hiero) to constrain NMT.
Hiero trees are not syntactically-aware, but instead constrained by symmetrized word alignments.",5 Related Work,[0],[0]
"Aharoni and Goldberg (2017) propose neural string-to-tree by predicting linearized parse trees.
",5 Related Work,[0],[0]
Multi-task Learning.,5 Related Work,[0],[0]
Sharing NMT parameters with a syntactic parser is a popular approach to obtaining syntactically-aware representations.,5 Related Work,[0],[0]
Luong et al. (2015a) predict linearized constituency parses as an additional task.,5 Related Work,[0],[0]
"Eriguchi et al. (2017) multi-task with a target-side RNNG parser (Dyer et al., 2016) and improve on various language pairs with English on the target side.",5 Related Work,[0],[0]
Nadejde et al. (2017) multi,5 Related Work,[0],[0]
"-task with CCG tagging, and also integrate syntax on the target side by predicting a sequence of words interleaved with CCG supertags.
",5 Related Work,[0],[0]
Latent structure.,5 Related Work,[0],[0]
Hashimoto and Tsuruoka (2017) add a syntax-inspired encoder on top of a BiLSTM layer.,5 Related Work,[0],[0]
They encode source words as a learned average of potential parents emulating a relaxed dependency tree.,5 Related Work,[0],[0]
"While their model is trained purely on translation data, they also experiment with pre-training the encoder using treebank annotation and report modest improvements on English-Japanese.",5 Related Work,[0],[0]
"Yogatama et al. (2016) introduce a model for language understanding and generation that composes words into sentences by inducing unlabeled binary bracketing trees.
",5 Related Work,[0],[0]
Convolutional encoders.,5 Related Work,[0],[0]
Gehring et al. (2016) show that CNNs can be competitive to BiRNNs when used as encoders.,5 Related Work,[0],[0]
To increase the receptive field of a word’s context they stack multiple CNN layers.,5 Related Work,[0],[0]
Kalchbrenner et al. (2016) use convolution in both the encoder and the decoder; they make use of dilation to increase the receptive field.,5 Related Work,[0],[0]
"In contrast to both approaches, we use a GCN informed by dependency structure to increase it.",5 Related Work,[0],[0]
"Finally, Cho et al. (2014a) propose a recursive convolutional neural network which builds a tree out of the word leaf nodes, but which ends up compressing the source sentence in a single vector.",5 Related Work,[0],[0]
We have presented a simple and effective approach to integrating syntax into neural machine translation models and have shown consistent BLEU4 improvements for two challenging language pairs: English-German and English-Czech.,6 Conclusions,[0],[0]
"Since GCNs are capable of encoding any kind of graph-based structure, in future work we would like to go be-
yond syntax, by using semantic annotations such as SRL and AMR, and co-reference chains.",6 Conclusions,[0],[0]
We would like to thank Michael Schlichtkrull and Thomas Kipf for their suggestions and comments.,Acknowledgments,[0],[0]
"This work was supported by the European Research Council (ERC StG BroadSem 678254) and the Dutch National Science Foundation (NWO VIDI 639.022.518, NWO VICI 277-89-002).",Acknowledgments,[0],[0]
We present a simple and effective approach to incorporating syntactic structure into neural attention-based encoderdecoder models for machine translation.,abstractText,[0],[0]
"We rely on graph-convolutional networks (GCNs), a recent class of neural networks developed for modeling graph-structured data.",abstractText,[0],[0]
Our GCNs use predicted syntactic dependency trees of source sentences to produce representations of words (i.e. hidden states of the encoder) that are sensitive to their syntactic neighborhoods.,abstractText,[0],[0]
"GCNs take word representations as input and produce word representations as output, so they can easily be incorporated as layers into standard encoders (e.g., on top of bidirectional RNNs or convolutional neural networks).",abstractText,[0],[0]
We evaluate their effectiveness with English-German and English-Czech translation experiments for different types of encoders and observe substantial improvements over their syntax-agnostic versions in all the considered setups.,abstractText,[0],[0]
Graph Convolutional Encoders for Syntax-aware Neural Machine Translation,title,[0],[0]
"Proceedings of NAACL-HLT 2013, pages 772–776, Atlanta, Georgia, 9–14 June 2013. c©2013 Association for Computational Linguistics",text,[0],[0]
The goal of relation extraction is to extract tuples of a particular relation from a corpus of natural language text.,1 Introduction,[0],[0]
"A widely employed approach to relation extraction is based on iterative bootstrapping (Brin, 1998; Agichtein and Gravano, 2000; Pasca et al., 2006; Pantel and Pennacchiotti, 2006), which can be applied with only small amounts of supervision and which scales well to very large datasets.
",1 Introduction,[0],[0]
"A well-known problem with iterative bootstrapping is a phenomenon known as semantic drift (Curran et al., 2007): as bootstrapping proceeds it is likely that unreliable patterns will lead to false extractions.",1 Introduction,[0],[0]
"These extraction errors are amplified in the following iterations and the extracted relation will drift away
from the intended target.",1 Introduction,[0],[0]
Semantic drift often results in low precision extractions and therefore poses a major limitation of iterative bootstrapping algorithms.,1 Introduction,[0],[0]
"Previous work on iterative bootstrapping has addressed the issue of reducing semantic drift for example by bagging the results of various runs employing differing seed tuples, constructing filters which identify false tuples or patterns and adding further constraints to the bootstrapping process (T. McIntosh, 2010; McIntosh and Curran, 2009; Curran et al., 2007).
",1 Introduction,[0],[0]
"However, the analysis of Komachi et al. (2008) has shown that semantic drift is an inherent property of iterative bootstrapping algorithms and therefore poses a fundamental problem.",1 Introduction,[0],[0]
"They have shown that iterative bootstrapping without pruning corresponds to an eigenvector computation and thus as the number of iterations increases the resulting ranking will always converge towards the same static ranking of tuples, regardless of the particular choice of seed instances.
",1 Introduction,[0],[0]
"In this paper, we describe an alternative method, that is not susceptible to semantic drift.",1 Introduction,[0],[0]
"We represent our data as a bipartite graph, whose vertices correspond to patterns and tuples respectively and whose edges capture cooccurrences and then measure the distance of a tuple to the seed set in terms of random walk hitting times.",1 Introduction,[0],[0]
"Experimental results confirm that semantic drift is avoided by our method and show that substantial improvements over iterative forms of bootstrapping are possible.
772",1 Introduction,[0],[0]
"From a given corpus, we extract a dataset consisting of tuples and patterns.",2 Scoring with Hitting Times,[0],[0]
"Tuples are pairs of co-occurring strings in the corpus, such as (Bill Gates, Microsoft), which potentially belong to a particular relation of interest.",2 Scoring with Hitting Times,[0],[0]
"In our case, patterns are simply the sequence of tokens occurring between tuple elements, e.g. “is the founder of”.",2 Scoring with Hitting Times,[0],[0]
"We represent all the tuple types1 X and all the extraction pattern types Y contained in a given corpus through an undirected, weighted, bipartite graph G = (V,E) with vertices V = X ∪ Y and edges E ⊂",2 Scoring with Hitting Times,[0],[0]
X,2 Scoring with Hitting Times,[0],[0]
"× Y , where an edge (x, y) ∈ E indicates that tuple x occurrs with pattern y somewhere in the corpus.",2 Scoring with Hitting Times,[0],[0]
"Edge weights are defined through a weight matrix W which holds the weight Wi,j = w(vi, vj) for edges (vi, vj) ∈ E. Specifically, we use the count of how many times a tuple occurs with a pattern in the corpus and weights for unconnected vertices are zero.
",2 Scoring with Hitting Times,[0],[0]
"Our goal is to compute a score vector σ holding a score σi = σ(xi) for each tuple xi ∈ X, which quantifies how well the tuple matches the seed tuples.",2 Scoring with Hitting Times,[0],[0]
"Higher scores indicate that the tuple is more likely to belong to the relation defined through the seeds and thus the score vector effectively provides a ranking of the tuples.
",2 Scoring with Hitting Times,[0],[0]
We define scores of tuples based on their distance2 to the seed tuples in the graph.,2 Scoring with Hitting Times,[0],[0]
"The distance of some tuple x to the seed set S can be naturally formalized in terms of the average time it takes until a random walk starting in S reaches x, the hitting time.",2 Scoring with Hitting Times,[0],[0]
The random walk is defined through the probability distribution over start vertices and through a matrix of transition probabilities.,2 Scoring with Hitting Times,[0],[0]
"Edge weights are constrained to be non-negative, which allows us to define the transition matrix P with Pi,j = p(vj |vi) = 1dviw(vi, vj), where dv =∑
vk∈V w(v, vk) is the degree of a vertex v ∈ V .",2 Scoring with Hitting Times,[0],[0]
The distance of two vertices is measured in terms of the average time of a random walk be1Note that we are using tuple and pattern types rather than particular mentions in the corpus. 2The term is used informally.,2 Scoring with Hitting Times,[0],[0]
"In particular, hitting times are not a distance metric, since they can be asymmetric.
",2 Scoring with Hitting Times,[0],[0]
tween the two.,2 Scoring with Hitting Times,[0],[0]
"Specifically, we adopt the notion of T-truncated hitting time (Sarkar and Moore, 2007) defined as the expected number of steps it takes until a random walk of at most T steps starting at vi reaches vj for the first time:
hT",2 Scoring with Hitting Times,[0],[0]
(vj |vi) = { 0 iff.,2 Scoring with Hitting Times,[0],[0]
"vj = vi or T=0 1 + ∑ vk∈V p(vk|vi)h T−1(vj |vk)
",2 Scoring with Hitting Times,[0],[0]
The truncated hitting time hT,2 Scoring with Hitting Times,[0],[0]
"(vj |vi) can be approximately computed by sampling M independent random walks starting at vi of length T and computing
ĥT",2 Scoring with Hitting Times,[0],[0]
(vj |vi),2 Scoring with Hitting Times,[0],[0]
"= 1
M m∑ k=1 tk",2 Scoring with Hitting Times,[0],[0]
"+ (1− m M )T (1)
",2 Scoring with Hitting Times,[0],[0]
where {t1 . . .,2 Scoring with Hitting Times,[0],[0]
"tm} are the sampled first-hit times of random walks which reach vj within T steps (Sarkar et al., 2008).
",2 Scoring with Hitting Times,[0],[0]
The score σHT (v) of a vertex v /∈,2 Scoring with Hitting Times,[0],[0]
"S to the seed set S is then defined as the inverse of the average T -truncated hitting time of random walks starting at a randomly chosen vertex s ∈ S:
1 σHT (v) = hT",2 Scoring with Hitting Times,[0],[0]
(v|S) = 1 |S| ∑ s∈S hT (v|s) (2),2 Scoring with Hitting Times,[0],[0]
"We extracted tuples and patterns from the fifth edition of the Gigaword corpus (Parker et al., 2011), by running a named entity tagger and extracting all pairs of named entities and extracting occurring within the same sentence which do not have another named entity standing between them.",3 Experiments,[0],[0]
"Gold standard seed and test tuples for a set of relations were obtained from YAGO (Suchanek et al., 2007).",3 Experiments,[0],[0]
"Specifically, we took all relations for which there are at least 300 tuples, each of which occurs at least once in the corpus.",3 Experiments,[0],[0]
"This resulted in the set of relations shown in Table 1, plus the development relation hasWonPrize.
",3 Experiments,[0],[0]
"For evaluation, we use the percentile rank of the median test set element (PRM, see Francois et al. 2007), which reflects the quality of the
full produced ranking, not just the top N elements and is furthermore computable with only a small set of labeled test tuples 3.
",3 Experiments,[0],[0]
We compare our proposed method based on hitting times (HT) with two variants of iterative bootstrapping.,3 Experiments,[0],[0]
The first one (IB1) does not employ pruning and corresponds to the algorithm described in Komachi et al. (2008).,3 Experiments,[0],[0]
The second one (IB2) corresponds to a standard bootstrapping algorithm which employs pruning after each step in order to reduce semantic drift.,3 Experiments,[0],[0]
"Specifically, scores are pruned after projecting from X onto Y and from Y onto X, retaining only the top N (t) =",3 Experiments,[0],[0]
N0t scores at iteration t and setting all other scores to zero.,3 Experiments,[0],[0]
The experiments in this section were conducted on the held out development relation hasWonPrize.,3.1 Parametrizations,[0],[0]
"The ranking produced by both forms of iterative bootstrapping IB1 and IB2 depend on the number of iterations, as shown in Figure 1.",3.1 Parametrizations,[0],[0]
IB1 achieves an optimal ranking after just one iteration and thereafter scores get worse due to semantic drift.,3.1 Parametrizations,[0],[0]
"In contrast, pruning helps avoid semantic drift for IB2, which attains an optimal score after 2 iterations and achieves relatively constant scores for several iterations.",3.1 Parametrizations,[0],[0]
"However, during iteration 9 an incorrect pattern is kept and this at once leads to a drastic loss in accuracy, showing that semantic drift is only deferred and not completely eliminated.
",3.1 Parametrizations,[0],[0]
"Our method HT has parameter T , corresponding to the truncation time, i.e., maximal number of steps of a random walk.",3.1 Parametrizations,[0],[0]
Figure 2 shows the PRM of our method for different values of T .,3.1 Parametrizations,[0],[0]
"Performance gets better as T increases and is optimal for T = 12, whereas for larger values, the performance gets slightly worse again.",3.1 Parametrizations,[0],[0]
"The figure shows that, if T is large enough (> 5), the PRM is relatively constant and there is no phenomenon comparable to semantic drift, which causes instability in the produced rankings.
",3.1 Parametrizations,[0],[0]
3other common metrics do not satisfy these conditions.,3.1 Parametrizations,[0],[0]
"To evaluate the methods, firstly the parameters for each method were set to the optimal values as determined in the previous section.",3.2 Method Comparison,[0],[0]
"For the experiments here, we again use 200 randomly chosen tuples as the seeds for each relation.",3.2 Method Comparison,[0],[0]
"All the remaining gold standard tuples are used for testing.
",3.2 Method Comparison,[0],[0]
Table 1 shows the PRM for the three methods.,3.2 Method Comparison,[0],[0]
"For a majority of the relations (12/16) HT attains the best, i.e. lowest, PRM, which confirms that hitting times constitute an accurate way of measuring the distance of tuples to the seed set.",3.2 Method Comparison,[0],[0]
IB1 and IB2 each perform best on 2/16 of the relations.,3.2 Method Comparison,[0],[0]
"A sign test on these results yields that
HT is better than both IB1 and IB2 at significance level α < 0.01.
",3.2 Method Comparison,[0],[0]
"Moreover, the ranking produced by HT is stable and not affected by semantic drift, given that even where results are worse than for IB1 or IB2, they are still close to the best performing method.",3.2 Method Comparison,[0],[0]
"In contrast, when semantic drift occurs, the performance of IB1 and IB2 can deteriorate drastically, e.g. for the worksAt relation, where both IB1 and IB2 produce rankings that are a lot worse than the one produced by HT.",3.2 Method Comparison,[0],[0]
Figure 3 shows the PRM for each of the three methods as a function of the size of the seed set for the relation created.,3.3 Sensitivity to Seed Set Size,[0],[0]
"For small seed sets, the performance of the iterative methods can be increased by adding more seeds.",3.3 Sensitivity to Seed Set Size,[0],[0]
"However, from a seed set size of 50 onwards, performance remains relatively constant.",3.3 Sensitivity to Seed Set Size,[0],[0]
"In other words, iterative bootstrapping is not benefitting from the information provided by the additional labeled data, and thus has a poor learning performance.",3.3 Sensitivity to Seed Set Size,[0],[0]
"In contrast, for our method based on hitting times, the performance continually improves as the seed set size is increased.",3.3 Sensitivity to Seed Set Size,[0],[0]
"Thus, also in terms of learning performance, our method is more sound than iterative bootstrapping.",3.3 Sensitivity to Seed Set Size,[0],[0]
The paper has presented a graph-based method for seed set expansion which is not susceptible to semantic drift and on most relations outperforms iterative bootstrapping.,4 Conclusions,[0],[0]
The method measures distance between vertices through random walk hitting times.,4 Conclusions,[0],[0]
"One property which makes hitting times an appropriate distance measure is their ability to reflect the overall connectivity structure of the graph, in contrast to measures such as the shortest path between two vertices.",4 Conclusions,[0],[0]
"The hitting time will decrease when the number of paths from the start vertex to the target vertex increases, when the length of paths decreases or when the likelihood (weights) of paths increases.",4 Conclusions,[0],[0]
"These properties are particularly important when the observed graph edges must be assumed to be merely a sample of all plausible edges, possibly perturbated by noise.",4 Conclusions,[0],[0]
"This has also been asserted by previous work, which has shown that hitting times successfully capture the notion of similarity for other natural language processing problems such as learning paraphrases (Kok and Brockett, 2010) and related problems such as query suggestion (Mei et al., 2008).",4 Conclusions,[0],[0]
Future work will be aimed towards employing our hitting time based method in combination with a richer feature set.,4 Conclusions,[0],[0]
"Iterative bootstrapping methods are widely employed for relation extraction, especially because they require only a small amount of human supervision.",abstractText,[0],[0]
"Unfortunately, a phenomenon known as semantic drift can affect the accuracy of iterative bootstrapping and lead to poor extractions.",abstractText,[0],[0]
"This paper proposes an alternative bootstrapping method, which ranks relation tuples by measuring their distance to the seed tuples in a bipartite tuple-pattern graph.",abstractText,[0],[0]
"In contrast to previous bootstrapping methods, our method is not susceptible to semantic drift, and it empirically results in better extractions than iterative methods.",abstractText,[0],[0]
Graph-Based Seed Set Expansion for Relation Extraction Using Random Walk Hitting Times,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1537–1546 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Metaphor is pervasive in our everyday communication, enriching it with sophisticated imagery and helping us to reconcile our experience in the world with our conceptual system (Lakoff and Johnson, 1980).",1 Introduction,[0],[0]
"In the most influential account of metaphor to date, Lakoff and Johnson explain the phenomenon through the presence of systematic metaphorical associations between two distinct concepts or domains.",1 Introduction,[0],[0]
"For instance, when we talk about “curing juvenile delinquency” or “corruption transmitting through the government ranks”, we view the general concept of crime (the target concept) in terms of the properties of a disease (the source concept).",1 Introduction,[0],[0]
"Such metaphorical associations are broad generalisations that allow us to project knowledge and inferences across domains; and our metaphorical use of language is a reflection of this process.
",1 Introduction,[0],[0]
"Given its ubiquity, metaphorical language poses an important problem for natural language understanding (Cameron, 2003; Shutova and Teufel, 2010).",1 Introduction,[0],[0]
"A number of approaches to metaphor processing have thus been proposed, focusing pre-
dominantly on classifying linguistic expressions as literal or metaphorical.",1 Introduction,[0],[0]
"They experimented with a range of features, including lexical and syntactic information (Hovy et al., 2013; Beigman Klebanov et al., 2016) and higher-level features such as semantic roles (Gedigian et al., 2006), domain types (Dunn, 2013), concreteness (Turney et al., 2011), imageability (Strzalkowski et al., 2013) and WordNet supersenses (Tsvetkov et al., 2014).",1 Introduction,[0],[0]
"While reporting promising results, all of these approaches used hand-engineered features and relied on manually-annotated resources to extract them.",1 Introduction,[0],[0]
"In order to reduce the reliance on manual annotation, other researchers experimented with sparse distributional features (Shutova et al., 2010; Shutova and Sun, 2013) and dense neural word embeddings (Bracewell et al., 2014; Shutova et al., 2016).",1 Introduction,[0],[0]
"Their experiments have demonstrated that corpus-driven lexical representations already encode information about semantic domains needed to learn the patterns of metaphor usage from linguistic data.
",1 Introduction,[0],[0]
We take this intuition a step further and present the first deep learning architecture designed to capture metaphorical composition.,1 Introduction,[0],[0]
"Deep learning methods have already been shown successful in many other semantic tasks (e.g. Hermann et al., 2015; Kumar et al., 2015; Zhao et al., 2015), which suggests that designing a specialised neural network architecture for metaphor detection will lead to improved performance.",1 Introduction,[0],[0]
"In this paper, we present a novel architecture which (1) models the interaction between the source and target domains in the metaphor via a gating function; (2) specialises word representations for the metaphor identification task via supervised training; (3) quantifies metaphoricity via a weighted similarity function that automatically selects the relevant dimensions of similarity.",1 Introduction,[0],[0]
"We experimented with two types of word representations
1537
as inputs to the network: the standard skip-gram word embeddings (Mikolov et al., 2013a) and the cognitively-driven attribute-based vectors (Bulat et al., 2017), as well as a combination thereof.
",1 Introduction,[0],[0]
"We evaluate our method in the metaphor identification task, focusing on adjective–noun, verb– subject and verb–direct object constructions where the verbs and adjectives can be used metaphorically.",1 Introduction,[0],[0]
Our results show that our architecture outperforms both a metaphor agnostic deep learning baseline (a basic feed forward network) and the previous corpus-based approaches to metaphor identification.,1 Introduction,[0],[0]
"We also investigate the effects of training data on this task, and demonstrate that with a sufficiently large training set our method also outperforms the best existing systems based on hand-coded lexical knowledge.",1 Introduction,[0],[0]
The majority of approaches to metaphor processing cast the problem as classification of linguistic expressions as metaphorical or literal.,2 Related Work,[0],[0]
Gedigian et al. (2006) classified verbs related to MOTION and CURE within the domain of financial discourse.,2 Related Work,[0],[0]
"They used the maximum entropy classifier and the verbs’ nominal arguments and their FrameNet roles (Fillmore et al., 2003) as features, reporting encouraging results.",2 Related Work,[0],[0]
"Dunn (2013) used a logistic regression classifier and high-level properties of concepts extracted from SUMO ontology, including domain types (ABSTRACT, PHYSICAL, SOCIAL, MENTAL) and event status (PROCESS, STATE, OBJECT).",2 Related Work,[0],[0]
"Tsvetkov et al. (2014) used random forest classifier and coarse semantic features, such as concreteness, animateness, named entity types and WordNet supersenses.",2 Related Work,[0],[0]
They have shown that the model learned with such coarse semantic features is portable across languages.,2 Related Work,[0],[0]
The work of Hovy et al. (2013) is notable as they focused on compositional rather than categorical features.,2 Related Work,[0],[0]
"They trained an SVM with dependency-tree kernels to capture compositional information, using lexical, part-of-speech tag and WordNet supersense representations of sentence trees.",2 Related Work,[0],[0]
Mohler et al. (2013) aimed at modelling conceptual information.,2 Related Work,[0],[0]
They derived semantic signatures of texts as sets of highly-related and interlinked WordNet synsets.,2 Related Work,[0],[0]
"The semantic signatures served as features to train a set of classifiers (maximum entropy, decision trees, SVM, random forest) that mapped new metaphors to the semantic signatures
of the known ones.
",2 Related Work,[0],[0]
"With the aim of reducing the dependence on manually-annotated lexical resources, other research focused on modelling metaphor using corpus-driven information alone.",2 Related Work,[0],[0]
Shutova et al. (2010) pointed out that the metaphorical uses of words constitute a large portion of the dependency features extracted for abstract concepts from corpora.,2 Related Work,[0],[0]
"For example, the feature vector for politics would contain GAME or MECHANISM terms among the frequent features.",2 Related Work,[0],[0]
"As a result, distributional clustering of abstract nouns with such features identifies groups of diverse concepts metaphorically associated with the same source domain.",2 Related Work,[0],[0]
Shutova et al. (2010) exploit this property of co-occurrence vectors to identify new metaphorical mappings starting from a set of examples.,2 Related Work,[0],[0]
Shutova and Sun (2013) used hierarchical clustering to derive a network of concepts in which metaphorical associations are learned in an unsupervised way.,2 Related Work,[0],[0]
"Do Dinh and Gurevych (2016) investigated metaphors through the task of sequence labelling, detecting metaphor related words in context.",2 Related Work,[0],[0]
Gutiérrez et al. (2016) investigated metaphorical composition in the compositional distributional semantics framework.,2 Related Work,[0],[0]
"Their method learns metaphors as linear transformations in a vector space and they demonstrated that it produces superior phrase representations for both metaphorical and literal language, as compared to the traditional ”single-sense” compositional distributional model.",2 Related Work,[0],[0]
"They then used these representations in the metaphor identification task, achieving promising results.
",2 Related Work,[0],[0]
"The more recent approaches of Shutova et al. (2016) and Bulat et al. (2017) used dense skipgram word embeddings (Mikolov et al., 2013a) instead of the sparse distributional features.",2 Related Work,[0],[0]
Shutova et al. (2016) investigated a set of metaphor identification methods using linguistic and visual features.,2 Related Work,[0],[0]
"They learned linguistic and visual representations for both words and phrases, using skipgram and convolutional neural networks (Kiela and Bottou, 2014) respectively.",2 Related Work,[0],[0]
"They then measured the difference between the phrase representation and those of its component words in terms of their cosine similarity, which served as a predictor of metaphoricity.",2 Related Work,[0],[0]
"They found basic cosine similarity between the component words in the phrase to be a powerful measure – the neural embeddings of the words were compared with cosine similar-
ity and a threshold was tuned on the development set to distinguish between literal and metaphorical phrases.",2 Related Work,[0],[0]
"This approach was their best performing linguistic model, outperformed only by a multimodal system which included both linguistic and visual features.
",2 Related Work,[0],[0]
"Bulat et al. (2017) presented a metaphor identification method that uses representations constructed from human property norms (McRae et al., 2005).",2 Related Work,[0],[0]
"They first learn a mapping from the skip-gram embedding vector space to the property norm space using linear regression, which allows them to generate property norm representations for unseen words.",2 Related Work,[0],[0]
The authors then train an SVM classifier to detect metaphors using these representations as input.,2 Related Work,[0],[0]
Bulat et al. (2017) have shown that the cognitively-driven property norms outperform standard skip-gram representations in this task.,2 Related Work,[0],[0]
"Our method is inspired by the findings of Shutova et al. (2016), who showed that the cosine similarity between neural embeddings of the two words in a phrase is indicative of its metaphoricity.",3 Supervised Similarity Network,[0],[0]
"For example, the phrase ‘colourful personality’ receives a score:
s = cos(xc, xp) (1)
where xc is the embedding for colourful and xp is the embedding for personality.",3 Supervised Similarity Network,[0],[0]
"The combined phrase is classified as being metaphorical based on a threshold, which is optimised on a development dataset.",3 Supervised Similarity Network,[0],[0]
"In this paper, we propose several extensions to this general idea, creating a supervised version of the cosine similarity metric which can be optimised on training data to be more suitable for metaphor detection.",3 Supervised Similarity Network,[0],[0]
Directly comparing the vector representations of both words treats each of the embeddings as an independent unit.,3.1 Word Representation Gating,[0],[0]
"In reality, however, word meanings vary and adapt based on the context.",3.1 Word Representation Gating,[0],[0]
"In case of metaphorical language (e.g. “cure crime”), the source domain properties of the verb (e.g. cure) are projected onto the target domain noun (e.g. crime), resulting in the interaction of the two domains in the interpretation of the metaphor.
",3.1 Word Representation Gating,[0],[0]
"In order to integrate this idea into the metaphor detection method, we can construct a gating function that modulates the representation of one word based on the other.",3.1 Word Representation Gating,[0],[0]
"Given embeddings x1 and x2, the gating values are predicted as a non-linear transformation of x1 and applied to x2 through element-wise multiplication:
g = σ(Wgx1) (2)
x̃2",3.1 Word Representation Gating,[0],[0]
"= x2 g (3)
",3.1 Word Representation Gating,[0],[0]
"whereWg is a weight matrix that is optimised during training, σ is the sigmoid activation function, and represents element-wise multiplication.",3.1 Word Representation Gating,[0],[0]
"In an adjective-noun phrase, this architecture allows the network to first look at the adjective, then use its meaning to change the representation of the noun.",3.1 Word Representation Gating,[0],[0]
"The sigmoid activation function makes it act as a filter, choosing which information from the original embedding gets through to the rest of the network.",3.1 Word Representation Gating,[0],[0]
"While learning a more complex gating function could be beneficial for very large training resources, the filtering approach is more suitable for the annotated metaphor datasets which are relatively small in size.",3.1 Word Representation Gating,[0],[0]
"As the next step, we implement position-specific mappings for the word embeddings.",3.2 Vector Space Mapping,[0],[0]
"The original method uses word embeddings that have been pretrained using the distributional skip-gram objective (Mikolov et al., 2013a).",3.2 Vector Space Mapping,[0],[0]
"While this tunes the vectors for predicting context words, there is no reason to believe that the same space is also optimal for the task of metaphor detection.",3.2 Vector Space Mapping,[0],[0]
"In order to address this shortcoming, we allow the model to learn a mapping from the skip-gram vector space to a new metaphor-specific vector space:
z1 = tanh(Wz1x1) (4)
z2 = tanh(Wz2 x̃2) (5)
where Wz1 and Wz2 are weight matrices, z1 and z2 are the new position-specific word representations.",3.2 Vector Space Mapping,[0],[0]
"While the original embeddings x1 and x2 are pre-trained on a large unannotated corpus, the transformation process is optimised using annotated metaphor examples, resulting in word representations that are more suitable for this task.",3.2 Vector Space Mapping,[0],[0]
"Furthermore, the adjectives and nouns use separate mapping weights, which allows the model to better distinguish between the different functionalities of these words.",3.2 Vector Space Mapping,[0],[0]
"In contrast, the original cosine similarity is not position-specific and would give the same result regardless of the word order.",3.2 Vector Space Mapping,[0],[0]
"If the vectors x1 and x2 are normalised to unit length, the cosine similarity between them is equal to their dot product, which in turn is equal to their elementwise multiplication followed by a sum over all elements:
cos(x1, x2) ∝",3.3 Weighted Cosine,[0],[0]
"∑
i
x1,ix2,i (6)
",3.3 Weighted Cosine,[0],[0]
This calculation of cosine similarity can be formulated as a small neural network where the two unit-normalised input vectors are directly multiplied together.,3.3 Weighted Cosine,[0],[0]
"This is followed by a single output neuron, with all the intermediate weights set to value 1.",3.3 Weighted Cosine,[0],[0]
"Such a network would calculate the same sum over the element-wise multiplication, outputting the value of cosine similarity.
",3.3 Weighted Cosine,[0],[0]
"Since there is no reason to assume that all the embedding dimensions are equally important when detecting metaphors, we can explore other strategies for weighting the similarity calculation.
",3.3 Weighted Cosine,[0],[0]
Rei and Briscoe (2014) used a fixed formula to calculate weights for different dimensions of cosine similarity and showed that it helped in recovering hyponym relations.,3.3 Weighted Cosine,[0],[0]
We extend this even further and allow the network to use multiple different weighting strategies which are all optimised during training.,3.3 Weighted Cosine,[0],[0]
"This is done by first creating a vector m, which is an element-wise multiplication of the two word representations:
mi = z1,iz2,i (7)
where mi is the i-th element of vector m and z1,i is the i-th element of vector z1.",3.3 Weighted Cosine,[0],[0]
"After that, the resulting vector is used as input for a hidden neural layer:
d = γ(Wdm) (8)
whereWd is a weight matrix and γ is an activation function.",3.3 Weighted Cosine,[0],[0]
"If the length of d is 1, all the weights in Wd have value 1, and γ is a linear activation, then this formula is equivalent to a regular cosine similarity.",3.3 Weighted Cosine,[0],[0]
"However, we use a larger length for d to capture more features, use tanh as the activation function, and optimise the weights of Wd during training, giving the framework more flexibility to customise the model for the task of metaphor detection.",3.3 Weighted Cosine,[0],[0]
"Based on vector d we can output a prediction for the word pair, showing whether it is literal or metaphorical:
y = σ(Wyd) (9)
where Wy is a weight matrix, σ is the logistic activation function, and y is a real-valued prediction with values between 0 and 1.
",3.4 Prediction and Optimisation,[0],[0]
"We optimise the model based on an annotated training dataset, while minimising the following hinge loss function:
E = ∑
k
qk (10)
qk = { (ỹ − y)2 if |ỹ − y| > 0.4 0, otherwise
(11)
where y is the predicted value, ỹ is the true label, and k iterates over all training examples.",3.4 Prediction and Optimisation,[0],[0]
Equation 11 optimises the model to minimise the squared error between the predicted and true labels.,3.4 Prediction and Optimisation,[0],[0]
"However, this is only done for training examples where the predicted error is not already close enough to the desired result.",3.4 Prediction and Optimisation,[0],[0]
The condition |ỹ,3.4 Prediction and Optimisation,[0],[0]
− y| > 0.4 only updates training examples where the difference from the true label is greater than 0.4.,3.4 Prediction and Optimisation,[0],[0]
The true labels ỹ can only take values 0,3.4 Prediction and Optimisation,[0],[0]
"(literal) or 1 (metaphorical), and the threshold 0.4 is chosen so that datapoints that are on the correct side of the decision boundary by more than 0.1 would be ignored, which helps reduce overfitting and allows the model to focus on the misclassified examples.
",3.4 Prediction and Optimisation,[0],[0]
The diagram of the complete network can be seen in Figure 1.,3.4 Prediction and Optimisation,[0],[0]
"Following Bulat et al. (2017) we experiment with two types of semantic vectors: skip-gram word embeddings and attribute-based representations.
",4 Word Representations,[0],[0]
"The word embeddings are 100-dimensional and were trained using the standard log-linear skipgram model with negative sampling of Mikolov et al. (2013b) on Wikipedia for 3 epochs, using a symmetric window of 5 and 10 negative samples per word-context pair.
",4 Word Representations,[0],[0]
"We use the 2526-dimensional attribute-based vectors trained by Bulat et al. (2017), following Fagarasan et al. (2015).",4 Word Representations,[0],[0]
These representations were induced by using partial least squares regression to learn a cross-modal mapping function between the word embeddings described above and the McRae et al. (2005) property-norm semantic space.,4 Word Representations,[0],[0]
"We evaluate our method using two datasets of phrases manually annotated for metaphoricity.
",5 Datasets,[0],[0]
"Since these datasets include examples for different senses (both metaphorical and literal) of the same verbs or adjectives, they allow us to test the extent to which our model is able to discriminate between different word senses, as opposed to merely selecting the most frequent class for a given word.
",5 Datasets,[0],[0]
"Mohammad et al. dataset (MOH) Mohammad et al. (2016) used WordNet to find verbs that had between three and ten senses and extracted the sentences exemplifying them in the corresponding glosses, yielding a total of 1639 verb uses in sentences.",5 Datasets,[0],[0]
Each of these was annotated for metaphoricity by 10 annotators via the crowdsourcing platform CrowdFlower1.,5 Datasets,[0],[0]
Mohammad et al. selected the verbs that were tagged by at least 70% of the annotators as metaphorical or literal to create their dataset.,5 Datasets,[0],[0]
"We extracted verb–direct object and verb–subject relations of the annotated verbs from this dataset, discarding the instances with pronominal or clausal subject or object.",5 Datasets,[0],[0]
This resulted in a dataset of 647 verb–noun pairs (316 metaphorical and 331 literal).,5 Datasets,[0],[0]
"Some examples of annotated verb phrases from MOH are presented in Table 1.
",5 Datasets,[0],[0]
Tsvetkov et al. dataset (TSV) Tsvetkov et al. (2014) construct a dataset of adjective–noun pairs annotated for metaphoricity.,5 Datasets,[0],[0]
This is divided into a training set consisting of 884 literal and 884 metaphorical pairs (TSV-TRAIN) and a test set containing 100 literal and 100 metaphorical pairs (TSV-TEST).,5 Datasets,[0],[0]
Table 2 shows a portion of annotated adjective-noun phrases from TSV-TEST.,5 Datasets,[0],[0]
"TSV-TRAIN was collected from publicly available metaphor collections on the web and manually
1www.crowdflower.com
curated by removing duplicates and metaphorical phrases that depend on wider context for their interpretation (e.g. drowning students).",5 Datasets,[0],[0]
TSVTEST was constructed by extracting nouns that co-occur with a list of 1000 frequent adjectives in the TenTen Web Corpus2 using SketchEngine.,5 Datasets,[0],[0]
The selected adjective-noun pairs were annotated for metaphoricity by 5 annotators with an interannotator agreement of κ = 0.76.,5 Datasets,[0],[0]
"Since TSVTRAIN and TSV-TEST were constructed differently, we follow previous work (Tsvetkov et al., 2014; Shutova et al., 2016; Bulat et al., 2017) and report performance on TSV-TEST.",5 Datasets,[0],[0]
We randomly separated 200 (out of the 1536) examples from the training set to use for development experiments.,5 Datasets,[0],[0]
"The word representations in our model were initialised with either the 100-dimensional skip-gram embeddings or the 2,526-dimensional attribute vectors (Section 4).",6 Experiments and Results,[0],[0]
"These were kept fixed and not updated, which reduces overfitting on the available training examples.",6 Experiments and Results,[0],[0]
"For both word representations we use the same embeddings as Bulat et al. (2017), which makes the results directly comparable and shows that the improvements are coming from the novel architecture and are not due to a different embedding initialisation.
",6 Experiments and Results,[0],[0]
"The network was optimised using AdaDelta (Zeiler, 2012) for controlling adaptive learning rates.",6 Experiments and Results,[0],[0]
The models were evaluated after each full pass over the training data and training was stopped if the F-score on the development set had not improved for 5 epochs.,6 Experiments and Results,[0],[0]
"The transformed embeddings z1 and z2 were set to size 300, layer d was set to size 50.",6 Experiments and Results,[0],[0]
The values for these hyperparameters were chosen experimentally using the development dataset.,6 Experiments and Results,[0],[0]
"In order to avoid drawing conclusions based on outlier results due to random initialisations, we ran each experiment 25 times with random seeds and present the averaged results in this paper.",6 Experiments and Results,[0],[0]
"We implemented the framework using Theano (Al-Rfou et al., 2016) and are making the source code publicly available.3
Table 3 contains results of different system configurations on the TSV dataset.",6 Experiments and Results,[0],[0]
"The original Fscore by Tsvetkov et al. (2014) is still the highest, as they used a range of highly-engineered features that require manual annotation, such as
2https://www.sketchengine.co.uk/ententen-corpus/ 3http://www.marekrei.com/projects/ssn
the lexical abstractness, imageability scores and the relative number of supersenses for each word in the dataset.",6 Experiments and Results,[0],[0]
"Our setup is more similar to the linguistic experiments by Shutova et al. (2016), where metaphor detection is performed using pretrained word embeddings.",6 Experiments and Results,[0],[0]
They also proposed combining the linguistic model with a system using visual word representations and achieved performance improvements.,6 Experiments and Results,[0],[0]
"Recently, Bulat et al. (2017) compared different types of embeddings and showed that attribute-based representations can outperform regular skip-gram embeddings.
",6 Experiments and Results,[0],[0]
"As an additional baseline, we report the performance on metaphor detection using a basic feedforward network (FFN).",6 Experiments and Results,[0],[0]
"In this configuration, the word embeddings x1 and x2 are directly connected to the hidden layer d, skipping all the intermediate network structure.",6 Experiments and Results,[0],[0]
"The FFN achieves 74.4% F-score on TSV-TEST, showing that even such a simple model can perform relatively well in a supervised setting.",6 Experiments and Results,[0],[0]
"Using attribute vectors instead of skip-gram embeddings gives a slight improvement, especially on the recall metric, which is consistent with the findings by Bulat et al. (2017).
",6 Experiments and Results,[0],[0]
"The architecture described in Section 3, which we refer to as a supervised similarity network (SSN), outperforms the baseline and achieves 80.1% F-score using skip-gram embeddings and 80.6% with attribute-based representations.",6 Experiments and Results,[0],[0]
We also created a fusion of these two models where the predictions from both are combined as a weighted average.,6 Experiments and Results,[0],[0]
"In this setting, the two networks are trained in tandem and a real-valued weight, which is also optimised during training, is
used to combine them together.",6 Experiments and Results,[0],[0]
"This configuration achieves 81.1% F-score, indicating that the the skip-gram embeddings and attribute vectors capture somewhat complementary information.",6 Experiments and Results,[0],[0]
"Excluding the system by Tsvetkov et al. (2014) which requires hand-annotated features, the proposed similarity network outperforms all the previous systems, even improving over the multimodal system by Shutova et al. (2016) without requiring any visual information.",6 Experiments and Results,[0],[0]
"The attribute-based SSN also improves over Bulat et al. (2017) by 5.6% absolute, using the same word representations as input.
",6 Experiments and Results,[0],[0]
Table 4 contains results of different system architectures on the MOH dataset.,6 Experiments and Results,[0],[0]
"Shutova et al. (2016) reported 75% F-score on this dataset with a multimodal system, after randomly separating a subset for testing.",6 Experiments and Results,[0],[0]
"Since this corpus contains only 647 annotated examples, we instead evaluated the systems using 10-fold cross-validation.",6 Experiments and Results,[0],[0]
"The feedforward baseline with skip-gram embeddings returns an F-score that is close to the linguistic configuration of Shutova et al, whereas the best results are achieved by the similarity network with skip-gram embeddings.",6 Experiments and Results,[0],[0]
"In this setting, the attribute-based representations did not improve performance – this is expected, as the attribute norms by McRae et al. (2005) are designed for nouns, whereas the MOH dataset is centered on verbs.
",6 Experiments and Results,[0],[0]
"Table 5 contains examples from the TSV development set, together with gold annotations and predicted scores.",6 Experiments and Results,[0],[0]
"The system confidently detects literal phrases such as sunny country and meaningless discussion, along with metaphorical phrases such as unforgiving heights and blind hope.",6 Experiments and Results,[0],[0]
"The predicted output disagrees with the annotation on
cases such as humane treatment and rich programmer – some of these examples could also be argued as being metaphorical, depending on the specific sense of the words.",6 Experiments and Results,[0],[0]
"While the system was relatively unsure about the false positives (the scores were close to 0.5), it tended to assign more decisive scores to the false negatives.",6 Experiments and Results,[0],[0]
"Results in Section 6 show that performance on the TSV dataset is higher than the MOH dataset, likely due to the former having more examples available for training.",7 The Effects of Training Data,[0],[0]
"Therefore, we ran an additional experiment to investigate the effect of dataset size on the performance of metaphor detection.",7 The Effects of Training Data,[0],[0]
"Gutiérrez et al. (2016) annotated a dataset of adjective-noun phrases as being literal or metaphorical, and we are able to use this as an additional training resource.",7 The Effects of Training Data,[0],[0]
"While it contains only 23 unique adjectives, the total number of phrases reaches 8,592.",7 The Effects of Training Data,[0],[0]
"We remove any phrases that occur in the development or test data of TSV, then incrementally add the remaining examples to the TSV training data and evaluate on the TSV-TEST.
",7 The Effects of Training Data,[0],[0]
"Figure 2 shows a graph of the system performance, when increasing the training data at intervals of 500.",7 The Effects of Training Data,[0],[0]
"There is a very rapid increase in performance until around 2,000 training points, whereas the existing TSV-TRAIN is limited to 1,336 examples.",7 The Effects of Training Data,[0],[0]
Providing even more data to the system gives an additional increase that is more gradual.,7 The Effects of Training Data,[0],[0]
"The final performance of the system us-
ing both datasets is 88.3 F-score, which is the highest result reported on the TSV dataset and translates to 36% relative error reduction with respect to the same system trained only on the original dataset.
",7 The Effects of Training Data,[0],[0]
We report the exact values in Table 6 for the different training sets.,7 The Effects of Training Data,[0],[0]
"The value on the Tsvetkov training data is different from the result in Table 3, which is due to the original attribute embeddings by Bulat et al. (2017) only containing representations for the vocabulary in the TSV dataset.",7 The Effects of Training Data,[0],[0]
"In order to include the data from Gutiérrez et al. (2016), we recreated the attribute vectors for a larger vocabulary, which results in a slightly different baseline performance.",7 The Effects of Training Data,[0],[0]
"The architecture in Section 3 also acts as a semantic composition model, extracting the meaning of the phrase by combining the meanings of its component words.",8 Qualitative analysis,[0],[0]
"Therefore, we performed a qualitative experiment to investigate: (1) how well do traditional compositional methods capture metaphors, without any fine-tuning; and (2) whether the supervised representations still retain their domain-specific semantic information.",8 Qualitative analysis,[0],[0]
"For this purpose, we construct three vector spaces and visualise some examples from the TSV training set,
using t-SNE (Van Der Maaten and Hinton, 2008).",8 Qualitative analysis,[0],[0]
"Figure 3 contains examples for three different composition methods: the additive method simply sums the skip-gram embeddings for both words (top); the multiplicative method multiplies the skip-gram embeddings (middle); the final system uses layer m from the SSN model to represent the
phrases (bottom).",8 Qualitative analysis,[0],[0]
"The visualisation shows that the additive and multiplicative models are both comparable when it comes to semantic clustering of the phrases, but metaphorical examples are mixed together with literal clusters.",8 Qualitative analysis,[0],[0]
The SSN is optimised for metaphor classification and therefore it produces representations with a very clear boundary for metaphoricity.,8 Qualitative analysis,[0],[0]
"Interestingly, the graph also reveals a misannotated example in the dataset, since ‘fiery temper’ should be labeled as a metaphor.",8 Qualitative analysis,[0],[0]
"At the same time, this space also retains the general semantic information, as similar phrases with the same label are still positioned close together.",8 Qualitative analysis,[0],[0]
"Future work could investigate models of multi-task training where metaphor detection is trained together with an unsupervised objective, allowing the system to take better advantage of unlabeled data while still learning to separate metaphors.",8 Qualitative analysis,[0],[0]
"In this paper, we introduced the first deep learning architecture designed to capture metaphorical composition and evaluated it on a metaphor identification task.
",9 Conclusion,[0],[0]
"Firstly, we demonstrated that the proposed framework outperforms both a metaphor-agnostic baseline (a feed-forward neural network) as well as previous corpus-driven approaches to metaphor identification.",9 Conclusion,[0],[0]
"The results showed that it is beneficial to construct a specialised network architecture for metaphor detection, which includes a gating function for capturing the interaction between the source and target domains, word embeddings mapped to a metaphor-specific space, and optimisation using a hinge loss function.
",9 Conclusion,[0],[0]
"Secondly, our qualitative analysis indicates that our supervised similarity network learns phrase representations with a very clear boundary for metaphoricity, in contrast to traditional compositional methods.
",9 Conclusion,[0],[0]
"Finally, we show that with a sufficiently large training set our model can also outperform the state-of-the art metaphor identification systems based on hand-coded lexical knowledge.",9 Conclusion,[0],[0]
Ekaterina Shutova’s research is supported by the Leverhulme Trust Early Career Fellowship.,Acknowledgments,[0],[0]
The ubiquity of metaphor in our everyday communication makes it an important problem for natural language understanding.,abstractText,[0],[0]
"Yet, the majority of metaphor processing systems to date rely on handengineered features and there is still no consensus in the field as to which features are optimal for this task.",abstractText,[0],[0]
"In this paper, we present the first deep learning architecture designed to capture metaphorical composition.",abstractText,[0],[0]
Our results demonstrate that it outperforms the existing approaches in the metaphor identification task.,abstractText,[0],[0]
Grasping the Finer Point: A Supervised Similarity Network for Metaphor Detection,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4778–4784 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4778",text,[0],[0]
"Neural machine translation (NMT) (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2014) has now achieved impressive performance (Wu et al., 2016; Gehring et al., 2017; Vaswani et al., 2017; Hassan et al., 2018; Chen et al., 2018; Lample et al., 2018) and draws more attention.",1 Introduction,[0],[0]
"NMT models are built on the encoder-decoder framework where the encoder network encodes the source sentence to distributed representations and the decoder network reconstructs the target sentence form the representations word by word.
",1 Introduction,[0],[0]
"Currently, NMT models are usually trained with the word-level loss (i.e., cross-entropy) under the teacher forcing algorithm (Williams and Zipser,
*Corresponding Author
1989), which forces the model to generate translation strictly matching the ground-truth at the word level.",1 Introduction,[0],[0]
"However, in practice it is impossible to generate translation totally the same as ground truth.",1 Introduction,[0],[0]
"Once different target words are generated, the word-level loss cannot evaluate the translation properly, usually under-estimating the translation.",1 Introduction,[0],[0]
"In addition, the teacher forcing algorithm suffers from the exposure bias (Ranzato et al., 2015) as it uses different inputs at training and inference, that is ground-truth words for the training and previously predicted words for the inference.",1 Introduction,[0],[0]
"Kim and Rush (2016) proposed a method of sequence-level knowledge distillation, which use teacher outputs to direct the training of student model, but the student model still have no access to its own predicted words.",1 Introduction,[0],[0]
"Scheduled sampling(SS) (Bengio et al., 2015; Venkatraman et al., 2015) attempts to alleviate the exposure bias problem through mixing ground-truth words and previously predicted words as inputs during training.",1 Introduction,[0],[0]
"However, the sequence generated by SS may not be aligned with the target sequence, which is inconsistent with the word-level loss.
",1 Introduction,[0],[0]
"In contrast, sequence-level objectives, such as BLEU (Papineni et al., 2002), GLEU (Wu et al., 2016), TER (Snover et al., 2006), and NIST (Doddington, 2002), evaluate translation at the sentence or n-gram level and allow for greater flexibility, and thus can mitigate the above problems of the word-level loss.",1 Introduction,[0],[0]
"However, due to the nondifferentiable of sequence-level objectives, previous works on sequence-level training (Ranzato et al., 2015; Shen et al., 2016; Bahdanau et al., 2016; Wu et al., 2016; He et al., 2016; Wu et al., 2017; Yang et al., 2017) mainly rely on reinforcement learning algorithms (Williams, 1992; Sutton et al., 2000) to find an unbiased gradient estimator for the gradient update.",1 Introduction,[0],[0]
"Sparse rewards in this situation often cause the high variance of gradient estimation, which consequently leads to unstable
training and limited improvements.",1 Introduction,[0],[0]
"Lamb et al. (2016); Gu et al. (2017); Ma et al. (2018) respectively use the discriminator, critic and bag-of-words target as sequence-level training objectives, all of which are directly connected to the generation model and hence enable direct gradient update.",1 Introduction,[0],[0]
"However, these methods do not allow for direct optimization with respect to evaluation metrics.
",1 Introduction,[0],[0]
"In this paper, we propose a method to combine the strengths of the word-level and sequencelevel training, that is the direct gradient update without gradient estimation from word-level training and the greater flexibility from sequence-level training.",1 Introduction,[0],[0]
"Our method introduces probabilistic ngram matching which makes sequence-level objectives (e.g., BLEU, GLEU) differentiable.",1 Introduction,[0],[0]
"During training, it abandons teacher forcing and performs greedy search instead to take into consideration the predicted words.",1 Introduction,[0],[0]
Experiment results show that our method significantly outperforms word-level training with the cross-entropy loss and sequence-level training under the reinforcement framework.,1 Introduction,[0],[0]
The experiments also indicate that greedy search strategy indeed has superiority over teacher forcing.,1 Introduction,[0],[0]
"NMT is based on an end-to-end framework which directly models the translation probability from the source sentence x to the target sentence ŷ:
",2 Background,[0],[0]
"P (ŷ|x) = T∏ j=1 p(ŷj |ŷ<j ,x, θ), (1)
where T is the target length and θ is the model parameters.",2 Background,[0],[0]
"Given the training set D = {XM,YM} withM sentences pairs, the training objective is to maximize the log-likelihood of the training data as
θ = argmax θ {L(θ)}
L(θ) = M∑ m=1 lm∑ j=1 log(p(ŷmj |ŷm<j ,xm, θ)), (2)
where the superior m indicates the m-th sentence in the dataset and lm is the length of m-th target sentence.
",2 Background,[0],[0]
"In the above model, the probability of each target word p(ŷmj |ŷm<j ,xm, θ) is conditioned on the previous target words.",2 Background,[0],[0]
"The scenario is that in the
training time, the teacher forcing algorithm is employed and the ground truth words from the target sentence are fed as context, while during inference, the ground truth words are not available and the previous predicted words are instead fed as context.",2 Background,[0],[0]
This discrepancy is called exposure bias.,2 Background,[0],[0]
"Many automatic evaluation metrics of machine translation, such as BLEU, GLEU and NIST, are based on the n-gram matching.",3.1 Sequence-Level Objectives,[0],[0]
Assuming that y and ŷ are the output sentence and the ground truth sentence with length T and T ′,3.1 Sequence-Level Objectives,[0],[0]
"respectively, the count of an n-gram g = (g1, . . .",3.1 Sequence-Level Objectives,[0],[0]
", gn) in sentence y is calculated as
Cy(g) =",3.1 Sequence-Level Objectives,[0],[0]
T−n∑ t=0 n∏ i=1,3.1 Sequence-Level Objectives,[0],[0]
"1{gi = yt+i}, (3)
where 1{·} is the indicator function.",3.1 Sequence-Level Objectives,[0],[0]
"The matching count of the n-gram g between ŷ and y is given by
Cŷy(g) = min (Cy(g),Cŷ(g)).",3.1 Sequence-Level Objectives,[0],[0]
"(4)
Then the precision pn and the recall rn of the predicted n-grams are calculated as follows
pn =
∑ g∈y C
ŷ",3.1 Sequence-Level Objectives,[0],[0]
"y(g)∑
g∈y Cy(g) , (5)
",3.1 Sequence-Level Objectives,[0],[0]
"rn =
∑ g∈y C
ŷ y(g)∑
g∈ŷ Cŷ(g) .",3.1 Sequence-Level Objectives,[0],[0]
"(6)
BLEU, the most widely used metric for machine translation evaluation, is defined based on the n-gram precision as follows
BLEU = BP · exp( N∑ n=1",3.1 Sequence-Level Objectives,[0],[0]
"wn log pn), (7)
where BP stands for the brevity penalty",3.1 Sequence-Level Objectives,[0],[0]
and wn is the weight for the n-gram.,3.1 Sequence-Level Objectives,[0],[0]
"In contrast, GLEU is the minimum of recall and precision of 1-4 grams where 1-4 grams are counted together:
GLEU =",3.1 Sequence-Level Objectives,[0],[0]
"min(p1-4, r1-4).",3.1 Sequence-Level Objectives,[0],[0]
(8),3.1 Sequence-Level Objectives,[0],[0]
"In the output sentence y, the prediction probability varies among words.",3.2 probabilistic Sequence-Level Objectives,[0],[0]
"Some words are translated by the model with high confidence while some words are translated with high uncertainty.
",3.2 probabilistic Sequence-Level Objectives,[0],[0]
"However, when calculating the count of n-grams in Eq.(3), all the words in the output sentence are treated equally, regardless of their respective prediction probabilities.
",3.2 probabilistic Sequence-Level Objectives,[0],[0]
"To give a more precise description of n-gram counts which considers the variety of prediction probabilities, we use the prediction probability p(yj |y<j ,x, θ) as the count of word yj , and correspondingly the count of an n-gram is the product of these probabilistic counts of all the words in the n-gram, not one anymore.",3.2 probabilistic Sequence-Level Objectives,[0],[0]
"Then the probabilistic count of g = (g1, . . .",3.2 probabilistic Sequence-Level Objectives,[0],[0]
", gn) is calculated by summing over the output sentence y as
C̃y(g) =",3.2 probabilistic Sequence-Level Objectives,[0],[0]
T−n∑ t=0 n∏ i=1,3.2 probabilistic Sequence-Level Objectives,[0],[0]
"1{gi = yt+i} · p(yt+i|y<t+i,x, θ).",3.2 probabilistic Sequence-Level Objectives,[0],[0]
"(9)
Now the probabilistic sequence-level objective can be got by replacing Cy(g) with C̃y(g) (the tilde over the head indicates the probabilistic version) and keeping the rest unchanged.",3.2 probabilistic Sequence-Level Objectives,[0],[0]
"Here, we take BLEU as an example and show how the probabilistic BLEU (denoted as P-BLEU) is defined.",3.2 probabilistic Sequence-Level Objectives,[0],[0]
"From this purpose, the matching count of n-gram g in Eq.(4) is modified as follows
C̃ ŷ
y(g) = min(C̃y(g),Cŷ(g)).",3.2 probabilistic Sequence-Level Objectives,[0],[0]
"(10)
and the predict precision of n-grams changes into
p̃n =
∑ g∈y C̃ ŷ
y(g)∑ g∈y C̃y(g) .",3.2 probabilistic Sequence-Level Objectives,[0],[0]
"(11)
Finally, the probabilistic BLEU (P-BLEU) is defined as
P-BLEU = BP · exp( N∑ n=1 wn log p̃n), (12)
Probabilistic GLEU (P-GLEU) can be defined in a similar way.",3.2 probabilistic Sequence-Level Objectives,[0],[0]
"Specifically, we denote the probabilistic precision of n-grams as P-Pn.",3.2 probabilistic Sequence-Level Objectives,[0],[0]
"The probabilistic precision is more reasonable than recall since the denominator in Eq.(11) plays a normalization role, so we modify the definition in Eq.(8) and define P-GLEU as simply the probabilistic precision of 1-4 grams.
",3.2 probabilistic Sequence-Level Objectives,[0],[0]
"The general probabilistic loss function is:
L(θ) =",3.2 probabilistic Sequence-Level Objectives,[0],[0]
− M∑ m=1,3.2 probabilistic Sequence-Level Objectives,[0],[0]
"P(ym, ŷm), (13)
where P represents the probabilistic sequencelevel objectives, and ym and ŷm are the predicted translation and the ground truth for the m-th sentence respectively.",3.2 probabilistic Sequence-Level Objectives,[0],[0]
The calculation of the probabilistic objective is illustrated in Figure 1.,3.2 probabilistic Sequence-Level Objectives,[0],[0]
This probabilistic loss can work with decoding strategies such as greedy search and teacher forcing.,3.2 probabilistic Sequence-Level Objectives,[0],[0]
In this paper we employ greedy search rather than teacher forcing so as to use the previously predicted words as context and alleviate the exposure bias problem.,3.2 probabilistic Sequence-Level Objectives,[0],[0]
We carry out experiments on Chinese-to-English translation.1 The training data consists of 1.25M pairs of sentences extracted from LDC corpora2.,4.1 Settings,[0],[0]
Sentence pairs with either side longer than 50 were dropped.,4.1 Settings,[0],[0]
We use NIST 2002 (MT 02) as the validation set and NIST 2003-2006 (MT 03-08) as the test sets.,4.1 Settings,[0],[0]
"We use the case insensitive 4-gram NIST BLEU score (Papineni et al., 2002) for the translation task.
",4.1 Settings,[0],[0]
"We apply our method to an attention-based NMT system (Bahdanau et al., 2014) implemented by Pytorch.",4.1 Settings,[0],[0]
"Both source and target vocabularies are limited to 30K. All word embedding sizes are set to 512, and the sizes of hidden units in both encoder and decoder RNNs are also set to 512.",4.1 Settings,[0],[0]
"All parameters are initialized by uniform distribution over [−0.1, 0.1].",4.1 Settings,[0],[0]
The mini-batch stochastic gradient descent (SGD) algorithm is employed to train the model with batch size of 40.,4.1 Settings,[0],[0]
"In addition, the learning rate is adjusted by adadelta optimizer (Zeiler, 2012) with ρ = 0.95 and = 1e-6.",4.1 Settings,[0],[0]
Dropout is applied on the output layer with dropout rate of 0.5.,4.1 Settings,[0],[0]
The beam size is set to 10.,4.1 Settings,[0],[0]
"Systems We first pretrain the baseline model by maximum likelihood estimation (MLE) and then refine the model using probabilistic sequencelevel objectives, including P-BLEU, P-GLEU and P-P2 (probabilistic 2-gram precision).",4.2 Performance,[0],[0]
"In addition, we reproduce previous works which train the NMT model through minimum risk training (MRT) (Shen et al., 2016) and REINFORCE algo-
1Experiment code: https://github.com/ictnlp/GS4NMT 2The corpora include LDC2002E18, LDC2003E07, LDC2003E14, Hansards portion of LDC2004T07, LDC2004T08 and LDC2005T06.
",4.2 Performance,[0],[0]
"rithm (RF) (Ranzato et al., 2015).",4.2 Performance,[0],[0]
"When reproducing their works, we set BLEU, GLEU and 2-gram precision as training objectives respectively and find out that GLEU yields the best performance.",4.2 Performance,[0],[0]
"In the following, we only report the results with training objective GLEU.",4.2 Performance,[0],[0]
Performance Table 1 shows the translation performance on test sets measured in BLEU score.,4.2 Performance,[0],[0]
"Simply training NMT model by the probabilistic 2-gram precision achieves an improvement of 1.5 BLEU points, which significantly outperforms the reinforcement-based algorithms.",4.2 Performance,[0],[0]
"We also test the precision of other n-grams and their combinations, but do not notice significant improvements over P-P2.",4.2 Performance,[0],[0]
"Notice that our method only changes the loss function, without any modification on model structure and training data.",4.2 Performance,[0],[0]
We use the probabilistic loss to finetune the baseline model rather than training from scratch.,4.3 Why Pretraining,[0],[0]
This is in line with our motivation: to alleviate the exposure bias and make the model exposed to its own output during training.,4.3 Why Pretraining,[0],[0]
"In the very beginning of the training, the model’s translation capability is nearly zero and the generated sentences are often meaningless and do not contain useful information for the training, so it is unreasonable to directly apply the greedy search strategy.",4.3 Why Pretraining,[0],[0]
"Therefore, we first apply the teacher forcing algorithm to pretrain the model, and then we let the model generate the sentences itself and learn from its own outputs.
",4.3 Why Pretraining,[0],[0]
Another reason favoring pretraining is that pretraining can lower the training cost.,4.3 Why Pretraining,[0],[0]
The training cost of the introduced probabilistic loss is about three times higher than the cost of cross entropy.,4.3 Why Pretraining,[0],[0]
"Without pretraining, the training time will be much higher than usual.",4.3 Why Pretraining,[0],[0]
"Otherwise, the training cost is acceptable if the probabilistic loss is only for finetuning.",4.3 Why Pretraining,[0],[0]
"The probabilistic loss, defined in Eq.(13), is computed from the model output y and reference ŷ.",4.4 Effect of Decoding Strategy,[0],[0]
"In this section, we apply two different decoding strategies to generate y: 1.",4.4 Effect of Decoding Strategy,[0],[0]
"teacher forcing, which uses the ground truth as decoder input.",4.4 Effect of Decoding Strategy,[0],[0]
"2. greedy search, which feeds the word with maximum probability.",4.4 Effect of Decoding Strategy,[0],[0]
"By conducting this experiment, we attempt to figure out where the improvements come from: the modification of loss or the mitigation of exposure bias?
",4.4 Effect of Decoding Strategy,[0],[0]
Figure 2 shows the learning curves of the two decoding strategies with training objective P-P2.,4.4 Effect of Decoding Strategy,[0],[0]
Teacher forcing raises about 0.5 BLEU improvements and greedy search outperform the teacher forcing algorithm by nearly 1 BLEU point.,4.4 Effect of Decoding Strategy,[0],[0]
"We conclude that the probabilistic loss has its own advantage even when trained by the teacher forcing algorithm, and greedy search is effective in alleviating the exposure bias.
",4.4 Effect of Decoding Strategy,[0],[0]
Notice that the greedy search strategy highly relys on the probabilistic loss and can not be conducted independently.,4.4 Effect of Decoding Strategy,[0],[0]
Greedy search together with the word-level loss is very similar with the scheduled sampling(SS).,4.4 Effect of Decoding Strategy,[0],[0]
"However, SS is inconsistent with the word-level loss since the word-level loss requires strict alignment between hypothesis and reference, which can only be accomplished by the teacher forcing algorithm.",4.4 Effect of Decoding Strategy,[0],[0]
"In this section, we explore how the probabilistic objective correlates with the real evaluation metric.",4.5 Correlation with Evaluation Metrics,[0],[0]
"We randomly sample 100 pairs of sentences
from the training set and compute their P-GLEU and GLEU scores (Wu et al. (2016) indicates that GLEU have better performance in the sentencelevel evaluation than BLEU).
",4.5 Correlation with Evaluation Metrics,[0],[0]
"Directly computing the correlation between GLEU and P-GLEU gives the correlation coefficient 0.86, which indicates strong correlation.",4.5 Correlation with Evaluation Metrics,[0],[0]
"In addition, we draw the scatter diagram of the 100 pairs of sentences in Figure 3 with GLEU as x-axis and P-GLEU as y-axix.",4.5 Correlation with Evaluation Metrics,[0],[0]
"Figure 3 shows that PGLEU correlates well with GLEU, suggesting that it is reasonable to directly train the NMT model with P-GLEU.",4.5 Correlation with Evaluation Metrics,[0],[0]
"Word-level loss cannot evaluate the translation properly and suffers from the exposure bias, and sequence-level objectives are usually indifferentiable and require gradient estimation.",5 Conclusion,[0],[0]
"We propose probabilistic sequence-level objectives based on ngram matching, which relieve the dependence on gradient estimation and can directly train the NMT model.",5 Conclusion,[0],[0]
Experiment results show that our method significantly outperforms previous sequence-level training works and successfully alleviates the exposure bias through performing greedy search.,5 Conclusion,[0],[0]
We thank the anonymous reviewers for their insightful comments.,6 Acknowledgments,[0],[0]
This work was supported by the National Natural Science Foundation of China (NSFC) under the project NO.61472428 and the project NO. 61662077.,6 Acknowledgments,[0],[0]
"Neural machine translation (NMT) models are usually trained with the word-level loss using the teacher forcing algorithm, which not only evaluates the translation improperly but also suffers from exposure bias.",abstractText,[0],[0]
"Sequence-level training under the reinforcement framework can mitigate the problems of the word-level loss, but its performance is unstable due to the high variance of the gradient estimation.",abstractText,[0],[0]
"On these grounds, we present a method with a differentiable sequence-level training objective based on probabilistic n-gram matching which can avoid the reinforcement framework.",abstractText,[0],[0]
"In addition, this method performs greedy search in the training which uses the predicted words as context just as at inference to alleviate the problem of exposure bias.",abstractText,[0],[0]
Experiment results on the NIST Chinese-to-English translation tasks show that our method significantly outperforms the reinforcement-based algorithms and achieves an improvement of 1.5 BLEU points on average over a strong baseline system.,abstractText,[0],[0]
Greedy Search with Probabilistic N-gram Matching for Neural Machine Translation,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1881–1890 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1881",text,[0],[0]
"Many key linguistic tasks, within and across languages or domains, including machine translation, rely on learning cross-lingual correspondences between words or other semantic units.",1 Introduction,[0],[0]
"While the associated alignment problem could be solved with access to large amounts of parallel data, broader applicability relies on the ability to do so with largely mono-lingual data, from Part-of-Speech (POS) tagging (Zhang et al., 2016), dependency parsing (Guo et al., 2015), to machine translation (Lample et al., 2018).",1 Introduction,[0],[0]
"The key subtask of bilingual lexical induction, for example, while long standing as a problem (Fung, 1995; Rapp, 1995, 1999), has been actively pursued recently (Artetxe et al., 2016; Zhang et al., 2017a; Conneau et al., 2018).
",1 Introduction,[0],[0]
"Current methods for learning cross-domain correspondences at the word level rely on distributed representations of words, building on the observation that mono-lingual word embeddings exhibit
similar geometric properties across languages Mikolov et al. (2013).",1 Introduction,[0],[0]
"While most early work assumed some, albeit minimal, amount of parallel data (Mikolov et al., 2013; Dinu et al., 2014; Zhang et al., 2016), recently fully-unsupervised methods have been shown to perform on par with their supervised counterparts (Conneau et al., 2018; Artetxe et al., 2018).",1 Introduction,[0],[0]
"While successful, the mappings arise from multiple steps of processing, requiring either careful initial guesses or postmapping refinements, including mitigating the effect of frequent words on neighborhoods.",1 Introduction,[0],[0]
"The associated adversarial training schemes can also be challenging to tune properly (Artetxe et al., 2018).
",1 Introduction,[0],[0]
"In this paper, we propose a direct optimization approach to solving correspondences based on recent generalizations of optimal transport (OT).",1 Introduction,[0],[0]
"OT is a general mathematical toolbox used to evaluate correspondence-based distances and establish mappings between probability distributions, including discrete distributions such as point-sets.",1 Introduction,[0],[0]
"However, the nature of mono-lingual word embeddings renders the classic formulation of OT inapplicable to our setting.",1 Introduction,[0],[0]
"Indeed, word embeddings are estimated primarily in a relational manner to the extent that the algorithms are naturally interpreted as metric recovery methods (Hashimoto et al., 2016).",1 Introduction,[0],[0]
"In such settings, previous work has sought to bypass this lack of registration by jointly optimizing over a matching and an orthogonal mapping (Rangarajan et al., 1997; Zhang et al., 2017b).",1 Introduction,[0],[0]
"Due to the focus on distances rather than points, we instead adopt a relational OT formulation based on the Gromov-Wasserstein distance that measures how distances between pairs of words are mapped across languages.",1 Introduction,[0],[0]
"We show that the resulting mapping admits an efficient solution and requires little or no tuning.
",1 Introduction,[0],[0]
"In summary, we make the following contributions:
• We propose the use of the GromovWasserstein distance to learn correspondences between word embedding spaces in a fully-unsupervised manner, leading to a theoretically-motivated optimization problem that can be solved efficiently, robustly, in a single step, and requires no post-processing or heuristic adjustments.
",1 Introduction,[0],[0]
"• To scale up to large vocabularies we realize an extended mapping to words not part of the original optimization problem.
",1 Introduction,[0],[0]
"• We show that the proposed approach performs on par with state-of-the-art neural network based methods on benchmark word translation tasks, while requiring a fraction of the computational cost and/or hyperparameter tuning.",1 Introduction,[0],[0]
"In the unsupervised bilingual lexical induction problem we consider two languages with vocabularies Vx and Vy, represented by word embeddings X = {x(i)}ni=1 and Y = {y(j)}mj=1, respectively, where x(i) ∈ X ⊂",2 Problem Formulation,[0],[0]
Rdx corresponds to wxi ∈,2 Problem Formulation,[0],[0]
Vx and y(j) ∈,2 Problem Formulation,[0],[0]
Y ⊂,2 Problem Formulation,[0],[0]
Rdy to wyj ∈ Vy.,2 Problem Formulation,[0],[0]
"For simplicity, we let m = n and dx = dy, although our methods carry over to the general case with little or no modifications.",2 Problem Formulation,[0],[0]
"Our goal is to learn an alignment between these two sets of words without any parallel data, i.e., we learn to relate x(i) ↔ y(j) with the implication that wxi translates to w y j .
",2 Problem Formulation,[0],[0]
"As background, we begin by discussing the problem of learning an explicit map between embeddings in the supervised scenario.",2 Problem Formulation,[0],[0]
The associated training procedure will later be used for extending unsupervised alignments (Section 3.2).,2 Problem Formulation,[0],[0]
"In the supervised setting, we learn a map T : X → Y such that T (x(i))",2.1 Supervised Maps: Procrustes,[0],[0]
≈ y(j) whenever wyj is a translation of wxi .,2.1 Supervised Maps: Procrustes,[0],[0]
"Let X and Y be the matrices whose columns are vectors x(i) and y(j), respectively.",2.1 Supervised Maps: Procrustes,[0],[0]
"Then we can find T by solving
min T∈F ‖X− T (Y)‖2F (1)
",2.1 Supervised Maps: Procrustes,[0],[0]
"where ‖ · ‖F is the Frobenius norm ‖A‖F =√∑ i,j |aij |2.",2.1 Supervised Maps: Procrustes,[0],[0]
"Naturally, both the difficulty of finding T and the quality of the resulting alignment depend on the choice of space F .",2.1 Supervised Maps: Procrustes,[0],[0]
"A classic
approach constrains T to be orthonormal matrices, i.e., rotations and reflections, resulting in the orthogonal Procrustes problem
min P∈O(n)
‖X−PY‖2F (2)
where O(n) = {P ∈ Rn×n | P>P = I}.",2.1 Supervised Maps: Procrustes,[0],[0]
"One key advantage of this formulation is that it has a closed-form solution in terms of a singular value decomposition (SVD), whereas for most other choices of constraint set F it does not.",2.1 Supervised Maps: Procrustes,[0],[0]
"Given an SVD decomposition UΣV> of XY>, the solution to problem (2) is P∗",2.1 Supervised Maps: Procrustes,[0],[0]
"= UV> (Schönemann, 1966).",2.1 Supervised Maps: Procrustes,[0],[0]
"Besides obvious computational advantage, constraining the mapping between spaces to be orthonormal is justified in the context of word embedding alignment because orthogonal maps preserve angles (and thus distances), which is often the only information used by downstream tasks (e.g., for nearest neighbor search) that rely on word embeddings.",2.1 Supervised Maps: Procrustes,[0],[0]
"(Smith et al., 2017) further show that orthogonality is required for self-consistency of linear transformations between vector spaces.
",2.1 Supervised Maps: Procrustes,[0],[0]
"Clearly, the Procrustes approach only solves the supervised version of the problem as it requires a known correspondence between the columns of X and Y. Steps beyond this constraint include using small amounts of parallel data (Zhang et al., 2016) or an unsupervised technique as the initial step to generate pseudo-parallel data (Conneau et al., 2018) before solving for P.",2.1 Supervised Maps: Procrustes,[0],[0]
"Optimal transport formalizes the problem of finding a minimum cost mapping between two point sets, viewed as discrete distributions.",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"Specifically, we assume two empirical distributions over embeddings, e.g.,
µ = n∑
i=1 piδx(i) , ν = m∑ j=1 qjδy(i) (3)
where p and q are vectors of probability weights associated with each point set.",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"In our case, we usually consider uniform weights, e.g., pi = 1/n and qj = 1/m, although if additional information were provided (such as in the form of word frequencies), those could be naturally incorporated via p and q (see discussion at the end of Section 3).",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"We find a transportation map T realizing
inf T {∫ X c(x, T (x))dµ(x)",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"| T#µ = ν } , (4)
where the cost c(x, T (x)) is typically just ‖x − T (x)‖ and T#µ = ν implies that the source points must exactly map to the targets.",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"However, such a map need not exist in general and we instead follow a relaxed Kantorovich’s formulation.",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"In this case, the set of transportation plans is a polytope:
Π(p,q) =",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"{Γ ∈ Rn×m+ | Γ1n = p, Γ>1n = q}.
",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"The cost function is given as a matrix C ∈ Rn×m, e.g., Cij = ‖x(i)",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
− y(j)‖.,2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"The total cost incurred by Γ is 〈Γ, C〉 := ∑ ij ΓijCij .",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"Thus, the discrete optimal transport (DOT) problem consists of finding a plan Γ that solves
min Γ∈Π(p,q)
〈Γ,C〉.",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"(5)
Problem (5) is a linear program, and thus can be solved exactly in O(n3 log n) with interior point methods.",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"However, regularizing the objective leads to more efficient optimization and often better empirical results.",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"The most common such regularization, popularized by Cuturi (2013), involves adding an entropy penalization:
min Γ∈Π(p,q)
〈Γ,C〉 − λH(Γ).",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"(6)
The solution of this strictly convex optimization problem has the form Γ∗ = diag (a)Kdiag (b), with K = e− C λ (element-wise), and can be obtained efficiently via the Sinkhorn-Knopp algorithm, a matrix-scaling procedure which iteratively computes:
a← p Kb and b← q",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"K>a, (7)
where denotes entry-wise division.",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"The derivation of these updates is immediate from the form of Γ∗ above, combined with the marginal constraints Γ1n = p, Γ>1n",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
= q,2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"(Peyré and Cuturi, 2018).
",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"Although simple, efficient and theoreticallymotivated, a direct application of discrete OT for unsupervised word translation is not appropriate.",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"One reason is that the mono-lingual embeddings are estimated in a relative manner, leaving, e.g., an overall rotation unspecified.",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
Such degrees of freedom can dramatically change the entries of the cost matrix Cij = ‖x(i) − y(j)‖ and the resulting transport map.,2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"One possible solution is to simultaneously learn an optimal coupling and an orthogonal transformation (Zhang et al., 2017b).",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"The transport problem is then solved iteratively, using
Cij = ‖x(i) − Py(j)‖, where P is in turn chosen to minimize the transport cost (via Procrustes).",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"While promising, the resulting iterative approach is sensitive to initialization, perhaps explaining why Zhang et al. (2017b) used an adversarially learned mapping as the initial step.",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"The computational cost can also be prohibitive (Artetxe et al., 2018) though could be remedied with additional development.
",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"We adopt a theoretically well-founded generalization of optimal transport for pairs of points (their distances), thus in line with how the embeddings are estimated in the first place.",2.2 Unsupervised Maps: Optimal Transport,[0],[0]
We explain the approach in detail in the next Section.,2.2 Unsupervised Maps: Optimal Transport,[0],[0]
"In this section we introduce the GromovWasserstein distance, describe an optimization algorithm for it, and discuss how to extend the approach to out-of-sample vectors.",3 Transporting across unaligned spaces,[0],[0]
The classic optimal transport requires a distance between vectors across the two domains.,3.1 The Gromov Wasserstein Distance,[0],[0]
"Such a metric may not be available, for example, when the sample sets to be matched do not belong to the same metric space (e.g., different dimension).",3.1 The Gromov Wasserstein Distance,[0],[0]
"The Gromov-Wasserstein distance (Mémoli, 2011) generalizes optimal transport by comparing the metric spaces directly instead of samples across the spaces.",3.1 The Gromov Wasserstein Distance,[0],[0]
"In other words, this framework operates on distances between pairs of points calculated within each domain and measures how these distances compare to those in the other domain.",3.1 The Gromov Wasserstein Distance,[0],[0]
"Thus, it requires a weaker but easy to define notion of distance between distances, and operates on pairs of points, turning the problem from a linear to a quadratic one.
",3.1 The Gromov Wasserstein Distance,[0],[0]
"Formally, in its discrete version, this framework considers two measure spaces expressed in terms of within-domain similarity matrices (C,p) and (C′,q) and a loss function defined between similarity pairs: L : R × R → R, where L(Cik, C ′jl) measures the discrepancy between the distances d(x(i),x(k)) and d′(y(j),y(l)).",3.1 The Gromov Wasserstein Distance,[0],[0]
"Typical choices for L are L(a, b) = 12(a",3.1 The Gromov Wasserstein Distance,[0],[0]
"− b)
2 or L(a, b) = KL(a|b).",3.1 The Gromov Wasserstein Distance,[0],[0]
"In this framework, L(Cik, C ′jl) can also be understood as the cost of “matching” i to j and k to l.
All the relevant values of L(·, ·) can be put in a 4-th order tensor L ∈ RN1×N1×N2×N2 , where Lijkl = L(Cik, C ′ jl).",3.1 The Gromov Wasserstein Distance,[0],[0]
"As before, we seek a cou-
pling Γ specifying how much mass to transfer between each pair of points from the two spaces.",3.1 The Gromov Wasserstein Distance,[0],[0]
"The Gromov-Wasserstein problem is then defined as solving
GW(C,C′,p,q) = min Γ∈Π(p,q) ∑",3.1 The Gromov Wasserstein Distance,[0],[0]
"i,j,k,l LijklΓijΓkl (8)
Compared to problem (5), this version is substantially harder since the objective is now not only non-linear, but non-convex too.1 In addition, it requires operating on a fourth-order tensor, which would be prohibitive in most settings.",3.1 The Gromov Wasserstein Distance,[0],[0]
"Surprisingly, this problem can be optimized efficiently with first-order methods, whereby each iteration involves solving a traditional optimal transport problem (Peyré et al., 2016).",3.1 The Gromov Wasserstein Distance,[0],[0]
"Furthermore, for suitable choices of loss function L, Peyré et al. (2016) show that instead of the O(N21N 2 2 ) complexity implied by naive fourthorder tensor product, this computation reduces to O(N21N2 + N1N 2 2 ) cost.",3.1 The Gromov Wasserstein Distance,[0],[0]
"Their approach consists of solving (5) by projected gradient descent, which yields iterations that involve projecting onto Π(p,q) a pseudo-cost matrix of the form
ĈΓ(C,C ′,Γ) =",3.1 The Gromov Wasserstein Distance,[0],[0]
Cxy,3.1 The Gromov Wasserstein Distance,[0],[0]
− h1(C)Γh2(C′)>,3.1 The Gromov Wasserstein Distance,[0],[0]
"(9)
where
Cxy = f1(C)p1 > m + 1nq >f2(C ′)>
and f1, f2, h2, h2 are functions that depend on the loss L. We provide an explicit algorithm for the case L = L2 at the end of this section.
",3.1 The Gromov Wasserstein Distance,[0],[0]
"1In fact, the discrete (Monge-type) formulation of the problem is essentially an instance of the well-known (and NP-hard) quadratic assignment problem (QAP).
",3.1 The Gromov Wasserstein Distance,[0],[0]
"Once we have solved (8), the optimal transport coupling Γ∗ provides an explicit (soft) matching between source and target samples, which for the problem of interest can be interpreted as a probabilistic translation: for every pair of words (w (i) src, w (j) trg), Γ ∗ ij provides a likelihood that these two words are translations of each other.",3.1 The Gromov Wasserstein Distance,[0],[0]
"This itself is enough to translate, and we show in the experiments section that Γ∗ by itself, without any further post-processing, provides highquality translations.",3.1 The Gromov Wasserstein Distance,[0],[0]
"This stands in sharp contrast to mapping-based methods, which rely on nearest-neighbor computation to infer translations, and thus become prone to hub-word effects which have to be mitigated with heuristic postprocessing techniques such as Inverted Softmax (Smith et al., 2017) and Cross-Domain Similarity Scaling (CSLS) (Conneau et al., 2018).",3.1 The Gromov Wasserstein Distance,[0],[0]
"The transportation coupling Γ, being normalized by construction, requires no such artifacts.
",3.1 The Gromov Wasserstein Distance,[0],[0]
"The Gromov-Wasserstein problem (8) possesses various desirable theoretical properties, including the fact that for a suitable choice of the loss function it is indeed a distance:
Theorem 3.1 (Mémoli 2011).",3.1 The Gromov Wasserstein Distance,[0],[0]
"With the choice L = L2, GW 1 2 is a distance on the space of metric measure spaces.
",3.1 The Gromov Wasserstein Distance,[0],[0]
"Solving problem (8) therefore yields a fascinating accompanying notion: the GromovWasserstein distance between languages, a measure of semantic discrepancy purely based on the relational characterization of their word embeddings.",3.1 The Gromov Wasserstein Distance,[0],[0]
"Owing to Theorem 3.1, such values can be
interpreted as distances, so that, e.g., the triangle inequality holds among them.",3.1 The Gromov Wasserstein Distance,[0],[0]
"In Section 4.4 we compare various languages in terms of their GWdistance.
",3.1 The Gromov Wasserstein Distance,[0],[0]
"Finally, we note that whenever word frequency counts are available, those would be used for p and q.",3.1 The Gromov Wasserstein Distance,[0],[0]
"If they are not, but words are sorted according to occurrence (as they often are in popular off-the-shelf embedding formats), one can estimate rank-probabilities such as Zipf power laws, which are known to accurately model multiple languages (Piantadosi, 2014).",3.1 The Gromov Wasserstein Distance,[0],[0]
"In order to provide a fair comparison to previous work, throughout our experiments we use uniform distributions so as to avoid providing our method with additional information not available to others.",3.1 The Gromov Wasserstein Distance,[0],[0]
"While the pure Gromov-Wasserstein approach leads to high quality solutions, it is best suited to small-to-moderate vocabulary sizes,2 since its optimization becomes prohibitive for very large problems.",3.2 Scaling Up,[0],[0]
"For such settings, we propose a twostep approach in which we first match a subset of the vocabulary via the optimal coupling, after which we learn an orthogonal mapping through a modified Procrustes problem.",3.2 Scaling Up,[0],[0]
"Formally, suppose we solve problem (8) for a reduced matrices X1:k and Yi:k consisting of the first columns k of X and Y, respectively, and let Γ∗ be the optimal coupling.",3.2 Scaling Up,[0],[0]
"We seek an orthogonal matrix that best recovers the barycentric mapping implied by Γ∗. Namely, we seek to find P which solves:
min P∈O(n)
‖XΓ∗ −PY‖22 (10)
Just as problem (2), it is easy to show that this Procrustes-type problem has a closed form solution in terms of a singular value decomposition.",3.2 Scaling Up,[0],[0]
"Namely, the solution to (10) is P∗ = UV>, where UΣV∗ = X1:mΓ
∗Y>1:m. After obtaining this projection, we can immediately map the rest of the embeddings via ŷ(j)",3.2 Scaling Up,[0],[0]
"= P∗y(j).
",3.2 Scaling Up,[0],[0]
We point out that this two-step procedure resembles that of Conneau et al. (2018).,3.2 Scaling Up,[0],[0]
"Both ultimately produce an orthogonal mapping obtained by solving a Procrustes problems, but they differ in the way they produce pseudo-matches to allow for such second-step: while their approach relies
2As shown in the experimental section, we are able to run problems of size in the order of |Vs| ≈ 105",3.2 Scaling Up,[0],[0]
"≈ |Vt| on a single machine without relying on GPU computation.
",3.2 Scaling Up,[0],[0]
"Algorithm 1 Gromov-Wasserstein Computation for Word Embedding Alignment
Input: Source and target embeddings X, Y. Regularization λ.",3.2 Scaling Up,[0],[0]
"Probability vectors p,q. //",3.2 Scaling Up,[0],[0]
Compute intra-language similarities,3.2 Scaling Up,[0],[0]
"Cs ← cos(X,X), Ct ← cos(Y,Y) Cst ← C2sp1>m + 1nq(C2t )> while not converged",3.2 Scaling Up,[0],[0]
"do
//",3.2 Scaling Up,[0],[0]
Compute pseudo-cost matrix (Eq. (9)),3.2 Scaling Up,[0],[0]
ĈΓ ← Cst − 2CsΓC>t //,3.2 Scaling Up,[0],[0]
Sinkhorn iterations (Eq. (7)),3.2 Scaling Up,[0],[0]
"a← 1, K← exp{−ĈΓ/λ} while not converged do a← p Kb, b← q",3.2 Scaling Up,[0],[0]
"K>a end while Γ← diag (a)Kdiag (b)
end while //",3.2 Scaling Up,[0],[0]
"Optional step: Learn explicit projection U,Σ,V> ← SVD(XΓY>)",3.2 Scaling Up,[0],[0]
"P = UV> return Γ,P
on an adversarially-learned transformation, we use an explicit optimization problem.
",3.2 Scaling Up,[0],[0]
We end this section by discussing parameter and configuration choices.,3.2 Scaling Up,[0],[0]
"To leverage the fast algorithm of Peyré et al. (2016), we always use the L2 distance as the loss function L between cost matrices.",3.2 Scaling Up,[0],[0]
"On the other hand, we observed throughout our experiments that the choice of cosine distance as the metric in both spaces consistently leads to better results, which agrees with common wisdom on computing distances between word embeddings.",3.2 Scaling Up,[0],[0]
This leaves us with a single hyperparameter to control: the entropy regularization term λ.,3.2 Scaling Up,[0],[0]
"By applying any sensible normalization on the cost matrices (e.g., dividing by the mean or median value), we are able to almost entirely eliminate sensitivity to that parameter.",3.2 Scaling Up,[0],[0]
"In practice, we use a simple scheme in all experiments: we first try the same fixed value (λ = 5× 10−5), and if the regularization proves too small (by leading to floating point errors), we instead use λ = 1× 10−4.",3.2 Scaling Up,[0],[0]
We never had to go beyond these two values in all our experiments.,3.2 Scaling Up,[0],[0]
We emphasize that at no point we use train (let alone test) supervision available with many datasets—model selection is done solely in terms of the unsupervised objective.,3.2 Scaling Up,[0],[0]
Pseudocode for the full method (with L = L2 and cosine similarity) is shown here as Algorithm 1.,3.2 Scaling Up,[0],[0]
"Through this experimental evaluation we seek to: (i) understand the optimization dynamics of the proposed approach (§4.2), evaluate its performance on benchmark cross-lingual word embedding tasks (§4.3), and (iii) qualitatively investigate the notion of distance-between-languages it computes (§4.4).",4 Experiments,[0],[0]
"Rather than focusing solely on prediction accuracy, we seek to demonstrate that the proposed approach offers a fast, principled, and robust alternative to state-of-the-art multi-step methods, delivering comparable performance.",4 Experiments,[0],[0]
Datasets We evaluate our method on two standard benchmark tasks for cross-lingual embeddings.,4.1 Evaluation Tasks and Methods,[0],[0]
"First, we consider the dataset of Conneau et al. (2018), which consists of word embeddings trained with FASTTEXT (Bojanowski et al., 2017) on Wikipedia and parallel dictionaries for 110 language pairs.",4.1 Evaluation Tasks and Methods,[0],[0]
"Here, we focus on the language pairs for which they report results: English (EN) from/to Spanish (ES), French (FR), German (DE), Russian (RU) and simplified Chinese (ZH).",4.1 Evaluation Tasks and Methods,[0],[0]
"We do not report results on Esperanto (EO) as dictionaries for that language were not provided with the original dataset release.
",4.1 Evaluation Tasks and Methods,[0],[0]
"For our second set of experiments, we consider the—substantially harder3—dataset of (Dinu et al., 2014), which has been extensively compared against in previous work.",4.1 Evaluation Tasks and Methods,[0],[0]
"It consists of embeddings and dictionaries in four pairs of languages; EN from/to ES, IT, DE, and FI (Finnish).
",4.1 Evaluation Tasks and Methods,[0],[0]
"3We discuss the difference in hardness of these two benchmark datasets in Section 4.3.
",4.1 Evaluation Tasks and Methods,[0],[0]
"Methods To see how our fully-unsupervised method compares with methods that require (some) cross-lingual supervision, we follow (Conneau et al., 2018) and consider a simple but strong baseline consisting of solving a procrustes problem directly using the available cross-lingual embedding pairs.",4.1 Evaluation Tasks and Methods,[0],[0]
We refer to this method simply as PROCRUSTES.,4.1 Evaluation Tasks and Methods,[0],[0]
"In addition, we compare against the fully-unsupervised methods of Zhang et al. (2017a), Artetxe et al. (2018) and Conneau et al. (2018).4 As proposed by the latter, we use CSLS whenever nearest neighbor search is required, which has been shown to improve upon naive nearest-neighbor retrieval in multiple work.",4.1 Evaluation Tasks and Methods,[0],[0]
"As previously mentioned, our approach involves only two optimization choices, one of which is required only for very large settings.",4.2 Training Dynamics of G-W,[0],[0]
"When running Algorithm 1 for the full set of embeddings is infeasible (due to memory limitations), one must decide what fraction of the embeddings to use during optimization.",4.2 Training Dynamics of G-W,[0],[0]
"In our experiments, we use the largest possible size allowed by memory constraints, which was found to be K = 20, 000 for the personal computer we used.
",4.2 Training Dynamics of G-W,[0],[0]
The other—more interesting—optimization choice involves the entropy regularization parameter λ used within the Sinkhorn iterations.,4.2 Training Dynamics of G-W,[0],[0]
"Large regularization values lead to denser optimal coupling Γ∗, while less regularization leads to sparser solutions,5 at the cost of a harder (more
4Despite its relevance, we do not include the OT-based method of Zhang et al. (2017b) in the comparison because their implementation required use of proprietary software.
",4.2 Training Dynamics of G-W,[0],[0]
"5In the limit λ→ 0, when n = m, the solution converges
non-convex) optimization problem.",4.2 Training Dynamics of G-W,[0],[0]
In Figure 2 we show the training dynamics of our method when learning correspondences between word embeddings from the dataset of Conneau et al. (2018).,4.2 Training Dynamics of G-W,[0],[0]
"As expected, larger values of λ lead to smoother improvements with faster runtime-per-iteration, at a price of some drop in performance.",4.2 Training Dynamics of G-W,[0],[0]
"In addition, we found that computing GW distances between closer languages (such as EN and FR) leads to faster convergence than for more distant ones (such as EN and RU, in Fig. 2c).
",4.2 Training Dynamics of G-W,[0],[0]
"Worth emphasizing are three desirable optimization properties that set apart the GromovWasserstein distance from other unsupervised alignment approaches, particularly adversarialtraining ones: (i) the objective decreases monotonically (ii) its value closely follows the true metric of interest (translation, which naturally is not available during training) and (iii) there is no risk of degradation due to overtraining, as is the case for adversarial-based methods trained with stochastic gradient descent (Conneau et al., 2018).",4.2 Training Dynamics of G-W,[0],[0]
We report the results on the dataset of Conneau et al. (2018) in Table 1.,4.3 Benchmark Results,[0],[0]
The strikingly high performance of all methods on this task belies the hardness of the general problem of unsupervised cross-lingual alignment.,4.3 Benchmark Results,[0],[0]
"Indeed, as pointed out by Artetxe et al. (2018), the FASTTEXT embeddings provided in this task are trained on very large and highly comparable—across languages— corpora (Wikipedia), and focuses on closely related pairs of languages.",4.3 Benchmark Results,[0],[0]
"Nevertheless, we carry out experiments here to have a broad evaluation of our approach in both easier and harder settings.
",4.3 Benchmark Results,[0],[0]
"Next, we present results on the more challeng-
to a permutation matrix, which gives a hard-matching solution to the transportation problem (Peyré and Cuturi, 2018).
",4.3 Benchmark Results,[0],[0]
"ing dataset of (Dinu et al., 2014) in Table 2.",4.3 Benchmark Results,[0],[0]
"Here, we rely on the results reported by (Artetxe et al., 2018) since by the time of writing the present work their implementation was not available yet.
",4.3 Benchmark Results,[0],[0]
"Part of what makes this dataset hard is the wide discrepancy between word distance across languages, which translates into uneven distance matrices (Figure 3), and in turn leads to poor results for G-W. To account for this, previous work has relied on an initial whitening step on the embeddings.",4.3 Benchmark Results,[0],[0]
"In our case, it suffices to normalize the pairwise similarity matrices to the same range to obtain substantially better results.",4.3 Benchmark Results,[0],[0]
"While we have observed that careful choice of the regularization parameter λ can obviate the need for this step, we opt for the normalization approach since it allows us to optimize without having to tune λ.
",4.3 Benchmark Results,[0],[0]
"We compare our method (with and without nor-
malization) against alternative approaches in Table 2.",4.3 Benchmark Results,[0],[0]
"Note that we report the runtimes of Artetxe et al. (2018) as-is, which are obtained by running on a Titan XP GPU, while our runtimes are, as before, obtained purely by CPU computation.",4.3 Benchmark Results,[0],[0]
"As mentioned earlier, Theorem 3.1 implies that the optimal value of the Gromov-Wasserstein problem can be legitimately interpreted as a distance between languages, or more explicitly, between their word embedding spaces.",4.4 Qualitative Results,[0],[0]
This distributional notion of distance is completely determined by pairwise geometric relations between these vectors.,4.4 Qualitative Results,[0],[0]
"In Figure 4 we show the values GW(Cs,Ct,p,q) computed on the FASTTEXT word embeddings of Conneau et al. (2018) corresponding to the most frequent 2000 words in each language.
",4.4 Qualitative Results,[0],[0]
"Overall, these distances conform to our intuitions: the cluster of romance languages exhibits some of the shortest distances, while classical Chinese (ZH) has the overall largest discrepancy with all other languages.",4.4 Qualitative Results,[0],[0]
"But somewhat surprisingly, Russian is relatively close to the romance languages in this metric.",4.4 Qualitative Results,[0],[0]
We conjecture that this could be due to Russian’s rich morphology (a trait shared by romance languages but not English).,4.4 Qualitative Results,[0],[0]
"Furthermore, both Russian and Spanish are prodrop languages (Haspelmath, 2001) and share syntactic phenomena, such as dative subjects (Moore and Perlmutter, 2000; Melis et al., 2013) and differential object marking (Bossong, 1991), which might explain why ES is closest to RU overall.
",4.4 Qualitative Results,[0],[0]
"On the other hand, English appears remarkably isolated from all languages, equally distant from its germanic (DE) and romance (FR) cousins.",4.4 Qualitative Results,[0],[0]
"Indeed, other aspects of the data (such as corpus size) might be underlying these observations.",4.4 Qualitative Results,[0],[0]
Study of the problem of bilingual lexical induction goes back to Rapp (1995) and Fung (1995).,5 Related Work,[0],[0]
"While the literature on this topic is extensive, we focus here on recent fully-unsupervised and minimallysupervised approaches, and refer the reader to one of various existing surveys for a broader panorama (Upadhyay et al., 2016; Ruder et al., 2017).
",5 Related Work,[0],[0]
Methods with coarse or limited parallel data.,5 Related Work,[0],[0]
"Most of these fall in one of two categories: methods that learn a mapping from one space to the other, e.g., as a least-squares objective (e.g., (Mikolov et al., 2013)) or via orthogonal transformations Zhang et al. (2016); Smith et al. (2017); Artetxe et al. (2016), and methods that find a com-
mon space on which to project both sets of embeddings (Faruqui and Dyer, 2014; Lu et al., 2015).
",5 Related Work,[0],[0]
Fully Unsupervised methods.,5 Related Work,[0],[0]
Conneau et al. (2018) and Zhang et al. (2017a) rely on adversarial training to produce an initial alignment between the spaces.,5 Related Work,[0],[0]
The former use pseudo-matches derived from this initial alignment to solve a Procrustes (2) alignment problem.,5 Related Work,[0],[0]
"Our GromovWasserstein framework can be thought of as providing an alternative to these adversarial training steps, albeit with a concise optimization formulation and producing explicit matches (via the optimal coupling) instead of depending on nearest neighbor search, as the adversarially-learnt mappings do.
",5 Related Work,[0],[0]
Zhang et al. (2017b) also leverage optimal transport distances for the cross-lingual embedding task.,5 Related Work,[0],[0]
"However, to address the issue of nonalignment of embedding spaces, their approach follows the joint optimization of the transportation and procrustes problem as outlined in Section 2.2.",5 Related Work,[0],[0]
"This formulation makes an explicit modeling assumption (invariance to unitary transformations), and requires repeated solution of Procrustes problems during alternating minimization.",5 Related Work,[0],[0]
"GromovWasserstein, on the other hand, is more flexible and makes no such assumption, since it directly deals with similarities rather than vectors.",5 Related Work,[0],[0]
"In the case where it is required, such an orthogonal mapping can be obtained by solving a single procrustes problem, as discussed in Section 3.2.",5 Related Work,[0],[0]
In this work we provided a direct optimization approach to cross-lingual word alignment.,6 Discussion and future work,[0],[0]
The Gromov-Wasserstein distance is well-suited for this task as it performs a relational comparison of word-vectors across languages rather than wordvectors directly.,6 Discussion and future work,[0],[0]
"The resulting objective is concise, and can be optimized efficiently.",6 Discussion and future work,[0],[0]
"The experimental results show that the resulting alignment framework is fast, stable and robust, yielding near stateof-the-art performance at a computational cost orders of magnitude lower than that of alternative fully unsupervised methods.
",6 Discussion and future work,[0],[0]
"While directly solving Gromov-Wasserstein problems of reasonable size is feasible, scaling up to large vocabularies made it necessary to learn an explicit mapping via Procrustes.",6 Discussion and future work,[0],[0]
GPU computations or stochastic optimization could help avoid this secondary step.,6 Discussion and future work,[0],[0]
The authors would like to thank the anonymous reviewers for helpful feedback.,Acknowledgments,[0],[0]
"The work was partially supported by MIT-IBM grant “Adversarial learning of multimodal and structured data”, and Graduate Fellowships from Hewlett Packard and CONACYT.",Acknowledgments,[0],[0]
Cross-lingual or cross-domain correspondences play key roles in tasks ranging from machine translation to transfer learning.,abstractText,[0],[0]
"Recently, purely unsupervised methods operating on monolingual embeddings have become effective alignment tools.",abstractText,[0],[0]
"Current state-of-theart methods, however, involve multiple steps, including heuristic post-hoc refinement strategies.",abstractText,[0],[0]
"In this paper, we cast the correspondence problem directly as an optimal transport (OT) problem, building on the idea that word embeddings arise from metric recovery algorithms.",abstractText,[0],[0]
"Indeed, we exploit the GromovWasserstein distance that measures how similarities between pairs of words relate across languages.",abstractText,[0],[0]
"We show that our OT objective can be estimated efficiently, requires little or no tuning, and results in performance comparable with the state-of-the-art in various unsupervised word translation tasks.",abstractText,[0],[0]
Gromov-Wasserstein Alignment of Word Embedding Spaces,title,[0],[0]
"In this paper, we focus on the multi-term nonsmooth convex composite optimization
min x∈X f(x) + n∑ i=1",1. Introduction,[0],[0]
gi(x),1. Introduction,[0],[0]
", (1)
where X is a linear space, gi : X → (−∞,+∞] is a proper, lower semicontinuous convex function for all i = 1, · · · , n, and f : X → (−∞,+∞) is a continuous
1Tencent AI Lab, China 2Sun Yat-sen University, China 3The Chinese University of Hong Kong, China.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
Li Shen,1. Introduction,[0],[0]
"<mathshenli@gmail.com>, Wei Liu <wliu@ee.columbia.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"differentiable convex function with its gradient satisfying the inequality that
1
L ∥∥∇f(x)−∇f(y)∥∥2 ≤ 〈∇f(x)−∇f(y), x− y〉. (2)",1. Introduction,[0],[0]
"The above multi-term nonsmooth convex composite optimization problem (1) covers a large class of applications in machine learning such as simultaneous low-rank and sparsity (Richard et al., 2012; Zhou et al., 2013), overlapping group Lasso (Zhao et al., 2009; Jacob et al., 2009; Mairal et al., 2010), graph-guided fused Lasso (Chen et al., 2012; Kim & Xing, 2009), graph-guided logistic regression (Chen et al., 2011; Zhong & Kwok, 2014), variational image restoration (Combettes & Pesquet, 2011; Dupé et al., 2009; Pustelnik et al., 2011), and other types of structure regularization paradigms (Teo et al., 2010; 2007).",1. Introduction,[0],[0]
"By introducing the multi-term nonsmooth regularization term∑n i=1 gi(x) such as structured sparsity (Huang et al., 2011; Bach et al., 2012; Bach, 2010) and nonnegativity (Chen & Plemmons, 2015; Xu & Yin, 2013), more prior information can be included to enhance the accuracy of regularization models.",1. Introduction,[0],[0]
"However, due to the multi-term nonsmooth regularization term ∑n i=1 gi(x), the optimization problem (1) is too complicated to be solved even for small n. For n ≤ 2, some existing popular first-order optimization methods are accelerated proximal gradient method (Beck & Teboulle, 2009; Nesterov, 2007), smoothing accelerated proximal gradient method (Nesterov, 2005a;b), three operator splitting method (Davis & Yin, 2015), and some primal-dual operator splitting methods such as majorized alternating direction method of multiplier (ADMM) (Cui et al., 2016; Lin et al., 2011), fast proximity method (Li & Zhang, 2016), and so on.
",1. Introduction,[0],[0]
"On the other hand, when n ≥ 3, there also exist some algorithms for solving problem (1).",1. Introduction,[0],[0]
"A directly method for (1) is smoothing accelerated proximal gradient (S-APG) proposed by Nesterov (Nesterov, 2005a;b).",1. Introduction,[0],[0]
"Then, Yu (Yu, 2013) proposed a new approximation method called PAAPG for handling (1) by combining the proximal average approximation technique and Nesterov’s acceleration technique, which has been enhanced very recently by Shen et al. (Shen et al., 2017).",1. Introduction,[0],[0]
Their proposed method called APA-APG adopts an adaptive stepsize strategy.,1. Introduction,[0],[0]
"However,
the above mentioned methods S-APG, PA-APG and its enhanced version APA-APG all need a strict restriction on the nonsmooth functions {gi(x)} that each gi(x) must be Lipschitz continuous.",1. Introduction,[0],[0]
"In addition, some primal-dual parallel splitting methods (Briceno-Arias et al., 2011; Combettes & Pesquet, 2007; 2008; Condat, 2013; Vũ, 2013) generalized from traditional operator splitting, such as forward backward splitting method (Chen & Rockafellar, 1997) and Douglas Rachford splitting method (Eckstein & Bertsekas, 1992), can also solve the multi-term nonsmooth convex composite optimization problem (1).",1. Introduction,[0],[0]
"Different from prior work, Raguet et al. (Raguet et al., 2013) proposed an efficient primal operator splitting method called generalized forward backward splitting method using the classic forward backward splitting technique, which has shown the superiority over numerous existing primal-dual splitting methods (Monteiro & Svaiter, 2013; Combettes & Pesquet, 2012; Chambolle & Pock, 2011) in dealing with variational image restoration problems.",1. Introduction,[0],[0]
All the above mentioned methods for problem (1) with n ≥ 3 share a common feature that they all split the nonsmooth composite term∑n i=1,1. Introduction,[0],[0]
gi(x),1. Introduction,[0],[0]
"in the Jacobi iteration manner, i.e., parallelly.",1. Introduction,[0],[0]
"This is one of the main differences between existing splitting methods and our proposed method in this paper.
",1. Introduction,[0],[0]
"To split the nonsmooth composite term ∑n i=1 gi(x) more efficiently, we propose a novel operator splitting algorithm to solve problem (1) by harnessing the advantage of GaussSeidel iterations, i.e., the computation of the proximal mapping of the current function gi(x) uses the proximal mappings of gj(x) for all j < i which have already been computed ahead.",1. Introduction,[0],[0]
"In addition, to further improve the algorithm’s efficiency, we leverage the over-relaxation acceleration technique.",1. Introduction,[0],[0]
"What’s more, we provide a new strategy that the over-relaxation stepsize can be determined adaptively, ensuring a larger value to accelerate the algorithm.",1. Introduction,[0],[0]
The most important is that the convergence of our proposed GSOS algorithm is established by a newly developed analysis technique.,1. Introduction,[0],[0]
"In detail, given an invertible linear operator R, we first argue that the optimal solution set [∇f + ∑n i=1 ∂gi] −1 (0) of problem (1) can be recovered
by the zero point set [ (R∗)−1SR, ∂g+A◦∇f◦A,NV ]−1 (0).",1. Introduction,[0],[0]
"This is fulfilled through adopting the tool of operator optimization theory, in which the composite operator SR, ∂g+A◦∇f◦A,NV is generalized from the definition of the composite monotone operator Sλ,A,B in (Eckstein & Bertsekas, 1992).",1. Introduction,[0],[0]
"Next, by unitizing the definition of the -enlargement of maximal monotone (Burachik et al., 1998; 1997; Burachik & Svaiter, 1999; Svaiter, 2000), we establish a key property for SR, ∂g+A◦∇f◦A,NV , that is, gph ( SR, (∂g+A∗◦∇f◦A)[",1. Introduction,[0],[0]
"],NV )",1. Introduction,[0],[0]
"⊆
gph ( R∗[(R∗)−1SR, ∂g+A∗◦∇f◦A,NV ]",1. Introduction,[0],[0]
[ ] ) .,1. Introduction,[0],[0]
"Based on this observation, we equivalently reformulate the GSOS algorithm as a two-step iterations algorithm.",1. Introduction,[0],[0]
"Then, the
global convergence of the proposed GSOS algorithm is easily established based on this reformulation.
",1. Introduction,[0],[0]
"The closest algorithm to our proposed GSOS algorithm is the generalized forward backward splitting method proposed by Raguet et al. (Raguet et al., 2013).",1. Introduction,[0],[0]
"By carefully selecting the scaling matrix H in the forthcoming GSOS algorithm, it is easy to check that GSOS covers the generalized forward backward splitting method as a special case.",1. Introduction,[0],[0]
"Another highly related algorithm to our proposed GSOS algorithm is the matrix splitting method (Luo & Tseng, 1991; Yuan et al., 2016).",1. Introduction,[0],[0]
"Choosing the scaling matrixH suitably, the proposed GSOS algorithm can inherit the advantage of the matrix splitting technique which has shown the efficiency in (Yuan et al., 2016) for coping with a special class of coordinate separable composite optimization problems.
",1. Introduction,[0],[0]
The rest of this paper is organized as follows.,1. Introduction,[0],[0]
"In Section 2, we first give the definitions of some useful notations which can make the paper much more readable.",1. Introduction,[0],[0]
"We also establish some lemmas and propositions based on monotone operator theory (Bauschke & Combettes, 2011), which are the key to the convergence of the GSOS algorithm.",1. Introduction,[0],[0]
"In Section 3, we present the proposed GSOS algorithm and then analyze its convergence and iteration complexity.",1. Introduction,[0],[0]
"In Section 4, we conduct numerical experiments on overlapping group Lasso and graph-guided fused Lasso problems to evaluate the efficacy of the GSOS algorithm.",1. Introduction,[0],[0]
"Finally, we draw conclusions in Section 5.",1. Introduction,[0],[0]
Let Y = ∏n i=1,2. Preliminaries and Notations,[0],[0]
"Xi be the product space of Xi with Xi = X for all i ∈ {1, 2, · · · , n}.",2. Preliminaries and Notations,[0],[0]
Let V be a linear space and V⊥ be its complementary space with the following definitions V=,2. Preliminaries and Notations,[0],[0]
{ y ∈ Y | y1 = · · ·,2. Preliminaries and Notations,[0],[0]
"= yn } , V⊥= { y ∈ Y |
n∑ i yi = 0 } .
",2. Preliminaries and Notations,[0],[0]
Let IX : X → X be the identity map and EY : X → Y be a block linear operator defined as EY =( IX · · · IX )∗ .,2. Preliminaries and Notations,[0],[0]
Let A : Y → X be a linear operator defined as Ay = 1nE ∗,2. Preliminaries and Notations,[0],[0]
Yy,2. Preliminaries and Notations,[0],[0]
= 1 n ∑n i=1 yi.,2. Preliminaries and Notations,[0],[0]
"Hence, its adjoint operator A∗ : X → Y is defined as A∗x = 1nEYx.",2. Preliminaries and Notations,[0],[0]
"Let H,R : Y → Y be block lower triangular linear invertible operators satisfying (R∗)−1 = H and H + H∗ 0.",2. Preliminaries and Notations,[0],[0]
"Moreover,H is defined as H1,1 0 · · · 0 ... . . .",2. Preliminaries and Notations,[0],[0]
"...
...",2. Preliminaries and Notations,[0],[0]
"Hn−1,1 · · · Hn−1,n−1 0",2. Preliminaries and Notations,[0],[0]
"Hn,1 · · ·",2. Preliminaries and Notations,[0],[0]
"Hn−1,n Hn,n  , (3) where Hi,j : X → X is a linear operator for all (i, j) ∈ {1, · · · , n}.",2. Preliminaries and Notations,[0],[0]
It is worthwhile to emphasize that,2. Preliminaries and Notations,[0],[0]
"Hi,i is also possible to be a lower triangular linear operator satisfying
Hi,i +H∗i,i 0.",2. Preliminaries and Notations,[0],[0]
"Next, we abuse the notation ‖ · ‖H which is induced by the inner product 〈·,H·〉 satisfying
‖ · ‖H : = √ 〈·,H·〉 = √ 〈·,H∗·〉
= √ 〈·, H+H ∗
2 ·〉 = ‖ · ‖H+H∗ 2 .",2. Preliminaries and Notations,[0],[0]
"(4)
In addition, we define the generalized proximal mapping of a proper, lower semicontinuous convex function gi(x) with respect to the invertible linear operatorHi,i.
Definition 1 For a given x, the proximal mapping denoted by ProxH−1i,i gi(x) of a proper, lower semicontinuous convex function gi with respect to an invertible linear operator",2. Preliminaries and Notations,[0],[0]
"Hi,i satisfying Hi,i + H∗i,i 0 is defined to be the zero point of the following inclusion equation
0 ∈ ∂gi(·)",2. Preliminaries and Notations,[0],[0]
"+Hi,i(· − x).",2. Preliminaries and Notations,[0],[0]
"(5)
Moreover, if Hi,i is symmetric, it can be reformulated as the following convex minimization
ProxHi,igi(x) := arg min y∈X
gi(y) + 1
2 ‖y",2. Preliminaries and Notations,[0],[0]
"− x‖2Hi,i .
",2. Preliminaries and Notations,[0],[0]
"Next, we recall the definition of -enlargement of monotone operators (Burachik et al., 1998; 1997; Burachik & Svaiter, 1999; Svaiter, 2000), which is an effective tool for establishing the convergence of the proposed GSOS algorithm.
",2. Preliminaries and Notations,[0],[0]
Definition 2,2. Preliminaries and Notations,[0],[0]
"Given a maximal monotone operator T : X ⇒ X, the (≥ 0)-enlargement of T is defined as the set T",2. Preliminaries and Notations,[0],[0]
"[ ](x) := { v ∈ Y | 〈w − v, z",2. Preliminaries and Notations,[0],[0]
− x〉 ≥,2. Preliminaries and Notations,[0],[0]
"− for all z ∈
X, w ∈ T",2. Preliminaries and Notations,[0],[0]
"(z) } .
",2. Preliminaries and Notations,[0],[0]
Recall that f(x) is a gradient Lipschitz convex function satisfying inequality (2).,2. Preliminaries and Notations,[0],[0]
"There exits 0 Σ Σ̂ LI such that the following two inequalities hold for any x, x′ ∈ X
f(x) ≤ f(x′) + 〈∇f(x′), x− x′〉+ 1 2",2. Preliminaries and Notations,[0],[0]
‖x− x′‖2,2. Preliminaries and Notations,[0],[0]
"Σ̂ , (6) f(x) ≥ f(x′) + 〈∇f(x′), x− x′〉+ 1 2 ‖x− x′‖2Σ. (7)
Actually, when f(x) is a quadratic function, it holds Σ = Σ̂ directly in inequalities (6) and (7).",2. Preliminaries and Notations,[0],[0]
"The following lemma establishes the property of the enlargement of the composite operatorA∗ ◦∇f ◦A with f satisfying inequalities (6)- (7) or (2), which is an essential ingredient for reformulating the GSOS algorithm as a two-step iterations algorithm.
",2. Preliminaries and Notations,[0],[0]
Proposition 1 Assume that f is a gradient Lipschitz continuous convex function satisfying inequality (2).,2. Preliminaries and Notations,[0],[0]
"For any x1, x2 ∈ Y , it holds that
(A∗ ◦ ∇f ◦",2. Preliminaries and Notations,[0],[0]
A)(x2) ∈ (A∗ ◦ ∇f ◦,2. Preliminaries and Notations,[0],[0]
"A)[ ](x1) (8)
with = L4 ‖Ax1−Ax2‖ 2.",2. Preliminaries and Notations,[0],[0]
"In addition, if f further satisfies inequalities (6)-(7), it holds that
(A∗ ◦ ∇f ◦",2. Preliminaries and Notations,[0],[0]
A)(x2) ∈ (A∗ ◦ ∇f ◦,2. Preliminaries and Notations,[0],[0]
"A)[ ](x1) (9)
with = 14‖Ax1 −Ax2‖ 2 2Σ̂−Σ .
",2. Preliminaries and Notations,[0],[0]
"Remark 1 Two comments are made for Proposition 1:
(1)",2. Preliminaries and Notations,[0],[0]
This proposition gives two types of estimations for in( A∗ ◦∇f ◦A ),2. Preliminaries and Notations,[0],[0]
[,2. Preliminaries and Notations,[0],[0]
] in (8) and (9).,2. Preliminaries and Notations,[0],[0]
"When f is a quadratic
function, it is easy to check that
1 4 ‖Ax1 −Ax2‖22Σ̂−Σ ≤",2. Preliminaries and Notations,[0],[0]
L 4,2. Preliminaries and Notations,[0],[0]
‖Ax1,2. Preliminaries and Notations,[0],[0]
"−Ax2‖2
due to Σ̂ = Σ LI.",2. Preliminaries and Notations,[0],[0]
"When f is a general gradient Lipschitz continuous function, we do not know which estimation for is tighter in (8) and (9).
",2. Preliminaries and Notations,[0],[0]
"(2) The second part of this proposition can be regarded as an intensified version of Lemma 2.2 in (Svaiter, 2014) for a specified composite operator A∗ ◦",2. Preliminaries and Notations,[0],[0]
∇f ◦,2. Preliminaries and Notations,[0],[0]
A.,2. Preliminaries and Notations,[0],[0]
"The first part of the proposition coincides with the results by applying Lemma 2.2 in (Svaiter, 2014) for A∗ ◦ ∇f ◦",2. Preliminaries and Notations,[0],[0]
"A.
",2. Preliminaries and Notations,[0],[0]
"Next, we generalize the notation Sλ,T1,T2 in (Eckstein & Bertsekas, 1992) for a given λ > 0 and two maximal monotone operators T1, T2 as SR,T1,T2 for a given invertible linear operatorR defined as
gphSR, T1, T2 (10) := { (x1 +Ry2, x2",2. Preliminaries and Notations,[0],[0]
− x1),2. Preliminaries and Notations,[0],[0]
"| y1 ∈ T1(x1),
y2 ∈ T2(x2), x1 +R∗y1 = x2 −R∗y2 } .
",2. Preliminaries and Notations,[0],[0]
"By (Eckstein & Bertsekas, 1992), we know that Sλ,T1,T2 is maximal monotone if T1 and T2 are both maximal monotone.",2. Preliminaries and Notations,[0],[0]
"However, its generalized operator SR,T1,T2 is not monotone unless the invertible linear operator R reduces to be a constant.",2. Preliminaries and Notations,[0],[0]
"Very interesting, it can be shown that its composition with (R∗)−1, i.e., (R∗)−1SR,T1,T2 , is maximal monotone for any invertible linear operatorR.
Lemma 1 For any given invertible linear operator R, operator (R∗)−1SR,T1,T2 is maximal monotone if T1 and T2 are both maximal monotone operators.
Setting T1 = ∂g + A∗",2. Preliminaries and Notations,[0],[0]
◦ ∇f ◦,2. Preliminaries and Notations,[0],[0]
"A, T2 = NV , we obtain SR, ∂g+A∗◦∇f◦A,NV , which is defined as
gph ( SR,∂g+A∗◦∇f◦A,NV ) (11)
:= { (x1+Ry2, x2−x1)",2. Preliminaries and Notations,[0],[0]
"| y1∈(∂g +A∗ ◦ ∇f ◦ A)(x1),
y2 ∈ NV(x2), x1 +R∗y1 = x2 −R∗y2 } .
",2. Preliminaries and Notations,[0],[0]
"By Lemma 1, we know that (R∗)−1SR, ∂g+A∗◦∇f◦A,NV is maximal monotone due to the maximal monotonicity of ∂g + A∗ ◦",2. Preliminaries and Notations,[0],[0]
∇f ◦,2. Preliminaries and Notations,[0],[0]
A and NV .,2. Preliminaries and Notations,[0],[0]
"Hence, given a constant ≥ 0, the enlargement [(R∗)−1SR, ∂g+A∗◦∇f◦A,NV",2. Preliminaries and Notations,[0],[0]
][ ] is well defined.,2. Preliminaries and Notations,[0],[0]
"In addition, based on the definition of SR,T1,T2 again, we set T1 = ∂g + (A∗ ◦ ∇f ◦",2. Preliminaries and Notations,[0],[0]
"A)[ ], or T1 = (∂g + A∗ ◦",2. Preliminaries and Notations,[0],[0]
∇f ◦,2. Preliminaries and Notations,[0],[0]
A)[ ] and T2 = NV in (10).,2. Preliminaries and Notations,[0],[0]
"Then we have the definition of SR,∂g+(A∗◦∇f◦A)[ ],NV or SR,(∂g+A∗◦∇f◦A)[ ],NV for any given invertible linear operatorR and constant ≥ 0",2. Preliminaries and Notations,[0],[0]
"as follows
gph ( SR,∂g+(A∗◦∇f◦A)",2. Preliminaries and Notations,[0],[0]
"[ ],NV ) (12)
:= { (x1+Ry2, x2−x1)|y1∈(∂g+(A∗◦∇f ◦A)[ ])(x1),
y2 ∈ NV(x2), x1 +R∗y1 = x2 −R∗y2 } ,
gph ( SR,(∂g+A∗◦∇f◦A)[ ],NV ) (13)
:= { (x1+Ry2, x2−x1)|y1∈(∂g +A∗◦∇f ◦A)[ ])(x1),
y2 ∈ NV(x2), x1 +R∗y1 = x2 −R∗y2 } .
",2. Preliminaries and Notations,[0],[0]
"In the proposition below, we will establish the relationships among the above mentioned three operators SR,∂g+(A∗◦∇f◦A)",2. Preliminaries and Notations,[0],[0]
"[ ],NV , SR,(∂g+A∗◦∇f◦A)[ ],NV and [(R∗)−1SR, ∂g+A∗◦∇f◦A,NV ]",2. Preliminaries and Notations,[0],[0]
"[ ].
Proposition 2",2. Preliminaries and Notations,[0],[0]
"Given a constant ≥ 0 and an invertible linear operatorR, it holds that
gph ( SR, ∂g+(A∗◦∇f◦A)[ ],NV ) ⊆ gph ( SR, (∂g+A∗◦∇f◦A)[ ],NV
) ⊆ gph ( R∗[(R∗)−1SR, ∂g+A∗◦∇f◦A,NV",2. Preliminaries and Notations,[0],[0]
],2. Preliminaries and Notations,[0],[0]
"[ ] ) .
In the following, we establish the relationship between the optimal solution set [∇f + ∑n i=1 ∂gi] −1 (0) of prob-
lem (1) and [ (R∗)−1SR, ∂g+A∗◦∇f◦A,NV ]−1 (0), which means that we can recover the solution of problem (1) through [ (R∗)−1SR, ∂g+A∗◦∇f◦A,NV ]−1 (0).
",2. Preliminaries and Notations,[0],[0]
Lemma 2 Let linear operators H and R satisfy (R∗)−1 = H and H satisfy (3).,2. Preliminaries and Notations,[0],[0]
Denote Ω =,2. Preliminaries and Notations,[0],[0]
"[ (R∗)−1SR, (∂g+A∗◦∇f◦A),NV ]−1 (0).",2. Preliminaries and Notations,[0],[0]
"It holds that[ ∇f +
n∑ i=1",2. Preliminaries and Notations,[0],[0]
"∂gi
]−1 (0) = ( ETYH∗EY
)−1ETYH∗(Ω).",2. Preliminaries and Notations,[0],[0]
"In this section, we first propose the Gauss-Seidel operator splitting algorithm for solving the multi-term nonsmooth convex composite problem (1).",3. GSOS Algorithm,[0],[0]
"Then, based on the preliminaries in Section 2, we establish the convergence and iteration complexity of the GSOS algorithm.
",3. GSOS Algorithm,[0],[0]
"Algorithm 1 GSOS Algorithm Parameters: Choose σ ∈ (0, 1), a linear operator H satisfying (3) and a starting point z0 ∈ Z .",3. GSOS Algorithm,[0],[0]
Set θfix1 ∈,3. GSOS Algorithm,[0],[0]
"( − 1, θ1 ] and θfix2 ∈",3. GSOS Algorithm,[0],[0]
"( − 1, θ2 ] , where θ1 and θ2 are
defined via equations (14a) and (14b), respectively.",3. GSOS Algorithm,[0],[0]
"for k = 0, 1, 2, · · · ,K do xk := EY ( ETYHEY )−1ETYHzk; for i = 1, 2 · · · , n do yki := ProxH−1i,i gi ( H−1i,i",3. GSOS Algorithm,[0],[0]
"[ ∑i j=1Hi,j(2xkj − zkj )",3. GSOS Algorithm,[0],[0]
"−
1 n∇f( 1 n ∑n i=1",3. GSOS Algorithm,[0],[0]
x,3. GSOS Algorithm,[0],[0]
k i ),3. GSOS Algorithm,[0],[0]
"− ∑i−1 j=1Hi,jykj ] ) ;
end for set θadap1k as (14c) and θ adap2 k as (14d); set θk ∈",3. GSOS Algorithm,[0],[0]
"[θfix1, θadap1k ]",3. GSOS Algorithm,[0],[0]
"∪ [θfix2, θ adap2 k ]; zk+1 := zk + (1 + θk)(y k − xk);
end for return ωK := ( ETYH∗EY )−1ETYH∗zK .",3. GSOS Algorithm,[0],[0]
"In Algorithm 1, parameters θ1, θ1, θ adap1 k , θ adap1 k are defined as θ1 = max { θ|(θ − σ)(H+H∗) + LA∗A 0 } ; (14a) θ2 = max { θ | (θ − σ)(H+H∗) (14b) +",3. GSOS Algorithm,[0],[0]
A∗(2Σ̂− Σ)A 0 } ; θadap1k = σ,3. GSOS Algorithm,[0],[0]
− L‖A(xk − yk)‖2 ‖xk,3. GSOS Algorithm,[0],[0]
− yk‖2H+H∗ ; (14c) θadap2k,3. GSOS Algorithm,[0],[0]
= σ,3. GSOS Algorithm,[0],[0]
− ‖A(xk,3. GSOS Algorithm,[0],[0]
"− yk)‖2
2Σ̂−Σ ‖xk",3. GSOS Algorithm,[0],[0]
− yk‖2H+H∗ .,3. GSOS Algorithm,[0],[0]
"(14d)
",3. GSOS Algorithm,[0],[0]
Remark 2,3. GSOS Algorithm,[0],[0]
"We make some comments on GSOS below.
",3. GSOS Algorithm,[0],[0]
"(1) For the updating step of xk, we obtain xk = EY (∑K i,j=1Hij )",3. GSOS Algorithm,[0],[0]
"−1∑K j=1 ∑K i=j Hijzkj by using the
notations H and EY .",3. GSOS Algorithm,[0],[0]
"Similarly, we have ωk =(∑K i,j=1Hij )−1∑K j=1 ∑j i=iH∗jizkj .",3. GSOS Algorithm,[0],[0]
"Hence, we need
to compute the inverse of ∑n i,j=1Hi,j .",3. GSOS Algorithm,[0],[0]
"However, if Hi,j is a lower triangular matrix operator, xk and ωk can be obtained easily.
",3. GSOS Algorithm,[0],[0]
"(2) By the definitions of ProxH−1i,i gi and y k, we need to
solve the following inclusion equation
Gki ∈",3. GSOS Algorithm,[0],[0]
"Hi,iyki + ∂gi(yki ),
where Gki = H −1",3. GSOS Algorithm,[0],[0]
"i,i",3. GSOS Algorithm,[0],[0]
"[∑i j=1Hi,j(2xkj − zkj )",3. GSOS Algorithm,[0],[0]
− 1 n∇f( 1 n ∑n i=1 x,3. GSOS Algorithm,[0],[0]
k i ),3. GSOS Algorithm,[0],[0]
"− ∑i−1 j=1Hi,jykj ] .",3. GSOS Algorithm,[0],[0]
"Usually, it is easy to choose a suitable Hi,i such that the solution of the above inclusion equation has a closed form.
",3. GSOS Algorithm,[0],[0]
(3) θk is the over-relaxation stepsize for accelerating the GSOS algorithm.,3. GSOS Algorithm,[0],[0]
"If the computations of θadap1k and θadap2k are time consuming, we can set θk = max{θfix1, θfix2}.
(4) WhenH is a diagonal matrix, i.e.,Hi,j = 0",3. GSOS Algorithm,[0],[0]
"andHi,i = aiI with some nonnegative constant ai, and the over relaxation stepsize θk is fixed to a smaller region, the GSOS algorithm reduces to the generalized forward backward splitting method in (Raguet et al., 2013).
",3. GSOS Algorithm,[0],[0]
"In the following, we reformulate the GSOS algorithm as a two-step iterations algorithm by utilizing monotone optimization theory established in Section 2, which is the key to the convergence of the GSOS algorithm.
",3. GSOS Algorithm,[0],[0]
"Proposition 3 Let g : Y → (−∞,+∞] be the function defined as g(x) = ∑n i=1 gi(xi).",3. GSOS Algorithm,[0],[0]
"Assume that the sequences (xk, yk) and zk are generated by Algorithm 1 with σ ∈ (0, 1).",3. GSOS Algorithm,[0],[0]
Let vk = (R∗)−1(xk − yk) and zk = yk + R(R∗)−1(zk,3. GSOS Algorithm,[0],[0]
− xk).,3. GSOS Algorithm,[0],[0]
"Then, for all k ∈ N, there exists k ≥ 0 such that the iterations in Algorithm 1 can be reformulated as the following two-step iterations algorithm:",3. GSOS Algorithm,[0],[0]
vk ∈,3. GSOS Algorithm,[0],[0]
"[(R∗)−1SR, ∂g+(A∗◦∇f◦A),NV ]",3. GSOS Algorithm,[0],[0]
"[ k](zk), (15a) θk‖R∗vk‖2R−1 + ‖R ∗vk + zk",3. GSOS Algorithm,[0],[0]
"− zk‖2R−1
+2 k ≤",3. GSOS Algorithm,[0],[0]
σ‖zk,3. GSOS Algorithm,[0],[0]
"− zk‖2R−1 , (15b)
",3. GSOS Algorithm,[0],[0]
and zk+1 =,3. GSOS Algorithm,[0],[0]
"zk − (1 + θk)R∗vk.
",3. GSOS Algorithm,[0],[0]
"Remark 3 Based on Proposition 3, the GSOS algorithm can be regarded as an inexact over-relaxed metric proximal point algorithm for the composite inclusion
0 ∈",3. GSOS Algorithm,[0],[0]
"(R∗)−1SR,∂g+A∗◦∇f◦A,NV (z).
",3. GSOS Algorithm,[0],[0]
"By Proposition 3 and Lemma 2, we can establish the convergence of the GSOS algorithm based on the relationship
between the two zero point sets [∇f+ n∑ i=1 ∂gi] −1(0) and Ω.
Theorem 1 Let {(xk, yk, zk)} be the sequence generated by Algorithm 1.",3. GSOS Algorithm,[0],[0]
"We have:
(i) for any z∗ ∈",3. GSOS Algorithm,[0],[0]
"[(R∗)−1SR,∂g+A∗◦∇f◦A,NV ]−1(0), it holds that
‖zk+1",3. GSOS Algorithm,[0],[0]
− z∗‖2R−1 ≤,3. GSOS Algorithm,[0],[0]
‖z,3. GSOS Algorithm,[0],[0]
k,3. GSOS Algorithm,[0],[0]
"− z∗‖2R−1 (16)
− (1− σ)(1 + θk)‖xk − yk‖2R−1 ;
(ii) zk converges to a point belonging to zero point set",3. GSOS Algorithm,[0],[0]
"[(R∗)−1SR,∂g+A∗◦∇f◦A,NV ]−1(0)",3. GSOS Algorithm,[0],[0]
"and ωk converges to a point belonging to [∇f + ∑n i=1 ∂gi] −1 (0), i.e., the optimal solution set
of problem (1).
",3. GSOS Algorithm,[0],[0]
Theorem 1 indicates that ‖xk − yk‖ approaching to zero implies the convergence of the GSOS algorithm.,3. GSOS Algorithm,[0],[0]
"In the theorem below, we measure the convergence rates of two sequences ‖xk − yk‖ and ‖ωk − ωk+1‖.
Theorem 2 Let zk be the sequence generated by the GSOS algorithm.",3. GSOS Algorithm,[0],[0]
"Then, there exists i ∈ {1, 2, · · · , k} such that
‖xi − yi‖2 ≤",3. GSOS Algorithm,[0],[0]
"O (1 k ) ,",3. GSOS Algorithm,[0],[0]
∥∥ωi+1,3. GSOS Algorithm,[0],[0]
"− ωi∥∥2 ≤ O(1 k ) .
",3. GSOS Algorithm,[0],[0]
"Due to the space limit, all proofs of the propositions, lemmas and theorems are placed into the supplementary material.",3. GSOS Algorithm,[0],[0]
"In this section, we apply the proposed algorithm to the overlapping group Lasso (Zhao et al., 2009; Jacob et al., 2009; Mairal et al., 2010) and graph-guided fused Lasso problems (Chen et al., 2012; Kim & Xing, 2009), which can be formulated as
min 1
2 ‖Sx− b‖2 + K∑ i=1",4. Experiments,[0],[0]
gi(x).,4. Experiments,[0],[0]
"(17)
For overlapping group Lasso problem (21), gi(x) = ναi‖xGi‖ andK denotes the number of groups.",4. Experiments,[0],[0]
"For graphguided Lasso problem (25), gi(x) = ναij‖xi−xj‖ and K denotes the number of edges in the graph edge set E.
We describe the detailed techniques in the experimental implementation for (17).",4. Experiments,[0],[0]
"Given a > 12 and a positive definite operator D satisfying D STS, we set
Hi,j = {
1 K2D, i ≥ j ∈ {1, 2, · · · ,K}; a K2D, i = j ∈ {1, 2, · · · ,K}.
(18)
",4. Experiments,[0],[0]
"Hence, it easy to check that H + H∗ = A∗DA + 2a−1 K2 Diag ( EYD ) 0.",4. Experiments,[0],[0]
"Due to the smooth term in overlapping group Lasso (21) is quadratic, the two estimations θ2 and θadap2k in (14b) and (14d) are preferred to be used.",4. Experiments,[0],[0]
"By specific H, we obtain ∑K i,j=1Hi,j =
K(K−1)+2αK 2K2 D and∑K
j=1 ∑K i=j Hi,jzkj = D K2 ∑K j=1(a+K−j)zkj ,which fur-
ther imply xk =",4. Experiments,[0],[0]
"(∑K i,j=1Hi,j )−1∑K j=1 ∑K i=j Hi,jzkj =
2 ∑K j=1(a+K−j)z k j
K(K−1)+2aK .",4. Experiments,[0],[0]
"Moreover, by the positive definiteness of Hi,i and D, it holds that ∑n j=1 ∑j i=iH∗j,izkj =
D K2 ∑K j=1(a + j − 1)zkj .",4. Experiments,[0],[0]
"Hence, we attain ωk =
2 ∑K j=1(a+j−1)z k j
K(K−1)+2aK .",4. Experiments,[0],[0]
"In addition, by the definition of H, we reformulate the estimation (14b) for θk as the following form:
θ = max { θ | EY [ (σ − θ)D − STS ]",4. Experiments,[0],[0]
"E∗Y
+ (2a− 1) ( σ − θ ) Diag(EYD) 0 } .
",4. Experiments,[0],[0]
"Due to a ≥ 12 and the positive definiteness of D, a sufficient condition satisfying the constraint in the above set is{
(σ − θ)D − STS 0, θ ≤ σ }
.",4. Experiments,[0],[0]
"Hence, we have an alternative estimation for θ as
θ = max { θ | (σ − θ)D − STS 0, θ ≤ σ } .",4. Experiments,[0],[0]
"(19)
Similarly, the adaptive stepsize estimation (14d) is reformulated as
θadapk = σ",4. Experiments,[0],[0]
"−
1 2K2 ∥∥∥∥ K∑ i=1",4. Experiments,[0],[0]
(xk − yki ),4. Experiments,[0],[0]
"∥∥∥∥2 STS
K∑ j=1 K∑",4. Experiments,[0],[0]
i=j (xk − yki )THij(xk,4. Experiments,[0],[0]
− ykj ) .,4. Experiments,[0],[0]
"(20)
Therefore, the GSOS algorithm can be specified as the following form for solving problem (17).
",4. Experiments,[0],[0]
Algorithm 2 GSOS Algorithm for Solving Problem (,4. Experiments,[0],[0]
"17) Parameters: Choose σ ∈ (0, 1), positive definite operators D and Hi,j satisfying (18), and a starting point z0 ∈ Z .",4. Experiments,[0],[0]
"Set θ as (19) and θfix ∈ ( − 1, θ1 ] .
for k = 0, 1, 2, · · · , do xk := 2 ∑K j=1(α+K−j)z k j
K(K−1)+2αK ; for i = 1, 2 · · · ,K do yki := ProxH−1i,i gi ( H−1i,i",4. Experiments,[0],[0]
"[ ∑i j=1Hi,j(2xk − zkj )",4. Experiments,[0],[0]
"−
1 KS T (Sxk − b)− ∑i−1 j=1Hi,jykj ] ) ;
end for set θk ∈",4. Experiments,[0],[0]
"[θfixk , θ adap k",4. Experiments,[0],[0]
"], where θ adap k is defined via (20); for j = 1, 2 · · · ,K do zk+1j := z k j + (1 + θk)(y k j − xk);
end for end for return ωN = 2 ∑K j=1(α+j−1)z N j
K(K−1)+2αK .
",4. Experiments,[0],[0]
"In this paper, we compare the proposed GSOS algorithm with four state-of-the-art algorithms below.
",4. Experiments,[0],[0]
"• GFB (Raguet et al., 2013): Generalized Forward Backward (GFB) splitting algorithm is a primal firstorder operator splitting algorithm for solving (1) proposed by Raguet et al. (Raguet et al., 2013), which has been shown to outperform other competing algorithms such as (Monteiro & Svaiter, 2013; Combettes & Pesquet, 2012; Chambolle & Pock, 2011) for variational image restoration.
",4. Experiments,[0],[0]
"• PDM (Condat, 2013):",4. Experiments,[0],[0]
"A first-order Primal-Dual splitting Method (PDM) (Condat, 2013) for solving jointly the primal and dual formulations of large-scale convex minimization problems involving Lipschitz, proximal and linear composite terms.
",4. Experiments,[0],[0]
"• PA-APG (Yu, 2013): Proximal Average approximated Accelerated Proximal Gradient (PA-APG) algorithm (Yu, 2013) is a primal first-order method, which utilizes the proximal average technique (Bauschke et al., 2008) to separate the multi-term nonsmooth function in (1).",4. Experiments,[0],[0]
"It has been shown to outperform the smoothing accelerated proximal gradient method (Nesterov, 2005b;a).
",4. Experiments,[0],[0]
"• APA-APG (Shen et al., 2017):",4. Experiments,[0],[0]
"An enhanced version of PA-APG, which incorporates the Adaptive Proximal Average approximation technique with the Accelerated Proximal Gradient (APA-APG) method to improve the efficiency of the optimization procedure.
",4. Experiments,[0],[0]
"It is worthwhile to emphasize that PA-APG and APA-APG algorithms can only be applied to a specific class of problems (1), in which the multi-term nonsmooth regularization is Lipschitz continuous.",4. Experiments,[0],[0]
"Since the nonsmooth regularization terms in overlapping group Lasso and graph-guided fused Lasso are all exactly Lipschitz continuous, the two efficient solvers PG-APG (Yu, 2013) and its enhanced version APA-APG (Shen et al., 2017) are also compared with the GSOS algorithm to illustrate the efficacy of GSOS.",4. Experiments,[0],[0]
"In the implementation, the approximation parameter for PAAPG is set as 1.0e− 5.",4. Experiments,[0],[0]
"In this subsection, we apply the proposed GSOS algorithm to the overlapping group Lasso problem, which takes the following formal definition:
min 1
2 ‖Sx− b‖2 + ν K∑ i=1 αi‖xGi‖, (21)
where S ∈ Rn×d is the sampling matrix, b is the noisy observation vector, G = {G1, · · · ,GK} denotes the set of overlapping groups (Gi ⊂ {1, · · · , d} satisfying ⋃K i=1",4.1. Overlapping Group Lasso,[0],[0]
"Gi =
{1, · · · , d} and Gi ⋂ Gj 6= ∅",4.1. Overlapping Group Lasso,[0],[0]
"for some i, j), xGi ∈ Rd is a duplication of x with x{1,··· ,d}\Gi = 0, αi is the weight for the i-th group, and ν is the regularization parameter controlling group sparsity.
",4.1. Overlapping Group Lasso,[0],[0]
"During the implementation of Algorithm 2, we need to calculate the generalized proximal mapping of ‖xGi‖ in the updating step of yki .",4.1. Overlapping Group Lasso,[0],[0]
"By the positive definiteness of Hi,i, the calculation of yki in Algorithm 2 is equivalent to solving the following problem:
yki := arg min x
1 2 ‖x− bk‖2Hi,i + ναi‖xGi‖,
where bk = H−1i,i",4.1. Overlapping Group Lasso,[0],[0]
"[∑i j=1Hi,j(2xk − zkj )",4.1. Overlapping Group Lasso,[0],[0]
"− 1 KS
T (Sxk − b)− ∑i−1 j=1Hi,jykj ] .",4.1. Overlapping Group Lasso,[0],[0]
"In the proposition below, given c, diag-
onal positive definite operatprHi,i and group G, we solve
x∗",4.1. Overlapping Group Lasso,[0],[0]
":= arg min x
1 2 ‖x− c‖2Hi,i + ν‖xG‖. (22)
",4.1. Overlapping Group Lasso,[0],[0]
"When Hi,i is identity matrix I, (22) has the closed-form solution
x∗ = { x∗G , i ∈ G, ci, else,
where x∗G",4.1. Overlapping Group Lasso,[0],[0]
"= { (1− ν/‖cG‖)cG , ‖cG‖ ≥ t; 0, else.
",4.1. Overlapping Group Lasso,[0],[0]
"Proposition 4 Let (Hi,i)G be the subdiagonal matrix of Hi,i with the index set G, and t∗ be the optimal solution of the one-dimensional optimization problem
min t≥0
{ 1
2
〈 cG , [ (Hi,i)−1G + 2tI",4.1. Overlapping Group Lasso,[0],[0]
]−1 cG 〉 + tν2 } .,4.1. Overlapping Group Lasso,[0],[0]
"(23)
Hence, the optimal solution of (22) has the following form
x∗ =
{ cG",4.1. Overlapping Group Lasso,[0],[0]
"− [ I + 2t∗(Hi,i)G ]−1 cG , i ∈ G;
ci, else.",4.1. Overlapping Group Lasso,[0],[0]
"(24)
Like (Chen et al., 2012; Yu, 2013), the entries of sampling matrix S ∈ Rn×d are sampled from an i.i.d. normal distribution, and x ∈ Rd with xj = (−1)j exp−(j−1)/100 and d = 90K + 10.",4.1. Overlapping Group Lasso,[0],[0]
"Let ξ be the noise sampled from the standard normal distribution, and the noisy observation satisfies b = Sx + ξ.",4.1. Overlapping Group Lasso,[0],[0]
"In addition, we set ν = 1 and αi = 1K2 for each group Gi and the groups {Gi} are overlapped by 10 elements, that is{
G1 = {1, · · · , 100} G2 = {91, · · · , 190} · · · GK = {d− 99, · · · , d}
} .
",4.1. Overlapping Group Lasso,[0],[0]
"The sampling size and the number of groups (n,K) are chosen from the following set
(n,K) ∈ {
(1000, 20), (2000, 40), (4000, 60), (4000, 80), (5000, 80), (5000, 100)
} .
",4.1. Overlapping Group Lasso,[0],[0]
"To further reduce the computations, in Algorithm 2 we set Hi,i = ‖STS‖I and the over-relaxation stepsize θk as θ in (19).",4.1. Overlapping Group Lasso,[0],[0]
"Hence, the compared five solvers GSOS, GFB, PDM, PA-APG and APA-APG have the same computational cost in each iteration.",4.1. Overlapping Group Lasso,[0],[0]
"To be fair, all the compared algorithms start with the same initial point.",4.1. Overlapping Group Lasso,[0],[0]
"The following six pictures in Figures 1 and 2 display the comparisons of the five solvers for a variety of (n,K).",4.1. Overlapping Group Lasso,[0],[0]
It is apparent that our proposed GSOS algorithm shows great superiorities over the other four solvers.,4.1. Overlapping Group Lasso,[0],[0]
The primal-dual solver PDM is slightly faster than the primal solver GFB.,4.1. Overlapping Group Lasso,[0],[0]
"PA-APG is the slowest algorithm, because the prespecified proximal average approximation precision is 1.0e − 5 which leads to a very small stepsize.",4.1. Overlapping Group Lasso,[0],[0]
"Also, APA-APG is much faster than the other four solvers at the first 50 iterations.",4.1. Overlapping Group Lasso,[0],[0]
"However, it is slowed down since the stepsize used in AP-APG becomes smaller and smaller as the iterations go on.",4.1. Overlapping Group Lasso,[0],[0]
"In this subsection, we perform experiments on graphguided fused Lasso which is formulated as
min 1
2 ‖Sx− b‖2 + ν ∑",4.2. Graph-Guided Fused Lasso,[0],[0]
"(i,j)∈E αij |xi",4.2. Graph-Guided Fused Lasso,[0],[0]
"− xj |, (25)
where αij ≥ 0 is the weight for the fused term ‖xi − xj‖ for all (i, j) ∈ E (E is the given graph edge set), and ν is
the regularization parameter.
",4.2. Graph-Guided Fused Lasso,[0],[0]
"In the implementation of Algorithm 2 for tackling graphguided fused Lasso (25), we need to solve the following optimization in the updating step of yk:
x∗ := arg min x
1 2 ‖x− b‖2Hi,i + ν|xi",4.2. Graph-Guided Fused Lasso,[0],[0]
"− xj |, (26)
whereHi,i is a diagonal positive definite matrix, and b and ν are given constants.",4.2. Graph-Guided Fused Lasso,[0],[0]
"Let hii and hjj be the i-th and j-th diagonal elements ofHi,i, respectively.
",4.2. Graph-Guided Fused Lasso,[0],[0]
"Proposition 5 The optimal solution of (26) takes the following closed-form:
x∗ =  ",4.2. Graph-Guided Fused Lasso,[0],[0]
bl,4.2. Graph-Guided Fused Lasso,[0],[0]
− h −1,4.2. Graph-Guided Fused Lasso,[0],[0]
"ll λ ∗, l = i, bl + h −1",4.2. Graph-Guided Fused Lasso,[0],[0]
"ll λ
∗, l = j, bl, l 6=",4.2. Graph-Guided Fused Lasso,[0],[0]
"i, j,
(27)
where λ∗ is defined as
λ∗ =  bi−bj",4.2. Graph-Guided Fused Lasso,[0],[0]
h−1ii,4.2. Graph-Guided Fused Lasso,[0],[0]
+,4.2. Graph-Guided Fused Lasso,[0],[0]
h −1,4.2. Graph-Guided Fused Lasso,[0],[0]
"jj , ∣∣∣ bi−bj h−1ii",4.2. Graph-Guided Fused Lasso,[0],[0]
+,4.2. Graph-Guided Fused Lasso,[0],[0]
h −1,4.2. Graph-Guided Fused Lasso,[0],[0]
"jj ∣∣∣ ≤ ν; sign (bi − bj) ν, ∣∣∣ bi−bj h−1ii",4.2. Graph-Guided Fused Lasso,[0],[0]
+,4.2. Graph-Guided Fused Lasso,[0],[0]
h −1,4.2. Graph-Guided Fused Lasso,[0],[0]
"jj
∣∣∣ >",4.2. Graph-Guided Fused Lasso,[0],[0]
ν.,4.2. Graph-Guided Fused Lasso,[0],[0]
"In the implementation, we use the similar parameter settings of S, ν as above.",4.2. Graph-Guided Fused Lasso,[0],[0]
"The dimension parameter pair (n, d) is chosen from the following set
(n, d) ∈ {
(2000, 500), (2000, 1000), (5000, 1000), (5000, 2000), (10000, 2000), (10000, 4000)
} ,
and the parameter αi = 100/|E|2.",4.2. Graph-Guided Fused Lasso,[0],[0]
"Similarly, all the compared algorithms start with the same initial point.",4.2. Graph-Guided Fused Lasso,[0],[0]
"The following six pictures in Figures 3 and 4 display the comparisons of the five solvers for six kinds of choices of (n, d).",4.2. Graph-Guided Fused Lasso,[0],[0]
"It
is obvious that the other four solvers GFB, PDM, AP-APG and APA-APG are not as efficient as the proposed GSOS algorithm, which demonstrates that the Gauss-Seidel technique is very useful for addressing nonsmooth optimization.",4.2. Graph-Guided Fused Lasso,[0],[0]
It is worthwhile to point out that the primal solver GFB is faster than the primal-dual solver PDM on graphguided fused Lasso.,4.2. Graph-Guided Fused Lasso,[0],[0]
"One possible reason is that the number of nonsmooth terms is too large, which will lead to a large quantity of dual variables introduced in PDM and hence slow down the updating of primal variables.",4.2. Graph-Guided Fused Lasso,[0],[0]
"In this paper, we proposed a novel first-order algorithm called GSOS for addressing multi-term nonsmooth convex composite optimization.",5. Conclusions,[0],[0]
"This algorithm inherits the advantages of the Gauss-Seidel technique and the operator splitting technique, therefore being largely accelerated.",5. Conclusions,[0],[0]
"We found that the GSOS algorithm includes the generalized forward backward splitting method (Raguet et al., 2013) as a special case.",5. Conclusions,[0],[0]
"In addition, we developed a new technique to establish the global convergence and iteration complexity of the GSOS algorithm.",5. Conclusions,[0],[0]
"Last, we applied the proposed GSOS algorithm to solve overlapping group Lasso and graph-guided fused Lasso problems, and compared it against several state-of-the-art algorithms.",5. Conclusions,[0],[0]
The experimental results show the great superiority of the GSOS algorithm in terms of both efficiency and effectiveness.,5. Conclusions,[0],[0]
Yuan is supported by NSF-China (61402182).,Acknowledgements,[0],[0]
"In this paper, we propose a fast Gauss-Seidel Operator Splitting (GSOS) algorithm for addressing multi-term nonsmooth convex composite optimization, which has wide applications in machine learning, signal processing and statistics.",abstractText,[0],[0]
"The proposed GSOS algorithm inherits the advantage of the Gauss-Seidel technique to accelerate the optimization procedure, and leverages the operator splitting technique to reduce the computational complexity.",abstractText,[0],[0]
"In addition, we develop a new technique to establish the global convergence of the GSOS algorithm.",abstractText,[0],[0]
"To be specific, we first reformulate the iterations of GSOS as a twostep iterations algorithm by employing the tool of operator optimization theory.",abstractText,[0],[0]
"Subsequently, we establish the convergence of GSOS based on the two-step iterations algorithm reformulation.",abstractText,[0],[0]
"At last, we apply the proposed GSOS algorithm to solve overlapping group Lasso and graph-guided fused Lasso problems.",abstractText,[0],[0]
Numerical experiments show that our proposed GSOS algorithm is superior to the state-of-the-art algorithms in terms of both efficiency and effectiveness.,abstractText,[0],[0]
GSOS: Gauss-Seidel Operator Splitting Algorithm for  Multi-Term Nonsmooth Convex Composite Optimization,title,[0],[0]
"↵ (1 e ↵) for cardinality constrained maximization. In addition, we bound the submodularity ratio and curvature for several important real-world objectives, including the Bayesian Aoptimality objective, the determinantal function of a square submatrix and certain linear programs with combinatorial constraints. We experimentally validate our theoretical findings for both synthetic and real-world applications.",text,[0],[0]
"Many important problems, such as experimental design and sparse modeling, are naturally formulated as a subset selection problem, where a set function F (S) over a Kcardinality constraint is maximized, i.e.,
max S✓V,|S|K F (S), (P)
1Department of Computer Science, ETH Zurich, Zurich, Switzerland.",1. Introduction,[0],[0]
"Correspondence to: Joachim M. Buhmann <jbuhmann@inf.ethz.ch>, Andreas Krause <krausea@ethz.ch>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"where V = {v1, . . .",1. Introduction,[0],[0]
", vn} is the ground set.",1. Introduction,[0],[0]
"Specifically, in experimental design, the goal is to select a set of experiments to perform such that some statistical criterion is optimized.",1. Introduction,[0],[0]
This problem arises naturally in domains where performing experiments is costly.,1. Introduction,[0],[0]
"In sparse modeling, the task is to identify sparse representations of signals, enabling interpretability and robustness in high-dimensional statistical problems—properties that are crucial in modern data analysis.
",1. Introduction,[0],[0]
"Frequently, the standard GREEDY algorithm (Alg. 1) is used to (approximately) solve (P).",1. Introduction,[0],[0]
"For the case that F (S)
Algorithm 1: The GREEDY Algorithm Input: Ground set V , set function F : 2V!R+, budget K S
0 ; for t = 1, . . .",1. Introduction,[0],[0]
",K do
v ⇤ argmax v2V\St 1 F (S t 1",1. Introduction,[0],[0]
"[ {v}) F (St 1) S
t St 1 [ {v⇤} Output: SK
is a monotone nondecreasing submodular set function1, the GREEDY algorithm enjoys the multiplicative approximation guarantee of (1 1/e) (Nemhauser et al., 1978; Vondrák, 2008; Krause & Golovin, 2014).",1. Introduction,[0],[0]
"This constant factor can be improved by refining the characterization of the objective using the curvature (Conforti & Cornuéjols, 1984; Vondrák, 2010; Iyer et al., 2013), which informally quantifies how close a submodular function is to being modular (i.e., F (S) and F (S) are submodular).
",1. Introduction,[0],[0]
"However, for many applications, including experimental design and sparse Gaussian processes (Lawrence et al., 2003), F (S) is in general not submodular (Krause et al., 2008) and the above guarantee does not hold.",1. Introduction,[0],[0]
"In practice, however, the standard GREEDY algorithm often achieves very good performance on these applications, e.g., in subset selection with the R2 (squared multiple correlation) ob-
1 F (·) is monotone nondecreasing if 8A ✓ V, v 2 V , F (A [ {v})",1. Introduction,[0],[0]
F (A).,1. Introduction,[0],[0]
F (·) is submodular iff it satisfies the diminishing returns property F (A [ {v}),1. Introduction,[0],[0]
F (A) F (B [ {v}) F (B) for all A ✓ B ✓ V \{v}.,1. Introduction,[0],[0]
Assume wlog.,1. Introduction,[0],[0]
"that F (·) is normalized, i.e., F (;) = 0.
jective (Das & Kempe, 2011).",1. Introduction,[0],[0]
"To explain the good empirical performance, Das & Kempe (2011) proposed the submodularity ratio, a quantity characterizing how close a set function is to being submodular.
",1. Introduction,[0],[0]
"Another important class of non-submodular set functions comes as the auxiliary function when optimizing a continuous function f(x) s.t. combinatorial constraints, i.e., min
x2C,supp(x)2I f(x), where supp(x) := {i | xi 6= 0} is the support set of x, C is a convex set, and I is the independent sets of the combinatorial structure.",1. Introduction,[0],[0]
"One of the most popular ways to solve this problem is to use the GREEDY algorithm to maximize the auxiliary function F (S) : = max
x2C,supp(x)✓S f(x).",1. Introduction,[0],[0]
"This setting covers various important applications, to name a few, feature selection (Guyon & Elisseeff, 2003), sparse approximation (Das & Kempe, 2008; Krause & Cevher, 2010), sparse recovery (Candes et al., 2006), sparse M-estimation (Jain et al., 2014), linear programming (LP) with combinatorial constraints, and column subset selection (Altschuler et al., 2016).",1. Introduction,[0],[0]
"Recently, Elenberg et al. (2016) proved that if f(x) has L-restricted smoothness and m-restricted strong convexity, then the submodularity ratio of F (S) is lower bounded by m/L.",1. Introduction,[0],[0]
"This result significantly enlarges the domain where the GREEDY algorithm can be applied.
",1. Introduction,[0],[0]
"In this paper, we combine and generalize the ideas of curvature and submodularity ratio to derive improved constant factor approximation guarantees of the GREEDY algorithm.",1. Introduction,[0],[0]
Our guarantees allow us to better characterize the empirical success of applying GREEDY on a significantly larger class of non-submodular functions.,1. Introduction,[0],[0]
"Furthermore, we bound these characteristics for important applications, rendering the usage of GREEDY a principled choice rather than a mere heuristic.",1. Introduction,[0],[0]
"Our main contributions are:
- We prove the first tight constant-factor approximation guarantees for GREEDY on maximizing nonsubmodular nondecreasing set functions s.t.",1. Introduction,[0],[0]
"a cardinality constraint, characterized by a novel combination of the (generalized) notions of submodularity ratio and curvature ↵.
- By theoretically bounding parameters ( ,↵) for several important objectives, including Bayesian A-optimality in experimental design, the determinantal function of a square submatrix and maximization of LPs with combinatorial constraints, our theory implies the first guarantees for them.
- Lastly, we experimentally validate our theory on several real-world applications.",1. Introduction,[0],[0]
"It is worth noting that for the Bayesian A-optimality objective, GREEDY generates comparable solutions as the classically used semidefinite programming (SDP) based method, but is usually two orders of magnitude faster.
Notation.",1. Introduction,[0],[0]
"We use boldface letters, e.g., x, to represent vectors, and capital boldface letters, e.g., A, to denote matrices.",1. Introduction,[0],[0]
"x
i is the ith entry of the vector x. We refer to V = {v1, ..., vn} as the ground set.",1. Introduction,[0],[0]
"We use f(·) to denote a continuous function, and F (·) to represent a set function.",1. Introduction,[0],[0]
"supp(x) := {i 2 V | x
i 6= 0} is the support set of the vector x, and [n] := {1, ..., n} for an integer n 1.",1. Introduction,[0],[0]
We denote the marginal gain of a set ⌦ ✓ V in context of a set S ✓ V as ⇢⌦(S) := F (⌦ [ S) F (S).,1. Introduction,[0],[0]
"For v 2 V , we use the shorthand ⇢
v (S) for ⇢{v}(S).",1. Introduction,[0],[0]
"In this section we provide the submodularity ratio and curvature for general, not necessarily submodular functions2, they are natural extensions of the classical ones.",2. Submodularity Ratio and Curvature,[0],[0]
"Let S 0 = ;, St = {j1, ..., jt}, t = 1, ...,K be the successive sets chosen by GREEDY.",2. Submodularity Ratio and Curvature,[0],[0]
"For brevity, let ⇢ t : = ⇢ jt(S t 1 ) be the marginal gain of GREEDY in step t.
Definition 1 (Submodularity ratio (Das & Kempe, 2011)).",2. Submodularity Ratio and Curvature,[0],[0]
"The submodularity ratio of a non-negative set function F (·) is the largest scalar s.t.
X !2⌦\S ⇢ !",2. Submodularity Ratio and Curvature,[0],[0]
"(S) ⇢⌦(S), 8 ⌦, S ✓ V.
The greedy submodularity ratio is the largest scalar G s.t. X
!2⌦\St ⇢ !",2. Submodularity Ratio and Curvature,[0],[0]
"(S
t )",2. Submodularity Ratio and Curvature,[0],[0]
"G⇢⌦(St), 8|⌦|=K, t = 0, . .",2. Submodularity Ratio and Curvature,[0],[0]
.,2. Submodularity Ratio and Curvature,[0],[0]
",K 1.
",2. Submodularity Ratio and Curvature,[0],[0]
It is easy to see that G .,2. Submodularity Ratio and Curvature,[0],[0]
The submodularity ratio measures to what extent F (·) has submodular properties.,2. Submodularity Ratio and Curvature,[0],[0]
"We make the following observations:
Remark 1.",2. Submodularity Ratio and Curvature,[0],[0]
"For a nondecreasing function F (·), it holds a) ,
G 2",2. Submodularity Ratio and Curvature,[0],[0]
"[0, 1]; b) F (·) is submodular iff = 1.",2. Submodularity Ratio and Curvature,[0],[0]
Definition 2 (Generalized curvature).,2. Submodularity Ratio and Curvature,[0],[0]
"The curvature of a non-negative function F (·) is the smallest scalar ↵ s.t.
⇢
i (S \ {i} [ ⌦) (1 ↵)⇢",2. Submodularity Ratio and Curvature,[0],[0]
"i (S \ {i}), 8 ⌦, S ✓ V, i 2 S\⌦.
",2. Submodularity Ratio and Curvature,[0],[0]
"The greedy curvature is the smallest scalar ↵G 0 s.t.
⇢ ji(S i 1 [ ⌦) (1 ↵G)⇢",2. Submodularity Ratio and Curvature,[0],[0]
"ji(S i 1 ),
8 ⌦ : |⌦| = K, i : j i 2 SK 1\⌦.",2. Submodularity Ratio and Curvature,[0],[0]
2Curvature is commonly defined for submodular functions.,2. Submodularity Ratio and Curvature,[0],[0]
Sviridenko et al. (2013) presented a notion of curvature for monotone non-submodular functions.,2. Submodularity Ratio and Curvature,[0],[0]
We show in Appendix C the details of these notions and the relations to ours.,2. Submodularity Ratio and Curvature,[0],[0]
"Additionally, we prove in Remark 3 of Appendix C.2 that our combination of curvature and submodularity ratio is more expressive than that of Sviridenko et al. (2013) in characterizing the maximization of problem (P) using standard GREEDY.
",2. Submodularity Ratio and Curvature,[0],[0]
"When K = n or 1, SK 1\⌦ = ;, it is natural to define ↵ G
= 0.",2. Submodularity Ratio and Curvature,[0],[0]
It is easy to observe that ↵G  ↵.,2. Submodularity Ratio and Curvature,[0],[0]
"Note that the classical total curvature is ↵total := 1 min i2V ⇢i(V\{i})
⇢i(;) .
",2. Submodularity Ratio and Curvature,[0],[0]
Remark 2.,2. Submodularity Ratio and Curvature,[0],[0]
"For a nondecreasing function F (·), it holds: a) ↵,↵G 2",2. Submodularity Ratio and Curvature,[0],[0]
"[0, 1]; b) F (·) is supermodular iff ↵ = 0; c)",2. Submodularity Ratio and Curvature,[0],[0]
"If F (·) is submodular, then ↵G  ↵ = ↵total.
",2. Submodularity Ratio and Curvature,[0],[0]
"So for a submodular function, our notion of curvature is consistent with ↵total.",2. Submodularity Ratio and Curvature,[0],[0]
"Notably, ↵G usually characterizes the problem better than ↵total, as will be validated in Section 5.",2. Submodularity Ratio and Curvature,[0],[0]
We present approximation guarantee of GREEDY in Theorem 1.,3. Approximation Guarantee,[0],[0]
Note that both versions of the submodularity ratio and curvature apply in the proof.,3. Approximation Guarantee,[0],[0]
"For brevity, we use and ↵ to refer to any of these versions in the sequel.",3. Approximation Guarantee,[0],[0]
In Section 3.3 we prove tightness of the approximation guarantees.,3. Approximation Guarantee,[0],[0]
All omitted proofs are given in Appendix B. Theorem 1.,3. Approximation Guarantee,[0],[0]
Let F (·) be a non-negative nondecreasing set function with submodularity ratio 2,3. Approximation Guarantee,[0],[0]
"[0, 1] and curvature ↵ 2 [0, 1].",3. Approximation Guarantee,[0],[0]
"The GREEDY algorithm enjoys the following approximation guarantee for solving problem (P):
F (S
K ) 1 ↵
"" 1 ✓ K ↵
K
◆ K # F (⌦ ⇤ )
1 ↵
(1 e ↵ )",3. Approximation Guarantee,[0],[0]
"F (⌦⇤), (1)
where ⌦⇤ is the optimal solution of (P) and SK the output of the GREEDY algorithm.3",3. Approximation Guarantee,[0],[0]
"Before proving the theorem, we want to give the reader an intuition of the results and show how our results recover and extend several classical guarantees for the GREEDY algorithm.",3.1. Interpreting Theorem 1,[0],[0]
"For the case ↵ = 0 (i.e., F (·) is supermodular), the approximation guarantee is lim
↵!0 1 ↵ (1 e ↵ ) = , which gives the first guarantee of greedily maximizing a nondecreasing supermodular function with bounded .",3.1. Interpreting Theorem 1,[0],[0]
"When = 1, (i.e., F (·) is submodular), we recover the guarantee of ↵ 1(1 e ↵) (Conforti & Cornuéjols, 1984).",3.1. Interpreting Theorem 1,[0],[0]
"For the case ↵ = 1, we have a guarantee of (1 e ) (Das & Kempe, 2011).",3.1. Interpreting Theorem 1,[0],[0]
"For the case ↵ = 1, = 1, we recover the classical guarantee of (1 1/e) (Nemhauser et al., 1978).",3.1. Interpreting Theorem 1,[0],[0]
We plot the constant-factor approximation guarantees for different values of and ↵ in Fig. 1.,3.1. Interpreting Theorem 1,[0],[0]
"One interesting phenomenon is that and ↵ play different roles: Looking at = 0, the approximation factor is always 0, independent of the value ↵ takes.",3.1. Interpreting Theorem 1,[0],[0]
"In contrast, for ↵ = 0, the
3For the setting that GREEDY is allowed to pick more than K elements, e.g., pick K0 > K elements, our theory can be easily extended to show that",3.1. Interpreting Theorem 1,[0],[0]
F (SK 0 ) ↵ 1(1 e ↵ K 0/,3.1. Interpreting Theorem 1,[0],[0]
"K)F (⌦⇤).
",3.1. Interpreting Theorem 1,[0],[0]
approximation guarantee is (1 e ).,3.1. Interpreting Theorem 1,[0],[0]
This can be interpreted as the curvature boosting the guarantees.,3.1. Interpreting Theorem 1,[0],[0]
The high-level proof framework is based on Conforti & Cornuéjols (1984) (where they derive the approximation guarantee for maximizing a nondecreasing submodular function with bounded curvature).,3.2. Proof of Theorem 1,[0],[0]
"However, adapting the proof to non-submodular functions requires several changes detailed in Section 6.
",3.2. Proof of Theorem 1,[0],[0]
Proof overview.,3.2. Proof of Theorem 1,[0],[0]
"Let us denote all problem instances of maximizing a non-negative nondecreasing function F (·) s.t. K-cardinality constraint (max|S|K F (S)) to be P K,↵,
, where F (·) is parametrized by submodularity ratio and curvature ↵.",3.2. Proof of Theorem 1,[0],[0]
"Let P⌦⇤,SK 2 PK,↵, denote those problem instances with optimal solution ⌦⇤ and greedy solution SK .",3.2. Proof of Theorem 1,[0],[0]
"We group all problem instances P
K,↵, according to the set ⌦",3.2. Proof of Theorem 1,[0],[0]
"⇤ \ SK := {l1 = jm1 , l2 = jm2 , . . .",3.2. Proof of Theorem 1,[0],[0]
", ls = j
ms}, where jm1 , . . .",3.2. Proof of Theorem 1,[0],[0]
", jms are consistent with the order of greedy selection.",3.2. Proof of Theorem 1,[0],[0]
"Let us denote the problem instances with ⌦ ⇤\SK = {l1, . . .",3.2. Proof of Theorem 1,[0],[0]
", ls} as the group PK,↵, ({l1, . . .",3.2. Proof of Theorem 1,[0],[0]
", ls}).
",3.2. Proof of Theorem 1,[0],[0]
"The main idea of the proof is to investigate the worst-case approximation ratio of each group of the problem instances P K,↵,
({l1, . . .",3.2. Proof of Theorem 1,[0],[0]
", ls}), 8{l1, . . .",3.2. Proof of Theorem 1,[0],[0]
", ls} ✓ SK .",3.2. Proof of Theorem 1,[0],[0]
We do this by constructing LPs based on the properties of the problem instances.,3.2. Proof of Theorem 1,[0],[0]
"By studying the structures of these LPs, we will prove that the worst-case approximation ratio of all problem instances occurs when ⌦⇤ \SK = ;.",3.2. Proof of Theorem 1,[0],[0]
"Thus the desired approximation guarantee corresponds to the worst-case approximation ratio of P
K,↵,
(;).
",3.2. Proof of Theorem 1,[0],[0]
The proof.,3.2. Proof of Theorem 1,[0],[0]
"When = 0 or F (⌦⇤) = 0, (1) holds naturally.",3.2. Proof of Theorem 1,[0],[0]
"In the following, let 2 (0, 1] and F (⌦⇤) > 0.",3.2. Proof of Theorem 1,[0],[0]
"First, we present Lemma 1, which will be used to construct the LPs.
",3.2. Proof of Theorem 1,[0],[0]
Lemma 1.,3.2. Proof of Theorem 1,[0],[0]
"For any ⌦ ✓ V with |⌦| = K and any t 2 {0, . . .",3.2. Proof of Theorem 1,[0],[0]
",K 1}, let wt := |St \ ⌦|.",3.2. Proof of Theorem 1,[0],[0]
"It holds that
↵
X
i:ji2St\⌦
⇢
i
+
X
i:ji2St\⌦
⇢
i
+ 1 (K wt)⇢
t+1 F (⌦).
",3.2. Proof of Theorem 1,[0],[0]
"We now specify the constructing of the LPs: For any problem instance P⌦⇤,SK 2 PK,↵, ({l1, . . .",3.2. Proof of Theorem 1,[0],[0]
", ls}), we know that F (SK) =",3.2. Proof of Theorem 1,[0],[0]
"P K
i=1 ⇢",3.2. Proof of Theorem 1,[0],[0]
i (telescoping sum).,3.2. Proof of Theorem 1,[0],[0]
"Hence, the approximation ratio is F (S
K) F (⌦⇤) =",3.2. Proof of Theorem 1,[0],[0]
P i ⇢,3.2. Proof of Theorem 1,[0],[0]
"i
F (⌦⇤) , which we denote as R({l1, . . .",3.2. Proof of Theorem 1,[0],[0]
", ls}) =",3.2. Proof of Theorem 1,[0],[0]
P i ⇢,3.2. Proof of Theorem 1,[0],[0]
i F (⌦⇤) .,3.2. Proof of Theorem 1,[0],[0]
Define xi,3.2. Proof of Theorem 1,[0],[0]
":= ⇢i
F (⌦⇤) , i 2",3.2. Proof of Theorem 1,[0],[0]
[K].,3.2. Proof of Theorem 1,[0],[0]
"Since F is nondecreasing, x
i 0.",3.2. Proof of Theorem 1,[0],[0]
"Plugging ⌦ = ⌦⇤ into Lemma 1, and considering t = 0, . . .",3.2. Proof of Theorem 1,[0],[0]
",K 1, we have in total K constraints over the variables x
i , which constitute the constraints of the LP.",3.2. Proof of Theorem 1,[0],[0]
"So the worst-case approximation ratio of the group P
K,↵, ({l1, . .",3.2. Proof of Theorem 1,[0],[0]
.,3.2. Proof of Theorem 1,[0],[0]
", ls}) is:
R({l1, . . .",3.2. Proof of Theorem 1,[0],[0]
", ls}) =",3.2. Proof of Theorem 1,[0],[0]
"min X K
i=1",3.2. Proof of Theorem 1,[0],[0]
x,3.2. Proof of Theorem 1,[0],[0]
"i
, s.t. x",3.2. Proof of Theorem 1,[0],[0]
"i 0 and,
row (0) row (1)
... row (l1 1) row (l2 1) row (q = lr) ...",3.2. Proof of Theorem 1,[0],[0]
"row (ls 1) ... row (K 1)
2
66666666666666666664
K
↵
K
... ... . . .",3.2. Proof of Theorem 1,[0],[0]
↵ ↵ · · · K 0 ↵ ↵ · · · 1 K 1 ↵ ↵ · · · 1 1 K r ... ... ... ...,3.2. Proof of Theorem 1,[0],[0]
"...
. . .",3.2. Proof of Theorem 1,[0],[0]
↵ ↵ · · · 1 1 ↵ · · · K s+1 ... ... ... ... ... ... . . .,3.2. Proof of Theorem 1,[0],[0]
"↵ ↵ · · · 1 1 ↵ · · · 1 · · · K s
3
77777777777777777775 ·
2
66666666666666664
x1
x2
...",3.2. Proof of Theorem 1,[0],[0]
"xl1 xl2 xq+1
...",3.2. Proof of Theorem 1,[0],[0]
"xls
... xK
3
77777777777777775
2
66666666666666664 1 1 ... 1 1 1 ... 1 ... 1
3
77777777777777775
(2)
",3.2. Proof of Theorem 1,[0],[0]
"The following Lemma presents the key structure of the constructed LPs, which will be used to deduce the relation between the LPs of different problem instance groups.",3.2. Proof of Theorem 1,[0],[0]
Lemma 2.,3.2. Proof of Theorem 1,[0],[0]
Assume that the optimal solution of the constructed LP is x⇤ 2 RK+,3.2. Proof of Theorem 1,[0],[0]
and that s = |⌦⇤ \ SK | 1.,3.2. Proof of Theorem 1,[0],[0]
"For all 1  r  s it holds that x⇤
q  x⇤ q+1, where q = lr.
",3.2. Proof of Theorem 1,[0],[0]
Proof sketch of Lemma 2.,3.2. Proof of Theorem 1,[0],[0]
"Assume by virture of creating a contradiction that x⇤
q
> x ⇤ q+1.",3.2. Proof of Theorem 1,[0],[0]
"We can always create a
new feasible solution y⇤ 2 RK+ by decreasing x⇤q by some ✏ > 0, while increasing all the x⇤
q+1 to x⇤ K by some proper values, s.t. y⇤ has smaller LP objective value.",3.2. Proof of Theorem 1,[0],[0]
"Specifically, we define y⇤ as: for k = 1, . . .",3.2. Proof of Theorem 1,[0],[0]
", q 1, y⇤
k
:= x ⇤ k ; y
⇤ q",3.2. Proof of Theorem 1,[0],[0]
":= x ⇤ q ✏; for k = q + 1, . . .",3.2. Proof of Theorem 1,[0],[0]
",K, y⇤ k",3.2. Proof of Theorem 1,[0],[0]
":= x ⇤ k + ✏ k where ✏
k s are defined recursively as: ✏ q+1 = ✏ K r , and
✏ q+1+u =",3.2. Proof of Theorem 1,[0],[0]
"✏q+u K r u+ 1 K r u , 1  u  K q 1.
",3.2. Proof of Theorem 1,[0],[0]
Claim 1.,3.2. Proof of Theorem 1,[0],[0]
"a) The new solution y⇤ 0; b) All of the constraints in (2) are still feasible for y⇤.
",3.2. Proof of Theorem 1,[0],[0]
"After that the change of the LP objective is,
LP = ✏+ ✏ q+1 + ✏q+2 + . .",3.2. Proof of Theorem 1,[0],[0]
.+,3.2. Proof of Theorem 1,[0],[0]
"✏K .
",3.2. Proof of Theorem 1,[0],[0]
"One can prove that the LP objective decreases:
Claim 2.",3.2. Proof of Theorem 1,[0],[0]
"For all K 1, 1  r  q < K, it holds that
LP  0, 8 2 (0, 1].",3.2. Proof of Theorem 1,[0],[0]
Equality is achieved when r = q and = 1.,3.2. Proof of Theorem 1,[0],[0]
"Therefore we reach the contradiction that x⇤ is an optimal solution of the constructed LP.
",3.2. Proof of Theorem 1,[0],[0]
"Given Lemma 2, we prove in the following Lemma, which states that the worst-case approximation ratio of all problem instances occurs when ⌦⇤ \ SK = ;.",3.2. Proof of Theorem 1,[0],[0]
Lemma 3.,3.2. Proof of Theorem 1,[0],[0]
"For all {l1, . . .",3.2. Proof of Theorem 1,[0],[0]
", ls} ✓ SK , it holds that
R({l1, . . .",3.2. Proof of Theorem 1,[0],[0]
", ls}) R(;) = 1 ↵
 1 ⇣ K ↵
K
⌘ K
.
",3.2. Proof of Theorem 1,[0],[0]
"So the greedy solution has objective F (SK) 1 ↵  1 ⇣ K ↵ K ⌘ K F (⌦ ⇤ ) 1 ↵ (1 e ↵ )F (⌦⇤).
3.3.",3.2. Proof of Theorem 1,[0],[0]
"Tightness Result
We demonstrate that the approximation guarantee in Theorem 1 is tight, i.e., for every submodularity ratio and every curvature ↵, there exist set functions that achieve the bound exactly.
",3.2. Proof of Theorem 1,[0],[0]
"Assume the ground set V contains the elements in S :=
{j1, . . .",3.2. Proof of Theorem 1,[0],[0]
", jK}",3.2. Proof of Theorem 1,[0],[0]
"and the elements in ⌦ := {!1, . . .",3.2. Proof of Theorem 1,[0],[0]
",!K} (S \ ⌦ = ;) and n 2K dummy elements.",3.2. Proof of Theorem 1,[0],[0]
"The objective function we are going to construct will not depend on these dummy elements, i.e., the objective value of a set does not change if dummy elements are removed from or added to that set.",3.2. Proof of Theorem 1,[0],[0]
"Consequently, the dummy elements will not affect the submodularity ratio and the curvature.",3.2. Proof of Theorem 1,[0],[0]
"For the constants ↵ 2 [0, 1], 2 (0, 1], we define the objective function as,
F (T ) := f(|⌦ \ T |)
K
1 ↵
X
i:ji2S\T
⇠i
+
X
i:ji2S\T
⇠i, (3)
where ⇠ i : = 1 K
⇣ K ↵
K
⌘ i 1
, i 2",3.2. Proof of Theorem 1,[0],[0]
"[K]; f(x) = 1 1 K 1 x 2 +
K 1 K 1 x. Note that f(x) is convex nondecreasing over [0,K], and that f(0)",3.2. Proof of Theorem 1,[0],[0]
"= 0, f(1) = 1, f(K) = K/ .",3.2. Proof of Theorem 1,[0],[0]
It is clear that F (;) = 0 and F (·) is monotone nondecreasing.,3.2. Proof of Theorem 1,[0],[0]
"The following lemma shows that it is generally nonsubmodular and non-supermodular.
",3.2. Proof of Theorem 1,[0],[0]
Lemma 4.,3.2. Proof of Theorem 1,[0],[0]
"For the objective in (3): a) When ↵ = 0, it is supermodular; b) When = 1, it is submodular; c) F (T ) has submodularity ratio and curvature ↵.
",3.2. Proof of Theorem 1,[0],[0]
"Considering the problem of max|T |K F (T ), we claim that the GREEDY algorithm may output S. This can be proved by induction.",3.2. Proof of Theorem 1,[0],[0]
"One can see that ⇢
j1(;) =",3.2. Proof of Theorem 1,[0],[0]
"⇠1 = ⇢
!1(;), so GREEDY can choose j1 in the first step.",3.2. Proof of Theorem 1,[0],[0]
"Assume in step t 1 GREEDY has chosen St 1 = {j1, . . .",3.2. Proof of Theorem 1,[0],[0]
", jt 1}, one can verify that the marginal gains coincide, i.e., ⇢
jt(S t 1 )",3.2. Proof of Theorem 1,[0],[0]
= ⇠ t = ⇢ !,3.2. Proof of Theorem 1,[0],[0]
t(S t 1 ).,3.2. Proof of Theorem 1,[0],[0]
"However, the optimal solution is actually ⌦ with function value as F (⌦) = 1 .",3.2. Proof of Theorem 1,[0],[0]
"So the
approximation ratio is F (S) F (⌦) = 1 ↵
 1 ⇣ K ↵
K
⌘ K
, which
matches our approximation guarantee in Theorem 1.",3.2. Proof of Theorem 1,[0],[0]
We consider several important real-world applications and their corresponding objective functions.,4. Applications,[0],[0]
"We show that the submodularity ratio and the curvature of these functions can be bounded and, hence, the approximation guarantees from our theoretical results are applicable.",4. Applications,[0],[0]
All the omitted proofs are provided in Appendix D.,4. Applications,[0],[0]
"In Bayesian experimental design (Chaloner & Verdinelli, 1995), the goal is to select a set of experiments to perform s.t.",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"some statistical criterion is optimized, e.g., the variance of certain parameter estimates is minimized.",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"Krause et al. (2008) investigated several criteria for this purpose, amongst others the Bayesian A-optimality criterion.",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
This criterion is used to maximally reduce the variance in the posterior distribution over the parameters.,4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"In general, the criterion is not submodular as shown in Krause et al. (2008, Section 8.4).
",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"Formally, assume there are n experimental stimuli {x1, . . .",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
",xn}, each xi 2 Rd, which constitute the data matrix X 2 Rd⇥n. Let us arrange a set S ✓ V of stimuli as a matrix X
S
:
=",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"[x v1 , . . .",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
",xvs ] 2 Rd⇥|S|.",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"Let ✓ 2 Rd be the parameter vector in the linear model y
S = X> S ✓ +w, where w is the Gaussian noise with zero mean and variance
2, i.e., w ⇠ N (0, 2I), and y S is the vector of dependent variables.",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"Suppose the prior takes the form of an isotropic Gaussian, i.e., ✓ ⇠ N (0,⇤ 1),⇤ = 2I. Then,  y
S
✓
⇠ N (0,⌃),⌃ =

2I+X> S ⇤ 1X S X> S ⇤ 1
⇤ 1X S
⇤ 1
.
",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
This implies that ⌃,4.1. Bayesian A-optimality in Experimental Design,[0],[0]
✓|yS =,4.1. Bayesian A-optimality in Experimental Design,[0],[0]
(⇤ + 2X S X> S ) 1.,4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"The Aoptimality objective is defined as,
F
A
(S)
: = tr(⌃ ✓ ) tr(⌃ ✓|yS ) (4) = tr(⇤ 1) tr((⇤+ 2X S X> S ) 1 ).
",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"The following Proposition gives bounds on the submodularity ratio and curvature of (4).
",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
Proposition 1.,4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"Assume normalized stimuli, i.e., kx i k = 1, 8i 2 V .",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
Let the spectral norm of X be kXk.4,4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"Then, a) The objective in (4) is monotone nondecreasing.",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
b),4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"Its submodularity ratio can be lower bounded by 2
kXk2( 2+ 2kXk2) , and its curvature ↵ can be upper
bounded by 1 2
kXk2( 2+ 2kXk2) .",4.1. Bayesian A-optimality in Experimental Design,[0],[0]
"The determinantal function of a square submatrix is widely used in many areas, e.g., in determinantal point processes (Kulesza & Taskar, 2012) and active set selection for sparse Gaussian processes.",4.2. The Determinantal Function,[0],[0]
Monotone nondecreasing determinantal functions appear in the second problem.,4.2. The Determinantal Function,[0],[0]
Assume ⌃ is the covariance matrix parameterized by a positive definite kernel.,4.2. The Determinantal Function,[0],[0]
"In the Informative Vector Machine (Lawrence et al., 2003), the information gain of a subset of points S ✓ V is 1 2 logF (S), where
F (S)
:",4.2. The Determinantal Function,[0],[0]
"= det(I+ 2⌃ S ), (5)
where is the noise variance in the Gaussian process model, ⌃
S is the square submatrix with both its rows and columns indexed by S. Although logF (S) is submodular, F (S) is in general not submodular.",4.2. The Determinantal Function,[0],[0]
The approximation guarantee of GREEDY for maximizing logF (S) does not translate to a guarantee for maximizing F (S).,4.2. The Determinantal Function,[0],[0]
"The following Proposition characterizes (5).
",4.2. The Determinantal Function,[0],[0]
Proposition 2.,4.2. The Determinantal Function,[0],[0]
"a) F (S) in (5) is supermodular, its curvature is 0; b) Let the eigenvalues of A := I + 2⌃ be 1 · · · n >",4.2. The Determinantal Function,[0],[0]
1.,4.2. The Determinantal Function,[0],[0]
"The greedy submodularity ratio of F (S) can be lower bounded by K( n 1)
",4.2. The Determinantal Function,[0],[0]
( QK j=1 j) 1 .,4.2. The Determinantal Function,[0],[0]
LPs with combinatorial constraints appear frequently in practice.,4.3. LPs with Combinatorial Constraints,[0],[0]
Consider the following example: Suppose that V is the set of all products a company can produce.,4.3. LPs with Combinatorial Constraints,[0],[0]
"Given budget constraints on the raw materials needed, companies consider the LP max
x2Phd,xi, where d is the vector of profits for the individual products and where P is a polytope representing the continuous constraints.",4.3. LPs with Combinatorial Constraints,[0],[0]
The above LP can be used to assess the profit maximizing production plan.,4.3. LPs with Combinatorial Constraints,[0],[0]
Usually the company needs to consider combinatorial constraints as well.,4.3. LPs with Combinatorial Constraints,[0],[0]
"For instance, the company has at most K production lines, thus they have to select a subset of K products to produce.",4.3. LPs with Combinatorial Constraints,[0],[0]
"Often this kind of problems can be formalized as max
x2P,supp(x)2Ihd,xi, where I is the independent set of the combinatorial structure.",4.3. LPs with Combinatorial Constraints,[0],[0]
"Hence, a natural auxiliary set function is,
F (S) := maxsupp(x)✓S, x2Phd,xi, 8S ✓ V. (6) 4By",4.3. LPs with Combinatorial Constraints,[0],[0]
"Weyl’s inequality, a naive upper bound is kXk  p n.
Let P = {x 2",4.3. LPs with Combinatorial Constraints,[0],[0]
"Rn | 0  x  ¯u,Ax  b, ¯u 2 Rn+,A 2 Rm⇥n+ , b 2 Rm+}.",4.3. LPs with Combinatorial Constraints,[0],[0]
In general F (S) in (6) is non-submodular as illustrated by two examples in Appendix D.3.,4.3. LPs with Combinatorial Constraints,[0],[0]
"Upper bounding the curvature is equivalent to lower bounding F (S[⌦) F (S\{i}[⌦)
F (S) F (S\{i}) , which can be 0 in the worst case.",4.3. LPs with Combinatorial Constraints,[0],[0]
"However, the submodularity ratio can be lower bounded by a non-zero scalar.
",4.3. LPs with Combinatorial Constraints,[0],[0]
Proposition 3.,4.3. LPs with Combinatorial Constraints,[0],[0]
a) F (S) in (6) is a normalized nondecreasing set function.,4.3. LPs with Combinatorial Constraints,[0],[0]
b),4.3. LPs with Combinatorial Constraints,[0],[0]
"With regular non-degenerancy assumptions (details in Appendix D.3.2), its submodularity ratio can be lower bounded by 0 > 0.",4.3. LPs with Combinatorial Constraints,[0],[0]
"Many real-world applications can benefit from the theory in this work, for instance: subset selection using the R2 objective, sparse modeling and the budget allocation problem with combinatorial constraints.",4.4. More Applications,[0],[0]
Details on these applications are deferred to Appendix G.,4.4. More Applications,[0],[0]
We empirically validated approximation guarantees characterized by the submodularity ratio and the curvature for several applications.,5. Experimental Results,[0],[0]
"Since it is too time consuming to calculate the full versions of ↵ and using exhaustive search, we only calculated the greedy versions (↵G, G).",5. Experimental Results,[0],[0]
All averaged results are from 20 repeated experiments.,5. Experimental Results,[0],[0]
Source code is available at https://github.com/bianan/ non-submodular-max.5 More results are put in Appendix H.,5. Experimental Results,[0],[0]
We considered the Bayesian A-optimality objective for both synthetic and real-world data.,5.1. Bayesian Experimental Design,[0],[0]
"In all experiments, we normalized the data points to have unit `2-norm.
",5.1. Bayesian Experimental Design,[0],[0]
Real-world results: We used the Boston Housing Data.,5.1. Bayesian Experimental Design,[0],[0]
5All experiments were implemented using Matlab.,5.1. Bayesian Experimental Design,[0],[0]
"We used the SDP solver provided by CVX (Version 2.1).
",5.1. Bayesian Experimental Design,[0],[0]
"The dataset6 has 14 features (e.g., crime rate, property tax rates, etc.) and 516 samples.",5.1. Bayesian Experimental Design,[0],[0]
"To be able to quickly calculate the parameters and optimal solution by exhaustive search, the first n = 14 samples were used.",5.1. Bayesian Experimental Design,[0],[0]
"As a baseline, we used an SDP-based algorithm (abbreviated as SDP, details are available in Appendix E).",5.1. Bayesian Experimental Design,[0],[0]
Results are shown in Fig. 2 for varying values of K. In Fig.,5.1. Bayesian Experimental Design,[0],[0]
2a we can observe that both GREEDY and SDP compute near-optimal solutions.,5.1. Bayesian Experimental Design,[0],[0]
From Fig.,5.1. Bayesian Experimental Design,[0],[0]
"2b we can see that the greedy submodularity ratio G is close to 1, and that the greedy curvature ↵G is less than 1, while the classical curvature ↵total is always 1 (the worstcase value).",5.1. Bayesian Experimental Design,[0],[0]
"This implies that the classical total curvature ↵
total characterizes the considered maximization problems less accurate than the greedy curvature.
",5.1. Bayesian Experimental Design,[0],[0]
Synthetic results: We generated random observations from a multivariate Gaussian distribution with different correlations.,5.1. Bayesian Experimental Design,[0],[0]
"To be able to assess the ground truth, we used n = 12 samples with d = 6 features.",5.1. Bayesian Experimental Design,[0],[0]
"Fig. 3 shows the results with correlation 0.2 (first column) and 0.6 (second column), respectively: The first row shows the average objective values over the optimal value with error bars, and the second row shows the parameters.",5.1. Bayesian Experimental Design,[0],[0]
One can observe that GREEDY always obtains near-optimal solutions and that these solutions are roughly comparable with those obtained by the SDP.,5.1. Bayesian Experimental Design,[0],[0]
"The classical curvature ↵total is always close to 1, while ↵G take smaller values, and G takes values close to 1, thus characterize the performance of GREEDY better.
",5.1. Bayesian Experimental Design,[0],[0]
"Medium-scale synthetic experiments: To compare the runtime of SDP and GREEDY, we considered mediumscale datasets (we cannot report results on larger datasets because of the huge computational demands of the SDP).
",5.1. Bayesian Experimental Design,[0],[0]
"6https://archive.ics.uci.edu/ml/datasets/ Housing
Fig. 4 shows the objective value achieved by GREEDY and SDP for different numbers of features d and numbers of samples n, as well as the correlations.",5.1. Bayesian Experimental Design,[0],[0]
We can observe that GREEDY computes solutions that are on par or superior to those of SDP.,5.1. Bayesian Experimental Design,[0],[0]
"In Table 1 we summarize the runtime of GREEDY and SDP for different values of d and n, for correlation 0.5.",5.1. Bayesian Experimental Design,[0],[0]
"Furthermore, we show the ratio of runtimes of the two algorithms.",5.1. Bayesian Experimental Design,[0],[0]
We can observe that GREEDY is usually two orders of magnitude faster than SDP.,5.1. Bayesian Experimental Design,[0],[0]
We generated synthetic LPs as follows:,5.2. LPs with Combinatorial Constraints,[0],[0]
"Firstly, we generated the matrix A 2 Rm⇥n+ , Aij 2 [0, 1] by drawing all entries independently from a uniform distribution on
[0, 1].",5.2. LPs with Combinatorial Constraints,[0],[0]
"We set b = d = 1, and set ¯u as 1.",5.2. LPs with Combinatorial Constraints,[0],[0]
The first row of Fig. 5 plots the optimal LP objective (calculated using exhaustive search) and the LP objective returned by GREEDY.,5.2. LPs with Combinatorial Constraints,[0],[0]
The second row shows the curvature and submodularity ratio.,5.2. LPs with Combinatorial Constraints,[0],[0]
"The first column (Fig. 5a) presents the results for n = 6,m = 20, while the second column (Fig. 5b) presents that for n = 8,m = 30.",5.2. LPs with Combinatorial Constraints,[0],[0]
"Note the greedy submodularity ratio takes values between ⇠ 0.15 and 1, and that the curvature is close to the worst-case value of 1.",5.2. LPs with Combinatorial Constraints,[0],[0]
These observations are consistent with the theory in Section 4.3.,5.2. LPs with Combinatorial Constraints,[0],[0]
"We experimented with synthetic and real-world data: For synthetic data, we generated random covariance matrices ⌃ 2 Rn⇥n with uniformly distributed eigenvalues in [0, 1].",5.3. Determinantal Functions Maximization,[0],[0]
"We set n = 10, = 2.",5.3. Determinantal Functions Maximization,[0],[0]
In Fig. 6 (left) we plot the optimal determinantal objective value and the value achieved by GREEDY.,5.3. Determinantal Functions Maximization,[0],[0]
Fig. 6,5.3. Determinantal Functions Maximization,[0],[0]
"(right) traces the greedy submodularity ratio G. Since the determinantal objective is supermodular, so the approximation guarantee equals to G. We can see that G can reasonably predict the performance of GREEDY.
",5.3. Determinantal Functions Maximization,[0],[0]
"For real-world data, we considered an active set selection task on the CIFAR-107 dataset.",5.3. Determinantal Functions Maximization,[0],[0]
"The first n = 12 images in the test set were used to calculate the covariance matrix with an squared exponential kernel (k(x
i
,x
j
) =
exp( kx i x j k2/h2), h was set to be 1).",5.3. Determinantal Functions Maximization,[0],[0]
"The results in Fig. 7 shows similar results as with the synthetic data.
7https://www.cs.toronto.edu/˜kriz/cifar.",5.3. Determinantal Functions Maximization,[0],[0]
html,5.3. Determinantal Functions Maximization,[0],[0]
"In this section we briefly discuss related work on various notions of non-submodularity and the optimization of nonsubmodular functions (Further details in Appendix F).
",6. Related Work,[0],[0]
Relation to Conforti & Cornuéjols (1984) in deriving approximation guarantees.,6. Related Work,[0],[0]
"In proving Theorem 1 we use the similar proof framework (i.e., utilizing LP formulations to analyze the worst-case approximation ratios of different groups of problem instances) as that in Conforti & Cornuéjols (1984), where they derive guarantees for maximizing submodular functions.",6. Related Work,[0],[0]
"However, since we are proving guarantees for non-submodular functions, the specific techniques on how to manipulate these LPs are different.",6. Related Work,[0],[0]
"Specifically, 1)",6. Related Work,[0],[0]
The building block to construct LPs (Lemma 1) is different;,6. Related Work,[0],[0]
"2) The technique to prove the structure of the LPs (which corresponds to Lemma 2) is significantly different for a submodular function and a nonsubmodular function, and Lemma 2 is the key to investigate the worst-case approximation ratios of different groups of problem instances.",6. Related Work,[0],[0]
3),6. Related Work,[0],[0]
"The specific way to prove Lemma 3 is also different since the constraints of the LPs are different for submodular and non-submodular functions.
",6. Related Work,[0],[0]
Submodularity ratio and curvature.,6. Related Work,[0],[0]
Curvature is typically defined for submodular functions.,6. Related Work,[0],[0]
Sviridenko et al. (2013) present a notion of curvature for monotone nonsubmodular functions.,6. Related Work,[0],[0]
Appendix C provides details of that notion and relates it to our definition.,6. Related Work,[0],[0]
Yoshida (2016) prove an improved approximation ratio for knapsack-constrained maximization of submodular functions with bounded curvature.,6. Related Work,[0],[0]
"Submodularity ratio (Das & Kempe, 2011) is a quantity characterizing how close a function is to being submodular.
",6. Related Work,[0],[0]
Approximate submodularity.,6. Related Work,[0],[0]
"Krause et al. (2008) define approximately submodular functions with parameter ✏ 0 as those functions F that satisfy an approximate diminishing returns property, i.e., 8A ✓ B ✓ V \ v it holds that ⇢
v (A) ⇢",6. Related Work,[0],[0]
v (B) ✏.,6. Related Work,[0],[0]
GREEDY yields a solution with objective F (SK) (1 e 1)F,6. Related Work,[0],[0]
"(⌦⇤) K✏, for maximizing a monotone F s.t.",6. Related Work,[0],[0]
a K-cardinality constraint.,6. Related Work,[0],[0]
Du et al. (2008) study the greedy maximization of nonsubmodular potential functions with restricted submodularity and shifted submodularity.,6. Related Work,[0],[0]
"Restricted submodularity refers to functions which are submodular only over some collection of subsets of V , and shifted submodularity can be viewed as a special case of the approximate diminishing returns as defined above.",6. Related Work,[0],[0]
"Recently, Horel & Singer (2016) study ✏-approximately submodular functions, which arised from their research on “noisy” submodular functions.",6. Related Work,[0],[0]
A function F (·) is ✏-approximately submodular if there exists a submodular function G s.t. (1 ✏)G(S)  ,6. Related Work,[0],[0]
"F (S)  (1 + ✏)G(S), 8S ✓ V .
",6. Related Work,[0],[0]
Weak submodularity.,6. Related Work,[0],[0]
"Borodin et al. (2014) study weakly submodular functions, i.e., montone, nomalized functions F (·) s.t. for any S, T , it holds |T |F (S) + |S|F (T ) |S \T |F (S [T )+ |S",6. Related Work,[0],[0]
[T |F (S \T ).,6. Related Work,[0],[0]
"For a function F (·), we show in Remark 4 that the following two facts do not imply each other: i)",6. Related Work,[0],[0]
F (·) is weakly submodular; ii),6. Related Work,[0],[0]
"The submodularity ratio of F (·) is strictly larger than 0, and its curvature is strictly smaller than 1.
",6. Related Work,[0],[0]
Other notions of non-submodularity.,6. Related Work,[0],[0]
Feige & Izsak (2013) introduce the supermodular degree as a complexity measure for set functions.,6. Related Work,[0],[0]
They show that a greedy algorithm for the welfare maximization problem enjoys an approximation guarantee increasing linearly with the supermodular degree.,6. Related Work,[0],[0]
"Zhou & Spanos (2016) use the submodularity index to characterize the performance of the RANDOMGREEDY algorithm (Buchbinder et al., 2014) for maximizing a non-monotone function.
",6. Related Work,[0],[0]
Optimization of non-submodular functions.,6. Related Work,[0],[0]
"The submodular-supermodular procedure has been proposed to minimize the difference of two submodular functions (Narasimhan & Bilmes, 2005; Iyer & Bilmes, 2012).",6. Related Work,[0],[0]
"Jegelka & Bilmes (2011) present the problem of minimizing “cooperative cuts”, which are non-submodular in general, and propose efficient algorithms for optimization.",6. Related Work,[0],[0]
Kawahara et al. (2015) analyze unconstrained minimization of the sum of a submodular function and a treestructured supermodular function.,6. Related Work,[0],[0]
"Bai et al. (2016) investigate the minimization of the ratio of two submodular functions, which can be solved with bounded approximation factor.",6. Related Work,[0],[0]
We analyzed the guarantees for greedy maximization of non-submodular nondecreasing set functions.,7. Conclusion,[0],[0]
"By combining the (generalized) curvature ↵ and submodularity ratio for generic set functions, we prove the first tight approximation bounds in terms of these definitions for greedily maximizing nondecreasing set functions.",7. Conclusion,[0],[0]
These approximation bounds significantly enlarge the domain where GREEDY has guarantees.,7. Conclusion,[0],[0]
"Furthermore, we theoretically bounded the parameters ↵ and for several non-trivial applications, and validate our theory in various experiments.",7. Conclusion,[0],[0]
"The authors would like to thank Adish Singla, Kfir Y. Levy and Aurelien Lucchi for valuable discussions.",ACKNOWLEDGEMENTS,[0],[0]
This research was partially supported by ERC StG 307036 and the Max Planck ETH Center for Learning Systems.,ACKNOWLEDGEMENTS,[0],[0]
This work was done in part while Andreas Krause was visiting the Simons Institute for the Theory of Computing.,ACKNOWLEDGEMENTS,[0],[0]
We investigate the performance of the standard GREEDY algorithm for cardinality constrained maximization of non-submodular nondecreasing set functions.,abstractText,[0],[0]
"While there are strong theoretical guarantees on the performance of GREEDY for maximizing submodular functions, there are few guarantees for non-submodular ones.",abstractText,[0],[0]
"However, GREEDY enjoys strong empirical performance for many important non-submodular functions, e.g., the Bayesian A-optimality objective in experimental design.",abstractText,[0],[0]
We prove theoretical guarantees supporting the empirical performance.,abstractText,[0],[0]
Our guarantees are characterized by a combination of the (generalized) curvature ↵ and the submodularity ratio .,abstractText,[0],[0]
"In particular, we prove that GREEDY enjoys a tight approximation guarantee of 1 ↵ (1 e ↵) for cardinality constrained maximization.",abstractText,[0],[0]
"In addition, we bound the submodularity ratio and curvature for several important real-world objectives, including the Bayesian Aoptimality objective, the determinantal function of a square submatrix and certain linear programs with combinatorial constraints.",abstractText,[0],[0]
We experimentally validate our theoretical findings for both synthetic and real-world applications.,abstractText,[0],[0]
Guarantees for Greedy Maximization of Non-submodular Functions with Applications,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1308–1317 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1308",text,[0],[0]
"Acronyms are abbreviations formed from the initial components of words or phrases (e.g., “AI” from “Artificial Intelligence”).",1 Introduction,[0],[0]
"As acronyms can shorten long names and make communications
∗Work done while authors were at Microsoft Research.
more efficient, they are widely used at almost everywhere in enterprises, including notifications, emails, reports and social network posts.",1 Introduction,[0],[0]
Figure 1 shows a sample enterprise social network post.,1 Introduction,[0],[0]
"As we can see, acronyms are frequently used there.
",1 Introduction,[0],[0]
"The enterprise acronym disambiguation task is challenging due to the high ambiguity of acronyms, e.g., “SP” could stand for “Service Pack”, “SharePoint” or “Surface Pro” in Microsoft.",1 Introduction,[0],[0]
"And there is one additional challenge compared with previous disambiguation tasks: in an enterprise document, an acronym could refer
to either an internal meaning (concepts created by the enterprise that may or may not be found outside) or an external meaning (all concepts that are not internal).",1 Introduction,[0],[0]
"For example, regarding the acronym “AI”, “Asset Intelligence” is an internal meaning mainly used only in Microsoft, while “Artificial Intelligence” is an external meaning widely used in public.",1 Introduction,[0],[0]
A good acronym disambiguation system should be able to handle both internal and external meanings.,1 Introduction,[0],[0]
"As we will explain in details, it is important to make such distinction and different strategies are needed for such two cases.
",1 Introduction,[0],[0]
"For internal meanings, there are some previous work on word sense disambiguation (Navigli, 2009) and acronym disambiguation (Feng et al., 2009; Pakhomov et al., 2005; Pustejovsky et al., 2001; Stevenson et al., 2009; Yu et al., 2006) on a closed-domain corpus.",1 Introduction,[0],[0]
"The main challenge here is that there are rarely any domain-specific knowledge bases available in enterprises, therefore all the signals for disambiguation (including potential meanings, and their popularity scores, context representations, etc.) need to be mined from plain text.",1 Introduction,[0],[0]
Training data should also be automatically generated to make the system easily scale out to all enterprises.,1 Introduction,[0],[0]
"Compared with previous work, we developed a more comprehensive and advanced set of features in the disambiguation model, and also used a much less restrictive way to discover meaning candidates and training data, so that both precision and recall can be improved.",1 Introduction,[0],[0]
"Moreover, one main limitation of all previous work is that they do not distinguish internal and external meanings.",1 Introduction,[0],[0]
"They merely rely on the enterprise corpus to discover information about external meanings, which we observe is quite ineffective.",1 Introduction,[0],[0]
"The reason is that for popular external meaning like “Artificial Intelligence”, people often directly use its acronym in enterprises without explanation, therefore there is limited information about the connection between the acronym and the external meaning in the enterprise corpus.",1 Introduction,[0],[0]
"On the other hand, there are much more such information available in the public domain, which should be leveraged by the system.
",1 Introduction,[0],[0]
"If we consider utilizing a public knowledge base such as Wikipedia to better handle external meanings of acronyms, the problem becomes very related to the well studied Entity Linking (Ji and Grishman, 2011; Cucerzan, 2007; Dredze et al., 2010; Hoffart et al., 2011; Li et al., 2013, 2016; Ratinov et al., 2011; Shen et al., 2012) prob-
lem, which is to map entity mentions in texts to their corresponding entities in a reference knowledge base (e.g. Wikipedia).",1 Introduction,[0],[0]
"But our disambiguation task is different from the entity linking task, because the system also needs to handle internal meanings which are not covered by any knowledge bases, and ultimately needs to decide whether an acronym refers to an internal meaning or an external meaning.",1 Introduction,[0],[0]
It is nontrivial to combine the information mined from the enterprise corpus and the public knowledge base so that the system can get the best of both worlds.,1 Introduction,[0],[0]
"For instance, we have tried to run an internal disambiguator (leveraging information mined from enterprise corpus) and then resort to a public entity linking system if the internal one’s confidence is low, but the performance is very poor.",1 Introduction,[0],[0]
"Even for external meanings, it is important to leverage signals from the enterprise corpus since the context surrounding them could be quite different from that in the external world, and context is one of the most important factor for disambiguation.",1 Introduction,[0],[0]
"For example, in public world, when people mention “Operating System” they mainly talk about how to install or use it; while within Microsoft, when people mention “Operating System” most of the time they focus on how to design or implement it.
",1 Introduction,[0],[0]
"In this work, we design a novel, end-to-end framework to address all the above challenges.",1 Introduction,[0],[0]
Our framework takes the enterprise corpus and certain public knowledge base as input and produces a high-quality acronym disambiguation system as output.,1 Introduction,[0],[0]
"The models are all trained via distant supervised learning, therefore our system requires no manually labeled training examples and can be easily deployed to any enterprises.",1 Introduction,[0],[0]
The Enterprise Acronym Disambiguation problem is comprised of two sub-problems.,2 Problem Statement,[0],[0]
"The first one is Acronym Meaning Mining (Adar, 2004; Ao and Takagi, 2005; Park and Byrd, 2001; Schwartz and Hearst, 2002; Jain et al., 2007; Larkey et al., 2000; Nadeau and Turney, 2005; Taneva et al., 2013), which aims at mining acronym/meaning pairs from the enterprise corpus.",2 Problem Statement,[0],[0]
"Each meaning m should contain the full name expansion e, popularity score p (indicating how often m is used as the genuine meaning of acronym a) and context words W (i.e. words frequently used in context of the meaning).",2 Problem Statement,[0],[0]
"The popularity score and
context words can provide critical information for making disambiguation decisions.",2 Problem Statement,[0],[0]
"The second one is Meaning Candidate Ranking, whose goal is to rank the candidate meanings associated with the target acronym a and select the genuine meaning m based on the given context.
",2 Problem Statement,[0],[0]
"In this paper we assume the acronyms for disambiguation are provided as input to the system, either by the user or by an existing acronym detection module.",2 Problem Statement,[0],[0]
"We do not try to optimize the performance of acronym detection (e.g. identifying acronyms beyond the simple capitalized rule, or distinguishing cases where a capitalized term is not an acronym but a regular English word, such as “OK”).",2 Problem Statement,[0],[0]
The task of acronym detection is also interesting and important.,2 Problem Statement,[0],[0]
"But due to the space limit, it is beyond the scope of this paper.",2 Problem Statement,[0],[0]
We propose a novel end-to-end framework to solve the Enterprise Acronym Disambiguation problem.,3 Framework,[0],[0]
Our framework takes the enterprise corpus as input and produces a high-quality acronym disambiguation system as output.,3 Framework,[0],[0]
Figure 2 shows the details of our proposed framework.,3 Framework,[0],[0]
"In the mining module, we will sequentially perform Candidates Generation, Popularity Calculation, Candidates Deduplication and Context Harvesting on the input enterprise corpus.",3 Framework,[0],[0]
The details of these steps will be discussed in Section 4.,3 Framework,[0],[0]
"After mining steps, we will get an acronym/meaning repository storing all the mined acronym/meaning pairs.",3 Framework,[0],[0]
"Feed this repository together with the training data (automatically generated via distant supervision from the enterprise corpus) to the training module, we will get a candidate ranking model, a confidence estimation model and a final selection model.",3 Framework,[0],[0]
These models form the final acronym disambiguator and will be used in the testing module for actual acronym disambiguation.,3 Framework,[0],[0]
"In the testing module, given the target acronym along with some context as input, the system will output the predicted meaning.",3 Framework,[0],[0]
"Note that the mining and training module run offline once for the entire corpus or periodically when the corpus update, while the testing can be run online repeatedly for processing new documents.",3 Framework,[0],[0]
"As there is no reference dictionary or knowledge base available in enterprise telling us the potential
meanings of acronyms, we have to extract them from plain text.",4.1 Candidates Generation,[0],[0]
We propose a strategy called Hybrid Generation to balance extraction accuracy and coverage.,4.1 Candidates Generation,[0],[0]
"Namely, we treat a phrase as a meaning candidate for an acronym if: (1) the initial letters of the phrase match the acronym and the phrase and the acronym co-occur in at least one document in the enterprise corpus; or (2) it is a valid candidate for the acronym in public knowledge bases (e.g. Wikipedia).",4.1 Candidates Generation,[0],[0]
The insight of this strategy is that the valid candidates missed by condition (1) are mainly public meanings which can be found in public knowledge bases.,4.1 Candidates Generation,[0],[0]
With this strategy we can make our system understand both the internal world and the external world.,4.1 Candidates Generation,[0],[0]
"As mentioned in Section 2, for each candidate meaning, we need to calculate its popularity score, which reveals how often the candidate meaning is used as the genuine meaning of the acronym.",4.2 Popularity Calculation,[0],[0]
"In previous research on Entity Linking, popularity is calculated as the fraction of times a candidate being the target page for an anchor text in a reference knowledge base (e.g. Wikipedia).",4.2 Popularity Calculation,[0],[0]
"However, in enterprises, we do not have a knowledge base with anchor links.",4.2 Popularity Calculation,[0],[0]
Thus we cannot calculate popularity in the same way.,4.2 Popularity Calculation,[0],[0]
"Here we propose to calculate two types of popularity to mimic the effect.
1.",4.2 Popularity Calculation,[0],[0]
Marginal Popularity.,4.2 Popularity Calculation,[0],[0]
"MP (mi) = Count(mi)∑n j=1Count(mj) , (1)
where m1, m2, . . .",4.2 Popularity Calculation,[0],[0]
", mn are the meaning candidates of acronym a and Count(mi) is the number of occurrences for mi in the corpus.
2.",4.2 Popularity Calculation,[0],[0]
"Conditional Popularity.
",4.2 Popularity Calculation,[0],[0]
"CP (mi) = Count(mi, a)∑n j=1Count(mj , a) , (2) where m1, m2, . .",4.2 Popularity Calculation,[0],[0]
"., mn are the meaning candidates of acronym a and Count(mi, a) is the number of document-level cooccurrences for mi and a in the corpus.
",4.2 Popularity Calculation,[0],[0]
Conditional Popularity can more reasonably reveal how often the acronym is used to represent each meaning candidate.,4.2 Popularity Calculation,[0],[0]
"However, due to the data sparsity issue in enterprises, many valid candidates may get zero value for conditional popularity since they may never co-occur with the acronyms in the enterprise corpus.",4.2 Popularity Calculation,[0],[0]
The Marginal Popularity does not have this problem since it is calculated from the raw counts of the candidates.,4.2 Popularity Calculation,[0],[0]
"Yet on the other hand, high marginal popularity score does not necessarily indicate high correlation between the candidate and the acronym.",4.2 Popularity Calculation,[0],[0]
"It is unclear how to combine the two scores into one popularity score, so we use both of them as features in the disambiguation model.",4.2 Popularity Calculation,[0],[0]
"In enterprises, people often create many variants (including abbreviations, plurals or even misspellings) for the same meaning, therefore many mined meaning candidates are actually equivalent.",4.3 Candidates Deduplication,[0],[0]
"For example, for the meaning “Certificate Authority” of the acronym “CA”, the variants include “Cert Auth”, “Certificate Authorities” and many others.",4.3 Candidates Deduplication,[0],[0]
It is important to deduplicate these variants before sending them to the disambiguation module.,4.3 Candidates Deduplication,[0],[0]
The deduplication helps aggregate disambiguation evidences and reduce noises.,4.3 Candidates Deduplication,[0],[0]
We design several heuristic rules1 to perform the deduplication.,4.3 Candidates Deduplication,[0],[0]
Experiments show that the rules can accurately group the variants together.,4.3 Candidates Deduplication,[0],[0]
"After grouping, we sort the variants within the same group based on their marginal popularity.",4.3 Candidates Deduplication,[0],[0]
The candidate with the largest marginal popularity is selected as the canonical candidate for the group.,4.3 Candidates Deduplication,[0],[0]
Other variants in the group will be deleted from the candidate list and their popularity scores will be aggregated to the canonical candidate.,4.3 Candidates Deduplication,[0],[0]
We maintain a table to record the variants for each canonical candidate.,4.3 Candidates Deduplication,[0],[0]
"In this step, we aim to harvest context words for each meaning candidate.",4.4 Context Harvesting,[0],[0]
These context words could be used to calculate context similarity with the query context.,4.4 Context Harvesting,[0],[0]
"For each meaning candidate m, we put its canonical form and all its variants (from the variants table in Section 4.3) into set S. Then we scan the enterprise corpus, each time we find a match of any e ∈ S, we harvest the words in a
1Due to space limitations, the detailed rules are omitted.",4.4 Context Harvesting,[0],[0]
"Example rules are “word overlap percentage after stemming > 0.8”, “corresponding component words share same prefix”.
width-W word window surrounding e as the context words of m. In our experiments we set window size as 30 after trying to vary the window size from 10 to 50 and finding 30 gives the best result.
",4.4 Context Harvesting,[0],[0]
"As mentioned before, some popular public meanings might be mentioned very rarely by their full names in the enterprise corpus since people directly use their acronyms most of the time.",4.4 Context Harvesting,[0],[0]
"Therefore, the above context harvesting process can only get very few context words for those public meanings.",4.4 Context Harvesting,[0],[0]
"To alleviate this, for each public meaning we add its Wikipedia page’s content as complementary context.",4.4 Context Harvesting,[0],[0]
"By doing so, we ensure almost all valid candidates get a reasonable amount of context words.",4.4 Context Harvesting,[0],[0]
We first train a candidate ranking model to rank candidates with respect to the likelihood of being the genuine meaning for the target acronym.,5.1 Candidate Ranking,[0],[0]
"In order to train a robust ranking model, we need to get adequate amount of labeled training data.",5.1.1 Training Data Generation,[0],[0]
"Manually labeling is obviously too expensive and it requires a lot of domain knowledge, which severely limits our framework’s generalization capability.",5.1.1 Training Data Generation,[0],[0]
"To tackle this problem, we propose to automatically generate training data via distant supervision.",5.1.1 Training Data Generation,[0],[0]
"The intuition is that since acronyms and the corresponding meanings are semantically equivalent, people use them interchangeably in enterprises.",5.1.1 Training Data Generation,[0],[0]
"Therefore we can fetch documents containing the meaning, replace the meaning with the corresponding acronym and treat the meaning as ground truth.",5.1.1 Training Data Generation,[0],[0]
Figure 3 shows an example of this automatic training data generation process.,5.1.1 Training Data Generation,[0],[0]
Any learning-to-rank algorithms can be used here.,5.1.2 Training Algorithm,[0],[0]
"In our system we utilize the LambdaMART algorithm (Burges, 2010) to train the model.",5.1.2 Training Algorithm,[0],[0]
Now we explain the features we developed for the candidate ranking model.,5.1.3 Features,[0],[0]
"First, we have the Marginal Popularity score and Conditional Popularity score as two context-independent features, which could compensate for each other.",5.1.3 Features,[0],[0]
"However, as discussed in the previous section, some popular public meanings (e.g., “Artificial Intelligence”) can be rarely mentioned in enterprise corpus by their full names, therefore both their marginal popularity score and conditional popularity score can be very low.",5.1.3 Features,[0],[0]
"To address this, we add a third feature called Wiki Popularity, which is calculated from Wikipedia anchor texts to capture how often an acronym refers to a public meaning in Wikipedia.",5.1.3 Features,[0],[0]
The fourth feature we adopt is Context Similarity.,5.1.3 Features,[0],[0]
We convert the harvested context for the meaning and the query context of the target acronym into TFIDF vectors and then compute their cosine similarity2.,5.1.3 Features,[0],[0]
"We also include two features (i.e. LeftNeighborScore and RightNeighborScore) to capture the effect of the immediate neighboring words, which are more important than further context words since immediate words could form phrases with the acronym.",5.1.3 Features,[0],[0]
"For example, if we see an acronym “SP” followed by the word “2”, then likely it stands for “Service Pack”.",5.1.3 Features,[0],[0]
"However, if we see “SP” followed by “2003”, then probably its genuine meaning is “SharePoint”.",5.1.3 Features,[0],[0]
The last feature we use is FullNamePercentage.,5.1.3 Features,[0],[0]
This feature is defined as the percentage of the meaning candidate’s component words appearing in the context of the target acronym.,5.1.3 Features,[0],[0]
Table 1 summarizes the features used to train the candidate ranking model.,5.1.3 Features,[0],[0]
"After getting the ranking results, we propose to apply a confidence estimation step to decide whether to trust the top ranked answer.",5.2 Confidence Estimation,[0],[0]
There are two motivations behind.,5.2 Confidence Estimation,[0],[0]
"First, our candidate generation approach is not perfect, therefore we could encounter cases in which the genuine meaning is not in our candidates.",5.2 Confidence Estimation,[0],[0]
"For such cases, the top ranked answer is obviously incorrect.",5.2 Confidence Estimation,[0],[0]
"Second, our training data is biased towards the internal meanings since external meanings may rarely appear with full names.
",5.2 Confidence Estimation,[0],[0]
"2One popular alternative to measure context similarity is using word embeddings (Mikolov et al., 2013; Li et al., 2015).",5.2 Confidence Estimation,[0],[0]
"In our system we experimented replacing TFIDF cosine similarity with word embedding similarity, or adding word embedding similarity as an additional feature, but both hurt the disambiguation accuracy.",5.2 Confidence Estimation,[0],[0]
"So we only included the TFIDF cosine similarity as the context similarity feature in our system.
",5.2 Confidence Estimation,[0],[0]
"As a result, the learned ranking model may lack the capability to properly rank the external meanings.",5.2 Confidence Estimation,[0],[0]
"In such cases, we would better have the system return nothing rather than directly provide a wrong answer to mislead the user.",5.2 Confidence Estimation,[0],[0]
"In this step, we train a confidence estimation model, which will estimate the top result’s confidence.",5.2 Confidence Estimation,[0],[0]
"Similar to the ranker training, here the training data is also automatically generated.",5.2.1 Training Data Generation,[0],[0]
"We run the learned ranker on some distant labeled data (generated from a different corpus), and then check if the top ranked answer is correct or not.",5.2.1 Training Data Generation,[0],[0]
"If it is correct, we generate a positive training example; otherwise we make a negative training example.",5.2.1 Training Data Generation,[0],[0]
Any classification algorithms can be used here.,5.2.2 Training Algorithm,[0],[0]
"In our system we utilize the MART boosted tree algorithm (Friedman, 2000) to train the model.",5.2.2 Training Algorithm,[0],[0]
We design 7 features (summarized in Table 2) to train the confidence estimation model.,5.2.3 Features,[0],[0]
"There are two intuitions behind: (1) If the top-ranked answer’s ranking score is very small, or the topranked answer’s score is close to the secondranked answer’s score, then the ranking is not very confident; (2) If the acronym has a dominating candidate in the public domain (e.g., “Personal Computer” is the dominating candidate for “PC”), and the candidates’ Wiki popularity distribution is significantly different from their marginal/conditional popularity distributions, then the ranker’s output is not very confident.",5.2.3 Features,[0],[0]
"The first intuition covers the first 3 features, while the second intuition covers the last 4 features.",5.2.3 Features,[0],[0]
We have discussed that one particular motivation for confidence estimation is that the candidate ranking stage has some bias so it does not always rank public meanings at top when they are correct.,5.3 Final Selection,[0],[0]
"Therefore, assuming the confidence estimation model can remove incorrect top-ranked result, we still need one additional step to decide if any public meaning is correct, which we call a final selection model.",5.3 Final Selection,[0],[0]
"In this step, we determine whether to return the most popular public meaning (based on Wiki Popularity) as the final answer, and this step is only triggered when the confidence estimator judges that the ranking result is unconfident.
",5.3 Final Selection,[0],[0]
The goal of the final selection model is similar to that of the confidence estimation model.,5.3 Final Selection,[0],[0]
"In confidence estimation, we judge whether the topranked answer is correct; while in final selection, we check whether the most popular external meaning is correct.",5.3 Final Selection,[0],[0]
"Thanks to this similarity, we can reuse the data, features and training algorithm in confidence estimation model.",5.3 Final Selection,[0],[0]
"We take the same training data in Section 5.2.1 and update the labels correspondingly: if the genuine answer is the most popular external meaning, we generate a positive example; otherwise we make a negative one.",5.3 Final Selection,[0],[0]
We use both the Microsoft Answer Corpus (MAC) and the Microsoft Yammer Corpus (MYC) as the mining corpus.,6.1.1 Mining and Training Corpus,[0],[0]
These corpus are kindly shared to us by Microsoft for research purpose.,6.1.1 Mining and Training Corpus,[0],[0]
MAC contains 0.3 million web pages from a Microsoft internal question answering forum.,6.1.1 Mining and Training Corpus,[0],[0]
MYC is consisted of 6.8 million posts from Microsoft’s Yammer social network.,6.1.1 Mining and Training Corpus,[0],[0]
"In total, our mining module harvested 5287 acronyms and 17258 meaning candidates from this joint corpus.
",6.1.1 Mining and Training Corpus,[0],[0]
"For model training, the confidence estimation model and final selection model need to be trained on a different corpus than the candidate ranking model.",6.1.1 Mining and Training Corpus,[0],[0]
"So we train the candidate ranking model
on MAC, with 12500 training examples being automatically generated; and train the confidence estimation and final selection model on MYC, with 40000 training instances being generated.",6.1.1 Mining and Training Corpus,[0],[0]
We prepared four datasets3 for evaluation purposes.,6.1.2 Evaluation Datasets,[0],[0]
The first one Manual is obtained from the recent pages of Microsoft answer forum.,6.1.2 Evaluation Datasets,[0],[0]
Note these pages are disjoint from those used as mining/training corpus.,6.1.2 Evaluation Datasets,[0],[0]
We randomly sampled 300 pages and filtered out pages which do not contain ambiguous acronyms.,6.1.2 Evaluation Datasets,[0],[0]
"After filtering, 240 test cases were left and we manually labeled them.
",6.1.2 Evaluation Datasets,[0],[0]
The second one Distant is generated via distant labeling on Microsoft Office365 documents.,6.1.2 Evaluation Datasets,[0],[0]
We sampled 2000 documents which contain at least one occurrence of a meaning candidate.,6.1.2 Evaluation Datasets,[0],[0]
Then we replaced the meanings with the corresponding acronyms and treat the meanings as ground truths.,6.1.2 Evaluation Datasets,[0],[0]
"We manually checked through this dataset to remove some bad cases (e.g., “AS” for “App Store”).",6.1.2 Evaluation Datasets,[0],[0]
"This resulted in a test set of 1949 test cases.
",6.1.2 Evaluation Datasets,[0],[0]
"Comparing the Manual dataset with the Distant dataset, the Manual one, though in smaller size, can more accurately evaluate the system performance, since the target acronyms in it are sampled from the real distribution, while in the Distant dataset acronyms are artificially generated from
3Due to data confidentiality issue, we were unable to directly release these datasets.
",6.1.2 Evaluation Datasets,[0],[0]
randomly sampled meanings.,6.1.2 Evaluation Datasets,[0],[0]
We also want to compare our method with the state-of-the-art Entity Linking (EL) systems based on public knowledge bases such as Wikipedia.,6.1.2 Evaluation Datasets,[0],[0]
"However, it is unfair to directly compare as most enterprise specific meanings are unknown to them.",6.1.2 Evaluation Datasets,[0],[0]
"Therefore, we need to only consider cases where the true meaning is a public meaning covered by both our system and the compared system.",6.1.2 Evaluation Datasets,[0],[0]
"By filtering the distant dataset from Office365, we get the third dataset JoinW (1659 test cases) for comparing with the Wikifier (Ratinov et al., 2011), and the fourth dataset JoinA (237 test cases) for comparing with AIDA (Hoffart et al., 2011).",6.1.2 Evaluation Datasets,[0],[0]
"We compare the following ablations of our system, to illustrate the effectiveness of the features and components.
",6.2.1 Ablations of Our System,[0],[0]
"• Internal Popularity (IP): Only the internal popularity features (i.e., marginal popularity and conditional popularity).
",6.2.1 Ablations of Our System,[0],[0]
"• Popularity (P): The internal popularity features plus Wiki popularity features.
",6.2.1 Ablations of Our System,[0],[0]
• Popularity+Context (P+C):,6.2.1 Ablations of Our System,[0],[0]
"The popularity features plus context similarity feature.
",6.2.1 Ablations of Our System,[0],[0]
"• Popularity+Context+Neighbbor (P+C+N): The popularity features, context similarity feature and immediate neighbor features.
",6.2.1 Ablations of Our System,[0],[0]
• Popularity+ Context+,6.2.1 Ablations of Our System,[0],[0]
"Neighbbor+ Fullname (a.k.a. Candidate Ranker, or CR): Using all the features in candidate ranking module.
",6.2.1 Ablations of Our System,[0],[0]
"• Candidate Ranker + Confidence Estimator (CR+ CE): Using the candidate ranking model plus the confidence estimation model.
",6.2.1 Ablations of Our System,[0],[0]
"• Candidate Ranker + Confidence Estimator + Final Selector (a.k.a. Acronym Disambiguator, or AD):",6.2.1 Ablations of Our System,[0],[0]
"Using the candidate ranking model, the confidence estimation model and the final selection model.",6.2.1 Ablations of Our System,[0],[0]
Full version of our system.,6.2.1 Ablations of Our System,[0],[0]
"We also compare our method with two state-ofthe-art Entity Linking (EL) systems.
",6.2.2 State-of-the-art EL Systems,[0],[0]
"• Wikifier: a popular EL system using machine learning to combine various features together.
• AIDA: a robust EL system using mention-entity graph to find the best mention-entity mapping.",6.2.2 State-of-the-art EL Systems,[0],[0]
We first conduct experiments to evaluate the quality of the acronym/meaning pairs harvested through our offline mining module.,6.3 Quality of Mined Acronyms/Meanings,[0],[0]
"Out of the 17258 mined pairs, we randomly sampled 2000 of them and asked 5 domain experts to manually check their validness.",6.3 Quality of Mined Acronyms/Meanings,[0],[0]
An acronym/meaning pair is considered as valid if the majority of the experts think the acronym is indeed used to abbreviate the meaning.,6.3 Quality of Mined Acronyms/Meanings,[0],[0]
"For example, (AS, Analysis Service) is a valid pair, but (AS, App Store) is considered as invalid because people will not actually use AS to represent App Store.",6.3 Quality of Mined Acronyms/Meanings,[0],[0]
"Among the sampled 2000 pairs, 94.5% are labeled as valid, indicating our offline mining module can accurately extract acronym/meaning pairs from enterprise corpus.",6.3 Quality of Mined Acronyms/Meanings,[0],[0]
"It is hard to precisely evaluate the coverage/recall of our mining method, since it is very difficult to obtain the complete meaning list for a given acronym.",6.3 Quality of Mined Acronyms/Meanings,[0],[0]
"To get a rough idea, we randomly picked up 100 acronyms and asked the 5 domain experts to enumerate the valid meanings for these acronyms.",6.3 Quality of Mined Acronyms/Meanings,[0],[0]
In total we got 230 valid meanings and all of them are covered by the mined pairs.,6.3 Quality of Mined Acronyms/Meanings,[0],[0]
"We first conduct experiments to evaluate the disambiguation performance of our ranking model, and compare the helpfulness of the features used in the model.",6.4 Disambiguation Performance,[0],[0]
"Figure 4 shows the precision (i.e., percentage of correctly disambiguated cases among all predicted cases), recall (i.e., percentage of correctly disambiguated cases among all test cases) and F1 (i.e., harmonic mean of precision and recall) of the compared methods on the Manual dataset and the Distant dataset.",6.4 Disambiguation Performance,[0],[0]
"In terms of the helpfulness of the features, the context similarity feature and the immediate neighbor features contribute most to the performance gain.",6.4 Disambiguation Performance,[0],[0]
"Other features are less helpful, yet still bring improvements to the overall performance.
",6.4 Disambiguation Performance,[0],[0]
Next we conduct experiments to illustrate the effectiveness of the confidence estimation module and the final selection module in our system.,6.4 Disambiguation Performance,[0],[0]
"Figure 5 shows the precision, recall and F1 of the compared system configurations on the Manual and Distant dataset.",6.4 Disambiguation Performance,[0],[0]
"As can be seen, the confidence estimation module can improve precision at the cost of hurting recall.",6.4 Disambiguation Performance,[0],[0]
"Fortunately, the final selection module can recover some recall losses without sacrificing too much on precision.",6.4 Disambiguation Performance,[0],[0]
"In
terms of the F1 measure, the final system achieves the best performance.
",6.4 Disambiguation Performance,[0],[0]
"Note that the ablation P+C naturally corresponds to the existing acronym disambiguation approaches (Feng et al., 2009; Pakhomov et al., 2005; Pustejovsky et al., 2001; Stevenson et al., 2009; Yu et al., 2006) mainly relying on context words and domain specific resources.",6.4 Disambiguation Performance,[0],[0]
These approaches do not specifically distinguish internal and external meanings.,6.4 Disambiguation Performance,[0],[0]
"They merely rely on the internal corpus to discover information about external meanings, which is quite ineffective in the scenario of enterprise acronym disambiguation (as discussed in Section 1).",6.4 Disambiguation Performance,[0],[0]
"In comparison, our system (AD) is able to leverage public resources together with the internal corpus to better handle the problem and therefore significantly outperforms them.",6.4 Disambiguation Performance,[0],[0]
We also compare our system (AD) with two stateof-the-art Entity Linking (EL) systems: Wikifier and AIDA.,6.5 Comparison with EL Systems,[0],[0]
"As explained in Section 6.1.2, we
made two datasets (i.e., JoinW and JoinA) for fair comparisons.",6.5 Comparison with EL Systems,[0],[0]
"Figure 6(a) and Figure 6(b) present the comparison of our AD system against Wikifer and AIDA, respectively.",6.5 Comparison with EL Systems,[0],[0]
"As we can see from the figures, AD significantly outperforms both Wikifier and AIDA on all three measures.",6.5 Comparison with EL Systems,[0],[0]
"The reason is that even for public meanings (e.g., Operating System) indexed by Wikifier and AIDA, the usage of them could be quite different in enterprises (e.g., inside Microsoft people talk more about designing Operating System rather than how to install it).",6.5 Comparison with EL Systems,[0],[0]
"Wikifier and AIDA utilize information from public knowledge bases (e.g., Wikipedia) to generate features, therefore can hardly capture such enterprisespecific signals.",6.5 Comparison with EL Systems,[0],[0]
"In contrast, our AD system mines disambiguation features directly from the enterprise corpus and utilizes them together with the public signals.",6.5 Comparison with EL Systems,[0],[0]
"As a result, it can more accurately represent the characteristics of the enterprise and lead to much better disambiguation performances.",6.5 Comparison with EL Systems,[0],[0]
Acronym meaning discovery has received a lot of attentions in vertical domains (mainly in biomedical).,7 Related Work,[0],[0]
"Most of the proposed approaches (Adar, 2004; Ao and Takagi, 2005; Park and Byrd, 2001; Schwartz and Hearst, 2002; Wren et al., 2002) utilized generic rules or text patterns (e.g. brackets, colons) to discover acronym meanings.",7 Related Work,[0],[0]
"These methods are usually based on the assumption that
acronyms are co-mentioned with the corresponding meanings in the same document.",7 Related Work,[0],[0]
"However, in enterprises, this assumption rarely holds.",7 Related Work,[0],[0]
"Enterprises themselves are closed ecosystems, so it is very common for people to define the acronyms somewhere and use them elsewhere.",7 Related Work,[0],[0]
"As a result, such methods cannot be used for acronym meaning discovery in enterprises.
",7 Related Work,[0],[0]
"Recently, there have been a few works (Jain et al., 2007; Larkey et al., 2000; Nadeau and Turney, 2005; Taneva et al., 2013) on automatically mining acronym meanings by leveraging Web data (e.g., query sessions, click logs).",7 Related Work,[0],[0]
"However, it is hard to apply them directly to enterprises, since most data in enterprises are raw text and therefore the query sessions/click logs are rarely available.
",7 Related Work,[0],[0]
"Acronym disambiguation can be seen as a special case for the Entity Linking (EL) (Ji and Grishman, 2011; Dredze et al., 2010) problem.",7 Related Work,[0],[0]
Approaches that link entity mentions to Wikipedia date back to Bunescu et.,7 Related Work,[0],[0]
"al’s work (Bunescu and Paşca, 2006).",7 Related Work,[0],[0]
They computed the cosine similarity between the text around the mention and the entity candidate’s Wikipedia page.,7 Related Work,[0],[0]
The referent entity with the maximum similarity score is selected as the disambiguation result.,7 Related Work,[0],[0]
"Cucerzan’s work (Cucerzan, 2007) is the first one to realize the effectiveness of using topical coherence to globally perform EL.",7 Related Work,[0],[0]
"In that work, the topical coherence between the referent entity candidate and other entities within the same context is calculated based on their overlaps in categories and incoming links in Wikipedia.",7 Related Work,[0],[0]
"Recently, several methods (Hoffart et al., 2011; Li et al., 2013, 2016; Ratinov et al., 2011; Shen et al., 2012; Cheng and Roth, 2013) also tried to enrich “context similarity” and “topical coherence” using hybrid strategies.",7 Related Work,[0],[0]
Shen et.,7 Related Work,[0],[0]
"al (Shen et al., 2015) provided a comprehensive survey for the techniques used in EL.",7 Related Work,[0],[0]
"However, these EL techniques cannot be used for acronym disambiguation in enterprises, since most enterprise meanings are not covered by public knowledge bases, and there are rarely any domain-specific knowledge bases available in enterprises.",7 Related Work,[0],[0]
"Automatic knowledge base construction (Suchanek et al., 2013) is promising, but the quality is far from applicable.",7 Related Work,[0],[0]
"Moreover, the structural information (e.g. entity taxonomy, crossdocument hyperlinks) within Wikipedia, is rarely available in enterprises.
",7 Related Work,[0],[0]
"Most of the previous work (Feng et al., 2009;
Pakhomov et al., 2005; Pustejovsky et al., 2001; Stevenson et al., 2009; Yu et al., 2006) on acronym disambiguation heavily rely on context words and domain specific resources.",7 Related Work,[0],[0]
"In comparison, our method explored a more comprehensive set of domain-independent features.",7 Related Work,[0],[0]
"Moreover, our method used a much less restrictive way to discover meaning candidates and training data, which is far more general than the methods relying on strict definition patterns (Schwartz and Hearst, 2002).",7 Related Work,[0],[0]
Another particular limitation of all these previous work is that they do not distinguish internal and external meanings.,7 Related Work,[0],[0]
"They merely rely on the internal corpus to discover information about external meanings, which is quite ineffective.",7 Related Work,[0],[0]
"In this paper, we studied the Acronym Disambiguation for Enterprises problem.",8 Conclusions,[0],[0]
"We proposed a novel, end-to-end framework to solve this problem.",8 Conclusions,[0],[0]
Our framework takes the enterprise corpus as input and produces a high-quality acronym disambiguation system as output.,8 Conclusions,[0],[0]
"The disambiguation models are trained via distant supervised learning, without requiring any manually labeled training examples.",8 Conclusions,[0],[0]
"Different from all the previous acronym disambiguation approaches, our system is capable of accurately resolving acronyms to both enterprise-specific meanings and public meanings.",8 Conclusions,[0],[0]
Experimental results on Microsoft enterprise data demonstrated that our system can effectively construct acronym/meaning repositories from scratch and accurately disambiguate acronyms to their meanings with over 90% precision.,8 Conclusions,[0],[0]
"Furthermore, our proposed framework can be easily deployed to any enterprises without requiring any domain knowledge.",8 Conclusions,[0],[0]
Acronyms are abbreviations formed from the initial components of words or phrases.,abstractText,[0],[0]
"In enterprises, people often use acronyms to make communications more efficient.",abstractText,[0],[0]
"However, acronyms could be difficult to understand for people who are not familiar with the subject matter (new employees, etc.), thereby affecting productivity.",abstractText,[0],[0]
"To alleviate such troubles, we study how to automatically resolve the true meanings of acronyms in a given context.",abstractText,[0],[0]
Acronym disambiguation for enterprises is challenging for several reasons.,abstractText,[0],[0]
"First, acronyms may be highly ambiguous since an acronym used in the enterprise could have multiple internal and external meanings.",abstractText,[0],[0]
"Second, there are usually no comprehensive knowledge bases such as Wikipedia available in enterprises.",abstractText,[0],[0]
"Finally, the system should be generic to work for any enterprise.",abstractText,[0],[0]
In this work we propose an end-to-end framework to tackle all these challenges.,abstractText,[0],[0]
The framework takes the enterprise corpus as input and produces a high-quality acronym disambiguation system as output.,abstractText,[0],[0]
"Our disambiguation models are trained via distant supervised learning, without requiring any manually labeled training examples.",abstractText,[0],[0]
"Therefore, our proposed framework can be deployed to any enterprise to support highquality acronym disambiguation.",abstractText,[0],[0]
Experimental results on real world data justified the effectiveness of our system.,abstractText,[0],[0]
Guess Me if You Can: Acronym Disambiguation for Enterprises,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 366–376 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1034",text,[0],[0]
"With the rapid growth of products reviews at the web, it has become common for people to read reviews before making a purchase decision.",1 Introduction,[0],[0]
The reviews usually contain abundant consumers’ personal experiences.,1 Introduction,[0],[0]
It has led to a significant influence on financial gains and fame for businesses.,1 Introduction,[0],[0]
"Existing studies have shown that an extra halfstar rating on Yelp causes restaurants to sell out 19% points more frequently (Anderson and Magruder, 2012), and a one-star increase in Yelp rating leads to a 5-9 % increase in revenue (Luca, 2011).",1 Introduction,[0],[0]
"This, unfortunately, gives strong incentives for imposters (called spammers) to game the system.",1 Introduction,[0],[0]
They post fake reviews or opinions (called review spam) to promote or to discredit some targeted products and services.,1 Introduction,[0],[0]
"The news from BBC has shown that around 25% of Yelp reviews could be fake.1 Therefore, it is urgent to detect review s-
1http://www.bbc.com/news/technology-24299742
pam, to ensure that the online review continues to be trusted.
",1 Introduction,[0],[0]
Jindal and Liu (2008) make the first step to detect review spam.,1 Introduction,[0],[0]
Most efforts are devoted to exploring effective linguistic and behavioral features by subsequent work to distinguish such spam from the real reviews.,1 Introduction,[0],[0]
"However, to notice such patterns or form behavioral features, developers should take a long time to observe the data, because the features are based on statistics.",1 Introduction,[0],[0]
"For instance, the feature activity window proposed by Mukherjee et al. (2013c) is to measure the activity freshness of reviewers.",1 Introduction,[0],[0]
It usually takes several months to count the difference of timestamps between the last and first reviews for reviewers.,1 Introduction,[0],[0]
"When the features show themselves finally, some major damages might have already been done.",1 Introduction,[0],[0]
"Thus, it is important to design algorithms that can detect review spam as soon as possible, ideally, right after they are posted by the new reviewers.",1 Introduction,[0],[0]
"It is a coldstart problem which is the focus of this paper.
",1 Introduction,[0],[0]
"In this paper, we assume that we must identify fake reviews immediately when a new reviewer posts just one review.",1 Introduction,[0],[0]
"Unfortunately, it is very difficult because the available information for detecting fake reviews is very poor.",1 Introduction,[0],[0]
Traditional behavioral features based on the statistics can only work well on users’ abundant behaviors.,1 Introduction,[0],[0]
"The more behavioral information obtained, the more effective the traditional behavioral features are (see experiments in Section 3 ).",1 Introduction,[0],[0]
"In the scenario of cold-start, a new reviewer only has a behavior: post a review.",1 Introduction,[0],[0]
"As a result, we can not get effective behavioral features from the data.",1 Introduction,[0],[0]
"Although, the linguistic features of reviews do not need to take much time to form, Mukherjee et al. (2013c) have proved that the linguistic features are not effective enough in detecting real-life fake reviews from the commercial websites, where we also obtain the same observation (the details are shown in Section 3).
",1 Introduction,[0],[0]
"366
Therefore, the main difficulty of the cold-start spam problem is that there are no sufficient behaviors of the new reviewers for constructing effective behavioral features.",1 Introduction,[0],[0]
"Nevertheless, there is ample textual and behavioral information contained in the abundant reviews posted by the existing reviewers (Figure 1).",1 Introduction,[0],[0]
We could employ behavioral information of existing similar reviewers to a new reviewer to approximate his behavioral features.,1 Introduction,[0],[0]
"We argue that a reviewer’s individual characteristics such as background information, motivation, and interactive behavior style have a great influence on a reviewer’s textual and behavioral information.",1 Introduction,[0],[0]
So the textual information and the behavioral information of a reviewer are correlated with each other (similar argument in Li et al. (2016)).,1 Introduction,[0],[0]
"For example, the students of the college are likely to choose the youth hostel during summer vacation and tend to comment the room price in their reviews.",1 Introduction,[0],[0]
"But the financial analysts on a business trip may tend to choose the business hotel, the environment and service are what they care about in their reviews.
",1 Introduction,[0],[0]
"To augment the behavioral information of the new reviewers in the cold-start problem, we first try to find the textual information which is similar with that of the new reviewer, from the existing reviews.",1 Introduction,[0],[0]
"There are several ways to model the textual information of the review spam, such as Unigram (Mukherjee et al., 2013c), POS (Ott et al., 2011) and LIWC (Linguistic Inquiry and Word Count) (Newman et al., 2003).",1 Introduction,[0],[0]
"We employ the CNN (Convolutional Neural Network) to model the review text, which has been proved that it can capture complex global semantic information that is difficult to express using traditional discrete manual features (Ren and Zhang, 2016).",1 Introduction,[0],[0]
Then we employ the behavioral information which is correlated with the found textual information to approximate the behavioral information of the new reviewer.,1 Introduction,[0],[0]
"An intuitive approach is to search the most similar existing review for the new review, then take the found reviewer’s behavioral features as the new reviewers’ features (detailed in Section 5.3).",1 Introduction,[0],[0]
"However, there is abundant behavioral information in the review graph (Figure 1), it is difficult for the traditional discrete manual behavioral features to record the global behavioral information (Wang et al., 2016).",1 Introduction,[0],[0]
"Moreover, the traditional features can not capture the reviewer’s individual characteristics, because there is no explicit characteristic tag available in the review system (experi-
ments in Section 5.3).",1 Introduction,[0],[0]
"So, we propose a neural network model to jointly encode the textual and behavioral information into the review embeddings for detecting the review spam in the cold-start problem.",1 Introduction,[0],[0]
"By encoding the review graph structure (Figure 1), the proposed model can record the global footprints of the existing reviewers in an unsupervised way, and further record the reviewers’ latent characteristic information in the footprints.",1 Introduction,[0],[0]
The jointly learnt review embeddings can model the correlation of the reviewers’ textual and behavioral information.,1 Introduction,[0],[0]
"When a new reviewer posts a review, the proposed model can represent the review with the similar textual information and the correlated behavioral information encoded in the word embeddings.",1 Introduction,[0],[0]
"Finally, the embeddings of the new review are fed into a classifier to identify whether it is spam or not.
",1 Introduction,[0],[0]
"In summary, our major contributions include: • To our best knowledge, this is the first work
that explores the cold-start problem in review spam detection.",1 Introduction,[0],[0]
We qualitatively and quantitatively prove that the traditional linguistic and behavioral features are not effective enough in detecting review spam for the coldstart task.,1 Introduction,[0],[0]
• We propose a neural network model to jointly encode the textual and behavioral information into the review embeddings for the cold-start spam detection task.,1 Introduction,[0],[0]
It is an unsupervised distributional representation model which can learn from large scale unlabeled review data.,1 Introduction,[0],[0]
• Experimental results on two domains (hotel and restaurant) give good confidence that the proposed model performs effectively in the cold-start spam detection task.,1 Introduction,[0],[0]
Jindal and Liu (2008) make the first step to detect review spam.,2 Related Work,[0],[0]
"Subsequent work devoted most
efforts to explore effective features and spammerlike clues.
",2 Related Work,[0],[0]
Linguistic features: Ott et al. (2011) applied psychological and linguistic clues to identify review spam; Harris (2012) explored several writing style features.,2 Related Work,[0],[0]
Syntactic stylometry for review spam detection was investigated in Feng et al. (2012a); Xu and Zhao (2012) using deep linguistic features for finding deceptive opinion spam; Li et al. (2013) studied the topics in the review spam; Li et al. (2014b) further analyzed the general difference of language usage.,2 Related Work,[0],[0]
Fornaciari and Poesio (2014) proved the effectiveness of the N-grams in detecting deceptive Amazon book reviews.,2 Related Work,[0],[0]
The effectiveness of the N-grams was also explored in Cagnina and Rosso (2015).,2 Related Work,[0],[0]
Li et al. (2014a) proposed a positive-unlabeled learning method based on unigrams and bigrams; Kim et al. (2015) carried out a frame-based deep semantic analysis.,2 Related Work,[0],[0]
Hai et al. (2016) exploited the relatedness of multiple review spam detection tasks and available unlabeled data to address the scarcity of labeled opinion spam data by using linguistic features.,2 Related Work,[0],[0]
"Besides, (Ren and Zhang, 2016) proved that the CNN model is more effective than the RNN and the traditional discrete manual linguistic features.",2 Related Work,[0],[0]
"Hovy (2016) used N-gram generative models to produce reviews and evaluated their effectiveness.
",2 Related Work,[0],[0]
Behavioral features: Lim et al. (2010) analyzed reviewers’ rating behavioral features; Jindal et al. (2010) identified unusual review patterns which can represent suspicious behaviors of reviews; Li et al. (2011) proposed a two-view semisupervised co-training method base on behavioral features.,2 Related Work,[0],[0]
Feng et al. (2012b) study the distributions of individual spammers’ behaviors.,2 Related Work,[0],[0]
The group spammers’ behavioral features were studied in Mukherjee et al. (2012).,2 Related Work,[0],[0]
"Temporal patterns of spammers were investigated by Xie et al. (2012), Fei et al. (2013); Li et al. (2015) explored the temporal and spatial patterns.",2 Related Work,[0],[0]
"The review graph was analyzed by Wang et al. (2011), Akoglu et al. (2013); Mukherjee et al. (2013a) studied the spamicity of reviewers.",2 Related Work,[0],[0]
"Mukherjee et al. (2013c), Mukherjee et al. (2013b) proved that reviewers’ behavioral features are more effective than reviews’ linguistic features for detecting review spam.",2 Related Work,[0],[0]
"Based on this conclusion, recently, researchers (Rayana and Akoglu, 2015; KC and Mukherjee, 2016) have put more efforts in employing reviewers’ behavioral features for de-
tecting review spam, the intuition behind which is to capture the reviewers’ actions and supposes that those reviews written with spammer-like behaviors would be spam.",2 Related Work,[0],[0]
Wang et al. (2016) explored a method to learn the review representation with global behavioral information.,2 Related Work,[0],[0]
Viviani and Pasi (2017) concentrated on the aggregation process with respect to each single veracity feature.,2 Related Work,[0],[0]
"As a new reviewer posted just one review and we have to identify it immediately, the major challenge of the cold-start task is that the available information about the new reviewer is very poor.",3 Whether Traditional Features are Effective,[0],[0]
The new reviewer only provides us with one review record.,3 Whether Traditional Features are Effective,[0],[0]
"For most traditional features based on the statistics, they can not form themselves or make no sense, such as the percentage of reviews written at weekends (Li et al., 2015), the entropy of rating distribution of user’s review (Rayana and Akoglu, 2015).",3 Whether Traditional Features are Effective,[0],[0]
"To investigate whether traditional features are effective in the cold-start task, we conducted experiments on the Yelp dataset in Mukherjee et al. (2013c).",3 Whether Traditional Features are Effective,[0],[0]
"We trained SVM models with different features on the existing reviews posted before January 1, 2012, and tested on the new reviews which just posted by the new reviewers after January 1, 2012.",3 Whether Traditional Features are Effective,[0],[0]
Results are shown in Table 1.,3 Whether Traditional Features are Effective,[0],[0]
The linguistic features need not take much time to form.,3.1 Linguistic Features’ Poor Performance,[0],[0]
"But Mukherjee et al. (2013c) have proved that the linguistic features are not effective enough in detecting real-life fake reviews from the commercial websites, compared with the performances on the crowd source datasets (Ott et al., 2011).",3.1 Linguistic Features’ Poor Performance,[0],[0]
"They showed that the word bigrams perform better than the other linguistic features, such as LIWC (Newman et al., 2003; Pennebaker et al., 2007), part-of-speech sequence patterns (Mukherjee and Liu, 2010), deep syntax (Feng et al., 2012a), information gain (Mukherjee et al., 2013c) and so on.",3.1 Linguistic Features’ Poor Performance,[0],[0]
"So, we conduct experiments with the word bigrams feature.",3.1 Linguistic Features’ Poor Performance,[0],[0]
"As shown in Table 1 (a, b) row 1, the word bigrams result in only around 55% in accuracy in both the hotel and restaurant domains.",3.1 Linguistic Features’ Poor Performance,[0],[0]
"It indicates that the most effective traditional linguistic feature (i.e., the word bigrams) can’t detect the review spam effectively in the cold start task.",3.1 Linguistic Features’ Poor Performance,[0],[0]
"Abundant Information
Because there is not enough available information about the new reviewer, for most traditional behavioral features based on the statistical mechanism, they couldn’t form themselves or make no sense.",3.2 Behavioral Features only Work Well with,[0],[0]
We investigated the previous work and found that there are three behavioral features can be applied to the cold-start task.,3.2 Behavioral Features only Work Well with,[0],[0]
"They are proposed by Mukherjee et al. (2013b), i.e., 1.Review length (RL) : the length of the new review posted by the new reviewer; 2.Reviewer deviation (RD): the absolute rating deviation of the new reviewer’s review from other reviews on the same business; 3.Maximum content similarity (MCS) : the maximum content similarity (using cosine similarity) between the new reviewer’s review with other reviews on the same business.
",3.2 Behavioral Features only Work Well with,[0],[0]
"Table 1 (a, b) row 2 shows the experiment results by the combinations of the bigrams feature and the three behavioral features described above.",3.2 Behavioral Features only Work Well with,[0],[0]
The behavioral features make around 5% improvement in accuracy in the hotel domain (2.7% in the restaurant domain) as compared with only using bigrams.,3.2 Behavioral Features only Work Well with,[0],[0]
The accuracy is improved but it is just near 60% in average.,3.2 Behavioral Features only Work Well with,[0],[0]
It indicates that the traditional features are not effective enough with poor behavioral information.,3.2 Behavioral Features only Work Well with,[0],[0]
"What’s more, the behavioral features cause around 4.6% decrease in F1-
score and around 19% decrease in Recall in both hotel and restaurant domains.",3.2 Behavioral Features only Work Well with,[0],[0]
It is obvious that there is more false-positive review spam caused by the behavioral features as compared to only using bigrams.,3.2 Behavioral Features only Work Well with,[0],[0]
"It further indicates that the traditional behavioral features’ discrimination for review spam gets to be weakened by the poor behavioral information.
",3.2 Behavioral Features only Work Well with,[0],[0]
"To go a step further, we carried experiments with the three behavioral features which are formed on abundant behavioral information.",3.2 Behavioral Features only Work Well with,[0],[0]
"When the new reviewers continue to post more reviews in after weeks, their behavioral information gets to be more.",3.2 Behavioral Features only Work Well with,[0],[0]
Then the review system could obtain sufficient data to extract behavior features as compared to the poor information in the cold-start period.,3.2 Behavioral Features only Work Well with,[0],[0]
So the behavioral features with abundant information make an obvious improvement in accuracy (6.4%) in the hotel domain (Table 1 (a) row 3) as compared with the results in Table 1 (a) row 2.,3.2 Behavioral Features only Work Well with,[0],[0]
But it is only 0.6% in the restaurant domain.,3.2 Behavioral Features only Work Well with,[0],[0]
"By statistics on the datasets, we found that the new reviewers posted about 54.4 reviews in average after their first post in the hotel domain, but it is only 10 reviews in average for the new reviewers in the restaurant domain.",3.2 Behavioral Features only Work Well with,[0],[0]
The added behavioral information in the hotel domain is richer than that in the restaurant domain.,3.2 Behavioral Features only Work Well with,[0],[0]
"It indicates that:
• the traditional behavioral features can only work well with abundant behavioral information; • the more behavioral information can be obtained, the more effective the traditional behavioral features are.",3.2 Behavioral Features only Work Well with,[0],[0]
The difficulty of detecting review spam in the cold-start task is that the available behavioral information of new reviewers is very poor.,4 The Proposed Model,[0],[0]
"The new reviewer just posted one review and we have to filter it out immediately, there is not any historical review provided to us.",4 The Proposed Model,[0],[0]
"As we argued, the textual information and the behavioral information of a reviewer are correlated with each other.",4 The Proposed Model,[0],[0]
"So, to augment the behavioral information of new reviewers, we try to find the textual information which is similar with that of the new reviewer, from existing reviews.",4 The Proposed Model,[0],[0]
Then we take the behavioral information which is correlated with the found textual information as the most possible behavioral information of the new reviewer.,4 The Proposed Model,[0],[0]
"For this purpose, we propose a neural network model to jointly encode the textual and behavioral information into the review embeddings for detecting the review spam in the cold-start problem (shown in Figure 2).",4 The Proposed Model,[0],[0]
"When a new reviewer posts a review, the neural network can represent the review with the similar textual information and the correlated behavioral information encoded in the word embeddings.",4 The Proposed Model,[0],[0]
"Finally, embeddings of the new review are fed into a classifier to identify whether it is spam or not.",4 The Proposed Model,[0],[0]
"In Figure 1, there is a part of review graph which is simplified from the Yelp website.",4.1 Behavioral Information Encoding,[0],[0]
"As it shows, the review graph contains the global behavioral information (footprints) of the existing reviewers.",4.1 Behavioral Information Encoding,[0],[0]
"Because the motivations of the spammers and the real reviewers are totally different, the distributions of the behavioral information of them are different (Mukherjee et al., 2013a).",4.1 Behavioral Information Encoding,[0],[0]
"There are businesses (even highly reputable ones) paying people to write fake reviews for them to promote their products/services and/or to discredit their competitors (Liu, 2015).",4.1 Behavioral Information Encoding,[0],[0]
So the behavioral footprints of the spammers are decided by the demands of the businesses.,4.1 Behavioral Information Encoding,[0],[0]
But the real reviewers only post reviews to the product or services they have actually experienced.,4.1 Behavioral Information Encoding,[0],[0]
Their behavioral footprints are influenced by their own characteristics.,4.1 Behavioral Information Encoding,[0],[0]
Previous work extracts behavioral features for reviewers from these behavioral information.,4.1 Behavioral Information Encoding,[0],[0]
But it is impractical to the new reviewers in the cold-start task.,4.1 Behavioral Information Encoding,[0],[0]
"Moreover, the traditional discrete features can not effectively record the global behavioral information (Wang et al., 2016).",4.1 Behavioral Information Encoding,[0],[0]
"Besides, there is no explicit charac-
teristic tag available in the review system, and we need to find a way to record the reviewers’ latent characters information in footprints.
",4.1 Behavioral Information Encoding,[0],[0]
"Therefore we encode these behavioral information into our model by utilizing an embedding learning model which is similar with TransE (Bordes et al., 2013).",4.1 Behavioral Information Encoding,[0],[0]
"TransE is a model which can encode the graph structure, and represent the nodes and edges (head, translation/relation, tail) in low dimension vector space.",4.1 Behavioral Information Encoding,[0],[0]
"TransE has been proved that it is good at describing the global information of the graph structure by the work about distributional representation for knowledge base (Guu et al., 2015).",4.1 Behavioral Information Encoding,[0],[0]
We consider that each reviewer in review graph describes the product in his/her own view and writes the review.,4.1 Behavioral Information Encoding,[0],[0]
"When we represent the product, reviewer, and review in low dimension vector space, the reviewer embeddings can be taken as a translation vector, which has translated the product embeddings to the review embeddings.",4.1 Behavioral Information Encoding,[0],[0]
"So, as shown in Figure 2, we take the products (hotels/restaurants) as the head part of the TransE network in our model, take the reviewers as the translation (relation) part and take the review as the tail part.",4.1 Behavioral Information Encoding,[0],[0]
"By learning from the existing large scale unlabeled reviews of the review graph, we can encode the global behavioral information into our model without extracting any traditional behavioral feature, and record reviewers’ latent characteristics information.
",4.1 Behavioral Information Encoding,[0],[0]
"More formally, we minimize a margin-based criterion over the training set:
L = ∑
(β,α,τ )",4.1 Behavioral Information Encoding,[0],[0]
"∈S
∑
(β′,α,τ ′)∈S′ max
{0, 1 + d(β + α, τ )",4.1 Behavioral Information Encoding,[0],[0]
"− d(β′ + α, τ ′)} (1)
S denotes the training set of triples (β, α, τ ) composed product β (β ∈ B, products set (head part)), reviewer α (α ∈ A, reviewers set (translation part)) and review text embeddings learnt by the CNN τ",4.1 Behavioral Information Encoding,[0],[0]
"(τ ∈ T , review texts set (tail part)).
",4.1 Behavioral Information Encoding,[0],[0]
"S′ = {(β′, α, τ )",4.1 Behavioral Information Encoding,[0],[0]
"|β′ ∈ B} ∪ {(β, α, τ ′)|τ ′",4.1 Behavioral Information Encoding,[0],[0]
"∈ T} (2)
",4.1 Behavioral Information Encoding,[0],[0]
"The set of corrupted triplets S′ (Equation (2)), is composed of training triplets with either the product or review text replaced by a random chosen one (but not both at the same time).
",4.1 Behavioral Information Encoding,[0],[0]
"d(β + α, τ )",4.1 Behavioral Information Encoding,[0],[0]
= ∥β + α,4.1 Behavioral Information Encoding,[0],[0]
"− τ∥22 , s.t.",4.1 Behavioral Information Encoding,[0],[0]
"∥β∥22 = ∥α∥22 = ∥τ∥22 = 1
(3)
d(β",4.1 Behavioral Information Encoding,[0],[0]
"+ α, τ ) is the dissimilarity function with the squared euclidean distance.",4.1 Behavioral Information Encoding,[0],[0]
"To encode the textual information into our model, we adopt a convolutional neural network (CNN) to learn to represent the existing reviews.",4.2 Textual Information Encoding,[0],[0]
"By statistics, we find that a review usually refers to several aspects of the products or services.",4.2 Textual Information Encoding,[0],[0]
"For example, a hotel review may comment the room price, the free WiFi, and the bathroom at the same time.",4.2 Textual Information Encoding,[0],[0]
"Compared with the recurrent neural network (RNN), the CNN can do a better job of modeling the different aspects of a review.",4.2 Textual Information Encoding,[0],[0]
"Ren and Zhang (2016) have proved that the CNN can capture complex global semantic information and detect review spam more effectively, compared with traditional discrete manual features and the RNN model.",4.2 Textual Information Encoding,[0],[0]
"As shown in Figure 2, we take the learnt embeddings τ of reviews by the CNN as the tail part.
",4.2 Textual Information Encoding,[0],[0]
"Specifically, we denote the review text consisting of n words as {w1, w2, ..., wn}, the word embeddings e(wi) ∈ RD, D is the word vector dimension.",4.2 Textual Information Encoding,[0],[0]
"We take the concatenation of the word embeddings in a fixed length window size Z as the input of the linear layer, which is denoted as Ii ∈ RD×Z .",4.2 Textual Information Encoding,[0],[0]
"So the output of the linear layer Hi is calculated by Hk,i = Wk · Ii + bi, where Wk ∈ RD×Z is the weight matrix of filter k.",4.2 Textual Information Encoding,[0],[0]
We utilize a max pooling layer to get the output of each filter.,4.2 Textual Information Encoding,[0],[0]
"Then we take tanh as the activation function and concatenate the outputs as the final review embeddings, which is denoted as τi.",4.2 Textual Information Encoding,[0],[0]
"To model the correlation of the textual and behavioral information, we employ the jointly information encoding.",4.3 Jointly Information Encoding,[0],[0]
"By jointly learning from the global review graph, the textual and behavioral information of existing spammers and real reviewers are embedded into the word embeddings.
",4.3 Jointly Information Encoding,[0],[0]
"In addition, the rating usually represents the sentiment polarity of a review, e.g., five star means ‘like’ and one star means ‘dislike’.",4.3 Jointly Information Encoding,[0],[0]
"The spammers often review their target products with a low rating for discredited purpose, and with a high rating for promoted purpose.",4.3 Jointly Information Encoding,[0],[0]
"To encode the semantics of the sentiment polarity into the review embeddings, we learn the embeddings of 1-5 stars rating in our model at the same time.",4.3 Jointly Information Encoding,[0],[0]
They are taken as the constraints of the review embeddings during the joint learning.,4.3 Jointly Information Encoding,[0],[0]
"They are calculated as:
C = ∑
(τ ,γ)∈Γ
∑
(τ ,γ′)∈Γ′ max{0, 1+ g(τ , γ)− g(τ , γ′)} (4)
",4.3 Jointly Information Encoding,[0],[0]
"The set of corrupted tuples Γ′ is composed of training tuples Γ with the rating of review replaced by its opposite rating (i.e., 1 by 5, 2 by 4, 3 by 1 or 5).",4.3 Jointly Information Encoding,[0],[0]
"g(τ , γ) =",4.3 Jointly Information Encoding,[0],[0]
"∥τ − γ∥22, norm constraints: ∥γ∥22 = 1.
",4.3 Jointly Information Encoding,[0],[0]
"The final joint loss function is as follows:
LJ = (1 − θ)L + θC (5)
where θ is a hyper-parameter.",4.3 Jointly Information Encoding,[0],[0]
"Datasets: To evaluate the proposed method, we conducted experiments on Yelp dataset that was used in (Mukherjee et al., 2013b,c; Rayana and Akoglu, 2015).",5.1 Datasets and Evaluation Metrics,[0],[0]
The statistics of the Yelp dataset are listed in Table 2 and Table 3.,5.1 Datasets and Evaluation Metrics,[0],[0]
The reviewed product here refers to a hotel or restaurant.,5.1 Datasets and Evaluation Metrics,[0],[0]
"We take the existing reviews posted before January 1, 2012 as the datasets for training our embedding learning model, and take the first new reviews which just posted by the new reviewers after January 1, 2012 as the test datasets.",5.1 Datasets and Evaluation Metrics,[0],[0]
Table 4 displays the statistics of the balanced datasets for training and testing the classifier.,5.1 Datasets and Evaluation Metrics,[0],[0]
Evaluation Metrics:,5.1 Datasets and Evaluation Metrics,[0],[0]
"We select precision (P), recall (R), F1-Score (F1), accuracy (A) as metrics.",5.1 Datasets and Evaluation Metrics,[0],[0]
"To illustrate the effectiveness of our model, we conduct experiments on the public datasets, and make comparison with the most effective traditional linguistic features, e.g., bigrams, and the three practicable traditional behavioral features (RL, RD, MCS (Mukherjee et al., 2013b)) referred in Section 3.2.",5.2 Our Model v.s. the Traditional Features,[0],[0]
The results are shown in Table 5.,5.2 Our Model v.s. the Traditional Features,[0],[0]
"For our model, we set the dimension of embeddings to 100, the number of CNN filters to 100, θ to 0.1, Z to 2.",5.2 Our Model v.s. the Traditional Features,[0],[0]
The hyper-parameters are tuned by grid search on the development dataset.,5.2 Our Model v.s. the Traditional Features,[0],[0]
"The product and reviewer embeddings are randomly ini-
tialized from a uniform distribution (Socher et al., 2013).",5.2 Our Model v.s. the Traditional Features,[0],[0]
"The word embeddings are initialized with 100-dimensions vectors pre-trained by the CBOW model (Word2Vec) (Mikolov et al., 2013).",5.2 Our Model v.s. the Traditional Features,[0],[0]
"As Table 5 showed, our model observably performs better in detecting review spam for the cold-start task in both hotel and restaurant domains.
",5.2 Our Model v.s. the Traditional Features,[0],[0]
Review Embeddings,5.2 Our Model v.s. the Traditional Features,[0],[0]
"Compared with the traditional linguistic features, e.g., bigrams, using the review embeddings learnt by our model, results in around 3.4% improvement in F1 and around 7.4% improvement in A in the hotel domain (1.1% in F1 and 5.0% in A for the restaurant domain, shown in Tabel 5 (a,b) rows 1, 5).",5.2 Our Model v.s. the Traditional Features,[0],[0]
"Compared with the combination of the bigrams and the traditional behavioral features, using the review embeddings learnt by our model, results in around 7.6% improvement in F1 and around 2.2% improvement in A in the hotel domain (6.1% in F1 and 2.3% in A for the restaurant domain, shown in Tabel 5 (a,b) rows 2, 5).",5.2 Our Model v.s. the Traditional Features,[0],[0]
The F1-Score (F1) of the classification under the balance distribution reflects the ability to detect the review spam.,5.2 Our Model v.s. the Traditional Features,[0],[0]
The accuracy (A) of the classification under the balance distribution reflects the ability to identify both the review spam and the real review.,5.2 Our Model v.s. the Traditional Features,[0],[0]
The experiment results indicate that our model performs significantly better than the traditional methods in F1 and A at the same time.,5.2 Our Model v.s. the Traditional Features,[0],[0]
"The learnt review embeddings with encoded linguistic and behavioral information are more effective in detecting review
spam for the cold-start task.
",5.2 Our Model v.s. the Traditional Features,[0],[0]
"Rating Embeddings As we referred in Section 4.3, the rating of a review usually means the sentiment polarity of a real reviewer or the motivation of a spammer.",5.2 Our Model v.s. the Traditional Features,[0],[0]
"As shown in Table 5 (a,b) rows 6, adding the rating embeddings of the products (hotel/restaurant) and reviews renders even higher F1 and A.",5.2 Our Model v.s. the Traditional Features,[0],[0]
We suppose that different rating embeddings are encoded with different semantic meanings.,5.2 Our Model v.s. the Traditional Features,[0],[0]
They reflect the semantic divergences between the average rating of the product and the review rating.,5.2 Our Model v.s. the Traditional Features,[0],[0]
"In results, using RE+RRE+PRE which makes the best performance of our model, results in around 5.5% improvement in F1 and around 9.4% improvement in A in the hotel domain (2.9% in F1 and 6.2% in A for the restaurant domain, shown in Tabel 5 (a,b) rows 1, 6), compared with the LF.",5.2 Our Model v.s. the Traditional Features,[0],[0]
"Using RE+RRE+PRE results in around 9.7% improvement in F1 and around 4.2% improvement in A in the hotel domain (7.9% in F1 and 3.5% in A for the restaurant domain, shown in Tabel 5 (a,b) rows 2, 6), compared with the LF+BF.
",5.2 Our Model v.s. the Traditional Features,[0],[0]
The experiment results prove that our model is effective.,5.2 Our Model v.s. the Traditional Features,[0],[0]
The improvements in both the F1 and A prove that our model performs well in both detecting the review spam and identifying the real review.,5.2 Our Model v.s. the Traditional Features,[0],[0]
"Furthermore, the improvements in both the hotel and restaurant domains prove that our model possesses preferable domain-adaptability 2.",5.2 Our Model v.s. the Traditional Features,[0],[0]
"It can learn to represent the reviews with global linguistic and behavioral information from largescale unlabeled existing reviews.
2The improvements in hotel domain are greater than that in restaurant domain.",5.2 Our Model v.s. the Traditional Features,[0],[0]
The possible reason is the proportion of the available training data in hotel domain is higher than that in restaurant domain (99.01% vs. 97.40% in Table 2).,5.2 Our Model v.s. the Traditional Features,[0],[0]
"As mentioned in Section 1, to approximate the behavioral information of the new reviewers, there are other intuitive methods.",5.3 Our Jointly Embeddings v.s. the Intuitive Methods,[0],[0]
So we conduct experiments with two intuitive methods as a comparison.,5.3 Our Jointly Embeddings v.s. the Intuitive Methods,[0],[0]
"One is finding the most similar existing review by edit distance ratio and taking the found reviewers’ behavioral features as an approximation, and then training the classifier on the behavioral features and bigrams (BF EditSim+LF).",5.3 Our Jointly Embeddings v.s. the Intuitive Methods,[0],[0]
"The other is finding the most similar existing review by cosine similarity of review embeddings which is the average of the pre-trained word embeddings (using Word2Vec), and then training the classifier on the behavioral features and review embeddings (BF W2Vsim+W2V).",5.3 Our Jointly Embeddings v.s. the Intuitive Methods,[0],[0]
"As shown in Table 5, our joint embeddings (Ours RE and Ours RE+RRE+PRE) obviously perform better than the intuitive methods, such as the Ours RE is 3.8% (Accuracy) and 3.2% (F1) better than BF W2Vsim+W2V in the hotel domain.",5.3 Our Jointly Embeddings v.s. the Intuitive Methods,[0],[0]
The experiments indicate that our joint embeddings do a better job in capturing the reviewer’s characteristics and modeling the correlation of textual and behavioral information.,5.3 Our Jointly Embeddings v.s. the Intuitive Methods,[0],[0]
"Behavioral Information
To further evaluate the effectiveness of encoding the global behavioral information in our model, we build an independent supervised convolutional neural network which has the same structure and parameter settings with the CNN part of our model.",5.4 The Effectiveness of Encoding the Global,[0],[0]
"There is not any review graphic or behavioral information in this independent supervised CNN (Tabel 6 (a,b) row 2).",5.4 The Effectiveness of Encoding the Global,[0],[0]
"As shown in Tabel 6 (a,b) rows 2, 3, compared with the review embeddings learnt by the independent supervised CNN, using
the review embeddings learnt by our model results in around 9.0% improvement in F1 and around 3.8% improvement in A in the hotel domain (7.9% in F1 and 3.7% in A for the restaurant domain).",5.4 The Effectiveness of Encoding the Global,[0],[0]
The results show that our model can represent the new reviews posted by the new reviewers with the correlated behavioral information encoded in the word embeddings.,5.4 The Effectiveness of Encoding the Global,[0],[0]
The transE part of our model has effectively recorded the behavioral information of the review graph.,5.4 The Effectiveness of Encoding the Global,[0],[0]
"Thus, our model is more effective by jointly embedding the textual and behavioral informations, it helps to augment the possible behavioral information of the new reviewer.",5.4 The Effectiveness of Encoding the Global,[0],[0]
"Compared with the the most effective linguistic features, e.g., bigrams, our independent supervised convolutional neural network performs better in A than F1 (shown in Tabel 5 (a,b) rows 1, 2).",5.5 The Effectiveness of CNN,[0],[0]
It indicates that the CNN do a better job in identifying the real review than the review spam.,5.5 The Effectiveness of CNN,[0],[0]
We suppose that the possible reason is that the CNN is good at modeling the different semantic aspects of a review.,5.5 The Effectiveness of CNN,[0],[0]
"And the real reviewers usually tend to describe different aspects of a hotel or restaurant according to their real personal experiences, but the spammers can only forge fake reviews with their own infinite imagination.",5.5 The Effectiveness of CNN,[0],[0]
"Mukherjee et al. (2013b) also proved that different psychological states of the minds of the spammers and non-spammers, lead to significant linguistic differences between review spam and non-spam.",5.5 The Effectiveness of CNN,[0],[0]
This paper analyzes the importance and difficulty of the cold-start challenge in review spam combat.,6 Conclusion and Future Work,[0],[0]
We propose a neural network model that jointly embeds the existing textual and behavioral information for detecting review spam in the coldstart task.,6 Conclusion and Future Work,[0],[0]
It can learn to represent the new review of the new reviewer with the similar textual information and the correlated behavioral information in an unsupervised way.,6 Conclusion and Future Work,[0],[0]
"Then, a classifier is applied to detect the review spam.",6 Conclusion and Future Work,[0],[0]
Experimental results prove the proposed model achieves an effective performance and possesses preferable domain-adaptability.,6 Conclusion and Future Work,[0],[0]
It is also applicable to a large-scale dataset in an unsupervised way.,6 Conclusion and Future Work,[0],[0]
"To our best knowledge, this is the first work to handle the cold-start problem in review spam detection.",6 Conclusion and Future Work,[0],[0]
"We are going to explore more effective models in fu-
ture.",6 Conclusion and Future Work,[0],[0]
This work was supported by the Natural Science Foundation of China (No. 61533018) and the National Basic Research Program of China (No. 2014CB340503).,Acknowledgments,[0],[0]
And this research work was also supported by Google through focused research awards program.,Acknowledgments,[0],[0]
"We would like to thank Prof. Bing Liu for useful advice, and the anonymous reviewers for their detailed comments and suggestions.",Acknowledgments,[0],[0]
Solving the cold-start problem in review spam detection is an urgent and significant task.,abstractText,[0],[0]
"It can help the on-line review websites to relieve the damage of spammers in time, but has never been investigated by previous work.",abstractText,[0],[0]
"This paper proposes a novel neural network model to detect review spam for the cold-start problem, by learning to represent the new reviewers’ review with jointly embedded textual and behavioral information.",abstractText,[0],[0]
Experimental results prove the proposed model achieves an effective performance and possesses preferable domain-adaptability.,abstractText,[0],[0]
It is also applicable to a large-scale dataset in an unsupervised way.,abstractText,[0],[0]
Handling Cold-Start Problem in Review Spam Detection by Jointly Embedding Texts and Behaviors,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1907–1917 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1907",text,[0],[0]
"Recently, there has been a resurgence of work in NLP on reading comprehension (Hermann et al., 2015; Rajpurkar et al., 2016; Joshi et al., 2017) with the goal of developing systems that can answer questions about the content of a given passage or document.",1 Introduction,[0],[0]
Large-scale QA datasets are indispensable for training expressive statistical models for this task and play a critical role in advancing the field.,1 Introduction,[0],[0]
And there have been a number of efforts in this direction.,1 Introduction,[0],[0]
"Miller et al. (2016), for example, develop a dataset for open-domain question answering; Rajpurkar et al. (2016) and Joshi et al. (2017) do so for reading comprehension (RC); and Hill et al. (2015) and Hermann
et al. (2015), for the related task of answering cloze questions (Winograd, 1972; Levesque et al., 2011).",1 Introduction,[0],[0]
"To create these datasets, either crowdsourcing or (semi-)synthetic approaches are used.",1 Introduction,[0],[0]
"The (semi-)synthetic datasets (e.g., Hermann et al. (2015)) are large in size and cheap to obtain; however, they do not share the same characteristics as explicit QA/RC questions (Rajpurkar et al., 2016).",1 Introduction,[0],[0]
"In comparison, high-quality crowdsourced datasets are much smaller in size, and the annotation process is quite expensive because the labeled examples require expertise and careful design (Chen et al., 2016).
",1 Introduction,[0],[0]
"Thus, there is a need for methods that can automatically generate high-quality question-answer pairs.",1 Introduction,[0],[0]
Serban et al. (2016) propose the use of recurrent neural networks to generate QA pairs from structured knowledge resources such as Freebase.,1 Introduction,[0],[0]
"Their work relies on the existence of automatically acquired KBs, which are known to have errors and suffer from incompleteness.",1 Introduction,[0],[0]
They are also nontrivial to obtain.,1 Introduction,[0],[0]
"In addition, the questions in the resulting dataset are limited to queries regarding a single fact (i.e., tuple) in the KB.
",1 Introduction,[0],[0]
"Motivated by the need for large scale QA pairs and the limitations of recent work, we investigate methods that can automatically “harvest” (generate) question-answer pairs from raw text/unstructured documents, such as Wikipediatype articles.
",1 Introduction,[0],[0]
"Recent work along these lines (Du et al., 2017; Zhou et al., 2017) (see Section 2) has proposed the use of attention-based recurrent neural models trained on the crowdsourced SQuAD dataset (Rajpurkar et al., 2016) for question generation.",1 Introduction,[0],[0]
"While successful, the resulting QA pairs are based on information from a single sentence.",1 Introduction,[0],[0]
"As described in Du et al. (2017), however, nearly 30% of the questions in the human-generated questions of SQuAD rely on information beyond a single sentence.",1 Introduction,[0],[0]
"For example, in Figure 1, the second and third questions require coreference information (i.e., recognizing that “His” in sentence 2 and “He” in sentence 3 both corefer with “Tesla” in sentence 1) to answer them.
",1 Introduction,[0],[0]
"Thus, our research studies methods for incorporating coreference information into the training of a question generation system.",1 Introduction,[0],[0]
"In particular, we propose gated Coreference knowledge for Neural Question Generation (CorefNQG), a neural sequence model with a novel gating mechanism that leverages continuous representations of coreference clusters — the set of mentions used to refer to each entity — to better encode linguistic knowledge introduced by coreference, for paragraph-level question generation.
",1 Introduction,[0],[0]
"In an evaluation using the SQuAD dataset, we find that CorefNQG enables better question generation.",1 Introduction,[0],[0]
"It outperforms significantly the baseline neural sequence models that encode information from a single sentence, and a model that encodes all preceding context and the input sentence itself.",1 Introduction,[0],[0]
"When evaluated on only the portion of SQuAD that requires coreference resolution, the gap be-
tween our system and the baseline systems is even larger.
",1 Introduction,[0],[0]
"By applying our approach to the 10,000 topranking Wikipedia articles, we obtain a question answering/reading comprehension dataset with over one million QA pairs; we provide a qualitative analysis in Section 6.",1 Introduction,[0],[0]
The dataset and the source code for the system are available at https://github.com/xinyadu/ HarvestingQA.,1 Introduction,[0],[0]
"Since the work by Rus et al. (2010), question generation (QG) has attracted interest from both the NLP and NLG communities.",2.1 Question Generation,[0],[0]
"Most early work in QG employed rule-based approaches to transform input text into questions, usually requiring the application of a sequence of well-designed general rules or templates (Mitkov and Ha, 2003; Labutov et al., 2015).",2.1 Question Generation,[0],[0]
Heilman and Smith (2010) introduced an overgenerate-and-rank approach: their system generates a set of questions and then ranks them to select the top candidates.,2.1 Question Generation,[0],[0]
"Apart from generating questions from raw text, there has also been research on question generation from symbolic representations (Yao et al., 2012; Olney et al., 2012).
",2.1 Question Generation,[0],[0]
"With the recent development of deep representation learning and large QA datasets, there has been research on recurrent neural network based approaches for question generation.",2.1 Question Generation,[0],[0]
Serban et al. (2016) used the encoder-decoder framework to generate QA pairs from knowledge base triples; Reddy et al. (2017) generated questions from a knowledge graph; Du et al. (2017) studied how to generate questions from sentences using an attention-based sequence-to-sequence model and investigated the effect of exploiting sentencevs.,2.1 Question Generation,[0],[0]
paragraph-level information.,2.1 Question Generation,[0],[0]
Du and Cardie (2017) proposed a hierarchical neural sentencelevel sequence tagging model for identifying question-worthy sentences in a text passage.,2.1 Question Generation,[0],[0]
"Finally, Duan et al. (2017) investigated how to use question generation to help improve question answering systems on the sentence selection subtask.
",2.1 Question Generation,[0],[0]
"In comparison to the related methods from above that generate questions from raw text, our method is different in its ability to take into account contextual information beyond the sentencelevel by introducing coreference knowledge.",2.1 Question Generation,[0],[0]
Recently there has been an increasing interest in question answering with the creation of many datasets.,2.2 Question Answering Datasets and Creation,[0],[0]
"Most are built using crowdsourcing; they are generally comprised of fewer than 100,000 QA pairs and are time-consuming to create.",2.2 Question Answering Datasets and Creation,[0],[0]
"WebQuestions (Berant et al., 2013), for example, contains 5,810 questions crawled via the Google Suggest API and is designed for knowledge base QA with answers restricted to Freebase entities.",2.2 Question Answering Datasets and Creation,[0],[0]
"To tackle the size issues associated with WebQuestions, Bordes et al. (2015) introduce SimpleQuestions, a dataset of 108,442 questions authored by English speakers.",2.2 Question Answering Datasets and Creation,[0],[0]
"SQuAD (Rajpurkar et al., 2016) is a dataset for machine comprehension; it is created by showing a Wikipedia paragraph to human annotators and asking them to write questions based on the paragraph.",2.2 Question Answering Datasets and Creation,[0],[0]
"TriviaQA (Joshi et al., 2017) includes 95k question-answer authored by trivia enthusiasts and corresponding evidence documents.
",2.2 Question Answering Datasets and Creation,[0],[0]
"(Semi-)synthetic generated datasets are easier to build to large-scale (Hill et al., 2015; Hermann et al., 2015).",2.2 Question Answering Datasets and Creation,[0],[0]
They usually come in the form of cloze-style questions.,2.2 Question Answering Datasets and Creation,[0],[0]
"For example, Hermann et al. (2015) created over a million examples by pairing CNN and Daily Mail news articles with their summarized bullet points.",2.2 Question Answering Datasets and Creation,[0],[0]
"Chen et al. (2016) showed that this dataset is quite noisy due to the method of data creation and concluded that performance of QA systems on the dataset is almost saturated.
",2.2 Question Answering Datasets and Creation,[0],[0]
Closest to our work is that of Serban et al. (2016).,2.2 Question Answering Datasets and Creation,[0],[0]
"They train a neural triple-to-sequence model on SimpleQuestions, and apply their system to Freebase to produce a large collection of human-like question-answer pairs.",2.2 Question Answering Datasets and Creation,[0],[0]
Our goal is to harvest high quality questionanswer pairs from the paragraphs of an article of interest.,3 Task Definition,[0],[0]
"In our task formulation, this consists of two steps: candidate answer extraction and answer-specific question generation.",3 Task Definition,[0],[0]
"Given an input paragraph, we first identify a set of question-worthy candidate answers ans = (ans1, ans2, ..., ansl), each a span of text as denoted in color in Figure 1.",3 Task Definition,[0],[0]
"For each candidate answer ansi, we then aim to generate a question Q — a sequence of tokens y1, ..., yN — based on the
sentence S that contains candidate ansi such that:
• Q asks about an aspect of ansi that is of potential interest to a human;
• Q might rely on information from sentences that precede S in the paragraph.
",3 Task Definition,[0],[0]
"Mathematically then,
Q = argmax Q
P (Q|S,C) (1)
where P (Q|S,C) = ∏N
n=1 P (yn|y<n, S, C) where C is the set of sentences that precede S in the paragraph.",3 Task Definition,[0],[0]
"In this section, we introduce our framework for harvesting the question-answer pairs.",4 Methodology,[0],[0]
"As described above, it consists of the question generator CorefNQG (Figure 2) and a candidate answer extraction module.",4 Methodology,[0],[0]
"During test/generation time, we (1) run the answer extraction module on the input text to obtain answers, and then (2) run the question generation module to obtain the corresponding questions.",4 Methodology,[0],[0]
"As shown in Figure 2, our generator prepares the feature-rich input embedding — a concatenation of (a) a refined coreference position feature embedding, (b) an answer feature embedding, and (c) a word embedding, each of which is described below.",4.1 Question Generation,[0],[0]
"It then encodes the textual input using an LSTM unit (Hochreiter and Schmidhuber, 1997).",4.1 Question Generation,[0],[0]
"Finally, an attention-copy equipped decoder is used to decode the question.
",4.1 Question Generation,[0],[0]
"More specifically, given the input sentence S (containing an answer span) and the preceding context C, we first run a coreference resolution system to get the coref-clusters for S and C and use them to create a coreference transformed input sentence: for each pronoun, we append its most representative non-pronominal coreferent mention.",4.1 Question Generation,[0],[0]
"Specifically, we apply the simple feedforward network based mention-ranking model of Clark and Manning (2016) to the concatenation of C and S to get the coref-clusters for all entities in C and S. The C&M model produces a score/representation s for each mention pair (m1,m2),
s(m1,m2) = Wmhm(m1,m2) + bm",4.1 Question Generation,[0],[0]
"(2)
…
Sentence encoder
...
where Wm is a 1 × d weight matrix and b is the bias.",4.1 Question Generation,[0],[0]
"hm(m1,m2) is representation of the last hidden layer of the three layer feedforward neural network.
",4.1 Question Generation,[0],[0]
"For each pronoun in S, we then heuristically identify the most “representative” antecedent from its coref-cluster.",4.1 Question Generation,[0],[0]
(Proper nouns are preferred.),4.1 Question Generation,[0],[0]
We append the new mention after the pronoun.,4.1 Question Generation,[0],[0]
"For example, in Table 1, “the panthers” is the most representative mention in the coref-cluster for “they”.",4.1 Question Generation,[0],[0]
The new sentence with the appended coreferent mention is our coreference transformed input sentence S ′,4.1 Question Generation,[0],[0]
"(see Figure 2).
",4.1 Question Generation,[0],[0]
Coreference Position Feature Embedding For each token in S ′,4.1 Question Generation,[0],[0]
", we also maintain one position feature fc = (c1, ..., cn), to denote pronouns (e.g., “they”) and antecedents (e.g., “the panthers”).",4.1 Question Generation,[0],[0]
We use the BIO tagging scheme to label the associated spans in S ′ .,4.1 Question Generation,[0],[0]
"“B_ANT” denotes the start of an antecedent span, tag “I_ANT” continues the antecedent span and tag “O” marks tokens that do not form part of a mention span.",4.1 Question Generation,[0],[0]
"Similarly, tags “B_PRO” and “I_PRO” denote the pronoun span.",4.1 Question Generation,[0],[0]
"(See Table 1, “coref.",4.1 Question Generation,[0],[0]
"feature”.)
",4.1 Question Generation,[0],[0]
Refined Coref.,4.1 Question Generation,[0],[0]
"Position Feature Embedding Inspired by the success of gating mecha-
nisms for controlling information flow in neural networks (Hochreiter and Schmidhuber, 1997; Dauphin et al., 2017), we propose to use a gating network here to obtain a refined representation of the coreference position feature vectors fc = (c1, ..., cn).",4.1 Question Generation,[0],[0]
The main idea is to utilize the mention-pair score (see Equation 2) to help the neural network learn the importance of the coreferent phrases.,4.1 Question Generation,[0],[0]
We compute the refined (gated) coreference position feature vector fd =,4.1 Question Generation,[0],[0]
"(d1, ..., dn) as follows,
gi = ReLU(Waci +Wbscorei + b)
",4.1 Question Generation,[0],[0]
"di = gi ci (3)
where denotes an element-wise product between two vectors and ReLU is the rectified linear activation function.",4.1 Question Generation,[0],[0]
"scorei denotes the mentionpair score for each antecedent token (e.g., “the” and “panthers”) with the pronoun (e.g., “they”); scorei is obtained from the trained model (Equation 2) of the C&M.",4.1 Question Generation,[0],[0]
"If token i is not added later as an antecedent token, scorei is set to zero.",4.1 Question Generation,[0],[0]
"Wa, Wb are weight matrices and b is the bias vector.
",4.1 Question Generation,[0],[0]
"Answer Feature Embedding We also include an answer position feature embedding to generate answer-specific questions; we denote the answer span with the usual BIO tagging scheme (see,
e.g., “the arizona cardinals” in Table 1).",4.1 Question Generation,[0],[0]
"During training and testing, the answer span feature (i.e., “B_ANS”, “I_ANS” or “O”) is mapped to its feature embedding space: fa = (a1, ..., an).
",4.1 Question Generation,[0],[0]
"Word Embedding To obtain the word embedding for the tokens themselves, we just map the tokens to the word embedding space: x = (x1, ..., xn).
",4.1 Question Generation,[0],[0]
"Final Encoder Input As noted above, the final input to the LSTM-based encoder is a concatenation of (1) the refined coreference position feature embedding (light blue units in Figure 2), (2) the answer position feature embedding (red units), and (3) the word embedding for the token (green units),
ei = concat(di, ai, xi) (4)
Encoder As for the encoder itself, we use bidirectional LSTMs to read the input e = (e1, ..., en) in both the forward and backward directions.",4.1 Question Generation,[0],[0]
"After encoding, we obtain two sequences of hidden vectors, namely, −→ h = ( −→ h1, ..., −→ hn) and ←− h = ( ←− h1, ..., ←− hn).",4.1 Question Generation,[0],[0]
"The final output state of the encoder is the concatenation of −→ h and ←− h where
hi = concat( −→ hi , ←− hi) (5)
",4.1 Question Generation,[0],[0]
"Question Decoder with Attention & Copy On top of the feature-rich encoder, we use LSTMs with attention (Bahdanau et al., 2015) as the decoder for generating the question y1, ..., ym one token at a time.",4.1 Question Generation,[0],[0]
"To deal with rare/unknown words, the decoder also allows directly copying words from the source sentence via pointing (Vinyals et al., 2015).
",4.1 Question Generation,[0],[0]
"At each time step t, the decoder LSTM reads the previous word embedding wt−1 and previous hidden state st−1 to compute the new hidden state,
st = LSTM(wt−1, st−1) (6) Then we calculate the attention distribution αt as in Bahdanau et al. (2015),
et,i = h T",4.1 Question Generation,[0],[0]
i,4.1 Question Generation,[0],[0]
"Wcst−1 αt = softmax(et) (7)
where Wc is a weight matrix and attention distribution αt is a probability distribution over the source sentence words.",4.1 Question Generation,[0],[0]
"With αt, we can obtain the context vector h∗t ,
h∗t = n∑
i=1
αithi (8)
Then, using the context vector h∗t and hidden state st, the probability distribution over the target (question) side vocabulary is calculated as,
Pvocab = softmax(Wdconcat(h∗t , st))",4.1 Question Generation,[0],[0]
"(9)
Instead of directly using Pvocab for training/generating with the fixed target side vocabulary, we also consider copying from the source sentence.",4.1 Question Generation,[0],[0]
"The copy probability is based on the context vector h∗t and hidden state st,
λcopyt = σ",4.1 Question Generation,[0],[0]
"(Weh ∗ t +Wfst) (10)
and the probability distribution over the source sentence words is the sum of the attention scores of the corresponding words,
Pcopy(w) = n∑ i=1 αit ∗ 1{w == wi} (11)
",4.1 Question Generation,[0],[0]
"Finally, we obtain the probability distribution over the dynamic vocabulary (i.e., union of original target side and source sentence vocabulary) by summing over Pcopy and Pvocab,
P (w) = λcopyt Pcopy(w) + (1− λ copy t )Pvocab(w)
(12) where σ is the sigmoid function, and Wd, We,",4.1 Question Generation,[0],[0]
Wf are weight matrices.,4.1 Question Generation,[0],[0]
"We frame the problem of identifying candidate answer spans from a paragraph as a sequence labeling task and base our model on the BiLSTM-CRF approach for named entity recognition (Huang et al., 2015).",4.2 Answer Span Identification,[0],[0]
"Given a paragraph of n tokens, instead of directly feeding the sequence of word vectors x = (x1, ..., xn) to the LSTM units, we first construct the feature-rich embedding x ′ for each token, which is the concatenation of the word embedding, an NER feature embedding, and a character-level representation of the word (Lample et al., 2016).",4.2 Answer Span Identification,[0],[0]
"We use the concatenated vector as the “final” embedding x ′ for the token,
x ′",4.2 Answer Span Identification,[0],[0]
"i = concat(xi,CharRepi,NERi) (13)
where CharRepi is the concatenation of the last hidden states of a character-based biLSTM.",4.2 Answer Span Identification,[0],[0]
"The intuition behind the use of NER features is that SQuAD answer spans contain a large number of named entities, numeric phrases, etc.
",4.2 Answer Span Identification,[0],[0]
"Then a multi-layer Bi-directional LSTM is applied to (x
′ 1, ..., x ′ n) and we obtain the output state
zt for time step t by concatenation of the hidden states (forward and backward) at time step t from the last layer of the BiLSTM.",4.2 Answer Span Identification,[0],[0]
"We apply the softmax to (z1, ..., zn) to get the normalized score representation for each token, which is of size n× k, where k is the number of tags.
",4.2 Answer Span Identification,[0],[0]
"Instead of using a softmax training objective that minimizes the cross-entropy loss for each individual word, the model is trained with a CRF (Lafferty et al., 2001) objective, which minimizes the negative log-likelihood for the entire correct sequence: − log(py),
py = exp(q(x ′ ,y))∑
y′∈Y′",4.2 Answer Span Identification,[0],[0]
"exp(q(x ′ ,y′))
",4.2 Answer Span Identification,[0],[0]
"(14)
where q(x ′ ,y) = ∑n t=1 Pt,yt + ∑n−1 t=0 Ayt,yt+1 , Pt,yt is the score of assigning tag yt to the t th token, and Ayt,yt+1 is the transition score from tag yt to yt+1, the scoring matrix A is to be learned.",4.2 Answer Span Identification,[0],[0]
Y ′ represents all the possible tagging sequences.,4.2 Answer Span Identification,[0],[0]
"We use the SQuAD dataset (Rajpurkar et al., 2016) to train our models.",5.1 Dataset,[0],[0]
It is one of the largest general purpose QA datasets derived from Wikipedia with over 100k questions posed by crowdworkers on a set of Wikipedia articles.,5.1 Dataset,[0],[0]
The answer to each question is a segment of text from the corresponding Wiki passage.,5.1 Dataset,[0],[0]
The crowdworkers were users of Amazon’s Mechanical Turk located in the US or Canada.,5.1 Dataset,[0],[0]
"To obtain high-quality articles, the authors sampled 500 articles from the top 10,000 articles obtained by Nayuki’s Wikipedia’s internal PageRanks.",5.1 Dataset,[0],[0]
"The question-answer pairs were generated by annotators from a paragraph; and although the dataset is typically used to evaluate reading comprehension, it has also been used in an open domain QA setting (Chen et al., 2017; Wang et al., 2018).",5.1 Dataset,[0],[0]
"For training/testing answer extraction systems, we pair each paragraph in the dataset with the gold answer spans that it contains.",5.1 Dataset,[0],[0]
"For the question generation system, we pair each sentence that contains an answer span with the corresponding gold question as in Du et al. (2017).
",5.1 Dataset,[0],[0]
"To quantify the effect of using predicted (rather than gold standard) answer spans on question generation (e.g., predicted answer span boundaries can be inaccurate), we also train the models on an augmented “Training set w/ noisy examples”
(see Table 2).",5.1 Dataset,[0],[0]
"This training set contains all of the original training examples plus new examples for predicted answer spans (from the top-performing answer extraction model, bottom row of Table 3) that overlap with a gold answer span.",5.1 Dataset,[0],[0]
We pair the new training sentence (w/ predicted answer span) with the gold question.,5.1 Dataset,[0],[0]
"The added examples comprise 42.21% of the noisy example training set.
",5.1 Dataset,[0],[0]
"For generation of our one million QA pair corpus, we apply our systems to the 10,000 topranking articles of Wikipedia.",5.1 Dataset,[0],[0]
"For question generation evaluation, we use BLEU (Papineni et al., 2002) and METEOR (Denkowski and Lavie, 2014).1 BLEU measures average n-gram precision vs. a set of reference questions and penalizes for overly short sentences.",5.2 Evaluation Metrics,[0],[0]
"METEOR is a recall-oriented metric that takes into account synonyms, stemming, and paraphrases.
",5.2 Evaluation Metrics,[0],[0]
"For answer candidate extraction evaluation, we use precision, recall and F-measure vs. the gold standard SQuAD answers.",5.2 Evaluation Metrics,[0],[0]
"Since answer boundaries are sometimes ambiguous, we compute Binary Overlap and Proportional Overlap metrics in addition to Exact Match.",5.2 Evaluation Metrics,[0],[0]
"Binary Overlap counts every predicted answer that overlaps with a gold answer span as correct, and Proportional Overlap give partial credit proportional to the amount of overlap (Johansson and Moschitti, 2010; Irsoy and Cardie, 2014).",5.2 Evaluation Metrics,[0],[0]
"For question generation, we compare to the stateof-the-art baselines and conduct ablation tests as follows: Du et al. (2017)’s model is an attention-based RNN sequence-to-sequence neural network (without using the answer location information feature).",5.3 Baselines and Ablation Tests,[0],[0]
"Seq2seq + copyw/ answer is the attention-based sequence-to-sequence model augmented with a copy mechanism, with answer features concatenated with the word embeddings during encoding.",5.3 Baselines and Ablation Tests,[0],[0]
"Seq2seq + copyw/ full context + answer is the same model as the previous one, but we allow access to the full context (i.e., all the preceding sentences and the input sentence itself).",5.3 Baselines and Ablation Tests,[0],[0]
We denote it as ContextNQG henceforth for simplicity.,5.3 Baselines and Ablation Tests,[0],[0]
CorefNQG is the coreference-based model proposed in this paper.,5.3 Baselines and Ablation Tests,[0],[0]
"CorefNQG–gating is an
1We use the evaluation scripts of Du et al. (2017).
ablation test, the gating network is removed and the coreference position embedding is not refined.",5.3 Baselines and Ablation Tests,[0],[0]
"CorefNQG–mention-pair score is also an ablation test where all mention-pair scorei are set to zero.
",5.3 Baselines and Ablation Tests,[0],[0]
"For answer span extraction, we conduct experiments to compare the performance of an off-theshelf NER system and BiLSTM based systems.
",5.3 Baselines and Ablation Tests,[0],[0]
"For training and implementation details, please see the Supplementary Material.",5.3 Baselines and Ablation Tests,[0],[0]
"Table 2 shows the BLEU-{3, 4} and METEOR scores of different models.",6.1 Automatic Evaluation,[0],[0]
Our CorefNQG outperforms the seq2seq baseline of Du et al. (2017) by a large margin.,6.1 Automatic Evaluation,[0],[0]
"This shows that the copy mechanism, answer features and coreference resolution all aid question generation.",6.1 Automatic Evaluation,[0],[0]
"In addition, CorefNQG outperforms both Seq2seq+Copy models significantly, whether or not they have access to the full context.",6.1 Automatic Evaluation,[0],[0]
This demonstrates that the coreference knowledge encoded with the gating network explicitly helps with the training and generation: it is more difficult for the neural sequence model to learn the coreference knowledge in a latent way.,6.1 Automatic Evaluation,[0],[0]
(See input 1 in Figure 3 for an example.),6.1 Automatic Evaluation,[0],[0]
Building end-to-end models that take into account coreference knowledge in a latent way is an interesting direction to explore.,6.1 Automatic Evaluation,[0],[0]
"In the ablation tests, the performance drop of CorefNQG–gating
shows that the gating network is playing an important role for getting refined coreference position feature embedding, which helps the model learn the importance of an antecedent.",6.1 Automatic Evaluation,[0],[0]
"The performance drop of CorefNQG–mention-pair score shows the mention-pair score introduced from the external system (Clark and Manning, 2016) helps the neural network better encode coreference knowledge.
",6.1 Automatic Evaluation,[0],[0]
"To better understand the effect of coreference resolution, we also evaluate our model and the baseline models on just that portion of the test set that requires pronoun resolution (36.42% of the examples) and show the results in Table 4.",6.1 Automatic Evaluation,[0],[0]
The gaps of performance between our model and the baseline models are still significant.,6.1 Automatic Evaluation,[0],[0]
"Besides, we see that all three systems’ performance drop on this partial test set, which demonstrates the hardness of generating questions for the cases that require pronoun resolution (passage context).
",6.1 Automatic Evaluation,[0],[0]
"We also show in Table 2 the results of the QG models trained on the training set augmented with noisy examples with predicted answer spans.
",6.1 Automatic Evaluation,[0],[0]
"There is a consistent but acceptable drop for each model on this new training set, given the inaccuracy of predicted answer spans.",6.1 Automatic Evaluation,[0],[0]
"We see that CorefNQG still outperforms the baseline models across all metrics.
",6.1 Automatic Evaluation,[0],[0]
Figure 3 provides sample output for input sentences that require contextual coreference knowledge.,6.1 Automatic Evaluation,[0],[0]
We see that ContextNQG fails in all cases; our model misses only the third example due to an error introduced by coreference resolution — the “city” and “it” are considered coreferent.,6.1 Automatic Evaluation,[0],[0]
"We can also see that human-generated questions are more natural and varied in form with better paraphrasing.
",6.1 Automatic Evaluation,[0],[0]
"In Table 3, we show the evaluation results for different answer extraction models.",6.1 Automatic Evaluation,[0],[0]
"First we see that all variants of BiLSTM models outperform the off-the-shelf NER system (that proposes all NEs as answer spans), though the NER system has a higher recall.",6.1 Automatic Evaluation,[0],[0]
The BiLSTM-CRF that encodes the character-level and NER features for each token performs best in terms of F-measure.,6.1 Automatic Evaluation,[0],[0]
We hired four native speakers of English to rate the systems’ outputs.,6.2 Human Study,[0],[0]
"Detailed guidelines for the raters are listed in the supplementary materials.
",6.2 Human Study,[0],[0]
The evaluation can also be seen as a measure of the quality of the generated dataset (Section 6.3).,6.2 Human Study,[0],[0]
"We randomly sampled 11 passages/paragraphs from the test set; there are in total around 70 questionanswer pairs for evaluation.
",6.2 Human Study,[0],[0]
"We consider three metrics — “grammaticality”, “making sense” and “answerability”.",6.2 Human Study,[0],[0]
The evaluators are asked to first rate the grammatical correctness of the generated question (before being shown the associated input sentence or any other textual context).,6.2 Human Study,[0],[0]
"Next, we ask them to rate the degree to which the question “makes sense” given the input sentence (i.e., without considering the correctness of the answer span).",6.2 Human Study,[0],[0]
"Finally, evaluators rate the “answerability” of the question given the full context.
",6.2 Human Study,[0],[0]
Table 5 shows the results of the human evaluation.,6.2 Human Study,[0],[0]
Bold indicates top scores.,6.2 Human Study,[0],[0]
"We see that the original human questions are preferred over the two NQG systems’ outputs, which is understandable given the examples in Figure 3.",6.2 Human Study,[0],[0]
"The humangenerated questions make more sense and correspond better with the provided answers, particularly when they require information in the preceding context.",6.2 Human Study,[0],[0]
How exactly to capture the preceding context so as to ask better and more diverse questions is an interesting future direction for research.,6.2 Human Study,[0],[0]
"In terms of grammaticality, however, the neural models do quite well, achieving very close to human performance.",6.2 Human Study,[0],[0]
"In addition, we see that our method (CorefNQG) performs statistically significantly better across all metrics in comparison to the baseline model (ContextNQG), which has access to the entire preceding context in the passage.",6.2 Human Study,[0],[0]
"Our system generates in total 1,259,691 questionanswer pairs, nearly 126 questions per article.",6.3 The Generated Corpus,[0],[0]
"Figure 5 shows the distribution of different types of
questions in our dataset vs. the SQuAD training set.",6.3 The Generated Corpus,[0],[0]
"We see that the distribution for “In what”, “When”, “How long”, “Who”, “Where”, “What does” and “What do” questions in the two datasets is similar.",6.3 The Generated Corpus,[0],[0]
"Our system generates more “What is”, “What was” and “What percentage” questions, while the proportions of “What did”, “Why” and “Which” questions in SQuAD are larger than ours.",6.3 The Generated Corpus,[0],[0]
"One possible reason is that the “Why”, “What did” questions are more complicated to ask (sometimes involving world knowledge) and the answer spans are longer phrases of various types that are harder to identify.",6.3 The Generated Corpus,[0],[0]
"“What is” and “What was” questions, on the other hand, are often safer for the neural networks systems to ask.
",6.3 The Generated Corpus,[0],[0]
"In Figure 4, we show some examples of the generated question-answer pairs.",6.3 The Generated Corpus,[0],[0]
The answer extractor identifies the answer span boundary well and all three questions correspond to their answers.,6.3 The Generated Corpus,[0],[0]
Q2 is valid but not entirely accurate.,6.3 The Generated Corpus,[0],[0]
"For more examples, please refer to our supplementary materials.
",6.3 The Generated Corpus,[0],[0]
"Table 6 shows the performance of a topperforming system for the SQuAD dataset (Document Reader (Chen et al., 2017)) when applied to the development and test set portions of our generated dataset.",6.3 The Generated Corpus,[0],[0]
The system was trained on the training set portion of our dataset.,6.3 The Generated Corpus,[0],[0]
"We use the SQuAD evaluation scripts, which calculate exact match (EM) and F-1 scores.2 Performance of the
2F-1 measures the average overlap between the predicted answer span and ground truth answer (Rajpurkar et al., 2016).
",6.3 The Generated Corpus,[0],[0]
neural machine reading model is reasonable.,6.3 The Generated Corpus,[0],[0]
"We also train the DocReader on our training set and test the models’ performance on the original dev set of SQuAD; for this, the performance is around 45.2% on EM and 56.7% on F-1 metric.",6.3 The Generated Corpus,[0],[0]
"DocReader trained on the original SQuAD training set achieves 69.5% EM, 78.8% F-1 indicating that our dataset is more difficult and/or less natural than the crowd-sourced QA pairs of SQuAD.",6.3 The Generated Corpus,[0],[0]
We propose a new neural network model for better encoding coreference knowledge for paragraphlevel question generation.,7 Conclusion,[0],[0]
Evaluations with different metrics on the SQuAD machine reading dataset show that our model outperforms state-ofthe-art baselines.,7 Conclusion,[0],[0]
The ablation study shows the effectiveness of different components in our model.,7 Conclusion,[0],[0]
"Finally, we apply our question generation framework to produce a corpus of 1.26 million questionanswer pairs, which we hope will benefit the QA research community.",7 Conclusion,[0],[0]
It would also be interesting to apply our approach to incorporating coreference knowledge to other text generation tasks.,7 Conclusion,[0],[0]
We thank the anonymous reviewers and members of Cornell NLP group for helpful comments.,Acknowledgments,[0],[0]
We study the task of generating from Wikipedia articles question-answer pairs that cover content beyond a single sentence.,abstractText,[0],[0]
We propose a neural network approach that incorporates coreference knowledge via a novel gating mechanism.,abstractText,[0],[0]
"Compared to models that only take into account sentence-level information (Heilman and Smith, 2010; Du et al., 2017; Zhou et al., 2017), we find that the linguistic knowledge introduced by the coreference representation aids question generation significantly, producing models that outperform the current state-of-theart.",abstractText,[0],[0]
"We apply our system (composed of an answer span extraction system and the passage-level QG system) to the 10,000 top-ranking Wikipedia articles and create a corpus of over one million questionanswer pairs.",abstractText,[0],[0]
We also provide a qualitative analysis for this large-scale generated corpus from Wikipedia.,abstractText,[0],[0]
Harvesting Paragraph-Level Question-Answer Pairs from Wikipedia,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4791–4796 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4791",text,[0],[0]
"Neural machine translation (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2015) has become the de-facto standard in machine translation, outperforming earlier phrasebased approaches in many data settings and shared translation tasks (Luong and Manning, 2015; Sennrich et al., 2016; Cromieres et al., 2016).",1 Introduction,[0],[0]
"Some recent results suggest that neural machine translation “approaches the accuracy achieved by average bilingual human translators [on some test sets]” (Wu et al., 2016), or even that its “translation quality is at human parity when compared to professional human translators” (Hassan et al., 2018).",1 Introduction,[1.0],"['Some recent results suggest that neural machine translation “approaches the accuracy achieved by average bilingual human translators [on some test sets]” (Wu et al., 2016), or even that its “translation quality is at human parity when compared to professional human translators” (Hassan et al., 2018).']"
"Claims of human parity in machine translation are certainly extraordinary, and require extraordinary evidence.1",1 Introduction,[0],[0]
"Laudably, Hassan et al. (2018) have
1The term “parity” may raise the expectation that there is evidence for equivalence, but the term is used in the definition of “there [being] no statistical significance between [two outputs] for a test set of candidate translations” by Hassan et al. (2018).",1 Introduction,[0],[0]
"Still, we consider this finding noteworthy given the strong evaluation setup.
released their data publicly to allow external validation of their claims.",1 Introduction,[0],[0]
"Their claims are further strengthened by the fact that they follow best practices in human machine translation evaluation, using evaluation protocols and tools that are also used at the yearly Conference on Machine Translation (WMT) (Bojar et al., 2017), and take great care in guarding against some confounds such as test set selection and rater inconsistency.
",1 Introduction,[1.0000000036156385],"['Their claims are further strengthened by the fact that they follow best practices in human machine translation evaluation, using evaluation protocols and tools that are also used at the yearly Conference on Machine Translation (WMT) (Bojar et al., 2017), and take great care in guarding against some confounds such as test set selection and rater inconsistency.']"
"However, the implications of a statistical tie between two machine translation systems in a shared translation task are less severe than that of a statistical tie between a machine translation system and a professional human translator, so we consider the results worthy of further scrutiny.",1 Introduction,[0],[0]
We perform an independent evaluation of the professional translation and best machine translation system that were found to be of equal quality by Hassan et al. (2018).,1 Introduction,[1.0],['We perform an independent evaluation of the professional translation and best machine translation system that were found to be of equal quality by Hassan et al. (2018).']
"Our main interest lies in the evaluation protocol, and we empirically investigate if the lack of document-level context could explain the inability of human raters to find a quality difference between human and machine translations.",1 Introduction,[1.0],"['Our main interest lies in the evaluation protocol, and we empirically investigate if the lack of document-level context could explain the inability of human raters to find a quality difference between human and machine translations.']"
"We test the following hypothesis:
A professional translator who is asked to rank the quality of two candidate translations on the document level will prefer a professional human translation over a machine translation.
",1 Introduction,[0],[0]
"Note that our hypothesis is slightly different from that tested by Hassan et al. (2018), which could be phrased as follows:
A bilingual crowd worker who is asked to directly assess the quality of candidate translations on the sentence level will prefer a professional human translation over a machine translation.
",1 Introduction,[0],[0]
"As such, our evaluation is not a direct replication of that by Hassan et al. (2018), and a failure to reproduce their findings does not imply an error on either our or their part.",1 Introduction,[1.0],"['As such, our evaluation is not a direct replication of that by Hassan et al. (2018), and a failure to reproduce their findings does not imply an error on either our or their part.']"
"Rather, we hope to indirectly assess the accuracy of different evaluation protocols.",1 Introduction,[0],[0]
"Our underlying assumption is that professional human translation is still superior to neural machine translation, but that the sensitivity of human raters to these quality differences depends on the evaluation protocol.",1 Introduction,[0],[0]
"Machine translation is typically evaluated by comparing system outputs to source texts, reference translations, other system outputs, or a combination thereof (for examples, see Bojar et al., 2016a).",2 Human Evaluation of Machine Translation,[1.0],"['Machine translation is typically evaluated by comparing system outputs to source texts, reference translations, other system outputs, or a combination thereof (for examples, see Bojar et al., 2016a).']"
"The scientific community concentrates on two aspects: adequacy, typically assessed by bilinguals; and target language fluency, typically assessed by monolinguals.",2 Human Evaluation of Machine Translation,[1.0],"['The scientific community concentrates on two aspects: adequacy, typically assessed by bilinguals; and target language fluency, typically assessed by monolinguals.']"
"Evaluation protocols have been subject to controversy for decades (e. g., Van Slype, 1979), and we identify three aspects with particular relevance to assessing human parity: granularity of measurement (ordinal vs. interval scales), raters (experts vs. crowd workers), and experimental unit (sentence vs. document).",2 Human Evaluation of Machine Translation,[0],[0]
Granularity of Measurement Callison-Burch et al. (2007) show that ranking (Which of these translations is better?) leads to better inter-rater agreement than absolute judgement on 5-point Likert scales (How good is this translation?) but gives no insight about how much a candidate translation differs from a (presumably perfect) reference.,2.1 Related Work,[0],[0]
"To this end, Graham et al. (2013) suggest the use of continuous scales for direct assessment of translation quality.",2.1 Related Work,[0],[0]
"Implemented as a slider between 0 (Not at all) and 100 (Perfectly), their method yields scores on a 100-point interval scale in practice (Bojar et al., 2016b, 2017), with each raters’ rating being standardised to increase homogeneity.",2.1 Related Work,[0],[0]
Hassan et al. (2018) use source-based direct assessment to avoid bias towards reference translations.,2.1 Related Work,[0],[0]
"In the shared task evaluation by Cettolo et al. (2017), raters are shown the source and a candidate text, and asked: How accurately does the above candidate text convey the semantics of the source text?",2.1 Related Work,[0],[0]
"In doing so, they have translations produced by humans and machines rated indepen-
dently, and parity is assumed if the mean score of the former does not significantly differ from the mean score of the latter.
",2.1 Related Work,[0],[0]
"Raters To optimise cost, machine translation quality is typically assessed by means of crowdsourcing.",2.1 Related Work,[0],[0]
"Combined ratings of bilingual crowd workers have been shown to be more reliable than automatic metrics and “very similar” to ratings produced by “experts”2 (Callison-Burch, 2009).",2.1 Related Work,[0],[0]
"Graham et al. (2017) compare crowdsourced to “expert” ratings on machine translations from WMT 2012, concluding that, with proper quality control, “machine translation systems can indeed be evaluated by the crowd alone.”",2.1 Related Work,[0],[0]
"However, it is unclear whether this finding carries over to translations produced by NMT systems where, due to increased fluency, errors are more difficult to identify (Castilho et al., 2017a), and concurrent work by Toral et al. (2018) highlights the importance of expert translators for MT evaluation.
",2.1 Related Work,[0],[0]
"Experimental Unit Machine translation evaluation is predominantly performed on single sentences, presented to raters in random order (e. g., Bojar et al., 2017; Cettolo et al., 2017).",2.1 Related Work,[0],[0]
There are two main reasons for this.,2.1 Related Work,[0],[0]
"The first is cost: if raters assess entire documents, obtaining the same number of data points in an evaluation campaign multiplies the cost by the average number of sentences per document.",2.1 Related Work,[0],[0]
The second is experimental validity.,2.1 Related Work,[0],[0]
"When comparing systems that produce sentences without considering documentlevel context, the perceived suprasentential cohesion of a system output is likely due to randomness and thus a confounding factor.",2.1 Related Work,[0],[0]
"While incorporating document-level context into machine translation systems is an active field of research (Webber et al., 2017), state-of-the-art systems still operate at the level of single sentences (Sennrich et al., 2017; Vaswani et al., 2017; Hassan et al., 2018).",2.1 Related Work,[0],[0]
"In contrast, human translators can and do take document-level context into account (Krings, 1986).",2.1 Related Work,[0],[0]
The same holds for raters in evaluation campaigns.,2.1 Related Work,[0],[0]
"In the discussion of their results, Wu et al. (2016) note that their raters “[did] not necessarily fully understand each randomly sampled sentence sufficiently” because it was provided with no context.",2.1 Related Work,[0],[0]
"In such setups, raters cannot reward textual cohesion and coherence.
2“Experts” here are computational linguists who develop MT systems, who may not be expert translators.",2.1 Related Work,[0],[0]
"We conduct a quality evaluation experiment with a 2× 2 mixed factorial design, testing the effect of source text availability (adequacy, fluency) and experimental unit (sentence, document) on ratings by professional translators.
",2.2 Our Evaluation Protocol,[0],[0]
Granularity of Measurement We elicit judgements by means of pairwise ranking.,2.2 Our Evaluation Protocol,[1.0],['Granularity of Measurement We elicit judgements by means of pairwise ranking.']
"Raters choose the better (with ties allowed) of two translations for each item: one produced by a professional translator (HUMAN), the other by machine translation (MT).",2.2 Our Evaluation Protocol,[1.0],"['Raters choose the better (with ties allowed) of two translations for each item: one produced by a professional translator (HUMAN), the other by machine translation (MT).']"
"Since our evaluation includes that of human translation, it is reference-free.",2.2 Our Evaluation Protocol,[0],[0]
"We evaluate in two conditions: adequacy, where raters see source texts and translations (Which translation expresses the meaning of the source text more adequately?); and fluency, where raters only see translations (Which text is better English?).
",2.2 Our Evaluation Protocol,[0],[0]
"Raters We recruit professional translators, only considering individuals with at least three years of professional experience and positive client reviews.
",2.2 Our Evaluation Protocol,[0],[0]
"Experimental Unit To test the effect of context on perceived translation quality, raters evaluate entire documents as well as single sentences in random order (i. e., context is a within-subjects factor).",2.2 Our Evaluation Protocol,[1.0],"['Experimental Unit To test the effect of context on perceived translation quality, raters evaluate entire documents as well as single sentences in random order (i. e., context is a within-subjects factor).']"
"They are shown both translations (HUMAN and MT) for each unit; the source text is only shown in the adequacy condition.
",2.2 Our Evaluation Protocol,[0.999999982762075],['They are shown both translations (HUMAN and MT) for each unit; the source text is only shown in the adequacy condition.']
"Quality Control To hedge against random ratings, we convert 5 documents and 16 sentences per set into spam items (Kittur et al., 2008): we render one of the two options nonsensical by shuffling its words randomly, except for 10 % at the beginning and end.
",2.2 Our Evaluation Protocol,[0],[0]
Statistical Analysis We test for statistically significant preference of HUMAN over MT or vice versa by means of two-sided Sign Tests.,2.2 Our Evaluation Protocol,[0],[0]
"Let a be the number of ratings in favour of MT, b the number of ratings in favour of HUMAN, and t the number of ties.",2.2 Our Evaluation Protocol,[0],[0]
"We report the number of successes x and the number of trials n for each test, such that x = b and n = a+ b.3
3Emerson and Simon (1979) suggest the inclusion of ties such that x = b+0.5t and n = a+ b+ t. This modification has no effect on the significance levels reported in this paper.",2.2 Our Evaluation Protocol,[0],[0]
We use the experimental protocol described in the previous section for a quality assessment of Chinese to English translations of news articles.,2.3 Data Collection,[0],[0]
"To this end, we randomly sampled 55 documents and 2×120 sentences from the WMT 2017 test set.",2.3 Data Collection,[1.0],"['To this end, we randomly sampled 55 documents and 2×120 sentences from the WMT 2017 test set.']"
"We only considered the 123 articles (documents) which are native Chinese,4 containing 8.13 sentences on average.",2.3 Data Collection,[0],[0]
"Human and machine translations (REFERENCE-HT as HUMAN, and COMBO6 as MT) were obtained from data released by Hassan et al. (2018).5
The sampled documents and sentences were rated by professional translators we recruited from ProZ:6 4 native in Chinese (2), English (1), or both (1) to rate adequacy, and 4 native in English to rate fluency.",2.3 Data Collection,[0],[0]
"On average, translators had 13.7 years of experience and 8.8 positive client reviews on ProZ, and received US$ 188.75 for rating 55 documents and 120 sentences.
",2.3 Data Collection,[0],[0]
"The averages reported above include an additional translator we recruited when one rater showed poor performance on document-level spam items in the fluency condition, whose judgements we exclude from analysis.",2.3 Data Collection,[0],[0]
"We also exclude sentence-level results from 4 raters because there was overlap with the documents they annotated, which means that we cannot rule out that the sentence-level decisions were informed by access to the full document.",2.3 Data Collection,[0],[0]
"To allow for external validation and further experimentation, we make all experimental data publicly available.7",2.3 Data Collection,[0],[0]
"In the adequacy condition, MT and HUMAN are not statistically significantly different on the sentence level (x=86, n=189, p= .244).",3 Results,[0],[0]
This is consistent with the results Hassan et al. (2018) obtained with an alternative evaluation protocol (crowdsourcing and direct assessment; see Section 2.1).,3 Results,[0],[0]
"However, when evaluating entire doc-
4While it is common practice in machine translation to use the same test set in both translation directions, we consider a direct comparison between human “translation” and machine translation hard to interpret if one is in fact the original English text, and the other an automatic translation into English of a human translation into Chinese.",3 Results,[0],[0]
"In concurrent work, Toral et al. (2018) expand on the confounding effect of evaluating text where the target side is actually the original document.
5 http://aka.ms/Translator-HumanParityData 6 https://www.proz.com 7 https://github.com/laeubli/parity
uments, raters show a statistically significant preference for HUMAN (x=104, n=178, p<.05).",3 Results,[0],[0]
"While the number of ties is similar in sentenceand document-level evaluation, preference for MT drops from 50 to 37 % in the latter (Figure 1a).
",3 Results,[0.9999999544653032],"['While the number of ties is similar in sentenceand document-level evaluation, preference for MT drops from 50 to 37 % in the latter (Figure 1a).']"
"In the fluency condition, raters prefer HUMAN on both the sentence (x= 106, n=172, p<.01) and document level (x=99, n=143, p< .001).",3 Results,[1.0],"['In the fluency condition, raters prefer HUMAN on both the sentence (x= 106, n=172, p<.01) and document level (x=99, n=143, p< .001).']"
"In contrast to adequacy, fluency ratings in favour of HUMAN are similar in sentence- and document-level evaluation, but raters find more ties with document-level context as preference for MT drops from 32 to 22 % (Figure 1b).
",3 Results,[0],[0]
We note that these large effect sizes lead to statistical significance despite modest sample size.,3 Results,[0],[0]
Inter-annotator agreement (Cohen’s κ) ranges from 0.13 to 0.32 (see Appendix for full results and discussion).,3 Results,[0],[0]
Our results emphasise the need for suprasentential context in human evaluation of machine translation.,4 Discussion,[1.0],['Our results emphasise the need for suprasentential context in human evaluation of machine translation.']
"Starting with Hassan et al.’s (2018) finding of no statistically significant difference in translation quality between HUMAN and MT for their Chinese–English test set, we set out to test this result with an alternative evaluation protocol which we expected to strengthen the ability of raters to judge translation quality.",4 Discussion,[0],[0]
"We employed professional translators instead of crowd workers, and pairwise ranking instead of direct assessment, but in a sentence-level evaluation of adequacy, raters still found it hard to discriminate between HUMAN and MT: they did not show a statistically significant preference for either of them.
",4 Discussion,[0],[0]
"Conversely, we observe a tendency to rate HUMAN more favourably on the document level than on the sentence level, even within single raters.",4 Discussion,[0],[0]
Adequacy raters show a statistically significant preference for HUMAN when evaluating entire documents.,4 Discussion,[0],[0]
"We hypothesise that document-level evaluation unveils errors such as mistranslation of an ambiguous word, or errors related to textual cohesion and coherence, which remain hard or impossible to spot in a sentence-level evaluation.",4 Discussion,[1.0],"['We hypothesise that document-level evaluation unveils errors such as mistranslation of an ambiguous word, or errors related to textual cohesion and coherence, which remain hard or impossible to spot in a sentence-level evaluation.']"
"For a subset of articles, we elicited both sentence-level and document-level judgements, and inspected articles for which sentence-level judgements were mixed, but where HUMAN was strongly preferred in document-level evaluation.",4 Discussion,[0],[0]
"In these articles, we do indeed observe the hypothesised phenomena.",4 Discussion,[0],[0]
"We find an example of lexical coherence in a 6-sentence article about a new app “微信挪 车”, which HUMAN consistently translates into “WeChat Move the Car”.",4 Discussion,[0],[0]
"In MT, we find three different translations in the same article: “Twitter Move Car”, “WeChat mobile”, and “WeChat Move”.",4 Discussion,[1.0],"['In MT, we find three different translations in the same article: “Twitter Move Car”, “WeChat mobile”, and “WeChat Move”.']"
"Other observations include the use of more appropriate discourse connectives in HUMAN, a more detailed investigation of which we leave to future work.
",4 Discussion,[0],[0]
"To our surprise, fluency raters show a stronger preference for HUMAN than adequacy raters (Figure 1).",4 Discussion,[1.0],"['To our surprise, fluency raters show a stronger preference for HUMAN than adequacy raters (Figure 1).']"
"The main strength of neural machine translation in comparison to previous statistical approaches was found to be increased fluency, while adequacy improvements were less clear (Bojar et al., 2016b; Castilho et al., 2017b), and we expected a similar pattern in our evaluation.",4 Discussion,[1.0],"['The main strength of neural machine translation in comparison to previous statistical approaches was found to be increased fluency, while adequacy improvements were less clear (Bojar et al., 2016b; Castilho et al., 2017b), and we expected a similar pattern in our evaluation.']"
"Does this indicate that adequacy is in fact a strength of
MT, not fluency?",4 Discussion,[0],[0]
We are wary to jump to this conclusion.,4 Discussion,[0],[0]
"An alternative interpretation is that MT, which tends to be more literal than HUMAN, is judged more favourably by raters in the bilingual condition, where the majority of raters are native speakers of the source language, because of L1 interference.",4 Discussion,[0],[0]
We note that the availability of document-level context still has a strong impact in the fluency condition (Section 3).,4 Discussion,[0],[0]
"In response to recent claims of parity between human and machine translation, we have empirically tested the impact of sentence and document level context on human assessment of machine translation.",5 Conclusions,[1.0],"['In response to recent claims of parity between human and machine translation, we have empirically tested the impact of sentence and document level context on human assessment of machine translation.']"
"Raters showed a markedly stronger preference for human translations when evaluating at the level of documents, as compared to an evaluation of single, isolated sentences.
",5 Conclusions,[0],[0]
We believe that our findings have several implications for machine translation research.,5 Conclusions,[1.0],['We believe that our findings have several implications for machine translation research.']
"Most importantly, if we accept our interpretation that human translation is indeed of higher quality in the dataset we tested, this points to a failure of current best practices in machine translation evaluation.",5 Conclusions,[1.0],"['Most importantly, if we accept our interpretation that human translation is indeed of higher quality in the dataset we tested, this points to a failure of current best practices in machine translation evaluation.']"
"As machine translation quality improves, translations will become harder to discriminate in terms of quality, and it may be time to shift towards document-level evaluation, which gives raters more context to understand the original text and its translation, and also exposes translation errors related to discourse phenomena which remain invisible in a sentence-level evaluation.
",5 Conclusions,[1.0000000347802016],"['As machine translation quality improves, translations will become harder to discriminate in terms of quality, and it may be time to shift towards document-level evaluation, which gives raters more context to understand the original text and its translation, and also exposes translation errors related to discourse phenomena which remain invisible in a sentence-level evaluation.']"
"Our evaluation protocol was designed with the aim of providing maximal validity, which is why we chose to use professional translators and pairwise ranking.",5 Conclusions,[1.0],"['Our evaluation protocol was designed with the aim of providing maximal validity, which is why we chose to use professional translators and pairwise ranking.']"
"For future work, it would be of high practical relevance to test whether we can also elicit accurate quality judgements on the document-level via crowdsourcing and direct assessment, or via alternative evaluation protocols.",5 Conclusions,[1.0],"['For future work, it would be of high practical relevance to test whether we can also elicit accurate quality judgements on the document-level via crowdsourcing and direct assessment, or via alternative evaluation protocols.']"
"The data released by Hassan et al. (2018) could serve as a test bed to this end.
",5 Conclusions,[1.0000000212950586],['The data released by Hassan et al. (2018) could serve as a test bed to this end.']
"One reason why document-level evaluation widens the quality gap between machine translation and human translation is that the machine translation system we tested still operates on the sentence level, ignoring wider context.",5 Conclusions,[1.0],"['One reason why document-level evaluation widens the quality gap between machine translation and human translation is that the machine translation system we tested still operates on the sentence level, ignoring wider context.']"
It will be interesting to explore to what extent existing and future techniques for document-level machine translation can narrow this gap.,5 Conclusions,[1.0],['It will be interesting to explore to what extent existing and future techniques for document-level machine translation can narrow this gap.']
"We ex-
pect that this will require further efforts in creating document-level training data, designing appropriate models, and supporting research with discourse-aware automatic metrics.",5 Conclusions,[0.9999999661261332],"['We ex- pect that this will require further efforts in creating document-level training data, designing appropriate models, and supporting research with discourse-aware automatic metrics.']"
We thank Xin Sennrich for her help with the analysis of translation errors.,Acknowledgements,[0],[0]
We also thank Antonio Toral and the anonymous reviewers for their helpful comments.,Acknowledgements,[0],[0]
Recent research suggests that neural machine translation achieves parity with professional human translation on the WMT Chinese– English news translation task.,abstractText,[0],[0]
"We empirically test this claim with alternative evaluation protocols, contrasting the evaluation of single sentences and entire documents.",abstractText,[0],[0]
"In a pairwise ranking experiment, human raters assessing adequacy and fluency show a stronger preference for human over machine translation when evaluating documents as compared to isolated sentences.",abstractText,[0],[0]
Our findings emphasise the need to shift towards document-level evaluation as machine translation improves to the degree that errors which are hard or impossible to spot at the sentence-level become decisive in discriminating quality of different translation outputs.,abstractText,[0],[0]
Has Machine Translation Achieved Human Parity? A Case for Document-level Evaluation,title,[0],[0]

0	21	User comments play a central role in social media and online discussion fora.
1	36	News portals and blogs often also allow their readers to comment to get feedback, engage their readers, and build customer loyalty.1 User comments, however, and more generally user content can also be abusive (e.g., bullying, profanity, hate speech) (Cheng et al., 2015).
8	32	They often employ moderators, who are frequently overwhelmed, however, by the volume and abusiveness of comments.3 Readers are disappointed when non-abusive comments do not appear quickly online because of moderation delays.
16	78	In a fully automatic scenario, there is no moderator and a system accepts or rejects comments.
17	48	Although this scenario may be the only available one, e.g., when news portals cannot afford moderators, it is unrealistic to expect that fully automatic moderation will be perfect, because abusive comments may involve irony, sarcasm, harassment without profane phrases etc., which are particularly difficult for a machine to detect.
81	26	Once hk has been computed, the LR layer estimates the probability that comment c should be rejected, with Wp ∈ R1×m, bp ∈ R: PRNN(reject|c) = σ(Wphk + bp) a-RNN: When the attention mechanism is added, the LR layer considers the weighted sum hsum of all the hidden states, instead of just hk (Fig.
92	37	We consider shorter texts (comments), we have a single RNN, and we assign attention scores to words only.12 da-CENT: We also experiment with a variant of a-RNN, called da-CENT, which does not use the hidden states of the RNN.
94	27	2), and hsum is now the weighted sum (centroid) of word embeddings hsum = ∑k t=1 atxt (cf.
95	24	13 We set l = 4, d = 300, r = m = 128, having tuned all hyper-parameters on the same 2% held-out comments of W-ATT-TRAIN or G-TRAINS that were used to tune DETOX.
115	49	A baseline, called LIST, collects every word w that occurs in more than 10 (for W-ATT-TRAIN, G-TRAIN-S) or 100 comments (for G-TRAIN-L) in the training set, along with the precision of w, i.e., the ratio of rejected training comments containing w divided by the total number of training comments containing w. The resulting lists contain 10,423, 16,864, and 21,940 word types, when using W-ATT-TRAIN, G-TRAIN-S, G-TRAIN-L, respectively.
119	21	In our experience, moderators (or their employers) can easily specify the approximate percentage of comments they can afford to check manually (e.g., 20% daily) or, equivalently, the approximate percentage of comments the system should handle automatically.
120	22	We call coverage the latter percentage; hence, 1 − coverage is the approximate percentage of comments to be checked manually.
124	50	For each ta value, we set tr to the value that leaves a 1 − coverage percentage of development comments in the gray zone (ta ≤ p ≤ tr).
125	32	We then select the ta (and tr) that maximizes the weighted harmonic mean Fβ(Preject, Paccept) on the development set: Fβ(Preject, Paccept) = (1 + β2) · Preject · Paccept β2 · Preject + Paccept where Preject is the rejection precision (correctly rejected comments divided by rejected comments) and Paccept is the acceptance precision (correctly accepted divided by accepted).
126	39	Intuitively, coverage sets the width of the gray zone, whereas Preject and Paccept show how certain we can be that the red (reject) and green (accept) zones are free of misclassified comments.
127	80	We set β = 2, emphasizing Paccept, because moderators are more worried about wrongly accepting abusive comments than wrongly rejecting non-abusive ones.17 The selected ta, tr (tuned on development data) are then used in experiments on test data.
129	24	Following Wulczyn et al. (2017), we report in Table 2 AUC scores (area under ROC curve), along with Spearman correlations between systemgenerated probabilities P (accept|c) and human probabilistic gold labels (Section 2.2) when probabilistic gold labels are available.18 Wulczyn et al. reported DETOX results only on W-ATT-DEV, shown in brackets.
131	35	Furthermore, a-RNN is always better than RNN on Gazzetta comments, but not on Wikipedia comments, where RNN is overall slightly better according to Table 2.
132	23	Also, da-CENT is always worse than a-RNN and RNN, confirming that the hidden states (intuitively, context-aware word embeddings) of the RNN chain are important, even with the attention mechanism.
138	30	Again, a-RNN and RNN are better than CNN and DETOX.
139	50	All three deep learning methods benefit from the larger training set (dotted).
142	33	When tuned for 100% coverage, comments for which the system is uncertain (gray zone) cannot be avoided and there are inevitably more misclassifications; the use of F2 during threshold tuning places more emphasis on avoiding wrongly accepted comments, leading to high Paccept (0.82), at the expense of wrongly rejected comments, i.e., sacrificing Preject (0.59).
144	52	We also repeated the annotator ensemble experiment of Wulczyn et al. (2017) on 8K randomly chosen comments of W-ATT-TEST (4K comments from random users, 4K comments from banned users).19 The decisions of 10 randomly chosen annotators (possibly different per comment) were used to construct the gold label of each comment.
148	94	To investigate if the attention scores of a-RNN can highlight suspicious words, we focused on GTEST-S-R, the only dataset with suspicious snippets annotated by humans.
158	24	Figure 7 shows the correlations on comments that were accepted (left) and rejected (right) by the majority of moderators.
161	32	By contrast, LIST performs reasonably well in terms of Spearman correlation, but much worse in terms of Pearson, indicating that its precision scores rank reasonably well the tokens from most to least suspicious ones, but are not linearly related to the gold scores.
191	94	We experimented with a new publicly available dataset of 1.6M moderated user comments from a Greek sports news portal and an existing dataset of 115K English Wikipedia talk page comments.
192	86	We showed that a GRU RNN operating on word embeddings outpeforms the previous state of the art, which used an LR or MLP classifier with character or word n-gram features, also outperforming a vanilla CNN operating on word embeddings, and a baseline that uses an automatically constructed word list with precision scores.
193	34	A novel, deep, classification-specific attention mechanism improves further the overall results of the RNN, and can also highlight suspicious words for free, without including highlighted words in the training data.
194	24	We considered both fully automatic and semi-automatic moderation, along with threshold tuning and evaluation measures for both.

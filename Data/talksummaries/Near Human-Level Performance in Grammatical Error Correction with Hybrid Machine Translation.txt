0	11	Currently, the most effective GEC systems are based on phrase-based statistical machine translation (Rozovskaya and Roth, 2016; JunczysDowmunt and Grundkiewicz, 2016; Chollampatt and Ng, 2017).
1	3	Systems that rely on neural machine translation (Yuan and Briscoe, 2016; Xie et al., 2016; Schmaltz et al., 2017; Ji et al., 2017) are not yet able to achieve as high performance as SMT systems according to automatic evaluation metrics (see Table 1 for comparison on the CoNLL-2014 test set).
2	5	However, it has been shown that the neural approach can produce more fluent output, which might be desirable by human evaluators (Napoles et al., 2017).
3	25	In this work, we combine both MT flavors within a hybrid GEC system.
6	14	Using consistent training data and preprocessing (§ 2), we first create strong SMT (§ 3) and NMT (§ 4) baseline systems.
7	7	Then, we experiment with system combinations through pipelining and reranking (§ 5).
19	16	For our SMT-based systems, we follow recipes proposed by Junczys-Dowmunt and Grundkiewicz (2016), and use a phrase-based SMT system with a log-linear combination of task-specific features.
20	14	We use word-level Levenshtein distance and edit operation counts as dense features (Dense), and correction patterns on words with one word left/right context on Word Classes (WC) as sparse features (Sparse).
22	7	All systems use a 5-gram Language Model (LM) and OSM (Durrani et al., 2011) both estimated from the target side of the training data, and a 5-gram LM and 9-gram WCLM trained on Common Crawl data (Buck et al., 2014).
26	11	MERT (Och, 2003) is used for tuning dense features and Batch Mira (Cherry and Foster, 2012) for sparse features.
43	6	Optimization is performed with Adam (Kingma and Ba, 2014) and the mini-batch size fitted into 4GB of GPU memory.
46	8	We use early stopping with a patience of 10 based on the cross-entropy cost on the CoNLL-2013 test set.
54	6	Our RNN LM is integrated with NMT models through ensemble decoding (Sennrich et al., 2016a).
61	20	A strippeddown SMT system without CCLM, quite surprisingly gives better results on JFLEG than the NMT system, and the opposite is true for CoNLL-2014.
63	5	If both systems are enhanced by a large-scale language model, the neural system outperforms the SMT system on JFLEG and it is competitive with SMT systems on CoNLL-2014.
67	7	In this case the NMT system serves as an automatic post-editing system.
69	4	As the performance of the NMT system without a RNN LM is much lower than the performance of the SMT system alone, this implies that both approaches produce complementary corrections.
70	20	Rescoring with NMT Rescoring of an n-best list obtained from one system by another is a commonly used technique in GEC, which allows to combine multiple different systems or even different approaches (Hoang et al., 2016; Yannakoudakis et al., 2017; Chollampatt and Ng, 2017; Ji et al., 2017).
72	10	Scores of NMT models and the RNN LM are added in the form of probabilities in negative log space.
74	8	As opposed to pipelining, rescoring improves precision at the expense of recall and is more effective for the CoNLL data resulting in up to 54.95 M2.
76	7	However, the best result for rescoring is lower than for pipelining on that test set.
77	6	It seems the SMT system is not able to produce as diversified corrections in an n-best list as those generated by the NMT ensemble.
78	6	Spelling correction and final results Pipelining the NMT-rescored SMT system and the NMT system leads to further improvement.
79	10	We believe this can be explained by different contributions to precision and recall trade-offs for the two methods, similar to effects observed for the combination of the NMT ensemble and our RNN LM.
80	23	On top of our final hybrid system we add a spellchecking component, which is run before pipelining.
82	54	As our BPE-based SMT does not really suffer from unknown words, we run the spell-checking component on words that would have been segmented by the BPE algorithm.
93	8	Our best system reaches nearly 100% of the average human score according to M2 and nearly 99% for GLEU being much closer to that bound than previous works6.
94	25	Further inspection reveals, however, that the precision/recall trade-off for the automatic system indicates lower coverage compared to human corrections — lower recall is compensated with high precision7.
95	52	Automatic systems might, for example, miss some obvious error corrections and therefore easily be distinguishable from human references.
96	24	Future work would require a human evaluation effort to draw more conclusions.

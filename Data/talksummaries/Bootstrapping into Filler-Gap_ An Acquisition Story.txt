0	20	The phenomenon of filler-gap, where the argument of a predicate appears outside its canonical position in the phrase structure (e.g. [the apple]i that the boy ate ti or [what]i did the boy eat ti), has long been an object of study for syntacticians (Ross, 1967) due to its apparent processing complexity.
1	93	Such complexity is due, in part, to the arbitrary length of the dependency between a filler and its gap (e.g. [the apple]i that Mary said the boy ate ti).
3	28	This finding raises the question of how such a complex phenomenon could be acquired so early since children at that age do not yet have a very advanced grasp of language (e.g. ditransitives do not seem to be generalized until at least 31 months; Goldberg et al. 2004, Bello 2012).
9	31	The developmental timeline during which children acquire the ability to process filler-gap constructions is not well-understood.
22	63	Similarly, Gertner and Fisher (2012) show that intransitive phrases with conjoined subjects (e.g. John and Mary gorped) are given a transitive interpretation (i.e. John gorped Mary) at 21 months (henceforth termed ‘1-1 role bias’), though this effect is no longer present at 25 months (Naigles, 1990).
23	39	This finding suggests both that learners will ignore canonical structure in favor of using all possible arguments and that children have a bias to assign a unique semantic role to each argument.
24	17	It is important to note, however, that crosslinguistically children do not seem to generalize beyond two arguments until after at least 31 months of age (Goldberg et al., 2004; Bello, 2012), so a predicate occurring with three nouns would still likely be interpreted as merely transitive rather than ditransitive.
25	20	Computational modeling provides a way to test the computational level of processing (Marr, 1982).
29	32	BabySRL learns weights over ordering constraints (e.g. preverbal, second noun, etc.)
35	49	This work assumes learners can already identify nouns and verbs, which is supported by Shi et al. (1999) who show that children at an extremely young age can distinguish between content and function words and by Waxman and Booth (2001) who show that children can distinguish between different types of content words.
37	22	To handle recursion, this work assumes that children treat the final verb in each sentence as the main verb (implicitly assuming sentence segmentation), which ideally assigns roles to each of the nouns in the sentence.
38	50	Due to the findings of Yuan et al. (2012), this work adopts a ‘syntactic bootstrapping’ theory of acquisition (Gleitman, 1990), where structural properties (e.g. number of nouns) inform the learner about semantic properties of a predicate (e.g. how many semantic roles it confers).
51	53	Thus, the initial model conditions (see Figure 2) are most likely to realize an SVO ordering, although it is possible to obtain SOV (by sampling a negative number from the blue curve) or even OSV (by also sampling the red curve very close to 0).
52	79	The model is most likely to hypothesize a preverbal object when it has already assigned the subject role to something and, in addition, there is no postverbal noun competing for the object label.
59	49	The lack of a canonical subject in English imperatives allows the model to improve the likelihood of the data by using the non-canonical subject Gaussian to capture fictitious postverbal arguments.
61	26	Therefore, if one makes the assumption that imperatives are prosodically-marked for learners (e.g. the learner is the implicit subject), the best model is one that lacks a non-canonical subject.7 The remainder of this paper assumes a symmetric model to demonstrate what happens if such an assumption is not made; for the evaluations described in this paper, the results are similar in either case.
67	58	The model in this work is trained using transcribed child-directed speech (CDS) from the BabySRL portions (Connor et al., 2008) of CHILDES (MacWhinney, 2000).
99	51	This slight, though significant in Eve, deficit is counter-balanced by a very substantial and significant improvement in objectextraction labelling accuracy.
118	42	As with subject extraction, the model in this paper gets less accurate after training because of the newly minted extracted object category that can be mistakenly used in these canonical settings.
139	53	Further, the model exhibits better comprehension of wh-relatives than that-relatives similar to children (Gagliardi and Lidz, 2010).
140	22	This could also be an area where a lexicalized model could do better.
141	18	As Gagliardi and Lidz (2010) point out, whereas wh-relatives such as who or which always signify a filler-gap construction, that can occur for many different reasons (demonstrative, determiner, complementizer, etc) and so is a much weaker filler-gap cue.
143	29	It is interesting to note that the cuurent model does not make use of that as a cue at all and yet is still slower at acquiring that-relatives than wh-relatives.
147	43	The canonical Gaussian expectations can begin far from the verb (±3) or close to the verb (±0.1), and the standard deviations of the distributions and the skip-penalty can vary widely; the model always converges to give comparable results to those presented here.
149	22	In short, this paper describes a simple, robust cognitive model of the development of a learner between 15 months until somewhere between 25- and 30-months old (since 1-1 role bias is no longer present but no more than two arguments are being generalized).
150	113	In future, it would be interesting to incorporate lexicalization into the model presented in this paper, as this feature seems likely to bridge the gap between this model and BabySRL in transitive settings.
152	123	It would also be interesting to investigate how well this model generalizes to languages besides English.
153	50	Since the model is able to use the verb position as a semi-permeable boundary between canonical subjects and objects, it may not work as well in verb-final languages, and thus makes the prediction that filler-gap comprehension may be acquired later in development in such languages due to a greater reliance on hierarchical syntax.
155	93	Note that this model cannot capture the constraints on filler-gap usage which require a hierarchical grammar (e.g. subjacency), but such knowledge is really only needed for successful production of filler-gap constructions, which occurs much later (around 5 years; de Villiers and Roeper, 1995).
156	25	Further, the kind of ordering system proposed in this paper may form an initial basis for learning such grammars (Jackendoff and Wittenberg, in press).

0,1,label2,summary_sentences
We consider learning a classifier from logged data.,1. Introduction,[0],[0]
"Here, the learner has access to a logged labeled dataset that has been collected according to a known pre-determined policy, and his goal is to learn a classifier that predicts the labels accurately over the entire population, not just conditioned on the logging policy.
",1. Introduction,[0],[0]
This problem arises frequently in many natural settings.,1. Introduction,[0],[0]
An example is predicting the efficacy of a treatment as a function of patient characteristics based on observed data.,1. Introduction,[0],[0]
Doctors may assign the treatment to patients based on some predetermined rule; recording these patient outcomes produces a logged dataset where outcomes are observed conditioned on the doctors’ assignment.,1. Introduction,[0],[0]
"A second example is recidivism prediction, where the goal is to predict whether a convict will re-offend.",1. Introduction,[0],[0]
"Judges use their own predefined policy to grant parole, and if parole is granted, then an outcome (reoffense or not) is observed.",1. Introduction,[0],[0]
"Thus the observed data records outcomes conditioned on the judges’ parole policy,
1University of California, San Diego.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Songbai Yan <yansongbai@eng.ucsd.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
while the learner’s goal is to learn a predictor over the entire population.
",1. Introduction,[0],[0]
A major challenge in learning from logged data is that the logging policy may leave large areas of the data distribution under-explored.,1. Introduction,[0],[0]
"Consequently, empirical risk minimization (ERM) on the logged data leads to classifiers that may be highly suboptimal on the population.",1. Introduction,[0],[0]
"When the logging policy is known, a second option is to use a weighted ERM, that reweighs each observed labeled data point to ensure that it reflects the underlying population.",1. Introduction,[0],[0]
"However, this may lead to sample inefficiency if the logging policy does not adequately explore essential regions of the population.",1. Introduction,[0],[0]
"A final approach, typically used in clinical trials, is controlled random experimentation – essentially, ignore the logged data, and record outcomes for fresh examples drawn from the population.",1. Introduction,[0],[0]
"This approach is expensive due to the high cost of trials, and wasteful since it ignores the observed data.
",1. Introduction,[0],[0]
"Motivated by these challenges, we propose active learning to combine logged data with a small amount of strategically chosen labeled data that can be used to correct the bias in the logging policy.",1. Introduction,[0],[0]
"This solution has the potential to achieve the best of both worlds by limiting experimentation to achieve higher sample efficiency, and by making the most of the logged data.",1. Introduction,[0],[0]
"Specifically, we assume that in addition to the logged data, the learner has some additional unlabeled data that he can selectively ask an annotator to label.",1. Introduction,[0],[0]
"The learner’s goal is to learn a highly accurate classifier over the entire population by using a combination of the logged data and with as few label queries to the annotator as possible.
",1. Introduction,[0],[0]
How can we utilize logged data for better active learning?,1. Introduction,[0],[0]
This problem has not been studied to the best of our knowledge.,1. Introduction,[0],[0]
A naive approach is to use the logged data to come up with a warm start and then do standard active learning.,1. Introduction,[0],[0]
"In this work, we show that we can do even better.",1. Introduction,[0],[0]
"In addition to the warm start, we show how to use multiple importance sampling estimators to utilize the logged data more efficiently.",1. Introduction,[0],[0]
"Additionally, we introduce a novel debiasing policy that selectively avoids label queries for those examples that are highly represented in the logged data.
",1. Introduction,[0],[0]
"Combining these three approaches, we provide a new algorithm.",1. Introduction,[0],[0]
"We prove that our algorithm is statistically consistent, and has a lower label requirement than simple active learning that uses the logged data as a warm start.",1. Introduction,[0],[0]
"Finally, we
evaluate our algorithm experimentally on various datasets and logging policies.",1. Introduction,[0],[0]
Our experiments show that the performance of our method is either the best or close to the best for a variety of datasets and logging policies.,1. Introduction,[0],[0]
This confirms that active learning to combine logged data with carefully chosen labeled data may indeed yield performance gains.,1. Introduction,[0],[0]
"Instances are drawn from an instance space X and a label space Y = {0, 1}.",2.1. Problem Setup,[0],[0]
There is an underlying data distribution D over X × Y that describes the population.,2.1. Problem Setup,[0],[0]
There is a hypothesis spaceH ⊂ YX .,2.1. Problem Setup,[0],[0]
"For simplicity, we assumeH is a finite set, but our results can be generalized to VC-classes by standard arguments (Vapnik & Chervonenkis, 1971).
",2.1. Problem Setup,[0],[0]
"The learning algorithm has access to two sources of data: logged data, and online data.",2.1. Problem Setup,[0],[0]
"The logged data are generated from m examples {(Xt, Yt)}mt=1 drawn i.i.d.",2.1. Problem Setup,[0],[0]
"from D, and",2.1. Problem Setup,[0],[0]
a logging policy Q0 : X,2.1. Problem Setup,[0],[0]
"→ [0, 1] that determines the probability of observing the label.",2.1. Problem Setup,[0],[0]
"For each example (Xt, Yt) (1 ≤ t ≤ m), an independent Bernoulli random variable Zt is drawn with expectation Q0(Xt), and then the label Yt is revealed to the learning algorithm if Zt = 11.",2.1. Problem Setup,[0],[0]
"We call T0 = {(Xt, Yt, Zt)}mt=1 the logged dataset.",2.1. Problem Setup,[0],[0]
"From the algorithm’s perspective, we assume it knows the logging policy Q0, and only observes instances {Xt}mt=1, decisions of the policy {Zt}mt=1, and revealed labels {Yt | Zt = 1}mt=1.
",2.1. Problem Setup,[0],[0]
The online data are generated as follows.,2.1. Problem Setup,[0],[0]
"Suppose there is a stream of another n examples {(Xt, Yt)}m+nt=m+1 drawn i.i.d.",2.1. Problem Setup,[0],[0]
from distribution D.,2.1. Problem Setup,[0],[0]
"At time t (m < t ≤ m+ n), the algorithm uses its query policy to compute a bit Zt ∈ {0, 1}, and then the label Yt is revealed to the algorithm if Zt = 1.",2.1. Problem Setup,[0],[0]
"The computation of Zt may in general be randomized, and is based on the observed logged data T0, observed instances {Xi}ti=m+1, previous decisions{Zi} t−1 i=m+1, and observed labels {Yi | Zi = 1}t−1i=m+1.
",2.1. Problem Setup,[0],[0]
The goal of the algorithm is to learn a classifier h ∈ H from observed logged data and online data.,2.1. Problem Setup,[0],[0]
"Fixing D, Q0, m, n, the performance measures are: (1) the error rate l(h) :",2.1. Problem Setup,[0],[0]
= PrD(h(X) 6=,2.1. Problem Setup,[0],[0]
"Y ) of the output classifier, and (2) the number of label queries on the online data.",2.1. Problem Setup,[0],[0]
"Note that the error rate is over the entire population D instead of conditioned on the logging policy, and that we assume the logged data T0 come at no cost.",2.1. Problem Setup,[0],[0]
"In this work, we are interested in the situation where n is about the same as or less than m.
1Note that this generating process implies the standard unconfoundedness assumption in the counterfactual inference literature: Pr(Yt, Zt | Xt) = Pr(Yt | Xt) Pr(Zt",2.1. Problem Setup,[0],[0]
"| Xt), that is, given the instance Xt, its label Yt is conditionally independent with the action Zt (whether the label is observed).",2.1. Problem Setup,[0],[0]
"Our algorithm is based on Disagreement-Based Active Learning (DBAL) which has rigorous theoretical guarantees and can be implemented practically (see (Hanneke et al., 2014) for a survey, and (Hanneke & Yang, 2015; Huang et al., 2015) for some recent developments).",2.2. Background on Disagreement-Based Active Learning,[0],[0]
DBAL iteratively maintains a candidate set of classifiers that contains the optimal classifier h?,2.2. Background on Disagreement-Based Active Learning,[0],[0]
:= arg minh∈H l(h) with high probability.,2.2. Background on Disagreement-Based Active Learning,[0],[0]
"At the k-th iteration, the candidate set Vk is constructed as all classifiers which have low estimated error on examples observed up to round k.",2.2. Background on Disagreement-Based Active Learning,[0],[0]
"Based on Vk, the algorithm constructs a disagreement set Dk to be a set of instances on which there are at least two classifiers in Vk that predict different labels.",2.2. Background on Disagreement-Based Active Learning,[0],[0]
"Then the algorithm draws a set Tk of unlabeled examples, where the size of Tk is a parameter of the algorithm.",2.2. Background on Disagreement-Based Active Learning,[0],[0]
"For each instance X ∈ Tk, if it falls into the disagreement region Dk, then the algorithm queries for its label; otherwise, observing that all classifiers in Vk have the same prediction on X , its label is not queried.",2.2. Background on Disagreement-Based Active Learning,[0],[0]
The queried labels are then used to update future candidate sets.,2.2. Background on Disagreement-Based Active Learning,[0],[0]
"Most learning algorithms, including DBAL, require estimating the error rate of a classifier.",2.3. Background on Error Estimators,[0],[0]
A good error estimator should be unbiased and of low variance.,2.3. Background on Error Estimators,[0],[0]
"When instances are observed with different probabilities, a commonly used error estimator is the standard importance sampling estimator that reweighs each observed labeled example according to the inverse probability of observing it.
",2.3. Background on Error Estimators,[0],[0]
Consider a simplified setting where the logged dataset T0 =,2.3. Background on Error Estimators,[0],[0]
"(Xi, Yi, Zi) m i=1",2.3. Background on Error Estimators,[0],[0]
and Pr(Zi = 1 | Xi) = Q0(Xi).,2.3. Background on Error Estimators,[0],[0]
On the online dataset T1 =,2.3. Background on Error Estimators,[0],[0]
"(Xi, Yi, Zi)m+ni=m+1, the algorithm uses a fixed query policy Q1 to determine whether to query for labels, that is, Pr(Zi = 1 | Xi) = Q1(Xi) for m < i ≤",2.3. Background on Error Estimators,[0],[0]
"m+ n. Let S = T0 ∪ T1.
",2.3. Background on Error Estimators,[0],[0]
"In this setting, the standard importance sampling (IS) error estimator for a classifier h is:
lIS(h, S) := 1
m+ n m∑ i=1 1{h(Xi) 6=",2.3. Background on Error Estimators,[0],[0]
"Yi}Zi Q0(Xi)
",2.3. Background on Error Estimators,[0],[0]
"+ 1
m+ n m+n∑ i=m+1 1{h(Xi) 6= Yi}Zi",2.3. Background on Error Estimators,[0],[0]
Q1(Xi) .,2.3. Background on Error Estimators,[0],[0]
"(1)
lIS is unbiased, and its variance is proportional to supi=0,1;x∈X 1 Qi(x)
.",2.3. Background on Error Estimators,[0],[0]
"Although the learning algorithm can choose its query policy Q1 to avoid Q1(Xi) to be too small for i > m, Q0 is the logging policy that cannot be changed.",2.3. Background on Error Estimators,[0],[0]
"When Q0(Xi) is small for some i ≤ m, the estimator in (1) have a high variance such that it may be even better to just ignore the logged dataset T0.
",2.3. Background on Error Estimators,[0],[0]
"An alternative is the multiple importance sampling (MIS) estimator with balanced heuristic (Veach & Guibas, 1995):
lMIS(h, S) := m+n∑ i=1",2.3. Background on Error Estimators,[0],[0]
1{h(Xi) 6=,2.3. Background on Error Estimators,[0],[0]
Yi}Zi mQ0(Xi) + nQ1(Xi) .,2.3. Background on Error Estimators,[0],[0]
"(2)
It can be proved that lMIS(h, S) is indeed an unbiased estimator for l(h).",2.3. Background on Error Estimators,[0],[0]
"Moreover, as proved in (Owen & Zhou, 2000; Agarwal et al., 2017), (2) always has a lower variance than both (1) and the standard importance sampling estimator that ignores the logged data.
",2.3. Background on Error Estimators,[0],[0]
"In this paper, we use multiple importance sampling estimators, and write lMIS(h, S) as l(h, S).
",2.3. Background on Error Estimators,[0],[0]
"Additional Notations In this paper, unless otherwise specified, all probabilities and expectations are over the distribution D, and we drop D from subscripts henceforth.
",2.3. Background on Error Estimators,[0],[0]
"Let ρ(h1, h2)",2.3. Background on Error Estimators,[0],[0]
:= Pr(h1(X) 6=,2.3. Background on Error Estimators,[0],[0]
"h2(X)) be the disagreement mass between h1 and h2, and ρS(h1, h2)",2.3. Background on Error Estimators,[0],[0]
:= 1 N ∑N i=1 1{h1(xi) 6=,2.3. Background on Error Estimators,[0],[0]
"h2(xi)} for S = {x1, x2, . . .",2.3. Background on Error Estimators,[0],[0]
", xN} ⊂ X be the empirical disagreement mass between h1 and h2 on S.
For any h ∈ H, r > 0, define B(h, r) := {h′ ∈ H | ρ(h, h′) ≤",2.3. Background on Error Estimators,[0],[0]
r} to be r-ball around h.,2.3. Background on Error Estimators,[0],[0]
"For any V ⊆ H, define the disagreement region DIS(V )",2.3. Background on Error Estimators,[0],[0]
:= {x ∈ X | ∃h1 6=,2.3. Background on Error Estimators,[0],[0]
h2 ∈ V s.t. h1(x) 6= h2(x)}.,2.3. Background on Error Estimators,[0],[0]
"Our algorithm employs the disagreement-based active learning framework, but modifies the main DBAL algorithm in three key ways.
",3.1. Main Ideas,[0],[0]
"KEY IDEA 1: WARM-START
Our algorithm applies a straightforward way of making use of the logged data T0 inside the DBAL framework: to set the initial candidate set V0 to be the set of classifiers that have a low empirical error on T0.
",3.1. Main Ideas,[0],[0]
KEY IDEA 2: MULTIPLE IMPORTANCE,3.1. Main Ideas,[0],[0]
"SAMPLING
Our algorithm uses multiple importance sampling estimators instead of standard importance sampling estimators.",3.1. Main Ideas,[0],[0]
"As noted in the previous section, in our setting, multiple importance sampling estimators are unbiased and have lower variance, which results in a better performance guarantee.
",3.1. Main Ideas,[0],[0]
We remark that the main purpose of using multiple importance sampling estimators here is to control the variance due to the predetermined logging policy.,3.1. Main Ideas,[0],[0]
"In the classical active learning setting without logged data, standard impor-
tance sampling can give satisfactory performance guarantees (Beygelzimer et al., 2009; 2010; Huang et al., 2015).
",3.1. Main Ideas,[0],[0]
"KEY IDEA 3: A DEBIASING QUERY STRATEGY
",3.1. Main Ideas,[0],[0]
The logging policy Q0 introduces bias into the logged data: some examples may be underrepresented since Q0 chooses to reveal their labels with lower probability.,3.1. Main Ideas,[0],[0]
Our algorithm employs a debiasing query strategy to neutralize this effect.,3.1. Main Ideas,[0],[0]
"For any instance x in the online data, the algorithm would query for its label with a lower probability if Q0(x) is relatively large.
",3.1. Main Ideas,[0],[0]
It is clear that a lower query probability leads to fewer label queries.,3.1. Main Ideas,[0],[0]
"Moreover, we claim that our debiasing strategy, though queries for less labels, does not deteriorate our theoretical guarantee on the error rate of the final output classifier.",3.1. Main Ideas,[0],[0]
"To see this, we note that we can establish a concentration bound for multiple importance sampling estimators that with probability at least 1− δ, for all h ∈ H,
l(h)− l(h?) ≤2(l(h, S)− l(h?, S))
",3.1. Main Ideas,[0],[0]
+γ1 sup x∈X 1{h(x) 6=,3.1. Main Ideas,[0],[0]
h?(x)} log |H|δ mQ0(x) +,3.1. Main Ideas,[0],[0]
"nQ1(x)
+γ1 √ sup x∈X 1{h(x) 6=",3.1. Main Ideas,[0],[0]
h?(x)} log |H|δ mQ0(x) +,3.1. Main Ideas,[0],[0]
"nQ1(x) l(h?)
(3)
where m,n are sizes of logged data and online data respectively, Q0 and Q1 are query policy during the logging phase and the online phase respectively, and γ1 is an absolute constant (see Corollary 15 in Appendix for proof).
",3.1. Main Ideas,[0],[0]
"This concentration bound implies that for any x ∈ X , if Q0(x) is large, we can set Q1(x) to be relatively small (as long as mQ0(x) + nQ1(x) ≥ infx′ mQ0(x′) + nQ1(x′)) while achieving the same concentration bound.",3.1. Main Ideas,[0],[0]
"Consequently, the upper bound on the final error rate that we can establish from this concentration bound would not be impacted by the debiasing querying strategy.
",3.1. Main Ideas,[0],[0]
One technical difficulty of applying both multiple importance sampling and the debiasing strategy to the DBAL framework is adaptivity.,3.1. Main Ideas,[0],[0]
Applying both methods requires that the query policy and consequently the importance weights in the error estimator are updated with observed examples in each iteration.,3.1. Main Ideas,[0],[0]
"In this case, the summands of the error estimator are not independent, and the estimator becomes an adaptive multiple importance sampling estimator whose convergence property is still an open problem (Cornuet et al., 2012).
",3.1. Main Ideas,[0],[0]
"To circumvent this convergence issue and establish rigorous theoretical guarantees, in each iteration, we compute the error estimator from a fresh sample set.",3.1. Main Ideas,[0],[0]
"In particular, we partition the logged data and the online data stream into
disjoint subsets, and we use one logged subset and one online subset for each iteration.",3.1. Main Ideas,[0],[0]
"Algorithm 1 Acitve learning with logged data 1: Input: confidence δ, size of online data n, logging pol-
icy Q0, logged data T0.",3.2. Details of the Algorithm,[0],[0]
2: K ← dlog ne.,3.2. Details of the Algorithm,[0],[0]
3: S̃0 ← T (0)0 ; V0 ← H; D0 ← X ; ξ0 ← infx∈X Q0(x).,3.2. Details of the Algorithm,[0],[0]
"4: for k = 0, . . .",3.2. Details of the Algorithm,[0],[0]
",K − 1 do 5: Define δk ← δ(k+1)(k+2) ; σ(k, δ) ← log |H|/δ mkξk+nk ;
∆k(h, h ′)← γ0(σ(k, δk2 )+",3.2. Details of the Algorithm,[0],[0]
"√ σ(k, δk2 )ρS̃k(h, h
′)).",3.2. Details of the Algorithm,[0],[0]
6: .,3.2. Details of the Algorithm,[0],[0]
γ0 is an absolute constant defined in Lemma 16.,3.2. Details of the Algorithm,[0],[0]
"7: ĥk ← arg minh∈Vk l(h, S̃k).",3.2. Details of the Algorithm,[0],[0]
"8: Define the candidate set
Vk+1",3.2. Details of the Algorithm,[0],[0]
← {h ∈,3.2. Details of the Algorithm,[0],[0]
"Vk | l(h, S̃k) ≤",3.2. Details of the Algorithm,[0],[0]
"l(ĥk, S̃k)+∆k(h, ĥk)}
and its disagreement region Dk+1 ← DIS(Vk+1).",3.2. Details of the Algorithm,[0],[0]
"9: Define ξk+1 ← infx∈Dk+1 Q0(x), and Qk+1(x) ←
1{Q0(x) ≤ ξk+1",3.2. Details of the Algorithm,[0],[0]
+ 1/α}.,3.2. Details of the Algorithm,[0],[0]
"10: Draw nk+1 samples {(Xt, Yt)} m+n1+···+nk+1 t=m+n1···+nk+1, and
present {Xt} m+n1+···+nk+1 t=m+n1+···+nk+1 to the algorithm.
11: for t = m+n1+· · ·+nk+1 to m+n1+· · ·+nk+1 do 12:",3.2. Details of the Algorithm,[0],[0]
Zt ← Qk+1(Xt).,3.2. Details of the Algorithm,[0],[0]
"13: if Zt = 1 then 14: If Xt ∈ Dk+1, query for label: Ỹt ← Yt; otherwise infer Ỹt ← ĥk(Xt).",3.2. Details of the Algorithm,[0],[0]
"15: end if 16: end for 17: T̃k+1 ← {Xt, Ỹt, Zt} m+n1+···+nk+1 t=m+n1+···+nk+1.",3.2. Details of the Algorithm,[0],[0]
"18: S̃k+1 ← T (k+1)0 ∪ T̃k+1. 19: end for 20: Output ĥ = arg minh∈VK l(h, S̃K).
",3.2. Details of the Algorithm,[0],[0]
The Algorithm is shown as Algorithm 1.,3.2. Details of the Algorithm,[0],[0]
Algorithm 1 runs in K iterations where K = dlog ne (recall n is the size of the online data stream).,3.2. Details of the Algorithm,[0],[0]
"For simplicity, we assume n = 2K − 1.
",3.2. Details of the Algorithm,[0],[0]
"As noted in the previous subsection, we require the algorithm to use a disjoint sample set for each iteration.",3.2. Details of the Algorithm,[0],[0]
"Thus, we partition the data as follows.",3.2. Details of the Algorithm,[0],[0]
"The online data stream is partitioned into K parts T1, · · · , TK of sizes n1 = 2
0, · · · , nK = 2K−1.",3.2. Details of the Algorithm,[0],[0]
We define n0 = 0 for completeness.,3.2. Details of the Algorithm,[0],[0]
"The logged data T0 is partitioned into K + 1 parts T
(0) 0 , · · · , T (K) 0 of sizes m0 = m/3,m1 = αn1,m2 = αn2, · · · ,mK = αnK (where α = 2m/3n and we assume α ≥ 1 is an integer for simplicity.",3.2. Details of the Algorithm,[0],[0]
m0 can take other values as long as it is a constant factor of m).,3.2. Details of the Algorithm,[0],[0]
"The algorithm uses T (0)0 to construct an initial candidate set, and uses
Sk := T (k) 0 ∪ Tk in iteration k.
Algorithm 1 uses the disagreement-based active learning framework.",3.2. Details of the Algorithm,[0],[0]
"At iteration k (k = 0, · · · ,K − 1), it first constructs a candidate set Vk+1 which is the set of classifiers whose training error (using the multiple importance sampling estimator) on T (k)0 ∪ T̃k is small, and its disagreement region Dk+1.",3.2. Details of the Algorithm,[0],[0]
"At the end of the k-th iteration, it receives the (k + 1)-th part of the online data stream {Xi} m+n1···+nk+1",3.2. Details of the Algorithm,[0],[0]
i=m+n1···+nk+1 from which it can query for labels.,3.2. Details of the Algorithm,[0],[0]
It only queries for labels inside the disagreement region Dk+1.,3.2. Details of the Algorithm,[0],[0]
"For any example X outside the disagreement region, Algorithm 1 infers its label Ỹ = ĥk(X).",3.2. Details of the Algorithm,[0],[0]
"Throughout this paper, we denote by Tk, Sk the set of examples with original labels, and by T̃k, S̃k the set of examples with inferred labels.",3.2. Details of the Algorithm,[0],[0]
"The algorithm only observes T̃k and S̃k.
",3.2. Details of the Algorithm,[0],[0]
"Algorithm 1 uses aforementioned debiasing query strategy, which leads to fewer label queries than the standard disagreement-based algorithms.",3.2. Details of the Algorithm,[0],[0]
"To simplify our analysis, we round the query probability Qk(x) to be 0 or 1.",3.2. Details of the Algorithm,[0],[0]
"We first introduce some additional quantities.
",4.1. Consistency,[0],[0]
Define h?,4.1. Consistency,[0],[0]
":= minh∈H l(h) to be the best classifier in H, and ν",4.1. Consistency,[0],[0]
:= l(h?) to be its error rate.,4.1. Consistency,[0],[0]
"Let γ2 to be an absolute constant to be specified in Lemma 17 in Appendix.
We introduce some definitions that will be used to upperbound the size of the disagreement sets in our algorithm.",4.1. Consistency,[0],[0]
Let DIS0 := X .,4.1. Consistency,[0],[0]
Recall K = dlog ne.,4.1. Consistency,[0],[0]
"For k = 1, . . .",4.1. Consistency,[0],[0]
",K, let ζk := supx∈DISk−1 log(2|H|/δk) mk−1Q0(x)+nk−1 , k := γ2ζk +
γ2 √ ζkl(h?), DISk := DIS(B(h?, 2ν + k)).",4.1. Consistency,[0],[0]
"Let ζ := supx∈DIS1 1 αQ0(x)+1 .
",4.1. Consistency,[0],[0]
"The following theorem gives statistical consistency of our algorithm.
",4.1. Consistency,[0],[0]
Theorem 1.,4.1. Consistency,[0],[0]
"There is an absolute constant c0 such that for any δ > 0, with probability at least 1− δ,
l(ĥ) ≤l(h?)",4.1. Consistency,[0],[0]
+,4.1. Consistency,[0],[0]
c0 sup x∈DISK,4.1. Consistency,[0],[0]
"log K|H|δ mQ0(x) + n
+ c0
√ sup
x∈DISK",4.1. Consistency,[0],[0]
log K|H|δ mQ0(x) + n l(h?).,4.1. Consistency,[0],[0]
"We first introduce the adjusted disagreement coefficient, which characterizes the rate of decrease of the query region as the candidate set shrinks.
",4.2. Label Complexity,[0],[0]
Definition 2.,4.2. Label Complexity,[0],[0]
"For any measurable set A ⊆ X , define
S(A,α) to be⋃ A′⊆A ( A′ ∩ { x : Q0(x) ≤ inf x∈A′ Q0(x)",4.2. Label Complexity,[0],[0]
"+ 1 α }) .
",4.2. Label Complexity,[0],[0]
"For any r0 ≥ 2ν, α ≥ 1, define the adjusted disagreement coefficient θ̃(r0, α) to be
sup r>r0
1 r Pr(S(DIS(B(h?, r)), α)).
",4.2. Label Complexity,[0],[0]
"The adjusted disagreement coefficient is a generalization of the standard disagreement coefficient (Hanneke, 2007) which has been widely used for analyzing active learning algorithms.",4.2. Label Complexity,[0],[0]
"The standard disagreement coefficient θ(r) can be written as θ(r) = θ̃(r, 1), and clearly θ(r) ≥ θ̃(r, α) for all α ≥ 1.
",4.2. Label Complexity,[0],[0]
We can upper-bound the number of labels queried by our algorithm using the adjusted disagreement coefficient.,4.2. Label Complexity,[0],[0]
"(Recall that we only count labels queried during the online phase, and that α = 2m/3n ≥ 1) Theorem 3.",4.2. Label Complexity,[0],[0]
"There is an absolute constant c1 such that for any δ > 0, with probability at least 1 − δ, the number of labels queried by Algorithm 1 is at most:
c1θ̃(2ν + K , α)(nν + ζ log n log |H| log n
δ
+ log n √ nνζ log
|H| log n δ ).",4.2. Label Complexity,[0],[0]
"As a sanity check, note that when Q0(x) ≡ 1 (i.e., all labels in the logged data are shown), our results reduce to the classical bounds for disagreement-based active learning with a warm-start.
",4.3. Remarks,[0],[0]
"Next, we compare the theoretical guarantees of our algorithm with some alternatives.",4.3. Remarks,[0],[0]
We fix the target error rate to be ν,4.3. Remarks,[0],[0]
"+ , assume we are given m logged data, and compare upper bounds on the number of labels required in the online phase to achieve the target error rate.",4.3. Remarks,[0],[0]
Recall ξ0 = infx∈X Q0(x).,4.3. Remarks,[0],[0]
"Define ξ̃K := infx∈DISK Q0(x), θ̃ := θ̃(2ν, α), θ := θ(2ν).
",4.3. Remarks,[0],[0]
"From Theorem 1 and 3 and some algebra, our algorithm requires Õ ( νθ̃ · (ν+ 2 log |H| δ −mξ̃K) ) labels.
",4.3. Remarks,[0],[0]
The first alternative is passive learning that requests all labels for {Xt}m+nt=m+1 and finds an empirical risk minimizer using both logged data and online data.,4.3. Remarks,[0],[0]
"If standard importance sampling is used, the upper bound is Õ (
1 ξ0 (ν+ 2 log |H| δ −mξ0)
) .",4.3. Remarks,[0],[0]
"If multiple importance sam-
pling is used, the upper bound is Õ ( ν+ 2 log |H| δ −mξ̃K ) .
",4.3. Remarks,[0],[0]
"Both bounds are worse than ours since νθ̃ ≤ 1 and ξ0 ≤ ξ̃K ≤ 1.
",4.3. Remarks,[0],[0]
A second alternative is standard disagreement-based active learning with naive warm-start where the logged data is only used to construct an initial candidate set.,4.3. Remarks,[0],[0]
"For standard importance sampling, the upper bound is Õ ( νθ ξ0 (ν+ 2 log |H| δ −mξ0) ) .",4.3. Remarks,[0],[0]
"For multiple importance sampling (i.e., out algorithm without the debiasing step), the upper bound is Õ ( νθ · (ν+ 2 log |H| δ −mξ̃K) ) .",4.3. Remarks,[0],[0]
"Both
bounds are worse than ours since νθ̃ ≤",4.3. Remarks,[0],[0]
"νθ and ξ0 ≤ ξ̃K ≤ 1.
",4.3. Remarks,[0],[0]
"A third alternative is to merely use past policy to label data – that is, query on x with probability Q0(x) in the online phase.",4.3. Remarks,[0],[0]
"The upper bound here is Õ (
E[Q0(X)]",4.3. Remarks,[0],[0]
"ξ0 (ν+ 2 log |H| δ −mξ0)
) .",4.3. Remarks,[0],[0]
"This is worse than ours
since ξ0 ≤ E[Q0(X)] and ξ0 ≤ ξ̃K ≤ 1.",4.3. Remarks,[0],[0]
We now empirically validate our theoretical results by comparing our algorithm with a few alternatives on several datasets and logging policies.,5. Experiments,[0],[0]
"In particular, we confirm that the test error of our classifier drops faster than several alternatives as the expected number of label queries increases.",5. Experiments,[0],[0]
"Furthermore, we investigate the effectiveness of two key components of our algorithm: multiple importance sampling and the debiasing query strategy.",5. Experiments,[0],[0]
"To the best of our knowledge, no algorithms with theoretical guarantees have been proposed in the literature.",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
We consider the overall performance of our algorithm against two natural baselines: standard passive learning (PASSIVE) and the disagreement-based active learning algorithm with warm start (DBALW).,5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"To understand the contribution of multiple importance sampling and the debiasing query strategy, we also compare the results with the disagreement-based active learning with warm start that uses multiple importance sampling (DBALWM).",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"We do not compare with the standard disagreement-based active learning that ignores the logged data since the contribution of warm start is clear: it always results in a smaller initial candidate set, and thus leads to less label queries.
",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"Precisely, the algorithms we implement are:
• PASSIVE:",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"A passive learning algorithm that queries labels for all examples in the online sequence and uses the standard importance sampling estimator to combine logged data and online data.
",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
• DBALW:,5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"A disagreement-based active learning algorithm that uses the standard importance sampling estimator, and constructs the initial candidate set with logged data.",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"This algorithm only uses only our first key idea – warm start.
",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
• DBALWM:,5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"A disagreement-based active learning algorithm that uses the multiple importance sampling estimator, and constructs the initial candidate set with logged data.",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"This algorithm uses our first and second key ideas, but not the debiasing query strategy.",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"In other words, this method sets Qk ≡ 1 in Algorithm 1.
• IDBAL:",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"The method proposed in this paper: improved disagreement-based active learning algorithm with warm start that uses the multiple importance sampling estimator and the debiasing query strategy.
",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
Our implementation of above algorithms follows Vowpal Wabbit (vw).,5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
Details can be found in Appendix.,5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"Due to lack of public datasets for learning with logged data, we convert datasets for standard binary classification into our setting.",5.1.2. DATA,[0],[0]
"Specifically, we first randomly select 80% of the whole dataset as training data and the remaining 20% is test data.",5.1.2. DATA,[0],[0]
"We randomly select 50% of the training set as logged data, and the remaining 50% is online data.",5.1.2. DATA,[0],[0]
"We then run an artificial logging policy (to be specified later) on the logged data to determine whether each label should be revealed to the learning algorithm or not.
",5.1.2. DATA,[0],[0]
"Experiments are conducted on synthetic data and 11 datasets from UCI datasets (Lichman, 2013) and LIBSVM datasets (Chang & Lin, 2011).",5.1.2. DATA,[0],[0]
"The synthetic data is generated as follows: we generate 6000 30-dimensional points uniformly from hypercube [−1, 1]30, and labels are assigned by a random linear classifier and then flipped with probability 0.1 independently.
",5.1.2. DATA,[0],[0]
"We use the following four logging policies:
• IDENTICAL:",5.1.2. DATA,[0],[0]
"Each label is revealed with probability 0.005.
",5.1.2. DATA,[0],[0]
• UNIFORM:,5.1.2. DATA,[0],[0]
We first assign each instance in the instance space to three groups with (approximately) equal probability.,5.1.2. DATA,[0],[0]
"Then the labels in each group are revealed with probability 0.005, 0.05, and 0.5 respectively.
",5.1.2. DATA,[0],[0]
• UNCERTAINTY:,5.1.2. DATA,[0],[0]
We first train a coarse linear classifier using 10% of the data.,5.1.2. DATA,[0],[0]
"Then, for an instance at distance r to the decision boundary, we reveal its label with probability exp(−cr2) where c is some constant.",5.1.2. DATA,[0],[0]
"This policy is intended to simulate uncertainty sampling used in active learning.
",5.1.2. DATA,[0],[0]
• CERTAINTY:,5.1.2. DATA,[0],[0]
We first train a coarse linear classifier using 10% of the data.,5.1.2. DATA,[0],[0]
"Then, for an instance at distance r to the decision boundary, we reveal its label with probability cr2 where c is some constant.",5.1.2. DATA,[0],[0]
This policy is intended to simulate a scenario where an action (i.e. querying for labels in our setting) is taken only if the current model is certain about its consequence.,5.1.2. DATA,[0],[0]
The experiments are conducted as follows.,5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"For a fixed policy, for each dataset d, we repeat the following process 10 times.",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"At time k, we first randomly generate a simulated logged dataset, an online dataset, and a test dataset as stated above.",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"Then for i = 1, 2, · · · , we set the horizon of the online data stream ai = 10 × 2i (in other words, we only allow the algorithm to use first ai examples in the online dataset), and run algorithm A with parameter set p (to be specified later) using the logged dataset and first ai examples in the online dataset.",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"We record n(d, k, i, A, p) to be the number of label queries, and e(d, k, i, A, p) to be the test error of the learned linear classifier.
",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"Let n̄(d, i, A, p) = 110 ∑ k n(d, k, i, A, p), ē(d, i, A, p) =
1 10 ∑ k e(d, k, i, A, p).",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"To evaluate the overall performance of algorithm A with parameter set p, we use the following area under the curve metric (see also (Huang et al., 2015)):
AUC(d,A, p) = ∑ i ē(d, i, A, p) + ē(d, i+ 1, A, p) 2
· (n̄(d, i+ 1, A, p)− n̄(d, i, A, p)).
",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"A small value of AUC means that the test error decays fast as the number of label queries increases.
",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"The parameter set p consists of two parameters:
• Model capacity C (see also item 4 in Appendix F.1).",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"In our theoretical analysis there is a term C := O(log Hδ ) in the bounds, which is known to be loose in practice (Hsu, 2010).",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"Therefore, in experiments, we treat C as a parameter to tune.",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"We try C in {0.01 × 2k | k = 0, 2, 4, . . .",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
", 18}
• Learning rate η (see also item 3 in Appendix F.1).",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
We use online gradient descent with stepsize √ η t+η .,5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"We
try η in {0.0001× 2k | k = 0, 2, 4, . . .",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
", 18}.
",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"For each policy, we report AUC(d,A) = minp AUC(d,A, p), the AUC under the parameter set that minimizes AUC for dataset d and algorithm A.",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
We report the AUCs for each algorithm under each policy and each dataset in Tables 1 to 4.,5.2. Results and Discussion,[0],[0]
"The test error curves can be found in Appendix.
",5.2. Results and Discussion,[0],[0]
"Table 1: AUC under Identical policy
Dataset Passive DBALw DBALwm IDBAL
synthetic 121.77 123.61 111.16 106.66 letter 4.40 3.65 3.82 3.48 skin 27.53 27.29 21.48 21.44 magic 109.46 101.77 89.95 83.82 covtype 228.04 209.56 208.82 220.27 mushrooms 19.22 25.29 18.54 23.67 phishing 78.49 73.40 70.54 71.68 splice 65.97 67.54 65.73 65.66 svmguide1 59.36 55.78 46.79 48.04 a5a 53.34 50.8 51.10 51.21 cod-rna 175.88 176.42 167.42 164.96 german 65.76 68.68 59.31 61.54
Table 2: AUC under Uniform policy
Dataset Passive DBALw DBALwm IDBAL
synthetic 113.49 106.24 92.67 88.38 letter 1.68 1.29 1.45 1.59 skin 23.76 21.42 20.67 19.58 magic 53.63 51.43 51.78 50.19 covtype 262.34 287.40 274.81 263.82 mushrooms 7.31 6.81 6.51 6.90 phishing 42.53 39.56 39.19 37.02 splice 88.61 89.61 90.98 87.75 svmguide1 110.06 105.63 98.41 96.46 a5a",5.2. Results and Discussion,[0],[0]
"46.96 48.79 49.50 47.60 cod-rna 63.39 63.30 66.32 58.48 german 63.60 55.87 56.22 55.79
Overall Performance The results confirm that the test error of the classifier output by our algorithm (IDBAL) drops faster than the baselines PASSIVE and DBALW: as demonstrated in Tables 1 to 4, IDBAL achieves lower AUC than both PASSIVE and DBALW for a majority of datasets under all policies.",5.2. Results and Discussion,[0],[0]
We also see that IDBAL performs better than or close to DBALWM for all policies other than Identical.,5.2. Results and Discussion,[0],[0]
"This confirms that among our two key novel ideas, using multiple importance sampling consistently results in a performance gain.",5.2. Results and Discussion,[0],[0]
"Using the debiasing query strategy over multiple importance sampling also leads to performance gains, but these are less consistent.
",5.2. Results and Discussion,[0],[0]
"The Effectiveness of Multiple Importance Sampling As noted in Section 2.3, multiple importance sampling estimators have lower variance than standard importance sampling estimators, and thus can lead to a lower label complexity.",5.2. Results and Discussion,[0],[0]
"This is verified in our experiments that DBALWM (DBAL with multiple importance sampling estimators) has a lower AUC than DBALW (DBAL with standard impor-
tance sampling estimator) on a majority of datasets under all policies.
",5.2. Results and Discussion,[0],[0]
"The Effectiveness of the Debiasing Query Strategy Under Identical policy, all labels in the logged data are revealed with equal probability.",5.2. Results and Discussion,[0],[0]
"In this case, our algorithm IDBAL queries all examples in the disagreement region as DBALWM does.",5.2. Results and Discussion,[0],[0]
"As shown in Table 1, IDBAL and DBALWM achieves the best AUC on similar number of datasets, and both methods outperform DBALW over most datasets.
",5.2. Results and Discussion,[0],[0]
"Under Uniform, Uncertainty, and Certainty policies, labels in the logged data are revealed with different probabilities.",5.2. Results and Discussion,[0],[0]
"In this case, IDBAL’s debiasing query strategy takes effect: it queries less frequently the instances that are wellrepresented in the logged data, and we show that this could lead to a lower label complexity theoretically.",5.2. Results and Discussion,[0],[0]
"In our experiments, as shown in Tables 2 to 4, IDBAL does indeed outperform DBALWM on these policies empirically.",5.2. Results and Discussion,[0],[0]
"Learning from logged observational data is a fundamental problem in machine learning with applications to causal inference (Shalit et al., 2017), information retrieval (Strehl et al., 2010; Li et al., 2015; Hofmann et al., 2016), recommender systems (Li et al., 2010; Schnabel et al., 2016), online learning (Agarwal et al., 2014; Wang et al., 2017), and reinforcement learning (Thomas, 2015; Thomas et al., 2015; Mandel et al., 2016).",6. Related Work,[0],[0]
"This problem is also closely related to covariate shift (Zadrozny, 2004; Sugiyama et al., 2007; Ben-David et al., 2010).",6. Related Work,[0],[0]
"Two variants are widely studied – first, when the logging policy is known, a problem known as learning from logged data (Li et al., 2015; Thomas et al., 2015; Swaminathan & Joachims, 2015a;b), and second, when this policy is unknown (Johansson et al., 2016; Athey & Imbens, 2016; Kallus, 2017; Shalit et al., 2017), a problem known as learning from observational data.",6. Related Work,[0],[0]
"Our work addresses the first problem.
",6. Related Work,[0],[0]
"When the logging policy is unknown, the direct method (Dudı́k et al., 2011) finds a classifier using observed data.",6. Related Work,[0],[0]
"This method, however, is vulnerable to selection bias (Hofmann et al., 2016; Johansson et al., 2016).",6. Related Work,[0],[0]
"Existing debiasing procedures include (Athey & Imbens, 2016; Kallus, 2017), which proposes a tree-based method to partition the data space, and (Johansson et al., 2016; Shalit et al., 2017), which proposes to use deep neural networks to learn a good representation for both the logged and population data.
",6. Related Work,[0],[0]
"When the logging policy is known, we can learn a classifier by optimizing a loss function that is an unbiased estimator of the expected error rate.",6. Related Work,[0],[0]
"Even in this case, however, estimating the expected error rate of a classifier is not completely straightforward and has been one of the central problems in contextual bandit (Wang et al., 2017), off-policy evaluation (Jiang & Li, 2016), and other related fields.",6. Related Work,[0],[0]
"The most common solution is to use importance sampling according to the inverse propensity scores (Rosenbaum & Rubin, 1983).",6. Related Work,[0],[0]
"This method is unbiased when propensity scores are accurate, but may have high variance when some propensity scores are close to zero.",6. Related Work,[0],[0]
"To resolve this, (Bottou et al., 2013; Strehl et al., 2010; Swaminathan & Joachims, 2015a) propose to truncate the inverse propensity score, (Swaminathan & Joachims, 2015b) proposes to use normalized importance sampling, and (Jiang & Li, 2016; Dudı́k et al., 2011; Thomas & Brunskill, 2016; Wang et al., 2017) propose doubly robust estimators.",6. Related Work,[0],[0]
"Recently, (Thomas et al., 2015) and (Agarwal et al., 2017) suggest adjusting the importance weights according to data to further reduce the variance.",6. Related Work,[0],[0]
"We use the multiple importance sampling estimator (which have also been recently studied in (Agarwal et al., 2017) for policy evaluation), and we prove this estimator concentrates around the true expected loss tightly.
",6. Related Work,[0],[0]
"Most existing work on learning with logged data falls into
the passive learning paradigm, that is, they first collect the observational data and then train a classifier.",6. Related Work,[0],[0]
"In this work, we allow for active learning, that is, the algorithm could adaptively collect some labeled data.",6. Related Work,[0],[0]
"It has been shown in the active learning literature that adaptively selecting data to label can achieve high accuracy at low labeling cost (Balcan et al., 2009; Beygelzimer et al., 2010; Hanneke et al., 2014; Zhang & Chaudhuri, 2014; Huang et al., 2015).",6. Related Work,[0],[0]
"Krishnamurthy et al. (2017) study active learning with bandit feedback and give a disagreement-based learning algorithm.
",6. Related Work,[0],[0]
"To the best of our knowledge, there is no prior work with theoretical guarantees that combines passive and active learning with a logged observational dataset.",6. Related Work,[0],[0]
"Beygelzimer et al. (2009) consider active learning with warm-start where the algorithm is presented with a labeled dataset prior to active learning, but the labeled dataset is not observational: it is assumed to be drawn from the same distribution for the entire population, while in our work, we assume the logged dataset is in general drawn from a different distribution by a logging policy.",6. Related Work,[0],[0]
We consider active learning with logged data.,7. Conclusion and Future Work,[0],[0]
The logged data are collected by a predetermined logging policy while the learner’s goal is to learn a classifier over the entire population.,7. Conclusion and Future Work,[0],[0]
"We propose a new disagreement-based active learning algorithm that makes use of warm start, multiple importance sampling, and a debiasing query strategy.",7. Conclusion and Future Work,[0],[0]
We show that theoretically our algorithm achieves better label complexity than alternative methods.,7. Conclusion and Future Work,[0],[0]
"Our theoretical results are further validated by empirical experiments on different datasets and logging policies.
",7. Conclusion and Future Work,[0],[0]
This work can be extended in several ways.,7. Conclusion and Future Work,[0],[0]
"First, the derivation and analysis of the debiasing strategy are based on a variant of the concentration inequality (3) in subsection 3.1.",7. Conclusion and Future Work,[0],[0]
"The inequality relates the generalization error with the best error rate l(h?), but has a looser variance term than some existing bounds (for example (Cortes et al., 2010)).",7. Conclusion and Future Work,[0],[0]
"A more refined analysis on the concentration of weighted estimators could better characterize the performance of the proposed algorithm, and might also improve the debiasing strategy.",7. Conclusion and Future Work,[0],[0]
"Second, due to the dependency of multiple importance sampling, in Algorithm 1, the candidate set Vk+1 is constructed with only the k-th segment of data S̃k instead of all data collected so far ∪ki=0S̃i.",7. Conclusion and Future Work,[0],[0]
One future direction is to investigate how to utilize all collected data while provably controlling the variance of the weighted estimator.,7. Conclusion and Future Work,[0],[0]
"Finally, it would be interesting to investigate how to perform active learning from logged observational data without knowing the logging policy.
",7. Conclusion and Future Work,[0],[0]
Acknowledgements We thank NSF under CCF 1719133 for support.,7. Conclusion and Future Work,[0],[0]
"We thank Chris Meek, Adith Swaminathan, and Chicheng Zhang for helpful discussions.",7. Conclusion and Future Work,[0],[0]
We also thank anonymous reviewers for constructive comments.,7. Conclusion and Future Work,[0],[0]
"We consider active learning with logged data, where labeled examples are drawn conditioned on a predetermined logging policy, and the goal is to learn a classifier on the entire population, not just conditioned on the logging policy.",abstractText,[0],[0]
"Prior work addresses this problem either when only logged data is available, or purely in a controlled random experimentation setting where the logged data is ignored.",abstractText,[0],[0]
"In this work, we combine both approaches to provide an algorithm that uses logged data to bootstrap and inform experimentation, thus achieving the best of both worlds.",abstractText,[0],[0]
"Our work is inspired by a connection between controlled random experimentation and active learning, and modifies existing disagreement-based active learning algorithms to exploit logged data.",abstractText,[0],[0]
Active Learning with Logged Data,title,[0],[0]
"Visual recognition is undergoing a period of transformative progress, due in large part to the success of deep architectures trained on massive datasets with supervision.",1. Introduction,[0],[0]
"While visual data is in ready supply, high-quality supervised labels are not.",1. Introduction,[0],[0]
One attractive solution is the exploration of unsupervised learning.,1. Introduction,[0],[0]
"However, regardless how they are trained, one still needs to evaluate accuracy of the resulting systems.",1. Introduction,[0],[0]
"Given the importance of rigorous, empirical benchmarking, it appears impossible to avoid the costs of assembling high-quality, human-annotated test data for test evaluation.
",1. Introduction,[0],[0]
"Unfortunately, manually annotating ground-truth for largescale test datasets is often prohibitively expensive, particu-
1University of California, Irvine 2Carnegie Mellon University.",1. Introduction,[0],[0]
"Correspondence to: Phuc Nguyen <nguyenpx@uci.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
larly for rich annotations required to evaluate object detection and segmentation.,1. Introduction,[0],[0]
Even simple image tag annotations pose an incredible cost at scale 1.,1. Introduction,[0],[0]
"In contrast, obtaining noisy or partial annotations is often far cheaper or even free.",1. Introduction,[0],[0]
"For example, numerous social media platforms produce image and video data that are dynamically annotated with user-provided tags (Flickr, Vine, Snapchat, Facebook, YouTube).",1. Introduction,[0],[0]
"While much work has explored the use of such massively-large “webly-supervised” data sources for learning (Wu et al., 2015; Yu et al., 2014; Li et al., 2017; Veit et al., 2017), we instead focus on them for evaluation.
",1. Introduction,[0],[0]
How can we exploit such partial or noisy labels during testing?,1. Introduction,[0],[0]
"With a limited budget for vetting noisy groundtruth labels, one may be tempted to simply evaluate performance on a small set of clean data, or alternately just trust the cheap-but-noisy labels on the whole dataset.",1. Introduction,[0],[0]
"However, such approaches can easily give an inaccurate impression of system performance.",1. Introduction,[0],[0]
We show in our experiments that these naive approaches can produce alarmingly-incorrect estimates of comparative model performance.,1. Introduction,[0],[0]
"Even with a significant fraction of vetted data, naive performance esti-
1For example, NUS-WIDE, (Chua et al., 2009) estimated 3000 man-hours to semi-manually annotate a relatively small set of 81 concepts across 270K images
mates can incorrectly rank two algorithms in 15% of trials, while our active testing approach significantly reduces this misranking error to 3%.
",1. Introduction,[0],[0]
"The problem of label noise even exists for “expertly” annotated datasets, whose construction involves manual selection of a test set which is deemed representative in combination with crowd-sourced labeling by multiple experts (Rashtchian et al., 2010; Khattak & Salleb-Aouissi, 2011).",1. Introduction,[0],[0]
"Preserving annotation quality is an area of intense research within the HCI/crowdsourcing community (Kamar et al., 2012; Sheshadri & Lease, 2013).",1. Introduction,[0],[0]
"In practice, annotation errors are often corrected incrementally through multiple rounds of interactive error discovery and visual inspection of algorithm test results over the lifetime of the dataset.",1. Introduction,[0],[0]
"For example, in evaluating object detectors, the careful examination of detector errors on the test set (Hoiem et al., 2012) often reveals missing annotations in widelyused benchmarks (Lin et al., 2014; Everingham et al., 2015; Dollar et al., 2012) and may in turn invoke further iterations of manual corrections (e.g., (Mathias et al., 2014)).",1. Introduction,[0],[0]
"In this work, we formalize such ad-hoc practices in a framework we term active testing, and show that significantly improved estimates of accuracy can be made through simple statistical models and active annotation strategies.",1. Introduction,[1.0],"['In this work, we formalize such ad-hoc practices in a framework we term active testing, and show that significantly improved estimates of accuracy can be made through simple statistical models and active annotation strategies.']"
Benchmarking:,2. Related Work,[0],[0]
Empirical benchmarking is now widely considered to be an integral tool in the development of vision and learning algorithms.,2. Related Work,[0],[0]
"Rigorous evaluation, often in terms of challenge competitions (Russakovsky et al., 2015; Everingham et al., 2010) on held-out data, serves to formally codify proxies for scientific or application goals and provides quantitative ways to characterize progress towards them.",2. Related Work,[0],[0]
"The importance and difficulties of test dataset construction and annotation are now readily appreciated (Ponce et al., 2006; Torralba & Efros, 2011).
",2. Related Work,[0],[0]
"Benchmark evaluation can be framed in terms of the well-known empirical risk minimization approach to learning (Vapnik, 1992).",2. Related Work,[0],[0]
"Benchmarking seeks to estimate the risk, defined as the expected loss of an algorithm under the true data distribution.",2. Related Work,[0],[0]
"Since the true distribution is unknown, the expected risk is estimated by computing loss a finite sized sample test set.",2. Related Work,[0],[0]
"Traditional losses (such as 0-1 error) decompose over test examples, but we are often interested in multivariate ranking-based metrics that do not decompose (such as Precision@K and Average Precision (Joachims, 2005)).",2. Related Work,[0],[0]
"Defining and estimating expected risk for such metrics is more involved (e.g., Precision@K should be replaced by precision at a specified quantile (Boyd et al., 2012))",2. Related Work,[0],[0]
"but generalization bounds are known (Agarwal et al., 2005; Hill et al., 2002).",2. Related Work,[0],[0]
"For simplicity, we focus on the problem of estimating the empirical risk on a fixed, large but finite
test set.
",2. Related Work,[0],[0]
"Semi-supervised testing: To our knowledge, there have only been a handful of works specifically studying the problem of estimating recognition performance on partially labeled test data.",2. Related Work,[0],[0]
"Anirudh et al. (Anirudh & Turaga, 2014) study the problem of ’test-driving’ a detector to allow the users to get a quick sense of the generalizability of the system.",2. Related Work,[0],[0]
Closer to our approach is that of Welinder et al.,2. Related Work,[0],[0]
"(Welinder et al., 2013), who estimate the performance curves using a generative model for the classifier’s confidence scores.",2. Related Work,[0],[0]
"Their approach leverages ideas from the semi-supervised learning literature while our approach builds on active learning.
",2. Related Work,[0],[0]
The problem of estimating benchmark performance from sampled relevance labels has been explored more extensively in the information retrieval literature where complete annotation was acknowledged as infeasible.,2. Related Work,[0],[0]
"Initial work focused on deriving labeling strategies that produce lowvariance and unbiased estimates (Yilmaz & Aslam, 2006; Aslam et al., 2006) and identifying performant retrieval systems (Moffat et al., 2007).",2. Related Work,[0],[0]
"(Sabharwal & Sedghi, 2017) give error bounds for estimating PR and ROC curves by choosing samples to label based on the system output ranking.",2. Related Work,[0],[0]
"(Gao et al., 2014) estimate performance using an EM algorithm to integrate relevance judgements.",2. Related Work,[0],[0]
"(Li & Kanoulas, 2017) and (Rahman et al., 2018) take a strategy similar to ours in actively selecting test items to label as well as estimating performance on remaining unlabeled data.
",2. Related Work,[0],[0]
Active learning: Our proposed formulation of active testing is closely related to active learning.,2. Related Work,[0],[0]
"From a theoretical perspective, active learning can provide strong guarantees of efficiency under certain restrictions (Balcan & Urner, 2016).",2. Related Work,[0],[0]
"Human-in-the-loop active learning approaches have been well explored for addressing training data collection in visual recognition systems (Branson et al., 2010; Wah et al., 2011; Vijayanarasimhan & Grauman, 2014).",2. Related Work,[0],[0]
"One
can view active testing as a form of active learning where the actively-trained model is a statistical predictor of performance on a test set.",2. Related Work,[0],[0]
"Active learning is typically cast within the standard machine-learning paradigm, where the goal is to (interactively) learn a model that makes accurate per-example predictions on held-out i.i.d data.",2. Related Work,[0],[0]
"In this case, generalization is of paramount importance.",2. Related Work,[0],[0]
"On the other hand, active-testing interactively learns a model that makes aggregate statistical predictions over a fixed dataset.",2. Related Work,[0],[0]
"This means that models learned for active-testing (that say, predict average precision) need not generalize beyond the test set of interest.",2. Related Work,[0],[0]
This suggests that one can be much more aggressive in overfitting to the statistics of the data at hand.,2. Related Work,[0],[0]
"In this section, we introduce the general framework for active testing.",3. Framework for Active Testing,[0],[0]
Figure 1 depicts the overall flow of our approach.,3. Framework for Active Testing,[0],[0]
Our evaluation database initially contains test examples with inaccurate (noisy) annotations.,3. Framework for Active Testing,[0],[0]
"We select a batch of data items whose labels will be manually vetted by an oracle (e.g., in-house annotators or a crowd-sourced platform such as Mechanical Turk).",3. Framework for Active Testing,[0],[0]
Figure 2 shows examples of such noisy labels and queries to Oracle.,3. Framework for Active Testing,[0],[0]
The evaluation database is then updated with these vetted labels to improve estimates of test performance.,3. Framework for Active Testing,[0],[0]
"Active testing consists of two key components: a metric estimator that estimates model performance from test data with a mix of noisy and vetted labels, and a vetting strategy which selects the subset of test data to be labeled in order to achieve the best possible estimate of the true performance.",3. Framework for Active Testing,[0],[0]
We first consider active testing for a simple binary prediction problem and then extend this idea to more complex benchmarking tasks such as multi-label tag prediction and instance segmentation.,3.1. Performance Metric Estimators,[0],[0]
"As a running example, assume that we are evaluating an system that classifies an image (e.g., as containing a cat or not).",3.1. Performance Metric Estimators,[0],[0]
The system returns of confidence score si ∈ R for each test example i ∈ {1 . . .,3.1. Performance Metric Estimators,[0],[0]
N}.,3.1. Performance Metric Estimators,[0],[0]
"Let yi denote a “noisy” binary label for example i (specifying if a cat is present), where the noise could arise from labeling the test set using some weak-but-cheap annotation technique (e.g., user-provided tags, search engine results, or approximate annotations).",3.1. Performance Metric Estimators,[0],[0]
"Finally, let zi be the true latent binary label whose value can be obtained by rigorous human inspection of the test data item.
",3.1. Performance Metric Estimators,[0],[0]
Typical benchmark performance metrics can be written as a function of the true ground-truth labels and system confidences.,3.1. Performance Metric Estimators,[0],[0]
"We focus on metrics that only depend on the rank ordering of the confidence scores and denote such a metric generically as Q({zi}) where for simplicity we hide the dependence on s by assuming that the indices are always
sorted according to si so that s1 ≥ · · · ≥ sN .",3.1. Performance Metric Estimators,[1.0000000075053324],['We focus on metrics that only depend on the rank ordering of the confidence scores and denote such a metric generically as Q({zi}) where for simplicity we hide the dependence on s by assuming that the indices are always sorted according to si so that s1 ≥ · · · ≥ sN .']
"For example, commonly-used metrics for binary labeling include precision@K and average precision (AP):
Prec@K({z1, . . .",3.1. Performance Metric Estimators,[0],[0]
", zN})",3.1. Performance Metric Estimators,[0],[0]
"= 1
K ∑",3.1. Performance Metric Estimators,[0],[0]
i≤K zi,3.1. Performance Metric Estimators,[0],[0]
"(1)
AP ({z1, . . .",3.1. Performance Metric Estimators,[0],[0]
", zN})",3.1. Performance Metric Estimators,[0],[0]
"= 1
",3.1. Performance Metric Estimators,[0],[0]
Np ∑ k zk k ∑ i≤k zi,3.1. Performance Metric Estimators,[0],[0]
"(2)
whereNp is the number of positives.",3.1. Performance Metric Estimators,[0],[0]
"We include derivations in supplmental material.
",3.1. Performance Metric Estimators,[0],[0]
"Estimation with partially vetted data: In practice, not all the data in our test set will be vetted.",3.1. Performance Metric Estimators,[0],[0]
"Let us divide the test set into two components, the unvetted set U for which we only know the approximate noisy labels yi and the vetted set V , for which we know the ground-truth label.",3.1. Performance Metric Estimators,[0],[0]
"With a slight abuse of notation, we henceforth treat the true label zi as a random variable, and denote its observed realization (on the vetted set) as z̃i.",3.1. Performance Metric Estimators,[0],[0]
"The simplest strategy for estimating the true performance is to ignore unvetted data and only measure performance Q on the vetted subset:
Q({z̃i",3.1. Performance Metric Estimators,[0],[0]
: i ∈ V }),3.1. Performance Metric Estimators,[0],[0]
"[Vetted Only] (3)
",3.1. Performance Metric Estimators,[0],[0]
"This represents the traditional approach to empirical evaluation in which we collect a single, vetted test dataset and ignore other available test data.",3.1. Performance Metric Estimators,[0],[0]
This has the advantage that it is unbiased and converges to the true empirical performance as the whole dataset is vetted.,3.1. Performance Metric Estimators,[0],[0]
"The limitation is that it makes use of only fully-vetted data and the variance in the estimate can be quite large when the vetting budget is limited.
",3.1. Performance Metric Estimators,[0],[0]
A natural alternative is to incorporate the unvetted examples by simply substituting yi as a “best guess” of the true zi.,3.1. Performance Metric Estimators,[0],[0]
"We specify this naive assumption in terms of a distribution over all labels z = {z1, . . .",3.1. Performance Metric Estimators,[0],[0]
", zN}:
pnaive(z) = ∏ i∈U δ(zi = yi) ∏",3.1. Performance Metric Estimators,[0],[0]
"i∈V δ(zi = z̃i) (4)
where z̃i is the label assigned during vetting.",3.1. Performance Metric Estimators,[0],[0]
"Under this assumption we can then compute an expected benchmark performance:
Epnaive(z)
",3.1. Performance Metric Estimators,[0],[0]
[ Q(z) ],3.1. Performance Metric Estimators,[0],[0]
"[Naive Estimator] (5)
which amounts to simply substituting z̃i for vetted examples and yi for unvetted examples.
Unfortunately, the above performance estimate may be greatly affected by noise in the nosiy labels yi.",3.1. Performance Metric Estimators,[0],[0]
"For example, if there are systematic biases in the yi, the performance estimate will similarly be biased.",3.1. Performance Metric Estimators,[0],[0]
"We also consider more general scenarios where side information such as features
Algorithm 1 Active Testing Algorithm Input: unvetted set U , vetted set V , total budget T , vetting strategy V S, system scores S = {si}, estimator pest(z) while T ≥ 0 do
of the test items and distribution of scores of the classifier under test may also be informative.",3.1. Performance Metric Estimators,[0],[0]
"We thus propose computing the expected performance under a more sophisticated estimator:
pest(z) = ∏ i∈U p(zi|O) ∏ i∈V δ(zi = z̃i)",3.1. Performance Metric Estimators,[0],[0]
"(6)
where O is the total set of all observations available to the benchmark system (e.g. noisy labels, vetted labels, classifier scores, data features).",3.1. Performance Metric Estimators,[0],[0]
"We make the plausible assumption that the distribution of unvetted labels factors conditioned on O.
Our proposed active testing framework (see Alg 1) estimates this distribution pest(z) based on available observations and predicts expected benchmark performance under this distribution:
Epest(z)
",3.1. Performance Metric Estimators,[0],[0]
[ Q(z) ],3.1. Performance Metric Estimators,[0],[0]
"[Learned Estimator] (7)
",3.1. Performance Metric Estimators,[0],[0]
Computing expected performance:,3.1. Performance Metric Estimators,[0],[0]
"Given posterior estimates p(zi|O) we can always compute the expected performance metric Q by generating samples from these distributions, computing the metric for each joint sample, and average over samples.",3.1. Performance Metric Estimators,[0],[0]
"Here we introduce two applications (studied in our experiments) where the metric is linear or quadratic in z, allowing us to compute the expected performance in closed-form.
",3.1. Performance Metric Estimators,[0],[0]
Multi-label Tags: Multi-label tag prediction is a common task in video/image retrieval.,3.1. Performance Metric Estimators,[1.0],['Multi-label Tags: Multi-label tag prediction is a common task in video/image retrieval.']
"Following recent work (Joulin et al., 2016; Gong et al., 2013; Izadinia et al., 2015; Guillaumin et al., 2009), we measure accuracy with Precision@K - e.g., what fraction of the topK search results contain the tag of interest?",3.1. Performance Metric Estimators,[0],[0]
"In this setting, noisy labels yi come from user provided tags which may contain errors and are typically incomplete.",3.1. Performance Metric Estimators,[0],[0]
"Conveniently, we can write expected performance Eq. 7 for Precision@K for a single tag in closed form:
E[Prec@K] = 1
K ( ∑ i∈VK z̃i + ∑ i∈UK p(zi = 1|O) ) (8)
where we write VK and UK to denote the vetted and unvetted subsets of K highest-scoring examples in the total set V ∪ U .",3.1. Performance Metric Estimators,[0],[0]
"Some benchmarks compute an aggregate mean precision over all tags under consideration, but since this average is linear, one again obtains a closed form estimate.
",3.1. Performance Metric Estimators,[0],[0]
Instance segmentation:,3.1. Performance Metric Estimators,[0],[0]
Instance segmentation is another natural task for which to apply active testing.,3.1. Performance Metric Estimators,[0],[0]
"It is well known that human annotation is prohibitively expensive – (Cordts et al., 2016) reports that an average of more than 1.5 hours is required to annotate a single image.",3.1. Performance Metric Estimators,[1.0],"['It is well known that human annotation is prohibitively expensive – (Cordts et al., 2016) reports that an average of more than 1.5 hours is required to annotate a single image.']"
"Widely used benchmarks such as (Cordts et al., 2016) release small fraction of images annotated with high quality, along with a larger set of noisy or “coarse”-quality annotations.",3.1. Performance Metric Estimators,[1.0],"['Widely used benchmarks such as (Cordts et al., 2016) release small fraction of images annotated with high quality, along with a larger set of noisy or “coarse”-quality annotations.']"
"Other instance segmentation datasets such as COCO (Lin et al., 2014) are constructed stage-wise by first creating a detection dataset which only indicates rectangular bounding boxes around each object which are subsequently refined into a precise instance segmentations.",3.1. Performance Metric Estimators,[0],[0]
"Fig. 3 shows an example of a partially vetted image in which some instances are only indicated by a bounding box (noisy), while others have a detailed mask (vetted).
",3.1. Performance Metric Estimators,[0],[0]
"When computing Average Precision, a predicted instance segmentation is considered a true positive if it has sufficient intersection-over-union (IoU) overlap with a ground-truth instance.",3.1. Performance Metric Estimators,[1.0],"['When computing Average Precision, a predicted instance segmentation is considered a true positive if it has sufficient intersection-over-union (IoU) overlap with a ground-truth instance.']"
"In this setting, we let the variable zi indicate that predicted instance i is matched to a ground-truth instance and has an above threshold overlap.",3.1. Performance Metric Estimators,[0],[0]
"Assuming independence of zi’s, the expected AP can be written as (see supplement for proof):
E[AP ] = 1
Np (∑ k∈V z̃kE[Prec@k]
+ ∑ k∈U p(zk = 1|O)E[Prec@k] )
(9)
",3.1. Performance Metric Estimators,[0],[0]
"In practice, standard instance segmentation benchmarks are somewhat more complicated.",3.1. Performance Metric Estimators,[0],[0]
"In particular, they enforce one-to-one matching between detections and ground-truth.",3.1. Performance Metric Estimators,[0],[0]
"For example, if two detections overlap a ground-truth instance, only one is counted as a true positive while the other
is scored as a false positive.",3.1. Performance Metric Estimators,[0],[0]
"This also holds for multi-class detections - if a detection is labeled as a dog (by matching to a ground-truth dog), it can no longer be labeled as cat.",3.1. Performance Metric Estimators,[0],[0]
"While this interdependence can in principle be modeled by the conditioning variables O which could include information about which class detections overlap, in practice our estimators for p(zi = 1|O) do not take this into account.",3.1. Performance Metric Estimators,[0],[0]
"Nevertheless, we show that such estimators provide remarkably good estimates of performance.
",3.1. Performance Metric Estimators,[1.0000000769206399],"['Nevertheless, we show that such estimators provide remarkably good estimates of performance.']"
Fitting estimators to partially vetted data: We alternate between vetting small batches of data and refitting the estimator to the vetted set.,3.1. Performance Metric Estimators,[0],[0]
"For multi-label tagging, we update estimates for the prior probability that a noisy tag for a particular category will be flipped when vetted p(z̃i 6= yi).",3.1. Performance Metric Estimators,[0],[0]
"For instance segmentation, we train a per-category classifier that uses sizes of the predicted and unvetted ground-truth bounding box to predict whether a detected instance will overlap the ground-truth.",3.1. Performance Metric Estimators,[0],[0]
We discuss the specifics of fitting these particular estimators in the experimental results.,3.1. Performance Metric Estimators,[0],[0]
The second component of the active testing system is a strategy for choosing the “next” data samples to vet.,3.2. Vetting Strategies,[0],[0]
The goal of such a strategy is to produce accurate estimates of benchmark performance with fewest number of vettings.,3.2. Vetting Strategies,[0],[0]
"An alternate, but closely related goal, is to determine the benchmark rankings of a set of recognition systems being compared.",3.2. Vetting Strategies,[0],[0]
"The success of a given strategy depends on the distribution of the data, the chosen estimator, and the system(s) under test.",3.2. Vetting Strategies,[0],[0]
"We consider several selection strategies, motivated by existing data collection practice and modeled after active learning, which adapt to these statistics in order to improve efficiency.
",3.2. Vetting Strategies,[0],[0]
Random Sampling:,3.2. Vetting Strategies,[0],[0]
The simplest vetting strategy is to choose test examples to vet at random.,3.2. Vetting Strategies,[0],[0]
The distribution of examples across categories often follows a long-tail distribution.,3.2. Vetting Strategies,[0],[0]
"To achieve faster uniform convergence of performance
estimates across all categories, we use a hierarchical sampling approach in which we first sample a category and then select a sub-batch of test examples to vet from that category.",3.2. Vetting Strategies,[0],[0]
"This mirrors the way, e.g. image classification and detection datasets are manually curated to assure a minimum number of examples per category.
",3.2. Vetting Strategies,[0],[0]
Most-Confident Mistake (MCM):,3.2. Vetting Strategies,[0],[0]
"This strategy selects unvetted examples for which the system under test reports a high-confidence detection/classification score, but which are considered a mistake according to the current metric estimator.",3.2. Vetting Strategies,[0],[0]
"Specifically, we focus on the strategy of selecting Most-confident Negative which is applicable to image/video tagging where the set of user-provided tags are often incomplete.",3.2. Vetting Strategies,[0],[0]
"The intuition is that, if a high-performance system believes that the current sample is a positive with high probability, it’s likely that the noisy label is at fault.",3.2. Vetting Strategies,[0],[0]
"This strategy is motivated by experience with object detection benchmarks where, e.g., visualizing high-confident false positive face detections often reveals missing annotations in the test set (Mathias et al., 2014).
",3.2. Vetting Strategies,[0],[0]
Maximum Expected Estimator Change (MEEC):,3.2. Vetting Strategies,[0],[0]
"In addition to utilizing the confidence scores produced by the system under test, it is natural to also consider the uncertainty in the learned estimator pest(z).",3.2. Vetting Strategies,[0],[0]
"Exploiting the analogy of active testing with active learning, it is natural to vet samples that are most confusing to the current estimator (e.g., with largest entropy), or ones that will likely generate a large update to the estimator (e.g., largest information gain).
",3.2. Vetting Strategies,[0],[0]
"Specifically, we explore a active selection strategy based on maximum expected model change (Settles, 2010), which in our case corresponds to selecting a sample that yields the largest expected change in our estimate of Q. Let Ep(z|V )",3.2. Vetting Strategies,[0],[0]
[Q(z)] be the expected performance based on the distribution p(z|V ) estimated from the current vetted set V .,3.2. Vetting Strategies,[0],[0]
"Ep(z|V,zi)[Q(z)] be the expected performance after vetting example i and updating the estimator based on the outcome.",3.2. Vetting Strategies,[0],[0]
"The actual change in the estimate of Q depends on the
realization of the random variable zi:
∆i(zi) =",3.2. Vetting Strategies,[0],[0]
"∣∣∣Ep(z|V,zi)[Q(z)]− Ep(z|V )",3.2. Vetting Strategies,[0],[0]
"[Q(z)]∣∣∣ (10)
We can choose the example i with the largest expected change, using the current estimate of the distribution over zi ∼ p(zi|V ) to compute the expected change Ep(zi|V )",3.2. Vetting Strategies,[0],[0]
"[∆i(zi)].
",3.2. Vetting Strategies,[0],[0]
"For Prec@K, this expected change is given by:
Ep(zi|V )",3.2. Vetting Strategies,[0],[0]
[∆i(zi)],3.2. Vetting Strategies,[0],[0]
"= 2
K pi(1− pi) (11)
where we write pi = p(zi = 1|O).",3.2. Vetting Strategies,[0],[0]
"Interestingly, selecting the sample yielded the maximum expected change in the estimator corresponds to a standard maximum entropy selection criteria for active learning.",3.2. Vetting Strategies,[0],[0]
"Similarly, in the supplement we show that for AP :
Ep(zi|V )",3.2. Vetting Strategies,[0],[0]
"[∆i(zi)] = 1
Np ripi(1− pi) (12)
where ri is the proportion of unvetted examples scoring higher than example i.",3.2. Vetting Strategies,[0],[0]
"In this case, we select an example to vet which has high-entropy and for which there is a relatively small proportion of higher-scoring unvetted examples.",3.2. Vetting Strategies,[0],[0]
"We validate our active testing framework on two specific applications, multi-label classification and instance segmentation.",4. Experiments,[0],[0]
"For each of these applications, we describe the datasets and systems evaluated and the specifics of the estimators and vetting strategies used.",4. Experiments,[0],[0]
NUS-WIDE:,4.1. Active Testing for Multi-label Classification,[0],[0]
"This dataset contains 269,648 Flickr images with 5018 unique tags.",4.1. Active Testing for Multi-label Classification,[0],[0]
"The authors also provide a ’semi-
complete’ ground-truth via manual annotations for 81 concepts.",4.1. Active Testing for Multi-label Classification,[0],[0]
We removed images that are no longer available and images that doesn’t contain one of the 81 tags.,4.1. Active Testing for Multi-label Classification,[0],[0]
We are left with around 100K images spanning across 81 concepts.,4.1. Active Testing for Multi-label Classification,[0],[0]
"(Izadinia et al., 2015) analyzed the noisy and missing label statistics for this dataset.",4.1. Active Testing for Multi-label Classification,[0],[0]
"Given that the tag is relevant to the image, there is only 38% chance that it will appear in the noisy tag list.",4.1. Active Testing for Multi-label Classification,[0],[0]
"If the tag does not apply, there’s 1% chance that it appears anyway.",4.1. Active Testing for Multi-label Classification,[0],[0]
"They posited that the missing tags are either non-entry level categories (e.g., person) or they are not important in the scene (e.g., clouds and buildings).
",4.1. Active Testing for Multi-label Classification,[0],[0]
"Micro-videos: Micro-videos have recently become a prevalent form of media on many social platforms, such as Vine, Instagram, and Snapchat.",4.1. Active Testing for Multi-label Classification,[0],[0]
"(Nguyen et al., 2016) formulated a multi-label video-retrieval/annotation task for a large collection of Vine videos.",4.1. Active Testing for Multi-label Classification,[0],[0]
"They introduce a micro-video dataset, MV-85k containing 260K videos with 58K tags.",4.1. Active Testing for Multi-label Classification,[0],[0]
"This dataset, however, only provides exhaustive vetting for a small subset of tags on a small subset of videos.",4.1. Active Testing for Multi-label Classification,[0],[0]
"We vetted 26K video-tag pairs from this dataset, spanning 17503 videos and 875 tags.",4.1. Active Testing for Multi-label Classification,[0],[0]
"Since tags provided by users have little constraints, this dataset suffers from both under-tagging and over-tagging.",4.1. Active Testing for Multi-label Classification,[0],[0]
"Under-tagging comes from not-yet popular concepts, while over-tagging comes from the spamming of extra tags In our experiments we use a subset of 75 tags.
",4.1. Active Testing for Multi-label Classification,[0],[0]
"Recognition systems: To obtain the classification results, we implement two multi-label classification algorithms for images (NUSWIDE) and videos (Microvideos).",4.1. Active Testing for Multi-label Classification,[0],[0]
"For NUSWIDE, we trained a multi-label logistic regression model built on the pretrained ResNet-50",4.1. Active Testing for Multi-label Classification,[0],[0]
"(He et al., 2016) features.",4.1. Active Testing for Multi-label Classification,[0],[0]
"For Micro-videos, we follow the state-of-the-art video action recognition framework (Wang et al., 2016) modified for the multi-label setting to use multiple logistic cross-entropy losses.
",4.1. Active Testing for Multi-label Classification,[0],[0]
Learned Estimators: We use Precision@48 as a evaluation metric.,4.1. Active Testing for Multi-label Classification,[0],[0]
"For tagging, we estimate the posterior over unvetted tags, p(zi|O), based on two pieces of observed information: the statistics of noisy labels yi on vetted examples, and the system confidence score, si.",4.1. Active Testing for Multi-label Classification,[0],[0]
"This posterior probability can be derived as (see supplement for proof):
p(zi|si, yi) = p(yi|zi)p(zi|si)∑
v∈{0,1} p(yi|zi = v)p(zi = v|si) (13)
",4.1. Active Testing for Multi-label Classification,[0],[0]
"Given some vetted data, we fit the tag-flipping priors p(yi|zi) by standard maximum likelihood estimation (counting frequencies).",4.1. Active Testing for Multi-label Classification,[0],[0]
"The posterior probabilities of the true label given the classifier confidence score, p(zi|si), is fit using logistic regression.",4.1. Active Testing for Multi-label Classification,[0],[0]
COCO Minival:,4.2. Object Instance Detection and Segmentation,[0],[0]
"For instance segmentation, we use ‘minival2014’ subset of the COCO dataset (Lin et al., 2014).",4.2. Object Instance Detection and Segmentation,[0],[0]
This subset contains 5k images spanning over 80 categories.,4.2. Object Instance Detection and Segmentation,[0],[0]
"We report the standard COCO metric: Average Precision (averaged over all IoU thresholds).
",4.2. Object Instance Detection and Segmentation,[0],[0]
"To systematically analyze the impact of evaluation on noise and vetting, we focus evaluation efforts on the high quality test set, but simulate noisy annotations by replacing actual instance segmentation masks by their tight-fitting bounding box (the unvetted “noisy” set).",4.2. Object Instance Detection and Segmentation,[0],[0]
"We then simulate active testing where certain instances are vetted, meaning the bounding-box is replaced by the true segmentation mask.
",4.2. Object Instance Detection and Segmentation,[0],[0]
"Detection Systems: We did not implement instance segmentation algorithms ourselves, but instead utilized three sets of detection mask results produced by the authors of Mask R-CNN (He et al., 2017).",4.2. Object Instance Detection and Segmentation,[0],[0]
"These were produced by variants of the instance segmentation systems proposed in (Xie et al., 2017; Lin et al., 2017; He et al., 2017).
",4.2. Object Instance Detection and Segmentation,[0],[0]
"Learned Estimators: To compute the probability whether a detection will pass the IoU threshold with a bounding box unvetted ground-truth instance (p(zi|O) in Eq. 9), we train a χ2-SVM using the vetted portion of the database.",4.2. Object Instance Detection and Segmentation,[0],[0]
"The features for an example includes the category id, the ‘noisy’ IoU estimate, the size of the bounding box containing the detection mask and the size of ground-truth bounding box.",4.2. Object Instance Detection and Segmentation,[0],[0]
"The training label is true whether the true IoU estimate, computed using the vetted ground-truth mask and the detection masks, is above a certain input IoU threshold.",4.2. Object Instance Detection and Segmentation,[0],[0]
We measure the estimation accuracy of different combination of vetting strategies and estimators at different amount of vetting efforts.,4.3. Efficiency of active testing estimates,[0],[0]
We compute the absolute error between the estimated metric and the true (fully vetted) metric and average over all classes.,4.3. Efficiency of active testing estimates,[0],[0]
"Averaging the absolute estimation error across classes prevents over-estimation for one class
canceling out under-estimation from another class.",4.3. Efficiency of active testing estimates,[0],[0]
"We plot the mean and the standard deviation over 50 simulation runs of each active testing approach.
",4.3. Efficiency of active testing estimates,[1.0000000406138982],['We plot the mean and the standard deviation over 50 simulation runs of each active testing approach.']
Performance estimation: Figure 5 shows the results for estimating Prec@48 for NUSWIDE and Microvideos.,4.3. Efficiency of active testing estimates,[0],[0]
The x-axis indicates the percentage of the top-k lists that are vetted.,4.3. Efficiency of active testing estimates,[0],[0]
"For the Prec@K metric, it is only necessary to vet 100% of the top-k lists rather than 100% of the whole test set2.",4.3. Efficiency of active testing estimates,[0],[0]
"A ’random’ strategy with a ‘naive’ estimator follows a
2The “vetted only” estimator is not applicable in this domain until at least K examples in each short list have been vetted and hence doesn’t appear in the plots.
linear trend since each batch of vetted examples contributes on average the same reduction in estimation error.",4.3. Efficiency of active testing estimates,[0],[0]
The most confident mistake (mcm) heuristic works very well for Microvideos due to the substantial amount of undertagging.,4.3. Efficiency of active testing estimates,[0],[0]
"However, in more reasonable balanced settings such as NUS-WIDE, this heuristic does not perform as well.",4.3. Efficiency of active testing estimates,[0],[0]
The MCM vetting strategy does not pair well with a learned estimator due to its biased sampling which quickly results in priors that overestimate the number missing tags.,4.3. Efficiency of active testing estimates,[0],[0]
"In contrast, the random and active MEEC vetting strategies offer good samples for learning a good estimator.",4.3. Efficiency of active testing estimates,[0],[0]
"At 50% vetting effort, MEEC sampling with a learned estimator on average can achieve within 2-3% of the real estimates.
",4.3. Efficiency of active testing estimates,[0],[0]
Figure 6 highlights the relative value of establishing the true vetted label versus the value of vetted data in updating the estimator.,4.3. Efficiency of active testing estimates,[0],[0]
"In some sense, traditional active learning is concerned primarily with the vertical drop (i.e. a better model/estimator), while active testing also takes direct advantage of the slope (i.e. more vetted labels).",4.3. Efficiency of active testing estimates,[0],[0]
"The initial learned estimates have larger error due to small sample size, but the fitting during the first few vetting batches rapidly improves the estimator quality.",4.3. Efficiency of active testing estimates,[0],[0]
"Past 40% vetting effort, the estimator model parameters stabilize and remaining vetting serves to correct labels whose true value can’t be predicted given the low-complexity of the estimator.
",4.3. Efficiency of active testing estimates,[0],[0]
Figure 7 shows similar results for estimating the mAP for instance segmentation on COCO.,4.3. Efficiency of active testing estimates,[0],[0]
The current ‘gold standard’ approach of estimating performance based only on the vetted subset of images leads to large errors in estimation accuracy and high variance from from small sample sizes.,4.3. Efficiency of active testing estimates,[0],[0]
"In the active testing framework, input algorithms are tested using the whole dataset (vetted and unvetted).",4.3. Efficiency of active testing estimates,[0],[0]
"Naive estimation is noticeably more accurate than vetted only and the learned estimator with uncertainty sampling further reduces
both the absolute error and the variance.
",4.3. Efficiency of active testing estimates,[0],[0]
Model ranking: The benefits of active testing are highlighted further when we consider the problem of ranking system performance.,4.3. Efficiency of active testing estimates,[0],[0]
"We are often interested not in the absolute performance number, but rather in the performance gap between different systems.",4.3. Efficiency of active testing estimates,[0],[0]
We find that active testing is also valuable in this setting.,4.3. Efficiency of active testing estimates,[0],[0]
Figure 8 shows the error in estimating the performance gap between two different instance segmentation systems as a function of the amount data vetted.,4.3. Efficiency of active testing estimates,[0],[0]
This follows a similar trend as the single model performance estimation plot.,4.3. Efficiency of active testing estimates,[1.0],['This follows a similar trend as the single model performance estimation plot.']
"Importantly, it highlights that only evaluating vetted data, though unbiased, typically produces a large error in in performance gap between models to high variance in the estimate of each individual models performance.",4.3. Efficiency of active testing estimates,[0],[0]
"In particular, if we use these estimates to rank two models, we will often make errors in model ranking even when relatively large amounts of the data have been vetted.",4.3. Efficiency of active testing estimates,[0],[0]
"Using stronger estimators, actively guided by MEEC sampling provide accurate rankings with substantially less vetting effort.",4.3. Efficiency of active testing estimates,[0],[0]
"With 50% of the data vetted, standard approaches that evaluate on only vetted data (black curve) incorrectly rank algorithms 15% of the time, while our learned estimators with active vetting (red curve) reduce this error to 3% of the time.
",4.3. Efficiency of active testing estimates,[1.00000001455884],"['With 50% of the data vetted, standard approaches that evaluate on only vetted data (black curve) incorrectly rank algorithms 15% of the time, while our learned estimators with active vetting (red curve) reduce this error to 3% of the time.']"
Conclusions We have introduced a general framework for active testing that minimizes human vetting effort by actively selecting test examples to label and using performance estimators that adapt to the statistics of the test data and the systems under test.,4.3. Efficiency of active testing estimates,[1.0],['Conclusions We have introduced a general framework for active testing that minimizes human vetting effort by actively selecting test examples to label and using performance estimators that adapt to the statistics of the test data and the systems under test.']
Simple implementations of this concept demonstrate the potential for radically decreasing the human labeling effort needed to evaluate system performance for standard computer vision tasks.,4.3. Efficiency of active testing estimates,[1.0],['Simple implementations of this concept demonstrate the potential for radically decreasing the human labeling effort needed to evaluate system performance for standard computer vision tasks.']
"We anticipate this will have substantial practical value in the ongoing construction of such benchmarks.
",4.3. Efficiency of active testing estimates,[0.9999999433205711],['We anticipate this will have substantial practical value in the ongoing construction of such benchmarks.']
Acknowledgement We thank Piotr Dollar and Ross Girshick for providing the instance segmentation results for the COCO dataset.,4.3. Efficiency of active testing estimates,[0],[0]
This project was supported in part by NSF grants IIS-1618806 and IIS-1253538.,4.3. Efficiency of active testing estimates,[0],[0]
"Much recent work on visual recognition aims to scale up learning to massive, noisily-annotated datasets.",abstractText,[0],[0]
We address the problem of scalingup the evaluation of such models to large-scale datasets with noisy labels.,abstractText,[0],[0]
"Current protocols for doing so require a human user to either vet (reannotate) a small fraction of the test set and ignore the rest, or else correct errors in annotation as they are found through manual inspection of results.",abstractText,[0],[0]
"In this work, we re-formulate the problem as one of active testing, and examine strategies for efficiently querying a user so as to obtain an accurate performance estimate with minimal vetting.",abstractText,[0],[0]
"We demonstrate the effectiveness of our proposed active testing framework on estimating two performance metrics, Precision@K and mean Average Precision, for two popular computer vision tasks, multi-label classification and instance segmentation.",abstractText,[0],[0]
We further show that our approach is able to save significant human annotation effort and is more robust than alternative evaluation protocols.,abstractText,[0],[0]
Active Testing: An Efficient and Robust Framework for Estimating Accuracy,title,[0],[0]

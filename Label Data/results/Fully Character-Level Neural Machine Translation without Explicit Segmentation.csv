0,1,label2,summary_sentences
"Recently, deep learning has emerged as a powerful and popular class of machine learning algorithms.",1. Introduction,[0],[0]
"Well-known examples include the convolutional neural network (LeCun et al., 1998), long short term memory (Hochreiter & Schmidhuber, 1997), memory network (Weston et al., 2014), and deep Q-network (Mnih et al., 2015).",1. Introduction,[0],[0]
"These models have achieved remarkable performance on various difficult tasks such as image classification (He et al., 2016), speech recognition (Graves et al., 2013), natural language understanding (Bahdanau et al., 2015; Sukhbaatar et al., 2015), and game playing (Silver et al., 2016).
",1. Introduction,[0],[0]
"Deep network is a highly nonlinear model with typically millions of parameters (Hinton et al., 2006).",1. Introduction,[0],[0]
"Thus, it is imperative to design scalable and effective solvers.",1. Introduction,[0],[0]
"How-
",1. Introduction,[0],[0]
"1Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong.",1. Introduction,[0],[0]
"Correspondence to: Shuai Zheng <szhengac@cse.ust.hk>, James T. Kwok <jamesk@cse.ust.hk>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
ever, training deep networks is difficult as the optimization can suffer from pathological curvature and get stuck in local minima (Martens, 2010).",1. Introduction,[0],[0]
"Moreover, every critical point that is not a global minimum is a saddle point (Kawaguchi, 2016), which can significantly slow down training.",1. Introduction,[0],[0]
Second-order information is useful in that it reflects local curvature of the error surface.,1. Introduction,[0],[0]
"However, a direct computation of the Hessian is computationally infeasible.",1. Introduction,[0],[0]
"Martens (2010) introduced Hessian-free optimization, a variant of truncated-Newton methods that relies on using the linear conjugate gradient to avoid computing the Hessian.",1. Introduction,[0],[0]
Dauphin et al. (2014) proposed to use the absolute Hessian to escape from saddle points.,1. Introduction,[0],[0]
"However, these methods still require higher computational costs.
",1. Introduction,[0],[0]
"Recent advances in deep learning optimization focus mainly on stochastic gradient descent (SGD) (Bottou, 1998) and its variants (Sutskever et al., 2013).",1. Introduction,[0],[0]
"However, SGD requires careful stepsize tuning, which is difficult as different weights have vastly different gradients (in terms of both magnitude and direction).",1. Introduction,[0],[0]
"On the other hand, online learning (Zinkevich, 2003), which is closely related to stochastic optimization, has been extensively studied in the past decade.",1. Introduction,[0],[0]
"Well-known algorithms include follow the regularized leader (FTRL) (Kalai & Vempala, 2005), follow the proximally-regularized leader (FTPRL) (McMahan & Streeter, 2010) and their variants (Duchi & Singer, 2009; Duchi et al., 2011; Shalev-Shwartz, 2012; Xiao, 2010).",1. Introduction,[0],[0]
"In particular, adaptive gradient descent (Adagrad) (Duchi et al., 2011) uses an adaptive per-coordinate stepsize.",1. Introduction,[0],[0]
"On convex problems, it has been shown both theoretically and empirically that Adagrad is especially efficient on highdimensional data (Duchi et al., 2011; McMahan et al., 2013).",1. Introduction,[0],[0]
"When used on deep networks, Adagrad also demonstrates significantly better performance than SGD (Dean et al., 2012).",1. Introduction,[0],[0]
"However, in Adagrad, the variance estimate underlying the adaptive stepsize is based on accumulating all past (squared) gradients.",1. Introduction,[0],[0]
This becomes infinitesimally small as training proceeds.,1. Introduction,[0],[0]
"In more recent algorithms, such as RMSprop (Tieleman & Hinton, 2012) and Adam (Kingma & Ba, 2015), the variance is estimated by an exponentially decaying average of the squared gradients.
",1. Introduction,[0],[0]
"Another problem with the FTRL family of algorithms is that in each round, the learner has to solve an optimization problem that considers the sum of all previous gradients.
",1. Introduction,[0],[0]
"For highly nonconvex models such as the deep network, the parameter iterate may move from one local basin to another.",1. Introduction,[0],[0]
Gradients that are due to samples in the distant past are less informative than those from the recent ones.,1. Introduction,[0],[0]
"In applications where the data distribution is changing (as in deep reinforcement learning), this may impede parameter adaptation to the environment.
",1. Introduction,[0],[0]
"To alleviate this problem, we propose a FTPRL variant that reweighs the learning subproblems in each iteration.",1. Introduction,[0],[0]
"The proposed algorithm, which will be called follow the moving leader (FTML), shows strong connections with popular deep learning optimizers such as RMSprop and Adam.",1. Introduction,[0],[0]
"Experiments on various deep learning models demonstrate that FTML outperforms or at least has comparable convergence performance with state-of-the-art solvers.
",1. Introduction,[0],[0]
The rest of this paper is organized as follows.,1. Introduction,[0],[0]
Section 2 first gives a brief review on FTRL and other solvers for deep learning.,1. Introduction,[0],[0]
Section 3 presents the proposed FTML.,1. Introduction,[0],[0]
"Experimental results are shown in Section 4, and the last section gives some concluding remarks.
Notation.",1. Introduction,[0],[0]
"For a vector x ∈ Rd, ‖x‖ = √∑d
i=1",1. Introduction,[0],[0]
"x 2 i ,
diag(x) is a diagonal matrix with x on its diagonal, √ x is the element-wise square root of x, x2 denotes the Hadamard (elementwise) product x x, and ‖x‖2Q = xTQx, whereQ is a symmetric matrix.",1. Introduction,[0],[0]
"For any two vectors x and y, x/y, and 〈x, y〉 denote the elementwise division and dot product, respectively.",1. Introduction,[0],[0]
"For a matrix X , X2 = XX , and diag(X) is a vector with the diagonal of X as its elements.",1. Introduction,[0],[0]
"For t vectors {x1, . . .",1. Introduction,[0],[0]
", xt}, x1:",1. Introduction,[0],[0]
t = ∑t i=1,1. Introduction,[0],[0]
"xi, and
x21:",1. Introduction,[0],[0]
t = ∑t i=1,1. Introduction,[0],[0]
"x
2 i .",1. Introduction,[0],[0]
"For t matrices {X1, . . .",1. Introduction,[0],[0]
", Xt}, X1:t =∑t
i=1Xi.",1. Introduction,[0],[0]
"In online learning, the learner observes a sequence of functions fi’s, which can be deterministic, stochastic, or even adversarially chosen.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
Let Θ ⊆ Rd be a convex compact set.,2.1. Follow the Regularized Leader and its Variants,[0],[0]
"At round t, the learner picks a predictor θt−1 ∈ Θ, and the adversary picks a loss ft.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
The learner then suffers a loss ft(θt−1).,2.1. Follow the Regularized Leader and its Variants,[0],[0]
The goal of the learner is to minimize the cumulative loss suffered over the course of T rounds.,2.1. Follow the Regularized Leader and its Variants,[0],[0]
"In online convex learning, ft is assumed to be convex.
",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"Two popular online learning algorithms are the follow the regularized leader (FTRL) (Kalai & Vempala, 2005; Shalev-Shwartz, 2012), and its variant follow the proximally-regularized leader (FTPRL) (McMahan & Streeter, 2010).",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"Both achieve the optimal O( √ T ) regret, where T is the number of rounds (Shalev-Shwartz, 2012).",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"Other FTRL-like algorithms include regularized dual aver-
aging (RDA) (Xiao, 2010) as well as its adaptive variant presented in (Duchi et al., 2011).",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"Gradient descent style algorithms like online forward and backward splitting (FOBOS) (Duchi & Singer, 2009) and adaptive gradient descent (Adagrad) (Duchi et al., 2011) can also be expressed as special cases of the FTRL family (McMahan, 2011).
",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"At round t, FTRL generates the next iterate θt by solving the optimization problem:
θt = arg min θ∈Θ t∑ i=1",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"( 〈gi, θ〉+ αt 2 ‖θ‖2 ) ,
where gt is a subgradient of ft at θt−1 (usually, θ0 = 0), and αt is the regularization parameter at round t. Note that the regularization is centered at the origin.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"McMahan & Streeter (2010) generalizes this to FTPRL by centering regularization at each iterate θi−1 as in online gradient descent and online mirror descent (Cesa-Bianchi & Lugosi, 2006),
θt = arg min θ∈Θ t∑ i=1",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"( 〈gi, θ〉+ 1 2 ‖θ − θi−1‖2Qi ) , (1)
where Qi is a full or diagonal positive semidefinite matrix, and ‖θ",2.1. Follow the Regularized Leader and its Variants,[0],[0]
− θi−1‖Qi is the corresponding Mahalanobis distance between θ and θi−1.,2.1. Follow the Regularized Leader and its Variants,[0],[0]
"When Qi is diagonal, each of its entries controls the learning rate in the corresponding dimension.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"When Θ = Rd, θt can be obtained in closedform (McMahan, 2011):
θt = θt−1 −Q−11:t gt.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"(2)
",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"When
Qt = 1
η diag
(√ g21:t − √ g21:t−1 ) , (3)
where η > 0 is the stepsize, (2) becomes the update rule of Adagrad (Duchi et al., 2011)
θt = θt−1 − diag
( η√
g21:t + 1
) gt.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"(4)
Here, > 0 (usually a very small number) is used to avoid division by zero, and 1 is the vector of all 1’s.
",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"In general, all these algorithms satisfy (McMahan & Streeter, 2010):
Q1:t = diag ( 1
η
(√ g21:t + 1 )) .",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"(5)
It can be shown that this setting is optimal within a factor of √ 2 of the best possible regret bound for any nonincreasing per-coordinate learning rate schedule (McMahan & Streeter, 2010).",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"In training deep networks, different weights may have vastly different gradients (in terms of both magnitude and direction).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Hence, using a per-coordinate learning rate as in Adagrad can significantly improve performance over standard SGD (Dean et al., 2012).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"However, a caveat is that Adagrad suffers from diminishing stepsize.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"As optimization proceeds, the accumulated squared gradient g21:t in (5) becomes larger and larger, making training difficult.
",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"To alleviate this problem, a number of algorithms have been proposed (Zeiler, 2012; Tieleman & Hinton, 2012; Kingma & Ba, 2015).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Typically, they employ an average of the past squared gradients (i.e., vt = ∑t i=1",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"αi,tg 2",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"i , where αi,t ∈",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"[0, 1]), which is exponentially decaying.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"For example, RMSprop (Tieleman & Hinton, 2012) uses
vi = βvi−1 + (1− β)g2i , (6)
where β is close to 1, and the corresponding αi,t is (1 − β)βt−i.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"This vt can then be used to replace g21:t, and the update in (4) becomes
θt = θt−1 − diag (
η √ vt + 1
) gt.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"(7)
Zeiler (2012) further argues that the parameter and update should have the same unit, and modifies (7) to the Adadelta update rule:
θt = θt−1 − diag (√
ut−1 + 1√ vt + 1
) gt,
where ut−1 = ∑t−1 i=0 αi,t−1(4θi)2, and 4θt = θt − θt−1 with4θ0 = 0.
",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"As v0 in (6) is often initialized to 0, the bias has to be corrected.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Adam (Kingma & Ba, 2015) uses the variance estimate vt/(1 − βt) (which corresponds to αi,t = (1− β)βt−i/(1− βt)).
",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Another recent proposal is the equilibrated stochastic gradient descent (Dauphin et al., 2015).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"It uses the variance estimate vt = vt−1 +(Htζt)2, whereHt is the Hessian and ζt ∼ N (0, 1).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"It is shown that (Htζt)2 is an unbiased estimator of √ diag(H2t ), which serves as the Jacobi preconditioner of the absolute Hessian.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Computation of the Hessian can be avoided by using the R-operator (Schraudolph, 2002), though it still costs roughly twice that of standard backpropagation.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Recall that at round t, FTRL generates the next iterate θt as
θt = arg min θ∈Θ t∑ i=1",3. Follow the Moving Leader,[0],[0]
"Pi(θ), (8)
where Pi(θ) = 〈gi, θ〉 + 12‖θ",3. Follow the Moving Leader,[0],[0]
− θi−1‖ 2 Qi .,3. Follow the Moving Leader,[0],[0]
Note that all Pi’s have the same weight.,3. Follow the Moving Leader,[0],[0]
"However, for highly nonconvex models such as the deep network, the parameter iterate may move from one local basin to another.",3. Follow the Moving Leader,[0],[0]
Pi’s that are due to samples in the distant past are less informative than those from the recent ones.,3. Follow the Moving Leader,[0],[0]
"To alleviate this problem, one may consider only Pi’s in a recent window.",3.1. Weighting the Components,[0],[0]
"However, a large memory is needed for its implementation.",3.1. Weighting the Components,[0],[0]
"A simpler alternative is by using an exponential moving average of the Pi’s: Si = β1Si−1 + (1 − β1)Pi, where β1 ∈",3.1. Weighting the Components,[0],[0]
"[0, 1) and S0 = 0.",3.1. Weighting the Components,[0],[0]
This can be easily rewritten as St = (1− β1) ∑t i=1,3.1. Weighting the Components,[0],[0]
β t−i 1 Pi.,3.1. Weighting the Components,[0],[0]
"Instead of minimizing (8), we have
θt = arg min θ∈Θ t∑ i=1",3.1. Weighting the Components,[0],[0]
"wi,tPi(θ), (9)
where the weights
wi,t = (1− β1)βt−i1
1− βt1 (10)
are normalized to sum to 1.",3.1. Weighting the Components,[0],[0]
The denominator 1− βt1 plays a similar role as bias correction in Adam.,3.1. Weighting the Components,[0],[0]
"When β1 = 0, wi,t = 0 for i < t, and wt,t = 1.",3.1. Weighting the Components,[0],[0]
"Thus, (9) reduces to minθ∈Θ Pt(θ).",3.1. Weighting the Components,[0],[0]
"When β1 → 1, the following Lemma shows that all Pi’s are weighted equally, and (8) is recovered.",3.1. Weighting the Components,[0],[0]
Lemma 1.,3.1. Weighting the Components,[0],[0]
"limβ1→1 wi,t = 1/t.
Note that the Hessian of the objective in (8) is Q1:t. This becomes ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi in (9).",3.1. Weighting the Components,[0],[0]
"Recall that Q1:t depends on the accumulated past gradients in (5), which is then refined by an exponential moving average in (6).",3.1. Weighting the Components,[0],[0]
"As in Adam, we define vi = β2vi−1 + (1 − β2)g2i , where β2 ∈",3.1. Weighting the Components,[0],[0]
"[0, 1) and v0 = 0, and then correct its bias by dividing by 1 − βt2.",3.1. Weighting the Components,[0],[0]
"Thus, (5) is changed to
t∑ i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi = diag ( 1 ηt (√ vt 1− βt2 + t1 )) , (11)
where ηt and t are the stepsize and value at time t, respectively.",3.1. Weighting the Components,[0],[0]
"When β2 = 0, (11) reduces to ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi =
diag (
1 ηt ( √ g2t + t1) ) .",3.1. Weighting the Components,[0],[0]
"When β2 → 1, all g2i ’s are
weighted equally and (11) reduces to ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi =
diag (
1 ηt (√ g21:",3.1. Weighting the Components,[0],[0]
t t + t1 )) .,3.1. Weighting the Components,[0],[0]
"Using ηt = η/ √ t and t =
/ √ t, this is further reduced to (5).",3.1. Weighting the Components,[0],[0]
"The following shows
that Qt in (11) has a closed-form expression.
",3.1. Weighting the Components,[0],[0]
Proposition 1.,3.1. Weighting the Components,[0],[0]
"Define dt = 1−βt1 ηt
(√ vt
1−βt2 + t1
) .",3.1. Weighting the Components,[0],[0]
"Then,
Qt = diag ( dt − β1dt−1
1− β1
) .",3.1. Weighting the Components,[0],[0]
"(12)
Algorithm 1 Follow the Moving Leader (FTML).",3.1. Weighting the Components,[0],[0]
"1: Input: ηt > 0, β1, β2 ∈",3.1. Weighting the Components,[0],[0]
"[0, 1), t > 0. 2: initialize θ0 ∈ Θ; d0 ← 0; v0 ← 0; z0 ← 0; 3: for t = 1, 2, . . .",3.1. Weighting the Components,[0],[0]
", T do 4: fetch function ft; 5: gt ← ∂θft(θt−1); 6: vt ← β2vt−1",3.1. Weighting the Components,[0],[0]
"+ (1− β2)g2t ;
7: dt ← 1−β t 1
ηt
(√ vt
1−βt2 + t1
) ;
8: σt ← dt − β1dt−1; 9: zt ← β1zt−1 + (1− β1)gt − σtθt−1;
10: θt ← Π diag(dt/(1−βt1))",3.1. Weighting the Components,[0],[0]
"Θ (−zt/dt); 11: end for 12: Output: θT .
",3.1. Weighting the Components,[0],[0]
"Substituting this back into (9), θt is then equal to
arg min θ∈Θ t∑ i=1",3.1. Weighting the Components,[0],[0]
"wi,t ( 〈gi, θ〉+ 1 2 ‖θ",3.1. Weighting the Components,[0],[0]
"− θi−1‖2diag ( σi 1−β1 )) , (13) where σi ≡",3.1. Weighting the Components,[0],[0]
di − β1di−1.,3.1. Weighting the Components,[0],[0]
"Note that some entries of σi may be negative, and ‖θ− θi−1‖2diag(σi/(1−β1)) is then not a regularizer in the usual sense.",3.1. Weighting the Components,[0],[0]
"Instead, the negative entries of σi encourage the corresponding entries of θ to move away from those of θi−1.",3.1. Weighting the Components,[0],[0]
"Nevertheless, from the definitions of dt, σt and (11), we have ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tdiag(σi/(1 − β1))",3.1. Weighting the Components,[0],[0]
"=∑t
i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi = diag(dt/(1−βt1)), and thus the following: Lemma 2. ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tdiag(σi/(1− β1)) 0.
",3.1. Weighting the Components,[0],[0]
"Hence, the objective in (13) is still strongly convex.",3.1. Weighting the Components,[0],[0]
"Moreover, the following Proposition shows that θt in (13) has a simple closed-form solution.
",3.1. Weighting the Components,[0],[0]
Proposition 2.,3.1. Weighting the Components,[0],[0]
"In (13),
θt = Π diag(dt/(1−βt1))",3.1. Weighting the Components,[0],[0]
"Θ (−zt/dt),
where zt = β1zt−1 + (1 − β1)gt − σtθt−1, and ΠAΘ(x) ≡ arg minu∈Θ 1 2‖u−x‖ 2",3.1. Weighting the Components,[0],[0]
"A is the projection onto Θ for a given positive semidefinite matrix A.
The proposed procedure, which will be called follow the moving leader (FTML), is shown in Algorithm 1.",3.1. Weighting the Components,[0],[0]
"Note that though {P1, . . .",3.1. Weighting the Components,[0],[0]
", Pt} are considered in each round, the update depends only the current gradient gt and parameter θt−1.",3.1. Weighting the Components,[0],[0]
"It can be easily seen that FTML is easy to implement, memory-efficient and has low per-iteration complexity.",3.1. Weighting the Components,[0],[0]
"The following Propositions show that we can recover Adagrad in two extreme cases: (i) β1 = 0 with decreasing stepsize; and (ii) β1 → 1 with increasing stepsize.
",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
Proposition 3.,3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"With β1 = 0, β2 → 1, ηt = η/ √ t, and
t = / √ t, θt in (13) reduces to:
Π diag(( √ g21:t+ 1)/η)
",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"Θ
( θt−1 − diag ( η√
g21:t + 1
) gt ) ,
which recovers Adagrad in (4).",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
Proposition 4.,3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"With β1 → 1, β2 → 1, ηt = η √ t, and
t = / √ t, we recover (1) with Qi in (3).",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"If Θ = Rd, it
generates identical updates as Adagrad in (4).",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"When Θ = Rd, McMahan (2011) showed that (1) and (2) generate the same updates.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
The following Theorem shows that FTML also has a similar gradient descent update.,3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
Theorem 1.,3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"With Θ = Rd, FTML generates the same updates as:
θt = θt−1 − diag ( 1− β1 1− βt1 ηt√ vt/(1− βt2) + t1 ) gt.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"(14)
When β1 = 0 and bias correction for the variance is not used, (14) reduces to RMSprop in (7).",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"However, recall from Section 3.1 that when β1 = 0, we have wi,t = 0 for i < t, and wt,t = 1.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"Hence, only the current loss component Pt is taken into account, and this may be sensitive to the noise in Pt.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"Moreover, as demonstrated in Adam, bias correction of the variance can be very important.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"When β2 → 1, the variance estimate of RMSprop,∑t i=1(1−β2)β t−i 2 g 2 i , becomes zero and blows up the stepsize, leading to divergence.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"In contrast, FTML’s Qi in (12) recovers that of Adagrad in this case (Proposition 4).",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"In practice, a smaller β2 has to be used for RMSprop.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"However, a larger β2 enables the algorithm to be more robust to the gradient noise in general.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"At iteration t, instead of centering regularization at each θi−1 in (13), consider centering all the proximal regularization terms at the last iterate θt−1. θt then becomes:
arg min θ∈Θ t∑ i=1",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"wi,t ( 〈gi, θ〉+ 1 2 ‖θ − θt−1‖2diag ( σi 1−β1 )) .",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"(15) Compared with (13), the regularization in (15) is more aggressive as it encourages θt to be close only to the last iterate θt−1.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
The following Proposition shows that (15) generates the same updates as Adam.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
Proposition 5.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"In (15),
θt = Π At Θ ( θt−1 −A−1t t∑ i=1",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"wi,tgi ) , (16)
where At = diag(( √ vt/(1− βt2) + t1)/ηt).
",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"As in Adam, ∑t i=1",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"wi,tgi in (16) can be obtained as mt/(1−βt1), wheremt is computed as an exponential moving average of gt’s: mt = β1mt−1 +",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"(1− β1)gt.
Note that the θt updates of Adagrad (4), RMSprop (7), and FTML (14) depend only on the current gradient gt.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"On the other hand, the Adam update in (16) involves ∑t i=1",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"wi,tgi, which contains all the past gradients (evaluated at past parameter estimates θi−1’s).",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"This is similar to the use of momentum, which is sometimes helpful in escaping from local minimum.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"However, when the data distribution is changing (as in deep reinforcement learning), the past gradients may not be very informative, and can even impede parameter adaptation to the environment.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"Recently, it is also reported that the use of momentum can make training unstable when the loss is nonstationary (Arjovsky et al., 2017).",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"Indeed, Theorem 4.1 in (Kingma & Ba, 2015) shows that Adam has low regret only when β1 is decreasing w.r.t.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
t.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"When β1 → 0, ∑t i=1 wi,tgi → gt and so only the current gradient is used.
",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
Remark 1.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
(Summary) RMSprop and Adam are improvements over Adagrad in training deep networks.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"However, RMSprop uses β1 = 0 (and thus relies only on the current sample), does not correct the bias of the variance estimate, but centers the regularization at the current iterates θi−1’s.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"On the other hand, Adam uses β1 > 0, bias-corrected variance, but centers all regularization terms at the last iterate θt−1.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
The proposed FTML combines the nice properties of the two.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"In this section, experiments are performed on a number of deep learning models, including convolutional neural networks (Section 4.1), deep residual networks (Section 4.2), memory networks (Section 4.3), neural conversational model (Section 4.4), deep Q-network (Section 4.5), and long short-term memory (LSTM) (Section 4.6).",4. Experiments,[0],[0]
"A summary of the empirical performance of the various deep learning optimizers is presented in Section 4.7.
",4. Experiments,[0],[0]
"The following state-of-the-art optimizers for deep learning models will be compared: (i) Adam (Kingma & Ba, 2015); (ii) RMSprop (Tieleman & Hinton, 2012); (iii) Adadelta (Zeiler, 2012); and (iv)",4. Experiments,[0],[0]
"Nesterov accelerated gradient (NAG) (Sutskever et al., 2013).",4. Experiments,[0],[0]
"For FTML, we set β1 = 0.6, β2 = 0.999, and a constant t = = 10−8 for all t. For FTML, Adam, RMSprop, and NAG, η is selected by monitoring performance on the training set (note that Adadelta does not need to set η).",4. Experiments,[0],[0]
"The learning rate is chosen from {0.5, 0.25, 0.1, . . .",4. Experiments,[0],[0]
", 0.00005, 0.000025, 0.00001}.",4. Experiments,[0],[0]
Significantly underperforming learning rates are removed after running the model for 5− 20 epochs.,4. Experiments,[0],[0]
We then pick the rate that leads to the smallest final training loss.,4. Experiments,[0],[0]
"In the section, we perform experiments with the convolutional neural network (CNN) (LeCun et al., 1998).",4.1. Convolutional Neural Networks,[0],[0]
We use the example models on the MNIST and CIFAR-10 data sets from the Keras library1.,4.1. Convolutional Neural Networks,[0],[0]
"For MNIST, the CNN has two alternating stages of 3 × 3 convolution filters (using ReLU activation), followed by a 2 × 2 max-pooling layer and a dropout layer (with a dropout rate of 0.25).",4.1. Convolutional Neural Networks,[0],[0]
"Finally, there is a fully-connected layer with ReLU activation and a dropout rate of 0.5.",4.1. Convolutional Neural Networks,[0],[0]
"For CIFAR-10, the CNN has four alternating stages of 3× 3 convolution filters (using ReLU activation).",4.1. Convolutional Neural Networks,[0],[0]
Every two convolutional layers is followed by a 2×2 maxpooling layer and a dropout layer (with a dropout rate of 0.25).,4.1. Convolutional Neural Networks,[0],[0]
The last stage has a fully-connected layer with ReLU activation and a dropout rate of 0.5.,4.1. Convolutional Neural Networks,[0],[0]
"Features in both data sets are normalized to [0, 1].",4.1. Convolutional Neural Networks,[0],[0]
"Minibatches of sizes 128 and 32 are used for MNIST and CIFAR-10, respectively.
",4.1. Convolutional Neural Networks,[0],[0]
"As the iteration complexities of the various algorithms are comparable and the total cost is dominated by backpropagation, we report convergence of the training cross entropy loss versus the number of epochs.",4.1. Convolutional Neural Networks,[0],[0]
"This setup is also used in (Zeiler, 2012; Kingma & Ba, 2015).
",4.1. Convolutional Neural Networks,[0],[0]
Figure 1 shows the convergence results.,4.1. Convolutional Neural Networks,[0],[0]
"As can be seen, FTML performs best on both data sets.",4.1. Convolutional Neural Networks,[0],[0]
"Adam has comparable performance with FTML on MNIST, but does not perform as well on CIFAR-10.",4.1. Convolutional Neural Networks,[0],[0]
The other methods are much inferior.,4.1. Convolutional Neural Networks,[0],[0]
"In particular, RMSprop is slow on both MNIST and CIFAR-10, and Adadelta tends to diverge on CIFAR-10.",4.1. Convolutional Neural Networks,[0],[0]
"Recently, substantially deeper networks have been popularly used, particularly in computer vision.",4.2. Deep Residual Networks,[0],[0]
"For example, a 152-layer deep residual network (He et al., 2016) achieves state-of-the-art performance on ImageNet classification, and won the first place on the ILSVRC 2015 classification task.
",4.2. Deep Residual Networks,[0],[0]
"In this section, we perform experiments with a 110-layer deep residual network on the CIFAR-10 and CIFAR-100 data sets.",4.2. Deep Residual Networks,[0],[0]
The code is based on its Torch implementation2.,4.2. Deep Residual Networks,[0],[0]
"We leave the architecture and related settings intact, and use the same learning rate schedule.",4.2. Deep Residual Networks,[0],[0]
The default optimizer in the Torch code is NAG.,4.2. Deep Residual Networks,[0],[0]
"Here, we also experiment with Adadelta, RMSprop, Adam and the proposed FTML.",4.2. Deep Residual Networks,[0],[0]
"A minibatch size of 32 is used.
",4.2. Deep Residual Networks,[0],[0]
Convergence of the training cross entropy loss is shown in Figure 2.,4.2. Deep Residual Networks,[0],[0]
"As can been seen, all optimizers, except Adadelta, are very competitive and have comparable per-
1https://github.com/fchollet/keras.",4.2. Deep Residual Networks,[0],[0]
"2https://github.com/facebook/fb.resnet.
torch.
",4.2. Deep Residual Networks,[0],[0]
formance on these two data sets.,4.2. Deep Residual Networks,[0],[0]
"NAG shows slower initial convergence, while FTML converges slightly faster than the others on the CIFAR-10 data set.",4.2. Deep Residual Networks,[0],[0]
"Recently, there has been a lot of attention on combining inference, attention and memory for various machine learning tasks.",4.3. Memory Networks,[0],[0]
"In particular, the memory network (Weston et al., 2014; Sukhbaatar et al., 2015) has been popularly used for natural language understanding.
",4.3. Memory Networks,[0],[0]
"In this section, we use the example model of the end-toend memory network (with LSTM) from the Keras library.",4.3. Memory Networks,[0],[0]
"We consider the question answering task (Sukhbaatar et al., 2015; Weston et al., 2016), and perform experiments on the “single supporting fact” task in the bAbI data set (Weston et al., 2016).",4.3. Memory Networks,[0],[0]
This task consists of questions in which a previously given single sentence provides the answer.,4.3. Memory Networks,[0],[0]
"An
example is shown below.",4.3. Memory Networks,[0],[0]
"We use a single supporting memory, and a minibatch size of 32.
",4.3. Memory Networks,[0],[0]
Single Supporting Fact:,4.3. Memory Networks,[0],[0]
Mary moved to the bathroom.,4.3. Memory Networks,[0],[0]
John went to the hallway.,4.3. Memory Networks,[0],[0]
Where is Mary?,4.3. Memory Networks,[0],[0]
"A: bathroom
Convergence of the training cross entropy loss is shown in Figure 3.",4.3. Memory Networks,[0],[0]
"As can be seen, FTML and RMSprop perform best on this data set.",4.3. Memory Networks,[0],[0]
"Adam is slower, while NAG and Adadelta perform poorly.",4.3. Memory Networks,[0],[0]
"The neural conversational model (Vinyals & Le, 2015) is a sequence-to-sequence model (Sutskever et al., 2014) that is capable of predicting the next sequence given the last or previous sequences in a conversation.",4.4. Neural Conversational Model,[0],[0]
"A LSTM layer en-
codes the input sentence to a thought vector, and a second LSTM layer decodes the thought vector to the response.",4.4. Neural Conversational Model,[0],[0]
"It has been shown that this model can often produce fluent and natural conversations.
",4.4. Neural Conversational Model,[0],[0]
"In this experiment, we use the publicly available Torch implementation3 with a constant stepsize, and its default data set Cornell Movie-Dialogs Corpus (with 50, 000 samples) (Danescu-Niculescu-Mizil & Lee, 2011).",4.4. Neural Conversational Model,[0],[0]
"The number of hidden units is set to 1000, and the minibatch size is 10.
",4.4. Neural Conversational Model,[0],[0]
Convergence of the training cross entropy loss is shown in Figure 4.,4.4. Neural Conversational Model,[0],[0]
"Adadelta is not reported here, since it performs poorly (as in previous experiments).",4.4. Neural Conversational Model,[0],[0]
"As can be seen, FTML outperforms Adam and RMSprop.",4.4. Neural Conversational Model,[0],[0]
"In particular, RMSprop is much inferior.",4.4. Neural Conversational Model,[0],[0]
"NAG is slower than FTML and Adam in the first 21 epochs, but becomes faster towards the end of training.",4.4. Neural Conversational Model,[0],[0]
"In this section, we use the Deep Q-network (DQN) (Mnih et al., 2015) for deep reinforcement learning.",4.5. Deep Q-Network,[0],[0]
Experiments are performed on two computer games on the Atari 2600 platform: Breakout and Asterix.,4.5. Deep Q-Network,[0],[0]
"We use the publicly available Torch implementation with the default network setup4, and a minibatch size of 32.",4.5. Deep Q-Network,[0],[0]
"We only compare FTML with RMSprop and Adam for optimization, as NAG and Adadelta are rarely used in training the DQN.",4.5. Deep Q-Network,[0],[0]
"As in (Mnih et al., 2015), we use = 10−2 for all methods, and performance evaluation is based on the average score per episode.",4.5. Deep Q-Network,[0],[0]
"The higher the score, the better the performance.
",4.5. Deep Q-Network,[0],[0]
Convergence is shown in Figure 5.,4.5. Deep Q-Network,[0],[0]
"On Breakout, RM-
3https://github.com/macournoyer/ neuralconvo.
",4.5. Deep Q-Network,[0],[0]
"4https://github.com/Kaixhin/Atari.
",4.5. Deep Q-Network,[0],[0]
Sprop and FTML are comparable and yield higher scores than Adam.,4.5. Deep Q-Network,[0],[0]
"On Asterix, FTML outperforms all the others.",4.5. Deep Q-Network,[0],[0]
"In particular, the DQN trained with RMSprop fails to learn the task, and its score begins to drop after about 100 epochs.",4.5. Deep Q-Network,[0],[0]
"A similar problem has also been observed in (Hasselt et al., 2016).",4.5. Deep Q-Network,[0],[0]
"Experience replay (Mnih et al., 2015) has been commonly used in deep reinforcement learning to smooth over changes in the data distribution, and avoid oscillations or divergence of the parameters.",4.5. Deep Q-Network,[0],[0]
"However, results here show that Adam still has inferior performance because of its use of all past gradients, many of these are not informative when the data distribution has changed.",4.5. Deep Q-Network,[0],[0]
"To illustrate the problem of Adam in Section 4.5 more clearly, we perform the following timeseries prediction experiment with the LSTM.",4.6. Long Short-Term Memory (LSTM),[0],[0]
We construct a synthetic timeseries of length 1000.,4.6. Long Short-Term Memory (LSTM),[0],[0]
"This is divided into 20 segments, each of length 50.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"At each time point, the sample is 10- dimensional.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"In segment i, samples are generated from a normal distribution with mean ([i, i, . . .",4.6. Long Short-Term Memory (LSTM),[0],[0]
", i] + ζi) ∈ R10 and identity covariance matrix, where the components of ζi are independent standard normal random variables.",4.6. Long Short-Term Memory (LSTM),[0],[0]
Noise from the standard normal distribution is added to corrupt the data.,4.6. Long Short-Term Memory (LSTM),[0],[0]
"The task is to predict the data sample at the next time point t.
We use a one-layer LSTM implemented in (Léonard et al., 2015).",4.6. Long Short-Term Memory (LSTM),[0],[0]
100 hidden units are used.,4.6. Long Short-Term Memory (LSTM),[0],[0]
"We truncate backpropagation through time (BPTT) to 5 timesteps, and input 5 samples to the LSTM in each iteration.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"Thus, the data distribution changes every 10 iterations, as a different normal distribution is then used for data generation.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"Performance evaluation is based on the squared loss ft(θt−1) at time t.
Convergence of the loss is shown in Figure 6(a).",4.6. Long Short-Term Memory (LSTM),[0],[0]
"As can be
seen, Adam has difficulty in adapting to the data.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"In contrast, FTML and RMSprop can adapt more quickly, yielding better and more stable performance.
",4.6. Long Short-Term Memory (LSTM),[0],[0]
"As a baseline, we consider the case where the data distribution does not change (the means of all the segments are fixed to the vector of ones)",4.6. Long Short-Term Memory (LSTM),[0],[0]
Figure 6(b) shows the results.,4.6. Long Short-Term Memory (LSTM),[0],[0]
"As can be seen, Adam now performs comparably to FTML and RMSprop.",4.6. Long Short-Term Memory (LSTM),[0],[0]
The main problem with RMSprop is that its performance is not stable.,4.7. Summary of Results,[0],[0]
"Sometimes, it performs well, but sometimes it can have significantly inferior performance (e.g., as can be seen from Figures 1, 4 and 5(b)).",4.7. Summary of Results,[0],[0]
"The performance of Adam is more stable, though it often lags behind the best optimizer (e.g., Figures 1(b), 3, and 4).",4.7. Summary of Results,[0],[0]
"It is particularly problematic when learning in a changing environment (Fig-
ures 5 and 6(a)).",4.7. Summary of Results,[0],[0]
"In contrast, the proposed FTML shows stable performance on various models and tasks.",4.7. Summary of Results,[0],[0]
"It converges quickly, and is always the best (or at least among the best) in all our experiments.",4.7. Summary of Results,[0],[0]
"In this paper, we proposed a FTPRL variant called FTML, in which the recent samples are weighted more heavily in each iteration.",5. Conclusion,[0],[0]
"Hence, it is able to adapt more quickly when the parameter moves to another local basin, or when the data distribution changes.",5. Conclusion,[0],[0]
FTML is closely related to RMSprop and Adam.,5. Conclusion,[0],[0]
"In particular, it enjoys their nice properties, but avoids their pitfalls.",5. Conclusion,[0],[0]
"Experimental results on a number of deep learning models and tasks demonstrate that FTML converges quickly, and is always the best (or among the best) of the various optimizers.",5. Conclusion,[0],[0]
This research was supported in part by ITF/391/15FX.,Acknowledgments,[0],[0]
Deep networks are highly nonlinear and difficult to optimize.,abstractText,[0],[0]
"During training, the parameter iterate may move from one local basin to another, or the data distribution may even change.",abstractText,[0],[0]
"Inspired by the close connection between stochastic optimization and online learning, we propose a variant of the follow the regularized leader (FTRL) algorithm called follow the moving leader (FTML).",abstractText,[0],[0]
"Unlike the FTRL family of algorithms, the recent samples are weighted more heavily in each iteration and so FTML can adapt more quickly to changes.",abstractText,[0],[0]
"We show that FTML enjoys the nice properties of RMSprop and Adam, while avoiding their pitfalls.",abstractText,[0],[0]
"Experimental results on a number of deep learning models and tasks demonstrate that FTML converges quickly, and outperforms other state-ofthe-art optimizers.",abstractText,[0],[0]
Follow the Moving Leader in Deep Learning,title,[0],[0]
NMT has witnessed promising improvements recently.,1 Introduction,[0],[0]
"Depending on the types of input and output, these efforts can be divided into three categories: string-to-string systems (Sutskever et al., 2014; Bahdanau et al., 2014); tree-to-string systems (Eriguchi et al., 2016, 2017); and string-totree systems (Aharoni and Goldberg, 2017; Nadejde et al., 2017).",1 Introduction,[0],[0]
"Compared with string-to-string systems, tree-to-string and string-to-tree systems (henceforth, tree-based systems) offer some attractive features.",1 Introduction,[0],[0]
"They can use more syntactic information (Li et al., 2017), and can conveniently incorporate prior knowledge (Zhang et al., 2017).
∗ Contribution during internship at National Institute of Information and Communications Technology.
†Corresponding author
Because of these advantages, tree-based methods become the focus of many researches of NMT nowadays.
",1 Introduction,[0],[0]
"Based on how to represent trees, there are two main categories of tree-based NMT methods: representing trees by a tree-structured neural network (Eriguchi et al., 2016; Zaremoodi and Haffari, 2017), representing trees by linearization (Vinyals et al., 2015; Dyer et al., 2016; Ma et al., 2017).",1 Introduction,[0],[0]
"Compared with the former, the latter method has a relatively simple model structure, so that a larger corpus can be used for training and the model can be trained within reasonable time, hence is preferred from the viewpoint of computation.",1 Introduction,[0],[0]
"Therefore we focus on this kind of methods in this paper.
",1 Introduction,[0],[0]
"In spite of impressive performance of tree-based NMT systems, they suffer from a major drawback: they only use the 1-best parse tree to direct the translation, which potentially introduces translation mistakes due to parsing errors (Quirk and Corston-Oliver, 2006).",1 Introduction,[0],[0]
"For SMT, forest-based methods have employed a packed forest to address this problem (Huang, 2008), which represents exponentially many parse trees rather than just the 1-best one (Mi et al., 2008; Mi and Huang, 2008).",1 Introduction,[0],[0]
"But for NMT, (computationally efficient) forestbased methods are still being explored1.
",1 Introduction,[0],[0]
"Because of the structural complexity of forests, the inexistence of appropriate topological ordering, and the hyperedge-attachment nature of weights (see Section 3.1 for details), it is not trivial to linearize a forest.",1 Introduction,[0],[0]
"This hinders the development of forest-based NMT to some extent.
",1 Introduction,[0],[0]
"Inspired by the tree-based NMT methods based on linearization, we propose an efficient forestbased NMT approach (Section 3), which can en-
1Zaremoodi and Haffari (2017) have proposed a forestbased NMT method based on a forest-structured neural network recently, but it is computationally inefficient (see Section 5).
code the syntactic information of a packed forest on the basis of a novel weighted linearization method for a packed forest (Section 3.1), and can decode the linearized packed forest under the simple sequence-to-sequence framework (Section 3.2).",1 Introduction,[0],[0]
Experiments demonstrate the effectiveness of our method (Section 4).,1 Introduction,[0],[0]
"We first review the general sequence-to-sequence model (Section 2.1), then describe tree-based NMT systems based on linearization (Section 2.2), and finally introduce the packed forest, through which exponentially many trees can be represented in a compact manner (Section 2.3).",2 Preliminaries,[0],[0]
"Current NMT systems usually resort to a simple framework, i.e., the sequence-to-sequence model (Cho et al., 2014; Sutskever et al., 2014).",2.1 Sequence-to-sequence model,[0],[0]
"Given a source sequence (x0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", xT ), in order to find a target sequence (y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", yT ′) that maximizes the conditional probability p(y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", yT ′",2.1 Sequence-to-sequence model,[0],[0]
"| x0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", xT ), the sequence-to-sequence model uses one RNN to encode the source sequence into a fixed-length context vector c and a second RNN to decode this vector and generate the target sequence.",2.1 Sequence-to-sequence model,[0],[0]
"Formally, the probability of the target sequence can be calculated as follows:
p(y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
",yT ′",2.1 Sequence-to-sequence model,[0],[0]
"| x0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", xT )
",2.1 Sequence-to-sequence model,[0],[0]
"= T ′∏ t=0 p(yt | c, y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", yt−1), (1)
where
p(yt | c, y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", yt−1) = g(yt−1, st, c), (2) st = f(st−1, yt−1, c), (3)
c = q(h0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", hT ), (4)
ht = f(et, ht−1).",2.1 Sequence-to-sequence model,[0],[0]
"(5)
Here, g, f , and q are nonlinear functions; ht and st are the hidden states of the source-side RNN and target-side RNN, respectively, c is the context vector, and et is the embedding of xt.
Bahdanau et al. (2014) introduced an attention mechanism to deal with the issues related to long sequences (Cho et al., 2014).",2.1 Sequence-to-sequence model,[0],[0]
"Instead of encoding the source sequence into a fixed vector c, the attention model uses different ci-s when calculating
the target-side output yi at time step i:
ci = T∑
j=0
αijhj , (6)
αij = exp(a(si−1, hj))∑T k=0",2.1 Sequence-to-sequence model,[0],[0]
"exp(a(si−1, hk))",2.1 Sequence-to-sequence model,[0],[0]
.,2.1 Sequence-to-sequence model,[0],[0]
"(7)
The function a(si−1, hj) can be regarded as representing the soft alignment between the target-side RNN hidden state si−1 and the source-side RNN hidden state hj .
",2.1 Sequence-to-sequence model,[0],[0]
"By changing the format of the source/target sequences, this framework can be regarded as a string-to-string NMT system (Sutskever et al., 2014), a tree-to-string NMT system (Li et al., 2017), or a string-to-tree NMT system (Aharoni and Goldberg, 2017).",2.1 Sequence-to-sequence model,[0],[0]
"Regarding the linearization adopted for tree-tostring NMT (i.e., linearization of the source side), Sennrich and Haddow (2016) encoded the sequence of dependency labels and the sequence of words simultaneously, partially utilizing the syntax information, while Li et al. (2017) traversed the constituent tree of the source sentence and combined this with the word sequence, utilizing the syntax information completely.
",2.2 Linear-structured tree-based NMT systems,[0],[0]
"Regarding the linearization used for string-totree NMT (i.e., linearization of the target side), Nadejde et al. (2017) used a CCG supertag sequence as the target sequence, while Aharoni and Goldberg (2017) applied a linearization method in a top-down manner, generating a sequence ensemble for the annotated tree in the Penn Treebank (Marcus et al., 1993).",2.2 Linear-structured tree-based NMT systems,[0],[0]
"Wu et al. (2017) used transition actions to linearize a dependency tree, and employed the sequence-to-sequence framework for NMT.
",2.2 Linear-structured tree-based NMT systems,[0],[0]
It can be seen all current tree-based NMT systems use only one tree for encoding or decoding.,2.2 Linear-structured tree-based NMT systems,[0],[0]
"In contrast, we hope to utilize multiple trees (i.e., a forest).",2.2 Linear-structured tree-based NMT systems,[0],[0]
"This is not trivial, on account of the lack of a fixed traversal order and the need for a compact representation.",2.2 Linear-structured tree-based NMT systems,[0],[0]
"The packed forest gives a representation of exponentially many parsing trees, and can compactly encode many more candidates than the n-best list
(Huang, 2008).",2.3 Packed forest,[0],[0]
"Figure 1a shows a packed forest, which can be unpacked into two constituent trees (Figure 1b and Figure 1c).
",2.3 Packed forest,[0],[0]
"Formally, a packed forest is a pair 〈V,E〉, where V is the set of nodes and E is the set of hyperedges.",2.3 Packed forest,[0],[0]
"Each v ∈ V can be represented as Xi,j , where X is a constituent label and i, j ∈",2.3 Packed forest,[0],[0]
"[0, n] are indices of words, showing that the node spans the words ranging from i (inclusive) to j (exclusive).",2.3 Packed forest,[0],[0]
"Here, n is the length of the input sentence.",2.3 Packed forest,[0],[0]
"Each e ∈ E is a three-tuple 〈head(e), tails(e), score(e)〉, where head(e) ∈ V is similar to the head node in a constituent tree, and tails(e) ∈ V ∗ is similar to the set of child nodes in a constituent tree.",2.3 Packed forest,[0],[0]
score(e) ∈ R is the logarithm of the probability that tails(e) represents the tails of head(e) calculated by the parser.,2.3 Packed forest,[0],[0]
"Based on score(e), the score of a constituent tree T can be calculated as follows:
score(T ) = −λn+",2.3 Packed forest,[0],[0]
"∑
e∈E(T )
score(e), (8)
where E(T ) is the set of hyperedges appearing in tree T , and λ is a regularization coefficient for the sentence length2.
2Following the configuration of Charniak and Johnson",2.3 Packed forest,[0],[0]
"We first propose a linearization method for the packed forest (Section 3.1), then describe how to encode the linearized forest (Section 3.2), which can then be translated by the conventional decoder (see Section 2.1).",3 Forest-based NMT,[0],[0]
"Recently, several studies have focused on the linearization methods of a syntax tree, both in the area of tree-based NMT (Section 2.2) and in the area of parsing (Vinyals et al., 2015; Dyer et al., 2016; Ma et al., 2017).",3.1 Forest linearization,[0],[0]
"Basically, these methods follow a fixed traversal order (e.g., depthfirst), which does not exist for the packed forest (a directed acyclic graph (DAG)).",3.1 Forest linearization,[0],[0]
"Furthermore, the weights are attached to edges of a packed forest instead of the nodes, which further increase the difficulty.
",3.1 Forest linearization,[0],[0]
"Topological ordering algorithms for DAG (Kahn, 1962; Tarjan, 1976) are not good solutions, because the outputted ordering is not always optimal for machine translation.",3.1 Forest linearization,[0],[0]
"In particular, a topo-
(2005), for all the experiments in this paper, we fixed λ to log2 600.
",3.1 Forest linearization,[0],[0]
"Algorithm 1 Linearization of a packed forest 1: function LINEARIZEFOREST(〈V,E〉,w) 2: v ← FINDROOT(V ) 3: r←",3.1 Forest linearization,[0],[0]
"[] 4: EXPANDSEQ(v, r, 〈V,E〉,w) 5: return r 6: function FINDROOT(V ) 7: for v ∈ V do 8: if v has no parent then 9: return v 10: procedure EXPANDSEQ(v, r, 〈V,E〉,w) 11: for e ∈ E do 12: if head(e) = v then 13: if tails(e) 6= ∅",3.1 Forest linearization,[0],[0]
then 14: for t ∈ SORT(tails(e)) do .,3.1 Forest linearization,[0],[0]
"Sort
tails(e) by word indices.",3.1 Forest linearization,[0],[0]
"15: EXPANDSEQ(t, r, 〈V,E〉,w) 16: l← LINEARIZEEDGE(head(e),w) 17: r.append(〈l, σ(0.0)〉) .",3.1 Forest linearization,[0],[0]
"σ is the sigmoid
function, i.e., σ(x) = 1 1+e−x , x ∈ R.
18:",3.1 Forest linearization,[0],[0]
"l ← c©LINEARIZEEDGES(tails(e),w) .",3.1 Forest linearization,[0],[0]
c© is a unary operator.,3.1 Forest linearization,[0],[0]
"19: r.append(〈l, σ(score(e))",3.1 Forest linearization,[0],[0]
"〉) 20: else 21: l← LINEARIZEEDGE(head(e),w) 22:",3.1 Forest linearization,[0],[0]
"r.append(〈l, σ(0.0)〉) 23: function LINEARIZEEDGE(Xi,j ,w) 24: return X ⊗",3.1 Forest linearization,[0],[0]
"( j−1k=iwk) 25: function LINEARIZEEDGES(v,w) 26: return ⊕v∈vLINEARIZEEDGE(v,w)
logical ordering could ignore “word sequential information” and “parent-child information” in the sentences.
",3.1 Forest linearization,[0],[0]
"For example, for the packed forest in Figure 1a, although “[10]→[1]→[2]→ · · · →[9]→[11]” is a valid topological ordering, the word sequential information of the words (e.g., “John” should be located ahead of the period), which is fairly crucial for translation of languages with fixed pragmatic word order such as Chinese or English, is lost.
",3.1 Forest linearization,[0],[0]
"As another example, for the packed forest in Figure 1a, nodes [2], [9], and [10] are all the children of node [11].",3.1 Forest linearization,[0],[0]
"However, in the topological order “[1]→[2]→ · · · →[9]→[10]→[11],” node [2] is quite far from node [11], while nodes [9] and [10] are both close to node [11].",3.1 Forest linearization,[0],[0]
"The parent-child information cannot be reflected in this topological order, which is not what we would expect.
",3.1 Forest linearization,[0],[0]
"To address the above two problems, we propose a novel linearization algorithm for a packed forest (Algorithm 1).",3.1 Forest linearization,[0],[0]
"The algorithm linearizes the packed forest from the root node (Line 2) to leaf nodes by calling the EXPANDSEQ procedure (Line 15) recursively, while preserving the word order in the sentence (Line 14).",3.1 Forest linearization,[0],[0]
"In this way, word sequential information is preserved.",3.1 Forest linearization,[0],[0]
"Within the
EXPANDSEQ procedure, once a hyperedge is linearized (Line 16), the tails are also linearized immediately (Line 18).",3.1 Forest linearization,[0],[0]
"In this way, parent-child information is preserved.",3.1 Forest linearization,[0],[0]
"Intuitively, different parts of constituent trees should be combined in different ways, therefore we define different operators ( c©, ⊗, ⊕, or ) to represent the relationships between different parts, so that the representations of these parts can be combined in different ways (see Section 3.2 for details).",3.1 Forest linearization,[0],[0]
"Words are concatenated by the operator “ ” with each other, a word and a constituent label is concatenated by the operator “⊗”, the linearization results of child nodes are concatenated by the operator “⊕” with each other, while the unary operator “ c©” is used to indicate that the node is the child node of the previous part.",3.1 Forest linearization,[0],[0]
"Furthermore, each token in the linearized sequence is related to a score, representing the confidence of the parser.
",3.1 Forest linearization,[0],[0]
The linearization result of the packed forest in Figure 1a is shown in Figure 2.,3.1 Forest linearization,[0],[0]
Tokens in the linearized sequence are separated by slashes.,3.1 Forest linearization,[0],[0]
Each token in the sequence is composed of different types of symbols and combined by different operators.,3.1 Forest linearization,[0],[0]
We can see that word sequential information is preserved.,3.1 Forest linearization,[0],[0]
"For example, “NNP⊗John” (linearization result of node [1]) is in front of “VBZ⊗has” (linearization result of node [3]), which is in front of “DT⊗a” (linearization result of node [4]).",3.1 Forest linearization,[0],[0]
"Moreover, parent-child information is also preserved.",3.1 Forest linearization,[0],[0]
"For example, “NP⊗John” (linearization result of node [2]) is followed by “ c©NNP⊗John” (linearization result of node [1], the child of node [2]).
",3.1 Forest linearization,[0],[0]
Note that our linearization method cannot fully recover packed forest.,3.1 Forest linearization,[0],[0]
What we want to do is not to propose a fully recoverable linearization method.,3.1 Forest linearization,[0],[0]
"What we actually want to do is to encode syntax information as much as possible, so that we can improve the performance of NMT.",3.1 Forest linearization,[0],[0]
"As will be shown in Section 4, this goal is achieved.
",3.1 Forest linearization,[0],[0]
"Also note that there is one more advantage of our linearization method: the linearized sequence
is a weighted sequence, while all the previous studies ignored the weights during linearization.",3.1 Forest linearization,[0],[0]
"As will be shown in Section 4, the weights are actually important not only for the linearization of a packed forest, but also for the linearization of a single tree.
",3.1 Forest linearization,[0],[0]
"By preserving only the nodes and hyperedges in the 1-best tree and removing all others, our linearization method can be regarded as a treelinearization method.",3.1 Forest linearization,[0],[0]
"Compared with other treelinearization methods, our method combines several different kinds of information within one symbol, retaining the parent-child information, and incorporating the confidence of the parser in the sequence.",3.1 Forest linearization,[0],[0]
"We examine whether the weights can be useful not only for linear structured tree-based NMT but also for our forest-based NMT.
",3.1 Forest linearization,[0],[0]
"Furthermore, although our method is nonreversible for packed forests, it is reversible for constituent trees, in that the linearization is processed exactly in the depth-first traversal order and all necessary information in the tree nodes has been encoded.",3.1 Forest linearization,[0],[0]
"As far as we know, there is no previous work on linearization of packed forests.",3.1 Forest linearization,[0],[0]
"The linearized packed forest forms the input of the encoder, which has two major differences from the input of a sequence-to-sequence NMT system.",3.2 Encoding the linearized forest,[0],[0]
"First, the input sequence of the encoder consists of two parts: the symbol sequence and the score sequence.",3.2 Encoding the linearized forest,[0],[0]
"Second, each symbol in the symbol sequence consists of several parts (words and constituent labels), which are combined by certain operators ( c©, ⊗, ⊕, or ).",3.2 Encoding the linearized forest,[0],[0]
"Based on these observa-
tions, we propose two new frameworks, which are illustrated in Figure 3.
",3.2 Encoding the linearized forest,[0],[0]
"Formally, the input layer receives the sequence (〈l0, ξ0〉, . . .",3.2 Encoding the linearized forest,[0],[0]
", 〈lT , ξT 〉), where li denotes the i-th symbol and ξi its score.",3.2 Encoding the linearized forest,[0],[0]
"Then, the sequence is fed into the score layer and the symbol layer.",3.2 Encoding the linearized forest,[0],[0]
"The score and symbol layers receive the sequence and output the score sequence ξ = (ξ0, . . .",3.2 Encoding the linearized forest,[0],[0]
", ξT ) and symbol sequence",3.2 Encoding the linearized forest,[0],[0]
"l = (l0, . . .",3.2 Encoding the linearized forest,[0],[0]
", lT ), respectively, from the input.",3.2 Encoding the linearized forest,[0],[0]
Any item l ∈,3.2 Encoding the linearized forest,[0],[0]
"l in the symbol layer has the form
l = o0x1o1 . . .",3.2 Encoding the linearized forest,[0],[0]
"xm−1om−1xm, (9)
where each xk (k = 1, . . .",3.2 Encoding the linearized forest,[0],[0]
",m) is a word or a constituent label, m is the total number of words and constituent labels in a symbol, o0 is “ c©” or empty, and each ok (k = 1, . . .",3.2 Encoding the linearized forest,[0],[0]
",m − 1) is either “⊗”, “⊕”, or “ ”.",3.2 Encoding the linearized forest,[0],[0]
"Then, in the node/operator layer, the x-s and o-s are separated and rearranged as x = (x1, . . .",3.2 Encoding the linearized forest,[0],[0]
", xm, o0, . . .",3.2 Encoding the linearized forest,[0],[0]
", om−1), which is fed to the pre-embedding layer.",3.2 Encoding the linearized forest,[0],[0]
"The pre-embedding layer generates a sequence p = (p1, . .",3.2 Encoding the linearized forest,[0],[0]
.,3.2 Encoding the linearized forest,[0],[0]
", pm, . . .",3.2 Encoding the linearized forest,[0],[0]
", p2m), which is calculated as follows:
p =Wemb[I(x)].",3.2 Encoding the linearized forest,[0],[0]
"(10)
Here, the function I(x) returns a list of the indices in the dictionary for all the elements in x, which consist of words, constituent labels, or operators.",3.2 Encoding the linearized forest,[0],[0]
"In addition, Wemb is the embedding matrix of size (|wword| + |wlabel| + 4) × dword, where |wword| and |wlabel| are the total number of words and constituent labels, respectively, dword is the dimension of the word embedding, and there are four possible operators: “",3.2 Encoding the linearized forest,[0],[0]
"c©,” “⊗,” “⊕,” and “ .”",3.2 Encoding the linearized forest,[0],[0]
"Note
that p is a list of 2m vectors, and the dimension of each vector is dword.
",3.2 Encoding the linearized forest,[0],[0]
"Because the length of the sequence of the input layer is T + 1, there are T + 1 different ps in the pre-embedding layer, which we denote by P = (p0, . . .",3.2 Encoding the linearized forest,[0],[0]
",pT ).",3.2 Encoding the linearized forest,[0],[0]
"Depending on where the score layer is incorporated, we propose two frameworks: Score-on-Embedding (SoE) and Score-onAttention (SoA).",3.2 Encoding the linearized forest,[0],[0]
"In SoE, the k-th element of the embedding layer is calculated as follows:
ek = ξk ∑ p∈pk p, (11)
while in SoA, the k-th element of the embedding layer is calculated as
ek = ∑ p∈pk p, (12)
where k = 0, . . .",3.2 Encoding the linearized forest,[0],[0]
", T .",3.2 Encoding the linearized forest,[0],[0]
Note that ek ∈ Rdword .,3.2 Encoding the linearized forest,[0],[0]
"In this manner, the proposed forest-to-string NMT framework is connected with the conventional sequence-to-sequence NMT framework.
",3.2 Encoding the linearized forest,[0],[0]
"After calculating the embedding vectors in the embedding layer, the hidden vectors are calculated using Equation 5.",3.2 Encoding the linearized forest,[0],[0]
"When calculating the context vector ci-s, SoE and SoA differ from each other.",3.2 Encoding the linearized forest,[0],[0]
"For SoE, the ci-s are calculated using Equation 6 and 7, while for SoA, the αij-s used to calculate the ci-s are determined as follows:
αij = exp(ξja(si−1, hj))∑T k=0",3.2 Encoding the linearized forest,[0],[0]
"exp(ξka(si−1, hk)) .",3.2 Encoding the linearized forest,[0],[0]
"(13)
Then, using the decoder of the sequence-tosequence framework, the sentence of the target language can be generated.",3.2 Encoding the linearized forest,[0],[0]
We evaluate the effectiveness of our forest-based NMT systems on English-to-Chinese and Englishto-Japanese translation tasks3.,4.1 Setup,[0],[0]
"The statistics of the corpora used in our experiments are summarized in Table 1.
",4.1 Setup,[0],[0]
The packed forests of English sentences are obtained by the constituent parser proposed by Huang (2008)4.,4.1 Setup,[0],[0]
"We filtered out the sentences for
3English is commonly chosen as the target language.",4.1 Setup,[0],[0]
"We chose English as the source language because a highperformance forest parser is not available for other languages.
4http://web.engr.oregonstate.edu/ ˜huanlian/software/forest-reranker/ forest-charniak-v0.8.tar.bz2
which the parser cannot generate the packed forest successfully and the sentences longer than 80 words.",4.1 Setup,[0],[0]
"For NIST datasets, we simply choose the first reference among the four English references of NIST corpora, because all of them are independent with each other, according to the documents of NIST datasets.",4.1 Setup,[0],[0]
"For Chinese sentences, we used Stanford segmenter5 for segmentation.",4.1 Setup,[0],[0]
"For Japanese sentences, we followed the preprocessing steps recommended in WAT 20176.
",4.1 Setup,[0],[0]
"We implemented our framework based on nematus8 (Sennrich et al., 2017).",4.1 Setup,[0],[0]
"For optimization, we used the Adadelta algorithm (Zeiler, 2012).",4.1 Setup,[0],[0]
"In order to avoid overfitting, we used dropout (Srivastava et al., 2014) on the embedding layer and hidden layer, with the dropout probability set to 0.2.",4.1 Setup,[0],[0]
"We used the gated recurrent unit (Cho et al., 2014) as the recurrent unit of RNNs, which are bi-directional, with one hidden layer.
",4.1 Setup,[0],[0]
"Based on the tuning result, we set the maximum length of the input sequence to 300, the hidden layer size as 512, the dimension of word embedding as 620, and the batch size for training as 40.",4.1 Setup,[0],[0]
"We pruned the packed forest using the algorithm of Huang (2008), with a threshold of 5.",4.1 Setup,[0],[0]
"If the linearization of the pruned forest is still longer than 300, then we linearize the 1-best parsing tree instead of the forest.",4.1 Setup,[0],[0]
"During decoding, we used beam search, and fixed the beam size to 12.",4.1 Setup,[0],[0]
"For the case of Forest (SoA), with 1 core of Tesla K80 GPU and LDC corpus as the training data, training spent about 10 days, and decoding speed is about 10 sentences per second.
",4.1 Setup,[0],[0]
"5https://nlp.stanford.edu/software/ stanford-segmenter-2017-06-09.zip
6http://lotus.kuee.kyoto-u.ac.jp/WAT/ WAT2017/baseline/dataPreparationJE.html
7LDC2002E18, LDC2003E07, LDC2003E14, Hansards portion of LDC2004T07, LDC2004T08, and LDC2005T06
8https://github.com/EdinburghNLP/ nematus",4.1 Setup,[0],[0]
Table 2 and 3 summarize the experimental results.,4.2 Experimental results,[0],[0]
"To avoid the affect of segmentation errors, the performance were evaluated by character-level BLEU (Papineni et al., 2002).",4.2 Experimental results,[0],[0]
"We compare our proposed models (i.e., Forest (SoE) and Forest (SoA)) with three types of baseline: a string-to-string model (s2s), forest-based models that do not use score sequences (Forest (No score)), and tree-based models that use the 1-best parsing tree (1-best (No score, SoE, SoA)).",4.2 Experimental results,[0],[0]
"For the 1-best models, we preserve the nodes and hyperedges that are used in the 1-best constituent tree in the packed forest, and remove all other nodes and hyperedges, yielding a pruned forest that contains only the 1-best constituent tree.",4.2 Experimental results,[0],[0]
"For the “No score” configurations, we force the input score sequence to be a sequence of 1.0 with the same length as the input symbol sequence, so that neither the embedding layer nor the attention layer are affected by the score sequence.
",4.2 Experimental results,[0],[0]
"In addition, we also perform a comparison with some state-of-the-art tree-based systems that are
publicly available, including an SMT system (Mi et al., 2008) and the NMT systems (Eriguchi et al. (2016)9, Chen et al. (2017)10, and Li et al. (2017)).",4.2 Experimental results,[0],[0]
"For Mi et al. (2008), we use the implementation of cicada11.",4.2 Experimental results,[0],[0]
"For Li et al. (2017), we reimplemented the “Mixed RNN Encoder” model, because of its outstanding performance on the NIST MT corpus.
",4.2 Experimental results,[0],[0]
"We can see that for both English-Chinese and English-Japanese, compared with the s2s baseline system, both the 1-best and forest-based configurations yield better results.",4.2 Experimental results,[0],[0]
This indicates syntactic information contained in the constituent trees or forests is indeed useful for machine translation.,4.2 Experimental results,[0],[0]
"Specifically, we observe the following facts.
",4.2 Experimental results,[0],[0]
"First, among the three different frameworks SoE, SoA, and No-score, the SoA framework performs the best, while the No-score framework per-
9https://github.com/tempra28/tree2seq 10https://github.com/howardchenhd/
Syntax-awared-NMT 11https://github.com/tarowatanabe/ cicada
forms the worst.",4.2 Experimental results,[0],[0]
"This indicates that the scores of the edges in constituent trees or packed forests, which reflect the confidence of the correctness of the edges, are indeed useful.",4.2 Experimental results,[0],[0]
"In fact, for the 1-best constituent parsing tree, the score of the edge reflects the confidence of the parser.",4.2 Experimental results,[0],[0]
"By using this information, the NMT system succeed to learn a better attention, paying much attention to the confident structure and not paying attention to the unconfident structure, which improved the translation performance.",4.2 Experimental results,[0],[0]
This fact is ignored by previous studies on tree-based NMT.,4.2 Experimental results,[0],[0]
"Furthermore, it is better to use the scores to modify the values of attention instead of rescaling the word embeddings, because modifying word embeddings carelessly may change the semantic meanings of words.
",4.2 Experimental results,[0],[0]
"Second, compared with the cases that only using the 1-best constituent trees, using packed forests yields statistical significantly better results for the SoE and SoA frameworks.",4.2 Experimental results,[0],[0]
This shows the effectiveness of using more syntactic information.,4.2 Experimental results,[0],[0]
"Compared with one constituent tree, the packed forest, which contains multiple different trees, describes the syntactic structure of the sentence in different aspects, which together increase the accuracy of machine translation.",4.2 Experimental results,[0],[0]
"However, without using the scores, the 1-best constituent tree is preferred.",4.2 Experimental results,[0],[0]
"This is because without using the scores, all trees in the packed forest are treated equally, which makes it easy to import noise into the encoder.
",4.2 Experimental results,[0],[0]
"Compared with other types of state-of-the-art systems, our systems using only the 1-best tree (1-best(SoE, SoA)) are better than the other treebased systems.",4.2 Experimental results,[0],[0]
"Moreover, our NMT systems using the packed forests achieve the best performance.",4.2 Experimental results,[0],[0]
"These results also support the usefulness of the scores of the edges and packed forests in NMT.
",4.2 Experimental results,[0],[0]
"As for the efficiency, the training time of the SoA system was slightly longer than that of the SoE system, which was about twice of the s2s baseline.",4.2 Experimental results,[0],[0]
The training time of the tree-based system was about 1.5 times of the baseline.,4.2 Experimental results,[0],[0]
"For the
case of Forest (SoA), with 1 core of Tesla P100 GPU and LDC corpus as the training data, training spent about 10 days, and decoding speed was about 10 sentences per second.",4.2 Experimental results,[0],[0]
"The reason for the relatively low efficiency is that the linearized sequences of packed forests were much longer than word sequences, enlarging the scale of the inputs.",4.2 Experimental results,[0],[0]
"Despite this, the training process ended within reasonable time.",4.2 Experimental results,[0],[0]
"Figure 4 illustrates the translation results of an English sentence using several different configurations: the s2s baseline, using only the 1-best tree (SoE), and using the packed forest (SoE).",4.3 Qualitative analysis,[0],[0]
"This is a sentence from NIST MT 03, and the training corpus is the LDC corpus.
",4.3 Qualitative analysis,[0],[0]
"For the s2s case, no syntactic information is utilized, and therefore the output of the system is not a grammatical Chinese sentence.",4.3 Qualitative analysis,[0],[0]
The attributive phrase of “Czech border region” is a complete sentence.,4.3 Qualitative analysis,[0],[0]
"However, the attributive is not allowed to be a complete sentence in Chinese.
",4.3 Qualitative analysis,[0],[0]
"For the case of using 1-best constituent tree, the output is a grammatical Chinese sentence.",4.3 Qualitative analysis,[0],[0]
"However, the phrase “adjacent to neighboring Slovakia” is completely ignored in the translation result.",4.3 Qualitative analysis,[0],[0]
"After analyzing the constituent tree, we found that this phrase was incorrectly parsed as an “adverb phrase”, so that the NMT system paid little attention to it, because of the low confidence given by the parser.
",4.3 Qualitative analysis,[0],[0]
"In contrast, for the case of the packed forest, we can see this phrase was not ignored and was translated correctly.",4.3 Qualitative analysis,[0],[0]
"Actually, besides “adverb phrase”, this phrase was also correctly parsed as an “adjective phrase”, and covered by multiple different nodes in the forest, making it difficult for the encoder to ignore the phrase.
",4.3 Qualitative analysis,[0],[0]
We also noticed that our method performed better on learning attention.,4.3 Qualitative analysis,[0],[0]
"For the example in Figure 4, we observed that for s2s model, the decoder paid attention to the word “Czech” twice, which
causes the output sentence contains the Chinese translation of Czech twice.",4.3 Qualitative analysis,[0],[0]
"On the other hand, for our forest model, by using the syntax information, the decoder paid attention to the phrase “In the Czech Republic” only once, making the decoder generates the correct output.",4.3 Qualitative analysis,[0],[0]
Incorporating syntactic information into NMT systems is attracting widespread attention nowadays.,5 Related work,[0],[0]
"Compared with conventional string-to-string NMT systems, tree-based systems demonstrate a better performance with the help of constituent trees or dependency trees.
",5 Related work,[0],[0]
"The first noteworthy study is Eriguchi et al. (2016), which used Tree-structured LSTM (Tai et al., 2015) to encode the HPSG syntax tree of the sentence in the source-side in a bottom-up manner.",5 Related work,[0],[0]
"Then, Chen et al. (2017) enhanced the encoder with a top-down tree encoder.
",5 Related work,[0],[0]
"As a simple extension of Eriguchi et al. (2016), very recently, Zaremoodi and Haffari (2017) proposed a forest-based NMT method by representing the packed forest with a forest-structured neural network.",5 Related work,[0],[0]
"However, their method was evaluated in small-scale MT settings (each training dataset consists of under 10k parallel sentences).",5 Related work,[0],[0]
"In contrast, our proposed method is effective in a largescale MT setting, and we present qualitative analysis regarding the effectiveness of using forests in NMT.
",5 Related work,[0],[0]
"Although these methods obtained good results, the tree-structured network used by the encoder made the training and decoding relatively slow, therefore restricts the scope of application.
",5 Related work,[0],[0]
Other attempts at encoding syntactic trees have also been proposed.,5 Related work,[0],[0]
"Eriguchi et al. (2017) combined the Recurrent Neural Network Grammar (Dyer et al., 2016) with NMT systems, while Li et al. (2017) linearized the constituent tree and encoded it using RNNs.",5 Related work,[0],[0]
"The training of these methods is fast, because of the linear structures of RNNs.",5 Related work,[0],[0]
"However, all these syntax-based NMT systems used only the 1-best parsing tree, making the systems sensitive to parsing errors.
",5 Related work,[0],[0]
"Instead of using trees to represent syntactic information, some studies use other data structures to represent the latent syntax of the input sentence.",5 Related work,[0],[0]
"For example, Hashimoto and Tsuruoka (2017) proposed translating using a latent graph.",5 Related work,[0],[0]
"However, such systems do not enjoy the benefit of
handcrafted syntactic knowledge, because they do not use a parser trained from a large treebank with human annotations.
",5 Related work,[0],[0]
"Compared with these related studies, our framework utilizes a linearized packed forest, meaning the encoder can encode exponentially many trees in an efficient manner.",5 Related work,[0],[0]
The experimental results demonstrated these advantages.,5 Related work,[0],[0]
"We proposed a new NMT framework, which encodes a packed forest for the source sentence using linear-structured neural networks, such as RNN.",6 Conclusion and future work,[0],[0]
"Compared with conventional string-tostring NMT systems and tree-to-string NMT systems, our framework can utilize exponentially many linearized parsing trees during encoding, without significantly decreasing the efficiency.",6 Conclusion and future work,[0],[0]
This represents the first attempt at using a forest under the string-to-string NMT framework.,6 Conclusion and future work,[0],[0]
"The experimental results demonstrate the effectiveness of our framework.
",6 Conclusion and future work,[0],[0]
"As future work, we plan to design some more elaborate structures to incorporate the score layer in the encoder.",6 Conclusion and future work,[0],[0]
Further improvement in the translation performance is expected to be achieved for the forest-based NMT system.,6 Conclusion and future work,[0],[0]
We will also apply the proposed linearization method to other tasks.,6 Conclusion and future work,[0],[0]
We are grateful to the anonymous reviewers for their insightful comments and suggestions.,Acknowledgements,[0],[0]
We thank Lemao Liu from Tencent AI Lab for his suggestions about the experiments.,Acknowledgements,[0],[0]
We thank Atsushi Fujita whose suggestions greatly improve the readability and the logical soundness of this paper.,Acknowledgements,[0],[0]
This work was done during the internship of Chunpeng Ma at NICT.,Acknowledgements,[0],[0]
Akihiro Tamura is supported by JSPS KAKENHI Grant Number JP18K18110.,Acknowledgements,[0],[0]
Tiejun Zhao is supported by the National Natural Science Foundation of China (NSFC) via grant 91520204 and State High-Tech Development Plan of China (863 program) via grant 2015AA015405.,Acknowledgements,[0],[0]
"Tree-based neural machine translation (NMT) approaches, although achieved impressive performance, suffer from a major drawback: they only use the 1best parse tree to direct the translation, which potentially introduces translation mistakes due to parsing errors.",abstractText,[0],[0]
"For statistical machine translation (SMT), forestbased methods have been proven to be effective for solving this problem, while for NMT this kind of approach has not been attempted.",abstractText,[0],[0]
"This paper proposes a forest-based NMT method that translates a linearized packed forest under a simple sequence-to-sequence framework (i.e., a forest-to-string NMT model).",abstractText,[0],[0]
"The BLEU score of the proposed method is higher than that of the string-to-string NMT, treebased NMT, and forest-based SMT systems.",abstractText,[0],[0]
Forest-Based Neural Machine Translation,title,[0],[0]
"Since its development by Breiman (2001), random forest has proven to be both accurate and efficient for classification and regression problems.",1. Introduction,[0],[0]
"In regression setting, random forest will predict the conditional mean of a response variable by averaging predictions of a large number of regression trees.",1. Introduction,[0],[0]
"Later then, many other machine learning algorithms were developed upon random forest.",1. Introduction,[0],[0]
"Among them, robust versions of random forest have also been proposed using various methodologies.",1. Introduction,[0],[0]
"Besides the sampling idea (Breiman, 2001) which adds extra randomness, the other variations are mainly based on two ideas: (1) use more robust criterion to construct regression trees (Galimberti et al., 2007; Brence & Brown, 2006; Roy & Larocque, 2012); (2) choose more robust aggregation method (Meinshausen, 2006; Roy & Larocque, 2012; Tsymbal et al., 2006).
",1. Introduction,[0],[0]
"Meinshausen (2006) generalized random forest to pre-
1University of California at San Diego, San Diego, California, USA 2Zillow, Seattle, Washington, USA.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Alexander Hanbo Li <alexanderhanboli@gmail.com>.
Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"dict quantiles by discovering that besides calculating the weighted mean of the observed response variables, one could also get information for the weighted distribution of observed response variables using the sets of local weights generated by random forest.",1. Introduction,[0],[0]
"This method is strongly connected to the adaptive nearest neighbors procedure (Lin & Jeon, 2006) which we will briefly review in section 1.2.",1. Introduction,[0],[0]
"Different from classical k-NN methods that rely on predefined distance metrics, the dissimilarities generated by random forest are data dependent and scale-invariant.
",1. Introduction,[0],[0]
"Another state-of-the-art algorithm AdaBoost (Freund & Schapire, 1995; Freund et al., 1996) has been generalized to be applicable to a large family of loss functions (Friedman, 2001; Mason et al., 1999; Li & Bradic, 2016).",1. Introduction,[0],[0]
"Recent development of more flexible boosting algorithms such as xgboost (Chen & Guestrin, 2016) have become the go-to forest estimators with tabular or matrix data.",1. Introduction,[0],[0]
"One way in which recent boosting algorithms have an advantage over the random forest is the ability to customize the loss function used to reduce the influence of outliers or optimize a metric more suited to the specific problem other than the mean squared error.
",1. Introduction,[0],[0]
"In this paper, we will propose a general framework for forest-type regression which can also be applied to a broad family of loss functions.",1. Introduction,[0],[0]
"It is claimed in (Meinshausen, 2006) that quantile random forest is another nonparametric approach which does not minimize an empirical loss.",1. Introduction,[0],[0]
"However, we will show in fact both random forest and quantile random forest estimators can be re-derived as regression methods using the squared error or quantile loss respectively in our framework.",1. Introduction,[0],[0]
"Inspired by the adaptive nearest neighbor viewpoint, we explore how random forest makes predictions using the local weights generated by ensemble of trees, and connect that with locally weighted regression (Fan & Gijbels, 1996; Tibshirani & Hastie, 1987; Staniswalis, 1989; Newey, 1994; Loader, 2006; Hastie & Loader, 1993).",1. Introduction,[0],[0]
"The intuition is that when predicting the target value (e.g. E[Y |X = x]) at point x, the observations closer to x should receive larger weights.",1. Introduction,[0],[0]
"Different from predefining a kernel, random forest assigns the weights data dependently and adaptively.",1. Introduction,[0],[0]
"After we illustrate the relation between random forest and local regression, we will use random forest weights to design other regression algo-
rithms.",1. Introduction,[0],[0]
"By plugging robust loss functions like Huber loss and Tukey’s redescending loss, we get forest-type regression methods that are more robust to outliers.",1. Introduction,[0],[0]
"Finally, motivated from the truncated squared error loss example, we will show that decreasing the number of nearest neighbors in random forest will also immediately improve its generalization performance.
",1. Introduction,[0],[0]
The layout of this paper is as follows.,1. Introduction,[0],[0]
In Section 1.1 and 1.2 we review random forest and adaptive nearest neighbors.,1. Introduction,[0],[0]
Section 2 introduces the general framework of forest-type regression.,1. Introduction,[0],[0]
In Section 3 we plug in robust regression loss functions to get robust forest algorithms.,1. Introduction,[0],[0]
In Section 4 we motivate from the truncated squared error loss and investigate the importance of choosing right number of nearest neighbors.,1. Introduction,[0],[0]
"Finally, we test our robust forests in Section 5 and show that they are always superior to the traditional formulation in the presence of outliers in both synthetic and real data set.",1. Introduction,[0],[0]
"Following the notation of Breiman (2001), let θ be the random parameter determining how a tree is grown, and data (X,Y ) ∈ X × Y .",1.1. Random forest,[0],[0]
"For each tree T (θ), let L be the total number of leaves, and Rl denotes the rectangular subspace in X corresponding to the l-th leaf.",1.1. Random forest,[0],[0]
"Then for every x ∈ X , there is exactly one leaf l",1.1. Random forest,[0],[0]
such that x ∈ Rl.,1.1. Random forest,[0],[0]
"Denote this leaf by l(x, θ).
",1.1. Random forest,[0],[0]
"For each tree T (θ), the prediction of a new data point X = x is the average of data values in leaf l(x, θ), that is, Ŷ (x, θ) = ∑n j=1 w(Xi, x, θ)Yi, where
w(Xi, x, θ) = 1I{Xi∈Rl(x,θ)}
#{j : Xj ∈ Rl(x,θ)} .",1.1. Random forest,[0],[0]
"(1)
Finally, the conditional mean E[Y |X = x] is approximated by the averaged prediction of m trees, Ŷ (x) = m−1 ∑m t=1",1.1. Random forest,[0],[0]
"Ŷ (x, θt).",1.1. Random forest,[0],[0]
"After rearranging the terms, we can write the prediction of random forest as
Ŷ (x) = n∑ i=1 w(Xi, x)Yi, (2)
where the averaged weight w(Xi, x) is defined as
w(Xi, x) = 1
m m∑ t=1 w(Xi, x, θt).",1.1. Random forest,[0],[0]
"(3)
From equation (2), the prediction of the conditional expectation E[Y |X = x] is the weighted average of the response values of all observations.",1.1. Random forest,[0],[0]
"Furthermore, it is easy to show that ∑n i=1 w(Xi, x) = 1.",1.1. Random forest,[0],[0]
Lin and Jeon (2006) studies the connection between random forest and adaptive nearest neighbor.,1.2. Adaptive nearest neighbors,[0],[0]
"They introduced the so-called potential nearest neighbors (PNN): A sample point xi is called a k-PNN to a target point x if there exists a monotone distance metric under which xi is among the k closest to x among all the sample points.
",1.2. Adaptive nearest neighbors,[0],[0]
"Therefore, any k-NN method can be viewed as choosing k points from the k-PNNs according to some monotone metric.",1.2. Adaptive nearest neighbors,[0],[0]
"For example, under Euclidean metric, the classical k-NN algorithm sorts the observations by their Euclidean distances to the target point and outputs the k closest ones.",1.2. Adaptive nearest neighbors,[0],[0]
"This is equivalent to weighting the k-PNNs using inverse L2 distance.
",1.2. Adaptive nearest neighbors,[0],[0]
"More interestingly, they prove that those observations with positive weights (3) all belong to the k-PNNs (Lin & Jeon, 2006).",1.2. Adaptive nearest neighbors,[0],[0]
"Therefore, random forests is another weighted kPNN method, but it assigns weights to the observations different from any k-NN method under a pre-defined monotonic distance metric.",1.2. Adaptive nearest neighbors,[0],[0]
"In fact, the random forest weights are adaptive to the data if the splitting scheme is adaptive.",1.2. Adaptive nearest neighbors,[0],[0]
"In this section, we generalize the classical random forest to a general forest-type regression (FTR) framework which is applicable to a broad family of loss functions.",2. General framework for forest-type regression,[0],[0]
"In Section 2.1, we motivate the framework by connecting random forest predictor with locally weighted regression.",2. General framework for forest-type regression,[0],[0]
"Then in Section 2.2, we formally propose the new forest-type regression framework.",2. General framework for forest-type regression,[0],[0]
"In Section 2.3, we rediscover the quantile random forest estimator by plugging the quantile loss function into our framework.",2. General framework for forest-type regression,[0],[0]
Classical random forest can be understood as an estimator of conditional mean E[Y |X].,2.1. Squared error and random forest,[0],[0]
"As shown in (2), the estimator Ŷ (x) is weighted average of all response",2.1. Squared error and random forest,[0],[0]
Yi’s.,2.1. Squared error and random forest,[0],[0]
"This special form reminds us of the classical least squares regression, where the estimator is the sample mean.",2.1. Squared error and random forest,[0],[0]
"To be more precise, we rewrite (2) as
n∑ i=1 w(Xi, x)(Yi",2.1. Squared error and random forest,[0],[0]
− Ŷ (x)),2.1. Squared error and random forest,[0],[0]
"= 0. (4)
Equation (4) is the estimating equation (first order condition) of the locally weighted least squares regression (Ruppert & Wand, 1994):
Ŷ (x) = argmin λ∈R n∑ i=1 w(Xi, x)(Yi",2.1. Squared error and random forest,[0],[0]
"− λ)2 (5)
In classical local regression, the weight w(Xi, x) serves as a local metric between the target point x and observation Xi.",2.1. Squared error and random forest,[0],[0]
"Intuitively, observations closer to target x should be given more weights when predicting the response at x. One common choice of such local metric is kernel Kh(Xi, x) = K((Xi − x)/h).",2.1. Squared error and random forest,[0],[0]
"For example, the tricube kernel K(u) =",2.1. Squared error and random forest,[0],[0]
(1 − |u|3)3 1I(|u| ≤ 1) will ignore the impact of observations outside a window centered at x and increase the weight of an observation when it is getting closer to x.,2.1. Squared error and random forest,[0],[0]
"The form of kernel-type local regression is as follows:
argmin λ∈R n∑ i=1 Kh(Xi",2.1. Squared error and random forest,[0],[0]
− x)(Yi,2.1. Squared error and random forest,[0],[0]
"− λ)2,
The random forest weight w(Xi, x) (3) defines a similar data dependent metric, which is constructed using the ensemble of regression trees.",2.1. Squared error and random forest,[0],[0]
"Using an adaptive splitting scheme, each tree chooses the most informative predictors from those at its disposal.",2.1. Squared error and random forest,[0],[0]
"The averaging process then assigns positive weights to these training responses, which are called voting points in (Lin & Jeon, 2006).",2.1. Squared error and random forest,[0],[0]
"Hence via the random forest voting mechanism, those observations close to the target point get assigned positive weights equivalent to a kernel functionality (Friedman et al., 2001).",2.1. Squared error and random forest,[0],[0]
"Note that the formation (5) is just a special case when using squared error loss φ(a, b) = (a−b)2.",2.2. Extension to general loss,[0],[0]
"In more general form, we have the following local regression problem:
Ŷ (x) = argmin s∈F n∑ i=1 w(Xi, x)φ(s(Xi), Yi) (6)
where w(Xi, x) is a local weight, F is a family of functions, and φ(·) is a general loss.",2.2. Extension to general loss,[0],[0]
"For example, when local weight is a kernel and F stands for polynomials of a certain degree, it reduces to local polynomial regression (Fan & Gijbels, 1996).",2.2. Extension to general loss,[0],[0]
"Random forest falls into this framework with squared error loss, a family of constant functions and local weights (3) constructed from ensemble of trees.
",2.2. Extension to general loss,[0],[0]
"Algorithm 1 Forest-type regression Step 1: Calculate local weights w(Xi, x) using ensemble or trees.",2.2. Extension to general loss,[0],[0]
"Step 2: Choose a loss φ(·, ·) and a family F of function.",2.2. Extension to general loss,[0],[0]
"Then do the locally weighted regression
Ŷ (x) = argmin s∈F n∑ i=1 w(Xi, x)φ(Yi, s(Xi)).
",2.2. Extension to general loss,[0],[0]
"In Algorithm 1, we summarize the forest-type regression as a general two-step method.",2.2. Extension to general loss,[0],[0]
"Note that here we only focus on local weights generated by random forest, which
uses ensemble of trees to recursively partition the covariate space X .",2.2. Extension to general loss,[0],[0]
"However, there are many other data dependent dissimilarity measures that can potentially be used, such as k-NN, mp-dissimilarity (Aryal et al., 2014), shared nearest neighbors (Jarvis & Patrick, 1973), information-based similarity (Lin et al., 1998), mass-based dissimilarity (Ting et al., 2016), etc.",2.2. Extension to general loss,[0],[0]
And there are many other domain specific dissimilarity measures.,2.2. Extension to general loss,[0],[0]
"To avoid distraction, we will only use random forest weights throughout the rest of this paper.",2.2. Extension to general loss,[0],[0]
Meinshausen (2006) proposed the quantile random forest which can extract the information of different quantiles rather than just predicting the average.,2.3. Quantile loss and quantile random forest,[0],[0]
"It has been shown that quantile random forest is more robust than the classical random forest (Meinshausen, 2006; Roy & Larocque, 2012).",2.3. Quantile loss and quantile random forest,[0],[0]
"In this section, we show quantile random forest estimator is also a special case of Algorithm 1.",2.3. Quantile loss and quantile random forest,[0],[0]
It is well known that the τ -th quantile of an (empirical) distribution is the constant that minimizes the (empirical) risk using τ - th quantile loss function,2.3. Quantile loss and quantile random forest,[0],[0]
"ρτ (z) = z(τ −1I{z<0}) (Koenker, 2005).",2.3. Quantile loss and quantile random forest,[0],[0]
"Now let the loss function in Algorithm 1 be the quantile loss ρτ (·), F be the family of constant functions, and w(Xi, x) be random forest weights (3).",2.3. Quantile loss and quantile random forest,[0],[0]
"Solving the optimization problem
Ŷτ (x) = argmin λ∈R n∑ i=1 w(Xi, x)ρτ (Yi − λ),
we get the corresponding first order condition
n∑ i=1 w(Xi, x)(τ",2.3. Quantile loss and quantile random forest,[0],[0]
"− 1I {Yi − Ŷτ (x) < 0}) = 0.
Recall that ∑n i=1 w(Xi, x) = 1, hence, we have
n∑ i=1 w(Xi, x) 1I {Yi < Ŷτ",2.3. Quantile loss and quantile random forest,[0],[0]
"(x)} = τ. (7)
The estimator Ŷτ (x) in (7) is exactly the same estimator proposed in (Meinshausen, 2006).",2.3. Quantile loss and quantile random forest,[0],[0]
"In particular, when τ = 0.5, the equation ∑n i=1 w(Xi, x) 1I {Yi < Ŷ0.5(x)} = 0.5 will give us the median estimator Ŷ0.5(x).",2.3. Quantile loss and quantile random forest,[0],[0]
"Therefore, we have rediscovered quantile random forest from a totally different point of view as a local regression estimator with quantile loss function and random forest weights.",2.3. Quantile loss and quantile random forest,[0],[0]
"From the framework 1, quantile random forest is insensitive to outliers because of the more robust loss function.",3. Robust forest,[0],[0]
"In this section, we test our framework on other robust losses and proposed fixed-point method to solve the estimating
equation.",3. Robust forest,[0],[0]
"In Section 3.1 we choose the famous robust loss – (pseudo) Huber loss, and in Section 3.2, we further investigate a non-convex loss – Tukey’s biweight.",3. Robust forest,[0],[0]
"The Huber loss (Huber et al., 1964)
Hδ(y) =
{ 1 2y
2 for |y| ≤ δ, δ(|y| − 12δ) elsewhere
is a well-known loss function used in robust regression.",3.1. Huber loss,[0],[0]
"The penalty acts like squared error loss when the error is within [−δ, δ] but becomes linear outside this range.",3.1. Huber loss,[0],[0]
"In this way, it will penalize the outliers more lightly but still preserves more efficiency than absolute deviation when data is concentrated in the center and has light tails (e.g. Normal).",3.1. Huber loss,[0],[0]
"By plugging Huber loss into the FTR framework 1, we get a robust counterpart of random forest.",3.1. Huber loss,[0],[0]
"The estimating equation is
n∑ i=1 wi(x) sign(Ŷ (x)− Yi) min(Ŷ",3.1. Huber loss,[0],[0]
"(x)− Yi, δ) = 0.",3.1. Huber loss,[0],[0]
"(8)
Direct optimization of (8) with local weights is hard, hence instead we will investigate the pseudo-Huber loss (see Figure 1),
Lδ(y) = δ 2 (√ 1 + (y δ )2 − 1 ) which is a smooth approximation of Huber loss (Charbonnier et al., 1997).",3.1. Huber loss,[0],[0]
"The estimating equation
n∑ i=1",3.1. Huber loss,[0],[0]
wpHi (x) ( ŶpH(x)− Yi ) = 0.,3.1. Huber loss,[0],[0]
"(9)
is very similar to that of square error loss if we define a new weight
wpHi (x) = wi(x)√
1 + ( ŶpH(x)−Yi
δ )2 .",3.1. Huber loss,[0],[0]
"(10) Then the (pseudo) Huber estimator can be expressed as
ŶpH(x) =
∑n i=1",3.1. Huber loss,[0],[0]
"w
pH i (x)Yi∑n
i=1",3.1. Huber loss,[0],[0]
w pH,3.1. Huber loss,[0],[0]
"i (x)
.",3.1. Huber loss,[0],[0]
"(11)
Informally, the estimator (11) can be viewed as a weighted average of all the responses Yi’s.",3.1. Huber loss,[0],[0]
"From (10), we know the new weight for pseudo-Huber loss has an extra scaling factor (√
1 + (δ−1u)2 )−1
(12)
and hence will shrink more to zero whenever δ−1|ŶpH(x)− Yi| is large.",3.1. Huber loss,[0],[0]
The tuning parameter δ acts like a control of the level of robustness.,3.1. Huber loss,[0],[0]
"A smaller δ will lead to more shrinkage on the weights of data that have responses far away from the estimator.
",3.1. Huber loss,[0],[0]
The estimating equation (9) can be solved by fix-point method which we propose in Algorithm 2.,3.1. Huber loss,[0],[0]
"For notation simplicity, we will use wi,j to denote w(Xi, xj), where Xi is the i-th training point and xj is the j-th testing point.",3.1. Huber loss,[0],[0]
"The convergence to the unique solution (if exists) is guaranteed by Lemma 1.
",3.1. Huber loss,[0],[0]
Lemma 1.,3.1. Huber loss,[0],[0]
"Define
Kδ(y) =
∑n i=1
wiYi√ 1+( y−Yiδ )
2∑n i=1
wi√ 1+( y−Yiδ ) 2 ,
Algorithm 2 pseudo-Huber loss (δ)
",3.1. Huber loss,[0],[0]
"Input: Test points {xj}mj=1, initial guess {Ŷ (0)(xj)}, local weights wi,j , training responses {Yi}ni=1, and error tolerance 0.",3.1. Huber loss,[0],[0]
"while > 0 do
(a) Update the weights
w (k) i,j = wi,j√ 1 + ( Ŷ (k−1)(xj)−Yi
δ )2 (b) Update the estimator
Ŷ (k)(xj) =
∑n i=1",3.1. Huber loss,[0],[0]
"w
(k) i,j Yi∑n
i=1",3.1. Huber loss,[0],[0]
w (k),3.1. Huber loss,[0],[0]
"i,j
(c) Calculate error
= 1
m",3.1. Huber loss,[0],[0]
m∑ j=1,3.1. Huber loss,[0],[0]
( Ŷ k(xj)− Ŷ (k−1)(xj) )2,3.1. Huber loss,[0],[0]
(d),3.1. Huber loss,[0],[0]
k,3.1. Huber loss,[0],[0]
"← k + 1
end while Output the pseudo-Huber estimator:
ŶpH(xj) =",3.1. Huber loss,[0],[0]
"Ŷ (k)(xj)
where",3.1. Huber loss,[0],[0]
∑n i=1 wi = 1.,3.1. Huber loss,[0],[0]
"Let K = maxi=1,··· ,n |Yi|.",3.1. Huber loss,[0],[0]
"Then Algorithm 2 can be written as Ŷ (k)(x) = Kδ(Ŷ (k−1)), and converges exponentially to a unique solution as long as δ > 2K.
From Lemma 1, we know it is important to standardize the responses Yi so that δ will be of the same scale for different problems.",3.1. Huber loss,[0],[0]
"In practice, we observe that one will not need to choose δ that satisfies the worst-case condition δ",3.1. Huber loss,[0],[0]
"> K in order for convergence, but making δ too small does lead to slow convergence rate.",3.1. Huber loss,[0],[0]
"For assigning the initial guess Ŷ (0), two simplest ways are to either take the random forest estimator we got or a constant vector equaling to the sample mean.",3.1. Huber loss,[0],[0]
"Throughout the rest of this paper, we will choose the weights to be random forest weights (3).",3.1. Huber loss,[0],[0]
"Non-convex function has played an important role in the context of robust regression (Huber, 2011; Hampel et al., 2011).",3.2. Tukey’s biweight,[0],[0]
"Unlike convex losses, the penalization on the errors can be bounded and hence the contribution of outliers in the estimating equation will eventually vanish.",3.2. Tukey’s biweight,[0],[0]
"Our forest regression framework 1 also incorporates the nonconvex losses which will show through the Tukey’s biweight function Tδ(·) (Huber, 2011), which is an example
of redescending loss whose derivative will vanish to zero as the input goes outside the interval",3.2. Tukey’s biweight,[0],[0]
"[−δ, δ].",3.2. Tukey’s biweight,[0],[0]
"It is defined in the following way:
d
dy Tδ(y) = y",3.2. Tukey’s biweight,[0],[0]
"( 1− y 2 δ2 )2 for |y| ≤ δ,
0 elsewhere.
",3.2. Tukey’s biweight,[0],[0]
"Similarly, by rearranging the estimating equation, we have
Ŷtukey(x) =
∑n i=1",3.2. Tukey’s biweight,[0],[0]
"w
tukey(Xi, x)Yi∑n i=1 w tukey(Xi, x)
where
wtukey(Xi, x) = w(Xi, x) max 1− ( Ŷtukey − Yi δ )2 , 0  with an extra scaling factor (see Figure 2)
",3.2. Tukey’s biweight,[0],[0]
"max { 1− (u δ )2 , 0 } .",3.2. Tukey’s biweight,[0],[0]
"(13)
In another word, the final estimator actually only depends on data with responses inside [−δ, δ], and the importance of any data (Xi, Yi) will be shrinking to zero when |Ŷtukey(x)− Yi| gets closer to the boundary value δ.",3.2. Tukey’s biweight,[0],[0]
"In this section, we will further use the framework 1 to investigate truncated squared error loss, and use this example to motivate the relation between random forest generalization performance and the number of adaptive nearest neighbors.",4. Truncated squared loss and nearest neighbors,[0],[0]
"For the truncated squared error loss
Sδ(y) =
{ 1 2y
2 for |y| ≤ δ, 1 2δ 2 elsewhere
the corresponding estimating equation is∑ |Ŷtrunc(x)−Yi|≤δ w(Xi, x)(Ŷtrunc(x)− Yi) = 0.
If we define a new weight
wtrunc(Xi, x) = w(Xi, x) 1I{|Ŷtrunc(x)− Yi| ≤ δ}, (14)
then the estimator for truncated squared loss is
Ŷtrunc(x) =
∑n i=1",4.1. Truncated squared error,[0],[0]
"w
trunc(Xi, x)Yi∑n i=1 w trunc(Xi, x) .",4.1. Truncated squared error,[0],[0]
"(15)
The estimator (15) is like a trimmed version of the random forest estimator (2).",4.1. Truncated squared error,[0],[0]
We first sort {Yi}ni=1 and trim off the responses where |Ŷtrunc(x),4.1. Truncated squared error,[0],[0]
− Yi| > δ.,4.1. Truncated squared error,[0],[0]
"Therefore, for any truncation level δ, the estimator Ŷtrunc(x) only depends on data satisfying |Ŷtrunc(x) − Yi| ≤ δ with the same local random forest weights (1).",4.1. Truncated squared error,[0],[0]
"In classical random forest, all the data with positive weights (3) are included when calculating the final estimator Ŷ (x).",4.2. Random Forest Nearest Neighbors,[0],[0]
"However, from section 4.1, we know in order to achieve robustness, some of the data should be dropped out of consideration.",4.2. Random Forest Nearest Neighbors,[0],[0]
"For example, using the truncated squared error loss, we will only consider the data satisfying |Yi − Ŷtrunc(x)| ≤ δ.",4.2. Random Forest Nearest Neighbors,[0],[0]
"In classical random forest, the criterion of tree split is to reduce the mean squared error, then in most cases, data points inside one terminal node will tend to have more similar responses.",4.2. Random Forest Nearest Neighbors,[0],[0]
"So informally larger |Ŷtrim(x)−Yi|will indicate smaller local weightw(Xi, x).",4.2. Random Forest Nearest Neighbors,[0],[0]
"Therefore, instead of solving for (15), we investigate a related estimator
Ŷwt(x) = ∑ w(Xi,x)≥ w(Xi, x)Yi∑ w(Xi,x)≥ w(Xi, x)
(16)
where > 0 is a constant in (0, 1).",4.2. Random Forest Nearest Neighbors,[0],[0]
"Recall that in (Lin & Jeon, 2006), they show all the observations with positive weights are considered voting points for random forest estimator.",4.2. Random Forest Nearest Neighbors,[0],[0]
"However, (16) implies that we should drop observations with weights smaller than a threshold in order for the robustness.",4.2. Random Forest Nearest Neighbors,[0],[0]
"More formally, let σ be a permutation such that w(Xσ(1), x) ≥ · · · ≥ w(Xσ(n0), x) > 0, then (2) is equivalent to
Ŷ (x) = n0∑ i=1",4.2. Random Forest Nearest Neighbors,[0],[0]
"w(Xσ(i), x)Yσ(i).
",4.2. Random Forest Nearest Neighbors,[0],[0]
"Then we can define the k random forest nearest neighbors (k-RFNN) of x to be {Xσ(1), · · · , Xσ(k)}, k ≤ n0, and get predictor
Ŷk(x) = k∑ i=1 w̃(Xσ(i), x)Yσ(i), (17)
where w̃(Xσ(i), x) = w(Xσ(i), x)/ ∑k j=1 w(Xσ(i), x).",4.2. Random Forest Nearest Neighbors,[0],[0]
"In the numerical experiments (Section 5.3), we will test the performance of the estimator (17) with different k, and show that by merely choosing the right number of nearest neighbors, one can largely improve the performance of classical random forest.
Shi and Horvath (2006) proposed a similar ensemble tree based nearest neighbor method.",4.2. Random Forest Nearest Neighbors,[0],[0]
"In their approach, if the observations Xi and Xj lie in the same leaf, then the similarity between them is increased by one.",4.2. Random Forest Nearest Neighbors,[0],[0]
"At the end, the similarities are normalized by dividing the total number of trees in the forest.",4.2. Random Forest Nearest Neighbors,[0],[0]
"Therefore, their weights (similarities) w(Xi, x) will be m−1 ∑m t=1 1I{Xi∈Rl(x,θ)} contrast to (3).",4.2. Random Forest Nearest Neighbors,[0],[0]
"So different from their approach, for random forest, the similarity between Xi and Xj will be increased by 1/#{p :",4.2. Random Forest Nearest Neighbors,[0],[0]
"Xp ∈ Rl(Xi,θ)} if they both lie in the same leaf l(Xi, θ).",4.2. Random Forest Nearest Neighbors,[0],[0]
This means the increment in the similarity also depends on the number of data points in the leaf.,4.2. Random Forest Nearest Neighbors,[0],[0]
"In this section, we plug in the quantile loss, Huber loss and Tukey’s biweight loss into the general forest framework and compare these algorithms with random forest.",5. Experiments,[0],[0]
"Unless otherwise stated, for both Huber and Tukey forest, the error tolerance is set to be 10−6, and every forest is an ensemble of 1000 trees with maximum terminal node size 10.",5. Experiments,[0],[0]
"The robust parameter δ are set to be 0.005 and 0.8 for Huber and Tukey forest, respectively.",5. Experiments,[0],[0]
"We generate 1000 training data points from a Uniform distribution on [−5, 5] and another 1000 testing points from the same distribution.",5.1. One dimensional toy example,[0],[0]
"The true underlying model is Y = X2 + , ∼ N (0, 1).",5.1. One dimensional toy example,[0],[0]
"But on the training samples, we choose 20% of the data and add noise 2T2 to the responses, where T2 follows t-distribution with degree of freedom 2.
",5.1. One dimensional toy example,[0],[0]
"In Figure 3, we plot the true squared curve and different forest predictions.",5.1. One dimensional toy example,[0],[0]
"It is clear that Huber and Tukey forest achieve competitive robustness as quantile random forest, and can almost recover the true underlying distribution, but random forest is largely impacted by the outliers.",5.1. One dimensional toy example,[0],[0]
"We also repeat the experiments for 20 times, and report the average mean squared error (MSE), mean absolute deviation (MAD) and median absolute percentage error (MAPE) in Table 1.",5.1. One dimensional toy example,[0],[0]
"We generate data from 10 dimensional Normal distribution, i.e. X ∼ N10(~0,Σ).",5.2. Multivariate example,[0],[0]
"Then we test out algorithms on following models.
",5.2. Multivariate example,[0],[0]
"(1) Y = ∑10 i=1X 2 i + and ∼ N (0, 1), Σ = I.
(2) Y = ∑10 i=1X 2 i + and ∼ N (0, 1), Σ = Toeplitz(ρ = 0.7).
",5.2. Multivariate example,[0],[0]
"Then for each model, we randomly choose η proportion of the training samples and add noise 15T2 where T2 follows t-distribution with degree of freedom 2.",5.2. Multivariate example,[0],[0]
"The noise level η ∈ {0, 0.05, 0.1, 0.15, 0.2}.",5.2. Multivariate example,[0],[0]
The results are summarized in Table 2 and 3.,5.2. Multivariate example,[0],[0]
"On the clean data, random forest still play the best, however, Huber forest’s performance is also competitive and lose less efficiency than QRF and Tukey forest.",5.2. Multivariate example,[0],[0]
"On the noisy data, all three robust methods outperform random forest.",5.2. Multivariate example,[0],[0]
"Among them, Huber forest is most robust and stable.",5.2. Multivariate example,[0],[0]
"In this section, we check how the number of adaptive nearest neighbors k in (17) will have impact on the performance of k-RFNN.",5.3. Nearest neighbors,[0],[0]
"We consider the same two models (1) and (2), and keep both training sample size and testing sample size to be 1000.",5.3. Nearest neighbors,[0],[0]
"The relations between MSE, MAD and the number of adaptive nearest neighbors are illustrated in Figure 4.",5.3. Nearest neighbors,[0],[0]
Recall that k-RFNN with all 1000 neighbors is equivalent to random forest.,5.3. Nearest neighbors,[0],[0]
"From the figures, we clearly observe a kink at k = 15, which is much less than 1000.",5.3. Nearest neighbors,[0],[0]
"We take two regression datasets from UCI machine learning repository (Lichman, 2013), and one real estate dataset from OpenIntro.",5.4. Real data,[0],[0]
"For each dataset, we randomly choose 2/3 observations for training and the rest for testing.",5.4. Real data,[0],[0]
MSE and MAD are reported by averaging over 20 trials.,5.4. Real data,[0],[0]
The results are presented in Table 4.,5.4. Real data,[0],[0]
"To further test the robustness, we then repeat the experiment but add extra T2 noise to 20%
of the standardized training data response variables everytime.",5.4. Real data,[0],[0]
The results are in Table 5.,5.4. Real data,[0],[0]
"Robust forests outperform random forest in most of the cases except for Ames data sets, on which quantile random forest behaves poorly.",5.4. Real data,[0],[0]
"The experimental results show that Huber forest, Tukey forest and quantile random forest are all much more robust than random forest in the presence of outliers.",6. Conclusion and discussion,[0],[0]
"However, without outliers, Huber forest preserves more efficiency than the other two robust methods.",6. Conclusion and discussion,[0],[0]
"We did not cross validate the parameter δ for different noise levels, so one would
expect even better performance after carefully tuning the parameter.
",6. Conclusion and discussion,[0],[0]
"Besides random forest weights, other data dependent similarities could also be used in Algorithm 1.",6. Conclusion and discussion,[0],[0]
We could also design loss functions which optimizes a metric for specific problems.,6. Conclusion and discussion,[0],[0]
The fixed-point method could be replaced by other more efficient algorithms.,6. Conclusion and discussion,[0],[0]
The framework could be easily extended to classification problems.,6. Conclusion and discussion,[0],[0]
All these will be potential future work.,6. Conclusion and discussion,[0],[0]
Proof.,7.1. Proof of Lemma 1,[0],[0]
"Because Ŷ (k)(x) = Kδ(Ŷ (k−1)) which is a fixedpoint method, we only need to show ∣∣∣K ′δ(y)∣∣∣ < 1 in order for the existence and uniqueness of the solution.",7.1. Proof of Lemma 1,[0],[0]
"Define the normalized weight
w̃i = wi√
1 + ( y−Yi δ
)2 / n∑
i=1 wi√",7.1. Proof of Lemma 1,[0],[0]
"1 + ( y−Yi δ )2 , we have ∑n i=1 w̃i = 1, and
∣∣∣K ′δ(y)∣∣∣ ≤
∣∣∣∣∣∣ n∑ i=1",7.1. Proof of Lemma 1,[0],[0]
w̃iYi  n∑ j=1 (1I(i = j)− w̃j),7.1. Proof of Lemma 1,[0],[0]
y,7.1. Proof of Lemma 1,[0],[0]
− Yj δ2 +,7.1. Proof of Lemma 1,[0],[0]
(y − Yj)2,7.1. Proof of Lemma 1,[0],[0]
"∣∣∣∣∣∣ ≤ 2
n∑ i=1",7.1. Proof of Lemma 1,[0],[0]
"w̃i |Yi| max i=1,··· ,n ( |y",7.1. Proof of Lemma 1,[0],[0]
− Yi| δ2 +,7.1. Proof of Lemma 1,[0],[0]
(,7.1. Proof of Lemma 1,[0],[0]
"y − Yi)2 )
",7.1. Proof of Lemma 1,[0],[0]
= 2 n∑ i=1,7.1. Proof of Lemma 1,[0],[0]
"w̃i |Yi| 1 mini=1,··· ,n (",7.1. Proof of Lemma 1,[0],[0]
"δ2 |y−Yi| + |y − Yi| )
≤ max i=1,··· ,n
|Yi| 1
δ .
",7.1. Proof of Lemma 1,[0],[0]
"Therefore, ∣∣∣K ′δ(y)∣∣∣ < 12 if δ > 2 maxi=1,··· ,n |Yi| = 2K.",7.1. Proof of Lemma 1,[0],[0]
"We would like to thank Stan Humphrys and Zillow for supporting this research, as well as three anonymous referees for their insightful comments.",Acknowledgements,[0],[0]
Part of the implementation in this paper is based on Zillow code library.,Acknowledgements,[0],[0]
This paper introduces a new general framework for forest-type regression which allows the development of robust forest regressors by selecting from a large family of robust loss functions.,abstractText,[0],[0]
"In particular, when plugged in the squared error and quantile losses, it will recover the classical random forest (Breiman, 2001) and quantile random forest (Meinshausen, 2006).",abstractText,[0],[0]
We then use robust loss functions to develop more robust foresttype regression algorithms.,abstractText,[0],[0]
"In the experiments, we show by simulation and real data that our robust forests are indeed much more insensitive to outliers, and choosing the right number of nearest neighbors can quickly improve the generalization performance of random forest.",abstractText,[0],[0]
Forest-type Regression with General Losses  and Robust Forest,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 47–57 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Due to the advent of computing technologies to indigenous communities all over the world, natural language processing (NLP) applications
∗*The first two authors contributed equally.
for languages with limited computer-readable textual data are getting increasingly important.",1 Introduction,[0],[0]
"This contrasts with current research, which focuses strongly on approaches which require large amounts of training data, e.g., deep neural networks.",1 Introduction,[0],[0]
"Those are not trivially applicable to minimal-resource settings with less than 1, 000 available training examples.",1 Introduction,[0],[0]
"We aim at closing this gap for morphological surface segmentation, the task of splitting a word into the surface forms of its smallest meaning-bearing units, its morphemes.
",1 Introduction,[0],[0]
Recovering morphemes provides information about unknown words and is thus especially important for polysynthetic languages with a high morpheme-to-word ratio and a consequently large overall number of words.,1 Introduction,[0],[0]
"To illustrate how segmentation helps understanding unknown multiplemorpheme words, consider an example in this paper’s language of writing: even if the word unconditionally did not appear in a given training corpus, its meaning could still be derived from a combination of its morphs un, condition, al and ly.
",1 Introduction,[0],[0]
"Due to its importance for down-stream tasks (Creutz et al., 2007; Dyer et al., 2008), segmentation has been tackled in many different ways, considering unsupervised (Creutz and Lagus, 2002), supervised (Ruokolainen et al., 2013) and semisupervised settings (Ruokolainen et al., 2014).",1 Introduction,[0],[0]
"Here, we add three new questions to this line of research: (i) Are data-hungry neural network models
47
applicable to segmentation of polysynthetic languages in minimal-resource settings?",1 Introduction,[0],[0]
(ii) How can the performance of neural networks for surface segmentation be improved if we have only unlabeled or no external data at hand?,1 Introduction,[0],[0]
(iii) Is crosslingual transfer for this task possible between related languages?,1 Introduction,[0],[0]
"The last two questions are crucial: While for many languages it is difficult to obtain the number of annotated examples used in earlier work on (semi-)supervised methods, a limited amount might still be obtainable.
",1 Introduction,[0],[0]
"We experiment on four polysynthetic Mexican languages: Mexicanero, Nahuatl, Wixarika and Yorem Nokki (details in §2).",1 Introduction,[0],[0]
"The datasets we use are, as far as we know, the first computer-readable datasets annotated for morphological segmentation in those languages.
",1 Introduction,[0],[0]
Our experiments show that neural seq2seq models perform on par with or better than other strong baselines for our polysynthetic languages in a minimal-resource setting.,1 Introduction,[0],[0]
"However, we further propose two novel multi-task approaches and two new data augmentation methods.",1 Introduction,[0],[0]
"Combining them with our neural model yields up to 5.05% absolute accuracy or 3.40% F1 improvements over our strongest baseline.
",1 Introduction,[0],[0]
"Finally, following earlier work on cross-lingual knowledge transfer for seq2seq tasks (Johnson et al., 2017; Kann et al., 2017), we investigate training one single model for all languages, while sharing parameters.",1 Introduction,[0],[0]
"The resulting model performs comparably to or better than the individual models, but requires only roughly as many parameters as one single model.
",1 Introduction,[0],[0]
Contributions.,1 Introduction,[0],[0]
"To sum up, we make the following contributions: (i) we confirm the applicability of neural seq2seq models to morphological segmentation of polysynthetic languages in minimalresource settings; (ii) we propose two novel multi-task training approaches and two novel data augmentation methods for neural segmentation models; (iii) we investigate the effectiveness of cross-lingual transfer between related languages; and (iv) we provide morphological segmentation datasets for Mexicanero, Nahuatl, Wixarika and Yorem Nokki.",1 Introduction,[0],[0]
"Polysynthetic languages are morphologically rich languages which are highly synthetic, i.e., single words can be composed of many individual
morphemes.",2 Polysynthetic Languages,[0],[0]
"In extreme cases, entire sentences consist of only one single token, whereupon “every argument of a predicate must be expressed by morphology on the word that contains that assigner” (Baker, 2006).",2 Polysynthetic Languages,[0],[0]
"This property makes surface segmentation of polysynthetic languages at the same time complex and particularly relevant for further linguistic analysis.
",2 Polysynthetic Languages,[0],[0]
"In this paper, we experiment on four polysynthetic languages of the Yuto-Aztecan family (Baker, 1997), with the goal of improving the performance of neural seq2seq models.",2 Polysynthetic Languages,[0],[0]
"The languages will be described in the rest of this section.
",2 Polysynthetic Languages,[0],[0]
"Mexicanero is a Western Peripheral Nahuatl variant, spoken in the Mexican state of Durango by approximately one thousand people.",2 Polysynthetic Languages,[0],[0]
"This dialect is isolated from the rest of the other branches and has a strong process of Spanish stem incorporation, while also having borrowed some suffixes from that language (Vanhove et al., 2012).",2 Polysynthetic Languages,[0],[0]
It is common to see Spanish words mixed with Nahuatl agglutinations.,2 Polysynthetic Languages,[0],[0]
"In the following example we can see an intrasentencial mixing of Spanish (in uppercases) and Mexicanero:
u|ni|ye MALO – I was sick
Nahuatl is a large subgroup of the YutoAztecan language family, and, including all of its variants, the most spoken native language in Mexico.",2 Polysynthetic Languages,[0],[0]
"Its almost two million native speakers live mainly in Puebla, Guerrero, Hidalgo, Veracruz, and San Luis Potosi, but also in Oaxaca, Durango, Modelos, Mexico City, Tlaxcala, Michoacan, Nayarit and the State of Mexico.",2 Polysynthetic Languages,[0],[0]
"Three dialectical groups are known: Central Nahuatl, Occidental Nahuatl and Oriental Nahuatl.",2 Polysynthetic Languages,[0],[0]
"The data collected for this work belongs to the Oriental branch spoken by 70 thousand people in Northern Puebla.
",2 Polysynthetic Languages,[0],[0]
"Like all languages of the Yuto-Aztecan family, Nahuatl is agglutinative and one word can consist of a combination of many different morphemes.",2 Polysynthetic Languages,[0],[0]
"Usually, the verb functions as the stem and gets extended by morphemes specifying, e.g., subject, patient, object or indirect object.",2 Polysynthetic Languages,[0],[0]
The most common syntax sequence for Nahuatl is SOV.,2 Polysynthetic Languages,[0],[0]
"An example word is:
o|ne|mo|kokowa|ya – I was sick
Wixarika is a language spoken in the states of Jalisco, Nayarit, Durango and Zacatecas in Central West Mexico by approximately fifty thousand people.",2 Polysynthetic Languages,[0],[0]
It belongs to the Coracholan group of languages within the Yuto-Aztecan family.,2 Polysynthetic Languages,[0],[0]
"Wixarika has five vowels {a,e,i,+1,u} with long and short variants.",2 Polysynthetic Languages,[0],[0]
"An example for a word in the language is:
ne|p+|ti|kuye|kai – I was sick
Like Nahuatl, it has an SOV syntax, with heavy agglutination on the verb.",2 Polysynthetic Languages,[0],[0]
"Wixarika is morphologically more complex than other languages from the same family, because it incorporates more information into the verb (Leza and López, 2006).",2 Polysynthetic Languages,[0],[0]
"This leads to a higher number of morphemes per word as can also be seen in Table 3.
",2 Polysynthetic Languages,[0],[0]
Yorem Nokki is part of Taracachita subgroup of the Yuto-Aztecan language family.,2 Polysynthetic Languages,[0],[0]
"Its Southern dialect is spoken by close to forty thousand people in the Mexican states of Sinaloa and Sonora, while its Northern dialect has about twenty thousand speakers.",2 Polysynthetic Languages,[0],[0]
"In this work, we consider the Southern dialect.",2 Polysynthetic Languages,[0],[0]
"The nominal morphology of Yorem
1While linguists often use a dashed i (i) to denote this vowel, in practice almost all native speakers use a plus symbol (+).",2 Polysynthetic Languages,[0],[0]
"In this work, we choose to use the latter.
",2 Polysynthetic Languages,[0],[0]
"Nokki is rather simple, but, like in the other YutoAztecan languages, the verb is highly complex.",2 Polysynthetic Languages,[0],[0]
Its alphabet consists of 28 characters and contains 8 different vowels.,2 Polysynthetic Languages,[0],[0]
"An example verb is:
ko’kore|ye|ne – I was sick",2 Polysynthetic Languages,[0],[0]
"To create our datasets, we make use of both segmentable (i.e., consisting of multiple morphemes) and non-segmentable (i.e., consisting of one single morpheme) words described in books of the collection Archive of Indigenous Languages in Mexicanero (Canger, 2001), Nahuatl (Lastra de Suárez, 1980), Wixarika (Gómez and López, 1999), and Yorem Nokki (Freeze, 1989).",3 Morphological Segmentation Datasets,[0],[0]
"Statistics about the data in the four languages are displayed in Tables 1, 2 and 3.",3 Morphological Segmentation Datasets,[0],[0]
We include segmentable as well as non-segmentable words into our datasets in order to ensure that our methods can correctly decide against splitting up single morphemes.,3 Morphological Segmentation Datasets,[0],[0]
"The phrases in all languages are mostly parallel, such that the corpora are roughly equivalent.",3 Morphological Segmentation Datasets,[0],[0]
"Therefore, we can compare the morphology of translated words (cf. Table 3), noticing that the language with most agglutination is Wixarika, with an average rate of 3.25 morphemes per word; the other languages have an average of close to 2.2 morphemes per word.",3 Morphological Segmentation Datasets,[0],[0]
This higher morphological complexity naturally produces data sparsity at the token level.,3 Morphological Segmentation Datasets,[0],[0]
"Also, we can notice that Wixarika has more unique words than the rest of our studied languages.",3 Morphological Segmentation Datasets,[0],[0]
"However, Nahuatl has with 810 the highest number of unique morphemes.
",3 Morphological Segmentation Datasets,[0],[0]
Final splits.,3 Morphological Segmentation Datasets,[0],[0]
"In order to make follow-up work on minimal-resource settings for morphological segmentation easily comparable, we provide predefined splits of our datasets2.",3 Morphological Segmentation Datasets,[0],[0]
40% of the data constitute the test sets.,3 Morphological Segmentation Datasets,[0],[0]
"Of the remaining data, we
2Our datasets can be found together with the code of our models at http://turing.iimas.unam.mx/wix/MexSeg .
use 20% for development and the rest for training.",3 Morphological Segmentation Datasets,[0],[0]
The final numbers of words per dataset and language are shown in Table 2.,3 Morphological Segmentation Datasets,[0],[0]
"In the beginning of this section, we will introduce our neural architecture for segmentation.",4 Neural Seq2seq Models for Segmentation,[0],[0]
"Subsequently, we will first describe our two proposed multi-task training approaches and second our data augmentation methods.",4 Neural Seq2seq Models for Segmentation,[0],[0]
"Finally, we will elaborate on expected differences between the two.",4 Neural Seq2seq Models for Segmentation,[0],[0]
"Following work on segmentation by Kann et al. (2016) for high-resource settings, our approach is based on the neural seq2seq model introduced by Bahdanau et al. (2015) for machine translation.
Encoder.",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"The first part of our model is a bidirectional recurrent neural network (RNN) which encodes the input sequence, i.e., the sequence of characters of a given word w = w1, w2, . . .",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
", wTv , represented by the corresponding embedding vectors vw1 , ..., vwTv .",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"In particular, our encoder consists of one gated recurrent neural network (GRU) which processes the input in forward direction and a second GRU which processes the input from the opposite side.
",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
Encoding with this bidirectional GRU yields the forward hidden state −→ h i = f,4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"(−→ h i−1, vi ) and the backward hidden state ←−",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
h,4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"i = f (←− h i+1, vi ) , for a non-linear activation function f .",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
Their concatenation hi =,4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"[−→ hi ; ←− hi ] is passed on to the decoder.
",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
Decoder.,4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"The second part of our network, the decoder, is a single GRU, defining a probability distribution over strings in (Σ ∪ S)∗, for an alphabet Σ and a separation symbol S:
pED(c | w) = Tc∏
t=1
p(ct | c1, . . .",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
", ct−1, w).",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"(1)
where p(ct | c1, . . .",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
", ct−1, w) is computed using an attention mechanism and an output softmax layer over Σ ∪ S.
A more detailed description of the general attention-based encoder-decoder architecture can be found in the original paper by Bahdanau et al. (2015).",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"In order to leverage unlabeled data or even random strings during training, we define an autoencoding auxiliary task, which consists of encoding the input and decoding an output which is identical to the original string.
",5.1 Multi-Task Training,[0],[0]
"Then, our multi-task training objective is to maximize the joint log-likelihood of this auxiliary task and our segmentation main task:
L(θ)= ∑
(w,c)∈T log pθ (c | e(w))",5.1 Multi-Task Training,[0],[0]
"(2)
+ ∑
a∈A log pθ(a | e(a))
",5.1 Multi-Task Training,[0],[0]
T denotes the segmentation training data with examples consisting of a word w and its segmentation c. A denotes either a set of words in the language of the system or a set of random strings.,5.1 Multi-Task Training,[0],[0]
"The function e describes the encoder and depends on the model parameters θ, which are shared across the two tasks.",5.1 Multi-Task Training,[0],[0]
"For training, we use data from both sets at the same time and mark each example with an additional, task-specific input symbol.
",5.1 Multi-Task Training,[0],[0]
We treat the size of A as a hyperparameter which we optimize on the development set separately for each language.,5.1 Multi-Task Training,[0],[0]
"Values we experiment with are m times the amount of instances in the original training set, with m ∈ {1, 2, 4, 8}.3
3An exception is Yorem Nokki, for which we do not have enough unlabeled data available, such that we experiment only with m ∈ {1, 2}.
",5.1 Multi-Task Training,[0],[0]
There are multiple reasons why we expect multi-task training to improve the performance of the final model.,5.1 Multi-Task Training,[0],[0]
"First, multi-task training should act as a regularizer.",5.1 Multi-Task Training,[0],[0]
"Second, for our models, the segmentation task consists in large parts of learning to copy the input character sequence to the output.",5.1 Multi-Task Training,[0],[0]
"This, however, can be learned from any string and does not require annotated segmentation boundaries.",5.1 Multi-Task Training,[0],[0]
"Third, in the case of unlabeled data (i.e., not for random strings), we expect the character language model in the decoder to improve, since it is trained on additional data.
",5.1 Multi-Task Training,[0],[0]
We denote models trained with multi-task training using unlabeled corpus data as MTT-U and models trained with multi-task training using random strings as MTT-R.,5.1 Multi-Task Training,[0],[0]
A second option to make use of unlabeled data or random strings is to extend the available training data with new examples made from those.,5.2 Data Augmentation,[0],[0]
The main question to answer here is how to include the new data into the existing datasets.,5.2 Data Augmentation,[0],[0]
We do this by building new training examples in a fashion similar to the multi-task setup.,5.2 Data Augmentation,[0],[0]
"All newly created instances are of the form
w 7→ w (3)
where either w ∈ V with V being the observed vocabulary of the language, e.g., words in a given unlabeled corpus, or w ∈ R with R being a set of sequences of random characters from the alphabet Σ of the language.
",5.2 Data Augmentation,[0],[0]
"Again, we treat the amount of additional training examples as a hyperparameter which we optimize on the development set separately for each language.",5.2 Data Augmentation,[0],[0]
"We explore m times the amount of instances in the original training set, with m ∈ {1, 2, 4, 8}.
",5.2 Data Augmentation,[0],[0]
"The reasons why we expect our data augmentation methods to lead to better segmentation models are similar to those for multi-task training.
",5.2 Data Augmentation,[0],[0]
"We call models trained on datasets augmented with unlabeled corpus data or random strings DAU or DA-R, respectively.",5.2 Data Augmentation,[0],[0]
The difference between MTT-U (resp.,5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
MTT-R) and DA-U (resp.,5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"MTT-U) is a single element in the input sequence (the one representing the task).
",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"However, this information enables the model to handle each given instance correctly at inference time.",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"As a result, it gets more robust against noisy data, which seems crucial for our way of using unlabeled corpora.",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"Consider, for example, the Nahuatl word onemokokowaya.",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"Training on
onemokokowaya 7→ onemokokowaya
will make the model learn not to segment words which consist of the morphemes o, ne,mo, kokowa, ya, which should ultimately hurt performance.",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"The multi-task approach, in contrast, mitigates this problem.
",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"As a conclusion, we expect the data augmentation approach with unlabeled data to not obtain outstanding performance, but rather consider it an important and informative baseline for the corresponding multi-task approach.",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"Using random strings, the difference between the multi-task and the data augmentation approaches is less obvious: Real morphemes should appear rarely enough in the created random character sequences to avoid the negative effect which we expect for corpus words.",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
We thus assume that the performances of MTT-R and DA-R should be similar.,5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
We apply our models to the datasets described in §3.,6.1 Data,[0],[0]
"For the multi-task training and data augmentation using unlabeled data, we use (unsegmented) words from a parallel corpus collected by Gutierrez-Vasques et al. (2016) for Nahuatl and the closely related Mexicanero.",6.1 Data,[0],[0]
For Wixarika we use data from Mager et al. (2018) and for Yorem Nokki we use text from Maldonado,6.1 Data,[0],[0]
Martı́nez,6.1 Data,[0],[0]
et al. (2010).,6.1 Data,[0],[0]
"Now, we will describe the baselines we use to evaluate the overall performance of our approaches.
",6.2 Baselines,[0],[0]
Supervised seq2seq RNN (S2S).,6.2 Baselines,[0],[0]
"As a first baseline, we employ a fully supervised neural model without data augmentation or multi-task training, i.e., an attention-based encoder-decoder RNN (Bahdanau et al., 2015) which has been trained only on the available annotated data.
",6.2 Baselines,[0],[0]
Semi-supervised MORFESSOR (MORF).,6.2 Baselines,[0],[0]
"We further compare to the semi-supervised version
of MORFESSOR (Kohonen et al., 2010), a wellknown morphological segmentation system.",6.2 Baselines,[0],[0]
"During training, we tune the hyperparameters for each language on the respective development set.",6.2 Baselines,[0],[0]
"The best performing model is applied to the test set.
",6.2 Baselines,[0],[0]
FlatCat (FC).,6.2 Baselines,[0],[0]
"Our next baseline is FlatCat (Grönroos et al., 2014), a variant of MORFESSOR.",6.2 Baselines,[0],[0]
It consists of a hidden Markov model for segmentation.,6.2 Baselines,[0],[0]
"The states of the model correspond either to a word boundary and one of the four morph categories stem, prefix, suffix, and nonmorpheme.",6.2 Baselines,[0],[0]
"It can work in an unsupervised way, but, similar to the previous baseline, can make effective use of small amounts of labeled data.
CRF.",6.2 Baselines,[0],[0]
"We further compare to a conditional random fields (CRF) (Lafferty et al., 2001) model, in particular a strong discriminative model for segmentation by Ruokolainen et al. (2014).",6.2 Baselines,[0],[0]
"It reduces the task to a classification problem with four classes: beginning of a morph, middle of a morph, end of a morph and single character morph.",6.2 Baselines,[0],[0]
"Training is again semi-supervised and the model was previously reported to obtain good results for small amounts of unlabeled data (Ruokolainen et al., 2014), which makes it very suitable for our minimal-resource setting.",6.2 Baselines,[0],[0]
Neural network parameters.,6.3 Hyperparameters,[0],[0]
All GRUs in both the encoder and the decoder have 100- dimensional hidden states.,6.3 Hyperparameters,[0],[0]
"All embeddings are 300-dimensional.
",6.3 Hyperparameters,[0],[0]
"For training, we use ADADELTA (Zeiler, 2012) with a minibatch size of 20.",6.3 Hyperparameters,[0],[0]
"We initialize all weights to the identity matrix and biases to zero (Le et al., 2015).",6.3 Hyperparameters,[0],[0]
"All models are trained for a maximum of 200 epochs, but we evaluate after every 5 epochs and apply the best performing model at test time.",6.3 Hyperparameters,[0],[0]
"Our final reported results are averaged accuracies over 5 single training runs.
",6.3 Hyperparameters,[0],[0]
Optimizing the amount of auxiliary task data.,6.3 Hyperparameters,[0],[0]
The performance of our neural segmentation model in dependence of the amount of auxiliary task training data can be seen in Figure 1.,6.3 Hyperparameters,[0],[0]
"As a general tendency across all languages, adding more data seems better, particularly for the autoencoding task with random strings.",6.3 Hyperparameters,[0],[0]
"The only exception is Wixarika.
",6.3 Hyperparameters,[0],[0]
The final configurations we choose for m (cf.,6.3 Hyperparameters,[0],[0]
"§5.1) in the case of multi-task training with the
auxiliary task of autoencoding corpus data are m = 4 for Mexicanero, Nahuatl and Wixarika and m = 1 for Yorem Nokki.",6.3 Hyperparameters,[0],[0]
"For multi-task training with autoencoding of random strings we select m = 8 for Mexicanero, Nahuatl and Yorem Nokki and m = 4 for Wixarika.
Optimizing the amount of artificial training data for data augmentation.",6.3 Hyperparameters,[0],[0]
Figure 2 shows the performance of the encoder-decoder depending on the amount of added artificial training data.,6.3 Hyperparameters,[0],[0]
"In the case of random strings, again, adding more training data seems to help more.",6.3 Hyperparameters,[0],[0]
"However, using corpus data seems to hurt performance and the more such examples we use, the worse accuracy we obtain.",6.3 Hyperparameters,[0],[0]
"Thus, we conclude that (as expected) data augmentation with corpus data is not a good way to improve the model’s performance.",6.3 Hyperparameters,[0],[0]
"We will discuss this in more detail in §6.5.
",6.3 Hyperparameters,[0],[0]
"Even though the final conclusion should be to not add much corpus data, we apply what gives best results on the development set.",6.3 Hyperparameters,[0],[0]
"The final configurations we thus choose for DA-U are m = 1 for Mexicanero, Wixarika and Yorem Nokki and m = 2 for Nahuatl.",6.3 Hyperparameters,[0],[0]
"For DA-R, we select m = 4 for Mexicanero, Wixarika and Yorem Nokki and m = 8 for Nahuatl.",6.3 Hyperparameters,[0],[0]
Accuracy.,6.4 Evaluation Metrics,[0],[0]
"First, we evaluate using accuracy on the token level.",6.4 Evaluation Metrics,[0],[0]
"Thus, an example counts as correct if and only if the output of the system matches the reference solution exactly, i.e., if all output symbols are predicted correctly.
F1.",6.4 Evaluation Metrics,[0],[0]
"Our second evaluation metric is border F1, which measures how many segment boundaries are predicted correctly by the model.",6.4 Evaluation Metrics,[0],[0]
"While we use this metric because it is common for segmentation tasks, it is not ideal for our models since those are not guaranteed to preserve the input character sequence.",6.4 Evaluation Metrics,[0],[0]
We handle this problem as follows:,6.4 Evaluation Metrics,[0],[0]
"In order to compare borders, we identify them by the position of their preceding letter, i.e., if in both the model’s guess and the gold solution a segment border appears after the second character, it counts as correct.",6.4 Evaluation Metrics,[0],[0]
Wrong characters are ignored.,6.4 Evaluation Metrics,[0],[0]
Note that this comes with the disadvantage of erroneously inserted characters leading to all subsequent segment borders being counted as incorrect.,6.4 Evaluation Metrics,[0],[0]
Table 4 shows that accuracy and F1 seem to be highly correlated for our task.,6.5 Test Results and Discussion,[0],[0]
"The test results also give an answer to our first research question: The neural model S2S performs on par with CRF, the strongest baseline, for all languages but Nahuatl.",6.5 Test Results and Discussion,[0],[0]
"Further, S2S and CRF both outperform MORF and FC by a wide margin.",6.5 Test Results and Discussion,[0],[0]
"We may thus conclude that neural models are indeed applicable to segmentation of polysynthetic languages in a low-resource setting.
",6.5 Test Results and Discussion,[0],[0]
"Second, we can see that all our proposed methods except for DA-U improve over S2S, the neural baseline: The accuracy of MTT-U is between 0.0141 (Wixarika) and 0.0547 (Mexicanero) higher than S2S’s.",6.5 Test Results and Discussion,[0],[0]
"MTT-R improves between 0.0380 (Wixarika) and 0.0532 (Yorem
Nokki).",6.5 Test Results and Discussion,[0],[0]
"Finally, DA-R outperforms S2S by 0.0367 to 0.0479 accuracy for Yorem Nokki and Mexicanero, respectively.",6.5 Test Results and Discussion,[0],[0]
The overall picture when considering F1 looks similar.,6.5 Test Results and Discussion,[0],[0]
"Comparing our approaches to each other, there is no clear winner.",6.5 Test Results and Discussion,[0],[0]
This might be due to differences in the unlabeled data we use: the corpus we use for Mexicanero and Nahuatl is from dialects different from both respective test sets.,6.5 Test Results and Discussion,[0],[0]
"Assuming that the effect of training a language model using unlabeled data and erroneously learning to not segment words are working against each other for MTT-U, this might explain why MTT-U is best for Mexicanero and the gap between MTT-U and MTT-R is smaller for Nahuatl than for Yorem Nokki and Wixarika.
",6.5 Test Results and Discussion,[0],[0]
"As mentioned before (cf. §5.3), a simple data augmentation method using unlabeled data should
hurt performance.",6.5 Test Results and Discussion,[0],[0]
"This is indeed the result of our experiments: DA-U performs worse than S2S for all languages except for Mexicanero, where the unlabeled corpus is from another language: the closely related Nahuatl.",6.5 Test Results and Discussion,[0],[0]
"We thus conclude that multi-task training (instead of simple data augmentation) is crucial for the use of unlabeled data.
",6.5 Test Results and Discussion,[0],[0]
"Finally, our methods compare favorably to all baselines, with the exception of CRF for Nahuatl.",6.5 Test Results and Discussion,[0],[0]
"While CRF is overall the strongest baseline for our considered languages, our methods outperform it by up to 0.0214 accuracy or 0.0147 F1 for Mexicanero, 0.0322 accuracy or 0.0229 F1 for Wixarika and 0.0505 accuracy or 0.0340 F1 for Yorem Nokki.",6.5 Test Results and Discussion,[0],[0]
This shows the effectiveness of our fortified neural models for minimal-resource morphological segmentation.,6.5 Test Results and Discussion,[0],[0]
We now want to investigate the performance of one single model trained on all languages at once.,7 Cross-Lingual Transfer Learning,[0],[0]
This is done in analogy to the multi-task training described in §5.1.,7 Cross-Lingual Transfer Learning,[0],[0]
"We treat segmentation in each language as a separate task and train an attentionbased encoder-decoder model on maximizing the joint log-likelihood:
L(θ)= ∑
Li∈L
∑
(w,c)∈TLi
log pθ (c | e(w))
(4)
TLi denotes the segmentation training data in language Li and L is the set of our languages.",7 Cross-Lingual Transfer Learning,[0],[0]
"As before, each training example consists of a word w and its segmentation c.",7 Cross-Lingual Transfer Learning,[0],[0]
We keep all model parameters and the training regime as described in §6.3.,7.1 Experimental Setup,[0],[0]
"However, our training data now consists of a combination of all available training data for all 4 languages.",7.1 Experimental Setup,[0],[0]
"In order to enable the model to differentiate between the tasks,
we prepend one language-specific input symbol to each instance.",7.1 Experimental Setup,[0],[0]
This corresponds to having one embedding in the input which marks the task.,7.1 Experimental Setup,[0],[0]
"An example training instance for Yorem Nokki is
L=YN ko′koreyene 7→ ko′kore|ye|ne,
where L=YN indicates the language.",7.1 Experimental Setup,[0],[0]
Due to the previous high correlation between accuracy and F1 we only use accuracy on the word level as the evaluation metric for this experiment.,7.1 Experimental Setup,[0],[0]
"In Table 5, we show the results of the multi-lingual model, which was trained on all languages, compared to all individual models, as well as each respective best multi-task approach and data augmentation method.",7.2 Results and Discussion,[0],[0]
"The results differ among languages: Most remarkably, for both Wixarika and Nahuatl, the accuracy of the multi-lingual model is higher than the one of the single-language model.",7.2 Results and Discussion,[0],[0]
"This might be related to them being the languages with most training data available (cf. Table 3).
",7.2 Results and Discussion,[0],[0]
"Note, however, that even for the remaining two languages—Mexicanero and Yorem Nokki— we hardly lose accuracy when comparing the multi-lingual to the individual models.",7.2 Results and Discussion,[0],[0]
"Since we only use one model (instead of four), without increasing its size significantly, we thus reduce the amount of parameters by nearly 75%.",7.2 Results and Discussion,[0],[0]
"Work on morphological segmentation was started more than 6 decades ago (Harris, 1951).",8 Related Work,[0],[0]
"Since then, many approaches have been developed: In the realm of unsupervised methods, two important systems are LINGUISTICS (Goldsmith, 2001) and MORFESSOR (Creutz and Lagus, 2002).",8 Related Work,[0],[0]
"The latter was later extended to a semi-supervised version (Kohonen et al., 2010) in order to make use of the abundance of unlabeled data which is available for many languages.
",8 Related Work,[0],[0]
Ruokolainen et al. (2013) focused explicitly on low-resource scenarios and applied CRFs to morphological segmentation in several languages.,8 Related Work,[0],[0]
"They reported better results than earlier work, including semi-supervised approaches.",8 Related Work,[0],[0]
"In the following year, they extended their approach to be able to use unlabeled data as well, further improving performance (Ruokolainen et al., 2014).
",8 Related Work,[0],[0]
"Cotterell et al. (2015) trained a semi-Markov CRF (semi-CRF) (Sarawagi and Cohen, 2005) jointly on morphological segmentation, stemming and tagging.",8 Related Work,[0],[0]
"For the similar problem of Chinese word segmentation, Zhang and Clark (2008) trained a model jointly on part-of-speech tagging.",8 Related Work,[0],[0]
"However, we are not aware of any prior work on multi-task training or data augmentation for neural segmentation models.
",8 Related Work,[0],[0]
"In fact, the two only neural seq2seq approaches for morphological segmentation we know of focused on canonical segmentation (Cotterell et al., 2016) which differs from the surface segmentation task considered here in that it restores changes to the surface form of morphemes which occurred during word formation.",8 Related Work,[0],[0]
Kann et al. (2016) also used an encoder-decoder RNN and combined it with a neural reranker.,8 Related Work,[0],[0]
"While our model architecture was inspired by them, their model was purely supervised.",8 Related Work,[0],[0]
"Additionally, they did not investigate the applicability of their neural seq2seq model in low-resource settings or for polysynthetic languages.",8 Related Work,[0],[0]
Ruzsics and Samardzic (2017) extended the standard encoder-decoder architecture for canonical segmentation to contain a language model over segments and improved results.,8 Related Work,[0],[0]
"However, a big difference to our work is that they still used more than ten times as much training data as we have available for the indigenous Mexican languages we are working on here.
",8 Related Work,[0],[0]
"Another neural approach—this time for surface segmentation—was presented by Wang et al.
(2016).",8 Related Work,[0],[0]
"The authors, instead of using seq2seq models, treat the task as a sequence labeling problem and use LSTMs to classify every character either as the beginning, middle or end of a morpheme, or as a single-character morpheme.
",8 Related Work,[0],[0]
"Cross-lingual knowledge transfer via language tags was proposed for neural seq2seq models before, both for tasks that handle sequences of words (Johnson et al., 2017) and tasks that work on sequences of characters (Kann et al., 2017).",8 Related Work,[0],[0]
"However, to the best of our knowledge, we are the first to try such an approach for a morphological segmentation task.",8 Related Work,[0],[0]
"In many other areas of NLP, cross-lingual transfer has been applied successfully, e.g., in entity recognition (Wang and Manning, 2014), language modeling (Tsvetkov et al., 2016), or parsing (Cohen et al., 2011; Søgaard, 2011; Ammar et al., 2016).",8 Related Work,[0],[0]
"We first investigated the applicability of neural seq2seq models to morphological surface segmentation for polysynthetic languages in minimalresource settings, i.e., for considerably less than 1, 000 training instances.",9 Conclusion and Future Work,[0],[0]
"Although they are generally thought to require large amounts of training data, neural networks obtained an accuracy comparable to or higher than several strong baselines.
",9 Conclusion and Future Work,[0],[0]
"Subsequently, we proposed two novel multitask training approaches and two novel data augmentation methods to further increase the performance of our neural models.",9 Conclusion and Future Work,[0],[0]
"Adding those, we improved over the neural baseline for all languages, and for Mexicanero, Wixarika and Yorem Nokki our final models outperformed all baselines by up to 5.05% absolute accuracy or 3.40% F1.",9 Conclusion and Future Work,[0],[0]
"Furthermore, we explored cross-lingual transfer between our languages and reduced the amount of necessary model parameters by about 75%, while improving performance for some of the languages.
",9 Conclusion and Future Work,[0],[0]
"We publically release our datasets for morphological surface segmentation of the polysynthetic minimal-resource languages Mexicanero, Nahuatl, Wixarika and Norem Yokki.",9 Conclusion and Future Work,[0],[0]
"We would like to thank Paulina Grnarova, Rodrigo Nogueira and Ximena Gutierrez-Vasques for their helpful feedback.",Acknowledgments,[0],[0]
"Morphological segmentation for polysynthetic languages is challenging, because a word may consist of many individual morphemes and training data can be extremely scarce.",abstractText,[0],[0]
"Since neural sequence-to-sequence (seq2seq) models define the state of the art for morphological segmentation in high-resource settings and for (mostly) European languages, we first show that they also obtain competitive performance for Mexican polysynthetic languages in minimal-resource settings.",abstractText,[0],[0]
"We then propose two novel multi-task training approaches— one with, one without need for external unlabeled resources—, and two corresponding data augmentation methods, improving over the neural baseline for all languages.",abstractText,[0],[0]
"Finally, we explore cross-lingual transfer as a third way to fortify our neural model and show that we can train one single multi-lingual model for related languages while maintaining comparable or even improved performance, thus reducing the amount of parameters by close to 75%.",abstractText,[0],[0]
"We provide our morphological segmentation datasets for Mexicanero, Nahuatl, Wixarika and Yorem Nokki for future research.",abstractText,[0],[0]
Fortification of Neural Morphological Segmentation Models for Polysynthetic Minimal-Resource Languages,title,[0],[0]
"The increasing complexity of machine learning algorithms has driven a large amount of research in the area of hyperparameter optimization (HO) — see, e.g., (Hutter et al., 2015) for a review.",1. Introduction,[0],[0]
"The core idea is relatively simple: given a measure of interest (e.g. the misclassification error) HO methods use a validation set to construct a response function of the hyperparameters (such as the average loss on the validation set) and explore the hyperparameter space to seek an optimum.
",1. Introduction,[0],[0]
"Early approaches based on grid search quickly become impractical as the number of hyperparameters grows and are even outperformed by random search (Bergstra & Bengio, 2012).",1. Introduction,[0],[0]
"Given the high computational cost of evaluating the
1Computational Statistics and Machine Learning, Istituto Italiano di Tecnologia, Genoa, Italy 2Department of Computer Science, University College London, UK 3Department of Information Engineering, Università degli Studi di Firenze, Italy.",1. Introduction,[0],[0]
"Correspondence to: Luca Franceschi <luca.franceschi@iit.it>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
response function, Bayesian optimization approaches provide a natural framework and have been extensively studied in this context (Snoek et al., 2012; Swersky et al., 2013; Snoek et al., 2015).",1. Introduction,[0],[0]
"Related and faster sequential modelbased optimization methods have been proposed using random forests (Hutter et al., 2011) and tree Parzen estimators (Bergstra et al., 2011), scaling up to a few hundreds of hyperparameters (Bergstra et al., 2013).
",1. Introduction,[0],[0]
"In this paper, we follow an alternative direction, where gradient-based algorithms are used to optimize the performance on a validation set with respect to the hyperparameters (Bengio, 2000; Larsen et al., 1996).",1. Introduction,[0],[0]
"In this setting, the validation error should be evaluated at a minimizer of the training objective.",1. Introduction,[0],[0]
"However, in many current learning systems such as deep learning, the minimizer is only approximate.",1. Introduction,[0],[0]
"Domke (2012) specifically considered running an iterative algorithm, like gradient descent or momentum, for a given number of steps, and subsequently computing the gradient of the validation error by a back-optimization algorithm.",1. Introduction,[0],[0]
Maclaurin et al. (2015) considered reverse-mode differentiation of the response function.,1. Introduction,[0],[0]
"They suggested the idea of reversing parameter updates to achieve space efficiency, proposing an approximation capable of addressing the associated loss of information due to finite precision arithmetics.",1. Introduction,[0],[0]
"Pedregosa (2016) proposed the use of inexact gradients, allowing hyperparameters to be updated before reaching the minimizer of the training objective.",1. Introduction,[0],[0]
"Both (Maclaurin et al., 2015) and (Pedregosa, 2016) managed to optimize a number of hyperparameters in the order of one thousand.
",1. Introduction,[0],[0]
"In this paper, we illustrate two alternative approaches to compute the hypergradient (i.e., the gradient of the response function), which have different trade-offs in terms of running time and space requirements.",1. Introduction,[0],[0]
One approach is based on a Lagrangian formulation associated with the parameter optimization dynamics.,1. Introduction,[0],[0]
"It encompasses the reverse-mode differentiation (RMD) approach used by Maclaurin et al. (2015), where the dynamics corresponds to stochastic gradient descent with momentum.",1. Introduction,[0],[0]
We do not assume reversible parameter optimization dynamics.,1. Introduction,[0],[0]
A well-known drawback of RMD is its space complexity: we need to store the whole trajectory of training iterates in order to compute the hypergradient.,1. Introduction,[0],[0]
"An alternative approach that we consider overcomes this problem by computing
the hypergradient in forward-mode and it is efficient when the number of hyperparameters is much smaller than the number of parameters.",1. Introduction,[0],[0]
"To the best of our knowledge, the forward-mode has not been studied before in this context.
",1. Introduction,[0],[0]
"As we shall see, these two approaches have a direct correspondence to two classic alternative ways of computing gradients for recurrent neural networks (RNN) (Pearlmutter, 1995): the Lagrangian (reverse) way corresponds to back-propagation through time (Werbos, 1990), while the forward way corresponds to real-time recurrent learning (RTRL) (Williams & Zipser, 1989).",1. Introduction,[0],[0]
"As RTRL allows one to update parameters after each time step, the forward approach is suitable for real-time hyperparameter updates, which may significantly speed up the overall hyperparameter optimization procedure in the presence of large datasets.",1. Introduction,[0],[0]
We give experimental evidence that the real-time approach is efficient enough to allow for the automatic tuning of crucial hyperparameters in a deep learning model.,1. Introduction,[0],[0]
"In our experiments, we also explore constrained hyperparameter optimization, showing that it can be used effectively to detect noisy examples and to discover the relationships between different learning tasks.
",1. Introduction,[0],[0]
The paper is organized in the following manner.,1. Introduction,[0],[0]
In Section 2 we introduce the problem under study.,1. Introduction,[0],[0]
In Section 3.1 we derive the reverse-mode computation.,1. Introduction,[0],[0]
"In Section 3.2 we present the forward-mode computation of the hypergradient, and in Section 3.3 we introduce the idea of real-time hyperparameter updates.",1. Introduction,[0],[0]
In Section 4 we discuss the time and space complexity of these methods.,1. Introduction,[0],[0]
In Section 5 we present empirical results with both algorithms.,1. Introduction,[0],[0]
Finally in Section 6 we discuss our findings and highlight directions of future research.,1. Introduction,[0],[0]
We focus on training procedures based on the optimization of an objective function J(w) with respect to w (e.g. the regularized average training loss for a neural network with weights w).,2. Hyperparameter Optimization,[0],[0]
"We see the training procedure by stochastic gradient descent (or one of its variants like momentum, RMSProp, Adam, etc.)",2. Hyperparameter Optimization,[0],[0]
as a dynamical system with a state st ∈ Rd that collects weights and possibly accessory variables such as velocities and accumulated squared gradients.,2. Hyperparameter Optimization,[0],[0]
"The dynamics are defined by the system of equations
st = Φt(st−1, λ) t = 1, . . .",2. Hyperparameter Optimization,[0],[0]
", T (1)
where T is the number of iterations, s0 contains initial weights and initial accessory variables, and, for every t ∈ {1, . . .",2. Hyperparameter Optimization,[0],[0]
", T},
Φt : (Rd × Rm)→",2. Hyperparameter Optimization,[0],[0]
"Rd
is a smooth mapping that represents the operation performed by the t-th step of the optimization algorithm (i.e.
on mini-batch t).",2. Hyperparameter Optimization,[0],[0]
"Finally, λ ∈ Rm is the vector of hyperparameters that we wish to tune.
",2. Hyperparameter Optimization,[0],[0]
"As simple example of these dynamics occurs when training a neural network by gradient descent with momentum (GDM), in which case st = (vt, wt) and
vt = µvt−1 +∇Jt(wt−1) wt = wt−1 − η(µvt−1 −∇Jt(wt−1))
(2)
where Jt is the objective associated with the t-th minibatch, µ is the rate and η is the momentum.",2. Hyperparameter Optimization,[0],[0]
"In this example, λ = (µ, η).
",2. Hyperparameter Optimization,[0],[0]
"Note that the iterates s1, . . .",2. Hyperparameter Optimization,[0],[0]
", sT implicitly depend on the vector of hyperparameters λ.",2. Hyperparameter Optimization,[0],[0]
Our goal is to optimize the hyperparameters according to a certain error function E evaluated at the last iterate sT .,2. Hyperparameter Optimization,[0],[0]
"Specifically, we wish to solve the problem
min λ∈Λ f(λ) (3)
where the set Λ ⊂ Rd incorporates constraints on the hyperparameters, and the response function f : Rm → R is defined at λ ∈",2. Hyperparameter Optimization,[0],[0]
"Rm as
f(λ) = E(sT (λ)).",2. Hyperparameter Optimization,[0],[0]
"(4)
We highlight the generality of the framework.",2. Hyperparameter Optimization,[0],[0]
"The vector of hyperparameters λ may include components associated with the training objective, and components associated with the iterative algorithm.",2. Hyperparameter Optimization,[0],[0]
"For example, the training objective may depend on hyperparameters used to design the loss function as well as multiple regularization parameters.",2. Hyperparameter Optimization,[0],[0]
"Yet other components of λ may be associated with the space of functions used to fit the training objective (e.g. number of layers and weights of a neural network, parameters associated with the kernel function used within a kernel based method, etc.).",2. Hyperparameter Optimization,[0],[0]
The validation error E can in turn be of different kinds.,2. Hyperparameter Optimization,[0],[0]
The simplest example is to choose E as the average of a loss function over a validation set.,2. Hyperparameter Optimization,[0],[0]
"We may however consider multiple validation objectives, in that the hyperparameters associated with the iterative algorithm (µ and γ in the case of momentum mentioned above) may be optimized using the training set, whereas the regularization parameters would typically require a validation set, which is distinct from the training set (in order to avoid over-fitting).",2. Hyperparameter Optimization,[0],[0]
"In this section, we review the reverse-mode computation of the gradient of the response function (or hypergradient) under a Lagrangian perspective and introduce a forwardmode strategy.",3. Hypergradient Computation,[0],[0]
"These procedures correspond to the reversemode and the forward-mode algorithmic differentiation schemes (Griewank & Walther, 2008).",3. Hypergradient Computation,[0],[0]
"We finally introduce a real-time version of the forward-mode procedure.
",3. Hypergradient Computation,[0],[0]
"Algorithm 1 REVERSE-HG Input: λ current values of the hyperparameters, s0 initial optimization state Output: Gradient of validation error w.r.t.",3. Hypergradient Computation,[0],[0]
λ for t,3. Hypergradient Computation,[0],[0]
"= 1 to T do st = Φt(st−1, λ)
end for αT =",3. Hypergradient Computation,[0],[0]
∇E(sT ) g = 0 for t = T − 1 downto 1 do g = g + αt+1Bt+1 αt = αt+1At+1 end for return g,3. Hypergradient Computation,[0],[0]
"The reverse-mode computation leads to an algorithm closely related to the one presented in (Maclaurin et al., 2015).",3.1. Reverse-Mode,[0],[0]
A major difference with respect to their work is that we do not require the mappings Φt defined in Eq.,3.1. Reverse-Mode,[0],[0]
(1) to be invertible.,3.1. Reverse-Mode,[0],[0]
"We also note that the reverse-mode calculation is structurally identical to back-propagation through time (Werbos, 1990).
",3.1. Reverse-Mode,[0],[0]
"We start by reformulating problem (3) as the constrained optimization problem
min λ,s1,...,sT
E(sT )
subject to st = Φt(st−1, λ), t ∈ {1, . . .",3.1. Reverse-Mode,[0],[0]
", T}.",3.1. Reverse-Mode,[0],[0]
"(5)
This formulation closely follows a classical Lagrangian approach used to derive the back-propagation algorithm (LeCun, 1988).",3.1. Reverse-Mode,[0],[0]
"Furthermore, the framework naturally allows one to incorporate constraints on the hyperparameters.
",3.1. Reverse-Mode,[0],[0]
"The Lagrangian of problem (5) is
L(s, λ, α) = E(sT ) + T∑ t=1 αt(Φt(st−1, λ)− st) (6)
where, for each t ∈ {1, . . .",3.1. Reverse-Mode,[0],[0]
", T}, αt ∈",3.1. Reverse-Mode,[0],[0]
"Rd is a row vector of Lagrange multipliers associated with the t-th step of the dynamics.
",3.1. Reverse-Mode,[0],[0]
"The partial derivatives of the Lagrangian are given by
∂L ∂αt",3.1. Reverse-Mode,[0],[0]
"= Φt(st−1, λ)− st, t ∈ {1, . . .",3.1. Reverse-Mode,[0],[0]
", T} (7) ∂L ∂st = αt+1At+1",3.1. Reverse-Mode,[0],[0]
"− αt, t ∈ {1, . . .",3.1. Reverse-Mode,[0],[0]
", T−1} (8) ∂L ∂sT = ∇E(sT )− αT (9)
",3.1. Reverse-Mode,[0],[0]
∂L ∂λ =,3.1. Reverse-Mode,[0],[0]
"T∑ t=1 αtBt, (10)
",3.1. Reverse-Mode,[0],[0]
"Algorithm 2 FORWARD-HG Input: λ current values of the hyperparameters, s0 initial optimization state Output: Gradient of validation error w.r.t.",3.1. Reverse-Mode,[0],[0]
λ,3.1. Reverse-Mode,[0],[0]
"Z0 = 0 for t = 1 to T do st = Φt(st−1, λ)",3.1. Reverse-Mode,[0],[0]
"Zt = AtZt−1 +Bt
end for return ∇E(s)ZT
where for every t ∈ {1, . . .",3.1. Reverse-Mode,[0],[0]
", T}, we define the matrices
At = ∂Φt(st−1, λ)
∂st−1 , Bt =
∂Φt(st−1, λ)
",3.1. Reverse-Mode,[0],[0]
∂λ .,3.1. Reverse-Mode,[0],[0]
"(11)
Note that At ∈ Rd×d and Bt ∈ Rd×m.
",3.1. Reverse-Mode,[0],[0]
The optimality conditions are then obtained by setting each derivative to zero.,3.1. Reverse-Mode,[0],[0]
"In particular, setting the right hand side of Equations (8) and (9) to zero gives
αt =  ∇E(sT ) if t = T,
∇E(sT )AT · · ·At+1 if t ∈ {1, . . .",3.1. Reverse-Mode,[0],[0]
", T−1}.
",3.1. Reverse-Mode,[0],[0]
Combining these equations with Eq.,3.1. Reverse-Mode,[0],[0]
"(10) we obtain that
∂L ∂λ =",3.1. Reverse-Mode,[0],[0]
"∇E(sT ) T∑ t=1
( T∏
s=t+1
As ) Bt.
",3.1. Reverse-Mode,[0],[0]
As we shall see this coincides with the expression for the gradient of f in Eq.,3.1. Reverse-Mode,[0],[0]
(15) derived in the next section.,3.1. Reverse-Mode,[0],[0]
Pseudo-code of REVERSE-HG is presented in Algorithm 1.,3.1. Reverse-Mode,[0],[0]
"The second approach to compute the hypergradient appeals to the chain rule for the derivative of composite functions, to obtain that the gradient of f at λ satisfies1
∇f(λ) = ∇E(sT ) dsT",3.2. Forward-Mode,[0],[0]
"dλ
(12)
where dsTdλ is the d×mmatrix formed by the total derivative of the components of sT (regarded as rows) with respect to the components of λ (regarded as columns).
",3.2. Forward-Mode,[0],[0]
"Recall that st = Φt(st−1, λ).",3.2. Forward-Mode,[0],[0]
The operators Φt depends on the hyperparameter λ both directly by its expression and indirectly through the state st−1.,3.2. Forward-Mode,[0],[0]
"Using again the chain
1Remember that the gradient of a scalar function is a row vector.
rule we have, for every t ∈ {1, . . .",3.2. Forward-Mode,[0],[0]
", T}, that
dst dλ = ∂Φt(st−1, λ)
",3.2. Forward-Mode,[0],[0]
"∂st−1
dst−1 dλ + ∂Φt(st−1, λ)",3.2. Forward-Mode,[0],[0]
∂λ .,3.2. Forward-Mode,[0],[0]
"(13)
Defining Zt = dstdλ for every t ∈ {1, . . .",3.2. Forward-Mode,[0],[0]
", T} and recalling Eq.",3.2. Forward-Mode,[0],[0]
"(11), we can rewrite Eq.",3.2. Forward-Mode,[0],[0]
"(13) as the recursion
Zt = AtZt−1 +Bt, t ∈ {1, . . .",3.2. Forward-Mode,[0],[0]
", T}.",3.2. Forward-Mode,[0],[0]
"(14)
Using Eq. (14), we obtain that
∇f(λ) =",3.2. Forward-Mode,[0],[0]
∇E(sT )ZT = ∇E(sT )(ATZT−1 +BT ) =,3.2. Forward-Mode,[0],[0]
"∇E(sT )(ATAT−1ZT−2 +ATBT−1 +BT ) ...
= ∇E(sT ) T∑ t=1
( T∏
s=t+1
As ) Bt. (15)
Note that the recurrence (14) on the Jacobian matrix is structurally identical to the recurrence in the RTRL procedure described in (Williams & Zipser, 1989, eq. (2.10)).
",3.2. Forward-Mode,[0],[0]
From the above derivation it is apparent that∇f(λ) can be computed by an iterative algorithm which runs in parallel to the training algorithm.,3.2. Forward-Mode,[0],[0]
Pseudo-code of FORWARD-HG is presented in Algorithm 2.,3.2. Forward-Mode,[0],[0]
"At first sight, the computation of the terms in the right hand side of Eq.",3.2. Forward-Mode,[0],[0]
(14) seems prohibitive.,3.2. Forward-Mode,[0],[0]
"However, in Section 4 we observe that if m is much smaller than d, the computation can be done efficiently.",3.2. Forward-Mode,[0],[0]
"For every t ∈ {1, . . .",3.3. Real-Time Forward-Mode,[0],[0]
", T} let ft : Rm → R be the response function at time t: ft(λ) = E(st(λ)).",3.3. Real-Time Forward-Mode,[0],[0]
Note that fT coincides with the definition of the response function in Eq.,3.3. Real-Time Forward-Mode,[0],[0]
(4).,3.3. Real-Time Forward-Mode,[0],[0]
"A major difference between REVERSE-HG and FORWARD-HG is that the partial hypergradients
∇ft(λ) = dE(st)
dλ = ∇E(st)Zt (16)
are available in the second procedure at each time step t and not only at the end.
",3.3. Real-Time Forward-Mode,[0],[0]
"The availability of partial hypergradients is significant since we are allowed to update hyperparameters several times in a single optimization epoch, without having to wait until time T .",3.3. Real-Time Forward-Mode,[0],[0]
This is reminiscent of the real-time updates suggested by Williams & Zipser (1989) for RTRL.,3.3. Real-Time Forward-Mode,[0],[0]
"The real-time approach may be suitable in the case of a data stream (i.e. T = ∞), where REVERSE-HG would be hardly applicable.",3.3. Real-Time Forward-Mode,[0],[0]
"Even in the case of finite (but large) datasets it is possible to perform one hyperparameter update after a hyper-batch of data (i.e. a set of minibatches)
has been processed.",3.3. Real-Time Forward-Mode,[0],[0]
Algorithm 2 can be easily modified to yield a partial hypergradient when t mod ∆ = 0,3.3. Real-Time Forward-Mode,[0],[0]
"(for some hyper-batch size ∆) and letting t run from 1 to ∞, reusing examples in a circular or random way.",3.3. Real-Time Forward-Mode,[0],[0]
We use this strategy in the phone recognition experiment reported in Section 5.3.,3.3. Real-Time Forward-Mode,[0],[0]
We discuss the time and space complexity of Algorithms 1 and 2.,4. Complexity Analysis,[0],[0]
"We begin by recalling some basic results from the algorithmic differentiation (AD) literature.
",4. Complexity Analysis,[0],[0]
Let F :,4. Complexity Analysis,[0],[0]
Rn 7→,4. Complexity Analysis,[0],[0]
"Rp be a differentiable function and suppose it can be evaluated in time c(n, p) and requires space s(n, p).",4. Complexity Analysis,[0],[0]
Denote by JF the p × n Jacobian matrix of F .,4. Complexity Analysis,[0],[0]
"Then the following facts hold true (Griewank & Walther, 2008) (see also Baydin et al. (2015) for a shorter account):
(i) For any vector r ∈ Rn, the product JF r can be evaluated in time O(c(n, p)) and requires space O(s(n, p)) using forward-mode AD.
(ii) For any vector q ∈",4. Complexity Analysis,[0],[0]
"Rp, the product JᵀF q has time and space complexities O(c(n, p)) using reverse-mode AD.
",4. Complexity Analysis,[0],[0]
"(iii) As a corollary of item (i), the whole JF can be computed in time O(nc(n, p)) and requires space O(s(n, p)) using forward-mode AD (just use unitary vectors r = ei for i = 1, . . .",4. Complexity Analysis,[0],[0]
",",4. Complexity Analysis,[0],[0]
"n).
",4. Complexity Analysis,[0],[0]
"(iv) Similarly, JF can be computed in time O(pc(n, p)) and requires space O(c(n, p)) using reverse-mode AD.
",4. Complexity Analysis,[0],[0]
"Let g(d,m) and h(d,m) denote time and space, respectively, required to evaluate the update map Φt defined by Eq.",4. Complexity Analysis,[0],[0]
(1).,4. Complexity Analysis,[0],[0]
Then the response function f :,4. Complexity Analysis,[0],[0]
Rm 7→ R defined in Eq.,4. Complexity Analysis,[0],[0]
"(3) can be evaluated in timeO(Tg(d,m))",4. Complexity Analysis,[0],[0]
"(assuming the time required to compute the validation errorE(λ) does not affect the bound2) and requires spaceO(h(d,m)) since variables st may be overwritten at each iteration.",4. Complexity Analysis,[0],[0]
"Then, a direct application of Fact (i) above shows that Algorithm 2 runs in time O(Tmg(d,m)) and space O(h(d,m)).",4. Complexity Analysis,[0],[0]
"The same results can also be obtained by noting that in Algorithm 2 the product AtZt−1 requires m Jacobian-vector products, each costing O(g(d,m)) (from Fact (i)), while computing the Jacobian Bt takes time O(mg(d,m))",4. Complexity Analysis,[0],[0]
"(from Fact (iii)).
",4. Complexity Analysis,[0],[0]
"Similarly, a direct application of Fact (ii) shows that Algorithm 1 has both time and space complexities O(Tg(d,m)).",4. Complexity Analysis,[0],[0]
"Again the same results can be obtained by
2This is indeed realistic since the number of validation examples is typically lower than the number of training iterations.
noting that αt+1At1 and αtBt are transposed-Jacobianvector products that in reverse-mode take both time O(g(d,m))",4. Complexity Analysis,[0],[0]
(from Fact (ii)).,4. Complexity Analysis,[0],[0]
"Unfortunately in this case variables st cannot be overwritten, explaining the much higher space requirement.
",4. Complexity Analysis,[0],[0]
"As an example, consider training a neural network with k weights3, using classic iterative optimization algorithms such as SGD (possibly with momentum) or Adam, where the hyperparameters are just learning rate and momentum terms.",4. Complexity Analysis,[0],[0]
"In this case, d = O(k) and m = O(1).",4. Complexity Analysis,[0],[0]
"Moreover, g(d,m) and h(d,m) are both O(k).",4. Complexity Analysis,[0],[0]
"As a result, Algorithm 1 runs in time and space O(Tk), while Algorithm 2 runs in timeO(Tk) and spaceO(k), which would typically make a dramatic difference in terms of memory requirements.",4. Complexity Analysis,[0],[0]
"In this section, we present numerical simulations with the proposed methods.",5. Experiments,[0],[0]
All algorithms were implemented in TensorFlow and the software package used to reproduce our experiments is available at https://github.,5. Experiments,[0],[0]
com/lucfra/RFHO.,5. Experiments,[0],[0]
"In all the experiments, hypergradients were used inside the Adam algorithm (Kingma & Ba, 2014) in order to minimize the response function.",5. Experiments,[0],[0]
The goal of this experiment is to highlight one potential advantage of constraints on the hyperparameters.,5.1. Data Hyper-cleaning,[0],[0]
Suppose we have a dataset with label noise and due to time or resource constraints we can only afford to cleanup (by checking and correcting the labels) a subset of the available data.,5.1. Data Hyper-cleaning,[0],[0]
"Then we may use the cleaned data as the validation set, the rest as the training set, and assign one hyperparameter to each training example.",5.1. Data Hyper-cleaning,[0],[0]
"By putting a sparsity constraint on the vector of hyperparameters λ, we hope to bring to zero the influence of noisy examples, in order to generate a better model.",5.1. Data Hyper-cleaning,[0],[0]
"While this is the same kind of data sparsity observed in support vector machines (SVM), our setting aims to get rid of erroneously labeled examples, in contrast to SVM which puts zero weight on redundant examples.",5.1. Data Hyper-cleaning,[0],[0]
"Although this experimental setup does not necessarily reflect a realistic scenario, it aims to test the ability of our HO method to effectively make use of constraints on the hyperparameters4
We instantiated the above setting with a balanced subset of N = 20000 examples from the MNIST dataset, split into three subsets:",5.1. Data Hyper-cleaning,[0],[0]
"Dtr of Ntr = 5000 training examples, V of
3This includes linear SVM and logistic regression as special cases.
",5.1. Data Hyper-cleaning,[0],[0]
"4We note that a related approach based on reinforcement learning is presented in (Fan et al., 2017).
",5.1. Data Hyper-cleaning,[0],[0]
Nval = 5000 validation examples and a test set containing the remaining samples.,5.1. Data Hyper-cleaning,[0],[0]
"Finally, we corrupted the labels of 2500 training examples, selecting a random subset Df ⊂ Dtr.
We considered a plain softmax regression model with parameters W (weights) and b (bias).",5.1. Data Hyper-cleaning,[0],[0]
"The error of a model (W, b) on an example x was evaluated by using the crossentropy `(W, b, x) both in the training objective function, Etr, and in the validation one, Eval.",5.1. Data Hyper-cleaning,[0],[0]
We added in Etr an hyperparameter vector λ ∈,5.1. Data Hyper-cleaning,[0],[0]
"[0, 1]Ntr that weights each example in the training phase, i.e. Etr(W, b) =
1 Ntr ∑ i∈Dtr λi`(W, b, xi).
",5.1. Data Hyper-cleaning,[0],[0]
"According to the general HO framework, we fit the parameters (W, b) to minimize the training loss and the hyperparameters λ to minimize the validation error.",5.1. Data Hyper-cleaning,[0],[0]
"The sparsity constraint was implemented by bounding the L1-norm of λ, resulting in the optimization problem
min λ∈Λ Eval(WT , bT ) (PHO)
where Λ = {λ : λ ∈",5.1. Data Hyper-cleaning,[0],[0]
"[0, 1]Ntr , ‖λ‖1 ≤ R} and (WT , bT ) are the parameters obtained after T iterations of gradient descent on the training objective.",5.1. Data Hyper-cleaning,[0],[0]
"Given the high dimensionality of λ, we solved (PHO) iteratively computing the hypergradients with REVERSE-HG method and projecting Adam updates on the set Λ.
We are interested in comparing the following three test set accuracies:
• Oracle: the accuracy of the minimizer of Etr trained on clean examples only, i.e. (Dtr\Df )∪V; this setting is effectively taking advantage of an oracle that tells which examples have a wrong label;
• Baseline: the accuracy of the minimizer ofEtr trained on all available data D ∪ V;
• DH-R: the accuracy of the data hyper-cleaner with a given value of the L1 radius, R.",5.1. Data Hyper-cleaning,[0],[0]
"In this case, we first optimized hyperparameters",5.1. Data Hyper-cleaning,[0],[0]
and then constructed a cleaned training set Dc ⊂,5.1. Data Hyper-cleaning,[0],[0]
"Dtr (keeping examples with λi > 0); we finally trained on Dc ∪ V .
",5.1. Data Hyper-cleaning,[0],[0]
We are also interested in evaluating the ability of the hypercleaner to detect noisy samples.,5.1. Data Hyper-cleaning,[0],[0]
Results are shown in Table 1.,5.1. Data Hyper-cleaning,[0],[0]
"The data hyper-cleaner is robust with respect to the choice of R and is able to identify corrupted examples, recovering a model that has almost the same accuracy as a model produced with the help of an oracle.
",5.1. Data Hyper-cleaning,[0],[0]
Figure 1 shows how the accuracy of DH-1000 improves with the number of hyper-iterations and the progression of the amount of discarded examples.,5.1. Data Hyper-cleaning,[0],[0]
"The data hyper-cleaner starts by discarding mainly corrupted examples, and while
0 100 200 300 400 500
Hyper-iterations
0
500
1000
1500
2000
2500
3000
3500
N u
m b
er of
d is
ca rd
ed ex
am p
le s
80
82
84
86
88
",5.1. Data Hyper-cleaning,[0],[0]
"90
92
A cc
u ra
cy
N u
m b
er of
d is
ca rd
ed ex
am p
le s
Accuracy and sparsity of λ
Validation
Test
TP
FP
Figure 1:",5.1. Data Hyper-cleaning,[0],[0]
Right vertical axis: accuracies of DH-1000 on validation and test sets.,5.1. Data Hyper-cleaning,[0],[0]
"Left vertical axis: number of discarded examples among noisy (True Positive, TP) and clean (False Positive, FP) ones.
",5.1. Data Hyper-cleaning,[0],[0]
"the optimization proceeds, it begins to remove also a portion of cleaned one.",5.1. Data Hyper-cleaning,[0],[0]
"Interestingly, the test set accuracy continues to improve even when some of the clean examples are discarded.",5.1. Data Hyper-cleaning,[0],[0]
"This second set of experiments is in the multitask learning (MTL) context, where the goal is to find simultaneously the model of multiple related tasks.",5.2. Learning Task Interactions,[0],[0]
Many MTL methods require that a task interaction matrix is given as input to the learning algorithm.,5.2. Learning Task Interactions,[0],[0]
"However, in real applications, this matrix is often unknown and it is interesting to learn it from data.",5.2. Learning Task Interactions,[0],[0]
"Below, we show that our framework can be naturally applied to learning the task relatedness matrix.
",5.2. Learning Task Interactions,[0],[0]
"We used CIFAR-10 and CIFAR-100 (Krizhevsky & Hinton, 2009), two object recognition datasets with 10 and 100 classes, respectively.",5.2. Learning Task Interactions,[0],[0]
As features we employed the preactivation of the second last layer of Inception-V3 model trained on ImageNet5.,5.2. Learning Task Interactions,[0],[0]
"From CIFAR-10, we extracted 50
5Available at tinyurl.com/h2x8wws
examples as training set, different 50 examples as validation set and the remaining for testing.",5.2. Learning Task Interactions,[0],[0]
"From CIFAR-100, we selected 300 examples as training set, 300 as validation set and the remaining for testing.",5.2. Learning Task Interactions,[0],[0]
"Finally, we used a onehot encoder of the labels obtaining a set of labels in {0, 1}K (K = 10 or K = 100).
",5.2. Learning Task Interactions,[0],[0]
The choice of small training set sizes is due to the strong discriminative power of the selected features.,5.2. Learning Task Interactions,[0],[0]
"In fact, using larger sample sizes would not allow to appreciate the advantage of MTL.",5.2. Learning Task Interactions,[0],[0]
"In order to leverage information among the different classes, we employed a multitask learning (MTL) regularizer (Evgeniou et al., 2005)
ΩC,ρ(W ) = K∑ j,k=1 Cj,k‖wj − wk‖22 + ρ K∑ k=1 ‖wk‖2,
where wk are the weights for class k, K is the number of classes, and the symmetric non-negative matrix C models the interactions between the classes/tasks.",5.2. Learning Task Interactions,[0],[0]
"We used a regularized training error defined as Etr(W ) =∑ i∈Dtr `(Wxi + b, yi) + ΩC,ρ(W )",5.2. Learning Task Interactions,[0],[0]
"where `(·, ·) is the categorical cross-entropy and b = (b1, . . .",5.2. Learning Task Interactions,[0],[0]
", bK) is the vector of thresholds associated with each linear model.",5.2. Learning Task Interactions,[0],[0]
"We wish solve the following optimization problem:
min { Eval(WT , bT ) subject to ρ ≥ 0, C = Cᵀ, C ≥ 0 } ,
where (WT , bT ) is the T -th iteration obtained by running gradient descent with momentum (GDM) on the training objective.",5.2. Learning Task Interactions,[0],[0]
"We solve this problem using REVERSE-HG and optimizing the hyperparameters by projecting Adam updates on the set {(ρ, C) : ρ ≥ 0, C = Cᵀ, C ≥ 0}.",5.2. Learning Task Interactions,[0],[0]
"We compare the following methods:
• SLT: single task learning, i.e. C = 0, using a validation set to tune the optimal value of ρ for each task;
• NMTL: we considered the naive MTL scenario in which the tasks are equally related, that is Cj,k = a for every 1 ≤ j, k ≤",5.2. Learning Task Interactions,[0],[0]
K.,5.2. Learning Task Interactions,[0],[0]
"In this case we learn the two non-negative hyperparameters a and ρ;
• HMTL:",5.2. Learning Task Interactions,[0],[0]
"our hyperparameter optimization method REVERSE-HG to tune C and ρ;
• HMTL-S: Learning the matrix C with only few examples per class could bring the discovery of spurious relationships.",5.2. Learning Task Interactions,[0],[0]
"We try to remove this effect by imposing the constraint that ∑ j,k Cj,k ≤ R, where6 R = 10−3.
",5.2. Learning Task Interactions,[0],[0]
"In this case, Adam updates are projected onto the set {(ρ, C) : ρ ≥ 0, C = Cᵀ, C ≥ 0, ∑ j,k Cj,k ≤ R}.
",5.2. Learning Task Interactions,[0],[0]
Results of five repetitions with different splits are presented in Table 2.,5.2. Learning Task Interactions,[0],[0]
"Note that HMTL gives a visible improvement in
6We observed that R = 10−4 yielded very similar results.
performance, and adding the constraint that ∑ j,k Cj,k ≤ R further improves performance in both datasets.",5.2. Learning Task Interactions,[0],[0]
"The matrix C can been interpreted as an adjacency matrix of a graph, highlighting the relationships between the classes.",5.2. Learning Task Interactions,[0],[0]
"Figure 2 depicts the graph for CIFAR-10 extracted from the algorithm HMTL-S. Although this result is strongly influenced by the choice of the data representations, we can note that animals tends to be more related to themselves than to vehicles and vice versa.",5.2. Learning Task Interactions,[0],[0]
The aim of the third set of experiments is to assess the efficacy of the real-time FORWARD-HG algorithm (RTHO).,5.3. Phone Classification,[0],[0]
"We run experiments on phone recognition in the multitask framework proposed in (Badino, 2016, and references therein).",5.3. Phone Classification,[0],[0]
"Data for all experiments was obtained from the TIMIT phonetic recognition dataset (Garofolo et al., 1993).",5.3. Phone Classification,[0],[0]
The dataset contains 5040 sentences corresponding to around 1.5 million speech acoustic frames.,5.3. Phone Classification,[0],[0]
"Training, validation and test sets contain respectively 73%, 23% and 4% of the data.",5.3. Phone Classification,[0],[0]
The primary task is a frame-level phone state classification with 183 classes and it consists in learning a mapping fP from acoustic speech vectors to hidden Markov model monophone states.,5.3. Phone Classification,[0],[0]
"Each 25ms speech frame is represented by a 123-dimensional vector containing 40 Mel frequency scale cepstral coefficients and energy, augmented with their deltas and delta-deltas.",5.3. Phone Classification,[0],[0]
We used a window of eleven frames centered around the prediction target to create the 1353-dimensional input to fP .,5.3. Phone Classification,[0],[0]
"The secondary (or auxiliary) task consists in learning a mapping fS from acoustic vectors to 300-dimensional real vectors of contextdependent phonetic embeddings defined in (Badino, 2016).
",5.3. Phone Classification,[0],[0]
"As in previous work, we assume that the two mappings fP and fS share inputs and an intermediate representation, obtained by four layers of a feed-forward neural network with 2000 units on each layer.",5.3. Phone Classification,[0],[0]
We denote by W the parameter vector of these four shared layers.,5.3. Phone Classification,[0],[0]
The network has two different output layers with parameter vectorsWP andWS each relative to the primary and secondary task.,5.3. Phone Classification,[0],[0]
"The network is trained to jointly minimize Etot(W,WP ,WS) = EP (W,W P )+ρES(W,W S), where the primary error EP is the average cross-entropy loss on the primary task, the secondary error ES is given by mean squared error on the embedding vectors and ρ ≥ 0 is a design hyperparameter.",5.3. Phone Classification,[0],[0]
"Since we are ultimately interested in learning fP , we formulate the hyperparameter optimization problem as
min { Eval(WT ,W P T ) subject to ρ, η ≥ 0, 0 ≤ µ ≤ 1 } ,
where Eval is the cross entropy loss computed on a validation set after T iterations of stochastic GDM, and η and µ are defined in (2).",5.3. Phone Classification,[0],[0]
In all the experiments we fix a minibatch size of 500.,5.3. Phone Classification,[0],[0]
"We compare the following methods:
1.",5.3. Phone Classification,[0],[0]
"Vanilla: the secondary target is ignored (ρ = 0); η and µ are set to 0.075 and 0.5 respectively as in (Badino, 2016).
2.",5.3. Phone Classification,[0],[0]
"RS: random search with ρ ∼ U(0, 4), η ∼ E(0.1) (exponential distribution with scale parameter 0.1) and µ ∼ U(0, 1) (Bergstra & Bengio, 2012).
3.",5.3. Phone Classification,[0],[0]
"RTHO: real-time hyperparameter optimization with initial learning rate and momentum factor as in Vanilla and initial ρ set to 1.6 (best value obtained by gridsearch in Badino (2016)).
",5.3. Phone Classification,[0],[0]
4.,5.3. Phone Classification,[0],[0]
"RTHO-NT: RTHO with “null teacher,” i.e. when the initial values of ρ, η and µ are set to 0.",5.3. Phone Classification,[0],[0]
"We regard this experiment as particularly interesting: this initial setting, while clearly not optimal, does not require any background knowledge on the task at hand.
",5.3. Phone Classification,[0],[0]
"We also tried to run FORWARD-HG for a fixed number of epochs, not in real-time mode.",5.3. Phone Classification,[0],[0]
"Results are not reported
since the method could not make any appreciable progress after running 24 hours on a Titan X GPU.
Test accuracies and execution times are reported in Table 3.",5.3. Phone Classification,[0],[0]
Figure 3 shows learning curves and hyperparameter evolutions for RTHO-NT.,5.3. Phone Classification,[0],[0]
"In Experiments 1 and 2 we employ a standard early stopping procedure on the validation accuracy, while in Experiments 3 and 4 a natural stopping time is given by the decay to 0 of the learning rate (see Figure 3 left-bottom plot).",5.3. Phone Classification,[0],[0]
"In Experiments 3 and 4 we used a hyperbatch size of ∆ = 200 (see Eq. (16)) and a hyper-learning rate of 0.005.
",5.3. Phone Classification,[0],[0]
"The best results in Table 3 are very similar to those obtained in state-of-the-art recognizers using multitask learning (Badino, 2016; 2017).",5.3. Phone Classification,[0],[0]
"In spite of the small number of hyperparameters, random search yields results only slightly better than the vanilla network (the result reported in Table 3 are an average over 5 trials, with a minimum and maximum accuracy of 59.93 and 60.86, respectively).",5.3. Phone Classification,[0],[0]
"Within the same time budget of 300 minutes, RTHO-NT is able to find hyperparameters yielding a substantial improvement over the vanilla version, thus effectively exploiting the auxiliary task.",5.3. Phone Classification,[0],[0]
Note that the model trained has more that 15×106 parameters for a corresponding state of more than 30× 106 variables.,5.3. Phone Classification,[0],[0]
"To the best of our knowledge, reversemode (Maclaurin et al., 2015) or approximate (Pedregosa, 2016) methods have not been applied to models of this size.",5.3. Phone Classification,[0],[0]
"We studied two alternative strategies for computing the hypergradients of any iterative differentiable learning dynam-
ics.",6. Discussion,[0],[0]
"Previous work has mainly focused on the reverse-mode computation, attempting to deal with its space complexity, that becomes prohibitive for very large models such as deep networks.
",6. Discussion,[0],[0]
Our first contribution is the definition and the application of forward-mode computation to HO.,6. Discussion,[0],[0]
Our analysis suggests that for large models the forward-mode computation may be a preferable alternative to reverse-mode if the number of hyperparameters is small.,6. Discussion,[0],[0]
"Additionally, forward-mode is amenable to real-time hyperparameter updates, which we showed to be an effective strategy for large datasets (see Section 5.3).",6. Discussion,[0],[0]
"We showed experimentally that even starting from a far-from-optimal value of the hyperparameters (the null teacher), our RTHO algorithm finds good values at a reasonable cost, whereas other gradient-based algorithms could not be applied in this context.
",6. Discussion,[0],[0]
Our second contribution is the Lagrangian derivation of the reverse-mode computation.,6. Discussion,[0],[0]
"It provides a general framework to tackle hyperparameter optimization problems involving a wide class of response functions, including those that take into account the whole parameter optimization dynamics.",6. Discussion,[0],[0]
"We have also presented in Sections 5.1 and 5.2 two non-standard learning problems where we specifically take advantage of a constrained formulation of the HO problem.
",6. Discussion,[0],[0]
We close by highlighting some potential extensions of our framework and direction of future research.,6. Discussion,[0],[0]
"First, the relatively low cost of our RTHO algorithm could suggest to make it a standard tool for the optimization of real-valued critical hyperparameters (such as learning rates, regularization factors and error function design coefficient), in context where no previous or expert knowledge is available (e.g. novel domains).",6. Discussion,[0],[0]
"Yet, RTHO must be thoroughly validated on diverse datasets and with different models and settings to empirically asses its robustness and its ability to find good hyperparameter values.",6. Discussion,[0],[0]
"Second, in order to perform gradient-based hyperparameter optimization, it is necessary to set a descent procedure over the hyperparameters.",6. Discussion,[0],[0]
In our experiments we have always used Adam with a manually adjusted value for the hyperlearning rate.,6. Discussion,[0],[0]
Devising procedures which are adaptive in these hyper-hyperparameters is an important direction of future research.,6. Discussion,[0],[0]
"Third, extensions of gradient-based HO techniques to integer or nominal hyperparameters (such as the depth and the width of a neural network) require additional design efforts and may not arise naturally in our framework.",6. Discussion,[0],[0]
"Future research should instead focus on the integration of gradient-based algorithm with Bayesian optimization and/or with emerging reinforcement learning hyperparameter optimization approaches (Zoph & Le, 2016).",6. Discussion,[0],[0]
A final important problem is to study the converge properties of RTHO.,6. Discussion,[0],[0]
Results in Pedregosa (2016) may prove useful in this direction.,6. Discussion,[0],[0]
We study two procedures (reverse-mode and forward-mode) for computing the gradient of the validation error with respect to the hyperparameters of any iterative learning algorithm such as stochastic gradient descent.,abstractText,[0],[0]
These procedures mirror two methods of computing gradients for recurrent neural networks and have different trade-offs in terms of running time and space requirements.,abstractText,[0],[0]
Our formulation of the reverse-mode procedure is linked to previous work by Maclaurin et al. (2015) but does not require reversible dynamics.,abstractText,[0],[0]
"The forward-mode procedure is suitable for real-time hyperparameter updates, which may significantly speed up hyperparameter optimization on large datasets.",abstractText,[0],[0]
We present experiments on data cleaning and on learning task interactions.,abstractText,[0],[0]
We also present one large-scale experiment where the use of previous gradient-based methods would be prohibitive.,abstractText,[0],[0]
Forward and Reverse Gradient-Based Hyperparameter Optimization,title,[0],[0]
"Goal-oriented, information-retrieving dialogue systems have been designed traditionally to help users find items in a database given a set of constraints (Singh et al., 2002; Raux et al., 2003; El Asri et al., 2014; Laroche et al., 2011).",1 Introduction,[0],[0]
"For instance, the LET’S GO dialogue system finds a bus schedule given a bus number and a location (Raux et al., 2003).
",1 Introduction,[0],[0]
"Available resources for data-driven learning of such goal-oriented systems are often collected with an existing system (Henderson et al., 2014b; Bennett and Rudnicky, 2002) and have been proposed to study one component of dialogue.",1 Introduction,[0],[0]
"Examples are the first three Dialogue State Tracking Challenges (DSTC, Williams et al., 2016) during which a se-
ries of datasets and tasks of increasing complexity were released.",1 Introduction,[0],[0]
These shared tasks were essential to advance the state of the art on state tracking.,1 Introduction,[0],[0]
"Other resources have allowed to study and develop different approaches to spoken language understanding and entity extraction (Mesnil et al., 2013).",1 Introduction,[0],[0]
"As for dialogue management, simulators have been proposed (Schatzmann et al., 2006) but datasets are scarce.
",1 Introduction,[0],[0]
"In most datasets collected with an existing system, the dialogues consist of sequential slot-filling: the system requests constraints until it can query the database and return several results to the user.",1 Introduction,[0],[0]
"Then, the user can ask for more information about a given result or request other possibilities.",1 Introduction,[0],[0]
"As a consequence, the tasks and methods that were based on these datasets were defined according to this sequential slot-filling process
We propose the Frames dataset to study more complex dialogue flows and decision-making behaviour.",1 Introduction,[0],[0]
"Our motivation comes from user studies in e-commerce which show that several informationseeking behaviours are exhibited by users who may come with a very well defined item in mind, but may also visit an e-commerce website with the intent to compare items and explore different possibilities (Moe and Fader, 2001; Saha et al., 2017).",1 Introduction,[0],[0]
Supporting this kind of decision-making process in conversational systems implies adding memory.,1 Introduction,[0],[0]
Memory is necessary to track different items or preferences set by the user during the dialogue.,1 Introduction,[0],[0]
"For instance, consider product comparisons.",1 Introduction,[0],[0]
"If a user wants to compare different items using a dialogue system, then this system should be able to separately recall properties pertaining to each item.
",1 Introduction,[0],[0]
"We collected 1369 human-human dialogues in a Wizard-of-Oz (WOz) setting – i.e., users were paired up with humans, whom we refer to as wizards, who assumed the role of the dialogue system.",1 Introduction,[0],[0]
"Wizards were given access to a database of vaca-
tion packages containing round-trip flights and a hotel.",1 Introduction,[0],[0]
Users were tasked with finding packages based on a few constraints such as a destination and a budget.,1 Introduction,[0],[0]
"The dataset has been fully annotated by human experts and is publicly available1.
",1 Introduction,[0],[0]
"Along with this dataset, we formalize a new task called frame tracking.",1 Introduction,[0],[0]
"Frame tracking is an extension of state tracking (Henderson, 2015; Williams et al., 2016).",1 Introduction,[0],[0]
"In state tracking, the information summarizing the full dialogue history is compressed into a single semantic frame which contains properties and values corresponding to the user’s preferences (e.g., destination city).",1 Introduction,[0],[0]
"In frame tracking, the dialogue agent must simultaneously track multiple semantic frames (e.g., different destination cities; frames are defined formally in Section 4.2) throughout the conversation.",1 Introduction,[0],[0]
"We collected the Frames data over a period of 20 days with 12 participants, who worked either for one day, one week, or 20 days.",2 Data Collection,[0],[0]
The participants alternated between the user and wizard roles on a daily basis.,2 Data Collection,[0],[0]
"Due to this rotation, we can assume that we deal with returning users who know how to use the system, and focus on the decision making process, skipping the phase where the user learns about the system capabilities.",2 Data Collection,[0],[0]
"The domain for all dialogues is travel: specifically, finding a vacation package that fulfils certain a priori requirements through a conversational search-and-compare process.",2 Data Collection,[0],[0]
"Wizard-of-Oz (WOz) dialogues (Kelley, 1984; Rieser et al., 2005; Wen et al., 2016) have the considerable advantage of exhibiting realistic behaviours often beyond the capabilities of existing dialogue systems.",2.1 Wizard-Of-Oz Setting,[0],[0]
"Our setting is slightly different from the usual WOz setting because, in our case, users did not believe they were interacting with a dialogue system; they knew they were conversing with fellow humans.",2.1 Wizard-Of-Oz Setting,[0],[0]
"We chose not to give templated answers to wizards because, apart from studying decision-making, we also wanted to study information presentation and dialogue management.",2.1 Wizard-Of-Oz Setting,[0],[0]
"We work with text-based dialogues because this engenders a more controlled wizard behaviour, obviates handling time-sensitive turn taking, and speech recognition noise.
1datasets.maluuba.com/Frames",2.1 Wizard-Of-Oz Setting,[0],[0]
User-wizard dialogues took place on Slack.2 We deployed a Slack bot to pair up participants and record conversations.,2.2 Task Templates and Instructions,[0],[0]
"At the beginning of each dialogue, a user was paired with a wizard and given a new task.",2.2 Task Templates and Instructions,[0],[0]
"Tasks were built from templates like the following:
“Find a vacation between [START DATE] and",2.2 Task Templates and Instructions,[0],[0]
[END DATE] for [NUM ADULTS] adults and [NUM CHILDREN] kids.,2.2 Task Templates and Instructions,[0],[0]
You leave from [ORIGIN CITY].,2.2 Task Templates and Instructions,[0],[0]
"You are travelling on a budget and you would like to spend at most $[BUDGET].”
Tasks were generated by drawing values (e.g., for BUDGET) from a database.",2.2 Task Templates and Instructions,[0],[0]
We constructed our database of flight and hotel properties by hand to simulate what one would find on a standard travel booking site.,2.2 Task Templates and Instructions,[0],[0]
"Each template was assigned a probability of success, and then constraint values were drawn in order to comply with this probability.",2.2 Task Templates and Instructions,[0],[0]
"For example, if 20 tasks were generated at probability 0.5, about 10 tasks would be generated with successful database queries and the other 10 would be generated such that the database returned no results for the constraints.",2.2 Task Templates and Instructions,[0],[0]
This success mechanism allowed us to emulate cases when a user would find nothing meeting her constraints.,2.2 Task Templates and Instructions,[0],[0]
"If a task was unsuccessful, the user either ended the dialogue or got an alternative task such as: “If nothing matches your constraints, try increasing your budget by $200.”",2.2 Task Templates and Instructions,[0],[0]
We wrote 38 templates.,2.2 Task Templates and Instructions,[0],[0]
14 were generic like the one presented above and the other 24 included a background story to encourage role-playing from users and to keep them engaged.,2.2 Task Templates and Instructions,[0],[0]
These templates were meant to add variety to the dialogues.,2.2 Task Templates and Instructions,[0],[0]
The generic templates were also important for the users to create their own character and personality.,2.2 Task Templates and Instructions,[0],[0]
We found that the combination of the two types of templates prevented the task from becoming too repetitive.,2.2 Task Templates and Instructions,[0],[0]
"Notably, we distributed the role-playing templates throughout the data collection process to bring some novelty and surprise.",2.2 Task Templates and Instructions,[0],[0]
"We also asked the participants to write templates (13 of them) to keep them engaged in the task.
",2.2 Task Templates and Instructions,[0],[0]
"To control data collection, we gave a set of instructions to the participants.",2.2 Task Templates and Instructions,[0],[0]
The user instructions encouraged a variety of behaviours.,2.2 Task Templates and Instructions,[0],[0]
"As for the wizards, they were asked only to talk about the
2www.slack.com
database results and the task at hand.",2.2 Task Templates and Instructions,[0],[0]
"We also asked the wizards to perform untimely actions occasionally, for instance, to ask for information that the user has already provided.",2.2 Task Templates and Instructions,[0],[0]
It is interesting from a dialogue management point of view to have examples of bad behaviour and of how it impacts user satisfaction.,2.2 Task Templates and Instructions,[0],[0]
"At the end of each dialogue, the user provided a wizard cooperativity rating on a scale of 1 to 5.",2.2 Task Templates and Instructions,[0],[0]
"The wizard, on the other hand, was shown the user’s task and was asked whether she thought the user had accomplished it.",2.2 Task Templates and Instructions,[0],[0]
Wizards received a link to a search interface every time a user was connected to them.,2.3 Search Interface And Suggestions,[0],[0]
The search interface was a simple GUI with all the searchable fields in the database (see Appendix A).,2.3 Search Interface And Suggestions,[0],[0]
"For every database search, up to 10 results were displayed, sorted by increasing price.
",2.3 Search Interface And Suggestions,[0],[0]
Another important property of human dialogue that we want to study with Frames is how to provide users with database information.,2.3 Search Interface And Suggestions,[0],[0]
"When a set of user constraints leads to no results, users would benefit from knowing that relaxing a given constraint (e.g., increasing the budget by a reasonable amount) leads to results.",2.3 Search Interface And Suggestions,[0],[0]
We modelled this by displaying suggestions to the wizards when a database query returned no results.,2.3 Search Interface And Suggestions,[0],[0]
Suggestions were packages obtained by randomly relaxing one or more constraints.,2.3 Search Interface And Suggestions,[0],[0]
It was up to the wizard to decide whether or not to use suggestions.,2.3 Search Interface And Suggestions,[0],[0]
"Using the data collection process described above, we collected 1369 dialogues.",3 Statistics of the Corpus,[0],[0]
Figure 1a shows the distribution of dialogue lengths in the corpus.,3 Statistics of the Corpus,[0],[0]
"The average number of turns is 15, for a total of 19986 turns in the dataset.",3 Statistics of the Corpus,[0],[0]
A turn is defined as a Slack message sent by either a user or a wizard.,3 Statistics of the Corpus,[0],[0]
"Turns always alternate between user and wizard.
",3 Statistics of the Corpus,[0],[0]
Figure 1b shows the number of acts per dialogue turn.,3 Statistics of the Corpus,[0],[0]
About 25% of the dialogue turns have more than one dialogue act.,3 Statistics of the Corpus,[0],[0]
"The turns without dialogue acts are turns where the user asked for something that the wizard could not provide, e.g., because it was not part of the database.",3 Statistics of the Corpus,[0],[0]
"We left such (rarely occurring) user turns unannotated, as they are usually followed up by the wizard saying she cannot provide the required information.",3 Statistics of the Corpus,[0],[0]
"This rarely occurs, since our users are familiar with the capabilities of the “system” after only few dialogues.
",3 Statistics of the Corpus,[0],[0]
Figure 1c shows the distribution of user ratings.,3 Statistics of the Corpus,[0],[0]
More than 70% of the dialogues have the maximum rating of 5.,3 Statistics of the Corpus,[0],[0]
Figure 2 shows the occurrences of dialogue acts in the corpus.,3 Statistics of the Corpus,[0],[0]
The dialogue acts are described in Table 9.,3 Statistics of the Corpus,[0],[0]
We present the annotation scheme in the following section.,3 Statistics of the Corpus,[0],[0]
"We manually annotated the Frames dataset with dialogue acts, slot types and values, references to other frames, and the ID of the currently active frame for each utterance.",4 Annotation,[0],[0]
We also computed frame descriptions based on the labels of earlier turns.,4 Annotation,[0],[0]
"Most of the dialogue acts used for annotation are typical of the goal-oriented setting, such as inform and offer (Henderson et al., 2014b).","4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
"We also introduced dialogue acts specifically for frame tracking, such as switch frame and request compare.","4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
"The dialogue acts are listed in Table 9.
","4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
Our annotation uses three sets of slot types.,"4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
"The first set, listed in Tables 7 and 8, corresponds to the fields of the database.","4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
"The second set is listed in Table 10 and contains the slot types which we defined to describe specific aspects of the dialogue, such as intent, action, and count.","4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
The remaining slot types in Table 10 were introduced to describe frames and cross-references between them.,"4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
Semantic frames form the core of our dataset.,4.2 Frame Definition,[0],[0]
"A semantic frame is defined by the following four components: • User requests: slots whose values the user
wants to know for this frame.",4.2 Frame Definition,[0],[0]
•,4.2 Frame Definition,[0],[0]
"User binary questions: user questions with
slot types and slot values.",4.2 Frame Definition,[0],[0]
•,4.2 Frame Definition,[0],[0]
"Constraints: slots which have been set to a
particular value by the user or the wizard.",4.2 Frame Definition,[0],[0]
•,4.2 Frame Definition,[0],[0]
"User comparison requests: slots whose values
the user wants to know for this frame and one or more other frames.
",4.2 Frame Definition,[0],[0]
"In DSTC, a semantic frame contains the constraints set by the user, the user requests, and the user’s search method (e.g., by constraints or alternatives).",4.2 Frame Definition,[0],[0]
"In our case, constraints can also be set by the wizard when she suggests or offers a package.",4.2 Frame Definition,[0],[0]
Any field in the database (see Tables 7 and 8 in Appendix A) can be constrained by the user or,4.2 Frame Definition,[0],[0]
"User I’d like to book a trip to Atlantis from Caprica on Saturday, 1 August 13, 2016 for 8 adults.",Author Utterance Frame,[0],[0]
I have a tight budget of 1700.,Author Utterance Frame,[0],[0]
"Wizard Hi...I checked a few options for you, and unfortunately, we do not currently have any 1 trips that meet this criteria.",Author Utterance Frame,[0],[0]
Would you like to book an alternate travel option?,Author Utterance Frame,[0],[0]
User,Author Utterance Frame,[0],[0]
"Yes, how about going to Neverland from Caprica on August 13, 2 2016 for 5 adults.",Author Utterance Frame,[0],[0]
"For this trip, my budget would be 1900.",Author Utterance Frame,[0],[0]
Wizard I checked the availability for those dates and there were no trips available.,Author Utterance Frame,[0],[0]
"2 Would you like to select some alternate dates?
the wizard.",Author Utterance Frame,[0],[0]
The comparison requests and the binary questions were added after analysing the dialogues.,Author Utterance Frame,[0],[0]
The comparison requests correspond to the request compare dialogue act.,Author Utterance Frame,[0],[0]
"This dialogue act is used to annotate turns when a user asks to compare different results, for instance: “Could you tell me which of these resorts offers free wifi?”.",Author Utterance Frame,[0],[0]
These questions possibly relate to several frames.,Author Utterance Frame,[0],[0]
"Binary questions are questions with slot types and slot values, e.g., “In which part of the town is the hotel located?”",Author Utterance Frame,[0],[0]
"(request act), or “Is the trip to Marseille cheaper than to Naples?”",Author Utterance Frame,[0],[0]
"(request compare act), as well as all confirm acts.",Author Utterance Frame,[0],[0]
Binary questions may concern one or several frames.,Author Utterance Frame,[0],[0]
Each dialogue starts in frame 1.,4.3 Frame Creation and Switching,[0],[0]
"New frames are introduced when the wizard offers or suggests some-
thing, or when the user modifies pre-established slots.",4.3 Frame Creation and Switching,[0],[0]
"Thus, all values discussed during the dialogue are recorded and the user can return to a previous set of constraints at any point.",4.3 Frame Creation and Switching,[0],[0]
"An example is given in Table 1: the frame number changes when the user modifies several slot values, namely, the destination city, the number of adults for the trip, and the budget.",4.3 Frame Creation and Switching,[0],[0]
"While modifying pre-established slots is supported by most dialogue systems, these rules allow us to clearly distinguishing creating frames from extending frames and thus define how the items in the dialogue memory, which the user can reference, are structured.",4.3 Frame Creation and Switching,[0],[0]
"Though frames are created for each offer or suggestion made by the wizard, the active frame can only be changed by the user so that the user has control over the dialogue.",4.3 Frame Creation and Switching,[0],[0]
"When creating frames, the annotator can explicitly mark which frame the new frame is derived from, which heuristically copies some of its content to the new frame.",4.3 Frame Creation and Switching,[0],[0]
"If not annotated, we assume it is derived from the currently active frame.",4.3 Frame Creation and Switching,[0],[0]
"If the user asks for more information about a specific offer or suggestion, the active frame is changed to the frame introduced with that offer or suggestion.",4.3 Frame Creation and Switching,[0],[0]
This change of frame is indicated by a switch frame act (see Appendix A).,4.3 Frame Creation and Switching,[0],[0]
"The rules for creating and switching frames are summarized in Table 2.
",4.3 Frame Creation and Switching,[0],[0]
We introduced specific slot types for recording the creation and modification of frames.,4.3 Frame Creation and Switching,[0],[0]
"These slot types are id, ref, read, and write (see Table 10 in Appendix A).",4.3 Frame Creation and Switching,[0],[0]
The frame id is defined when the frame is created and is used to switch to,4.3 Frame Creation and Switching,[0],[0]
"Switching User Changing the value of a slot (it causes the dialogue to switch to that frame)
50% 2092
Considering a wizard offer or suggestion 39% 1635 Switching to an earlier frame by mentioning its slot values 11% 458
this frame when the user decides to do so.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
The other slot types are used to annotate cross-references between frames.,Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
A reference has two parts: the id of the frame it refers to and the slots and values that are used to refer to that frame (if any).,Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"For instance, ref[1{name=Tropic}] means that frame 1 is being referred to by the hotel name Tropic.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"If anaphora are used to refer to a frame, we annotated this with the slot ref anaphora (e.g., “This is too long” – inform(duration=toolong, ref anaphora=this)).",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"Inside an offer dialogue act, a ref means that the frame corresponding to the offer is derived from another frame.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
This happens for instance when a wizard proposes a package with business or economy options.,Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"In this case, the business and economy offers are derived from the hotel offer.
",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"The slot types read and write only occur inside a wizard’s inform act and are used by wizards to provide relations between offers or suggestions: read is used to indicate which frame the values come from (and which slots are used to refer to this frame, if any), while write indicates the frame where the slot values are to be written (and which slot values are used to refer to this frame, if any).",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"If there is a read without a write, the current frame is assumed as the storage for the slot values.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"A slot type without a value indicates that the value is the same as in the referenced frame, but was not mentioned explicitly e.g., “for the same price”.
",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"Table 3 gives an example of how these slot types are used in practice: inform( read=[7{dst city=Punta Cana, category=2.5}]) means that the values 2.5 and Punta Cana are to be read from frame 7, and to be written in the current frame.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"At this turn of the dialogue, the wizard repeats information from frame 7.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"The annotation inform(breakfast=False,write= [7{name=El Mar}]) means that the value
False for breakfast is written in frame 7 and that frame 7 was identified in this utterance by the name of the hotel El Mar.
The average number of frames created per dialogue is 6.71 and the average number of frame switches is 3.58.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
Figure 3 shows boxplots for the number of frame creations and the number of frame changes in the corpus.,Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
Five trained experts annotated the dataset according to the above rules.,4.4 Annotation Reproducibility,[0],[0]
"To measure inter-annotator agreement, the experts annotated the same randomly chosen 10 dialogues.",4.4 Annotation Reproducibility,[0],[0]
"On this subset, we compute the inter-annotator agreement rate as the F1-score.",4.4 Annotation Reproducibility,[0],[0]
"Note that the commonly used κ statistic cannot be directly applied here, since the annotation is not a multi-class classification problem.",4.4 Annotation Reproducibility,[0],[0]
"The provided F1 score also captures how much the annotators failed to annotate words or acts, or disagreed about the correct value.",4.4 Annotation Reproducibility,[0],[0]
We report the mean and standard deviation over all possible pairing of annotators.,4.4 Annotation Reproducibility,[0],[0]
"On dialogue acts only, this score is 81.2 ± 3.1, on slot values, it is 95.2 ± 1.1, and on dialogue acts, slot values, and content of referenced frames, it is 62.3 ± 4.9.
",4.4 Annotation Reproducibility,[0],[0]
Table 3:,4.4 Annotation Reproducibility,[0],[0]
Annotation example with the write and read slot types,4.4 Annotation Reproducibility,[0],[0]
"Wizard I am only able to find hotels with a 6 inform(read=[7{dst city=Punta Cana, 2.5 star rating in Punta Cana for that time.",Author Utterance Frame Annotation,[0],[0]
category=2.5}]),Author Utterance Frame Annotation,[0],[0]
User 2.5 stars will do.,Author Utterance Frame Annotation,[0],[0]
11 inform(category=2.5) Can you offer any additional activities?,Author Utterance Frame Annotation,[0],[0]
"Wizard Unfortunately I am not able to provide 11 sorry, canthelp this information.",Author Utterance Frame Annotation,[0],[0]
User How about breakfast?,Author Utterance Frame Annotation,[0],[0]
11 request(breakfast) Wizard El Mar does not provide breakfast.,Author Utterance Frame Annotation,[0],[0]
"11 inform(breakfast=False, write=[7{name=El Mar}])
id=0 (current)",Author Utterance Frame Annotation,[0],[0]
id=1 dst city=Mannheim or city=Melbourne price=8000USD id=2,Author Utterance Frame Annotation,[0],[0]
dst city=New York or city=Melbourne id=3,Author Utterance Frame Annotation,[0],[0]
"(new)
inform(dst city=Mannheim, budget=cheaper, flex=T) Is there a cheaper package to Mannheim?",Author Utterance Frame Annotation,[0],[0]
"I’m flexible with the dates.
",Author Utterance Frame Annotation,[0],[0]
Figure 4: Illustration of the frame tracking task.,Author Utterance Frame Annotation,[0],[0]
"The model must choose, for each slot, which frame it is referring to, given the set of available frames, the previous active frame (bold), and the potential new frame (marked “(new)”).",Author Utterance Frame Annotation,[0],[0]
"Frames can be used to study many aspects of goaloriented dialogue, from Natural Language Understanding (NLU) to Natural Language Generation (NLG).",5 Research Topics,[0],[0]
"In this section, we propose three topics that we believe are new and representative of Frames.",5 Research Topics,[0],[0]
"We propose Frame tracking as an extension of state tracking (Henderson, 2015) to a setting where several semantic frames are tracked simultaneously.",5.1.1 Definition,[0],[0]
"In state tracking, the dialogue history is compressed into one semantic frame.",5.1.1 Definition,[0],[0]
"The state tracker updates a probability distribution, for each slot, over the different possible values.",5.1.1 Definition,[0],[0]
"Every time the user sets a new value, the probability distribution is updated.",5.1.1 Definition,[0],[0]
This architecture prevents the user from comparing options or returning to an item discussed earlier since the values for each slot are tracked separately.,5.1.1 Definition,[0],[0]
"In frame tracking, a new value creates a new semantic frame.",5.1.1 Definition,[0],[0]
"The frame tracking task is significantly harder as it requires, for each user utterance, identifying the active frame as well as all the frames modified by the utterance.",5.1.1 Definition,[0],[0]
"An example is provided in Fig. 4.
",5.1.1 Definition,[0],[0]
Definition 1 (Frame Tracking).,5.1.1 Definition,[0],[0]
"At each user turn t, we assume access to the full dialogue history H = {f1, ..., fnt−1}, where fi is a frame and nt−1 is the number of frames created so far in the dialogue.",5.1.1 Definition,[0],[0]
"For a user utterance ut at time t, we provide the following NLU labels: dialogue acts, slot types, and slot values.",5.1.1 Definition,[0],[0]
"The goal of frame tracking is to predict if a new frame is created and to predict for each dialogue act the ref labels (possibly none) and the ids of the frames referenced.
",5.1.1 Definition,[0],[0]
"Predicting the frame that is referenced by a dialogue act requires detecting if a new frame is created and recognizing a previous frame from the values mentioned by the user (potentially synonyms, e.g., NYC for New York), or by using the user utterance directly.",5.1.1 Definition,[0],[0]
It is necessary in many cases to use the user utterance directly because users do not always use slot values to refer to previous frames.,5.1.1 Definition,[0],[0]
An example in the corpus is a user asking: “Which package has the soonest departure?”.,5.1.1 Definition,[0],[0]
"In this case, the user refers to several frames (the packages) without ever explicitly describing which ones.",5.1.1 Definition,[0],[0]
This phenomenon is quite common for dialogue acts such as switch frame (979 occurrences in the corpus) and request compare (455 occurrences in the corpus).,5.1.1 Definition,[0],[0]
"These cases can only be resolved by working on the text directly and solving anaphora.
",5.1.1 Definition,[0],[0]
"Note that when talking with real users, a system would need to generate the frames dynamically during the dialogue.",5.1.1 Definition,[0],[0]
We propose the frame tracking task as a first step and we show in Section 6.2 that this simplified task entails many challenges.,5.1.1 Definition,[0],[0]
We define two metrics: frame identification and frame creation.,5.1.2 Evaluation Metrics,[0],[0]
"For frame identification, for each dialogue act, we compare the ground truth pair (key-value, frame) to that predicted by the frame tracker.",5.1.2 Evaluation Metrics,[0],[0]
"We compute performance as the number of correct predictions over the number of
pairs.",5.1.2 Evaluation Metrics,[0],[0]
The frame is the id of the referenced frame.,5.1.2 Evaluation Metrics,[0],[0]
"The key and value are respectively the type and the value of the slot used to refer to the frame (these can be null).
",5.1.2 Evaluation Metrics,[0],[0]
"For frame creation, we compute the number of times the frame tracker correctly predicts that a frame is created or correctly predicts that a frame has not been created over the number of dialogue turns.",5.1.2 Evaluation Metrics,[0],[0]
"In previous work, some limitations of sequential slot filling dialogue systems were addressed using goal-modeling (Crook and Lemon, 2010; Crook et al., 2012; Misu et al., 2011), task tracking (Lee and Stent, 2016) and memory-augmentation of classical state tracking (Weston et al., 2015).
",5.1.3 Related Work,[0],[0]
Crook and Lemon (2010); Crook et al. (2012) model the user goal as a subset of all possible slot value combinations and propose techniques to automatically compress this huge space into a summary space.,5.1.3 Related Work,[0],[0]
"Rewards, transitions, and observations of a POMDP system can then be projected to the reduced space, which facilitates policy learning.",5.1.3 Related Work,[0],[0]
Misu et al. (2011) propose a method for decision support in spoken dialogue systems that aids a user who is assumed to have an (unknown) weighted preference over the possible slot values and limited knowledge about alternatives.,5.1.3 Related Work,[0],[0]
The authors employ a user simulator that outputs dialogue acts to learn a policy that optimizes the sum of the weights of the final user selection.,5.1.3 Related Work,[0],[0]
The Frames dataset allows learning and evaluating these techniques on a large and more realistic text-based dataset.,5.1.3 Related Work,[0],[0]
"Additionally, the memorized frames would allow a dialogue system to compare disjunct goals or return to earlier states.
",5.1.3 Related Work,[0],[0]
Recent approaches to state tracking have been suggested to go beyond the sequential slot-filling approach.,5.1.3 Related Work,[0],[0]
An important contribution is the Task Lineage-based Dialog State Tracking (TL-DST) proposed by Lee and Stent (2016).,5.1.3 Related Work,[0],[0]
TL-DST is a framework that allows keeping track of tasks across different domains.,5.1.3 Related Work,[0],[0]
"Similarly to frame tracking, Lee and Stent propose building a dynamic structure of the dialogue containing different frames corresponding to different tasks.",5.1.3 Related Work,[0],[0]
They defined different sub-tasks among which task frame parsing which is closely related to frame tracking except that they impose constraints on how a dialogue act can be assigned to a frame and a dialogue act can only relate to one frame.,5.1.3 Related Work,[0],[0]
"Because of the lack of data, Lee
and Stent (2016) trained their tracking model on datasets released for DSTC (DSTC2 and DSTC3, Henderson et al., 2014b,a).",5.1.3 Related Work,[0],[0]
"As a result, they could artificially mix different tasks, e.g., looking for a restaurant and looking for a pub, but they could not study how human beings switch between topics.",5.1.3 Related Work,[0],[0]
"In addition, this framework can switch between different tasks but does not handle comparisons between disjunct frames, which is an important aspect of frame tracking.
",5.1.3 Related Work,[0],[0]
Another related approach was proposed by Perez and Liu (2016) who re-interpreted the state tracking task as a question-answering task.,5.1.3 Related Work,[0],[0]
"Their state tracker is based on a memory network (Weston et al., 2015) and can answer questions about the user goal at the end of the dialogue.",5.1.3 Related Work,[0],[0]
"They also propose adding functionalities such as keeping a list of the constraints expressed by the user during the dialogue.
",5.1.3 Related Work,[0],[0]
The Frames dataset may be used to test and validate these approaches on real data.,5.1.3 Related Work,[0],[0]
"In addition, we propose the frame tracking task as benchmark and as a first step towards modelling complex decisionmaking behaviour.",5.1.3 Related Work,[0],[0]
"Most of the time, the wizard would speak about the current frame to ask or answer questions.",5.2 Dialogue Management,[0],[0]
"However, sometimes, the wizard would talk about previous frames.",5.2 Dialogue Management,[0],[0]
"An example is given in Table 11 in Appendix A. In the bold utterance in this dialogue, the wizard mentions a frame which is not the currently active frame.",5.2 Dialogue Management,[0],[0]
"In order to reproduce this kind of behaviour, a dialogue manager would need to be able to identify potentially relevant frames for the current turn and to output actions for these frames.
",5.2 Dialogue Management,[0],[0]
Table 11 also illustrates another novelty.,5.2 Dialogue Management,[0],[0]
"In the utterance in italics, the wizard actually performs two actions.",5.2 Dialogue Management,[0],[0]
"The first action consists of informing the user about the price of the regal resort and the second action consists of proposing another option, Hotel Globetrotter.",5.2 Dialogue Management,[0],[0]
"Performing more than one action per turn is a challenge when using reinforcement learning (Pietquin et al., 2011; Gašić et al., 2012; Fatemi et al., 2016) and, to our knowledge, has only been tackled in a simulated setting (Laroche et al., 2009).",5.2 Dialogue Management,[0],[0]
An interesting behaviour observed in Frames is that wizards often tend to summarize database results.,5.3 Natural Language Generation,[0],[0]
"An example is a wizard saying: “The cheapest
available flight is 1947.14USD.”",5.3 Natural Language Generation,[0],[0]
"In this case, the wizard informs the user that the database has no cheaper result than the one she is proposing.",5.3 Natural Language Generation,[0],[0]
"To imitate this behaviour, a natural language generator (Oh and Rudnicky, 2000; Wen et al., 2015; Sharma et al., 2017) would need to reason over the database and decide how to tailor the results to the user and present them in a concise but sufficient way.",5.3 Natural Language Generation,[0],[0]
"Various strategies and their combinations can be employed, e.g. summarization, comparison or recommendation (Rieser and Lemon, 2009).",5.3 Natural Language Generation,[0],[0]
A decision-theoretical foundation of such an approach was presented by Walker et al. (2004).,5.3 Natural Language Generation,[0],[0]
A data-driven approach to attribute selection for NLG as planning under uncertainty was proposed by Rieser et al. (2014).,5.3 Natural Language Generation,[0],[0]
"The Frames dataset contains a larger set of dialogues as well as wizard-generated text with detailed annotations, which we believe will provide insight into when humans use which strategy and how they present the information.",5.3 Natural Language Generation,[0],[0]
We developed baseline models for natural language understanding and frame tracking.,6 Baselines,[0],[0]
"We define the NLU task as dialogue act prediction and IOB (Inside, Outside, Beginning) tagging.",6.1 Natural Language Understanding,[0],[0]
The NLU model that we propose as baseline is illustrated in Fig. 5.,6.1 Natural Language Understanding,[0],[0]
"We predict, for each word of the utterance, a pair of tags – one for the act and one for the slot.",6.1 Natural Language Understanding,[0],[0]
"This model operates on character trigrams and is based on the robust named entity recognition model (Arnold et al., 2016) except that it has two heads instead of one: one head for the slot type (either a slot type or an O tag) as in the original model and one head for dialogue act prediction.",6.1 Natural Language Understanding,[0],[0]
"These two parts share an embedding matrix for the input character trigrams.
",6.1 Natural Language Understanding,[0],[0]
We generated the IOB tags by matching the slot values in the manual annotations with the corresponding textual utterances.,6.1 Natural Language Understanding,[0],[0]
Note that the model only predicts IOB tags for slots whose values can be found in the text.,6.1 Natural Language Understanding,[0],[0]
"Therefore, the prediction for slots such as intent or vicinities and amenities is not evaluated for this simple baseline.",6.1 Natural Language Understanding,[0],[0]
"The act tags were also generated at the word level: for a given dialogue act with slot values, each word between the slot value that occurred first in the text and the one that occurred last in the text was tagged with the corresponding act.",6.1 Natural Language Understanding,[0],[0]
"For example, for the utterance I am only able to find hotels with a 2.5 star rating in Punta Cana for that time.",6.1 Natural Language Understanding,[0],[0]
", the words 2.5 star rating in Punta Cana are tagged with the inform dialogue act.",6.1 Natural Language Understanding,[0],[0]
"The other words are tagged with O.
The two parts of the model are trained simultaneously, using a modified categorical crossentropy loss for both sets of outputs.",6.1 Natural Language Understanding,[0],[0]
We modify the loss to ignore O labels that are already predicted correctly by the model.,6.1 Natural Language Understanding,[0],[0]
"We introduce this modification because O labels are far more frequent than other labels, and not limiting their contribution to the loss causes the model to degenerate to predicting O labels for every word.",6.1 Natural Language Understanding,[0],[0]
"The losses for both parts of the model are added together and the combined objective is optimized using ADAM (Kingma and Ba, 2015).
",6.1 Natural Language Understanding,[0],[0]
We provide F1 scores for acts and slots for this model in Table 4.,6.1 Natural Language Understanding,[0],[0]
"We report average and stan-
dard deviation over ten leave-one-user-out splits of the Frames dataset.",6.1 Natural Language Understanding,[0],[0]
We had a total of 11 participants who played the user role at least once during data collection.,6.1 Natural Language Understanding,[0],[0]
Two participants performed significantly fewer dialogues than the others.,6.1 Natural Language Understanding,[0],[0]
We merged the dialogues generated by these two participants (ids U21E41CQP and U23KPC9QV).,6.1 Natural Language Understanding,[0],[0]
"For each of the resulting 10 users, we randomly split the combined dialogues of the nine others into training (80%) and validation (20%), and then tested on the dialogues from the held-out user.",6.1 Natural Language Understanding,[0],[0]
"We propose a rule-based frame tracking baseline which takes as input the dialogue acts with slot types and slot values but without the referenced frames (i.e., the ref slots) as well as all the frames created so far during the dialogue.",6.2 Frame Tracking,[0],[0]
"Based on this input, the tracker predicts the ref tags (for frame identification, see Section 5.1.2) for each dialogue act, and it predicts if a frame is created.",6.2 Frame Tracking,[0],[0]
We write f,6.2 Frame Tracking,[0],[0]
[k] to denote the value of slot k in frame f .,6.2 Frame Tracking,[0],[0]
"For an act a(k=v) in frame f , the following rules are used:
• Create and switch to a new frame if f",6.2 Frame Tracking,[0],[0]
"[k] is set and a is inform, but v does not match f",6.2 Frame Tracking,[0],[0]
[k].,6.2 Frame Tracking,[0],[0]
• Switch to frame g if a is switch frame and g[k] matches v.,6.2 Frame Tracking,[0],[0]
"If no match is found, switch to the most recently created frame.3 • Assign ref to frame g if a can have a ref tag, and g[k] matches v. The most recently created frame is used in ambiguous cases.",6.2 Frame Tracking,[0],[0]
"If no match is found, assign ref to the current frame.
",6.2 Frame Tracking,[0],[0]
We compare this baseline to random performance.,6.2 Frame Tracking,[0],[0]
"For random performance, for each (dialogue act, slot type) combination, we compute priors on the corpus for each time the user would refer to the current frame vs a previous one.",6.2 Frame Tracking,[0],[0]
"We sampled whether each slot referred to the current frame or another one based on that prior, and if it referred to another frame, the frame number for that other frame was sampled uniformly from the list of frames created so far.
",6.2 Frame Tracking,[0],[0]
Table 5 presents results for these baselines.,6.2 Frame Tracking,[0],[0]
We report results over 10 runs following the same evaluation method as for the NLU model.,6.2 Frame Tracking,[0],[0]
"Table 5 shows that the rule-based model performs only slightly better than random on frame identification
3a reasonable assumption since this case often happens when a wizard makes an offer and the user talks about it.
and performs similarly on frame creation.",6.2 Frame Tracking,[0],[0]
Table 6 presents an analysis of the performance of the rulebased model.,6.2 Frame Tracking,[0],[0]
We report the accuracy of the frame tracking baseline on the most crucial sub-tasks of frame tracking for one fold.,6.2 Frame Tracking,[0],[0]
The top table shows that the most difficult tasks consist of assigning the correct frame to a switch frame act when the act is not directly preceded by an offer and when the act has no slots.,6.2 Frame Tracking,[0],[0]
"As discussed previously, when the act has no slots, it is important to consider the text and solve anaphora.",6.2 Frame Tracking,[0],[0]
"When the act is directly preceded by an offer, the baseline assigns the previous frame, which is the frame of the offer and which most of the time is the frame that the user switched to, e.g., to ask for more information about the offer.",6.2 Frame Tracking,[0],[0]
"In terms of frame creation, the baseline has very poor performance in correctly predicting that a frame is created because the user changes the value of a previously set slot.",6.2 Frame Tracking,[0],[0]
These results demonstrate that frame tracking cannot be solved with simple rules and necessitates tackling many complex sub-tasks.,6.2 Frame Tracking,[0],[0]
We introduced the Frames dataset: a corpus of human-human dialogues in a travel domain.,7 Conclusion,[0],[0]
This dataset contains complex user behaviour such as comparing between offers.,7 Conclusion,[0],[0]
"We formalized the frame tracking task, which requires tracking simultaneously several semantic frames during a dialogue.",7 Conclusion,[0],[0]
We proposed a rule-based model for this task and analysed its performance.,7 Conclusion,[0],[0]
We release Frames in the hope of driving further research on complex decision-making in the dialogue community.,7 Conclusion,[0],[0]
"Wizard A 5 star hotel called the Regal Resort, Wizard it has free wifi and a spa.",Author Utterance,[0],[0]
User dates?,Author Utterance,[0],[0]
Wizard Starts on august 27th until the 30th User ok that could work.,Author Utterance,[0],[0]
"I would like to see my options in Santos as well Wizard regal resort goes for $2800 or there is the Hotel
Globetrotter in Santos it has 3 stars and comes with breakfast and wifi, it leaves on the 25th and returns on the 30th!",Author Utterance,[0],[0]
"all for $2000
User",Author Utterance,[0],[0]
ahh,Author Utterance,[0],[0]
I can’t leave until august 26 though Wizard then i guess you might have to choose the Regal resort,Author Utterance,[0],[0]
User,Author Utterance,[0],[0]
yeah.,Author Utterance,[0],[0]
I will book it Wizard Thank you!,Author Utterance,[0],[0]
"This paper proposes a new dataset, Frames, composed of 1369 human-human dialogues with an average of 15 turns per dialogue.",abstractText,[0],[0]
This corpus contains goal-oriented dialogues between users who are given some constraints to book a trip and assistants who search a database to find appropriate trips.,abstractText,[0],[0]
"The users exhibit complex decision-making behaviour which involve comparing trips, exploring different options, and selecting among the trips that were discussed during the dialogue.",abstractText,[0],[0]
"To drive research on dialogue systems towards handling such behaviour, we have annotated and released the dataset and we propose in this paper a task called frame tracking.",abstractText,[0],[0]
This task consists of keeping track of different semantic frames throughout each dialogue.,abstractText,[0],[0]
We propose a rule-based baseline and analyse the frame tracking task through this baseline.,abstractText,[0],[0]
Frames: A Corpus for Adding Memory to Goal-Oriented Dialogue Systems,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 773–783 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1072",text,[0],[0]
"Ideas exist in the mind, but are made manifest in language, where they compete with each other for the scarce resource of human attention.",1 Introduction,[0],[0]
Milton (1644) used the “marketplace of ideas” metaphor to argue that the truth will win out when ideas freely compete; Dawkins (1976) similarly likened the evolution of ideas to natural selection of genes.,1 Introduction,[0],[0]
"We propose a framework to quantitatively characterize competition and cooperation between ideas in texts, independent of how they might be represented.
",1 Introduction,[0],[0]
"By “ideas”, we mean any discrete conceptual
units that can be identified as being present or absent in a document.",1 Introduction,[0],[0]
"In this work, we consider representing ideas using keywords and topics obtained in an unsupervised fashion, but our way of characterizing the relations between ideas could be applied to many other types of textual representations, such as frames (Card et al., 2015) and hashtags.
",1 Introduction,[0],[0]
"What does it mean for two ideas to compete in texts, quantitatively?",1 Introduction,[0],[0]
"Consider, for example, the issue of immigration.",1 Introduction,[0],[0]
There are two strongly competing narratives about the roughly 11 million people1 who are residing in the United States without permission.,1 Introduction,[0],[0]
"One is “illegal aliens”, who “steal” jobs and deny opportunities to legal immigrants; the other is “undocumented immigrants”, who are already part of the fabric of society and deserve a path to citizenship (Merolla et al., 2013).
",1 Introduction,[0],[0]
"Although prior knowledge suggests that these two narratives compete, it is not immediately obvious what measures might reveal this competition in a corpus of writing about immigration.",1 Introduction,[0],[0]
One question is whether or not these two ideas cooccur in the same documents.,1 Introduction,[0],[0]
"In the example above, these narratives are used by distinct groups of people with different ideologies.",1 Introduction,[0],[0]
"The fact that they don’t cooccur is one clue that they may be in competition with each other.
",1 Introduction,[0],[0]
"However, cooccurrence is insufficient to express the selection process of ideas, i.e., some ideas fade out over time, while others rise in popularity, analogous to the populations of species in nature.",1 Introduction,[0],[0]
"Of the two narratives on immigration, we may expect one to win out at the expense of another as public opinion shifts.",1 Introduction,[0],[0]
"Alternatively, we might expect to see these narratives reinforcing each other, as both sides intensify their messaging in response to growing opposition, much like the U.S.S.R. and
1As of 2014, according to the most recent numbers from the Center for Migration Studies (Warren, 2016).
",1 Introduction,[0],[0]
"773
the U.S. during the cold war.",1 Introduction,[0],[0]
"To capture these possibilities, we use prevalence correlation over time.
",1 Introduction,[0],[0]
"Building on these insights, we propose a framework that combines cooccurrence within documents and prevalence correlation over time.",1 Introduction,[0],[0]
This framework gives rise to four possible types of relation that correspond to the four quadrants in Fig. 1.,1 Introduction,[0],[0]
We explain each type using examples from news articles in U.S. newspapers on immigration from 1980 to 2016.,1 Introduction,[0],[0]
"Here, we have used LDA to identify ideas in the form of topics, and we denote each idea with a pair of words most strongly associated with the corresponding topic.
",1 Introduction,[0],[0]
"Friendship (correlated over time, likely to cooccur).",1 Introduction,[0],[0]
"The “immigrant, undocumented” topic tends to cooccur with “obama, president” and both topics have been rising during the period of our dataset, likely because the “undocumented immigrants” narrative was an important part of Obama’s framing of the immigration issue (Haynes et al., 2016).
",1 Introduction,[0],[0]
"Head-to-head (anti-correlated over time, unlikely to cooccur).",1 Introduction,[0],[0]
"“immigrant, undocumented” and “illegal, alien” are in a head-to-head competition: these two topics rarely cooccur, and “immigrant, undocu-
mented” has been growing in prevalence, while the usage of “illegal, alien” in newspapers has been declining.",1 Introduction,[0],[0]
"This observation agrees with a report from Pew Research Center (Guskin, 2013).
",1 Introduction,[0],[0]
"Tryst (anti-correlated over time, likely to cooccur).",1 Introduction,[0],[0]
The two off-diagonal examples use topics related to law enforcement.,1 Introduction,[0],[0]
"Overall, “immigration, deportation” and “detention, jail” often cooccur but “detention, jail” has been declining, while “immigration, deportation” has been rising.",1 Introduction,[0],[0]
"This possibly relates to the promises to overhaul the immigration detention system (Kalhan, 2010).2
Arms-race (correlated over time, unlikely to cooccur).",1 Introduction,[0],[0]
"One of the above law enforcement topics (“immigration, deportation”) and a topic on the Republican party (“republican, party”) hold an armsrace relation: they are both growing in prevalence over time, but rarely cooccur, perhaps suggesting an underlying common cause.
",1 Introduction,[0],[0]
"2The tryst relation is the least intuitive, yet is nevertheless observed.",1 Introduction,[0],[0]
"The pattern of being anti-correlated yet likely to cooccur is typically found when two ideas exhibit a friendship pattern (cooccurring and correlated), but only briefly, and then diverge.
",1 Introduction,[0],[0]
"Note that our terminology describes the relations between ideas in texts, not necessarily between the entities to which the ideas refer.",1 Introduction,[0],[0]
"For example, we find that the relation between “Israel” and “Palestine” is “friendship” in news articles on terrorism, based on their prevalence correlation and cooccurrence in that corpus.
We introduce the formal definition of our framework in §2 and apply it to news articles on five issues and research papers from ACL Anthology and NIPS as testbeds.",1 Introduction,[0],[0]
"We operationalize ideas using topics (Blei et al., 2003) and keywords (Monroe et al., 2008).
",1 Introduction,[0],[0]
"To explore whether the four relation types exist and how strong these relations are, we first examine the marginal and joint distributions of cooccurrence and prevalence correlation (§3).",1 Introduction,[0],[0]
We find that cooccurrence shows a unimodal normal-shaped distribution but prevalence correlation demonstrates more diverse distributions across corpora.,1 Introduction,[0],[0]
"As we would expect, there are, in general, more and stronger friendship and head-to-head relations than arms-race and tryst relations.
",1 Introduction,[0],[0]
"Second, we demonstrate the effectiveness of our framework through in-depth case studies (§4).",1 Introduction,[0],[0]
"We not only validate existing knowledge about some news issues and research areas, but also identify hypotheses that require further investigation.",1 Introduction,[0],[0]
"For example, using keywords to represent ideas, a top pair with the tryst relation in news articles on terrorism is “arab” and “islam”; they are likely to cooccur, but “islam” is rising in relative prevalence while “arab” is declining.",1 Introduction,[0],[0]
This suggests a conjecture that the news media have increasingly linked terrorism to a religious group rather than an ethnic group.,1 Introduction,[0],[0]
"We also show relations between topics in ACL that center around machine translation.
",1 Introduction,[0],[0]
"Our work is a first step towards understanding relations between ideas from text corpora, a complex and important research question.",1 Introduction,[0],[0]
We provide some concluding thoughts in §6.,1 Introduction,[0],[0]
The aim of our computational framework is to explore relations between ideas.,2 Computational Framework,[0],[0]
"We thus assume that the set of relevant ideas has been identified, and those expressed in each document have been tabulated.",2 Computational Framework,[0],[0]
Our open-source implementation is at https://github.com/Noahs-ARK/ idea_relations/.,2 Computational Framework,[0],[0]
"In the following, we introduce our formal definitions and datasets.
∀x, y ∈",2 Computational Framework,[0],[0]
"I, P̂MI(x, y) = log P̂ (x, y) P̂ (x)P̂ (y)
",2 Computational Framework,[0],[0]
"= C + log 1+ ∑ t ∑ k 1{x∈dtk}·1{y∈dtk}
(1+ ∑
t ∑ k 1{x∈dtk})·(1+ ∑ t ∑ k 1{y∈dtk})
(1)
r̂(x, y) =
∑ t ( P̂ (x|t)−P̂ (x|t) )",2 Computational Framework,[0],[0]
"( P̂ (y|t)−P̂ (y|t) )
",2 Computational Framework,[0],[0]
"√ ∑
t
( P̂ (x|t)−P̂ (x|t) )",2 Computational Framework,[0],[0]
"2√∑ t ( P̂ (y|t)−P̂ (y|t) )2
",2 Computational Framework,[0],[0]
"(2)
Figure 2: Eq. 1 is the empirical pointwise mutual information for two ideas, our measure of cooccurrence of ideas; note that we use add-one smoothing in estimating PMI.",2 Computational Framework,[0],[0]
Eq. 2 is the Pearson correlation between two ideas’ prevalence over time.,2 Computational Framework,[0],[0]
"As discussed in the introduction, we focus on two dimensions to quantify relations between ideas:
1.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"cooccurrence reveals to what extent two ideas tend to occur in the same contexts;
2.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"similarity between the relative prevalence of ideas over time reveals how two ideas relate in terms of popularity or coverage.
",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"Our input is a collection of documents, each represented by a set of ideas and indexed by time.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"We denote a static set of ideas as I and a text corpus that consists of these ideas as C = {D1, . . .",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
", DT }, where Dt = {dt1 , . . .",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
", dtNt} gives the collection of documents at timestep t, and each document, dtk , is represented as a subset of ideas in I.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"Here T is the total number of timesteps, and Nt is the number of documents at timestep t.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"It follows that the total number of documents N = ∑T t=1Nt.
",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"In order to formally capture the two dimensions above, we employ two commonly-used statistics.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"First, we use empirical pointwise mutual information (PMI) to capture the cooccurrence of ideas within the same document (Church and Hanks, 1990); see Eq. 1 in Fig. 2.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
Positive,2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"P̂MI indicates that ideas occur together more frequently than would be expected if they were independent, while negative P̂MI indicates the opposite.
",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"Second, we compute the correlation between normalized document frequency of ideas to capture the relation between the relative prevalence of ideas across documents over time; see Eq. 2 in Fig. 2.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"Positive r̂ indicates that two ideas have similar prevalence over time, while negative r̂ sug-
gests two anti-correlated ideas (i.e., when one goes up, the other goes down).
",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"The four types of relations in the introduction can now be obtained using P̂MI and r̂, which capture cooccurrence and prevalence correlation respectively.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"We further define the strength of the relation between two ideas as the absolute value of the product of their P̂MI and r̂ scores:
∀x, y ∈",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"I, strength(x, y) = |P̂MI(x, y)×r̂(x, y)|.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
(3),2.1 Cooccurrence and Prevalence Correlation,[0],[0]
We use two types of datasets to validate our framework: news articles and research papers.,2.2 Datasets and Representation of Ideas,[0],[0]
"We choose these two domains because competition between ideas has received significant interest in history of science (Kuhn, 1996) and research on framing (Chong and Druckman, 2007; Entman, 1993; Gitlin, 1980; Lakoff, 2014).",2.2 Datasets and Representation of Ideas,[0],[0]
"Furthermore, interesting differences may exist in these two domains as news evolves with external events and scientific research progresses through innovations.",2.2 Datasets and Representation of Ideas,[0],[0]
• News articles.,2.2 Datasets and Representation of Ideas,[0],[0]
"We follow the strategy in Card
et al. (2015) to obtain news articles from LexisNexis on five issues: abortion, immigration, same-sex marriage, smoking, and terrorism.",2.2 Datasets and Representation of Ideas,[0],[0]
We search for relevant articles using LexisNexis subject terms in U.S. newspapers from 1980 to 2016.,2.2 Datasets and Representation of Ideas,[0],[0]
"Each of these corpora contains more than 25,000 articles.",2.2 Datasets and Representation of Ideas,[0],[0]
"Please refer to the supplementary material for details.
",2.2 Datasets and Representation of Ideas,[0],[0]
• Research papers.,2.2 Datasets and Representation of Ideas,[0],[0]
"We consider full texts of papers from two communities: our own ACL community captured by papers from ACL, NAACL, EMNLP, and TACL from 1980 to 2014 (Radev et al., 2009); and the NIPS community from 1987 to 2016.3 There are 4.8K papers from the ACL community and 6.6K papers from the NIPS community.",2.2 Datasets and Representation of Ideas,[0],[0]
"The processed datasets are available at https://chenhaot.com/ pages/idea-relations.html.
",2.2 Datasets and Representation of Ideas,[0],[0]
"In order to operationalize ideas in a text corpus, we consider two ways to represent ideas.",2.2 Datasets and Representation of Ideas,[0],[0]
•,2.2 Datasets and Representation of Ideas,[0],[0]
Topics.,2.2 Datasets and Representation of Ideas,[0],[0]
"We extract topics from each document
by running LDA (Blei et al., 2003) on each corpus C. In all datasets, we set the number of topics to 50.4 Formally, I is the 50 topics learned 3 http://papers.nips.cc/. 4We chose 50 topics based on past experience, though this could be tuned for particular applications.",2.2 Datasets and Representation of Ideas,[0],[0]
"Recall that
from the corpus, and each document is represented as the set of topics that are present with greater than 0.01 probability in the topic distribution for that document.
",2.2 Datasets and Representation of Ideas,[0],[0]
•,2.2 Datasets and Representation of Ideas,[0],[0]
Keywords.,2.2 Datasets and Representation of Ideas,[0],[0]
We identify a list of distinguishing keywords for each corpus by comparing its word frequencies to the background frequencies found in other corpora using the informative Dirichlet prior model in Monroe et al. (2008).,2.2 Datasets and Representation of Ideas,[0],[0]
We set the number of keywords to 100 for all corpora.,2.2 Datasets and Representation of Ideas,[0],[0]
"For news articles, the background corpus for each issue is comprised of all articles from the other four issues.",2.2 Datasets and Representation of Ideas,[0],[0]
"For research papers, we use NIPS as the background corpus for ACL and vice versa to identify what are the core concepts for each of these research areas.",2.2 Datasets and Representation of Ideas,[0],[0]
"Formally, I is the 100 top distinguishing keywords in the corpus and each document is represented as the set of keywords within I that are present in the document.",2.2 Datasets and Representation of Ideas,[0],[0]
"Refer to the supplementary material for a list of example keywords in each corpus.
",2.2 Datasets and Representation of Ideas,[0],[0]
"In both procedures, we lemmatize all words and add common bigram phrases to the vocabulary following Mikolov et al. (2013).",2.2 Datasets and Representation of Ideas,[0],[0]
"Note that in our analysis, ideas are only present or absent in a document, and a document can in principle be mapped to any subset of ideas in I.",2.2 Datasets and Representation of Ideas,[0],[0]
"In our experiments 90% of documents are marked as containing between 7 and 14 ideas using topics, 8 and 33 ideas using keywords.",2.2 Datasets and Representation of Ideas,[0],[0]
"To provide an overview of the four relation types in Fig. 1, we first examine the empirical distributions of the two statistics of interest across pairs of ideas.",3 Characterizing the Space of Relations,[0],[0]
"In most exploratory studies, however, we are most interested in pairs that exemplify each type of relation, i.e., the most extreme points in each quadrant.",3 Characterizing the Space of Relations,[0],[0]
We thus look at these pairs in each corpus to observe how the four types differ in salience across datasets.,3 Characterizing the Space of Relations,[0],[0]
"To the best of our knowledge, the distributions of pairwise cooccurrence and prevalence correlation have not been examined in previous literature.",3.1 Empirical Distribution Properties,[0],[0]
"We thus first investigate the marginal distributions of cooccurrence and prevalence correlation and then
our framework is to analyze relations between ideas, so this choice is not essential in this work.
",3.1 Empirical Distribution Properties,[0],[0]
their joint distribution.,3.1 Empirical Distribution Properties,[0],[0]
Fig. 3 shows three examples: two from news articles and one from research papers.,3.1 Empirical Distribution Properties,[0],[0]
We will also focus our case studies on these three corpora in §4.,3.1 Empirical Distribution Properties,[0],[0]
The corresponding plots for keywords have been relegated to supplementary material due to space limitations.,3.1 Empirical Distribution Properties,[0],[0]
Cooccurrence tends to be unimodal but not normal.,3.1 Empirical Distribution Properties,[0],[0]
"In all of our datasets, pairwise cooccurrence (P̂MI) presents a unimodal distribution that somewhat resembles a normal distribution, but it is rarely precisely normal.",3.1 Empirical Distribution Properties,[0],[0]
"We cannot reject the hypothesis that it is unimodal for any dataset (using topics or keywords) using the dip test (Hartigan and Hartigan, 1985), though D’Agostino’s K2 test (D’Agostino et al., 1990) rejects normality in almost all cases.",3.1 Empirical Distribution Properties,[0],[0]
Prevalence correlation exhibits diverse distributions.,3.1 Empirical Distribution Properties,[0],[0]
"Pairwise prevalence correlation follows different distributions in news articles compared to research papers: they are unimodal in news articles, but not in ACL or NIPS.",3.1 Empirical Distribution Properties,[0],[0]
The dip test only rejects the unimodality hypothesis in NIPS.,3.1 Empirical Distribution Properties,[0],[0]
None follow normal distributions based on D’Agostino’s K2 test.,3.1 Empirical Distribution Properties,[0],[0]
Cooccurrence is positively correlated with prevalence correlation.,3.1 Empirical Distribution Properties,[0],[0]
"In all of our datasets, cooccurrence is positively correlated with prevalence correlation whether we use topics or keywords to represent ideas, although the Pearson correlation coefficients vary.",3.1 Empirical Distribution Properties,[0],[0]
This suggests that there are more friendship and head-to-head relations than tryst and arms-race relations.,3.1 Empirical Distribution Properties,[0],[0]
"Based on the results of kernel density estimation, we also observe that this correlation is often loose, e.g., in
ACL topics, cooccurrence spreads widely at each mode of prevalence correlation.",3.1 Empirical Distribution Properties,[0],[0]
We are interested in how our framework can identify intriguing relations between ideas.,3.2 Relative Strength of Extreme Pairs,[0],[0]
"These potentially interesting pairs likely correspond to the extreme points in each quadrant instead of the ones around the origin, where PMI and prevalence correlation are both close to zero.",3.2 Relative Strength of Extreme Pairs,[0],[0]
Here we compare the relative strength of extreme pairs in each dataset.,3.2 Relative Strength of Extreme Pairs,[0],[0]
"We will discuss how these extreme pairs confirm existing knowledge and suggest new hypotheses via case studies in §4.
",3.2 Relative Strength of Extreme Pairs,[0],[0]
"For each relation type, we average the strengths of the 25 pairs with the strongest relations in that type, with strength defined in Eq. 3.",3.2 Relative Strength of Extreme Pairs,[0],[0]
"This heuristic (henceforth collective strength) allows us to collectively compare the strengths of the most prominent friendship, tryst, arms-race, and head-to-head relations.",3.2 Relative Strength of Extreme Pairs,[0],[0]
"The results are not sensitive to the choice of 25.
",3.2 Relative Strength of Extreme Pairs,[0],[0]
Fig. 4 shows the collective strength of the four types in all of our datasets.,3.2 Relative Strength of Extreme Pairs,[0],[0]
"The most common ordering is:
friendship > head-to-head > arms-race > tryst.
",3.2 Relative Strength of Extreme Pairs,[0],[0]
The fact that friendship and head-to-head relations are strong is consistent with the positive correlation between cooccurrence and prevalence correlation.,3.2 Relative Strength of Extreme Pairs,[0],[0]
"In news, friendship is the strongest relation type, but head-to-head is the strongest in ACL topics and NIPS topics.",3.2 Relative Strength of Extreme Pairs,[0],[0]
"This suggests, unsurprisingly, that there are stronger head-to-head competitions
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 co lle ct iv e st re ng th
friends tryst head-to-head arms-race
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 co lle ct iv e st re ng th
friends tryst head-to-head arms-race
(i.e., one idea takes over another) between ideas in scientific research than in news.",3.2 Relative Strength of Extreme Pairs,[0],[0]
"We also see that topics show greater strength in our scientific article collections, while keywords dominate in news, especially in friendship.",3.2 Relative Strength of Extreme Pairs,[0],[0]
"We conjecture that terms in scientific literature are often overloaded (e.g., a tree could be a parse tree or a decision tree), necessitating some abstraction when representing ideas.",3.2 Relative Strength of Extreme Pairs,[0],[0]
"In contrast, news stories are more self-contained and seek to employ consistent usage.",3.2 Relative Strength of Extreme Pairs,[0],[0]
We present case studies based on strongly related pairs of ideas in the four types of relation.,4 Exploratory Studies,[0],[0]
"Throughout this section, “rank” refers to the rank of the relation strength between a pair of ideas in its corresponding relation type.",4 Exploratory Studies,[0],[0]
"Following a decade of declining violence in the 90s, the events of September 11, 2001 precipitated a dramatic increase in concern about terrorism, and a major shift in how it was framed (Kern et al., 2003).",4.1 International Relations in Terrorism,[0],[0]
"As a showcase, we consider a topic which encompasses much of the U.S. government’s response to terrorism: “federal, state”.5 We observe two topics engaging in an “arms race” with this one: “afghanistan, taliban” and “pakistan, india”.",4.1 International Relations in Terrorism,[0],[0]
"These correspond to two geopolitical regions closely linked to the U.S. government’s concern with terrorism, and both were sites of U.S. military action during the period of our dataset.",4.1 International Relations in Terrorism,[0],[0]
"Events abroad and the U.S. government’s responses follow the arms-race pattern, each holding increasing
5As in §1, we summarize each topic using a pair of strongly associated words, instead of assigning a name.
attention with the other, likely because they share the same underlying cause.
",4.1 International Relations in Terrorism,[0],[0]
"We also observe two head-to-head rivals to the “federal, state” topic: “iran, libya” and “israel, palestinian”.",4.1 International Relations in Terrorism,[0],[0]
"While these topics correspond to regions that are hotly debated in the U.S., their coverage in news tends not to correlate temporally with the U.S. government’s responses to terrorism, at least during the time period of our corpus.",4.1 International Relations in Terrorism,[0],[0]
"Discussion of these regions was more prevalent in the 80s and 90s, with declining media coverage since then (Kern et al., 2003).
",4.1 International Relations in Terrorism,[0],[0]
"The relations between these topics are consistent with structural balance theory (Cartwright and Harary, 1956; Heider, 1946), which suggests that the enemy of an enemy is a friend.",4.1 International Relations in Terrorism,[0],[0]
"The “afghanistan, taliban” topic has the strongest friendship relation with the “pakistan, india” topic, i.e., they are likely to cooccur and are positively correlated in prevalence.",4.1 International Relations in Terrorism,[0],[0]
"Similarly, the “iran, libya” topic is a close “friend” with the “israel, palestinian” topic (ranked 8th in friendship).
",4.1 International Relations in Terrorism,[0],[0]
"When using keywords to represent ideas, we observe similar relations between the term homeland security and terms related to the above foreign countries.",4.1 International Relations in Terrorism,[0],[0]
"In addition, we highlight an interesting but unexpected tryst relation between arab and islam (Fig. 6).",4.1 International Relations in Terrorism,[0],[0]
"It is not surprising that these two words tend to cooccur in the same news articles, but the usage of islam in the news is increasing while arab is declining.",4.1 International Relations in Terrorism,[0],[0]
"The increasing prevalence of islam and decreasing prevalence of arab over this time period can also be seen, for example, using Google’s n-gram viewer, but it of course provides no information about cooccurrence.
",4.1 International Relations in Terrorism,[0],[0]
"This trend has not been previously noted to the best of our knowledge, although an article in the Huffington Post called for news editors to distinguish Muslim from Arab.6 Our observation suggests a conjecture that the news media have increasingly linked terrorism to a religious group rather than an ethnic group, perhaps in part due to the tie between the events of 9/11 and Afghanistan, which is not an Arab or Arabic-speaking country.",4.1 International Relations in Terrorism,[0],[0]
"We leave it to further investigation to confirm or reject this hypothesis.
",4.1 International Relations in Terrorism,[0],[0]
"To further demonstrate the effectiveness of our approach, we compare a pair’s rank using only cooccurrence or prevalence correlation with its rank in our framework.",4.1 International Relations in Terrorism,[0],[0]
Table 1 shows the results for three pairs above.,4.1 International Relations in Terrorism,[0],[0]
"If we had looked at only cooccurrence or prevalence correlation, we would probably have missed these interesting pairs.
",4.1 International Relations in Terrorism,[0],[0]
6http://www.huffingtonpost.com/ haroon-moghul/even-the-new-york-times-d_ b_766658.html,4.1 International Relations in Terrorism,[0],[0]
"In addition to results on topics in §1, we observe unexpected patterns about ethnicity keywords in immigration news.",4.2 Ethnicity Keywords in Immigration,[0],[0]
Our observation starts with a top tryst relation between latino and asian.,4.2 Ethnicity Keywords in Immigration,[0],[0]
"Although these words are likely to cooccur, their prevalence trajectories differ, with the discussion of Asian immigrants in the 1990s giving way to a focus on the word latino from 2000 onward.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"Possible theories to explain this observation include that undocumented immigrants are generally perceived as a Latino issue, or that Latino voters are increasingly influential in U.S. elections.
",4.2 Ethnicity Keywords in Immigration,[0],[0]
"Furthermore, latino holds head-to-head relations with two subgroups of Latin American immigrants: haitian and cuban.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"In particular, the strength of the relation with haitian is ranked #18 in headto-head relations.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"Meanwhile, haitian and cuban have a friendship relation, which is again consistent with structural balance theory.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"The decreasing prevalence of haitian and cuban perhaps speaks to the shifting geographical focus of recent immigration to the U.S., and issues of the Latino panethnicity.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"In fact, a majority of Latinos prefer to identify with their national origin relative to the
pan-ethnic terms (Taylor et al., 2012).",4.2 Ethnicity Keywords in Immigration,[0],[0]
"However, we should also note that much of this coverage relates to a set of specific refugee crises, temporarily elevating the political importance of these nations in the U.S.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"Nevertheless, the underlying social and political reasons behind these head-to-head relations are worth further investigation.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"Finally, we analyze relations between topics in the ACL Anthology.",4.3 Relations between Topics in ACL,[0],[0]
It turns out that “machine translation” is at a central position among top ranked relations in all the four types (Fig.,4.3 Relations between Topics in ACL,[0],[0]
8).7,4.3 Relations between Topics in ACL,[0],[0]
"It is part of the strongest relation in all four types except tryst (ranked #5).
",4.3 Relations between Topics in ACL,[0],[0]
The full relation graph presents further patterns.,4.3 Relations between Topics in ACL,[0],[0]
Friendship demonstrates transitivity: both “machine translation” and “word alignment” have similar relations with other topics.,4.3 Relations between Topics in ACL,[0],[0]
"But such transitivity does not hold for tryst: although the prevalence of “rule, forest methods” is anti-correlated with both “machine translation” and “sentiment analysis”, “sentiment analysis” seldom cooccurs with “rule, for-
7In the ranking, we filtered a topic where the top words are ion, ing, system, process, language, one, input, natural language, processing, grammar.",4.3 Relations between Topics in ACL,[0],[0]
"For the purposes of this corpus, this is effectively a stopword topic.
",4.3 Relations between Topics in ACL,[0],[0]
est methods” because “sentiment analysis” is seldom built on parsing algorithms.,4.3 Relations between Topics in ACL,[0],[0]
"Similarly, “rule, forest methods” and “discourse (coherence)” hold an armsrace relation: they do not tend to cooccur and both decline in relative prevalence as “machine translation” rises.
",4.3 Relations between Topics in ACL,[0],[0]
"The prevalence of each of these ideas in comparison to machine translation is shown in in Fig. 9, which reveals additional detail.",4.3 Relations between Topics in ACL,[0],[0]
We present two strands of related studies in addition to what we have discussed.,5 Related Work,[0],[0]
Trends in ideas.,5 Related Work,[0],[0]
"Most studies have so far examined the trends of ideas individually (Michel et al., 2011; Hall et al., 2008; Rule et al., 2015).",5 Related Work,[0],[0]
"For instance, Hall et al. (2008) present various trends in our own computational linguistics community, including the rise of statistical machine translation.",5 Related Work,[0],[0]
"More recently, rhetorical framing has been used to predict these sorts of patterns (Prabhakaran et al., 2016).",5 Related Work,[0],[0]
An exception is that Shi et al. (2010) use prevalence correlation to analyze lag relations between topics in publications and research grants.,5 Related Work,[0],[0]
"Anecdotally, Grudin (2009) observes a “head-tohead” relation between artificial intelligence and human-computer interaction in research funding.",5 Related Work,[0],[0]
"However, to our knowledge, our work is the first study to systematically characterize relations between ideas.",5 Related Work,[0],[0]
Representation of ideas.,5 Related Work,[0],[0]
"In addition to topics and keywords, studies have also sought to operationalize the “memes” metaphor using quotes and text reuse in the media (Leskovec et al., 2009; Niculae et al., 2015; Smith et al., 2013; Wei et al., 2013).",5 Related Work,[0],[0]
"In topic modeling literature, Blei and Lafferty (2006) also point out that topics do not cooccur independently and explicitly model the cooccurrence within documents.",5 Related Work,[0],[0]
We proposed a method to characterize relations between ideas in texts through the lens of cooccurrence within documents and prevalence correlation over time.,6 Concluding Discussion,[0],[0]
"For the first time, we observe that the distribution of pairwise cooccurrence is unimodal, while the distribution of pairwise prevalence correlation is not always unimodal, and show that they are positively correlated.",6 Concluding Discussion,[0],[0]
"This combination suggests four types of relations between ideas, and these four types are all found to varying extents in our experiments.
",6 Concluding Discussion,[0],[0]
We illustrate our computational method by exploratory studies on news corpora and scientific research papers.,6 Concluding Discussion,[0],[0]
"We not only confirm existing knowledge but also suggest hypotheses around the usage of arab and islam in terrorism and latino and asian in immigration.
",6 Concluding Discussion,[0],[0]
It is important to note that the relations found using our approach depend on the nature of the representation of ideas and the source of texts.,6 Concluding Discussion,[0],[0]
"For instance, we cannot expect relations found in news articles to reflect shifts in public opinion if news articles do not effectively track public opinion.
",6 Concluding Discussion,[0],[0]
Our method is entirely observational.,6 Concluding Discussion,[0],[0]
"It remains as a further stage of analysis to understand the underlying reasons that lead to these relations be-
tween ideas.",6 Concluding Discussion,[0],[0]
"In scientific research, for example, it could simply be the progress of science, i.e., newer ideas overtake older ones deemed less valuable at a given time; on the other hand, history suggests that it is not always the correct ideas that are most expressed, and many other factors may be important.",6 Concluding Discussion,[0],[0]
"Similarly, in news coverage, underlying sociological and political situations have significant impact on which ideas are presented, and how.
",6 Concluding Discussion,[0],[0]
There are many potential directions to improve our method to account for complex relations between ideas.,6 Concluding Discussion,[0],[0]
"For instance, we assume that both ideas and relations are statically grounded in keywords or topics.",6 Concluding Discussion,[0],[0]
"In reality, ideas and relations both evolve over time: a tryst relation might appear as friendship if we focus on a narrower time period.",6 Concluding Discussion,[0],[0]
"Similarly, new ideas show up and even the same idea may change over time and be represented by different words.",6 Concluding Discussion,[0],[0]
Acknowledgments.,6 Concluding Discussion,[0],[0]
"We thank Amber Boydstun, Justin Gross, Lillian Lee, anonymous reviewers, and all members of Noah’s ARK for helpful comments and discussions.",6 Concluding Discussion,[0],[0]
This research was made possible by a Natural Sciences and Engineering Research Council of Canada Postgraduate Scholarship (to D.C.) and a University of Washington Innovation Award.,6 Concluding Discussion,[0],[0]
"Understanding how ideas relate to each other is a fundamental question in many domains, ranging from intellectual history to public communication.",abstractText,[0],[0]
"Because ideas are naturally embedded in texts, we propose the first framework to systematically characterize the relations between ideas based on their occurrence in a corpus of documents, independent of how these ideas are represented.",abstractText,[0],[0]
Combining two statistics—cooccurrence within documents and prevalence correlation over time—our approach reveals a number of different ways in which ideas can cooperate and compete.,abstractText,[0],[0]
"For instance, two ideas can closely track each other’s prevalence over time, and yet rarely cooccur, almost like a “cold war” scenario.",abstractText,[0],[0]
We observe that pairwise cooccurrence and prevalence correlation exhibit different distributions.,abstractText,[0],[0]
We further demonstrate that our approach is able to uncover intriguing relations between ideas through in-depth case studies on news articles and research papers.,abstractText,[0],[0]
"Friendships, Rivalries, and Trysts: Characterizing Relations between Ideas in Texts",title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1051–1062 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1097",text,[0],[0]
"We are interested in learning a semantic parser that maps natural language utterances into executable programs (e.g., logical forms).",1 Introduction,[0],[0]
"For example, in Figure 1, a program corresponding to the utterance transforms an initial world state into a new world state.",1 Introduction,[0],[0]
"We would like to learn from indirect supervision, where each training example is only labeled with the correct output (e.g. a target world state), but not the program that produced that out-
z*
z'0.1
0.1
0.1 0.1 0.1
0.1 0.1 0.1 0.1 0.1
p(z')",1 Introduction,[0],[0]
"= 10-4
p(z*) = 10-6
red
yellow hasHat blue hasShirt leftOf move
move1hasShirt
put (Clarke et al., 2010; Liang et al., 2011; Krishnamurthy and Mitchell, 2012; Artzi and Zettlemoyer, 2013; Liang et al., 2017).
",1 Introduction,[0],[0]
"The process of constructing a program can be formulated as a sequential decision-making process, where feedback is only received at the end of the sequence when the completed program is executed.",1 Introduction,[0],[0]
"In the natural language processing literature, there are two common approaches for handling this situation: 1) reinforcement learning (RL), particularly the REINFORCE algorithm (Williams, 1992; Sutton et al., 1999), which maximizes the expected reward of a sequence of actions; and 2) maximum marginal likelihood (MML), which treats the sequence of actions as a latent variable, and then maximizes the marginal likelihood of observing the correct program output (Dempster et al., 1977).
",1 Introduction,[0],[0]
"While the two approaches have enjoyed success on many tasks, we found them to work poorly out of the box for our task.",1 Introduction,[0],[0]
"This is because in addition to the sparsity of correct programs, our task also requires weeding out spurious programs (Pasupat and Liang, 2016): incorrect interpretations
1051
of the utterances that accidentally produce the correct output, as illustrated in Figure 1.
",1 Introduction,[0],[0]
We show that MML and RL optimize closely related objectives.,1 Introduction,[0],[0]
"Furthermore, both MML and RL methods have a mechanism for exploring program space in search of programs that generate the correct output.",1 Introduction,[0],[0]
"We explain why this exploration tends to quickly concentrate around short spurious programs, causing the model to sometimes overlook the correct program.",1 Introduction,[0],[0]
"To address this problem, we propose RANDOMER, a new learning algorithm with two parts:
First, we propose randomized beam search, an exploration strategy which combines the systematic beam search traditionally employed in MML with the randomized off-policy exploration of RL.",1 Introduction,[0],[0]
"This increases the chance of finding correct programs even when the beam size is small or the parameters are not pre-trained.
",1 Introduction,[0],[0]
"Second, we observe that even with good exploration, the gradients of both the RL and MML objectives may still upweight entrenched spurious programs more strongly than correct programs with low probability under the current model.",1 Introduction,[0],[0]
"We propose a meritocratic parameter update rule, a modification to the MML gradient update, which more equally upweights all programs that produce the correct output.",1 Introduction,[0],[0]
"This makes the model less likely to overfit spurious programs.
",1 Introduction,[0],[0]
"We apply RANDOMER to train a new neural semantic parser, which outputs programs in a stackbased programming language.",1 Introduction,[0],[0]
"We evaluate our resulting system on SCONE, the context-dependent semantic parsing dataset of Long et al. (2016).",1 Introduction,[0],[0]
"Our approach outperforms standard RL and MML methods in a direct comparison, and achieves new state-of-the-art results, improving over Long et al. (2016) in all three domains of SCONE, and by over 30% accuracy on the most challenging one.",1 Introduction,[0],[0]
"We consider the semantic parsing task in the SCONE dataset1 (Long et al., 2016).",2 Task,[0],[0]
"As illustrated in Figure 1, each example consists of a world containing several objects (e.g., people), each with certain properties (e.g., shirt color and hat color).",2 Task,[0],[0]
"Given the initial world state w0 and a sequence of M natural language utterances u = (u1, . . .",2 Task,[0],[0]
", uM ), the task is to generate a program that manipulates the world state according to the utterances.",2 Task,[0],[0]
"Each
1 https://nlp.stanford.edu/projects/scone
utterance um describes a single action that transforms the world state wm−1 into a new world state wm.",2 Task,[0],[0]
"For training, the system receives weakly supervised examples with input x = (u, w0) and the target final world state y = wM .
",2 Task,[0],[0]
"The dataset includes 3 domains: ALCHEMY, TANGRAMS, and SCENE.",2 Task,[0],[0]
"The description of each domain can be found in Appendix B. The domains highlight different linguistic phenomena: ALCHEMY features ellipsis (e.g., “throw the rest out”, “mix”); TANGRAMS features anaphora on actions (e.g., “repeat step 3”, “bring it back”); and SCENE features anaphora on entities (e.g., “he moves back”, “. . .",2 Task,[0],[0]
to his left”).,2 Task,[0],[0]
"Each domain contains roughly 3,700 training and 900 test examples.",2 Task,[0],[0]
"Each example contains 5 utterances and is labeled with the target world state after each utterance, but not the target program.
",2 Task,[0],[0]
Spurious programs.,2 Task,[0],[0]
"Given a training example (u, w0, wM ), our goal is to find the true underlying program z∗ which reflects the meaning of u. The constraint that z∗ must transformw0 intowM , i.e. z(w0) = wM , is not enough to uniquely identify the true z∗, as there are often many z satisfying z(w0) = wM",2 Task,[0],[0]
": in our experiments, we found at least 1600 on average for each example.",2 Task,[0],[0]
Almost all do not capture the meaning of u (see Figure 1).,2 Task,[0],[0]
We refer to these incorrect z’s as spurious programs.,2 Task,[0],[0]
"Such programs encourage the model to learn an incorrect mapping from language to program operations: e.g., the spurious program in Figure 1 would cause the model to learn that “man in the yellow hat” maps to hasShirt(red).
",2 Task,[0],[0]
Spurious programs in SCONE.,2 Task,[0],[0]
"In this dataset, utterances often reference objects in different ways (e.g. a person can be referenced by shirt color, hat color, or position).",2 Task,[0],[0]
"Hence, any target programming language must also support these different reference strategies.",2 Task,[0],[0]
"As a result, even a single action such as moving a person to a target destination can be achieved by many different programs, each selecting the person and destination in a different way.",2 Task,[0],[0]
"Across multiple actions, the number of programs grows combinatorially.2",2 Task,[0],[0]
Only a few programs actually implement the correct reference strategy as defined by the utterance.,2 Task,[0],[0]
"This problem would be more severe in any more general-purpose language (e.g. Python).
2The number of well-formed programs in SCENE exceeds 1015",2 Task,[0],[0]
We formulate program generation as a sequence prediction problem.,3 Model,[0],[0]
"We represent a program as a sequence of program tokens in postfix notation; for example, move(hasHat(yellow), leftOf(hasShirt(blue))) is linearized as yellow hasHat blue hasShirt leftOf move.",3 Model,[0],[0]
"This representation also allows us to incrementally execute programs from left to right using a stack: constants (e.g., yellow) are pushed onto the stack, while functions (e.g., hasHat) pop appropriate arguments from the stack and push back the computed result (e.g., the list of people with yellow hats).",3 Model,[0],[0]
"Appendix B lists the full set of program tokens, Z , and how they are executed.",3 Model,[0],[0]
"Note that each action always ends with an action token (e.g., move).
",3 Model,[0],[0]
"Given an input x = (u, w0), the model generates program tokens z1, z2, . . .",3 Model,[0],[0]
"from left to right using a neural encoder-decoder model with attention (Bahdanau et al., 2015).",3 Model,[0],[0]
"Throughout the generation process, the model maintains an utterance pointer, m, initialized to 1.",3 Model,[0],[0]
"To generate zt, the model’s encoder first encodes the utterance um into a vector em.",3 Model,[0],[0]
"Then, based on em and previously generated tokens z1:t−1, the model’s decoder defines a distribution p(zt | x, z1:t−1) over the possible values of zt ∈ Z .",3 Model,[0],[0]
The next token zt is sampled from this distribution.,3 Model,[0],[0]
"If an action token (e.g., move) is generated, the model increments the utterance pointer m. The process terminates when all M utterances are processed.",3 Model,[0],[0]
"The final probability of generating a particular program z = (z1, . . .",3 Model,[0],[0]
", zT ) is",3 Model,[0],[0]
p(z | x) = ∏T t=1,3 Model,[0],[0]
p(zt,3 Model,[0],[0]
"| x, z1:t−1).
",3 Model,[0],[0]
Encoder.,3 Model,[0],[0]
"The utterance um under the pointer is encoded using a bidirectional LSTM:
hFi = LSTM(h F i−1,Φu(um,i))",3 Model,[0],[0]
"hBi = LSTM(h B i+1,Φu(um,i))
",3 Model,[0],[0]
hi =,3 Model,[0],[0]
"[h F i ;h B i ],
where Φu(um,i) is the fixed GloVe word embedding (Pennington et al., 2014) of the ith word in um.",3 Model,[0],[0]
The final utterance embedding is the concatenation em =,3 Model,[0],[0]
"[hF|um|;h B 1 ].
Decoder.",3 Model,[0],[0]
"Unlike Bahdanau et al. (2015), which used a recurrent network for the decoder, we opt for a feed-forward network for simplicity.",3 Model,[0],[0]
"We use em and an embedding f(z1:t−1) of the previous execution history (described later) as inputs to
compute an attention vector ct:
qt = ReLU(Wq[em; f(z1:t−1)])",3 Model,[0],[0]
αi ∝,3 Model,[0],[0]
"exp(q>t Wahi) (i = 1, . . .",3 Model,[0],[0]
", |um|) ct = ∑
i
αihi.
",3 Model,[0],[0]
"Finally, after concatenating qt with ct, the distribution over the set Z of possible program tokens is computed via a softmax:
p(zt | x, z1:t−1) ∝",3 Model,[0],[0]
"exp(Φz(zt)>Ws[qt; ct]),
where Φz(zt) is the embedding for token zt.
",3 Model,[0],[0]
Execution history embedding.,3 Model,[0],[0]
"We compare two options for f(z1:t−1), our embedding of the execution history.",3 Model,[0],[0]
A standard approach is to simply take the k most recent tokens zt−k:t−1 and concatenate their embeddings.,3 Model,[0],[0]
"We will refer to this as TOKENS and use k = 4 in our experiments.
",3 Model,[0],[0]
We also consider a new approach which leverages our ability to incrementally execute programs using a stack.,3 Model,[0],[0]
"We summarize the execution history by embedding the state of the stack at time t − 1, achieved by concatenating the embeddings of all values on the stack.",3 Model,[0],[0]
(We limit the maximum stack size to 3.),3 Model,[0],[0]
We refer to this as STACK.,3 Model,[0],[0]
"Having formulated our task as a sequence prediction problem, we must still choose a learning algorithm.",4 Reinforcement learning versus maximum marginal likelihood,[0],[0]
We first compare two standard paradigms: reinforcement learning (RL) and maximum marginal likelihood (MML).,4 Reinforcement learning versus maximum marginal likelihood,[0],[0]
"In the next section, we propose a better alternative.",4 Reinforcement learning versus maximum marginal likelihood,[0],[0]
Reinforcement learning.,4.1 Comparing objective functions,[0],[0]
"From an RL perspective, given a training example (x, y), a policy makes a sequence of decisions z = (z1, . . .",4.1 Comparing objective functions,[0],[0]
", zT ), and then receives a reward at the end of the episode: R(z)",4.1 Comparing objective functions,[0],[0]
"= 1 if z executes to y and 0 otherwise (dependence on x and y has been omitted from the notation).
",4.1 Comparing objective functions,[0],[0]
"We focus on policy gradient methods, in which a stochastic policy function is trained to maximize the expected reward.",4.1 Comparing objective functions,[0],[0]
"In our setup, pθ(z | x) is the policy (with parameters θ), and its expected reward on a given example (x, y) is
G(x, y) = ∑
z
R(z) pθ(z | x), (1)
where the sum is over all possible programs.",4.1 Comparing objective functions,[0],[0]
"The overall RL objective, JRL, is the expected reward across examples:
JRL = ∑
(x,y)
G(x, y).",4.1 Comparing objective functions,[0],[0]
"(2)
Maximum marginal likelihood.",4.1 Comparing objective functions,[0],[0]
"The MML perspective assumes that y is generated by a partially-observed random process: conditioned on x, a latent program z is generated, and conditioned on z, the observation y is generated.",4.1 Comparing objective functions,[0],[0]
"This implies the marginal likelihood:
pθ(y",4.1 Comparing objective functions,[0],[0]
"| x) = ∑
z
p(y | z) pθ(z | x).",4.1 Comparing objective functions,[0],[0]
"(3)
Note that since the execution of z is deterministic, pθ(y | z) = 1 if z executes to y and 0 otherwise.",4.1 Comparing objective functions,[0],[0]
"The log marginal likelihood of the data is then
JMML = logLMML, (4)",4.1 Comparing objective functions,[0],[0]
"where LMML = ∏
(x,y)
pθ(y | x).",4.1 Comparing objective functions,[0],[0]
"(5)
To estimate our model parameters θ, we maximize JMML with respect to θ.
",4.1 Comparing objective functions,[0],[0]
"With our choice of reward, the RL expected reward (1) is equal to the MML marginal probability (3).",4.1 Comparing objective functions,[0],[0]
"Hence the only difference between the two formulations is that in RL we optimize the sum of expected rewards (2), whereas in MML we optimize the product (5).3",4.1 Comparing objective functions,[0],[0]
"In both policy gradient and MML, the objectives are typically optimized via (stochastic) gradient ascent.",4.2 Comparing gradients,[0],[0]
The gradients of JRL and JMML are closely related.,4.2 Comparing gradients,[0],[0]
"They both have the form:
∇θJ = ∑
(x,y)
Ez∼q",4.2 Comparing gradients,[0],[0]
[R(z)∇ log pθ(z | x)],4.2 Comparing gradients,[0],[0]
"(6)
= ∑
(x,y)
∑
z
q(z)R(z)∇ log pθ(z | x),
where q(z) equals
qRL(z) = pθ(z | x) for JRL, (7)
qMML(z) = R(z)pθ(z | x)∑ z̃R(z̃)pθ(z̃",4.2 Comparing gradients,[0],[0]
"| x)
",4.2 Comparing gradients,[0],[0]
"(8)
= pθ(z | x,R(z) 6= 0) for JMML. 3",4.2 Comparing gradients,[0],[0]
"Note that the log of the product in (5) does not equal the
sum in (2).
",4.2 Comparing gradients,[0],[0]
"Taking a step in the direction of∇ log pθ(z | x) upweights the probability of z, so we can heuristically think of the gradient as attempting to upweight each reward-earning program z by a gradient weight q(z).",4.2 Comparing gradients,[0],[0]
"In Subsection 5.2, we argue why qMML is better at guarding against spurious programs, and propose an even better alternative.",4.2 Comparing gradients,[0],[0]
It is often intractable to compute the gradient (6) because it involves taking an expectation over all possible programs.,4.3 Comparing gradient approximation strategies,[0],[0]
"So in practice, the expectation is approximated.
",4.3 Comparing gradient approximation strategies,[0],[0]
"In the policy gradient literature, Monte Carlo integration (MC) is the typical approximation strategy.",4.3 Comparing gradient approximation strategies,[0],[0]
"For example, the popular REINFORCE algorithm (Williams, 1992) uses Monte Carlo sampling to compute an unbiased estimate of the gradient:
∆MC = 1
B
∑ z∈S",4.3 Comparing gradient approximation strategies,[0],[0]
"[R(z)− c]∇ log pθ(z | x), (9)
where S is a collection of B samples z(b) ∼ q(z), and c is a baseline (Williams, 1992) used to reduce the variance of the estimate without altering its expectation.
",4.3 Comparing gradient approximation strategies,[0],[0]
"In the MML literature for latent sequences, the expectation is typically approximated via numerical integration (NUM) instead:
∆NUM = ∑
z∈S q(z)R(z)∇ log pθ(z | x).",4.3 Comparing gradient approximation strategies,[0],[0]
"(10)
where the programs in S come from beam search.
",4.3 Comparing gradient approximation strategies,[0],[0]
Beam search.,4.3 Comparing gradient approximation strategies,[0],[0]
Beam search generates a set of programs via the following process.,4.3 Comparing gradient approximation strategies,[0],[0]
"At step t of beam search, we maintain a beam Bt of at most B search states.",4.3 Comparing gradient approximation strategies,[0],[0]
"Each state s ∈ Bt represents a partially constructed program, s = (z1, . . .",4.3 Comparing gradient approximation strategies,[0],[0]
", zt) (the first t tokens of the program).",4.3 Comparing gradient approximation strategies,[0],[0]
"For each state s in the beam, we generate all possible continuations,
cont(s) = cont((z1, . . .",4.3 Comparing gradient approximation strategies,[0],[0]
", zt))
",4.3 Comparing gradient approximation strategies,[0],[0]
"= {(z1, . . .",4.3 Comparing gradient approximation strategies,[0],[0]
", zt, zt+1)",4.3 Comparing gradient approximation strategies,[0],[0]
"| zt+1 ∈ Z} .
",4.3 Comparing gradient approximation strategies,[0],[0]
"We then take the union of these continuations, cont(Bt) =",4.3 Comparing gradient approximation strategies,[0],[0]
⋃ s∈Bt cont(s).,4.3 Comparing gradient approximation strategies,[0],[0]
"The new beam Bt+1 is simply the highest scoringB continuations in cont(Bt), as scored by the policy, pθ(s | x).",4.3 Comparing gradient approximation strategies,[0],[0]
"Search is halted after a fixed number of iterations
or when there are no continuations possible.",4.3 Comparing gradient approximation strategies,[0],[0]
S is then the set of all complete programs discovered during beam search.,4.3 Comparing gradient approximation strategies,[0],[0]
"We will refer to this as beam search MML (BS-MML).
",4.3 Comparing gradient approximation strategies,[0],[0]
"In both policy gradient and MML, we think of the procedure used to produce the set of programs S as an exploration strategy which searches for programs that produce reward.",4.3 Comparing gradient approximation strategies,[0],[0]
One advantage of numerical integration is that it allows us to decouple the exploration strategy from the gradient weights assigned to each program.,4.3 Comparing gradient approximation strategies,[0],[0]
"In this section, we illustrate why spurious programs are problematic for the most commonly used methods in RL (REINFORCE) and MML (beam search MML).",5 Tackling spurious programs,[0],[0]
"We describe two key problems and propose a solution to each, based on insights gained from our comparison of RL and MML in Section 4.",5 Tackling spurious programs,[0],[0]
"As mentioned in Section 4, REINFORCE and BSMML both employ an exploration strategy to approximate their respective gradients.",5.1 Spurious programs bias exploration,[0],[0]
"In both methods, exploration is guided by the current model policy, whereby programs with high probability under the current policy are more likely to be explored.",5.1 Spurious programs bias exploration,[0],[0]
"A troubling implication is that programs with low probability under the current policy are likely to be overlooked by exploration.
",5.1 Spurious programs bias exploration,[0],[0]
"If the current policy incorrectly assigns low probability to the correct program z∗, it will likely fail to discover z∗ during exploration, and will consequently fail to upweight the probability of z∗.",5.1 Spurious programs bias exploration,[0],[0]
"This repeats on every gradient step, keeping the probability of z∗ perpetually low.",5.1 Spurious programs bias exploration,[0],[0]
The same feedback loop can also cause already highprobability spurious programs to gain even more probability.,5.1 Spurious programs bias exploration,[0],[0]
"From this, we see that exploration is sensitive to initial conditions: the rich get richer, and the poor get poorer.
",5.1 Spurious programs bias exploration,[0],[0]
"Since there are often thousands of spurious programs and only a few correct programs, spurious programs are usually found first.",5.1 Spurious programs bias exploration,[0],[0]
"Once spurious programs get a head start, exploration increasingly biases towards them.
",5.1 Spurious programs bias exploration,[0],[0]
"As a remedy, one could try initializing parameters such that the model puts a uniform distribution over all possible programs.",5.1 Spurious programs bias exploration,[0],[0]
"A seemingly reasonable tactic is to initialize parameters such that the
""The man in the yellow hat moves to the left of the woman in blue.”
",5.1 Spurious programs bias exploration,[0],[0]
"Spurious: move(hasShirt(red), 1) Correct: move(hasHat(yellow), leftOf(hasShirt(blue)))
1 2 3 1 2 3
BEFORE AFTER
model policy puts near-uniform probability over the decisions at each time step.",5.1 Spurious programs bias exploration,[0],[0]
"However, this causes shorter programs to have orders of magnitude higher probability than longer programs, as illustrated in Figure 2 and as we empirically observe.",5.1 Spurious programs bias exploration,[0],[0]
A more sophisticated approach might involve approximating the total number of programs reachable from each point in the programgenerating decision tree.,5.1 Spurious programs bias exploration,[0],[0]
"However, we instead propose to reduce sensitivity to the initial distribution over programs.
",5.1 Spurious programs bias exploration,[0],[0]
Solution: randomized beam search One solution to biased exploration is to simply rely less on the untrustworthy current policy.,5.1 Spurious programs bias exploration,[0],[0]
"We can do this by injecting random noise into exploration.
",5.1 Spurious programs bias exploration,[0],[0]
"In REINFORCE, a common solution is to sample from an -greedy variant of the current policy.",5.1 Spurious programs bias exploration,[0],[0]
"On the other hand, MML exploration with beam search is deterministic.",5.1 Spurious programs bias exploration,[0],[0]
"However, it has a key advantage over REINFORCE-style sampling: even if one program occupies almost all probability under the current policy (a peaky distribution), beam search will still use its remaining beam capacity to explore at least B− 1 other programs.",5.1 Spurious programs bias exploration,[0],[0]
"In contrast, sampling methods will repeatedly visit the mode of the distribution.
",5.1 Spurious programs bias exploration,[0],[0]
"To get the best of both worlds, we propose a simple -greedy randomized beam search.",5.1 Spurious programs bias exploration,[0],[0]
"Like regular beam search, at iteration t we compute the set of all continuations cont(Bt) and sort them by their model probability pθ(s | x).",5.1 Spurious programs bias exploration,[0],[0]
"But instead of selecting the B highest-scoring continuations, we choose B continuations one by one without replacement from cont(Bt).",5.1 Spurious programs bias exploration,[0],[0]
"When choosing a continuation from the remaining pool, we either uniformly sample a random continuation with probability , or pick the highest-scoring continuation in the pool with probability 1− .",5.1 Spurious programs bias exploration,[0],[0]
"Empirically, we
find that this performs much better than both classic beam search and -greedy sampling (Table 3).",5.1 Spurious programs bias exploration,[0],[0]
"In both RL and MML, even if exploration is perfect and the gradient is exactly computed, spurious programs can still be problematic.
",5.2 Spurious programs dominate gradients,[0],[0]
"Even if perfect exploration visits every program, we see from the gradient weights q(z) in (7) and (8) that programs are weighted proportional to their current policy probability.",5.2 Spurious programs dominate gradients,[0],[0]
"If a spurious program z′ has 100 times higher probability than z∗ as in Figure 2, the gradient will spend roughly 99% of its magnitude upweighting towards z′ and only 1% towards z∗ even though the two programs get the same reward.
",5.2 Spurious programs dominate gradients,[0],[0]
This implies that it would take many updates for z∗ to catch up.,5.2 Spurious programs dominate gradients,[0],[0]
"In fact, z∗ may never catch up, depending on the gradient updates for other training examples.",5.2 Spurious programs dominate gradients,[0],[0]
"Simply increasing the learning rate is inadequate, as it would cause the model to take overly large steps towards z′, potentially causing optimization to diverge.
",5.2 Spurious programs dominate gradients,[0],[0]
"Solution: the meritocratic update rule To solve this problem, we want the upweighting to be more “meritocratic”: any program that obtains reward should be upweighted roughly equally.
",5.2 Spurious programs dominate gradients,[0],[0]
We first observe that JMML already improves over JRL in this regard.,5.2 Spurious programs dominate gradients,[0],[0]
"From (6), we see that the gradient weight qMML(z) is the policy distribution restricted to and renormalized over only rewardearning programs.",5.2 Spurious programs dominate gradients,[0],[0]
"This renormalization makes the gradient weight uniform across examples: even if all reward-earning programs for a particular example have very low model probability, their combined gradient weight ∑ z qMML(z) is always 1.",5.2 Spurious programs dominate gradients,[0],[0]
"In our experiments, JMML performs significantly better than JRL (Table 4).
",5.2 Spurious programs dominate gradients,[0],[0]
"However, while JMML assigns uniform weight across examples, it is still not uniform over the programs within each example.",5.2 Spurious programs dominate gradients,[0],[0]
Hence we propose a new update rule which goes one step further in pursuing uniform updates.,5.2 Spurious programs dominate gradients,[0],[0]
"Extending qMML(z), we define a β-smoothed version:
qβ(z) = qMML(z)
β
∑ z̃ qMML(z̃) β .",5.2 Spurious programs dominate gradients,[0],[0]
"(11)
When β = 0, our weighting is completely uniform across all reward-earning programs within an example while β = 1 recovers the original MML weighting.",5.2 Spurious programs dominate gradients,[0],[0]
"Our new update rule is to simply take
a modified gradient step where q = qβ .4 We will refer to this as the β-meritocratic update rule.",5.2 Spurious programs dominate gradients,[0],[0]
We described two problems5 and their solutions: we reduce exploration bias using -greedy randomized beam search and perform more balanced optimization using the β-meritocratic parameter update rule.,5.3 Summary of the proposed approach,[0],[0]
We call our resulting approach RANDOMER.,5.3 Summary of the proposed approach,[0],[0]
Table 1 summarizes how RANDOMER combines desirable qualities from both REINFORCE and BS-MML.,5.3 Summary of the proposed approach,[0],[0]
Evaluation.,6 Experiments,[0],[0]
We evaluate our proposed methods on all three domains of the SCONE dataset.,6 Experiments,[0],[0]
Accuracy is defined as the percentage of test examples where the model produces the correct final world state wM .,6 Experiments,[0],[0]
"All test examples have M = 5 (5utts), but we also report accuracy after processing the first 3 utterances (3utts).",6 Experiments,[0],[0]
"To control for the effects of randomness, we train 5 instances of each model with different random seeds.",6 Experiments,[0],[0]
"We report the median accuracy of the instances unless otherwise noted.
Training.",6 Experiments,[0],[0]
"Following Long et al. (2016), we decompose each training example into smaller examples.",6 Experiments,[0],[0]
"Given an example with 5 utterances, u = [u1, . . .",6 Experiments,[0],[0]
", u5], we consider all length-1 and length-2 substrings of u:",6 Experiments,[0],[0]
"[u1], [u2], . . .",6 Experiments,[0],[0]
",",6 Experiments,[0],[0]
"[u3, u4], [u4, u5] (9 total).",6 Experiments,[0],[0]
"We form a new training example from each substring, e.g., (u′, w′0, w ′ M )",6 Experiments,[0],[0]
"where u
′ =",6 Experiments,[0],[0]
"[u4, u5], w′0 = w3 and w ′",6 Experiments,[0],[0]
"M = w5.
",6 Experiments,[0],[0]
"All models are implemented in TensorFlow (Abadi et al., 2015).",6 Experiments,[0],[0]
"Model parameters are randomly initialized (Glorot and Bengio, 2010), with no pre-training.",6 Experiments,[0],[0]
"We use the Adam optimizer (Kingma and Ba, 2014) (which is applied to the gradient in (6)), a learning rate of 0.001, a minibatch size of 8 examples (different from the beam size), and train until accuracy on the validation set converges (on average about 13,000 steps).",6 Experiments,[0],[0]
"We
4 Also, note that if exploration were exhaustive, β = 0 would be equivalent to supervised learning using the set of all reward-earning programs as targets.
",6 Experiments,[0],[0]
5,6 Experiments,[0],[0]
These problems concern the gradient w.r.t.,6 Experiments,[0],[0]
a single example.,6 Experiments,[0],[0]
"The full gradient averages over multiple examples, which helps separate correct from spurious.",6 Experiments,[0],[0]
"E.g., if multiple examples all mention “yellow hat”, we will find a correct program parsing this as hasHat(yellow) for each example, whereas the spurious programs we find will follow no consistent pattern.",6 Experiments,[0],[0]
"Consequently, spurious gradient contributions may cancel out while correct program gradients will all “vote” in the same direction.
",6 Experiments,[0],[0]
"use fixed GloVe vectors (Pennington et al., 2014) to embed the words in each utterance.
Hyperparameters.",6 Experiments,[0],[0]
"For all models, we performed a grid search over hyperparameters to maximize accuracy on the validation set.",6 Experiments,[0],[0]
"Hyperparameters include the learning rate, the baseline in REINFORCE, -greediness and βmeritocraticness.",6 Experiments,[0],[0]
"For REINFORCE, we also experimented with a regression-estimated baseline (Ranzato et al., 2015), but found it to perform worse than a constant baseline.",6 Experiments,[0],[0]
Comparison to prior work.,6.1 Main results,[0],[0]
"Table 2 compares RANDOMER to results from Long et al. (2016) as well as two baselines, REINFORCE and BSMML",6.1 Main results,[0],[0]
(using the same neural model but different learning algorithms).,6.1 Main results,[0],[0]
"Our approach achieves new state-of-the-art results by a significant margin, especially on the SCENE domain, which features the most complex program syntax.",6.1 Main results,[0],[0]
"We report the results for REINFORCE, BS-MML, and RANDOMER on the seed and hyperparameters that achieve the best validation accuracy.
",6.1 Main results,[0],[0]
We note that REINFORCE performs very well on TANGRAMS but worse on ALCHEMY and very poorly on SCENE.,6.1 Main results,[0],[0]
"This might be because the program syntax for TANGRAMS is simpler than the other two: there is no other way to refer to objects except by index.
",6.1 Main results,[0],[0]
We also found that REINFORCE required - greedy exploration to make any progress.,6.1 Main results,[0],[0]
"Using -greedy greatly skews the Monte Carlo approximation of ∇JRL, making it more uniformly weighted over programs in a similar spirit to using β-meritocratic gradient weights qβ .",6.1 Main results,[0],[0]
"However, qβ increases uniformity over reward-earning programs only, rather than over all programs.
",6.1 Main results,[0],[0]
Effect of randomized beam search.,6.1 Main results,[0],[0]
Table 3 shows that -greedy randomized beam search consistently outperforms classic beam search.,6.1 Main results,[0],[0]
"Even when we increase the beam size of classic beam
search to 128, it still does not surpass randomized beam search with a beam of 32, and further increases yield no additional improvement.
",6.1 Main results,[0],[0]
Effect of β-meritocratic updates.,6.1 Main results,[0],[0]
Table 4 evaluates the impact of β-meritocratic parameter updates (gradient weight qβ).,6.1 Main results,[0],[0]
"More uniform upweighting across reward-earning programs leads to higher accuracy and fewer spurious programs, especially in SCENE.",6.1 Main results,[0],[0]
"However, no single value of β performs best over all domains.
",6.1 Main results,[0],[0]
Choosing the right value of β in RANDOMER significantly accelerates training.,6.1 Main results,[0],[0]
"Figure 3 illustrates that while β = 0 and β = 1 ultimately achieve similar accuracy on ALCHEMY, β = 0 reaches good performance in half the time.
",6.1 Main results,[0],[0]
"Since lowering β reduces trust in the model policy, β < 1 helps in early training when the current policy is untrustworthy.",6.1 Main results,[0],[0]
"However, as it grows more trustworthy, β < 1 begins to pay a price for ignoring it.",6.1 Main results,[0],[0]
"Hence, it may be worthwhile to anneal β towards 1 over time.
",6.1 Main results,[0],[0]
Effect of execution history embedding.,6.1 Main results,[0],[0]
Table 5 compares our two proposals for embedding the execution history: TOKENS and STACK.,6.1 Main results,[0],[0]
STACK performs better in the two domains where an object can be referenced in multiple ways (SCENE and ALCHEMY).,6.1 Main results,[0],[0]
"STACK directly embeds objects on the stack, invariant to the way in which they were pushed onto the stack, unlike TOKENS.",6.1 Main results,[0],[0]
"We hypothesize that this invariance increases robustness to spurious behavior: if a program accidentally pushes the right object onto the stack via spurious means, the model can still learn the remaining steps of the program without conditioning on a spurious history.
",6.1 Main results,[0],[0]
Fitting vs overfitting the training data.,6.1 Main results,[0],[0]
Table 6 reveals that BS-MML and RANDOMER use different strategies to fit the training data.,6.1 Main results,[0],[0]
"On the depicted training example, BS-MML actually achieves higher expected reward / marginal probability than RANDOMER, but it does so by putting most of its probability on a spurious program— a form of overfitting.",6.1 Main results,[0],[0]
"In contrast, RANDOMER spreads probability mass over multiple rewardearning programs, including the correct ones.
",6.1 Main results,[0],[0]
"As a consequence of overfitting, we observed at test time that BS-MML only references people by positional indices instead of by shirt or hat color, whereas RANDOMER successfully learns to use multiple reference strategies.",6.1 Main results,[0],[0]
Semantic parsing from indirect supervision.,7 Related work and discussion,[0],[0]
"Our work is motivated by the classic problem of learning semantic parsers from indirect supervision (Clarke et al., 2010; Liang et al., 2011; Artzi
and Zettlemoyer, 2011, 2013; Reddy et al., 2014; Pasupat and Liang, 2015).",7 Related work and discussion,[0],[0]
"We are interested in the initial stages of training from scratch, where getting any training signal is difficult due to the combinatorially large search space.",7 Related work and discussion,[0],[0]
"We also highlighted the problem of spurious programs which capture reward but give incorrect generalizations.
",7 Related work and discussion,[0],[0]
"Maximum marginal likelihood with beam search (BS-MML) is traditionally used to learn semantic parsers from indirect supervision.
",7 Related work and discussion,[0],[0]
Reinforcement learning.,7 Related work and discussion,[0],[0]
"Concurrently, there has been a recent surge of interest in reinforcement learning, along with the wide application of the classic REINFORCE algorithm (Williams, 1992)—to troubleshooting (Branavan et al., 2009), dialog generation (Li et al., 2016), game playing (Narasimhan et al., 2015), coreference resolution (Clark and Manning, 2016), machine translation (Norouzi et al., 2016), and even semantic parsing (Liang et al., 2017).",7 Related work and discussion,[0],[0]
"Indeed, the challenge of training semantic parsers from indirect supervision is perhaps better captured by the notion of sparse rewards in reinforcement learning.
",7 Related work and discussion,[0],[0]
"The RL answer would be better exploration, which can take many forms including simple action-dithering such as -greedy, entropy regularization (Williams and Peng, 1991), Monte Carlo tree search (Coulom, 2006), randomized value functions (Osband et al., 2014, 2016), and methods which prioritize learning environment dynamics (Duff, 2002) or under-explored states (Kearns and Singh, 2002; Bellemare et al., 2016; Nachum et al., 2016).",7 Related work and discussion,[0],[0]
The majority of these methods employ Monte Carlo sampling for exploration.,7 Related work and discussion,[0],[0]
"In
contrast, we find randomized beam search to be more suitable in our setting, because it explores low-probability states even when the policy distribution is peaky.",7 Related work and discussion,[0],[0]
"Our β-meritocratic update also depends on the fact that beam search returns an entire set of reward-earning programs rather than one, since it renormalizes over the reward-earning set.",7 Related work and discussion,[0],[0]
"While similar to entropy regularization, βmeritocratic update is more targeted as it only increases uniformity of the gradient among rewardearning programs, rather than across all programs.
",7 Related work and discussion,[0],[0]
"Our strategy of using randomized beam search and meritocratic updates lies closer to MML than RL, but this does not imply that RL has nothing to offer in our setting.",7 Related work and discussion,[0],[0]
"With the simple connection between RL and MML we established, much of the literature on exploration and variance reduction in RL can be directly applied to MML problems.",7 Related work and discussion,[0],[0]
"Of special interest are methods which incorporate a value function such as actor-critic.
",7 Related work and discussion,[0],[0]
Maximum likelihood and RL.,7 Related work and discussion,[0],[0]
"It is tempting to group our approach with sequence learning methods which interpolate between supervised learning and reinforcement learning (Ranzato et al., 2015; Venkatraman et al., 2015; Ross et al., 2011; Norouzi et al., 2016; Bengio et al., 2015; Levine,
2014).",7 Related work and discussion,[0],[0]
These methods generally seek to make RL training easier by pre-training or “warm-starting” with fully supervised learning.,7 Related work and discussion,[0],[0]
This requires each training example to be labeled with a reasonably correct output sequence.,7 Related work and discussion,[0],[0]
"In our setting, this would amount to labeling each example with the correct program, which is not known.",7 Related work and discussion,[0],[0]
"Hence, these methods cannot be directly applied.
",7 Related work and discussion,[0],[0]
"Without access to correct output sequences, we cannot directly maximize likelihood, and instead resort to maximizing the marginal likelihood (MML).",7 Related work and discussion,[0],[0]
"Rather than proposing MML as a form of pre-training, we argue that MML is a superior substitute for the standard RL objective, and that the β-meritocratic update is even better.
",7 Related work and discussion,[0],[0]
Simulated annealing.,7 Related work and discussion,[0],[0]
"Our β-meritocratic update employs exponential smoothing, which bears resemblance to the simulated annealing strategy of Och (2003); Smith and Eisner (2006); Shen et al. (2015).",7 Related work and discussion,[0],[0]
"However, a key difference is that these methods smooth the objective function whereas we smooth an expectation in the gradient.",7 Related work and discussion,[0],[0]
"To underscore the difference, we note that fixing β = 0 in our method (total smoothing) is quite effective, whereas total smoothing in the simulated annealing methods would correspond to a completely flat objective function, and an uninformative gradient of zero everywhere.
",7 Related work and discussion,[0],[0]
Neural semantic parsing.,7 Related work and discussion,[0],[0]
"There has been recent interest in using recurrent neural networks for semantic parsing, both for modeling logical forms (Dong and Lapata, 2016; Jia and Liang, 2016; Liang et al., 2017) and for end-to-end execution (Yin et al., 2015; Neelakantan et al., 2016).",7 Related work and discussion,[0],[0]
"We develop a neural model for the context-dependent setting, which is made possible by a new stackbased language similar to Riedel et al. (2016).
Acknowledgments.",7 Related work and discussion,[0],[0]
This work was supported by the NSF Graduate Research Fellowship under No.,7 Related work and discussion,[0],[0]
DGE-114747 and the NSF CAREER Award under No.,7 Related work and discussion,[0],[0]
"IIS-1552635.
Reproducibility.",7 Related work and discussion,[0],[0]
Our code is made available at https://github.com/kelvinguu/lang2program.,7 Related work and discussion,[0],[0]
Reproducible experiments are available at https://worksheets.codalab.org/worksheets/ 0x88c914ee1d4b4a4587a07f36f090f3e5/.,7 Related work and discussion,[0],[0]
"System ALCHEMY TANGRAMS SCENE
REINFORCE
Sample size 32 Baseline 10−2
= 0.15 embed TOKENS
Sample size 32 Baseline 10−2
= 0.15 embed TOKENS
Sample size 32 Baseline 10−4
= 0.15 embed TOKENS
BS-MML Beam size 128 embed TOKENS Beam size 128 embed TOKENS Beam size 128 embed TOKENS
RANDOMER β = 1 = 0.05 embed TOKENS β",A Hyperparameters in Table 2,[0],[0]
= 1 = 0.15 embed TOKENS β,A Hyperparameters in Table 2,[0],[0]
"= 0 = 0.15 embed STACK
B SCONE domains and program tokens token type semantics Shared across ALCHEMY, TANGRAMS, SCENE 1, 2, 3, . . .",A Hyperparameters in Table 2,[0],[0]
"constant push: number -1, -2, -3, . . .",A Hyperparameters in Table 2,[0],[0]
"red, yellow, green, constant push: color orange, purple, brown allObjects constant push: the list of all objects index function pop: a list L and a number i
push: the object L[i] (the index starts from 1; negative indices are allowed) prevArgj (j = 1, 2) function pop: a number i push: the j argument from the ith action prevAction action pop: a number i perform: fetch the ith action and execute it using the arguments on the stack Additional tokens for the ALCHEMY domain An ALCHEMY world contains 7 beakers.",A Hyperparameters in Table 2,[0],[0]
Each beaker may contain up to 4 units of colored chemical.,A Hyperparameters in Table 2,[0],[0]
1/1 constant push: fraction (used in the drain action) hasColor function pop: a color c push: list of beakers with chemical color c drain action pop: a beaker b and a number or fraction a perform: remove a units of chemical (or all chemical if a = 1/1) from b pour action pop: two beakers b1 and b2 perform: transfer all chemical from b1 to b2 mix action pop: a beaker b perform: turn the color of the chemical in b to brown Additional tokens for the TANGRAMS domain A TANGRAMS world contains a row of tangram pieces with different shapes.,A Hyperparameters in Table 2,[0],[0]
"The shapes are anonymized; a tangram can be referred to by an index or a history reference, but not by shape.",A Hyperparameters in Table 2,[0],[0]
swap action pop: two tangrams t1 and t2 perform: exchange the positions of t1 and t2 remove action pop: a tangram t perform: remove t from the stage add action pop: a number i and a previously removed tangram t perform: insert t to position i Additional tokens for the SCENE domain A SCENE world is a linear stage with 10 positions.,A Hyperparameters in Table 2,[0],[0]
Each position may be occupied by a person with a colored shirt and optionally a colored hat.,A Hyperparameters in Table 2,[0],[0]
There are usually 1-5 people on the stage.,A Hyperparameters in Table 2,[0],[0]
noHat constant push: pseudo-color (indicating that the person is not wearing a hat),A Hyperparameters in Table 2,[0],[0]
"hasShirt, hasHat function pop: a color c push: the list of all people with shirt or hat color c hasShirtHat function pop: two colors c1 and c2 push: the list of all people with shirt color c1 and hat color c2 leftOf, rightOf function pop: a person p push: the location index left or right of p create action pop: a number i and two colors c1, c2 perform: add a new person at position i with shirt color c1 and hat color c2 move action pop: a person p and a number i perform: move p to position i swapHats action pop: two people p1 and p2 perform: have p1 and p2 exchange their hats leave action pop: a person p
perform: remove p from the stage",A Hyperparameters in Table 2,[0],[0]
"Our goal is to learn a semantic parser that maps natural language utterances into executable programs when only indirect supervision is available: examples are labeled with the correct execution result, but not the program itself.",abstractText,[0],[0]
"Consequently, we must search the space of programs for those that output the correct result, while not being misled by spurious programs: incorrect programs that coincidentally output the correct result.",abstractText,[0],[0]
"We connect two common learning paradigms, reinforcement learning (RL) and maximum marginal likelihood (MML), and then present a new learning algorithm that combines the strengths of both.",abstractText,[0],[0]
"The new algorithm guards against spurious programs by combining the systematic search traditionally employed in MML with the randomized exploration of RL, and by updating parameters such that probability is spread more evenly across consistent programs.",abstractText,[0],[0]
We apply our learning algorithm to a new neural semantic parser and show significant gains over existing state-of-theart results on a recent context-dependent semantic parsing task.,abstractText,[0],[0]
From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal Likelihood,title,[0],[0]
"ar X
iv :1
50 6.
03 48
7v 2
[ cs
.C L
] 2
6 A
ug 2
01 5",text,[0],[0]
Paraphrase detection3 is the task of analyzing two segments of text and determining if they have the same meaning despite differences in structure and wording.,1 Introduction,[0],[0]
"It is useful for a variety of NLP tasks like question answering (Rinaldi et al., 2003; Fader et al., 2013), semantic parsing (Berant and Liang, 2014), textual entail-
1We release our datasets, code, and trained models on the authors’ websites.
",1 Introduction,[0],[0]
"2This version differs from the previous one with the inclusion of Appendix A, which contains details about new higher dimensional embeddings we have released.",1 Introduction,[0],[0]
"These embeddings achieve human-level performance on SL999 and WS353.
3See Androutsopoulos and Malakasiotis (2010) for a survey on approaches for detecting paraphrases.
ment (Bosma and Callison-Burch, 2007), and machine translation (Marton et al., 2009).
",1 Introduction,[0],[0]
"One component of many such systems is a paraphrase table containing pairs of text snippets, usually automatically generated, that have the same meaning.",1 Introduction,[0],[0]
"The most recent work in this area is the Paraphrase Database (PPDB; Ganitkevitch et al., 2013), a collection of confidence-rated paraphrases created using the pivoting technique of Bannard and Callison-Burch (2005) over large parallel corpora.",1 Introduction,[0],[0]
"The PPDB is a massive resource, containing 220 million paraphrase pairs.",1 Introduction,[0],[0]
It captures many short paraphrases that would be difficult to obtain using any other resource.,1 Introduction,[0],[0]
"For example, the pair {we must do our utmost, we must make every effort} has little lexical overlap but is present in PPDB.",1 Introduction,[0],[0]
"The PPDB has recently been used for monolingual alignment (Yao et al., 2013), for predicting sentence similarity (Bjerva et al., 2014), and to improve the coverage of FrameNet (Rastogi and Van Durme, 2014).
",1 Introduction,[0],[0]
"Though already effective for multiple NLP tasks, we note some drawbacks of PPDB.",1 Introduction,[0],[0]
"The first is lack of coverage: to use the PPDB to compare two phrases, both must be in the database.",1 Introduction,[0],[0]
The second is that PPDB is a nonparametric paraphrase model; the number of parameters (phrase pairs) grows with the size of the dataset used to build it.,1 Introduction,[0],[0]
"In practice, it can become unwieldy to work with as the size of the database increases.",1 Introduction,[0],[0]
"A third concern is that the confidence estimates in PPDB are a heuristic combination of features, and their quality is unclear.
",1 Introduction,[0],[0]
We address these issues in this work by introducing ways to use PPDB to construct parametric paraphrase models.,1 Introduction,[0],[0]
"First we show that initial skip-gram word vectors (Mikolov et al., 2013a) can be fine-tuned for the paraphrase task by training on word pairs from PPDB.",1 Introduction,[0],[0]
"We call them PARA-
GRAM word vectors.",1 Introduction,[0],[0]
We find additive composition of PARAGRAM vectors to be a simple but effective way to embed phrases for short-phrase paraphrase tasks.,1 Introduction,[0],[0]
"We find improved performance by training a recursive neural network (RNN; Socher et al., 2010) directly on phrase pairs from PPDB.
",1 Introduction,[0],[0]
"We show that our resulting word and phrase representations are effective on a wide variety of tasks, including two new datasets that we introduce.",1 Introduction,[0],[0]
"The first, Annotated-PPDB, contains pairs from PPDB that were scored by human annotators.",1 Introduction,[0],[0]
It can be used to evaluate paraphrase models for short phrases.,1 Introduction,[0],[0]
We use it to show that the phrase embeddings produced by our methods are significantly more indicative of paraphrasability than the original heuristic scoring used by Ganitkevitch et al. (2013).,1 Introduction,[0],[0]
"Thus we use the power of PPDB to improve its contents.
",1 Introduction,[0],[0]
"Our second dataset, ML-Paraphrase, is a reannotation of the bigram similarity corpus from Mitchell and Lapata (2010).",1 Introduction,[0],[0]
"The task was originally developed to measure semantic similarity of bigrams, but some annotations are not congruent with the functional similarity central to paraphrase relationships.",1 Introduction,[0],[0]
Our re-annotation can be used to assess paraphrasing capability of bigram compositional models.,1 Introduction,[0],[0]
"In summary, we make the following contributions:
Provide new PARAGRAM word vectors, learned using PPDB, that achieve state-of-the-art performance on the SimLex-999 lexical similarity task (Hill et al., 2014b) and lead to improved performance in sentiment analysis.
",1 Introduction,[0],[0]
Provide ways to use PPDB to embed phrases.,1 Introduction,[0],[0]
We compare additive and RNN composition of PARAGRAM vectors.,1 Introduction,[0],[0]
Both can improve PPDB by reranking the paraphrases in PPDB to improve correlations with human judgments.,1 Introduction,[0],[0]
"They can be used as concise parameterizations of PPDB, thereby vastly increasing its coverage.",1 Introduction,[0],[0]
"We also perform a qualitative analysis of the differences between additive and RNN composition.
",1 Introduction,[0],[0]
Introduce two new datasets.,1 Introduction,[0],[0]
The first contains PPDB phrase pairs and evaluates how well models can measure the quality of short paraphrases.,1 Introduction,[0],[0]
"The second is a new annotation of the bigram similarity task in Mitchell and Lapata (2010) that makes it suitable for evaluating bigram paraphrases.
",1 Introduction,[0],[0]
"We release the new datasets, complete with annotation instructions and raw annotations, as well as our code and the trained models.4",1 Introduction,[0],[0]
There is a vast literature on representing words as vectors.,2 Related Work,[0],[0]
"The intuition of most methods to create these vectors (or embeddings) is that similar words have similar contexts (Firth, 1957).",2 Related Work,[0],[0]
"Earlier models made use of latent semantic analysis (LSA) (Deerwester et al., 1990).",2 Related Work,[0],[0]
"Recently, more sophisticated neural models, work originating with (Bengio et al., 2003), have been gaining popularity (Mikolov et al., 2013a; Pennington et al., 2014).",2 Related Work,[0],[0]
"These embeddings are now being used in new ways as they are being tailored to specific downstream tasks (Bansal et al., 2014).
",2 Related Work,[0],[0]
Phrase representations can be created from word vectors using compositional models.,2 Related Work,[0],[0]
Simple but effective compositional models were studied by Mitchell and Lapata (2008; 2010) and Blacoe and Lapata (2012).,2 Related Work,[0],[0]
They compared a variety of binary operations on word vectors and found that simple point-wise multiplication of explicit vector representations performed very well.,2 Related Work,[0],[0]
"Other works like Zanzotto et al. (2010) and Baroni and Zamparelli (2010) also explored composition using models based on operations of vectors and matrices.
",2 Related Work,[0],[0]
"More recent work has shown that the extremely efficient neural embeddings of Mikolov et al. (2013a) also do well on compositional tasks simply by adding the word vectors (Mikolov et al., 2013b).",2 Related Work,[0],[0]
"Hashimoto et al. (2014) introduced an alternative word embedding and compositional model based on predicate-argument structures that does well on two simple composition tasks, including the one introduced by Mitchell and Lapata (2010).
",2 Related Work,[0],[0]
"An alternative approach to composition, used by Socher et al. (2011), is to train a recursive neural network (RNN) whose structure is defined by a binarized parse tree.",2 Related Work,[0],[0]
"In particular, they trained their RNN as an unsupervised autoencoder.",2 Related Work,[0],[0]
The RNN captures the latent structure of composition.,2 Related Work,[0],[0]
"Recent work has shown that this model struggles in tasks in-
4available on the authors’ websites
volving compositionality (Blacoe and Lapata, 2012; Hashimoto et al., 2014).5",2 Related Work,[0],[0]
"However, we found success using RNNs in a supervised setting, similar to Socher et al. (2014), who used RNNs to learn representations for image descriptions.",2 Related Work,[0],[0]
"The objective function we used in this work was motivated by their multimodal objective function for learning joint image-sentence representations.
",2 Related Work,[0],[0]
"Lastly, the PPDB has been used along with other resources to learn word embeddings for several tasks, including semantic similarity, language modeling, predicting human judgments, and classification (Yu and Dredze, 2014; Faruqui et al., 2015).",2 Related Work,[0],[0]
"Concurrently with our work, it has also been used to construct paraphrase models for short phrases (Yu and Dredze, 2015).",2 Related Work,[0],[0]
"We created two novel datasets: (1) AnnotatedPPDB, a subset of phrase pairs from PPDB which are annotated according to how strongly they represent a paraphrase relationship, and (2) MLParaphrase, a re-annotation of the bigram similarity dataset from Mitchell and Lapata (2010), again annotated for strength of paraphrase relationship.",3 New Paraphrase Datasets,[0],[0]
Our motivation for creating Annotated-PPDB was to establish a way to evaluate compositional paraphrase models on short phrases.,3.1 Annotated-PPDB,[0],[0]
"Most existing paraphrase tasks focus on words, like SimLex-999 (Hill et al., 2014b), or entire sentences, such as the Microsoft Research Paraphrase Corpus (Dolan et al., 2004; Quirk et al., 2004).",3.1 Annotated-PPDB,[0],[0]
"To our knowledge, there are no datasets that focus on the paraphrasability of short phrases.",3.1 Annotated-PPDB,[0],[0]
"Thus, we created Annotated-PPDB so that researchers can focus on local compositional phenomena and measure the performance of models directly—avoiding the need to do so indirectly in a sentence-level task.",3.1 Annotated-PPDB,[0],[0]
"Models that have strong performance on Annotated-PPDB can be used to provide more accurate confidence scores for the paraphrases in the PPDB as well as reduce the need for large paraphrase tables altogether.
",3.1 Annotated-PPDB,[0],[0]
"5We also replicated this approach and found training to be time-consuming even using low-dimensional word vectors.
",3.1 Annotated-PPDB,[0],[0]
Annotated-PPDB was created in a multi-step process (outlined below) involving various automatic filtering steps followed by crowdsourced human annotation.,3.1 Annotated-PPDB,[0],[0]
One of the aims for our dataset was to collect a variety of paraphrase types—we wanted to include pairs that were non-trivial to recognize as well as those with a range of similarity and length.,3.1 Annotated-PPDB,[0],[0]
"We focused on phrase pairs with limited lexical overlap to avoid including those with only trivial differences.
",3.1 Annotated-PPDB,[0],[0]
We started with candidate phrases extracted from the first 10M pairs in the XXL version of the PPDB and then executed the following steps.6 Filter phrases for quality: Only those phrases whose tokens were in our vocabulary were retained.7,3.1 Annotated-PPDB,[0],[0]
"Next, all duplicate paraphrase pairs were removed; in PPDB, these are distinct pairs that contain the same two phrases with the order swapped.",3.1 Annotated-PPDB,[0],[0]
"Filter by lexical overlap: Next, we calculated the word overlap score in each phrase pair and then retained only those pairs that had a score of less than 0.5.",3.1 Annotated-PPDB,[0],[0]
"By word overlap score, we mean the fraction of tokens in the smaller of the phrases with Levenshtein distance ≤ 1 to a token in the larger of the phrases.",3.1 Annotated-PPDB,[0],[0]
"This was done to exclude less interesting phrase pairs like 〈my dad had, my father had〉 or 〈ballistic missiles, of ballistic missiles〉 that only differ in a synonym or the addition of a single word.",3.1 Annotated-PPDB,[0],[0]
"Select range of paraphrasabilities: To balance our dataset with both clear paraphrases and erroneous pairs in PPDB, we sampled 5,000 examples from ten chunks of the first 10M initial phrase pairs where a chunk is defined as 1M phrase pairs.",3.1 Annotated-PPDB,[0],[0]
"Select range of phrase lengths: We then selected 1,500 phrases from each 5000-example sample that encompassed a wide range of phrase lengths.",3.1 Annotated-PPDB,[0],[0]
"To do this, we first binned the phrase pairs by their effective size.",3.1 Annotated-PPDB,[0],[0]
Let n1 be the number of tokens of length greater than one character in the first phrase and n2 the same for the second phrase.,3.1 Annotated-PPDB,[0],[0]
"Then the effective size is defined as max(n1, n2).",3.1 Annotated-PPDB,[0],[0]
"The bins contained pairs of effective size of 3, 4, and 5 or more, and 500
6Note that the confidence scores for phrase pairs in PPDB are based on a weighted combination of features with weights determined heuristically.",3.1 Annotated-PPDB,[0],[0]
"The confidence scores were used to place the phrase pairs into their respective sets (S, M, L, XL, XXL, etc.), where each larger set subsumes all smaller ones.
",3.1 Annotated-PPDB,[0],[0]
"7Throughout, our vocabulary is defined as the most common 100K word types in English Wikipedia, following tokenization and lowercasing (see §5).
",3.1 Annotated-PPDB,[0],[0]
pairs were selected from each bin.,3.1 Annotated-PPDB,[0],[0]
"This gave us a total of 15,000 phrase pairs.
",3.1 Annotated-PPDB,[0],[0]
"Prune to 3,000: 3,000 phrase pairs were then selected randomly from the 15,000 remaining pairs to form an initial dataset, Annotated-PPDB-3K.",3.1 Annotated-PPDB,[0],[0]
"The phrases were selected so that every phrase in the dataset was unique.
",3.1 Annotated-PPDB,[0],[0]
Annotate with Mechanical Turk:,3.1 Annotated-PPDB,[0],[0]
"The dataset was then rated on a scale from 1-5 using Amazon Mechanical Turk, where a score of 5 denoted phrases that are equivalent in a large number of contexts, 3 meant that the phrases had some overlap in meaning, and 1 indicated that the phrases were dissimilar or contradictory in some way (e.g., can not adopt and is able to accept).
",3.1 Annotated-PPDB,[0],[0]
"We only permitted workers whose location was in the United States and who had done at least 1,000 HITS with a 99% acceptance rate.",3.1 Annotated-PPDB,[0],[0]
Each example was labeled by 5 annotators and their scores were averaged to produce the final rating.,3.1 Annotated-PPDB,[0],[0]
Table 1 shows some statistics of the data.,3.1 Annotated-PPDB,[0],[0]
"Overall, the annotated data had a mean deviation (MD)8 of 0.80.",3.1 Annotated-PPDB,[0],[0]
"Table 1 shows that overall, workers found the phrases to be of high quality, as more than two-thirds of the pairs had an average score of at least 3.",3.1 Annotated-PPDB,[0],[0]
"Also from the Table, we can see that workers had stronger agreement on very low and very high quality pairs and were less certain in the middle of the range.
",3.1 Annotated-PPDB,[0],[0]
"Prune to 1,260: To create our final dataset, Annotated-PPDB, we selected 1,260 phrase pairs from the 3,000 annotations.",3.1 Annotated-PPDB,[0],[0]
We did this by first binning the phrases into 3 categories: those with scores in the interval,3.1 Annotated-PPDB,[0],[0]
"[1, 2.5), those with scores in the interval [2.5, 3.5], and those with scores in the interval (3.5, 5].",3.1 Annotated-PPDB,[0],[0]
"We took the 420 phrase pairs with the lowest MD in each bin, as these have the most agreement about their label, to form Annotated-PPDB.
",3.1 Annotated-PPDB,[0],[0]
"These 1,260 examples were then randomly split into a development set of 260 examples and a test set of 1,000 examples.",3.1 Annotated-PPDB,[0],[0]
"The development set had an MD of 0.61 and the test set had an MD of 0.60, indicating the final dataset had pairs of higher agreement than the initial 3,000.
8MD is similar to standard deviation, but uses absolute value instead of squared value and thus is both more intuitive and less sensitive to outliers.",3.1 Annotated-PPDB,[0],[0]
"Our second newly-annotated dataset, ML-Paraphrase, is based on the bigram similarity task originally introduced by Mitchell and Lapata (2010); we refer to the original annotations as the ML dataset.
",3.2 ML-Paraphrase,[0],[0]
"The ML dataset consists of human similarity ratings for three types of bigrams: adjective-noun (JN), noun-noun (NN), and verb-noun (VN).",3.2 ML-Paraphrase,[0],[0]
"Through manual inspection, we found that the annotations were not consistent with the notion of similarity central to paraphrase tasks.",3.2 ML-Paraphrase,[0],[0]
"For instance, television set and television programme were the highest rated phrases in the NN section (based on average annotator score).",3.2 ML-Paraphrase,[0],[0]
"Similarly, one of the highest ranked JN pairs was older man and elderly woman.",3.2 ML-Paraphrase,[0],[0]
"This indicates that the annotations reflect topical similarity in addition to capturing functional or definitional similarity.
",3.2 ML-Paraphrase,[0],[0]
"Therefore, we had the data re-annotated by two authors of this paper who are native English speakers.9",3.2 ML-Paraphrase,[0],[0]
"The bigrams were labeled on a scale from 1- 5 where 5 denotes phrases that are equivalent in a large number of contexts, 3 indicates the phrases are roughly equivalent in a narrow set of contexts, and 1 means the phrases are not at all equivalent in any context.",3.2 ML-Paraphrase,[0],[0]
"Following annotation, we collapsed the rating scale by merging 4s and 5s together and 1s and 2s together.
",3.2 ML-Paraphrase,[0],[0]
Statistics for the data are shown in Table 2.,3.2 ML-Paraphrase,[0],[0]
"We show inter-annotator Spearman ρ and Cohen’s κ in columns 2 and 3, indicating substantial agreement on the JN and VN portions but only moderate agreement on NN.",3.2 ML-Paraphrase,[0],[0]
"In fact, when evaluating our NN anno-
9We tried using Mechanical Turk here, but due to such short phrases, with few having the paraphrase relationship, workers did not perform well on the task.
tations against those from the original ML data (column 4), we find ρ to be 0.38, well below the average human correlation of 0.49 (final column) reported by Mitchell and Lapata and also surpassed by pointwise multiplication (Mitchell and Lapata, 2010).",3.2 ML-Paraphrase,[0],[0]
"This suggests that the original NN portion, more so than the others, favored a notion of similarity more related to association than paraphrase.",3.2 ML-Paraphrase,[0],[0]
We now present parametric paraphrase models and discuss training.,4 Paraphrase Models,[0],[0]
"Our goal is to embed phrases into a low-dimensional space such that cosine similarity in the space corresponds to the strength of the paraphrase relationship between phrases.
",4 Paraphrase Models,[0],[0]
We use a recursive neural network (RNN) similar to that used by Socher et al. (2014).,4 Paraphrase Models,[0],[0]
We first use a constituent parser to obtain a binarized parse of a phrase.,4 Paraphrase Models,[0],[0]
"For phrase p, we compute its vector g(p) through recursive computation on the parse.",4 Paraphrase Models,[0],[0]
"That is, if phrase p is the yield of a parent node in a parse tree, and phrases c1 and c2 are the yields of its two child nodes, we define g(p) recursively as follows:
g(p) = f(W [g(c1); g(c2)]",4 Paraphrase Models,[0],[0]
"+ b)
where f is an element-wise activation function (tanh), [g(c1); g(c2)] ∈ R2n is the concatenation of the child vectors, W ∈ Rn×2n is the composition matrix, b ∈",4 Paraphrase Models,[0],[0]
"Rn is the offset, and n is the dimensionality of the word embeddings.",4 Paraphrase Models,[0],[0]
"If node p has no children (i.e., it is a single token), we define g(p) = W (p) w , where Ww is the word embedding matrix in which particular word vectors are indexed using superscripts.",4 Paraphrase Models,[0],[0]
"The trainable parameters of the model are W , b, and Ww.",4 Paraphrase Models,[0],[0]
We now present objective functions for training on pairs extracted from PPDB.,4.1 Objective Functions,[0],[0]
The training data consists of (possibly noisy) pairs taken directly from the original PPDB.,4.1 Objective Functions,[0],[0]
"In subsequent sections, we discuss how we extract training pairs for particular tasks.
",4.1 Objective Functions,[0],[0]
"We assume our training data consists of a set X of phrase pairs 〈x1, x2〉, where x1 and x2 are assumed to be paraphrases.",4.1 Objective Functions,[0],[0]
"To learn the model parameters (W, b,Ww), we minimize our objective function over the data using AdaGrad (Duchi et al., 2011) with mini-batches.",4.1 Objective Functions,[0],[0]
"The objective function follows:
min W,b,Ww
1
|X|
(
∑
〈x1,x2〉∈X
max(0, δ − g(x1) · g(x2) + g(x1) · g(t1))
+ max(0, δ − g(x1) · g(x2) + g(x2) · g(t2))
)
+ λW (‖W‖ 2 + ‖b‖2) +",4.1 Objective Functions,[0],[0]
"λWw ‖Wwinitial −Ww‖ 2
(1)
where λW and λWw are regularization parameters, Wwinitial is the initial word embedding matrix, δ is the margin (set to 1 in all of our experiments), and t1 and t2 are carefully-selected negative examples taken from a mini-batch during optimization.
",4.1 Objective Functions,[0],[0]
"The intuition for this objective is that we want the two phrases to be more similar to each other (g(x1) · g(x2)) than either is to their respective negative examples t1 and t2, by a margin of at least δ.
",4.1 Objective Functions,[0],[0]
"Selecting Negative Examples To select t1 and t2 in Eq. 1, we simply chose the most similar phrase in the mini-batch (other than those in the given phrase pair).",4.1 Objective Functions,[0],[0]
"E.g., for choosing t1 for a given 〈x1, x2〉:
t1 = argmax t:〈t,·〉∈Xb\{〈x1,x2〉} g(x1) · g(t)
where Xb ⊆ X is the current mini-batch.",4.1 Objective Functions,[0],[0]
"That is, we want to choose a negative example ti that is similar to xi according to the current model parameters.",4.1 Objective Functions,[0],[0]
The downside of this approach is that we may occasionally choose a phrase ti that is actually a true paraphrase of xi.,4.1 Objective Functions,[0],[0]
"We also tried a strategy in which we selected the least similar phrase that would trigger an update (i.e., g(ti) ·g(xi) > g(x1) ·g(x2)−δ), but we found the simpler strategy above to work better and used it for all experiments reported below.
",4.1 Objective Functions,[0],[0]
"Discussion The objective in Eq. 1 is similar to one used by Socher et al. (2014), but with several differences.",4.1 Objective Functions,[0],[0]
Their objective compared text and projected images.,4.1 Objective Functions,[0],[0]
"They also did not update the underlying word embeddings; we do so here, and in a way such that they are penalized from deviating from their initialization.",4.1 Objective Functions,[0],[0]
"Also for a given 〈x1, x2〉, they do not select a single t1 and t2 as we do, but use the entire training set, which can be very expensive with a large training dataset.
",4.1 Objective Functions,[0],[0]
"We also experimented with a simpler objective that sought to directly minimize the squared L2norm between g(x1) and g(x2) in each pair, along with the same regularization terms as in Eq. 1.",4.1 Objective Functions,[0],[0]
One problem with this objective function is that the global minimum is 0 and is achieved simply by driving the parameters to 0.,4.1 Objective Functions,[0],[0]
"We obtained much better results using the objective in Eq. 1.
",4.1 Objective Functions,[0],[0]
"Training Word Paraphrase Models To train just word vectors on word paraphrase pairs (again from PPDB), we used the same objective function as above, but simply dropped the composition terms.",4.1 Objective Functions,[0],[0]
"This gave us an objective that bears some similarity to the skip-gram objective with negative sampling in word2vec (Mikolov et al., 2013a).",4.1 Objective Functions,[0],[0]
Both seek to maximize the dot products of certain word pairs while minimizing the dot products of others.,4.1 Objective Functions,[0],[0]
"This objective function is:
min Ww
1
|X|
(
∑
〈x1,x2〉∈X
max(0, δ −W",4.1 Objective Functions,[0],[0]
(x1)w ·W (x2),4.1 Objective Functions,[0],[0]
"w
+W (x1)w ·W (t1) w )",4.1 Objective Functions,[0],[0]
"+ max(0, δ −W (x1) w ·W (x2)",4.1 Objective Functions,[0],[0]
w,4.1 Objective Functions,[0],[0]
"+
W (x2)w ·W (t2) w )
)
",4.1 Objective Functions,[0],[0]
"+ λWw ‖Wwinitial −Ww‖ 2 (2)
",4.1 Objective Functions,[0],[0]
"It is like Eq. 1 except with word vectors replacing the RNN composition function and with the regularization terms on the W and b removed.
",4.1 Objective Functions,[0],[0]
We further found we could improve this model by incorporating constraints.,4.1 Objective Functions,[0],[0]
"From our training pairs, for a given word w, we assembled all other words that were paired with it in PPDB and all of their lemmas.",4.1 Objective Functions,[0],[0]
These were then used as constraints during the pairing process: a word t could only be paired with w if it was not in its list of assembled words.,4.1 Objective Functions,[0],[0]
We first present experiments on learning lexical paraphrasability.,5 Experiments – Word Paraphrasing,[0],[0]
"We train on word pairs from PPDB and evaluate on the SimLex-999 dataset (Hill et al., 2014b), achieving the best results reported to date.",5 Experiments – Word Paraphrasing,[0],[0]
"To learn word vectors that reflect paraphrasability, we optimized Eq. 2.",5.1 Training Procedure,[0],[0]
"There are many tunable hyperparameters with this objective, so to make training tractable we fixed the initial learning rates for the word embeddings to 0.5 and the margin δ to 1.",5.1 Training Procedure,[0],[0]
Then we did a coarse grid search over a parameter space for λWw and the mini-batch size.,5.1 Training Procedure,[0],[0]
"We considered λWw values in {10
−2, 10−3, ..., 10−7, 0} and minibatch sizes in {100, 250, 500, 1000}.",5.1 Training Procedure,[0],[0]
"We trained for 20 epochs for each set of hyperparameters using AdaGrad (Duchi et al., 2011).
",5.1 Training Procedure,[0],[0]
"For all experiments, we initialized our word vectors with skip-gram vectors trained using word2vec (Mikolov et al., 2013a).",5.1 Training Procedure,[0],[0]
"The vectors were trained on English Wikipedia (tokenized and lowercased, yielding 1.8B tokens).10",5.1 Training Procedure,[0],[0]
"We used a window size of 5 and a minimum count cut-off of 60, producing vectors for approximately 270K word types.",5.1 Training Procedure,[0],[0]
"We retained vectors for only the 100K most frequent words, averaging the rest to obtain a single vector for unknown words.",5.1 Training Procedure,[0],[0]
We will refer to this set of the 100K most frequent words as our vocabulary.,5.1 Training Procedure,[0],[0]
"For training, we extracted word pairs from the lexical XL section of PPDB.",5.2 Extracting Training Data,[0],[0]
"We used the XL data for all experiments, including those for phrases.",5.2 Extracting Training Data,[0],[0]
We used XL instead of XXL because XL has better quality overall while still being large enough so that we could be selective in choosing training pairs.,5.2 Extracting Training Data,[0],[0]
"There are a total of 548,085 pairs.",5.2 Extracting Training Data,[0],[0]
"We removed 174,766 that either contained numerical digits or words not in our vocabulary.",5.2 Extracting Training Data,[0],[0]
"We then removed 260,425 redundant pairs, leaving us with a final training set of 112,894 word pairs.
",5.2 Extracting Training Data,[0],[0]
"10We used the December 2, 2013 snapshot.",5.2 Extracting Training Data,[0],[0]
"Hyperparameters were tuned using the wordsim-353 (WS353) dataset (Finkelstein et al., 2001), specifically its similarity (WS-S) and relatedness (WSR) partitions (Agirre et al., 2009).",5.3 Tuning and Evaluation,[0],[0]
"In particular, we tuned to maximize 2×WS-S correlation minus the WS-R correlation.",5.3 Tuning and Evaluation,[0],[0]
"The idea was to reward vectors with high similarity and relatively low relatedness, in order to target the paraphrase relationship.
",5.3 Tuning and Evaluation,[0],[0]
"After tuning, we evaluated the best hyperparameters on the SimLex-999 (SL999) dataset (Hill et al., 2014b).",5.3 Tuning and Evaluation,[0],[0]
We chose SL999 as our primary test set as it most closely evaluates the paraphrase relationship.,5.3 Tuning and Evaluation,[0],[0]
"Even though WS-S is a close approximation to this relationship, it does not include pairs that are merely associated and assigned low scores, which SL999 does (see discussion in Hill et al., 2014b).
",5.3 Tuning and Evaluation,[0],[0]
"Note that for all experiments we used cosine similarity as our similarity metric and evaluated the statistical significance of dependent correlations using the one-tailed method of (Steiger, 1980).",5.3 Tuning and Evaluation,[0],[0]
"Table 3 shows results on SL999 when improving the initial word vectors by training on word pairs from PPDB, both with and without constraints.",5.4 Results,[0],[0]
"The “PARAGRAM WS” rows show results when tuning to maximize 2×WS-S − WS-R. We also show results for strong skip-gram baselines and the best results from the literature, including the state-of-the-art results from Hill et al. (2014a) as well as the inter-
annotator agreement from Hill et al.",5.4 Results,[0],[0]
"(2014b).11
The table illustrates that, by training on PPDB, we can surpass the previous best correlations on SL999 by 4-6% absolute, achieving the best results reported to date.",5.4 Results,[0],[0]
We also find that we can train low-dimensional word vectors that exceed the performance of much larger vectors.,5.4 Results,[0],[0]
"This is very useful as using large vectors can increase both time and memory consumption in NLP applications.
",5.4 Results,[0],[0]
"To generate word vectors to use for downstream applications, we chose hyperparameters so as to maximize performance on SL999.12 These word vectors, which we refer to as PARAGRAM vectors, had a ρ of 0.57 on SL999.",5.4 Results,[0],[0]
We use them as initial word vectors for the remainder of the paper.,5.4 Results,[0],[0]
"As an extrinsic evaluation of our PARAGRAM word vectors, we used them in a convolutional neural network (CNN) for sentiment analysis.",5.5 Sentiment Analysis,[0],[0]
We used the simple CNN from Kim (2014) and the binary sentence-level sentiment analysis task from Socher et al. (2013).,5.5 Sentiment Analysis,[0],[0]
"We used the standard data splits, removing examples with a neutral rating.",5.5 Sentiment Analysis,[0],[0]
"We trained on all constituents in the training set while only using full sentences from development and test, giving us train/development/test sizes of 67,349/872/1,821.
",5.5 Sentiment Analysis,[0],[0]
"The CNN uses m-gram filters, each of which is an m×n vector.",5.5 Sentiment Analysis,[0],[0]
"The CNN computes the inner product between an m-gram filter and each m-gram in an example, retaining the maximum match (so-called “max-pooling”).",5.5 Sentiment Analysis,[0],[0]
"The score of the match is a single dimension in a feature vector for the example, which is then associated with a weight in a linear classifier used to predict positive or negative sentiment.
",5.5 Sentiment Analysis,[0],[0]
"While Kim (2014) used m-gram filters of several lengths, we only used unigram filters.",5.5 Sentiment Analysis,[0],[0]
We also fixed the word vectors during learning (called “static” by Kim).,5.5 Sentiment Analysis,[0],[0]
"After learning, the unigram filters correspond to locations in the fixed word vector space.",5.5 Sentiment Analysis,[0],[0]
The learned classifier weights represent how strongly each location corresponds to positive or negative sentiment.,5.5 Sentiment Analysis,[0],[0]
"We expect this static CNN to
11Hill et al. (2014a) did not report the dimensionality of the vectors that led to their state-of-the-art results.
",5.5 Sentiment Analysis,[0],[0]
"12We did not use constraints during training.
be more effective if the word vector space separates positive and negative sentiment.
",5.5 Sentiment Analysis,[0],[0]
"In our experiments, we compared baseline skipgram embeddings to our PARAGRAM vectors.",5.5 Sentiment Analysis,[0],[0]
"We used AdaGrad learning rate of 0.1, mini-batches of size 10, and a dropout rate of 0.5.",5.5 Sentiment Analysis,[0],[0]
We used 200 unigram filters and rectified linear units as the activation (applied to the filter output + filter bias).,5.5 Sentiment Analysis,[0],[0]
"We trained for 30 epochs, predicting labels on the development set after each set of 3,000 examples.",5.5 Sentiment Analysis,[0],[0]
"We recorded the highest development accuracy and used those parameters to predict labels on the test set.
",5.5 Sentiment Analysis,[0],[0]
Results are shown in Table 4.,5.5 Sentiment Analysis,[0],[0]
"We see improvements over the baselines when using PARAGRAM vectors, even exceeding the performance of higherdimensional skip-gram vectors.",5.5 Sentiment Analysis,[0],[0]
"In this section, we describe experiments on a variety of compositional phrase-based paraphrasing tasks.",6 Experiments – Compositional Paraphrasing,[0],[0]
"We start with the simplest case of bigrams, and then proceed to short phrases.",6 Experiments – Compositional Paraphrasing,[0],[0]
"For all tasks, we again train on appropriate data from PPDB and test on various evaluation datasets, including our two novel datasets (Annotated-PPDB and ML-Paraphrase).",6 Experiments – Compositional Paraphrasing,[0],[0]
"We trained our models by optimizing Eq. 1 using AdaGrad (Duchi et al., 2011).",6.1 Training Procedure,[0],[0]
"We fixed the initial learning rates to 0.5 for the word embeddings and 0.05 for the composition parameters, and the margin to 1.",6.1 Training Procedure,[0],[0]
"Then we did a coarse grid search over a parameter space for λWw , λW , and mini-batch size.
",6.1 Training Procedure,[0],[0]
"For λWw , our search space again consisted of {10−2, 10−3, ..., 10−7, 0}, for λW it was {10−1, 10−2, 10−3, 0}, and we explored batch sizes of {100, 250, 500, 1000, 2000}.",6.1 Training Procedure,[0],[0]
"When initializing with PARAGRAM vectors, the search space for λWw was shifted upwards to be
{10, 1, 10−1 , 10−3, ..., 10−6} to reflect our increased confidence in the initial vectors.",6.1 Training Procedure,[0],[0]
We trained only for 5 epochs for each set of parameters.,6.1 Training Procedure,[0],[0]
"For baselines, we used the same initial skip-gram vectors as in Section 5.",6.1 Training Procedure,[0],[0]
"For all experiments, we again used cosine similarity as our similarity metric and evaluated the statistical significance using the method of (Steiger, 1980).
",6.2 Evaluation and Baselines,[0],[0]
A baseline used in all compositional experiments is vector addition of skip-gram (or PARAGRAM) word vectors.,6.2 Evaluation and Baselines,[0],[0]
"Unlike explicit word vectors, where point-wise multiplication acts as a conjunction of features and performs well on composition tasks (Mitchell and Lapata, 2008), using addition with skip-gram vectors (Mikolov et al., 2013b) gives better performance than multiplication.",6.2 Evaluation and Baselines,[0],[0]
"To evaluate our ability to paraphrase bigrams, we consider the original bigram similarity task from Mitchell and Lapata (2010) as well as our newlyannotated version of it: ML-Paraphrase.
",6.3 Bigram Paraphrasability,[0],[0]
Extracting Training Data Training data for these tasks was extracted from the XL portion of PPDB.,6.3 Bigram Paraphrasability,[0],[0]
"The bigram similarity task from Mitchell and Lapata (2010) contains three types of bigrams: adjective-noun (JN), noun-noun (NN), and verb-noun (VN).",6.3 Bigram Paraphrasability,[0],[0]
"We aimed to collect pairs from PPDB that mirrored these three types of bigrams.
",6.3 Bigram Paraphrasability,[0],[0]
"We found parsing to be unreliable on such short segments of text, so we used a POS tagger (Manning et al., 2014) to tag the tokens in each phrase.",6.3 Bigram Paraphrasability,[0],[0]
We then used the word alignments in PPDB to extract bigrams for training.,6.3 Bigram Paraphrasability,[0],[0]
"For JN and NN, we extracted pairs containing aligned, adjacent tokens in the two phrases with the appropriate partof-speech tag.",6.3 Bigram Paraphrasability,[0],[0]
"Thus we extracted pairs like 〈easy job, simple task〉 for the JN section and 〈town meeting, town council〉 for the NN section.",6.3 Bigram Paraphrasability,[0],[0]
We used a different strategy for extracting training data for the VN subset: we took aligned VN tokens and took the closest noun after the verb.,6.3 Bigram Paraphrasability,[0],[0]
This was done to approximate the direct object that would have been ideally extracted with a dependency parse.,6.3 Bigram Paraphrasability,[0],[0]
"An example from this section is 〈achieve goal, achieve aim〉.
",6.3 Bigram Paraphrasability,[0],[0]
"We removed phrase pairs that (1) contained words not in our vocabulary, (2) were redundant with others, (3) contained brackets, or (4) had Levenshtein distance ≤ 1.",6.3 Bigram Paraphrasability,[0],[0]
The final criterion helps to ensure that we train on phrase pairs with non-trivial differences.,6.3 Bigram Paraphrasability,[0],[0]
"The final training data consisted of 133,997 JN pairs, 62,640 VN pairs and 35,601 NN pairs.
",6.3 Bigram Paraphrasability,[0],[0]
Baselines,6.3 Bigram Paraphrasability,[0],[0]
"In addition to RNN models, we report baselines that use vector addition as the composition function, both with our skip-gram embeddings and PARAGRAM embeddings from Section 5.
",6.3 Bigram Paraphrasability,[0],[0]
We also compare to several results from prior work.,6.3 Bigram Paraphrasability,[0],[0]
"When doing so, we took their best correlations for each data subset.",6.3 Bigram Paraphrasability,[0],[0]
"That is, the JN and NN results from Mitchell and Lapata (2010) use their multiplicative model and the VN results use their dilation model.",6.3 Bigram Paraphrasability,[0],[0]
From Hashimoto et al. (2014) we used their PAS-CLBLM Addl and PAS-CLBLM Addnl models.,6.3 Bigram Paraphrasability,[0],[0]
"We note that their vector dimensionalities are larger than ours, using n = 2000 and 50 respectively.
",6.3 Bigram Paraphrasability,[0],[0]
Results Results are shown in Table 5.,6.3 Bigram Paraphrasability,[0],[0]
We report results on the test portion of the original Mitchell and Lapata (2010) dataset (ML) as well as the entirety of our newly-annotated dataset (MLParaphrase).,6.3 Bigram Paraphrasability,[0],[0]
"RNN results on ML were tuned on the respective development sections and RNN results on ML-Paraphrase were tuned on the entire ML dataset.
",6.3 Bigram Paraphrasability,[0],[0]
Our RNN model outperforms results from the literature on most sections in both datasets and its average correlations are among the highest.13,6.3 Bigram Paraphrasability,[0],[0]
"The one
13The results obtained here differ from those reported in Hashimoto et al. (2014) as we scored their vectors with a newer Python implementation of Spearman ρ that handles ties (Hashimoto, P.C.).
subset of the data that posed difficulty was the NN section of the ML dataset.",6.3 Bigram Paraphrasability,[0],[0]
"We suspect this is due to the reasons discussed in Section 3.2; for our MLParaphrase dataset, by contrast, we do see gains on the NN section.
",6.3 Bigram Paraphrasability,[0],[0]
"We also outperform the strong baseline of adding 1000-dimensional skip-gram embeddings, a model with 40 times the number of parameters, on our MLParaphrase dataset.",6.3 Bigram Paraphrasability,[0],[0]
"This baseline had correlations of 0.45, 0.43, and 0.47 on the JN, NN, and VN partitions, with an average of 0.45—below the average ρ of the RNN (0.52) and even the {PARAGRAM, +} model (0.46).
",6.3 Bigram Paraphrasability,[0],[0]
"Interestingly, the type of vectors used to initialize the RNN has a significant effect on performance.",6.3 Bigram Paraphrasability,[0],[0]
"If we initialize using the 25-dimensional skip-gram vectors, the average ρ on ML-Paraphrase drops to 0.43, below even the {PARAGRAM, +} model.",6.3 Bigram Paraphrasability,[0],[0]
"In this section we show that by training a model based on filtered phrase pairs in PPDB, we can actually distinguish between quality paraphrases and poor paraphrases in PPDB better than the original heuristic scoring scheme from Ganitkevitch et al. (2013).
",6.4 Phrase Paraphrasability,[0],[0]
"Extracting Training Data As before, training data was extracted from the XL section of PPDB.",6.4 Phrase Paraphrasability,[0],[0]
"Similar to the procedure to create our AnnotatedPPDB dataset, phrases were filtered such that only those with a word overlap score of less than 0.5 were kept.",6.4 Phrase Paraphrasability,[0],[0]
We also removed redundant phrases and phrases that contained tokens not in our vocabulary.,6.4 Phrase Paraphrasability,[0],[0]
"The phrases were then binned according to their effective size and 20,000 examples were selected from
bins of effective sizes of 3, 4, and more than 5, creating a training set of 60,000 examples.",6.4 Phrase Paraphrasability,[0],[0]
"Care was taken to ensure that none of our training pairs was also present in our development and test sets.
",6.4 Phrase Paraphrasability,[0],[0]
Baselines We compare our models with strong lexical baselines.,6.4 Phrase Paraphrasability,[0],[0]
"The first, strict word overlap, is the percentage of words in the smaller phrase that are also in the larger phrase.",6.4 Phrase Paraphrasability,[0],[0]
"We also include a version where the words are lemmatized prior to the calculation.
",6.4 Phrase Paraphrasability,[0],[0]
"We also train a support vector regression model (epsilon-SVR) (Chang and Lin, 2011) on the 33 features that are included for each phrase pair in PPDB.",6.4 Phrase Paraphrasability,[0],[0]
We scaled the features such that each lies in the interval,6.4 Phrase Paraphrasability,[0],[0]
"[−1, 1] and tuned the parameters using 5-fold cross validation on our dev set.14",6.4 Phrase Paraphrasability,[0],[0]
"We then trained on the entire dev set after finding the best performing C and ǫ combination and evaluated on the test set of Annotated-PPDB.
",6.4 Phrase Paraphrasability,[0],[0]
Results We evaluated on our Annotated-PPDB dataset described in §3.1.,6.4 Phrase Paraphrasability,[0],[0]
Table 6 shows the Spearman correlations on the 1000-example test set.,6.4 Phrase Paraphrasability,[0],[0]
RNN models were tuned on the development set of 260 examples.,6.4 Phrase Paraphrasability,[0],[0]
"All other methods had no hyperparameters and therefore required no tuning.
",6.4 Phrase Paraphrasability,[0],[0]
"We note that the confidence estimates from Ganitkevitch et al. (2013) reach a ρ of 0.25 on the test set, similar to the results of strict overlap.",6.4 Phrase Paraphrasability,[0],[0]
"While 25-dimensional skip-gram embeddings only reach 0.20, we can improve this to 0.32 by fine-tuning them using PPDB (thereby obtaining our PARA-
14We tuned both parameters over {2−10, 2−9, ..., 210}.
GRAM vectors).",6.4 Phrase Paraphrasability,[0],[0]
"By using the PARAGRAM vectors to initialize the RNN, we reach a correlation of 0.40, which is better than the PPDB confidence estimates by 15% absolute.
",6.4 Phrase Paraphrasability,[0],[0]
"We again consider addition of 1000-dimensional skip-gram embeddings as a baseline, and they continue to perform strongly (ρ = 0.37).",6.4 Phrase Paraphrasability,[0],[0]
"The RNN initialized with PARAGRAM vectors does reach a higher ρ (0.40), but the difference is not statistically significant (p = 0.16).",6.4 Phrase Paraphrasability,[0],[0]
"Thus we can achieve similarlystrong results with far fewer parameters.
",6.4 Phrase Paraphrasability,[0],[0]
This task also illustrates the importance of initializing our RNN model with appropriate word embeddings.,6.4 Phrase Paraphrasability,[0],[0]
"An RNN initialized with skip-gram vectors has a modest ρ of 0.22, well below the ρ of the RNN initialized with PARAGRAM vectors.",6.4 Phrase Paraphrasability,[0],[0]
"Clearly, initialization is important when optimizing non-convex objectives like ours, but it is noteworthy that our best results came from first improving the word vectors and then learning the composition model, rather than jointly learning both from scratch.",6.4 Phrase Paraphrasability,[0],[0]
We performed a qualitative analysis to uncover sources of error and determine differences between adding PARAGRAM vectors and using an RNN initialized with them.,7 Qualitative Analysis,[0],[0]
"To do so, we took the output of both systems on Annotated-PPDB and mapped their cosine similarities to the interval",7 Qualitative Analysis,[0],[0]
"[1, 5].",7 Qualitative Analysis,[0],[0]
"We then computed their absolute error as compared to the gold ratings.
",7 Qualitative Analysis,[0],[0]
Table 7 shows how the average of these absolute errors changes with the magnitude of the gold ratings.,7 Qualitative Analysis,[0],[0]
The RNN performs better (has lower average absolute error) for less similar pairs.,7 Qualitative Analysis,[0],[0]
Vector addition only does better on the most similar pairs.,7 Qualitative Analysis,[0],[0]
"This is presumably because the most positive pairs have high word overlap and so can be represented effectively with a simpler model.
",7 Qualitative Analysis,[0],[0]
"To further investigate the differences between these models, we removed those pairs with gold scores in [2, 4], in order to focus on pairs with extreme scores.",7 Qualitative Analysis,[0],[0]
We identified two factors that distinguished the performance between the two models: length ratio and the amount of lexical overlap.,7 Qualitative Analysis,[0],[0]
"We did not find evidence that non-compositional phrases, such as idioms, were a source of error as these were not found in ML-Paraphrase and only appear rarely in Annotated-PPDB.
",7 Qualitative Analysis,[0],[0]
We define length ratio as simply the number of tokens in the smaller phrase divided by the number of tokens in the larger phrase.,7 Qualitative Analysis,[0],[0]
Overlap ratio is the number of equivalent tokens in the phrase pair divided by the number of tokens in the smaller of the two phrases.,7 Qualitative Analysis,[0],[0]
"Equivalent tokens are defined as tokens that are either exact matches or are paired up in the lexical portion of PPDB used to train the PARAGRAM vectors.
",7 Qualitative Analysis,[0],[0]
Table 9 shows how the performance of the models changes under different values of length ratio and overlap ratio.15,7 Qualitative Analysis,[0],[0]
The values in this table are the percentage changes in absolute error when using the RNN over the PARAGRAM vector addition model.,7 Qualitative Analysis,[0],[0]
"So negative values indicate superior performance by the RNN.
",7 Qualitative Analysis,[0],[0]
A few trends emerge from this table.,7 Qualitative Analysis,[0],[0]
"One is that as the length ratio increases (i.e., the phrase pairs are closer in length), addition surpasses the RNN for positive examples.",7 Qualitative Analysis,[0],[0]
"For negative examples, the trend is reversed.",7 Qualitative Analysis,[0],[0]
"The same trend appears for over-
15The bin delimiters were chosen to be uniform over the range of output values of the length ratio ([0.4,1] with one outlier data point removed) and overlap ratio ([0,1]).
lap ratio.",7 Qualitative Analysis,[0],[0]
"Examples from Annotated-PPDB illustrating these trends on positive examples are shown in Table 8.
",7 Qualitative Analysis,[0],[0]
"When considering both positive and negative examples (“Both”), we see that the RNN excels on the most difficult examples (large differences in phrase length and less lexical overlap).",7 Qualitative Analysis,[0],[0]
"For easier examples, the two fare similarly overall (-2.0 to 0.0% change), but the RNN does much better on negative examples.",7 Qualitative Analysis,[0],[0]
This aligns with the intuition that addition should perform well when two paraphrastic phrases have high lexical overlap and similar length.,7 Qualitative Analysis,[0],[0]
"But when they are not paraphrases, simple addition is misled and the RNN’s learned composition function better captures the relationship.",7 Qualitative Analysis,[0],[0]
This may suggest new architectures for modeling compositionality differently depending on differences in length and amount of overlap.,7 Qualitative Analysis,[0],[0]
We have shown how to leverage PPDB to learn state-of-the-art word embeddings and compositional models for paraphrase tasks.,8 Conclusion,[0],[0]
"Since PPDB was created automatically from parallel corpora, our models are also built automatically.",8 Conclusion,[0],[0]
"Only small amounts of annotated data are used to tune hyperparameters.
",8 Conclusion,[0],[0]
"We also introduced two new datasets to evaluate compositional models of short paraphrases, filling a gap in the NLP community, as currently there are no datasets created for this purpose.",8 Conclusion,[0],[0]
"Successful models on these datasets can then be used to extend the coverage of, or provide an alternative to, PPDB.
",8 Conclusion,[0],[0]
"There remains a great deal of work to be done in developing new composition models, whether with new network architectures or distance functions.",8 Conclusion,[0],[0]
"In this work, we based our composition function on constituent parse trees, but this may not be the best approach—especially for short phrases.",8 Conclusion,[0],[0]
"Dependency syntax may be a better alternative (Socher et al., 2014).",8 Conclusion,[0],[0]
"Besides improving composition, another direction to explore is how to use models for short phrases in sentence-level paraphrase recognition and other downstream tasks.",8 Conclusion,[0],[0]
Increasing the dimension of word embeddings or training them on more data can have a significant positive impact on many tasks—both at the word level and on downstream tasks.,Appendix A,[0],[0]
"We scaled
up our original 25-dimensional PARAGRAM embeddings and modified our training procedure slightly in order to produce two sets of 300-dimensional PARAGRAM vectors.16 The vectors outperform our original 25-dimensional PARAGRAM vectors on all tasks and achieve human-level performance on SL999 and WS353.",Appendix A,[0],[0]
"Moreover, when simply using vector addition as a compositional model, they are both on par with the RNN models we trained specifically for each task.",Appendix A,[0],[0]
"These results can be seen in Tables 10, 11, and 12.
",Appendix A,[0],[0]
"The main modification was to use higherdimensional initial embeddings, in our case the pretrained 300-dimensional GloVe embeddings.17 Since PPDB only contains lowercased words, we extracted only one GloVe vector per word type (regardless of case) by taking the first occurrence of each word in the vocabulary.",Appendix A,[0],[0]
"This is the vector for the most common casing of the word, and was used as
16Both PARAGRAM300,WS353 and PARAGRAM300,SL999 vectors can be found on the authors’ websites.
",Appendix A,[0],[0]
"17We used the GloVe vectors trained on 840 billion tokens of Common Crawl data, available at http://nlp.stanford.edu/projects/glove/
the word’s single initial vector in our experiments.",Appendix A,[0],[0]
"This reduced the vocabulary from the original 2.2 million types to 1.7 million.
",Appendix A,[0],[0]
Smaller changes included replacing dot product with cosine similarity in Equation 2 and a change to the negative sampling procedure.,Appendix A,[0],[0]
"We experimented with three approaches: MAX sampling discussed in Section 4.1, RAND sampling which is random sampling from the batch, and a 50/50 mixture of MAX sampling and RAND sampling.
",Appendix A,[0],[0]
"For training data, we selected all word pairs in the lexical portion of PPDB XL that were in our vocabulary, removing redundancies.",Appendix A,[0],[0]
"This resulted in 169,591 pairs for training.",Appendix A,[0],[0]
"We trained our models for 10 epochs and tuned hyperparameters (batch size, λWw , δ, and sampling method) in two ways: maximum correlation on WS353 (PARAGRAM300,WS353) and maximum correlation on SL999 (PARAGRAM300,SL999).18",Appendix A,[0],[0]
"We report results for both sets of embeddings in Tables 10, 11, and 12, and make both available to the community in the hope that they may be useful for other downstream tasks.",Appendix A,[0],[0]
"We thank the editor and the anonymous reviewers as well as Juri Ganitkevitch, Weiran Wang, and Kazuma Hashimoto for their valuable comments and technical assistance.",Acknowledgements,[0],[0]
"We also thank Chris Callison-Burch, Dipanjan Das, Kuzman Ganchev, Ellie Pavlick, Slav Petrov, Owen Rambow, David Sontag, Oscar Täckström, Kapil Thadani, Lyle Ungar, Benjamin Van Durme, and Mo Yu for helpful conversations.",Acknowledgements,[0],[0]
"This research was supported by a Google Faculty Research Award to Mohit Bansal, Karen Livescu, and Kevin Gimpel, the Multimodal Information Access & Synthesis Center at UIUC, part of CCICADA, a DHS Science and Technology Center of Excellence, and by DARPA under agreement number FA8750-13-2-0008.",Acknowledgements,[0],[0]
"The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of DARPA or the U.S. Government.
",Acknowledgements,[0],[0]
"18Note that if we use the approach in Section 5.3 in which we tune to maximize 2×WS-S correlation minus the WS-R correlation, the SL999 ρ is 0.640, still higher than any other reported result to the best of our knowledge.",Acknowledgements,[0],[0]
"The Paraphrase Database (PPDB; Ganitkevitch et al., 2013) is an extensive semantic resource, consisting of a list of phrase pairs with (heuristic) confidence estimates.",abstractText,[0],[0]
"However, it is still unclear how it can best be used, due to the heuristic nature of the confidences and its necessarily incomplete coverage.",abstractText,[0],[0]
We propose models to leverage the phrase pairs from the PPDB to build parametric paraphrase models that score paraphrase pairs more accurately than the PPDB’s internal scores while simultaneously improving its coverage.,abstractText,[0],[0]
They allow for learning phrase embeddings as well as improved word embeddings.,abstractText,[0],[0]
"Moreover, we introduce two new, manually annotated datasets to evaluate short-phrase paraphrasing models.",abstractText,[0],[0]
"Using our paraphrase model trained using PPDB, we achieve state-of-the-art results on standard word and bigram similarity tasks and beat strong baselines on our new short phrase paraphrase tasks.1,2",abstractText,[0],[0]
From Paraphrase Database to Compositional Paraphrase Model and Back,title,[0],[0]
"Models of the statistical structure of natural images play a key role in computer vision and image processing (Srivastava et al., 2003).",1. Introduction,[0],[0]
"Due to the high dimensionality of the images captured by modern cameras, a rich research literature instead models the statistics of small image patches.",1. Introduction,[0],[0]
"For example, the K-SVD method (Elad & Aharon, 2006) generalizes K-means clustering to learn a dictionary for sparse coding of image patches.",1. Introduction,[0],[0]
"The state-of-the-art learned simultaneous sparse coding (LSSC, Mairal et al. (2009)) and block matching and 3D filtering (BM3D, Dabov et al. (2008)) methods integrate clustering, dictionary learning,
1Brown University, Providence, RI, USA.",1. Introduction,[0],[0]
"2Harvard University, Cambridge, MA, USA. 3University of California, Irvine, CA, USA.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Geng Ji <gji@cs.brown.edu>.
Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
and denoising to extract information directly from a single corrupted image.,1. Introduction,[0],[0]
"Alternatively, the accurate expected patch log-likelihood (EPLL, Zoran & Weiss (2011)) method maximizes the log-likelihood of overlapping image patches under a finite Gaussian mixture model learned from uncorrupted natural images.
",1. Introduction,[0],[0]
"We show that with minor modifications, the objective function underlying EPLL is equivalent to a variational loglikelihood bound for a novel generative model of whole images.",1. Introduction,[0],[0]
Our model coherently captures overlapping image patches via a randomly positioned spatial grid.,1. Introduction,[0],[0]
"By deriving a rigorous variational bound, we then develop improved nonparametric models of natural image statistics using the hierarchical Dirichlet process (HDP, Teh et al. (2006)).",1. Introduction,[0],[0]
"In particular, DP mixtures allow an appropriate model complexity to be inferred from data, while the hierarchical DP captures the patch self-similarities and repetitions that are ubiquitous in natural images (Jégou et al., 2009).",1. Introduction,[0],[0]
"Unlike previous whole-image generative models such as fields of experts (FoE, Roth & Black (2005)), which uses a single set of Markov random field parameters to model all images, our HDP model learns image-specific clusters to accurately model distinctive textures.",1. Introduction,[0],[0]
"Coupled with a scalable structured variational inference algorithm, we improve on the excellent denoising accuracy of the LSSC and BM3D algorithms, while providing a Bayesian nonparametric model with a broader range of potential applications.",1. Introduction,[0],[0]
"Our approach is derived from models of small (8× 8 pixel) patches of a large natural image x. Let Pi be a binary indicator matrix that extracts the G = 82 pixels Pix ∈ RG in patch i. To reduce sensitivity to lighting variations, a contrast normalizing transform is applied to remove the mean (or “DC component”) of the pixel intensities in each patch:
vi = Pix− 1G1TPix = BPix, (1)
for a “zero-centering” matrix B. Zoran & Weiss (2012) show that a finite mixture of K zero-mean Gaussians,
p(vi) = ∑K k=1 πkNorm(vi | 0,Λ−1k ), (2)
is superior to many classic image models in terms of predictive likelihood and patch denoising performance.
",2. Expected Patch Log-likelihood,[0],[0]
"The widely-used EPLL image restoration framework measures the quality of a reconstruction by the expected patch log-likelihood, “assuming a patch location in the image is chosen uniformly at random” (Zoran & Weiss, 2011).",2. Expected Patch Log-likelihood,[0],[0]
"Given a corrupted image y, EPLL estimates a clean image x by minimizing the objective:
min x
λ 2 ‖x− y‖2 −∑i log p(BPix).",2. Expected Patch Log-likelihood,[0],[0]
"(3)
Here, the sum ranges over all overlapping, completely visible (uncropped) image patches.",2. Expected Patch Log-likelihood,[0],[0]
"The constant λ is determined by the noise level of the corrupted image y.
Direct optimization of Eq.",2. Expected Patch Log-likelihood,[0],[0]
"(3) is challenging, so inspired by half quadratic splitting (Geman & Yang, 1995), the EPLL objective can be reformulated as follows:
min x,v̄
λ",2. Expected Patch Log-likelihood,[0],[0]
2 ‖x− y‖2 + ∑,2. Expected Patch Log-likelihood,[0],[0]
i κ 2 ‖Pix− v̄i‖2 − log p(Bv̄i).,2. Expected Patch Log-likelihood,[0],[0]
"(4)
Each patch i is allocated an auxiliary variable v̄i, which (unlike the vi variable in Eq.",2. Expected Patch Log-likelihood,[0],[0]
(1)) includes an estimate of the mean patch intensity.,2. Expected Patch Log-likelihood,[0],[0]
This augmented objective leads to closed-form coordinate descent updates.,2. Expected Patch Log-likelihood,[0],[0]
Gating.,2. Expected Patch Log-likelihood,[0],[0]
"Assign each patch i to some cluster zi:
zi = arg max k
πk Norm ( BPix | 0,Λ−1k + κI ) .",2. Expected Patch Log-likelihood,[0],[0]
"(5)
Filtering.",2. Expected Patch Log-likelihood,[0],[0]
"Given an approximate clean image x and cluster assignments z, denoise patches via least squares:
v̄i =",2. Expected Patch Log-likelihood,[0],[0]
( I + κ−1BTΛziB )−1,2. Expected Patch Log-likelihood,[0],[0]
Pix.,2. Expected Patch Log-likelihood,[0],[0]
"(6)
Mixing.",2. Expected Patch Log-likelihood,[0],[0]
"Given a fixed set of auxiliary patches v̄ and the noisy image y, a denoised image x is estimated as
x = ( λI + κ ∑ i PTi Pi )−1",2. Expected Patch Log-likelihood,[0],[0]
( λy + κ ∑ i PTi v̄i ) .,2. Expected Patch Log-likelihood,[0],[0]
"(7)
Annealing.",2. Expected Patch Log-likelihood,[0],[0]
Optimal solutions of Eq.,2. Expected Patch Log-likelihood,[0],[0]
(4) approach those of the EPLL objective in Eq.,2. Expected Patch Log-likelihood,[0],[0]
(3) as κ→∞. EPLL denoising algorithms slowly increase κ via an annealing schedule that must be tuned for best performance.,2. Expected Patch Log-likelihood,[0],[0]
Justification?,2. Expected Patch Log-likelihood,[0],[0]
"Empirically, the intuitive EPLL objective is much more effective than baselines which use only a subset of non-overlapping patches, or average independently denoised patches (Zoran & Weiss, 2011).",2. Expected Patch Log-likelihood,[0],[0]
"But why should we optimize the expected log-likelihood, instead of the expected likelihood or another function of patch-specific likelihoods?",2. Expected Patch Log-likelihood,[0],[0]
And how can the EPLL heuristic be generalized to capture more complex statistics of natural images?,2. Expected Patch Log-likelihood,[0],[0]
"This paper answers these questions by linking EPLL to a rigorous, nonparametric generative model of whole images.",2. Expected Patch Log-likelihood,[0],[0]
"We now develop the HDP-Grid generative model summarized in Fig. 1, which uses randomly placed patch grids to formalize the EPLL objective, and hierarchical DP mixtures to capture image patch self-similarity.",3. Mixture Models for Grids of Image Patches,[0],[0]
"The hierarchical Dirichlet process (HDP, Teh et al. (2006)) is a Bayesian nonparametric prior used to cluster groups of related data; we model natural images as groups of patches.",3.1. Hierarchical Dirichlet Process Mixtures,[0],[0]
"The HDP shares visual structure, such as patches of grass or bricks, by sharing a common set of clusters (called topics in applications to text data) across images.",3.1. Hierarchical Dirichlet Process Mixtures,[0],[0]
"In addition, the HDP models image-specific variability by allowing each image to use this shared set of clusters with unique frequencies; grass might be abundant in one image but absent in another.",3.1. Hierarchical Dirichlet Process Mixtures,[0],[0]
"Via the HDP, we can learn the proper number of hidden clusters from data, and discover new clusters as we collect new images with novel visual textures.
",3.1. Hierarchical Dirichlet Process Mixtures,[0],[0]
The HDP uses a stick-breaking construction to generate a corpus-wide vector π0 =,3.1. Hierarchical Dirichlet Process Mixtures,[0],[0]
"[π01, π02, . . .",3.1. Hierarchical Dirichlet Process Mixtures,[0],[0]
", π0k, . . .",3.1. Hierarchical Dirichlet Process Mixtures,[0],[0]
],3.1. Hierarchical Dirichlet Process Mixtures,[0],[0]
"of frequencies for a countably infinite set of visual clusters:
βk ∼ Beta(1, γ), π0k(β) , βk ∏k−1 `=1 (1− β`).",3.1. Hierarchical Dirichlet Process Mixtures,[0],[0]
"(8) The HDP allocates each image m its own cluster frequencies πm, where the vector π0 determines the mean of a DP prior on the frequencies of shared clusters:
πm ∼ DP(απ0), E[πmk] = π0k.",3.1. Hierarchical Dirichlet Process Mixtures,[0],[0]
"(9) When the concentration parameter α < 1, we capture the “burstiness” and self-similarity of natural image regions (Jégou et al., 2009) by placing most probability mass in πm on a sparse subset of global clusters.",3.1. Hierarchical Dirichlet Process Mixtures,[0],[0]
We sample pixels in imagem via a randomly placed grid of patches.,3.2. Image Generation via Random Grids,[0],[0]
"When each patch has G pixels, Fig. 2 shows there are exactlyG grid alignments for an image of arbitrary size.",3.2. Image Generation via Random Grids,[0],[0]
"The alignment wm ∈ {1, . . .",3.2. Image Generation via Random Grids,[0],[0]
", G} has a uniform prior: wm ∼ Cat(1/G, . . .",3.2. Image Generation via Random Grids,[0],[0]
", 1/G).",3.2. Image Generation via Random Grids,[0],[0]
(10) Modeling multiple overlapping grids is crucial to capture real image statistics.,3.2. Image Generation via Random Grids,[0],[0]
"As the true grid alignment for each image is uncertain, posterior inference will favor images
that are likely under all possible wm.",3.2. Image Generation via Random Grids,[0],[0]
"Models based on a single, fixed grid produce severe artifacts at patch boundaries, as shown in Fig. 2 of Zoran & Weiss (2011).",3.2. Image Generation via Random Grids,[0],[0]
"Gaussian mixtures provide excellent density models for natural image patches (Zoran & Weiss, 2012).",3.3. Patch Generation via Gaussian Mixtures,[0],[0]
"We associate clusters with zero-mean, full-covariance Gaussian distributions on patches with G pixels.",3.3. Patch Generation via Gaussian Mixtures,[0],[0]
We parameterize cluster k by a precision (inverse covariance) matrix,3.3. Patch Generation via Gaussian Mixtures,[0],[0]
"Λk ∼ Wish(ν,W ), whose conjugate Wishart prior has ν degrees of freedom and scale matrix W .",3.3. Patch Generation via Gaussian Mixtures,[0],[0]
"Given that wm = g, each of the Nmg patches vmgn in grid g is sampled from an infinite mixture with image-specific cluster frequencies:
p(vmgn|wm = g) = ∞∑ k=1 πmkNorm(vmgn|0,Λ−1k ).",3.3. Patch Generation via Gaussian Mixtures,[0],[0]
(11) Let zmgn |,3.3. Patch Generation via Gaussian Mixtures,[0],[0]
wm = g ∼ Cat(πm) denote the cluster that generates patch n. To account for the contrast normalization of Eq.,3.3. Patch Generation via Gaussian Mixtures,[0],[0]
"(1), the intensities in patch n are shifted by an independent, scalar “DC offset” umgn: p(umgn | wm = g) =",3.3. Patch Generation via Gaussian Mixtures,[0],[0]
"Norm(umgn | r, s2).",3.3. Patch Generation via Gaussian Mixtures,[0],[0]
"(12) Finally, if wm 6=",3.3. Patch Generation via Gaussian Mixtures,[0],[0]
"g so that grid g is unobserved, we sample (zmgn, vmgn, umgn) from some reference distribution
independent of the HDP mixture model parameters.",3.3. Patch Generation via Gaussian Mixtures,[0],[0]
"Given patches vmg with offsets umg generated via grid wm = g, we sample a whole “clean image” xm as
Norm ( xm | ∑Nmg n=1 PTmgnv̄mgn, δ 2I ) , (13)
where v̄mgn , Cmgnvmgn+umgn.",3.4. From Patches to Corrupted Images,[0],[0]
"Binary indicator matrices Pmgn, as in Sec. 2, stitch together patches in the chosen grid g. Image xm is then generated by adding independent Gaussian noise with small variance δ2.",3.4. From Patches to Corrupted Images,[0],[0]
"Most patches in the chosen grid will be fully observed in xm, but as illustrated in Fig. 2, some may be clipped by the image boundary.",3.4. From Patches to Corrupted Images,[0],[0]
"Indicator matrices Cmgn are defined so Cmgnvmgn + umgn is a vector containing the observed pixels from patch n.
For image restoration tasks, the observed image",3.4. From Patches to Corrupted Images,[0],[0]
ym is a corrupted version of some clean image xm,3.4. From Patches to Corrupted Images,[0],[0]
that we would like to estimate.,3.4. From Patches to Corrupted Images,[0],[0]
"Models of natural image statistics are commonly validated on the problem of image denoising, where xm is polluted by additive white Gaussian noise:
p(ym | xm) = Norm(ym",3.4. From Patches to Corrupted Images,[0],[0]
"| xm, σ2I).",3.4. From Patches to Corrupted Images,[0],[0]
(14) The variance σ2 δ2 indicates the noise level.,3.4. From Patches to Corrupted Images,[0],[0]
"We also validate our model on image inpainting problems (Bertalmio et al., 2000), where some pixels are observed without noise but others are completely missing.",3.4. From Patches to Corrupted Images,[0],[0]
"By replacing Eq. (14) with other linear likelihood models, our novel generative model for natural images may be easily applied to other tasks including image deblurring (Zoran & Weiss, 2011), image super resolution (Yang & Huang, 2010), and color image demosaicing (Mairal et al., 2009).",3.4. From Patches to Corrupted Images,[0],[0]
"We now develop scalable learning algorithms for our nonparametric, grid-based image model.",4. Variational Inference,[0],[0]
We first examine a baseline DP Grid model in which the same cluster frequencies π0 are shared by all images.,4. Variational Inference,[0],[0]
"Our full HDP Grid model then learns image-specific cluster frequencies πm, and instantiates new clusters to model unique visual textures.",4. Variational Inference,[0],[0]
Our goal is to infer the DP Grid model parameters that best explain observed images which may be clean (xm) or corrupted by noise (ym).,4.1. DP Grid: Variational Inference,[0],[0]
"The DP Grid model uses the same cluster probabilities π0, generated from stickbreaking weights β as in Eq.",4.1. DP Grid: Variational Inference,[0],[0]
"(8), for all images.
",4.1. DP Grid: Variational Inference,[0],[0]
Learning from clean images.,4.1. DP Grid: Variational Inference,[0],[0]
"Given a training set D of uncorrupted images x1, . . .",4.1. DP Grid: Variational Inference,[0],[0]
"xM , we estimate the posterior distribution p(β,Λ, w,Ψpatch | x) for our global mixture model parameters β and Λ, grid assignment indicators wm, and patch-level latent variables Ψpatchm = {um, vm, zm}.
",4.1. DP Grid: Variational Inference,[0],[0]
"Exact posterior inference is intractable, so we instead find an approximate posterior q(·) = q(β,Λ, w,Ψpatch) minimizing the KL divergence (Wainwright & Jordan, 2008) from the true posterior p(·|x).",4.1. DP Grid: Variational Inference,[0],[0]
"Equivalently, our variational method maximizes the following objective L:
max q∈Q L(q, x) = max q∈Q Eq [ log p(x, ·) q(·) ] ≤ log p(x).",4.1. DP Grid: Variational Inference,[0],[0]
"(15)
We constrain the solution of our optimization to come from a tractable family of structured mean-field distributions Q, parameterized by free parameters.",4.1. DP Grid: Variational Inference,[0],[0]
"Unlike naı̈ve mean-field methods which assume complete posterior independence, our structured mean-field approximation is more accurate and includes dependencies between some latent variables:
q(·) = ∞∏ k=1 q(Λk)q(βk) · M∏",4.1. DP Grid: Variational Inference,[0],[0]
"m=1 q(wm)q(Ψ patch m |wm).
",4.1. DP Grid: Variational Inference,[0],[0]
"As in Hughes & Sudderth (2013), this approximate posterior family contains infinitely many clusters, just like the true posterior.",4.1. DP Grid: Variational Inference,[0],[0]
"Rather than applying a fixed truncation to the stick-breaking prior (Blei & Jordan, 2006), we dynamically truncate the patch assignment distributions q(z) to only use the first K clusters to explain the M observed images.",4.1. DP Grid: Variational Inference,[0],[0]
"Clusters with indices k > K then have factors q(Λk) set to the prior, and need not be explicitly represented.
",4.1. DP Grid: Variational Inference,[0],[0]
Global mixture model.,4.1. DP Grid: Variational Inference,[0],[0]
"The global cluster weights β and precision matrices Λ have standard exponential family forms (free parameters are marked by hats):
q(Λk) = Wish ( ν̂k, Ŵk ) , q(βk) = Beta ( ρ̂kω̂k, (1− ρ̂k)ω̂k ) .
",4.1. DP Grid: Variational Inference,[0],[0]
"Here ρ̂k = Eq[βk], and ω̂k controls the variance of q(βk).
",4.1. DP Grid: Variational Inference,[0],[0]
Image-specific alignment.,4.1. DP Grid: Variational Inference,[0],[0]
"For natural images, all grid alignments are typically of similar quality, so we fix a uniform alignment posterior q(wm) =",4.1. DP Grid: Variational Inference,[0],[0]
"Cat ( 1 G , . . .",4.1. DP Grid: Variational Inference,[0],[0]
", 1 G ) .",4.1. DP Grid: Variational Inference,[0],[0]
"This simplifies many updates while still avoiding artifacts that would arise from a single, non-overlapping patch grid.
",4.1. DP Grid: Variational Inference,[0],[0]
Patch-specific factors.,4.1. DP Grid: Variational Inference,[0],[0]
"The patch-specific variables Ψpatch have structured posteriors, conditioned on the value of the grid indicator wm for the current image:
q(zmgn | wm = g)",4.1. DP Grid: Variational Inference,[0],[0]
"= Categorical ( r̂mgn1, ..., r̂mgnK ) ,
q(umgn | wm = g) =",4.1. DP Grid: Variational Inference,[0],[0]
"Norm ( ûmgn, φ̂ u mgn ) ,
q(vmgn | wm = g,zmgn = k) =",4.1. DP Grid: Variational Inference,[0],[0]
"Norm ( v̂mgnk, φ̂ v mgnk ) .
",4.1. DP Grid: Variational Inference,[0],[0]
"Below, we let",4.1. DP Grid: Variational Inference,[0],[0]
"Eq[·] denote the conditional expectation with respect to the variational distribution q, given wm.
Learning.",4.1. DP Grid: Variational Inference,[0],[0]
"Given clean images x, we perform coodinate ascent on the objective L, alternatively updating one factor among q(β)q(Λ)q(w)q(Ψpatch).",4.1. DP Grid: Variational Inference,[0],[0]
Most updates have closed forms due to the exponential families defining Q (see supplement).,4.1. DP Grid: Variational Inference,[0],[0]
"As one intuitive example, consider the update for
the cluster precision matrix posterior q(Λk|ν̂k, Ŵk):
ν̂k = ν + 1
G Nk, Nk = M∑ m=1",4.1. DP Grid: Variational Inference,[0],[0]
"G∑ g=1 Nmg∑ n=1 r̂mgnk, (16)
",4.1. DP Grid: Variational Inference,[0],[0]
"Ŵk = W + 1
G M∑ m=1",4.1. DP Grid: Variational Inference,[0],[0]
G∑ g=1 Nmg∑ n=1,4.1. DP Grid: Variational Inference,[0],[0]
Eq [ 1k(zmgn)vmgnv T mgn ] .︸,4.1. DP Grid: Variational Inference,[0],[0]
"︷︷ ︸
Sk
Statistic Nk(r̂) counts patches assigned to cluster k, while Sk(r̂, v̂, φ̂
v) aggregates second moments.",4.1. DP Grid: Variational Inference,[0],[0]
"These updates follow the standard form of prior parameter plus expected sufficient statistic, except the statistics are averaged (not simply added) across the G grid alignments.",4.1. DP Grid: Variational Inference,[0],[0]
"Given a corrupted image ym, we seek to compute the posterior p(xm | ym,D), where we condition on the training set D. Our variational posterior family Q now includes an additional factor for the unobserved, “clean” image xm:
q(xm) =",4.2. Image Denoising and Connections to EPLL,[0],[0]
"Norm ( xm | x̂m, φ̂xm ) .",4.2. Image Denoising and Connections to EPLL,[0],[0]
"(17)
",4.2. Image Denoising and Connections to EPLL,[0],[0]
"The variational inference objective becomes
max q∈Q
Eq [ log
p(D, ym, xm, ·) q(xm, ·)
] ≤ log p(ym,D), (18)
and the coordinate ascent update for q(xm) equals
x̂m = φ̂ x m (ym σ2 + hm δ2 ) , φ̂xm = δ2σ2 δ2 + σ2 I. (19)
",4.2. Image Denoising and Connections to EPLL,[0],[0]
"The updated covariance is diagonal, improving computational efficiency.",4.2. Image Denoising and Connections to EPLL,[0],[0]
"The mean depends on the average image vector across all patches in all grids, denoted by hm:
hm , 1
G G∑ g=1 Nmg∑ n=1 PTmgn(CmgnEq[vmgn] + ûmgn).",4.2. Image Denoising and Connections to EPLL,[0],[0]
"(20)
Note that the update for x̂m in Eq.",4.2. Image Denoising and Connections to EPLL,[0],[0]
(19) is similar to the EPLL update in Eq.,4.2. Image Denoising and Connections to EPLL,[0],[0]
"(7), except that some terms involving projection matrices become constants because we account for partially observed patches.",4.2. Image Denoising and Connections to EPLL,[0],[0]
Modeling partial patches is necessary to produce a valid likelihood bound in Eq.,4.2. Image Denoising and Connections to EPLL,[0],[0]
"(18).
",4.2. Image Denoising and Connections to EPLL,[0],[0]
"In fact, as we show below all three terms in the EPLL objective in Eq. (4) are very similar to our proposed minimization objective function −L, up to a scale factor of G. Of course, a key difference is that our objective seeks full posteriors rather than point estimates, and enables the HDP model of multiple images detailed in Sec. 4.3.
",4.2. Image Denoising and Connections to EPLL,[0],[0]
EPLL Term 1.,4.2. Image Denoising and Connections to EPLL,[0],[0]
"When we set λ , Gσ2 , the first term of the EPLL objective in Eq. (4) becomes
G · 12σ2 (x− y)T (x− y).",4.2. Image Denoising and Connections to EPLL,[0],[0]
"(21) Similarly, suppressing the subscript m denoting the image for simplicity, Eq[− log p(y|x)] in our −L simplifies as
1 2σ2Eq[(x− y)T (x− y)].",4.2. Image Denoising and Connections to EPLL,[0],[0]
"(22)
EPLL Term 2.",4.2. Image Denoising and Connections to EPLL,[0],[0]
Taking the second term in Eq.,4.2. Image Denoising and Connections to EPLL,[0],[0]
"(4) and substituting κ = 1/δ2, we have:
1 2δ2 ∑ i(Pix− v̄i)T (Pix− v̄i).",4.2. Image Denoising and Connections to EPLL,[0],[0]
"(23)
",4.2. Image Denoising and Connections to EPLL,[0],[0]
"The corresponding term Eq[− log p(x|w, u, v)] in our objective −L can be written similarly up to a scaling by G:
1
G
1
2δ2 G∑",4.2. Image Denoising and Connections to EPLL,[0],[0]
g=1 Ng∑ n=1,4.2. Image Denoising and Connections to EPLL,[0],[0]
Eq [ (Pgnx− v̄gn)T (Pgnx− v̄gn) ] .,4.2. Image Denoising and Connections to EPLL,[0],[0]
"(24)
EPLL Term 3.",4.2. Image Denoising and Connections to EPLL,[0],[0]
"The third EPLL term assumes zerocentered patches Bv̄i are drawn from Gaussian mixtures:
−∑i log p(Bv̄i | π0,Λ).",4.2. Image Denoising and Connections to EPLL,[0],[0]
"(25) Similarly, in our minimization objective −L we draw vgn from a DP mixture model.",4.2. Image Denoising and Connections to EPLL,[0],[0]
"Explicitly including the cluster assignment zgn, Eq[− log p(v, z|w)] equals
− 1 G G∑ g=1",4.2. Image Denoising and Connections to EPLL,[0],[0]
Ng∑ n=1,4.2. Image Denoising and Connections to EPLL,[0],[0]
Eq[log,4.2. Image Denoising and Connections to EPLL,[0],[0]
"p(vgn, zgn | π0,Λ)].",4.2. Image Denoising and Connections to EPLL,[0],[0]
"(26)
EPLL is similar, but maximizes assignments (Eq. (5)) rather than computing posterior assignment probabilities.",4.2. Image Denoising and Connections to EPLL,[0],[0]
Image-specific frequencies.,4.3. HDP Grid: Variational Inference,[0],[0]
"The DP model above, and the parametric EPLL objective it generalizes, assume the same cluster frequency vector π0 for each image m. Our HDP Grid model allows image-specific frequencies πm to be learned from data, via the hierarchical regularization of the HDP prior (Teh et al., 2006).",4.3. HDP Grid: Variational Inference,[0],[0]
"Our approximate posterior family Q now has the following HDP-specific factors:
q(β)",4.3. HDP Grid: Variational Inference,[0],[0]
"= ∏∞ k=1 Beta (βk | ρ̂kω̂k, (1− ρ̂k)ω̂k) , (27)
q([πm1 . .",4.3. HDP Grid: Variational Inference,[0],[0]
.πmK,4.3. HDP Grid: Variational Inference,[0],[0]
πm>K ]),4.3. HDP Grid: Variational Inference,[0],[0]
= Dir(θ̂m1 . . .,4.3. HDP Grid: Variational Inference,[0],[0]
"θ̂mK , θ̂m>K).",4.3. HDP Grid: Variational Inference,[0],[0]
"This approximate posterior represents infinitely many clusters via a finite partition of πm into K + 1 terms: one for each of theK active clusters, and a remainder term at index >K that aggregates the mass of all inactive clusters.",4.3. HDP Grid: Variational Inference,[0],[0]
The free parameter θ̂m is also a vector of size K + 1 whose last entry represents all inactive clusters.,4.3. HDP Grid: Variational Inference,[0],[0]
"We follow Hughes et al. (2015) to obtain a closed-form update for θ̂m, and gradient-based updates for ρ̂, ω̂; see the supplement for details.",4.3. HDP Grid: Variational Inference,[0],[0]
We highlight that the θ̂m update naturally includes a 1G rescaling of count sufficient statistics as in Eq.,4.3. HDP Grid: Variational Inference,[0],[0]
(16).,4.3. HDP Grid: Variational Inference,[0],[0]
"Other factors remain unchanged from the DP Grid model.
",4.3. HDP Grid: Variational Inference,[0],[0]
Image-specific clusters.,4.3. HDP Grid: Variational Inference,[0],[0]
"Due to the heavy-tailed distribution of natural images (Ruderman, 1997), even with large training sets, test images may still contain unique textural patterns like the striped scarf in the Barbara image in Fig. 3.",4.3. HDP Grid: Variational Inference,[0],[0]
"Fortunately, our Bayesian nonparametric HDP Grid model provides a coherent way to capture such patterns by appending K ′ novel, image-specific clusters to the original K clusters learned from training images.",4.3. HDP Grid: Variational Inference,[0],[0]
"These novel clusters lead to more accurate posterior approximations q ∈ Q that better optimize our objective L.
We initialize inference by creating K ′ = 100 imagespecific clusters with the k-means++ algorithm (Arthur & Vassilvitskii, 2007), which minimizes the cost function
J (z′,Λ′) = ∑i∑K′k=1 1k(z′i)D(ṽiṽTi ,Λ′k), (28) where the first sum is over the set of fully-observed patches within the image.",4.3. HDP Grid: Variational Inference,[0],[0]
"The function D is the Bregman divergence associated with our zero-mean Gaussian likelihood (Banerjee et al., 2005), and ṽi = BPiy is a zerocentered patch.",4.3. HDP Grid: Variational Inference,[0],[0]
We initialize the algorithm by sampling K ′,4.3. HDP Grid: Variational Inference,[0],[0]
"diverse patches in a distance-biased fashion, and refine with 50 iterations of coordinate descent updates of z′ and Λ′.
Then we expand the variational posterior q(Λ) intoK+K ′ clusters.",4.3. HDP Grid: Variational Inference,[0],[0]
"The first K indices are kept the same as training, and the last K ′ indices are set via Eq.",4.3. HDP Grid: Variational Inference,[0],[0]
"(16) using sufficient statistics N ′, S′ derived from hard assignments z′:
N ′k′ ← ∑ i 1k′(z ′",4.3. HDP Grid: Variational Inference,[0],[0]
"i), S ′ k′",4.3. HDP Grid: Variational Inference,[0],[0]
←,4.3. HDP Grid: Variational Inference,[0],[0]
[∑ i 1k′(z ′,4.3. HDP Grid: Variational Inference,[0],[0]
i)ṽiṽ T i −Nk′σ2I ] + .,4.3. HDP Grid: Variational Inference,[0],[0]
"Here, following Portilla et al. (2003) and Kivinen et al. (2007), S′k′ estimates the clean data statistic Sk′ by subtracting the expected noise covariance.",4.3. HDP Grid: Variational Inference,[0],[0]
"The [·]+ operator thresholds any negative eigenvalues to zero.
",4.3. HDP Grid: Variational Inference,[0],[0]
"Similarly, the other global variational factor q(β) is also expanded to K + K ′ clusters via sufficient statistics N ′ and counts of cluster usage from training data.",4.3. HDP Grid: Variational Inference,[0],[0]
"Given {β,Λ}K+K′k=1 , each factor in q may then be updated in turn to maximize the variational objective L (see supplement).",4.3. HDP Grid: Variational Inference,[0],[0]
"Finally, while we initialize K ′ to a large number to avoid local optima, this may lead to extraneous clusters.",4.3. HDP Grid: Variational Inference,[0],[0]
We thus delete new clusters that our sparsity-biased variational updates do not assign to any patch.,4.3. HDP Grid: Variational Inference,[0],[0]
"In the Barbara image in Fig. 3, this leaves 9 image-specific clusters.",4.3. HDP Grid: Variational Inference,[0],[0]
"Deletion improves model interpretability and algorithm speed, because costs scale linearly with the number of instantiated clusters.",4.3. HDP Grid: Variational Inference,[0],[0]
"Following EPLL, we train our HDP-Grid model using 400 clean training and validation images from the Berkeley segmentation dataset (BSDS, Martin et al. (2001)).",5. Experiments,[0],[0]
We fix δ = 0.5/255 to account for the quantization of image intensities to 8-bit integers.,5. Experiments,[0],[0]
Observed DC offsets u provide maximum likelihood estimates of the mean r and variance s2 in Eq.,5. Experiments,[0],[0]
(12).,5. Experiments,[0],[0]
"Similarly, we compute empirical covariance matrices for patches in the same image segments to estimate hyperparameters W and ν in Eq.",5. Experiments,[0],[0]
(16).,5. Experiments,[0],[0]
"Using variational learning algorithms that adapt the number of clusters to the observed data (Hughes & Sudderth, 2013), we discover K = 449 clusters for the DP-Grid model, which we use to initialize our HDP model.",5. Experiments,[0],[0]
"We set our annealing schedule for κ to match that used by the public EPLL code.
",5. Experiments,[0],[0]
"Image denoising methods are often divided into two types (Zontak & Irani, 2011): external methods (like
EPLL) that learn all parameters from a training database of clean images, and internal methods that denoise patches using other patches of the single noisy image.",5. Experiments,[0],[0]
"For example, the K-SVD (Elad & Aharon, 2006) has an external variant that uses a dictionary learned from clean images, and an internal variant that learns its dictionary from the noisy image.",5. Experiments,[0],[0]
"A major contribution of our paper is to show that the hierarchical DP leads to a principled hybrid of internal and external methods, in which cues from clean and noisy images are automatically combined in an adaptive way.",5. Experiments,[0],[0]
"We test our algorithm on 12 “classic” images used in many previous denoising papers (Mairal et al., 2009; Zoran & Weiss, 2011), as well as the 68 BSDS test images used by (Roth & Black, 2005; Zoran & Weiss, 2011).",5.1. Image Denoising,[0],[0]
"We evaluate
the denoising performance by the peak signal-to-noise ratio (PSNR), a logarithmic transform of the mean squared error (MSE) between images with normalized intensities,
PSNR , −20 log10 MSE.",5.1. Image Denoising,[0],[0]
"(29) We also evaluate the structural similarity index (SSIM, Wang et al. (2004)), which quantifies image quality degradation via changes in structure, luminance, and contrast.
",5.1. Image Denoising,[0],[0]
Internal vs. external clusters.,5.1. Image Denoising,[0],[0]
"In result figures, we use eDP to refer to our DP-Grid model trained solely on external clean images and HDP to refer to the HDP-Grid model that also learns novel image-specific clusters.",5.1. Image Denoising,[0],[0]
"We also train an internal DP-Grid model, referred to as iDP, using only information from the noisy test image.",5.1. Image Denoising,[0],[0]
"The first four columns of Table 1 compare their average denoising performance, where EPLL can be viewed as a simplification of eDP.",5.1. Image Denoising,[0],[0]
"For all noise levels and datasets, the HDP model has superior performance.",5.1. Image Denoising,[0],[0]
"As shown in Fig. 6, HDP is more accurate than EPLL and eDP for every single classic-12 image.",5.1. Image Denoising,[0],[0]
"Also, the consistent gain in performance from EPLL to eDP demonstrates the benefits of Bayesian nonparametric learning of an appropriate model complexity (for EPLL, the number of clusters was arbitrarily fixed at K = 200).
",5.1. Image Denoising,[0],[0]
"Fig. 3 further illustrates the complementary role of internal
Table 1.",5.1. Image Denoising,[0],[0]
Average PSNR and SSIM values on benchmark datasets (larger values indicate better denoising).,5.1. Image Denoising,[0],[0]
"Methods are highlighted if they are indistinguishable with 95% confidence, according to a Wilcoxon signed-rank test on the fraction of images where one method outperforms another.",5.1. Image Denoising,[0],[0]
"For all noise levels the patch size of BM3D is fixed to 8× 8 and LSSC is fixed to 9× 9.
",5.1. Image Denoising,[0],[0]
metric dataset σ iDP,5.1. Image Denoising,[0],[0]
"EPLL eDP HDP FoE eKSVD iKSVD BM3D LSSC
PSNR
classic-12 10 33.66 33.68 33.77 33.99 33.11 33.45 33.62 33.98 34.05 25 29.02 29.39 29.47 29.68 28.32 28.89 29.11 29.73 29.74 50 25.44 26.22 26.28 26.42 24.69 25.44 25.64 26.55 26.43 BSDS-68 10 33.10 33.37 33.42 33.47 32.69 33.06 33.08 33.26 33.45 25 28.33 28.72 28.76 28.82 27.76 28.28 28.28 28.55 28.70 50 25.10 25.72 25.75 25.83 24.48 25.17 25.17 25.59 25.50
SSIM
classic-12 10 0.9118 0.9136 0.9143 0.9169 0.8962 0.9084 0.9111 0.9168 0.9185 25 0.8189 0.8286 0.8299 0.8337 0.8018 0.8082 0.8131 0.8357 0.8359 50 0.6962 0.7301 0.7316 0.7366 0.6885 0.6926 0.6975 0.7425 0.7390 BSDS-68 10 0.9119 0.9219 0.9224 0.9230 0.8971 0.9128 0.9135 0.9157 0.9206 25 0.7964 0.8090 0.8103 0.8131 0.7804 0.7859 0.7879 0.8010 0.8109 50 0.6636 0.6870 0.6880 0.6962 0.6585 0.6544 0.6539 0.6840 0.6885
1 1.5 2
ELBO/pixel
26
28
30
32
P S
N R
eDP HDP
Figure 6.",5.1. Image Denoising,[0],[0]
Clean-image evidence lower bound (ELBO) versus output PSNR (σ = 25) for 12 “classic” images.,5.1. Image Denoising,[0],[0]
The horizontal axis plots log p(xtest|xtrain),5.1. Image Denoising,[0],[0]
"≈ L(xtest, xtrain)−L(xtrain), divided by the number of pixels.",5.1. Image Denoising,[0],[0]
"Our HDP is uniformly superior to the eDP.
and external clusters for a single test image (“Barbara”).",5.1. Image Denoising,[0],[0]
"The internal iDP perfectly captures some unique textures like the striped clothing, but produces artifacts in smooth background regions.",5.1. Image Denoising,[0],[0]
"The external EPLL and eDP better represent smooth surfaces and contours, which are common in training data, but poorly recover striped textures.
",5.1. Image Denoising,[0],[0]
"As shown in Fig. 5, while the relative accuracy of the eDP and iDP models varies depending on image statistics, the HDP model adaptively combines external and internal clusters for superior performance at all noise levels.",5.1. Image Denoising,[0],[0]
"By capturing the expected self-similarity of image patches, the HDP model also reduces artifacts in large regions with regular textures, such as the smoothly shaded areas of Fig. 4.
",5.1. Image Denoising,[0],[0]
Computational speed.,5.1. Image Denoising,[0],[0]
"To denoise a 512× 512 pixel image on a modern laptop, our Python code for eDP inference with K = 449 clusters takes about 12 min.",5.1. Image Denoising,[0],[0]
"The public EPLL Matlab code (Zoran & Weiss, 2011) with K = 200 clusters takes about 5 min.",5.1. Image Denoising,[0],[0]
"With equal numbers of clusters, the two methods have comparable runtimes.",5.1. Image Denoising,[0],[0]
"Our open-source Python code is available online at
Original FoE
EPLL HDP
Figure 7.",5.1. Image Denoising,[0],[0]
A qualitative comparison of image inpainting algorithms.,5.1. Image Denoising,[0],[0]
"As illustrated in the three close-up views, the HDP exploits patch self-similarity to better recover fine details.
",5.1. Image Denoising,[0],[0]
"github.com/bnpy/hdp-grid-image-restoration.
",5.1. Image Denoising,[0],[0]
Learning image-specific clusters for the HDP model is more expensive: our non-optimized Python denoising code currently requires about 30 min. per image.,5.1. Image Denoising,[0],[0]
Nearly all of the extra time is spent on the k-means++ initialization of Eq.,5.1. Image Denoising,[0],[0]
(28).,5.1. Image Denoising,[0],[0]
"We expect this can be sped up significantly by coding core routines in C, parallelizing some sub-steps (possibly via GPUs), using fewer internal clusters (100 is often too many), or using faster initialization heuristics.
Performance.",5.1. Image Denoising,[0],[0]
We compare our HDP model to other patch-based denoising methods in Table 1.,5.1. Image Denoising,[0],[0]
"On classic-12, where many top methods have been hand-tuned to perform well, our model is statistically indistinguishable from the best baselines.",5.1. Image Denoising,[0],[0]
"On the larger BSDS-68, our performance is superior to the state-of-the-art, showing the value of nonparametric learning from large image collections.",5.1. Image Denoising,[0],[0]
See Fig. 8 for examples.,5.1. Image Denoising,[0],[0]
"At higher noise levels (σ = 50), LSSC has modestly improved performance (0.2 dB in PSNR) when modeling 12× 12 patches (Mairal et al., 2009).",5.1. Image Denoising,[0],[0]
HDP models of larger patches are a promising research area.,5.1. Image Denoising,[0],[0]
"While many image processing systems are designed for just one problem, our generative model is useful for many tasks.",5.2. Image Inpainting,[0],[0]
"For example, we can “inpaint” occluded image regions (like the red pixels in Fig. 7) by modifying Eq. (14) to
let σ2 →∞ for only those regions and setting σ2 = 0 elsewhere.",5.2. Image Inpainting,[0],[0]
"To process color images, we follow the approach of FoE and EPLL and convert to the YCbCr color space before independently inpainting each channel.",5.2. Image Inpainting,[0],[0]
"While ground truth is unavailable for the classic image in Fig. 7, our gridbased HDP produces fewer visual artifacts than baselines.",5.2. Image Inpainting,[0],[0]
"We have developed a coherent Bayesian nonparametric model that, via randomly positioned grids of image patches, provides a novel statistical foundation for the popular EPLL method.",6. Conclusion,[0],[0]
We show that HDP mixture models of visual textures can grow in complexity as additional images are observed and capture the self-similarity of natural images.,6. Conclusion,[0],[0]
"Our HDP-grid image denoising and inpainting algorithms are competitive with the state-of-the-art, and our model is applicable to many other computer vision tasks.",6. Conclusion,[0],[0]
This research supported in part by NSF CAREER Award No. IIS-1349774.,Acknowledgements,[0],[0]
MCH supported in part by Oracle Labs.,Acknowledgements,[0],[0]
We propose a hierarchical generative model that captures the self-similar structure of image regions as well as how this structure is shared across image collections.,abstractText,[0],[0]
"Our model is based on a novel, variational interpretation of the popular expected patch log-likelihood (EPLL) method as a model for randomly positioned grids of image patches.",abstractText,[0],[0]
"While previous EPLL methods modeled image patches with finite Gaussian mixtures, we use nonparametric Dirichlet process (DP) mixtures to create models whose complexity grows as additional images are observed.",abstractText,[0],[0]
An extension based on the hierarchical DP then captures repetitive and self-similar structure via imagespecific variations in cluster frequencies.,abstractText,[0],[0]
We derive a structured variational inference algorithm that adaptively creates new patch clusters to more accurately model novel image textures.,abstractText,[0],[0]
"Our denoising performance on standard benchmarks is superior to EPLL and comparable to the state-ofthe-art, and we provide novel statistical justifications for common image processing heuristics.",abstractText,[0],[0]
We also show accurate image inpainting results.,abstractText,[0],[0]
From Patches to Images: A Nonparametric Generative Model,title,[0],[0]
Nearly all previous work in machine translation has been at the level of words.,1 Introduction,[0],[0]
"Aside from our intu-
∗The majority of this work was completed while the author was visiting New York University.
",1 Introduction,[0],[0]
"itive understanding of word as a basic unit of meaning (Jackendoff, 1992), one reason behind this is that sequences are significantly longer when represented in characters, compounding the problem of data sparsity and modeling long-range dependencies.",1 Introduction,[0],[0]
"This has driven NMT research to be almost exclusively word-level (Bahdanau et al., 2015; Sutskever et al., 2015).
",1 Introduction,[0],[0]
"Despite their remarkable success, word-level NMT models suffer from several major weaknesses.",1 Introduction,[0],[0]
"For one, they are unable to model rare, out-ofvocabulary words, making them limited in translating languages with rich morphology such as Czech, Finnish and Turkish.",1 Introduction,[0],[0]
"If one uses a large vocabulary to combat this (Jean et al., 2015), the complexity of training and decoding grows linearly with respect to the target vocabulary size, leading to a vicious cycle.
",1 Introduction,[0],[0]
"To address this, we present a fully character-level NMT model that maps a character sequence in a source language to a character sequence in a target language.",1 Introduction,[1.0],"['To address this, we present a fully character-level NMT model that maps a character sequence in a source language to a character sequence in a target language.']"
"We show that our model outperforms a baseline with a subword-level encoder on DE-EN and CS-EN, and achieves a comparable result on FI-EN and RU-EN.",1 Introduction,[0],[0]
"A purely character-level NMT model with a basic encoder was proposed as a baseline by Luong and Manning (2016), but training it was prohibitively slow.",1 Introduction,[0],[0]
"We were able to train our model at a reasonable speed by drastically reducing the length of source sentence representation using a stack of convolutional, pooling and highway layers.
",1 Introduction,[0],[0]
One advantage of character-level models is that they are better suited for multilingual translation than their word-level counterparts which require a separate word vocabulary for each language.,1 Introduction,[0],[0]
"We
ar X
iv :1
61 0.
03 01
7v 3
[ cs
.C",1 Introduction,[0],[0]
"L
] 1
3 Ju
n 20
verify this by training a single model to translate four languages (German, Czech, Finnish and Russian) to English.",1 Introduction,[0],[0]
"Our multilingual character-level model outperforms the subword-level baseline by a considerable margin in all four language pairs, strongly indicating that a character-level model is more flexible in assigning its capacity to different language pairs.",1 Introduction,[0],[0]
"Furthermore, we observe that our multilingual character-level translation even exceeds the quality of bilingual translation in three out of four language pairs, both in BLEU score metric and human evaluation.",1 Introduction,[0],[0]
This demonstrates excellent parameter efficiency of character-level translation in a multilingual setting.,1 Introduction,[0],[0]
"We also showcase our model’s ability to handle intra-sentence codeswitching while performing language identification on the fly.
",1 Introduction,[1.000000057148377],['We also showcase our model’s ability to handle intra-sentence codeswitching while performing language identification on the fly.']
The contributions of this work are twofold: we empirically show that (1) we can train character-tocharacter NMT model without any explicit segmentation; and (2) we can share a single character-level encoder across multiple languages to build a multilingual translation system without increasing the model size.,1 Introduction,[1.0],['The contributions of this work are twofold: we empirically show that (1) we can train character-tocharacter NMT model without any explicit segmentation; and (2) we can share a single character-level encoder across multiple languages to build a multilingual translation system without increasing the model size.']
Neural machine translation (NMT) is a recently proposed approach to machine translation that builds a single neural network which takes as an input a source sentence X =,2 Background: Attentional Neural Machine Translation,[0],[0]
"(x1, . . .",2 Background: Attentional Neural Machine Translation,[0],[0]
", xTX ) and generates its translation Y =",2 Background: Attentional Neural Machine Translation,[0],[0]
"(y1, . . .",2 Background: Attentional Neural Machine Translation,[0],[0]
", yTY ), where xt and yt′ are source and target symbols (Bahdanau et al., 2015; Sutskever et al., 2015; Luong et al., 2015; Cho et al., 2014a).",2 Background: Attentional Neural Machine Translation,[0],[0]
"Attentional NMT models have three components: an encoder, a decoder and an attention mechanism.
",2 Background: Attentional Neural Machine Translation,[0],[0]
Encoder,2 Background: Attentional Neural Machine Translation,[0],[0]
"Given a source sentence X , the encoder constructs a continuous representation that summarizes its meaning with a recurrent neural network (RNN).",2 Background: Attentional Neural Machine Translation,[0],[0]
"A bidirectional RNN is often implemented as proposed in (Bahdanau et al., 2015).",2 Background: Attentional Neural Machine Translation,[0],[0]
"A forward encoder reads the input sentence from left to right: −→ h t = −→ fenc ( Ex(xt), −→ h t−1 ) .",2 Background: Attentional Neural Machine Translation,[0],[0]
"Similarly, a backward encoder reads it from right to left: ←− h t = ←− fenc ( Ex(xt), ←− h t+1 ) , where Ex is
the source embedding lookup table, and −→ fenc and←− fenc are recurrent activation functions such as long short-term memory units (LSTMs, (Hochreiter and Schmidhuber, 1997)) or gated recurrent units (GRUs, (Cho et al., 2014b)).",2 Background: Attentional Neural Machine Translation,[0],[0]
"The encoder constructs a set of continuous source sentence representations C by concatenating the forward and backward hidden states at each timestep: C = { h1, . . .",2 Background: Attentional Neural Machine Translation,[0],[0]
",hTX } ,
",2 Background: Attentional Neural Machine Translation,[0],[0]
where ht =,2 Background: Attentional Neural Machine Translation,[0],[0]
"[−→ h t; ←− h t ] .
",2 Background: Attentional Neural Machine Translation,[0],[0]
"Attention First introduced in (Bahdanau et al., 2015), the attention mechanism lets the decoder attend more to different source symbols for each target symbol.",2 Background: Attentional Neural Machine Translation,[0],[0]
"More concretely, it computes the context vector ct′ at each decoding time step t′ as a weighted sum of the source hidden states: ct′ = ∑TX t=1",2 Background: Attentional Neural Machine Translation,[0],[0]
αt′tht.,2 Background: Attentional Neural Machine Translation,[0],[0]
"Similarly to (Chung et al., 2016; Firat et al., 2016a), each attentional weight αt′t represents how relevant the t-th source token xt is to the t′-th target token yt′ , and is computed as:
αt′t = 1 Z exp ( score ( Ey(yt′−1), st′−1,ht ))",2 Background: Attentional Neural Machine Translation,[0],[0]
", (1)
where Z = ∑TX k=1 exp ( score(Ey(yt′−1), st′−1,hk) ) is the normalization constant.",2 Background: Attentional Neural Machine Translation,[0],[0]
score() is a feedforward neural network with a single hidden layer that scores how well the source symbol xt and the target symbol yt′ match.,2 Background: Attentional Neural Machine Translation,[0],[0]
"Ey is the target embedding lookup table and st′ is the target hidden state at time t′.
Decoder Given a source context vector ct′ , the decoder computes its hidden state at time t′ as: st′ = fdec ( Ey(yt′−1), st′−1, ct′ ) .",2 Background: Attentional Neural Machine Translation,[0],[0]
"Then, a parametric function outk() returns the conditional probability of the next target symbol being k:
p(yt′ =k|y<t′ , X) = 1 Z exp ( outk ( Ey(yt′−1), st′ , ct′ ))",2 Background: Attentional Neural Machine Translation,[0],[0]
"(2) where Z is again the normalization constant:
Z = ∑ j exp ( outj(Ey(yt′−1), st′ , ct′) ) .
",2 Background: Attentional Neural Machine Translation,[0],[0]
"Training The entire model can be trained end-toend by minimizing the negative conditional log-
likelihood, which is defined as:
L = − 1 N N∑ n=1 T (n) Y∑ t=1",2 Background: Attentional Neural Machine Translation,[0],[0]
log p(yt = y (n) t |y (n) <,2 Background: Attentional Neural Machine Translation,[0],[0]
"t , X (n)),
where N is the number of sentence pairs, and X(n) and y(n)t are the source sentence and the t-th target symbol in the n-th pair, respectively.",2 Background: Attentional Neural Machine Translation,[0],[0]
The benefits of character-level translation over word-level translation are well known.,3.1 Why Character-Level?,[0],[0]
"Chung et al. (2016) present three main arguments: character level models (1) do not suffer from out-of-vocabulary issues, (2) are able to model different, rare morphological variants of a word, and (3) do not require segmentation.",3.1 Why Character-Level?,[0],[0]
"Particularly, text segmentation is highly non-trivial for many languages and problematic even for English as word tokenizers are either manually designed or trained on a corpus using an objective function that is unrelated to the translation task at hand, which makes the overall system sub-optimal.
",3.1 Why Character-Level?,[0],[0]
Here we present two additional arguments for character-level translation.,3.1 Why Character-Level?,[0],[0]
"First, a character-level translation system can easily be applied to a multilingual translation setting.",3.1 Why Character-Level?,[0],[0]
"Between European languages where the majority of alphabets overlaps, for instance, a character-level model may easily identify morphemes that are shared across different languages.",3.1 Why Character-Level?,[0],[0]
"A word-level model, however, will need a separate word vocabulary for each language, allowing no cross-lingual parameter sharing.
",3.1 Why Character-Level?,[0],[0]
"Also, by not segmenting source sentences into words, we no longer inject our knowledge of words and word boundaries into the system; instead, we encourage the model to discover an internal structure of a sentence by itself and learn how a sequence of symbols can be mapped to a continuous meaning representation.",3.1 Why Character-Level?,[0],[0]
"To address these limitations associated with wordlevel translation, a recent line of research has investigated using sub-word information.
",3.2 Related Work,[0],[0]
"Costa-Jussá and Fonollosa (2016) replaced the word-lookup table with convolutional and highway
layers on top of character embeddings, while still segmenting source sentences into words.",3.2 Related Work,[0],[0]
"Target sentences were also segmented into words, and prediction was made at word-level.
",3.2 Related Work,[0],[0]
"Similarly, Ling et al. (2015) employed a bidirectional LSTM to compose character embeddings into word embeddings.",3.2 Related Work,[0],[0]
"At the target side, another LSTM takes the hidden state of the decoder and generates the target word, character by character.",3.2 Related Work,[0],[0]
"While this system is completely open-vocabulary, it also requires offline segmentation.",3.2 Related Work,[0],[0]
"Also, characterto-word and word-to-character LSTMs significantly slow down training.
",3.2 Related Work,[0],[0]
"Most recently, Luong and Manning (2016) proposed a hybrid scheme that consults character-level information whenever the model encounters an outof-vocabulary word.",3.2 Related Work,[0],[0]
"As a baseline, they also implemented a purely character-level NMT model with 4 layers of unidirectional LSTMs with 512 cells, with attention over each character.",3.2 Related Work,[0],[0]
"Despite being extremely slow (approximately 3 months to train), the character-level model gave comparable performance to the word-level baseline.",3.2 Related Work,[0],[0]
"This shows the possibility of fully character-level translation.
",3.2 Related Work,[0],[0]
Having a word-level decoder restricts the model to only being able to generate previously seen words.,3.2 Related Work,[0],[0]
Sennrich et al. (2015) introduced a subword-level NMT model that is capable of open-vocabulary translation using subword-level segmentation based on the byte pair encoding (BPE) algorithm.,3.2 Related Work,[0],[0]
"Starting from a character vocabulary, the algorithm identifies frequent character n-grams in the training data and iteratively adds them to the vocabulary, ultimately giving a subword vocabulary which consists of words, subwords and characters.",3.2 Related Work,[0],[0]
"Once the segmentation rules have been learned, their model performs subword-to-subword translation (bpe2bpe) in the same way as word-to-word translation.
",3.2 Related Work,[0],[0]
"Perhaps the work that is closest to our end goal is (Chung et al., 2016), which used a subword-level encoder from (Sennrich et al., 2015) and a fully character-level decoder (bpe2char).",3.2 Related Work,[0],[0]
Their results show that character-level decoding performs better than subword-level decoding.,3.2 Related Work,[0],[0]
"Motivated by this work, we aim for fully character-level translation at both sides (char2char).
",3.2 Related Work,[0],[0]
"Outside NMT, our work is based on a few existing approaches that applied convolutional networks
to text, most notably in text classification (Zhang et al., 2015; Xiao and Cho, 2016).",3.2 Related Work,[0],[0]
"Also, we drew inspiration for our multilingual models from previous work that showed the possibility of training a single recurrent model for multiple languages in domains other than translation (Tsvetkov et al., 2016; Gillick et al., 2015).",3.2 Related Work,[0],[0]
"Sentences are on average 6 (DE, CS and RU) to 8 (FI) times longer when represented in characters.",3.3 Challenges,[0],[0]
"This poses three major challenges to achieving fully character-level translation.
",3.3 Challenges,[0],[0]
"(1) Training/decoding latency For the decoder, although the sequence to be generated is much longer, each character-level softmax operation costs considerably less compared to a word- or subwordlevel softmax.",3.3 Challenges,[0],[0]
"Chung et al. (2016) report that character-level decoding is only 14% slower than subword-level decoding.
",3.3 Challenges,[0],[0]
"On the other hand, computational complexity of the attention mechanism grows quadratically with respect to the sentence length, as it needs to attend to every source token for every target token.",3.3 Challenges,[0],[0]
"This makes a naive character-level approach, such as in (Luong and Manning, 2016), computationally prohibitive.",3.3 Challenges,[0.9981334918872933],"['This makes a naive character-level approach, such as in Luong and Manning (2016), computationally prohibitive.']"
"Consequently, reducing the length of the source sequence is key to ensuring reasonable speed in both training and decoding.
",3.3 Challenges,[0],[0]
"(2) Mapping character sequence to continuous representation The arbitrary relationship between the orthography of a word and its meaning is a well-known problem in linguistics (de Saussure, 1916).",3.3 Challenges,[0],[0]
"Building a character-level encoder is arguably a more difficult problem, as the encoder needs to learn a highly non-linear function from a long sequence of character symbols to a meaning representation.
",3.3 Challenges,[0],[0]
(3) Long range dependencies in characters A character-level encoder needs to model dependencies over longer timespans than a word-level encoder does.,3.3 Challenges,[1.0],['(3) Long range dependencies in characters A character-level encoder needs to model dependencies over longer timespans than a word-level encoder does.']
We design an encoder that addresses all the challenges discussed above by using convolutional and pooling layers aggressively to both (1) drastically shorten the input sentence and (2) efficiently capture local regularities.,4.1 Encoder,[0],[0]
"Inspired by the character-level language model from (Kim et al., 2015), our encoder first reduces the source sentence length with a series of convolutional, pooling and highway layers.",4.1 Encoder,[0],[0]
"The shorter representation, instead of the full character sequence, is passed through a bidirectional GRU to (3) help it resolve long term dependencies.",4.1 Encoder,[0],[0]
"We illustrate the proposed encoder in Figure 1 and discuss each layer in detail below.
",4.1 Encoder,[0],[0]
"Embedding We map the sequence of source characters (x1, . . .",4.1 Encoder,[0],[0]
", xTx) to a sequence of character embeddings of dimensionality dc: X = (C(x1), . . .",4.1 Encoder,[0],[0]
",C(xTx)) ∈ Rdc×Tx where Tx is the number of source characters and C is the character embedding lookup table: C ∈ Rdc×|C|.
",4.1 Encoder,[0],[0]
Convolution One-dimensional convolution operation is then used along consecutive character embeddings.,4.1 Encoder,[0],[0]
"Assuming we have a single filter f ∈ Rdc×w of width w, we first apply padding to the beginning and the end of X , such that the padded sentence X ′ ∈ Rdc×(Tx+w−1) is w − 1 symbols longer.",4.1 Encoder,[1.0],"['Assuming we have a single filter f ∈ Rdc×w of width w, we first apply padding to the beginning and the end of X , such that the padded sentence X ′ ∈ Rdc×(Tx+w−1) is w − 1 symbols longer.']"
"We then apply narrow convolution between X ′ and f such that the k-th element of the output Yk is given as:
Yk = (X ′ ∗ f)k = ∑ i,j (X ′[:,k−w+1:k] ⊗ f)ij , (3)
where ⊗ denotes elementwise matrix multiplication and ∗ is the convolution operation.",4.1 Encoder,[0],[0]
"X ′[:,k−w+1:k] is the sliced subset of X ′",4.1 Encoder,[0],[0]
that contains all the rows but only w adjacent columns.,4.1 Encoder,[0],[0]
"The padding scheme employed above, commonly known as half convolution, ensures the length of the output is identical to the input’s: Y ∈ R1×Tx .
",4.1 Encoder,[0],[0]
We just illustrated how a single convolutional filter of fixed width might be applied to a sentence.,4.1 Encoder,[0],[0]
"In order to extract informative character patterns of different lengths, we employ a set of filters of varying widths.",4.1 Encoder,[0],[0]
"More concretely, we use a filter
bank F = {f1, . . .",4.1 Encoder,[0],[0]
", fm} where fi = Rdc×i×ni is a collection of ni filters of width i.",4.1 Encoder,[0],[0]
"Our model uses m = 8, hence extracts character n-grams up to 8 characters long.",4.1 Encoder,[0],[0]
"Outputs from all the filters are stacked upon each other, giving a single representation Y ∈ RN×Tx , where the dimensionality of each column is given by the total number of filters N = ∑m i=1 ni.",4.1 Encoder,[0],[0]
"Finally, rectified linear activation (ReLU) is applied elementwise to this representation.
",4.1 Encoder,[0],[0]
"Max pooling with stride The output from the convolutional layer is first split into segments of width s, and max-pooling over time is applied to each segment with no overlap.",4.1 Encoder,[0],[0]
This procedure selects the most salient features to give a segment embedding.,4.1 Encoder,[0],[0]
Each segment embedding is a summary of meaningful character n-grams occurring in a particular (overlapping) subsequence in the source sentence.,4.1 Encoder,[0],[0]
Note that the rightmost segment (above ‘on’) in Figure 1 may capture ‘son’ (the filter in green) although ‘s’ occurs in the previous segment.,4.1 Encoder,[0],[0]
"In other words, our segments are overlapping as opposed to in word- or subword-level models with hard segmentation.
",4.1 Encoder,[0],[0]
"Segments act as our internal linguistic unit from this layer and above: the attention mechanism, for instance, attends to each source segment instead of source character.",4.1 Encoder,[0],[0]
This shortens the source representation s-fold: Y ′ ∈ RN×(Tx/s).,4.1 Encoder,[0],[0]
"Empirically, we found using smaller s leads to better performance
at increased training time.",4.1 Encoder,[0],[0]
"We chose s = 5 in our experiments as it gives a reasonable balance between the two.
Highway network A sequence of segment embeddings from the max pooling layer is fed into a highway network (Srivastava et al., 2015).",4.1 Encoder,[0],[0]
"Highway networks are shown to significantly improve the quality of a character-level language model when used with convolutional layers (Kim et al., 2015).",4.1 Encoder,[1.0],"['Highway networks are shown to significantly improve the quality of a character-level language model when used with convolutional layers (Kim et al., 2015).']"
"A highway network transforms input x with a gating mechanism that adaptively regulates information flow:
y = g ReLU(W1x+ b1) +",4.1 Encoder,[0],[0]
(1− g),4.1 Encoder,[0],[0]
"x,
where g = σ((W2x + b2)).",4.1 Encoder,[0],[0]
"We apply this to each segment embedding individually.
",4.1 Encoder,[0],[0]
"Recurrent layer Finally, the output from the highway layer is given to a bidirectional GRU from §2, using each segment embedding as input.
",4.1 Encoder,[0],[0]
"Subword-level encoder Unlike a subword-level encoder, our model does not commit to a specific choice of segmentation; it is instead trained to consider every possible character pattern and extract only the most meaningful ones.",4.1 Encoder,[0],[0]
"Therefore, the definition of segmentation in our model is dynamic unlike subword-level encoders.",4.1 Encoder,[0],[0]
"During training, the model finds the most salient character patterns in a sentence via max-pooling, and the character
sequences extracted by the model change over the course of training.",4.1 Encoder,[0],[0]
This is in contrast to how BPE segmentation rules are learned: the segmentation is learned and fixed before training begins.,4.1 Encoder,[0],[0]
"Similarly to the attention model in (Chung et al., 2016; Firat et al., 2016a), a single-layer feedforward network computes the attention score of next target character to be generated with every source segment representation.",4.2 Attention and Decoder,[0],[0]
A standard two-layer character-level decoder then takes the source context vector from the attention mechanism and predicts each target character.,4.2 Attention and Decoder,[0],[0]
This decoder was described as base decoder by Chung et al. (2016).,4.2 Attention and Decoder,[0],[0]
"We evaluate the proposed character-to-character (char2char) translation model against subwordlevel baselines (bpe2bpe and bpe2char) on the WMT’15 DE→EN, CS→EN, FI→EN and RU→EN translation tasks.1 We do not consider word-level models, as it has already been shown that subword-level models outperform them by mitigating issues inherent to closed-vocabulary translation (Sennrich et al., 2015; Sennrich et al., 2016).",5.1 Task and Models,[0],[0]
"Indeed, subword-level NMT models have been the de-facto state-of-the-art and are now used in a very large-scale industry NMT system to serve millions of users per day (Wu et al., 2016).
",5.1 Task and Models,[0],[0]
"1http://www.statmt.org/wmt15/translation -task.html
",5.1 Task and Models,[0],[0]
We experiment in two different scenarios: 1) a bilingual setting where we train a model on data from a single language pair; and 2) a multilingual setting where the task is many-to-one translation: we train a single model on data from all four language pairs.,5.1 Task and Models,[0.9921931255858369],['We experiment in two different scenarios: 1) a bilingual setting where we train a model on data from a single language pair; and 2) a multilingual setting where the task is many-to-one translation.']
"Hence, our baselines and models are:
(a) bilingual bpe2bpe: from (Firat et al., 2016a).",5.1 Task and Models,[0],[0]
"(b) bilingual bpe2char: from (Chung et al., 2016).",5.1 Task and Models,[0],[0]
"(c) bilingual char2char (d) multilingual bpe2char (e) multilingual char2char
We train all the models ourselves other than (a), for which we report the results from (Firat et al., 2016a).",5.1 Task and Models,[0],[0]
We detail the configuration of our models in Table 1 and Table 2.,5.1 Task and Models,[0],[0]
"We use all available parallel data on the four language pairs from WMT’15: DE-EN, CS-EN, FI-EN and RU-EN.
",5.2 Datasets and Preprocessing,[0],[0]
"For the bpe2char baselines, we only use sentence pairs where the source is no longer than 50 subword symbols.",5.2 Datasets and Preprocessing,[0],[0]
"For our char2char models, we only use pairs where the source sentence is no longer than 450 characters.",5.2 Datasets and Preprocessing,[0],[0]
"For all the language pairs apart from FI-EN, we use newstest-2013 as a development set and newstest-2014 and newstest-2015 as test sets.",5.2 Datasets and Preprocessing,[0],[0]
"For FI-EN, we use newsdev-2015 and newstest-2015 as development and test sets respectively.",5.2 Datasets and Preprocessing,[0],[0]
"We tokenize2 each corpus using the script from Moses.3
When training bilingual bpe2char models, we extract 20,000 BPE operations from each of the source and target corpus using a script from (Sennrich et al., 2015).",5.2 Datasets and Preprocessing,[0],[0]
This gives a source BPE vocabulary of size 20k−24k for each language.,5.2 Datasets and Preprocessing,[0],[0]
"Each model is trained using stochastic gradient descent and Adam (Kingma and Ba, 2014) with learning rate 0.0001 and minibatch size 64.",5.3 Training Details,[0],[0]
"Training continues until the BLEU score on the validation set
2This is unnecessary for char2char models, yet was carried out for comparison.
",5.3 Training Details,[0],[0]
"3https://github.com/moses-smt/mosesdecod er
stops improving.",5.3 Training Details,[0],[0]
"The norm of the gradient is clipped with a threshold of 1 (Pascanu et al., 2013).",5.3 Training Details,[0],[0]
All weights are initialized from a uniform distribution,5.3 Training Details,[0],[0]
"[−0.01, 0.01].
",5.3 Training Details,[0],[0]
Each model is trained on a single pre-2016 GTX Titan X GPU with 12GB RAM.,5.3 Training Details,[0],[0]
"As from (Chung et al., 2016), a two-layer unidirectional character-level decoder with 1024 GRU units is used for all our experiments.",5.4 Decoding Details,[0],[0]
"For decoding, we use beam search with length-normalization to penalize shorter hypotheses.",5.4 Decoding Details,[0],[0]
The beam width is 20 for all models.,5.4 Decoding Details,[0],[0]
"Task description We train a model on a many-toone translation task to translate a sentence in any of the four languages (German, Czech, Finnish and Russian) to English.",5.5 Training Multilingual Models,[0],[0]
"We do not provide a language identifier to the encoder, but merely the sentence itself, encouraging the model to perform language identification on the fly.",5.5 Training Multilingual Models,[0],[0]
"In addition, by not providing the language identifier, we expect the model to handle intra-sentence code-switching seamlessly.
",5.5 Training Multilingual Models,[0],[0]
"Model architecture The multilingual char2char model uses slightly more convolutional filters than the bilingual char2char model, namely (200-250- 300-300-400-400-400-400).",5.5 Training Multilingual Models,[0],[0]
"Otherwise, the architecture remains the same as shown in Table 1.",5.5 Training Multilingual Models,[0],[0]
"By not changing the size of the encoder and the decoder, we fix the capacity of the core translation module, and only allow the multilingual model to detect more character patterns.
",5.5 Training Multilingual Models,[0],[0]
"Similarly, the multilingual bpe2char model has the same encoder and decoder as the bilingual bpe2char model, but a larger vocabulary.",5.5 Training Multilingual Models,[0],[0]
"We learn 50,000 multilingual BPE operations on the multilingual corpus, resulting in 54,544 subwords.",5.5 Training Multilingual Models,[0],[0]
"See Table 2 for the exact configuration of our multilingual models.
",5.5 Training Multilingual Models,[0],[0]
"Data scheduling For the multilingual models, an appropriate scheduling of data from different languages is crucial to avoid overfitting to one language too soon.",5.5 Training Multilingual Models,[0],[0]
"Following (Firat et al., 2016a; Firat et al., 2016b), each minibatch is balanced, in that the proportion of each language pair in a single minibatch corresponds to that of the full corpus.",5.5 Training Multilingual Models,[0],[0]
"With this minibatch scheme, roughly the same number of updates is required to make one full pass over the entire training corpus of each language pair.",5.5 Training Multilingual Models,[0],[0]
Minibatches from all language pairs are combined and presented to the model as a single minibatch.,5.5 Training Multilingual Models,[0],[0]
"See Table 3 for the minibatch size for each language pair.
",5.5 Training Multilingual Models,[0],[0]
"Treatment of Cyrillic To facilitate cross-lingual parameter sharing, we convert every Cyrillic character in the Russian source corpus to Latin alphabet according to ISO-9.",5.5 Training Multilingual Models,[0],[0]
"Table 4 shows an example of how this conversion may help the multilingual models identify lexemes that are shared across multiple languages.
",5.5 Training Multilingual Models,[0],[0]
"Multilingual BPE For the multilingual bpe2char model, multilingual BPE segmentation rules are extracted from a large dataset containing training source corpora of all the language pairs.",5.5 Training Multilingual Models,[1.0],"['Multilingual BPE For the multilingual bpe2char model, multilingual BPE segmentation rules are extracted from a large dataset containing training source corpora of all the language pairs.']"
"To ensure the BPE rules are not biased towards one language,
larger datasets such as Czech and German corpora are trimmed such that every corpus contains an approximately equal number of characters.",5.5 Training Multilingual Models,[0.9956708476429155],"['To ensure the BPE rules are not biased towards one language, larger datasets such as Czech and German corpora are trimmed such that every corpus contains, approximately, an equal number of characters.']"
"In this section, we first establish our main hypotheses for introducing character-level and multilingual models, and investigate whether our observations support or disagree with our hypotheses.",6.1 Evaluation with BLEU Score,[0],[0]
"From our empirical results, we want to verify: (1) if fully character-level translation outperforms subwordlevel translation, (2) in which setting and to what extent is multilingual translation beneficial and (3) if multilingual, character-level translation achieves superior performance to other models.",6.1 Evaluation with BLEU Score,[0],[0]
"We outline our results with respect to each hypothesis below.
",6.1 Evaluation with BLEU Score,[0],[0]
(1) Character-,6.1 Evaluation with BLEU Score,[0],[0]
"vs. subword-level In a bilingual setting, the char2char model outperforms both subword-level baselines on DE-EN (Table 5 (a-c)) and CS-EN (Table 5 (f-h)).",6.1 Evaluation with BLEU Score,[0],[0]
"On the other two language pairs, it exceeds the bpe2bpe model and achieves similar performance with the bpe2char baseline (Table 5 (k-m) and (p-r)).",6.1 Evaluation with BLEU Score,[0],[0]
"We conclude that
the proposed character-level model is comparable to or better than both subword-level baselines.
",6.1 Evaluation with BLEU Score,[0],[0]
"Meanwhile, in a multilingual setting, the character-level encoder significantly surpasses the subword-level encoder consistently in all the language pairs (Table 5 (d-e), (i-j), (n-o) and (s-t)).",6.1 Evaluation with BLEU Score,[1.0],"['Meanwhile, in a multilingual setting, the character-level encoder significantly surpasses the subword-level encoder consistently in all the language pairs (Table 5 (d-e), (i-j), (n-o) and (s-t)).']"
"From this, we conclude that translating at the level of characters allows the model to discover shared constructs between languages more effectively.",6.1 Evaluation with BLEU Score,[0],[0]
"This also demonstrates that the character-level model is more flexible in assigning model capacity to different language pairs.
(2) Multilingual vs. bilingual At the level of characters, we note that multilingual translation is indeed strongly beneficial.",6.1 Evaluation with BLEU Score,[0],[0]
"On the test sets, the multilingual character-level model outperforms the singlepair character-level model by 2.64 BLEU in FI-EN (Table 5 (m, o)) and 0.78 BLEU in CS-EN (Table 5 (h, j)), while achieving comparable results on DE-EN and RU-EN.
",6.1 Evaluation with BLEU Score,[0],[0]
"At the level of subwords, on the other hand, we do not observe the same degree of performance benefit from multilingual translation.",6.1 Evaluation with BLEU Score,[0],[0]
"Also, the multilingual bpe2char model requires much more updates to reach the performance of the bilingual
bpe2char model (see Figure 2).",6.1 Evaluation with BLEU Score,[0],[0]
"This suggests that learning useful subword segmentation across languages is difficult.
(3) Multilingual char2char vs. others The multilingual char2char model is the best performer in CS-EN, FI-EN and RU-EN (Table 5 (j, o, t)), and is the runner-up in DE-EN (Table 5 (e)).",6.1 Evaluation with BLEU Score,[0],[0]
"The fact that the multilingual char2char model outperforms the single-pair models goes to show the parameter efficiency of character-level translation: instead of training N separate models for N language pairs, it is possible to get better performance with a single multilingual character-level model.",6.1 Evaluation with BLEU Score,[0],[0]
"It is well known that automatic evaluation metrics such as BLEU encourage reference-like translations and do not fully capture true translation quality (Callison-Burch, 2009; Graham et al., 2015).",6.2 Human Evaluation,[0],[0]
"Therefore, we also carry out a recently proposed evaluation from (Graham et al., 2016) where we have human assessors rate both (1) adequacy and (2) fluency of each system translation on a scale from 0 to 100 via Amazon Mechanical Turk.",6.2 Human Evaluation,[0],[0]
Adequacy is the degree to which assessors agree that the system translation expresses the meaning of the reference translation.,6.2 Human Evaluation,[0],[0]
"Fluency is evaluated using system translation alone without any reference translation.
",6.2 Human Evaluation,[0],[0]
Approximately 1k turkers assessed a single test set (3k sentences in newstest-2014) for each system and language pair.,6.2 Human Evaluation,[0],[0]
"Each turker conducted a minimum of 100 assessments for quality control, and the set of scores generated by each turker was standardized to remove any bias in the individual’s scoring strategy.
",6.2 Human Evaluation,[0],[0]
"We consider three models (bilingual bpe2char, bilingual char2char and multilingual char2char) for the human evaluation.",6.2 Human Evaluation,[0],[0]
"We leave out the multilingual bpe2char model to minimize the number of similar systems to improve the interpretability of the evaluation overall.
",6.2 Human Evaluation,[0],[0]
"For DE-EN, we observe that the multilingual char2char and bilingual char2char models are tied with respect to both adequacy and fluency (Table 6 (b-c)).",6.2 Human Evaluation,[0],[0]
"For CS-EN, the multilingual char2char and bilingual bpe2char models ared tied for adequacy.",6.2 Human Evaluation,[0],[0]
"However, the multilingual char2char model yields significantly better fluency (Table 6 (d, f)).",6.2 Human Evaluation,[0],[0]
"For FI-EN and RU-EN, the multilingual char2char model is tied with the bilingual char2char model with respect to adequacy, but significantly outperforms all other models in fluency (Table 6 (g-i, j-l)).
",6.2 Human Evaluation,[0],[0]
"Overall, the improvement in translation quality yielded by the multilingual character-level model mainly comes from fluency.",6.2 Human Evaluation,[1.0],"['Overall, the improvement in translation quality yielded by the multilingual character-level model mainly comes from fluency.']"
"We conjecture that because the English decoder of the multilingual model is tuned on all the training sentence pairs, it becomes
a better language model than a bilingual model’s decoder.",6.2 Human Evaluation,[0],[0]
We leave it for future work to confirm if this is indeed the case.,6.2 Human Evaluation,[0],[0]
"In Table 7, we demonstrate our character-level model’s robustness in four translation scenarios that conventional NMT systems are known to suffer in.",7 Qualitative Analysis,[0],[0]
"We also showcase our model’s ability to seamlessly handle intra-sentence code-switching, or mixed utterances from two or more languages.",7 Qualitative Analysis,[0],[0]
"We compare
sample translations from the character-level model with those from the subword-level model, which already sidesteps some of the issues associated with word-level translation.
",7 Qualitative Analysis,[0],[0]
"With real-world text containing typos and spelling mistakes, the quality of word-based translation would severely drop, as every non-canonical form of a word cannot be represented.",7 Qualitative Analysis,[0],[0]
"On the other hand, a character-level model has a much better chance recovering the original word or sentence.",7 Qualitative Analysis,[1.0],"['On the other hand, a character-level model has a much better chance recovering the original word or sentence.']"
"Indeed, our char2char model is robust against a few spelling
mistakes (Table 7 (a)).",7 Qualitative Analysis,[0.9999999736641372],"['Indeed, our char2char model is robust against a few spelling mistakes (Table 7 (a)).']"
"Given a long, rare word such as “Siebentausendzweihundertvierundfünfzig” (seven thousand two hundred fifty four) in Table 7 (b), the subword-level model segments “Siebentausend” as (Sieb, ent, aus, end), which results in an inaccurate translation.",7 Qualitative Analysis,[0],[0]
"The character-level model performs better on these long, concatenative words with ambiguous segmentation.
",7 Qualitative Analysis,[0],[0]
"Also, we expect a character-level model to handle novel and unseen morphological inflections well.",7 Qualitative Analysis,[0],[0]
"We observe that this is indeed the case, as our char2char model correctly understands “gesperrt”, a past participle form of “sperren” (to block) (Table 7 (c)).
",7 Qualitative Analysis,[0],[0]
Nonce words are terms coined for a single use.,7 Qualitative Analysis,[0],[0]
"They are not actual words but are constructed in a way that humans can intuitively guess what they mean, such as workoliday and friyay.",7 Qualitative Analysis,[0],[0]
"We construct a few DE-EN sentence pairs that contain German nonce words (one example shown in Table 7 (d)), and observe that the character-level model can indeed detect salient character patterns and arrive at a correct translation.
",7 Qualitative Analysis,[0],[0]
"Finally, we evaluate our multilingual models’ capacity to perform intra-sentence code-switching, by giving them as input mixed sentences from multiple languages.",7 Qualitative Analysis,[0],[0]
"The newstest-2013 development datasets for DE-EN, CS-EN and FI-EN contain intersecting examples with the same English sentences.",7 Qualitative Analysis,[0],[0]
"We compile a list of these sentences in DE/CS/FI and their translation in EN, and choose a few samples uniformly at random from the English side.",7 Qualitative Analysis,[0],[0]
"Words or clauses from different languages are manually intermixed to create multilingual sentences.
",7 Qualitative Analysis,[0],[0]
"We discover that when given sentences with high degree of language intermixing, as in Table 7 (e), the multilingual bpe2char model fails to seamlessly handle alternation of languages.",7 Qualitative Analysis,[0.9952246895144502],"['We discover that when given sentences with a high degree of language intermixing, as in Table 7 (e), the multilingual bpe2char model fails to seamlessly handle alternation of languages.']"
"Overall, however, both multilingual models generate reasonable translations.",7 Qualitative Analysis,[1.0],"['Overall, however, both multilingual models generate reasonable translations.']"
"This is possible because we did not provide a language identifier when training our multilingual models; as a result, they learned to understand a multilingual sentence and translate it into a coherent English sentence.",7 Qualitative Analysis,[0],[0]
"We show supplementary sample translations in each scenario on a webpage.4
4https://sites.google.com/site/dl4mtc2c
Training and decoding speed On a single Titan X GPU, we observe that our char2char models are approximately 35% slower to train than our bpe2char baselines when the same batch size was used.",7 Qualitative Analysis,[0.9991340675914411],"['We show supplementary, sample translations in each scenario on a webpage.4 Training and decoding speed On a single Titan X GPU, we observe that our char2char models are approximately 35% slower to train than our bpe2char baselines when the same batch size was used.']"
"Our bilingual character-level models can be trained in roughly two weeks.
",7 Qualitative Analysis,[0.9999999765109542],['Our bilingual character-level models can be trained in roughly two weeks.']
"We further note that the bilingual bpe2char model can translate 3,000 sentences in 66.63 minutes while the bilingual char2char model requires 71.71 minutes (online, not in batch).",7 Qualitative Analysis,[0],[0]
"See Table 8 for the exact details.
",7 Qualitative Analysis,[0],[0]
Further observations We also note that the multilingual models are less prone to overfitting than the bilingual models.,7 Qualitative Analysis,[0],[0]
This is particularly visible for low-resource language pairs such as FI-EN.,7 Qualitative Analysis,[0],[0]
Figure 2 shows the evolution of the FI-EN validation BLEU scores where the bilingual models overfit rapidly but the multilingual models seem to regularize learning by training simultaneously on other language pairs.,7 Qualitative Analysis,[1.0],['Figure 2 shows the evolution of the FI-EN validation BLEU scores where the bilingual models overfit rapidly but the multilingual models seem to regularize learning by training simultaneously on other language pairs.']
We propose a fully character-level NMT model that accepts a sequence of characters in the source language and outputs a sequence of characters in the target language.,8 Conclusion,[1.0],['We propose a fully character-level NMT model that accepts a sequence of characters in the source language and outputs a sequence of characters in the target language.']
"What is remarkable about this model is the absence of explicitly hard-coded knowledge of words and their boundaries, and that the model learns these concepts from a translation task alone.
",8 Conclusion,[0],[0]
"Our empirical results show that the fully character-level model performs as well as, or better than, subword-level translation models.",8 Conclusion,[1.0],"['Our empirical results show that the fully character-level model performs as well as, or better than, subword-level translation models.']"
"The performance gain is distinctly pronounced in the multilingual many-to-one translation task, where results show that character-level model can assign model capacities to different languages more efficiently than the subword-level models.",8 Conclusion,[0],[0]
"We observe a particularly large improvement in FI-EN translation when the model is trained to translate multiple languages, indicating positive cross-lingual transfer to a lowresource language pair.
",8 Conclusion,[0],[0]
We discover two main benefits of the multilingual character-level model: (1) it is much more parameter efficient than the bilingual models and (2) it can naturally handle intra-sentence code-switching as a result of the many-to-one translation task.,8 Conclusion,[0],[0]
"Ultimately, we present a case for fully character-level translation: that translation at the level of character is strongly beneficial and should be encouraged more.
",8 Conclusion,[1.0000000201698225],"['Ultimately, we present a case for fully character-level translation: that translation at the level of character is strongly beneficial and should be encouraged more.']"
"The repository https://github.com/nyu-dl /dl4mt-c2c contains the source code and pretrained models for reproducing the experimental results.
",8 Conclusion,[1.00000002538384],['The repository https://github.com/nyu-dl /dl4mt-c2c contains the source code and pretrained models for reproducing the experimental results.']
"In the next stage of this research, we will investigate extending our multilingual many-to-one translation models to perform many-to-many translation, which will allow the decoder, similarly with the encoder, to learn from multiple target languages.",8 Conclusion,[0],[0]
"Furthermore, a more thorough investigation into model architectures and hyperparameters is needed.",8 Conclusion,[0],[0]
"KC thanks the support by eBay, Facebook, Google (Google Faculty Award 2016) and NVidia (NVIDIA AI Lab 2016-2019).",Acknowledgements,[0],[0]
"This work was partly supported by Samsung Advanced Institute of Technol-
ogy (Deep Learning).",Acknowledgements,[0],[0]
"JL was supported by Qualcomm Innovation Fellowship, and thanks David Yenicelik and Kevin Wallimann for their contribution in designing the qualitative analysis.",Acknowledgements,[0],[0]
"The authors would like to thank Prof. Zheng Zhang (NYU Shanghai) for fruitful discussion and comments, as well as Yvette Graham for her help with the human evaluation.",Acknowledgements,[0],[0]
"Most existing machine translation systems operate at the level of words, relying on explicit segmentation to extract tokens.",abstractText,[0],[0]
We introduce a neural machine translation (NMT) model that maps a source character sequence to a target character sequence without any segmentation.,abstractText,[0],[0]
"We employ a character-level convolutional network with max-pooling at the encoder to reduce the length of source representation, allowing the model to be trained at a speed comparable to subword-level models while capturing local regularities.",abstractText,[0],[0]
"Our character-to-character model outperforms a recently proposed baseline with a subwordlevel encoder on WMT’15 DE-EN and CSEN, and gives comparable performance on FIEN and RU-EN.",abstractText,[0],[0]
We then demonstrate that it is possible to share a single characterlevel encoder across multiple languages by training a model on a many-to-one translation task.,abstractText,[0],[0]
"In this multilingual setting, the character-level encoder significantly outperforms the subword-level encoder on all the language pairs.",abstractText,[0],[0]
"We observe that on CS-EN, FI-EN and RU-EN, the quality of the multilingual character-level translation even surpasses the models specifically trained on that language pair alone, both in terms of BLEU score and human judgment.",abstractText,[0],[0]
Fully Character-Level Neural Machine Translation without Explicit Segmentation,title,[0],[0]

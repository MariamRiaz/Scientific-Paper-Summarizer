0	9	Closed compounding, i.e., the formation of a oneword unit composing several lexemes, is a common linguistic phenomenon in several languages such as German, Dutch, Greek, and Finnish.
4	18	In extrinsic evaluation setups, compound splitting is applied to the input data of an external natural language processing (NLP) task that benefits from split compounds.
5	8	As closed compounding introduces semantic opaqueness and vastly increases the vocabulary size of a language, many NLP tasks benefit from compound splitters.
8	7	Interestingly, the performance found in intrinsic evaluations does not automatically propagate to performance in downstream evaluations as shown in (Fritzinger and Fraser, 2010) for SMT, where oversplit compounds are simply learned as phrases (Dyer, 2009; Weller et al., 2014).
9	38	Oversplitting is an example of a feature that might not be measured in intrinsic evaluations, because some available gold standards contain positive examples only (Ziering and van der Plas, 2016).
11	17	In this paper we investigate the suitability of Recognizing Textual Entailment (RTE) for the task of compound splitting, inspired by the fact that previous work in RTE underlined the potential benefits of compound splitting for this task (Zeller, 2016).
12	13	Textual Entailment (TE) is a directional relationship between an entailing text fragment T and an entailed hypothesis, H, saying that the meaning of T entails (or implies) the meaning of H. This relation holds if ‘typically, a human, reading T, would infer that H is most likely true’ (Dagan et al., 2006).
13	18	The following is an example of an entailing T-H pair: T: Yoko Ono unveiled a bronze statue of her late husband, John Lennon.
14	19	H: Yoko Ono is John Lennon’s widow.
15	13	58 We opted for exploring the use of RTE as an extrinsic evaluation for compound splitting for three main reasons: first, in contrast to SMT systems, most RTE systems are less complex.
22	15	The approach to RTE taken in this paper follows the Lexical Overlap Hypothesis (LOH), which states that the higher the number of lexical matches between T and H, the more likely the T-H pair is entailing rather than non-entailing (Zeller, 2016).
26	10	As shown in the example below, missing information on the constituents of closed compounds hinders the matching of words from T in H1.
29	26	T: Kinder lieben Fruchtsäfte1 aus Äpfeln2 ‘Children love fruit juices1 made of apples2’ H1: Peters Sohn liebt Apfel3saft4 ‘Peter’s son loves apple3 juice4’ H2: Peters Sohn liebt Apfel5kuchen6stücke7 ‘Peter’s son loves pieces7 of apple5 pie6’
32	25	However, in the present work we test it on the most prominent closed-compounding language, German (Ziering and van der Plas, 2014).
43	18	We use the alignment-based algorithm P1EDA (Noh et al., 2015) in all our experiments as it has been shown to be simple and transparent while yielding relatively good results.
46	9	Finally, these features are given as input to a multinomial logistic regression classifier which is trained on annotated data.
47	14	For the sake of simplicity, for now we only use one basic aligner which aligns (sequences of) words in T and H that consist of identical lemmas.
53	8	We apply a compound splitter on the RTE training and test dataset before we input the data to the EOP pipeline.
58	20	This holds for all compound splitters that we used in our experiments.
59	12	It is also noticeable that the different compound splitters yield different results in the downstream task, with FF2010 being the most beneficial and significantly5 outperforming the initial RTE setup without prior compound splitting (INIT) by up to four percentage points in accuracy and F1-score.
64	48	When we compare these results from the extrinsic evaluation with intrinsic evaluation results (in terms of splitting accuracy) reported in Ziering and van der Plas (2016), we see the same performance ordering with respect to the three compound splitters, while the current extrinsic evaluation on RTE differentiates between the best system (FF2010) and the two others in that only the former reached statistically significant improvements over the INIT baseline.
65	56	To analyze the possible causes of difference in performance between the systems and to see the benefits of using RTE for compound splitting evaluation we performed a manual error analysis.
67	18	Using FF2010, the classifier was able to correctly classify an additional 36 entailing and 25 non-entailing T-H pairs.
70	66	Most of the examples were cases in which there was almost no lexical overlap between T and H even with compound splitting.
72	34	For ZvdP2016, most errors can be attributed to oversplitting.
74	8	For example, ZvdP2016 oversplit the name Landowska into Line Dow Ska6 that appeared in both T and H in an non-entailing pair, which artificially increased the coverage ratio of words in H and therefore pointed to the incorrect entailment classification.
75	19	For WH2012, oversplitting is also a major contributor of RTE errors, however it appeares not as predominant as for ZvdP2016.
78	13	To the contrary, FF2010 did not split Amazonas in T, which lead to a higher token coverage ratio in H. Again, in the H Die EU senkt die Fangquoten ‘The EU lowers the fishing quota’ of another entailing T-H pair, WH2010 correctly split Fang1quoten2 ‘fishing quota’ in H into fangen1 Quote2 but failed to split EU-Quote in T, failing to cover both EU and Quote in H. Our closer inspections also showed that compound splitting does not always suffice to reveal a lexical match between T and H as shown in the following example: T: Ben fährt1 einen Mercedes2 ‘Ben drives1 a Mercedes2’ H: Ben ist Auto3fahrer4 ‘Ben is a car3 driver4’ Given a correct splitting of Autofahrer to Auto Fahrer, a derivational morphology resource (Zeller et al., 2013) would be required to discover the relationship between fahren and Fahrer and a synonym database to find that Mercedes is a hyponym of Auto.
83	22	Given a correct split of Kinder1buch2 into Kind1 Buch2, H1 and H2 have the same token coverage ratio while only H1 is entailed by T. T: Yuki kauft ein Kinder1buch2 ‘Yuki buys a children’s1 book2’ H1: Yuki kauft ein Buch ‘Yuki buys a book’ H2: Yuki ist ein Kind ‘Yuki is a child’ It should be noted that the transparency gain using compound splitting is limited to closed compounds that are compositional with respect to at least one constituent.
85	17	‘mouth throw’)) is counterproductive.

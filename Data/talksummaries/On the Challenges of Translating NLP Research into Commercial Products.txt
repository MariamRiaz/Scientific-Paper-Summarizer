9	7	This paper does not contain any new algorithms, experiments, or results.
10	81	Instead, it seeks to share my experience working at the intersection of academic research and industry with the aim to stimulate a discussion how technology transfer of NLP research can be improved.
11	116	I want to emphasize upfront that the paper is not arguing that all NLP researchers should focus their efforts on building commercial products nor does every new product require a research breakthrough to be successful.
12	81	The paper’s aim is rather to discuss how we can improve useinspired basic research that satisfies both the desire for fundamental understanding and considerations of use, sometimes referred to as Pasteur’s quadrant (Stokes, 1997).
16	9	This section highlights challenges in NLP research that make it difficult to translate the results into impactful innovation.
18	7	That is why many methodologies for creating new products or business models start with a user persona and how to create value for the user (Ries, 2011; Osterwalder et al., 2014).
19	9	Similarly, to conduct research with practical impact, it is worthwhile to consider what potential applications the research could enable 92 and what the value proposition for a potential user might be.
31	6	The author himself has his own experience trying to (unsuccessfully) reproduce published results.
34	17	While the “big data” revolution has given us access to large quantities of text data from some domains, for many industry problems there is no or very limited data available to conduct research on.
41	37	Crawling data from web (or using corpora created by others in this manner) might be acceptable for research purposes, but when building a commercial product the exact license, copyright, etc.
50	61	For practical applications, the test score on a benchmark dataset is only one criteria among many when it comes to choosing an algorithm for practical use.
51	48	Other factors include the time and costs required to implement the method, the computational resources required, speed and performance, the ease of integration, support for multi-lingual input, the ability to adapt and customize the method, the ability to incorporate prior knowledge, and the ability to interpret and explain the model.
52	31	For example, in our text categorization work, we encountered the requirement to accommodate changes in the the output classes, i.e., adding, merging, splitting, and removing classes, without re-training the model from scratch.
54	21	No matter how good an NLP model is, it cannot have practical impact if it is never implemented.
58	41	This makes it harder to adopt statistical models in practical applications (Chiticariu et al., 2013).
70	71	Would it be easier or cheaper to solve the task manually?
77	44	At this stage, we can often already map the problem to a standard NLP task, e.g., text classification, sequence tagging, or sequence-to-sequence learning.
78	10	Next, we establish whether data is available.
80	37	For example for learning to classify customer service tickets, we can start with text classification on public datasets.
81	12	If it is unlikely that data will be available in the foreseeable future, we do not proceed with a use case.
83	12	Is there an intuitive regularity in the data which we believe a statistical model could pick up?
91	11	While this “recipe” for qualifying an NLP use case is simple and common sense, we have found it helpful in prioritizing use cases.
105	46	Second, interactive computational environments, such as Jupyter notebooks4, that tie together data, code, and documentation, allow for reproducible results that can easily be shared and published.
109	34	On the problem of data availability, there is already a considerable amount of work in the area of building NLP models in low-resource environments (see for example (Duong et al., 2014; Garrette and Baldridge, 2013; Wang et al., 2015)) which deals with limited data availability.
111	25	Finally, recent work on learning models from private data (Papernot et al., 2016) and federated learning across many devices (McMahan et al., 2016) appear to be promising directions for practical NLP engineering research.
112	13	I believe that there is an opportunity to increase the exchange between industry and the research community by establishing an industry paper submission format, potentially with its own industry track at NLP conferences.
113	8	Such a track could offer a venue to discuss practical challenges in building large-scale NLP systems and deploying NLP models in production settings, such as scalability, trade-offs between accuracy and computational costs, robustness, data quality, etc.
115	62	Industry tracks are common in other communities and have strong participation from industry players there.
123	76	I have highlighted difficulties that exist for researchers who try to bring NLP research into commercially products and offered suggestions for improving the odds of commercial success.
124	287	I hope that my experience can stimulate creative thought and a healthy discussion in the NLP community.

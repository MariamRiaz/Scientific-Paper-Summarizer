0	34	Shallow semantic representations, and semantic role labels in particular, have a long history in linguistics (Fillmore, 1968).
1	58	More recently, with an emergence of large annotated resources such as PropBank (Palmer et al., 2005) and FrameNet (Baker et al., 1998), automatic semantic role labeling (SRL) has attracted a lot of attention (Gildea and Jurafsky, 2002; Carreras and Màrquez, 2005; Surdeanu et al., 2008; Hajič et al., 2009; Das et al., 2010).
2	65	Semantic role representations encode the underlying predicate-argument structure of sentences, or, more specifically, for every predicate in a sentence they identify a set of arguments and associate each argument with an underlying semantic role, such as an agent (an initiator or doer of the action) or a patient (an affected entity).
5	47	However, such resources are expensive to create and only available for a small number of languages.
7	19	The scarcity of annotated data has motivated the research into unsupervised learning of semantic representations (Swier and Stevenson, 2004; Grenager and Manning, 2006; Lang and Lapata, 2010; Lang and Lapata, 2011a; Lang and Lapata, 2011b; Titov and Klementiev, 2012a; Fürstenau and Rambow, 2012; Garg and Henderson, 2012).
16	79	In this work, we propose a method for effective unsupervised estimation of feature-rich models of semantic roles.
24	26	This confirms the intuition that using richer features helps to capture the syntax-semantics interface in multilingual settings, reducing the need for languagespecific model engineering, as is highly desirable in unsupervised learning.
36	26	Identification, though an important problem, can be tackled with heuristics (Lang and Lapata, 2011a; Grenager and Manning, 2006; de Marneffe et al., 2006), with unsupervised techniques (Abend et al., 2009) or potentially by using a supervised classifier trained on a small amount of data.
39	33	The idea which underlines much of latent variable modeling is that a good latent representation is the one which helps us to reconstruct x.
41	40	Thus, it is crucial to design the model in such a way that the good r (the one predictive of x) indeed encodes roles, rather than some other form of abstraction.
43	20	We will use the following sentence as a motivating example in our discussion of the model: [Agent The police] charged [Patient the demonstrators] [Instrument with batons].
48	28	Intuitively, we can think of predicting one argument at a time (see Figure 1(b)): an argument (e.g., demonstrator in our example) is predicted based on the predicate lemma (charge), the role assigned to this argument (i.e. Patient) and other role-argument pairs ((Agent, police) and (Instrument, baton)).
49	33	While learning to predict arguments, the inference algorithm will search for role assignments which simplify this prediction task as much as possible.
55	33	Crucially, what we referred to above as ‘searching for role assignments to simplify argument prediction’ would actually correspond to learning another component: a semantic role labeler which predicts roles relying on a rich set of sentence features.
65	75	In autoencoders, a latent representation y (their hidden layer) is predicted from x by an encoding model and then this y is used to recover x̃with a reconstruction model (see Figure 1(a)).
70	18	The idea of training linear models by minimizing the reconstruction error was previously explored by Daumé (2009) and very recently by Ammar et al. (2014).
81	28	The product Cv,rua is a k-dimensional vector encoding beliefs about other arguments based on the argument-role pair (a, r).
89	43	In our generalization, we model soft restrictions imposed not only by the role itself but also by other arguments and their assignment to roles.
90	44	In practice, we extend the model slightly: (1) we introduce a word-specific bias (a scalar ba for every a ∈ A) in the argument prediction model (equation (1)); (2) we smooth the model by using a sum of predicate-specific and cross-predicate projection matrices (Cv,r + Cr) instead of just Cv,r.
91	37	Parameters of both model components (w, u and C) are learned jointly: the natural objective associated with every sentence would be the following: N∑ i=1 log ∑ r p(ai|a−i, r, v, C,u)p(r|x,w).
92	47	(3) However optimizing this objective is not practical in its exact form for two reasons: (1) marginalization over r is exponential in the number of arguments; (2) the partition function Z(r, v, i) requires summation over the entire set of potential argument lemmas.
99	21	In our experiments, we used the AdaGrad algorithm (Duchi et al., 2011) to perform the optimization.
109	33	The two small segments (sections 22 and 23) were used for model development.
118	122	As in most previous work on unsupervised SRL, we evaluate our model using purity, collocation and their harmonic mean F1.
119	21	Purity (PU) measures the average number of arguments with the same gold role label in each cluster, collocation (CO) measures to what extent a specific gold role is represented by a single cluster.
122	66	For the semantic role labeling (encoding) component, we relied on 14 feature patterns used for argument labeling in a popular supervised role labeler (Johansson and Nugues, 2008).
124	44	The resulting feature space is quite large (49,474 feature instantiations for our English dataset) and arguably sufficient to accurately capture syntax-semantics interface for most languages.
126	52	Importantly, the dimensionality of the feature space is very different from the one used typically in unsupervised SRL.
133	31	The model was not sensitive to the parameter |R|, defining the number of roles as long it was large enough (see Section 4.3 for more discussion).
147	29	On the contrary, Bayes predicts more than 30 roles for the majority of frequent predicates (e.g., 43 roles for the predicate include or 35 for say).

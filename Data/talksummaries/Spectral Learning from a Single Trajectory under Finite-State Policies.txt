18	53	Regarding tensor methods, (Azizzadenesheli et al., 2016) gave the first analysis under dependent data satisfying certain mixing conditions.
20	62	We provide efficient algorithms with provable guarantees for learning several sequential models from a single trajectory.
21	53	Specifically, we consider three models: probabilistic automata, stochastic weighted automata, and PSRs under control from a finitestate policy.
26	22	case, although they do not provide finitesample guarantees.
40	16	For space reasons, most of our proofs are deferred to the Supplementary Material.
41	40	Let Σ be a finite alphabet, Σ?
62	19	→ R is the infinite matrix Hf ∈ RΣ ?×Σ?
69	39	The pseudo-code of this algorithm is given below: Algorithm 1: Spectral Learning for WFA Input: number of states n, Hankel matrix HU,V Find U ′ such that U = U ′ ∪ (∪σ∈ΣU ′σ) Let H = HU ′,V Compute the rank n SVD H ≈ UDV > Let hV = H{ },V and take α = V >hV Let hU ′ = HU ′,{ } and take β = D−1U>hU ′ foreach σ ∈ Σ do Let Hσ = HU ′σ,V and take Aσ = D−1U>HσV return A = 〈α, β, {Aσ}〉 The main strength of Algorithm 1 is its robustness to noise.
70	47	Specifically, if only an approximation ĤU,V of the Hankel matrix is known, then the error between the target automaton A and the automaton Â learned from ĤU,V can be controlled in terms of the error ‖HU,V − ĤU,V‖2; see (Hsu et al., 2012) for a proof in the HMM case and (Balle, 2013) for a proof in the general WFA case.
75	26	, ξ(N)) containing N finite-length trajectories from ρ, and use them to estimate a Hankel matrix ĤU,VS as follows: ĤU,VS (u, v) = 1 N N∑ i=1 I{ξ(i) ∈ uvΣω} .
77	23	Explicit concentration bounds for Hankel matrices bounding the error ‖HU,VfA − Ĥ U,V S ‖2 can be found in (Denis et al., 2016).
107	11	Let A = 〈α, β, {Aσ}〉 be a PFA computing a function fA : Σ?→R and defining a stochastic process ρA∈P(Σω).
110	44	Instead, we compute Césaro averages over the trajectory ξ to obtain a Hankel matrix whose expectation is related to A as follows.
116	12	Thus, we have just proved the following: Lemma 1 (Consistency) The Césaro average of f over t steps, f̄t, is computed by the probabilistic automaton Āt = 〈ᾱt, β, {Aσ}〉.
121	30	Remark 1 The irreducible condition simply ensures there is a unique stationary distribution, and that the Hankel matrix of Āt has the same rank as the Hankel matrix of A (otherwise it could be smaller).
122	13	Algorithm 2 describes the estimation of the empirical Hankel matrix ĤU,Vt,ξ from the first t+L symbols of a single trajectory using the corresponding Césaro averages.
128	13	In particular, we provide concentration bounds that depend on the length t, the mixing coefficient ηρ of the process ρ, and the structure of the basis (U ,V).
171	14	The proof is concluded by collecting the previous bounds, plugging them into (1), and using Lemma 2 to get E[g(ξ)]2 6 ( ) m t .
179	31	Nonetheless, it follows from these properties that β is an eigenvector of A of eigenvalue 1 exactly like in the case of PFA.
187	29	When A is a PFA one can takeK to be the cone of vectors in Rn with non-negative entries, in which case β = (1, .
209	16	The trajectory is generated by coupling an environment defining a distribution over observations conditioned on actions and a policy defining a distribution over actions conditioned on observations.
210	15	Assuming the joint action-observation distribution can be represented by a stochastic WFA is equivalent to saying that the environment corresponds to a POMDP or PSR, and the policy has finite memory.
215	16	In particular, Aπ represents a stochastic policy that starts in a state s1 ∈ [k] sampled according to απ(i) = P[s1 = i], and at each time step samples an action and changes state according to Πo,a(i, j) = P[st+1 = j, at = a|ot = o, st = i].
220	22	However, since the agent interacting with environment A knows the policy π, we would like to leverage this information to learn directly a model of the environment.
223	12	κ plays a similar role in our analysis as the smoothing parameter introduced in (Denis et al., 2014) for learning Algorithm 3: Single Trajectory Spectral Learning (Reactive Case) Input: number of states n, length t, U ,V⊂(A×O)?, policy π, smoothing coefficient κ Let L = maxw∈U·V |w| Sample trajectory o1a1o2a2 · · · ot+Lat+L using π foreach u ∈ U and v ∈ V do Let Ĥ(u, v) = 1 t ∑t−1 s=0 I{os+1as+1···os+|uv|as+|uv|=uv} κsπ(a1···as+|uv||o1···os+|uv|) Apply the spectral algorithm to Ĥ with rank n stochastic languages from factor estimates in the i.i.d.
234	12	Ultimately, this makes our bound depend not only on the mixing properties of ρB, but also on those of the normalized process ρĀ induced by the SWFA Ā.
241	37	We present the first rigorous analysis of single-trajectory SVD-based spectral learning algorithms for sequential models with latent variables.
242	40	Our analysis highlights the role of mixing properties of WFA and their relation with the geometry of the underlying state space.
243	96	In the controlled case we obtain a result for control with finite-state policies, a much more general class than previously considered memoryless policies.
244	199	In future work we will use our results to get upper confidence bounds on the predictions made by the learned environment with the goal of solving the full RL problem for PSR with complex control policies.

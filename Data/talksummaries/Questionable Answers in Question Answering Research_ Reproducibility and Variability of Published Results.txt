1	44	The efforts of Collberg’s repeatability studies highlight the state of affairs within the computer systems research community (Moraila et al., 2014; Collberg et al., 2015).1 Other fields have also begun to push for more stringent presentation of results, for example, the information retrieval community has been aware for some time of the issues surrounding weak baselines (Armstrong et al., 2009) and more recently reproducibility (Arguello et al., 2016; Lin et al., 2016).
14	17	Along with each of the presented factors we include suggestions on how to respond to these in order to best ensure that the work, as presented, is reproducible.
15	48	Answer selection is one important aspect of opendomain question answering.
16	52	Given a question, q, and a set of candidate sentences, A, the answer selection task is to rank the sentences contained in A such that those candidates that answer the question are ranked at the top of the list.
27	32	Figure 1 shows a diagram of the model, which adopts a “Siamese” structure with two sub-networks to process the question and candidate sentence.
39	63	Table 2 shows the state-of-the-art results in answer selection, as replicated from the ACL Wiki, Table 3 likewise shows the (potentially incomplete) state-ofthe-art results on the WikiQA dataset, sourced by inspection of relevant papers.
49	41	To aid discussion, the state-of-the-art tables have been recreated and annotated with the change in AP and RR over the then state-of-the-art result (Table 2 and Table 3).
52	22	All the data that is required to reproduce the results in this paper is publicly available.
53	26	Including Docker images, scripts to create and use those images, and resulting pretrained model files.4
54	32	There are numerous points of software in which the version of the software being used can impact the end results substantially.
68	16	It shows that newer (0.2.0) is not necessarily better, although this depends on the dataset.
70	121	Version 0.1.8 and earlier would not run the sample model due to use of features introduced in 0.1.9.
71	21	The results are stable for 0.1.x versions across datasets.
73	23	Alternatively, the model code may not be using features of PyTorch that were changing across these versions.
74	20	While fixing the framework version is a good step, these frameworks often themselves rely on other libraries.
84	61	Threading introduces a number of possibilities for non-reproducible results, as results from threads can be returned in differing orders.
89	20	The reason for this is related to the non-associativity of floating point maths.
94	20	We range this from 1–6 on our machine, as this is the number of hardware cores on the CPU, and therefore the maximum number of threads that OpenMP will spawn.
96	23	Interestingly the results are consistent within datasets when using an odd number of threads, although this is most likely coincidental.
108	21	In addition to running the experiment on our own GPU, an Asus branded nVidia GeForce 1080GTX (revision a1) we also repeated the experiment on an Amazon EC2 p2.xlarge instance.
144	17	We suggest that specifying the random seed used in training is the bare minimum, necessary step that should be taken, although given the potential for different pseudo-random generators, and differences in implementation, this may not be enough.
151	51	In this section we briefly examine one of these interactions, namely the seed selection combined with either CPU or GPU training.
158	19	For example, a middling result on the CPU may be transformed to either a top or bottom result if switching to GPU training, with everything else fixed.
159	48	By reporting results as single numbers the variation due to the hardware on which the training is performed is hidden, and this could lead authors to conclude that their model is a substantial improvement on state-of-the-art.
162	17	Statistical significance testing (p ≫ 0.05 in a paired t-test, both two- and single-tailed) bears out this intuition.
167	22	While this difference of 0.0002 is small, there is a newer trend (present in the latter three papers in Table 2) of reporting results to three decimal points.
173	21	These parameters, and their settings, often go unreported in the literature.
176	39	The effects that we presented are not stand-alone effects.
187	18	Finally, beyond the hardware effects, the software that is used to both run the model, and define the model, has an impact.
189	23	These issues are easily avoidable by the use of common packaging tools such as Docker, which also provides opportunities to fix most of the nonversioning environmental issues as well.

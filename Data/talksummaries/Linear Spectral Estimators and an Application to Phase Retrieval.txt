0	31	Phase retrieval refers to the problem of recovering an unknown N -dimensional signal vector x 2 HN , with H being the set of either real (R) or complex (C) numbers, from the following nonlinear measurement process: y = f(Ax+ e z ) + e y .
1	29	(1) Here, the measurement vector y 2 RM contains M realvalued observations, for example measured through the nonlinear function f(z) = |z|2 that operates element-wise on vectors, A 2 HM⇥N is a given measurement matrix, and the vectors ez 2 HM and ey 2 RN model signal and measurement noises, respectively.
2	56	In contrast to the majority of existing results on phase retrieval that assume randomness in the measurement matrix A, we focus on the practical scenario in which the measurement matrix A is deterministic, but the signal vector x to be recovered as well as the two noise sources ez and ey are random.
3	87	Phase retrieval has been studied extensively over the last decades (Gerchberg & Saxton, 1972; Fienup, 1982) and finds use in a range of applications, including imaging (Fogel et al., 2016; Yeh et al., 2015; Holloway et al., 2016), microscopy (Kou et al., 2010; Faulkner & Rodenburg, 2004), and X-ray crystallography (Harrison, 1993; Miao et al., 2008; Pfeiffer et al., 2006).
4	75	Phase retrieval problems were solved traditionally using alternating projection methods, such as the Gerchberg-Saxton (Gerchberg & Saxton, 1972) and Fienup (Fienup, 1982) algorithms.
5	76	More recent results have shown that semidefinite programming enables the design of algorithms with performance guarantees (Candès et al., 2013; Candès & Li, 2014; Candès et al., 2015a; Waldspurger et al., 2015).
6	42	These methods lift the problem to a higher dimension, resulting in excessive complexity and memory requirements.
7	45	To perform phase retrieval for highdimensional problems with performance guarantees, a range of convex (Bahmani & Romberg, 2017; Goldstein & Studer, 2017; Hand & Voroninski, 2016; Dhifallah et al., 2017; Dhifallah & Lu, 2017; Yuan & Wang, 2017; Salehi et al., 2018) and nonconvex methods (Netrapalli et al., 2013; Schniter & Rangan, 2015; Candès et al., 2015b; Chen & Candès, 2015; Zhang & Liang, 2016; Wang et al., 2017a; Zhang et al., 2016; Wei, 2015; Sun et al., 2016; Zeng & So, 2017; Lu & Li, 2017; Ma et al., 2018) have been proposed recently.
13	69	From the matrix D in (2), one then extracts the (scaled) eigenvector ˆx associated with the largest eigenvalue, which serves as an initial estimate of the solution to the phase retrieval problem.
18	65	Gaussian measurement matrices A is impractical—it is more natural to assume that the signal vector x is random and the measurement matrix A is deterministic and structured (Bendory & Eldar, 2017).
20	99	We showcase the efficacy of LSPEs by applying them to phase retrieval problems, where we compute initialization vectors for real- and complex-valued systems with deterministic and finite-dimensional measurement matrices.
21	30	For the proposed LSPEs, we derive nonasymptotic and sharp bounds on the MSE for signal estimation from phaseless measurements.
36	32	One way of combating this issue is to directly recover the outer product xxH instead of x, which is unaffected by phase shifts; this insight is the key underlying lifting-based phase retrieval methods (Candès et al., 2013; Candès & Li, 2014; Candès et al., 2015a; Waldspurger et al., 2015).
49	78	In the second step, we use the spectral estimator matrix D y to extract a (scaled) leading eigenvector as in (3), which is the linear spectral estimate of the signal vector x.
50	21	Intuitively, if we can construct a matrix D y from the preprocessed measurements in T (y) for which the S-MSE in (5) is minimal, then we expect that computing its best rank-1 approximation would yield an accurate estimate of the signal vector x up to a global phase shift.
52	16	Mathematically, we wish to compute a matrix D y of the form (6) that is the solution to the following problem: minimize f Wm2HN⇥N m=0,...,M E 2 4 f W0 + MX m=1 T (ym)fWm xxH 2 F 3 5 .
53	62	(7) Clearly, the spectral estimator matrix D y will depend on the measurement matrix A, the statistics of the signal to be estimated x and the two noise sources ez and ey, the nonlinearity f , as well as the preprocessing function T .
54	42	For this setting, we have the following general result which summarizes the LSPE; the proof is given in Appendix A. Theorem 1 (Linear Spectral Estimator).
55	18	Let the measurement vector y be a result of the general measurement model in (1) and select a preprocessing function T .
59	20	(8) The linear spectral estimate ˆx is then given by the scaled leading eigenvector of the matrix D y in (8).
60	15	The vector t is the only quantity in Theorem 1 that depends on the actual (nonlinear) observations contained in the measurement vector y.
120	136	More concretely, exponential preprocessing as well as Topt(y) enables one to attenuate the effect of measurements with large magnitude, which is also the idea underlying the class of orthogonal spectral initializers, as proposed in (Chen et al., 2015; Wang et al., 2017a;b), that perform well in practice.
121	25	We now compare the performance of our LSPEs against existing spectral initializers proposed for phase retrieval on synthetic and real image data.
125	29	Gaussian measurement matrix with signal dimension N = 16, (ii) an i.i.d.
128	47	Figure 1a shows that the proposed LSPEs significantly outperform all existing spectral initializers for small problem dimensions with Gaussian measurements; this improvement is even more pronounced for large oversampling ratios.
133	52	For structured measurements, as it is the case for the transmission matrix from (Metzler et al., 2017), we see in Figure 1c that LSPEs significantly outperform existing methods that are designed for random measurement ensembles.
150	46	The proposed LSPEs (often significantly) outperform all spectral initializers in terms of visual quality as well as the N-MSE.
157	20	Our simulations with synthetic and real data have shown that LSPEs are able to significantly outperform existing spectral initializers, especially for low-dimensional problems, for structured measurement matrices, or for large oversampling ratios.
169	20	,M , we take the derivatives in WHm and setting them to zero: d dfWHm E " MX m=1 (T (ym) T (ym))fWm (xxH Kx) 2 F # =0.
175	16	We expand this expression into four terms E  PM m=1 tmVm (xxH Kx) 2 F = E  PM m=1 tmVm 2 F (19) + E h xx H K x 2 F i E h tr ⇣ (xx H K x ) H ⇣PM m=1 tmVm ⌘⌘i (20) E  tr ✓⇣PM m=1 tmVm ⌘H (xx H K x ) ◆ (21) and simplify each expression individually.

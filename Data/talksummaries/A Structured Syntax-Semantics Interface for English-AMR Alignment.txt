1	30	An AMR annotation is a directed, usually acyclic graph in which nodes represent entities and events, and edges represent relations between them, as on the right in figure 1.1 AMR annotations include no explicit mapping between elements of an AMR and the corresponding elements of the sentence that evoke them, and this presents a challenge to developers of machine learning systems that parse sentences to AMR or generate sentences from AMR, since they must first infer this mapping in the training data (e.g. Flanigan et al., 2014; Wang et al., 2015; Artzi et al., 2015; Flanigan et al., 2016; Pourdamghani et al., 2016; Misra and Artzi, 2016; Damonte et al., 2017; Peng et al., 2017, inter alia).2 This AMR alignment problem was first formalized by Flanigan et al. (2014), who mapped AMR nodes or connected subgraphs to words or sequences of words under the assumption of a oneto-one mapping—we call this JAMR alignment.
3	83	In ISI alignments, edges often align to syntactic function words: for example, :location aligns to in in figure 1.
4	22	So edge alignments allow ISI to explain more of the AMR structure than JAMR, but in a limited way: only 23% of AMR edges are aligned in the ISI corpus.
10	47	But AMR explicitly avoids theoretical commitment to a syntaxsemantics mapping: Banarescu et al. (2013) state that “AMR is agnostic about how we might want to derive meanings from strings.” If we are going to build such an assumption into our models, we should test it empirically, which we can do by analysing our corpus.
14	22	We make our annotated data and aligner freely available for further research.3
15	98	Our syntactic representation is dependency grammar, which represents the sentence as a rooted, directed graph where nodes are words and edges are grammatical relations between them (Kruijff, 2006).
16	16	We use Universal Dependencies (UD), a cross-lingual dependency annotation scheme, as implemented in Stanford CoreNLP (Manning et al., 2014).
17	69	Within the UD framework, we use enhanced dependencies (Schuster and Manning, 2016), in which dependents can have more than one head, resulting in dependency graphs (DGs).4 Our alignment guidelines generalize ideas present in the existing frameworks.
18	45	We want to allow many-to-many alignments, which we motivate by the observation that some phenomena cause an AMR graph to have one structure expressing the same information as multiple DG structures, and vice versa.
24	13	However, AMR by design abstracts away from syntax and it should not be assumed that all mappings will be so clean.
34	15	Node labels usually reflect their lexically aligned word or its lemma, including derivational morphology (e.g. thirsty ∼ thirst-01).
44	24	Structural alignments hold between two subgraphs, at least one of which is larger than a single node.
87	14	There is no edge between AMR nodes aligned to those words, and the smallest AMR subgraph which contains them also contains and, which is itself lexically aligned.
97	17	The overall inter-annotator F1-score was 88%, with 96% agreement on lexical alignments and 80% on structural alignments.
100	40	Overall, 99.3% of nodes and 97.2% of edges in AMRs are aligned.
101	53	We found that 81.5% of AMR graphs have full coverage, 18.5% have at least one unaligned edge, and 7.5% have one unaligned node (none had more than one; all unaligned nodes express mood or discourse-related information: interrogative, and, and say).
111	18	We define the size of a subgraph as the number of edges it contains.
113	22	The configuration of an alignment is then the pair of sizes for its AMR and DG sides; for example, an alignment with 1 AMR edge and 2 DG edges has configuration 1:2.
114	14	We call an alignment configuration simple if at least one of the subgraphs is a single edge, indicating that there is a single relation which the alignment captures.
115	41	Complex configurations cover multiple relations.
143	14	Structural alignment algorithm.
181	18	Simple algorithms for lexical and structural alignment establish baselines for the new alignment task; we expect statistical models will be brought to bear on this task in future work.
182	25	Our framework also facilitates syntactically-based analysis of AMR parsers.
183	32	We release our data and code for the benefit of the research community.
193	45	For multiword wh-expressions like how much, the expression is aligned structurally (not lexically) to amr-unknown.
194	33	In AMR, non-wh questions are indicated by modeÐÐ→interrogative, imperatives by modeÐÐ→imperative, and exclamations/interjections by modeÐÐ→expressive.
195	23	UD parses do not encode sentence mood, which can be conveyed by noncanonical word order (subject-auxiliary inversion for questions) or argument omission (subject omission for imperatives), rather than the presence of certain relations or words.
197	21	More often the parse has no obvious alignment point, and the constant interrogative, imperative, or expressive is left unaligned.21 A.2 Structural alignments Copulas.
198	16	In UD, copulas are treated as modifiers of a predicate nominal or adjective, which is linked directly to the subject of the sentence via an nsubj dependency.
199	24	We do not align copulas or the cop edge.

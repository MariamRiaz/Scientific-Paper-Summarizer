{"sections": [{"text": "\u221a T .\nIt is well known that minor variants of standard algorithms satisfy first-order regret bounds in the full information and multi-armed bandit settings. In a COLT 2017 open problem (Agarwal et al., 2017), Agarwal, Krishnamurthy, Langford, Luo, and Schapire raised the issue that existing techniques do not seem sufficient to obtain first-order regret bounds for the contextual bandit problem. In the present paper, we resolve this open problem by presenting a new strategy based on augmenting the policy space.1"}, {"heading": "1 Introduction", "text": "The contextual bandit problem is an influential extension of the classical multi-armed bandit. It can be described as follows. Let K be the number of actions, E a set of experts (or \u201cpolicies\u201d), T the time horizon, and denote \u2206K = {x \u2208 [0, 1]K : \u2211K i=1 x(i) = 1}. At each time step t = 1, . . . , T ,\n\u2022 The player receives from each expert e \u2208 E an \u201cadvice\u201d \u03beet \u2208 \u2206K .\n\u2022 Using advices and previous feedbacks, the player selects a probability distribution pt \u2208 \u2206K .\n*Equal contribution 1Microsoft Research AI 2Princeton University. Correspondence to: Zeyuan Allen-Zhu <zeyuan@csail.mit.edu>, Se\u0301bastien Bubeck <sebubeck@microsoft.com>, Yuanzhi Li <yuanzhil@cs.princeton.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\n1The full version of this paper can be found at https:// arxiv.org/abs/1802.03386. The work was done when Yuanzhi Li was a summer intern at Microsoft Research in 2017.\n\u2022 The adversary selects a loss function `t : [K]\u2192 [0, 1]. \u2022 The player plays an action at \u2208 [K] at random from pt\n(and independently of the past).\n\u2022 The player\u2019s suffered loss is `t(at) \u2208 [0, 1], which is also the only feedback the player receives about the loss function `t.\nThe player\u2019s performance at the end of the T rounds is measured through the regret with respect to the best expert:\nRT def = max\ne\u2208E { E [ T\u2211 t=1 `t(at)\u2212 \u3008\u03beet , `t\u3009 ]}\n= max e\u2208E { E [ T\u2211 t=1 \u3008pt \u2212 \u03beet , `t\u3009 ]} . (1.1)\nA landmark result by Auer et al. (2002) is that a regret of order O( \u221a TK log(|E|)) is achievable in this setting. The general intuition captured by regret bounds is that the player\u2019s performance is equal to the best expert\u2019s performance up to a term of lower order. However the aforementioned bound might fail to capture this intuition if T L\u2217T def = mine\u2208E E \u2211T t=1\u3008\u03beet , `t\u3009. It is thus natural to ask whether one could obtain a stronger guarantee where T is essentially replaced by L\u2217T . This question was posed as a COLT 2017 open problem (Agarwal et al., 2017). Such bounds are called first-order regret bounds, and they are known to be possible with full information (Auer et al., 2002), as well as in the multi-armed bandit setting (Allenberg et al., 2006) (see also (Foster et al., 2016) for a different proof) and the semi-bandit framework (Neu, 2015; Lykouris et al., 2017). Our main contribution is a new algorithm for contextual bandit, which we call MYGA (see Section 2), and for which we prove the following first-order regret bound, thus resolving the open problem. Theorem 1.1. For any loss sequence such that mine\u2208E E \u2211T t=1\u3008\u03beet , `t\u3009 \u2264 L\u2217 one has that MYGA\nwith \u03b3 = \u0398(\u03b7) and \u03b7 = \u0398 ( min { 1 K , \u221a log(|E|+T ) KL\u2217 }) satisfies\nRT \u2264 O (\u221a K log(|E|+ T )L\u2217 +K log(|E|+ T ) ) ."}, {"heading": "2 Algorithm Description", "text": "In this section we describe the MYGA algorithm."}, {"heading": "2.1 Truncation", "text": "We introduce a truncation operator T ks that takes as input an index k \u2208 [K] and a threshold s \u2208 [0, 12 ]. Then, treating the first k arms as \u201cmajority arms\u201d and the last K \u2212 k arms as \u201cminority arms,\u201d T ks redistributes \u201cmultiplicatively\u201d the probability mass of all minority arms below threshold s to the majority arms.\nDefinition 2.1. For k \u2208 [K] and s \u2208 (0, 12 ], the truncation operator T ks : \u2206K \u2192 \u2206K is defined as follows. Given any q \u2208 \u2206K , then we set T ks q(i) = 0, i > k and q(i) \u2264 s; q(i), i > k and q(i) > s; q(i) \u00b7 ( 1 + \u2211 j:j>k\u2227 q(j)\u2264s q(j)\u2211\nj\u2264k q(j)\n) , i \u2264 k.\nEquivalently one can define T ks q(i) for the majority arms i \u2264 k with the following implicit formula:\nT ks q(i) = q(i)\u2211 j\u2264k q(j) \u2211 j\u2264k T ks q(j) . (2.1)\nTo see this it suffices to note that the amount of mass in the majority arms is given by\u2211 j\u2264k T ks q(j) = 1\u2212 \u2211 j>k T ks q(j) = 1\u2212 \u2211 j:j>k\u2227 q(j)>s q(j)\n= \u2211 j\u2264k q(j) + \u2211 j:j>k\u2227 q(j)\u2264s q(j) .\nIf K = 2, then T 1s q simply adds q(2) into q(1) if q(2) \u2264 s. For an example with K = 11, see Figure 1."}, {"heading": "2.2 Informal description", "text": "MYGA is parameterized by two parameters: a classical learning rate \u03b7 > 0, and a thresholding parameter \u03b3 \u2208 12T N = { 12T , 2 2T , 3 2T , . . . }. Also let S = (\u03b3, 1/2] \u2229 1 2T N = (\u03b3, 1/2] \u2229 { 12T , 2 2T , 3 2T , . . . } At a high level, a key feature of MYGA is to introduce a set of auxiliary experts, one for each s \u2208 S. More precisely, in each round t, after receiving expert advices {\u03beet }e\u2208E ,\nMYGA calculates a distribution \u03best \u2208 \u2206K for each s \u2208 S. Then, MYGA uses the standard exponential weight updates on E\u2032 = E \u222a S with learning rate \u03b7 > 0, to calculate a weight functionwt \u2208 RE\u222aS+ \u2014see (2.3). Then, it computes \u2022 \u03b6t \u2208 \u2206K , the weighted average of expert advices in E:\n\u03b6t = 1\u2211\ne\u2208E wt(e) \u2211 e\u2208E wt(e) \u00b7 \u03beet .\n\u2022 qt \u2208 \u2206K , the weighted average of expert advices in E\u2032:\nqt = 1\n\u2016wt\u20161 \u2211 e\u2208E\u2032 wt(e) \u00b7 \u03beet .\nUsing these information, MYGA calculates the probability distribution pt \u2208 \u2206K from which the arm is played at round t.\nLet us now explain how pt and \u03best , s \u2208 S are defined. First we remark that in the contextual bandit setting, the arm index has no real meaning since in each round t we can permute the arms by some \u03c0t : [K] \u2192 [K] and permute the expert\u2019s advices and the loss vector by the same \u03c0t. For this reason, throughout this paper, we shall assume\n\u2200t \u2208 [T ] : \u03b6t(1) \u2265 \u03b6t(2) \u2265 \u00b7 \u00b7 \u00b7 \u03b6t(K) . Let us define the \u201cpivot\u201d index kt = min{i \u2208 [K] :\u2211 j\u2264i \u03b6t(j) \u2265 1/2}. Then, in order to perform truncation, MYGA views the first kt arms as \u201cmajority arms\u201d and the last K \u2212 kt arms as \u201cminority arms\u201d of the current round t. At a high level we will have:\n\u2022 the distribution to play from is pt = T kt\u03b3 qt. \u2022 each auxiliary expert s \u2208 S is defined by \u03best = T kts qt.\nWe now give a more precise description in Algorithm 1."}, {"heading": "3 Preliminaries", "text": "Definition 3.1. For analysis purpose, let us define the truncated loss \u00af\u0300t(i) def = `t(i)1{pt(i) > 0}, so that\nEat [ \u3008\u02dc\u0300t, pt\u3009] = \u3008\u00af\u0300t, pt\u3009 = \u3008`t, pt\u3009 .\nWe next derive two lemmas that will prove useful to isolate\nAlgorithm 1 MYGA (Make the minoritY Great Again)\nInput: learning rate \u03b7 > 0, threshold parameter \u03b3 \u2208 12T N 1: S \u2190 (\u03b3, 1/2] \u2229 12T N and w1 \u2190 (1, . . . , 1) \u2208 R E\u222aS\n2: for t = 1 to T do 3: receive advices \u03beet \u2208 \u2206K from each expert e \u2208 E 4: weighted average \u03b6t \u2190 \u2211 e\u2208E wt(e)\u03be e t\u2211\ne\u2208E wt(e) \u2208 \u2206K\n5: assume \u03b6t(1) \u2265 \u03b6t(2) \u2265 \u00b7 \u00b7 \u00b7 \u03b6t(K) wlog. by permuting the arms 6: kt \u2190 min{i \u2208 [K] : \u2211 j\u2264i \u03b6t(j) \u2265 1/2} the first kt arms are majority arms 7: find qt \u2208 \u2206K such that qt can be found in time O(K|S|) = O(KT ), see Lemma 6.1\nqt = 1\u2211 e\u2208E wt(e)+ \u2211 s\u2208S wt(s) (\u2211 e\u2208E wt(e)\u03be e t + \u2211 s\u2208S wt(s)T kts qt ) . (2.2)\n8: \u03best \u2190 T kts qt for every s \u2208 S and pt \u2190 T kt\u03b3 qt 9: draw an arm at \u2208 [K] from probability distribution pt and receive feedback `t(at)\n10: compute loss estimator \u02dc\u0300t \u2208 RK+ as \u02dc\u0300t(i) = `t(i)pt(i)1i=at 11: update the exponential weights for any e \u2208 E \u222a S:\nwt+1(e) = exp ( \u2212 \u03b7 \u2211t r=1\u3008\u03beer , \u02dc\u0300r\u3009) . (2.3)\n12: end for\nthe properties of the truncation operator T ks that are needed to obtain a first-order regret bound. Lemma 3.2. Let \u03b3 \u2208 [0, 1] and assume that for all i \u2208 [K], (1\u2212 cK\u03b3)pt(i) \u2264 qt(i) for some universal constant c > 0, and that pt(i) 6= 0\u21d2 pt(i) \u2265 qt(i). Then one has\n(1\u2212 cK\u03b3)LT \u2212L\u2217T \u2264 log(|E\u2032|) \u03b7 + \u03b7 2 E T\u2211 t=1 \u2016\u00af\u0300t\u201622 . (3.1)\nProof. Using \u3008pt, `t\u3009 = \u3008pt, \u00af\u0300t\u3009, \u3008\u2212\u03beet , `t\u3009 \u2264 \u3008\u2212\u03beet , \u00af\u0300t\u3009, and (1\u2212 cK\u03b3)pt(i) \u2264 qt(i), we have\n(1\u2212 cK\u03b3)LT \u2212 L\u2217T \u2264 max e\u2208E\u2032 E T\u2211 t=1 \u3008(1\u2212 cK\u03b3)pt \u2212 \u03beet , \u00af\u0300t\u3009\n\u2264 max e\u2208E\u2032 E T\u2211 t=1 \u3008qt \u2212 \u03beet , \u00af\u0300t\u3009 .\nThe rest of the proof follows from standard argument to bound the regret of Exp4, see e.g., (Bubeck & CesaBianchi, 2012, Theorem 4.2) (with the minor modification that the assumption on pt implies that \u02dc\u0300t(i) \u2264 `t(i)qt(i)1{i = at}).\nThe next lemma is straightforward. Lemma 3.3. In addition to the assumptions in Lemma 3.2, assume that there exists some numerical constants c\u2032, c\u2032\u2032 \u2265 0 such that\n\u03b3 E T\u2211 t=1 \u2016\u00af\u0300t\u201622 \u2264 2 c\u2032 (\u03b7 + \u03b3) K LT + 2 c\u2032\u2032 log(|E\u2032|) \u03b7 .\n(3.2)\nThen one has( 1\u2212 cK\u03b3 \u2212 ( \u03b7 + \u03b72\n\u03b3\n) c\u2032K) ) (LT \u2212 L\u2217T )\n\u2264 ( 1\n\u03b7 + c\u2032\u2032 \u03b3\n) log(|E\u2032|) + ( cK\u03b3 + ( \u03b7 + \u03b72\n\u03b3\n) c\u2032K ) L\u2217T .\nWe now see that it suffices to show that MYGA satisfies the assumptions of Lemma 3.2 and Lemma 3.3 for \u03b3 ' \u03b7, and \u03b7 ' min { 1 K , \u221a log(|E\u2032|) KL\u2217T } (assume that L\u2217T is\nknown), in which case one obtains a bound of order\u221a K log(|E\u2032|)L\u2217T +K log(|E\u2032|).\nIn fact the assumption of Lemma 3.2 will be easily verified, and the real difficulty will be to prove (3.2). We observe that the standard trick of thresholding the arms with probability below \u03b3 would yield (3.2) with the right hand side replaced by LT , and in turn this leads to a regret of order (L\u2217T ) 2/3. Our goal is to improve over this naive argument.\n4 Proof of the 2-Armed Case The goal of this section is to explain how our MYGA algorithm arises naturally. To focus on the main ideas we restrict to the case K = 2. The complete formal proof of Theorem 1.1 is given in Section 5.\nRecall we have assumed without loss of generality that \u03b6t(1) \u2265 \u03b6t(2) for each round t \u2208 [T ]. This implies kt = 1 because \u03b6t(1) \u2265 12 . In this simple case, for s \u2208 [0, 1/2], we abbreviate our truncation operator T kts as Ts, and it acts as\nfollows. Given q \u2208 \u22062 if q(2) \u2264 s we have Tsq = (1, 0); and if q(2) > s we have Tsq = q.\nIn particular, we have qt(1) \u2265 qt(2) and pt(1) \u2265 pt(2) for all t \u2208 [T ]. We refer to arm 1 as the majority arm and arm 2 as the minority arm. We denote M = E \u2211T t=1 \u00af\u0300 t(1) as\nthe loss of the majority arm and m = E \u2211T t=1 \u00af\u0300 t(2) as the loss of the minority arm. Since `t \u2208 [0, 1]K and K = 2, we have E \u2211T t=1 \u2016\u00af\u0300t\u201622 \u2264 E \u2211T t=1 \u00af\u0300 t(1) + \u00af\u0300t(2) = M +m . (4.1) Observe also that one always has LT \u2265 12M (indeed pt(1) \u2265 qt(1) \u2265 1/2), and thus the whole game to prove (3.2) is to upper bound the minority\u2019s loss m."}, {"heading": "4.1 When the minority suffers small loss", "text": "Assume that m \u2264 (c\u2032 \u2212 1)M for some constant c\u2032 > 0. Then, because M \u2264 2LT , one can directly obtain (3.2) from (4.1) with c\u2032\u2032 = 0. In words, when the minority arm has a total loss comparable to the majority arm, simply playing from \u03b6t would satisfy a first-order regret bound.\nOur main idea is to somehow enforce this relation m .M between the minority and majority losses, by \u201ctruncating\u201d probabilities appropriately. Indeed, recall that if after some truncation we have pt(2) = 0, then it satisfies \u00af\u0300t(2) = 0 so the minority loss m can be improved."}, {"heading": "4.2 Make the minority great again", "text": "Our key new insight is captured by the following lemma which is proved using an integral averaging argument.\nDefinition 4.1. For each s \u2265 \u03b3, let Lst def = E \u2211T t=1\u3008Tsqt, `t\u3009 be the expected loss if the truncated strategy Tsqt \u2208 \u2206K is played at each round. Lemma 4.2. As long as m\u2212M > 0,\n\u2203s \u2208 (\u03b3, 1/2] : m\u2212M \u2264 LT \u2212 L s T\n\u03b3 .\nIn words, ifm is large, then smust be a much better threshold compared to \u03b3, that is LT \u2212 LsT is large.\nProof of Lemma 4.2. For any s \u2265 \u03b3, define the function f(s) def = E \u2211T t=1 1{qt(2) \u2264 s}(\u00af\u0300t(1)\u2212 \u00af\u0300t(2)) . Let us pick s \u2208 [\u03b3, 1/2] to minimize f(s), and breaking ties by choosing the smaller value of s. We make several observations:\n\u2022 f(\u03b3) \u2265 0 because for any t with qt(2) \u2264 \u03b3 we must have \u00af\u0300t(2) = 0.\n\u2022 f(1/2) = M \u2212m < 0. \u2022 s > \u03b3 because f(s) \u2264 f(1/2) < 0.\nLet us define the points s0 def = \u03b3 and\n{s1 < . . . < sm} def = (\u03b3, s] \u2229 {q1(2), . . . , qT (2)}.\nNote that the tie-breaking rule for the choice of s ensures sm = s (if sm < s then it must satisfy f(sm) = f(s) giving a contradiction). Using the identity T\u2211 t=1 \u3008Tsqt \u2212 qt, \u00af\u0300t\u3009 = 1{qt(2) \u2264 s}qt(2)(\u00af\u0300t(1)\u2212 \u00af\u0300t(2)) , (4.2) we calculate that\nLT \u2212 LsT\n= E T\u2211 t=1 \u3008T\u03b3qt \u2212 Tsqt, `t\u3009 = E T\u2211 t=1 \u3008T\u03b3qt \u2212 Tsqt, \u00af\u0300t\u3009\n= E T\u2211 t=1 (1{qt(2) \u2264 \u03b3} \u2212 1{qt(2) \u2264 s})\n\u00d7 qt(2)(\u00af\u0300t(1)\u2212 \u00af\u0300t(2))\n= E T\u2211 t=1 m\u2211 i=1 \u2212si1{qt(2) = si}(\u00af\u0300t(1)\u2212 \u00af\u0300t(2))\n= m\u2211 i=1 si(f(si\u22121)\u2212 f(si))\n= m\u22121\u2211 i=1 (si+1 \u2212 si)f(si) + s1f(s0)\u2212 smf(sm) .\nSince f(s0) \u2265 0, f(si) \u2265 f(s) and s = sm, we conclude that\nLT \u2212 LsT \u2265 (sm \u2212 s1)f(sm)\u2212 smf(sm) = \u2212s1f(sm) \u2265 \u03b3(m\u2212M) .\nGiven Lemma 4.2, a very intuitive strategy start to emerge. Suppose we can somehow get an upper bound of the form\nLT \u2212 LsT \u2264 O ( log(|E\u2032|) \u03b7 + \u03b7(m+M) + \u03b3LT ) . (4.3) Then, putting this into Lemma 4.2 and using M \u2264 2LT , we have for any \u03b3 \u2265 2\u03b7,\n\u03b3m \u2264 O ( log(|E\u2032|) \u03b7 + \u03b3LT ) .\nIn words, the minority arm also suffers from a small loss (and thus is great again!) Putting this into (4.1), we immediately get (3.2) as desired and finish the proof of Theorem 1.1 in the case K = 2.\nThus, we are left with showing (4.3). The main idea is to add the truncated strategy Tsqt as an additional auxiliary expert. If we can achieve this, then (4.3) can be obtained from the regret formula in Lemma 3.2."}, {"heading": "4.3 Expanding the set of experts", "text": "Assume for a moment that we somehow expand the set of experts into E\u2032 \u2283 E so that: \u2200s \u2208 (\u03b3, 1/2],\u2203e \u2208 E\u2032 such that for all t \u2208 [T ], \u03beet = Tsqt . (4.4) Then clearly (4.3) would be satisfied using Lemma 3.2, (4.1) and L\u2217T \u2264 LsT (the loss of an expert should be no\nbetter than the loss of the best expert L\u2217T ).\nThere are two issues with condition (4.4): first, it selfreferential, in the sense that it assumes {\u03beet }e\u2208E\u2032 satisfies a certain form depending on qt while qt is defined via {\u03beet }e\u2208E\u2032 (recall (2.2)); and second, it potentially requires to have an infinite number of experts (one for each s \u2208 (\u03b3, 1/2]). Let us first deal with the second issue via discretization.\nLemma 4.3. In the same setting as Lemma 4.2, there exists s \u2208 S def= (\u03b3, 1/2] \u2229 12T N such that\nm\u2212M \u2264 1 + LT \u2212 L s T\n\u03b3 .\nProof. For x \u2208 R let x be the smallest element in [x,+\u221e) \u2229 12T N. For any s \u2208 S we can rewrite (4.2) as (note that x \u2264 s\u21d4 x \u2264 s) \u3008Tsqt\u2212 qt, \u00af\u0300t\u3009 = 1{qt(2) \u2264 s}qt(2)(\u00af\u0300t(1)\u2212 \u00af\u0300t(2)) + \u03b5t,s , where |\u03b5t,s| \u2264 1/2T . Using the same proof of Lemma 4.2, and redefining\nf(s) def = E \u2211T t=1 1{qt(2) \u2264 s}(\u00af\u0300t(1)\u2212 \u00af\u0300t(2)) .\nwe get that there exists s1, . . . , sm \u2208 S def = (\u03b3, 12 ] \u2229 1 2T N and \u03b5 \u2208 [\u22121, 1] such that\nLT \u2212 LsT = \u03b5+ m\u2211 i=1 si(f(si\u22121)\u2212 f(si)) .\nThe rest of the proof now follows from the same proof of Lemma 4.2, except that we minimize f(s) over s \u2208 S instead of s \u2208 [\u03b3, 12 ].\nThus, instead of (4.4), we only need to require\n\u2200s \u2208 S, \u2203e \u2208 E\u2032 such that for all t \u2208 [T ], \u03beet = Tsqt . (4.5)\nWe now resolve the self-referentiality of (4.5) by defining simultaneously qt and \u03beet , e \u2208 S as follows. Consider the map Ft : [0, 1/2]\u2192 [0, 1/2] defined by:\nFt(x) = 1\u2211 e\u2208E wt(e) + \u2211 s\u2208S wt(s)\n\u00d7 (\u2211 e\u2208E wt(e)\u03be e t (2) + \u2211 s\u2208S wt(s)x1{x > s} ) .\nIt suffices to find a fixed point x = Ft(x): indeed, setting qt def = (1\u2212 x, x) and\n\u03best (2) def = x1{x > s} = Tsqt for s \u2208 S, we have both (4.5) holds and qt = 1\u2016wt\u20161 \u2211 e\u2208E\u2032 wt(e) \u00b7 \u03beet is the correct weighted average of expert advices in E\u2032 = E \u222a S Finally, Ft has a fixed point since it is a nondecreasing function from a closed interval to itself. It is also not hard to find such a point algorithmically.\nThis concludes the (slightly informal) proof forK = 2. We give the complete proof for arbitrary K in the next section."}, {"heading": "5 Proof of Theorem 1.1", "text": "In this section, we assume qt \u2208 \u2206K satisfies (2.2) and we defer the constructive proof of finding qt to Section 6. Recall the arm index has no real meaning so without loss of generality we have permuted the arms so that\n\u03b6t(1) \u2265 \u03b6t(2) \u2264 . . . \u2265 \u03b6t(K) for each t = 1, 2, . . . , T . We refer to {1, 2, . . . , kt} the set of majority arms and {kt+1, . . . ,K} the set of minority arms at round t.2 We let M def = \u2211T t=1 E \u2211 i\u2264kt \u00af\u0300 t(i) and m def = \u2211T t=1 E \u2211 i>kt \u00af\u0300 t(i) respectively be the total loss of the majority and minority arms. We again have\nE \u2211T t=1 \u2016\u00af\u0300t\u201622 \u2264 E \u2211T t=1 \u2211 i\u2208[K] \u00af\u0300 t(i) = M +m . (5.1)\nThus, the whole game to prove (3.2) is to upper bound M and m."}, {"heading": "5.1 Useful properties", "text": "We state a few properties about qt and its truncations.\nLemma 5.1. In each round t = 1, 2, . . . , T , if qt satisfies (2.2), then for every s \u2208 S and i \u2264 kt:\n\u03best (i) = \u03b6t(i)\u2211 j\u2264k \u03b6t(j)\n\u00b7 ( 1\u2212 \u2211 j>k \u03best (j) )\nProof. Let i \u2264 kt and s \u2208 S. By (2.1) and since \u03best = T kts qt one has\n\u03best (i) = qt(i)\u2211 j\u2264k qt(j) \u2211 j\u2264k \u03best (j) .\nMoreover qt is a mixture of \u03b6t and truncated versions of \u03b6t so similarly using (2.1) one has\nqt(i) = \u03b6t(i)\u2211 j\u2264k \u03b6t(j) \u2211 j\u2264k qt(j) .\nPutting the two above displays together concludes the proof.\nLemma 5.2. In each round t = 1, 2, . . . , T , if qt satisfies (2.2), then\n\u2022 for every i > kt it satisfies qt(i) \u2264 \u03b6t(i), and \u2022 for every i \u2264 kt it satisfies qt(i) \u2265 \u03b6t(i) \u2265 12K .\nProof. For sake of notation we drop the index t in this proof. Recall q = \u2211 e\u2208E\u222aS w(e) \u2016w\u20161 \u00b7 \u03be e.\n\u2022 For every minority arm i > k, every s \u2208 S, we have \u03bes(i) = ( T ks q ) (i) \u2264 q(i) according to Definition 2.1.\n2We stress that in the K-arm setting, although kt is the minimum index such that \u03b6t(1) + \u00b7 \u00b7 \u00b7+ \u03b6t(kt) \u2265 12 , it may not be the minimum index so that qt(1) + \u00b7 \u00b7 \u00b7+ qt(kt) \u2265 12 .\nTherefore, we must have q(i) = \u2211 e\u2208E\u222aS w(e) \u2016w\u20161 \u00b7\n\u03bee(i) \u2264 \u2211 e\u2208E w(e)\u03be\ne(i)\u2211 e\u2208E w(e) = \u03b6(i).\n\u2022 For every majority arm i \u2264 k, we have (using Lemma 5.1)\n\u03bee(i) = \u03b6(i)\u2211 j\u2264k \u03b6(j) \u00b7 (1\u2212 \u2211 j>k \u03bes(j))\n\u2265 \u03b6(i)\u2211 j\u2264k \u03b6(j) \u00b7 (1\u2212 \u2211 j>k \u03b6(j)) = \u03b6(i)\nFrom the definition of k = min{i \u2208 [K] : \u2211 j\u2264i \u03b6(j) \u2265 1 2}, we can also conclude \u03b6(i) \u2265 \u03b6(k) \u2265 12K . This is because 1 2 \u2264 \u2211 j>k \u03b6(j) \u2264 K\u03b6(k).\nThe next lemma shows that setting pt = T kt\u03b3 qt satisfies the assumption of Lemma 3.2.\nLemma 5.3. If qt satisfies (2.2), \u03b3 \u2208 (0, 12 ] and pt = T kt\u03b3 qt, then for every arm i \u2208 [K]: (1\u22122K\u03b3)pt(i) \u2264 qt(i) and pt(i) 6= 0\u21d2 pt(i) \u2265 qt(i) .\nProof. For sake of notation we drop the index t in this proof.\nBy Definition 2.1 and Lemma 5.2, we have for every i \u2208 [K]:\np(i) \u2264 q(i) ( 1 + \u2211 j:j>k\u2227 q(j)\u2264\u03b3 q(j)\u2211\nj\u2264k q(j) ) \u2264 q(i) ( 1 +\n\u2211 j:q(j)\u2264\u03b3 q(j)\u2211 j\u2264k \u03b6(j) ) \u2264 q(i)(1 + 2K\u03b3) .\nThe other statement follows because whenever p(i) 6= 0, Definition 2.1 says it must satisfy p(i) \u2265 q(i)."}, {"heading": "5.2 Bounding m and M", "text": "We first upper bound M and then upper bound m.\nLemma 5.4. If qt satisfies (2.2), then M \u2264 2KLT .\nProof. Using Lemma 5.2 we have qt(i) \u2265 12K for any i \u2264 kt. Also, pt(i) \u2265 qt(i) for every i satisfying \u00af\u0300t(i) > 0 (owing to Definition 3.1 and Lemma 5.3). Therefore,\nM = T\u2211 t=1 E \u2211 i\u2264kt \u00af\u0300 t(i) \u2264 2K T\u2211 t=1 E \u2211 i\u2264kt qt(i) \u00b7 \u00af\u0300t(i)\n\u2264 2K T\u2211 t=1 E \u2211 i\u2264kt pt(i) \u00b7 \u00af\u0300t(i) \u2264 2K T\u2211 t=1 E\u3008pt, \u00af\u0300t\u3009\n= 2K T\u2211 t=1 E\u3008pt, `t\u3009 = 2KLT .\nLemma 5.5. Suppose qt satisfies (2.2), and denote by Lst def = E \u2211T t=1\u3008T kts qt, `t\u3009 = E \u2211T t=1\u3008\u03best , `t\u3009 the total\nexpected loss of qt truncated to s. Then, as long as m\u2212 2KLT > 0,\n\u2203s \u2208 (\u03b3, 1/2] \u2229 1 2T N : m\u2212 2KLT \u2264 1 + LT \u2212 LsT \u03b3 .\nProof. The proof is a careful generalization of the proof of Lemma 4.3 (which in turn is just a discretization of the proof of Lemma 4.2). Recall the notation x for the smallest element in [x,+\u221e) \u2229 12T N, and observe that for s \u2208 1 2T N, x \u2264 s\u21d4 x \u2264 s. Denote by\n`majt def = \u2211 i\u2264kt qt(i)\u2211 j\u2264kt qt(j) \u00af\u0300 t(i) .\nthe weighted loss of the majority arms at round t. We have\u2211T t=1 ` maj t \u2264 2LT because \u2211 j\u2264kt qt(j) \u2265 \u2211 j\u2264kt \u03b6t(j) \u2265 1 2 and qt(i) \u2264 pt(i) whenever \u00af\u0300t(i) > 0 (owing to Definition 3.1 and Lemma 5.3).\nNow, for any s \u2265 \u03b3, define the function\nf(s) def = E \u2211T t=1 \u2211 i>kt 1{qt(i) \u2264 s}(`majt \u2212 \u00af\u0300t(i)) .\nLet us pick s \u2208 [\u03b3, 1/2] \u2229 12T N to minimize f(s), and breaking ties by choosing the smaller value of s. We make several observations:\n\u2022 f(\u03b3) \u2265 0 because for any t and i > kt with qt(i) \u2264 \u03b3 we must have pt(i) = (T kt\u03b3 qt)(i) = 0 and thus \u00af\u0300t(i) = 0 by the definition of \u00af\u0300t in Definition 3.1.\n\u2022 f(1/2) = \u2211T t=1(K \u2212 kt)` maj t \u2212m \u2264 2KLT \u2212m < 0.\n\u2022 s > \u03b3 because f(s) \u2264 f(1/2) < 0.\nLet us define the points s0 def = \u03b3 and\n{s1 < . . . < sm} def = (\u03b3, s] \u2229 \u22c3 i\u2208[K] {q1(i), . . . , qT (i)}.\nNote that the tie-breaking rule for the choice of s ensures sm = s (if sm < s then it must satisfy f(sm) = f(s) giving a contradiction).\nObserve that by definition of the truncation operator, one has\n\u3008T kts qt \u2212 qt, \u00af\u0300t\u3009 = \u2211 i>kt 1{qt(i) \u2264 s}qt(i)(`majt \u2212 \u00af\u0300t(i))\nIn fact, after rounding, one can rewrite the above for some \u03b5s,t \u2208 [\u2212 12T , 1 2T ] as\n\u3008T kts qt\u2212qt, \u00af\u0300t\u3009 = \u03b5s,t+ \u2211 i>kt 1{qt(i) \u2264 s}qt(i)(`majt \u2212\u00af\u0300t(i))\nThen, for some \u03b5 \u2208 [\u22121, 1], one has\nLT \u2212 LsT = E T\u2211 t=1 \u3008T kt\u03b3 qt \u2212 T kts qt, `t\u3009\n= E T\u2211 t=1 \u3008T kt\u03b3 qt \u2212 T kts qt, \u00af\u0300t\u3009\n= \u03b5+ E T\u2211 t=1 \u2211 i>kt (1{qt(i) \u2264 \u03b3} \u2212 1{qt(i) \u2264 s})qt(i)(`majt \u2212 \u00af\u0300t(i))\n= \u03b5+ E m\u2211 j=1 T\u2211 t=1 \u2211 i>kt \u2212sj1{qt(i) = sj}(`majt \u2212 \u00af\u0300t(i))\n= \u03b5+ m\u2211 j=1 sj(f(sj\u22121)\u2212 f(sj))\n= \u03b5+ m\u22121\u2211 j=1 (sj+1 \u2212 sj)f(sj) + s1f(s0)\u2212 smf(sm) .\nSince f(s0) = f(\u03b3) \u2265 0, f(si) \u2265 f(s) and s = sm, we conclude that\nLT \u2212 LsT \u2265 \u03b5+ (sm \u2212 s1)f(sm)\u2212 smf(sm) = \u03b5\u2212 s1f(sm) \u2265 \u03b3(m\u2212 2KLT ) ."}, {"heading": "5.3 Putting all together", "text": "Finally, using Lemma 3.2 (which applies thanks to Lemma 5.3), (5.1) and L\u2217T \u2264 LsT (the loss of an expert is no better than the loss of the best expert L\u2217T ), we have\nLT \u2212 LsT \u2264 O ( log(|E\u2032|) \u03b7 + \u03b7(m+M) + \u03b3KLT ) . (5.2) Putting this into Lemma 5.5 and then using M \u2264 2KLT from Lemma 5.4, we have for any \u03b3 \u2265 2\u03b7,\n\u03b3(m+M) \u2264 O ( log(|E\u2032|) \u03b7 + \u03b3KLT ) .\nPutting this into (5.1), we immediately get (3.2) as desired. This finishes the proof of Theorem 1.1. It only remains to ensure that qt verifying (2.2) indeed exists. We provide an algorithm for this in Section 6."}, {"heading": "6 Algorithmic Process to Find qt", "text": "In this section, we answer the question of how to algorithmically find qt satisfying the implicitly definition (2.2). We recall (2.2):\nqt = 1\u2211 e\u2208E wt(e) + \u2211 s\u2208S wt(s)\n\u00d7 (\u2211\ne\u2208E wt(e)\u03be e t + \u2211 s\u2208S wt(s)T kts qt ) . (2.2)\nWe show the following general lemma: Lemma 6.1. Given k \u2208 [K], a finite subset S \u2282 [ 0, 12 ] , \u03b6 \u2208 \u2206K with \u03b6(1) \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03b6(K), and W \u2208 \u22061+|S|, Algorithm 2 finds some q \u2208 \u2206K such that\nq = W (1)\u03b6 + \u2211 s\u2208SW (s)T ks q .\nFurthermore, Algorithm 2 runs in time O(K \u00b7 |S|).\nWe observe that by setting k = kt, \u03b6 = \u03b6t = \u2211 e\u2208E wt(e)\u00b7\u03be e t\u2211\ne\u2208E wt(e) , W (1) =\n\u2211 e\u2208E wt(e)\n\u2016wt\u20161\nand \u2200s \u2208 S : W (s) = wt(s)\u2016wt\u20161 in Lemma 6.1, we immediately obtain a vector q \u2208 \u2206K that we can use as qt.\nIntuition for Lemma 6.1. We only search for q that is monotonically non-increasing for minority arms. This implies T ks q is also non-increasing for minority arms. In symbols: q(k + 1) \u2265 \u00b7 \u00b7 \u00b7 \u2265 q(K) and\n(T ks q)(k + 1) \u2265 \u00b7 \u00b7 \u00b7 \u2265 (T ks q)(K) . Due to such monotonicity, when computing T ks q for each s \u2208 S, there must exist some index \u03c0s \u2208 {k + 1, k + 2, . . . ,K + 1} such that the entry q(i) gets zeroed out for all i \u2265 \u03c0s or in symbols, (T ks q)(i) = 0 for all i \u2265 \u03c0s. Now, the main idea of Algorithm 2 is to search for such non-increasing function \u03c0 : S \u2192 [K+1]. It initializes itself with \u03c0s = k + 1 for all s \u2208 S, and then tries to increase \u03c0 coordinate by coordinate.\nFor each choice of \u03c0, Algorithm 2 computes a candidate distribution q\u03c0 \u2208 \u2206K which satisfies\nq\u03c0 = W (1)\u03b6 + \u2211 s\u2208S W (s)us (6.1)\nwhere each us is q\u03c0 but truncated so that its probabilities after \u03c0s are redistributed to the first k arms, or in symbols,\nus(i) =  0, i \u2265 \u03c0s; q\u03c0(i), \u03c0s > i > k; q\u03c0(i) \u00b7 ( 1 + \u2211 j:j\u2265\u03c0s q\u03c0(j)\u2211 j\u2264k q\u03c0(j) ) , i \u2264 k.\nOne can verify that the distribution q\u03c0 \u2208 \u2206K defined in Line 3 of Algorithm 2 is an explicit solution to (6.1). Unfortunately, each us may not satisfy T ks q\u03c0 = us. In particular, there may exist\nsome s \u2208 S and i > k such that q\u03c0(i) > s but us(i) = 0. This means, we may have truncated too much for expert s in defining us, and we must increase \u03c0s.\nPerhaps not very surprisingly, if each iteration we only increase one \u03c0s by exactly 1, then we never overshoot and there exists a moment when q = q\u03c0 exactly satisfies\nq = W (1)\u03b6 + \u2211 s\u2208SW (s)T ks q .\nWe now give a formal proof of Lemma 6.1."}, {"heading": "6.1 Proof details", "text": "Claim 6.2. We claim some properties about Algorithm 2 (a) The process finishes after at most K \u00b7 |S| iterations. (b) We always have q\u03c0(k + 1) \u2265 \u00b7 \u00b7 \u00b7 \u2265 q\u03c0(K). (c) As \u03c0 changes, for each minority arm i > k, q\u03c0(i) never\ndecreases.\n(d) When the while loop ends, for each i > k and s \u2208 S, we have q\u03c0(i) > s\u21d0\u21d2 \u03c0s > i.\nThe proof of Claim 6.2 can be found in the full version.\nProof of Lemma 6.1. Suppose in the end of Algorithm 2 we obtain q = q\u03c0 for some \u03c0 : S \u2192 [K+1]. Let \u03bes = T ks q\nAlgorithm 2 Input: k \u2208 [K], a finite set S \u2286 [ 0, 12 ] , \u03b6 \u2208 \u2206K with \u03b6(1) \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03b6(K), and W \u2208 \u22061+|S|\nOutput: q \u2208 \u2206K such that q = W (1)\u03b6 + \u2211 s\u2208SW (s)T ks q.\n1: initialize \u03c0 : S \u2192 [K + 1] as \u03c0s = k + 1; will ensure \u03c0s \u2208 {k + 1, k + 2, . . . ,K + 1} 2: while true do\n3: q\u03c0(i)\u2190  W (1) 1\u2212 \u2211 s\u2208S\u2227\u03c0s>iW (s)\n\u00b7 \u03b6(i), if i > k; \u03b6(i)\u2211 j\u2264k \u03b6(j) \u00b7 (1\u2212 \u2211 j>k q\u03c0(j)), if i \u2264 k.\nq\u03c0 \u2208 \u2206K\n4: Pick any s \u2208 S with \u03c0s \u2264 K such that q\u03c0(\u03c0s) > s. 5: if s is not found then break 6: else \u03c0s \u2190 \u03c0s + 1. 7: end while 8: return q\u03c0 .\nfor each s \u2208 S and q\u2032 = W (1)\u03b6 + \u2211 s\u2208SW (s)T ks q. We need to show q = q\u2032. For every minority arm i > k:\nq\u2032(i) \u00ac = W (1) \u00b7 \u03b6(i) + \u2211 s\u2208S W (s) \u00b7 \u03bes(i)\n = W (1) \u00b7 \u03b6(i) + ( \u2211 s\u2208S\u2227q(i)>s W (s) ) \u00b7 q(i)\n\u00ae = W (1) \u00b7 \u03b6(i) + ( \u2211 s\u2208S\u2227\u03c0s>i W (s) ) \u00b7 q(i) \u00af= q(i) .\nAbove, equality \u00ac is by the definition of q\u2032, equality  is by the definition of \u03bes = T ks q, equality \u00ae follows from Claim 6.2.d, and equality \u00af is by definition of q(i) = q\u03c0(i) = W (1) 1\u2212 \u2211 s\u2208S\u2227\u03c0s>iW (s) \u00b7 \u03b6(i). For every majority arm i \u2264 k, q\u2032(i)\n\u03b6(i)\n\u00ac = W (1) \u00b7 \u03b6(i)\u03b6(i) + \u2211 s\u2208SW (s) \u00b7 \u03bes(i) \u03b6(i)\n = W (1) + \u2211 s\u2208SW (s) \u00b7 \u2211 j\u2264k \u03be s(j)\u2211 j\u2264k \u03b6(j)\n(6.2)\nwhere equality \u00ac is by the definition of q\u2032 and equality  is because for every i \u2264 k it satisfies \u03be\ns(i) q(i) =\n\u2211 j\u2264k \u03be\ns(j)\u2211 j\u2264k q(j)\n(using definition of \u03bes = T ks q) and for every i \u2264 k it satisfies \u03b6(i)q(i) = \u2211 j\u2264k \u03b6(j)\u2211 j\u2264k q(j)\n(using definition of q = q\u03c0 Line 3 of Algorithm 2).\nNow, the right hand side of (6.2) is independent of i. Therefore, we can write q\u2032(i) = C1 \u00b7 \u03b6(i) for each i \u2264 k with some constant C1 > 0. Our definition of q = q\u03c0 (see Line 3 of Algorithm 2) ensures that we can also write q(i) = C2 \u00b7 \u03b6(i) for each i \u2264 k with some constant C2 > 0. Therefore, since for every i > k we have already shown q\u2032(i) = q(i), it must satisfy C1 = C2 and therefore q\u2032(i) = q(i) for all i \u2208 [K]. After proving q\u2032 = q, we only need to argue about the running time.\nIf Algorithm 2 is implemented naively, then the total running time is O((K \u00b7 |S|)2) because there are at most K \u00b7 |S|\niterations (see Claim 6.2.a) and in each iteration we can compute q\u03c0 in time O(K \u00b7 |S|). In fact it is rather easy to find implicit update rules to make each iteration of Algorithm 2 run in O(1) time. We give some hints below.\nIndeed, if in an iteration some \u03c0s is changed from i to i+ 1 (recalling i > k), then we can update q\u03c0(i) in O(1) time. For each j > k where j 6= i, we have q\u03c0(j) is unchanged. The values of q\u03c0(j) for j \u2264 k all need to be changed, but they are only changed altogether by the same multiplicative factor (which can again be calculated in O(1) time).\nFinally, to search for s \u2208 S with \u03c0s \u2264 K and q\u03c0(\u03c0s) > s, we do not need to go through all s \u2208 S. Instead, for each i > k, we maintain \u201cthe smallest si \u2208 S so that q\u03c0(i) > si.\u201d Then, whenever \u03c0si \u2264 i, that means we can pick s = si because q\u03c0(\u03c0s) = q\u03c0(\u03c0si) \u2265 q\u03c0(i) > si = s. For such reason, one can maintain a first-in-first-out list to store all values of i where q\u03c0(i) > si. In each iteration of Algorithm 2 we simply pick the first element in list and perform the update. This changes exactly one q\u03c0(j) for j > k, and thus may additionally insert one element to list. Therefore, in each iteration we only needO(1) time to find some \u03c0s to increase."}], "year": 2018, "references": [{"title": "Open problem: First-order regret bounds for contextual bandits", "authors": ["A. Agarwal", "A. Krishnamurthy", "J. Langford", "H. Luo", "R.E. Schapire"], "venue": "Proceedings of the 2017 Conference on Learning Theory,", "year": 2017}, {"title": "Hannan consistency in on-line learning in case of unbounded losses under partial monitoring", "authors": ["C. Allenberg", "P. Auer", "L. Gy\u00f6rfi", "G. Ottucs\u00e1k"], "venue": "In Proceedings of the 17th International Conference on Algorithmic Learning Theory (ALT),", "year": 2006}, {"title": "The non-stochastic multi-armed bandit problem", "authors": ["P. Auer", "N. Cesa-Bianchi", "Y. Freund", "R. Schapire"], "venue": "SIAM Journal on Computing,", "year": 2002}, {"title": "Regret analysis of stochastic and nonstochastic multi-armed bandit problems", "authors": ["S. Bubeck", "N. Cesa-Bianchi"], "venue": "Foundations and Trends in Machine Learning,", "year": 2012}, {"title": "Learning in games: Robustness of fast convergence", "authors": ["D.J. Foster", "Z. Li", "T. Lykouris", "K. Sridharan", "E. Tardos"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "year": 2016}, {"title": "Small-loss bounds for online learning with partial information", "authors": ["T. Lykouris", "K. Sridharan", "E. Tardos"], "venue": "arXiv preprint arXiv:1711.03639,", "year": 2017}, {"title": "First-order regret bounds for combinatorial semibandits", "authors": ["G. Neu"], "venue": "In Proceedings of the 2015 Conference on Learning Theory (COLT),", "year": 2015}], "id": "SP:6077662d29c768ce81353b197ac8c31453b8a297", "authors": [{"name": "Zeyuan Allen-Zhu", "affiliations": []}, {"name": "S\u00e9bastien Bubeck", "affiliations": []}, {"name": "Yuanzhi Li", "affiliations": []}], "abstractText": "Regret bounds in online learning compare the player\u2019s performance to L\u2217, the optimal performance in hindsight with a fixed strategy. Typically such bounds scale with the square root of the time horizon T . The more refined concept of first-order regret bound replaces this with a scaling \u221a L\u2217, which may be much smaller than \u221a T . It is well known that minor variants of standard algorithms satisfy first-order regret bounds in the full information and multi-armed bandit settings. In a COLT 2017 open problem (Agarwal et al., 2017), Agarwal, Krishnamurthy, Langford, Luo, and Schapire raised the issue that existing techniques do not seem sufficient to obtain first-order regret bounds for the contextual bandit problem. In the present paper, we resolve this open problem by presenting a new strategy based on augmenting the policy space.1", "title": "Make the Minority Great Again:  First-Order Regret Bound for Contextual Bandits"}
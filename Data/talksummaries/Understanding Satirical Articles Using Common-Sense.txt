1	21	It is often used in contemporary politics to ridicule individual politicians, political parties or society as a whole.
5	110	With the recent rise of social media outlets, satirical articles have become increasingly popular and have famously fooled several leading news agencies1.
9	65	We look into the satire detection task (Burfoot and Baldwin, 2009), predicting if a given news article is real or satirical, and suggest that this prediction task should be defined over common-sense inferences, rather than looking at it as a lexical text classification task (Pang and Lee, 2008; Burfoot and Baldwin, 2009), which bases the decision on word-level features.
11	33	Both excerpts mention top-ranking politicians (the President and Vice President) in a drug-related context, and contain informal slang utterances, inappropriate for the subjects’ 537 Transactions of the Association for Computational Linguistics, vol.
14	45	The difference between the two examples is apparent when analyzing the situation described in the two articles: The first example (top), describes the Vice President speaking inappropriately in a work setting, clearly an unrealistic situation.
15	42	In the second (bottom) the President is spoken to inappropriately, an unlikely, yet not unrealistic, situation.
62	21	The system makes a prediction by reasoning over the abstract NRG, by decomposing it into paths, where each path captures a partial view of the abstract NRG.
67	32	We formulate these inferences as parameterized rules, mapping elements of the narrative, represented using the NRG, to a classification decision.
84	24	In the future we intend to study approximate inference methods that can help alleviate this computational difficultly, such as using LP-approximation (Martins et al., 2009).
85	30	The Narrative Representation Graph (NRG) is a simple graph-based representation for narrative text, describing the connections between entities and their actions.
104	21	This simple, word-based representation for prediction structured according to the NRG (denoted NARRLEX), generates features by using the words in the original document, corresponding to the graph decomposition.
106	64	Simple features could associate the utterances words with that entity, rather than with the President.
113	24	We define three types of categories corresponding to the three types of vertices, and denote them E,A,Q for Entity category, Action category and Quote category, respectively.
114	23	Each category variable can take k different values.
180	21	We compare the models’ performance when using in-domain data (test and training data are from the same source), and out-ofdomain data, where the test data is collected from a different source.
186	24	Prediction tasks We look into two prediction tasks: (1) Satire Detection (denoted SD), a binary classification task, in which the model has access to the complete article (2) “Did I say that?” (denoted DIST), a binary classification task, consisting only of entities mentions (and their surrounding context in text) and direct quotes.
190	20	We use the data collected by Burfoot and Baldwin (2009) for training the model in both settings, and its test data for in-domain prediction (denoted TRAIN - SD’09, TEST - SD’09, TRAIN - SD’09 - DIST, TEST - SD’09 - DIST, respectively for training and testing in the SD and DIST tasks).
192	34	This collection of articles contains real articles from cnn.com and satirical articles from theonion.com, a well known satirical news website.
209	61	Interestingly, for the satire detection (SD) task, the COMSENSEQ model performs best for the indomain setting, and COMSENSEF gives the best performance in the out-of-domain settings.
231	43	The top part of Figure 5, in red, shows the activation strength of each of the category com- binations when making predictions over the training data.
233	37	We assume that different patterns will be associated with satirical and real articles, and indeed we can see that most entities and quotes appearing in REAL articles fall into a distinctive category pattern, E0, Q0.
236	122	(b) Associating topic words with learned categories In order to understand the entity and quote categories emerging from the training phase, we look at the activation strength of each category pattern with respect to a set of topic words.
237	33	We manually identified a set of entity types and quote topics, which are likely to appear in political articles.
245	31	Note that we only look at the text span corresponding to quote vertices in the NRG.
250	29	But topic words related to drugs also appear in satirical articles portraying politicians using these substances.
251	38	While these are only qualitative results, we believe they provide strong intuitions for future work, especially considering the fact that the activation values do not rely on direct supervision, and only reflect the common-sense patterns emerging from the learned model.
255	36	Our experiments show that in these challenging settings, the performance gap between our approach and the unstructured models increases, demonstrating the effectiveness of our approach.
259	28	As the NLP community considers increasingly challenging tasks focusing on semantic and pragmatic aspects, the importance of finding such common-sense representation will increase.
260	21	In this paper we demonstrated the potential of common-sense representations for one application.
261	38	We hope these results will serve as a starting point for other studies in this direction.

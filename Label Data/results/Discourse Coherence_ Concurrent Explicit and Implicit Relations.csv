0,1,label2,summary_sentences
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1948–1958 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1948",text,[0],[0]
"With the recent surge of interest in deep learning, one question that is being asked across a number of fronts is: can deep learning techniques be harnessed for creative purposes?",1 Introduction,[0],[0]
"Creative applications where such research exists include the composition of music (Humphrey et al., 2013; Sturm et al., 2016; Choi et al., 2016), the design of sculptures (Lehman et al., 2016), and automatic choreography (Crnkovic-Friis and Crnkovic-Friis, 2016).",1 Introduction,[0],[0]
"In this paper, we focus on a creative textual task: automatic poetry composition.
",1 Introduction,[0],[0]
"A distinguishing feature of poetry is its aesthetic forms, e.g. rhyme and rhythm/",1 Introduction,[0],[0]
"meter.1 In this work, we treat the task of poem generation as a constrained language modelling task, such that lines of a given poem rhyme, and each line follows a canonical meter and has a fixed number
1Noting that there are many notable divergences from this in the work of particular poets (e.g. Walt Whitman) and poetry types (such as free verse or haiku).
",1 Introduction,[0],[0]
Shall I compare thee to a summer’s day?,1 Introduction,[0],[0]
"Thou art more lovely and more temperate: Rough winds do shake the darling buds of May, And summer’s lease hath all too short a date:
",1 Introduction,[0],[0]
"Figure 1: 1st quatrain of Shakespeare’s Sonnet 18.
of stresses.",1 Introduction,[0],[0]
"Specifically, we focus on sonnets and generate quatrains in iambic pentameter (e.g. see Figure 1), based on an unsupervised model of language, rhyme and meter trained on a novel corpus of sonnets.
",1 Introduction,[0],[0]
"Our findings are as follows:
• our proposed stress and rhyme models work very well, generating sonnet quatrains with stress and rhyme patterns that are indistinguishable from human-written poems and rated highly by an expert; • a vanilla language model trained over our son-
net corpus, surprisingly, captures meter implicitly at human-level performance; • while crowd workers rate the poems generated
by our best model as nearly indistinguishable from published poems by humans, an expert annotator found the machine-generated poems to lack readability and emotion, and our best model to be only comparable to a vanilla language model on these dimensions; • most work on poetry generation focuses on me-
ter (Greene et al., 2010; Ghazvininejad et al., 2016; Hopkins and Kiela, 2017); our results suggest that future research should look beyond meter and focus on improving readability.
",1 Introduction,[0],[0]
"In this, we develop a new annotation framework for the evaluation of machine-generated poems, and release both a novel data of sonnets and the full source code associated with this research.2
2https://github.com/jhlau/deepspeare",1 Introduction,[0],[0]
"Early poetry generation systems were generally rule-based, and based on rhyming/TTS dictionaries and syllable counting (Gervás, 2000; Wu et al., 2009; Netzer et al., 2009; Colton et al., 2012; Toivanen et al., 2013).",2 Related Work,[0],[0]
"The earliest attempt at using statistical modelling for poetry generation was Greene et al. (2010), based on a language model paired with a stress model.
",2 Related Work,[0],[0]
Neural networks have dominated recent research.,2 Related Work,[0],[0]
"Zhang and Lapata (2014) use a combination of convolutional and recurrent networks for modelling Chinese poetry, which Wang et al. (2016) later simplified by incorporating an attention mechanism and training at the character level.",2 Related Work,[0],[0]
"For English poetry, Ghazvininejad et al. (2016) introduced a finite-state acceptor to explicitly model rhythm in conjunction with a recurrent neural language model for generation.",2 Related Work,[0],[0]
"Hopkins and Kiela (2017) improve rhythm modelling with a cascade of weighted state transducers, and demonstrate the use of character-level language model for English poetry.",2 Related Work,[0],[0]
"A critical difference over our work is that we jointly model both poetry content and forms, and unlike previous work which use dictionaries (Ghazvininejad et al., 2016) or heuristics (Greene et al., 2010) for rhyme, we learn it automatically.",2 Related Work,[0],[0]
"The sonnet is a poem type popularised by Shakespeare, made up of 14 lines structured as 3 quatrains (4 lines) and a couplet (2 lines);3 an example quatrain is presented in Figure 1.",3 Sonnet Structure and Dataset,[0],[0]
"It follows a number of aesthetic forms, of which two are particularly salient: stress and rhyme.
",3 Sonnet Structure and Dataset,[0],[0]
"A sonnet line obeys an alternating stress pattern, called the iambic pentameter, e.g.:
S− S+ S− S+ S− S+ S− S+ S− S+
Shall I compare thee to a summer’s day?",3 Sonnet Structure and Dataset,[0],[0]
"where S− and S+ denote unstressed and stressed syllables, respectively.
",3 Sonnet Structure and Dataset,[0],[0]
"A sonnet also rhymes, with a typical rhyming scheme being ABAB CDCD EFEF GG.",3 Sonnet Structure and Dataset,[0],[0]
"There are a number of variants, however, mostly seen in the quatrains; e.g. AABB or ABBA are also common.
",3 Sonnet Structure and Dataset,[0],[0]
"We build our sonnet dataset from the latest image of Project Gutenberg.4 We first create a
3There are other forms of sonnets, but the Shakespearean sonnet is the dominant one.",3 Sonnet Structure and Dataset,[0],[0]
"Hereinafter “sonnet” is used to specifically mean Shakespearean sonnets.
",3 Sonnet Structure and Dataset,[0],[0]
"4https://www.gutenberg.org/.
(generic) poetry document collection using the GutenTag tool (Brooke et al., 2015), based on its inbuilt poetry classifier and rule-based structural tagging of individual poems.
",3 Sonnet Structure and Dataset,[0],[0]
"Given the poems, we use word and character statistics derived from Shakespeare’s 154 sonnets to filter out all non-sonnet poems (to form the “BACKGROUND” dataset), leaving the sonnet corpus (“SONNET”).5 Based on a small-scale manual analysis of SONNET, we find that the approach is sufficient for extracting sonnets with high precision.",3 Sonnet Structure and Dataset,[0],[0]
"BACKGROUND serves as a large corpus (34M words) for pre-training word embeddings, and SONNET is further partitioned into training, development and testing sets.",3 Sonnet Structure and Dataset,[0],[0]
Statistics of SONNET are given in Table 1.6,3 Sonnet Structure and Dataset,[0],[0]
"We propose modelling both content and forms jointly with a neural architecture, composed of 3 components: (1) a language model; (2) a pentameter model for capturing iambic pentameter; and (3) a rhyme model for learning rhyming words.
",4 Architecture,[0],[0]
"Given a sonnet line, the language model uses standard categorical cross-entropy to predict the next word, and the pentameter model is similarly trained to learn the alternating iambic stress patterns.7 The rhyme model, on the other hand, uses a margin-based loss to separate rhyming word pairs from non-rhyming word pairs in a quatrain.",4 Architecture,[0],[0]
"For generation we use the language model to generate one word at a time, while applying the pentame-
5The following constraints were used to select sonnets: 8.0 6 mean words per line 6 11.5; 40 6 mean characters per line 6 51.0; min/max number of words per line of 6/15; min/max number of characters per line of 32/60; and min letter ratio per line > 0.59.
6The sonnets in our collection are largely in Modern English, with possibly a small number of poetry in Early Modern English.",4 Architecture,[0],[0]
"The potentially mixed-language dialect data might add noise to our system, and given more data it would be worthwhile to include time period as a factor in the model.
",4 Architecture,[0],[0]
"7There are a number of variations in addition to the standard pattern (Greene et al., 2010), but our model uses only the standard pattern as it is the dominant one.
",4 Architecture,[0],[0]
ter model to sample meter-conforming sentences and the rhyme model to enforce rhyme.,4 Architecture,[0],[0]
The architecture of the joint model is illustrated in Figure 2.,4 Architecture,[0],[0]
We train all the components together by treating each component as a sub-task in a multitask learning setting.8,4 Architecture,[0],[0]
"The language model is a variant of an LSTM encoder–decoder model with attention (Bahdanau et al., 2015), where the encoder encodes the preceding context (i.e. all sonnet lines before the current line) and the decoder decodes one word at a time for the current line, while attending to the preceding context.
",4.1 Language Model,[0],[0]
"In the encoder, we embed context words zi using embedding matrix Wwrd to yield wi, and feed them to a biLSTM9 to produce a sequence of encoder hidden states",4.1 Language Model,[0],[0]
hi =,4.1 Language Model,[0],[0]
[~hi; ~hi].,4.1 Language Model,[0],[0]
"Next we apply
8We stress that although the components appear to be disjointed, the shared parameters allow the components to mutually influence each other during joint training.",4.1 Language Model,[0],[0]
"To exemplify this, we found that the pentameter model performs very poorly when we train each component separately.
",4.1 Language Model,[0],[0]
"9We use a single layer for all LSTMs.
",4.1 Language Model,[0],[0]
"a selective mechanism (Zhou et al., 2017) to each hi.",4.1 Language Model,[0],[0]
"By defining the representation of the whole context h = [~hC ; ~h1] (where C is the number of words in the context), the selective mechanism filters the hidden states hi using h as follows:
h′i = hi σ(Wahi",4.1 Language Model,[0],[0]
"+Uah+ ba)
where denotes element-wise product.",4.1 Language Model,[0],[0]
"Hereinafter W, U and b are used to refer to model parameters.",4.1 Language Model,[0],[0]
"The intuition behind this procedure is to selectively filter less useful elements from the context words.
",4.1 Language Model,[0],[0]
"In the decoder, we embed words xt in the current line using the encoder-shared embedding matrix (Wwrd) to produce wt.",4.1 Language Model,[0],[0]
"In addition to the word embeddings, we also embed the characters of a word using embedding matrix Wchr to produce ct,i, and feed them to a bidirectional (character-level) LSTM:
~ut,i = LSTMf (ct,i, ~ut,i−1) ~ut,i = LSTMb(ct,i, ~ut,i+1)
(1)
We represent the character encoding of a word by concatenating the last forward and first back-
ward hidden states ut =",4.1 Language Model,[0],[0]
"[~ut,L; ~ut,1], where L is the length of the word.",4.1 Language Model,[0],[0]
"We incorporate character encodings because they provide orthographic information, improve representations of unknown words, and are shared with the pentameter model (Section 4.2).10 The rationale for sharing the parameters is that we see word stress and language model information as complementary.
",4.1 Language Model,[0],[0]
"Given the word embedding wt and character encoding ut, we concatenate them together and feed them to a unidirectional (word-level) LSTM to produce the decoding states:
st = LSTM([wt;ut], st−1) (2)
We attend st to encoder hidden states h′i and compute the weighted sum of h′i as follows:
eti = v ᵀ b tanh(Wbh ′",4.1 Language Model,[0],[0]
"i +Ubst + bb) at = softmax(et)
h∗t",4.1 Language Model,[0],[0]
= ∑ i atih ′,4.1 Language Model,[0],[0]
"i
To combine st and h∗t , we use a gating unit similar to a GRU (Cho et al., 2014; Chung et al., 2014): s′t = GRU(st,h ∗ t ).",4.1 Language Model,[0],[0]
"We then feed s ′ t to a linear layer with softmax activation to produce the vocabulary distribution (i.e. softmax(Wouts′t + bout), and optimise the model with standard categorical cross-entropy loss.",4.1 Language Model,[0],[0]
"We use dropout as regularisation (Srivastava et al., 2014), and apply it to the encoder/decoder LSTM outputs and word embedding lookup.",4.1 Language Model,[0],[0]
"The same regularisation method is used for the pentameter and rhyme models.
",4.1 Language Model,[0],[0]
"As our sonnet data is relatively small for training a neural language model (367K words; see Table 1), we pre-train word embeddings and reduce parameters further by introducing weight-sharing between output matrix Wout and embedding matrix Wwrd via a projection matrix",4.1 Language Model,[0],[0]
"Wprj (Inan et al., 2016; Paulus et al., 2017; Press and Wolf, 2017):
Wout = tanh(WwrdWprj)",4.1 Language Model,[0],[0]
This component is designed to capture the alternating iambic stress pattern.,4.2 Pentameter Model,[0],[0]
"Given a sonnet line,
10We initially shared the character encodings with the rhyme model as well, but found sub-par performance for the rhyme model.",4.2 Pentameter Model,[0],[0]
"This is perhaps unsurprising, as rhyme and stress are qualitatively very different aspects of forms.
",4.2 Pentameter Model,[0],[0]
"the pentameter model learns to attend to the appropriate characters to predict the 10 binary stress symbols sequentially.11 As punctuation is not pronounced, we preprocess each sonnet line to remove all punctuation, leaving only spaces and letters.",4.2 Pentameter Model,[0],[0]
"Like the language model, the pentameter model is fashioned as an encoder–decoder network.
",4.2 Pentameter Model,[0],[0]
"In the encoder, we embed the characters using the shared embedding matrix Wchr and feed them to the shared bidirectional character-level LSTM (Equation (1)) to produce the character encodings for the sentence: uj = [~uj ; ~uj ].
",4.2 Pentameter Model,[0],[0]
"In the decoder, it attends to the characters to predict the stresses sequentially with an LSTM:
gt = LSTM(u∗t−1,gt−1)
where u∗t−1 is the weighted sum of character encodings from the previous time step, produced by an attention network which we describe next,12 and gt is fed to a linear layer with softmax activation to compute the stress distribution.
",4.2 Pentameter Model,[0],[0]
"The attention network is designed to focus on stress-producing characters, whose positions are monotonically increasing (as stress is predicted sequentially).",4.2 Pentameter Model,[0],[0]
"We first compute µt, the mean position of focus:
µ′t = σ(v ᵀ c tanh(Wcgt +Ucµt−1 + bc)) µt =M ×min(µ′t + µt−1, 1.0)
where M is the number of characters in the sonnet line.",4.2 Pentameter Model,[0],[0]
"Given µt, we can compute the (unnormalised) probability for each character position:
ptj = exp",4.2 Pentameter Model,[0],[0]
"( −(j − µt)2
2T 2 ) where standard deviation T is a hyper-parameter.",4.2 Pentameter Model,[0],[0]
"We incorporate this position information when computing u∗t : 13
u′j = p t juj",4.2 Pentameter Model,[0],[0]
dtj = v ᵀ d tanh(Wdu ′,4.2 Pentameter Model,[0],[0]
j,4.2 Pentameter Model,[0],[0]
"+Udgt + bd)
f t = softmax(dt + logpt) u∗t = ∑ j btjuj
11That is, given the input line Shall I compare thee to a summer’s day?",4.2 Pentameter Model,[0],[0]
the model is required to output S− S+ S− S+ S− S+ S− S+,4.2 Pentameter Model,[0],[0]
"S− S+, based on the syllable boundaries from Section 3.
",4.2 Pentameter Model,[0],[0]
"12Initial input (u∗0) and state (g0) is a trainable vector and zero vector respectively.
",4.2 Pentameter Model,[0],[0]
"13Spaces are masked out, so they always yield zero attention weights.
",4.2 Pentameter Model,[0],[0]
"Intuitively, the attention network incorporates the position information at two points, when computing: (1) dtj by weighting the character encodings; and (2) f t by adding the position log probabilities.",4.2 Pentameter Model,[0],[0]
"This may appear excessive, but preliminary experiments found that this formulation produces the best performance.
",4.2 Pentameter Model,[0],[0]
"In a typical encoder–decoder model, the attended encoder vector u∗t would be combined with the decoder state gt to compute the output probability distribution.",4.2 Pentameter Model,[0],[0]
"Doing so, however, would result in a zero-loss model as it will quickly learn that it can simply ignore u∗t to predict the alternating stresses based on gt.",4.2 Pentameter Model,[0],[0]
"For this reason we use only u∗t to compute the stress probability:
P (S−) = σ(Weu ∗ t + be)
which gives the loss Lent = ∑
t− logP (S?t ) for the whole sequence, where S?t is the target stress at time step t.
We find the decoder still has the tendency to attend to the same characters, despite the incorporation of position information.",4.2 Pentameter Model,[0],[0]
"To regularise the model further, we introduce two loss penalties: repeat and coverage loss.
",4.2 Pentameter Model,[0],[0]
"The repeat loss penalises the model when it attends to previously attended characters (See et al., 2017), and is computed as follows:
Lrep = ∑ t ∑ j min(f tj , t−1∑ t=1 f tj )
By keeping a sum of attention weights over all previous time steps, we penalise the model when it focuses on characters that have non-zero history weights.
",4.2 Pentameter Model,[0],[0]
"The repeat loss discourages the model from focussing on the same characters, but does not assure that the appropriate characters receive attention.",4.2 Pentameter Model,[0],[0]
"Observing that stresses are aligned with the vowels of a syllable, we therefore penalise the model when vowels are ignored:
Lcov = ∑ j∈V ReLU(C − 10∑ t=1 f tj )
where V is a set of positions containing vowel characters, and C is a hyper-parameter that defines the minimum attention threshold that avoids penalty.
",4.2 Pentameter Model,[0],[0]
"To summarise, the pentameter model is optimised with the following loss:
Lpm = Lent + αLrep + βLcov (3)
where α and β are hyper-parameters for weighting the additional loss terms.",4.2 Pentameter Model,[0],[0]
"Two reasons motivate us to learn rhyme in an unsupervised manner: (1) we intend to extend the current model to poetry in other languages (which may not have pronunciation dictionaries); and (2) the language in our SONNET data is not Modern English, and so contemporary dictionaries may not accurately reflect the rhyme of the data.
",4.3 Rhyme Model,[0],[0]
"Exploiting the fact that rhyme exists in a quatrain, we feed sentence-ending word pairs of a quatrain as input to the rhyme model and train it to learn how to separate rhyming word pairs from non-rhyming ones.",4.3 Rhyme Model,[0],[0]
"Note that the model does not assume any particular rhyming scheme — it works as long as quatrains have rhyme.
",4.3 Rhyme Model,[0],[0]
"A training example consists of a number of word pairs, generated by pairing one target word with 3 other reference words in the quatrain, i.e. {(xt, xr), (xt, xr+1), (xt, xr+2)}, where xt is the target word and xr+i are the reference words.14",4.3 Rhyme Model,[0],[0]
We assume that in these 3 pairs there should be one rhyming and 2 non-rhyming pairs.,4.3 Rhyme Model,[0],[0]
From preliminary experiments we found that we can improve the model by introducing additional non-rhyming or negative reference words.,4.3 Rhyme Model,[0],[0]
"Negative reference words are sampled uniform randomly from the vocabulary, and the number of additional negative words is a hyper-parameter.
",4.3 Rhyme Model,[0],[0]
For each word x in the word pairs we embed the characters using the shared embedding matrix Wchr and feed them to an LSTM to produce the character states uj,4.3 Rhyme Model,[0],[0]
.15,4.3 Rhyme Model,[0],[0]
"Unlike the language and pentameter models, we use a unidirectional forward LSTM here (as rhyme is largely determined by the final characters), and the LSTM parameters are not shared.",4.3 Rhyme Model,[0],[0]
"We represent the encoding of the whole word by taking the last state u = uL, where L is the character length of the word.
",4.3 Rhyme Model,[0],[0]
"Given the character encodings, we use a
14E.g.",4.3 Rhyme Model,[0],[0]
"for the quatrain in Figure 1, a training example is {(day, temperate), (day, may), (day, date)}.
",4.3 Rhyme Model,[0],[0]
"15The character embeddings are the only shared parameters in this model.
margin-based loss to optimise the model:
Q = {cos(ut,ur), cos(ut,ur+1), ...}",4.3 Rhyme Model,[0],[0]
"Lrm = max(0, δ − top(Q, 1) + top(Q, 2))
where top(Q, k) returns the k-th largest element in Q, and δ is a margin hyper-parameter.
",4.3 Rhyme Model,[0],[0]
"Intuitively, the model is trained to learn a sufficient margin (defined by δ) that separates the best pair with all others, with the second-best being used to quantify all others.",4.3 Rhyme Model,[0],[0]
"This is the justification used in the multi-class SVM literature for a similar objective (Wang and Xue, 2014).
",4.3 Rhyme Model,[0],[0]
"With this network we can estimate whether two words rhyme by computing the cosine similarity score during generation, and resample words as necessary to enforce rhyme.",4.3 Rhyme Model,[0],[0]
"We focus on quatrain generation in this work, and so the aim is to generate 4 lines of poetry.",4.4 Generation Procedure,[0],[0]
During generation we feed the hidden state from the previous time step to the language model’s decoder to compute the vocabulary distribution for the current time step.,4.4 Generation Procedure,[0],[0]
"Words are sampled using a temperature between 0.6 and 0.8, and they are resampled if the following set of words is generated: (1) UNK token; (2) non-stopwords that were generated before;16 (3) any generated words with a frequency > 2; (4) the preceding 3 words; and (5) a number of symbols including parentheses, single and double quotes.17",4.4 Generation Procedure,[0],[0]
"The first sonnet line is generated without using any preceding context.
",4.4 Generation Procedure,[0],[0]
We next describe how to incorporate the pentameter model for generation.,4.4 Generation Procedure,[0],[0]
"Given a sonnet line, the pentameter model computes a loss Lpm (Equation (3))",4.4 Generation Procedure,[0],[0]
that indicates how well the line conforms to the iambic pentameter.,4.4 Generation Procedure,[0],[0]
"We first generate 10 candidate lines (all initialised with the same hidden state), and then sample one line from the candidate lines based on the pentameter loss values (Lpm).",4.4 Generation Procedure,[0],[0]
"We convert the losses into probabilities by taking the softmax, and a sentence is sampled with temperature = 0.1.
",4.4 Generation Procedure,[0],[0]
"To enforce rhyme, we randomly select one of the rhyming schemes (AABB, ABAB or ABBA) and resample sentence-ending words as necessary.",4.4 Generation Procedure,[0],[0]
"Given a pair of words, the rhyme model produces a cosine similarity score that estimates how well the
16We use the NLTK stopword list (Bird et al., 2009).",4.4 Generation Procedure,[0],[0]
"17We add these constraints to prevent the model from being
too repetitive, in generating the same words.
",4.4 Generation Procedure,[0],[0]
two words rhyme.,4.4 Generation Procedure,[0],[0]
We resample the second word of a rhyming pair (e.g. when generating the second A in AABB) until it produces a cosine similarity > 0.9.,4.4 Generation Procedure,[0],[0]
"We also resample the second word of a nonrhyming pair (e.g. when generating the first B in AABB) by requiring a cosine similarity 6 0.7.18
When generating in the forward direction we can never be sure that any particular word is the last word of a line, which creates a problem for resampling to produce good rhymes.",4.4 Generation Procedure,[0],[0]
"This problem is resolved in our model by reversing the direction of the language model, i.e. generating the last word of each line first.",4.4 Generation Procedure,[0],[0]
We apply this inversion trick at the word level (character order of a word is not modified) and only to the language model; the pentameter model receives the original word order as input.,4.4 Generation Procedure,[0],[0]
"We assess our sonnet model in two ways: (1) component evaluation of the language, pentameter and rhyme models; and (2) poetry generation evaluation, by crowd workers and an English literature expert.",5 Experiments,[0],[0]
"A sample of machine-generated sonnets are included in the supplementary material.
",5 Experiments,[0],[0]
We tune the hyper-parameters of the model over the development data (optimal configuration in the supplementary material).,5 Experiments,[0],[0]
"Word embeddings are initialised with pre-trained skip-gram embeddings (Mikolov et al., 2013a,b) on the BACKGROUND dataset, and are updated during training.",5 Experiments,[0],[0]
"For optimisers, we use Adagrad (Duchi et al., 2011) for the language model, and Adam (Kingma and Ba, 2014) for the pentameter and rhyme models.",5 Experiments,[0],[0]
"We truncate backpropagation through time after 2 sonnet lines, and train using 30 epochs, resetting the network weights to the weights from the previous epoch whenever development loss worsens.",5 Experiments,[0],[0]
We use standard perplexity for evaluating the language model.,5.1.1 Language Model,[0],[0]
"In terms of model variants, we have:19 • LM: Vanilla LSTM language model; • LM∗: LSTM language model that incorporates
character encodings (Equation (2)); 18Maximum number of resampling steps is capped at 1000.",5.1.1 Language Model,[0],[0]
"If the threshold is exceeded the model is reset to generate from scratch again.
",5.1.1 Language Model,[0],[0]
"19All models use the same (applicable) hyper-parameter configurations.
",5.1.1 Language Model,[0],[0]
• LM∗∗: LSTM language model that incorporates both character encodings and preceding context; • LM∗∗-C:,5.1.1 Language Model,[0],[0]
"Similar to LM∗∗, but preceding con-
text is encoded using convolutional networks, inspired by the poetry model of Zhang and Lapata (2014);20 • LM∗∗+PM+RM: the full model, with joint training of the language, pentameter and rhyme models.",5.1.1 Language Model,[0],[0]
Perplexity on the test partition is detailed in Table 2.,5.1.1 Language Model,[0],[0]
"Encouragingly, we see that the incorporation of character encodings and preceding context improves performance substantially, reducing perplexity by almost 10 points from LM to LM∗∗.",5.1.1 Language Model,[0],[0]
The inferior performance of LM∗∗-C compared to LM∗∗ demonstrates that our approach of processing context with recurrent networks with selective encoding is more effective than convolutional networks.,5.1.1 Language Model,[0],[0]
"The full model LM∗∗+PM+RM, which learns stress
20In Zhang and Lapata (2014), the authors use a series of convolutional networks with a width of 2 words to convert 5/7 poetry lines into a fixed size vector; here we use a standard convolutional network with max-pooling operation (Kim, 2014) to process the context.
and rhyme patterns simultaneously, also appears to improve the language model slightly.",5.1.1 Language Model,[0],[0]
"To assess the pentameter model, we use the attention weights to predict stress patterns for words in the test data, and compare them against stress patterns in the CMU pronunciation dictionary.21 Words that have no coverage or have nonalternating patterns given by the dictionary are discarded.",5.1.2 Pentameter Model,[0],[0]
"We use accuracy as the metric, and a predicted stress pattern is judged to be correct if it matches any of the dictionary stress patterns.
",5.1.2 Pentameter Model,[0],[0]
"To extract a stress pattern for a word from the model, we iterate through the pentameter (10 time steps), and append the appropriate stress (e.g. 1st time step = S−) to the word if any of its characters receives an attention > 0.20.
",5.1.2 Pentameter Model,[0],[0]
For the baseline (Stress-BL) we use the pretrained weighted finite state transducer (WFST) provided by Hopkins and Kiela (2017).22 The WFST maps a sequence word to a sequence of stresses by assuming each word has 1–5 stresses and the full word sequence produces iambic pentameter.,5.1.2 Pentameter Model,[0],[0]
"It is trained using the EM algorithm on a sonnet corpus developed by the authors.
",5.1.2 Pentameter Model,[0],[0]
We present stress accuracy in Table 2.,5.1.2 Pentameter Model,[0],[0]
"LM∗∗+PM+RM performs competitively, and informal inspection reveals that a number of mistakes are due to dictionary errors.",5.1.2 Pentameter Model,[0],[0]
"To understand the predicted stresses qualitatively, we display attention heatmaps for the the first quatrain of Shakespeare’s Sonnet 18 in Figure 3.",5.1.2 Pentameter Model,[0],[0]
"The y-axis represents the ten stresses of the iambic pentameter, and
21http://www.speech.cs.cmu.edu/cgi-bin/ cmudict.",5.1.2 Pentameter Model,[0],[0]
"Note that the dictionary provides 3 levels of stresses: 0, 1 and 2; we collapse 1 and 2 to S+.
22https://github.com/JackHopkins/ ACLPoetry
x-axis the characters of the sonnet line (punctuation removed).",5.1.2 Pentameter Model,[0],[0]
"The attention network appears to perform very well, without any noticeable errors.",5.1.2 Pentameter Model,[0],[0]
"The only minor exception is lovely in the second line, where it predicts 2 stresses but the second stress focuses incorrectly on the character e rather than y. Additional heatmaps for the full sonnet are provided in the supplementary material.",5.1.2 Pentameter Model,[0],[0]
"We follow a similar approach to evaluate the rhyme model against the CMU dictionary, but score based on F1 score.",5.1.3 Rhyme Model,[0],[0]
Word pairs that are not included in the dictionary are discarded.,5.1.3 Rhyme Model,[0],[0]
"Rhyme is determined by extracting the final stressed phoneme for the paired words, and testing if their phoneme patterns match.
",5.1.3 Rhyme Model,[0],[0]
"We predict rhyme for a word pair by feeding them to the rhyme model and computing cosine similarity; if a word pair is assigned a score > 0.8,23 it is considered to rhyme.",5.1.3 Rhyme Model,[0],[0]
"As a baseline (Rhyme-BL), we first extract for each word the last vowel and all following consonants, and predict a word pair as rhyming if their extracted sequences match.",5.1.3 Rhyme Model,[0],[0]
"The extracted sequence can be interpreted as a proxy for the last syllable of a word.
",5.1.3 Rhyme Model,[0],[0]
Reddy and Knight (2011) propose an unsupervised model for learning rhyme schemes in poems via EM.,5.1.3 Rhyme Model,[0],[0]
"There are two latent variables: φ specifies the distribution of rhyme schemes, and θ defines
230.8 is empirically found to be the best threshold based on development data.
",5.1.3 Rhyme Model,[0],[0]
the pairwise rhyme strength between two words.,5.1.3 Rhyme Model,[0],[0]
The model’s objective is to maximise poem likelihood over all possible rhyme scheme assignments under the latent variables φ and θ.,5.1.3 Rhyme Model,[0],[0]
"We train this model (Rhyme-EM) on our data24 and use the learnt θ to decide whether two words rhyme.25
Table 2 details the rhyming results.",5.1.3 Rhyme Model,[0],[0]
"The rhyme model performs very strongly at F1 > 0.90, well above both baselines.",5.1.3 Rhyme Model,[0],[0]
"Rhyme-EM performs poorly because it operates at the word level (i.e. it ignores character/orthographic information) and hence does not generalise well to unseen words and word pairs.26
To better understand the errors qualitatively, we present a list of word pairs with their predicted cosine similarity in Table 3.",5.1.3 Rhyme Model,[0],[0]
Examples on the left side are rhyming word pairs as determined by the CMU dictionary; right are non-rhyming pairs.,5.1.3 Rhyme Model,[0],[0]
"Looking at the rhyming word pairs (left), it appears that these words tend not to share any wordending characters.",5.1.3 Rhyme Model,[0],[0]
"For the non-rhyming pairs, we spot several CMU errors: (sire, ire) and (queen, been) clearly rhyme.",5.1.3 Rhyme Model,[0],[0]
"Following Hopkins and Kiela (2017), we present a pair of quatrains (one machine-generated and one human-written, in random order) to crowd workers on CrowdFlower, and ask them to guess which is the human-written poem.",5.2.1 Crowdworker Evaluation,[0],[0]
"Generation quality is estimated by computing the accuracy of workers at correctly identifying the human-written poem (with lower values indicate better results for the model).
",5.2.1 Crowdworker Evaluation,[0],[0]
"We generate 50 quatrains each for LM, LM∗∗ and LM∗∗+PM+RM (150 in total), and as a control, generate 30 quatrains with LM trained for one epoch.",5.2.1 Crowdworker Evaluation,[0],[0]
An equal number of human-written quatrains was sampled from the training partition.,5.2.1 Crowdworker Evaluation,[0],[0]
"A HIT contained 5 pairs of poems (of which one is a control), and workers were paid $0.05 for each HIT.",5.2.1 Crowdworker Evaluation,[0],[0]
"Workers who failed to identify the human-written poem in the control pair reliably (minimum accuracy = 70%) were removed by CrowdFlower automati-
24We use the original authors’ implementation: https: //github.com/jvamvas/rhymediscovery.
",5.2.1 Crowdworker Evaluation,[0],[0]
"25A word pair is judged to rhyme if θw1,w2 > 0.02; the threshold (0.02) is selected based on development performance.
",5.2.1 Crowdworker Evaluation,[0],[0]
"26Word pairs that did not co-occur in a poem in the training data have rhyme strength of zero.
cally, and they were restricted to do a maximum of 3 HITs.",5.2.1 Crowdworker Evaluation,[0],[0]
"To dissuade workers from using search engines to identify real poems, we presented the quatrains as images.
",5.2.1 Crowdworker Evaluation,[0],[0]
Accuracy is presented in Table 4.,5.2.1 Crowdworker Evaluation,[0],[0]
"We see a steady decrease in accuracy (= improvement in model quality) from LM to LM∗∗ to LM∗∗+PM+RM, indicating that each model generates quatrains that are less distinguishable from human-written ones.",5.2.1 Crowdworker Evaluation,[0],[0]
"Based on the suspicion that workers were using rhyme to judge the poems, we tested a second model, LM∗∗+RM, which is the full model without the pentameter component.",5.2.1 Crowdworker Evaluation,[0],[0]
"We found identical accuracy (0.532), confirming our suspicion that crowd workers depend on only rhyme in their judgements.",5.2.1 Crowdworker Evaluation,[0],[0]
These observations demonstrate that meter is largely ignored by lay persons in poetry evaluation.,5.2.1 Crowdworker Evaluation,[0],[0]
"To better understand the qualitative aspects of our generated quatrains, we asked an English literature expert (a Professor of English literature at a major English-speaking university; the last author of this paper) to directly rate 4 aspects: meter, rhyme, readability and emotion (i.e. amount of emotion the poem evokes).",5.2.2 Expert Judgement,[0],[0]
All are rated on an ordinal scale between 1 to 5 (1 = worst; 5 = best).,5.2.2 Expert Judgement,[0],[0]
"In total, 120 quatrains were annotated, 30 each for LM, LM∗∗, LM∗∗+PM+RM, and human-written poems (Human).",5.2.2 Expert Judgement,[0],[0]
The expert was blind to the source of each poem.,5.2.2 Expert Judgement,[0],[0]
"The mean and standard deviation of the ratings are presented in Table 5.
",5.2.2 Expert Judgement,[0],[0]
"We found that our full model has the highest ratings for both rhyme and meter, even higher than
human poets.",5.2.2 Expert Judgement,[0],[0]
"This might seem surprising, but in fact it is well established that real poets regularly break rules of form to create other effects (Adams, 1997).",5.2.2 Expert Judgement,[0],[0]
"Despite excellent form, the output of our model can easily be distinguished from humanwritten poetry due to its lower emotional impact and readability.",5.2.2 Expert Judgement,[0],[0]
"In particular, there is evidence here that our focus on form actually hurts the readability of the resulting poems, relative even to the simpler language models.",5.2.2 Expert Judgement,[0],[0]
"Another surprise is how well simple language models do in terms of their grasp of meter: in this expert evaluation, we see only marginal benefit as we increase the sophistication of the model.",5.2.2 Expert Judgement,[0],[0]
"Taken as a whole, this evaluation suggests that future research should look beyond forms, towards the substance of good poetry.",5.2.2 Expert Judgement,[0],[0]
"We propose a joint model of language, meter and rhyme that captures language and form for modelling sonnets.",6 Conclusion,[0],[0]
"We provide quantitative analyses for each component, and assess the quality of generated poems using judgements from crowdworkers and a literature expert.",6 Conclusion,[0],[0]
"Our research reveals that vanilla LSTM language model captures meter implicitly, and our proposed rhyme model performs exceptionally well.",6 Conclusion,[0],[0]
"Machine-generated generated poems, however, still underperform in terms of readability and emotion.",6 Conclusion,[0],[0]
"In this paper, we propose a joint architecture that captures language, rhyme and meter for sonnet modelling.",abstractText,[0],[0]
We assess the quality of generated poems using crowd and expert judgements.,abstractText,[0],[0]
"The stress and rhyme models perform very well, as generated poems are largely indistinguishable from human-written poems.",abstractText,[0],[0]
"Expert evaluation, however, reveals that a vanilla language model captures meter implicitly, and that machine-generated poems still underperform in terms of readability and emotion.",abstractText,[0],[0]
"Our research shows the importance expert evaluation for poetry generation, and that future research should look beyond rhyme/meter and focus on poetic language.",abstractText,[0],[0]
"Deep-speare: A joint neural model of poetic language, meter and rhyme",title,[0],[0]
The composition of polyphonic chorale music in the style of J.S. Bach has represented a major challenge in automatic music composition over the last decades.,1. Introduction,[0],[0]
"The corpus of the chorale harmonizations by Johann Sebastian Bach is remarkable by its homogeneity and its size (389 chorales in (Bach, 1985)).",1. Introduction,[0],[0]
"All these short pieces (approximately one minute long) are written for a four-part chorus (soprano, alto, tenor and bass) using similar compositional principles: the composer takes a well-known (at that time) melody from a Lutheran hymn and harmonizes it i.e. the three lower parts (alto, tenor and bass) accompanying the soprano (the highest part) are composed, see Fig.1 for an example.
",1. Introduction,[0],[0]
"1LIP6, Université Pierre et Marie Curie 2Sony CSL, Paris 3Sony CSL, Japan.",1. Introduction,[0],[0]
"Correspondence to: Gaëtan Hadjeres <gaetan.hadjeres@etu.upmc.fr>, François",1. Introduction,[0],[0]
"Pachet <pachetcsl@gmail.com>, Frank Nielsen <Frank.Nielsen@acm.org>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Moreover, since the aim of reharmonizing a melody is to give more power or new insights to its text, the lyrics have to be understood clearly.",1. Introduction,[0],[0]
"We say that voices are in homophony, i.e. they articulate syllables simultaneously.",1. Introduction,[0],[0]
"This implies characteristic rhythms, variety of harmonic ideas as well as characteristic melodic movements which make the style of these chorale compositions easily distinguishable, even for non experts.
",1. Introduction,[0],[0]
"The difficulty, from a compositional point of view comes from the intricate interplay between harmony (notes sounding at the same time) and voice movements (how a single voice evolves through time).",1. Introduction,[0],[0]
"Furthermore, each voice has its own “style” and its own coherence.",1. Introduction,[0],[0]
"Finding a chorale-like reharmonization which combines Bach-like harmonic progressions with musically interesting melodic movements is a problem which often takes years of practice for musicians.
",1. Introduction,[0],[0]
"From the point of view of automatic music generation, the first solution to this apparently highly combinatorial problem was proposed by (Ebcioglu, 1988) in 1988.",1. Introduction,[0],[0]
"This problem is seen as a constraint satisfaction problem, where the system must fulfill numerous hand-crafted constraints characterizing the style of Bach.",1. Introduction,[0],[0]
It is a rule-based expert system which contains no less than 300 rules and tries to reharmonize a given melody with a generate-and-test method and intelligent backtracking.,1. Introduction,[0],[0]
"Among the short examples presented at the end of the paper, some are flawless.",1. Introduction,[0],[0]
"The drawbacks of this method are, as stated by the author, the considerable effort to generate the rule base and the fact that the harmonizations produced “do not sound like Bach, except for occasional Bachian patterns and cadence formulas.”",1. Introduction,[0],[0]
"In our opinion, the requirement of an expert knowledge implies a lot of subjective choices.
",1. Introduction,[0],[0]
"A neural-network-based solution was later developed by (Hild et al., 1992).",1. Introduction,[0],[0]
"This method relies on several neural networks, each one trained for solving a specific task: a harmonic skeleton is first computed then refined and ornamented.",1. Introduction,[0],[0]
"A similar approach is adopted in (Allan & Williams, 2005), but uses Hidden Markov Models (HMMs) instead of neural networks.",1. Introduction,[0],[0]
"Chords are represented as lists of intervals and form the states of the Markov mod-
2https://www.youtube.com/watch?v=",1. Introduction,[0],[0]
"73WF0M99vlg
els.",1. Introduction,[0],[0]
These approaches produce interesting results even if they both use expert knowledge and bias the generation by imposing their compositional process.,1. Introduction,[0],[0]
"In (Whorley et al., 2013; Whorley & Conklin, 2016), authors elaborate on those methods by introducing multiple viewpoints and variations on the sampling method (generated sequences which violate “rules of harmony” are put aside for instance).",1. Introduction,[0],[0]
"However, this approach does not produce a convincing chorale-like texture, rhythmically as well as harmonically and the resort to hand-crafted criteria to assess the quality of the generated sequences might rule out many musically-interesting solutions.
",1. Introduction,[0],[0]
"Recently, agnostic approaches (requiring no knowledge about harmony, Bach’s style or music) using neural networks have been investigated with promising results.",1. Introduction,[0],[0]
"In (Boulanger-Lewandowski et al., 2012), chords are modeled with Restricted Boltzmann Machines (RBMs).",1. Introduction,[0],[0]
Their temporal dependencies are learned using Recurrent Neural Networks (RNNs).,1. Introduction,[0],[0]
"Variations of these architectures based on Long Short-Term Memory (LSTM) units ((Hochreiter & Schmidhuber, 1997; Mikolov et al., 2014)) or GRUs (Gated Recurrent Units) have been developed by (Lyu et al., 2015) and (Chung et al., 2014) respectively.",1. Introduction,[0],[0]
"However, these models which work on piano roll representations of the music are too general to capture the specificity of Bach chorales.",1. Introduction,[0],[0]
"Also, a major drawback is their lack of flexibility.",1. Introduction,[0],[0]
Generation is performed from left to right.,1. Introduction,[0],[0]
A user cannot interact with the system: it is impossible to do reharmonization for instance which is the essentially how the corpus of Bach chorales was composed.,1. Introduction,[0],[0]
"Moreover, their invention capacity and non-plagiarism abilities are not demonstrated.
",1. Introduction,[0],[0]
"A method that addresses the rigidity of sequential generation in music was first proposed in (Sakellariou et al., 2015; Sakellariou et al., 2016) for monophonic music and later generalized to polyphony in (Hadjeres et al., 2016).",1. Introduction,[0],[0]
"These approaches advocate for the use of Gibbs sampling as a generation process in automatic music composition.
",1. Introduction,[0],[0]
"The most recent advances in chorale harmonization is arguably the BachBot model (Liang, 2016), a LSTMbased approach specifically designed to deal with Bach
chorales.",1. Introduction,[0],[0]
This approach relies on little musical knowledge (all chorales are transposed in a common key) and is able to produce high-quality chorale harmonizations.,1. Introduction,[0],[0]
"However, compared to our approach, this model is less general (produced chorales are all in the C key for instance) and less flexible (only the soprano can be fixed).",1. Introduction,[0],[0]
"Similarly to our work, the authors evaluate their model with an online Turing test to assess the efficiency of their model.",1. Introduction,[0],[0]
"They also take into account the fermata symbols (Fig. 2) which are indicators of the structure of the chorales.
",1. Introduction,[0],[0]
"In this paper we introduce DeepBach, a dependency network (Heckerman et al., 2000) capable of producing musically convincing four-part chorales in the style of Bach by using a Gibbs-like sampling procedure.",1. Introduction,[0],[0]
"Contrary to models based on RNNs, we do not sample from left to right which allows us to enforce positional, unary user-defined constraints such as rhythm, notes, parts, chords and cadences.",1. Introduction,[0],[0]
"DeepBach is able to generate coherent musical phrases and provides, for instance, varied reharmonizations of melodies without plagiarism.",1. Introduction,[0],[0]
"Its core features are its speed, the possible interaction with users and the richness of harmonic ideas it proposes.",1. Introduction,[0],[0]
"Its efficiency opens up new ways of composing Bach-like chorales for non experts in an interactive manner similarly to what is proposed in (Papadopoulos et al., 2016) for leadsheets.
",1. Introduction,[0],[0]
In Sect.,1. Introduction,[0],[0]
2 we present the DeepBach model for four-part chorale generation.,1. Introduction,[0],[0]
We discuss in Sect.,1. Introduction,[0],[0]
3 the results of an experimental study we conducted to assess the quality of our model.,1. Introduction,[0],[0]
"Finally, we provide generated examples in Sect.",1. Introduction,[0],[0]
4.3 and elaborate on the possibilities offered by our interactive music composition editor in Sect.,1. Introduction,[0],[0]
4.,1. Introduction,[0],[0]
All examples can be heard on the accompanying web page3 and the code of our implementation is available on GitHub4.,1. Introduction,[0],[0]
"Even if our presentation focuses on Bach chorales, this model has been successfully applied to other styles and composers including Monteverdi five-voice madrigals to Palestrina masses.
",1. Introduction,[0],[0]
"3https://sites.google.com/site/ deepbachexamples/
4https://github.com/Ghadjeres/DeepBach",1. Introduction,[0],[0]
In this paper we introduce a generative model which takes into account the distinction between voices.,2. DeepBach,[0],[0]
Sect.,2. DeepBach,[0],[0]
2.1 presents the data representation we used.,2. DeepBach,[0],[0]
This representation is both fitted for our sampling procedure and more accurate than many data representation commonly used in automatic music composition.,2. DeepBach,[0],[0]
Sect.,2. DeepBach,[0],[0]
2.2 presents the model’s architecture and Sect.,2. DeepBach,[0],[0]
2.3 our generation method.,2. DeepBach,[0],[0]
"Finally, Sect. 2.4 provides implementation details and indicates how we preprocessed the corpus of Bach chorale harmonizations.",2. DeepBach,[0],[0]
We use MIDI pitches to encode notes and choose to model voices separately.,2.1.1. NOTES AND VOICES,[0],[0]
"We consider that only one note can be sung at a given time and discard chorales with voice divisions.
",2.1.1. NOTES AND VOICES,[0],[0]
"Since Bach chorales only contain simple time signatures, we discretize time with sixteenth notes, which means that each beat is subdivided into four equal parts.",2.1.1. NOTES AND VOICES,[0],[0]
"Since there is no smaller subdivision in Bach chorales, there is no loss of information in this process.
",2.1.1. NOTES AND VOICES,[0],[0]
"In this setting, a voice Vi = {Vti }t is a list of notes indexed by t ∈",2.1.1. NOTES AND VOICES,[0],[0]
"[T ]5, where T is the duration piece (in sixteenth notes).",2.1.1. NOTES AND VOICES,[0],[0]
We choose to model rhythm by simply adding a hold symbol “ ” coding whether or not the preceding note is held to the list of existing notes.,2.1.2. RHYTHM,[0],[0]
"This representation is thus unambiguous, compact and well-suited to our sampling method (see Sect.",2.1.2. RHYTHM,[0],[0]
2.3.4).,2.1.2. RHYTHM,[0],[0]
The music sheet (Fig. 1b) conveys more information than only the notes played.,2.1.3. METADATA,[0],[0]
"We can cite:
• the lyrics,
• the key signature,
• the time signature,
• the beat index,
• an implicit metronome (on which subdivision of the beat the note is played),
• the fermata symbols (see Fig. 2), 5We adopt the standard notation [N ] to denote the set of inte-
gers {1, . . .",2.1.3. METADATA,[0],[0]
", N} for any integer N .
",2.1.3. METADATA,[0],[0]
"In the following, we will only take into account the fermata symbols, the subdivision indexes and the current key signature.",2.1.3. METADATA,[0],[0]
"To this end, we introduce:
•",2.1.3. METADATA,[0],[0]
"The fermata list F that indicates if there is a fermata symbol, see Fig. 2, over the current note, it is a Boolean value.",2.1.3. METADATA,[0],[0]
"If a fermata is placed over a note on the music sheet, we consider that it is active for all time indexes within the duration of the note.
",2.1.3. METADATA,[0],[0]
•,2.1.3. METADATA,[0],[0]
The subdivision list S that contains the subdivision indexes of the beat.,2.1.3. METADATA,[0],[0]
It is an integer between 1 and 4: there is no distinction between beats in a bar so that our model is able to deal with chorales with three and four beats per measure.,2.1.3. METADATA,[0],[0]
"We represent a chorale as a couple
(V,M) (1)
composed of voices and metadata.",2.1.4. CHORALE,[0],[0]
"For Bach chorales, V is a list of 4 voices Vi for i ∈",2.1.4. CHORALE,[0],[0]
"[4] (soprano, alto, tenor and bass) andM a collection of metadata lists (F and S).
",2.1.4. CHORALE,[0],[0]
Our choices are very general and do not involve expert knowledge about harmony or scales but are only mere observations of the corpus.,2.1.4. CHORALE,[0],[0]
The list S acts as a metronome.,2.1.4. CHORALE,[0],[0]
The list F is added since fermatas in Bach chorales indicate the end of each musical phrase.,2.1.4. CHORALE,[0],[0]
The use of fermata to this end is a specificity of Bach chorales that we want to take advantage of.,2.1.4. CHORALE,[0],[0]
We choose to consider the metadata sequences in M as given.,2.2. Model Architecture,[0],[0]
"For clarity, we suppose in this section that our dataset is composed of only one chorale written as in Eq. 1 of size T .",2.2. Model Architecture,[0],[0]
"We define a dependency network on the finite set of variables V = {V ti } by specifying a set of conditional probability distributions (parametrized by parameter θi,t){
pi,t(V t i |V\i,t,M, θi,t) } i∈[4],t∈[T ] , (2)
where Vti indicates the note of voice i at time index t and V\i,t all variables in V except from the variable Vti .",2.2. Model Architecture,[0],[0]
"As we want our model to be time invariant so that we can apply it to sequences of any size, we share the parameters between all conditional probability distributions on variables lying in the same voice, i.e.
θi := θi,t, pi := pi,t ∀t ∈",2.2. Model Architecture,[0],[0]
"[T ].
Finally, we fit each of these conditional probability distributions on the data by maximizing the log-likelihood.",2.2. Model Architecture,[0],[0]
"Due to weight sharing, this amounts to solving four classification problems of the form:
max θi ∑ t log pi(Vti |V\i,t,M, θi), for i ∈",2.2. Model Architecture,[0],[0]
"[4], (3)
where the aim is to predict a note knowing the value of its neighboring notes, the subdivision of the beat it is on and the presence of fermatas.",2.2. Model Architecture,[0],[0]
"The advantage with this formulation is that each classifier has to make predictions within a small range of notes whose ranges correspond to the notes within the usual voice ranges (see 2.4).
",2.2. Model Architecture,[0],[0]
"For accurate predictions and in order to take into account the sequential aspect of the data, each classifier is modeled using four neural networks: two Deep Recurrent Neural Networks (Pascanu et al., 2013), one summing up past information and another summing up information coming from the future together with a non-recurrent neural network for notes occurring at the same time.",2.2. Model Architecture,[0],[0]
Only the last output from the uppermost RNN layer is kept.,2.2. Model Architecture,[0],[0]
"These three outputs are then merged and passed as the input of a fourth neural network whose output is pi(Vti |V\i,t,M, θ).",2.2. Model Architecture,[0],[0]
Figure 4 shows a graphical representation for one of these models.,2.2. Model Architecture,[0],[0]
Details are provided in Sect.,2.2. Model Architecture,[0],[0]
2.4.,2.2. Model Architecture,[0],[0]
These choices of architecture somehow match real compositional practice on Bach chorales.,2.2. Model Architecture,[0],[0]
"Indeed, when reharmonizing a given melody, it is often simpler to start from the cadence and write music “backwards.”",2.2. Model Architecture,[0],[0]
Generation in dependency networks is performed using the pseudo-Gibbs sampling procedure.,2.3.1. ALGORITHM,[0],[0]
"This Markov Chain
Monte Carlo (MCMC) algorithm is described in Alg.1.",2.3.1. ALGORITHM,[0],[0]
"It is similar to the classical Gibbs sampling procedure (Geman & Geman, 1984) on the difference that the conditional distributions are potentially incompatible (Chen & Ip, 2015).",2.3.1. ALGORITHM,[0],[0]
This means that the conditional distributions of Eq.,2.3.1. ALGORITHM,[0],[0]
(2) do not necessarily comes from a joint distribution p(V) and that the theoretical guarantees that the MCMC converges to this stationary joint distribution vanish.,2.3.1. ALGORITHM,[0],[0]
"We experimentally verified that it was indeed the case by checking that the Markov Chain of Alg.1 violates Kolmogorov’s criterion (Kelly, 2011): it is thus not reversible and cannot converge to a joint distribution whose conditional distributions match the ones used for sampling.
",2.3.1. ALGORITHM,[0],[0]
"However, this Markov chain converges to another stationary distribution and applications on real data demonstrated that this method yielded accurate joint probabilities, especially when the inconsistent probability distributions are learned from data (Heckerman et al., 2000).",2.3.1. ALGORITHM,[0],[0]
"Furthermore, nonreversible MCMC algorithms can in particular cases be better at sampling that reversible Markov Chains (Vucelja, 2014).",2.3.1. ALGORITHM,[0],[0]
The advantage of this method is that we can enforce userdefined constraints by tweaking Alg.,2.3.2. FLEXIBILITY OF THE SAMPLING PROCEDURE,[0],[0]
"1:
• instead of choosing voice i from 1 to 4 we can choose to fix the soprano and only resample voices from 2, 3
Algorithm 1 Pseudo-Gibbs sampling 1: Input: Chorale length L, metadataM containing lists
of length L, probability distributions (p1, p2, p3, p4), maximum number of iterations M 2: Create four lists V = (V1,V2,V3,V4) of length L 3: {The lists are initialized with random notes drawn from
the ranges of the corresponding voices (sampled uniformly or from the marginal distributions of the notes)}
4: for m from 1 to M do 5: Choose voice i uniformly between 1 and 4 6: Choose time t uniformly between 1 and L 7: Re-sample Vti from pi(Vti |V\i,t,M, θi) 8: end for 9: Output: V = (V1,V2,V3,V4)
and 4 in step (3) in order to provide reharmonizations of the fixed melody
• we can choose the fermata list F in order to impose end of musical phrases at some places
• more generally, we can impose any metadata
• for any t and any i, we can fix specific subsets Rti of notes within the range of voice i.",2.3.2. FLEXIBILITY OF THE SAMPLING PROCEDURE,[0],[0]
"We then restrict ourselves to some specific chorales by re-sampling Vti from
pi(Vti |V\i,t,M, θi,Vti ∈",2.3.2. FLEXIBILITY OF THE SAMPLING PROCEDURE,[0],[0]
"Rti)
at step (5).",2.3.2. FLEXIBILITY OF THE SAMPLING PROCEDURE,[0],[0]
"This allows us for instance to fix rhythm (since the hold symbol is considered as a note), impose some chords in a soft manner or restrict the vocal ranges.",2.3.2. FLEXIBILITY OF THE SAMPLING PROCEDURE,[0],[0]
Note that it is possible to make generation faster by making parallel Gibbs updates on GPU.,2.3.3. PERFORMANCE,[0],[0]
Steps (3) to (5) from Alg. 1 can be run simultaneously to provide significant speedups.,2.3.3. PERFORMANCE,[0],[0]
"Even if it is known that this approach is biased (De Sa et al., 2016) (since we can update simultaneously variables which are not conditionally independent), we experimentally observed that for small batch sizes (16 or 32), DeepBach still generates samples of great musicality while running ten times faster than the sequential version.",2.3.3. PERFORMANCE,[0],[0]
"This allows DeepBach to generate chorales in a few seconds.
",2.3.3. PERFORMANCE,[0],[0]
"It is also possible to use the hard-disk-configurations generation algorithm (Alg.2.9 in (Krauth, 2006)) to appropriately choose all the time indexes at which we parallelly resample so that:
• every time index is at distance at least δ from the other time indexes
• configurations of time indexes satisfying the relation above are equally sampled.
",2.3.3. PERFORMANCE,[0],[0]
This trick allows to assert that we do not update simultaneously a variable and its local context.,2.3.3. PERFORMANCE,[0],[0]
We emphasize on this section the importance of our particular choice of data representation with respect to our sampling procedure.,2.3.4. IMPORTANCE OF THE DATA REPRESENTATION,[0],[0]
"The fact that we obtain great results using pseudo-Gibbs sampling relies exclusively on our choice to integrate the hold symbol into the list of notes.
",2.3.4. IMPORTANCE OF THE DATA REPRESENTATION,[0],[0]
"Indeed, Gibbs sampling fails to sample the true joint distribution p(V|M, θ) when variables are highly correlated, creating isolated regions of high probability states in which the MCMC chain can be trapped.",2.3.4. IMPORTANCE OF THE DATA REPRESENTATION,[0],[0]
"However, many data representations used in music modeling such as
• the piano-roll representation,
• the couple (pitch, articulation) representation where articulation is a Boolean value indicating whether or not the note is played or held,
tend to make the musical data suffer from this drawback.
",2.3.4. IMPORTANCE OF THE DATA REPRESENTATION,[0],[0]
"As an example, in the piano-roll representation, a long note is represented as the repetition of the same value over many variables.",2.3.4. IMPORTANCE OF THE DATA REPRESENTATION,[0],[0]
"In order to only change its pitch, one needs to change simultaneously a large number of variables (which is exponentially rare) while this is achievable with only one variable change with our representation.",2.3.4. IMPORTANCE OF THE DATA REPRESENTATION,[0],[0]
"We implemented DeepBach using Keras (Chollet, 2015) with the Tensorflow (Abadi et al., 2015) backend.",2.4. Implementation Details,[0],[0]
"We used the database of chorale harmonizations by J.S. Bach included in the music21 toolkit (Cuthbert & Ariza, 2010).",2.4. Implementation Details,[0],[0]
"After removing chorales with instrumental parts and chorales containing parts with two simultaneous notes (bass parts sometimes divide for the last chord), we ended up with 352 pieces.",2.4. Implementation Details,[0],[0]
"Contrary to other approaches which transpose all chorales to the same key (usually in C major or A minor), we choose to augment our dataset by adding all chorale transpositions which fit within the vocal ranges defined by the initial corpus.",2.4. Implementation Details,[0],[0]
This gives us a corpus of 2503 chorales and split it between a training set (80%) and a validation set (20%).,2.4. Implementation Details,[0],[0]
"The vocal ranges contains less than 30 different pitches for each voice (21, 21, 21, 28) for the soprano, alto, tenor and bass parts respectively.
",2.4. Implementation Details,[0],[0]
"As shown in Fig. 4, we model only local interactions between a note Vti and its context (V\i,t, M) i.e. only elements with time index t between t − ∆t and t + ∆t are
taken as inputs of our model for some scope ∆t.",2.4. Implementation Details,[0],[0]
"This approximation appears to be accurate since musical analysis reveals that Bach chorales do not exhibit clear long-term dependencies.
",2.4. Implementation Details,[0],[0]
The reported results in Sect.,2.4. Implementation Details,[0],[0]
3 and examples in Sect.,2.4. Implementation Details,[0],[0]
4.3 were obtained with ∆t = 16.,2.4. Implementation Details,[0],[0]
"We chose as the “neural network brick” in Fig. 4 a neural network with one hidden layer of size 200 and ReLU (Nair & Hinton, 2010)",2.4. Implementation Details,[0],[0]
"nonlinearity and as the “Deep RNN brick” two stacked LSTMs (Hochreiter & Schmidhuber, 1997; Mikolov et al., 2014), each one being of size 200 (see Fig. 2 (f) in (Li & Wu, 2015)).",2.4. Implementation Details,[0],[0]
"The “embedding brick” applies the same neural network to each time slice (Vt,Mt).",2.4. Implementation Details,[0],[0]
"There are 20% dropout on input and 50% dropout after each layer.
",2.4. Implementation Details,[0],[0]
We experimentally found that sharing weights between the left and right embedding layers improved neither validation accuracy nor the musical quality of our generated chorales.,2.4. Implementation Details,[0],[0]
We evaluated the quality of our model with an online test conducted on human listeners.,3. Experimental Results,[0],[0]
"For the parameters used in our experiment, see Sect 2.4.",3.1. Setup,[0],[0]
"We compared our model with two other models: a Maximum Entropy model (MaxEnt) as in (Hadjeres et al., 2016) and a Multilayer Perceptron (MLP) model.
",3.1. Setup,[0],[0]
The Maximum Entropy model is a neural network with no hidden layer.,3.1. Setup,[0],[0]
"It is given by:
pi(Vti |V\i,t,M, Ai, bi) = Softmax(AX + b) (4)
where X is a vector containing the elements in V\i,t ∪Mt, Ai a (ni,mi) matrix and bi a vector of size mi with mi being the size of X , ni the number of notes in the voice range i and Softmax the softmax function given by
Softmax(z)j = ezj∑K k=1 e zk for j ∈",3.1. Setup,[0],[0]
"[K],
for a vector z = (z1, . . .",3.1. Setup,[0],[0]
", zK).
",3.1. Setup,[0],[0]
"The Multilayer Perceptron model we chose takes as input elements in V\i,t∪M, is a neural network with one hidden layer of size 500 and uses a ReLU (Nair & Hinton, 2010)",3.1. Setup,[0],[0]
"nonlinearity.
",3.1. Setup,[0],[0]
"All models are local and have the same scope ∆t, see Sect. 2.4.
",3.1. Setup,[0],[0]
Subjects were asked to give information about their musical expertise.,3.1. Setup,[0],[0]
"They could choose what category fits them best between:
1.",3.1. Setup,[0],[0]
"I seldom listen to classical music
2.",3.1. Setup,[0],[0]
"Music lover or musician
3.",3.1. Setup,[0],[0]
"Student in music composition or professional musician.
",3.1. Setup,[0],[0]
"The musical extracts have been obtained by reharmonizing 50 chorales from the validation set by each of the three models (MaxEnt, MLP, DeepBach).",3.1. Setup,[0],[0]
"We rendered the MIDI files using the Leeds Town Hall Organ soundfont6 and cut two extracts of 12 seconds from each chorale, which gives us 400 musical extracts for our test: 4 versions for each of the 100 melody chunks.",3.1. Setup,[0],[0]
"We chose our rendering so that the generated parts (alto, tenor and bass) can be distinctly heard and differentiated from the soprano part (which is fixed and identical for all models): in our mix, dissonances are easily heard, the velocity is the same for all notes as in a real organ performance and the sound does not decay, which is important when evaluating the reharmonization of long notes.",3.1. Setup,[0],[0]
Subjects were presented series of only one musical extract together with the binary choice “Bach” or “Computer”.,3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
Fig. 5 shows how the votes are distributed depending on the level of musical expertise of the subjects for each model.,3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
"For this experiment, 1272 people took this test, 261 with musical expertise 1, 646 with musical expertise 2 and 365 with musical expertise 3.
",3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
The results are quite clear: the percentage of “Bach” votes augment as the model’s complexity increase.,3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
"Furthermore, the distinction between computer-generated extracts and Bach’s extracts is more accurate when the level of musical expertise is higher.",3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
"When presented a DeepBach-generated
6https://www.samplephonics.com/products/ free/sampler-instruments/the-leeds-townhall-organ
extract, around 50% of the voters would judge it as composed by Bach.",3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
"We consider this to be a good score knowing the complexity of Bach’s compositions and the facility to detect badly-sounding chords even for non musicians.
",3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
We also plotted specific results for each of the 400 extracts.,3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
Fig. 6 shows for each reharmonization extract the percentage of Bach votes it collected: more than half of the DeepBach’s automatically-composed extracts has a majority of votes considering them as being composed by J.S. Bach while it is only a third for the MLP model.,3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
We developed a plugin on top of the MuseScore music editor allowing a user to call DeepBach on any rectangular region.,4.1. Description,[0],[0]
"Even if the interface is minimal (see Fig.7), the possibilities are numerous: we can generate a chorale from scratch, reharmonize a melody and regenerate a given chord, bar or part.",4.1. Description,[0],[0]
We believe that this interplay between a user and the system can boost creativity and can interest a wide range of audience.,4.1. Description,[0],[0]
We made two major changes between the model we described for the online test and the interactive composition tool.,4.2. Adapting the model,[0],[0]
We changed the MIDI encoding of the notes to a full name encoding of the notes.,4.2.1. NOTE ENCODING,[0],[0]
"Indeed, some information is lost when reducing a music sheet to its MIDI representation since we cannot differentiate between two enharmonic
notes (notes that sound the same but that are written differently e.g. F# and Gb).",4.2.1. NOTE ENCODING,[0],[0]
"This difference in Bach chorales is unambiguous and it is thus natural to consider the full name of the notes, like C#3, Db3 or E#4.",4.2.1. NOTE ENCODING,[0],[0]
"From a machine learning point of view, these notes would appear in totally different contexts.",4.2.1. NOTE ENCODING,[0],[0]
"This improvement enables the model to generate notes with the correct spelling, which is important when we focus on the music sheet rather than on its audio rendering.",4.2.1. NOTE ENCODING,[0],[0]
We added the current key signature list K to the metadataM. This allows users to impose modulations and key changes.,4.2.2. STEERING MODULATIONS,[0],[0]
Each element Kt of this list contains the number of sharps of the estimated key for the current bar.,4.2.2. STEERING MODULATIONS,[0],[0]
It is a integer between -7 and 7.,4.2.2. STEERING MODULATIONS,[0],[0]
The current key is computed using the key analyzer algorithm from music21.,4.2.2. STEERING MODULATIONS,[0],[0]
We now provide and comment on examples of chorales generated using the DeepBach plugin.,4.3. Generation examples,[0],[0]
Our aim is to show the quality of the solutions produced by DeepBach.,4.3. Generation examples,[0],[0]
"For these examples, no note was set by hand and we asked DeepBach to generate regions longer than one bar and covering all four voices.
",4.3. Generation examples,[0],[0]
"Despite some compositional errors like parallel octaves, the musical analysis reveals that the DeepBach compositions reproduce typical Bach-like patterns, from characteristic cadences to the expressive use of nonchord tones.",4.3. Generation examples,[0],[0]
As discussed in Sect.,4.3. Generation examples,[0],[0]
"4.2, DeepBach also learned the correct spelling of the notes.",4.3. Generation examples,[0],[0]
"Among examples in Fig. 8, examples (a) and (b) share the same metadata (S,F and K).",4.3. Generation examples,[0],[0]
"This demonstrates that even with fixed metadata it is possible to generate contrasting chorales.
",4.3. Generation examples,[0],[0]
"Since we aimed at producing music that could not be distinguished from actual Bach compositions, we had all provided extracts sung by the Wishful Singing choir.",4.3. Generation examples,[0],[0]
These audio files can be heard on the accompanying website.,4.3. Generation examples,[0],[0]
"We described DeepBach, a probabilistic model together with a sampling method which is flexible, efficient and provides musically convincing results even to the ears of professionals.",5. Discussion and future work,[0],[0]
"The strength of our method is the possibility to let users impose unary constraints, which is a feature often neglected in probabilistic models of music.",5. Discussion and future work,[0],[0]
"Through our graphical interface, the composition of polyphonic music becomes accessible to non-specialists.",5. Discussion and future work,[0],[0]
The playful interaction between the user and this system can boost creativity and help explore new ideas quickly.,5. Discussion and future work,[0],[0]
"We believe that this approach could form a starting point for a novel com-
positional process that could be described as a constructive dialogue between a human operator and the computer.",5. Discussion and future work,[0],[0]
This method is general and its implementation simple.,5. Discussion and future work,[0],[0]
"It is not only applicable to Bach chorales but embraces a wider range of polyphonic music.
",5. Discussion and future work,[0],[0]
"Future work aims at refining our interface, speeding up
generation and handling datasets with small corpora.",5. Discussion and future work,[0],[0]
"This paper introduces DeepBach, a graphical model aimed at modeling polyphonic music and specifically hymn-like pieces.",abstractText,[0],[0]
"We claim that, after being trained on the chorale harmonizations by Johann Sebastian Bach, our model is capable of generating highly convincing chorales in the style of Bach.",abstractText,[0],[0]
DeepBach’s strength comes from the use of pseudo-Gibbs sampling coupled with an adapted representation of musical data.,abstractText,[0],[0]
This is in contrast with many automatic music composition approaches which tend to compose music sequentially.,abstractText,[0],[0]
"Our model is also steerable in the sense that a user can constrain the generation by imposing positional constraints such as notes, rhythms or cadences in the generated score.",abstractText,[0],[0]
We also provide a plugin on top of the MuseScore music editor making the interaction with DeepBach easy to use.,abstractText,[0],[0]
DeepBach: a Steerable Model for Bach Chorales Generation ,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1125–1135 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
User comments play a central role in social media and online discussion fora.,1 Introduction,[0],[0]
"News portals and blogs often also allow their readers to comment to get feedback, engage their readers, and build customer loyalty.1 User comments, however, and more generally user content can also be abusive (e.g., bullying, profanity, hate speech) (Cheng et al., 2015).",1 Introduction,[0],[0]
"Social media are under pressure to combat abusive content, but so far rely mostly on user reports and tools that detect frequent words and phrases of reported posts.2 Wulczyn et al. (2017) estimated that only 17.9% of personal attacks in Wikipedia discussions were followed by moderator actions.",1 Introduction,[0],[0]
"News portals also
1 See, for example, http://niemanreports.org/ articles/the-future-of-comments/.
2 Consult, for example, https://www.facebook.",1 Introduction,[0],[0]
com/help/131671940241729 and https://www.,1 Introduction,[0],[0]
"theguardian.com/technology/2017/feb/07/ twitter-abuse-harassment-crackdown.
suffer from abusive user comments, which damage their reputations and make them liable to fines, e.g., when hosting comments encouraging illegal actions.",1 Introduction,[0],[0]
"They often employ moderators, who are frequently overwhelmed, however, by the volume and abusiveness of comments.3 Readers are disappointed when non-abusive comments do not appear quickly online because of moderation delays.",1 Introduction,[0],[0]
"Smaller news portals may be unable to employ moderators, and some are forced to shut down their comments sections entirely.
",1 Introduction,[0],[0]
"We examine how deep learning (Goodfellow et al., 2016; Goldberg, 2016, 2017) can be employed to moderate user comments.",1 Introduction,[0],[0]
We experiment with a new dataset of approx.,1 Introduction,[0],[0]
"1.6M manually moderated (accepted or rejected) user comments from a Greek sports news portal (called Gazzetta), which we make publicly available.4 This is one of the largest publicly available datasets of moderated user comments.",1 Introduction,[0],[0]
We also provide word embeddings pre-trained on 5.2M comments from the same portal.,1 Introduction,[0],[0]
"Furthermore, we experiment on the ‘attacks’ dataset of Wulczyn et al. (2017), approx.",1 Introduction,[0],[0]
"115K English Wikipedia talk page comments labeled as containing personal attacks or not.
",1 Introduction,[0],[0]
"In a fully automatic scenario, there is no moderator and a system accepts or rejects comments.",1 Introduction,[0],[0]
"Although this scenario may be the only available one, e.g., when news portals cannot afford moderators, it is unrealistic to expect that fully automatic moderation will be perfect, because abusive comments may involve irony, sarcasm, harassment without profane phrases etc., which are particularly difficult for a machine to detect.",1 Introduction,[0],[0]
"When moderators are available, it is more realistic to develop semi-
3See, e.g., https://www.wired.com/2017/04/ zerochaos-google-ads-quality-raters and https://goo.gl/89M2bI.
4The portal is http://www.gazzetta.gr/. Instructions to download the dataset will become available at http://nlp.cs.aueb.gr/software.html.
1125
automatic systems aiming to assist, rather than replace the moderators, a scenario that has not been considered in previous work.",1 Introduction,[0],[0]
"In this case, comments for which the system is uncertain (Fig. 1) are shown to a moderator to decide; all other comments are accepted or rejected by the system.",1 Introduction,[0],[0]
"We discuss how moderation systems can be tuned, depending on the availability and workload of the moderators.",1 Introduction,[0],[0]
"We also introduce additional evaluation measures for the semi-automatic scenario.
",1 Introduction,[0],[0]
"On both datasets (Gazzetta and Wikipedia comments) and for both scenarios (automatic, semiautomatic), we show that a recurrent neural network (RNN) outperforms the system of Wulczyn et al. (2017), the previous state of the art for comment moderation, which employed logistic regression or a multi-layer Perceptron (MLP), and represented each comment as a bag of (character or word) n",1 Introduction,[0],[0]
-grams.,1 Introduction,[0],[0]
We also propose an attention mechanism that improves the overall performance of the RNN.,1 Introduction,[0],[0]
"Our attention mechanism differs from most previous ones (Bahdanau et al., 2015; Luong et al., 2015) in that it is used in a classification setting, where there is no previously generated output subsequence to drive the attention, unlike sequence-to-sequence models (Sutskever et al., 2014).",1 Introduction,[0],[0]
"In that sense, our attention is similar to that of of Yang et al. (2016), but our attention mechanism is a deeper MLP and it is only applied to words, whereas Yang et al. also have a second attention mechanism that assigns attention scores to entire sentences.",1 Introduction,[0],[0]
"In effect, our attention detects the words of a comment that affect most the classification decision (accept, reject), by examining them in the context of the particular comment.
",1 Introduction,[0],[0]
"Although our attention mechanism does not always improve the performance of the RNN, it has the additional advantage of allowing the RNN to highlight suspicious words that a moderator could consider to decide more quickly if a comment should be accepted or rejected.",1 Introduction,[0],[0]
"The highlighting
comes for free, i.e., the training data do not contain highlighted words.",1 Introduction,[0],[0]
"We also show that words highlighted by the attention mechanism correlate well with words that moderators would highlight.
",1 Introduction,[0],[0]
Our main contributions are: (i),1 Introduction,[0],[0]
We release a dataset of 1.6M moderated user comments.,1 Introduction,[0],[0]
"(ii) We introduce a novel, deep, classification-specific attention mechanism and we show that an RNN with our attention mechanism outperforms the previous state of the art in user comment moderation.",1 Introduction,[0],[0]
"(iii) Unlike previous work, we also consider a semiautomatic scenario, along with threshold tuning and evaluation measures for it.",1 Introduction,[0],[0]
"(iv) We show that the attention mechanism can automatically highlight suspicious words for free, without manually highlighting words in the training data.",1 Introduction,[0],[0]
"We first discuss the datasets we used, to help acquaint the reader with the problem.",2 Datasets,[0],[0]
There are approx.,2.1 Gazzetta comments,[0],[0]
"1.45M training comments (covering Jan. 1, 2015 to Oct. 6, 2016) in the Gazzetta dataset; we call them G-TRAIN-L (Table 1).",2.1 Gazzetta comments,[0],[0]
"Some experiments use only the first 100K comments of G-TRAIN-L, called G-TRAIN-S. An additional set of 60,900 comments (Oct. 7 to Nov. 11, 2016) was split to development (G-DEV, 29,700 comments), large test (G-TEST-L, 29,700), and small test set (G-TEST-S, 1,500).",2.1 Gazzetta comments,[0],[0]
"Gazzetta’s moderators (2 full-time, plus journalists occasionally helping) are occasionally instructed to be stricter (e.g., during violent events).",2.1 Gazzetta comments,[0],[0]
"To get a more accurate view of performance in normal situtations, we manually re-moderated (labeled as ‘accept’ or ‘reject’)",2.1 Gazzetta comments,[0],[0]
"the comments of G-TEST-S, producing G-TEST-SR.",2.1 Gazzetta comments,[0],[0]
The reject ratio is approx.,2.1 Gazzetta comments,[0],[0]
"30% in all subsets, except for G-TEST-S-R where it drops to 22%, because there are no occasions where the moderators were instructed to be stricter in G-TEST-S-R.
Each G-TEST-S-R comment was re-moderated by five annotators.",2.1 Gazzetta comments,[0],[0]
"Krippendorff’s (2004) alpha was 0.4762, close to the value (0.45) reported by Wulczyn et al. (2017) for the Wikipedia ‘attacks’ dataset.",2.1 Gazzetta comments,[0],[0]
"Using Cohen’s Kappa (Cohen, 1960), the mean pairwise agreement was 0.4749.",2.1 Gazzetta comments,[0],[0]
The mean pairwise percentage of agreement (% of comments each pair of annotators agreed on) was 81.33%.,2.1 Gazzetta comments,[0],[0]
"Cohen’s Kappa and Krippendorff’s alpha lead to lower scores, because they account for agreement by chance, which is high when there is class imbalance (22% reject, 78% accept in G-TEST-S-R).
",2.1 Gazzetta comments,[0],[0]
"During the re-moderation of G-TEST-S-R, the annotators were also asked to highlight snippets they considered suspicious, i.e., words or phrases that could lead a moderator to consider rejecting each comment.5",2.1 Gazzetta comments,[0],[0]
"We also asked the annotators to classify each snippet into one of the following categories: calumniation (e.g., false accusations), discrimination (e.g., racism), disrespect (e.g., looking down at a profession), hooliganism (e.g., calling for violence), insult (e.g., making fun of appearance), irony, swearing, threat, other.",2.1 Gazzetta comments,[0],[0]
"Figure 2 shows how many comments of G-TEST-S-R contained at least one snippet of each category, according to the majority of annotators; e.g., a comment counts as containing irony if at least 3 annotators annotated it with an irony snippet (not necessarily the same).",2.1 Gazzetta comments,[0],[0]
The gold class of each comment (accept or reject) is determined by the majority of the annotators.,2.1 Gazzetta comments,[0],[0]
"Irony and disrespect are particularly frequent in both classes, followed by calumniation, swearing, hooliganism, insults.",2.1 Gazzetta comments,[0],[0]
"Notice that comments that contain irony, disrespect etc. are not necessarily rejected.",2.1 Gazzetta comments,[0],[0]
"They are, however, more likely in the rejected class, considering that the accepted comments are 2.5 times more
5Treating snippet overlaps as agreements, the mean pairwise Dice coefficient for snippet highlighting was 50.03%.
",2.1 Gazzetta comments,[0],[0]
than the rejected ones (78% vs. 22%).,2.1 Gazzetta comments,[0],[0]
"We also provide 300-dimensional word embeddings, pre-trained on approx.",2.1 Gazzetta comments,[0],[0]
"5.2M comments (268M tokens) from Gazzetta using WORD2VEC (Mikolov et al., 2013a,b).6 This larger dataset cannot be used to directly train classifiers, because most of its comments are from a period (before 2015) when Gazzetta did not employ moderators.",2.1 Gazzetta comments,[0],[0]
"The Wikipedia ‘attacks’ dataset (Wulczyn et al., 2017) contains approx.",2.2 Wikipedia comments,[0],[0]
"115K English Wikipedia talk page comments, which were labeled as containing personal attacks or not.",2.2 Wikipedia comments,[0],[0]
Each comment was labeled by at least 10 annotators.,2.2 Wikipedia comments,[0],[0]
"Inter-annotator agreement, measured on a random sample of 1K comments using Krippendorff’s (2004) alpha, was 0.45.",2.2 Wikipedia comments,[0],[0]
"The gold label of each comment is determined by the majority of annotators, leading to binary labels (accept, reject).",2.2 Wikipedia comments,[0],[0]
"Alternatively, the gold label is the percentage of annotators that labeled the comment as ‘accept’ (or ‘reject’), leading to probabilistic labels.7",2.2 Wikipedia comments,[0],[0]
"The dataset is split in three parts (Table 1): training (W-ATT-TRAIN, 69,526 comments), development (W-ATT-DEV, 23,160), and test (W-ATT-TEST, 23,178).",2.2 Wikipedia comments,[0],[0]
"In all three parts, the rejected comments are 12%, but this is an artificial ratio (Wulczyn et al. oversampled comments posted by banned users).",2.2 Wikipedia comments,[0],[0]
"By contrast, the ratio of rejected comments in all the Gazzetta subsets is the truly observed one.",2.2 Wikipedia comments,[0],[0]
"The Wikipedia comments are also longer (median length 38 tokens) compared to Gazzetta’s (median length 25 tokens).
",2.2 Wikipedia comments,[0],[0]
"Wulczyn et al. (2017) also provide two additional datasets of English Wikipedia talk page comments, which are not used in this paper.",2.2 Wikipedia comments,[0],[0]
"The first one, called ‘aggression’ dataset, contains the same comments as the ‘attacks’ dataset, now labeled as ‘aggressive’ or not.",2.2 Wikipedia comments,[0],[0]
"The (probabilistic) labels of the ‘attacks’ and ‘aggression’ datasets are very highly correlated (0.8992 Spearman, 0.9718 Pearson) and we did not consider the aggression dataset any further.",2.2 Wikipedia comments,[0],[0]
"The second additional dataset, called ‘toxicity’ dataset, contains approx.",2.2 Wikipedia comments,[0],[0]
160K comments labeled as being toxic or not.,2.2 Wikipedia comments,[0],[0]
"Experiments we reported elsewhere (Pavlopoulos et al., 2017) show that results on the ‘attacks’ and ‘toxicity’ datasets are very similar; we do not include
6We used CBOW, window size 5, min. term freq.",2.2 Wikipedia comments,[0],[0]
"5, negative sampling, obtaining a vocabulary size of approx.",2.2 Wikipedia comments,[0],[0]
"478K.
7 We also construct probabilistic labels for G-TEST-S-R, where there are five annotators.
results on the latter in this paper to save space.",2.2 Wikipedia comments,[0],[0]
"We experimented with an RNN operating on word embeddings, the same RNN enhanced with our attention mechanism (a-RNN), a vanilla convolutional neural network (CNN) also operating on word embeddings, the DETOX system of Wulczyn et al. (2017), and a baseline that uses word lists.",3 Methods,[0],[0]
"DETOX (Wulczyn et al., 2017) was the previous state of the art in comment moderation, in the sense that it had the best reported results on the Wikipedia datasets (Section 2.2), which were in turn the largest previous publicly available dataset of moderated user comments.8 DETOX represents each comment as a bag of word n-grams (n ≤ 2, each comment becomes a bag containing its 1- grams and 2-grams) or a bag of character n-grams (n ≤ 5, each comment becomes a bag containing character 1-grams, . . .",3.1 DETOX,[0],[0]
", 5-grams).",3.1 DETOX,[0],[0]
"DETOX can rely on a logistic regression (LR) or MLP classifier, and it can use binary or probabilistic gold labels (Section 2.2) during training.
",3.1 DETOX,[0],[0]
"We used the DETOX implementation provided by Wulczyn et al. and the same grid search (and code) to tune the hyper-parameters of DETOX that select word or character n-grams, classifier (LR or MLP), and gold labels (binary or probabilistic).",3.1 DETOX,[0],[0]
"For Gazzetta, only binary gold labels were possible, since G-TRAIN-L and G-TRAIN-S have a single gold label per comment.",3.1 DETOX,[0],[0]
"Unlike Wulczyn et al., we tuned the hyper-parameters by evaluating (computing AUC and Spearman, Section 4) on a random 2% of held-out comments of W-ATTTRAIN or G-TRAIN-S, instead of the development subsets, to be able to obtain more realistic results from the development sets while developing the methods.",3.1 DETOX,[0],[0]
"For both Wikipedia and Gazzetta, the tuning selected character n-grams, as in the work of Wulczyn et al.",3.1 DETOX,[0],[0]
"Also, for both Wikipedia and Gazzetta, it preferred LR to MLP, whereas Wulczyn et al. reported slightly higher performance
8Two of the co-authors of Wulczyn et al. (2017) are with Jigsaw, who recently announced Perspective, a system to detect ‘toxic’ comments.",3.1 DETOX,[0],[0]
"Perspective is not the same as DETOX (personal communication), but we were unable to obtain scientific articles describing it.",3.1 DETOX,[0],[0]
An API for Perspective is available at https://www.perspectiveapi.,3.1 DETOX,[0],[0]
"com/, but we did not have access to the API at the time the experiments of this paper were carried out.
for the MLP on W-ATT-DEV.9",3.1 DETOX,[0],[0]
"The tuning also selected probabilistic labels for Wikipedia, as in the work of Wulczyn et al.",3.1 DETOX,[0],[0]
RNN:,3.2 RNN-based methods,[0],[0]
"The RNN method is a chain of GRU cells (Cho et al., 2014) that transforms the tokens w1 . .",3.2 RNN-based methods,[0],[0]
.,3.2 RNN-based methods,[0],[0]
", wk of each comment to the hidden states h1 . . .",3.2 RNN-based methods,[0],[0]
", hk, followed by an LR layer that uses hk to classify the comment (accept, reject).",3.2 RNN-based methods,[0],[0]
"Formally, given the vocabulary V , a matrixE ∈ Rd×|V | containing d-dimensional word embeddings, an initial h0, and a comment c = 〈w1, . . .",3.2 RNN-based methods,[0],[0]
", wk〉, the RNN computes h1, . . .",3.2 RNN-based methods,[0],[0]
", hk as follows (ht ∈ Rm):
h̃t = tanh(Whxt + Uh(rt ht−1) + bh) ht = (1− zt) ht−1",3.2 RNN-based methods,[0],[0]
+ zt h̃t zt = σ(Wzxt + Uzht−1 + bz) rt = σ(Wrxt + Urht−1,3.2 RNN-based methods,[0],[0]
"+ br)
where h̃t ∈ Rm is the proposed hidden state at position t, obtained by considering the word embedding xt of token wt and the previous hidden state ht−1; denotes element-wise multiplication; rt ∈ Rm is the reset gate (for rt all zeros, it allows the RNN to forget the previous state ht−1); zt ∈ Rm is the update gate (for zt all zeros, it allows the RNN to ignore the new proposed h̃t, hence also xt, and copy ht−1 as ht); σ is the sigmoid function; Wh,Wz,Wr ∈ Rm×d; Uh, Uz, Ur ∈ Rm×m; bh, bz, br ∈ Rm.",3.2 RNN-based methods,[0],[0]
"Once hk has been computed, the LR layer estimates the probability that comment c should be rejected, with Wp ∈ R1×m, bp ∈ R:
PRNN(reject|c) = σ(Wphk + bp)
a-RNN: When the attention mechanism is added, the LR layer considers the weighted sum hsum of all the hidden states, instead of",3.2 RNN-based methods,[0],[0]
just hk (Fig.,3.2 RNN-based methods,[0],[0]
"3):10
hsum = k∑ t=1 atht (1)
Pa−RNN(reject|c) = σ(Wphsum + bp)
",3.2 RNN-based methods,[0],[0]
"The weights at are produced by an attention mech-
9We repeated the tuning by evaluating on W-ATT-DEV, and again character n-grams with LR were selected.
",3.2 RNN-based methods,[0],[0]
"10We tried replacing the LR layer by a deeper classification MLP, and the RNN chain by a bidirectional RNN (Schuster and Paliwal, 1997), but there were no improvements.
",3.2 RNN-based methods,[0],[0]
"anism, which is an MLP with l layers:
a (1) t = RELU(W (1)ht + b(1)) (2) . .",3.2 RNN-based methods,[0],[0]
".
",3.2 RNN-based methods,[0],[0]
a (l−1) t = RELU(W (l−1)a(l−2)t + b,3.2 RNN-based methods,[0],[0]
"(l−1))
",3.2 RNN-based methods,[0],[0]
a (l) t = W (l)a (l−1) t + b,3.2 RNN-based methods,[0],[0]
"(l)
at = softmax(a (l) t ; a (l) 1 , . . .",3.2 RNN-based methods,[0],[0]
", a (l) k ) (3)
where a(1)t , . . .",3.2 RNN-based methods,[0],[0]
", a (l−1) t ∈",3.2 RNN-based methods,[0],[0]
"Rr, a(l)t , at ∈ R, W (1) ∈",3.2 RNN-based methods,[0],[0]
"Rr×m, W (2), . . .",3.2 RNN-based methods,[0],[0]
",W (l−1) ∈",3.2 RNN-based methods,[0],[0]
"Rr×r, W (l) ∈",3.2 RNN-based methods,[0],[0]
"R1×r, b(1), . . .",3.2 RNN-based methods,[0],[0]
", b(l−1) ∈",3.2 RNN-based methods,[0],[0]
"Rr, b(l) ∈",3.2 RNN-based methods,[0],[0]
R.,3.2 RNN-based methods,[0],[0]
"The softmax operates across the a(l)t (t = 1, . . .",3.2 RNN-based methods,[0],[0]
", k), making the weights at sum to 1.",3.2 RNN-based methods,[0],[0]
"Our attention mechanism differs from most previous ones (Mnih et al., 2014; Bahdanau et al., 2015; Xu et al., 2015; Luong et al., 2015) in that it is used in a classification setting, where there is no previously generated output subsequence (e.g., partly generated translation) to drive the attention (e.g., assign more weight to source words to translate next), unlike seq2seq models (Sutskever et al., 2014).",3.2 RNN-based methods,[0],[0]
"It assigns larger weights at to hidden states ht corresponding to positions where there is more evidence that the comment should be accepted or rejected.
",3.2 RNN-based methods,[0],[0]
"Yang et al. (2016) use a similar attention mechanism, but ours is deeper.",3.2 RNN-based methods,[0],[0]
"In effect they always set l = 2, whereas we allow l to be larger (tuning selects l = 4).11",3.2 RNN-based methods,[0],[0]
"On the other hand, the attention mechanism of Yang et al. is part of a classification method for longer texts (e.g., product reviews).",3.2 RNN-based methods,[0],[0]
"Their method uses two GRU RNNs, both bidirectional (Schuster and Paliwal, 1997), one turning the word embeddings of each sentence to a sentence embedding, and one turning the sentence embeddings to a document embedding, which is then fed to an LR layer.",3.2 RNN-based methods,[0],[0]
"Yang et al. use their attention mechanism in both RNNs, to assign attention scores to words and sentences.",3.2 RNN-based methods,[0],[0]
"We consider shorter texts (comments), we have a single RNN, and we assign attention scores to words only.12
da-CENT: We also experiment with a variant of a-RNN, called da-CENT, which does not use the hidden states of the RNN.",3.2 RNN-based methods,[0],[0]
"The input to the first layer of the attention mechanism is now directly the embedding xt instead of ht (cf. Eq. 2), and
11Yang et al. use tanh instead of RELU in Eq. 2, which works worse in our case, and no bias b(l) in the l-th layer.
",3.2 RNN-based methods,[0],[0]
"12We tried a bidirectional instead of unidirectional GRU chain in our methods, also replacing the LR layer by a deeper classification MLP, but there were no improvements.
hsum is now the weighted sum (centroid) of word embeddings hsum = ∑k t=1 atxt (cf. Eq. 1).",3.2 RNN-based methods,[0],[0]
"13
We set l = 4, d = 300, r = m = 128, having tuned all hyper-parameters on the same 2% held-out comments of W-ATT-TRAIN or G-TRAINS that were used to tune DETOX.",3.2 RNN-based methods,[0],[0]
"We use Glorot initialization (Glorot and Bengio, 2010), categorical cross-entropy loss, and Adam (Kingma and Ba, 2015).14",3.2 RNN-based methods,[0],[0]
Early stopping evaluates on the same held-out subsets.,3.2 RNN-based methods,[0],[0]
"For Gazzetta, word embeddings are initialized to the WORD2VEC embeddings we provide (Section 2.1).",3.2 RNN-based methods,[0],[0]
"For Wikipedia, they are initialized to GLOVE embeddings (Pennington et al., 2014).15",3.2 RNN-based methods,[0],[0]
"In both cases, the embeddings are updated during backpropagation.",3.2 RNN-based methods,[0],[0]
"Out of vocabulary (OOV) words, meaning words for which we have no initial embeddings, are mapped to a single randomly initialized embedding, also updated.",3.2 RNN-based methods,[0],[0]
We also compare against a vanilla CNN operating on word embeddings.,3.3 CNN,[0],[0]
"We describe the CNN only briefly, because it is very similar to that of of Kim (2014); see also Goldberg (2016) for an introduction to CNNs, and Zhang and Wallace (2015).
",3.3 CNN,[0],[0]
"For Wikipedia comments, we use a ‘narrow’ convolution layer, with kernels sliding (stride 1) over (entire) embeddings of word n-grams of sizes n = 1, . . .",3.3 CNN,[0],[0]
", 4.",3.3 CNN,[0],[0]
"We use 300 kernels for each n value, a total of 1,200 kernels.",3.3 CNN,[0],[0]
"The outputs of each kernel, obtained by applying the kernel to the different n-grams of a comment c, are then
13 For experiments with additional variants of a-RNN, consult Pavlopoulos et al. (2017).
",3.3 CNN,[0],[0]
"14We implemented the methods of this sub-section using Keras (keras.io) and TensorFlow (tensorflow.org).
",3.3 CNN,[0],[0]
"15See https://nlp.stanford.edu/projects/ glove/. We use ‘Common Crawl’ (840B tokens).
",3.3 CNN,[0],[0]
"max-pooled, leading to a single output per kernel.",3.3 CNN,[0],[0]
"The resulting feature vector (1,200 maxpooled outputs) goes through a dropout layer (Hinton et al., 2012) (p = 0.5), and then to an LR layer, which provides PCNN(reject|c).",3.3 CNN,[0],[0]
"For Gazzetta, the CNN is the same, except that n = 1, . . .",3.3 CNN,[0],[0]
", 5, leading to 1,500 features per comment.",3.3 CNN,[0],[0]
All hyperparameters were tuned on the 2% held-out comments of W-ATT-TRAIN or G-TRAIN-S that were used to tune the other methods.,3.3 CNN,[0],[0]
"Again, we use 300-dimensional embeddings, which are now randomly initialized, since tuning indicated this was better than initializing to pre-trained embeddings.",3.3 CNN,[0],[0]
OOV words are treated as in the RNN-based methods.,3.3 CNN,[0],[0]
All embeddings are updated during backpropagation.,3.3 CNN,[0],[0]
Early stopping evaluates on the heldout subsets.,3.3 CNN,[0],[0]
"Again, we use Glorot initialization, categorical cross-entropy loss, and Adam.16",3.3 CNN,[0],[0]
"A baseline, called LIST, collects every word w that occurs in more than 10 (for W-ATT-TRAIN, G-TRAIN-S) or 100 comments (for G-TRAIN-L) in the training set, along with the precision of w, i.e., the ratio of rejected training comments containing w divided by the total number of training comments containing",3.4 LIST baseline,[0],[0]
w.,3.4 LIST baseline,[0],[0]
"The resulting lists contain 10,423, 16,864, and 21,940 word types, when using W-ATT-TRAIN, G-TRAIN-S, G-TRAIN-L, respectively.",3.4 LIST baseline,[0],[0]
"For a comment c, LIST returns as PLIST(reject|c) the maximum precision of all the words in c.",3.4 LIST baseline,[0],[0]
"All methods produce a p = P (reject|c) per comment c. In semi-automatic moderation (Fig. 1), a comment is directly rejected if its p is above a rejection theshold tr, it is directly accepted if p is below an acceptance threshold ta, and it is shown to a moderator if ta ≤ p ≤ tr (gray zone of Fig. 4).
",3.5 Tuning thresholds,[0],[0]
"In our experience, moderators (or their employers) can easily specify the approximate percentage of comments they can afford to check manually (e.g., 20% daily) or, equivalently, the approximate percentage of comments the system should
16We implemented the CNN directly in TensorFlow.
handle automatically.",3.5 Tuning thresholds,[0],[0]
"We call coverage the latter percentage; hence, 1 − coverage is the approximate percentage of comments to be checked manually.",3.5 Tuning thresholds,[0],[0]
"By contrast, moderators are baffled when asked to tune tr and ta directly.",3.5 Tuning thresholds,[0],[0]
"Consequently, we ask them to specify the approximate desired coverage.",3.5 Tuning thresholds,[0],[0]
"We then sort the comments of the development set (G-DEV or W-ATT-DEV) by p, and slide ta from 0.0 to 1.0 (Fig. 4).",3.5 Tuning thresholds,[0],[0]
"For each ta value, we set tr to the value that leaves a 1 − coverage percentage of development comments in the gray zone (ta ≤ p ≤ tr).",3.5 Tuning thresholds,[0],[0]
"We then select the ta (and tr) that maximizes the weighted harmonic mean Fβ(Preject, Paccept) on the development set:
Fβ(Preject, Paccept) =",3.5 Tuning thresholds,[0],[0]
"(1 + β2) · Preject · Paccept β2 · Preject + Paccept
where Preject is the rejection precision (correctly rejected comments divided by rejected comments) and Paccept is the acceptance precision (correctly accepted divided by accepted).",3.5 Tuning thresholds,[0],[0]
"Intuitively, coverage sets the width of the gray zone, whereas Preject and Paccept show how certain we can be that the red (reject) and green (accept) zones are free of misclassified comments.",3.5 Tuning thresholds,[0],[0]
"We set β = 2, emphasizing Paccept, because moderators are more worried about wrongly accepting abusive comments than wrongly rejecting non-abusive ones.17 The selected ta, tr (tuned on development data) are then used in experiments on test data.",3.5 Tuning thresholds,[0],[0]
"In fully automatic moderation, coverage = 100 and ta = tr; otherwise, threshold tuning is identical.",3.5 Tuning thresholds,[0],[0]
"Following Wulczyn et al. (2017), we report in Table 2 AUC scores (area under ROC curve), along with Spearman correlations between systemgenerated probabilities P (accept|c) and human probabilistic gold labels (Section 2.2) when probabilistic gold labels are available.18",4.1 Comment classification evaluation,[0],[0]
"Wulczyn et al. reported DETOX results only on W-ATT-DEV, shown in brackets.",4.1 Comment classification evaluation,[0],[0]
"Table 2 shows that RNN is
17More precisely, when computing Fβ , we reorder the development comments by time posted, and split them into batches of 100.",4.1 Comment classification evaluation,[0],[0]
"For each ta (and tr) value, we compute Fβ per batch and macro-average across batches.",4.1 Comment classification evaluation,[0],[0]
"The resulting thresholds lead to Fβ scores that are more stable over time.
",4.1 Comment classification evaluation,[0],[0]
"18When computing AUC, the gold label is the majority label of the annotators.",4.1 Comment classification evaluation,[0],[0]
"When computing Spearman, the gold label is probabilistic (% of annotators that accepted the comment).",4.1 Comment classification evaluation,[0],[0]
"The decisions of the systems are always probabilistic.
always better than CNN and DETOX; there is no clear winner between CNN and DETOX.",4.1 Comment classification evaluation,[0],[0]
"Furthermore, a-RNN is always better than RNN on Gazzetta comments, but not on Wikipedia comments, where RNN is overall slightly better according to Table 2.",4.1 Comment classification evaluation,[0],[0]
"Also, da-CENT is always worse than a-RNN and RNN, confirming that the hidden states (intuitively, context-aware word embeddings) of the RNN chain are important, even with the attention mechanism.",4.1 Comment classification evaluation,[0],[0]
Increasing the size of the Gazzetta training set (G-TRAIN-S to G-TRAINL) significantly improves the performance of all methods.,4.1 Comment classification evaluation,[0],[0]
"The implementation of DETOX could not handle the size of G-TRAIN-L, which is why we do not report DETOX results for G-TRAIN-L. Notice, also, that the Wikipedia dataset is easier than the Gazzetta one (all methods perform better on Wikipedia comments, compared to Gazzetta).
",4.1 Comment classification evaluation,[0],[0]
"Figure 5 shows F2(Preject, Paccept) on G-TESTL and W-ATT-TEST, when ta, tr are tuned on GDEV, W-ATT-DEV for varying coverage.",4.1 Comment classification evaluation,[0],[0]
"For GTEST-L, we show results training on G-TRAIN-S (solid lines) and G-TRAIN-L (dotted).",4.1 Comment classification evaluation,[0],[0]
"The differ-
ences between RNN and a-RNN are again small, but it is now easier to see that a-RNN is overall better.",4.1 Comment classification evaluation,[0],[0]
"Again, a-RNN and RNN are better than CNN and DETOX.",4.1 Comment classification evaluation,[0],[0]
All three deep learning methods benefit from the larger training set (dotted).,4.1 Comment classification evaluation,[0],[0]
"In Wikipedia, a-RNN obtains Paccept, Preject ≥ 0.94 for all coverages (Fig. 5, call-outs).",4.1 Comment classification evaluation,[0],[0]
"On the more difficult Gazzetta dataset, a-RNN still obtains Paccept, Preject ≥ 0.85 when tuned for 50% coverage.",4.1 Comment classification evaluation,[0],[0]
"When tuned for 100% coverage, comments for which the system is uncertain (gray zone) cannot be avoided and there are inevitably more misclassifications; the use of F2 during threshold tuning places more emphasis on avoiding wrongly accepted comments, leading to high Paccept (0.82), at the expense of wrongly rejected comments, i.e., sacrificing Preject (0.59).",4.1 Comment classification evaluation,[0],[0]
"On the re-moderated G-TEST-S-R (similar diagrams, not shown), Paccept, Preject become 0.96, 0.88 for coverage 50%, and 0.92, 0.48 for coverage 100%.
",4.1 Comment classification evaluation,[0],[0]
"We also repeated the annotator ensemble experiment of Wulczyn et al. (2017) on 8K randomly chosen comments of W-ATT-TEST (4K comments
from random users, 4K comments from banned users).19 The decisions of 10 randomly chosen annotators (possibly different per comment) were used to construct the gold label of each comment.",4.1 Comment classification evaluation,[0],[0]
"The gold labels were then compared to the decisions of the systems and the decisions of an ensemble of k other annotators, k ranging from 1 to 10.",4.1 Comment classification evaluation,[0],[0]
"Table 3 shows the mean AUC and Spearman scores, averaged over 25 runs of the experiment, along with standard errrors (in brackets).",4.1 Comment classification evaluation,[0],[0]
"We conclude that RNN and a-RNN are as good as an ensemble of 7 human annotators; CNN is as good as 4 annotators; DETOX is as good as 4 in AUC and 3 annotators in Spearman correlation, which is consistent with the results of Wulczyn et al. (2017).",4.1 Comment classification evaluation,[0],[0]
"To investigate if the attention scores of a-RNN can highlight suspicious words, we focused on GTEST-S-R, the only dataset with suspicious snippets annotated by humans.",4.2 Snippet highlighting evaluation,[0],[0]
"We removed comments with no human-annotated snippets, leaving 841 comments (515 accepted, 326 rejected), a total of 40,572 tokens, of which 13,146 were inside a suspicious snippet of at least one annotator.",4.2 Snippet highlighting evaluation,[0],[0]
"In each remaining comment, each token was assigned a gold suspiciousness score, defined as the percentage of annotators that included it in their snippets.
",4.2 Snippet highlighting evaluation,[0],[0]
We evaluated three methods that score each token wt of a comment c for suspiciousness.,4.2 Snippet highlighting evaluation,[0],[0]
"The first one assigns to each wt the attention score at
19We used the protocol, code, and data of Wulczyn et al.
",4.2 Snippet highlighting evaluation,[0],[0]
(Eq. 3) of a-RNN (trained on G-TRAIN-L).,4.2 Snippet highlighting evaluation,[0],[0]
"The second method assigns to each wt its precision, as computed by LIST (Section 3.4).",4.2 Snippet highlighting evaluation,[0],[0]
The third method (RAND) assigns to each wt a random (uniform distribution) score between 0 and 1.,4.2 Snippet highlighting evaluation,[0],[0]
"In the latter two methods, a softmax is applied to the scores of all the tokens per comment, as in a-RNN.",4.2 Snippet highlighting evaluation,[0],[0]
"Figure 6 shows three comments (from W-ATT-TEST) highlighted by a-RNN; heat corresponds to attention.20
We computed Pearson and Spearman correlations between the gold suspiciousness scores and the scores of the three methods on the 40,572 tokens.",4.2 Snippet highlighting evaluation,[0],[0]
Figure 7 shows the correlations on comments that were accepted (left) and rejected (right) by the majority of moderators.,4.2 Snippet highlighting evaluation,[0],[0]
"In both cases, a-RNN performs better than LIST and RAND by both Pearson and Spearman correlations.",4.2 Snippet highlighting evaluation,[0],[0]
The high Pearson correlations of a-RNN also show that its attention scores are to a large extent linearly related to the gold ones.,4.2 Snippet highlighting evaluation,[0],[0]
"By contrast, LIST performs reasonably well in terms of Spearman correlation, but much worse in terms of Pearson, indicating that its precision scores rank reasonably well the tokens from most to least suspicious ones, but are not linearly related to the gold scores.",4.2 Snippet highlighting evaluation,[0],[0]
"Djuric et al. (2015) experimented with 952K manually moderated comments from Yahoo Finance, but their dataset is not publicly available.",5 Related work,[0],[0]
"They convert each comment to a comment embedding using DOC2VEC (Le and Mikolov, 2014), which is then fed to an LR classifier.",5 Related work,[0],[0]
Nobata et al. (2016) experimented with approx.,5 Related work,[0],[0]
3.3M manually moderated comments from Yahoo Finance and News,5 Related work,[0],[0]
; their data are also not available.21,5 Related work,[0],[0]
"They used Vowpal Wabbit22 with character n-grams (n = 3, . . .",5 Related work,[0],[0]
", 5) and word n-grams (n = 1, 2), handcrafted features (e.g., number of capitalized or black-listed words), features based on dependency
20In innocent comments, a-RNN spreads its attention to all tokens, leading to quasi-uniform low color intensity.
21According to Nobata et al., their clean test dataset (2K comments) would be made available, but it is currently not.
22See http://hunch.net/˜vw/.
trees, averages of WORD2VEC embeddings, and DOC2VEC-like embeddings.",5 Related work,[0],[0]
Character n,5 Related work,[0],[0]
"-grams were the best, on their own outperforming Djuric et al. (2015).",5 Related work,[0],[0]
"The best results, however, were obtained using all features.",5 Related work,[0],[0]
"We use no hand-crafted features and parsers, making our methods more easily portable to other domains and languages.
",5 Related work,[0],[0]
"Mehdad et al. (2016) train a (token or characterbased) RNN language model per class (accept, reject), and use the probability ratio of the two models to accept or reject user comments.",5 Related work,[0],[0]
"Experiments on the dataset of Djuric et al. (2015), however, showed that their method (RNNLMs) performed worse than a combination of SVM and Naive Bayes classifiers (NBSVM) that used character and token n-grams.",5 Related work,[0],[0]
"An LR classifier operating on DOC2VEC-like comment embeddings (Le and Mikolov, 2014) also performed worse than NBSVM.",5 Related work,[0],[0]
"To surpass NBSVM, Mehdad et al. used an SVM to combine features from their three other methods (RNNLMs, LR with DOC2VEC, NBSVM).
",5 Related work,[0],[0]
Wulczyn et al. (2017) experimented with character and word n-grams.,5 Related work,[0],[0]
We included their dataset and moderation system (DETOX) in our experiments.,5 Related work,[0],[0]
Waseem et al. (2016) used approx.,5 Related work,[0],[0]
17K tweets annotated for hate speech.,5 Related work,[0],[0]
"Their best results were obtained using an LR classifier with character n-grams (n = 1, . . .",5 Related work,[0],[0]
", 4), plus gender.",5 Related work,[0],[0]
"Warner and Hirschberg (2012) aimed to detect anti-semitic speech, experimenting with 9K paragraphs and a linear SVM.",5 Related work,[0],[0]
"Their features consider windows of at most 5 tokens, examining the tokens of each window, their order, POS tags, Brown clusters etc., following Yarowsky (1994).
",5 Related work,[0],[0]
Cheng et al. (2015) aimed to predict which users would be banned from on-line communities.,5 Related work,[0],[0]
"Their best system used a random forest or LR classifier, with features examining readability, activity (e.g., number of posts daily), community and moderator reactions (e.g., up-votes, number of deleted posts).
",5 Related work,[0],[0]
"Sood et al. (2012a; 2012b) experimented with 6.5K comments from Yahoo Buzz, moderated via crowdsourcing.",5 Related work,[0],[0]
"They showed that a linear SVM, representing each comment as a bag of word bigrams and stems, performs better than word lists.",5 Related work,[0],[0]
"Their best results were obtained by combining the SVM with a word list and edit distance.
",5 Related work,[0],[0]
Yin et al. (2009) used posts from chat rooms and discussion fora (<15K posts in total) to train an SVM to detect online harassment.,5 Related work,[0],[0]
"They used TF-IDF, sentiment, and context features (e.g., sim-
ilarity to other posts in a thread).",5 Related work,[0],[0]
"Our methods might also benefit by considering threads, rather than individual comments.",5 Related work,[0],[0]
"Yin at al. point out that unlike other abusive content, spam in comments or dicsussion fora (Mishne et al., 2005; Niu et al., 2007) is off-topic and serves a commercial purpose.",5 Related work,[0],[0]
"Spam is unlikely in Wikipedia discussions and not an issue in the Gazzetta dataset (Fig. 2).
",5 Related work,[0],[0]
"For a more extensive discussion of related work, consult Pavlopoulos et al. (2017).",5 Related work,[0],[0]
We experimented with a new publicly available dataset of 1.6M moderated user comments from a Greek sports news portal and an existing dataset of 115K English Wikipedia talk page comments.,6 Conclusions,[0],[0]
"We showed that a GRU RNN operating on word embeddings outpeforms the previous state of the art, which used an LR or MLP classifier with character or word n-gram features, also outperforming a vanilla CNN operating on word embeddings, and a baseline that uses an automatically constructed word list with precision scores.",6 Conclusions,[0],[0]
"A novel, deep, classification-specific attention mechanism improves further the overall results of the RNN, and can also highlight suspicious words for free, without including highlighted words in the training data.",6 Conclusions,[0],[0]
"We considered both fully automatic and semi-automatic moderation, along with threshold tuning and evaluation measures for both.
",6 Conclusions,[0],[0]
"We plan to consider user-specific information (e.g., ratio of comments rejected in the past) (Cheng et al., 2015; Waseem and Hovy, 2016) and explore character-level RNNs or CNNs (Zhang et al., 2015), e.g., as a first layer to produce embeddings of unknown words from characters (dos Santos and Zadrozny, 2014; Ling et al., 2015), which would then be passed on to our current methods that operate on word embeddings.",6 Conclusions,[0],[0]
"This work was funded by Google’s Digital News Initiative (project ML2P, contract 362826).23 We are grateful to Gazzetta for the data they provided.",Acknowledgments,[0],[0]
"We also thank Gazzetta’s moderators for their feedback, insights, and advice.
23See https://digitalnewsinitiative.com/.",Acknowledgments,[0],[0]
"Experimenting with a new dataset of 1.6M user comments from a news portal and an existing dataset of 115K Wikipedia talk page comments, we show that an RNN operating on word embeddings outpeforms the previous state of the art in moderation, which used logistic regression or an MLP classifier with character or word n-grams.",abstractText,[0],[0]
"We also compare against a CNN operating on word embeddings, and a word-list baseline.",abstractText,[0],[0]
"A novel, deep, classificationspecific attention mechanism improves the performance of the RNN further, and can also highlight suspicious words for free, without including highlighted words in the training data.",abstractText,[0],[0]
We consider both fully automatic and semi-automatic moderation.,abstractText,[0],[0]
Deeper Attention to Abusive User Content Moderation,title,[0],[0]
"A fundamental challenge in artificial intelligence, robotics, and language processing is sequential prediction: to reason, plan, and make a sequence of predictions or decisions to minimize accumulated cost, achieve a long-term goal, or
1Robotics Institute, Carnegie Mellon University, USA 2Machine Learning Department, Carnegie Mellon University, USA 3College of Computing, Georgia Institute of Technology, USA.",1. Introduction,[0],[0]
"Correspondence to: Wen Sun <wensun@cs.cmu.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"optimize for a loss acquired only after many predictions.
",1. Introduction,[0],[0]
"Although conventional supervised learning of deep models has been pivotal in advancing performance in sequential prediction problems, researchers are beginning to utilize Reinforcement Learning (RL) methods to achieve even higher performance (Ranzato et al., 2015; Bahdanau et al., 2016; Li et al., 2016).",1. Introduction,[0],[0]
"In sequential prediction tasks, future predictions often depend on the history of previous predictions; thus, a poor prediction early in the sequence can lead to high loss (cost) for future predictions.",1. Introduction,[0],[0]
"Viewing the predictor as a policy ⇡, deep RL algorithms are able to reason about the future accumulated cost in sequential prediction problems.",1. Introduction,[0],[0]
"These approaches have dramatically advanced the state-of-the-art on a number of problems including high-dimensional robotics control tasks and video and board games (Schulman et al., 2015; Silver et al., 2016).
",1. Introduction,[0],[0]
"In contrast with general reinforcement learning methods, imitation learning and related sequential prediction algorithms such as SEARN (Daumé III et al., 2009), DaD (Venkatraman et al., 2015), AggreVaTe (Ross & Bagnell, 2014), and LOLS (Chang et al., 2015b) reduce the sequential prediction problems to supervised learning by leveraging a (near) optimal cost-to-go oracle that can be queried for the next (near)-best prediction at any point during training.",1. Introduction,[0],[0]
"Specifically, these methods assume access to an oracle that provides an optimal or near-optimal action and the future accumulated loss Q⇤, the so-called cost-to-go.",1. Introduction,[0],[0]
"For robotics control problems, this oracle may be a human expert guiding the robot during the training phase (Abbeel & Ng, 2004) or the policy from an optimal MDP solver (Ross et al., 2011; Kahn et al., 2016; Choudhury et al., 2017) that is either too slow to use at test time or leverages information unavailable at test time.",1. Introduction,[0],[0]
"For sequential prediction problems, an oracle can be constructed by optimization (e.g., beam search) or by a clairvoyant greedy algorithm (Daumé III et al., 2009; Ross et al., 2013; Rhinehart et al., 2015; Chang et al., 2015a) that, given the training data’s ground truth, is near-optimal on the task-specific performance metric (e.g., cumulative reward, IoU, Unlabeled Attachment Score, BLEU).
",1. Introduction,[0],[0]
"Expert, demonstrator, and oracle are used interchangeably.
",1. Introduction,[0],[0]
We stress that the oracle is only required to be available during training.,1. Introduction,[0],[0]
"Therefore, the goal of IL is to learn a policy ⇡̂ with the help of the oracle (⇡⇤, Q⇤) during the training session, such that ⇡̂ achieves similar or better performance at test time when the oracle is unavailable.",1. Introduction,[0],[0]
"In contrast to IL, reinforcement learning methods often initialize with a random policy ⇡
0 or cost-to-go estimate Q 0 that may be far from optimal.",1. Introduction,[0],[0]
"The optimal policy (or cost-to-go) must be found by exploring, often with random actions.
",1. Introduction,[0],[0]
A classic family of IL methods is to collect data from running the demonstrator or oracle and train a regressor or classifier via supervised learning.,1. Introduction,[0],[0]
"These methods (Abbeel & Ng, 2004; Syed et al., 2008; Ratliff et al., 2006; Ziebart et al., 2008; Finn et al., 2016; Ho & Ermon, 2016) learn either a policy ⇡̂⇤ or ˆQ⇤ from a fixed-size dataset precollected from the oracle.",1. Introduction,[0],[0]
"Unfortunately, these methods exhibit a pernicious problem: they require the training and test data to be sampled from the same distribution, despite the fact they explicitly change the sample policy during training.",1. Introduction,[0],[0]
"As a result, policies learned by these methods can fail spectacularly (Ross & Bagnell, 2010).",1. Introduction,[0],[0]
"Interactive approaches to IL such as SEARN (Daumé III et al., 2009), DAgger (Ross et al., 2011), and AggreVaTe (Ross & Bagnell, 2014) interleave learning and testing to overcome the data mismatch issue and, as a result, work well in practical applications.",1. Introduction,[0],[0]
"Furthermore, these interactive approaches can provide strong theoretical guarantees between training time loss and test time performance through a reduction to no-regret online learning.
",1. Introduction,[0],[0]
"In this work, we introduce AggreVaTeD, a differentiable version of AggreVaTe (Aggregate Values to Imitate (Ross & Bagnell, 2014)) which allows us to train policies with efficient gradient update procedures.",1. Introduction,[0],[0]
AggreVaTeD extends and scales interactive IL for use in sequential prediction and challenging continuous robot control tasks.,1. Introduction,[0],[0]
"We provide two gradient update procedures: a regular gradient update developed from Online Gradient Descent (OGD) (Zinkevich, 2003) and a natural gradient update (Kakade, 2002; Bagnell & Schneider, 2003), which is closely related to Weighted Majority (WM) (Littlestone & Warmuth, 1994), a popular no-regret algorithm that enjoys an almost dimension-free property (Bubeck et al., 2015).
",1. Introduction,[0],[0]
AggreVaTeD leverages the oracle to learn rich polices that can be represented by complicated non-linear function approximators.,1. Introduction,[0],[0]
"Our experiments with deep neural networks on various robotics control simulators and on a dependency parsing sequential prediction task show that AggreVaTeD can achieve expert-level performance and even super-expert performance when the oracle is sub-optimal, a result rarely achieved by non-interactive IL approaches.
",1. Introduction,[0],[0]
"i.e., the regret bound depends on poly-log of the dimension of parameter space.
",1. Introduction,[0],[0]
"The differentiable nature of AggreVaTeD additionally allows us to employ Recurrent Neural Network policies, e.g., Long Short-Term Memory (LSTM) (Hochreiter & Schmidhuber, 1997), to handle partially observable settings (e.g., observe only partial robot state).",1. Introduction,[0],[0]
"Empirical results demonstrate that by leveraging an oracle, IL can learn much faster than RL.
",1. Introduction,[0],[0]
"In addition to providing a set of practical algorithms, we develop a comprehensive theoretical study of IL on discrete MDPs.",1. Introduction,[0],[0]
We construct an MDP that demonstrates exponentially better sample efficiency for IL than any RL algorithm.,1. Introduction,[0],[0]
"For general discrete MDPs, we provide a regret upper bound for AggreVaTeD with WM, which shows IL can learn dramatically faster than RL.",1. Introduction,[0],[0]
"We provide a regret lower bound for any IL algorithm, which demonstrates that AggreVaTeD with WM is near-optimal.
",1. Introduction,[0],[0]
"To summarize the contributions of this work: (1) AggreVaTeD allows us to handle continuous action spaces and employ recurrent neural network policies for Partially Observable Markov Decision Processes (POMDPs); (2) understanding IL from a perspective that is related to policy gradient allows us to leverage advances from the wellstudied RL policy gradient literature (e.g., gradient variance reduction techniques, efficient natural gradient computation); (3) we provide a new sample complexity study of IL and compare to RL, showing that we can expect up to exponentially lower sample complexity.",1. Introduction,[0],[0]
"Our experimental and theoretical results support the proposition:
Imitation Learning is a more effective strategy than Reinforcement Learning for sequential prediction with near-optimal cost-to-go oracles.",1. Introduction,[0],[0]
"A Markov Decision Process consists of a set of states, actions (that come from a policy), cost (loss), and a model that transitions states given actions.",2. Preliminaries,[0],[0]
"Interestingly, most sequential prediction problems can be framed in terms of MDPs (Daumé III et al., 2009).",2. Preliminaries,[0],[0]
"The actions are the learner’s (e.g., RNN’s) predictions.",2. Preliminaries,[0],[0]
"The state is then the result of all the predictions made so far (e.g., the dependency tree constructed so far or the words translated so far).",2. Preliminaries,[0],[0]
"The cumulative cost is the performance metric such as (negative) UAS, received at the end (horizon) or after the final prediction.",2. Preliminaries,[0],[0]
"For robotics control problems, the robot’s configuration is the state, the controls (e.g., joint torques) are the actions, and the cost is related to achieving a task (e.g., distance walked).
",2. Preliminaries,[0],[0]
"Formally, a finite-horizon Markov Decision Process (MDP) is defined as (S,A, P, C, ⇢
0 , H).",2. Preliminaries,[0],[0]
"Here, S is a set of S states and A is a set of A actions; at time step t, Pt is the transition dynamics such that for any st 2 S, st+1 2 S, at 2 A,
Pt(st+1|st, at) is the probability of transitioning to state st+1 from state st by taking action at at step t; C is the cost distribution such that a cost ct at step t is sampled from Ct(·|st, at).",2. Preliminaries,[0],[0]
"Finally, we denote c̄t(st, at) as the expected cost, ⇢
0",2. Preliminaries,[0],[0]
"as the initial distribution of states,",2. Preliminaries,[0],[0]
and,2. Preliminaries,[0],[0]
"H 2 N+ as the finite horizon (max length) of the MDP.
",2. Preliminaries,[0],[0]
"We define a stochastic policy ⇡ such that for any state s 2 S , ⇡(·|s) 2 (A), where (A) is a A-dimensional simplex, conditioned on state s. ⇡(a|s) 2",2. Preliminaries,[0],[0]
"[0, 1] outputs the probability of taking action a at state s.",2. Preliminaries,[0],[0]
"The distribution of trajectories ⌧ = (s
1 , a 1 , . . .",2. Preliminaries,[0],[0]
", aH 1, sH) is determined by ⇡ and the MDP, and is defined as
⇢⇡(⌧) = ⇢0(s1) HY
t=2
⇡(at 1|st 1)Pt 1(st|st 1, at 1).
",2. Preliminaries,[0],[0]
"The distribution of the states at time step t, induced by running the policy ⇡ until t, is defined 8st:
d⇡t (st) = X
{si,ai}it 1
⇢ 0",2. Preliminaries,[0],[0]
"(s 1 )
t 1Y
i=1
⇡(ai|si)Pi(si+1|si, ai).
",2. Preliminaries,[0],[0]
Note that the summation above can be replaced by an integral if the state or action space is continuous.,2. Preliminaries,[0],[0]
"The average state distribution ¯d⇡(s) = PH t=1 d ⇡ t (s)/H .
",2. Preliminaries,[0],[0]
"The expected average cost of a policy ⇡ can be defined with respect to ⇢⇡ or {d⇡t }:
µ(⇡) = E ⌧⇠⇢⇡
"" HX
t=1
c̄t(st, at) # = HX
t=1
E s⇠d⇡t (s),a⇠⇡(a|s)",2. Preliminaries,[0],[0]
"[c̄t(s, a)] .
We define the state-action value Q⇡t (s, a) (i.e., cost-to-go) for policy ⇡ at time step t as:
Q⇡t (st, at) = c̄t(st, at) + E s⇠Pt(·|st,at),a⇠⇡(·|s) Q⇡t+1(s, a),
where the expectation is taken over the randomness of the policy ⇡ and the MDP.
",2. Preliminaries,[0],[0]
"We define ⇡⇤ as the expert policy (e.g., human demonstrators, search algorithms equipped with ground-truth) and Q⇤t (s, a) as the expert’s cost-to-go oracle.",2. Preliminaries,[0],[0]
"We emphasize that ⇡⇤ may not be optimal, i.e., ⇡⇤ 62 argmin⇡ µ(⇡).",2. Preliminaries,[0],[0]
"Throughout the paper, we assume Q⇤t (s, a) is known or can be estimated without bias (e.g., by rolling out ⇡⇤: starting from state s, applying action a, and then following ⇡⇤ for H t steps).
",2. Preliminaries,[0],[0]
"When ⇡ is represented by a function approximator, we use the notation ⇡✓ to represent the policy parametrized by ✓ 2 Rd: ⇡(·|s; ✓).",2. Preliminaries,[0],[0]
In this work we specifically consider optimizing policies in which the parameter dimension d may be large.,2. Preliminaries,[0],[0]
"We also consider the partially observable setting in our experiments, where the policy ⇡(·|o
1 , a 1 , ..., ot; ✓)
is defined over the whole history of observations and actions (ot is generated from the hidden state st).",2. Preliminaries,[0],[0]
"We use both LSTM and Gated Recurrent Unit (GRU) (Chung et al., 2014) based policies where the RNN’s hidden states provide a compressed feature of the history.",2. Preliminaries,[0],[0]
"To our best knowledge, this is the first time RNNs are employed in an IL framework to handle partially observable environments.",2. Preliminaries,[0],[0]
Policy based imitation learning aims to learn a policy ⇡̂ that approaches the performance of the expert ⇡⇤ at test time when ⇡⇤ is no longer available.,3. Differentiable Imitation Learning,[0],[0]
"In order to learn rich policies such as LSTMs or deep networks (Schulman et al., 2015), we derive a method related to policy gradients for imitation learning and sequential prediction.",3. Differentiable Imitation Learning,[0],[0]
"To do this, we leverage the reduction of IL and sequential prediction to online learning as shown in (Ross & Bagnell, 2014) to learn policies represented by expressive differentiable function approximators.
",3. Differentiable Imitation Learning,[0],[0]
"The fundamental idea in Ross & Bagnell (2014) is to use a no-regret online learner to update policies using the following loss function at each episode n:
`n(⇡)",3. Differentiable Imitation Learning,[0],[0]
"= 1
H
HX
t=1
E st⇠d⇡nt
h E
a⇠⇡(·|st) [Q⇤t (st, a)]
i .",3. Differentiable Imitation Learning,[0],[0]
"(1)
",3. Differentiable Imitation Learning,[0],[0]
"The loss function intuitively encourages the learner to find a policy that minimize the expert’s cost-to-go under the state distribution resulting from the current learned policy ⇡n. Specifically, Ross & Bagnell (2014) suggest an algorithm named AggreVaTe (Aggregate Values to Imitate) that uses Follow-the-Leader (FTL) (ShalevShwartz et al., 2012) to update policies: ⇡n+1 = argmin⇡2⇧",3. Differentiable Imitation Learning,[0],[0]
Pn i=1,3. Differentiable Imitation Learning,[0],[0]
"`n(⇡), where ⇧ is a pre-defined convex policy set.",3. Differentiable Imitation Learning,[0],[0]
"When `n(⇡) is strongly convex with respect to ⇡ and ⇡⇤ 2 ⇧, after N iterations AggreVaTe with FTL can find a policy ⇡̂ with:
µ(⇡̂)  µ(⇡⇤) ✏N +O(ln(N)/N), (2)
where ✏N =",3. Differentiable Imitation Learning,[0],[0]
[ PN n=1 `n(⇡ ⇤ ) min⇡ PN n=1 `n(⇡)]/N .,3. Differentiable Imitation Learning,[0],[0]
"Note that ✏N 0 and the above inequality indicates that ⇡̂ can outperform ⇡⇤ when ⇡⇤ is not (locally) optimal (i.e., ✏n > 0).",3. Differentiable Imitation Learning,[0],[0]
"Our experimental results support this observation.
",3. Differentiable Imitation Learning,[0],[0]
A simple implementation of AggreVaTe that aggregates the values (as the name suggests) will require an exact solution to a batch optimization procedure in each episode.,3. Differentiable Imitation Learning,[0],[0]
"When ⇡ is represented by large, non-linear function approximators, the argmin procedure generally takes more and more computation time as n increases.",3. Differentiable Imitation Learning,[0],[0]
"Hence an efficient incremental update procedure is necessary for the method to scale.
",3. Differentiable Imitation Learning,[0],[0]
"To derive an incremental update procedure, we can take one of two routes.",3. Differentiable Imitation Learning,[0],[0]
"The first route, suggested already by (Ross & Bagnell, 2014), is to update our policy with an incremental no-regret algorithm such as weighted majority (Littlestone & Warmuth, 1994), instead of with a batch algorithm like FTRL.",3. Differentiable Imitation Learning,[0],[0]
"Unfortunately, for rich policy classes such as deep networks, no-regret learning algorithms may not be available (e.g., a deep network policy is non-convex with respect to its parameters).",3. Differentiable Imitation Learning,[0],[0]
"So instead we propose a novel second route: we directly differentiate Eq. 1, yielding an update related to policy gradient methods.",3. Differentiable Imitation Learning,[0],[0]
"We work out the details below, including a novel update rule for IL based on natural gradients.
",3. Differentiable Imitation Learning,[0],[0]
"Interestingly, the two routes described above yield almost identical algorithms if our policy class is simple enough: e.g., for a tabular policy, AggreVaTe with weighted majority yields the natural gradient version of AggreVaTeD described below.",3. Differentiable Imitation Learning,[0],[0]
"And, the two routes yield complementary theoretical guarantees: the first route yields a regret bound for simple-enough policy classes, while the second route yields convergence to a local optimum for extremely flexible policy classes.",3. Differentiable Imitation Learning,[0],[0]
"For discrete actions, the gradient of `n(⇡✓) (Eq. 1) with respect to the parameters ✓ of the policy is
r✓`n(✓) = 1
H
HX
t=1
E st⇠d ⇡✓n t
X
a
r✓⇡(a|st; ✓)Q⇤t (st, a).
",3.1. Online Gradient Descent,[0],[0]
"(3)
For continuous action spaces, we cannot simply replace the summation by integration since in practice it is hard to evaluate Q⇤t (s, a) for infinitely many a, so, instead, we use importance weighting to re-formulate `n (Eq. 1) as
`n(⇡✓)",3.1. Online Gradient Descent,[0],[0]
"= 1
H
HX
t=1
E s⇠d
⇡✓n t ,a⇠⇡(·|s;✓n)
⇡(a|s; ✓) ⇡(a|s; ✓n) Q⇤t (s, a)
=
1
H E
⌧⇠⇢⇡✓n
HX
t=1
⇡(at|st; ✓) ⇡(at|st; ✓n) Q⇤t (st, at).",3.1. Online Gradient Descent,[0],[0]
"(4)
See Appendix B for the derivation of the above equation.",3.1. Online Gradient Descent,[0],[0]
"With this reformulation, the gradient with respect to ✓ is
r✓`n(✓) = 1 H E
⌧⇠⇢⇡✓n
HX
t=1
r✓⇡(at|st; ✓) ⇡(at|st; ✓n) Q⇤t (st, at)
=
1 H E⌧⇠⇢⇡✓n
HX
t=1
r✓ ln(⇡(at|st; ✓n))Q⇤t (st, at).",3.1. Online Gradient Descent,[0],[0]
"(5)
The above gradient computation enables a very efficient update procedure with online gradient descent: ✓n+1 = ✓n ⌘nr✓`n(✓)|✓=✓n , where ⌘n is the learning rate.",3.1. Online Gradient Descent,[0],[0]
"We derive a natural gradient update procedure for imitation learning inspired by the success of natural gradient descent in RL (Kakade, 2002; Bagnell & Schneider, 2003; Schulman et al., 2015).",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"Following (Bagnell & Schneider, 2003), we define the Fisher information matrix I(✓n) using trajectory likelihood:
I(✓n) = 1 H2 E ⌧⇠⇢⇡✓n r✓n log(⇢⇡✓n (⌧))",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
r,3.2. Policy Updates with Natural Gradient Descent,[0],[0]
✓n log(⇢⇡✓n (⌧)),3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"T ,
(6)
where r✓ log(⇢⇡⌧ (⌧)) is the gradient of the log likelihood of the trajectory ⌧ which can be computed asPH
t=1 r✓ log(⇡✓(at|st)).",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"Note that this representation is equivalent to the original Fisher information matrix proposed by (Kakade, 2002).",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"Now, we can use Fisher information matrix together with the IL gradient derived in the previous section (Eq. 53) to compute the natural gradient as I(✓n)",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"1r✓`n(✓)|✓=✓n , which yields a natural gradient update: ✓n+1 = ✓n µnI(✓n)",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"1r✓`n(✓)|✓=✓n .
",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"Interesting, as we mentioned before, when the given MDP is discrete and the policy class is in a tabular representation, AggreVaTe with Weighted Majority (Littlestone & Warmuth, 1994) yields an extremely similar update procedure as AggreVaTeD with natural gradient.",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"Due to space limitation, we defer the detailed similarity between AggreVaTe with Weighted Majority and AggreVaTeD with natural gradient to Appendix A.",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"As Weighted Majority can speed up online learning (i.e., almost dimension free (Bubeck et al., 2015)) and AggreVaTe with Weighted Majority enjoys strong theoretical guarantees on the performance of the learned policy (Ross & Bagnell, 2014), this similarity provides an intuitive explanation why we can expect AggreVaTeD with natural gradient to speed up IL and learn a high quality policy.",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"In the previous section, we derived a regular gradient update procedure and a natural gradient update procedure for IL.",4. Sample-Based Practical Algorithms,[0],[0]
Note that all of the computations of gradients and Fisher information matrices assumed it was possible to exactly compute expectations including Es⇠d⇡ and Ea⇠⇡(a|s).,4. Sample-Based Practical Algorithms,[0],[0]
"In this section, we provide practical algorithms where we approximate the gradients and Fisher information matrices using finite samples collected during policy execution.",4. Sample-Based Practical Algorithms,[0],[0]
"We consider an episodic framework where given a policy ⇡n at episode n, we roll out ⇡n K times to collect K trajectories {⌧ni }, for i 2",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"[K], ⌧ni = {s i,n 1 , ai,n 1
, ...}.",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"For gradient r✓`n(✓)|✓=✓n we can compute an unbiased estimate
using {⌧ni }i2[K]:
˜r✓n = 1
HK
KX
i=1
HX
t=1
X
a
r✓n⇡✓n(a|s",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"i,n t )Q ⇤ t (s i,n t , a),
(7)
˜r✓n = 1
HK
KX
i=1
HX
t=1
r✓n ln(⇡✓n(a i,n t |s",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"i,n t ))",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"Q ⇤ t (s i,n t , a i,n t ).
",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"(8)
for discrete and continuous setting respectively.
",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"When we can compute V ⇤t (s), we can replace Q⇤t (s i,n t , a) by the state-action advantage function A⇤t (s i,n t , a) = Q⇤t (s i,n t , a) V ⇤t (s i,n t ), which leads to the following unbiased and variance-reduced gradient estimation for continuous action setting (Greensmith et al., 2004):
˜r✓n = 1
HK
KX
i=1
HX
t=1
r✓n ln(⇡✓n(a i,n t |s",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"i,n t ))",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"A ⇤ t (s i,n t , a i,n t ),
(9)
",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"In fact, we can use any baselines to reduce the variance by replacing Q⇤t (st, at) by Q⇤t (st, at) b(st), where b(st) : S !",4.1. Gradient Estimation and Variance Reduction,[0],[0]
R is a action-independent function.,4.1. Gradient Estimation and Variance Reduction,[0],[0]
Ideally b(st) should be some function approximator that approximates V ⇤(st).,4.1. Gradient Estimation and Variance Reduction,[0],[0]
"In our experiments, we test linear function approximator b(s) = wT s, which is online learned using ⇡⇤’s roll-out data.
",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"The Fisher information matrix (Eq. 19) is approximated as:
˜I(✓n)",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"= 1
H2K
KX
i=1
r✓n log(⇢⇡✓n (⌧i))r✓n log(⇢⇡✓n (⌧i))",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"T
= SnS T n , (10)
where, for notation simplicity, we denote Sn as a d⇥K matrix where the i’s th column is r✓n log(⇢⇡✓n (⌧i))/(H p K).",4.1. Gradient Estimation and Variance Reduction,[0],[0]
Namely the Fisher information matrix is represented by a sum of K rank-one matrices.,4.1. Gradient Estimation and Variance Reduction,[0],[0]
"For large policies represented by neural networks, K ⌧ d, and hence ˜I(✓n) a low rank matrix.",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"One can find the descent direction ✓n by solving the linear system SnSTn ✓n = ˜r✓n for ✓n using Conjugate Gradient (CG) with a fixed number of iterations, which is equivalent to solving the above linear systems using Partial Least Squares (Phatak & de Hoog, 2002).",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"This approach is used in TRPO (Schulman et al., 2015).",4.1. Gradient Estimation and Variance Reduction,[0],[0]
The difference is that our representation of the Fisher matrix is in the form of SnSTn and in CG we never need to explicitly compute or store SnSTn which requires d2 space and time.,4.1. Gradient Estimation and Variance Reduction,[0],[0]
"Instead, we only compute and store Sn (O(Kd)) and the total computational time is still O(K2d).",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"The learning-rate for natural gradient descent can be chosen as ⌘n = q KL/( ˜rT✓n ✓n), such that KL(⇢⇡✓n+1 (⌧)k⇢⇡✓n (⌧)) ⇡",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"KL 2 R +
Algorithm 1",4.1. Gradient Estimation and Variance Reduction,[0],[0]
AggreVaTeD (Differentiable AggreVaTe) 1: Input: The given MDP and expert ⇡⇤.,4.1. Gradient Estimation and Variance Reduction,[0],[0]
"Learning rate
{⌘n}.",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"Schedule rate {↵i}, ↵n ! 0, n !",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"1. 2: Initialize policy ⇡✓1 (either random or supervised
learning).",4.1. Gradient Estimation and Variance Reduction,[0],[0]
3: for n = 1 to N do 4: Mixing policies: ⇡̂n = ↵n⇡⇤ + (1 ↵n)⇡✓n .,4.1. Gradient Estimation and Variance Reduction,[0],[0]
"5: Starting from ⇢
0 , roll out by executing ⇡̂n on the given MDP to generate K trajectories {⌧ni }.
6: Using Q⇤ and {⌧ni }i, compute the descent direction ✓n",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"(Eq. 7, Eq. 8, Eq. 9, or CG).",4.1. Gradient Estimation and Variance Reduction,[0],[0]
7: Update: ✓n+1 = ✓n ⌘n ✓n .,4.1. Gradient Estimation and Variance Reduction,[0],[0]
8: end for 9: Return: the best hypothesis ⇡̂ 2 {⇡n}n on validation.,4.1. Gradient Estimation and Variance Reduction,[0],[0]
"Summarizing the above discussion, we present the differentiable imitation learning framework AggreVaTeD, in Alg. 1.",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"At every iteration n, the roll out policy ⇡̂n is a mix of the expert policy ⇡⇤ and the current policy ⇡✓n , with mixing rate ↵ (↵n !",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"0, n !",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"1): at every step, with probability ↵ ⇡̂n picks ⇡⇤ and picks ⇡✓n otherwise.",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"This mixing strategy with the decay rate was first introduced in (Ross et al., 2011) for IL, and later on was used in sequence prediction (Bengio et al., 2015).",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"In Line 6, one can either choose Eq. 8 or the corresponding variance reduced estimation Eq. 9 to perform regular gradient descent, and choose CG to perform natural gradient descent.",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"AggreVaTeD is extremely simple: we do not need to perform any data aggregation (i.e., we do not need to store all {⌧i}i from all previous iterations); the computational complexity of each policy update scales in O(d).
",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"When we use non-linear function approximators to represent the polices, the analysis of AggreVaTe from (Ross & Bagnell, 2014) will not hold, since the loss function `n(✓) is not convex with respect to parameters ✓.",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"Nevertheless, as we will show in experiments, in practice AggreVaTeD is still able to learn a policy that is competitive with, and sometimes superior to, the oracle’s performance.",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
How much faster can IL learn a good policy than RL?,5. Quantify the Gap: An Analysis of IL vs RL,[0],[0]
In this section we quantify the gap on discrete MDPs when IL can (1) query for an optimal Q⇤ or (2) query for a noisy but unbiased estimate of Q⇤.,5. Quantify the Gap: An Analysis of IL vs RL,[0],[0]
"To measure the speed of learning, we look at the cumulative regret of the entire learning process, defined as RN = PN n=1(µ(⇡n) µ(⇡⇤)).",5. Quantify the Gap: An Analysis of IL vs RL,[0],[0]
A smaller regret rate indicates faster learning.,5. Quantify the Gap: An Analysis of IL vs RL,[0],[0]
"Throughout this section, we assume the expert ⇡⇤ is optimal.",5. Quantify the Gap: An Analysis of IL vs RL,[0],[0]
"We consider finite-horizon, episodic IL and RL algorithms.",5. Quantify the Gap: An Analysis of IL vs RL,[0],[0]
"We consider an MDP M shown in Fig. 1 which is a depthK binary tree-structure with S = 2K 1 states and two actions al, ar: go-left and go-right.",5.1. Exponential Gap,[0],[0]
"The transition is deterministic and the initial state s
0 (root) is fixed.",5.1. Exponential Gap,[0],[0]
The cost for each non-leaf state is zero; the cost for each leaf is i.i.d sampled from a given distribution (possibly different distributions per leaf).,5.1. Exponential Gap,[0],[0]
"Below we show that for M, IL can be exponentially more sample efficient than RL.
Theorem 5.1.",5.1. Exponential Gap,[0],[0]
"For M, the regret RN of any finite-horizon, episodic RL algorithm is at least:
E[RN ] ⌦( p SN).",5.1. Exponential Gap,[0],[0]
"(11)
",5.1. Exponential Gap,[0],[0]
The expectation is with respect to random generation of cost and internal randomness of the algorithm.,5.1. Exponential Gap,[0],[0]
"However, for the same MDP M, with the access to Q⇤, we show IL can learn exponentially faster:
Theorem 5.2.",5.1. Exponential Gap,[0],[0]
"For the MDP M, AggreVaTe with FTL can achieve the following regret bound:
RN  O(ln (S)).",5.1. Exponential Gap,[0],[0]
"(12)
Fig. 1 illustrates the intuition behind the theorem.",5.1. Exponential Gap,[0],[0]
"Assume during the first episode, the initial policy ⇡
1 picks the rightmost trajectory (bold black) to explore.",5.1. Exponential Gap,[0],[0]
"We query from the cost-to-go oracle Q⇤ at s
0 for al and ar, and learn that Q⇤(s
0 , al) <",5.1. Exponential Gap,[0],[0]
"Q⇤(s0, ar).",5.1. Exponential Gap,[0],[0]
"This immediately tells us that the optimal policy will go left (black arrow) at s
0 .",5.1. Exponential Gap,[0],[0]
"Hence the algorithm does not have to explore the right sub-tree (dotted circle).
",5.1. Exponential Gap,[0],[0]
"Next we consider a more difficult setting where one can only query for a noisy but unbiased estimate of Q⇤ (e.g., by rolling out ⇡⇤ finite number of times).",5.1. Exponential Gap,[0],[0]
The above halving argument will not apply since deterministically eliminating nodes based on noisy estimates might permanently remove good trajectories.,5.1. Exponential Gap,[0],[0]
"However, IL can still achieve a poly-log regret with respect to S, even in the noisy setting:
Theorem 5.3.",5.1. Exponential Gap,[0],[0]
"With only access to unbiased estimate of Q⇤, for the MDP M, AggreVaTeD with WM can achieve the
following regret with probability at least 1 :
RN  O ⇣ ln(S)( p ln(S)N + p ln(2/ )N)",5.1. Exponential Gap,[0],[0]
⌘ .,5.1. Exponential Gap,[0],[0]
"(13)
",5.1. Exponential Gap,[0],[0]
"The detailed proofs of the above three theorems can be found in Appendix E,F,G respectively.",5.1. Exponential Gap,[0],[0]
"In summary, for MDP M, IL is is exponentially faster than RL.",5.1. Exponential Gap,[0],[0]
We next quantify the gap in general discrete MDPs and also show that AggreVaTeD is near-optimal.,5.2. Polynomial Gap and Near-Optimality,[0],[0]
"We consider the harder case where we can only access an unbiased estimate of Q⇤t , for any t and state-action pair.",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"The policy ⇡ is represented as a set of probability vectors ⇡s,t 2 (A), for all s 2 S and t 2",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"[H]: ⇡ = {⇡s,t}s2S,t2[H].",5.2. Polynomial Gap and Near-Optimality,[0],[0]
Theorem 5.4.,5.2. Polynomial Gap and Near-Optimality,[0],[0]
"With access to unbiased estimates of Q⇤t , AggreVaTeD with WM achieves the regret upper bound:
RN  O HQe
max
p S ln(A)N .",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"(14)
",5.2. Polynomial Gap and Near-Optimality,[0],[0]
Here Qe max is the maximum cost-to-go of the expert.,5.2. Polynomial Gap and Near-Optimality,[0],[0]
The total regret shown in Eq. 14 allows us to compare IL algorithms to RL algorithms.,5.2. Polynomial Gap and Near-Optimality,[0],[0]
"For example, the Upper Confidence Bound (UCB) based, near-optimal optimistic RL algorithms from (Jaksch et al., 2010), specifically designed for efficient exploration, admit regret ˜O(HS",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"p HAN), leading to a gap of approximately p HAS compared to the regret bound of imitation learning shown in Eq. 14.
",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"We also provide a lower bound on RN for the H = 1 case which shows the dependencies on N,A, S are tight:
Theorem 5.5.",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"There exists an MDP (H=1) such that, with only access to unbiased estimates of Q⇤, any finite-horizon episodic imitation learning algorithm must have:
E[RN ] ⌦( p S ln(A)N).",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"(15)
The proofs of the above two theorems regarding general MDPs can be found in Appendix H,I.",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"In summary for discrete MDPs, one can expect at least a polynomial gap and a possible exponential gap between IL and RL.",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"We evaluate our algorithms on robotics simulations from OpenAI Gym (Brockman et al., 2016) and on Handwritten Algebra Dependency Parsing (Duyck & Gordon, 2015).",6. Experiments,[0],[0]
"We report reward instead of cost, since OpenAI Gym by default uses reward and dependency parsing aims to maximize UAS score.",6. Experiments,[0],[0]
"As our approach only promises there
Here we assume Qe max is a constant compared to H .",6. Experiments,[0],[0]
"If Qe
max = ⇥(H), then the expert is no better than a random policy of which the cost-to-go is around ⇥(H).
exists a policy among all of the learned polices that can perform as well as the expert, we report the performance of the best policy so far: max{µ(⇡
1 ), ..., µ(⇡i)}.",6. Experiments,[0],[0]
"For regular gradient descent, we use ADAM (Kingma & Ba, 2014) which is a first-order no-regret algorithm, and for natural gradient, we use CG to compute the descent direction.",6. Experiments,[0],[0]
"For RL we use REINFORCE (Williams, 1992) and Truncated Natural Policy Gradient (TNPG)",6. Experiments,[0],[0]
"(Duan et al., 2016).",6. Experiments,[0],[0]
"We consider CartPole Balancing, Acrobot Swing-up, Hopper and Walker.",6.1. Robotics Simulations,[0],[0]
"For generating an expert, similar to previous work (Ho & Ermon, 2016), we used a Deep Q-Network (DQN) to generate Q⇤ for CartPole and Acrobot (e.g., to simulate the settings where Q⇤ is available), while using the publicly available TRPO implementation to generate ⇡⇤ for Hopper and Walker to simulate the settings where one has to estimate Q⇤ by Monte-Carlo roll outs ⇡⇤.
",6.1. Robotics Simulations,[0],[0]
Discrete Action Setting We use a one-layer (16 hidden units) neural network with ReLu activation functions to represent the policy ⇡ for the Cart-pole and Acrobot benchmarks.,6.1. Robotics Simulations,[0],[0]
"The value function Q⇤ is obtained from the DQN (Mnih et al., 2015) and represented by a multi-layer fully connected neural network.",6.1. Robotics Simulations,[0],[0]
The policy ⇡✓1 is initialized with common ReLu neural network initialization techniques.,6.1. Robotics Simulations,[0],[0]
"For the scheduling rate {↵i}, we set all ↵i = 0: namely we did not roll-in using the expert’s actions during training.",6.1. Robotics Simulations,[0],[0]
"We set the number of roll outs K = 50 and horizon H = 500 for CartPole and H = 200 for Acrobot.
",6.1. Robotics Simulations,[0],[0]
Fig.,6.1. Robotics Simulations,[0],[0]
2a and 2b shows the performance averaged over 10 random trials of AggreVaTeD with regular gradient descent and natural gradient descent.,6.1. Robotics Simulations,[0],[0]
Note that AggreVaTeD outperforms the experts’ performance significantly: Natural gradient surpasses the expert by 5.8% in Acrobot and 25% in Cart-pole.,6.1. Robotics Simulations,[0],[0]
"Also, for Acrobot swing-up, at horizon H = 200, with high probability a randomly initialized neural network policy won’t be able to collect any reward signals.",6.1. Robotics Simulations,[0],[0]
Hence the improvement rates of REINFORCE and TNPG are slow.,6.1. Robotics Simulations,[0],[0]
"In fact, we observed that for a short horizon such as H = 200, REINFORCE and Truncated Natural Gradient often even fail to improve the policy at all (failed
6 times among 10 trials).",6.1. Robotics Simulations,[0],[0]
"On the contrary, AggreVaTeD does not suffer from the delayed reward signal issue, since the expert will collect reward signals much faster than a randomly initialized policy.
",6.1. Robotics Simulations,[0],[0]
Fig. 2c shows the performance of AggreVaTeD with an LSTM policy (32 hidden states) in a partially observed setting where the expert has access to full states but the learner has access to partial observations (link positions).,6.1. Robotics Simulations,[0],[0]
RL algorithms did not achieve any improvement while AggreVaTeD still achieved 92% of the expert’s performance.,6.1. Robotics Simulations,[0],[0]
"In Appendix K, we provide extra experiments on partial observable CartPole with GRU-based policies, where we demonstrate that even in partial observable setting, AggreVaTeD can learn RNN polices that outperform experts.
",6.1. Robotics Simulations,[0],[0]
Continuous Action Setting We test our approaches on two robotics simulators with continuous actions: (1) the 2-d Walker and (2) the Hopper from the MuJoCo physics simulator.,6.1. Robotics Simulations,[0],[0]
"Following the neural network settings described in Schulman et al. (2015), the expert policy ⇡⇤ is obtained from TRPO with one hidden layer (64 hidden states), which is the same structure that we use to represent our policies ⇡✓.",6.1. Robotics Simulations,[0],[0]
We set K = 50 and H = 100.,6.1. Robotics Simulations,[0],[0]
"We initialize ⇡✓1 by collecting K expert demonstrations and then maximize the likelihood of these demonstrations (i.e., supervised learning).",6.1. Robotics Simulations,[0],[0]
"We use a linear baseline b(s) = wT s for RL and IL.
Fig.",6.1. Robotics Simulations,[0],[0]
2e and 2d show the performance averaged over 5 random trials.,6.1. Robotics Simulations,[0],[0]
Note that AggreVaTeD outperforms the expert in the Walker by 13.7% while achieving 97% of the expert’s performance in the Hopper problem.,6.1. Robotics Simulations,[0],[0]
"After 100 iterations, we see that by leveraging the help from experts, AggreVaTeD can achieve much faster improvement rate than the corresponding RL algorithms (though eventually we can expect RL to catch up).",6.1. Robotics Simulations,[0],[0]
"In Walker, we also tested AggreVaTeD without linear baseline, which still outperforms the expert but performed slightly worse than AggreVaTeD with baseline as expected.",6.1. Robotics Simulations,[0],[0]
"We consider a sequential prediction problem: transitionbased dependency parsing for handwritten algebra with raw image data (Duyck & Gordon, 2015).",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"The parsing task
for algebra is similar to the classic dependency parsing for natural language (Chang et al., 2015a) where the problem is modelled in the IL setting and the state-of-the-art is achieved by AggreVaTe with FTRL (using Data Aggregation).",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
The additional challenge here is that the inputs are handwritten algebra symbols in raw images.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
We directly learn to predict parse trees from low level image features (Histogram of Gradient features (HoG)).,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"During training, the expert is constructed using the ground-truth dependencies in training data.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"The full state s during parsing consists of three data structures: Stack, Buffer and Arcs, which store raw images of the algebraic symbols.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"Since the sizes of stack, buffer and arcs change during parsing, a common approach is to featurize the state s by taking the features of the latest three symbols from stack, buffer and arcs (e.g., (Chang et al., 2015a)).",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"Hence the problem falls into the partially observable setting, where the feature o is extracted from state s and only contains partial information about s. The dataset consists of 400 sets of handwritten algebra equations.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"We use 80% for training, 10% for validation, and 10% for testing.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"We include an example of handwritten algebra equations and its dependency tree in Appendix J. Note that different from robotics simulators where at every episode one can get fresh data from the simulators, the dataset is fixed and sample efficiency is critical.
",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"The RNN policy follows the design from (Sutskever et al., 2014).",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
It consists of two LSTMs.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"Given a sequence of algebra symbols ⌧ , the first LSTM processes one symbol at a time and at the end outputs its hidden states and memory (i.e., a summary of ⌧ ).",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
The second LSTM initializes its own hidden states and memory using the outputs of the first LSTM.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"At every parsing step t, the second LSTM takes the current partial observation ot (ot consists of features of the most recent item from stack, buffer and arcs) as input, and uses its internal hidden state and memory to compute the action distribution ⇡(·|o
1 , ..., ot, ⌧) conditioned on history.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"We also tested reactive policies constructed as fully connected ReLu neural networks (NN) (one-layer with 1000 hidden states) that directly maps from observation ot to action a, where ot uses the most three recent items.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"We use variance reduced gradient estimations, which give better performance in practice.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
The performance is summarised in Table 1.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"Due to the partial observability of the problem, AggreVaTeD with a LSTM policy achieves significantly better UAS scores compared to the NN reactive pol-
icy and DAgger with a Kernelized SVM (Duyck & Gordon, 2015).",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
Also AggreVaTeD with a LSTM policy achieves 97% of optimal expert’s performance.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
Fig. 3 shows the improvement rate of regular gradient and natural gradient on both validation set and test set.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
Overall we observe that both methods have similar performance.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
Natural gradient achieves a better UAS score in validation and converges slightly faster on the test set but also achieves a lower UAS score on test set.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"We introduced AggreVaTeD, a differentiable imitation learning algorithm which trains neural network policies for sequential prediction tasks such as continuous robot control and dependency parsing on raw image data.",7. Conclusion,[0],[0]
We showed that in theory and in practice IL can learn much faster than RL with access to optimal cost-to-go oracles.,7. Conclusion,[0],[0]
The IL learned policies were able to achieve expert and sometimes super-expert levels of performance in both fully observable and partially observable settings.,7. Conclusion,[0],[0]
The theoretical and experimental results suggest that IL is significantly more effective than RL for sequential prediction with near optimal cost-to-go oracles.,7. Conclusion,[0],[0]
This research was supported in part by ONR 36060-1b1141268.,Acknowledgement,[0],[0]
"Recently, researchers have demonstrated stateof-the-art performance on sequential prediction problems using deep neural networks and Reinforcement Learning (RL).",abstractText,[0],[0]
"For some of these problems, oracles that can demonstrate good performance may be available during training, but are not used by plain RL methods.",abstractText,[0],[0]
"To take advantage of this extra information, we propose AggreVaTeD, an extension of the Imitation Learning (IL) approach of Ross & Bagnell (2014).",abstractText,[0],[0]
"AggreVaTeD allows us to use expressive differentiable policy representations such as deep networks, while leveraging training-time oracles to achieve faster and more accurate solutions with less training data.",abstractText,[0],[0]
"Specifically, we present two gradient procedures that can learn neural network policies for several problems, including a sequential prediction task and several high-dimensional robotics control problems.",abstractText,[0],[0]
We also provide a comprehensive theoretical study of IL that demonstrates that we can expect up to exponentially-lower sample complexity for learning with AggreVaTeD than with plain RL algorithms.,abstractText,[0],[0]
Our results and theory indicate that IL (and AggreVaTeD in particular) can be a more effective strategy for sequential prediction than plain RL.,abstractText,[0],[0]
Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential Prediction,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 564–573 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"In recent years, deep learning techniques have obtained many state-of-the-art results in various classification and recognition problems (Krizhevsky et al., 2012; Hinton et al., 2012; Kim, 2014).",1 Introduction,[0],[0]
"However, complex natural language processing problems often require multiple inter-related decisions, and empowering deep learning models with the ability of learning to reason is still a challenging issue.",1 Introduction,[0],[0]
"To handle complex queries where there are no obvious answers, intelligent machines must be able to reason with existing resources, and learn to infer an unknown answer.
",1 Introduction,[0],[0]
"More specifically, we situate our study in the context of multi-hop reasoning, which is the task of learning explicit inference formulas, given a large KG.",1 Introduction,[0],[0]
"For example, if the KG includes the
1Code and the NELL dataset are available at https:// github.com/xwhan/DeepPath.
",1 Introduction,[0],[0]
"beliefs such as Neymar plays for Barcelona, and Barcelona are in the La Liga league, then machines should be able to learn the following formula: playerPlaysForTeam(P,T)",1 Introduction,[0],[0]
"∧ teamPlaysInLeague(T,L) ⇒ playerPlaysInLeague(P,L).",1 Introduction,[0],[0]
"In the testing time, by plugging in the learned formulas, the system should be able to automatically infer the missing link between a pair of entities.",1 Introduction,[0],[0]
"This kind of reasoning machine will potentially serve as an essential components of complex QA systems.
",1 Introduction,[0],[0]
"In recent years, the Path-Ranking Algorithm (PRA) (Lao et al., 2010, 2011a) emerges as a promising method for learning inference paths in large KGs.",1 Introduction,[0],[0]
PRA uses a random-walk with restarts based inference mechanism to perform multiple bounded depth-first search processes to find relational paths.,1 Introduction,[0],[0]
"Coupled with elastic-net based learning, PRA then picks more plausible paths using supervised learning.",1 Introduction,[0],[0]
"However, PRA operates in a fully discrete space, which makes it difficult to evaluate and compare similar entities and relations in a KG.
",1 Introduction,[0],[0]
"In this work, we propose a novel approach for controllable multi-hop reasoning: we frame the path learning process as reinforcement learning (RL).",1 Introduction,[0],[0]
"In contrast to PRA, we use translationbased knowledge based embedding method (Bordes et al., 2013) to encode the continuous state of our RL agent, which reasons in the vector space environment of the knowledge graph.",1 Introduction,[0],[0]
The agent takes incremental steps by sampling a relation to extend its path.,1 Introduction,[0],[0]
"To better guide the RL agent for learning relational paths, we use policy gradient training (Mnih et al., 2015) with a novel reward function that jointly encourages accuracy, diversity, and efficiency.",1 Introduction,[0],[0]
"Empirically, we show that our method outperforms PRA and embedding based methods on a Freebase and a Never-Ending Language Learning (Carlson et al., 2010a) dataset.
564
Our contributions are three-fold:
• We are the first to consider reinforcement learning (RL) methods for learning relational paths in knowledge graphs;
• Our learning method uses a complex reward function that considers accuracy, efficiency, and path diversity simultaneously, offering better control and more flexibility in the pathfinding process;
• We show that our method can scale up to large scale knowledge graphs, outperforming PRA and KG embedding methods in two tasks.
",1 Introduction,[0],[0]
"In the next section, we outline related work in path-finding and embedding methods in KGs.",1 Introduction,[0],[0]
We describe the proposed method in Section 3.,1 Introduction,[0],[0]
We show experimental results in Section 4.,1 Introduction,[0],[0]
"Finally, we conclude in Section 5.",1 Introduction,[0],[0]
"The Path-Ranking Algorithm (PRA) method (Lao et al., 2011b) is a primary path-finding approach that uses random walk with restart strategies for multi-hop reasoning.",2 Related Work,[0],[0]
Gardner et al. (2013; 2014) propose a modification to PRA that computes feature similarity in the vector space.,2 Related Work,[0],[0]
Wang and Cohen (2015) introduce a recursive random walk approach for integrating the background KG and text—the method performs structure learning of logic programs and information extraction from text at the same time.,2 Related Work,[0],[0]
"A potential bottleneck for random walk inference is that supernodes connecting to large amount of formulas will create huge fan-out areas that significantly slow down the inference and affect the accuracy.
",2 Related Work,[0],[0]
Toutanova et al. (2015) provide a convolutional neural network solution to multi-hop reasoning.,2 Related Work,[0],[0]
"They build a CNN model based on lexicalized dependency paths, which suffers from the error propagation issue due to parse errors.",2 Related Work,[0],[0]
Guu et al. (2015) uses KG embeddings to answer path queries.,2 Related Work,[0],[0]
"Zeng et al. (2014) described a CNN model for relational extraction, but it does not explicitly model the relational paths.",2 Related Work,[0],[0]
"Neelakantan et al. (2015) propose a recurrent neural networks model for modeling relational paths in knowledge base completion (KBC), but it trains too many separate models, and therefore it does not scale.",2 Related Work,[0],[0]
"Note that many of the recent KG reasoning methods (Neelakantan et al.,
2015; Das et al., 2017) still rely on first learning the PRA paths, which only operates in a discrete space.",2 Related Work,[0],[0]
"Comparing to PRA, our method reasons in a continuous space, and by incorporating various criteria in the reward function, our reinforcement learning (RL) framework has better control and more flexibility over the path-finding process.
",2 Related Work,[0],[0]
"Neural symbolic machine (Liang et al., 2016) is a more recent work on KG reasoning, which also applies reinforcement learning but has a different flavor from our work.",2 Related Work,[0],[0]
"NSM learns to compose programs that can find answers to natural language questions, while our RL model tries to add new facts to knowledge graph (KG) by reasoning on existing KG triples.",2 Related Work,[0],[0]
"In order to get answers, NSM learns to generate a sequence of actions that can be combined as a executable program.",2 Related Work,[0],[0]
The action space in NSM is a set of predefined tokens.,2 Related Work,[0],[0]
"In our framework, the goal is to find reasoning paths, thus the action space is relation space in the KG.",2 Related Work,[0],[0]
"A similar framework (Johnson et al., 2017) has also been applied to visual reasoning tasks.",2 Related Work,[0],[0]
"In this section, we describe in detail our RL-based framework for multi-hop relation reasoning.",3 Methodology,[0],[0]
The specific task of relation reasoning is to find reliable predictive paths between entity pairs.,3 Methodology,[0],[0]
We formulate the path finding problem as a sequential decision making problem which can be solved with a RL agent.,3 Methodology,[0],[0]
We first describe the environment and the policy-based RL agent.,3 Methodology,[0],[0]
"By interacting with the environment designed around the KG, the agent learns to pick the promising reasoning paths.",3 Methodology,[0],[0]
Then we describe the training procedure of our RL model.,3 Methodology,[0],[0]
"After that, we describe an efficient path-constrained search algorithm for relation reasoning with the paths found by the RL agent.",3 Methodology,[0],[0]
The RL system consists of two parts (see Figure 1).,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
The first part is the external environment E which specifies the dynamics of the interaction between the agent and the KG.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
This environment is modeled as a Markov decision process (MDP).,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"A tuple < S,A,P,R > is defined to represent the MDP, where S is the continuous state space, A = {a1, a2, ..., an} is the set of all available actions, P(St+1 = s′",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"|St = s,At = a) is the transition probability matrix, and R(s, a) is the reward
function of every (s, a) pairs.
",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"The second part of the system, the RL agent, is represented as a policy network πθ(s, a) = p(a|s; θ) which maps the state vector to a stochastic policy.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
The neural network parameters θ are updated using stochastic gradient descent.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"Compared to Deep Q Network (DQN) (Mnih et al., 2013), policy-based RL methods turn out to be more appropriate for our knowledge graph scenario.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"One reason is that for the path finding problem in KG, the action space can be very large due to complexity of the relation graph.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
This can lead to poor convergence properties for DQN.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"Besides, instead of learning a greedy policy which is common in value-based methods like DQN, the policy network is able to learn a stochastic policy which prevent the agent from getting stuck at an intermediate state.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"Before we describe the structure of our policy network, we first describe the components (actions, states, rewards) of the RL environment.
",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"Actions Given the entity pairs (es, et) with relation r, we want the agent to find the most informative paths linking these entity pairs.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"Beginning with the source entity es, the agent use the policy network to pick the most promising
relation to extend its path at each step until it reaches the target entity et.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"To keep the output dimension of the policy network consistent, the action space is defined as all the relations in the KG.
",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
States,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
The entities and relations in a KG are naturally discrete atomic symbols.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"Since existing practical KGs like Freebase (Bollacker et al., 2008) and NELL (Carlson et al., 2010b) often have huge amounts of triples.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
It is impossible to directly model all the symbolic atoms in states.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"To capture the semantic information of these symbols, we use translation-based embeddings such as TransE (Bordes et al., 2013) and TransH (Wang et al., 2014) to represent the entities and relations.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
These embeddings map all the symbols to a lowdimensional vector space.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"In our framework, each state captures the agent’s position in the KG.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"After taking an action, the agent will move from one entity to another.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
These two are linked by the action (relation) just taken by the agent.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"The state vector at step t is given as follows:
st = (et, etarget − et)
where et denotes the embeddings of the current entity node and etarget denotes the embeddings of
the target entity.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"At the initial state, et = esource.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"We do not incorporate the reasoning relation in the state, because the embedding of the reasoning relation remain constant during path finding, which is not helpful in training.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"However, we find out that by training the RL agent using a set of positive samples for one particular relation, the agent can successfully discover the relation semantics.
",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
Rewards There are a few factors that contribute to the quality of the paths found by the RL agent.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"To encourage the agent to find predictive paths, our reward functions include the following scoring criteria: Global accuracy: For our environment settings, the number of actions that can be taken by the agent can be very large.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"In other words, there are much more incorrect sequential decisions than the correct ones.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
The number of these incorrect decision sequences can increase exponentially with the length of the path.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"In view of this challenge, the first reward function we add to the RL model is defined as follows:
rGLOBAL = { +1, if the path reaches etarget −1, otherwise
the agent is given an offline positive reward +1 if it reaches the target after a sequence of actions.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"Path efficiency: For the relation reasoning task, we observe that short paths tend to provide more reliable reasoning evidence than longer paths.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
Shorter chains of relations can also improve the efficiency of the reasoning by limiting the length of the RL’s interactions with the environment.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"The efficiency reward is defined as follows:
rEFFICIENCY = 1
length(p)
where path p is defined as a sequence of relations r1 → r2 → ...→ rn.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
Path diversity: We train the agent to find paths using positive samples for each relation.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"These training sample (esource, etarget) have similar state representations in the vector space.",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
The agent tends to find paths with similar syntax and semantics.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
These paths often contains redundant information since some of them may be correlated.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"To encourage the agent to find diverse paths, we define a diversity reward function using the cosine similarity
between the current path and the existing ones:
rDIVERSITY =",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
− 1|F | |F |∑ i=1,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"cos(p,pi)
",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"where p = ∑n
i=1",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
ri represents the path embedding for the relation chain r1 → r2 → ...→ rn. Policy Network,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
We use a fully-connected neural network to parameterize the policy function π(s; θ) that maps the state vector s to a probability distribution over all possible actions.,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"The neural network consists of two hidden layers, each followed by a rectifier nonlinearity layer (ReLU).",3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
The output layer is normalized using a softmax function (see Figure 1).,3.1 Reinforcement Learning for Relation Reasoning,[0],[0]
"In practice, one big challenge of KG reasoning is that the relation set can be quite large.",3.2 Training Pipeline,[0],[0]
"For a typical KG, the RL agent is often faced with hundreds (thousands) of possible actions.",3.2 Training Pipeline,[0],[0]
"In other words, the output layer of the policy network often has a large dimension.",3.2 Training Pipeline,[0],[0]
"Due to the complexity of the relation graph and the large action space, if we directly train the RL model by trial and errors, which is typical for RL algorithms, the RL model will show very poor convergence properties.",3.2 Training Pipeline,[0],[0]
"After a long-time training, the agents fails to find any valuable path.",3.2 Training Pipeline,[0],[0]
"To tackle this problem, we start our training with a supervised policy which is inspired by the imitation learning pipeline used by AlphaGo (Silver et al., 2016).",3.2 Training Pipeline,[0],[0]
"In the Go game, the player is facing nearly 250 possible legal moves at each step.",3.2 Training Pipeline,[0],[0]
Directly training the agent to pick actions from the original action space can be a difficult task.,3.2 Training Pipeline,[0],[0]
AlphaGo first train a supervised policy network using experts moves.,3.2 Training Pipeline,[0],[0]
"In our case, the supervised policy is trained with a randomized breadth-first search (BFS).
",3.2 Training Pipeline,[0],[0]
"Supervised Policy Learning For each relation, we use a subset of all the positive samples (entity pairs) to learn the supervised policy.",3.2 Training Pipeline,[0],[0]
"For each positive sample (esource, etarget), a two-side BFS is conducted to find same correct paths between the entities.",3.2 Training Pipeline,[0],[0]
For each path p with a sequence of relations r1 → r2 → ...,3.2 Training Pipeline,[0],[0]
"→ rn, we update the parameters θ to maximize the expected cumulative reward using Monte-Carlo Policy Gradient (RE-
INFORCE)",3.2 Training Pipeline,[0],[0]
"(Williams, 1992): J(θ) = Ea∼π(a|s;θ)( ∑ t Rst,at)
= ∑ t ∑ a∈A π(a|st; θ)Rst,at (1)
where J(θ) is the expected total rewards for one episode.",3.2 Training Pipeline,[0],[0]
"For supervised learning, we give a reward of +1 for each step of a successful episode.",3.2 Training Pipeline,[0],[0]
"By plugging in the paths found by the BFS, the approximated gradient used to update the policy network is shown below:
∇θJ(θ)",3.2 Training Pipeline,[0],[0]
"= ∑ t ∑ a∈A π(a|st; θ)∇θ log π(a|st; θ)
≈",3.2 Training Pipeline,[0],[0]
"∇θ ∑ t log π(a = rt|st; θ) (2)
where rt belongs to the path",3.2 Training Pipeline,[0],[0]
p.,3.2 Training Pipeline,[0],[0]
"However, the vanilla BFS is a biased search algorithm which prefers short paths.",3.2 Training Pipeline,[0],[0]
"When plugging in these biased paths, it becomes difficult for the agent to find longer paths which may potentially be useful.",3.2 Training Pipeline,[0],[0]
We want the paths to be controlled only by the defined reward functions.,3.2 Training Pipeline,[0],[0]
"To prevent the biased search, we adopt a simple trick to add some random mechanisms to the BFS.",3.2 Training Pipeline,[0],[0]
"Instead of directly searching the path between esource and etarget, we randomly pick a intermediate node einter and then conduct two BFS between (esource, einter) and (einter, etarget).",3.2 Training Pipeline,[0],[0]
The concatenated paths are used to train the agent.,3.2 Training Pipeline,[0],[0]
The supervised learning saves the agent great efforts learning from failed actions.,3.2 Training Pipeline,[0],[0]
"With the learned experience, we then train the agent to find desirable paths.",3.2 Training Pipeline,[0],[0]
"Retraining with Rewards To find the reasoning paths controlled by the reward functions, we use reward functions to retrain the supervised policy network.",3.2 Training Pipeline,[0],[0]
"For each relation, the reasoning with one entity pair is treated as one episode.",3.2 Training Pipeline,[0],[0]
"Starting with the source node esource, the agent picks a relation according to the stochastic policy π(a|s), which is a probability distribution over all relations, to extend its reasoning path.",3.2 Training Pipeline,[0],[0]
"This relation link may lead to a new entity, or it may lead to nothing.",3.2 Training Pipeline,[0],[0]
These failed steps will cause the agent to receive negative rewards.,3.2 Training Pipeline,[0],[0]
The agent will stay at the same state after these failed steps.,3.2 Training Pipeline,[0],[0]
"Since the agent is following a stochastic policy, the agent will not get stuck by repeating a wrong step.",3.2 Training Pipeline,[0],[0]
"To improve the training efficiency, we limit the episode length with an upper
Algorithm 1: Retraining Procedure with reward functions
1 Restore parameters θ from supervised policy; 2 for episode← 1 to N do 3 Initialize state vector st ← s0 4 Initialize episode length steps← 0 5 while num steps < max length do 6 Randomly sample action a ∼ π(a|st) 7 Observe rewardRt, next state st+1 //",3.2 Training Pipeline,[0],[0]
if the step fails 8 ifRt = −1 then 9,3.2 Training Pipeline,[0],[0]
"Save < st, a > toMneg
10 if success or steps = max length then 11 break 12 Increment num steps
// penalize failed steps 13 Update θ using
g ∝",3.2 Training Pipeline,[0],[0]
∇θ,3.2 Training Pipeline,[0],[0]
"∑ Mneg log π(a = rt|st; θ)(−1)
",3.2 Training Pipeline,[0],[0]
if success then 14 Rtotal ← λ1rGLOBAL + λ2rEFFICIENCY,3.2 Training Pipeline,[0],[0]
"+ λ3rDIVERSITY 15 Update θ using
g ∝",3.2 Training Pipeline,[0],[0]
∇θ,3.2 Training Pipeline,[0],[0]
∑,3.2 Training Pipeline,[0],[0]
"t log π(a = rt|st; θ)Rtotal
boundmax length.",3.2 Training Pipeline,[0],[0]
The episode ends if the agent fails to reach the target entity within max length steps.,3.2 Training Pipeline,[0],[0]
"After each episode, the policy network is updated using the following gradient:
∇θJ(θ) =",3.2 Training Pipeline,[0],[0]
"∇θ ∑ t log π(a = rt|st; θ)Rtotal (3)
where Rtotal is the linear combination of the defined reward functions.",3.2 Training Pipeline,[0],[0]
The detail of the retrain process is shown in Algorithm 1.,3.2 Training Pipeline,[0],[0]
"In practice, θ is updated using the Adam Optimizer (Kingma and Ba, 2014) with L2 regularization.",3.2 Training Pipeline,[0],[0]
"Given an entity pair, the reasoning paths learned by the RL agent can be used as logical formulas to predict the relation link.",3.3 Bi-directional Path-constrained Search,[0],[0]
Each formula is verified using a bi-directional search.,3.3 Bi-directional Path-constrained Search,[0],[0]
"In a typical KG, one entity node can be linked to a large number of neighbors with the same relation link.",3.3 Bi-directional Path-constrained Search,[0],[0]
"A simple example is the relation personNationality−1, which denotes the inverse of personNationality.",3.3 Bi-directional Path-constrained Search,[0],[0]
"Following this link, the entity United States can reach numerous neighboring entities.",3.3 Bi-directional Path-constrained Search,[0],[0]
"If the for-
Algorithm 2: Bi-directional search for path verification
1",3.3 Bi-directional Path-constrained Search,[0],[0]
"Given a reasoning path p : r1 → r2 → ...→ rn 2 for (ei, ej) in test set D do 3 start← 0; end← n 4 left← ∅; right← ∅ 5 while start < end do 6 leftEx← ∅; rightEx← ∅ 7 if len(left) < len(right) then 8 Extend path on the left side 9 Add connected nodes to leftEx
10 left← leftEx 11 else 12 Extend path on the right side 13 Add connected nodes to rightEx 14 right← rightEx 15 if left ∩ right 6= ∅",3.3 Bi-directional Path-constrained Search,[0],[0]
"then 16 return True 17 else 18 return False
mula consists of such links, the number of intermediate entities can exponentially increase as we follow the reasoning formula.",3.3 Bi-directional Path-constrained Search,[0],[0]
"However, we observe that for these formulas, if we verify the formula from the inverse direction.",3.3 Bi-directional Path-constrained Search,[0],[0]
The number of intermediate nodes can be tremendously decreased.,3.3 Bi-directional Path-constrained Search,[0],[0]
Algorithm 2 shows a detailed description of the proposed bi-directional search.,3.3 Bi-directional Path-constrained Search,[0],[0]
"To evaluate the reasoning formulas found by our RL agent, we explore two standard KG reasoning tasks: link prediction (predicting target entities) and fact prediction (predicting whether an unknown fact holds or not).",4 Experiments,[0],[0]
We compare our method with both path-based methods and embedding based methods.,4 Experiments,[0],[0]
"After that, we further analyze the reasoning paths found by our RL agent.",4 Experiments,[0],[0]
These highly predictive paths validate the effectiveness of the reward functions.,4 Experiments,[0],[0]
"Finally, we conduct a experiment to investigate the effect of the supervised learning procedure.",4 Experiments,[0],[0]
Table 1 shows the statistics of the two datasets we conduct our experiments on.,4.1 Dataset and Settings,[0],[0]
"Both of them
are subsets of larger datasets.",4.1 Dataset and Settings,[0],[0]
"The triples in FB15K-237 (Toutanova et al., 2015) are sampled from FB15K (Bordes et al., 2013) with redundant relations removed.",4.1 Dataset and Settings,[0],[0]
We perform the reasoning tasks on 20 relations which have enough reasoning paths.,4.1 Dataset and Settings,[0],[0]
"These tasks consists of relations from different domains like Sports, People, Locations, Film, etc.",4.1 Dataset and Settings,[0],[0]
"Besides, we present a new NELL subset that is suitable for multi-hop reasoning from the 995th iteration of the NELL system.",4.1 Dataset and Settings,[0],[0]
We first remove the triples with relation generalizations or haswikipediaurl.,4.1 Dataset and Settings,[0],[0]
"These two relations appear more than 2M times in the NELL dataset, but they have no reasoning values.",4.1 Dataset and Settings,[0],[0]
"After this step, we only select the triples with Top-200 relations.",4.1 Dataset and Settings,[0],[0]
"To facilitate path finding, we also add the inverse triples.",4.1 Dataset and Settings,[0],[0]
"For each triple (h, r, t), we append (t, r−1, h) to the datasets.",4.1 Dataset and Settings,[0],[0]
"With these inverse triples, the agent is able to step backward in the KG.
",4.1 Dataset and Settings,[0],[0]
"For each reasoning task ri, we remove all the triples with ri or r−1i from the KG.",4.1 Dataset and Settings,[0],[0]
These removed triples are split into train and test samples.,4.1 Dataset and Settings,[0],[0]
"For the link prediction task, each h in the test triples {(h, r, t)} is considered as one query.",4.1 Dataset and Settings,[0],[0]
A set of candidate target entities are ranked using different methods.,4.1 Dataset and Settings,[0],[0]
"For fact prediction, the true test triples are ranked with some generated false triples.",4.1 Dataset and Settings,[0],[0]
Most KG reasoning methods are based on either path formulas or KG embeddings.,4.2 Baselines and Implementation Details,[0],[0]
we explore methods from both of these two classes in our experiments.,4.2 Baselines and Implementation Details,[0],[0]
"For path based methods, we compare our RL model with the PRA (Lao et al., 2011a) algorithm, which has been used in a couple of reasoning methods (Gardner et al., 2013; Neelakantan et al., 2015).",4.2 Baselines and Implementation Details,[0],[0]
PRA is a data-driven algorithm using random walks (RW) to find paths and obtain path features.,4.2 Baselines and Implementation Details,[0],[0]
"For embedding based methods, we evaluate several state-of-the-art embeddings designed for knowledge base completion, such as TransE (Bordes et al., 2013), TransH (Wang et al., 2014), TransR",4.2 Baselines and Implementation Details,[0],[0]
"(Lin et al., 2015) and TransD (Ji et al., 2015) .
",4.2 Baselines and Implementation Details,[0],[0]
"The implementation of PRA is based on the
code released by (Lao et al., 2011a).",4.2 Baselines and Implementation Details,[0],[0]
We use the TopK negative mode to generate negative samples for both train and test samples.,4.2 Baselines and Implementation Details,[0],[0]
"For each positive samples, there are approximately 10 corresponding negative samples.",4.2 Baselines and Implementation Details,[0],[0]
Each negative sample is generated by replacing the true target entity t with a faked one t ′,4.2 Baselines and Implementation Details,[0],[0]
"in each triple (h, r, t).",4.2 Baselines and Implementation Details,[0],[0]
These positive and negative test pairs generated by PRA make up the test set for all methods evaluated in this paper.,4.2 Baselines and Implementation Details,[0],[0]
"For TransE,R,H,D, we learn a separate embedding matrix for each reasoning task using the positive training entity pairs.",4.2 Baselines and Implementation Details,[0],[0]
"All these embeddings are trained for 1,000 epochs.",4.2 Baselines and Implementation Details,[0],[0]
"2
Our RL model make use of TransE to get the continuous representation of the entities and relations.",4.2 Baselines and Implementation Details,[0],[0]
"We use the same dimension as TransE, R to embed the entities.",4.2 Baselines and Implementation Details,[0],[0]
"Specifically, the state vector we use has a dimension of 200, which is also the input size of the policy network.",4.2 Baselines and Implementation Details,[0],[0]
"To reason using the path formulas, we adopt a similar linear regression approach as in PRA to re-rank the paths.",4.2 Baselines and Implementation Details,[0],[0]
"However, instead of using the random walk probabilities as path features, which can be computationally expensive, we simply use binary path features obtained by the bi-directional search.",4.2 Baselines and Implementation Details,[0],[0]
"We observe that with only a few mined path formulas, our method can achieve better results than PRA’s data-driven approach.",4.2 Baselines and Implementation Details,[0],[0]
Link Prediction This task is to rank the target entities given a query entity.,4.3.1 Quantitative Results,[0],[0]
"Table 2 shows the mean average precision (MAP) results on two datasets.
2The implementation we used can be found at https: //github.com/thunlp/Fast-TransX",4.3.1 Quantitative Results,[0],[0]
"Since path-based methods generally work better than embedding methods for this task, we do not include the other two embedding baselines in this table.",RL 0.311 0.493,[0],[0]
"Instead, we spare the room to show the detailed results on each relation reasoning task.
",RL 0.311 0.493,[0],[0]
"For the overall MAP shown in the last row of the table, our approach significantly outperforms both the path-based method and embedding methods on two datasets, which validates the strong reasoning ability of our RL model.",RL 0.311 0.493,[0],[0]
"For most relations, since the embedding methods fail to use the path infor-
mation in the KG, they generally perform worse than our RL model or PRA.",RL 0.311 0.493,[0],[0]
"However, when there are not enough paths between entities, our model and PRA can give poor results.",RL 0.311 0.493,[0],[0]
"For example, for the relation filmWrittenBy, our RL model only finds 4 unique reasoning paths, which means there is actually not enough reasoning evidence existing in the KG.",RL 0.311 0.493,[0],[0]
Another observation is that we always get better performance on the NELL dataset.,RL 0.311 0.493,[0],[0]
"By analyzing the paths found from the KGs, we believe the potential reason is that the NELL dataset has more short paths than FB15K-237 and some of them are simply synonyms of the reasoning relations.",RL 0.311 0.493,[0],[0]
"Fact Prediction Instead of ranking the target entities, this task directly ranks all the positive and negative samples for a particular relation.",RL 0.311 0.493,[0],[0]
"The PRA is not included as a baseline here, since the PRA code only gives a target entity ranking for each query node instead of a ranking of all triples.",RL 0.311 0.493,[0],[0]
Table 3 shows the overall results of all the methods.,RL 0.311 0.493,[0],[0]
Our RL model gets even better results on this task.,RL 0.311 0.493,[0],[0]
We also observe that the RL model beats all the embedding baselines on most reasoning tasks.,RL 0.311 0.493,[0],[0]
"To analyze the properties of reasoning paths, we show a few reasoning paths found by the agent in Table 5.",4.3.2 Qualitative Analysis of Reasoning Paths,[0],[0]
"To illustrate the effect of the efficiency reward function, we show the path length distributions in Figure 2.",4.3.2 Qualitative Analysis of Reasoning Paths,[0],[0]
"To interpret these paths, take the personNationality relation for example, the first reasoning path indicates that if we know facts placeOfBirth(x,y) and locationContains(z,y) then it is highly possible that person x has nationality z.",4.3.2 Qualitative Analysis of Reasoning Paths,[0],[0]
These short but predictive paths indicate the effectiveness of the RL model.,4.3.2 Qualitative Analysis of Reasoning Paths,[0],[0]
"Another important observation is that our model use much
fewer reasoning paths than PRA, which indicates that our model can actually extract the most reliable reasoning evidence from KG.",4.3.2 Qualitative Analysis of Reasoning Paths,[0],[0]
Table 4 shows some comparisons about the number of reasoning paths.,4.3.2 Qualitative Analysis of Reasoning Paths,[0],[0]
"We can see that, with the pre-defined reward functions, the RL agent is capable of picking the strong ones and filter out similar or irrelevant ones.",4.3.2 Qualitative Analysis of Reasoning Paths,[0],[0]
"As mentioned in Section 3.2, one major challenge for applying RL to KG reasoning is the large action space.",4.3.3 Effect of Supervised Learning,[0],[0]
We address this issue by applying supervised learning before the reward retraining step.,4.3.3 Effect of Supervised Learning,[0],[0]
"To show the effect of the supervised training, we evaluate the agent’s success ratio of reaching the target within 10 steps (succ10) after different number of training episodes.",4.3.3 Effect of Supervised Learning,[0],[0]
"For each training episode, one pair of entities (esource, etarget) in the train set is used to find paths.",4.3.3 Effect of Supervised Learning,[0],[0]
All the correct paths linking the entities will get a +1 global reward.,4.3.3 Effect of Supervised Learning,[0],[0]
We then plug in some true paths for training.,4.3.3 Effect of Supervised Learning,[0],[0]
The succ10 is calculated on a held-out test set that consists of 100 entity pairs.,4.3.3 Effect of Supervised Learning,[0],[0]
"For the NELL995 dataset, since we have 200 unique relations, the dimension of the action space will be 400 after we add the backward actions.",4.3.3 Effect of Supervised Learning,[0],[0]
This means that random walks will get very low succ10 since there may be nearly 40010 invalid paths.,4.3.3 Effect of Supervised Learning,[0],[0]
Figure 3 shows the succ10 during training.,4.3.3 Effect of Supervised Learning,[0],[0]
"We see that even the agent has not seen the entity before, it can actually pick the promising relation to extend its path.",4.3.3 Effect of Supervised Learning,[0],[0]
"This also validates the effectiveness of our state representations.
",4.3.3 Effect of Supervised Learning,[0],[0]
3The confidence band is generated using 50 different runs.,4.3.3 Effect of Supervised Learning,[0],[0]
"In this paper, we propose a reinforcement learning framework to improve the performance of relation reasoning in KGs.",5 Conclusion and Future Work,[0],[0]
"Specifically, we train a RL agent to find reasoning paths in the knowledge base.",5 Conclusion and Future Work,[0],[0]
"Unlike previous path finding models that are based on random walks, the RL model allows us to control the properties of the found paths.",5 Conclusion and Future Work,[0],[0]
These effective paths can also be used as an alternative to PRA in many path-based reasoning methods.,5 Conclusion and Future Work,[0],[0]
"For two standard reasoning tasks, using the RL paths as reasoning formulas, our approach generally outperforms two classes of baselines.
",5 Conclusion and Future Work,[0],[0]
"For future studies, we plan to investigate the possibility of incorporating adversarial learning (Goodfellow et al., 2014) to give better rewards than the human-defined reward functions used in this work.",5 Conclusion and Future Work,[0],[0]
"Instead of designing rewards according to path characteristics, a discriminative model can be trained to give rewards.",5 Conclusion and Future Work,[0],[0]
"Also, to address the problematic scenario when the KG does not have enough reasoning paths, we are interested in applying our RL framework to joint reasoning with KG triples and text mentions.",5 Conclusion and Future Work,[0],[0]
We study the problem of learning to reason in large scale knowledge graphs (KGs).,abstractText,[0],[0]
"More specifically, we describe a novel reinforcement learning framework for learning multi-hop relational paths: we use a policy-based agent with continuous states based on knowledge graph embeddings, which reasons in a KG vector space by sampling the most promising relation to extend its path.",abstractText,[0],[0]
"In contrast to prior work, our approach includes a reward function that takes the accuracy, diversity, and efficiency into consideration.",abstractText,[0],[0]
"Experimentally, we show that our proposed method outperforms a path-ranking based algorithm and knowledge graph embedding methods on Freebase and Never-Ending Language Learning datasets.1",abstractText,[0],[0]
DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 433–438 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Models tackling vision-to-language (V2L) tasks, for example Image Captioning (IC) and Visual Question Answering (VQA), have demonstrated impressive results in recent years in terms of automatic metric scores.",1 Introduction,[0],[0]
"However, whether or not these models are actually learning to address the tasks they are designed for is questionable.",1 Introduction,[0],[0]
"For example, Hodosh and Hockenmaier (2016) showed that IC models do not understand images sufficiently, as reflected by the generated captions.",1 Introduction,[0],[0]
"As a consequence, in the last few years many diagnostic tasks and datasets have been proposed aiming at investigating the capabilities of such models in more detail to determine whether and how these models are capable of exploiting visual and/or linguistic information (Shekhar et al., 2017b; John-
son et al., 2017; Antol et al., 2015; Chen et al., 2015; Gao et al., 2015; Yu et al., 2015; Zhu et al., 2016).
FOIL (Shekhar et al., 2017b) is one such dataset.",1 Introduction,[0],[0]
It was proposed to evaluate the ability of V2L models in understanding the interplay of objects and their attributes in the images and their relations in an image captioning framework.,1 Introduction,[0],[0]
"This is done by replacing a word in MSCOCO (Lin et al., 2014) captions with a ‘foiled’ word that is semantically similar or related to the original word (substituting dog with cat), thus rendering the image caption unfaithful to the image content, while yet linguistically valid.",1 Introduction,[0],[0]
Shekhar et al. (2017b) report poor performance for V2L models in classifying captions as foiled (or not).,1 Introduction,[0],[0]
"They suggested that their models (using image embeddings as input) are very poor at encoding structured visuallinguistic information to spot the mismatch between a foiled caption and the corresponding content depicted in the image.
",1 Introduction,[0],[0]
"In this paper, we focus on the foiled captions classification task (Section 2), and propose the use of explicit object detections as salient image cues for solving the task.",1 Introduction,[0],[0]
"In contrast to methods from previous work that make use of word based information extracted from captions (Heuer et al., 2016; Yao et al., 2016; Wu et al., 2018), we use explicit object category information directly extracted from the images.",1 Introduction,[0],[0]
"More specifically, we use an interpretable bag of objects as image representation for the classifier.",1 Introduction,[0],[0]
"Our hypothesis is that, to truly ‘understand’ the image, V2L models should exploit information about objects and their relations in the image and not just global, low-level image embeddings as used by most V2L models.
",1 Introduction,[0],[0]
"Our main contributions are:
1.",1 Introduction,[0],[0]
"A model (Section 3) for foiled captions classification using a simple and interpretable
433
object-based representation, which leads to the best performance in the task (Section 4);
2.",1 Introduction,[0],[0]
"Insights on upper-bound performance for foiled captions classification using gold standard object annotations (Section 4);
3.",1 Introduction,[0],[0]
"An analysis of the models, providing insights into the reasons for their strong performance (Section 5).
",1 Introduction,[0],[0]
"Our results reveal that the FOIL dataset has a very strong linguistic bias, and that the proposed simple object-based models are capable of finding salient patterns to solve the task.",1 Introduction,[0],[0]
"In this section we describe the foiled caption classification task and dataset.
",2 Background,[0],[0]
We combine the tasks and data from Shekhar et al. (2017b) and Shekhar et al. (2017a).,2 Background,[0],[0]
"Given an image and a caption, in both cases the task is to learn a model that can distinguish between a REAL caption that describes the image, and a FOILed caption where a word from the original caption is swapped such that it no longer describes the image accurately.",2 Background,[0],[0]
"There are several sets of ‘foiled captions’ where words from specific parts of speech are swapped:
• Foiled Noun: In this case a noun word in the original caption is replaced with another similar noun, such that the resultant caption is not the correct description for the image.",2 Background,[0],[0]
"The foiled noun is obtained from list of object annotations from MSCOCO (Lin et al., 2014) and nouns are constrained to the same supercategory;
",2 Background,[0],[0]
"• Foiled Verb: Here, verb is foiled with a similar verb.",2 Background,[0],[0]
"The similar verb is extracted using external resources;
• Foiled Adjective and Adverb: Adjectives and adverbs are replaced with similar adjectives and adverbs.",2 Background,[0],[0]
"Here, the notion of similarity again is obtained from external resources;
• Foiled Preposition: Prepositions are directly replaced with functionally similar prepositions.
",2 Background,[0],[0]
"The Verb, Adjective, Adverb and Preposition subsets were obtained using a slightly different
methodology (see Shekhar et al. (2017a))",2 Background,[0],[0]
"than that used for Nouns (Shekhar et al., 2017b).",2 Background,[0],[0]
"Therefore, we evaluate these two groups separately.",2 Background,[0],[0]
"For the foiled caption classification task (Section 3.1), our proposed model uses information from explicit object detections as an object-based image representation along with textual representations (Section 3.2) as input to several different classifiers (Section 3.3).",3 Proposed Model,[0],[0]
"Let y ∈ {REAL, FOIL} denote binary class labels.",3.1 Model definition,[0],[0]
"The objective is to learn a model that computes P (y|I;C), where I and C correspond to the image and caption respectively.",3.1 Model definition,[0],[0]
"Our model seeks to maximize a scoring function θ:
y = argmax θ(I;C)",3.1 Model definition,[0],[0]
(1),3.1 Model definition,[0],[0]
Our scoring function θ takes in image features and text features (from captions) and concatenates them.,3.2 Representations,[0],[0]
"We experiment with various types of features.
",3.2 Representations,[0],[0]
"For the image side, we propose a bag of objects representation for 80 pre-defined MSCOCO categories.",3.2 Representations,[0],[0]
"We consider two variants: (a) Object Mention: A binary vector where we encode the presence/absence of instances of each object category for a given image; (b) Object Frequency: A histogram vector where we encode the number of instances of each object category in a given image.
",3.2 Representations,[0],[0]
"For both features, we use Gold MSCOCO object annotations as well as Predicted object detections using YOLO (Redmon and Farhadi, 2017) pre-trained on MSCOCO to detect instances of the 80 categories.
",3.2 Representations,[0],[0]
"As comparison, we also compute a standard CNN-based image representation, using the POOL5 layer of a ResNet-152 (He et al., 2016)",3.2 Representations,[0],[0]
CNN pre-trained on ImageNet.,3.2 Representations,[0],[0]
"We posit that our object-based representation will better capture semantic information corresponding to the text compared to the CNN embeddings used directly as a feature by most V2L models.
",3.2 Representations,[0],[0]
"For the language side, we explore two features: (a) a simple bag of words (BOW) representation for each caption; (b) an LSTM classifier based model trained on the training part of the dataset.
",3.2 Representations,[0],[0]
"Our intuition is that an image description/caption is essentially a result of the interaction between important objects in the image (this includes spatial relations, co-occurrences, etc.).",3.2 Representations,[0],[0]
"Thus, representations explicitly encoding objectlevel information are better suited for the foiled caption classification task.",3.2 Representations,[0],[0]
Three types of classifiers are explored: (a) Multilayer Perceptron (MLP):,3.3 Classifiers,[0],[0]
"For BOW-based text representations, a two 100-dimensional hidden layer MLP with ReLU activation function is used with cross-entropy loss, and is optimized with Adam (learning rate 0.001); (b) LSTM Classifier: For LSTM-based text representations, a uni-directional LSTM classifier is used with 100-dimensional word embeddings and 200- dimensional hidden representations.",3.3 Classifiers,[0],[0]
We train it using cross-entropy loss and optimize it using Adam (learning rate 0.001).,3.3 Classifiers,[0],[0]
Image representations are appended to the final hidden state of the LSTM; (c) Multimodal LSTM (MM-LSTM),3.3 Classifiers,[0],[0]
"Classifier: As above, except that we initialize the LSTM with the image representation instead of appending it to its output.",3.3 Classifiers,[0],[0]
This can also be seen as am image grounded LSTM based classifier.,3.3 Classifiers,[0],[0]
Data:,4 Experiments,[0],[0]
We use the dataset for nouns from Shekhar et al. (2017b)1 and the datasets for other parts of speech from Shekhar et al. (2017a) 2.,4 Experiments,[0],[0]
Statistics about the dataset are given in Table 1.,4 Experiments,[0],[0]
"The evaluation metric is accuracy per class and the average (overall) accuracy over the two classes.
",4 Experiments,[0],[0]
Performance on nouns: The results of our experiments with foiled nouns are summarized in Table 2.,4 Experiments,[0],[0]
"First, we note that the models that use Gold
1https://foilunitn.github.io/ 2The authors have kindly provided us the datasets.
bag of objects information are the best performing models across classifiers.",4 Experiments,[0],[0]
We also note that the performance is better than human performance.,4 Experiments,[0],[0]
"We hypothesize the following reasons for this: (a) human responses were crowd-sourced, which could have resulted in some noisy annotations; (b) our gold object-based features closely resembles the information used for data-generation as described in Shekhar et al. (2017b) for the foil noun dataset.",4 Experiments,[0],[0]
The models using Predicted bag of objects from a detector are very close to the performance of Gold.,4 Experiments,[0],[0]
The performance of models using simple bag of words (BOW) sentence representations and an MLP is better than that of models that use LSTMs.,4 Experiments,[0],[0]
"Also, the accuracy of the bag of objects model with Frequency counts is higher than with the binary Mention vector, which only encodes the presence of objects.",4 Experiments,[0],[0]
The Multimodal LSTM (MM-LSTM) has a slightly better performance than LSTM classifiers.,4 Experiments,[0],[0]
"In all cases, we observe that the performance is on par with human-level accuracy.",4 Experiments,[0],[0]
Our overall accuracy is substantially higher than that reported in Shekhar et al. (2017b).,4 Experiments,[0],[0]
"Interestingly, our implementation of CNN+LSTM produced better results than their equivalent model (they reported 61.07% vs. our 87.45%).",4 Experiments,[0],[0]
"We investigate this further in Section 5.
",4 Experiments,[0],[0]
"Performance on other parts of speech: For other parts of speech, we fix the image representation to Gold Frequency, and compare results using the BOW-based MLP and MM-LSTM.",4 Experiments,[0],[0]
We also compare the scores to the state of the art reported in Shekhar et al. (2017a).,4 Experiments,[0],[0]
"Note that this
model does not use gold object information and may thus not be directly comparable – we however recall that only a slight drop in accuracy was found for our models when using predicted object detections rather than gold ones.",4 Experiments,[0],[0]
Our findings are summarized in Table 3.,4 Experiments,[0],[0]
The classification performance is not as high as it was for the nouns dataset.,4 Experiments,[0],[0]
"Noteworthy is the performance on adverbs, which is significantly lower than the performance across other parts of speech.",4 Experiments,[0],[0]
We hypothesize that this is because of the imbalanced distribution of foiled and real captions in the dataset.,4 Experiments,[0],[0]
"We also found that the performance of LSTM-based models on other parts of speech datasets are almost always better than BOW-based models, indicating the necessity of more sophisticated features.",4 Experiments,[0],[0]
"In this section, we attempt to better understand why our models achieve such a high accuracy.",5 Analysis,[0],[0]
We first perform ablation experiments with our proposed models over the Nouns dataset (FOIL).,5.1 Ablation Analysis,[0],[0]
"We compute image-only models (CNN or Gold Frequency) and text-only models (BOW or LSTM), and investigate which components of our model (text or image/objects) contribute to the strong classification performance (Table 4).",5.1 Ablation Analysis,[0],[0]
"As expected, we cannot classify foiled captions given only image information (global or object-level), resulting in chance-level performance.
",5.1 Ablation Analysis,[0],[0]
"On the other hand, text-only models achieve a
very high accuracy.",5.1 Ablation Analysis,[0],[0]
"This is a central finding, suggesting that foiled captions are easy to detect even without image information.",5.1 Ablation Analysis,[0],[0]
"We also observe that the performance of BOW improves by adding object Frequency image information, but not CNN image embeddings.",5.1 Ablation Analysis,[0],[0]
We posit that this is because there is a tighter correspondence between the bag of objects and bag of word models.,5.1 Ablation Analysis,[0],[0]
"In the case of LSTMs, adding either image information helps slightly.",5.1 Ablation Analysis,[0],[0]
"The accuracy of our models is substantially higher than that reported in Shekhar et al. (2017b), even for equivalent models.
",5.1 Ablation Analysis,[0],[0]
"We note, however, that while the trends of image information is similar for other parts of speech datasets, the performance of BOW based models are lower than the performance of LSTM based models.",5.1 Ablation Analysis,[0],[0]
The anomaly of improved performance of BOW based models seems heavily pronounced in the nouns dataset.,5.1 Ablation Analysis,[0],[0]
"Thus, we further analyze our model in the next section to shed light on whether the high performance is due to the models or the dataset itself.",5.1 Ablation Analysis,[0],[0]
"We apply Local Interpretable Model-agnostic Explanations (Ribeiro et al., 2016) to further understand the strong performance of our simple classifier on the Nouns dataset (FOIL) without any image information.",5.2 Feature Importance Analysis,[0],[0]
We present an example in Figure 1.,5.2 Feature Importance Analysis,[0],[0]
We use MLP with BOW only (no image information) as our classifier.,5.2 Feature Importance Analysis,[0],[0]
"As the caption is correctly predicted to be foiled, we observe that the most important feature for classification is the information on the word ball, which also happens to be the foiled word.",5.2 Feature Importance Analysis,[0],[0]
We further analyzed the chances of this happening on the entire test set.,5.2 Feature Importance Analysis,[0],[0]
We found that 96.56% of the time the most important classification feature happens to be the foiled word.,5.2 Feature Importance Analysis,[0],[0]
"This firmly indicates that there is a very strong linguistic bias in the training data, despite
the claim in Shekhar et al. (2017b) that special attention was paid to avoid linguistic biases in the dataset.3",5.2 Feature Importance Analysis,[0],[0]
We note that we were not able to detect the linguistic bias in the other parts of speech datasets.,5.2 Feature Importance Analysis,[0],[0]
We presented an object-based image representation derived from explicit object detectors/gold annotations to tackle the task of classifying foiled captions.,6 Conclusions,[0],[0]
"The hypothesis was that such models provide the necessary semantic information for the task, while this informaiton is not explicitly present in CNN image embeddings commonly used in V2L tasks.",6 Conclusions,[0],[0]
"We achieved stateof-the-art performance on the task, and also provided a strong upper-bound using gold annotations.",6 Conclusions,[0],[0]
"A significant finding is that our simple models, especially for the foiled noun dataset, perform well even without image information.",6 Conclusions,[0],[0]
"This could be partly due to the strong linguistic bias in the foiled noun dataset, which was revealed by our analysis on our interpretable object-based models.",6 Conclusions,[0],[0]
We release our analysis and source code at https://github.com/ sheffieldnlp/foildataset.git.,6 Conclusions,[0],[0]
This work is supported by the MultiMT project (H2020 ERC Starting Grant,Acknowledgments,[0],[0]
No. 678017).,Acknowledgments,[0],[0]
"The authors also thank the anonymous reviewers for their valuable feedback on an earlier draft of the paper.
",Acknowledgments,[0],[0]
3Shekhar et al. (2017b) have acknowledged about the bias in our personal communications and are currently working on a fix,Acknowledgments,[0],[0]
"We address the task of detecting foiled image captions, i.e. identifying whether a caption contains a word that has been deliberately replaced by a semantically similar word, thus rendering it inaccurate with respect to the image being described.",abstractText,[0],[0]
Solving this problem should in principle require a fine-grained understanding of images to detect linguistically valid perturbations in captions.,abstractText,[0],[0]
"In such contexts, encoding sufficiently descriptive image information becomes a key challenge.",abstractText,[0],[0]
"In this paper, we demonstrate that it is possible to solve this task using simple, interpretable yet powerful representations based on explicit object information.",abstractText,[0],[0]
"Our models achieve stateof-the-art performance on a standard dataset, with scores exceeding those achieved by humans on the task.",abstractText,[0],[0]
We also measure the upperbound performance of our models using gold standard annotations.,abstractText,[0],[0]
"Our analysis reveals that the simpler model performs well even without image information, suggesting that the dataset contains strong linguistic bias.",abstractText,[0],[0]
Defoiling Foiled Image Captions,title,[0],[0]
"Machine learning commonly considers static objectives defined on a snapshot of the population at one instant in time; consequential decisions, in contrast, reshape the population over time.",1 Introduction,[0],[0]
"Lending practices, for example, can shift the distribution of debt and wealth in the population.",1 Introduction,[0],[0]
Job advertisements allocate opportunity.,1 Introduction,[0],[0]
"School admissions shape the level of education in a community.
",1 Introduction,[0],[0]
Existing scholarship on fairness in automated decisionmaking criticizes unconstrained machine learning for its potential to harm historically underrepresented or disadvantaged groups in the population,1 Introduction,[0],[0]
"[Executive Office of the President, 2016; Barocas and Selbst, 2016].",1 Introduction,[0],[0]
"Consequently, a variety of fairness criteria have been proposed as constraints on standard learning objectives.",1 Introduction,[0],[0]
"Even though, in each case, these constraints are clearly intended to protect the disadvantaged group by an appeal to intuition, a rigorous argument to that effect is often lacking.
",1 Introduction,[0],[0]
"In this work, we formally examine under what circumstances fairness criteria do indeed promote the long-term well-being of disadvantaged groups measured in terms of a temporal variable of interest.",1 Introduction,[0],[0]
"Going beyond the standard classification setting, we introduce a one-step feedback model of
∗This paper is an abridged version of the paper of the same name which appeared at the 35th International Conference of Machine Learning",1 Introduction,[0],[0]
"[Liu et al., 2018].",1 Introduction,[0],[0]
"The interested reader is referred to the full version for extended results and discussion.
decision-making that exposes how decisions change the underlying population over time.
",1 Introduction,[0],[0]
Our running example is a hypothetical lending scenario.,1 Introduction,[0],[0]
"There are two groups in the population with features described by a summary statistic, such as a credit score, whose distribution differs between the two groups.",1 Introduction,[0],[0]
The bank can choose thresholds for each group at which loans are offered.,1 Introduction,[0],[0]
"While group-dependent thresholds may face legal challenges [Ross and Yinger, 2006], they are generally inevitable for some of the criteria we examine.",1 Introduction,[0],[0]
The impact of a lending decision has multiple facets.,1 Introduction,[0],[0]
"A default event not only diminishes profit for the bank, it also worsens the financial situation of the borrower as reflected in a subsequent decline in credit score.",1 Introduction,[0],[0]
"A successful lending outcome leads to profit for the bank and also to an increase in credit score for the borrower.
",1 Introduction,[0],[0]
"When thinking of one of the two groups as disadvantaged, it makes sense to ask what lending policies (choices of thresholds) lead to an expected improvement in the score distribution within that group.",1 Introduction,[0],[0]
"An unconstrained bank would maximize profit, choosing thresholds that meet a break-even point above which it is profitable to give out loans.",1 Introduction,[0],[0]
"One frequently proposed fairness criterion, sometimes called demographic parity, requires the bank to lend to both groups at an equal rate.",1 Introduction,[0],[0]
Subject to this requirement the bank would continue to maximize profit to the extent possible.,1 Introduction,[0],[0]
"Another criterion, originally called equality of opportunity, equalizes the true positive rates between the two groups, thus requiring the bank to lend in both groups at an equal rate among individuals who repay their loan.",1 Introduction,[0],[0]
"Other criteria are natural, but for clarity we restrict our attention to these three.
",1 Introduction,[0],[0]
Do these fairness criteria benefit the disadvantaged group?,1 Introduction,[0],[0]
When do they show a clear advantage over unconstrained classification?,1 Introduction,[0],[0]
Under what circumstances does profit maximization work in the interest of the individual?,1 Introduction,[0],[0]
These are important questions that we begin to address in this work.,1 Introduction,[0],[0]
We introduce a one-step feedback model that allows for the quantification of the long-term impact of classification on different groups in the population.,2 Problem Setting,[0],[0]
"Individuals are assigned scores in X := {1, . . .",2 Problem Setting,[0],[0]
", C}, where a score highlights one variable of interest in a specific domain such that higher score values correspond to a higher probability of a positive outcome.",2 Problem Setting,[0],[0]
"This score is used by an institution, which makes a
binary decision for each individual in each group.",2 Problem Setting,[0],[0]
The institution designs selection policies τ :,2 Problem Setting,[0],[0]
"X → [0, 1] that assign to each possible score a number representing the rate of selection for that value.",2 Problem Setting,[0],[0]
"In our example, these policies specify the lending rate at a given credit score.",2 Problem Setting,[0],[0]
"We consider policies designed to maximize the utility of the institution, potentially subject to fairness constraints.
",2 Problem Setting,[0],[0]
"To measure the impact of decisions, we assume the availability of a function ∆ : X → R that provides the expected change in score for a selected individual at a given score.",2 Problem Setting,[0],[0]
The central quantity we study is the expected difference ∆µ in the mean score that results from the selection policy.,2 Problem Setting,[0],[0]
"When modeling the problem, the expected mean difference can also absorb external factors so long as they are mean-preserving.
",2 Problem Setting,[0],[0]
We focus on the impact of a selection policy over a single epoch.,2 Problem Setting,[0],[0]
The motivation is that the designer of a system usually has an understanding of the time horizon after which the system is evaluated and possibly redesigned.,2 Problem Setting,[0],[0]
"Formally, nothing prevents the repeated application of our model and to trace changes over multiple epochs.",2 Problem Setting,[0],[0]
"In reality, however, it is plausible that over greater time periods, economic background variables might dominate the effect of selection.
",2 Problem Setting,[0],[0]
"To compare the impact of classification for different groups, we consider two groups A and B, which comprise a gA and gB = 1 − gA fraction of the total population.",2 Problem Setting,[0],[0]
"We use subscripts on previously defined quantities to denote the group-specific values, e.g. πA denotes the distribution of A over scores.",2 Problem Setting,[0],[0]
"We assume that that there exists a function u : X → R, such that the institution’s expected utility for a policy τ is additive over individuals:
U(τ ) = ∑ j∈{A,B} gj ∑",2 Problem Setting,[0],[0]
x∈X τ j(x)πj(x)u(x).,2 Problem Setting,[0],[0]
"(1)
Then we consider how the outcome of the decision differs between groups.",2 Problem Setting,[0],[0]
"The average change of the mean score µj for group j is given by
∆µj(τ )",2 Problem Setting,[0],[0]
:= ∑ x∈X πj(x)τ j(x)∆(x) .,2 Problem Setting,[0],[0]
"(2)
We remark that many of our results also go through if ∆µj(τ ) simply refers to an abstract change in group well-being, not necessarily a change in the mean score.",2 Problem Setting,[0],[0]
"Lastly, we assume that the success of an individual is independent of their group given the score; that is, the score summarizes all relevant information about the success event, so there exists a function ρ :",2 Problem Setting,[0],[0]
"X → [0, 1] such that individuals of score x succeed with probability ρ(x).
",2 Problem Setting,[0],[0]
Example 2.1 (Credit scores).,2 Problem Setting,[0],[0]
"In the setting of loans, scores x ∈",2 Problem Setting,[0],[0]
"[C] represent credit scores, and the bank serves as the institution.",2 Problem Setting,[0],[0]
The bank chooses to grant or refuse loans to individuals according to a policy τ .,2 Problem Setting,[0],[0]
"Both the profit and the change in credit score are given as functions of loan repayment, and therefore depend on the success probabilities ρ(x), representing the probability that any individual with credit score x can repay a loan within a fixed time frame.",2 Problem Setting,[0],[0]
"The expected utility to the bank is given by the expected return from a loan, which can be modeled as an affine function of ρ(x): u(x) = u+ρ(x) + u−(1 − ρ(x)), where u+ denotes the profit when loans are repaid and u− the loss when they are defaulted on.",2 Problem Setting,[0],[0]
"Individual outcomes of being granted a loan
OUTCOME CURVE
are based on whether or not an individual repays the loan, and a simple model for ∆(x) may also be affine in ρ(x): ∆(x) = c+ρ(x) + c−(1 − ρ(x)), modified accordingly at boundary states.",2 Problem Setting,[0],[0]
The constant c+ > 0 denotes the gain in credit score if loans are repaid and c− < 0,2 Problem Setting,[0],[0]
is the score penalty in case of default.,2 Problem Setting,[0],[0]
"We now introduce important outcome regimes, stated in terms of the change in average group score.",2.1 The Outcome Curve,[0],[0]
"In particular, we focus on these outcomes for a disadvantaged group, and from this point forward, we take A to be the disadvantaged or protected group.",2.1 The Outcome Curve,[0],[0]
We denote the policy that maximizes the institution’s utility in the absence of constraints as MaxUtil.,2.1 The Outcome Curve,[0],[0]
"Under our model, MaxUtil policies can be chosen in a standard fashion which applies the same threshold τ",2.1 The Outcome Curve,[0],[0]
"MaxUtil for both groups, and is agnostic to the distributions πA and πB.",2.1 The Outcome Curve,[0],[0]
"Hence, if we define
∆µMaxUtilj := ∆µj(τ MaxUtil) (3)
we say that a policy causes relative harm to the protected group if ∆µA(τA)",2.1 The Outcome Curve,[0],[0]
<,2.1 The Outcome Curve,[0],[0]
"∆µ MaxUtil A , relative improvement if ∆µA(τA) >",2.1 The Outcome Curve,[0],[0]
"∆µ MaxUtil A , and active harm if ∆µA(τA)",2.1 The Outcome Curve,[0],[0]
"< 0.
",2.1 The Outcome Curve,[0],[0]
Figure 1 displays the important outcome regimes in terms of selection rates βj := ∑ x∈X πj(x)τ j(x).,2.1 The Outcome Curve,[0],[0]
"This succinct characterization is possible when considering decision rules based on score thresholding, in which all individuals with scores above a threshold are selected.",2.1 The Outcome Curve,[0],[0]
"To explicitly connect selection rates to decision policies, we define the rate function rπj(τ j) which returns the proportion of group j selected by the policy.",2.1 The Outcome Curve,[0],[0]
"In the following, we will abuse notation to abbreviate ∆µj(r −1",2.1 The Outcome Curve,[0],[0]
πj (β)) as ∆µj(β).,2.1 The Outcome Curve,[0],[0]
Now we define the values of β that mark boundaries of the outcome regions: Definition 2.1 (Selection rates of interest).,2.1 The Outcome Curve,[0],[0]
"Given the protected group A, the following selection rates are of interest in distinguishing between qualitatively different classes of outcomes (Figure 1): βMaxUtil is the selection rate for A under MaxUtil; β0 is the harm threshold, such that ∆µA(β0) = 0; β∗ is the selection rate such that ∆µA is maximized; β
is the outcome-complement of the MaxUtil selection rate, ∆µA(β) = ∆µA(β MaxUtil) with β ≥ βMaxUtil.",2.1 The Outcome Curve,[0],[0]
"We will consider policies that maximize the institution’s total expected utility, potentially subject to a constraint set C which enforces some notion of “fairness”.",2.2 Decision Rules and Fairness Criteria,[0],[0]
"Formally, the institution selects τ∗ ∈ argmax U(τ ) s.t. τ ∈ C.",2.2 Decision Rules and Fairness Criteria,[0],[0]
We consider the three following constraints: Definition 2.2 (Fairness criteria).,2.2 Decision Rules and Fairness Criteria,[0],[0]
"The maximum utility (MaxUtil) policy corresponds to the null-constraint, so that the institution is free to focus solely on utility.",2.2 Decision Rules and Fairness Criteria,[0],[0]
The demographic parity (DemParity) policy results in equal selection rates between both groups.,2.2 Decision Rules and Fairness Criteria,[0],[0]
"Formally, the constraint is C = { (τA, τB) : ∑ x∈X πA(x)τA = ∑ x∈X πB(x)τB } .",2.2 Decision Rules and Fairness Criteria,[0],[0]
"The equal opportunity (EqOpt) policy results in equal true positive rates (TPR) between both group, where TPR is defined as TPRj(τ )",2.2 Decision Rules and Fairness Criteria,[0],[0]
:= ∑ x∈X πj(x)ρ(x)τ,2.2 Decision Rules and Fairness Criteria,[0],[0]
"(x)∑
x∈X πj(x)ρ(x) .",2.2 Decision Rules and Fairness Criteria,[0],[0]
"EqOpt en-
sures that the conditional probability of selection given that the individual will be successful is independent of the population, formally enforced by the constraint C = {(τA, τB) : TPRA(τA) = TPRB(τB)} .
",2.2 Decision Rules and Fairness Criteria,[0],[0]
"Just as the expected outcome ∆µ can be expressed in terms of selection rate for threshold policies, so can the total utility U .",2.2 Decision Rules and Fairness Criteria,[0],[0]
"In the unconstrained case, U varies independently over the selection rates for group A and B; however, in the presence of fairness constraints the selection rate for one group determines the allowable selection rate for the other.",2.2 Decision Rules and Fairness Criteria,[0],[0]
"The selection rates must be equal for DemParity, and for EqOpt there is a one-to-one mapping.",2.2 Decision Rules and Fairness Criteria,[0],[0]
"Therefore, when considering threshold policies, decision rules amount to maximizing functions of single parameters.",2.2 Decision Rules and Fairness Criteria,[0],[0]
"This idea is expressed in Figure 2, and underpins the results to follow.",2.2 Decision Rules and Fairness Criteria,[0],[0]
"In order to clearly characterize the outcome of applying fairness constraints, we make the following assumption.
",3 Results,[0],[0]
Assumption 1 (Institution utilities).,3 Results,[0],[0]
"The institution’s individual utility function is more stringent than the expected score changes, u(x)",3 Results,[0],[0]
> 0,3 Results,[0],[0]
=⇒ ∆(x) > 0.,3 Results,[0],[0]
"(For the linear form presented in Example 2.1, u−u+ < c− c+
is necessary and sufficient.)
",3 Results,[0],[0]
This simplifying assumption quantifies the intuitive notion that institutions take a greater risk by accepting than the individual does by applying.,3 Results,[0],[0]
"For example, in the credit setting, a bank loses the amount loaned in the case of a default, but makes only interest in case of a payback.",3 Results,[0],[0]
"Using Assumption 1, we can restrict the position of MaxUtil on the outcome curve in the following sense.",3 Results,[0],[0]
Proposition 3.1 (MaxUtil does not cause active harm).,3 Results,[0],[0]
"Under Assumption 1, 0 ≤ ∆µMaxUtil ≤ ∆µ∗.
We direct the reader to the full version of this paper",3 Results,[0],[0]
"[Liu et al., 2018] for the proof of the above proposition, and all subsequent theorems presented in this section.",3 Results,[0],[0]
We begin by characterizing general settings under which fairness criteria act to improve outcomes over unconstrained MaxUtil strategies.,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
Proposition 3.2 (Fairness criteria can cause relative improvement).,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
Assume that group A is disadvantaged in the sense that the MaxUtil acceptance rate for B is large compared to relevant acceptance rates for A.,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"Then there are general settings under which g0, g1, g2, g3 exist such that (a) DemParity causes relative improvement as long as gA ∈",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"[g0, g1], and (b) EqOpt causes relative improvement as long as gA ∈",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"[g2, g3].
",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"A full description of conditions under which we can guarantee that fairness criteria cause improvement relative to MaxUtil is given in [Liu et al., 2018].",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
The result follows from comparing the position of optima on the utility curve to the outcome curve.,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
Figure 2 displays an illustrative example of both the outcome curve and the institution’s utility U as a function of the selection rates in group A.,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"In the utility function (1), the contributions of each group are weighted by their population proportions gj, and thus the resulting selection rates are sensitive to these proportions.",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"As we see in the remainder of this section, fairness criteria can achieve nearly any position along the outcome curve under the right conditions.",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"This fact comes from the potential mismatch between the outcomes, controlled by ∆, and the institution’s utility u.
The next theorem implies that DemParity can be bad for long term well-being of the protected group by being overgenerous.",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
Proposition 3.3 (DemParity can cause harm by being over-eager).,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
Assume that ∆µA(βMaxUtilB ),3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
< 0.,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
Then there are general settings under which a g0 exists such that DemParity cases active or relative harm as long as gA ∈,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"[0, g0].
",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
Notice that both the assumption and the condition encode notions that could be taken to mean ‘disadvantage:’,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
The assumption says that a policy which selects individuals from group A at the selection rate that MaxUtil would have used for group B necessarily lowers average score in A.,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"The condition requires that gA is small enough.
",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"Using credit scores as an example, Theorem 3.3 tells us that an overly aggressive fairness criterion will give too many loans to people in a protected group who cannot pay them back, hurting the group’s credit scores on average.",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"An analogous result holds for EqOpt, and is stated in [Liu et al., 2018].
3.2",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
Comparing EqOpt and DemParity,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
It is difficult to compare DemParity and EqOpt on general terms.,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"In fact, we have found that settings exist both in which DemParity causes harm while EqOpt causes improvement and in which DemParity causes improvement while EqOpt causes harm.",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
Proposition 3.4 (EqOpt may avoid active harm where DemParity fails).,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"For a simple example of distributions, there exists g0, g1 such that for gA ∈",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"[g0, g1], DemParity causes active harm while EqOpt causes improvement.
",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"In the simple geometry of the example for the above result, EqOpt is better than DemParity at avoiding active harm because it is more conservative.",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
A natural question then is: can EqOpt cause relative harm by being too stingy?,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"Theorem 3.5 (DemParity never loans less than MaxUtil, but EqOpt might).",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
Suppose that the MaxUtil policy is such that βMaxUtilA,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"< β MaxUtil B and TPRA(τ
MaxUtil) >",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
"TPRB(τ
MaxUtil).",3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
Then EqOpt causes relative harm by selecting at a rate lower than MaxUtil.,3.1 Prospects and Pitfalls of Fairness Criteria,[0],[0]
We examine the outcomes induced by fairness constraints in the context of FICO scores for two race groups.,4 Simulations,[0],[0]
FICO scores are a proprietary classifier widely used in the United States to predict credit worthiness.,4 Simulations,[0],[0]
"Our FICO data is based on a sample of 301,536 TransUnion TransRisk scores from 2003 [US Federal Reserve, 2007], preprocessed by [Hardt et al., 2016].",4 Simulations,[0],[0]
"Empirical data labeled by race allows us to estimate the distributions πj, where j represents race, which is restricted to two values: white non-Hispanic (labeled “white” in figures), and black.",4 Simulations,[0],[0]
"We use the outcome and profit models from Example 2.1, with individual penalties as a score drop of c− = −150 in the case of a default, and in increase of c+ = 75 in the case of successful repayment.",4 Simulations,[0],[0]
We also model the utility ratio of the bank as u−u+ = −4.,4 Simulations,[0],[0]
"Further details of the presented simulations are in [Liu et al., 2018].
",4 Simulations,[0],[0]
Figure 3 displays the outcome and utility curves for both the white and the black group.,4 Simulations,[0],[0]
"In this figure, the top panel corresponds to the average simulated change in credit scores for each group under different loaning rates β; the bottom panels shows the corresponding total utility U (summed over both groups and weighted by group population sizes) for the bank.",4 Simulations,[0],[0]
"Although one might hope for decisions made under fairness constraints to positively affect the black group, we observe the opposite behavior for DemParity, which causes a decrease in the average credit score.",4 Simulations,[0],[0]
This behavior stems from a discrepancy in the outcome and profit curves for the black population.,4 Simulations,[0],[0]
"Reflecting on our findings, we argue that careful temporal modeling is necessary in order to accurately evaluate the im-
pact of different fairness criteria on the population.",5 Conclusion,[0],[0]
The nuances of our characterization underline how intuition may be a poor guide in judging the long-term impact of fairness constraints.,5 Conclusion,[0],[0]
"Our formal framework exposes a concise, yet expressive way to model outcomes via the expected change in a variable of interest caused by an institutional decision.",5 Conclusion,[0],[0]
This leads to the natural concept of an outcome curve that allows us to interpret and compare solutions effectively.,5 Conclusion,[0],[0]
"In essence, the formalism we propose requires us to understand the twovariable causal mechanism that translates decisions to outcomes.",5 Conclusion,[0],[0]
"Depending on the application, such an understanding might necessitate greater domain knowledge and additional research into the specifics of the application.",5 Conclusion,[0],[0]
"This is consistent with much scholarship that points to the context-sensitive nature of fairness in machine learning [Green and Hu, 2018].",5 Conclusion,[0],[0]
"We thank Lily Hu, Aaron Roth, and Cathy O’Neil for discussions and feedback on an earlier version of the manuscript.",Acknowledgements,[0],[0]
"We thank the students of CS294: Fairness in Machine Learning (Fall 2017, University of California, Berkeley) for inspiring class discussions and comments on a presentation that was a precursor of this work.",Acknowledgements,[0],[0]
This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE 1752814.,Acknowledgements,[0],[0]
Static classification has been the predominant focus of the study of fairness in machine learning.,abstractText,[0],[0]
"While most models do not consider how decisions change populations over time, it is conventional wisdom that fairness criteria promote the long-term wellbeing of groups they aim to protect.",abstractText,[0],[0]
This work studies the interaction of static fairness criteria with temporal indicators of well-being.,abstractText,[0],[0]
"We show a simple one-step feedback model in which common criteria do not generally promote improvement over time, and may in fact cause harm.",abstractText,[0],[0]
"Our results highlight the importance of temporal modeling in the evaluation of fairness criteria, suggesting a range of new challenges and trade-offs.",abstractText,[0],[0]
Delayed Impact of Fair Machine Learning,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1865–1874 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"The success of natural language generation (NLG) systems depends on their ability to carefully control not only the topic of produced utterances, but also attributes such as sentiment and style.",1 Introduction,[0],[0]
"The desire for more sophisticated, controllable NLG has led to increased interest in text attribute transfer— the task of editing a sentence to alter specific attributes, such as style, sentiment, and tense (Hu
∗Work done while the author was a visiting researcher at Stanford University.
great food but horrible staff and very very rude workers !
target=positivegreat food staff and very workers !
",1 Introduction,[0],[0]
"Delete attribute markers
(b) Attribute transfer
neg pos
pos pos
pos neg
neg neg
worst very disappointed won't be back ...
",1 Introduction,[0],[0]
"delicious great place for well worth ...
(a) Extracting attribute markers
et al., 2017; Shen et al., 2017; Fu et al., 2018).",1 Introduction,[0],[0]
"In each of these cases, the goal is to convert a sentence with one attribute (e.g., negative sentiment) to one with a different attribute (e.g., positive sentiment), while preserving all attribute-independent content1 (e.g., what properties of a restaurant are being discussed).",1 Introduction,[0],[0]
"Typically, aligned sentences with the same content but different attributes are not available; systems must learn to disentangle attributes and content given only unaligned sentences labeled with attributes.
",1 Introduction,[0],[0]
"Previous work has attempted to use adversarial 1 Henceforth, we refer to attribute-independent content as
simply content, for simplicity.
1865
networks (Shen et al., 2017; Fu et al., 2018) for this task, but—as we demonstrate—their outputs tend to be low-quality, as judged by human raters.",1 Introduction,[0],[0]
"These models are also difficult to train (Salimans et al., 2016; Arjovsky and Bottou, 2017; Bousmalis et al., 2017).
",1 Introduction,[0],[0]
"In this work, we propose a set of simpler, easierto-train systems that leverage an important observation: attribute transfer can often be accomplished by changing a few attribute markers— words or phrases in the sentence that are indicative of a particular attribute—while leaving the rest of the sentence largely unchanged.",1 Introduction,[0],[0]
"Figure 1 shows an example in which the sentiment of a sentence can be altered by changing a few sentiment-specific phrases but keeping other words fixed.
",1 Introduction,[0],[0]
"With this intuition, we first propose a simple baseline that already outperforms prior adversarial approaches.",1 Introduction,[0],[0]
Consider a sentiment transfer (negative to positive) task.,1 Introduction,[0],[0]
"First, from unaligned corpora of positive and negative sentences, we identify attribute markers by finding phrases that occur much more often within sentences of one attribute than the other (e.g., “worst” and “very disppointed” are negative markers).",1 Introduction,[0],[0]
"Second, given a sentence, we delete any negative markers in it, and regard the remaining words as its content.",1 Introduction,[0],[0]
"Third, we retrieve a sentence with similar content from the positive corpus.
",1 Introduction,[0],[0]
"We further improve upon this baseline by incorporating a neural generative model, as shown in Figure 1.",1 Introduction,[0],[0]
"Our neural system extracts content words in the same way as our baseline, then generates the final output with an RNN decoder that conditions on the extracted content and the target attribute.",1 Introduction,[0],[0]
"This approach has significant benefits at training time, compared to adversarial networks: having already separated content and attribute, we simply train our neural model to reconstruct sentences in the training data as an auto-encoder.
",1 Introduction,[0],[0]
"We test our methods on three text attribute transfer datasets: altering sentiment of Yelp reviews, altering sentiment of Amazon reviews, and altering image captions to be more romantic or humorous.",1 Introduction,[0],[0]
"Averaged across these three datasets, our simple baseline generated grammatical sentences with appropriate content and attribute 23% of the time, according to human raters; in contrast, the best adversarial method achieved only 12%.",1 Introduction,[0],[0]
"Our best neural system in turn outperformed our baseline, achieving an average
success rate of 34%.",1 Introduction,[0],[0]
"Our code and data, including newly collected human reference outputs for the Yelp and Amazon domains, can be found at https://github.com/lijuncen/ Sentiment-and-Style-Transfer.",1 Introduction,[0],[0]
"We assume access to a corpus of labeled sentences D = {(x1, v1), . . .",2 Problem Statement,[0],[0]
", (xm, vm)}, where xi is a sentence and vi ∈ V , the set of possible attributes (e.g., for sentiment, V = {“positive”, “negative”}).",2 Problem Statement,[0],[0]
"We define Dv = {x : (x, v) ∈ D}, the set of sentences in the corpus with attribute v. Crucially, we do not assume access to a parallel corpus that pairs sentences with different attributes and the same content.
",2 Problem Statement,[0],[0]
"Our goal is to learn a model that takes as input (x, vtgt) where x is a sentence exhibiting source (original) attribute vsrc, and vtgt is the target attribute, and outputs a sentence y that retains the content of x while exhibiting vtgt.",2 Problem Statement,[0],[0]
"As a motivating example, suppose we wanted to change the sentiment of “The chicken was delicious.”",3 Approach,[0],[0]
from positive to negative.,3 Approach,[0],[0]
"Here the word “delicious” is the only sentiment-bearing word, so we just need to replace it with an appropriate negative sentiment word.",3 Approach,[0],[0]
"More generally, we find that the attribute is often localized to a small fraction of the words, an inductive bias not captured by previous work.
",3 Approach,[0],[0]
How do we know which negative sentiment word to insert?,3 Approach,[0],[0]
The key observation is that the remaining content words provide strong cues: given “The chicken was . . .,3 Approach,[0],[0]
"”, one can infer that a tasterelated word like “bland” fits, but a word like “rude” does not, even though both have negative sentiment.",3 Approach,[0],[0]
"In other words, while the deleted sentiment words do contain non-sentiment information too, this information can often be recovered using the other content words.
",3 Approach,[0],[0]
"In the rest of this section, we describe our four systems: two baselines (RETRIEVEONLY and TEMPLATEBASED) and two neural models (DELETEONLY and DELETEANDRETRIEVE).",3 Approach,[0],[0]
An overview of all four systems is shown in Figure 2.,3 Approach,[0],[0]
"Formally, the main components of these systems are as follows:
1.",3 Approach,[0],[0]
"Delete: All 4 systems use the same procedure to separate the words in x into a set of
attribute markers a(x, vsrc) and a sequence of content words c(x, vsrc).
",3 Approach,[0],[0]
2.,3 Approach,[0],[0]
"Retrieve: 3 of the 4 systems look through the corpus and retrieve a sentence xtgt that has the target attribute vtgt and whose content is similar to that of x.
3.",3 Approach,[0],[0]
Generate:,3 Approach,[0],[0]
"Given the content c(x, vsrc), target attribute vtgt, and (optionally) the retrieved sentence xtgt, each system generates y, either in a rule-based fashion or with a neural sequence-to-sequence model.
",3 Approach,[0],[0]
We describe each component in detail below.,3 Approach,[0],[0]
We propose a simple method to delete attribute markers (n-grams) that have the most discriminative power.,3.1 Delete,[0],[0]
"Formally, for any v ∈ V , we define the salience of an n-gram u with respect to v by its (smoothed) relative frequency in Dv:
s(u, v) =",3.1 Delete,[0],[0]
"count(u,Dv) + λ(∑
v′∈V,v′ 6=v count(u,Dv′) )",3.1 Delete,[0],[0]
"+ λ ,
(1) where count(u,Dv) denotes the number of times an n-gram u appears inDv, and λ is the smoothing parameter.",3.1 Delete,[0],[0]
"We declare u to be an attribute marker for v if s(u, v) is larger than a specified threshold γ.",3.1 Delete,[0],[0]
"The attributed markers can be viewed as discriminative features for a Naive Bayes classifier.
",3.1 Delete,[0],[0]
"We define a(x, vsrc) to be the set of all source attribute markers in x, and define c(x, vsrc) as the sequence of words after deleting all markers in a(x, vsrc) from x.",3.1 Delete,[0],[0]
"For example, for “The chicken was delicious,” we would delete “delicious” and consider “The chicken was. . . ”",3.1 Delete,[0],[0]
"to be the content (Figure 2, Step 1).",3.1 Delete,[0],[0]
"To decide what words to insert into c(x, vsrc), one useful strategy is to look at similar sentences with the target attribute.",3.2 Retrieve,[0],[0]
"For example, negative sentences that use phrases similar to “The chicken was. . . ” are more likely to contain “bland” than “rude.”",3.2 Retrieve,[0],[0]
"Therefore, we retrieve sentences of similar content and use target attribute markers in them for insertion.
",3.2 Retrieve,[0],[0]
"Formally, we retrieve xtgt according to:
xtgt = argmin x′∈Dvtgt d(c(x, vsrc), c(x′, vtgt)), (2)
where d may be any distance metric comparing two sequences of words.",3.2 Retrieve,[0],[0]
"We experiment with two options: (i) TF-IDF weighted word overlap and (ii) Euclidean distance using the content embeddings in Section 3.3 (Figure 2, Step 2).",3.2 Retrieve,[0],[0]
"Finally, we describe how each system generates y (Figure 2, Step 3).
",3.3 Generate,[0],[0]
RETRIEVEONLY returns the retrieved sentence xtgt verbatim.,3.3 Generate,[0],[0]
"This is guaranteed to produce a grammatical sentence with the target attribute, but its content might not be similar to x.
TEMPLATEBASED replaces the attribute markers deleted from the source sentence a(x, vsrc) with those of the target sentence a(xtgt,",3.3 Generate,[0],[0]
"vtgt).2 This strategy relies on the assumption that if two attribute markers appear in similar contexts , they are roughly syntactically exchangeable.",3.3 Generate,[0],[0]
"For example, “love” and “don’t like” appear in similar contexts (e.g., “i love this place.”",3.3 Generate,[0],[0]
"and “i don’t like this place.”), and exchanging them is syntactically valid.",3.3 Generate,[0],[0]
"However, this naive swapping of attribute markers can result in ungrammatical outputs.
",3.3 Generate,[0],[0]
"DELETEONLY first embeds the content c(x, vsrc) into a vector using an RNN.",3.3 Generate,[0],[0]
"It then concatenates the final hidden state with a learned embedding for vtgt, and feeds this into an RNN decoder to generate y.",3.3 Generate,[0],[0]
"The decoder attempts to produce words indicative of the source content and target attribute, while remaining fluent.
",3.3 Generate,[0],[0]
"DELETEANDRETRIEVE is similar to DELETEONLY, but uses the attribute markers of the retrieved sentence xtgt rather than the target attribute vtgt.",3.3 Generate,[0],[0]
"Like DELETEONLY, it encodes c(x, vsrc) with an RNN.",3.3 Generate,[0],[0]
"It then encodes the sequence of attribute markers a(xtgt, vtgt) with another RNN.",3.3 Generate,[0],[0]
"The RNN decoder uses the concatenation of this vector and the content embedding to generate y.
DELETEANDRETRIEVE combines the advantages of TEMPLATEBASED and DELETEONLY.",3.3 Generate,[0],[0]
"Unlike TEMPLATEBASED, DELETEANDRETRIEVE can pick a better place to insert the given attribute markers, and can add or remove function words to ensure grammaticality.",3.3 Generate,[0],[0]
"Compared to DELETEONLY, DELETEANDRETRIEVE has a stronger inductive bias towards using target attribute markers that are likely to fit in the current context.",3.3 Generate,[0],[0]
Guu et al. (2018) showed that retrieval strategies like ours can help neural generative models.,3.3 Generate,[0],[0]
"Finally, DELETEANDRETRIEVE gives us finer control over the output; for example, we can control the degree of sentiment by deciding whether to add “good” or “fantastic” based on the retrieved sentence xtgt.
",3.3 Generate,[0],[0]
"2 Markers are replaced from left to right, in order.",3.3 Generate,[0],[0]
"If there are not enough markers in xtgt, we use an empty string.",3.3 Generate,[0],[0]
We now describe how to train DELETEANDRETRIEVE and DELETEONLY.,3.4 Training,[0],[0]
"Recall that at training time, we do not have access to ground truth outputs that express the target attribute.",3.4 Training,[0],[0]
"Instead, we train DELETEONLY to reconstruct the sentences in the training corpus given their content and original attribute value by maximizing:
L(θ) = ∑
(x,vsrc)∈D log p(x | c(x, vsrc), vsrc); θ).
(3) For DELETEANDRETRIEVE, we could similarly learn an auto-encoder that reconstructs x from c(x, vsrc) and a(x, vsrc).",3.4 Training,[0],[0]
"However, this results in a trivial solution: because a(x, vsrc) and c(x, vsrc) were known to come from the same sentence, the model merely learns to stitch the two sequences together without any smoothing.",3.4 Training,[0],[0]
"Such a model would fare poorly at test time, when we may need to alter some words to fluently combine a(xtgt, vtgt) with c(x, vsrc).",3.4 Training,[0],[0]
"To address this train/test mismatch, we adopt a denoising method similar to the denoising auto-encoder (Vincent et al., 2008).",3.4 Training,[0],[0]
"During training, we apply some noise to a(x, vsrc) by randomly altering each attribute marker in it independently with probability 0.1.",3.4 Training,[0],[0]
"Specifically, we replace an attribute marker with another randomly selected attribute marker of the same attribute and word-level edit distance 1 if such a noising marker exists, e.g., “was very rude” to “very rude”, which produces a′(x, vsrc).
",3.4 Training,[0],[0]
"Therefore, the training objective for DELETEANDRETRIEVE is to maximize:
L(θ) = ∑
(x,vsrc)∈D log p(x | c(x, vsrc), a′(x, vsrc); θ).
(4)",3.4 Training,[0],[0]
"We evaluated our approach on three domains: flipping sentiment of Yelp reviews (YELP) and Amazon reviews (AMAZON), and changing image captions to be romantic or humorous (CAPTIONS).",4 Experiments,[0],[0]
We compared our four systems to human references and three previously published adversarial approaches.,4 Experiments,[0],[0]
"As judged by human raters, both of our two baselines outperform all three adversarial methods.",4 Experiments,[0],[0]
"Moreover, DELETEANDRETRIEVE outperforms all other automatic approaches.",4 Experiments,[0],[0]
"First, we describe the three datasets we use, which are commonly used in prior works too.",4.1 Datasets,[0],[0]
"All datasets are randomly split into train, development, and test sets (Table 1).
",4.1 Datasets,[0],[0]
YELP,4.1 Datasets,[0],[0]
"Each example is a sentence from a business review on Yelp, and is labeled as having either positive or negative sentiment.
",4.1 Datasets,[0],[0]
"AMAZON Similar to YELP, each example is a sentence from a product review on Amazon, and is labeled as having either positive or negative sentiment (He and McAuley, 2016).
",4.1 Datasets,[0],[0]
CAPTIONS,4.1 Datasets,[0],[0]
"In the CAPTIONS dataset (Gan et al., 2017), each example is a sentence that describes an image, and is labeled as either factual, romantic, or humorous.",4.1 Datasets,[0],[0]
We focus on the task of converting factual sentences into romantic and humorous ones.,4.1 Datasets,[0],[0]
"Unlike YELP and AMAZON, CAPTIONS is actually an aligned corpus—it contains captions for the same image in different styles.",4.1 Datasets,[0],[0]
"Our systems do not use these alignments, but we use them as gold references for evaluation.
",4.1 Datasets,[0],[0]
"CAPTIONS is also unique in that we reconstruct romantic and humorous sentences during training, whereas at test time we are given factual captions.",4.1 Datasets,[0],[0]
"We assume these factual captions carry only content, and therefore do not look for and delete factual attribute markers; The model essentially only inserts romantic or humorous attribute markers as appropriate.",4.1 Datasets,[0],[0]
"To supply human reference outputs to which we could compare the system outputs for YELP and AMAZON, we hired crowdworkers on Amazon Mechanical Turk to write gold outputs for all test sentences.",4.2 Human References,[0],[0]
"Workers were instructed to edit a sentence to flip its sentiment while preserving its content.
",4.2 Human References,[0],[0]
"Our delete-retrieve-generate approach relies on the prior knowledge that to accomplish attribute
transfer, a small number of attribute markers should be changed, and most other words should be kept the same.",4.2 Human References,[0],[0]
We analyzed our human reference data to understand the extent to which humans follow this pattern.,4.2 Human References,[0],[0]
"We measured whether humans preserved words our system marks as content, and changed words our system marks as attribute-related (Section 3.1).",4.2 Human References,[0],[0]
"We define the content word preservation rate Sc as the average fraction of words our system marks as content that were preserved by humans, and the attributerelated word change rate Sa as the average fraction of words our system marks as attribute-related that were changed by humans:
",4.2 Human References,[0],[0]
"Sc = 1 |Dtest| ∑
(x,vsrc,y∗)∈Dtest
|c(x, vsrc) ∩ y∗| |c(x, vsrc)|
Sa = 1− 1 |Dtest| ∑
(x,vsrc,y∗)∈Dtest
|a(x, vsrc) ∩",4.2 Human References,[0],[0]
"y∗| |a(x, vsrc)| ,
(5) where Dtest is the test set, y∗ is the human reference sentence, and | · | denotes the number of nonstopwords.",4.2 Human References,[0],[0]
"Higher values of Sc and Sa indicate that humans preserve content words and change attribute-related words, in line with the inductive bias of our model.",4.2 Human References,[0],[0]
"Sc is 0.61, 0.71, and 0.50 on YELP, AMAZON, and CAPTIONS, respectively; Sa is 0.72 on YELP and 0.54 on AMAZON (not applicable on CAPTIONS).
",4.2 Human References,[0],[0]
"To understand why humans sometimes deviated from the inductive bias of our model, we randomly sampled 50 cases from YELP where humans changed a content word or preserved an attribute-related word.",4.2 Human References,[0],[0]
"70% of changed content words were unimportant words (e.g., “whole” was deleted from “whole experience”), and another 18% were paraphrases (e.g., “charge” became “price”); the remaining 12% were errors where the system mislabeled an attribute-related word as a content word (e.g., “old” became “new”).",4.2 Human References,[0],[0]
"84% of preserved attribute-related words did pertain to sentiment but remained fixed due to changes in the surrounding context (e.g., “don’t like” became “like”, and “below average” became “above average”); the remaining 16% were mistagged by our system as being attribute-related (e.g., “walked out”).",4.2 Human References,[0],[0]
"We compare with three previous models, all of which use adversarial training.",4.3 Previous Methods,[0],[0]
"STYLEEMBED-
DING (Fu et al., 2018) learns an vector encoding of the source sentence such that a decoder can use it to reconstruct the sentence, but a discriminator, which tries to identify the source attribute using this encoding, fails.",4.3 Previous Methods,[0],[0]
"They use a basic MLP discriminator and an LSTM decoder. MULTIDECODER (Fu et al., 2018) is similar to STYLEEMBEDDING, except that it uses a different decoder for each attribute value.",4.3 Previous Methods,[0],[0]
"CROSSALIGNED (Shen et al., 2017) also encodes the source sentence into a vector, but the discriminator looks at the hidden states of the RNN decoder instead.",4.3 Previous Methods,[0],[0]
The system is trained so that the discriminator cannot distinguish these hidden states from those obtained by forcing the decoder to output real sentences from the target domain; this objective encourages the real and generated target sentences to look similar at a population level.,4.3 Previous Methods,[0],[0]
"For our methods, we use 128-dimensional word vectors and a single-layer GRU with 512 hidden units for both encoders and the decoder.",4.4 Experimental Details,[0],[0]
"We use the maxout activation function (Goodfellow et al., 2013).",4.4 Experimental Details,[0],[0]
All parameters are initialized by sampling from a uniform distribution between−0.1 and 0.1.,4.4 Experimental Details,[0],[0]
"For optimization, we use Adadelta (Zeiler, 2012) with a minibatch size of 256.
",4.4 Experimental Details,[0],[0]
"For attribute marker extraction, we consider spans up to 4 words, and the smoothing parameter λ is set to 1.",4.4 Experimental Details,[0],[0]
"We set the attribute marker threshold γ, which controls the precision and recall of our attribute markers, to 15, 5.5 and 5 for YELP, AMAZON, and CAPTIONS.",4.4 Experimental Details,[0],[0]
These values were set by manual inspection of the resulting markers and tuning slightly on the dev set.,4.4 Experimental Details,[0],[0]
"For retrieval, we used the TF-IDF weighted word overlap score for DELETEANDRETRIEVE and TEMPLATEBASED,
and the Euclidean distance of content embeddings for RETRIEVEONLY.",4.4 Experimental Details,[0],[0]
"We find the two scoring functions give similar results.
",4.4 Experimental Details,[0],[0]
"For all neural models, we do beam search with a beam size of 10.",4.4 Experimental Details,[0],[0]
"For DELETEANDRETRIEVE, similar to Guu et al. (2018), we retrieve the top10 sentences and generate results using markers from each sentence.",4.4 Experimental Details,[0],[0]
We then select the output with the lowest perplexity given by a separately-trained neural language model on the target-domain training data.,4.4 Experimental Details,[0],[0]
We hired workers on Amazon Mechanical Turk to rate the outputs of all systems.,4.5 Human Evaluation,[0],[0]
"For each source sentence and target attribute, the same worker was shown the output of each tested system.",4.5 Human Evaluation,[0],[0]
"Workers were asked to rate each output on three criteria on a Likert scale from 1 to 5: grammaticality, similarity to the target attribute, and preservation of the source content.",4.5 Human Evaluation,[0],[0]
"Finally, we consider a generated output “successful” if it is rated 4 or 5 on all three criteria.",4.5 Human Evaluation,[0],[0]
"For each dataset, we evaluated 400 randomly sampled examples (200 for each target attribute).
",4.5 Human Evaluation,[0],[0]
Table 2 shows the human evaluation results.,4.5 Human Evaluation,[0],[0]
"On all three datasets, both of our baselines have a higher success rate than the previously published models, and DELETEANDRETRIEVE achieves the best performance among all systems.",4.5 Human Evaluation,[0],[0]
"Additionally, we see that human raters strongly preferred the human references to all systems, suggesting there is still significant room for improvement on this task.
",4.5 Human Evaluation,[0],[0]
We find that a human evaluator’s judgment of a sentence is largely relative to other sentences being evaluated together and examples given in the instruction (different for each dataset/task).,4.5 Human Evaluation,[0],[0]
"There-
fore, evaluating all system outputs in one batch is important and results on different datasets are not directly comparable.",4.5 Human Evaluation,[0],[0]
We analyze the strengths and weaknesses of the different systems.,4.6 Analysis,[0],[0]
"Table 3 show typical outputs of each system on the YELP and CAPTIONS dataset.
",4.6 Analysis,[0],[0]
We first analyze the adversarial methods.,4.6 Analysis,[0],[0]
"CROSSALIGNED and MULTIDECODER tend to lose the content of the source sentence, as seen in both the example outputs and the overall human ratings.",4.6 Analysis,[0],[0]
The decoder tends to generate a frequent but only weakly related sentence with the target attribute.,4.6 Analysis,[0],[0]
"On the other hand, STYLEEMBEDDING almost always generates a paraphrase of the input sentence, implying that the encoder preserves some attribute information.",4.6 Analysis,[0],[0]
"We conclude that there is a delicate balance between preserving the original content and dropping the original attribute, and existing adversarial models tend to sacrifice one or the other.
",4.6 Analysis,[0],[0]
"Next, we analyze our baselines.",4.6 Analysis,[0],[0]
"RETRIEVEONLY scores well on grammaticality and having the target attribute, since it retrieves sentences with the desired attribute directly from the corpus.",4.6 Analysis,[0],[0]
"However, it is likely to change the content when there is no perfectly aligned sentence in the target domain.",4.6 Analysis,[0],[0]
"In contrast, TEMPLATEBASED is good at preserving the content because the content words are guaranteed to be kept.",4.6 Analysis,[0],[0]
"However, it makes grammatical mistakes due to the unsmoothed combination of content and attribute words.
DELETEANDRETRIEVE and DELETEONLY achieve a good balance among grammaticality, preserving content, and changing the attribute.",4.6 Analysis,[0],[0]
"Both have strong inductive bias on what words should be changed, but still have the flexibility to smooth out the sentence.",4.6 Analysis,[0],[0]
"The main difference is that DELETEONLY fills in attribute words based on only the target attribute, whereas DELETEANDRETRIEVE conditions on retrieved attribute words.",4.6 Analysis,[0],[0]
When there is a diverse set of phrases to fill in—for example in CAPTIONS— conditioning on retrieved attribute words helps generate longer sentences with more specific attribute descriptions.,4.6 Analysis,[0],[0]
"Following previous work (Hu et al., 2017; Shen et al., 2017), we also compute automatic evalua-
tion metrics, and compare these numbers to our human evaluation results.
",4.7 Automatic Evaluation,[0],[0]
"We use an attribute classifier to assess whether outputs have the desired attribute (Hu et al., 2017; Shen et al., 2017).",4.7 Automatic Evaluation,[0],[0]
We define the classifier score as the fraction of outputs classified as having the target attribute.,4.7 Automatic Evaluation,[0],[0]
"For each dataset, we train an attribute classifier on the same training data.",4.7 Automatic Evaluation,[0],[0]
"Specifically, we encode the sentence into a vector by a bidirectional LSTM with an average pooling layer over the outputs, and train the classifier by minimizing the logistic loss.
",4.7 Automatic Evaluation,[0],[0]
"We also compute BLEU between the output and the human references, similar to Gan et al. (2017).",4.7 Automatic Evaluation,[0],[0]
A high BLEU score primarily indicates that the system can correctly preserve content by retaining the same words from the source sentence as the reference.,4.7 Automatic Evaluation,[0],[0]
"One might also hope that it has some correlation with fluency, though we expect this correlation to be much weaker.
",4.7 Automatic Evaluation,[0],[0]
Table 4 shows the classifier and BLEU scores.,4.7 Automatic Evaluation,[0],[0]
"In Table 5, we compute the system-level correlation between classifier score and human judgments of attribute transfer, and between BLEU and human judgments of content preservation and grammaticality.",4.7 Automatic Evaluation,[0],[0]
We also plot scores given by the automatic metrics and humans in Figure 4.,4.7 Automatic Evaluation,[0],[0]
"While the scores are sometimes well-correlated, the results vary significantly between datasets; on AMAZON, there is no correlation between the classifier score and the human evaluation.",4.7 Automatic Evaluation,[0],[0]
"Manual inspection shows that on AMAZON, some product genres are associated with either mostly positive or mostly negative reviews.",4.7 Automatic Evaluation,[0],[0]
"However, our systems produce, for example, negative reviews about products that are mostly discussed positively in the training set.",4.7 Automatic Evaluation,[0],[0]
"Therefore, the classifier often gives unreliable predictions on system outputs.",4.7 Automatic Evaluation,[0],[0]
"As expected, BLEU does not correlate well with human grammaticality ratings.",4.7 Automatic Evaluation,[0],[0]
"The lack of automatic fluency evaluation artificially favors systems like TEMPLATEBASED, which make more grammatical mistakes.",4.7 Automatic Evaluation,[0],[0]
"We conclude that while these automatic evaluation methods are useful for model development, they cannot replace human evaluation.",4.7 Automatic Evaluation,[0],[0]
One advantage of our methods is that we can control the trade-off between matching the target attribute and preserving the source content.,4.8 Trading off Content versus Attribute,[0],[0]
"To achieve different points along this trade-off curve,
we simply vary the threshold γ (Section 3.1) at test time to control how many attribute markers we delete from the source sentence.",4.8 Trading off Content versus Attribute,[0],[0]
"In contrast, other methods (Shen et al., 2017; Fu et al., 2018) would require retraining the model with different hyperparameters to achieve this effect.
",4.8 Trading off Content versus Attribute,[0],[0]
"Figure 3 shows this trade-off curve for DELETEANDRETRIEVE, DELETEONLY, and TEMPLATEBASED on YELP, where target attribute match is measured by the classifier score and content preservation is measured by BLEU.3",4.8 Trading off Content versus Attribute,[0],[0]
"We see a clear trade-off between changing the attribute and retaining the content.
",4.8 Trading off Content versus Attribute,[0],[0]
"3 RETRIEVEONLY is less affected by what content words are preserved, especially when no good output sentence exists in the target corpus.",4.8 Trading off Content versus Attribute,[0],[0]
"Therefore, we found that it did not exhibit a clear content-attribute trade-off.",4.8 Trading off Content versus Attribute,[0],[0]
"Our work is closely related to the recent body of work on text attribute transfer with unaligned data, where the key challenge to disentangle attribute and content in an unsupervised way.",5 Related Work and Discussion,[0],[0]
"Most existing work (Shen et al., 2017; Zhao et al., 2018; Fu et al., 2018; Melnyk et al., 2017) uses adversarial training to separate attribute and content: the content encoder aims to fool the attribute discriminator by removing attribute information from the content embedding.",5 Related Work and Discussion,[0],[0]
"However, we find that empirically it is often easy to fool the discriminator without actually removing the attribute information.",5 Related Work and Discussion,[0],[0]
"Therefore, we explicitly separate attribute and content by taking advantage of the prior knowledge that the attribute is localized to parts of the sentence.
",5 Related Work and Discussion,[0],[0]
"To address the problem of unaligned data, Hu
et al. (2017) relies on an attribute classifier to guide the generator to produce sentences with a desired attribute (e.g. sentiment, tense) in the Variational Autoencoder (VAE) framework.",5 Related Work and Discussion,[0],[0]
"Similarly, Zhao et al. (2018) used a regularized autoencoder in the adversarial training framework; however, they also find that these models require extensive hyperparameter tuning and the content tends to be changed during the transfer.",5 Related Work and Discussion,[0],[0]
Shen et al. (2017) used a discriminator to align target sentences and sentences transfered to the target domain from the source domain.,5 Related Work and Discussion,[0],[0]
"More recently, unsupervised machine translation models (Artetxe et al., 2017; Lample et al., 2017) used a cycle loss similar to Jun-Yan et al. (2017) to ensure that the content is preserved during the transformation.",5 Related Work and Discussion,[0],[0]
"These methods often rely on bilinguial word vectors to provide word-for-word translations, which are then finetune by back-translation.",5 Related Work and Discussion,[0],[0]
"Thus they can be used to further improve our results.
",5 Related Work and Discussion,[0],[0]
"Our method of detecting attribute markers is reminiscent of Naive Bayes, which is a strong baseline for tasks like sentiment classification (Wang and Manning, 2012).",5 Related Work and Discussion,[0],[0]
"Deleting these at-
tribute markers can be viewed as attacking a Naive Bayes classifier by deleting the most informative features (Globerson and Roweis, 2006), similarly to how adversarial methods are trained to fool an attribute classifier.",5 Related Work and Discussion,[0],[0]
"One difference is that our classifier is fixed, not jointly trained with the model.
",5 Related Work and Discussion,[0],[0]
"To conclude, we have described a simple method for text attribute transfer that outperforms previous models based on adversarial training.",5 Related Work and Discussion,[0],[0]
The main leverage comes from the inductive bias that attributes are usually manifested in localized discriminative phrases.,5 Related Work and Discussion,[0],[0]
"While many prior works on linguistic style analysis confirm our observation that attributes often manifest in idiosyncratic phrases (Recasens et al., 2013; Schwartz et al., 2017; Newman et al., 2003), we recognize the fact that in some problems (e.g., Pavlick and Tetreault (2017)), content and attribute cannot be so cleanly separated along phrase boundaries.",5 Related Work and Discussion,[0],[0]
"Looking forward, a fruitful direction is to develop a notion of attributes more general than n-grams, but with more inductive bias than arbitrary latent vectors.
",5 Related Work and Discussion,[0],[0]
Reproducibility.,5 Related Work and Discussion,[0],[0]
"All code, data, and experiments for this paper are available on the CodaLab platform at https://worksheets.",5 Related Work and Discussion,[0],[0]
"codalab.org/worksheets/ 0xe3eb416773ed4883bb737662b31b4948/.
Acknowledgements.",5 Related Work and Discussion,[0],[0]
This work is supported by the DARPA Communicating with Computers (CwC) program under ARO prime contract no.,5 Related Work and Discussion,[0],[0]
W911NF- 15-1-0462.,5 Related Work and Discussion,[0],[0]
J.L. is supported by Tencent.,5 Related Work and Discussion,[0],[0]
R.J. is supported by an NSF Graduate Research Fellowship under Grant No.,5 Related Work and Discussion,[0],[0]
DGE-114747.,5 Related Work and Discussion,[0],[0]
"We consider the task of text attribute transfer: transforming a sentence to alter a specific attribute (e.g., sentiment) while preserving its attribute-independent content (e.g., changing “screen is just the right size” to “screen is too small”).",abstractText,[0],[0]
"Our training data includes only sentences labeled with their attribute (e.g., positive or negative), but not pairs of sentences that differ only in their attributes, so we must learn to disentangle attributes from attributeindependent content in an unsupervised way.",abstractText,[0],[0]
Previous work using adversarial methods has struggled to produce high-quality outputs.,abstractText,[0],[0]
"In this paper, we propose simpler methods motivated by the observation that text attributes are often marked by distinctive phrases (e.g., “too small”).",abstractText,[0],[0]
"Our strongest method extracts content words by deleting phrases associated with the sentence’s original attribute value, retrieves new phrases associated with the target attribute, and uses a neural model to fluently combine these into a final output.",abstractText,[0],[0]
"On human evaluation, our best method generates grammatical and appropriate responses on 22% more inputs than the best previous system, averaged over three attribute transfer datasets: altering sentiment of reviews on Yelp, altering sentiment of reviews on Amazon, and altering image captions to be more romantic or humorous.",abstractText,[0],[0]
"Delete, Retrieve, Generate: a Simple Approach to Sentiment and Style Transfer",title,[0],[0]
"Streams of data of massive and increasing volume are generated every second, and demand fast analysis and efficient storage, including massive clickstreams, stock market data, image and video streams, sensor data for environmental or health monitoring, to name a few.",1. Introduction,[0],[0]
To make efficient and reliable decisions we usually need to react in real-time to the data.,1. Introduction,[0],[0]
"However, big and fast data makes it difficult to store, analyze, or make predictions.",1. Introduction,[0],[0]
"Therefore, data summarization – mining and extracting useful information from large data sets – has become a central topic in machine learning and information retrieval.
",1. Introduction,[0],[0]
A recent body of research on data summarization relies on utility/scoring functions that are submodular.,1. Introduction,[0],[0]
"Intuitively, submodularity (Krause & Golovin, 2013) states that select-
1ETH Zurich, Switzerland 2Yale University, New Haven, USA.",1. Introduction,[0],[0]
"Correspondence to: Baharan Mirzasoleiman <baharanm@inf.ethz.ch>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
ing any given data point earlier helps more than selecting it later.,1. Introduction,[0],[0]
"Hence, submodular functions can score both diversity and representativeness of a subset w.r.t.",1. Introduction,[0],[0]
the entire dataset.,1. Introduction,[0],[0]
"Thus, many problems in data summarization require maximizing submodular set functions subject to cardinality (or more complicated hereditary constraints).",1. Introduction,[0],[0]
"Numerous examples include exemplar-based clustering (Dueck & Frey, 2007), document (Lin & Bilmes, 2011) and corpus summarization (Sipos et al., 2012), recommender systems (El-Arini & Guestrin, 2011), search result diversification (Rakesh Agrawal, 2009), data subset selection (Wei et al., 2015), and social networks analysis (Kempe et al., 2003).
",1. Introduction,[0],[0]
"Classical methods, such as the celebrated greedy algorithm (Nemhauser et al., 1978) or its accelerated versions (Mirzasoleiman et al., 2015; Badanidiyuru & Vondrák, 2014) require random access to the entire data, make multiple passes, and select elements sequentially in order to produce near optimal solutions.",1. Introduction,[0],[0]
"Naturally, such solutions cannot scale to large instances.",1. Introduction,[0],[0]
"The limitations of centralized methods inspired the design of streaming algorithms that are able to gain insights from data as it is being collected (Badanidiyuru et al., 2014; Chakrabarti & Kale, 2014; Chekuri et al., 2015; Mirzasoleiman et al., 2017).
",1. Introduction,[0],[0]
"While extracting useful information from big data in realtime promises many benefits, the development of more sophisticated methods for extracting, analyzing and using personal information has made privacy a major public issue.",1. Introduction,[0],[0]
Various web services rely on the collection and combination of data about individuals from a wide variety of sources.,1. Introduction,[0],[0]
"At the same time, the ability to control the information an individual can reveal about herself in online applications has become a growing concern.
",1. Introduction,[0],[0]
"The “right to be forgotten” (with a specific mandate for protection in the European Data Protection Regulation (2012), and concrete guidelines released in 2014) allows individuals to claim the ownership of their personal information and gives them the authority to their online activities (videos, photos, tweets, etc).",1. Introduction,[0],[0]
"As an example, consider a road traffic information system that monitors traffic speeds, travel times and incidents in real time.",1. Introduction,[0],[0]
"It combines the massive amount of control messages available at the cellular network with their geo-coordinates in order to gen-
erate the area-wide traffic information service.",1. Introduction,[0],[0]
"Some consumers, while using the service and providing data, may not be willing to share information about specific locations in order to protect their own privacy.",1. Introduction,[0],[0]
"With the right to be forgotten, an individual can have certain data deleted from online database records so that third parties (e.g., search engines) can no longer trace them (Weber, 2011).",1. Introduction,[0],[0]
"Note that the data could be in many forms, including a) user’s posts to an online social media, b) visual data shared by wearable cameras (e.g., Google Glass), c) behavioral patterns or feedback obtained from clicking on advertisement or news.
",1. Introduction,[0],[0]
"In this paper, we propose the first framework that offers instantaneous data summarization while preserving the right of an individual to be forgotten.",1. Introduction,[0],[0]
We cast this problem as an instance of robust streaming submodular maximization where the goal is to produce a concise real-time summary in the face of data deletion requested by users.,1. Introduction,[0],[0]
"We develop ROBUST-STREAMING, a method that for a generic streaming algorithm STREAMINGALG with approximation guarantee α, ROBUST-STREAMING outputs a robust solution, against any m deletions from the summary at any given time, while preserving the same approximation guarantee.",1. Introduction,[0],[0]
"To the best of our knowledge, ROBUST-STREAMING is the first algorithm with such strong theoretical guarantees.",1. Introduction,[0],[0]
Our experimental results also demonstrate the effectiveness of ROBUST-STREAMING on several practical applications.,1. Introduction,[0],[0]
Several streaming algorithms for submodular maximization have been recently developed.,2. Background and Related Work,[0],[0]
"For monotone functions, Gomes & Krause (2010) first developed a multipass algorithm with 1/2− approximation guarantee subject to a cardinality constraint k, using O(k) memory, under strong assumptions on the way the data is generated.",2. Background and Related Work,[0],[0]
"Later, Badanidiyuru et al. (2014) proposed the first single pass streaming algorithm with 1/2 − approximation under a cardinality constraint.",2. Background and Related Work,[0],[0]
"They made no assumptions on the order of receiving data points, and only require O(k log k/ ) memory.",2. Background and Related Work,[0],[0]
"Following the same line of inquiry, Chakrabarti & Kale (2014) developed a single pass algorithm with 1/4p approximation guarantee for handling more general constraints such as intersections of p matroids.",2. Background and Related Work,[0],[0]
The required memory is unbounded and increases polylogarithmically with the size of the data.,2. Background and Related Work,[0],[0]
"For general submodular functions, Chekuri et al. (2015) presented a randomized algorithm subject to a broader range of constraints, namely p-matchoids.",2. Background and Related Work,[0],[0]
Their method gives a (2 − o(1))/(8+e)p approximation usingO(k log k/ 2) memory (k is the size of the largest feasible solution).,2. Background and Related Work,[0],[0]
"Very recently, Mirzasoleiman et al. (2017) introduced a (4p−1)/4p(8p+ 2d − 1)-approximation algorithm under a p-system and d knapsack constraints, using O(pk log2(k)/ 2) memory.
",2. Background and Related Work,[0],[0]
"An important requirement, which frequently arises in practice, is robustness.",2. Background and Related Work,[0],[0]
"Krause et al. (2008) proposed the problem of robust submodular observation selection, where we want to solve max|A|≤k mini∈[`] fi(A), for normalized monotonic fi.",2. Background and Related Work,[0],[0]
Submodular maximization of f robust against m deletions can be cast as an instance of the above problem: max|A|≤k min|B|≤m f(A\B).,2. Background and Related Work,[0],[0]
"The running time, however, will be exponential in m. Recently, Orlin et al. (2016) developed an algorithm with an asymptotic guarantee 0.285 for deletion-robust submodular maximization under up to m =",2. Background and Related Work,[0],[0]
o( √ k) deletions.,2. Background and Related Work,[0],[0]
"The results can be improved for only 1 or 2 deletions.
",2. Background and Related Work,[0],[0]
"The aforementioned approaches aim to construct solutions that are robust against deletions in a batch mode way, without being able to update the solution set after each deletion.",2. Background and Related Work,[0],[0]
"To the best of our knowledge, this is the first to address the general deletion-robust submodular maximization problem in the streaming setting.",2. Background and Related Work,[0],[0]
"We also highlight the fact that our method does not require m, the number of deletions, to be bounded by k, the size of the largest feasible solution.
",2. Background and Related Work,[0],[0]
"Very recently, submodular optimization over sliding windows has been considered, where we want to maintain a solution that considers only the last W items (Epasto et al., 2017; Jiecao et al., 2017).",2. Background and Related Work,[0],[0]
"This is in contrast to our setting, where the guarantee is with respect to all the elements received from the stream, except those that have been deleted.",2. Background and Related Work,[0],[0]
The sliding window model can be easily incorporated into our solution to get a robust sliding window streaming algorithm with the possibility of m deletions in the window.,2. Background and Related Work,[0],[0]
We review the static submodular data summarization problem.,3. Deletion-Robust Model,[0],[0]
"We then formalize a novel dynamic variant, and constraints on time and memory that algorithms need to obey.",3. Deletion-Robust Model,[0],[0]
"In static data summarization, we have a large but fixed dataset V of size n, and we are interested in finding a summary that best represents the data.",3.1. Static Submodular Data Summarization,[0],[0]
The representativeness of a subset is defined based on a utility function f :,3.1. Static Submodular Data Summarization,[0],[0]
2V → R+ where for any A ⊂ V the function f(A) quantifies how well A represents V .,3.1. Static Submodular Data Summarization,[0],[0]
We define the marginal gain of adding an element e ∈ V to a summary A ⊂ V by ∆(e|A) = f(A ∪ {e}),3.1. Static Submodular Data Summarization,[0],[0]
− f(A),3.1. Static Submodular Data Summarization,[0],[0]
.,3.1. Static Submodular Data Summarization,[0],[0]
"In many data summarization applications, the utility function f satisfies submodularity, i.e., for all A ⊆ B ⊆ V and e ∈ V \B,
∆(e|A) ≥ ∆(e|B).
",3.1. Static Submodular Data Summarization,[0],[0]
"Many data summarization applications can be cast as an instance of a constrained submodular maximization:
OPT = max A∈I f(A), (1)
where I ⊂ 2V is a given family of feasible solutions.",3.1. Static Submodular Data Summarization,[0],[0]
"We will denote by A∗ the optimal solution, i.e. A∗ = arg maxA∈I f(A).",3.1. Static Submodular Data Summarization,[0],[0]
"A common type of constraint is a cardinality constraint, i.e., I = {A ⊆ 2V , s.t., |A| ≤ k}.",3.1. Static Submodular Data Summarization,[0],[0]
"Finding A∗ even under cardinality constraint is NP-hard, for many classes of submodular functions (Feige, 1998).",3.1. Static Submodular Data Summarization,[0],[0]
"However, a seminal result by Nemhauser et al. (1978) states that for a non-negative and monotone submodular function a simple greedy algorithm that starts with the empty set S0 = ∅, and at each iteration augments the solution with the element with highest marginal gain, obtains a (1−1/e) approximation to the optimum solution.",3.1. Static Submodular Data Summarization,[0],[0]
"For small, static data, the centralized greedy algorithm or its accelerated variants produce near-optimal solutions.",3.1. Static Submodular Data Summarization,[0],[0]
"However, such methods fail to scale to truly large problems.",3.1. Static Submodular Data Summarization,[0],[0]
"In dynamic deletion-robust submodular maximization problem, the data V is generated at a fast pace and in realtime, such that at any point t in time, a subset Vt ⊆ V of the data has arrived.",3.2. Dynamic Data: Additions and Deletions,[0],[0]
"Naturally, we assume that V1 ⊆ V2 ⊆ · · · ⊆ Vn, with no assumption made on the order or the size of the datastream.",3.2. Dynamic Data: Additions and Deletions,[0],[0]
"Importantly, we allow data to be deleted dynamically as well.",3.2. Dynamic Data: Additions and Deletions,[0],[0]
"We use Dt to refer to data deleted by time t, where again D1 ⊆ D2 ⊆ · · · ⊆ Dn.",3.2. Dynamic Data: Additions and Deletions,[0],[0]
"Without loss of generality, below we assume that at every time step t exactly one element et ∈ V is either added or deleted, i.e., |Dt \",3.2. Dynamic Data: Additions and Deletions,[0],[0]
Dt−1|,3.2. Dynamic Data: Additions and Deletions,[0],[0]
+,3.2. Dynamic Data: Additions and Deletions,[0],[0]
|Vt \ Vt−1| = 1.,3.2. Dynamic Data: Additions and Deletions,[0],[0]
"We now seek to solve a dynamic variant of Problem (1) OPTt = max
At∈It f(At) s.t.",3.2. Dynamic Data: Additions and Deletions,[0],[0]
"It = {A : A ∈ I∧A ⊆ Vt \Dt}.
(2) Note that in general a feasible solution at time t might not be a feasible solution at a later time t′.",3.2. Dynamic Data: Additions and Deletions,[0],[0]
This is particularly important in practical situations where a subset of the elements Dt should be removed from the solution.,3.2. Dynamic Data: Additions and Deletions,[0],[0]
"We do not make any assumptions on the order or the size of the data stream V , but we assume that the total number of deletions is limited to m , i.e., |Dn| ≤ m.",3.2. Dynamic Data: Additions and Deletions,[0],[0]
"In principle, we could solve Problem (2) by repeatedly – at every time t – solving a static Problem (1) by restricting the ground set V to Vt \Dt.",3.3. Dealing with Limited Time and Memory,[0],[0]
This is impractical even for moderate problem sizes.,3.3. Dealing with Limited Time and Memory,[0],[0]
"For large problems, we may not even be able to fit Vt into the main memory of the computing device (space constraints).",3.3. Dealing with Limited Time and Memory,[0],[0]
"Moreover, in real-time applications, one needs to make decisions in a timely manner while the data is continuously arriving (time constraints).
",3.3. Dealing with Limited Time and Memory,[0],[0]
We hence focus on streaming algorithms which may maintain a limited memory Mt ⊂,3.3. Dealing with Limited Time and Memory,[0],[0]
"Vt \ Dt, and must have an updated feasible solution {At |At ⊆Mt, At ∈",3.3. Dealing with Limited Time and Memory,[0],[0]
"It} to output at any given time t. Ideally, the capacity of the memory
|Mt| should not depend on t and Vt.",3.3. Dealing with Limited Time and Memory,[0],[0]
"Whenever a new element is received, the algorithm can choose 1) to insert it into its memory, provided that the memory does not exceed a pre-specified capacity bound, 2) to replace it with one or a subset of elements in the memory (in the preemptive model), or otherwise 3) the element gets discarded and cannot be used later by the algorithm.",3.3. Dealing with Limited Time and Memory,[0],[0]
If the algorithm receives a deletion request for a subset Dt ⊂ Vt at time t (in which case It will be updated to accommodate this request) it has to drop Dt from Mt in addition to updating At to make sure that the current solution is feasible (all subsetsA′t ⊂,3.3. Dealing with Limited Time and Memory,[0],[0]
"Vt that contain an element fromDt are infeasible, i.e., A′t /∈",3.3. Dealing with Limited Time and Memory,[0],[0]
It).,3.3. Dealing with Limited Time and Memory,[0],[0]
"To account for such losses, the streaming algorithm can only use other elements maintained in its memory in order to produce a feasible candidate solution, i.e. At ⊆ Mt ⊆ ((Vt \ Vt−1) ∪Mt−1) \Dt.",3.3. Dealing with Limited Time and Memory,[0],[0]
"We say that the streaming algorithm is robust against m deletions, if it can provide a feasible solution At ∈",3.3. Dealing with Limited Time and Memory,[0],[0]
It at any given time t such that f(At) ≥ τOPTt for some constant τ > 0.,3.3. Dealing with Limited Time and Memory,[0],[0]
"Later, we show how robust streaming algorithms can be obtained by carefully increasing the memory and running multiple instances of existing streaming methods simultaneously.",3.3. Dealing with Limited Time and Memory,[0],[0]
"We now discuss three concrete applications, with their submodular objective functions f , where the size of the datasets and the nature of the problem often require a deletion-robust streaming solution.",4. Example Applications,[0],[0]
There exists a tremendous opportunity of harnessing prevalent activity logs and sensing resources.,4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
"For instance, GPS traces of mobile phones can be used by road traffic information systems (such as Google traffic, TrafficSense, Navigon) to monitor travel times and incidents in real time.",4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
"In another example, stream of user activity logs is recorded while users click on various parts of a webpage such as ads and news while browsing the web, or using social media.",4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
Continuously sharing all collected data is problematic for several reasons.,4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
"First, memory and communication constraints may limit the amount of data that can be stored and transmitted across the network.",4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
"Second, reasonable privacy concerns may prohibit continuous tracking of users.
",4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
"In many such applications, the data can be described in terms of a kernel matrix K which encodes the similarity between different data elements.",4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
The goal is to select a small subset (active set) of elements while maintaining a certain diversity.,4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
"Very often, the utility function boils down to the following monotone submodular function (Krause & Golovin, 2013) where α > 0",4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
"andKS,S is the principal submatrix of K indexed by the set S.
f(S) = log det(I + αKS,S) (3)
",4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
"In light of privacy concerns, it is natural to consider participatory models that empower users to decide what portion of their data could be made available.",4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
"If a user decides not to share, or to revoke information about parts of their activity, the monitoring system should be able to update the summary to comply with users’ preferences.",4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
"Therefore, we use ROBUST-STREAMING to identify a robust set of the k most informative data points by maximizing Eq.",4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
(3).,4.1. Summarizing Click-stream and Geolocation Data,[0],[0]
"Given a collection of images, one might be interested in finding a subset that best summarizes and represents the collection.",4.2. Summarizing Image Collections,[0],[0]
This problem has recently been addressed via submodular maximization.,4.2. Summarizing Image Collections,[0],[0]
"More concretely, Tschiatschek et al. (2014) designed several submodular objectives f1, . . .",4.2. Summarizing Image Collections,[0],[0]
", fl, which quantify different characteristics that good summaries should have, e.g., being representative w.r.t.",4.2. Summarizing Image Collections,[0],[0]
commonly reoccurring motives.,4.2. Summarizing Image Collections,[0],[0]
"Each function either captures coverage (including facility location, sumcoverage, and truncated graph cut, or rewards diversity (such as clustered facility location, and clustered diversity).",4.2. Summarizing Image Collections,[0],[0]
"Then, they optimize a weighted combination of such functions
fw(A) = l∑ i=1",4.2. Summarizing Image Collections,[0],[0]
"wifi(A), (4)
where weights are non-negative, i.e., wi ≥ 0, and learned via a large-margin structured prediction.",4.2. Summarizing Image Collections,[0],[0]
We use their learned mixtures of submodular functions in our image summarization experiments.,4.2. Summarizing Image Collections,[0],[0]
"Now, consider a situation where a user wants to summarize a large collection of her photos.",4.2. Summarizing Image Collections,[0],[0]
"If she decides to delete some of the selected photos in the summary, she should be able to update the result without processing the whole collection from scratch.",4.2. Summarizing Image Collections,[0],[0]
ROBUST-STREAMING can be used as an appealing method.,4.2. Summarizing Image Collections,[0],[0]
"In this section, we first elaborate on why naively increasing the solution size does not help.",5. Robust-Streaming Algorithm,[0],[0]
"Then, we present our main algorithm, ROBUST-STREAMING, for deletion-robust streaming submodular maximization.",5. Robust-Streaming Algorithm,[0],[0]
"Our approach builds on the following key ideas: 1) simultaneously constructing non-overlapping solutions, and 2) appropriately merging solutions upon deleting an element from the memory.",5. Robust-Streaming Algorithm,[0],[0]
One of the main challenges in designing streaming solutions is to immediately discover whether an element received from the data stream at time t is good enough to be added to the memory Mt.,5.1. Increasing the Solution Size Does Not Help,[0],[0]
"This decision is usually made based on the added value or marginal gain of the new element which in turn depends on the previously chosen elements in the memory, i.e., Mt−1.",5.1. Increasing the Solution Size Does Not Help,[0],[0]
"Now, let us consider
the opposite scenario when an element e should be deleted from the memory at time t. Since now we have a smaller context, submodularity guarantees that the marginal gains of the elements added to the memory after e was added, could have only increased if e was not part of the stream (diminishing returns).",5.1. Increasing the Solution Size Does Not Help,[0],[0]
"Hence, if some elements had large marginal values to be included in the memory before the deletion, they still do after the deletion.",5.1. Increasing the Solution Size Does Not Help,[0],[0]
"Based on this intuition, a natural idea is to keep a solution of a bigger size, saym+k (rather than k) for at mostm deletions.",5.1. Increasing the Solution Size Does Not Help,[0],[0]
"However, this idea does not work as shown by the following example.
",5.1. Increasing the Solution Size Does Not Help,[0],[0]
"Bad Example (Coverage): Consider a collection of n subsets V = {B1, . . .",5.1. Increasing the Solution Size Does Not Help,[0],[0]
", Bn}, where Bi ⊆ {1, . . .",5.1. Increasing the Solution Size Does Not Help,[0],[0]
",",5.1. Increasing the Solution Size Does Not Help,[0],[0]
"n}, and",5.1. Increasing the Solution Size Does Not Help,[0],[0]
a coverage function f(A),5.1. Increasing the Solution Size Does Not Help,[0],[0]
"= |∪i∈ABi|,A ⊆ V .",5.1. Increasing the Solution Size Does Not Help,[0],[0]
"Suppose we receive B1 = {1, . . .",5.1. Increasing the Solution Size Does Not Help,[0],[0]
", n}, and then Bi = {i} for 2≤ i ≤ n from the stream.",5.1. Increasing the Solution Size Does Not Help,[0],[0]
"Streaming algorithms that select elements according to their marginal gain and are allowed to pick k + m elements, will only pick up B1 upon encounter (as other elements provide no gain), and returnAn = {B1} after processing the stream.",5.1. Increasing the Solution Size Does Not Help,[0],[0]
"Hence, if B1 is deleted after the stream is received, these algorithms return the empty set An = ∅ (with f(An) = 0).",5.1. Increasing the Solution Size Does Not Help,[0],[0]
"An optimal algorithm which knows that elementB1 will be deleted, however, will return set An = {B2, . . .",5.1. Increasing the Solution Size Does Not Help,[0],[0]
", Bk+2}, with value f(An) =",5.1. Increasing the Solution Size Does Not Help,[0],[0]
k + 1.,5.1. Increasing the Solution Size Does Not Help,[0],[0]
"Hence, standard streaming algorithms fail arbitrarily badly even under a single deletion (i.e., m = 1), even when we allow them to pick sets larger than k.
In the following we show how we can solve the above issue by carefully constructing not one but multiple solutions.",5.1. Increasing the Solution Size Does Not Help,[0],[0]
"As stated earlier, the existing one-pass streaming algorithms for submodular maximization work by identifying elements with marginal gains above a carefully chosen threshold.",5.2. Building Multiple Solutions,[0],[0]
This ensures that any element received from the stream which is fairly similar to the elements of the solution set is discarded by the algorithm.,5.2. Building Multiple Solutions,[0],[0]
"Since elements are chosen as diverse as possible, the solution may suffer dramatically in case of a deletion.
",5.2. Building Multiple Solutions,[0],[0]
"One simple idea is to try to findm (near) duplicates for each element e in the memory, i.e., find e′ such that f(e′) = f(e) and ∆(e′|e) = 0",5.2. Building Multiple Solutions,[0],[0]
"(Orlin et al., 2016).",5.2. Building Multiple Solutions,[0],[0]
This way if we facem deletions we can still find a good solution.,5.2. Building Multiple Solutions,[0],[0]
"The drawback is that even one duplicate may not exist in the data stream (see the bad example above), and we may not be able to recover for the deleted element.",5.2. Building Multiple Solutions,[0],[0]
"Instead, what we will do is to construct non-overlapping solutions such that once we experience a deletion, only one solution gets affected.
",5.2. Building Multiple Solutions,[0],[0]
"In order to be robust against m deletions, we run a cascading chain of r instances of STREAMINGALGs as follows.",5.2. Building Multiple Solutions,[0],[0]
"Let Mt = M (1)t ,M (2) t , . . .",5.2. Building Multiple Solutions,[0],[0]
",M (r) t denote the con-
tent of their memories at time t. When we receive a new element e ∈ Vt from the data stream at time t, we pass it to the first instance of STREAMINGALG(1).",5.2. Building Multiple Solutions,[0],[0]
"If STREAMINGALG(1) discards e, the discarded element is cascaded in the chain and is passed to its successive algorithm, i.e. STREAMINGALG(2).",5.2. Building Multiple Solutions,[0],[0]
"If e is discarded by STREAMINGALG(2), the cascade continues and e is passed to STREAMINGALG(3).",5.2. Building Multiple Solutions,[0],[0]
This process continues until either e is accepted by one of the instances or discarded for good.,5.2. Building Multiple Solutions,[0],[0]
"Now, let us consider the case where e is accepted by the i-th instance, SIEVE-STREAMING(i), in the chain.",5.2. Building Multiple Solutions,[0],[0]
"As discussed in Section 3.3, STREAMINGALG may choose to discard a set of points R(i)t ⊂ M (i) t from its memory before inserting e, i.e., M (i)t ←M (i) t ∪ {e} \R (i) t .",5.2. Building Multiple Solutions,[0],[0]
"Note that R (i) t is empty, if e is inserted and no element is discarded from M
(i) t .",5.2. Building Multiple Solutions,[0],[0]
"For every discarded element r ∈ R (i) t , we start a new
cascade from (i+ 1)-th instance, STREAMINGALG (i+1).
",5.2. Building Multiple Solutions,[0],[0]
"Note that in the worst case, every element of the stream can go once through the whole chain during the execution of the algorithm, and thus the processing time for each element scales linearly by r. An important observation is that at any given time t, all the memories M (1)t ,M (2) t , · · · ,M (r) t contain disjoint sets of elements.",5.2. Building Multiple Solutions,[0],[0]
"Next, we show how this data structure leads to a deletion-robust streaming algorithm.",5.2. Building Multiple Solutions,[0],[0]
"Equipped with the above data structure shown in Fig. 1, we now demonstrate how deletions can be treated.",5.3. Dealing with Deletions,[0],[0]
"Assume an element ed is being deleted from the memory of the j-th instance of STREAMINGALG(j) at time t, i.e., M
(j) t ← M (j) t \ {ed}.",5.3. Dealing with Deletions,[0],[0]
"As discussed in Section 5.1, the solution of the streaming algorithm can suffer dramatically from a deletion, and we may not be able to restore the quality of the solution by substituting similar elements.",5.3. Dealing with Deletions,[0],[0]
"Since there is no guarantee for the quality of the solution after a deletion, we remove STREAMINGALG (j) from the chain by makingR(j)t =null and for all the remaining elements in
its memory M (j)t , namely, R (j) t ←M (j) t \ {ed}, we start a new cascade from j+1-th instance, STREAMINGALG(j+1).
",5.3. Dealing with Deletions,[0],[0]
The key reason why the above algorithm works is that the guarantee provided by the streaming algorithm is independent of the order of receiving the data elements.,5.3. Dealing with Deletions,[0],[0]
"Note that at any point in time, the first instance i of the algorithm with M (i)t 6= null has processed all the elements from the stream Vt (not necessarily in the order the stream is originally received) except the ones deleted by time t, i.e., Dt.",5.3. Dealing with Deletions,[0],[0]
"Therefore, we can guarantee that STREAMINGALG (i) provides us with its inherent α-approximation guarantee for reading Vt \Dt.",5.3. Dealing with Deletions,[0],[0]
"More precisely, f(S(i)t ) ≥ αOPTt, where OPTt is the optimum solution for the constrained optimization problem (2) when we have m deletions.
",5.3. Dealing with Deletions,[0],[0]
"In case of adversary deletions, there will be one deletion from the solution of m instances of STREAMINGALG in the chain.",5.3. Dealing with Deletions,[0],[0]
"Therefore, having r = m+ 1 instances, we will remain with only one STREAMINGALG that gives us the desired result.",5.3. Dealing with Deletions,[0],[0]
"However, as shown later in this section, if the deletions are i.i.d.",5.3. Dealing with Deletions,[0],[0]
"(which is often the case in practice), and we have m deletions in expectation, we need r to be much smaller than m+1.",5.3. Dealing with Deletions,[0],[0]
"Finally, note that we do not need to assume that m ≤ k where k is the size of the largest feasible solution.",5.3. Dealing with Deletions,[0],[0]
"The above idea works for arbitrarym≤n.
",5.3. Dealing with Deletions,[0],[0]
The pseudocode of ROBUST-STREAMING is given in Algorithm 1.,5.3. Dealing with Deletions,[0],[0]
It uses r ≤,5.3. Dealing with Deletions,[0],[0]
m+ 1 instances of STREAMINGALG as subroutines in order to produce r solutions.,5.3. Dealing with Deletions,[0],[0]
"We denote by S(1)t , S (1) t , . . .",5.3. Dealing with Deletions,[0],[0]
", S (r) t the solutions of the r STREAMINGALGs at any given time t.",5.3. Dealing with Deletions,[0],[0]
We assume that an instance i of STREAMINGALG(i) receive an input element and produces a solution S(i)t based on the input.,5.3. Dealing with Deletions,[0],[0]
"It may also change its memory content M (i)t , and discard a set R(i)t .",5.3. Dealing with Deletions,[0],[0]
"Among all the remained solutions (i.e., the ones that are not ”null”), it returns the first solution in the chain, i.e. the one with the lowest index.
",5.3. Dealing with Deletions,[0],[0]
"Theorem 1 Let STREAMINGALG be a 1-pass streaming algorithm that achieves an α-approximation guarantee for the constrained maximization problem (2) with an update time of T , and a memory of size M when there is no deletion.",5.3. Dealing with Deletions,[0],[0]
Then ROBUST-STREAMING uses r ≤ m + 1 instances of STREAMINGALGs to produce a feasible solution St ∈,5.3. Dealing with Deletions,[0],[0]
It (now It encodes deletions in addition to constraints) such that f(St) = αOPTt as long as no more than m elements are deleted from the data stream.,5.3. Dealing with Deletions,[0],[0]
"Moreover, ROBUST-STREAMING uses a memory of size rM , and has worst case update time of O(r2MT ), and average update time of O(rT ).
",5.3. Dealing with Deletions,[0],[0]
The proofs can be found in the appendix.,5.3. Dealing with Deletions,[0],[0]
"In Table 1 we combine the result of Theorem 1 with the existing streaming algorithms that satisfy our requirements.
",5.3. Dealing with Deletions,[0],[0]
Algorithm 1 ROBUST-STREAMING Input: data stream,5.3. Dealing with Deletions,[0],[0]
"Vt, deletion set",5.3. Dealing with Deletions,[0],[0]
"Dt, r ≤ m+1.",5.3. Dealing with Deletions,[0],[0]
"Output: solution St at any time t.
1: t = 1, M (i)t = 0, S (i) t = ∅",5.3. Dealing with Deletions,[0],[0]
∀i ∈,5.3. Dealing with Deletions,[0],[0]
[1 · · · r] 2: while ({Vt \ Vt−1} ∪ {Dt \Dt−1} 6= ∅) do 3: if {Dt \Dt−1} 6= ∅,5.3. Dealing with Deletions,[0],[0]
"then 4: ed ← {Dt \Dt−1} 5: Delete(ed) 6: else 7: et ← {Vt \ Vt−1} 8: Add(1, et) 9: end if
10: t = t+ 1 11: St = { S (i) t",5.3. Dealing with Deletions,[0],[0]
| i = min{j ∈,5.3. Dealing with Deletions,[0],[0]
"[1 · · · r], M (j) t 6= null} } 12: end while
13: function Add(i, R) 14: for e ∈ R do 15:",5.3. Dealing with Deletions,[0],[0]
"[R(i)t ,M (i) t , S (i) t ] =STREAMINGALG (i)(e) 16: if R(i)t 6= ∅",5.3. Dealing with Deletions,[0],[0]
"and i < r then 17: Add(i+ 1, R(i)t ) 18: end if 19: end for 20: end function
21: function Delete(e) 22: for i = 1 to r do 23: if e ∈M (i)t then 24: R(i)t = M (i) t",5.3. Dealing with Deletions,[0],[0]
\,5.3. Dealing with Deletions,[0],[0]
"{e} 25: M (i)t ← null 26: Add(i+ 1, R(i)t ) 27: return 28: end if 29: end for 30: end function
Theorem 2",5.3. Dealing with Deletions,[0],[0]
Assume each element of the stream is deleted with equal probability p,5.3. Dealing with Deletions,[0],[0]
"= m/n, i.e., in expectation we have m deletions from the stream.",5.3. Dealing with Deletions,[0],[0]
"Then, with probability 1− δ, ROBUST-STREAMING provides an α-approximation as long as
r ≥",5.3. Dealing with Deletions,[0],[0]
"( 1
1− p
)k log ( 1/δ ) .
",5.3. Dealing with Deletions,[0],[0]
"Theorem 2 shows that for fixed k, δ and p, a constant number r of STREAMINGALGs is sufficient to support m = pn (expected) deletions independently of n.",5.3. Dealing with Deletions,[0],[0]
"In contrast, for adversarial deletions, as analyzed in Theorem 1, pn + 1 copies of STREAMINGALG are required, which grows linearly in n. Hence, the required dependence of r on m is much milder for random than adversarial deletions.",5.3. Dealing with Deletions,[0],[0]
This is also verified by our experiments in Section 6.,5.3. Dealing with Deletions,[0],[0]
We address the following questions: 1) How much can ROBUST-STREAMING recover and possibly improve the performance of STREAMINGALG in case of deletions?,6. Experiments,[0],[0]
2) How much does the time of deletions affect the performance?,6. Experiments,[0],[0]
3) To what extent does deleting representative vs. random data points affect the performance?,6. Experiments,[0],[0]
"To this end, we run ROBUST-STREAMING on the applications we described in Section 4, namely, image collection summarization, summarizing stream of geolocation sensor data, as well as summarizing a clickstream of size 45 million.
",6. Experiments,[0],[0]
"Throughout this section we consider the following streaming algorithms: SIEVE-STREAMING (Badanidiyuru et al., 2014), STREAM-GREEDY (Gomes & Krause, 2010), and STREAMING-GREEDY (Chekuri et al., 2015).",6. Experiments,[0],[0]
"We allow all streaming algorithms, including the non-preemptive SIEVE-STREAMING, to update their solution after each deletion.",6. Experiments,[0],[0]
"We also consider a stronger variant of SIEVESTREAMING, called EXTSIEVE, that aims to pick k ·r elements to protect for deletions, i.e., is allowed the same memory as ROBUST-STREAMING.",6. Experiments,[0],[0]
"After the deletions, the remaining solution is pruned to k elements.
",6. Experiments,[0],[0]
"To compare the effect of deleting representative elements to the that of deleting random elements from the stream, we use two stochastic variants of the greedy algorithm, namely, STOCHASTIC-GREEDY (Mirzasoleiman et al., 2015) and RANDOM-GREEDY (Buchbinder et al., 2014).",6. Experiments,[0],[0]
This way we introduce randomness into the deletion process in a principled way.,6. Experiments,[0],[0]
"Hence, we have:
STOCHASTIC-GREEDY (SG): Similar to the the greedy algorithm, STOCHASTIC-GREEDY starts with an empty set and adds one element at each iteration until obtains a solution of sizem.",6. Experiments,[0],[0]
"But in each step it first samples a random set R of size (n/m) log(1/ ) and then adds an element from R to the solution which maximizes the marginal gain.
",6. Experiments,[0],[0]
"RANDOM-GREEDY (RG): RANDOM-GREEDY iteratively selects a random element from the top m elements with the highest marginal gains, until finds a solution of size m.
For each deletion method, the m data points are deleted either while receiving the data (where the steaming algorithms have the chance to update their solutions by selecting new elements) or after receiving the data (where there is no chance of updating the solution with new elements).",6. Experiments,[0],[0]
"Finally, the performance of all algorithms are normalized against the utility obtained by the centralized algorithm that knows the set of deleted elements in advance.",6. Experiments,[0],[0]
We first apply ROBUST-STREAMING to a collection of 100 images from Tschiatschek et al. (2014).,6.1. Image Collection Summarization,[0],[0]
"We used
the weighted combination of 594 submodular functions either capturing coverage or rewarding diversity (c.f. Section 4.2).",6.1. Image Collection Summarization,[0],[0]
"Here, despite the small size of the dataset, computing the weighted combination of 594 functions makes the function evaluation considerably expensive.
",6.1. Image Collection Summarization,[0],[0]
Fig.,6.1. Image Collection Summarization,[0],[0]
2a compares the performance of SIEVE-STREAMING with its robust version ROBUST-STREAMING for r = 3 and solution size k=5.,6.1. Image Collection Summarization,[0],[0]
"Here, we vary the numberm of deletions from 1 to 20 after the whole stream is received.",6.1. Image Collection Summarization,[0],[0]
We see that ROBUST-STREAMING maintains its performance by updating the solution after deleting subsets of data points imposed by different deletion strategies.,6.1. Image Collection Summarization,[0],[0]
"It can be seen that, even for a larger number m of deletions, ROBUSTSTREAMING, run with parameter r < m, is able to return a solution competitive with the strong centralized benchmark that knows the deleted elements beforehand.",6.1. Image Collection Summarization,[0],[0]
"For the image collection, we were not able to compare the performance of STREAM-GREEDY with its robust version due to the prohibitive running time.",6.1. Image Collection Summarization,[0],[0]
Fig. 2b shows an example of an updated image summary returned by ROBUST-STREAMING after deleting the first image from the summary.,6.1. Image Collection Summarization,[0],[0]
Next we apply ROBUST-STREAMING to the active set selection objective described in Section 4.1.,6.2. Summarizing a stream of geolocation data,[0],[0]
"Our dataset con-
sists of 3,607 geolocations, collected during a one hour bike ride around Zurich (Fatio, 2015).",6.2. Summarizing a stream of geolocation data,[0],[0]
"For each pair of points i and j we used the corresponding (latitude, longitude) coordinates to calculate their distance in meters di,j and chose a Gaussian kernel Ki,j = exp(−d2i,j/h2) with h=1500.",6.2. Summarizing a stream of geolocation data,[0],[0]
Fig.,6.2. Summarizing a stream of geolocation data,[0],[0]
"3e shows the dataset where red and green triangles show a summary of size 10 found by SIEVESTREAMING, and the updated summary provided by ROBUST-STREAMING with r = 5 after deleting m= 70% of the datapoints.",6.2. Summarizing a stream of geolocation data,[0],[0]
Fig.,6.2. Summarizing a stream of geolocation data,[0],[0]
"3a and 3c compare the performance of SIEVE-STREAMING with its robust version when the data is deleted after or during the stream, respectively.",6.2. Summarizing a stream of geolocation data,[0],[0]
"As we see, ROBUST-STREAMING provides a solution very close to the hindsight centralized method.",6.2. Summarizing a stream of geolocation data,[0],[0]
Fig.,6.2. Summarizing a stream of geolocation data,[0],[0]
3b and 3d show similar behavior for STREAM-GREEDY.,6.2. Summarizing a stream of geolocation data,[0],[0]
Note that deleting data points via STOCHASTIC-GREEDY or RANDOM-GREEDY are much more harmful on the quality of the solution provided by STREAM-GREEDY.,6.2. Summarizing a stream of geolocation data,[0],[0]
We repeated the same experiment by dividing the map into grids of length 2km.,6.2. Summarizing a stream of geolocation data,[0],[0]
We then considered a partition matroid by restricting the number of points selected from each grid to be 1.,6.2. Summarizing a stream of geolocation data,[0],[0]
The red and green triangles in Fig.,6.2. Summarizing a stream of geolocation data,[0],[0]
3f are the summary found by STREAMING-GREEDY and the updated summary provided by ROBUST-STREAMING after deleting the shaded area in the figure.,6.2. Summarizing a stream of geolocation data,[0],[0]
"For our large-scale experiment we consider again the active set selection objective, described in Section 4.1.",6.3. Large scale click through prediction,[0],[0]
We used Yahoo!,6.3. Large scale click through prediction,[0],[0]
"Webscope data set containing 45,811,883 user click logs for news articles displayed in the Featured Tab of the Today Module on Yahoo!",6.3. Large scale click through prediction,[0],[0]
"Front Page during the first ten days in May 2009 (Yahoo, 2012).",6.3. Large scale click through prediction,[0],[0]
"For each visit, both the user and shown articles are associated with a feature vector of dimension 6.",6.3. Large scale click through prediction,[0],[0]
"We take their outer product, resulting in a feature vector of size 36.
",6.3. Large scale click through prediction,[0],[0]
The goal was to predict the user behavior for each displayed article based on historical clicks.,6.3. Large scale click through prediction,[0],[0]
"To do so, we considered the first 80% of the data (for the fist 8 days) as our training set, and the last 20% (for the last 2 days) as our test set.",6.3. Large scale click through prediction,[0],[0]
"We used Vowpal-Wabbit (Langford et al., 2007) to train a linear classifier on the full training set.",6.3. Large scale click through prediction,[0],[0]
"Since only 4% of the data points are clicked, we assign a weight of 10 to each
clicked vector.",6.3. Large scale click through prediction,[0],[0]
The AUC score of the trained classifier on the test set was 65%.,6.3. Large scale click through prediction,[0],[0]
We then used ROBUST-STREAMING and SIEVE-STREAMING to find a representative subset of size k consisting of k/2 clicked and k/2 not-clicked examples from the training data.,6.3. Large scale click through prediction,[0],[0]
"Due to the massive size of the dataset, we used Spark on a cluster of 15 quad-core machines with 32GB of memory each.",6.3. Large scale click through prediction,[0],[0]
We partitioned the training data to the machines keeping its original order.,6.3. Large scale click through prediction,[0],[0]
"We
ran ROBUST-STREAMING on each machine to find a summary of size k/15, and merged the results to obtain the final summary of size",6.3. Large scale click through prediction,[0],[0]
"k. We then start deleting the data uniformly at random until we left with only 1% of the data, and trained another classifier on the remaining elements from the summary.
",6.3. Large scale click through prediction,[0],[0]
"Fig. 4a compares the performance of ROBUSTSTREAMING for a fixed active set of size k = 10, 000, and r = 2 with random selection, randomly selecting equal numbers of clicked and not-clicked vectors, and using SIEVE-STREAMING for selecting equal numbers of clicked and not-clicked data points.",6.3. Large scale click through prediction,[0],[0]
"The y-axis shows the improvement in AUC score of the classifier trained on a summary obtained by different algorithms over random guessing (AUC=0.5), normalized by the AUC score of the classifier trained on the whole training data.",6.3. Large scale click through prediction,[0],[0]
"To maximize fairness, we let other baselines select a subset of r.k elements before deletions.",6.3. Large scale click through prediction,[0],[0]
Fig.,6.3. Large scale click through prediction,[0],[0]
4b shows the same quantity for r = 5.,6.3. Large scale click through prediction,[0],[0]
It can be seen that a slight increase in the amount of memory helps boosting the performance for all the algorithms.,6.3. Large scale click through prediction,[0],[0]
"However, ROBUST-STREAMING benefits from the additional memory the most, and can almost recover the performance of the classifier trained on the full training data, even after 99% deletion.",6.3. Large scale click through prediction,[0],[0]
We have developed the first deletion-robust streaming algorithm – ROBUST-STREAMING – for constrained submodular maximization.,7. Conclusion,[0],[0]
"Given any single-pass streaming algorithm STREAMINGALG with α-approximation guarantee, ROBUST-STREAMING outputs a solution that is robust against m deletions.",7. Conclusion,[0],[0]
The returned solution also satisfies an α-approximation guarantee w.r.t.,7. Conclusion,[0],[0]
to the solution of the optimum centralized algorithm that knows the set of m deletions in advance.,7. Conclusion,[0],[0]
We have demonstrated the effectiveness of our approach through an extensive set of experiments.,7. Conclusion,[0],[0]
"This research was supported by ERC StG 307036, a Microsoft Faculty Fellowship, DARPA Young Faculty Award (D16AP00046), Simons-Berkeley fellowship and an ETH Fellowship.",Acknowledgements,[0],[0]
"This work was done in part while Amin Karbasi, and Andreas Krause were visiting the Simons Institute for the Theory of Computing.",Acknowledgements,[0],[0]
How can we summarize a dynamic data stream when elements selected for the summary can be deleted at any time?,abstractText,[0],[0]
"This is an important challenge in online services, where the users generating the data may decide to exercise their right to restrict the service provider from using (part of) their data due to privacy concerns.",abstractText,[0],[0]
"Motivated by this challenge, we introduce the dynamic deletion-robust submodular maximization problem.",abstractText,[0],[0]
"We develop the first resilient streaming algorithm, called ROBUST-STREAMING, with a constant factor approximation guarantee to the optimum solution.",abstractText,[0],[0]
"We evaluate the effectiveness of our approach on several real-world applications, including summarizing (1) streams of geocoordinates (2); streams of images; and (3) clickstream log data, consisting of 45 million feature vectors from a news recommendation task.",abstractText,[0],[0]
Deletion-Robust Submodular Maximization: Data Summarization with ``the Right to be Forgotten'',title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 200–207 New Orleans, Louisiana, June 1 - 6, 2018. c©2017 Association for Computational Linguistics",text,[0],[0]
Knowledge Bases (KBs) are widely used for representing information in a structured format.,1 Introduction,[0],[0]
"Such KBs, including Wikidata (Vrandečić and Krötzsch, 2014), Google Knowledge Vault (Dong et al., 2014), and YAGO (Suchanek et al., 2007), often store information as facts in the form of triples, consisting of two entities and a relation between them.",1 Introduction,[0],[0]
"KBs have many applications in fields such as machine translation, information retrieval and question answering (Ferrucci, 2012).
",1 Introduction,[0],[0]
"When considering a KB’s suitability for a task, primary considerations are the number of facts it contains (Färber et al., 2015), and the precision of those facts.",1 Introduction,[0],[0]
One metric which is often overlooked is completeness.,1 Introduction,[0],[0]
"This can be defined as the proportion of facts about an entity that are present in the KB as compared to an ideal KB which has every
fact that can be known about that entity.",1 Introduction,[0],[0]
"For example, previous research (Suchanek et al., 2011; Min et al., 2013) has shown that between 69% and 99% of entities in popular KBs lack at least one relation that other entities in the same class have.",1 Introduction,[0],[0]
"As of 2016, Wikidata knows the father of only 2% of all people in the KB (Galárraga et al., 2017).",1 Introduction,[0],[0]
"Google found that 71% of people in Freebase have no known place of birth, and 75% have no known nationality (Dong et al., 2014).
",1 Introduction,[0],[0]
"Previous work has focused on a general concept of completeness, where all KB entities are expected to be fully complete, independent of how the KB is used (Motro, 1989; Razniewski et al., 2016; Zaveri et al., 2013).",1 Introduction,[0],[0]
This is a problem because different use cases of a KB may have different completeness requirements.,1 Introduction,[0],[0]
"For this work, we were interested in determining a KB’s completeness with respect to its query usage, which we term Demand-Weighted Completeness.",1 Introduction,[0],[0]
"For example, a relation used 100 times per day is more important than one only used twice per day.",1 Introduction,[0],[0]
"We define our task as follows: ‘Given an entity E in a KB, and query usage data of the KB, predict the distribution of relations that E must have in order for 95% of queries about E to be answered successfully.’",1.1 Problem specification,[0],[0]
"Demand-Weighted Completeness allows us to predict both important missing relations for existing entities, and relations required for unseen entities.",1.2 Motivation,[0],[0]
"As a result we can target acquisition of sources to fill important KB gaps.
",1.2 Motivation,[0],[0]
"It is possible to be entirely reactive when ad-
200
dressing gaps in KB data.",1.2 Motivation,[0],[0]
Failing queries can be examined and missing fields marked for investigation.,1.2 Motivation,[0],[0]
"However, this approach assumes that:
1.",1.2 Motivation,[0],[0]
"the same KB entity will be accessed again in future, making the data acquisition useful.",1.2 Motivation,[0],[0]
"This is far from guaranteed.
",1.2 Motivation,[0],[0]
2.,1.2 Motivation,[0],[0]
the KB already contains all entities needed.,1.2 Motivation,[0],[0]
"While this may hold for some use cases, the most useful KB’s today grow and change to reflect a changing world.
",1.2 Motivation,[0],[0]
"Both assumptions become unnecessary with an abstract representation of entities, allowing generalization to predict usage.",1.2 Motivation,[0],[0]
"The appropriateness of the abstract representation can be measured by how well the model distinguishes different entity types, and how well the model predicts actual usage for a set of entities, either known or unknown.
",1.2 Motivation,[0],[0]
"Further, the Demand-Weighted Completeness of a KB with respect to a specific task can be used as a metric for system performance at that task.",1.2 Motivation,[0],[0]
"By identifying gaps in the KB, it allows targeting of specific improvements to achieve the greatest increase in completeness.
",1.2 Motivation,[0],[0]
Our work is the first to consider KB completeness using the distribution of observed KB queries as a signal.,1.2 Motivation,[0],[0]
"This paper details a learning-based approach that predicts the required relation distributions for both seen and unseen class signatures (Section 3), and shows that a neural network model can generalize relation distributions efficiently and accurately compared to a baseline frequency-based approach (Section 6).",1.2 Motivation,[0],[0]
"Previous work has studied the completeness of the individual properties or database tables over which queries are executed (Razniewski and Nutt, 2011; Razniewski et al., 2015).",2 Related work,[0],[0]
"This approach is suitable for KBs or use cases where individual tables, and individual rows in those tables, are all of equal importance to the KB, or are queried separately.
",2 Related work,[0],[0]
Completeness of KBs has also been measured based on the cardinality of properties.,2 Related work,[0],[0]
"Galárraga et al. (2017) and Mirza et al. (2016) estimated cardinality for several relations with respect to individual entities, yielding targeted completeness information for specific entities.",2 Related work,[0],[0]
"This approach depends on the availability of relevant free text, and uses handcrafted regular expressions to extract the
information, which can be noisy and doesn’t scale to large numbers of relations.
",2 Related work,[0],[0]
"The potential for metrics around completeness and dynamicity of a KB are explored in Zaveri et al. (2013), focusing on the task-independent idea of completeness, and the temporal currency, volatility and timeliness of the KB contents.",2 Related work,[0],[0]
"While their concept of timeliness has some similarities to demand-weighted completeness in its taskspecific ’data currency’, we focus more on how the demand varies over time, and how the completeness of the KB varies with respect to that change in demand.",2 Related work,[0],[0]
The data for a single entity does not generalize on its own.,3.1 Class Distributions,[0],[0]
"In order to generalize from observed usage information to unseen entities and unseen usage, and smooth out outliers, we need to combine data from similar entities.",3.1 Class Distributions,[0],[0]
"Such combination requires a shared entity representation, allowing combination of similar entities while preventing their confusion with dissimilar entities.
",3.1 Class Distributions,[0],[0]
"For this work, an entity may be a member of multiple classes (or types).",3.1 Class Distributions,[0],[0]
We aggregate usage across multiple entities by abstracting to their classes.,3.1 Class Distributions,[0],[0]
"Membership of a class can be considered as a binary attribute for an entity, with the entity’s membership of all the classes considered in the analysis forming a class signature.
",3.1 Class Distributions,[0],[0]
"For example, the entity barackObama is a person, politician, democrat, and writer, among other classes.",3.1 Class Distributions,[0],[0]
He is not a republican.,3.1 Class Distributions,[0],[0]
"Considering these five classes as our class space, the class signature for barackObama would look like Figure 1.
",3.1 Class Distributions,[0],[0]
"Defining an entity by its classes has precedent in previous work (Galárraga et al., 2017; Razniewski et al., 2016).",3.1 Class Distributions,[0],[0]
"It allows consideration of entities and
class combinations not yet seen in the KB (though not entirely new classes).",3.1 Class Distributions,[0],[0]
"KB queries can be considered as graph traversals, stepping through multiple edges of the knowledge graph to determine the result of multi-clause query.",3.2 Relation Distributions,[0],[0]
"For example, the query:
y : hasPresident(USA, x) ∧ hasSpouse(y, x) (1)
determines the spouse of the president of the United States by composing two clauses, as shown in Figure 2.
",3.2 Relation Distributions,[0],[0]
"The demand-weighted importance of a relation R for an entity E is defined as the number of query clauses about E which contain R, as a fraction of the total number of clauses about E.",3.2 Relation Distributions,[0],[0]
"For example, Equation 1 contains two clauses.",3.2 Relation Distributions,[0],[0]
"As the first clause queries for the hasPresident relation of the USA entity, we attribute this occurrence of hasPresident to the USA entity.",3.2 Relation Distributions,[0],[0]
"Aggregating the clauses for an entity gives a total entity usage of the form seen in Figure 3.
",3.2 Relation Distributions,[0],[0]
"Since the distribution of relation usage is dominated by a few high-value relations (see Figure 6), we only consider relations required to satisfy 95% of queries.",3.2 Relation Distributions,[0],[0]
"Combining the two representation methods above, we aim to predict the relation distribution for a
given entity (as in Figure 4) using the class membership for the entity (as in Figure 1).",3.3 Predicting Relations from Classes,[0],[0]
"This provides the expected usage profile of an entity, potentially before it has seen any usage.",3.3 Predicting Relations from Classes,[0],[0]
"We make use of a proprietary KB (Tunstall-Pedoe, 2010) constructed over several years, combining a hand-curated ontology with publicly available data from Wikipedia, Freebase, DBPedia, and other sources.",4.1 Our knowledge base,[0],[0]
"However, the task can be applied to any KB with usage data, relations and classes.",4.1 Our knowledge base,[0],[0]
"We use a subset of our KB for this analysis due to the limitation of model size as a function of the number of classes (input features) and the number of relations (output features).
",4.1 Our knowledge base,[0],[0]
"Our usage data is generated by our Natural Language Understanding system, which produces KB queries from text utterances.",4.1 Our knowledge base,[0],[0]
"Though it is difficult to remove all biases and errors from the system when operated at industrial scale, we use a hybrid system of curated rules and statistical methods to reduce such problems to a minimum.",4.1 Our knowledge base,[0],[0]
Such errors should not impact the way we evaluate different models for their ability to model the data itself.,4.1 Our knowledge base,[0],[0]
"To create a class signature, we first determine the binary class membership vector for every entity in the usage dataset.",4.2 Datasets,[0],[0]
"We then group entities by class signature, so entities with identical class membership are grouped together.
",4.2 Datasets,[0],[0]
"For each class signature, we generate the relation distribution from the usage data of the entities with that signature.",4.2 Datasets,[0],[0]
"In our case, this usage data is a random subset of query traffic against the KB taken from a specific period of time.",4.2 Datasets,[0],[0]
"The more usage a class signature has, the more fine-grained the
distribution of relations becomes.",4.2 Datasets,[0],[0]
"The data is divided into 10 cross-validation folds to ensure that no class signature appears in both the validation and training sets.
",4.2 Datasets,[0],[0]
"We generate 3 different sizes of dataset for experimentation (see Table 1), to see how dataset size influences the models.",4.2 Datasets,[0],[0]
"In this approach, we compute the relation distribution for each individual class by summing the usage data for all entities of that class (see Section 3).",4.3.1 Baseline - Frequency-Based,[0],[0]
"This gives a combined raw relation usage as seen in Figure 5.
",4.3.1 Baseline - Frequency-Based,[0],[0]
For every class in the training set we store this raw relation distribution.,4.3.1 Baseline - Frequency-Based,[0],[0]
"At test time, we compute the predicted relation distribution for a class signature as the normalized sum of the raw distributions of all its classes.",4.3.1 Baseline - Frequency-Based,[0],[0]
"However, these single-class distributions do not capture the influence of class co-occurrence, where the presence of two classes together may have a stronger influence on the importance of a relation than each class on their own.",4.3.1 Baseline - Frequency-Based,[0],[0]
"Additionally, storing distributions for each class signature does not scale, and does not generalize to unseen class combinations.",4.3.1 Baseline - Frequency-Based,[0],[0]
"To investigate the impact of class co-occurrence, we use two different learning models to predict the relation distribution for a given set of input classes.",4.3.2 Learning-Based Approaches,[0],[0]
"The vector of classes comprising the class signature is used as input to the learned models.
",4.3.2 Learning-Based Approaches,[0],[0]
Linear regression.,4.3.2 Learning-Based Approaches,[0],[0]
"Using the normalized relation distribution for each class signature, we
trained a least-squares linear regression model to predict the relation distribution from a binary vector of classes.",4.3.2 Learning-Based Approaches,[0],[0]
"This model has (n×m) parameters, where n is the number of input classes and m is the number of relations.",4.3.2 Learning-Based Approaches,[0],[0]
"We implemented our linear regression model using Scikit-learn toolkit (Pedregosa et al., 2011).
",4.3.2 Learning-Based Approaches,[0],[0]
Neural network.,4.3.2 Learning-Based Approaches,[0],[0]
"We trained a feed-forward neural network using the binary class vector as the input layer, with a low-dimensional (h) hidden layer (with rectified linear unit as activation) followed by a softmax output layer of the size of the relation set.",4.3.2 Learning-Based Approaches,[0],[0]
"This model has h(n+m) parameters, which depending on the value of h is significantly smaller than the linear regression model.",4.3.2 Learning-Based Approaches,[0],[0]
The objective function used for training was KullbackLiebler Divergence.,4.3.2 Learning-Based Approaches,[0],[0]
"We chose Keras (Chollet, 2015) to implement the neural network model.",4.3.2 Learning-Based Approaches,[0],[0]
"The model had a single 10-node Rectified Linear Unit hidden layer, with a softmax over the output.",4.3.2 Learning-Based Approaches,[0],[0]
"We compare the predicted relation distributions to those observed for the test examples in two ways:
Weighted Jaccard Index.",5 Evaluation,[0],[0]
"We modified the Jaccard index (Jaccard, 1912) to include a weighting term, which weights every relation with the mean weight in the predicted and observed distribution (see Figure 6).",5 Evaluation,[0],[0]
"This rewards a correctly predicted relation without focusing on the proportion predicted for that relation, and is sufficient to define a set of important relations for a class sig-
nature.",5 Evaluation,[0],[0]
"This is given by:
J =
∑ i W (Ri)×Ri ∈",5 Evaluation,[0],[0]
(P ∩O) ∑ i W (Ri)×Ri ∈,5 Evaluation,[0],[0]
"(P ∪O)
(2)
where P is the predicted distribution, O is the observed distribution, W (Ri) is the mean weight of relation Ri in P and O. We also calculate false negatives (observed but not predicted) and false positives (predicted but not observed), by modifying the second term in the numerator of Equation 2 to give P\O and O\P , rather than P ∩O.
Intersection.",5 Evaluation,[0],[0]
We compute the intersection of the two distributions (see Figure 6).,5 Evaluation,[0],[0]
This is a more strict comparison between the distributions which penalizes differences in weight for individual relations.,5 Evaluation,[0],[0]
"This is given by:
I = ∑
i
min(P (Ri), O(Ri))",5 Evaluation,[0],[0]
(3),5 Evaluation,[0],[0]
"We also evaluated the models using the Weighted Jaccard index and Intersection methods, but weighting by usage counts for each signature.",5.1 Usage Weighted Evaluation,[0],[0]
This metric rewards the models more for correctly predicting relation distributions for common class signatures in the usage data.,5.1 Usage Weighted Evaluation,[0],[0]
"While unweighted analysis is useful to examine how the model covers the breadth of the problem space, weighted evaluation more closely reflects the model’s utility for real usage data.",5.1 Usage Weighted Evaluation,[0],[0]
"Additionally, we evaluated the models on their ability to predict future usage.",5.2 Temporal Prediction,[0],[0]
"With an unchanging usage pattern, evaluation against future usage would be equivalent to cross-validation (assuming the same signature distribution in the folds).",5.2 Temporal Prediction,[0],[0]
"However, in many real world cases, usage of a KB varies over time, seasonally or as a result of changing user requirements.
",5.2 Temporal Prediction,[0],[0]
Therefore we also evaluated a neural model against future usage data to measure how elapsed time affected model performance.,5.2 Temporal Prediction,[0],[0]
"The datasets T1, T2, and T3 each contain 3 datasets (of similar size to D1small, D2medium, and D1large), and were created using usage data from time periods with a fixed offset, t.",5.2 Temporal Prediction,[0],[0]
"The base set was created at time t0, T1 at time t0 + t, T2 at time t0 + 2t, and T3 at time t0+3t. A time interval was chosen that reflected the known variability of the usage data,
such that we would expect the usage to not be the same.",5.2 Temporal Prediction,[0],[0]
10-fold cross-validation results are shown in Table 2.,6.1 Cross-Validation,[0],[0]
"The neural network model performs best, outperforming the baseline model by 6-8 percentage points.",6.1 Cross-Validation,[0],[0]
"The regression model performs worst, trailing the baseline model by 4-8 percentage points.",6.1 Cross-Validation,[0],[0]
The baseline model shows little improvement with increasing amounts of data - the results from D1small to D3large (3x more data points) only improve by just over 1 percentage point.,6.1.1 Baseline,[0],[0]
"This suggests that this model is unable to generalise from the data, which is expected from the lack of class co-occurrence information in the model.",6.1.1 Baseline,[0],[0]
"Interestingly, the baseline model shows an increase in false negatives on the larger datasets, implying the lack of generalisation is more problematic for more fine-grained relation distributions.",6.1.1 Baseline,[0],[0]
The linear regression model gives a much lower Jaccard measure than the baseline model.,6.1.2 Linear Regression,[0],[0]
This is likely due to the number of parameters in the model relative to the number of examples.,6.1.2 Linear Regression,[0],[0]
"For D1small, the model has approximately 6m parameters, with 12k training examples, making this an
under-determined system.",6.1.2 Linear Regression,[0],[0]
"For D3large the number of parameters rises to 20m, with 37k training examples, maintaining the poor example:parameter ratio.",6.1.2 Linear Regression,[0],[0]
"From this we might expect the performance of the model to be invariant with the amount of data.
",6.1.2 Linear Regression,[0],[0]
"However, the larger datasets also have higher resolution relation distributions, as they are aggregated from more individual examples.",6.1.2 Linear Regression,[0],[0]
"This has the effect of reducing the impact of outliers in the data, giving improved predictions when the model generalises.",6.1.2 Linear Regression,[0],[0]
"We do indeed see that the linear regression model improves notably with larger datasets, closing the gap to the baseline model from 8 percentage points to 4.",6.1.2 Linear Regression,[0],[0]
The neural network model shows much better performance than either of the other two methods.,6.1.3 Neural Network,[0],[0]
"The Jaccard score is consistently 6-8% above the regression model, with far fewer false negatives and smaller numbers of false positives.",6.1.3 Neural Network,[0],[0]
This is likely to be due to the smaller number of parameters of the neural model versus the linear regression model.,6.1.3 Neural Network,[0],[0]
"For D3large, the 10-node hidden layer model amounts to 115k parameters with 37k training examples, a far better ratio (though still not ideal) than for the linear regression model.",6.1.3 Neural Network,[0],[0]
We include in Table 3 the results using the weighted evaluation scheme described in Section 5.1.,6.1.4 Weighted Evaluation,[0],[0]
"This gives more usage-focused evaluation, emphasizing the non-uniform usage of different class signatures.",6.1.4 Weighted Evaluation,[0],[0]
The D3large neural model achieves 85% precision with a weighted evaluation.,6.1.4 Weighted Evaluation,[0],[0]
"With the low rate of false negatives, this indicates that a similar model could be used to predict the necessary relations for KB usage.",6.1.4 Weighted Evaluation,[0],[0]
Table 4 gives measurements of the intersection metric.,6.2 Intersection,[0],[0]
"These show a similar trend to the Jaccard scores, with lower absolute values from the stricter evaluation metric.",6.2 Intersection,[0],[0]
"Although the Jaccard measure shows correct relation set prediction with a precision of 0.700, predicting the proportions for those relations accurately remains a difficult problem.",6.2 Intersection,[0],[0]
The best value we achieved was 0.398.,6.2 Intersection,[0],[0]
"In addition to evaluating models on their ability to predict the behaviour of unseen class signatures, we also evaluated the neural model on its ability to predict future usage behaviour.",6.3 Unweighted Temporal Prediction,[0],[0]
"The results of this experiment are given in Table 5.
",6.3 Unweighted Temporal Prediction,[0],[0]
"We observe a very slight downward trend in the precision of the model using all three base datasets (D1small - D3large), with a steeper (but still slight) downward trend for the larger datasets.",6.3 Unweighted Temporal Prediction,[0],[0]
This suggests that a model trained on usage data from one period of time will have significant predictive power on future datasets.,6.3 Unweighted Temporal Prediction,[0],[0]
"Once we have a suitable model of the expected relation distributions for class combinations, we use the model to predict the expected relation distribution for specific entities in our KB.",7 Measuring Completeness of a KB,[0],[0]
We then compare the predicted relation distribution to the observed relations for each specific entity.,7 Measuring Completeness of a KB,[0],[0]
"The completeness of an entity is given by the sum of the relation proportions for the predicted relations the entity has in the KB.
",7 Measuring Completeness of a KB,[0],[0]
"Any gaps for an entity represent relations that, if added to the KB, would have a quantifiable positive impact on the performance of the KB.",7 Measuring Completeness of a KB,[0],[0]
"By focussing on the most important entities according to our usage, we can target fact addition to have the greatest impact to the usage the KB receives.
",7 Measuring Completeness of a KB,[0],[0]
"By aggregating the completeness values for a set of entities, we may estimate the completeness of subsets of the KB.",7 Measuring Completeness of a KB,[0],[0]
"This aggregation is weighted by the frequency with which the entity appears in the usage data, giving a usage-weighted measure of the subset’s completeness.",7 Measuring Completeness of a KB,[0],[0]
"These subsets can represent individual topics, individual classes of entity, or overall information about the KB as a whole.
",7 Measuring Completeness of a KB,[0],[0]
"For example, using the best neural model above on an unrepresentative subset of our KB, we evaluate the completeness of that subset at 58.3%.",7 Measuring Completeness of a KB,[0],[0]
"This not only implies that we are missing a substantial amount of necessary information for these entities with respect to the usage data chosen, but permits targeting of source acquisition to improve the entity completness in aggregate.",7 Measuring Completeness of a KB,[0],[0]
"For example, if we are missing a large number of hasBirthdate facts for people, we might locate a source that has that information.",7 Measuring Completeness of a KB,[0],[0]
We can quantify the benefit of that effort in terms of improved usage performance.,7 Measuring Completeness of a KB,[0],[0]
We have introduced the notion of DemandWeighted Completeness as a way of determining a KB’s suitability by employing usage data.,8 Conclusions and Future Work,[0],[0]
"We have demonstrated a method to predict the distribution of relations needed in a KB for entities of a given class signature, and have compared three different models for predicting these distributions.",8 Conclusions and Future Work,[0],[0]
"Further, we have described a method to measure the completeness of a KB using these distributions.
",8 Conclusions and Future Work,[0],[0]
"For future work we would like to try complex neural network architectures, regularisation, and semantic embeddings or other abstracted relations to enhance the signatures.",8 Conclusions and Future Work,[0],[0]
"We would also like to investigate Good-Turing frequency estimation (Good, 1953).",8 Conclusions and Future Work,[0],[0]
"In this paper we introduce the notion of Demand-Weighted Completeness, allowing estimation of the completeness of a knowledge base with respect to how it is used.",abstractText,[0],[0]
"Defining an entity by its classes, we employ usage data to predict the distribution over relations for that entity.",abstractText,[0],[0]
"For example, instances of person in a knowledge base may require a birth date, name and nationality to be considered complete.",abstractText,[0],[0]
"These predicted relation distributions enable detection of important gaps in the knowledge base, and define the required facts for unseen entities.",abstractText,[0],[0]
Such characterisation of the knowledge base can also quantify how usage and completeness change over time.,abstractText,[0],[0]
"We demonstrate a method to measure DemandWeighted Completeness, and show that a simple neural network model performs well at this prediction task.",abstractText,[0],[0]
Demand-Weighted Completeness Prediction for a Knowledge Base,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1119–1130, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
Though dialectal language is increasingly abundant on social media, few resources exist for developing NLP tools to handle such language. We conduct a case study of dialectal language in online conversational text by investigating African-American English (AAE) on Twitter. We propose a distantly supervised model to identify AAE-like language from demographics associated with geo-located messages, and we verify that this language follows well-known AAE linguistic phenomena. In addition, we analyze the quality of existing language identification and dependency parsing tools on AAE-like text, demonstrating that they perform poorly on such text compared to text associated with white speakers. We also provide an ensemble classifier for language identification which eliminates this disparity and release a new corpus of tweets containing AAE-like language.
Data and software resources are available at: http://slanglab.cs.umass.edu/TwitterAAE",text,[0],[0]
"Owing to variation within a standard language, regional and social dialects exist within languages across the world.",1 Introduction,[0],[0]
"These varieties or dialects differ from the standard variety in syntax (sentence structure), phonology (sound structure), and the inventory of words and phrases (lexicon).",1 Introduction,[0],[0]
"Dialect communities often align with geographic and sociological factors, as language variation emerges within distinct social networks, or is affirmed as a marker of social identity.
",1 Introduction,[0],[0]
"As many of these dialects have traditionally existed primarily in oral contexts, they have historically been underrepresented in written sources.",1 Introduction,[0],[0]
"Consequently, NLP tools have been developed from text which aligns with mainstream languages.",1 Introduction,[0],[0]
"With the rise of social media, however, dialectal language is playing an increasingly prominent role in online conversational text, for which traditional NLP tools may be insufficient.",1 Introduction,[0],[0]
"This impacts many applications: for example, dialect speakers’ opinions may be mischaracterized under social media sentiment analysis or omitted altogether (Hovy and Spruit, 2016).",1 Introduction,[0],[0]
"Since this data is now available, we seek to analyze current NLP challenges and extract dialectal language from online data.
",1 Introduction,[0],[0]
"Specifically, we investigate dialectal language in publicly available Twitter data, focusing on AfricanAmerican English (AAE), a dialect of Standard American English (SAE) spoken by millions of people across the United States.",1 Introduction,[0],[0]
"AAE is a linguistic variety with defined syntactic-semantic, phonological, and lexical features, which have been the subject of a rich body of sociolinguistic literature.",1 Introduction,[0],[0]
"In addition to the linguistic characterization, reference to its speakers and their geographical location or speech communities is important, especially in light of the historical development of the dialect.",1 Introduction,[0],[0]
"Not all African-Americans speak AAE, and not all speakers of AAE are African-American; nevertheless, speakers of this variety have close ties with specific communities of African-Americans (Green, 2002).",1 Introduction,[0],[0]
"Due to its widespread use, established history in the sociolinguistic literature, and demographic associations, AAE provides an ideal starting point for the development of a statistical model that uncovers dialectal
1119
language.",1 Introduction,[0],[0]
"In fact, its presence in social media is attracting increasing interest for natural language processing (Jørgensen et al., 2016) and sociolinguistic (Stewart, 2014; Eisenstein, 2015; Jones, 2015)",1 Introduction,[0],[0]
"research.1 In this work we:
• Develop a method to identify demographically-aligned text and language from geo-located messages (§2), based on distant supervision of geographic census demographics through a statistical model that assumes a soft correlation between demographics and language.
•",1 Introduction,[0],[0]
"Validate our approach by verifying that text aligned with African-American demographics follows well-known phonological and syntactic properties of AAE, and document the previously unattested ways in which such text diverges from SAE (§3).",1 Introduction,[0],[0]
"• Demonstrate racial disparity in the efficacy
of NLP tools for language identification and dependency parsing—they perform poorly on this text, compared to text associated with white speakers (§4, §5).",1 Introduction,[0],[0]
"• Improve language identification for U.S. on-
line conversational text with a simple ensemble classifier using our demographicallybased distant supervision method, aiming to eliminate racial disparity in accuracy rates (§4.2).",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"Provide a corpus of 830,000 tweets aligned
with African-American demographics.",1 Introduction,[0],[0]
"The presence of AAE in social media and the generation of resources of AAE-like text for NLP tasks has attracted recent interest in sociolinguistic and natural language processing research; Jones (2015) shows that nonstandard AAE orthography on Twitter aligns with historical patterns of AfricanAmerican migration in the U.S., while Jørgensen et al. (2015) investigate to what extent it supports well-known sociolinguistics hypotheses about AAE.
",2 Identifying AAE from Demographics,[0],[0]
"1Including a recent linguistics workshop: http://linguistlaura.blogspot.co.uk/2016/06/ using-twitter-for-linguistic-research.html
Both, however, find AAE-like language on Twitter through keyword searches, which may not yield broad corpora reflective of general AAE use.",2 Identifying AAE from Demographics,[0],[0]
"More recently, Jørgensen et al. (2016) generated a large unlabeled corpus of text from hip-hop lyrics, subtitles from The Wire and The Boondocks, and tweets from a region of the southeast U.S. While this corpus does indeed capture a wide variety of language, we aim to discover AAE-like language by utilizing finer-grained, neighborhood-level demographics from across the country.
",2 Identifying AAE from Demographics,[0],[0]
"Our approach to identifying AAE-like text is to first harvest a set of messages from Twitter, cross-referenced against U.S. Census demographics (§2.1), then to analyze words against demographics with two alternative methods, a seedlist approach (§2.2) and a mixed-membership probabilistic model (§2.3).",2 Identifying AAE from Demographics,[0],[0]
"In order to create a corpus of demographicallyassociated dialectal language, we turn to Twitter, whose public messages contain large amounts of casual conversation and dialectal speech (Eisenstein, 2015).",2.1 Twitter and Census data,[0],[0]
It is well-established that Twitter can be used to study both geographic dialectal varieties2 and minority,2.1 Twitter and Census data,[0],[0]
"languages.3
Some methods exist to associate messages with authors’ races; one possibility is to use birth record statistics to identify African-American-associated names, which has been used in (non-social media) social science studies (Sweeney, 2013; Bertrand and Mullainathan, 2003).",2.1 Twitter and Census data,[0],[0]
"However, metadata about authors is fairly limited on Twitter and most other social media services, and many supplied names are obviously not real.
",2.1 Twitter and Census data,[0],[0]
"Instead, we turn to geo-location and induce a distantly supervised mapping between authors and the demographics of the neighborhoods they live in (O’Connor et al., 2010; Eisenstein et al., 2011b; Stewart, 2014).",2.1 Twitter and Census data,[0],[0]
"We draw on a set of geo-located Twitter messages, most of which are sent on mobile phones, by authors in the U.S. in 2013.",2.1 Twitter and Census data,[0],[0]
"(These are selected from a general archive of the “Gardenhose/Decahose” sample stream of public Twit-
2For example, of American English (Huang et al., 2015; Doyle, 2014).
",2.1 Twitter and Census data,[0],[0]
"3For example, Lynn et al. (2015) develop POS corpora and taggers for Irish tweets; see also related work in §4.1.
ter messages (Morstatter et al., 2013)).",2.1 Twitter and Census data,[0],[0]
"Geolocated users are a particular sample of the userbase (Pavalanathan and Eisenstein, 2015), but we expect it is reasonable to compare users of different races within this group.
",2.1 Twitter and Census data,[0],[0]
"We look up the U.S. Census blockgroup geographic area that the message was sent in; blockgroups are one of the smallest geographic areas defined by the Census, typically containing a population of 600–3000 people.",2.1 Twitter and Census data,[0],[0]
"We use race and ethnicity information for each blockgroup from the Census’ 2013 American Community Survey, defining four covariates: percentages of the population that are non-Hispanic whites, non-Hispanic blacks, Hispanics (of any race), and Asian.4 Finally, for each user u, we average the demographic values of all their messages in our dataset into a length-four vector π(census)u .",2.1 Twitter and Census data,[0],[0]
"Under strong assumptions, this could be interpreted as the probability of which race the user is; we prefer to think of it as a rough proxy for likely demographics of the author and the neighborhood they live in.
",2.1 Twitter and Census data,[0],[0]
"Messages were filtered in order to focus on casual conversational text; we exclude tweets whose authors had 1000 or more followers, or that (a) contained 3 or more hashtags, (b) contained the strings “http”, “follow”, or “mention” (messages designed to generate followers), or (c) were retweeted (either containing the string “rt” or marked by Twitter’s metadata as re-tweeted).
",2.1 Twitter and Census data,[0],[0]
Our initial Gardenhose/Decahose stream archive had 16 billion messages in 2013; 90 million were geo-located with coordinates that matched a U.S. Census blockgroup.,2.1 Twitter and Census data,[0],[0]
59.2 million tweets from 2.8 million users remained after pre-processing; each user is associated with a set of messages and averaged demographics π(census)u .,2.1 Twitter and Census data,[0],[0]
"Given a set of messages and demographics associated with their authors, a number of methods could be used to infer statistical associations between language and demographics.
",2.2 Direct Word-Demographic Analysis,[0],[0]
Direct word-demographic analysis methods use the π(census)u quantities to calculate statistics at the word level in a single pass.,2.2 Direct Word-Demographic Analysis,[0],[0]
"An intuitive approach is to calculate the average demographics per word.
4See appendix for additional details.
",2.2 Direct Word-Demographic Analysis,[0],[0]
"For a token in the corpus indexed by t (across the whole corpus), let u(t) be the author of the message containing that token, andwt be the word token.",2.2 Direct Word-Demographic Analysis,[0],[0]
"The average demographics of word type w is:5
π(softcount)w ≡ ∑ t 1{wt = w}π (census) u(t)∑
t 1{wt = w}",2.2 Direct Word-Demographic Analysis,[0],[0]
"We find that terms with the highest πw,AA values (denoting high average African-American demographics of their authors’ locations) are very non-standard, while Stewart (2014) and Eisenstein (2013) find large πw,AA associated with certain AAE linguistic features.
",2.2 Direct Word-Demographic Analysis,[0],[0]
"One way to use the πw,k values to construct a corpus is through a seedlist approach.",2.2 Direct Word-Demographic Analysis,[0],[0]
"In early experiments, we constructed a corpus of 41,774 users (2.3 million messages) by first selecting the n = 100 highest-πw,AA terms occurring at least m = 3000 times across the data set, then collecting all tweets from frequent authors who have at least 10 tweets and frequently use these terms, defined as the case when at least p = 20% of their messages contain at least one of the seedlist terms.",2.2 Direct Word-Demographic Analysis,[0],[0]
"Unfortunately, the n,m, p thresholds are ad-hoc.",2.2 Direct Word-Demographic Analysis,[0],[0]
"The direct word-demographics analysis gives useful validation that the demographic information may yield dialectal corpora, and the seedlist approach can assemble a set of users with heavy dialectal usage.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"However, the approach requires a number of ad-hoc thresholds, cannot capture authors who only occasionally use demographically-aligned language, and cannot differentiate language use at the message-level.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"To address these concerns, we develop a mixed-membership model for demographics and language use in social media.
",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"The model directly associates each of the four demographic variables with a topic; i.e. a unigram language model over the vocabulary.6 The model assumes an author’s mixture over the topics tends to
5 πw,k has the flavor of “soft counts” in multinomial EM.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"By changing the denominator to ∑ t π (census)
u(t) , it calculates a unigram language model that sums to one across the vocabulary.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"This hints at a more complete modeling approach (§2.3).
",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"6To build the vocabulary, we select all words used by at least 20 different users, resulting in 191,873 unique words; other words are mapped to an out-of-vocabulary symbol.
be similar to their Census-associated demographic weights, and that every message has its own topic distribution.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"This allows for a single author to use different types of language in different messages, accommodating multidialectal authors.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"The messagelevel topic probabilities θm are drawn from an asymmetric Dirichlet centered on π(census)u , whose scalar concentration parameter α controls whether authors’ language is very similar to the demographic prior, or can have some deviation.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"A token t’s latent topic zt is drawn from θm, and the word itself is drawn from φzt , the language model for the topic (Figure 1).
",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
Thus the model learns demographically-aligned language models for each demographic category.,2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"The model is much more tightly constrained than a topic model—for example, if α → ∞, θ becomes fixed and the likelihood is concave as a function of φ—but it still has more joint learning than a direct calculation approach, since the inference of a messages’ topic memberships θm is affected not just by the Census priors, but also by the language used.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"A tweet written by an author in a highly AA neighborhood may be inferred to be non-AAE-aligned if it uses non-AAE-associated terms; as inference proceeeds, this information is used to learn sharper language models.
",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"We fit the model with collapsed Gibbs sampling (Griffiths and Steyvers, 2004) with repeated sample updates for each token t in the corpus,
p(zt",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"= k | w, z−t) ∝",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"Nwk + β/V
Nk + β",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"Nmk + απuk Nm + α
where Nwk is the number of tokens where word w occurs under topic z = k, Nmk is the number of tokens in the current message with topic k, etc.; all counts exclude the current t position.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"We observed
convergence of the log-likelihood within 100 to 200 iterations, and ran for 300 total.7 We average together count tables from the last 50 Gibbs samples for analysis of posterior topic memberships at the word, message, and user level; for example, the posterior probability a particular user u uses topic k, P (z = k | u), can be calculated as the fraction of tokens with topic k within messages authored by u.
We considered α to be a fixed control parameter; setting it higher increases the correlations between P (z = k | u) and π(census)u,k .",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"We view the selection of α as an inherently difficult problem, since the correlation between race and AAE usage is already complicated and imperfect at the author-level, and census demographics allow only for rough associations.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"We set α = 10 which yields posterior user-level correlations of P (z = AA | u) against πu,AA to be approximately 0.8.
",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"This model has broadly similar goals as nonlatent, log-linear generative models of text that condition on document-level covariates (Monroe et al., 2008; Eisenstein et al., 2011a; Taddy, 2013).",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"The formulation here has the advantage of fast inference with large vocabularies (since the partition function never has to be computed), and gives probabilistic admixture semantics at arbitrary levels of the data.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"This model is also related to topic models where the selection of θ conditions on covariates (Mimno and McCallum, 2008; Ramage et al., 2011; Roberts et al., 2013), though it is much simpler without full latent topic learning.
",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"In early experiments, we used only two classes (AA and not AA), and found Spanish terms being included in the AA topic.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
Thus we turned to four race categories in order to better draw out non-AAE language.,2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"This removed Spanish terms from the AA topic; interestingly, they did not go to the Hispanic topic, but instead to Asian, along with other foreign languages.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"In fact, the correlation between users’ Census-derived proportions of Asian populations, versus this posterior topic’s proportions, is only 0.29, while the other three topics correlate to their respective Census priors in the range 0.83 to 0.87.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
This indicates the “Asian” topic actually functions as a background topic (at least in part).,2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"Better modeling of demographics and non-English
7Our straightforward single core implementation (in Julia) spends 80 seconds for each iteration over 586 million tokens.
language interactions is interesting potential future work.
",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"By fitting the model to data, we can directly analyze unigram probabilities within the model parameters φ, but for other analyses, such as analyzing larger syntactic constructions and testing NLP tools, we require an explicit corpus of messages.
To generate a user-based AA-aligned corpus, we collected all tweets from users whose posterior probability of using AA-associated terms under the model was at least 80%, and generated a corresponding white-aligned corpus as well.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"In order to remove the effects of non-English languages, and given uncertainty about what the model learned in the Hispanic and Asian-aligned demographic topics, we focused only on AA- and white-aligned language by imposing the additional constraint that each user’s combined posterior proportion of Hispanic or Asian language was less than 5%.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"Our two resulting user corpora contain 830,000 and 7.3 million tweets, for which we are making their message IDs available for further research (in conformance with the Twitter API’s Terms of Service).",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"In the rest of the work, we refer to these as the AA- and white-aligned corpora, respectively.",2.3 Mixed-Membership Demographic-Language Model,[0],[0]
"Because validation by manual inspection of our AAaligned text is impractical, we turn to the wellstudied phonological and syntactic phenomena that traditionally distinguish AAE from SAE.",3 Linguistic Validation,[0],[0]
"We validate our model by reproducing these phenomena, and document a variety of other ways in which our AA-aligned text diverges from SAE.",3 Linguistic Validation,[0],[0]
We begin by examining how much AA- and whitealigned lexical items diverge from a standard dictionary.,3.1 Lexical-Level Variation,[0],[0]
"We used SCOWL’s largest wordlist with level 1 variants as our dictionary, totaling 627,685 words.8
We calculated, for each word w in the model’s vocabulary, the ratio
rk(w) = p(w|z = k) p(w|z 6=",3.1 Lexical-Level Variation,[0],[0]
"k)
",3.1 Lexical-Level Variation,[0],[0]
"where the p(.|.) probabilities are posterior inferences, derived from averaged Gibbs samples of the
8http://wordlist.aspell.net/
sufficient statistic count tables Nwk.",3.1 Lexical-Level Variation,[0],[0]
"We selected heavily AA- and white-aligned words as those where rAA(w) ≥ 2 and rwhite(w) ≥ 2, respectively.",3.1 Lexical-Level Variation,[0],[0]
"We find that while 58.2% of heavily white-aligned words were not in our dictionary, fully 79.1% of heavily AA-aligned words were not.",3.1 Lexical-Level Variation,[0],[0]
"While a high number of out-of-dictionary lexical items is expected for Twitter data, this disparity suggests that the AA-aligned lexicon diverges from SAE more strongly than the white-aligned lexicon.",3.1 Lexical-Level Variation,[0],[0]
We performed an “open vocabulary” unigram analysis by ranking all words in the vocabulary by rAA(w) and browsed them and samples of their usage.,3.2 Internet-Specific Orthographic Variation,[0],[0]
"Among the words with high rAA, we observe a number of Internet-specific orthographic variations, which we separate into three types: abbreviations (e.g. llh, kmsl), shortenings (e.g. dwn, dnt), and spelling variations which do not correlate to the word’s pronunciation (e.g. axx, bxtch).",3.2 Internet-Specific Orthographic Variation,[0],[0]
"These variations do not reflect features attested in the literature; rather, they appear to be purely orthographic variations highly specific to AAE-speaking communities online.",3.2 Internet-Specific Orthographic Variation,[0],[0]
"They may highlight previously unknown linguistic phenomena; for example, we observe that thoe (SAE though) frequently appears in the role of a discourse marker instead of its standard SAE usage (e.g. Girl Madison outfit THOE).",3.2 Internet-Specific Orthographic Variation,[0],[0]
"This new use of though as a discourse marker, which is difficult to observe using the SAE spelling amidst many instances of the SAE usage, is readily identifiable in examples containing the thoe variant.",3.2 Internet-Specific Orthographic Variation,[0],[0]
"Thus, nonstandard spellings provide valuable windows into a variety of linguistic phenomena.
",3.2 Internet-Specific Orthographic Variation,[0],[0]
"In the next section, we turn to variations which do appear to arise from known phonological processes.",3.2 Internet-Specific Orthographic Variation,[0],[0]
"Many phonological features are closely associated with AAE (Green, 2002).",3.3 Phonological Variation,[0],[0]
"While there is not a perfect correlation between orthographic variations and people’s pronunciations, Eisenstein (2013) shows that some genuine phonological phenomena, including a number of AAE features, are accurately reflected in orthographic variation on social media.",3.3 Phonological Variation,[0],[0]
"We therefore validate our model by verifying that spellings reflecting known AAE phonological features align closely with the AA topic.
",3.3 Phonological Variation,[0],[0]
"We selected 31 variants of SAE words from previous studies of AAE phonology on Twitter (Jørgensen et al., 2015; Jones, 2015).",3.3 Phonological Variation,[0],[0]
"These variations display a range of attested AAE phonological features, such as derhotacization (e.g. brotha), deletion of initial g and d (e.g. iont), and realization of voiced th as d (e.g. dey) (Rickford, 1999).
",3.3 Phonological Variation,[0],[0]
Table 1 shows the top five of these words by their rAA(w) ratio.,3.3 Phonological Variation,[0],[0]
"For 30 of the 31 words, r ≥ 1, and for 13 words, r ≥ 100, suggesting that our model strongly identifies words displaying AAE phonological features with the AA topic.",3.3 Phonological Variation,[0],[0]
"The sole exception is the word brotha, which appears to have been adopted into general usage as its own lexical item.",3.3 Phonological Variation,[0],[0]
"We further validate our model by verifying that it reproduces well-known AAE syntactic constructions, investigating three well-attested AAE aspectual or preverbal markers: habitual be, future gone, and completive done (Green, 2002).",3.4 Syntactic Variation,[0],[0]
"Table 2 shows examples of each construction.
",3.4 Syntactic Variation,[0],[0]
"To search for the constructions, we tagged the corpora using the ARK Twitter POS tagger (Gimpel et al., 2011; Owoputi et al., 2013),9 which Jørgensen et al. (2015) show has similar accuracy rates on both AAE and non-AAE tweets, unlike other POS taggers.",3.4 Syntactic Variation,[0],[0]
"We searched for each construction by searching for sequences of unigrams and POS tags characterizing the construction; e.g. for habitual be we searched for the sequences O-be-V and O-b-V. Nonstandard spellings for the unigrams in the patterns were identified from the ranked analysis of §3.2.
",3.4 Syntactic Variation,[0],[0]
We examined how a message’s likelihood of using each construction varies with the message’s posterior probability of AA.,3.4 Syntactic Variation,[0],[0]
"We split all messages into deciles based on the messages’ posterior probabil-
9Version 0.3.2: http://www.cs.cmu.edu/∼ark/TweetNLP/
ity of AA.",3.4 Syntactic Variation,[0],[0]
"From each decile, we sampled 200,000 messages and calculated the proportion of messages containing the three syntactic constructions.
",3.4 Syntactic Variation,[0],[0]
"For all three constructions, we observed the clear pattern that as messages’ posterior probabilities of AA increase, so does their likelihood of containing the construction.",3.4 Syntactic Variation,[0],[0]
"Interestingly, for all three constructions, frequency of usage peaks at approximately the [0.7, 0.8) decile.",3.4 Syntactic Variation,[0],[0]
"One possible reason for the decline in higher deciles might be tendency of high-AA messages to be shorter; while the mean number of tokens per message across all deciles in our samples is 9.4, the means for the last two deciles are 8.6 and 7.1, respectively.
",3.4 Syntactic Variation,[0],[0]
"Given the important linguistic differences between our demographically-aligned subcorpora, we hypothesize that current NLP tools may behave differently.",3.4 Syntactic Variation,[0],[0]
We investigate this hypothesis in §4 and §5.,3.4 Syntactic Variation,[0],[0]
"Language identification, the task of classifying the major world language in which a message is written, is a crucial first step in almost any web or social
media text processing pipeline.",4.1 Evaluation of Existing Classifiers,[0],[0]
"For example, in order to analyze the opinions of U.S. Twitter users, one might throw away all non-English messages before running an English sentiment analyzer.
Hughes et al. (2006) review language identification methods; social media language identification is challenging since messages are short, and also use non-standard and multiple (often related) languages (Baldwin et al., 2013).",4.1 Evaluation of Existing Classifiers,[0],[0]
"Researchers have sought to model code-switching in social media language (Rosner and Farrugia, 2007; Solorio and Liu, 2008; Maharjan et al., 2015; Zampieri et al., 2013; King and Abney, 2013), and recent workshops have focused on code-switching (Solorio et al., 2014) and general language identification (Zubiaga et al., 2014).",4.1 Evaluation of Existing Classifiers,[0],[0]
"For Arabic dialect classification, work has developed corpora in both traditional and Romanized script (Cotterell et al., 2014; Malmasi et al., 2015) and tools that use n-gram and morphological analysis to identify code-switching between dialects and with English (Elfardy et al., 2014).
",4.1 Evaluation of Existing Classifiers,[0],[0]
"We take the perspective that since AAE is a dialect of American English, it ought to be classified as English for the task of major world language identification.",4.1 Evaluation of Existing Classifiers,[0],[0]
"Lui and Baldwin (2012) develop langid.py, one of the most popular open source language identification tools, training it on over 97 languages from texts including Wikipedia, and evaluating on both traditional corpora and Twitter messages.",4.1 Evaluation of Existing Classifiers,[0],[0]
"We hypothesize that if a language identification tool is trained on standard English data, it may exhibit disparate performance on AA- versus whitealigned tweets.",4.1 Evaluation of Existing Classifiers,[0],[0]
"Since language identifiers are typically based on character n-gram features, they may get confused by the types of lexical/orthographic divergences seen in §3.",4.1 Evaluation of Existing Classifiers,[0],[0]
"To evaluate this hypothesis, we compare the behavior of existing language identifiers on our subcorpora.
We test langid.py as well as the output of Twitter’s in-house identifier, whose predictions are included in a tweet’s metadata (from 2013, the time of data
collection); the latter may give a language code or a missing value (unk or an empty/null value).",4.1 Evaluation of Existing Classifiers,[0],[0]
"We record the proportion of non-English predictions by these systems; Twitter-1 does not consider missing values to be a non-English prediction, and Twitter-2 does.
",4.1 Evaluation of Existing Classifiers,[0],[0]
"We noticed emojis had seemingly unintended consequences on langid.py’s classifications, so removed all emojis by characters from the relevant Unicode ranges.",4.1 Evaluation of Existing Classifiers,[0],[0]
"We also removed @-mentions.
",4.1 Evaluation of Existing Classifiers,[0],[0]
User-level analysis We begin by comparing the classifiers’ behavior on the AA- and white-aligned corpora.,4.1 Evaluation of Existing Classifiers,[0],[0]
"Of the AA-aligned tweets, 13.2% were classified by langid.py as non-English; in contrast, 7.6% of white-aligned tweets were classified as such.",4.1 Evaluation of Existing Classifiers,[0],[0]
"We observed similar disparities for Twitter-1 and Twitter-2, illustrated in Table 3.
",4.1 Evaluation of Existing Classifiers,[0],[0]
"It turns out these “non-English” tweets are, for the most part, actually English.",4.1 Evaluation of Existing Classifiers,[0],[0]
We sampled and annotated 50 tweets from the tweets classified as nonEnglish by each run.,4.1 Evaluation of Existing Classifiers,[0],[0]
"Of these 300 tweets, only 3 could be unambiguously identified as written in a language other than English.
",4.1 Evaluation of Existing Classifiers,[0],[0]
Message-level analysis We examine how a message’s likelihood of being classified as non-English varies with its posterior probability of AA.,4.1 Evaluation of Existing Classifiers,[0],[0]
"As in §3.4, we split all messages into deciles based on the messages’ posterior probability of AA, and predicted language identifications on 200,000 sampled messages from each decile.
",4.1 Evaluation of Existing Classifiers,[0],[0]
"For all three systems, the proportion of messages classified as non-English increases steadily as the messages’ posterior probabilities of AA increase.",4.1 Evaluation of Existing Classifiers,[0],[0]
"As before, we sampled and annotated from the tweets classified as non-English, sampling 50 tweets from each decile for each of the three systems.",4.1 Evaluation of Existing Classifiers,[0],[0]
"Of the 1500 sampled tweets, only 13 (∼0.87%) could be unambiguously identified as being in a language other than English.",4.1 Evaluation of Existing Classifiers,[0],[0]
"Natural language processing tools can be improved to better support dialects; for example, Jørgensen et al. (2016) use domain adaptation methods to improve POS tagging on AAE corpora.",4.2 Adapting Language Identification for AAE,[0],[0]
"In this section, we contribute a fix to language identification to correctly identify AAE and other social media messages as English.",4.2 Adapting Language Identification for AAE,[0],[0]
"We observed that messages where our model infers a high probability of AAE, white-aligned, or “Hispanic”-aligned language almost always are written in English; therefore we construct a simple ensemble classifier by combining it with langid.py.
",4.2.1 Ensemble Classifier,[0],[0]
"For a new message ~w, we predict its demographic-language proportions θ̂ via posterior inference with our trained model, given a symmetric α prior over demographic-topic proportions (see appendix for details).",4.2.1 Ensemble Classifier,[0],[0]
"The ensemble classifier, given a message, is as follows:
• Calculate langid.py’s prediction ŷ. •",4.2.1 Ensemble Classifier,[0],[0]
"If ŷ is English, accept it as English.",4.2.1 Ensemble Classifier,[0],[0]
•,4.2.1 Ensemble Classifier,[0],[0]
"If ŷ is non-English, and at least one of the
message’s tokens are in demographic model’s vocabulary: Infer θ̂ and return English only if the combined AA, Hispanic, and white posterior probabilities are at least 0.9.",4.2.1 Ensemble Classifier,[0],[0]
"Otherwise return the non-English ŷ decision.
",4.2.1 Ensemble Classifier,[0],[0]
"Another way to view this method is that we are effectively training a system on an extended Twitterspecific English language corpus softly labeled by our system’s posterior inference; in this respect, it is related to efforts to collect new language-specific Twitter corpora (Bergsma et al., 2012) or minority language data from the web (Ghani et al., 2001).",4.2.1 Ensemble Classifier,[0],[0]
"Our analysis from §4.1 indicates that this method would correct erroneous false negatives for AAE
messages in the training set for the model.",4.2.2 Evaluation,[0],[0]
"We further confirm this by testing the classifier on a sample of 2.2 million geolocated tweets sent in the U.S. in 2014, which are not in the training set.
",4.2.2 Evaluation,[0],[0]
"In addition to performance on the entire sample, we examine our classifier’s performance on messages whose posterior probability of using AA- or white-associated terms was greater than 0.8 within the sample, which in this section we will call high AA and high white messages, respectively.",4.2.2 Evaluation,[0],[0]
"Our classifier’s precision is high across the board, at 100% across manually annotated samples of 200 messages from each sample.10 Since we are concerned about the system’s overall recall, we impute recall (Table 4) by assuming that all high AA and high white messages are indeed English.",4.2.2 Evaluation,[0],[0]
"Recall for langid.py alone is calculated by nN , where n is the number of messages predicted to be English by langid.py, and N is the total number of messages in the set.",4.2.2 Evaluation,[0],[0]
"(This is the complement of Table 3, except evaluated on the test set.)",4.2.2 Evaluation,[0],[0]
"We estimate the ensemble’s recall as n+mN , where m = (nflip)P (English | flip) is the expected number of correctly changed classifications (from non-English to English) by the ensemble and the second term is the precision (estimated as 1.0).",4.2.2 Evaluation,[0],[0]
"We observe the baseline system has considerable difference in recall between the groups which is solved by the ensemble.
",4.2.2 Evaluation,[0],[0]
We also apply the same calculation to the general set of all 2.2 million messages; the baseline classifies 88% as English.,4.2.2 Evaluation,[0],[0]
This is a less accurate approximation of recall since we have observed a substantial presence of non-English messages.,4.2.2 Evaluation,[0],[0]
"The ensemble classifies an additional 5.4% of the messages as English; since these are all (or nearly all) correct, this
10We annotated 600 messages as English, not English, or not applicable, from 200 sampled each from general, high AA, and high white messages.",4.2.2 Evaluation,[0],[0]
Ambiguous tweets which were too short (e.g. ”Gm”) or contained only named entities (e.g. ”Tennessee”) were excluded from the final calculations.,4.2.2 Evaluation,[0],[0]
"The resulting samples have 197/197, 198/198, and 200/200 correct English classifications, respectively.
reflects at least a 5.4% gain to recall.",4.2.2 Evaluation,[0],[0]
"Given the lexical and syntactic variation of AAE compared to SAE, we hypothesize that syntactic analysis tools also have differential accuracy.",5 Dependency Parser Evaluation,[0],[0]
"Jørgensen et al. (2015) demonstrate this for part-ofspeech tagging, finding that SAE-trained taggers had disparate accuracy on AAE versus non-AAE tweets.
",5 Dependency Parser Evaluation,[0],[0]
We assess a publicly available syntactic dependency parser on our AAE and white-aligned corpora.,5 Dependency Parser Evaluation,[0],[0]
"Syntactic parsing for tweets has received some research attention; Foster et al. (2011) create a corpus of constituent trees for English tweets, and Kong et al. (2014)’s Tweeboparser is trained on a Twitter corpus annotated with a customized unlabeled dependency formalism; since its data was uniformly sampled from tweets, we expect it may have low disparity between demographic groups.
",5 Dependency Parser Evaluation,[0],[0]
"We focus on widely used syntactic representations, testing the SyntaxNet neural network-based dependency parser (Andor et al., 2016),11 which reports state-of-the-art results, including for web corpora.",5 Dependency Parser Evaluation,[0],[0]
"We evaluate it against a new manual annotation of 200 messages, 100 randomly sampled from each of the AA- and white-aligned corpora described in §2.3.
",5 Dependency Parser Evaluation,[0],[0]
"SyntaxNet outputs grammatical relations conforming to the Stanford Dependencies (SD) system (de Marneffe and Manning, 2008), which we used to annotate messages using Brat,12 comparing to predicted parses for reference.",5 Dependency Parser Evaluation,[0],[0]
Message order was randomized and demographic inferences were hidden from the annotator.,5 Dependency Parser Evaluation,[0],[0]
"To increase statistical power relative to annotation effort, we developed a partial annotation approach to only annotate edges for the root word of the first major sentence in a message.",5 Dependency Parser Evaluation,[0],[0]
"Generally, we found that that SD worked well as a descriptive formalism for tweets’ syntax; we describe handling of AAE and Internet-specific non-standard issues in the appendix.",5 Dependency Parser Evaluation,[0],[0]
"We evaluate labeled recall of the annotated edges for each message set:
Parser AA Wh.",5 Dependency Parser Evaluation,[0],[0]
Difference SyntaxNet 64.0 (2.5) 80.4 (2.2) 16.3,5 Dependency Parser Evaluation,[0],[0]
"(3.4) CoreNLP 50.0 (2.7) 71.0 (2.5) 21.0 (3.7)
11Using the publicly available mcparseface model:",5 Dependency Parser Evaluation,[0],[0]
"https:// github.com/tensorflow/models/tree/master/syntaxnet
12http://brat.nlplab.org/
Bootstrapped standard errors (from 10,000 message resamplings) are in parentheses; differences are statistically significant (p < 10−6 in both cases).
",5 Dependency Parser Evaluation,[0],[0]
"The white-aligned accuracy rate of 80.4% is broadly in line with previous work (compare to the parser’s unlabeled accuracy of 89% on English Web Treebank full annotations), but parse quality is much worse on AAE tweets at 64.0%.",5 Dependency Parser Evaluation,[0],[0]
"We test the Stanford CoreNLP neural network dependency parser (Chen and Manning, 2014) using the english SD model that outputs this formalism;13 its disparity is worse.",5 Dependency Parser Evaluation,[0],[0]
Soni et al. (2014) used a similar parser14 on Twitter text; our analysis suggests this approach may suffer from errors caused by the parser.,5 Dependency Parser Evaluation,[0],[0]
We have presented a distantly supervised probabilistic model that employs demographic correlations of a dialect and its speaker communities to uncover dialectal language on Twitter.,6 Discussion and Conclusion,[0],[0]
"Our model can also close the gap between NLP tools’ performance on dialectal and standard text.
",6 Discussion and Conclusion,[0],[0]
"This represents a case study in dialect identification, characterization, and ultimately language technology adaptation for the dialect.",6 Discussion and Conclusion,[0],[0]
"In the case of AAE, dialect identification is greatly assisted since AAE speakers are strongly associated with a demographic group for which highly accurate governmental records (the U.S. Census) exist, which we leverage to help identify speaker communities.",6 Discussion and Conclusion,[0],[0]
"The notion of non-standard dialectal language implies that the dialect is underrepresented or underrecognized in some way, and thus should be inherently difficult to collect data on; and of course, many other language communities and groups are not necessarily officially recognized.",6 Discussion and Conclusion,[0],[0]
"An interesting direction for future research would be to combine distant supervision with unsupervised linguistic models to automatically uncover such underrecognized dialectal language.
",6 Discussion and Conclusion,[0],[0]
"Acknowledgments: We thank Jacob Eisenstein, Taylor Jones, Anna Jørgensen, Dirk Hovy, and the anonymous reviewers for discussion and feedback.
",6 Discussion and Conclusion,[0],[0]
"13pos,depparse options in version 2015-04-20, using tokenizations output by SyntaxNet.
",6 Discussion and Conclusion,[0],[0]
14The older Stanford englishPCFG model with dependency transform (via pers.,6 Discussion and Conclusion,[0],[0]
comm.).,6 Discussion and Conclusion,[0],[0]
"Though dialectal language is increasingly abundant on social media, few resources exist for developing NLP tools to handle such language.",abstractText,[0],[0]
We conduct a case study of dialectal language in online conversational text by investigating African-American English (AAE) on Twitter.,abstractText,[0],[0]
"We propose a distantly supervised model to identify AAE-like language from demographics associated with geo-located messages, and we verify that this language follows well-known AAE linguistic phenomena.",abstractText,[0],[0]
"In addition, we analyze the quality of existing language identification and dependency parsing tools on AAE-like text, demonstrating that they perform poorly on such text compared to text associated with white speakers.",abstractText,[0],[0]
We also provide an ensemble classifier for language identification which eliminates this disparity and release a new corpus of tweets containing AAE-like language.,abstractText,[0],[0]
Data and software resources are available at: http://slanglab.cs.umass.edu/TwitterAAE,abstractText,[0],[0]
Demographic Dialectal Variation in Social Media: A Case Study of African-American English,title,[0],[0]
"DBSCAN (Ester et al., 1996) is one of the most popular clustering algorithms amongst practitioners and has had profound success in a wide range of data analysis applications.",1. Introduction,[0],[0]
"However, despite this, its statistical properties have not been fully understood.",1. Introduction,[0],[0]
"The goal of this work is to give a theoretical analysis of the procedure and to the best of our knowledge, provide the first analysis of density levelset estimation on manifolds.",1. Introduction,[0],[0]
"We also contribute ideas to related areas that may be of independent interest.
",1. Introduction,[0],[0]
DBSCAN aims at discovering clusters which turn out to be the high-density regions of the dataset.,1. Introduction,[0],[0]
It takes in two hyperparameters: minPts and ε.,1. Introduction,[0],[0]
It defines a point as a core-point if there are at least minPts sample points in its εradius neighborhood.,1. Introduction,[0],[0]
The points within the ε-radius neighborhood of a core-point are said to be directly reachable from that core-point.,1. Introduction,[0],[0]
"Then, a point q is reachable from a core-point p if there exists a path from q to p where each point is directly reachable from the next point.",1. Introduction,[0],[0]
"It is now clear that this definition of reachable gives a partitioning of
1Google.",1. Introduction,[0],[0]
"Correspondence to: Heinrich Jiang <heinrich.jiang@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
the dataset (and remaining points not reachable from any core-point are considered noise).,1. Introduction,[0],[0]
"This partitioning is the clustering that is returned by DBSCAN.
",1. Introduction,[0],[0]
"The problem of analyzing DBSCAN has recently been explored in (Sriperumbudur & Steinwart, 2012).",1. Introduction,[0],[0]
Their analysis is for a modified version of DBSCAN and is not focused on estimating a fixed density level.,1. Introduction,[0],[0]
"Their results have many desirable properties, but are not immediately applicable for what this paper tries to address.",1. Introduction,[0],[0]
"Using recent developments in topological data analysis along with some tools we develop in this paper, we show that it is now possible to analyze the original procedure.
",1. Introduction,[0],[0]
The clusters DBSCAN aims at discovering can be viewed as approximations of the connected components of the level sets {x : f(x) ≥ λ} where f is the density and λ is some density level.,1. Introduction,[0],[0]
We provide the first comprehensive analysis in tuning minPts and ε to estimate the density level set for a particular level.,1. Introduction,[0],[0]
"Here, the density level λ is known to the algorithm while the density remains unknown.",1. Introduction,[0],[0]
Density level set estimation has been studied extensively.,1. Introduction,[0],[0]
"e.g., (Carmichael et al., 1968; Hartigan, 1975; Polonik, 1995; Cuevas & Fraiman, 1997; Walther, 1997; Tsybakov et al., 1997; Baıllo et al., 2001; Cadre, 2006; Willett & Nowak, 2007; Biau et al., 2008; Rigollet & Vert, 2009; Maier et al., 2009; Singh et al., 2009; Rinaldo & Wasserman, 2010; Steinwart, 2011; Rinaldo et al., 2012; Steinwart et al., 2015; Chen et al., 2016; Jiang, 2017).",1. Introduction,[0],[0]
However approaches that obtain state-of-art consistency results are largely unpractical (i.e. unimplementable).,1. Introduction,[0],[0]
"Our work shows that in actuality, DBSCAN, a procedure known for decades and has since been used widely, can achieve the strongest known results.",1. Introduction,[0],[0]
"Also, unlike much of the existing work, we show that DBSCAN can also recover the connected components of the level sets separately and bijectively.
",1. Introduction,[0],[0]
"Our work begins with the insight that DBSCAN behaves like an ε-neighborhood graph, which is different from, but related to the k-nearest neighbor graph.",1. Introduction,[0],[0]
"The latter has been heavily used for cluster-tree estimation (Chaudhuri & Dasgupta, 2010; Stuetzle & Nugent, 2010; Kpotufe & von Luxburg, 2011; Chaudhuri et al., 2014; Jiang & Kpotufe, 2017) and in this paper we adapt some of these ideas for ε-neighborhood graphs.
",1. Introduction,[0],[0]
Cluster-tree estimation aims at discovering the hierarchical tree structure of the connected-components as the levels vary.,1. Introduction,[0],[0]
Balakrishnan et al. (2013) extends results by Chaudhuri & Dasgupta (2010) to the setting where the data lies on a lower dimensional manifold and provide consistency results depending on the lower dimension and independent of the ambient dimension.,1. Introduction,[0],[0]
Here we are instead interested in how to set minPts and ε in order to estimate a particular level and provide rates on the Hausdorff distance error.,1. Introduction,[0],[0]
This is different from works on cluster tree estimation which focuses on how to recover the tree structure rather than recovering a particular level.,1. Introduction,[0],[0]
"In that regard, we also require density estimation bounds in order to get a handle on the true density-levels and the empirical ones.
",1. Introduction,[0],[0]
Dasgupta & Kpotufe (2014) gives us optimal highprobability finite-sample k-NN density estimation bounds which hold uniformly; this is key to obtaining optimal level-set estimation rates under the Hausdorff error.,1. Introduction,[0],[0]
"Much of the previous works on density level-set estimation, e.g. (Rigollet & Vert, 2009) provide rates under risk measures such as symmetric set difference.",1. Introduction,[0],[0]
These metrics are considerably weaker than the Hausdorff metric; the latter is a uniform guarantee.,1. Introduction,[0],[0]
There are such bounds for the histogram density estimator.,1. Introduction,[0],[0]
"This allowed Singh et al. (2009) to obtain optimal rates under Hausdorff metric, while having a fully adaptive procedure.",1. Introduction,[0],[0]
"This was a significant breakthrough for level set estimation, as discussed by Chazal et al. (2015).",1. Introduction,[0],[0]
We believe this to be the strongest consistency results obtained thus far.,1. Introduction,[0],[0]
"However, a downside is that the histogram density estimator has little practical value.",1. Introduction,[0],[0]
"Here, aided with the desired bounds on the k-NN density estimator, we can actually obtain similar results to Singh et al. (2009) but with the clearly practical DBSCAN.
",1. Introduction,[0],[0]
"We extend the k-NN density estimation results of Dasgupta & Kpotufe (2014) to the manifold case, as the bulk our analysis is about the more general case that the data lies on a manifold.",1. Introduction,[0],[0]
Density-based procedures perform poorly in high-dimensions since the number of samples required increases exponentially in the dimension– the so called curse of dimensionality.,1. Introduction,[0],[0]
"Thus, the consequences of handling the manifold case are of practical significance.",1. Introduction,[0],[0]
"Since the estimation rates we obtain depend only on the intrinsic dimension, it explains why DBSCAN can do well in high dimensions if the data has low intrinsic dimension (i.e. the manifold hypothesis).",1. Introduction,[0],[0]
"Given the modern capacity of systems to collect data of increasing complexity, it has become ever more important to understand the feasibility of practical algorithms in high dimensions.
",1. Introduction,[0],[0]
"To analyze DBSCAN, we write minPts and ε in terms of the d, unknown manfold dimension; k, which controls the density estimator; and λ, which determines which level to estimate.",1. Introduction,[0],[0]
"We assume knowledge of λ with the goal of es-
timating the λ-level set of the density.",1. Introduction,[0],[0]
We give a range of k in terms of n and corresponding consistency guarantees and estimation rates for such choices.,1. Introduction,[0],[0]
We then adaptively tune d and k in order to attain close to optimal performance with no a priori knowledge of the distribution.,1. Introduction,[0],[0]
"Adaptivity is highly desirable because it allows for automatic tuning of the hyper-parameters, which is a core tenet of unsupervised learning.",1. Introduction,[0],[0]
"To solve for the unknown dimension, we use an estimator from Farahmand et al. (2007), which we show to have considerably better finite-sample behavior than previously thought.",1. Introduction,[0],[0]
More details and discussion of related works is in the main text.,1. Introduction,[0],[0]
We then provide a new method of choosing k such that it will asymptotically approach a value that provides near-optimal level set estimation rates.,1. Introduction,[0],[0]
We start by analyzing the procedure under the manifold assumption.,2. Overview,[0],[0]
The end of the paper will discuss the fulldimensional setting.,2. Overview,[0],[0]
"The bulk of our contribution lies in analyzing the former situation, while the analysis of the latter uses a subset of those techniques.
",2. Overview,[0],[0]
• Section 3 proves that the clusters returned by DBSCAN are close to the connected components of certain ε-neighborhood graphs (Lemma 2).,2. Overview,[0],[0]
"This is significant because these graphs can be shown to estimate density level sets.
",2. Overview,[0],[0]
"• Section 4 introduces the manifold setting and provides supporting results including k-nearest neighbor density estimation bounds (Lemma 5 and Lemma 6) that are useful later on.
",2. Overview,[0],[0]
"• Section 5 provides a range of parameter settings under which for each true cluster, there exists a corresponding cluster returned by DBSCAN (Lemma 7 and Lemma 8), and a rate for the Hausdorff distance between them (Theorem 1).
",2. Overview,[0],[0]
"• Section 6 shows how one can apply DBSCAN a second time to remove false clusters from the first application, thus completing a bijection between the estimates and the true clusters (Theorem 2).
",2. Overview,[0],[0]
• Section 7 explains how to adaptively tune the parameters so that they fall within the theoretical ranges.,2. Overview,[0],[0]
"The main contributions of this section are a stronger result about a known k-nearest neighbor based approach to estimating the unknown dimension (Theorem 3) and a new way to tune k to approach an optimal choice of k (Theorem 4).
",2. Overview,[0],[0]
• Section 8 gives the result when the data lives in RD without the manifold assumption.,2. Overview,[0],[0]
This section is dedicated towards the understanding of the clusters produced by DBSCAN.,3. The connection to neighborhood graphs,[0],[0]
"The algorithm can be found in (Ester et al., 1996) and is not shown here since Lemma 1 characterizes what DBSCAN returns.
",3. The connection to neighborhood graphs,[0],[0]
We have n i.i.d.,3. The connection to neighborhood graphs,[0],[0]
"samples X = {x1, ..., xn} drawn from a distribution F over RD.",3. The connection to neighborhood graphs,[0],[0]
Definition 1.,3. The connection to neighborhood graphs,[0],[0]
"Define the k-NN radius of x ∈ RD as
rk(x) := inf{r > 0 :",3. The connection to neighborhood graphs,[0],[0]
"|X ∩B(x, r)| ≥ k},
where B(x, r) denotes the Euclidean ball of radius r centered at x. Let G(k, ε) denote the ε-neighborhood level graph of X with vertices {x ∈ X : rk(x) ≤ ε} and an edge between x and x′ iff ||x− x′|| ≤ ε.",3. The connection to neighborhood graphs,[0],[0]
Remark 1.,3. The connection to neighborhood graphs,[0],[0]
"This is slightly different from ε-neighborhood graph, which includes all vertices.",3. The connection to neighborhood graphs,[0],[0]
"Here we exclude vertices below certain empirical density level (i.e. rk(x) > ε).
",3. The connection to neighborhood graphs,[0],[0]
"The next definition is relevant to DBSCAN and is from (Ester et al., 1996) but in the notation of Definition 1.
Definition 2.",3. The connection to neighborhood graphs,[0],[0]
The following is with respect to fixed ε > 0,3. The connection to neighborhood graphs,[0],[0]
"and minPts ∈ N.
• p is a core-point if rminPts(p) ≤ ε.",3. The connection to neighborhood graphs,[0],[0]
"• q is directly density-reachable from p if |p − q| ≤ ε
and p is a core-point.
",3. The connection to neighborhood graphs,[0],[0]
"• q is density-reachable from p if there exists a sequence q = p1, p2, ..., pm = p such that pi is directly densityreachable from pi+1 for i = 1, ..,m− 1.
",3. The connection to neighborhood graphs,[0],[0]
"The following result is paraphrased from Lemmas 1 and 2 from (Ester et al., 1996), which characterizes the clusters learned by DBSCAN.
",3. The connection to neighborhood graphs,[0],[0]
Lemma 1.,3. The connection to neighborhood graphs,[0],[0]
"(Ester et al., 1996)",3. The connection to neighborhood graphs,[0],[0]
"Let C be the clusters returned by DBSCAN(minPts, ε).",3. The connection to neighborhood graphs,[0],[0]
"For any core-point x, there exists C ∈ C with x ∈ C. On the other hand, for any C ∈ C, there exists core-point x such that C = {x′ : x′ is density-reachable from x}.
",3. The connection to neighborhood graphs,[0],[0]
We now show the following result relating the εneighborhood level graphs and the clusters obtained from DBSCAN.,3. The connection to neighborhood graphs,[0],[0]
"Such an interpretation of DBSCAN has been given in previous works such as Campello et al. (2015).
",3. The connection to neighborhood graphs,[0],[0]
Lemma 2 (DBSCAN and ε-neighborhood level graphs).,3. The connection to neighborhood graphs,[0],[0]
"Let C be the clusters obtained from DBSCAN(minPts, ε) on X .",3. The connection to neighborhood graphs,[0],[0]
"Let K be the connected components of G(minPts, ε).",3. The connection to neighborhood graphs,[0],[0]
"Then, there exists a one-to-one correspence between C and K such that if C ∈ C and K ∈ K correspond, then
K ⊆ C ⊆ ∪x∈KB(x, ε) ∩X.
Proof.",3. The connection to neighborhood graphs,[0],[0]
"Take any K ∈ K. Each point in K is a core-point and by Lemma 1 and the definition of density-reachable, each point in K belongs to the same C ∈ C. Thus, K ⊆ {x ∈ C : rk(x) ≤ ε}.",3. The connection to neighborhood graphs,[0],[0]
"Next we show that K = {x ∈ C : rk(x) ≤ ε}.
",3. The connection to neighborhood graphs,[0],[0]
Suppose there exists core-point x ∈ C but x /∈,3. The connection to neighborhood graphs,[0],[0]
K and let y ∈ K.,3. The connection to neighborhood graphs,[0],[0]
"By Lemma 1, there exists core-point c ∈ C such that all points in C are directly reachable from c.",3. The connection to neighborhood graphs,[0],[0]
Then there exists a path of core-points from x to c with pairwise edges of length at most ε.,3. The connection to neighborhood graphs,[0],[0]
The same holds for c to y.,3. The connection to neighborhood graphs,[0],[0]
"Thus there exists such a path of core-points from x to y, which means that x, y are in the same CC of G(minPts, ε), contradicting the assumption",3. The connection to neighborhood graphs,[0],[0]
that x /∈ K and y ∈ K.,3. The connection to neighborhood graphs,[0],[0]
"Thus, in fact K = {x ∈ C : rk(x) ≤ ε}.",3. The connection to neighborhood graphs,[0],[0]
"The result now follows since C consists of points that are at most ε from its core-points.
",3. The connection to neighborhood graphs,[0],[0]
We can now see that DBSCAN’s clusterings can be viewed as the connected components (CCs) of an appropriate - neighborhood level graph.,3. The connection to neighborhood graphs,[0],[0]
"Using a neighborhood graph to approximate the level-set has been studied in (Rinaldo & Wasserman, 2010).",3. The connection to neighborhood graphs,[0],[0]
The difference is that they use a kernel density estimator instead of a k-NN density estimator and study the convergence properties under different settings.,3. The connection to neighborhood graphs,[0],[0]
"We make the following regularity assumptions which are standard among works on manifold learning e.g. (Baraniuk & Wakin, 2009; Genovese et al., 2012; Balakrishnan et al., 2013).
",4.1. Setup,[0],[0]
Assumption 1.,4.1. Setup,[0],[0]
"F is supported on M where: • M is a d-dimensional smooth compact Riemannian
manifold without boundary embedded in compact subset X ⊆ RD.
•",4.1. Setup,[0],[0]
The volume of M is bounded above by a constant.,4.1. Setup,[0],[0]
"• M has condition number 1/τ , which controls the cur-
vature and prevents self-intersection.
",4.1. Setup,[0],[0]
"Let f be the density of F with respect to the uniform measure on M .
",4.1. Setup,[0],[0]
Assumption 2.,4.1. Setup,[0],[0]
f is continuous and bounded.,4.1. Setup,[0],[0]
The following result bounds the empirical mass of Euclidean balls to the true mass under f .,4.2. Basic Supporting Bounds,[0],[0]
"It is a direct consequence of Lemma 6 of Balakrishnan et al. (2013).
",4.2. Basic Supporting Bounds,[0],[0]
Lemma 3 (Uniform convergence of empirical Euclidean balls (Lemma 6 of Balakrishnan et al. (2013))).,4.2. Basic Supporting Bounds,[0],[0]
Let N be a minimal fixed set such that each point inM is at most distance 1/n from some point in N .,4.2. Basic Supporting Bounds,[0],[0]
"There exists a universal
constant C0 such that the following holds with probability at least 1− δ.",4.2. Basic Supporting Bounds,[0],[0]
"For all x ∈ X ∪N ,
F(B) ≥",4.2. Basic Supporting Bounds,[0],[0]
"Cδ,n √ d log n
n ⇒ Fn(B) > 0
F(B)",4.2. Basic Supporting Bounds,[0],[0]
≥ k n,4.2. Basic Supporting Bounds,[0],[0]
+,4.2. Basic Supporting Bounds,[0],[0]
"Cδ,n
√ k
n ⇒ Fn(B) ≥
k
n
F(B) ≤",4.2. Basic Supporting Bounds,[0],[0]
k n,4.2. Basic Supporting Bounds,[0],[0]
"− Cδ,n
√ k
n ⇒ Fn(B) <
k n .
",4.2. Basic Supporting Bounds,[0],[0]
"where Cδ,n = C0 log(2/δ)",4.2. Basic Supporting Bounds,[0],[0]
"√ d log n,",4.2. Basic Supporting Bounds,[0],[0]
"Fn is the empirical distribution, and",4.2. Basic Supporting Bounds,[0],[0]
"k ≥ Cδ,n. Remark 2.",4.2. Basic Supporting Bounds,[0],[0]
"For the rest of the paper, many results are qualified to hold with probability at least 1−δ.",4.2. Basic Supporting Bounds,[0],[0]
"This is precisely the event in which Lemma 3 holds.
",4.2. Basic Supporting Bounds,[0],[0]
Remark 3.,4.2. Basic Supporting Bounds,[0],[0]
"If δ = 1/n, then Cδ,n = O((log n)3/2).
",4.2. Basic Supporting Bounds,[0],[0]
"Next, we need the following bound on the volume of the intersection Euclidean ball and M ; this is required to get a handle on the true mass of the ball under F in later arguments.",4.2. Basic Supporting Bounds,[0],[0]
The upper and lower bounds follow from Chazal (2013) and Lemma 5.3 of Niyogi et al. (2008).,4.2. Basic Supporting Bounds,[0],[0]
"The proof is given in the appendix.
",4.2. Basic Supporting Bounds,[0],[0]
Lemma 4 (Ball Volume).,4.2. Basic Supporting Bounds,[0],[0]
"If 0 < r < min{τ/4d, 1/τ}, and x ∈M then
vdr d(1− τ2r2) ≤ vold(B(x, r) ∩M) ≤",4.2. Basic Supporting Bounds,[0],[0]
"vdrd(1 + 4dr/τ).
where vd is the volume of a unit ball in Rd and vold is the volume w.r.t.",4.2. Basic Supporting Bounds,[0],[0]
"the uniform measure on M .
4.3.",4.2. Basic Supporting Bounds,[0],[0]
"k-NN Density Estimation
Here, we establish density estimation rates for the k-NN density estimator in the manifold setting.",4.2. Basic Supporting Bounds,[0],[0]
"This builds on work in density estimation on manifolds e.g. (Hendriks, 1990; Pelletier, 2005; Ozakin & Gray, 2009; Kim & Park, 2013; Berry & Sauer, 2017); thus, it may be of independent interest.",4.2. Basic Supporting Bounds,[0],[0]
"The estimator is defined as follows
Definition 3 (k-NN Density Estimator).
fk(x) := k
n · vd · rk(x)d .
",4.2. Basic Supporting Bounds,[0],[0]
The following extends previous work of Dasgupta & Kpotufe (2014) to the manifold case.,4.2. Basic Supporting Bounds,[0],[0]
"The proofs can be found in the appendix.
",4.2. Basic Supporting Bounds,[0],[0]
Lemma 5 (fk upper bound).,4.2. Basic Supporting Bounds,[0],[0]
Suppose that Assumptions 1 and 2 hold.,4.2. Basic Supporting Bounds,[0],[0]
"Define the following which charaterizes how much the density increases locally in M :
r̂( , x) := sup { r : sup
x′∈B(x,r)∩M f(x′)− f(x) ≤
} .
",4.2. Basic Supporting Bounds,[0],[0]
Fix λ0 > 0,4.2. Basic Supporting Bounds,[0],[0]
and δ > 0,4.2. Basic Supporting Bounds,[0],[0]
"and suppose that k ≥ C2δ,n.",4.2. Basic Supporting Bounds,[0],[0]
"Then there exists constant C1 ≡ C1(λ0, d, τ) such that if
k ≤ C1 · C2d/(2+d)δ,n · n 2/(2+d),
then the following holds with probability at least 1− δ uniformly in > 0 and x ∈ X with f(x) + ≥ λ0:
fk(x) <
( 1 + 3 · Cδ,n√
k
) · (f(x) + ),
provided k satisfies vd · r̂( , x)d ·(f(x)+ ) ≥ kn−Cδ,n",4.2. Basic Supporting Bounds,[0],[0]
√ k n .,4.2. Basic Supporting Bounds,[0],[0]
Lemma 6 (fk lower bound).,4.2. Basic Supporting Bounds,[0],[0]
Suppose that Assumptions 1 and 2 hold.,4.2. Basic Supporting Bounds,[0],[0]
"Define the following which charaterizes how much the density decreases locally in M :
ř( , x) := sup { r : sup
x′∈B(x,r)∩M f(x)− f(x′) ≤
} .
",4.2. Basic Supporting Bounds,[0],[0]
Fix λ0 > 0 and 0,4.2. Basic Supporting Bounds,[0],[0]
< δ < 1 and suppose k ≥,4.2. Basic Supporting Bounds,[0],[0]
"Cδ,n.",4.2. Basic Supporting Bounds,[0],[0]
"Then there exists constant C2 ≡ C2(λ0, d, τ) such that if
k ≤ C2 · C2d/(4+d)δ,n · n 4/(4+d),
then with probability at least 1 − δ, the following holds uniformly for all > 0 and x ∈ X with f(x)− ≥ λ0:
fk(x) ≥ (
1− 3 · Cδ,n√ k
) · (f(x)− ),
provided k satisfies vd · ř( , x)d · (f(x) − )",4.2. Basic Supporting Bounds,[0],[0]
"≥ 4 3 ( k n + Cδ,n √ k n ) .
",4.2. Basic Supporting Bounds,[0],[0]
Remark 4.,4.2. Basic Supporting Bounds,[0],[0]
We will often bound the density of points with low density.,4.2. Basic Supporting Bounds,[0],[0]
"In low-density regions, there is less data and thus we require more points to get a tight bound.",4.2. Basic Supporting Bounds,[0],[0]
"However, in many cases a tight bound is not necessary; thus the purposes of is to allow some slack.",4.2. Basic Supporting Bounds,[0],[0]
"The higher the , the easier it is for the lemma conditions to be satisified.",4.2. Basic Supporting Bounds,[0],[0]
"In particular, if f is α-Hölder continuous (i.e. |f(x)",4.2. Basic Supporting Bounds,[0],[0]
"− f(x′)| ≤ Cα|x− x′|α), we have r̂( , x), ř( , x) ≥ ( /Cα)1/α.",4.2. Basic Supporting Bounds,[0],[0]
Much of the results will depend on the behavior of level set boundaries.,5.1. Level-Set Conditions,[0],[0]
"Thus, we require sufficient drop-off at the boundaries, as well as separation between the CCs at a particular level set.",5.1. Level-Set Conditions,[0],[0]
We give the following notion of separation.,5.1. Level-Set Conditions,[0],[0]
Definition 4.,5.1. Level-Set Conditions,[0],[0]
"A,A′ are r-separated in M if there exists a set S such that every path from A to A′ intersects S and supx∈M∩(S+B(0,r)) f(x) < infx∈A∪A′ f(x).
",5.1. Level-Set Conditions,[0],[0]
"Define the following shorthands for distance from a point to a set, the intersection of M with a neighborhood around a set under the Euclidean distance, and the largest Euclidean distance from a point in a set to its closest sample point.
",5.1. Level-Set Conditions,[0],[0]
Definition 5.,5.1. Level-Set Conditions,[0],[0]
"d(x,A) := infx′∈A |x − x′|, C⊕r",5.1. Level-Set Conditions,[0],[0]
:,5.1. Level-Set Conditions,[0],[0]
"= {x ∈ M : d(x,C) ≤ r}, rn(C)",5.1. Level-Set Conditions,[0],[0]
":= supc∈C d(c,X).
",5.1. Level-Set Conditions,[0],[0]
"We have the following mild assumptions which ensures that the CCs can be separated from the rest of the density by sufficiently wide valleys and there is sufficient decay around the level set boundaries.
",5.1. Level-Set Conditions,[0],[0]
Assumption 3 (Separation Conditions).,5.1. Level-Set Conditions,[0],[0]
Let λ > 0,5.1. Level-Set Conditions,[0],[0]
and Cλ be a CCs of {x ∈ M : f(x) ≥ λ}.,5.1. Level-Set Conditions,[0],[0]
"There exists Čβ , Ĉβ , β, rs, rc > 0 and 0 <",5.1. Level-Set Conditions,[0],[0]
"λ0 < λ such that the following holds:
For each C ∈ Cλ, there exists AC , a connected component of Mλ0 := {x ∈M : f(x) ≥ λ0} such that:
• AC separates C by a valley: AC does not intersect with any other CC in Cλ; AC and Mλ0\AC are rsseparated by some SC .
",5.1. Level-Set Conditions,[0],[0]
"• C⊕rc ⊆ AC .
",5.1. Level-Set Conditions,[0],[0]
"• β-regularity: For x ∈ C⊕rc\C, we have
Čβ · d(x,C)β ≤",5.1. Level-Set Conditions,[0],[0]
λ− f(x) ≤,5.1. Level-Set Conditions,[0],[0]
"Ĉβ · d(x,C)β .
",5.1. Level-Set Conditions,[0],[0]
Remark 5.,5.1. Level-Set Conditions,[0],[0]
We can choose any 0 <,5.1. Level-Set Conditions,[0],[0]
β,5.1. Level-Set Conditions,[0],[0]
<,5.1. Level-Set Conditions,[0],[0]
∞.,5.1. Level-Set Conditions,[0],[0]
"The βregularity assumption appears in e.g. (Singh et al., 2009).",5.1. Level-Set Conditions,[0],[0]
"This is very general and also allows us to make a separate global smoothness assumption.
",5.1. Level-Set Conditions,[0],[0]
Remark 6.,5.1. Level-Set Conditions,[0],[0]
We currently characterize the smoothness w.r.t.,5.1. Level-Set Conditions,[0],[0]
the Euclidean distance.,5.1. Level-Set Conditions,[0],[0]
"One could alternatively use the geodesic distance on M , dM (p, q).",5.1. Level-Set Conditions,[0],[0]
"It follows from Proposition 6.3 of Niyogi et al. (2008) that when |p − q| < τ/4, we have |p − q| ≤ dM (p, q) ≤ 2|p − q|.",5.1. Level-Set Conditions,[0],[0]
"Since the distances we deal in our analysis with are of such small order, these distances can thus essentially be treated as equivalent.",5.1. Level-Set Conditions,[0],[0]
"We use the Euclidean distance throughout the paper for simplicity.
",5.1. Level-Set Conditions,[0],[0]
Remark 7.,5.1. Level-Set Conditions,[0],[0]
"For the rest of this paper, it will be understood that Assumptions 1, 2, and 3 hold.
",5.1. Level-Set Conditions,[0],[0]
We can define a region which isolates C away from other clusters of {x ∈M : f(x) ≥ λ}.,5.1. Level-Set Conditions,[0],[0]
Definition 6.,5.1. Level-Set Conditions,[0],[0]
XC := {x : ∃ a path P from x to x′ ∈ C such that P ∩ SC = ∅}.,5.1. Level-Set Conditions,[0],[0]
Fix λ > 0 and δ > 0.,5.2. Parameter Settings,[0],[0]
"Let k satisfy the following
Kl · (log n)2 ≤",5.2. Parameter Settings,[0],[0]
k ≤,5.2. Parameter Settings,[0],[0]
"Ku · (log n)2d/(2+d) · n2β ′/(2β′+d),
where β′",5.2. Parameter Settings,[0],[0]
":= min{1, β}, and Kl and Ku are positive constants depending on δ, Čβ , Ĉβ , β, τ, d, ||f ||∞, λ0, rs, rc which are implicit in the proofs later in this section.
",5.2. Parameter Settings,[0],[0]
"The remainder of this section will be to show that DBSCAN(minPts, ε) with
minPts = k, ε =
( k
n · vd · (λ− λ · C2δ,n/ √ k) )",5.2. Parameter Settings,[0],[0]
1/d will consistently estimate each CC of {x ∈ M : f(x) ≥ λ}.,5.2. Parameter Settings,[0],[0]
"Throughout the text, we denote Ĉλ as the clusters returned by DBSCAN under this setting.",5.2. Parameter Settings,[0],[0]
Take C ∈ Cλ.,5.3. Separation and Connectedness,[0],[0]
"We show that DBSCAN will return an estimated CC Ĉ, such that Ĉ does not contain any points outside of XC .",5.3. Separation and Connectedness,[0],[0]
"Then, we show that Ĉ contains all the sample points inC.",5.3. Separation and Connectedness,[0],[0]
The proof ideas used are similar to that of standard results in cluster trees estimation; they can be found in the appendix.,5.3. Separation and Connectedness,[0],[0]
Lemma 7 (Separation).,5.3. Separation and Connectedness,[0],[0]
There exists Kl sufficiently large andKu sufficiently small such that the following holds with probability at least 1− δ.,5.3. Separation and Connectedness,[0],[0]
Let C ∈ Cλ.,5.3. Separation and Connectedness,[0],[0]
There exists Ĉ ∈ Ĉλ such that Ĉ ⊆ XC .,5.3. Separation and Connectedness,[0],[0]
Lemma 8 (Connectedness).,5.3. Separation and Connectedness,[0],[0]
There exists Kl sufficiently large and Ku sufficiently small such that the following holds with probability at least 1 − δ.,5.3. Separation and Connectedness,[0],[0]
Let C ∈ Cλ.,5.3. Separation and Connectedness,[0],[0]
If there exists Ĉ ∈ Ĉλ such that Ĉ ⊆,5.3. Separation and Connectedness,[0],[0]
"XC , then C⊕rn(C) ∩X",5.3. Separation and Connectedness,[0],[0]
⊆ Ĉ.,5.3. Separation and Connectedness,[0],[0]
Remark 8.,5.3. Separation and Connectedness,[0],[0]
"These results allow C to have any dimension between 0 to d since we reason with C⊕rn(C), which contains samples, instead of simply C.",5.3. Separation and Connectedness,[0],[0]
We give the estimation rate under the Hausdorff metric.,5.4. Hausdorff Error,[0],[0]
"Definition 7 (Hausdorff Distance).
",5.4. Hausdorff Error,[0],[0]
"dHaus(A,A ′) =",5.4. Hausdorff Error,[0],[0]
"max{sup x∈A d(x,A′), sup x′∈A′ d(x′, A)}.
",5.4. Hausdorff Error,[0],[0]
Theorem 1.,5.4. Hausdorff Error,[0],[0]
There existsKl sufficiently large andKu sufficiently small such that the following holds with probability at least 1 − δ.,5.4. Hausdorff Error,[0],[0]
"For each C ∈ Cλ, there exists Ĉ ∈ Ĉλ such that
dHaus(C, Ĉ) ≤ 2 · (4λ/Čβ)1/β · C2/βδ,n · k −1/2β .
",5.4. Hausdorff Error,[0],[0]
Proof.,5.4. Hausdorff Error,[0],[0]
"For Kl and Ku appropriately chosen, we have Lemma 7 and Lemma 8 hold.",5.4. Hausdorff Error,[0],[0]
"Thus we have for C ∈ Cλ, there exists Ĉ ∈ Ĉλ such that
C⊕rn(C) ∩X",5.4. Hausdorff Error,[0],[0]
"⊆ Ĉ ⊆ ⋃
x∈XC∩X
fk(x)≥λ− C2δ,n√ k λ
B(x, ε) ∩M.
Define r̄ := (
4λ·C2δ,n Čβ · √ k
)1/β .",5.4. Hausdorff Error,[0],[0]
"We show that dHaus(C, Ĉ) ≤",5.4. Hausdorff Error,[0],[0]
"r̄,
which involves two directions to show from the Hausdroff
metric: that maxx∈Ĉ d(x,C) ≤",5.4. Hausdorff Error,[0],[0]
"r̄ and supx∈C d(x, Ĉ) ≤",5.4. Hausdorff Error,[0],[0]
"r̄.
We start by proving maxx∈Ĉ d(x,C) ≤ r̄.",5.4. Hausdorff Error,[0],[0]
Define r0 = r̄/2.,5.4. Hausdorff Error,[0],[0]
"We have
r0 = 1
2 ( 4 · C2δ,n Čβ · √ k )1/β ≥",5.4. Hausdorff Error,[0],[0]
"( k vdnλ0 )1/d ≥ ε,
where the first inequality holds when Ku is chosen sufficiently small, and the last inequality holds because λ0 < λ",5.4. Hausdorff Error,[0],[0]
"− C 2 δ,n√ k λ.",5.4. Hausdorff Error,[0],[0]
Hence r0 + ε ≤ r̄.,5.4. Hausdorff Error,[0],[0]
"Therefore, it suffices to show
sup x∈(XC\C⊕r0 )∩X fk(x)",5.4. Hausdorff Error,[0],[0]
"< λ− C2δ,n√ k λ.
",5.4. Hausdorff Error,[0],[0]
"We have that for x ∈ (XC\C⊕r0/2) ∩ X , f(x) ≤ λ",5.4. Hausdorff Error,[0],[0]
"− Čβ(r0/2)
",5.4. Hausdorff Error,[0],[0]
β :,5.4. Hausdorff Error,[0],[0]
"= λ′. Thus, for any x ∈ (XC\C⊕r0) ∩X and letting = λ′ − f(x), we have
r̂( , x) ≥ r0/2 ≥ (4λ0Cδ,n/( √ k · Čβ))1/β/2.
",5.4. Hausdorff Error,[0],[0]
"For Ku chosen sufficiently small, the last equation will be large enough (i.e. of order (k/vdnλ)1/d) so that the conditions of Lemma 5 hold.",5.4. Hausdorff Error,[0],[0]
"Thus, applying this for each x ∈ (XC\C⊕r0) ∩X , we obtain
sup x∈(XC\C⊕r0 )∩X fk(x)",5.4. Hausdorff Error,[0],[0]
"<
( 1 + 3
Cδ,n√ k
) (λ− Čβ(r0/2)β).
",5.4. Hausdorff Error,[0],[0]
"We have the r.h.s. is at most λ − C 2 δ,n√ k λ for Ku chosen appropriately and the first direction follows.
",5.4. Hausdorff Error,[0],[0]
"We now turn to the other direction, that supx∈C d(x, Ĉ) ≤ r̄.",5.4. Hausdorff Error,[0],[0]
Let x ∈,5.4. Hausdorff Error,[0],[0]
C.,5.4. Hausdorff Error,[0],[0]
"Then there exists sample point x′ ∈ B(x, rn(C)) by definition of rn and we have that x′ ∈ Ĉ.",5.4. Hausdorff Error,[0],[0]
"Finally, rn(C) ≤ r̄ for Kl sufficiently large, and thus |x′",5.4. Hausdorff Error,[0],[0]
− x| ≤ r̄.,5.4. Hausdorff Error,[0],[0]
"The result follows.
",5.4. Hausdorff Error,[0],[0]
Remark 9.,5.4. Hausdorff Error,[0],[0]
"When taking k ≈ n2β′/(2β′+d), we obtain the error rate of dHaus(C, Ĉ)",5.4. Hausdorff Error,[0],[0]
"≈ n−1/(2β+d·max{1,β}), ignoring logarithmic factors.",5.4. Hausdorff Error,[0],[0]
"When 0 < β ≤ 1, this matches the known lower bound established in Theorem 4 of Tsybakov et al. (1997).",5.4. Hausdorff Error,[0],[0]
"However, we do not obtain this rate when β > 1.",5.4. Hausdorff Error,[0],[0]
"In this case, the density estimation error will be of order at least n−1/(2+d) due in part to the error from resolving the geodesic balls with Euclidean balls.",5.4. Hausdorff Error,[0],[0]
"This does not arise in the full dimensional setting, which will be described later.",5.4. Hausdorff Error,[0],[0]
"The result of Theorem 1 guarantees us that for each C ∈ Cλ, there exists Ĉ ∈ Ĉλ that estimates it.",6. Removal of False Clusters,[0],[0]
"In this section, we
show how a second application of DBSCAN (Algorithm 1) can remove the false clusters discovered by the first application of DBSCAN with no additional parameters.",6. Removal of False Clusters,[0],[0]
"This gives us the other direction, that each estimate in Ĉλ corresponds to a true CC in Cλ, and thus DBSCAN can identify with a one-to-one correspondence each CC of the level-set.
",6. Removal of False Clusters,[0],[0]
Algorithm 1 DBSCAN False CC Removal,6. Removal of False Clusters,[0],[0]
"As in Section 5.2, let minPts = k and
ε =
( k
n·vd·(λ−λ·C2δ,n/ √ k)
)1/d .
",6. Removal of False Clusters,[0],[0]
"Define ε̃ := (
k
n·vd·(λ−λ·C2δ,n/ 3√ k)
)1/d .
",6. Removal of False Clusters,[0],[0]
"Let Ĉλ be the clusters returned by DBSCAN(minPts, ε).",6. Removal of False Clusters,[0],[0]
"Let D̂λ be the clusters returned by DBSCAN(minPts, ε̃).",6. Removal of False Clusters,[0],[0]
Let C̃λ be the clusters obtained by merging clusters from Ĉλ which are subsets of the same cluster in D̂λ .,6. Removal of False Clusters,[0],[0]
"Return C̃λ.
",6. Removal of False Clusters,[0],[0]
We state our result below.,6. Removal of False Clusters,[0],[0]
"The proof is less involved and is in the appendix.
",6. Removal of False Clusters,[0],[0]
Theorem 2 (Removal of False CC Estimates).,6. Removal of False Clusters,[0],[0]
"Define γ = λ− supx∈M\(∪C∈CλXC) f(x), which is positive.",6. Removal of False Clusters,[0],[0]
There exists Kl sufficiently large and Ku sufficiently small depending on γ in addition to the constants mentioned in Section 5.2 so that the following holds with probability at least 1− δ.,6. Removal of False Clusters,[0],[0]
"For all Ĉ ∈ C̃λ, there exists C ∈",6. Removal of False Clusters,[0],[0]
"Cλ such that
dHaus(C, Ĉ) ≤ 2 · (4λ/Čβ)1/β · C2/βδ,n · k −1/2β .",6. Removal of False Clusters,[0],[0]
"In this section, we show how to obtain the near optimal rates by estimating d and adaptively choosing k such that k ≈ n2β′/(2β′+d) without knowledge of β.",7. Adaptive Parameter Tuning,[0],[0]
Knowing the manifold dimension d is necessary to tune the parameters as described in Section 5.2.,7.1. Determining d,[0],[0]
There has been much work done on estimating the intrinsic dimension as many learning procedures (including this one) require d as an input.,7.1. Determining d,[0],[0]
"Such work in intrinsic dimension estimation include (Kegl, 2002; Levina & Bickel, 2004; Hein & Audibert, 2005).",7.1. Determining d,[0],[0]
Pettis et al. (1979) and more recently Farahmand et al. (2007) take a k-nearest neighbor approach.,7.1. Determining d,[0],[0]
"We work with the estimate of a dimension at a point proposed in the latter work:
d̂(x) = log 2
log(r2k(x)/rk(x)) .
",7.1. Determining d,[0],[0]
The main result of Farahmand et al. (2007) gives a highprobability bound for a single sample X1 ∈ X .,7.1. Determining d,[0],[0]
"Here we
give a high-probability bound under more mild smoothness assumptions which hold uniformly for all samples above some density-level given our new knowledge of k-NN density estimation rates.",7.1. Determining d,[0],[0]
This may be of independent interest.,7.1. Determining d,[0],[0]
Theorem 3.,7.1. Determining d,[0],[0]
Suppose that f is α-Hölder continuous for some 0,7.1. Determining d,[0],[0]
< α ≤ 1.,7.1. Determining d,[0],[0]
Choose λ̄0 > 0,7.1. Determining d,[0],[0]
and δ > 0.,7.1. Determining d,[0],[0]
"Then there exists constants C1, C2 depending on δ, Cα, α, τ, d, λ̄0 such that if k satisfies
C1 · (log n)2 ≤ k ≤ C2 · n2α/(2α+d),
then with probability at least 1− δ,
|d̂(x)− d| ≤ 20d · ||f ||∞ · Cδ,n√ k ,
uniformly for all x ∈ X with fk(x) ≥ λ̄0.
Proof.",7.1. Determining d,[0],[0]
"We have for x ∈ X such that if fk(x) ≥ λ̄0, then f(x) ≥ λ0 := λ̄0/2 by Lemma 5 for C1 chosen appropriately large and C2 chosen appropriately small.
d̂(x) = log 2
log(r2k(x)/rk(x))",7.1. Determining d,[0],[0]
"=
d log 2
log 2 + log(fk(x)/f2k(x)) .
",7.1. Determining d,[0],[0]
We now try to get a handle on fk(x)/f2k(x) and show it is sufficiently close to 1.,7.1. Determining d,[0],[0]
"Applying Lemma 5 and 6 with =
Cδ,n√ k f(x) and C1, C2 appropriately chosen so that the conditions for the two Lemmas hold (remember that here we have r̂( , x), ř( , x) ≥ ( /Cα)1/α), we obtain
fk(x) f2k(x)",7.1. Determining d,[0],[0]
"≥ (1− 3Cδ,n/
√ k)(1− Cδ,n/ √ k) · f(x)
(1 + 3Cδ,n/ √ k)(1 +",7.1. Determining d,[0],[0]
"Cδ,n/ √ k) · f(x)
≥ 1− 9 · Cδ,n√ k ,
where the last inequality holds when C1 is chosen sufficiently large so that Cδ,n/",7.1. Determining d,[0],[0]
√ k is sufficiently small.,7.1. Determining d,[0],[0]
"On the other hand, we similarly obtain (for C1 and C2 appropriately chosen):
fk(x) f2k(x) ≤",7.1. Determining d,[0],[0]
"(1 + 3Cδ,n/
√ k)(1 +",7.1. Determining d,[0],[0]
"Cδ,n/ √ k) · f(x)
(1− 3Cδ,n/",7.1. Determining d,[0],[0]
"√ k)(1− Cδ,n/ √ k) · f(x)
≤ 1 + 9 · Cδ,n√ k .
",7.1. Determining d,[0],[0]
It is now clear that by the expansion log(1,7.1. Determining d,[0],[0]
− r) = −r,7.1. Determining d,[0],[0]
"− r2/2 − r3/3 − · · · , and for Kl chosen sufficently large so that Cδ,n/
√ k is sufficiently small, we have∣∣∣∣log( fk(x)f2k(x) )",7.1. Determining d,[0],[0]
"∣∣∣∣ ≤ 10 · Cδ,n√k .",7.1. Determining d,[0],[0]
"The result now follows by combining this with the earlier established expression for d̂(x), as desired.
",7.1. Determining d,[0],[0]
Remark 10.,7.1. Determining d,[0],[0]
"In Farahmand et al. (2007), it is the case that α = 1; under this setting, we match their bound with an error rate of n1/(2+d) with k",7.1. Determining d,[0],[0]
≈ n2/(2+d) being the optimal choice for k (ignoring log factors).,7.1. Determining d,[0],[0]
"After determining d, the next parameter we look at is k.",7.2. Determining k,[0],[0]
"In particular, to obtain the optimal rate, we must choose k ≈ n2β′/(2β′+d) without knowledge of β.",7.2. Determining k,[0],[0]
"We present a consistent estimator for β.
",7.2. Determining k,[0],[0]
We need the following definition.,7.2. Determining k,[0],[0]
The first characterizes how much f varies in balls of a certain radius along the boundaries of the λ-level set (where ∂Cλ denotes the boundary of Cλ).,7.2. Determining k,[0],[0]
"The second is meant to be an estimate of the first, which can be computed from the data alone.",7.2. Determining k,[0],[0]
"The final is our estimate of β.
",7.2. Determining k,[0],[0]
"Dr = inf x0∈∂Cλ sup x∈B(x0,r)
|λ−",7.2. Determining k,[0],[0]
"f(x)|
D̂r,k = min x0∈X
B(x0,r)∩X 6=∅
max x∈B(x0,r)∩X
|λ− fk(x)|
β̂ = logr(D̂r,k)
",7.2. Determining k,[0],[0]
"The next is a result of how D̂r,k estimates Dr. Lemma 9.",7.2. Determining k,[0],[0]
Suppose that f is α-Hölder continuous for some 0,7.2. Determining k,[0],[0]
< α ≤ 1.,7.2. Determining k,[0],[0]
Let k = b(log n)5c and r = 1/ √ log n.,7.2. Determining k,[0],[0]
Then there exists positive constants C̃,7.2. Determining k,[0],[0]
"andN depending on d, τ, α, Cα, λ0, ||f ||∞, rc such that when n ≥ N , then the following holds with probability at least 1− 1/n.
|Dr − D̂r,k| ≤ C̃/(log n)2.
",7.2. Determining k,[0],[0]
Proof sketch.,7.2. Determining k,[0],[0]
"Suppose that the value of Dr is attained at x0 = p and the value of D̂r,k is attained at x0 = q. Let y, z be the points that maximize |λ−",7.2. Determining k,[0],[0]
"f(x)| on B(p, r) and B(q, r), respectively.",7.2. Determining k,[0],[0]
"Let ŷ, ẑ",7.2. Determining k,[0],[0]
"be the sample points that maximize |λ−fk(x)| on B(p, r) and B(q, r), respectively.",7.2. Determining k,[0],[0]
"Now, we have
Dr − D̂r,k = |λ− f(y)|",7.2. Determining k,[0],[0]
− |λ− fk(ẑ)| ≤ |λ− f(z)|,7.2. Determining k,[0],[0]
"− |λ− fk(ẑ)| ≤ |f(z)− fk(ẑ)| ≤ max{f(z)− fk(z), fk(ẑ)− f(ẑ)}.
",7.2. Determining k,[0],[0]
"Now let z′ be the closest sample point to z inB(q, r).",7.2. Determining k,[0],[0]
"Then,
≤ max{f(z′)− fk(z′), fk(ẑ)− f(ẑ)}+ |f(z)− f(z′)| + |fk(z)− fk(z′)| ≤",7.2. Determining k,[0],[0]
"max
x∈X,f(x)≥λ0 |f(x)− fk(x)|
+ Cα|z",7.2. Determining k,[0],[0]
"− z′|α + |fk(z)− fk(z′)|.
",7.2. Determining k,[0],[0]
"On the other hand, we have D̂r,k −Dr = |λ− fk(ẑ)|",7.2. Determining k,[0],[0]
− |λ− f(y)| ≤ |λ− fk(ŷ)|,7.2. Determining k,[0],[0]
"− |λ− f(y)| ≤ |f(y)− fk(ŷ)| ≤ max{f(y)− fk(y), fk(ŷ)− f(ŷ)}.
",7.2. Determining k,[0],[0]
"Let y′ be the closest sample point to y in B(p, r).",7.2. Determining k,[0],[0]
"Then, ≤ max{f(y′)− fk(y′), fk(ŷ)− f(ŷ)}+ |f(y)− f(y′)| + |fk(y)− fk(y′)| ≤ max
x∈X,f(x)≥λ0 |f(x)− fk(x)|
+ Cα|y",7.2. Determining k,[0],[0]
"− y′|α + |fk(y)− fk(y′)|.
",7.2. Determining k,[0],[0]
"Thus it suffices to bound maxx∈X,f(x)≥λ0 |f(x)",7.2. Determining k,[0],[0]
"− fk(x)|, |y− y′|, |z−",7.2. Determining k,[0],[0]
"z′|, |fk(y)− fk(y′)|, |fk(z)− fk(z′)|.",7.2. Determining k,[0],[0]
"First take δ = 1/n and use Lemma 5 and 6 for maxx∈X,f(x)≥λ0 |f(x)− fk(x)|.",7.2. Determining k,[0],[0]
"Using Lemma 3, we can show that rn := |y − y′| .",7.2. Determining k,[0],[0]
(log n/n)1/d. Next we bound |fk(y) − fk(y′)|. y′,7.2. Determining k,[0],[0]
∈,7.2. Determining k,[0],[0]
X,7.2. Determining k,[0],[0]
so we have guarantees on its fk value.,7.2. Determining k,[0],[0]
Note that rk(y′),7.2. Determining k,[0],[0]
− rn ≤ rk(y) ≤ rk(y′),7.2. Determining k,[0],[0]
+ rn.,7.2. Determining k,[0],[0]
Let rk = rk(y′).,7.2. Determining k,[0],[0]
"This implies that fk(y′)(rk/(rk + rn))
d ≤ fk(y) ≤ fk(y′)(rk/(rk",7.2. Determining k,[0],[0]
− rn))d.,7.2. Determining k,[0],[0]
"Now since rk ≈ (k/n)1/d, we have |fk(y) − fk(y′)| .",7.2. Determining k,[0],[0]
log n/k.,7.2. Determining k,[0],[0]
"The same holds for the bounds related to z, z′.
Theorem 4 (β̂ → β in probability).",7.2. Determining k,[0],[0]
Suppose f is αHölder continuous for some α with 0 < α ≤ β′.,7.2. Determining k,[0],[0]
Let k = b(log n)5c and r = 1/ √ log n.,7.2. Determining k,[0],[0]
"Then for all > 0,
lim n→∞
P ( |β̂",7.2. Determining k,[0],[0]
"− β| ≥ ) = 0.
Proof.",7.2. Determining k,[0],[0]
"Based on the β-regularity assumption, we have for r < rc:
Čβr β ≤",7.2. Determining k,[0],[0]
"Dr ≤ Ĉβrβ .
",7.2. Determining k,[0],[0]
"Combining this with Lemma 9, we have with probability at least 1− 1/ √ n",7.2. Determining k,[0],[0]
"that
Čβr β",7.2. Determining k,[0],[0]
"− C̃/(log n)2 ≤ D̂r,k ≤ Ĉβrβ",7.2. Determining k,[0],[0]
+,7.2. Determining k,[0],[0]
"C̃/(log n)2.
",7.2. Determining k,[0],[0]
"Thus with probability at least 1− 1/n,
β − β̂",7.2. Determining k,[0],[0]
"≥ log(1− C̃/(D̂r,k · (log n 2)))",7.2. Determining k,[0],[0]
log,7.2. Determining k,[0],[0]
"r − log Ĉβ log r
β",7.2. Determining k,[0],[0]
"− β̂ ≤ log(1 + C̃/(D̂r,k · (log n 2)))
",7.2. Determining k,[0],[0]
"log r + log Čβ log r .
",7.2. Determining k,[0],[0]
"It is clear that these expressions go to 0 as n→∞ and the result follows.
",7.2. Determining k,[0],[0]
Remark 11.,7.2. Determining k,[0],[0]
"We can then take k = nβ̂′/(2β̂′+d) with β̂′ = min{1, β̂− 0} for some 0 > 0",7.2. Determining k,[0],[0]
so that β̂′ < β′ for n sufficiently large and thus k lies in the allowed ranges described in Section 5.2 asymptotically.,7.2. Determining k,[0],[0]
The settings of ε and MinPts are implied by this choice of k and our estimate of d.,7.2. Determining k,[0],[0]
"Putting this all together, along with Theorems 1 and 2, gives us the following consequence about level set recovery with adaptive tuning.",7.3. Rates with Data-driven Tuning,[0],[0]
"It shows that we can obtain rates arbitrarily close to those obtained as if the smoothness parameter β and intrinsic dimension were known.
",7.3. Rates with Data-driven Tuning,[0],[0]
Corollary 1.,7.3. Rates with Data-driven Tuning,[0],[0]
Suppose that 0,7.3. Rates with Data-driven Tuning,[0],[0]
< δ < 1 and f is αHölder continuous for some 0,7.3. Rates with Data-driven Tuning,[0],[0]
< α ≤ 1 and suppose the data-driven choices of parameters described in Remark 11 are used for DBSCAN.,7.3. Rates with Data-driven Tuning,[0],[0]
"For any > 0, there exists
N ,δ,f ≡ N( , δ, f) and Cδ ≡ Cδ(δ, f) such that the following holds.",7.3. Rates with Data-driven Tuning,[0],[0]
"If n ≥ N ,δ,f , then with probability at least 1− δ simulatenously for each C ∈ Cλ, there exists Ĉ ∈ Ĉλ such that
dHaus(C, Ĉ) ≤",7.3. Rates with Data-driven Tuning,[0],[0]
"Cδ · n− 1 2β+dmax{1,β}+ .
",7.3. Rates with Data-driven Tuning,[0],[0]
"Moreover, using Algorithm 2, there is a one-to-one correspondence between Cλ and Ĉλ.",7.3. Rates with Data-driven Tuning,[0],[0]
Here we instead take f to be the density of F over the uniform measure on RD.,8. Full Dimensional Setting,[0],[0]
"Let
minPts = k, ε =
( k
n · vD · (λ− λ · C2δ,n/ √ k)
)1/D ,
where k satisfies
Kl · (log n)2 ≤ k ≤",8. Full Dimensional Setting,[0],[0]
"Ku · (log n)2D/(2+D) · n2β/(2β+D),
and Kl and Ku are positive constants depending δ, Čβ , Ĉβ , β, τ,D, ||f ||∞, λ0, rs, rc.
",8. Full Dimensional Setting,[0],[0]
Then Theorem 1 and 2 hold (replacing d with D in Algorithm 1) for this setting of DBSCAN and thus taking k ≈ n2β/(2β+D) gives us the optimal estimation rate of O(n−1/(2β+D)).,8. Full Dimensional Setting,[0],[0]
A straightforward modification of Corollary 1 also holds.,8. Full Dimensional Setting,[0],[0]
This is discussed further in the Appendix.,8. Full Dimensional Setting,[0],[0]
"We proved that DBSCAN can obtain Hausdorff level-set recovery rates of Õ(n−1/(2β+D)) when the data is in RD, and Õ(n−1/(2β+d·max{1,β})) when the data lies on an embedded d-dimensional manifold.",9. Conclusion,[0],[0]
The former rate is optimal up to log factors and the latter matches known ddimensional lower bounds for 0 < β ≤ 1 up to log factors.,9. Conclusion,[0],[0]
"Moreover, we provided a fully data-driven procedure to tune the parameters to attain these rates.
",9. Conclusion,[0],[0]
This shows that the procedure’s ability to recover density level sets matches the strongest known consistency results attained for this problem.,9. Conclusion,[0],[0]
"Furthermore, we developed the necessary tools and give the first analysis of density levelset estimation on manifolds, let alone with a practical procedure such as DBSCAN.
",9. Conclusion,[0],[0]
"Our density estimation errors however cannot converge faster than Õ(n−1/(2+d)), which is due in part to the error from resolving geodesic balls with Euclidean balls.",9. Conclusion,[0],[0]
Thus it remains an open problem whether the manifold level-set rates are minimax optimal when β > 1.,9. Conclusion,[0],[0]
The author is grateful to Samory Kpotufe for insightful discussions and to the anonymous reviewers for their useful feedback.,Acknowledgements,[0],[0]
We show that DBSCAN can estimate the connected components of the λ-density level set {x : f(x) ≥ λ} given n i.i.d. samples from an unknown density f .,abstractText,[0],[0]
We characterize the regularity of the level set boundaries using parameter β > 0 and analyze the estimation error under the Hausdorff metric.,abstractText,[0],[0]
"When the data lies in R we obtain a rate of Õ(n−1/(2β+D)), which matches known lower bounds up to logarithmic factors.",abstractText,[0],[0]
"When the data lies on an embedded unknown ddimensional manifold in R, then we obtain a rate of Õ(n−1/(2β+d·max{1,β})).",abstractText,[0],[0]
"Finally, we provide adaptive parameter tuning in order to attain these rates with no a priori knowledge of the intrinsic dimension, density, or β.",abstractText,[0],[0]
Density Level Set Estimation on Manifolds with DBSCAN,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 328–338, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
In recent years there has been a great deal of interest in dependency parsing models for natural languages.,1 Introduction,[0],[0]
"Supervised learning methods have been shown to produce highly accurate dependencyparsing models; unfortunately, these methods rely on human-annotated data, which is expensive to obtain, leading to a significant barrier to the development of dependency parsers for new languages.",1 Introduction,[0],[0]
"Recent work has considered unsupervised methods (e.g. (Klein and Manning, 2004; Headden III et al., 2009; Gillenwater et al., 2011; Mareček and Straka, 2013; Spitkovsky et al., 2013; Le and Zuidema, 2015; Grave and Elhadad, 2015)), or methods that transfer linguistic structures across languages (e.g. (Cohen et al., 2011; McDonald et al., 2011; Ma and Xia, 2014; Tiedemann, 2015;
∗Currently on leave at Google Inc.",1 Introduction,[0],[0]
"New York.
",1 Introduction,[0],[0]
"Guo et al., 2015; Zhang and Barzilay, 2015; Xiao and Guo, 2015)), in an effort to reduce or eliminate the need for annotated training examples.",1 Introduction,[0],[0]
"Unfortunately the accuracy of these methods generally lags quite substantially behind the performance of fully supervised approaches.
",1 Introduction,[0],[0]
This paper describes novel methods for the transfer of syntactic information between languages.,1 Introduction,[0],[0]
"As in previous work (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014), our goal is to induce a dependency parser in a target language of interest without any direct supervision (i.e., a treebank) in the target language: instead we assume access to parallel translations between the target and one or more source languages, and to supervised parsers in the source languages.",1 Introduction,[0],[0]
"We can then use alignments induced using tools such as GIZA++ (Och and Ney, 2000), to transfer dependencies from the source language(s) to the target language (example projections are shown in Figure 1).",1 Introduction,[0],[0]
"A target language parser is then trained on the projected dependencies.
",1 Introduction,[0],[0]
"Our contributions are as follows:
• We demonstrate the utility of dense projected structures when training the target-language parser.",1 Introduction,[0],[0]
"In the most extreme case, a “dense” structure is a sentence in the target language where the projected dependencies form a fully projective tree that includes all words in the sentence (we will refer to these structures as “full” trees).",1 Introduction,[0],[0]
"In more relaxed definitions, we might include sentences where at least some proportion (e.g., 80%) of the words participate as a modifier in some dependency, or where long sequences (e.g., 7 words or more) of words all participate as modifiers in some dependency.",1 Introduction,[0],[0]
"We give empirical evidence that dense structures give particularly high accuracy for their projected dependencies.
328
• We describe a training algorithm that builds on the definitions of dense structures.",1 Introduction,[0],[0]
"The algorithm initially trains the model on full trees, then iteratively introduces increasingly relaxed definitions of density.",1 Introduction,[0],[0]
"The algorithm makes use of a training method that can leverage partial (incomplete) dependency structures, and also makes use of confidence scores from a perceptron-trained model.
",1 Introduction,[0],[0]
"In spite of the simplicity of our approach, our experiments demonstrate significant improvements in accuracy over previous work.",1 Introduction,[0],[0]
"In experiments on transfer from a single source language (English) to a single target language (German, French, Spanish, Italian, Portuguese, and Swedish), our average dependency accuracy is 78.89%.",1 Introduction,[0],[0]
"When using multiple source languages, average accuracy is improved to 82.18%.",1 Introduction,[0],[0]
"This is a 5.51% absolute improvement over the previous best results reported on this data set, 76.67% for the approach of (Ma and Xia, 2014).",1 Introduction,[0],[0]
"To give another perspective, our accuracy is close to that of the fully supervised approach of (McDonald et al., 2005), which gives 84.29% accuracy on this data.",1 Introduction,[0],[0]
To the best of our knowledge these are the highest accuracy parsing results for an approach that makes no use of treebank data for the language of interest.,1 Introduction,[0],[0]
"A number of researchers have considered the problem of projecting linguistic annotations from the source to the target language in a parallel corpus (Yarowsky et al., 2001; Hwa et al., 2005;
Ganchev et al., 2009; Spreyer and Kuhn, 2009; McDonald et al., 2011; Ma and Xia, 2014).",2 Related Work,[0],[0]
The projected annotations are then used to train a model in the target language.,2 Related Work,[0],[0]
"This prior work involves various innovations such as the use of posterior regularization (Ganchev et al., 2009), the use of entropy regularization and parallel guidance (Ma and Xia, 2014), the use of a simple method to transfer delexicalized parsers across languages (McDonald et al., 2011), and a method for training on partial annotations that are projected from source to target language (Spreyer and Kuhn, 2009).",2 Related Work,[0],[0]
"There is also recent work on treebank translation via a machine translation system (Tiedemann et al., 2014; Tiedemann, 2015).",2 Related Work,[0],[0]
"The work of (McDonald et al., 2011) and (Ma and Xia, 2014) is most relevant to our own work, for two reasons: first, these papers consider dependency parsing, and as in our work use the latest version of the Google universal treebank for evaluation;1 second, these papers represent the state of the art in accuracy.",2 Related Work,[0],[0]
"The results in (Ma and Xia, 2014) dominate the accuracies for all other papers discussed in this related work section: they report an average accuracy of 76.67% on the languages German, Italian, Spanish, French, Swedish and Portuguese; this evaluation includes all sentence lengths.
",2 Related Work,[0],[0]
"Other work on unsupervised parsing has considered various methods that transfer information from source to target languages, where parsers are available in the source languages, but without the use of parallel corpora (Cohen et al., 2011; Dur-
1The original paper of (McDonald et al., 2011) does not use the Google universal treebank, however (Ma and Xia, 2014) reimplemented the model and report results on the Google universal treebank.
rett et al., 2012; Naseem et al., 2012; Täckström",2 Related Work,[0],[0]
"et al., 2013; Duong et al., 2015; Zhang and Barzilay, 2015).",2 Related Work,[0],[0]
"These results are somewhat below the performance of (Ma and Xia, 2014).2",2 Related Work,[0],[0]
"This section describes our approach, giving definitions of parallel data and of dense projected structures; describing preliminary exploratory experiments on transfer from German to English; describing the iterative training algorithm used in our work; and finally describing a generalization of the method to transfer from multiple languages.",3 Our Approach,[0],[0]
We assume that we have parallel data in two languages.,3.1 Parallel Data Definitions,[0],[0]
"The source language, for which we have a supervised parser, is assumed to be English.",3.1 Parallel Data Definitions,[0],[0]
"The target language, for which our goal is to learn a parser, will be referred to as the “foreign” language.",3.1 Parallel Data Definitions,[0],[0]
"We describe the generalization to more than two languages in §3.5.
",3.1 Parallel Data Definitions,[0],[0]
We use the following notation.,3.1 Parallel Data Definitions,[0],[0]
"Our parallel data is a set of examples (e(k), f (k)) for k = 1 . . .",3.1 Parallel Data Definitions,[0],[0]
"n,",3.1 Parallel Data Definitions,[0],[0]
"where each e(k) is an English sentence, and each f (k) is a foreign sentence.",3.1 Parallel Data Definitions,[0],[0]
Each e(k) = e (k) 1 . . .,3.1 Parallel Data Definitions,[0],[0]
"e (k) sk where e (k) i is a word, and sk is the length of k’th source sentence.",3.1 Parallel Data Definitions,[0],[0]
"Similarly, f (k) = f
(k) 1 . . .",3.1 Parallel Data Definitions,[0],[0]
"f (k) tk where f (k)j is a word, and tk is the length of k’th foreign sentence.
",3.1 Parallel Data Definitions,[0],[0]
"A dependency is a four-tuple (l, k, h,m) where l ∈ {e, f} is the language, k is the sentence number, h is the head index, m is the modifier index.",3.1 Parallel Data Definitions,[0],[0]
"Note that if l = e then we have 0 ≤ h ≤ sk and 1 ≤ m ≤ sk, conversely if l = f then 0 ≤ h ≤ tk and 1 ≤ m ≤ tk.",3.1 Parallel Data Definitions,[0],[0]
"We use h = 0 when h is the root of the sentence.
",3.1 Parallel Data Definitions,[0],[0]
For any k ∈ {1 . . .,3.1 Parallel Data Definitions,[0],[0]
"n}, j ∈",3.1 Parallel Data Definitions,[0],[0]
{0 . . .,3.1 Parallel Data Definitions,[0],[0]
"tk}, Ak,j is an integer specifying which word in e(k)1 . . .",3.1 Parallel Data Definitions,[0],[0]
"e (k) sk , word f (k)j is aligned to.",3.1 Parallel Data Definitions,[0],[0]
It is NULL if f (k) j is not aligned to anything.,3.1 Parallel Data Definitions,[0],[0]
"We have Ak,0 = 0 for all k: that is, the root in one language is always aligned to the root in the other language.
",3.1 Parallel Data Definitions,[0],[0]
In our experiments we use intersected alignments from GIZA++,3.1 Parallel Data Definitions,[0],[0]
"(Och and Ney, 2000) to provide the Ak,j values.
",3.1 Parallel Data Definitions,[0],[0]
"2With one exception: on Spanish, using the CoNLL definition of dependencies.",3.1 Parallel Data Definitions,[0],[0]
"The good results from (Ma and Xia, 2014) on the universal dependencies for Spanish may show that the result on the CONLL data is an anomaly, perhaps due to the annotation scheme in Spanish being different from other languages.",3.1 Parallel Data Definitions,[0],[0]
We now describe various sets of projected dependencies.,3.2 Projected Dependencies,[0],[0]
We use D to denote the set of all dependencies in the source language: these dependencies are the result of parsing the English side of the translation data using a supervised parser.,3.2 Projected Dependencies,[0],[0]
"Each dependency (l, k, h,m) ∈ D is a four-tuple as described above, with l = e.",3.2 Projected Dependencies,[0],[0]
We will use P to denote the set of all projected dependencies from the source to target language.,3.2 Projected Dependencies,[0],[0]
"The set P is constructed from D and the alignment variables Ak,j as follows:
P = {(l, k, h,m) :",3.2 Projected Dependencies,[0],[0]
"l = f ∧ (e, k, Ak,h, Ak,m) ∈ D}
",3.2 Projected Dependencies,[0],[0]
"We say the k’th sentence receives a full parse under the dependencies P if the dependencies (f, k, h,m) for k form a projective tree over the entire sentence: that is, each word has exactly one head, the root symbol is the head of the entire structure, and the resulting structure is a projective tree.",3.2 Projected Dependencies,[0],[0]
We use T100 ⊆ {1 . . .,3.2 Projected Dependencies,[0],[0]
n} to denote the set of all sentences that receive a full parse under P .,3.2 Projected Dependencies,[0],[0]
"We then define the following set,
P100 = {",3.2 Projected Dependencies,[0],[0]
"(l, k, h,m) ∈ P : k ∈ T100}",3.2 Projected Dependencies,[0],[0]
"We say the k’th sentence receives a dense parse under the dependencies P if the dependencies of the form (f, k, h,m) for k form a projective tree over at least 80% of the words in the sentence.",3.2 Projected Dependencies,[0],[0]
We use T80 ⊆ {1 . . .,3.2 Projected Dependencies,[0],[0]
n} to denote the set of all sentences that receive a dense parse under P .,3.2 Projected Dependencies,[0],[0]
"We then define the following set,
P80 = {(l, k, h,m",3.2 Projected Dependencies,[0],[0]
) ∈ P : k ∈ T80},3.2 Projected Dependencies,[0],[0]
We say the k’th sentence receives a span-s parse where s is an integer if there is a sequence of at least s consecutive words in the target language that are all seen as a modifier in the set P .,3.2 Projected Dependencies,[0],[0]
We use Ss to refer to the set of all sentences with a span-s parse.,3.2 Projected Dependencies,[0],[0]
"We define the sets
P≥7 =",3.2 Projected Dependencies,[0],[0]
"{(l, k, h,m) ∈ P : k ∈ S7} P≥5 = {(l, k, h,m) ∈",3.2 Projected Dependencies,[0],[0]
"P : k ∈ S5} P≥1 = {(l, k, h,m) ∈ P :",3.2 Projected Dependencies,[0],[0]
"k ∈ S1}
Finally, we also create datasets that only include projected dependencies that are consistent with respect to part-of-speech (POS) tags for the head and
modifier words in source and target data.",3.2 Projected Dependencies,[0],[0]
"We assume a function POS(k, j, i) which returns TRUE if the POS tags for words f (k)j and e (k) i are consistent.",3.2 Projected Dependencies,[0],[0]
"The definition of POS-consistent projected dependencies is then as follows:
P̄ = {(l, k, h,m) ∈",3.2 Projected Dependencies,[0],[0]
"P : POS(k, h,Ak,h) ∧ POS(k,m,Ak,m)}
",3.2 Projected Dependencies,[0],[0]
We experiment with two definitions for the POS function.,3.2 Projected Dependencies,[0],[0]
"The first imposes a hard constraint, that the POS tags in the two languages must be identical.",3.2 Projected Dependencies,[0],[0]
"The second imposes a soft constraint, that the two POS tags must fall into the same equivalance class: the equivalence classes used are listed in §4.1.
",3.2 Projected Dependencies,[0],[0]
"Given this definition of P̄ , we can create sets P̄100, P̄80, P̄≥7, P̄≥5, and P̄≥1, using analogous definitions to those given above.",3.2 Projected Dependencies,[0],[0]
"Throughout the experiments in this paper, we used German as the target language for development of our approach.",3.3 Preliminary Experiments with Transfer from English to German,[0],[0]
Table 1 shows some preliminary results on transferring dependencies from English to German.,3.3 Preliminary Experiments with Transfer from English to German,[0],[0]
"We can estimate the accuracy of dependency subsets such as P100, P80, P≥7 and so on by comparing these dependencies to the dependencies from a supervised German parser on the same data.",3.3 Preliminary Experiments with Transfer from English to German,[0],[0]
"That is, we use a supervised parser to provide gold standard annotations.",3.3 Preliminary Experiments with Transfer from English to German,[0],[0]
"The full set of dependencies P give 74.0% accuracy under this measure; results for P100 are considerably higher in accuracy, ranging from 83.0% to 90.1% depending on how POS constraints are used.
",3.3 Preliminary Experiments with Transfer from English to German,[0],[0]
"As a second evaluation method, we can test the accuracy of a model trained on the P100 data.",3.3 Preliminary Experiments with Transfer from English to German,[0],[0]
The benefit of the soft-matching POS definition is clear.,3.3 Preliminary Experiments with Transfer from English to German,[0],[0]
"The hard match definition harms performance, presumably because it reduces the number of sentences used to train the model.
",3.3 Preliminary Experiments with Transfer from English to German,[0],[0]
"Throughout the rest of this paper, we use the soft POS constraints in all projection algorithms.3",3.3 Preliminary Experiments with Transfer from English to German,[0],[0]
We now describe the training procedure used in our experiments.,3.4 The Training Procedure,[0],[0]
"We use a perceptron-trained shift-reduce parser, similar to that of (Zhang and Nivre, 2011).",3.4 The Training Procedure,[0],[0]
"We assume that the parser is able
3The hard constraint is also used by Ma and Xia (2014).
to operate in a “constrained” mode, where it returns the highest scoring parse that is consistent with a given subset of dependencies.",3.4 The Training Procedure,[0],[0]
"This can be achieved via zero-cost dynamic oracles (Goldberg and Nivre, 2013).
",3.4 The Training Procedure,[0],[0]
"We assume the following definitions:
• TRAIN(D) is a function that takes a set of dependency structures D as input, and returns a model θ as its output.",3.4 The Training Procedure,[0],[0]
"The dependency structures are assumed to be full trees: that is, they correspond to fully projected trees with the root symbol as their root.
",3.4 The Training Procedure,[0],[0]
"• CDECODE(P, θ) is a function that takes a set of partial dependency structures P , and a model θ as input, and as output returns a set of full trees D. It achieves this by constrained decoding of the sentences inP under the model θ, where for each sentence we use beam search to search for the highest scoring projective full tree that is consistent with the dependencies in P .",3.4 The Training Procedure,[0],[0]
"• TOP(D, θ) takes as input a set of full trees D, and a model θ.",3.4 The Training Procedure,[0],[0]
"It returns the top m highest scoring trees in D (in our experiments we usedm = 200, 000), where the score for each tree is the perceptron-based score normalized by the sentence length.",3.4 The Training Procedure,[0],[0]
"Thus we return the
200,000 trees that the perceptron is most confident on.4
Figure 2 shows the learning algorithm.",3.4 The Training Procedure,[0],[0]
"It generates a sequence of parsing models, θ1 . . .",3.4 The Training Procedure,[0],[0]
θ4.,3.4 The Training Procedure,[0],[0]
"In the first stage of learning, the model is initialized by training on P100.",3.4 The Training Procedure,[0],[0]
The method then uses this model to fill in the missing dependencies on P80 ∪ P≥7 using the CDECODE method; this data is added to P100 and the model is retrained.,3.4 The Training Procedure,[0],[0]
"The method is iterated, at each point adding in additional partial structures (note that P≥7 ⊆",3.4 The Training Procedure,[0],[0]
"P≥5 ⊆ P≥1, hence at each stage we expand the set of training data that is parsed using CDECODE).",3.4 The Training Procedure,[0],[0]
We now consider the generalization to learning from multiple languages.,3.5 Generalization to Multiple Languages,[0],[0]
"We again assume that the task is to learn a parser in a single target language, for example German.",3.5 Generalization to Multiple Languages,[0],[0]
We assume that we now have multiple source languages.,3.5 Generalization to Multiple Languages,[0],[0]
"For example, in our experiments with German as the target, we used English, French, Spanish, Portuguese, Swedish, and Italian as source languages.",3.5 Generalization to Multiple Languages,[0],[0]
We assume that we have fully supervised parsers for all source languages.,3.5 Generalization to Multiple Languages,[0],[0]
"We will consider two methods for combining information from the different languages:
",3.5 Generalization to Multiple Languages,[0],[0]
Method 1: Concatenation,3.5 Generalization to Multiple Languages,[0],[0]
"In this approach, we form sets P , P100, P80, P≥7 etc. from each of the languages separately, and then concatenate5 the data to give new definitions of P , P100,P80, P≥7 etc.",3.5 Generalization to Multiple Languages,[0],[0]
"Method 2: Voting In this case, we assume that each target language sentence is aligned to a source language sentence in each of the source languages.",3.5 Generalization to Multiple Languages,[0],[0]
"This is the case, for example, in the
4In cases where |D| < m, the entire set D is returned.",3.5 Generalization to Multiple Languages,[0],[0]
"5That is, dependency structures projected from different
languages are taken to be entirely separate from each other.
",3.5 Generalization to Multiple Languages,[0],[0]
"Europarl data, where we have translations of the same material into multiple languages.",3.5 Generalization to Multiple Languages,[0],[0]
We can then create the set P of projected dependencies using a voting scheme.,3.5 Generalization to Multiple Languages,[0],[0]
"For any word (k, j) seen in the target language, each source language will identify a headword (this headword may be NULL if there is no alignment giving a dependency).",3.5 Generalization to Multiple Languages,[0],[0]
We simply take the most frequent headword chosen by the languages.,3.5 Generalization to Multiple Languages,[0],[0]
"After creating the set P , we can create subsets such as P100, P80, P≥7 in exactly the same way as before.
",3.5 Generalization to Multiple Languages,[0],[0]
"Once the various projected dependency training sets have been created, we train the dependency parsing model using the algorithm given in §3.4.",3.5 Generalization to Multiple Languages,[0],[0]
We now describe experiments using our approach.,4 Experiments,[0],[0]
"We first describe data and tools used in the experiments, and then describe results.",4 Experiments,[0],[0]
"Data We use the EuroParl data (Koehn, 2005) as our parallel data and the Google universal treebank (v2; standard data) (McDonald et al., 2013) as our evaluation data, and as our training data for the supervised source-language parsers.",4.1 Data and Tools,[0],[0]
"We use seven languages that are present in both Europarl and the Google universal treebank: English (used only as the source language), and German, Spanish, French, Italian, Portuguese and Swedish.
",4.1 Data and Tools,[0],[0]
"Word Alignments We use Giza++6 (Och and Ney, 2000) to induce word alignments.",4.1 Data and Tools,[0],[0]
Sentences with length greater than 100 and single-word sentences are removed from the parallel data.,4.1 Data and Tools,[0],[0]
"We follow common practice in training Giza++ for both translation directions, and taking the intersection of the two sets as our final alignment.",4.1 Data and Tools,[0],[0]
"Giza++ de-
6http://www.statmt.org/moses/giza/ GIZA++.html
en→trgt concat→trgt voting→trgt
fault alignment model is used in all of our experiments.
",4.1 Data and Tools,[0],[0]
The Parsing Model,4.1 Data and Tools,[0],[0]
"For all parsing experiments we use the Yara parser7 (Rasooli and Tetreault, 2015), a reimplementation of the k-beam arc-eager parser of Zhang and Nivre (2011).",4.1 Data and Tools,[0],[0]
"We use a beam size of 64, and Brown clustering features8 (Brown et al., 1992; Liang, 2005).",4.1 Data and Tools,[0],[0]
"The parser gives performance close to the state of the art: for example on section 23 of the Penn WSJ treebank (Marcus et al., 1993), it achieves 93.32% accuracy, compared to 92.9% accuracy for the parser of (Zhang and Nivre, 2011).
",4.1 Data and Tools,[0],[0]
"POS Consistency As mentioned in §3.2, we define a soft POS consistency constraint to prune some projected dependencies.",4.1 Data and Tools,[0],[0]
"A source/target language word pair satisifies this constraint if one of the following conditions hold: 1) the POS tags for the two words are identical; 2) the word forms for the two words are identical (this occurs frequently for numbers, for example); 3) both tags are in one of the following equivalence classes: {ADV ↔ ADJ} {ADV ↔ PRT} {ADJ ↔ PRON} {DET ↔ NUM} {DET ↔ PRON} {DET ↔ NOUN} {PRON↔NOUN} {NUM↔X} {X↔ .}.",4.1 Data and Tools,[0],[0]
"These rules were developed primarily on German, with some additional validation on Spanish.",4.1 Data and Tools,[0],[0]
"These rules required a small amount of human engineering, but we view this as relatively negligible.
",4.1 Data and Tools,[0],[0]
"Parameter Tuning We used German as a target language in the development of our approach, and in setting hyper-parameters.",4.1 Data and Tools,[0],[0]
"The parser is
7https://github.com/yahoo/YaraParser 8https://github.com/percyliang/
brown-cluster
trained using the averaged structured perceptron algorithm (Collins, 2002) with max-violation updates (Huang et al., 2012).",4.1 Data and Tools,[0],[0]
"The number of iterations over the training data is 5 when training model θ1 in any setting, and 2, 1 and 4 when training models θ2, θ3, θ4 respectively.",4.1 Data and Tools,[0],[0]
These values are chosen by observing the performance on German.,4.1 Data and Tools,[0],[0]
We use θ4 as the final output from the training process: this is found to be optimal in English to German projections.,4.1 Data and Tools,[0],[0]
"This section gives results of our approach for the single source, multi-source (concatenation) and multi-source (voting) methods.",4.2 Results,[0],[0]
"Following previous work (Ma and Xia, 2014) we use goldstandard part-of-speech (POS) tags on test data.",4.2 Results,[0],[0]
"We also provide results with automatic POS tags.
Results with a Single Source Language The first set of results are with a single source language; we use English as the source in all of these experiments.",4.2 Results,[0],[0]
Table 2 shows the accuracy of parameters θ1 . . .,4.2 Results,[0],[0]
"θ4 for transfer into German, Spanish, French, Italian, Portuguese, and Swedish.",4.2 Results,[0],[0]
"Even the lowest performing model, θ1, which is trained only on full trees, has a performance of 75.88%, close to the 76.15% accuracy for the method of (Ma and Xia, 2014).",4.2 Results,[0],[0]
"There are clear gains as we move from θ1 to θ4, on all languages.",4.2 Results,[0],[0]
"The average accuracy for θ4 is 78.89%.
",4.2 Results,[0],[0]
"Results with Multiple Source Languages, using Concatenation Table 2 shows results using multiple source languages, using the concatenation method.",4.2 Results,[0],[0]
"In these experiments for a given target language we use all other languages in our
data as source languages.",4.2 Results,[0],[0]
"The performance of θ1 improves from an average of 75.88% for a single source language, to 79.76% for multiple languages.",4.2 Results,[0],[0]
"The performance of θ4 gives an additional improvement to 81.23%.
Results with Multiple Source Languages, using Voting The final set of results in Table 2 are for multiple languages using the voting strategy.",4.2 Results,[0],[0]
"There are further improvements: model θ1 has average accuracy of 80.95%, and model θ4 has average accuracy of 82.18%.
",4.2 Results,[0],[0]
Results with Automatic POS,4.2 Results,[0],[0]
Tags We use our final θ4 models to parse the treebank with automatic tags provided by the same POS tagger used for tagging the parallel data.,4.2 Results,[0],[0]
"Table 3 shows the results for the transfer methods and the supervised parsing models of (McDonald et al., 2011) and (Rasooli and Tetreault, 2015).",4.2 Results,[0],[0]
"The first-order supervised method of (McDonald et al., 2005) gives only a 1.7% average absolute improvement in ac-
curacy over the voting method.",4.2 Results,[0],[0]
"For one language (Swedish), our method actually gives improved accuracy over the 1st order parser.
",4.2 Results,[0],[0]
"Comparison to Previous Results Table 4 gives a comparison of the accuracy on the six languages, using the single source and multiple source methods, to previous work.",4.2 Results,[0],[0]
"As shown in the table, our model outperforms all models: among them, the results of (McDonald et al., 2011) and (Ma and Xia, 2014) are directly comparable to us because they use the same training and evaluation data.",4.2 Results,[0],[0]
"The recent work of (Xiao and Guo, 2015) uses the same parallel data but evaluates on CoNLL treebanks but their results are lower than Ma and Xia (2014).",4.2 Results,[0],[0]
"The recent work of (Guo et al., 2015) evaluates on the same data as ours but uses different parallel corpora.",4.2 Results,[0],[0]
"They only reported on three languages (German: 60.35, Spanish: 71.90 and French: 72.93) which are all far bellow our results.",4.2 Results,[0],[0]
"The work of (Grave and Elhadad, 2015) is the state-of-the-art fully unsupervised model with
minimal linguistic prior knowledge.",4.2 Results,[0],[0]
"The model of (Zhang and Barzilay, 2015) does not use any parallel data but uses linguistic information across languages.",4.2 Results,[0],[0]
"Their semi-supervised model selectively samples 50 annotated sentences but our model outperforms their model.
",4.2 Results,[0],[0]
"Compared to the results of (McDonald et al., 2011) and (Ma and Xia, 2014) which are directly comparable, there are clear improvements across all languages; the highest accuracy, 82.18%, is a 5.51% absolute improvement over the average accuracy for (Ma and Xia, 2014).",4.2 Results,[0],[0]
"We conclude with some analysis of the accuracy of the projected dependencies for the different languages, for different definitions (P100, P80 etc.), and for different projection methods.",5 Analysis,[0],[0]
Table 5 gives a summary of statistics for the various languages.,5 Analysis,[0],[0]
Recall that German is used as the development language in our experiments; the other languages can be considered to be test languages.,5 Analysis,[0],[0]
"In all cases the accuracy reported is the percentage match to a supervised parser used to parse the same data.
",5 Analysis,[0],[0]
There are some clear trends.,5 Analysis,[0],[0]
"The accuracy of the P100 datasets is high, with an average accuracy of 84.7% for the single source method, 88.3% for the concatenation method, and 89.0% for the voting method.",5 Analysis,[0],[0]
"The voting method not only increases accuracy over the single source method, but also increases the number of sentences (from an average 17k to 77k) and the average number of dependencies per sentence (from 6.8 to 10.4).
",5 Analysis,[0],[0]
"The accuracy of the P80 ∪ P≥7 datasets is slightly lower, with around 83-87% accuracy for the single source, concatenation and voting methods.",5 Analysis,[0],[0]
"The voting method gives a significant increase in the number of sentences—from an av-
erage of 140k to 243k.",5 Analysis,[0],[0]
"The average sentence length for this data is around 28 words, considerably longer than the P100 data; the addition of longer sentences is very likely beneficial to the model.",5 Analysis,[0],[0]
"For the voting method the average number of dependencies is 13.7, giving an average density of 50% on these sentences.
",5 Analysis,[0],[0]
"The accuracy for the different languages, in particular for the voting data, is surprisingly uniform, with a range of 85.8-91.4% for the P100 data, and 81.3-87.4% for the P80 ∪ P≥7 data.",5 Analysis,[0],[0]
"The number of sentences for each language, the average length of those sentences, and average number of dependencies per sentence is also quite uniform, with the exception of German, which is a clear outlier.",5 Analysis,[0],[0]
"German has fewer sentences, and fewer dependencies per sentence: this may account for it having the lowest accuracy for our models.",5 Analysis,[0],[0]
"Future work should investigate why this is the case: one hypothesis is that German has quite different word order from the other languages (it is V2, and verb final), which may lead to a degradation in the quality of the alignments from GIZA++, or in the projection process.
",5 Analysis,[0],[0]
"Finally, figure 3 shows some randomly selected examples from the P100 data for Spanish, giving a qualitative feel for the data obtained using the voting method.",5 Analysis,[0],[0]
We have described a density-driven method for the induction of dependency parsers using parallel data and source-language parsers.,6 Conclusions,[0],[0]
"The key ideas are a series of increasingly relaxed definitions of density, together with an iterative training procedure that makes use of these definitions.",6 Conclusions,[0],[0]
"The method gives a significant gain over previous methods, with dependency accuracies approach-
ing the level of fully supervised methods.",6 Conclusions,[0],[0]
"Future work should consider application of the method to a broader set of languages, and application of the method to transfer of information other than dependency structures.",6 Conclusions,[0],[0]
We thank Avner May and anonymous reviewers for their useful comments.,Acknowledgement,[0],[0]
Mohammad Sadegh Rasooli was supported by a grant from Bloomberg’s Knowledge Engineering team.,Acknowledgement,[0],[0]
We present a novel method for the crosslingual transfer of dependency parsers.,abstractText,[0],[0]
"Our goal is to induce a dependency parser in a target language of interest without any direct supervision: instead we assume access to parallel translations between the target and one or more source languages, and to supervised parsers in the source language(s).",abstractText,[0],[0]
"Our key contributions are to show the utility of dense projected structures when training the target language parser, and to introduce a novel learning algorithm that makes use of dense structures.",abstractText,[0],[0]
"Results on several languages show an absolute improvement of 5.51% in average dependency accuracy over the state-of-the-art method of (Ma and Xia, 2014).",abstractText,[0],[0]
Our average dependency accuracy of 82.18% compares favourably to the accuracy of fully supervised methods.,abstractText,[0],[0]
Density-Driven Cross-Lingual Transfer of Dependency Parsers,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 33–43, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Compared to trees, which have dominated the field of natural language processing (NLP) for decades, graphs are more general for modelling natural languages.",1 Introduction,[0],[0]
The corresponding grammars for recognizing and producing graphs are more flexible and powerful than tree grammars.,1 Introduction,[0],[0]
"However, because of their high complexity, graph grammars have not been widely used in NLP.
",1 Introduction,[0],[0]
"Recently, along with progress on graph-based meaning representation, hyperedge replacement grammars (HRG) (Drewes et al., 1997) have been revisited, explored and used for semantic-based machine translation (Jones et al., 2012).",1 Introduction,[0],[0]
"However, the translation process is rather complex and the resources it relies on, namely abstract meaning corpora, are limited as well.
",1 Introduction,[0],[0]
"As most available syntactic resources and tools are tree-based, in this paper we propose to convert dependency trees, which are usually taken as a kind of shallow semantic representation, to dependency graphs by labelling edges.",1 Introduction,[0],[0]
"We then use a synchronous version of edge replacement grammar (ERG) (Section 2), a special case of HRG, to translate these graphs.",1 Introduction,[0],[0]
"The resulting translation model has the same order of magnitude in terms of time complexity with the hierarchical phrasebased model (HPB) (Chiang, 2005) under a certain restriction (Section 3).
",1 Introduction,[0],[0]
"Compared to dependency tree-to-string models, using ERG for graph-to-string translation brings some benefits (Section 3).",1 Introduction,[0],[0]
"Thanks to the stronger generative capacity of the grammar, our model can naturally translate siblings in a tree structure, which are usually treated as non-syntactic phrases and handled by other techniques (Huck et al., 2014; Xie et al., 2014).",1 Introduction,[0],[0]
"Furthermore, compared to the known treelet approach (Quirk et al., 2005) and Dep2Str (Xie et al., 2011), our method not only uses treelets but also has a full capacity of reordering.
",1 Introduction,[0],[0]
"We define our translation model (Section 4) in the log-linear framework (Och and Ney, 2002).",1 Introduction,[0],[0]
"Large-scale experiments (Section 5) on Chinese– English and German–English, two language pairs that have a high degree of syntactic reordering, show that our method significantly improves translation quality over both HPB and Dep2Str, as measured by BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and METEOR (Denkowski and Lavie, 2011).",1 Introduction,[0],[0]
We also find that the rules in our model are more suitable for long-distance reordering and translating long sentences.,1 Introduction,[0],[0]
"As a special case of HRG, ERG is also a contextfree rewriting grammar to recognize and produce graphs.",2 Edge Replacement Grammar,[0],[0]
"Following HRG, the graph we use in this
33
paper is connected, nodes ordered, acyclic and has edge labels but no node labels (Chiang et al., 2013).",2 Edge Replacement Grammar,[0],[0]
"We provide some formal definitions on ERG.
Definition 1.",2 Edge Replacement Grammar,[0],[0]
"A connected, edge-labeled, ordered graph is a tuple H = 〈V,E, φ〉, where
• V is a finite set of nodes.
",2 Edge Replacement Grammar,[0],[0]
"• E ⊆ V 2 is a finite set of edges.
",2 Edge Replacement Grammar,[0],[0]
"• φ : E → C assigns a label (drawn from C) to each edge.
",2 Edge Replacement Grammar,[0],[0]
"In ERG, the elementary unit is a graph fragment, which is also the right-hand side of a production in the grammar.",2 Edge Replacement Grammar,[0],[0]
"Its definition is as follows.
",2 Edge Replacement Grammar,[0],[0]
Definition 2.,2 Edge Replacement Grammar,[0],[0]
"A graph fragment is a tuple H = 〈V,E, φ,X〉, where 〈V,E, φ〉 is a graph and X ∈ (V ∪ V 2) is a list of distinct nodes.",2 Edge Replacement Grammar,[0],[0]
"Following Chiang et al. (2013), we call these external nodes.
",2 Edge Replacement Grammar,[0],[0]
The external nodes indicate how to integrate a graph into another one during a derivation.,2 Edge Replacement Grammar,[0],[0]
"Different to HRG, ERG limits the number of external nodes to 2 at most to make sure hyperedges do not exist during a derivation.",2 Edge Replacement Grammar,[0],[0]
"Now we define the ERG.
Definition 3.",2 Edge Replacement Grammar,[0],[0]
"An edge replacement grammar is a tuple 〈N,T, P, S〉, where
• N and T are disjoint finite sets of nonterminal symbols and terminal symbols, respectively.
",2 Edge Replacement Grammar,[0],[0]
• P is a finite set of productions of the form,2 Edge Replacement Grammar,[0],[0]
"A→ R, where A ∈ N and R is a graph fragment, where edge-labels are from N ⋃ T .
",2 Edge Replacement Grammar,[0],[0]
• S ∈ N is the start symbol.,2 Edge Replacement Grammar,[0],[0]
Figure 1 shows an example of a derivation in an ERG to produce a graph.,2 Edge Replacement Grammar,[0],[0]
"Starting from the start symbol S, when a rule (A → R) is applied to an edge e, the edge is replaced by the graph fragment R.",2 Edge Replacement Grammar,[0],[0]
"Just like in HRG, the ordering of nodes Ve in e and external nodes XR in R implies the mapping from Ve to XR (Chiang et al., 2013).",2 Edge Replacement Grammar,[0],[0]
"In SMT, we need a synchronous grammar to simultaneously parse an input graph and produce translations.",3 Graph-to-String Grammar,[0],[0]
The graph we use in this paper is from a dependency structure which is capable of modelling long-distance relations in a sentence.,3 Graph-to-String Grammar,[0],[0]
"Before defining the synchronous grammar, we firstly define a dependency graph which is a special case of a graph.",3.1 The Grammar,[0],[0]
Definition 4.,3.1 The Grammar,[0],[0]
"A dependency graph is a tuple 〈V,E, φ,∆〉, where 〈V,E, φ〉 is a graph and ∆ is a restriction: edges are ordered.
",3.1 The Grammar,[0],[0]
"A dependency graph is directly derived from a dependency tree by labeling edges with words, as shown in Figure 2.",3.1 The Grammar,[0],[0]
"Although in general graph edges are unordered, in Definition 4 we keep word order by ordering edges, because the word order is an important piece of information for translation.
",3.1 The Grammar,[0],[0]
"Similar to the graph fragment, a dependencygraph fragment is defined as below.",3.1 The Grammar,[0],[0]
Definition 5.,3.1 The Grammar,[0],[0]
"A dependency-graph fragment is a tuple 〈V,E, φ,∆, X〉, where 〈V,E, φ,∆〉 is a dependency graph,X ∈ (V ∪V 2) is a list of external nodes.
",3.1 The Grammar,[0],[0]
"In this paper, we define a synchronous ERG over dependency graphs as a dependency graphto-string grammar, which can be used for MT.
Definition 6.",3.1 The Grammar,[0],[0]
"A dependency graph-to-string grammar (DGSG) is a tuple 〈N,T, T ′, P, S〉, where
• N is a finite set of non-terminal symbols.",3.1 The Grammar,[0],[0]
• T and T ′ are finite sets of terminal symbols.,3.1 The Grammar,[0],[0]
• S ∈ N is the start symbol.,3.1 The Grammar,[0],[0]
"• P is a finite set of productions of the form 〈A→ R,A′",3.1 The Grammar,[0],[0]
"→ R′,∼〉, where A,A′ ∈ N , R is a dependency-graph fragment over N ⋃ T
andR′ is a string overN ⋃ T ′. ∼ is a one-toone mapping between non-terminal symbols in R and R′.
Figure 3 shows a derivation simultaneously producing a Chinese dependency graph and an English string using a DGSG.",3.1 The Grammar,[0],[0]
"Each time a rule is applied, the dependency-graph fragment in the rule replaces an edge in the source graph, and the string in the rule replaces a non-terminal in the target string.
",3.1 The Grammar,[0],[0]
Proposition 1.,3.1 The Grammar,[0],[0]
"DGSG has stronger generative capacity over graph-string pairs than both SCFG and synchronous tree substitution grammar (STSG).
",3.1 The Grammar,[0],[0]
Proof.,3.1 The Grammar,[0],[0]
"STSG has stronger generative capacity over structures than SCFG (Chiang, 2012).1
Any STSG can easily be converted into a DGSG by labelling edges in tree structures.
1The following STSG generates a trivial example of a tree-string pair that no SCFG can generate, as SCFG must always have an equal number of non-terminal symbols.
",3.1 The Grammar,[0],[0]
"X | : X | X |
The following DGSG generates a trivial example of a graph-string pair, which no STSG can generate, as the left-head side has no head nodes while STSG always requires one to form a tree.
",3.1 The Grammar,[0],[0]
"c:a b
This proof is also verified in Figure 3 where the third rule is used to translate a non-syntactic phrase, which can be a problem for dependency tree-to-string methods.",3.1 The Grammar,[0],[0]
"In addition, the second rule translates a treelet and the first rule encodes reordering information inside.",3.1 The Grammar,[0],[0]
"All these three aspects are uniformly modeled in our grammar, which makes it more powerful than other methods, such as the treelet approach and the Dep2Str.",3.1 The Grammar,[0],[0]
"Given a dependency graph, training and decoding time using DGSG depends on the number of dependency-graph fragments.",3.2 Time Complexity and a Restriction,[0],[0]
"For example, for a graph where the degree of a node is k, the number of all possible fragments starting from the node is O(2k).",3.2 Time Complexity and a Restriction,[0],[0]
"Therefore, the time complexity would be exponential if we consider them all.
",3.2 Time Complexity and a Restriction,[0],[0]
It is easy to find that the high complexity of DGSG comes from the free combination of edges.,3.2 Time Complexity and a Restriction,[0],[0]
That means that a dependency-graph fragment can cover discontinuous words of an input sentence.,3.2 Time Complexity and a Restriction,[0],[0]
"However, this is not the convention in the field of SMT.
",3.2 Time Complexity and a Restriction,[0],[0]
"For efficient training and decoding, we add a restriction to DGSG: each dependency-graph fragment covers a continuous span of the source sentence.",3.2 Time Complexity and a Restriction,[0],[0]
This reduces the complexity from exponential time to cubic time.,3.2 Time Complexity and a Restriction,[0],[0]
"In this paper we build a dependency graph-tostring model, so we only use one non-terminal symbol X as in HPB on the target side.",3.3 Non-terminal Symbols,[0],[0]
"However, on the source side we define non-terminal symbols over Part-of-Speech (POS) tags, which can be easily obtained as a by-product of dependency parsing.
",3.3 Non-terminal Symbols,[0],[0]
"We define the head of a dependency-graph fragment H as a list of edges, the dependency head of each of which is not in this fragment.",3.3 Non-terminal Symbols,[0],[0]
"Then the
non-terminal symbol for H is defined as the joining of POS tags of its head (Li et al., 2012).",3.3 Non-terminal Symbols,[0],[0]
Figure 4 shows an example.,3.3 Non-terminal Symbols,[0],[0]
"As well as the restriction defined in Section 3.2 making the grammar much smaller, it also results in a similar way of extracting rules as in HPB.",3.4 Rule Extraction,[0],[0]
"Inspired by HPB, we define the rule set over initial pairs.
",3.4 Rule Extraction,[0],[0]
"Given a word-aligned dependency graph-string pair P = 〈G, e,∼〉, let Gji stand for the sub-graph (it may not be connected) covering words from position i to position j. Then a rule 〈Gji , ej ′ i′ 〉 is an initial pair of P , iff:
1.",3.4 Rule Extraction,[0],[0]
Gji is a dependency-graph fragment.,3.4 Rule Extraction,[0],[0]
"That means it is a connected sub-graph and has at most two external nodes, nodes which connect with nodes outside or are the root.
2.",3.4 Rule Extraction,[0],[0]
It is consistent with the word alignment ∼,3.4 Rule Extraction,[0],[0]
"(Och and Ney, 2004).
",3.4 Rule Extraction,[0],[0]
"The set of rules from P satisfies the following:
1.",3.4 Rule Extraction,[0],[0]
"If 〈Gji , ej ′ i′ 〉 is an initial pair, then
〈N(Gji )",3.4 Rule Extraction,[0],[0]
"→ Gji , X → ej ′ i′ 〉
is a rule, where N(G) defines the nonterminal symbol for G.
2.",3.4 Rule Extraction,[0],[0]
"If 〈N(R) → R,X → R′〉 is a rule of P and 〈Gji , ej ′ i′ 〉 is an initial pair such that Gji is a
sub-graph of R and R′ = r1e j′ i′ r2, then
〈N(R)→ R\Gji k, X → r1Xkr2〉
is a rule of P , where \ means replacing Gji in R with an edge labelled with N(Gji ) and
k is a unique index for a pair of non-terminal symbols.
",3.4 Rule Extraction,[0],[0]
"As in HPB, in addition to rules extracted from the parallel corpus, we also use glue rules to combine fragments and translations when no matched rule can be found.
",3.4 Rule Extraction,[0],[0]
"Furthermore, we can use the same rule extraction algorithm as that in HPB, except that we need to check if a span of a source sentence indicates a dependency-graph fragment, in which case we keep the dependency structure and induce a nonterminal for the fragment.",3.4 Rule Extraction,[0],[0]
"We define our model in the log-linear framework over a derivation d, as in Equation (1):
P (d) ∝",4 Model and Decoding,[0],[0]
∏,4 Model and Decoding,[0],[0]
"i φi(d)λi (1)
where φi are features defined on derivations and λi are feature weights.",4 Model and Decoding,[0],[0]
"In our experiments, we use 9 features:
• translation probabilities P (s|t) and P (t|s), where s is the source graph fragment and t is the target string.
",4 Model and Decoding,[0],[0]
"• lexical translation probabilities Plex(s|t) and Plex(t|s).
",4 Model and Decoding,[0],[0]
• language model lm(e),4 Model and Decoding,[0],[0]
"over translation e.
• rule penalty exp(−1).
• word penalty exp(|e|).
• glue penalty exp(−1).
",4 Model and Decoding,[0],[0]
• unknown words penalty exp(u(g)),4 Model and Decoding,[0],[0]
", where u(g) is the number of unknown words in a source graph",4 Model and Decoding,[0],[0]
"g.
Our decoder is based on the conventional chart parsing CYK algorithm (Kasami, 1965; Younger, 1967; Cocke and Schwartz, 1970).",4 Model and Decoding,[0],[0]
"It searches for the best derivation d∗ among all possible derivations D, as in Equation (2):
d∗ = argmax d∈D P (d) (2)
",4 Model and Decoding,[0],[0]
"For each span of an input graph, the decoder checks if it is a dependency-graph fragment.",4 Model and Decoding,[0],[0]
"Then
for each fragment, the decoder finds rules to translate it.",4 Model and Decoding,[0],[0]
The translation of a large span can be obtained by combining translations from its sub-span using rules which have non-terminals.,4 Model and Decoding,[0],[0]
"Finally, glue rules are used to make sure that at least one translation is produced.",4 Model and Decoding,[0],[0]
We conduct experiments on Chinese–English and German–English translation tasks.,5 Experiment,[0],[0]
"The Chinese–English training corpus is from LDC, including LDC2002E18, LDC2003E07, LDC2003E14, LDC2004T07, the Hansards portion of LDC2004T08 and LDC2005T06.",5.1 Datasets,[0],[0]
"NIST 2002 is taken as a development set to tune weights, and NIST 2004 (MT04) and NIST 2005 (MT05) are two test sets to evaluate systems.",5.1 Datasets,[0],[0]
Table 1 provides a summary of this corpus.,5.1 Datasets,[0],[0]
"The Stanford Chinese word segmenter (Chang et al., 2008) is used to segment Chinese sentences.",5.1 Datasets,[0],[0]
"The Stanford dependency parser (Chang et al., 2009) parses a Chinese sentence into a projective dependency tree which is then converted to a dependency graph in our model.
",5.1 Datasets,[0],[0]
"The German–English training corpus is from WMT 2014, including Europarl V7 and News Commentary.",5.1 Datasets,[0],[0]
"News-test 2011 is taken as a development set, while News-test 2012 (WMT12) and News-test 2013 (WMT13) are our test sets.",5.1 Datasets,[0],[0]
Table 1 provides a summary of this corpus.,5.1 Datasets,[0],[0]
"We
use mate-tools2 to perform morphological analysis and parse German sentences (Bohnet, 2010).",5.1 Datasets,[0],[0]
"Then MaltParser3 converts a parse result into a projective dependency tree (Nivre and Nilsson, 2005).",5.1 Datasets,[0],[0]
"In this paper, we mainly compare our system (DGST) with HPB in Moses (Koehn et al., 2007).",5.2 Settings,[0],[0]
We implement our model in Moses and take the same settings as Moses HPB in all experiments.,5.2 Settings,[0],[0]
"In addition, translation results from a recently open-source dependency tree-to-string system, Dep2Str4 (Li et al., 2014), which is implemented in Moses and improves the dependencybased model in Xie et al. (2011), are also reported.",5.2 Settings,[0],[0]
"All systems use the same sets of features defined in Section 4.
",5.2 Settings,[0],[0]
"In all experiments, word alignment is performed by GIZA++",5.2 Settings,[0],[0]
"(Och and Ney, 2003) with the heuristic function grow-diag-final-and.",5.2 Settings,[0],[0]
"We use SRILM (Stolcke, 2002) to train a 5-gram language model on the Xinhua portion of the English Gigaword corpus 5th edition with modified Kneser-Ney discounting (Chen and Goodman, 1996).",5.2 Settings,[0],[0]
"Minimum Error Rate Training (MERT) (Och, 2003) is used to tune weights.
",5.2 Settings,[0],[0]
"To obtain more reliable results, in each experiment, we run MERT three times and report average scores.",5.2 Settings,[0],[0]
"These scores are calculated by three widely used automatic metrics in case-insensitive mode: BLEU, METEOR and TER.",5.2 Settings,[0],[0]
Table 2 shows the scores of all three metrics on all systems.,5.3 Results,[0],[0]
"Similar to Li et al. (2014), in our experiments Dep2Str has on average a comparable result with Moses HPB in terms of BLEU and METEOR scores.",5.3 Results,[0],[0]
"However, it obtains a significantly higher (i.e. worse) TER score on the Chinese–English task.",5.3 Results,[0],[0]
"This may suggest that translations produced by Dep2Str need more post-editing effort (He et al., 2010).
",5.3 Results,[0],[0]
"By contrast, on all test sets, measured by all metrics, our system is significantly better than Moses HPB.",5.3 Results,[0],[0]
"On the Chinese–English task, our system achieves an average gain of 1.25 (absolute, 3.6% relative) BLEU score and 0.55 (absolute, 1.7% relative) METEOR score while also ob-
2http://code.google.com/p/mate-tools/ 3http://www.maltparser.org/ 4http://computing.dcu.ie/˜liangyouli/
dep2str.zip
taining a reduction of 1.1 (absolute, 1.91% relative) TER score on average.
",5.3 Results,[0],[0]
"On the German–English task, our system achieves an average gain of 0.55 (absolute, 2.56% relative) BLEU score and 0.1 (absolute, 0.35% relative) METEOR score and also obtains a reduction of 0.55 (absolute, 0.89% relative) TER score on average.",5.3 Results,[0],[0]
"As shown in Table 2, compared to Moses HPB and Dep2Str, our system achieves higher translation quality as measured by three automatic metrics.",5.4 Analysis,[0],[0]
"In this section, we investigate whether dependency structures bring benefits as expected on long-distance reordering.",5.4 Analysis,[0],[0]
"Table 3 provides the statistics on sentence length of our four test sets.
",5.4 Analysis,[0],[0]
"In both HPB and our model, the length range of a reordering performed on an input sentence is related to the use of glue grammars which bring two benefits during decoding.",5.4 Analysis,[0],[0]
"When no matched rule is found in the models, glue grammars are applied to make sure a translation is produced.",5.4 Analysis,[0],[0]
"In addition, because of the generalization capability of
rules, which typically are learned under a length limitation, using them on long sentences could cause translation quality to deteriorate.",5.4 Analysis,[0],[0]
"Therefore, when the length of a phrase is greater than a certain value, glue grammars are also applied.",5.4 Analysis,[0],[0]
"Therefore, our experiment of analysis is based on the length limitation that a rule can cover (max. phrase length) during decoding.
",5.4 Analysis,[0],[0]
"We set this max. phrase length to different values, including 10, 20 (default), 30, 40 and 50.",5.4 Analysis,[0],[0]
Figure 5 gives the BLEU scores on all test sets.,5.4 Analysis,[0],[0]
"We find that on all different values, our system achieves higher BLEU scores than Moses HPB.",5.4 Analysis,[0],[0]
"In addition, when the max. phrase length becomes larger, Moses HPB shows a declining trend in most cases, especially on the German–English task (WMT12 and WMT13).",5.4 Analysis,[0],[0]
"However, our system is less sensitive to this value.",5.4 Analysis,[0],[0]
We hypothesize that this is because rules from dependency graphs have better generalization for translating longer phrases and are more suitable for translating long sentences.,5.4 Analysis,[0],[0]
"On a manual check, we find that translations produced by our system are more fluent than those of both Moses HPB and Dep2Str.",5.5 Case Study,[0],[0]
"Figure 6 gives an example comparing translations produced by three systems on the Chinese–English task.
",5.5 Case Study,[0],[0]
"We first find a case of long-distance relation, i.e. the subject-verb-object (SVO) structure in the source sentence.",5.5 Case Study,[0],[0]
"In this example, this relation implies a long-distance reordering, which moves the translation of the object to the front of its modifiers, as shown in the given reference.",5.5 Case Study,[0],[0]
"Com-
pared to Moses HPB, both Dep2Str and our system, which rely on dependency structures, are capable of dealing with this.",5.5 Case Study,[0],[0]
"This also suggests that dependency structures are useful for long-distance reordering.
",5.5 Case Study,[0],[0]
"Furthermore, compared to Dep2Str, our system produces a better translation for the ”X 的(of) X” expression, which is not explicitly represented in the dependency structure and thus results in a wrong translation in Dep2Str.",5.5 Case Study,[0],[0]
"After looking into the details of the translation process, we find that our system induces the dependency structure to the ”X 的(of) X” structure by handling both treelets and non-syntactic phrases.",5.5 Case Study,[0],[0]
Figure 7 shows the process of this induction.,5.5 Case Study,[0],[0]
Dependency structures have been used in SMT for a few years.,6 Related Work,[0],[0]
"Because of its better inter-lingual phrasal cohesion properties (Fox, 2002), it is believed to be beneficial to translation.
",6 Related Work,[0],[0]
Researchers have tried to use dependency structures on both target and source sides.,6 Related Work,[0],[0]
"Shen et al. (2010) propose a string-to-dependency model by using dependency fragments of neighbouring words on the target side, which makes the model easier to include a dependency-based language model.
",6 Related Work,[0],[0]
Menezes and Quirk (2005) and Quirk et al. (2005) propose the treelet approach which uses dependency structures on the source side.,6 Related Work,[0],[0]
Xiong et al. (2007) extend this approach by allowing gaps in rules.,6 Related Work,[0],[0]
"However, their methods need a separate reordering model to decide the position of translated words (insertion problem).",6 Related Work,[0],[0]
"To avoid this problem, Xie et al. (2011) propose to use full head-dependent structures of a dependency tree and build a new dependency-to-string model.",6 Related Work,[0],[0]
"However, this model has difficulties in handling non-syntactic phrasal rules and ignores treelets.",6 Related Work,[0],[0]
"Meng et al. (2013) and Xie et al. (2014) further augment this model by incorporating constituent phrases and integrating fix/float structures (Shen et al., 2010), respectively, to allow phrasal rules.",6 Related Work,[0],[0]
"Li et al. (2014) extend this model by decomposing head-dependent structures into treelets.
",6 Related Work,[0],[0]
"Different from these methods, by labelling edges and using the ERG, our model considers the three aspects in a unified way: treelet, reordering and non-syntactic phrase.",6 Related Work,[0],[0]
"In addition, the ERG also naturally provides a decision on what kind of
treelets and phrases should be used.",6 Related Work,[0],[0]
"In this paper, we present a dependency graph-tostring grammar based on a graph grammar, which we call edge replacement grammar.",7 Conclusion,[0],[0]
This grammar can simultaneously produce a pair of dependency graph and string.,7 Conclusion,[0],[0]
"With a restriction of using contiguous edges, our translation model built using this grammar can decode an input dependency graph, which is directly converted from a dependency tree, in cubic time using the CYK algorithm.
",7 Conclusion,[0],[0]
Experiments on Chinese–English and German– English tasks show that our model is significantly better than the hierarchical phrase-based model and a recent dependency tree-to-string model (Dep2Str) in Moses.,7 Conclusion,[0],[0]
"We also find that the rules used in our model are more suitable for longdistance reordering and translating long sentences.
",7 Conclusion,[0],[0]
"Although experiments show significant improvements over baselines, our model has limitations that can be avenues for future work.",7 Conclusion,[0],[0]
The restriction used in this paper reduces the time complexity but at the same time reduces the generative capacity of graph grammars.,7 Conclusion,[0],[0]
Without allowing hyperedges or only using at most two external nodes reduces the phrase coverage in our model as well.,7 Conclusion,[0],[0]
This research has received funding from the People Programme (Marie Curie Actions) of the European Union’s Framework Programme (FP7/20072013) under REA grant agreement no 317471.,Acknowledgments,[0],[0]
The ADAPT Centre for Digital Content Technology is funded under the SFI Research Centres Programme (Grant 13/RC/2106) and is co-funded under the European Regional Development Fund.,Acknowledgments,[0],[0]
We thank anonymous reviewers for their insightful comments and suggestions.,Acknowledgments,[0],[0]
"Compared to tree grammars, graph grammars have stronger generative capacity over structures.",abstractText,[0],[0]
"Based on an edge replacement grammar, in this paper we propose to use a synchronous graph-to-string grammar for statistical machine translation.",abstractText,[0],[0]
The graph we use is directly converted from a dependency tree by labelling edges.,abstractText,[0],[0]
We build our translation model in the log-linear framework with standard features.,abstractText,[0],[0]
"Large-scale experiments on Chinese–English and German–English tasks show that our model is significantly better than the state-of-the-art hierarchical phrase-based (HPB) model and a recently improved dependency tree-to-string model on BLEU, METEOR and TER scores.",abstractText,[0],[0]
Experiments also suggest that our model has better capability to perform long-distance reordering and is more suitable for translating long sentences.,abstractText,[0],[0]
Dependency Graph-to-String Translation,title,[0],[0]
"Proceedings of NAACL-HLT 2013, pages 1051–1060, Atlanta, Georgia, 9–14 June 2013. c©2013 Association for Computational Linguistics",text,[0],[0]
"In modern theoretical linguistics, empty categories (ECs) are an important piece of machinery in representing the syntactic structure of a sentence and they are used to represent phonologically null elements such as dropped pronouns and traces of dislocated elements.",1 Introduction,[0],[0]
They have also found their way into largescale treebanks which have played an important role in advancing the state of the art in syntactic parsing.,1 Introduction,[0],[0]
"In phrase-structure treebanks, ECs have been used to indicate long-distance dependencies, discontinuous constituents, and certain dropped elements (Marcus et al., 1993; Xue et al., 2005).",1 Introduction,[0],[0]
"Together with labeled brackets and function tags, they make up the full syntactic representation of a sentence.
",1 Introduction,[0],[0]
The use of ECs captures some cross-linguistic commonalities and differences.,1 Introduction,[0],[0]
"For example, while both the Penn English TreeBank (PTB) (Marcus et al., 1993) and the Chinese TreeBank (CTB) (Xue
et al., 2005) use traces to represent the extraction site of a dislocated element, dropped pronouns (represented as *pro*s) are much more widespread in the CTB.",1 Introduction,[0],[0]
"This is because Chinese is a pro-drop language (Huang, 1984) that allows the subject to be dropped in more contexts than English does.",1 Introduction,[0],[0]
"While detecting and resolving traces is important to the interpretation of the syntactic structure of a sentence in both English and Chinese, the prevalence of dropped nouns in Chinese text gives EC detection added significance and urgency.",1 Introduction,[0],[0]
"They are not only an important component of the syntactic parse of a sentence, but are also essential to a wide range of NLP applications.",1 Introduction,[0],[0]
"For example, any meaningful tracking of entities and events in natural language text would have to include those represented by dropped pronouns.",1 Introduction,[0],[0]
"If Chinese is translated into a different language, it is also necessary to render these dropped pronouns explicit if the target language does not allow pro-drop.",1 Introduction,[0],[0]
"In fact, Chung and Gildea (2010) reported preliminary work that has shown a positive impact of automatic EC detection on statistical machine translation.
",1 Introduction,[0],[0]
Some ECs can be resolved to an overt element in the same text while others only have a generic reference that cannot be linked to any specific entity.,1 Introduction,[0],[0]
"Still others have a plausible antecedent in the text, but are not annotated due to annotation limitations.",1 Introduction,[0],[0]
"A common practice is to resolve ECs in two separate stages (Johnson, 2002; Dienes and Dubey, 2003b; Dienes and Dubey, 2003a; Campbell, 2004; Gabbard et al., 2006; Schmid, 2006; Cai et al., 2011).",1 Introduction,[0],[0]
"The first stage is EC detection, where empty categories are first located and typed.",1 Introduction,[0],[0]
"The second stage
1051
is EC resolution, where empty categories are linked to an overt element if possible.
",1 Introduction,[0],[0]
"In this paper we describe a novel approach to detecting empty categories in Chinese, using the CTB as training and test data.",1 Introduction,[0],[0]
"More concretely, EC detection involves (i) identifying the position of the EC, relative to some overt word tokens in the same sentence, and (ii) determining the type of EC, e.g., whether it is a dropped pronoun or a trace.",1 Introduction,[0],[0]
We focus on EC detection here because most of the ECs in the Chinese Treebank are either not resolved to an overt element or linked to another EC.,1 Introduction,[0],[0]
"For example, dropped pronouns (*pro*) are not resolved, and traces (*T*) in relative clauses are linked to an empty relative pronoun (*OP*).
",1 Introduction,[0],[0]
"In previous work, ECs are either represented linearly, where ECs are indexed to the following word (Yang and Xue, 2010) or attached to nodes in a phrase structure tree (Johnson, 2002; Dienes and Dubey, 2003b; Gabbard et al., 2006).",1 Introduction,[0],[0]
"In a linear representation where ECs are indexed to the following word, it is difficult to represent consecutive ECs because that will mean more than one EC will be indexed to the same word (making the classification task more complicated).",1 Introduction,[0],[0]
"While in English consecutive ECs are relatively rare, in Chinese this is very common.",1 Introduction,[0],[0]
"For example, it is often the case that an empty relative pronoun (*OP*) is followed immediately by a trace (*T*).",1 Introduction,[0],[0]
"Another issue with the linear representation of ECs is that it leaves unspecified where the EC should be attached, and crucial dependencies between ECs and other elements in the syntactic structure are not represented, thus limiting the utility of this task.
",1 Introduction,[0],[0]
"In a phrase structure representation, ECs are attached to a hierarchical structure and the problem of multiple ECs indexed to the same word token can be avoided because linearly consecutive ECs may be attached to different non-terminal nodes in a phrase structure tree.",1 Introduction,[0],[0]
"In a phrase structure framework, ECs are evaluated based on their linear position as well as on their contribution to the overall accuracy of the syntactic parse (Cai et al., 2011).
",1 Introduction,[0],[0]
"In the present work, we propose to look at EC detection in a dependency structure representation, where we define EC detection as (i) determining its linear position relative to the following word token, (ii) determining its head it is a dependent of, and (iii)
determining the type of EC.",1 Introduction,[0],[0]
Framing EC detection this way also requires a new evaluation metric.,1 Introduction,[0],[0]
"An EC is considered to be correctly detected if its linear position, its head, and its type are all correctly determined.",1 Introduction,[0],[0]
"We report experimental results that show even using this more stringent measure, our EC detection system achieved performance that improved significantly over the state-of-the-art results.
",1 Introduction,[0],[0]
The rest of the paper is organized as follows.,1 Introduction,[0],[0]
"In Section 2, we will describe how to represent ECs in a dependency structure in detail and present our approach to EC detection.",1 Introduction,[0],[0]
"In Section 3, we describe how linguistic information is encoded as features.",1 Introduction,[0],[0]
"In Section 4, we discuss our experimental setup and present our results.",1 Introduction,[0],[0]
"In Section 5, we describe related work.",1 Introduction,[0],[0]
Section 6 concludes the paper.,1 Introduction,[0],[0]
"In order to detect ECs anchored in a dependency tree, we first convert the phrase structure trees in the CTB into dependency trees.",2 Approach,[0],[0]
"After the conversion, each word token in a dependency tree, including the ECs, will have one and only one head (or parent).",2 Approach,[0],[0]
We then train a classifier to predict the position and type of ECs in the dependency tree.,2 Approach,[0],[0]
"Let W be a sequence of word tokens in a sentence, and T is syntactic parse tree for W , our task is to predict whether there is a tuple (h, t, e), such that h and t are word tokens in W , e is an EC, h is the head of e, and t immediately follows e. When EC detection is formulated as a classification task, each classification instance is thus a tuple (h, t).",2 Approach,[0],[0]
"The input to our classifier is T , which can either be a phrase structure tree or a dependency tree.",2 Approach,[0],[0]
"We choose to use a phrase structure tree because phrase structure parsers trained on the Chinese Treebank are readily available, and we also hypothesize that phrase structure trees have a richer hierarchical structure that can be exploited as features for EC detection.",2 Approach,[0],[0]
"According to the CTB bracketing guidelines (Xue and Xia, 2000), there are seven different types of ECs in the CTB.",2.1 Empty categories in the Chinese Treebank,[0],[0]
"Below is a brief description of the empty categories:
1.",2.1 Empty categories in the Chinese Treebank,[0],[0]
"*pro*: small pro, used to represent dropped pronouns.
2.",2.1 Empty categories in the Chinese Treebank,[0],[0]
"*PRO*: big PRO, used to represent shared elements in control structures or elements that have generic references.",2.1 Empty categories in the Chinese Treebank,[0],[0]
3.,2.1 Empty categories in the Chinese Treebank,[0],[0]
"*OP*: null operator, used to represent empty relative pronouns.",2.1 Empty categories in the Chinese Treebank,[0],[0]
4.,2.1 Empty categories in the Chinese Treebank,[0],[0]
*T*: trace left by movement such as topicalization and relativization.,2.1 Empty categories in the Chinese Treebank,[0],[0]
5.,2.1 Empty categories in the Chinese Treebank,[0],[0]
*RNR*: right node raising.,2.1 Empty categories in the Chinese Treebank,[0],[0]
6.,2.1 Empty categories in the Chinese Treebank,[0],[0]
*: trace left by passivization and raising.,2.1 Empty categories in the Chinese Treebank,[0],[0]
7.,2.1 Empty categories in the Chinese Treebank,[0],[0]
"*?*: missing elements of unknown category.
",2.1 Empty categories in the Chinese Treebank,[0],[0]
An example parse tree with ECs is shown in Figure 1.,2.1 Empty categories in the Chinese Treebank,[0],[0]
"In the example, there are two ECs, an empty relative pronoun (*OP*) and a trace (*T*), a common syntactic pattern for relative clauses in the CTB.",2.1 Empty categories in the Chinese Treebank,[0],[0]
"We convert the phrase structure parses in the CTB to dependency trees using the conversion tool that generated the Chinese data sets for the CoNLL 2009 Shared Task on multilingual dependency parsing and semantic role labeling (Hajič et al., 2009)1.",2.2 Converting phrase structure to dependency structure,[0],[0]
"While the Chinese data of CoNLL 2009 Shared Task does not include ECs, the tool has an option of preserving the ECs in the conversion process.",2.2 Converting phrase structure to dependency structure,[0],[0]
"As an example, the dependency tree in Figure 2 is converted from the phrase structure tree in Figure 1, with the ECs preserved.
",2.2 Converting phrase structure to dependency structure,[0],[0]
"1The tool can be downloaded at http://www.cs.brandeis.edu/ clp/ctb/ctb.html.
",2.2 Converting phrase structure to dependency structure,[0],[0]
"In previous work EC detection has been formulated as a classification problem with the target of the classification being word tokens (Yang and Xue, 2010; Chung and Gildea, 2010), or constituents in a parse tree (Gabbard et al., 2006).",2.2 Converting phrase structure to dependency structure,[0],[0]
"When word tokens are used as the target of classification, the task is to determine whether there is an EC before each word token, and what type EC it is.",2.2 Converting phrase structure to dependency structure,[0],[0]
"One shortcoming with that representation is that more than one EC can precede the same word token, as is the case in the example in Figure 1, where both *OP* and *T* precede 涉及 (“involve”).",2.2 Converting phrase structure to dependency structure,[0],[0]
"In fact, (Yang and Xue, 2010) takes the last EC when there is a sequence of ECs and as a result, some ECs will never get the chance to be detected.",2.2 Converting phrase structure to dependency structure,[0],[0]
Notice that this problem can be avoided in a dependency structure representation if we make the target of classification a tuple that consists of the following word token and the head of the EC.,2.2 Converting phrase structure to dependency structure,[0],[0]
"From Figure 2, it should be clear that while *OP* and *T* both precede the same word token涉 及",2.2 Converting phrase structure to dependency structure,[0],[0]
"(“involve”), they have different heads, which are 的 (DE) and涉及 respectively.
",2.2 Converting phrase structure to dependency structure,[0],[0]
Dependency-based EC detection also has other nice properties.,2.2 Converting phrase structure to dependency structure,[0],[0]
"For ECs that are arguments of their verbal head, when they are resolved to some overt element, the dependency between the referent of the EC and its head will be naturally established.",2.2 Converting phrase structure to dependency structure,[0],[0]
"This can be viewed as an alternative to the approach adopted by Levy and Manning (2004), where phrase structure parses are augmented to recover non-local dependencies.",2.2 Converting phrase structure to dependency structure,[0],[0]
Dependency structures are also easily decomposable into head/dependency pairs and this makes the evaluation more straightforward.,2.2 Converting phrase structure to dependency structure,[0],[0]
Each classification instance can be evaluated independently of other parts of the dependency structure.,2.2 Converting phrase structure to dependency structure,[0],[0]
"With pairs of tokens (h, t) as the classification target, all possible pairs in a sentence will have to be considered and there will be a large number of (h, t) tuples that are not associated with an EC, leading to a highly imbalanced data set.",2.3 One pass vs two passes,[0],[0]
One can conceive a two-pass scenario where we first make a binary decision of whether there is an empty category associated with the head in the first pass and then determine whether there is an EC associated with the tuple as well as the EC type in the second pass.,2.3 One pass vs two passes,[0],[0]
"The alternative is to have a one-pass model in which we
add a NONE category indicating there is no EC associated with the tuple.",2.3 One pass vs two passes,[0],[0]
"With the seven EC types presented earlier in this section, this will be an eightway classification problem.",2.3 One pass vs two passes,[0],[0]
There are reasons for either model: the one-pass model is simpler but in the two-pass model we can bring different sources of information to bear on each sub-problem.,2.3 One pass vs two passes,[0],[0]
Ultimately which model leads to better accuracy is an empirical question.,2.3 One pass vs two passes,[0],[0]
We experimented with both models and it turned out that they led to very similar results.,2.3 One pass vs two passes,[0],[0]
"In this paper, we report results from the simpler onepass model.",2.3 One pass vs two passes,[0],[0]
"We explored a wide range of features, all derived from the phrase structure parse tree (T ).",3 Features,[0],[0]
"With each classification instance being a tuple (h, t), the “pivots” for these features are h the head, t the word token following the EC, and p, the word token preceding the EC.",3 Features,[0],[0]
The features we tried fall into six broad groups that are all empirically confirmed to have made a positive contribution to our classification task.,3 Features,[0],[0]
"These are (i) horizontal features, (ii) vertical features, (iii) targeted grammatical constructions, (iv) head information, (v) transitivity features, and (vi) semantic role features.",3 Features,[0],[0]
"We obviously have looked at features used in previous work on Chinese EC detection, most notably (Yang and Xue, 2010), which has also adopted a classification-based approach, but because we frame our classification task very differently, we have to use very different features.",3 Features,[0],[0]
"However, there is a subset of features we used here that has at least a partial overlap with their features, and such features are clearly indicated with ∗.",3 Features,[0],[0]
"The first group of features we use can be described as horizontal features that exploit lexical context of the head (h), the word token following the EC (t),
and the word token before the EC (p) .",3.1 Horizontal features,[0],[0]
"These include different combinations of h, t and p, as well as their parts-of-speech.",3.1 Horizontal features,[0],[0]
"They also include various linear distance features between h and t. Below is the full list of lexical features:
1.",3.1 Horizontal features,[0],[0]
"∗The token string representation of h, t and p, as well as their part-of-speech tag (POS).",3.1 Horizontal features,[0],[0]
2.,3.1 Horizontal features,[0],[0]
"∗The POS combination of h and t, the POS combination of t and p.
3.",3.1 Horizontal features,[0],[0]
"The normalized word distance between h and t, with the values of this feature being same, immediately before, immediately after, near before, and near after, and other.
4.",3.1 Horizontal features,[0],[0]
"The verb distance between h and t, defined as the number of verbs that occur between h and t.
5.",3.1 Horizontal features,[0],[0]
"The comma distance between h and t, defined as the number of commas that occur between h and t.",3.1 Horizontal features,[0],[0]
Vertical features are designed to exploit the hierarchical structure of the syntactic tree.,3.2 Vertical features,[0],[0]
Our hierarchical features are based on the following observations.,3.2 Vertical features,[0],[0]
"An empty category is always located between its left frontier and right frontier, anchored by t and p.",3.2 Vertical features,[0],[0]
"Given the lowest common ancestor A of p and t, the right frontier is the path from t to A and the left frontier is the path from the p to A.",3.2 Vertical features,[0],[0]
"We also define a path feature from h to t, which constrains the distance between the EC and its head, just as it constrains the distance between a predicate and its argument in the semantic role labeling task (Gildea and Jurafsky, 2002).",3.2 Vertical features,[0],[0]
"Given the lowest common ancestor A′ of h and t, the path from h to t is the path from h to A′ and from A′ to t.
In Figure 3, assuming that t is 迅速 (“rapidly”) and h is 崛起 (“take off”), the vertical features ex-
tracted include:
1.",3.2 Vertical features,[0],[0]
"The string representation of the right frontier, AD↑ADVP↑VP↑IP↑VP
2.",3.2 Vertical features,[0],[0]
"The path from the head t to h, AD↑ADVP↑VP↓VP↓VV
3.",3.2 Vertical features,[0],[0]
"The path from the head h to A, VV↑VP↑VP↑IP↑VP.",3.2 Vertical features,[0],[0]
"Notice there is not always a path from h to A.
",3.2 Vertical features,[0],[0]
The vertical features are really a condensed representation of a certain syntactic configuration that helps to predict the presence or absence of an empty category as well as the empty category type.,3.2 Vertical features,[0],[0]
"For example, the right frontier of *PRO* in Figure 3 AD↑ADVP↑VP↑IP↑VP represents a subjectless IP.",3.2 Vertical features,[0],[0]
"Had there been an overt subject in the place of the *PRO*, the right frontier would have been AD↑ADVP↑VP↑IP.",3.2 Vertical features,[0],[0]
"Therefore, the vertical features are discriminative features that can help detect the presence or absence of an empty category.",3.2 Vertical features,[0],[0]
"The third group of features target specific, linguistically motivated grammatical constructions.",3.3 Targeted grammatical constructions,[0],[0]
The majority of features in this group hinge on the immediate IP (roughly corresponds to S in the PTB) ancestor of t headed by h.,3.3 Targeted grammatical constructions,[0],[0]
"These features are only invoked when t starts (or is on the left edge of) the immediate IP ancestor, and they are designed to capture the context in which the IP ancestor is located.",3.3 Targeted grammatical constructions,[0],[0]
This context can provide discriminative clues that may help identify the types of empty category.,3.3 Targeted grammatical constructions,[0],[0]
"For example, both *pro*s and *PRO*s tend to occur in the subject position of an IP, but the larger context of the
IP often determines the exact empty category type.",3.3 Targeted grammatical constructions,[0],[0]
"In Figure 3, the IP that has a *PRO* subject is the complement of a verb in a canonical object-control construction.",3.3 Targeted grammatical constructions,[0],[0]
"An IP can also be a sentential subject, the complement of a preposition or a localizer (also called postposition in the literature), or the complement in a CP (roughly SBAR in the PTB), etc.",3.3 Targeted grammatical constructions,[0],[0]
These different contexts tend to be associated with different types of empty categories.,3.3 Targeted grammatical constructions,[0],[0]
"The full list of features that exploit these contexts include:
1. ∗Whether",3.3 Targeted grammatical constructions,[0],[0]
t starts an IP 2.,3.3 Targeted grammatical constructions,[0],[0]
∗Whether,3.3 Targeted grammatical constructions,[0],[0]
t starts a subjectless IP 3.,3.3 Targeted grammatical constructions,[0],[0]
"The left sisters of the immediate IP parent that
t starts 4.",3.3 Targeted grammatical constructions,[0],[0]
"The right sisters of the immediate IP parent that
t starts 5.",3.3 Targeted grammatical constructions,[0],[0]
"The string representation of the governing verb
of the immediate IP parent that t starts 6.",3.3 Targeted grammatical constructions,[0],[0]
"Whether the IP started by t is the complement
of a localizer phrase 7.",3.3 Targeted grammatical constructions,[0],[0]
"Whether the immediate IP parent that t starts is
a sentential subject",3.3 Targeted grammatical constructions,[0],[0]
"Most ECs have a verb as its head, but when there is a coordination VP structure where more than one VP share an EC subject, only one such verb can be the head of this EC.",3.4 Head information,[0],[0]
The phrase structure to dependency structure conversion tool designates the first verb as the head of the coordinated VP and thus the head of the EC subject in the dependency structure.,3.4 Head information,[0],[0]
Other verbs have no chance of being the head.,3.4 Head information,[0],[0]
We use a VP head feature to capture this information.,3.4 Head information,[0],[0]
It is a binary feature indicating whether a verb can be a head.,3.4 Head information,[0],[0]
A transitivity lexicon has been extracted from the Chinese Treebank and it is used to determine the transitivity value of a word.,3.5 Transitivity features,[0],[0]
"A word can be transitive, intransitive, or unknown if it is not a verb.",3.5 Transitivity features,[0],[0]
Ditransitive verbs are small in number and are folded into transitive verbs.,3.5 Transitivity features,[0],[0]
Transitivity features are defined on h and constrained by word distance: it is only used when h immediately precedes t.,3.5 Transitivity features,[0],[0]
This feature category is intended to capture transitive verbs that are missing an object.,3.5 Transitivity features,[0],[0]
There are apparent connections between semantic role labeling and EC detection.,3.6 Semantic role features,[0],[0]
"The task of semantic role labeling is typically defined as one of detecting and classifying arguments for verbal or nominal predicates, with more work done so far on verbal than nominal predicates.",3.6 Semantic role features,[0],[0]
"Although empty categories are annotated as arguments to verbal predicates in linguistic resources such as the English (Palmer et al., 2005) and Chinese (Xue and Palmer, 2009)",3.6 Semantic role features,[0],[0]
"Propbanks, they are often left out in semantic role labeling systems trained on these resources.",3.6 Semantic role features,[0],[0]
"This is because the best performing semantic role labeling systems rely on syntactic features extracted from automatic parses (Gildea and Palmer, 2002; Punyakanok et al., 2005) and the parsers that produce them do not generally reproduce empty categories.",3.6 Semantic role features,[0],[0]
"As a result, current semantic role labeling systems can only recover explicit arguments.",3.6 Semantic role features,[0],[0]
"However, assuming that all the explicit arguments to a predicate are detected and classified, one can infer the empty arguments of a predicate from its explicit arguments, given a list of expected arguments for the predicate.",3.6 Semantic role features,[0],[0]
The list of expected arguments can be found in the “frame files” that are used to guide probank annotation.,3.6 Semantic role features,[0],[0]
We defined a semantic role feature category on h when it is a verb and the value of this feature is the semantic role labels for the EC arguments.,3.6 Semantic role features,[0],[0]
"Like transitivity features, this feature category is also constrained by word distance.",3.6 Semantic role features,[0],[0]
"It is only used when h immediately precedes t.
To extract semantic role features, we retrained a Chinese semantic role labeling system on the Chinese Propbank.",3.6 Semantic role features,[0],[0]
"We divided the Chinese Propbank data into 10 different subsets, and automatically assigned semantic roles to each subset with a system trained on the other nine subsets.",3.6 Semantic role features,[0],[0]
"Using the frame files for the Chinese Propbank, we are able to infer the semantic roles for the missing arguments and use them as features.",3.6 Semantic role features,[0],[0]
Our EC detection models are trained and evaluated on a subset of the Chinese TreeBank 6.0.,4.1 Experimental setup,[0],[0]
The training/development/test data split in our experiments is recommended in the CTB documentation.,4.1 Experimental setup,[0],[0]
"The
CTB file IDs for training, development and testing are listed in Table 1.",4.1 Experimental setup,[0],[0]
"The development data is used for feature selection and tuning, and results are reported on the test set.
",4.1 Experimental setup,[0],[0]
"As discussed in Section 2, the gold standard dependency structure parses are converted from the CTB parse trees, with the ECs preserved.",4.1 Experimental setup,[0],[0]
"From these gold standard parse trees, we extract triples of (e, h, t) where e is the EC type, h is (the position of) the head of the EC, and t is (the position of) the word token following the EC.",4.1 Experimental setup,[0],[0]
"During the training phrase, features are extracted from automatic phrase structure parses and paired with these triples.",4.1 Experimental setup,[0],[0]
"The automatic phrase structure parses are produced by the the Berkeley parser2 with a 10-fold cross-validation, which each fold parsed using a model trained on the other nine folds.",4.1 Experimental setup,[0],[0]
"Measured by the ParsEval metric (Black et al., 1991), the parsing accuracy on the CTB test set stands at 83.63% (F-score), with a precision of 85.66% and a recall of 81.69%.",4.1 Experimental setup,[0],[0]
"We chose to train a Maximum Entropy classifier using the Mallet toolkit3 (McCallum, 2002) to detect ECs.",4.1 Experimental setup,[0],[0]
"We use standard metrics of precision, recall and Fmeasure in our evaluation.",4.2 Evaluation metric,[0],[0]
"In a dependency structure representation, evaluation is very straightforward because individual arcs from the dependency tree can be easily decomposed.",4.2 Evaluation metric,[0],[0]
"An EC is considered to be correctly detected if it is attached to the correct head h, correctly positioned relative to t, and correctly typed.",4.2 Evaluation metric,[0],[0]
"This is a more stringent measure than metrics proposed in previous work, which evaluates EC detection based on its position and type without considering the head it is a dependent of.",4.2 Evaluation metric,[0],[0]
"There are 1,838 total EC instances in the test set, and if we follow (Yang and Xue, 2010) and collapse all
2http://code.google.com/p/berkeleyparser 3http://mallet.cs.umass.edu
consecutive ECs before the same word token to one, we will end up with a total EC count of 1,352, and this is also the EC count used by (Cai et al., 2011) in their evaluation.",4.3 Results,[0],[0]
"On the dependency-based representation adopted here, after collapsing all consecutive ECs before the same word token AND attached to the same head to one, we end up with a total EC count of 1,765.",4.3 Results,[0],[0]
"The distribution of the ECs in the test set are presented in Table 2, with the EC count per type from (Yang and Xue, 2010) in parenthesis if it is different.",4.3 Results,[0],[0]
"The number of *OP*s, in particular, has increased dramatically from 134 to 527, and this is because a null relative pronoun (*OP*) immediately followed by a trace (*T*) in the subject position of a relative clause is a very common pattern in the Chinese Treebank, as illustrated in Figure 2.",4.3 Results,[0],[0]
"In (Yang and Xue, 2010), the *OP*-*T* sequences are collapsed into one, and only the *T*s are counted.",4.3 Results,[0],[0]
"That leads to the much smaller count of *OP*s.
",4.3 Results,[0],[0]
Our results are shown in Table 3.,4.3 Results,[0],[0]
These results are achieved by using the full feature set presented in Section 3.,4.3 Results,[0],[0]
"The overall accuracy by F1-measure is 0.574 if we assume there can only be one EC associated with a given (h, t) tuple and hence the total EC count in the gold standard is 1,765, or 0.561 if we factor in all the EC instances and use the higher total count of 1,838, which lowers the recall.",4.3 Results,[0],[0]
"If instead we use the total EC count of 1,352 that was used in previous work (Yang and Xue, 2010; Cai et al., 2011), then the F1-measure is 0.660 because the lower total count greatly improves the recall.",4.3 Results,[0],[0]
"This is a significant improvement over the best previous result reported by Cai et al (2011), which is an F1 measure of 0.586 on the same test set but based on a less stringent metric of just comparing the EC position and type, without considering whether the EC is attached to the correct head.
",4.3 Results,[0],[0]
There are several observations worth noting from these results.,4.3 Results,[0],[0]
"One is that our method performs particularly well on null relative pronouns (*OP*) and
traces (*T*), indicating that our features are effective in capturing information from relative clause constructions.",4.3 Results,[0],[0]
This accounts for most of the gain compared with previous approaches.,4.3 Results,[0],[0]
"The *OP* category, in particular, benefits most from the dependency representation because it is collapsed to the immediately following *T* in previous approaches and does not even get a chance to be detected.",4.3 Results,[0],[0]
"On the other hand, our model did poorly on dropped pronouns (*pro*).",4.3 Results,[0],[0]
"One possible explanation is that *pro*s generally occupy subject positions in a sentence and is attached as an immediate child of an IP, which is the top-level structure of a sentence that an automatic parser tends to get wrong.",4.3 Results,[0],[0]
"Unlike *PRO*, it is not constrained to well-defined grammatical constructions such as subject- and objectcontrol structures.
",4.3 Results,[0],[0]
"To evaluate the effectiveness of our features, we also did an ablation study on the contribution of different feature groups.",4.3 Results,[0],[0]
The most effective features are the ones when taken out lead to the most drop in accuracy.,4.3 Results,[0],[0]
"As should be clear from Table 4, the most effective features are the horizontal features, followed by vertical structures.",4.3 Results,[0],[0]
Features extracted from targeted grammatical constructions and features representing whether h is the head of a coordinated VP lead to modest improvement.,4.3 Results,[0],[0]
Transitivity and semantic role features make virtually no difference at all.,4.3 Results,[0],[0]
We believe it is premature to conclude that they are not useful.,4.3 Results,[0],[0]
"Possible explanations for their lack of effectiveness is that they are used in very limited context and the accuracy of the semantic role label-
ing system is not sufficient to make a difference.",4.3 Results,[0],[0]
"The work reported here follows a fruitful line of research on EC detection and resolution, mostly in English.",5 Related Work,[0],[0]
"Empty categories have initially been left behind in research on syntactic parsing (Collins, 1999; Charniak, 2001) for efficiency reasons, but more recent work has shown that EC detection can be effectively integrated into the parsing process (Schmid, 2006; Cai et al., 2011).",5 Related Work,[0],[0]
"In the meantime, both pre-processing and post-processing approaches have been explored in previous work as alternatives.",5 Related Work,[0],[0]
Johnson (2002) has showed that empty categories can be added to the skeletal parses with reasonable accuracy with a simple pattern-matching algorithm in a postprocessing step.,5 Related Work,[0],[0]
Dienes and Dubey (2003b; 2003a) achieved generally superior accuracy using a machine learning framework without having to refer to the syntactic structure in the skeletal parses.,5 Related Work,[0],[0]
"They described their approach as a pre-processing step for parsing because they only use as features morphosyntactic clues (passives, gerunds and to-infinitives) that can be found in certain function words and partof-speech tags.",5 Related Work,[0],[0]
"Even better results, however, were obtained by Campbell (2004) in a postprocessing step that makes use of rules inspired by work in theoretical linguistics.",5 Related Work,[0],[0]
"Gabbard et al (2006) reported further improvement largely by recasting the Campbell rules as features to seven different machine learning classifiers.
",5 Related Work,[0],[0]
We adopted a machine-learning based postprocessing approach based on insights gained from prior work in English and on Chinese-specific considerations.,5 Related Work,[0],[0]
"All things being equal, we believe that a machine learning approach that can exploit partial
information is more likely to succeed than deterministic rules that have to make reference to morphosyntactic clues such as to-infinitives and gerunds that are largely non-existent in Chinese.",5 Related Work,[0],[0]
"Without these clues, we believe a preprocessing approach that does not take advantage of skeletal parses is unlikely to succeed either.",5 Related Work,[0],[0]
The work we report here also builds on emerging work in Chinese EC detection.,5 Related Work,[0],[0]
Yang and Xue (2010) reported work on detecting just the presence and absence of empty categories without further classifying them.,5 Related Work,[0],[0]
Chung and Gildea (2010) reported work on just detecting just a small subset of the empty categories posited in the Chinese TreeBank.,5 Related Work,[0],[0]
"Kong and Zhou (2010) worked on Chinese zero anaphora resolution, where empty category detection is a subtask.",5 Related Work,[0],[0]
"More recently, Cai et al (2011) has successfully integrated EC detection into phrasestructure based syntactic parsing and reported stateof-the-art results in both English and Chinese.",5 Related Work,[0],[0]
We described a novel approach to detecting empty categories (EC) represented in dependency trees and a new metric for measuring EC detection accuracy.,6 Conclusions and Future Work,[0],[0]
"The new metric takes into account not only the position and type of an EC, but also the head it is a dependent of in a dependency structure.",6 Conclusions and Future Work,[0],[0]
We also proposed new features that are more suited for this new approach.,6 Conclusions and Future Work,[0],[0]
"Tested on a subset of the Chinese Treebank, we show that our system improved significantly over the best previously reported results despite using a more stringent evaluation metric, with most of the gain coming from an improved representation.",6 Conclusions and Future Work,[0],[0]
"In the future, we intend to work toward resolving ECs to their antecedents when EC detection can be done with adequate accuracy.",6 Conclusions and Future Work,[0],[0]
"We also plan to test our approach on the Penn (English) Treebank, with the first step being converting the Penn Treebank to a dependency representation with the ECs preserved.",6 Conclusions and Future Work,[0],[0]
This work is supported by the National Science Foundation via Grant No. 0910532 entitled“Richer Representations for Machine Translation”.,Acknowledgments,[0],[0]
"All views expressed in this paper are those of the authors and do not necessarily represent the
view of the National Science Foundation.",Acknowledgments,[0],[0]
We describe a novel approach to detecting empty categories (EC) as represented in dependency trees as well as a new metric for measuring EC detection accuracy.,abstractText,[0],[0]
"The new metric takes into account not only the position and type of an EC, but also the head it is a dependent of in a dependency tree.",abstractText,[0],[0]
We also introduce a variety of new features that are more suited for this approach.,abstractText,[0],[0]
"Tested on a subset of the Chinese Treebank, our system improved significantly over the best previously reported results even when evaluated with this more stringent metric.",abstractText,[0],[0]
Dependency-based empty category detection via phrase structure trees,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2431–2441 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2431",text,[0],[0]
Semantic parsing is a fundamental task within the field of natural language processing (NLP).,1 Introduction,[0],[0]
Consider a natural language (NL) sentence and its corresponding meaning representation (MR) as illustrated in Figure 1.,1 Introduction,[0],[0]
Semantic parsing aims to transform the natural language sentences into machine interpretable meaning representations automatically.,1 Introduction,[0],[0]
The task has been popular for decades and keeps receiving significant attention from the NLP community.,1 Introduction,[0],[0]
"Various systems (Zelle and Mooney, 1996; Kate et al., 2005; Zettlemoyer and Collins, 2005; Liang et al., 2011) were proposed over the years to deal with different types of semantic representations.",1 Introduction,[0],[0]
"Such models include structure-based models (Wong and Mooney, 2006; Lu et al., 2008;
1We make our system and code available at http:// statnlp.org/research/sp.
",1 Introduction,[0],[0]
"Kwiatkowski et al., 2010; Jones et al., 2012) and neural network based models (Dong and Lapata, 2016; Cheng et al., 2017).
",1 Introduction,[0],[0]
"Following various previous research efforts (Wong and Mooney, 2006; Lu et al., 2008; Jones et al., 2012), in this work, we adopt a popular class of semantic formalism – logical forms that can be equivalently represented as tree structures.",1 Introduction,[0],[0]
The tree representation of an example MR is shown in the middle of Figure 1.,1 Introduction,[0],[0]
One challenge associated with building a semantic parser is that the exact correspondence between the words and atomic semantic units are not explicitly given during the training phase.,1 Introduction,[0],[0]
The key to the building of a successful semantic parsing model lies in the identification of a good joint latent representation of both the sentence and its corresponding semantics.,1 Introduction,[0],[0]
"Example joint representations proposed in the literature include a chart used in phrase-based translation (Wong and Mooney, 2006), a constituency tree-like representation known as hybrid tree (Lu et al., 2008), and a CCG-based derivation tree (Kwiatkowski et al., 2010).
",1 Introduction,[0],[0]
"Previous research efforts have shown the effec-
tiveness of using dependency structures to extract semantic representations (Debusmann et al., 2004; Cimiano, 2009; Bédaride and Gardent, 2011; Stanovsky et al., 2016).",1 Introduction,[0],[0]
"Recently, Reddy et al. (2016, 2017) proposed a model to construct logical representations from sentences that are parsed into dependency structures.",1 Introduction,[0],[0]
Their work demonstrates the connection between the dependency structures of a sentence and its underlying semantics.,1 Introduction,[0],[0]
"Although their setup and objectives are different from ours where externally trained dependency parsers are assumed available and their system was trained to use the semantics for a specific down-stream task, the success of their work motivates us to propose a novel joint representation that can explicitly capture dependency structures among words for the semantic parsing task.
",1 Introduction,[0],[0]
"In this work, we propose a new joint representation for both semantics and words, presenting a new model for semantic parsing.",1 Introduction,[0],[0]
"Our main contributions can be summarized as follows:
• We present a novel dependency-based hybrid tree representation that captures both words and semantics in a joint manner.",1 Introduction,[0],[0]
"Such a dependency tree reveals semantic dependencies between words which are easily interpretable.
",1 Introduction,[0],[0]
• We show that exact dynamic programming algorithms for inference can be designed on top of our new representation.,1 Introduction,[0],[0]
"We further show that the model can be integrated with neural networks for improved effectiveness.
",1 Introduction,[0],[0]
• Extensive experiments conducted on the standard multilingual GeoQuery dataset show that our model outperforms the state-of-theart models on 7 out of 8 languages.,1 Introduction,[0],[0]
"Further analysis confirms the effectiveness of our dependency-based representation.
",1 Introduction,[0],[0]
"To the best of our knowledge, this is the first work that models the semantics as latent dependencies between words for semantic parsing.",1 Introduction,[0],[0]
The literature on semantic parsing has focused on various types of semantic formalisms.,2 Related Work,[0],[0]
"The λ-calculus expressions (Zettlemoyer and Collins, 2005) have been popular and widely used in semantic parsing tasks over recent years (Dong and Lapata, 2016; Gardner and Krishnamurthy, 2017; Reddy et al., 2016, 2017; Susanto and Lu, 2017a; Cheng et al., 2017).",2 Related Work,[0],[0]
"Dependency-based composi-
tional semantics (DCS)2 was introduced by Liang et al. (2011), whose extension, λ-DCS, was later proposed by Liang (2013).",2 Related Work,[0],[0]
"Various models (Berant et al., 2013; Wang et al., 2015; Jia and Liang, 2016) on semantic parsing with the λ-DCS formalism were proposed.",2 Related Work,[0],[0]
"In this work, we focus on the tree-structured semantic formalism which has been examined by various research efforts (Wong and Mooney, 2006; Kate and Mooney, 2006; Lu et al., 2008; Kwiatkowski et al., 2010; Jones et al., 2012; Lu, 2014; Zou and Lu, 2018).
",2 Related Work,[0],[0]
Wong and Mooney (2006) proposed the WASP semantic parser that regards the task as a phrasebased machine translation problem.,2 Related Work,[0],[0]
Lu et al. (2008) proposed a generative process to generate natural language words and semantic units in a joint model.,2 Related Work,[0],[0]
The resulting representation is called hybrid tree where both natural language words and semantics are encoded into a joint representation.,2 Related Work,[0],[0]
"The UBL-s (Kwiatkowski et al., 2010) parser applied the CCG grammar (Steedman, 1996) to model the joint representation of both semantic units and contiguous word sequences which do not overlap with one another.",2 Related Work,[0],[0]
Jones et al. (2012) applied a generative process with Bayesian tree transducer and their model also simultaneously generates the meaning representations and natural language words.,2 Related Work,[0],[0]
"Lu (2014, 2015) proposed a discriminative version of the hybrid tree model of (Lu et al., 2008) where richer features can be captured.",2 Related Work,[0],[0]
Dong and Lapata (2016) proposed a sequence-totree model using recurrent neural networks where the decoder can branch out to produce tree structures.,2 Related Work,[0],[0]
"Susanto and Lu (2017b) augmented the discriminative hybrid tree model with multilayer perceptron and achieved state-of-the-art performance.
",2 Related Work,[0],[0]
There exists another line of work that applies given syntactic dependency information to semantic parsing.,2 Related Work,[0],[0]
Titov and Klementiev (2011) decomposed a syntactic dependency tree into fragments and modeled the semantics as relations between the fragments.,2 Related Work,[0],[0]
Poon (2013) learned to derive semantic structures based on syntactic dependency trees predicted by the Stanford dependency parser.,2 Related Work,[0],[0]
"Reddy et al. (2016, 2017) proposed a linguistically motivated procedure to transform syntactic dependencies into logical forms.",2 Related Work,[0],[0]
Their semantic parsing performance relies on the quality of the syntactic dependencies.,2 Related Work,[0],[0]
"Unlike such efforts, we do not re-
2Unlike ours, their work captures dependencies between semantic units but not natural language words.
",2 Related Work,[0],[0]
"Sentence: What rivers do not run through Tennessee ?
",2 Related Work,[0],[0]
"quire external syntactic dependencies, but model the semantic units as latent dependencies between natural language words.",2 Related Work,[0],[0]
"The variable-free semantic representations in the form of FunQL (Kate et al., 2005) used by the defacto GeoQuery dataset (Zelle and Mooney, 1996) encode semantic compositionality of the logical forms (Cheng et al., 2017).",3.1 Variable-free Semantics,[0],[0]
"In the tree-structured semantic representations as illustrated in Figure 1, each tree node is a semantic unit of the following form:
",3.1 Variable-free Semantics,[0],[0]
"mi ≡ τα : pα(τ∗β)
where mi denotes the complete semantic unit, which consists of semantic type τα, function symbol pα and an argument list of semantic types τ∗β (here ∗ denotes that there can be 0, 1, or 2 semantic types in the argument list.",3.1 Variable-free Semantics,[0],[0]
This number is known as the arity of mi).,3.1 Variable-free Semantics,[0],[0]
Each semantic unit can be regarded as a function that takes in other (partial) semantic representations of certain types as arguments and returns a semantic representation of a specific type.,3.1 Variable-free Semantics,[0],[0]
"For example in Figure 1, the root unit is represented by m1, the type of this unit is QUERY, the function name is answer and it has a single argument RIVER which is a semantic type.",3.1 Variable-free Semantics,[0],[0]
"With recursive function composition, we can obtain a complete MR as shown in Figure 1.",3.1 Variable-free Semantics,[0],[0]
"To jointly encode the tree-structured semantics m and a natural language sentence n, we in-
troduce our novel dependency-based hybrid tree.",3.2 Dependency-based Hybrid Trees,[0],[0]
Figure 2 (right) shows the two equivalent ways of visualizing the dependency-based hybrid tree based on the example given in Figure 1.,3.2 Dependency-based Hybrid Trees,[0],[0]
"In this example, m is the tree-structured semantics m1(m2(m3,m4(m5(m6))))",3.2 Dependency-based Hybrid Trees,[0],[0]
"and n is the sentence {w1, w2, · · · , w8}3.",3.2 Dependency-based Hybrid Trees,[0],[0]
"Our dependency-based hybrid tree t consists of a set of dependencies between the natural language words, each of which is labeled with a semantic unit.",3.2 Dependency-based Hybrid Trees,[0],[0]
"Formally, a dependency arc is represented as (wp, wc,mi), wherewp is the parent of this dependency, wc is the child, and mi is the semantic unit that serves as the label for the dependency arc.",3.2 Dependency-based Hybrid Trees,[0],[0]
A valid dependency-based hybrid tree (with respect to a given semantic representation) allows one to recover the correct semantics from it.,3.2 Dependency-based Hybrid Trees,[0],[0]
"Thus, one constraint is that for any two adjacent dependencies (wp, wc,mi) and (w′p, w ′ c,mj), where wc ≡ w′p, mi must be the parent of mj in the tree-structured representation m. For example, in Figure 2, the dependencies (not, through, m4) and (through, Tennessee, m5) satisfy the above condition.",3.2 Dependency-based Hybrid Trees,[0],[0]
"However, we cannot replace (through, Tennessee, m5) with, for example, (through, Tennessee, m6), since m6 is not the child of m4.",3.2 Dependency-based Hybrid Trees,[0],[0]
"Furthermore, the number of children for a word in the dependency tree should be consistent with the arity of the corresponding semantic unit that points to it.",3.2 Dependency-based Hybrid Trees,[0],[0]
"For example, “not” has 2 children in our dependency-based hybrid tree representation because the semantic unit m2 (i.e., RIVER : exclude (RIVER, RIVER)) has arity 2.",3.2 Dependency-based Hybrid Trees,[0],[0]
"Also, “rivers” is the leaf as m3, which points to it, has arity 0.",3.2 Dependency-based Hybrid Trees,[0],[0]
"We will discuss in Section 3.3
3We also introduce a special token “root” as w0.
on how to derive the set of allowable dependencybased hybrid trees for a given (m,n) pair.
",3.2 Dependency-based Hybrid Trees,[0],[0]
"To understand the potential advantages of our new joint representation, we compare it with the relaxed hybrid tree representation (Lu, 2014), which is illustrated on the left of Figure 2.",3.2 Dependency-based Hybrid Trees,[0],[0]
"We highlight some similarities and differences between the two representations from the span level and word level perspectives.
",3.2 Dependency-based Hybrid Trees,[0],[0]
"In a relaxed hybrid tree representation, words and semantic units jointly form a constituency tree-like structure, where the former are leaves and the latter are internal nodes of such a joint representation.",3.2 Dependency-based Hybrid Trees,[0],[0]
Such a representation is able to capture alignment between the natural language words and semantics at the span level.4,3.2 Dependency-based Hybrid Trees,[0],[0]
"For example, m2 covers the span from “rivers” to “Tennessee”, which allows the interactions between the semantic unit and the span to be captured.",3.2 Dependency-based Hybrid Trees,[0],[0]
"Similarly, in our dependency-based hybrid tree, such span level word-semantics correspondence can also be captured.",3.2 Dependency-based Hybrid Trees,[0],[0]
"For example, the arc between “not” and “through” is labeled by the semantic unitm4.",3.2 Dependency-based Hybrid Trees,[0],[0]
"This also allows the interactions betweenm4 and words within the span from “not” to “through” to be captured.
",3.2 Dependency-based Hybrid Trees,[0],[0]
"While both models are able to capture the spanlevel correspondence between words and semantics, we can observe that in the relaxed hybrid tree, some words within the span are more directly related to the semantic unit (e.g., “do not” are more related to m2) and some are not.",3.2 Dependency-based Hybrid Trees,[0],[0]
"Specifically, in their representation, the span level information assigned to the parent semantic unit always contains the span level information assigned to all its child semantic units.",3.2 Dependency-based Hybrid Trees,[0],[0]
This may not always be desirable and may lead to irrelevant features.,3.2 Dependency-based Hybrid Trees,[0],[0]
"In fact, Lu (2014) also empirically showed that the spanlevel features may not always be helpful in their representation.",3.2 Dependency-based Hybrid Trees,[0],[0]
"In contrast, in our dependencybased hybrid tree, the span covered by m2 is from “What” to “not”, which only consists of the span level information associated with its first child semantic units.",3.2 Dependency-based Hybrid Trees,[0],[0]
"Therefore, our representation is
4We refer readers to (Lu, 2014) for more details.
more flexible in capturing the correspondence between words and semantics at the span level, allowing the model to choose the relevant span for features.
",3.2 Dependency-based Hybrid Trees,[0],[0]
"Furthermore, our representation can also capture precise interactions between words through dependency arcs labeled with semantic units.",3.2 Dependency-based Hybrid Trees,[0],[0]
"For example, the semantic unit m4 on the dependency arc from “not” to “through” in our representation can be used to capture their interactions.",3.2 Dependency-based Hybrid Trees,[0],[0]
"However, such information could not be straightforwardly captured in a relaxed hybrid tree, which is essentially a constituency tree-like representation.",3.2 Dependency-based Hybrid Trees,[0],[0]
"In the same example, consider the word “not” that bridges two arcs labeled by m2 and m4.",3.2 Dependency-based Hybrid Trees,[0],[0]
Lexical features defined over such arcs can be used to indirectly capture the interactions between semantic units and guide the tree construction process.,3.2 Dependency-based Hybrid Trees,[0],[0]
"We believe such properties can be beneficial in practice, especially for certain languages.",3.2 Dependency-based Hybrid Trees,[0],[0]
We will examine their significance in our experiments later.,3.2 Dependency-based Hybrid Trees,[0],[0]
"To define the set of allowable dependency-based hybrid tree representation so as to allow us to perform exact inference later, we introduce the dependency patterns as shown in Table 1.",3.3 Dependency Patterns,[0],[0]
"We use A, B or C to denote the abstract semantic units with arity 0, 1, and 2, respectively.",3.3 Dependency Patterns,[0],[0]
"We use W to denote a contiguous word span, and X and Y to denote the first and second child semantic unit, respectively.
",3.3 Dependency Patterns,[0],[0]
We explain these patterns with concrete cases in Figure 3 based on the example in Figure 2.,3.3 Dependency Patterns,[0],[0]
"For the first case, the semantic unit m3 has arity 0, the pattern involved is WW, indicating both the lefthand and right-hand sides of “rivers” (under the dependency arc with semantic unit m3) are just word spans (W, whose length could be zero).",3.3 Dependency Patterns,[0],[0]
"In the second case, the semantic unit m4 has arity 1, the pattern involved is WX, indicating the lefthand side of “through” (under the arc of semantic unit m4) is a word span and the right-hand side should be handled by the first child of m4 in the
semantic tree, which is m5 in this case.",3.3 Dependency Patterns,[0],[0]
"In the third case, the semantic unit m2 has two arguments, and the pattern involved in the example is XY, meaning the left-hand and right-hand sides should be handled by the first and second child semantic units (i.e., m3 and m4),",3.3 Dependency Patterns,[0],[0]
"respectively.5 The final case illustrates that we also allow self-loops on our dependency-based hybrid trees, where an arc can be attached to a single word.6 To avoid an infinite number of self-loops over a word, we set a maximum depth c to restrict the maximum number of recurrences, which is similar to the method introduced in (Lu, 2015).
",3.3 Dependency Patterns,[0],[0]
"Based on the dependency patterns, we are able to define the set of all possible allowable dependency-based hybrid tree representations.",3.3 Dependency Patterns,[0],[0]
Each representation essentially belongs to a class of projective dependency trees where semantic units appear on the dependency arcs and (some of the) words are selected as nodes.,3.3 Dependency Patterns,[0],[0]
The semantic tree can be constructed by following the arcs while referring to the dependency patterns involved.,3.3 Dependency Patterns,[0],[0]
"Given the natural language words n, our task is to predict m, which is a tree-structured meaning representation, consisting of a set of semantic units as the nodes in the semantic tree.",3.4 Model,[0],[0]
"We use t to denote a dependency-based hybrid tree (as shown in Figure 2), which jointly encodes both natural language words and the gold meaning representation.",3.4 Model,[0],[0]
"Let T (n,m) denote all the possible dependencybased hybrid trees that contain the natural language words n and the meaning representation m. We adopt the widely-used structured prediction model conditional random fields (CRF) (Lafferty et al., 2001).",3.4 Model,[0],[0]
"The probability of a possible meaning representation m and dependency-based hybrid tree t for a sentence n is given by:
Pw(m, t|n) = ew·f(n,m,t)∑
m′,t′∈T (n,m′)",3.4 Model,[0],[0]
"e w·f(n,m′,t′)
where f(n,m, t) is the feature vector defined over the (n,m, t) tuple, and w is the parameter vector.",3.4 Model,[0],[0]
"Since we do not have the knowledge of the “true” dependencies during training, t is regarded as a latent-variable in our model.",3.4 Model,[0],[0]
"We marginalize
5Analogously, the pattern YX would mean m4 handles the left-hand side and m3 right-hand side.
",3.4 Model,[0],[0]
"6The limitations associated with disallowing such a pattern have been discussed in the previous work of (Lu, 2015).
",3.4 Model,[0],[0]
"t in the above equation and the resulting model is a latent-variable CRF (Quattoni et al., 2005):
Pw(m|n) =",3.4 Model,[0],[0]
"∑
t∈T (n,m)
Pw(m, t|n)
",3.4 Model,[0],[0]
"=
∑ t∈T",3.4 Model,[0],[0]
"(n,m) e
w·f(n,m,t)∑ m′,t′∈T (n,m′)",3.4 Model,[0],[0]
"e w·f(n,m′,t′)
(1)
",3.4 Model,[0],[0]
"Given a datasetD of (n,m) pairs, our objective is to minimize the negative log-likelihood:7
L(w) =",3.4 Model,[0],[0]
"− ∑
(n,m)∈D
log ∑
t∈T (n,m)
Pw(m, t|n) (2)
The gradient for model parameter wk is:
∂L(w)",3.4 Model,[0],[0]
"∂wk
= ∑
(n,m)∈D ∑",3.4 Model,[0],[0]
"m′,t EPw(m′,t|n)[fk(n,m, t)]
",3.4 Model,[0],[0]
"− ∑
(n,m)∈D ∑ t EPw(t|n,m)[fk(n,m, t)]
where fk(n,m, t) represents the number of occurrences of the k-th feature.",3.4 Model,[0],[0]
"With both the objective and gradient above, we can minimize the objective function with standard optimizers, such as L-BFGS (Liu and Nocedal, 1989) and stochastic gradient descent.",3.4 Model,[0],[0]
Calculation of these expectations involves all possible dependency-based hybrid trees.,3.4 Model,[0],[0]
"As there are exponentially many such trees, an efficient inference procedure is required.",3.4 Model,[0],[0]
We will present our efficient algorithm to perform exact inference for learning and decoding in the next section.,3.4 Model,[0],[0]
"We propose dynamic-programming algorithms to perform efficient and exact inference, which will be used for calculating the objective and gradients discussed in the previous section.",3.5 Learning and Decoding,[0],[0]
"The algorithms are inspired by the inside-outside style algorithm (Baker, 1979), graph-based dependency parsing (Eisner, 2000; Koo and Collins, 2010; Shi et al., 2017), and the relaxed hybrid tree model (Lu, 2014, 2015).",3.5 Learning and Decoding,[0],[0]
"As discussed in Section 3.3, our latent dependency trees are projective as in traditional dependency parsing (Eisner, 1996; Nivre and Scholz, 2004; McDonald et al., 2005) – the dependencies are non-crossing with respect to the word order (see bottom of Figure 1).
",3.5 Learning and Decoding,[0],[0]
"7We ignore the L2 regularization term for brevity.
",3.5 Learning and Decoding,[0],[0]
"The objective function in Equation 2 can be further decomposed into the following form8:
L(w) =",3.5 Learning and Decoding,[0],[0]
"− ∑
(n,m)∈D
log ∑
t∈T (n,m)
ew·f(n,m,t)
+ ∑
(n,m)∈D
log ∑
m′,t′∈T (n,m′)
ew·f(n,m ′,t′)
We can see the first term is essentially the combined score of all the possible latent structures containing the pair (n,m).",3.5 Learning and Decoding,[0],[0]
The second term is the combined score for all the possible latent structures containing n.,3.5 Learning and Decoding,[0],[0]
"We show how such scores can be calculated in a factorized manner, based on the fact that we can recursively decompose a dependency-based hybrid tree based on the dependency patterns we introduced.
",3.5 Learning and Decoding,[0],[0]
"Formally, we introduce two interrelated dynamic-programming structures that are similar to those used in graph-based dependency parsing (Eisner, 2000; Koo and Collins, 2010; Shi et al., 2017), namely complete span and complete arc span.",3.5 Learning and Decoding,[0],[0]
Figure 4a shows an example of complete span (left) and complete arc span (right).,3.5 Learning and Decoding,[0],[0]
"The complete span (over [i, j]) consists of a headword (at i) and its descendants on one side (they altogether form a subtree), a dependency pattern and a semantic unit.",3.5 Learning and Decoding,[0],[0]
"The complete arc span is a span (over [i, j]) with a dependency between the headword (at i) and the modifier (at k).",3.5 Learning and Decoding,[0],[0]
"We use Ci,j,p,m to denote a complete span, where i and j represent the indices of the headword and endpoint, p is the dependency pattern and m is the semantic unit.",3.5 Learning and Decoding,[0],[0]
"Analogously, we use Ai,k,j,p,m to denote a complete arc span where i and k are used to denote the additional dependency from the word at the i-th position as headword to the word at the k-th position as modifier.
",3.5 Learning and Decoding,[0],[0]
"As we can see from the derivation in Figure 4, each type of span can be constructed from smaller spans in a bottom-up manner.",3.5 Learning and Decoding,[0],[0]
Figure 4a shows that a complete span is constructed from a complete arc span following the dependency patterns in Table 1.,3.5 Learning and Decoding,[0],[0]
Figure 4b shows a complete arc span can be simply constructed from two smaller complete spans based on the dependency pattern.,3.5 Learning and Decoding,[0],[0]
"In Figure 4c and 4d, we further show how such two complete spans with pattern X (or Y) and W can be constructed.",3.5 Learning and Decoding,[0],[0]
"Figure 4c illustrates how to model a transition from one semantic unit to another where
8Regularization term is excluded for brevity.
",3.5 Learning and Decoding,[0],[0]
the parent is m1 and the child is m2 in the semantic tree.,3.5 Learning and Decoding,[0],[0]
"If m2 has arity 1, then the pattern is B following the dependency patterns in Table 1.",3.5 Learning and Decoding,[0],[0]
"For spans with a single word, we use the lowercase w as the pattern to indicate this fact, as shown in Figure 4d.",3.5 Learning and Decoding,[0],[0]
They are the atomic spans used for building larger spans.,3.5 Learning and Decoding,[0],[0]
"As the complete span in Figure 4d is associated with pattern W, which means the words within this span are under the semantic unit m1, we can incrementally construct this span with atomic spans.",3.5 Learning and Decoding,[0],[0]
"We illustrate the construction of a complete dependency-based hybrid tree in the supplementary material.
",3.5 Learning and Decoding,[0],[0]
"Our final goal during training for a sentence n = {w0, w1, · · · , wN} is to construct all the possible complete spans that cover the interval",3.5 Learning and Decoding,[0],[0]
"[0, N ], which can be represented asC0,N,·,·.",3.5 Learning and Decoding,[0],[0]
"Similar to the chart-based dependency parsing algorithms (Eisner, 1996, 2000; Koo and Collins, 2010), we can obtain the inside and outside scores using our dynamic-programming derivation in Figure 4 during the inference process, which can then be used to calculate the objective and feature expectations.",3.5 Learning and Decoding,[0],[0]
"Since the spans are defined by at most three free indices, the dependency pattern and the semantic unit, our dynamic-programming algorithm requires O(N3M) time9 where M is the number of semantic units.",3.5 Learning and Decoding,[0],[0]
"The resulting complexity is the same as the relaxed hybrid tree model (Lu, 2014).
",3.5 Learning and Decoding,[0],[0]
"During decoding, we can find the optimal (treestructured) meaning representation m∗ for a given
9We omit a small constant factor associated with patterns.
input sentence n by the Viterbi algorithm.",3.5 Learning and Decoding,[0],[0]
"This step can also be done efficiently with our dynamicprogramming approach, where we switch from marginal inference to MAP inference:
m∗, t∗",3.5 Learning and Decoding,[0],[0]
"= argmax m,t∈T (n,m) ew·f(n,m,t)
",3.5 Learning and Decoding,[0],[0]
"A similar decoding procedure has been used in previous work (Lu, 2014; Durrett and Klein, 2015) with CKY-based parsing algorithm.",3.5 Learning and Decoding,[0],[0]
"As shown in Equation 1, the features are defined on the tuple (n,m, t).",3.6 Features,[0],[0]
"With the dynamicprogramming procedure, we can define the features over the structures in Figure 2.",3.6 Features,[0],[0]
"Our feature design is inspired by the hybrid tree model (Lu, 2015) and graph-based dependency parsing (McDonald et al., 2005).",3.6 Features,[0],[0]
Table 2 shows the feature templates for the example in Figure 2.,3.6 Features,[0],[0]
"Specifically, we define simple unigram features (concatenation of a semantic unit and a word that directly appears under the unit), pattern features (concatenation of the semantic unit and the child pattern) and transition features (concatenation of the parent and child semantic units).",3.6 Features,[0],[0]
"They form our basic feature set.
",3.6 Features,[0],[0]
"Additionally, with the structured properties of dependencies, we can define dependency-related features (McDonald et al., 2005).",3.6 Features,[0],[0]
We use the parent (head) and child (modifier) words of the dependency as features.,3.6 Features,[0],[0]
We also use the bag-of-words covered under a dependency as features.,3.6 Features,[0],[0]
The dependency features are useful in helping improve the performance as we can see in the experiments section.,3.6 Features,[0],[0]
"Following the approach used in Susanto and Lu (2017b), we could further incorporate neural networks into our latent-variable graphical model.",3.7 Neural Component,[0],[0]
"The integration is analogous to the approaches described in the neural CRF models (Do and
Artieres, 2010; Durrett and Klein, 2015; Gormley, 2015; Lample et al., 2016), where we use neural networks to learn distributed feature representations within our graphical model.
",3.7 Neural Component,[0],[0]
"We employ a neural architecture to calculate the score associated with each dependency arc (wp, wc,m) (here wp and wc are the parent and child words in the dependency andm is the semantic unit over the arc), where the input to the neural network consists of words (i.e., (wp, wc)) associated with this dependency and the neural network will calculate a score for each possible semantic unit, includingm.",3.7 Neural Component,[0],[0]
The two words are first mapped to word embeddings ep and ec (both of dimension d).,3.7 Neural Component,[0],[0]
"Next, we use a bilinear layer10 (Socher et al., 2013; Chen et al., 2016) to capture the interaction between the parent and the child in a dependency:
ri = e T p Uiec
where ri represents the score for the i-th semantic unit and Ui ∈ Rd×d.",3.7 Neural Component,[0],[0]
The scores are then incorporated into the probability expression in Equation 1 during learning and decoding.,3.7 Neural Component,[0],[0]
"As a comparison, we also implemented a variant where our model directly takes in the average embedding of ep and ec as additional features, without using our neural component.",3.7 Neural Component,[0],[0]
"Data and evaluation methodology We conduct experiments on the publicly available variablefree version of the GeoQuery dataset, which has been widely used for semantic parsing (Wong and Mooney, 2006; Lu et al., 2008; Jones et al., 2012).",4 Experiments,[0],[0]
The dataset consists of 880 pairs of natural language sentences and the corresponding treestructured semantic representations.,4 Experiments,[0],[0]
This dataset is annotated with eight languages.,4 Experiments,[0],[0]
"The original annotation of this dataset is English (Zelle and Mooney, 1996) and Jones et al. (2012) annotated the dataset with three more languages: German, Greek and Thai.",4 Experiments,[0],[0]
"Lu and Ng (2011) released the Chinese annotation and Susanto and Lu (2017b) annotated the corpus with three additional languages: Indonesian, Swedish and Farsi.",4 Experiments,[0],[0]
"In order to compare with previous work (Jones et al., 2012; Lu, 2015), we follow the standard splits with 600 instances for training and 280 instances for testing.",4 Experiments,[0],[0]
"To evaluate the performance, we follow the
10Empirically, we also tried multilayer perceptron but the bilinear model gives us better results.
",4 Experiments,[0],[0]
"standard evaluation procedure used in various previous works (Wong and Mooney, 2006; Lu et al., 2008; Jones et al., 2012; Lu, 2015) to construct the Prolog query from the tree-structured semantic representation using a standard and publicly available script.",4 Experiments,[0],[0]
"The queries are then used to retrieve the answers from the GeoQuery database, and we report accuracy and F1 scores.
",4 Experiments,[0],[0]
"Hyperparameters We set the maximum depth c of the semantic tree to 20, following Lu (2015).",4 Experiments,[0],[0]
The L2 regularization coefficient is tuned from 0.01 to 0.05 using 5-fold cross-validation on the training set.,4 Experiments,[0],[0]
"The Polyglot (Al-Rfou et al., 2013) multilingual word embeddings11 (with 64 dimensions) are used for all languages.",4 Experiments,[0],[0]
"We use LBFGS (Liu and Nocedal, 1989) to optimize the DEPHT model until convergence and stochastic gradient descent (SGD) with a learning rate of 0.05 to optimize the neural DEPHT model.",4 Experiments,[0],[0]
"We implemented our neural component with the Torch7 library (Collobert et al., 2011).",4 Experiments,[0],[0]
"Our complete implementation is based on the StatNLP12 structured prediction framework (Lu, 2017).",4 Experiments,[0],[0]
"We run the released systems of several state-ofthe-art semantic parsers, namely the WASP parser (Wong and Mooney, 2006), HYBRIDTREE model (Lu et al., 2008), UBL system (Kwiatkowski et al., 2010), relaxed hybrid tree (RHT) (Lu, 2015)13, the sequence-to-tree (SEQ2TREE) model (Dong and Lapata, 2016), the neural hybrid tree (NEURAL HT) model (Susanto and Lu, 2017b), and the multilingual semantic
11The embeddings are fixed to avoid overfitting.",4.1 Baseline Systems,[0],[0]
"12https://gitlab.com/sutd nlp/statnlp-core 13(Lu, 2015) is an extension of the original relaxed hybrid
tree (Lu, 2014), which reports improved results.
",4.1 Baseline Systems,[0],[0]
Sentence: San Antonio berada di negara bagian apa ?,4.1 Baseline Systems,[0],[0]
"(San) (Antonio) (located) (in) ( state ) (what) (?)
",4.1 Baseline Systems,[0],[0]
"Gold Meaning Representation: answer(loc(cityid(′san antonio′)))
",4.1 Baseline Systems,[0],[0]
"Relaxed Hybrid Tree
m1
San Antonio breada di ?m4
negara bagian apa
m1: QUERY : answer (STATE) m2: STATE : loc (CITY) m3: CITY : cityid (CITYNAME) m4:",4.1 Baseline Systems,[0],[0]
STATE : state (all) m5:,4.1 Baseline Systems,[0],[0]
"CITYNAME : (′san antonio′)
Dependency-based Hybrid Tree
parser (Susanto and Lu, 2017a) with single language (MSP-SINGLE) as input.",4.1 Baseline Systems,[0],[0]
"The results for TREETRANS (Jones et al., 2012) are taken from their paper.",4.1 Baseline Systems,[0],[0]
Table 3 (top) shows the results of our dependencybased hybrid tree model compared with nonneural models which achieve state-of-the-art performance on the GeoQuery dataset.,4.2 Results and Discussion,[0],[0]
Our model DEPHT achieves competitive performance and outperforms the previous best system RHT on 6 languages.,4.2 Results and Discussion,[0],[0]
Improvements on the Indonesian dataset are particularly striking (+11.8 absolute points in F1).,4.2 Results and Discussion,[0],[0]
We further investigated the outputs from both systems on Indonesian by doing error analysis.,4.2 Results and Discussion,[0],[0]
We found 40 instances that are incorrectly predicted by RHT are correctly predicted by DEPHT.,4.2 Results and Discussion,[0],[0]
We found that 77.5% of the errors are due to incorrect alignment between words and semantic units.,4.2 Results and Discussion,[0],[0]
Figure 5 shows an example of such errors where the relaxed hybrid tree fails to capture the correct alignment.,4.2 Results and Discussion,[0],[0]
We can see the question is asking “What state is San Antonio located in?”.,4.2 Results and Discussion,[0],[0]
"However, the natural language word order in Indone-
sian is different from English, where the phrase “berada di” that corresponds to m2 (i.e., loc) appears between “San Antonio” (which corresponds to m5 – ′san antonio′) and “what” (which corresponds to m1 – answer).",4.2 Results and Discussion,[0],[0]
Such a structural non isomorphism issue between the sentence and the semantic tree makes the relaxed hybrid tree parser unable to produce a joint representation with valid word-semantics alignment.,4.2 Results and Discussion,[0],[0]
"This issue makes the RHT model unable to predict the semantic unit m2 (i.e., loc) as RHT has to align the words “San Antonio” which should be aligned to m5 before aligning “berada di”.",4.2 Results and Discussion,[0],[0]
"However, m5 has arity 0 and cannot have m2 as its child.",4.2 Results and Discussion,[0],[0]
"Thus, it would be impossible for the RHT model to predict such a meaning representation as output.",4.2 Results and Discussion,[0],[0]
"In contrast, we can see that our dependency-based hybrid tree representation appears to be more flexible in handling such cases.",4.2 Results and Discussion,[0],[0]
The dependency between the two words “di” (in) and “berada” (located) is also well captured by the arc between them that is labeled with m2.,4.2 Results and Discussion,[0],[0]
"The error analysis reveals the flexibility of our joint representation in different languages in terms of the word ordering, indicating that the novel dependency-based joint representation is more robust and suffers less from languagespecific characteristics associated with the data.
",4.2 Results and Discussion,[0],[0]
"Effectiveness of dependency To investigate the helpfulness of the features defined over latent dependencies, we conduct ablation tests by removing the dependency-related features.",4.2 Results and Discussion,[0],[0]
Table 4 shows the performance of augmenting different dependency features in our DEPHT model with basic features.,4.2 Results and Discussion,[0],[0]
"Specifically, we investigate the performance of head word and modifier word features (HM) and also the bag-of-words features (BOW) that can be extracted based on dependencies.",4.2 Results and Discussion,[0],[0]
"It can be observed that dependency features associated with the words are crucial for all languages, especially the BOW features.
",4.2 Results and Discussion,[0],[0]
Effectiveness of neural component The bottom part of Table 3 shows the performance comparison among models that involve neural networks.,4.2 Results and Discussion,[0],[0]
"Our DEPHT model with embeddings as
features can outperform neural baselines across several languages (i.e., Chinese, Indonesian and Swedish).",4.2 Results and Discussion,[0],[0]
"From the table, we can see the neural component is effective, which consistently gives better results than DEPHT and the approach that uses word embedding features only.",4.2 Results and Discussion,[0],[0]
Susanto and Lu (2017b) presented the NEURAL HT model with different window size J for their multilayer perceptron.,4.2 Results and Discussion,[0],[0]
"Their performance will differ with different window sizes, which need to be tuned for each language.",4.2 Results and Discussion,[0],[0]
"In our neural component, we do not require such a language-specific hyperparameter, yet our neural approach consistently achieves the highest performance on 7 out of 8 languages compared with all previous approaches.",4.2 Results and Discussion,[0],[0]
"As both the embeddings and the neural component are defined on the dependency arcs, the superior results also reveal the effectiveness of our dependencybased hybrid tree representation.",4.2 Results and Discussion,[0],[0]
"In this work, we present a novel dependencybased hybrid tree model for semantic parsing.",5 Conclusions and Future Work,[0],[0]
The model captures the underlying semantic information of a sentence as latent dependencies between the natural language words.,5 Conclusions and Future Work,[0],[0]
We develop an efficient algorithm for exact inference based on dynamic-programming.,5 Conclusions and Future Work,[0],[0]
"Extensive experiments on benchmark dataset across 8 different languages demonstrate the effectiveness of our newly proposed representation for semantic parsing.
",5 Conclusions and Future Work,[0],[0]
"Future work includes exploring alternative approaches such as transition-based methods (Nivre et al., 2006; Chen and Manning, 2014) for semantic parsing with latent dependencies, applying our dependency-based hybrid trees on other types of logical representations (e.g., lambda calculus expressions and SQL (Finegan-Dollak et al., 2018)) as well as multilingual semantic parsing (Jie and Lu, 2014; Susanto and Lu, 2017a).",5 Conclusions and Future Work,[0],[0]
We would like to thank the anonymous reviewers for their constructive comments on this work.,Acknowledgments,[0],[0]
We would also like to thank Yanyan Zou for helping us with running the experiments for baseline systems.,Acknowledgments,[0],[0]
"This work is supported by Singapore Ministry of Education Academic Research Fund (AcRF) Tier 2 Project MOE2017-T2-1-156, and is partially supported by project 61472191 under the National Natural Science Foundation of China.",Acknowledgments,[0],[0]
"We propose a novel dependency-based hybrid tree model for semantic parsing, which converts natural language utterance into machine interpretable meaning representations.",abstractText,[0],[0]
"Unlike previous state-of-the-art models, the semantic information is interpreted as the latent dependency between the natural language words in our joint representation.",abstractText,[0],[0]
Such dependency information can capture the interactions between the semantics and natural language words.,abstractText,[0],[0]
We integrate a neural component into our model and propose an efficient dynamicprogramming algorithm to perform tractable inference.,abstractText,[0],[0]
"Through extensive experiments on the standard multilingual GeoQuery dataset with eight languages, we demonstrate that our proposed approach is able to achieve state-ofthe-art performance across several languages.",abstractText,[0],[0]
Analysis also justifies the effectiveness of using our new dependency-based representation.1,abstractText,[0],[0]
Dependency-based Hybrid Trees for Semantic Parsing,title,[0],[0]
"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 2755–2768, Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics
2755",text,[0],[0]
"For more than a decade, research on data-driven dependency parsing has been dominated by two approaches: transition-based parsing and graphbased parsing (McDonald and Nivre, 2007, 2011).",1 Introduction,[0],[0]
Transition-based parsing reduces the parsing task to scoring single parse actions and is often combined with local optimization and greedy search algorithms.,1 Introduction,[0],[0]
"Graph-based parsing decomposes parse trees into subgraphs and relies on global optimization and exhaustive (or at least non-greedy)
∗We gratefully acknowledge the inspiration for our subtitle in the seminal paper by Zhang and Clark (2008).
search to find the best tree.",1 Introduction,[0],[0]
"These radically different approaches often lead to comparable parsing accuracy, but with distinct error profiles indicative of their respective strengths and weaknesses, as shown by McDonald and Nivre (2007, 2011).
",1 Introduction,[0],[0]
"In recent years, dependency parsing, like most of NLP, has shifted from linear models and discrete features to neural networks and continuous representations.",1 Introduction,[0],[0]
This has led to substantial accuracy improvements for both transition-based and graph-based parsers and raises the question whether their complementary strengths and weaknesses are still relevant.,1 Introduction,[0],[0]
"In this paper, we replicate the analysis of McDonald and Nivre (2007, 2011) for neural parsers.",1 Introduction,[0],[0]
"In addition, we investigate the impact of deep contextualized word representations (Peters et al., 2018; Devlin et al., 2019) for both types of parsers.
",1 Introduction,[0],[0]
"Based on what we know about the strengths and weaknesses of the two approaches, we hypothesize that deep contextualized word representations will benefit transition-based parsing more than graph-based parsing.",1 Introduction,[0],[0]
"The reason is that these representations make information about global sentence structure available locally, thereby helping to prevent search errors in greedy transition-based parsing.",1 Introduction,[0],[0]
"The hypothesis is corroborated in experiments on 13 languages, and the error analysis supports our suggested explanation.",1 Introduction,[0],[0]
"We also find that deep contextualized word representations improve parsing accuracy for longer sentences, both for transition-based and graph-based parsers.",1 Introduction,[0],[0]
"After playing a marginal role in NLP for many years, dependency-based approaches to syntactic parsing have become mainstream during the last fifteen years.",2 Two Models of Dependency Parsing,[0],[0]
"This is especially true if we consider languages other than English, ever since the influ-
2756
ential CoNLL shared tasks on dependency parsing in 2006 (Buchholz and Marsi, 2006) and 2007 (Nivre et al., 2007) with data from 19 languages.
",2 Two Models of Dependency Parsing,[0],[0]
"The transition-based approach to dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre (2003), with inspiration from history-based parsing (Black et al., 1992) and data-driven shift-reduce parsing (Veenstra and Daelemans, 2000).",2 Two Models of Dependency Parsing,[0],[0]
"The idea is to reduce the complex parsing task to the simpler task of predicting the next parsing action and to implement parsing as greedy search for the optimal sequence of actions, guided by a simple classifier trained on local parser configurations.",2 Two Models of Dependency Parsing,[0],[0]
"This produces parsers that are very efficient, often with linear time complexity, and which can benefit from rich non-local features defined over parser configurations but which may suffer from compounding search errors.
",2 Two Models of Dependency Parsing,[0],[0]
"The graph-based approach to dependency parsing was developed by McDonald et al. (2005a,b), building on earlier work by Eisner (1996).",2 Two Models of Dependency Parsing,[0],[0]
"The idea is to score dependency trees by a linear combination of scores of local subgraphs, often single arcs, and to implement parsing as exact search for the highest scoring tree under a globally optimized model.",2 Two Models of Dependency Parsing,[0],[0]
"These parsers do not suffer from search errors but parsing algorithms are more complex and restrict the scope of features to local subgraphs.
",2 Two Models of Dependency Parsing,[0],[0]
"The terms transition-based and graph-based were coined by McDonald and Nivre (2007, 2011), who performed a contrastive error analysis of the two top-performing systems in the CoNLL 2006 shared task on multilingual dependency parsing: MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2006), which represented the state of the art in transition-based and graph-based parsing, respectively, at the time.",2 Two Models of Dependency Parsing,[0],[0]
"Their analysis shows that, despite having almost exactly the same parsing accuracy when averaged over 13 languages, the two parsers have very distinctive error profiles.",2 Two Models of Dependency Parsing,[0],[0]
"MaltParser is more accurate on short sentences, on short dependencies, on dependencies near the leaves of the tree, on nouns and prounouns, and on subject and object relations.",2 Two Models of Dependency Parsing,[0],[0]
"MSTParser is more accurate on long sentences, on long dependencies, on dependencies near the root of the tree, on verbs, and on coordination relations and sentence roots.
",2 Two Models of Dependency Parsing,[0],[0]
"McDonald and Nivre (2007, 2011) argue that these patterns can be explained by the complementary strengths and weaknesses of the systems.",2 Two Models of Dependency Parsing,[0],[0]
"The
0 2 4 6 8 10 12 14 Dependency length
0.5
0.6
0.7
0.8
0.9
D ep
en de
nc y
pr ec
is io
n
MSTParser MaltParser ZPar
2 4 6 8 10 12 14 Dependency length
0.5
0.6
0.7
0.8
0.9
D ep
en de
nc y
re ca
ll
MSTParser MaltParser ZPar
Figure 3:",2 Two Models of Dependency Parsing,[0],[0]
"Dependency arc precision/recall relative to predicted/gold dependency length.
",2 Two Models of Dependency Parsing,[0],[0]
"1 2 3 4 5 6 7 Distance to root
0.76
0.78
0.8
0.82
0.84
0.86
0.88
0.9
0.92
0.94
D ep
en de
nc y
pr ec
is io
n
MSTParser MaltParser ZPar
1 2 3 4 5 6 7 Distance to root
0.78
0.8
0.82
0.84
0.86
0.88
0.9
D ep
en de
nc y
re ca
ll
MSTParser MaltParser ZPar
Figure 4: Dependency arc precision/recall relative to predicted/gold distance to root.
",2 Two Models of Dependency Parsing,[0],[0]
"ZPar performs better than MaltParser and MSTParser, particularly on short sentences ( 30), due to the richest feature representation.",2 Two Models of Dependency Parsing,[0],[0]
"For longer sentences (20 to 50), the performance of ZPar drops as quickly as that of MaltParser.",2 Two Models of Dependency Parsing,[0],[0]
One possible reason is that the effect of a fixedsize beam on the reduction of error propagation becomes less obvious when the number of possible parse trees grows exponentially with sentence size.,2 Two Models of Dependency Parsing,[0],[0]
"The performance of MSTParser decreases less quickly as the size of the sentence increases, demonstrating the advantage of exact inference.",2 Two Models of Dependency Parsing,[0],[0]
"Sentences with 50+ words are relatively rare in the test set.
",2 Two Models of Dependency Parsing,[0],[0]
The three parsers show larger variance in performance when evaluated against specific properties of the dependency tree.,2 Two Models of Dependency Parsing,[0],[0]
Figure 3 shows the precision and recall for each parser relative to the arc lengths in the predicted and gold-standard dependency trees.,2 Two Models of Dependency Parsing,[0],[0]
Here the length of an arc is defined as the absolute difference between the indices of the head and modifier.,2 Two Models of Dependency Parsing,[0],[0]
"Precision represents the percentage of predicted arcs with a particular length that are correct, and recall represents the percentage of gold arcs of a particular length that are correctly predicted.
",2 Two Models of Dependency Parsing,[0],[0]
"MaltParser gives higher precision than MSTParser for short dependency arcs ( 4), but its precision drops rapidly for arcs with increased lengths.",2 Two Models of Dependency Parsing,[0],[0]
"These arcs take more shift-reduce actions to build, and are hence more prone to error propagation.",2 Two Models of Dependency Parsing,[0],[0]
"The precision of ZPar drops much slower compared to MaltParser, demonstrating the effect of beam-search for the reduction of error propagation.",2 Two Models of Dependency Parsing,[0],[0]
"Another important factor is the use of rich non-local features by ZPar, which is a likely reason for its precision to drop slower even than that of MSTParser when the arc size increases from 1 to 8.",2 Two Models of Dependency Parsing,[0],[0]
"Interestingly, the precision of ZPar is almost indistinguishable from that of MaltParser for size 1 arcs (arcs between neighbouring words), showing that the wider range of features in ZPar is the most helpful in arcs that take more than one, but not too many shiftreduce actions to build.",2 Two Models of Dependency Parsing,[0],[0]
"The recall curves of the three parsers are similar, with ZPar having
Figure 1: Labeled precision by dependency length fo MST (global–exhaustive–graph), Malt (local–greedy– transition) and ZPar (global–beam–transition).",2 Two Models of Dependency Parsing,[0],[0]
"From Zhang and Nivre (2012).
transition-based MaltParser prioritizes rich structural features, which enable accurate disambiguation in local contexts, but is limited by a locally optimized model and greedy algorithm, resulting in search errors for structures that require longer transition sequences.",2 Two Models of Dependency Parsing,[0],[0]
"The graph-based MSTParser benefits from a globally optimized model and ex-
act inference, which gives a better analysis of
global sentence structure, but is more restricted in the features it can use, which limits its capacity to score local structures accurately.
",2 Two Models of Dependency Parsing,[0],[0]
Many of the developments in dependency parsing during the last decade can be understood in this light as attempts to mitigate the weaknesses of traditional transition-based and graph-based parsers without sacrificing their strengths.,2 Two Models of Dependency Parsing,[0],[0]
"This may mean evolving the model structure through new transition systems (Nivre, 2008, 2009; Kuhlmann et al., 2011) or higher-order models for graphbased parsing (McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010); it may mean exploring alternative learning strategies, in particular for transition-based parsing, where improvements have been achieved thanks to global structure learning (Zhang and Clark, 2008; Zhang and Nivre, 2011; Andor et al., 2016) and dynamic oracles (Goldberg and Nivre, 2012, 2013); it may mean using alternative search strategies, such as transition-based parsing with beam search (Johansson and Nugues, 2007; Titov and Henderson, 2007; Zhang and Clark, 2008) or exact search (Huang and Sagae, 2010; Kuhlmann et al., 2011) or graph-based parsing with heuristic search to cope with the complexity of higher-order models, especially for non-projective parsing (McDonald and Pereira, 2006; Koo et al., 2010; Zhang and McDonald, 2012); or it may mean hybrid or en-
semble systems (Sagae and Lavie, 2006; Nivre and McDonald, 2008; Zhang and Clark, 2008; Bohnet and Kuhn, 2012).",2 Two Models of Dependency Parsing,[0],[0]
"A nice illustration of the impact of new techniques can be found in Zhang and Nivre (2012), where an error analysis along the lines of McDonald and Nivre (2007, 2011) shows that a transition-based parser using global learning and beam search (instead of local learning and greedy search) performs on par with graph-based parsers for long dependencies, while retaining the advantage of the original transition-based parsers on short dependencies (see Figure 1).
",2 Two Models of Dependency Parsing,[0],[0]
"Neural networks for dependency parsing, first explored by Titov and Henderson (2007) and Attardi et al. (2009), have come to dominate the field during the last five years.",2 Two Models of Dependency Parsing,[0],[0]
"While this has dramatically changed learning architectures and feature representations, most parsing models are still either transition-based (Chen and Manning, 2014; Dyer et al., 2015; Weiss et al., 2015; Andor et al., 2016; Kiperwasser and Goldberg, 2016) or graph-based (Kiperwasser and Goldberg, 2016; Dozat and Manning, 2017).",2 Two Models of Dependency Parsing,[0],[0]
"However, more accurate feature learning using continuous representations and nonlinear models has allowed parsing architectures to be simplified.",2 Two Models of Dependency Parsing,[0],[0]
"Thus, most recent transition-based parsers have moved back to local learning and greedy inference, seemingly without losing accurracy (Chen and Manning, 2014; Dyer et al., 2015; Kiperwasser and Goldberg, 2016).",2 Two Models of Dependency Parsing,[0],[0]
"Similarly, graph-based parsers again rely on first-order models and obtain no improvements from using higher-order models (Kiperwasser and Goldberg, 2016; Dozat and Manning, 2017).
",2 Two Models of Dependency Parsing,[0],[0]
The increasing use of neural networks has also led to a convergence in feature representations and learning algorithms for transition-based and graph-based parsers.,2 Two Models of Dependency Parsing,[0],[0]
"In particular, most recent systems rely on an encoder, typically in the form of a BiLSTM, that provides contextualized representations of the input words as input to the scoring of transitions – in transition-based parsers – or of dependency arcs – in graph-based parsers.",2 Two Models of Dependency Parsing,[0],[0]
"By making information about the global sentence context available in local word representations, this encoder can be assumed to mitigate error propagation for transition-based parsers and to widen the feature scope beyond individual word pairs for graph-based parsers.",2 Two Models of Dependency Parsing,[0],[0]
"For both types of parsers, this also obviates the need for complex structural feature templates, as recently shown by
Falenska and Kuhn (2019).",2 Two Models of Dependency Parsing,[0],[0]
We should therefore expect neural transition-based and graph-based parsers to be not only more accurate than their non-neural counterparts but also more similar to each other in their error profiles.,2 Two Models of Dependency Parsing,[0],[0]
"Neural parsers rely on vector representations of words as their primary input, often in the form of pretrained word embeddings such as word2vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014), or fastText (Bojanowski et al., 2016), which are sometimes extended with characterbased representations produced by recurrent neural networks (Ballesteros et al., 2015).",3 Deep Contextualized Word Representations,[0],[0]
"These techniques assign a single static representation to each word type and therefore cannot capture contextdependent variation in meaning and syntactic behavior.
",3 Deep Contextualized Word Representations,[0],[0]
"By contrast, deep contextualized word representations encode words with respect to the sentential context in which they appear.",3 Deep Contextualized Word Representations,[0],[0]
"Like word embeddings, such models are typically trained with a language-modeling objective, but yield sentence-level tensors as representations, instead of single vectors.",3 Deep Contextualized Word Representations,[0],[0]
"These representations are typically produced by transferring a model’s entire feature encoder – be it a BiLSTM (Hochreiter and Schmidhuber, 1997) or Transformer (Vaswani et al., 2017) – to a target task, where the dimensionality of the tensor S is typically S ∈ RN×L×D for a sentence of length N , an encoder with L layers, and word-level vectors of dimensionality D. The advantage of such models, compared to the parser-internal encoders discussed in the previous section, is that they not only produce contextualized representations but do so over several layers of abstraction, as captured by the model’s different layers, and are pre-trained on corpora much larger than typical treebanks.
",3 Deep Contextualized Word Representations,[0],[0]
"Deep contextualized embedding models have proven to be adept at a wide array of NLP tasks, achieving state-of-the-art performance in standard Natural Language Understanding (NLU) benchmarks, such as GLUE (Wang et al., 2019).",3 Deep Contextualized Word Representations,[0],[0]
"Though many such models have been proposed, we adopt the two arguably most popular ones for our experiments: ELMo and BERT.",3 Deep Contextualized Word Representations,[0],[0]
"Both models have previously been used for dependency parsing (Che et al., 2018; Jawahar et al., 2018; Lim et al., 2018;
Kondratyuk, 2019; Schuster et al., 2019), but there has been no systematic analysis of their impact on transition-based and graph-based parsers.",3 Deep Contextualized Word Representations,[0],[0]
"ELMo is a deep contextualized embedding model proposed by Peters et al. (2018), which produces sentence-level representations yielded by a multi-layer BiLSTM language model.",3.1 ELMo,[0],[0]
"ELMo is trained with a standard language-modeling objective, in which a BiLSTM reads a sequence of N learned context-independent embeddings w1, . . .",3.1 ELMo,[0],[0]
",wN (obtained via a character-level CNN) and produces a context-dependent representation hj,k = BiLSTM(w1:N , k), where j (1≤ j≤L) is the BiLSTM layer and k is the index of the word in the sequence.",3.1 ELMo,[0],[0]
"The output of the last layer hL,k is then employed in conjunction with a softmax layer to predict the next token at k + 1.
",3.1 ELMo,[0],[0]
"The simplest way of transferring ELMo to a downstream task is to encode the input sentence S = w1, . . .",3.1 ELMo,[0],[0]
", wN by extracting the representations from the BiLSTM at layer L for each token wk ∈ S: hL,1, . . .",3.1 ELMo,[0],[0]
",hL,N ,.",3.1 ELMo,[0],[0]
"However, Peters et al. (2018) posit that the best way to take advantage of ELMo’s representational power is to compute a linear combination of BiLSTM layers:
ELMok = γ L∑
j=0
sjhj,k (1)
where sj is a softmax-normalized task-specific parameter and γ is a task-specific scalar.",3.1 ELMo,[0],[0]
Peters et al. (2018) demonstrate that this scales the layers of linguistic abstraction encoded by the BiLSTM for the task at hand.,3.1 ELMo,[0],[0]
"BERT (Devlin et al., 2019) is similar to ELMo in that it employs a language-modeling objective over unannotated text in order to produce deep contextualized embeddings.",3.2 BERT,[0],[0]
"However, BERT differs from ELMo in that, in place of a BiLSTM, it employs a bidirectional Transformer (Vaswani et al., 2017), which, among other factors, carries the benefit of learning potential dependencies between words directly.",3.2 BERT,[0],[0]
"This lies in contrast to recurrent models, which may struggle to learn correspondences between constituent signals when the time-lag between them is long (Hochreiter et al., 2001).",3.2 BERT,[0],[0]
"For a token wk in sentence S, BERT’s input representation is composed by summing a
word embedding xk, a position embedding ik, and a WordPiece embedding sk (Wu et al., 2016): wk = xk + ik + sk.
",3.2 BERT,[0],[0]
"Each wk ∈ S is passed to an L-layered BiTransformer, which is trained with a masked language modeling objective (i.e., randomly masking a percentage of input tokens and only predicting said tokens).",3.2 BERT,[0],[0]
"For use in downstream tasks, Devlin et al. (2019) propose to extract the Transformer’s encoding of each token wk ∈ S at layer L, which effectively produces BERTk.",3.2 BERT,[0],[0]
"Based on our discussion in Section 2, we assume that transition-based and graph-based parsers still have distinctive error profiles due to the basic trade-off between rich structural features, which allow transition-based parsers to make accurate local decisions, and global learning and exact search, which give graph-based parsers an advantage with respect to global sentence structure.",4 Hypotheses,[0],[0]
"At the same time, we expect the differences to be less pronounced than they were ten years ago because of the convergence in neural architectures and feature representations.",4 Hypotheses,[0],[0]
"But how will the addition of deep contextualized word representations affect the behavior of the two parsers?
",4 Hypotheses,[0],[0]
"Given recent recent work showing that deep contextualized word representations incorporate rich information about syntactic structure (Goldberg, 2019; Liu et al., 2019; Tenney et al., 2019; Hewitt and Manning, 2019), we hypothesize that transition-based parsers have most to gain from these representations because it will improve their capacity to make decisions informed by global sentence structure and therefore reduce the number of search errors.",4 Hypotheses,[0],[0]
"Our main hypothesis can be stated as follows:
Deep contextualized word representations are more effective at reducing errors in transitionbased parsing than in graph-based parsing.
",4 Hypotheses,[0],[0]
"If this holds true, then the analysis of McDonald and Nivre (2007, 2011) suggests that the differential error reduction should be especially visible on phenomena such as:
1.",4 Hypotheses,[0],[0]
"longer dependencies, 2.",4 Hypotheses,[0],[0]
"dependencies closer to the root, 3.",4 Hypotheses,[0],[0]
"certain parts of speech, 4.",4 Hypotheses,[0],[0]
"certain dependency relations, 5. longer sentences.
",4 Hypotheses,[0],[0]
The error analysis will consider all these factors as well as non-projective dependencies.,4 Hypotheses,[0],[0]
"To be able to compare transition-based and graphbased parsers under equivalent conditions, we use and extend UUParser1 (de Lhoneux et al., 2017a; Smith et al., 2018a), an evolution of bistparser (Kiperwasser and Goldberg, 2016), which supports transition-based and graph-based parsing with a common infrastructure but different scoring models and parsing algorithms.
",5.1 Parsing Architecture,[0],[0]
"For an input sentence S = w1, . . .",5.1 Parsing Architecture,[0],[0]
", wN , the parser creates a sequence of vectors w1:N , where the vector wk = xk ◦",5.1 Parsing Architecture,[0],[0]
BILSTM(c1:M ) representing input word wk is the concatenation of a pretrained word embedding xk and a character-based embedding BILSTM(c1:M ) obtained by running a BiLSTM over the character sequence c1:M of wk.,5.1 Parsing Architecture,[0],[0]
"Finally, each input element is represented by a BiLSTM vector, hk =",5.1 Parsing Architecture,[0],[0]
"BILSTM(w1:N , k).
",5.1 Parsing Architecture,[0],[0]
"In transition-based parsing, the BiLSTM vectors are input to a multi-layer perceptron (MLP) for scoring transitions, using the arc-hybrid transition system from Kuhlmann et al. (2011) extended with a SWAP transition to allow the construction of non-projective dependency trees (Nivre, 2009; de Lhoneux et al., 2017b).",5.1 Parsing Architecture,[0],[0]
"The scoring is based on the top three words on the stack and the first word of the buffer, and the input to the MLP includes the BiLSTM vectors for these words as well as their leftmost and rightmost dependents (up to 12 words in total).
",5.1 Parsing Architecture,[0],[0]
"In graph-based parsing, the BiLSTM vectors are input to an MLP for scoring all possible dependency relations under an arc-factored model, meaning that only the vectors corresponding to the head and dependent are part of the input (2 words in total).",5.1 Parsing Architecture,[0],[0]
"The parser then extracts a maximum spanning tree over the score matrix using the ChuLiu-Edmonds (CLE) algorithm2 (Edmonds, 1967) which allows us to construct non-projective trees.
",5.1 Parsing Architecture,[0],[0]
"It is important to note that, while we acknowledge the existence of graph-based parsers that outperform the implementation of Kiperwasser and Goldberg (2016), such models do not meet our criteria for systematic comparison.",5.1 Parsing Architecture,[0],[0]
"The parser
1https://github.com/UppsalaNLP/ uuparser
2We use the implementation from Qi et al. (2018).
by Dozat et al. (2017) is very similar, but employs the MLP as a further step in the featurization process prior to scoring via a biaffine classifier.",5.1 Parsing Architecture,[0],[0]
"To keep the comparison as exact as possible, we forego comparing our transition-based systems to the Dozat et al. (2017) parser (and its numerous modifications).",5.1 Parsing Architecture,[0],[0]
"In addition, preliminary experiments showed that our chosen graph-based parser outperforms its transition-based counterpart, which was itself competitive in the CoNLL 2018 shared task (Zeman et al., 2018).",5.1 Parsing Architecture,[0],[0]
"In our experiments, we evaluate three pairs of systems – differing only in their input representations.",5.2 Input Representations,[0],[0]
The first is a baseline that represents tokens by wk = xk ◦,5.2 Input Representations,[0],[0]
"BILSTM(c1:M ), as described in Section 5.1.",5.2 Input Representations,[0],[0]
The word embeddings xk are initialized via pretrained fastText vectors (xk ∈ R300),5.2 Input Representations,[0],[0]
"(Grave et al., 2018), which are updated for the parsing task.",5.2 Input Representations,[0],[0]
"We term these transition-based and graphbased baselines TR and GR.
",5.2 Input Representations,[0],[0]
"For the ELMo experiments, we make use of pretrained models provided by Che et al. (2018), who train ELMo on 20 million words randomly sampled from raw WikiDump and Common Crawl datasets for 44 languages.",5.2 Input Representations,[0],[0]
"We encode each goldsegmented sentence in our treebank via the ELMo model for that language, which yields a tensor SELMo = RN×L×D, where N is the number of words in the sentence, L = 3 is the number of ELMo layers, and D = 1024 is the ELMo vector dimensionality.",5.2 Input Representations,[0],[0]
"Following Peters et al. (2018) (see Eq. 1), we learn a linear combination and a task-specific γ of each token’s ELMo representation, which yields a vector ELMok ∈ R1024.",5.2 Input Representations,[0],[0]
We then concatenate this vector with wk and pass it to the BiLSTM.,5.2 Input Representations,[0],[0]
"We call the transition-based and graph-based systems enhanced with ELMo TR+E and GR+E.
For the BERT experiments, we employ the pretrained multilingual cased model provided by Google,3 4 which is trained on the concatenation of WikiDumps for the top 104 languages with the largest Wikipedias.5 The model’s parameters feature a 12-layer transformer trained with 768 hid-
3https://github.com/google-research/ bert
4Except for Chinese, for which we make use of a separate, pretrained model.
5See sorted list here: https://meta.wikimedia.",5.2 Input Representations,[0],[0]
"org/wiki/List_of_Wikipedias
den units and 12 self-attention heads.",5.2 Input Representations,[0],[0]
"In order to obtain a word-level vector for each token in a sentence, we experimented with a variety of representations: namely, concatenating each transformer layer’s word representation into a single vector wconcat ∈ R768∗12, employing the last layer’s representation, or learning a linear combination over a range of layers, as we do with ELMo (e.g., via Eq. 1).",5.2 Input Representations,[0],[0]
"In a preliminary set of experiments, we found that the latter approach over layers 4–8 consistently yielded the best results, and thus chose to adopt this method going forward.",5.2 Input Representations,[0],[0]
"Regarding tokenization, we select the vector for the first subword token, as produced by the native BERT tokenizer.",5.2 Input Representations,[0],[0]
"Surprisingly, this gave us better results than averaging subword token vectors in a preliminary round of experiments.",5.2 Input Representations,[0],[0]
"Like with the ELMo representations, we concatenate each BERT vector BERTk ∈ R768 with wk and pass it to the respective TR+B and GR+B parsers.
",5.2 Input Representations,[0],[0]
"It is important to note that while the ELMo models we work with are monolingual, the BERT model is multilingual.",5.2 Input Representations,[0],[0]
"In other words, while the standalone ELMo models were trained on the tokenized WikiDump and CommonCrawl for each language respectively, the BERT model was trained only on the former, albeit simultaneously for 104 languages.",5.2 Input Representations,[0],[0]
"This means that the models are not strictly comparable, and it is an interesting question whether either of the models has an advantage in terms of training regime.",5.2 Input Representations,[0],[0]
"However, since our purpose is not to compare the two models but to study their impact on parsing, we leave this question for future work.",5.2 Input Representations,[0],[0]
"For treebank selection, we rely on the criteria proposed by de Lhoneux et al. (2017c) and adapted by Smith et al. (2018b) to have languages from different language families, with different morphological complexity, different scripts and character set sizes, different training sizes and domains, and with good annotation quality.",5.3 Language and Treebank Selection,[0],[0]
"This gives us 13 treebanks from UD v2.3 (Nivre et al., 2018), information about which is shown in Table 1.",5.3 Language and Treebank Selection,[0],[0]
"In all experiments, we train parsers with default settings6 for 30 epochs and select the model with
6All hyperparameters are specified in the supplementary material (Part A).
",5.4 Parser Training and Evaluation,[0],[0]
the best labeled attachment score on the dev set.,5.4 Parser Training and Evaluation,[0],[0]
"For each combination of model and training set, we repeat this procedure three times with different random seeds, apply the three selected models to the test set, and report the average result.",5.4 Parser Training and Evaluation,[0],[0]
"In order to conduct an error analysis along the lines of McDonald and Nivre (2007, 2011), we extract all sentences from the smallest development set in our treebank sample (Hebrew HTB, 484 sentences) and sample the same number of sentences from each of the other development sets (6,292 sentences in total).",5.5 Error Analysis,[0],[0]
"For each system, we then extract parses of these sentences for the three training runs with different random seeds (18,876 predictions in total).",5.5 Error Analysis,[0],[0]
"Although it could be interesting to look at each language separately, we follow McDonald and Nivre (2007, 2011) and base our main analysis on all languages together to prevent data sparsity for longer dependencies, longer sentences, etc.7",5.5 Error Analysis,[0],[0]
"Table 2 shows labeled attachment scores for the six parsers on all languages, averaged over three training runs with random seeds.",6 Results and Discussion,[0],[0]
The results clearly corroborate our main hypothesis.,6 Results and Discussion,[0],[0]
"While ELMo and BERT provide significant improvements for both transition-based and graph-based
7The supplementary material contains tables for the error analysis (Part B) and graphs for each language (Part C).
",6 Results and Discussion,[0],[0]
"parsers, the magnitude of the improvement is greater in the transition-based case: 3.99 vs. 2.85 for ELMo and 4.47 vs. 3.13 for BERT.",6 Results and Discussion,[0],[0]
"In terms of error reduction, this corresponds to 21.1% vs. 16.5% for ELMo and 22.5% vs. 17.4% for BERT.",6 Results and Discussion,[0],[0]
The differences in error reduction are statistically significant at α = 0.01,6 Results and Discussion,[0],[0]
"(Wilcoxon).
",6 Results and Discussion,[0],[0]
"Although both parsing accuracy and absolute improvements vary across languages, the overall trend is remarkably consistent and the transitionbased parser improves more with both ELMo and BERT for every single language.",6 Results and Discussion,[0],[0]
"Furthermore, a linear mixed effect model analysis reveals that, when accounting for language as a random effect, there are no significant interactions between the improvement of each model (over its respective baseline) and factors such as language family (IE vs. non-IE), dominant word order, or number of training sentences.",6 Results and Discussion,[0],[0]
"In other words, the improvements for both parsers seem to be largely independent of treebank-specific factors.",6 Results and Discussion,[0],[0]
Let us now see to what extent they can be explained by the error analysis.,6 Results and Discussion,[0],[0]
"Figure 2 shows labeled F-score for dependencies of different lengths, where the length of a dependency between words wi and wj is equal to |i− j| (and with root tokens in a special bin on the far left).",6.1 Dependency Length,[0],[0]
"For the baseline parsers, we see that the curves diverge with increasing length, clearly indicating that the transition-based parser still suffers
from search errors on long dependencies, which require longer transition sequences for their construction.",6.1 Dependency Length,[0],[0]
"However, the differences are much smaller than in McDonald and Nivre (2007, 2011) and the transition-based parser no longer has an advantage for short dependencies, which is consistent with the BiLSTM architecture providing the parsers with more similar features that help the graph-based parser overcome the limited scope of the first-order model.
",6.1 Dependency Length,[0],[0]
Adding deep contextualized word representations clearly helps the transition-based parser to perform better on longer dependencies.,6.1 Dependency Length,[0],[0]
"For ELMo there is still a discernible difference for dependencies longer than 5, but for BERT the two curves
are almost indistinguishable throughout the whole range.",6.1 Dependency Length,[0],[0]
"This could be related to the aforementioned intuition that a Transformer captures long dependencies more effectively than a BiLSTM (see Tran et al. (2018) for contrary observations, albeit for different tasks).",6.1 Dependency Length,[0],[0]
"The overall trends for both baseline and enhanced models are quite consistent across languages, although with large variations in accuracy levels.",6.1 Dependency Length,[0],[0]
"Figure 3 reports labeled F-score for dependencies at different distances from the root of the tree, where distance is measured by the number of arcs in the path from the root.",6.2 Distance to Root,[0],[0]
"There is a fairly strong (inverse) correlation between dependency length and distance to the root, so it is not surprising that the plots in Figure 3 largely show the mirror image of the plots in Figure 2.",6.2 Distance to Root,[0],[0]
"For the baseline parsers, the graph-based parser has a clear advantage for dependencies near the root (including the root itself), but the transition-based parser closes the gap with increasing distance.8",6.2 Distance to Root,[0],[0]
"For ELMo and BERT, the curves are much more similar, with only a slight advantage for the graph-based parser near the root and with the transition-based BERT parser being superior from distance 5 upwards.",6.2 Distance to Root,[0],[0]
The main trends are again similar across all languages.,6.2 Distance to Root,[0],[0]
Figure 4 shows precision and recall specifically for non-projective dependencies.,6.3 Non-Projective Dependencies,[0],[0]
We see that there is a clear tendency for the transition-based parser to have better precision and the graph-based parser,6.3 Non-Projective Dependencies,[0],[0]
better recall.9,6.3 Non-Projective Dependencies,[0],[0]
"In other words, non-projective dependencies are more likely to be correct when they are predicted by the transition-based parser using the swap transition, but real non-projective dependencies are more likely to be found by the graphbased parser using a spanning tree algorithm.",6.3 Non-Projective Dependencies,[0],[0]
"Interestingly, adding deep contextualized word representations has almost no effect on the graphbased parser,10 while especially the ELMo em-
8At the very end, the curves appear to diverge again, but the data is very sparse in this part of the plot.
",6.3 Non-Projective Dependencies,[0],[0]
"9Incidentally, the same pattern is reported by McDonald and Nivre (2007, 2011), even though the techniques for processing non-projective dependencies are different in that study: pseudo-projective parsing (Nivre and Nilsson, 2005) for the transition-based parser and approximate second-order non-projective parsing (McDonald and Pereira, 2006) for the graph-based parser.
",6.3 Non-Projective Dependencies,[0],[0]
"10The breakdown per language shows marginal improvements for the enhanced graph-based models on a few lan-
beddings improve both precision and recall for the transition-based parser.",6.3 Non-Projective Dependencies,[0],[0]
"Thanks to the cross-linguistically consistent UD annotations, we can relate errors to linguistic categories more systematically than in the old study.",6.4 Parts of Speech and Dependency Types,[0],[0]
"The main impression, however, is that there are very few clear differences, which is again indicative of the convergence between the two parsing approaches.",6.4 Parts of Speech and Dependency Types,[0],[0]
"We highlight the most notable differences and refer to the supplementary material (Part B) for the full results.
",6.4 Parts of Speech and Dependency Types,[0],[0]
"Looking first at parts of speech, the baseline graph-based parser is slightly more accurate on verbs and nouns than its transition-based counterpart, which is consistent with the old study for verbs but not for nouns.",6.4 Parts of Speech and Dependency Types,[0],[0]
"After adding the deep contextualized word representations, both differences are essentially eliminated.
",6.4 Parts of Speech and Dependency Types,[0],[0]
"With regard to dependency relations, the baseline graph-based parser has better precision and recall than the baseline transition-based parser for the relations of coordination (conj), which is consistent with the old study, as well as clausal subjects (csubj) and clausal complements (ccomp), which are relations that involve verbs in clausal structures.",6.4 Parts of Speech and Dependency Types,[0],[0]
"Again, the differences are greatly reduced in the enhanced parsing models, especially for clausal complements, where the transitionbased parser with ELMo representations is even slightly more accurate than the graph-based parser.",6.4 Parts of Speech and Dependency Types,[0],[0]
"Figure 5 plots labeled attachment score for sentences of different lengths, measured by number of words in bins of 1–10, 11–20, etc.",6.5 Sentence Length,[0],[0]
"Here we
guages, canceled out by equally marginal degradations on others.
find the most unexpected results of the study.",6.5 Sentence Length,[0],[0]
"First of all, although the baseline parsers exhibit the familiar pattern of accuracy decreasing with sentence length, it is not the transition-based but the graph-based parser that is more accurate on short sentences and degrades faster.",6.5 Sentence Length,[0],[0]
"In other words, although the transition-based parser still seems to suffer from search errors, as shown by the results on dependency length and distance to the root, it no longer seems to suffer from error propagation in the sense that earlier errors make later errors more probable.",6.5 Sentence Length,[0],[0]
"The most likely explanation for this is the improved training for transition-based parsers using dynamic oracles and aggressive exploration to learn how to behave optimally also in non-optimal configurations (Goldberg and Nivre, 2012, 2013; Kiperwasser and Goldberg, 2016).
",6.5 Sentence Length,[0],[0]
"Turning to the models with deep contextualized word representations, we find that transitionbased and graph-based parsers behave more similarly, which is in line with our hypotheses.",6.5 Sentence Length,[0],[0]
"However, the most noteworthy result is that accuracy improves with increasing sentence length.",6.5 Sentence Length,[0],[0]
"For ELMo this holds only from 1–10 to 11–20, but for BERT it holds up to 21–30, and even sentences of length 31–40 are parsed with higher accuracy than sentences of length 1–10.",6.5 Sentence Length,[0],[0]
A closer look at the breakdown per language reveals that this picture is slightly distorted by different sentence length distributions in different languages.,6.5 Sentence Length,[0],[0]
"More precisely, high-accuracy languages seem to have a higher proportion of sentences of mid-range length, causing a slight boost in the accuracy scores of these bins, and no single language exhibits exactly the patterns shown in Figure 5.",6.5 Sentence Length,[0],[0]
"Nevertheless, several languages exhibit an increase in accuracy from the first to the second bin or from the second to the third bin for one or more of the enhanced models (especially the BERT models).",6.5 Sentence Length,[0],[0]
"And almost all languages show a less steep degradation for the enhanced models, clearly indicating that deep contextualized word representations improve the capacity to parse longer sentences.",6.5 Sentence Length,[0],[0]
"In this paper, we have essentially replicated the study of McDonald and Nivre (2007, 2011) for neural parsers.",7 Conclusion,[0],[0]
"In the baseline setting, where parsers use pre-trained word embeddings and character representations fed through a BiLSTM, we can still discern the basic trade-off identified
in the old study, with the transition-based parser suffering from search errors leading to lower accuracy on long dependencies and dependencies near the root of the tree.",7 Conclusion,[0],[0]
"However, important details of the picture have changed.",7 Conclusion,[0],[0]
"The graph-based parser is now as accurate as the transition-based parser on shorter dependencies and dependencies near the leaves of the tree, thanks to improved representation learning that overcomes the limited feature scope of the first order model.",7 Conclusion,[0],[0]
"And with respect to sentence length, the pattern has actually been reversed, with the graph-based parser being more accurate on short sentences and the transitionbased parser gradually catching up thanks to new training methods that prevent error propagation.
",7 Conclusion,[0],[0]
"When adding deep contextualized word representations, the behavior of the two parsers converge even more, and the transition-based parser in particular improves with respect to longer dependencies and dependencies near the root, as a result of fewer search errors thanks to enhanced information about the global sentence structure.",7 Conclusion,[0],[0]
"One of the most striking results, however, is that both parsers improve their accuracy on longer sentences, with some models for some languages in fact being more accurate on medium-length sentences than on shorter sentences.",7 Conclusion,[0],[0]
"This is a milestone in parsing research, and more research is needed to explain it.
",7 Conclusion,[0],[0]
"In a broader perspective, we hope that future studies on dependency parsing will take the results obtained here into account and extend them by investigating other parsing approaches and neural network architectures.",7 Conclusion,[0],[0]
"Indeed, given the rapid development of new representations and architectures, future work should include analyses of how all components in neural parsing architectures (embeddings, encoders, decoders) contribute to distinct error profiles (or lack thereof).",7 Conclusion,[0],[0]
"We want to thank Ali Basirat, Christian Hardmeier, Jamie Henderson, Ryan McDonald, Paola Merlo, Gongbo Tang, and the EMNLP reviewers and area chairs for valuable feedback on preliminary versions of this paper.",Acknowledgments,[0],[0]
We acknowledge the computational resources provided by CSC in Helsinki and Sigma2 in Oslo through NeIC-NLPL (www.nlpl.eu).,Acknowledgments,[0],[0]
"Transition-based and graph-based dependency parsers have previously been shown to have complementary strengths and weaknesses: transition-based parsers exploit rich structural features but suffer from error propagation, while graph-based parsers benefit from global optimization but have restricted feature scope.",abstractText,[0],[0]
"In this paper, we show that, even though some details of the picture have changed after the switch to neural networks and continuous representations, the basic trade-off between rich features and global optimization remains essentially the same.",abstractText,[0],[0]
"Moreover, we show that deep contextualized word embeddings, which allow parsers to pack information about global sentence structure into local feature representations, benefit transition-based parsers more than graph-based parsers, making the two approaches virtually equivalent in terms of both accuracy and error profile.",abstractText,[0],[0]
We argue that the reason is that these representations help prevent search errors and thereby allow transitionbased parsers to better exploit their inherent strength of making accurate local decisions.,abstractText,[0],[0]
We support this explanation by an error analysis of parsing experiments on 13 languages.,abstractText,[0],[0]
Deep Contextualized Word Embeddings in Transition-Based and Graph-Based Dependency Parsing - A Tale of Two Parsers Revisited,title,[0],[0]
"The study of relational data arising from various networks including social, biological and physical networks is becoming increasingly important due to the emergence of massive relational data collected from these domains.",1. Introduction,[0],[0]
"Many efforts have been dedicated to develop statistical models in terms of community detection and missing link prediction for analyzing relational data arising from static networks, where either a single snapshot of the network of interest or an aggregated network over time is presented; see (Goldenberg et al., 2010) for a review of the literature.",1. Introduction,[0],[0]
"However, network data, such
1Department of Electrical Engineering and Information Technology, Technische Universität Darmstadt, Germany.",1. Introduction,[0],[0]
"Correspondence to: Sikun Yang <sikun.yang@bcs.tu-darmstadt.de>, Heinz Koeppl <heinz.koeppl@bcs.tu-darmstadt.de>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
as friendships or interactions in a social network, is often dynamic since the relations among the entities within the network may appear or disappear over time (Mucha et al., 2010).",1. Introduction,[0],[0]
"Accordingly, the latent groups composed of those temporally connected entities also form and decay over time.",1. Introduction,[0],[0]
"Hence, appropriate models are needed to enable a better understanding of the formation and evolution of dynamic networks (Phan & Airoldi, 2015).
",1. Introduction,[0],[0]
A probabilistic framework is proposed to model such dynamic networks by assuming the network of interest is composed of a set of latent groups.,1. Introduction,[0],[0]
Each node of the observed network is hence associated with a time-dependent memberships vector that governs its involvement in multiple groups and interactions with other nodes.,1. Introduction,[0],[0]
"The node-group memberships are assumed to be gamma distributed, thus, naturally nonnegative real-valued.",1. Introduction,[0],[0]
"Moreover, to capture time-evolving interactions between groups of nodes, we model the birth and death dynamics of individual groups explicitly via a dependent relational gamma process (dRGaP).",1. Introduction,[0],[0]
"The ideal number of latent groups can be adaptively learned from data via the shrinkage mechanism of the dRGaP.
Explicitly modelling group birth/death dynamics can be useful in many applications.",1. Introduction,[0],[0]
"For instance, latent groups in a network of military disputes between countries could mean alliances such as NATO coordinating collective defence to attacks by external forces (Schein et al., 2016a).",1. Introduction,[0],[0]
These groups can be born and die afterwards.,1. Introduction,[0],[0]
"For example, the Warsaw Pact was established during the Cold War and dissolved in later years.",1. Introduction,[0],[0]
"We demonstrate that our model can discover interpretable latent structure on a real network of military interstate disputes (Ghosn et al., 2004) that agrees with our knowledge of international relations (Section 5).",1. Introduction,[0],[0]
"Furthermore, it is reasonable to model the time-evolving memberships of each individual node to interpret its joining and withdrawing behavior to these groups.",1. Introduction,[0],[0]
"Hence, we capture the dynamics of individual node-group memberships evolving over time via gamma Markov processes.
",1. Introduction,[0],[0]
"In contrast to dynamic network modelling using logistic or probit mapping functions (Foulds et al., 2011; Heaukulani et al., 2013; Durante et al., 2014a), we leverage the Bernoulli-Poisson link (BPL) function (Dunson & Herring, 2005; Zhou, 2015) to generate edges from the latent space representation, which makes the computational cost of our
model to scale linearly with the number of edges, rather than quadratically with the number of nodes.",1. Introduction,[0],[0]
"In addition, the Bernoulli-Poisson link is also a more appropriate model for imbalanced binary data (Zhou, 2017; Hu et al., 2015), which makes the proposed model appealing for analyzing real-world relational data that are usually extremely sparse.",1. Introduction,[0],[0]
"To perform inference, we present an efficient Gibbs sampling algorithm exploiting the Pólya-gamma data augmentation technique (Polson et al., 2013) and the data augmentation and marginalization technique for discrete data (Zhou et al., 2015).
",1. Introduction,[0],[0]
The paper is organized as follows.,1. Introduction,[0],[0]
"In Section 2, we shortly review the gamma process and the thinned completely random measure framework.",1. Introduction,[0],[0]
"In Section 3, we present our generative model.",1. Introduction,[0],[0]
"In Section 4, we discuss some related work.",1. Introduction,[0],[0]
Experimental results are provided in Section 5.,1. Introduction,[0],[0]
The complete Gibbs sampling algorithm and additional experimental results are presented in the supplementary material.,1. Introduction,[0],[0]
"Our dynamic network model is based on the thinned completely random measures (tCRMs) framework, originally proposed in (Foti et al., 2013) for the construction of covariate-dependent topic models and latent feature models.",2. Covariate-Dependent Random Measures,[0],[0]
We generalize this construction for longitudinal network modelling.,2. Covariate-Dependent Random Measures,[0],[0]
"More specifically, a set of latent groups that constitute the underlying structure of the observed dynamic network is generated.",2. Covariate-Dependent Random Measures,[0],[0]
"Via the tCRMs framework, the generated groups are allowed to form and decay over time.",2. Covariate-Dependent Random Measures,[0],[0]
"To facilitate understanding, we shortly review the gamma process and the thinned CRMs.",2. Covariate-Dependent Random Measures,[0],[0]
"The gamma process (GaP) is a completely random measure (CRM) (Kingman, 1967) defined on the product space Θ × R>0 as G ∼ GaP(G0, c), where c is a scale parameter, and G0 is a finite and continuous base measure over a complete separable metric space Θ, such that G(Sk) ∼ Gamma(G0(Sk), c) are independent gamma random variables for disjoint subsets {Sk}∞k=1 of Θ. The positive Lévy measure of the gamma process can be expressed as ν(dr) = cr−1e−crdr.",2.1. Gamma Process,[0],[0]
"As a completely random measure, the gamma process can be regarded as a Poisson process on Θ × R>0 with mean measure ν(dθ,dr).",2.1. Gamma Process,[0],[0]
"A sample from this Poisson process consists of countably infinite atoms because ∫ ∫ Θ×R>0 ν(dθ,dr) = ∞.",2.1. Gamma Process,[0],[0]
"Thus, a sample from the gamma process can be expressed as G = ∑∞",2.1. Gamma Process,[0],[0]
"k=1 rkδθk ∼ GaP(G0, c).",2.1. Gamma Process,[0],[0]
"More detailed information about the gamma process can be found in (Wolpert et al., 1998; 2011).",2.1. Gamma Process,[0],[0]
"Let Π = {(xk, θk, rk)}∞k=1 be generated by a Poisson process on the augmented product space X × Θ × R>0 with mean measure ν(dx, dθ,dr).",2.2. The Thinned CRMs Framework,[0],[0]
Let G = ∑∞,2.2. The Thinned CRMs Framework,[0],[0]
k=1,2.2. The Thinned CRMs Framework,[0],[0]
"rkδ(xk,θk) be a CRM on X × Θ × R>0, and let T denote the time set as the coveriate.",2.2. The Thinned CRMs Framework,[0],[0]
Our goal is to construct a family of random measures {G(t)}t∈T dependent on covariate values t ∈ T .,2.2. The Thinned CRMs Framework,[0],[0]
"To achieve this, we generate a set of binary random variables b(t)k for each point (xk, rk, θk) ∈ Π such that p(b
(t) k = 1) = Pxk(t), where Px : T",2.2. The Thinned CRMs Framework,[0],[0]
"→ [0, 1] denotes the thinning function which determines the probability that atom k in the global measure G appears in the local measure G(t) at covariate value t. Then, the set of covariate-dependent CRMs {G(t)}t∈T can be specified as
G(t) = ∞∑ k=1 b (t) k rkδθk , t ∈ T .
",2.2. The Thinned CRMs Framework,[0],[0]
"The new CRMs are well-defined by the mapping theorem for the Poisson processes (Kingman, 1993), that is proved in (Foti et al., 2013).",2.2. The Thinned CRMs Framework,[0],[0]
"As a concrete example, we exploit a thinned gamma process (tGaP) to model the global atoms and their activity/inactivity at multiple time points originally developed for dynamic topic models.",2.2. The Thinned CRMs Framework,[0],[0]
"Let ν(dx,dθ,dr) = H(dx)G0(dθ)ν0(dr), where ν0(dr) = cr−1e−crdr is the Lévy measure of the gamma process.",2.2. The Thinned CRMs Framework,[0],[0]
"We transform a Gaussian basis kernel pointwise using a logistic function as the thinning function:
Pxk(t)",2.2. The Thinned CRMs Framework,[0],[0]
= σ,2.2. The Thinned CRMs Framework,[0],[0]
{ ω0k +,2.2. The Thinned CRMs Framework,[0],[0]
T∑ l=1 ωlk exp[−φk(t−,2.2. The Thinned CRMs Framework,[0],[0]
"l)2] } ,
where σ(x) = 1/(1 + exp(−x)) denotes the logistic function.",2.2. The Thinned CRMs Framework,[0],[0]
We fix the centres of these kernels to the T discrete time points in covariate space T .,2.2. The Thinned CRMs Framework,[0],[0]
"We characterize each location xk ∈ X by a set of T + 1 kernel weights ωlk ∈ R, and a (shared) kernel width φk uniformly drawn from a fixed dictionary {φ∗1, . . .",2.2. The Thinned CRMs Framework,[0],[0]
", φ∗D} of size D.",2.2. The Thinned CRMs Framework,[0],[0]
"To encourage sparsity of the kernel weights, we place a normalinverse gamma prior over ωlk, i.e., ωlk ∼ NIG(ωlk; 0, 1, 1).",2.2. The Thinned CRMs Framework,[0],[0]
"Hence, the base measure H(dx) can be expressed as H(dx) = NIG(ωlk; 0, 1, 1)Cat(φk; {φ∗1, . . .",2.2. The Thinned CRMs Framework,[0],[0]
", φ∗D}).",2.2. The Thinned CRMs Framework,[0],[0]
"The generative procedure can be expressed as
G = ∞∑ k=1 rkδ(xk,θk) ∼ CRM(ν(dx, dθ,dr)), (1)
ωlk ∼ NIG(0, 1, 1), φk ∼ Cat(φ∗1, . . .",2.2. The Thinned CRMs Framework,[0],[0]
", φ∗D),
Pxk(t)",2.2. The Thinned CRMs Framework,[0],[0]
= σ,2.2. The Thinned CRMs Framework,[0],[0]
{ ω0k +,2.2. The Thinned CRMs Framework,[0],[0]
T∑ l=1 ωlk exp[−φk(t−,2.2. The Thinned CRMs Framework,[0],[0]
"l)2] } ,
b (t) k ∼ Bernoulli [ Pxk(t) ] , G(t) = ∞∑ k=1 b (t) k rkδθk .",2.2. The Thinned CRMs Framework,[0],[0]
"We represent a dynamic network by a sequence of adjacency matrices A(t) for each time t = 1, 2, . . .",3. Model Formulation,[0],[0]
", T .",3. Model Formulation,[0],[0]
"For the sake of clarity, we limit our focus to unweighted (binary) undirected (symmetric) dynamic networks without self-links although the proposed model can straightforwardly be generalized to nonnegative real-weighted networks via the Poisson randomized gamma distribution (Zhou et al., 2016).",3. Model Formulation,[0],[0]
"We denote each snapshot of a dynamic network by A(t) ∈ {0, 1}N×N with N being the number of nodes.",3. Model Formulation,[0],[0]
"The binary symmetric matrix A(t) has entries A(t)ij = 1 if an edge between nodes i and j is present at time t, and A(t)ij = 0 otherwise.",3. Model Formulation,[0],[0]
"Let Π (t) ij be the link probability between nodes i and j. Our model specifies
A (t) ij",3. Model Formulation,[0],[0]
"| Π (t) ij ∼ Bernoulli(Π (t) ij ), t ∈ T
independently for each i = 2, . . .",3. Model Formulation,[0],[0]
", N and j = 1, . . .",3. Model Formulation,[0],[0]
", i− 1, with
E [ A
(t) ij",3. Model Formulation,[0],[0]
"| Π (t) ij
] = 1− exp ( −
K∑ k=1 K∑ k′=1 z (t) ik λ (t) kk′z (t) jk′
) ,
where z(t)ik ∈ R>0 characterizes the membership of node i to group k at time t ∈ T .",3. Model Formulation,[0],[0]
"In contrast to the latent feature relational models (Foulds et al., 2011; Heaukulani et al., 2013; Kim et al., 2013) that assume binary node-group relationships, our nonnegative memberships capture how strongly each node associates with multiple groups.",3. Model Formulation,[0],[0]
The group interaction weight λ(t)kk′ modulates the probability that there exists a link between a node affiliated to group k and a second node affiliated to group k′ at time t. Our framework exploits the dynamics of the underlying relations between nodes on two levels: (1) The latent groups can be active and inactive; and (2) the memberships of each node to groups evolve over time.,3. Model Formulation,[0],[0]
We now proceed to describe each component of our framework in the following sections.,3. Model Formulation,[0],[0]
"Many previous works (Kim et al., 2013; Xu, 2015) have shown that explicitly modelling the dynamics of latent groups using a distance-dependent Indian buffet process (dd-IBP) (Gershman et al., 2015) or a linear dynamical system discovers interpretable latent structures and achieves good predictive performance.",3.1. Model of Active Groups,[0],[0]
"Here, we build the group interaction weight λkk′ on the relational gamma process construction (Zhou, 2015).",3.1. Model of Active Groups,[0],[0]
"For implementation convenience, we use a truncated version of the infinite capacity model by fixing the maximum number of groups toK. That is, we first generate a group weight rk independently for each group k as rk ∼ Gamma(γ0/K, c), where γ0 denotes the concentration parameter and c denotes the rate parameters.",3.1. Model of Active Groups,[0],[0]
"Then,
the inter-group interaction weight λkk′ and intra-group interaction weight λkk can be generated as
λkk′ ∼
{ Gamma(ξrk, β), if k = k′
Gamma(rkrk′ , β), otherwise (2)
where ξ ∼ Gamma(1, 1) and β ∈ R>0.
",3.1. Model of Active Groups,[0],[0]
"For dynamic relational data, we exploit the thinned CRMs framework to capture the birth/death dynamics of latent groups assuming that the status of group k can be either active or inactive at time t. More specifically, we use a Bernoulli random variable b(t)k",3.1. Model of Active Groups,[0],[0]
"= 1 to indicate the presence of group k at time t, and b(t)k = 0 otherwise.",3.1. Model of Active Groups,[0],[0]
"Accordingly, the interaction weight between group k and k′ is active at time t only if the two groups are both active at that time, i.e., λ
(t) kk′ = λkk′b (t)",3.1. Model of Active Groups,[0],[0]
k b,3.1. Model of Active Groups,[0],[0]
"(t) k′ .
",3.1. Model of Active Groups,[0],[0]
Given the group interaction weight matrix Λ defined in Eq.,3.1. Model of Active Groups,[0],[0]
"(2), we generate the time-dependent group interaction weights λ(t)kk′ using the thinning function introduced in Section 2.2 with the prior specification:
ωlk ∼ NIG(0, 1, 1), φk ∼ Cat(φ∗1, . . .",3.1. Model of Active Groups,[0],[0]
", φ∗D),
Pxk(t)",3.1. Model of Active Groups,[0],[0]
= σ,3.1. Model of Active Groups,[0],[0]
{ ω0k +,3.1. Model of Active Groups,[0],[0]
T∑ l=1 ωlk exp[−φk(t−,3.1. Model of Active Groups,[0],[0]
"l)2] } ,
where we fix the centres of the covariate-dependent kernel functions to the T discrete time points of the considered dynamic network.",3.1. Model of Active Groups,[0],[0]
The probability of activity/inactivity of group k at time t can be determined by the thinning function.,3.1. Model of Active Groups,[0],[0]
A smooth thinning function can encourage the snapshots of a dynamic network at nearby covariate values t to share a similar set of groups.,3.1. Model of Active Groups,[0],[0]
"To capture the temporal dynamics of node-group memberships, we represent the individual memberships as independently evolving gamma Markov chains.",3.2. Dynamics of Node-Group Memberships,[0],[0]
"More specifically, the individual membership z(t)ik is assumed to be gamma distributed with shape parameter z(t−1)ik , where z (t−1) ik corresponds to the membership of the same node at the previous time, and rate parameter τ as
z (t) ik",3.2. Dynamics of Node-Group Memberships,[0],[0]
"∼ Gamma(z (t−1) ik , τ), t ∈ T (3) z (1) ik ∼ Gamma(θik, τ),
where we assume each membership starts off in a dummy state (θik for i = 1, . . .",3.2. Dynamics of Node-Group Memberships,[0],[0]
", N , and k = 1, . . .",3.2. Dynamics of Node-Group Memberships,[0],[0]
",K).",3.2. Dynamics of Node-Group Memberships,[0],[0]
"We place a gamma prior over the dummy node membership θik, i.e. θik ∼ Gamma(1, 1).",3.2. Dynamics of Node-Group Memberships,[0],[0]
"Given the group interaction weights {λ(t)kk′} and node-group memberships {z (t) ik } generated by our model, we generate an edge A(t)ij between two nodes i
and j at time t via the Bernoulli-Poisson link (BPL) function as
m (t) ij ∼ Poisson ( K∑ k=1 K∑ k′=1 z (t) ik λ",3.2. Dynamics of Node-Group Memberships,[0],[0]
"(t) kk′z (t) jk′ ) , (4)
",3.2. Dynamics of Node-Group Memberships,[0],[0]
"A (t) ij = 1(m (t) ij ≥ 1), t ∈ T
where mij is a latent Poisson count that measures how often nodes i and j interact in the latent space representation.",3.2. Dynamics of Node-Group Memberships,[0],[0]
Marginalizing out m(t)ij from Eq.,3.2. Dynamics of Node-Group Memberships,[0],[0]
"(4) yields
A (t) ij ∼ Bernoulli
[ 1− exp ( −
K∑ k=1 K∑ k′=1 z (t) ik λ (t) kk′z (t) jk′
)] .
",3.2. Dynamics of Node-Group Memberships,[0],[0]
"The conditional distribution of the latent count m(t)ij can be expressed as
(m (t) ij |",3.2. Dynamics of Node-Group Memberships,[0],[0]
"A (t) ij ,−) ∼",3.2. Dynamics of Node-Group Memberships,[0],[0]
A (t) ij Poisson+ ( K∑ k=1 K∑ k′=1 z (t) ik λ,3.2. Dynamics of Node-Group Memberships,[0],[0]
"(t) kk′z (t) jk′ ) ,
where x ∼ Poisson+(σ) is the zero-truncated Poisson distribution with support only on the positive integers, and “–” denotes all other variables.",3.2. Dynamics of Node-Group Memberships,[0],[0]
"We note that if A(t)ij = 0, then m(t)ij = 0 almost surely (a.s.), and if A (t) ij = 1, then m (t) ij ∼ Poisson+( ∑K k=1 ∑K k′=1 z (t) ik λ",3.2. Dynamics of Node-Group Memberships,[0],[0]
(t) kk′z (t) jk′).,3.2. Dynamics of Node-Group Memberships,[0],[0]
"Thus, the latent count m(t)ij only needs to be sampled for A (t) ij",3.2. Dynamics of Node-Group Memberships,[0],[0]
"= 1 with a rejection sampler (Zhou, 2015).",3.2. Dynamics of Node-Group Memberships,[0],[0]
This property makes the proposed model appealing for modelling large sparse dynamic networks because the computational cost of our model scales linearly with the number of edges.,3.2. Dynamics of Node-Group Memberships,[0],[0]
"As K → ∞, the group weights and their corresponding dummy node memberships vector constitute a draw from a gamma process as G = ∑∞",3.3. Bayesian Nonparametric Interpretation,[0],[0]
"k=1 rkδθk , where θk = (θ1k, . . .",3.3. Bayesian Nonparametric Interpretation,[0],[0]
", θNk) ∈ Θ is an atom sampled from a N-dimensional base measure G0(dθk)/G0(Θ) =∏N i=1",3.3. Bayesian Nonparametric Interpretation,[0],[0]
"Gamma(1, 1).",3.3. Bayesian Nonparametric Interpretation,[0],[0]
"Accordingly, the intra- and intergroup interaction weights and their corresponding pair of node memberships vector constitute a draw Λ | G =∑∞ k=1 ∑∞",3.3. Bayesian Nonparametric Interpretation,[0],[0]
"k′=1 λkk′δ(θk,θk′ ) from a relational gamma process (Zhou, 2015).",3.3. Bayesian Nonparametric Interpretation,[0],[0]
"Via the thinned CRMs framework, Λ(t) | Λ = ∑∞",3.3. Bayesian Nonparametric Interpretation,[0],[0]
k=1 ∑∞,3.3. Bayesian Nonparametric Interpretation,[0],[0]
k′=1 b (t) k b (t) k′,3.3. Bayesian Nonparametric Interpretation,[0],[0]
"λkk′δ(θk,θk′ ) can be viewed as a draw from a covariate-dependent relational gamma process.",3.3. Bayesian Nonparametric Interpretation,[0],[0]
"For brevity, the definitions of these processes are presented in the supplementary material.",3.3. Bayesian Nonparametric Interpretation,[0],[0]
"The full generative model (truncated) for the observed dynamic network data {A(t)}t∈T along with the latent vari-
ables, parameters, and hyperparameters, is given by
rk ∼ Gamma(γ0/K, c), θik ∼ Gamma(1, 1), (5) ξ ∼ Gamma(1, 1),
λkk′ ∼
{ Gamma(ξrk, β), if k = k′
Gamma(rkrk′ , β), otherwise
ωlk ∼ NIG(0, 1, 1), φk ∼ Cat(φ∗1, . . .",3.4. The Full Generative Model,[0],[0]
", φ∗D),
b (t) k ∼ Bernoulli ( σ { ω0k +",3.4. The Full Generative Model,[0],[0]
"T∑ l=1 ωlk exp[−φk(t− l)2] }) ,
z (t) ik",3.4. The Full Generative Model,[0],[0]
"∼ Gamma(z (t−1) ik , τ), z (1) ik ∼ Gamma(θik, τ),
λ (t) kk′ = b (t) k λkk′b (t) k′ ,m (t) ij ∼ Poisson  K∑ k,k′=1 z (t) ik λ (t) kk′z (t) jk′  , A
(t) ij",3.4. The Full Generative Model,[0],[0]
= 1(m (t) ij ≥ 1).,3.4. The Full Generative Model,[0],[0]
"LetA(1:t) denotes the sequenceA(1), . . .",3.5. Inference via Gibbs Sampling,[0],[0]
", A(t) and similarly for Z(1:t) and Λ(1:t).",3.5. Inference via Gibbs Sampling,[0],[0]
"The model parameters that need to be sampled include: latent node-group memberships {z(t)ik }, {θik}, individual group weights {rk}, scale parameter ξ, groups interaction weights {λkk′}, kernel weights {ωlk}, kernel widths {φk}, thinning variables {b(t)k }, and latent counts {m(t)ij }.",3.5. Inference via Gibbs Sampling,[0],[0]
"Exploiting the Pólya-gamma data augmentation technique (Polson et al., 2013) and the data augmentation and marginalization technique (Zhou et al., 2015), a simple and efficient Gibbs sampling algorithm is developed to perform the model inference.",3.5. Inference via Gibbs Sampling,[0],[0]
The details of our inference algorithm are presented in the supplementary material.,3.5. Inference via Gibbs Sampling,[0],[0]
"Prior works on dynamic networks modelling include the exponential random graph model (ERGM) (Guo et al., 2007), matrix and tensor factorization based methods (Dunlavy et al., 2011) and statistical models (Sarkar et al., 2007; 2014; Ishiguro et al., 2010; Durante et al., 2014b; Schein et al., 2016a; Palla et al., 2016).",4. Related Work,[0],[0]
"Statistical dynamic network models received considerable attention because these models have favourable interpretability by providing uncertainty estimates for the uncovered latent representations (Hoff et al., 2001).",4. Related Work,[0],[0]
"Dynamic extensions of the mixed membership stochastic blockmodel (MMSB) (Airoldi et al., 2008) have been developed (Fu et al., 2009; Xing et al., 2010; Ho et al., 2011) using linear state space models to capture the evolution of real-valued node-group memberships.",4. Related Work,[0],[0]
"Recently, an extended Kalman filter (EKF) based algorithm (Xu et al., 2014) was proposed to infer dynamic stochastic blockmodels (SBM) with competitive performance.",4. Related Work,[0],[0]
"Dynamic extensions of the latent feature relational model (LFRM) (Miller et al., 2009) using an infinite factorial hidden Markov pro-
cess to capture the evolution of binary node-group memberships include the dynamic relational infinite feature model (DRIFT) (Foulds et al., 2011), the latent feature propagation model (LFP) (Heaukulani et al., 2013), and the dynamic multi-group membership graph model (DMMG) (Kim et al., 2013).
",4. Related Work,[0],[0]
"Our proposed model is a form of Poisson factorization model (Zhou et al., 2015; Gopalan et al., 2015), and can be considered as the dynamic extension of the hierarchical gamma process edge partition model (HGPEPM) (Zhou, 2015).",4. Related Work,[0],[0]
"The dependent CRM framework (Foti et al., 2013) has been exploited for dynamic topic models and dependent latent feature models previously.",4. Related Work,[0],[0]
"To the best of our knowledge, this is the first attempt to model activity and inactivity of latent groups using a thinned CRMs framework in longitudinal network modelling.",4. Related Work,[0],[0]
"Our Markov chain construction, used to capture the evolution of node-group memberships, is inspired by the data augmentation technique (Zhou et al., 2015) that has been exploited for dynamic matrix factorization (Acharya et al., 2015a; Schein et al., 2016b) and deep gamma belief networks (Zhou et al., 2016).",4. Related Work,[0],[0]
"We note that the dynamic gamma process Poisson factorization (DGPPF) (Acharya et al., 2015b) has been proposed using gamma Markov chains to model the evolution of latent groups while the D-GPPF assumes node memberships are static over time.",4. Related Work,[0],[0]
Yang & Koeppl (2018) directly generalized the relational gamma process model to dynamic networks using gamma Markov chains to model node-group evolving behavior.,4. Related Work,[0],[0]
"For longitudinal networks, it is more reasonable to explicitly model the birth and death dynamics of latent groups by switching off redundant groups to avoid overfitting the data and to strengthen the interpretability of the latent network structure.",4. Related Work,[0],[0]
We demonstrate that the proposed Dependent Relational Gamma Process Model (DRGPM) infers more interpretable latent structure compared with the related methods using a synthetic example.,5. Experiments,[0],[0]
"Quantitive evaluations of our model, compared with state-of-the-art methods as discussed in Section 4, are performed in terms of missing link prediction and future network forecasting on three real-world data sets.",5. Experiments,[0],[0]
"The first baseline is the dynamic relational infinite feature model (DRIFT) for which we used the code provided by Foulds et al. (2011).1 Additionally, we implemented the D-GPPF, where we set the hyperparameters and initialized the model parameters with the values provided in (Acharya et al., 2015b).",5. Experiments,[0],[0]
"The third baseline is the dynamic stochastic blockmodel (DSBM) based on an extended Kalman filter (EKF) augmented with a local search, for which we use
1http://jfoulds.informationsystems.umbc.",5. Experiments,[0],[0]
"edu/code/DRIFT.tar.gz.
",5. Experiments,[0],[0]
the released code2 with the default settings.,5. Experiments,[0],[0]
"We also compare DRGPM with the hierarchical gamma process edge partition model (HGPEPM) (Zhou, 2015)3 and the dynamic Poisson gamma model (DPGM) (Yang & Koeppl, 2018) that only models the evolving node memberships.",5. Experiments,[0],[0]
"Moreover, we demonstrate that our model can discover highly interpretable latent structure on a military interstate disputes dataset.",5. Experiments,[0],[0]
"In the experiments, we set the hyperparameters for our model as γ0 = 1, β = 1, c = 1, τ = 1.",5. Experiments,[0],[0]
"Unless otherwise stated, we use K = N/2 for initilization, where N is the number of nodes.",5. Experiments,[0],[0]
A sensitivity analysis revealed that we obtain similar results when instead setting γ0 = 0.1 or γ0 = 10.,5. Experiments,[0],[0]
All the experiments were run on a standard desktop with 2.7 GHz CPU and 24 GB RAM.,5. Experiments,[0],[0]
"Following the procedure suggested by Durante et al. (2016), we generate synthetic data to evaluate our proposed model in estimating the formation and evolution of the latent network sturcture.",5.1. Simulation Study,[0],[0]
We consider a dynamic network with N = 50 nodes monitored for T = 70 equally spaced time snapshots.,5.1. Simulation Study,[0],[0]
"To generate a time-varying network, we first generate five regimes defining the true edge probabilities, as shown in Figure 2.",5.1. Simulation Study,[0],[0]
"We then simulate the network edges A
(t) ij",5.1. Simulation Study,[0],[0]
| Π (t) ij ∼ Bernoulli(Π (t) ij ),5.1. Simulation Study,[0],[0]
with each of the five regimes according to Figure 1.,5.1. Simulation Study,[0],[0]
"To demonstrate that DRGPM can infer interpretable latent structure while avoiding to overfit the data, we compare DRGPM with D-GPPF and DPGM.",5.1. Simulation Study,[0],[0]
"We initialize all methods setting K = 30.
2https://tinyurl.com/ydf29he9. 3https://github.com/mingyuanzhou/EPM.
redundant groups over time, which strengthens the model interpretability for longitudinal network analysis.",5.1. Simulation Study,[0],[0]
"In Figure 4, we depict the thinning probabilities (mean of b(t)k ) over time for six inferred active groups by DRGPM.",5.1. Simulation Study,[0],[0]
"We notice that
DRGPM infers three groups (4, 11, 24) at t = 0, turns off Group 4 and turns on Groups 3 and 7 at t = 10.",5.1. Simulation Study,[0],[0]
Group 28 is only active from t = 30 to 40.,5.1. Simulation Study,[0],[0]
The comparison of DRGPM to DPGM is presented in the supplementary material.,5.1. Simulation Study,[0],[0]
"For the quantitative evaluation, we consider the following data sets: (1) Face-to-face dynamic contacts network (FFDC): This dataset (Mastrandrea et al., 2015) records timestamped face-to-face contacts among 180 students for 7 school days.",5.2. Quantitative Results,[0],[0]
"We generated a dynamic network considering each school day as a snapshot, and created an edge between each pair of students at time t if they have at least one contact recorded at that given time.",5.2. Quantitative Results,[0],[0]
(2) DBLP:,5.2. Quantitative Results,[0],[0]
"The DBLP co-authorship network data (Asur et al., 2009) contains the co-authorship information among 958 authors over ten years (1997-2006) in 28 conferences which spans three related research topics-database, data mining, and artificial
intelligence.",5.2. Quantitative Results,[0],[0]
We focus on a subset of 324 most connected authors over all time period.,5.2. Quantitative Results,[0],[0]
"(3) Enron: The Enron data4 contains 517,431 emails among 151 users over 38 months (from May 1999 to June 2002).",5.2. Quantitative Results,[0],[0]
"We generated a dynamic network aggregating the data into monthly snapshots, and created an edge between each pair of users at time t if they have at least one email recorded at that given time.",5.2. Quantitative Results,[0],[0]
"The summary statistics are detailed in Table 2.
",5.2. Quantitative Results,[0],[0]
Task 1:,5.2. Quantitative Results,[0],[0]
"Predicting missing links First, we perform missing link prediction on the real-world data sets, and show the proposed model’s predictive performance compared to the baseline models.",5.2. Quantitative Results,[0],[0]
"We randomly hold out 20% of the network entries (either links or non-links) for each snapshot as test data, and use the remaining 80% to predict the held-out entries.",5.2. Quantitative Results,[0],[0]
DRIFT was infeasible to run on the Enron dataset in a reasonable amount of time given our computational resource.,5.2. Quantitative Results,[0],[0]
"For DSBM, we either set K to the true number of classes provided by the data set or initialize it by examining the singular values of the first snapshot (Xu et al., 2014).",5.2. Quantitative Results,[0],[0]
We apply HGPEPM to each snapshot of dynamic networks independently.,5.2. Quantitative Results,[0],[0]
"For all probabilistic methods, we use 2000 burn-in iterations, and collect 1000 samples from the model posterior distribution.",5.2. Quantitative Results,[0],[0]
We estimate the posterior mean of the edge probability for each held-out edge in the test data by averaging over the collected Gibbs samples.,5.2. Quantitative Results,[0],[0]
We then use these edge probabilities to evaluate the predictive performance of each model by calculating the area under the curve of the receiver operating characteristic (AUROC) and of the precision-recall (PR).,5.2. Quantitative Results,[0],[0]
"In Table 1, we report the average evaluation metrics for each model over 10 runs.",5.2. Quantitative Results,[0],[0]
"Overall, we found that DRIFT performs slightly better than
4https://www.cs.cmu.edu/˜enron/.
DRGPM, although DRGPM has a significant advantage in terms of computational cost due to the Bernoulli-Poisson link (see Section 5.3).",5.2. Quantitative Results,[0],[0]
"HGPEPM performs better than the dynamic models on the DBLP dataset because co-authorship links change dramatically from one year to the next one, and hence, the static model is better at fitting each snapshot independently.",5.2. Quantitative Results,[0],[0]
"For the longitudinal Enron email network that is recorded monthly, DRGPM performs better than the baseline methods.
",5.2. Quantitative Results,[0],[0]
"Task 2: Forecasting future networks Next, we consider the task of forecasting an unseen network snapshot A(t) given observed snapshots A(1:t−1).",5.2. Quantitative Results,[0],[0]
"Following previous works (Foulds et al., 2011; Heaukulani et al., 2013; Kim et al., 2013), we train the models on the first (t−1) snapshots of the considered network, and then estimate the predictive distribution of the unseen snapshot A(t) by running MCMC sampling one time step into the future.",5.2. Quantitative Results,[0],[0]
"We apply HGPEPM to the most recent snapshot A(t−1), and then to perform prediction on the unseen snapshot A(t).",5.2. Quantitative Results,[0],[0]
"For DRGPM, we set Λ(t) = Λ(t−1), assuming the snapshots at nearby time points share a similar set of groups.",5.2. Quantitative Results,[0],[0]
We generated 10 samples of Z(t) for each of the 1000 samples collected for Z(t−1).,5.2. Quantitative Results,[0],[0]
"For DSBM, we use the method detailed in (Xu et al., 2014) to perform future network forecasting.",5.2. Quantitative Results,[0],[0]
Table 1 shows the averaged performance for each model over different network snapshots from 3 to T .,5.2. Quantitative Results,[0],[0]
"Overall, DRGPM shows competitive performance on all three datasets.",5.2. Quantitative Results,[0],[0]
This confirms that DRGPM can flexibly characterize temporally local links via time-evolving node memberships and switch off redundant groups to avoid overfitting the data.,5.2. Quantitative Results,[0],[0]
The probilistic models achieve higher accuracy although these methods require more computation time to collect MCMC samples.,5.3. Running Time,[0],[0]
"DSBM is much faster than the probabilistc models because its inference is performed using the
extended Kalman filter.",5.3. Running Time,[0],[0]
Table 3 compares the per-iteration computation time of the sampling-based models (all models are implemented in Matlab).,5.3. Running Time,[0],[0]
"The computational cost of DRIFT scales inO(K̄2N2T ), where K̄ is the expected number of groups.",5.3. Running Time,[0],[0]
"The Bernoulli-Poisson link based models (DGPPF, DPGM, DRGPM) are much faster than the logistic link based method (DRIFT) because the former models scale linearly with the number of non-zero entries in network data.",5.3. Running Time,[0],[0]
"For DRGPM, sampling {m(t)ij }i,j,t and {m (t) ikk′j}i,j,k,k′,t takes O(NeK̄2) with Ne being the number of non-zero entries.",5.3. Running Time,[0],[0]
"Sampling {z(t)ik }i,k,t takes O(NK̄T ) and sampling {λ(t)kk′}k,k′,t takes O(K̄2T ).",5.3. Running Time,[0],[0]
"Overall, the computational complexity of DRGPM is O(NeK̄2 + NK̄T + K̄2T ).",5.3. Running Time,[0],[0]
"The computational complexity of D-GPPF and DPGM is O(NeK̄ +NK̄ + K̄T ) and O(NeK̄2 +NK̄T + K̄2), respectively.",5.3. Running Time,[0],[0]
DRGPM is slightly faster than DPGM because DRGPM can effectively turn off redundant groups and hence achieves a lower computational cost.,5.3. Running Time,[0],[0]
"We investigate the military interstate disputes (MID) dataset that contains disputes events between 138 countries from 1992 to 2001 (Ghosn et al., 2004) to explore the latent structure discovered by DRGPM.",5.4. Case Study: Military Interstate Disputes Dataset,[0],[0]
A dynamic network was generated by aggregating the data into monthly snapshots and a link was created between each pair of two countries if either country has disputes with the other one at that given time.,5.4. Case Study: Military Interstate Disputes Dataset,[0],[0]
We applied DRGPM to this dynamic network initializing K = 30 groups.,5.4. Case Study: Military Interstate Disputes Dataset,[0],[0]
Most of the identified groups correspond to some regional relations or conflicts.,5.4. Case Study: Military Interstate Disputes Dataset,[0],[0]
"In Figure 5, we depict four interesting groups inferred by DRGPM and show the group activity by plotting the mean of the thinning function b (t) k .",5.4. Case Study: Military Interstate Disputes Dataset,[0],[0]
"We normalized the node memberships to [0, 1] by dividing them by the sum of memberships within the same group.",5.4. Case Study: Military Interstate Disputes Dataset,[0],[0]
"In Table 4, we report the top 20 nodes associated to each
of four groups with positive memberships.",5.4. Case Study: Military Interstate Disputes Dataset,[0],[0]
"For instance, we found that Group 1 corresponds to the second Congo war (1998-2000).",5.4. Case Study: Military Interstate Disputes Dataset,[0],[0]
The first six nodes of the group are indeed the belligerents of this war.,5.4. Case Study: Military Interstate Disputes Dataset,[0],[0]
"Group 2 corresponds to the Bosnian War (1992-1995), and its associated nodes are Yugoslavia and some NATO members that are indeed the belligerents of this war.",5.4. Case Study: Military Interstate Disputes Dataset,[0],[0]
Groups 3 and 4 are related to the regional disputes between some African countries.,5.4. Case Study: Military Interstate Disputes Dataset,[0],[0]
"Additional graphs of the inferred groups, and tables showing the associated nodes are presented in the supplementary material.",5.4. Case Study: Military Interstate Disputes Dataset,[0],[0]
We proposed a probabilistic framework for longitudinal network modelling based on the covariate-dependent relational gamma process.,6. Conclusion,[0],[0]
"Our framework can characterize the group birth/death dynamics using the thinned CRM, which enables us to investigate the evolution of the inferred latent structure.",6. Conclusion,[0],[0]
The inferred latent dynamic structure can be useful for various qualitative analyses in practical applications.,6. Conclusion,[0],[0]
We experimentally demonstrated the competitive predictive performance and scalability of our framework on three real-world datasets.,6. Conclusion,[0],[0]
Our generative model can be easily extended in many interesting ways.,6. Conclusion,[0],[0]
"For instance, it can be extended to dynamic multilayer networks (Durante et al., 2017) with relational data arising from multiple-related contexts via multi-level hierarchical gamma processes (Zhou et al., 2015).",6. Conclusion,[0],[0]
"Additionally, network side information can be flexibly leveraged via a regression model (Rai et al., 2015).",6. Conclusion,[0],[0]
The authors thank the anonymous reviewers and Adrian Šošić for their useful comments and suggestions.,Acknowledgements,[0],[0]
This research is funded by the European Union’s Horizon 2020 research and innovation programme under grant agreement 668858.,Acknowledgements,[0],[0]
A probabilistic framework based on the covariatedependent relational gamma process is developed to analyze relational data arising from longitudinal networks.,abstractText,[0],[0]
"The proposed framework characterizes networked nodes by nonnegative nodegroup memberships, which allow each node to belong to multiple latent groups simultaneously, and encodes edge probabilities between each pair of nodes using a Bernoulli Poisson link to the embedded latent space.",abstractText,[0],[0]
"Within the latent space, our framework models the birth and death dynamics of individual groups via a thinning function.",abstractText,[0],[0]
Our framework also captures the evolution of individual node-group memberships over time using gamma Markov processes.,abstractText,[0],[0]
"Exploiting the recent advances in data augmentation and marginalization techniques, a simple and efficient Gibbs sampler is proposed for posterior computation.",abstractText,[0],[0]
"Experimental results on a simulation study and three realworld temporal network data sets demonstrate the model’s capability, competitive performance and scalability compared to state-of-the-art methods.",abstractText,[0],[0]
Dependent Relational Gamma Process Models for Longitudinal Networks,title,[0],[0]
"Deep learning, in the form of artificial neural networks, has seen a dramatic resurgence in the past recent years, achieving great performance improvements in various fields of artificial intelligence such as computer vision and speech recognition.",1. Introduction,[0],[0]
"While empirically successful, our theoretical understanding of deep learning is still limited at best.
",1. Introduction,[0],[0]
An emerging line of recent works has studied the expressive power of neural networks: What functions can and cannot be represented by networks of a given architecture (see related work section below).,1. Introduction,[0],[0]
"A particular focus has been the trade-off between the network’s width and depth: On the one hand, it is well-known that large enough networks of depth 2 can already approximate any continuous target function on [0, 1]d to arbitrary accuracy (Cybenko, 1989; Hornik, 1991).",1. Introduction,[0],[0]
"On the other hand, it has long been evident that deeper networks tend to perform better than shallow ones, a phenomenon supported by the intuition that depth, providing compositional expressibility, is necessary for efficiently representing some functions.",1. Introduction,[0],[0]
"Moreover, re-
1Weizmann Institute of Science, Rehovot, Israel.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Itay Safran <itay.safran@weizmann.ac.il>, Ohad Shamir <ohad.shamir@weizmann.ac.il>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
cent empirical evidence suggests that standard feedforward deep networks are harder to optimize than shallower networks which lead to worse training error and testing error (He et al., 2015).
",1. Introduction,[0],[0]
"To demonstrate the power of depth in neural networks, a clean and precise approach is to prove the existence of functions which can be expressed (or well-approximated) by moderately-sized networks of a given depth, yet cannot be approximated well by shallower networks, even if their size is much larger.",1. Introduction,[0],[0]
"However, the mere existence of such functions is not enough: Ideally, we would like to show such depth separation results using natural, interpretable functions, of the type we may expect neural networks to successfully train on.",1. Introduction,[0],[0]
"Proving that depth is necessary for such functions can give us a clearer and more useful insight into what various neural network architectures can and cannot express in practice.
",1. Introduction,[0],[0]
"In this paper, we provide several contributions to this emerging line of work.",1. Introduction,[0],[0]
"We focus on standard, vanilla feedforward networks (using some fixed activation function, such as the popular ReLU), and measure expressiveness directly in terms of approximation error, defined as the expected squared loss with respect to some distribution over the input domain.",1. Introduction,[0],[0]
"In this setting, we show the following:
• We prove that the indicator of the Euclidean unit ball, x 7→ 1 (‖x‖ ≤ 1) in Rd, which can be easily approximated to accuracy using a 3-layer network with O(d2/ ) neurons, cannot be approximated to an accuracy higher than O(1/d4) using a 2-layer network, unless its width is exponential in d.",1. Introduction,[0],[0]
"In fact, we show the same result more generally, for any indicator of an ellipsoid x 7→ 1 (‖Ax + b‖ ≤ r) (where A is a non-singular matrix and b is a vector).",1. Introduction,[0],[0]
"The proof is based on a reduction from the main result of (Eldan & Shamir, 2016), which shows a separation between 2- layer and 3-layer networks using a more complicated and less natural radial function.
",1. Introduction,[0],[0]
"• We prove that any L1 radial function x 7→ f(‖x‖1), where x ∈ Rd and f : R → R is piecewise-linear, cannot be approximated to accuracy by a depth 2 ReLU network of width less than
Ω̃(min{1/ , exp(Ω(d))}).",1. Introduction,[0],[0]
"In contrast, such functions can be represented exactly by 3-layer ReLU networks.
",1. Introduction,[0],[0]
"• We show that this depth/width trade-off can also be observed experimentally: Specifically, that when using standard backpropagation to learn the indicators of the L1 and L2 unit balls, 3-layer nets give significantly better performance compared to 2-layer nets (even if much larger).",1. Introduction,[0],[0]
Our theoretical results indicate that this gap in performance is due to approximation error issues.,1. Introduction,[0],[0]
"This experiment also highlights the fact that our separation result is for a natural function that is not just well-approximated by some 3-layer network, but can also be learned well from data using standard methods.
",1. Introduction,[0],[0]
"• Finally, we prove that any member of a wide family of non-linear and twice-differentiable functions (including for instance x 7→ x2 in [0, 1]), which can be approximated to accuracy using ReLU networks of depth and width O(poly(log(1/ ))), cannot be approximated to similar accuracy by constantdepth ReLU networks, unless their width is at least Ω(poly(1/ )).",1. Introduction,[0],[0]
"We note that a similar result appeared online concurrently and independently of ours in (Yarotsky, 2016; Liang & Srikant, 2016), but the setting is a bit different (see related work below for more details).
",1. Introduction,[0],[0]
"RELATED WORK
The question of studying the effect of depth in neural network has received considerable attention recently, and studied under various settings.",1. Introduction,[0],[0]
"Many of these works consider a somewhat different setting than ours, and hence are not directly comparable.",1. Introduction,[0],[0]
"These include networks which are not plain-vanilla ones (e.g. (Cohen et al., 2016; Delalleau & Bengio, 2011; Martens & Medabalimi, 2014)), measuring quantities other than approximation error (e.g. (Bianchini & Scarselli, 2014; Poole et al., 2016)), focusing only on approximation upper bounds (e.g. (Shaham et al., 2016)), or measuring approximation error in terms of L∞-type bounds, i.e. supx |f(x)",1. Introduction,[0],[0]
− f̃(x))| rather than L2-type bounds Ex(f(x),1. Introduction,[0],[0]
"− f̃(x))2 (e.g. (Yarotsky, 2016; Liang & Srikant, 2016)).",1. Introduction,[0],[0]
"We note that the latter distinction is important: Although L∞ bounds are more common in the approximation theory literature, L2 bounds are more natural in the context of statistical machine learning problems (where we care about the expected loss over some distribution).",1. Introduction,[0],[0]
"Moreover, L2 approximation lower bounds are stronger, in the sense that an L2 lower bound easily translates to a lower bound on L∞ lower bound, but not vice versa1.
1To give a trivial example, ReLU networks always express continuous functions, and therefore can never approximate a dis-
A noteworthy paper in the same setting as ours is (Telgarsky, 2016), which proves a separation result between the expressivity of ReLU networks of depth k and depth",1. Introduction,[0],[0]
o (k/ log (k)),1. Introduction,[0],[0]
(for any k).,1. Introduction,[0],[0]
"This holds even for onedimensional functions, where a depth k network is shown to realize a saw-tooth function with exp(O(k)) oscillations, whereas any network of depth o (k/ log (k)) would require a width super-polynomial in k to approximate it by more than a constant.",1. Introduction,[0],[0]
"In fact, we ourselves rely on this construction in the proofs of our results in section 5.",1. Introduction,[0],[0]
"On the flip side, in our paper we focus on separation in terms of the accuracy or dimension, rather than a parameter",1. Introduction,[0],[0]
"k. Moreover, the construction there relies on a highly oscillatory function, with Lipschitz constant exponential in k almost everywhere.",1. Introduction,[0],[0]
"In contrast, in our paper we focus on simpler functions, of the type that are likely to be learnable from data using standard methods.
",1. Introduction,[0],[0]
"Our separation results in Sec. 5 (for smooth non-linear functions) are closely related to those of (Yarotsky, 2016; Liang & Srikant, 2016), which appeared online concurrently and independently of our work, and the proof ideas are quite similar.",1. Introduction,[0],[0]
"However, these papers focused on L∞ bounds rather than L2 bounds.",1. Introduction,[0],[0]
"Moreover, (Yarotsky, 2016) considers a class of functions different than ours in their positive results, and (Liang & Srikant, 2016) consider networks employing a mix of ReLU and threshold activations, whereas we consider a purely ReLU network.
",1. Introduction,[0],[0]
"Another relevant and insightful work is (Poggio et al., 2016), which considers width vs. depth and provide general results on expressibility of functions with a compositional nature.",1. Introduction,[0],[0]
"However, the focus there is on worse-case approximation over general classes of functions, rather than separation results in terms of specific functions as we do here, and the details and setting is somewhat orthogonal to ours.",1. Introduction,[0],[0]
"In general, we let bold-faced letters such as x = (x1, . . .",2. Preliminaries,[0],[0]
", xd) denote vectors, and capital letters denote matrices or probabilistic events.",2. Preliminaries,[0],[0]
"‖·‖ denotes the Euclidean norm, and ‖·‖1 the 1-norm.",2. Preliminaries,[0],[0]
1 (·) denotes the indicator function.,2. Preliminaries,[0],[0]
"We use the standard asymptotic notationO(·) and Ω(·) to hide constants, and Õ(·) and Ω̃(·) to hide constants and factors logarithmic in the problem parameters.
",2. Preliminaries,[0],[0]
Neural Networks.,2. Preliminaries,[0],[0]
"We consider feed-forward neural networks, computing functions from Rd to R. The network is composed of layers of neurons, where each neuron computes a function of the form x 7→",2. Preliminaries,[0],[0]
"σ(w>x + b), where w
continuous function such as x 7→ 1 (x ≥ 0) in an L∞ sense, yet can easily approximate it in an L2 sense given any continuous distribution.
",2. Preliminaries,[0],[0]
"is a weight vector, b is a bias term and σ :",2. Preliminaries,[0],[0]
"R 7→ R is a non-linear activation function, such as the ReLU function σ(z) =",2. Preliminaries,[0],[0]
"[z]+ = max{0, z}.",2. Preliminaries,[0],[0]
"Letting σ(Wx+b) be a shorthand for ( σ(w>1 x + b1), . . .",2. Preliminaries,[0],[0]
", σ(w > n",2. Preliminaries,[0],[0]
"x + bn) ) , we define a layer of n neurons as x 7→ σ(Wx + b).",2. Preliminaries,[0],[0]
"By denoting the output of the ith layer as Oi, we can define a network of arbitrary depth recursively by Oi+1 = σ(Wi+1Oi+bi+1), where Wi,bi represent the matrix of weights and bias of the ith layer, respectively.",2. Preliminaries,[0],[0]
"Following a standard convention for multi-layer networks, the final layer h is a purely linear function with no bias, i.e. Oh = Wh ·Oh−1.",2. Preliminaries,[0],[0]
"We define the depth of the network as the number of layers l, and denote the number of neurons ni in the ith layer as the size of the layer.",2. Preliminaries,[0],[0]
"We define the width of a network as maxi∈{1,...,l} ni.",2. Preliminaries,[0],[0]
"Finally, a ReLU network is a neural network where all the non-linear activations are the ReLU function.",2. Preliminaries,[0],[0]
We use “2- layer” and “3-layer” to denote networks of depth 2 and 3.,2. Preliminaries,[0],[0]
"In particular, in our notation a 2-layer ReLU network has the form
x 7→ n1∑ i=1",2. Preliminaries,[0],[0]
vi ·,2. Preliminaries,[0],[0]
"[w>i x + bi]+
for some parameters v1, b1, . . .",2. Preliminaries,[0],[0]
", vn1 , bn1 and ddimensional vectors w1, . . .",2. Preliminaries,[0],[0]
",wn1 .",2. Preliminaries,[0],[0]
"Similarly, a 3-layer ReLU network has the form
n2∑ i=1",2. Preliminaries,[0],[0]
"ui  n1∑ j=1 vi,j",2. Preliminaries,[0],[0]
"[ w>i,jx + bi,j ]",2. Preliminaries,[0],[0]
"+ + ci  +
for some parameters {ui, vi,j , bi,j , ci,wi,j}.
Approximation error.",2. Preliminaries,[0],[0]
"Given some function f on a domain X endowed with some probability distribution (with density function µ), we define the quality of its approximation by some other function f̃ as ∫ X (f(x) − f̃(x))",2. Preliminaries,[0],[0]
2µ(x)dx = Ex∼µ[(f(x),2. Preliminaries,[0],[0]
− f̃(x))2].,2. Preliminaries,[0],[0]
We refer to this as approximation in the L2-norm sense.,2. Preliminaries,[0],[0]
"In one of our results (Thm. 6), we also consider approximation in the L∞-norm sense, defined as supx∈X |f(x)− f̃(x)|.",2. Preliminaries,[0],[0]
"Clearly, this upper-bounds the (square root of the) L2 approximation error defined above, so as discussed in the introduction, lower bounds on the L2 approximation error (w.r.t.",2. Preliminaries,[0],[0]
any distribution) are stronger than lower bounds on theL∞ approximation error.,2. Preliminaries,[0],[0]
"We begin by considering one of the simplest possible function classes on Rd, namely indicators of L2 balls (and more generally, ellipsoids).",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"The ability to compute such functions is necessary for many useful primitives, for example determining if the distance between two points in Euclidean space is below or above some threshold (either with respect to the Euclidean distance, or a more general Mahalanobis distance).",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"In this section, we show a depth separation result for such functions: Although they can be easily
approximated with 3-layer networks, no 2-layer network can approximate it to high accuracy w.r.t.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"any distribution, unless its width is exponential in the dimension.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"This is formally stated in the following theorem:
Theorem 1 (Inapproximability with 2-layer networks).",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"The following holds for some positive universal constants c1, c2, c3, c4, and any network employing an activation function satisfying Assumptions 1 and 2 in Eldan & Shamir (2016):",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"For any d > c1, and any non-singular matrix A ∈ Rd×d, b ∈ Rd and r ∈ (0,∞), there exists a continuous probability distribution γ on Rd, such that for any function g computed by a 2-layer network of width at most c3 exp(c4d), and for the function f(x) = 1 (‖Ax + b‖ ≤ r), we have∫
Rd (f(x)− g(x))2 ·",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"γ(x)dx ≥ c2 d4 .
",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"We note that the assumptions from (Eldan & Shamir, 2016) are very mild, and apply to all standard activation functions, including ReLU, sigmoid and threshold.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"For completeness, the fully stated assumptions are presented in Subsection A.1
The formal proof of Thm. 1 (provided below) is based on a reduction from the main result of (Eldan & Shamir, 2016), which shows the existence of a certain radial function (depending on the input x only through its norm) and a probability distribution which cannot be expressed by a 2-layer network, whose width is less than exponential in the dimension d to more than constant accuracy.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
A closer look at the proof reveals that this function (denoted as g̃) can be expressed as a sum of Θ(d2) indicators of L2 balls of various radii.,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"We argue that if we could have accurately approximated a given L2 ball indicator with respect to all distributions, then we could have approximated all the indicators whose sum add up to g̃, and hence reach a contradiction.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"By a linear transformation argument, we show the same contradiction would have occured if we could have approximated the indicators of an non-degenerate ellipse with respect to any distribution.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"The formal proof is provided below:
Proof of Thm. 1.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"Assume by contradiction that for f as described in the theorem, and for any distribution γ, there exists a 2-layer network f̃γ of width at most c3 exp(c4d), such that∫
x∈Rd
( f(x)− f̃γ(x) )",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
2 γ(x)dx ≤ ≤,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"c2
d4 .
",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"Let Â and b̂ be a d × d non-singular matrix and vector respectively, to be determined later.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"We begin by performing a change of variables, y = Âx+b̂ ⇐⇒ x = Â−1(y−b̂),
dx = ∣∣∣det(Â−1)∣∣∣ · dy, which yields∫
y∈Rd
( f ( Â−1 ( y − b̂ ))",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
− f̃γ ( Â−1 ( y − b̂ )))2 · γ ( Â−1 ( y − b̂ )) · ∣∣∣det(Â−1)∣∣∣ · dy ≤ .,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"(1)
In particular, let us choose the distribution γ defined as γ(z) = |det(Â)| · µ(Âz + b̂), where µ is the (continuous) distribution used in the main result of (Eldan & Shamir, 2016) (note that γ is indeed a distribution, since ∫ z",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"γ (z) =
(det(Â)) ∫",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"z µ(Âz+b̂)dz, which by the change of variables
x = Âz + b̂, dx = |det(Â)|dz equals ∫ x µ(x)dx = 1).",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
Plugging the definition of γ in Eq.,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"(1), and using the fact that |det(Â−1)| · | det(Â)| = 1, we get∫
y∈Rd
( f ( Â−1 ( y − b̂ ))",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
− f̃γ ( Â−1 ( y − b̂ )))2 · µ (y) dy ≤ .,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"(2)
Letting z > 0 be an arbitrary parameter, we now pick Â = z rA and b̂ = z rb.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"Recalling the definition of f as x 7→ 1 (‖Ax + b‖ ≤ r), we get that∫ y∈Rd ( 1 (‖y‖ ≤ z)− f̃γ",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"(r z A−1 ( y − z r b )))2
· µ (y) dy ≤ .",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
(3) Note that f̃γ ( r zA −1,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"(y − zrb)) expresses a 2-layer network composed with a linear transformation of the input, and hence can be expressed in turn by a 2-layer network (as we can absorb the linear transformation into the parameters of each neuron in the first layer).",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"Therefore, letting ‖f‖L2(µ) = √∫ y f2(y)dy denote the norm in L2(µ) function space, we showed the following: For any z > 0, there exists a 2-layer network f̃z such that∥∥∥(1 (‖·‖ ≤ z)− f̃z (·))",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"∥∥∥
L2(µ) ≤ √ .",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"(4)
With this key result in hand, we now turn to complete the proof.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"We consider the function g̃ from (Eldan & Shamir, 2016), for which it was proven that no 2-layer network can approximate it w.r.t. µ to better than constant accuracy, unless its width is exponential in the dimension d. In particular g̃ can be written as
g̃(x) = n∑ i=1",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
i · 1 (‖x‖ ∈,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"[ai, bi]) ,
where [ai, bi] are disjoint intervals, i ∈ {−1,+1}, and n = Θ(d2) where d is the dimension.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"Since g̃ can also be written as
n∑ i=1",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"i (1 (‖x‖ ≤ bi)− 1 (‖x‖ ≤ ai)) ,
we get by Eq.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
(4) and the triangle inequality that∥∥∥∥∥g̃(·)− n∑ i=1,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
i · (f̃bi(·)− f̃ai(·) ∥∥∥∥∥,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"L2(µ)
≤ n∑ i=1",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"| i| (∥∥∥(1 (‖·‖ ≤ bi)− f̃bi)∥∥∥ L2(µ)
+ ∥∥∥1",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"(‖·‖ ≤ ai)− f̃ai(·)∥∥∥
L2(µ) )",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"≤ 2n √ .
",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"However, since a linear combination of 2n 2-layer neural networks of width at most w is still a 2-layer network, of width at most 2nw, we get that ∑n i=1",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"i · (f̃bi(·) − f̃ai(·)) is a 2-layer network, of width at most Θ(d2) ·",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"c3 exp(c4d), which approximates g̃ to an accuracy of less than 2n √ =
Θ(d2) ·",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
√ c2/d4 = Θ(1) · √ c2.,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"Hence, by picking c2, c3, c4 sufficiently small, we get a contradiction to the result of (Eldan & Shamir, 2016), that no 2-layer network of width smaller than c exp(cd) (for some constant c) can approximate g̃ to more than constant accuracy, for a sufficiently large dimension d.
To complement Thm. 1, we also show that such indicator functions can be easily approximated with 3-layer networks.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"The argument is quite simple: Using an activation such as ReLU or Sigmoid, we can use one layer to approximate any Lipschitz continuous function on any bounded interval, and in particular x 7→ x2.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"Given a vector x ∈ Rd, we can apply this construction on each coordinate xi seperately, hence approximating x 7→ ‖x‖2 = ∑d i=1",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
x 2 i .,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"Similarly, we can approximate x 7→",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
‖Ax,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
+ b‖ for arbitrary fixed matrices A and vectors b.,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"Finally, with a 3-layer network, we can use the second layer to compute a continuous approximation to the threshold function z 7→ 1 (z ≤ r).",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"Composing these two layers, we get an arbitrarily good approximation to the function x 7→ 1 (‖Ax + b‖ ≤ r) w.r.t.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"any continuous distribution, with the network size scaling polynomially with the dimension d and the required accuracy.",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"In the theorem below, we formalize this intuition, where for simplicity we focus on approximating the indicator of the unit ball:
Theorem 2 (Approximability with 3-layer networks).",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"Given δ > 0, for any activation function σ satisfying Assumption 1 in Eldan & Shamir (2016) and any continuous probability distribution µ on Rd, there exists a constant cσ dependent only on σ, and a function g expressible by a 3- layer network of width at most max { 8cσd 2/δ, cσ √ 1/2δ }
, such that the following holds:∫
Rd (g (x)− 1 (‖x‖2 ≤ 1)) 2 µ (x) dx ≤ δ,
where cσ is a constant depending solely on σ.
",3. Indicators of L2 Balls and Ellipsoids,[0],[0]
The proof of the theorem appears in the supplementary material,3. Indicators of L2 Balls and Ellipsoids,[0],[0]
"In this subsection, we empirically demonstrate that indicator functions of L2 balls are indeed easier to learn with a 3-layer network, compared to a 2-layer network (even if the 2-layer network is significantly larger).",3.1. An Experiment,[0],[0]
"This indicates that the depth/width trade-off for indicators of balls, predicted by our theory, can indeed be observed experimentally.",3.1. An Experiment,[0],[0]
"Moreover, it highlights the fact that our separation result is for simple natural functions, that can be learned reasonably well from data using standard methods.
",3.1. An Experiment,[0],[0]
"For our experiment, we sampled 5 · 105 data instances in R100, with a direction chosen uniformly at random and a norm drawn uniformly at random from the interval",3.1. An Experiment,[0],[0]
"[0, 2].",3.1. An Experiment,[0],[0]
"To each instance, we associated a target value computed according to the target function f(x) = 1 (‖x‖2 ≤ 1).",3.1. An Experiment,[0],[0]
"Another 5 · 104 examples were generated in a similar manner and used as a validation set.
",3.1. An Experiment,[0],[0]
"We trained 5 ReLU networks on this dataset:
• One 3-layer network, with a first hidden layer of size 100, a second hidden layer of size 20, and a linear output neuron.
",3.1. An Experiment,[0],[0]
"• Four 2-layer networks, with hidden layer of sizes 100, 200, 400 and 800, and a linear output neuron.
",3.1. An Experiment,[0],[0]
"Training was performed with backpropagation, using the TensorFlow library.",3.1. An Experiment,[0],[0]
"We used the squared loss `(y, y′) =",3.1. An Experiment,[0],[0]
(y − y′)2 and batches of size 100.,3.1. An Experiment,[0],[0]
"For all networks, we chose a momentum parameter of 0.95, and a learning rate starting at 0.1, decaying by a multiplicative factor of 0.95 every 1000 batches, and stopping at 10−4.
",3.1. An Experiment,[0],[0]
The results are presented in Fig. 1.,3.1. An Experiment,[0],[0]
"As can be clearly seen, the 3-layer network achieves significantly better performance than the 2-layer networks.",3.1. An Experiment,[0],[0]
"This is true even though some of these networks are significantly larger and with more parameters (for example, the 2-layer, width 800 network has ˜80K parameters, vs. ˜10K parameters for the 3- layer network).",3.1. An Experiment,[0],[0]
This gap in performance is the exact opposite of what might be expected based on parameter counting alone.,3.1. An Experiment,[0],[0]
"Moreover, increasing the width of the 2-layer networks exhibits diminishing returns: The performance improvement in doubling the width from 100 to 200 is much larger than doubling the width from 200 to 400 or 400 to 800.",3.1. An Experiment,[0],[0]
"This indicates that one would need a much larger 2- layer network to match the 3-layer, width 100 network’s performance.",3.1. An Experiment,[0],[0]
"Thus, we conclude that the network’s depth indeed plays a crucial role, and that 3-layer networks are inherently more suitable to express indicator functions of the type we studied.",3.1. An Experiment,[0],[0]
"Having considered functions depending on the L2 norm, we now turn to consider functions depending on the L1 norm.",4. L1 Radial Functions; ReLU Networks,[0],[0]
"Focusing on ReLU networks, we will show a certain separation result holding for any non-linear function, which depends on the input x only via its 1-norm ‖x‖1.",4. L1 Radial Functions; ReLU Networks,[0],[0]
Theorem 3.,4. L1 Radial Functions; ReLU Networks,[0],[0]
Let f :,4. L1 Radial Functions; ReLU Networks,[0],[0]
"[0,∞) 7→ R be a function such that for some r, δ > 0",4. L1 Radial Functions; ReLU Networks,[0],[0]
"and ∈ (0, 1/2),
inf a,b∈R
Ex uniform on [r,(1+ )",4. L1 Radial Functions; ReLU Networks,[0],[0]
"r][(f(x)− (ax− b))2] > δ .
",4. L1 Radial Functions; ReLU Networks,[0],[0]
"Then there exists a distribution γ over {x : ‖x‖1 ≤ (1 + )r}, such that if a 2-layer ReLU network F (x) satisfies∫
x
(f(‖x‖1)− F (x)) 2 γ(x)dx ≤ δ/2,
then its width must be at least Ω̃(min {1/ , exp(Ω(d))}) (where the Ω̃ notation hides constants and factors logarithmic in , d).
",4. L1 Radial Functions; ReLU Networks,[0],[0]
The proof appears in the supplementary material.,4. L1 Radial Functions; ReLU Networks,[0],[0]
"We note that δ controls how ‘linearly inapproximable’ is f in a narrow interval (of width ) around r, and that δ is generally dependent on .",4. L1 Radial Functions; ReLU Networks,[0],[0]
"To give a concrete example, suppose that f(z) =",4. L1 Radial Functions; ReLU Networks,[0],[0]
"[z − 1]+, which cannot be approximated by a linear function to an accuracy better than O( 2) in an - neighborhood of 1.",4. L1 Radial Functions; ReLU Networks,[0],[0]
"By taking r = 1− 2 and δ = O(
2), we get that no 2-layer network can approximate the function
",4. L1 Radial Functions; ReLU Networks,[0],[0]
"[‖x‖1−1]+ (at least with respect to some distribution), unless its width is Ω̃(min {1/ , exp(Ω(d))}).",4. L1 Radial Functions; ReLU Networks,[0],[0]
"On the flip side, f(‖x‖1) can be expressed exactly by a 3-layer, width 2d ReLU network: x 7→ [ ∑d i=1([xi]++[−xi]+)−1]+, where the output neuron is simply the identity function.",4. L1 Radial Functions; ReLU Networks,[0],[0]
The same argument would work for any piecewise-linear f .,4. L1 Radial Functions; ReLU Networks,[0],[0]
"More generally, the same kind of argument would work for any function f exhibiting a non-linear behavior at some points: Such functions can be well-approximated by 3-layer networks (by approximating f with a piecewise-linear function), yet any approximating 2-layer network will have a lower bound on its size as specified in the theorem.
",4. L1 Radial Functions; ReLU Networks,[0],[0]
"Intuitively, the proof relies on showing that any good 2- layer approximation of f(‖x‖1) must capture the nonlinear behavior of f close to “most” points x satisfying ‖x‖1",4. L1 Radial Functions; ReLU Networks,[0],[0]
≈ r.,4. L1 Radial Functions; ReLU Networks,[0],[0]
"However,",4. L1 Radial Functions; ReLU Networks,[0],[0]
a 2-layer ReLU network x 7→∑N j=1 aj,4. L1 Radial Functions; ReLU Networks,[0],[0]
"[〈wj ,x〉+ bj ]+ is piecewise linear, with nonlinearities only at the union of the N hyperplanes",4. L1 Radial Functions; ReLU Networks,[0],[0]
"∪j{x : 〈wj ,x〉 + bj = 0}.",4. L1 Radial Functions; ReLU Networks,[0],[0]
This implies that “most” points x s.t. ‖x‖1,4. L1 Radial Functions; ReLU Networks,[0],[0]
"≈ r must be -close to a hyperplane {x : 〈wj ,x〉 + bj = 0}.",4. L1 Radial Functions; ReLU Networks,[0],[0]
"However, the geometry of the L1 ball {x : ‖x‖ = r} is such that the neighborhood of any single hyperplane can only cover a “small” portion of that ball, yet we need to cover most of the L1 ball.",4. L1 Radial Functions; ReLU Networks,[0],[0]
"Using this and an appropriate construction, we show that required number of hyperplanes is at least 1/ , as long as > exp(−O(d))",4. L1 Radial Functions; ReLU Networks,[0],[0]
"(and if is smaller than that, we can simply use one neuron/hyperplane for each of the 2d facets of the L1 ball, and get a covering using 2d neurons/hyperplanes).",4. L1 Radial Functions; ReLU Networks,[0],[0]
"The formal proof appears in the supplementary material.
",4. L1 Radial Functions; ReLU Networks,[0],[0]
"We note that the bound in Thm. 3 is of a weaker nature than the bound in the previous section, in that the lower bound is only polynomial rather than exponential (albeit w.r.t. different problem parameters: vs. d).",4. L1 Radial Functions; ReLU Networks,[0],[0]
"Nevertheless, we believe this does point out that L1 balls also pose a geometric difficulty for 2-layer networks, and conjecture that our lower bound can be considerably improved: Indeed, at the moment we do not know how to approximate a function such as x 7→",4. L1 Radial Functions; ReLU Networks,[0],[0]
"[‖x‖1 − 1]+ with 2-layer networks to better than constant accuracy, using less than Ω(2d) neurons.
",4. L1 Radial Functions; ReLU Networks,[0],[0]
"Finally, we performed an experiment similar to the one presented in Subsection 3.1, where we verified that the bounds we derived are indeed reflected in differences in empirical performance, when training 2-layer nets versus 3-layer nets.",4. L1 Radial Functions; ReLU Networks,[0],[0]
The reader is referred to Sec. B for the full details of the experiment and its results.,4. L1 Radial Functions; ReLU Networks,[0],[0]
"In this section, we establish a depth separation result for approximating continuously twice-differentiable (C2) functions using ReLU neural networks.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Unlike the previous re-
sults in this paper, the separation is for depths which can be larger than 3, depending on the required approximation error.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Also, the results will all be with respect to the uniform distribution µd over [0, 1]d.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"As mentioned earlier, the results and techniques in this section are closely related to the independent results of (Yarotsky, 2016; Liang & Srikant, 2016), but our emphasis is on L2 rather than L∞ approximation bounds, and we focus on somewhat different network architectures and function classes.
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Clearly, not all C2 functions are difficult to approximate (e.g. a linear function can be expressed exactly with a 2- layer network).",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Instead, we consider functions which have a certain degree of non-linearity, in the sense that its Hessians are non-zero along some direction, on a significant portion of the domain.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Formally, we make the following definition:
Definition 1.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Let µd denote the uniform distribution on [0, 1]
d. For a function f :",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"[0, 1]d → R and some λ > 0, denote
σλ",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"(f) = sup v∈Sd−1, U∈U s.t. v>",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"H(f)(x)v≥λ ∀x∈U µd (U) ,
where Sd−1 = {x : ‖x‖2 = 1} is the d-dimensional unit hypersphere, and U is the set of all connected and measurable subsets of [0, 1]d.
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"In words, σλ (f) is the measure (w.r.t.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"the uniform distribution on [0, 1]d) of the largest connected set in the domain of f , where at any point, f has curvature at least λ along some fixed direction v. The “prototypical” functions f we are interested in is when σλ(f) is lower bounded by a constant (e.g. it is 1 if f is strongly convex).",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"We stress that our results in this section will hold equally well by considering the condition v>H(f)(x)v ≤ −λ as well, however for the sake of simplicity we focus on the former condition appearing in Def. 1.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Our goal is to show a depth separation result inidividually for any such function (that is, for any such function, there is a gap in the attainable error between deeper and shallower networks, even if the shallow network is considerably larger).
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"As usual, we start with an inapproximability result.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Specifically, we prove the following lower bound on the attainable approximation error of f , using a ReLU neural network of a given depth and width:
Theorem 4.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
For any C2 function f :,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"[0, 1]d → R, any λ > 0, and any function g on [0, 1]d expressible by a ReLU network of depth l and maximal width m, it holds that∫
[0,1]d (f(x)− g(x)2µd (x) dx ≥ c · λ2 · σ5λ (2m)4l ,
where c > 0 is a universal constant.
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"The theorem conveys a key tradeoff between depth and width when approximating a C2 function using ReLU networks: The error cannot decay faster than polynomially in the widthm, yet the bound deteriorates exponentially in the depth l. As we show later on, this deterioration does not stem from the looseness in the bound: For well-behaved f , it is indeed possible to construct ReLU networks, where the approximation error decays exponentially with depth.
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"The proof of Thm. 4 appears in the supplementary material, and is based on a series of intermediate results.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"First, we show that any strictly curved function (in a sense similar to Definition 1) cannot be well-approximated in an L2 sense by piecewise linear functions, unless the number of linear regions is large.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"To that end, we first establish some necessary tools based on Legendre polynomials.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"We then prove a result specific to the one-dimensional case, including an explicit lower bound if the target function is quadratic (Thm. 9) or strongly convex or concave (Thm. 10).",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"We then expand the construction to get an error lower bound in general dimension d, depending on the number of linear regions in the approximating piecewiselinear function.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Finally, we note that any ReLU network induces a piecewise-linear function, and bound the number of linear regions induced by a ReLU network of a given width and depth (using a lemma borrowed from (Telgarsky, 2016)).",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Combining this with the previous lower bound yields Thm. 4.
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"We now turn to complement this lower bound with an approximability result, showing that with more depth, a wide family of functions to which Thm. 4 applies can be approximated with exponentially high accuracy.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Specifically, we consider functions which can be approximated using a moderate number of multiplications and additions, where the values of intermediate computations are bounded (for example, a special case is any function approximable by a moderately-sized Boolean circuit, or a polynomial).
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"The key result to show this is the following, which implies that the multiplication of two (bounded-size) numbers can be approximated by a ReLU network, with error decaying exponentially with depth:
Theorem 5.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
Let f :,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"[−M,M ]2 → R, f (x, y) = x · y and let > 0 be arbitrary.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Then exists a ReLU neural network g of width 4 ⌈ log ( M )⌉ + 13 and depth ⌈ 2 log ( M )⌉ + 9 satisfying
sup (x,y)∈[−M,M ]2
|f (x, y)− g (x, y)| ≤ .
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"The idea of the construction is that depth allows us to compute highly-oscillating functions, which can extract highorder bits from the binary representation of the inputs.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Given these bits, one can compute the product by a procedure resembling long multiplication, as shown in Fig. 2,
and formally proven as follows:
Proof of Thm. 5.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"We begin by observing that by using a simple linear change of variables on x, we may assume without loss of generality that x ∈",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"[0, 1], as we can just rescale x to the interval",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"[0, 1], and then map it back to its original domain [−M,M ], where the error will multiply by a factor of 2M .",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Then by requiring accuracy 2M instead of , the result will follow.
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
The key behind the proof is that performing bit-wise operations on the first k bits of x ∈,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"[0, 1] yields an estimation of the product to accuracy 21−kM .",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
Let x = ∑∞ i=1,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"2
−ixi be the binary representation of x where xi is the ith bit of x, then
x · y = ∞∑ i=1",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"2−ixi · y
= k∑ i=1",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
2−ixi · y + ∞∑,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"i=k+1 2−ixi · y. (5)
But since∣∣∣∣∣ ∞∑
i=k+1
2−ixi · y ∣∣∣∣∣ ≤",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
∣∣∣∣∣,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"∞∑
i=k+1
2−i · y ∣∣∣∣∣ = 2−k |y| ≤ 21−kM, Eq. (5) implies∣∣∣∣∣x · y − k∑ i=1",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"2−ixi · y
∣∣∣∣∣ ≤",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
21−kM.,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Requiring that 22−kM ≤ 2M , it suffices to show the existence of a network which approximates the function∑k i=1 2 −ixi · y to accuracy 2 , where k = 2 ⌈ log ( 8M )⌉ .
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"This way both approximations will be at most 2 , resulting in the desired accuracy of .
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Before specifying the architecture which extracts the ith bit of x, we first describe the last 2 layers of the network.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Let the penultimate layer comprise of k neurons, each receiving both y and xi as input, and having the set of weights( 2−i, 1,−1 ) .",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Thus, the output of the ith neuron in the penultimate layer is[ 2−iy + xi",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"− 1 ] + = 2−ixiy.
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Let the final single output neuron have the set of weights (1, . . .",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
", 1, 0) ∈ Rk+1, this way, the output of the network will be ∑k i=1 2 −ixi · y as required.
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"We now specify the architecture which extracts the first most significant k bits of x. In Telgarsky (2016), the author demonstrates how the composition of the function
ϕ",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
(x) =,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"[2x]+ − [4x− 2]+
with itself i times, ϕi, yields a highly oscillatory triangle wave function in the domain [0, 1].",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Furthermore, we observe that ϕ",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"(x) = 0 ∀x ≤ 0, and thus ϕi (x) = 0 ∀x ≤ 0.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Now, a linear shift of the input of ϕi by 2−i−1, and composing the output with
σδ (x) =
[ 1
2δ x− 1 4δ + 1 2 ] +",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"− [ 1 2δ x− 1 4δ − 1 2 ] + ,
which converges to 1[x≥0.5] (x) as δ → 0, results in an approximation of x 7→ xi: σδ ( ϕi ( x− 2−i−1 )) .",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"We stress that choosing δ such that the network approximates the bitwise product to accuracy 2 will require δ to be of magnitude 1 , but this poses no problem as representing such a number requires log ( 1 ) bits, which is also the magnitude of the size of the network, as suggested by the following analysis.
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Next, we compute the size of the network required to implement the above approximation.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"To compute ϕ only two neurons are required, therefore ϕi can be computed using i layers with 2 neurons in each, and finally composing this with σδ requires a subsequent layer with 2 more neurons.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
To implement the ith bit extractor we therefore require a network of size 2×(i+ 1).,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Using dummy neurons to propagate the ith bit for i < k, the architecture extracting the k most significant bits of x will be of size 2k ×",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
(k + 1).,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Adding the final component performing the multiplication estimation will require 2 more layers of width k and 1 respectively, and an increase of the width by 1 to propagate y to the penultimate layer, resulting in a network of size (2k + 1)× (k + 1).
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
Thm. 5 shows that multiplication can be performed very accurately by deep networks.,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Moreover, additions can be
computed by ReLU networks exactly, using only a single layer with 4 neurons: Let α, β ∈ R be arbitrary, then (x, y) 7→ α ·x+β ·y is given in terms of ReLU summation by
α",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
[x]+,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
− α,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
[−x]+ + β,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
[y]+ − β,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"[−y]+ .
Repeating these arguments, we see that any function which can be approximated by a bounded number of operations involving additions and multiplications, can also be approximated well by moderately-sized networks.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"This is formalized in the following theorem, which provides an approximation error upper bound (in the L∞ sense, which is stronger than L2 for upper bounds):
Theorem 6.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Let Ft,M, be the family of functions on the domain [0, 1]d with the property that f ∈",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Ft,M, is approximable to accuracy with respect to the infinity norm, using at most t operations involving weighted addition, (x, y) 7→ α ·",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"x+ β · y, where α, β ∈ R are fixed; and multiplication, (x, y) 7→ x · y, where each intermediate computation stage is bounded in the interval [−M,M ].",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Then there exists a universal constant c, and a ReLU network g of width and depth at most c ( t log ( 1 ) + t2 log (M) ) , such that sup
x∈[0,1]d |f (x)− g (x)| ≤ 2 .
",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"As discussed in Sec. 2, this type of L∞ approximation bound implies an L2 approximation bound with respect to any distribution.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"The proof of the theorem appears in Sec. A.
Combining Thm. 4 and Thm. 6, we can state the following corollary, which formally shows how depth can be exponentially more valuable than width as a function of the target accuracy :
Corollary 1.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
Suppose f ∈,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
C2∩Ft,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"( ),M( ), , where t ( ) = O (poly (log (1/ ))) and M ( ) = O (poly (1/ )).",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"Then approximating f to accuracy in the L2 norm using a fixed depth ReLU network requires width at least poly(1/ ), whereas there exists a ReLU network of depth and width at most p (log (1/ )) which approximates f to accuracy in the infinity norm, where p is a polynomial depending solely on f .
Proof.",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
The lower bound follows immediately from Thm. 4.,5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"For the upper bound, observe that Thm. 6 implies an approximation by a network of width and depth at most
c ( t ( /2) log (2/ )",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"+ (t ( /2)) 2 log (M ( /2)) ) ,
which by the assumption of Corollary 1, can be bounded by p (log (1/ )) for some polynomial p which depends solely on f .",5. C2 Nonlinear Functions; ReLU Networks,[0],[0]
"This research is supported in part by an FP7 Marie Curie CIG grant, Israel Science Foundation grant 425/13, and the Intel ICRI-CI Institute.",Acknowledgements,[0],[0]
"We would like to thank Shai Shalev-Shwartz for some illuminating discussions, and Eran Amar for his valuable help with the experiments.",Acknowledgements,[0],[0]
"We provide several new depth-based separation results for feed-forward neural networks, proving that various types of simple and natural functions can be better approximated using deeper networks than shallower ones, even if the shallower networks are much larger.",abstractText,[0],[0]
This includes indicators of balls and ellipses; non-linear functions which are radial with respect to the L1 norm; and smooth non-linear functions.,abstractText,[0],[0]
"We also show that these gaps can be observed experimentally: Increasing the depth indeed allows better learning than increasing width, when training neural networks to learn an indicator of a unit ball.",abstractText,[0],[0]
Depth-Width Tradeoffs in Approximating Natural Functions with Neural Networks,title,[0],[0]
Different aspects of natural language semantics have been studied from different perspectives.,1 Introduction,[0],[0]
"Distributional semantic models (Turney and Pantel, 2010) induce large-scale vector-based lexical semantic representations from statistical patterns of word usage.",1 Introduction,[0],[0]
"These models have proven successful in tasks relying on meaning relatedness, such as synonymy detection (Landauer and Dumais, 1997), word sense discrimination (Schütze, 1997), or even measuring phrase plausibility (Vecchi et al., 2011).",1 Introduction,[0],[0]
"On the other hand, logical relations and operations, such as entailment, contradiction, conjunction and negation, receive an elegant treatment in formal semantic models.",1 Introduction,[0],[0]
"The latter lack, however, general pro-
cedures to learn from data, and consequently have problems scaling up to real-life problems.
",1 Introduction,[0],[0]
"Formal semantics captures fundamental aspects of meaning in set-theoretic terms: Entailment, for example, is captured as the inclusion relation between the sets (of the relevant type) denoted by words or other linguistic expressions, e.g., sets of possible worlds that two propositions hold of (Chierchia and McConnell-Ginet, 2000, 299).",1 Introduction,[0],[0]
"In finite models, a mathematically convenient way to represent these denotations is to encode them in Boolean vectors, i.e., vectors of 0s and 1s (Sasao, 1999, 21).",1 Introduction,[0],[0]
"Given all elements ei in the domain in which linguistic expressions of a certain type denote, the Boolean vector associated to a linguistic expression of that type has 1 in position i if ei ∈ S for S the set denoted by the expression, 0 otherwise.",1 Introduction,[0],[0]
"An expression a entailing b will have a Boolean vector including the one of b, in the sense that all positions occupied by 1s in the b vector are also set to 1 in the a vector.",1 Introduction,[0],[0]
"Very general expressions (entailing nearly everything else) will have very dense vectors, whereas very specific expressions will have very sparse vectors.",1 Introduction,[0],[0]
The negation of an expression a will denote a “flipped” version of the a Boolean vector.,1 Introduction,[0],[0]
"Vice versa, two expressions with at least partially compatible meanings will have some overlap of the 1s in their vectors; conjunction and disjunction are carried through with the obvious bit-wise operations, etc.
",1 Introduction,[0],[0]
"To narrow the gap between the large-scale inductive properties of distributional semantic models and the logical power of Boolean semantics, we create Boolean meaning representations that build on the wealth of information inherent in distributional vectors of words (and sentences).",1 Introduction,[0],[0]
"More precisely, we use word (or sentence) pairs labeled as entailing
375
Transactions of the Association for Computational Linguistics, vol. 3, pp.",1 Introduction,[0],[0]
"375–388, 2015.",1 Introduction,[0],[0]
Action Editor: Alexander Koller.,1 Introduction,[0],[0]
"Submission batch: 4/2015; Published 6/2015.
",1 Introduction,[0],[0]
c©2015 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY-NC-SA 4.0 license.
or not entailing to train a mapping from their distributional representations to Boolean vectors, enforcing feature inclusion in Boolean space for the entailing pairs.",1 Introduction,[0],[0]
"By focusing on inducing Boolean representations that respect the inclusion relation, our method is radically different from recent supervised approaches that learn an entailment classifier directly on distributional vectors, without enforcing inclusion or other representational constraints.",1 Introduction,[0],[0]
"We show, experimentally, that the method is competitive against state-of-the-art techniques in lexical entailment, improving on them in sentential entailment, while learning more effectively from less training data.",1 Introduction,[0],[0]
This is crucial for practical applications that involve bigger and more diverse data than the focused test sets we used for testing.,1 Introduction,[0],[0]
"Moreover, extensive qualitative analysis reveals several interesting properties of the Boolean vectors we induce, suggesting that they are representations of greater generality beyond entailment, that might be exploited in further work for other logic-related semantic tasks.",1 Introduction,[0],[0]
"Entailment in distributional semantics Due to the lack of methods to induce the relevant representations on the large scale needed for practical tasks, the Boolean structure defined by the entailment relation is typically not considered in efforts to automatically recognize entailment between words or sentences (Dagan et al., 2009).",2 Related work,[0],[0]
"On the other hand, some researchers relying on distributional representations of meaning have attempted to apply various versions of the notion of feature inclusion to entailment detection.",2 Related work,[0],[0]
"This is based on the intuitive idea – the so-called distributional inclusion hypothesis – that the features (vector dimensions) of a hypernym and a hyponym should be in a superset-subset relation, analogously to what we are trying to achieve in the Boolean space we induce, but directly applied to distributional vectors (Geffet and Dagan, 2005; Kotlerman et al., 2010; Lenci and Benotto, 2012; Weeds et al., 2004).",2 Related work,[0],[0]
"It has been noticed that distributional context inclusion defines a Boolean structure on vectors just as entailment defines a Boolean structure on formal semantic representations (Clarke, 2012).",2 Related work,[0],[0]
"However, the match between context inclusion and entailment is far from perfect.
",2 Related work,[0],[0]
"First, distributional vectors are real-valued and contain way more nuanced information than simply inclusion or exclusion of certain features.",2 Related work,[0],[0]
"Second, and more fundamentally, the information encoded in distributional vectors is simply not of the right kind since “feature inclusion” for distributional vectors boils down to contextual inclusion, and there is no reason to think that a hypernym should occur in all the contexts in which its hyponyms appear.",2 Related work,[0],[0]
"For example, bark can be a typical context for dog, but we don’t expect to find it a significant number of times with mammal even in a very large corpus.",2 Related work,[0],[0]
"In practice distributional inclusion turns out to be a weak tool for recognizing the entailment relation (Erk, 2009; Santus et al., 2014) because denotational and distributional inclusion are independent properties.
",2 Related work,[0],[0]
"More recently, several authors have explored supervised methods.",2 Related work,[0],[0]
"In particular, Baroni et al. (2012), Roller et al. (2014) and Weeds et al. (2014) show that a Support Vector Machine trained on the distributional vectors of entailing or non-entailing pairs outperform the distributional inclusion measures.",2 Related work,[0],[0]
"In our experiments, we will use this method as the main comparison point.",2 Related work,[0],[0]
"The similarly supervised approach of Turney and Mohammad (2014) assumes the representational framework of Turney (2012), and we do not attempt to re-implement it here.
",2 Related work,[0],[0]
"Very recently, other properties of distributional vectors, such as entropy (Santus et al., 2014) and topical coherence (Rimell, 2014), have been proposed as entailment cues.",2 Related work,[0],[0]
"Since they are not based on feature inclusion, we see them as complementary, rather than alternative to our proposal.
",2 Related work,[0],[0]
Formal and distributional semantic models We try to derive a structured representation inspired by formal semantic theories from data-driven distributional semantic models.,2 Related work,[0],[0]
Combining the two approaches has proven a hard task.,2 Related work,[0],[0]
"Some systems adopt logic-based representations but use distributional evidence for predicate disambiguation (Lewis and Steedman, 2013) or to weight probabilistic inference rules (Garrette et al., 2013; Beltagy et al., 2013).",2 Related work,[0],[0]
"Other authors propose ways to encode aspects of logic-based representations such as logical connectives and truth values (Grefenstette, 2013) or predicate-argument structure (Clark and Pulman, 2007) in a vector-based framework.",2 Related work,[0],[0]
"These studies
are, however, entirely theoretical.",2 Related work,[0],[0]
"Rocktäschel et al. (2015) expand on the first, allowing for some generalization to unseen knowledge, by introducing some degree of fuzziness into the representations of predicates and terms.",2 Related work,[0],[0]
"Still, this work does not attempt to map concepts to a logic-based representation nor tries to exploit the wealth of information contained in distributional vectors.
",2 Related work,[0],[0]
"Socher et al. (2013), Bordes et al. (2012) and Jenatton et al. (2012) try to discover unseen facts from a knowledge base, which can be seen as a form of inference based on a restricted predicate logic.",2 Related work,[0],[0]
"To do so, they build vector representations for entities, while relations are represented through classifiers.",2 Related work,[0],[0]
"Only Socher et al. (2013) harness distributional vectors, and just as initialization values.",2 Related work,[0],[0]
"The others, unlike us, do not build on independently-motivated word representations.",2 Related work,[0],[0]
"Moreover, since the representations are learned from entities present in their knowledge base, one cannot infer the properties of unseen concepts.
",2 Related work,[0],[0]
"In the spirit of inducing a variety of logical relations and operators (including entailment), Bowman (2013) applies a softmax classifier to the combined distributional representation of two given statements, which are in turn learned compositionally in a supervised fashion in order to guess the relation between them.",2 Related work,[0],[0]
"The paper, however, only evaluates the model on a small restricted dataset, and it is unclear whether the method would scale to realworld challenges.
",2 Related work,[0],[0]
"None of the papers with concrete implementations reviewed above tries, like us, to learn a Boolean structure where entailment corresponds to inclusion.",2 Related work,[0],[0]
"A paper that does attempt to exploit a similar idea is Young et al. (2014), which also uses the notion of model from Formal Semantics to recognize entailment based on denotations of words and phrases.",2 Related work,[0],[0]
"However, since the denotations in their approach are ultimately derived from humangenerated captions of images, the method does not generalize to concepts that are not exemplified in the training database.
",2 Related work,[0],[0]
"Finally, a number of studies, both theoretical (Baroni et al., 2014a; Coecke et al., 2010) and empirical (Paperno et al., 2014; Polajnar et al., 2014), adapt compositional methods from formal semantics to distributional vectors, in order to derive representa-
tions of phrases and sentences.",2 Related work,[0],[0]
"This line of research applies formal operations to distributional representations, whereas we derive formal-semantics-like representations from distributional ones.",2 Related work,[0],[0]
"Below, we apply our method to input sentence vectors constructed with the composition algorithm of Paperno et al. (2014).",2 Related work,[0],[0]
"We build the Boolean Distributional Semantic Model (BDSM) by mapping real-valued vectors from a distributional semantic model into Booleanvalued vectors, so that feature inclusion in Boolean space corresponds to entailment between words (or sentences).",3 The Boolean Distributional Semantic Model,[0],[0]
"That is, we optimize the mapping function so that, if two words (or sentences) entail each other, then the more specific one will get a Boolean vector included in the Boolean vector of the more general one.",3 The Boolean Distributional Semantic Model,[0],[0]
"The is illustrated in Figure 1.
",3 The Boolean Distributional Semantic Model,[0],[0]
Our model differs crucially from a neural network with a softmax objective in imposing a strong bias on the hypothesis space that it explores.,3 The Boolean Distributional Semantic Model,[0],[0]
"In contrast to the latter, it only learns the weights corresponding to the mapping, while all other operations in the network (in particular, the inference step) are fixed in advance.",3 The Boolean Distributional Semantic Model,[0],[0]
"The goal of such a bias is to improve learning efficiency and generalization using prior knowledge of the relation that the model must capture.
",3 The Boolean Distributional Semantic Model,[0],[0]
We will now discuss how the model is formalized in an incremental manner.,3 The Boolean Distributional Semantic Model,[0],[0]
The goal of the model is to find a functionMΘ (with parameters Θ) that maps the distributional representations into the Boolean vector space.,3 The Boolean Distributional Semantic Model,[0],[0]
"To facilitate optimization, we relax the image of this mapping to be the full [0, 1] interval, thus defining MΘ : RN 7→",3 The Boolean Distributional Semantic Model,[0],[0]
"[0, 1]H .",3 The Boolean Distributional Semantic Model,[0],[0]
"This mapping has to respect the following condition as closely as possible: For two given words (or other linguistic expressions) p and q, and their distributional vectors vp and vq, all the active features (i.e., those having value close to 1) of MΘ(vp) must also be active in MΘ(vq) if and only if p⇒ q.
To find such a mapping, we assume training data in the form of a sequence [(pk, qk), yk] m k=1 containing both positive (pk ⇒ qk and yk = 1) and negative pairs (pk ; qk and yk = 0).",3 The Boolean Distributional Semantic Model,[0],[0]
"We learn the mapping by minimizing the difference between the model’s
entailment predictions (given by a function hΘ) and the training targets, as measured by the MSE:
J(Θ)",3 The Boolean Distributional Semantic Model,[0],[0]
"= 1
2
m∑
k=1
(hΘ(pk, qk)− yk)2 (1)
Here, we defineMΘ as a sigmoid function applied to a linear transformation: MΘ(x) = g(Wx+b) and g(x) = 1
1+e −x t
, where t stands for an extra “temper-
ature” parameter.",3 The Boolean Distributional Semantic Model,[0],[0]
"We represent the W ∈ RH×N , b ∈ RH parameters succinctly by Θ =",3 The Boolean Distributional Semantic Model,[0],[0]
"[W, b].
",3 The Boolean Distributional Semantic Model,[0],[0]
"The calculation of hΘ(p, q) involves a series of steps that can be construed as the architecture of a neural network, schematically represented in Figure 2.",3 The Boolean Distributional Semantic Model,[0],[0]
Recall that the output value of this function represents the model’s prediction of the truth value for pk ⇒ qk.,3 The Boolean Distributional Semantic Model,[0],[0]
Here is an outline of how it is calculated.,3 The Boolean Distributional Semantic Model,[0],[0]
"For each pair of words (or sentences) (p, q) in the training set, we map them onto their (soft) boolean correlates (r, s) by applying MΘ to their corresponding distributional vectors.",3 The Boolean Distributional Semantic Model,[0],[0]
"Next, we measure whether features that are active in r are also active in s (analogously to how Boolean implication works), obtaining a soft Boolean vector w. Finally, the output of h can be close to 1 only if all values in
w are also close to 1.",3 The Boolean Distributional Semantic Model,[0],[0]
"Thus, we compute the output value of h as the conjunction across all dimensions in w.
Concretely, hΘ(p, q) is obtained as follows.",3 The Boolean Distributional Semantic Model,[0],[0]
The passage from the first to the second layer is computed as rΘ = MΘ(vp) and sΘ = MΘ(vq).,3 The Boolean Distributional Semantic Model,[0],[0]
"Next, we compute whether the features that are active in rΘ are also active in sΘ.",3 The Boolean Distributional Semantic Model,[0],[0]
"Given that we are working in the [0, 1] range, we approximate this operation as wΘi = max (1− rΘi, sΘi)1.",3 The Boolean Distributional Semantic Model,[0],[0]
"It is easy to see that if rΘi = 0, then wΘi = 1.",3 The Boolean Distributional Semantic Model,[0],[0]
"Otherwise, sΘi must also be equal to 1 for wΘi to be 1.",3 The Boolean Distributional Semantic Model,[0],[0]
"Finally, we compute hΘ = miniwΘi.",3 The Boolean Distributional Semantic Model,[0],[0]
"This is a way to compute the conjunction over the whole previous layer, thus checking whether all the features of rΘ are included in those of sΘ2.
",3 The Boolean Distributional Semantic Model,[0],[0]
"Finally, to allow for better generalization, the cost function is extended with two more components.",3 The Boolean Distributional Semantic Model,[0],[0]
"The fist one is a L2 regularization term weighted by
1In practice, we use a differentiable approximation given by max(x, y)",3 The Boolean Distributional Semantic Model,[0],[0]
"≈ log(eLx+eLy)
L , where L is a sufficiently large
number.",3 The Boolean Distributional Semantic Model,[0],[0]
"We set L = 100, which yields results accurate enough for our purposes.
",3 The Boolean Distributional Semantic Model,[0],[0]
"2Analogously, we use the differentiable approximation
given by min(wθ) =",3 The Boolean Distributional Semantic Model,[0],[0]
"− log( ∑ i e −Lwθi L )
a parameter λ.",3 The Boolean Distributional Semantic Model,[0],[0]
The second one is a term that enforces sparsity of the resulting representations based on some desired level ρ.,3 The Boolean Distributional Semantic Model,[0],[0]
"During training, positive pairs p⇒ q are required to satisfy full feature inclusion in their mapped representations (all the active features of MΘ(vp) must also be in MΘ(vq)).",3.1 Assessing entailment with BDSM,[0],[0]
"At test time, we relax this condition to grant the model some flexibility.",3.1 Assessing entailment with BDSM,[0],[0]
"Concretely, entailment is quantified by the BI (“Boolean Inclusion”) function, counting the proportion of features in the antecedent that are also present in the consequent after binarizing the outputs:
BI(u, v) =",3.1 Assessing entailment with BDSM,[0],[0]
"∑ i rnd(MΘ(u)i) rnd(MΘ(v)i)∑
i rnd(MΘ(u)i)
where rnd(x)",3.1 Assessing entailment with BDSM,[0],[0]
= 1,3.1 Assessing entailment with BDSM,[0],[0]
[x > 0.5].,3.1 Assessing entailment with BDSM,[0],[0]
The 0.5 threshold comes from construing each of the features in the output of M as probabilities.,3.1 Assessing entailment with BDSM,[0],[0]
"Of course, other formulas could be used to quantify entailment through BDSM, but we leave this to further research.
",3.1 Assessing entailment with BDSM,[0],[0]
"Since BI returns continuous values, we use development data to calculate a threshold e above which an entailment response is returned.",3.1 Assessing entailment with BDSM,[0],[0]
"Our approach is agnostic to the kind of distributional representation used, since it doesn’t modify the input vectors, but builds on top of them.",4.1 Distributional semantic spaces,[0],[0]
"Still, it is interesting to test whether specific kinds of distributional vectors are better suited to act as input to BDSM.",4.1 Distributional semantic spaces,[0],[0]
"For our experiments, we use both the count and predict distributional semantic vectors of Baroni et al. (2014b).3 These vectors were shown by their creators to reach the best average performance (among comparable alternatives) on a variety of semantic relatedness/similarity tasks, such as synonymy detection, concept categorization and analogy solving.",4.1 Distributional semantic spaces,[0],[0]
"If the same vectors turn out to also serve as good inputs for constructing Boolean representations, we are thus getting the best of both worlds: distributional vectors with proven high performance on relatedness/similarity tasks which can
3http://clic.cimec.unitn.it/composes/ semantic-vectors.html
be mapped into a Boolean space to tackle logicrelated tasks.",4.1 Distributional semantic spaces,[0],[0]
"We also experiment with the pretrained vectors from TypeDM (Baroni and Lenci, 2010),4 which are built by exploiting syntactic information, and should have different qualitative properties from the window-based approaches.
",4.1 Distributional semantic spaces,[0],[0]
The count vectors of Baroni and colleagues are built from a 2-word-window co-occurrence matrix of 300k lower-cased words extracted from a 2.8 billion tokens corpus.,4.1 Distributional semantic spaces,[0],[0]
"The matrix is weighted using positive Pointwise Mutual Information (Church and Hanks, 1990).",4.1 Distributional semantic spaces,[0],[0]
"We use the full 300k×300k positive PMI matrix to compute the asymmetric similarity measures discussed in the next section, since the latter are designed for non-negative, sparse, full-rank representations.",4.1 Distributional semantic spaces,[0],[0]
"Due to efficiency constraints, for BDSM and SVM (also presented next), the matrix is reduced to 300 dimensions by Singular Value Decomposition (Schütze, 1997).",4.1 Distributional semantic spaces,[0],[0]
The experiments of Baroni et al. (2014b) with these very same vectors suggest that SVD is lowering performance somewhat.,4.1 Distributional semantic spaces,[0],[0]
"So we are, if anything, giving an advantage to the simple asymmetric measures.
",4.1 Distributional semantic spaces,[0],[0]
"The predict vectors are built with the word2vec tool (Mikolov et al., 2013) on the same corpus and for the same vocabulary as the count vectors, using the CBOW method.",4.1 Distributional semantic spaces,[0],[0]
"They are constructed by associating 400-dimensional vectors to each word in the vocabulary and optimizing a single-layer neural network that, while traversing the training corpus, tries to predict the word in the center of a 5-word window from the vectors of those surrounding it.",4.1 Distributional semantic spaces,[0],[0]
"The word2vec subsampling parameter (that downweights the impact of frequent words) is set to 1e−5.
",4.1 Distributional semantic spaces,[0],[0]
"Finally, TypeDM vectors were induced from the same corpus by taking into account the dependency links of a word with its sentential collocates.",4.1 Distributional semantic spaces,[0],[0]
"See Baroni and Lenci (2010) for details.
",4.1 Distributional semantic spaces,[0],[0]
"Composition methods For sentence entailment (Section 6), we need vectors for sentences, rather than words.",4.1 Distributional semantic spaces,[0],[0]
"We derive them from the count vectors compositionally in two different ways.5 First, we use the additive model (add), under which we
4http://clic.cimec.unitn.it/dm 5A reviewer notes that composition rules could also be induced directly on the entailment task.",4.1 Distributional semantic spaces,[0],[0]
"This is an interesting possibility, but note that it would probably require a larger training set than we have available.",4.1 Distributional semantic spaces,[0],[0]
"Moreover, from a theoretical per-
sum the vectors of the words they contain to obtain sentence representations (Mitchell and Lapata, 2010).",4.1 Distributional semantic spaces,[0],[0]
"This approach, however, does not take into account word order, which is of obvious relevance to determining entailment between phrases.",4.1 Distributional semantic spaces,[0],[0]
"For example, a dog chases a cat does not entail a cat chases a dog, whereas each sentence entails itself.",4.1 Distributional semantic spaces,[0],[0]
"Therefore, we also used sentence vectors derived with the linguistically-motivated “practical lexical function” model (plf), that takes syntactic structure and word order into account (Paperno et al., 2014).",4.1 Distributional semantic spaces,[0],[0]
"In short, words acting as argument-taking functions (such as verbs) are not only associated to vectors, but also to one matrix for each argument they take (e.g., each transitive verb comes with a subject and an object matrix).",4.1 Distributional semantic spaces,[0],[0]
"Vector representations of arguments are recursively multiplied by function matrices, following the syntactic structure of a sentence.",4.1 Distributional semantic spaces,[0],[0]
The final sentence representation is obtained by summing all the resulting vectors.,4.1 Distributional semantic spaces,[0],[0]
We used pre-trained vector and matrix representations provided by Paperno and colleagues.,4.1 Distributional semantic spaces,[0],[0]
"Their setup is very comparable to the one of our count vectors: same source corpus, similar window size (3-word-window), positive PMI, and SVD reduction to 300 dimensions.",4.1 Distributional semantic spaces,[0],[0]
"The only notable differences are a vocabulary cut-off to the top 30K most frequent words in the corpus, and the use of content words only as windows.",4.1 Distributional semantic spaces,[0],[0]
"As reviewed in Section 2, the literature on entailment with distributional methods has been dominated by the idea of feature inclusion.",4.2 Alternative entailment measures,[0],[0]
We thus compare BDSM to a variety of state-of-the art asymmetric similarity measures based on the distributional inclusion hypothesis (the dimensions of hyponym/antecedent vectors are included in those of their hypernyms/consequents).,4.2 Alternative entailment measures,[0],[0]
"We consider the measures described in Lenci and Benotto (2012) (clarkeDE, weedsPrec, cosWeeds, and invCL), as well as balAPinc, which was shown to achieve optimal performance by Kotlerman et al. (2010).",4.2 Alternative entailment measures,[0],[0]
"All these measures provide a score that is higher when a significant part of the candidate antecedent fea-
spective, we are interested in testing general methods of composition that are also good for other tasks (e.g., modeling sentence similarity), rather than developing ad-hoc composition rules specifically for entailment.
",4.2 Alternative entailment measures,[0],[0]
tures (=dimensions) are included in those of the consequent.,4.2 Alternative entailment measures,[0],[0]
The measures are only meaningful when computed on a non-negative sparse space.,4.2 Alternative entailment measures,[0],[0]
"Therefore, we evaluate them using the full count space.",4.2 Alternative entailment measures,[0],[0]
"As an example, weedsPrec is computed as follows:
weedsPrec(u, v) =",4.2 Alternative entailment measures,[0],[0]
∑ i 1[vi > 0] ·,4.2 Alternative entailment measures,[0],[0]
"ui∑
i ui
where u is the distributional vector of the antecedent, v that of the consequent.6
",4.2 Alternative entailment measures,[0],[0]
"Finally, we implement a full-fledged supervised machine learning approach directly operating on distributional representations.",4.2 Alternative entailment measures,[0],[0]
"Following the recent literature reviewed in Section 2 above, we train a Support Vector Machine (SVM) (Cristianini and Shawe-Taylor, 2000) on the concatenated distributional vectors of the training pairs, and judge the presence of entailment for a test pair based on the same concatenated representation (the results of Weeds et al. (2014) and Roller et al. (2014) suggest that concatenation is the most reliable way to construct SVM input representations that take both the antecedent and the consequent into account).",4.2 Alternative entailment measures,[0],[0]
Lexical entailment We test the models on benchmarks derived from two existing resources.,4.3 Data sets,[0],[0]
We used the Lexical Entailment Data Set (LEDS) from Baroni et al. (2012) that contains both entailing (obtained by extracting hyponym-hypernym links from WordNet) and non-entailing pairs of words (constructed by reversing a third of the pairs and randomly shuffling the rest).,4.3 Data sets,[0],[0]
"We edited this resource by removing dubious data from the entailing pairs (e.g., logo/signal, mankind/mammal, geek/performer) and adding more negative cases (non-entailing pairs), obtained by shuffling words in the positive examples.",4.3 Data sets,[0],[0]
"We derived two balanced subsets: a development set (LEDS-dev) with 236 pairs in each class and a core set with 911 pairs in each class (LEDScore), such that there is no lexical overlap between the positive classes of each set, and negative class overlap is minimized.",4.3 Data sets,[0],[0]
"Since a fair amount of negative cases were obtained by randomly shuffling words from the positive examples, leading to many unrelated couples, just pair similarity might be a
6BI is equivalent to weedsPrec in Boolean space.
very strong baseline here.",4.3 Data sets,[0],[0]
"We thus explore a more challenging setup, LEDS-dir, where we replace the negative examples of LEDS-core by positive pairs in reverse order, thus focusing on entailment direction.
",4.3 Data sets,[0],[0]
"We derive two more benchmarks from BLESS (Baroni and Lenci, 2011).",4.3 Data sets,[0],[0]
"BLESS lists pairs of concepts linked by one of 5 possible relations: coordinates, hypernymy, meronymy, attributes and events.",4.3 Data sets,[0],[0]
"We employed this resource to construct BLESScoord, which –unlike LEDS, where entailing pairs have to be distinguished from pairs of words that, mostly, bear no relation– is composed of 1,236 super-subordinate pairs (which we treat as positive examples) to be distinguished from 3,526 coordinate pairs.",4.3 Data sets,[0],[0]
"BLESS-mero has the same positive examples, but 2,943 holo-meronyms pairs as negatives.",4.3 Data sets,[0],[0]
"Examples of all lexical benchmarks are given in Table 1.
",4.3 Data sets,[0],[0]
"Sentence entailment To evaluate the models on recognizing entailment between sentences, we use a benchmark derived from SICK (Marelli et al., 2014b).",4.3 Data sets,[0],[0]
"The original data set contains pairs of sentences in entailment, contradiction and neutral relations.",4.3 Data sets,[0],[0]
"We focus on recognizing entailment, treating both contradictory and neutral pairs as negative examples (as in the classic RTE shared tasks up to 2008).7 Data are divided into a development set (SICK-dev) with 500 sentence pairs (144 positive, 356 negative), a training set (SICK-train) with 4,500 pairs (1,299 positive, 3,201 negative) and a test set (SICK-test) with 4,927 pairs (1,414 positive, 3,513 negative).",4.3 Data sets,[0],[0]
"Examples from SICK are given in
7This prevents a direct comparison with the results of the SICK shared task at SemEval (Marelli et al., 2014a).",4.3 Data sets,[0],[0]
"However, all competitive SemEval systems were highly engineered for the task, and made extensive use of a variety of pre-processing tools, features and external resources (cf. Table 8 of Marelli et al. (2014a)), so that a fair comparison with our simpler methods would not be possible in any case.
",4.3 Data sets,[0],[0]
Table 2.,4.3 Data sets,[0],[0]
We tune once and for all the hyperparameters of the models by maximizing accuracy on the small LEDSdev set.,4.4 Training regime,[0],[0]
"For SVM, we tune the kernel type, picking a 2nd degree polynomial kernel for the count and TypeDM spaces, and a linear one for the predict space (alternatives: RBF and 1st, 2nd or 3rd degree polynomials).",4.4 Training regime,[0],[0]
The choice for the count space is consistent with Turney and Mohammad (2014).,4.4 Training regime,[0],[0]
"For BDSM, we tune H (dimensionality of Boolean vectors), setting it to 100 for count, 1,000 for predict and 500 for TypeDM (alternatives: 10, 100, 500, 1,000 and 1,500) and the sparsity parameter ρ, picking 0.5 for count, 0.75 for predict, and 0.25 for TypeDM (alternatives: 0.01, 0.05, 0.1, 0.25, 0.5, 0.75).",4.4 Training regime,[0],[0]
"For BDSM and the asymmetric similarity measures, we also tune the e threshold above which a pair is treated as entailing for each dataset.
",4.4 Training regime,[0],[0]
"The γ (RBF kernel radius) and C (margin slackness) parameters of SVM and the λ, β and t parameters of BDSM (see Section 3) are set by maximizing accuracy on LEDS-dev for all lexical entailment experiments.",4.4 Training regime,[0],[0]
"For sentence entailment, we tune the same parameters on SICK-dev.",4.4 Training regime,[0],[0]
"In this case, given the imbalance between positive and negative pairs, we maximize weighted accuracy (that is, we count each true negative as (|pos| + |neg|)/2|neg|, and each true positive as (|pos| + |neg|)/2|pos|, where |class| is the cardinality of the relevant class in the tuning data).
",4.4 Training regime,[0],[0]
"Finally, for lexical entailment, we train the SVM and BDSM weights by maximizing accuracy on LEDS-core.",4.4 Training regime,[0],[0]
"For LEDS-core and LEDS-dir evaluation, we use 10-fold validation.",4.4 Training regime,[0],[0]
"When evaluating on the BLESS benchmarks, we train on full LEDScore, excluding any pairs also present in BLESS.",4.4 Training regime,[0],[0]
"For sentential entailment, the models are trained by
maximizing weighted accuracy on SICK-train.",4.4 Training regime,[0],[0]
"Table 3 reports lexical entailment results (percentage accuracies for the LEDS benchmarks, F1 scores for the unbalanced BLESS sets).",5 Lexical entailment,[0],[0]
"We observe, first of all, that SVM and BDSM are clearly outperforming the asymmetric similarity measures in all tasks.",5 Lexical entailment,[0],[0]
In only one case the lowest performance attained by a supervised model drops below the level of the best asymmetric measure performance (BDSM using TypeDM on LEDS-dir).8,5 Lexical entailment,[0],[0]
"The performance of the unsupervised measures, which rely most directly on the original distributional space, confirms that the latter is more suited to capture similarity than entailment.",5 Lexical entailment,[0],[0]
"This is shown by the drop in performance from LEDS-core (where many negative examples are semantically unrelated) to LEDSdir (where items in positive and negative pairs are equally similar), as well as by the increase from BLESS-coord to BLESS-mero (as coordinate neg-
8We also inspected ROC curves for BDSM (count) and the asymmetric measures, to check that the better performance of BDSM was not due to a brittle e (entailment threshold).",5 Lexical entailment,[0],[0]
"The curves confirmed that, for all tasks, BDSM is clearly dominating all asymmetric measures across the whole e range.
",5 Lexical entailment,[0],[0]
"ative examples are more tightly related than holomeronym pairs).
",5 Lexical entailment,[0],[0]
"In the count input space, SVM and BDSM perform similarly across all 4 tasks, with SVM having a small edge.",5 Lexical entailment,[0],[0]
"In the next sections, we will thus focus on count vectors, for the fairest comparison between the two models.",5 Lexical entailment,[0],[0]
"BDSM reaches the most consistent results with predict vectors, where it performs particularly well on BLESS, and not dramatically worse than with count vectors on LEDS.",5 Lexical entailment,[0],[0]
"On the other hand, predict vectors have a negative overall impact on SVM in 3 over 4 tasks.",5 Lexical entailment,[0],[0]
"Concerning the interaction of input representations and tasks, we observe that count vectors work best with LEDS, whereas for BLESS predict vectors are the best choice, regardless of the supervised method employed.
",5 Lexical entailment,[0],[0]
"Confirming the results of Baroni et al. (2014b), the TypeDM vectors are not a particularly good choice for either model.",5 Lexical entailment,[0],[0]
BDSM is specifically negatively affected by this choice in the LEDS-dir and BLESS-coord tasks.,5 Lexical entailment,[0],[0]
"The tight taxonomic information captured by a dependency-based model such as TypeDM might actually be detrimental in tasks that require distinguishing between closely related forms, such as coordinates and hypernyms in BLESS-coord.
",5 Lexical entailment,[0],[0]
"In terms of relative performance of the supervised entailment models, if one was to weigh each task equally, the best average performance would be reached by BDSM trained on predict vectors, with an average score of 75.75, followed by SVM on count vectors, with an average score of 71.5.",5 Lexical entailment,[0],[0]
We assess the significance of the difference between supervised models trained on the input vectors that give the best performance for each task by means paired t-tests on LEDS and McNemar tests on BLESS.,5 Lexical entailment,[0],[0]
SVM with count vectors is better than BDSM on LEDS-core (not significant) and LEDSdir (p<0.05).,5 Lexical entailment,[0],[0]
"On the other hand, BDSM with predict vectors is better than SVM on BLESS-coord (p<0.001) and BLESS-mero (p<0.001).",5 Lexical entailment,[0],[0]
"We conclude that, overall, the two models perform similarly on lexical entailment tasks.",5 Lexical entailment,[0],[0]
"We just observed that SVM and BDSM have similar lexical entailment performance, especially in count space.",5.1 Learning efficiency,[0],[0]
"However, the two models are radically differ-
ent in their structure.",5.1 Learning efficiency,[0],[0]
SVM fits a 2nd order polynomial separating entailing from non-entailing pairs in a space formed by the concatenation of their distributional representations.,5.1 Learning efficiency,[0],[0]
"BDSM, on the other hand, finds a linear transformation into a space where features of the antecedent are included in those of the consequent.",5.1 Learning efficiency,[0],[0]
"We conjecture that the latter has much larger bias, imposed by this strict subsective constraint.9 We expect this bias to help learning, by limiting the search space and allowing the algorithm to harness training data in a more efficient way.",5.1 Learning efficiency,[0],[0]
"Thus, BDSM should be better at learning with less data, where SVM will be prone to overfitting.",5.1 Learning efficiency,[0],[0]
"To test this claim, we measured the cross-validated LEDS-core accuracy obtained from using vectors in count space when reducing the training items in steps of 182 pairs.",5.1 Learning efficiency,[0],[0]
The results can be seen in Figure 3.,5.1 Learning efficiency,[0],[0]
"As expected, BDSM scales down much more gracefully, with accuracy well above 70% with as little as 182 training pairs.",5.1 Learning efficiency,[0],[0]
"Having shown in the previous experiments that the asymmetric measures are not competitive, we focus here on SVM and BDSM.",6 Sentence entailment,[0],[0]
"As mentioned above in Section 5, we use count vectors for a fair comparison between the two models, based on their similar performance on the lexical benchmarks.
",6 Sentence entailment,[0],[0]
"Recall that for sentence entailment we use the 9Mitchell (1980) defines bias as any basis for choosing one generalization over another, other than strict consistency with the observed training instances.
same hyperparameters as for the lexical tasks, that the model constants were tuned on SICK-dev, and the model weights on SICK-train (details in Section 4.4 above).",6 Sentence entailment,[0],[0]
"Sentence representations are derived either with the plf approach, that returns sentence vectors built according to syntactic structure, or the additive (add) method, where constituent word vectors are simply summed to derive a sentence vector (see Section 4.1 above).
",6 Sentence entailment,[0],[0]
We compare SVM and BDSM to the Sycophantic baseline classifying all pairs as entailing and to a Majority baseline classifying everything as nonentailing.,6 Sentence entailment,[0],[0]
"The Word Overlap method (WO) calculates the number of words in common between two sentences and classifies them as entailing whenever the ratio is above a certain threshold (calibrated on SICK-train).
",6 Sentence entailment,[0],[0]
Results are given in Table 4.,6 Sentence entailment,[0],[0]
"Because of class unbalance, F1 is more informative than accuracy (the Majority baseline reaches the best accuracy with 0 precision and recall), so we focus on the former for analysis.",6 Sentence entailment,[0],[0]
We observe first that sentence vectors obtained with the additive model are consistently outperforming the more sophisticated plf approach.,6 Sentence entailment,[0],[0]
This confirms the results of Blacoe and Lapata (2012) on the effectiveness of simple composition methods.,6 Sentence entailment,[0],[0]
"We leave it to further studies to determine to what extent this can be attributed to specific characteristics of SICK that make word order information redundant, and to what extent it indicates that plf is not exploiting syntactic information adequately (note that Paperno et al. (2014) report minimal performance differences between additive and plf for their msrvid benchmark, that is the closest to SICK).
",6 Sentence entailment,[0],[0]
"Coming now to the crucial comparison of BDSM against SVM (focusing on the results obtained with the additive method), BDSM emerges as the best classifier when evaluated alone, improving over SVM, although the difference is not significant.",6 Sentence entailment,[0],[0]
"Since the Word Overlap method is performing quite well (better than SVM) and the surface information used by WO should be complementary to the semantic cues exploited by the vector-based models, we built combined classifiers by training SVMs (on SICK-dev) with linear kernels and WO value plus each method’s score (BI for BDSM and distance to the margin for SVM) as features.",6 Sentence entailment,[0],[0]
"The combi-
nations improve performance for both models and BDSM+WO attains the best overall F1 score, being statistically superior to both SVM+WO (p<0.001) and WO alone (p < 0.001) (statistical significance values obtained through McNemar tests).
",6 Sentence entailment,[0],[0]
We repeated the training data reduction experiment from Section 5.1 by measuring cross-validated F1 scores for SICK (with additive composition).,6 Sentence entailment,[0],[0]
"We confirmed that BDSM is robust to decreasing the amount of training data, maintaining an F1 score of 56 with only 942 training items, whereas, with the same amount of training data, SVM drops to a F1 of 42.",6 Sentence entailment,[0],[0]
BDSM produces representations that are meant to respect inclusion and be interpretable.,7 Understanding Boolean vectors,[0],[0]
"We turn now to an extended analysis of the learned representations (focusing on those derived from count vectors), showing first how BDSM activation correlates with generality and abstractness, and then how similarity in BDSM space points in the direction of an extensional interpretation of Boolean units.",7 Understanding Boolean vectors,[0],[0]
"The BDSM layer is trained to assign more activation to a hypernym than its hyponyms (the hypernym units should include the hyponyms’ ones), so the more general (that is, higher on the hypernymy scale) a concept is, the higher the proportion of activated units in its BDSM vector.",7.1 Boolean dimensions and generality,[0],[0]
The words that activate all nodes should be implied by all other terms.,7.1 Boolean dimensions and generality,[0],[0]
"Indeed, very general words such as thing(s), everything, and anything have Boolean vectors with all 1s.
",7.1 Boolean dimensions and generality,[0],[0]
"But there are also other words (a total of 768) mapping to the top element of the Boolean algebra (a vector of all 1s), including reduction, excluded, results, benefit, global, extent, achieve.",7.1 Boolean dimensions and generality,[0],[0]
"The collapsing of these latter terms must be due to a combination of two factors: low dimensionality of Boolean space,10 and the fact that the model was trained on a limited vocabulary, mostly consisting of concrete nouns, so there was simply no training evidence to characterize abstract words such as benefit in a more nuanced way.
",7.1 Boolean dimensions and generality,[0],[0]
"Still, we predict that the proportion of Boolean dimensions that a word activates (i.e., dimensions with value 1) should correspond, as a trend, to its degree of semantic generality.",7.1 Boolean dimensions and generality,[0],[0]
"More general concepts also tend to be more abstract, so we also expect a correlation between Boolean activation and the word rating on the concrete-abstract scale.11 To evaluate these claims quantitatively, we rely on WordNet (Fellbaum, 1998), which provides an is-a hierarchy of word senses (‘synsets’) that can be used to measure semantic generality.",7.1 Boolean dimensions and generality,[0],[0]
"We compute the average length of a path from the root of the hierarchy to the WordNet synsets of a word (shortest is most general, so that a higher depth score corresponds to a more specific concept).",7.1 Boolean dimensions and generality,[0],[0]
"We further use the Ghent database (Brysbaert et al., 2013), that contains 40K English words rated on a 1-5 scale from least to most concrete (as expected, depth and concreteness are correlated, ρ = .54).
",7.1 Boolean dimensions and generality,[0],[0]
"Boolean vector activation significantly correlates with both variables (ρ=-18 with depth, ρ=-30 with concreteness; these and all correlations below significant at p < 0.005).",7.1 Boolean dimensions and generality,[0],[0]
"Moreover, the BDSM activations are much higher than those achieved by distributional vector L1 norm (which, surprisingly, has positive correlations: ρ=13 with depth, ρ=21 with concreteness) and word frequency (ρ=-2 with depth, ρ=4 with concreteness).
",7.1 Boolean dimensions and generality,[0],[0]
We visualize how Boolean activation correlates with generality in Figure 4.,7.1 Boolean dimensions and generality,[0],[0]
"We plot the two example words car and newspaper together with their 30 nearest nominal neighbours in distributional
10With count input representations, our tuning favoured relatively dense 100-dimensional vectors (see Section 4.4).
",7.1 Boolean dimensions and generality,[0],[0]
"11Automatically determining the degree of abstractness of concepts is a lively topic of research (Kiela et al., 2014; Turney et al., 2011).
",7.1 Boolean dimensions and generality,[0],[0]
"space,12 sorting them from most to least activated.",7.1 Boolean dimensions and generality,[0],[0]
"More general words do indeed cluster towards the top, while more specific words are pushed to the bottom.",7.1 Boolean dimensions and generality,[0],[0]
"Interestingly, while vehicle and organization were present in the training data, that was not the case for media or press.",7.1 Boolean dimensions and generality,[0],[0]
"Moreover, the training data did not contain any specific type of car (like volvo or suv) or newspaper (tribune or tabloid).",7.1 Boolean dimensions and generality,[0],[0]
"From the model-theoretical point of view, wordto-BDSM mapping provides an interpretation function in the logical sense, mapping linguistic expressions to elements of the model domain (Boolean dimensions).",7.2 Similarity in Boolean space,[0],[0]
"If distributional vectors relate to concepts in a (hyper)intensional construal (Erk, 2013), Boolean vectors could encode their (possible) extensions along the lines suggested by Grefenstette (2013), with vector dimensions corresponding to entities in the domain of discourse.13 Under the exten-
12Due to tagging errors, the neighbors also include some verbs like parked or adjectives like weekly.
",7.2 Similarity in Boolean space,[0],[0]
13In fact everything we say here applies equally well to certain intensional interpretations of Boolean vectors.,7.2 Similarity in Boolean space,[0],[0]
"For example, the atoms of the Boolean algebra could correspond not to entities in the actual world but to classes of individuals across
sional interpretation, the Boolean vector of a word encodes the set of objects in the word extension.",7.2 Similarity in Boolean space,[0],[0]
"But of course, given that our BDSM implementation operates with only 100 dimensions, one cannot expect such an extensional interpretation of the model to be realistic.",7.2 Similarity in Boolean space,[0],[0]
"Still, the extensional interpretation of the Boolean model, while being highly idealized, makes some testable predictions.",7.2 Similarity in Boolean space,[0],[0]
"Under this view, synonyms should have identical Boolean vectors, antonyms should have disjoint vectors.",7.2 Similarity in Boolean space,[0],[0]
Compatible terms (including hyponym-hypernym pairs) should overlap in their 1s.,7.2 Similarity in Boolean space,[0],[0]
"Cohyponyms, while high on the relatedness scale, should have low “extensional similarity”; singer and drummer are very related notions but the intersection of their extensions is small, and that between alligator and crocodile is empty (in real life, no entity is simultaneously a crocodile and an alligator).
",7.2 Similarity in Boolean space,[0],[0]
"As expected, the straightforward interpretation of dimensions as individuals in a possible world close to ours is contradicted by many counterexamples in the present BDSM implementation.",7.2 Similarity in Boolean space,[0],[0]
"For example, the nouns man and woman have a considerable overlap in activated Boolean dimensions, while in any plausible world hermaphrodite humans are rare.",7.2 Similarity in Boolean space,[0],[0]
"Still, compared to distributional space, BDSM goes in the direction of an extensional model as discussed above.",7.2 Similarity in Boolean space,[0],[0]
"To quantify this difference, we compared the similarity scores (cosines) produced by the two models.",7.2 Similarity in Boolean space,[0],[0]
"Specifically, we first created a list of pairs of semantically related words using the following procedure.",7.2 Similarity in Boolean space,[0],[0]
We took the 10K most frequent words paired with their 10 closest neighbors in the count distributional space.,7.2 Similarity in Boolean space,[0],[0]
We then filtered them to be of “medium frequency” (both words must lie within the 60K-90K frequency range in our 2.8B token corpus).,7.2 Similarity in Boolean space,[0],[0]
"One of the authors annotated the resulting 624 pairs as belonging to one of the following types: cohyponyms (137, e.g., AIDS vs. diabetes); derivationally related words (10, e.g., depend vs. dependent); hypernym-hyponym pairs (37, e.g., arena vs. theater); personal names (97, e.g., Adams vs. Harris); synonyms (including contextual ones; 49, e.g., abilities vs. skill); or “other” (294, e.g., actress vs. starring), if the pair does not fit any of the above types
possible worlds.",7.2 Similarity in Boolean space,[0],[0]
"Alternatively, one can think of the atoms as “typical cases” rather than actual individuals, or even as typical properties of the relevant individuals.
",7.2 Similarity in Boolean space,[0],[0]
"(some relations of interest, such as antonymy, were excluded from further analysis as they were instantiated by very few pairs).",7.2 Similarity in Boolean space,[0],[0]
"Since cosines have different distributions in distributional (DS) and Boolean space (BS), we z-normalized them before comparing those of pairs of the same type across the two spaces.
",7.2 Similarity in Boolean space,[0],[0]
"Under the extensional interpretation, we expect co-hyponyms to go apart after Boolean mapping, as they should in general have little extensional overlap.",7.2 Similarity in Boolean space,[0],[0]
Indeed they have significantly lower cosines in BS than DS (p < 0.001; paired t-test).,7.2 Similarity in Boolean space,[0],[0]
"As expected under the extensional interpretation, personal names are very significantly less similar in BS than DS (p < 0.001).",7.2 Similarity in Boolean space,[0],[0]
"Synonyms and hypo/hypernyms have significant denotational overlap, and they move closer to each other after mapping.",7.2 Similarity in Boolean space,[0],[0]
"Specifically, synonyms significantly gain in similarity between BS and DS (p<0.01), whereas hyponym-hypernym pairs, while not differing significantly in average similarity across the spaces, change from being weakly significantly lower in cosine than all other pairs in DS (p < 0.05) to being indistinguishable from the other pairs in BS.",7.2 Similarity in Boolean space,[0],[0]
Derivationally related words gain in similarity (p<0.01) collapsing to almost identical vectors after Boolean mapping.,7.2 Similarity in Boolean space,[0],[0]
This deserves a special comment.,7.2 Similarity in Boolean space,[0],[0]
"Although words in these pairs typically belong to different parts of speech and are not synonyms in the usual sense, one could interpret them as denotational synonyms in the sense that they get reference in the same situations.",7.2 Similarity in Boolean space,[0],[0]
"Taking two word pairs from our data as examples, the existence of experiments entails the presence of something experimental, anything Islamic entails the presence of Islam in the situation, etc.",7.2 Similarity in Boolean space,[0],[0]
"If so, the fact that derivationally related words collapse under Boolean mapping makes perfect sense from the viewpoint of denotational overlap.",7.2 Similarity in Boolean space,[0],[0]
"We introduced BDSM, a method that extracts representations encoding semantic properties relevant for making inferences from distributional semantic vectors.",8 Conclusion,[0],[0]
"When applied to the task of detecting entailment between words or sentences, BDSM is competitive against a state-of-the-art SVM classifier, and needs less learning data to generalize.",8 Conclusion,[0],[0]
"In contrast to
SVM, BDSM is transparent: we are able not only to classify a pair of words (or sentences) with respect to entailment, but we also produce a compact Boolean vector for each word, that can be used alone for recognizing its entailment relations.",8 Conclusion,[0],[0]
"Besides the analogy with the structures postulated in formal semantics, this can be important for practical applications that involve entailment recognition, where Boolean vectors can reduce memory and computing power requirements.
",8 Conclusion,[0],[0]
"The Boolean vectors also allow for a certain degree of interpretability, with the number of active dimensions correlating with semantic generality and abstractness.",8 Conclusion,[0],[0]
"Qualitative analysis suggests that Boolean mapping moves the semantic space from one organized around word relatedness towards a different criterion, where vectors of two words are closer to each other whenever their denotations have greater overlap.",8 Conclusion,[0],[0]
"This is, however, just a tendency.",8 Conclusion,[0],[0]
"Ideally, the overlap between dimensions of two vectors should be a measure of compatibility of concepts.",8 Conclusion,[0],[0]
"In future research, we would like to explore to what extent one can reach this ideal, explicitly teaching the network to also capture other types of relations (e.g., no overlap between cohyponym representations), and using alternative learning methods.
",8 Conclusion,[0],[0]
"We also want to look within the same framework at other phenomena, such as negation and conjunction, that have an elegant treatment in formal semantics but are currently largely outside the scope of distributional approaches.",8 Conclusion,[0],[0]
"We thank Yoav Goldberg, Omer Levy, Ivan Titov, Tim Rocktäschel, the members of the COMPOSES team (especially Angeliki Lazaridou) and the FLOSS reading group.",Acknowledgements,[0],[0]
We also thank Alexander Koller and the anonymous reviewers for their insightful comments.,Acknowledgements,[0],[0]
We acknowledge ERC 2011 Starting Independent Research Grant n. 283554 (COMPOSES),Acknowledgements,[0],[0]
"Corpus-based distributional semantic models capture degrees of semantic relatedness among the words of very large vocabularies, but have problems with logical phenomena such as entailment, that are instead elegantly handled by model-theoretic approaches, which, in turn, do not scale up.",abstractText,[0],[0]
We combine the advantages of the two views by inducing a mapping from distributional vectors of words (or sentences) into a Boolean structure of the kind in which natural language terms are assumed to denote.,abstractText,[0],[0]
We evaluate this Boolean Distributional Semantic Model (BDSM) on recognizing entailment between words and sentences.,abstractText,[0],[0]
"The method achieves results comparable to a state-of-theart SVM, degrades more gracefully when less training data are available and displays interesting qualitative properties.",abstractText,[0],[0]
Deriving Boolean structures from distributional vectors,title,[0],[0]
Attention-based models have become architectures of choice for many NLP tasks.,1 Introduction,[0],[0]
"In addition to significant performance gains, these models are attractive, as attention is often used as a proxy for human interpretable rationales.",1 Introduction,[0],[0]
"Their success, however, is conditioned on access to large amounts of training data.",1 Introduction,[0],[0]
"To make these models applicable in low-resource scenarios, we utilize this connection in the opposite direction.",1 Introduction,[0],[0]
"Specifically, we propose an approach to map human rationales to high-performing attention, and use this attention to guide models trained in low-resource scenarios.
",1 Introduction,[0],[0]
The notions of rationale and attention are closely related.,1 Introduction,[0],[0]
Both of them highlight word importance for the final prediction.,1 Introduction,[0],[0]
"In the case of rationale, the importance is expressed as a hard selection, while attention provides a soft distribution over the words.",1 Introduction,[0],[0]
Figure 1 illustrates this relatedness.,1 Introduction,[0],[0]
"One obvious approach to improve low-
1Our code and data are available at https://github.",1 Introduction,[0],[0]
"com/YujiaBao/R2A.
resource performance is to directly use human rationales as a supervision for attention generation.",1 Introduction,[0],[0]
The implicit assumption behind this method is that machine-generated attention should mimic human rationales.,1 Introduction,[0],[0]
"However, rationales on their own are not adequate substitutes for machine attention.",1 Introduction,[0],[0]
"Instead of providing a soft distribution, human rationales only provide the binary indication about relevance.",1 Introduction,[0],[0]
"Furthermore, rationales are subjectively defined and often vary across annotators.",1 Introduction,[0],[0]
"Finally, human rationales are not customized for a given model architecture.",1 Introduction,[0],[0]
"In contrast, machine attention is always derived as a part of a specific model architecture.
",1 Introduction,[0],[0]
"To further understand this connection, we empirically compare models informed by human rationales and those by high-quality attention.",1 Introduction,[0],[0]
"To obtain the latter, we derive an “oracle” attention using a large amount of annotations.",1 Introduction,[0],[0]
This “oracle” attention is then used to guide a model that only has access to a small subset of this training data.,1 Introduction,[0],[0]
"Not only does this model outperform the oracle-free variant, but it also yields substantial gains over its counterpart trained with human ra-
ar X
iv :1
80 8.
09 36
7v 1
[ cs
.C",1 Introduction,[0],[0]
"L
] 2
8 A
ug 2
01 8
tionales — 89.98 % vs 85.22 % average accuracy on three aspects of hotel review (see Section 4 for details).",1 Introduction,[0],[0]
"In practice, however, this “oracle” attention is not available.",1 Introduction,[0],[0]
"To employ this method, we need to find a way to obtain a substitute for the “oracle” attention.
",1 Introduction,[0],[0]
"In this paper, we show how to achieve this goal using rationales.",1 Introduction,[0],[0]
"Specifically, we learn a mapping from human rationales to high-quality attention (R2A).",1 Introduction,[0],[0]
"We hypothesize that this mapping is generalizable across tasks and thus can be transferred from resource-rich tasks.2 Figure 1 illustrates that in both tasks, attention weighs rationale words in a similar fashion: highlighting taskspecific nouns and adjectives, while downplaying functional words.",1 Introduction,[0],[0]
To learn and apply this mapping we need access to rationales in both source and target tasks.,1 Introduction,[0],[0]
"In the target task, we assume rationales are provided by humans.",1 Introduction,[0],[0]
"In the source task(s), collecting rationales at scale is infeasible.",1 Introduction,[0],[0]
"Therefore, we use machine-generated rationales (Lei et al., 2016) as a proxy.
",1 Introduction,[0],[0]
Our R2A model consists of three components.,1 Introduction,[0],[0]
The first one is an attention-based model for the source task(s) that provides supervision for attention generation.,1 Introduction,[0],[0]
The second component focuses on learning a domain-invariant representation to support transfer.,1 Introduction,[0],[0]
The third component combines this invariant representation and rationales together to generate the attention.,1 Introduction,[0],[0]
These three components are trained jointly to optimize the overall objective.,1 Introduction,[0],[0]
"Once the model is trained, we apply it to the target task to generate attention from human rationales.",1 Introduction,[0],[0]
"This attention is consequently used to supervise the training of the target classifier.
",1 Introduction,[0],[0]
We evaluate our approach on two transfer settings: aspect transfer within single domain and domain transfer across multiple domains.,1 Introduction,[0],[0]
Our experiments demonstrate that our approach delivers significant performance improvements over the baselines.,1 Introduction,[0],[0]
"For instance, the average error reduction over the best baseline in domain transfer is over 15%.",1 Introduction,[0],[0]
"In addition, both qualitative and quantitative analyses confirm that our R2A model is capable of generating high-quality attention for target tasks.
",1 Introduction,[0],[0]
"2In this paper, we consider a more general setting where one domain contains multiple tasks.",1 Introduction,[0],[0]
"Also, we assume having one source domain.",1 Introduction,[0],[0]
"However, our proposed method is a general framework and can be easily adapted to problems with multiple source domains.",1 Introduction,[0],[0]
"Attention-based models Attention has been shown to be effective when the model is trained on large amounts of training data (Bahdanau et al., 2014; Luong et al., 2015; Rush et al., 2015; Yang et al., 2016; Lin et al., 2017; Chen et al., 2017; Vaswani et al., 2017).",2 Related Work,[0],[0]
"In this setting, typically no additional supervision is required for learning the attention.",2 Related Work,[0],[0]
"Nevertheless, further refining attention by extra supervision has been shown to be beneficial.",2 Related Work,[0],[0]
"Examples include using word alignments to learn attention in neural machine translation (Liu et al., 2016), employing argument words to supervise attention in event detection (Liu et al., 2017), utilizing linguisticallymotivated annotations to guide attention in constituency parsing (Kamigaito et al., 2017).",2 Related Work,[0],[0]
These supervision mechanisms are tailored to specific applications.,2 Related Work,[0],[0]
"In contrast, our approach is based on the connection between rationales and attention, and can be used for multiple applications.
",2 Related Work,[0],[0]
Rationale-based models Zaidan et al. (2007) was the first to explore the value of rationales in low-resource scenarios.,2 Related Work,[0],[0]
"They hypothesize that the model confidence should decrease when the rationale words are removed from the inputs, and validate this idea for linear models.",2 Related Work,[0],[0]
"Recent work (Zhang et al., 2016) explores the potential of integrating rationales with more complex neural classifiers.",2 Related Work,[0],[0]
"In their model, human rationales are directly used to guide the sentence-level attention for a CNN-based classifier.",2 Related Work,[0],[0]
"To reach good performance, their model still requires a sufficient amount of training data.",2 Related Work,[0],[0]
Our work differs from theirs as we discern the intrinsic difference between human rationales and machine attention.,2 Related Work,[0],[0]
"Moreover, we learn a model to map human rationales into high-quality attention so as to provide a richer supervision for low-resource models.
",2 Related Work,[0],[0]
"Transfer learning When labeled data on the target task is available, existing approaches typically transfer the knowledge by either fine-tuning an encoder trained on the source tasks(s) (Conneau et al., 2017; Peters et al., 2018) or multi-task learning on all tasks with a shared encoder (Collobert et al., 2011).",2 Related Work,[0],[0]
"In this paper, we explore the transferability of the task-specific attention through human rationales.",2 Related Work,[0],[0]
"We believe this will further assist learning in low-resource scenarios.
",2 Related Work,[0],[0]
"Our work is also related to unsupervised domain
adaptation, as the R2A model has never seen any target annotations during training.",2 Related Work,[0],[0]
"Existing methods commonly adapt the classifier by aligning the representations between the source and target domains (Glorot et al., 2011; Chen et al., 2012; Zhou et al., 2016; Ganin et al., 2016; Zhang et al., 2017).",2 Related Work,[0],[0]
"In contrast, our model adapts the mapping from rationales to attention; thus after training, it can be applied to different target tasks.",2 Related Work,[0],[0]
"Problem formulation We assume that we have N source tasks {Si}Ni=1, where each of them has sufficient amounts of labeled examples.",3 Method,[0],[0]
"Using existing methods (Lei et al., 2016), we can generate rationales for each source example automatically (see Appendix 1 for details).",3 Method,[0],[0]
"In the target task T , we only have a limited amount of labeled examples with large amounts of unlabeled data.",3 Method,[0],[0]
"For those labeled examples, we assume access to human-annotated rationales.
",3 Method,[0],[0]
Overview Our goal is to improve classification performance on the target task by learning a mapping from human rationales to high-quality machine attention (R2A).,3 Method,[0],[0]
"Given the scarcity of our target data, we learn this mapping on resource rich tasks where high-quality attention can be readily obtained during training.",3 Method,[0],[0]
"Next, the mapping between rationales and attention derived from the source tasks is exported into the target task.",3 Method,[0],[0]
"To enable this transfer, models have to operate over an invariant representation which we construct via an adversarial objective.",3 Method,[0],[0]
"Once the mapping is derived, we can translate human rationales in the target task into high-quality attention.",3 Method,[0],[0]
This generated attention is then used to provide additional training signal for an attention-based classifier for the target task.,3 Method,[0],[0]
"The overall pipeline is shown in Figure 2.
",3 Method,[0],[0]
"Alternatively, we can view the R2A mapping as a meta model that produces a prior over the attention distribution across different tasks.
",3 Method,[0],[0]
"Model architecture Figure 3 illustrates the architecture of our R2A model, which consists of three components.
",3 Method,[0],[0]
"• Multi-task learning In order to learn the R2A mapping, we need annotation for the attention.",3 Method,[0],[0]
"This module generates high-quality attention as an intermediate result by minimizing the prediction error on the source tasks (Section 3.1).
unlabeled target data
R2A
labeled target data with rationales
labeled target data with R2A-generated attention R2A
Step 1: Training R2A
Step 2: R2A inference
Step 3:",3 Method,[0],[0]
"Training target classifier
labeled source data with rationales
• Domain-invariant encoder This module aims to transform the contextualized representation obtained from the first module into a domain-invariant version.",3 Method,[0],[0]
"We achieve this goal through domain adversarial training over the source data and the unlabeled target data (Section 3.2).
",3 Method,[0],[0]
• Attention generation This module learns to predict the intermediate attention obtained from the first module based on the domain-invariant representation and the rationales (Section 3.3).,3 Method,[0],[0]
The goal of the multi-task learning module is to learn good attention for each source task.,3.1 Multi-task learning,[0],[0]
This learned attention will be used later to supervise the attention generation module.,3.1 Multi-task learning,[0],[0]
This module takes the input text from the source tasks and predicts the labels.,3.1 Multi-task learning,[0],[0]
"To accomplish the previously stated goal, we minimize the prediction error over all labeled source data.
",3.1 Multi-task learning,[0],[0]
"Let (xt, yt) be a training instance from any source task t ∈ {S1, . .",3.1 Multi-task learning,[0],[0]
.SN},3.1 Multi-task learning,[0],[0]
.,3.1 Multi-task learning,[0],[0]
"We first encode the input sequence xt into hidden states: ht = enc(xt), where enc is a bi-directional LSTM (Hochreiter and Schmidhuber, 1997) that is shared across all source tasks.",3.1 Multi-task learning,[0],[0]
"For each position i, the dense vector hti encodes the content and context information of the word xti.",3.1 Multi-task learning,[0],[0]
"We then pass the
sequence ht on to a task-specific attention module to produce attention αt = attt(ht) as follows:
h̃ti = tanh(W t atth t",3.1 Multi-task learning,[0],[0]
"i + b t att), αti = exp(〈h̃ti, qtatt〉)∑",3.1 Multi-task learning,[0],[0]
"j exp(〈h̃tj , qtatt〉) ,
where 〈·, ·〉 denotes inner product and W tatt, btatt, qtatt are learnable parameters.",3.1 Multi-task learning,[0],[0]
"We predict the label of xt using the weighted sum of its contextualized representation: ŷt = predt( ∑ i α t ih t i), where predt is a task-specific multi-layer perceptron.",3.1 Multi-task learning,[0],[0]
"We train this module to minimize the loss, Llbl, between the prediction and the annotated label for all source tasks.",3.1 Multi-task learning,[0],[0]
We use cross entropy loss for classification tasks and mean square loss for regression tasks.,3.1 Multi-task learning,[0],[0]
"Supplied with large amounts of source data and unlabeled target data, this module has two goals: 1) learning a general encoder for both source and target corpora, and 2) learning domain-invariant representation.",3.2 Domain-invariant encoder,[0],[0]
This module enables effective transfer—especially in the presence of significant variance between the source and target domains.,3.2 Domain-invariant encoder,[0],[0]
"We achieve the first goal by optimizing a language modeling objective and the second goal by minimizing the Wasserstein distance between the source and target distribution.
",3.2 Domain-invariant encoder,[0],[0]
"Let x be an input sequence, and h , [ −→ h ; ←− h ] be its corresponding contextualized representation obtained from enc.",3.2 Domain-invariant encoder,[0],[0]
"Here, −→ h and ←− h denote the output sequence of the forward and backward LSTM, respectively.",3.2 Domain-invariant encoder,[0],[0]
"In order to support transfer, enc should be general enough to effectively represent both source and target corpora.",3.2 Domain-invariant encoder,[0],[0]
"For this reason, we ground the encoder by a language modeling component (Bengio et al., 2003; Mikolov et al., 2011).",3.2 Domain-invariant encoder,[0],[0]
"Specifically, we employ two Softmax classifiers to predict the word xi based on−→ h i−1 and ←− h i+1 respectively.",3.2 Domain-invariant encoder,[0],[0]
"We minimize the cross-entropy lossLlm over all source data and unlabeled target data.
",3.2 Domain-invariant encoder,[0],[0]
The representation h is domain-specific as it is trained to encode useful features for language modeling and the source tasks.,3.2 Domain-invariant encoder,[0],[0]
"To obtain an invariant representation, we employ a transformation layer and propose to align the transformed representation so that it is not distinguishable whether it comes from the source or the target.",3.2 Domain-invariant encoder,[0],[0]
"Specifically, we transform the representation hi at each position i linearly and obtain
hinvi =Winvhi + binv,
where Winv and binv are learnable parameters.",3.2 Domain-invariant encoder,[0],[0]
"We minimize the Wasserstein distance (Arjovsky et al., 2017) between the distribution of hinv from the source and the one from the target, denoted as PS and PT , respectively.",3.2 Domain-invariant encoder,[0],[0]
"Since hinv is a sequence
of variable length, L, we summarize it by its first and last element via concatenation, [hinv1 ;h inv L ].",3.2 Domain-invariant encoder,[0],[0]
"The training objective is defined as:
Lwd = sup ‖f‖L≤K
Ehinv∼PS [ f([hinv1 ;h inv L ])",3.2 Domain-invariant encoder,[0],[0]
"]
− Ehinv∼PT",3.2 Domain-invariant encoder,[0],[0]
"[ f([hinv1 ;h inv L ]) ] ,
where the supremum is over allK-Lipschitz scalar functions f .",3.2 Domain-invariant encoder,[0],[0]
"Following Gulrajani et al. (2017), we approximate f by a multi-layer perceptron, and use gradient penalty to fulfill the Lipschitz constraint.",3.2 Domain-invariant encoder,[0],[0]
The goal of this module is to generate high-quality attention for each task.,3.3 Attention generation,[0],[0]
This module combines the domain-invariant representation together with task-specific rationales as its input and predicts task-specific attention scores.,3.3 Attention generation,[0],[0]
"We minimize the distance between the predicted attention and the intermediate attention obtained from the multitask learning module.
",3.3 Attention generation,[0],[0]
"For any source task t ∈ {Si}Ni=1, we denote rt as the task-specific rationales corresponding to the input text xt, and denote hinv,t as the domaininvariant representation of xt.",3.3 Attention generation,[0],[0]
"For each position i, we first concatenate rti with the frequency of x t i occurring as a rationale from all training examples of this task.",3.3 Attention generation,[0],[0]
We denote this augmented sequence as r̃t.,3.3 Attention generation,[0],[0]
This frequency term provides the unigram likelihood of each word being a rationale for the task.,3.3 Attention generation,[0],[0]
"Then we employ a sequence encoder encr2a and an attention module attr2a to predict the attention scores:
ut = encr2a([hinv,t; r̃t]),
ũti = tanh(W r2a att",3.3 Attention generation,[0],[0]
u t i + b,3.3 Attention generation,[0],[0]
"r2a att), α̂ti = exp(〈ũti, qr2aatt 〉)∑ j exp(〈ũtj , qr2aatt 〉) ,
where W r2aatt ,",3.3 Attention generation,[0],[0]
"b r2a att and q r2a att are learnable parameters, and both encr2a and attr2a are shareable across all tasks.",3.3 Attention generation,[0],[0]
"We minimize the distance between α̂t and the αt obtained from the first multitask learning module over all source data:
Latt = ∑
(αt,α̂t),t∈{Si}Ni=1
d(αt, α̂t),
where d(·, ·) can be any distance metric.",3.3 Attention generation,[0],[0]
"In this paper, we consider a soft-margin cosine distance:
d(a, b) , max(0, 1− cos(a, b)− 0.1),
where cos(·, ·) denotes the cosine similarity.",3.3 Attention generation,[0],[0]
Training R2A We train the three aforementioned modules jointly using both the source data and the unlabeled target data.,3.4 Pipeline,[0],[0]
"The overall objective is given by:
L = Llbl + λattLatt",3.4 Pipeline,[0],[0]
+ λlmLlm + λwdLwd.,3.4 Pipeline,[0],[0]
"(1)
",3.4 Pipeline,[0],[0]
"The λs are hyper-parameters that control the importance of each training objective and Ls represent the corresponding loss functions.
",3.4 Pipeline,[0],[0]
"R2A inference Once the R2A model is trained, we can generate attention for each labeled target example based on its human-annotated rationales.
",3.4 Pipeline,[0],[0]
Training target classifier,3.4 Pipeline,[0],[0]
"When testing the performance on the target task, of course, we are neither provided with labels nor rationales.",3.4 Pipeline,[0],[0]
"In order to make predictions for the target task, we train a new classifier under the supervision of both the labels and the R2A-generated attention.",3.4 Pipeline,[0],[0]
"Specifically, this target classifier shares the same architecture as the source one in the multi-task learning module.",3.4 Pipeline,[0],[0]
"We minimize the prediction loss, LTlbl, on the labeled target data together with the cosine distance, LTatt, between the R2A-generated attention and the attention generated by this target classifier.",3.4 Pipeline,[0],[0]
"The joint objective for this target classifier is defined as
L = LTlbl + λTattLTatt, (2)
where λTatt controls the importance of LTatt.",3.4 Pipeline,[0],[0]
"For better transfer, we initialize the encoder in the target classifier as enc from the trained R2A model.",3.4 Pipeline,[0],[0]
"We evaluate our approach on two transfer settings: transfer among aspects within the same domain and transfer among different domains.
",4.1 Datasets,[0],[0]
Aspect transfer We first consider the transfer problem between multiple aspects of one domain: beer review.,4.1 Datasets,[0],[0]
"We use a subset of the BeerAdvocate3 review dataset (McAuley et al., 2012) introduced by Lei et al. (2016).",4.1 Datasets,[0],[0]
"This dataset contains reviews with ratings (in the scale of [0, 1]) from three aspects of the beer: look, aroma and palate.",4.1 Datasets,[0],[0]
"We treat
3https://www.beeradvocate.com
any two aspects as the source and the other one as the target.",4.1 Datasets,[0],[0]
We consider a classification setting for each target task.,4.1 Datasets,[0],[0]
"Specifically, reviews with ratings ≤ 0.4 are labeled as negative and those with ≥ 0.6 are labeled as positive.",4.1 Datasets,[0],[0]
We form our dataset by randomly selecting an equal number of positive and negative examples.,4.1 Datasets,[0],[0]
Then we randomly select 200 examples and ask human annotators to provide rationales (see Appendix 2 for details).,4.1 Datasets,[0],[0]
These 200 examples are treated as our labeled training data for the target aspect.,4.1 Datasets,[0],[0]
Unlabeled target data is not required since both source and target tasks are from the same domain.,4.1 Datasets,[0],[0]
"Table 1 summarizes the statistics of the beer review dataset.
",4.1 Datasets,[0],[0]
Domain transfer Our second experiment focuses on domain transfer from beer reviews to different aspects of hotel reviews.,4.1 Datasets,[0],[0]
"We use the TripAdvisor4 hotel review dataset (Wang et al., 2010), with the following three aspects as our transfer target: location, cleanliness, and service.",4.1 Datasets,[0],[0]
"For each aspect, reviews with ratings > 3 are labeled as positive and those with < 3 are labeled as negative.",4.1 Datasets,[0],[0]
"Similarly, we collect human rationales for 200 examples and treat them as our training data (see Appendix 2 for details).",4.1 Datasets,[0],[0]
Table 2 summarizes the statistics of the hotel review dataset.,4.1 Datasets,[0],[0]
"In this experiment, data from all three aspects of the beer reviews are treated as the source tasks.",4.1 Datasets,[0],[0]
"We compare our approach (OURS) with four types of baselines:
4https://www.tripadvisor.com
Basic classifier We train a linear SVM using bag-of-ngrams representation on the labeled target data.",4.2 Baselines,[0],[0]
"We combine uni-gram, bi-grams, and trigrams as features and use tf-idf weighting.
",4.2 Baselines,[0],[0]
"Rationale augmented classifiers We evaluate two previous methods that incorporate human rationales during training: 1) rationale augmented SVM (RA-SVM) (Zaidan et al., 2007), an SVMbased model that utilizes human rationales to regularize the decision boundary of the classifier; 2) rationale augmented CNN (RA-CNN) (Zhang et al., 2016).",4.2 Baselines,[0],[0]
RA-CNN first trains a CNN-based sentence classifier to estimate the probability that a given sentence contains rationale words.,4.2 Baselines,[0],[0]
Then RA-CNN scales the contribution of each sentence to the overall representation in proportion to these estimates.,4.2 Baselines,[0],[0]
"The final prediction is made from this overall representation.
",4.2 Baselines,[0],[0]
"Transfer methods We compare against two variants of our method: 1) TRANS, an attentionbased classifier that does not use human rationales from the target task; 2) RA-TRANS, an attentionbased classifier that directly uses human rationales to supervise the attention.",4.2 Baselines,[0],[0]
"Specifically, TRANS only optimizes the cross-entropy loss LTlbl in the objective (Eq. (2)).",4.2 Baselines,[0],[0]
"For RA-TRANS, the term LTatt in the objective Eq. (2) is replaced by the cosine distance between human rationales and the attention generated by itself.",4.2 Baselines,[0],[0]
"Note that both models still have the ability to transfer, as their encoders are both initialized from enc, which has been trained on source data and unlabeled target data.
",4.2 Baselines,[0],[0]
Oracle We also report the performance of an ORACLE which shares the same architecture as ours but is supervised by the oracle attention.,4.2 Baselines,[0],[0]
The oracle attention is derived from a held-out dataset with large-scale annotations for the target task (see Appendix 3 for details).,4.2 Baselines,[0],[0]
This helps us analyze the contribution of our R2A approach in isolation of the inherent limitations of the target tasks.,4.2 Baselines,[0],[0]
"We use pre-trained fastText embeddings (Bojanowski et al., 2017), a 200-dimension bidirectional LSTM (Hochreiter and Schmidhuber, 1997) for the language encoder, and a 50- dimension bi-directional LSTM for the R2A encoder.",4.3 Implementation details,[0],[0]
"Dropout (Srivastava et al., 2014) is applied with drop rate 0.1 on the word embeddings and the last hidden layers of the classifiers.",4.3 Implementation details,[0],[0]
"All
parameters are optimized using Adam (Kingma and Ba, 2014).",4.3 Implementation details,[0],[0]
We set the initial learning rate to 0.001 and divide it by 10 once the performance on the development set plateaus.,4.3 Implementation details,[0],[0]
"For RATRANS, OURS and ORACLE, we tuned λTatt from {102, 101, 100, 10−1, 10−2}.",4.3 Implementation details,[0],[0]
"For domain transfer, we set λlm = 0.1, λwd = 0.01 and λatt = 0.01.",4.3 Implementation details,[0],[0]
"For aspect transfer, we adapt the same hyperparameters, but set λwd = 0",4.3 Implementation details,[0],[0]
as both source tasks and the target task come from the same domain.,4.3 Implementation details,[0],[0]
"To encourage the R2A-generated attention to be consistent with the provided rationales in aspect transfer, we augment the overall training objective of R2A in Eq.",4.3 Implementation details,[0],[0]
"(3.3) by a consistency regularization, which is computed from the cosine distance between the R2A-generated attention and the provided rationales.
",4.3 Implementation details,[0],[0]
"In addition, computing Llm is both time and memory inefficient because the complexity is linear to the size of the vocabulary, which can be very large.",4.3 Implementation details,[0],[0]
"To expedite the training, we adopt a technique proposed by Mikolov et al. (2011), which randomly splits the entire vocabulary into a predefined number of bins and minimizes the loss of the bin prediction instead of the exact token prediction.",4.3 Implementation details,[0],[0]
We set the bin size as 100 for our experiment.,4.3 Implementation details,[0],[0]
Aspect transfer Table 3 summarizes the results of aspect transfer on the beer review dataset.,5 Results,[0],[0]
Our model (OURS) obtains substantial gains in accuracy over the baselines across all three target aspects.,5 Results,[0],[0]
"It closely matches the performance of ORACLE with only 0.40% absolute difference.
",5 Results,[0],[0]
"Specifically, all rationale-augmented methods (RA-SVM, RA-TRANS and OURS) outperform their rationale-free counterparts on average.",5 Results,[0],[0]
This confirms the value of human rationales in the low-resource settings.,5 Results,[0],[0]
We observe that the transfer baseline that directly uses rationale as augmented supervision (RA-TRANS) underperforms ORACLE by a large margin.,5 Results,[0],[0]
"This validates our hypothesis that human rationales and attention are different.
",5 Results,[0],[0]
Domain transfer Table 4 presents the results of domain transfer using 200 training examples.,5 Results,[0],[0]
We use the three aspects of the beer review data together as our source tasks while use the three aspects of hotel review data as the target.,5 Results,[0],[0]
Our model (OURS) shows marked performance improvement.,5 Results,[0],[0]
"The error reduction over the best baseline is 15.08% on average.
",5 Results,[0],[0]
We compare the learning curve in Figure 4.,5 Results,[0],[0]
"We observe that the performance of our model steadily improves as more annotations are provided, and the improvement over other baselines is significant and consistent.
",5 Results,[0],[0]
Ablation study Table 5 presents the results of an ablation study of our model in the setting of domain transfer.,5 Results,[0],[0]
"As this table indicates, both the language modeling objective and the Wasserstein
distance contribute similarly to the task, with the Wasserstein distance having a bigger impact.
",5 Results,[0],[0]
"Visualization of representation Figure 5 visualizes the hidden representation of 200 beer reviews and 200 hotel reviews using t-SNE (Maaten and Hinton, 2008).",5 Results,[0],[0]
We observe that our model successfully aligns the source and the target feature distribution.,5 Results,[0],[0]
"This indicates the effectiveness of optimizing the Wasserstein distance objective.
",5 Results,[0],[0]
"Analysis of R2A-generated attention In order to validate that the trained R2A model is able to generate task-specific attention from human rationales, we perform both qualitative and quantitative
5Since the hidden representation is a sequence of variable length, we applied t-SNE on the concatenation of the first and last element: [hinv1 ;hinvL ].
analysis on the R2A-generated attention in the setting of domain transfer.",5 Results,[0],[0]
"It is worth pointing out that our R2A model has never seen any labeled hotel reviews during training.
",5 Results,[0],[0]
Table 6 presents the average cosine distance between the R2A-generated attention and the oracle attention over the target training set.,5 Results,[0],[0]
"Compared with human rationales, the R2A-generated attention is much closer to the oracle attention.",5 Results,[0],[0]
"This explains the large performance boost of our method.
",5 Results,[0],[0]
Figure 6 visualize the R2A-generated attention on the same hotel review with human rationales corresponding to three different aspects.,5 Results,[0],[0]
We observe that the trained R2A model is able to produce task-specific attention scores corresponding to the provided human rationale.,5 Results,[0],[0]
"For example, given the rationale sentence “not the cleanest rooms but bed was clean and so was bathroom”, R2A recognizes that not every token is equally important, and the attention should focus more on “clean”, “cleanest”, “rooms” and “bathroom”.
",5 Results,[0],[0]
"Annotating rationales versus annotating more labeled data Providing rationales for the training data roughly doubles the annotation cost (Zaidan et al., 2007).",5 Results,[0],[0]
"Given the same annotation budget, a natural question is: shall we collect a few labeled examples with rationales or annotate more labeled examples?",5 Results,[0],[0]
"To answer this question, we vary the number of training examples in the target task.",5 Results,[0],[0]
Figure 7 shows the corresponding learning curve of a classifier that is trained without rationales.,5 Results,[0],[0]
The reference line represents the accuracy of our approach trained on 200 examples with rationales.,5 Results,[0],[0]
"We notice that in order to reach the same level of performance, the rationale-free classifier requires 800, 3100, and 1900 labeled examples on the three target tasks respectively.",5 Results,[0],[0]
"In this paper, we propose a novel approach that utilizes the connection between human rationales and machine attention to improve the performance of low-resource tasks.",6 Conclusion,[0],[0]
"Specifically, we learn a transferrable mapping from rationales to high-quality attention on resource-rich tasks.",6 Conclusion,[0],[0]
The learned mapping is then used to provide an additional supervision for the target task.,6 Conclusion,[0],[0]
"Experimental results on both aspect and domain transfer validate that the R2A-generated attention serves as a better form of
supervision.",6 Conclusion,[0],[0]
Our model produces high-quality attention for low-resource tasks.,6 Conclusion,[0],[0]
We thank the MIT NLP group and the reviewers for their helpful discussion and comments.,Acknowledgments,[0],[0]
This work is supported by MIT-IBM Watson AI Lab.,Acknowledgments,[0],[0]
"Any opinions, findings, conclusions, or recommendations expressed in this paper are those of the authors, and do not necessarily reflect the views of the funding organizations.",Acknowledgments,[0],[0]
Collecting rationales at scale is expensive.,A1 Generating machine rationales,[0],[0]
"Thus, we employ an existing rationalization model (Lei et al., 2016) to generate high-quality rationales automatically for the resource-rich source tasks.
",A1 Generating machine rationales,[0],[0]
The rationalization model is composed of two modular components: a generator and a classifier.,A1 Generating machine rationales,[0],[0]
"The generator generates rationales from the input, and the classifier maps the generated rationales into the final label.",A1 Generating machine rationales,[0],[0]
"The two components are trained jointly to minimize a loss function that favors short, concise rationales while enforcing that the rationales alone suffice for accurate prediction.
",A1 Generating machine rationales,[0],[0]
Figure 8 illustrates the model architecture.,A1 Generating machine rationales,[0],[0]
"For the generator, we use a 200 dimensional bi-LSTM to encode the word embedding sequence.",A1 Generating machine rationales,[0],[0]
Then we apply a linear regressor at each position i to predict the probability pi that the current word is a rationale.,A1 Generating machine rationales,[0],[0]
We sample zi from this probability and pass the sampled rationales zixi to the classifier module.,A1 Generating machine rationales,[0],[0]
"To encourage fast and stable convergence, we use the Gumbel trick (Jang et al., 2016) during sampling.
",A1 Generating machine rationales,[0],[0]
"For the classifier, we employ a CNN-based model (Kim, 2014).",A1 Generating machine rationales,[0],[0]
"Specifically, the classifier first computes 1D convolution over the embeddings of the generated rationales.",A1 Generating machine rationales,[0],[0]
"The filter windows are 3, 5, 7 with 50 feature maps each.",A1 Generating machine rationales,[0],[0]
It then applies max-over-time pooling to obtain a fixedlength feature vector.,A1 Generating machine rationales,[0],[0]
"Finally, a multilayer perceptron (MLP) is used to predict the label from the feature vector.",A1 Generating machine rationales,[0],[0]
"The MLP consists of one hidden
layer (50 units and ReLU activation).",A1 Generating machine rationales,[0],[0]
"We collected human rationales on six sentiment classification tasks: beer look, beer aroma, beer palate, hotel location, hotel cleanliness and hotel service.",A2 Collecting human rationales,[0],[0]
"For each task, we randomly picked 100 positive examples and 100 negative examples.",A2 Collecting human rationales,[0],[0]
"These 200 labeled examples are given to the annotators (five students) to highlight rationales that are short and coherent, yet sufficient for supporting the label (Lei et al., 2016).",A2 Collecting human rationales,[0],[0]
The annotators can also flip the original label if it is incorrect.,A2 Collecting human rationales,[0],[0]
"Figure 9 shows our annotation interface, and Table 7 presents the statistics of the collected rationales.",A2 Collecting human rationales,[0],[0]
Figure 10 illustrates the model architecture that we used to derive the oracle attention.,A3 Deriving the oracle attention,[0],[0]
It has the same architecture as the source classifier in our R2A model (Section 3.1).,A3 Deriving the oracle attention,[0],[0]
"Specifically, we use pre-trained fastText embeddings.",A3 Deriving the oracle attention,[0],[0]
The encoder is a bi-LSTM with 200 hidden units.,A3 Deriving the oracle attention,[0],[0]
The attention head q is a vector of dimension 50.,A3 Deriving the oracle attention,[0],[0]
"For the prediction module pred, we use a MLP with one hidden
layer (50 units and ReLU activation).",A3 Deriving the oracle attention,[0],[0]
"For each task, we train this attention-based classifier on a large amount of annotations.",A3 Deriving the oracle attention,[0],[0]
Table 8 presents the statistics of the training data and the testing performance of the classifier.,A3 Deriving the oracle attention,[0],[0]
"We train a critic network to estimate the Wasserstein distance between the distribution of the representation from the source domain and the one from the target domain:
Lwd = sup ‖f‖L≤K
Ehinv∼PS",A4 Estimating the Wasserstein distance,[0],[0]
"[ f([hinv1 ;h inv L ]) ]
",A4 Estimating the Wasserstein distance,[0],[0]
− Ehinv∼PT,A4 Estimating the Wasserstein distance,[0],[0]
"[ f([hinv1 ;h inv L ]) ] .
",A4 Estimating the Wasserstein distance,[0],[0]
The critic network is parametrized as a MLP with one hidden layer (100 units and ReLU activation).,A4 Estimating the Wasserstein distance,[0],[0]
"Following Gulrajani et al. (2017), we set the weight of the gradient penalty to 10 and optimize the critic network for 5 iterations during each batch.",A4 Estimating the Wasserstein distance,[0],[0]
Figure 11 plots the loss on the development set versus the number of training batches.,A4 Estimating the Wasserstein distance,[0],[0]
We see that our R2A model converges smoothly during training.,A4 Estimating the Wasserstein distance,[0],[0]
Attention-based models are successful when trained on large amounts of data.,abstractText,[0],[0]
"In this paper, we demonstrate that even in the low-resource scenario, attention can be learned effectively.",abstractText,[0],[0]
"To this end, we start with discrete humanannotated rationales and map them into continuous attention.",abstractText,[0],[0]
"Our central hypothesis is that this mapping is general across domains, and thus can be transferred from resource-rich domains to low-resource ones.",abstractText,[0],[0]
Our model jointly learns a domain-invariant representation and induces the desired mapping between rationales and attention.,abstractText,[0],[0]
"Our empirical results validate this hypothesis and show that our approach delivers significant gains over state-ofthe-art baselines, yielding over 15% average error reduction on benchmark datasets.1",abstractText,[0],[0]
Deriving Machine Attention from Human Rationales,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 708–717 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1066",text,[0],[0]
"On November 9th, 2016, Eric Tucker, a grassroots user who had just about 40 followers on Twitter, tweeted his unverified observations about paid protesters being bused to attend anti-Trump demonstration in Austin, Texas.",1 Introduction,[0],[0]
"The tweet, which was proved false later, was shared over 16 thousand times on Twitter and 350 thousand times on Facebook within a couple of days, fueling a nation-wide conspiracy theory1.",1 Introduction,[0],[0]
The diffusion of the story is illustrated as Figure 1 which gives the key spreading points of the story along the time line.,1 Introduction,[0],[0]
"We can see that after the initial post, the tweet
1https://www.nytimes.com/2016/11/20/ business/media/how-fake-news-spreads.",1 Introduction,[0],[0]
"html
was shared or promoted by some influential online communities and users (including Trump himself), resulting in its wide spread.
",1 Introduction,[0],[0]
"A widely accepted definition of rumor is “unverified and instrumentally relevant information statements in circulation” (DiFonzo and Bordia, 2007).",1 Introduction,[0],[0]
"This unverified information may eventually turn out to be true, or partly or entirely false.",1 Introduction,[0],[0]
"In today’s ever-connected world, rumors can arise and spread at lightening speed thanks to social media platforms, which could not only be wrong, but be misleading and dangerous to the public society.",1 Introduction,[0],[0]
"Therefore, it is crucial to track and debunk such rumors in timely manner.
",1 Introduction,[0],[0]
Journalists and fact-checking websites such as snopes.com have made efforts to track and detect rumors.,1 Introduction,[0],[0]
"However, such endeavor is manual, thus prone to poor coverage and low speed.",1 Introduction,[0],[0]
"Feature-based methods (Castillo et al., 2011; Yang et al., 2012; Ma et al., 2015) achieved certain success by employing large feature sets crafted from message contents, user profiles and holistic statistics of diffusion patterns (e.g., number of retweets, propagation time, etc.).",1 Introduction,[0],[0]
But such an approach was over simplified as they ignored the dynamics of rumor propagation.,1 Introduction,[0],[0]
"Existing studies considering propagation characteristics mainly focused on the temporal features (Kwon et al., 2013, 2017) rather than the structure of propagation.
",1 Introduction,[0],[0]
"So, can the propagation structure make any difference for differentiating rumors from nonrumors?",1 Introduction,[0],[0]
"Recent studies showed that rumor spreaders are persons who want to get attention and popularity (Sunstein, 2014).",1 Introduction,[0],[0]
"However, popular users who get more attention on Twitter (e.g., with more followers) are actually less likely to spread rumor in a sense that the high audience size might hinder a user from participating in propagating unverified information (Kwon et al., 2017).",1 Introduction,[0],[0]
"Intuitively, for “successful” rumors being propagated as widely
708
as popular real news, initial spreaders (typically lack of popularity) must attract certain amount of broadcasting power, e.g., attention of influential users or communities that have a lot of audiences joining in promoting the propagation.",1 Introduction,[0],[0]
"We refer to this as a constrained mode propagation, relative to the open mode propagation of normal messages that everyone is open to share.",1 Introduction,[0],[0]
"Such different modes of propagation may imply some distinct propagation structures between rumors and nonrumors and even among different types of rumors.
",1 Introduction,[0],[0]
"Due to the complex nature of information diffusion, explicitly defining discriminant features based on propagation structure is difficult and biased.",1 Introduction,[0],[0]
"Figure 2 exemplifies the propagation structures of two Twitter posts, a rumor and a nonrumor, initiated by two users shown as the root nodes (in green color).",1 Introduction,[0],[0]
"The information flows here illustrate that the rumorous tweet is first posted by a low-impact user, then some popular users joining in who boost the spreading, but the non-rumorous tweet is initially posted by a popular user and directly spread by many general users; contentbased signal like various users’ stance (Zhao et al., 2015) and edge-based signal such as relative influence (Kwon et al., 2017) can also suggest the different nature of source tweets.",1 Introduction,[0],[0]
Many of such implicit distinctions throughout message propagation are hard to hand craft specifically using flat summary of statistics as previous work did.,1 Introduction,[0],[0]
"In addition, unlike representation learning for plain text, learning for representation of structures such as networks is not well studied in general.",1 Introduction,[0],[0]
"Therefore, traditional and latest text-based models (Castillo
et al., 2011; Ma et al., 2015, 2016) cannot be applied easily on such complex, dynamic structures.
",1 Introduction,[0],[0]
"To capture high-order propagation patterns for rumor detection, we firstly represent the propagation of each source tweet with a propagation tree which is formed by harvesting user’s interactions to one another triggered by the source tweet.",1 Introduction,[0],[0]
"Then, we propose a kernel-based data-driven method called Propagation Tree Kernel (PTK) to generate relevant features (i.e., subtrees) automatically for estimating the similarity between two propagation trees.",1 Introduction,[0],[0]
"Unlike traditional tree kernel (Moschitti, 2006; Zhang et al., 2008) for modeling syntactic structure based on parse tree, our propagation tree consists of nodes corresponding to microblog
posts, each represented as a continuous vector, and edges representing the direction of propagation and providing the context to individual posts.",1 Introduction,[0],[0]
The basic idea is to find and capture the salient substructures in the propagation trees indicative of rumors.,1 Introduction,[0],[0]
"We also extend PTK into a context-enriched PTK (cPTK) to enhance the model by considering different propagation paths from source tweet to the roots of subtrees, which capture the context of transmission.",1 Introduction,[0],[0]
"Extensive experiments on two real-world Twitter datasets show that the proposed methods outperform state-of-the-art rumor detection models with large margin.
",1 Introduction,[0],[0]
"Moreover, most existing approaches regard rumor detection as a binary classification problem, which predicts a candidate hypothesis as rumor or not.",1 Introduction,[0],[0]
"Since a rumor often begins as unverified and later turns out to be confirmed as true or false, or remains unverified (Zubiaga et al., 2016), here we consider a set of more practical, finer-grained classes: false rumor, true rumor, unverified rumor, and non-rumor, which becomes an even more challenging problem.",1 Introduction,[0],[0]
"Tracking misinformation or debunking rumors has been a hot research topic in multiple disciplines (DiFonzo and Bordia, 2007; Morris et al., 2012; Rosnow, 1991).",2 Related Work,[0],[0]
Castillo et al. (2011) studied information credibility on Twitter using a wide range of hand-crafted features.,2 Related Work,[0],[0]
"Following that, various features corresponding to message contents, user profiles and statistics of propagation patterns were proposed in many studies (Yang et al., 2012; Wu et al., 2015; Sun et al., 2013; Liu et al., 2015).",2 Related Work,[0],[0]
Zhao et al. (2015) focused on early rumor detection by using regular expressions for finding questing and denying tweets as the key for debunking rumor.,2 Related Work,[0],[0]
"All such approaches are over simplistic because they ignore the dynamic propagation patterns given the rich structures of social media data.
",2 Related Work,[0],[0]
Some studies focus on finding temporal patterns for understanding rumor diffusion.,2 Related Work,[0],[0]
Kown et al. (2013; 2017) introduced a time-series fitting model based on the temporal properties of tweet volume.,2 Related Work,[0],[0]
Ma et al. (2015) extended the model using time series to capture the variation of features over time.,2 Related Work,[0],[0]
"Friggeri et al. (2014) and Hannak et al. (2014) studied the structure of misinformation cascades by analyzing comments linking to
rumor debunking websites.",2 Related Work,[0],[0]
"More recently, Ma et al. (2016) used recurrent neural networks to learn the representations of rumor signals from tweet text at different times.",2 Related Work,[0],[0]
"Our work will consider temporal, structural and linguistic signals in a unified framework based on propagation tree kernel.
",2 Related Work,[0],[0]
"Most previous work formulated the task as classification at event level where an event is comprised of a number of source tweets, each being associated with a group of retweets and replies.",2 Related Work,[0],[0]
Here we focus on classifying a given source tweet regarding a claim which is a finer-grained task.,2 Related Work,[0],[0]
"Similar setting was also considered in (Wu et al., 2015; Qazvinian et al., 2011).
",2 Related Work,[0],[0]
"Kernel methods are designed to evaluate the similarity between two objects, and tree kernel specifically addresses structured data which has been successfully applied for modeling syntactic information in many natural language tasks such as syntactic parsing (Collins and Duffy, 2001), question-answering (Moschitti, 2006), semantic analysis (Moschitti, 2004), relation extraction (Zhang et al., 2008) and machine translation (Sun et al., 2010).",2 Related Work,[0],[0]
"These kernels are not suitable for modeling the social media propagation structures because the nodes are not given as discrete values like part-of-speech tags, but are represented as high dimensional real-valued vectors.",2 Related Work,[0],[0]
Our proposed method is a substantial extension of tree kernel for modeling such structures.,2 Related Work,[0],[0]
"On microblogging platforms, the follower/friend relationship embeds shared interests among the users.",3 Representation of Tweets Propagation,[0],[0]
"Once a user has posted a tweet, all his followers will receive the tweet.",3 Representation of Tweets Propagation,[0],[0]
"Furthermore, Twitter allows a user to retweet or comment another user’s post, so that the information could reach beyond the network of the original creator.
",3 Representation of Tweets Propagation,[0],[0]
"We model the propagation of each source tweet as a tree structure T (r) = 〈V,E〉, where r is the source tweet as well as the root of the tree, V refers to a set of nodes each representing a responsive post (i.e., retweet or reply) of a user at a certain time to the source tweet r which initiates the circulation, and E is a set of directed edges corresponding to the response relation among the nodes in V .",3 Representation of Tweets Propagation,[0],[0]
"If there exists a directed edge from vi to vj , it means vj is a direct response to vi.
More specifically, each node v ∈ V is represented as a tuple v = (uv, cv, tv), which provides
the following information: uv is the creator of the post, cv represents the text content of the post, and tv is the time lag between the source tweet r and v.",3 Representation of Tweets Propagation,[0],[0]
"In our case, uv contains attributes of the user such as # of followers/friends, verification status, # of history posts, etc., cv is a vector of binary features based on uni-grams and/or bi-grams representing the post’s content.",3 Representation of Tweets Propagation,[0],[0]
"In this section, we describe our rumor detection model based on propagation trees using kernel method called Propagation Tree Kernel (PTK).",4 Propagation Tree Kernel Modeling,[0],[0]
"Our task is, given a propagation tree T (r) of a source tweet r, to predict the label of r.",4 Propagation Tree Kernel Modeling,[0],[0]
"Before presenting our proposed algorithm, we briefly present the traditional tree kernel, which our PTK model is based on.
",4.1 Background of Tree Kernel,[0],[0]
Tree kernel was designed to compute the syntactic and semantic similarity between two natural language sentences by implicitly counting the number of common subtrees between their corresponding parse trees.,4.1 Background of Tree Kernel,[0],[0]
"Given a syntactic parse tree, each node with its children is associated with a grammar production rule.",4.1 Background of Tree Kernel,[0],[0]
Figure 3 illustrates the syntactic parse tree of “cut a tree” and its subtrees.,4.1 Background of Tree Kernel,[0],[0]
"A subtree is defined as any subgraph which has more than one nodes, with the restriction that entire (not partial) rule productions must be included.",4.1 Background of Tree Kernel,[0],[0]
"For example, the fragment [NP [D a]] is excluded because it contains only part of the production NP→ D N (Collins and Duffy, 2001).
",4.1 Background of Tree Kernel,[0],[0]
"Following Collins and Duffy (2001), given two parse trees T1 and T2, the kernel function K(T1, T2) is defined as:
∑
vi∈V1
∑
vj∈V2 ∆(vi, vj) (1)
where V1 and V2 are the sets of all nodes respectively in T1 and T2, and each node is associated with a production rule, and ∆(vi, vj) evaluates the common subtrees rooted at vi and vj . ∆(vi, vj) can be computed using the following recursive procedure (Collins and Duffy, 2001):
1) if the production rules at vi and vj are different, then ∆(vi, vj) = 0;
2) else if the production rules at vi and vj are same, and vi and vj have only leaf children
(i.e., they are pre-terminal symbols), then ∆(vi, vj) = λ;
3) else ∆(vi, vj) = λ ∏min(nc(vi),nc(vj))
",4.1 Background of Tree Kernel,[0],[0]
"k=1 (1 + ∆(ch(vi, k), ch(vj , k))).
where nc(v) is the number of children of node v, ch(v, k) is the k-th child of node v, and λ (0 < λ ≤ 1) is a decay factor.",4.1 Background of Tree Kernel,[0],[0]
λ,4.1 Background of Tree Kernel,[0],[0]
= 1 yields the number of common subtrees; λ < 1 down weighs the contribution of larger subtrees to make the kernel value less variable with respect to subtree size.,4.1 Background of Tree Kernel,[0],[0]
"To classify propagation trees, we can calculate the similarity between the trees, which is supposed to reflect the distinction of different types of rumors and non-rumors based on structural, linguistic and temporal properties.",4.2 Our PTK Model,[0],[0]
"However, existing tree kernels cannot be readily applied on propagation trees because 1) unlike parse tree where the node is represented by enumerable nominal value (e.g., part-of-speech tag), the propagation tree node is given as a vector of continuous numerical values representing the basic properties of the node; 2) the similarity of two parse trees is based on the count of common subtrees, for which the commonality of subtrees is evaluated by checking if the same production rules and the same children are associated with the nodes in two subtrees being compared, whereas in our context the similarity function should be defined softly since hardly two nodes from different propagation trees are same.
",4.2 Our PTK Model,[0],[0]
"With the representation of propagation tree, we first define a function f to evaluate the similarity between two nodes vi and vj (we simplify the node representation for instance",4.2 Our PTK Model,[0],[0]
"vi = (ui, ci, ti))",4.2 Our PTK Model,[0],[0]
"as the following:
f(vi, vj) = e −t (αE(ui, uj) + (1− α)J (ci, cj))
where t = |ti",4.2 Our PTK Model,[0],[0]
"− tj | is the absolute difference between the time lags of vi and vj , E and J are
user-based similarity and content-based similarity, respectively, and α is the trade-off parameter.",4.2 Our PTK Model,[0],[0]
The intuition of using exponential function of t to scale down the similarity is to capture the discriminant signals or patterns at the different stages of propagation.,4.2 Our PTK Model,[0],[0]
"For example, a questioning message posted very early may signal a false rumor while the same posted far later from initial post may indicate the rumor is still unverified, despite that the two messages are semantically similar.
",4.2 Our PTK Model,[0],[0]
"The user-based similarity is defined as an Euclidean distance E(ui, uj) = ||ui − uj ||2, where ui and uj are the user vectors of node vi and vj and ||",4.2 Our PTK Model,[0],[0]
• ||2 is the 2-norm of a vector.,4.2 Our PTK Model,[0],[0]
"Here E is used to capture the characteristics of users participating in spreading rumors as discriminant signals, throughout the entire stage of propagation.
",4.2 Our PTK Model,[0],[0]
"Contentwise, we use Jaccard coefficient to measure the similarity of post content:
J (ci, cj) = |Ngram(ci) ∩Ngram(cj)| |Ngram(ci) ∪Ngram(cj)|
where ci and cj are the sets of content words in two nodes.",4.2 Our PTK Model,[0],[0]
"For n-grams here, we adopt both uni-grams and bi-grams.",4.2 Our PTK Model,[0],[0]
"It can capture cue terms e.g., ‘false’, ‘debunk’, ‘not true’, etc. commonly occurring in rumors but not in non-rumors.
",4.2 Our PTK Model,[0],[0]
"Given two propagation trees T1 = 〈V1, E1〉 and T2 = 〈V2, E2〉, PTK aims to compute the similarity between T1 and T2 iteratively based on enumerating all pairs of most similar subtrees.",4.2 Our PTK Model,[0],[0]
"First, for each node vi ∈ V1, we obtain v′i ∈ V2, the most similar node of vi from V2:
v′i = arg max vj∈V2 f(vi, vj)
Similarly, for each vj ∈ V2, we obtain v′j ∈ V1:
v′j = arg max vi∈V1 f(vi, vj)
",4.2 Our PTK Model,[0],[0]
"Then, the propagation tree kernel KP (T1, T2) is defined as:
∑
vi∈V1 Λ(vi, v
′",4.2 Our PTK Model,[0],[0]
i),4.2 Our PTK Model,[0],[0]
"+
∑
vj∈V2 Λ(v′j , vj) (2)
",4.2 Our PTK Model,[0],[0]
"where Λ(v, v′) evaluates the similarity of two subtrees rooted at v and v′, which is computed recursively as follows:
1) if v or v′ are leaf nodes, then Λ(v, v′) = f(v, v′);
2) else Λ(v, v′) = f(v, v′) ∏min(nc(v),nc(v′)) k=1 (1 +
Λ(ch(v, k), ch(v′, k)))
",4.2 Our PTK Model,[0],[0]
"Note that unlike traditional tree kernel, in PTK the node similarity f ∈",4.2 Our PTK Model,[0],[0]
"[0, 1] is used for softly counting similar subtrees instead of common subtrees.",4.2 Our PTK Model,[0],[0]
"Also, λ in tree kernel is not needed as subtree size is not an issue here thanks to node similarity f .
PTK aims to capture discriminant patterns from propagation trees inclusive of user, content and temporal traits, which is inspired by prior analyses on rumors spreading, e.g., user information can be a strong clue in the initial broadcast, content features are important throughout entire propagation periods, and structural and temporal patterns help for longitudinal diffusion (Zubiaga et al., 2016; Kwon et al., 2017).",4.2 Our PTK Model,[0],[0]
"One defect of PTK is that it ignores the clues outside the subtrees, e.g., how the information propagates from source post to the current subtree.",4.3 Context-Sensitive Extension of PTK,[0],[0]
"Intuitively, propagation paths provide further clue for determining the truthfulness of information since they embed the route and context of how the propagation happens.",4.3 Context-Sensitive Extension of PTK,[0],[0]
"Therefore, we propose contextsensitive PTK (cPTK) by considering the propagation paths from the root of the tree to the roots of subtrees, which shares similar intuition with the context-sensitive tree kernel (Zhou et al., 2007).
",4.3 Context-Sensitive Extension of PTK,[0],[0]
"For a propagation tree node v ∈ T (r), let Lrv be the length (i.e., # of nodes) of the propagation path from root r to v, and v[x] be the x-th ancestor of v on the path starting from v (0 ≤",4.3 Context-Sensitive Extension of PTK,[0],[0]
x,4.3 Context-Sensitive Extension of PTK,[0],[0]
<,4.3 Context-Sensitive Extension of PTK,[0],[0]
"Lrv, v[0] = v, v[Lrv",4.3 Context-Sensitive Extension of PTK,[0],[0]
− 1] = r).,4.3 Context-Sensitive Extension of PTK,[0],[0]
"cPTK evaluates the similarity between two trees T1(r1) and T2(r2) as follows:
∑
vi∈V1
L r1 vi −1∑
x=0
Λx(vi, v ′",4.3 Context-Sensitive Extension of PTK,[0],[0]
i),4.3 Context-Sensitive Extension of PTK,[0],[0]
"+
∑
vj∈V2
L r2 vj −1∑
x=0
Λx(v ′ j , vj)
(3) where Λx(v, v′) measures the similarity of subtrees rooted at v[x] and v′[x] for context-sensitive evaluation, which is computed as follows:
1) if x > 0, Λx(v, v′) = f(v[x], v′[x]), where v[x] and v′[x] are the x-th ancestor nodes of v and v′ on the respective propagation path.
2) else Λx(v, v′) = Λ(v, v′), namely PTK.
",4.3 Context-Sensitive Extension of PTK,[0],[0]
"Clearly, PTK is a special case of cPTK when x = 0 (see equation 3).",4.3 Context-Sensitive Extension of PTK,[0],[0]
"cPTK evaluates the oc-
currence of both context-free (without considering ancestors on propagation paths) and contextsensitive cases.",4.3 Context-Sensitive Extension of PTK,[0],[0]
The advantage of kernel-based method is that we can avoid painstakingly engineering the features.,4.4 Rumor Detection via Kernel Learning,[0],[0]
"This is possible because the kernel function can explore an implicit feature space when calculating the similarity between two objects (Culotta and Sorensen, 2004).
",4.4 Rumor Detection via Kernel Learning,[0],[0]
"We incorporate the proposed tree kernel functions, i.e., PTK (equation 2) or cPTK (equation 3), into a supervised learning framework, for which we utilize a kernel-based SVM classifier.",4.4 Rumor Detection via Kernel Learning,[0],[0]
"We treat each tree as an instance, and its similarity values with all training instances as feature space.",4.4 Rumor Detection via Kernel Learning,[0],[0]
"Therefore, the kernel matrix of training set is m × m and that of test set is n×m where m and n are the sizes of training and test sets, respectively.
",4.4 Rumor Detection via Kernel Learning,[0],[0]
"For our multi-class task, we perform a one-vsall classification for each label and then assign the one with the highest likelihood among the four, i.e., non-rumor, false rumor, true rumor or unverified rumor.",4.4 Rumor Detection via Kernel Learning,[0],[0]
"We choose this method due to interpretability of results, similar to recent work on occupational class classification (Preotiuc-Pietro et al., 2015; Lukasik et al., 2015).",4.4 Rumor Detection via Kernel Learning,[0],[0]
"To our knowledge, there is no public large dataset available for classifying propagation trees, where we need a good number of source tweets, more accurately, the tree roots together with the corresponding propagation structure, to be appropriately annotated with ground truth.
",5.1 Data Sets,[0],[0]
"We constructed our datasets based on a couple of reference datasets, namely Twitter15 (Liu et al., 2015) and Twitter16 (Ma et al., 2016).",5.1 Data Sets,[0],[0]
"The original datasets were released and used for binary classification of rumor and non-rumor with respect to given events that contain their relevant tweets.
",5.1 Data Sets,[0],[0]
"First, we extracted the popular source tweets2 that are highly retweeted or replied.",5.1 Data Sets,[0],[0]
"We then collected all the propagation threads (i.e., retweets and replies) for these source tweets.",5.1 Data Sets,[0],[0]
"Because Twitter API cannot retrieve the retweets or replies, we gathered the retweet users for a given tweet from
2Though unpopular tweets could be false, we ignore them as they do not draw much attention and are hardly impactful
Twrench3 and crawled the replies through Twitter’s web interface.
",5.1 Data Sets,[0],[0]
"Finally, we annotated the source tweets by referring to the labels of the events they are from.",5.1 Data Sets,[0],[0]
"We first turned the label of each event in Twitter15 and Twitter16 from binary to quaternary according to the veracity tag of the article in rumor debunking websites (e.g., snopes.com, Emergent.info, etc).",5.1 Data Sets,[0],[0]
"Then we labeled the source tweets by following these rules: 1) Source tweets from unverified rumor events or non-rumor events are labeled the same as the corresponding event’s label; 2) For a source tweet in false rumor event, we flip over the label and assign true to the source tweet if it expresses denial type of stance; otherwise, the label is assigned as false; 3)",5.1 Data Sets,[0],[0]
"The analogous flip-over/nochange rule applies to the source tweets from true rumor events.
",5.1 Data Sets,[0],[0]
We make the datasets produced publicly accessible4.,5.1 Data Sets,[0],[0]
Table 1 gives statistics on the resulting datasets.,5.1 Data Sets,[0],[0]
"We compare our kernel-based method against the following baselines:
SVM-TS: A linear SVM classification model that uses time-series to model the variation of a set of hand-crafted features (Ma et al., 2015).
",5.2 Experimental Setup,[0],[0]
"DTR: A Decision-Tree-based Ranking method to identify trending rumors (Zhao et al., 2015), which searches for enquiry phrases and clusters disputed factual claims, and ranked the clustered results based on statistical features.
",5.2 Experimental Setup,[0],[0]
DTC and SVM-RBF:,5.2 Experimental Setup,[0],[0]
"The Twitter information credibility model using Decision Tree Classifier (Castillo et al., 2011) and the SVM-based
3https://twren.ch 4https://www.dropbox.com/s/
7ewzdrbelpmrnxu/rumdetect2017.zip?dl=0
model with RBF kernel (Yang et al., 2012), respectively, both using hand-crafted features based on the overall statistics of the posts.
RFC:",5.2 Experimental Setup,[0],[0]
"The Random Forest Classifier proposed by Kwon et al. (2017) using three parameters to fit the temporal properties and an extensive set of hand-crafted features related to the user, linguistic and structure characteristics.
GRU: The RNN-based rumor detection model proposed by Ma et al. (2016) with gated recurrent unit for representation learning of high-level features from relevant posts over time.
",5.2 Experimental Setup,[0],[0]
"BOW: A naive baseline we worked by representing the text in each tree using bag-of-words and building the rumor classifier with linear SVM.
",5.2 Experimental Setup,[0],[0]
"Our models: PTK and cPTK are our full PTK and cPTK models, respectively; PTK- and cPTKare the setting of only using content while ignoring user properties.
",5.2 Experimental Setup,[0],[0]
"We implemented DTC and RFC with Weka5, SVM models with LibSVM6 and GRU with Theano7.",5.2 Experimental Setup,[0],[0]
"We held out 10% of the trees in each dataset for model tuning, and for the rest of the trees, we performed 3-fold cross-validation.",5.2 Experimental Setup,[0],[0]
"We used accuracy, F1 measure as evaluation metrics.",5.2 Experimental Setup,[0],[0]
"Table 2 shows that our proposed methods outperform all the baselines on both datasets.
",5.3 Experimental Results,[0],[0]
"Among all baselines, GRU performs the best, which learns the low-dimensional representation of responsive tweets by capturing the textual and temporal information.",5.3 Experimental Results,[0],[0]
"This indicates the effectiveness of complex signals indicative of rumors beyond cue words or phrases (e.g., “what?”, “really?”, “not sure”, etc.).",5.3 Experimental Results,[0],[0]
This also justifies the good performance of BOW even though it only uses uni-grams for representation.,5.3 Experimental Results,[0],[0]
"Although DTR uses a set of regular expressions, we found only 19.59% and 22.21% tweets in our datasets containing these expressions.",5.3 Experimental Results,[0],[0]
"That is why the results of DTR are not satisfactory.
SVM-TS and RFC are comparable because both of them utilize an extensive set of features especially focusing on temporal traits.",5.3 Experimental Results,[0],[0]
"But none of the models can directly incorporate structured propagation patterns for deep similarity compar-
5http://www.cs.waikato.ac.nz/ml/weka/ 6https://www.csie.ntu.edu.tw/˜cjlin/
libsvm/ 7http://deeplearning.net/software/ theano/
ison between propagation trees.",5.3 Experimental Results,[0],[0]
"SVM-RBF, although using a non-linear kernel, is based on traditional hand-crafted features instead of the structural kernel like ours.",5.3 Experimental Results,[0],[0]
"So, they performed obviously worse than our approach.
",5.3 Experimental Results,[0],[0]
Representation learning methods like GRU cannot easily utilize complex structural information for learning important features from our networked data.,5.3 Experimental Results,[0],[0]
"In contrast, our models can capture complex propagation patterns from structured data rich of linguistic, user and temporal signals.",5.3 Experimental Results,[0],[0]
"Therefore, the superiority of our models is clear: PTK- which only uses text is already better than GRU, demonstrating the importance of propagation structures.",5.3 Experimental Results,[0],[0]
"PTK that combines text and user yields better results on both datasets, implying that both properties are complementary and PTK integrating flat and structured information is obviously more effective.
",5.3 Experimental Results,[0],[0]
It is also observed that cPTK outperforms PTK except for non-rumor class.,5.3 Experimental Results,[0],[0]
"This suggests the context-sensitive modeling based on PTK is effective for different types of rumors, but for non-
rumors, it seems that considering context of propagation path is not always helpful.",5.3 Experimental Results,[0],[0]
This might be due to the generally weak signals originated from node properties on the paths during non-rumor’s diffusion since user distribution patterns in nonrumors do not seem as obvious as in rumors.,5.3 Experimental Results,[0],[0]
This is not an issue in cPTK- since user information is not considered at all.,5.3 Experimental Results,[0],[0]
"Over all classes, cPTK achieves the highest accuracies on both datasets.
",5.3 Experimental Results,[0],[0]
"Furthermore, we observe that all the baseline methods perform much better on non-rumors than on rumors.",5.3 Experimental Results,[0],[0]
This is because the features of existing methods were defined for a binary (rumor vs. non-rumor) classification problem.,5.3 Experimental Results,[0],[0]
"So, they do not perform well for finer-grained classes.",5.3 Experimental Results,[0],[0]
"Our ap-
proach can differentiate various classes much better by deep, detailed comparison of different patterns based on propagation structure.",5.3 Experimental Results,[0],[0]
Detecting rumors at an early stage of propagation is very important so that preventive measures could be taken as quickly as possible.,5.4 Early Detection Performance,[0],[0]
"In early detection task, all the posts after a detection deadline are invisible during test.",5.4 Early Detection Performance,[0],[0]
"The earlier the deadline, the less propagation information can be available.
",5.4 Early Detection Performance,[0],[0]
"Figure 4 shows the performances of our PTK and cPTK models versus RFC (the best system based on feature engineering), GRU (the best system based on RNN) and DTR (an early-detection-
specific algorithm) against various deadlines.",5.4 Early Detection Performance,[0],[0]
"In the first few hours, our approach demonstrates superior early detection performance than other models.",5.4 Early Detection Performance,[0],[0]
"Particularly, cPTK achieve 75% accuracy on Twitter15 and 73% on Twitter16 within 24 hours, that is much faster than other models.
",5.4 Early Detection Performance,[0],[0]
Our analysis shows that rumors typically demonstrate more complex propagation substructures especially at early stage.,5.4 Early Detection Performance,[0],[0]
"Figure 5 shows a detected subtree of a false rumor spread in its first few hours, where influential users are somehow captured to boost its propagation and the information flows among the users with an obvious unpopular-to-popular-to-unpopular trend in terms of user popularity, but such pattern was not witnessed in non-rumors in early stage.",5.4 Early Detection Performance,[0],[0]
Many textual signals (underlined) can also be observed in that early period.,5.4 Early Detection Performance,[0],[0]
"Our method can learn such structures and patterns naturally, but it is difficult to know and hand-craft them in feature engineering.",5.4 Early Detection Performance,[0],[0]
We propose a novel approach for detecting rumors in microblog posts based on kernel learning method using propagation trees.,6 Conclusion and Future Work,[0],[0]
"A propagation tree encodes the spread of a hypothesis (i.e., a source tweet) with complex structured patterns and flat information regarding content, user and time associated with the tree nodes.",6 Conclusion and Future Work,[0],[0]
"Enlightened by tree kernel techniques, our kernel method learns discriminant clues for identifying rumors of finer-grained levels by directly measuring the similarity among propagation trees via kernel functions.",6 Conclusion and Future Work,[0],[0]
"Experiments on two Twitter datasets show that our approach outperforms stateof-the-art baselines with large margin for both general and early rumor detection tasks.
",6 Conclusion and Future Work,[0],[0]
"Since kernel-based approach covers more structural information than feature-based methods, it allows kernel to further incorporate information from a high dimensional space for possibly better discrimination.",6 Conclusion and Future Work,[0],[0]
"In the future, we will focus on improving the rumor detection task by exploring network representation learning framework.",6 Conclusion and Future Work,[0],[0]
"Moreover, we plan to investigate unsupervised models considering massive unlabeled rumorous data from social media.",6 Conclusion and Future Work,[0],[0]
This work is partly supported by General Research Fund of Hong Kong (14232816).,Acknowledgment,[0],[0]
"We would like
to thank anonymous reviewers for the insightful comments.",Acknowledgment,[0],[0]
How fake news goes viral via social media?,abstractText,[0],[0]
How does its propagation pattern differ from real stories?,abstractText,[0],[0]
"In this paper, we attempt to address the problem of identifying rumors, i.e., fake information, out of microblog posts based on their propagation structure.",abstractText,[0],[0]
"We firstly model microblog posts diffusion with propagation trees, which provide valuable clues on how an original message is transmitted and developed over time.",abstractText,[0],[0]
"We then propose a kernel-based method called Propagation Tree Kernel, which captures high-order patterns differentiating different types of rumors by evaluating the similarities between their propagation tree structures.",abstractText,[0],[0]
Experimental results on two real-world datasets demonstrate that the proposed kernel-based approach can detect rumors more quickly and accurately than state-ofthe-art rumor detection models.,abstractText,[0],[0]
Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1142–1152, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
Foreign embassies of the United States government communicate with one another and with the U.S. State Department through diplomatic cables.,1 Introduction,[0],[0]
"The National Archive collects these cables in a corpus, which traces the (declassified) diplomatic history of the United States.1",1 Introduction,[0],[0]
"The corpus contains, for example, over two million cables sent between 1973 and 1978.
",1 Introduction,[0],[0]
"Most of these cables describe diplomatic “business as usual,” such as arrangements for visiting officials,
1 The National Archives’ corpus also includes messages sent by diplomatic pouch; however, for brevity, and at the risk of being imprecise, we also refer to these messages as “cables.”
recovery of lost or stolen passports, or obtaining lists of names for meetings and conferences.",1 Introduction,[0],[0]
"For example, the embassies sent 8,635 cables during the week of April 21, 1975.",1 Introduction,[0],[0]
"Here is one, selected at random:
Hoffman, UNESCO Secretariat, requested info from PermDel concerning an official invitation from the USG RE subject meeting scheduled 10–13 JUNE 1975, Madison, Wisconsin.",1 Introduction,[0],[0]
Would appreciate info RE status of action to be taken in order to inform Secretariat.,1 Introduction,[0],[0]
"Hoffman communicating with Dr. John P. Klus RE list of persons to be invited.
",1 Introduction,[0],[0]
"But, hidden in the corpus are also cables about important diplomatic events—the cables and events that are most interesting to historians, political scientists, and journalists.",1 Introduction,[0],[0]
"For example, during that same week, the U.S. was in the last moments of the Vietnam War and, on April 30, 1975, lost its hold on Saigon.",1 Introduction,[0],[0]
This marked the end of the war and induced a mass exodus of refugees.,1 Introduction,[0],[0]
"Here is one cable about this event:
GOA program to move Vietnamese Refugees to Australia is making little progress and probably will not cover more than 100-200 persons.",1 Introduction,[0],[0]
"Press comment on smallness of program has recognized difficulty of getting Vietnamese out of Saigon, but “Canberra Times” Apr 25 sharply critical of government’s performance.",1 Introduction,[0],[0]
"[...] Labor government clearly hopes whole matter will somehow disappear.
",1 Introduction,[0],[0]
"Our goal in this paper is to develop a tool to help historians, political scientists, and journalists wade
1142
through corpora of documents to find potentially significant events and the primary sources around them.",1 Introduction,[0],[0]
"We present Capsule, a probabilistic model for detecting and characterizing important events, such as the fall of Saigon, in large corpora of historical communication, such as diplomatic cables from the 1970s.
",1 Introduction,[0],[0]
Figure 1 illustrates Capsule’s analysis of two million cables from the National Archives’ corpus.,1 Introduction,[0],[0]
"The y-axis represents “eventness,” a loose measure of how strongly a week’s cables deviate from typical diplomatic “business as usual” to discuss some matter that is common to many embassies.",1 Introduction,[0],[0]
"(We describe this measure of “eventness” in detail in section 3.)
",1 Introduction,[0],[0]
"This figure shows that Capsule detects many wellknown events between 1973 and 1978, including the fall of Saigon (April 30, 1975) and the death of Mao Tse-tung (September 9, 1976).",1 Introduction,[0],[0]
"Capsule also uncovers obscure, but significant, events that have largely escaped the attention of scholars, such as when the U.S. defended its control of the Panama Canal before the United Nations Security Council (March 19, 1973).",1 Introduction,[0],[0]
"Capsule therefore provides a new way to detect and characterize historical moments that may be of interest to historians, political scientists, and journalists.
",1 Introduction,[0],[0]
"The intuition behind Capsule is this: Embassies write cables throughout the year, usually describing typical diplomatic business, such as visits from government officials.",1 Introduction,[0],[0]
"Sometimes, however, important events occur, such as the fall of Saigon, that pull embassies away from their typical activities and lead them to write cables that discuss these events and
their consequences.",1 Introduction,[0],[0]
"Capsule therefore operationalizes an “event” as a moment in history when multiple embassies deviate from their usual topics of discussion and each embassy deviates in a similar way.
",1 Introduction,[0],[0]
"Capsule embeds this intuition into a Bayesian model that uses latent variables to encode what “business as usual” means for each embassy, to characterize the events of each week, and to identify the cables that discuss those events.",1 Introduction,[0],[0]
"Given a corpus of cables, the corresponding posterior distribution of the latent variables provides a filter for the cables that isolates important moments in diplomatic history.",1 Introduction,[0],[0]
"Figure 1 depicts the mean of this posterior distribution.
",1 Introduction,[0],[0]
"We present the Capsule model in section 3, providing both a formal model specification and guidance on how to use the model to detect and characterize real-world events.",1 Introduction,[0],[0]
"In section 4, we validate Capsule using simulated data, and in section 5, we use it to analyze over two million U.S. State Department cables.",1 Introduction,[0],[0]
"Although we describe Capsule in the context of diplomatic cables, it is suitable for exploring any corpus with the same underlying structure: text (or other discrete multivariate data) generated over time by known entities.",1 Introduction,[0],[0]
"This includes email, consumer behavior, social media posts, and opinion articles.",1 Introduction,[0],[0]
"We first review previous work on automatic event detection and other related concepts, to contextualize our approach in general and Capsule in particular.
",2 Related Work,[0],[0]
"In both univariate and multivariate settings, ana-
lysts often want to predict whether or not rare events will occur (Weiss and Hirsh, 1998; Das et al., 2008).",2 Related Work,[0],[0]
"In contrast, Capsule is intended to help analysts explore and understand their data; our goal is human interpretability rather than prediction or forecasting.
",2 Related Work,[0],[0]
"Events can be construed as either anomalies— temporary deviations from usual behavior—or “changepoints” that mark persistent shifts in usual behavior (Guralnik and Srivastava, 1999; Adams and MacKay, 2007).",2 Related Work,[0],[0]
"We focus on events as anomalies.
",2 Related Work,[0],[0]
"Event detection in the context of news articles (Zhao et al., 2012; Zhao et al., 2007; Zhang et al., 2002; Li et al., 2005; Wang et al., 2007; Allan et al., 1998) and social media posts (Atefeh and Khreich, 2015; VanDam, 2012; Lau et al., 2012; Jackoway et al., 2011; Sakaki et al., 2010; Reuter and Cimiano, 2012; Becker et al., 2010; Sayyadi et al., 2009) usually means identifying clusters of documents.",2 Related Work,[0],[0]
"For news, the goal is to create new clusters as novel stories appear; each article is assumed to be associated with one event, which does not allow for distinctions between typical content and rare events.",2 Related Work,[0],[0]
"For social media, the goal is to identify rare events, but the resultant methods are intended for short documents, and are not appropriate for longer documents that may contain information about a variety of subjects.
",2 Related Work,[0],[0]
"Many existing methods for detecting events from text focus on individual vocabulary terms, often weighted by tf-idf values (Fung et al., 2005; Kumaran and Allan, 2004; Brants et al., 2003; Das Sarma et al., 2011; Zhao et al., 2007; Zhao et al., 2012).",2 Related Work,[0],[0]
"We characterize events by bursts in groups of terms.
",2 Related Work,[0],[0]
"Although groups of terms can be summarized directly (Peng et al., 2007; Chakrabarti and Punera, 2011; Gao et al., 2012), topic models (Blei, 2012) provide a way to automatically identify groups of related terms and reduce the dimensionality of text data.",2 Related Work,[0],[0]
"Researchers have previously used topic models to detect events mentioned in social media posts (Lau et al., 2012; Dou et al., 2012) and to find posts relevant to particular, monitored events (VanDam, 2012).",2 Related Work,[0],[0]
"Capsule uses topics to characterize both typical diplomatic content and potentially significant events.
",2 Related Work,[0],[0]
"In addition to modeling text over time, researchers have also used spatial information (Neill et al., 2005; Mathioudakis et al., 2010; Liu et al., 2011) and information about authors (Zhao et al., 2007) and news outlets (Wang et al., 2007) to enhance event detec-
tion.",2 Related Work,[0],[0]
"We rely on author information to characterize diplomatic “business as usual” for each embassy.
",2 Related Work,[0],[0]
"Event detection is closely related to detecting and characterizing relationships between entities (Schein et al., 2015; Linderman and Adams, 2014; Das Sarma et al., 2011).",2 Related Work,[0],[0]
"Capsule can trivially use sender– receiver pairs instead of authors, and the model specification can be tailored to reflect network structure.
",2 Related Work,[0],[0]
"Finally, there are connections between Capsule and recent work on Poisson processes.",2 Related Work,[0],[0]
"In particular, we can interpret Capsule as a collection of related discrete-time Poisson processes with random intensity measures.",2 Related Work,[0],[0]
"Further, marginalizing out the event strengths (described in section 3.1) reveals that the use of a vocabulary term by one embassy can “excite” the use of that term by another.",2 Related Work,[0],[0]
"This suggests a close relationship to Hawkes processes (Hawkes, 1971).",2 Related Work,[0],[0]
"In this section, we present the Capsule model for detecting and characterizing significant diplomatic events.",3 The Capsule Model,[0],[0]
"We first provide the intuition behind Capsule, and then formally specify the model.",3 The Capsule Model,[0],[0]
"We also explain how to use Capsule to explore a corpus and how to learn the posterior distribution of the latent variables.
",3 The Capsule Model,[0],[0]
"Consider an entity like the Bangkok embassy, as
illustrated in figure 2.",3 The Capsule Model,[0],[0]
"We can imagine that this entity sends a stream of diplomatic cables over time— some to the U.S. State Department, others to other American embassies, such as the one in Hong Kong.",3 The Capsule Model,[0],[0]
Embassies usually write cables that describe typical diplomatic business.,3 The Capsule Model,[0],[0]
"For example, the Bangkok embassy might write about topics regarding southeast Asia more generally.",3 The Capsule Model,[0],[0]
"We can think of a topic as being a probability distribution over vocabulary terms.
",3 The Capsule Model,[0],[0]
"Now imagine that an event, such as the capture of Saigon during the Vietnam War, occurs during a particular time interval t .",3 The Capsule Model,[0],[0]
"We cannot directly observe the occurrence of this event, but we can observe the stream of cables and the event’s impact on it.",3 The Capsule Model,[0],[0]
"When the event occurs, multiple entities deviate from their usual topics of discussion simultaneously, before returning to their usual behavior, as depicted in figure 2.",3 The Capsule Model,[0],[0]
"For example, the day after the capture of Saigon, the majority of the diplomatic cables written by the Bangkok embassy and several other entities were about Vietnam War refugees.",3 The Capsule Model,[0],[0]
"If we think of the event as another probability distribution over vocabulary terms, then each entity’s stream of cables reflects its typical concerns, as well as any significant events.",3 The Capsule Model,[0],[0]
We now define the Capsule model.,3.1 Model Specification,[0],[0]
"Our data come from entities (e.g., embassies) who send messages (e.g., diplomatic cables) over time; specifically, we observe the number of times ndv that each vocabulary term v occurs in each message d .",3.1 Model Specification,[0],[0]
"Each message is associated with an author entity ad and a time interval td within which that message was sent.
",3.1 Model Specification,[0],[0]
"We model each message with a bank of Poisson distributions2—one for each vocabulary term:
ndv Poisson .",3.1 Model Specification,[0],[0]
"dv/ : (1)
",3.1 Model Specification,[0],[0]
The rate dv blends the different influences on message content.,3.1 Model Specification,[0],[0]
"Specifically, it blends three types of topics, intended to capture “business-as-usual” discussion and content related to significant events.
",3.1 Model Specification,[0],[0]
"We operationalize each topic as a specialized probability distribution over vocabulary terms (the set of unique words in the corpus of messages), as is common in topic models (Blei et al., 2003; Canny, 2004;
2Readers familiar with topic modeling may expect a multinomial model of term occurrences, but Poisson models of counts better capture messages with different lengths (Canny, 2004).
",3.1 Model Specification,[0],[0]
"Gopalan et al., 2014)—i.e., each term is associated with each topic, but with a different probability.
",3.1 Model Specification,[0],[0]
Each message blends 1) general topics ˇ1; : : : ;ˇK,3.1 Model Specification,[0],[0]
"about diplomacy (e.g., terms about diplomats, terms about communication), 2) an entity topic ad specific to the author of that message (e.g., terms about Hong Kong),3 and 3) event topics 1; : : : ; T that are specific to the events in recent time intervals (e.g., terms about a coup, terms about the death of a dignitary).
",3.1 Model Specification,[0],[0]
Examples of these three types of topics are in table 1.,3.1 Model Specification,[0],[0]
"The general topic relates to planning travel, the entity topic captures words related to the U.S.S.R., and the event topic captures words related to the evacuation of Saigon toward the end of the Vietnam War.
",3.1 Model Specification,[0],[0]
"The messages share the three types of topics in different ways: all messages share the general topics, messages written by a single entity share an entity topic, and messages in the same time interval use the event topics in similar ways.",3.1 Model Specification,[0],[0]
Each message blends its corresponding topics with a set of message-specific strengths.,3.1 Model Specification,[0],[0]
"As a result, each message captures a different mix of general diplomacy discussion, entityspecific terms, and recent events.",3.1 Model Specification,[0],[0]
"Specifically, the Poisson rate for vocabulary term v in message d is
dv D KX kD1 dkˇkv C",3.1 Model Specification,[0],[0]
"d adv C
TX tD1 f .td",3.1 Model Specification,[0],[0]
"; t / dt tv; (2)
where dk is message d ’s strength for general topic k, d is message d ’s strength for ad ’s entity topic, and dt is message d ’s strength for event topic t .",3.1 Model Specification,[0],[0]
The function f . / ensures that the events influences decay over time.,3.1 Model Specification,[0],[0]
"As we describe in appendix B, we
3The entity-specific topics play a similar role to the background topics introduced by Paul and Dredze (2012).
",3.1 Model Specification,[0],[0]
"compared several different decay functions (exponential, linear, and step) and found that the following exponential decay function works well in practice:
f .td ; t / D
( 0 t td < t C
exp .td",3.1 Model Specification,[0],[0]
"t/ = 5
otherwise.
",3.1 Model Specification,[0],[0]
"(3)
Dividing by five means that we can interpret it as the number of time intervals after which an event will have little impact on the content of the messages.
",3.1 Model Specification,[0],[0]
"We place hierarchical gamma priors over the message-specific strengths, introducing entityspecific strengths 1; : : : ; A and 1; : : : ; A that allow different entities to focus on different topics and event strengths 1; : : : ; T that allow different time intervals to be more or less “eventful.”",3.1 Model Specification,[0],[0]
We place Dirichlet priors over the topics.,3.1 Model Specification,[0],[0]
"The graphical model is in figure 3 and the generative process is in figure 4.
",3.1 Model Specification,[0],[0]
"Given a corpus of messages, learning the posterior distribution of the latent variables uncovers the three types of topics, the message- and entity-specific strengths, and the event strengths.",3.1 Model Specification,[0],[0]
"In section 3.3, we explain how an analyst can use the event strengths as a filter that isolates potentially significant messages.",3.1 Model Specification,[0],[0]
"In order to use Capsule to to explore a corpus of messages, we must first learn the posterior distribution of
the latent variables—the general topics, the entity topics, the event topics, the message- and entity-specific strengths, and the event strengths—conditioned on the observed term counts.",3.2 Learning the Posterior Distribution,[0],[0]
"As for many Bayesian models, this posterior distribution is not tractable to compute; approximating it is therefore our central statistical and computational problem.",3.2 Learning the Posterior Distribution,[0],[0]
"We introduce an approximate inference algorithm for Capsule, based on variational methods (Jordan et al., 1999),4, which
4Source code: https://github.com/ajbc/capsule.
we outline in appendix A.5 This algorithm produces a fitted variational distribution which be can then be used as a proxy for the true posterior distribution.",3.2 Learning the Posterior Distribution,[0],[0]
We can use the mean of the fitted variational distribution to explore the data.,3.3 Detecting and Characterizing Events,[0],[0]
"Specifically, we can explore “business-as-usual” content using the posterior expected values of the general topics ˇ1; : : : ;ˇK and the entity topics 1; : : : ; A, and we can detect and characterize events using the posterior expected values of the event strengths and the event topics.
",3.3 Detecting and Characterizing Events,[0],[0]
"To detect events, we define an measure that quantifies the “eventness” of time interval t .",3.3 Detecting and Characterizing Events,[0],[0]
"Specifically, we first compute how relevant each message d is to that time interval: mdt D f .td ; t /EŒ dt .",3.3 Detecting and Characterizing Events,[0],[0]
"Using these relevancy values, we then compute the proportion of each message’s term counts that are associated with the event topic specific to time interval t :
",3.3 Detecting and Characterizing Events,[0],[0]
pdt D,3.3 Detecting and Characterizing Events,[0],[0]
mdtP k,3.3 Detecting and Characterizing Events,[0],[0]
"EŒ dk C EŒ d C P t 0 mdt 0 : (4)
",3.3 Detecting and Characterizing Events,[0],[0]
"Finally, we aggregate these values over messages:
1P d f .td ; t / DX dD1 pdt ; (5)
where the multiplicative fraction ensures that messages that were sent during time intervals that are further from t contribute less than than messages that were sent during time intervals that are closer to t .
",3.3 Detecting and Characterizing Events,[0],[0]
We can characterize an event t by selecting the highest-probability vocabulary terms from EŒ t .,3.3 Detecting and Characterizing Events,[0],[0]
"By ordering the messages according to mdt D f .td ; t /EŒ dt , we can also identify the messages that are most strongly associated with event t .
",3.3 Detecting and Characterizing Events,[0],[0]
"In section 5, we explore the cables associated with significant events in the National Archives’ corpus of diplomatic cables.",3.3 Detecting and Characterizing Events,[0],[0]
"To make Capsule more accessible for historians, political scientists, and journalists, we have released an open-source tool for visualizing its results.6",3.3 Detecting and Characterizing Events,[0],[0]
"This tool allows analysts to browse a corpus of messages and the mean of the corresponding posterior distribution, including general topics, entity topics, and event topics.",3.3 Detecting and Characterizing Events,[0],[0]
"Figure 5 contains several screenshots of the tool’s browsing interface.
",3.3 Detecting and Characterizing Events,[0],[0]
5Appendices are in the supplemental material.,3.3 Detecting and Characterizing Events,[0],[0]
"6Source code: https://github.com/ajbc/capsule-viz;
demo: http://www.princeton.edu/~achaney/capsule/.",3.3 Detecting and Characterizing Events,[0],[0]
"Before using Capsule to explore a corpus of real messages (described in section 5), we provide a quantitative validation of the model using simulated data.
",4 Model Validation with Simulated Data,[0],[0]
"We used the generative process in figure 4 to create ten data sets, each with 100 time intervals, ten general topics, ten entities, and roughly 20,000 messages.",4 Model Validation with Simulated Data,[0],[0]
We then used these data sets to compare Capsule’s event detection performance to that of four baseline methods.,4 Model Validation with Simulated Data,[0],[0]
We also compared the methods’ abilities to identify the most relevant messages for each event.,4 Model Validation with Simulated Data,[0],[0]
"For each data set, we ordered the time intervals from most to least eventful, using the “eventness” measure described in section 3.3 and the simulated values of the latent variables.",4.1 Detecting Events,[0],[0]
"We then treated these ranked lists of time intervals as “ground truth” and assessed how well each method was able to recover them.
",4.1 Detecting Events,[0],[0]
"For Capsule itself, we used our approximate inference algorithm to obtain a fitted variational distribution for each simulated data set.",4.1 Detecting Events,[0],[0]
"We then ordered the time intervals using our “eventness” measure and the posterior expected values of the latent variables.
",4.1 Detecting Events,[0],[0]
"For our first baseline, we constructed an “eventonly” version of Capsule by dropping the first and
second terms in equation (2).",4.1 Detecting Events,[0],[0]
We used this baseline to test whether modeling “business as usual” discussion makes it easier to detect significant events.,4.1 Detecting Events,[0],[0]
"We obtained a fitted variational distribution for this model using a variant of our approximate inference algorithm, and then ordered the time intervals using our “eventness” measure, modified appropriately, and the posterior expected values of the latent variables.
",4.1 Detecting Events,[0],[0]
"For our second baseline, we drew inspiration from previous work on event detection in the context of news articles, and focused on each time interval’s deviation in term counts from the average.",4.1 Detecting Events,[0],[0]
"Specifically, we ordered the time intervals 1; : : : ; T for each simulated data set according to this measure:
VX vD1 DX dD1",4.1 Detecting Events,[0],[0]
tdDt ˇ̌̌̌,4.1 Detecting Events,[0],[0]
ˇndv 1D DX dD1 ndv,4.1 Detecting Events,[0],[0]
"ˇ̌̌̌ ˇ : (6)
We added tf-idf term weights for our third baseline:
VX vD1 tf-idf .v/",4.1 Detecting Events,[0],[0]
DX dD1 tdDt ˇ̌̌̌,4.1 Detecting Events,[0],[0]
ˇndv 1D DX dD1 ndv,4.1 Detecting Events,[0],[0]
"ˇ̌̌̌ ˇ : (7)
Finally, we randomly ordered the time intervals for each data set to serve as a straw-man baseline.
",4.1 Detecting Events,[0],[0]
"We also experimented with baselines that involved term-count deviations on the entity level and topicusage deviations on the message level (Dou et al., 2012), but found that they were not competitive.
",4.1 Detecting Events,[0],[0]
"For each data set, we compared each method’s ranked list of time intervals to the corresponding “ground-truth” list of time intervals, by dividing the sum of the lists’ actual set overlap at each rank by the sum of their maximum set overlap at each rank:PT
rD1 jS truth r \ S method r jPT
rD1 r ; (8)
where S truthr is a set of the top r time intervals according to the “ground-truth” list and Smethodr is a set of the top r time intervals according to the method.
",4.1 Detecting Events,[0],[0]
Figure 6 shows that Capsule outperforms all four baseline methods.,4.1 Detecting Events,[0],[0]
These results serve as a sanity check for both the model and its implementation.,4.1 Detecting Events,[0],[0]
"For each data set, we created a list of the most relevant messages for each time interval t by computing
f .td ;",4.2 Identifying Relevant Messages,[0],[0]
t / dt for each message d,4.2 Identifying Relevant Messages,[0],[0]
(using the simulated values of dt ) and ordering the messages accordingly.,4.2 Identifying Relevant Messages,[0],[0]
"We then treated these ranked lists of messages as “ground truth” and assessed how well Capsule and the baseline methods were able to recover them.
",4.2 Identifying Relevant Messages,[0],[0]
"For Capsule, we used our approximate inference algorithm to obtain a fitted variational distribution for each data set, and then, for each time interval, ordered the messages according to mdt D f .td ; t /EŒ dt .",4.2 Identifying Relevant Messages,[0],[0]
"For our second and third baselines, we ordered the messages sent during each time interval according message-specific versions of equations (6) and (7).
",4.2 Identifying Relevant Messages,[0],[0]
"For each data set, we compared each method’s ranked list of messages for each time interval to the corresponding “ground-truth” list, by computing precision at ten messages.",4.2 Identifying Relevant Messages,[0],[0]
"The average precision for Capsule was was 0.44, while the average precision for the “event-only” version of the model was 0.09.",4.2 Identifying Relevant Messages,[0],[0]
The other baselines recovered zero relevant messages.,4.2 Identifying Relevant Messages,[0],[0]
Capsule is intended to help analysts explore and understand their data.,5 Exploratory Analysis,[0],[0]
"In this section, we demonstrate its capabilities by analyzing a corpus of over two million U.S. State Department cables from the 1970s.",5 Exploratory Analysis,[0],[0]
The National Archive collects diplomatic cables sent between the U.S. State Department and its foreign embassies.,5.1 Data,[0],[0]
"We obtained a subset of this corpus from the Central Foreign Policy Files at the National Archives, via the History Lab at Columbia Univer-
sity;7 the subset contains cables sent between 1973 and 1978.",5.1 Data,[0],[0]
"In addition to the text of the cables, each message is labeled with its author (e.g., the U.S. State Department, a particular embassy, or an individual), the date the cable was sent, and other metadata.",5.1 Data,[0],[0]
"We used a vocabulary of 6,293 terms and omitted cables with fewer than three terms, resulting in 2,021,852 cables sent by 22,961 entities.",5.1 Data,[0],[0]
"We used weekly time intervals, as few cables were sent on weekends.",5.1 Data,[0],[0]
We ran our approximate inference algorithm for Capsule to obtain a fitted variational distribution.,5.2 Model Settings,[0],[0]
"We used K D 100 general topics, the exponential decay function in equation (3) with D 4, and top-level hyperparameters s D r D 0:3.",5.2 Model Settings,[0],[0]
"With these settings, a single iteration of the algorithm took about an hour.8",5.2 Model Settings,[0],[0]
"To evaluate Capsule’s ability to detect well-known events, we used a list, provided to us by the History Lab, of thirty-nine well-known events that took place between 1973 and 1978.",5.3 Detecting Well-Known Events,[0],[0]
"Each event is present in at least one of six reputable collections of historic events, such as the Office of the Historian’s Milestones in the History of U.S. Foreign Relations.9 We treated this list of events as “ground truth” and assessed how well Capsule and each of the baselines described in section 4.1 were able to recover them—or, in other words, how well the methods identify these eventful weeks, compared to more typical weeks.
",5.3 Detecting Well-Known Events,[0],[0]
"Specifically, we used each method to construct a ranked list of time intervals.",5.3 Detecting Well-Known Events,[0],[0]
"Then, for each method, we computed the discounted cumulative gain (DCG), which, in this context, is equivalent to computing
39X eD1
1
log rank e; LmethodT ; (9) where LmethodT is the method’s ranked list of time intervals and rank
e; LmethodT is the rank of the eth
well-known event in LmethodT .",5.3 Detecting Well-Known Events,[0],[0]
"Finally, we divided the DCG by the ideal DCG—i.e., P39 eD1 1 log .e/—to
7http://history-lab.org 8Each iteration of our algorithm considers all messages.",5.3 Detecting Well-Known Events,[0],[0]
"Modifying it to stochastically sample the data would reduce the time required to obtain an equivalent fitted variational distribution.
",5.3 Detecting Well-Known Events,[0],[0]
"9https://history.state.gov/milestones/1969-1976
obtain the normalized DCG (nDCG).",5.3 Detecting Well-Known Events,[0],[0]
Table 2 shows that Capsule outperforms all four baseline methods.,5.3 Detecting Well-Known Events,[0],[0]
We now turn to our primary goal—using Capsule to explore and understand a corpus of messages.,5.4 Exploration,[0],[0]
Figure 1 shows our “eventness” measure (equation (5)) over time.,5.4 Exploration,[0],[0]
"One of the tallest peaks occurs during the week of December 1, 1975, when the United Nations General Assembly discussed omnibus decolonization.",5.4 Exploration,[0],[0]
"As described in section 3.3, we can characterize this event by computing mdt D f .td ;",5.4 Exploration,[0],[0]
t /EŒ dt for each message d and then ordering the messages accordingly.,5.4 Exploration,[0],[0]
"Table 3 lists the highest-ranked messages.
",5.4 Exploration,[0],[0]
"Another notable event was the seizure of the S.S. Mayaguez, an American merchant vessel, during May, 1975, at the end of the Vietnam War.",5.4 Exploration,[0],[0]
Table 4 lists the highest-ranked messages for this event.,5.4 Exploration,[0],[0]
We can examine these messages to confirm their relevancy and learn more about the event.,5.4 Exploration,[0],[0]
"For example, here is the content of the most relevant message:
",5.4 Exploration,[0],[0]
"In absence of MFA Chief of Eighth Department Avramov, I informed American desk officer Yankov of circumstances surrounding seizure and recovery of merchant ship Mayaguez and its crew.",5.4 Exploration,[0],[0]
Yankov promised to inform the Foreign Minister of US statement today (May 15).,5.4 Exploration,[0],[0]
"Batjer
A third week of interest occurs in early July, 1976.",5.4 Exploration,[0],[0]
"On July 4, the U.S. celebrated its Bicentennial, but on the same day, Israeli forces completed a hostage rescue mission because an Air France flight from Tel Aviv had been hijacked and taken to Entebbe, Uganda.10 This event was mostly discussed the week
10Capsule assumes that only one event occurs during each
after the event took place; the most relevant messages are listed in appendix B (table 5).",5.4 Exploration,[0],[0]
"The cable from Stockholm describing the “Ugandan role in Air France hijacking” begins with the following content, which reveals further information about this event:
1.",5.4 Exploration,[0],[0]
We provided MFA Director of Political Affairs Leifland with Evidence of Ugandan assistance to hijackers contained in Ref A.,5.4 Exploration,[0],[0]
"After reading material, Leifland described it a “quite good”, and said it would be helpful for meeting MFA has scheduled for early this morning to determine position GOS will take at July 8 UNSC consideration of Israeli Rescue Operation.",5.4 Exploration,[0],[0]
"...
",5.4 Exploration,[0],[0]
"In addition to detecting and characterizing wellknown events, such the S.S. Mayaguez incident and Operation Entebbe, Capsule can detect and characterize obscure, but significant, events, such as when Eritrean rebels kidnapped Tenneco oil employees (April 8, 1974) and when the U.S. Navy evacuated citizens from Lebanon (“Operation Fluid Drive,” June 20, 1976).",5.4 Exploration,[0],[0]
Both events appear in figure 1.,5.4 Exploration,[0],[0]
"Capsule uncovers events where analysts might not otherwise look.
",5.4 Exploration,[0],[0]
"Capsule also provides a way to explore “business-
time interval.",5.4 Exploration,[0],[0]
"This example is a clear violation of this assumption, but also serves to demonstrate that Capsule can successfully detect and characterize multiple events, even when they overlap.
",5.4 Exploration,[0],[0]
as-usual” discussion using the posterior expected values of the general topics ˇ1; : : : ;ˇK and the entity topics 1; : : : ;,5.4 Exploration,[0],[0]
"A. Examples of each of these types of topics are in appendix B (tables 6 and 7, respectively); these examples illustrate that, as desired, the entity topics absorb location-specific terms, preventing them from overwhelming the general topics.",5.4 Exploration,[0],[0]
"We presented Capsule, a Bayesian model for detecting and characterizing potentially significant events.",6 Conclusion,[0],[0]
We evaluated Capsule’s ability to detect events and identify relevant messages; it outperformed four baseline methods.,6 Conclusion,[0],[0]
"We used Capsule to analyze a large corpus of U.S. State Department cables from the 1970s, demonstrating that it can discover both well-known and obscure (but significant) events, as well as relevant documents.",6 Conclusion,[0],[0]
"We anticipate that Capsule, and our visualization tool, will be useful for historians, political scientists, and journalists who wish to explore and understand large corpora of documents.",6 Conclusion,[0],[0]
This is increasingly important—the U.S. State Department alone produces around two billion e-mails annually.,6 Conclusion,[0],[0]
This work was supported by NSF IIS-1247664; ONR N00014-11-1-0651; DARPA FA8750-14-2-0009 and N66001-15-C-4032; Adobe; the Alfred P. Sloan Foundation; the Columbia Global Policy Initiative.,Acknowledgments,[0],[0]
"Significant events are characterized by interactions between entities (such as countries, organizations, or individuals) that deviate from typical interaction patterns.",abstractText,[0],[0]
"Analysts, including historians, political scientists, and journalists, commonly read large quantities of text to construct an accurate picture of when and where an event happened, who was involved, and in what ways.",abstractText,[0],[0]
"In this paper, we present the Capsule model for analyzing documents to detect and characterize events of potential significance.",abstractText,[0],[0]
"Specifically, we develop a model based on topic modeling that distinguishes between topics that describe “business as usual” and topics that deviate from these patterns.",abstractText,[0],[0]
"To demonstrate this model, we analyze a corpus of over two million U.S. State Department cables from the 1970s.",abstractText,[0],[0]
We provide an open-source implementation of an inference algorithm for the model and a pipeline for exploring its results.,abstractText,[0],[0]
Detecting and Characterizing Events,title,[0],[0]
"ar X
iv :1
71 1.
05 78
0v 2
[ cs
.C L
] 1
6 A
pr 2
01 8
Virtual agents are becoming a prominent channel of interaction in customer service. Not all customer interactions are smooth, however, and some can become almost comically bad. In such instances, a human agent might need to step in and salvage the conversation. Detecting bad conversations is important since disappointing customer service may threaten customer loyalty and impact revenue. In this paper, we outline an approach to detecting such egregious conversations, using behavioral cues from the user, patterns in agent responses, and useragent interaction. Using logs of two commercial systems, we show that using these features improves the detection F1-score by around 20% over using textual features alone. In addition, we show that those features are common across two quite different domains and, arguably, universal.",text,[0],[0]
Automated conversational agents (chatbots) are becoming widely used for various tasks such as personal assistants or as customer service agents.,1 Introduction,[0],[0]
"Recent studies project that 80% of businesses plan to use chatbots by 20201, and that chatbots will power 85% of customer service interactions by the year 20202.",1 Introduction,[0],[0]
"This increasing usage is mainly due to advances in artificial intelligence and natural language processing (Hirschberg and Manning, 2015)
1http://read.bi/2gU0szG 2http://gtnr.it/2z428RS
along with increasingly capable chat development environments, leading to improvements in conversational richness and robustness.
",1 Introduction,[0],[0]
"Still, chatbots may behave extremely badly, leading to conversations so off-the-mark that only a human agent could step in and salvage them.",1 Introduction,[0],[0]
"Consequences of these failures may include loss of customer goodwill and associated revenue, and even exposure to litigation if the failures can be shown to include fraudulent claims.",1 Introduction,[0],[0]
"Due to the increasing prevalence of chatbots, even a small fraction of such egregious3 conversations could be problematic for the companies deploying chatbots and the providers of chatbot services.
",1 Introduction,[0],[0]
In this paper we study detecting these egregious conversations that can arise in numerous ways.,1 Introduction,[0],[0]
"For example, incomplete or internally inconsistent training data can lead to false classification of user intent.",1 Introduction,[0],[0]
Bugs in dialog descriptions can lead to dead ends.,1 Introduction,[0],[0]
Failure to maintain adequate context can cause chatbots to miss anaphoric references.,1 Introduction,[0],[0]
"In the extreme case, malicious actors may provide heavily biased (e.g., the Tay chatbot4) or even hacked misbehaviors.
",1 Introduction,[0],[0]
"In this article, we focus on customer care systems.",1 Introduction,[0],[0]
"In such setting, a conversation usually becomes egregious due to a combination of the aforementioned problems.",1 Introduction,[0],[0]
"The resulting customer frustration may not surface in easily detectable ways such as the appearance of all caps, shouting to a speech recognizer, or the use of profanity or extreme punctuation.",1 Introduction,[0],[0]
"Consequently, the chatbot will continue as if the conversation is proceeding well, usually
3Defined by the dictionary as outstandingly bad.",1 Introduction,[0],[0]
"4http://bit.ly/2fwYaa5
leading to conversational breakdown.
",1 Introduction,[0],[0]
"Consider, for example, the anonymized but representative conversation depicted in Figure 1.",1 Introduction,[0],[0]
Here the customer aims to understand the details of a flight ticket.,1 Introduction,[0],[0]
"In the first two turns, the chatbot misses the customer’s intentions, which leads to the customer asking “Are you a real person?”.",1 Introduction,[0],[0]
"The customer then tries to explain what went wrong, but the chatbot has insufficient exposure to this sort of utterance to provide anything but the default response (“I’m not trained on that”).",1 Introduction,[0],[0]
"The response seems to upset the customer and leads to a request for a human agent, which is rejected by the system (“We don’t currently have live agents”).",1 Introduction,[0],[0]
"Such rejection along with the previous responses could lead to customer frustration (Amsel, 1992).
Being able to automatically detect such conversations, either in real time or through log analysis, could help to improve chatbot quality.",1 Introduction,[0],[0]
"If detected in real time, a human agent can be pulled in to salvage the conversation.",1 Introduction,[0],[0]
"As an aid to chatbot improvement, analysis of egregious conversations can often point to problems in training data or system logic that can be repaired.",1 Introduction,[0],[0]
"While it is possible to scan system logs by eye, the sheer volume of conversations may overwhelm the analyst or lead to random sampling that misses important failures.",1 Introduction,[0],[0]
"If, though, we can automatically detect the worst conversations (in our experience, typically under 10% of the total),
the focus can be on fixing the worst problems.
",1 Introduction,[0],[0]
Our goal in this paper is to study conversational features that lead to egregious conversations.,1 Introduction,[0],[0]
"Specifically, we consider customer inputs throughout a whole conversation, and detect cues such as rephrasing, the presence of heightened emotions, and queries about whether the chatbot is a human or requests to speak to an actual human.",1 Introduction,[0],[0]
"In addition, we analyze the chatbot responses, looking for repetitions (e.g. from loops that might be due to flow problems), and the presence of ”not trained” responses.",1 Introduction,[0],[0]
"Finally, we analyze the larger conversational context exploring, for example, where the presence of a ”not trained” response might be especially problematic (e.g., in the presence of strong customer emotion).
",1 Introduction,[0],[0]
"The main contributions of this paper are twofold: (1) This is the first research focusing on detecting egregious conversations in conversational agent (chatbot) setting and (2) this is the first research using unique agent, customer, and customer-agent interaction features to detect egregiousness.
",1 Introduction,[0],[0]
The rest of this paper is organized as follows.,1 Introduction,[0],[0]
"We review related work, then we formally define the methodology for detecting egregious conversations.",1 Introduction,[0],[0]
"We describe our data, experimental setting, and results.",1 Introduction,[0],[0]
We then conclude and suggest future directions.,1 Introduction,[0],[0]
"Detecting egregious conversations is a new task, however, there is related work that aim at measuring the general quality of the interactions in conversational systems.",2 Related Work,[0],[0]
These works studied the complementary problem of detecting and measuring user satisfaction and engagement.,2 Related Work,[0],[0]
"Early work by (Walker et al., 1997, 2001) discussed a framework that maximizes the user satisfaction by considering measures such as number of inappropriate utterances, recognition rates, number of times user requests repetitions, number of turns per interaction, etc.",2 Related Work,[0],[0]
"Shortcomings of this approach are discussed by (Hajdinjak and Mihelic, 2006).",2 Related Work,[0],[0]
Other works focus on predicting the user engagement in such systems.,2 Related Work,[0],[0]
"Examples include (Kiseleva et al., 2016b,a; Jiang et al.,
2015).",2 Related Work,[0],[0]
"Specifically, these works evaluated chat functionality by asking users to make conversations with an intelligent agent and measured the user satisfaction along with other features such as the automatic speech recognition (ASR) quality and intent classification quality.",2 Related Work,[0],[0]
"In (Sandbank et al., 2017)",2 Related Work,[0],[0]
"the authors presented a conversational system enhanced with emotion analysis, and suggested using emotions as triggers for human escalation.",2 Related Work,[0],[0]
"In our work, we likewise use emotion analysis as predictive features for egregious conversation.",2 Related Work,[0],[0]
"The works of (Sarikaya, 2017; Sano et al., 2017) studied reasons why users reformulated utterances in such systems.",2 Related Work,[0],[0]
"Specifically, in (Sarikaya, 2017)",2 Related Work,[0],[0]
they reported on how the different reasons affect the users’ satisfaction.,2 Related Work,[0],[0]
"In (Sano et al., 2017)",2 Related Work,[0],[0]
they focused on how to automatically predict the reason for user’s dissatisfaction using different features.,2 Related Work,[0],[0]
Our work also explores user reformulation (or rephrasing) as one of the features to predict egregious conversations.,2 Related Work,[0],[0]
We build on the previous work by leveraging some of the approaches in our classifier for egregious conversations.,2 Related Work,[0],[0]
"In (Walker et al., 2000; Hastie et al., 2002) the authors also looked for problems in a specific setting of spoken conversations.",2 Related Work,[0],[0]
"The main difference with our work is that we focus on chat logs for domains for which the expected user utterances are a bit more diverse, using interaction features as well as features that are not sensitive to any architectural aspects of the conversational system (e.g., ASR component).",2 Related Work,[0],[0]
Several other approaches for evaluating chatbot conversations indirectly capture the notion of conversational quality.,2 Related Work,[0],[0]
"For example, several prior works borrowed from the field of pragmatics in various metrics around the principles of cooperative conversation (Chakrabarti and Luger, 2013; Saygin A. P., 2002).",2 Related Work,[0],[0]
"In (Steidl et al., 2004)",2 Related Work,[0],[0]
they measured dialogue success at the turn level as a way of predicting the success of a conversation as a whole.,2 Related Work,[0],[0]
"(Webb et al., 2010) created a measure of dialogue appropriateness to determine its role in maintaining a conversation.",2 Related Work,[0],[0]
"Recently, (Liu et al., 2016) evaluated a number of popular measures for dialogue response generation systems and high-
lighted specific weaknesses in the measures.",2 Related Work,[0],[0]
"Similarly, in (Sebastian et al., 2009) they developed a taxonomy of available measures for an end-user’s quality of experience for multimodel dialogue systems, some of which touch on conversational quality.",2 Related Work,[0],[0]
"All these measures may serve as reasons for a conversation turning egregious, but none try to capture or predict it directly.
",2 Related Work,[0],[0]
"In the domain of customer service, researchers mainly studied reasons for failure of such systems along with suggestions for improved design (Mimoun et al., 2012; Gnewuch et al., 2017).",2 Related Work,[0],[0]
"In (Mimoun et al., 2012)",2 Related Work,[0],[0]
the authors analyzed reasons sales chatbots fail by interviewing chatbots experts.,2 Related Work,[0],[0]
"They found that a combination of exaggerated customer expectations along with a reduction in agent performance (e.g., failure to listen to the consumer, being too intrusive) caused customers to stop using such systems.",2 Related Work,[0],[0]
"Based on this qualitative study, they proposed an improved model for sales chatbots.",2 Related Work,[0],[0]
"In (Gnewuch et al., 2017)",2 Related Work,[0],[0]
"they studied service quality dimensions (i.e., reliability, empathy, responsiveness, and tangibility) and how to apply them during agent design.",2 Related Work,[0],[0]
The main difference between those works and ours is that they focus on qualitative high-level analysis while we focus on automatic detection based on the conversations logs.,2 Related Work,[0],[0]
The objective of this work is to reliably detect egregious conversations between a human and a virtual agent.,3 Methodology,[0],[0]
"We treat this as a binary classification task, where the target classes are “egregious” and “non-egregious”.",3 Methodology,[0],[0]
"While we are currently applying this to complete conversations (i.e., the classification is done on the whole conversation), some of the features examined here could likely be used to detect egregious conversations as they were unfolding in real time.",3 Methodology,[0],[0]
"To perform egregious conversation detection, features from both customer inputs and agent responses are extracted, together with features related to the combination of specific inputs and responses.",3 Methodology,[0],[0]
"In addition, some of these features are contextual, meaning that they are dependent on where in the conversation they appear.
",3 Methodology,[0],[0]
"Using this set of features for detecting egregious conversations is novel, and as our experimental results show, improves performance compared to a model based solely on features extracted from the conversation’s text.",3 Methodology,[0],[0]
"We now describe the agent, customer, and combined customer-agent features.",3 Methodology,[0],[0]
"A virtual agent is generally expected to closely simulate interactions with a human operator (Reeves and Nass, 1996; Nass and Moon,Y, 2000; Krämer, 2008).",3.1 Agent Response Features,[0],[0]
"When the agent starts losing the context of a conversation, fails in understanding the customer intention, or keeps repeating the same responses, the illusion of conversing with a human is lost and the conversation may become extremely annoying.",3.1 Agent Response Features,[0],[0]
"With this in mind, we now describe the analysis of the agent’s responses and associated features (summarized in the top part of Table 1).",3.1 Agent Response Features,[0],[0]
"As typically implemented, the virtual agent’s task is to reliably detect the intent of each customer’s utterance and respond meaningfully.",3.1.1 Repeating Response Analysis,[0],[0]
"Accurate intent detection is thus a fundamental characteristic of well-trained virtual agents, and incorrect intent analysis is reported as the leading cause of user dissatisfaction (Sarikaya, 2017).",3.1.1 Repeating Response Analysis,[0],[0]
"Moreover, since a classifier (e.g., SVM, neural network, etc.) is often used to detect intents, its probabilistic behavior can cause the agent to repeat the same (or semantically similar) response over and over again, despite the user’s attempt to rephrase the same intent.
",3.1.1 Repeating Response Analysis,[0],[0]
"Such agent repetitions lead to an unnatural interaction (Klüwer, 2011).",3.1.1 Repeating Response Analysis,[0],[0]
"To identify the agent’s repeating responses, we measured similarity between agent’s subsequent (not necessarily sequential) turns.",3.1.1 Repeating Response Analysis,[0],[0]
"We represented each sentence by averaging the pre-trained embeddings5 of each word in the sentence, calculating the cosine similarity between the representations.",3.1.1 Repeating Response Analysis,[0],[0]
"Turns with a high similarity value6 are considered as repeating responses.
",3.1.1 Repeating Response Analysis,[0],[0]
"5https://code.google.com/archive/p/word2vec 6Empirically, similarity values ≥ 0.8",3.1.1 Repeating Response Analysis,[0],[0]
"Given that the knowledge of a virtual agent is necessarily limited, we can expect that training would not cover all customer intents.",3.1.2 Unsupported Intent Analysis,[0],[0]
"If the classifier technology provides an estimate of classification confidence, the agent can respond with some variant of “I’m not trained on that” when confidence is low.",3.1.2 Unsupported Intent Analysis,[0],[0]
"In some cases, customers will accept that not all requests are supported.",3.1.2 Unsupported Intent Analysis,[0],[0]
"In other cases, unsupported intents can lead to customer dissatisfaction (Sarikaya, 2017), and cascade to an egregious conversation (as discussed below in Section 3.3).",3.1.2 Unsupported Intent Analysis,[0],[0]
"We extracted the possible variants of the unsupported intent messages directly from the system, and later matched them with the agent responses from the logs.",3.1.2 Unsupported Intent Analysis,[0],[0]
"From the customer’s point of view, an ineffective interaction with a virtual agent is clearly undesirable.",3.2 Customer Inputs Features,[0],[0]
"An ineffective interaction requires the expenditure of relatively large effort from the customer with little return on the investment (Zeithaml et al., 1990; Mimoun et al., 2012).",3.2 Customer Inputs Features,[0],[0]
"These efforts can appear as behavioral cues in the customer’s inputs, and include emotions, repetitions, and more.",3.2 Customer Inputs Features,[0],[0]
We used the following customer analysis in our model.,3.2 Customer Inputs Features,[0],[0]
Customer features are summarized in the middle part of Table 1.,3.2 Customer Inputs Features,[0],[0]
"When a customer repeats or rephrases an utterance, it usually indicates a problem with the agent’s understanding of the customer’s intent.",3.2.1 Rephrasing Analysis,[0],[0]
"This can be caused by different reasons as described in (Sano et al., 2017).",3.2.1 Rephrasing Analysis,[0],[0]
"To measure the similarity between subsequent customer turns to detect repetition or rephrasing, we used the same approach as described in Section 3.1.1.",3.2.1 Rephrasing Analysis,[0],[0]
Turns with a high similarity value6 are considered as rephrases.,3.2.1 Rephrasing Analysis,[0],[0]
"The customer’s emotional state during the conversation is known to correlate with the conversation’s quality (Oliver, 2014).",3.2.2 Emotional Analysis,[0],[0]
"In order to analyze the emotions that customers exhibit in each turn, we utilized the IBM Tone Analyzer service, available publicly online7.
",3.2.2 Emotional Analysis,[0],[0]
"7https://ibm.co/2hnYkCv
This service was trained using customer care interactions, and infers emotions such as frustration, sadness, happiness.",3.2.2 Emotional Analysis,[0],[0]
"We focused on negative emotions (denoted as NEG EMO) to identify turns with a negative emotional peak (i.e., single utterances that carried high negative emotional state), as well as to estimate the aggregated negative emotion throughout the conversation (i.e., the averaged negative emotion intensity).",3.2.2 Emotional Analysis,[0],[0]
"In order to get a more robust representation of the customer’s negative emotional state, we summed the score of the negative emotions (such as frustration, sadness, anger, etc.) into a single negative sentiment score (denoted as NEG SENT).",3.2.2 Emotional Analysis,[0],[0]
"Note that we used the positive emotions as a filter for other customer features, such as the rephrasing analysis.",3.2.2 Emotional Analysis,[0],[0]
"Usually, high positive emotions capture different styles of “thanking the agent”, or indicate that the customer is somewhat satisfied (Rychalski and Hudson, 2017), thus, the conversation is less likely to become egregious.",3.2.2 Emotional Analysis,[0],[0]
"In examining the conversation logs, we noticed that it is not unusual to find a customer asking to be transferred to a human agent.",3.2.3 Asking for a Human Agent,[0],[0]
Such a request might indicate that the virtual agent is not providing a satisfactory service.,3.2.3 Asking for a Human Agent,[0],[0]
"Moreover, even if there are human agents, they might not be available at all times, and thus, a rejection of such a request is sometimes reasonable, but might still lead to customer frustration (Amsel, 1992).",3.2.3 Asking for a Human Agent,[0],[0]
"In addition to the above analyses, we also detected customer turns that contain exactly one word.",3.2.4 Unigram Input,[0],[0]
"The assumption is that single word (unigram) sentences are probably short customer responses (e.g., no, yes, thanks, okay), which in most cases do not contribute to the egregiousness of the conversation.",3.2.4 Unigram Input,[0],[0]
"Hence, calculating the percentage of those turns out of the whole conversation gives us another measurable feature.",3.2.4 Unigram Input,[0],[0]
"We also looked at features across conversation utterance-response pairs in order to capture a more complete picture of the interac-
tion between the customer and the virtual agent.",3.3 Customer-Agent Interaction Features,[0],[0]
"Here, we considered a pair to be customer utterance followed by an agent response.",3.3 Customer-Agent Interaction Features,[0],[0]
"For example, a pair may contain a turn in which the customer expressed negative emotions and received a response of “not trained” by the agent.",3.3 Customer-Agent Interaction Features,[0],[0]
"In this case, we would leverage the two analyses: emotional and unsupported intent.",3.3 Customer-Agent Interaction Features,[0],[0]
Figure 1 gives an example of this in the customer’s penultimate turn.,3.3 Customer-Agent Interaction Features,[0],[0]
Such interactions may divert the conversation towards becoming egregious.,3.3 Customer-Agent Interaction Features,[0],[0]
These features are summarized in the last part of Table 1.,3.3 Customer-Agent Interaction Features,[0],[0]
We also calculated the similarity between the customer’s turn and the virtual agent’s response in cases of customer rephrasing.,3.3.1 Similarity Analysis,[0],[0]
This analysis aims to capture the reason for the customer rephrasing.,3.3.1 Similarity Analysis,[0],[0]
"When a similarity score between the customer’s turn and the agent’s response is low, this may indicate a misclassified intent, as the agent’s responses are likely to share some textual similarity to the customer’s utterance.",3.3.1 Similarity Analysis,[0],[0]
"Thus, a low score may indicate a poor interaction, which might lead the conversation to become egregious.",3.3.1 Similarity Analysis,[0],[0]
Another similarity feature is between two customer’s subsequent turns when the agent’s response was “not trained”.,3.3.1 Similarity Analysis,[0],[0]
We trained a binary SVM classifier with a linear kernel.,3.4 Conversation Egregiousness Prediction Classifier,[0],[0]
"A feature vector for a sample in the training data is generated using the scores calculated for the described features, where each feature value is a number between [0,1].",3.4 Conversation Egregiousness Prediction Classifier,[0],[0]
"After the model was trained, test conversations are classified by the model, after being transformed to a feature vector in the same way a training sample is transformed.",3.4 Conversation Egregiousness Prediction Classifier,[0],[0]
The SVM classification model (denoted EGR) outputs a label “egregious” or “non-egregious” as a prediction for the conversation.,3.4 Conversation Egregiousness Prediction Classifier,[0],[0]
We extracted data from two commercial systems that provide customer support via conversational bots (hereafter denoted as company A and company B).,4.1 Dataset,[0],[0]
"Both agents are using similar underlying conversation engines, each embedded in a larger system with its own unique business logic.",4.1 Dataset,[0],[0]
"Company A’s system deals with sales support during an online purchase, while company B’s system deals with technical support for purchased software products.",4.1 Dataset,[0],[0]
"Each system logs conversations, and each conversation is a sequence of tuples, where each tuple consists of {conversation id, turn id, customer input, agent response}.",4.1 Dataset,[0],[0]
"From each system, we randomly extracted 10000 conversations.",4.1 Dataset,[0],[0]
"We further removed conversations that contained fewer than 2 turns, as these are too short to be meaningful since the customer never replied or provided more details about the issue at hand.",4.1 Dataset,[0],[0]
Figure 2 depicts the frequencies of conversation lengths which follow a power-law relationship.,4.1 Dataset,[0],[0]
"The conversations from company A’s system tend to be longer, with an average of 8.4 turns vs. an average of 4.4 turns for company B.",4.1 Dataset,[0],[0]
The first step in building a classification model is to obtain ground truth data.,4.2 Experimental Setup,[0],[0]
"For this purpose, we randomly sampled conversations from our datasets.",4.2 Experimental Setup,[0],[0]
This sample included 1100 and 200 conversations for company A and company B respectively.,4.2 Experimental Setup,[0],[0]
"The
sampled conversations were tagged using an in-house tagging system designed to increase the consistency of human judgements.",4.2 Experimental Setup,[0],[0]
Each conversation was tagged by four different expert judges8.,4.2 Experimental Setup,[0],[0]
"Given the full conversation, each judge tagged whether the conversation was egregious or not following this guideline: “Conversations which are extraordinarily bad in some way, those conversations where you’d like to see a human jump in and save the conversation”.
",4.2 Experimental Setup,[0],[0]
We generated true binary labels by considering a conversation to be egregious if at least three of the four judges agreed.,4.2 Experimental Setup,[0],[0]
"The interrater reliability between all judges, measured by Cohen’s Kappa, was 0.72 which indicates high level agreement.",4.2 Experimental Setup,[0],[0]
"This process generated the egregious class sizes of 95 (8.6%) and 16 (8%) for company A and company B, respectively.",4.2 Experimental Setup,[0],[0]
"This verifies the unbalanced data expectation as previously discussed.
",4.2 Experimental Setup,[0],[0]
"We also implemented two baseline models, rule-based and text-based, as follows:
Rule-based.",4.2 Experimental Setup,[0],[0]
"In this approach, we look for cases in which the virtual agent responded with a “not trained” reply, or occurrences of the customer requesting to talk to a human agent.",4.2 Experimental Setup,[0],[0]
"As discussed earlier, these may be indicative of the customer’s dissatisfaction with the nature of the virtual agent’s responses.
",4.2 Experimental Setup,[0],[0]
Text-based.,4.2 Experimental Setup,[0],[0]
"A model that was trained to predict egregiousness given the conversation’s text (all customer and agent’s text dur-
8judges that are HCI experts and have experience in designing conversational agents systems.
",4.2 Experimental Setup,[0],[0]
ing the conversation).,4.2 Experimental Setup,[0],[0]
"This model was implemented using state-of-the-art textual features as in (Herzig et al., 2017).",4.2 Experimental Setup,[0],[0]
"In (Herzig et al., 2017) emotions are detected from text, which can be thought of as similar to our task of predicting egregious conversations.
",4.2 Experimental Setup,[0],[0]
We evaluated these baseline methods against our classifier using 10-fold crossvalidation over company A’s dataset (we did not use company B’s data for training due to the low number of tagged conversations).,4.2 Experimental Setup,[0],[0]
"Since class distribution is unbalanced, we evaluated classification performance by using precision (P), recall (R) and F1-score (F) for each class.",4.2 Experimental Setup,[0],[0]
The EGR classifier was implemented using an SVM with a linear kernel9.,4.2 Experimental Setup,[0],[0]
Table 2 depicts the classification results for both classes and the three models we explored.,4.3 Classification Results,[0],[0]
The EGR model significantly outperformed both baselines10.,4.3 Classification Results,[0],[0]
"Specifically, for the egregious class, the precision obtained by the text-based and EGR models were similar.",4.3 Classification Results,[0],[0]
This indicates that the text analyzed by both models encodes some information about egregiousness.,4.3 Classification Results,[0],[0]
"On the other hand, for the recall and hence the F1-score, the EGR model relatively improved the text-based model by 41% and 18%, respectively.",4.3 Classification Results,[0],[0]
We will further analyze the models below.,4.3 Classification Results,[0],[0]
"To better understand the contributions of different sets of features to our EGR model, we examined various features in an incremental fashion.",4.4 Feature Set Contribution Analysis,[0],[0]
"Based on the groups of feature sets that we defined in Section 3, we tested the performance of different group combinations, added in the following order: agent, customer and customer-agent interactions.
",4.4 Feature Set Contribution Analysis,[0],[0]
"9http://scikit-learn.org/stable/modules/svm.html 10EGR with p < 0.001, using McNemar’s test.
",4.4 Feature Set Contribution Analysis,[0],[0]
Figure 3 depicts the results for the classification task.,4.4 Feature Set Contribution Analysis,[0],[0]
"The x-axis represents specific combinations of groups, and the y-axis represents the performance obtained.",4.4 Feature Set Contribution Analysis,[0],[0]
"Figure 3 shows that adding each group improved performance, which indicates the informative value of each group.",4.4 Feature Set Contribution Analysis,[0],[0]
The figure also suggests that the most informative group in terms of prediction ability is the customer group.,4.4 Feature Set Contribution Analysis,[0],[0]
"We also studied how robust our features were: If our features generalize well, performance should not drop much when testing company B with the classifier trained exclusively on the data from company A.",4.5 Cross-Domain Analysis,[0],[0]
"Although company A and company B share similar conversation engine platforms, they are completely different in terms of objectives, domain, terminology, etc.",4.5 Cross-Domain Analysis,[0],[0]
"For this task, we utilized the 200 annotated conversations of company B as test data, and experimented with the different models, trained on company A’s data.",4.5 Cross-Domain Analysis,[0],[0]
"The rule-based baseline does not require training, of course, and could be applied directly.
",4.5 Cross-Domain Analysis,[0],[0]
"Table 3 summarizes the results showing that the performance of the EGR model is relatively stable (w.r.t the model’s performance when it was trained and tested on the same domain), with a degradation of only 9% in F1-score11.",4.5 Cross-Domain Analysis,[0],[0]
"In addition, the results also show that the text-based model performs poorly when applied to a different domain (F1-score of 0.11).",4.5 Cross-Domain Analysis,[0],[0]
"This may occur since textual features are closely tied to the training domain.
",4.5 Cross-Domain Analysis,[0],[0]
"11EGR model results are statistically significant compared to the baselines models with p < 0.001, using McNemar’s test.",4.5 Cross-Domain Analysis,[0],[0]
"Inspired by (Sarikaya, 2017; Sano et al., 2017)",4.6.1 Customer Rephrasing Analysis,[0],[0]
we analyzed the customer rephrasing motivations for both the egregious and the non-egregious classes.,4.6.1 Customer Rephrasing Analysis,[0],[0]
"First, we detected customer rephrasing as described in Section 3.2.1, and then assigned to each its motivation.",4.6.1 Customer Rephrasing Analysis,[0],[0]
"Specifically, in our setting, the relevant motivations are12: (1) Natural language understanding (NLU) error - the agent’s intent detection is wrong, and thus the agent’s response is semantically far from the customer’s turn; (2) Language generation (LG) limitation - the intent is detected correctly, but the customer is not satisfied by the response (for example, the response was too generic); (3) Unsupported intent error - the customer’s intent is not supported by the agent.
",4.6.1 Customer Rephrasing Analysis,[0],[0]
"In order to detect NLU errors, we measured the similarity between the first customer turn (before the rephrasing) and the agent response.",4.6.1 Customer Rephrasing Analysis,[0],[0]
"We followed the methodology presented in (Jovita et al., 2015) claiming that the best answer given by the system has the highest similarity value between the customer turn and the agent answer.",4.6.1 Customer Rephrasing Analysis,[0],[0]
"Thus, if the similarity was < 0.8 we considered this as an erroneous detection.",4.6.1 Customer Rephrasing Analysis,[0],[0]
"If the similarity was ≥ 0.8 we considered the detection as correct, and thus the rephrasing occurred due to LG limitation.",4.6.1 Customer Rephrasing Analysis,[0],[0]
To detect unsupported intent error we used the approach described in Section 3.1.2.,4.6.1 Customer Rephrasing Analysis,[0],[0]
"As reported in table 4, rephrasing due to an unsupported intent is more common in egregious conversations (18% vs. 14%), whereas, rephrasing due to generation limitations (LG limitation) is more common in
12We did not consider other motivations like automatic speech recognition (ASR) errors, fallback to search, and backend failure as they are not relevant to our setting.
non-egregious conversations (37% vs. 33%).",4.6.1 Customer Rephrasing Analysis,[0],[0]
"This indicates that customers are more tolerant of cases where the system understood their intent, but the response is not exactly what they expected, rather than cases where the system’s response was “not trained”.",4.6.1 Customer Rephrasing Analysis,[0],[0]
"Finally, the percentage of rephrasing due to wrong intent detection (NLU errors) is similar for both classes, which is somewhat expected as similar underlying systems provided NLU support.",4.6.1 Customer Rephrasing Analysis,[0],[0]
"We further investigated why the EGR model was better at identifying egregious conversations (i.e., its recall was higher compared to the baseline models).",4.6.2 Recall Analysis,[0],[0]
"We manually examined 26 egregious conversations that were identified justly so by the EGR model, but misclassified by the other models.",4.6.2 Recall Analysis,[0],[0]
Those conversations were particularly prevalent with the agent’s difficulty to identify correctly the user’s intent due to NLU errors or LG limitation.,4.6.2 Recall Analysis,[0],[0]
"We did not encounter any unsupported intent errors leading to customer rephrasing, which affected the ability of the rule-based model to classify those conversations as egregious.",4.6.2 Recall Analysis,[0],[0]
"In addition, the customer intents that appeared in those conversations were very diverse.",4.6.2 Recall Analysis,[0],[0]
"While customer rephrasing was captured by the EGR model, for the text-based model some of the intents were new (did not appear in the training data) and thus were difficult for the model to capture.",4.6.2 Recall Analysis,[0],[0]
"In this paper, we have shown how it is possible to detect egregious conversations using a combination of customer utterances, agent responses, and customer-agent interactional features.",5 Conclusions and Future Work,[0],[0]
"As explained, the goal of this work is to give developers of automated agents tools to detect and then solve problems cre-
ated by exceptionally bad conversations.",5 Conclusions and Future Work,[0],[0]
"In this context, future work includes collecting more data and using neural approaches (e.g., RNN, CNN) for analysis, validating our models on a range of domains beyond the two explored here.",5 Conclusions and Future Work,[0],[0]
"We also plan to extend the work to detect egregious conversations in real time (e.g., for escalating to a human operators), and create log analysis tools to analyze the root causes of egregious conversations and suggest possible remedies.",5 Conclusions and Future Work,[0],[0]
Virtual agents are becoming a prominent channel of interaction in customer service.,abstractText,[0],[0]
"Not all customer interactions are smooth, however, and some can become almost comically bad.",abstractText,[0],[0]
"In such instances, a human agent might need to step in and salvage the conversation.",abstractText,[0],[0]
Detecting bad conversations is important since disappointing customer service may threaten customer loyalty and impact revenue.,abstractText,[0],[0]
"In this paper, we outline an approach to detecting such egregious conversations, using behavioral cues from the user, patterns in agent responses, and useragent interaction.",abstractText,[0],[0]
"Using logs of two commercial systems, we show that using these features improves the detection F1-score by around 20% over using textual features alone.",abstractText,[0],[0]
"In addition, we show that those features are common across two quite different domains and, arguably, universal.",abstractText,[0],[0]
Detecting Egregious Conversations between Customers and Virtual Agents,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 46–56 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
46",text,[0],[0]
"In cities such as Chicago, gang-involved youth have increasingly turned to social media to post about their experience, often expressing grief when friends or family members are shot and killed.",1 Introduction,[0],[0]
"As grief turns to anger, their posts turn to retribution and ultimately to plans for revenge (Patton et al., 2018b).",1 Introduction,[0],[0]
"Research in this space has shown that online posts often affect life in the real world (Moule et al., 2013; Patton et al., 2013; Pyrooz et al., 2015; Patton et al., 2016, 2017a).",1 Introduction,[0],[0]
"In some communities, violence outreach workers manually scour online spaces to identify such possibilities and intervene to diffuse situations.",1 Introduction,[0],[0]
"A tool that identifies Aggression or Loss posts could help them filter irrelevant posts, but resources to develop a tool like this are scarce.
",1 Introduction,[0],[0]
"In this paper, we present automatic approaches for constructing resources and context features in this domain, and apply them to detecting Aggression and Loss in the social media posts of ganginvolved youth in Chicago.",1 Introduction,[0],[0]
"We exploit both a small
labeled dataset (4,936 posts) and a much larger unlabeled dataset (approximately 1 million posts), which we constructed using a method that enabled us to gather Twitter posts representative of the community we study.",1 Introduction,[0],[0]
"We incorporate our approaches into a CNN system, as well as a Support Vector Machine (SVM) to match the architecture of prior work, thus enabling analysis of the impact in different frameworks1.
",1 Introduction,[0],[0]
Key features of our system are the use of domainspecific word embeddings and a lexicon automatically induced from our unlabeled dataset.,1 Introduction,[0],[0]
"When classifying an individual tweet, our system considers the content and emotional impact of the tweets in the author’s recent history.",1 Introduction,[0],[0]
"If applicable, our system additionally takes into account a model of the pairwise interactions between the author and other users in the tweet referenced via either retweet or mention.
",1 Introduction,[0],[0]
"We compare our approaches with previous work that used a smaller dataset (800 tweets) and handcurated resources with an SVM (Blevins et al., 2016).",1 Introduction,[0],[0]
"By integrating our induced domain-specific and context information in a CNN, we achieve a significant increase over their reported results.
",1 Introduction,[0],[0]
"Our contributions include:
• A new labeled dataset, six times larger than that of prior work;
• Domain-specific resources, automatically induced from our constructed unlabeled dataset;
• Context features that capture semantic and emotion content in the user’s recent posts as
1We will make tweet IDs for the data available to researchers who sign an MOU specifying their intended use of the data and their agreement with our ethical guidelines.",1 Introduction,[0],[0]
Contact Serina Chang (sc3003@columbia.edu) or Kathleen McKeown (kathy@cs.columbia.edu).,1 Introduction,[0],[0]
"Our code is available at https://github.com/serinachang5/contextifier.
well as their interactions with other users in the dataset.
",1 Introduction,[0],[0]
Our approach brings us one step closer to building a useful tool that can help reduce gang violence in urban neighborhoods.,1 Introduction,[0],[0]
"In the remainder of the paper, we present related work, the dataset that we used, and our methodology.",1 Introduction,[0],[0]
We conclude with an error analysis and a discussion of the impact of our contributions.,1 Introduction,[0],[0]
Researchers have begun to explore how online data can be used to help prevent gun violence.,2 Related Work,[0],[0]
"Pavlick et al. 2016 are creating the Gun Violence Data Base by crowdsourcing annotations on newspaper articles that report on gun violence, labeling the sections of text that report on incidents, the shooter, and the victim.",2 Related Work,[0],[0]
"Researchers have also explored identifying deaths from police shootings with semisupervised methods for both CNNs and logistic regression (Keith et al., 2017) and found that logistic regression using a soft-labeling approach gave the best results.",2 Related Work,[0],[0]
"Researchers studying gun control issues analyzed social media for posts related to any issue around guns in the year following the Sandy Hook elementary school shooting (Benton et al., 2016) and argued that online media can be used to understand trends in gun violence and gun-related behaviors (Ayers et al., 2016).
",2 Related Work,[0],[0]
"Closely related research aims to automatically identify gang members’ Twitter profiles (Balasuriya et al., 2016).",2 Related Work,[0],[0]
"After collecting profiles using bootstrapping, they trained different classifiers on the tweets and meta-information about the authors.",2 Related Work,[0],[0]
"Further research analyzes the social networks of gangs (Radil et al., 2010) and predicts gang affiliation based on the analysis of graffiti style features (Piergallini et al., 2014).
",2 Related Work,[0],[0]
The most relevant work in automatically analyzing social media posts by gang-involved youth is that of Blevins et al. 2016.,2 Related Work,[0],[0]
"The labeled dataset that Blevins and collaborators used is extremely challenging, in part due to its size, but also because it contains text in a particular dialect of English – African American English (AAE) – which has very little core NLP tool support.",2 Related Work,[0],[0]
"Other research investigating the development of tools for understanding AAE in social media (Blodgett et al., 2016) shows that existing tools (e.g., dependency parsers) perform poorly on this language.",2 Related Work,[0],[0]
"Previous work by Patton on a subset of our dataset notes that due
to the linguistic style, tweets from gang-involved youth in Chicago can be challenging for outsiders to interpret and thus are often open to misinterpretation and potential criminalization (Patton et al., 2017b).
",2 Related Work,[0],[0]
The challenges of interpreting our data are further compounded by the usual difficulties with Twitter data.,2 Related Work,[0],[0]
Twitter data is sometimes handled by translating it to Standard American English (SAE) through the use of a phrasebook.,2 Related Work,[0],[0]
"The NoSlang Slang Translator (NoSlang, 2018b), and the accompanying NoSlang Drug Slang Translator (NoSlang, 2018a), have been used in other tasks to translate social media communication (Sarker et al., 2016), (Han and Baldwin, 2011).
",2 Related Work,[0],[0]
"To engineer features for an SVM classifier, Blevins et al. 2016 learned a part-of-speech (POS) tagger for their data and constructed a word level translation phrasebook to map emojis and slang to the Dictionary of Affect in Language (DAL) in order to identify their emotion.
",2 Related Work,[0],[0]
"In contrast to Blevins’ translation approach, we leverage our large unlabeled dataset to automatically induce resources, such as word embeddings, that function well within the domain of our task.",2 Related Work,[0],[0]
"Previous research on domain-specific word embeddings includes work in cybersecurity (Roy et al., 2017), disease surveillance (Ghosh et al., 2016), and construction (Tixier et al., 2016).",2 Related Work,[0],[0]
"These domain-specific word embeddings tend to improve performance on tasks within that domain.
",2 Related Work,[0],[0]
Context has been used in previous research on detecting hate speech in social media.,2 Related Work,[0],[0]
"Qian et al. 2018 found significant improvements by collecting the entire history of a user’s tweets and feeding them to a encoder to create an intra-user representation, which was used as input to a Bidirectional LSTM.",2 Related Work,[0],[0]
They also used a representation of tweets similar to the tweet being classified.,2 Related Work,[0],[0]
"While their approach captures a user profile based on everything the user has posted, in our approach we investigate how the recent history of tweets and interactions with others can improve classification.",2 Related Work,[0],[0]
"Others also make use of a user profile, though not one learned from unlabeled data (Dadvar et al., 2013).",2 Related Work,[0],[0]
"Our dataset consists of two parts: first, a collection of 4,936 tweets authored or retweeted by Gakirah Barnes, a powerful female Chicago gang member, and her top communicators, as well as ad-
ditional Twitter users in the same demographic, annotated by social work researchers who have been studying Gakirah and the associated Chicago gangs.",3 Data,[0],[0]
"Second, we use a much larger collection of approximately one million unlabeled tweets automatically scraped from 279 users in the same social network.",3 Data,[0],[0]
This social network is comprised of 214 users snowball-sampled from Gakirah Barnes’ top 14 communicators.,3 Data,[0],[0]
"Traditionally, snowball sampling has been used to recruit hard-to-reach research subjects (Atkinson and Flint, 2001) and we have adapted it for social media.",3 Data,[0],[0]
The remaining 65 users were added to this network by retaining those with the highest IQI score 2 from the full list of Gakirah’s Twitter followers.,3 Data,[0],[0]
"Our tweets thus form a representative sample of Twitter dialogue between youth from Chicago neighborhoods with high levels of gang activity during that time period.
",3 Data,[0],[0]
"The social work researchers performed a detailed, qualitative analysis of a subset of the dataset, with a focus on analyzing how context influences determination of a label.",3 Data,[0],[0]
"For example, they note that an aggressive tweet may reference a previous event, and will often use coded language to do so.",3 Data,[0],[0]
"Since much of the language used in our data differs significantly from standard American English, local youth active in similar environments served as consultants to answer questions about the language, as they were able to interpret the slang terms present in these tweets.",3 Data,[0],[0]
"The social work researchers conducted a fine-grained analysis using an online tool for annotation, identifying insults, threats, bragging, hypervigilance and challenges to authority, all of which were collapsed into a single category, Aggression.",3 Data,[0],[0]
"Posts including distress, sadness, loneliness and death were collapsed into the category Loss.",3 Data,[0],[0]
"The Other category includes discussion of other aspects of their life, such as friendships, relationships, drugs, general conversations, and happiness.",3 Data,[0],[0]
"We developed our system (as did Blevins et al. 2016) on the collapsed labels, as the task is difficult even with three-way categorization.
",3 Data,[0],[0]
"Each tweet in a subset of the entire dataset consisting of 3,000 tweets was reviewed by two different annotators.",3 Data,[0],[0]
"Inter-rater reliability between raters was tracked, with dissimilar annotations flagged for further review.",3 Data,[0],[0]
"Flagged tweets were further analyzed by the social work researchers, which in-
2https://www.brookings.edu/wp-content/ uploads/2016/06/isis_twitter_census_ berger_morgan.pdf
cluded youth from Chicago who currently live in the same community as, or an adjacent one to, that in which the deceased Gakirah Barnes resided, to adjudicate disagreement.",3 Data,[0],[0]
"Among the set of tweets coded by two annotators, inter-annotator agreement on the Aggression class was high even before adjudication, with a Cohen’s kappa coefficient of .94; agreement on the Loss class was somewhat lower, with a Cohen’s kappa of .83.",3 Data,[0],[0]
"Examples of labeled Twitter posts from Gakirah and her followers are shown in Table 1 3.
",3 Data,[0],[0]
"In order to mitigate potential issues with training and test data being drawn from different time periods or having different distributions of labels, we shuffled our data and drew stratified samples with equal distribution across classes for our training, validation, and test sets for each of the cross validation folds, using 64%, 16%, and 20% of our data for each respectively.",3 Data,[0],[0]
"The Aggression and Loss classes are relatively small, reflecting their low distribution in real life: we have only 329 Aggression tweets and 734 Loss tweets, with the Other class comprising the remaining 3,873 tweets.",3 Data,[0],[0]
"We approach this classification task using a standard CNN classifier architecture (Kim, 2014; Collobert et al., 2011) as our starting point.",4 Methods,[0],[0]
"We initially experimented with both character and word level CNNs but found the word level to be 1.6 macro-F1
3Our data was scraped from publicly available posts and was determined exempt by our organization’s IRB.",4 Methods,[0],[0]
"User names are replaced with USER in the table, and text has been modified to render tweets unsearchable.
points better than the character level, so we only include the word level here.",4 Methods,[0],[0]
We leveraged the unlabeled corpora by constructing domain-specific embeddings and a lexicon that better fit our unique and low-resource domain.,4 Methods,[0],[0]
We then integrated our domain-specific resources into the CNN to represent the given tweet as well as to represent context features.,4 Methods,[0],[0]
Our context features represent a window of the user’s recent tweets as well as the interactions of the author with other users via references in their tweets.,4 Methods,[0],[0]
We exploited the large unlabeled corpus to build two domain-specific resources for this task: word embeddings and a task-specific lexicon.,4.1 Domain-Specific Resources,[0],[0]
Word embeddings have proven useful in representing the semantic content of sentences.,4.1.1 Word Embeddings,[0],[0]
"The semantic representation of a word by its associated embedding, however, depends on its usage in the corpus the embedding was trained on, and so off-theshelf word embeddings do not always adapt well to tasks with a unique domain (Roy et al., 2017), (Ghosh et al., 2016), (Tixier et al., 2016).",4.1.1 Word Embeddings,[0],[0]
"Thus, we were motivated to use our unlabeled corpus to create domain-specific word embeddings.",4.1.1 Word Embeddings,[0],[0]
"We used the Word2Vec (Mikolov et al., 2013) CBOW model to train the embeddings which is the default training algorithm available in Gensim 4.",4.1.1 Word Embeddings,[0],[0]
We used a window size of 5 words with a minimum word count of 5 to train w ∈ R300.,4.1.1 Word Embeddings,[0],[0]
The CBOW model was trained for 20 epochs.,4.1.1 Word Embeddings,[0],[0]
"Given the domain-specific nature of our users’ language, we could not rely on standard NLP lexicons to represent emotion in their tweets.",4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
"For our task, the two emotions of interest are Aggression and Loss.",4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
"Previous work (Blevins et al., 2016) used a phrasebook to translate the domain-specific words of their corpus to Standard American English so that they could access emotion in the Dictionary of Affect in Language (DAL) (Whissell, 2009), but this approach does not generalize to capture new words.
",4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
"We therefore adapted the SENTPROP algorithm (Hamilton et al., 2016) to automatically induce a
4https://radimrehurek.com/gensim/ models/word2vec.html
lexicon of Aggression and Loss from our unlabeled corpus.",4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
"The SENTPROP algorithm constructs a lexical graph out of the word embeddings, then propagates labels from the seed sets over the unlabeled nodes via a random walk method.",4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
The resulting output for each word indicates the probability of a random walk from the seed set landing on that node.,4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
"We chose SENTPROP as an induction method because it performs especially well for domain-specific corpora, and it is resource-light and interpretable.
",4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
We created word embeddings by employing an SVD-based method that was reported by the SENTPROP authors to perform optimally with their algorithm.,4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
"We first constructed the positive point-wise mutual information matrix, MPPMI , over the unlabeled corpus, then computed singular value decomposition (SVD) to derive MPPMI = UΣV ᵀ.",4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
"The word embedding for word wi was thus given by Ui, truncated to a standard length of dimension 300.",4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
"To construct our seed sets, we asked our annotators to consider words for Loss and Aggression which they associated most strongly with each class.",4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
"They generated a set of 29 words for Aggression and a set of 40 words for Loss, which we include in our appendix.
",4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
We ran SENTPROP with our SVD-based embeddings and the seed sets from our annotators.,4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
"We used the output probabilities from the random walks to map words to their association with Aggression and Loss, thus forming our lexicon of Aggression and Loss.",4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
"Finally, we scaled the probabilities per class to mean 0 and variance 1.",4.1.2 Computing a Lexicon of Aggression and Loss,[0],[0]
Our context features utilize the domain-specific resources that we induced from the unlabeled corpora.,4.2 Context Features,[0],[0]
"To capture context, we first considered the author’s recent history, separately exploring representations by our domain-specific word embeddings and by the SENTPROP lexicon (SPLex).",4.2 Context Features,[0],[0]
"If applicable, we also considered the interactions between the author and other users who were referenced in the tweet, either via retweet or mention.",4.2 Context Features,[0],[0]
"To obtain the user’s recent history, we ordered all the tweets chronologically and bucketed them by author.",4.2.1 User History,[0],[0]
"Thus, for any given tweet occurring at time t, at, we were able to retrieve previous tweets at−1, at−2, . . .",4.2.1 User History,[0],[0]
by that user.,4.2.1 User History,[0],[0]
"We treated recent history as a sliding window and fetched tweets within
the past d days from when the current tweet was tweeted, such that recent history tweets would be the set {at−1, . . .",4.2.1 User History,[0],[0]
", at−k}, where t− k < d.
To represent the tweets within the context of recent history, we first combined word level representations into tweet level, then tweet level representations into context level.",4.2.1 User History,[0],[0]
"At each stage of combination, we tried both summing and averaging.",4.2.1 User History,[0],[0]
"Thus, our recent history representations were built by aggregating either word embeddings or SPLex scores, which maintained their dimensionality of 300 or 2, respectively.
",4.2.1 User History,[0],[0]
We also considered three types of tweets that would be relevant to a user.,4.2.1 User History,[0],[0]
The user’s own tweets (SELF) would always be relevant; we experimented with also including tweets where the user was retweeted (RETWEET) and tweets where the user was mentioned (MENTION).,4.2.1 User History,[0],[0]
"We included these parameters as additional sources of context because a user’s tweet may be a response to a recent mention or retweet from another user.
",4.2.1 User History,[0],[0]
We also experimented with weighting the most recent tweets more heavily than further tweets within the recent history window.,4.2.1 User History,[0],[0]
"This became especially important when we experimented with larger windows of a month or more, since tweets from a few days ago are more likely to be related to the current tweet than tweets from a few weeks ago.",4.2.1 User History,[0],[0]
"To model this diminishing relevance, we introduced a weighting protocol with a variable half-life where weights decay exponentially over time.",4.2.1 User History,[0],[0]
"The parameter we tuned was the half-life ratio r, which is the proportion of the window size d that corresponds to the window’s half-life.",4.2.1 User History,[0],[0]
"Then, before combining tweet level representations into context level, we multiplied each tweet representation bi by its weight, 2− ∆t f , where ∆t = t",4.2.1 User History,[0],[0]
"− i is the distance in days between the context tweet ai and the current tweet at, and f = d ∗ r is the half life.",4.2.1 User History,[0],[0]
"As an additional context feature, we modeled the pairwise interactions between users.",4.2.2 User Interactions,[0],[0]
"To identify interactions, we iterated through our unlabeled and labeled corpora and checked which users were involved in each tweet.",4.2.2 User Interactions,[0],[0]
We counted a user as involved in a tweet if they posted the tweet or were referenced via retweet or mention.,4.2.2 User Interactions,[0],[0]
"For each pair of users, we aggregated all their tweets of mutual involvement into one document and averaged the document’s word embeddings to create a representation of their pairwise interactions in R300.",4.2.2 User Interactions,[0],[0]
"We experimented with the efficacy of our domainspecific resources, the impact of different context parameters, and the contribution of context to predicting Aggression and Loss.",5 Experiments,[0],[0]
"For word level models, we preprocess each tweet by: i) lowercasing every character, ii) replacing every user mention and url with special tokens “user” and “url”, iii) considering each emoji an individual token, whether space separated or not, and iv) removing emoji modifiers to reduce sparsity, just as we used lowercasing.",5.1 Corpus pre-processing,[0],[0]
"We select the top 40K tokens based on frequency, replacing the remaining tokens with “UNKNOWN”.",5.1 Corpus pre-processing,[0],[0]
We zero-pad or trim tweets so that tweet length will be 50 when passed to our CNN model.,5.1 Corpus pre-processing,[0],[0]
"Similarly, we only consider users who occur (as author, source of retweet, or in mention) in the labeled and unlabeled corpus at least twice, resulting in 35,656 users in total.
",5.1 Corpus pre-processing,[0],[0]
"We extract the author of the tweets from metadata, and user mentions and original posters of retweets from the Twitter text, based on their Twitter display name.",5.1 Corpus pre-processing,[0],[0]
We used Twitter display name rather than user ID because we cannot collect user ID for interaction features.,5.1 Corpus pre-processing,[0],[0]
"For this 3-way classification task, we train two models; the first model predicts whether a tweet has the Aggression label and the second predicts for Loss.",5.2 CNN Architecture,[0],[0]
Each model maps a sequence of tokens to a probability value for a class.,5.2 CNN Architecture,[0],[0]
Here we define the architecture of our CNN model.,5.2 CNN Architecture,[0],[0]
Our input c is a token index sequence of length 50.,5.2 CNN Architecture,[0],[0]
"We map each token index to a vector ∈ R300 with a trainable embedding matrix, followed by dropout 0.5.",5.2 CNN Architecture,[0],[0]
"We apply a 1D Convolutional layer with kernel sizes 1 and 2, filter size 200 each, to the embedded token sequence, followed by ReLU activation, max pooling and dropout 0.5.",5.2 CNN Architecture,[0],[0]
"We concatenate the output of max pooling for kernel sizes 1 and 2, stack another dense layer h with dimension 256, and connect the output of h to the final single output unit with sigmoid activation.
",5.2 CNN Architecture,[0],[0]
"In the prediction phase, for each data point, we classify it as Aggression if the the first model produces the probability score above threshold tA. If it is not predicted as Aggression, then we classify it as Loss if the second model produces a score above
a threshold tL.",5.2 CNN Architecture,[0],[0]
"The remaining tweets are classified as Other. tA and tL are tuned on the validation set.
",5.2 CNN Architecture,[0],[0]
We incorporate context information into the neural network in the following way.,5.2 CNN Architecture,[0],[0]
"Each type of context feature takes the form of a real vector: both word embedding user history and word embedding user interaction features are in R300, and SPLex user history features are in R2.",5.2 CNN Architecture,[0],[0]
We concatenate these feature vectors with the last layer h before the final classification output.,5.2 CNN Architecture,[0],[0]
We used as our baseline method a linear-kernel SVM classifier as used by Blevins et al. 2016.,5.3 SVM Baseline,[0],[0]
We obtained code from the authors and trained on our larger dataset.,5.3 SVM Baseline,[0],[0]
"In this method, after basic preprocessing is performed to replace urls and user mentions with special tokens, unigram, bigram, part-of-speech tag, and emotion features are extracted.",5.3 SVM Baseline,[0],[0]
Feature selection is performed to prune the feature space.,5.3 SVM Baseline,[0],[0]
The part-of-speech tagger used in Blevins et al. 2016 was developed for use on this domain; emotion features are computed using scores for each tweet word taken from the Dictionary of Affect in Language (DAL).,5.3 SVM Baseline,[0],[0]
"We performed gridsearch to re-tune the loss function, the regularization penalty type, and the penalty parameter C, but found that the original settings for these parameters still performed best even on our new development set.",5.3 SVM Baseline,[0],[0]
"We also tuned the class weights used: while the model performed best on the original data with balanced class weights, we found that less extreme balancing performed better here (weights 2, 1, and 0.12 for Aggression, Loss, and Other, respectively).
",5.3 SVM Baseline,[0],[0]
"While we retrained the SVM on our new training set, we did not modify the additional components used for feature selection such as the phrase table or the specialized part-of-speech tagger, as we had no additional data available for this.",5.3 SVM Baseline,[0],[0]
"This indicates the difficulty of generalizing to new data with unseen vocabulary, and is one of the disadvantages of using manually-created specialized feature sets such as these.",5.3 SVM Baseline,[0],[0]
"In order to test the efficacy of our domain-specific word embeddings, we compared them with a number of other embedding types.",5.4 Domain Experiments,[0],[0]
"Our baseline method was Pennington et al. 2014’s GloVe embeddings pretrained on a general Twitter dataset, available
from their website5.",5.4 Domain Experiments,[0],[0]
"We trained a parallel set of word embeddings on the African American English (AAE) corpus of around 1.1 million tweets provided by Blodgett et al. 2016, and another set on a corpus of a location-specific set of tweets that we scraped, drawn from users who posted from a specific area within the South Side of Chicago where the gangs we study are based.",5.4 Domain Experiments,[0],[0]
We also compared performance with a randomly initialized word embedding matrix.,5.4 Domain Experiments,[0],[0]
"We first explored the impact of the user history parameters, tuning them separately for representations by our domain-specific word embeddings and by SPLex.",5.5 Context Experiments,[0],[0]
"We kept these representations separate because we expected them to capture different types of context: word embeddings should capture the semantic content of the user’s history, while SPLex scores should capture something closer to the user’s emotional state leading up to the tweet.
",5.5 Context Experiments,[0],[0]
"With each representation, we experimented with summing versus averaging word embeddings to yield a tweet level representation, and similarly experimented with summing and averaging from tweet embeddings to context level representations.",5.5 Context Experiments,[0],[0]
"We varied the size of the context window, d, trying 2 days, 1 week, 1 month, 2 months, and 3 months.",5.5 Context Experiments,[0],[0]
"We also varied the half-life ratio, r = .25, .5, .75, or no weighting.",5.5 Context Experiments,[0],[0]
"Lastly, we tried including different types of posts in the user history.
",5.5 Context Experiments,[0],[0]
"Once we tuned the user history parameters, we experimented with adding our context features (user history and user interactions) to the best tweet level model we could achieve without context.",5.5 Context Experiments,[0],[0]
"For our CNN, our best tweet level model used our domain-specific word embeddings as pretrained weights for the embedding layer (CNN-DS in Table 3).",5.5 Context Experiments,[0],[0]
"To evaluate the impact of our resources in different frameworks, we additionally experimented with the contribution of context in an SVM.",5.5 Context Experiments,[0],[0]
The best tweet level SVM included the averaged domain-specific word embeddings and summed SPLex scores of the tokens in the tweet (SVM-DS).,5.5 Context Experiments,[0],[0]
We report results comparing different embeddings and comparing parameters for context.,6 Results and Discussion,[0],[0]
"We use the best results from these experiments to produce our
5https://nlp.stanford.edu/projects/ glove/
final systems in the SVM and CNN frameworks.",6 Results and Discussion,[0],[0]
The best resulting architecture for the CNN framework is illustrated in Fig. 1.,6 Results and Discussion,[0],[0]
Experiments were performed using five-fold crossvalidation over the labeled data and were repeated five times for each fold to account for variance between runs.,6.1 Comparison of Embeddings,[0],[0]
"Reported F-scores, shown in Table 2, are averaged across runs and across folds.
",6.1 Comparison of Embeddings,[0],[0]
Word embeddings trained on our unlabeled corpus outperformed other embeddings by over 4 points.,6.1 Comparison of Embeddings,[0],[0]
"Related datasets such as the locationspecific or AAE corpus did not provide helpful semantic information, as their embeddings did not even beat random initialization.",6.1 Comparison of Embeddings,[0],[0]
"This was not an effect of corpus size, since these corpora contained 800,000 and 1.1 million tweets, respectively, compared to the 1 million in our unlabeled corpus.",6.1 Comparison of Embeddings,[0],[0]
"Thus, we attribute the difference to the importance of deriving embeddings directly from our community of interest, demonstrating that the language of our community is more specific than AAE in general and that our snowballing method was able to capture a better representation of user language than a location driven method.",6.1 Comparison of Embeddings,[0],[0]
Experiments were performed using five-fold crossvalidation and F-scores computed as in the word embedding experiments.,6.2 User History Parameters,[0],[0]
"We found that user history
represented by domain-specific word embeddings performed optimally when we averaged from word to tweet level and from tweet to context level.",6.2 User History Parameters,[0],[0]
"The best window size was d = 90 days, including only SELF posts, and using a half-life ratio of r = 0.25.",6.2 User History Parameters,[0],[0]
"For user history represented by SPLex, we found the best method of combination to be summing, at both the word and tweet level.",6.2 User History Parameters,[0],[0]
We hypothesize this is because summing captures not only the presence but also the number or density of highly indicative Aggression or Loss words posted by the user over the context window.,6.2 User History Parameters,[0],[0]
"The best window size was d = 2 days, including both SELF and RETWEET posts, without half-life weighting.
",6.2 User History Parameters,[0],[0]
"Our approach was designed to implement and
test previous insights about the domain, particularly that context plays a role in the interpretation of posts.",6.2 User History Parameters,[0],[0]
The short time frame for SPLex user history corresponds with the 2 day window found in Patton et al. 2018b’s research and reflects the fact that emotional states may fluctuate often and within a certain number of days.,6.2 User History Parameters,[0],[0]
"In contrast, word embeddings improved consistently as we extended the context window from 2 days to 90 days.",6.2 User History Parameters,[0],[0]
"Since word embedding user history is meant to capture the user’s semantics, a larger window size means the representation can be drawn from more tweets, and thus reflects a more representative sample of the user’s semantics around this time period.",6.2 User History Parameters,[0],[0]
"To develop a more stable measurement of comparison between different systems, we create four independent sets of 5-fold cross validation splits on our data set (altogether 20 folds); to account for randomness in neural net training, we train each neural net model 5 times and take the majority vote of the predictions.",6.3 Comparison of Best Systems,[0],[0]
"For each class, we calculate the statistical significance of F-score based on the predictions on the concatenated test sets of all 20 folds using the Approximate Randomization Test (Riezler and Maxwell 2005) with the Bonferroni correction for multiple comparisons.",6.3 Comparison of Best Systems,[0],[0]
"Results are shown in Table 3.
",6.3 Comparison of Best Systems,[0],[0]
"Adding context contributed to a significant improvement in both the CNN and SVM frameworks, demonstrating the independent value of our context features over domain-specific resources.",6.3 Comparison of Best Systems,[0],[0]
"For contrast, we also compared our context features with user profiles built from averaging the word embeddings in all of the user’s tweets.",6.3 Comparison of Best Systems,[0],[0]
"Our pairwise and user history features outperformed user profiles by .7 points, demonstrating that it is valuable to provide dynamic representations of users
that can adjust to their recent posts or their interactions with other users, as opposed to stereotyping their overall behavior.
",6.3 Comparison of Best Systems,[0],[0]
"Additionally, we compare the impact of our domain-specific resources to those used by Blevins et al. (2016).",6.3 Comparison of Best Systems,[0],[0]
"In particular, we expect that their emotion scores will not generalize to the new vocabulary in our large unlabeled corpus (see Section 4.1).",6.3 Comparison of Best Systems,[0],[0]
"Our domain-specific resources alone without context raise our SVM to comparable performance with the Blevins et al. retrained baseline, and the resources push our CNN without context over this baseline.",6.3 Comparison of Best Systems,[0],[0]
"This demonstrates that our automatic methods can do as well as if not better than phrasebook methods, and they are significantly more efficient to generate.",6.3 Comparison of Best Systems,[0],[0]
"In this section we provide an analysis of the tradeoffs of each classifier by analyzing some of the examples in Table 1.
",7 Error Analysis,[0],[0]
Context vs non-context CNN.,7 Error Analysis,[0],[0]
"Our best CNN - a system which incorporated context - was able to correctly predict tweets 3 and 4, whereas our baseline using only our pretrained Word2Vec embeddings was not.",7 Error Analysis,[0],[0]
"Correctly classifying tweet 4 relies on the knowledge that the referenced user, DMoney, is a deceased member of a rival gang of the poster.",7 Error Analysis,[0],[0]
"In tweet 3, the poster is saying that he has seen Gakirah’s death on the news; this is an expression of loss.
",7 Error Analysis,[0],[0]
Domain-specific vocabulary.,7 Error Analysis,[0],[0]
"Our CNN trained on domain-specific word embeddings is able to correctly classify tweet 5, while the one trained on Twitter word embeddings did not pick up the aggressive content.",7 Error Analysis,[0],[0]
This user is talking about how their friend is ready to kill someone.,7 Error Analysis,[0],[0]
"This tweet contains the word thirsty but in this domain-specific
context it means being ready and having an urge (although it would not always refer to killing).
",7 Error Analysis,[0],[0]
Hashtags and character sequences.,7 Error Analysis,[0],[0]
"Despite their strengths, both our best CNN and our best SVM classifiers were still unable to correctly classify some of the trickier cases.",7 Error Analysis,[0],[0]
"There were certain types of tweets they were categorically unable to recognize: tweet 1 features a hashtag that refers to an incarcerated acquaintance of the poster, but as both our CNN and SVM models operate at the word level, this tag would have appeared simply as a rare or unknown token to them.
",7 Error Analysis,[0],[0]
Anger miscategorized as Aggression.,7 Error Analysis,[0],[0]
"At times, the classifier categorized posts that express anger as Aggression.",7 Error Analysis,[0],[0]
"For example, in tweet 4 the author uses profanity to express grief related to the loss of a friend.",7 Error Analysis,[0],[0]
"In addition, the devil face emoji, which is sometimes used to express aggression, is also used in the context of anger.",7 Error Analysis,[0],[0]
"While the best CNN model managed to correctly predict this as Loss, the SVM miscategorized it as Aggression.",7 Error Analysis,[0],[0]
"Our ethics guidelines include just treatment of the users who provide our data, removal of identifying information for publication, and the inclusion of Chicago-based community members as domain experts in the analysis and validation of our findings.
",8 Ethics,[0],[0]
There are risks involved with detecting Aggression and Loss in social media data using automatic detection systems.,8 Ethics,[0],[0]
"These risks include possible misidentifications of tweets, increased police involvement, and loss of privacy, which all have the potential to harm marginalized communities and people.",8 Ethics,[0],[0]
"Our mitigation strategies begin by partnering with violence prevention organizations and incorporating domain experts (Frey et al., 2018) to ensure the highest ethical standards for interpreting social media posts and for the dissemination and use of our research for violence prevention.",8 Ethics,[0],[0]
"Through insights gained from these partnerships, we developed our own risk mitigation strategies: de-identifying each tweet and rendering it unsearchable through textual modification without altering meaning; encrypting our social media corpus to protect user identities; and relying on violence prevention organizations’ expertise in deciding if and when to involve law enforcement to prevent the unethical use of our data (e.g., hyper-surveillance of communities of color).",8 Ethics,[0],[0]
Our approach shows that integrating emotions and semantic content of a user’s recent posts is an important component for the task of predicting Aggression and Loss in social media posts of gang-involved youth.,9 Conclusion and Future Work,[0],[0]
"Furthermore, using domainspecific embeddings and an Aggression-Loss lexicon induced from a corpus of language constructed to represent our specific community of users is also critical to success.",9 Conclusion and Future Work,[0],[0]
"Our experiments reveal that our snowballing technique is more effective than a location based approach and that fitting our community is more complex than resorting to their demographic, as captured in the AAE corpus of Blodgett et al. (2016).
",9 Conclusion and Future Work,[0],[0]
"Our work has real life implications for the use of machine learning to identify unique characteristics in social media data that may indicate the process by which gun violence may occur (Patton et al., 2018a).",9 Conclusion and Future Work,[0],[0]
"Our partnership between computer scientists, social work researchers and practitioners has advanced plans to create applications to help outreach workers in Chicago identify factors related to potential violence, potentially allowing them to prevent and intervene in aggressive online activity.",9 Conclusion and Future Work,[0],[0]
"The tool, which would be co-created with community stakeholders, would enable quick scanning of large quantities of social media posts that outreach workers would be unable to perform manually.
",9 Conclusion and Future Work,[0],[0]
"We expect our methods to be generalizable because we compute embeddings and lexicons from neighborhood-specific data and do not rely on large, hand-crafted resources such as dictionaries.",9 Conclusion and Future Work,[0],[0]
"However, we hope to test generalizability in future work by applying our methods to other gang-related corpora, because there is variation in language, local concepts, and behavior across gangs.",9 Conclusion and Future Work,[0],[0]
"In the future, we are also interested in further experimenting with the context features introduced in this work; for instance, by extending our pairwise interaction features to take into account direction between users.",9 Conclusion and Future Work,[0],[0]
"Finally, we intend to explore other types of context, such as reference to specific events that may trigger the emotions of either Aggression or Loss.",9 Conclusion and Future Work,[0],[0]
This research is supported in part by DARPA contract 55630053.,10 Acknowledgements,[0],[0]
The authors also thank the anonymous reviewers for their thoughtful comments.,10 Acknowledgements,[0],[0]
Gang-involved youth in cities such as Chicago have increasingly turned to social media to post about their experiences and intents online.,abstractText,[0],[0]
"In some situations, when they experience the loss of a loved one, their online expression of emotion may evolve into aggression towards rival gangs and ultimately into real-world violence.",abstractText,[0],[0]
"In this paper, we present a novel system for detecting Aggression and Loss in social media.",abstractText,[0],[0]
"Our system features the use of domainspecific resources automatically derived from a large unlabeled corpus, and contextual representations of the emotional and semantic content of the user’s recent tweets as well as their interactions with other users.",abstractText,[0],[0]
Incorporating context in our Convolutional Neural Network (CNN) leads to a significant improvement.,abstractText,[0],[0]
Detecting Gang-Involved Escalation on Social Media Using Context,title,[0],[0]
Improving the relationship between police officers and the communities they serve is a critical societal goal.,1 Introduction,[0],[0]
We propose to study this relationship by applying NLP techniques to conversations between officers and community members in traffic stops.,1 Introduction,[0],[0]
"Traffic stops are one of the most common forms of police contact with community members, with 10% of U.S. adults pulled over every year (Langton and Durose, 2013).",1 Introduction,[0],[0]
"Yet past research on what people ex-
perience during these traffic stops has mainly been limited to self-reported behavior and post-hoc narratives (Lundman and Kaufman, 2003; Engel, 2005; Brunson, 2007; Epp et al., 2014).
",1 Introduction,[0],[0]
"The rapid adoption of body-worn cameras by police departments in the U.S. (laws in 60% of states in the U.S. encourage the use of body cameras) and across the world has provided unprecedented insight into traffic stops.1 While footage from these cameras is used as evidence in contentious cases, the unstructured nature and immense volume of video data means that most of this footage is untapped.
",1 Introduction,[0],[0]
"Recent work by Voigt et al. (2017) demonstrated that body-worn camera footage could be used not just as evidence in court, but as data.",1 Introduction,[0],[0]
"They developed algorithms to automatically detect the degree of respect that officers communicated to drivers in close to 1,000 routine traffic stops captured on camera.",1 Introduction,[0],[0]
"It was the first study to use machine learning techniques to extract insights from this footage.
",1 Introduction,[0],[0]
This footage can be further used to unearth the structure of police-community interactions and gain a more comprehensive picture of the traffic stop as an every day institutional practice.,1 Introduction,[0],[0]
"For instance, knowing which requests the officer makes, whether and when they introduce themselves or explain the reason for the stop is a novel way to measure procedural justice; a set of fairness principles recommended by the President’s Task Force on 21st Century Policing,2 and endorsed by police departments across the U.S.
1https://en.wikipedia.org/wiki/Body_ worn_video_(police_equipment)
2http://www.theiacp.org/TaskForceReport
467
Transactions of the Association for Computational Linguistics, vol. 6, pp.",1 Introduction,[0],[0]
"467–481, 2018.",1 Introduction,[0],[0]
Action Editor: Jordan Boyd-Graber .,1 Introduction,[0],[0]
"Submission batch: 11/2017; Revision batch: 2/2018; Published 7/2018.
",1 Introduction,[0],[0]
c©2018 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
",1 Introduction,[0],[0]
We propose automatically extracting dialog structure from body camera footage to contribute to our understanding of police-community interactions.,1 Introduction,[0],[0]
"We rely on the notion of institutional talk (Heritage, 2005), which posits that dialog acts, topics, and narrative are heavily defined by the institutional context.",1 Introduction,[0],[0]
"Traffic stops are a kind of institutional talk; as are, for example, doctor-patient interactions, counseling conversations, and citizen calls for help from police.",1 Introduction,[0],[0]
We introduce a model of institutional acts for traffic stop conversations.,1 Introduction,[0],[0]
"Since the officer holds a position of power within this institutional context, their dialog behavior has a greater influence in shaping the conversation (Coupland et al., 1991; Gnisci, 2005); hence, we focus on the institutional acts performed by the officer in this paper.
",1 Introduction,[0],[0]
Contributions of our paper: 1) A typology of institutional dialog acts to model the structure of police-driver interactions during traffic stops.,1 Introduction,[0],[0]
2),1 Introduction,[0],[0]
An institutional act tagger that works from transcribed words (78% F-score) or from raw audio (60% Fscore).,1 Introduction,[0],[0]
"3) A classifier that uses this dialog structure to detect acts at the stop level (e.g., “Does this stop contain a Reason?”)",1 Introduction,[0],[0]
(81% F-score from raw audio).,1 Introduction,[0],[0]
4) An analysis of salient dialog structure patterns in traffic stops; demonstrating its potential as a tool for police departments to assess and improve police community interactions.,1 Introduction,[0],[0]
"Computational work on human-human conversation has long focused on dialog structure, beginning with the influential work of Grosz showing the homology between dialog and task structure (Grosz, 1977).",2 Background,[0],[0]
"Recent work has integrated speech act theory (Austin, 1975) and conversational analysis (Schegloff and Sacks, 1973; Sacks et al., 1974; Schegloff, 1979) into models of dialog acts for domains like meetings (Ang et al., 2005), telephone calls (Stolcke et al., 2006), emails (Cohen et al., 2004), chats (Kim et al., 2010), and Twitter (Ritter et al., 2010).
",2 Background,[0],[0]
"Our models extend this work by drawing on the notion of institutional talk (Atkinson and Drew, 1979), an application of conversational analysis to environments in which the goals of participants are institution-specific.",2 Background,[0],[0]
"Actions, their sequences, and interpretations during institutional talk depend not
only on the speaker (as speech act theory suggests) or the dialog (as conversational analysts argue), but they are inherently tied to the institutional context.
",2 Background,[0],[0]
Institutional talk has been used as a tool to understand the work of social institutions.,2 Background,[0],[0]
"For example, Whalen and Zimmerman (1987) studied dialog structure in transcripts of citizen calls for help.",2 Background,[0],[0]
"They observed that the “regular, repetitive and reproducible features of calls for police, fire or paramedic services [...] arise from situated practices responsive to the sequential and institutional contexts of this type of call”.",2 Background,[0],[0]
"Such recurring patterns in language and conversation exist across different institutional contexts such as doctor-patient interactions, psychological counseling, sales calls, court room conversations, as well as traffic stops (Heritage, 2005).
",2 Background,[0],[0]
Deviations from these sequential configurations are consequential.,2 Background,[0],[0]
"A police officer failing to explain the reason for the traffic stop can lead to aggravation in the driver (Giles et al., 2007), and an officer’s perceived communication skills (e.g. do they listen, take civilian views into account) predict civilian’s attitudes towards the police (Giles et al., 2006).
",2 Background,[0],[0]
These findings demonstrate the importance of understanding the role of institutional context in shaping conversation structure.,2 Background,[0],[0]
"In doing so, our paper also draws on recent research on automatically extracting structure from human-human dialog.",2 Background,[0],[0]
"Drawing on Grosz’s original insights, Bangalore et al. (2006) show how to extract a hierarchical task structure for catalog ordering dialogs with subtasks like opening, contact-information, order-item, relatedoffers, and summary.",2 Background,[0],[0]
"Prabhakaran et al. (2012) and Prabhakaran et al. (2014) employ dialog act analysis to study correlates of gender and power in work emails, while Althoff et al. (2016)",2 Background,[0],[0]
"studied structural aspects of successful counseling conversations, and Yang et al. (2013) and Chandrasekaran et al. (2017) investigated structures in online classroom conversations that predict success or need for intervention.",2 Background,[0],[0]
"Our work also draws on an important line of unsupervised work that models topical structure of conversations (Blei and Moreno, 2001; Eisenstein and Barzilay, 2008; Paul, 2012; Nguyen et al., 2012).
",2 Background,[0],[0]
Our work is closely related to the active line of research in NLP on dialog act classification.,2 Background,[0],[0]
"Recently, recurrent neural network-based dialog act taggers, e.g., Khanpour et al. (2016), Li and Wu (2016) and
Liu et al. (2017), have posted state-of-the-art performance on benchmark datasets such as the Switchboard corpus (Jurafsky et al., 1997) and MRDA (Ang et al., 2005).",2 Background,[0],[0]
"Since these corpora come from significantly different domains (telephone conversations and meeting transcripts, respectively) than ours, and since we are interested specifically in the institutional acts (e.g., did the officer request documentation from the driver?) rather than the general dialog acts (did the officer issue a request?), these taggers do not directly serve our purpose.",2 Background,[0],[0]
"Furthermore, our data is an order of magnitude smaller (around 7K sentences) than these corpora; making it infeasible to train in-domain recurrent networks.
",2 Background,[0],[0]
"Prior to neural network approaches, support vector machines and conditional random fields (Cohen et al., 2004; Kim et al., 2010; Kim et al., 2012; Omuya et al., 2013) were the state-of-the-art algorithms on this task.",2 Background,[0],[0]
These approaches also incorporated contextual and structural information into the classifier.,2 Background,[0],[0]
"For instance, Kim et al. (2012) used lexical information from previous utterances in predicting the dialog act of a current utterance; and Omuya et al. (2013) uses features such as the relative position of an utterance",2 Background,[0],[0]
w.r.t the whole dialog.,2 Background,[0],[0]
We draw from this line of work; we also experiment with positional and contextual features in addition to lexical features.,2 Background,[0],[0]
"Furthermore, we use features that capture the institutional context of the conversation.",2 Background,[0],[0]
"We begin with a framework for analyzing the structure of interactions in this important but understudied domain of traffic stop conversations, developed by applying a data-oriented approach to body camera footage.",3 Institutional Dialog Acts of Traffic Stops,[0],[0]
"Our goal is to create a framework that can be a tool for police departments, policy makers, and the general public to understand, assess and improve policing practices.",3 Institutional Dialog Acts of Traffic Stops,[0],[0]
We use the Voigt et al. (2017) dataset of body camera audio from 981 vehicle stops conducted by the Oakland Police Department during the month of April 2014.,3.1 Data,[0],[0]
"This amounts to 35 hours of speech, handtranscribed to 94K speaker turns and 757K words.",3.1 Data,[0],[0]
"Traffic stops possess all three characteristics of institutional talk (Heritage, 2005):",3.2 Traffic Stops as Institutional Talk,[0],[0]
i) participants’ goals are tied to their institution-relevant identity (e.g. officer & driver); ii) there are special constraints on what is allowable within the interaction; iii) there are special inferences that are particular to the context.,3.2 Traffic Stops as Institutional Talk,[0],[0]
"Table 1 presents an excerpt from a traffic stop conversation from our corpus: The officer greets the community member, gives the reason for the stop, asks about personal details, issues the sanction, and closes by encouraging safe driving.",3.2 Traffic Stops as Institutional Talk,[0],[0]
"We are interested in such recurring sequences of institutionspecific dialog acts, or institutional acts, which combine aspects of dialog acts and those of topical segments, all conditioned by the institutional context.",3.2 Traffic Stops as Institutional Talk,[0],[0]
"To develop the taxonomy of institutional dialog acts, we begin with a data-oriented exploration: identifying recurring sequences of topic segments using the (unsupervised) mixed membership Markov model (Paul, 2012).3 Figure 1 shows the topic segments assigned by a 10-topic model on the traffic stop of Table 1.",3.3 Developing the Typology,[0],[0]
"The model identified different spans of con-
3We trained the model on a subset of 541 stop transcripts from our data, exploring different numbers of topics.
versation; the officer gives the reason for the stop (orange), asks for documents (blue), collects driver information (purple), then in the end, there are spans of issuing a sanction (beige) and closing (yellow).
",3.3 Developing the Typology,[0],[0]
"While these topical assignments helpfully suggest a high-level notion of the structure of these conversations, they do not capture the specific acts officers do.",3.3 Developing the Typology,[0],[0]
"We next turned to the procedural justice literature, which highlights specific acts.",3.3 Developing the Typology,[0],[0]
"For instance, questioning the driver’s legitimacy for being somewhere (why are you here?) or driving a car (whose car is it?) are acts that trigger negative reactions in drivers (Epp et al., 2014).",3.3 Developing the Typology,[0],[0]
"On the other hand, officers introducing themselves and explaining the reasons for the stop are important procedural justice facets that communicate fairness and respect (Ramsey and Robinson, 2015).",3.3 Developing the Typology,[0],[0]
"Informed by the procedural justice literature, the President’s Task Force recommendations, and a review of the unsupervised topic segments, two of the authors manually analyzed twenty stop transcripts to identify institutional dialog acts.
",3.3 Developing the Typology,[0],[0]
"We focused on acts that tend to recur (e.g. citations), and those with procedural justice interest (e.g. reasons, introductions), teasing apart acts with similar goals but different illocutionary force (explicitly stating vs. implying the reason for the stop; or requesting to search the vehicle vs. stating that a search was being conducted).",3.3 Developing the Typology,[0],[0]
"This process resulted in an initial coding scheme of twenty two institu-
tional acts in nine categories.",3.3 Developing the Typology,[0],[0]
"We also observe that the recurring acts by community members were often in response to officers’ acts (e.g., responding to demographic questions), as their position of power gives them higher influence in shaping the conversation (Giles et al., 2007).",3.3 Developing the Typology,[0],[0]
"Hence, we focus on officer speech to capture our institutional act annotations.",3.3 Developing the Typology,[0],[0]
"From each stop transcript, we selected all officer turns (excluding those directed to the radio dispatcher), and annotated each sentence of each turn.
",3.4 Annotating Institutional Acts,[0],[0]
"In the first round, three annotators annotated the same 10 stops using the taxonomy and manual developed above with an average pair-wise interannotator agreement of κ=0.79.",3.4 Annotating Institutional Acts,[0],[0]
"We discussed the sources of disagreement, ratified the annotations, and updated the annotation manual to clarify act descriptions.",3.4 Annotating Institutional Acts,[0],[0]
"During this process, we also updated the annotation manual to include four additional institutional acts, resulting in a set of twenty five acts in eleven categories.",3.4 Annotating Institutional Acts,[0],[0]
"Table 2 presents this final typology, along with actual examples from our data.
",3.4 Annotating Institutional Acts,[0],[0]
"We then performed two subsequent rounds of three-way parallel annotations obtaining average pair-wise κ values of 0.84 and 0.88, respectively.",3.4 Annotating Institutional Acts,[0],[0]
"Once we obtained high agreement, we conducted a fourth round where each annotator annotated a separate set of 30 stops.",3.4 Annotating Institutional Acts,[0],[0]
"Stops were chosen at random from the entire corpus for each round; however, seven of the previously annotated stops were incorrectly included in the final round of annotations, resulting in a total of 113 annotated stops (7081 sentences, 4245 turns).",3.4 Annotating Institutional Acts,[0],[0]
Table 1 shows resulting labels.,3.4 Annotating Institutional Acts,[0],[0]
We now investigate whether we can train a model that can automatically detect the institutional acts during the course of a traffic stop.,4 Learning to Detect Institutional Acts,[0],[0]
"In Sections 5-7, we present an institutional act tagger, and describe three increasingly difficult evaluation settings:
1.",4 Learning to Detect Institutional Acts,[0],[0]
Using manual transcripts: We train and test an institutional act tagger on the manual transcripts.,4 Learning to Detect Institutional Acts,[0],[0]
"This task is similar to dialog act tagging (e.g., (Stolcke et al., 2006)), but it has the important distinction that it needs to captures dialog structure at the intersection of the general dialog acts
(e.g., requests, responses) and the topical structure.",4 Learning to Detect Institutional Acts,[0],[0]
Section 5 presents the experiments on building the institutional act tagger for this domain.,4 Learning to Detect Institutional Acts,[0],[0]
2.,4 Learning to Detect Institutional Acts,[0],[0]
Using ASR:,4 Learning to Detect Institutional Acts,[0],[0]
"We develop an automatic speech recognizer that works in our domain, and uses the text it generates, instead of manual transcripts, to train and test the model.",4 Learning to Detect Institutional Acts,[0],[0]
The downstream institutional act tagging framework stays the same.,4 Learning to Detect Institutional Acts,[0],[0]
"This setting is not fully automatic, as we still rely on the manually identified segments of audio where officers spoke.",4 Learning to Detect Institutional Acts,[0],[0]
"Section 6 first presents experiments on building the ASR system for this domain, and then presents results on using ASRgenerated text for institutional act tagging.",4 Learning to Detect Institutional Acts,[0],[0]
3.,4 Learning to Detect Institutional Acts,[0],[0]
"From raw audio: We build automatic means to detect the segments of officers’ speech, apply the ASR on those segments, and then use the text thus produced to detect institutional acts, building a fully automatic tagger with no human intervention.",4 Learning to Detect Institutional Acts,[0],[0]
"Section 7 first describes the experiments on detecting the officers’ speech automatically, and then presents results on institutional act tagging in this fully automatic setting.",4 Learning to Detect Institutional Acts,[0],[0]
"For all our experiments, we merge labels from all sentences in each turn, making this a multi-label (instead of multi-class) classification task.4 Only around 7% of the institutional act bearing utterances had multiple acts.",4 Learning to Detect Institutional Acts,[0],[0]
"Common co-occurrences were GREETING and REASON, and GREETING and ORDERS, e.g., Hey, turn the car off.",4 Learning to Detect Institutional Acts,[0],[0]
How you doing?,4 Learning to Detect Institutional Acts,[0],[0]
We adopt a supervised machine learning approach to the task of institutional act tagging.,5 Institutional Act Tagging from Manual Transcripts,[0],[0]
"We draw from prior work in the area of dialog act modeling, while also adding features that specifically capture the institutional context of traffic stop conversations.",5 Institutional Act Tagging from Manual Transcripts,[0],[0]
"We compared three supervised text classification methods: Support Vector Machine (SVM) (Cortes and Vapnik, 1995) and Extremely Randomized
4We present turn-level (instead of sentence-level) predictions to facilitate comparisons with experiments presented in Section 6 & 7; sentence-level experiments were performed using manual transcripts and yielded slightly better numbers.
",5.1 Algorithms,[0],[0]
"Trees (ERT) (Geurts et al., 2006),5 which are efficient and tend to work well with smaller datasets like ours, and Convolutional Neural Network (CNN) (Kim, 2014), which captures variable length patterns without feature engineering.",5.1 Algorithms,[0],[0]
"For SVM, we use the one-vs-all multi-label algorithm (ERT and CNN inherently deal with multi-label classification) and use the balanced mode to address the skewed label distribution (0.5% to 3.5% positive cases).",5.1 Algorithms,[0],[0]
"In the balanced mode, positive and negative examples are balanced at training time.",5.1 Algorithms,[0],[0]
"For CNN, we use two convolutional layers of filter sizes 3 and 4 and 20 filters with relu activation and max-pooling with pool size 2.",5.1 Algorithms,[0],[0]
"This is followed by two dense layers, and a final layer with sigmoid activation and binary cross entropy loss to handle multi-label classification.
",5.1 Algorithms,[0],[0]
"While some prior work in dialog act tagging (e.g., (Kim et al., 2010; Kim et al., 2012) have shown that sequence tagging algorithms such as conditional random fields (CRF) have some advantage over text classification approaches such as SVMs, preliminary experiments using CRFs revealed this to not be the case in our corpus.",5.1 Algorithms,[0],[0]
Lexical Features: We used unigrams and bigrams as indicator features for SVM and ERT.,5.2 Features,[0],[0]
"We initialize the input layer of CNN with word embeddings trained using our entire transcribed dataset.6
Pattern features: We use indicator features for two types of patterns.",5.2 Features,[0],[0]
"1) For each institutional act, we hand-crafted a list of linguistic patterns; e.g., the pattern feature for GREETING included how are you, hello, and good morning, among others.",5.2 Features,[0],[0]
2),5.2 Features,[0],[0]
"We use a semi-automatically built dictionary of offenses (e.g., tail light) by querying the word embedding model trained on all transcripts with a seed list of offenses, resulting in a large list of offenses and variations of their usage (e.g., break light, rear lite) with high incidence in some acts (e.g., REASON, SANCTION).
",5.2 Features,[0],[0]
"5ERT is a variant of the random forest algorithm, with the difference that the splits at each step are selected at random rather than using a preset criteria.
",5.2 Features,[0],[0]
"6In preliminary experiments, we found that SVMs using these word embeddings (or GloVe embeddings) performed worse than using ngram features directly.
",5.2 Features,[0],[0]
Structural features: 1),5.2 Features,[0],[0]
"The number of words in the utterance, since some acts (e.g., GREETING) require fewer words than others (e.g., SANCTION).",5.2 Features,[0],[0]
"We binned this feature into four bins: <3, 4-10, 11- 20, and >20. 2)",5.2 Features,[0],[0]
"The position of the utterance within the conversation (e.g., SANCTION is likely to happen late, and GREETING early), binned to one or more of: first five, first quarter, first third, first half, last half, last third, last quarter, and last five.
",5.2 Features,[0],[0]
"Other features: We tried other features such as 1) ngrams from previous utterances, 2) ngrams from driver’s responses, 3) dependency parse patterns, 4) word/sentence embeddings, and 5) topic assignments obtained from the mixed membership Markov model (Paul, 2012) discussed in Section 3.3.",5.2 Features,[0],[0]
"These features turned out not to be helpful for this task, and we do not include those results here.",5.2 Features,[0],[0]
"Table 3 presents micro-averaged (i.e., weighted average of each class) precision, recall and F-measure obtained on 10-fold cross validation.7 While ERT posted the highest precision of 80.9% at a low recall of 63.6%, SVM reported the highest recall of 76.2% without a huge dent in precision.",5.3 Experiments and Results,[0],[0]
"Overall, we obtain the best micro-averaged F-score of 77.5% using SVM.",5.3 Experiments and Results,[0],[0]
CNN performed worse than both ERT and SVM.8,5.3 Experiments and Results,[0],[0]
"We also performed an ablation study to see the relative importance of features in the SVM
7CNN: batch size of 10, dropout of 0.3, adam, 10 epochs.",5.3 Experiments and Results,[0],[0]
"SVM: C=1, linear kernel.",5.3 Experiments and Results,[0],[0]
"ERT: 100 estimators, max tree depth 75, # of features capped at 20% of all features.",5.3 Experiments and Results,[0],[0]
"Parameter values obtained using grid-search within the training set for each fold.
",5.3 Experiments and Results,[0],[0]
"8Since CNN performed much worse than SVM with lexical features alone (last row), presumably because of the small amount of data, we did not perform more CNN experiments.
model.",5.3 Experiments and Results,[0],[0]
"As expected, the ngram features contribute the most; removing them drastically lowered performance.",5.3 Experiments and Results,[0],[0]
"Patterns and structural features had a smaller impact on performance.
",5.3 Experiments and Results,[0],[0]
We inspected the weights assigned to the features by a model trained on the entire dataset.,5.3 Experiments and Results,[0],[0]
The models created for each institutional act had at least one pattern or structure feature in the top twenty five features.,5.3 Experiments and Results,[0],[0]
Figure 2 shows the feature weights assigned to the model detecting GREETING.,5.3 Experiments and Results,[0],[0]
"The model up-weighted utterances with greeting patterns (GREETINGS), first utterances (FIRST), and utterances in the first quarter (FIRSTQUART), while down-weighting longer utterances (LENGTH 11- 20) and those that mention lenience (LENIENCE).",5.3 Experiments and Results,[0],[0]
"The institutional act tagger of Section 5 relies on manual transcriptions, making it not scalable to the thousands of traffic stops conducted every month.",6 Institutional Act Tagging using ASR,[0],[0]
"We now investigate using automatic speech recognition, while assuming manual segmentation, i.e., we know the time segments where an officer spoke to the driver; in the next section we explore the additional task of automatic officer turn detection.",6 Institutional Act Tagging using ASR,[0],[0]
"Traffic stops have considerable noise (wind, traffic, horns), overlap, and difficult vocabulary (names, addresses, jargon), making it a challenging domain for off-the-shelf automatic speech recognizers (ASR).",6.1 Data Augmentation,[0],[0]
"However, our 35 hours of transcribed speech is insufficient to train a domain-specific recognizer.",6.1 Data Augmentation,[0],[0]
"We
therefore employ two data augmentation techniques.",6.1 Data Augmentation,[0],[0]
"First, we perturb our data by frame-shifting and filterbank adjustment following the procedure described in (Ko et al., 2015).",6.1 Data Augmentation,[0],[0]
"In frame-shifting, we change the starting point of each frame, making features generated from these frames slightly different from the original ones.",6.1 Data Augmentation,[0],[0]
"For filterbank adjustment, we move the locations of the center frequencies of filterbank triangular frequency bins during feature extraction.",6.1 Data Augmentation,[0],[0]
This method increases our training data 5-fold to 180 hours.,6.1 Data Augmentation,[0],[0]
"Second, we make use of the 300-hour Switchboard telephone speech dataset (Godfrey and Holliman, 1997) to create additional data.",6.1 Data Augmentation,[0],[0]
"We first upsample Switchboard speech to the 16 KHz of our data, and then mix them with noise samples randomly picked from our data where speech is not identified, using a random speech-tonoise-ratio between 0 and 10.",6.1 Data Augmentation,[0],[0]
This method contributes another 300 hours of speech for training.,6.1 Data Augmentation,[0],[0]
"We implemented two acoustic models, a Bidirectional Long Short-Term Memory network (BLSTM) (Graves et al., 2013) and a Deep Neural Net Hidden Markov Model (DNN-HMM) tri-phone baseline.",6.2 Acoustic Modeling,[0],[0]
"While LSTM based approaches generally work better, they are much slower to train, so we wanted to know if their word error improvements indeed translated to act tagger improvements.
",6.2 Acoustic Modeling,[0],[0]
"DNN-HMM system training follows the standard pipeline in the Kaldi toolkit (Povey et al., 2011; Veselý et al., 2013).",6.2 Acoustic Modeling,[0],[0]
"Frame alignments generated from a traditional Gaussian mixture model based system are used as targets and 40-dimension fMLLR features (Gales, 1998) are used as inputs to the DNN to aid speaker adaptation.",6.2 Acoustic Modeling,[0],[0]
"The network was trained using Restricted Boltzmann Machine (RBM) based pretraining (Salakhutdinov et al., 2007) and then discriminatively trained using stochastic gradient descent with cross-entropy as loss function.",6.2 Acoustic Modeling,[0],[0]
"(Veselý
et al., 2013) describes more training details.",6.2 Acoustic Modeling,[0],[0]
We trained the BLSTM using the recipe proposed by Mohamed et al. (2015).,6.2 Acoustic Modeling,[0],[0]
"The BLSTM is used to model short segments of speech (with a sliding window of 40 frames), and predict frame-level HMM states at each time frame9.",6.2 Acoustic Modeling,[0],[0]
We use 6 hidden layers and 512 LSTM cells in each direction.,6.2 Acoustic Modeling,[0],[0]
"Dropout (Srivastava et al., 2014), peephole connections (Gers et al., 2002) and gradient clipping are adopted to stabilize training (Sak et al., 2014).",6.2 Acoustic Modeling,[0],[0]
"As in DNN-HMM training, fMLLR features and frame alignments are used as inputs and targets respectively.
",6.2 Acoustic Modeling,[0],[0]
"For decoding, frame posteriors from the acoustic model are fed into a weighted finite state transducer with HMMs, context-dependent tri-phone models, a lexicon,10 and a 3-gram language model with Kneser-Ney smoothing (Kneser and Ney, 1995).",6.2 Acoustic Modeling,[0],[0]
"To mitigate language model data scarcity, we use transcriptions from the Switchboard and Fisher (Cieri et al., 2004) corpora, adding about 3.12M and 21.1M words, respectively.",6.3 Language Model Data Augmentation,[0],[0]
"Separate language models are trained on these datasets, and then interpolated with the traffic stop language model; interpolation weights were chosen by minimizing perplexity on a separate Dev set.",6.3 Language Model Data Augmentation,[0],[0]
Table 5 shows the perplexities of different language models on this Dev set.,6.3 Language Model Data Augmentation,[0],[0]
Table 4 shows statistics of the data used to build the ASR system.,6.4 Evaluating ASR Models,[0],[0]
We kept aside the 113 institutional act annotated stops from Section 3 as test set.,6.4 Evaluating ASR Models,[0],[0]
The remaining 669 stops were divided 9:1 into Train and Dev sets.,6.4 Evaluating ASR Models,[0],[0]
"The Train set also includes the 2435 recordings from the Switchboard corpora.
",6.4 Evaluating ASR Models,[0],[0]
"9Note that this recipe is different from the end-to-end approach where LSTM model takes in the whole utterance and predict phone / word outputs directly (Graves and Jaitly, 2014)
10CMU dictionary (CMUdict v0.7a) is used.
",6.4 Evaluating ASR Models,[0],[0]
Table 6 shows word error rates under different settings.,6.4 Evaluating ASR Models,[0],[0]
"Overall, we obtain relatively high error rates, largely due to the noisy environment of the audio in this domain.",6.4 Evaluating ASR Models,[0],[0]
"BLSTM performs better than DNNHMM, consistent with prior research (Mohamed et al., 2015; Sak et al., 2014).11 Interpolating Switchboard and Fisher language models provides a further boost of 0.7 percentage points.",6.4 Evaluating ASR Models,[0],[0]
We now use text generated by ASR to train and test the institutional act tagger of Section 4.,6.5 Institutional Act Tagging Experiments,[0],[0]
"To increase recall, we also made use of N-best list output from the ASR systems, collecting ngram and pattern features from the top 10 candidate transcriptions.",6.5 Institutional Act Tagging Experiments,[0],[0]
"The L1 penalty in the SVM limits the impact of the resulting noisier ngrams on precision.
",6.5 Institutional Act Tagging Experiments,[0],[0]
Table 7 presents micro-averaged F-scores.,6.5 Institutional Act Tagging Experiments,[0],[0]
BLSTM with 10Best obtained the best F-score of 65.3.,6.5 Institutional Act Tagging Experiments,[0],[0]
"While using 10Best lists only helped marginally for BLSTM, it helped the DNN enough to eliminate most of the gap in performance with BLSTMs.",6.5 Institutional Act Tagging Experiments,[0],[0]
"Our results suggest that downstream tasks with efficiency constraints could employ DNNs without a huge dent in performance by making use of NBest or lattice output.
11Note that our Test set, designed for measuring institutional act detection, consists of only police officers talking close to the camera; hence the word error rate can be lower than the Dev, which is designed to measure overall ASR performance and includes community member speech as well.",6.5 Institutional Act Tagging Experiments,[0],[0]
We now turn to the task of detecting institutional acts directly from raw body camera audio.,7 Institutional Act Tagging from Raw Audio,[0],[0]
This requires detecting spans with speech activity and distinguishing them from noise— voice activity detection—and identifying segments spoken by the police officers.,7 Institutional Act Tagging from Raw Audio,[0],[0]
Our goal is to find regions of the audio with a high probability of being officer speech.,7.1 Finding Officer Speech Segments,[0],[0]
"We could not build a standard supervised officer-versus-other classifier, because the stops contain large untranscribed regions of officer speech (we did not transcribe segments where the officer was, for example, talking to the dispatcher in the car).",7.1 Finding Officer Speech Segments,[0],[0]
"We therefore instead built a two-output classifier to discriminate between the officer and community member speech, and used a tuned threshold (0.55) on the posterior probability of officer as our voice activity detector, drawing on the intuitions of (Williams and Ellis, 1999; Verma et al., 2015) who found that posterior features on speech tasks also improved speech/nonspeech performance.",7.1 Finding Officer Speech Segments,[0],[0]
Our model is a 3-layer fully connected neural network with 1024 neurons trained with cross entropy loss.12 Figure 3 sketches the architecture.,7.1 Finding Officer Speech Segments,[0],[0]
We run the classifier on each .5 second span; (recall=.97 and precision =,7.1 Finding Officer Speech Segments,[0],[0]
".90 on the Dev set of Table 4), and then merge classifications to a single turn if adjacent spans are classified as officer speech, with a 500 ms lenience for pauses.",7.1 Finding Officer Speech Segments,[0],[0]
We now present experiments using the automatically identified officer speech segments.,7.2 Institutional Act Tagging Experiments,[0],[0]
"At training time, we use the ASR generated text using gold segments;
12Patch of 210ms with a stride of 50ms.",7.2 Institutional Act Tagging Experiments,[0],[0]
"Audio was downsampled to 16kHz, and converted to 21-dimensional magnitude mel-filterbank representation covering frequencies from 0- 8 kHz.",7.2 Institutional Act Tagging Experiments,[0],[0]
"FFT size was 512 with 10ms hop and 30ms frame size.
at test time, we use the same ASR model to generate text for the predicted segments.",7.2 Institutional Act Tagging Experiments,[0],[0]
"Since the predicted segments do not exactly match gold segments, we use a fuzzy-matching approach for evaluation.",7.2 Institutional Act Tagging Experiments,[0],[0]
"If a gold segment contains an act and an overlapping predicted segment has the same act, we consider it a true positive.",7.2 Institutional Act Tagging Experiments,[0],[0]
"If a gold segment contains an act, but none of the overlapping predicted segments have that act, it is counted as a false negative.",7.2 Institutional Act Tagging Experiments,[0],[0]
"If an act is identified in one of the predicted segments, without any of the overlapping gold segments having it, then we consider it a false positive.
",7.2 Institutional Act Tagging Experiments,[0],[0]
Table 8 presents results using this evaluation scheme.,7.2 Institutional Act Tagging Experiments,[0],[0]
"Again, BLSTM using the 10Best strategy obtained the best F-score of 59.8%.",7.2 Institutional Act Tagging Experiments,[0],[0]
Both BLSTM and DNN benefited significantly from using the 10Best likely predictions.,7.2 Institutional Act Tagging Experiments,[0],[0]
"As in the ASR experiments, the DNN substantially closes the gap in performance by using the 10Best strategy.",7.2 Institutional Act Tagging Experiments,[0],[0]
Our three previous sets of models focused on labeling each officer turn with one or more institutional acts.,8 Stop Level Act Detection,[0],[0]
"For many purposes, it suffices to ask a far simpler question: does an act occur somewhere in the traffic stop?",8 Stop Level Act Detection,[0],[0]
"From a procedural justice standpoint, for example, we want to know whether the officer explained the reason for the stop; we may not care about the turn in which the reason occurred.
",8 Stop Level Act Detection,[0],[0]
"We call this task stop-level act detection, in which each stop is labeled as a positive instance of an act if that particular act occurred in it in the gold labels.
",8 Stop Level Act Detection,[0],[0]
"Our algorithm is simple: run our best turn-based act tagger, and if the tagger labels an institutional act anywhere in the conversation, tag the conversation as having that class.13 We explore all three settings: manual segments and transcripts, manual segments with ASR, and automatic segments with ASR.
",8 Stop Level Act Detection,[0],[0]
We compare our results with a dialog-structureignorant lexical baseline: simply merge all text features (ngrams and patterns) from all the officer turns in a stop and use them to classify whether the stop did or didn’t contain an act.,8 Stop Level Act Detection,[0],[0]
"Our goal here is to see whether dialog structure is useful for this task; if so, the tagger based on dialog turns should outperform the global text classifier.
",8 Stop Level Act Detection,[0],[0]
"Table 10 shows that using the output of the turnbased classifier to do stop classification offers a huge advantage over the structure-ignorant baseline, reducing F-score error by 49% while using manual transcripts, and by 22% while applied to raw audio.
",8 Stop Level Act Detection,[0],[0]
Table 9 and Table 11 summarize the different experiments presented in Sections 4-8.,8 Stop Level Act Detection,[0],[0]
"Table 9 breaks down performance for each of the 11 acts, while Table 11 compares turn-level to stop-level results.
",8 Stop Level Act Detection,[0],[0]
"Despite our relatively small training resources (113 stops with dialog act labels, ASR and segmentation training data from one month), performance at the stop level directly from raw audio is surprisingly high.",8 Stop Level Act Detection,[0],[0]
"For instance, detecting whether or not the community member was explained the reason they were stopped—an important question for pro-
13We use the best system from each set of experiments: SVM model using ngrams, patterns, and structure features trained on manual transcripts or from the BLSTM ASR model.
",8 Stop Level Act Detection,[0],[0]
cedural justice—we obtained around 96% precision with an 84% recall from raw camera audio.,8 Stop Level Act Detection,[0],[0]
"The institutional acts that happen during a traffic stop, when they occur, and in what order are all of importance to police departments.",9 Conversation Trajectories,[0],[0]
"For instance, the President’s Task Force on 21st Century Policing recommends (and some departments require) that officers identify themselves and state the reason for the stop as an important aspect of fairness.",9 Conversation Trajectories,[0],[0]
"However,
police departments currently have no way of easily measuring how consistently such policies are carried out during traffic stops.",9 Conversation Trajectories,[0],[0]
"They also have no way to test the effectiveness of any training programs or policy updates that are meant to affect these conversations.
",9 Conversation Trajectories,[0],[0]
"In this section, we demonstrate that our institutional act tagger provides an efficient and reliable tool for departments to detect and monitor conversational patterns during traffic stops.",9 Conversation Trajectories,[0],[0]
"Specifically, we focus on conversational openings, a fundamental aspect of conversations (Schegloff and Sacks, 1973) that is also important for procedural justice (Whalen and Zimmerman, 1987; Ramsey and Robinson, 2015).",9 Conversation Trajectories,[0],[0]
"For instance, do officers start the conversations with a greeting?",9 Conversation Trajectories,[0],[0]
Are the drivers told the reason why they were stopped?,9 Conversation Trajectories,[0],[0]
"Was the reason given before or after asking for their documentation?
",9 Conversation Trajectories,[0],[0]
We first apply our high performance (78% F-score at turn level; 89% at stop level) tagging model on manual transcripts.,9 Conversation Trajectories,[0],[0]
Figure 5 shows the percentage of stops made in which each of the eleven institutional acts was present.,9 Conversation Trajectories,[0],[0]
Around 17% of stops did not provide a reason at all.,9 Conversation Trajectories,[0],[0]
"Only 69% of the stops started with a greeting, and an even smaller percentage of stops ended with a positive closing.",9 Conversation Trajectories,[0],[0]
"While these high level statistics provide a window into these con-
versations, our institutional event tagger allows us to gain deeper perspectives.
",9 Conversation Trajectories,[0],[0]
"Using the turn-level tags assigned by our system, we calculate the transition probabilities between dialog acts.",9 Conversation Trajectories,[0],[0]
"Figure 4 shows a traffic stop ‘narrative schema’ or script, extracted from the high probability transitions.",9 Conversation Trajectories,[0],[0]
"Variations from this prototypical script can be a useful tool for police departments to study how police community interactions differ across different squads, city locations, or driver characteristics like race.
",9 Conversation Trajectories,[0],[0]
"Figure 6, for example, shows different conversational paths that officers take before explaining the reason for the stop.",9 Conversation Trajectories,[0],[0]
"In over a quarter of the stops, either the reason is not given, or it is given after issuing orders or requesting documents.",9 Conversation Trajectories,[0],[0]
These violations of policing recommendations or requirements can impact the drivers’ attitude and perception of the legitimacy of the institution.,9 Conversation Trajectories,[0],[0]
"In this section, we outline some of the limitations of our work and discuss future directions of research.
",10 Discussion,[0],[0]
"First, our work is based on data from a single police department (the Oakland Police Department in the State of California) in the U.S.",10 Discussion,[0],[0]
"The schema we developed may need to be updated for it to be applicable to other police departments; especially those in other countries, where the laws, policies and culture around policing may be significantly different.
",10 Discussion,[0],[0]
"Due to the sensitive nature of the data, we will not be able to publicly release the raw annotations described in Section 3.4.",10 Discussion,[0],[0]
"However, we will release the labeling scheme for institutional acts in traffic stops, along with the annotation manual.",10 Discussion,[0],[0]
"We believe that it will serve as a starting point for future researchers working in this domain.
",10 Discussion,[0],[0]
"Like any data-oriented approach, our machine learning models may have captured the idiosyncrasies of the particular department represented in our dataset.",10 Discussion,[0],[0]
"Since we are not aware of any other police departments’ body-worn camera footage that is available for research, we have no way to guarantee that our models are directly applicable to other police departments’ data.
",10 Discussion,[0],[0]
"Our institutional act tagger enables us to perform large scale social science analyses controlling for various confounds, which is infeasible to perform using hand-labeled data.",10 Discussion,[0],[0]
"However, although our models obtain high performance in detecting individual institutional acts, it may also capture biases that exist in the data (Hopkins and King, 2010).",10 Discussion,[0],[0]
"Hence, our models should be corrected for biases before they may be used to estimate proportions in any category of stops.
",10 Discussion,[0],[0]
"In this paper, we focus on officers’ speech alone, since the conversational initiative with respect to the institutional acts lies mostly with the officer.",10 Discussion,[0],[0]
"However, drivers’ speech may also need to be taken into account sometimes; e.g., if an officer says yes to a driver’s question did you stop me for running the red light?, the officer has in fact given the reason for the stop even though their words alone don’t convey that fact.",10 Discussion,[0],[0]
"Moreover, drivers’ speech may also contribute to how the conversations are shaped.",10 Discussion,[0],[0]
"However, since the camera is further away from the driver than the officer, and since the environment is noisy, the audio quality of drivers’ speech is poor, and further work is required to extract useful information from driver’s speech.",10 Discussion,[0],[0]
"This is an important line of future work.
",10 Discussion,[0],[0]
"The video information from the body-camera footage may potentially help in the diarization and segmentation tasks, and in analyzing the effects the institutional acts have on the driver.",10 Discussion,[0],[0]
"However, since many of the stops occur at night when the video is often dark, it is not straightforward to extract useful information from them.",10 Discussion,[0],[0]
This is another direction of future work.,10 Discussion,[0],[0]
"In this paper, we developed a typology of institutional dialog acts to model the structure of police officer interactions with drivers in traffic stops.",11 Conclusion,[0],[0]
It enables a fine-grained and contextualized analysis of dialog structure that generic dialog acts fail to provide.,11 Conclusion,[0],[0]
"We built supervised taggers for detecting these institutional dialog acts from interactions captured on police body-worn cameras, achieving around 78% F-score at the turn level and 89% Fscore at the stop level.",11 Conclusion,[0],[0]
"Our tagger detects institutional acts at the stop level directly from raw bodycamera audio with 81% F-score, with even higher accuracy on important acts like giving the reason for a stop.",11 Conclusion,[0],[0]
"Finally, we use our institutional act tagger on one month’s worth of stops to extract insights about the frequency and order in which these acts occur.
",11 Conclusion,[0],[0]
The strains on police-community relations in the U.S. make it ever more important to develop insights into how conversations between police and community members are shaped.,11 Conclusion,[0],[0]
"Until now, we have not had a reliable way to understand the dynamics of these stops.",11 Conclusion,[0],[0]
"In this paper, we present a novel way to look at these conversations and gain actionable insights into their structure.",11 Conclusion,[0],[0]
"Being able to automatically extract this information directly from raw body-worn camera footage holds immense potential not only for police departments, but also for policy makers and the general public alike to understand and improve this ubiquitous institutional practice.
",11 Conclusion,[0],[0]
"The core contribution of this paper is a technical one of detecting institutional acts in the domain of traffic stops, from text and from unstructured audio files extracted from raw body-worn camera footage.",11 Conclusion,[0],[0]
"Current work aims to improve the performance of the segmentation and diarization components, with the hope of reducing some of the performance gap with our system run on gold transcripts.",11 Conclusion,[0],[0]
"We also plan to extend the preliminary analyses we describe in Section 9, for instance, studying how the different conversational paths and the presence or absence of certain acts (such as greetings or reason) shapes the rest of the conversation, including how it changes the community member’s language use.",11 Conclusion,[0],[0]
"Finally, our model allows us to study whether police training has an effect on the kinds of conversations that police officers have with the communities they serve.",11 Conclusion,[0],[0]
"We thank the anonymous reviewers as well as the action editor, Jordan Boyd-Graber, for helpful feedback on an earlier draft of this paper.",Acknowledgments,[0],[0]
"This research was supported by a John D. and Catherine T. MacArthur Foundation award granted to J.L. Eberhardt and D. Jurafsky, as well as NSF grants IIS1514268 and IIS-1159679.",Acknowledgments,[0],[0]
We also thank the City of Oakland and the Oakland Police Department for their support and cooperation in this project.,Acknowledgments,[0],[0]
We apply computational dialog methods to police body-worn camera footage to model conversations between police officers and community members in traffic stops.,abstractText,[0],[0]
"Relying on the theory of institutional talk, we develop a labeling scheme for police speech during traffic stops, and a tagger to detect institutional dialog acts (Reasons, Searches, Offering Help) from transcribed text at the turn (78% F-score) and stop (89% F-score) level.",abstractText,[0],[0]
"We then develop speech recognition and segmentation algorithms to detect these acts at the stop level from raw camera audio (81% Fscore, with even higher accuracy for crucial acts like conveying the reason for the stop).",abstractText,[0],[0]
"We demonstrate that the dialog structures produced by our tagger could reveal whether officers follow law enforcement norms like introducing themselves, explaining the reason for the stop, and asking permission for searches.",abstractText,[0],[0]
This work may therefore inform and aid efforts to ensure the procedural justice of policecommunity interactions.,abstractText,[0],[0]
Detecting Institutional Dialog Acts in Police Traffic Stops,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1573–1582 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
Stance classification is binary classification to detect whether people is supporting or against a topic.,1 Introduction,[0],[0]
"Existing approaches largely rely on labelled data collected under specific topics for learning supervised classifiers for stance classification (Mohammad et al., 2016a).",1 Introduction,[0],[0]
"At most time, apart from detecting one’s stance, we are interested in finding out the arguments behind the person’s position.",1 Introduction,[0],[0]
"Perspectives, that state people’s ideas or the facts known to one, can be contrastive, i.e. to be in favour of or against something (e.g. Brexit vs Bremain), or non-contrastive, i.e. independent discussions that share a common topic (e.g. unemployment and migration in the context of economy).
",1 Introduction,[0],[0]
"Recent years have seen increasing interests in argumentation mining which involves the automatic identification of argumentative structures, e.g., the claims and premises, and detection
of argumentative relations between claims and premises or evidences.",1 Introduction,[0],[0]
"However, learning models for argumentation mining often require text labelled with components within argumentative structures and detailed indication of argumentative relations among them.",1 Introduction,[0],[0]
"Such labelled data is expensive to obtain in practice and it is also difficult to port models trained on one domain to another.
",1 Introduction,[0],[0]
We are particularly interested in detecting different perspectives in political debates.,1 Introduction,[0],[0]
"Essentially, we would like to achieve somewhere in between stance classification and argumentation mining.",1 Introduction,[0],[0]
"Given a text document, we want to identify a speaker’s key arguments, without the use of any labelled data.",1 Introduction,[0],[0]
"For example, in debates about ‘Education’, we want to automatically extract sentences summarising the key perspectives and their arguments, e.g. ‘our education system needs to promote excellence in stem subjects’, ‘teenagers need to be taught with sexual and health education’ or ‘grammar schools promote inequality’.",1 Introduction,[0],[0]
"Similarly, if ‘Brexit’ is being discussed in terms of leaving or remaining, we want to cluster arguments into those two viewpoints.
",1 Introduction,[0],[0]
"To do this, we introduce a Latent Argument Model (LAM) which assumes that words can be separated as topic words and argument words and follow different generative routes.",1 Introduction,[0],[0]
"While topic words only involve a sampling of topics, argument words involve a joint sampling of both topics and arguments.",1 Introduction,[0],[0]
The model does not rely on labelled data as opposed to most existing approaches to stance classification or argument recognition.,1 Introduction,[0],[0]
"It is also different from cross-perspective topic models which assume the perspectives are observed (Fang et al., 2012).",1 Introduction,[0],[0]
"Quantitative and qualitative evaluations on debates from the House of Commons of United Kingdom show the utility of the approach and provide a comparison against related models.
1573",1 Introduction,[0],[0]
"Our research is related to stance classification, argument recognition and topic modelling for sentiment/perspective detection.",2 Related work,[0],[0]
"Stance detection aims to automatically detect from text whether the author is in favour of, against, or neutral towards a target.",2.1 Stance Classification,[0],[0]
"As previously reported in (Mohammad et al., 2016b), a person may express the same stance towards a target by using negative or positive language.",2.1 Stance Classification,[0],[0]
"Hence, stance detection is different from sentiment classification and sentiment features alone are not sufficient for stance detection.",2.1 Stance Classification,[0],[0]
"With the introduction of the shared task of stance detection in tweets in SemEval 2016 (Mohammad et al., 2016a), there have been increasing interests of developing various approaches for stance detection.",2.1 Stance Classification,[0],[0]
But most of them focused on building supervised classifiers from labelled data.,2.1 Stance Classification,[0],[0]
"The best performing system (Zarrella and Marsh, 2016) made use of large unlabelled data by first learning sentence representations via a hashtag prediction auxiliary task and then fine tuning these sentence representations for stance detection on several hundred labelled examples.",2.1 Stance Classification,[0],[0]
"Nevertheless, labelled data are expensive to obtain and there is a lack of portability of classifiers trained on one domain to move to another domain.",2.1 Stance Classification,[0],[0]
Closely related to stance detection is argument recognition which can be considered as a more fine-grained task that it aims to identify text segments that contain premises that are against or in support of a claim.,2.2 Argument Recognition,[0],[0]
Cabrio and Villata (2012) combined textual entailment with argumentation theory to automatically extract the arguments from online debates.,2.2 Argument Recognition,[0],[0]
Boltuzic and Šnajder (2014) trained supervised classifiers for argument extraction from their manually annotated corpus by collecting comments from online discussions about two specific topics.,2.2 Argument Recognition,[0],[0]
Sardianos et al. (2015) proposed a supervised approach based on Conditional Random Fields for argument extraction from Greek news.,2.2 Argument Recognition,[0],[0]
"Nguyen and Litman (2015) run an LDA model and post-processed the output, computing argument and domain weights for each of the topics, which were then used to extract argument and domain words.",2.2 Argument Recognition,[0],[0]
Their model outperformed traditional n-grams and lexical/syntactic rules on a collection of persuasive essays.,2.2 Argument Recognition,[0],[0]
"Lippi
and Torroni (2016a) hypothesized that vocal features of speech can improve argument mining and proposed to train supervised classifiers by combining features from both text and speech for claim detection from annotated political debates.",2.2 Argument Recognition,[0],[0]
"Apart from claim/evidence detection, there has also been work focusing on identification of argument discourse structures such as the prediction of relations among arguments or argument components (Stab and Gurevych, 2014; Peldszus and Stede, 2015).",2.2 Argument Recognition,[0],[0]
"A more recent survey of various machine learning approaches used for argumentation mining can be found in (Lippi and Torroni, 2016b).",2.2 Argument Recognition,[0],[0]
All these approaches have been largely domainspecific and rely on a small set of labelled data for supervised model learning.,2.2 Argument Recognition,[0],[0]
Topic models can be modified to detect sentiments or perspectives.,2.3 Topic Modeling for Sentiment/Perspective Detection,[0],[0]
"Lin and He (2009) introduced a joint sentiment topic (JST) model, which simultaneously extracts topics and topic-associated sentiments from text.",2.3 Topic Modeling for Sentiment/Perspective Detection,[0],[0]
Trabelsi and Zaıane (2014) proposed a joint topic viewpoint (JTV) model for the detection of latent viewpoints under a certain topic.,2.3 Topic Modeling for Sentiment/Perspective Detection,[0],[0]
"This is essentially equivalent to the reparameterized version of the JST model called REVERSE-JST (Lin et al., 2012) in which sentiment label (or viewpoint) generation is dependent on topics, as opposed to JST where topic generation is conditioned on sentiment labels.
",2.3 Topic Modeling for Sentiment/Perspective Detection,[0],[0]
"Fang et al. (2012) proposed a Cross-Perspective Topic Model (CPT) in which the generative processes for topic words (nouns) and opinion words (adjectives, adverbs and verbs) are different, as the opinion words are sampled independently from the topic.",2.3 Topic Modeling for Sentiment/Perspective Detection,[0],[0]
"Also, CPT assumed perspectives are observed, which implies texts need to be annotated with the viewpoint they belong to.",2.3 Topic Modeling for Sentiment/Perspective Detection,[0],[0]
Awadallah et al. (2012) detected politically controversial topics by creating an opinion-base of opinion holders and their views.,2.3 Topic Modeling for Sentiment/Perspective Detection,[0],[0]
Das and Lavoie (2014) observed the editions and interactions of a user in Wikipedia pages to infer topics and points of view at the same time.,2.3 Topic Modeling for Sentiment/Perspective Detection,[0],[0]
"Qiu et al. (2015) proposed a regression-based latent factor model which jointly models user arguments, interactions, and attributes for user stance prediction in online debates.",2.3 Topic Modeling for Sentiment/Perspective Detection,[0],[0]
"We assume that in a political debate, the speaker first decides on which topic she wants to comment on (e.g. Education).",3 Latent Argument Model (LAM),[0],[0]
She then takes a stance (e.g. remark the importance about stem subjects) and elaborates her stance with arguments.,3 Latent Argument Model (LAM),[0],[0]
"It is worth noting that we do not consider the temporal dimension of documents here, i.e., our model is fed with a collection of unlabeled documents without temporal order.
",3 Latent Argument Model (LAM),[0],[0]
"We use a switch variable x to denote whether a word is a background word (shared across multiple topics), a topic word (relating to a certain topic) or an argument word (expressing arguments under a specific topic).",3 Latent Argument Model (LAM),[0],[0]
"Depending on the type of word, we follow a different generative process.",3 Latent Argument Model (LAM),[0],[0]
"For each word in a document, if it is a background word, we simply sample it from the background word distribution φb; if it is a topic word, we first sample a topic z from the document-specific topic distribution θd and then sample the word from the topic-word multinomial distribution ψz shared across all documents; if it is an argument word, we need to first jointly sample the topic-argument pair, (z, a), where z comes from the existing topics already sampled for the topic words in the document and a is sampled from the topic-specific argument distribution ωz , and finally the word is sampled from the multinomial word distribution for the topic-specific argument ψz,a.",3 Latent Argument Model (LAM),[0],[0]
The argument indicator here is a latent categorical variable.,3 Latent Argument Model (LAM),[0],[0]
It can take a binary value to denote pro/con or positive/negative towards a certain topic.,3 Latent Argument Model (LAM),[0],[0]
"More generally, it could also take a value from multiple stance or perspective categories.",3 Latent Argument Model (LAM),[0],[0]
We thus propose a Latent Argument Model (LAM) shown in Figure 1.,3 Latent Argument Model (LAM),[0],[0]
"Formally, the generative process is as follows:
•",3 Latent Argument Model (LAM),[0],[0]
"Draw a distribution over the word switch variable, φ ∼ Dirichlet(γ), and background word distribution, ψb ∼ Dirichlet(βb).",3 Latent Argument Model (LAM),[0],[0]
•,3 Latent Argument Model (LAM),[0],[0]
"For each topic z ∈ {1...T}, draw a multinomial topic-word distribution ψz ∼ Dirichlet(βz).
–",3 Latent Argument Model (LAM),[0],[0]
"For each argument a ∈ {1...A} draw a multinomial topic-argument distribution ωz ∼ Dirichlet(δ) as well as a multinomial topic-argument-word distribution ψvz,a ∼ Dirichlet(βa).
",3 Latent Argument Model (LAM),[0],[0]
"• For each document d ∈ {1...D} : – Draw a multinomial topic distribution, θd ∼ Dirichlet(α).
–",3 Latent Argument Model (LAM),[0],[0]
"For each word n ∈ {1, .., Nd} in d: * Choose xd,n ∼ Multinomial(φ).",3 Latent Argument Model (LAM),[0],[0]
*,3 Latent Argument Model (LAM),[0],[0]
"If xd,n = 0, draw a background
word wd,n ∼ ψb; *",3 Latent Argument Model (LAM),[0],[0]
"If xd,n = 1, draw a topic z ∼
Multinomial(θd) and a word wd,n ∼ Multinomial(ψz);",3 Latent Argument Model (LAM),[0],[0]
"* If xd,n = 2, draw a topic z ∼ Multinomial(θd), an argument a ∼ Multinomial(ωz) and a wordwd,n ∼ Multinomial(ψaz,a).
",3 Latent Argument Model (LAM),[0],[0]
Figure 1 shows its plate representation.,3 Latent Argument Model (LAM),[0],[0]
"We use Collapsed Gibbs Sampling (Casella and George, 1992) to infer the model parameters and the latent assignments of topics and arguments, given the observed data.",3.1 Inference and Parameter Estimation,[0],[0]
Gibbs sampling is a Markov chain Monte Carlo method to iterative estimate latent parameters.,3.1 Inference and Parameter Estimation,[0],[0]
"In each iteration, a new sample of the hidden parameters is made based on the distribution of the previous epoch.",3.1 Inference and Parameter Estimation,[0],[0]
"Letting the index t = (d, n) denote the nth word in document d and the subscript −t denote a quantity that excludes data from the nth word position in document d, Λ = {α, βb, βz, βa, γ, δ}, the conditional posterior for xt is:
P (xt = r|x−t, z,a,w,Λ) ∝",3.1 Inference and Parameter Estimation,[0],[0]
{N rd}−t,3.1 Inference and Parameter Estimation,[0],[0]
+ γ {Nd}−t + 3γ · {N rwt}−t + βr∑,3.1 Inference and Parameter Estimation,[0],[0]
"w′{N rw′}−t +Wβr , (1)
where r denotes different word types, either background word, topic word or argument word.",3.1 Inference and Parameter Estimation,[0],[0]
"N rd denotes the number of words in document d assigned to the word type r, Nd is the total number of words in the document d, N rwt is the number of
times word wt is sampled from the distribution for the word type r, W is the vocabulary size.
",3.1 Inference and Parameter Estimation,[0],[0]
"For topic words, the conditional posterior for zt is:
P (zt = k|z−t,w,Λ) ∝ N−td,k + αk
N−td + ∑ k αk · N −t k,wt + βz N−tk +Wβz , (2)
where Nd,k is the number of times topic k was assigned to some word tokens in document d, Nd is the total number of words in document d,",3.1 Inference and Parameter Estimation,[0],[0]
"Nk,wt is the number of times word wt appeared in topic",3.1 Inference and Parameter Estimation,[0],[0]
"k.
For argument words, the conditional posterior for zt and at is:
P (zt = k, at = j|z−t,a−t,w,Λ) ∝",3.1 Inference and Parameter Estimation,[0],[0]
"N−td,k + αk
N−td + ∑ k αk · N −t d,k,j + δk,j N−td,k + ∑ j δk,j ·N −t k,j,wt + βv N−tk,j +Wβv ,
(3)
where Nd,k,j is the number of times a word from document d has been associated with topic k and argument j, Nk,j,wt is the number of times word wt appeared in topic k and with argument j, and Nk,j is the number of words assigned to topic k and argument j.
Once the assignments for all the latent variables are known, we can easily estimate the model parameters {θ,φ,ρ,ψb,ψz,ψa,ω}.",3.1 Inference and Parameter Estimation,[0],[0]
"We set the symmetric prior γ = 0.3, = 0.01, βb = βz = 0.01, δ = (0.05 × L)/A, where L is the average document length, A the is total number of arguments, and the value of 0.05 on average allocates 5% of probability mass for mixing.",3.1 Inference and Parameter Estimation,[0],[0]
"The asymmetric prior α is learned directly from data using maximum-likelihood estimation (Minka, 2003) and updated every 40 iterations during the Gibbs sampling procedure.",3.1 Inference and Parameter Estimation,[0],[0]
"In this paper we only consider two possible stances, hence, A = 2.",3.1 Inference and Parameter Estimation,[0],[0]
But the model can be easily extended to accommodate more than two stances or perspectives.,3.1 Inference and Parameter Estimation,[0],[0]
We set the asymmetric prior βa for the topic-argument-word distribution based on a subjectivity lexicon in hoping that contrastive perspectives can be identified based on the use of positive and negative words.,3.1 Inference and Parameter Estimation,[0],[0]
We run Gibbs sampler for 1 000 iterations and stop the iteration once the log-likelihood of the training data converges.,3.1 Inference and Parameter Estimation,[0],[0]
"Using the word type switch variable x, we could separate topic and argument words in LAM based
solely on the statistics gathered from data.",3.2 Separating Topic and Perspective Words,[0],[0]
We also explore another two methods to separate topic and argument words based on Part-of-Speech (POS) tags and with the incorporation of a subjectivity lexicon.,3.2 Separating Topic and Perspective Words,[0],[0]
"For the first variant, we adopt the similary strategy as in (Fang et al., 2012) that nouns (NOUN) are topic words; adjectives (ADJ), adverbs (ADV) and verbs (VERB) are argument words; words with other POS tags are background words.",3.2 Separating Topic and Perspective Words,[0],[0]
"Essentially, x is observed.",3.2 Separating Topic and Perspective Words,[0],[0]
"We call this model LAM POS.
",3.2 Separating Topic and Perspective Words,[0],[0]
"For the second variant, instead of assuming x is observed, we incorporate the POS tags as prior information to modify the Dirichlet prior γ for the word type switch variable at the initialization step.",3.2 Separating Topic and Perspective Words,[0],[0]
"In addition, we also consider a subjective lexicon1, L, that if a word can be found in the lexicon, then it is very likely the word is used to convey an opinion or argument, although there is still a small probability that word could be either background or topic word.",3.2 Separating Topic and Perspective Words,[0],[0]
Assuming an asymmetric Dirichlet prior for x is parametrized by γᵀ =,3.2 Separating Topic and Perspective Words,[0],[0]
"[γb, γz, γa] for background, topic and argument words, it is modified by a transformation matrix λ, γnew = λ×γᵀ, where λ is defined by:
•",3.2 Separating Topic and Perspective Words,[0],[0]
If word w ∈ L ∧ POSTAG(w),3.2 Separating Topic and Perspective Words,[0],[0]
6=,3.2 Separating Topic and Perspective Words,[0],[0]
NOUN then λᵀ =,3.2 Separating Topic and Perspective Words,[0],[0]
"[0.05, 0.05, 0.9] • else if POSTAG(w)",3.2 Separating Topic and Perspective Words,[0],[0]
"= NOUN then λᵀ = [0.05, 0.9, 0.05] • else if POSTAG(w) ∈ {ADJ,ADV,VERB} then λᵀ = [0.05, 0.05, 0.9] • else λᵀ = [0.9, 0.05, 0.05]
The conditional probability for the switch variable x is modified by simultaneously considering the POS tag g for the word at position t:
P (xt = r, yt = g|x−t, z,a,w,Λ) ∝",3.2 Separating Topic and Perspective Words,[0],[0]
{N rd}−t,3.2 Separating Topic and Perspective Words,[0],[0]
+ γ {Nd}−t + 3γ · {N rwt}−t + βr∑,3.2 Separating Topic and Perspective Words,[0],[0]
"w′{N rw′}−t +Wβr
· {N rg }+ rg
{Ng}+ ∑ g′ r g′ , (4)
where an additional term is added to the RHS of Equation 1.",3.2 Separating Topic and Perspective Words,[0],[0]
"Here, N rg denotes the number of words with POS tag g assigned to the word type r, Ng is the total number of words assigned to the POS tag g, rg is the Dirichlet prior for the POS tag-word type distribution.
",3.2 Separating Topic and Perspective Words,[0],[0]
"1In this work, we use the subjectivity lexicon presented at (Wiebe et al., 2005).
",3.2 Separating Topic and Perspective Words,[0],[0]
We call the second variant LAM LEX.,3.2 Separating Topic and Perspective Words,[0],[0]
"As both the POS tag information and the subjectivity lexicon are only incorporated in the initialisation step, LAM LEX sits in-between LAM and LAM POS that it performs soft clustering of topic words and argument words.",3.2 Separating Topic and Perspective Words,[0],[0]
"That is, during the initialisation, nouns are more likely to be topic words, but there is still a small probability that they could be either argument or background words; and similarly for words tagged as adjectives, adverts and verbs.",3.2 Separating Topic and Perspective Words,[0],[0]
Debates from the UK parliament are archived and available for consulting.2 A custom web-crawler was developed to obtain the records of every day that The House of Commons was in session between 2009 and 2016.,4 House of Common Debates (HCD),[0],[0]
"Due to inconsistencies in the data format and volume of data, much of the analysis focuses on the recordings for the parliamentary year 2014-2015.",4 House of Common Debates (HCD),[0],[0]
The general structure of a single day of recording is as follows: a question will be put to the house (generally a Bill) and Members of Parliament (MPs) will discuss various aspects regarding the Bill or show stances about it.,4 House of Common Debates (HCD),[0],[0]
Each speech made by an MP is considered to be a single document.,4 House of Common Debates (HCD),[0],[0]
Multiple Bills will be discussed each day.,4 House of Common Debates (HCD),[0],[0]
"The current item being discussed is clearly marked in the source data format, so linking documents to the current bill and MP is trivial.",4 House of Common Debates (HCD),[0],[0]
"Each speech is labelled with a major (e.g. education) and a minor topic (e.g. grammar schools) and help us create a dataset with the desired needs.
",4 House of Common Debates (HCD),[0],[0]
The length that The House will be in session varies and the number of bills discussed also varies.,4 House of Common Debates (HCD),[0],[0]
"In this paper, we considered debates occurred during March of 20153 and contains 1 992 speeches belonging to diverse domains: justice, education, energy and climate change, treasury, transport, armed forces, foreign and commonwealth office, environment, transport, royal assent, work and pensions, northern Ireland.",4 House of Common Debates (HCD),[0],[0]
"This House of Commons Debates (HCD) dataset is made available for the research community.4
We followed a standard methodology to clean the texts: stopwords were removed, lemmatization was applied, and a naive negation treatment was considered for the particle ‘not’, by creating bigrams for words occurs in the subjectivity lexicon
2https://hansard.parliament.uk 3Period of time what selected on a basis of existence of a
large number of major topics.",4 House of Common Debates (HCD),[0],[0]
"4https://github.com/aghie/lam/blob/ master/hcd.tsv
(e.g., ‘not good’ becomes ‘not good’).",4 House of Common Debates (HCD),[0],[0]
"As topic models suffer from lack of robustness if large outliers are present, we also removed very frequent (above 99%) and rare words (below percentile 65%), assuming that word occurrences of the collection follow a Zip’s law distribution.5 Similar strategy was carried out for texts, in order to just consider texts of similar length.",4 House of Common Debates (HCD),[0],[0]
The preprocessed HCD contains a total of 1 598 speeches.,4 House of Common Debates (HCD),[0],[0]
"This section evaluates LAM and its variants qualitatively and quantitatively (averaged over 5 runs).
",5 Experiments,[0],[0]
"The models for comparison are listed below:
• LDA.",5 Experiments,[0],[0]
"Latent Dirichlet Allocation (Blei et al., 2003).
",5 Experiments,[0],[0]
• CPT.,5 Experiments,[0],[0]
"The Cross-perspective Topic Model (Fang et al., 2012) assumes perspectives are observed.",5 Experiments,[0],[0]
"To be able to run this model on the political speeches, we implemented a version that can manage latent perspectives and separately sample topics and viewpoints.
",5 Experiments,[0],[0]
• JTV.,5 Experiments,[0],[0]
"Joint Topic-Viewpoint Model (Trabelsi and Zaıane, 2014) is essentially the reparameterized version of the Joint SentimentTopic (JST) model (Lin and He, 2009) called REVERSE-JST (Lin et al., 2012) in which sentiment label (or viewpoint) generation is dependent on topics.",5 Experiments,[0],[0]
"We implemented JTV as the reversed JST model.6
• LAM.",5 Experiments,[0],[0]
Latent Argument Model from §3.,5 Experiments,[0],[0]
• LAM POS.,5 Experiments,[0],[0]
"LAM with topic, argument or
background words separated by POS tags.",5 Experiments,[0],[0]
• LAM LEX.,5 Experiments,[0],[0]
"Both POS tags and a subjec-
tive lexicon are used to initialise the Dirichlet prior γ for the word type switch variable as described in §3.2.",5 Experiments,[0],[0]
Results are evaluated in terms of both topic coherence and the quality of the extracted perspectives.,5.1 Experimental Results,[0],[0]
"The CV metric7 is used to measure the coherence of the topics generated by the models as it has been shown to give the results closest to human evaluation compared to other topic coherence metrics (Röder et al., 2015).",5.1.1 Topic Coherence,[0],[0]
"In brief, given a set of words,
5Percentiles were selected on an empirical basis.",5.1.1 Topic Coherence,[0],[0]
"6We were not able to find a publicly available code of the
JTV implementation.",5.1.1 Topic Coherence,[0],[0]
"7https://github.com/AKSW/Palmetto/
it gives an intuition of how likely those words cooccur compared to expected by chance.
",5.1.1 Topic Coherence,[0],[0]
Figure 2 plots the CV results8 versus the number of topics on HCD for various models.,5.1.1 Topic Coherence,[0],[0]
"For each topic z, we extract the top ten most representative words ranked by their respective normalised discriminative score defined by DS(w, z) = P",5.1.1 Topic Coherence,[0],[0]
(w|z)/[maxz′ 6=z P (w|z′)].,5.1.1 Topic Coherence,[0],[0]
We chose this approach instead of simple P (w|z) as it was observed to turn into higher quality topics.,5.1.1 Topic Coherence,[0],[0]
"It is clear that LAM LEX models outperform baselines and that all variants are learning well the topics from the data, showing that the three different mechanisms for the switch variable are effective to generate coherent topics.",5.1.1 Topic Coherence,[0],[0]
"Also, our models work robustly under different number of topics.",5.1.1 Topic Coherence,[0],[0]
"Moreover, LAM LEX achieve better coherence scores than the original LAM and LAM POS.",5.1.1 Topic Coherence,[0],[0]
"This shows that it is more effective to use POS tags and a subjectivity lexicon to initialise the Dirichlet prior for the word type switch variable rather than simply relying on POS tags or subjectivity lexica to give hard discrimination between topic and argument words.
",5.1.1 Topic Coherence,[0],[0]
We also used the gold-standard major topic label assigned by Hansard to each speech to carry out an additional quantitative evaluation.,5.1.1 Topic Coherence,[0],[0]
"For each topic z, we extract the top ten most representative sentences ranked by their respective normalised discriminative score defined by DS(s, z) = ∑ w∈s DS(w, z)/Length(s).
",5.1.1 Topic Coherence,[0],[0]
"If a particular model is clustering robustly, the top sentences it extracts should belong to speeches
8The CV results were calculated based on the top 10 words from each topic.
",5.1.1 Topic Coherence,[0],[0]
that discuss the same topic and share the same major and/or minor topic labels in the HCD corpus.,5.1.1 Topic Coherence,[0],[0]
Table 2 shows for the studied models the percentage of sentences where x out of top 10 topic sentences belong to the same major topic.,5.1.1 Topic Coherence,[0],[0]
"The results reinforce the superior performance of the LAM LEX approach in comparison with other models.
",5.1.1 Topic Coherence,[0],[0]
"It is worth remarking that in cases where LAM LEX cluster together sentences labelled with different major topics, some clustering results are actually quite sensible.",5.1.1 Topic Coherence,[0],[0]
Table 1 illustrates it with a representative case.,5.1.1 Topic Coherence,[0],[0]
"These sentences were extracted from a cluster about farmers in which 9 out of 10 top topic sentences have “environment, food and rural affairs” as the gold major topic.",5.1.1 Topic Coherence,[0],[0]
"The only discording sentence, belonging to treasury (major topic) and infrastructure investment (minor topic), is however closely related to farmers too and it makes sense to put it into the same cluster.",5.1.1 Topic Coherence,[0],[0]
"In this section we evaluate the quality of the relation of the arguments with respect to their topics.
",5.1.2 Perspectiven Summarisation,[0],[0]
"In terms of a quantitative evaluation, we are interested in knowing how strongly the perspectives are related to their topic: it might be the case that the separate CV coherence for the topic and viewpoints is high, but there is no actual relation between them, which would be an undesirable behaviour.",5.1.2 Perspectiven Summarisation,[0],[0]
"To determine whether this is happening or not in the studied models, for each perspective we compute a mixed topic-perspective CV value, by extracting the top 5 perspective words, concatenating them with the top 5 words of the corresponding topic and running Palmetto as in the previous section.9",5.1.2 Perspectiven Summarisation,[0],[0]
"We then average the computed mixed topic-perspective CV values by T ×A. Following this methodology, a high average CV value means that the perspective words are likely to occur when discussing about that particular topic, and therefore a test of whether the model is learning perspectives that have to do with it.",5.1.2 Perspectiven Summarisation,[0],[0]
"Figure 3 compares topic-perspective models evaluated following this methodology, showing that LAM LEX gives the best overall coherence.
",5.1.2 Perspectiven Summarisation,[0],[0]
"For a better understanding of what perspectives LAM LEX is learning, we extract the top perspective sentences for a given topic based on normalised discriminative score of each sen-
9Palmetto does not accept more than 10 words.
tence10, similar to what have been done in selecting the top topic sentences.",5.1.2 Perspectiven Summarisation,[0],[0]
"In specific, we first define the discriminative score of word w under topic z and argument a by: DS(w, a, z) = P (w|z,a) maxz′ 6=z,a′ 6=a P (w|z′,a′) .",5.1.2 Perspectiven Summarisation,[0],[0]
"Then the sentence-level discriminative score is calculated based on the aggregated discriminative scores over all the words normalised by the sentence length: DS(s, z, a) =∑
w∈s DS(w, a, z)/Length(s).",5.1.2 Perspectiven Summarisation,[0],[0]
"In order to have better correspondence between topics and their respective arguments, we perform two-stage selection: first ranking sentences based on topiclevel discriminative scores DS(s,z), and then further ranking sentences based on topic-argumentlevel discriminative scores DS(s, z, a).
",5.1.2 Perspectiven Summarisation,[0],[0]
We can use these extracted top representative sentences together with the gold major topics from HCD to measure if perspectives are connected to their topic.,5.1.2 Perspectiven Summarisation,[0],[0]
"We define the label-based accuracy
10We can also rank sentences for an argument a under a topic z based on the generative probability of sentences.",5.1.2 Perspectiven Summarisation,[0],[0]
"But this consistently produce worse results.
",5.1.2 Perspectiven Summarisation,[0],[0]
"(LA) as follows: let pi be the gold major topics associated to the top 10 perspective sentences of a perspective i and let t be the gold major topics corresponding to the top 10 topic sentences; LA(t,pi) = |t∩pi||t∪pi| measures how many gold major topic labels are shared between topic and perspective sentences.",5.1.2 Perspectiven Summarisation,[0],[0]
LA also penalises the major topics that are not in common.,5.1.2 Perspectiven Summarisation,[0],[0]
Table 3 shows for different number of topics the averaged LA measure across all perspectives for three models.,5.1.2 Perspectiven Summarisation,[0],[0]
"It can be observed that LAM LEX obtains the best performance, followed by CPT.
",5.1.2 Perspectiven Summarisation,[0],[0]
To compare the quality of perspectives inferred by LAM LEX and CPT (over 30 topics) we also conducted human evaluation.,5.1.2 Perspectiven Summarisation,[0],[0]
"To do this, topics and perspectives were represented as bag-ofwords.",5.1.2 Perspectiven Summarisation,[0],[0]
Each perspective was also represented with its three most representative sentences.,5.1.2 Perspectiven Summarisation,[0],[0]
The outputs from the two models was first merged and shuffled.,5.1.2 Perspectiven Summarisation,[0],[0]
Two external annotators were then asked to answer (‘yes’ or ‘no’) for each topic if they could differentiate two perspectives.,5.1.2 Perspectiven Summarisation,[0],[0]
"Co-
hen’s Kappa coefficient (Cohen, 1968) for interannotator agreement was 0.421.",5.1.2 Perspectiven Summarisation,[0],[0]
"Table 4 shows the results of the evaluation and it is clear that LAM LEX outperforms CPT.
",5.1.2 Perspectiven Summarisation,[0],[0]
"Table 5 shows the three most representative perspective sentences for some of the extracted topics by LAM LEX and CPT, to illustrate how LAM LEX obtains more coherent sentences.11 The example involving the first topic shows a case where LAM LEX learned non-contrastive perspectives: both deal with Palestina, but focusing in different aspects (illegal settlements vs. Israel actions).",5.1.2 Perspectiven Summarisation,[0],[0]
"In contrast, CPT mixed perspectives about Israel/Palestina and other viewpoints about GCSE and mortgages.",5.1.2 Perspectiven Summarisation,[0],[0]
"In the second topic, LAM LEX ranks at the top sentences relating to Sinn Fein & Northern Ireland, that show two different stances (positive vs negative) meanwhile in CPT it is not possible to infer any clear perspective despite sentences contain semantically related terms.
",5.1.2 Perspectiven Summarisation,[0],[0]
Table 6 shows cases where LAM LEX obtained a less-coherent output according to the annotators.,5.1.2 Perspectiven Summarisation,[0],[0]
The first topic deals with Shaker Aamer and the legality of its imprisonment in Guantanamo.,5.1.2 Perspectiven Summarisation,[0],[0]
"Perspective 2 reflects this issue, but Perspective 1 includes other types of crimes.",5.1.2 Perspectiven Summarisation,[0],[0]
The second example discusses issues relating to transports.,5.1.2 Perspectiven Summarisation,[0],[0]
"While Perspective 1 is all about the negotiation with the train company, First Great Western, on its franchise extension proposal, Perspective 2 contains sentences relating to a number of different issues under transports.",5.1.2 Perspectiven Summarisation,[0],[0]
"To alleviate this problem, we hypothesise that additional levels of information (in addition to the topic and perspective levels), such as a Bill or a speaker, might be needed to better distinguish different topics and perspectives that share a significant proportion of vocabulary.",5.1.2 Perspectiven Summarisation,[0],[0]
LAM LEX gave a glimpse of the perspectives that occupy a topic.,5.1.3 Discussion,[0],[0]
"However, in many cases those differ from the initial expectation given the priors
11The examples were identified as two perspectives by at least one annotator.",5.1.3 Discussion,[0],[0]
"Its selection was made based on an existence of a similar topic both on LAM LEX and CPT outputs.
used in our model.",5.1.3 Discussion,[0],[0]
"Despite of the use of the subjectivity lexicon to initialise the Dirichlet prior βa for the topic-argument-word distribution, after a few iterations the initial distribution changes radically and turns instead into contrastive and noncontrastive perspectives, with the latter group being the most common one.",5.1.3 Discussion,[0],[0]
We think this is due to factors that involve: (1) lack of contrastive speeches about very specific topics; and (2) jargon from the House of Commons that makes the task more challenging as stances are showed in subtle and polite way.,5.1.3 Discussion,[0],[0]
"This is also in line with what has been previously observed in (Mohammad et al., 2016b) that a person may express the same stance towards a target by using negative or positive language.",5.1.3 Discussion,[0],[0]
"This shows that LAM LEX can infer perspectives from raw data, but we have little control on guiding the model on what perspectives to extract.",5.1.3 Discussion,[0],[0]
"We have presented LAM, a model able to provide a glimpse of what is going on in political debates, without relying on any labelled data and assuming the perspectives of a topic to be latent.",6 Conclusion and Future Work,[0],[0]
"It is implemented through a hierarchical Bayesian model considering that words can be separated as topic, argument or background words and follow different generative routes.",6 Conclusion and Future Work,[0],[0]
Experiments show that our model obtains more coherent topics than related approaches and also extracts more interpretable perspectives.,6 Conclusion and Future Work,[0],[0]
"The code is made available at https://github.com/aghie/lam.
",6 Conclusion and Future Work,[0],[0]
"Although LAM can extract perspectives under a certain topic, there is little control in what kind of information to extract (e.g. we might want only contrastive or non-contrastive arguments).",6 Conclusion and Future Work,[0],[0]
"In future work, we plan to improve the model through complex priors or semantic similarity strategies.",6 Conclusion and Future Work,[0],[0]
"Also, adding a ‘Bill’ level could be beneficial as speeches about the same Bill should share the same high-level topic.",6 Conclusion and Future Work,[0],[0]
But we need labels indicating to which Bill the text belongs to.,6 Conclusion and Future Work,[0],[0]
Including a ‘speaker’ level to know which parliamentarians discuss which topics is another interesting path to follow.,6 Conclusion and Future Work,[0],[0]
We thank Charles Marshall for crawling the HCD data.,Acknowledgments,[0],[0]
"DV was funded by MECD (FPU 13/01180), MINECO (FFI2014-51978-C2-2-R) and InditexUDC grants for research stays.",Acknowledgments,[0],[0]
"YH is partly
funded by the Natural Science Foundation of China (61528302).",Acknowledgments,[0],[0]
We explore how to detect people’s perspectives that occupy a certain proposition.,abstractText,[0],[0]
We propose a Bayesian modelling approach where topics (or propositions) and their associated perspectives (or viewpoints) are modeled as latent variables.,abstractText,[0],[0]
Words associated with topics or perspectives follow different generative routes.,abstractText,[0],[0]
"Based on the extracted perspectives, we can extract the top associated sentences from text to generate a succinct summary which allows a quick glimpse of the main viewpoints in a document.",abstractText,[0],[0]
"The model is evaluated on debates from the House of Commons of the UK Parliament, revealing perspectives from the debates without the use of labelled data and obtaining better results than previous related solutions under a variety of evaluations.",abstractText,[0],[0]
Detecting Perspectives in Political Debates,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 591–600, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"From 2007 on, a global crisis struck the financial markets and led to a severe slow-down of the real economy.",1 Introduction,[0],[0]
"It was triggered by the collapsing US subprime mortgage sector, where loans had been issued to borrowers with poor credit ratings.",1 Introduction,[0],[0]
"Due to the tight interconnectedness of the financial system, problems quickly propagated in the global banking system.",1 Introduction,[0],[0]
"Governments had to bail out important institutions like Northern Rock, but such
solutions could not be provided for every troubled bank.",1 Introduction,[0],[0]
"In September 2008, the large investment bank Lehman Brothers had to file bankruptcy.",1 Introduction,[0],[0]
"In the aftermath of this event, further banks had to be rescued in order to stabilize the financial system.",1 Introduction,[0],[0]
"This deep financial crisis highlighted the necessity of better financial regulation as well as more effective financial supervision in the future (Hodson and Quaglia, 2009).
",1 Introduction,[0],[0]
"As a reaction to the crisis and its severe economic consequences, EU institutions decided to build up an European Banking Union (EBU).",1 Introduction,[0],[0]
"The EBU consists of three pillars, one of them being a new system of financial supervision, the Single Supervisory Mechanism (SSM).",1 Introduction,[0],[0]
Its goal is to “promote long-term safety and soundness of credit institutions and the stability of the financial system within the Union and each Member State,1 Introduction,[0],[0]
"[...]” (Council of the EU, 2013, p. 72).
",1 Introduction,[0],[0]
"For supervising over 120 of the largest banks in the Eurozone, the SSM utilizes a range of information sources in order to detect vulnerabilities and risks.",1 Introduction,[0],[0]
"The sources include mainly backwardlooking quantitative Key Risk Indicators (KRIs), which are complemented with surveys in order to include forward-looking information as well (European Banking Authority, 2014).",1 Introduction,[0],[0]
"However, another source of information seems to be largely untapped, namely textual data published by the banks.",1 Introduction,[0],[0]
"Publications like periodic reports, press releases, and news published for investors also contain forward-looking information.",1 Introduction,[0],[0]
Analyzing this readily available data would be more cost-efficient in comparison to traditional approaches like surveys.,1 Introduction,[0],[0]
"It could provide answers to questions like: what does official communication by banks reveal about their expectations and attitudes towards risk?
",1 Introduction,[0],[0]
"In this paper, we present a novel application of sentiment analysis for exploring attitudes and opinions about risk in textual disclosures by
591
banks.",1 Introduction,[0],[0]
"In particular, this work (1) finds suitable data sources, (2) identifies appropriate techniques for risk sentiment analysis, and (3) analyzes risk sentiment within the last decade in order to cover the financial crisis of 2007-08 adequately.",1 Introduction,[0],[0]
"The derived sentiment scores quantify uncertainty, negativity, and positivity in the analyzed documents.",1 Introduction,[0],[0]
"All of them are interesting with regards to risk sentiment analysis: uncertainty relates to risk in a direct way since the latter are “uncertainties resulting in adverse variations of profitability or in losses” (Bessis, 2002, p. 11).",1 Introduction,[0],[0]
"Highly negative sentiment refers to current or future problems, and too positive sentiment could represent overconfidence.",1 Introduction,[0],[0]
"We find that sentiment scores reflect not only the financial crisis, but also other major economic events within the last decade.
",1 Introduction,[0],[0]
"In addition, we test for correlations between the sentiment scores and a popular quantitative risk indicator.",1 Introduction,[0],[0]
"It turns out that aggregated risk sentiment in forward-looking documents is a leading indicator for the actual risk figures, so it can be used within predictive models.
",1 Introduction,[0],[0]
"The remainder of this paper, which is based on the Master’s thesis of one of the authors (Nopp, 2015), is organized as follows: first, we give an overview on related work in the field of risk sentiment analysis.",1 Introduction,[0],[0]
The following section introduces the chosen sources for text data and quantitative figures.,1 Introduction,[0],[0]
"Afterwards, we give an overview on the chosen methodologies and evaluate the experimental results.",1 Introduction,[0],[0]
The last section concludes.,1 Introduction,[0],[0]
Sentiment analysis in general and its application in the financial domain in particular gained a lot of interest within the last decade.,2 Related Work,[0],[0]
There is a number of studies which aim to identify risks by means of text mining.,2 Related Work,[0],[0]
"A common question tackled by researchers is whether corporate disclosures drive stock price volatilities or future earnings of the respective firm (Groth and Muntermann, 2011; Kogan et al., 2009; Tsai and Wang, 2013).",2 Related Work,[0],[0]
"Hence, they focus on the risk an investor takes if he or she buys stocks of a company.",2 Related Work,[0],[0]
"Generally spoken, these studies find significant correlations between sentiment extracted from corporate disclosures and future volatilities.",2 Related Work,[0],[0]
"Other papers deal with financial distress prediction, for example Hajek and Olej (2013).",2 Related Work,[0],[0]
"As a baseline, they classify companies based on financial indicators.",2 Related Work,[0],[0]
"It turned
out that the inclusion of sentiment indicators improved financial distress prediction.
",2 Related Work,[0],[0]
"Among the text data sources for these studies are mainly annual reports, but also news stories or earning calls transcripts1.",2 Related Work,[0],[0]
"Kogan et al. (2009) exclude irrelevant information from the annual reports by focusing on a section which contains important forward-looking content.
",2 Related Work,[0],[0]
"In the related studies, authors work with similar approaches for extracting sentiment from texts.",2 Related Work,[0],[0]
"Linguistic preprocessing generally involves tokenization, lemmatization, and removing nonessential items like tables, exhibits, or digit sequences.",2 Related Work,[0],[0]
"In almost every study, the authors also make use of term weighting schemes.",2 Related Work,[0],[0]
"With the selected features and additional quantitative data, the studies either employ machine learning algorithms, or use the data for regression analyses.
",2 Related Work,[0],[0]
"Although none of the mentioned papers focuses on risk sentiment analysis in the banking industry, parts of their processing pipelines and approaches can be reused for this work.",2 Related Work,[0],[0]
"With regards to the selection of appropriate data sources, it can be concluded that analyzing annual reports is very popular in this field of research.",2 Related Work,[0],[0]
"Hence, these data should also be considered for the experiments of this study.",2 Related Work,[0],[0]
"In contrast to the majority of the related papers, we only use specific sections of the annual reports, namely CEO letters and outlook sections (see Section 3).
",2 Related Work,[0],[0]
"Regarding the machine learning algorithms and the incorporation of quantitative indicators, the approaches of Groth and Muntermann (2011), Kogan et al. (2009), and Hajek and Olej (2013) are a good basis for the experiments of this study.",2 Related Work,[0],[0]
All of them define the document labels based on suitable quantitative indicators.,2 Related Work,[0],[0]
"For labeling, the related studies consider the fact that text data are forwardlooking, but quantitative indicators reflect the past.",2 Related Work,[0],[0]
"Hence, the indicators are taken from one period after publication of the text data.",2 Related Work,[0],[0]
The labeled data are then used for training machine learning algorithms.,2 Related Work,[0],[0]
"Since the focus of our work lies on banks, we make use of a specific quantitative risk indicator which is not employed by related studies.",2 Related Work,[0],[0]
"In the following section, we introduce this indicator and the selected text data sources.
",2 Related Work,[0],[0]
1Earning calls are regular events where managers report about the company’s current situation and answer questions from business analysts.,2 Related Work,[0],[0]
Among this work’s aims is to test for relations between textual risk sentiment and quantitative risk indicators.,3 Data Sources,[0],[0]
"A careful selection of sources for both types of data is crucial since irrelevant ones would lead to biased conclusions.
",3 Data Sources,[0],[0]
Quantitative Risk Indicator.,3 Data Sources,[0],[0]
The selected quantitative risk indicator has to represent financial health and the general risk exposure of a bank within a specific period or at a specific point in time.,3 Data Sources,[0],[0]
"Furthermore, the data have to be (1) publicly accessible, (2) available for each analyzed bank, (3) published at least annually, and (4) comparable among the different banks.
",3 Data Sources,[0],[0]
A comparison of several quantitative risk indicators based on expert interviews revealed that only the Tier 1 Capital Ratio (T1) fulfills all criteria.,3 Data Sources,[0],[0]
The T1 is one of the most important ratios based on risk-weighted amount of the bank’s assets.,3 Data Sources,[0],[0]
"In particular, it refers to the bank’s Tier 1 capital as a percentage of its risk-weighted assets:
Tier 1 Capital Ratio = Tier 1 Capital
Risk-Weighted Assets (1)
",3 Data Sources,[0],[0]
Tier 1 capital is considered as the best form of bank capital and has to fulfill several criteria making it relatively secure.,3 Data Sources,[0],[0]
"As Cannata et al. (2012, p. 12) put it, this ratio “measures the ability of the bank to absorb losses”.",3 Data Sources,[0],[0]
"If the T1 is high, the bank acts conservatively and with a high risk buffer.",3 Data Sources,[0],[0]
"A high ratio can be achieved by either increasing the Tier 1 capital or by reducing the amount of riskweighted assets, i.e. reducing the amount of total assets or replacing them with safer ones.
",3 Data Sources,[0],[0]
"The T1 also played a major role during the 2014 EU-wide banking stress test, which was an important part of the preparation phase for the Single Supervisory Mechanism.",3 Data Sources,[0],[0]
"The stress test had the purpose to assess the resilience of large EU banks in different macroeconomic scenarios, measured by the impact on the T1.
",3 Data Sources,[0],[0]
Text Data Sources.,3 Data Sources,[0],[0]
"In order to minimize noise and to enhance the sentiment analysis validity, it is crucial to work with the documents well adapted to the task of risk sentiment analysis.",3 Data Sources,[0],[0]
"Like the quantitative risk indicators, they need to be (1) publicly accessible, (2) available for every analyzed bank, and (3) published at least annually.",3 Data Sources,[0],[0]
"In addition, for this study, the documents need to be (4) written in
the English language, (5) directly published by the bank, and (6) contain forward-looking and subjective information about the bank’s attitude and expectations towards risk.
",3 Data Sources,[0],[0]
"These criteria are best fulfilled by two types of document published in the banks’ annual reports, namely CEO letters and outlook sections.",3 Data Sources,[0],[0]
The former are carefully crafted documents which contain valuable information about the management’s opinions about risk.,3 Data Sources,[0],[0]
"Amernic et al. (2010) recognize in their study from 2010 that the word choice of managers strongly influences companies, and CEO letters are a way for communicating their attitudes and values.
",3 Data Sources,[0],[0]
"Outlook sections are usually a part of the management report, which is a textual summary of the bank’s results, its business environment, and regulatory as well as internal developments.",3 Data Sources,[0],[0]
"In their outlook on the next year, banks write about the expected macroeconomic environment, management guidelines, and priorities for the next period.",3 Data Sources,[0],[0]
"These documents might be less subjective compared to CEO letters, but they are usually more comprehensive and contain interesting forwardlooking information.
",3 Data Sources,[0],[0]
Collection of Data.,3 Data Sources,[0],[0]
"The annual reports for this work were collected via a Bloomberg Terminal, supplemented by direct downloads from bank websites.",3 Data Sources,[0],[0]
"In total, over 500 documents from 27 banks which published them between 2001 and 2013 were collected.",3 Data Sources,[0],[0]
The sample contains banks from all 12 countries which have belonged to the Eurozone at least since 2002.,3 Data Sources,[0],[0]
"This promotes comparability of the data because the banks operated in similar economic circumstances and with the same currency.
",3 Data Sources,[0],[0]
"Further data were retrieved from the online database Bankscope: the bank’s country of residence, its full name, its size measured by total assets, and its Tier 1 capital ratio at the end of each year between 2001 and 2013.",3 Data Sources,[0],[0]
"31 % of the Tier 1 capital ratios could not be directly retrieved from the database, so they had to be manually extracted from the respective annual reports.",3 Data Sources,[0],[0]
Two independent approaches are employed for the risk sentiment analysis.,4 Methodologies,[0],[0]
"First, a lexicon-based approach derives and analyzes negativity, positivity, and uncertainty in publications by banks.",4 Methodologies,[0],[0]
"The second approach aims to predict the evolution of
quantitative risk indicators by means of supervised classification.",4 Methodologies,[0],[0]
"The aim of both approaches is to assess the potential of risk sentiment analysis in banking supervision.
",4 Methodologies,[0],[0]
Creation of the Document Collection.,4 Methodologies,[0],[0]
The original documents are provided as PDF files.,4 Methodologies,[0],[0]
"For building up the collection, they have to be parsed in order to acquire plain text files containing the required sections.",4 Methodologies,[0],[0]
One method for extracting the relevant sections is to split the original PDF files according to their bookmarks and to convert them into plain text files afterwards.,4 Methodologies,[0],[0]
Another way is to convert the PDF files already in the first step and to extract the relevant sections by making use of specific tokens.,4 Methodologies,[0],[0]
"For example, a typical CEO letter is delimited by the tokens Dear Shareholders and Sincerely.",4 Methodologies,[0],[0]
"If neither of these semi-automated approaches is applicable, the extraction has to be done manually2.
",4 Methodologies,[0],[0]
Table 4 gives an overview of the number of documents in the created collection.,4 Methodologies,[0],[0]
It shows that the number of published outlook sections constantly increased between 2002 and 2008.,4 Methodologies,[0],[0]
"From 2009 on, the number was quite stable.",4 Methodologies,[0],[0]
"The number of CEO letters also increased over time, but only until 2008, when some CEOs stopped writing letters in the course of the financial crisis.",4 Methodologies,[0],[0]
"The first experiment is about analyzing sentiment scores derived from the documents by incorpo-
2This was the case for around 20 % of the documents.
",4.1 Lexicon-based Approach,[0],[0]
rating finance-specific word lists.,4.1 Lexicon-based Approach,[0],[0]
The objective of this experiment is to show how the language of forward-looking disclosures by European banks evolved within the last decade.,4.1 Lexicon-based Approach,[0],[0]
"The workflow consists of the following steps: (1) pre-processing the collected data, (2) the actual sentiment analysis which derives the scores, (3) data consolidation, and (4) data evaluation.
",4.1 Lexicon-based Approach,[0],[0]
Sentiment Tagging.,4.1 Lexicon-based Approach,[0],[0]
"In the first step of the analysis, sentiment words in the textual data are tagged.",4.1 Lexicon-based Approach,[0],[0]
"In particular, this study works with negative words (Fin-Neg), positive words (Fin-Pos), and words related to uncertainty (Fin-Unc).",4.1 Lexicon-based Approach,[0],[0]
All of these word lists are provided by Loughran and McDonald (2011).,4.1 Lexicon-based Approach,[0],[0]
"Such topic-specific word lists are necessary because many words bear a different sentiment if used in a financial context: according to Loughran and McDonald (2011), almost three quarters (73.8 %) of typically negative words cannot be considered as negative when they appear in financial texts.",4.1 Lexicon-based Approach,[0],[0]
Kearney and Liu (2014) give the examples tax and liability.,4.1 Lexicon-based Approach,[0],[0]
"These words appear in the Harvard IV Negative Word List (H4N), but are neutral when used in a financial context, e.g. in an annual report.",4.1 Lexicon-based Approach,[0],[0]
"Table 2 lists some examples for sentiment words in the financial context.
",4.1 Lexicon-based Approach,[0],[0]
Term Weighting.,4.1 Lexicon-based Approach,[0],[0]
"All terms in a document are normalized by
Nj = 1√∑m
i=0(GiLi,j)2 .",4.1 Lexicon-based Approach,[0],[0]
"(2)
",4.1 Lexicon-based Approach,[0],[0]
This equation is based on Salton and Buckley (1988) and accounts for documents of different lengths.,4.1 Lexicon-based Approach,[0],[0]
"Gi is the global weight of term i and Li,j the local weight of term i in document j. An established method for the latter is given by the following formula (Manning and Schütze, 1999, p. 543):
Li,j = { 1 + log(tfi ,j )",4.1 Lexicon-based Approach,[0],[0]
"if tfi ,j ≥ 1 0 otherwise
(3)
",4.1 Lexicon-based Approach,[0],[0]
"The term frequency is denoted as tfi,j .",4.1 Lexicon-based Approach,[0],[0]
The most popular global weight is the inverse document frequency (IDF).,4.1 Lexicon-based Approach,[0],[0]
"In
Gi = log (N dfi ) , (4)
the total number of documents is denoted by N , and dfi is the number of documents where term i occurs at least once (Salton and Buckley, 1988).
",4.1 Lexicon-based Approach,[0],[0]
Valence Shifting.,4.1 Lexicon-based Approach,[0],[0]
"In order to account for negated sentiment words, the simple negation handling algorithm proposed by Polanyi and Zaenen (2006) is implemented.",4.1 Lexicon-based Approach,[0],[0]
"If one of the three direct predecessors of a sentiment word is a negation word3, its sentiment score will be negated.",4.1 Lexicon-based Approach,[0],[0]
This is done by assigning −1 to the valence shifter variable vi of term i.,4.1 Lexicon-based Approach,[0],[0]
"If there is no negation word among the predecessors, vi is set to 1.
",4.1 Lexicon-based Approach,[0],[0]
Calculating Sentiment Scores.,4.1 Lexicon-based Approach,[0],[0]
"The documentlevel sentiment scores are calculated for three sentiment classes, namely uncertainty, positivity, and negativity.",4.1 Lexicon-based Approach,[0],[0]
"In
sc,j = ∑ i∈c Li,jGiNjvi, (5)
the term-level sentiment score is represented by the product of the term weights Li,j and Gi, the normalization factor Nj , and the valence shifter vi.",4.1 Lexicon-based Approach,[0],[0]
"The document sentiment score sc,j is the sum of the term sentiment scores which belong to the document j and the sentiment class c.
Data Consolidation and Evaluation.",4.1 Lexicon-based Approach,[0],[0]
"After calculating the sentiment scores, the data are filtered and grouped in order to prepare them for the evaluations.",4.1 Lexicon-based Approach,[0],[0]
"In particular, the data are filtered according to specific countries and grouped by year respectively by bank.",4.1 Lexicon-based Approach,[0],[0]
"For the second experiment, the documents are labeled based on a quantitative risk measure, namely the T1 dating to the end of the period referred to in the CEO letters and outlook sections.",4.2 Supervised Classification,[0],[0]
"These data are then used for training supervised classification algorithms which aim to predict the indicator’s evolution.
3The considered negation words are no, not, don’t, never, none, and neither.
",4.2 Supervised Classification,[0],[0]
"The experiment consists of three steps: (1) reading and parsing the collected data as well as assigning the class labels, (2) linguistic preprocessing and feature selection, and (3) classifying the data with Naı̈ve Bayes (NB) and Support Vector Machine (SVM).
",4.2 Supervised Classification,[0],[0]
Assigning the Class Labels.,4.2 Supervised Classification,[0],[0]
The Tier 1 capital ratio is published by banks at least once a year.,4.2 Supervised Classification,[0],[0]
"Since it is actually a continuous measure, it always strongly depends on the previous year’s ratio.",4.2 Supervised Classification,[0],[0]
"Banking supervisors like the ECB are interested in the future evolution of the ratio: if it increases, the bank acts in a less risky way, and vice versa.",4.2 Supervised Classification,[0],[0]
"Hence, appropriate labels for the supervised classification task are UP for an increasing T1, and DOWN for a decreasing one.",4.2 Supervised Classification,[0],[0]
We assume that the T1 did not change notably if the difference to the previous year is less than 0.2 percent points4.,4.2 Supervised Classification,[0],[0]
"In this case, no class label is assigned.
",4.2 Supervised Classification,[0],[0]
Preprocessing and Feature Selection.,4.2 Supervised Classification,[0],[0]
"Linguistic preprocessing comprises the removal of punctuation, numbers, single characters, and stop words.",4.2 Supervised Classification,[0],[0]
The remaining words are converted to lower case.,4.2 Supervised Classification,[0],[0]
"Furthermore, the terms are weighted according to the term weighting strategy presented in Section 4.1.
",4.2 Supervised Classification,[0],[0]
"For feature selection, two approaches are followed.",4.2 Supervised Classification,[0],[0]
The first one assumes that the sentiment words used in the lexicon-based analysis are the relevant features for this experiment.,4.2 Supervised Classification,[0],[0]
"Hence, all words which do not appear in the first experiment’s dictionaries are removed.",4.2 Supervised Classification,[0],[0]
The second approach utilizes a Snowball Stemmer to ensure that different versions of the same word are treated as equal.,4.2 Supervised Classification,[0],[0]
Its feature selection strategy is based on the concepts of document frequency (DF) and information gain (IG).,4.2 Supervised Classification,[0],[0]
"For DF, tests showed that a lower bound of 20 documents yields the best results.",4.2 Supervised Classification,[0],[0]
The objective of the IG measure is to identify those features which have the highest discriminatory power in a classification problem.,4.2 Supervised Classification,[0],[0]
"It measures the impurity of a dataset, i.e. its entropy.",4.2 Supervised Classification,[0],[0]
"If a feature is able to reduce the entropy in a data set by a large amount, its information gain is high.",4.2 Supervised Classification,[0],[0]
Such features have a relatively high ability to predict the corresponding class.,4.2 Supervised Classification,[0],[0]
"For calculating the information gain, one has to compute the entropies given the presence or absence of a feature in a data set and subtract the results from the entropy
4This affected 17 % of the data points in the sample.
of the original data set (Aggarwal and Zhai, 2012, p. 169).
",4.2 Supervised Classification,[0],[0]
Classification.,4.2 Supervised Classification,[0],[0]
The outcome of the previous steps is a set of document vectors with associated class labels.,4.2 Supervised Classification,[0],[0]
"With these data, the classification algorithms Naı̈ve Bayes (NB) and Support Vector Machine (SVM) are trained.",4.2 Supervised Classification,[0],[0]
"The latter is used in its basic version, i.e. with a linear kernel.",4.2 Supervised Classification,[0],[0]
"The performance measures are determined by employing 10-fold cross validation, which helps to avoid problems like overfitting.
",4.2 Supervised Classification,[0],[0]
"While Naı̈ve Bayes works without parameters, the linear SVM depends on the parameter C. Its optimal value of 111 was determined by conducting an automated grid search.",4.2 Supervised Classification,[0],[0]
Both experiments aim to capture attitudes and opinions about risk by analyzing CEO letters and outlook sections of Eurozone banks.,5 Evaluation of the Experiments,[0],[0]
"In this section, conclusions are drawn from the results of the experiments.",5 Evaluation of the Experiments,[0],[0]
"The outcome of the lexicon-based approach consists of sentiment scores for each document representing the degrees of uncertainty, negativity, and positivity.
",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
Evolution of Sentiment Over Time.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
Figure 1 shows how sentiment in CEO letters has been evolving since 2002.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"The evolution of sentiment in outlook sections is not depicted, but is very similar to that of CEO letters.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
The individual data points represent the arithmetic mean of the documentlevel sentiment scores for each year.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"In 2002 and 2003, CEO letters contained more negative sentiment than in the following years.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
Banks might have emphasized that the recession following the burst of the dot-com bubble was still not over and that recovery had not yet arrived.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"Between 2003 and 2006, the letters became more positive and less negative from year to year.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"The turning point was in 2006—from that time on, negativity in CEO letters rose and quadrupled within three years.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"During the same period, positive sentiment scores decreased continuously.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"The summit of these evolutions was in 2009, in the midst of the financial crisis.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"The letters in 2010 had been already much more optimistic, but negativity in-
creased in 2011 and 2012 again when CEOs recognized that the crisis was still not over.
",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
The evolution of the uncertainty scores is similar to the negative sentiment scores.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
This observation is supported by a high correlation coefficient of 0.93 between uncertainty and negativity scores.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"Since 2012, uncertainty has been decreasing quite sharply.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"This can potentially be attributed to an important and often-cited speech by ECB president Mario Draghi, who calmed the financial markets with the announcement to do “whatever it takes to preserve the Euro.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"And believe me, it will be enough”5.
",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
Another observation is that the average uncertainty scores are much lower than the average positivity and negativity scores.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"A plausible interpretation thereof is that CEOs rather use clear statements than uncertain language.
",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
Do Sentiment Scores Predict Quantitative Risk Measures?,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"A comparison of the T1 average evolution and the corresponding sentiment scores reveals interesting relations, see Figure 2.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"The correlation coefficients in Table 3 indicate that a higher degree of uncertainty or negativity in the documents is commonly followed by a higher increase of the T1, and vice versa.
",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
It is interesting to analyze the data by a regression model for predicting the T1 evolution.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
Table 4 shows such a model with negativity as the only explaining variable.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"The coefficients can be interpreted as follows: if the average negativity score rises by one unit, the T1 evolution increases by 0.9963 pp.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"If negativity is zero, the Tier 1 capital ratio would decrease by the computed intercept, which is -0.502 pp.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"Both coefficients are statistically significant if a 95 % confidence level is assumed.
",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
About 76 % of the average T1 evolution’s variation can be explained by the negativity score.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
A model of similar quality could be constructed by analyzing uncertainty in outlook sections.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"Hence, sentiment scores can be considered as an additional leading indicator for the future evolution of the Tier 1 capital ratio.
Limitations.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"A drawback of this regression model is that it cannot model external shocks which influence the T1 evolution, but are not ad-
5A transcript of this speech is available at https://www.ecb.europa.eu/press/key/ date/2012/html/sp120726.en.html, accessed April 20th, 2015.
equately covered in the text data.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
Examples for such shocks would be new regulations concerning the minimum capital ratio or monetary policy actions by the ECB.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"A further limitation is induced by the fact that our methodology makes use of the bag of words (BoW) model, which ignores the documents internal structure.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"Hence, it is not possible to utilize information like word order and grammar, although this definitely plays a role in carefully crafted documents like CEO letters.
",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
It should also be emphasized that the model is based on figures aggregated by year.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
Applying it on the data of individual banks could lead to incorrect conclusions.,5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"This assumption is supported by Figure 3, which compares negativity scores of individual outlook sections with the associated T1 evolutions.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"Although it is still possible to identify a positive relationship between the variables, the variance is too big for satisfactory representation by a regression model6.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
"This observation is in line with the relatively high standard deviations if the figures are aggregated by year, see Figure 2.",5.1 Evaluation of the Lexicon-based Approach,[0],[0]
The supervised classification experiment aims to assess whether this approach works better than the lexicon-based approach in terms of predicting the T1 evolution for individual banks based on their CEO letters or outlook sections.,5.2 Evaluation of the Supervised Classification Approach,[0],[0]
The class labels UP and DOWN have been assigned according to the direction of the T1 evolution.,5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"Table 5 gives an overview of the experiments and lists
6If the regression model is built with non-aggregated data, it explains only 6.6 % of the variation.
",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
the respective performance measures.,5.2 Evaluation of the Supervised Classification Approach,[0],[0]
An analysis of the data in the table reveals interesting results.,5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"First, feature selection based on document frequency and information gain works better than the approach based on word lists.",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"Second, the classifiers trained with CEO letters yield better results than the ones trained with outlook sections.",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"Finally, three out of the four SVM results are not meaningful due to the following reason: the parameter optimization of C suggests to choose a very low value, which indeed maximizes the classifier accuracy—but these SVMs simply assign the class UP to every instance.",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
These classifiers can be seen as a baseline for comparisons.,5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"However, the remaining SVM clearly yields the best results among the employed algorithms.
",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
None of the classifiers based on the feature selection method (1) is able to outperform the baseline (assigning every instance to the UP class).,5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"Both SVMs simply classify every instance as UP, and the Naı̈ve Bayes classifiers also deliver unsatisfactory results.",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"Feature selection based on document frequency and information gain achieves better results than the first one, but only when the classifiers are trained with the CEO letter collection.",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"Most likely, this can be explained with the fact that outlook sections provide less terms with discriminatory power than CEO letters.",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"Naı̈ve Bayes correctly classifies 75 % of the instances, and the optimized SVM yields 79.2 %.",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
The other SVM performance measures can be interpreted as follows: 81 % of the instances classified as UP were indeed instances where the Tier 1 capital ratio increased (= precision U).,5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"Furthermore, the SVM correctly identified almost 92 % of the instances which belong to the class UP (= recall U).
",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
These results are better than the baseline and demonstrate a noticeable potential for supervised classification even at the level of individual bank disclosures.,5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"Nevertheless, they are not good enough for reliable predictions.",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"However, the aggregated classification data accurately predict whether the majority of banks will increase or decrease their Tier 1 capital ratio in the following year: for 12 out of 13 years, the algorithm correctly predicts the direction of the T1 evolution.",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
"This finding is in line with the lexicon-based approach, where the aggregated data yielded much better results than the individual ones.",5.2 Evaluation of the Supervised Classification Approach,[0],[0]
This study explored how banking supervisors could utilize sentiment analysis for risk assessments.,6 Conclusion,[0],[0]
"The analysis of potential document types revealed that two sections in a bank’s annual report are particularly well suited for this work, namely CEO letters and outlook sections.",6 Conclusion,[0],[0]
The former represent the tone from the top and provide subjective information about the bank’s current and future situation.,6 Conclusion,[0],[0]
Outlook sections are exclusively forward-looking and reveal opinions about the near future.,6 Conclusion,[0],[0]
"Furthermore, the Tier 1 capital ratio (T1) is the best suited quantitative risk indicator.",6 Conclusion,[0],[0]
"The T1 sets the most secure forms of bank capital in relation to its risk-weighted assets and is widely used in banking supervision, e.g. as a key ratio for the ECB’s stress test in fall 2014.
",6 Conclusion,[0],[0]
The lexicon-based analysis showed that sentiment scores reflect major economic events between 2002 and 2014 very well.,6 Conclusion,[0],[0]
"In addition, there is a strong correlation between uncertainty, negativity, and the Tier 1 capital ratio evolution over time.",6 Conclusion,[0],[0]
"Hence, the sentiment scores could be used in regression models for predicting the T1 evolution.",6 Conclusion,[0],[0]
"However, the results are only meaningful if the figures are aggregated by year.",6 Conclusion,[0],[0]
Applying the model on data of individual banks leads to inaccurate results.,6 Conclusion,[0],[0]
It should also be noted that this method is not meant to be used as a stand-alone estimator for the T1 evolution.,6 Conclusion,[0],[0]
"Instead, it should be combined with other estimation methods.
",6 Conclusion,[0],[0]
The supervised risk classification approach correctly classifies 79.2 % of the CEO letters.,6 Conclusion,[0],[0]
This is not good if one considers that it is possible to yield an accuracy of 70 % simply by assigning the class UP to every instance.,6 Conclusion,[0],[0]
"However, if the results of the best SVM classifier are aggregated by year, the data correctly predict for 12 out of 13 years whether the majority of banks will increase or decrease their Tier 1 capital ratio.
",6 Conclusion,[0],[0]
"The described systems have the potential to provide valuable insights for banking supervisors, in particular because of the strong correlation between sentiment scores derived from textual data and the T1.",6 Conclusion,[0],[0]
"Because of the mentioned limitations, these techniques should only be used for macroprudential analyses, i.e. the promotion of stability in the whole financial system.",6 Conclusion,[0],[0]
Examples are predictions for the average Tier 1 capital ratio’s evolution in the whole Eurozone or in groups of countries.,6 Conclusion,[0],[0]
"Another option is to improve existing risk prediction frameworks.
",6 Conclusion,[0],[0]
"For future research, it would be interesting to validate the results by conducting the study on a larger scale.",6 Conclusion,[0],[0]
"One could incorporate data from all European banks, or from other regions.",6 Conclusion,[0],[0]
"The approach could also be used for other document types, for example analyst reports or internal memos, or in other industries.",6 Conclusion,[0],[0]
"Regarding the methodology, it would be interesting to see how alternative algorithms or word lists would affect the results.",6 Conclusion,[0],[0]
"In November 2014, the European Central Bank (ECB) started to directly supervise the largest banks in the Eurozone via the Single Supervisory Mechanism (SSM).",abstractText,[0],[0]
"While supervisory risk assessments are usually based on quantitative data and surveys, this work explores whether sentiment analysis is capable of measuring a bank’s attitude and opinions towards risk by analyzing text data.",abstractText,[0],[0]
"For realizing this study, a collection consisting of more than 500 CEO letters and outlook sections extracted from bank annual reports is built up.",abstractText,[0],[0]
"Based on these data, two distinct experiments are conducted.",abstractText,[0],[0]
"The evaluations find promising opportunities, but also limitations for risk sentiment analysis in banking supervision.",abstractText,[0],[0]
"At the level of individual banks, predictions are relatively inaccurate.",abstractText,[0],[0]
"In contrast, the analysis of aggregated figures revealed strong and significant correlations between uncertainty or negativity in textual disclosures and the quantitative risk indicator’s future evolution.",abstractText,[0],[0]
Risk sentiment analysis should therefore rather be used for macroprudential analyses than for assessments of individual banks.,abstractText,[0],[0]
Detecting Risks in the Banking System by Sentiment Analysis,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1173–1182 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1173",text,[0],[0]
"Conditional neural sequence modeling has become a de facto standard in a variety of tasks (see, e.g., Cho et al., 2015, and references therein).",1 Introduction,[0],[0]
Much of this recent success is built on top of autoregressive sequence models in which the probability of a target sequence is factorized as a product of conditional probabilities of next symbols given all the preceding ones.,1 Introduction,[0],[0]
"Despite its success, neural autoregressive modeling has its weakness in decoding, i.e., finding the most likely sequence.",1 Introduction,[0],[0]
"Because of intractability, we must resort to suboptimal approximate decoding, and due to its sequential nature, decoding cannot be easily parallelized and results in a large latency (see, e.g., Cho, 2016).",1 Introduction,[0],[0]
"This has motivated the recent investigation into non-autoregressive neural sequence modeling by Gu et al. (2017) in the context of machine translation and Oord et al. (2017) in the context of speech synthesis.
",1 Introduction,[0],[0]
"In this paper, we propose a non-autoregressive neural sequence model based on iterative refinement, which is generally applicable to any sequence generation task beyond machine translation.",1 Introduction,[0],[0]
"The proposed model can be viewed as both
⇤ Equal Contribution
a latent variable model and a conditional denoising autoencoder.",1 Introduction,[0],[0]
We thus propose a learning algorithm that is hybrid of lowerbound maximization and reconstruction error minimization.,1 Introduction,[0],[0]
"We further design an iterative inference strategy with an adaptive number of steps to minimize the generation latency without sacrificing the generation quality.
",1 Introduction,[0],[0]
"We extensively evaluate the proposed conditional non-autoregressive sequence model and compare it against the autoregressive counterpart, using the state-of-the-art Transformer (Vaswani et al., 2017), on machine translation and image caption generation.",1 Introduction,[0],[0]
"In the case of machine translation, the proposed deterministic nonautoregressive models are able to decode approximately 2 3⇥ faster than beam search from the autoregressive counterparts on both GPU and CPU, while maintaining 90-95% of translation quality on IWSLT’16 En$De, WMT’16 En$Ro and WMT’14 En$De.",1 Introduction,[0],[0]
"On image caption generation, we observe approximately 3⇥ and 5⇥ faster decoding on GPU and CPU, respectively, while maintaining 85% of caption quality.1",1 Introduction,[0],[0]
Sequence modeling in deep learning has largely focused on autoregressive modeling.,2 Non-Autoregressive Sequence Models,[0],[0]
"That is, given a sequence Y = (y1, . . .",2 Non-Autoregressive Sequence Models,[0],[0]
", yT ), we use some form of a neural network to parametrize the conditional distribution over each variable yt given all the preceding variables, i.e.,
log p(yt|y<t) = f✓(y<t),
where f✓ is for instance a recurrent neural network.",2 Non-Autoregressive Sequence Models,[0],[0]
"This approach has become a de facto standard in language modeling (Mikolov et al.,
1 We release the implementation, preprocessed datasets as well as trained models online at https://github.com/ nyu-dl/dl4mt-nonauto.
2010).",2 Non-Autoregressive Sequence Models,[0],[0]
"When this is conditioned on an extra variable X , it becomes a conditional sequence model log p(Y |X) which serves as a basis on which many recent advances in, e.g., machine translation (Bahdanau et al., 2014; Sutskever et al., 2014; Kalchbrenner and Blunsom, 2013) and speech recognition (Chorowski et al., 2015; Chiu et al., 2017) have been made.
",2 Non-Autoregressive Sequence Models,[0],[0]
"Despite the recent success, autoregressive sequence modeling has a weakness due to its nature of sequential processing.",2 Non-Autoregressive Sequence Models,[0],[0]
"This weakness shows itself especially when we try to decode the most likely sequence from a trained model, i.e.,
ˆ Y",2 Non-Autoregressive Sequence Models,[0],[0]
"= argmax Y log p(Y |X).
",2 Non-Autoregressive Sequence Models,[0],[0]
"There is no known polynomial algorithm for solving it exactly, and practitioners have relied on approximate decoding algorithms (see, e.g., Cho, 2016; Hoang et al., 2017).",2 Non-Autoregressive Sequence Models,[0],[0]
"Among these, beam search has become the method of choice, due to its superior performance over greedy decoding, which however comes with a substantial computational overhead (Cho, 2016).
",2 Non-Autoregressive Sequence Models,[0],[0]
"As a solution to this issue of slow decoding, two recent works have attempted non-autoregressive sequence modeling.",2 Non-Autoregressive Sequence Models,[0],[0]
"Gu et al. (2017) have modified the Transformer (Vaswani et al., 2017) for non-autoregressive machine translation, and Oord et al. (2017) a convolutional network (Oord et al., 2016) for non-autoregressive modeling of waveform.",2 Non-Autoregressive Sequence Models,[0],[0]
"Non-autoregressive modeling factorizes the distribution over a target sequence given a source into a product of conditionally independent perstep distributions:
p(Y |X) = TY
t=1
p(yt|X),
breaking the dependency among the target variables across time.",2 Non-Autoregressive Sequence Models,[0],[0]
"This allows us to trivially find the most likely target sequence by taking argmaxyt p(yt|X) for each t, effectively bypassing the computational overhead and suboptimality of decoding from an autoregressive sequence model.
",2 Non-Autoregressive Sequence Models,[0],[0]
"This desirable property of exact and parallel decoding however comes at the expense of potential performance degradation (Kaiser and Bengio, 2016).",2 Non-Autoregressive Sequence Models,[0],[0]
"The potential modeling gap, which is the gap between the underlying, true model and the neural sequence model, could be larger with the
non-autogressive model compared to the autoregressive one due to challenge of modeling the factorized conditional distribution above.",2 Non-Autoregressive Sequence Models,[0],[0]
"Similarly to two recent works (Oord et al., 2017; Gu et al., 2017), we introduce latent variables to implicitly capture the dependencies among target variables.",3.1 Latent variable model,[0],[0]
"We however remove any stochastic behavior by interpreting this latent variable model, introduced immediately below, as a process of iterative refinement.
",3.1 Latent variable model,[0],[0]
"Our goal is to capture the dependencies among target symbols given a source sentence without auto-regression by introducing L intermediate random variables and marginalizing them out:
p(Y |X) =",3.1 Latent variable model,[0],[0]
"X
Y 0,...,Y L
TY
t=1
p(yt|Y L, X) !
",3.1 Latent variable model,[0],[0]
"(1)
TY
t=1
p(y L t |Y L 1, X)
! ·",3.1 Latent variable model,[0],[0]
"· · TY
t=1
p(y 0 t |X)
! .
",3.1 Latent variable model,[0],[0]
"Each product term inside the summation is modelled by a deep neural network that takes as input a source sentence and outputs the conditional distribution over the target vocabulary V for each t.
Deterministic Approximation",3.1 Latent variable model,[0],[0]
The marginalization in Eq.,3.1 Latent variable model,[0],[0]
(1) is intractable.,3.1 Latent variable model,[0],[0]
"In order to avoid this issue, we consider two approximation strategies; deterministic and stochastic approximation.",3.1 Latent variable model,[0],[0]
"Without loss of generality, let us consider the case of single intermediate latent variable, that is L = 1.",3.1 Latent variable model,[0],[0]
"In the deterministic case, we set ŷ0t to the most likely value according to its distribution p(y0t |X), that is ŷ0t = argmaxy0t p(y 0 t |X).",3.1 Latent variable model,[0],[0]
"The entire lower bound can then be written as:
log p(Y |X)
TX
t=1
log p(yt| ˆY",3.1 Latent variable model,[0],[0]
"L, X) !",3.1 Latent variable model,[0],[0]
"+ · · ·
+
TX
t=1
log p(y 1 t | ˆY 0, X)
!",3.1 Latent variable model,[0],[0]
"+ TX
t=1
log p(ŷ 0 t |X)
! .
",3.1 Latent variable model,[0],[0]
Stochastic Approximation,3.1 Latent variable model,[0],[0]
"In the case of stochastic approximation, we instead sample ŷ0t from the distribution p(y0t |X).",3.1 Latent variable model,[0],[0]
This results in the unbiased estimate of the marginal log-probability log p(Y |X).,3.1 Latent variable model,[0],[0]
"Other than the difference in whether
most likely values or samples are used, the remaining steps are identical.
",3.1 Latent variable model,[0],[0]
Latent Variables,3.1 Latent variable model,[0],[0]
"Although the intermediate random variables could be anonymous, we constrain them to be of the same type as the output Y is, in order to share an underlying neural network.",3.1 Latent variable model,[0],[0]
"This constraint allows us to view each conditional p(Y
l| ˆY",3.1 Latent variable model,[0],[0]
"l 1, X)",3.1 Latent variable model,[0],[0]
as a single-step of refinement of a rough target sequence ˆY,3.1 Latent variable model,[0],[0]
l 1.,3.1 Latent variable model,[0],[0]
The entire chain of L conditionals is then the L-step iterative refinement.,3.1 Latent variable model,[0],[0]
"Furthermore, sharing the parameters across these refinement steps enables us to dynamically adapt the number of iterations per input X .",3.1 Latent variable model,[0],[0]
"This is important as it substantially reduces the amount of time required for decoding, as we see later in the experiments.
",3.1 Latent variable model,[0],[0]
"Training For each training pair (X,Y ⇤), we first approximate the marginal log-probability.",3.1 Latent variable model,[0],[0]
"We then minimize
JLVM(✓) = L+1X
l=0
TX
t=1
log p✓(y ⇤ t | ˆY",3.1 Latent variable model,[0],[0]
"l 1, X)
!",3.1 Latent variable model,[0],[0]
",
(2)
where ˆY l 1 = (ŷl 11 , . . .",3.1 Latent variable model,[0],[0]
", ŷ",3.1 Latent variable model,[0],[0]
"l 1 T ), and ✓ is a set of parameters.",3.1 Latent variable model,[0],[0]
"We initialize ŷ0t (t-th target word in the first iteration) as xt0 , where t0 = (T 0/T ) · t. T 0 and T are the lengths of the source X and target Y ⇤, respectively.",3.1 Latent variable model,[0],[0]
The proposed approach could instead be viewed as learning a conditional denoising autoencoder which is known to capture the gradient of the logdensity.,3.2 Denoising Autoencoder,[0],[0]
"That is, we implicitly learn to find a direction Y in the output space that maximizes the underlying true, data-generating distribution logP (Y |X).",3.2 Denoising Autoencoder,[0],[0]
"Because the output space is discrete, much of the theoretical analysis by Alain and Bengio (2014) are not strictly applicable.",3.2 Denoising Autoencoder,[0],[0]
"We however find this view attractive as it serves as an alternative foundation for designing a learning algorithm.
",3.2 Denoising Autoencoder,[0],[0]
"Training We start with a corruption process C(Y |Y ⇤), which introduces noise to the correct output Y ⇤.",3.2 Denoising Autoencoder,[0],[0]
"Given the reference translation Y ⇤, we sample ˜Y ⇠ C(Y |Y ⇤) which becomes as an input to each conditional in Eq.",3.2 Denoising Autoencoder,[0],[0]
(1).,3.2 Denoising Autoencoder,[0],[0]
"Then, the goal of learning is to maximize the log-probability of the original reference Y ⇤ given the corrupted version.",3.2 Denoising Autoencoder,[0],[0]
"That is, to minimize
JDAE(✓) = TX
t=1
log p✓(y ⇤ t | ˜Y ,X).",3.2 Denoising Autoencoder,[0],[0]
"(3)
Once this cost JDAE is minimized, we can recursively perform the maximum-a-posterior inference, i.e., ˆY = argmaxY log p✓(Y |X), to find ˆY that (approximately) maximizes log p(Y |X).
",3.2 Denoising Autoencoder,[0],[0]
Corruption Process C,3.2 Denoising Autoencoder,[0],[0]
"There is little consensus on the best corruption process for a sequence, especially of discrete tokens.",3.2 Denoising Autoencoder,[0],[0]
"In this work, we use a corruption process proposed by Hill et al. (2016), which has recently become more widely adopted (see, e.g., Artetxe et al., 2017; Lample et al., 2017).",3.2 Denoising Autoencoder,[0],[0]
Each y⇤t in a reference target Y ⇤,3.2 Denoising Autoencoder,[0],[0]
=,3.2 Denoising Autoencoder,[0],[0]
"(y
⇤ 1, . . .",3.2 Denoising Autoencoder,[0],[0]
", y ⇤ T ) is corrupted with a probability
2 [0, 1].",3.2 Denoising Autoencoder,[0],[0]
"If decided to corrupt, we either (1) replace y⇤t+1 with this token y⇤t , (2) replace y⇤t with a token uniformly selected from a vocabulary of all unique tokens at random, or (3) swap y⇤t and y⇤t+1.",3.2 Denoising Autoencoder,[0],[0]
This is done sequentially from y⇤1 until y⇤T .,3.2 Denoising Autoencoder,[0],[0]
"Cost function Although it is possible to train the proposed non-autoregressive sequence model using either of the cost functions above (JLVM or JDAE,) we propose to stochastically mix these two cost functions.",3.3 Learning,[0],[0]
We do so by randomly replacing each term ˆY,3.3 Learning,[0],[0]
l 1 in Eq.,3.3 Learning,[0],[0]
(2) with ˜Y in Eq.,3.3 Learning,[0],[0]
"(3):
J(✓) = L+1X
l=0
↵l
TX
t=1
log p✓(y ⇤ t | ˆY",3.3 Learning,[0],[0]
"l 1, X) (4)
+(1 ↵l) TX
t=1
log p✓(y ⇤ t | ˜Y ,X)
!",3.3 Learning,[0],[0]
",
where ˜Y ⇠ C(Y |Y ⇤), and ↵l is a sample from a Bernoulli distribution with the probability pDAE.",3.3 Learning,[0],[0]
pDAE is a hyperparameter.,3.3 Learning,[0],[0]
"As the first conditional p(Y
0|X) in Eq. (1) does not take as input any target Y , we set ↵0 = 1 always.
",3.3 Learning,[0],[0]
"Distillation Gu et al. (2017), in the context of machine translation, and Oord et al. (2017), in the context of speech generation, have recently discovered that it is important to use knowledge distillation (Hinton et al., 2015; Kim and Rush, 2016) to successfully train a non-autoregressive sequence model.",3.3 Learning,[0],[0]
"Following Gu et al. (2017), we also use knowledge distillation by replacing the reference target Y ⇤ of each training example
(X,Y ⇤ ) with a target Y AR generated from a welltrained autoregressive counterpart.",3.3 Learning,[0],[0]
"Other than this replacement, the cost function in Eq (4) and the model architecture remain unchanged.
",3.3 Learning,[0],[0]
"Target Length Prediction One difference between the autoregressive and non-autoregressive models is that the former naturally models the length of a target sequence without any arbitrary upper-bound, while the latter does not.",3.3 Learning,[0],[0]
"It is hence necessary to separately model p(T |X), where T is the length of a target sequence, although during training, we simply use the length of each reference target sequence.",3.3 Learning,[0],[0]
Inference in the proposed approach is entirely deterministic.,3.4 Inference: Decoding,[0],[0]
We start from the input X and first predict the length of the target sequence ˆT = argmaxT log p(T |X).,3.4 Inference: Decoding,[0],[0]
"Then, given X and ˆT we generate the initial target sequence by ŷ0t = argmaxyt log p(y0t |X), for t = 1, . . .",3.4 Inference: Decoding,[0],[0]
", T We continue refining the target sequence by ŷlt = argmaxyt log p(ylt| ˆY",3.4 Inference: Decoding,[0],[0]
"l 1, X), for t = 1, . . .",3.4 Inference: Decoding,[0],[0]
", T .
",3.4 Inference: Decoding,[0],[0]
"Because these conditionals, except for the initial one, are modeled by a single, shared neural network, this refinement can be performed as many iterations as necessary until a predefined stopping criterion is met.",3.4 Inference: Decoding,[0],[0]
"A criterion can be based either on the amount of change in a target sequence after each iteration (i.e., D( ˆY l 1, ˆY l)  ✏), or on the amount of change in the conditional log-probabilities (i.e., | log p( ˆY l 1|X) log p( ˆY l 1|X)|  ✏) or on the computational budget.",3.4 Inference: Decoding,[0],[0]
"In our experiments, we use the first criterion and use Jaccard distance as our distance function D.",3.4 Inference: Decoding,[0],[0]
"Non-Autoregressive Neural Machine Translation Schwenk (2012) proposed a continuousspace translation model to estimate the conditional distribution over a target phrase given a source phrase, while dropping the conditional dependencies among target tokens.",4 Related Work,[0],[0]
The evaluation was however limited to reranking and to short phrase pairs (up to 7 words on each side) only.,4 Related Work,[0],[0]
"Kaiser and Bengio (2016) investigated neural GPU (Kaiser and Sutskever, 2015), for machine translation.",4 Related Work,[0],[0]
"They evaluated both non-autoregressive and autoregressive approaches, and found that the non-
autoregressive approach significantly lags behind the autoregressive variants.",4 Related Work,[0],[0]
It however differs from our approach that each iteration does not output a refined version from the previous iteration.,4 Related Work,[0],[0]
The recent paper by Gu et al. (2017) is most relevant to the proposed work.,4 Related Work,[0],[0]
They similarly introduced a sequence of discrete latent variables.,4 Related Work,[0],[0]
"They however use supervised learning for inference, using the word alignment tool (Dyer et al., 2013).",4 Related Work,[0],[0]
"To achieve the best result, Gu et al. (2017) stochastically sample the latent variables and rerank the corresponding target sequences with an external, autoregressive model.",4 Related Work,[0],[0]
"This is in contrast to the proposed approach which is fully deterministic during decoding and does not rely on any extra reranking mechanism.
",4 Related Work,[0],[0]
"Parallel WaveNet Simultaneously with Gu et al. (2017), Oord et al. (2017) presented a nonautoregressive sequence model for speech generation.",4 Related Work,[0],[0]
"They use inverse autoregressive flow (IAF, Kingma et al., 2016) to map a sequence of independent random variables to a target sequence.",4 Related Work,[0],[0]
"They apply the IAF multiple times, similarly to our iterative refinement strategy.",4 Related Work,[0],[0]
"Their approach is however restricted to continuous target variables, while the proposed approach in principle could be applied to both discrete and continuous variables.
",4 Related Work,[0],[0]
Post-Editing for Machine Translation Novak et al. (2016) proposed a convolutional neural network that iteratively predicts and applies token substitutions given a translation from a phasebased translation system.,4 Related Work,[0],[0]
"Unlike their system, our approach can edit an intermediate translation with a higher degree of freedom.",4 Related Work,[0],[0]
"QuickEdit (Grangier and Auli, 2017) and deliberation network (Xia et al., 2017) incorporate the idea of refinement into neural machine translation.",4 Related Work,[0],[0]
Both systems consist of two autoregressive decoders.,4 Related Work,[0],[0]
The second decoder takes into account the translation generated by the first decoder.,4 Related Work,[0],[0]
"We extend these earlier efforts by incorporating more than one refinement steps without necessitating extra annotations.
",4 Related Work,[0],[0]
Infusion Training Bordes et al. (2017) proposed an unconditional generative model for images based on iterative refinement.,4 Related Work,[0],[0]
"At each step l of iterative refinement, the model is trained to maximize the log-likelihood of target Y given the weighted mixture of generated samples from the previous iteration ˆY",4 Related Work,[0],[0]
l 1 and a corrupted target ˜Y .,4 Related Work,[0],[0]
"That is, the corrupted version of target is “infused”
(a) (b)
10
2).",4 Related Work,[0],[0]
The x-axis is in the logarithmic scale.,4 Related Work,[0],[0]
(b) the decoding latencies (sec/sentence) of different approaches on IWSLT’16 En!De.,4 Related Work,[0],[0]
"The y-axis is in the logarithmic scale.
",4 Related Work,[0],[0]
"Src Attention
Pos Attention
Self Attention
Source
Linear
Softmax
Feedforward
Src Attention
Pos Attention
Self Attention
Prev Output
Linear
Softmax
Loss
x N
Encoder Decoder 1 Decoder 2
Loss
copy
argmax embed
x K Self Attention
Feedforward
Source
Feedforward
positional encoding
x N x N
argmax embed
Softmax
Loss (target length)
stop gradient
Figure 2: We compose three transformer blocks (“Encoder”, “Decoder 1” and “Decoder 2”) to implement the proposed non-autoregressive sequence model.
into generated samples during training.",4 Related Work,[0],[0]
"In the domain of text, however, computing a weighted mixture of two sequences of discrete tokens is not well defined, and we propose to stochastically mix denoising and lowerbound maximization objectives.",4 Related Work,[0],[0]
We use three transformer-based network blocks to implement our model.,5 Network Architecture,[0],[0]
"The first block (“Encoder”) encodes the input X , the second block (“Decoder 1”) models the first conditional log p(Y
0|X), and the final block (“Decoder 2”) is shared across iterative refinement steps, modeling log p(Y l| ˆY",5 Network Architecture,[0],[0]
"l 1, X).",5 Network Architecture,[0],[0]
These blocks are depicted side-by-side in Fig. 2.,5 Network Architecture,[0],[0]
"The encoder is identical to that from the original Transformer (Vaswani et al., 2017).",5 Network Architecture,[0],[0]
"We however use the decoders from Gu et al. (2017) with additional positional attention and use the highway layer (Srivastava et al., 2015) instead of the residual layer (He et al., 2016).
",5 Network Architecture,[0],[0]
The original input X is padded or shortned to fit the length of the reference target sequence before being fed to Decoder 1.,5 Network Architecture,[0],[0]
"At each refinement step l, Decoder 2 takes as input the predicted target sequence ˆY",5 Network Architecture,[0],[0]
l 1 and the sequence of final activation vectors from the previous step.,5 Network Architecture,[0],[0]
We evaluate the proposed approach on two sequence modeling tasks: machine translation and image caption generation.,6 Experimental Setting,[0],[0]
"We compare the proposed non-autoregressive model against the autoregressive counterpart both in terms of generation quality, measured in terms of BLEU (Papineni et al., 2002), and generation efficiency, measured in terms of (source) tokens and images per second for translation and image captioning, respectively.
",6 Experimental Setting,[0],[0]
"Machine Translation We choose three tasks of different sizes: IWSLT’16 En$De (196k pairs), WMT’16 En$Ro (610k pairs) and WMT’14",6 Experimental Setting,[0],[0]
En$De (4.5M pairs).,6 Experimental Setting,[0],[0]
"We tokenize each sentence using a script from Moses (Koehn et al., 2007) and segment each word into subword units using BPE (Sennrich et al., 2016).",6 Experimental Setting,[0],[0]
We use 40k tokens from both source and target for all the tasks.,6 Experimental Setting,[0],[0]
"For WMT’14 En-De, we use newstest-2013 and newstest-2014 as development and test sets.",6 Experimental Setting,[0],[0]
"For WMT’16 En-Ro, we use newsdev-2016 and newstest-2016 as development and test sets.",6 Experimental Setting,[0],[0]
"For IWSLT’16 En-De, we use test2013 for validation.
",6 Experimental Setting,[0],[0]
We closely follow the setting by Gu et al. (2017).,6 Experimental Setting,[0],[0]
"In the case of IWSLT’16 En-De, we use the small model (dmodel = 278, dhidden = 507, pdropout = 0.1, nlayer = 5 and nhead = 2).2 For WMT’14 En-De and WMT’16 En-Ro, we use the base transformer by Vaswani et al. (2017) (dmodel = 512, dhidden = 512, pdropout = 0.1, nlayer = 6 and nhead = 8).",6 Experimental Setting,[0],[0]
"We use the warm-up learning rate scheduling (Vaswani et al., 2017) for the WMT tasks, while using linear annealing (from 3 ⇥ 10 4 to 10 5) for the IWSLT task.",6 Experimental Setting,[0],[0]
We do not use label smoothing nor average multiple check-pointed models.,6 Experimental Setting,[0],[0]
These decisions were made based on the preliminary experiments.,6 Experimental Setting,[0],[0]
"We train each model either on a single
2 Due to the space constraint, we refer readers to (Vaswani et al., 2017; Gu et al., 2017) for more details.
",6 Experimental Setting,[0],[0]
P40 (WMT’14 En-De and WMT’16 En-Ro) or on a single P100 (IWSLT’16 En-De) with each minibatch consisting of approximately 2k tokens.,6 Experimental Setting,[0],[0]
"We use four P100’s to train non-autoregressive models on WMT’14 En-De.
",6 Experimental Setting,[0],[0]
"Image Caption Generation: MS COCO We use MS COCO (Lin et al., 2014).",6 Experimental Setting,[0],[0]
"We use the publicly available splits (Karpathy and Li, 2015), consisting of 113,287 training images, 5k validation images and 5k test images.",6 Experimental Setting,[0],[0]
"We extract 49 512-dimensional feature vectors for each image, using a ResNet-18",6 Experimental Setting,[0],[0]
"(He et al., 2016) pretrained on ImageNet (Deng et al., 2009).",6 Experimental Setting,[0],[0]
The average of these vectors is copied as many times to match the length of the target sentence (reference during training and predicted during evaluation) to form the initial input to Decoder 1.,6 Experimental Setting,[0],[0]
"We use the base transformer (Vaswani et al., 2017) except that nlayer is set to 4.",6 Experimental Setting,[0],[0]
"We train each model on a single 1080ti with each minibatch consisting of approximately 1,024 tokens.
",6 Experimental Setting,[0],[0]
"Target Length Prediction We formulate the target length prediction as classification, predicting the difference between the target and source lengths for translation and the target length for image captioning.",6 Experimental Setting,[0],[0]
All the hidden vectors from the nlayer layers of the encoder are summed and fed to a softmax classifier after affine transformation.,6 Experimental Setting,[0],[0]
We however do not tune the encoder’s parameters for target length prediction.,6 Experimental Setting,[0],[0]
We use this length predictor only during test time.,6 Experimental Setting,[0],[0]
We find it important to accurately predict the target length for good overall performance.,6 Experimental Setting,[0],[0]
"See Appendix A for an analysis on our length prediction model.
",6 Experimental Setting,[0],[0]
"Training and Inference We use Adam (Kingma and Ba, 2014) and use L = 3 in Eq.",6 Experimental Setting,[0],[0]
(1) during training (itrain = 4 from hereon.),6 Experimental Setting,[0],[0]
We use pDAE = 0.5.,6 Experimental Setting,[0],[0]
"We use the deterministic strategy for IWSLT’16 En-De, WMT’16 En-Ro and MS COCO, while the stochastic strategy is used for WMT’14 En-De.",6 Experimental Setting,[0],[0]
These decisions were made based on the validation set performance.,6 Experimental Setting,[0],[0]
"After both the non-autogressive sequence model and target length predictor are trained, we decode by first predicting the target length and then running iterative refinement steps until the outputs of consecutive iterations are the same (or Jaccard distance between consecutive decoded sequences is 1).",6 Experimental Setting,[0],[0]
"To assess the effectiveness of this adaptive scheme, we also test a fixed number of steps (idec).",6 Experimental Setting,[0],[0]
"In machine translation, we remove any repetition by collapsing multiple consecutive occurrences of a token.",6 Experimental Setting,[0],[0]
We make some important observations in Table 1.,7 Results and Analysis,[0],[0]
"First, the generation quality improves across all the tasks as we run more refinement steps idec even beyond that used in training (itrain = 4), which supports our interpretation as a conditional denoising autoencoder in Sec. 3.2.",7 Results and Analysis,[0],[0]
"To further verify this, we run decoding on WMT’14 (both directions) up to 100 iterations.",7 Results and Analysis,[0],[0]
"As shown in Fig. 1 (a), the quality improves well beyond the number of refinement steps used during training.
",7 Results and Analysis,[0],[0]
"Second, the generation efficiency decreases as more refinements are made.",7 Results and Analysis,[0],[0]
"We plot the average seconds per sentence in Fig. 1 (b), measured on GPU while sequentially decoding one sentence at a time.",7 Results and Analysis,[0],[0]
"As expected, decoding from the autoregressive model linearly slows down as the sen-
tence length grows, while decoding from the nonautoregressive model with a fixed number of iterations has the constant complexity.",7 Results and Analysis,[0],[0]
"However, the generation efficiency of non-autoregressive model decreases as more refinements are made.",7 Results and Analysis,[0],[0]
"To make a smooth trade-off between the quality and speed, the adaptive decoding scheme allows us to achieve near-best generation quality with a significantly lower computational overhead.",7 Results and Analysis,[0],[0]
"Moreover, the adaptive decoding scheme automatically increases the number of refinement steps as the sentence length increases, suggesting that this scheme captures the amount of information in the input well.",7 Results and Analysis,[0],[0]
"The increase in latency is however less severe than that of the autoregressive model.
",7 Results and Analysis,[0],[0]
We also observe that the speedup in decoding is much clearer on GPU than on CPU.,7 Results and Analysis,[0],[0]
"This is a consequence of highly parallel computation of the proposed non-autoregressive model, which is better suited to GPUs, showcasing the potential of using the non-autoregressive model with a specialized hardware for parallel computation, such as Google’s TPUs (Jouppi et al., 2017).",7 Results and Analysis,[0],[0]
"The results of our model decoded with adaptive decoding scheme are comparable to the results from (Gu et al., 2017), without relying on any external tool.",7 Results and Analysis,[0],[0]
"On WMT’14 En-De, the proposed model outperforms the best model from (Gu et al., 2017) by two points.
",7 Results and Analysis,[0],[0]
"Lastly, it is encouraging to observe that the proposed non-autoregressive model works well on image caption generation.",7 Results and Analysis,[0],[0]
"This result confirms the generality of our approach beyond machine translation, unlike that by Gu et al. (2017) which was for machine translation or by Oord et al. (2017) which was for speech synthesis.
",7 Results and Analysis,[0],[0]
Ablation Study We use IWSLT’16 En-De to investigate the impact of different number of refinement steps during training (denoted as itrain) as well as probability of using denoising autoencoder objective during training (denoted as pDAE).,7 Results and Analysis,[0],[0]
"The
results are presented in Table 2.",7 Results and Analysis,[0],[0]
"First, we observe that it is beneficial to use multiple iterations of refinement during training.",7 Results and Analysis,[0],[0]
"By using four iterations (one step of decoder 1, followed by three steps of decoder 2), the BLEU score improved by approximately 1.5 points in both directions.",7 Results and Analysis,[0],[0]
"We also notice that it is necessary to use the proposed hybrid learning strategy to maximize the improvement from more iterations during training (itrain = 4 vs. itrain = 4, pDAE = 1.0 vs. itrain = 4, pDAE = 0.5.)",7 Results and Analysis,[0],[0]
"Knowledge distillation was crucial to close the gap between the proposed deterministic non-autoregressive sequence model and its autoregressive counterpart, echoing the observations by Gu et al. (2017) and Oord et al. (2017).",7 Results and Analysis,[0],[0]
"Finally, we see that removing repeating consecutive symbols improves the quality of the best trained models (itrain = 4, pDAE = 0.5) by approximately +1 BLEU.",7 Results and Analysis,[0],[0]
This suggests that the proposed iterative refinement is not enough to remove repetitions on its own.,7 Results and Analysis,[0],[0]
"Further investigation is necessary to properly tackle this issue, which we leave as a future work.
",7 Results and Analysis,[0],[0]
We then compare the deterministic and stochastic approximation strategies on IWSLT’16 En!De and WMT’14 En!De.,7 Results and Analysis,[0],[0]
"According to the results in Table 3, the stochastic strategy is crucial with a large corpus (WMT’14), while the deterministic strategy works as well or better with a small corpus (IWSLT’16).",7 Results and Analysis,[0],[0]
"Both of the strategies benefit from knowledge distillation, but the gap between the two strategies when the dataset is large is much more apparent without knowledge distillation.",7 Results and Analysis,[0],[0]
"Machine Translation In Table 4, we present three sample translations and their iterative refinement steps from the development set of IWSLT’16 (De!En).",7.1 Qualitative Analysis,[0],[0]
"As expected, the sequence generated from the first iteration is a rough version of translation and is iteratively refined over multiple steps.",7.1 Qualitative Analysis,[0],[0]
"By inspecting the underlined sub-sequences, we see that each iteration does not monotonically improve the translation, but overall modifies the
Src seitdem habe ich sieben Häuser in der Nachbarschaft mit den Lichtern versorgt und sie funktionierenen wirklich gut .",7.1 Qualitative Analysis,[0],[0]
Iter 1,7.1 Qualitative Analysis,[0],[0]
and I ’ve been seven homes since in neighborhood with the lights and they ’re really functional .,7.1 Qualitative Analysis,[0],[0]
Iter 2,7.1 Qualitative Analysis,[0],[0]
"and I ’ve been seven homes in the neighborhood with the lights , and they ’re a really functional .",7.1 Qualitative Analysis,[0],[0]
"Iter 4 and I ’ve been seven homes in neighborhood with the lights , and they ’re a really functional .",7.1 Qualitative Analysis,[0],[0]
Iter 8,7.1 Qualitative Analysis,[0],[0]
and I ’ve been providing seven homes in the neighborhood with the lights and they ’re a really functional .,7.1 Qualitative Analysis,[0],[0]
"Iter 20 and I ’ve been providing seven homes in the neighborhood with the lights , and they ’re a very good functional .",7.1 Qualitative Analysis,[0],[0]
"Ref since now , I ’ve set up seven homes around my community , and they ’re really working .
",7.1 Qualitative Analysis,[0],[0]
Src er sah sehr,7.1 Qualitative Analysis,[0],[0]
glücklich,7.1 Qualitative Analysis,[0],[0]
"aus , was damals ziemlich ungewöhnlich war , da ihn die Nachrichten meistens deprimierten .",7.1 Qualitative Analysis,[0],[0]
"Iter 1 he looked very happy , which was pretty unusual the , because the news was were usually depressing .",7.1 Qualitative Analysis,[0],[0]
Iter 2,7.1 Qualitative Analysis,[0],[0]
"he looked very happy , which was pretty unusual at the , because the news was s depressing .",7.1 Qualitative Analysis,[0],[0]
"Iter 4 he looked very happy , which was pretty unusual at the , because news was mostly depressing .",7.1 Qualitative Analysis,[0],[0]
"Iter 8 he looked very happy , which was pretty unusual at the time because the news was mostly depressing .",7.1 Qualitative Analysis,[0],[0]
"Iter 20 he looked very happy , which was pretty unusual at the time , because the news was mostly depressing .",7.1 Qualitative Analysis,[0],[0]
"Ref there was a big smile on his face which was unusual then , because the news mostly depressed him .
",7.1 Qualitative Analysis,[0],[0]
"Src furchtlos zu sein heißt für mich , heute ehrlich zu sein .",7.1 Qualitative Analysis,[0],[0]
"Iter 1 to be , for me , to be honest today .",7.1 Qualitative Analysis,[0],[0]
"Iter 2 to be fearless , me , is to be honest today .",7.1 Qualitative Analysis,[0],[0]
"Iter 4 to be fearless for me , is to be honest today .",7.1 Qualitative Analysis,[0],[0]
"Iter 8 to be fearless for me , me to be honest today .",7.1 Qualitative Analysis,[0],[0]
"Iter 20 to be fearless for me , is to be honest today .",7.1 Qualitative Analysis,[0],[0]
"Ref so today , for me , being fearless means being honest .
",7.1 Qualitative Analysis,[0],[0]
Table 4: Three sample De!En translations from the non-autoregressive sequence model.,7.1 Qualitative Analysis,[0],[0]
Source sentences are from the dev set of IWSLT’16.,7.1 Qualitative Analysis,[0],[0]
"The first iteration corresponds to Decoder 1, and from thereon, Decoder 2 is repeatedly applied.",7.1 Qualitative Analysis,[0],[0]
"Sub-sequences with changes across the refinement steps are underlined.
translation towards the reference sentence.",7.1 Qualitative Analysis,[0],[0]
"Missing words are added, while unnecessary words are dropped.",7.1 Qualitative Analysis,[0],[0]
"For instance, see the second example.",7.1 Qualitative Analysis,[0],[0]
"The second iteration removes the unnecessary “were”, and the fourth iteration inserts a new word “mostly”.",7.1 Qualitative Analysis,[0],[0]
"The phrase “at the time” is gradually added one word at a time.
",7.1 Qualitative Analysis,[0],[0]
Image Caption Generation Table 5 shows two examples of image caption generation.,7.1 Qualitative Analysis,[0],[0]
We observe that each iteration captures more and more details of the input image.,7.1 Qualitative Analysis,[0],[0]
"In the first example (left), the bus was described only as a “yellow bus” in the first iteration, but the subsequent iterations refine it into “yellow and black bus”.",7.1 Qualitative Analysis,[0],[0]
"Similarly, “road” is refined into “lot”.",7.1 Qualitative Analysis,[0],[0]
We notice this behavior in the second example (right) as well.,7.1 Qualitative Analysis,[0],[0]
"The first iteration does not specify the place in which “a woman” is “standing on”, which is fixed immediately in the second iteration: “standing on a tennis court”.",7.1 Qualitative Analysis,[0],[0]
"In the final and fourth iteration, the proposed model captures the fact that the “woman” is “holding” a racquet.",7.1 Qualitative Analysis,[0],[0]
"Following on the exciting, recent success of nonautoregressive neural sequence modeling by Gu et al. (2017) and Oord et al. (2017), we proposed a deterministic non-autoregressive neural sequence model based on the idea of iterative refinement.",8 Conclusion,[0],[0]
"We designed a learning algorithm specialized to the proposed approach by interpreting the entire
model as a latent variable model and each refinement step as denoising.
",8 Conclusion,[0],[0]
We implemented our approach using the Transformer and evaluated it on two tasks: machine translation and image caption generation.,8 Conclusion,[0],[0]
"On both tasks, we were able to show that the proposed nonautoregressive model performs closely to the autoregressive counterpart with significant speedup in decoding.",8 Conclusion,[0],[0]
"Qualitative analysis revealed that the iterative refinement indeed refines a target sequence gradually over multiple steps.
",8 Conclusion,[0],[0]
"Despite these promising results, we observed that proposed non-autoregressive neural sequence model is outperformed by its autoregressive counterpart in terms of the generation quality.",8 Conclusion,[0],[0]
The following directions should be pursued in the future to narrow this gap.,8 Conclusion,[0],[0]
"First, we should investigate better approximation to the marginal logprobability.",8 Conclusion,[0],[0]
"Second, the impact of the corruption process on the generation quality must be studied.",8 Conclusion,[0],[0]
"Lastly, further work on sequence-to-sequence model architectures could yield better results in non-autoregressive sequence modeling.",8 Conclusion,[0],[0]
"We thank support by AdeptMind, eBay, TenCent and NVIDIA.",Acknowledgement,[0],[0]
This work was partly supported by Samsung Advanced Institute of Technology (Next Generation Deep Learning: from pattern recognition to AI) and Samsung Electronics (Improving Deep Learning using Latent Structure).,Acknowledgement,[0],[0]
We also thank Jiatao Gu for valuable feedback.,Acknowledgement,[0],[0]
We propose a conditional non-autoregressive neural sequence model based on iterative refinement.,abstractText,[0],[0]
"The proposed model is designed based on the principles of latent variable models and denoising autoencoders, and is generally applicable to any sequence generation task.",abstractText,[0],[0]
"We extensively evaluate the proposed model on machine translation (En$De and En$Ro) and image caption generation, and observe that it significantly speeds up decoding while maintaining the generation quality comparable to the autoregressive counterpart.",abstractText,[0],[0]
Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement,title,[0],[0]
Machine learning systems are difficult to engineer for many fundamental reasons.,1. Introduction,[0],[0]
"First and foremost, implementation errors can be extremely difficult to detect—let alone to localize and address—since there are many other potential causes of undesired behavior in a machine learning system.",1. Introduction,[0],[0]
"For example, an implementation error may lead to incorrect gradients and so cause a learning algorithm to stall, but such a symptom may also be caused by noise in the training data, a poor choice of model, an unfavorable optimization landscape, an inadequate search strategy, or numerical instability.",1. Introduction,[0],[0]
These other issues are so common that it is often assumed that any undesired behavior is caused by one of them.,1. Introduction,[0],[0]
"As a result, actual implementation errors can persist
1Stanford University, Stanford, CA.",1. Introduction,[0],[0]
"Correspondence to: Daniel Selsam <dselsam@stanford.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Standard methodology: test it empirically
Program
Debug
Test
Our methodology: verify it mathematically
indefinitely without detection.1 Errors are even more difficult to detect in stochastic programs, since some errors may only distort the distributions of random variables and may require writing custom statistical tests to detect.
",1. Introduction,[0],[0]
"Machine learning systems are also difficult to engineer because it can require substantial expertise in mathematics (e.g. linear algebra, statistics, multivariate analysis, measure theory, differential geometry, topology) to even understand what a machine learning algorithm is supposed to do and why it is thought to do it correctly.",1. Introduction,[0],[0]
"Even simple algorithms such as gradient descent can have intricate justifications, and there can be a large gap between the mechanics of an implementation—especially a highly-optimized one—and its intended mathematical semantics.
",1. Introduction,[0],[0]
"1Theano (Bergstra et al., 2010) has been under development for almost a decade and yet there is a recent GitHub issue (https://github.com/Theano/Theano/issues/4770) reporting a model for which the loss continually diverges in the middle of training.",1. Introduction,[0],[0]
Only after various experiments and comparing the behavior to other systems did the team agree that it is most likely an implementation error.,1. Introduction,[0],[0]
"As of this writing, neither the cause of this error nor the set of models it affects have been determined.
",1. Introduction,[0],[0]
"In this paper, we demonstrate a practical methodology for building machine learning systems that addresses these challenges by enabling developers to find and eliminate implementation errors systematically without recourse to empirical testing.",1. Introduction,[0],[0]
"Our approach makes use of a tool called an interactive proof assistant (Gordon, 1979; Gordon & Melham, 1993; Harrison, 1996; Nipkow et al., 2002; Owre et al., 1992; Coq Development Team, 2015-2016; de Moura et al., 2015), which consists of (a) a programming language, (b) a language to state mathematical theorems, and (c) a set of tools for constructing formal proofs of such theorems.",1. Introduction,[0],[0]
"Note: we use the term formal proof to mean a proof that is in a formal system and so can be checked by a machine.
",1. Introduction,[0],[0]
"In our approach, developers use the theorem language (b) to state a formal mathematical theorem that defines what it means for their implementation to be error-free in terms of the underlying mathematics (e.g. multivariate analysis).",1. Introduction,[0],[0]
"Upon implementing the system using the programming language (a), developers use the proof tools (c) to construct a formal proof of the theorem stating that their implementation is correct.",1. Introduction,[0],[0]
"The first draft of any implementation will often have errors, and the process of interactive proving will expose these errors systematically by yielding impossible proof obligations.",1. Introduction,[0],[0]
"Once all implementation errors have been fixed, the developers will be able to complete the formal proof and be certain that the implementation has no errors with respect to its specification.",1. Introduction,[0],[0]
"Moreover, the proof assistant can check the formal proof automatically so no human needs to understand why the proof is correct in order to trust that it is.",1. Introduction,[0],[0]
"Figure 1 illustrates this process.
",1. Introduction,[0],[0]
"Proving correctness of machine learning systems requires building on the tools and insights from two distinct fields: program verification (Leroy, 2009; Klein et al., 2009; Chlipala, 2013; Chen et al., 2015), which has aimed to prove properties of computer programs, and formal mathematics (Rudnicki, 1992; Gonthier, 2008; Gonthier et al., 2013; Hales et al., 2015), which has aimed to formally represent and generate machine-checkable proofs of mathematical theorems.",1. Introduction,[0],[0]
"Both of these fields make use of interactive proof assistants, but the tools, libraries and design patterns developed by the two fields focus on different problems and have remained largely incompatible.",1. Introduction,[0],[0]
"While the methodology we have outlined will be familiar to the program verification community, and while reasoning formally about the mathematics that underlies machine learning will be familiar to the formal mathematics community, proving such sophisticated mathematical properties of large (stochastic) software systems is a new goal and poses many new challenges.
",1. Introduction,[0],[0]
"To explore these challenges and to demonstrate the prac-
ticality of our approach, we implemented a new machine learning system, Certigrad, for optimizing over stochastic computation graphs (Schulman et al., 2015).",1. Introduction,[0],[0]
"Stochastic computation graphs extend the computation graphs that underly systems like TensorFlow (Abadi et al., 2015) and Theano (Bergstra et al., 2010) by allowing nodes to represent random variables and by defining the loss function for a graph to be the expected value of the sum of the leaf nodes over the stochastic choices.",1. Introduction,[0],[0]
See Figure 2 for an example of a stochastic computation graph.,1. Introduction,[0],[0]
"We implement our system in the Lean Theorem Prover (de Moura et al., 2015), a new interactive proof assistant still under active development for which the integration of programming and mathematical reasoning is an ongoing design goal.",1. Introduction,[0],[0]
"We formally state and prove functional correctness for the stochastic backpropagation algorithm: that the sampled gradients are indeed unbiased estimates of the gradients of the loss function with respect to the parameters.
",1. Introduction,[0],[0]
We note that provable correctness need not come at the expense of computational efficiency: proofs need only be checked once during development and they introduce no runtime overhead.,1. Introduction,[0],[0]
"Although the algorithms we verify in this work lack many optimizations, most of the running time when training machine learning systems is spent multiplying matrices, and we are able to achieve competitive performance simply by linking with an optimized library for matrix operations (we used Eigen (Guennebaud et al., 2010)).2 To demonstrate practical feasibility empirically, we trained an Auto-Encoding Variational Bayes (AEVB) model (Kingma & Welling, 2014) on MNIST using ADAM (Kingma & Ba, 2014) and found the performance comparable to training the same model in TensorFlow.
",1. Introduction,[0],[0]
"2Note that the validity of our theorem becomes contingent on Eigen’s matrix operations being functionally equivalent to the versions we formally proved correct.
",1. Introduction,[0],[0]
"We summarize our contributions:
1.",1. Introduction,[0],[0]
"We present the first application of formal (i.e. machine-checkable) proof techniques to developing machine learning systems.
",1. Introduction,[0],[0]
2.,1. Introduction,[0],[0]
"We describe a methodology that can detect implementation errors systematically in machine learning systems.
3.",1. Introduction,[0],[0]
We demonstrate that our approach is practical by developing a performant implementation of a sophisticated machine learning system along with a machinecheckable proof of correctness.,1. Introduction,[0],[0]
"When developing machine learning systems, many program optimizations involve extensive algebraic derivations to put mathematical expressions in closed-form .",2. Motivation,[0],[0]
"For example, suppose you want to compute the following quantity efficiently:
∫ x N (x;µ,Diag(σ2))",2. Motivation,[0],[0]
"logN (x; 0, In×n).",2. Motivation,[0],[0]
"(1)
You expand the density functions, grind through the algebra by hand and eventually derive the following closed form expression:
−1 2",2. Motivation,[0],[0]
[ n∑ i=1,2. Motivation,[0],[0]
"( σ2i − µ2i ) + n log 2π ] (2)
You implement a procedure to compute this quantity and include it as part of a larger program, but when you run your first experiment, your plots are not as encouraging as you hoped.",2. Motivation,[0],[0]
"After ruling out many other possible explanations, you eventually decide to scrutinize this procedure more closely.",2. Motivation,[0],[0]
"You implement a naı̈ve Monte Carlo estimator for the quantity above, compare it against your procedure on a few random inputs and find that its estimates are systematically biased.",2. Motivation,[0],[0]
What do you do now?,2. Motivation,[0],[0]
"If you re-check your algebra carefully, you might notice that the sign of µ2i is wrong, but wouldn’t it be easier if the compiler checked your algebra for you and found the erroneous step?",2. Motivation,[0],[0]
"Or better yet, if it did the algebra for you in the first place and could guarantee the result was error-free?",2. Motivation,[0],[0]
"To develop software systems with no implementation errors, we need a way to write computer programs, mathematical theorems, and mathematical proofs all in the same
language.",3. Background: The Lean Theorem Prover,[0],[0]
"All three capabilities are provided by the new interactive proof assistant Lean (de Moura et al., 2015).",3. Background: The Lean Theorem Prover,[0],[0]
"Lean is an implementation of a logical system known as the Calculus of Inductive Constructions (Coquand & Huet, 1988), and its design is inspired by the better-known Coq Proof Assistant (Coq Development Team, 2015-2016).",3. Background: The Lean Theorem Prover,[0],[0]
"Our development makes use of certain features that are unique to Lean, but most of what we present is equally applicable to Coq, and to a lesser extent, other interactive theorem provers such as Isabelle/HOL (Nipkow et al., 2002).
",3. Background: The Lean Theorem Prover,[0],[0]
"To explain and motivate the relevant features of Lean, we will walk through applying our methodology to a toy problem: writing a program to compute the gradient of the softplus function.",3. Background: The Lean Theorem Prover,[0],[0]
"We can write standard functional programs in Lean, such as softplus: def splus (x : R) :",3. Background: The Lean Theorem Prover,[0],[0]
"R := log (1 + exp x)
",3. Background: The Lean Theorem Prover,[0],[0]
"We can also represent more abstract operations such as integrals and gradients:∫
(f : R→ R) :",3. Background: The Lean Theorem Prover,[0],[0]
"R ∇ (f : R→ R) (θ : R) : R
Here the intended meaning of ∫ f is the integral of the function f over all of R, while the intended meaning of ∇",3. Background: The Lean Theorem Prover,[0],[0]
f θ is the gradient (i.e. the derivative) of the function f at the point θ.,3. Background: The Lean Theorem Prover,[0],[0]
"Figure 3 shows how to represent common idioms of informal mathematics in our formal representation; note that whereas some of the informal examples are too ambiguous to interpret without additional information, the Lean representation is always unambiguous.
",3. Background: The Lean Theorem Prover,[0],[0]
We can represent mathematical theorems in Lean as well.,3. Background: The Lean Theorem Prover,[0],[0]
"For example, we can use the following predicate to state that a particular function f is differentiable at a point θ: is_diff (f : R→ R) (θ : R) :",3. Background: The Lean Theorem Prover,[0],[0]
"Prop
The fact that the return type of is_diff is Prop indicates that it is not a computer program to be executed but rather that it represents a mathematical theorem.
",3. Background: The Lean Theorem Prover,[0],[0]
"We can also state and assume basic properties about the gradient, such as linearity: ∀ (f g : R→ R) (θ : R), is_diff f",3. Background: The Lean Theorem Prover,[0],[0]
θ ∧ is_diff g θ→ ∇,3. Background: The Lean Theorem Prover,[0],[0]
(f + g) θ =∇ f θ +∇ g,3. Background: The Lean Theorem Prover,[0],[0]
"θ
Returning to our running example, we can state the theorem that a particular function f computes the gradient of the softplus function:
def gsplus_spec (f : R→ R) :",3. Background: The Lean Theorem Prover,[0],[0]
"Prop := ∀ x, f x =∇ splus x
Suppose we try to write a program to compute the gradient of the softplus function as follows:
def gsplus (x : R) :",3. Background: The Lean Theorem Prover,[0],[0]
"R := 1 / (1 + exp x)
",3. Background: The Lean Theorem Prover,[0],[0]
"The application gsplus_spec gsplus represents the proposition that our implementation gsplus is correct, i.e. that it indeed computes the gradient of the softplus function for all inputs.
",3. Background: The Lean Theorem Prover,[0],[0]
"We can try to formally prove theorems in Lean interactively:
theorem gsplus_correct : gsplus_spec gsplus := lean: ` gsplus_spec gsplus user: expand_def gsplus_spec, lean: ` ∀ x, gsplus x =∇ splus x user: introduce x, lean: x : R ` gsplus x =∇ splus x user: expand_defs",3. Background: The Lean Theorem Prover,[0],[0]
"[gsplus, splus], lean: x : R ` 1 / (1 + exp x) =∇",3. Background: The Lean Theorem Prover,[0],[0]
"(λ x, log (1 + exp x)) x user: simplify_grad, lean: x : R ` 1 / (1 + exp x) = exp x / (1 + exp x)
",3. Background: The Lean Theorem Prover,[0],[0]
"The lines beginning with lean show the current state of the proof as displayed by Lean, which at any time consists of a collection of goals of the form assumptions ` conclusion.",3. Background: The Lean Theorem Prover,[0],[0]
"Every line beginning with user invokes a tactic, which is a command that modifies the proof state in some way such that Lean can automatically construct proofs of the original goals given proofs of the new ones.",3. Background: The Lean Theorem Prover,[0],[0]
"Here the simplify_grad tactic rewrites exhaustively with known gradient rules—in this case it uses the rules for log, exp, addition, constants, and the identity function.",3. Background: The Lean Theorem Prover,[0],[0]
"The final goal is clearly not provable, which means we have found an implementation error in gsplus.",3. Background: The Lean Theorem Prover,[0],[0]
Luckily the goal tells us exactly what gsplus x needs to return: gsplus x = exp x / (1 + exp x).,3. Background: The Lean Theorem Prover,[0],[0]
"Once we fix the implementation of gsplus, the proof script that failed before now succeeds and generates a machine-checkable proof that the revised gsplus is bug-free.",3. Background: The Lean Theorem Prover,[0],[0]
"Note that we need not have even attempted to implement gsplus before starting the proof, since the process itself revealed what the program needs to compute.",3. Background: The Lean Theorem Prover,[0],[0]
"We will revisit this phenomenon in §4.5.
",3. Background: The Lean Theorem Prover,[0],[0]
"In the process of proving the theorem, Lean constructs a formal proof certificate that can be automatically verified by a small stand-alone executable, whose soundness is based on a well-established meta-theoretic argument embedding the core logic of Lean into set theory, and whose implementation has been heavily scrutinized by many developers.",3. Background: The Lean Theorem Prover,[0],[0]
"Thus no human needs to be able to understand
why a proof is correct in order to trust that it",3. Background: The Lean Theorem Prover,[0],[0]
"is.3
Although we cannot execute functions such as gsplus directly in the core logic of Lean (since a real number is an infinite object that cannot be stored in a computer), we can execute the floating-point approximation inside Lean’s virtual machine:
vm_eval gsplus π",3. Background: The Lean Theorem Prover,[0],[0]
−− answer: 0.958576,3. Background: The Lean Theorem Prover,[0],[0]
"Stochastic computation graphs are directed acyclic graphs in which each node represents a specific computational operation that may be deterministic or stochastic (Schulman et al., 2015).",4. Case Study: Certified Stochastic Computation Graphs,[0],[0]
The loss function for a graph is defined to be the expected value of the sum of the leaf nodes over the stochastic choices.,4. Case Study: Certified Stochastic Computation Graphs,[0],[0]
"Figure 2 shows the stochastic computation graph for a simple variational autoencoder.
",4. Case Study: Certified Stochastic Computation Graphs,[0],[0]
"Using our methodology, we developed a system, Certigrad, which allows users to construct arbitrary stochastic computation graphs out of the primitives that we provide.",4. Case Study: Certified Stochastic Computation Graphs,[0],[0]
"The main purpose of the system is to take a program describing a stochastic computation graph and to run a randomized algorithm (stochastic backpropagation) that, in expectation, provably generates unbiased samples of the gradients of the loss function with respect to the parameters.",4. Case Study: Certified Stochastic Computation Graphs,[0],[0]
"We now briefly describe the components of Certigrad, some of which have no analogues in traditional software systems.4
Mathematics libraries.",4.1. Overview of Certigrad,[0],[0]
"There is a type that represents tensors of a particular shape, along with basic functions (e.g. exp, log) and operations (e.g. the gradient, the integral).",4.1. Overview of Certigrad,[0],[0]
"There are assumptions about tensors (e.g. gradient rules for exp and log), and facts that are proved in terms of those assumptions (e.g. the gradient rule for softplus).",4.1. Overview of Certigrad,[0],[0]
"There is also a type that represents probability distributions over vectors of tensors, that can be reasoned about mathematically and that can also be executed procedurally using a pseudo-random number generator.
Implementation.",4.1. Overview of Certigrad,[0],[0]
"There is a data structure that represents stochastic computation graphs, as well as an implementation of stochastic backpropagation.",4.1. Overview of Certigrad,[0],[0]
"There are also functions that optimize stochastic computation graphs in various ways (e.g. by integrating out parts of the objective
3This appealing property can be lost when an axiom is assumed that is not true.",4.1. Overview of Certigrad,[0],[0]
"We discuss this issue further in §4.3.
",4.1. Overview of Certigrad,[0],[0]
"4The complete development can be found at www.github.com/ dselsam/certigrad.
function), as well as basic utilities for training models (e.g. stochastic gradient descent).
",4.1. Overview of Certigrad,[0],[0]
Specification.,4.1. Overview of Certigrad,[0],[0]
There is a collection of theorem statements that collectively define what it means for the implementation to be correct.,4.1. Overview of Certigrad,[0],[0]
"For Certigrad, there is one main theorem that states that the stochastic backpropagation procedure yields unbiased estimates of the true mathematical gradients.",4.1. Overview of Certigrad,[0],[0]
"There are also other theorems that state that individual graph optimizations are sound.
Proof.",4.1. Overview of Certigrad,[0],[0]
"There are many helper lemmas to decompose the proofs into more manageable chunks, and there are tactic scripts to generate machine-checkable proofs for each of the lemmas and theorems appearing in the system.",4.1. Overview of Certigrad,[0],[0]
"There are also tactic programs to automate certain types of reasoning, such as computing gradients or proving that functions are continuous.
",4.1. Overview of Certigrad,[0],[0]
Optimized libraries.,4.1. Overview of Certigrad,[0],[0]
"While the stochastic backpropagation function is written in Lean and proved correct, we execute the primitive tensor operations with the Eigen library for linear algebra.",4.1. Overview of Certigrad,[0],[0]
"There is a small amount of C++ code to wrap Eigen operations for use inside Lean’s virtual machine.
",4.1. Overview of Certigrad,[0],[0]
"The rest of this section describes the steps we took to develop Certigrad, which include sketching the high-level architecture, designing the mathematics libraries, stating the main correctness theorem and constructing the formal proof.",4.1. Overview of Certigrad,[0],[0]
"Though many details are specific to Certigrad, this case study is designed to illustrate our methodology and we expect other projects will follow a similar process.",4.1. Overview of Certigrad,[0],[0]
"Note: Certigrad supports arbitrarily-shaped tensors, but doing so introduces more notational complexity than conceptual difficulty and so we simplify the presentation that follows by assuming that all values are scalars.",4.1. Overview of Certigrad,[0],[0]
The first step of applying our methodology is to write down informally what the system is required to do.,4.2. Informal specification,[0],[0]
Suppose g is a stochastic computation graph with n nodes and (to simplify the notation) that it only takes a single parameter θ.,4.2. Informal specification,[0],[0]
"Then g, θ together define a distribution over the values at the n nodes (X1, . . .",4.2. Informal specification,[0],[0]
", Xn).",4.2. Informal specification,[0],[0]
"Let cost(g,X1:n) be the function that sums the values of the leaf nodes.",4.2. Informal specification,[0],[0]
"Our primary goal is to write a (stochastic) backpropagation algorithm bprop such that for any graph g,
Eg,θ [bprop(g, θ,X1:n)]",4.2. Informal specification,[0],[0]
"= ∇θ (Eg,θ [cost(g,X1:n)]) (3)
While this equation may seem sufficient to communicate the specification to a human with a mathematical background, more precision is needed to communicate it to a computer.",4.2. Informal specification,[0],[0]
"The next step is to formalize the background
mathematics, such as real numbers (tensors) and probability distributions, so that we can state a formal analogue of Equation 3 that the computer can understand.",4.2. Informal specification,[0],[0]
"Although we believe it will be possible to develop standard libraries of mathematics that future developers can use off-the-shelf, we needed to develop the mathematics libraries for Certigrad from scratch.",4.2. Informal specification,[0],[0]
"Whereas in traditional formal mathematics the goal is to construct mathematics from first principles (Gonthier et al., 2013; Hales et al., 2015), we need not concern ourselves with foundational issues and can simply assume that standard mathematical properties hold.",4.3. Designing the mathematics libraries,[0],[0]
"For example, we can assume that there is a type R of real numbers without needing to construct them (e.g. from Cauchy sequences), and likewise can assume there is an integration operator on the reals ∫",4.3. Designing the mathematics libraries,[0],[0]
"(f : R→ R) : R that satisfies the well-known properties without needing to construct it either (e.g. from Riemann sums).
",4.3. Designing the mathematics libraries,[0],[0]
Note that axioms must be chosen with great care since even a single false axiom (perhaps caused by a single missing precondition) can in principle allow proving any false theorem and so would invalidate the property that all formal proofs can be trusted without inspection.5,4.3. Designing the mathematics libraries,[0],[0]
"However, there are many preconditions that appear in mathematical theorems, such as integrability, that are almost always satisfied in machine learning contexts and which most developers ignore.",4.3. Designing the mathematics libraries,[0],[0]
"Using axioms that omit such preconditions will necessarily lead to proving theorems that are themselves missing the corresponding preconditions, but in practice a non-adversarial developer is extremely unlikely to accidentally construct vacuous proofs by exploiting these axioms.",4.3. Designing the mathematics libraries,[0],[0]
"For the first draft of our system, we purposely omitted integrability preconditions in our axioms to simplify the development.",4.3. Designing the mathematics libraries,[0],[0]
"Only later did we make our axioms sound and propagate the additional preconditions throughout the system so that we could fully trust our formal proofs.
",4.3. Designing the mathematics libraries,[0],[0]
"Despite the convenience of axiomatizing the mathematics, designing the libraries was still challenging for two reasons.",4.3. Designing the mathematics libraries,[0],[0]
"First, there were many different ways to formally represent the mathematical objects in question, and we needed to experiment to understand the tradeoffs between the different representations.",4.3. Designing the mathematics libraries,[0],[0]
"Second, we needed to extend several traditional mathematical concepts to support reasoning about executable computer programs.",4.3. Designing the mathematics libraries,[0],[0]
"The rest of this sub-
5For example, the seemingly harmless axiom ∀x, x/x = 1 without the precondition x 6= 0 can be used to prove the absurdity (0 = 0 ∗ 1 = 0 ∗ (0/0) = (0 ∗ 0)/0 = 0/0 = 1).",4.3. Designing the mathematics libraries,[0],[0]
"If a system assumes this axiom, then a formal proof of correctness could not be trusted without inspection since the proof may exploit this contradiction.
",4.3. Designing the mathematics libraries,[0],[0]
"section illustrates these challenges by considering the problem we faced of designing a representation of probability distributions for Certigrad.
",4.3. Designing the mathematics libraries,[0],[0]
Representing probability distributions.,4.3. Designing the mathematics libraries,[0],[0]
"Our challenge is to devise a sufficiently abstract representation of probability distributions that satisfies the following desiderata: we can reason about the probability density functions of continuous random variables, we have a way to reason about arbitrary deterministic functions applied to random variables, we can execute a distribution procedurally using a pseudorandom number generator (RNG), the mathematical and procedural representations of a distribution are guaranteed to correspond, and the mathematics will be recognizable to somebody familiar with the informal math behind stochastic computation graphs.
",4.3. Designing the mathematics libraries,[0],[0]
We first define types to represent the mathematical and procedural notions of probability distribution.,4.3. Designing the mathematics libraries,[0],[0]
"For mathematics, we define a Func n to be a functional that takes a realvalued function on Rn to a scalar: def Func (n : N) :",4.3. Designing the mathematics libraries,[0],[0]
"Type := ∀ (f : Rn→ R), R
The intended semantics is that if p : Func n represents a distribution on Rn, then p f is the expected value of f over p, i.e. Ex∼p[f(x)].
",4.3. Designing the mathematics libraries,[0],[0]
"For sampling, we define an Prog n to be a procedure that takes an RNG and returns a vector in Rn along with an updated RNG:
def Prog (n : N) :",4.3. Designing the mathematics libraries,[0],[0]
"Type := RNG→ Rn × RNG
We also assume that there are primitive (continuous) distributions (PrimDist := Func 1 × Prog 1) that consist of a probability density function and a corresponding sampling procedure.",4.3. Designing the mathematics libraries,[0],[0]
"In principle, we could construct all distributions from uniform variates, but for expediency, we treat other well-understood distributions as primitive, such as the Gaussian (gauss µ σ : PrimDist).
",4.3. Designing the mathematics libraries,[0],[0]
"Finally, we define a type of distributions (Dist n) that abstractly represents programs that may mix sampling from primitive distributions with arbitrary deterministic computations.",4.3. Designing the mathematics libraries,[0],[0]
A Dist n can be denoted to a Func n,4.3. Designing the mathematics libraries,[0],[0]
"(with the function E) to reason about mathematically, and to an Prog n",4.3. Designing the mathematics libraries,[0],[0]
"(with the function run) to execute with an RNG.
",4.3. Designing the mathematics libraries,[0],[0]
"For readers familiar with functional programming, our construction is similar to a monad.",4.3. Designing the mathematics libraries,[0],[0]
"We allow three ways of constructing a Dist n, corresponding to sampling from a primitive distribution (sample), returning a value deterministically (det), and composing two distributions (compose):
sample ((pdf, prog) : PrimDist) :",4.3. Designing the mathematics libraries,[0],[0]
Dist 1 det (xs : Rn) :,4.3. Designing the mathematics libraries,[0],[0]
Dist n compose (d1 : Dist m) (d2 : Rm→ Dist n) :,4.3. Designing the mathematics libraries,[0],[0]
Dist n,4.3. Designing the mathematics libraries,[0],[0]
"The mathematical semantics of all three constructors are straightforward:
E (sample (pdf, prog))",E {n : N} (d : Dist n) (f : Rn→ R) : R SCG n : Type,[0],[0]
"f = ∫
(λ x, pdf x * f x) E (det xs) f = f xs E (compose d1 d2) f = E",E {n : N} (d : Dist n) (f : Rn→ R) : R SCG n : Type,[0],[0]
"d1 (λ x, (E (d2 x) f))
",E {n : N} (d : Dist n) (f : Rn→ R) : R SCG n : Type,[0],[0]
"as are the procedural semantics:
run (sample (pdf, prog))",E {n : N} (d : Dist n) (f : Rn→ R) : R SCG n : Type,[0],[0]
"rng = prog rng run (det xs) rng = (xs, rng) run (compose d1 d2) rng = let (x, rng’) := run d1 rng in run (d2 x) rng’
We have defined E and run to correspond; we consider a stochastic program correct if we can prove the relevant theorems about its Func denotation, and we sample from it by passing an RNG to its Prog denotation.",E {n : N} (d : Dist n) (f : Rn→ R) : R SCG n : Type,[0],[0]
"With the background mathematics in place, the next step is to write down the formal specification itself.",4.4. Formal specification,[0],[0]
"First, we design types for every other object and function appearing in the informal description.",4.4. Formal specification,[0],[0]
"To start, we need a type SCG n",4.4. Formal specification,[0],[0]
"to represent stochastic computation graphs on n nodes, and a function SCG.to_dist that takes an SCG n and a scalar parameter θ to a distribution over n real numbers (Dist n).",4.4. Formal specification,[0],[0]
We also need a function cost that takes a graph and the values at each of its nodes and sums the values at the leaf nodes.,4.4. Formal specification,[0],[0]
"Figure 4 provides the full types of all objects that will appear in the specification.
",4.4. Formal specification,[0],[0]
"Now we can write down a type-correct analogue of the informal specification presented in Equation 3:
def bprop_spec (bprop : ∀ {n}, SCG n→ R→ Rn→ R) :",4.4. Formal specification,[0],[0]
"Prop := ∀ (n : N) (g : SCG n) (θ : R), E (SCG.to_dist g θ) (λ xs, bprop g θ xs) = ∇ (λ θ, E (SCG.to_dist g θ) (λ xs, cost g xs))",4.4. Formal specification,[0],[0]
"θ
Given the mathematics libraries, implementing the other
objects and functions appearing in the specification such as SCG n and SCG.to_dist is straightforward functional programming.",4.4. Formal specification,[0],[0]
"While conventional wisdom is that one would write their program before trying to prove it correct, the interactive proof process provides so much helpful information about what the system needs to do that we began working on the proof immediately after drafting the specification.",4.5. Interactive proof,[0],[0]
We split the proof into two steps.,4.5. Interactive proof,[0],[0]
"First, we implemented the simplest possible function that satisfied the specification (that only computed the gradient for a single parameter at a time and did not memoize at all) and proved that correct.",4.5. Interactive proof,[0],[0]
"Second, we implemented a more performant version (that computed the gradient for multiple parameters simultaneously using memoization) and proved it equivalent to the first one.
",4.5. Interactive proof,[0],[0]
"For the first step, we started with a placeholder implementation that immediately returned zero and let the interactive proof process guide the implementation.",4.5. Interactive proof,[0],[0]
"Whenever the proof seemed to require induction on a particular data structure, we extended the program to recurse on that data structure; whenever the proof showed that a branch of the program needed to return a value with a given expectation, we worked backwards from that to determine what value to return.",4.5. Interactive proof,[0],[0]
Proving the first step also exposed errors in our specification in the form of missing preconditions.,4.5. Interactive proof,[0],[0]
"For the specification to hold, we needed to make additional assumptions about the graph, e.g. that the identifier for each node in the graph is unique, and that each leaf node is a scalar (WellFormed g).",4.5. Interactive proof,[0],[0]
"We also needed to assume a generalization of the differentiability requirement mentioned in Schulman et al. (2015), that a subset of the nodes determined by the structure of the graph must be differentiable no matter the result of any stochastic choices (GradsExist g θ).
",4.5. Interactive proof,[0],[0]
"For the second step, we wrote the memoizing implementation before starting the proof and used the process of proving to test and debug it.",4.5. Interactive proof,[0],[0]
"Although the code for memoizing was simple and short, we still managed to make two implementation errors, one conceptual and one syntactic.",4.5. Interactive proof,[0],[0]
"Luckily the process of proving necessarily exposes all implementation errors, and in this case made it clear how to fix both of them.
",4.5. Interactive proof,[0],[0]
"We completed the main proof of correctness before proving most of the lemmas that the proof depends on, but the lemmas turned out to be true (except for a few missing preconditions) and so proving them did not expose any additional implementation errors.",4.5. Interactive proof,[0],[0]
We also completed the main proof while our axioms were still unsound (see §4.3).,4.5. Interactive proof,[0],[0]
"When we made our axioms sound and propagated the changes we
found that our specification required two additional preconditions: that all functions that are integrated over in the theorem statement are indeed integrable (IntegralsExist g θ), and that the many preconditions needed for pushing the gradient over each integral in the expected loss are satisfied (CanDiffUnderInts g θ).",4.5. Interactive proof,[0],[0]
"However, tracking these additional preconditions did not lead to any changes in our actual implementation.",4.5. Interactive proof,[0],[0]
Figure 5 shows the final specification.,4.5. Interactive proof,[0],[0]
We can also use our methodology to verify optimizations that involve mathematical reasoning.,4.6. Optimizations,[0],[0]
"When developing machine learning models, one often starts with an easyto-understand model that induces a gradient estimator with unacceptably high variance, and does informal mathematics by hand to derive a new model that has the same objective function but that induces a better gradient estimator.",4.6. Optimizations,[0],[0]
"In our approach, the user can write both models and use the process of interactive proving to confirm that they induce the same objective function.",4.6. Optimizations,[0],[0]
"Common transformations can be written once and proved correct so that users need only write the first model and the second can be derived and proved equivalent automatically.
",4.6. Optimizations,[0],[0]
"As part of Certigrad, we wrote a program optimization that integrates out the KL-divergence of the multivariate isotropic Gaussian distribution and we proved once and for all that the optimization is sound.",4.6. Optimizations,[0],[0]
We also verified an optimization that reparameterizes a model so that random variables do not depend on parameters (and so need not be backpropagated through).,4.6. Optimizations,[0],[0]
"Specifically, the optimization replaces a node that samples from N (µ,Diag(σ2)) with a graph of three nodes that first samples from N (0, In×n) and then scales and shifts the result according to σ and µ respectively.",4.6. Optimizations,[0],[0]
"We applied these two transformations in sequence to a naı̈ve variational-autoencoder to yield the Auto-Encoding Variational Bayes (AEVB) estimator (Kingma & Welling, 2014).",4.6. Optimizations,[0],[0]
"Even though we proved that bprop satisfies its formal specification (bprop_spec), we cannot be sure that it will compute the correct gradients for a particular model unless we prove that the model satisfies the preconditions of the specification.",4.7. Verifying specific models,[0],[0]
"Although some of the preconditions are technically undecidable, in practice most machine learning models will satisfy them all for simple reasons.",4.7. Verifying specific models,[0],[0]
We wrote a (heuristic) tactic program to prove that specific models satisfy all the preconditions and used it to verify that bprop computes the correct gradients for the AEVB model derived in §4.6.,4.7. Verifying specific models,[0],[0]
We have proved that our system is correct in an idealized mathematical context with infinite-precision real numbers.,4.8. Running the system,[0],[0]
To actually execute the system we need to replace all real numbers in the program with floating-point numbers.,4.8. Running the system,[0],[0]
"Although doing so technically invalidates the specification and can introduce numerical instability in some cases, this class of errors is well understood (Higham, 2002), could be ruled out as well in principle (Harrison, 2006; Boldo et al., 2015; Ramananandro et al., 2016) and is conceptually distinct from the algorithmic and mathematical errors that our methodology is designed to eliminate.",4.8. Running the system,[0],[0]
"To improve performance, we also replace all tensors with an optimized tensor library (Eigen).",4.8. Running the system,[0],[0]
This approximation could introduce errors into our system if for whatever reason the Eigen methods we use are not functionally equivalent to ones we formally reason about; of course developers could achieve even higher assurance by verifying their optimized tensor code as well.,4.8. Running the system,[0],[0]
Certigrad is efficient.,4.9. Experiments,[0],[0]
"As an experiment, we trained an AEVB model with a 2-layer encoding network and a 2- layer decoding network on MNIST using the optimization procedure ADAM (Kingma & Ba, 2014), and compared both the expected loss and the running time of our system
at each iteration against the same model and optimization procedure in TensorFlow, both running on 2 CPU cores.",4.9. Experiments,[0],[0]
"We find that our expected losses decrease at the same rate, and that while Certigrad takes 25% longer for the first few iterations, its performance is more stable over time and it eventually surpasses TensorFlow (Figure 6).",4.9. Experiments,[0],[0]
"Our primary motivation is to develop bug-free machine learning systems, but our approach may provide significant benefits even when building systems that need not be perfect.",5. Discussion,[0],[0]
"Perhaps the greatest burden software developers must bear is needing to fully understand how and why their system works, and we found that by formally specifying the system requirements we were able to relegate much of this burden to the computer.",5. Discussion,[0],[0]
"Not only were we able to synthesize some fragments of the system (§4.5), we were able to achieve extremely high confidence that our system was bug-free without needing to think about how all the pieces of the system fit together.",5. Discussion,[0],[0]
"In our approach, the computer— not the human—is responsible for ensuring that all the local properties that the developer establishes imply that the overall system is correct.",5. Discussion,[0],[0]
"Although using our methodology to develop Certigrad imposed many new requirements and increased the overall workload substantially, we found that on the whole it made the development process less cognitively demanding.
",5. Discussion,[0],[0]
There are many ways that our methodology can be adopted incrementally.,5. Discussion,[0],[0]
"For example, specifications need not cover functional correctness, not all theorems need to be proved, unsound axioms can be used that omit certain preconditions, and more traditional code can be wrapped and axiomatized (as we did with Eigen).",5. Discussion,[0],[0]
"When developing Certigrad we pursued the ideal of a complete, machinecheckable proof of functional correctness, and achieved an extremely high level of confidence that the system was correct.",5. Discussion,[0],[0]
"However, we realized many of the benefits of our methodology—including partial synthesis and reduced cognitive demand—early in the process before proving most of the lemmas.",5. Discussion,[0],[0]
"Although we could not be certain that we had found all of the bugs before we made our axioms sound and filled in the gaps in the formal proofs, in hindsight we had eliminated all bugs early in the process as well.",5. Discussion,[0],[0]
"While a pure version of our methodology may already be cost-effective for high-assurance applications, we expect that pragmatic use of our methodology could yield many of the benefits for relatively little cost and could be useful for developing a wide range of machine learning systems to varying standards of correctness.",5. Discussion,[0],[0]
"We thank Jacob Steinhardt, Alexander Ratner, Cristina White, William Hamilton, Nathaniel Thomas, and Vatsal Sharan for providing valuable feedback on early drafts.",Acknowledgments,[0],[0]
"We also thank Leonardo de Moura, Tatsu Hashimoto, and Joseph Helfer for helpful discussions.",Acknowledgments,[0],[0]
This work was supported by Future of Life Institute grant 2016-158712.,Acknowledgments,[0],[0]
"Noisy data, non-convex objectives, model misspecification, and numerical instability can all cause undesired behaviors in machine learning systems.",abstractText,[0],[0]
"As a result, detecting actual implementation errors can be extremely difficult.",abstractText,[0],[0]
We demonstrate a methodology in which developers use an interactive proof assistant to both implement their system and to state a formal theorem defining what it means for their system to be correct.,abstractText,[0],[0]
The process of proving this theorem interactively in the proof assistant exposes all implementation errors since any error in the program would cause the proof to fail.,abstractText,[0],[0]
"As a case study, we implement a new system, Certigrad, for optimizing over stochastic computation graphs, and we generate a formal (i.e. machine-checkable) proof that the gradients sampled by the system are unbiased estimates of the true mathematical gradients.",abstractText,[0],[0]
We train a variational autoencoder using Certigrad and find the performance comparable to training the same model in TensorFlow.,abstractText,[0],[0]
Developing Bug-Free Machine Learning Systems With Formal Mathematics,title,[0],[0]
"Over the past few years, neural networks have proven to be a general and effective tool for many practical problems, such as image classification (Krizhevsky et al., 2012; Szegedy et al., 2015; He et al., 2016), speech recognition (Hinton et al., 2012; Graves & Jaitly, 2014; Hannun et al., 2014; Chan et al., 2015), machine translation (Sutskever et al., 2014; Cho et al., 2014; Bahdanau
*Equal contribution 1Google Brain 2Members of the Google Brain Residency Program (g.co/brainresidency) 3Google.",1. Introduction,[0],[0]
"Correspondence to: Azalia Mirhoseini <azalia@google.com>, Hieu Pham <hyhieu@google.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"et al., 2015; Wu et al., 2016) and speech synthesis (Oord et al., 2016; Arik et al., 2017; Wang et al., 2017).",1. Introduction,[0],[0]
Together with their success is the growth in size and computational requirements of training and inference.,1. Introduction,[0],[0]
"Currently, a typical approach to address these requirements is to use a heterogeneous distributed environment with a mixture of many CPUs and GPUs.",1. Introduction,[0],[0]
"In this environment, it is a common practice for a machine learning practitioner to specify the device placement for certain operations in the neural network.",1. Introduction,[0],[0]
"For example, in a neural translation network, each layer, including all LSTM layers, the attention layer, and the softmax layer, is computed by a GPU (Sutskever et al., 2014; Wu et al., 2016).
",1. Introduction,[0],[0]
"Although such decisions can be made by machine learning practitioners, they can be challenging, especially when the network has many branches (Szegedy et al., 2016), or when the minibatches get larger.",1. Introduction,[0],[0]
"Existing algorithmic solvers (Pellegrini, 2009; Karypis & Kumar, 1995b), on the other hand, are not flexible enough to work with a dynamic environment with many interferences.
",1. Introduction,[0],[0]
"In this paper, we propose a method which learns to optimize device placement for training and inference with neural networks.",1. Introduction,[0],[0]
"The method, illustrated in Figure 1, takes into account information of the environment by performing series of experiments to understand which parts of the model should be placed on which device, and how to arrange the computations so that the communication is optimized.",1. Introduction,[0],[0]
"Key to our method is the use of a sequence-to-sequence model to read input information about the operations as well as the dependencies between them, and then propose a placement for each operation.",1. Introduction,[0],[0]
Each proposal is executed in the hardware environment to measure the execution time.,1. Introduction,[0],[0]
"The execution time is then used as a reward signal to train the
recurrent model so that it gives better proposals over time.
",1. Introduction,[0],[0]
"Our main result is that our method finds non-trivial placements on multiple devices for Inception-V3 (Szegedy et al., 2016), Recurrent Neural Language Model (Zaremba et al., 2014; Jozefowicz et al., 2016) and Neural Machine Translation (Sutskever et al., 2014; Wu et al., 2016).",1. Introduction,[0],[0]
"Single-step measurements show that Scotch (Pellegrini, 2009) yields disappointing results on all three benchmarks, suggesting that their graph-based heuristics are not flexible enough for them.",1. Introduction,[0],[0]
Our method can find non-trivial placements that are up to 3.5 times faster.,1. Introduction,[0],[0]
"When applied to train the three models in real time, the placements found by our method are up to 20% faster than human experts’ placements.",1. Introduction,[0],[0]
"Our work is closely related to the idea of using neural networks and reinforcement learning for combinatorial optimization (Vinyals et al., 2015; Bello et al., 2016).",2. Related Work,[0],[0]
"The space of possible placements for a computational graph is discrete, and we model the placements using a sequenceto-sequence approach, trained with policy gradients.",2. Related Work,[0],[0]
"However, experiments in early work were only concerned with toy datasets, whereas this work applies the framework to a large-scale practical application with noisy rewards.
",2. Related Work,[0],[0]
Reinforcement learning has also been applied to optimize system performance.,2. Related Work,[0],[0]
"For example, Mao et al. (2016) propose to train a resource management algorithm with policy gradients.",2. Related Work,[0],[0]
"However, they optimize the expected value of a hand-crafted objective function based on the reward, unlike this work, where we optimize directly for the running time of the configurations, hence relieving the need to design intermediate cost models.
",2. Related Work,[0],[0]
Graph partitioning is an intensively studied subject in computer science.,2. Related Work,[0],[0]
Early work such as Kernighan & Lin (1970); Kirkpatrick et al. (1983); Fiduccia & Mattheyses (1988); Johnson et al. (1989) employ several iterative refinement procedures that start from a partition and continue to explore similar partitions to improve.,2. Related Work,[0],[0]
Alternative methods such as Hagen & Kahng (1992); Karypis & Kumar (1995b) perform spectral analyses on matrix representations of graphs to partition them.,2. Related Work,[0],[0]
"Despite their extensive literature, graph partitioning algorithms remain heuristics for computational graphs.",2. Related Work,[0],[0]
"The reason is that in order to apply these algorithms, one has to construct cost models for the graphs of concern.",2. Related Work,[0],[0]
"Since such models are expensive to even estimate and in virtually all cases, are not accurate, graph partitioning algorithms applied on them can lead to unsatisfying results, as we show in Section 4 of this paper.
",2. Related Work,[0],[0]
"A well-known graph partitioning algorithm with an open source software library is the Scotch optimizer (Pellegrini, 2009), which we use as a baseline in our experiments.
",2. Related Work,[0],[0]
"The Scotch mapper attempts to balance the computational load of a collection of tasks among a set of connected processing nodes, while reducing the cost of communication by keeping intensively communicating tasks on nearby nodes.",2. Related Work,[0],[0]
"Scotch relies on a collection of graph partitioning techniques such as k-way Fiduccia-Mattheyses (Fiduccia & Mattheyses, 1988), multilevel method (Barnard & Simon, 1994; Hendrickson & Leland, 1993; Karypis & Kumar, 1995a), band method (Chevalier & Pellegrini, 2006), diffusion method (Pellegrini, 2007), and dual recursive bipartitioning mapping (Pellegrini & Roman, 1996)).
",2. Related Work,[0],[0]
Scotch models the problem with 2 graphs.,2. Related Work,[0],[0]
"The first graph is called the target architecture graph, whose vertices represent hardware resources such as CPUs or GPUs and whose edges represent the communication paths available between them, such as a PCIe bus or a network link.",2. Related Work,[0],[0]
"The second graph is called the source graph, which models the computation to be mapped onto the target architecture graph.",2. Related Work,[0],[0]
"In the case of TensorFlow (Abadi et al., 2016), the computations of programs are modeled as a graph whose vertices represent operations, while the graph edges represent the multidimensional data arrays (tensors) communicated between them.",2. Related Work,[0],[0]
Scotch users have to choose how and when given partitioning should be applied to graphs.,2. Related Work,[0],[0]
"However, in our experiment, we rely on the software’s default strategies implemented in Scotch, which have already been extensively tuned.",2. Related Work,[0],[0]
"Consider a TensorFlow computational graph G, which consists ofM operations {o1, o2, ..., oM}, and a list ofD available devices.",3. Method,[0],[0]
"A placement P = {p1, p2, ..., pM} is an assignment of an operation oi ∈ G to a device pi, where pi ∈ {1, ..., D}.",3. Method,[0],[0]
Let r(P) denote the time that it takes to perform a complete execution of G under the placement P .,3. Method,[0],[0]
The goal of device placement optimization is to find P such that the execution time r(P) is minimized.,3. Method,[0],[0]
"While we seek to minimize the execution time r(P), direct optimization of r(P) results in two major issues.",3.1. Training with Policy Gradients,[0],[0]
"First, in the beginning of the training process, due to the bad placements sampled, the measurements of r(P) can be noisy, leading to inappropriate learning signals.",3.1. Training with Policy Gradients,[0],[0]
"Second, as the RL model gradually converges, the placements that are sampled become more similar to each other, leading to small differences between the corresponding running times, which results in less distinguishable training signals.",3.1. Training with Policy Gradients,[0],[0]
"We empirically find that the square root of running time, R(P) = √ r(P), makes the learning process more robust.",3.1. Training with Policy Gradients,[0],[0]
"Accordingly, we propose to train a stochastic pol-
icy π(P|G; θ) to minimize the objective
J(θ) = EP∼π(P|G;θ)",3.1. Training with Policy Gradients,[0],[0]
"[R (P) |G] (1)
",3.1. Training with Policy Gradients,[0],[0]
"In our work, π(P|G; θ) is defined by an attentional sequence-to-sequence model, which we will describe in Section 3.2.",3.1. Training with Policy Gradients,[0],[0]
"We learn the network parameters using Adam (Kingma & Ba, 2014) optimizer based on policy gradients computed via the REINFORCE equation (Williams, 1992),
∇θJ(θ) = EP∼π(P|G;θ)",3.1. Training with Policy Gradients,[0],[0]
[R (P) ·,3.1. Training with Policy Gradients,[0],[0]
"∇θ log p (P|G; θ)] (2)
We estimate∇θJ(θ) by drawing K placement samples using Pi ∼ π(·|G; θ).",3.1. Training with Policy Gradients,[0],[0]
"We reduce the variance of policy gradients by using a baseline term B, leading to
∇θJ(θ)",3.1. Training with Policy Gradients,[0],[0]
"≈ 1
K K∑ i=1",3.1. Training with Policy Gradients,[0],[0]
(R (Pi)−B) ·,3.1. Training with Policy Gradients,[0],[0]
"∇θ log p (Pi|G; θ) (3)
We find that a simple moving average baseline B works well in our experiments.",3.1. Training with Policy Gradients,[0],[0]
"In practice, on computational graphs with large memory footprints, some placements can fail to execute, e.g., putting all of the operations of a huge LSTM on a single GPU will exceed the device’s memory limit.",3.1. Training with Policy Gradients,[0],[0]
"For such cases, we set the square root of running time R(P) to a large constant, which we call the failing signal.",3.1. Training with Policy Gradients,[0],[0]
We specify the failing signal manually depending on the input graph.,3.1. Training with Policy Gradients,[0],[0]
"We observe that throughout our training process, some placements sporadically and unexpectedly fail, perhaps due to factors such as the state of the machine (we train our model on a shared cluster).",3.1. Training with Policy Gradients,[0],[0]
"This phenomenon is particularly undesirable towards the end of the training process, since a large difference between R(Pi) and the baseline B leads to a large update of the parameters, which potentially perturbs parameters θ out of a good minimum.",3.1. Training with Policy Gradients,[0],[0]
"We thus hard-code the training process so that after 5, 000 steps, one performs a parameter update with a sampled placement P only if the placement executes.",3.1. Training with Policy Gradients,[0],[0]
"In our experiments, we also find that initializing the baseline B with the failing signal results in more exploration.",3.1. Training with Policy Gradients,[0],[0]
"We use a sequence-to-sequence model (Sutskever et al., 2014) with LSTM (Hochreiter & Schmidhuber, 1997) and a content-based attention mechanism (Bahdanau et al., 2015) to predict the placements.",3.2. Architecture Details,[0],[0]
"Figure 2 shows the overall architecture of our model, which can be divided into two parts: encoder RNN and decoder RNN.
",3.2. Architecture Details,[0],[0]
The input to the encoder RNN is the sequence of operations of the input graph.,3.2. Architecture Details,[0],[0]
We embed the operations by concatenating their information.,3.2. Architecture Details,[0],[0]
"Specifically, for each input graph G, we first collect the types of its operations.",3.2. Architecture Details,[0],[0]
"An operation’s type describes the underlying computation, such as MatMul or conv2d.",3.2. Architecture Details,[0],[0]
"For each type, we store a tunable embedding vector.",3.2. Architecture Details,[0],[0]
We then record the size of each operation’s list of output tensors and concatenate them into a fixed-size zero-padded list called the output shape.,3.2. Architecture Details,[0],[0]
We also take the one-hot encoding vector that represents the operations that are direct inputs and outputs to each operation.,3.2. Architecture Details,[0],[0]
"Finally, the embedding of each operation is the concatenation of its type, its output shape, and its one-hot encoded adjacency information.
",3.2. Architecture Details,[0],[0]
"The decoder is an attentional LSTM (Bahdanau et al., 2015) with a fixed number of time steps that is equal to the number of operations in a graph G. At each step, the decoder outputs the device for the operation at the same encoder time step.",3.2. Architecture Details,[0],[0]
"Each device has its own tunable embedding, which is then fed as input to the next decoder time step.",3.2. Architecture Details,[0],[0]
A key challenge when applying our method to TensorFlow computational graphs is that these graphs generally have thousands of operations (see Table 1).,3.3. Co-locating Operations,[0],[0]
"Modeling such a large number of operations with sequence-to-sequence models is difficult due to vanishing and exploding gradient issues (Pascanu et al., 2013) and large memory footprints.",3.3. Co-locating Operations,[0],[0]
"We propose to reduce the number of objects to place on dif-
ferent devices by manually forcing several operations to be located on the same device.",3.3. Co-locating Operations,[0],[0]
"In practice, this is implemented by the colocate with feature of TensorFlow.
",3.3. Co-locating Operations,[0],[0]
We use several heuristics to create co-location groups.,3.3. Co-locating Operations,[0],[0]
"First, we rely on TensorFlow’s default co-location groups, such as co-locating each operation’s outputs with its gradients.",3.3. Co-locating Operations,[0],[0]
We further apply a simple heuristic to merge more operations into co-location groups.,3.3. Co-locating Operations,[0],[0]
"Specifically, if the output of an operation X is consumed only by another operation Y , then operations X and Y are co-located.",3.3. Co-locating Operations,[0],[0]
Many initialization operations in TensorFlow can be grouped in this way.,3.3. Co-locating Operations,[0],[0]
"In our experiments, we apply this heuristic recursively, and after each iteration, we treat the co-location groups as operations until there are not any further groups that can be merged.",3.3. Co-locating Operations,[0],[0]
"For certain models, we apply specific rules to construct co-location groups.",3.3. Co-locating Operations,[0],[0]
"For example, with ConvNets, we can treat several convolutions and pooling layers as a co-location group, and with RNN models, we treat each LSTM cell as a group.",3.3. Co-locating Operations,[0],[0]
"We speed up the training process of our model using asynchronous distributed training, as shown in Figure 3.",3.4. Distributed Training,[0],[0]
"Our framework consists of several controllers, each of which execute the current policy defined by the attentional sequence-to-sequence model as described in Section 3.2.",3.4. Distributed Training,[0],[0]
All of the controllers interact with a single shared parameter server.,3.4. Distributed Training,[0],[0]
"We note that the parameter server holds only the controllers’ parameters, and not the input graph’s parameters, because keeping the input graph’s parameters on the parameter server can potentially create a latency bottleneck to transfer these parameters.",3.4. Distributed Training,[0],[0]
"Each controller in our framework interacts with K workers, where K is the number of Monte Carlo samples in Equation 3.
",3.4. Distributed Training,[0],[0]
The training process has two alternating phases.,3.4. Distributed Training,[0],[0]
"In the first phase, each worker receives a signal that indicates that it should wait for placements from its controller, while each controller receives a signal that indicates it should sample K placements.",3.4. Distributed Training,[0],[0]
Each sampled placement comes with a probability.,3.4. Distributed Training,[0],[0]
"Each controller then independently sends the
placements to their workers, one placement per worker, and sends a signal to indicate a phase change.
",3.4. Distributed Training,[0],[0]
"In the second phase, each worker executes the placement it receives and measures the running time.",3.4. Distributed Training,[0],[0]
"To reduce the variance in these measurements, each placement is executed for 10 steps and the average running time of the steps but the first one is recorded.",3.4. Distributed Training,[0],[0]
"We observe that in TensorFlow, the first step can take longer to execute compared to the following steps, and hence we treat itss runing time as an outlier.",3.4. Distributed Training,[0],[0]
Each controller waits for all of its workers to finish executing their assigned placements and returning their running times.,3.4. Distributed Training,[0],[0]
"When all of the running times are received, the controller uses the running times to scale the corresponding gradients to asynchronously update the controller parameters that reside in the parameter server.
",3.4. Distributed Training,[0],[0]
"In our experiments, we use up to 20 controllers, each with either 4 or 8 workers.",3.4. Distributed Training,[0],[0]
"Under this setting, it takes between 12 to 27 hours to find the best placement for the models in our experiments.",3.4. Distributed Training,[0],[0]
"Using more workers per controller yields more accurate estimates of the policy gradient as in Equation 3, but comes at the expense of possibly having to put more workers in idle states.",3.4. Distributed Training,[0],[0]
"We also note that due to the discrepancies between machines, it is more stable to let each controller have its own baseline.",3.4. Distributed Training,[0],[0]
"In the following experiments, we apply our proposed method to assign computations to devices on three important neural networks in the deep learning literature:",4. Experiments,[0],[0]
"Recurrent Neural Language Model (RNNLM) (Zaremba et al., 2014; Jozefowicz et al., 2016), Attentional Neural Machine Translation (Bahdanau et al., 2015), and InceptionV3 (Szegedy et al., 2016).",4. Experiments,[0],[0]
We compare the RL placements against strong existing baselines described in Section 4.2.,4. Experiments,[0],[0]
Benchmarks.,4.1. Experiment Setup,[0],[0]
"We evaluate our approach on three established deep learning models:
• Recurrent Neural Network Language Model (RNNLM) with multiple LSTM layers (Zaremba et al., 2014; Jozefowicz et al., 2016).",4.1. Experiment Setup,[0],[0]
"The grid structure of this model introduces tremendous potential for parallel executions because each LSTM cell can start as soon as its input and previous states are available.
",4.1. Experiment Setup,[0],[0]
"• Neural Machine Translation with attention mechanism (NMT) (Bahdanau et al., 2015; Wu et al., 2016).",4.1. Experiment Setup,[0],[0]
"While the architecture of this model is similar to that of RNNLM, its large number of hidden states due to the source and target sentences necessitates model parallelism.",4.1. Experiment Setup,[0],[0]
"Both Sutskever et al. (2014) and Wu
et al. (2016) propose to place each LSTM layer, the attention layer, and the softmax layer, each on a separate device.",4.1. Experiment Setup,[0],[0]
"While the authors observe significant improvements at training time, their choices are not optimal.",4.1. Experiment Setup,[0],[0]
"In fact, we show in our experiments that a trained policy can find significantly better placements.
",4.1. Experiment Setup,[0],[0]
"• Inception-V3 (Szegedy et al., 2016) is a widely-used architecture for image recognition and visual feature extraction (Khetan & Oh, 2016; Esteva et al., 2016).",4.1. Experiment Setup,[0],[0]
The Inception network has multiple blocks.,4.1. Experiment Setup,[0],[0]
"Each block has several branches of convolutional and pooling layers, which are then concatenated to make the inputs for the next block.",4.1. Experiment Setup,[0],[0]
"While these branches can be executed in parallel, the network’s depth restricts such potential since the later blocks have to wait for the previous ones.
",4.1. Experiment Setup,[0],[0]
Model details.,4.1. Experiment Setup,[0],[0]
"For Inception-V3, each step is executed on a batch of images, each of size 299 × 299 × 3, which is the widely-used setting for the ImageNet Challenge (Szegedy et al., 2015).",4.1. Experiment Setup,[0],[0]
"For RNNLM and NMT, we use the model with 2 LSTM layers, with sizes of 2048 and 1024, respectively.",4.1. Experiment Setup,[0],[0]
"We set the number of unrolling steps for RNNLM, as well as the maximum length for the source and target sentences of NMT, to 40.",4.1. Experiment Setup,[0],[0]
"Each pass on RNNLM and NMT consists of a minibatch of 64 sequences.
",4.1. Experiment Setup,[0],[0]
Co-location groups.,4.1. Experiment Setup,[0],[0]
We pre-process the TensorFlow computational graphs of the three aforementioned models to manually create their co-location groups.,4.1. Experiment Setup,[0],[0]
"More precisely; for RNNLM and NMT, we treat each LSTM cell, each embedding lookup, each attention step and each softmax prediction step as a group; for Inception-V3, we treat each branch as a group.",4.1. Experiment Setup,[0],[0]
"Table 1 shows the grouping statistics of these models.
",4.1. Experiment Setup,[0],[0]
Metrics.,4.1. Experiment Setup,[0],[0]
"We implement training operations for RNNLM and NMT using Adam (Kingma & Ba, 2014), and for Inception-V3 using RMSProp (Tieleman & Hinton, 2012).",4.1. Experiment Setup,[0],[0]
"We evaluate a placement by the total time it takes to perform one forward pass, one backward pass and one parameter update.",4.1. Experiment Setup,[0],[0]
"To reduce measurement variance, we average the running times over several trials.",4.1. Experiment Setup,[0],[0]
"Additionally, we train each model from scratch using the placements found by our method and compare the training time to that of the strongest baseline placement.
Devices.",4.1. Experiment Setup,[0],[0]
"In our experiments, the available devices are 1 Intel Haswell 2300 CPU, which has 18 cores, and either 2 or 4 Nvidia Tesla K80 GPUs.",4.1. Experiment Setup,[0],[0]
We allow 50 GB of RAM for all models and settings.,4.1. Experiment Setup,[0],[0]
Single-CPU.,4.2. Baselines,[0],[0]
This placement executes the whole neural network on a single CPU.,4.2. Baselines,[0],[0]
"Processing some large models on GPUs is infeasible due to memory limits, leaving SingleCPU the only choice despite being slow.
",4.2. Baselines,[0],[0]
Single-GPU.,4.2. Baselines,[0],[0]
This placement executes the whole neural network on a single CPU.,4.2. Baselines,[0],[0]
"If an operation lacks GPU implemention, it will be placed on CPU.
Scotch.",4.2. Baselines,[0],[0]
"We estimate the computational costs of each operation as well as the amount of data that flows along each edge of the neural network model, and feed them to the Scotch static mapper (Pellegrini, 2009).",4.2. Baselines,[0],[0]
"We also annotate the architecture graph (see Section 2) with compute and communication capacities of the underlying devices.
",4.2. Baselines,[0],[0]
MinCut.,4.2. Baselines,[0],[0]
"We use the same Scotch optimizer, but eliminate the CPU from the list of available devices fed to the optimizer.",4.2. Baselines,[0],[0]
"Similar to the single-GPU placement, if an operation has no GPU implementation, it runs on the CPU.
",4.2. Baselines,[0],[0]
Expert-designed.,4.2. Baselines,[0],[0]
"For RNNLM and NMT, we put each LSTM layer on a device.",4.2. Baselines,[0],[0]
"For NMT, we also put the attention mechanism and the softmax layer on the same device with the highest LSTM layer, and we put the embedding layer on the same device with the first LSTM layer.",4.2. Baselines,[0],[0]
"For Inception-V3, the common practice for the batch size of 32 is to put the entire model on a single GPU.",4.2. Baselines,[0],[0]
There is no implementation of Inception-V3 with batch 32 using more than 1 GPU.,4.2. Baselines,[0],[0]
"To create an intuitive baseline on multiple GPUs, we heuristically partition the model into contiguous parts that have roughly the same number of layers.",4.2. Baselines,[0],[0]
We compare against this approach in Section 4.3.,4.2. Baselines,[0],[0]
The common practice for Inception-V3 with the larger batch size of 128 is to apply data parallelism using 4 GPUs.,4.2. Baselines,[0],[0]
"Each GPU runs a replica of the model and processes a batch of size 32 (Szegedy et al., 2016).",4.2. Baselines,[0],[0]
We compare against this approach in Section 4.4.,4.2. Baselines,[0],[0]
"In Table 2, we present the per-step running times of the placements found by our method and by the baselines.",4.3. Single-Step Runtime Efficiency,[0],[0]
We observe that our model is either on par with or better than other methods of placements.,4.3. Single-Step Runtime Efficiency,[0],[0]
"Despite being given no information other than the running times of the placements and the number of available devices, our model learns subtle tradeoffs between performance gain by parallelism and
LSTM 2
LSTM 1
Embedding
Softmax
Attention
LSTM 2
LSTM 1
Embedding
Figure 4.",4.3. Single-Step Runtime Efficiency,[0],[0]
RL-based placement of Neural MT graph.,4.3. Single-Step Runtime Efficiency,[0],[0]
"Top: encoder, Bottom: decoder.",4.3. Single-Step Runtime Efficiency,[0],[0]
"Devices are denoted by colors, where the transparent color represents an operation on a CPU and each other unique color represents a different GPU.",4.3. Single-Step Runtime Efficiency,[0],[0]
"This placement achieves an improvement of 19.3% in running time compared to the fine-tuned expert-designed placement.
",4.3. Single-Step Runtime Efficiency,[0],[0]
"the costs induced by inter-device communications.
",4.3. Single-Step Runtime Efficiency,[0],[0]
RNNLM.,4.3. Single-Step Runtime Efficiency,[0],[0]
"Our method detects that it is possible to fit the whole RNNLM graph into one GPU, and decides to do so to save the inter-device communication latencies.",4.3. Single-Step Runtime Efficiency,[0],[0]
"The resulting placement is more than twice faster than the best published human-designed baseline.
",4.3. Single-Step Runtime Efficiency,[0],[0]
Neural MT.,4.3. Single-Step Runtime Efficiency,[0],[0]
Our method finds a non-trivial placement (see Figure 4) that leads to a speedup of up to 20.6% for 4 GPUs.,4.3. Single-Step Runtime Efficiency,[0],[0]
"Our method also learns to put the less computational expensive operations, such as embedding lookups, on the CPU.",4.3. Single-Step Runtime Efficiency,[0],[0]
"We suspect that whilst being the slowest device, the CPU can handle these lookup operations (which are less computationally expensive than other operations) to reduce the load for other GPUs.
",4.3. Single-Step Runtime Efficiency,[0],[0]
Inception-V3.,4.3. Single-Step Runtime Efficiency,[0],[0]
"For Inception-V3 with the batch size of 32, RL-based placer learns that when there are only 2 GPUs available, the degree of freedom for model parallelism is limited.",4.3. Single-Step Runtime Efficiency,[0],[0]
It thus places all the operations on a single GPU (although it could use 2 GPUs).,4.3. Single-Step Runtime Efficiency,[0],[0]
"However, when 4 GPUs are available, the RL-based placer finds an efficient way to use all of the GPUs, reducing the model’s per-step running time from 4.60 seconds to 3.85 seconds.",4.3. Single-Step Runtime Efficiency,[0],[0]
"This result is significant, as neither of our baselines could find a placement
better than assigning all the operations to a single GPU.
",4.3. Single-Step Runtime Efficiency,[0],[0]
"We also conduct a simple extension of our experiments, by increasing the batch sizes of RNNLM and NMT to 256, and their LSTM sizes to 4, 096 and 2, 048, respectively.",4.3. Single-Step Runtime Efficiency,[0],[0]
"This makes the models’ memory footprints so large that even one layer of them cannot be fitted into any single device, hence ruling out the human-designed placement.",4.3. Single-Step Runtime Efficiency,[0],[0]
"Nevertheless, after several steps of finding placements that fail to run, our approach manages to find a way to successfully place input models on devices The running times of the placements found for large RNNLM and NMT are 33.46 and 35.84 seconds, respectively.",4.3. Single-Step Runtime Efficiency,[0],[0]
"We now investigate whether the RL-based placements can speedup not only the single-step running time but also the entire training process.
",4.4. End-to-End Runtime Efficiency,[0],[0]
Neural MT.,4.4. End-to-End Runtime Efficiency,[0],[0]
"We train our Neural MT model on the WMT14 English-German dataset.1 For these experiments, we pre-process the dataset into word pieces (Wu et al., 2016) such that the vocabularies of both languages consist of 32, 000 word pieces.",4.4. End-to-End Runtime Efficiency,[0],[0]
"In order to match our model’s set-
1http://www.statmt.org/wmt14/
tings, we consider only the translation pairs where no sentence has more than 40 word pieces.",4.4. End-to-End Runtime Efficiency,[0],[0]
"We train each model for 200, 000 steps and record their train perplexities.",4.4. End-to-End Runtime Efficiency,[0],[0]
Each training machine has 4 Nvidia Tesla K80 GPUs and 1 Intel Haswell 2300 CPU.,4.4. End-to-End Runtime Efficiency,[0],[0]
"Since there are inevitable noises in the computer systems when measuring the running times, we train each model 4 times independently and average their per-step running times and perplexities.
",4.4. End-to-End Runtime Efficiency,[0],[0]
"The RL-based placement runs faster than the expertdesigned placement, as shown in the training curves in Figure 6.",4.4. End-to-End Runtime Efficiency,[0],[0]
"Quantitatively, the expert-designed placement, which puts each layer (LSTM, attention and softmax) on a different GPU, takes 229.57 hours; meanwhile the RLbased placement (see Figure 4) takes 165.73 hours, giving 27.8% speed up of total training time.",4.4. End-to-End Runtime Efficiency,[0],[0]
"We note that the measured speedup rate (and the running times) of these models appear different than reported in Table 2 because measuring them in our RL method has several overheads.
",4.4. End-to-End Runtime Efficiency,[0],[0]
Inception-V3.,4.4. End-to-End Runtime Efficiency,[0],[0]
"We train Inception-V3 on the ImageNet dataset (Russakovsky et al., 2015) until the model reaches the accuracy of 72% on the validation set.",4.4. End-to-End Runtime Efficiency,[0],[0]
"In practice, more often, inception models are trained with data parallelism rather than model parallelism.",4.4. End-to-End Runtime Efficiency,[0],[0]
"We thus compare the place-
ments found by our algorithm (see Figure 5) against two such baselines.
",4.4. End-to-End Runtime Efficiency,[0],[0]
"The first baseline, called Asynchronous towers, puts one replica of the Inception-V3 network on each GPU.",4.4. End-to-End Runtime Efficiency,[0],[0]
"These replicas share the data reading operations, which are assigned to the CPU.",4.4. End-to-End Runtime Efficiency,[0],[0]
Each replica independently performs forward and backward passes to compute the model’s gradients with respect to a minibatch of 32 images and then updates the parameters asynchronously.,4.4. End-to-End Runtime Efficiency,[0],[0]
"The second baseline, called Synchronous Tower, is the same as Asynchronous towers, except that it waits for the gradients of all copies before making an update.",4.4. End-to-End Runtime Efficiency,[0],[0]
"All settings use the learning rate of 0.045 and are trained using RMSProp.
Figure 7 shows the training curves of the three settings for Inception-V3.",4.4. End-to-End Runtime Efficiency,[0],[0]
"As can be seen from the figure, the end-toend training result confirms that the RL-based placement indeed speedups the training process by 19.7% compared to the Synchronous Tower.",4.4. End-to-End Runtime Efficiency,[0],[0]
"While Asynchronous towers gives a better per-step time, synchronous approaches lead to faster convergence.",4.4. End-to-End Runtime Efficiency,[0],[0]
"The training curve of the RL-based placement, being slower at first, eventually crosses the training curve of Asynchronous towers.",4.4. End-to-End Runtime Efficiency,[0],[0]
"In order to understand the rationale behind the RL-based placements, we analyze their profiling information and compare them against those of expert-designed placements.
",4.5. Analysis of Found Placements,[0],[0]
Neural MT.,4.5. Analysis of Found Placements,[0],[0]
We first compare the per-device computational loads by RL-based placement and expert-designed placement for the NMT model.,4.5. Analysis of Found Placements,[0],[0]
Figure 8 shows such performance profiling.,4.5. Analysis of Found Placements,[0],[0]
RL-based placement balances the workload significantly better than does the expert-designed placement.,4.5. Analysis of Found Placements,[0],[0]
"Interestingly, if we do not take into account the time for back-propagation, then expert-designed placement makes sense because the workload is more balanced (whilst still less balanced than ours).",4.5. Analysis of Found Placements,[0],[0]
"The imbalance is much more significant when back-propagation time is considered.
",4.5. Analysis of Found Placements,[0],[0]
Inception-V3.,4.5. Analysis of Found Placements,[0],[0]
"On Inception-V3, however, the RL-based placement does not seek to balance the computations between GPUs, as illustrated in Figure 9-top.",4.5. Analysis of Found Placements,[0],[0]
"We suspect this is because Inception-V3 has more dependencies than NMT, allowing less room for model parallelism across GPUs.",4.5. Analysis of Found Placements,[0],[0]
"The reduction in running time of the RL-based placement comes from the less time it spends copying data between devices, as shown in Figure 9-bottom.",4.5. Analysis of Found Placements,[0],[0]
"In particular, the models parameters are on the same device as the operations that use them, unlike in Synchronous tower, where all towers have to wait for all parameters have to be updated and sent to them.",4.5. Analysis of Found Placements,[0],[0]
"On the contrary, that use them to reduce the communication cost, leading to overall reduction in computing time.",4.5. Analysis of Found Placements,[0],[0]
"In this paper, we present an adaptive method to optimize device placements for neural networks.",5. Conclusion,[0],[0]
Key to our approach is the use of a sequence-to-sequence model to propose device placements given the operations in a neural network.,5. Conclusion,[0],[0]
The model is trained to optimize the execution time of the neural network.,5. Conclusion,[0],[0]
"Besides the execution time, the number of available devices is the only other information about the hardware configuration that we feed to our model.
",5. Conclusion,[0],[0]
Our results demonstrate that the proposed approach learns the properties of the environment including the complex tradeoff between computation and communication in hardware.,5. Conclusion,[0],[0]
"On a range of tasks including image classification, language modeling, and machine translation, our method surpasses placements carefully designed by human experts and highly optimized algorithmic solvers.",5. Conclusion,[0],[0]
"We thank Martin Abadi, Stephan Gouws, and the Google Brain team for their help with the project.",Acknowledgements,[0],[0]
The past few years have witnessed a growth in size and computational requirements for training and inference with neural networks.,abstractText,[0],[0]
"Currently, a common approach to address these requirements is to use a heterogeneous distributed environment with a mixture of hardware devices such as CPUs and GPUs.",abstractText,[0],[0]
"Importantly, the decision of placing parts of the neural models on devices is often made by human experts based on simple heuristics and intuitions.",abstractText,[0],[0]
"In this paper, we propose a method which learns to optimize device placement for TensorFlow computational graphs.",abstractText,[0],[0]
Key to our method is the use of a sequence-tosequence model to predict which subsets of operations in a TensorFlow graph should run on which of the available devices.,abstractText,[0],[0]
The execution time of the predicted placements is then used as the reward signal to optimize the parameters of the sequence-to-sequence model.,abstractText,[0],[0]
"Our main result is that on Inception-V3 for ImageNet classification, and on RNN LSTM, for language modeling and neural machine translation, our model finds non-trivial device placements that outperform hand-crafted heuristics and traditional algorithmic methods.",abstractText,[0],[0]
Device Placement Optimization with Reinforcement Learning,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1339–1349 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1339",text,[0],[0]
Building natural language interfaces to databases (NLIDB) is a long-standing open problem and has significant implications for many application domains.,1 Introduction,[0],[0]
It can enable users without SQL programming background to freely query the data they have.,1 Introduction,[0],[0]
"For this reason, generating SQL queries from natural language questions has gained a renewed interest due to the recent advance in deep learning and semantic parsing (Yaghmazadeh et al., 2017; Zhong et al., 2017; Xu et al., 2017; Iyer et al., 2017).
",1 Introduction,[0],[0]
"While new methods race to achieve the stateof-the-art performance on NLIDB datasets such as WikiSQL (Xu et al., 2017; Zhong et al., 2017), the accuracy is still not high enough for real use.",1 Introduction,[0],[0]
"For example, SQLNet (Xu et al., 2017) achieves 61.3% accuracy on WikiSQL.",1 Introduction,[0],[0]
"After analyzing the error cases of Seq2SQL (Zhong et al., 2017) and SQLNet, we recognized that many wrong translations cannot be easily corrected due to the lack of external knowledge and semantic understanding.
",1 Introduction,[0],[0]
"In this paper, we aim to alleviate the aforementioned problem by putting human users in the loop.",1 Introduction,[0],[0]
"Previous human-in-the-loop NLIDBs (Li and Jagadish, 2014; Yaghmazadeh et al., 2017) rely on users to carefully go through a generated SQL query and revise it accordingly, which is not feasible for users who do not know the SQL language.",1 Introduction,[0],[0]
"Instead, we resort to a different approach by introducing a goal-oriented dialogue model, DialSQL, that interacts with users to extract and correct potential errors in the generated queries.
",1 Introduction,[0],[0]
"Given a SQL query generated from a natural language question, we assume any segment, or span, of the generated query such as a WHERE clause can be potentially erroneous.",1 Introduction,[0],[0]
The goal of DialSQL is to extract the erroneous spans and ask users multi-choice questions to validate and correct these errors.,1 Introduction,[0],[0]
DialSQL is based on a hierarchical encoder-decoder architecture with attention and pointer mechanisms.,1 Introduction,[0],[0]
The model first encodes each turn of interaction and runs a dialogue level RNN network on the dialogue history.,1 Introduction,[0],[0]
"The output of the network is then used to predict the error category, i.e., whether it is a selection, projection, or aggregation error.",1 Introduction,[0],[0]
"Conditioned on the error category, the output of a second RNN is used to predict the start and end positions of the error span by pointing to the query tokens.",1 Introduction,[0],[0]
"Finally, candidate choices are decoded from the error category and span representations.",1 Introduction,[0],[0]
"Following previous
work (Zhong et al., 2017; Xu et al., 2017), we only use column names and do not utilize table values.
",1 Introduction,[0],[0]
How to train and evaluate DialSQL become two challenging issues due to the lack of error data and interaction data.,1 Introduction,[0],[0]
"In this work, we construct a simulator to generate simulated dialogues, a general approach practiced by many dialogue studies.",1 Introduction,[0],[0]
"Inspired by the agenda-based methods for user simulation (Schatzmann et al., 2007), we keep an agenda of pending actions that are needed to induce the ground truth query.",1 Introduction,[0],[0]
"At the start of the dialogue, a new query is carefully synthesized by randomly altering the ground truth query and the agenda is populated by the sequence of altering actions.",1 Introduction,[0],[0]
Each action consists of three sub-actions: (i) Pick an error category and extract a span; (ii) Raise a question; (iii) Update the query by randomly altering the span and remove the action from the agenda.,1 Introduction,[0],[0]
"Consider the example in Figure 1: Step1 synthesizes the initial query by randomly altering the WHERE clause and AGGREGATION; Step2 generates the simulated dialogue by validating the altered spans and offering the correct choice.
",1 Introduction,[0],[0]
"To evaluate our model, we first train DialSQL on the simulated dialogues.",1 Introduction,[0],[0]
Initial queries for new questions are manufactured by running a black box SQL generation system on the new questions.,1 Introduction,[0],[0]
"When tested on the WikiSQL (Zhong et al., 2017) dataset, our model increases the query match accuracy of SQLNet (Xu et al., 2017) from 61.3% to 69.0% using on average 2.4 validation questions per query.",1 Introduction,[0],[0]
"Research on natural language interfaces to databases (NLIDBs), or semantic parsing, has spanned several decades.",2 Related Work,[0],[0]
"Early rule-based NLIDBs (Woods, 1973; Androutsopoulos et al., 1995; Popescu et al., 2003) employ carefully designed rules to map natural language questions to formal meaning representations like SQL queries.",2 Related Work,[0],[0]
"While having a high precision, rule-based systems are brittle when facing with language variations.",2 Related Work,[0],[0]
"The rise of statistical models (Zettlemoyer and Collins, 2005; Kate et al., 2005; Berant et al., 2013), especially the ongoing wave of neural network models (Yih et al., 2015; Dong and Lapata, 2016; Sun et al., 2016; Zhong et al., 2017; Xu et al., 2017; Guo and Gao, 2018; Yavuz et al., 2016), has enabled NLIDBs that are more robust to language variations.",2 Related Work,[0],[0]
Such systems allow users to formulate questions with greater flexibility.,2 Related Work,[0],[0]
"However, although state-of-the-art systems have achieved a high accuracy of 80% to 90% (Dong and Lapata, 2016) on well-curated datasets like GEO (Zelle and Ray, 1996) and ATIS (Zettlemoyer and Collins, 2007), the best accuracies on datasets with questions formulated by real human users, e.g., WebQuestions (Berant et al., 2013), GraphQuestions (Su et al., 2016), and WikiSQL (Zhong et al., 2017), are still far from enough for real use, typically in the range of 20% to 60%.
",2 Related Work,[0],[0]
Human-in-the-loop systems are a promising paradigm for building practical NLIDBs.,2 Related Work,[0],[0]
A number of recent studies have explored this paradigm with two types of user interaction: coarse-grained and fine-grained.,2 Related Work,[0],[0]
"Iyer et al. (2017) and Li et
al. (2016) incorporate coarse-grained user interaction, i.e., asking the user to verify the correctness of the final results.",2 Related Work,[0],[0]
"However, for real-world questions, it may not always be possible for users to verify result correctness, especially in the absence of supporting evidence.",2 Related Work,[0],[0]
Li and Jagadish (2014) and Yaghmazadeh et al. (2017) have shown that incorporating fine-grained user interaction can greatly improve the accuracy of NLIDBs.,2 Related Work,[0],[0]
"However, they require that the users have intimate knowledge of SQL, an assumption that does not hold for general users.",2 Related Work,[0],[0]
"Our method also enables fine-grained user interaction for NLIDBs, but we solicit user feedback via a dialogue between the user and the system.
",2 Related Work,[0],[0]
"Our model architecture is inspired by recent studies on hierarchical neural network models (Sordoni et al., 2015; Serban et al., 2015; Gur et al., 2017).",2 Related Work,[0],[0]
"Recently, Saha et al. (2018) propose a hierarchical encoder-decoder model augmented with key-value memory network for sequential question answering over knowledge graphs.",2 Related Work,[0],[0]
"Users ask a series of questions, and their system finds the answers by traversing a knowledge graph and resolves coreferences between questions.",2 Related Work,[0],[0]
"Our interactive query generation task significantly differs from their setup in that we aim to explicitly detect and correct the errors in the generated SQL query via a dialogue between our model and the user.
",2 Related Work,[0],[0]
"Agenda based user simulations have been investigated in goal-oriented dialogues for model training (Schatzmann et al., 2007).",2 Related Work,[0],[0]
"Recently, Seq2seq neural network models are proposed for user simulation (Asri et al., 2016) that utilize additional state tracking signals and encode dialogue turns
in a more coarse way.",2 Related Work,[0],[0]
We design a simulation method for the proposed task where we generate dialogues with annotated errors by altering queries and tracking the sequence of alteration steps.,2 Related Work,[0],[0]
We study the problem of building an interactive natural language interface to databases (INLIDB) for synthesizing SQL queries from natural language questions.,3 Problem Setup and Datasets,[0],[0]
"In particular, our goal is to design a dialogue system to extract and validate potential errors in generated queries by asking users multi-choice questions over multiple turns.",3 Problem Setup and Datasets,[0],[0]
We will first define the problem formally and then explain our simulation strategy.,3 Problem Setup and Datasets,[0],[0]
"At the beginning of each dialogue, we are given a question Q = {q1, q2, · · · , qN}, a table with column names T = {T1, T2, · · · , TK} where each name is a sequence of words, and an initial SQL query U generated using a black box SQL generation system.",3.1 Interactive Query Generation,[0],[0]
"Each turn t is represented by a tuple of system and user responses, (St, Rt), and augmented with the dialogue history (list of previous turns), Ht.",3.1 Interactive Query Generation,[0],[0]
"Each system response is a triplet of error category c, error span s, and a set of candidate choices C, i.e., St = (c, s, C).",3.1 Interactive Query Generation,[0],[0]
An error category (Table 2) denotes the type of the error that we seek to correct and an error span is the segment of the current query that indicates the actual error.,3.1 Interactive Query Generation,[0],[0]
"Candidate choices depend on the error category and range over the following possibilities: (i) a column name, (ii) an aggregation operator, or (iii) a where condition.",3.1 Interactive Query Generation,[0],[0]
"User responses are represented by ei-
ther an affirmation or a negation answer and an index c′ to identify a choice.",3.1 Interactive Query Generation,[0],[0]
"We define the interactive query generation task as a list of subtasks: at each turn t, (i) predict c, (ii) extract s from U , and (iii) decode C.",3.1 Interactive Query Generation,[0],[0]
"The task is supervised and each subtask is annotated with labeled data.
",3.1 Interactive Query Generation,[0],[0]
Consider the example dialogue in Table 1.,3.1 Interactive Query Generation,[0],[0]
"We first predict validate agg as the error category and error span (start = 1, end = 2) is decoded by pointing to the aggregation segment of the query.",3.1 Interactive Query Generation,[0],[0]
"Candidate choices, (average, no agg), are decoded using the predicted error category, predicted error span, and dialogue history.",3.1 Interactive Query Generation,[0],[0]
We use a template based natural language generation (NLG) component to convert system and user responses into natural language.,3.1 Interactive Query Generation,[0],[0]
"In our work, we evaluate our model on the WikiSQL task.",3.2 Dialogue Simulation for INLIDB,[0],[0]
Each example in WikiSQL consists of a natural language question and a table to query from.,3.2 Dialogue Simulation for INLIDB,[0],[0]
The task is to generate a SQL query that correctly maps the question to the given table.,3.2 Dialogue Simulation for INLIDB,[0],[0]
"Unfortunately, the original WikiSQL lacks error data and user interaction data to train and evaluate DialSQL.",3.2 Dialogue Simulation for INLIDB,[0],[0]
"We work around this problem by designing a simulator to bootstrap training dialogues and evaluate DialSQL on the test questions of WikiSQL.
",3.2 Dialogue Simulation for INLIDB,[0],[0]
"Inspired by the agenda-based methods (Schatzmann et al., 2007), we keep an agenda of pending actions that are needed to induce the ground truth query.",3.2 Dialogue Simulation for INLIDB,[0],[0]
"At the start of the dialogue, we synthesize a new query by randomly altering the ground truth query and populating the agenda by the sequence of altering actions.",3.2 Dialogue Simulation for INLIDB,[0],[0]
"Each action launches a sequence of sub-actions: (i) Randomly select an error category and extract a related span from the current query, (ii) randomly generate a valid choice for the chosen span, and (iii) update the current query by replacing the span with the choice.",3.2 Dialogue Simulation for INLIDB,[0],[0]
"The dialogue is initiated with the final query and a rule-based system interacts with a rule-based user
simulator to populate the dialogue.",3.2 Dialogue Simulation for INLIDB,[0],[0]
The rule-based system follows the sequence of altering actions previously generated and asks the user simulator a single question at each turn.,3.2 Dialogue Simulation for INLIDB,[0],[0]
"The user simulator has access to the ground truth query and answers each question by comparing the question (error span and the choice) with the ground truth.
",3.2 Dialogue Simulation for INLIDB,[0],[0]
Consider the example in Figure 1 where Step1 synthesizes the initial query and Step-2 simulates a dialogue using the outputs of Step-1.,3.2 Dialogue Simulation for INLIDB,[0],[0]
Step-1 first randomly alters the WHERE clause; the operator is replaced with a random operator.,3.2 Dialogue Simulation for INLIDB,[0],[0]
The updated query is further altered and the final query is passed to Step-2.,3.2 Dialogue Simulation for INLIDB,[0],[0]
"In Step-2, the system starts with validating the aggregation with the user simulator.",3.2 Dialogue Simulation for INLIDB,[0],[0]
"In this motivating example, the aggregation is incorrect and the user simulator negates and selects the offered choice.",3.2 Dialogue Simulation for INLIDB,[0],[0]
"During training, there is only a single choice offered and DialSQL trains to produce this choice; however, during testing, it can offer multiple choices.",3.2 Dialogue Simulation for INLIDB,[0],[0]
"In the next step, the system validates the WHERE clause and generates a no error action to issue the generated query.",3.2 Dialogue Simulation for INLIDB,[0],[0]
"At the end of this process, we generate a set of labeled dialogues by executing Step-1 and Step2 consecutively.",3.2 Dialogue Simulation for INLIDB,[0],[0]
DialSQL interacts with the same rule-based simulator during testing and the SQL queries obtained at the end of the dialogues are used to evaluate the model.,3.2 Dialogue Simulation for INLIDB,[0],[0]
"In this section, we present our DialSQL model and describe its operation in a fully supervised setting.",4 Dialogue Based SQL Generation,[0],[0]
DialSQL is composed of three layers linked in a hierarchical structure where each layer solves a different subtask : (i),4 Dialogue Based SQL Generation,[0],[0]
"Predicting error category, (ii)",4 Dialogue Based SQL Generation,[0],[0]
"Decoding error span, and (iii) Decoding candidate choices (illustrated in Figure 2).",4 Dialogue Based SQL Generation,[0],[0]
"Given a (Q,T, U) triplet, the model first encodes Q, each column name Ti ∈ T , and query U into vector representations in parallel using Recurrent Neural Networks (RNN).",4 Dialogue Based SQL Generation,[0],[0]
"Next, the first layer of the
model encodes the dialogue history with an RNN and predicts the error category from this encoding.",4 Dialogue Based SQL Generation,[0],[0]
The second layer is conditioned on the error category and decodes the start and end positions of the error span by attending over the outputs of query encoder.,4 Dialogue Based SQL Generation,[0],[0]
"Finally, the last layer is conditioned on both error category and error span and decodes a list of choices to offer to the user.",4 Dialogue Based SQL Generation,[0],[0]
"Each token w is associated with a vector ew from rows of an embeddings matrix E. We aim at obtaining vector representations for question, table headers, and query, then generating error category, error span, and candidate choices.
",4.1 Preliminaries and Notation,[0],[0]
"For our purposes, we use GRU units (Cho et al., 2014) in our RNN encoders which are defined as
ht = f(xt;ht−1)
where ht is the hidden state at time t. f is a nonlinear function operating on input vector xt and previous state ht−1.",4.1 Preliminaries and Notation,[0],[0]
We refer to the last hidden state of an RNN encoder as the encoding of a sequence.,4.1 Preliminaries and Notation,[0],[0]
The core of our model is a hierarchical encoderdecoder neural network that encodes dialogue history and decodes errors and candidate choices at the end of each user turn.,4.2 Encoding,[0],[0]
"The input to the model is the previous system turn and the current user turn and the output is the next system question.
",4.2 Encoding,[0],[0]
"Encoding Question, Column Names, and Query.",4.2 Encoding,[0],[0]
"Using decoupled RNNs (Enc), we encode natural language question, column names, and query sequences in parallel and produce outputs and hidden states.",4.2 Encoding,[0],[0]
"oQ, oTi , and oU denote the sequence of hidden states at each step and hQ, hTi , and hU denote the last hidden states of question, column name, and query encoders, respectively.",4.2 Encoding,[0],[0]
"Parameters of the encoders are decoupled and only the word embedding matrix E is shared.
",4.2 Encoding,[0],[0]
"Encoding System and User Turns Since there is only a single candidate choice during training, we ignore the index and encode user turn by doing an embedding lookup using the validation answer (affirmation or negation).",4.2 Encoding,[0],[0]
"Each element (error category, error span, and candidate choice) of the system response is encoded by doing an
embedding lookup and different elements are used as input at different layers of our model.
",4.2 Encoding,[0],[0]
"Encoding Dialogue History At the end of each user turn, we first concatenate the previous error category and the current user turn encodings to generate the turn level input.",4.2 Encoding,[0],[0]
"We employ an RNN to encode dialogue history and current turn into a fixed length vector as
hD10 = h Q
oD1t ,",4.2 Encoding,[0],[0]
"g D1 t = Enc([Ec, Ea])
",4.2 Encoding,[0],[0]
hD1t =,4.2 Encoding,[0],[0]
"[Attn(g D1 t , H T ), oDt ]
where [.] is vector concatenation, Ec is the error category encoding,",4.2 Encoding,[0],[0]
"Ea is the user turn encoding, hD10 is the initial hidden state, and h D1 t is the current hidden state.",4.2 Encoding,[0],[0]
"Attn is an attention layer with a bilinear product defined as in (Luong et al., 2015)
Attn(h,O) = ∑ softmax(tanh(hWO))",4.2 Encoding,[0],[0]
"∗O
",4.2 Encoding,[0],[0]
where W is attention parameter.,4.2 Encoding,[0],[0]
"We predict the error category by attending over query states using the output of the dialogue encoder as
ct = tanh(Lin([Attn(h D1 t , O U ), hD1t ]))",4.3 Predicting Error Category,[0],[0]
"lt = softmax(ct · E(C))
where Lin is a linear transformation, E(C) is a matrix with error category embeddings, and lt is the probability distribution over categories.",4.3 Predicting Error Category,[0],[0]
Consider the case in which there are more than one different WHERE clauses in the query and each clause has an error.,4.4 Decoding Error Span,[0],[0]
"In this case, the model needs to monitor previous error spans to avoid decoding the same error.",4.4 Decoding Error Span,[0],[0]
"DialSQL runs another RNN to generate a new dialogue encoding to solve the aforementioned problem as
hD20 = h Q
oD2t , g D2 t = Enc(Ec)
hD2t =",4.4 Decoding Error Span,[0],[0]
"[Attn(g D2 t , H T )oD2",4.4 Decoding Error Span,[0],[0]
"t ]
where hD20 is the initial hidden state, and h D2 t is the current hidden state.",4.4 Decoding Error Span,[0],[0]
"Start position i of the error span is decoded using the following probability distribution over query tokens
pi = softmax(tanh(h D2 t L1H U ))
where pi is the probability of start position over the ith query token.",4.4 Decoding Error Span,[0],[0]
"End position j of the error span is predicted by conditioning on the start position
ci = ∑ pi ∗HU
p̂j = softmax(tanh([h D2 t , ci]L2H U ))
where p̂j is the probability of end position over the jth query token.",4.4 Decoding Error Span,[0],[0]
Conditioning on the error category will localize the span prediction problem as each category is defined by only a small segment of the query.,4.4 Decoding Error Span,[0],[0]
"Given error category c and error span (i, j) , DialSQL decodes a list of choices that will potentially replace the error span based on user feedback.",4.5 Decoding Candidate Choices,[0],[0]
"Inspired by SQLNet (Xu et al., 2017), we describe our candidate choice decoding approach as follows.",4.5 Decoding Candidate Choices,[0],[0]
Select column choice.,4.5 Decoding Candidate Choices,[0],[0]
"We define the following
scores over column names,
h = Attn(Lin([oUi−1, o U j , Ec]), H T )
ssel = u T ∗",4.5 Decoding Candidate Choices,[0],[0]
"tanh(Lin([HT , h]))
where oUi−1 is the output vector of the query encoder preceding the start position, and oUj is the output of query encoder at the end position.",4.5 Decoding Candidate Choices,[0],[0]
Aggregation choice.,4.5 Decoding Candidate Choices,[0],[0]
"Conditioned on the encoding e of the select column, we define the following scores over the set of aggregations (MIN, MAX, COUNT, NO AGGREGATION)
",4.5 Decoding Candidate Choices,[0],[0]
"sagg = v T ∗ tanh(Lin(Attn(e,HQ)))
",4.5 Decoding Candidate Choices,[0],[0]
Where condition choice.,4.5 Decoding Candidate Choices,[0],[0]
We first decode the condition column name similar to decoding select column.,4.5 Decoding Candidate Choices,[0],[0]
"Given the encoding e of condition column, we define the following scores over the set of operators (=, <, >)
sop = w T ∗ tanh(Lin(Attn(e,HQ)))
",4.5 Decoding Candidate Choices,[0],[0]
"Next, we define the following scores over question tokens for the start and end positions of the condition value
sst = Attn(e,H Q)
sed = Attn([e, hst, H Q])
where hst is the context vector generated from the first attention.",4.5 Decoding Candidate Choices,[0],[0]
We denote the number of candidate choices to be decoded by,4.5 Decoding Candidate Choices,[0],[0]
k. We train DialSQL with k = 1.,4.5 Decoding Candidate Choices,[0],[0]
The list of k > 1 candidate choices is decoded similar to beam search during testing.,4.5 Decoding Candidate Choices,[0],[0]
"As an example, we select k column names that have the highest scores as the candidate where column choices.",4.5 Decoding Candidate Choices,[0],[0]
"For each column name, we first generate k different operators and from the set of k ∗ 2 column name and operator pairs; select k operators that have the highest joint probability.",4.5 Decoding Candidate Choices,[0],[0]
"Ideally, DialSQL should be able to learn the type of errors present in the generated query, extract precise error spans by pointing to query tokens, and using the location of the error spans, generate a set of related choices.",4.5 Decoding Candidate Choices,[0],[0]
"In this section, we evaluate DialSQL on WikiSQL using several evaluation metrics by comparing with previous literature.",5 Experimental Results and Discussion,[0],[0]
We measure the query generation accuracy as well as the complexity of the questions and the length of the user interactions.,5.1 Evaluation Setup and Metrics,[0],[0]
Query-match accuracy.,5.1 Evaluation Setup and Metrics,[0],[0]
"We evaluate DialSQL on WikiSQL using query-match accuracy (Zhong et al., 2017; Xu et al., 2017).",5.1 Evaluation Setup and Metrics,[0],[0]
"Query-match accuracy is the proportion of testing examples for which the generated query is exactly the same as the ground truth, except the ordering of the WHERE clauses.",5.1 Evaluation Setup and Metrics,[0],[0]
Dialogue length.,5.1 Evaluation Setup and Metrics,[0],[0]
We count the number of turns to analyze whether DialSQL generates any redundant validation questions.,5.1 Evaluation Setup and Metrics,[0],[0]
Question complexity.,5.1 Evaluation Setup and Metrics,[0],[0]
"We use the average number of tokens in the generated validation questions to evaluate if DialSQL can generate simple questions without overwhelming users.
",5.1 Evaluation Setup and Metrics,[0],[0]
"Since SQLNet and Seq2SQL are single-step models, we can not analyze DialSQL’s performance by comparing against these on the last two metrics.",5.1 Evaluation Setup and Metrics,[0],[0]
"We overcome this issue by generating simulated dialogues using an oracle system
that has access to the ground truth query.",5.1 Evaluation Setup and Metrics,[0],[0]
The system compares SELECT and AGGREGATION clauses of the predicted query and the ground truth; asks a validation question if they differ.,5.1 Evaluation Setup and Metrics,[0],[0]
"For each WHERE clause pairs of generated query and the ground truth, the system counts the number of matching segments namely COLUMN, OP, and VALUE.",5.1 Evaluation Setup and Metrics,[0],[0]
The system takes all the pairs with the highest matching scores and asks a validation question until one of the queries has no remaining WHERE clause.,5.1 Evaluation Setup and Metrics,[0],[0]
"If both queries have no remaining clauses, the dialogue terminates.",5.1 Evaluation Setup and Metrics,[0],[0]
"Otherwise, the system asks a validate where added (validate where removed) question when the generated query (ground truth query) has more remaining clauses.",5.1 Evaluation Setup and Metrics,[0],[0]
We call this strategy OracleMatching (OM).,5.1 Evaluation Setup and Metrics,[0],[0]
OM ensures that the generated dialogues have the minimum number of turns possible.,5.1 Evaluation Setup and Metrics,[0],[0]
"We implement DialSQL in TensorFlow (Abadi et al., 2016) using the Adam optimizer (Kingma and Ba, 2014) for the training with a learning rate of 1e−4.",5.2 Training Details,[0],[0]
"We use an embedding size of 300, RNN state size of 50, and a batch size of 64.",5.2 Training Details,[0],[0]
"The embeddings are initialized from pretrained GloVe embeddings (Pennington et al., 2014) and fine-tuned during training.",5.2 Training Details,[0],[0]
"We use bidirectional RNN encoders with two layers for questions, column names, and queries.",5.2 Training Details,[0],[0]
"Stanford CoreNLP tokenizer (Manning et al., 2014) is used to parse questions and column names.",5.2 Training Details,[0],[0]
Parameters of each layer are decoupled from each other and only the embedding matrix is shared.,5.2 Training Details,[0],[0]
The total number of turns is limited to 10 and 10 simulated dialogues are generated for each example in the WikiSQL training set.,5.2 Training Details,[0],[0]
SQLNet and Seq2SQL models are trained on WikiSQL using the existing implemention provided by their authors.,5.2 Training Details,[0],[0]
The code is available at https://github.com/ izzeddingur/DialSQL.,5.2 Training Details,[0],[0]
Table 3 presents the results of query match accuracy.,5.3 Evaluation on the WikiSQL Dataset,[0],[0]
"We observe that DialSQL model with a number of 5 choices improves the performance of both SQLNet and Seq2SQL by 7.7% and 9.4%, respectively.",5.3 Evaluation on the WikiSQL Dataset,[0],[0]
The higher gain on Seq2SQL model can be attributed that the single-step Seq2SQL makes more errors: DialSQL has more room for improvement.,5.3 Evaluation on the WikiSQL Dataset,[0],[0]
"We also show the results of DialSQL where
users are allowed to revisit their previous answers and with more informative user responses; instead the model only validates the error span and the user directly gives the correct choice.",5.3 Evaluation on the WikiSQL Dataset,[0],[0]
"In this scenario, the performance further improves on both development and test sets.",5.3 Evaluation on the WikiSQL Dataset,[0],[0]
It seems decoding candidate choices is a hard task and has room for improvement.,5.3 Evaluation on the WikiSQL Dataset,[0],[0]
"For the rest of the evaluation, we present results with multi-choice questions.",5.3 Evaluation on the WikiSQL Dataset,[0],[0]
"In Table 4, we compare DialSQL to the OM strategy on query complexity (QC) and dialogue length (DL) metrics.",5.4 Query Complexity and Dialogue Length,[0],[0]
DialSQL,5.4 Query Complexity and Dialogue Length,[0],[0]
and SQLNet-OM both have very similar query complexity scores showing that DialSQL produces simple questions.,5.4 Query Complexity and Dialogue Length,[0],[0]
The number of questions DialSQL asks is around 3 for both query generation models.,5.4 Query Complexity and Dialogue Length,[0],[0]
"Even though SQLNet-OM dialogues have much smaller dialogue lengths, we attribute this to the fact that 61.3% of the dialogues have empty interactions since OM will match every segment in the generated query and the ground truth.",5.4 Query Complexity and Dialogue Length,[0],[0]
"The average number of turns in dialogues with non-empty interactions, on the other hand, is 3.10 which is close to DialSQL.",5.4 Query Complexity and Dialogue Length,[0],[0]
"In Figure 3, we plot the accuracy of DialSQL on WikiSQL with a varying number of choices at each turn.",5.5 A Varying Number of Choices,[0],[0]
We train DialSQL once and generate a different number of choices at each turn by offering top-k candidates during testing.,5.5 A Varying Number of Choices,[0],[0]
"We observe that offering even a single candidate improves the performance of SQLNet remarkably, 1.9% and
2.5% for development and test sets, respectively.",5.5 A Varying Number of Choices,[0],[0]
"As the number of choices increases, the performance of DialSQL improves in all the cases.",5.5 A Varying Number of Choices,[0],[0]
"Particularly, for the SQLNet-DialSQL model we observe more accuray gain.",5.5 A Varying Number of Choices,[0],[0]
We increased the number of choices to 10 and observed no notable further improvement in the development set which suggests that 5 is a good value for the number of choices.,5.5 A Varying Number of Choices,[0],[0]
We examine the error distribution of DialSQL and SQLNet.,5.6 Error Distribution,[0],[0]
"In DialSQL, almost all the errors are caused by validate sel and validate where change, while in SQLNet validate where change is the major cause of error and other errors are distributed uniformly.",5.6 Error Distribution,[0],[0]
We extend our evaluation of DialSQL using human subject experiment so that real users interact with the system instead of our simulated user.,5.7 Human Evaluation,[0],[0]
We randomly pick 100 questions from WikiSQL development set and run SQLNet to generate initial candidate queries.,5.7 Human Evaluation,[0],[0]
"Next, we run DialSQL using these candidate queries to generate 100 dialogues, each of which is evaluated
by 3 different users.",5.7 Human Evaluation,[0],[0]
"At each turn, we show users the headers of the corresponding table, original question, system response, and list of candidate choices for users to pick.",5.7 Human Evaluation,[0],[0]
"For each error category, we generate 5 choices except for the validate where added category for which we only show 2 choices (YES or NO).",5.7 Human Evaluation,[0],[0]
"Also, we add an additional choice of None of the above so that users can keep the previous prediction unchanged.",5.7 Human Evaluation,[0],[0]
"At the end of each turn, we also ask users to give an overall score between 1 and 3 to evaluate whether they had a successful interaction with the DialSQL for the current turn.",5.7 Human Evaluation,[0],[0]
"On average, the length of the generated dialogues is 5.6.
",5.7 Human Evaluation,[0],[0]
"In Table 5, we compare the performance of SQLNet, DialSQL with user simulation, and DialSQL with real users using QM metric.",5.7 Human Evaluation,[0],[0]
We present the average performance across 3 different users with the standard deviation estimated over all dialogues.,5.7 Human Evaluation,[0],[0]
"We observe that when real users interact with our system, the overall performance of the generated queries are better than SQLNet model showing that DialSQL can improve the performance of a strong NLIDB system in a real setting.",5.7 Human Evaluation,[0],[0]
"However, there is still a large room for improvement between simulated dialogues and real users.
",5.7 Human Evaluation,[0],[0]
"In Figure 4, we present the correlation between DialSQL ranking of the candidate choices and user preferences.",5.7 Human Evaluation,[0],[0]
"We observe that, user answers and
DialSQL rankings are positively correlated; most of the time users prefer the top-1 choice.",5.7 Human Evaluation,[0],[0]
"Interestingly, 15% of the user answers is None of the above.",5.7 Human Evaluation,[0],[0]
This commonly happens in the scenario where DialSQL response asks to replace a correct condition and users prefer to keep the original prediction unchanged.,5.7 Human Evaluation,[0],[0]
Another scenario where users commonly select None of the above is when table headers without the content remain insufficient for users to correctly disambiguate condition values from questions.,5.7 Human Evaluation,[0],[0]
We also compute the Mean Reciprocal Rank (MMR) for each user to measure the correlation between real users and DialSQL.,5.7 Human Evaluation,[0],[0]
Average MMR is 0.69 with standard deviation of 0.004 which also shows that users generally prefer the choices ranked higher by DialSQL.,5.7 Human Evaluation,[0],[0]
The overall score of each turn also suggests that users had a reasonable conversation with DialSQL.,5.7 Human Evaluation,[0],[0]
"The average score is 2.86 with standard deviation of 0.14, showing users can understand DialSQL responses and can pick a choice confidently.",5.7 Human Evaluation,[0],[0]
"We demonstrated the efficacy of the DialSQL, improving the state of the art accuracy from 62.5% to 69.0% on the WikiSQL dataset.",6 Conclusion,[0],[0]
DialSQL successfully extracts error spans from queries and offers several alternatives to users.,6 Conclusion,[0],[0]
It generates simple questions over a small number of turns without overwhelming users.,6 Conclusion,[0],[0]
The model learns from only simulated data which makes it easy to adapt to new domains.,6 Conclusion,[0],[0]
We further investigate the usability of DialSQL in a real life setting by conducting human evaluations.,6 Conclusion,[0],[0]
Our results suggest that the accuracy of the generated queries can be improved via real user feedback.,6 Conclusion,[0],[0]
The authors would like to thank the anonymous reviewers for their thoughtful comments.,Acknowledgements,[0],[0]
This research was sponsored in part by the Army Research Laboratory under cooperative agreements W911NF09-2-0053 and NSF 1528175.,Acknowledgements,[0],[0]
"The views and conclusions contained herein are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory or the U.S. Government.",Acknowledgements,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notice herein.,Acknowledgements,[0],[0]
The recent advance in deep learning and semantic parsing has significantly improved the translation accuracy of natural language questions to structured queries.,abstractText,[0],[0]
"However, further improvement of the existing approaches turns out to be quite challenging.",abstractText,[0],[0]
"Rather than solely relying on algorithmic innovations, in this work, we introduce DialSQL, a dialoguebased structured query generation framework that leverages human intelligence to boost the performance of existing algorithms via user interaction.",abstractText,[0],[0]
DialSQL is capable of identifying potential errors in a generated SQL query and asking users for validation via simple multi-choice questions.,abstractText,[0],[0]
User feedback is then leveraged to revise the query.,abstractText,[0],[0]
We design a generic simulator to bootstrap synthetic training dialogues and evaluate the performance of DialSQL on the WikiSQL dataset.,abstractText,[0],[0]
"Using SQLNet as a black box query generation tool, DialSQL improves its performance from 61.3% to 69.0% using only 2.4 validation questions per dialogue.",abstractText,[0],[0]
DialSQL: Dialogue Based Structured Query Generation,title,[0],[0]
"In many situations where a classifier is to be learned, it is easy to collect unlabeled data but costly to obtain labels.",1. Introduction,[0],[0]
"This has motivated the pool-based active learning model, in which a learner has access to a collection of unlabeled data points and is allowed to ask for individual labels in an adaptive manner.",1. Introduction,[0],[0]
"The hope is that choosing these queries intelligently will rapidly yield a low-error classifier, much more quickly than with random querying.",1. Introduction,[0],[0]
"A central focus of active learning is developing efficient querying strategies and understanding their label complexity.
",1. Introduction,[0],[0]
"Over the past decade or two, there has been substantial progress in developing such rigorously-justified active learning schemes for general concept classes.",1. Introduction,[0],[0]
"For the most part, these schemes can be described as mellow: rather than focusing upon maximally informative points, they query any point whose label cannot reasonably be inferred from the information received so far.",1. Introduction,[0],[0]
"It is of interest to develop more aggressive strategies with better label complexity.
",1. Introduction,[0],[0]
"An exception to this general trend is the aggressive strategy of (Dasgupta, 2005), whose label complexity is known to be optimal in its dependence on a key parameter called the splitting index.",1. Introduction,[0],[0]
"However, this strategy has been primarily of theoretical interest because it is difficult to implement algorithmically.",1. Introduction,[0],[0]
"In this paper, we introduce a variant of the methodology that yields efficient algorithms.",1. Introduction,[0],[0]
"We show that
1Department of Computer Science and Engineering, UC San Diego, La Jolla, CA, USA.",1. Introduction,[0],[0]
"Correspondence to: Christopher Tosh <ctosh@cs.ucsd.edu>, Sanjoy Dasgupta <dasgupta@cs.ucsd.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"it admits roughly the same label complexity bounds as well as having promising experimental performance.
",1. Introduction,[0],[0]
"As with the original splitting index result, we operate in the realizable setting, where data can be perfectly classified by some function h⇤ in the hypothesis class H.",1. Introduction,[0],[0]
"At any given time during the active learning process, the remaining candidates—that is, the elements of H consistent with the data so far—are called the version space.",1. Introduction,[0],[0]
The goal of aggressive active learners is typically to pick queries that are likely to shrink this version space rapidly.,1. Introduction,[0],[0]
But what is the right notion of size?,1. Introduction,[0],[0]
"Dasgupta (2005) pointed out that the diameter of the version space is what matters, where the distance between two classifiers is taken to be the fraction of points on which they make different predictions.",1. Introduction,[0],[0]
"Unfortunately, the diameter is a difficult measure to work with because it cannot, in general, be decreased at a steady rate.",1. Introduction,[0],[0]
"Thus the earlier work used a procedure that has quantifiable label complexity but is not conducive to implementation.
",1. Introduction,[0],[0]
We take a fresh perspective on this earlier result.,1. Introduction,[0],[0]
"We start by suggesting an alternative, but closely related, notion of the size of a version space: the average pairwise distance between hypotheses in the version space, with respect to some underlying probability distribution ⇡ on H. This distribution ⇡ can be arbitrary—that is, there is no requirement that the target h⇤ is chosen from it—but should be chosen so that it is easy to sample from.",1. Introduction,[0],[0]
"When H consists of linear separators, for instance, a good choice would be a log-concave density, such as a Gaussian.
",1. Introduction,[0],[0]
"At any given time, the next query x is chosen roughly as follows:
• Sample a collection of classifiers h 1 , h 2 , . . .",1. Introduction,[0],[0]
", h m
from ⇡ restricted to the current version space V .
•",1. Introduction,[0],[0]
"Compute the distances between them; this can be done using just the unlabeled points.
",1. Introduction,[0],[0]
"• Any candidate query x partitions the classifiers {h i } into two groups: those that assign it a + label (call these V +
x ) and those that assign it a label (call these V x
).",1. Introduction,[0],[0]
"Estimate the average-diameter after labeling x by the sum of the distances between classifiers h
i
within V + x , or those within V x , whichever is larger.
",1. Introduction,[0],[0]
"• Out of the pool of unlabeled data, pick the x for which
this diameter-estimate is smallest.
",1. Introduction,[0],[0]
This is repeated until the version space has small enough average diameter that a random sample from it is very likely to have error less than a user-specified threshold ✏.,1. Introduction,[0],[0]
"We show how all these steps can be achieved efficiently, as long as there is a sampler for ⇡.
Dasgupta (2005) pointed out that the label complexity of active learning depends on the underlying distribution, the amount of unlabeled data (since more data means greater potential for highly-informative points), and also the target classifier h⇤.",1. Introduction,[0],[0]
"That paper identifies a parameter called the splitting index ⇢ that captures the relevant geometry, and gives upper bounds on label complexity that are proportional to 1/⇢, as well as showing that this dependence is inevitable.",1. Introduction,[0],[0]
"For our modified notion of diameter, a different averaged splitting index is needed.",1. Introduction,[0],[0]
"However, we show that it can be bounded by the original splitting index, with an extra multiplicative factor of log(1/✏); thus all previouslyobtained label complexity results translate immediately for our new algorithm.",1. Introduction,[0],[0]
"The theory of active learning has developed along several fronts.
",2. Related Work,[0],[0]
"One of these is nonparametric active learning, where the learner starts with a pool of unlabeled points, adaptively queries a few of them, and then fills in the remaining labels.",2. Related Work,[0],[0]
The goal is to do this with as few errors as possible.,2. Related Work,[0],[0]
"(In particular, the learner does not return a classifier from some predefined parametrized class.)",2. Related Work,[0],[0]
"One scheme begins by building a neighborhood graph on the unlabeled data, and propagating queried labels along the edges of this graph (Zhu et al., 2003; Cesa-Bianchi et al., 2009; Dasarathy et al., 2015).",2. Related Work,[0],[0]
"Another starts with a hierarchical clustering of the data and moves down the tree, sampling at random until it finds clusters that are relatively pure in their labels (Dasgupta & Hsu, 2008).",2. Related Work,[0],[0]
"The label complexity of such methods have typically be given in terms of smoothness properties of the underlying data distribution (Castro & Nowak, 2008; Kpotufe et al., 2015).
",2. Related Work,[0],[0]
"Another line of work has focused on active learning of linear separators, by querying points close to the current guess at the decision boundary (Balcan et al., 2007; Dasgupta et al., 2009; Balcan & Long, 2013).",2. Related Work,[0],[0]
"Such algorithms are close in spirit to those used in practice, but their analysis to date has required fairly strong assumptions to the effect that the underlying distribution on the unlabeled points is logconcave.",2. Related Work,[0],[0]
"Interestingly, regret guarantees for online algorithms of this sort can be shown under far weaker conditions (Cesa-Bianchi et al., 2006).
",2. Related Work,[0],[0]
"The third category of results, to which the present paper belongs, considers active learning strategies for general concept classes H.",2. Related Work,[0],[0]
"Some of these schemes (Cohn et al., 1994; Dasgupta et al., 2007; Beygelzimer et al., 2009; Balcan et al., 2009; Zhang & Chaudhuri, 2014) are fairly mellow in the sense described earlier, using generalization bounds to gauge which labels can be inferred from those obtained so far.",2. Related Work,[0],[0]
"The label complexity of these methods can be bounded in terms of a quantity known as the disagreement coefficient (Hanneke, 2007).",2. Related Work,[0],[0]
"In the realizable case, the canonical such algorithm is that of (Cohn et al., 1994), henceforth referred to as CAL.",2. Related Work,[0],[0]
"Other methods use a prior distribution ⇡ over the hypothesis class, sometimes assuming that the target classifier is a random draw from this prior.",2. Related Work,[0],[0]
"These methods typically aim to shrink the mass of the version space under ⇡, either greedily and explicitly (Dasgupta, 2004; Guillory & Bilmes, 2009; Golovin et al., 2010) or implicitly (Freund et al., 1997).",2. Related Work,[0],[0]
"Perhaps the most widely-used of these methods is the latter, query-by-committee, henceforth QBC.",2. Related Work,[0],[0]
"As mentioned earlier, shrinking ⇡-mass is not an optimal strategy if low misclassification error is the ultimate goal.",2. Related Work,[0],[0]
"In particular, what matters is not the prior mass of the remaining version space, but rather how different these candidate classifiers are from each other.",2. Related Work,[0],[0]
"This motivates using the diameter of the version space as a yardstick, which was first proposed in (Dasgupta, 2005) and is taken up again here.",2. Related Work,[0],[0]
"Consider a binary hypothesis class H, a data space X , and a distribution D over X .",3. Preliminaries,[0],[0]
"For mathematical convenience, we will restrict ourselves to finite hypothesis classes.",3. Preliminaries,[0],[0]
"(We can do this without loss of generality when H has finite VC dimension, since we only use the predictions of hypotheses on a pool of unlabeled points; however, we do not spell out the details of this reduction here.)",3. Preliminaries,[0],[0]
"The hypothesis distance induced by D over H is the pseudometric
d(h, h0) :",3. Preliminaries,[0],[0]
"= Pr x⇠D(h(x) 6= h0(x)).
",3. Preliminaries,[0],[0]
"Given a point x 2 X and a subset V ⇢ H, denote V + x
= {h 2 V : h(x) = 1} and V
x = V \ V + x
.",3. Preliminaries,[0],[0]
"Given a sequence of data points x 1 , . . .",3. Preliminaries,[0],[0]
", x n
and a target hypothesis h⇤, the induced version space is the set of hypotheses that are consistent with the target hypotheses on the sequence, i.e.
{h 2 H : h(x i )",3. Preliminaries,[0],[0]
=,3. Preliminaries,[0],[0]
"h⇤(x i ) for all i = 1, . . .",3. Preliminaries,[0],[0]
", n}.",3. Preliminaries,[0],[0]
"The diameter of a set of hypotheses V ⇢ H is the maximal distance between any two hypotheses in V , i.e.
diam(V ) := max h,h 02V d(h, h0).
",3.1. Diameter and the Splitting Index,[0],[0]
"Without any prior information, any hypothesis in the version space could be the target.",3.1. Diameter and the Splitting Index,[0],[0]
Thus the worst case error of any hypothesis in the version space is the diameter of the version space.,3.1. Diameter and the Splitting Index,[0],[0]
"The splitting index roughly characterizes the number of queries required for an active learning algorithm to reduce the diameter of the version space below ✏.
",3.1. Diameter and the Splitting Index,[0],[0]
"While reducing the diameter of a version space V ⇢ H, we will sometimes identify pairs of hypotheses h, h0 2 V that are far apart and therefore need to be separated.",3.1. Diameter and the Splitting Index,[0],[0]
"We will refer to {h, h0} as an edge.",3.1. Diameter and the Splitting Index,[0],[0]
"Given a set of edges E = {{h
1 , h0 1 }, . . .",3.1. Diameter and the Splitting Index,[0],[0]
", {h n , h0 n }} ⇢",3.1. Diameter and the Splitting Index,[0],[0]
"H 2 , we say a data point x ⇢- splits E if querying x separates at least a ⇢ fraction of the pairs, that is, if
max E+ x",3.1. Diameter and the Splitting Index,[0],[0]
"|, |E x  (1 ⇢)|E|
where E+ x = E \ H+x 2 and similarly for E x
.",3.1. Diameter and the Splitting Index,[0],[0]
"When attempting to get accuracy ✏ > 0, we need to only eliminate edge of length greater than ✏.",3.1. Diameter and the Splitting Index,[0],[0]
"Define
E ✏
= {{h, h0} 2 E : d(h, h0) >",3.1. Diameter and the Splitting Index,[0],[0]
"✏}.
",3.1. Diameter and the Splitting Index,[0],[0]
"The splitting index of a set V ⇢ H is a tuple (⇢, ✏, ⌧) such that for all finite edge-sets E ⇢ V
2
,
Pr x⇠D(x ⇢-splits E✏) ⌧.
",3.1. Diameter and the Splitting Index,[0],[0]
"The following theorem, due to Dasgupta (2005), bounds the sample complexity of active learning in terms of the splitting index.",3.1. Diameter and the Splitting Index,[0],[0]
"The ˜O notation hides polylogarithmic factors in d, ⇢, ⌧ , log 1/✏, and the failure probability .
",3.1. Diameter and the Splitting Index,[0],[0]
Theorem 1 (Dasgupta 2005).,3.1. Diameter and the Splitting Index,[0],[0]
"Suppose H is a hypothesis class with splitting index (⇢, ✏, ⌧).",3.1. Diameter and the Splitting Index,[0],[0]
"Then to learn a hypothesis with error ✏,
(a) any active learning algorithm with  1/⌧ unlabeled samples must request at least 1/⇢ labels, and
(b) if H has VC-dimension d, there is an active learning algorithm that draws
˜O(d/(⇢⌧) log2(1/✏)) unlabeled data points and requests ˜O((d/⇢) log2(1/✏)) labels.
",3.1. Diameter and the Splitting Index,[0],[0]
"Unfortunately, the only known algorithm satisfying (b) above is intractable for all but the simplest hypothesis classes: it constructs an ✏-covering of the hypothesis space and queries points which whittle away at the diameter of this covering.",3.1. Diameter and the Splitting Index,[0],[0]
"To overcome this intractability, we consider a slightly more benign setting in which we have a samplable prior distribution ⇡ over our hypothesis space H.",3.1. Diameter and the Splitting Index,[0],[0]
"With a prior distribution, it makes sense to shift away from the worst-case to the average-case.",3.2. An Average Notion of Diameter,[0],[0]
"We define the average
diameter of a subset V ⇢ H as the expected distance between two hypotheses in V randomly drawn from ⇡, i.e.
(V ) := E h,h 0⇠⇡| V
[d(h, h0)]
where ⇡| V
is the conditional distribution induced by restricting ⇡ to V , that is, ⇡|
V (h) = ⇡(h)/⇡(V ) for h 2 V .",3.2. An Average Notion of Diameter,[0],[0]
"Intuitively, a version space with very small average diameter ought to put high weight on hypotheses that are close to the true hypothesis.",3.2. An Average Notion of Diameter,[0],[0]
"Indeed, given a version space V with h⇤ 2 V , the following lemma shows that if (V ) is small enough, then a low error hypothesis can be found by two popular heuristics: random sampling and MAP estimation.
",3.2. An Average Notion of Diameter,[0],[0]
Lemma 2.,3.2. An Average Notion of Diameter,[0],[0]
Suppose V ⇢ H contains h⇤.,3.2. An Average Notion of Diameter,[0],[0]
"Pick ✏ > 0.
(a) (Random sampling)",3.2. An Average Notion of Diameter,[0],[0]
"If (V )  ✏ ⇡| V (h⇤) then E h⇠⇡|
V [d(h⇤, h)]  ✏.",3.2. An Average Notion of Diameter,[0],[0]
"(b) (MAP estimation) Write p
map
= max h2V ⇡|V (h).",3.2. An Average Notion of Diameter,[0],[0]
Pick 0,3.2. An Average Notion of Diameter,[0],[0]
<,3.2. An Average Notion of Diameter,[0],[0]
"↵ < p
map
.",3.2. An Average Notion of Diameter,[0],[0]
"If
(V )  2✏ (min{⇡| V (h⇤), p map ↵})2 ,
then d(h⇤, h)  ",3.2. An Average Notion of Diameter,[0],[0]
"✏ for any h with ⇡| V (h) p map ↵.
",3.2. An Average Notion of Diameter,[0],[0]
Proof.,3.2. An Average Notion of Diameter,[0],[0]
"Part (a) follows from
(V ) =",3.2. An Average Notion of Diameter,[0],[0]
"E h,h 0⇠⇡| V [d(h, h0)]",3.2. An Average Notion of Diameter,[0],[0]
"⇡| V (h⇤)E h⇠⇡| V [d(h⇤, h)].
",3.2. An Average Notion of Diameter,[0],[0]
"For (b), take = min(⇡| V (h⇤), p map
↵) and define V ⇡, = {h 2 V : ⇡| V (h) }.",3.2. An Average Notion of Diameter,[0],[0]
"Note that V ⇡,
contains h⇤ as well as any h 2 V with ⇡|
V (h) p map ↵.",3.2. An Average Notion of Diameter,[0],[0]
"We claim diam(V
⇡, ) is at most ✏.",3.2. An Average Notion of Diameter,[0],[0]
Suppose not.,3.2. An Average Notion of Diameter,[0],[0]
"Then there exist h
1 , h 2 2 V ⇡, satisfying d(h 1 , h 2 ) >",3.2. An Average Notion of Diameter,[0],[0]
"✏, implying
(V ) =",3.2. An Average Notion of Diameter,[0],[0]
"E h,h 0⇠⇡| V
[d(h, h0)]
2 · ⇡| V (h 1 ) · ⇡| V (h 2 ) ·",3.2. An Average Notion of Diameter,[0],[0]
"d(h 1 , h 2 ) >",3.2. An Average Notion of Diameter,[0],[0]
"2 2✏.
",3.2. An Average Notion of Diameter,[0],[0]
But this contradicts our assumption on (V ).,3.2. An Average Notion of Diameter,[0],[0]
"Since both h, h⇤ 2 V
⇡,
, we have (b).",3.2. An Average Notion of Diameter,[0],[0]
We now turn to defining an average notion of splitting.,3.3. An Average Notion of Splitting,[0],[0]
"A data point x ⇢-average splits V if
max
⇢ ⇡(V +
x
)
2
⇡(V )2 (V + x
), ⇡(V x ) 2
⇡(V )2 (V x )
 (1 ⇢) (V ).
",3.3. An Average Notion of Splitting,[0],[0]
"And we say a set S ⇢ H has average splitting index (⇢, ✏, ⌧) if for any subset V ⇢ S such that (V ) >",3.3. An Average Notion of Splitting,[0],[0]
"✏,
Pr x⇠D (x ⇢-average splits V ) ⌧.
",3.3. An Average Notion of Splitting,[0],[0]
"Intuitively, average splitting refers to the ability to significantly decrease the potential function
⇡(V )2 (V ) =",3.3. An Average Notion of Splitting,[0],[0]
"E h,h 0⇠⇡[ (h, h0 2 V ) d(h, h0)] with a single query.
",3.3. An Average Notion of Splitting,[0],[0]
"While this potential function may seem strange at first glance, it is closely related to the original splitting index.",3.3. An Average Notion of Splitting,[0],[0]
"The following lemma, whose proof is deferred to Section 5, shows the splitting index bounds the average splitting index for any hypothesis class.",3.3. An Average Notion of Splitting,[0],[0]
Lemma 3.,3.3. An Average Notion of Splitting,[0],[0]
"Let ⇡ be a probability measure over a hypothesis class H. If H has splitting index (⇢, ✏, ⌧), then it has average splitting index ( ⇢
4dlog(1/✏)e , 2✏, ⌧).
",3.3. An Average Notion of Splitting,[0],[0]
"Dasgupta (2005) derived the splitting indices for several hypothesis classes, including intervals and homogeneous linear separators.",3.3. An Average Notion of Splitting,[0],[0]
"Lemma 3 implies average splitting indices within a log(1/✏) factor in these settings.
",3.3. An Average Notion of Splitting,[0],[0]
"Moreover, given access to samples from ⇡| V
, we can easily estimate the quantities appearing in the definition of average splitting.",3.3. An Average Notion of Splitting,[0],[0]
"For an edge sequence E = ({h
1 , h0 1 }, . . .",3.3. An Average Notion of Splitting,[0],[0]
", {h n , h0 n }), define
(E) := nX
i=1
",3.3. An Average Notion of Splitting,[0],[0]
"d(h i , h0 i ).
",3.3. An Average Notion of Splitting,[0],[0]
"When h i , h0 i are i.i.d.",3.3. An Average Notion of Splitting,[0],[0]
"draws from ⇡| V
for all i = 1, . . .",3.3. An Average Notion of Splitting,[0],[0]
", n, which we denote E ⇠ (⇡|
V
) 2⇥n, the random variables (E), (E
x ), and (E+ x ) are unbiased estimators of the quantities appearing in the definition of average splitting.",3.3. An Average Notion of Splitting,[0],[0]
Lemma 4.,3.3. An Average Notion of Splitting,[0],[0]
"Given E ⇠ (⇡|
V
) 2⇥n , we have
E  1
n",3.3. An Average Notion of Splitting,[0],[0]
"(E)
= (V ) and E
 1
n",3.3. An Average Notion of Splitting,[0],[0]
(E+ x ),3.3. An Average Notion of Splitting,[0],[0]
"=
⇡(V + x ) 2
⇡(V )2 (V + x )
for any x 2 X .",3.3. An Average Notion of Splitting,[0],[0]
"Similarly for E x and V x .
Proof.",3.3. An Average Notion of Splitting,[0],[0]
"From definitions and linearity of expectations, it is easy to observe E[ (E)]",3.3. An Average Notion of Splitting,[0],[0]
= n (V ).,3.3. An Average Notion of Splitting,[0],[0]
"By the independence of h
i , h0",3.3. An Average Notion of Splitting,[0],[0]
"i , we additionally have
E  1
n",3.3. An Average Notion of Splitting,[0],[0]
(E+ x ),3.3. An Average Notion of Splitting,[0],[0]
"=
1 n E
2 4 X
{h i ,h 0",3.3. An Average Notion of Splitting,[0],[0]
"i }2E+ x
d(h i , h0 i )
3
5
=
1 n E
2 4 X
{h i ,h 0",3.3. An Average Notion of Splitting,[0],[0]
"i
}2E",3.3. An Average Notion of Splitting,[0],[0]
"[h i
2 V + x ]",3.3. An Average Notion of Splitting,[0],[0]
[h0 i 2 V + x ],3.3. An Average Notion of Splitting,[0],[0]
"d(h i , h0 i )
3
5
=
1
n
X
{h i ,h 0",3.3. An Average Notion of Splitting,[0],[0]
"i }2E
✓ ⇡(V +
x
)
⇡(V )
◆ 2
E ⇥",3.3. An Average Notion of Splitting,[0],[0]
"d(h
i , h0 i )",3.3. An Average Notion of Splitting,[0],[0]
|h,3.3. An Average Notion of Splitting,[0],[0]
"i , h0 i 2 V + x
⇤
=
✓ ⇡(V +
x
)
⇡(V )
◆ 2
(V + x ).
",3.3. An Average Notion of Splitting,[0],[0]
"Remark: It is tempting to define average splitting in terms of the average diameter as
max{ (V + x ), (V x )}  (1 ⇢) (V ).",3.3. An Average Notion of Splitting,[0],[0]
"However, this definition does not satisfy a nice relationship with the splitting index.",3.3. An Average Notion of Splitting,[0],[0]
"Indeed, there exist hypothesis classes V for which there are many points which 1/4-split E for any E ⇢ V
2
but for which every x 2 X satisfies
max{ (V + x ), (V x )} ⇡ (V ).",3.3. An Average Notion of Splitting,[0],[0]
This observation is formally proven in the appendix.,3.3. An Average Notion of Splitting,[0],[0]
"Suppose we are given a version space V with average splitting index (⇢, ✏, ⌧).",4. An Average Splitting Index Algorithm,[0],[0]
"If we draw ˜O(1/⌧) points from the data distribution then, with high probability, one of these will ⇢- average split V .",4. An Average Splitting Index Algorithm,[0],[0]
"Querying that point will result in a version space V 0 with significantly smaller potential ⇡(V 0)2 (V 0).
",4. An Average Splitting Index Algorithm,[0],[0]
"If we knew the value ⇢ a priori, then Lemma 4 combined with standard concentration bounds (Hoeffding, 1963; Angluin & Valiant, 1977) would give us a relatively straightforward procedure to find a good query point:
1.",4. An Average Splitting Index Algorithm,[0],[0]
"Draw E0 ⇠ (⇡| V ) 2⇥M and compute the empirical estimate b (V ) = 1
M
(E0).
2.",4. An Average Splitting Index Algorithm,[0],[0]
"Draw E ⇠ (⇡| V ) 2⇥N for N depending on ⇢ and b .
3.",4. An Average Splitting Index Algorithm,[0],[0]
"For suitable M and N , it will be the case that with high probability, for some x,
1
N max
(E+
x ), (E x )
⇡ (1 ⇢)b .
",4. An Average Splitting Index Algorithm,[0],[0]
"Querying that point will decrease the potential.
",4. An Average Splitting Index Algorithm,[0],[0]
"However, we typically would not know the average splitting index ahead of time.",4. An Average Splitting Index Algorithm,[0],[0]
"Moreover, it is possible that the average splitting index may change from one version space to the next.",4. An Average Splitting Index Algorithm,[0],[0]
"In the next section, we describe a query selection procedure that adapts to the splittability of the current version space.",4. An Average Splitting Index Algorithm,[0],[0]
"Algorithm 2, which we term SELECT, is our query selection procedure.",4.1. Finding a Good Query Point,[0],[0]
"It takes as input a sequence of data points x 1 , . . .",4.1. Finding a Good Query Point,[0],[0]
", x m
, at least one of which ⇢-average splits the current version space, and with high probability finds a data point that ⇢/8-average splits the version space.
",4.1. Finding a Good Query Point,[0],[0]
"SELECT proceeds by positing an optimistic estimate of ⇢, which we denote b⇢
t
, and successively halving it until we are
Algorithm 1 DBAL Input: Hypothesis class H, prior distribution ⇡ Initialize V = H while 1
n",4.1. Finding a Good Query Point,[0],[0]
"(E) 3✏ 4
for E ⇠ (⇡| V ) 2⇥n",4.1. Finding a Good Query Point,[0],[0]
"do Draw m data points x = (x
1 , . . .",4.1. Finding a Good Query Point,[0],[0]
", x m )
",4.1. Finding a Good Query Point,[0],[0]
Query point x,4.1. Finding a Good Query Point,[0],[0]
"i = SELECT(V,x) and set V to be consistent with the result end while return Current version space V in the form of the queried points (x
1 , h⇤(x 1 )), . . .",4.1. Finding a Good Query Point,[0],[0]
", (x K , h⇤(x K ))
",4.1. Finding a Good Query Point,[0],[0]
"Algorithm 2 SELECT Input: Version space V , prior ⇡, data x = (x
1 , . . .",4.1. Finding a Good Query Point,[0],[0]
", x m )
",4.1. Finding a Good Query Point,[0],[0]
"Set b⇢ 1 = 1/2 for t = 1, 2, . . .",4.1. Finding a Good Query Point,[0],[0]
"do
Draw E0 ⇠ (⇡| V ) 2⇥m t and compute b t = 1
m
t (E0)",4.1. Finding a Good Query Point,[0],[0]
"Draw E ⇠ (⇡|
V
)
2⇥n t
",4.1. Finding a Good Query Point,[0],[0]
"If 9x i s.t. 1 n
t
max (E+
x
i
), (E x
i
)  (1 b⇢ t ) b t
, then halt and return x
i
Otherwise, let b⇢ t+1 = b⇢ t /2",4.1. Finding a Good Query Point,[0],[0]
"end for
confident that we have found a point that b⇢ t -average splits the version space.",4.1. Finding a Good Query Point,[0],[0]
"In order for this algorithm to succeed, we need to choose n
t and m t such that with high probability (1) b
t is an accurate estimate of (V ) and (2) our halting condition will be true if b⇢
t is within a constant factor of ⇢ and false otherwise.",4.1. Finding a Good Query Point,[0],[0]
"The following lemma, whose proof is in the appendix, provides such choices for n
t and m t .
",4.1. Finding a Good Query Point,[0],[0]
Lemma 5.,4.1. Finding a Good Query Point,[0],[0]
"Let ⇢, ✏, 0 > 0 be given.",4.1. Finding a Good Query Point,[0],[0]
Suppose that version space V satisfies (V ) >,4.1. Finding a Good Query Point,[0],[0]
✏.,4.1. Finding a Good Query Point,[0],[0]
"In SELECT, fix a round t and data point x 2 X that exactly ⇢-average splits V (that is, max{⇡|
V (V + x ) 2 (V + x ), ⇡| V (V x ) 2 (V x )} = (1 ⇢) (V )).",4.1. Finding a Good Query Point,[0],[0]
"If
m t 48b⇢2 t ✏ log 4 0 and n t
max ( 32
b⇢2 t
b
t
, 40
b 2
t
) log 4
0
then with probability 1 0 ,
b
t (1 b⇢ t /4)",4.1. Finding a Good Query Point,[0],[0]
"(V ) and
(a) if ⇢  b⇢ t /2, then
1
n t
max (E+
x ), (E x )
>",4.1. Finding a Good Query Point,[0],[0]
"(1 b⇢
t
)
b
t
.
",4.1. Finding a Good Query Point,[0],[0]
"(b) If ⇢ 2b⇢ t , then
1
n t
max (E+
x ), (E x )  (1 b⇢ t ) b t .
",4.1. Finding a Good Query Point,[0],[0]
"Given the above lemma, we can establish a bound on the number of rounds and the total number of hypotheses SELECT needs to find a data point that ⇢/8-average splits the version space.
",4.1. Finding a Good Query Point,[0],[0]
Theorem 6.,4.1. Finding a Good Query Point,[0],[0]
"Suppose that SELECT is called with a version space V with (V ) ✏ and a collection of points x 1 , . . .",4.1. Finding a Good Query Point,[0],[0]
", x m such that at least one of x i
⇢-average splits V .",4.1. Finding a Good Query Point,[0],[0]
"If
0  /(2m(2 + log(1/⇢))), then with probability at least 1 , SELECT returns a point x
i that (⇢/8)-average splits V , finishing in less than dlog(1/⇢)e + 1 rounds and sampling O ⇣⇣ 1
✏⇢
2 + log(1/⇢)
(V )
2
⌘ log 1
0
⌘ hypotheses in total.
",4.1. Finding a Good Query Point,[0],[0]
Remark 1: It is possible to modify SELECT to find a point x,4.1. Finding a Good Query Point,[0],[0]
"i
that (c⇢)-average splits V for any constant c < 1 while only having to draw O(1) more hypotheses in total.",4.1. Finding a Good Query Point,[0],[0]
"First note that by halving b⇢
t at each step, we immediately give up a factor of two in our approximation.",4.1. Finding a Good Query Point,[0],[0]
This can be made smaller by taking narrower steps.,4.1. Finding a Good Query Point,[0],[0]
"Additionally, with a constant factor increase in m
t and n t , the approximation ratios in Lemma 5 can be set to any constant.
",4.1. Finding a Good Query Point,[0],[0]
"Remark 2: At first glance, it appears that SELECT requires us to know ⇢ in order to calculate
0 .",4.1. Finding a Good Query Point,[0],[0]
"However, a crude lower bound on ⇢ suffices.",4.1. Finding a Good Query Point,[0],[0]
Such a bound can always be found in terms of ✏.,4.1. Finding a Good Query Point,[0],[0]
"This is because any version space is (✏/2, ✏, ✏/2)-splittable (Dasgupta, 2005, Lemma 1).",4.1. Finding a Good Query Point,[0],[0]
"By Lemma 3, so long as ⌧ is less than ✏/4, we can substitute
✏ 8dlog(2/✏)e for ⇢ in when we compute 0.
",4.1. Finding a Good Query Point,[0],[0]
Proof of Theorem 6.,4.1. Finding a Good Query Point,[0],[0]
Let T := dlog(1/⇢)e + 1.,4.1. Finding a Good Query Point,[0],[0]
"By Lemma 5, we know that for rounds t = 1, . . .",4.1. Finding a Good Query Point,[0],[0]
", T , we don’t return any point which does worse than b⇢
t /2-average splits V with probability 1 /2.",4.1. Finding a Good Query Point,[0],[0]
"Moreover, in the T -th round, it will be the case that ⇢/4  b⇢
T  ⇢/2, and therefore, with probability 1 /2, we will select a point which does no worse than b⇢
T /2-average split V , which in turn does no worse than ⇢/8-average split V .
",4.1. Finding a Good Query Point,[0],[0]
Note that we draw m t + n t hypotheses at each round.,4.1. Finding a Good Query Point,[0],[0]
"By Lemma 5, for each round b
t
3 (V )/4 3✏/4.",4.1. Finding a Good Query Point,[0],[0]
"Thus
# of hypotheses drawn = TX
t=1
m t + n t
=
TX
t=1
48
b⇢2 t ✏ +
32
b⇢2 t
b
t
+
40 b 2
t
!",4.1. Finding a Good Query Point,[0],[0]
"log 4
0
 TX
t=1
✓ 96
✏b⇢2 t
+
72
(V )2
◆ log 4
0
",4.1. Finding a Good Query Point,[0],[0]
"Given b⇢ t = 1/2t and T  2 + log 1/⇢, we have TX
t=1
1
b⇢2 t
=
TX
t=1
2 2t 
TX
t=1
2
t
!",4.1. Finding a Good Query Point,[0],[0]
"2
 ⇣ 2 2+log 1/⇢ ⌘ 2 = 16
⇢2 .
",4.1. Finding a Good Query Point,[0],[0]
"Plugging in 0  2m(2+log(1/⇢))
, we recover the theorem statement.",4.1. Finding a Good Query Point,[0],[0]
"Using the SELECT procedure as a subroutine, Algorithm 1, henceforth DBAL for Diameter-based Active Learning, is our active learning strategy.",4.2. Active Learning Strategy,[0],[0]
"Given a hypothesis class with average splitting index (⇢, ✏/2, ⌧), DBAL queries data points provided by SELECT until it is confident (V ) <",4.2. Active Learning Strategy,[0],[0]
"✏.
",4.2. Active Learning Strategy,[0],[0]
Denote by V t the version space in the t-th round of DBAL.,4.2. Active Learning Strategy,[0],[0]
"The following lemma, which is proven in the appendix, demonstrates that the halting condition (that is, (E) < 3✏n/4, where E consists of n pairs sampled from (⇡|
V
) 2) guarantees that with high probability DBAL stops when (V
t
) is small.
",4.2. Active Learning Strategy,[0],[0]
Lemma 7.,4.2. Active Learning Strategy,[0],[0]
"The following holds for DBAL:
(a) Suppose that for all t = 1, 2, . . .",4.2. Active Learning Strategy,[0],[0]
",K that (V t ) >",4.2. Active Learning Strategy,[0],[0]
✏.,4.2. Active Learning Strategy,[0],[0]
"Then the probability that the termination condition is
ever true for any of those rounds is bounded above by
K exp ✏n
32
.
",4.2. Active Learning Strategy,[0],[0]
"(b) Suppose that for some t = 1, 2, . . .",4.2. Active Learning Strategy,[0],[0]
",K that (V t )  ",4.2. Active Learning Strategy,[0],[0]
✏/2.,4.2. Active Learning Strategy,[0],[0]
"Then the probability that the termination condition is not true in that round is bounded above by
K exp ✏n
48
.
",4.2. Active Learning Strategy,[0],[0]
"Given the guarantees on the SELECT procedure in Theorem 6 and on the termination condition provided by Lemma 7, we get the following theorem.
",4.2. Active Learning Strategy,[0],[0]
Theorem 8.,4.2. Active Learning Strategy,[0],[0]
"Suppose that H has average splitting index (⇢, ✏/2, ⌧).",4.2. Active Learning Strategy,[0],[0]
Then DBAL returns a version space V satisfying (V )  ,4.2. Active Learning Strategy,[0],[0]
"✏ with probability at least 1 while using the following resources:
(a) K  8 ⇢
⇣ log 2
✏
+ 2 log
1
⇡(h ⇤ )
⌘ rounds, with one label
per round,
(b) m  1 ⌧ log 2K unlabeled data points sampled per
round, and
(c) n  ",4.2. Active Learning Strategy,[0],[0]
"O ⇣⇣ 1
✏⇢
2 + log(1/⇢)
✏
2
⌘ log mK + log log 1
✏
⌘ hy-
potheses sampled per round.
",4.2. Active Learning Strategy,[0],[0]
Proof.,4.2. Active Learning Strategy,[0],[0]
"From definition of the average splitting index, if we draw m = 1
⌧
log
2K unlabeled points per round, then with probability 1 /2, each of the first K rounds will have at least one data point that ⇢-average splits the current version space.",4.2. Active Learning Strategy,[0],[0]
"In each such round, if the version space has average diameter at least ✏/2, then with probability 1 /4 SELECT will return a data point that ⇢/8-average splits the current version space while sampling no more
than n = O ⇣⇣ 1
✏⇢
2 + 1
✏
2 log 1
⇢
⌘ log mK log 1 ✏ ⌘ hypotheses
per round by Theorem 6.
",4.2. Active Learning Strategy,[0],[0]
"By Lemma 7, if the termination check uses n0 = O 1
✏
log
1 hypotheses per round, then with probability
1 /4 in the first K rounds the termination condition will never be true when the current version space has average diameter greater than ✏ and will certainly be true if the current version space has diameter less than ✏/2.
",4.2. Active Learning Strategy,[0],[0]
"Thus it suffices to bound the number of rounds in which we can ⇢/8-average split the version space before encountering a version space with ✏/2.
",4.2. Active Learning Strategy,[0],[0]
"Since the version space is always consistent with the true hypothesis h⇤, we will always have ⇡(V
t )",4.2. Active Learning Strategy,[0],[0]
⇡(h⇤).,4.2. Active Learning Strategy,[0],[0]
"After K = 8
⇢
⇣ log 2
✏
+ 2 log
1
⇡(h ⇤ )
⌘ rounds of ⇢/8-average split-
ting, we have
⇡(h⇤)2 (V K )  ⇡(V K ) 2 (V K )
 ⇣ 1 ⇢
8
⌘ K
⇡(V 0 ) 2 (V 0 )
 ⇡(h ⇤ ) 2✏
2
Thus in the first K rounds, we must terminate with a version space with average diameter less than ✏.",4.2. Active Learning Strategy,[0],[0]
"In this section, we give the proof of the following relationship between the original splitting index and our average splitting index.
",5. Proof of Lemma 3,[0],[0]
Lemma 3.,5. Proof of Lemma 3,[0],[0]
"Let ⇡ be a probability measure over a hypothesis class H. If H has splitting index (⇢, ✏, ⌧), then it has average splitting index ( ⇢
4dlog(1/✏)e , 2✏, ⌧).
",5. Proof of Lemma 3,[0],[0]
The first step in proving Lemma 3 is to relate the splitting index to our estimator (·).,5. Proof of Lemma 3,[0],[0]
"Intuitively, splittability says that for any set of large edges there are many data points which remove a significant fraction of them.",5. Proof of Lemma 3,[0],[0]
"One may suspect this should imply that if a set of edges is large on average, then there should be many data points which remove a significant fraction of their weight.",5. Proof of Lemma 3,[0],[0]
"The following lemma confirms this suspicion.
",5. Proof of Lemma 3,[0],[0]
Lemma 9.,5. Proof of Lemma 3,[0],[0]
"Suppose that V ⇢ H has splitting index (⇢, ✏, ⌧), and say E = ({h
1 , h0 1 }, . . .",5. Proof of Lemma 3,[0],[0]
", {h n , h0 n }) is a sequence of hypothesis pairs from V satisfying 1
n",5. Proof of Lemma 3,[0],[0]
(E) > 2✏.,5. Proof of Lemma 3,[0],[0]
"Then if x ⇠ D, we have with probability at least ⌧ ,
max (E+
x ), (E x )
 ✓ 1 ⇢ 4dlog(1/✏)e ◆ (E).
",5. Proof of Lemma 3,[0],[0]
Proof.,5. Proof of Lemma 3,[0],[0]
"Consider partitioning E as
E 0 =",5. Proof of Lemma 3,[0],[0]
"{{h, h0} 2 E : d(h, h0) < ✏} and E
k = {{h, h0} 2 E : d(h, h0) 2",5. Proof of Lemma 3,[0],[0]
"[2k 1✏, 2k✏) for k = 1, . . .",5. Proof of Lemma 3,[0],[0]
",K with K = dlog 1
✏
e. Then E 0 , . . .",5. Proof of Lemma 3,[0],[0]
", E K
are all disjoint and their union is E. Define E
1:K =",5. Proof of Lemma 3,[0],[0]
"[K k=1 E k .
",5. Proof of Lemma 3,[0],[0]
We first claim that (E 1:K ) >,5. Proof of Lemma 3,[0],[0]
(E 0 ).,5. Proof of Lemma 3,[0],[0]
"This follows from the observation that because (E) 2n✏ and each edge in E
0
has length less than ✏, we must have
(E 1:K ) =",5. Proof of Lemma 3,[0],[0]
(E) (E 0 ),5. Proof of Lemma 3,[0],[0]
"> 2n✏ n✏ > (E 0 ).
",5. Proof of Lemma 3,[0],[0]
"Next, observe that because each edge {h, h0} 2 E k
with k 1 satisfies d(h, h0) 2",5. Proof of Lemma 3,[0],[0]
"[2k 1✏, 2k✏), we have
(E 1:K ) =
KX
k=1
X
{h,h0}2E k
d(h, h0)  ",5. Proof of Lemma 3,[0],[0]
"KX
k=1
2 k✏|E k |.
",5. Proof of Lemma 3,[0],[0]
"Since there are only K summands on the right, at least one of these must be larger than (E
1:K )/K.",5. Proof of Lemma 3,[0],[0]
"Let k denote that index and let x be a point which ⇢-splits E
k
.",5. Proof of Lemma 3,[0],[0]
"Then we have
((E 1:K ) +
x
)  ",5. Proof of Lemma 3,[0],[0]
(E 1:K ) (E k \,5. Proof of Lemma 3,[0],[0]
(E k ),5. Proof of Lemma 3,[0],[0]
"+
x
)
 (E 1:K ) ⇢2k 1✏|E k",5. Proof of Lemma 3,[0],[0]
"|  ⇣ 1 ⇢
2K
⌘ (E
1:K
).
",5. Proof of Lemma 3,[0],[0]
"Since (E 1:K ) (E 0 ), we have
(E+ x )  ",5. Proof of Lemma 3,[0],[0]
(E 0 ),5. Proof of Lemma 3,[0],[0]
"+
⇣ 1 ⇢
2K
⌘ (E
1:K
)
 ⇣ 1 ⇢
4K
⌘ (E).
",5. Proof of Lemma 3,[0],[0]
"Symmetric arguments show the same holds for E x .
",5. Proof of Lemma 3,[0],[0]
"Finally, by the definition of splitting, the probability of drawing a point x which ⇢-splits E
k is at least ⌧ , giving us the lemma.
",5. Proof of Lemma 3,[0],[0]
"With Lemma 9 in hand, we are now ready to prove Lemma 3.
",5. Proof of Lemma 3,[0],[0]
Proof of Lemma 3.,5. Proof of Lemma 3,[0],[0]
Let V ⇢ H such that (V ) > 2✏.,5. Proof of Lemma 3,[0],[0]
"Suppose that we draw n edges E i.i.d. from ⇡|
V and draw a data point x ⇠ D. Then Hoeffding’s inequality (Hoeffding, 1963), combined with Lemma 4, tells us that there exist sequences ✏
n , n & 0 such that with probability at least 1 3
n
, the following hold simultaneously:
• (V ) ✏ n  1 n (E)  (V ) + ✏ n ,
• 1 n (E+ x ) ⇡(V +x )2 ⇡(V ) 2 (V + x )",5. Proof of Lemma 3,[0],[0]
"✏ n , and
•",5. Proof of Lemma 3,[0],[0]
1 n,5. Proof of Lemma 3,[0],[0]
"(E x ) ⇡(V x )2 ⇡(V ) 2 (V x ) ✏ n .
",5. Proof of Lemma 3,[0],[0]
"For ✏ n small enough, we have that (V ) ✏ n > 2✏.",5. Proof of Lemma 3,[0],[0]
"Combining the above with Lemma 9, we have with probability at least ⌧ 3
n
,
max
⇢ ⇡(V +
x
)
2
⇡(V )2 (V + x
), ⇡(V x ) 2
⇡(V )2 (V x )
✏
n
 1 n max{ (E+ x ), (E x )}  ✓ 1 ⇢
4dlog(1/✏)e ◆ (E) n
 ✓ 1 ⇢ 4dlog(1/✏)e ◆ ( (V ) +",5. Proof of Lemma 3,[0],[0]
"✏ n )
",5. Proof of Lemma 3,[0],[0]
By taking n !,5. Proof of Lemma 3,[0],[0]
"1, we have ✏ n , n & 0, giving us the lemma.",5. Proof of Lemma 3,[0],[0]
"We compared DBAL against the baseline passive learner as well as two other generic active learning strategies: CAL
and QBC. CAL proceeds by randomly sampling a data point and querying it if its label cannot be inferred from previously queried data points.",6. Simulations,[0],[0]
QBC uses a prior distribution ⇡ and maintains a version space V .,6. Simulations,[0],[0]
"Given a randomly sampled data point x, QBC samples two hypotheses h, h0 ⇠ ⇡|
V and queries x if h(x) 6= h0(x).",6. Simulations,[0],[0]
"We tested on two hypothesis classes: homogeneous, or through-the-origin, linear separators and k-sparse monotone disjunctions.",6. Simulations,[0],[0]
"In each of our simulations, we drew our target h⇤ from the prior distribution.",6. Simulations,[0],[0]
"After each query, we estimated the average diameter of the version space.",6. Simulations,[0],[0]
"We repeated each simulation several times and plotted the average performance of each algorithm.
",6. Simulations,[0],[0]
Homogeneous linear separators,6. Simulations,[0],[0]
The class of ddimensional homogeneous linear separators can be identified with elements of the d-dimensional unit sphere.,6. Simulations,[0],[0]
"That is, a hypothesis h 2",6. Simulations,[0],[0]
"Sd 1 acts on a data point x 2 Rd via the sign of their inner product:
h(x) := sign(hh, xi).
",6. Simulations,[0],[0]
"In our simulations, both the prior distribution and the data distribution are uniform over the unit sphere.",6. Simulations,[0],[0]
"Although there is no known method to exactly sample uniformly from the version space, Gilad-Bachrach et al. (2005) demonstrated that using samples generated by the hit-andrun Markov chain works well in practice.",6. Simulations,[0],[0]
"We adopted this approach for our sampling tasks.
",6. Simulations,[0],[0]
"Figure 1 shows the results of our simulations on homogeneous linear separators.
",6. Simulations,[0],[0]
Sparse monotone disjunctions A k-sparse monotone disjunction is a disjunction of k positive literals.,6. Simulations,[0],[0]
"Given a Boolean vector x 2 {0, 1}n, a monotone disjunction h classifies x as positive if and only if x
i = 1 for some positive literal i in h.
In our simulations, each data point is a vector whose coordinates are i.i.d.",6. Simulations,[0],[0]
Bernoulli random variables with parameter p.,6. Simulations,[0],[0]
The prior distribution is uniform over all k-sparse monotone disjunctions.,6. Simulations,[0],[0]
"When k is constant, it is possible to sample from the prior restricted to the version space in expected polynomial time using rejection sampling.
",6. Simulations,[0],[0]
The results of our simulations on k-sparse monotone disjunctions are in Figure 2.,6. Simulations,[0],[0]
The authors are grateful to the reviewers for their feedback and to the NSF for support under grants IIS-1162581 and DGE-1144086.,Acknowledgments,[0],[0]
"Part of this work was done at the Simons Institute for Theoretical Computer Science, Berkeley, as part of a program on the foundations of machine learning.",Acknowledgments,[0],[0]
CT additionally thanks Daniel Hsu and Stefanos Poulis for helpful discussions.,Acknowledgments,[0],[0]
"In many situations where a classifier is to be learned, it is easy to collect unlabeled data but costly to obtain labels.",abstractText,[0],[0]
"This has motivated the pool-based active learning model, in which a learner has access to a collection of unlabeled data points and is allowed to ask for individual labels in an adaptive manner.",abstractText,[0],[0]
"The hope is that choosing these queries intelligently will rapidly yield a low-error classifier, much more quickly than with random querying.",abstractText,[0],[0]
A central focus of active learning is developing efficient querying strategies and understanding their label complexity.,abstractText,[0],[0]
Diameter-Based Active Learning,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 686–693 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
686",text,[0],[0]
Problem.,1 Introduction,[0],[0]
Schumacher convinced to win on Sunday.,1 Introduction,[0],[0]
"When this news headline is fed into modern tools for Named Entity Disambiguation (NED), virtually all of them would map the mention Schumacher onto the former Formula One champion Michael Schumacher, as the best-fitting entity from a Wikipedia-centric knowledge base (KB).",1 Introduction,[0],[0]
"However, knowing that Sunday refers to August 14, 1949, i.e., ignoring the surface form but exploiting normalized information, it becomes clear that the text actually refers to the German politician Kurt Schumacher.",1 Introduction,[0],[0]
"State-of-the-art NED methods (see surveys by Hachey et al. (2013), Ling et al. (2015), Shen et al. (2015)) tend to miss this because they are designed and trained for temporally focused input corpora such as current news, and do not cope well with longitudinal archives and other diachronic corpora that span decades.",1 Introduction,[0],[0]
"Standard NED benchmarks from CoNLL and TAC do not reflect this difficulty either.
",1 Introduction,[0],[0]
1The diaNED corpus and the temporal signatures of entities are publicly available: https://www.mpi-inf.,1 Introduction,[0],[0]
"mpg.de/yago-naga/dianed/.
What is needed here is a better way of capturing temporal context, for both the mention Schumacher and each of the candidate entities.",1 Introduction,[0],[0]
Figure 1 illustrates “time profiles” for sample entities with highly ambiguous names.,1 Introduction,[0],[0]
"Normalized temporal information from the input context, such as Sunday (1949-08-14), can provide additional cues for proper disambiguation.",1 Introduction,[0],[0]
The problem addressed in this paper is how to model and capture temporal contexts and how to enhance NED with this novel asset.,1 Introduction,[0],[0]
Contribution.,1 Introduction,[0],[0]
"Our approach to this problem is to compute temporal signatures for entities in the KB, and to use these as expressive features when comparing candidate entities against the context of an input mention.",1 Introduction,[0],[0]
Temporal signatures are embeddings that reflect the importance of different years for entities.,1 Introduction,[0],[0]
They are automatically constructed by extracting and normalizing temporal expressions in entity descriptions such as Wikipedia articles.,1 Introduction,[0],[0]
"Analogously, temporal signals are captured in the contexts of textual mentions and represented by embeddings.
",1 Introduction,[0],[0]
"The time-aware NED method that we devise with these features can robustly cope with inputs
from diachronic corpora.",1 Introduction,[0],[0]
"We propose a new evaluation benchmark, based on the New York Times Archive, spanning more than 20 years, and the history collection historynet.com, spanning several centuries.",1 Introduction,[0],[0]
Our experiments demonstrate that timeaware NED substantially outperforms some of the best standard NED tools.,1 Introduction,[0],[0]
"Better context representation improves disambiguation quality (see, e.g., Shen et al. (2015)).",2 Temporal Signatures and Contexts,[0],[0]
"As the underlying entity descriptions (e.g., Wikipedia articles) are not only textually but also temporally related to their mentions, we enrich the context representation with a temporal dimension, which no prior work handles explicitly.
",2 Temporal Signatures and Contexts,[0],[0]
We model the temporal dimension by embedding vectors.,2 Temporal Signatures and Contexts,[0],[0]
The embeddings represent the temporal signatures of entities in a KB and the temporal contexts of entity mentions in text in a joint vector space.,2 Temporal Signatures and Contexts,[0],[0]
"Then, the similarity between them quantifies their temporal relatedness.
",2 Temporal Signatures and Contexts,[0],[0]
Temporal vector space.,2 Temporal Signatures and Contexts,[0],[0]
"We use 2,050 dimensions (years 1 AD to 2050) to define the vector space.",2 Temporal Signatures and Contexts,[0],[0]
"Coarser and finer granularities than years could be used, but finer ones (e.g., days) are rarely needed for NED and coarser granularities (e.g., centuries) are too vague.2
Temporal signatures of entities.",2 Temporal Signatures and Contexts,[0],[0]
We use the temporal tagger HeidelTime,2 Temporal Signatures and Contexts,[0],[0]
"(Strötgen and Gertz, 2010; Strötgen and Gertz, 2015) to extract and normalize date expressions from an entity’s Wikipedia page3 and aggregate them by years.",2 Temporal Signatures and Contexts,[0],[0]
"This results in a count-based temporal vector tcbe = (t0001, ..., ti, ..., t2050) where ti is the total number of temporal expressions extracted from e’s Wikipedia page referring to year i. Temporal expressions of finer granularities are mapped to respective years and expressions of coarser granularities than year are currently ignored.
",2 Temporal Signatures and Contexts,[0],[0]
"As the count-based vectors may overfit to the entity descriptions and to avoid discontinuity in the temporal signatures, we apply exponential smoothing and get smoothed temporal vectors
2In an analysis of temporal expressions extracted with HeidelTime from the Wikipedia corpus (August 2016 dump), we find that there are on average 18.500 expressions per year value (with year values ranging from 0001 AD to 2050 AD) in contrast to only 9.64 expressions per day value (with day values ranging from 0001-01-01 to 2050-12-31).",2 Temporal Signatures and Contexts,[0],[0]
"Therefore, using year level identifiers to define our temporal vector space results in short and non-sparse temporal vectors.
",2 Temporal Signatures and Contexts,[0],[0]
"3August 2016 Wikipedia dump
tse = (t s 0001, ..., t s i , ..., t s 2050) such that t s i = α · tcbi + (1 − α) ·",2 Temporal Signatures and Contexts,[0],[0]
"tsi−1, for i > 0001 where α is the smoothing factor with 0 ≤ α ≤ 1.",2 Temporal Signatures and Contexts,[0],[0]
"For further smoothing, this procedure can be recursively applied n times.",2 Temporal Signatures and Contexts,[0],[0]
"In experiments, we set α = 0.2 and n = 2 based on cross-validation.
",2 Temporal Signatures and Contexts,[0],[0]
Temporal contexts of entity mentions.,2 Temporal Signatures and Contexts,[0],[0]
We exploit temporal expressions in the surrounding text of entity mentions and the texts’ publication dates.,2 Temporal Signatures and Contexts,[0],[0]
"In news-style articles, entities are likely to be related to the document creation time (dct), while dates in the content are important for other types of documents (Strötgen and Gertz, 2016).
",2 Temporal Signatures and Contexts,[0],[0]
"Temporal vectors for mentions tm are thus a combination of a one-hot temporal vector tdctm = (0, ..., ti, ..., 0)",2 Temporal Signatures and Contexts,[0],[0]
"where ti=1 if i is the dct’s year, and tcontentm containing dates extracted by a temporal tagger in the immediate context of the mention (e.g., in the same sentence or paragraph), aggregated by year.",2 Temporal Signatures and Contexts,[0],[0]
tdctm and t content m are linearly combined as tm = λ · tdctm +(1−λ) · tcontentm where λ (with 0 ≤,2 Temporal Signatures and Contexts,[0],[0]
λ,2 Temporal Signatures and Contexts,[0],[0]
"≤ 1) weights the components.
",2 Temporal Signatures and Contexts,[0],[0]
Relatedness.,2 Temporal Signatures and Contexts,[0],[0]
We calculate the temporal relatedness between a mention and all candidate entities as the cosine similarity between tm and te.,2 Temporal Signatures and Contexts,[0],[0]
"To test the importance of time-awareness for NED, we use two settings.",3 Time-aware NED,[0],[0]
"We enhance a basic NED system and a state-of-the-art system by enriching both with temporal signatures and contexts.
",3 Time-aware NED,[0],[0]
"diaNED-1, as basic NED system, uses a mention-entity prior reflecting entity prominence and a keyphrase-based language model for the similarity of mention and entity contexts (as suggested by Hoffart et al. (2011)).",3 Time-aware NED,[0],[0]
These components are cast into edge weights for a graph over which the final disambiguation is computed.,3 Time-aware NED,[0],[0]
"Hyper-parameters for the relative influence of the two components are tuned using an SVM.
",3 Time-aware NED,[0],[0]
"We added the temporal dimension to the feature set and retrained the model accordingly to get new feature weights.
",3 Time-aware NED,[0],[0]
diaNED-2 based on Yamada et al. (2016):,3 Time-aware NED,[0],[0]
This is a learning-to-rank-based model.,3 Time-aware NED,[0],[0]
"Besides mention-entity priors and string-similarity features, it uses word and entity embeddings trained in a joint vector space to model context and coherence.",3 Time-aware NED,[0],[0]
"The intuition is that a good candidate entity vector must be close to the word and entity vectors appearing in the same context.
",3 Time-aware NED,[0],[0]
Yamada et al. (2016) measures entity context by averaging the word vectors of the proper noun neighbors and calculating the cosine similarity with each candidate entity.,3 Time-aware NED,[0],[0]
"Similarly, the coherence between entities is measured by computing the cosine similarity between candidates and the average of the other entities in the neighborhood.
",3 Time-aware NED,[0],[0]
diaNED-2 enhances this model as follows.,3 Time-aware NED,[0],[0]
"We compute the cosine similarity between the mention’s and the candidate entities’ temporal vectors, and normalize the time relatedness scores across candidate entities.",3 Time-aware NED,[0],[0]
"Finally, all similarity features are used to train a binary classifier with gradientboosted decision trees.",3 Time-aware NED,[0],[0]
The top-ranked candidate entity in each pool of candidates is assigned to the mention being evaluated.,3 Time-aware NED,[0],[0]
Datasets for NED evaluation contain articles published within a short period.,4 A Diachronic NED Data Set,[0],[0]
"Consequently, all mentions share a temporal context making it difficult to evaluate temporal variability.",4 A Diachronic NED Data Set,[0],[0]
"CoNLLAIDA (Hoffart et al., 2011) are newswire articles from 1996, TAC 2010 (Ji et al., 2010) news and forum articles from 2004–2007, and Microposts2014",4 A Diachronic NED Data Set,[0],[0]
"(Cano et al., 2014) tweets from 2011.
",4 A Diachronic NED Data Set,[0],[0]
"To account for this limitation, we create a new diachronic benchmark containing documents with heterogeneous temporal context.",4 A Diachronic NED Data Set,[0],[0]
"As in Microposts-2014, we limit documents to single sentences and headlines from HistoryNet.com (HN) and The New York Times corpus (NYT).",4 A Diachronic NED Data Set,[0],[0]
"For the annotation process, we followed the entity annotation guidelines, which have been used for annotating CoNLL-AIDA (Hoffart et al., 2011).
",4 A Diachronic NED Data Set,[0],[0]
HN is an online resource of world history with information on popular historical topics.,4 A Diachronic NED Data Set,[0],[0]
"Its section Today in History contains short texts on what happened on a specific day with a total of 7,061 facts/events (excluding born today).",4 A Diachronic NED Data Set,[0],[0]
"Using Stanford NER (Finkel et al., 2005), we extracted 13,773 entity mentions and randomly selected 350 of them.",4 A Diachronic NED Data Set,[0],[0]
We annotated all entity mentions in respective sentences with their Wikipedia ids.,4 A Diachronic NED Data Set,[0],[0]
"After removing NER errors and out-of-KB entities, the dataset contains 865 gold entity mentions in 334 sentences.",4 A Diachronic NED Data Set,[0],[0]
"Examples are: “Conrad II claims the throne in France” from 1032 or “The Old Pretender, son of James III dies” from 1766.
",4 A Diachronic NED Data Set,[0],[0]
NYT contains more than 1.5 million documents published between 1987 and 2007.,4 A Diachronic NED Data Set,[0],[0]
"After apply-
ing the same procedure, the dataset contains 368 manually annotated mentions in 290 news headlines.",4 A Diachronic NED Data Set,[0],[0]
"Examples are “Arafat’s Faction is Said to Avoid Guerrilla Actions” from 1989 or “U.N. Aide to Meet Milosevic, Angering Some” from 1999.
",4 A Diachronic NED Data Set,[0],[0]
"As HN texts come without further context, entity mentions are rather explicit.",4 A Diachronic NED Data Set,[0],[0]
"Entity mentions in NYT ’s headlines are more ambiguous as more information is available in the articles and the entities are mostly, at the time of publication, prominent and obvious to the reader.
",4 A Diachronic NED Data Set,[0],[0]
"Finally, we created a third subset from the 7,061 documents of HistoryNet.com with 13,773 entity mentions.",4 A Diachronic NED Data Set,[0],[0]
"It contains the sentences with all the entity mentions which are linked to different entities by diaNED-2 depending on whether it uses its time-awareness or not, i.e., whether diaNED2 is trained with or without the temporal feature.",4 A Diachronic NED Data Set,[0],[0]
This set (HN-timediff ) contains 567 manually annotated entities from 547 documents.,4 A Diachronic NED Data Set,[0],[0]
It is the most challenging subset as all entity mentions are difficult to disambiguate.,4 A Diachronic NED Data Set,[0],[0]
"To evaluate the importance of temporal information in NED, we focus in our analysis on the newly created diaNED corpus.",5 Evaluation,[0],[0]
"As standard NED datasets CoNLL-AIDA and TAC 2010 contain only articles published within a short period of time, they are not suited for evaluating timeaware NED (cf. Section 4), and experiments on these datasets showed no significant differences between using diaNED-1 and diaNED-2 with or without their time-awareness features.
",5 Evaluation,[0],[0]
Note that the temporal contexts in the HN sentences and the NYT headlines of the diaNED corpus are part of the metadata.,5 Evaluation,[0],[0]
"Thus, to ensure a fair comparison among all systems, we added the temporal contexts in the form of year information to all documents to allow the non-time-aware systems to exploit the temporal context in case the respective year number occurs as part of the entities’ textual context.4",5 Evaluation,[0],[0]
"As described above, we (re-)implemented two NED systems as diaNED-1 and diaNED-2.",5.1 Intra-system Comparison,[0],[0]
"To al-
4Disambiguation quality of non-time-aware systems was generally lower without this additional information.",5.1 Intra-system Comparison,[0],[0]
"The diaNED corpus contains all sentences with and without year information so that evaluation results can be reproduced for both settings.
",5.1 Intra-system Comparison,[0],[0]
"low the systems to adapt to the diachronic corpus without considering temporal information explicitly, we retrained the systems so that appropriate weights are learnt for each standard feature.",5.1 Intra-system Comparison,[0],[0]
"Due to the rather small size of the diaNED corpus, we use bootstrapping (i.e., train and evaluate on 50 randomly shuffled versions of the corpus) with and without using the time-awareness feature.
diaNED-1.",5.1 Intra-system Comparison,[0],[0]
Table 1 shows micro-accuracy for our basic NED system on the HN and NYT sets of diaNED.,5.1 Intra-system Comparison,[0],[0]
Significant gains are achieved when combining the prior and context features with the time-awareness feature.,5.1 Intra-system Comparison,[0],[0]
"This demonstrates that NED systems with standard features can be improved by making them time-aware.
diaNED-2.",5.1 Intra-system Comparison,[0],[0]
Table 2 shows micro-accuracy for our re-implementation of Yamada et al. (2016)’s initial features with and without the timeawareness feature.,5.1 Intra-system Comparison,[0],[0]
"As can be seen in the table, adding the temporal feature improves the results significantly in each setting on both sets, which demonstrates that even state-of-the-art systems can be improved by making them time-aware.",5.1 Intra-system Comparison,[0],[0]
"In Table 3, we compare the time-aware NED approach diaNED-2 to various NED tools available via GERBIL (v. 1.2.5) (Usbeck et al., 2015) and to the recent work by Gupta et al. (2017).",5.2 Inter-system Comparison,[0],[0]
"As all systems are used with standard settings, we also trained diaNED-2 on standard NED training data (CoNLL-AIDA) with the temporal context of entity mentions being the respective article’s year
of publication.",5.2 Inter-system Comparison,[0],[0]
"However, due to the differences in what kind of entities the systems consider and what kind of candidate entity lookup dictionaries they use, the systems are not directly comparable and the performance differences should be interpreted with a grain of salt.",5.2 Inter-system Comparison,[0],[0]
"Nevertheless, timeawareness further increases the distance between (Yamada et al., 2016) and the second best system significantly, which demonstrates its usefulness for NED.",5.2 Inter-system Comparison,[0],[0]
"To gain further insights about the importance of time-awareness, we analyzed the results of diaNED-2 with and without temporal feature on the HN-timediff set of our benchmark (Table 4).",5.3 Type-based Analysis,[0],[0]
"On these particularly challenging documents, the time-awareness feature helps to improve NED quality for all entity types.",5.3 Type-based Analysis,[0],[0]
"While location and organization entities moderately benefit, there is a huge performance increase for person entities.",5.3 Type-based Analysis,[0],[0]
The explanation that person entities benefit most could be that person entities have comparably short life spans and are thus most time-sensitive.,5.3 Type-based Analysis,[0],[0]
"Starting with the early work of Bunescu and Paşca (2006), Cucerzan (2007), Mihalcea and Csomai (2007), and Milne and Witten (2008),
NED methods and tools have been greatly advanced and become mature.",6 Related Work,[0],[0]
"Many systems use a combination of (i) local features like string similarities, lexico-syntactic characteristics and context between mentions and candidate entities and (ii) global features like the coherence among a set of selected entities.",6 Related Work,[0],[0]
"The inference over this feature space is typically performed by probabilistic graphical models, learning-to-rank techniques or algorithms related to such models (see, e.g., Ratinov et al. (2011), Hoffart et al. (2011), Ferragina and Scaiella (2012), Cheng and Roth (2013), Guo and Barbosa (2014), Durrett and Klein (2014), Chisholm and Hachey (2015), Pershina et al. (2015), Lazic et al. (2015), Nguyen et al. (2016), Globerson et al. (2016), Eshel et al. (2017), and Ganea and Hofmann (2017)).",6 Related Work,[0],[0]
"The GERBIL framework (Usbeck et al., 2015) provides a unified way of evaluating a wide variety of NED tools and services.
",6 Related Work,[0],[0]
"A recent line of work uses representational learning to characterize contexts through embeddings (e.g., He et al. (2013), Sun et al. (2015), Francis-Landau et al. (2016), Yamada et al. (2016), Gupta et al. (2017), Yamada et al. (2017)).",6 Related Work,[0],[0]
These approaches naturally lend themselves towards inference by neural networks such as LSTMs.,6 Related Work,[0],[0]
"In our experiments, the Neural TextEntity Encoder by Yamada et al. (2016) serves as state-of-the-art baseline.
",6 Related Work,[0],[0]
"While temporal information was used as a global feature to compute coherence between entity lifespans (Hoffart et al., 2013), no prior work on named entity disambiguation made explicit use of temporal information as a local feature.",6 Related Work,[0],[0]
"However, the value of time has been shown in a variety of other information extraction tasks, such as relation extraction (UzZaman et al., 2013; Mirza and Tonelli, 2016), event extraction (Kuzey et al., 2016; Spitz and Gertz, 2016), and slot filling (Ji et al., 2011; Surdeanu et al., 2011; Surdeanu, 2013), as well as in the context of information retrieval (Berberich et al., 2010; Agarwal and Strötgen, 2017) and fact checking (Popat et al., 2017).",6 Related Work,[0],[0]
"In this paper, inspired by the importance of temporal information for many NLP tasks, we analyzed its value for NED.",6 Related Work,[0],[0]
We proposed the first NED method with explicit consideration of temporal background.,7 Conclusions and Ongoing Work,[0],[0]
"As demon-
strated in our experiments, this time-awareness improves NED quality over diachronic texts that span long time periods.",7 Conclusions and Ongoing Work,[0],[0]
"The diaNED dataset and the temporal signatures of entities are publicly available.5
Currently, we integrate a strategy for handling out-of-KB entities to determine how temporal affinity may help in the nil detection problem.",7 Conclusions and Ongoing Work,[0],[0]
"Furthermore, we plan large-scale experiments with distant supervision data which will also allow to evaluate the effectiveness of considering temporal expressions in the context of the entity mentions as further temporal context information.",7 Conclusions and Ongoing Work,[0],[0]
"Finally, using a multilingual temporal tagger (Strötgen and Gertz, 2015), the value of time for NED could be studied for further languages.",7 Conclusions and Ongoing Work,[0],[0]
The authors thank the anonymous reviewers for their valuable comments and suggestions and Ikuya Yamada for providing the word-entity embeddings and his help in the implementation of one of the baseline systems.,Acknowledgments,[0],[0]
Named Entity Disambiguation (NED) systems perform well on news articles and other texts covering a specific time interval.,abstractText,[0],[0]
"However, NED quality drops when inputs span long time periods like in archives or historic corpora.",abstractText,[0],[0]
This paper presents the first time-aware method for NED that resolves ambiguities even when mention contexts give only few cues.,abstractText,[0],[0]
The method is based on computing temporal signatures for entities and comparing these to the temporal contexts of input mentions.,abstractText,[0],[0]
Our experiments show superior quality on a newly created diachronic corpus.1,abstractText,[0],[0]
diaNED: Time-Aware Named Entity Disambiguation for Diachronic Corpora,title,[0],[0]
"The problem of finding the mixing matrix A from a set of observation vectors y in the model
y = Ax (1)
is only solvable if one can benefit from strong hypotheses on the signal vector x.",1. Introduction,[0],[0]
"For instance, one may assume that
*Equal contribution 1Biomedical Imaging Group, EPFL, Lausanne, Switzerland 2Computer Communications and Applications Laboratory 3, EPFL, Lausanne, Switzerland.",1. Introduction,[0],[0]
"Correspondence to: Pedram Pad <pedram.pad@epfl.ch>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"the entries of x are statistically independent, which results in a class of methods refered to as independent component analysis (ICA) (Hyvärinen et al., 2004).",1. Introduction,[0],[0]
"A more recent trend is to assume that the vector x is sparse, so that the recovery can be recast as a deterministic dictionary learning problem, the prototypical example being sparse component analysis (SCA) (Gribonval & Lesage, 2006; Aharon et al., 2006; Spielman et al., 2012).",1. Introduction,[0],[0]
"Extensive research has been conducted on these problems in the past three decades.
",1. Introduction,[0],[0]
"Prior work: In the literature, ICA precedes SCA and can be traced back to (Herault & Jutten, 1986).",1. Introduction,[0],[0]
"In fact, ICA constitutes the non-Gaussian generalization of the much older principal component analysis (PCA), which is widely used in classical signal processing.",1. Introduction,[0],[0]
"ICA is usually formalized as an optimization problem involving a cost function that measures the independence of the estimated xi (i.e., the entries of the vector x).",1. Introduction,[0],[0]
"A common measure of independence, which is inspired by information theory, is the mutual information of the entries of x. However, due to its computational complexity, other measures such as the kurtosis, which measures the non-Gaussianity of the components, are often used (Hyvärinen & Oja, 2000; Naik & Kumar, 2011) (except in special cases such as the analysis of stable AR(1) processes by (Pad & Unser, 2015)).",1. Introduction,[0],[0]
"The main drawback of ICA is that the system (1) needs to be determined; i.e., A should be square—otherwise the complexity is so high that the methods can only be implemented for small problems (Lathauwer et al., 2007; Lathauwer & Castaing, 2008).
",1. Introduction,[0],[0]
"SCA, on the other hand, is usually achieved by putting constraints on the sparsity of the representation or by optimizing a sparsity-promoting cost function.",1. Introduction,[0],[0]
"Thanks to the emergence of very efficient algorithms, SCA has found wide use in different applications (see (Mairal et al., 2010; Marvasti et al., 2012)).",1. Introduction,[0],[0]
"The underlying framework for SCA is deterministic—this is the primary difference with ICA, which aims to decouple signals that are realizations of stochastic processes.
",1. Introduction,[0],[0]
"α-stable distributions: In this paper, we aim to achieve the best of both worlds: the use of a statistical formulation—in the spirit of ICA—with a restriction to a parametric class of stochastic models that is well adapted to the notion of sparsity.",1. Introduction,[0],[0]
"Specifically, we assume that the entries of the vector x are random variables that are i.i.d.",1. Introduction,[0],[0]
"symmetric-α-
stable.",1. Introduction,[0],[0]
The family of α-stable distributions is a generalization of the Gaussian probability density function (PDF).,1. Introduction,[0],[0]
"Since α-stability is preserved through linear transformation, this class of models has a central position in the study of stochastic processes (Samoradnitsky & Taqqu, 1994; Nikias & Shao, 1995; Shao & Nikias, 1993).",1. Introduction,[0],[0]
"The family is parametrized by α ∈ (0, 2], which controls the rate of decay of the distribution.",1. Introduction,[0],[0]
The extreme case of α = 2 corresponds to the Gaussian distribution—the only non-sparse member of the family.,1. Introduction,[0],[0]
"By contrast, the other members of the SαS family for α < 2 are heavy-tailed with unbounded variance.",1. Introduction,[0],[0]
"This property implies that an i.i.d. sequence of such random variables generates a sparse signal (Amini et al., 2011; Gribonval et al., 2012).",1. Introduction,[0],[0]
"By decreasing α, the distribution becomes more heavy-tailed and thus the signal becomes more sparse (the effect of α is illustrated in Figure 1).
",1. Introduction,[0],[0]
This class of random variables has also been widely used in practice.,1. Introduction,[0],[0]
"Typical applications include: modeling of ultrasound RF signals, (Achim et al., 2015), signal detection theory (Kuruoglu et al., 1998), communications (Middleton, 1999), image processing (Achim & Kuruoglu, 2005), audio processing (Georgiou et al., 1999), sea surface (Gallagher, 2001), network traffic (Resnick, 1997), and finance (Nolan, 2003; Ling, 2005).
",1. Introduction,[0],[0]
Main contributions: Our main contribution in this paper is a new dictionary learning algorithm based on the signal modeling mentioned above.,1. Introduction,[0],[0]
"The proposed method has the following advantages:
1.",1. Introduction,[0],[0]
"all parameters can be estimated from the data (it is hyperparameter-free), 2.",1. Introduction,[0],[0]
"it learns the dictionary without the need to recover the signal x, and 3.",1. Introduction,[0],[0]
"it is fast and remarkably robust.
",1. Introduction,[0],[0]
"Once the matrix A is estimated, it is then possible to efficiently recover x by using standard procedures (Bickson & Guestrin, 2010).
",1. Introduction,[0],[0]
We also show that the proposed algorithm provides an efficient estimator of the spectral measure of a stable random vector.,1. Introduction,[0],[0]
"An enabling component of our method is a new theorem that generalizes a classical result about isometries of `p-norms.
",1. Introduction,[0],[0]
"Organization: In the next section, we briefly review SαS random variables and present our mathematical model.",1. Introduction,[0],[0]
"In Section 3, we establish our main result which then yields an algorithm for finding the matrix A as well as the sparsity index α.",1. Introduction,[0],[0]
"In Section 4, we present the simulation results and compare their performance with existing algorithms.",1. Introduction,[0],[0]
"In Section 5, we summarize the paper and give some suggestions for future work.",1. Introduction,[0],[0]
We begin by recalling some basic properties of symmetricα-stable random variables.,2. Preliminaries and problem formulation,[0],[0]
We then proceed with the formulation of the estimation problem that we solve in Section 3.,2. Preliminaries and problem formulation,[0],[0]
"The notation that we use throughout the paper is as follows: we use italic symbols for random variables, capital boldface symbols for matrices and lowercase boldface symbols for vectors.",2. Preliminaries and problem formulation,[0],[0]
"Thus, X is a deterministic matrix,X is a random matrix and x is a random variable.",2. Preliminaries and problem formulation,[0],[0]
"Likewise, x and x denote a random and a deterministic vector respectively.",2. Preliminaries and problem formulation,[0],[0]
"For any α ∈ (0, 2] and γ > 0, a random variable X with characteristic function
p̂X(ω) = exp(−γ|ω|α) (2)
is called a symmetric-α-stable (SαS) random variable with dispersion γ and stability parameter α (Nikias & Shao, 1995).",2.1. Symmetric-α-stable random variables,[0],[0]
This class of random variables is a generalization of the Gaussian model:,2.1. Symmetric-α-stable random variables,[0],[0]
"For α = 2, X is a Gaussian random variable with zero mean and variance 2γ.",2.1. Symmetric-α-stable random variables,[0],[0]
"As their name suggests, α-stable variables share the property of stability under linear combination (Nikias & Shao, 1995); i.e., if X1, . . .",2.1. Symmetric-α-stable random variables,[0],[0]
", Xn are n i.i.d.",2.1. Symmetric-α-stable random variables,[0],[0]
"copies ofX and a1, . .",2.1. Symmetric-α-stable random variables,[0],[0]
.,2.1. Symmetric-α-stable random variables,[0],[0]
", an ∈ R are n real numbers, then the random variable
Y = a1X1 + · · ·+ anXn (3)
has the same distribution as( |a1|α + · · ·+ |an|α ) 1 αX. (4)
",2.1. Symmetric-α-stable random variables,[0],[0]
"In other words, the random variable Y is an SαS random variable with dispersion γ ‖a‖αα where ‖a‖α = ( |a1|α +
· · · + |an|α )",2.1. Symmetric-α-stable random variables,[0],[0]
1 α is the α-(pseudo)norm of the vector,2.1. Symmetric-α-stable random variables,[0],[0]
"a = (a1, . . .",2.1. Symmetric-α-stable random variables,[0],[0]
", an).",2.1. Symmetric-α-stable random variables,[0],[0]
"This property makes SαS random variables convenient for the study of linear systems.
",2.1. Symmetric-α-stable random variables,[0],[0]
The other property of SαS random variables with α < 2 is their heavy-tailed PDF.,2.1. Symmetric-α-stable random variables,[0],[0]
"When α < 2, we have
lim |x|→∞
|x|1+αpX(x) = C(α, γ), (5)
where pX is the PDF of X and C(α, γ) is a positive constant that depends on α and γ (Nikias & Shao, 1995).",2.1. Symmetric-α-stable random variables,[0],[0]
This implies that the variance of SαS random variables is unbounded for α < 2.,2.1. Symmetric-α-stable random variables,[0],[0]
"Also, note that a smaller α results in heavier tails.
",2.1. Symmetric-α-stable random variables,[0],[0]
"Infinite-variance random variables are considered to be appropriate candidates for sparse signals (Amini et al., 2011; Gribonval et al., 2012).",2.1. Symmetric-α-stable random variables,[0],[0]
"Because an i.i.d. sequence of heavytailed random variables has most of its energy concentrated on a small fraction of samples, they are good candidates to model signals that exhibit sparse behavior.
",2.1. Symmetric-α-stable random variables,[0],[0]
"Yet, the truly fundamental aspect of α-stable random variables is their role in the generalized central limit theorem.",2.1. Symmetric-α-stable random variables,[0],[0]
"As we know, the limit distribution of normalized sums of i.i.d. finite-variance random variables are Gaussian.",2.1. Symmetric-α-stable random variables,[0],[0]
"Likewise, any properly normalized sum of heavy-tailed i.i.d. random variables converges to an α-stable random variable whee the α depends on the weight of their tail (Meerschaert & Scheffler, 2001).",2.1. Symmetric-α-stable random variables,[0],[0]
This implies that a linear combination of a large number of samples of a sparse signal is well represented by α-stable random variables.,2.1. Symmetric-α-stable random variables,[0],[0]
"Our underlying signal model is
y = Ax (6)
where x is an unknown n× 1 random vector with SαS i.i.d. entries and α < 2, y is an m× 1 observation vector and A is an m× n dictionary matrix,.",2.2. Problem formulation,[0],[0]
"We are given K realizations of y; namely, y1, . . .",2.2. Problem formulation,[0],[0]
",yK , and our goal is to estimate A.",2.2. Problem formulation,[0],[0]
"In the problem of dictionary learning, the maximum information that we can asymptotically try to retrieve from y1, . . .",3. Dictionary learning for SαS signals,[0],[0]
",yK is the exact distribution of y.",3. Dictionary learning for SαS signals,[0],[0]
"However, even if we knew y, identifying A is still not tractable in general— for instance, in the case of Gaussian vectors, A is only identifiable up to right-multiplication by a unitary matrix.",3. Dictionary learning for SαS signals,[0],[0]
"Moreover, obtaining an acceptable estimate of the distribution of y requires, in general, a vast amount of data and processing power (since it is a m-dimensional function with m possibly large).",3. Dictionary learning for SαS signals,[0],[0]
"In this section, we leverage the property of stability under linear combination of SαS random variables explained in Section 2.1 to propose a new algorithm to estimate A for the dictionary learning problem stated in Section 2.2.",3. Dictionary learning for SαS signals,[0],[0]
"Recall that, the random vector y (see Equations (2) and (6)) is an m-dimensional α-stable vector with characteristic function
p̂y(ω) = exp ( −γ‖A>ω‖αα ) (7)
for ω ∈ Rm.",3.1. New cost function for sparse SαS signals,[0],[0]
"Thus, knowing ‖A>u‖α for all u ∈ Sm−1, where Sm−1 is the (m− 1)-dimensional unit sphere, i.e.,
Sm−1 = {u ∈",3.1. New cost function for sparse SαS signals,[0],[0]
"Rm | ‖u‖2 = 1} , (8) is equivalent to knowing the distribution of y. Note that u",3.1. New cost function for sparse SαS signals,[0],[0]
>y = u,3.1. New cost function for sparse SαS signals,[0],[0]
>,3.1. New cost function for sparse SαS signals,[0],[0]
"Ax (see Equations (3) and (4)) is an SαS random variable with dispersion
γ(u) = γ‖A>u‖αα. (9) Thus, knowing the dispersion of the marginal distributions of y for all u ∈ Sm−1 is equivalent to knowing the distribution of y.",3.1. New cost function for sparse SαS signals,[0],[0]
"In other words, in the case of SαS random vectors, knowing their marginal dispersions is equivalent to knowing the Radon transform of their PDFs or, equivalently, their joint characteristic function (Helgason, 2010).",3.1. New cost function for sparse SαS signals,[0],[0]
"Due to the relationship between the Radon transform and the field of tomography, we call our algorithm sparse distribution tomography (SparsDT).
",3.1. New cost function for sparse SαS signals,[0],[0]
"Another interesting fact is that, in the non-Gaussian case (α < 2), knowing the marginal dispersions of y, i.e., γ(u), identifies the matrix A uniquely, up to negation and permutation of the columns.",3.1. New cost function for sparse SαS signals,[0],[0]
"Formally, we have the following theorem, which is proved in Appendix A:
Theorem 1 Let A be an m× n matrix where columns are pairwise linearly independent.",3.1. New cost function for sparse SαS signals,[0],[0]
"If α ∈ (0, 2) and B is an m× n matrix for which we have
‖A>u‖αα = ‖B>u‖αα (10) for all u ∈ Rm, then B is equal to A up to negation and permutation of its columns.
",3.1. New cost function for sparse SαS signals,[0],[0]
Remark 1,3.1. New cost function for sparse SαS signals,[0],[0]
"This theorem can be seen as a generalization of the result in (Rolewicz, 1985) that states that the isometries of `p-norms are generalized permutation matrices (permutation matrices with some of their rows negated).",3.1. New cost function for sparse SαS signals,[0],[0]
"To the best of our knowledge, this result is novel and could be of independent interest.
",3.1. New cost function for sparse SαS signals,[0],[0]
This theorem suggests that in order to find A all we need is to find γ(u) for u ∈ Rm.,3.1. New cost function for sparse SαS signals,[0],[0]
"Intuitively, we can say that as A has a finite number of parameters (entries), A is identifiable based on the knowledge of γ(u) for an appropriate finite set of vectors u = u1, . . .",3.1. New cost function for sparse SαS signals,[0],[0]
",uL (for some L ≥ mn).",3.1. New cost function for sparse SαS signals,[0],[0]
"We can then solve the set of non-linear equations
γ‖B>u1‖αα = γ(u1), ... (11) γ‖B>uL‖αα = γ(uL),
for B to obtain A.
Now, the problem is to find γ(u) for a given u ∈ Rm.",3.1. New cost function for sparse SαS signals,[0],[0]
Recall that γ(u) is the dispersion of the SαS random variable uTy.,3.1. New cost function for sparse SαS signals,[0],[0]
"As y1, . .",3.1. New cost function for sparse SαS signals,[0],[0]
.,3.1. New cost function for sparse SαS signals,[0],[0]
",yK are realizations of y, uTy1, . . .",3.1. New cost function for sparse SαS signals,[0],[0]
",uTyK are realizations of uTy.",3.1. New cost function for sparse SαS signals,[0],[0]
"There is a rich literature on the estimation of the parameters of α-stable random variables through their realizations, see, e.g, (Nikias & Shao, 1995).",3.1. New cost function for sparse SαS signals,[0],[0]
"We use the estimation from (Achim et al., 2015) in the following equation
log γ̂(u)",3.1. New cost function for sparse SαS signals,[0],[0]
"= α
K K∑ k=1 log |uTyk|",3.1. New cost function for sparse SαS signals,[0],[0]
"− (α− 1)ψ(1) (12)
where ψ is the digamma function (ψ(1) is the negative of the Euler-Mascheroni constant and is approximately 0.5572), and γ̂(u) denotes the estimation of γ(u).",3.1. New cost function for sparse SαS signals,[0],[0]
"Note that γ̂(u) tends to γ(u) when the number of observations, K, tends to infinity.",3.1. New cost function for sparse SαS signals,[0],[0]
"This means that we can obtain the exact value of γ(u) asymptotically.
",3.1. New cost function for sparse SαS signals,[0],[0]
"However, non-exact values for γ(u`), for ` = 1, . . .",3.1. New cost function for sparse SαS signals,[0],[0]
", L (which is the case when K is finite), can lead to the nonexistence of a solution for the system of equations (11).",3.1. New cost function for sparse SαS signals,[0],[0]
"To overcome this problem, instead of solving this system of equations exactly, we minimize the following objective function
E(B)",3.1. New cost function for sparse SαS signals,[0],[0]
"= 1 L L∑ `=1 d ( γ‖B>u`‖αα, γ̂(u`) )",3.1. New cost function for sparse SαS signals,[0],[0]
"(13)
= 1
αL L∑ `=1 ∣∣log(γ‖B>u`‖αα)− log(γ̂(u`))∣∣ where log γ̂(u1), . .",3.1. New cost function for sparse SαS signals,[0],[0]
.,3.1. New cost function for sparse SαS signals,[0],[0]
", log γ̂(uL) are L numbers calculated from (12).",3.1. New cost function for sparse SαS signals,[0],[0]
"The cost function d(a, b) = 1α | log a− log b| is a continuous positive function1 from R2 to R, whose global minimum is 0 and is reached over the line a = b.",3.1. New cost function for sparse SαS signals,[0],[0]
When γ̂(u),3.1. New cost function for sparse SαS signals,[0],[0]
"= γ(u), B = A minimizes E(B).",3.1. New cost function for sparse SαS signals,[0],[0]
"Thus, if γ̂(u) is close enough to γ(u), due to the continuity of d, we expect that the minimizer of E will be close to A. Therefore, our approach to dictionary learning is to solve
Â = argmin B E(B) (14)
= argmin B
1
αL L∑ `=1 ∣∣log (γ‖B>u`‖αα)− log γ̂(u`)∣∣ .",3.1. New cost function for sparse SαS signals,[0],[0]
The only parameter that needs to be set now is the stability parameter α.,3.1. New cost function for sparse SαS signals,[0],[0]
"Note that the dispersion parameter γ in Equation (14) does not need to be set as it will be automatically
1In our simulations we also implemented other natural candidates for d(a, b) and all of them gave approximately the same performance.",3.1. New cost function for sparse SαS signals,[0],[0]
"Due to the limited space, we do not present results for other cost functions.
merged into the learned dictionary.",3.1. New cost function for sparse SαS signals,[0],[0]
"Recall that there are well-known methods for estimating α from data; among which we use
α̂(u)",3.1. New cost function for sparse SαS signals,[0],[0]
"=
( 6
π2K K∑ k=1 ( log |u>yk| − log κ̂(u) )2",3.1. New cost function for sparse SαS signals,[0],[0]
− 1 2 ),3.1. New cost function for sparse SαS signals,[0],[0]
"− 12 (15)
from (Achim et al., 2015), where
log κ̂(u) = 1
K K∑ k=1 log |u>yk|.",3.1. New cost function for sparse SαS signals,[0],[0]
"(16)
",3.1. New cost function for sparse SαS signals,[0],[0]
This gives us an estimate for α for any given u ∈ Rm.,3.1. New cost function for sparse SαS signals,[0],[0]
"Hence, the estimated value of α is the average over all α̂(u`) for ` = 1, . . .",3.1. New cost function for sparse SαS signals,[0],[0]
", L, i.e.,
α̂ = 1
L L∑ `=1 α̂(u`).",3.1. New cost function for sparse SαS signals,[0],[0]
"(17)
Now, using this estimate, Equation (12) becomes
log γ̂(u)",3.1. New cost function for sparse SαS signals,[0],[0]
= α̂ log κ̂(u)− (α̂− 1)ψ(1).,3.1. New cost function for sparse SαS signals,[0],[0]
"(18)
We also replace α with α̂ in Equation (13) which results in a parameter-free cost function.",3.1. New cost function for sparse SαS signals,[0],[0]
This is in contrast with most existing cost functions that have parameters one must set.,3.1. New cost function for sparse SαS signals,[0],[0]
"To solve the minimization problem in Equation (14), we propose a variation on a gradient-descent algorithm with an adaptive step size that has a changing cost function.",3.2. Learning algorithm,[0],[0]
"To do so, we first derive the gradient of E at B. Using matrix calculus (see Appendix B), we find that
∇E(B) = (19)
1
αL L∑ `=1 sgn ( log(γ‖B>u`‖αα)− log γ̂(u`) ) ·",3.2. Learning algorithm,[0],[0]
"∇‖B >u`‖αα ‖B>u`‖αα
where sgn(·) is the sign function (i.e., sgn(e)",3.2. Learning algorithm,[0],[0]
= 1,3.2. Learning algorithm,[0],[0]
if e > 0,3.2. Learning algorithm,[0],[0]
and sgn(e) = 0,3.2. Learning algorithm,[0],[0]
otherwise),3.2. Learning algorithm,[0],[0]
"and
∇‖B>u‖αα = α  sgn ( b>1 u )",3.2. Learning algorithm,[0],[0]
"∣∣b>1 u∣∣α−1 u> ...
",3.2. Learning algorithm,[0],[0]
"sgn ( b>nu ) ∣∣b>nu∣∣α−1 u>  >
(20)
where bi is the ith column of B.
The cost function in Equation (13) is non-convex in B.",3.2. Learning algorithm,[0],[0]
"In order to avoid getting trapped in local minima, we iteratively change the cost function inside the gradient descent algorithm.",3.2. Learning algorithm,[0],[0]
"The idea is that instead of keeping u1, . . .",3.2. Learning algorithm,[0],[0]
",uL fixed throughout the optimization process, we regenerate them randomly with a uniform distribution on Rm after some
iterations of steepest descent.",3.2. Learning algorithm,[0],[0]
We repeat this process until convergence.,3.2. Learning algorithm,[0],[0]
"Note that (11) holds for any u1, . . .",3.2. Learning algorithm,[0],[0]
",uL and thus changing this set does not change the end result of (11).
",3.2. Learning algorithm,[0],[0]
Remark 2 Using this idea always results in convergence to the global minimum in our computer simulations.,3.2. Learning algorithm,[0],[0]
"A plausible explanation of this phenomenon is that each set of u1, . . .",3.2. Learning algorithm,[0],[0]
",uL yields a non-convex cost function with different local minima.",3.2. Learning algorithm,[0],[0]
Yet they all have the same global minimum.,3.2. Learning algorithm,[0],[0]
"Therefore, switching between them during the optimization process prevents getting trapped in any of the local minima, which ultimately results in finding the global minimum of the cost function.
",3.2. Learning algorithm,[0],[0]
The pseudocode of our dictionary learning method is given in Algorithm 1.,3.2. Learning algorithm,[0],[0]
"There, η is the step size of the gradient descent that increases or decreases by factors of κ+ or κ− upon taking a good or poor step.",3.2. Learning algorithm,[0],[0]
"The adaptive step size is especially helpful for α ≤ 1, where the cost function is not smooth.",3.2. Learning algorithm,[0],[0]
"The algorithm does not depend on the exact choice of convergence criteria.
",3.2. Learning algorithm,[0],[0]
Remark 3 Algorithm 1 can also be seen as an efficient method for estimating the spectral measure of stable random vectors.,3.2. Learning algorithm,[0],[0]
"In fact, the problem of estimating A from a set of realizations of y can also be seen as parameter estimation for a stable random vector y with a symmetric distribution around the origin.",3.2. Learning algorithm,[0],[0]
Such random vectors are parametrized by a measure Γ on Sm−1 that is called the spectral measure.,3.2. Learning algorithm,[0],[0]
"In our problem, we have Γ(·) = ∑n i=1",3.2. Learning algorithm,[0],[0]
‖ai‖α δai(·) where the δais are unit point masses at ai ‖ai‖2,3.2. Learning algorithm,[0],[0]
and ai is the i th column of A.,3.2. Learning algorithm,[0],[0]
"Some methods have been proposed to solve this problem, e.g., (Nolan et al., 2001).",3.2. Learning algorithm,[0],[0]
"However, they tend to be computationally intractable for dimensions greater than 3.
",3.2. Learning algorithm,[0],[0]
Remark 4,3.2. Learning algorithm,[0],[0]
"According to the generalized central limit theorem, under some mild conditions, the distribution of the sum of symmetric heavy-tailed random variables tends to a SαS distribution as the number of summands tends to infinity.",3.2. Learning algorithm,[0],[0]
This means that we can represent u>y = u>Ax with an SαS random variable for large enough n irrespective of the distribution of the xis provided that the latter are heavy tailed.,3.2. Learning algorithm,[0],[0]
"Therefore, we expect Algorithm 1 to find applications for other classes of sparse signals, provided that n is sufficiently large.",3.2. Learning algorithm,[0],[0]
"In this section, we analyze the performance of the proposed algorithm SparsDT and compare it with existing methods.",4. Empirical results,[0],[0]
Recall that the actual dictionary is A and the learned dictionary is Â.,4. Empirical results,[0],[0]
"We run two types of the experiments: We first test the algorithm on synthetic SαS data and then we test it on real images.
",4. Empirical results,[0],[0]
"Algorithm 1 SparseDT 1: initialize: η > 0 2: initialize: κ+ ≥ 1 and κ− ≤ 1 3: initialize: generate b1, . . .",4. Empirical results,[0],[0]
", bn ∼ N (0, Im×m) and
B← [ b1| . . .",4. Empirical results,[0],[0]
"|bn ] 4: repeat 5: initialize: generate u1, . . .",4. Empirical results,[0],[0]
",uL ∼ N (0, Im×m) 6: estimate α̂ from (15) 7: E ← E(B) 8: repeat 9:",4. Empirical results,[0],[0]
Bold ← B 10:,4. Empirical results,[0],[0]
Eold ← E 11: B← B− η ∇E(B) 12: E ← E(B) 13: if E ≤,4. Empirical results,[0],[0]
"Eold then 14: η ← κ+ · η 15: else 16: B← Bold 17: E ← Eold 18: η ← κ− · η 19: end if 20: until B converges (for this choice of u1, . . .",4. Empirical results,[0],[0]
",uL) 21: until B converges
return B",4. Empirical results,[0],[0]
We compare our algorithm with three commonly used algorithms that are available in the Python package SPAMS2.,4.1. Benchmarks,[0],[0]
"These constrained optimization problems3 are as follows:
1.",4.1. Benchmarks,[0],[0]
"`2/`1: Maximizing the data fidelity while controling the sparsity of representation with parameter λ1:
Â`2/`1 = argmin B
1
2K K∑ k=1 ‖yk −Bxk‖22
s.t. ‖xi‖1 ≤ λ1.
2.",4.1. Benchmarks,[0],[0]
"`1/`2: Maximizing the sparsity of representation while controling the data fidelity with parameter λ2:
Â`1/`2 = argmin B
1
2K K∑ k=1 ‖xk‖1
s.t. ‖yk −Bxk‖2 ≤ λ2.
3.",4.1. Benchmarks,[0],[0]
"`1 + `2: Combining sparsity and data fidelity in the cost function using Lagrange multipliers:
Â`1+`2 = argmin B
1
2K K∑ k=1 ‖yk −Bxk‖22
+ λ3‖xk‖1 + λ4‖xk‖22.",4.1. Benchmarks,[0],[0]
"2http://spams-devel.gforge.inria.fr/ 3Other cost functions are also available in the package SPAMS,
but those retained here yield the best results in our experiments.
",4.1. Benchmarks,[0],[0]
"One of the challenges in utilizing these benchmarks is determining the regularization parameters λ1, . . .",4.1. Benchmarks,[0],[0]
", λ4.",4.1. Benchmarks,[0],[0]
"In our experiments, the regularization parameters are optimized (by grid search) in order to maximize the performance of each of the benchmarks above.",4.1. Benchmarks,[0],[0]
"This is in contrast to our algorithm, which has no regularization parameter to tune.",4.1. Benchmarks,[0],[0]
We first test the algorithms on synthetic data.,4.2. Experimental results for synthetic data,[0],[0]
"In order to quantify the performance of the algorithms, we use several metrics.",4.2. Experimental results for synthetic data,[0],[0]
One is the average correlation of the dictionaries.,4.2. Experimental results for synthetic data,[0],[0]
"Specifically, we calculate the correlation between all columns of Â and A, and then match each column of Â with one of the columns of A (a one-to-one map) such that the average correlation between the corresponding columns is maximized.",4.2. Experimental results for synthetic data,[0],[0]
"Additionally, we say that the dictionary is found if the average correlation of the columns is larger than 0.97.
",4.2. Experimental results for synthetic data,[0],[0]
Effect of K: We demonstrate the effect of the number of samples K on the performance of our proposed algorithm SparsDT.,4.2. Experimental results for synthetic data,[0],[0]
"Intuitively, the precision of the estimation increases with the number of samples K, and, as K goes to infinity, the estimation error goes to zero, which ultimately gives the exact A. We demonstrate this effect with the following experiment: We take m = 16, n = 24 and α = 1 and 1.5.",4.2. Experimental results for synthetic data,[0],[0]
"Then, for each K, we run the experiment for 50 random matrices A, and, for each case, we run Algorithm 1 with both exact and estimated α (from (17)).",4.2. Experimental results for synthetic data,[0],[0]
"The results are depicted in Figure 2, where the vertical axis is the average correlation of the estimated dictionary with the exact one, and the horizontal axis is the number of samples K. Interestingly, the performance of the algorithm is almost the same when using the exact or estimated value of α, which suggests that the estimator of α is robust and accurate.",4.2. Experimental results for synthetic data,[0],[0]
"Moreover, we see that the average correlation is an increasing function of K, as expected.",4.2. Experimental results for synthetic data,[0],[0]
"Also note that the convergence is faster for α = 1, which corresponds to the setting with more sparsity.
",4.2. Experimental results for synthetic data,[0],[0]
"Comparison metrics
Algorithm % found Avg. time (s)
",4.2. Experimental results for synthetic data,[0],[0]
"Comparison against benchmarks: We compare SparsDT against the `2/`1, `1/`2 and `1 + `2 methods described above.",4.2. Experimental results for synthetic data,[0],[0]
"We compare the algorithms with regard to their success rate (i.e., the percentage of the dictionaries found by the algorithm), and the time that they take to find the dictionary (in the cases of success only).",4.2. Experimental results for synthetic data,[0],[0]
"We again take m = 16, n = 24 and generate 100 random matrices A.",4.2. Experimental results for synthetic data,[0],[0]
"In Table 1, the results for α = 1.2 and K = 500 are given.",4.2. Experimental results for synthetic data,[0],[0]
"Finally, in Figure 3 we compare the algorithms success rate for different α, we take m = 16, n = 24, and K = 1000.",4.2. Experimental results for synthetic data,[0],[0]
These results indicate that SparsDT outperforms the other methods in the rate of success.,4.2. Experimental results for synthetic data,[0],[0]
"Also, its average learning time is typically much less than the others, except for `2/`1 which does not find the correct dictionary at best in 10% of the time.",4.2. Experimental results for synthetic data,[0],[0]
The range of α that was observed in our experiments is α ∈,4.2. Experimental results for synthetic data,[0],[0]
"[1, 1.6], which is also the range where our algorithm works well and which is interesting for many applications including image processing.",4.2. Experimental results for synthetic data,[0],[0]
We do not recommend using the method for α > 1.7 because the convergence properties degrade as we get closer to 2 (a larger value of K is then needed to reach high success rates).,4.2. Experimental results for synthetic data,[0],[0]
"Since images often have sparse representations, we apply our algorithm to problems in image processing applications.",4.3. Experimental results for real images,[0],[0]
"Our experiments are missing pixel recovery (in-painting) and denoising, based on dictionary learning.",4.3. Experimental results for real images,[0],[0]
"We use a
Algorithm PSNR (dB)
database of face images provided by AT&T4 and crop them to have size 112 × 91",4.3. Experimental results for real images,[0],[0]
"so we can chop each image to 208 patches of size 7× 7, which correspond to yi in our model.
",4.3. Experimental results for real images,[0],[0]
"In this situation, the data is not exactly SαS, so we must adapt our choice of u in Step 5 of Algorithm 1.",4.3. Experimental results for real images,[0],[0]
"Specifically, in Equation (17) we eliminate projection vectors u that result in α greater than 2 (as α is required to be less than 2).",4.3. Experimental results for real images,[0],[0]
"In addition, we only select u that results in an α close to our estimated α̂ in (17).",4.3. Experimental results for real images,[0],[0]
"The number of iterations are chosen such that all algorithms converge.
",4.3. Experimental results for real images,[0],[0]
Missing pixel recovery:,4.3. Experimental results for real images,[0],[0]
"In this experiment, we reconstruct an image from 50% of its pixels.",4.3. Experimental results for real images,[0],[0]
"We take out the image shown in Figure 4, remove 50% of its pixels uniformly at random, and learn the dictionary using the patches of the other images in the collection.",4.3. Experimental results for real images,[0],[0]
We assume 248 atoms in the dictionary.,4.3. Experimental results for real images,[0],[0]
"Then, using the learned dictionary, we reconstruct the image using orthogonal matching pursuit (for a detailed analysis see (Sahoo & Makur, 2015)).",4.3. Experimental results for real images,[0],[0]
"The results for different dictionary learning methods are depicted in Figure 4; SparsDT outperforms existing methods both visually and in term of PSNR.
",4.3. Experimental results for real images,[0],[0]
"Image denoising: In this experiment, we use the dictionaries learned in the previous experiment to denoise the image in Figure 4.",4.3. Experimental results for real images,[0],[0]
"More precisely, we add Gaussian noise with standard deviation 10 to the original image and use orthogonal matching pursuit to denoise it.",4.3. Experimental results for real images,[0],[0]
The performance of each method in PSNR can be seen in Table 2.,4.3. Experimental results for real images,[0],[0]
"As we see, SparsDT outperforms the other methods by at least 0.6 dB.",4.3. Experimental results for real images,[0],[0]
"In this paper, we consider a stochastic generation model of sparse signals that involves an SαS innovation.",5. Summary and future work,[0],[0]
"Then, by designing an estimator of the spectral measure of so-defined stable random vectors, we propose a new dictionary learning algorithm.",5. Summary and future work,[0],[0]
"The proposed algorithm (SparsDT) turns out to be quite robust; it works well on sparse real-world signals, even when these do not rigorously follow the SαS model.",5. Summary and future work,[0],[0]
This surprising fact can be explained by invoking the generalized central limit theorem.,5. Summary and future work,[0],[0]
"We validate SparsDT on several image-processing tasks and found it to outperform popular dictionary learning methods often significantly.
",5. Summary and future work,[0],[0]
"4www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html
Moreover, SparsDT has no parameter to tune, contrary to other algorithms.
",5. Summary and future work,[0],[0]
Extending this work to non-symmetric α-stable random variables is a possible direction of future research.,5. Summary and future work,[0],[0]
"Given the excellent numerical behavior of the algorithm, it is of interest to get a good handle on the accuracy of the estimation in terms of the number of samples and the dimensionality of signals.",5. Summary and future work,[0],[0]
"Denote the jth column of A and B by aj and bj , respectively.",A. Proof of Theorem 1,[0],[0]
"Also, denote the set of indices j for which bj 6= 0 by B ⊆ {1, . . .",A. Proof of Theorem 1,[0],[0]
", n}.",A. Proof of Theorem 1,[0],[0]
"Note that due to the assumption of the pairwise linear independence of columns of A, aj 6= 0 for all j ∈ {1, . . .",A. Proof of Theorem 1,[0],[0]
", n}.",A. Proof of Theorem 1,[0],[0]
"Since
∥∥A>u∥∥α α = n∑ j=1 ∣∣u>aj∣∣α = ∑ j∈B ∣∣u>bj∣∣α = ∥∥B>u∥∥αα .",A. Proof of Theorem 1,[0],[0]
"for all u ∈ Rm, the partial derivatives of any order of the two side of the equation are also equal.",A. Proof of Theorem 1,[0],[0]
"In particular, we have
∂d
∂ui d
∥∥A>u∥∥α α = ∂d
∂ui d
∥∥B>u∥∥α α
(21)
for all i = 1, . . .",A. Proof of Theorem 1,[0],[0]
",m and d ∈ N, where ui is the ith entry of u.
First we prove the theorem for 0 < α ≤ 1.",A. Proof of Theorem 1,[0],[0]
"In (21), we set d = 1 and obtain
n∑ j=1 ∣∣u>aj∣∣α−1 sgn (u>aj) aij = ∑ j∈B
∣∣u>bj∣∣α−1 sgn (u>bj) bij .",A. Proof of Theorem 1,[0],[0]
"(22) Exploiting this equation, we prove the following lemma:
Lemma 1",A. Proof of Theorem 1,[0],[0]
"Under the assumptions of Theorem 1, for any j′ ∈ {1, . . .",A. Proof of Theorem 1,[0],[0]
", n}, there exists j ∈ B and tj′ 6= 0, such that tj′aj′ = bj .
",A. Proof of Theorem 1,[0],[0]
Proof: Take i′ such that ai′j′ 6= 0.,A. Proof of Theorem 1,[0],[0]
"Also, for all r = 1, . . .",A. Proof of Theorem 1,[0],[0]
", n, define
Kar = { u ∈ Rm|u",A. Proof of Theorem 1,[0],[0]
>,A. Proof of Theorem 1,[0],[0]
"ar = 0 } (23)
which is an (m − 1)-dimensional subspace of Rm.",A. Proof of Theorem 1,[0],[0]
"Since for any j 6= j′, aj′ and aj are linearly independent, the subspace Kaj′ ∩ Kaj is (m − 2)-dimensional.",A. Proof of Theorem 1,[0],[0]
This implies that their (m− 1)-dimensional Lebesgue measure is zero; and the same holds for the union ⋃ j 6=j′ ( Kaj′ ∩ Kaj ) .,A. Proof of Theorem 1,[0],[0]
"Since
Kaj′ \",A. Proof of Theorem 1,[0],[0]
⋃ j 6=j′ Kaj = Kaj′ \,A. Proof of Theorem 1,[0],[0]
"⋃ j 6=j′ ( Kaj′ ∩ Kaj ) , (24)
we conclude that the (m− 1)-dimensional Lebesgue measure of Kaj′ \",A. Proof of Theorem 1,[0],[0]
"⋃ j 6=j′ Kaj is infinity.
",A. Proof of Theorem 1,[0],[0]
Note that any u ∈ Kaj′ \,A. Proof of Theorem 1,[0],[0]
⋃ j 6=j′ Kaj is only orthogonal to aj′ and not to any other column of A.,A. Proof of Theorem 1,[0],[0]
"This yields that if we set i = i′ in the left-hand side of (22), for any u ∈ Kaj′ \",A. Proof of Theorem 1,[0],[0]
"⋃ j 6=j′ Kaj , the only discontinuous term at u is the j′th one (because the function |x|α−1sgn(x) has a single point of discontinuity at x = 0).",A. Proof of Theorem 1,[0],[0]
"As a result, the sum itself is discontinuous over Kaj′ \",A. Proof of Theorem 1,[0],[0]
⋃ j 6=j′ Kaj .,A. Proof of Theorem 1,[0],[0]
"Hence, the same should hold for the right-hand side of the equation.
",A. Proof of Theorem 1,[0],[0]
"Similar to (23), define Kbr = { u ∈ Rm|u",A. Proof of Theorem 1,[0],[0]
>,A. Proof of Theorem 1,[0],[0]
br = 0 } .,A. Proof of Theorem 1,[0],[0]
"(25)
The set of discontinuity points of the right-hand side of (22) is a subset of ⋃ j∈B Kbj .",A. Proof of Theorem 1,[0],[0]
"Therefore, we have
Kaj′ \",A. Proof of Theorem 1,[0],[0]
⋃ j 6=j′ Kaj ⊆,A. Proof of Theorem 1,[0],[0]
"⋃ j∈B Kbj (26)
which can also be written as Kaj′ \",A. Proof of Theorem 1,[0],[0]
⋃ j 6=j′ Kaj ⊆ ⋃ j∈B,A. Proof of Theorem 1,[0],[0]
"( Kaj′ ∩ Kbj ) (27)
",A. Proof of Theorem 1,[0],[0]
"Now, if none of the columns of B is linearly dependent to aj′ , all Kaj′ ∩ Kbj will be (m− 2)-dimensional spaces, and their (m− 1)-dimesnional Lebesgue measure is zero.",A. Proof of Theorem 1,[0],[0]
"This implies that the (m− 1)-dimensional Lebesgue measure of the right-hand side of (27) is also zero, which contradicts the result after (24).",A. Proof of Theorem 1,[0],[0]
"Therefore, there exists a j ∈ B such that bj is linearly dependent to aj′ , which completes the proof of the lemma.
",A. Proof of Theorem 1,[0],[0]
"The first consequence of Lemma 1 is that none of the columns of B is the zero vector and thus B = {1, . . .",A. Proof of Theorem 1,[0],[0]
", n}.
",A. Proof of Theorem 1,[0],[0]
"Also, since all pairs of columns of A are linearly independent, the correspondence between a column of A and a column of B that are linearly dependent is one-to-one.",A. Proof of Theorem 1,[0],[0]
"Thus, we can simplify (22) to be
n∑ j=1 (1− |tj |)",A. Proof of Theorem 1,[0],[0]
"∣∣u>aj∣∣α−1 sgn (u>aj) aij = 0, (28)
which holds for all u.",A. Proof of Theorem 1,[0],[0]
This implies that the left hand-side of the above equation is a continuous function.,A. Proof of Theorem 1,[0],[0]
"However, as we saw in the proof of the lemma, every u ∈ Kaj′ \",A. Proof of Theorem 1,[0],[0]
"⋃ j 6=j′ Kaj is a discontinuity point of the left-hand unless 1− |t′j | = 0 which completes the proof for the case of 0 < α ≤ 1.
",A. Proof of Theorem 1,[0],[0]
"For the case of 1 < α < 2, we set d = 2 in (21) and obtain n∑ j=1 ∣∣u>aj∣∣α−2 a2ij = n∑ j=1 ∣∣u>bj∣∣α−2 b2ij .",A. Proof of Theorem 1,[0],[0]
"(29) Replacing (22) by (29), the same reasoning as for 0 < α",A. Proof of Theorem 1,[0],[0]
≤,A. Proof of Theorem 1,[0],[0]
1,A. Proof of Theorem 1,[0],[0]
"works to prove the theorem for 1 < α < 2.
",A. Proof of Theorem 1,[0],[0]
B. Derivation of the gradient of E(B),A. Proof of Theorem 1,[0],[0]
"To calculate the gradient of E(B), we first calculate the gradient of ‖B>u‖αα using the definition of the gradient, i.e.
〈∇‖B>u‖αα,C〉 = ∂
∂
∥∥(B> − C>)u∥∥α α ∣∣∣ =0
= α n∑ j=1 c>j u sgn ( b>j u )",A. Proof of Theorem 1,[0],[0]
∣∣b>j u∣∣α−1 .,A. Proof of Theorem 1,[0],[0]
"Here, 〈D,C〉 = tr(D>C) is the standard inner product on the space of matrices.",A. Proof of Theorem 1,[0],[0]
"Writing the last equation in the matrix form, we obtain (20).",A. Proof of Theorem 1,[0],[0]
"Now, using the fact ddx |log",A. Proof of Theorem 1,[0],[0]
x|,A. Proof of Theorem 1,[0],[0]
= sgn(log x) 1x and the chain rule for differentiation yields (19).,A. Proof of Theorem 1,[0],[0]
"The research was partially supported by the Hasler Foundation under Grant 16009, by the European Research Council under Grant 692726 (H2020-ERC Project GlobalBioIm) and by the SNF Project Grant (205121 163385).",Acknowledgements,[0],[0]
We propose a new statistical dictionary learning algorithm for sparse signals that is based on an α-stable innovation model.,abstractText,[0],[0]
"The parameters of the underlying model—that is, the atoms of the dictionary, the sparsity index α and the dispersion of the transform-domain coefficients—are recovered using a new type of probability distribution tomography.",abstractText,[0],[0]
"Specifically, we drive our estimator with a series of random projections of the data, which results in an efficient algorithm.",abstractText,[0],[0]
"Moreover, since the projections are achieved using linear combinations, we can invoke the generalized central limit theorem to justify the use of our method for sparse signals that are not necessarily α-stable.",abstractText,[0],[0]
We evaluate our algorithm by performing two types of experiments: image inpainting and image denoising.,abstractText,[0],[0]
"In both cases, we find that our approach is competitive with stateof-the-art dictionary learning techniques.",abstractText,[0],[0]
"Beyond the algorithm itself, two aspects of this study are interesting in their own right.",abstractText,[0],[0]
"The first is our statistical formulation of the problem, which unifies the topics of dictionary learning and independent component analysis.",abstractText,[0],[0]
The second is a generalization of a classical theorem about isometries of `p-norms that constitutes the foundation of our approach.,abstractText,[0],[0]
Dictionary Learning Based on Sparse Distribution Tomography,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1896–1906 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1896",text,[0],[0]
"Recently, deep learning has been applied to a variety of question answering tasks.",1 Introduction,[0],[0]
"For instance, to answer questions about images (e.g. (Kazemi and Elqursh, 2017)), tabular data (e.g. (Neelakantan et al., 2017)), and passages of text (e.g. (Yu et al., 2018)).",1 Introduction,[0],[0]
"Developers, end-users, and reviewers (in academia) would all like to understand the capabilities of these models.
",1 Introduction,[0],[0]
The standard way of measuring the goodness of a system is to evaluate its error on a test set.,1 Introduction,[0],[0]
High accuracy is indicative of a good model only if the test set is representative of the underlying realworld task.,1 Introduction,[0],[0]
"Most tasks have large test and training sets, and it is hard to manually check that they are representative of the real world.
",1 Introduction,[0],[0]
"In this paper, we propose techniques to analyze the sensitivity of a deep learning model to question words.",1 Introduction,[0],[0]
"We do this by applying attribution (as discussed in section 3), and generating adversarial questions.",1 Introduction,[0],[0]
"Here is an illustrative example: recall Visual Question Answering (Agrawal et al., 2015) where the task is to answer questions about images.",1 Introduction,[0],[0]
Consider the question “how symmetrical are the white bricks on either side of the building?”,1 Introduction,[0],[0]
(corresponding image in Figure 1).,1 Introduction,[0],[0]
The system that we study gets the answer right (“very”).,1 Introduction,[0],[0]
"But, we find (using an attribution approach) that the system relies on only a few of the words like “how” and “bricks”.",1 Introduction,[0],[0]
"Indeed, we can construct adversarial questions about the same image that the system gets wrong.",1 Introduction,[0],[0]
"For instance, “how spherical are the white bricks on either side of the building?” returns the same answer (“very”).",1 Introduction,[0],[0]
A key premise of our work is that most humans have expertise in question answering.,1 Introduction,[0],[0]
"Even if they cannot manually check that a dataset is representative of the real world, they can identify important question words, and anticipate their function in question answering.",1 Introduction,[0],[0]
We follow an analysis workflow to understand three question answering models.,1.1 Our Contributions,[0],[0]
There are two steps.,1.1 Our Contributions,[0],[0]
"First, we apply Integrated Gradients (henceforth, IG) (Sundararajan et al., 2017) to attribute the systems’ predictions to words in the questions.",1.1 Our Contributions,[0],[0]
We propose visualizations of attributions to make analysis easy.,1.1 Our Contributions,[0],[0]
"Second, we identify weaknesses (e.g., relying on unimportant words) in the networks’ logic as exposed by the attributions, and leverage them to craft adversarial questions.
",1.1 Our Contributions,[0],[0]
A key contribution of this work is an overstability test for question answering networks.,1.1 Our Contributions,[0],[0]
Jia and Liang (2017) showed that reading comprehension networks are overly stable to semantics-altering edits to the passage.,1.1 Our Contributions,[0],[0]
"In this work, we find that
such overstability also applies to questions.",1.1 Our Contributions,[0],[0]
"Furthermore, this behavior can be seen in visual and tabular question answering networks as well.",1.1 Our Contributions,[0],[0]
We use attributions to a define a general-purpose test for measuring the extent of the overstability (sections 4.3 and 5.3).,1.1 Our Contributions,[0],[0]
"It involves measuring how a network’s accuracy changes as words are systematically dropped from questions.
",1.1 Our Contributions,[0],[0]
"We emphasize that, in contrast to modelindependent adversarial techniques such as that of Jia and Liang (2017), our method exploits the strengths and weaknesses of the model(s) at hand.",1.1 Our Contributions,[0],[0]
This allows our attacks to have a high success rate.,1.1 Our Contributions,[0],[0]
"Additionally, using insights derived from attributions we were able to improve the attack success rate of Jia and Liang (2017) (section 6.2).",1.1 Our Contributions,[0],[0]
"Such extensive use of attributions in crafting adversarial examples is novel to the best of our knowledge.
",1.1 Our Contributions,[0],[0]
"Next, we provide an overview of our results.",1.1 Our Contributions,[0],[0]
"In each case, we evaluate a pre-trained model on new inputs.",1.1 Our Contributions,[0],[0]
"We keep the networks’ parameters intact.
",1.1 Our Contributions,[0],[0]
Visual QA (section 4): The task is to answer questions about images.,1.1 Our Contributions,[0],[0]
We analyze the deep network in Kazemi and Elqursh (2017).,1.1 Our Contributions,[0],[0]
"We find that the network ignores many question words, relying largely on the image to produce answers.",1.1 Our Contributions,[0],[0]
"For instance, we show that the model retains more than 50% of its original accuracy even when every word that is not “color” is deleted from all questions in the validation set.",1.1 Our Contributions,[0],[0]
"We also show that the model under-relies on important question words (e.g. nouns) and attaching contentfree prefixes (e.g., “in not many words, . . .”) to questions drops the accuracy from 61.1% to 19%.
",1.1 Our Contributions,[0],[0]
"QA on tables (section 5): We analyze a system called Neural Programmer (henceforth, NP) (Neelakantan et al., 2017) that answers questions on tabular data.",1.1 Our Contributions,[0],[0]
NP determines the answer to a question by selecting a sequence of operations to apply on the accompanying table (akin to an SQL query; details in section 5).,1.1 Our Contributions,[0],[0]
"We find that these operation selections are more influenced by content-free words (e.g., “in”, “at”, “the”, etc.) in questions than important words such as nouns or adjectives.",1.1 Our Contributions,[0],[0]
Dropping all content-free words reduces the validation accuracy of the network from 33.5%1 to 28.5%.,1.1 Our Contributions,[0],[0]
"Similar to Visual QA, we
1This is the single-model accuracy that we obtained on training the Neural Programmer network.",1.1 Our Contributions,[0],[0]
"The accuracy reported in the paper is 34.1%.
",1.1 Our Contributions,[0],[0]
"show that attaching content-free phrases (e.g., “in not a lot of words”) to the question drops the network’s accuracy from 33.5% to 3.3%.",1.1 Our Contributions,[0],[0]
We also find that NP often gets the answer right for the wrong reasons.,1.1 Our Contributions,[0],[0]
"For instance, for the question “which nation earned the most gold medals?”, one of the operations selected by NP is “first” (pick the first row of the table).",1.1 Our Contributions,[0],[0]
Its answer is right only because the table happens to be arranged in order of rank.,1.1 Our Contributions,[0],[0]
We quantify this weakness by evaluating NP on the set of perturbed tables generated by Pasupat and Liang (2016) and find that its accuracy drops from 33.5% to 23%.,1.1 Our Contributions,[0],[0]
"Finally, we show an extreme form of overstability where the table itself induces a large bias in the network regardless of the question.",1.1 Our Contributions,[0],[0]
"For instance, we found that in tables about Olympic medal counts, NP was predisposed to selecting the “prev” operator.
",1.1 Our Contributions,[0],[0]
Reading comprehension (Section 6):,1.1 Our Contributions,[0],[0]
The task is to answer questions about paragraphs of text.,1.1 Our Contributions,[0],[0]
We analyze the network by Yu et al. (2018).,1.1 Our Contributions,[0],[0]
"Again, we find that the network often ignores words that should be important.",1.1 Our Contributions,[0],[0]
"Jia and Liang (2017) proposed attacks wherein sentences are added to paragraphs that ought not to change the network’s answers, but sometimes do.",1.1 Our Contributions,[0],[0]
Our main finding is that these attacks are more likely to succeed when an added sentence includes all the question words that the model found important (for the original paragraph).,1.1 Our Contributions,[0],[0]
"For instance, we find that attacks are 50% more likely to be successful when the added sentence includes top-attributed nouns in the question.",1.1 Our Contributions,[0],[0]
"This insight should allow the construction of more successful attacks and better training data sets.
",1.1 Our Contributions,[0],[0]
"In summary, we find that all networks ignore important parts of questions.",1.1 Our Contributions,[0],[0]
"One can fix this by either improving training data, or introducing an inductive bias.",1.1 Our Contributions,[0],[0]
Our analysis workflow is helpful in both cases.,1.1 Our Contributions,[0],[0]
It would also make sense to expose end-users to attribution visualizations.,1.1 Our Contributions,[0],[0]
"Knowing which words were ignored, or which operations the words were mapped to, can help the user decide whether to trust a system’s response.",1.1 Our Contributions,[0],[0]
We are motivated by Jia and Liang (2017).,2 Related Work,[0],[0]
"As they discuss, “the extent to which [reading comprehension systems] truly understand language remains unclear”.",2 Related Work,[0],[0]
"The contrast between Jia and Liang
(2017) and our work is instructive.",2 Related Work,[0],[0]
Their main contribution is to fix the evaluation of reading comprehension systems by augmenting the test set with adversarially constructed examples.,2 Related Work,[0],[0]
"(As they point out in Section 4.6 of their paper, this does not necessarily fix the model; the model may simply learn to circumvent the specific attack underlying the adversarial examples.)",2 Related Work,[0],[0]
Their method is independent of the specification of the model at hand.,2 Related Work,[0],[0]
"They use crowdsourcing to craft passage perturbations intended to fool the network, and then query the network to test their effectiveness.
",2 Related Work,[0],[0]
"In contrast, we propose improving the analysis of question answering systems.",2 Related Work,[0],[0]
Our method peeks into the logic of a network to identify highattribution question terms.,2 Related Work,[0],[0]
"Often there are several important question terms (e.g., nouns, adjectives) that receive tiny attribution.",2 Related Work,[0],[0]
We leverage this weakness and perturb questions to craft targeted attacks.,2 Related Work,[0],[0]
"While Jia and Liang (2017) focus exclusively on systems for the reading comprehension task, we analyze one system each for three different tasks.",2 Related Work,[0],[0]
Our method also helps improve the efficacy Jia and Liang (2017)’s attacks; see table 4 for examples.,2 Related Work,[0],[0]
"Our analysis technique is specific to deep-learning-based systems, whereas theirs is not.
",2 Related Work,[0],[0]
"We could use many other methods instead of Integrated Gradients (IG) to attribute a deep network’s prediction to its input features (Baehrens et al., 2010; Simonyan et al., 2013; Shrikumar et al., 2016; Binder et al., 2016; Springenberg et al., 2014).",2 Related Work,[0],[0]
One could also use model agnostic techniques like Ribeiro et al. (2016b).,2 Related Work,[0],[0]
"We choose IG for its ease and efficiency of implementation (requires just a few gradient-calls) and its axiomatic justification (see Sundararajan et al. (2017) for a detailed comparison with other attribution methods).
",2 Related Work,[0],[0]
"Recently, there have been a number of techniques for crafting and defending against adversarial attacks on image-based deep learning models (cf. Goodfellow et al. (2015)).",2 Related Work,[0],[0]
"They are based on oversensitivity of models, i.e., tiny, imperceptible perturbations of the image to change a model’s response.",2 Related Work,[0],[0]
"In contrast, our attacks are based on models’ over-reliance on few question words even when other words should matter.
",2 Related Work,[0],[0]
We discuss task-specific related work in corresponding sections (sections 4 to 6).,2 Related Work,[0],[0]
"We employ an attribution technique called Integrated Gradients (IG) (Sundararajan et al., 2017) to isolate question words that a deep learning system uses to produce an answer.
",3 Integrated Gradients (IG),[0],[0]
"Formally, suppose a function F : Rn !",3 Integrated Gradients (IG),[0],[0]
"[0, 1] represents a deep network, and an input x =",3 Integrated Gradients (IG),[0],[0]
"(x1, . . .",3 Integrated Gradients (IG),[0],[0]
", xn) 2 Rn.",3 Integrated Gradients (IG),[0],[0]
"An attribution of the prediction at input x relative to a baseline input x0 is a vector AF (x, x0)",3 Integrated Gradients (IG),[0],[0]
=,3 Integrated Gradients (IG),[0],[0]
"(a1, . . .",3 Integrated Gradients (IG),[0],[0]
", an) 2 Rn where ai is the contribution of xi to the prediction F (x).",3 Integrated Gradients (IG),[0],[0]
One can think of F as the probability of a specific response.,3 Integrated Gradients (IG),[0],[0]
"x1, . . .",3 Integrated Gradients (IG),[0],[0]
", xn are the question words; to be precise, they are going to be vector representations of these terms.",3 Integrated Gradients (IG),[0],[0]
"The attributions a1, . . .",3 Integrated Gradients (IG),[0],[0]
", an are the influences/blame-assignments to the variables x1, . . .",3 Integrated Gradients (IG),[0],[0]
", xn on the probability F .
Notice that attributions are defined relative to a special, uninformative input called the baseline.",3 Integrated Gradients (IG),[0],[0]
"In this paper, we use an empty question as the baseline, that is, a sequence of word embeddings corresponding to padding value.",3 Integrated Gradients (IG),[0],[0]
"Note that the context (image, table, or passage) of the baseline x0 is set to be that of x; only the question is set to empty.",3 Integrated Gradients (IG),[0],[0]
"We now describe how IG produces attributions.
",3 Integrated Gradients (IG),[0],[0]
"Intuitively, as we interpolate between the baseline and the input, the prediction moves along a trajectory, from uncertainty to certainty (the final probability).",3 Integrated Gradients (IG),[0],[0]
"At each point on this trajectory, one can use the gradient of the function F with respect to the input to attribute the change in probability back to the input variables.",3 Integrated Gradients (IG),[0],[0]
"IG simply aggregates the gradients of the probability with respect to the input along this trajectory using a path integral.
",3 Integrated Gradients (IG),[0],[0]
Definition 1 (Integrated Gradients),3 Integrated Gradients (IG),[0],[0]
"Given an input x and baseline x0, the integrated gradient along the ith dimension is defined as follows.
",3 Integrated Gradients (IG),[0],[0]
"IGi(x, x 0)",3 Integrated Gradients (IG),[0],[0]
"::= (xi x0i)⇥
Z 1
↵=0
@F (x0+↵⇥(x x0))",3 Integrated Gradients (IG),[0],[0]
"@xi d↵
(here @F (x) @xi is the gradient of F along the ith dimension at x).
",3 Integrated Gradients (IG),[0],[0]
Sundararajan et al. (2017) discuss several properties of IG.,3 Integrated Gradients (IG),[0],[0]
"Here, we informally mention a few desirable ones, deferring the reader to Sundararajan et al. (2017) for formal definitions.
",3 Integrated Gradients (IG),[0],[0]
"IG satisfies the condition that the attributions sum to the difference between the probabilities at
the input and the baseline.",3 Integrated Gradients (IG),[0],[0]
"We call a variable uninfluential if all else fixed, varying it does not change the output probability.",3 Integrated Gradients (IG),[0],[0]
IG satisfies the property that uninfluential variables do not get any attribution.,3 Integrated Gradients (IG),[0],[0]
"Conversely, influential variables always get some attribution.",3 Integrated Gradients (IG),[0],[0]
Attributions for a linear combination of two functions F1 and F2 are a linear combination of the attributions for F1 and F2.,3 Integrated Gradients (IG),[0],[0]
"Finally, IG satisfies the condition that symmetric variables get equal attributions.
",3 Integrated Gradients (IG),[0],[0]
"In this work, we validate the use of IG empirically via question perturbations.",3 Integrated Gradients (IG),[0],[0]
We observe that perturbing high-attribution terms changes the networks’ response (sections 4.4 and 5.5).,3 Integrated Gradients (IG),[0],[0]
"Conversely, perturbing terms that receive a low attribution does not change the network’s response (sections 4.3 and 5.3).",3 Integrated Gradients (IG),[0],[0]
"We use these observations to craft attacks against the network by perturbing instances where generic words (e.g., “a”, “the”) receive high attribution or contentful words receive low attribution.",3 Integrated Gradients (IG),[0],[0]
"The Visual Question Answering Task (Agrawal et al., 2015; Teney et al., 2017; Kazemi and Elqursh, 2017; Ben-younes et al., 2017; Zhu et al., 2016) requires a system to answer questions about images (fig. 1).","4.1 Task, model, and data",[0],[0]
We analyze the deep network from Kazemi and Elqursh (2017).,"4.1 Task, model, and data",[0],[0]
"It achieves 61.1% accuracy on the validation set (the state of the art (Fukui et al., 2016) achieves 66.7%).","4.1 Task, model, and data",[0],[0]
"We chose this model for its easy reproducibility.
","4.1 Task, model, and data",[0],[0]
"The VQA 1.0 dataset (Agrawal et al., 2015) consists of 614,163 questions posed over 204,721 images (3 questions per image).","4.1 Task, model, and data",[0],[0]
"The images were taken from COCO (Lin et al., 2014), and the questions and answers were crowdsourced.
","4.1 Task, model, and data",[0],[0]
The network in Kazemi and Elqursh (2017) treats question answering as a classification task wherein the classes are 3000 most frequent answers in the training data.,"4.1 Task, model, and data",[0],[0]
"The input question is tokenized, embedded and fed to a multi-layer LSTM.","4.1 Task, model, and data",[0],[0]
"The states of the LSTM attend to a featurized version of the image, and ultimately produce a probability distribution over the answer classes.","4.1 Task, model, and data",[0],[0]
We applied IG and attributed the top selected answer class to input question words.,4.2 Observations,[0],[0]
"The baseline for a given input instance is the image and an
empty question2.",4.2 Observations,[0],[0]
"We omit instances where the top answer class predicted by the network remains the same even when the question is emptied (i.e., the baseline input).",4.2 Observations,[0],[0]
"This is because IG attributions are not informative when the input and the baseline have the same prediction.
",4.2 Observations,[0],[0]
A visualization of the attributions is shown in fig.,4.2 Observations,[0],[0]
1. Notice that very few words have high attribution.,4.2 Observations,[0],[0]
We verified that altering the low attribution words in the question does not change the network’s answer.,4.2 Observations,[0],[0]
"For instance, the following questions still return “very” as the answer: “how spherical are the white bricks on either side of the building”, “how soon are the bricks fading on either side of the building”, “how fast are the bricks speaking on either side of the building”.
",4.2 Observations,[0],[0]
"On analyzing attributions across examples, we find that most of the highly attributed words are words such as “there”, “what”, “how”, “doing”– they are usually the less important words in questions.",4.2 Observations,[0],[0]
In section 4.3 we describe a test to measure the extent to which the network depends on such words.,4.2 Observations,[0],[0]
"We also find that informative words in the question (e.g., nouns) often receive very low attribution, indicating a weakness on part of the network.",4.2 Observations,[0],[0]
"In Section 4.4, we describe various attacks that exploit this weakness.",4.2 Observations,[0],[0]
"To determine the set of question words that the network finds most important, we isolate words that most frequently occur as top attributed words in questions.",4.3 Overstability test,[0],[0]
"We then drop all words except these and compute the accuracy.
",4.3 Overstability test,[0],[0]
"Figure 2 shows how the accuracy changes as the size of this isolated set is varied from 0 to 5305.
",4.3 Overstability test,[0],[0]
"2We do not black out the image in our baseline as our objective is to study the influence of just the question words for a given image
We find that just one word is enough for the model to achieve more than 50% of its final accuracy.",4.3 Overstability test,[0],[0]
"That word is “color”.
",4.3 Overstability test,[0],[0]
"Note that even when empty questions are passed as input to the network, its accuracy remains at about 44.3% of its original accuracy.",4.3 Overstability test,[0],[0]
"This shows that the model is largely reliant on the image for producing the answer.
",4.3 Overstability test,[0],[0]
The accuracy increases (almost) monotonically with the size of the isolated set.,4.3 Overstability test,[0],[0]
"The top 6 words in the isolated set are “color”, “many”, “what”, “is”, “there”, and “how”.",4.3 Overstability test,[0],[0]
We suspect that generic words like these are used to determine the type of the answer.,4.3 Overstability test,[0],[0]
The network then uses the type to choose between a few answers it can give for the image.,4.3 Overstability test,[0],[0]
Attributions reveal that the network relies largely on generic words in answering questions (section 4.3).,4.4 Attacks,[0],[0]
This is a weakness in the network’s logic.,4.4 Attacks,[0],[0]
"We now describe a few attacks against the network that exploit this weakness.
",4.4 Attacks,[0],[0]
"Subject ablation attack
In this attack, we replace the subject of a question with a specific noun that consistently receives low attribution across questions.",4.4 Attacks,[0],[0]
"We then determine, among the questions that the network originally answered correctly, what percentage result in the same answer after the ablation.",4.4 Attacks,[0],[0]
"We repeat this process for different nouns; specifically, “fits”, “childhood”, “copyrights”, “mornings”, “disorder”, “importance”, “topless”, “critter”, “jumper”, “tweet”, and average the result.
",4.4 Attacks,[0],[0]
"We find that, among the set of questions that the network originally answered correctly, 75.6% of the questions return the same answer despite the subject replacement.
",4.4 Attacks,[0],[0]
"Prefix attack
In this attack, we attach content-free phrases to questions.",4.4 Attacks,[0],[0]
The phrases are manually crafted using generic words that the network finds important (section 4.3).,4.4 Attacks,[0],[0]
"Table 1 (top half) shows the resulting accuracy for three prefixes —“in not a lot of words”, “what is the answer to”, and “in not many words”.",4.4 Attacks,[0],[0]
All of these phrases nearly halve the model’s accuracy.,4.4 Attacks,[0],[0]
"The union of the three attacks drops the model’s accuracy from 61.1% to 19%.
",4.4 Attacks,[0],[0]
We note that the attributions computed for the network were crucial in crafting the prefixes.,4.4 Attacks,[0],[0]
"For instance, we find that other prefixes like “tell me”, “answer this” and “answer this for me” do not drop the accuracy by much; see table 1 (bottom half).",4.4 Attacks,[0],[0]
The union of these three ineffective prefixes drops the accuracy from 61.1% to only 46.9%.,4.4 Attacks,[0],[0]
"Per attributions, words present in these prefixes are not deemed important by the network.",4.4 Attacks,[0],[0]
Agrawal et al. (2016) analyze several VQA models.,4.5 Related work,[0],[0]
"Among other attacks, they test the models on question fragments of telescopically increasing length.",4.5 Related work,[0],[0]
They observe that VQA models often arrive at the same answer by looking at a small fragment of the question.,4.5 Related work,[0],[0]
"Our stability analysis in section 4.3 explains, and intuitively subsumes this; indeed, several of the top attributed words appear in the prefix, while important words like “color” often occur in the middle of the question.",4.5 Related work,[0],[0]
"Our analysis enables additional attacks, for instance, replacing question subject with low attri-
bution nouns.",4.5 Related work,[0],[0]
Ribeiro et al. (2016a) use a model explanation technique to illustrate overstability for two examples.,4.5 Related work,[0],[0]
They do not quantify their analysis at scale.,4.5 Related work,[0],[0]
"Kafle and Kanan (2017); Zhang et al. (2016) examine the VQA data, identify deficiencies, and propose data augmentation to reduce over-representation of certain question/answer types.",4.5 Related work,[0],[0]
"Goyal et al. (2016) propose the VQA 2.0 dataset, which has pairs of similar images that have different answers on the same question.",4.5 Related work,[0],[0]
We note that our method can be used to improve these datasets by identifying inputs where models ignore several words.,4.5 Related work,[0],[0]
Huang et al. (2017) evaluate robustness of VQA models by appending questions with semantically similar questions.,4.5 Related work,[0],[0]
Our prefix attacks in section 4.4 are in a similar vein and perhaps a more natural and targeted approach.,4.5 Related work,[0],[0]
"Finally, Fong and Vedaldi (2017) use saliency methods to produce image perturbations as adversarial examples; our attacks are on the question.",4.5 Related work,[0],[0]
"We now analyze question answering over tables based on the WikiTableQuestions benchmark dataset (Pasupat and Liang, 2015).","5.1 Task, model, and data",[0],[0]
The dataset has 22033 questions posed over 2108 tables scraped from Wikipedia.,"5.1 Task, model, and data",[0],[0]
Answers are either contents of table cells or some table aggregations.,"5.1 Task, model, and data",[0],[0]
Models performing QA on tables translate the question into a structured program (akin to an SQL query) which is then executed on the table to produce the answer.,"5.1 Task, model, and data",[0],[0]
"We analyze a model called Neural Programmer (NP) (Neelakantan et al., 2017).","5.1 Task, model, and data",[0],[0]
"NP is the state of the art among models that are weakly supervised, i.e., supervised using the final answer instead of the correct structured program.","5.1 Task, model, and data",[0],[0]
"It achieves 33.5% accuracy on the validation set.
","5.1 Task, model, and data",[0],[0]
NP translates the input into a structured program consisting of four operator and table column selections.,"5.1 Task, model, and data",[0],[0]
"An example of such a program is “reset (score), reset (score), min (score), print (name)”, where the output is the name of the person who has the lowest score.","5.1 Task, model, and data",[0],[0]
We applied IG to attribute operator and column selection to question words.,5.2 Observations,[0],[0]
"NP preprocesses inputs and whenever applicable, appends symbols tm token, cm token to questions that signify matches between a question and the accom-
panying table.",5.2 Observations,[0],[0]
These symbols are treated the same as question words.,5.2 Observations,[0],[0]
NP also computes priors for column selection using question-table matches.,5.2 Observations,[0],[0]
"These vectors, tm and cm , are passed as additional inputs to the neural network.",5.2 Observations,[0],[0]
"In the baseline for IG, we use an empty question, and zero vectors for column selection priors3.
",5.2 Observations,[0],[0]
We visualize the attributions using an alignment matrix; they are commonly used in the analysis of translation models (fig. 3).,5.2 Observations,[0],[0]
Observe that the operator “first” is used when the question is asking for a superlative.,5.2 Observations,[0],[0]
"Further, we see that the word “gold” is a trigger for this operator.",5.2 Observations,[0],[0]
We investigate implications of this behavior in the following sections.,5.2 Observations,[0],[0]
"Similar to the test we did for Visual QA (section 4.3), we check for overstability in NP by looking at accuracy as a function of the vocabulary size.",5.3 Overstability test,[0],[0]
"We treat table match annotations tm token , cm token and the out-of-vocab token (unk ) as part of the vocabulary.",5.3 Overstability test,[0],[0]
The results are in fig.,5.3 Overstability test,[0],[0]
4.,5.3 Overstability test,[0],[0]
We see that the curve is similar to that of Visual QA (fig. 2).,5.3 Overstability test,[0],[0]
Just 5 words (along with the column selection priors) are sufficient for the model to reach more than 50% of its final accuracy on the validation set.,5.3 Overstability test,[0],[0]
"These five words are: “many”, “number”, “tm token”, “after”, and “total”.",5.3 Overstability test,[0],[0]
We saw in the previous section that the model relies on only a few words in producing correct answers.,5.4 Table-specific default programs,[0],[0]
"An extreme case of overstability is when
3Note that the table is left intact in the baseline
the operator sequences produced by the model are independent of the question.",5.4 Table-specific default programs,[0],[0]
"We find that if we supply an empty question as an input, i.e., the output is a function only of the table, then the distribution over programs is quite skewed.",5.4 Table-specific default programs,[0],[0]
We call these programs table-specific default programs.,5.4 Table-specific default programs,[0],[0]
"On average, about 36.9% of the selected operators match their table-default counterparts, indicating that the model relies significantly on the table for producing an answer.
",5.4 Table-specific default programs,[0],[0]
"For each default program, we used IG to attribute operator and column selections to column names and show ten most frequently occurring ones across tables in the validation set (table 2).
",5.4 Table-specific default programs,[0],[0]
"Here is an insight from this analysis: NP uses the combination “reset, prev” to exclude the last row of the table from answer computation.",5.4 Table-specific default programs,[0],[0]
"The default program corresponding to “reset, prev, max, print” has attributions to column names such as “rank”, “gold”, “silver”, “bronze”, “nation”, “year”.",5.4 Table-specific default programs,[0],[0]
These column names indicate medal tallies and usually have a “total” row.,5.4 Table-specific default programs,[0],[0]
"If the table happens not to have a “total” row, the model may
produce an incorrect answer.",5.4 Table-specific default programs,[0],[0]
"We now describe attacks that add or drop content-free words from the question, and cause NP to produce the wrong answer.",5.4 Table-specific default programs,[0],[0]
These attacks leverage the attribution analysis.,5.4 Table-specific default programs,[0],[0]
"Question concatenation attacks
In these attacks, we either suffix or prefix contentfree phrases to questions.",5.5 Attacks,[0],[0]
"The phrases are crafted using irrelevant trigger words for operator selections (supplementary material, table 5).",5.5 Attacks,[0],[0]
"We manually ensure that the phrases are content-free.
",5.5 Attacks,[0],[0]
Table 3 describes our results.,5.5 Attacks,[0],[0]
The first 4 phrases use irrelevant trigger words and result in a large drop in accuracy.,5.5 Attacks,[0],[0]
"For instance, the first phrase uses “not” which is a trigger for “next”, “last”, and “min”, and the second uses “same” which is a trigger for “next” and “mfe”.",5.5 Attacks,[0],[0]
The four phrases combined results in the model’s accuracy going down from 33.5% to 3.3%.,5.5 Attacks,[0],[0]
"The first two phrases alone drop the accuracy to 5.6%.
",5.5 Attacks,[0],[0]
"The next set of phrases use words that receive low attribution across questions, and are hence non-triggers for any operator.",5.5 Attacks,[0],[0]
"The resulting drop in accuracy on using these phrases is relatively
low.",5.5 Attacks,[0],[0]
"Combined, they result in the model’s accuracy dropping from 33.5% to 27.1%.
",5.5 Attacks,[0],[0]
"Stop word deletion attacks
We find that sometimes an operator is selected based on stop words like: “a”, “at”, “the”, etc.",5.5 Attacks,[0],[0]
"For instance, in the question, “what ethnicity is at the top?”, the operator “next” is triggered on the word “at”.",5.5 Attacks,[0],[0]
"Dropping the word “at” from the question changes the operator selection and causes NP to return the wrong answer.
",5.5 Attacks,[0],[0]
We drop stop words from questions in the validation dataset that were originally answered correctly and test NP on them.,5.5 Attacks,[0],[0]
"The stop words to be dropped were manually selected4 and are shown in Figure 5 in the supplementary material.
",5.5 Attacks,[0],[0]
"By dropping stop words, the accuracy drops from 33.5% to 28.5%.",5.5 Attacks,[0],[0]
Selecting operators based on stop words is not robust.,5.5 Attacks,[0],[0]
"In real world search queries, users often phrase questions without stop words, trading grammatical correctness for conciseness.",5.5 Attacks,[0],[0]
"For instance, the user may simply say “top ethnicity”.",5.5 Attacks,[0],[0]
"It may be possible to defend against such examples by generating synthetic training data, and re-training the network on it.
",5.5 Attacks,[0],[0]
"Row reordering attacks
We found that NP often got the question right by leveraging artifacts of the table.",5.5 Attacks,[0],[0]
"For instance, the operators for the question “which nation earned the most gold medals” are “reset”, “prev”, “first” and “print”.",5.5 Attacks,[0],[0]
The “prev” operator essentially excludes the last row from the answer computation.,5.5 Attacks,[0],[0]
"It gets the answer right for two reasons: (1) the answer is not in the last row, and (2) rows are sorted by the values in the column “gold”.
",5.5 Attacks,[0],[0]
"In general, a question answering system should not rely on row ordering in tables.",5.5 Attacks,[0],[0]
"To quantify the extent of such biases, we used a perturbed version of WikiTableQuestions validation dataset as described in Pasupat and Liang (2016)5 and evaluated the existing NP model on it (there was no re-training involved here).",5.5 Attacks,[0],[0]
"We found that NP has only 23% accuracy on it, in constrast to an accuracy of 33.5% on the original validation dataset.
",5.5 Attacks,[0],[0]
One approach to making the network robust to row-reordering attacks is to train against perturbed tables.,5.5 Attacks,[0],[0]
"This may also help the model generalize
4We avoided standard stop word lists (e.g. NLTK) as they contain contentful words (e.g “after”) which may be important in some questions (e.g. “who ranked right after turkey?”)
5based on data at https://nlp.stanford.edu/ software/sempre/wikitable/dpd/
better.",5.5 Attacks,[0],[0]
"Indeed, Mudrakarta et al. (2018) note that the state-of-the-art strongly supervised6 model on WikiTableQuestions (Krishnamurthy et al., 2017) enjoys a 7% gain in its final accuracy by leveraging perturbed tables during training.",5.5 Attacks,[0],[0]
The reading comprehension task involves identifying a span from a context paragraph as an answer to a question.,"6.1 Task, model, and data",[0],[0]
"The SQuAD dataset (Rajpurkar et al., 2016) for machine reading comprehension contains 107.7K query-answer pairs, with 87.5K for training, 10.1K for validation, and another 10.1K for testing.","6.1 Task, model, and data",[0],[0]
"Deep learning methods are quite successful on this problem, with the state-of-the-art F1 score at 84.6 achieved by Yu et al. (2018); we analyze their model.","6.1 Task, model, and data",[0],[0]
Recall the adversarial attacks proposed by Jia and Liang (2017) for reading comprehension systems.,6.2 Analyzing adversarial examples,[0],[0]
Their attack ADDSENT appends sentences to the paragraph that resemble an answer to the question without changing the ground truth.,6.2 Analyzing adversarial examples,[0],[0]
"See the second column of table 4 for a few examples.
",6.2 Analyzing adversarial examples,[0],[0]
We investigate the effectiveness of their attacks using attributions.,6.2 Analyzing adversarial examples,[0],[0]
"We analyze 100 examples generated by the ADDSENT method in Jia and Liang (2017), and find that an adversarial sentence is successful in fooling the model in two cases:
First, a contentful word in the question gets low/zero attribution and the adversarially added sentence modifies that word.",6.2 Analyzing adversarial examples,[0],[0]
"E.g. in the question, “Who did Kubiak take the place of after Super Bowl XXIV?”, the word “Super” gets low attribution.",6.2 Analyzing adversarial examples,[0],[0]
"Adding “After Champ Bowl XXV, Crowton took the place of Jeff Dean” changes the prediction for the model.",6.2 Analyzing adversarial examples,[0],[0]
"Second, a contentful word in the question that is not present in the context.",6.2 Analyzing adversarial examples,[0],[0]
"For e.g. in the question “Where hotel did the Panthers stay at?”, “hotel”, is not present in the context.",6.2 Analyzing adversarial examples,[0],[0]
Adding “The Vikings stayed at Chicago hotel.”,6.2 Analyzing adversarial examples,[0],[0]
"changes the prediction for the model.
",6.2 Analyzing adversarial examples,[0],[0]
"On the flip side, an adversarial sentence is unsuccessful when a contentful word in the question having high attribution is not present in the added sentence.",6.2 Analyzing adversarial examples,[0],[0]
"E.g. for “Where according to gross state product does Victoria rank in Australia?”, “Australia” receives high attribution.",6.2 Analyzing adversarial examples,[0],[0]
"Adding “Accord-
6supervised on the structured program
ing to net state product, Adelaide ranks 7 in New Zealand.”",6.2 Analyzing adversarial examples,[0],[0]
does not fool the model.,6.2 Analyzing adversarial examples,[0],[0]
"However, retaining “Australia” in the adversarial sentence does change the model’s prediction.",6.2 Analyzing adversarial examples,[0],[0]
Next we correlate attributions with efficacy of the ADDSENT attacks.,6.3 Predicting the effectiveness of attacks,[0],[0]
"We analyzed 1000 (question, attack phrase) instances7 where Yu et al. (2018) model has the correct baseline prediction.",6.3 Predicting the effectiveness of attacks,[0],[0]
"Of the 1000 cases, 508 are able to fool the model, while 492 are not.",6.3 Predicting the effectiveness of attacks,[0],[0]
We split the examples into two groups.,6.3 Predicting the effectiveness of attacks,[0],[0]
"The first group has examples where a noun or adjective in the question has high attribution, but is missing from the adversarial sentence and the rest are in the second group.",6.3 Predicting the effectiveness of attacks,[0],[0]
Our attribution analysis suggests that we should find more failed examples in the first group.,6.3 Predicting the effectiveness of attacks,[0],[0]
That is indeed the case.,6.3 Predicting the effectiveness of attacks,[0],[0]
"The first group has 63% failed examples, while the second has only 40%.
",6.3 Predicting the effectiveness of attacks,[0],[0]
"Recall that the attack sentences were constructed by (a) generating a sentence that answers the question, (b) replacing all the adjectives and nouns with antonyms, and named entities by the nearest word in GloVe word vector space (Pennington et al., 2014) and (c) crowdsourcing to check that the new sentence is grammatically correct.",6.3 Predicting the effectiveness of attacks,[0],[0]
"This suggests a use of attributions to improve the effectiveness of the attacks, namely ensuring that question words that the model thinks are important are left untouched in step (b) (we note that other changes in should be carried out).",6.3 Predicting the effectiveness of attacks,[0],[0]
"In table 4,
7data sourced from https:// worksheets.codalab.org/worksheets/ 0xc86d3ebe69a3427d91f9aaa63f7d1e7d/
we show a few examples where an original attack did not fool the model, but preserving a noun with high attribution did.",6.3 Predicting the effectiveness of attacks,[0],[0]
We analyzed three question answering models using an attribution technique.,7 Conclusion,[0],[0]
Attributions helped us identify weaknesses of these models more effectively than conventional methods (based on validation sets).,7 Conclusion,[0],[0]
"We believe that a workflow that uses attributions can aid the developer in iterating on model quality more effectively.
",7 Conclusion,[0],[0]
"While the attacks in this paper may seem unrealistic, they do expose real weaknesses that affect the usage of a QA product.",7 Conclusion,[0],[0]
Under-reliance on important question terms is not safe.,7 Conclusion,[0],[0]
We also believe that other QA models may share these weaknesses.,7 Conclusion,[0],[0]
Our attribution-based methods can be directly used to gauge the extent of such problems.,7 Conclusion,[0],[0]
"Additionally, our perturbation attacks (sections 4.4 and 5.5) serve as empirical validation of attributions.
",7 Conclusion,[0],[0]
"Reproducibility
Code to generate attributions and reproduce our results is freely available at https://github.",7 Conclusion,[0],[0]
com/pramodkaushik/acl18_results.,7 Conclusion,[0],[0]
"We thank the anonymous reviewers and Kevin Gimpel for feedback on our work, and David Dohan for helping with the reading comprehension network.",Acknowledgments,[0],[0]
We are grateful to Jiřı́ Šimša for helpful comments on drafts of this paper.,Acknowledgments,[0],[0]
"We analyze state-of-the-art deep learning models for three tasks: question answering on (1) images, (2) tables, and (3) passages of text.",abstractText,[0],[0]
"Using the notion of attribution (word importance), we find that these deep networks often ignore important question terms.",abstractText,[0],[0]
"Leveraging such behavior, we perturb questions to craft a variety of adversarial examples.",abstractText,[0],[0]
"Our strongest attacks drop the accuracy of a visual question answering model from 61.1% to 19%, and that of a tabular question answering model from 33.5% to 3.3%.",abstractText,[0],[0]
"Additionally, we show how attributions can strengthen attacks proposed by Jia and Liang (2017) on paragraph comprehension models.",abstractText,[0],[0]
Our results demonstrate that attributions can augment standard measures of accuracy and empower investigation of model performance.,abstractText,[0],[0]
"When a model is accurate but for the wrong reasons, attributions can surface erroneous logic in the model that indicates inadequacies in the test data.",abstractText,[0],[0]
Did the Model Understand the Question?,title,[0],[0]
"Gaussian processes (GPs) are a powerful and widely used class of models due to their nonparametric nature, explicit representation of posterior uncertainty, and ability to flexibly model a variety of structures in data.",1. Introduction,[0],[0]
"However, patterns of generalization in GP depend heavily on the choice of kernel function (Rasmussen, 1999); different kernels can impose widely varying modeling assumptions, such as smoothness, linearity, or periodicity.",1. Introduction,[0],[0]
"Capturing appropriate kernel structures can be crucial for interpretability and extrapolation (Duvenaud et al., 2013; Wilson & Adams, 2013).",1. Introduction,[0],[0]
"Even for experts, choosing GP kernel structures remains a dark art.
",1. Introduction,[0],[0]
GPs’ strong dependence on kernel structures has motivated work on automatic kernel learning methods.,1. Introduction,[0],[0]
"Sometimes this
1Department of Computer Science, University of Toronto, Toronto, ON, CA. 2Vector Institute.",1. Introduction,[0],[0]
"3Uber Advanced Technologies Group, Toronto, ON, CA.",1. Introduction,[0],[0]
"Correspondence to: Shengyang Sun <ssy@cs.toronto.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
can be done by imposing a specific kind of structure: e.g., Bach (2009); Duvenaud et al. (2011) learned kernel structures which were additive over subsets of the variables.",1. Introduction,[0],[0]
"A more expressive space of kernels is spectral mixtures (Wilson & Adams, 2013; Kom Samo & Roberts, 2015; Remes et al., 2017), which are based on spectral domain summations.",1. Introduction,[0],[0]
"For example, spectral mixture (SM) kernels (Wilson & Adams, 2013) approximate all stationary kernels using Gaussian mixture models in the spectral domain.",1. Introduction,[0],[0]
"Deep kernel learning (DKL) (Wilson et al., 2016) further boosted the expressiveness by transforming the inputs of spectral mixture base kernel with a deep neural network.",1. Introduction,[0],[0]
"However, the expressiveness of DKL still depends heavily on the kernel placed on the output layer.
",1. Introduction,[0],[0]
"In another line of work, Duvenaud et al. (2013) defined a context-free grammar of kernel structures based on the composition rules for kernels.",1. Introduction,[0],[0]
"Due to its compositionality, this grammar could express combinations of properties such as smoothness, linearity, or periodicity.",1. Introduction,[0],[0]
They performed a greedy search over this grammar to find a kernel struture which matched the input data.,1. Introduction,[0],[0]
"Using the learned structures, they were able to produce sensible extrapolations and interpretable decompositions for time series datasets.",1. Introduction,[0],[0]
Lloyd et al. (2014) extended this work to an Automatic Statistician which automatically generated natural language reports.,1. Introduction,[0],[0]
All of these results depended crucially on the compositionality of the underlying space.,1. Introduction,[0],[0]
"The drawback was that discrete search over the kernel grammar is very expensive, often requiring hours of computation even for short time series.
",1. Introduction,[0],[0]
"In this paper, we propose the Neural Kernel Network (NKN), a flexible family of kernels represented by a neural network.",1. Introduction,[0],[0]
"The network’s first layer units represent primitive kernels, including those used by the Automatic Statistician.",1. Introduction,[0],[0]
"Subsequent layers are based on the composition rules for kernels, so that each intermediate unit is itself a valid kernel.",1. Introduction,[0],[0]
"The NKN can compactly approximate the kernel structures from the Automatic Statistician grammar, but is fully differentiable, so that the kernel structures can be learned with gradient-based optimization.",1. Introduction,[0],[0]
"To illustrate the flexibility of our approach, Figure 1 shows the result of fitting an NKN to model a 2-D function; it is able to extrapolate sensibly.
",1. Introduction,[0],[0]
We analyze the NKN’s expressive power for various choices of primitive kernels.,1. Introduction,[0],[0]
"We show that the NKN can represent nonnegative polynomial functions of its primitive kernels, and from this demonstrate universality for the class of stationary kernels.",1. Introduction,[0],[0]
"Our universality result holds even if the width of the network is limited, analogously to Sutskever & Hinton (2008).",1. Introduction,[0],[0]
"Interestingly, we find that the network’s representations can be made significantly more compact by allowing its units to represent complex-valued kernels, and taking the real component only at the end.
",1. Introduction,[0],[0]
We empirically analyze the NKN’s pattern discovery and extrapolation abilities on several tasks that depend crucially on identifying the underlying structure.,1. Introduction,[0],[0]
The NKN produces sensible extrapolations on both 1-D time series datasets and 2-D textures.,1. Introduction,[0],[0]
It outperforms competing approaches on regression benchmarks.,1. Introduction,[0],[0]
"In the context of Bayesian optimization, it is able to optimize black-box functions more efficiently than generic smoothness kernels.",1. Introduction,[0],[0]
A Gaussian process (GP) defines a distribution p(f) over functions X !,2.1. Gaussian Process Regression,[0],[0]
R for some domain X .,2.1. Gaussian Process Regression,[0],[0]
"For any finite set {x1, ...,xn} ⇢ X , the function values f = (f(x1), f(x2), ..., f(xn)) have a multivariate Gaussian distribution.",2.1. Gaussian Process Regression,[0],[0]
Gaussian processes are parameterized by a mean function µ(·) and a covariance function or kernel function,2.1. Gaussian Process Regression,[0],[0]
"k(·, ·).",2.1. Gaussian Process Regression,[0],[0]
"The marginal distribution of function values is given by
f ⇠ N (µ,K XX ), (1) where K
XX denotes the matrix of k(x i ,x j ) for all (i, j).
",2.1. Gaussian Process Regression,[0],[0]
"Assume we are given a set of training input-output pairs, D = {(x
i , y i )}n i=1",2.1. Gaussian Process Regression,[0],[0]
"= (X,y), and each target yn is gener-
ated from the corresponding f(x n ) by adding independent Gaussian noise; i.e.,
y n = f(x n ) +",2.1. Gaussian Process Regression,[0],[0]
"✏ n , ✏ n
⇠ N (0, 2) (2)
",2.1. Gaussian Process Regression,[0],[0]
"As the prior on f is a Gaussian process and the likelihood is Gaussian, the posterior on f is also Gaussian.",2.1. Gaussian Process Regression,[0],[0]
"We can use
this to make predictions p(y⇤|x⇤,D) in closed form:
p(y⇤|x⇤,D) = N (µ⇤, 2⇤) µ⇤ = K⇤X(KXX + 2 I) 1 y
2⇤ = K⇤⇤ K⇤X(KXX + 2I) 1KX⇤ + 2 (3)
",2.1. Gaussian Process Regression,[0],[0]
Here we assume zero mean function for f .,2.1. Gaussian Process Regression,[0],[0]
"Most GP kernels have several hyperparameters ✓ which can be optimized jointly with to maximize the log marginal likelihood,
L(✓) =",2.1. Gaussian Process Regression,[0],[0]
"ln p(y|0,K XX + 2I) (4)",2.1. Gaussian Process Regression,[0],[0]
"Gaussian Processes depend on specifying a kernel function k(x, x0), which acts as a similarity measure between inputs.
",2.2. Bochner’s Theorem,[0],[0]
Definition 1.,2.2. Bochner’s Theorem,[0],[0]
"Let X be a set, and k be a conjugate symmetric function k : X ⇥ X !",2.2. Bochner’s Theorem,[0],[0]
C is a positive definite kernel,2.2. Bochner’s Theorem,[0],[0]
"if 8x
1 , · · ·, x n 2 X and 8c 1 , · · ·, c n 2 C, nX
i,j=1
c
i
c
j k(x",2.2. Bochner’s Theorem,[0],[0]
"i , x j ) 0, (5)
where the bar denotes the complex conjugate.",2.2. Bochner’s Theorem,[0],[0]
"Bochner’s Theorem (Bochner, 1959) establishes a bijection between complex-valued stationary kernels and positive finite measures using Fourier transform, thus providing an approach to analyze stationary kernels in the spectral domain (Wilson & Adams, 2013; Kom Samo & Roberts, 2015).
",2.2. Bochner’s Theorem,[0],[0]
Theorem 1.,2.2. Bochner’s Theorem,[0],[0]
"(Bochner) A complex-valued function k on Rd is the covariance function of a weakly stationary mean square continuous complex-valued random process on Rd if and only if it can be represented as
k(⌧ ) =
Z
RP exp(2⇡iw>⌧ ) (dw) (6)
where is a positive and finite measure.",2.2. Bochner’s Theorem,[0],[0]
"If has a density S(w), then S is called the spectral density or power spectrum of k. S and k are Fourier duals.",2.2. Bochner’s Theorem,[0],[0]
"For compositional kernel learning, the Automatic Statistician (Lloyd et al., 2014; Duvenaud et al., 2013) used a compositional space of kernels defined as sums and products of a small number of primitive kernels.",2.3. Automatic Statistician,[0],[0]
"The primitive kernels included:
• radial basis functions, corresponding to smooth functions.",2.3. Automatic Statistician,[0],[0]
"RBF(x,x0) = 2 exp( kx x
0k2 2l2 )
• periodic.",2.3. Automatic Statistician,[0],[0]
"PER(x,x0)",2.3. Automatic Statistician,[0],[0]
"= 2 exp( 2 sin 2(⇡kx x0k/p)
l
2 )
• linear kernel.",2.3. Automatic Statistician,[0],[0]
"LIN(x,x0) = 2x>x0
• rational quadratic, corresponding to functions with multiple scale variations.",2.3. Automatic Statistician,[0],[0]
"RQ(x,x0) = 2(1+ kx x
0k2 2↵l2 ) 1 ↵
• white noise.",2.3. Automatic Statistician,[0],[0]
"WN(x,x0)",2.3. Automatic Statistician,[0],[0]
"= 2 x,x 0 • constant kernel.",2.3. Automatic Statistician,[0],[0]
"C(x,x0)",2.3. Automatic Statistician,[0],[0]
"= 2
The Automatic Statistician searches over the compositional space based on three search operators.
1.",2.3. Automatic Statistician,[0],[0]
"Any subexpression S can be replaced with S + B, where B is any primitive kernel family.",2.3. Automatic Statistician,[0],[0]
2.,2.3. Automatic Statistician,[0],[0]
"Any subexpression S can be replaced with S ⇥ B, where B is any primitive kernel family.",2.3. Automatic Statistician,[0],[0]
3.,2.3. Automatic Statistician,[0],[0]
"Any primitive kernel B can be replaced with any other primitive kernel family B0.
",2.3. Automatic Statistician,[0],[0]
"The search procedure relies on a greedy search: at every stage, it searches over all subexpressions and all possible operators, then chooses the highest scoring combination.",2.3. Automatic Statistician,[0],[0]
"To score kernel families, it approximates the marginal likelihood using the Bayesian information criterion (Schwarz et al., 1978) after optimizing to find the maximumlikelihood kernel parameters.",2.3. Automatic Statistician,[0],[0]
"In this section, we introduce the Neural Kernel Network (NKN), a neural net which computes compositional kernel structures and is end-to-end trainable with gradient-based optimization.",3. Neural Kernel Networks,[0],[0]
"The input to the network consists of two vectors x1,x2 2 Rd, and the output k(x1,x2) 2 R (or C) is the kernel value.",3. Neural Kernel Networks,[0],[0]
Our NKN architecture is based on well-known composition rules for kernels: Lemma 2.,3. Neural Kernel Networks,[0],[0]
"For kernels k1, k2
• For 1, 2 2 R+, 1k1 + 2k2 is a kernel.
",3. Neural Kernel Networks,[0],[0]
"• The product k1k2 is a kernel.
",3. Neural Kernel Networks,[0],[0]
"We design the architecture such that every unit of the network computes a kernel, although some of those kernels may be complex-valued.",3. Neural Kernel Networks,[0],[0]
The first layer of the NKN consists of a set of primitive kernels.,3.1. Architecture,[0],[0]
Subsequent layers alternate between linear combinations and products.,3.1. Architecture,[0],[0]
"Since the space of kernels is closed under both operations, each unit in the network represents a kernel.",3.1. Architecture,[0],[0]
"Linear combinations and products can be seen as OR-like and AND-like operations, respectively; this is a common pattern in neural net design (LeCun et al., 1989; Poon & Domingos, 2011).",3.1. Architecture,[0],[0]
"The full architecture is illustrated in Figure 2.
Primitive kernels.",3.1. Architecture,[0],[0]
The first layer of the network consists of a set of primitive kernel families with simple functional forms.,3.1. Architecture,[0],[0]
"While any kernels can be used here, we use the RBF, PER, LIN, and RQ kernels from the Automatic Statistician (see Section 2.3) because these express important structural motifs for GPs.",3.1. Architecture,[0],[0]
"Each of these kernel families has an associated set of hyperparameters (such as lengthscales or variances), and instantiating the hyperparameters gives a kernel.",3.1. Architecture,[0],[0]
"These hyperparameters are treated as parameters (weights) in this layer of the network, and are optimized with the rest of the network.",3.1. Architecture,[0],[0]
"Note that it may be advantageous to have multiple copies of each primitive kernel so that they can be instantiated with different hyperparameters.
",3.1. Architecture,[0],[0]
Linear layers.,3.1. Architecture,[0],[0]
"The Linear layer closely resembles a fully connected layer in deep neural networks, with each layer h
l
= W
l
h l 1 representing a nonnegative linear combination of units in the previous layer (i.e. W
l is a nonnegative matrix).",3.1. Architecture,[0],[0]
"In practice, we use the parameterization
W
l
= log(1 + exp(A
l )) to enforce the nonnegativity constraint.",3.1. Architecture,[0],[0]
"(Here, exp is applied elementwise.)
",3.1. Architecture,[0],[0]
"The Linear layer can be seen as a OR-like operation: two points are considered similar if either kernel has a high value, while the Linear layer further controls the balance using trainable weights.
",3.1. Architecture,[0],[0]
Product layers.,3.1. Architecture,[0],[0]
"The Product layer introduces multiplication, in that each unit is the product of several units in the previous layer.",3.1. Architecture,[0],[0]
This layer has a fixed connectivity pattern and no trainable parameters.,3.1. Architecture,[0],[0]
"While this fixed structure may appear restrictive, Section 3.3 shows that it does not restrict the expressiveness of the network.
",3.1. Architecture,[0],[0]
"The Product layer can be seen as an AND-like operation: two points are considered similar if both constituent kernels have large values.
",3.1. Architecture,[0],[0]
Activation functions.,3.1. Architecture,[0],[0]
"Analogously to ordinary neural nets, each layer may also include a nonlinear activation function, so that h
l = f(z l ), where z l , the pre-activations, are the result of a linear combination or product.",3.1. Architecture,[0],[0]
"However, f must be selected with care in order to ensure closure of the kernels.",3.1. Architecture,[0],[0]
"Polynomials with positive coefficients, as well as the exponential function f(z) = ez , fulfill this requirement.
",3.1. Architecture,[0],[0]
Complex-valued kernels.,3.1. Architecture,[0],[0]
"Allowing units in NKN to represent complex-valued kernels as in Definition 1 and take the real component only at the end, can make the network’s representations significantly more compact.",3.1. Architecture,[0],[0]
"As complexvalued kernels also maintain closure under summation and multiplication (Yaglom, 2012), additional modifications are unnecessary.",3.1. Architecture,[0],[0]
"In practice, we can include exp(iµ>⌧ ) in our primitive kernels.",3.1. Architecture,[0],[0]
Optimization.,3.2. Learning,[0],[0]
"All trainable parameters can be grouped into two categories: (1) parameters of primitive kernels, e.g., lengthscale in an RBF kernel; (2) parameters of Linear layers.",3.2. Learning,[0],[0]
We jointly learn these parameters by maximizing the marginal likelihood L(✓).,3.2. Learning,[0],[0]
"Since the NKN architecture is differentiable, we can jointly fit all parameters using gradient-based optimization.
",3.2. Learning,[0],[0]
Computational Cost.,3.2. Learning,[0],[0]
NKN introduces small computational overhead.,3.2. Learning,[0],[0]
Suppose we have N data points and m connections in the NKN; the computational cost of the forward pass is O(N2m).,3.2. Learning,[0],[0]
"Note that a moderately-sized NKN, as we used in our experiments1, has only tens of parameters, and the main computational bottleneck in training lies in inverting kernel matrix, which is an O(N3) operation; therefore, NKN incurs only small per-iteration overhead compared to ordinary GP training.
",3.2. Learning,[0],[0]
"1In our experiments, we found 1 or 2 modules work very well.",3.2. Learning,[0],[0]
But it might be advantageous to use more modules in other tasks.,3.2. Learning,[0],[0]
"In this section, we analyze the expressive power of the NKN, and in particular its ability to approximate arbitrary stationary kernels.",3.3. Universality,[0],[0]
"Our analysis provides insight into certain design decisions for the NKN: in particular, we show that the NKN can approximate some stationary kernels much more compactly if the units of the network are allowed to take complex values.",3.3. Universality,[0],[0]
"Furthermore, we show that the fixed structure of the product layers does not limit what the network can represent.",3.3. Universality,[0],[0]
Definition 2.,3.3. Universality,[0],[0]
"For kernels {k
j }n j=1, a kernel k is positive-
weighted polynomial (PWP) of these kernels if 9T 2 N and {w
t , {p tj }n j=1|wi",3.3. Universality,[0],[0]
"2 R+, ptj 2 N}Tt=0, such that
k(x, y) = TX
t=1
w t
nY
j=1
k ptj
j
(7)
holds for all x, y 2 R.",3.3. Universality,[0],[0]
"Its degree is max t
P n
j=1 ptj .
",3.3. Universality,[0],[0]
"Composed of summation and multiplication, the NKN naturally forms a positive-weighted polynomial of primitive kernels.",3.3. Universality,[0],[0]
"Although NKN adopts a fixed multiplication order in the Product layer, the following theorem shows that this fixed architecture doesn’t undermine NKN’s expressiveness (proof in Appendix D).",3.3. Universality,[0],[0]
Theorem 3.,3.3. Universality,[0],[0]
"Given B primitive kernels,
• An NKN with width 2B + 6 can represent any PWP of primitive kernels.
",3.3. Universality,[0],[0]
"• An NKN with width 2Bp+1 and p Linear-Product modules can represent any PWP with degree no more than 2 p.
Interestingly, NKNs can sometimes approximate (realvalued) kernels more compactly if the hidden units are allowed to represent complex-valued kernels, and the real part is taken only at the end.",3.3. Universality,[0],[0]
"In particular, we give an example of a spectral mixture kernel class which can be represented with an NKN with a single complex-valued primitive kernel, but whose real-valued NKN representation requires a primitive kernel for each mixture component (proof in Appendix E).
",3.3. Universality,[0],[0]
Example 1.,3.3. Universality,[0],[0]
"Define a d-dimensional spectral mixture kernel with n+1 components, k⇤(⌧ ) = n+1P t=1 n 2 2t cos(4 t 1 > ⌧ ).",3.3. Universality,[0],[0]
"Then 9✏ > 0, such that 8{µ t }n t=1, and any PWP of {cos(µ> t ⌧ )}n t=1 denoted as ¯k,
max ⌧2Rd |¯k(⌧ ) k⇤(⌧ )",3.3. Universality,[0],[0]
| > ✏ (8),3.3. Universality,[0],[0]
"of only one complex-valued primitive kernel ei1 > ⌧ ,
k⇤(⌧ ) = <{ n+1X
t=1
✓ n
2
◆2t","In contrast, k⇤ can be represented as the real part of a PWP",[0],[0]
"[ei1 > ⌧ ] 4t} (9)
We find that an NKN with small width can approximate any complex-valued stationary kernel, as shown in the following theorem (Proof in Appendix F).
","In contrast, k⇤ can be represented as the real part of a PWP",[0],[0]
Theorem 4.,"In contrast, k⇤ can be represented as the real part of a PWP",[0],[0]
"For any d-dimensional complex-valued stationary kernel k⇤ and ✏ 2 R+, 9{
j }d j=1, {µj}2dj=1, and an
NKN ¯k with primitive kernels {exp( 2⇡2k⌧ j k2)}d j=1, {exp(iµ> j ⌧ )}2d j=1, and width no more than 6d+6, such that
max ⌧2Rd |¯k(⌧ ) k⇤(⌧ )","In contrast, k⇤ can be represented as the real part of a PWP",[0],[0]
"| < ✏ (10)
","In contrast, k⇤ can be represented as the real part of a PWP",[0],[0]
"Beyond approximating stationary kernels, NKN can also capture non-stationary structure by incorporating nonstationary primitive kernels.","In contrast, k⇤ can be represented as the real part of a PWP",[0],[0]
"In Appendix G, we prove that with the proper choice of primitive kernels, NKN can approximate a broad family of non-stationary kernels called generalized spectral kernels (Kom Samo & Roberts, 2015).","In contrast, k⇤ can be represented as the real part of a PWP",[0],[0]
"Additive kernels (Duvenaud et al., 2011) are linear combinations of kernels over individual dimensions or groups of dimensions, and are a promising method to combat the curse of dimensionality.",4. Related Work,[0],[0]
"While additive kernels need an exponential number of multiplication terms in the input dimension, hierarchical kernel learning (HKL) (Bach, 2009) presents a similar kernel except selecting only a subset to get a polynomial number of terms.",4. Related Work,[0],[0]
"However, this subset selection imposes additional optimization difficulty.
",4. Related Work,[0],[0]
"Based on Bochner’s theorem, there is another a line of work on designing kernels in the spectral domain, including sparse spectrum kernels (SS) (Lázaro-Gredilla et al., 2010); spectral mixture (SM) kernels (Wilson & Adams, 2013); generalized spectral kernels (GSK) (Kom Samo & Roberts, 2015) and generalized spectral mixture (GSM) kernels (Remes et al., 2017).",4. Related Work,[0],[0]
"Though these approaches often extrapolate sensibly, capturing complex covariance structure may require a large number of mixture components.
",4. Related Work,[0],[0]
"The Automatic Statistician (Duvenaud et al., 2013; Lloyd et al., 2014; Malkomes et al., 2016) used a compositional grammar of kernel structures to analyze datasets and provide natural language reports.",4. Related Work,[0],[0]
"In each stage, it considered all production rules and used the one that resulted in the largest log-likelihood improvement.",4. Related Work,[0],[0]
"Their model showed
good extrapolation for many time series tasks, attributed to the recovery of underlying structure.",4. Related Work,[0],[0]
"However, it relied on greedy discrete search over kernel and operator combinations, making it computational expensive, even for small time series datasets.
",4. Related Work,[0],[0]
"There have been several attempts (Hinton & Salakhutdinov, 2008; Wilson et al., 2016) to combine neural networks with Gaussian processes.",4. Related Work,[0],[0]
"Specifically, they used a fixed kernel structure on top of the hidden representation of a neural network.",4. Related Work,[0],[0]
"This is complementary to our work, which focuses on using neural networks to infer the kernel structure itself.",4. Related Work,[0],[0]
"Both approaches could potentially be combined.
",4. Related Work,[0],[0]
"Instead of represeting kernel parametrically, Oliva et al. (2016) modeled random feature dimension with stick breaking prior and Tobar et al. (2015)",4. Related Work,[0],[0]
generated functions as the convolution between a white noise process and a linear filter drawn from GP.,4. Related Work,[0],[0]
These approaches offer much flexibility but also incur challenges in training.,4. Related Work,[0],[0]
"We conducted a series of experiments to measure the NKN’s predictive ability in several settings: time series, regression benchmarks, and texture images.",5. Experiments,[0],[0]
"We focused in particular on extrapolation, since this is a strong test of whether it has uncovered the underlying structure.",5. Experiments,[0],[0]
"Furthermore, we tested the NKN on Bayesian Optimization, where model structure and calibrated uncertainty can each enable more efficient exploration.",5. Experiments,[0],[0]
Code is available at git@github.com: ssydasheng/Neural-Kernel-Network.git,5. Experiments,[0],[0]
We first conducted experiments time series datasets to study extrapolation performance.,5.1. Time Series Extrapolation,[0],[0]
"For all of these experiments, as well as the 2-d experiment in Figure 1, we used the same NKN architecture and training setup (Appendix J.1).
",5.1. Time Series Extrapolation,[0],[0]
"We validated the NKN on three time series datasets introduced by Duvenaud et al. (2013): airline passenger volume (Airline), Mauna Loa atmospheric CO2 concentration (Mauna), and solar irradiance (Solar).",5.1. Time Series Extrapolation,[0],[0]
"Our focus is on extrapolation, since this is a much better test than interpolation for whether the model has learned the underlying structure.
",5.1. Time Series Extrapolation,[0],[0]
"We compared the NKN with the Automatic Statistician (Duvenaud et al., 2013); both methods used RBF, RQ, PER and LIN as the primitive kernels.",5.1. Time Series Extrapolation,[0],[0]
"In addition, because many time series datasets appear to contain a combination of seasonal patterns, long-term trends, and medium-scale variability, we also considered a baseline consisting of sums of PER, LIN, RBF, and Constant kernels, with trainable weights and kernel parameters.",5.1. Time Series Extrapolation,[0],[0]
"We refer to this baseline as “heuristic”.
",5.1. Time Series Extrapolation,[0],[0]
"The results for Airline are shown in Figure 3, while the
Table 1.",5.1. Time Series Extrapolation,[0],[0]
"Average test RMSE and log-likelihood for regression benchmarks with random splits.
",5.1. Time Series Extrapolation,[0],[0]
"TEST RMSE TEST LOG-LIKELIHOOD
DATASET BBB GP-RBF GP-SM4 GP-NKN BBB GP-RBF GP-SM4 GP-NKN BOSTON 3.171±0.149 2.753±0.137 2.979±0.162",5.1. Time Series Extrapolation,[0],[0]
2.506±0.150 -2.602±0.031 -2.434±0.069 -2.518±0.107 -2.394±0.080 CONCRETE 5.678±0.087 4.685±0.137 3.730±0.190 3.688±0.249 -3.149±0.018,5.1. Time Series Extrapolation,[0],[0]
-2.948±0.025,5.1. Time Series Extrapolation,[0],[0]
-2.662±0.053 -2.842±0.263 ENERGY 0.565±0.018,5.1. Time Series Extrapolation,[0],[0]
0.471±0.013 0.316±0.018 0.254±0.020,5.1. Time Series Extrapolation,[0],[0]
-1.500±0.006 -0.673±0.035,5.1. Time Series Extrapolation,[0],[0]
-0.320±0.089 -0.213±0.162 KIN8NM 0.080±0.001 0.068±0.001 0.061±0.000 0.067±0.001,5.1. Time Series Extrapolation,[0],[0]
1.111±0.007 1.287±0.007 1.387±0.006 1.291±0.006 NAVAL 0.000±0.000 0.000±0.000 0.000±0.000 0.000±0.000 6.143±0.032 9.557±0.001 9.923±0.000 9.916±0.000 POW.,5.1. Time Series Extrapolation,[0],[0]
PLANT 4.023±0.036 3.014±0.068 2.781±0.071 2.675±0.074,5.1. Time Series Extrapolation,[0],[0]
-2.807±0.010 -2.518±0.020,5.1. Time Series Extrapolation,[0],[0]
-2.450±0.022 -2.406±0.023,5.1. Time Series Extrapolation,[0],[0]
WINE 0.643±0.012 0.597±0.013 0.579±0.012 0.523±0.011,5.1. Time Series Extrapolation,[0],[0]
-0.977±0.017 0.723±0.067 0.652±0.060 0.852±0.064,5.1. Time Series Extrapolation,[0],[0]
YACHT 1.174±0.086 0.447±0.083 0.436±0.070 0.305±0.060,5.1. Time Series Extrapolation,[0],[0]
-2.408±0.007 -0.714±0.449,5.1. Time Series Extrapolation,[0],[0]
"-0.891±0.523 -0.116±0.270
Figure 3.",5.1. Time Series Extrapolation,[0],[0]
Extrapolation results of NKN on the Airline dataset.,5.1. Time Series Extrapolation,[0],[0]
"“Heuristic” denotes linear combination of RBF, PER, LIN, and Constant kernels.",5.1. Time Series Extrapolation,[0],[0]
"AS represents Automatic Statistician (Duvenaud et al., 2013).",5.1. Time Series Extrapolation,[0],[0]
"The red circles are the training points, and the curve after the blue dashed line is the extrapolation result.",5.1. Time Series Extrapolation,[0],[0]
"Shaded areas represent 1 standard deviation.
results for Mauna and Solar are shown in Figures 8 and 9 in the Appendix.",5.1. Time Series Extrapolation,[0],[0]
All three models were able to capture the periodic and increasing patterns.,5.1. Time Series Extrapolation,[0],[0]
"However, the heuristic kernel failed to fit the data points well or capture the increasing amplitude, stemming from its lack of PER*LIN structure.",5.1. Time Series Extrapolation,[0],[0]
"In comparison, both AS and NKN fit the train-
ing points perfectly, and generated sensible extrapolations.",5.1. Time Series Extrapolation,[0],[0]
"However, the NKN was far faster to train because it avoided discrete search: for the Airline dataset, the NKN took only 201 seconds, compared with 6147 seconds for AS.",5.1. Time Series Extrapolation,[0],[0]
"To evaluate the predictive performance of NKN, we first conducted experiments on regression benchmark datasets from the UCI collection (Asuncion & Newman, 2007).",5.2.1. RANDOM TRAINING/TEST SPLITS,[0],[0]
"Following the settings in Hernández-Lobato & Adams (2015), the datasets were randomly split into training and testing sets, comprising 90% and 10% of the data respectively.",5.2.1. RANDOM TRAINING/TEST SPLITS,[0],[0]
This splitting process was repeated 10 times to reduce variability.,5.2.1. RANDOM TRAINING/TEST SPLITS,[0],[0]
"We compared NKN to RBF and SM (Wilson & Adams, 2013) kernels, and the popular Bayesian neural network method Bayes-by-Backprop (BBB) (Blundell et al., 2015).",5.2.1. RANDOM TRAINING/TEST SPLITS,[0],[0]
"For the SM kernel, we used 4 mixture components, so we denote it as SM-4.",5.2.1. RANDOM TRAINING/TEST SPLITS,[0],[0]
"For all experiments, the NKN uses 6 primitive kernels including 2 RQ, 2 RBF, and 2 LIN.",5.2.1. RANDOM TRAINING/TEST SPLITS,[0],[0]
The following layers are organized as Linear8-Product4-Linear4-Product2-Linear1.2,5.2.1. RANDOM TRAINING/TEST SPLITS,[0],[0]
We trained both the variance and d-dimensional lengthscales for all kernels.,5.2.1. RANDOM TRAINING/TEST SPLITS,[0],[0]
"As a result, for d dimensional inputs, SM-4 has 8d+12 trainable parameters and NKN has 4d+ 85 parameters.
",5.2.1. RANDOM TRAINING/TEST SPLITS,[0],[0]
"As shown in Table 1, BBB performed worse than the Gaussian processes methods on all datasets.",5.2.1. RANDOM TRAINING/TEST SPLITS,[0],[0]
"On the other hand, NKN and SM-4 performed consistently better than the standard RBF kernel in terms of both RMSE and log-likelihoods.",5.2.1. RANDOM TRAINING/TEST SPLITS,[0],[0]
"Moreover, the NKN outperformed the SM-4 kernel on all datasets other than Naval and Kin8nm.",5.2.1. RANDOM TRAINING/TEST SPLITS,[0],[0]
"Since the experiments just presented used random training/test splits, they can be thought of as measuring interpolation performance.",5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
"We are also interested in measuring extrapolation performance, since this is a better measure of whether the model has captured the underlying structure.",5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
"In
2The number for each layer represents the output dimension.
order to test this, we sorted the data points according to their projection onto the top principal component of the data.",5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
"The top 1/15 and bottom 1/15 of the data were used as test data, and the remainder was used as training data.
",5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
We compared NKN with standard RBF and SM kernels using the same architectural settings as in the previous section.,5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
"All models were trained for 20,000 iterations.",5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
"To select the mixture number of SM kernels, we further subdivided the training set into a training and validation set, using the same PCA-splitting method as described above.",5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
"For each dataset, we trained SM on the sub-training set using {1, 2, 3, 4} mixture components and selected the number based on validation error.",5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
(We considered up to 4 mixture components in order to roughly match the number of parameters for NKN.),5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
Then we retrained the SM kernel using the combined training and validation sets.,5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
"The resulting test RMSE and log-likelihood are shown in Table 2.
",5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
"As seen in Table 2, all three kernels performed significantly worse compared with Table 1, consistent with the intuition that extrapolation is more difficult that interpolation.",5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
"However, we can see NKN outperformed SM for most of the datasets.",5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
"In particular, for small datasets (and hence more chance to overfit), NKN performed better than SM by a substantial margin, with the exception of the Energy dataset.",5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
"This demonstrates the NKN was better able to capture the underlying structure, rather than overfitting the training points.",5.2.2. MEASURING EXTRAPOLATION WITH PCA SPLITS,[0],[0]
"Bayesian optimization (Brochu et al., 2010; Snoek et al., 2012) is a technique for optimization expensive black-box functions which repeatedly queries the function, fits a surrogate function to past queries, and maximizes an acquisition function to choose the next query.",5.3. Bayesian Optimization,[0],[0]
It’s important to model both the predictive mean (to query points that are likely to perform well) and the predictive variance (to query points that have high uncertainty).,5.3. Bayesian Optimization,[0],[0]
"Typically, the surrogate functions are estimated using a GP with a simple kernel, such as Matern.",5.3. Bayesian Optimization,[0],[0]
"But simple kernels lead to inefficient exploration due to the curse of dimensionality, leading various researchers to consider additive kernels (Kandasamy et al., 2015; Gardner et al., 2017; Wang et al., 2017).",5.3. Bayesian Optimization,[0],[0]
"Since additivity is among the patterns the NKN can learn, we were interested in testing its performance on Bayesian optimization tasks with additive structure.",5.3. Bayesian Optimization,[0],[0]
"We used Expectated Improvement (EI) to perform BO.
",5.3. Bayesian Optimization,[0],[0]
"Following the protocol in Kandasamy et al. (2015); Gardner et al. (2017); Wang et al. (2017), we evaluated the performance on three toy function benchmarks with additive structure,
f(x) =
|P |X
i=1
f i (x[P i ]) (11)
",5.3. Bayesian Optimization,[0],[0]
The d-dimensional Styblinski-Tang function and Michalewicz function have fully additive structure with independent dimensions.,5.3. Bayesian Optimization,[0],[0]
"In our experiment, we set d = 10 and explored the function over domain [ 4, 4]d for Styblinski-Tang and [0,⇡]d for Michalewicz.",5.3. Bayesian Optimization,[0],[0]
"We also experimented with a transformed Styblinski-Tang function, which applies Styblinski-Tang function on partitioned dimension groups.
",5.3. Bayesian Optimization,[0],[0]
"For modelling additive functions with GP, the kernel can decompose as a summation between additive groups as well.",5.3. Bayesian Optimization,[0],[0]
"k(x,x0)",5.3. Bayesian Optimization,[0],[0]
= P|P | i=1,5.3. Bayesian Optimization,[0],[0]
"ki(x[Pi],x 0",5.3. Bayesian Optimization,[0],[0]
"[P i
]).",5.3. Bayesian Optimization,[0],[0]
"We considered an oracle kernel, which was a linear combination of RBF kernels
corresponding to the true additive structure of the function.",5.3. Bayesian Optimization,[0],[0]
Both the kernel parameters and the combination coefficients were trained with maximum likelihood.,5.3. Bayesian Optimization,[0],[0]
We also tested the standard RBF kernel without additive structure.,5.3. Bayesian Optimization,[0],[0]
"For the NKN, we used d RBF kernels over individual input dimensions as the primitive kernels.",5.3. Bayesian Optimization,[0],[0]
The following layers were arranged as Linear8-Product4-Linear4-Product2-Linear1.,5.3. Bayesian Optimization,[0],[0]
"Note that, although the primitive kernels corresponded to seperate dimensions, NKN can represent additive structure through these linear combination and product operations.",5.3. Bayesian Optimization,[0],[0]
"In all cases, we used Expected Improvement as the acquisition function.
",5.3. Bayesian Optimization,[0],[0]
"As shown in Figure 4, for all three benchmarks, the oracle kernel not only converged faster than RBF kernel, but also found smaller function values by a large margin.",5.3. Bayesian Optimization,[0],[0]
"In comparsion, we can see that although NKN converged slower than oracle in the beginning, it caught up with oracle eventually and reached the same function value.",5.3. Bayesian Optimization,[0],[0]
This suggests that the NKN is able to exploit additivity for Bayesian optimization.,5.3. Bayesian Optimization,[0],[0]
"Based on Wilson et al. (2014), we evaluated the NKN on texture exploration, a test of the network’s ability to learn local correlations as well as complex quasi-periodic patterns.",5.4. Texture Extrapolation,[0],[0]
"From the original 224 ⇥ 224 images, we removed a 60 ⇥ 80 region, as shown in Figure 5(a).",5.4. Texture Extrapolation,[0],[0]
"From a regression perspective, this corresponds to 45376 training examples and 4800 test examples, where the inputs are 2-D pixel locations and the outputs are pixel intensities.",5.4. Texture Extrapolation,[0],[0]
"To scale our algorithms to this setting, we used the approach of Wilson et al. (2014).",5.4. Texture Extrapolation,[0],[0]
"In particular, we exploited the grid structure of texture images to represent the kernel matrix for the full image as a Kronecker product of kernel matrices along each dimension (Saatçi, 2012).",5.4. Texture Extrapolation,[0],[0]
"Since some of the grid points are unobserved, we followed the algorithm in Wilson et al.
(2014) complete the grid with imaginary observations, and placed infinite measurement noise on these observations.
",5.4. Texture Extrapolation,[0],[0]
"To reconstruct the missing region, we used an NKN with 4 primitive kernels: LIN, RBF, RQ, and PER.",5.4. Texture Extrapolation,[0],[0]
"As shown in Figure 5(c), our NKN was able to learn and extrapolate complex image patterns.",5.4. Texture Extrapolation,[0],[0]
"As baselines, we tested RBF and PER kernels; those results are shown in Figure 5(d) and Figure 5(e).",5.4. Texture Extrapolation,[0],[0]
"The RBF kernel was unable to extrapolate to the missing region, while the PER kernel was able to extrapolate beyond the training data since the image pattern is almost exactly periodic.",5.4. Texture Extrapolation,[0],[0]
"We also tested the spectral mixture (SM) kernel, which has previously shown promising results in texture extrapolation.",5.4. Texture Extrapolation,[0],[0]
"Even with 10 mixture components, its extrapolations were blurrier compared to those of the NKN.",5.4. Texture Extrapolation,[0],[0]
"The second row shows extrapolations on an irregular paved pattern, which we believe is more difficult.",5.4. Texture Extrapolation,[0],[0]
The NKN still provided convincing extrapolation.,5.4. Texture Extrapolation,[0],[0]
"By contrast, RBF and PER kernels were unable to capture enough information to reconstruct the missing region.",5.4. Texture Extrapolation,[0],[0]
"We proposed the Neural Kernel Network (NKN), a differentiable architecture for compositional kernel learning.",6. Conclusion,[0],[0]
"Since the architecture is based on the composition rules for kernels, the NKN can compactly approximate the kernel structures from the Automatic Statistician (AS) grammar.",6. Conclusion,[0],[0]
"But because the architecture is differentiable, the kernel can be learned orders-of-magnitude faster than the AS using gradient-based optimization.",6. Conclusion,[0],[0]
"We demonstrated the universality of the NKN for the class of stationary kernels, and showed that the network’s representations can be made significantly more compact using complex-valued kernels.",6. Conclusion,[0],[0]
"Empirically, we found the NKN is capable of pattern discovery and extrapolation in both 1-D time series datasets and 2-D textures, and can find and exploit additive structure for Bayesian Optimization.",6. Conclusion,[0],[0]
We thank David Duvenaud and Jeongseop Kim for their insightful comments and discussions on this project.,Acknowledgements,[0],[0]
SS was supported by a Connaught New Researcher Award and a Connaught Fellowship.,Acknowledgements,[0],[0]
GZ was supported by an NSERC Discovery Grant.,Acknowledgements,[0],[0]
"The generalization properties of Gaussian processes depend heavily on the choice of kernel, and this choice remains a dark art.",abstractText,[0],[0]
"We present the Neural Kernel Network (NKN), a flexible family of kernels represented by a neural network.",abstractText,[0],[0]
"The NKN’s architecture is based on the composition rules for kernels, so that each unit of the network corresponds to a valid kernel.",abstractText,[0],[0]
"It can compactly approximate compositional kernel structures such as those used by the Automatic Statistician (Lloyd et al., 2014), but because the architecture is differentiable, it is end-to-end trainable with gradientbased optimization.",abstractText,[0],[0]
We show that the NKN is universal for the class of stationary kernels.,abstractText,[0],[0]
"Empirically we demonstrate NKN’s pattern discovery and extrapolation abilities on several tasks that depend crucially on identifying the underlying structure, including time series and texture extrapolation, as well as Bayesian optimization.",abstractText,[0],[0]
Differentiable Compositional Kernel Learning for Gaussian Processes,title,[0],[0]
"structured combinatorial problems by iteratively breaking them down into smaller subproblems. In spite of their versatility, many DP algorithms are non-differentiable, which hampers their use as a layer in neural networks trained by backpropagation. To address this issue, we propose to smooth the max operator in the dynamic programming recursion, using a strongly convex regularizer. This allows to relax both the optimal value and solution of the original combinatorial problem, and turns a broad class of DP algorithms into differentiable operators. Theoretically, we provide a new probabilistic perspective on backpropagating through these DP operators, and relate them to inference in graphical models. We derive two particular instantiations of our framework, a smoothed Viterbi algorithm for sequence prediction and a smoothed DTW algorithm for time-series alignment. We showcase these instantiations on structured prediction (audio-to-score alignment, NER) and on structured and sparse attention for translation.
Modern neural networks are composed of multiple layers of nested functions. Although layers usually consist of elementary linear algebraic operations and simple nonlinearities, there is a growing need for layers that output the value or the solution of an optimization problem. This can be used to design loss functions that capture relevant regularities in the input (Lample et al., 2016; Cuturi & Blondel, 2017) or to create layers that impose prior structure on the output (Kim et al., 2017; Amos & Kolter, 2017; Niculae & Blondel, 2017; Djolonga & Krause, 2017).
Among these works, several involve a convex optimization
1Inria, CEA, Université Paris-Saclay, Gif-sur-Yvette, France. Work performed at 2NTT Communication Science Laboratories, Kyoto, Japan. Correspondence to: AM <arthur.mensch@m4x.org>, MB <mathieu@mblondel.org>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).
problem (Amos & Kolter, 2017; Niculae & Blondel, 2017; Djolonga & Krause, 2017); others solve certain combinatorial optimization problems by dynamic programming (Kim et al., 2017; Cuturi & Blondel, 2017; Nowak et al., 2018). However, because dynamic programs (Bellman, 1952) are usually non-differentiable, virtually all these works resort to the formalism of conditional random fields (CRFs) (Lafferty et al., 2001), which can be seen as changing the semiring used by the dynamic program — replacing all values by their exponentials and all (max,+) operations with (+,×) operations (Verdu & Poor, 1987). While this modification smoothes the dynamic program, it looses the sparsity of solutions, since hard assignments become soft ones. Moreover, a general understanding of how to relax and differentiate dynamic programs is lacking. In this work, we propose to do so by leveraging smoothing (Moreau, 1965; Nesterov, 2005) and backpropagation (Linnainmaa, 1970). We make the following contributions.
1) We present a unified framework for turning a broad class of dynamic programs (DP) into differentiable operators. Unlike existing works, we propose to change the semiring to use (maxΩ,+) operations, where maxΩ is a max operator smoothed with a strongly convex regularizer Ω (§1).
2) We show that the resulting DP operators, that we call DPΩ, are smoothed relaxations of the original DP algorithm and satisfy several key properties, chief among them convexity. In addition, we show that their gradient,∇DPΩ, is equal to the expected trajectory of a certain random walk and can be used as a sound relaxation to the original dynamic program’s solution. Using negative entropy for Ω recovers existing CRF-based works from a different perspective — we provide new arguments as to why this Ω is a good choice. On the other hand, using squared ℓ2 norm for Ω leads to new algorithms whose expected solution is sparse. We derive a clean and efficient method to backpropagate gradients, both through DPΩ and ∇DPΩ. This allows us to define differentiable DP layers that can be incorporated in neural networks trained end-to-end (§2).
3) We illustrate how to to derive two particular instantiations of our framework, a smoothed Viterbi algorithm for sequence prediction and a smoothed DTW algorithm for supervised time-series alignment (§3). The latter is illustrated in Figure 1. Finally, we showcase these two instanti-
ations on structured prediction tasks (§4) and on structured attention for neural machine translation (§5).
Notation. We denote scalars, vectors and matrices using lower-case, bold lower-case and bold upper-case letters, e.g., y, y and Y . We denote the elements of Y by yi,j and its rows by yi. We denote the Frobenius inner product between A and B by 〈A,B〉 , ∑
i,j ai,jbi,j . We denote the
(D− 1)-probability simplex by△D , {λ ∈ RD+ : ‖λ‖1 = 1}. We write conv(Y) , { ∑
Y ∈Y λY Y : λ ∈ △ |Y|} the
convex hull of Y , [N ] the set {1, . . . , N} and supp(x) , {j ∈ [D] : xj 6= 0} the support of x ∈ R D. We denote the Shannon entropy by H(q) , ∑
i qi log qi.
We have released an optimized and modular PyTorch implementation for reproduction and reuse.",text,[0],[0]
"In this section, we introduce smoothed max operators (Nesterov, 2005; Beck & Teboulle, 2012; Niculae & Blondel, 2017), that will serve as a powerful and generic abstraction to define differentiable dynamic programs in §2.",1. Smoothed max operators,[0],[0]
Let Ω : RD → R be a strongly convex function on△D and let x ∈ RD.,1. Smoothed max operators,[0],[0]
"We define the max operator smoothed by Ω as:
maxΩ(x) , max q∈△D 〈q,x〉 − Ω(q).",1. Smoothed max operators,[0],[0]
"(1)
In other words, maxΩ is the convex conjugate of Ω, restricted to the simplex.",1. Smoothed max operators,[0],[0]
"From the duality between strong convexity and smoothness, maxΩ is smooth: differentiable everywhere and with Lipschitz continuous gradient.",1. Smoothed max operators,[0],[0]
"Since the argument that achieves the maximum in (1) is unique,
from Danskin’s theorem (1966), it is equal to the gradient:
∇maxΩ(x) = argmax q∈△D 〈q,x〉 − Ω(q).
",1. Smoothed max operators,[0],[0]
The gradient is differentiable almost everywhere for any strongly-convex Ω (everywhere for negentropy).,1. Smoothed max operators,[0],[0]
"Next, we state properties that will be useful throughout this paper.
",1. Smoothed max operators,[0],[0]
Lemma 1.,1. Smoothed max operators,[0],[0]
"Properties of maxΩ operators
Let x = (x1, . . .",1. Smoothed max operators,[0],[0]
", xD) ⊤ ∈ RD.
1.",1. Smoothed max operators,[0],[0]
"Boundedness: If Ω is lower-bounded by LΩ,D and upper-bounded by UΩ,D on the simplex△ D, then
max(x)− UΩ,D ≤ maxΩ(x) ≤",1. Smoothed max operators,[0],[0]
"max(x)− LΩ,D.
2.",1. Smoothed max operators,[0],[0]
"Distributivity of + over maxΩ: maxΩ(x+ c1) = maxΩ(x) + c ∀c ∈ R.
3.",1. Smoothed max operators,[0],[0]
"Commutativity: If Ω(Pq) = Ω(q), where P is a permutation matrix, then maxΩ(Px) = maxΩ(x).
4.",1. Smoothed max operators,[0],[0]
"Non-decreasingness in each coordinate:
maxΩ(x) ≤ maxΩ(y) ∀x ≤ y
5.",1. Smoothed max operators,[0],[0]
"Insensitivity to −∞: xj = −∞⇒ ∇maxΩ(x)j = 0.
",1. Smoothed max operators,[0],[0]
Proofs are given in §A.1.,1. Smoothed max operators,[0],[0]
"In particular, property 3 holds whenever Ω(q) =
∑D i=1 ω(qi), for some function ω.",1. Smoothed max operators,[0],[0]
"We
focus in this paper on two specific regularizers Ω: the negentropy −H and the squared ℓ2 norm.",1. Smoothed max operators,[0],[0]
"For these choices, all properties above are satisfied and we can derive closedform expressions for maxΩ, its gradient and its Hessian — see §B.1.",1. Smoothed max operators,[0],[0]
"When using negentropy, maxΩ becomes the log-sum-exp and∇maxΩ the softmax.",1. Smoothed max operators,[0],[0]
"The former satisfies associativity, which as we shall see, makes it natural to use in dynamic programming.",1. Smoothed max operators,[0],[0]
"With the squared ℓ2 regularization, as observed by Martins & Astudillo (2016); Niculae & Blondel (2017), the gradient∇maxΩ is sparse.",1. Smoothed max operators,[0],[0]
This will prove useful to enforce sparsity in the models we study.,1. Smoothed max operators,[0],[0]
Dynamic programming (DP) is a generic way of solving combinatorial optimization problems by recursively solving problems on smaller sets.,2. Differentiable DP layers,[0],[0]
"We first introduce this category of algorithms in a broad setting, then use smoothed max operators to define differentiable DP layers.",2. Differentiable DP layers,[0],[0]
"Every problem solved by dynamic programming reduces to finding the highest-scoring path between a start node and an end node, on a weighted directed acyclic graph (DAG).",2.1. Dynamic programming on a DAG,[0],[0]
"We therefore introduce our formalism on this generic problem, and give concrete examples in §3.
",2.1. Dynamic programming on a DAG,[0],[0]
"Formally, let G = (V, E) be a DAG, with nodes V and edges E .",2.1. Dynamic programming on a DAG,[0],[0]
"We write N = |V| ≥ 2 the number of nodes.
",2.1. Dynamic programming on a DAG,[0],[0]
"Without loss of generality, we number the nodes in topological order, from 1 (start) to N (end), and thus V =",2.1. Dynamic programming on a DAG,[0],[0]
[N ].,2.1. Dynamic programming on a DAG,[0],[0]
"Node 1 is the only node without parents, and node N the only node without children.",2.1. Dynamic programming on a DAG,[0],[0]
"Every directed edge (i, j) from a parent node j to a child node i has a weight θi,j ∈ R.",2.1. Dynamic programming on a DAG,[0],[0]
We gather the edge weights in a matrix θ ∈ Θ ⊆,2.1. Dynamic programming on a DAG,[0],[0]
"RN×N , setting θi,j = −∞ if (i, j) /∈",2.1. Dynamic programming on a DAG,[0],[0]
"E and θ1,1 = 1.",2.1. Dynamic programming on a DAG,[0],[0]
We consider the set Y of all paths in G from node 1 to node N .,2.1. Dynamic programming on a DAG,[0],[0]
"Any path Y ∈ Y can be represented as a N × N binary matrix, with yi,j = 1 if the path goes through the edge (i, j) and yi,j = 0 otherwise.",2.1. Dynamic programming on a DAG,[0],[0]
"In the sequel, paths will have a one-to-one correspondence with discrete structures such as sequences or alignments.",2.1. Dynamic programming on a DAG,[0],[0]
"Using this representation, 〈Y ,θ〉 corresponds to the cumulated sum of edge weights, along the path Y .",2.1. Dynamic programming on a DAG,[0],[0]
"The computation of the highest score among all paths amounts to solving the combinatorial problem
LP(θ) , max Y ∈Y 〈Y ,θ〉 ∈ R. (2)
",2.1. Dynamic programming on a DAG,[0],[0]
"Although the size of Y is in general exponential in N , LP(θ) can be computed in one topologically-ordered pass over G using dynamic programming.",2.1. Dynamic programming on a DAG,[0],[0]
"We let Pi be the set of parent nodes of node i in graph G and define recursively
v1(θ) , 0
∀",2.1. Dynamic programming on a DAG,[0],[0]
i ∈,2.1. Dynamic programming on a DAG,[0],[0]
"[2, . . .",2.1. Dynamic programming on a DAG,[0],[0]
", N ] : vi(θ) , max j∈Pi θi,j + vj(θ).",2.1. Dynamic programming on a DAG,[0],[0]
"(3)
This algorithm outputs DP(θ) , vN (θ).",2.1. Dynamic programming on a DAG,[0],[0]
"We now show that this is precisely the highest score among all paths.
",2.1. Dynamic programming on a DAG,[0],[0]
Proposition 1.,2.1. Dynamic programming on a DAG,[0],[0]
"Optimality of dynamic programming
∀θ ∈",2.1. Dynamic programming on a DAG,[0],[0]
"Θ : DP(θ) = LP(θ)
",2.1. Dynamic programming on a DAG,[0],[0]
"The optimality of recursion (3) is well-known (Bellman, 1952).",2.1. Dynamic programming on a DAG,[0],[0]
"We prove it again with our formalism in §A.2, since it exhibits the two key properties that the max operator must satisfy to guarantee optimality: distributivity of + over it and associativity.",2.1. Dynamic programming on a DAG,[0],[0]
"The cost of computing DP(θ) is O(|E|), which is exponentially better than O(|Y|).
",2.1. Dynamic programming on a DAG,[0],[0]
"In many applications, we will often rather be interested in the argument that achieves the maximum, i.e., one of the highest-scoring paths
Y ⋆(θ) ∈ argmax Y ∈Y 〈Y ,θ〉.",2.1. Dynamic programming on a DAG,[0],[0]
"(4)
This argument can be computed by backtracking, that we now relate to computing subgradients of LP(θ).
",2.1. Dynamic programming on a DAG,[0],[0]
"Linear program, lack of differentiality.",2.1. Dynamic programming on a DAG,[0],[0]
"Unfortunately, LP(θ) is not differentiable everywhere.",2.1. Dynamic programming on a DAG,[0],[0]
"To see why this is the case, notice that (2) can be rewritten as a linear program over the convex polytope conv(Y):
LP(θ) = max Y ∈conv(Y) 〈Y ,θ〉.
",2.1. Dynamic programming on a DAG,[0],[0]
"From the generalized Danskin theorem (Bertsekas, 1971),
Y ⋆(θ) ∈ ∂LP(θ) = argmax Y ∈conv(Y) 〈Y ,θ〉,
where ∂ denotes the subdifferential of LP(θ), i.e., the set of subgradients.",2.1. Dynamic programming on a DAG,[0],[0]
"When Y ⋆(θ) is unique, ∂LP(θ) is a singleton and Y ⋆ is equal to the gradient of LP(θ), that we write∇LP(θ).",2.1. Dynamic programming on a DAG,[0],[0]
"Unfortunately, Y ⋆(θ) is not always unique, meaning that LP(θ) is not differentiable everywhere.",2.1. Dynamic programming on a DAG,[0],[0]
"As we will show in §4.2, this hinders optimization as we can only train models involving LP(θ) with subgradient methods.",2.1. Dynamic programming on a DAG,[0],[0]
"Worse, Y ⋆(θ), a function from Θ to Y , is discontinuous and has null or undefined derivatives.",2.1. Dynamic programming on a DAG,[0],[0]
It is thus impossible to use it in a model trained by gradient descent.,2.1. Dynamic programming on a DAG,[0],[0]
"To address the lack of differentiability of dynamic programming, we introduce the operator maxΩ, presented in §1, and consider two approaches.
",2.2. Smoothed max layers,[0],[0]
Smoothing the linear program.,2.2. Smoothed max layers,[0],[0]
"Let us define the Ωsmoothed maximum of a function f : Y → R over a finite set Y using the following shorthand notation:
maxΩ Y ∈Y f(Y ) , maxΩ((f(Y ))",2.2. Smoothed max layers,[0],[0]
"Y ∈Y).
",2.2. Smoothed max layers,[0],[0]
"A natural way to circumvent the lack of differentiability of LP(θ) is then to replace the global max operator by maxΩ:
LPΩ(θ) , maxΩ Y ∈Y 〈Y ,θ〉 ∈ R. (5)
",2.2. Smoothed max layers,[0],[0]
"From §1, LPΩ(θ) is convex and, as long as Ω is strongly convex, differentiable everywhere.",2.2. Smoothed max layers,[0],[0]
"In addition, ∇LPΩ(θ) is Lipschitz continuous and thus differentiable almost everywhere.",2.2. Smoothed max layers,[0],[0]
"Unfortunately, solving (5) for general Ω is likely intractable when Y has an exponential size.
",2.2. Smoothed max layers,[0],[0]
Smoothing the dynamic program.,2.2. Smoothed max layers,[0],[0]
"As a tractable alternative, we propose an algorithmic smoothing.",2.2. Smoothed max layers,[0],[0]
"Namely, we replace max by maxΩ locally within the DP recursion.",2.2. Smoothed max layers,[0],[0]
"Omitting the dependence on Ω, this defines a smoothed recursion over the new sequence (vi(θ))",2.2. Smoothed max layers,[0],[0]
N i=1,2.2. Smoothed max layers,[0],[0]
":
v1(θ)",2.2. Smoothed max layers,[0],[0]
", 0
∀i ∈",2.2. Smoothed max layers,[0],[0]
"[2, . . .",2.2. Smoothed max layers,[0],[0]
", N ] : vi(θ) , maxΩ j∈Pi θi,j + vj(θ).",2.2. Smoothed max layers,[0],[0]
"(6)
The new algorithm outputs DPΩ(θ), vN (θ), the smoothed highest score.",2.2. Smoothed max layers,[0],[0]
Smoothing the max operator locally brings the same benefit as before — DPΩ(θ) is smooth and ∇DPΩ(θ) is differentiable almost everywhere.,2.2. Smoothed max layers,[0],[0]
"However, computing DPΩ(θ) is now always tractable, since it simply requires to evaluate (vi(θ))",2.2. Smoothed max layers,[0],[0]
N i=1,2.2. Smoothed max layers,[0],[0]
"in topological order, as in
the original recursion (3).",2.2. Smoothed max layers,[0],[0]
"Although LPΩ(θ) and DPΩ(θ) are generally different (in fact, LPΩ(θ) ≥ DPΩ(θ) for all θ ∈ Θ), we now show that DPΩ(θ) is a sensible approximation of LP(θ) in several respects.
",2.2. Smoothed max layers,[0],[0]
Proposition 2.,2.2. Smoothed max layers,[0],[0]
"Properties of DPΩ
1. DPΩ(θ) is convex
2. LP(θ)−DPΩ(θ) is bounded above and below: it lies in (N − 1)[LΩ,N , UΩ,N ], with Lemma 1 notations.
3.",2.2. Smoothed max layers,[0],[0]
"When Ω is separable, DPΩ(θ) = LPΩ(θ)",2.2. Smoothed max layers,[0],[0]
"if and only if Ω = −γH , where γ ≥ 0.
Proofs are given in §A.3.",2.2. Smoothed max layers,[0],[0]
The first claim can be surprising due to the recursive definition of DPΩ(θ).,2.2. Smoothed max layers,[0],[0]
The second claim implies that DPγΩ(θ) converges to LP(θ) when the regularization vanishes: DPγΩ(θ)→γ→0 LP(θ); LPγΩ(θ) also satisfies this property.,2.2. Smoothed max layers,[0],[0]
The “if” direction of the third claim follows by showing that max−γH satisfies associativity.,2.2. Smoothed max layers,[0],[0]
"This recovers known results in the framework of message passing algorithms for probabilistic graphical models (e.g., Wainwright & Jordan, 2008, Section 4.1.3), with a more algebraic point of view.",2.2. Smoothed max layers,[0],[0]
"The key role that the distributive and associative properties play into breaking down large problems into smaller ones has long been noted (Verdu & Poor, 1987; Aji & McEliece, 2000).",2.2. Smoothed max layers,[0],[0]
"However, the “and only if” part of the claim is new to our knowledge.",2.2. Smoothed max layers,[0],[0]
"Its proof shows that max−γH is the only maxΩ satisfying associativity, exhibiting a functional equation from information theory (Horibe, 1988).",2.2. Smoothed max layers,[0],[0]
"While this provides an argument in favor of entropic regularization, ℓ22 regularization has different benefits in terms of sparsity of the solutions.",2.2. Smoothed max layers,[0],[0]
"It is easy to check that ∇LPΩ(θ) belongs to conv(Y) and can be interpreted as an expected path under some distribution induced by ∇maxΩ, over all possible Y ∈ Y — see §A.4 for details.",2.3. Relaxed argmax layers,[0],[0]
This makes ∇LPΩ(θ) interpretable as a continuous relaxation of the highest-scoring path Y ⋆(θ) defined in (4).,2.3. Relaxed argmax layers,[0],[0]
"However, like LPΩ(θ), computing ∇LPΩ(θ) is likely intractable in the general case.",2.3. Relaxed argmax layers,[0],[0]
"Fortunately, ∇DPΩ(θ) is always easily computable by backpropagation and enjoys similar properties, as we now show.
",2.3. Relaxed argmax layers,[0],[0]
Computing ∇DPΩ(θ).,2.3. Relaxed argmax layers,[0],[0]
Computing ∇DPΩ(θ) can be broken down into two steps.,2.3. Relaxed argmax layers,[0],[0]
"First, we compute and record the local gradients alongside the recursive step (6):
∀",2.3. Relaxed argmax layers,[0],[0]
i ∈,2.3. Relaxed argmax layers,[0],[0]
"[N ] : qi(θ) , ∇maxΩ(θi + v(θ)) ∈ △ N ,
where v(θ) , (v1(θ), . . .",2.3. Relaxed argmax layers,[0],[0]
", vN (θ)).",2.3. Relaxed argmax layers,[0],[0]
"Since we assume that θi,j = −∞ if (i, j) 6∈ E , we have supp(qi(θ))",2.3. Relaxed argmax layers,[0],[0]
= Pi.,2.3. Relaxed argmax layers,[0],[0]
"This ensures that, similarly to vi(θ), qi(θ) exclusively depends on (vj(θ))j∈Pi .",2.3. Relaxed argmax layers,[0],[0]
Let Cj be the children of node j ∈,2.3. Relaxed argmax layers,[0],[0]
[N ].,2.3. Relaxed argmax layers,[0],[0]
"A
straighforward application of backpropagation (cf.",2.3. Relaxed argmax layers,[0],[0]
"§A.5) yields a recursion run in reverse-topological order, starting from node j = N − 1 down to j = 1:
∀",2.3. Relaxed argmax layers,[0],[0]
i ∈,2.3. Relaxed argmax layers,[0],[0]
"Cj : ei,j ← ēiqi,j then ēj ← ∑
i∈Cj
ei,j ,
where ēN ← 1 and ei,j ← 0 for (i, j) /∈",2.3. Relaxed argmax layers,[0],[0]
E .,2.3. Relaxed argmax layers,[0],[0]
The final output is ∇DPΩ(θ) =,2.3. Relaxed argmax layers,[0],[0]
"E. Assuming maxΩ can be computed in linear time, the total cost is O(|E|), the same as DP(θ).",2.3. Relaxed argmax layers,[0],[0]
"Pseudo-code is summarized in §A.5.
Associated path distribution.",2.3. Relaxed argmax layers,[0],[0]
The backpropagation we derived has a probabilistic interpretation.,2.3. Relaxed argmax layers,[0],[0]
"Indeed, Q(θ) ∈ R N×N can be interpreted as a transition matrix: it defines a random walk on the graph G, i.e., a finite Markov chain with states V and transition probabilities supported by E .",2.3. Relaxed argmax layers,[0],[0]
"The random walk starts from node N and, when at node i, hops to node j ∈ Pi with probability qi,j .",2.3. Relaxed argmax layers,[0],[0]
"It always ends at node 1, which is absorbing.",2.3. Relaxed argmax layers,[0],[0]
"The walk follows the path Y ∈ Y with a probability pθ,Ω(Y ), which is simply the product of the qi,j of visited edges.",2.3. Relaxed argmax layers,[0],[0]
"Thus, Q(θ) defines a path distribution pθ,Ω. Our next proposition shows that ∇DPΩ(Y ) ∈ conv(Y) and is equal to the expected path Eθ,Ω[Y ] under that distribution.
",2.3. Relaxed argmax layers,[0],[0]
Proposition 3.,2.3. Relaxed argmax layers,[0],[0]
∇DPΩ(θ),2.3. Relaxed argmax layers,[0],[0]
"as an expected path
∀θ ∈ Θ : ∇DPΩ(θ) = Eθ,Ω[Y ] = E ∈ conv(Y).
",2.3. Relaxed argmax layers,[0],[0]
Proof is provided in §A.5.,2.3. Relaxed argmax layers,[0],[0]
"Moreover, ∇DPΩ(θ) is a principled relaxation of the highest-scoring path Y ⋆(θ), in the sense that it converges to a subgradient of LP(θ) as the regularization vanishes: ∇DPγΩ(θ) −−−→
γ→0 Y ⋆(θ) ∈ ∂LP(θ).
",2.3. Relaxed argmax layers,[0],[0]
"When Ω = −γH , the distributions underpinning LPΩ(θ) and DPΩ(θ) coincide and reduce to the Gibbs distribution pθ,Ω(Y )",2.3. Relaxed argmax layers,[0],[0]
"∝ exp(〈θ,Y 〉/γ).",2.3. Relaxed argmax layers,[0],[0]
The value LPΩ(θ) = DPΩ(θ) is then equal to the log partition.,2.3. Relaxed argmax layers,[0],[0]
"When Ω = γ‖ · ‖2, some transitions between nodes have zero probability and hence some paths have zero probability under the distribution pθ,Ω. Thus, ∇DPΩ(θ) is typically sparse — this will prove interesting to introspect the various models we consider (typically, the smaller γ, the sparser ∇DPΩ(θ)).",2.3. Relaxed argmax layers,[0],[0]
Using ∇DPΩ(θ) as a layer involves backpropagating through ∇DPΩ(θ).,2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"This requires to apply the Jacobian of ∇DPΩ operator (a linear map from R N×N to RN×N ), or in other words to apply the Hessian of DPΩ, to an input sensibility vector Z, computing
∇2DPΩ(θ)Z",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"= ∇〈∇DPΩ(θ),Z〉 ∈ R N×N ,
where derivatives are w.r.t.",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
θ.,2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"The above vector may be computed in two ways, that differ in the order in which
derivatives are computed.",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"Using automatic differentiation frameworks such as PyTorch (Paszke et al., 2017), we may backpropagate over the computational graph a first time to compute the gradient ∇DPΩ(θ), while recording operations.",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"We may then compute 〈∇DPΩ(θ),Z〉, and backpropagate once again.",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"However, due to the structure of the problem, it proves more efficient, adapting Pearlmutter’s approach (1994), to directly compute 〈∇DPΩ(θ),Z〉 ∈ R, namely, the directional derivative at θ along Z.",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"This is done by applying the chain rule in one topologicallyordered pass over G. Similarly to the gradient computation, we record products with the local Hessians Hi(θ) , ∇2maxΩ(θi + v(θ)) along the way.",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
We then compute the gradient of the directional derivative using backpropagation.,2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
This yields a recursion for computing ∇2DPΩ(θ)Z in reverse topological-order over G. The complete derivation and the pseudo-code are given in §A.7.,2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
They allow to implement DPΩ as as a custom twice-differentiable module in existing software.,2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"For both approaches, the computational cost is O(|E|), the same as for gradient computation.",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"In our experiments in §4.2, our custom Hessian-vector product computation brings a 3×/12× speed-up during the backward pass on GPU/CPU vs. automatic differentiation.
",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
Related works.,2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"Smoothing LP formulations was also used for MAP inference (Meshi et al., 2015) or optimal transport (Blondel et al., 2018) but these works do not address how to differentiate through the smoothed formulation.",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"An alternative approach to create structured prediction layers, fundamentally different both in the forward and backward passes, is SparseMAP (Niculae et al., 2018).
",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
Summary.,2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"We have proposed DPΩ(θ), a smooth, convex and tractable relaxation to the value of LP(θ).",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
We have also shown that ∇DPΩ(θ) belongs to conv(Y) and is therefore a sound relaxation to solutions of LP(θ).,2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"To conclude this section, we formally define our proposed two layers.
",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
Definition 1.,2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
"Differentiable dynamic programming layers
Value layer: DPΩ(θ) ∈ R
Gradient layer: ∇DPΩ(θ) ∈ conv(Y)",2.4. Multiplication with the Hessian∇2DPΩ(θ)Z,[0],[0]
We now illustrate two instantiations of our framework for specific computational graphs.,3. Examples of computational graphs,[0],[0]
"We demonstrate in this section how to instantiate DPΩ to the computational graph of the Viterbi algorithm (Viterbi, 1967; Rabiner, 1990), one of the most famous instances of DP algorithm.",3.1. Sequence prediction,[0],[0]
"We call the resulting operator VitΩ. We wish to tag a sequence X = (x1, . . .",3.1. Sequence prediction,[0],[0]
",xT )",3.1. Sequence prediction,[0],[0]
"of vectors in R D
(e.g., word representations) with the most probable output sequence (e.g., entity tags) y = (y1, . . .",3.1. Sequence prediction,[0],[0]
", yT ) ∈",3.1. Sequence prediction,[0],[0]
[S] T .,3.1. Sequence prediction,[0],[0]
"This problem can be cast as finding the highest-scoring path on a treillis G. While y can always be represented as a sparse N×N binary matrix, it is convenient to represent it instead as a T×S×S binary tensor Y , such that yt,i,j = 1 if y transitions from node j to node i on time t, and 0 otherwise — we set y0 = 1.",3.1. Sequence prediction,[0],[0]
"The potentials can similarly be organized as a T×S×S real tensor, such that θt,i,j = φt(xt, i, j).",3.1. Sequence prediction,[0],[0]
"Traditionally, the potential functions φt were human-engineered (Sutton et al., 2012, §2.5).",3.1. Sequence prediction,[0],[0]
"In recent works and in this paper, they are learned end-to-end (Bottou et al., 1997; Collobert et al., 2011; Lample et al., 2016).
",3.1. Sequence prediction,[0],[0]
"Using the above binary tensor representation, the inner product 〈Y ,θ〉 is equal to ∑T
t=1 φt(xt, yt, yt−1), y’s cumulated score.",3.1. Sequence prediction,[0],[0]
This is illustrated in Figure 2 on the task of part-of-speech tagging.,3.1. Sequence prediction,[0],[0]
"The bold arrows indicate one possible output sequence y, i.e., one possible path in G.
When Ω = −H , we recover linear-chain conditional random fields (CRFs) (Lafferty et al., 2001) and the probability of y (Y in tensor representation) given X is
pθ,−H(y|X)∝ exp(〈Y ,θ〉)= exp (
T∑
t=1
φt(xt, yt, yt−1) ) .
",3.1. Sequence prediction,[0],[0]
"From Prop. 3, the gradient ∇Vit−H(θ)",3.1. Sequence prediction,[0],[0]
"= E ∈ R T×S×S is such that et,i,j = pθ,−H(yt = i, yt−1 = j|X).",3.1. Sequence prediction,[0],[0]
"The marginal probability of state i at time t is simply pθ,−H(yt = i|X) = ∑S j=1",3.1. Sequence prediction,[0],[0]
"et,i,j .",3.1. Sequence prediction,[0],[0]
Using a different Ω simply changes the distribution over state transitions.,3.1. Sequence prediction,[0],[0]
"When Ω = ‖ · ‖2, the marginal probabilities are typically sparse.",3.1. Sequence prediction,[0],[0]
"Pseudo-code for VitΩ(θ), as well as gradient and Hessian-product computations, is provided in §B.2.",3.1. Sequence prediction,[0],[0]
"The case Ω = ‖ · ‖2 is new to our knowledge.
",3.1. Sequence prediction,[0],[0]
"When Ω = −H , the marginal probabilities are traditionally computed using the forward-backward algorithm (Baum & Petrie, 1966).",3.1. Sequence prediction,[0],[0]
"In contrast, we compute ∇Vit−H(θ) using backpropagation while efficiently maintaining the marginalization.",3.1. Sequence prediction,[0],[0]
An advantage of our approach is that all operations are numerically stable.,3.1. Sequence prediction,[0],[0]
"The relation between forward-backward and backpropagation has been noted before (e.g., Eisner (2016)).",3.1. Sequence prediction,[0],[0]
"However, the analysis is led using (+,×) operations, instead of (maxΩ,+) as we do.",3.1. Sequence prediction,[0],[0]
"Our
Viterbi instantiation can be generalized to graphical models with a tree structure, and to approximate inference in general graphical models, since unrolled loopy belief propagation (Pearl, 1988) yields a dynamic program.",3.1. Sequence prediction,[0],[0]
"We note that continuous beam search (Goyal et al., 2017) can also be cleanly rewritten and extended using VitΩ operators.",3.1. Sequence prediction,[0],[0]
"We now demonstrate how to instantiate DPΩ to the computational graph of dynamic time warping (DTW) (Sakoe & Chiba, 1978), whose goal is to seek the minimal cost alignment between two time-series.",3.2. Time-series alignment,[0],[0]
"We call the resulting operator DTWΩ. Formally, let NA and NB be the lengths of two time-series, A and B. Let ai and bj be the i th and jth observations of A and B, respectively.",3.2. Time-series alignment,[0],[0]
"Since edge weights only depend on child nodes, it is convenient to rearrange Y and θ as NA × NB matrices.",3.2. Time-series alignment,[0],[0]
"Namely, we represent an alignment Y as a NA × NB binary matrix, such that yi,j = 1 if ai is aligned with bj , and 0 otherwise.",3.2. Time-series alignment,[0],[0]
"Likewise, we represent θ as a NA × NB matrix.",3.2. Time-series alignment,[0],[0]
"A classical example is θi,j = d(ai, bj), for some differentiable discrepancy measure d.",3.2. Time-series alignment,[0],[0]
"We write Y the set of all monotonic alignment matrices, such that the path that connects the upper-left (1, 1) matrix entry to the lower-right (NA, NB) one uses only ↓,→,ցmoves.",3.2. Time-series alignment,[0],[0]
"The DAG associated with Y is illustrated in Figure 3 with NA = 4 and NB = 3 below.
",3.2. Time-series alignment,[0],[0]
"Again, the bold arrows indicate one possible path Y ∈ Y from start to end in the DAG, and correspond to one possible alignment.",3.2. Time-series alignment,[0],[0]
"Using this representation, the cost of an alignment (cumulated cost along the path) is conveniently computed by 〈Y ,θ〉.",3.2. Time-series alignment,[0],[0]
The value DTWΩ(θ) can be used to define a loss between alignments or between time-series.,3.2. Time-series alignment,[0],[0]
"Following Proposition 3, ∇DTWΩ(θ) = E ∈ R NA×NB can be understood as a soft alignment matrix.",3.2. Time-series alignment,[0],[0]
"This matrix is sparse when Ω = ‖ · ‖2, as illustrated in Figure 1 (right).
",3.2. Time-series alignment,[0],[0]
Pseudo-code to compute DTWΩ(θ) as well as its gradient and its Hessian products are provided in §B.3.,3.2. Time-series alignment,[0],[0]
"When Ω = −H , DTWΩ(θ) is a conditional random field known as soft-DTW, and the probability pθ,Ω(Y |A,B) is a Gibbs distribution similar to §3.1 (Cuturi & Blondel, 2017).
",3.2. Time-series alignment,[0],[0]
"However, the case Ω = ‖ · ‖2 and the computation of ∇2DTWΩ(θ)Z are new and allow new applications.",3.2. Time-series alignment,[0],[0]
"We now apply the proposed layers, DPΩ(θ) and∇DPΩ(θ), to structured prediction (Bakır et al., 2007), whose goal is to predict a structured output Y ∈ Y associated with a structured input X ∈ X .",4. Differentiable structured prediction,[0],[0]
"We define old and new structured losses, and demonstrate them on two structured prediction tasks: named entity recognition and time-series alignment.",4. Differentiable structured prediction,[0],[0]
"Throughout this section, we assume that the potentials θ ∈ Θ have already been computed using a function from X to Θ and let C : Y×Y → R+ be a cost function between the ground-truth output Ytrue and the predicted output Y .
",4.1. Structured loss functions,[0],[0]
Convex losses.,4.1. Structured loss functions,[0],[0]
"Because C is typically non-convex, the cost-augmented structured hinge loss (Tsochantaridis et al., 2005) is often used instead for linear models
ℓC(Ytrue;θ) , max Y ∈Y C(Ytrue,Y )+",4.1. Structured loss functions,[0],[0]
"〈Y ,θ〉−〈Ytrue,θ〉.",4.1. Structured loss functions,[0],[0]
"(7)
This is a convex upper-bound on C(Ytrue,Y ⋆(θ)), where Y ⋆(θ) is defined in (4).",4.1. Structured loss functions,[0],[0]
"To make the cost-augmented decoding tractable, it is usually assumed that C(Ytrue,Y ) is linear in Y , i. e., it can be written as 〈CYtrue ,Y 〉 for some matrix CYtrue .",4.1. Structured loss functions,[0],[0]
"We can then rewrite (7) using our notation as
ℓC(Ytrue;θ) = LP(θ +CYtrue)− 〈Ytrue,θ〉.
",4.1. Structured loss functions,[0],[0]
"However, this loss function is non-differentiable.",4.1. Structured loss functions,[0],[0]
"We therefore propose to relax LP by substituting it with DPΩ:
ℓC,Ω(Ytrue;θ) , DPΩ(θ +CYtrue)− 〈Ytrue,θ〉.
Losses in this class are convex, smooth, tractable for any Ω, and by Proposition 2 property 2 a sensible approximation of ℓC .",4.1. Structured loss functions,[0],[0]
"In addition, they only require to backpropagate through DPΩ(θ) at training time.",4.1. Structured loss functions,[0],[0]
"It is easy to check that we recover the structured perceptron loss with ℓ0,0 (Collins, 2002), the structured hinge loss with ℓC,0 (Tsochantaridis et al., 2005) and the CRF loss with ℓ0,−H (Lafferty et al., 2001).",4.1. Structured loss functions,[0],[0]
"The last one has been used on top of LSTMs in several recent works (Lample et al., 2016; Ma & Hovy, 2016).",4.1. Structured loss functions,[0],[0]
"Minimizing ℓ0,−H(θ) is equivalent to maximizing the likelihood pθ,−H(Ytrue).",4.1. Structured loss functions,[0],[0]
"However, minimizing ℓ0,‖·‖2 is not equivalent to maximizing pθ,‖·‖2(Ytrue).",4.1. Structured loss functions,[0],[0]
"In fact, the former is convex while the latter is not.
",4.1. Structured loss functions,[0],[0]
Non-convex losses.,4.1. Structured loss functions,[0],[0]
"A direct approach that uses the output distribution pθ,Ω consists in minimizing the risk∑ y∈Y pθ,−H(Y )C(Ytrue,Y ).",4.1. Structured loss functions,[0],[0]
"As shown by Stoyanov &
Eisner (2012), this can be achieved by backpropagating through the minimum risk decoder.",4.1. Structured loss functions,[0],[0]
"However, the risk is usually non-differentiable, piecewise constant (Smith & Eisner, 2006) and several smoothing heuristics are necessary to make the method work (Stoyanov & Eisner, 2012).
",4.1. Structured loss functions,[0],[0]
"Another principled approach is to consider a differentiable approximation ∆: Y × conv(Y) → R+ of the cost C. We can then relax C(Ytrue,Y
⋆(θ)) by ∆(Ytrue,∇DPΩ(θ)).",4.1. Structured loss functions,[0],[0]
"Unlike minimum risk training, this approach is differentiable everywhere when Ω = −H .",4.1. Structured loss functions,[0],[0]
"Both approaches require to backpropagate through ∇DPΩ(θ), which is twice as costly as backpropagating through DPΩ(θ) (see §2.4).",4.1. Structured loss functions,[0],[0]
"Let X = (x1, · · · ,xT ) be an input sentence, where each word xt is represented by a vector in R D, computed using a neural recurrent architecture trained end-to-end.",4.2. Named entity recognition,[0],[0]
"We wish to tag each word with named entities, i.e., identify blocks of words that correspond to names, locations, dates, etc.",4.2. Named entity recognition,[0],[0]
We use the specialized operator VitΩ described in §3.1.,4.2. Named entity recognition,[0],[0]
"We construct the potential tensor θ(X) ∈ RT×S×S as
∀ t > 1, θ(X)t,i,j , w ⊤ i xt + bi + ti,j ,
and θ(X)1,i,j , w ⊤ i xt + bi, where (wi, bi) ∈",4.2. Named entity recognition,[0],[0]
R D × R is the linear classifier associated with tag i and T ∈ RS×S is a transition matrix.,4.2. Named entity recognition,[0],[0]
"We learn W , b and T along with the network producing X , and compare two losses:
Surrogate convex loss: ℓ0,Ω(Ytrue;θ),
Relaxed loss: ∆(Ytrue,∇DPΩ(θ)),
where ∆(Ytrue,Y ) is the squared ℓ2 distance when Ω = ‖ · ‖22 and the Kullback-Leibler divergence when Ω = −H , applied row-wise to the marginalization of Ytrue and Y .
Experiments.",4.2. Named entity recognition,[0],[0]
We measure the performance of the different losses and regularizations on the four languages of the CoNLL 2003 dataset.,4.2. Named entity recognition,[0],[0]
"Following Lample et al. (2016), who use the ℓ0,−H loss, we use a character LSTM and FastText (Joulin et al., 2016) pretrained embeddings computed using on Wikipedia.",4.2. Named entity recognition,[0],[0]
Those are fed to a word bidirectional LSTM to obtain X .,4.2. Named entity recognition,[0],[0]
Architecture details are provided in §C.1.,4.2. Named entity recognition,[0],[0]
"Results are reported in Table 1, along with reference results with different pretrained embeddings.",4.2. Named entity recognition,[0],[0]
"We first note that the non-regularized structured perceptron loss ℓ0,0, that involves working with subgradients of DP(θ), perform significantly worse than regularized losses.",4.2. Named entity recognition,[0],[0]
"With proper parameter selections, all regularized losses perform within 1% F1-score of each other, although entropyregularized losses perform slightly better on 3/4 languages.",4.2. Named entity recognition,[0],[0]
"However, the ℓ22-regularized losses yield sparse predictions, whereas entropy regularization always yields dense probability vectors.",4.2. Named entity recognition,[0],[0]
"Qualitatively, this allows to identify ambiguous predictions more easily, as illustrated in §C.1.",4.2. Named entity recognition,[0],[0]
"Sparse
predictions also allows to enumerate all non-zero probability entities, and to trade precision for recall at test time.",4.2. Named entity recognition,[0],[0]
"We use our framework to perform supervised audio-toscore alignment on the Bach 10 dataset (Duan & Pardo, 2011).",4.3. Supervised audio-to-score transcription,[0],[0]
"The dataset consists of 10 music pieces with audio tracks, MIDI transcriptions, and annotated alignments between them.",4.3. Supervised audio-to-score transcription,[0],[0]
"We transform the audio tracks into a sequence of audio frames using a feature extractor (see §C.2) to obtain a sequence A ∈ RNA×D, while the associated score sequence is represented by B ∈ RNB×K (each row bj is a one-hot vector corresponding to one key bj).",4.3. Supervised audio-to-score transcription,[0],[0]
"Each pair (A,B) is associated to an alignment Ytrue ∈ R NA×NB .",4.3. Supervised audio-to-score transcription,[0],[0]
"As described in §3.2, we define a discrepancy matrix θ ∈ R NA×NB between the elements of the two sequences.",4.3. Supervised audio-to-score transcription,[0],[0]
"We set the cost between an audio frame and a key to be the loglikelihood of this key given a multinomial linear classifier:
∀",4.3. Supervised audio-to-score transcription,[0],[0]
i ∈,4.3. Supervised audio-to-score transcription,[0],[0]
"[NA], li , − log(softmax(W ⊤ai + c))",4.3. Supervised audio-to-score transcription,[0],[0]
"∈ R K
and ∀ j ∈",4.3. Supervised audio-to-score transcription,[0],[0]
"[NB ], θi,j , li,bj ,
where (W , c) ∈ RD×K×RK are learned classifier parameters.",4.3. Supervised audio-to-score transcription,[0],[0]
We predict a soft alignment by Y = ∇DTW−H(θ).,4.3. Supervised audio-to-score transcription,[0],[0]
"Following (Garreau et al., 2014), we define the relaxed loss
∆(Ytrue,Y ) , ‖L(Y − Ytrue) ⊤‖2F ,
where L a the lower triangular matrix filled with 1.",4.3. Supervised audio-to-score transcription,[0],[0]
"When Y ∈ Y is a true alignement matrix, ∆(Ytrue,Y ) is the area between the path of Ytrue and Y , which corresponds to the mean absolute deviation in the audio literature.",4.3. Supervised audio-to-score transcription,[0],[0]
"When Y ∈ conv(Y), it is a convex relaxation of the area.",4.3. Supervised audio-to-score transcription,[0],[0]
"At test time, once θ is learned, we use the non-regularized DTW algorithm to output a hard alignment Y ⋆(θ) ∈ Y .
Results.",4.3. Supervised audio-to-score transcription,[0],[0]
"We perform a leave-one-out cross-validation of our model performance, learning the multinomial classifier on 9 pieces and assessing the quality of the alignment on the remaining piece.",4.3. Supervised audio-to-score transcription,[0],[0]
We report the mean absolute deviation on both train and test sets.,4.3. Supervised audio-to-score transcription,[0],[0]
"A solid baseline consists in learning the multinomial classifier (W , c) beforehand, i.e., without end-to-end training.",4.3. Supervised audio-to-score transcription,[0],[0]
We then use this model to compute θ as in (4.3) and obtain Y ⋆(θ).,4.3. Supervised audio-to-score transcription,[0],[0]
"As shown in Table 2, our end-to-end technique outperforms this baseline by a large margin.",4.3. Supervised audio-to-score transcription,[0],[0]
We also demonstrate in §C.2 that the alignments obtained by end-to-end training are visibly closer to the ground truth.,4.3. Supervised audio-to-score transcription,[0],[0]
End-to-end training thus allows to fine-tune the distance matrix θ for the task at hand.,4.3. Supervised audio-to-score transcription,[0],[0]
"We show in this section how to apply our framework to neural sequence-to-sequence models augmented with an attention mechanism (Bahdanau et al., 2015).",5. Structured and sparse attention,[0],[0]
An encoder first produces a list of vectors X =,5. Structured and sparse attention,[0],[0]
"(x1, . . .",5. Structured and sparse attention,[0],[0]
",xT )",5. Structured and sparse attention,[0],[0]
representing the input sequence.,5. Structured and sparse attention,[0],[0]
A decoder is then used to greedily produce the corresponding output sequence.,5. Structured and sparse attention,[0],[0]
"To simplify the notation, we focus on one time step of the decoding procedure.",5. Structured and sparse attention,[0],[0]
"Given the decoder’s current hidden state z and X as inputs, the role of the attention mechanism is to produce a distribution w ∈ △T over X , for the current time step.",5. Structured and sparse attention,[0],[0]
"This distribution is then typically used to produce a context vector c , X⊤w, that is in turn invoved in the computation of the output sequence’s next element.
",5. Structured and sparse attention,[0],[0]
Structured attention layers.,5. Structured and sparse attention,[0],[0]
"Kim et al. (2017) proposed a segmentation attention layer, which is capable of taking into account the transitions between elements of X .",5. Structured and sparse attention,[0],[0]
"They use a linear-chain CRF to model the probability pθ,−H(y|X) of a sequence y = (y1, . . .",5. Structured and sparse attention,[0],[0]
", yT ), where each yt is either 1 (“pay attention”) or 0.",5. Structured and sparse attention,[0],[0]
"They then propose to use normalized marginal probabilities as attention weights: wt ∝ pθ,−H(yt = 1|X).",5. Structured and sparse attention,[0],[0]
"They show how to backpropagate gradients through the forward-backward algorithm, which they use to compute the marginal probabilities.
",5. Structured and sparse attention,[0],[0]
Generalizing structured attention.,5. Structured and sparse attention,[0],[0]
"Using the notation from §3.1, any y can be represented as a tensor Y ∈ {0, 1}T×2×2 and the potentials as a tensor θ ∈ RT×2×2.",5. Structured and sparse attention,[0],[0]
"Similarly to Kim et al. (2017), we define
θt,1,j , xtMz + t1,j and θt,0,j ,",5. Structured and sparse attention,[0],[0]
"t0,j ,
where xMz is a learned bilinear form and T ∈ R2×2 is a learned transition matrix.",5. Structured and sparse attention,[0],[0]
"Following §3.1, the gradient ∇VitΩ(θ) is equal to the expected matrix E ∈ R T×2×2 and the marginals are obtained by marginalizing that matrix.",5. Structured and sparse attention,[0],[0]
"Hence, we can set wt ∝ pθ,Ω(yt =",5. Structured and sparse attention,[0],[0]
1|X),5. Structured and sparse attention,[0],[0]
"= et,1,0 + et,1,1.",5. Structured and sparse attention,[0],[0]
Backpropagating through ∇VitΩ(θ) can be carried out using our approach outlined in §2.4.,5. Structured and sparse attention,[0],[0]
"This approach is not only more general, but also simpler and more robust to under-
flow problems than backpropagating through the forwardbackward algorithm as done by Kim et al. (2017).
",5. Structured and sparse attention,[0],[0]
Experiments.,5. Structured and sparse attention,[0],[0]
We demonstrate structured attention layers with an LSTM encoder and decoder to perform French to English translation using data from a 1 million sentence subset of the WMT14 FR-EN challenge.,5. Structured and sparse attention,[0],[0]
We illustrate an example of attenion map obtained with negentropy and ℓ22 regularizations in Figure 4.,5. Structured and sparse attention,[0],[0]
"Non-zero elements are underlined with borders: ℓ22-regularized attention maps are sparse and more interpretable — this provides a structured alternative to sparsemax attention (Martins & Astudillo, 2016).",5. Structured and sparse attention,[0],[0]
Results were all within 0.8 point of BLEU score on the newstest2014 dataset.,5. Structured and sparse attention,[0],[0]
"For French to English, standard softmax attention obtained 27.96, while entropy and ℓ22 regularized structured attention obtained 27.96 and 27.19 — introducing structure and sparsity therefore provides enhanced interpretability with comparable peformance.",5. Structured and sparse attention,[0],[0]
"We provide model details, full results and further visualizations in §C.3.",5. Structured and sparse attention,[0],[0]
"We proposed a theoretical framework for turning a broad class of dynamic programs into convex, differentiable and tractable operators, using the novel point of view of smoothed max operators.",6. Conclusion,[0],[0]
"Our work sheds a new light on how to transform dynamic programs that predict hard assignments (e.g., the maximum a-posteriori estimator in a probabilistic graphical model or an alignment matrix between two time-series) into continuous and probabilistic ones.",6. Conclusion,[0],[0]
We provided a new argument in favor of negentropy regularization by showing that it is the only one to preserve associativity of the smoothed max operator.,6. Conclusion,[0],[0]
"We showed that different regularizations induce different distributions over outputs and that ℓ22 regularization has other benefits, in terms of sparsity of the expected outputs.",6. Conclusion,[0],[0]
"Generally speaking, performing inference in a graphical model and backpropagating through it reduces to computing the first and second-order derivatives of a relaxed maximum-likelihood estimation — leveraging this observation yields elegant and efficient algorithms that are readily usable in deep learning frameworks, with various promising applications.",6. Conclusion,[0],[0]
MB thanks Vlad,Acknowledgements,[0],[0]
Niculae and Marco Cuturi for many fruitful discussions.,Acknowledgements,[0],[0]
"AM thanks Julien Mairal, Inria Thoth and Inria Parietal for lending him the computational resources necessary to run the experiments.",Acknowledgements,[0],[0]
"He thanks University Paris-Saclay for allowing him to do an internship at NTT, and Olivier Grisel for his insightful comments on natural language processing models.",Acknowledgements,[0],[0]
Dynamic programming (DP) solves a variety of structured combinatorial problems by iteratively breaking them down into smaller subproblems.,abstractText,[0],[0]
"In spite of their versatility, many DP algorithms are non-differentiable, which hampers their use as a layer in neural networks trained by backpropagation.",abstractText,[0],[0]
"To address this issue, we propose to smooth the max operator in the dynamic programming recursion, using a strongly convex regularizer.",abstractText,[0],[0]
"This allows to relax both the optimal value and solution of the original combinatorial problem, and turns a broad class of DP algorithms into differentiable operators.",abstractText,[0],[0]
"Theoretically, we provide a new probabilistic perspective on backpropagating through these DP operators, and relate them to inference in graphical models.",abstractText,[0],[0]
"We derive two particular instantiations of our framework, a smoothed Viterbi algorithm for sequence prediction and a smoothed DTW algorithm for time-series alignment.",abstractText,[0],[0]
"We showcase these instantiations on structured prediction (audio-to-score alignment, NER) and on structured and sparse attention for translation.",abstractText,[0],[0]
Modern neural networks are composed of multiple layers of nested functions.,abstractText,[0],[0]
"Although layers usually consist of elementary linear algebraic operations and simple nonlinearities, there is a growing need for layers that output the value or the solution of an optimization problem.",abstractText,[0],[0]
"This can be used to design loss functions that capture relevant regularities in the input (Lample et al., 2016; Cuturi & Blondel, 2017) or to create layers that impose prior structure on the output (Kim et al., 2017; Amos & Kolter, 2017; Niculae & Blondel, 2017; Djolonga & Krause, 2017).",abstractText,[0],[0]
"Among these works, several involve a convex optimization Inria, CEA, Université Paris-Saclay, Gif-sur-Yvette, France.",abstractText,[0],[0]
"Work performed at NTT Communication Science Laboratories, Kyoto, Japan.",abstractText,[0],[0]
"Correspondence to: AM <arthur.mensch@m4x.org>, MB <mathieu@mblondel.org>.",abstractText,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",abstractText,[0],[0]
Copyright 2018 by the author(s).,abstractText,[0],[0]
"problem (Amos & Kolter, 2017; Niculae & Blondel, 2017; Djolonga & Krause, 2017); others solve certain combinatorial optimization problems by dynamic programming (Kim et al., 2017; Cuturi & Blondel, 2017; Nowak et al., 2018).",abstractText,[0],[0]
"However, because dynamic programs (Bellman, 1952) are usually non-differentiable, virtually all these works resort to the formalism of conditional random fields (CRFs) (Lafferty et al., 2001), which can be seen as changing the semiring used by the dynamic program — replacing all values by their exponentials and all (max,+) operations with (+,×) operations (Verdu & Poor, 1987).",abstractText,[0],[0]
"While this modification smoothes the dynamic program, it looses the sparsity of solutions, since hard assignments become soft ones.",abstractText,[0],[0]
"Moreover, a general understanding of how to relax and differentiate dynamic programs is lacking.",abstractText,[0],[0]
"In this work, we propose to do so by leveraging smoothing (Moreau, 1965; Nesterov, 2005) and backpropagation (Linnainmaa, 1970).",abstractText,[0],[0]
We make the following contributions.,abstractText,[0],[0]
1),abstractText,[0],[0]
We present a unified framework for turning a broad class of dynamic programs (DP) into differentiable operators.,abstractText,[0],[0]
"Unlike existing works, we propose to change the semiring to use (maxΩ,+) operations, where maxΩ is a max operator smoothed with a strongly convex regularizer Ω (§1).",abstractText,[0],[0]
2),abstractText,[0],[0]
"We show that the resulting DP operators, that we call DPΩ, are smoothed relaxations of the original DP algorithm and satisfy several key properties, chief among them convexity.",abstractText,[0],[0]
"In addition, we show that their gradient,∇DPΩ, is equal to the expected trajectory of a certain random walk and can be used as a sound relaxation to the original dynamic program’s solution.",abstractText,[0],[0]
Using negative entropy for Ω recovers existing CRF-based works from a different perspective — we provide new arguments as to why this Ω is a good choice.,abstractText,[0],[0]
"On the other hand, using squared l2 norm for Ω leads to new algorithms whose expected solution is sparse.",abstractText,[0],[0]
"We derive a clean and efficient method to backpropagate gradients, both through DPΩ and ∇DPΩ.",abstractText,[0],[0]
This allows us to define differentiable DP layers that can be incorporated in neural networks trained end-to-end (§2).,abstractText,[0],[0]
3),abstractText,[0],[0]
"We illustrate how to to derive two particular instantiations of our framework, a smoothed Viterbi algorithm for sequence prediction and a smoothed DTW algorithm for supervised time-series alignment (§3).",abstractText,[0],[0]
The latter is illustrated in Figure 1.,abstractText,[0],[0]
"Finally, we showcase these two instantiDifferentiable Dynamic Programming for Structured Prediction and Attention DTW H(θ) = 7.49 DTWk·k2(θ) = 9.61 Figure 1. DTWΩ(θ) is an instantiation of the proposed smoothed dynamic programming operator, DPΩ(θ), to the dynamic time warping (DTW) computational graph.",abstractText,[0],[0]
"In this picture, θ is the squared Euclidean distance matrix between the observations of two time-series.",abstractText,[0],[0]
The gradient ∇DTWΩ(θ) is equal to the expected alignment under a certain random walk characterized in §2.3 and is a sound continuous relaxation to the hard DTW alignment between the two time-series (here depicted with a yellow path).,abstractText,[0],[0]
"Unlike negentropy regularization (left), l22 regularization leads to exactly sparse alignments (right).",abstractText,[0],[0]
"Our framework allows to backpropagate through both DTWΩ(θ) and ∇DTWΩ(θ), which makes it possible to learn the distance matrix θ end-to-end.",abstractText,[0],[0]
ations on structured prediction tasks (§4) and on structured attention for neural machine translation (§5).,abstractText,[0],[0]
Notation.,abstractText,[0],[0]
"We denote scalars, vectors and matrices using lower-case, bold lower-case and bold upper-case letters, e.g., y, y and Y .",abstractText,[0],[0]
"We denote the elements of Y by yi,j and its rows by yi.",abstractText,[0],[0]
"We denote the Frobenius inner product between A and B by 〈A,B〉 , ∑ i,j ai,jbi,j .",abstractText,[0],[0]
"We denote the (D− 1)-probability simplex by△ , {λ ∈ R+ : ‖λ‖1 = 1}.",abstractText,[0],[0]
"We write conv(Y) , { ∑ Y ∈Y λY Y : λ ∈ △ } the convex hull of Y ,",abstractText,[0],[0]
"[N ] the set {1, . . .",abstractText,[0],[0]
", N} and supp(x) , {j ∈",abstractText,[0],[0]
[D] : xj 6= 0} the support of x ∈ R .,abstractText,[0],[0]
"We denote the Shannon entropy by H(q) , ∑ i qi log qi.",abstractText,[0],[0]
We have released an optimized and modular PyTorch implementation for reproduction and reuse.,abstractText,[0],[0]
1.,abstractText,[0],[0]
Smoothed max operators,abstractText,[0],[0]
"In this section, we introduce smoothed max operators (Nesterov, 2005; Beck & Teboulle, 2012; Niculae & Blondel, 2017), that will serve as a powerful and generic abstraction to define differentiable dynamic programs in §2.",abstractText,[0],[0]
Let Ω : R → R be a strongly convex function on△ and let x ∈,abstractText,[0],[0]
R.,abstractText,[0],[0]
"We define the max operator smoothed by Ω as: maxΩ(x) , max q∈△D 〈q,x〉 − Ω(q).",abstractText,[0],[0]
"(1) In other words, maxΩ is the convex conjugate of Ω, restricted to the simplex.",abstractText,[0],[0]
"From the duality between strong convexity and smoothness, maxΩ is smooth: differentiable everywhere and with Lipschitz continuous gradient.",abstractText,[0],[0]
"Since the argument that achieves the maximum in (1) is unique, from Danskin’s theorem (1966), it is equal to the gradient: ∇maxΩ(x) = argmax q∈△D 〈q,x〉 − Ω(q).",abstractText,[0],[0]
The gradient is differentiable almost everywhere for any strongly-convex Ω (everywhere for negentropy).,abstractText,[0],[0]
"Next, we state properties that will be useful throughout this paper.",abstractText,[0],[0]
Lemma 1.,abstractText,[0],[0]
"Properties of maxΩ operators Let x = (x1, . . .",abstractText,[0],[0]
", xD) ⊤ ∈ R. 1.",abstractText,[0],[0]
"Boundedness: If Ω is lower-bounded by LΩ,D and upper-bounded by UΩ,D on the simplex△ , then max(x)− UΩ,D ≤ maxΩ(x) ≤",abstractText,[0],[0]
"max(x)− LΩ,D. 2.",abstractText,[0],[0]
Distributivity of + over maxΩ: maxΩ(x+ c1) = maxΩ(x) + c ∀c ∈,abstractText,[0],[0]
R. 3.,abstractText,[0],[0]
"Commutativity: If Ω(Pq) = Ω(q), where P is a permutation matrix, then maxΩ(Px) = maxΩ(x).",abstractText,[0],[0]
4.,abstractText,[0],[0]
Non-decreasingness in each coordinate: maxΩ(x) ≤ maxΩ(y) ∀x ≤,abstractText,[0],[0]
y 5.,abstractText,[0],[0]
Insensitivity to −∞: xj = −∞⇒ ∇maxΩ(x)j = 0.,abstractText,[0],[0]
Proofs are given in §A.1.,abstractText,[0],[0]
"In particular, property 3 holds whenever Ω(q) = ∑D i=1 ω(qi), for some function ω.",abstractText,[0],[0]
We focus in this paper on two specific regularizers Ω: the negentropy −H and the squared l2 norm.,abstractText,[0],[0]
"For these choices, all properties above are satisfied and we can derive closedform expressions for maxΩ, its gradient and its Hessian — see §B.1.",abstractText,[0],[0]
"When using negentropy, maxΩ becomes the log-sum-exp and∇maxΩ the softmax.",abstractText,[0],[0]
"The former satisfies associativity, which as we shall see, makes it natural to use in dynamic programming.",abstractText,[0],[0]
"With the squared l2 regularization, as observed by Martins & Astudillo (2016); Niculae & Blondel (2017), the gradient∇maxΩ is sparse.",abstractText,[0],[0]
This will prove useful to enforce sparsity in the models we study.,abstractText,[0],[0]
2. Differentiable DP layers Dynamic programming (DP) is a generic way of solving combinatorial optimization problems by recursively solving problems on smaller sets.,abstractText,[0],[0]
"We first introduce this category of algorithms in a broad setting, then use smoothed max operators to define differentiable DP layers.",abstractText,[0],[0]
2.1.,abstractText,[0],[0]
"Dynamic programming on a DAG Every problem solved by dynamic programming reduces to finding the highest-scoring path between a start node and an end node, on a weighted directed acyclic graph (DAG).",abstractText,[0],[0]
"We therefore introduce our formalism on this generic problem, and give concrete examples in §3.",abstractText,[0],[0]
"Formally, let G = (V, E) be a DAG, with nodes V and edges E .",abstractText,[0],[0]
We write N = |V| ≥ 2 the number of nodes.,abstractText,[0],[0]
"Differentiable Dynamic Programming for Structured Prediction and Attention Without loss of generality, we number the nodes in topological order, from 1 (start) to N (end), and thus V =",abstractText,[0],[0]
[N ].,abstractText,[0],[0]
"Node 1 is the only node without parents, and node N the only node without children.",abstractText,[0],[0]
"Every directed edge (i, j) from a parent node j to a child node i has a weight θi,j ∈ R.",abstractText,[0],[0]
"We gather the edge weights in a matrix θ ∈ Θ ⊆ R , setting θi,j = −∞ if (i, j) / ∈ E",abstractText,[0],[0]
"and θ1,1 = 1.",abstractText,[0],[0]
We consider the set Y of all paths in G from node 1 to node N .,abstractText,[0],[0]
"Any path Y ∈ Y can be represented as a N × N binary matrix, with yi,j = 1 if the path goes through the edge (i, j) and yi,j = 0 otherwise.",abstractText,[0],[0]
"In the sequel, paths will have a one-to-one correspondence with discrete structures such as sequences or alignments.",abstractText,[0],[0]
"Using this representation, 〈Y ,θ〉 corresponds to the cumulated sum of edge weights, along the path Y .",abstractText,[0],[0]
"The computation of the highest score among all paths amounts to solving the combinatorial problem LP(θ) , max Y ∈Y 〈Y ,θ〉 ∈ R. (2)",abstractText,[0],[0]
"Although the size of Y is in general exponential in N , LP(θ) can be computed in one topologically-ordered pass over G using dynamic programming.",abstractText,[0],[0]
"We let Pi be the set of parent nodes of node i in graph G and define recursively v1(θ) , 0 ∀",abstractText,[0],[0]
i ∈,abstractText,[0],[0]
"[2, . . .",abstractText,[0],[0]
", N ] : vi(θ) , max j∈Pi θi,j + vj(θ).",abstractText,[0],[0]
"(3) This algorithm outputs DP(θ) , vN (θ).",abstractText,[0],[0]
We now show that this is precisely the highest score among all paths.,abstractText,[0],[0]
Proposition 1.,abstractText,[0],[0]
Optimality of dynamic programming ∀θ ∈ Θ : DP(θ) = LP(θ),abstractText,[0],[0]
"The optimality of recursion (3) is well-known (Bellman, 1952).",abstractText,[0],[0]
"We prove it again with our formalism in §A.2, since it exhibits the two key properties that the max operator must satisfy to guarantee optimality: distributivity of + over it and associativity.",abstractText,[0],[0]
"The cost of computing DP(θ) is O(|E|), which is exponentially better than O(|Y|).",abstractText,[0],[0]
"In many applications, we will often rather be interested in the argument that achieves the maximum, i.e., one of the highest-scoring paths Y (θ) ∈ argmax Y ∈Y 〈Y ,θ〉.",abstractText,[0],[0]
"(4) This argument can be computed by backtracking, that we now relate to computing subgradients of LP(θ).",abstractText,[0],[0]
"Linear program, lack of differentiality.",abstractText,[0],[0]
"Unfortunately, LP(θ) is not differentiable everywhere.",abstractText,[0],[0]
"To see why this is the case, notice that (2) can be rewritten as a linear program over the convex polytope conv(Y): LP(θ) = max Y ∈conv(Y) 〈Y ,θ〉.",abstractText,[0],[0]
"From the generalized Danskin theorem (Bertsekas, 1971), Y (θ) ∈ ∂LP(θ) = argmax Y ∈conv(Y) 〈Y ,θ〉, where ∂ denotes the subdifferential of LP(θ), i.e., the set of subgradients.",abstractText,[0],[0]
"When Y (θ) is unique, ∂LP(θ) is a singleton and Y ⋆ is equal to the gradient of LP(θ), that we write∇LP(θ).",abstractText,[0],[0]
"Unfortunately, Y (θ) is not always unique, meaning that LP(θ) is not differentiable everywhere.",abstractText,[0],[0]
"As we will show in §4.2, this hinders optimization as we can only train models involving LP(θ) with subgradient methods.",abstractText,[0],[0]
"Worse, Y (θ), a function from Θ to Y , is discontinuous and has null or undefined derivatives.",abstractText,[0],[0]
It is thus impossible to use it in a model trained by gradient descent.,abstractText,[0],[0]
2.2.,abstractText,[0],[0]
"Smoothed max layers To address the lack of differentiability of dynamic programming, we introduce the operator maxΩ, presented in §1, and consider two approaches.",abstractText,[0],[0]
Smoothing the linear program.,abstractText,[0],[0]
"Let us define the Ωsmoothed maximum of a function f : Y → R over a finite set Y using the following shorthand notation: maxΩ Y ∈Y f(Y ) , maxΩ((f(Y ))",abstractText,[0],[0]
Y ∈Y).,abstractText,[0],[0]
"A natural way to circumvent the lack of differentiability of LP(θ) is then to replace the global max operator by maxΩ: LPΩ(θ) , maxΩ Y ∈Y 〈Y ,θ〉 ∈ R. (5) From §1, LPΩ(θ) is convex and, as long as Ω is strongly convex, differentiable everywhere.",abstractText,[0],[0]
"In addition, ∇LPΩ(θ) is Lipschitz continuous and thus differentiable almost everywhere.",abstractText,[0],[0]
"Unfortunately, solving (5) for general Ω is likely intractable when Y has an exponential size.",abstractText,[0],[0]
Smoothing the dynamic program.,abstractText,[0],[0]
"As a tractable alternative, we propose an algorithmic smoothing.",abstractText,[0],[0]
"Namely, we replace max by maxΩ locally within the DP recursion.",abstractText,[0],[0]
"Omitting the dependence on Ω, this defines a smoothed recursion over the new sequence (vi(θ))",abstractText,[0],[0]
N i=1,abstractText,[0],[0]
:,abstractText,[0],[0]
"v1(θ) , 0 ∀i ∈",abstractText,[0],[0]
"[2, . . .",abstractText,[0],[0]
", N ] : vi(θ) , maxΩ j∈Pi θi,j + vj(θ).",abstractText,[0],[0]
"(6) The new algorithm outputs DPΩ(θ), vN (θ), the smoothed highest score.",abstractText,[0],[0]
Smoothing the max operator locally brings the same benefit as before — DPΩ(θ) is smooth and ∇DPΩ(θ) is differentiable almost everywhere.,abstractText,[0],[0]
"However, computing DPΩ(θ) is now always tractable, since it simply requires to evaluate (vi(θ))",abstractText,[0],[0]
N i=1,abstractText,[0],[0]
"in topological order, as in Differentiable Dynamic Programming for Structured Prediction and Attention the original recursion (3).",abstractText,[0],[0]
"Although LPΩ(θ) and DPΩ(θ) are generally different (in fact, LPΩ(θ) ≥ DPΩ(θ) for all θ ∈ Θ), we now show that DPΩ(θ) is a sensible approximation of LP(θ) in several respects.",abstractText,[0],[0]
Proposition 2.,abstractText,[0],[0]
Properties of DPΩ,abstractText,[0],[0]
Differentiable Dynamic Programming for Structured Prediction and Attention,title,[0],[0]
"Recently, there has been much work on learning algorithms using neural networks.",1. Introduction,[0],[0]
"Following the idea of the Neural Turing Machine (Graves et al., 2014), this work has focused on extending neural networks with interpretable components that are differentiable versions of traditional computer components, such as external memories, stacks, and discrete functional units.",1. Introduction,[0],[0]
"However, trained models are not easily interpreted as the learned algorithms are embedded in the weights of a monolithic neural network.",1. Introduction,[0],[0]
In this work we flip the roles of the neural network and differentiable computer architecture.,1. Introduction,[0],[0]
"We consider interpretable controller architectures which express algorithms using differentiable programming languages (Gaunt et al., 2016; Riedel et al., 2016; Bunel et al., 2016).",1. Introduction,[0],[0]
"In our framework, these controllers can execute discrete functional units (such as those considered by past work), but also have access to a library of trainable, uninterpretable neural network functional units.",1. Introduction,[0],[0]
The system is end-to-end differentiable such that the source code representation of the algorithm is jointly induced with the parameters of the neural function library.,1. Introduction,[0],[0]
"In this paper we
1Microsoft Research, Cambridge, UK 2Google Brain, Montréal, Canada (work done while at Microsoft).",1. Introduction,[0],[0]
"Correspondence to: Alexander L. Gaunt <algaunt@microsoft.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"explore potential advantages of this class of hybrid model over purely neural systems, with a particular emphasis on lifelong learning systems that learn from weak supervision.
",1. Introduction,[0],[0]
We concentrate on perceptual programming by example (PPBE) tasks that have both algorithmic and perceptual elements to exercise the traditional strengths of program-like and neural components.,1. Introduction,[0],[0]
Examples of this class of task include navigation tasks guided by images or natural language (see Fig. 1) or handwritten symbol manipulation (see Sec. 3).,1. Introduction,[0],[0]
"Using an illustrative set of PPBE tasks we aim to emphasize two specific benefits of our hybrid models:
First, the source code representation in the controller allows modularity: the neural components are small functions that specialize to different tasks within the larger program structure.",1. Introduction,[0],[0]
It is easy to separate and share these functional units to transfer knowledge between tasks.,1. Introduction,[0],[0]
"In contrast, the absence of well-defined functions in purely neural solutions makes effective knowledge transfer more difficult, leading to problems such as catastrophic forgetting in multitask and lifelong learning (McCloskey & Cohen, 1989; Ratcliff, 1990).",1. Introduction,[0],[0]
"In our experiments, we consider a lifelong learning setting in which we train the system on a sequence of PPBE tasks that share perceptual subtasks.
",1. Introduction,[0],[0]
"Second, the source code representation enforces an inductive bias that favors learning solutions that exhibit strong generalization.",1. Introduction,[0],[0]
"For example, once a suitable control flow structures (e.g., a for loop) for a list manipulation problem was learned on short examples, it trivially generalizes to lists of arbitrary length.",1. Introduction,[0],[0]
"In contrast, although some neural architectures demonstrate a surprising ability to generalize, the reasons for this generalization are not fully understood (Zhang et al., 2017) and generalization performance invariably degrades as inputs become increasingly distinct from the training data.
",1. Introduction,[0],[0]
This paper is structured as follows.,1. Introduction,[0],[0]
"We first present a language, called NEURAL TERPRET (NTPT), for specifying hybrid source code/neural network models (Sec. 2), and then introduce a sequence of PPBE tasks (Sec. 3).",1. Introduction,[0],[0]
Our NTPT models and purely neural baselines are described in Sec. 4 and 5 respectively.,1. Introduction,[0],[0]
The experimental results are presented in Sec. 6.,1. Introduction,[0],[0]
"The TERPRET language (Gaunt et al., 2016) provides a system for constructing differentiable program interpreters that can induce source code operating on basic data types (e.g. integers) from input-output examples.",2. Building hybrid models,[0],[0]
We extend this language with the concept of learnable neural functions.,2. Building hybrid models,[0],[0]
These can either be embedded inside the differentiable interpreter as mappings from integer to integer or (as we emphasize in this work) can act as learnable interfaces between perceptual data represented as floating point Tensors and the differentiable interpreter’s integer data type.,2. Building hybrid models,[0],[0]
"Below we briefly review the TERPRET language and describe the NEURAL TERPRET extensions.
2.1.",2. Building hybrid models,[0],[0]
"TERPRET
TERPRET programs specify a differentiable interpreter by defining the relationship between Inputs and Outputs via a set of inferrable Params (that define an executable program) and Vars (that store intermediate results).",2. Building hybrid models,[0],[0]
TERPRET requires all of these variables to range over bounded integers.,2. Building hybrid models,[0],[0]
"The model is made differentiable by a compilation step that lifts the relationships between integers specified by the TERPRET code to relationships between marginal
distributions over integers in finite ranges.",2. Building hybrid models,[0],[0]
"Fig. 1 illustrates an example application of the language.
",2. Building hybrid models,[0],[0]
"TERPRET can be translated into a TensorFlow (Abadi et al., 2015) computation graph which can then be trained using standard methods.",2. Building hybrid models,[0],[0]
"For this, two key features of the language need to be translated:
• Function application.",2. Building hybrid models,[0],[0]
"The statement z.set to(foo(x, y)) is translated into µzi = ∑ jk Iijkµ x jµ y k where µ
a represents the marginal distribution for the variable a",2. Building hybrid models,[0],[0]
"and I is an indicator tensor 1[i = foo(j, k)].",2. Building hybrid models,[0],[0]
"This approach extends to all functions mapping any number of integer arguments to an integer output.
",2. Building hybrid models,[0],[0]
• Conditional statements,2. Building hybrid models,[0],[0]
The statements if x == 0: z.set to(a); elif x == 1: z.set to(b) are translated to µz = µx0µ a + µx1µ,2. Building hybrid models,[0],[0]
"b.
Statements switching between more than two cases follow a similar pattern, with details given in (Gaunt et al., 2016).
2.2.",2. Building hybrid models,[0],[0]
"NEURAL TERPRET
To handle perceptual data, we relax the restriction that all variables need to be finite integers.",2. Building hybrid models,[0],[0]
"We introduce a new floating point Tensor type whose dimensions are fixed at declaration, and which is suitable for storing perceptual data.",2. Building hybrid models,[0],[0]
"Additionally, we introduce learnable functions that can process integer or tensor variables.",2. Building hybrid models,[0],[0]
"A learnable function is declared using @Learn([d1, . . .",2. Building hybrid models,[0],[0]
", dD], dout, hid sizes=[`1, . . .",2. Building hybrid models,[0],[0]
", `L]), where the first component specifies the dimensions (resp. ranges)",2. Building hybrid models,[0],[0]
"d1, . .",2. Building hybrid models,[0],[0]
.,2. Building hybrid models,[0],[0]
", dD of the input tensors (resp. integers) and the second specifies the dimension of the output.",2. Building hybrid models,[0],[0]
NTPT compiles such functions into a fully-connected feed-forward neural network whose layout is controlled by the hid sizes component (specifying the number neurons in each layer).,2. Building hybrid models,[0],[0]
The inputs of the function are simply concatenated.,2. Building hybrid models,[0],[0]
"Tensor output is generated by learning a mapping from the last hidden layer, and finite integer output is generated by a softmax layer producing a distribution over integers up to the declared bound.",2. Building hybrid models,[0],[0]
"Learnable parameters for the generated network are shared across every use of the function in the NTPT program, and as they naturally fit into the computation graph for the remaining TERPRET program, the whole system is trained end-to-end.",2. Building hybrid models,[0],[0]
"We illustrate an example NTPT program for learning navigation tasks in a maze of street signs (Stallkamp et al., 2011) in Fig. 1.",2. Building hybrid models,[0],[0]
"Motivated by the hypothesis that the modularity of the source code representation benefits knowledge transfer, we devise a sequence of PPBE tasks to be solved by sharing knowledge between tasks.",3. A Lifetime of PPBE Tasks,[0],[0]
"Our tasks are based on algorithmic manipulation of handwritten digits and mathematical operators.
",3. A Lifetime of PPBE Tasks,[0],[0]
"In early tasks the model learns to navigate simple 2 × 2 grids of images, and to become familiar with the concepts of digits and operators from a variety of weak supervision.",3. A Lifetime of PPBE Tasks,[0],[0]
"Despite their simplicity, these challenges already pose problems for purely neural lifelong learning systems.
",3. A Lifetime of PPBE Tasks,[0],[0]
The final task in the learning lifetime is more complex and designed to test generalization properties: the system must learn to compute the results of variable-length mathematical expressions expressed using handwritten symbols.,3. A Lifetime of PPBE Tasks,[0],[0]
"The algorithmic component of this task is similar to arithmetic tasks presented to contemporary Neural GPU models (Kaiser & Sutskever, 2016; Price et al., 2016).",3. A Lifetime of PPBE Tasks,[0],[0]
"The complete set of tasks is illustrated in Fig. 2 and described in detail below.
",3. A Lifetime of PPBE Tasks,[0],[0]
ADD2X2 scenario: The first scenario in Fig. 2(a) uses of a 2× 2 grid of MNIST digits.,3. A Lifetime of PPBE Tasks,[0],[0]
"We set 4 tasks based on this grid: compute the sum of the digits in the (1) top row, (2) left column, (3) bottom row, (4) right column.",3. A Lifetime of PPBE Tasks,[0],[0]
"All tasks require classification of MNIST digits, but need different programs to compute the result.",3. A Lifetime of PPBE Tasks,[0],[0]
"As training examples, we supply only a grid and the resulting sum.",3. A Lifetime of PPBE Tasks,[0],[0]
"Thus, we never directly label an MNIST digit with its class.
",3. A Lifetime of PPBE Tasks,[0],[0]
APPLY2X2 scenario: The second scenario in Fig. 2(b) presents a 2 × 2 grid of of handwritten arithmetic operators.,3. A Lifetime of PPBE Tasks,[0],[0]
"Providing three auxiliary random integers d1, d2, d3, we again set 4 tasks based on this grid, namely to evaluate the expression1",3. A Lifetime of PPBE Tasks,[0],[0]
"d1 op1 d2 op2 d3 where (op1,op2) are the operators represented in the (1) top row, (2) left column, (3) bottom row, (4) right column.",3. A Lifetime of PPBE Tasks,[0],[0]
"In comparison to the first scenario, the dataset of operators is relatively small and consistent2, making the perceptual task of classifying operators considerably easier.
MATH scenario: The final task in Fig.",3. A Lifetime of PPBE Tasks,[0],[0]
"2(c) requires combination of the knowledge gained from the weakly labeled data in the first two scenarios to execute a handwritten arithmetic expression.
",3. A Lifetime of PPBE Tasks,[0],[0]
"1Note that for simplicity, our toy system ignores operator precedence and executes operations from left to right - i.e. the sequence in the text is executed as ((d1 op1 d2) op2 d3).
",3. A Lifetime of PPBE Tasks,[0],[0]
2200 handwritten examples of each operator were collected from a single author to produce a training set of 600 symbols and a test set of 200 symbols from which to construct random 2 × 2 grids.,3. A Lifetime of PPBE Tasks,[0],[0]
We study two kinds of NTPT model.,4. Models,[0],[0]
"First, for navigating the introductory 2 × 2 grid scenarios, we create a model which learns to write simple straight-line code.",4. Models,[0],[0]
"Second, for the MATH scenario we ask the system to use a more complex language which supports loopy control flow (note that the baselines will also be specialized between the 2 × 2 scenarios and the MATH scenario).",4. Models,[0],[0]
Knowledge transfer is achieved by defining a library of 2 neural network functions shared across all tasks and scenarios.,4. Models,[0],[0]
Training on each task should produce a task-specific source code solution (from scratch) and improve the overall usefulness of the shared networks.,4. Models,[0],[0]
"All models are included in Supplementary Material, and below we outline further details of the models.",4. Models,[0],[0]
We refer to the 2 networks in the shared library as net 0 and net 1.,4.1. Shared components,[0],[0]
Both networks have similar architectures: they take a 28 × 28 monochrome image as input and pass this sequentially through two fully connected layers each with 256 neurons and ReLU activations.,4.1. Shared components,[0],[0]
"The last hidden vector is passed through a fully connected layer and a softmax to produce a 10 dimensional output (net 0) or 4 dimensional output (net 1) to feed to the differentiable interpreter (the output sizes are chosen to match the number of classes of MNIST digits and arithmetic operators respectively).
",4.1. Shared components,[0],[0]
"One restriction that we impose is that when a new task is presented, no more than one new untrained network can be introduced into the library (i.e. in our experiments the very first task has access to only net 0, and all other tasks have access to both nets).",4.1. Shared components,[0],[0]
"This restriction is imposed because if a differentiable program tries to make a call to one of N untrained networks based on an unknown parameter net choice = Param(N), then the system effectively sees the N nets together with the net choice parameter as one large untrained network, which cannot usefully be split apart into the N components after training.",4.1. Shared components,[0],[0]
For the 2× 2 scenarios we build a model capable of writing short straight line algorithms with up to 4 instructions.,4.2. 2× 2 model,[0],[0]
"The model consists of a read head containing net 0 and net 1 which are connected to a set of registers each capable of holding integers in the range 0, . . .",4.2. 2× 2 model,[0],[0]
",M , where M = 18.",4.2. 2× 2 model,[0],[0]
The head is initialized reading the top left cell of the 2× 2 grid.,4.2. 2× 2 model,[0],[0]
"At each step in the program, one instruction can be executed, and lines of code are constructed by choosing an instruction and addresses of arguments for that instruction.",4.2. 2× 2 model,[0],[0]
"We follow (Feser et al., 2016) and allow each line to store its result in a separate immutable register.",4.2. 2× 2 model,[0],[0]
"For the ADD2X2 scenario the instruction set is:
• NOOP: a trivial no-operation instruction.
",4.2. 2× 2 model,[0],[0]
"• MOVE NORTH, MOVE EAST, MOVE SOUTH, MOVE WEST: translate the head (if possible) and return the result of applying the neural network chosen by net choice to the image in the new cell.
",4.2. 2× 2 model,[0],[0]
"• ADD(·, ·): accepts two register addresses and returns the sum of their contents.
",4.2. 2× 2 model,[0],[0]
The parameter net choice is to be learned and decides which of net 0 and net 1 to apply.,4.2. 2× 2 model,[0],[0]
"In the APPLY2X2 scenario we extend the ADD instruction to APPLY(a, b, op) which interprets the integer stored at op as an arithmetic operator and computes3 a op b.",4.2. 2× 2 model,[0],[0]
"In addition, for the APPLY2X2 scenario we initialize three registers with the auxiliary integers supplied with each 2 × 2 operator grid",4.2. 2× 2 model,[0],[0]
[see Fig. 2(b)].,4.2. 2× 2 model,[0],[0]
"In total, this model exposes a program space of up to ∼ 1012 syntactically distinct programs.",4.2. 2× 2 model,[0],[0]
"The final task investigates the synthesis of more complex, loopy control flow.",4.3. MATH model,[0],[0]
A natural solution to execute the expression on the tape is to build a loop with a body that alternates between moving the head and applying the operators [see Fig. 4(b)].,4.3. MATH model,[0],[0]
"This loopy solution has the advantage that it generalizes to handle arbitrary length arithmetic expressions.
",4.3. MATH model,[0],[0]
Fig. 4(a) shows the basic architecture of the interpreter used in this scenario.,4.3. MATH model,[0],[0]
"We provide a set of three blocks each containing the instruction MOVE or APPLY, an address, a register and a net choice.",4.3. MATH model,[0],[0]
A MOVE instruction increments the position of the head and loads the new symbol into a block’s register using either net 0 or net 1 as determined by the block’s net choice.,4.3. MATH model,[0],[0]
"After executing the instruction, the interpreter executes a GOTO IF statement which checks whether the head is over the end of the tape and if not
3All operations are performed modulo (M + 1) and division by zero returns M .
",4.3. MATH model,[0],[0]
"then it passes control to the block specified by goto addr, otherwise control passes to a halt block which returns a chosen register value and exits the program.",4.3. MATH model,[0],[0]
This model describes a space of ∼ 106 syntactically distinct programs.,4.3. MATH model,[0],[0]
"To evaluate the merits of including the source code structure in NTPT models, we build baselines that replace the differentiable program interpreter with neural networks, thereby creating purely neural solutions to the lifelong PPBE tasks.",5. Baselines,[0],[0]
We specialize these neural baselines for the 2× 2 task (with emphasis on lifelong learning) and for the MATH task (with emphasis on generalization).,5. Baselines,[0],[0]
"We define a column as the following neural architecture (see Fig. 5(a)):
• Each of the images in the 2× 2 grid is passed through an embedding network with 2 layers of 256 neurons (cf. net 0/1) to produce a 10-dimensional embedding.",5.1. 2× 2 baselines,[0],[0]
"The weights of the embedding network are shared across all 4 images.
",5.1. 2× 2 baselines,[0],[0]
"• These 4 embeddings are concatenated into a 40- dimensional vector and for the APPLY2X2 the auxiliary integers are represented as one-hot vectors and concatenated with this 40-dimensional vector.
",5.1. 2× 2 baselines,[0],[0]
•,5.1. 2× 2 baselines,[0],[0]
"This is then passed through a network consisting of 3 hidden layers of 128 neurons to produce a 19- dimensional output.
",5.1. 2× 2 baselines,[0],[0]
"We construct 3 different neural baselines derived from this column architecture (see Fig. 5):
1. Indep.:",5.1. 2× 2 baselines,[0],[0]
"Each task is handled by an independent column with no mechanism for transfer.
",5.1. 2× 2 baselines,[0],[0]
2.,5.1. 2× 2 baselines,[0],[0]
"Progressive Neural Network (PNN): We follow (Rusu et al., 2016) and build lateral connections linking each task specific column to columns from tasks appearing earlier in the learning lifetime.",5.1. 2× 2 baselines,[0],[0]
Weights in all columns except the active task’s column are frozen during a training update.,5.1. 2× 2 baselines,[0],[0]
"Note that the number of layers in each column must be identical to allow lateral connections, meaning we cannot tune the architecture separately for each task.
3.",5.1. 2× 2 baselines,[0],[0]
Multitask neural network (MTNN): We split the column into a shared perceptual part and a task specific part.,5.1. 2× 2 baselines,[0],[0]
"The perceptual part consists of net 0 and net 1 embedding networks (note that we use a similar symmetry breaking technique mentioned in Sec. 4.1 to encourage specialization of these networks to either digit or operator recognition respectively).
",5.1. 2× 2 baselines,[0],[0]
The task-specific part consists of a neural network that maps the perceptual embeddings to a 19 dimensional output.,5.1. 2× 2 baselines,[0],[0]
"Note that unlike PNNs, the precise architecture of the task specific part of the MTNN can be tuned for each individual task.",5.1. 2× 2 baselines,[0],[0]
"We consider two MTNN architectures:
(a) MTNN-1:",5.1. 2× 2 baselines,[0],[0]
"All task-specific parts are 3 layer networks comparable to the PNN case.
",5.1. 2× 2 baselines,[0],[0]
(b) MTNN-2:,5.1. 2× 2 baselines,[0],[0]
We manually tune the number of layers for each task and find best performance when the task specific part contains 1 hidden layer for the ADD2X2 tasks and 3 layers for the APPLY2X2 tasks.,5.1. 2× 2 baselines,[0],[0]
"For the MATH task, we build purely neural baselines which (1) have previously been shown to offer competitive generalization performance for some tasks with sequential inputs of varying length (2) are able to learn to execute arithmetic operations and (3) are easily integrated with the library of perceptual networks learned in the 2× 2 tasks.",5.2. MATH baselines,[0],[0]
"We consider two models fulfilling these criteria: an LSTM and a Neural GPU.
",5.2. MATH baselines,[0],[0]
"For the LSTM, at each image in the mathematical expression the network takes in the embeddings of the current symbol from net 0 and net 1, updates an LSTM hidden state and then proceeds to the next symbol.",5.2. MATH baselines,[0],[0]
We make a classification of the final answer using the last hidden state of the LSTM.,5.2. MATH baselines,[0],[0]
"Our best performance is achieved with a 3 layer LSTM with 1024 elements in each hidden state and dropout between layers.
",5.2. MATH baselines,[0],[0]
"For the Neural GPU, we use the implementation from the original authors4 (Kaiser & Sutskever, 2016).",5.2. MATH baselines,[0],[0]
In this section we report results illustrating the key benefits of NTPT for the lifelong PPBE tasks in terms of knowledge transfer (Sec. 6.1) and generalization (Sec. 6.2).,6. Experiments,[0],[0]
"Demonstration of lifelong learning requires a series of tasks for which there is insufficient data to learn independent solutions to all tasks and instead, success requires transferring knowledge from one task to the next.",6.1. Lifelong Learning,[0],[0]
"Empirically, we find that training any of the purely neural baselines or the NTPT model on individual tasks from the ADD2X2 scenario with only 1k distinct 2× 2 examples produces low accuracies of around 40±20% (measured on a held-out test set of 10k examples).",6.1. Lifelong Learning,[0],[0]
"Since none of our models can satisfactorily solve an ADD2X2 task independently in this small data regime, we can say that any success on these tasks during a lifetime of learning can be attributed to successful knowledge transfer.",6.1. Lifelong Learning,[0],[0]
"In addition, we check that in a data rich regime (e.g. ≥4k examples) all of the baseline models and NTPT can independently solve each task with >80% accuracy.",6.1. Lifelong Learning,[0],[0]
"This indicates that the models all have sufficient capacity to represent satisfactory solutions, and the challenge is to find these solutions during training.
",6.1. Lifelong Learning,[0],[0]
We train on batches of data drawn from a time-evolving probability distribution over all 8 tasks in the 2×2 scenarios (see the top of Fig. 6(a)).,6.1. Lifelong Learning,[0],[0]
"During training, we observe the following key properties of the knowledge transfer achieved by NTPT:
4available at https://github.com/tensorflow/ models/tree/master/neural_gpu
Reverse transfer: Fig. 6(a) focuses on the performance of NTPT on the first task (ADD2X2:top).",6.1. Lifelong Learning,[0],[0]
The red bars indicate times where the the system was presented with an example from this task.,6.1. Lifelong Learning,[0],[0]
"Note that even when we have stopped presenting examples, the performance on this task continues to increase as we train on later tasks - an example of reverse transfer.",6.1. Lifelong Learning,[0],[0]
"We verify that this is due to continuous improvement of net 0 in later tasks by observing that the accuracy on the ADD2X2:top task closely tracks measurements of the accuracy of net 0 directly on the digit classification task.
",6.1. Lifelong Learning,[0],[0]
Avoidance of catastrophic forgetting: Fig. 6(b) shows the performance of the NTPT on the remaining ADD2X2 tasks.,6.1. Lifelong Learning,[0],[0]
Both Fig. 6(a) and (b) include results for the MTNN-2 baseline (the best baseline for these tasks).,6.1. Lifelong Learning,[0],[0]
Note that whenever the dominant training task swaps from an ADD2X2 task to an APPLY2X2 task the baseline’s performance on ADD2X2 tasks drops.,6.1. Lifelong Learning,[0],[0]
This is because the shared perceptual network becomes corrupted by the change in task - an example of catastrophic forgetting.,6.1. Lifelong Learning,[0],[0]
"To try to limit the extent of catastrophic forgetting and make the shared components more robust, we have a separate learning rate for the perceptual networks in both the MTNN baseline and NTPT which is 100 fold smaller than the learning rate for the task-specific parts.",6.1. Lifelong Learning,[0],[0]
"With this balance of learning rates we find empirically that NTPT does not display catastrophic forgetting, while the MTNN does.
Final performance: Fig. 6(c) focuses on the ADD2X2:left and APPLY2X2:left tasks to illustrate the relative performance of all the baselines described in Sec. 5.",6.1. Lifelong Learning,[0],[0]
"Note that although PNNs are effective at avoiding catastrophic forgetting, there is no clear overall winner between the MTNN and PNN baselines.",6.1. Lifelong Learning,[0],[0]
NTPT learns faster and to a higher accuracy than all baselines for all the tasks considered here.,6.1. Lifelong Learning,[0],[0]
For clarity we only plot results for the *:left tasks: the other tasks show similar behavior and the accuracies for all tasks at the end of the lifetime of learning are presented in Fig. 7.,6.1. Lifelong Learning,[0],[0]
In the final experiment we take net 0/1 from the end of the NTPT 2 × 2 training and start training on the MATH scenario.,6.2. Generalization,[0],[0]
For the NTPT model we train on arithmetic expressions containing only 2 digits.,6.2. Generalization,[0],[0]
"The known difficulty in training differentiable interpreters with free loop structure (Gaunt et al., 2016) is revealed by the fact that only 2/100 random restarts converge on a correct program in a global optimum of the loss landscape.",6.2. Generalization,[0],[0]
We detect convergence by a rapid increase in the accuracy on a validation set (typically occurring after around 30k training examples).,6.2. Generalization,[0],[0]
"Once the correct program is found, continuing to train the
model mainly leads to further improvement in the accuracy of net 0, which saturates at 97.5% on the digit classification task.",6.2. Generalization,[0],[0]
"The learned source code provably generalizes perfectly to expressions containing any number of digits, and the only limitation on the performance on long expressions comes from the repeated application of the imperfect net 0.
",6.2. Generalization,[0],[0]
"To pick a strong baseline for the MATH problem, we first perform a preliminary experiment with two simplifications: (1) rather than expecting strong generalization from just 2- digit training examples, we train candidate baselines with supervision on examples of up to 5 digits and 4 operators, and (2) we remove the perceptual component of the task, presenting the digits and operators as one-hot vectors rather than images.",6.2. Generalization,[0],[0]
Fig. 8(a) shows the generalization performance of the LSTM and Neural GPU (512-filter) baselines in this simpler setting after training to convergence.5,6.2. Generalization,[0],[0]
"Based on these results, we restrict attention to the LSTM baseline and return to the full task including the perceptual component.",6.2. Generalization,[0],[0]
"In the full MATH task, we initialize the embedding networks of each model using net 0/1 from the end of the NTPT 2× 2 training.",6.2. Generalization,[0],[0]
Fig. 8(b) shows generalization of the NTPT and LSTM models on expressions of up to 16 digits (31 symbols) after training to convergence.,6.2. Generalization,[0],[0]
"We find that even though the LSTM shows surprisingly effective generalization when supplied supervision for up to 5 digits, NTPT trained on only 2-digit expressions still offers better results.",6.2. Generalization,[0],[0]
Lifelong Machine Learning.,7. Related work,[0],[0]
"We operate in the paradigm of Lifelong Machine Learning (LML) (Thrun, 1994; 1995; Thrun & O’Sullivan, 1996; Silver et al., 2013;
5Note that (Price et al., 2016) also find poor generalization performance for a Neural GPU applied to the similar task of evaluating arithmetic expressions involving binary numbers.
",7. Related work,[0],[0]
"Chen et al., 2015), where a learner is presented a sequence of different tasks and the aim is to retain and re-use knowledge from earlier tasks to more efficiently and effectively learn new tasks.",7. Related work,[0],[0]
"This is distinct from related paradigms of multitask learning (where a set of tasks is presented rather than in sequence (Caruana, 1997; Kumar & Daume III, 2012; Luong et al., 2015; Rusu et al., 2016)), transfer learning (transfer of knowledge from a source to target domain without notion of knowledge retention (Pan & Yang, 2010)), and curriculum learning (training a single model for a single task of varying difficulty (Bengio et al., 2009)).
",7. Related work,[0],[0]
"The challenge for LML with neural networks is the problem of catastrophic forgetting: if the distribution of examples changes during training, then neural networks are prone to forget knowledge gathered from early examples.",7. Related work,[0],[0]
Solutions to this problem involve instantiating a knowledge repository (KR) either directly storing data from earlier tasks or storing (sub)networks trained on the earlier tasks with their weights frozen.,7. Related work,[0],[0]
"This knowledge base allows either (1) rehearsal on historical examples (Robins, 1995), (2) rehearsal on virtual examples generated by the frozen networks (Silver & Mercer, 2002; Silver & Poirier, 2006) or (3) creation of new networks containing frozen sub networks from the historical tasks (Rusu et al., 2016; Shultz & Rivest, 2001)
To frame our approach in these terms, our KR contains partially-trained neural network classifiers which we call from learned source code.",7. Related work,[0],[0]
"Crucially, we never freeze the weights of the networks in the KR: all parts of the KR can be updated during the training of all tasks - this allows us to improve performance on earlier tasks by continuing training on later tasks (so-called reverse transfer).",7. Related work,[0],[0]
"Reverse transfer has been demonstrated previously in systems which assume that each task can be solved by a model parameterized by an (uninterpretable) task-specific linear combination of shared basis weights (Ruvolo & Eaton, 2013).",7. Related work,[0],[0]
"The representation of task-specific knowledge as source code, learning from weak supervision, and shared knowledge as a deep neural networks distinguishes this work from the linear model used in (Ruvolo & Eaton, 2013).
",7. Related work,[0],[0]
Neural Networks Learning Algorithms.,7. Related work,[0],[0]
"Recently, extensions of neural networks with primitives such as memory and discrete computation units have been studied to learn algorithms from input-output data (Graves et al., 2014; Weston et al., 2014; Joulin & Mikolov, 2015; Grefenstette et al., 2015; Kurach et al., 2015; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Bunel et al., 2016; Andrychowicz & Kurach, 2016; Zaremba et al., 2016; Graves et al., 2016; Riedel et al., 2016; Gaunt et al., 2016; Feser et al., 2016).",7. Related work,[0],[0]
A dominant trend in these works is to use a neural network controller to managing differentiable computer architecture.,7. Related work,[0],[0]
"We flip this relationship, and in our approach, a differentiable interpreter acts as the controller that can make calls to neural network components.
",7. Related work,[0],[0]
"The methods above, with the exception of (Reed & de Freitas, 2016) and (Graves et al., 2016), operate on inputs of (arrays of) integers.",7. Related work,[0],[0]
"However, (Reed & de Freitas, 2016) requires extremely strong supervision, where the learner is shown all intermediate steps to solving a problem; our learner only observes input-output examples.",7. Related work,[0],[0]
"(Reed & de Freitas, 2016) also show the performance of their system in a multitask setting.",7. Related work,[0],[0]
"In some cases, additional tasks harm performance of their model",7. Related work,[0],[0]
and they freeze parts of their model when adding to their library of functions.,7. Related work,[0],[0]
"Only (Bunel et al., 2016), (Riedel et al., 2016) and (Gaunt et al., 2016) aim to consume and produce source code that can be provided by a human (e.g. as sketch of a solution) or returned to a human (to potentially provide feedback).",7. Related work,[0],[0]
"We have presented NEURAL TERPRET, a framework for building end-to-end trainable models that structure their solution as a source code description of an algorithm which may make calls into a library of neural functions.",8. Discussion,[0],[0]
"Experimental results show that these models can successfully be trained in a lifelong learning context, and they are resistant to catastrophic forgetting; in fact, they show that even after instances of earlier tasks are no longer presented to the model, performance still continues to improve.
",8. Discussion,[0],[0]
Our experiments concentrated on two key benefits of the hybrid representation of task solutions as source code and neural networks.,8. Discussion,[0],[0]
"First, the source code structure imposes modularity which can be seen as focusing the supervision.",8. Discussion,[0],[0]
"If a component is not needed for a given task, then the differentiable interpreter can choose not to use it, which shuts off any gradients from flowing to that component.",8. Discussion,[0],[0]
"We speculate that this could be a reason for the models being resistant to catastrophic forgetting, as the model either chooses to use a classifier, or ignores it (which leaves the component unchanged).",8. Discussion,[0],[0]
The second benefit is that learning programs imposes a bias that favors learning models that exhibit strong generalization.,8. Discussion,[0],[0]
"Additionally, the source code representation has the advantage of being interpretable by humans, allowing verification and incorporation of domain knowledge describing the shape of the problem through the source code structure.
",8. Discussion,[0],[0]
"The primary limitation of this design is that it is known that differentiable interpreters are difficult to train on problems significantly more complex than those presented here (Kurach et al., 2015; Neelakantan et al., 2016; Gaunt et al., 2016).",8. Discussion,[0],[0]
"However, if progress can be made on more robust training of differentiable interpreters (perhaps extending ideas in (Neelakantan et al., 2016) and (Feser et al., 2016)), then we believe there to be great promise in using hybrid models to build large lifelong learning systems.",8. Discussion,[0],[0]
We develop a framework for combining differentiable programming languages with neural networks.,abstractText,[0],[0]
Using this framework we create end-toend trainable systems that learn to write interpretable algorithms with perceptual components.,abstractText,[0],[0]
We explore the benefits of inductive biases for strong generalization and modularity that come from the program-like structure of our models.,abstractText,[0],[0]
"In particular, modularity allows us to learn a library of (neural) functions which grows and improves as more tasks are solved.",abstractText,[0],[0]
"Empirically, we show that this leads to lifelong learning systems that transfer knowledge to new tasks more effectively than baselines.",abstractText,[0],[0]
Differentiable Programs with Neural Libraries,title,[0],[0]
"√ N)) where N is the
sample size. Furthermore, we introduce novel procedures for multiple χ2 tests by incorporating the unit circle mechanism into the sparse vector technique and the exponential mechanism. These procedures can control the family-wise error rate (FWER) properly, which has never been attained by existing mechanisms.",text,[0],[0]
Hypothesis testing is a statistical framework to ascertain whether or not given samples follow a specific model or not in a systematic manner.,1. Introduction,[0],[0]
"For this study, we presume that highly sensitive information might be included in the samples.",1. Introduction,[0],[0]
A typical situation is genome-wide association studies (GWAS).,1. Introduction,[0],[0]
"Homer et al. reported that a patient’s disease status could be inferred from aggregate statistics collected for GWAS (Homer et al., 2008).
",1. Introduction,[0],[0]
"Differential privacy (Dwork et al., 2006) is a recent notion of privacy that is tailored to a privacy-preserving release of aggregate statistics.",1. Introduction,[0],[0]
"As described in this paper, we give specific consideration to the differential privacy of χ2 test
1Department of Computer Science, University of Tsukuba, 1-1-1 Tennohdai, Tsukuba, Ibaraki, Japan 2JST CREST 3RIKEN Center for Advanced Intelligence Project.",1. Introduction,[0],[0]
"Correspondence to: Kazuya Kakizaki <kazuya@mdl.cs.tsukuba.ac.jp>, Kazuto Fukuchi <kazuto@mdl.cs.tsukuba.ac.jp>, Jun Sakuma <jun@cs.tsukuba.ac.jp>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
of independence.",1. Introduction,[0],[0]
Two lines of studies exist in differentially private χ2-tests of independence: input perturbation and output perturbation.,1. Introduction,[0],[0]
"The input perturbation method ensures differential privacy by randomizing each count in the contingency table (Uhler et al., 2013; Johnson & Shmatikov, 2013; Wang et al., 2015; Gaboardi et al., 2016).",1. Introduction,[0],[0]
"The output perturbation method randomizes the test statistic to satisfy differential privacy (Fienberg et al., 2011; Yu et al., 2014; Uhler et al., 2013; Wang et al., 2015).",1. Introduction,[0],[0]
"Also recently, there is a study for the differential privacy of χ2 test of identity, which ensures type-I and typ-II error (Cai et al., 2017).
",1. Introduction,[0],[0]
The contribution of this study is three-fold.,1. Introduction,[0],[0]
"First, we analyze the type-II error of the differentially private mechanism for output perturbation.",1. Introduction,[0],[0]
"In principle, (non-privacypreserving) hypothesis test procedures are preferred to achieve a greater power with keeping the significance at a prescribed level.",1. Introduction,[0],[0]
"In the case of differentially private hypothesis test, the same is required under the constraint of differential privacy.",1. Introduction,[0],[0]
"Much efforts have been devoted to controlling the significance level properly (Wang et al., 2015; Gaboardi et al., 2016) whereas little attention has been paid to the power analysis.",1. Introduction,[0],[0]
"We analyze the type-II error of the differentially private mechanism for χ2-test, and show that it is upper-bounded by two terms which are mechanism-dependent.",1. Introduction,[0],[0]
"The bound indicates that a mechanism with a lower sensitivity and lower γ error (defined in Section 4) achieves a greater power.
",1. Introduction,[0],[0]
"Second, we investigate the geometrical property of the test statistic of the χ2-test.",1. Introduction,[0],[0]
"Then, we propose the unit circle mechanism: a novel differentially private mechanism based on the geometrical property.",1. Introduction,[0],[0]
"In existing mechanisms based on output perturbation, the sensitivity is O(1) in terms of N (Fienberg et al., 2011; Yu et al., 2014; Uhler et al., 2013).",1. Introduction,[0],[0]
"We demonstrate that the sensitivity of the unit circle mechanism is O(1/ √ N), which achieves lower type-II error (Theorem 7).
",1. Introduction,[0],[0]
"Third, we present two procedures for differentially private multiple χ2 tests of independence that can control the familywise error rate (FWER).",1. Introduction,[0],[0]
"Actually, FWER can be controlled properly using existing DP mechanisms for χ2-test by repeatedly using (Uhler et al., 2013), for example.",1. Introduction,[0],[0]
"However, such a naive construction consumes the privacy budget, which is linear to the number of all the considered
tests and which would produce useless test results.",1. Introduction,[0],[0]
"There exist several studies that work with a lower privacy budget in the multiple testing setting (Johnson & Shmatikov, 2013).",1. Introduction,[0],[0]
"However, to the best of our knowledge, no differentially private multiple testing procedure that can control FWER properly has been presented.",1. Introduction,[0],[0]
"We introduce two novel procedures for multiple χ2 tests by incorporating the unit circle mechanism into the sparse vector technique (SVT) (Dwork & Roth, 2014) and exponential mechanism (McSherry & Talwar, 2007).",1. Introduction,[0],[0]
"The exponential mechanism based procedure works in the non-interactive setting, in which the set of hypotheses considered needs to be prescribed before starting the testing procedure.",1. Introduction,[0],[0]
This mechanism first selects top-k significant hypotheses and then performs the statistical test for each hypothesis.,1. Introduction,[0],[0]
"The SVT based procedure works in the interactive setting, in which the hypothesis to be considered at each round can be interactively chosen after observing the result of the tests in the previous rounds.",1. Introduction,[0],[0]
The SVT based procedure controls FWER by adjusting the threshold of SVT using Monte Carlo sampling.,1. Introduction,[0],[0]
"Simultaneously, we show the privacy budget consumed by the both procedures is not dependent on the total number of the hypotheses considered, but only on the prescribed maximum number of hypothesizes to be accepted.",1. Introduction,[0],[0]
"Let S = {xi|xi ∈ X , i = 1, . . .",2.1. Differential Privacy,[0],[0]
", N} be a set of records.",2.1. Differential Privacy,[0],[0]
"Presume that an analyst holds S and wishes to release a result of statistical analysis f(S) to the public, where",2.1. Differential Privacy,[0],[0]
f : S,2.1. Differential Privacy,[0],[0]
→ Y is a statistical query.,2.1. Differential Privacy,[0],[0]
S and Y respectively denote the input domain and output domain.,2.1. Differential Privacy,[0],[0]
"Differential privacy (DP) is a privacy definition that restricts privacy breach of any element in S caused by releasing y = f(S) (Dwork et al., 2006).",2.1. Differential Privacy,[0],[0]
"Let d(S, S′) = |{i : xi ̸= x′i, xi ∈ S, x′i ∈ S′}| denote the Hamming distance between two sets.",2.1. Differential Privacy,[0],[0]
"When h(S, S′) = 1, we say that S and S′ are adjacent, or that S ∼ S′. Ensuring DP requires randomization of outputs, by definition.",2.1. Differential Privacy,[0],[0]
Let Mf (S) denote a randomization mechanism of f .,2.1. Differential Privacy,[0],[0]
"Mf is differentially private if it satisfies the following definition:
Definition 1 (ϵ-DP (Dwork et al., 2006)).",2.1. Differential Privacy,[0],[0]
Mechanism M : S → Y provides ϵ-DP,2.1. Differential Privacy,[0],[0]
"if, for any S ∼ S′ and Y ⊆ Y ,
Pr[M(S) ∈ Y ] ≤ exp(ϵ) Pr[M(x′) ∈ Y ].
",2.1. Differential Privacy,[0],[0]
We introduce a basic mechanism that ensures DP for scalar outputs.,2.1. Differential Privacy,[0],[0]
"For query f , the following randomization by Laplace mechanism
M(S) = f(S) + Lap(∆f ϵ )
guarantees ϵ-DP, where Lap(b) denotes a random value generated from the Laplace distribution for which the scale parameter is b (Dwork et al., 2006).",2.1. Differential Privacy,[0],[0]
"∆f denotes the sensitivity of the query, which is defined as
∆f = max S∼S′
|f(S)− f(S′)|.
",2.1. Differential Privacy,[0],[0]
We remark that no post-processing of outputs obtained from any DP mechanism changes the guarantee on,2.1. Differential Privacy,[0],[0]
"When we obtain multiple outputs from a mechanism computed on disjoint data subsets, the following composition theorem is applied.",2.2. Answering Multiple Queries,[0],[0]
"Theorem 1 (Composition theorem (McSherry & Talwar, 2007)).",2.2. Answering Multiple Queries,[0],[0]
"Let Mi : S → Yi be ϵ-DP mechanism for i = 1, · · · ,K. Let M̂ : S → Yi×, · · · ,×YK be the mechanism that outputs (M1, · · · ,MK).",2.2. Answering Multiple Queries,[0],[0]
"Then, M̂ is Kϵdifferential private.
",2.2. Answering Multiple Queries,[0],[0]
"Let f1, . . .",2.2. Answering Multiple Queries,[0],[0]
", fK be a query sequence.",2.2. Answering Multiple Queries,[0],[0]
Suppose analyst wishes to know whether or not fk(S) > τ holds for all k where τ is a threshold.,2.2. Answering Multiple Queries,[0],[0]
"If the analyst obtains {fk(S)}Kk=1, the privacy budget for each query needs to be set to 1/Kϵ to ensure ϵ-DP, which would result in extremely unuseful outputs when K is large.",2.2. Answering Multiple Queries,[0],[0]
Suppose the analyst is interested only in whether or not each output is above a threshold value.,2.2. Answering Multiple Queries,[0],[0]
"If the analyst has a good reason to believe that only s(≪ K) answers would exceed the threshold value, the sparse vector technique (SVT) (Dwork & Roth, 2014) helps to reduce consumption of the privacy budget drastically.",2.2. Answering Multiple Queries,[0],[0]
Let ⊤ mean that fk(S) > τ .,2.2. Answering Multiple Queries,[0],[0]
"Assuming SVT is terminated after answering at most s outputs, it outputs ⊤ only when the following holds for k = 1, . . .",2.2. Answering Multiple Queries,[0],[0]
":
fk(S) + Lap(4∆s/ϵ) ≥ τ",2.2. Answering Multiple Queries,[0],[0]
"+ ρ (1)
where ρ = Lap(2∆s/ϵ) and ∆ is the sensitivity of fk1.",2.2. Answering Multiple Queries,[0],[0]
"Otherwise, it outputs nothing.",2.2. Answering Multiple Queries,[0],[0]
It is proved that SVT guarantees ϵ-DP.,2.2. Answering Multiple Queries,[0],[0]
"What is remarkable about SVT is that the privacy budget is independent on the total number of the queries, but only on s. See Appendix.",2.2. Answering Multiple Queries,[0],[0]
A for the detail .,2.2. Answering Multiple Queries,[0],[0]
Let X0 and X1 be discrete random variables and presume that we are interested in the independence between the two random variables.,3.1. χ2-Test of Independence,[0],[0]
"In this study, we suppose the random variables are binary.",3.1. χ2-Test of Independence,[0],[0]
"For the statistical test of independence, the null hypothesis is that X0 and X1 are independent.",3.1. χ2-Test of Independence,[0],[0]
"Let S = {x1, · · · , xN} be a set of samples drawn
1We require that all the queries have the same sensitivity
from the two random variables where xTn = (xn,0, xn,1) ∈",3.1. χ2-Test of Independence,[0],[0]
"{0, 1}2 are realization of X0 and X1.",3.1. χ2-Test of Independence,[0],[0]
"Given S, Table 1 denotes the 2 × 2 contingency table w.r.t.",3.1. χ2-Test of Independence,[0],[0]
X0 and X1 where cpq denotes the number of samples in S such that X0 = p and X1 = q.,3.1. χ2-Test of Independence,[0],[0]
"The marginals N1, N0,M1, and M0 are defined as in Table 1.",3.1. χ2-Test of Independence,[0],[0]
"The test statistic for χ2-test of independence is given as
χ2(S) =
(c11c00 − c10c01)2N (c11 + c10)(c11 + c01)(c10 +",3.1. χ2-Test of Independence,[0],[0]
c00)(c01 + c00) .,3.1. χ2-Test of Independence,[0],[0]
"(2)
Under the null hypothesis H0, the χ2-test statistics is known to follow the χ2 distribution with one degree of freedom, asymptotically (Bishop et al., 1975).",3.1. χ2-Test of Independence,[0],[0]
"Given S and significance level α, the χ2-test of independence is run as
χ2-test(S,α) =
{ rej if χ2(S)",3.1. χ2-Test of Independence,[0],[0]
"> τα,
acc",3.1. χ2-Test of Independence,[0],[0]
"otherwise.
",3.1. χ2-Test of Independence,[0],[0]
"Therein, τα is a threshold determined such that∫∞ τ",3.1. χ2-Test of Independence,[0],[0]
χ 2 (1)(z)dz = α.,3.1. χ2-Test of Independence,[0],[0]
"Here, rej and acc respectively indicate that H0 is rejected and accepted.",3.1. χ2-Test of Independence,[0],[0]
We learn that there exists evidence that X0 and X1 are dependent on the significance level of α if H0 rejected.,3.1. χ2-Test of Independence,[0],[0]
"The type-1 error of χ2 test is equivalent to the significance level:
α = Pr[χ2(S)",3.1. χ2-Test of Independence,[0],[0]
"> τα|H0 is true].
",3.1. χ2-Test of Independence,[0],[0]
"The power is defined by the probability of rejecting the null hypothesis when the alternative hypothesis is true:
1− β = Pr[χ2(S)",3.1. χ2-Test of Independence,[0],[0]
"> τα|H1 is true]
Therein, β denotes the type-II error.
",3.1. χ2-Test of Independence,[0],[0]
Let M be a randomization mechanism for χ2 testing.,3.1. χ2-Test of Independence,[0],[0]
"Under the constraints that M ensures DP and that type-I error is preserved at most α, we evaluate the utility of the mechanism by 1− β, the power of the mechanism.",3.1. χ2-Test of Independence,[0],[0]
"The most straightforward method to ensure the DP of χ2 test is the randomization of the test statistic (Fienberg et al.,",3.2. Output Perturbation Method,[0],[0]
χ̂2(S),"2011; Yu et al., 2014; Uhler et al., 2013; Wang et al., 2015). Application of the Laplace mechanism to the χ2 statistic immediately ensures DP, as",[0],[0]
= χ2(S) +,"2011; Yu et al., 2014; Uhler et al., 2013; Wang et al., 2015). Application of the Laplace mechanism to the χ2 statistic immediately ensures DP, as",[0],[0]
"Lap( ∆
ϵ ),
where ∆ is the sensitivity of the test statistic.","2011; Yu et al., 2014; Uhler et al., 2013; Wang et al., 2015). Application of the Laplace mechanism to the χ2 statistic immediately ensures DP, as",[0],[0]
"For example, given N0 and N1 are released to the public, (Yu et al., 2014) derived the following sensitivity:
∆Y = N2
N0N1
( max{N0, N1}
max{N0, N1}+ 1
) .","2011; Yu et al., 2014; Uhler et al., 2013; Wang et al., 2015). Application of the Laplace mechanism to the χ2 statistic immediately ensures DP, as",[0],[0]
"(3)
Other sensitivity analyses are provided elsewhere in the relevant literature (Fienberg et al., 2011; Wang et al., 2015).","2011; Yu et al., 2014; Uhler et al., 2013; Wang et al., 2015). Application of the Laplace mechanism to the χ2 statistic immediately ensures DP, as",[0],[0]
"In principle, these sensitivities are in O(1) with respect to N assuming N0 ≃ N1.","2011; Yu et al., 2014; Uhler et al., 2013; Wang et al., 2015). Application of the Laplace mechanism to the χ2 statistic immediately ensures DP, as",[0],[0]
"Given a contingency table, the input perturbation method first randomizes each cell of the contingency table independently as2",3.3. Input Perturbation Method,[0],[0]
"ĉpq = cpq + Lap( 2ϵ ), and then evaluates the test statistic with the randomized table (Johnson & Shmatikov, 2013).",3.3. Input Perturbation Method,[0],[0]
"After randomization, each cell can take a negative value.",3.3. Input Perturbation Method,[0],[0]
"(Barak et al., 2007; Li et al., 2010; Hardt et al., 2012; Li & Miklau, 2012; Gaboardi et al., 2014) have suggested methods of calculating a differentially private contingency table while avoiding this problem.",3.3. Input Perturbation Method,[0],[0]
"For independence testing, (Gaboardi et al., 2016) modified the contingency table by using the work of (Lee et al., 2015) based on constraint optimization problem so that the total number of the samples is N and each cell has a positive value.",3.3. Input Perturbation Method,[0],[0]
The DP of the test statistic is readily ensured because of the post-processing theorem.,3.3. Input Perturbation Method,[0],[0]
"In input perturbation, given N0 ≃ N1, (Gaboardi et al., 2016) and (Wang et al., 2015) reported by experiments that the accuracy of the test results can be improved when the number of samples increases.",3.3. Input Perturbation Method,[0],[0]
The threshold for non-privacy-preserving χ2 test is determined based on the fact that χ2(S) follows the χ2 distribution asymptotically when H holds.,3.4. Significance Level of DP χ2 Test,[0],[0]
"However, χ̂2(S) does not follow the χ2 distribution anymore, even when H holds.",3.4. Significance Level of DP χ2 Test,[0],[0]
"For the randomization mechanism to keep the type-I error α, the threshold τα needs to be adjusted so that α = Pr[χ̂2(S) >",3.4. Significance Level of DP χ2 Test,[0],[0]
τ̂α|H0 is true] holds.,3.4. Significance Level of DP χ2 Test,[0],[0]
"Letting χ̂2(1) denote the distribution that χ̂2(S) follows, then τ̂α is determined so that
∫∞ τ̃α χ̂2(1)(z)dz = α.
",3.4. Significance Level of DP χ2 Test,[0],[0]
"For the input perturbation case, (Uhler et al., 2013) demonstrated that the test static arising from randomized cell counts asymptotically approximates the χ2 distribution.",3.4. Significance Level of DP χ2 Test,[0],[0]
"However, the sample distribution can deviate considerably from the χ2 distribution when the sample size is small.",3.4. Significance Level of DP χ2 Test,[0],[0]
"A study by (Gaboardi et al., 2016) also proved that the ex-
2When one can assume that the marginal of the table (N0 and N1) is known publicly, the global sensitivity of the count query is 1.
pectation of χ̂2(S) generated by input perturbation is biased.",3.4. Significance Level of DP χ2 Test,[0],[0]
"(Gaboardi et al., 2016) and (Wang et al., 2015) independently presented methods to correct the bias by adjusting the threshold, respectively using Monte Carlo sampling and a permutation test.
",3.4. Significance Level of DP χ2 Test,[0],[0]
"For the output perturbation case, (Uhler et al., 2013) derived a distribution of perturbed χ2 statistic when the test statistic is randomized with the Laplace distribution.",3.4. Significance Level of DP χ2 Test,[0],[0]
"In this case, the threshold can be adjusted accurately using the derived distribution.",3.4. Significance Level of DP χ2 Test,[0],[0]
"Although not described in the literature above specifically, the threshold for test statistics generated by output perturbation can be adjusted using Monte Carlo sampling in a method similar to one reported in (Gaboardi et al., 2016).",3.4. Significance Level of DP χ2 Test,[0],[0]
The type-I error can be correctly controlled by adjusting the threshold appropriately as discussed in Section 3.4 whereas theoretical analysis on the power has never been intensively investigated in existing works.,4. Power of DP χ2 Test,[0],[0]
"For the power analysis, we derive the following upper bound.",4. Power of DP χ2 Test,[0],[0]
Theorem 2.,4. Power of DP χ2 Test,[0],[0]
Let βτ denote the type-II error when one use threshold τ for the (non-privacy-preserving) χ2 test.,4. Power of DP χ2 Test,[0],[0]
Let P = {P :,4. Power of DP χ2 Test,[0],[0]
H1is true} be the set of distributions of sample sets.,4. Power of DP χ2 Test,[0],[0]
Let M be a differentially private mechanism for χ2 test and τ̂α > τα be the threshold for M that is determined so that the type-I error of M becomes α.,4. Power of DP χ2 Test,[0],[0]
"Then for any γ > 0, the upper bound of the type-II error of M is
Pr[M(S, τ̂α) = acc|H1 is true] ≤
sup P∈P {",4. Power of DP χ2 Test,[0],[0]
Pr S∼P,4. Power of DP χ2 Test,[0],[0]
"[M(S, τ̂α)=acc|χ2(S)> τ̂α+γ]+βτ̂α+γ } .
",4. Power of DP χ2 Test,[0],[0]
The proof is shown in Appendix B. The upper bound consists of the probability term and the type-II error term.,4. Power of DP χ2 Test,[0],[0]
We discuss the behavior of these terms w.r.t.,4. Power of DP χ2 Test,[0],[0]
"N .
",4. Power of DP χ2 Test,[0],[0]
The first probability term represents the probability that the privacy mechanism accepts the null hypothesis when the non-privacy-preserving test rejects it with threshold τ̂α+γ.,4. Power of DP χ2 Test,[0],[0]
"For notational simplicity, we call the probability term the γ error:
E(τ̂α, γ,M) = sup P∈P",4. Power of DP χ2 Test,[0],[0]
Pr S∼P,4. Power of DP χ2 Test,[0],[0]
"[M(S, τ̂α) = acc|χ2(S) > τ̂α",4. Power of DP χ2 Test,[0],[0]
+,4. Power of DP χ2 Test,[0],[0]
"γ].
",4. Power of DP χ2 Test,[0],[0]
The γ error measures how often the mechanism wrongly rejects the null hypothesis.,4. Power of DP χ2 Test,[0],[0]
"The γ error thus depends on the mechanism M. The analysis of this term will be discussed in the next subsection again.
",4. Power of DP χ2 Test,[0],[0]
The second term βτ̂α+γ is the type-II error of non-privacypreserving test with threshold τ̂α,4. Power of DP χ2 Test,[0],[0]
"+ γ, which depends on
the mechanism, too.",4. Power of DP χ2 Test,[0],[0]
This term becomes smaller if τ̂α is closer to τα.,4. Power of DP χ2 Test,[0],[0]
This occurs when the distribution of χ̂2(S) is close to the distribution of χ2(S).,4. Power of DP χ2 Test,[0],[0]
"In the case of output perturbation, this happens when the sensitivity of the mechanism decreases faster w.r.t.",4. Power of DP χ2 Test,[0],[0]
N .,4. Power of DP χ2 Test,[0],[0]
"Thus, fixing sample size N , a greater power would be realized by employing a mechanism with a low sensitivity .",4. Power of DP χ2 Test,[0],[0]
"First, we discuss the γ error of output perturbation.",4.1. Power Analysis of Output Perturbation,[0],[0]
Theorem 3.,4.1. Power Analysis of Output Perturbation,[0],[0]
"Let M∆ be a ϵ-differentially private mechanism of output perturbation with sensitivity ∆. Then, the γ error is upper bounded by 12 exp ( −γϵ ∆ ) .
",4.1. Power Analysis of Output Perturbation,[0],[0]
"The proof is shown in Appendix C. Substituting the sensitivity derived in Eq.3 to this bound, we can confirm that the γ error of the mechanism of (Yu et al., 2014) is O(1) in terms of N .",4.1. Power Analysis of Output Perturbation,[0],[0]
"The same conclusion is derived from the mechanisms of (Fienberg et al., 2011) and (Wang et al., 2015).",4.1. Power Analysis of Output Perturbation,[0],[0]
The sensitivities employed by these mechanisms are also O(1).,4.1. Power Analysis of Output Perturbation,[0],[0]
A mechanism with a lower γ error and a lower sensitivity is needed to achieve greater power with ensuring DP.,4.1. Power Analysis of Output Perturbation,[0],[0]
"In the input perturbation method, randomization is applied to each cell.",4.2. Power Analysis of Input Perturbation,[0],[0]
So the analysis of the γ error and the sensitivity cannot be appropriately derived.,4.2. Power Analysis of Input Perturbation,[0],[0]
"Because of this difficulty of analysis, we will evaluate the power of input perturbation numerically in Section 7.",4.2. Power Analysis of Input Perturbation,[0],[0]
This section introduces a variant of output perturbation: the unit circle mechanism.,5. Unit Circle Mechanism,[0],[0]
This section first investigates the geometrical property.,5. Unit Circle Mechanism,[0],[0]
Then a novel mechanism is designed based on the property.,5. Unit Circle Mechanism,[0],[0]
We also show that the γ error and the sensitivity asymptotically vanish in the limit of N .,5. Unit Circle Mechanism,[0],[0]
"Because of this property, the proposed mechanism achieves better power compared to existing output perturbation mechanisms.",5. Unit Circle Mechanism,[0],[0]
"Given (c11, c10) and the marginals N0 and N1 in Table 1, the test statistic of Eq. 2 is represented as
χ2(c11, c10) =",5.1. Geometrical Interpretation of χ2 Test,[0],[0]
"(c11N0 − c10N1)2N
(c11 + c10)(N",5.1. Geometrical Interpretation of χ2 Test,[0],[0]
− c11 − c10)N1N0 .,5.1. Geometrical Interpretation of χ2 Test,[0],[0]
"(4)
Letting χ2(c11, c10) = τα and rearranging Eq. 4 with respect to c11 and c10, we have a quadratic form.",5.1. Geometrical Interpretation of χ2 Test,[0],[0]
"The following lemma provides a geometrical interpretation of the test
statistic of χ2-test on the (c11, c10)-plane. Lemma 1.",5.1. Geometrical Interpretation of χ2 Test,[0],[0]
"Given τα > 0, for any N1 > 0, N0 > 0, and N > 0, χ2(c11, c10) = τα forms an ellipse on the (c11, c10)-plane.
",5.1. Geometrical Interpretation of χ2 Test,[0],[0]
The proof is presented in Appendix D. Recall that the null hypothesis is rejected at significance level α if χ2(S) > τα.,5.1. Geometrical Interpretation of χ2 Test,[0],[0]
"Using this, we can infer the following theorem.",5.1. Geometrical Interpretation of χ2 Test,[0],[0]
Theorem 4.,5.1. Geometrical Interpretation of χ2 Test,[0],[0]
Given Table 1 specified by S and a threshold τα,5.1. Geometrical Interpretation of χ2 Test,[0],[0]
"> 0, H0 is rejected if and only if (c11, c10) exists outside of the ellipse χ2(c11, c10) = τα.
",5.1. Geometrical Interpretation of χ2 Test,[0],[0]
"The proof, although it might be readily apparent, is omitted here.",5.1. Geometrical Interpretation of χ2 Test,[0],[0]
Figure 1(a) present plots of contingency tables with the ellipse.,5.1. Geometrical Interpretation of χ2 Test,[0],[0]
"For the convenience of theoretical analysis, we introduce an affine transformation V , which transforms the ellipse to the unit circle.",5.1. Geometrical Interpretation of χ2 Test,[0],[0]
"The formulation of the affine transformation V is shown in Appendix E.
Using this transformation, χ2 test can be conducted by using ||V ((c11, c10)t)||2 as the test statistic.",5.1. Geometrical Interpretation of χ2 Test,[0],[0]
Theorem 5.,5.1. Geometrical Interpretation of χ2 Test,[0],[0]
Given Table 1 specified by S and a threshold τα,5.1. Geometrical Interpretation of χ2 Test,[0],[0]
"> 0, H0 is rejected if and only if ||V ((c11, c10)t)||2 > 1, i.e., V ((c11, c10)t) exists outside of the unit circle.
",5.1. Geometrical Interpretation of χ2 Test,[0],[0]
The proof is presented in the Appendix F. Figure.,5.1. Geometrical Interpretation of χ2 Test,[0],[0]
1(b) presents the plot of contingency tables and the ellipse after transformation.,5.1. Geometrical Interpretation of χ2 Test,[0],[0]
The input perturbation ensures DP by randomizing c10 and c11 independently by the Laplace or Gaussian mechanism.,5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"In the unit circle view, equivalent results are obtainable by randomizing the distance from the origin, ||V ((c11, c10)t)||2, and judging whether the randomized distance is greater than 1 or not.",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"The global sensitivity of ||V ((c11, c10)t)||2 is derived as described below.",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"Lemma 2 (Sensitivity of ||V ((c11, c10)t)||2).",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
Given Table 1 specified by S and threshold τα,5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"> 0, the sensitivity of
||T ((c11, c10)t)||2 is given as
∆V,α(N0, N1) = 2
√ (N20 +N 2 1 )N + 2ταN0N1
ταN0N1N2 .",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"(5)
The proof is presented in the Appendix G. This sensitivity analysis immediately derives the following Laplace mechanism:
d̂(S)",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"= ||Vτα((c11, c10)t)||2 + Lap( ∆V,α(N0, N1)
ϵ ).",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"(6)
",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
The mechanism releasing d̂(S) ensures ϵ-DP,5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"whereas, as we already discussed in Section 3.4, if we use d̂(S) as the test statistic, the type-I error cannot be properly controlled.",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"To maintain type-I error as α or less, we want d̂(S)",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
< 1 to hold with the probability of at least 1 − α if H0 holds.,5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"To attain this state, we propose the unit circle mechanism in Algorithm 1 that controls the type-I error by generating the finite sample distribution of d̂(S) with Monte-Carlo sampling.",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"At line 2, the randomized test statistics is evaluated.",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
The for-loop starting from line 4 generates the sample distribution of the randomized test statistics when the null hypothesis is true.,5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"At line 8, the p-value of S is evaluated with the sample distribution.",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
The null hypothesis is rejected at line 10 if the p-value is less than the significance level.,5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
Theorem 6.,5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"Algorithm 1 ensures ϵ-DP.
",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"If marginals M0,M1, N0, N1 are public, then computation with Sk does not consume the privacy budget because Sk are samples that are artificially generated using the distribution specified by the public marginals.",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
All operations after line 2 are attributable to post processing and therefore do not consume the privacy budget.,5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"Consequently, the privacy budget is consumed at line 2 only.",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"Thus, the proof is immediately obtained by the privacy guarantee of the mechanism based on the global sensitivity(Dwork et al., 2006).",5.2. Privacy Analysis of Unit Circle Mechanism,[0],[0]
"From the discussion in Section 4, the power of test mechanisms can be investigated by analyzing the γ error and the sensitivity.",5.3. Utility Analysis of Unit Circle Mechanism,[0],[0]
The γ error of Algorithm 1 is obtained using the following theorem.,5.3. Utility Analysis of Unit Circle Mechanism,[0],[0]
Theorem 7.,5.3. Utility Analysis of Unit Circle Mechanism,[0],[0]
"The γ error of Algorithm 1 is
E(τ̂α, γ,M∆V,α(N0,N1))
≤ 1 2 exp
( ϵN
2
( 1− √ 1 +
4γM1M0 τ̂αN2
)
·
√ τ̂αN1N0
(N21 +N 2 0 )N + 2τ̂αN1N0
) .",5.3. Utility Analysis of Unit Circle Mechanism,[0],[0]
(7),5.3. Utility Analysis of Unit Circle Mechanism,[0],[0]
"O(exp(− √ N)), and asymptotically vanishing as the sample size increases.",The proof is shown in Appendix H. Eq. 7 is,[0],[0]
"Furthermore, the sensitivity of the unit
Algorithm 1 Unit Circle Mechanism Require: Sample set S, sig level α, privacy budget ϵ
1: Evaluate contingency table from S 2: d̂(S) = ||V ((c11, c10)t)||2 + Lap(∆V,α(N0,N1)ϵ ) 3: for k = 1 to m do 4: Sk ∼ mult(N1M1N2 , N0M1 N2 , N1M0 N2 , N0M0 N2 ) 5: Evaluate contingency table from Sk 6: d̂(Sk) = ||V ((ck11, ck10)t)||2 + Lap( ∆V,α(N k 0 ,N k 1 )
ϵ )",The proof is shown in Appendix H. Eq. 7 is,[0],[0]
"7: end for 8: p = |{i:d̂(S)
k≥d̂(S)}| m
9: if p < α then 10:",The proof is shown in Appendix H. Eq. 7 is,[0],[0]
"Return rej 11: else 12: Return acc 13: end if
circle mechanism is O( 1√ N ) as derived from Eq. 5.",The proof is shown in Appendix H. Eq. 7 is,[0],[0]
"Thus, from the discussion in Section 4, the upper bound of the type-II error of Algorithm 1 is expected to decrease with a faster rate than existing output perturbation method.",The proof is shown in Appendix H. Eq. 7 is,[0],[0]
"Presume that we are interested in the independence between random variables X0 and other K random variables, X1, X2, . . .",6. Differentially Private Multiple χ2-test,[0],[0]
", XK .",6. Differentially Private Multiple χ2-test,[0],[0]
"The objective is investigation of the independence between X0 and Xk for k = 1, . . .",6. Differentially Private Multiple χ2-test,[0],[0]
",K. We denote the null hypothesis that X0 and Xk are independent by Hk0 .",6. Differentially Private Multiple χ2-test,[0],[0]
The test statistic for independence between X0 and Xk is calculated with the set of samples Sk.,6. Differentially Private Multiple χ2-test,[0],[0]
"We suppose N0, N1, and N are the same for all Sk.",6. Differentially Private Multiple χ2-test,[0],[0]
"We can verify the independence of each random variable pair by evaluating Eq. 2 with Sk for k = 1, . . .",6. Differentially Private Multiple χ2-test,[0],[0]
",K in turn.",6. Differentially Private Multiple χ2-test,[0],[0]
"In multiple hypothesis testing, we consider to control the familywise error rate (FWER), the probability that the null hypothesis is rejected mistakenly at least once among K tests.",6. Differentially Private Multiple χ2-test,[0],[0]
"If the significance of each test is kept 1- α, the FWER of the K tests in this setting is given as 1− (1− α)K ≃ αK, which increases as K increases.",6. Differentially Private Multiple χ2-test,[0],[0]
"We use Bonferroni correction to correct the significance level so that the FWER for the entire test set is kept less than α (Bonferroni, 1936).
",6. Differentially Private Multiple χ2-test,[0],[0]
We can realize DP multiple χ2-test using the DP χ2 test mechanisms repeatedly.,6. Differentially Private Multiple χ2-test,[0],[0]
"However, the privacy guarantee weakens as the number of hypothesis K increases by Theorem 1.",6. Differentially Private Multiple χ2-test,[0],[0]
"(Fienberg et al., 2011) presented a multiple testing procedure using output perturbation.",6. Differentially Private Multiple χ2-test,[0],[0]
"This method consumes a privacy budget that is proportional to K, which makes it almost impossible to obtain useful results under a meaningful privacy guarantee.",6. Differentially Private Multiple χ2-test,[0],[0]
"(Johnson & Shmatikov, 2013; Yu et al., 2014; Simmons & Berger, 2016) presented a method which outputs the top s1 significant random variable pairs using the exponential mechanism
(McSherry & Talwar, 2007).",6. Differentially Private Multiple χ2-test,[0],[0]
This method outputs s1 pairs even if all pairs are not significant.,6. Differentially Private Multiple χ2-test,[0],[0]
"For that reason, naive application of exponential mechanism cannot control FWER.
",6. Differentially Private Multiple χ2-test,[0],[0]
"In this section, we provide two differentially private multiple hypothesis testing methods that can conserve the privacy budget even with large K and controls FWER properly.",6. Differentially Private Multiple χ2-test,[0],[0]
"The exponential mechanism based procedure works in the non-interactive setting, in which the set of hypotheses considered needs to be prescribed before starting the testing procedure.",6. Differentially Private Multiple χ2-test,[0],[0]
"The SVT based procedure works in the interactive setting (Lyu et al., 2017), in which the hypothesis to be considered at each round can be interactively chosen after observing the result of the tests in the previous rounds (Webb & Petitjean, 2016).",6. Differentially Private Multiple χ2-test,[0],[0]
We first show the SVT-based procedure with the unit circle mechanism (UCM+SVT).,6.1. Unit Circle Mechanism + SVT,[0],[0]
"Recall that the unit circle mechanism verifies the result by checking if ||V ((c11, c10)t)||2",6.1. Unit Circle Mechanism + SVT,[0],[0]
> 1.,6.1. Unit Circle Mechanism + SVT,[0],[0]
"Also, provided all the marginals are public information and N0 and N1 are the same for all Sk, the sensitivity of ||V ((c11, c10)t)||2 is the same for any contingency table.",6.1. Unit Circle Mechanism + SVT,[0],[0]
"Thus, the unit circle mechanism can be naturally incorporated into SVT.
",6.1. Unit Circle Mechanism + SVT,[0],[0]
"Application of the unit circle mechanism (i.e., thresholding by Eq. 6) to SVT immediately guarantees differential privacy.",6.1. Unit Circle Mechanism + SVT,[0],[0]
"However, the type-I error cannot be properly controlled by the naive combination.",6.1. Unit Circle Mechanism + SVT,[0],[0]
Recall that SVT adds noise to the threshold to compare in Eq. 1.,6.1. Unit Circle Mechanism + SVT,[0],[0]
"In order to control the type-I error, the threshold of SVT should be properly adjusted considering the effect of the additive noise.",6.1. Unit Circle Mechanism + SVT,[0],[0]
We employ Monte Carlo sampling to determine the threshold that properly controls the type-I error.,6.1. Unit Circle Mechanism + SVT,[0],[0]
"Also, we use Bonferoni correction to control the FWER.
",6.1. Unit Circle Mechanism + SVT,[0],[0]
"The UCM+SVT takes as input sample sets S1, · · · , SK， the significance level α, the privacy budget ϵ, and stop parameters s1 ≤ s2.",6.1. Unit Circle Mechanism + SVT,[0],[0]
"The UCN+SVT is terminated if (1) it rejects at most s1 null hypotheses, or (2) it outputs s2 test results.",6.1. Unit Circle Mechanism + SVT,[0],[0]
"Here, we remark the stop parameter s2 is not used in the regular SVT.",6.1. Unit Circle Mechanism + SVT,[0],[0]
"In our setting, we need to apply Bonferroni correction to control the FWER.",6.1. Unit Circle Mechanism + SVT,[0],[0]
We thus use s2 to upper bound the maximum number of hypotheses considered.,6.1. Unit Circle Mechanism + SVT,[0],[0]
"The settings and the algorithm are detailed in Appendix I.
",6.1. Unit Circle Mechanism + SVT,[0],[0]
"In the experimental results of single hypothesis test in Section 7, input perturbation+MC also achieves good performance.",6.1. Unit Circle Mechanism + SVT,[0],[0]
"However, when input perturbation is used, the sensitivity of the test statistic is not uniform and thus it cannot be used with SVT.",6.1. Unit Circle Mechanism + SVT,[0],[0]
We introduce another DP multiple test procedure using the exponential mechanism (UCM+EM).,6.2. Unit Circle Mechanism + EM,[0],[0]
"By simple application of the exponential mechanism, we can get the top s1 significant random variable pairs.",6.2. Unit Circle Mechanism + EM,[0],[0]
"However, this method outputs s1 pairs even if all pairs are not significant.",6.2. Unit Circle Mechanism + EM,[0],[0]
"For that reason, it cannot control FWER.",6.2. Unit Circle Mechanism + EM,[0],[0]
"By adding s1 significant dummy pairs of random variables, we can avoid accepting non-significant random variable pairs.",6.2. Unit Circle Mechanism + EM,[0],[0]
"However, this method does not necessarily control FWER properly because we cannot add appropriate dummy pairs to control FWER without knowing the scores related the p-values of non-significant pairs.",6.2. Unit Circle Mechanism + EM,[0],[0]
"In order to control FWER properly, we can use the exponential mechanism to select candidate pairs, and then apply the unit circle mechanism to the candidate pairs so that the significance level of each test is properly controlled.",6.2. Unit Circle Mechanism + EM,[0],[0]
The settings and the algorithm is detailed in Appendix J.,6.2. Unit Circle Mechanism + EM,[0],[0]
"In this section, we evaluate the significance and the power of the respective mechanisms, input perturbation (Gaboardi et al., 2016), output perturbation (Yu et al., 2014), and unit circle mechanism for single hypothesis testing.",7.1. Experiments for Single Testing,[0],[0]
Both the output perturbation and the unit circle mechanism use N1 and N0 as public information.,7.1. Experiments for Single Testing,[0],[0]
"If these are public, the sensitivity of the input perturbation can be made 1.",7.1. Experiments for Single Testing,[0],[0]
"For controlling the significance of input perturbation, we use MCIndepLap with the Laplace distribution in (Gaboardi et al., 2016).",7.1. Experiments for Single Testing,[0],[0]
The significance of the unit circle mechanism and output perturbation is controlled by adjusting τα by Monte Carlo sampling.,7.1. Experiments for Single Testing,[0],[0]
"For Monte Carlo sampling, we set the number of sampling as 1000 for MCIndepLap with the laplace distribution, and 10000 for the other methods.",7.1. Experiments for Single Testing,[0],[0]
"For output perturbation, we used the sensitivity derived in Eq.3.
Significance.",7.1. Experiments for Single Testing,[0],[0]
"To evaluate the significance, we sample 1000 contingency tables from mult(0.25, 0.25, 0.25, 0.25) so that H0 is true.",7.1. Experiments for Single Testing,[0],[0]
"mult(·, ·, ·, ·) denotes the multinomial distribution.",7.1. Experiments for Single Testing,[0],[0]
"Then, we assess the proportion that the mechanism outputs acc correctly.",7.1. Experiments for Single Testing,[0],[0]
"We set the privacy parameter as ϵ = 0.1 and significance level as α = 0.05.
",7.1. Experiments for Single Testing,[0],[0]
"In Figure 2, the significance of mechanisms are shown.",7.1. Experiments for Single Testing,[0],[0]
"If Monte Carlo sampling is not used (Figure 2(a)-2(c)), the significance remains poor for small samples.",7.1. Experiments for Single Testing,[0],[0]
The significance of output perturbation unchanged even when the sample size increases.,7.1. Experiments for Single Testing,[0],[0]
"However, the input perturbation and the unit circle mechanism improve the significance as the sample size increases.",7.1. Experiments for Single Testing,[0],[0]
"The controlled significance version of these mechanisms can properly control the significance
at 0.95 for any sample size (Figure 2(d)-2(f)).
Power.",7.1. Experiments for Single Testing,[0],[0]
Evaluation of the power of the respective mechanisms controlling significance is presented.,7.1. Experiments for Single Testing,[0],[0]
"We sample 1000 contingency tables from mult(0.25 + 0.01, 0.25 − 0.01, 0.25− 0.01, 0.25 + 0.01) so that H1 is true.",7.1. Experiments for Single Testing,[0],[0]
"To evaluate the power, we assess the rate at which the mechanism outputs rej correctly when H1 is true.",7.1. Experiments for Single Testing,[0],[0]
We set the privacy parameter ϵ,7.1. Experiments for Single Testing,[0],[0]
"= 0.1 and significance level α = 0.05.
",7.1. Experiments for Single Testing,[0],[0]
Figure 3 shows that the unit circle mechanism with Monte Carlo sampling (UCM+MC) has similar power to that of the input perturbation with Monte Carlo sampling (IP+MC).,7.1. Experiments for Single Testing,[0],[0]
"In addition, compared with output perturbation with Monte Carlo sampling (OP+MC), UCM+MC quickly improves the power as the number of samples increases.
",7.1. Experiments for Single Testing,[0],[0]
The γ-error of UCM+MC can be analyzed as discussed in Section 3.4.,7.1. Experiments for Single Testing,[0],[0]
UCM+MC has a faster rate of the power than OP+MC because the γ-error of the UCM+MC decreases as the sample size increases.,7.1. Experiments for Single Testing,[0],[0]
"Unlike the UCM/OP+MC, the γerror of IP+MC has never been analyzed.",7.1. Experiments for Single Testing,[0],[0]
The UCM+MC is thus advantageous compared with the IP+MC in that the upper bound of type-II error is analyzed by Theorem 2.,7.1. Experiments for Single Testing,[0],[0]
"We remark that, looking at the results of the power, IP+MC and UCM+MC might have the same the γ-error rate.",7.1. Experiments for Single Testing,[0],[0]
The analysis of IP+MC remains as future work.,7.1. Experiments for Single Testing,[0],[0]
"In this subsection, we experimentally evaluate FWER and utility of UCM+SVT and UCM+EM.
FWER.",7.2. Experiments for Multiple Testing,[0],[0]
FWER can be properly controlled if the significance for a single test is exactly adjusted to α by using the Bonferroni correction.,7.2. Experiments for Multiple Testing,[0],[0]
"In UCM+EM, the significance of each test perfomed by UCM is properly controlled with a sufficiently large number of Monte Carlo samples.",7.2. Experiments for Multiple Testing,[0],[0]
We can thus guarantee that FWER is properly controlled by applying Bonferroni correction.,7.2. Experiments for Multiple Testing,[0],[0]
"Since we can confirme this from Fig. 2, we skip experimental evaluation of the significance of UCM+EM.",7.2. Experiments for Multiple Testing,[0],[0]
"Similarly, UCM+SVT is expected to properly control FWER with a sufficiently large number of Monte Carlo samples.",7.2. Experiments for Multiple Testing,[0],[0]
"To confirm this, we evaluate the FWER of UCM+SVT experimentally.
",7.2. Experiments for Multiple Testing,[0],[0]
"In order to evaluate the FWER of UCM+SVT, all samples must be drawn from the null distribution.",7.2. Experiments for Multiple Testing,[0],[0]
We artificially generated samples for evaluation in the following manner.,7.2. Experiments for Multiple Testing,[0],[0]
"We generated 1000 sample sets from mult(0.25, 0.25, 0.25, 0.25) so that H0 is true.",7.2. Experiments for Multiple Testing,[0],[0]
"Then, we assess the rate at which UCM+SVT outputs acc correctly.",7.2. Experiments for Multiple Testing,[0],[0]
We set the privacy parameter as ϵ = 0.1 and the significance level as α = 0.05.,7.2. Experiments for Multiple Testing,[0],[0]
"We set the stop parameters as s1 = 1 and s2 = 1, and evaluate the significance 1 − α for a single test instead of FWER.",7.2. Experiments for Multiple Testing,[0],[0]
"Note that we can control FWER by Bonferroni correction for multiple tests if the
mechanism can guarantee the significance of a single test.",7.2. Experiments for Multiple Testing,[0],[0]
"Also, we remark that this does not mean that our mechanism cannot work with multiple sample sets.
",7.2. Experiments for Multiple Testing,[0],[0]
Figure 4 shows the significance level of UCM+SVT when the sample size is changed.,7.2. Experiments for Multiple Testing,[0],[0]
"As we can see from the figure, UCM+SVT can control the significance at the prescribed level (0.95) for any sample size.
Utility.",7.2. Experiments for Multiple Testing,[0],[0]
"Next, we compare the utility of UCM+SVT and UCM+EM with existing methods.",7.2. Experiments for Multiple Testing,[0],[0]
"We denote the SVT with the output perturbation by OP+SVT, the EM with the input perturbation by IP+EM.",7.2. Experiments for Multiple Testing,[0],[0]
"We compare the correctness of these algorithms with respect to the sample size.
",7.2. Experiments for Multiple Testing,[0],[0]
"For evaluation, we artificially generated K = 10 sample sets in the following method.",7.2. Experiments for Multiple Testing,[0],[0]
"We fix the marginals Nk1 = N 2 , N k 0",7.2. Experiments for Multiple Testing,[0],[0]
"= N 2 ,M k 1 = N 2 ,M k 0 = N 2 , and then create the sample sets S1, . . .",7.2. Experiments for Multiple Testing,[0],[0]
", SK so that the test statistics of the resulting sample sets become χ2(Sk) ∈ {1, 1, 1, 1, 1, 1, 1, 1, 30, 30}.",7.2. Experiments for Multiple Testing,[0],[0]
"Two of them reject the corresponding null hypotheses at significance level α = 0.05 after Bonferroni correction (i.e., χ2(Sk) = 30).",7.2. Experiments for Multiple Testing,[0],[0]
"Regarding the remaining eight sample sets, the corresponding null hypotheses are accepted.",7.2. Experiments for Multiple Testing,[0],[0]
"We input Sk to the algorithms, and then evaluate the utility.",7.2. Experiments for Multiple Testing,[0],[0]
"For utility measure, we employ the correctness rr′ , where r is the number that the algorithm outputs rej correctly; r′ is the number of the contingency tables rejected by non-private multiple χ2 tests with Bonferroni correction.",7.2. Experiments for Multiple Testing,[0],[0]
"In our artificially generated sample sets, r′ = 2.",7.2. Experiments for Multiple Testing,[0],[0]
"For UCM+SVT, we input the sample sets in a random order.",7.2. Experiments for Multiple Testing,[0],[0]
"We set the privacy parameter as ϵ = {0.1, 0.5}, the significance levels as α = 0.05, and the stop parameters as s1 = 2, s2 = 10.
",7.2. Experiments for Multiple Testing,[0],[0]
Figure 5 shows the correctness (average of 100 trials) of each algorithm with respect to the sample size.,7.2. Experiments for Multiple Testing,[0],[0]
"As we see from the figure, the correctness of UCM+SVT approaches to 1 when N increases while the correctness of OP+SVT does not.",7.2. Experiments for Multiple Testing,[0],[0]
This is because the sensitivity of the unit circle mechanism decreases faster than that of output perturbation with respect to the sample size.,7.2. Experiments for Multiple Testing,[0],[0]
Both UCM+EM and IP+EM have the comparable correctness.,7.2. Experiments for Multiple Testing,[0],[0]
"We remark that UCM is advantageous compared to IP in the sense that the type-II error of UCM is upper-bounded as we discuss in Section 5, while no theoretical guarantee on the type-II error of input perturbation is provided.
",7.2. Experiments for Multiple Testing,[0],[0]
The algorithms using EM achieves better correctness than the algorithms using SVT.,7.2. Experiments for Multiple Testing,[0],[0]
This difference of the correctness comes from the settings that SVT and EM can handle.,7.2. Experiments for Multiple Testing,[0],[0]
"As we discussed in Section 6, SVT can deal with the interactive setting whereas EM considers the non-interactive setting only.",7.2. Experiments for Multiple Testing,[0],[0]
"In this sense, the results of these two procedures are not directly comparable.",7.2. Experiments for Multiple Testing,[0],[0]
We thank anonymous reviewers for insightful reviews and discussions.,Acknowledgement,[0],[0]
We appreciate that one of the reviewers gives an important suggestion regarding the combination of the unit circle mechanism and exponential mechanism.,Acknowledgement,[0],[0]
We thank Prof. Hideitsu Hino and Dr. Masayuki Terada for important comments that greatly improved the manuscript.,Acknowledgement,[0],[0]
The research is partly supported by JST CREST Grant Number JPMJCR1302 and JSPS Grand-in-Aid for Scientific Research No. 16H02864.,Acknowledgement,[0],[0]
"Satyen, McSherry, Frank, and Talwar, Kunal.","Barak, Boaz, Chaudhuri, Kamalika, Dwork, Cynthia, Kale,",[0],[0]
"Privacy, accuracy, and consistency too: a holistic solution to contingency table release.","Barak, Boaz, Chaudhuri, Kamalika, Dwork, Cynthia, Kale,",[0],[0]
"In Proceedings of the twenty-sixth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems, pp.","Barak, Boaz, Chaudhuri, Kamalika, Dwork, Cynthia, Kale,",[0],[0]
"273–282, 2007.","Barak, Boaz, Chaudhuri, Kamalika, Dwork, Cynthia, Kale,",[0],[0]
Paul W. Discrete multivariate analysis: Theory and practice.,"Bishop, Yvonne M.M, Fienberg, Stephen E, and Holland,",[0],[0]
"1975.
","Bishop, Yvonne M.M, Fienberg, Stephen E, and Holland,",[0],[0]
"Bonferroni, C.E. Teoria statistica delle classi e calcolo delle probabilità.","Bishop, Yvonne M.M, Fienberg, Stephen E, and Holland,",[0],[0]
Pubblicazioni del R. Istituto superiore di scienze economiche e commerciali di Firenze.,"Bishop, Yvonne M.M, Fienberg, Stephen E, and Holland,",[0],[0]
"Libreria internazionale Seeber, 1936.
","Bishop, Yvonne M.M, Fienberg, Stephen E, and Holland,",[0],[0]
"Cai, Bryan, Daskalakis, Constantinos, and Kamath, Gautam.","Bishop, Yvonne M.M, Fienberg, Stephen E, and Holland,",[0],[0]
Priv’it:,"Bishop, Yvonne M.M, Fienberg, Stephen E, and Holland,",[0],[0]
Private and sample efficient identity testing.,"Bishop, Yvonne M.M, Fienberg, Stephen E, and Holland,",[0],[0]
"In Proceedings of The 34rd International Conference on Machine Learning, pp.","Bishop, Yvonne M.M, Fienberg, Stephen E, and Holland,",[0],[0]
"to appear, 2017.
Dwork, Cynthia and Roth, Aaron.","Bishop, Yvonne M.M, Fienberg, Stephen E, and Holland,",[0],[0]
The algorithmic foundations of differential privacy.,"Bishop, Yvonne M.M, Fienberg, Stephen E, and Holland,",[0],[0]
"Foundations and Trends in Theoretical Computer Science, 9(3-4):211–407, 2014.","Bishop, Yvonne M.M, Fienberg, Stephen E, and Holland,",[0],[0]
"Smith, Adam.","Dwork, Cynthia, McSherry, Frank, Nissim, Kobbi, and",[0],[0]
Calibrating noise to sensitivity in private data analysis.,"Dwork, Cynthia, McSherry, Frank, Nissim, Kobbi, and",[0],[0]
"In Proceedings of the Third Conference on Theory of Cryptography, pp. 265–284, 2006.","Dwork, Cynthia, McSherry, Frank, Nissim, Kobbi, and",[0],[0]
Caroline.,"Fienberg, Stephen E., Slavkovic, Aleksandra, and Uhler,",[0],[0]
Privacy preserving gwas data sharing.,"Fienberg, Stephen E., Slavkovic, Aleksandra, and Uhler,",[0],[0]
"In Proceedings of the 2011 IEEE 11th International Conference on Data Mining Workshops, pp.","Fienberg, Stephen E., Slavkovic, Aleksandra, and Uhler,",[0],[0]
"628–635, 2011.","Fienberg, Stephen E., Slavkovic, Aleksandra, and Uhler,",[0],[0]
"Roth, Aaron, and Wu, Zhiwei Steven.","Gaboardi, Marco, Arias, Emilio Jesús Gallego, Hsu, Justin,",[0],[0]
Dual query: Practical private query release for high dimensional data.,"Gaboardi, Marco, Arias, Emilio Jesús Gallego, Hsu, Justin,",[0],[0]
"In Proceedings of The 31rd International Conference on Machine Learning, pp. 1170–1178, 2014.","Gaboardi, Marco, Arias, Emilio Jesús Gallego, Hsu, Justin,",[0],[0]
Salil.,"Gaboardi, Marco, Lim, Hyun, Rogers, Ryan, and Vadhan,",[0],[0]
"Differentially private chi-squared hypothesis test-
ing: Goodness of fit and independence testing.","Gaboardi, Marco, Lim, Hyun, Rogers, Ryan, and Vadhan,",[0],[0]
"In Proceedings of The 33rd International Conference on Machine Learning, pp. 2111–2120, 2016.","Gaboardi, Marco, Lim, Hyun, Rogers, Ryan, and Vadhan,",[0],[0]
simple and practical algorithm for differentially private data release.,"Hardt, Moritz, Ligett, Katrina, and McSherry, Frank. A",[0],[0]
"In Advances in Neural Information Processing Systems 25, pp. 2339–2347, 2012.","Hardt, Moritz, Ligett, Katrina, and McSherry, Frank. A",[0],[0]
"John V, Stephan, Dietrich A, Nelson, Stanley F, and Craig, David W. Resolving individuals contributing trace amounts of dna to highly complex mixtures using highdensity snp genotyping microarrays.","Homer, Nils, Szelinger, Szabolcs, Redman, Margot, Duggan, David, Tembe, Waibhav, Muehling, Jill, Pearson,",[0],[0]
"PLoS genetics, 4 (8):e1000167, 2008.","Homer, Nils, Szelinger, Szabolcs, Redman, Margot, Duggan, David, Tembe, Waibhav, Muehling, Jill, Pearson,",[0],[0]
data exploration in genome-wide association studies.,"Johnson, Aaron and Shmatikov, Vitaly. Privacy-preserving",[0],[0]
"In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp.","Johnson, Aaron and Shmatikov, Vitaly. Privacy-preserving",[0],[0]
"1079–1087, 2013.","Johnson, Aaron and Shmatikov, Vitaly. Privacy-preserving",[0],[0]
likelihood postprocessing for differential privacy under consistency constraints.,"Lee, Jaewoo, Wang, Yue, and Kifer, Daniel. Maximum",[0],[0]
"In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp.","Lee, Jaewoo, Wang, Yue, and Kifer, Daniel. Maximum",[0],[0]
"635–644, 2015.
","Lee, Jaewoo, Wang, Yue, and Kifer, Daniel. Maximum",[0],[0]
"Li, Chao and Miklau, Gerome.","Lee, Jaewoo, Wang, Yue, and Kifer, Daniel. Maximum",[0],[0]
An adaptive mechanism for accurate query answering under differential privacy.,"Lee, Jaewoo, Wang, Yue, and Kifer, Daniel. Maximum",[0],[0]
"In Proceedings of the VLDB Endowment, volume 5, pp.","Lee, Jaewoo, Wang, Yue, and Kifer, Daniel. Maximum",[0],[0]
"514–525, 2012.
","Lee, Jaewoo, Wang, Yue, and Kifer, Daniel. Maximum",[0],[0]
"Li, Chao, Hay, Michael, Rastogi, Vibhor, Miklau, Gerome, and McGregor, Andrew.","Lee, Jaewoo, Wang, Yue, and Kifer, Daniel. Maximum",[0],[0]
Optimizing linear counting queries under differential privacy.,"Lee, Jaewoo, Wang, Yue, and Kifer, Daniel. Maximum",[0],[0]
"In Proceedings of the twenty-ninth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems, pp.","Lee, Jaewoo, Wang, Yue, and Kifer, Daniel. Maximum",[0],[0]
"123–134, 2010.","Lee, Jaewoo, Wang, Yue, and Kifer, Daniel. Maximum",[0],[0]
sparse vector technique for differential privacy.,"Lyu, Min, Su, Dong, and Li, Ninghui. Understanding the",[0],[0]
"In Proceedings of the VLDB Endowment, volume 10, pp.","Lyu, Min, Su, Dong, and Li, Ninghui. Understanding the",[0],[0]
"637– 648, 2017.","Lyu, Min, Su, Dong, and Li, Ninghui. Understanding the",[0],[0]
differential privacy.,"McSherry, Frank and Talwar, Kunal. Mechanism design via",[0],[0]
"In Proceedings of the 48th Annual IEEE Symposium on Foundations of Computer Science, pp. 94–103, 2007.
Simmons, Sean and Berger, Bonnie.","McSherry, Frank and Talwar, Kunal. Mechanism design via",[0],[0]
Realizing privacy preserving genome-wide association studies.,"McSherry, Frank and Talwar, Kunal. Mechanism design via",[0],[0]
"Bioinformatics, 32(9):1293–1300, 2016.","McSherry, Frank and Talwar, Kunal. Mechanism design via",[0],[0]
Stephen E. Privacy-preserving data sharing for genomewide association studies.,"Uhler, Caroline, Slavković, Aleksandra, and Fienberg,",[0],[0]
"The Journal of privacy and confidentiality, 5(1):137, 2013.
","Uhler, Caroline, Slavković, Aleksandra, and Fienberg,",[0],[0]
"Wang, Yue, Lee, Jaewoo, and Kifer, Daniel.","Uhler, Caroline, Slavković, Aleksandra, and Fienberg,",[0],[0]
"Differentially private hypothesis testing, revisited.","Uhler, Caroline, Slavković, Aleksandra, and Fienberg,",[0],[0]
"arXiv preprint arXiv:1511.03376, 2015.
","Uhler, Caroline, Slavković, Aleksandra, and Fienberg,",[0],[0]
"Webb, Geoffrey I and Petitjean, François.","Uhler, Caroline, Slavković, Aleksandra, and Fienberg,",[0],[0]
A multiple test correction for streams and cascades of statistical hypothesis tests.,"Uhler, Caroline, Slavković, Aleksandra, and Fienberg,",[0],[0]
"In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1255–1264, 2016.","Uhler, Caroline, Slavković, Aleksandra, and Fienberg,",[0],[0]
"Uhler, Caroline.","Yu, Fei, Fienberg, Stephen E, Slavković, Aleksandra B, and",[0],[0]
Scalable privacy-preserving data sharing methodology for genome-wide association studies.,"Yu, Fei, Fienberg, Stephen E, Slavković, Aleksandra B, and",[0],[0]
"Journal of biomedical informatics, 50:133–141, 2014.","Yu, Fei, Fienberg, Stephen E, Slavković, Aleksandra B, and",[0],[0]
This paper develops differentially private mechanisms for χ2 test of independence.,abstractText,[0],[0]
"While existing works put their effort into properly controlling the type-I error, in addition to that, we investigate the type-II error of differentially private mechanisms.",abstractText,[0],[0]
"Based on the analysis, we present unit circle mechanism: a novel differentially private mechanism based on the geometrical property of the test statistics.",abstractText,[0],[0]
"Compared to existing output perturbation mechanisms, our mechanism improves the dominated term of the type-II error from O(1) to O(exp(− √ N)) where N is the sample size.",abstractText,[0],[0]
"Furthermore, we introduce novel procedures for multiple χ2 tests by incorporating the unit circle mechanism into the sparse vector technique and the exponential mechanism.",abstractText,[0],[0]
"These procedures can control the family-wise error rate (FWER) properly, which has never been attained by existing mechanisms.",abstractText,[0],[0]
Differentially Private Chi-squared Test by Unit Circle Mechanism,title,[0],[0]
"√ dOPT+
poly(log n, dd, kd). We also study the case where the data points are s-sparse and show that the clustering loss can scale logarithmically with d, i.e., log3(n)OPT + poly(log n, log d, k, s). Experiments on both synthetic and real datasets verify the effectiveness of the proposed method.",text,[0],[0]
"In this work, we consider the problem of clustering sensitive data while preserving the privacy of individuals represented in the dataset.",1. Introduction,[0],[0]
"In particular, we consider k-means and k-median clustering under the constraint of differential privacy, which is a popular information-theoretic notion of privacy (Dwork et al., 2014; 2006) that roughly requires the output of algorithm to be insensitive to changes in an individual’s data.",1. Introduction,[0],[0]
"Clustering is an important building block for many data processing tasks with applications in recommendation systems (McSherry & Mironov, 2009), database systems (Ester et al., 1996), image processing (Zhang et al., 2014; 2015; Pappas, 1992), and data mining (Berkhin, 2006).",1. Introduction,[0],[0]
"Improved privacy-preserving clustering algorithms have the potential to significantly improve
1Carnegie Mellon University, Pittsburgh, PA, USA 2Princeton University, Princeton, NJ, USA 3Peking University, Beijing, China.",1. Introduction,[0],[0]
"Correspondence to: Wenlong Mou <mouwenlong@pku.edu.cn>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"the quality of many different areas of private data analysis.
",1. Introduction,[0],[0]
"Formally, we consider the following problem:",1. Introduction,[0],[0]
"Given a set of points x1, . . .",1. Introduction,[0],[0]
", xn in Rd, privately find a set of k centers z1, . . .",1. Introduction,[0],[0]
", zk in Rd that approximately minimize one of the following clustering objectives:
n∑ i=1
min j ‖xi",1. Introduction,[0],[0]
"− zj‖2︸ ︷︷ ︸
k-means objective
or n∑ i=1
min j ‖xi",1. Introduction,[0],[0]
− zj‖︸ ︷︷ ︸ k-median objective .,1. Introduction,[0],[0]
"(1)
Minimizing these objectives exactly is NP-hard (Dasgupta, 2008), so we instead seek to find approximate solutions whose clustering objective is at most α×OPT+ β, where OPT denotes the optimal objective.",1. Introduction,[0],[0]
"Unlike the non-private setting, any differentially private clustering algorithm must have β > 0",1. Introduction,[0],[0]
"(Bassily et al., 2014).
",1. Introduction,[0],[0]
"Despite a large amount of work on private clustering, many fundamental problems remain open.",1. Introduction,[0],[0]
"One of the longstanding challenges is to design polynomial-time private k-means and k-median clustering algorithms with small clustering loss for the high-dimensional, big-data setting.",1. Introduction,[0],[0]
"There is significant evidence to indicate that even without the requirement on privacy, exact optimization of these objective function in Euclidean spaces might be computationally infeasible (Dasgupta, 2008; Aloise et al., 2009): The best-known result in this line of research is (9 + )×OPT by the local search algorithm (Kanungo et al., 2002).",1. Introduction,[0],[0]
"When the space is discrete, there exists a private algorithm that provides slightly better loss guarantee 6 × OPT (Gupta et al., 2010).",1. Introduction,[0],[0]
"However, this problem becomes notoriously hard in the context of differential privacy in Euclidean spaces, as one typically needs to preserve privacy for each point in the much larger Euclidean space.",1. Introduction,[0],[0]
While there exist algorithms in this setting with clustering loss polylog(k) × OPT + O(n/ log2 n),1. Introduction,[0],[0]
"(Nock et al., 2016), or√ d × OPT + poly(dd, kd, log n)",1. Introduction,[0],[0]
"when d is a small constant (Feldman et al., 2009) (See Table 1), the problem is left unresolved in the big-data (large n), high-dimensional (d = Ω(polylogn))",1. Introduction,[0],[0]
scenarios if we require both α and β to be as small as polylog(n).,1. Introduction,[0],[0]
Note that running the algorithm of Feldman et al. (2009) after projecting to O(log n) dimensional space gives O(log(n)log(n)),1. Introduction,[0],[0]
"error, and the algorithm of Nock et al. (2016) has Õ(n) additive loss.",1. Introduction,[0],[0]
"Moreover, brute-force discretization in O(log n) dimensional space
does not give a polynomial time algorithm.
",1. Introduction,[0],[0]
"Given the difficulty of the general form of private clustering, many positive results in this line of research have focused on the assumptions that the data points are wellseparated.",1. Introduction,[0],[0]
A set of data points are called well-separated if all near-optimal clusterings of data induce similar data partitions.,1. Introduction,[0],[0]
We can exploit such a structural assumption in many aspects.,1. Introduction,[0],[0]
"For example, these well-separated datasets are amenable to slightly perturbed initialization (Ostrovsky et al., 2012).",1. Introduction,[0],[0]
"This is the main insight behind prior work for private k-means clustering (Nissim et al., 2007; Wang et al., 2015).",1. Introduction,[0],[0]
"However, these observations and techniques break down in the general case.
",1. Introduction,[0],[0]
"Another interesting setting is when the data is extremely high dimensional, but each example is s-sparse.",1. Introduction,[0],[0]
"In this case, we might hope to improve the additive error β to be as small as poly(log d, k, log n, s).",1. Introduction,[0],[0]
"When the entries of data points are dense, the dependence of β = poly(d) is in general inevitable even if the number of centers is 1, according to the lower bound for private empirical risk minimization (Bassily et al., 2014).",1. Introduction,[0],[0]
"While some prior works have explored the possibility of non-private clustering in the context of sparse data (Barger & Feldman, 2016), much remains unknown in the private setting.",1. Introduction,[0],[0]
"Our work tackles the problem of private clustering in high-dimensional Euclidean spaces, specifically in the case when we have plentiful high-dimensional data.",1.1. Our Contributions,[0],[0]
"We advance the state-of-the-art in several aspects: • We design and analyze a computationally efficient algo-
rithm for private k-means clustering with clustering loss at most log3(n)",1.1. Our Contributions,[0],[0]
"× OPT + poly(log n, d, k) (See Corollary 1).",1.1. Our Contributions,[0],[0]
"In contrast to Nock et al. (2016) and Nissim et al. (2007), our algorithm achieves small clustering loss without additional assumptions on data.",1.1. Our Contributions,[0],[0]
"Furthermore, our clustering loss bound is also competitive even under their assumptions.
",1.1. Our Contributions,[0],[0]
• We extend our algorithm to the problem of k-median clustering.,1.1. Our Contributions,[0],[0]
"The clustering loss is at most log3/2(n) ×
OPT+poly(log n, d, k) (See Theorem 12).",1.1. Our Contributions,[0],[0]
"Our guarantee advances the state-of-the-art results of Feldman et al. (2009) in the high-dimensional space.
",1.1. Our Contributions,[0],[0]
"• In the case of s-sparse data, we further improve the additive error term β to be at most poly(log n, log d, s, k) for private k-means clustering (See Corollary 2).",1.1. Our Contributions,[0],[0]
"To the best of knowledge, this is the first result concerning the computationally efficient, differentially private clustering algorithm for high-dimensional s-sparse data.
",1.1. Our Contributions,[0],[0]
• We propose an approach for privately constructing a candidate set of centers with approximation guarantee (See Theorem 5).,1.1. Our Contributions,[0],[0]
"The candidate set can be potentially applied to other problems and is of independent interest.
",1.1. Our Contributions,[0],[0]
• We empirically compare our algorithm with the nonprivate k-means++ algorithm and four strong private baseilnes.,1.1. Our Contributions,[0],[0]
"Across all datasets, our algorithm is competitive with k-means++ and significantly outperforms the private baselines, especially for large dimensional data.",1.1. Our Contributions,[0],[0]
"Our algorithm has two main steps: First, we use the Johnson-Lindenstrauss (JL) transform to project the data into O(log n)-dimensional space and use a novel technique to privately construct a small set of good candidate centers in the projected space; Then we apply a discrete clustering algorithm to privately find k good centers from the candidate set.",1.2. Our Techniques,[0],[0]
"Centers in the original space are recovered by noisy averaging.
",1.2. Our Techniques,[0],[0]
Private Candidate Set: Our algorithm uses a novel private technique that recursively subdivides low-dimensional Euclidean spaces to construct a set of candidate points containing good centers.,1.2. Our Techniques,[0],[0]
"The algorithm proceeds in rounds, recursively subdividing the space into multiple cubes until there are few points in each cube.",1.2. Our Techniques,[0],[0]
"Finally, the algorithm outputs the centers of all cubes as a candidate set of centers.
",1.2. Our Techniques,[0],[0]
"In order to make the above procedure work well, we need to achieve three goals: (a) The output preserves privacy; (b) The algorithm is computationally efficient, i.e., the size
of candidate set is polynomial in n and k; and (c)",1.2. Our Techniques,[0],[0]
"The candidate set has high (α, β)-approximation rate, namely, it contains a subset of size k on which the clustering loss is at most α × OPT + β with α, β small.",1.2. Our Techniques,[0],[0]
"To achieve goal (a), our algorithm randomizes the decision of whether to subdivide a cube or not.",1.2. Our Techniques,[0],[0]
"To achieve goal (b), we make the probability of empty cube being further divided negligible, and the size of candidate set is upper bounded by the size of a simple partition tree, which is poly(n, k).",1.2. Our Techniques,[0],[0]
"For goal (c), it suffices to ensure each of the cluster centers to be captured within distance at scale of its own radius.",1.2. Our Techniques,[0],[0]
"As a lot of data points will be gathered around an optimal center, we can put candidate centers at each cube containing many points during partition.",1.2. Our Techniques,[0],[0]
"Random shift and repetition are used to avoid the worst cases.
",1.2. Our Techniques,[0],[0]
"From Candidate Set to Private Clustering: Our private clustering algorithm then follows the technique of local swapping on the discrete set of candidate centers, inspired by the work of Gupta et al. (2010) for k-median clustering.",1.2. Our Techniques,[0],[0]
Their algorithm maintains a set of k centers and greedily replaces one center with a better one from the candidate set.,1.2. Our Techniques,[0],[0]
"However, Gupta et al. (2010)’s algorithm only works for the k-median problem where the loss obeys the triangle inequality.",1.2. Our Techniques,[0],[0]
"To extend the analysis to the k-means problem, we adopt the techniques of Kanungo et al. (2002).",1.2. Our Techniques,[0],[0]
"In particular, we construct k swap pairs of points, take the average of gains of these swap pairs, and relate it to the optimal loss OPT.",1.2. Our Techniques,[0],[0]
"Finally, we recover the centers in the original high-dimensional space privately.",1.2. Our Techniques,[0],[0]
"Given the centers in the projected space, the centers in the original space has low sensitivity.",1.2. Our Techniques,[0],[0]
We can thus take the noisy mean of a cluster to obtain a private center for each cluster.,1.2. Our Techniques,[0],[0]
"The problem of private clustering in the Euclidean spaces was investigated by Blum et al. (2005), who proposed a private version of Lloyd iteration, which we refer to as SuLQ k-means.",2. Related Work,[0],[0]
"However, the algorithm suffers from the absence of uniform guarantee on the clustering loss.",2. Related Work,[0],[0]
"Given the sensitive and non-convex nature of clustering objective, Nissim et al. (2007) and Wang et al. (2015) applied the sampleand-aggregate framework to address the problem of private clustering by making strong assumptions on the input data.",2. Related Work,[0],[0]
"When no assumption is made on the structure of data, Feldman et al. (2009) provided an information-theoretic upper bound OPT + poly(k, d, log n) for the clustering loss according to the brute-force discretization of whole space and the exponential mechanism.",2. Related Work,[0],[0]
"However, no computationally efficient algorithm is available in the high-dimensional Euclidean spaces with clustering loss even close to this bound: Feldman et al. (2009) proposed an efficient algorithm for the bi-criteria approximation in the constantdimensional spaces, but their additive loss term β actu-
ally exponentially depends on d;",2. Related Work,[0],[0]
"Gupta et al. (2010) designed an algorithm with a constant-factor approximation ratio and poly(k, log |V |) additive loss term for clustering in the finite-data space V , but the algorithm does not work in the Euclidean spaces.",2. Related Work,[0],[0]
"Recently, Nock et al. (2016) proposed a private version of the k-means++ algorithm.",2. Related Work,[0],[0]
"However, the additive loss term β therein is almost as high as the data size n.",2. Related Work,[0],[0]
"We define some notation and clarify our problem setup.
",3. Preliminaries,[0],[0]
Notation: We will use capital letters to represent matrices or datasets and lower-case letter to represent vectors or single data points.,3. Preliminaries,[0],[0]
"For a vector v, v[i] denotes the ith entry of v. We denote by M(X) the output of an algorithm with input dataset X .",3. Preliminaries,[0],[0]
"We will frequently use d to indicate the dimension of input space, p to indicate the dimension of space after projection, and Λ to indicate the radius of input data.",3. Preliminaries,[0],[0]
"For vector norms, we will denote by ‖ · ‖ the `2 norm, ‖ · ‖0 the number of non-zero entries, and ‖ · ‖∞ the maximum of absolute value among entries.",3. Preliminaries,[0],[0]
"Define B(x,Λ) = {y :",3. Preliminaries,[0],[0]
‖x,3. Preliminaries,[0],[0]
− y‖ ≤ Λ}.,3. Preliminaries,[0],[0]
"We denote by U([−Λ,Λ]p) the uniform distribution in the p-dimensional cube [−Λ,Λ]p.",3. Preliminaries,[0],[0]
"For any set V , we denote by |V | the cardinality of the set.",3. Preliminaries,[0],[0]
"We will frequently denote the clustering loss in problem (1) on the centers z1, z2, ..., zk by L(z1, z2, ..., zk).",3. Preliminaries,[0],[0]
"A sample drawn from one-dimensional Laplace distribution with density f(x) = 12b exp ( − |x|b ) is denoted by Lap(b).
",3. Preliminaries,[0],[0]
"Problem Setup: We use the following definition of differential privacy:
Definition 1 ( -Differential Privacy).",3. Preliminaries,[0],[0]
A randomized algorithmM with output range O is -differentially private if for any given set,3. Preliminaries,[0],[0]
S ⊆ O and two datasets X ∈ Rd×n and Y =,3. Preliminaries,[0],[0]
"[X; z] for any z ∈ Rd, we have e− Pr[M(X) ∈ S] ≤",3. Preliminaries,[0],[0]
"Pr[M(Y ) ∈ S] ≤ e Pr[M(X) ∈ S].
",3. Preliminaries,[0],[0]
"In this paper, we study the problem of private clustering in high-dimensional Euclidean spaces without making any assumptions on the data structure.",3. Preliminaries,[0],[0]
"Formally, we define our problem as follows.
",3. Preliminaries,[0],[0]
Problem 1 (Private Clustering in High-Dimensional Euclidean Spaces).,3. Preliminaries,[0],[0]
Suppose d = Ω(polylog(n)) is the dimension of Euclidean space.,3. Preliminaries,[0],[0]
"Given bounded data points x1, x2, ..., xn ∈ Rd as input, how can we efficiently output k centers z1, z2, ..., zk such that the algorithm is -differentially private and the clustering loss is at most polylog(n) × OPT + poly(d, log n, k, 1 )?",3. Preliminaries,[0],[0]
"In the case of sparse data where ‖xi‖0 ≤ s for each i, can we improve the clustering loss to polylog(n) × OPT + poly(log d, log n, k, s, 1 )?
",3. Preliminaries,[0],[0]
"Algorithm 1 private partition({xi}ni=1, , δ,Q).",3. Preliminaries,[0],[0]
input X =,3. Preliminaries,[0],[0]
"[x1, x2, · · · , xn] ⊆ B(0,Λ) ⊆ Rp, parameters , δ, initial cube Q s.t. {xi}ni=1 ⊆ Q. output Private grid C",3. Preliminaries,[0],[0]
⊆,3. Preliminaries,[0],[0]
Rp.,3. Preliminaries,[0],[0]
"Initialize depth a = 0, active set of cubesA = {Q}, and set C = ∅. while a ≤ log n",3. Preliminaries,[0],[0]
and A 6= ∅ do a = a+ 1.,3. Preliminaries,[0],[0]
"C = C ∪ (⋃ Qi∈A center(Qi) ) .
",3. Preliminaries,[0],[0]
for Qi ∈,3. Preliminaries,[0],[0]
"A do Remove Qi from A. PartitionQi evenly in each dimension and obtain 2p
cubes {Q(l)i }2 p
l=1.",3. Preliminaries,[0],[0]
"for l ∈ {1, 2, · · · , 2p} do Add Q(l)i to A with probability f ( |Q(l)i ∩X| ) ,
where
f(m) =
{ 1 2 exp(−
′(γ −m)), m ≤ γ, 1− 12 exp( ′(γ −m)), otherwise,
′ = 2 logn and γ = 20 ′",3. Preliminaries,[0],[0]
"log n δ .
",3. Preliminaries,[0],[0]
"end for end for
end while",3. Preliminaries,[0],[0]
"In this section, we present an efficient algorithm that constructs a polynomial-sized candidate set of centers privately in the low-dimensional space Rp with dimension p = 8 log n. This algorithm will serve as the building block for the private clustering.",4. Private Candidate Set,[0],[0]
Our algorithm works by repeatedly applying a recursive discretization of the space with random shifts.,4. Private Candidate Set,[0],[0]
"It is worth noticing that direct extension of previous methods such as (Matoušek, 2000) lead to arbitrarily bad quality.",4. Private Candidate Set,[0],[0]
"The random shift is thus essential to our proof, which will be further explained in Appendix.",4. Private Candidate Set,[0],[0]
"We first describe our subroutine of private discretization, a private recursive division procedure: We start with a cube containing all the data points, privately decide whether to partition the current cubes based on number of data points they contain, and stop when there are few points in each cube.",4.1. Private Discretization Routine,[0],[0]
"Our algorithm is a variation of the hierarchical partitioning in (Matoušek, 2000), while setting appropriate stopping probabilities preserves privacy for our algorithm (See Algorithm 1).
",4.1. Private Discretization Routine,[0],[0]
"To make the algorithm computationally efficient, we need to show that the number of candidate centers generated by Algorithm 1 is as small as poly(n).",4.1. Private Discretization Routine,[0],[0]
"This is based on the fact that, by design, no empty cube is subdivided by our
algorithm with high probability.",4.1. Private Discretization Routine,[0],[0]
A cube is called active if the algorithm will divide the cube into multiple subcubes in the next round.,4.1. Private Discretization Routine,[0],[0]
"We have the following theorem on the size of candidate set.
",4.1. Private Discretization Routine,[0],[0]
Theorem 1.,4.1. Private Discretization Routine,[0],[0]
"The set C generated by Algorithm 1 satisfies |C| ≤ n log n, with probability 1− δ.
",4.1. Private Discretization Routine,[0],[0]
"Though we have generated n log n candidate centers, they are well-aligned and depend only slightly on the data.",4.1. Private Discretization Routine,[0],[0]
This alignment makes it possible for us to perform composition argument by the number of recursion instead of by number of points.,4.1. Private Discretization Routine,[0],[0]
"We have the following theorem on the privacy.
",4.1. Private Discretization Routine,[0],[0]
Theorem 2.,4.1. Private Discretization Routine,[0],[0]
"Algorithm 1 preserves -differential privacy.
",4.1. Private Discretization Routine,[0],[0]
"The following theorem uses tail bounds for the exponential distribution and the union bound to upper bound the number of points in each cube not subdivided by Algorithm 1.
Theorem 3.",4.1. Private Discretization Routine,[0],[0]
"With probability at least 1 − δ, in Algorithm 1, when a cube Qi is removed from A and its subdivided cubes are not inserted to A, then we have either |Qi ∩X| ≤",4.1. Private Discretization Routine,[0],[0]
"O ( γ log nδ ) , or the edge length of Qi is at most Λn .",4.1. Private Discretization Routine,[0],[0]
We now give an algorithm that constructs a polynomialsized candidate set with -differential privacy by applying the above procedure of private discretization as a subroutine.,4.2. Private Construction of Candidate Set,[0],[0]
A good candidate set should contain k potential centers with small clustering loss relative to OPT.,4.2. Private Construction of Candidate Set,[0],[0]
"We formalize such a criterion as follows.
",4.2. Private Construction of Candidate Set,[0],[0]
"Definition 2 ((α, β)-Approximate",4.2. Private Construction of Candidate Set,[0],[0]
Candidate Set).,4.2. Private Construction of Candidate Set,[0],[0]
"Given a set of points S = {x1, x2, · · · , xn} ⊆ Rp, a set of points C ⊆",4.2. Private Construction of Candidate Set,[0],[0]
"Rp is called an (α, β)-approximate candidate set of centers, if ∃z1, z2, · · · , zk ∈ C such that the clustering loss (1) on these points is at most α× OPT + β.
",4.2. Private Construction of Candidate Set,[0],[0]
"As an example, the dataset S is itself a (2, 0)-approximate candidate set, although is not private.",4.2. Private Construction of Candidate Set,[0],[0]
"One may also use an
Algorithm 2 candidate({xi}ni=1, , δ).",4.2. Private Construction of Candidate Set,[0],[0]
input X =,4.2. Private Construction of Candidate Set,[0],[0]
"[x1, x2, · · · , xn] ⊆ B(0,Λ) ⊆ Rp, parameters , δ.",4.2. Private Construction of Candidate Set,[0],[0]
"output Candidate center set C. Initialize C = ∅. for t = 1, 2, · · · , T = 27k log nδ do
Sample shift vector v ∼ U([−Λ,Λ]p).",4.2. Private Construction of Candidate Set,[0],[0]
"Let Qv = [−Λ,Λ]d + v. C = C ∪ private partition({xi}ni=1, T , δ T , Qv).
end for
Λ n -cover of B(0,Λ) to construct an (1, O(kΛγ",4.2. Private Construction of Candidate Set,[0],[0]
log n δ ),4.2. Private Construction of Candidate Set,[0],[0]
Λ 2)- approximate candidate set with privacy.,4.2. Private Construction of Candidate Set,[0],[0]
"However, this brute-force discretization results in a set of size nΩ(p) in Rp, which depends on n exponentially even if p = Θ(log n).",4.2. Private Construction of Candidate Set,[0],[0]
"In contrast, our following Algorithm 2 efficiently constructs an (O(log3 n),O(kpolylog(n)))-approximate candidate set of size polynomial in n.
Since Algorithm 2 only sees the private data through repeated application of Algorithm 1, we obtain the following privacy guarantee using standard composition theorems.
",4.2. Private Construction of Candidate Set,[0],[0]
Theorem 4.,4.2. Private Construction of Candidate Set,[0],[0]
"Algorithm 2 preserves -differential privacy.
",4.2. Private Construction of Candidate Set,[0],[0]
The remaining key argument is to show the approximation rate of candidate set constructed by Algorithm 2.,4.2. Private Construction of Candidate Set,[0],[0]
The randomness and repetition is critical for the algorithm: They make it possible for us to “guess” the position of optimal centers and avoid the worst cases.,4.2. Private Construction of Candidate Set,[0],[0]
"Figure 1 depicts how each optimal cluster may be captured by a cube of the appropriate scale, provided that the center of the cluster is not near the boundary of a cube.",4.2. Private Construction of Candidate Set,[0],[0]
"Our proof techniques are partly inspired by random grids for near neighbor reporting (Aiger et al., 2014) and locality sensitive hashing (Andoni & Indyk, 2006).",4.2. Private Construction of Candidate Set,[0],[0]
"We give a short sketch of our proof in the following, and readers may refer to the Appendix for complete proofs.
",4.2. Private Construction of Candidate Set,[0],[0]
Theorem 5.,4.2. Private Construction of Candidate Set,[0],[0]
"With probability at least 1 − δ, Algorithm 2 outputs an ( O(log3 n),O(kγ( T ) log n δ ) )",4.2. Private Construction of Candidate Set,[0],[0]
"-appriximate candidate set of centers, where γ(c) = 40c log n δ log n, and",4.2. Private Construction of Candidate Set,[0],[0]
Proof Sketch.,T = k log nδ .,[0],[0]
"There exists a set of fixed but unknown optimal centers u∗1, u ∗ 2, · · · , u∗k, and corresponding optimal clusters S∗1 , S ∗ 2 , · · · , S∗k .",T = k log nδ .,[0],[0]
"We say u∗i is captured by C
with factor L, if B ( u∗j ,",T = k log nδ .,[0],[0]
Lr ∗ j + O( 1 n ) ) ∩,T = k log nδ .,[0],[0]
C 6=,T = k log nδ .,[0],[0]
"∅, where
r∗j = √
1 |S∗j | ∑ i∈S∗j ‖xi",T = k log nδ .,[0],[0]
− ul‖2 is the average loss.,T = k log nδ .,[0],[0]
"We
will show that any optimal center is captured with factor O(log3/2 n), unless the size of corresponding cluster is too small.
",T = k log nδ .,[0],[0]
"For each u∗i , we can guarantee the number of points around it, using Markov Inequality: ∣∣B(u∗j , 2r∗j ) ∩ S∗j ∣∣",T = k log nδ .,[0],[0]
"≥ 12 ∣∣S∗j ∣∣. Consider the tree induced by hierarchical partition, as
Algorithm 3 localswap({xi}ni=1, C, , δ).",T = k log nδ .,[0],[0]
input Private dataset {xi}ni=1 ⊆,T = k log nδ .,[0],[0]
"Rp with ‖xi‖ ≤ Λ, pa-
rameters , δ, candidate set C. output Clustering centers Z =",T = k log nδ .,[0],[0]
"[z1, z2, · · · , zk] ⊆ C.
Uniformly sample k centers i.i.d.",T = k log nδ .,[0],[0]
fromC and formZ(0).,T = k log nδ .,[0],[0]
T ← 100k log nδ .,T = k log nδ .,[0],[0]
"for t = 1, 2, · · · , T do
Choose ( x ∈ Z(t−1), y ∈ C \ Z(t−1) ) with proba-
bility in proposition to exp ( − L(Z
′)−L(Z(t−1))",T = k log nδ .,[0],[0]
"8Λ2(T+1)
) ,
where Z ′ = Z(t−1) − {x}+ {y}.",T = k log nδ .,[0],[0]
Z(t) ← Z(t−1),T = k log nδ .,[0],[0]
"− {x}+ {y}.
end for Choose t ∈ {1, 2, · · · , T} with probability in proportion
to exp ( − L(Z
(t))",T = k log nδ .,[0],[0]
"8(T+1)Λ2
) .
",T = k log nδ .,[0],[0]
"Output Z(t).
shown in Theorem 3, it doesn’t stop being divided until either there’re only γ( T ) log n δ data points within it, or it’s edge length is less than 1n .",T = k log nδ .,[0],[0]
"Since the center of a cube Ql can capture points within this cube with factor √ p, we only need to show the partition tree is activated at a level with edge length pr∗j .
",T = k log nδ .,[0],[0]
"If the ball around u∗j is completely contained in Ql, we’ve already capture this center with O(log3 n) factor.",T = k log nδ .,[0],[0]
"But actually the ball can be divided into several cubes, making it hard to activate this cube.",T = k log nδ .,[0],[0]
That’s why we turn to the random shift.,T = k log nδ .,[0],[0]
"Using geometric arguments we can show that, B(u∗j , 2r∗j ) ⊆",T = k log nδ .,[0],[0]
Ql with constant probability.,T = k log nδ .,[0],[0]
"Several repetitions are then used to boost the probability of success, and to make it uniformly hold for k centers.
",T = k log nδ .,[0],[0]
"Therefore, we can guarantee that each optimal cluster with size at least Ω ( kγ log nδ ) will be captured.",T = k log nδ .,[0],[0]
"Smaller clusters can be ignored safely, as its contribution to the total clustering loss goes to the σ =",T = k log nδ .,[0],[0]
"O ( k log
3 n δ
) term.",T = k log nδ .,[0],[0]
"In this section, we develop an efficient algorithm of private clustering based on the candidate set of centers that we construct in the low-dimensional spaces.",5. From Candidate Set to Private Clustering,[0],[0]
"Technically, our approach is a two-step procedure of private discrete clustering in the low-dimensional space and private recovery in the original high-dimensional space.",5. From Candidate Set to Private Clustering,[0],[0]
"In particular, the step of private discrete clustering extends the work of Gupta et al. (2010) to the k-means problem on the candidate set of centers, and the step of private recovery outputs k centers in the input space.
5.1.",5. From Candidate Set to Private Clustering,[0],[0]
"Private Discrete Clustering
In this section, we propose a differentially private k-means algorithm in the discrete spaces.",5. From Candidate Set to Private Clustering,[0],[0]
"Inspired from the previous work on k-median problem (Gupta et al., 2010), our algorithm builds upon the local swap heuristics for k-means clustering (Kanungo et al., 2002):",5. From Candidate Set to Private Clustering,[0],[0]
"In each round, the algorithm maintains a set greedily by replacing one point therein with a better one outside (See Algorithm 3).",5. From Candidate Set to Private Clustering,[0],[0]
"We first prove that such an algorithm is differentially private.
",5. From Candidate Set to Private Clustering,[0],[0]
Theorem 6.,5. From Candidate Set to Private Clustering,[0],[0]
"Algorithm 3 preserves -differential privacy.
",5. From Candidate Set to Private Clustering,[0],[0]
Proof.,5. From Candidate Set to Private Clustering,[0],[0]
"The privacy guarantee is straightforward using the basic composition theorem over T rounds of the algorithm, and an additional exponential mechanism that selects the best one.",5. From Candidate Set to Private Clustering,[0],[0]
It is easy to verify the sensitivity of loss increments L(Z,5. From Candidate Set to Private Clustering,[0],[0]
"−{x}+ {y})−L(Z) is 8Λ2, the privacy guarantee of exponential mechanism in each round follows.
",5. From Candidate Set to Private Clustering,[0],[0]
"The analysis of clustering loss of Algorithm 3 is based on a lower bound on the total gains of k swap pairs (Gupta et al., 2010).",5. From Candidate Set to Private Clustering,[0],[0]
"However, for the k-means problem, the triangle inequality does not hold for the quadratic `2 loss.",5. From Candidate Set to Private Clustering,[0],[0]
"To resolve this issue, we apply the inequality relaxation techniques for swap pairs developed by Kanungo et al. (2002).",5. From Candidate Set to Private Clustering,[0],[0]
"We have the following theorem on the clustering loss.
",5. From Candidate Set to Private Clustering,[0],[0]
Theorem 7.,5. From Candidate Set to Private Clustering,[0],[0]
"With probability at least 1 − δ, the output of Algorithm 3 obeys L(Z) ≤ 30OPT+O",5. From Candidate Set to Private Clustering,[0],[0]
"( k2Λ2 log 2 n|C|
δ
) .",5. From Candidate Set to Private Clustering,[0],[0]
We now propose Algorithm 4 for approximately recovering k centers in the original high-dimensional space.,5.2. Private Recovery of Centers in Original Space,[0],[0]
"This algorithm is basically built on Algorithms 2 and 3 as subroutines: Algorithm 2 receives a set of points in the lowdimensional projected space as input, and outputs a small set of points that contains k centers with good clustering loss; Algorithm 3 privately outputs a set of clustering centers from a given candidate set.
",5.2. Private Recovery of Centers in Original Space,[0],[0]
"The following parallel composition lemma (McSherry, 2009) guarantees that if we have an -differentially private algorithm for recovering the center of one cluster, then we can use it to output the centers of all k centers while still preserving differential privacy.",5.2. Private Recovery of Centers in Original Space,[0],[0]
"This result follows from the fact that the clusters are disjoint.
",5.2. Private Recovery of Centers in Original Space,[0],[0]
Lemma 1 (McSherry (2009)).,5.2. Private Recovery of Centers in Original Space,[0],[0]
"Let C1, . . .",5.2. Private Recovery of Centers in Original Space,[0],[0]
", Ck be any partition of the points x1, . . .",5.2. Private Recovery of Centers in Original Space,[0],[0]
", xn in Rd and suppose thatA(S) is an differentially private algorithm that operates on sets of points in Rd.",5.2. Private Recovery of Centers in Original Space,[0],[0]
"Outputting (A(C1), . . .",5.2. Private Recovery of Centers in Original Space,[0],[0]
",A(Ck)) also preserves differential privacy.
",5.2. Private Recovery of Centers in Original Space,[0],[0]
"Now we are ready to prove the privacy of Algorithm 4.
",5.2. Private Recovery of Centers in Original Space,[0],[0]
Theorem 8.,5.2. Private Recovery of Centers in Original Space,[0],[0]
"Assume that candidate ({xi}ni=1, , δ) (Algorithm 2) preserves -differential privacy for {xi}ni=1, and that given any candidate set of centers C,
Algorithm 4 Private Clustering.",5.2. Private Recovery of Centers in Original Space,[0],[0]
"input x1, x2, · · · , xn ∈ B(0,Λ), parameters k, , δ.",5.2. Private Recovery of Centers in Original Space,[0],[0]
"output Clustering centres z1, z2, · · · , zk ∈ Rd.
",5.2. Private Recovery of Centers in Original Space,[0],[0]
"Set dimension p = 8 log n, number of trials T = 2 log 1δ .",5.2. Private Recovery of Centers in Original Space,[0],[0]
"for t = 1, 2, · · ·T do
Sample G ∼ N (0, 1)p×d.",5.2. Private Recovery of Centers in Original Space,[0],[0]
"[y1, y2, · · · , yn] = 1√dG[x1, x2, · · · , xn].",5.2. Private Recovery of Centers in Original Space,[0],[0]
"C = candidate ( {yi}ni=1, 6T , δ ) .
{u1, u2, · · · , uk} = localswap ( {yi}ni=1, C, 6T , δ ) .",5.2. Private Recovery of Centers in Original Space,[0],[0]
"Sj = {i : j = argminl ‖yi − ul‖}, j = 1, 2, · · · , k. sj = max { |Sj |+ Lap ( 24T ) , 1 } .
",5.2. Private Recovery of Centers in Original Space,[0],[0]
"z (t) j = 1 |sj | ∑ xi∈Sj xi + Lap ( 24TΛ sj )d , ∀j.
end for Choose Z from Z(1), Z(2), · · · , Z(T ) with probability in proportion to exp ( − L(Z
(t))",5.2. Private Recovery of Centers in Original Space,[0],[0]
"24Λ2
) .
",5.2. Private Recovery of Centers in Original Space,[0],[0]
"localswap ({xi}ni=1, C, , δ) (Algorithm 3) preserves - differential privacy for {xi}ni=1.",5.2. Private Recovery of Centers in Original Space,[0],[0]
Then Algorithm 4 preserves -differential privacy.,5.2. Private Recovery of Centers in Original Space,[0],[0]
"Putting everything together, we have the following theorem on the clustering loss of Algorithm 4.",5.2. Private Recovery of Centers in Original Space,[0],[0]
The key technique in our proof is to convert the argument of preservation of pairwise distance in the JL Lemma to the bound on the clustering loss.,5.2. Private Recovery of Centers in Original Space,[0],[0]
This is due to a simple observation that the optimal loss in any cluster only depends on the pairwise distances among its data points.,5.2. Private Recovery of Centers in Original Space,[0],[0]
Theorem 9.,5.2. Private Recovery of Centers in Original Space,[0],[0]
"Assume that candidate ({xi}ni=1, , δ) (Algorithm 2) outputs an (α, σ1( ))-approximate candidate set with probability at least 23 , and that with probability at least 23 , localswap ({xi} n i=1, C, , δ) (Algorithm 3) achieves clustering loss at most cOPTC + σ2( ), where OPTC is the optimal clustering centers in the candidate set of centers C. Then with probability at least 1 − δ, the output of Algorithm 4 has k-means clustering loss at most 3cαOPT + 3cσ′1 + 3σ ′",5.2. Private Recovery of Centers in Original Space,[0],[0]
"2 + O ( dΛ2 log3 1δ 2 ) , where
σ′i = σi
(
2 log 1/δ
) for i = 1, 2.
Theorem 9, together with Theorems 5 and 7, leads to the following guarantees on the clustering loss of Algorithm 4.",5.2. Private Recovery of Centers in Original Space,[0],[0]
Corollary 1.,5.2. Private Recovery of Centers in Original Space,[0],[0]
"There is an -differential private algorithm that runs in poly(k, d, n) time, and releases a set of centers z̃1, z̃2, · · · , z̃k such that with probability at least 1− δ, L ( {z̃j}kj=1 ) ≤ O(log3",5.2. Private Recovery of Centers in Original Space,[0],[0]
n)OPT +,5.2. Private Recovery of Centers in Original Space,[0],[0]
O ( k2 +d 2 Λ 2 log5 nδ ) .,5.2. Private Recovery of Centers in Original Space,[0],[0]
"In this section, we present two extensions of our algorithms: a) private k-means clustering with highdimensional sparse data; b) private k-median clustering.
",6. Extensions,[0],[0]
6.1.,6. Extensions,[0],[0]
"High-Dimensional Sparse Data
Algorithm 5 Privately Recover Centers for Sparse Dataset.",6. Extensions,[0],[0]
"input Private data set {xi}ni=1 ⊆ Rd with ‖xi‖∞ ≤
Λ, ‖xi‖0 ≤ s, parameters , δ, accuracy η.",6. Extensions,[0],[0]
"output v ∈ Rd.
Compute µ = 1n",6. Extensions,[0],[0]
∑n i=1,6. Extensions,[0],[0]
xi ∈ Rd.,6. Extensions,[0],[0]
"Initialize I = {1, 2, · · · , d}, v = 0 ∈ Rd.",6. Extensions,[0],[0]
"for j ∈ {1, 2, · · · , d 2sη e} do
Sample r ∈",6. Extensions,[0],[0]
"I with probability in proportion to exp { ηn 4Λs |µ[r]| } .
",6. Extensions,[0],[0]
I = I \,6. Extensions,[0],[0]
"{r}, v[r] = v[r] + µ[r] + Lap (
4Λs ηn
) .
end for
For the case of high-dimensional sparse data where ‖xi‖0 ≤ s, our goal is to improve the additive loss term β to be as small as poly(k, s, log d, log n) by small modifications of Algorithm 4.",6. Extensions,[0],[0]
"The steps of discretization routine, construction of candidate set, and clustering in the discrete space all remain the same as in the general case.",6. Extensions,[0],[0]
The only difference is the step of private recovery of centers in the high-dimensional original space.,6. Extensions,[0],[0]
"In the non-sparse setting, we simply take a noisy mean of points that belong to cluster i and output the center for cluster i, resulting in Ω(d) additive loss.",6. Extensions,[0],[0]
"However, such a procedure does not exploit the sparse nature of data points.",6. Extensions,[0],[0]
"The challenge is that a high-dimensional vector has too many entries to hide for differential privacy, usually resulting in large error.",6. Extensions,[0],[0]
"To improve the clustering loss, we force the output vector to be sparse, by choosing coordinates with large absolute values, while zeroing out others (See Algorithm 5).",6. Extensions,[0],[0]
"Both the choice of non-zero coordinates and the estimation of their values need to preserve privacy, for which we use both the exponential and Laplacian mechanisms.",6. Extensions,[0],[0]
"By a composition argument, we have the privacy of Algorithm 5.
",6. Extensions,[0],[0]
Theorem 10.,6. Extensions,[0],[0]
Algorithm 5 preserves -differential privacy.,6. Extensions,[0],[0]
"The following theorem guarantees that for highdimensional sparse data, the clustering loss has logarithmic dependence on the dimension.
",6. Extensions,[0],[0]
Theorem 11.,6. Extensions,[0],[0]
"With probability at least 1 − δ, the output of Algorithm 5 obeys ∑n i=1",6. Extensions,[0],[0]
"‖xi − v‖2 ≤ 1 1−ηOPT +
O
( Λ2s2 log dsηδ
η2
) .
",6. Extensions,[0],[0]
The intuition of Theorem 11 is based on the following observation:,6. Extensions,[0],[0]
"If the mean is approximately sparse, we can truncate it safely with small additional loss; If not, the mean must spread across a large set of entries, so the support of data vectors must be very different from each other, making the variance large.",6. Extensions,[0],[0]
"In both cases, the loss of truncation can be bounded by the variance of data points, and we can put such a loss of truncation to the multiplicative factor.
",6. Extensions,[0],[0]
"By the privacy argument in Lemma 1, as well as Theorems 5 and 7, we have the following result.
",6. Extensions,[0],[0]
Corollary 2.,6. Extensions,[0],[0]
"For x1, x2, · · · , xn ∈ Rd with ‖xi‖0 ≤ s and ‖xi‖∞ ≤ C, there is an -differentially private algorithm that runs in poly(k, d, n) time, and releases a set of centers z̃1, z̃2, · · · , z̃k such that with probability at least 1− δ, L ( {z̃j}kj=1 )",6. Extensions,[0],[0]
≤ O(log3 n)OPT+O,6. Extensions,[0],[0]
"( sk2+s2 log dδ log 2 n δ ) .
",6. Extensions,[0],[0]
An important implication of Corollary 2 is that private clustering for high-dimensional sparse data is as easy as private clustering in O(log d) dimensions.,6. Extensions,[0],[0]
"The approximation factor we can achieve in the high-dimensional sparse case is roughly the same as low-dimensional case.
6.2.",6. Extensions,[0],[0]
k-Median Clustering We can also easily modify our algorithms to adapt to kmedian problem.,6. Extensions,[0],[0]
"Note that Theorem 5 is independent of form of loss function, since it is based on capturing the optimal centers.",6. Extensions,[0],[0]
"Therefore, the candidate set constructed in Algorithm 2 guarantees an ( O(log
3 2 n),O(kΛγ log nδ )
) -
approximation rate.",6. Extensions,[0],[0]
"Since the discrete clustering algorithm proposed by Gupta et al. (2010) is designed for k-median, it only remains to develop a private recovery procedure in the original space Rd.",6. Extensions,[0],[0]
"According to Lemma 1, a private 1-median algorithm suffices to recover the centers.",6. Extensions,[0],[0]
"We can achieve good approximation rate via log-concave sampling (Bassily et al., 2014).",6. Extensions,[0],[0]
"Lemma 2 (Error Bound for Exponential Mechanism (Bassily et al., 2014)).",6. Extensions,[0],[0]
"For x1, x2, · · · , xn ∈ Rd, there is a polynomial-time algorithm that releases a center z and preserves -differential privacy, such that with probability at least 1 − δ, we have ∑n i=1",6. Extensions,[0],[0]
‖xi,6. Extensions,[0],[0]
− z‖,6. Extensions,[0],[0]
− minp ‖xi − p‖ ≤,6. Extensions,[0],[0]
O(dΛ log 2 1 δ ).,6. Extensions,[0],[0]
"Incorporating log-concave sampling into the step of private recovery in Algorithm 4, we derive a private k-median algorithm.",6. Extensions,[0],[0]
The privacy guarantee follows directly from Lemma 1 and the composition argument.,6. Extensions,[0],[0]
"As for the kmedian objective, the optimal clustering loss is no longer a function of pairwise distances.",6. Extensions,[0],[0]
"Fortunately, observe that the original dataset is (2, 0)-approximate candidate set for k-median loss.",6. Extensions,[0],[0]
"By this, we have the following guarantee.
",6. Extensions,[0],[0]
Theorem 12.,6. Extensions,[0],[0]
"For k-median problem, there is an - differentially private algorithms that runs in poly(k, d, n) time, and releases a set of centers z̃1, z̃2, · · · , z̃k such that with probability at least 1 − δ, L ( {z̃j}kj=1 ) ≤
O(log3/2 n)OPT +",6. Extensions,[0],[0]
"O ( (k2+d)Λ log
3 n δ
) .",6. Extensions,[0],[0]
"In this section, we present an empirical evaluation of our proposed clustering algorithm and several strong baselines on real-world image and synthetic datasets.",7. Experiments,[0],[0]
"We compare against non-private k-means++ of Arthur & Vassilvitskii (2007), SuLQ k-means of Blum et al. (2005), the sample and aggregate clustering algorithm of Nissim et al. (2007),
the k-variates++ algorithm of Nock et al. (2016), and the griding algorithm of Su et al. (2016).",7. Experiments,[0],[0]
"The k-variates++ algorithm can only run when k is small, and the griding algorithm has time and space complexity exponential in the dimension, so we are only able to compare against these two baselines with small k or small d.",7. Experiments,[0],[0]
We postpone detailed comparisons against these two algorithms to supplementary material.,7. Experiments,[0],[0]
"For all other datasets with higher dimensions and all values of k, our algorithm is competitive with non-private k-means++ and is always better than SuLQ and sample and aggregate.",7. Experiments,[0],[0]
"Moreover, in agreement with our theory, the gap between the performance of our algorithm and the other private baselines grows drastically as the dimension of the dataset increases.
",7. Experiments,[0],[0]
"The implementation of our algorithm projects to a space of dimension p = log(n)/2, rather than 8 log(n) and repeats the candidate set construction routine only k times.",7. Experiments,[0],[0]
"Finally, we perform 8 iterations of the SuLQ k-means algorithm to further improve the quality of the resulting centers.",7. Experiments,[0],[0]
"These modifications do not affect the privacy guarantee of the algorithm, but gave improved empirical performance.",7. Experiments,[0],[0]
"Our implementation of the SuLQ k-means algorithm runs for 20 iterations and uses the Gaussian mechanism to approximate the sum of points in each cluster, since this allowed us to add less noise.",7. Experiments,[0],[0]
The SuLQ algorithm initializes its centers to be k randomly chosen points from the bounding box of the data.,7. Experiments,[0],[0]
"Unless otherwise stated, we set = 1.0.
",7. Experiments,[0],[0]
Results: We first compared our algorithm and all baselines on a small synthetic dataset in 3 dimensions with k = 3.,7. Experiments,[0],[0]
"Su et al.’s griding algorithm achieves the best objective, while sample and aggregate, SuLQ, and our method all perform comparably, and k-variates++ is an order of magnitude worse.",7. Experiments,[0],[0]
Details of the comparison are given in the supplementary material.,7. Experiments,[0],[0]
"The griding algorithm and k-variates++ were not able to run in the rest of our experiments.
",7. Experiments,[0],[0]
"Next, we ran the non-private k-means++, SuLQ k-means, and sample and aggregate algorithms on the following datasets for each value of k in {2, 4, 8, 16, 32, 64}.",7. Experiments,[0],[0]
"A more detailed description is given in the supplementary material.
",7. Experiments,[0],[0]
MNIST:,7. Experiments,[0],[0]
"The raw pixels of MNIST (LeCun et al., 1998).",7. Experiments,[0],[0]
"It has 70k examples and 784 features.
",7. Experiments,[0],[0]
"CIFAR-10: 100k randomly sampled examples from the CIFAR10 dataset (Krizhevsky, 2009) with 160 features extracted from layer in3c of a Google Inception (Szegedy et al., 2015) network.
",7. Experiments,[0],[0]
"Synthetic: A synthetic dataset of 100k samples drawn from a mixture of 64 Gaussians in R100.
Figure 2 (a-c) shows the objective values obtained by each algorithm averaged over 5 independent runs.",7. Experiments,[0],[0]
"The sample and aggregate algorithm’s results have been omitted, since its objective values are orders of magnitude worse than the other algorithms.",7. Experiments,[0],[0]
"Across all values of k and all datasets, our algorithm is competitive with non-private k-means++ and always outperforms SuLQ k-means.",7. Experiments,[0],[0]
"As the dimensionality of the datasets increases, our algorithm remains competitive with k-means++, while SuLQ becomes less competitive for large dimensions.
",7. Experiments,[0],[0]
"Finally, figure 2 (d) shows the effect of the privacy parameter on the objective values for each algorithm on MNIST with k = 10.",7. Experiments,[0],[0]
"Our algorithm is competitive with the nonprivate k-means algorithm even for small , while the SuLQ algorithm objective deteriorates quickly.",7. Experiments,[0],[0]
"In this paper, we propose efficient algorithms for -private k-means and k-median clustering in Rd that achieves clustering loss at most O ( log3 n ) OPT + poly ( k, d, log n, 1
) and O ( log 3 2 n )",8. Conclusions,[0],[0]
"OPT + poly ( k, d, log n, 1 ) , respectively.
",8. Conclusions,[0],[0]
"We also study the scenario where the data points are s-sparse and show that the k-means clustering loss can be even smaller, namely, O",8. Conclusions,[0],[0]
"( log3 n ) OPT +
poly ( k, s, log d, log n, 1 ) .",8. Conclusions,[0],[0]
Results of this type advance the state-of-the-art approaches in the high-dimensional Euclidean spaces.,8. Conclusions,[0],[0]
"Our method of constructing candidate set can be potentially applied to other problems, which might be of independent interest more broadly.",8. Conclusions,[0],[0]
The authors would like to thank Liwei Wang and Colin White for helpful discussions.,Acknowledgments,[0],[0]
Parts of this work was done when W.M. was visiting CMU.,Acknowledgments,[0],[0]
This work was done when Y.L. was visiting Simons Institute.,Acknowledgments,[0],[0]
"This work was supported in part by grants NSF IIS-1618714, NSF CCF-1535967, NSF CCF-1422910, NSF CCF-1451177, a Sloan Fellowship, a Microsoft Research Fellowship, NSF grants CCF-1527371, DMS-1317308, Simons Investigator Award, Simons Collaboration Grant, ONRN00014-16-12329, and the Chinese MOE Training Plan for Top-Notch Students in Basic Discipline.",Acknowledgments,[0],[0]
"We study the problem of clustering sensitive data while preserving the privacy of individuals represented in the dataset, which has broad applications in practical machine learning and data analysis tasks.",abstractText,[0],[0]
"Although the problem has been widely studied in the context of lowdimensional, discrete spaces, much remains unknown concerning private clustering in highdimensional Euclidean spaces",abstractText,[0],[0]
R.,abstractText,[0],[0]
"In this work, we give differentially private and efficient algorithms achieving strong guarantees for k-means and k-median clustering when d = Ω(polylog(n)).",abstractText,[0],[0]
"Our algorithm achieves clustering loss at most log(n)OPT+poly(log n, d, k), advancing the state-of-the-art result of √ dOPT+ poly(log n, d, k).",abstractText,[0],[0]
"We also study the case where the data points are s-sparse and show that the clustering loss can scale logarithmically with d, i.e., log(n)OPT + poly(log n, log d, k, s).",abstractText,[0],[0]
Experiments on both synthetic and real datasets verify the effectiveness of the proposed method.,abstractText,[0],[0]
Differentially Private Clustering in High-Dimensional Euclidean Spaces,title,[0],[0]
"We aim to contribute to the body of research on the trade-off between releasing datasets from which publicly beneficial statistical inferences can be drawn, and between protecting the privacy of individuals who contribute to such datasets.",1. Introduction,[0],[0]
"Currently the most successful formalisation of protecting user privacy is provided by differential privacy (Dwork & Roth, 2014), which is a definition that any algorithm operating on a database may or may not satisfy.",1. Introduction,[0],[0]
"An algorithm that does satisfy the definition ensures that a particular individual does not lose too much privacy by deciding to contribute to the database on which the algorithm operates.
",1. Introduction,[0],[0]
"While differentially private algorithms for releasing entire
1MPI-IS, Tübingen, Germany 2University of Cambridge, UK.",1. Introduction,[0],[0]
Correspondence to: Matej Balog <first.surname@gmail.com>.,1. Introduction,[0],[0]
Code:,1. Introduction,[0],[0]
"https://github.com/matejbalog/RKHS-private-database/.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"databases have been studied previously (Blum et al., 2008; Wasserman & Zhou, 2010; Zhou et al., 2009), most algorithms focus on releasing a privacy-protected version of a particular summary statistic, or of a statistical model trained on the private dataset.",1. Introduction,[0],[0]
"In this work we revisit the more difficult non-interactive, or offline setting, where the database owner aims to release a privacy-protected version of the entire database without knowing what statistics third-parties may wish to compute in the future.
",1. Introduction,[0],[0]
"In our new framework we propose to use the kernel mean embedding (Smola et al., 2007) as an intermediate representation of a database.",1. Introduction,[0],[0]
"It is (1) sufficiently rich in the sense that it captures a wide class of statistical properties of the data, while at the same time (2) it lives in a Reproducing Kernel Hilbert Space (RKHS), where it can be handled mathematically in a principled way and privacy-protected in a unified manner, independently of the type of data appearing in the database.",1. Introduction,[0],[0]
"Although kernel mean embeddings are functions in an abstract Hilbert space, in practice they can be (at least approximately) represented using a possibly weighted set of data points in input space (i.e. a set of database rows).",1. Introduction,[0],[0]
"The privacy-protected kernel mean embedding is released to the public in this representation, however, using synthetic datapoints instead of the private ones.",1. Introduction,[0],[0]
"As a result, our framework can be seen as leading to synthetic database algorithms.
",1. Introduction,[0],[0]
"We validate our approach by instantiating two concrete algorithms and proving that they output consistent estimators of the true kernel mean embedding of the data generating process, while satisfying the definition of differential privacy.",1. Introduction,[0],[0]
"The consistency results ensure that third-parties can carry out a wide variety of statistically founded computation on the released data, such as constructing consistent estimators of population statistics, estimating the Maximum Mean Discrepancy (MMD) between distributions, and two-sample testing (Gretton et al., 2012), or using the data in the kernel probabilistic programming framework for random variable arithmetics (Schölkopf et al., 2015; Simon-Gabriel et al., 2016, Section 3), repeatedly and unlimitedly without being able to, or having to worry about, violating user privacy.
",1. Introduction,[0],[0]
One of our algorithms is especially suited to the interesting scenario where a (small) subset of a database has already been published.,1. Introduction,[0],[0]
"This situation can arise in a wide variety of settings, for example, due to weaker privacy protections in
the past, due to a leak, or due to the presence of an incentive, financial or otherwise, for users to publish their data.",1. Introduction,[0],[0]
"In such a situation our algorithm provides a principled approach for reweighting the public data in such a way that the accuracy of statistical inferences on this dataset benefits from the larger sample size (including the private data), while maintaining differential privacy for the undisclosed data.
",1. Introduction,[0],[0]
"In summary, the contributions of this paper are:
1.",1. Introduction,[0],[0]
A new framework for designing database release algorithms with the guarantee of differential privacy.,1. Introduction,[0],[0]
"The framework uses kernel mean embeddings as intermediate database representations, so that the RKHS metric can be used to control accuracy of the released synthetic database in a principled manner (Section 3).
2.",1. Introduction,[0],[0]
"Two instantiations of our framework in the form of two synthetic database algorithms, with proofs of their consistency, convergence rates and differential privacy, as well as basic empirical illustrations of their performance on synthetic datasets (Sections 4 and 5).",1. Introduction,[0],[0]
"Definition 1 (Dwork, 2006).",2.1. Differential Privacy,[0],[0]
"For ε > 0, δ ≥ 0, algorithmA is said to be (ε, δ)-differentially private if for all neighbouring databases D ∼ D′ (differing in at most one element) and all measurable subsets S of the co-domain of A,
P (A(D) ∈ S) ≤ eεP (A(D′) ∈ S) +",2.1. Differential Privacy,[0],[0]
δ.,2.1. Differential Privacy,[0],[0]
"(1)
The parameter ε controls the amount of information the algorithm can leak about an individual, while a positive δ allows the algorithm to produce an unlikely output that leaks more information, but only with probability up to δ.",2.1. Differential Privacy,[0],[0]
"This notion is sometimes called approximate differential privacy; an algorithm that is (ε, 0)-differentially private is simply said to be ε-differentially private.",2.1. Differential Privacy,[0],[0]
"Note that any non-trivial differentially private algorithm must be randomised; the definition asserts that the distribution of algorithm outputs is not too sensitive to changing one row in the database.
",2.1. Differential Privacy,[0],[0]
When the algorithm’s output is a finite vector A(D) ∈,2.1. Differential Privacy,[0],[0]
"RJ , two standard random perturbation mechanisms for making this output differentially private are the Laplace and Gaussian mechanisms.",2.1. Differential Privacy,[0],[0]
"As the perturbation needs to mask the contribution of each individual entry of the database D, the scale of the added noise is closely linked to the notion of sensitivity, measuring how much the algorithm’s output can change due to changing a single data point:
∆1 := sup D∼D′
‖A(D)−A(D′)‖1 , (2)
",2.1. Differential Privacy,[0],[0]
"∆2 := sup D∼D′
‖A(D)−A(D′)‖2 .",2.1. Differential Privacy,[0],[0]
"(3)
The Laplace mechanism adds i.i.d.",2.1. Differential Privacy,[0],[0]
"Lap(∆1/ε) noise to each of the J coordinates of the output vector and ensures pure ε-differential privacy, while the Gaussian mechanism adds i.i.d.",2.1. Differential Privacy,[0],[0]
"N (0, σ2) noise to each coordinate, where σ2 > 2∆22 ln(1.25/δ)/ε
2, and ensures (ε, δ)-differential privacy.",2.1. Differential Privacy,[0],[0]
"Applying these mechanisms thus requires computing (an upper bound on) the relevant sensitivity.
",2.1. Differential Privacy,[0],[0]
"Differential privacy is preserved under post-processing: if an algorithm A is (ε, δ)-differentially private, then so is its sequential composition B(A(·)) with any other algorithm B that does not have direct or indirect access to the private database D (Dwork & Roth, 2014).",2.1. Differential Privacy,[0],[0]
"A kernel on a non-empty set (data type) X is a binary positive-definite function k(·, ·) :","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
X × X → R. Intuitively it can be thought of as expressing the similarity between any two elements in X .,"2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"The literature on kernels is vast and their properties are well studied (Schölkopf & Smola, 2002); many kernels are known for a large variety of data types such as vectors, strings, time series, graphs, etc, and kernels can be composed to yield valid kernels for composite data types (e.g. the type of a database row containing both numerical and string data).
","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
The kernel mean embedding (KME) of an X -valued random variable X in the RKHS is the function µkX,"2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
": X → R, y 7→","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"EX [k(X, y)], defined whenever EX [ √ k(X,X)]","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"< ∞ (Smola et al., 2007).","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"Several popular kernels have been proved to be characteristic (Fukumizu et al., 2008), in which case the map pX 7→ µkX , where pX is the distribution of X , is injective.","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"This means that no information about the distribution of X is lost when passing to its KME µkX .
","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"In practice, the KME of a random variable X is approximated using a sample x1, . . .","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
", xN drawn from X , which can be used to construct an empirical KME µ̂kX of X in the RKHS: a function given by y 7→ 1N ∑N n=1 k(xn, y).","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"When the xn’s are i.i.d., under a boundedness condition µ̂kX converges to the true KME µkX at rate Op(N−1/2), independently of the dimension of X (Lopez-Paz et al., 2015)1.","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
Our approach relies on the metric of the RKHS in which these KMEs live.,"2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"The RKHS Hk is a space of functions, endowed with an inner product 〈·, ·〉Hk that satisfies the reproducing property 〈k(x, ·), h〉 = h(x) for all x ∈ X and h ∈ Hk.","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"The inner product induces a norm ‖ · ‖Hk , which can be used to measure distances ‖µkX","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
− µkY ‖Hk between distributions of X and Y .,"2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"This can be exploited for various
1The KME can be viewed as a smoothed version of the density, which is easier to estimate than the density itself; rates of nonparametric density estimation or statistical powers of two-sample or independence tests involving pX are known to necessarily degrade with growing dimension (Tolstikhin et al., 2017, Section 4.3).
purposes such as two-sample tests (Gretton et al., 2012), independence testing (Gretton et al., 2005), or one can attempt to minimise this distance in order to match one distribution to another.
","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"An example of such minimisation are reduced set methods (Burges, 1996; Schölkopf & Smola, 2002, Chap. 18), which replace a set of points S = {x1, . . .","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
", xN} ⊆ X with a weighted set R = {(z1, w1), . . .","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
", (zM , wM )}","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"⊆ X × R (of potentially smaller size), where the new points zm can, but need not equal any of the xns, such that the KME computed using the reduced setR is close to the KME computed using the original set S, as measured by the RKHS norm:
∥∥µkS","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"− µkR∥∥Hk = ∥∥∥∥∥ 1N N∑ n=1 k(xn, ·)","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"− M∑ m=1 wmk(zm, ·) ∥∥∥∥∥","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"Hk .
","2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
Reduced set methods are usually motivated by the computational savings arising when |R| < |S|; we will invoke them mainly to replace a collection S of private data points with a (possibly weighted) set R of synthetic data points.,"2.2. Kernels, RKHS, and Kernel Mean Embeddings",[0],[0]
"Throughout this work, we assume the following setup.",3.1. Problem Formulation,[0],[0]
"A database curator wishes to publicly release a database D = {x1, . . .",3.1. Problem Formulation,[0],[0]
"xN} ∈ XN containing private data about N individuals, with each data point (database row)",3.1. Problem Formulation,[0],[0]
xn taking values in a non-empty set X .,3.1. Problem Formulation,[0],[0]
"The set X can be arbitrarily rich, for example, it could be a product of Euclidean spaces, integer spaces, sets of strings, etc.; we only require availability of a kernel function",3.1. Problem Formulation,[0],[0]
k,3.1. Problem Formulation,[0],[0]
:,3.1. Problem Formulation,[0],[0]
X × X → R on X .,3.1. Problem Formulation,[0],[0]
"We assume that the N rows x1, . . .",3.1. Problem Formulation,[0],[0]
", xN in the database D can be thought of as i.i.d.",3.1. Problem Formulation,[0],[0]
observations from some X -valued data-generating random variable X (but see Section 7 for a discussion about relaxing this assumption).,3.1. Problem Formulation,[0],[0]
"The database curator, wishing to protect the privacy of individuals in the database, seeks a database release mechanism that satisfies the definition of (ε, δ)-differential privacy, with ε > 0",3.1. Problem Formulation,[0],[0]
and δ ≥ 0 given.,3.1. Problem Formulation,[0],[0]
"The main purpose of releasing the database is to allow third parties to construct estimators of population statistics (i.e. properties of the distribution of X), but it is not known at the time of release what statistics the third-parties will be interested in.
",3.1. Problem Formulation,[0],[0]
"To lighten notation, henceforth we drop the superscript k from KMEs (such as µkX ) and the subscript k from the RKHS Hk, whenever k is the kernel on X chosen by the database curator.",3.1. Problem Formulation,[0],[0]
"We propose the following general algorithm template for differentially private database release:
1.",3.2. Algorithm Template,[0],[0]
"Construct a consistent estimator µ̂X of the KME µX of X using the private database.
2.",3.2. Algorithm Template,[0],[0]
"Obtain a perturbed version µ̃X of the constructed estimate µ̂X to ensure differential privacy.
3.",3.2. Algorithm Template,[0],[0]
"Release a (potentially approximate) representation of µ̃X in terms of a (possibly weighted) dataset {(z1, w1), . . .",3.2. Algorithm Template,[0],[0]
", (zM , wM )}",3.2. Algorithm Template,[0],[0]
"⊆ X × R.
The released representation should be such that∑M m=1 wmk(zm, ·) is a consistent estimator of the true KME µX , i.e. such that the RKHS distance between the two converges to 0 in probability as the private database size N , and together with it the synthetic database size M , go to infinity.
",3.2. Algorithm Template,[0],[0]
Each step of this template admits several possibilities.,3.2. Algorithm Template,[0],[0]
"For the first step we have discussed the standard empirical KME 1 N ∑N n=1 k(xn, ·) with x1, . . .",3.2. Algorithm Template,[0],[0]
", xN i.i.d.",3.2. Algorithm Template,[0],[0]
"observations of X , but the framework remains valid with improved estimators such as kernel-based quadrature (Chen et al., 2010) or the shrinkage kernel mean estimators of (Muandet et al., 2016).
",3.2. Algorithm Template,[0],[0]
"As the KMEs µ̂X and µX live in the RKHSH of the kernel k, a natural mechanism for privatising µ̂X in the second step would be to follow (Hall et al., 2013) and pointwise add to µ̂X a suitably scaled sample path g of a Gaussian process with covariance function k(·, ·).",3.2. Algorithm Template,[0],[0]
"This does ensure (ε, δ)-differential privacy of the resulting function µ̃X = µ̂X + g, but unfortunately µ̃X 6∈ H, because the RKHS norm ‖g‖H of a Gaussian process sample path with the same kernel k is infinite almost surely (Rasmussen & Williams, 2005).",3.2. Algorithm Template,[0],[0]
"While our framework allows pursuing this direction by, for example, moving to a larger function space that does contain the Gaussian process sample path, in this work we will present algorithms that achieve differential privacy by mapping µ̂X into a finite-dimensional Hilbert space and then employing the standard Laplace or Gaussian mechanisms to the finite coordinate vector.
",3.2. Algorithm Template,[0],[0]
"Differential privacy is preserved under post-processing, but the third step does require some care to ensure that private data is not leaked.",3.2. Algorithm Template,[0],[0]
"Specifically, when several possible (approximate) representations µ̃X ≈ ∑M m=1 wmk(zm, ·) in terms of a weighted dataset (w1, z1), . . .",3.2. Algorithm Template,[0],[0]
", (wM , zM ) are possible, committing to a particular one reveals more information than just the function µ̃X (consider, for example, the extreme case where the representation would be in terms of the private points x1, . . .",3.2. Algorithm Template,[0],[0]
", xN ).",3.2. Algorithm Template,[0],[0]
"One thus needs to either control the privacy leak due to choosing a representation in a way that depends on the private data, or, as we do in our concrete algorithms below, choose a representation independently of the private data (but still minimising its RKHS distance to the privacy-protected µ̃X ).",3.2. Algorithm Template,[0],[0]
"Algorithms in our framework release a possibly weighted synthetic dataset {(z1, w1), . . .",3.3. Versatility,[0],[0]
", (zM , wM )}",3.3. Versatility,[0],[0]
"⊆ X ×R such that ∑M m=1 wmk(zm, ·) is a consistent estimator of the true KME µX of the data generating random variable X .",3.3. Versatility,[0],[0]
"This allows third-parties to perform a wide spectrum of statistical computation, all without having to worry about violating differential privacy:
1.",3.3. Versatility,[0],[0]
"Kernel probabilistic programming (Schölkopf et al., 2015):",3.3. Versatility,[0],[0]
"The versatility of our approach is greatly expanded thanks to the result of (Simon-Gabriel et al., 2016), who showed that under technical conditions, applying a continuous function f to all points zm in the synthetic dataset yields a consistent estimator ∑M m=1 wmkf (f(zm), ·) of the KME µf(X) of the
transformed random variable f(X), even when the points z1, . . .",3.3. Versatility,[0],[0]
", zM are not i.i.d.",3.3. Versatility,[0],[0]
"(as they may not be, depending on the particular synthetic database release algorithm).
",3.3. Versatility,[0],[0]
2.,3.3. Versatility,[0],[0]
"Consistent estimation of population statistics: For any RKHS function h ∈ H, we have 〈µX , h〉H = E[h(X)], so a consistent estimator of µX yields a consistent estimator of the expectation of h(X).",3.3. Versatility,[0],[0]
"It can be evaluated using the reproducing kernel property:
E[h(X)]",3.3. Versatility,[0],[0]
"= 〈µX , h〉H ≈ 〈 M∑ m=1 wmk(zm, ·), h 〉 H
= M∑ m=1 wmh(zm).",3.3. Versatility,[0],[0]
"(4)
For example, approximating the indicator function 1S of a set S ⊆ X with functions in the RKHS allows estimating probabilities: E[1S(X)]",3.3. Versatility,[0],[0]
"= P[X ∈ S] (note that 1S itself may not be an element of the RKHS).
",3.3. Versatility,[0],[0]
3.,3.3. Versatility,[0],[0]
"MMD estimation and two-sample testing (Gretton et al., 2012):",3.3. Versatility,[0],[0]
"Given another random variable Y on X , one can consistently estimate the Maximum Mean Discrepancy (MMD) distance ‖µX − µY",3.3. Versatility,[0],[0]
"‖H between the distributions of X and Y , and in particular to construct a two-sample test based on this distance.",3.3. Versatility,[0],[0]
"Given a sample y1, . . .",3.3. Versatility,[0],[0]
", yL ∼ Y :
‖µX − µY",3.3. Versatility,[0],[0]
"‖H ≈ ∥∥∥∥∥ M∑ m=1 wmk(zm, ·)",3.3. Versatility,[0],[0]
"− 1 L L∑ l=1 k(yl, ·) ∥∥∥∥∥",3.3. Versatility,[0],[0]
"H ,
which can again be evaluated using the reproducing property.
",3.3. Versatility,[0],[0]
4.,3.3. Versatility,[0],[0]
"Subsequent use of synthetic data: Since the output of the algorithm is a (possibly weighted) database, thirdparties are free to use this data for arbitrary purposes,
such as training any machine learning model on this data.",3.3. Versatility,[0],[0]
"Models trained purely on this data can be released with differential privacy guaranteed; however, the accuracy of such models on real data remains an empirical question that is beyond the scope of this work.
",3.3. Versatility,[0],[0]
"An orthogonal spectrum of versatility arises from the fact that the third step in the algorithm template can constrain the released dataset (z1, w1), . . .",3.3. Versatility,[0],[0]
", (zM , wM ) to be more convenient or more computationally efficient for further processing.",3.3. Versatility,[0],[0]
"For example, one could fix the weights to uniform wm = 1 M to obtain an unweighted dataset, or to replace an expensive data type with a cheaper subset, such as requesting floats instead of doubles in the zm’s.",3.3. Versatility,[0],[0]
All this can be performed while an RKHS distance is available to control accuracy between µ̃X and its released representation.,3.3. Versatility,[0],[0]
"As a first illustrative example, we describe how a particular case of an existing, but inefficient synthetic database algorithm already fits into our framework.",3.4. Concrete Algorithms,[0],[0]
"The exponential mechanism (McSherry & Talwar, 2007) is a general mechanism for ensuring ε-differential privacy, and in our setting it operates as follows: given a similarity measure s : XN × XM → R between (private) databases of size N and (synthetic) databases of size M , output a random (synthetic) database R with probability proportional to exp( ε2∆1 s(D,R)), where D is the actual private database and ∆1 is the L1 sensitivity of s w.r.t.",3.4. Concrete Algorithms,[0],[0]
"D. This ensures ε-differential privacy (McSherry & Talwar, 2007).
",3.4. Concrete Algorithms,[0],[0]
"To fit this into our framework, we can take s(D,R) =",3.4. Concrete Algorithms,[0],[0]
"−‖µD − µR‖H to be the negative RKHS distance between the KMEs computed using D and R, and achieve ε-differential privacy by releasing R with probability proportional to exp(− ε2∆1 ‖µD − µR‖H).",3.4. Concrete Algorithms,[0],[0]
"This solves steps 2 and 3 of our general algorithm template simultaneously, as it directly samples a concrete representation of a “perturbed” KME µR. The algorithm essentially corresponds to the SmallDB algorithm of Blum et al. (2008), except for choosing the RKHS distance as a well-studied similarity measure between two databases.
",3.4. Concrete Algorithms,[0],[0]
"The principal issue with this algorithm is its computational infeasibility except in trivial cases, as it requires sampling from a probability distribution supported on all potential synthetic databases, and employing an approximate sampling scheme can break the differential privacy guarantee of the exponential mechanism.",3.4. Concrete Algorithms,[0],[0]
"In Sections 4 and 5 respectively, we describe two concrete synthetic database release algorithms that may possess failure modes where they become inefficient, but employing approximations in those cases can only affect their statistical accuracy, not the promise of differential privacy.
",3.4. Concrete Algorithms,[0],[0]
"Algorithm 1 Differentially private database release via a synthetic data subspace of the RKHS Input: database D = {x1, . . .",3.4. Concrete Algorithms,[0],[0]
", xN} ⊆ X , kernel k on X , privacy parameters ε > 0",3.4. Concrete Algorithms,[0],[0]
and δ > 0,3.4. Concrete Algorithms,[0],[0]
"Output: (ε, δ)-differentially private, weighted synthetic database (representing an estimate of µX in the RKHSH of k)
1: M ←M(N) ∈ ω(1) ∩ o(N2), number of synthetic data points to use 2: z1, . . .",3.4. Concrete Algorithms,[0],[0]
", zM ← initialised deterministically or randomly from some distribution q on X 3: HM ← Span({k(z1, ·), . . .",3.4. Concrete Algorithms,[0],[0]
", k(zM , ·)}) ≤",3.4. Concrete Algorithms,[0],[0]
"H 4: b1, . . .",3.4. Concrete Algorithms,[0],[0]
", bF ← orthonormal basis ofHM (obtained using, e.g. Gram-Schmidt) 5: µ̂X ← 1N ∑N n=1 k(xn, ·), empirical KME of X inH
6: µX ← ∑F f=1〈bf , µ̂X〉Hbf =: ∑F f=1 αfbf , projection of µ̂X ontoHM 7: β ← α+N (0, 8 ln(1.25/δ)N2ε2 IF ), an (ε, δ)-differentially private version of the coordinate vector α (Gaussian mechanism) 8: µ̃X ← ∑F f=1 βfbf = ∑M m=1 wmk(zm, ·), re-expressed in terms of k(zm, ·)’s 9: return (z1, w1), . .",3.4. Concrete Algorithms,[0],[0]
.,3.4. Concrete Algorithms,[0],[0]
", (zM , wM )",3.4. Concrete Algorithms,[0],[0]
"In this section we describe an instantiation of the framework proposed in Section 3 that achieves differential privacy of the KME by projecting it onto a finite-dimensional subspace of the RKHS spanned by feature maps k(zm, ·) of synthetic data points z1, . . .",4. Perturbation in Synthetic-Data Subspace,[0],[0]
", zM , and perturbing the resulting finite coordinate vector.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"To ensure differential privacy, the synthetic data points are chosen independently of the private database.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"As a result, statistical efficiency of this approach will depend on the choice of synthetic data points, with efficiency increasing if there are enough synthetic data points to capture the patterns in the private data.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Therefore this algorithm is especially suited to the scenario discussed in Section 1, where a part of the database (or of a similar one) has already been published, as this can serve as a good starting set for the synthetic data points.
",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"The setting where some observations from X have already been released highlights the fact that differential privacy only protects against additional privacy violation due to an individual deciding to contribute to the private database; if a particular user’s data has already been published, differential privacy does not protect against privacy violations based on exploiting this previously published data.
",4. Perturbation in Synthetic-Data Subspace,[0],[0]
The algorithm is formalised as Algorithm 1 above.,4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Lines 1- 2 choose synthetic data points z1, . . .",4. Perturbation in Synthetic-Data Subspace,[0],[0]
", zM independently of the private data (only using the database size N ).",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Lines 3-4 construct the linear subspaceHM ofH spanned by feature maps of the chosen synthetic data points, and compute a (finite) basis for it.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Only then the private data is accessed: the empirical KME µ̂X is computed (line 5), projected onto the subspace HM and expressed in terms of the precomputed basis (line 6).",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"The basis coefficients of the projection are then perturbed to achieve differential privacy (line 7), and the perturbed element µ̃X ∈ HM is then re-expressed in terms of the spanning set containing feature maps of synthetic data points (line 8).",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"This expansion is finally released to the public (line 9).
",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Line 1 stipulates that the number of synthetic data points M → ∞ as N → ∞, but asymptotically slower than N2.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"This is to ensure that the privatisation noise added in the subspace HM to each coordinate is small enough overall to preserve consistency, as stated in the following Theorem 2.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"This theorem assures us that Algorithm 1 produces a consistent estimator of the true KME µX , if the synthetic data points are sampled from a distribution with sufficiently large support.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Due to space constraints, all proofs appear in Appendix A.
Theorem 2.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
Let X be a compact metric space and k a continuous kernel on X .,4. Perturbation in Synthetic-Data Subspace,[0],[0]
"If the synthetic data points z1, z2, . .",4. Perturbation in Synthetic-Data Subspace,[0],[0]
.,4. Perturbation in Synthetic-Data Subspace,[0],[0]
are sampled i.i.d.,4. Perturbation in Synthetic-Data Subspace,[0],[0]
"from a distribution q on X such that the support of X is included in the support of q, then Algorithm 1 outputs a consistent estimator of the KME µX :∑M m=1 wmk(zm, ·) P→ µX as N →∞.
As discussed by Simon-Gabriel et al. (2016), these assumptions are usually satisfied: X can be taken to be compact whenever the data comes from measurements with any bounded range, and many kernels are continuous, including all kernels on discrete spaces (w.r.t. to the discrete topology).
",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"In order to use the output of Algorithm 1 in the very general kernel probabilistic programming framework and obtain a consistent estimator of the KME µf(X) of f(X) for any continuous function f , there is a technical condition that the L1 norm ∑M m=1 |wm| of the released weights may need to remain bounded by a constant as N →∞",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"(Simon-Gabriel et al., 2016).",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"This is not enforced by Algorithm 1, but Theorem 11 in Appendix A.1 shows how a simple regularisation in the final stage of the algorithm achieves this without breaking consistency (or privacy).
",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"The next result about Algorithm 1 shows that it is differentially private whenever k(x, x) ≤ 1 for all x ∈ X .",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"This is a weak assumption that holds for all normalised kernels, and can be achieved by simple rescaling for any bounded kernel (such that supx∈X k(x, x) < ∞).",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"When X is a compact domain, all continuous kernels are bounded.
",4. Perturbation in Synthetic-Data Subspace,[0],[0]
Proposition 3.,4. Perturbation in Synthetic-Data Subspace,[0],[0]
"If k(x, x) ≤ 1 for all x ∈ X , then Algorithm 1 is (ε, δ)-differentially private.
",4. Perturbation in Synthetic-Data Subspace,[0],[0]
Remark 4.,4. Perturbation in Synthetic-Data Subspace,[0],[0]
"One usually requires that δ decreases faster than polynomially with the database size N (Dwork & Roth, 2014).",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"The proof of Theorem 2 remains valid whenever M(N) ∈ o(N2/ ln(1.25/δ(N))), so for example we could have δ(N) = e− √ N and M(N) ∈ o(N3/2).
",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"For a finite private database, actual performance will heavily depend on how the synthetic data points are chosen.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"We consider the following two extreme scenarios:
1.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"No publishable subset: No rows of the private database are, or can be made public unmodified.
2.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Publishable subset: A small proportion of the private database is already public, or can be made public.
",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Proposition 5 (Algorithm 1, No publishable subset).",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Say X is a bounded subset of RD, the kernel k is Lipschitz, and the synthetic data points z1, z2, . . .",4. Perturbation in Synthetic-Data Subspace,[0],[0]
are sampled i.i.d.,4. Perturbation in Synthetic-Data Subspace,[0],[0]
from a distribution q with density bounded away from 0 on any bounded subset of RD.,4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Then M = M(N) can be chosen so that the output of Algorithm 1 converges to the true KME µX in RKHS norm at a rate Op(N−1/(D+1+c)), where c is any fixed positive number c > 0.
",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Unsurprisingly, the convergence rate deteriorates with input dimension D, since without prior information about the private data manifold it is increasingly difficult for randomly sampled synthetic points to capture patterns in the private data.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"One of the main strengths of KMEs is that the empirical estimator converges to the true embedding at a rate
Op(N−1/2) independently of the input dimension D, so we see that in this unfavourable scenario Algorithm 1 incurs a substantial privacy cost in high dimensions.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"On the other hand, if a small, but fixed proportion of the private database is publishable, then Algorithm 1 incurs no privacy cost in terms of the convergence rate:
Proposition 6 (Algorithm 1, Publishable subset).",4. Perturbation in Synthetic-Data Subspace,[0],[0]
Say that a fixed proportion η of the private database can be published unmodified.,4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Using this part of the database as the synthetic data points, Algorithm 1 outputs a consistent estimator of µX that converges in RKHS norm at a rate Op(N−1/2).
",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Note that in this scenario the rate Op(N−1/2) can be also achieved by uniform weighting of the synthetic data points, since µ̂baseline := 1M ∑M m=1 k(zm, ·) with zm = xm is already a consistent estimator of µX (although based on a much smaller sample size M = ηN N ).",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"The purpose of Algorithm 1 is to find (generally non-uniform) w1, . . .",4. Perturbation in Synthetic-Data Subspace,[0],[0]
", wM that reweight the public data points using the information in the large private dataset, but respecting differential privacy.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Proposition 6 confirmed theoretically that this does not hurt the convergence rate, while Figure 1 shows empirically on two synthetic datasets of dimensions D = 2 and D = 5 that Algorithm 1 can in fact yield more accurate estimates of the KME than µ̂baseline, especially when the proportion of public data points is small.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"This is encouraging, since obtaining permission to publish a larger subset of the private data unchanged will usually come at an increased cost.",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"The ability to instead reweight a smaller public dataset in a differentially private manner using Algorithm 1 is therefore useful.
",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Algorithm 2 Differentially private database release via a random features RKHS Input: database D = {x1, . . .",4. Perturbation in Synthetic-Data Subspace,[0],[0]
", xN} ⊆ X , kernel k on X , privacy parameters ε > 0",4. Perturbation in Synthetic-Data Subspace,[0],[0]
and δ > 0,4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Output: (ε, δ)-differentially private, weighted synthetic database (representing an estimate of µX in the RKHSH of k)
1: J ← J(N) ∈ ω(1) ∩ o(N2), number of random features to use 2: φ← random feature map X 7→ RJ for kernel k with J features 3: µ̂φX ← 1 N ∑N n=1 φ(xn) ∈ RJ , empirical KME of X in RKHSHφ of the random features kernel kφ(·, ·) := φ(·)Tφ(·) 4: µ̃φX ← µ̂ φ X +N (0, 8 ln(1.25/δ) N2ε2 IJ), an (ε, δ)-differentially private version of the vector µ̂ φ X (Gaussian mechanism) 5: M ←M(N)",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"≥ N , number of synthetic expansion points to use for representing µ̃φX 6: (z1, w1), . . .",4. Perturbation in Synthetic-Data Subspace,[0],[0]
", (zM , wM )",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"← approximate µ̃φX in the RKHSHφ using a Reduced set method:
(z1, w1), . . .",4. Perturbation in Synthetic-Data Subspace,[0],[0]
", (zM , wM )",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"≈ argmin (z′1,w ′",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"1),...,(z ′ M ,w ′ M ) s.t. ∑ m |w ′",4. Perturbation in Synthetic-Data Subspace,[0],[0]
m|≤1 ∥∥∥∥∥ M∑ m=1,4. Perturbation in Synthetic-Data Subspace,[0],[0]
w′mφ(z ′,4. Perturbation in Synthetic-Data Subspace,[0],[0]
m)− µ̃ φ X ∥∥∥∥∥,4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Hφ
(5)
7: return (z1, w1), . . .",4. Perturbation in Synthetic-Data Subspace,[0],[0]
", (zM , wM )",4. Perturbation in Synthetic-Data Subspace,[0],[0]
"Another approach to ensuring differential privacy is to map the potentially infinite dimensional RKHS H of k into a different, finite-dimensional RKHSHφ using random features (Rahimi & Recht, 2007), privacy-protect the finite coordinate vector in this space (Chaudhuri et al., 2011), and then employ a reduced set method to find an expansion of the resulting RKHS element in terms of synthetic data points.",5. Perturbation in Random-Features RKHS,[0],[0]
"In contrast to Algorithm 1, both the weights and locations of synthetic data points can be optimised here.
",5. Perturbation in Random-Features RKHS,[0],[0]
The algorithm is formalised as Algorithm 2 above.,5. Perturbation in Random-Features RKHS,[0],[0]
"Lines 1- 2 pick the number J = J(N) of random features to use, and construct a random feature map φ with that many features.",5. Perturbation in Random-Features RKHS,[0],[0]
"Lines 3-4 compute the empirical KME of X in the RKHS Hφ corresponding to the kernel induced by the random features, and then privacy-protect the resulting finite, realvalued vector.",5. Perturbation in Random-Features RKHS,[0],[0]
Lines 5-6 run a blindly initialised Reduced set method to find a weighted synthetic dataset whose KME inHφ is close to the privacy-protected KME of the private database.,5. Perturbation in Random-Features RKHS,[0],[0]
"Line 7 releases this weighted dataset to the public.
",5. Perturbation in Random-Features RKHS,[0],[0]
"The following theorem confirms that Algorithm 2 outputs a consistent estimator of the true KME µX , provided that the optimisation problem (5) is solved exactly, and the random features converge to the kernel k uniformly on X .",5. Perturbation in Random-Features RKHS,[0],[0]
"On compact sets X this requirement is satisfied by general schemes such as random Fourier features and random binning for shift-invariant kernels (Rahimi & Recht, 2007), or by random features for dot product kernels (Kar & Karnick, 2012).
",5. Perturbation in Random-Features RKHS,[0],[0]
Theorem 7.,5. Perturbation in Random-Features RKHS,[0],[0]
"If φ(·)Tφ(·)→ k(·, ·) converges uniformly in X × X as J → ∞, then the output of Algorithm 2 is a consistent estimator of the true KME µX as N →∞.
Moreover, a uniform convergence rate for the random features, such as the one for random Fourier features by Sriperumbudur & Szabo (2015), can be used to derive a convergence rate for the output of Algorithm 2:
Proposition 8.",5. Perturbation in Random-Features RKHS,[0],[0]
"If φ(·)Tφ(·)→ k(·, ·) converges uniformly in X ×X at a rate Op(J−1/2) as J →∞, then J = J(N) can be chosen so that the output of Algorithm 2 converges to the true KME µX at a rate Op(N−1/3).
",5. Perturbation in Random-Features RKHS,[0],[0]
"The empirical KME of the private database µ̂X converges at a rateOp(N−1/2), so we see that under perfect optimisation, the privacy cost incurred by Algorithm 2 is a factor of N1/6.",5. Perturbation in Random-Features RKHS,[0],[0]
"In practice performance will also depend on the Reduced set method used, and the computational budget allocated to it.",5. Perturbation in Random-Features RKHS,[0],[0]
Figure 2 shows how the incurred error (in terms of RKHS distance) varies with the number of synthetic data points M .,5. Perturbation in Random-Features RKHS,[0],[0]
"The additional ability of Algorithm 2 to optimise the locations of the synthetic data points (rather than just the weights, as in Algorithm 1) seems to be more helpful in the higher-dimensional case D = 5, where the randomly sampled synthetic data points are less likely to land close to private data points.
",5. Perturbation in Random-Features RKHS,[0],[0]
Proposition 9.,5. Perturbation in Random-Features RKHS,[0],[0]
"If ‖φ(x)‖2 ≤ 1 for all x ∈ X , then Algorithm 2 is (ε, δ)-differentially private.
",5. Perturbation in Random-Features RKHS,[0],[0]
"This L2-boundedness requirement on the random feature vectors φ(x) is reasonable under the weak assumption k(x, x) ≤ 1 for all x ∈ X discussed in Section 4, as in that case ‖φ(x)‖22",5. Perturbation in Random-Features RKHS,[0],[0]
= φ(x)Tφ(x),5. Perturbation in Random-Features RKHS,[0],[0]
"≈ k(x, x) ≤ 1.",5. Perturbation in Random-Features RKHS,[0],[0]
Synthetic database release algorithms with a differential privacy guarantee have been studied in the literature before.,6. Related Work,[0],[0]
"Machanavajjhala et al. (2008) analyzed such a procedure for count data, ensuring privacy by sampling a distribution and then synthetic counts from a Dirichlet-Multinomial posterior.",6. Related Work,[0],[0]
"Blum et al. (2008) studied the exponential mechanism applied to synthetic database generation, which leads to a very general, but unfortunately inefficient algorithm (see also Section 3.4).",6. Related Work,[0],[0]
"Wasserman & Zhou (2010) provided a theoretical comparison of this algorithm to sampling synthetic
databases from deterministically smoothed, or randomly perturbed histograms.",6. Related Work,[0],[0]
"Unlike our approach, these algorithms achieve differential privacy by sampling synthetic data points from a specific distribution, where resorting to approximate sampling can break the privacy guarantee.",6. Related Work,[0],[0]
"In our framework we propose to arrive at the synthetic database using a reduced set method, where poor performance could affect statistical usefulness of the synthetic database, but cannot break its differential privacy.
",6. Related Work,[0],[0]
"Zhou et al. (2009) and Kenthapadi et al. (2012) proposed randomised database compression schemes that yield synthetic databases useful for particular types of algorithms, while guaranteeing differential privacy.",6. Related Work,[0],[0]
"The former compresses the number of data points using a random linear or affine transformation of the entire database, and the result can be used by procedures that rely on the empirical covariance of the original data.",6. Related Work,[0],[0]
"The latter compresses the number of data point dimensions while approximately preserving distances between original, private data points.
",6. Related Work,[0],[0]
"Differentially private learning in a RKHS has also been studied, with Chaudhuri et al. (2011) and Rubinstein et al. (2012) having independently presented release mechanisms for the result of an empirical risk minimisation procedure (such as a SVM).",6. Related Work,[0],[0]
"Similarly to our Algorithm 2, they map data points into a finite-dimensional space defined by random features and carry out the privacy-protecting perturbation there.",6. Related Work,[0],[0]
"However, they do not require the final stage of invoking a Reduced set method to construct a synthetic database, because the output (such as a trained SVM) is only used for evaluation on test points, for which it suffices to additionally release the used random feature map φ.
",6. Related Work,[0],[0]
"As our framework stipulates privacy-protecting an empirical
KME, which is a function X → R, the work on differential privacy for functional data is of relevance.",6. Related Work,[0],[0]
"Hall et al. (2013) showed how an RKHS element can be made differentially private via pointwise addition of a Gaussian process sample path, but as discussed in Section 3.2, the resulting function is no longer an element of the RKHS.",6. Related Work,[0],[0]
"Recently, Aldà & Rubinstein (2017) proposed a general Bernstein mechanism for ε-differentially private function release.",6. Related Work,[0],[0]
"The released function can be evaluated pointwise arbitrarily many times, but again, the geometry of the RKHS to which the unperturbed function belonged cannot be easily exploited anymore.",6. Related Work,[0],[0]
"We proposed a framework for constructing differentially private synthetic database release algorithms, based on the idea of using KMEs in RKHS as intermediate database representations.",7. Discussion,[0],[0]
"To justify our framework, we presented two concrete algorithms and proved theoretical results guaranteeing their consistency and differential privacy.",7. Discussion,[0],[0]
"We also studied their finite-sample convergence rates, and provided empirical illustrations of their performance on synthetic datasets.",7. Discussion,[0],[0]
"We believe that exploring other instantiations of this framework, and comparing them theoretically and empirically, can be a fruitful direction for future research.
",7. Discussion,[0],[0]
The i.i.d. assumption on database rows can be relaxed.,7. Discussion,[0],[0]
"For example, if they are identically distributed (as a random variable X), but not necessarily independent, the framework remains valid as long as a consistent estimator of the KME µX can be constructed from the database rows.",7. Discussion,[0],[0]
"A common situation where this arises is, for example, duplication of database rows due to user error.",7. Discussion,[0],[0]
The authors would like to thank Bharath Sriperumbudur and the anonymous reviewers for helpful feedback.,Acknowledgements,[0],[0]
"We lay theoretical foundations for new database release mechanisms that allow third-parties to construct consistent estimators of population statistics, while ensuring that the privacy of each individual contributing to the database is protected.",abstractText,[0],[0]
The proposed framework rests on two main ideas.,abstractText,[0],[0]
"First, releasing (an estimate of) the kernel mean embedding of the data generating random variable instead of the database itself still allows thirdparties to construct consistent estimators of a wide class of population statistics.",abstractText,[0],[0]
"Second, the algorithm can satisfy the definition of differential privacy by basing the released kernel mean embedding on entirely synthetic data points, while controlling accuracy through the metric available in a Reproducing Kernel Hilbert Space.",abstractText,[0],[0]
"We describe two instantiations of the proposed framework, suitable under different scenarios, and prove theoretical results guaranteeing differential privacy of the resulting algorithms and the consistency of estimators constructed from their outputs.",abstractText,[0],[0]
Differentially Private Database Release via Kernel Mean Embeddings,title,[0],[0]
We consider the problem of designing sample-efficient algorithms to understand properties of distributions over large discrete domains.,1. Introduction,[0],[0]
Such statistical tests have been traditionally studied in statistics because of their importance in virtually every scientific endeavor that involves data.,1. Introduction,[0],[0]
"Recent work in the theoretical computer science community has investigated the setting where the discrete domains are large and no a priori assumptions can be made about the underlying data distribution (for example, when it cannot be assumed that the distribution is normal, Gaussian, or even smooth).",1. Introduction,[0],[0]
"In the last few years, optimal methods with sublinear sample complexity have been obtained for testing a range of properties, including whether a distribution is uniform, identical to a known distribution (testing “goodness-of-fit”),
*Equal contribution 1CSAIL, MIT, Cambridge, MA 02139, USA 2Department of Computer Science, USC, Los Angeles, CA 90089, USA 3TAU, Tel Aviv-Yafo, Israel.",1. Introduction,[0],[0]
"Correspondence to: Maryam Aliakbarpour <maryama@mit.edu>, Ilias Diakonikolas <diakonik@usc.edu>, Ronitt Rubinfeld <ronitt@csail.mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
equivalence of two distributions (two sample testing), and independence.
",1. Introduction,[0],[0]
"While statistical tests are very important for advancing science, when they are performed on sensitive data representing specific individuals, such as data describing medical or other behavioral phenomena, it may be that the outcomes of the tests reveal private information that should not be divulged.",1. Introduction,[0],[0]
Techniques from differential privacy give us hope that one may obtain the scientific benefit of statistical tests without compromising the privacy of the individuals in the study.,1. Introduction,[0],[0]
"Concretely, differential privacy requires that similar datasets have statistically close outputs – once this property is achieved, then provable privacy guarantees can be made.",1. Introduction,[0],[0]
"Differential privacy is a rich and active area of study, in which techniques have been developed and applied to obtain private algorithms for a range of data analysis tasks.
",1. Introduction,[0],[0]
"Our Contributions We study the general problem of hypothesis testing in the setting of differential privacy (Dwork & Roth, 2014).",1. Introduction,[0],[0]
"Our emphasis is on the sublinear regime, i.e., when the number of samples available is sublinear in the domain size of the underlying distribution(s).",1. Introduction,[0],[0]
We obtain sample-efficient private algorithms for the problems of testing the identity and equivalence of discrete distributions.,1. Introduction,[0],[0]
The main conceptual message of our work is that we can achieve differential privacy with only a small increase in the sample complexity compared to the non-private case.,1. Introduction,[0],[0]
"Our theoretical results significantly improve over the best known algorithms for identity testing, and are the first results for private equivalence testing.",1. Introduction,[0],[0]
Our experimental evaluation illustrates that our testers achieve small type I and type II errors with a sublinear number of samples when the domain size is large.,1. Introduction,[0],[0]
The sample complexity of our private identity tester significantly outperforms the sample complexity of recently proposed methods for this problem.,1. Introduction,[0],[0]
"For both identity and equivalence testing, our experiments show that differential privacy can be achieved essentially for free, i.e., with a very mild increase in sample complexity.
",1. Introduction,[0],[0]
Technical Overview,1. Introduction,[0],[0]
We now provide a brief overview of our techniques.,1. Introduction,[0],[0]
We start by observing that there is a simple generic method to convert a non-private tester into a private tester with a multiplicative overhead in the sample complexity.,1. Introduction,[0],[0]
"This method is known in differential privacy, but for the sake of completeness we describe it in Appendix B. It will
be useful to contrast the sample complexity of the generic method with the (substantially better) sample complexity of our testers (Sections 3-5).",1. Introduction,[0],[0]
"For convenience, throughout our theoretical analysis, we obtain testing algorithms that have failure probability at most 1/3.",1. Introduction,[0],[0]
"As shown in Appendix C, this is without loss of generality: we can achieve error probability at the expense of a log(1/ ) multiplicative increase in the sample complexity, even in the differentially private setting.
",1. Introduction,[0],[0]
"Our algorithm for identity testing is obtained via the following modular approach: First, we adapt a recently discovered reduction of identity testing to uniformity testing (Goldreich, 2016), building on (Diakonikolas & Kane, 2016).",1. Introduction,[0],[0]
We show (Section 3) that this reduction can be adapted to work in the private setting as well.,1. Introduction,[0],[0]
"Therefore, we can translate any private uniformity tester to a private identity tester without increasing the sample size by more than a constant factor.",1. Introduction,[0],[0]
It remains to develop sample-efficient private uniformity testers.,1. Introduction,[0],[0]
"We develop two such private methods (Section 4): Our first method is a private version of (Paninski, 2008), which relies on the number of domain elements that appear in the sample exactly once.",1. Introduction,[0],[0]
"This statistic has low sensitivity, allowing a translation to the private setting via standard techniques.",1. Introduction,[0],[0]
"The sample complexity of our aforementioned uniformity tester is
⇥",1. Introduction,[0],[0]
"( p n/✏ 2 + p n/(✏ p ⇠)) , (1)
where n is the domain size, ✏ is the accuracy of the tester, and ⇠ is the privacy parameter.",1. Introduction,[0],[0]
"Our experimental results illustrate that this private tester performs exceptionally well in practice, significantly outperforming recently proposed private algorithms for identity testing (see Section 6).
",1. Introduction,[0],[0]
"We note that the uniformity tester of (Paninski, 2008) is known to completely fail when the sample size is larger than the domain size (even in the non-private setting).",1. Introduction,[0],[0]
"To obtain a uniformity tester that works for the non-sparse regime, we develop our second algorithm: a private version of the collisions-based tester of (Goldreich & Ron, 2000).",1. Introduction,[0],[0]
A collision refers to the event that two random samples drawn from the underlying distribution correspond to the same domain element.,1. Introduction,[0],[0]
"The collisions-based tester was recently shown to be sample-optimal in the non-private setting (Diakonikolas et al., 2016).",1. Introduction,[0],[0]
The main difficulty in turning this non-private tester into a private tester is that the underlying statistic (number of collisions) has very high worst-case sensitivity.,1. Introduction,[0],[0]
"Hence, the standard approach of adding Laplace noise to the statistic fails in this setting.",1. Introduction,[0],[0]
"To overcome this obstacle, we add an appropriate pre-processing step to our tester that rejects when there is a single element that appears many times in the sample.",1. Introduction,[0],[0]
"(We note that a similar idea was independently used in (Cai et al., 2017), though the details are somewhat different.)",1. Introduction,[0],[0]
"This step allows us to reduce the effective sensitivity of the statistic and can be shown to yield
a sample-efficient private tester.",1. Introduction,[0],[0]
"Specifically, the sample complexity of our collisions-based private tester is
Õ p n/✏ 2 + p n/(✏⇠) + 1/(✏2⇠) .",1. Introduction,[0],[0]
"(2)
For the problem of equivalence testing, we build on the recently developed chi-square tester of (Chan et al., 2014), which is sample-optimal in the non-private testing.",1. Introduction,[0],[0]
We show that this statistic has bounded sensitivity.,1. Introduction,[0],[0]
"Hence, developing a sample-efficient private version can be achieved by adding Laplace noise.",1. Introduction,[0],[0]
A careful analysis shows that the noisy statistic is still accurate without substantially increasing the sample complexity.,1. Introduction,[0],[0]
"Specifically, the sample complexity of our private equivalence tester is
O ⇣p n/✏ 2 + n2/3/✏4/3 + p n/( p ⇠✏) + 1/(⇠✏2) ⌘ .",1. Introduction,[0],[0]
"(3)
We note that the effect of the privacy constraint on the sample complexity of our testers is in some sense additive, as opposed to multiplicative.",1. Introduction,[0],[0]
"In particular, for each case, the sample complexity of the private tester equals the sample complexity of the corresponding non-private tester plus a term that depends on the privacy parameter.",1. Introduction,[0],[0]
"For reasonable settings of the privacy parameter, this additive term can be negligible compared to the first term, in which case we obtain differential privacy essentially for free.",1. Introduction,[0],[0]
"As a concrete example, the second term in (1) is dominated by the first term (which is provably necessary for any identity tester, even in the non-private setting (Paninski, 2008)), as long as ⇠ ✏2.",1. Introduction,[0],[0]
"This phenomenon is confirmed in our experimental evaluation.
",1. Introduction,[0],[0]
"Related Work During the past two decades, distribution property testing (Batu et al., 2000) – whose roots lie in statistical hypothesis testing (Neyman & Pearson, 1933; Lehmann & Romano, 2005) – has received considerable attention by the computer science community, see (Rubinfeld, 2012; Canonne, 2015) for two recent surveys.",1. Introduction,[0],[0]
The majority of the early work in this field has focused on characterizing the sample size needed to test properties of arbitrary distributions of a given support size.,1. Introduction,[0],[0]
"After two decades of study, this “worst-case” regime is well-understood: for many properties of interest there exist sample-optimal testers (matched by information-theoretic lower bounds)",1. Introduction,[0],[0]
"(Paninski, 2008; Daskalakis et al., 2013; Chan et al., 2014; Valiant & Valiant, 2014; Diakonikolas et al., 2015b;c; Acharya et al., 2015; Diakonikolas & Kane, 2016; Canonne et al., 2016; Diakonikolas et al., 2016; Canonne et al., 2017; Diakonikolas et al., 2017b).
",1. Introduction,[0],[0]
"A recent line of work (Wang et al., 2015; Gaboardi et al., 2016; Kifer & Rogers, 2017; Kakizaki et al., 2017; Cai et al., 2017) has studied distribution testing with privacy constraints.",1. Introduction,[0],[0]
"The majority of these works (Wang et al., 2015; Gaboardi et al., 2016; Kifer & Rogers, 2017) only obtain
type I error guarantees subject to the privacy constraint, which is a significantly weaker guarantee than ours.",1. Introduction,[0],[0]
"The recent work by Cai et al. (Cai et al., 2017) provides an identity tester with finite sample guarantees and bounded type I and type II errors.",1. Introduction,[0],[0]
"Specifically, (Cai et al., 2017) give a private identity tester with sample complexity
Õ ⇣p n/✏ 2 + p n/(✏3/2⇠) +",1. Introduction,[0],[0]
n1/3/(✏5/3⇠2/3),1. Introduction,[0],[0]
⌘ .,1. Introduction,[0],[0]
"(4)
The above bound is always asymptotically worse than (1) and worse than (2) for most parameter settings.",1. Introduction,[0],[0]
"We remind the reader that (Cai et al., 2017) does not consider the more general problem of equivalence testing, and that ours are the first results in this setting.",1. Introduction,[0],[0]
"Finally, (Diakonikolas et al., 2015a) has provided differentially private algorithms for learning various families of discrete distributions.",1. Introduction,[0],[0]
"For the case of unstructured discrete distributions, as the ones considered here, such algorithms inherently require sample size at least linear in the domain size, even for constant values of the approximation parameter.
",1. Introduction,[0],[0]
"Independent and concurrent work (Acharya et al., 2017) obtained similar upper bounds for private identity and closeness testing.",1. Introduction,[0],[0]
"In addition, they obtained nearly matching sample lower bounds in some regimes.",1. Introduction,[0],[0]
Notation and Basic Definitions.,2. Preliminaries,[0],[0]
"We use [n] to denote the set {1, 2, . . .",2. Preliminaries,[0],[0]
", n}.",2. Preliminaries,[0],[0]
We say that p is a distribution over [n] if p :,2. Preliminaries,[0],[0]
[n] !,2. Preliminaries,[0],[0]
"[0, 1] is a function such that Pn i=1",2. Preliminaries,[0],[0]
p(i),2. Preliminaries,[0],[0]
"= 1, where p(i) denotes the probability of element i. For a set S ✓",2. Preliminaries,[0],[0]
"[n], p(S) denotes the total probability of the elements in S (i.e., p(S) = P i2S p(i)).",2. Preliminaries,[0],[0]
"For any integer k > 0, the `k-norm of p is equal to Pn
i=1 |p(i)|k",2. Preliminaries,[0],[0]
"1
k , and it is denoted by kpkk.",2. Preliminaries,[0],[0]
The `k-distance between two distributions p and q over [n] is equal to Pn i=1 |p(i),2. Preliminaries,[0],[0]
q(i)|k 1 k .,2. Preliminaries,[0],[0]
"We use Lap(b) to denote a random variable that is drawn from a Laplace distribution with parameter b and mean zero.
",2. Preliminaries,[0],[0]
The problem of identity testing (or goodness-of-fit) is the following:,2. Preliminaries,[0],[0]
"Given sample access to an unknown distribution p over [n] and an explicit distribution q over [n], we want to distinguish, with probability at least 2/3, between the cases that p = q (completeness) and kp qk1 ✏ (soundness).",2. Preliminaries,[0],[0]
"(If kp qk1 ✏, we will say that p and q are ✏-far from each other.)",2. Preliminaries,[0],[0]
"The special case of this problem when q = Un, the uniform distribution over [n], is called uniformity testing.",2. Preliminaries,[0],[0]
"The generalization of identity testing when both p and q are unknown and only accessible via samples is called equivalence testing.
",2. Preliminaries,[0],[0]
Differential Privacy.,2. Preliminaries,[0],[0]
"In our context, a dataset is a multiset of samples drawn from a distribution over [n].",2. Preliminaries,[0],[0]
"We say that X and Y are neighboring datasets if they differ in exactly
one element.
",2. Preliminaries,[0],[0]
Definition 2.1.,2. Preliminaries,[0],[0]
A randomized algorithm A : [n]s !,2. Preliminaries,[0],[0]
"R, is ⇠-differentially private if for any S ✓ R and any neighboring datasets X,Y , we have that Pr[A(X) 2 S]  ",2. Preliminaries,[0],[0]
"e ⇠ ·Pr[A(Y ) 2 S] .
",2. Preliminaries,[0],[0]
"We will say that a tester is (✏, ⇠)-private, to mean that ✏ is the accuracy parameter, ⇠ is the privacy parameter, and the tester outputs the right answer with probability at least 2/31.",2. Preliminaries,[0],[0]
"For conciseness, we use the term ⇠-private instead of ⇠-differentially private.",2. Preliminaries,[0],[0]
We provide more details about general techniques in differential privacy in Appendix A.,2. Preliminaries,[0],[0]
"In this section, we provide a reduction of private identity testing (against a fixed distribution) to its special case of private uniformity testing.",3. Private Identity Testing: Reduction to Private Uniformity Testing,[0],[0]
"Specifically, we prove that a recent reduction (Goldreich, 2016) of (non-private) identity testing to (non-private) uniformity testing can be adapted to work in the private setting as well.
",3. Private Identity Testing: Reduction to Private Uniformity Testing,[0],[0]
Suppose we want to test identity between an unknown distribution p over [n] and an explicit distribution q.,3. Private Identity Testing: Reduction to Private Uniformity Testing,[0],[0]
"The reduction of (Goldreich, 2016) transforms the distribution p into a new distribution p0, over a domain of size O(n), such that if p = q then p0 is the uniform distribution, and if p is far from q, p0 is also far from uniform.",3. Private Identity Testing: Reduction to Private Uniformity Testing,[0],[0]
"Specifically, the reduction defines a randomized mapping of a sample i 2",3. Private Identity Testing: Reduction to Private Uniformity Testing,[0],[0]
"[n] from p to a sample (j, a) from p0 that depends only on the explicit distribution q. This property is crucial as it allows us to show that the transformation preserves differential privacy, as the following theorem states:
Theorem 3.1.",3. Private Identity Testing: Reduction to Private Uniformity Testing,[0],[0]
"Given an (✏, ⇠)-private uniformity tester using s(n, ✏, ⇠) samples, there exists an (✏, ⇠)-private tester for identity using s = s(6n, ✏/3, ⇠) samples.
",3. Private Identity Testing: Reduction to Private Uniformity Testing,[0],[0]
The detailed proof of the theorem is deferred to Appendix D.,3. Private Identity Testing: Reduction to Private Uniformity Testing,[0],[0]
"In this section, we provide two sample-efficient private uniformity testers.",4. Private Uniformity Testing,[0],[0]
"Our testers are private versions of two well-studied (non-private) testers, due to Goldreich and Ron (Goldreich & Ron, 2000) and Paninski (Paninski, 2008).",4. Private Uniformity Testing,[0],[0]
"Paninski’s uniformity tester (Paninski, 2008) relies on the number of unique elements in the sample, while (Goldreich & Ron, 2000) relies on the number of collisions.",4. Private Uniformity Testing,[0],[0]
"Both testers are known to be sample-optimal in the non-private setting (Paninski, 2008; Diakonikolas et al., 2016).
",4. Private Uniformity Testing,[0],[0]
1We emphasize that the confidence probability 2/3 can be increased to 1 at the expense of a log(1/ ) multiplicative increase in the sample complexity.,4. Private Uniformity Testing,[0],[0]
"See Appendix C.
Algorithm 1 Private Uniformity Testing via Unique Elements: Private-Unique-Elements-Uniformity
1: Input: Sample access to p, n, ✏, ⇠ 2: s 5 p n/(✏ p ⇠) + 6 p n/✏ 2 3: C s✏ 2
p n
4: x1, x2, . . .",4. Private Uniformity Testing,[0],[0]
", xs s samples drawn from p 5: K the number of unique elements in
{x1, x2, . . .",4. Private Uniformity Testing,[0],[0]
", xs} 6:",4. Private Uniformity Testing,[0],[0]
"K 0 K + Lap(2/⇠) 7: T EU [K] C2/(2✏2) {where EU [K] equals to
s · 1 1n s 1} 8: if K 0 < T then 9: Output reject.
10: end if 11: Output accept.
",4. Private Uniformity Testing,[0],[0]
We give private versions of both of these algorithms.,4. Private Uniformity Testing,[0],[0]
The sample complexity of our private Paninski uniformity tester is O( p n/✏ 2 + p n/(✏ p ⇠)) .,4. Private Uniformity Testing,[0],[0]
"Therefore, as long as ⇠ = ⌦(✏2), the privacy requirement increases the sample complexity by at most a constant factor.
",4. Private Uniformity Testing,[0],[0]
"Unfortunately, the aforementioned tester only succeeds when its sample size is smaller than the domain size n. To be able to handle the entire range of parameters, we develop a private version of the collisions-based tester from (Goldreich & Ron, 2000).",4. Private Uniformity Testing,[0],[0]
Our private version of the collisions tester has sample complexity Õ p n/✏ 2 + p n/(✏⇠) + 1/(✏2⇠) .,4. Private Uniformity Testing,[0],[0]
"Similarly, the effect of the privacy is mild as long as ⇠ = ⌦(✏).",4. Private Uniformity Testing,[0],[0]
We provide a private tester for uniformity based on the number of unique elements.,4.1. Private Uniformity Tester via Unique Elements,[0],[0]
The number of unique elements is (negatively) related to the number of collisions and the ` 2-norm of the distribution.,4.1. Private Uniformity Tester via Unique Elements,[0],[0]
"Therefore, the greater the number of unique elements is, the more the distribution appears uniform.",4.1. Private Uniformity Tester via Unique Elements,[0],[0]
"To make the algorithm private, we use the Laplace mechanism which adds a small amount of noise to the number of unique elements.",4.1. Private Uniformity Tester via Unique Elements,[0],[0]
"Then, we compare the number of unique elements with a threshold to decide if the distribution is uniform or far from uniform.",4.1. Private Uniformity Tester via Unique Elements,[0],[0]
"The noise rate is chosen appropriately so that the following conflicting goals are simultaneously achieved: (1) the algorithm is guaranteed to be private, and (2) the accuracy of the tester does not significantly decrease.",4.1. Private Uniformity Tester via Unique Elements,[0],[0]
This is formalized in Theorem 4.1.,4.1. Private Uniformity Tester via Unique Elements,[0],[0]
"The algorithm is described in the following pseudocode:
Theorem 4.1.",4.1. Private Uniformity Tester via Unique Elements,[0],[0]
Given s =,4.1. Private Uniformity Tester via Unique Elements,[0],[0]
O( p n/,4.1. Private Uniformity Tester via Unique Elements,[0],[0]
(,4.1. Private Uniformity Tester via Unique Elements,[0],[0]
"✏ p ⇠)+ p n/✏
2) samples from a distribution p over [n], Algorithm 1 is an (✏, ⇠)- private uniformity tester, if s is sufficiently smaller than the
domain size n.
Let K be the number of unique elements in the sample set.",4.1. Private Uniformity Tester via Unique Elements,[0],[0]
"Since changing one sample in the sample set can change the number of unique elements by no more than two, adding Laplace noise with parameter 2/⇠ to K makes it ⇠-private.",4.1. Private Uniformity Tester via Unique Elements,[0],[0]
"Using the composition theorem of differential privacy, we conclude that the overall algorithm is ⇠-private.",4.1. Private Uniformity Tester via Unique Elements,[0],[0]
"To show that the algorithm is an ✏-tester, we prove that the statistic K
0 concentrates well around its expectation in both the completeness and soundness cases.",4.1. Private Uniformity Tester via Unique Elements,[0],[0]
"To establish this, we exploit the fact that the variance introduced by the added noise is sufficiently small.",4.1. Private Uniformity Tester via Unique Elements,[0],[0]
"Since there is a non-trivial gap between the expected values of K 0 in the two cases, the proof follows by an application of Chebyshev’s inequality.",4.1. Private Uniformity Tester via Unique Elements,[0],[0]
See Appendix E for the formal details.,4.1. Private Uniformity Tester via Unique Elements,[0],[0]
"In this subsection, we describe the private version of our collisions-based uniformity tester.",4.2. Private Uniformity Tester via Collisions,[0],[0]
Recall that a collision refers to the event that two random samples drawn from the underlying distribution correspond to the same domain element.,4.2. Private Uniformity Tester via Collisions,[0],[0]
The main difficulty in turning this into a private tester is that the underlying statistic (number of collisions) has very high worst-case sensitivity.,4.2. Private Uniformity Tester via Collisions,[0],[0]
"Specifically, if the sample set contains s copies of a given domain element, by changing just one of the copies to another element, the number of collisions drops by an additive s.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"So, if we add enough noise to the statistic to cover the sensitivity of s, the tester accuracy substantially degrades.
",4.2. Private Uniformity Tester via Collisions,[0],[0]
"To overcome this obstacle, we add a pre-processing step to our tester.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"We notice that the sensitivity of the number of collisions, f(X), for sample set X , depends on the maximum frequency of any element in the sample set.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"Let ni(X) denote the number of occurrences of element i in the sample set X , and let nmax(X) denote the maximum ni(X).",4.2. Private Uniformity Tester via Collisions,[0],[0]
"We note that for two neighboring sample sets X and Y , the difference of the number of collisions, |f(X) f(Y )",4.2. Private Uniformity Tester via Collisions,[0],[0]
"|, is at most nmax(X).",4.2. Private Uniformity Tester via Collisions,[0],[0]
"Therefore, the sensitivity of f is high on X’s with large nmax(X).",4.2. Private Uniformity Tester via Collisions,[0],[0]
"If the underlying distribution is uniform, we do not expect any particular element to show up very frequently.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"Hence, if nmax(X) is high, the algorithm can output reject regardless of f(X).",4.2. Private Uniformity Tester via Collisions,[0],[0]
"So, the final output of the algorithm does not change drastically on X and Y , while the number of collisions varies a lot.
",4.2. Private Uniformity Tester via Collisions,[0],[0]
This simple idea forms the basis for our modified tester.,4.2. Private Uniformity Tester via Collisions,[0],[0]
"The algorithm uses two statistics: nmax and f (or more precisely the noisy version of them, n̂max and f̂ ).",4.2. Private Uniformity Tester via Collisions,[0],[0]
"If n̂max is too large, it outputs reject.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"Otherwise, f̂(X) determines the output.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"In the second case, since nmax is not too large, f has bounded sensitivity.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"Therefore, we can make it private by adding a small amount of noise to it.
",4.2. Private Uniformity Tester via Collisions,[0],[0]
"To prove the privacy guarantee, note that if f(X) has lowsensitivity, then f̂(X) is easily seen to be private.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"By the
Algorithm 2 Private uniformity tester based on the number of collisions: Private-Collisions-Uniformity
1: Input: Sample access to p, n, ✏, ⇠ 2: s ⇥ ✓p
n",4.2. Private Uniformity Tester via Collisions,[0],[0]
"✏2 + p n logn ✏ ⇠1/2
+ p nmax(1,log 1/⇠)
✏ ⇠ + 1 ✏2 ⇠
◆ .
",4.2. Private Uniformity Tester via Collisions,[0],[0]
"3: Let X = {x1, x2, . . .",4.2. Private Uniformity Tester via Collisions,[0],[0]
", xs} be a multiset of s samples drawn from p
4: ni(X) |{j|xj 2 x and xj = i}|
5: nmax(X) max i ni(X) 6: n̂max(X) nmax(X) + Lap(2/⇠)
7: f(X) collisions(X)
8: ⌘f max 3s 2n , 12 e 2 ln 24n
+ (2 ln 12)/⇠ + 2max(ln 3, ln 3/⇠)/⇠
9: T max 3s 2n , 12 e 2 ln 24n",4.2. Private Uniformity Tester via Collisions,[0],[0]
"+ (2 ln 12)/⇠
10: f̂(X) f(X) + Lap(2 ⌘f/⇠)
11: if n̂max(X)",4.2. Private Uniformity Tester via Collisions,[0],[0]
"< T & f̂(X) < 6+✏ 2
6n s 2 then
12: O accept.
13: else
14: O reject.
15: end if 16: With probability 1/6, O {accept, reject} \O. hhflip
the answer with probability 1/6.ii 17: Output O.
composition theorem of differential privacy (Lemma A.3), in this case the overall algorithm will be private.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"The difficulty appears in the complementary case, i.e., when f(X) is highly sensitive.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"In this case, nmax(X) has to be large.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"From that we can deduce, that it is very unlikely (over the random noise) that n̂max is small.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"Given the above and the fact that our algorithm flips its answer with probability 1/6 in the last step, we can compute a closed form formula for the probability that our tester accepts, which allows us to directly prove the privacy guarantee.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"With a similar argument, we show the privacy guarantee holds for the case that our tester rejects.
",4.2. Private Uniformity Tester via Collisions,[0],[0]
The detailed procedure is explained in Algorithm 2.,4.2. Private Uniformity Tester via Collisions,[0],[0]
"We have the following (see Appendix F for the proof):
Theorem 4.2.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"Algorithm 2 is an (✏, ⇠)-private tester for uniformity.
",4.2. Private Uniformity Tester via Collisions,[0],[0]
Remark 4.3.,4.2. Private Uniformity Tester via Collisions,[0],[0]
"Recent work (Diakonikolas et al., 2017a) has obtained an optimal (non-private) uniformity tester based on the `1-distance of the empirical distribution from the uniform distribution.",4.2. Private Uniformity Tester via Collisions,[0],[0]
"Since this new tester is Lipschitz, we can make it private by adding Laplace noise to the distribution.
",4.2. Private Uniformity Tester via Collisions,[0],[0]
The simple proof of this fact will appear in a revised version of this paper.,4.2. Private Uniformity Tester via Collisions,[0],[0]
"A similar observation was made independently in (Acharya et al., 2017).",4.2. Private Uniformity Tester via Collisions,[0],[0]
"In this section, we give a private algorithm for testing equivalence of two unknown discrete distributions.",5. Private Equivalence Testing,[0],[0]
"Our tester relies on the chi-squared type sample-optimal (non-private) equivalence tester of (Chan et al., 2014).",5. Private Equivalence Testing,[0],[0]
"The equivalence tester relies on the following statistic:
Z := X
i
(Xi Yi)2 Xi Yi Xi + Yi ,
where Xi is the number of occurrences of element i in the sample set from p, and Yi is the number of occurrences of element",5. Private Equivalence Testing,[0],[0]
i in the sample set from q.,5. Private Equivalence Testing,[0],[0]
The statistic Z is chosen in a way so that its expected values in the completeness and soundness cases differ substantially.,5. Private Equivalence Testing,[0],[0]
"The challenging part of the analysis involves a tight upper bound on the variance, which allows to show that Z is well-concentrated after an appropriate number of samples.",5. Private Equivalence Testing,[0],[0]
"More precisely, the following statements were shown in (Chan et al., 2014):
E[Z] = X
i
(p(i) q(i))2
p(i) + q(i) m
✓ 1 1 e m(p(i)+q(i))
",5. Private Equivalence Testing,[0],[0]
"m(p(i) + q(i))
◆
m 2
4n+ 2m kp qk21 .",5. Private Equivalence Testing,[0],[0]
"(5)
and
Var[Z]  2min{m,n}+ X
i
5m (p(i)",5. Private Equivalence Testing,[0],[0]
"q(i))2
p(i) + q(i) .",5. Private Equivalence Testing,[0],[0]
"(6)
The private version of the above statistic is simple: We add noise to the random variable Z and work with the noisy statistic, denoted by Z 0.",5. Private Equivalence Testing,[0],[0]
"We need to show that we still can infer the correct answer from Z 0, and the noise does not incapacitate our tester.",5. Private Equivalence Testing,[0],[0]
"The main reason that this is indeed possible is because the statistic Z has bounded sensitivity.
",5. Private Equivalence Testing,[0],[0]
Algorithm 3 is our private equivalence tester and we prove its correctness in Theorem 5.1.,5. Private Equivalence Testing,[0],[0]
Theorem 5.1.,5. Private Equivalence Testing,[0],[0]
"Given sample access to two distributions p
and q, Algorithm 3 is an (✏, ⇠)-private tester for equivalence of p and q.
Since the sensitivity of Z is small, we can add a small amount of noise to it to make it private, using the Laplace mechanism.",5. Private Equivalence Testing,[0],[0]
"Then, we show that adding the noise to Z does not increase its variance drastically.",5. Private Equivalence Testing,[0],[0]
"Finally, we prove by the Chebyshev inequality that, with high probability, Z concentrates well around its expected value given the size of the sample set.",5. Private Equivalence Testing,[0],[0]
"The proof of the theorem is in Appendix G.
Algorithm 3 Private Equivalence Tester: PrivateEquivalence-Test
1: Input: Sample access to p and q, n, ✏, ⇠ 2: m C ·max ✓p n
✏2 , n 2/3 ✏4/3 , p np ⇠✏ , 1 ⇠✏2 ◆
3: Draw m samples from distributions p and q. 4: Xi the number of occurrences of the i-th element in
the samples from p 5: Yi the number of occurrences of the i-th element in
the samples from q
6:",5. Private Equivalence Testing,[0],[0]
Z P i,5. Private Equivalence Testing,[0],[0]
(Xi Yi)2 Xi Yi Xi + Yi hhfor Xi + Yi 6= 0.ii,5. Private Equivalence Testing,[0],[0]
"7: ⌘ Lap(8/⇠)
8: Z 0 = Z + ⌘
9: T m 2 ✏ 2
8n+ 4m
10: if Z 0  T then 11: Output accept.",5. Private Equivalence Testing,[0],[0]
12: else 13: Output reject.,5. Private Equivalence Testing,[0],[0]
14: end if,5. Private Equivalence Testing,[0],[0]
We provide an empirical evaluation of the proposed algorithms on synthetic data.,6. Experiments,[0],[0]
"All experiments were performed on a computer with a 1.6 GHz Intel(R) Core(TM) i5-4200U CPU and 3 GB of RAM.
",6. Experiments,[0],[0]
"Before we describe our methodology and experimental results in detail, we make two crucial remarks.",6. Experiments,[0],[0]
"First, as we explain in more detail below, we note that our synthetic datasets include the provably hardest instances of the corresponding testing problems in the non-private setting.",6. Experiments,[0],[0]
"That is, we provide as input to our algorithms sets of samples from pairs of discrete distributions that are the hardest to distinguish information-theoretically.",6. Experiments,[0],[0]
"The related work (Cai et al., 2017) evaluated the empirical performance of their identity tester on essentially identical synthetic inputs.",6. Experiments,[0],[0]
"Second, since theoretical sample upper bounds in distribution testing typically use big-O notation, the practical performance of the various algorithms depends on the hidden absolute constants in these bounds (which are notoriously hard to pin-down theoretically).",6. Experiments,[0],[0]
"As a result, our experimental evaluation reveals phenomena which are not directly implied by our theoretical upper bounds.
",6. Experiments,[0],[0]
We now briefly describe our methodology.,6. Experiments,[0],[0]
"To measure the accuracy of our algorithms, we empirically estimate the error probability, i.e., the probability that our algorithms output the wrong answer.",6. Experiments,[0],[0]
"We run our algorithms on input of s samples from a distribution q (or a pair of distributions) that either satisfies the property (completeness) or is ✏-far
in `1-distance from satisfying the property.",6. Experiments,[0],[0]
We denote the distribution q in these two cases by q+ and q respectively.,6. Experiments,[0],[0]
We repeatedly run our algorithm r times and compute the ratio of the incorrect answers among these r trials for both q + and q .,6. Experiments,[0],[0]
This gives as estimates for the type I and II errors of our algorithm.,6. Experiments,[0],[0]
"We want to understand how fast the error probability converges to 0 as the sample size increases.
",6. Experiments,[0],[0]
"For the case of uniformity testing, we observe that PrivateUnique-Elements-Uniformity (Algorithm 1) performs significantly better on our datasets than algorithm PrivateCollisions-Uniformity (Algorithm 2), especially when the domain size n is very large (Figure 1).",6. Experiments,[0],[0]
"For the case of private identity testing, we show (Figures 3 and 4) that our identity tester obtained by combining our reduction with Private-Unique-Elements-Uniformity significantly outperforms all previous algorithms for this problem.",6. Experiments,[0],[0]
"Finally, for the case of equivalence testing, our experiments illustrate (Figure 5) that we can obtain differential privacy essentially for free.
",6. Experiments,[0],[0]
Private Uniformity Testing.,6. Experiments,[0],[0]
"We implemented PrivateUnique-Elements-Uniformity (Algorithm 1) and PrivateCollisions-Uniformity (Algorithm 2) to test the uniformity of a distribution in `1-distance.
",6. Experiments,[0],[0]
Let q+ be the uniform distribution on [n] and q be a distribution that has probability (1 + ✏)/n,6. Experiments,[0],[0]
on half of the domain and probability (1 ✏)/n,6. Experiments,[0],[0]
on the other half.,6. Experiments,[0],[0]
Note that q is ✏-far from uniform in `1-distance.,6. Experiments,[0],[0]
"It is known that q is the hardest distribution to distinguish from uniform among all distributions that are ✏-far (Paninski, 2008), without losing any constant factor (Diakonikolas et al., 2017a).
",6. Experiments,[0],[0]
"We run our two algorithms using samples from q+ and q with the following parameters: n = 800, 000, ✏ = 0.3, r = 300, and ⇠ = 0.2.",6. Experiments,[0],[0]
We estimate how the empirical error probability of the tester changes by increasing the number of samples.,6. Experiments,[0],[0]
"As shown in Figure 1, for such a large domain, the algorithm Private-Unique-Elements-Uniformity reaches empirical error of almost zero with sample size sublinear in the size of the domain.",6. Experiments,[0],[0]
"We emphasize that none of the previous algorithms in this setting was able to obtain meaningful guarantees in this sparse sample regime.
",6. Experiments,[0],[0]
"As predicted by our theoretical bounds, the tester PrivateUnique-Elements-Uniformity completely fails if it uses more samples than the domain size.",6. Experiments,[0],[0]
"This fact is important when the domain size n and accuracy ✏ are such that the quantity p n/✏
2 is comparable to the domain size n.",6. Experiments,[0],[0]
"For example, if n = 1000 and ✏ = 0.1, Private-UniqueElements-Uniformity is unable to provide any meaningful guarantees, hence we need to resort to Private-CollisionsUniformity.",6. Experiments,[0],[0]
"This is illustrated in Figure 2.
",6. Experiments,[0],[0]
"A plausible interpretation for the apparent superiority of Private-Unique-Elements-Uniformity in the sparse regime
is that: (1) The non-private version of this tester is known to achieve optimal constants in the big-O of the sample complexity (Huang & Meyn, 2013).",6. Experiments,[0],[0]
"(2) The non-private tester has low sensitivity, hence we do not require a preprocessing phase (as in Private-Collisions-Uniformity) to obtain a private algorithm.
",6. Experiments,[0],[0]
Private Identity Testing.,6. Experiments,[0],[0]
We now describe our two private identity testers and experimentally compare them to previous private identity testers developed in the recent literature.,6. Experiments,[0],[0]
"As explained in Section 3, we proceed to reduce private identity testing to private uniformity testing.",6. Experiments,[0],[0]
"More specifically, our identity testers work by first mapping the sample set S to
a new set S0 on a somewhat larger domain, and then testing uniformity on the new domain using samples in S0.",6. Experiments,[0],[0]
"Since we have two uniformity testers, Private-Unique-ElementsUniformity and Private-Collisions-Uniformity, we thus obtain two identity testers based on which uniformity tester we use.",6. Experiments,[0],[0]
"We term these two private identity testers PrivateUnique-Elements-Identity and Private-Collisions-Identity respectively.
",6. Experiments,[0],[0]
"We compare our algorithms with the two recent algorithms: Priv’IT proposed in (Cai et al., 2017) and MCGOF proposed in (Gaboardi et al., 2016).",6. Experiments,[0],[0]
"It should be noted that our algorithms (and those of (Cai et al., 2017)) provides significantly stronger guarantees compared to (Gaboardi et al., 2016).",6. Experiments,[0],[0]
"More specifically, (Gaboardi et al., 2016) only provides type I error guarantees: the algorithm outputs reject with small probability when the distribution is identical to the given distribution.",6. Experiments,[0],[0]
"In contrast, our identity testers provably provide small type I and type II error probabilities.
",6. Experiments,[0],[0]
"We evaluate the various identity testers on two different pairs of distributions: (1) q+1 is the uniform distribution on [n], while q 1 assigns probability (1+✏)/n on half of the domain and probability (1 ✏)/n",6. Experiments,[0],[0]
on the other half.,6. Experiments,[0],[0]
"(2) q+2 is a 4- histogram distribution, i.e., the probability mass function is piecewise constant with 4 pieces, and q 2 is obtained from q + 2 by perturbing the probability of each element by ±✏/n.",6. Experiments,[0],[0]
"Testing uniformity is a special case of identity testing, and it is known to be essentially the hardest instance of this more general problem.
",6. Experiments,[0],[0]
"For (1), we explicitly give the uniform distribution, q+1 , to our identity testing algorithm, and draw samples from q+1 or q 1 .",6. Experiments,[0],[0]
"We use the parameters n = 800, 000, ✏ = 0.3, and ⇠ = 0.2.",6. Experiments,[0],[0]
"We vary the sample size staring from 50, 000 and up to 3 ⇥ 106, increasing it by 50, 000 at each step, and repeat the algorithm for r = 200 times to estimate the maximum of type I and type II errors.",6. Experiments,[0],[0]
We repeat the same process for all the testers we compared against.,6. Experiments,[0],[0]
"The results are shown in Figure 3.
",6. Experiments,[0],[0]
"For (2), we use the same methodology on input the 4- histogram distribution q+2 with interval pieces I1, I2, I3, I4 each of size n/4 such that q+2 (I1) = 4q + 2 (I4), q + 2 (I2) =",6. Experiments,[0],[0]
"3q+2 (I4), and q + 2 (I3) = 2q + 2 (I4).",6. Experiments,[0],[0]
"The results are shown in Figure 4.
",6. Experiments,[0],[0]
"In both cases, we observe that our identity tester PrivateUnique-Elements-Identity converges much faster than all other algorithms.
",6. Experiments,[0],[0]
"We remind the reader that (Gaboardi et al., 2016) did not provide any type II error guarantees for their tester MCGOF.",6. Experiments,[0],[0]
"We included two different curves in our plots illustrating the empirical type I and type II errors of the (Gaboardi et al., 2016) tester.
",6. Experiments,[0],[0]
Private Equivalence Testing.,6. Experiments,[0],[0]
"The focus of the experimental evaluation for equivalence testing is as follows: For a range of increasing domain sizes, n, we want to find the smallest sample size such that the error probability (maximum of type I and type II errors) drops below 1/3.
",6. Experiments,[0],[0]
We implemented Algorithm 3 to test equivalence of two unknown distributions.,6. Experiments,[0],[0]
"We show that for sufficiently large domain size n, our private algorithm succeeds with a sublinear number of samples.
",6. Experiments,[0],[0]
"For given domain size n, to find the (approximately) minimum number of samples such that the error probability of the algorithm drops below 1/3, we proceed as follows: We start with an initial number of samples s.",6. Experiments,[0],[0]
"Then, we estimate the empirical error of the algorithm for these sample sets.",6. Experiments,[0],[0]
"If it is more than 1/3, we increase s appropriately and repeat the process until we find s that results in an error of at most 1/3.
",6. Experiments,[0],[0]
"We choose our input distributions to be the informationtheoretically hardest distributions to distinguish in the nonprivate setting (Batu et al., 2013; Chan et al., 2014).",6. Experiments,[0],[0]
"In particular, p is defined to be the distribution such that n2/3 of the domain elements have probability (1 ✏/2)/n2/3 (the “heavy elements”) and n/4 “light” elements have probability 2✏/n.",6. Experiments,[0],[0]
(The rest of the domain elements have mass 0.),6. Experiments,[0],[0]
"Similarly, q is defined to be be a distribution that has probability (1 ✏/2)/n2/3 on the same set of heavy elements as p, and for a disjoint set of n/4 light elements assigns probability 2✏/n.",6. Experiments,[0],[0]
"Since the light elements are disjoint, it is clear that p is ✏-far from q.
To evaluate the sample complexity of our algorithm, we use the tester to distinguish the following pairs: (q, q) and (p, q).
",6. Experiments,[0],[0]
"We set ✏ = 0.3, r = 200, and ⇠ = 0.2.",6. Experiments,[0],[0]
"We calculate the required number of samples of this tester in order to achieve accuracy at least 2/3, for n raging from 104 up to 2⇥ 106, increasing n by 104 at each step.
",6. Experiments,[0],[0]
"As a point of comparison, we also implemented the nonprivate equivalence tester of (Chan et al., 2014).",6. Experiments,[0],[0]
"As shown in Figure 5, the sample complexities of private and non-private equivalence testing are very close to each other.",6. Experiments,[0],[0]
"This result was expected given the theoretical sample complexity of our equivalence tester, since the dependence on the privacy parameter ⇠ appears in an additive term, and is dominated by the other term, when ⇠ is a constant.",6. Experiments,[0],[0]
M.A. and R.R. were supported by the National Science Foundation Award under Grant No.,Acknowledgements,[0],[0]
"CCF-1733808, CCF1650733, and IIS-1741137.",Acknowledgements,[0],[0]
"In addition, R.R. was supported by National Science Foundation Award under Grant No. CCF-1740751, and ISF grant 1536/14. I.D. was supported by National Science Foundation Award",Acknowledgements,[0],[0]
No. CCF-1652862 (CAREER) and a Sloan Research Fellowship.,Acknowledgements,[0],[0]
We study the fundamental problems of identity and equivalence testing over a discrete population from random samples.,abstractText,[0],[0]
Our goal is to develop efficient testers while guaranteeing differential privacy to the individuals of the population.,abstractText,[0],[0]
We provide sample-efficient differentially private testers for these problems.,abstractText,[0],[0]
"Our theoretical results significantly improve over the best known algorithms for identity testing, and are the first results for private equivalence testing.",abstractText,[0],[0]
The conceptual message of our work is that there exist private hypothesis testers that are nearly as sample-efficient as their non-private counterparts.,abstractText,[0],[0]
We perform an experimental evaluation of our algorithms on synthetic data.,abstractText,[0],[0]
Our experiments illustrate that our private testers achieve small type I and type II errors with sample size sublinear in the domain size of the underlying distributions.,abstractText,[0],[0]
Differentially Private Identity and Equivalence Testing of Discrete Distributions,title,[0],[0]
Graphical models are a central tool in probabilistic modeling and machine learning.,1. Introduction,[0],[0]
They pair expressive probability models with algorithms that leverage the graphical structure for efficient inference and learning.,1. Introduction,[0],[0]
"However, with data collection and modeling growing in importance in nearly all domains of society, there is increasing demand to apply graphical models in settings where the underlying data is sensitive and must be kept private.",1. Introduction,[0],[0]
"For example, consider applying graphical models to analyze electronic health records, with the goal of guiding public health policy.",1. Introduction,[0],[0]
"How can we derive these useful population-level outcomes without compromising the privacy of individuals?
1University of Massachusetts Amherst 2Mount Holyoke College 3Colgate University.",1. Introduction,[0],[0]
"Correspondence to: Garrett Bernstein <gbernstein@cs.umass.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Differential privacy is a widely studied formalism for private data analysis (Dwork et al., 2006).",1. Introduction,[0],[0]
It provides a statistical privacy guarantee to individuals: the output of a differentially private algorithm is statistically nearly unchanged even if any single individual’s record is added to or removed from the input data set.,1. Introduction,[0],[0]
"The general idea is to carefully randomize the algorithm so that the (random) output does not depend too much on any individual’s data.
",1. Introduction,[0],[0]
Differentially private machine learning cleanly addresses the problem of extracting useful population-level models from data sets while protecting the privacy of individuals.,1. Introduction,[0],[0]
"Indeed, this is an active and important research area (see Section 1.1), which includes private learning algorithms for a variety of general frameworks and specific machine learning models.",1. Introduction,[0],[0]
"This paper addresses the problem of privately learning parameters in a widely used class of probabilistic models: discrete, undirected graphical models.",1. Introduction,[0],[0]
"Although our problem can be cast in terms of general private learning frameworks, these do not lead to practical algorithms.",1. Introduction,[0],[0]
"Previous work also addresses private learning for directed graphical models (J. Zhang et al., 2014; Z. Zhang et al., 2016).",1. Introduction,[0],[0]
"Our problem of learning in undirected models, which are not locally normalized, is more general and substantially harder computationally.
",1. Introduction,[0],[0]
"To learn accurate models under differential privacy, it is critical to randomize the algorithm “just enough” to achieve the desired privacy guarantee without diminishing the quality of the learned model too much.",1. Introduction,[0],[0]
"This is usually done by modifying a learning algorithm to add noise to some intermediate quantity X , with the noise magnitude calibrated to the sensitivity of X , a measure of how much X can depend on any single individual’s data in the worst case (Dwork et al., 2006).",1. Introduction,[0],[0]
"The randomization renders the noisy estimate of X safe for release; all subsequent calculations using the noisy X , but not the original data, are also safe.",1. Introduction,[0],[0]
Where should noise be injected into a machine learning algorithm to achieve the best utility?,1. Introduction,[0],[0]
"We highlight two highlevel goals: (1) Noise should be added at an “information bottleneck”, so the sensitivity is as small as possible relative to the information being sought,1 (2) noise should be
1Sensitivity scales with the number of measurements; all else equal, a lower dimensional quantity will have lower sensitivity.
",1. Introduction,[0],[0]
"added to a quantity for which the sensitivity can be bounded tightly, so the noise magnitude can be kept as small as possible.",1. Introduction,[0],[0]
These two principles are often at odds.,1. Introduction,[0],[0]
"For example, adding noise to the final learned parameters θ (known as output perturbation; Dwork et al., 2006), is appealing from the information bottleneck standpoint, but if the learning algorithm is complex we may not be able to analyze the sensitivity and would have to rely on a coarse bound.",1. Introduction,[0],[0]
"Indeed, general private learning frameworks bound the sensitivity using quantities such as Lipschitz, strong-convexity, and smoothness constants (Bassily et al., 2014; Wu et al., 2016) or diameter of the parameter space (Smith, 2008), which may be loose in practice.
",1. Introduction,[0],[0]
"In this paper we will take the approach of adding noise to the sufficient statistics of a graphical model using the Laplace mechanism, a high-level approach that has also been applied recently for directed models (Zhang et al., 2016; Foulds et al., 2016).",1. Introduction,[0],[0]
This has a number of advantages.,1. Introduction,[0],[0]
"First, sufficient statistics, by definition, are an information bottleneck.",1. Introduction,[0],[0]
"Second, it is very easy to exactly analyze the sensitivity of sufficient statistics in graphical models, which are contingency tables.",1. Introduction,[0],[0]
"Third, adding Laplace noise to contingency tables prior to release is very simple, so it is reasonable to imagine adoption in practice, say, by public agencies.
",1. Introduction,[0],[0]
"However, it is not entirely clear how to learn parameters of a graphical model with noisy sufficient statistics.",1. Introduction,[0],[0]
"One option, which we will refer to as naive MLE, is to ignore the noise and conduct maximum-likelihood estimation as if we had true sufficient statistics.",1. Introduction,[0],[0]
"This works reasonably well in practice, and is competitive with or better than stateof-the-art general-purpose methods.",1. Introduction,[0],[0]
"In fact, we will show that naive MLE is consistent and achieves the same asymptotic mean-squared error as non-private MLE.",1. Introduction,[0],[0]
"However, at reasonable sample sizes the error due to privacy is significant, and the approach has several pathologies (see also Yang et al., 2012; Karwa et al., 2014; 2016), some of which make it difficult to apply in practice.",1. Introduction,[0],[0]
"Therefore, we adopt a more principled approach of performing inference about the true sufficient statistics within an expectationmaximization (EM) learning framework.
",1. Introduction,[0],[0]
The remaining problem is how to conduct inference over sufficient statistics of a graphical model given noisy observations thereof.,1. Introduction,[0],[0]
"This is exactly the goal of inference in collective graphical models (CGMs; Sheldon & Dietterich, 2011), and we will adapt CGM inference techniques to solve this problem.",1. Introduction,[0],[0]
"Put together, our results significantly advance the state-of-the-art for privately learning discrete, undirected graphical models.",1. Introduction,[0],[0]
We clarify the theory and practice of naive MLE.,1. Introduction,[0],[0]
"We show that it learns better models than existing state-of-the-art approaches in most scenarios across a broad range of synthetic tasks, and in experiments
modeling human mobility from wifi access point data.",1. Introduction,[0],[0]
We then show the more principled approach of conducting inference with CGMs is superior to competing approaches in nearly all scenarios.,1. Introduction,[0],[0]
"Differential privacy has been applied to many areas of machine learning, including learning specific models such as logistic regression (Chaudhuri & Monteleoni, 2009), support vector machines (Rubinstein et al., 2009), and deep neural networks (Abadi et al., 2016); privacy in general frameworks such as empirical risk minimization (ERM; Chaudhuri et al., 2011; Kifer et al., 2012; Jain & Thakurta, 2013; Bassily et al., 2014), gradient descent (Wu et al., 2016), and parameter estimation (Smith, 2011); and theoretical analysis of what can be learned privately (e.g., Blum et al., 2005; Kasiviswanathan et al., 2011).
",1.1. Related Work,[0],[0]
A key aspect of our work is conducting probabilistic inference over data or model parameters given knowledge of the probabilistic privacy mechanism and its output.,1.1. Related Work,[0],[0]
"Karwa et al. (2014; 2016) take a similar approach but for exponential random graph models, as do Williams & McSherry (2010), but for the factored exponential mechanism.",1.1. Related Work,[0],[0]
"Because sufficient statistics of graphical models are contingency tables, our work connects to the well-studied problem of releasing differentially private contingency tables (Barak et al., 2007; Yang et al., 2012; Hardt et al., 2012); we adopt the Laplace mechanism because it is simple and fits well within our learning framework.
",1.1. Related Work,[0],[0]
We highlight connections between CGMs and differential privacy and adopt existing inference techniques for CGMs.,1.1. Related Work,[0],[0]
"In general, the inference problems we wish to solve are NP-hard (Sheldon et al., 2013), but a number of efficient approximate inference algorithms are available (Liu et al., 2014; Sun et al., 2015; Vilnis et al., 2015).",1.1. Related Work,[0],[0]
"In a paper that was primarily about CGM inference, Sun et al. (2015) conducted a case study using CGMs to privately learn Markov chains; we build on this approach, which was limited in scope and did not address general graph structures.
",1.1. Related Work,[0],[0]
"Our work connects to an active current line of work on private probabilistic inference, some of which directly addresses learning in directed graphical models, but not the more challenging problem of learning in undirected graphical models.",1.1. Related Work,[0],[0]
"Several closely related approaches, which we refer to as One Posterior Sampling (OPS), show that a single sample drawn from a posterior distribution is differentially private (Dimitrakakis et al., 2014; Wang et al., 2015; Zhang et al., 2016).",1.1. Related Work,[0],[0]
"This can be understood as applying the exponential mechanism to the log-likelihood function, and can provide a point estimate for graphical model parameters (Zhang et al., 2016).",1.1. Related Work,[0],[0]
"To apply OPS, one must sample from the posterior over parameters, p(Θ|X), which is
straightforward for directed graphical models with conjugate priors, but not in undirected models, where posteriors over parameters are usually intractable.",1.1. Related Work,[0],[0]
Zhang et al. (2016) and Foulds et al. (2016) also developed fully Bayesian methods using Laplace noise-corrupted sufficient statistics to update posterior parameters.,1.1. Related Work,[0],[0]
"Similar considerations apply to this approach, which matches ours in that it uses the same data release mechanism, but, like OPS, requires conjugate priors and thus easily applies only to directed graphical models.",1.1. Related Work,[0],[0]
"Wang et al. (2015) also describe MCMC approaches to draw many private samples from a posterior distribution; this is another general framework that could apply to our problem, but, it relies on loose sensitivity bounds and since we only request point estimates, it would waste privacy budget by drawing many samples.",1.1. Related Work,[0],[0]
We consider data sets consisting of T discrete attributes associated with each individual.,2. Background and Problem Statement,[0],[0]
Let xt ∈ X denote the value of the tth attribute of an individual; we assume for simplicity of notation that all variables take values in the same finite set X .,2. Background and Problem Statement,[0],[0]
"Let x = (x1, . . .",2. Background and Problem Statement,[0],[0]
", xT ) denote the complete vector of attributes for an individual, and let X = (x(1),x(2), . . .",2. Background and Problem Statement,[0],[0]
",x(N)) denote a data set for an entire population of N individuals.",2. Background and Problem Statement,[0],[0]
Differential privacy offers strong privacy protection by imposing constraints on any algorithm that computes on the private dataset.,2.1. Differential Privacy,[0],[0]
"Informally, it requires that an individual’s data has a bounded effect on the algorithm’s behavior.",2.1. Differential Privacy,[0],[0]
The formal definition requires reasoning about all pairs of datasets that are otherwise identical except one dataset contains one additional individual’s data vector.,2.1. Differential Privacy,[0],[0]
"Let nbrs(X) denote the set of datasets that differ from X by at most one individual’s vector—i.e., if X′ ∈ nbrs(X), then X′ =",2.1. Differential Privacy,[0],[0]
"(x(1), . . .",2.1. Differential Privacy,[0],[0]
",x(i−1),x(i+1), . . .",2.1. Differential Privacy,[0],[0]
",x(n))",2.1. Differential Privacy,[0],[0]
"for some i or X′ = (x(1), . . .",2.1. Differential Privacy,[0],[0]
",x(i),x′,x(i+1), . . .",2.1. Differential Privacy,[0],[0]
",x(n))",2.1. Differential Privacy,[0],[0]
for some i and some x′ ∈ X T .,2.1. Differential Privacy,[0],[0]
"Definition 1 (Differential Privacy; Dwork et al., 2006).",2.1. Differential Privacy,[0],[0]
"A randomized algorithmA satisfies ( , δ)-differential privacy if for any input X, any X′ ∈ nbrs(X) and any subset of outputs S ⊆ Range(A),
Pr[A(X) ∈",2.1. Differential Privacy,[0],[0]
"S] ≤ exp( )Pr[A(X′) ∈ S] + δ.
",2.1. Differential Privacy,[0],[0]
"When δ = 0, we say that the algorithm satisfies - differential privacy.",2.1. Differential Privacy,[0],[0]
"All of the algorithms we propose satisfy -differential privacy but we compare against some algorithms that satisfy the weaker condition of ( , δ)differential privacy with non-zero δ.
",2.1. Differential Privacy,[0],[0]
"We achieve differential privacy by injecting noise into the
statistics that are computed on the data.",2.1. Differential Privacy,[0],[0]
Let f be any function that maps datasets to Rd.,2.1. Differential Privacy,[0],[0]
"The amount of noise depends on the sensitivity of f .
",2.1. Differential Privacy,[0],[0]
Definition 2 (Sensitivity).,2.1. Differential Privacy,[0],[0]
"The sensitivity of a function f is defined as ∆f = maxX LSf (X) where LSf denotes the local sensitivity of f on input X and is defined as LSf (X) = maxX′∈nbrs(X) ‖f(X)− f(X′)‖1.
",2.1. Differential Privacy,[0],[0]
"We drop the subscript f when it is clear from context.
",2.1. Differential Privacy,[0],[0]
"Our approach achieves differential privacy through the application of the Laplace mechanism.
",2.1. Differential Privacy,[0],[0]
"Definition 3 (Laplace Mechanism; Dwork et al., 2006).",2.1. Differential Privacy,[0],[0]
"Given function f that maps datasets to Rd, the Laplace mechanism is defined as L(X) = f(X) + z",2.1. Differential Privacy,[0],[0]
"where z = (z1, . . .",2.1. Differential Privacy,[0],[0]
", zd) and each zi is an i.i.d. random variable from Laplace(∆f/ ).
",2.1. Differential Privacy,[0],[0]
"An important property of differential privacy is that any additional post-processing on the output cannot weaken the privacy guarantee.
",2.1. Differential Privacy,[0],[0]
"Proposition 1 (Post-processing; Dwork & Roth, 2014).",2.1. Differential Privacy,[0],[0]
"Let A be an ( , δ)-differentially private algorithm that maps datasets to Rd and let g : Rd → Rd′ be an arbitrary function.",2.1. Differential Privacy,[0],[0]
Then g ◦,2.1. Differential Privacy,[0],[0]
"A is also ( , δ)-differentially private.",2.1. Differential Privacy,[0],[0]
Our goal is to learn a probabilistic model p(x) from the data set X while protecting the privacy of individuals.,2.2. Problem Statement,[0],[0]
"We will learn probability distributions p(x) that are undirected discrete graphical models (also called Markov random fields; Koller & Friedman, 2009).",2.2. Problem Statement,[0],[0]
"These are defined by a set of local potential functions of the form ψC(xC), where C ⊆ {1, . . .",2.2. Problem Statement,[0],[0]
", T} is an index set or clique, xC is a subvector of x corresponding to C, and ψC : X |C| → R+ assigns a potential value to each possible xC .",2.2. Problem Statement,[0],[0]
"The probability model is p(x) = 1Z ∏ C∈C ψC(xC) where C is the
collection of cliques that appear in the model, and Z =∑ x ∏ C∈C ψC(xC) is the normalizing constant or partition function.",2.2. Problem Statement,[0],[0]
"The graph G with node set V = {1, . . .",2.2. Problem Statement,[0],[0]
", T} and edges between any two indices that co-occur in some C ∈ C is the independence graph of the model; therefore, each index set C is a clique in G.
For learning, it is most convenient to express the model in log-linear or exponential family form as:
p(x;θ) = exp {∑ C∈C ∑ iC∈X |C| I{xC = iC}θC(iC)−A(θ) } .",2.2. Problem Statement,[0],[0]
"(1) In this expression: I{·} is an indicator function; the variable iC ∈ X |C| denotes a particular setting of the variables xC ; the parameters θC(iC) = logψC(iC) are logpotential values; the vector θ ∈ Rd is the concatenation of
all parameters; and A(θ) = logZ(θ) is the log-partition function, with the dependence of Z on the parameters now made explicit.",2.2. Problem Statement,[0],[0]
"Note that, for any θ ∈ Rd, the density is strictly positive: p(x;θ) > 0",2.2. Problem Statement,[0],[0]
for all x.,2.2. Problem Statement,[0],[0]
"This is true because the potential values ψC(iC) are strictly positive, so the log-potentials are finite.
",2.2. Problem Statement,[0],[0]
The goal is to learn parameters θ̂ from the data X in a way that is -differentially private and such that p(x; θ̂) is as accurate as possible.,2.2. Problem Statement,[0],[0]
"We will measure accuracy as KullbackLeibler divergence from an appropriate reference distribution (Kullback & Leibler, 1951).",2.2. Problem Statement,[0],[0]
"In synthetic experiments, we will measure the divergence D ( p(·;θ)‖p(·; θ̂) ) , where p(x;θ) is the true density.",2.2. Problem Statement,[0],[0]
"For real data, we will measure the holdout log-likelihood Eq [ log p(x; θ̂) ] where q is the empirical distribution of the holdout data, which is equal to a constant minus D ( q‖p(·; θ̂) ) .
",2.2. Problem Statement,[0],[0]
"The problem of privately selecting which cliques to include in the model (i.e., model selection or structure learning) is interesting but not considered in this paper; we assume the cliques C are fixed in advance by the modeler.",2.2. Problem Statement,[0],[0]
"To develop our approach to privately learn graphical model parameters, we first discuss standard concepts related to maximum-likelihood estimation for graphical models.
",3. Approach,[0],[0]
"Log-Likelihood, Sufficient Statistics, Marginals.",3. Approach,[0],[0]
From Eq.,3. Approach,[0],[0]
"(1), the log-likelihood L(θ) = log ∏N i=1",3. Approach,[0],[0]
p,3. Approach,[0],[0]
"( x(i);θ ) of the entire data set can be written as
L(θ) =",3. Approach,[0],[0]
"[∑ C∈C ∑ iC∈X |C| nC(iC)θC(iC) ] −NA(θ)
where nC(iC) = ∑N i=1",3. Approach,[0],[0]
I{x (i) C = iC} is a count of how many times the configuration iC for the variables in clique C appears in the population.,3. Approach,[0],[0]
The collection of counts nC = ( nC(iC) ) for all possible iC is the (population) contingency table on clique C.,3. Approach,[0],[0]
Let n denote the vector concatenation of the contingency tables for all cliques.,3. Approach,[0],[0]
"Then we can rewrite the log-likelihood more compactly as
L(θ) = f(n,θ) := θTn−NA(θ) (2)
The most common approach for parameter learning in graphical models is maximum likelihood estimation: find the parameters θ̂ that maximizeL(θ).",3. Approach,[0],[0]
The resulting parameter vector θ̂ is a maximum-likelihood estimator (MLE).,3. Approach,[0],[0]
It is clear from Eq.,3. Approach,[0],[0]
(2) that this problem depends on the data only through the contingency tables n.,3. Approach,[0],[0]
"Indeed, the clique contingency tables n are sufficient statistics of the model: they measure all of the information from the data set X that is relevant for estimating the parameter θ (Fisher, 1922).
",3. Approach,[0],[0]
"The algorithmic approach for maximum-likelihood estimation in graphical models is standard (Koller & Friedman, 2009), and we do not repeat the details here.",3. Approach,[0],[0]
"However, there are a few concepts that are important for our development.",3. Approach,[0],[0]
The marginals of a graphical model are the marginal probabilities µC(iC) = p(xC = iC ;θ) for all cliques C and configurations iC .,3. Approach,[0],[0]
"Let µ be the vector concatenation of all marginals, and note that µ = Eθ[n]/N .",3. Approach,[0],[0]
"Similarly, let µ̂ = n/N be the data marginals—these are marginal probabilities of the empirical distribution of the data.
",3. Approach,[0],[0]
Marginals play a fundamental role in estimation.,3. Approach,[0],[0]
"First, note that we can divide Eq.",3. Approach,[0],[0]
(2) by N to see that the MLE only depends on the data through the data marginals µ̂.,3. Approach,[0],[0]
"However, we leave L(θ) in the current form because it is more convenient for the CGM development in Section 3.2.",3. Approach,[0],[0]
"Second, it is well known that ∇θL(θ) =",3. Approach,[0],[0]
"N(µ̂ − µ), so maximum likelihood estimation seeks to adjust θ so that the data and model marginals match.",3. Approach,[0],[0]
"Third, it can (almost) always succeed in doing so, even if the data marginals do not come from a graphical model.",3. Approach,[0],[0]
"More formally, letM be the marginal polytope: the set of all vectors µ such that there exists some distribution q(x) with marginal probabilities µ.
Proposition 2 (Wainwright & Jordan, 2008).",3. Approach,[0],[0]
"For any µ in the interior ofM, there is a unique distribution p(x;θ) with marginals µ, i.e., such that µ = Eθ[n]/N .
",3. Approach,[0],[0]
"Applying Proposition 2 to the data marginals µ̂ shows that if these belong to the interior of M, we may learn a distribution with marginals that match what we observe in the data.",3. Approach,[0],[0]
"Note that, while the distribution p(x;θ) is unique, the parameters θ are not, because our model is overcomplete.",3. Approach,[0],[0]
"If µ belongs toM but not the interior ofM, which occurs, for example, when some marginals are zero, the situation is more complex: there is no (finite) θ ∈ Rd such that p(x;θ) has marginals µ.2 Similarly, the MLE does not exist, meaning that its maximum is not attained for any finite θ (Fienberg & Rinaldo, 2012; Haberman, 1973).",3. Approach,[0],[0]
This issue will end up being significant in our understanding of the naive MLE approach in the following section.,3. Approach,[0],[0]
"From the development so far, there are two obvious possibilities for randomizing the learning process to achieve privacy:
1.",3.1. Noisy sufficient statistics,[0],[0]
"(Output perturbation) Find the MLE θ̂ and add Laplace noise proportional to its sensitivity.
2.",3.1. Noisy sufficient statistics,[0],[0]
(Sufficient statistics perturbation),3.1. Noisy sufficient statistics,[0],[0]
"Add Laplace noise to the sufficient statistics n, and then conduct maximumlikelihood estimation.",3.1. Noisy sufficient statistics,[0],[0]
"2However, there is a sequence {θk} where θk ∈ Rd and lim k→∞",3.1. Noisy sufficient statistics,[0],[0]
"Eθk [n]/N = µ.
",3.1. Noisy sufficient statistics,[0],[0]
The two approaches are similar from an information bottleneck standpoint—the dimensionality of n and θ̂ is the same.,3.1. Noisy sufficient statistics,[0],[0]
"However, the sensitivity of θ̂ is difficult to analyze, since it requires reasoning about worst-case inputs.",3.1. Noisy sufficient statistics,[0],[0]
It also may be high due to pathological inputs whose local sensitivity is much higher than that of realistic data sets.,3.1. Noisy sufficient statistics,[0],[0]
"On the other hand, the sensitivity of n is very easy to analyze and the analysis is tight: the local sensitivity is the same for all data sets.
",3.1. Noisy sufficient statistics,[0],[0]
Proposition 3.,3.1. Noisy sufficient statistics,[0],[0]
"Let n(X) be the sufficient statistics of a graphical model with clique set C on data set X. The local sensitivity of n is |C| for all inputs X. Therefore the sensitivity of n is |C|.
(Proofs can be found in the supplementary material.)",3.1. Noisy sufficient statistics,[0],[0]
"So, a simple approach to achieve privacy is to release noisy sufficient statistics y that are obtained after applying the Laplace mechanism:
yC(iC) = nC(iC) +",3.1. Noisy sufficient statistics,[0],[0]
"Laplace ( |C|/ ) (3)
",3.1. Noisy sufficient statistics,[0],[0]
Positive results.,3.1. Noisy sufficient statistics,[0],[0]
How can we learn with noisy sufficient statistics y?,3.1. Noisy sufficient statistics,[0],[0]
"A naive approach is to use y in place of n in maximum-likelihood estimation, i.e., to find θ̂ to maximize f(y,θ).",3.1. Noisy sufficient statistics,[0],[0]
"The validity of this approach has been debated in the literature (Yang et al., 2012).",3.1. Noisy sufficient statistics,[0],[0]
"However, it is relatively easy to show that it behaves well asymptotically.
",3.1. Noisy sufficient statistics,[0],[0]
Proposition 4.,3.1. Noisy sufficient statistics,[0],[0]
"Assume x(1), . . .",3.1. Noisy sufficient statistics,[0],[0]
",x(N) are drawn iid from a probability distribution with marginals µ.",3.1. Noisy sufficient statistics,[0],[0]
"The marginal estimate µ̄C(iC) = 1N yC(iC) obtained from the noisy sufficient statistics is unbiased and consistent, with mean squared error:
MSE ( µ̄C(iC) )",3.1. Noisy sufficient statistics,[0],[0]
"= µC(iC)
( 1− µC(iC) )",3.1. Noisy sufficient statistics,[0],[0]
N + 2|C|2,3.1. Noisy sufficient statistics,[0],[0]
"N2 2 (4)
Now let θ̂ ∈ argmaxθ f(y,θ) be parameters estimated using the noisy sufficient statistics y.",3.1. Noisy sufficient statistics,[0],[0]
"If the true distribution p(x;θ) is a graphical model with cliques C, then the estimated distribution p(x; θ̂) converges to p(x;θ).
Pathologies.",3.1. Noisy sufficient statistics,[0],[0]
"Asymptotically, the noisy sufficient statistics behave as desired in terms of MSE: the O(1/N) term, which is due to sampling error and not privacy, dominates for large N .",3.1. Noisy sufficient statistics,[0],[0]
"However, for practical settings of the O(1/N2) term, which is due to privacy, is dominant until N becomes very large, due to the large constant 2|C|2/ 2.",3.1. Noisy sufficient statistics,[0],[0]
"Figure 1(a) illustrates this issue.
",3.1. Noisy sufficient statistics,[0],[0]
A second pathology is that the noise added for privacy destroys some of the structure expected in the empirical marginals.,3.1. Noisy sufficient statistics,[0],[0]
"The true data marginals µ̂ = n/N belong to the marginal polytope: in particular, this means that each clique marginal µ̂C is nonnegative and sums to one, and
that clique marginals agree on common subsets of variables.",3.1. Noisy sufficient statistics,[0],[0]
"After adding noise, the pseudo-marginals µ̄ = y/N do not belong to the marginal polytope: µ̄ may have negative values, and does not satisfy consistency constraints.",3.1. Noisy sufficient statistics,[0],[0]
"We find that a partial fix is very helpful empirically: project the pseudo-marginal µ̄C for each clique onto the simplex prior to conducting MLE, which can be done via a standard procedure (Duchi et al., 2008).",3.1. Noisy sufficient statistics,[0],[0]
Let µ̃ be the projected marginals.,3.1. Noisy sufficient statistics,[0],[0]
"We now have that µ̃C is a valid marginal for each clique C, but consistency constraints are not satisfied among cliques, and it is still the case that µ̃ /∈",3.1. Noisy sufficient statistics,[0],[0]
"M. Figure 1(b) illustrates the benefits of projection on the quality of the model learned by Naive MLE.
",3.1. Noisy sufficient statistics,[0],[0]
"A more significant pathology has to do with zeros in the projected marginals µ̃, which are more prevalent than in true data marginals µ̂.",3.1. Noisy sufficient statistics,[0],[0]
"This is because the addition of Laplace noise creates negative values, which are then truncated to zero during projection.",3.1. Noisy sufficient statistics,[0],[0]
"As discussed following Proposition 2, zero values in the marginals lead to nonexistence of the MLE (Fienberg & Rinaldo, 2012; Haberman, 1973).",3.1. Noisy sufficient statistics,[0],[0]
"If µ̃C(iC) = 0, the likelihood increases monotonically as θC(iC) goes to negative infinity; in other words, the model attempts to drive the learned marginal probability to zero.",3.1. Noisy sufficient statistics,[0],[0]
"Numerically, we can address this by regularization, e.g., adding λ‖θ‖2 to the objective function for arbitrarily small λ > 0.",3.1. Noisy sufficient statistics,[0],[0]
"However, we may still learn vanishingly small marginal probabilities, which can lead to a very large KL-divergence between the true and learned models.",3.1. Noisy sufficient statistics,[0],[0]
Figure 1(c) illustrates the effect of λ on KL-divergence with both noisy sufficient statistics and true sufficient statistics.,3.1. Noisy sufficient statistics,[0],[0]
"At high λ (strong regularization), both methods underfit and yield poor KL divergence.",3.1. Noisy sufficient statistics,[0],[0]
Learning with true sufficient statistics has no tendency to overfit; it achieves good performance for a broad range of λ approaching zero.,3.1. Noisy sufficient statistics,[0],[0]
"Naive MLE with noisy sufficient statistics overfits badly (to zeros) for small λ, and must be tuned “just right” to achieve reasonable performance.",3.1. Noisy sufficient statistics,[0],[0]
"Since learning with noisy sufficient statistics “as-is” has several pathologies and is less robust than maximumlikelihood estimation in the absence of privacy, we investigate a more principled approach, which matches the data generating process: We treat the true sufficient statistics n as latent variables, and learn θ to maximize the marginal likelihood p(y;θ) = ∑ n p(n,y;θ).",3.2. Collective Graphical Models,[0],[0]
"In this section, we will develop an EM approach to accomplish this.
",3.2. Collective Graphical Models,[0],[0]
"In EM, we need to conduct inference to compute E[n |y;θ] for a fixed value of θ.",3.2. Collective Graphical Models,[0],[0]
"This is the central problem of collective graphical models (CGMs) (Sheldon & Dietterich, 2011).",3.2. Collective Graphical Models,[0],[0]
"Consider the joint distribution p(n,y;θ) = p(n;θ)p(y |n), which we use to compute E[n |y;θ].",3.2. Collective Graphical Models,[0],[0]
"The
noise mechanism p(y |n) arises directly from the Laplace mechanism (see Eq.",3.2. Collective Graphical Models,[0],[0]
(3)).,3.2. Collective Graphical Models,[0],[0]
"The distribution of the sufficient statistics, p(n;θ), is known as the CGM distribution.",3.2. Collective Graphical Models,[0],[0]
"It can be written in closed form when the model is decomposable, i.e., the cliques C correspond to the nodes of some junction tree T .",3.2. Collective Graphical Models,[0],[0]
"Although decomposability is a significant restriction, let us assume that such a tree T exists; we will use the exact results derived for this case to develop an approximation for the general case.",3.2. Collective Graphical Models,[0],[0]
"Let S be the set of separators of T , and let ν(S) be the multiplicity of S ∈ S , i.e., the number of distinct edges (Ci, Cj) ∈ T for which S = Ci ∩Cj .",3.2. Collective Graphical Models,[0],[0]
"Under these assumptions, the CGM distribution has the form (Liu et al., 2014):
p(n;θ) = h(n) · exp ( f(n,θ) ) ,
h(n) = N !",3.2. Collective Graphical Models,[0],[0]
"·
∏ S∈S ∏ iS∈X |S| ( nS(iS)! )",3.2. Collective Graphical Models,[0],[0]
ν(S) ∏ C∈C ∏ iC∈X |C| nC(iC)! ·,3.2. Collective Graphical Models,[0],[0]
"I{n ∈MZN}
The term exp ( f(n,θ) ) is the probability of an ordered data set X with sufficient statistics n, as discussed previously.",3.2. Collective Graphical Models,[0],[0]
"The term h(n) is a base measure that counts the number of ordered data sets with sufficient statistics equal to n, and enforces constraints on n.",3.2. Collective Graphical Models,[0],[0]
"The integer-valued marginal polytopeMZN is the set of all vectors n that are sufficient statistics of some data set X of size N .
",3.2. Collective Graphical Models,[0],[0]
"Exact inference in CGMs is intractable (Sheldon et al., 2013).",3.2. Collective Graphical Models,[0],[0]
"Therefore, it is typical to relax the integrality constraint and apply Stirling’s approximation: log n!",3.2. Collective Graphical Models,[0],[0]
≈ n log n,3.2. Collective Graphical Models,[0],[0]
"− n. Let MN be the feasible set with the integrality constraint removed, which is now just the standard marginal polytope scaled so that each marginal sums to N instead of one.
",3.2. Collective Graphical Models,[0],[0]
Proposition 5 (Sun et al.;,3.2. Collective Graphical Models,[0],[0]
"Nguyen et al., 2015; 2016).",3.2. Collective Graphical Models,[0],[0]
"For a decomposable CGM with junction tree T , the following
approximation of the CGM log-density for any n ∈MN is obtained by applying Stirling’s approximation:
log p(n,y;θ)",3.2. Collective Graphical Models,[0],[0]
≈ θTn−NA(θ)+H(n)+log p(y|n).,3.2. Collective Graphical Models,[0],[0]
"(5) Here, H(n) = −N ∑
x q(x) log q(x) is the entropy of the unique distribution q(x) = p(x;θ) in the graphical model family with marginals equal to n/N .
",3.2. Collective Graphical Models,[0],[0]
Proposition 5 is the basis for approximate MAP inference problem in CGMs: find n to maximize Eq.,3.2. Collective Graphical Models,[0],[0]
(5) and obtain an approximate mode of p(n |y;θ).,3.2. Collective Graphical Models,[0],[0]
"Even though our goal is to compute the mean E[n |y;θ], it has been shown that the approximate mode, which is also a real-valued vector, is an excellent approximation to the mean for use within the EM algorithm (Sheldon et al., 2013).",3.2. Collective Graphical Models,[0],[0]
"Note that for non-decomposable models, we will simply apply the same approximation as in Proposition 5, even though an exact expression for the counting measure h(n), and therefore the correspondence of log h(n) to an entropy H(n), is not known in this case.",3.2. Collective Graphical Models,[0],[0]
"Then, after dropping the term NA(θ) from Proposition 5, which is constant with respect to n, the approximate MAP problem can be rewritten as:
n∗ ∈ argmax n∈MN θTn +H(n) + log p(y |n) (6)
",3.2. Collective Graphical Models,[0],[0]
"This equation reveals a close connection to variational principles for graphical models (Wainwright & Jordan, 2008).",3.2. Collective Graphical Models,[0],[0]
"It is identical to the variational optimization problem for marginal inference in standard graphical models, except the objective has an additional term log p(y|n), which is nonlinear in n. Several message-passing based algorithms have been developed to efficiently solve the approximate MAP problem.",3.2. Collective Graphical Models,[0],[0]
"For trees or junction trees, Problem (6) is convex as long as log p(y|n) is concave in n (which is true in most cases of interest, such as Laplace noise) so it can be solved exactly (Sun et al., 2015; Vilnis et al., 2015).",3.2. Collective Graphical Models,[0],[0]
"For loopy models, both the entropy H(n) and the feasible set MN must be approximated (Nguyen et al., 2016).
",3.2. Collective Graphical Models,[0],[0]
"Algorithm 1 Non-Linear Belief Propagation (NLBP) Input: θ, y, damping parameter α > 0
",3.2. Collective Graphical Models,[0],[0]
while ¬ converged do θ′ ← θ +∇n log p(y |n) n′,3.2. Collective Graphical Models,[0],[0]
"← STANDARD-BP ( θ′ ) {Normalized to sum to N}
n← (1− α)n+ αn′
end while
Algorithm 2 EM for CGMs Input: Noisy sufficient statistics y
Initialize θ0 arbitrarily while ¬ converged do nt ← NLBP(θt,y) θt+1 ← argmaxθ θ
Tnt −NA(θ) end while
Algorithm 1 shows pseudocode non-linear belief propagation (NLBP; Sun et al., 2015), which we select as our primary inference approach due to its simplicity.",3.2. Collective Graphical Models,[0],[0]
"It is a thin wrapper around standard BP, and can be applied to trees, in which case it exactly solves Problem (6), or it can be applied to loopy graphs by using loopy BP (LBP) as the subroutine, in which case it is approximate.
",3.2. Collective Graphical Models,[0],[0]
Our final EM learning procedure is shown in Algorithm 2.,3.2. Collective Graphical Models,[0],[0]
"It alternates between inference steps that solve the approximate MAP problem to find nt ≈ E[n |y; θt], and optimization steps to re-estimate parameters given the inferred sufficient statistics nt.",3.2. Collective Graphical Models,[0],[0]
"See also (Sheldon et al., 2013; Liu et al., 2014; Sun et al., 2015).",3.2. Collective Graphical Models,[0],[0]
"We conduct a number of experiments on synthetic and real data to evaluate the quality of models learned by both Naive MLE and CGM.
Methods.",4. Experiments,[0],[0]
"We compare three algorithms: Naive MLE, CGM, and a version of private stochastic gradient descent (PSGD) due to Abadi et al. (2016).",4. Experiments,[0],[0]
"PSGD belongs to a class of general-purpose private learning algorithms that can be adapted to our problem, including gradient descent or stochastic gradient descent algorithms for empirical risk minimization (Chaudhuri et al., 2011; Kifer et al., 2012; Jain & Thakurta, 2013; Bassily et al., 2014; Abadi et al., 2016) and the subsample-and-aggregate approach for parameter estimation (Smith, 2011).",4. Experiments,[0],[0]
We chose PSGD because it is a state-of-the-art method and it significantly outperformed other approaches in preliminary experiments.,4. Experiments,[0],[0]
"However, note that PSGD satisfies only ( , δ)-differential privacy for δ > 0, which is a weaker privacy guarantee than -differential privacy.",4. Experiments,[0],[0]
"We tune PSGD using a grid search over all relevant parameters to ensure it performs as well as
possible.",4. Experiments,[0],[0]
We evaluate two types of pairwise graphical models: thirdorder chains with edges between two nodes i and j if 1 ≤ |i,4.1. Synthetic data,[0],[0]
"− j| ≤ 3, and (connected) Erdős-Réyni (ER) random graphs.",4.1. Synthetic data,[0],[0]
"We report results for graphs of 10 nodes, where potentials on each edge are drawn from a Dirichlet distribution with concentration parameter of one; results are similar for smaller and larger models, models with different structures, and for different types of potentials.",4.1. Synthetic data,[0],[0]
We vary data size N and privacy parameter .,4.1. Synthetic data,[0],[0]
"For each setting of model type, N , and , we conduct 25 trials.",4.1. Synthetic data,[0],[0]
"The trials are nested, with five random populations and five replications per population, i.e.: ni ∼ p(n),yi,j ∼ p(y |ni) for i ∈ {1, . . .",4.1. Synthetic data,[0],[0]
", 5}, j ∈ {1, . . .",4.1. Synthetic data,[0],[0]
", 5}.",4.1. Synthetic data,[0],[0]
"We measure the quality of learned models using KL divergence from the true distribution, and include for comparison two reference models: a random estimator and a non-private MLE estimator.",4.1. Synthetic data,[0],[0]
"The random estimator is obtained by randomly generating marginals µ̄ and then learning potentials via MLE.
Results.",4.1. Synthetic data,[0],[0]
"Figure 2 shows the results for the two models (top: third-order chain, bottom: ER) for different values of N and .",4.1. Synthetic data,[0],[0]
"CGM improves upon Naive MLE for all models, privacy levels, and population sizes.",4.1. Synthetic data,[0],[0]
"Recall that PSGD promises only ( , δ)-differential privacy.",4.1. Synthetic data,[0],[0]
"While δ is often assumed to be “cryptographically small”, e.g.,O(2−N ), we set δ to a relatively large value of δ = 1/N .",4.1. Synthetic data,[0],[0]
Increasing δ weakens the privacy guarantee but enables PGSD to run on a wider range of .,4.1. Synthetic data,[0],[0]
"However, even with this setting for δ, some of the smaller values of are not attainable by PGSD and are omitted from those plots.
",4.1. Synthetic data,[0],[0]
"Figure 3(a) shows a qualitative comparison of edge marginals of a single graph learned by the different methods, compared with the true model marginals; it is evident that CGM learns marginals that are much closer to both the true marginals and those learned by the non-private estimator than Naive MLE is able to learn.",4.1. Synthetic data,[0],[0]
"Naive MLE is the fastest method; CGM is approximately 4x/8x slower on third-order chains and ER graphs, respectively, and PSGD is approximately 27x/40x slower.",4.1. Synthetic data,[0],[0]
We study human mobility data in the form of connections to wifi access points throughout a highly-trafficked academic building over a twenty-one day period.,4.2. Wifi data,[0],[0]
"We treat each (user ID, day) combination as an “individual”, leading to 124,399 unique individuals; with this data preparation scheme, the unit of protection is one day’s worth of a user’s data.",4.2. Wifi data,[0],[0]
"We discretize time by recording the location every 10 minutes, and assign null if the user is not connected to the network.",4.2. Wifi data,[0],[0]
"Our probability model p(x) is a
pairwise graphical model over hour-long segments.",4.2. Wifi data,[0],[0]
"Therefore, we break each individual’s data into 24 one-hour long segments.
",4.2. Wifi data,[0],[0]
An individual now contributes 24 records to each contingency table for the model p(x).,4.2. Wifi data,[0],[0]
"Therefore, the sensitivity is now 24 times the number of edges (cliques).",4.2. Wifi data,[0],[0]
"However, real data is typically sparse—i.e., an individual is typically observed only a small number of times over the observation period.",4.2. Wifi data,[0],[0]
"Therefore, to reduce the sensitivity, the data is normalized prior to calculating sufficient statistics, in a fashion similar to (He et al., 2015).",4.2. Wifi data,[0],[0]
"Each user contributes a value of 1/K to each contingency table, where K is the number of edges (xs, xt) for which the user’s values are not both null.",4.2. Wifi data,[0],[0]
"With this pre-processing in place, the sensitivity equals the number of edges in the model.",4.2. Wifi data,[0],[0]
"A trade-off of
this technique is that we bias the model towards individuals with fewer transitions, but we reduce the amount of noise by limiting sensitivity caused by null–null transitions.
",4.2. Wifi data,[0],[0]
We reserve data from 25% of the individuals for testing.,4.2. Wifi data,[0],[0]
"To compare different approaches, we apply Naive MLE, CGM, and PSGD to privately learn parameters of a graphical model from the training set (75% of the data), with varying privacy levels.",4.2. Wifi data,[0],[0]
We then calculate holdout loglikelihood of the learned parameters on the test set.,4.2. Wifi data,[0],[0]
"We again include a non-private method for reference, but in this case, all methods perform better than the random estimator, so we do not show it.
",4.2. Wifi data,[0],[0]
"Figure 3(b) shows the results for fitting a timehomogeneous chain model (edges between adjacent time steps, every potential ψ(xt, xt+1) is the same, and the model includes a node potential φ(x1) so it can learn a time-stationary model).",4.2. Wifi data,[0],[0]
"As in the synthetic data experiments, CGM improves upon naive MLE across all parameter regimes, and performance improves with population size N and with weakening of privacy (larger ).",4.2. Wifi data,[0],[0]
Both methods outperform PSGD.,4.2. Wifi data,[0],[0]
"Naive MLE is the fastest method; CGM is approximately 15x slower, and PSGD is approximately 46x slower.",4.2. Wifi data,[0],[0]
"This material is based upon work supported by the National Science Foundation under Grant Nos. 1409125, 1409143, 1421325, and 1617533.",Acknowledgments,[0],[0]
"We investigate the problem of learning discrete, undirected graphical models in a differentially private way.",abstractText,[0],[0]
"We show that the approach of releasing noisy sufficient statistics using the Laplace mechanism achieves a good trade-off between privacy, utility, and practicality.",abstractText,[0],[0]
A naive learning algorithm that uses the noisy sufficient statistics “as is” outperforms general-purpose differentially private learning algorithms.,abstractText,[0],[0]
"However, it has three limitations: it ignores knowledge about the data generating process, rests on uncertain theoretical foundations, and exhibits certain pathologies.",abstractText,[0],[0]
We develop a more principled approach that applies the formalism of collective graphical models to perform inference over the true sufficient statistics within an expectationmaximization framework.,abstractText,[0],[0]
We show that this learns better models than competing approaches on both synthetic data and on real human mobility data used as a case study.,abstractText,[0],[0]
Differentially Private Learning of Undirected Graphical Models Using Collective Graphical Models,title,[0],[0]
"√ n randomly selected
items. Along the way, we provide an optimal differentially private algorithm for singular vector computation, based on the celebrated Oja’s method, that provides significant savings in terms of space and time while operating on sparse matrices. We also empirically evaluate our algorithm on a suite of datasets, and show that it consistently outperforms the state-of-the-art private algorithms.",text,[0],[0]
"Collaborative filtering (or matrix completion) is a popular approach for modeling the recommendation system problem, where the goal is to provide personalized recommendations about certain items to a user (Koren & Bell, 2015).",1. Introduction,[0],[0]
"In other words, the objective of a personalized recommendation system is to learn the entire users-items preference matrix Y ∗ ∈ <m×n using a small number of user-item preferences Y ∗ij , (i, j) ∈",1. Introduction,[0],[0]
[m] ×,1. Introduction,[0],[0]
"[n], where m is the number of users and n is the number of items.",1. Introduction,[0],[0]
"Naturally, in absence of any structure in Y ∗, the problem is ill-defined as the unknown entries of Y ∗ can be arbitrary.",1. Introduction,[0],[0]
"Hence, a popular modeling hypothesis is that the underlying preference matrix Y ∗ is low-rank, and thus, the collaborative filtering problem reduces to that of low-rank matrix com-
1Microsoft Research.",1. Introduction,[0],[0]
"Email: prajain@microsoft.com 2Department of Computer Science, Boston University.",1. Introduction,[0],[0]
"Email: omthkkr@bu.edu 3Computer Science Department, University of California Santa Cruz.",1. Introduction,[0],[0]
Email: aguhatha@ucsc.edu.,1. Introduction,[0],[0]
"Correspondence to: Om Thakkar <omthkkr@bu.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"pletion (Recht, 2011; Candes & Recht, 2012).",1. Introduction,[0],[0]
"One can also enhance this formulation using side-information like userfeatures or item-features (Yu et al., 2014).
",1. Introduction,[0],[0]
"Naturally, personalization problems require collecting and analyzing sensitive customer data like their preferences for various items, which can lead to serious privacy breaches (Korolova, 2010; Narayanan & Shmatikov, 2010; Calandrino et al., 2011).",1. Introduction,[0],[0]
"In this work, we attempt to address this problem of privacy-preserving recommendations using collaborative filtering (McSherry & Mironov, 2009; Liu et al., 2015).",1. Introduction,[0],[0]
"We answer the following question in the affirmative: Can we design a matrix completion algorithm which keeps all the ratings of a user private, i.e., guarantees userlevel privacy while still providing accurate recommendations?",1. Introduction,[0],[0]
"In particular, we provide the first differentially private (Dwork et al., 2006b) matrix completion algorithms with provable accuracy guarantees.",1. Introduction,[0],[0]
"Differential privacy (DP) is a rigorous privacy notion which formally protects the privacy of any user participating in a statistical computation by controlling her influence to the final output.
",1. Introduction,[0],[0]
"Most of the prior works on DP matrix completion (and lowrank approximation) (Blum et al., 2005; Chan et al., 2011; Hardt & Roth, 2012; 2013; Kapralov & Talwar, 2013; Dwork et al., 2014b) have provided guarantees which are non-trivial only in the entry-level privacy setting, i.e., they preserve privacy of only a single rating of a user.",1. Introduction,[0],[0]
"Hence, they are not suitable for preserving a user’s privacy in practical recommendation systems.",1. Introduction,[0],[0]
"In fact, their trivial extension to user-level privacy leads to vacuous bounds (see Table 1).",1. Introduction,[0],[0]
"Some works (McSherry & Mironov, 2009; Liu et al., 2015) do serve as an exception, and directly address the user-level privacy problem.",1. Introduction,[0],[0]
"However, they only show empirical evidences of their effectiveness; they do not provide formal error bounds.1 In contrast, we provide an efficient algorithm based on the classic Frank-Wolfe (FW) procedure (Frank & Wolfe, 1956), and show that it gives strong utility guarantees while preserving user-level privacy.",1. Introduction,[0],[0]
"Furthermore, we empirically demonstrate its effectiveness on various benchmark datasets.
",1. Introduction,[0],[0]
"Our private FW procedure needs to compute the top right singular vector of a sparse user preference matrix, while
1In case of (Liu et al., 2015), the DP guarantee itself might require an exponential amount of computation.
",1. Introduction,[0],[0]
preserving DP.,1. Introduction,[0],[0]
"For practical recommendation systems with a large number of items, this step turns out to be a significant bottleneck both in terms of space as well as time complexity.",1. Introduction,[0],[0]
"To alleviate this issue, we provide a method, based on the celebrated Oja’s algorithm (Jain et al., 2016), which is nearly optimal in terms of the accuracy of the computed singular vector while still providing significant improvement in terms of space and computation.",1. Introduction,[0],[0]
"In fact, our method can be used to speed-up even the vanilla differentially private PCA computation (Dwork et al., 2013).",1. Introduction,[0],[0]
"To the best of our knowledge, this is the first algorithm for DP singular value computation with optimal utility guarantee, that also exploits the sparsity of the underlying matrix.
",1. Introduction,[0],[0]
"Notion of privacy: To measure privacy, we select differential privacy, which is a de-facto privacy notion for largescale learning systems, and has been widely adopted by the academic community as well as big corporations like Google (Erlingsson et al., 2014), Apple (McMillan, 2016), etc.",1. Introduction,[0],[0]
The underlying principle of standard DP is that the output of the algorithm should not change significantly due to presence or absence of any user.,1. Introduction,[0],[0]
"In the context of matrix completion, where the goal is to release the entire preference matrix while preserving privacy, this implies that the computed ratings/preferences for any particular user cannot depend strongly on her own personal preferences.",1. Introduction,[0],[0]
"Naturally, the resulting preference computation is going to be trivial and inaccurate (which also follows from the reconstruction attacks of (Dinur & Nissim, 2003) and (Hardt & Roth, 2012)).
",1. Introduction,[0],[0]
"To alleviate this concern, we consider a relaxed but natural DP notion (for recommendation systems) called joint differential privacy (Kearns et al., 2014).",1. Introduction,[0],[0]
"Consider an algorithm A that produces individual outputs Yi for each user i, i.e., the i-th row of preference matrix Y .",1. Introduction,[0],[0]
"Joint DP ensures that for each user i, the output ofA for all other users (denoted by Y−i) does not reveal “much” about the preferences of user i.",1. Introduction,[0],[0]
"That is, the recommendations made to all the users except the i-th user do not depend significantly upon the i-th user’s preferences.",1. Introduction,[0],[0]
"Although not mentioned explicitly, previous works on DP matrix completion (McSherry & Mironov, 2009; Liu et al., 2015) strive to ensure Joint DP.",1. Introduction,[0],[0]
"Formal definitions are provided in Section 2.
",1. Introduction,[0],[0]
Granularity of privacy: DP protects the information about a user in the context of presence or absence of her data record.,1. Introduction,[0],[0]
"Prior works on DP matrix completion (McSherry & Mironov, 2009; Liu et al., 2015), and its close analogue, low-rank approximation (Blum et al., 2005; Chan et al., 2011; Hardt & Roth, 2012; Dwork et al., 2013; Hardt & Roth, 2013), have considered different variants of the notion of a data record.",1. Introduction,[0],[0]
"Some have considered a single entry in the matrix Y ∗ as a data record (resulting in entry-level privacy), whereas others have considered a more practical
setting where the complete row is a data record (resulting in user-level privacy).",1. Introduction,[0],[0]
"In this work, we present all our results in the strictly harder user-level privacy setting.",1. Introduction,[0],[0]
"To ensure a fair comparison, we present the results of prior works in the same setting.",1. Introduction,[0],[0]
The goal of a low-rank matrix completion problem is to estimate a low-rank (or a convex relaxation of bounded nuclear norm) matrix Y ∗ ∈,1.1. Problem definition: Matrix completion,[0],[0]
"<m×n, having seen only a small number of entries from it.",1.1. Problem definition: Matrix completion,[0],[0]
"Here, m is the number of users, and n is the number of items.",1.1. Problem definition: Matrix completion,[0],[0]
Let Ω = {,1.1. Problem definition: Matrix completion,[0],[0]
"(i, j) ⊆",1.1. Problem definition: Matrix completion,[0],[0]
"[m]× [n]} be the index set of the observed entries from Y ∗, and let PΩ : <m×n → <m×n be a matrix operator s.t. PΩ(Y )",1.1. Problem definition: Matrix completion,[0],[0]
ij,1.1. Problem definition: Matrix completion,[0],[0]
"= Yij if (i, j) ∈ Ω, and 0 otherwise.",1.1. Problem definition: Matrix completion,[0],[0]
"Given, PΩ(Y ∗), the objective is to output a matrix Y such that the following generalization error, i.e., the error in approximating a uniformly random entry from the matrix Y ∗, is minimized:
F (Y ) =",1.1. Problem definition: Matrix completion,[0],[0]
"E(i,j)∼unif [m]×[n] [( Yij − Y ∗ij )2] .",1.1. Problem definition: Matrix completion,[0],[0]
"(1)
Generalization error captures the ability of an algorithm to predict unseen samples from Y ∗.",1.1. Problem definition: Matrix completion,[0],[0]
We would want the generalization error to be o(1) in terms of the problem parameters when Ω = o(mn).,1.1. Problem definition: Matrix completion,[0],[0]
"Throughout the paper, we will assume that m > n.",1.1. Problem definition: Matrix completion,[0],[0]
"In this work, we provide the first joint DP algorithm for low-rank matrix completion with formal non-trivial error bounds, which are summarized in Tables 1 and 2.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"At a high level, our key result can be summarized as follows:
Informal Theorem 1.1 (Corresponds to Corollary 3.1).",1.1.1. OUR CONTRIBUTIONS,[0],[0]
Assume that each entry of a hidden matrix Y ∗ ∈,1.1.1. OUR CONTRIBUTIONS,[0],[0]
"<m×n is in [−1, 1], and there are √ n observed entries per user.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Also, assume that the nuclear norm of Y ∗ is bounded by O( √ mn), i.e., Y ∗ has nearly constant rank.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Then, there exist ( , δ)-joint differentially private algorithms that have o(1) generalization error as long as m = ω(n5/4).
",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"In other words, even with √ n observed ratings per user, we obtain asymptotically the correct estimation of each entry of Y ∗ on average, as long asm is large enough.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"The sample complexity bound dependence on m can be strengthened by making additional assumptions, such as incoherence, on Y ∗. See the supplementary material for details.
",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Our algorithm is based on two important ideas: a) using local and global computation, b) using the Frank-Wolfe method as a base optimization technique.
",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Local and global computation: The key idea that defines our algorithm, and allows us to get strong error bounds under joint DP is splitting the algorithm into two components:
global and local.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
Recall that each row of the hidden matrix Y ∗ belongs to an individual user.,1.1.1. OUR CONTRIBUTIONS,[0],[0]
"The global component of our algorithm computes statistics that are aggregate in nature (e.g., computing the correlation across columns of the revealed matrix PΩ(Y ∗)).",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"On the other hand, the local component independently fine-tunes the statistics computed by the global component to generate accurate predictions for each user.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Since the global component depends on the data of all users, adding noise to it (for privacy) does not significantly affect the accuracy of the predictions.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"(McSherry & Mironov, 2009; Liu et al., 2015) also exploit a similar idea of segregating the computation, but they do not utilize it formally to provide non-trivial error bounds.
",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Frank-Wolfe based method: We use the standard nuclear norm formulation (Recht, 2011; Shalev-shwartz et al., 2011; Tewari et al., 2011; Candes & Recht, 2012) for the matrix completion problem:
min ‖Y ‖nuc≤k F̂ (Y ), (2)
",1.1.1. OUR CONTRIBUTIONS,[0],[0]
where F̂ (Y ) =,1.1.1. OUR CONTRIBUTIONS,[0],[0]
12|Ω|‖PΩ(Y,1.1.1. OUR CONTRIBUTIONS,[0],[0]
"− Y ∗)‖2F , ‖Y ‖nuc is the sum
of singular values of Y , and the underlying hidden matrix Y ∗ is assumed to have nuclear norm of at most k. Note that we denote the empirical risk of a solution Y by F̂ (Y ) throughout the paper.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"We use the popular Frank-Wolfe algorithm (Frank & Wolfe, 1956; Jaggi & Sulovsky, 2010) as our algorithmic building block.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"At a high-level, FW computes the solution to (2) as a convex combination of rankone matrices, each with nuclear norm at most k. These matrices are added iteratively to the solution.
",1.1.1. OUR CONTRIBUTIONS,[0],[0]
Our main contribution is to design a version of the FW method that preserves Joint DP.,1.1.1. OUR CONTRIBUTIONS,[0],[0]
"That is, if the standard FW algorithm decides to add matrix u · vT during an iteration, our private FW computes a noisy version of v ∈",1.1.1. OUR CONTRIBUTIONS,[0],[0]
<n,1.1.1. OUR CONTRIBUTIONS,[0],[0]
via its global component.,1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Then, each user computes the respective element of u ∈ <m to obtain her update.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"The noisy version of v suffices for the Joint DP guarantee, and allows us to provide the strong error bound in Theorem 1.1 above.
",1.1.1. OUR CONTRIBUTIONS,[0],[0]
We want to emphasize that the choice of FW as the underlying matrix completion algorithm is critical for our system.,1.1.1. OUR CONTRIBUTIONS,[0],[0]
FW updates via rank-one matrices in each step.,1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Hence, the error due to noise addition in each step is small (i.e., proportional to the rank), and allows for an easy decomposition into the local-global computation model.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Other standard techniques like proximal gradient descent based techniques (Cai et al., 2010b; Lin et al., 2010) can involve nearly full-rank updates in an iteration, and hence might incur large error, leading to arbitrary inaccurate solutions.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Note that though a prior work (Talwar et al., 2015) has proposed a DP Frank-Wolfe algorithm for high-dimensional regression, it was for a completely different problem in a different setting where the segregation of computation into global and local components was not necessary.
",1.1.1. OUR CONTRIBUTIONS,[0],[0]
Private singular vector of sparse matrices using Oja’s method: Our private FW requires computing a noisy covariance matrix which implies Ω(n2) space/time complexity for n items.,1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Naturally, such an algorithm does not scale to practical recommendation systems.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"In fact, this drawback exists even for standard private PCA techniques (Dwork et al., 2013).",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Using insights from the popular Oja’s method, we provide a technique (see Algorithm 2) that has a linear dependency on n as long as the number of ratings per user is small.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Moreover, the performance of our private FW method isn’t affected by using this technique.
",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"SVD-based method: In the supplementary material, we also extend our technique to a singular value decomposition (SVD) based method for matrix completion/factorization.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Our utility analysis shows that there are settings where this method outperforms our FW-based method, but in general it can provide a significantly worse solution.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"The main goal is to study the power of the simple SVD-based method, which is still a popular method for collaborative filtering.
",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Empirical results: Finally, we show that along with providing strong analytical guarantees, our private FW also performs well empirically.",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"In particular, we show its efficacy on benchmark collaborative filtering datasets like Jester (Goldberg et al., 2001), MovieLens (Harper & Konstan, 2015), the Netflix prize dataset (Bennett et al., 2007), and the Yahoo! Music recommender dataset (Yahoo, 2011).",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"Our algorithm consistently outperforms (in terms of accuracy) the existing state-of-the-art DP matrix completion methods (SVD-based method by (McSherry & Mironov, 2009), and a variant of projected gradient descent (Cai et al., 2010c; Bassily et al., 2014b; Abadi et al., 2016)).",1.1.1. OUR CONTRIBUTIONS,[0],[0]
"As discussed earlier, our results are the first to provide nontrivial error bounds for DP matrix completion.",1.2. Comparison to prior work,[0],[0]
"For comparing different results, we consider the following setting of the hidden matrix Y ∗ ∈",1.2. Comparison to prior work,[0],[0]
<m×n and the set of released entries Ω: i) |Ω|,1.2. Comparison to prior work,[0],[0]
"≈ m √ n, ii) each row of Y ∗ has an `2 norm of √ n, and iii) each row of PΩ(Y ∗) has `2-norm at most n1/4, i.e., ≈ √ n random entries are revealed for each row.",1.2. Comparison to prior work,[0],[0]
"Furthermore, we assume the spectral norm of Y ∗ is at most O( √ mn), and Y ∗ is rank-one.",1.2. Comparison to prior work,[0],[0]
"Note that these conditions are satisfied by a matrix Y ∗ = u·vT where ui, vj ∈",1.2. Comparison to prior work,[0],[0]
"[−1, 1] ∀i, j, and √ n random entries are observed per user.
",1.2. Comparison to prior work,[0],[0]
"In Table 1, we provide a comparison based on the sample complexity, i.e., the number of usersm and the number observed samples |Ω| needed to attain a generalization error of o(1).",1.2. Comparison to prior work,[0],[0]
"We compare our results with the best non-private algorithm for matrix completion based on nuclear norm minimization (Shalev-shwartz et al., 2011), and the prior work on DP matrix completion (McSherry & Mironov, 2009; Liu et al., 2015).",1.2. Comparison to prior work,[0],[0]
"We see that for the same |Ω|, the
sample complexity on m increases from ω(n) to ω(n5/4) for our FW-based algorithm.",1.2. Comparison to prior work,[0],[0]
"While (McSherry & Mironov, 2009; Liu et al., 2015) work under the notion of Joint DP as well, they do not provide any formal accuracy guarantees.
",1.2. Comparison to prior work,[0],[0]
Interlude: Low-rank approximation.,1.2. Comparison to prior work,[0],[0]
We also compare our results with the prior work on a related problem of DP lowrank approximation.,1.2. Comparison to prior work,[0],[0]
"Given a matrix Y ∗ ∈ <m×n, the goal is to compute a DP low-rank approximation Ypriv, s.t. Ypriv is close to Y ∗ either in the spectral or Frobenius norm.",1.2. Comparison to prior work,[0],[0]
Notice that this is similar to matrix completion if the set of revealed entries Ω is the complete matrix.,1.2. Comparison to prior work,[0],[0]
"Hence, our methods can be applied directly.",1.2. Comparison to prior work,[0],[0]
"To be consistent with the existing literature, we assume that Y ∗ is rank-one matrix, and each row of Y ∗ has `2-norm at most one .",1.2. Comparison to prior work,[0],[0]
Table 2 compares the various results.,1.2. Comparison to prior work,[0],[0]
"While all the prior works provide trivial error bounds (in both Frobenius and spectral norm, as ‖Y ∗‖2 = ‖Y ∗‖F ≤ √ m), our methods provide non-trivial bounds.",1.2. Comparison to prior work,[0],[0]
"The key difference is that we ensure Joint DP (Definition 2.2), while existing methods ensure the stricter standard DP (Definition 2.1), with the exponential mechanism (Kapralov & Talwar, 2013) ensuring ( , 0)-standard DP.
matrix Ypriv isO
(
m2/5/n1/5
)
for Private FW, whereas it isO(1) for the others.",1.2. Comparison to prior work,[0],[0]
"References: ‡(Blum et al., 2005; Chan et al., 2011; Dwork et al., 2014b), S(Hardt & Roth, 2012), ¶(Hardt & Roth, 2013),£(Kapralov & Talwar, 2013)",1.2. Comparison to prior work,[0],[0]
"Let D = {d1, · · · , dm} be a dataset of m entries.",2. Background: Notions of privacy,[0],[0]
"Each entry di lies in a fixed domain T , and belongs to an individual",2. Background: Notions of privacy,[0],[0]
"i, whom we refer to as an agent in this paper.",2. Background: Notions of privacy,[0],[0]
"Furthermore, di encodes potentially sensitive information about agent i. Let A be an algorithm that operates on dataset D, and produces a vector of m outputs, one for each agent i and from a set of possible outputs S. Formally, let A : T m → Sm.",2. Background: Notions of privacy,[0],[0]
"Let D−i denote the dataset D without the entry of the i-th agent, and similarly A−i(D) be the set of outputs without the output for the i-th agent.",2. Background: Notions of privacy,[0],[0]
"Also, let (di;D−i) denote the dataset obtained by adding data entry di to the dataset D−i.",2. Background: Notions of privacy,[0],[0]
"In the following, we define both standard differential privacy and joint differential privacy , and contrast them.
",2. Background: Notions of privacy,[0],[0]
"Definition 2.1 (Standard differential privacy (Dwork et al., 2006a;b)).",2. Background: Notions of privacy,[0],[0]
"An algorithm A satisfies ( , δ)-differential privacy if for any agent i, any two possible values of data entry di, d ′",2. Background: Notions of privacy,[0],[0]
"i ∈ T for agent i, any tuple of data entries for all other agents, D−i ∈ T m−1, and",2. Background: Notions of privacy,[0],[0]
"any output S ∈ Sm, we have Pr A [A (di;D−i) ∈ S] ≤",2. Background: Notions of privacy,[0],[0]
e,2. Background: Notions of privacy,[0],[0]
Pr,2. Background: Notions of privacy,[0],[0]
"A [A (d′i;D−i) ∈ S] + δ.
",2. Background: Notions of privacy,[0],[0]
"At a high-level, an algorithm A is ( , δ)-standard DP if for any agent i and dataset D, the output A(D) and D−i do not reveal “much” about her data entry di.",2. Background: Notions of privacy,[0],[0]
"For reasons mentioned in Section 1, our matrix completion algorithms provide privacy guarantee based on a relaxed notion of DP, called joint differential privacy , which was initially proposed in (Kearns et al., 2014).",2. Background: Notions of privacy,[0],[0]
"At a high-level, an algorithm A preserves ( , δ)-joint DP if for any agent i and datasetD, the output of A for the other (m − 1) agents (denoted by A−i(D)) and D−i do not reveal “much” about her data entry di.",2. Background: Notions of privacy,[0],[0]
Such a relaxation is necessary for matrix completion because an accurate completion of the row of an agent can reveal a lot of information about her data entry.,2. Background: Notions of privacy,[0],[0]
"However, it is still a very strong privacy guarantee for an agent even if every other agent colludes against her, as long as she does not make the predictions made to her public.
",2. Background: Notions of privacy,[0],[0]
"Definition 2.2 (Joint differential privacy (Kearns et al., 2014)).",2. Background: Notions of privacy,[0],[0]
"An algorithm A satisfies ( , δ)-joint differential privacy if for any agent i, any two possible values of data entry di, d′i ∈ T for agent",2. Background: Notions of privacy,[0],[0]
"i, any tuple of data entries for all other agents,D−i ∈ T m−1, and any output S ∈ Sm−1,
",2. Background: Notions of privacy,[0],[0]
Pr A [A−i (di;D−i) ∈ S] ≤ e,2. Background: Notions of privacy,[0],[0]
Pr A,2. Background: Notions of privacy,[0],[0]
"[A−i (d′i;D−i) ∈ S] + δ.
",2. Background: Notions of privacy,[0],[0]
"In this paper, we consider the privacy parameter to be a small constant (≈ 0.1), and δ < 1/m. There are semantic reasons for such choice of parameters (Kasiviswanathan & Smith, 2008), but that is beyond the scope of this work.",2. Background: Notions of privacy,[0],[0]
Recall that the objective is to solve the matrix completion problem (defined in Section 1.1) under Joint DP.,3. Private matrix completion via Frank-Wolfe,[0],[0]
"A standard modeling assumption is that Y ∗ is nearly low-rank, leading to the following empirical risk minimization problem (Keshavan et al., 2010; Jain et al., 2013; Jin et al., 2016):
min rank(Y )≤k
1
2|Ω| ‖PΩ(Y",3. Private matrix completion via Frank-Wolfe,[0],[0]
"− Y ∗)‖2F︸ ︷︷ ︸
F̂ (Y )
, where k min(m,n).
",3. Private matrix completion via Frank-Wolfe,[0],[0]
"As this is a challenging non-convex optimization problem, a popular approach is to relax the rank constraint to a nuclear-norm constraint, i.e., min
‖Y ‖nuc≤k F̂ (Y ).
",3. Private matrix completion via Frank-Wolfe,[0],[0]
"To this end, we use the FW algorithm (see the supplementary material for more details) as our building block.",3. Private matrix completion via Frank-Wolfe,[0],[0]
"FW is a popular conditional gradient algorithm in which the current iterate is updated as: Y (t) ← (1 − η)Y (t−1) + η · G, where η is the step size, and G is given by: argmin ‖G‖nuc≤k 〈 G,∇Y (t−1) F̂ (Y ) 〉 .",3. Private matrix completion via Frank-Wolfe,[0],[0]
"Note that the optimal solution to the above problem is G = −kuv>, where (λ, u, v) are the top singular components of A(t−1) = PΩ(Y (t−1)− Y ∗).",3. Private matrix completion via Frank-Wolfe,[0],[0]
"Also, the optimal G is a rank-one matrix.
",3. Private matrix completion via Frank-Wolfe,[0],[0]
"Algorithmic ideas: In order ensure Joint DP and still have strong error guarantees, we develop the following ideas.",3. Private matrix completion via Frank-Wolfe,[0],[0]
These ideas have been formally compiled into Algorithm 1.,3. Private matrix completion via Frank-Wolfe,[0],[0]
"Notice that both the functionsAglobal andAlocal in Algorithm 1 are parts of the Private FW technique, whereAglobal consists of the global component, and each user runsAlocal at her end to carry out a local update.",3. Private matrix completion via Frank-Wolfe,[0],[0]
"Throughout this discussion, we assume that max
i∈[m] ‖PΩ(Y ∗i )‖2 ≤ L.
Splitting the update into global and local components: One can equivalently write the Frank-Wolfe update as follows:
Y (t) ← (1−η)Y (t−1)−η · kλA (t−1)vv>, whereA(t−1),v, and λ are defined as above.",3. Private matrix completion via Frank-Wolfe,[0],[0]
"Note that v and λ2 can also be obtained as the top right eigenvector and eigenvalue of A(t−1) > A(t−1) =
m∑ i=1",3. Private matrix completion via Frank-Wolfe,[0],[0]
"Ai (t−1)>Ai (t−1), where Ai(t−1) =
PΩ(Yi (t−1) − Y ∗i ) is the i-th row of A(t−1).",3. Private matrix completion via Frank-Wolfe,[0],[0]
We will use the global component Aglobal in Algorithm 1 to compute v and λ.,3. Private matrix completion via Frank-Wolfe,[0],[0]
"Using the output of Aglobal, each user (row)",3. Private matrix completion via Frank-Wolfe,[0],[0]
i ∈,3. Private matrix completion via Frank-Wolfe,[0],[0]
"[m] can compute her local update (using Alocal) as follows:
Yi (t) =",3. Private matrix completion via Frank-Wolfe,[0],[0]
"(1− η)Yi(t−1)−
ηk
λ",3. Private matrix completion via Frank-Wolfe,[0],[0]
"PΩ(Y
(t−1)− Y ∗)ivv>.",3. Private matrix completion via Frank-Wolfe,[0],[0]
"(3)
A block schematic of this idea is presented in Figure 1.
",3. Private matrix completion via Frank-Wolfe,[0],[0]
Algorithm 1,3. Private matrix completion via Frank-Wolfe,[0],[0]
"Private Frank-Wolfe algorithm function Global Component Aglobal (Input- privacy parameters: ( , δ) s.t. ≤ 2 log (1/δ), total number of iterations: T , bound on ‖PΩ(Y ∗i )‖2: L, failure probability: β, number of users: m, number of items: n) σ",3. Private matrix completion via Frank-Wolfe,[0],[0]
"← L2 √ 64 · T log(1/δ)/ , v̂← {0}n, λ̂← 0
for t ∈",3. Private matrix completion via Frank-Wolfe,[0],[0]
"[T ] do W (t) ← {0}n×n, λ̂′ ←",3. Private matrix completion via Frank-Wolfe,[0],[0]
λ̂+,3. Private matrix completion via Frank-Wolfe,[0],[0]
√ σ,3. Private matrix completion via Frank-Wolfe,[0],[0]
"log(n/β)n1/4
for i ∈",3. Private matrix completion via Frank-Wolfe,[0],[0]
[m] do W (t) ←W,3. Private matrix completion via Frank-Wolfe,[0],[0]
(t),3. Private matrix completion via Frank-Wolfe,[0],[0]
"+Alocal(i, v̂, λ̂′, T, t, L) Ŵ (t) ← W (t) + N (t), where N (t) ∈",3. Private matrix completion via Frank-Wolfe,[0],[0]
<,3. Private matrix completion via Frank-Wolfe,[0],[0]
"n×n is a matrix with i.i.d. entries from N (0, σ2) (v̂, λ̂2)←",3. Private matrix completion via Frank-Wolfe,[0],[0]
"Top eigenvector and eigenvalue of Ŵ (t)
end for end function function Local Update Alocal (Input- user number: i, top right singular vector: v̂, top singular value: λ̂′, total number of iterations: T , current iteration: t, bound on ‖PΩ(Y ∗i )",3. Private matrix completion via Frank-Wolfe,[0],[0]
"‖2: L, private true matrix row: PΩ(Y ∗i ))",3. Private matrix completion via Frank-Wolfe,[0],[0]
"Yi
(0) ← {0}n, Ai(t−1) ← PΩ(Yi(t−1)",3. Private matrix completion via Frank-Wolfe,[0],[0]
"− Y ∗i ) ûi ← (Ai(t−1) · v̂)/λ̂′
Define ΠL,Ω (M)i,j = min {
L ‖PΩ(Mi)‖2
, 1 } ·Mi,j
Yi (t) ← ΠL,Ω",3. Private matrix completion via Frank-Wolfe,[0],[0]
(( 1− 1T ),3. Private matrix completion via Frank-Wolfe,[0],[0]
"Yi (t−1) − kT ûi(v̂) T )
",3. Private matrix completion via Frank-Wolfe,[0],[0]
Ai (t) ← PΩ ( Yi (t),3. Private matrix completion via Frank-Wolfe,[0],[0]
"− Y ∗i )
if t = T , Output Yi(T )",3. Private matrix completion via Frank-Wolfe,[0],[0]
as prediction to user i and stop else,3. Private matrix completion via Frank-Wolfe,[0],[0]
Return Ai(t) >,3. Private matrix completion via Frank-Wolfe,[0],[0]
"Ai
(t) to Aglobal end function
Noisy rank-one update: Observe that v and λ, the statistics computed in each iteration of Aglobal, are aggregate statistics that use information from all rows of Y ∗.",3. Private matrix completion via Frank-Wolfe,[0],[0]
This ensures that they are noise tolerant.,3. Private matrix completion via Frank-Wolfe,[0],[0]
"Hence, adding sufficient noise can ensure standard DP (Definition 2.1)",3. Private matrix completion via Frank-Wolfe,[0],[0]
"forAglobal. 2 Since
2The second term in computing λ̂′ in Algorithm 1 is due to a bound on the spectral norm of the Gaussian noise matrix.",3. Private matrix completion via Frank-Wolfe,[0],[0]
"We use this bound to control the error introduced in the computation of λ̂.
the final objective is to satisfy Joint DP (Definition 2.2), the local component Alocal can compute the update for each user (corresponding to (3)) without adding any noise.
",3. Private matrix completion via Frank-Wolfe,[0],[0]
"Controlling norm via projection: In order to control the amount of noise needed to ensure DP, any individual data entry (here, any row of Y ∗) should have a bounded effect on the aggregate statistic computed by Aglobal.",3. Private matrix completion via Frank-Wolfe,[0],[0]
"However, each intermediate computation Yi(t) in (3) can have high `2-norm even if ‖PΩ(Y ∗i )‖2 ≤",3. Private matrix completion via Frank-Wolfe,[0],[0]
L.,3. Private matrix completion via Frank-Wolfe,[0],[0]
"We address this by applying a projection operator ΠL,Ω (defined below) to Yi (t), and compute the local update as ΠL,Ω ( Yi (t) )
in place of (3).",3. Private matrix completion via Frank-Wolfe,[0],[0]
"ΠL,Ω is defined as follows:",3. Private matrix completion via Frank-Wolfe,[0],[0]
"For any matrix M , ΠL,Ω ensures that any row of the “zeroed out” matrix PΩ(M) does not have `2-norm higher than L. Formally, ΠL,Ω (M)i,j = min { L ‖PΩ(Mi)‖2 , 1 } ·Mi,j for all entries (i, j) of M .",3. Private matrix completion via Frank-Wolfe,[0],[0]
"In our analysis, we show that this projection operation does not increase the error.",3. Private matrix completion via Frank-Wolfe,[0],[0]
Theorem 3.1.,3.1. Privacy and utility analysis,[0],[0]
"Algorithm 1 satisfies ( , δ)-joint DP.
",3.1. Privacy and utility analysis,[0],[0]
We defer the proof to the supplementary material.,3.1. Privacy and utility analysis,[0],[0]
"The proof uses standard DP properties of Gaussian noise addition from (Bun & Steinke, 2016).",3.1. Privacy and utility analysis,[0],[0]
The requirement ≤ 2 log (1/δ) in the input of Algorithm 1 is due to a reduction of a Concentrated DP guarantee to a standard DP guarantee.,3.1. Privacy and utility analysis,[0],[0]
We now show that the empirical risk of our algorithm is close to the optimal as long as the number of users m is “large”.,3.1. Privacy and utility analysis,[0],[0]
Theorem 3.2 (Excess empirical risk guarantee).,3.1. Privacy and utility analysis,[0],[0]
"Let Y ∗ be a matrix with ‖Y ∗‖nuc ≤ k, and max
i∈[m] ‖PΩ(Y ∗)i‖2 ≤",3.1. Privacy and utility analysis,[0],[0]
"L.
Let Y (T ) be a matrix, with its rows being Yi(T ) for all",3.1. Privacy and utility analysis,[0],[0]
i ∈,3.1. Privacy and utility analysis,[0],[0]
"[m], computed by function Alocal in Algorithm 1 after T iterations.",3.1. Privacy and utility analysis,[0],[0]
"If ≤ 2 log ( 1 δ ) , then with probability at least 2/3 over the outcomes of Algorithm 1, the following is true: F̂ ( Y (T ) )",3.1. Privacy and utility analysis,[0],[0]
= O  k2 |Ω|T + kT,3.1. Privacy and utility analysis,[0],[0]
"1/4L √ n1/2 log1/2(1/δ) logn |Ω| √
 .",3.1. Privacy and utility analysis,[0],[0]
"Furthermore, if T = Õ ( k4/5 2/5
n1/5L4/5
) , then F̂ ( Y (T ) ) =
Õ ( k6/5n1/5L4/5
|Ω| 2/5
) after hiding poly-logarithmic terms.
",3.1. Privacy and utility analysis,[0],[0]
We defer the proof to the supplementary material.,3.1. Privacy and utility analysis,[0],[0]
"At a high-level, our proof combines the noisy eigenvector estimation error for Algorithm 1 with a noisy-gradient analysis of the FW algorithm.",3.1. Privacy and utility analysis,[0],[0]
"Also, note that the first term in the bound corresponds to the standard FW convergence error, while the second term can be attributed to the noise added for DP which directly depends on T .",3.1. Privacy and utility analysis,[0],[0]
We also compute the optimal number of iterations required to minimize the empirical risk.,3.1. Privacy and utility analysis,[0],[0]
"Finally, the rank of Y (T ) is at most T , but its
nuclear-norm is bounded by k.",3.1. Privacy and utility analysis,[0],[0]
"As a result, Y (T ) has low generalization error (see Section 3.1.1).",3.1. Privacy and utility analysis,[0],[0]
Remark 1.,3.1. Privacy and utility analysis,[0],[0]
We further illustrate our empirical risk bound by considering a simple setting: let Y ∗ be a rank-one matrix with Y ∗ij ∈,3.1. Privacy and utility analysis,[0],[0]
"[−1, 1] and |Ω| = m √ n.",3.1. Privacy and utility analysis,[0],[0]
"Then k = O( √ mn),
and L = O(n1/4), implying an error of Õ (√ nm−2/5 ) hiding the privacy parameter ; in contrast, a trivial solution like Y = 0 leads to O(1) error.",3.1. Privacy and utility analysis,[0],[0]
"Naturally, the error increases with n",3.1. Privacy and utility analysis,[0],[0]
as there is more information to be protected.,3.1. Privacy and utility analysis,[0],[0]
"However, it decreases with a larger number of users m as the presence/absence of a user has lesser effect on the solution with increasing m. We leave further investigation into the dependency of the error on m for future work.",3.1. Privacy and utility analysis,[0],[0]
Remark 2.,3.1. Privacy and utility analysis,[0],[0]
"Our analysis does not require an upper bound on the nuclear norm of Y ∗ (as stated in Theorem 3.2); we would instead incur an additional error of
min ‖Y ‖nuc≤k
1 |Ω| ‖PΩ",3.1. Privacy and utility analysis,[0],[0]
(Y ∗ − Y )‖2F .,3.1. Privacy and utility analysis,[0],[0]
"Moreover, consider a sim-
ilar scenario as in Remark 1, but |Ω| = mn, i.e., all the entries of Y ∗ are revealed.",3.1. Privacy and utility analysis,[0],[0]
"In such a case, L = O( √ n), and the problem reduces to that of standard low-rank matrix approximation of Y ∗. Note that our result here leads to an error bound of Õ ( n1/5m−2/5 ) , while the state-of-the-art result by (Hardt & Roth, 2013) leads to an error bound of O(1) due to being in the much stricter standard DP model.",3.1. Privacy and utility analysis,[0],[0]
We now present a generalization error (defined in Equation 1) bound which shows that our approach provides accurate prediction over unknown entries.,3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"For obtaining our bound, we use Theorem 1 from (Srebro & Shraibman, 2005) (provided in the supplementary material for reference).",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"Also, the output of Private FW (Algorithm 1) has rank at most T , where T is the number of iterations.",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"Thus, replacing T from Theorem 3.2, we get the following: Corollary 3.1 (Generalization Error).",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"Let ‖Y ∗‖nuc ≤ k for a hidden matrix Y ∗, and ‖PΩ(Y ∗i )‖2 ≤ L for every row i of Y ∗.",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"If we choose the number of rounds in Algorithm 1 to be O ( k4/3
(|Ω|(m+n))1/3
) , the data samples in Ω are drawn u.a.r.
from [m]× [n], and ≤ 2 log (
1 δ
) , then with probability at
least 2/3 over the outcomes of the algorithm and choosing Ω, the following is true for the final completed matrix Y :
F (Y ) =",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"Õ ( k4/3Ln1/4√
|Ω|13/6(m+ n)1/6",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"+
( k √ m+ n
|Ω|
)2/3) .
",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"The Õ (·) hides poly-logarithmic terms in m,n, |Ω| and δ.",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
Remark 3.,3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
We further illustrate our bound using a setting similar to the one considered in Remark 1.,3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
Let Y ∗ be a rank-one matrix with Y ∗ij ∈,3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"[−1, 1] for all i, j; let |Ω| ≥ m √ n · polylog(n), i.e., the fraction of movies rated by each user is arbitrarily small for larger n.",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"For this setting, our generalization error is o(1) for m = ω(n5/4).
",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"This is slightly higher than the bound in the non-private setting by (Shalev-shwartz et al., 2011), where m = ω(n) is sufficient to get generalization error o(1).",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"Also, as the first term in the error bound pertains to DP, it decreases with a larger number of users m, and increases with n as it has to preserve privacy of a larger number of items.",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"In contrast, the second term is the matrix completion error decreases with n.",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"This is intuitive, as a larger number of movies enables more sharing of information between users, thus allowing a better estimation of preferences Y ∗.",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"However, just increasing m may not always lead to a more accurate solution (for example, consider the case of n = 1).",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
Remark 4.,3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"The guarantee in Corollary 3.1 is for uniformly random Ω, but using the results of (Shamir & ShalevShwartz, 2011), it is straightforward to extend our results to any i.i.d.",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
distribution over Ω.,3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"Moreover, we can extend our results to handle strongly convex and smooth loss functions instead of the squared loss considered in this paper.",3.1.1. GENERALIZATION ERROR GUARANTEE,[0],[0]
"Algorithm 1 requires computing the top eigenvector of Ŵ (t) = W (t) + N (t), where W (t) = ∑ i ( Ai (t) )",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
>,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
Ai (t) and N (t) is a random noise matrix.,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"However, this can be a bottleneck for computation as N (t) itself is a dense n×nmatrix, implying a space complexity of Ω(n2 +mk), where k is the maximum number of ratings provided by a user.",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"Similarly, standard eigenvector computation algorithms will require O(mk2 + n2) time (ignoring factors relating to rate of convergence), which can be prohibitive for practical recommendation systems with large n. We would like to stress that this issue plagues even standard DP PCA algorithms (Dwork et al., 2013), which have quadratic space-time complexity in the number of dimensions.
",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
We tackle this by using a stochastic algorithm for the top eigenvector computation that significantly reduces both space and time complexity while preserving privacy.,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"In particular, we use Oja’s algorithm (Jain et al., 2016), which computes top eigenvectors of a matrix with a stochastic access to the matrix itself.",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"That is, if we want to compute the top eigenvector of W (t), we can use the following updates:
v̂τ = (I + ηXτ )v̂τ−1, v̂τ = v̂τ/‖v̂τ‖2 (4)
where E[Xτ ] = W (t).",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"For example, we can update v̂τ usingXτ = W (t)+N (t) τ where each entry ofN (t) τ is sampled i.i.d.",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
from a Gaussian distribution calibrated to ensure DP.,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
Even this algorithm in its current form does not decrease the space or time complexity as we need to generate a dense matrix Nτ (t) in each iteration.,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"However, by observing that Nτ
(t)v = gτ ∼ N (0, σ21n) where v is independent of Nτ
(t), we can now replace the generation of Nτ (t) by the generation of a vector gτ , thus reducing both the space and time complexity of our algorithm.",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"The computation of each
Algorithm 2",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
Private Oja’s algorithm Input: Anm×nmatrixA s.t. each row ‖Ai‖2 ≤,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"L, privacy parameters: ( , δ) s.t. ≤ 2 log(1/δ), total number of iterations:",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
Γ σ,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
← L2 √ 256 ·,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"Γ log(2/δ)/ , v̂0 ∼ N (0, σ2I)
for τ ∈",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"[Γ] do η = 1
Γσ √ n , gτ ∼ N (0, σ21n) v̂τ ← v̂τ−1 + η ( ATAv̂τ−1 + gτ ) , v̂τ ← v̂τ/‖v̂τ‖2
end for Return v̂Γ, ( λ̂2Γ ← ||A · v̂Γ||22 +N (0, σ2) )
update is significantly cheaper as long as mk n2, which is the case for practical recommendation systems as k tends to be fairly small there (typically on the order of √ n).
",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
Algorithm 2 provides a pseudocode of the eigenvector computation method.,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
The computation of the approximate eigenvector v̂Γ and the eigenvalue λ̂2Γ in it is DP (directly follows via the proof of Theorem 3.1).,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
The next natural question is how well can v̂Γ approximate the behavior of the top eigenvector of the non-private covariance matrix W (t)?,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"To this end, we provide Theorem 3.3 below that analyzes Oja’s algorithm, and shows that the Rayleigh quotient of the approximate eigenvector is close to the top eigenvalue of W (t).",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"In particular, using Theorem 3.3 along with the fact that in our case, V = σ2n, we have ∥∥A(t)∥∥2 2 ≤",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
‖A(t)v̂Γ‖22,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"+O (σ √ n log(η/β)) with high probability (w.p. ≥ 1−β2)), where v̂Γ is the output of Algorithm 2, Γ = Ω ( min { 1 β , ‖A(t)‖2 σ √ n }) , and η = 1 Γ·σ √ n .
Note that the above given bound is exactly the bound required in the proof of Theorem 3.2.",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"Hence, computing the top eigenvector privately using Algorithm 2 does not change the utility bound of Theorem 3.2.
",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"Theorem 3.3 (Based on Theorem 3 (Allen-Zhu & Li, 2017)).",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"Let X1, X2, . . .",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
XΓ be sampled i.i.d.,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
such that EXi = W = ATA.,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"Moreover, let V = max{‖E(Xi −W )T",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
(Xi −W ),3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"‖, ‖E(Xi −W )(",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"Xi −W )T ‖}, and η = 1√VΓ .",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"Then, the Γ-th iterate of Oja’s Algorithm (Update (4)) , i.e., v̂Γ, satisfies (w.p. ≥ 1",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
− 1/poly(Γ)):,3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"v̂TΓW v̂Γ ≥ ‖W‖2 −O (√ V Γ + ‖W‖2 Γ ) .
",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"Comparison with Private Power Iteration (PPI) method (Hardt & Roth, 2013): Private PCA via PPI provides utility guarantees dependent on the gap between the top and the kth eigenvalue of the input matrix A for some k > 1, whereas private Oja’s utility guarantee is gap-independent.",3.2. Efficient PCA via Oja’s Algorithm,[0],[0]
"We now present empirical results for Private FW (Algorithm 1) on several benchmark datasets, and compare its
performance to state-of-the-art methods like (McSherry & Mironov, 2009), and private as well as non-private variant of the Projected Gradient Descent (PGD) method (Cai et al., 2010c; Bassily et al., 2014a; Abadi et al., 2016).",4. Experimental evaluation,[0],[0]
"In all our experiments, we see that private FW provides accuracy very close to that of the non-private baseline, and almost always significantly outperforms both the private baselines.
",4. Experimental evaluation,[0],[0]
"Datasets: As we want to preserve privacy of every user, and the output for each user is n-dimensional, we can expect the private recommendations to be accurate only when m n (see Theorem 3.1).",4. Experimental evaluation,[0],[0]
"Due to this constraint, we conduct experiments on the following datasets:",4. Experimental evaluation,[0],[0]
"1) Synthetic: We generate a random rank-one matrix Y ∗ = uvT with unit `∞-norm, m = 500K, and n = 400, 2)",4. Experimental evaluation,[0],[0]
"Jester: This dataset contains n = 100 jokes, and",4. Experimental evaluation,[0],[0]
"m ≈ 73K users, 3) MovieLens10M (Top 400):",4. Experimental evaluation,[0],[0]
"We pick the n = 400 most rated movies from the Movielens10M dataset, resulting in m ≈ 70K users, 4) Netflix (Top 400): We pick the n = 400 most rated movies from the Netflix prize dataset, resulting in m ≈ 474K users, and",4. Experimental evaluation,[0],[0]
"5) Yahoo! Music (Top 400): We pick the n = 400 most rated songs from the Yahoo! music dataset, resulting in m ≈ 995K",4. Experimental evaluation,[0],[0]
"users.3 We rescale the ratings to be from 0 to 5 for Jester and Yahoo! Music.
",4. Experimental evaluation,[0],[0]
"Procedure: For all datasets, we randomly sample 1% of the given ratings for measuring the test error.",4. Experimental evaluation,[0],[0]
"For experiments with privacy, for all datasets except Jester, we randomly select at most ξ = 80 ratings per user to get PΩ(Y ∗).",4. Experimental evaluation,[0],[0]
We vary the privacy parameter ∈,4. Experimental evaluation,[0],[0]
"[0.1, 5] 4, but keep δ = 10−6, thus ensuring that δ",4. Experimental evaluation,[0],[0]
< 1m for all datasets.,4. Experimental evaluation,[0],[0]
"Moreover, we report results averaged over 10 independent runs.
",4. Experimental evaluation,[0],[0]
"Note that the privacy guarantee is user-level, which effectively translates to an entry-level guarantee of entry = user ξ , i.e., entry ∈",4. Experimental evaluation,[0],[0]
"[0.00125, 0.0625]",4. Experimental evaluation,[0],[0]
as user ∈,4. Experimental evaluation,[0],[0]
"[0.1, 5].
",4. Experimental evaluation,[0],[0]
"Non-private baseline: We find that non-private FW and non-private PGD converge to the same accuracy after tuning, and",4. Experimental evaluation,[0],[0]
"hence, we use this as our baseline.
",4. Experimental evaluation,[0],[0]
"Private baselines: To the best of our knowledge, only (McSherry & Mironov, 2009) and (Liu et al., 2015) address the user-level DP matrix completion problem.",4. Experimental evaluation,[0],[0]
"While we present an empirical evaluation of the ‘SVD after cleansing method’ from the former, we refrain from comparing to the latter 5.",4. Experimental evaluation,[0],[0]
"We also provide a comparison with private PGD
3For n",4. Experimental evaluation,[0],[0]
"= 900 with all the considered datasets (except Jester), we see that private PGD takes too long to complete; we present an evaluation for the other algorithms in the supplementary material.
",4. Experimental evaluation,[0],[0]
"4The requirement in Algorithm 1 that ≤ 2 log (1/δ) is satisfied by all the values of considered for the experiments.
",4. Experimental evaluation,[0],[0]
"5The exact privacy parameters ( and δ) for the Stochastic Gradient Langevin Dynamics based algorithm in (Liu et al., 2015) (correspondigly, in (Wang et al., 2015)) are unclear.",4. Experimental evaluation,[0],[0]
"They use a Markov chain based sampling method; to obtain quantifiable ( , δ), the sampled distribution is required to converge (non-
(pseudocode provided in the supplementary material).
",4. Experimental evaluation,[0],[0]
"We elaborate on the data normalization and the parameter choices for all algorithms in the supplementary material.
",4. Experimental evaluation,[0],[0]
Results: Figure 2 shows the results of our experiments6.,4. Experimental evaluation,[0],[0]
"Even though all the considered private algorithms satisfy Joint DP, our private FW method almost always incurs a significantly lower test RMSE than the two private baselines.",4. Experimental evaluation,[0],[0]
"Note that although non-private PGD provides similar empirical accuracy as non-private FW, the difference in performance for their private versions can be attributed to the noise being calibrated to a rank-one update for our private Frank-Wolfe.
asymptotically) to a DP preserving distribution in `1 distance, for which we are not aware of any analysis.
",4. Experimental evaluation,[0],[0]
"6In all our experiments, the implementation of private FW with Oja’s method (Algorithm 2) did not suffer any perceivable loss of accuracy as compared to the variant in Algorithm 1; all the plots in Figure 2 remain identical.",4. Experimental evaluation,[0],[0]
"The authors would like to thank Ilya Mironov, and the anonymous reviewers, for their helpful comments.",Acknowledgements,[0],[0]
"This material is in part based upon work supported by NSF grants CCF-1740850 and IIS-1447700, and a grant from the Sloan foundation.",Acknowledgements,[0],[0]
The full version of this work is available at https://arxiv.org/abs/1712.09765.,Acknowledgements,[0],[0]
We provide the first provably joint differentially private algorithm with formal utility guarantees for the problem of user-level privacy-preserving collaborative filtering.,abstractText,[0],[0]
"Our algorithm is based on the Frank-Wolfe method, and it consistently estimates the underlying preference matrix as long as the number of users m is ω(n), where n is the number of items, and each user provides her preference for at least √ n randomly selected items.",abstractText,[0],[0]
"Along the way, we provide an optimal differentially private algorithm for singular vector computation, based on the celebrated Oja’s method, that provides significant savings in terms of space and time while operating on sparse matrices.",abstractText,[0],[0]
"We also empirically evaluate our algorithm on a suite of datasets, and show that it consistently outperforms the state-of-the-art private algorithms.",abstractText,[0],[0]
Differentially Private Matrix Completion Revisited,title,[0],[0]
"Since the early days of differential privacy, its main goal was to design privacy preserving versions of existing techniques for data analysis.",1. Introduction,[0],[0]
"It is therefore no surprise that several of the first differentially private algorithms were machine learning algorithms, with a special emphasis on the ubiquitous problem of linear regression (Kasiviswanathan et al., 2008; Chaudhuri et al., 2011; Kifer et al., 2012; Bass-
1Computing Science Dept., University of Alberta, Edmonton AB, Canada.",1. Introduction,[0],[0]
"This work was done when the author was at Harvard University, supported by NSF grant CNS-123723.",1. Introduction,[0],[0]
Correspondence to: Or Sheffet,1. Introduction,[0],[0]
"<osheffet@ualberta.ca>.
",1. Introduction,[0],[0]
"ily et al., 2014).",1. Introduction,[0],[0]
"However, all existing body of work on differentially private linear regression measures utility by bounding the distance between the linear regressor found by the standard non-private algorithm and the regressor found by the privacy-preserving algorithm.",1. Introduction,[0],[0]
"This is motivated from a machine-learning perspective, since bounds on the difference in the estimators translate to error bounds on prediction (or on the loss function).",1. Introduction,[0],[0]
"Such bounds are (highly) interesting and non-trivial, yet they are of little use in situations where one uses linear regression to establish correlations rather than predict labels.
",1. Introduction,[0],[0]
"In the statistics literature, Ordinary Least Squares (OLS) is a technique that uses linear regression in order to infer the correlation between a variable and an outcome, especially in the presence of other factors.",1. Introduction,[0],[0]
"And so, in this paper, we draw a distinction between “linear regression,” by which we refer to the machine learning technique of finding a specific estimator for a specific loss function; and “Ordinary Least Squares,” by which we refer to the statistical inference done assuming a specific model for generating the data and that uses linear regression.",1. Introduction,[0],[0]
"Many argue that OLS is the most prevalent technique in social sciences (Agresti & Finlay, 2009).",1. Introduction,[0],[0]
Such works make no claim as to the labels of a new unlabeled batch of samples.,1. Introduction,[0],[0]
Rather they aim to establish the existence of a strong correlation between the label and some feature.,1. Introduction,[0],[0]
"Needless to say, in such works, the privacy of individuals’ data is a concern.
",1. Introduction,[0],[0]
"In order to determine that a certain variable xj is positively (resp. negatively) correlated with an outcome y, OLS assumes a model where the outcome y is a noisy version of a linear mapping of all variables: y = β · x + e (with e denoting random Gaussian noise) for some predetermined and unknown β .",1. Introduction,[0],[0]
"Then, given many samples (xi, yi) OLS establishes two things: (i) when fitting a linear function to best predict y from x over the sample (via computing β̂ =",1. Introduction,[0],[0]
(∑ i xix T i )−1,1. Introduction,[0],[0]
( ∑ i yixi)),1. Introduction,[0],[0]
"the coefficient β̂j is positive (resp. negative); and (ii) inferring, based on β̂j , that the true βj is likely to reside in R>0 (resp. R<0).",1. Introduction,[0],[0]
"In fact, the crux in OLS is by describing βj using a probability distribution over the reals, indicating where βj is likely to fall, derived by computing t-values.",1. Introduction,[0],[0]
These values take into account both the variance in the data as well as the variance of the noise e.1,1. Introduction,[0],[0]
"Based on this probability distribution one can
1For example, imagine we run linear regression on a certain (X,y) which results in a vector β̂ with coordinates β̂1 = β̂2 =
ar X
iv :1
50 7.
02 48
2v 4
[ cs
.D",1. Introduction,[0],[0]
"S]
2 1
A ug
2 01
7
define the α-confidence interval — an interval I centered at β̂j whose likelihood to contain βj is 1−α.",1. Introduction,[0],[0]
"Of particular importance is the notion of rejecting the null-hypothesis, where the interval I does not contain the origin, and so one is able to say with high confidence that βj is positive (resp. negative).",1. Introduction,[0],[0]
"Further details regarding OLS appear in Section 2.
",1. Introduction,[0],[0]
In this work we give the first analysis of statistical inference for OLS using differentially private estimators.,1. Introduction,[0],[0]
"We emphasize that the novelty of our work does not lie in the differentially-private algorithms, which are, as we discuss next, based on the Johnson-Lindenstrauss Transform (JLT) and on additive Gaussian noise and are already known to be differentially private (Blocki et al., 2012; Dwork et al., 2014).",1. Introduction,[0],[0]
"Instead, the novelty of our work lies in the analyses of the algorithms and in proving that the output of the algorithms is useful for statistical inference.
",1. Introduction,[0],[0]
The Algorithms.,1. Introduction,[0],[0]
Our first algorithm (Algorithm 1) is an adaptation of Gaussian JLT.,1. Introduction,[0],[0]
"Proving that this adaptation remains ( , δ)-differentially private is straightforward (the proof appears in Appendix A.1).",1. Introduction,[0],[0]
"As described, the algorithm takes as input a parameter r (in addition to the other parameters of the problem) that indicates the number of rows in the JL-matrix.",1. Introduction,[0],[0]
"Later, we analyze what should one set as the value of r. Our second algorithm is taken
Algorithm 1 Outputting a private Johnson-Lindenstrauss projection of a matrix.
",1. Introduction,[0],[0]
Input: A matrix A ∈ Rn×d and a bound B > 0,1. Introduction,[0],[0]
"on the l2-norm of any row in A. Privacy parameters: , δ > 0.",1. Introduction,[0],[0]
"Parameter r indicating the number of rows in the resulting matrix.
",1. Introduction,[0],[0]
"Set w s.t. w2 = 8B 2 (√ 2r ln(8/δ) + 2 ln(8/δ) ) .
",1. Introduction,[0],[0]
Sample Z ∼ Lap(4B2/ ),1. Introduction,[0],[0]
and let σmin(A) denote the smallest singular value of A. if σmin(A)2 >,1. Introduction,[0],[0]
"w2 + Z + 4B 2 ln(1/δ) then
Sample a (r×n)-matrixRwhose entries are i.i.d samples from a normal Gaussian.",1. Introduction,[0],[0]
return RA and “matrix unaltered”.,1. Introduction,[0],[0]
else LetA′ denote the result of appendingAwith the d×dmatrix wId×d.,1. Introduction,[0],[0]
Sample a (r × (n + d))-matrix R whose entries are i.i.d samples from a normal Gaussian. returnRA′,1. Introduction,[0],[0]
and “matrix altered”.,1. Introduction,[0],[0]
"end if
verbatim from the work of Dwork et al (2014).",1. Introduction,[0],[0]
"We de-
0.1.",1. Introduction,[0],[0]
"Yet while the column X1 contains many 1s and (−1)s, the column X2 is mostly populated with zeros.",1. Introduction,[0],[0]
"In such a setting, OLS gives that it is likely to have β1 ≈ 0.1, whereas no such guarantees can be given for β2.
liberately focus on algorithms that approximate the 2ndmoment matrix of the data and then run hypothesis-testing by post-processing the output, for two reasons.",1. Introduction,[0],[0]
"First, they enable sharing of data2 and running unboundedly many hypothesis-tests.",1. Introduction,[0],[0]
"Since, we do not deal with OLS based on the private single-regression ERM algorithms (Chaudhuri et al., 2011; Bassily et al., 2014) as such inference requires us to use the Fisher-information matrix of the loss function — but these algorithms do not minimize a private loss-function but rather prove that outputting the minimizer of the perturbed loss-function is private.",1. Introduction,[0],[0]
"This means that differentially-private OLS based on these ERM algorithms requires us to devise new versions of these algorithms, making this a second step in this line of work...",1. Introduction,[0],[0]
(After first understanding what we can do using existing algorithms.),1. Introduction,[0],[0]
"We leave this approach — as well as performing private hypothesis testing using a PTR-type algorithm (Dwork & Lei, 2009) (output merely reject / don’t-reject decision without justification), or releasing only relevant tests judging by their p-values (Dwork et al., 2015) — for future work.
",1. Introduction,[0],[0]
Our Contribution and Organization.,1. Introduction,[0],[0]
"We analyze the performances of our algorithms on a matrix A of the form A = [X;y], where each coordinate yi is generated according to the homoscedastic model with Gaussian noise, which is a classical model in statistics.",1. Introduction,[0],[0]
"We assume the existence of a vector β s.t. for every i we have yi = βTxi + ei and ei is sampled i.i.d from N (0, σ2).3
We study the result of running Algorithm 1 on such data in the two cases: where A wasn’t altered by the algorithm and when A was appended by the algorithm.",1. Introduction,[0],[0]
"In the former case, Algorithm 1 boils down to projecting the data under a Gaussian JLT.",1. Introduction,[0],[0]
"Sarlos (2006) has already shown that the JLT is useful for linear regression, yet his work bounds the l2-norm of the difference between the estimated regression before and after the projection.",1. Introduction,[0],[0]
"Following Sarlos’ work, other works in statistics have analyzed compressed
2Researcher A collects the data and uses the approximation of the 2nd-moment matrix to test some OLS hypothesis; but once the approximation is published researcher B can use it to test for a completely different hypothesis.
",1. Introduction,[0],[0]
3This model may seem objectionable.,1. Introduction,[0],[0]
"Assumptions like the noise independence, 0-meaned or sampled from a Gaussian distribution have all been called into question in the past.",1. Introduction,[0],[0]
"Yet due to the prevalence of this model we see fit to initiate the line of work on differentially private Least Squares with this Ordinary model.
",1. Introduction,[0],[0]
"Algorithm 2 “Analyze Gauss” Algorithm of Dwork et al (2014).
",1. Introduction,[0],[0]
Input: A matrix A ∈ Rn×d and a bound B > 0,1. Introduction,[0],[0]
"on the l2-norm of any row in A. Privacy parameters: , δ > 0.",1. Introduction,[0],[0]
N,1. Introduction,[0],[0]
"← symmetric (d × d)-matrix with upper triangle entries sampled i.i.d from N ( 0, 2B 4",1. Introduction,[0],[0]
"ln(2/δ) 2 ) .
return ATA+N .
linear regression (Zhou et al., 2007; Pilanci & Wainwright, 2014a;b).",1. Introduction,[0],[0]
"However, none of these works give confidence intervals based on the projected data, presumably for three reasons.",1. Introduction,[0],[0]
"Firstly, these works are motivated by computational speedups, and so they use fast JLT as opposed to our analysis which leverages on the fact that our JL-matrix is composed of i.i.d Gaussians.",1. Introduction,[0],[0]
"Secondly, the focus of these works is not on OLS but rather on newer versions of linear regression, such as Lasso or when β lies in some convex set.",1. Introduction,[0],[0]
"Lastly, it is evident that the smallest confidence interval is derived from the data itself.",1. Introduction,[0],[0]
"Since these works do not consider privacy applications, (actually, (Zhou et al., 2007; Pilanci & Wainwright, 2014a) do consider privacy applications of the JLT, but quite different than differential privacy)",1. Introduction,[0],[0]
"they assume the analyst has access to the data itself, and so there was no need to give confidence intervals for the projected data.",1. Introduction,[0],[0]
"Our analysis is therefore the first, to the best of our knowledge, to derive t-values — and therefore achieve all of the rich expressivity one infers from tvalues, such as confidence bounds and null-hypotheses rejection — for OLS estimations without having access to X itself.",1. Introduction,[0],[0]
"We also show that, under certain conditions, the sample complexity for correctly rejecting the null-hypothesis increases from a certain bound N0 (without privacy) to a bound ofN0 + Õ( √ N0 ·κ( 1nA
TA)/ ) with privacy (where κ(M) denotes the condition number of the matrixM .)",1. Introduction,[0],[0]
"This appears in Section 3.
",1. Introduction,[0],[0]
In Section 4 we analyze the case Algorithm 1 does append the data and the JLT is applied to A′.,1. Introduction,[0],[0]
"In this case, solving the linear regression problem on the projected A′ approximates the solution for Ridge Regression (Tikhonov, 1963; Hoerl & Kennard, 1970).",1. Introduction,[0],[0]
"In Ridge Regression we aim to solve minz (∑ i(yi − zTxi)2 + w2‖z‖2 ) , which means we penalize vectors whose l2-norm is large.",1. Introduction,[0],[0]
"In general, it is not known how to derive t-values from Ridge regression, and the literature on deriving confidence intervals solely from Ridge regression is virtually non-existent.",1. Introduction,[0],[0]
"Indeed, prior to our work there was no need for such calculations, as access to the data was (in general) freely given, and so deriving confidence intervals could be done by appealing back to OLS.",1. Introduction,[0],[0]
"We too are unable to derive approximated t-values in the general case, but under additional assumptions about the data — which admittedly depend in part on ‖β‖ and so cannot be verified solely from the data — we show that solving the linear regression problem on RA′ allows us to give confidence intervals for βj , thus correctly determining the correlation’s sign.
",1. Introduction,[0],[0]
"In Section 5 we discuss the “Analyze Gauss” algorithm (Dwork et al., 2014) that outputs a noisy version of a covariance of a given matrix using additive noise rather than multiplicative noise.",1. Introduction,[0],[0]
"Empirical work (Xi et al., 2011) shows that Analyze Gauss’s output might be non-PSD if the input has small singular values, and this results in truly bad regressors.",1. Introduction,[0],[0]
"Nonetheless, under additional conditions (that imply that the output is PSD), we derive confidence
bounds for Dwork et al’s “Analyze Gauss” algorithm.",1. Introduction,[0],[0]
"Finally, in Section 6 we experiment with the heuristic of computing the t-values directly from the outputs of Algorithms 1 and 2.",1. Introduction,[0],[0]
We show that Algorithm 1 is more “conservative” than Algorithm 2 in the sense that it tends to not reject the null-hypothesis until the number of examples is large enough to give a very strong indication of rejection.,1. Introduction,[0],[0]
"In contrast, Algorithm 2 may wrongly rejects the null-hypothesis even when it is true.
Discussion.",1. Introduction,[0],[0]
"Some works have already looked at the intersection of differentially privacy and statistics (Dwork & Lei, 2009; Smith, 2011; Chaudhuri & Hsu, 2012; Duchi et al., 2013; Dwork et al., 2015) (especially focusing on robust statistics and rate of convergence).",1. Introduction,[0],[0]
"But only a handful of works studied the significance and power of hypotheses testing under differential privacy, without arguing that the noise introduced by differential privacy vanishes asymptotically (Vu & Slavkovic, 2009; Uhler et al., 2013; Wang et al., 2015; Rogers et al., 2016).",1. Introduction,[0],[0]
"These works are experimentally promising, yet they (i) focus on different statistical tests (mostly Goodness-of-Fit and Independence testing), (ii) are only able to prove results for the case of simple hypothesis-testing (a single hypothesis) with an efficient data-generation procedure through repeated simulations — a cumbersome and time consuming approach.",1. Introduction,[0],[0]
"In contrast, we deal with a composite hypothesis (we simultaneously reject all βs with sign(βj) 6= sign(β̂j)) by altering the confidence interval (or the critical region).
",1. Introduction,[0],[0]
One potential reason for avoiding confidence-interval analysis for differentially private hypotheses testing is that it does involve re-visiting existing results.,1. Introduction,[0],[0]
"Typically, in statistical inference the sole source of randomness lies in the underlying model of data generation, whereas the estimators themselves are a deterministic function of the dataset.",1. Introduction,[0],[0]
"In contrast, differentially private estimators are inherently random in their computation.",1. Introduction,[0],[0]
"Statistical inference that considers both the randomness in the data and the randomness in the computation is highly uncommon, and this work, to the best of our knowledge, is the first to deal with randomness in OLS hypothesis testing.",1. Introduction,[0],[0]
"We therefore strive in our analysis to separate the two sources of randomness — as in classic hypothesis testing, we use α to denote the bound on any bad event that depends solely on the homoscedastic model, and use ν to bound any bad event that depends on the randomized algorithm.4 (Thus, any result which is originally of the form “α-reject the null-hypothesis” is now converted into a result “(α+ν)-reject the null hypothesis”.)
",1. Introduction,[0],[0]
"4Or any randomness in generating the feature matrixX which standard OLS theory assumes to be fixed, see Theorems 2.2 and 3.3.",1. Introduction,[0],[0]
Notation.,2. Preliminaries and OLS Background,[0],[0]
"Throughout this paper, we use lower-case letters to denote scalars (e.g., yi or ei); bold characters to denote vectors; and UPPER-case letters to denote matrices.",2. Preliminaries and OLS Background,[0],[0]
"The l-dimensional all zero vector is denoted 0l, and the l × m-matrix of all zeros is denoted 0l×m.",2. Preliminaries and OLS Background,[0],[0]
We use e to denote the specific vector y − Xβ in our model; and though the reader may find it a bit confusing but hopefully clear from the context — we also use ej and ek to denote elements of the natural basis (unit length vector in the direction of coordinate j or k).,2. Preliminaries and OLS Background,[0],[0]
"We use , δ to denote the privacy parameters of Algorithms 1 and 2, and use α and ν to denote confidence parameters (referring to bad events that hold w.p. ≤ α and ≤ ν resp.)",2. Preliminaries and OLS Background,[0],[0]
based on the homoscedastic model or the randomized algorithm resp.,2. Preliminaries and OLS Background,[0],[0]
"We also stick to the notation from Algorithm 1 and usew to denote the positive scalar for which w2 = 8B 2 (√ 2r ln(8/δ) + ln(8/δ)
) throughout this paper.",2. Preliminaries and OLS Background,[0],[0]
"We use standard notation for SVD composition of a matrix (M = UΣV T), its singular values and its Moore-Penrose inverse (M+).
",2. Preliminaries and OLS Background,[0],[0]
The Gaussian distribution.,2. Preliminaries and OLS Background,[0],[0]
"A univariate Gaussian N (µ, σ2) denotes the Gaussian distribution whose mean is µ and variance σ2.",2. Preliminaries and OLS Background,[0],[0]
Standard concentration bounds on Gaussians give that Pr[x > µ + 2σ,2. Preliminaries and OLS Background,[0],[0]
√ ln(2/ν)],2. Preliminaries and OLS Background,[0],[0]
< ν for any ν ∈,2. Preliminaries and OLS Background,[0],[0]
"(0, 1e ).",2. Preliminaries and OLS Background,[0],[0]
"A multivariate Gaussian N (µ,Σ) for some positive semi-definite Σ denotes the multivariate Gaussian distribution where the mean of the j-th coordinate is the µj and the covariance between coordinates j and k is Σj,k.",2. Preliminaries and OLS Background,[0],[0]
The PDF of such Gaussian is defined only on the subspace colspan(Σ).,2. Preliminaries and OLS Background,[0],[0]
"A matrix Gaussian distribution, denoted N (Ma×b, Ia×a, V ) has mean M , independence among its rows and variance V for each of its columns.",2. Preliminaries and OLS Background,[0],[0]
"We also require the following property of Gaussian random variables: Let X and Y be two random Gaussians s.t. X ∼ N (0, σ2) and Y ∼ N (0, λ2) where 1 ≤ σ 2
λ2 ≤",2. Preliminaries and OLS Background,[0],[0]
"c 2 for some c, then for any S ⊂ R we have
1 cPrx←Y [x ∈ S] ≤",2. Preliminaries and OLS Background,[0],[0]
Prx←X [x ∈ S] ≤,2. Preliminaries and OLS Background,[0],[0]
"cPrx←Y [x ∈ S/c] (see Proposition A.2).
",2. Preliminaries and OLS Background,[0],[0]
Additional Distributions.,2. Preliminaries and OLS Background,[0],[0]
We denote by Lap(σ) the Laplace distribution whose mean is 0 and variance is 2σ2.,2. Preliminaries and OLS Background,[0],[0]
"The χ2k-distribution, where k is referred to as the degrees of freedom of the distribution, is the distribution over the l2-norm squared of the sum of k independent normal Gaussians.",2. Preliminaries and OLS Background,[0],[0]
"That is, given i.i.d X1, . . .",2. Preliminaries and OLS Background,[0],[0]
", Xk ∼ N (0, 1) it holds that ζ def=",2. Preliminaries and OLS Background,[0],[0]
"(X1, X2, . . .",2. Preliminaries and OLS Background,[0],[0]
", Xk) ∼ N",2. Preliminaries and OLS Background,[0],[0]
"(0k, Ik×k), and ‖ζ‖2 ∼ χ2k.",2. Preliminaries and OLS Background,[0],[0]
"Existing tail bounds on the χ2k distribution (Laurent & Massart, 2000) give that
Pr [ ‖ζ‖2 ∈ ( √ k ± √ 2 ln(2/ν))2 ]",2. Preliminaries and OLS Background,[0],[0]
≥ 1 − ν.,2. Preliminaries and OLS Background,[0],[0]
"The Tk-
distribution, where k is referred to as the degrees of freedom of the distribution, denotes the distribution over the reals created by independently sampling Z ∼ N (0, 1) and
‖ζ‖2 ∼ χ2k, and taking the quantity Z/ √ ‖ζ‖2/",2. Preliminaries and OLS Background,[0],[0]
k.,2. Preliminaries and OLS Background,[0],[0]
"It is a known fact that Tk k→∞→ N (0, 1), thus it is a common practice to apply Gaussian tail bounds to the Tk-distribution when k is sufficiently large.
",2. Preliminaries and OLS Background,[0],[0]
Differential Privacy.,2. Preliminaries and OLS Background,[0],[0]
"In this work, we deal with input in the form of a n × d-matrix with each row bounded by a l2-norm of B. Two inputs A and A′ are called neighbors if they differ on a single row.",2. Preliminaries and OLS Background,[0],[0]
"Definition 2.1 ((Dwork et al., 2006a)).",2. Preliminaries and OLS Background,[0],[0]
"An algorithm ALG which maps (n × d)-matrices into some range R is ( , δ)differential privacy it holds that Pr[ALG(A) ∈ S] ≤ e Pr[ALG(A′) ∈ S]",2. Preliminaries and OLS Background,[0],[0]
"+ δ for all neighboring inputs A and A′ and all subsets S ⊂ R.
Background on OLS.",2. Preliminaries and OLS Background,[0],[0]
"For the unfamiliar reader, we give here a very brief overview of the main points in OLS.",2. Preliminaries and OLS Background,[0],[0]
"Further details, explanations and proofs appear in Section A.3.
",2. Preliminaries and OLS Background,[0],[0]
"We are given n observations {(xi, yi)}ni=1 where ∀i,xi ∈",2. Preliminaries and OLS Background,[0],[0]
Rp and yi ∈,2. Preliminaries and OLS Background,[0],[0]
R. We assume the existence of β ∈,2. Preliminaries and OLS Background,[0],[0]
Rp s.t.,2. Preliminaries and OLS Background,[0],[0]
"the label yi was derived by yi = βTxi + ei where ei ∼ N (0, σ2) independently (also known as the homoscedastic Gaussian model).",2. Preliminaries and OLS Background,[0],[0]
We use the matrix notation where X denotes the (n × p)- feature matrix and y denotes the labels.,2. Preliminaries and OLS Background,[0],[0]
"We assume X has full rank.
",2. Preliminaries and OLS Background,[0],[0]
"The parameters of the model are therefore β and σ2, which we set to discover.",2. Preliminaries and OLS Background,[0],[0]
"To that end, we minimize minz ‖y",2. Preliminaries and OLS Background,[0],[0]
"− Xz‖2 and have
β̂ =",2. Preliminaries and OLS Background,[0],[0]
"(XTX)−1XTy = (XTX)−1XT(Xβ + e) = β +X+e (1) ζ = y −Xβ̂ = (Xβ + e)−X(β +X+e) = (I −XX+)e (2)
",2. Preliminaries and OLS Background,[0],[0]
"And then for any coordinate j the t-value, which is the quantity t(βj) def =
β̂j−βj√ (XTX)−1j,j · ‖ζ‖√ n−p , is
distributed according to Tn−p-distribution.",2. Preliminaries and OLS Background,[0],[0]
"I.e., Pr [ β̂ and ζ satisfying t(βj) ∈ S ] = ∫ S PDFTn−p(x)dx for any measurable S ⊂ R. Thus t(βj) describes the likelihood of any βj — for any z ∈ R we can now give an estimation of how likely it is to have βj = z (which is PDFTn−p(t(z))), and this is known as t-test for the value z.",2. Preliminaries and OLS Background,[0],[0]
"In particular, given 0 < α < 1, we denote cα as the number for which the interval (−cα, cα) contains a probability mass of 1 − α from the Tn−p-distribution.",2. Preliminaries and OLS Background,[0],[0]
And so we derive a corresponding confidence interval,2. Preliminaries and OLS Background,[0],[0]
"Iα centered at β̂j where βj ∈ Iα with confidence of level of 1− α.
",2. Preliminaries and OLS Background,[0],[0]
"Of particular importance is the quantity t0 def = t(0) =
β̂j √ n−p ‖ζ‖ √
(XTX)−1j,j
,since if there is no correlation between xj
and y then the likelihood of seeing β̂j depends on the ratio of its magnitude to its standard deviation.",2. Preliminaries and OLS Background,[0],[0]
"As mentioned earlier, since Tk k→∞→ N (0, 1), then rather than viewing
this t0 as sampled from a Tn−p-distribution, it is common to think of t0 as a sample from a normal GaussianN (0, 1).",2. Preliminaries and OLS Background,[0],[0]
"This allows us to associate t0 with a p-value, estimating the event “βj and β̂j have different signs.”",2. Preliminaries and OLS Background,[0],[0]
"Specifically, given α ∈ (0, 1/2), we α-reject the null hypothesis if p0 < α.",2. Preliminaries and OLS Background,[0],[0]
"Let τα be the number s.t. Φ(τα) = ∫∞ τα 1√ 2π e−x
2/2dx = α.",2. Preliminaries and OLS Background,[0],[0]
This means we α-reject the null hypothesis when |t0| > τα.,2. Preliminaries and OLS Background,[0],[0]
We now lower bound the number of i.i.d sample points needed in order to α-reject the null hypothesis.,2. Preliminaries and OLS Background,[0],[0]
"This bound is our basis for comparison between standard OLS and the differentially private version.5
Theorem 2.2.",2. Preliminaries and OLS Background,[0],[0]
Fix any positive definite matrix Σ ∈ Rp×p and any ν ∈,2. Preliminaries and OLS Background,[0],[0]
"(0, 12 ).",2. Preliminaries and OLS Background,[0],[0]
Fix parameters β ∈ R p and σ2 and a coordinate j s.t. βj 6= 0.,2. Preliminaries and OLS Background,[0],[0]
"Let X be a matrix whose n rows are i.i.d samples from N (0,Σ), and y be a vector where yi − (Xβ)i is sampled i.i.d from N (0, σ2).",2. Preliminaries and OLS Background,[0],[0]
"Fix α ∈ (0, 1).",2. Preliminaries and OLS Background,[0],[0]
Then w.p. ≥ 1 − α,2. Preliminaries and OLS Background,[0],[0]
− ν we have that OLS’s (1 − α)-confidence interval has length O(cα √ σ2/(nσmin(Σ))),2. Preliminaries and OLS Background,[0],[0]
provided n ≥ C1(p + ln(1/ν)) for some sufficiently large constant C1.,2. Preliminaries and OLS Background,[0],[0]
"Furthermore, there exists a constant C2 such that w.p. ≥ 1 − α",2. Preliminaries and OLS Background,[0],[0]
"− ν OLS (correctly) rejects the null hypothesis provided n ≥ max { C1(p+ ln(1/ν)), p+ C2 σ2
β2j · c
2 α+τ 2 α
σmin(Σ)
} , where cα
is the number for which ∫ cα −cα PDFTn−p(x)dx = 1− α.",2. Preliminaries and OLS Background,[0],[0]
"In this section we deal with the output of Algorithm 1 in the special case where Algorithm 1 outputs matrix unaltered and so we work with RA.
",3. OLS over Projected Data,[0],[0]
"To clarify, the setting is as follows.",3. OLS over Projected Data,[0],[0]
We denote A = [X;y] the column-wise concatenation of the (n× (d− 1))-matrix X with the n-length vector y .,3. OLS over Projected Data,[0],[0]
"(Clearly, we can denote any column of A as y and any subset of the remaining columns as the matrix X .)",3. OLS over Projected Data,[0],[0]
We therefore denote the output RA = [RX;Ry] and for simplicity we denote M = RX and p = d,3. OLS over Projected Data,[0],[0]
− 1.,3. OLS over Projected Data,[0],[0]
We denote the SVD decomposition of X = UΣV,3. OLS over Projected Data,[0],[0]
T.,3. OLS over Projected Data,[0],[0]
So U is an orthonormal basis for the columnspan of X and as X is full-rank V is an orthonormal basis for Rp.,3. OLS over Projected Data,[0],[0]
"Finally, in our work we examine the linear regression problem derived from the projected data.",3. OLS over Projected Data,[0],[0]
"That is, we denote
β̃ = (XTRTRX)−1(RX)T(Ry) =",3. OLS over Projected Data,[0],[0]
β +,3. OLS over Projected Data,[0],[0]
"(RX)+Re (3)
σ̃2 = r
r − p ‖ζ̃‖2 , with ζ̃ = 1√ r Ry",3. OLS over Projected Data,[0],[0]
"− 1√ r (RX)β̃ (4)
We now give our main theorem, for estimating the t-values based on β̃ and σ̃.
5Theorem 2.2 also illustrates how we “separate” the two sources of privacy.",3. OLS over Projected Data,[0],[0]
"In this case, ν bounds the probability of bad events that depend to sampling the rows of X , and α bounds the probability of a bad event that depends on the sampling of the y coordinates.
",3. OLS over Projected Data,[0],[0]
Theorem 3.1.,3. OLS over Projected Data,[0],[0]
"Let X be a (n × p)-matrix, and parameters β ∈",3. OLS over Projected Data,[0],[0]
"Rp and σ2 are such that we generate the vector y = Xβ + e with each coordinate of e sampled independently from N (0, σ2).",3. OLS over Projected Data,[0],[0]
Assume Algorithm 1 projects the matrix A =,3. OLS over Projected Data,[0],[0]
[X;y] without altering it.,3. OLS over Projected Data,[0],[0]
Fix ν ∈,3. OLS over Projected Data,[0],[0]
"(0, 1/2) and r = p + Ω(ln(1/ν)).",3. OLS over Projected Data,[0],[0]
"Fix coordinate j. Then we have that w.p. ≥ 1 − ν deriving β̃ and σ̃2 as in Equations (3) and (4), the pivot quantity t̃(βj)",3. OLS over Projected Data,[0],[0]
"=
β̃j−βj σ̃ √
(XTRTRX)−1j,j
has a
distribution D satisfying e−aPDFTr−p(x) ≤ PDFD(x) ≤ eaPDFTr−p(e
−ax) for any x ∈ R, where we denote a = r−p n−p .
",3. OLS over Projected Data,[0],[0]
"The implications of Theorem 3.1 are immediate: all estimations one can do based on the t-values from the true data X,y , we can now do based on t̃ modulo an approximation factor of exp( r−pn−p ).",3. OLS over Projected Data,[0],[0]
"In particular, Theorem 3.1 enables us to deduce a corresponding confidence interval based on β̃ .
",3. OLS over Projected Data,[0],[0]
Corollary 3.2.,3. OLS over Projected Data,[0],[0]
"In the same setting as in Theorem 3.1, w.p. ≥ 1− ν we have the following.",3. OLS over Projected Data,[0],[0]
"Fix any α ∈ (0, 12 ).",3. OLS over Projected Data,[0],[0]
Let c̃α denote the number s.t.,3. OLS over Projected Data,[0],[0]
"the interval (c̃α,∞) contains α2 e −a
probability mass of the Tr−p-distribution.",3. OLS over Projected Data,[0],[0]
"Then Pr[βj ∈( β̃j ± ea · c̃α · σ̃ √ (XTRTRX)−1j,j ) ]",3. OLS over Projected Data,[0],[0]
≥ 1− α.,3. OLS over Projected Data,[0],[0]
"6
We compare the confidence interval of Corollary 3.2 to the confidence interval of the standard OLS model, whose length is cα ‖ζ‖√ n−p √ (XTX)−1j,j .",3. OLS over Projected Data,[0],[0]
"As R is a JLmatrix, known results regarding the JL transform give
that ‖ζ̃‖ = Θ (‖ζ‖), and that √
(r − p)(XTRTRX)−1j,j = Θ (√
(XTX)−1j,j
) .",3. OLS over Projected Data,[0],[0]
"We therefore have that
σ̃ √ (XTRTRX)−1j,j = ‖ζ̃‖ √ r√
r−p √ (XTRTRX)−1j,j =√
r·(n−p) (r−p)2 · Θ ( ‖ζ‖√ n−p √ (XTX)−1j,j ) .",3. OLS over Projected Data,[0],[0]
So for values of r for which rr−p = Θ(1),3. OLS over Projected Data,[0],[0]
"we get that the confidence interval
of Theorem 3.1 is a factor of Θ ( c̃α cα √ n−p r−p ) -larger than the standard OLS confidence interval.",3. OLS over Projected Data,[0],[0]
"Observe that when α = Θ(1), which is the common case, the dominating factor is √ (n− p)/(r − p).",3. OLS over Projected Data,[0],[0]
"This bound intuitively makes sense: we have contracted n observations to r observations, hence our model is based on confidence intervals derived from Tr−p rather than Tn−p.
",3. OLS over Projected Data,[0],[0]
"In the supplementary material we give further discussion, in which we compare our work to the more straight-forward bounds one gets by “plugging in” Sarlos’ work (2006); and we also compare ourselves to the bounds derived from alternative works in differentially private linear regression.
",3. OLS over Projected Data,[0],[0]
"6Moreover, this interval is essentially optimal: denote d̃α s.t the interval (d̃α,∞) contains α2 e r−p n−p prob-
ability mass of the Tr−p-distribution.",3. OLS over Projected Data,[0],[0]
"Then Pr[βj ∈( β̃j ± d̃α · σ̃ √ (XTRTRX)−1j,j ) ]",3. OLS over Projected Data,[0],[0]
"≤ 1− α.
",3. OLS over Projected Data,[0],[0]
Rejecting the Null Hypothesis.,3. OLS over Projected Data,[0],[0]
"Due to Theorem 3.1, we can mimic OLS’ technique for rejecting the null hypothesis.",3. OLS over Projected Data,[0],[0]
"I.e., we denote t̃0 = β̃j
σ̃ √
(XTRTRX)−1j,j
and re-
ject the null-hypothesis if indeed the associated p̃0, denoting p-value of the slightly truncated e− r−p n−p t̃0, is below α · e− r−p n−p .",3. OLS over Projected Data,[0],[0]
Much like Theorem 2.2 we now establish a lower bound on n,3. OLS over Projected Data,[0],[0]
"so that w.h.p we end up (correctly) rejecting the null-hypothesis.
",3. OLS over Projected Data,[0],[0]
Theorem 3.3.,3. OLS over Projected Data,[0],[0]
Fix a positive definite matrix Σ ∈ Rp×p.,3. OLS over Projected Data,[0],[0]
Fix parameters,3. OLS over Projected Data,[0],[0]
β ∈,3. OLS over Projected Data,[0],[0]
Rp and σ2 > 0 and a coordinate j s.t. βj 6= 0.,3. OLS over Projected Data,[0],[0]
"Let X be a matrix whose n rows are sampled i.i.d from N (0p,Σ).",3. OLS over Projected Data,[0],[0]
Let y be a vector s.t. yi,3. OLS over Projected Data,[0],[0]
"− (Xβ)i is sampled i.i.d from N (0, σ2).",3. OLS over Projected Data,[0],[0]
Fix ν ∈,3. OLS over Projected Data,[0],[0]
"(0, 1/2) and α ∈ (0, 1/2).",3. OLS over Projected Data,[0],[0]
"Then there exist constants C1, C2, C3 and C4 such that when we run Algorithm 1 over [X;y] with parameter r w.p. ≥ 1 − α",3. OLS over Projected Data,[0],[0]
"− ν we (correctly) reject the null hypothesis using p̃0 (i.e., Algorithm 1 returns matrix unaltered and we can estimate t̃0 and verify that indeed p̃0 < α · e − r−pn−p ) provided
r ≥",3. OLS over Projected Data,[0],[0]
"p + max { C1 σ2(c̃2α+τ̃ 2 α)
β2jσmin(Σ) , C2 ln(1/ν)
} , and n ≥
max { r, C3
w2 min{σmin(Σ),σ2} , C4p ln(1/ν) }
where
c̃α, τ̃α defined s.t.",3. OLS over Projected Data,[0],[0]
"PrX∼Tr−p [X > c̃α/e r−p n−p ] = PrX∼N (0,1)[X > τ̃α/e r−p n−p ] = α2 e − r−pn−p .",3. OLS over Projected Data,[0],[0]
"Comparing the lower bound on n given by Theorem 3.3 to the bound of Theorem 2.2, we have that the data-dependent bound of Ω ( (c̃α+τ̃α) 2σ2
β2jσmin(Σ)
) should now hold for r rather than
n.","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"Yet, Theorem 3.3 also introduces an additional dependency between n and r: we require n = Ω(w 2
σ2 + w2 σmin(Σ) )
(since otherwise we do not have σmin(A) w and Algorithm 1 might alterA before projecting it) and by definition w2 is proportional to √ r ln(1/δ)/ .","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
This is precisely the focus of our discussion in this subsection.,"3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"We would like to set r’s value as high as possible — the larger r is, the more observations we have in RA and the better our confidence bounds (that depend on Tr−p) are — while satisfying n = Ω( √ r
·min{σ2,σmin(Σ)} ).
","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"Recall that if each sample point is drawn i.i.d x ∼ N (0p,Σ), then each sample (xi ◦ yi) is sampled from N (0p+1,ΣA) for ΣA defined in the proof of Theorem 3.3,
that is: ΣA = (
Σ Σβ
βTΣ σ2+βTΣβ
) .","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"So, Theo-
rem 3.3 gives the lower bound r − p = Ω ( σ2(c̃α+τ̃α) 2
β2jσmin(Σ) ) and the following lower bounds on n: n","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"≥ r and
n = Ω
( B2( √ r ln(1/δ)+ln(1/δ))
σmin(ΣA)
) , which means r =
min { n,
2σ2min(ΣA) B4 ln(1/δ) (n− ln(1/δ))
2 }
.","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"This discussion culminates in the following corollary.
","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
Corollary 3.4.,"3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"Denoting L̃B2.2 = σ 2(c̃α+τ̃α) 2
β2jσmin(Σ) , we thus conclude that if n − p ≥ Ω ( L̃B2.2 ) and n =
Ω ( B2 ln(1/δ) σmin(ΣA) · √ L̃B2.2 ) , then the result of Theorem 3.3
holds by setting r = min { n,
2σ2min(ΣA) B4 ln(1/δ) (n− ln(1/δ))
2 }
.
","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"It is interesting to note that when we know ΣA, we also have a bound on B. Recall ΣA, the variance of the Gaussian (x ◦ y).","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"Since every sample is an independent draw from N (0p+1,ΣA) then we have an upper bound of B2 ≤ log(np)σmax(ΣA).","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
So our lower bound on n,"3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"(using κ(ΣA) to denote the condition number of ΣA) is given by
n","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"≥ max { Ω ( L̃B2.2 ) , Ω̃ ( κ(ΣA) ln(1/δ) ·","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"√ L̃B2.2 )} .
","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"Observe, overall this result is similar in nature to many other results in differentially private learning (Bassily et al., 2014) which are of the form “without privacy, in order to achieve a total loss of ≤ η","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
we have a sample complexity bound of some Nη; and with differential privacy the sample complexity increases to Nη + Ω( √ Nη/ ).”,"3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"However,
there’s a subtlety here worth noting.","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
"L̃B2.2 is proportional to 1σmin(ΣA) but not to κ(ΣA) = σmax(ΣA) σmin(ΣA)
.","3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
The additional dependence on σmax follows from the fact that differential privacy adds noise proportional to the upper bound on the norm of each row.,"3.1. Setting the Value of r, Deriving a Bound on n",[0],[0]
We now turn to deal with the case that our matrix does not pass the if-condition of Algorithm 1.,4. Projected Ridge Regression,[0],[0]
"In this case, the matrix is appended with a d × d-matrix which is wId×d.",4. Projected Ridge Regression,[0],[0]
"De-
noting A′ =",4. Projected Ridge Regression,[0],[0]
"[
A w · Id×d
] we have that the algorithm’s
output is RA′. Similarly to before, we are going to denote d = p+ 1 and decompose A =",4. Projected Ridge Regression,[0],[0]
"[X;y] with X ∈ Rn×p and y ∈ Rn, with the standard assumption of y = Xβ + e and ei sampled i.i.d from N (0, σ2).",4. Projected Ridge Regression,[0],[0]
We now need to introduce some additional notation.,4. Projected Ridge Regression,[0],[0]
We denote the appended matrix and vectors X ′,4. Projected Ridge Regression,[0],[0]
and y ′ s.t. A′ =,4. Projected Ridge Regression,[0],[0]
[X ′;y ′].,4. Projected Ridge Regression,[0],[0]
"And so, using the output RA′ of Algorithm 1, we solve the linear regression problem derived from 1√
r RX ′ and 1√ r Ry ′. I.e., we set
β ′ =",4. Projected Ridge Regression,[0],[0]
(X ′TRTRX ′)−1(RX ′)T(Ry ′) ζ ′,4. Projected Ridge Regression,[0],[0]
"= 1√
r",4. Projected Ridge Regression,[0],[0]
"(Ry ′ −RX ′β ′) (5)
Sarlos’ results (2006) regarding the Johnson Lindenstrauss transform give that, when R has sufficiently many rows, solving the latter optimization problem gives a good approximation for the solution of the optimization problem βR",4. Projected Ridge Regression,[0],[0]
= arg minz ‖y ′,4. Projected Ridge Regression,[0],[0]
− X ′z‖2 = arg minz ( ‖y −Xz‖2 + w2‖z‖2 ) .,4. Projected Ridge Regression,[0],[0]
"The latter problem is
known as the Ridge Regression problem.",4. Projected Ridge Regression,[0],[0]
"Invented in the 60s (Tikhonov, 1963; Hoerl & Kennard, 1970), Ridge Regression is often motivated from the perspective of penalizing linear vectors whose coefficients are too large.",4. Projected Ridge Regression,[0],[0]
It is also often applied in the case where X doesn’t have full rank or is close to not having full-rank: one can show that the minimizer βR =,4. Projected Ridge Regression,[0],[0]
"(XTX + w2Ip×p)−1XTy is the unique solution of the Ridge Regression problem and that the RHS is always well-defined.
",4. Projected Ridge Regression,[0],[0]
"While the solution of the Ridge Regression problem might have smaller risk than the OLS solution, it is not known how to derive t-values and/or reject the null hypothesis under Ridge Regression (except for using X to manipulate βR back into β̂ =",4. Projected Ridge Regression,[0],[0]
(XTX)−1XTy and relying on OLS).,4. Projected Ridge Regression,[0],[0]
"In fact, prior to our work there was no need for such analysis!",4. Projected Ridge Regression,[0],[0]
"For confidence intervals one could just use the standard OLS, because access to X and y was given.
",4. Projected Ridge Regression,[0],[0]
"Therefore, much for the same reason, we are unable to derive t-values under projected Ridge Regression.7 Clearly, there are situations where such confidence bounds simply cannot be derived.",4. Projected Ridge Regression,[0],[0]
"Nonetheless, under additional assumptions about the data, our work can give confidence intervals for βj , and in the case where the interval doesn’t intersect the origin — assure us that sign(β′j) = sign(βj) w.h.p.",4. Projected Ridge Regression,[0],[0]
"This is detailed in the supplementary material.
",4. Projected Ridge Regression,[0],[0]
"To give an overview of our analysis, we first discuss a model where e = y",4. Projected Ridge Regression,[0],[0]
"− Xβ is fixed (i.e., the data is fixed and the algorithm is the sole source of randomness), and prove that in this model β′ is as an approximation to β̂ .
",4. Projected Ridge Regression,[0],[0]
Theorem 4.1.,4. Projected Ridge Regression,[0],[0]
Fix X ∈ Rn×p and y ∈ R. Define β̂ = X+y and ζ =,4. Projected Ridge Regression,[0],[0]
(I − XX+)y .,4. Projected Ridge Regression,[0],[0]
Let RX ′ = M ′ and Ry ′ denote the result of applying Algorithm 1 to the matrixA =,4. Projected Ridge Regression,[0],[0]
[X;y] when the algorithm appends the data with a w · I matrix.,4. Projected Ridge Regression,[0],[0]
"Fix a coordinate j and any α ∈ (0, 1/2).",4. Projected Ridge Regression,[0],[0]
When computing β ′,4. Projected Ridge Regression,[0],[0]
and ζ ′,4. Projected Ridge Regression,[0],[0]
"as in (5), we have that w.p. ≥ 1",4. Projected Ridge Regression,[0],[0]
− α it holds that β̂j ∈,4. Projected Ridge Regression,[0],[0]
( β′j ± c′α‖ζ ′‖,4. Projected Ridge Regression,[0],[0]
√ r r−p · (M ′TM ′) −1,4. Projected Ridge Regression,[0],[0]
"j,j
) where c′α denotes the number such that (−c′α, c′α) contains 1− α mass of the Tr−p-distribution.
",4. Projected Ridge Regression,[0],[0]
"However, our goal remains to argue that β′j serves as a good approximation for βj .",4. Projected Ridge Regression,[0],[0]
"To that end, we combine the standard OLS confidence interval — which says that w.p. ≥ 1−α over the randomness of picking e in the homoscedas-
tic model we have |βj − β̂j | ≤",4. Projected Ridge Regression,[0],[0]
"cα‖ζ‖ √ (XTX)−1j,j n−p — with the confidence interval of Theorem 4.1 above, and denoting I = cα ‖ζ‖√ n−p",4. Projected Ridge Regression,[0],[0]
√,4. Projected Ridge Regression,[0],[0]
(,4. Projected Ridge Regression,[0],[0]
"XTX)−1j,j + c ′",4. Projected Ridge Regression,[0],[0]
α ‖ζ ′‖√,4. Projected Ridge Regression,[0],[0]
"r−p √ r(M ′TM ′)−1j,j we have that Pr[|β′j − βj | = O(I)]",4. Projected Ridge Regression,[0],[0]
≥ 1 − α.,4. Projected Ridge Regression,[0],[0]
And 7Note: The naı̈ve approach of using RX ′,4. Projected Ridge Regression,[0],[0]
"and Ry ′ to interpolate RX and Ry and then apply Theorem 3.1 using these estimations of RX and Ry ignores the noise added from appending the matrix A into A′, and therefore leads to inaccurate estimations of the t-values.
",4. Projected Ridge Regression,[0],[0]
"so, in summary, in Section C we give conditions under which the length of the interval I is dominated by the c′α ‖ζ ′‖√",4. Projected Ridge Regression,[0],[0]
"r−p √ r(M ′TM ′)−1j,j factor derived from Theorem 4.1.",4. Projected Ridge Regression,[0],[0]
In this section we analyze the “Analyze Gauss” algorithm of Dwork et al (2014).,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Algorithm 2 works by adding random Gaussian noise to ATA, where the noise is symmetric with each coordinate above the diagonal sampled i.i.d from N (0,∆2) with ∆2 = O ( B4 log(1/δ) 2 ) .",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Using the same no-
tation for a sub-matrix of A as [X;y] as before, we denote
the output of Algorithm 2 as  X̃TX X̃Ty ỹTX ỹTy .",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Thus, we approximate β and ‖ζ‖ by β̃ = ( X̃TX )−1",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
X̃Ty,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"and
‖̃ζ‖2 = ỹTy",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
− 2 ỹTX β̃ + β̃ T X̃TX β̃ resp.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"We now argue
that it is possible to use β̃j",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
and ‖̃ζ‖2 to get a confidence interval for βj under certain conditions.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
Theorem 5.1.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Fix α, ν ∈ (0, 12 ).",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Assume that there exists η ∈ (0, 12 ) s.t. σmin(X",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
TX) > ∆,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
√ p ln(1/ν)/η.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Under the homoscedastic model, given β and σ2, if we assume also that ‖β‖ ≤ B and ‖β̂‖ =",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"‖(XTX)−1XTy‖ ≤ B, then w.p. ≥ 1− α− ν",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"it holds that
∣∣∣βj − β̃j∣∣∣ is at most O ( ρ · √( X̃TX −1",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"j,j + ∆",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
√ p ln(1/ν) · X̃TX −2,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"j,j ) ln(1/α)
+ ∆",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
√ X̃TX −2,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"j,j · ln(1/ν) · (B √ p+ 1) )",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"where ρ is w.h.p an upper bound on σ (details appear in the Supplementary material).
",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
Note that the assumptions that ‖β‖ ≤ B and ‖β̂‖,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
≤,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
B are fairly benign once we assume each row has bounded l2-norm.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
The key assumption is that XTX is well-spread.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Yet in the model where each row in X is sampled i.i.d fromN (0,Σ), this assumption merely means that n is large enough — namely, that n = Ω̃(∆ √ p ln(1/ν)
η·σmin(Σ) ).
6.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Experiment: t-Values of Output
Goal.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
We set to experiment with the outputs of Algorithms 1 and 2.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
While Theorem 3.1 guarantees that computing the t-value from the output of Algorithm 1 in the matrix unaltered case does give a good approximation of the t-value – we were wondering if by computing the t-value directly from the output we can (a) get a good approximation of the true (non-private) t-value and (b) get the same “higher-level conclusion” of rejecting the nullhypothesis.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"The answers are, as ever, mixed.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"The two main
observations we do notice is that both algorithms improve as the number of examples increases, and that Algorithm 1 is more conservative then Algorithm 2.
Setting.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
We tested both algorithms in two settings.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
The first is over synthetic data.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Much like the setting in Theorems 2.2 and 3.3, X was generated using p = 3 independent normal Gaussian features, and y was generated using the homoscedastic model.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"We chose β = (0.5,−0.25, 0) so the first coordinate is twice as big a the second but of opposite sign, and moreover, y is independent of the 3rd feature.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"The variance of the label is also set to 1, and so the variance of the homosedastic noise equals to σ2 = 1− (0.5)2 − (−0.25)2.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"The number of observations n ranges from n = 1000 to n = 100000.
",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
The second setting is over real-life data.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"We ran the two algorithms over diabetes dataset collected over ten years (1999-2008) taken from the UCI repository (Strack et al., 2014).",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"We truncated the data to 4 attributes: sex (binary), age (in buckets of 10 years), number medications (numeric, 0-100), and a diagnosis (numeric, 0-1000).",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Naturally, we added a 5th column of all-1 (intercept).",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Omitting any entry with missing or non-numeric values on these nine attributes we were left with N = 91842 entries, which we shuffled and fed to the algorithm in varying sizes — from n = 30, 000 to n = 90, 000.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
Running OLS over the entire N observation yields β,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"≈ (14.07, 0.54,−0.22, 482.59), and t-Values of (10.48, 1.25,−2.66, 157.55).
",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
The Algorithms.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"We ran a version of Algorithm 1 that uses a DP-estimation of σmin, and finds the largest r the we can use without altering the input, yet if this r is below 25 then it does alter the input and approximates Ridge regression.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
We ran Algorithm 2 verbatim.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
We set = 0.25 and δ = 10−6.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"We repeated each algorithm 100 times.
Results.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
We plot the t-values we get from Algorithms 1 and 2 and decide to reject the null-hypothesis based on tvalue larger than 2.8 (which corresponds to a fairly conservative p-value of 0.005).,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Not surprisingly, as n increases, the t-values become closer to their expected value – the tvalue of Analyze Gauss is close to the non-private t-value and the t-value from Algorithm 1 is a factor of √ r n smaller as detailed above (see after Corollary 3.2).",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"As a result, when the null-hypothesis is false, Analyze Gauss tends to produce larger t-values (and thus reject the null-hypothesis) for values of n under which Algorithm 1 still does not reject, as shown in Figure 1a.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"This is exacerbated in real data setting, where its actual least singular value (≈ 500) is fairly small in comparison to its size (N = 91842).
",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"However, what is fairly surprising is the case where the null-hypothesis should not be rejected — since βj = 0",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
(in the synthetic case) or its non-private t-value is close to 0 (in the real-data case).,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Here, the Analyze Gauss’ tvalue approximation has fairly large variance, and we still
get fairly high (in magnitude) t-values.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"As the result, we falsely reject the null-hypothesis based on the t-value of Analyze Gauss quite often, even for large values of n. This is shown in Figure 1b.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Additional figures (including plotting the distribution of the t-value approximations) appear in the supplementary material.
",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
The results show that t-value approximations that do not take into account the inherent randomness in the DPalgorithms lead to erroneous conclusions.,5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"One approach would be to follow the more conservative approach we advocate in this paper, where Algorithm 1 may allow you to get true approximation of the t-values and otherwise reject the null-hypothesis only based on the confidence interval (of Algorithm 1 or 2) not intersecting the origin.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"Another approach, which we leave as future work, is to replace the T -distribution with a new distribution, one that takes into account the randomness in the estimator as well.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"This, however, has been an open and long-standing challenge since the first works on DP and statistics (see (Vu & Slavkovic, 2009; Dwork & Lei, 2009)) and requires we move into non-asymptotic hypothesis testing.",5. Confidence Intervals for “Analyze Gauss”,[0],[0]
"The bulk of this work was done when the author was a postdoctoral fellow at Harvard University, supported by NSF grant CNS-123723; and also an unpaid collaborator on NSF grant 1565387.",Acknowledgements,[0],[0]
"The author wishes to wholeheartedly thank Prof. Salil Vadhan, for his tremendous help in shaping this paper.",Acknowledgements,[0],[0]
"The author would also like to thank Prof. Jelani Nelson and the members of the “Privacy Tools for Sharing Research Data” project at Harvard University (especially James Honaker, Vito D’Orazio, Vishesh Karwa, Prof. Kobbi Nissim and Prof. Gary King) for many helpful discussions and suggestions; as well as Abhradeep Thakurta for clarifying the similarity between our result.",Acknowledgements,[0],[0]
"Lastly the author thanks the anonymous referees for many helpful suggestions in general and for a reference to (Ullman, 2015) in particular.",Acknowledgements,[0],[0]
"Due to space constraint, a few details from the introductory parts (Sections 1,2) were omitted.",A. Extended Introductory Discussion,[0],[0]
We bring them in this appendix.,A. Extended Introductory Discussion,[0],[0]
We especially recommend the uninformed reader to go over the extended OLS background we provide in Appendix A.3.,A. Extended Introductory Discussion,[0],[0]
Theorem A.1.,A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"Algorithm 1 is ( , δ)-differentially private.
",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
Proof.,A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"The proof of the theorem is based on the fact the Algorithm 1 is the result of composing the differentially private Propose-Test-Release algorithm of (Dwork & Lei, 2009) with the differentially private analysis of the Johnson-Lindenstrauss transform of (Sheffet, 2015).
",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"More specifically, we use Theorem B.1 from (Sheffet, 2015) that states that given a matrix A whose all of its singular values at greater than T ( , δ) where T ( , δ)2 = 2B2 (√ 2r ln(4/δ) + 2 ln(4/δ) ) , publishing RA is ( , δ)-
differentially private for a r-row matrix R whose entries sampled are i.i.d normal Gaussians.",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"Since we have that all of the singular values of A′ are greater than w (as specified in Algorithm 1), outputtingRA′ is ( /2, δ/2)-differentially private.",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"The rest of the proof boils down to showing that (i) the if-else-condition is ( /2, 0)-differentially private and that (ii) w.p. ≤ δ/2 any matrix A whose smallest singular value is smaller than w passes the if-condition (step 3).",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"If both these facts hold, then knowing whether we pass the if-condition or not is ( /2)-differentially private and the output of the algorithm is ( /2, δ)-differentially private, hence basic composition gives the overall bound of ( , δ)differential privacy.
",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"To prove (i) we have that for any pair of neighboring matricesA andB that differ only on the i-th row, denoted ai and bi resp., we have BTB − bibTi = ATA − aiaTi .",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"Applying Weyl’s inequality we have
σmin(B TB) ≤ σmin(BTB − bibTi )",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"+ σmax(bibTi )
≤ σmin(ATA) + σmax(aiaTi ) + σmax(bibTi )",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"≤ σmin(ATA) + 2B2
hence |σmin(A)2−σmin(B)2| ≤ 2B2, so addingLap( 4B 2
) is ( /2)-differentially private.
",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"To prove (ii), note that by standard tail-bounds on the Laplace distribution we have that Pr[Z <",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"− 4B2 ln(1/δ)
]",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
≤ δ 2 .,A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"Therefore, w.p. 1 − δ/2 it holds that
any matrix A that passes the if-test of the algorithm must have σmin(A)2 > w2.",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
Also note that a similar argument shows that for any 0 <,A.1. Proof Of Privacy of Algorithm 1,[0],[0]
"β < 1, any matrix A s.t. σmin(A) 2 > w2 +",A.1. Proof Of Privacy of Algorithm 1,[0],[0]
4B 2 ln(1/β) passes the if-condition of the algorithm w.p. 1− β.,A.1. Proof Of Privacy of Algorithm 1,[0],[0]
Linear Algebra and Pseudo-Inverses.,A.2. Omitted Preliminary Details,[0],[0]
Given a matrix M we denote its SVD as M = USV T with U and V being orthonormal matrices and S being a non-negative diagonal matrix whose entries are the singular values of M .,A.2. Omitted Preliminary Details,[0],[0]
We use σmax(M) and σmin(M) to denote the largest and smallest singular value resp.,A.2. Omitted Preliminary Details,[0],[0]
"Despite the risk of confusion, we stick to the standard notation of using σ2 to denote the variance of a Gaussian, and use σj(M) to denote the j-th singular value of M .",A.2. Omitted Preliminary Details,[0],[0]
"We use M+ to denote the Moore-Penrose inverse of M , defined as M+ = V S−1UT where S−1 is a matrix with S−1j,j = 1/Sj,j for any j s.t.",A.2. Omitted Preliminary Details,[0],[0]
"Sj,j > 0.
",A.2. Omitted Preliminary Details,[0],[0]
The Gaussian Distribution.,A.2. Omitted Preliminary Details,[0],[0]
"A univariate Gaussian N (µ, σ2) denotes the Gaussian distribution whose mean is µ and variance σ2, with PDF(x) =",A.2. Omitted Preliminary Details,[0],[0]
"( √
2πσ2)−1 exp(−x−µ2σ2 ).",A.2. Omitted Preliminary Details,[0],[0]
Standard concentration bounds on Gaussians give that Pr[x > µ + 2σ,A.2. Omitted Preliminary Details,[0],[0]
√ ln(1/ν)],A.2. Omitted Preliminary Details,[0],[0]
< ν for any ν ∈,A.2. Omitted Preliminary Details,[0],[0]
"(0, 1e ).",A.2. Omitted Preliminary Details,[0],[0]
"A multivariate Gaussian N (µ,Σ) for some positive semi-definite Σ denotes the multivariate Gaussian distribution where the mean of the j-th coordinate is the µj and the co-variance between coordinates j and k is Σj,k. The PDF of such Gaussian is defined only on the subspace colspan(Σ), where for every x ∈ colspan(Σ) we have PDF(x) =(
(2π)rank(Σ) · d̃et(Σ) )",A.2. Omitted Preliminary Details,[0],[0]
"−1/2 exp ( − 12 (x −µ) TΣ+(x −µ) )
and d̃et(Σ) is the multiplication of all non-zero singular values of Σ.",A.2. Omitted Preliminary Details,[0],[0]
"A matrix Gaussian distribution denoted N (Ma×b, U, V ) has mean M , variance U on its rows and variance V on its columns.",A.2. Omitted Preliminary Details,[0],[0]
"For full rank U and V it holds that PDFN (M,U,V )(X) = (2π)−ab/2(det(U))−b/2(det(V ))−a/2",A.2. Omitted Preliminary Details,[0],[0]
· exp(− 12 trace ( V −1(X −M)TU−1(X −M) ) ).,A.2. Omitted Preliminary Details,[0],[0]
"In our case, we will only use matrix Gaussian distributions with N (Ma×b, Ia×a, V ) and so each row in this matrix is an i.i.d sample from a b-dimensional multivariate Gaussian N ((M)j→, V ).
",A.2. Omitted Preliminary Details,[0],[0]
We will repeatedly use the rules regarding linear operations on Gaussians.,A.2. Omitted Preliminary Details,[0],[0]
"That in, for any c, it holds that cN (µ, σ2) = N (c · µ, c2σ2).",A.2. Omitted Preliminary Details,[0],[0]
"For any C it holds that C · N (µ,Σ) = N (Cµ,CΣCT).",A.2. Omitted Preliminary Details,[0],[0]
"And for any C is holds thatN (M,U, V ) · C = N (MC,U,CTV C).",A.2. Omitted Preliminary Details,[0],[0]
"In particular, for any c (which can be viewed as a b×1-matrix) it holds thatN (M,U, V ) ·",A.2. Omitted Preliminary Details,[0],[0]
"c = N (Mc,U,cTV c) = N (Mc,cTV",A.2. Omitted Preliminary Details,[0],[0]
c,A.2. Omitted Preliminary Details,[0],[0]
·,A.2. Omitted Preliminary Details,[0],[0]
"U).
",A.2. Omitted Preliminary Details,[0],[0]
"We will also require the following proposition.
",A.2. Omitted Preliminary Details,[0],[0]
Proposition A.2.,A.2. Omitted Preliminary Details,[0],[0]
"Given σ2, λ2 s.t. 1 ≤ σ 2
λ2 ≤",A.2. Omitted Preliminary Details,[0],[0]
"c 2 for some
constant c, letX and Y be two random Gaussians s.t. X",A.2. Omitted Preliminary Details,[0],[0]
"∼ N (0, σ2) and Y ∼ N (0, λ2).",A.2. Omitted Preliminary Details,[0],[0]
It follows that 1cPDFY (x) ≤ PDFX(x) ≤ cPDFcY (x) for any x. Corollary A.3.,A.2. Omitted Preliminary Details,[0],[0]
"Under the same notation as in Proposition A.2, for any set S ⊂ R it holds that 1cPrx←Y",A.2. Omitted Preliminary Details,[0],[0]
[x ∈ S] ≤,A.2. Omitted Preliminary Details,[0],[0]
Prx←X [x ∈ S] ≤ cPrx←cY,A.2. Omitted Preliminary Details,[0],[0]
"[x ∈ S] =
cPrx←Y [x ∈ S/c]
Proof.",A.2. Omitted Preliminary Details,[0],[0]
"The proof is mere calculation.
",A.2. Omitted Preliminary Details,[0],[0]
PDFX(x) PDFcY,A.2. Omitted Preliminary Details,[0],[0]
"(x) =
√ c2λ2
σ2 ·
exp(− x 2
2σ2 )
",A.2. Omitted Preliminary Details,[0],[0]
"exp(− x 2
2c2λ2 )
",A.2. Omitted Preliminary Details,[0],[0]
≤,A.2. Omitted Preliminary Details,[0],[0]
c ·,A.2. Omitted Preliminary Details,[0],[0]
"exp(x 2
2 (
1 c2λ2",A.2. Omitted Preliminary Details,[0],[0]
− 1 σ2 )),A.2. Omitted Preliminary Details,[0],[0]
≤ c · exp(0),A.2. Omitted Preliminary Details,[0],[0]
"= c
PDFX(x)",A.2. Omitted Preliminary Details,[0],[0]
"PDFY (x) =
√ λ2
σ2 ·
exp(− x 2
2σ2 )
",A.2. Omitted Preliminary Details,[0],[0]
"exp(− x 2
2λ2 )
",A.2. Omitted Preliminary Details,[0],[0]
≥ c−1,A.2. Omitted Preliminary Details,[0],[0]
"exp(x 2
2 ( 1 λ2 − 1 σ2 ))",A.2. Omitted Preliminary Details,[0],[0]
≥ exp(0),A.2. Omitted Preliminary Details,[0],[0]
"c = c −1
",A.2. Omitted Preliminary Details,[0],[0]
The Tk-Distribution.,A.2. Omitted Preliminary Details,[0],[0]
"The Tk-distribution, where k is referred to as the degrees of freedom of the distribution, denotes the distribution over the reals created by independently sampling Z ∼ N (0, 1) and ‖ζ‖2 ∼ χ2k, and taking the quantity Z√
‖ζ‖2/k .",A.2. Omitted Preliminary Details,[0],[0]
"Its PDF is given by
PDFTk(x) ∝",A.2. Omitted Preliminary Details,[0],[0]
"( 1 + x 2
k )",A.2. Omitted Preliminary Details,[0],[0]
−k+12 .,A.2. Omitted Preliminary Details,[0],[0]
"It is a known fact that as k increases, Tk becomes closer and closer to a normal Gaussian.",A.2. Omitted Preliminary Details,[0],[0]
"The T -distribution is often used to determine suitable bounds on the rate of converges, as we illustrate in Section A.3.",A.2. Omitted Preliminary Details,[0],[0]
"As the T -distribution is heavy-tailed, existing tail bounds on the T -distribution (which are of the form: if τν = C √ k((1/ν)2/k − 1) for some constant C
then ∫∞ τν
PDFTk(x)dx < ν) are often cumbersome to work with.",A.2. Omitted Preliminary Details,[0],[0]
"Therefore, in many cases in practice, it common to assume ν = Θ(1) (most commonly, ν = 0.05) and use existing tail-bounds on normal Gaussians.
",A.2. Omitted Preliminary Details,[0],[0]
Differential Privacy facts.,A.2. Omitted Preliminary Details,[0],[0]
"It is known (Dwork et al., 2006b) that if ALG outputs a vector in Rd such that for any A and A′ it holds that ‖ALG(A)",A.2. Omitted Preliminary Details,[0],[0]
"− ALG(A′)‖1 ≤ B, then adding Laplace noise Lap(1/ ) to each coordinate of the output of ALG(A) satisfies -differential privacy.",A.2. Omitted Preliminary Details,[0],[0]
"Similarly, (2006b) showed that if for any neighboring A and A′ it holds that ‖ALG(A)−ALG(A′)‖22 ≤ ∆2 then adding Gaussian noise N (0,∆2 · 2 ln(2/δ) 2 ) to each coordinate of the output of ALG(A) satisfies ( , δ)-differential privacy.
",A.2. Omitted Preliminary Details,[0],[0]
"Another standard result (Dwork et al., 2006a) gives that the composition of the output of a ( 1, δ1)-differentially private algorithm with the output of a ( 2, δ2)-differentially private algorithm results in a ( 1+ 2, δ1+δ2)-differentially private algorithm.",A.2. Omitted Preliminary Details,[0],[0]
"For the unfamiliar reader, we give a short description of the model under which OLS operates as well as the confidence bounds one derives using OLS.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"This is by no means an ex-
haustive account of OLS and we refer the interested reader to (Rao, 1973; Muller & Stewart, 2006).
",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Given n observations {(xi, yi)}ni=1 where for all i we have xi ∈",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Rp and yi ∈ R, we assume the existence of a pdimensional vector β ∈",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Rp s.t.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"the label yi was derived by yi = β
Txi + ei where ei ∼ N (0, σ2) independently (also known as the homoscedastic Gaussian model).",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"We use the matrix notation whereX denotes the (n×p)-matrix whose rows are xi, and use y,e ∈ Rn to denote the vectors whose i-th entry is yi and ei resp.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"To simplify the discussion, we assume X has full rank.
",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"The parameters of the model are therefore β and σ2, which we set to discover.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"To that end, we minimize minz ‖y",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"− Xz‖2 and solve
β̂ = (XTX)−1XTy = (XTX)−1XT(Xβ+e) = β+X+e
As e ∼ N (0n, σ2In×n), it holds that β̂",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"∼ N (β, σ2(XTX)−1), or alternatively, that for every coordinate j it holds that β̂j = eTj β̂",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"∼ N (βj , σ2(XTX) −1",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"j,j ).",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Hence we get β̂j−βj σ √
(XTX)−1j,j
∼ N (0, 1).",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"In addition, we de-
note the vector
ζ = y−Xβ̂ = (Xβ +e)−X(β +X+e) =",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"(I −XX+)e
and since XX+ is a rank-p (symmetric) projection matrix, we have ζ ∼ N (0, σ2(I − XX+)).",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Therefore, ‖ζ‖2 is equivalent to summing the squares of (n− p) i.i.d samples from N (0, σ2).",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"In other words, the quantity ‖ζ‖2/σ2 is sampled from a χ2-distribution with (n − p) degrees of freedom.
",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"We sidetrack from the OLS discussion to give the following bounds on the l2-distance between β and β̂ , as the next claim shows.
",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Claim A.4.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"For any 0 < ν < 1/2, the following holds w.p. ≥ 1−ν over the randomness of the model (the randomness over e)
‖β",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"− β̂‖2 = ‖X+e‖2 = O ( σ2 log(p/ν) · ‖X+‖2F ) (6)
‖β̂‖2 = ‖β +X+e‖2 =",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
O( ( ‖β‖+ σ · ‖X+‖F · √ log(p/ν) )2 )∣∣∣ 1n−p‖ζ‖2,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
− σ2∣∣∣ = O(√,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"ln(1/ν)n−p )
",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Proof.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Since e ∼ N (0n, σ2In×n) then X+e ∼ N (0n, σ2(XTX)−1)",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Denoting the SVD decomposition (XTX)−1 = V SV T with S denoting the diagonal matrix whose entries are σ−2max(X), . . .",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
", σ −2 min(X), we have that V TX+e ∼ N (0n, σ2S).",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"And so, each coordinate of V TX+e is distributed like an i.i.d Gaussian.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"So
w.p. ≥ 1 − ν/2 non of these Gaussians is a factor of O(σ √ ln(p/ν)) greater than its standard deviation.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
And so w.p. ≥ 1 − ν/2 it holds that ‖X+e‖2 = ‖V TX+e‖2 ≤,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
O(σ2 log(p/ν) (∑ i σ −2,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
i (X) ) ).,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Since ∑ i σ −2,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"i (X) = trace((XTX)−1) = trace(X+(X+)T) = ‖X+‖2F , the bound of (6) is proven.
",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
The bound on ‖β̂‖2 is an immediate corollary of (6) using the triangle inequality.8,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"The bound on ‖ζ‖2 follows from tail bounds on the χ2n−p distribution, as detailed in Section 2.
",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Returning to OLS, it is important to note that β̂",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
and ζ are independent of one another.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"(Note, β̂ depends solely on X+e = (X+X)X+e = X+PUe, whereas ζ depends on (I −XX+)e =",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
PU⊥e.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"As e is spherically symmetric, the two projections are independent of one another and so β̂ is independent of ζ .)",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"As a result of the above two calculations, we have that the quantity
tβ̂j (βj) def = β̂j−βj√",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"(XTX)−1j,j · ‖ζ‖√ n−p = β̂j−βj σ √ (XTX)−1j,j
/ ‖ζ‖
σ √ n−p
is distributed like a T -distribution with (n − p) degrees of freedom.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Therefore, we can compute an exact probability estimation for this quantity.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"That is, for any measurable S ⊂ R we have Pr [ β̂ and ζ satisfying tβ̂j (βj) ∈ S ] = ∫ S PDFTn−p(x)dx
The importance of the t-value t(βj) lies in the fact that it can be fully estimated from the observed data X and y (for any value of βj), which makes it a pivotal quantity.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Therefore, given X and y , we can use t(βj) to describe the likelihood of any βj — for any z ∈ R we can now give an estimation of how likely it is to have βj = z (which is PDFTn−p(t(z))).",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
The t-values enable us to perform multitude of statistical inferences.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"For example, we can say which of two hypotheses is more likely and by how much (e.g., we are 5-times more likely that the hypothesis βj = 3 is true than the hypothesis βj = 14 is true); we can compare between two coordinates j and j′ and report we are more confident that βj > 0",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"than βj′ > 0; or even compare among the t-values we get across multiple datasets (such as the datasets we get from subsampling rows from a single dataset).
",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"In particular, we can use t(βj) to α-reject unlikely values of βj .",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Given 0 <,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"α < 1, we denote cα as the number for which the interval (−cα, cα) contains a probability mass of 1 − α from the Tn−p-distribution.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"And so we derive a
8Observe, though e is spherically symmetric, and is likely to be approximately-orthogonal to β , this does not necessarily hold for X+e which isn’t spherically symmetric.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Therefore, we result to bounding the l2-norm of β̂ using the triangle bound.
corresponding confidence interval",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Iα centered at β̂j where βj ∈ Iα with confidence of level of 1− α.
",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
We comment as to the actual meaning of this confidence interval.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Our analysis thus far applied w.h.p to a vector y derived according to this model.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Such X and y will result in the quantity tβ̂j (βj) being distributed like a Tn−pdistribution — where βj is given as the model parameters and β̂j is the random variable.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"We therefore have that guarantee that for X and y derived according to this model, the
event Eα def = β̂j ∈ ( βj ± cα · √ (XTX)−1j,j · ‖ζ‖2 n−p ) hap-
pens w.p. 1 − α.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"However, the analysis done over a given dataset X and y (once y has been drawn) views the quantity tβ̂j (βj) with β̂j given and βj unknown.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Therefore the event Eα either holds or does not hold.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"That is why the alternative terms of likelihood or confidence are used, instead of probability.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
We have a confidence level of 1 − α that indeed βj ∈ β̂j±cα ·,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"√ (XTX)−1j,j · ‖ζ‖2 n−p , because this event does happen in 1−α fraction of all datasets generated according to our model.
",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Rejecting the Null Hypothesis.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"One important implication of the quantity t(βj) is that we can refer specifically to the hypothesis that βj = 0, called the null hypothesis.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"This quantity, t0 def = tβ̂j (0) = β̂j √ n−p ‖ζ‖ √
(XTX)−1j,j
, represents how
large is β̂j relatively to the empirical estimation of standard deviation σ.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Since it is known that as the number of degrees of freedom of a T -distribution tends to infinity then the T - distribution becomes a normal Gaussian, it is common to think of t0 as a sample from a normal Gaussian N (0, 1).",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"This allows us to associate t0 with a p-value, estimating the event “βj and β̂j have different signs.”",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Formally, we define p0 = ∫∞ |t0| 1√ 2π e−x
2/2dx.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"It is common to reject the null hypothesis when p0 is sufficiently small (typically, below 0.05).9
Specifically, given α ∈ (0, 1/2), we say we α-reject the null hypothesis if p0 < α.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Let τα be the number s.t. Φ(τα) = ∫∞ τα 1√ 2π e−x 2/2dx = α.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"(Standard bounds
give that τα < 2 √
ln(1/α).)",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"This means we α-reject the null hypothesis if t0 > τα or t0 < −τα, meaning if |β̂j | > τα √ (XTX)−1j,j ‖ζ‖√ n−p .
",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
We can now lower bound the number of i.i.d sample points needed in order to α-reject the null hypothesis.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"This bound will be our basis for comparison — between standard OLS and the differentially private version.10 9Indeed, it is more accurate to associate with t0 the value∫∞ |t0|
PDFTn−p(x)dx and check that this value is < α.",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"However, as most uses take α to be a constant (often α = 0.05), asymptotically the threshold we get for rejecting the null hypothesis are the same.
",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"10This theorem is far from being new (except for maybe fo-
Theorem A.5 (Theorem 2.2 restated.).",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Fix any positive definite matrix Σ ∈ Rp×p and any ν ∈,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"(0, 12 ).",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Fix parameters,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
β ∈,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Rp and σ2 and a coordinate j s.t. βj 6= 0.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Let X be a matrix whose n rows are i.i.d samples from N (0,Σ), and y be a vector where yi − (Xβ)i is sampled i.i.d from N (0, σ2).",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Fix α ∈ (0, 1).",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
Then w.p. ≥ 1 − ν we have that the (1 − α)-confidence interval is of length O(cα √ σ2/(nσmin(Σ))) provided n ≥ C1(p + ln(1/ν)) for some sufficiently large constant C1.,A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"Furthermore, there exists a constant C2 such that w.p. ≥ 1 − α",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"− ν we (correctly) reject the null hypothesis provided
n",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
"≥ max { C1(p+ ln(1/ν)), C2 σ2
β2j · c
2 α + τ 2 α
σmin(Σ)
}",A.3. Detailed Background on Ordinary Least Squares,[0],[0]
−cα PDFTn−p(x)dx = 1 − α.,Here cα denotes the number for which∫ cα,[0],[0]
"(If we are content with approximating Tn−p with a normal Gaussian than one can set cα ≈ τα < 2 √ ln(1/α).)
",Here cα denotes the number for which∫ cα,[0],[0]
Proof.,Here cα denotes the number for which∫ cα,[0],[0]
"The discussion above shows that w.p. ≥ 1 − α we have |βj − β̂j | ≤ cα √ (XTX)−1j,j ‖ζ‖2 n−p ; and in order to α-reject the null hypothesis we must have |β̂j | > τα √ (XTX)−1j,j ‖ζ‖2 n−p .",Here cα denotes the number for which∫ cα,[0],[0]
"Therefore, a sufficient condition for OLS to α-reject the null-hypothesis is to have n large
enough s.t. |βj",Here cα denotes the number for which∫ cα,[0],[0]
| >,Here cα denotes the number for which∫ cα,[0],[0]
"(cα + τα) √ (XTX)−1j,j ‖ζ‖2 n−p .",Here cα denotes the number for which∫ cα,[0],[0]
"We therefore argue that w.p.≥ 1− ν this inequality indeed holds.
",Here cα denotes the number for which∫ cα,[0],[0]
"We assume each row of X i.i.d vector xi ∼ N (0p,Σ), and recall that according to the model ‖ζ‖2 ∼ σ2χ2(n − p).",Here cα denotes the number for which∫ cα,[0],[0]
Straightforward concentration bounds on Gaussians and on the χ2-distribution give: (i) W.p.,Here cα denotes the number for which∫ cα,[0],[0]
≤ α,Here cα denotes the number for which∫ cα,[0],[0]
it holds that ‖ζ‖ > σ,Here cα denotes the number for which∫ cα,[0],[0]
( √ n− p+ 2 ln(2/α))).,Here cα denotes the number for which∫ cα,[0],[0]
(This is part of the standard OLS analysis.),Here cα denotes the number for which∫ cα,[0],[0]
(ii) W.p. ≤ ν,Here cα denotes the number for which∫ cα,[0],[0]
it holds that σmin(XTX) ≤ σmin(Σ)( √ n,Here cα denotes the number for which∫ cα,[0],[0]
− ( √ p+ √ 2 ln(2/ν)))2.,Here cα denotes the number for which∫ cα,[0],[0]
"(Rudelson & Vershynin, 2009)",Here cα denotes the number for which∫ cα,[0],[0]
"Therefore, due to the lower bound n = Ω(p + ln(1/ν)), w.p.≥ 1 − ν",Here cα denotes the number for which∫ cα,[0],[0]
− α we have that none of these events hold.,Here cα denotes the number for which∫ cα,[0],[0]
"In such a case we have√
(XTX)−1j,j ≤ √ σmax((XTX)−1) =",Here cα denotes the number for which∫ cα,[0],[0]
"O(
1√ nσmin(Σ) )
and ‖ζ‖ = O(σ √ n− p).",Here cα denotes the number for which∫ cα,[0],[0]
"This implies that the confidence interval of level 1 − α has length of cα √ (XTX)−1j,j · ‖ζ‖2 n−p =",Here cα denotes the number for which∫ cα,[0],[0]
"O ( cα √ σ2
nσmin(Σ)
) ; and that in
order to α-reject that null-hypothesis it suffices to have |βj | = Ω ( (cα + τα) √ σ2
nσmin(Σ)
) .",Here cα denotes the number for which∫ cα,[0],[0]
"Plugging in the lower
bound on n, we see that this inequality holds.
",Here cα denotes the number for which∫ cα,[0],[0]
"We comment that for sufficiently large constants C1, C2,
cusing on the setting where every row in X is sampled from an i.i.d multivariate Gaussians), it is just stated in a non-standard way, discussing solely the power of the t-test in OLS.",Here cα denotes the number for which∫ cα,[0],[0]
"For further discussions on sample size calculations see (Muller & Stewart, 2006).
",Here cα denotes the number for which∫ cα,[0],[0]
it holds that all the constants hidden in the O- and Ωnotations of the proof are close to 1.,Here cα denotes the number for which∫ cα,[0],[0]
"I.e., they are all within the interval (1 ± η) for some small η > 0",Here cα denotes the number for which∫ cα,[0],[0]
"given C1, C2 ∈ Ω(η−2).",Here cα denotes the number for which∫ cα,[0],[0]
Theorem B.1 (Theorem 3.1 restated.).,B.1. Main Theorem Restated and Further Discussion,[0],[0]
"Let X be a n × p matrix, and parameters β ∈",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"Rp and σ2 are such that we generate the vector y = Xβ + e with each coordinate of e sampled independently from N (0, σ2).",B.1. Main Theorem Restated and Further Discussion,[0],[0]
Assume σmin(X),B.1. Main Theorem Restated and Further Discussion,[0],[0]
≥ C · w and that n is sufficiently large s.t.,B.1. Main Theorem Restated and Further Discussion,[0],[0]
"all of the singular values of the matrix [X;y] are greater than C · w for some large constant C, and so Algorithm 1 projects the matrixA =",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"[X;y] without altering it, and publishes [RX;Ry].",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"Fix ν ∈ (0, 1/2) and r = p + Ω(ln(1/ν)).",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"Fix coordinate j. Then w.p. ≥ 1− ν we have that deriving β̃ , ζ̃ and σ̃2 as follows
β̃ = (XTRTRX)−1(RX)T(Ry) =",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"β + (RX)+Re
ζ̃ = 1√",B.1. Main Theorem Restated and Further Discussion,[0],[0]
r Ry,B.1. Main Theorem Restated and Further Discussion,[0],[0]
"− 1√ r (RX)β̃
= 1√ r
( I − (RX)(XTRTRX)−1(RX)T) )",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"Re
σ̃2 = r
r − p ‖ζ̃‖2
then the pivot quantity
t̃(βj) =",B.1. Main Theorem Restated and Further Discussion,[0],[0]
β̃j,B.1. Main Theorem Restated and Further Discussion,[0],[0]
"− βj σ̃ √
(XTRTRX)−1j,j
has a distribution D satisfying e−aPDFTr−p(x) ≤",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"PDFD(x) ≤ eaPDFTr−p(e−ax) for any x ∈ R, where we denote a = r−pn−p .
",B.1. Main Theorem Restated and Further Discussion,[0],[0]
Comparison with Existing Bounds.,B.1. Main Theorem Restated and Further Discussion,[0],[0]
"Sarlos’ work (2006) utilizes the fact that when r, the numbers of rows in R, is large enough, then 1√
r R is a Johnson-Lindenstrauss
matrix.",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"Specifically, given r and ν ∈ (0, 1) we denote η = Ω(
√ p ln(p) ln(1/ν)
r ), and so r =",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"O( p ln(p) ln(1/ν) η2 ).
",B.1. Main Theorem Restated and Further Discussion,[0],[0]
Let us denote β̃ = arg minz 1r‖RXz,B.1. Main Theorem Restated and Further Discussion,[0],[0]
− Ry‖ 2.,B.1. Main Theorem Restated and Further Discussion,[0],[0]
"In this setting, Sarlos’ work (Sarlós, 2006) (Theorem 12(3)) guarantees that w.p. ≥ 1 − ν",B.1. Main Theorem Restated and Further Discussion,[0],[0]
we have ‖β̂,B.1. Main Theorem Restated and Further Discussion,[0],[0]
− β̃‖2 ≤ η‖ζ‖/σmin(X) =,B.1. Main Theorem Restated and Further Discussion,[0],[0]
O (√ p log(p) log(1/ν) rσmin(XTX),B.1. Main Theorem Restated and Further Discussion,[0],[0]
‖ζ‖ ) .,B.1. Main Theorem Restated and Further Discussion,[0],[0]
Naı̈vely bounding |β̂j − β̃j | ≤ ‖β̂,B.1. Main Theorem Restated and Further Discussion,[0],[0]
"− β̃‖ and using the confidence interval for β̂j − βj from Section A.311
11Where we approximate cα, the tail bound of the Tn−pdistribution with the tail bound on a Gaussian, i.e., use the approximation",B.1. Main Theorem Restated and Further Discussion,[0],[0]
cα ≈,B.1. Main Theorem Restated and Further Discussion,[0],[0]
"O( √ ln(1/α)).
gives a confidence interval of level 1 − (α + ν) centered at β̃j with length of O (√ p ln(p) log(1/ν) rσmin(XTX) ‖ζ‖ )",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"+
O (√ (XTX)−1j,j log(1/α) n−p ‖ζ‖ ) =
O (√
p ln(p) log(1/ν)+log(1/α) rσmin(XTX)
‖ζ‖ )
.",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"This implies that our confidence interval has decreased its degrees of freedom from n− p to roughly r/p ln(p), and furthermore, that it no longer depends on (XTX)−1j,j but rather on 1/σmin(X
TX).",B.1. Main Theorem Restated and Further Discussion,[0],[0]
It is only due to the fact that we rely on Gaussians and by mimicking carefully the original proof that we can deduce that the t̃-value has (roughly) r,B.1. Main Theorem Restated and Further Discussion,[0],[0]
"− p degrees of freedom and depends solely on (XTX)−1j,j .
",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"(In the worst case, we have that (XTX)−1j,j is proportional to σmin(XTX)−1, but it is not uncommon to have matrices where the former is much larger than the latter.)",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"As mentioned in the introduction, alternative techniques ((Chaudhuri et al., 2011; Bassily et al., 2014; Ullman, 2015)) for finding a DP estimator βdp of the linear regression give a data-independent12 bound of ‖βdp",B.1. Main Theorem Restated and Further Discussion,[0],[0]
− β̂‖ = Õ(p/ ).,B.1. Main Theorem Restated and Further Discussion,[0],[0]
Such bounds are harder to compare with the interval length given by Corollary 3.2.,B.1. Main Theorem Restated and Further Discussion,[0],[0]
"Indeed, as we discuss in Section 3 under “Rejecting the null-hypothesis,” enough samples from a multivariate Gaussian whose covariance-matrix is well conditioned give a bound which is well below the worstupper bound of O(p/ ).",B.1. Main Theorem Restated and Further Discussion,[0],[0]
"(Yet, it is possible that these techniques also do much better on such “well-behaved” data.)",B.1. Main Theorem Restated and Further Discussion,[0],[0]
What the works of Sarlos and alternative works regrading differentially private linear regression do not take into account are questions such as generating a likelihood for βj nor do they discuss rejecting the null hypothesis.,B.1. Main Theorem Restated and Further Discussion,[0],[0]
"We now turn to our analysis of β̃ and ζ̃ , where our goal is to show that the distribution of the t̃-values as specified in Theorem 3.1 is well-approximated by the Tr−pdistribution.",B.2. Proof of Theorem 3.1,[0],[0]
"For now, we assume the existence of fixed vectors β ∈",B.2. Proof of Theorem 3.1,[0],[0]
Rp and e ∈,B.2. Proof of Theorem 3.1,[0],[0]
"Rn s.t. y = Xβ + e. (Later, we will return to the homoscedastic model where each coordinate of e is sampled i.i.d from N (0, σ2) for some σ2.)",B.2. Proof of Theorem 3.1,[0],[0]
"In other words, we first examine the case where R is the sole source of randomness in our estimation.",B.2. Proof of Theorem 3.1,[0],[0]
"Based on the assumption that e is fixed, we argue the following.
",B.2. Proof of Theorem 3.1,[0],[0]
Claim B.2.,B.2. Proof of Theorem 3.1,[0],[0]
"In our model, given X and the output M = RX , we have that β̃ ∼ N ( β +X+e, ‖PU⊥e‖2(MTM)−1 ) and ζ̃ ∼
N ( 0n, ‖P U⊥e‖ 2 r (Ir×r −M(M TM)−1MT) ) .",B.2. Proof of Theorem 3.1,[0],[0]
"Where PU⊥ denotes the projection operator onto the subspace orthogonal to colspan(X); i.e., PU = XX+ and PU⊥ = (Ir×r −XX+).
",B.2. Proof of Theorem 3.1,[0],[0]
"12In other words, independent of X,ζ .
",B.2. Proof of Theorem 3.1,[0],[0]
Proof.,B.2. Proof of Theorem 3.1,[0],[0]
"The matrix R is sampled from N (0r×p, Ir×r, Ip×p).",B.2. Proof of Theorem 3.1,[0],[0]
"Given X and RX = M , we learn the projection of each row in R onto the subspace spanned by the columns of X .",B.2. Proof of Theorem 3.1,[0],[0]
"That is, denoting uT as the i-th row of R and vT as the i-th row of M , we have that XTu = v .",B.2. Proof of Theorem 3.1,[0],[0]
"Recall, initially u ∼ N (0n, In×n) – a spherically symmetric Gaussian.",B.2. Proof of Theorem 3.1,[0],[0]
"As a result, we can denote u = PUu × PU⊥u where the two projections are independent samples from N (0n, PU ) and N (0n, PU⊥) resp.",B.2. Proof of Theorem 3.1,[0],[0]
"However, once we know that v = XTu we have that PUu = X(X
TX)−1XTu = X(XTX)−1v so we learn PUu exactly, whereas we get no information about PU⊥ so PU⊥u is still sampled from a Gaussian N (0n, PU⊥).",B.2. Proof of Theorem 3.1,[0],[0]
"As we know for each row of R that uTPU = vTX+, we therefore have that
R = RPU +RPU⊥ = MX + +RPU⊥
where RPU⊥ ∼ N (0r×n, Ir×r, PU⊥).",B.2. Proof of Theorem 3.1,[0],[0]
"From here on, we just rely on the existing results about the linearity of Gaussians.
",B.2. Proof of Theorem 3.1,[0],[0]
"R ∼ N (MX+, Ir×r, PU⊥) ⇒",B.2. Proof of Theorem 3.1,[0],[0]
"Re ∼ N (MX+e, ‖PU⊥e‖2Ir×r) ⇒M+Re",B.2. Proof of Theorem 3.1,[0],[0]
"∼ N (X+e, ‖PU⊥e‖2(MTM)−1)
so β̃ = β + M+Re implies β̃ ∼ N (β + X+e, ‖PU⊥e‖2(MTM)−1).",B.2. Proof of Theorem 3.1,[0],[0]
And as ζ̃ = 1√ r,B.2. Proof of Theorem 3.1,[0],[0]
"(Ir×r − M(MTM)−1MT)Re then we have ζ̃ ∼ N (0r, ‖P U⊥e‖ 2 r (Ir×r − MM +))",B.2. Proof of Theorem 3.1,[0],[0]
"as (Ir×r −MM+)M = 0r×p.
",B.2. Proof of Theorem 3.1,[0],[0]
Claim B.2 was based on the assumption that e is fixed.,B.2. Proof of Theorem 3.1,[0],[0]
"However, given X and y there are many different ways to assign vectors β and e s.t. y = Xβ + e.",B.2. Proof of Theorem 3.1,[0],[0]
"However, the distributions we get in Claim B.2 are unique.",B.2. Proof of Theorem 3.1,[0],[0]
"To see that, recall Equations (1) and (2): β + X+e = X+y = β̂ and PU⊥e = PU⊥y =",B.2. Proof of Theorem 3.1,[0],[0]
(I − XX+)y = ζ .,B.2. Proof of Theorem 3.1,[0],[0]
"We therefore have β̃ ∼ N (β̂ , ‖ζ‖2(MTM)−1) and ζ̃ ∼ N (0n, ‖ζ‖ 2
r (I − MM+)).",B.2. Proof of Theorem 3.1,[0],[0]
"We will discuss this further, in Section 4, where we will not be able to better analyze the explicit distributions of our estimators.",B.2. Proof of Theorem 3.1,[0],[0]
"But in this section, we are able to argue more about the distributions of β̃ and ζ̃ .
",B.2. Proof of Theorem 3.1,[0],[0]
"So far we have considered the case that e is fixed, whereas our goal is to argue about the case where each coordinate of e is sampled i.i.d from N (0, σ2).",B.2. Proof of Theorem 3.1,[0],[0]
"To that end, we now switch to an intermediate model, in which PUe is sampled from a multivariate Gaussian while PU⊥e is fixed as some arbitrary vector of length l. Formally, let Dl denote the distribution where PUe ∼ N (0, σ2PU ) and PU⊥e is fixed as some specific vector whose length is denoted by ‖PU⊥e‖ = l. Claim B.3.",B.2. Proof of Theorem 3.1,[0],[0]
"Under the same assumptions as in Claim B.2, given that e ∼ Dl, we have that
β̃ ∼ N ( β, σ2(XTX)−1 + l2(MTM)−1 ) and
ζ̃ ∼ N ( 0n, l2 r (I −MM +) ) .
",B.2. Proof of Theorem 3.1,[0],[0]
Proof.,B.2. Proof of Theorem 3.1,[0],[0]
"Recall, β̃ = β + M+Re = β + M+(MX+ + RPU⊥)e = β + X
+e + M+R(PU⊥e).",B.2. Proof of Theorem 3.1,[0],[0]
"Now, under the assumption e ∼ Dl we have that β is the sum of two independent Gaussians:
β +X+e ∼ N (β, σ2 ( X+ · PU · (X+)T ) )",B.2. Proof of Theorem 3.1,[0],[0]
"= N (β, σ2(XTX)−1) RPU⊥e ∼ N (0r, ‖PU⊥e‖2Ir×r) ⇒M+Re ∼ N (0p, ‖PU⊥e‖2(MTM)−1)
Summing the two independent Gaussians’ means and variances gives the distribution of β̃ .",B.2. Proof of Theorem 3.1,[0],[0]
"Furthermore, in Claim B.2 we have already established that for any fixed e we have ζ̃ ∼ N ( 0n, ‖P U⊥e‖ 2 r (I −MM +) ) .",B.2. Proof of Theorem 3.1,[0],[0]
"Hence, for
e ∼ Dl we still have ζ̃ ∼ N ( 0n, l2 r",B.2. Proof of Theorem 3.1,[0],[0]
"(I −MM +) )
.",B.2. Proof of Theorem 3.1,[0],[0]
"(It is easy to verify that the same chain of derivations is applicable when e ∼ Dl.)
",B.2. Proof of Theorem 3.1,[0],[0]
Corollary B.4.,B.2. Proof of Theorem 3.1,[0],[0]
Given that e ∼ Dl we have that β̃j ∼ N,B.2. Proof of Theorem 3.1,[0],[0]
"(βj , σ2(XTX)−1j,j + l2(MTM) −1",B.2. Proof of Theorem 3.1,[0],[0]
"j,j ) for any coordinate j, and that ‖ζ̃‖2 ∼ l 2
r · χ 2 r−p.
",B.2. Proof of Theorem 3.1,[0],[0]
Proof.,B.2. Proof of Theorem 3.1,[0],[0]
"The corollary follows immediately from the fact that βj = eTj β̃ , and from the definition of the χ
2- distribution, as ζ̃ is a spherically symmetric Gaussian defined on the subspace colspan(M)⊥ of dimension r",B.2. Proof of Theorem 3.1,[0],[0]
"− p.
To continue, we need the following claim.
",B.2. Proof of Theorem 3.1,[0],[0]
Claim B.5.,B.2. Proof of Theorem 3.1,[0],[0]
GivenX,B.2. Proof of Theorem 3.1,[0],[0]
"andM = RX , and given that e ∼ Dl we have that β̃ and ζ̃ are independent.
",B.2. Proof of Theorem 3.1,[0],[0]
Proof.,B.2. Proof of Theorem 3.1,[0],[0]
"Recall, β̃ = β + X+e + M+R(PU⊥e).",B.2. Proof of Theorem 3.1,[0],[0]
"And so, given X , M and a specific vector PU⊥e we have that the distribution of β̃ depends on (i) the projection of e on U = colspan(X) and on (ii) the projection of each row in R onto Ũ = colspan(M).",B.2. Proof of Theorem 3.1,[0],[0]
"The distribution of ζ̃ = 1√
r PŨ⊥Re = 1√ r PŨ⊥(MX + + RPU⊥)e = 1√ r PŨ⊥RPU⊥e depends on (i) the projection of e onto U ⊥ (which for the time being is fix to some specific vector of length l) and on (ii) the projection of each row in R onto Ũ⊥. Since PUe is independent from PU⊥e, and since for any rowuT ofRwe have thatPŨu is independent ofPŨ⊥u, and since e and R are chosen independently, we have that β̃ and ζ̃ are independent.
",B.2. Proof of Theorem 3.1,[0],[0]
"Formally, consider any pair of coordinates β̃j and ζ̃k, and we have
β̃j",B.2. Proof of Theorem 3.1,[0],[0]
"− βj = eTjX+e + eTjM+(RPU⊥e)
ζ̃k = e T kPŨ⊥(RPU⊥e)
",B.2. Proof of Theorem 3.1,[0],[0]
"Recall, we are givenX andM = RX .",B.2. Proof of Theorem 3.1,[0],[0]
"Therefore, we know PU and PŨ .",B.2. Proof of Theorem 3.1,[0],[0]
"And so
Cov[β̃j , ζ̃k]
=",B.2. Proof of Theorem 3.1,[0],[0]
E[(β̃j − βj)(ζ̃k − 0)],B.2. Proof of Theorem 3.1,[0],[0]
"= E[eTjX +e(RPU⊥e) TPŨ⊥ek]
+ E[eTjM",B.2. Proof of Theorem 3.1,[0],[0]
+(RPU⊥e)(RPU⊥e) TPŨ⊥ek,B.2. Proof of Theorem 3.1,[0],[0]
"]
= eTjX +E[eeTPU⊥ ]E[R T]PŨ⊥ek
+ eTjM +E[(RPU⊥e)(RPU⊥e) T]PŨ⊥ek
= eTjX +E[eeTPU⊥ ] ( (MX+)T + E[(RPU⊥) T] ) PŨ⊥ek
",B.2. Proof of Theorem 3.1,[0],[0]
+ eTjM +,B.2. Proof of Theorem 3.1,[0],[0]
"( ‖PU⊥e‖2Ir×r ) PŨ⊥ek
= eTjX +E[eeTPU⊥ ](X +)T ( MTPŨ⊥ ) ek + 0
+ l2 · eTj ( M+PŨ⊥ )",B.2. Proof of Theorem 3.1,[0],[0]
"ek
= 0 + 0",B.2. Proof of Theorem 3.1,[0],[0]
+ 0,B.2. Proof of Theorem 3.1,[0],[0]
"= 0
And as β̃ and ζ̃ are Gaussians, having their covariance = 0 implies independence.
",B.2. Proof of Theorem 3.1,[0],[0]
"Having established that β̃ and ζ̃ are independent Gaussians and specified their distributions, we continue with the proof of Theorem 3.1.",B.2. Proof of Theorem 3.1,[0],[0]
"We assume for now that there exists some small a > 0 s.t.
l2(MTM)−1j,j ≤ σ 2(XTX)−1j,j + l 2(MTM)−1j,j ≤ e2a · l2(MTM)−1j,j (7)
Then, due to Corollary A.3, denoting the distributions N1 = N (0, l2(MTM)−1j,j ) and N2 = N (0, σ2(XTX)−1j,j + l2(MTM) −1",B.2. Proof of Theorem 3.1,[0],[0]
"j,j ), we have that for any S ⊂ R it holds that13
e−aPrβ̃j∼N1",B.2. Proof of Theorem 3.1,[0],[0]
[S] ≤,B.2. Proof of Theorem 3.1,[0],[0]
Prβ̃j∼N2,B.2. Proof of Theorem 3.1,[0],[0]
"[S] ≤ e aPrβ̃j∼N1 [S/e a]
(8)
More specifically, denote the function
t̃(ψ, ‖ξ‖, βj) = ψ",B.2. Proof of Theorem 3.1,[0],[0]
"− βj ‖ξ‖ √
r r−p (M TM)−1j,j
= ψ",B.2. Proof of Theorem 3.1,[0],[0]
"− βj l √
(MTM)−1j,j
/‖ξ‖√",B.2. Proof of Theorem 3.1,[0],[0]
rr−p,B.2. Proof of Theorem 3.1,[0],[0]
"l
and observe that when we sample ψ,ξ independently s.t. ψ",B.2. Proof of Theorem 3.1,[0],[0]
"∼ N (βj , l2(MTM)−1j,j ) and ‖ξ‖2",B.2. Proof of Theorem 3.1,[0],[0]
"∼ l 2 r χ 2 r−p then t̃(ψ, ‖ξ‖, βj) is distributed like a T -distribution with r − p 13In fact, it is possible to use standard techniques from differential privacy, and argue a similar result — that the probabilities of any event that depends on some function f(βj) under βj ∼ N1 and under βj ∼ N2 are close in the differential privacy sense.
",B.2. Proof of Theorem 3.1,[0],[0]
degrees of freedom.,B.2. Proof of Theorem 3.1,[0],[0]
"And so, for any τ > 0",B.2. Proof of Theorem 3.1,[0],[0]
"we have that under such way to sample ψ,ξ we have Pr[t̃(ψ, ‖ξ‖, βj) > τ",B.2. Proof of Theorem 3.1,[0],[0]
],B.2. Proof of Theorem 3.1,[0],[0]
"= 1− CDFTr−p(τ).
",B.2. Proof of Theorem 3.1,[0],[0]
"For any τ ≥ 0 and for any non-negative real value z let Sτz denote the suitable set of values s.t.
Prψ∼N (βj , l 2(MTM)−1j,j )
‖ξ‖2∼",B.2. Proof of Theorem 3.1,[0],[0]
"l 2
r χ 2 r−p
 [t̃(ψ, ‖ξ‖, βj) > τ",B.2. Proof of Theorem 3.1,[0],[0]
"]
= ∞∫ 0",B.2. Proof of Theorem 3.1,[0],[0]
PDF l2 r χ 2 r−p (z) ·,B.2. Proof of Theorem 3.1,[0],[0]
"Pr {ψ−βj∼N (0, l2(MTM)−1j,j )}",B.2. Proof of Theorem 3.1,[0],[0]
"[Sτz ] dz
That is, Sτz",B.2. Proof of Theorem 3.1,[0],[0]
"= ( τ · z √ r r−p (M TM)−1j,j , ∞ ) .
",B.2. Proof of Theorem 3.1,[0],[0]
"We now use Equation (8) (Since N (0, l2(MTM)−1j,j ) is precisely N1) to deduce that Prψ∼N (βj , l 2(MTM)−1j,j+σ 2(XTX)−1j,j )
",B.2. Proof of Theorem 3.1,[0],[0]
‖ξ‖2∼,B.2. Proof of Theorem 3.1,[0],[0]
"l 2
r χ 2 r−p
 [t̃(ψ, ‖ξ‖, βj) > τ",B.2. Proof of Theorem 3.1,[0],[0]
"]
= ∫ ∞ 0 PDF l2 r χ",B.2. Proof of Theorem 3.1,[0],[0]
2 r−p (z) Pr ψ,B.2. Proof of Theorem 3.1,[0],[0]
"− βj ∼ N (0, l2(MTM)−1j,j + σ2(XTX) −1",B.2. Proof of Theorem 3.1,[0],[0]
"j,j )",B.2. Proof of Theorem 3.1,[0],[0]
"[Sτz ]dz
≤ ea ∫ ∞
0 PDF l2 r χ 2 r−p (z) Pr ψ−βj∼N (0, l2(MTM)−1j,j )
",B.2. Proof of Theorem 3.1,[0],[0]
"[Sτz /ea]dz
(∗) = ea ∫ ∞ 0",B.2. Proof of Theorem 3.1,[0],[0]
"PDF l2 r χ 2 r−p (z) Pr ψ−βj∼N (0, l2(MTM)−1j,j )",B.2. Proof of Theorem 3.1,[0],[0]
"[Sτ/e a z ]dz = eaPrψ∼N (βj , l 2(MTM)−1j,j )
",B.2. Proof of Theorem 3.1,[0],[0]
‖ξ‖2∼,B.2. Proof of Theorem 3.1,[0],[0]
"l 2
r χ 2 r−p
 [t̃(ψ, ‖ξ‖, βj) >",B.2. Proof of Theorem 3.1,[0],[0]
"τ/ea]
= ea ( 1− CDFTr−p(τ/ea) ) where the equality (∗) follows from the fact that Sτz /c = S τ/c z for any c > 0, since it is a non-negative interval.",B.2. Proof of Theorem 3.1,[0],[0]
"Analogously, we can also show that Prψ∼N (βj , l 2(MTM)−1j,j+σ 2(XTX)−1j,j )
‖ξ‖2∼",B.2. Proof of Theorem 3.1,[0],[0]
"l 2
r χ 2 r−p
 [t̃(ψ, ‖ξ‖, βj) > τ",B.2. Proof of Theorem 3.1,[0],[0]
"]
≥",B.2. Proof of Theorem 3.1,[0],[0]
"e−aPrψ∼N (βj , l 2(MTM)−1j,j )
",B.2. Proof of Theorem 3.1,[0],[0]
‖ξ‖2∼,B.2. Proof of Theorem 3.1,[0],[0]
"l 2
r χ 2 r−p
 [t̃(ψ, ‖ξ‖, βj) > τ",B.2. Proof of Theorem 3.1,[0],[0]
"]
= e−a ( 1− CDFTr−p(τ) )",B.2. Proof of Theorem 3.1,[0],[0]
"In other words, we have just shown that for any interval I = (τ,∞) with τ ≥ 0",B.2. Proof of Theorem 3.1,[0],[0]
"we have that Prψ∼N (βj , l 2(MTM)−1j,j+σ 2(XTX)−1j,j )
‖ξ‖2∼",B.2. Proof of Theorem 3.1,[0],[0]
"l 2
r χ 2 r−p
 [t̃(ψ, ‖ξ‖, βj) ∈",B.2. Proof of Theorem 3.1,[0],[0]
"I]
is lower bounded by ea ∫ I PDFTr−p(z)dz and upper
bounded by ea ∫
I/ea PDFTr−p(z)dz.",B.2. Proof of Theorem 3.1,[0],[0]
"We can now repeat
the same argument for I = (τ1, τ2) with 0 ≤ τ1 < τ2 (using an analogous definition of Sτ1,τ2z ), and again
for any I = (τ1, τ2) with τ1 < τ2 ≤ 0, and deduce that the PDF of the function t̃(ψ, ‖ξ‖, βj) at x — where we sample ψ ∼ N (βj , l2(MTM)−1j,j + σ2(XTX) −1",B.2. Proof of Theorem 3.1,[0],[0]
"j,j ) and ‖ξ‖2",B.2. Proof of Theorem 3.1,[0],[0]
"∼ l 2
r χ 2 r−p independently — lies in the range(
e−aPDFTr−p(x), e aPDFTr−p(x/e
a) ) .",B.2. Proof of Theorem 3.1,[0],[0]
"And so, using
Corollary B.4 and Claim B.5, we have that when e ∼ Dl, the distributions of β̃j and ‖ζ̃‖2 are precisely as stated above, and so we have that the distribution of t̃(βj)",B.2. Proof of Theorem 3.1,[0],[0]
"def = t̃(β̃j , ‖ζ̃‖, βj) has a PDF that at the point x is “sandwiched” between e−aPDFTr−p(x) and e aPDFTr−p(x/e a).
",B.2. Proof of Theorem 3.1,[0],[0]
"Next, we aim to argue that this characterization of the PDF of t̃(βj) still holds when e ∼ N (0n, σ2In×n).",B.2. Proof of Theorem 3.1,[0],[0]
"It would be convenient to think of e as a sample in N (0n, σ2PU ) ×N (0n, σ2PU⊥).",B.2. Proof of Theorem 3.1,[0],[0]
"(So while in Dl we have PUe ∼ N (0n, σ2PU )",B.2. Proof of Theorem 3.1,[0],[0]
"butPU⊥e is fixed, now bothPUe and PU⊥e are sampled from spherical Gaussians.)",B.2. Proof of Theorem 3.1,[0],[0]
"The reason why the above still holds lies in the fact that t̃(βj) does not depend on l. In more details:
Pre∼N (0n,σ2In×n) [ t̃(βj) ∈",B.2. Proof of Theorem 3.1,[0],[0]
"I ] =
∫ v Pre∼N (0n,σ2In×n) [ t̃(βj) ∈",B.2. Proof of Theorem 3.1,[0],[0]
I | PU⊥e,B.2. Proof of Theorem 3.1,[0],[0]
= v ] PDFP,B.2. Proof of Theorem 3.1,[0],[0]
"U⊥e (v)dv
= ∫ v Pr e∼Dl [ t̃(βj) ∈",B.2. Proof of Theorem 3.1,[0],[0]
"I | l = ‖v‖ ] PDFP U⊥e (v)dv
≤ ∫ v",B.2. Proof of Theorem 3.1,[0],[0]
( ea ∫ I/ea PDFTr−p(z)dz ) PDFP,B.2. Proof of Theorem 3.1,[0],[0]
"U⊥e (v)dv
=",B.2. Proof of Theorem 3.1,[0],[0]
( ea ∫ I/ea PDFTr−p(z)dz )∫,B.2. Proof of Theorem 3.1,[0],[0]
"v PDFP U⊥e (v)dv
= ea ∫",B.2. Proof of Theorem 3.1,[0],[0]
"I/ea PDFTr−p(z)dz
where the last transition is possible precisely because t̃ is independent of l (or ‖v‖) — which is precisely what makes this t-value a pivot quantity.",B.2. Proof of Theorem 3.1,[0],[0]
"The proof of the lower bound is symmetric.
",B.2. Proof of Theorem 3.1,[0],[0]
"To conclude, we have shown that if Equation (7) holds, then for every interval I ⊂",B.2. Proof of Theorem 3.1,[0],[0]
"R we have that Pre∼N (0n,σ2In×n)",B.2. Proof of Theorem 3.1,[0],[0]
[ t̃(βj) ∈,B.2. Proof of Theorem 3.1,[0],[0]
I ] is lower bounded by e−aPrz∼Tr−p,B.2. Proof of Theorem 3.1,[0],[0]
[z ∈ I] and upper bounded by eaPrz∼Tr−p,B.2. Proof of Theorem 3.1,[0],[0]
[z ∈ (I/ea)].,B.2. Proof of Theorem 3.1,[0],[0]
"So to conclude the proof of Theorem 3.1, we need to show that w.h.p such a as in Equation (7) exists.",B.2. Proof of Theorem 3.1,[0],[0]
Claim B.6.,B.2. Proof of Theorem 3.1,[0],[0]
"In the homoscedastic model with Gaussian noise, if both n and r satisfy n, r ≥ p + Ω(log(1/ν)), then we have that σ2(XTX)−1j,j +l 2(MTM)−1j,j ≥ l2(MTM) −1",B.2. Proof of Theorem 3.1,[0],[0]
"j,j and
σ2(XTX)−1j,j +l 2(MTM)−1j,j ≤ (1+ 2(r−p) n−p )·l 2(MTM)−1j,j
Using (1 + 2(r−p)n−p )",B.2. Proof of Theorem 3.1,[0],[0]
"≤ e 2(r−p) n−p , Theorem 3.1 now follows from plugging a = r−pn−p to our above discussion.
",B.2. Proof of Theorem 3.1,[0],[0]
Proof.,B.2. Proof of Theorem 3.1,[0],[0]
"The lower bound is immediate from non-negativity of σ2 and of (XTX)−1j,j = ‖(XTX)−1/2ej‖2.",B.2. Proof of Theorem 3.1,[0],[0]
"We therefore prove the upper bound.
",B.2. Proof of Theorem 3.1,[0],[0]
"First, observe that l2 = ‖PU⊥e‖2 is sampled from σ2·χ2n−p as U⊥ is of dimension n",B.2. Proof of Theorem 3.1,[0],[0]
− p.,B.2. Proof of Theorem 3.1,[0],[0]
"Therefore, it holds that w.p. ≥ 1− ν/2 that
σ2 (√ n− p− √ 2 ln(2/ν) )2 ≤ l2
and assuming n > p+100",B.2. Proof of Theorem 3.1,[0],[0]
ln(2/ν) we therefore have σ2 ≤ 4 3(n−p),B.2. Proof of Theorem 3.1,[0],[0]
"l 2.
",B.2. Proof of Theorem 3.1,[0],[0]
"Secondly, we argue that when r > p + 300 ln(4/ν) we have that w.p. ≥ 1 − ν/2",B.2. Proof of Theorem 3.1,[0],[0]
"it holds that 3 4 (X TX)−1j,j ≤ (r − p)(XTRTRX) −1",B.2. Proof of Theorem 3.1,[0],[0]
"j,j .",B.2. Proof of Theorem 3.1,[0],[0]
"To see this, first observe that by picking R ∼ N (0r×n, Ir×r, In×n) the distribution of the product RX ∼ N (0r×d, Ir×r, XTX) is identical to picking Q ∼ N (0r×d, Ir×r, Id×d) and taking the product Q(XTX)1/2.",B.2. Proof of Theorem 3.1,[0],[0]
"Therefore, the distribution of (XTRTRX)−1 is identical to ( (XTX)1/2QTQ(XTX)1/2 )−1",B.2. Proof of Theorem 3.1,[0],[0]
= (XTX)−1/2(QTQ)−1(XTX)−1/2.,B.2. Proof of Theorem 3.1,[0],[0]
"Denoting v = (XTX)−1/2ej we have ‖v‖2 = (XTX)−1j,j .",B.2. Proof of Theorem 3.1,[0],[0]
"Claim A.1 from (Sheffet, 2015) gives that w.p. ≥ 1 − ν/2 we have
(r − p) · eTj ( (XTX)1/2QTQ(XTX)1/2 )−1",B.2. Proof of Theorem 3.1,[0],[0]
"ej
= vT( 1r−pQ",B.2. Proof of Theorem 3.1,[0],[0]
TQ)−1v ≥ 34v,B.2. Proof of Theorem 3.1,[0],[0]
"Tv = 34 (X TX)−1j,j
which implies the required.
",B.2. Proof of Theorem 3.1,[0],[0]
"Combining the two inequalities we get:
σ2(XTX)−1j,j ≤ 16l2(r−p) n−p (X TRTRX)−1j,j
≤ 2(r−p)n−p l 2(XTRTRX)−1j,j
and as we denote M = RX we are done.
",B.2. Proof of Theorem 3.1,[0],[0]
We comment that our analysis in the proof of Claim B.6 implicitly assumes r n,B.2. Proof of Theorem 3.1,[0],[0]
"(as we do think of the projection R as dimensionality reduction), and so the ratio r−p n−p is small.",B.2. Proof of Theorem 3.1,[0],[0]
"However, a similar analysis holds for r which is comparable to n — in which we would argue that σ2(XTX)−1j,j+l
2(MTM)−1j,j σ2(XTX)−1 ∈",B.2. Proof of Theorem 3.1,[0],[0]
"[1, 1 + η] for some small η.",B.2. Proof of Theorem 3.1,[0],[0]
Theorem B.7 (Theorem 3.3 restated.).,B.3. Proof of Theorem 3.3,[0],[0]
Fix a positive definite matrix Σ ∈ Rp×p.,B.3. Proof of Theorem 3.3,[0],[0]
Fix parameters,B.3. Proof of Theorem 3.3,[0],[0]
β ∈,B.3. Proof of Theorem 3.3,[0],[0]
Rp and σ2 > 0 and a coordinate j s.t. βj 6= 0.,B.3. Proof of Theorem 3.3,[0],[0]
"Let X be a matrix whose n rows are sampled i.i.d fromN (0p,Σ).",B.3. Proof of Theorem 3.3,[0],[0]
Let y be a vector s.t.,B.3. Proof of Theorem 3.3,[0],[0]
"yi−(Xβ)i is sampled i.i.d fromN (0, σ2).",B.3. Proof of Theorem 3.3,[0],[0]
Fix ν ∈,B.3. Proof of Theorem 3.3,[0],[0]
"(0, 1/2) and α ∈ (0, 1/2).",B.3. Proof of Theorem 3.3,[0],[0]
"Then there exist constants C1, C2, C3 and C4 such that when we run Algorithm 1 over [X;y] with
parameter r w.p. ≥ 1−ν we correctly α-reject the null hypothesis using p̃0 (i.e., w.p. ≥ 1 − ν",B.3. Proof of Theorem 3.3,[0],[0]
Algorithm 1 returns matrix unaltered,B.3. Proof of Theorem 3.3,[0],[0]
"and we can estimate t̃0 and verify that indeed p̃0 < α · e − r−pn−p ) provided
r ≥ p+ max { C1 σ2(c̃2α + τ̃ 2 α)
β2jσmin(Σ) , C2 ln(1/ν)
}
and n ≥ max { r, C3
w2
min{σmin(Σ), σ2} , C4(p+ ln(1/ν)) } where c̃α, τ̃α denote the numbers s.t. ∞∫
c̃α/e
r−p n−p
PDFTr−p(x)dx = α 2 e",B.3. Proof of Theorem 3.3,[0],[0]
"− r−pn−p and
∞∫ τ̃α/e r−p n−p PDFN (0,1)(x)dx = α 2 e",B.3. Proof of Theorem 3.3,[0],[0]
"− r−pn−p resp.
",B.3. Proof of Theorem 3.3,[0],[0]
Proof.,B.3. Proof of Theorem 3.3,[0],[0]
"First we need to use the lower bound on n to show that indeed Algorithm 1 does not alter A, and that various quantities are not far from their expected values.",B.3. Proof of Theorem 3.3,[0],[0]
"Formally, we claim the following.
",B.3. Proof of Theorem 3.3,[0],[0]
Proposition B.8.,B.3. Proof of Theorem 3.3,[0],[0]
"Under the same lower bounds on n and r as in Theorem 3.3, w.p. 1−α−ν we have that Theorem 3.1 holds and also that
ζ̃‖2 = Θ( r−pr ‖PU⊥e‖ 2) = Θ( r−pr (n− p)σ 2)
and (XTRTRX)−1j,j = Θ( 1 r−p (X TX)−1j,j )
",B.3. Proof of Theorem 3.3,[0],[0]
Proof of Proposition B.8.,B.3. Proof of Theorem 3.3,[0],[0]
"First, we need to argue that we have enough samples as to have the gap σ2min([X; y])−w2 sufficiently large.
",B.3. Proof of Theorem 3.3,[0],[0]
"Since xi ∼ N (0,Σ), and yi = βTxi + ei with ei ∼ N (0, σ2), we have that the concatenation (xi ◦ yi) is also sampled from a Gaussian.",B.3. Proof of Theorem 3.3,[0],[0]
"Clearly, E[yi] = βTE[xi] + E[ei] = 0.",B.3. Proof of Theorem 3.3,[0],[0]
"Similarly, E[xi,jyi] = E[xi,j · (βTxi + ei)] = (Σβ)j and E[y2i ] = E[e 2",B.3. Proof of Theorem 3.3,[0],[0]
i ],B.3. Proof of Theorem 3.3,[0],[0]
+ E[‖Xβ‖2] = σ2 + E[βTXTXβ ] = σ2 + βTΣβ .,B.3. Proof of Theorem 3.3,[0],[0]
"Therefore, each row of A is an i.i.d sample of N (0p+1,ΣA), with
ΣA =
( Σ Σβ
βTΣ σ2+βTΣβ )",B.3. Proof of Theorem 3.3,[0],[0]
Denote λ2 = σmin(Σ).,B.3. Proof of Theorem 3.3,[0],[0]
"Then, to argue that σmin(ΣA) is large we use the lower bound from (Ma & Zarowski, 1995) (Theorem 3.1) combining with some simple arithmetic manipulations to deduce that σmin(ΣA) ≥ min{σmin(Σ), σ2}.
Having established a lower bound on σmin(ΣA), it follows that with n = Ω(p ln(1/ν))",B.3. Proof of Theorem 3.3,[0],[0]
"i.i.d draws from N (0p+1,ΣA) we have w.p. ≤ ν/4",B.3. Proof of Theorem 3.3,[0],[0]
"that σmin(ATA) = o(n) · min{σmin(Σ), σ2}.",B.3. Proof of Theorem 3.3,[0],[0]
Conditioned on σmin(ATA) = Ω(nσmin(ΣA)),B.3. Proof of Theorem 3.3,[0],[0]
"= Ω(w
2) being large enough, we have that w.p. ≤ ν/4",B.3. Proof of Theorem 3.3,[0],[0]
over the randomness of Algorithm 1 the matrix A does not pass the if-condition and the output of the algorithm is not RA.,B.3. Proof of Theorem 3.3,[0],[0]
"Conditioned on Algorithm 1 outputting RA, and due to the lower bound r = p + Ω(ln(1/ν)), we have that the result of Theorem 3.1 does not hold w.p. ≤ α+ ν/4.",B.3. Proof of Theorem 3.3,[0],[0]
All in all we deduce that w.p. ≥ 1−α− 3ν/4 the result of Theorem 3.1 holds.,B.3. Proof of Theorem 3.3,[0],[0]
"And since we argue Theorem 3.1 holds, then the following two bounds that are used in the proof14 also hold:
(XTRTRX)−1j,j = Θ( 1 r−p (X TX)−1j,j )
‖PU⊥e‖2 = Θ((n− p)σ2)
",B.3. Proof of Theorem 3.3,[0],[0]
"Lastly, in the proof of Theorem 3.1 we argue that for a given PU⊥e the length ‖ζ̃‖2 is distributed like ‖P U⊥e‖ 2
r χ 2 r−p.",B.3. Proof of Theorem 3.3,[0],[0]
Appealing again to the fact that r = p + Ω(ln(1/ν) we have that w.p. ≥ ν/4,B.3. Proof of Theorem 3.3,[0],[0]
"it holds that ‖ζ̃‖2 > 2(r − p)‖PU⊥e‖ 2
r .",B.3. Proof of Theorem 3.3,[0],[0]
"Plugging in the value of ‖PU⊥e‖ 2 con-
cludes the proof of the proposition.
",B.3. Proof of Theorem 3.3,[0],[0]
"Based on Proposition B.8, we now show that we indeed reject the null-hypothesis (as we should).",B.3. Proof of Theorem 3.3,[0],[0]
"When Theorem 3.1 holds, reject the null-hypothesis iff p̃0 < α · e − r−pn−p which holds iff |t̃0| > e r−p n−p τ̃α.",B.3. Proof of Theorem 3.3,[0],[0]
This implies we reject that null-hypothesis when |β̃j | > e,B.3. Proof of Theorem 3.3,[0],[0]
"r−p n−p τ̃α ·
σ̃ √
(XTRTRX)−1j,j ).",B.3. Proof of Theorem 3.3,[0],[0]
"Note that this bound is based
on Corollary 3.2 that determines that |β̃j − βj | =
O ( e r−p n−p c̃α · σ̃ √ (XTRTRX)−1j,j ) ) .",B.3. Proof of Theorem 3.3,[0],[0]
"And so we have that
w.p. ≥ 1− ν",B.3. Proof of Theorem 3.3,[0],[0]
we α-reject the null hypothesis when it holds that |βj,B.3. Proof of Theorem 3.3,[0],[0]
"| > 3(c̃α+ τ̃α) · σ̃ √ (XTRTRX)−1j,j )",B.3. Proof of Theorem 3.3,[0],[0]
"≥ e r−p n−p (c̃α+
τ̃α)σ̃ √ (XTRTRX)−1j,j ) (due to the lower bound n ≥ r).
",B.3. Proof of Theorem 3.3,[0],[0]
"Based on the bounds stated above we have that σ̃ = ‖ζ̃‖ √
r r−p = Θ(σ
√ n− p √ r−p r √ r r−p )",B.3. Proof of Theorem 3.3,[0],[0]
"= Θ(σ √ n− p)
and that
(XTRTRX)−1j,j = Θ( 1 r−p (X TX)−1j,j ) =",B.3. Proof of Theorem 3.3,[0],[0]
O ( 1 r−p · 1 nσmin(Σ) ),B.3. Proof of Theorem 3.3,[0],[0]
"And so, a sufficient condition for rejecting the nullhypothesis is to have
|βj",B.3. Proof of Theorem 3.3,[0],[0]
| = Ω ( (c̃α + τ̃α)σ,B.3. Proof of Theorem 3.3,[0],[0]
"√ n− p r − p · √ 1 nσmin(Σ) ) 14More accurately, both are bounds shown in Claim B.6.
= Ω(e r−p n−p (c̃α + τ̃α)σ̃ √ (XTRTRX)−1j,j ))
which, given the lower bound r = p + Ω ( (c̃α+τ̃α) 2σ2
β2jσmin(Σ) )",B.3. Proof of Theorem 3.3,[0],[0]
indeed holds.,B.3. Proof of Theorem 3.3,[0],[0]
In this section we deal with the case that our matrix does not pass the if-condition of Algorithm 1.,C. Projected Ridge Regression,[0],[0]
"In this case, the matrix is appended with a d × d-matrix which is wId×d.
Denoting A′ =",C. Projected Ridge Regression,[0],[0]
"[
A w · Id×d
] we have that the algorithm’s
output is RA′.
Similarly to before, we are going to denote d = p + 1 and decompose A =",C. Projected Ridge Regression,[0],[0]
"[X;y] with X ∈ Rn×p and y ∈ Rn, with the standard assumption of y = Xβ + e and ei sampled i.i.d from N (0, σ2).15 We now need to introduce some additional notation.",C. Projected Ridge Regression,[0],[0]
We denote the appended matrix and vectors X ′,C. Projected Ridge Regression,[0],[0]
and y ′ s.t. A′ =,C. Projected Ridge Regression,[0],[0]
[X ′;y ′].,C. Projected Ridge Regression,[0],[0]
"Meaning:
X ′ =  XwIp×p 0Tp  and
y ′ =  y0p w  = X ′β +  e−wβ w  def=",C. Projected Ridge Regression,[0],[0]
X ′β,C. Projected Ridge Regression,[0],[0]
+,C. Projected Ridge Regression,[0],[0]
e′,C. Projected Ridge Regression,[0],[0]
And so we respectively denote R =,C. Projected Ridge Regression,[0],[0]
"[R1;R2;R3] with R1 ∈ Rr×n,",C. Projected Ridge Regression,[0],[0]
R2 ∈ Rr×p and R3 ∈ Rr×1,C. Projected Ridge Regression,[0],[0]
(so R3 is a vector denoted as a matrix).,C. Projected Ridge Regression,[0],[0]
"Hence:
M ′ = RX ′ = R1X + wR2
and
Ry ′ = RX ′β+Re′ = R1y+wR3 = R1Xβ+R1e+wR3
And so, using the output RA′ of Algorithm 1, we solve the linear regression problem derived from 1√
r RX ′",C. Projected Ridge Regression,[0],[0]
"and
1√ r Ry ′. I.e., we set
β ′",C. Projected Ridge Regression,[0],[0]
"= arg min z 1 r‖Ry ′ −RX ′z‖2
= (X ′TRTRX ′)−1(RX ′)T(Ry ′)
",C. Projected Ridge Regression,[0],[0]
"Sarlos’ results (2006) regarding the Johnson Lindenstrauss transform give that, when R has sufficiently many rows, solving the latter optimization problem gives a good approximation for the solution of the optimization problem βR",C. Projected Ridge Regression,[0],[0]
= arg minz ‖y ′,C. Projected Ridge Regression,[0],[0]
"−X ′z‖2 = arg minz ( ‖y −Xz‖2 + w2‖z‖2
) 15Just",C. Projected Ridge Regression,[0],[0]
"as before, it is possible to denote any single column as y
and any subset of the remaining columns as X .
",C. Projected Ridge Regression,[0],[0]
The latter problem is known as the Ridge Regression problem.,C. Projected Ridge Regression,[0],[0]
"Invented in the 60s (Tikhonov, 1963; Hoerl & Kennard, 1970), Ridge Regression is often motivated from the perspective of penalizing linear vectors whose coefficients are too large.",C. Projected Ridge Regression,[0],[0]
It is also often applied in the case where X doesn’t have full rank or is close to not having full-rank.,C. Projected Ridge Regression,[0],[0]
That is because the Ridge Regression problem is always solvable.,C. Projected Ridge Regression,[0],[0]
One can show that the minimizer βR =,C. Projected Ridge Regression,[0],[0]
"(XTX + w2Ip×p)
−1XTy is the unique solution of the Ridge Regression problem and that the RHS is always defined (even when X is singular).
",C. Projected Ridge Regression,[0],[0]
The original focus of Ridge Regression is on penalizing βR for having large coefficients.,C. Projected Ridge Regression,[0],[0]
"Therefore, Ridge Regression actually poses a family of linear regression problems: minz ‖y−Xz‖+ λ‖z‖2, where one may set λ to be any non-negative scalar.",C. Projected Ridge Regression,[0],[0]
"And so, much of the literature on Ridge Regression is devoted to the art of fine-tuning this penalty term — either empirically or based on the λ that yields the best risk: ‖E[βR]",C. Projected Ridge Regression,[0],[0]
− β‖2 +,C. Projected Ridge Regression,[0],[0]
Var(βR).16,C. Projected Ridge Regression,[0],[0]
"Here we propose a fundamentally different approach for the choice of the normalization factor — we set it so that solution of the regression problem would satisfy ( , δ)-differential privacy (by projecting the problem onto a lower dimension).
",C. Projected Ridge Regression,[0],[0]
"While the solution of the Ridge Regression problem might have smaller risk than the OLS solution, it is not known how to derive t-values and/or reject the null hypothesis under Ridge Regression (except for using X to manipulate βR back into β̂ =",C. Projected Ridge Regression,[0],[0]
(XTX)−1XTy and relying on OLS).,C. Projected Ridge Regression,[0],[0]
"In fact, prior to our work there was no need for such analysis!",C. Projected Ridge Regression,[0],[0]
"For confidence intervals one could just use the standard OLS, because access to X and y was given.
",C. Projected Ridge Regression,[0],[0]
"Therefore, much for the same reason, we are unable to derive t-values under projected Ridge Regression.17",C. Projected Ridge Regression,[0],[0]
"Clearly, there are situations where such confidence bounds simply cannot be derived.",C. Projected Ridge Regression,[0],[0]
"(Consider for example the case where X = 0n×p and y is just i.i.d draws from N (0, σ2), so obviously [X; y] gives no information about β .)",C. Projected Ridge Regression,[0],[0]
"Nonetheless, under additional assumptions about the data, our work can give confidence intervals for βj , and in the case where the interval doesn’t intersect the origin — assure us that sign(β′j) = sign(βj) w.h.p.
",C. Projected Ridge Regression,[0],[0]
"Clearly, Sarlos’ work (2006) gives an upper bound on the distance ‖β",C. Projected Ridge Regression,[0],[0]
"′−βR‖. However, such distance bound doesn’t come with the coordinate by coordinate confidence guarantee we would like to have.",C. Projected Ridge Regression,[0],[0]
"In fact, it is not even clear from Sarlos’ work that E[β ′] = βR",C. Projected Ridge Regression,[0],[0]
(though it is obvious to see that E[(X ′TRTRX ′)]βR = E[(RX ′)TRy ′]).,C. Projected Ridge Regression,[0],[0]
"Here,
16Ridge Regression, as opposed to OLS, does not yield an unbiased estimator.",C. Projected Ridge Regression,[0],[0]
"I.e., E[βR] 6= β .
",C. Projected Ridge Regression,[0],[0]
17Note: The naı̈ve approach of using RX ′,C. Projected Ridge Regression,[0],[0]
"and Ry ′ to interpolate RX and Ry and then apply Theorem 3.1 using these estimations of RX and Ry ignores the noise added from appending the matrix A into A′, and it is therefore bound to produce inaccurate estimations of the t-values.
",C. Projected Ridge Regression,[0],[0]
"we show that E[β ′] = β̂ which, more often than not, does not equal βR.
Comment about notation.",C. Projected Ridge Regression,[0],[0]
Throughout this section we assume X is of full rank and so (XTX)−1 is well-defined.,C. Projected Ridge Regression,[0],[0]
"If X isn’t full-rank, then one can simply replace any occurrence of (XTX)−1 with X+(X+)T. This makes all our formulas well-defined in the general case.",C. Projected Ridge Regression,[0],[0]
"In this section, we analyze the projected Ridge Regression, under the assumption (for now) that e is fixed.",C.1. Running OLS on the Projected Data,[0],[0]
"That is, for now we assume that the only source of randomness comes from picking the matrix R =",C.1. Running OLS on the Projected Data,[0],[0]
[R1;R2;R3].,C.1. Running OLS on the Projected Data,[0],[0]
"As before, we analyze the distribution over β ′",C.1. Running OLS on the Projected Data,[0],[0]
"(see Equation (9)), and the value of the function we optimize at β ′. Denoting M ′",C.1. Running OLS on the Projected Data,[0],[0]
"= RX ′, we can formally express the estimators:
β ′",C.1. Running OLS on the Projected Data,[0],[0]
= (M ′TM ′)−1M ′TRy ′,C.1. Running OLS on the Projected Data,[0],[0]
(9) ζ ′,C.1. Running OLS on the Projected Data,[0],[0]
"= 1√
r",C.1. Running OLS on the Projected Data,[0],[0]
"(Ry ′ −RX ′β ′) (10)
Claim C.1.",C.1. Running OLS on the Projected Data,[0],[0]
"Given that y = Xβ+e for a fixed e, and given X and M ′ = RX ′ = R1X + wR2 we have that β ′",C.1. Running OLS on the Projected Data,[0],[0]
"∼ N ( β +X+e,
(w2(‖β +X+e‖2 + 1) +",C.1. Running OLS on the Projected Data,[0],[0]
"‖PU⊥e‖2)(M ′TM ′)−1 )
ζ ′",C.1. Running OLS on the Projected Data,[0],[0]
"∼ N ( 0r,
w2(‖β+X+e‖2+1)+‖P U⊥e‖ 2
r (Ir×r −M ′M ′+) ) and furthermore, β ′",C.1. Running OLS on the Projected Data,[0],[0]
"and ζ ′ are independent of one another.
",C.1. Running OLS on the Projected Data,[0],[0]
Proof.,C.1. Running OLS on the Projected Data,[0],[0]
"First, we write β ′",C.1. Running OLS on the Projected Data,[0],[0]
and ζ ′,C.1. Running OLS on the Projected Data,[0],[0]
"explicitly, based on e and projection matrices:
β ′",C.1. Running OLS on the Projected Data,[0],[0]
"= (M ′TM ′)−1M ′TRy ′
= M ′+(R1X)β",C.1. Running OLS on the Projected Data,[0],[0]
"+M ′+(R1e + wR3)
ζ ′",C.1. Running OLS on the Projected Data,[0],[0]
= 1√ r,C.1. Running OLS on the Projected Data,[0],[0]
"(Ry ′ −RX ′β ′)
",C.1. Running OLS on the Projected Data,[0],[0]
= 1√ r,C.1. Running OLS on the Projected Data,[0],[0]
(Ir×r −M ′M ′+)Re′ = 1√ r PU ′⊥(R1e,C.1. Running OLS on the Projected Data,[0],[0]
"− wR2β + wR3)
with U ′ denoting colspan(M ′) and PU ′⊥ denoting the projection onto the subspace U ′⊥.
Again, we break e into an orthogonal composition: e = PUe + PU⊥e with U = colspan(X) (hence PU = XX+) and U⊥ = colspan(X)⊥.",C.1. Running OLS on the Projected Data,[0],[0]
"Therefore,
β ′",C.1. Running OLS on the Projected Data,[0],[0]
"= M ′+(R1X)β +M ′+(R1XX +e +R1PU⊥e + wR3) = M ′+(R1X)(β +X +e) +M ′+(R1PU⊥e + wR3)
whereas ζ ′ is essentially 1√ r (Ir×r −M ′M ′+)(R1XX+e +R1PU⊥e − wR2β + wR3)
(∗) = 1√
r (Ir×r −M ′M ′+)·
(R1XX +e +R1PU⊥e + (M ′",C.1. Running OLS on the Projected Data,[0],[0]
"− wR2)β + wR3) = 1√
r (Ir×r −M ′M ′+)·
(R1X(β +X +e) +R1PU⊥e + wR3)
where equality (∗) holds because (I −M ′M ′+)M ′v = 0 for any v .
",C.1. Running OLS on the Projected Data,[0],[0]
We now aim to describe the distribution of R given that we know X ′,C.1. Running OLS on the Projected Data,[0],[0]
"and M ′ = RX ′. Since
M ′ = R1X + wR2 + 0",C.1. Running OLS on the Projected Data,[0],[0]
"·R3 = R1X(X+X) + wR2 = (R1PU )X + wR2
then M ′ is independent of R3 and independent of R1PU⊥ .",C.1. Running OLS on the Projected Data,[0],[0]
"Therefore, given X and M ′",C.1. Running OLS on the Projected Data,[0],[0]
"the induced distribution over R3 remainsR3 ∼ N (0r, Ir×r), and similarly, givenX and M ′",C.1. Running OLS on the Projected Data,[0],[0]
"we have R1PU⊥ ∼ N (0r×n, Ir×r, PU⊥) (rows remain independent from one another, and each row is distributed like a spherical Gaussian in colspan(X)⊥).",C.1. Running OLS on the Projected Data,[0],[0]
"And so, we have that R1X = R1PUX = M ′",C.1. Running OLS on the Projected Data,[0],[0]
"− wR2, which in turn implies:
R1X ∼ N",C.1. Running OLS on the Projected Data,[0],[0]
"( M ′, Ir×r, w 2 · Ip×p )
multiplying this random matrix with a vector, we get
R1X(β+X +e) ∼ N (M ′β",C.1. Running OLS on the Projected Data,[0],[0]
"+M ′X+e, w2‖β +X+e‖2Ir×r)
and multiplying this random vector with a matrix we get
M ′+R1X(β+X +e) ∼ N (β +X+e, w2‖β",C.1. Running OLS on the Projected Data,[0],[0]
"+X+e‖2(M ′TM)−1)
I.e.,
M ′+R1X(β+X +e) ∼ ‖β+X+e‖·N (u,w2(M ′TM)−1)
where u denotes a unit-length vector in the direction of β+ X+e.
Similar to before we have
RPU⊥ ∼ N (0r×n, Ir×r, PU⊥) ⇒M",C.1. Running OLS on the Projected Data,[0],[0]
′+(RPU⊥e),C.1. Running OLS on the Projected Data,[0],[0]
"∼ N (0d, ‖PU⊥e‖2(M ′TM ′)−1)
wR3 ∼ N (0r, w2Ir×r) ⇒M ′+(wR3) ∼ N (0d, w2(M ′+M ′)−1)
Therefore, the distribution of β ′, which is the sum of the 3 independent Gaussians, is as required.
",C.1. Running OLS on the Projected Data,[0],[0]
"Also, ζ ′ = 1√ r PU ′⊥ (R1X(β +X +e) +R1PU⊥e + wR3) is the sum of 3 independent Gaussians, which implies its distribution is
N (
1√ r PU ′⊥M ′(β +X+e),
1 r (w 2(‖β",C.1. Running OLS on the Projected Data,[0],[0]
"+X+e‖2 + 1) + ‖PU⊥e‖2)PU ′⊥ )
I.e., N ( 0r, 1 r (w 2(‖β +X+e‖2 + 1) + ‖PU⊥e‖2)PU ′⊥ ) as PU ′⊥M ′",C.1. Running OLS on the Projected Data,[0],[0]
"= 0r×r.
Finally, observe that β ′",C.1. Running OLS on the Projected Data,[0],[0]
and ζ ′ are independent as the former depends on the projection of the spherical Gaussian R1X(β,C.1. Running OLS on the Projected Data,[0],[0]
+,C.1. Running OLS on the Projected Data,[0],[0]
"X
+e) + R1PU⊥e + wR3 on U ′, and the latter depends on the projection of the same multivariate Gaussian on U ′⊥.
Observe that Claim C.1 assumes e is given.",C.1. Running OLS on the Projected Data,[0],[0]
"This may seem somewhat strange, since without assuming anything about e there can be many combinations of β and e for which y = Xβ + e.",C.1. Running OLS on the Projected Data,[0],[0]
"However, we always have that β + X+e = X+y = β̂ .",C.1. Running OLS on the Projected Data,[0],[0]
"Similarly, it is always the case the PU⊥e = (I − XX+)y = ζ .",C.1. Running OLS on the Projected Data,[0],[0]
(Recall OLS definitions of β̂ and ζ in Equation (1) and (2).),C.1. Running OLS on the Projected Data,[0],[0]
"Therefore, the distribution of β ′ and ζ ′ is unique (once y is set):
β ′",C.1. Running OLS on the Projected Data,[0],[0]
"∼ N ( β̂ , (w2(‖β̂‖2 + 1) +",C.1. Running OLS on the Projected Data,[0],[0]
‖ζ‖2)(M ′TM ′)−1 ) ζ ′,C.1. Running OLS on the Projected Data,[0],[0]
"∼ N ( 0r, w2(‖β̂‖2 + 1) + ‖ζ‖2
",C.1. Running OLS on the Projected Data,[0],[0]
"r (Ir×r −M ′M ′+)
)
",C.1. Running OLS on the Projected Data,[0],[0]
"And so for a given dataset [X;y] we have that β ′ serves as an approximation for β̂ .
",C.1. Running OLS on the Projected Data,[0],[0]
An immediate corollary of Claim C.1 is that for any fixed e it holds that the quantity t′(βj),C.1. Running OLS on the Projected Data,[0],[0]
"=
β′j−(βj+(X +e)j) ‖ζ ′‖",C.1. Running OLS on the Projected Data,[0],[0]
"√ r r−p ·(M ′TM ′)−1j,j = β′j−β̂j ‖ζ ′‖",C.1. Running OLS on the Projected Data,[0],[0]
"√ r r−p ·(M ′TM ′)−1j,j is distributed like a Tr−p-distribution.",C.1. Running OLS on the Projected Data,[0],[0]
"Therefore, the following theorem follows immediately.
",C.1. Running OLS on the Projected Data,[0],[0]
Theorem C.2.,C.1. Running OLS on the Projected Data,[0],[0]
Fix X ∈ Rn×p and y ∈ R. Define β̂ = X+y and ζ =,C.1. Running OLS on the Projected Data,[0],[0]
(I − XX+)y .,C.1. Running OLS on the Projected Data,[0],[0]
Let RX ′,C.1. Running OLS on the Projected Data,[0],[0]
and Ry ′ denote the result of applying Algorithm 1 to the matrix A = [X;y] when the algorithm appends the data with a w · I matrix.,C.1. Running OLS on the Projected Data,[0],[0]
"Fix a coordinate j and any α ∈ (0, 1/2).",C.1. Running OLS on the Projected Data,[0],[0]
When computing β ′,C.1. Running OLS on the Projected Data,[0],[0]
and ζ ′,C.1. Running OLS on the Projected Data,[0],[0]
"as in Equations (9) it and (10), we have that w.p. ≥ 1− α it holds that
β̂j ∈",C.1. Running OLS on the Projected Data,[0],[0]
( β′j ± c′α‖ζ ′‖,C.1. Running OLS on the Projected Data,[0],[0]
√ r r−p · (M ′TM ′) −1,C.1. Running OLS on the Projected Data,[0],[0]
"j,j ) where c′α denotes the number such that (−c′α, c′α) contains 1− α mass of the Tr−p-distribution.
",C.1. Running OLS on the Projected Data,[0],[0]
"Note that Theorem C.2, much like the rest of the discussion in this Section, builds on y being fixed, which means β′j serves as an approximation for β̂j .",C.1. Running OLS on the Projected Data,[0],[0]
Yet our goal is to argue about similarity (or proximity) between β′j and βj .,C.1. Running OLS on the Projected Data,[0],[0]
"To that end, we combine the standard OLS confidence interval — which says that w.p. ≥ 1 − α over the randomness of picking e in the homoscedastic model we have
|βj − β̂j | ≤",C.1. Running OLS on the Projected Data,[0],[0]
"cα‖ζ‖ √ (XTX)−1j,j n−p — with the confidence interval of Theorem C.2 above, and deduce that w.p. ≥ 1−α
we have that |β′j",C.1. Running OLS on the Projected Data,[0],[0]
"− βj | is at most
O cα ‖ζ‖ √
(XTX)−1j,j √ n− p + c′α ‖ζ ′‖",C.1. Running OLS on the Projected Data,[0],[0]
"√ r(M ′TM ′)−1j,j √ r − p  ",C.1. Running OLS on the Projected Data,[0],[0]
"(11)
18And so, in the next section, our goal is to give conditions under which the interval of Equation (11) isn’t much larger in comparison to the interval length of c′α ‖ζ ′‖√",C.1. Running OLS on the Projected Data,[0],[0]
"r−p √ r(M ′TM ′)−1j,j we get from Theorem C.2; and more importantly — conditions that make the interval of Theorem C.2 useful and not too large.",C.1. Running OLS on the Projected Data,[0],[0]
"(Note, in expectation ‖ζ",C.1. Running OLS on the Projected Data,[0],[0]
′‖√ r−p is about √ (w2 + w2‖β̂‖2,C.1. Running OLS on the Projected Data,[0],[0]
+ ‖ζ‖2)/r.,C.1. Running OLS on the Projected Data,[0],[0]
"So, for example, in situations where ‖β̂‖ is very large, this interval isn’t likely to inform us as to the sign of βj .)
",C.1. Running OLS on the Projected Data,[0],[0]
Motivating Example.,C.1. Running OLS on the Projected Data,[0],[0]
"A good motivating example for the discussion in the following section is when [X;y] is a strict submatrix of the dataset A. That is, our data contains many variables for each entry (i.e., the dimensionality d of each entry is large), yet our regression is made only over a modest subset of variables out of the d.",C.1. Running OLS on the Projected Data,[0],[0]
"In this case, the least singular value of A might be too small, causing the algorithm to alter A; however, σmin(XTX) could be sufficiently large so that had we run Algorithm 1 only on [X;y] we would not alter the input.",C.1. Running OLS on the Projected Data,[0],[0]
"(Indeed, a differentially private way for finding a subset of the variables that induce a submatrix with high σmin is an interesting open question, partially answered — for a single regression — in the work of Thakurta and Smith (Thakurta & Smith, 2013).)",C.1. Running OLS on the Projected Data,[0],[0]
"Indeed, the conditions we specify in the following section depend on σmin( 1nX
TX), which, for a zero-mean data, the minimal variance of the data in any direction.",C.1. Running OLS on the Projected Data,[0],[0]
"For this motivating example, indeed such variance isn’t necessarily small.",C.1. Running OLS on the Projected Data,[0],[0]
"Looking at the interval specified in Equation (11), we now give an upper bound on the the random quantities in this interval: ‖ζ‖, ‖ζ ′‖, and (M ′TM ′)−1j,j .",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"First, we give bound that are dependent on the randomness in R (i.e., we continue to view e as fixed).
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
Proposition C.3.,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
For any ν ∈,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"(0, 1/2), if we have r = p + Ω(ln(1/ν))",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"then with probability ≥
18Observe that w.p. ≥ 1 − α over the randomness of e we have that |βj",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
− β̂j | ≤,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"cα‖ζ‖ √ (XTX)−1j,j n−p , and w.p. ≥ 1",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
− α over the randomness of R we have that |β′j,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
− β̂j | ≤ c′α‖ζ ′‖,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
√ r r−p · (M ′TM ′) −1,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"j,j .",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"So technically, to give a (1 − α)confidence interval around β′j",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"that contains βj w.p. ≥ 1− α, we need to use cα/2 and c′α/2 instead of cα and c ′",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
α resp.,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"To avoid overburdening the reader with what we already see as too many parameters, we switch to asymptotic notation.
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"1 − ν over the randomness of R we have (r − p)(M ′TM)−1j,j = Θ ( (w2Ip×p +X TX)−1j,j ) and ‖ζ",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"′‖2 r−p = Θ(w 2+w2‖β̂‖2+‖ζ‖2
r ).
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
Proof.,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
The former bound follows from known results on the Johnson-Lindenstrauss transform (as were shown in the proof of Claim B.6).,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"The latter bound follows from standard concentration bounds of the χ2-distribution.
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
Plugging in the result of Proposition C.3 to Equation (11) we get that w.p. ≥ 1− ν the difference |β′j,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"− βj | is at most O ( cα ‖ζ‖√ n− p √ (XTX)−1j,j
+ c′α
√ w2 +",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
w2‖β̂‖2,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
+,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"‖ζ‖2
r − p
√ (w2Ip×p +XTX) −1",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"j,j ) (12)
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"We will also use the following proposition.
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"Proposition C.4.
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"(XTX)−1j,j ≤ ( 1 + w2
σmin(XTX)
) (w2Ip×p +X TX)−1j,j
Proof.",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"We have that
(XTX)−1
= (XTX)−1(XTX + w2Ip×p)(X TX + w2Ip×p) −1
= (XTX + w2Ip×p) −1",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"+ w2(XTX)−1(XTX + w2Ip×p) −1
= (Ip×p + w 2(XTX)−1)(XTX + w2Ip×p) −1
= (XTX + w2Ip×p) −1/2·
(Ip×p + w 2(XTX)−1)·
(XTX + w2Ip×p) −1/2
where the latter holds because (Ip×p + w2(XTX)−1) and (XTX + w2Ip×p)
−1 are diagonalizable by the same matrix V (the same matrix for which (XTX) = V S−1V T).",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"Since we have ‖Ip×p +w2(XTX)−1‖ = 1 + w 2
σ2min(X) , it is
clear that (Ip×p + w2(XTX)−1) (1 + w 2
σ2min(X) )",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"Ip×p.
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"We deduce that (XTX)−1j,j = e T j (X TX)−1ej ≤",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
(1 + w2 σ2min(X) ),C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
(XTX + w2Ip×p) −1,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"j,j .
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"Based on Proposition C.4 we get from Equation (12) that
|β′j",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"− βj | is at most
O( ( cα √√√√‖ζ‖2(1 + w2σmin(XTX) )",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"n− p +
c′α
√ w2 + w2‖β̂‖2",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"+ ‖ζ‖2
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"r − p
)√ (w2Ip×p +XTX) −1",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"j,j )
(13)
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"And so, if it happens to be the case that exists some small η > 0 for which β̂ , ζ and w2 satisfy
‖ζ‖2(1 + w 2
σmin(XTX) )
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"n− p ≤ η2
( w2 + w2‖β̂‖2",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"+ ‖ζ‖2
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"r − p
) (14)
then we have that Pr[βj ∈( β′j ±O((1 + η) · c′α‖ζ ′‖",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
√ r r−p · (M ′TM ′) −1,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"j,j ) )
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
],C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
≥ 1 − α.19,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"Moreover, if in this case |βj |",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
">
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"c′α(1 + η)
√ w2+w2‖β̂‖2+‖ζ‖2
r−p
√ (w2Ip×p +XTX) −1",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"j,j
then Pr[sign(β′j) = sign(βj)]",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
≥ 1− α.,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
This is precisely what Claims C.5 and C.6 below do.,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
Claim C.5.,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
If there exists η > 0 s.t. n,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
− p ≥ 2η2,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"(r − p) and n 2 =
Ω ( r3/2 · B 2 ln(1/δ) ·
1
η2σmin( 1 nX TX) ) , then Pr[βj ∈(
β′j ±O((1 + η) · c′α‖ζ ′‖",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
√ r r−p · (M ′TM ′) −1,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"j,j ) )
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
],C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"≥ 1− α.
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
Proof.,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"Based on the above discussion, it is enough to argue that under the conditions of the claim, the constraint of Equation (14) holds.",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"Since we require η 2
2 ≥ r−p n−p then
it is evident that ‖ζ‖ 2 n−p ≤ η2‖ζ‖2 2(r−p) .",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"So we now show that ‖ζ‖2 n−p · w2 σmin(XTX) ≤ η 2‖ζ‖2 2(r−p) under the conditions of the claim, and this will show the required.",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
All that is left is some algebraic manipulations.,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"It suffices to have:
η2 2 · n−p r−pσmin(X TX)",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
≥,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"η 2 2 · n2 r σmin( 1 nX TX)
≥ 32B 2 √ r ln(8/δ) ≥ w2
which holds for n2 ≥ r3/2 · 64B 2 ln(1/δ) η2 σmin( 1 nX TX)−1, as we assume to hold.
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
Claim C.6.,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"Fix ν ∈ (0, 12 ).",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"If (i) n = p + Ω(ln(1/ν)), (ii) ‖β‖2 = Ω(σ2‖X+‖2F ln( p ν ))",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
and (iii) r,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"− p =
Ω
( (c′α) 2(1+η)2
β2j
( 1 + ‖β‖2",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"+ σ 2
σmin( 1 nX TX)
)) , then in the
homoscedastic model, with probability≥ 1−ν−α",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"we have that sign(βj) = sign(β′j).
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
19We assume n ≥ r,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
so,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"cα < c′α as the Tn−p-distribution is closer to a normal Gaussian than the Tr−p-distribution.
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
Proof.,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"Based on the above discussion, we aim to show that in the homoscedastic model (where each coordinate ei ∼ N (0, σ2) independently) w.p. ≥ 1",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
− ν,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"it holds that the magnitude of βj is greater than
c′α(1+η)
√ w2 + w2‖β̂‖2",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"+ ‖ζ‖2
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"r − p
√ (w2Ip×p +XTX) −1",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"j,j
To show this, we invoke Claim A.4 to argue that w.p. ≥ 1 − ν we have (i) ‖ζ‖2 ≤ 2σ2(n",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"− p) (since n = p + Ω(ln(1/ν))), and (ii) ‖β̂‖2 ≤ 2‖β‖2 (since ‖β − β̂‖2 ≤",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
σ2‖X+‖2F,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
ln( p ν ),C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
whereas ‖β‖ 2 = Ω(σ2‖X+‖2F ln( p ν ))).,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"We also use the fact that (w2Ip×p + XTX)−1j,j ≤ (w2 + σ−1min(X TX)), and then deduce that
(1 + η)c′α
√ w2 + w2‖β̂‖2",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"+ ‖ζ‖2
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"r − p
√ (w2Ip×p +XTX) −1",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"j,j
≤ (1 + η)c ′",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"α√
r − p
√ 2 w2(1 + ‖β‖2) + σ2(n− p)
w2 + σmin(XTX)
≤ (1 + η)c ′",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"α√
r − p
√ 2(1 + ‖β‖2) + 2σ
2(n− p) σmin(XTX) ≤",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
|βj,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"|
due to our requirement on r − p.
Observe, out of the 3 conditions specified in Claim C.6, condition (i) merely guarantees that the sample is large enough to argue that estimations are close to their expect value; and condition (ii) is there merely to guarantee that ‖β̂‖",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
≈ ‖β‖.,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"It is condition (iii) which is non-trivial to hold, especially together with the conditions of Claim C.5 that pose other constraints in regards to r, n, η and the various other parameters in play.",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
It is interesting to compare the requirements on r to the lower bound we get in Theorem 3.3 — especially the latter bound.,C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"The two bounds are strikingly similar, with the exception that here we also require r − p to be greater than 1+‖β‖ 2
β2j .",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"This is part of the
unfortunate effect of altering the matrix A: we cannot give confidence bounds only for the coordinates j for which β2j is very small relative to ‖β‖2.
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"In summary, we require to have n = p + Ω(ln(1/ν)) and that X contains enough sample points to have ‖β̂‖ comparable to ‖β‖, and then set r and η such that (it is convenient to think of η as a small constant, say, η = 0.1)
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
• r − p = O(η2(n− p)),C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
(which implies r = O(n)),C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"• r = O( ( η2 n 2
B2 ln(1/δ)σmin( 1 nX
TX) )",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"2 3 )
",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"• r − p = Ω( 1+‖β‖ 2
β2j + σ
2 β2j · σ−1min( 1nX TX))
to have that the (1 − α)-confidence interval around β′j does not intersect the origin.",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"Once again, we comment that these conditions are sufficient but not necessary, and furthermore — even with these conditions holding — we do not make any claims of optimality of our confidence bound.",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"That is because from Proposition C.4 onwards our discussion uses upper bounds that do not have corresponding lower bounds, to the best of our knowledge.",C.2. Conditions for Deriving a Confidence Interval for Ridge Regression,[0],[0]
"To complete the picture, we now analyze the “Analyze Gauss” algorithm of Dwork et al (Dwork et al., 2014).",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Algorithm 2 works by adding random Gaussian noise to ATA, where the noise is symmetric with each coordinate above the diagonal sampled i.i.d from N (0,∆2) with ∆2 = O ( B4 log(1/δ) 2 ) .20",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Using the same notation for a sub-matrix of A as [X;y] as before, with X ∈ Rn×p and y ∈ Rn, we denote the output of Algorithm 2 as X̃TX X̃Ty
ỹTX ỹTy
 =  XTX +N XTy +n
yTX +nT yTy +m  (15)
where N is a symmetric p× p-matrix, n is a p-dimensional vector and m is a scalar, whose coordinates are sampled i.i.d from N (0,∆2).
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Using the output of Algorithm 2, it is simple to derive analogues of β̂ and ‖ζ‖2 (Equations (1) and (2))
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
β̃ = ( X̃TX )−1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
X̃Ty =,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
( XTX +N )−1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"(XTy +n)
(16)
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
‖̃ζ‖2 = ỹTy,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
− 2 ỹTX β̃ + β̃ T X̃TX,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"β̃
= ỹTy",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
− ỹTX X̃TX −1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"X̃Ty (17)
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
We now argue that it is possible to use β̃j,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
and ‖̃ζ‖2 to get a confidence interval for βj under certain conditions.,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Theorem D.1.,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Fix α, ν ∈ (0, 12 ).",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Assume that there exists η ∈ (0, 12 ) s.t. σmin(X",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
TX) > ∆,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
√ p ln(1/ν)/η.,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Under the homoscedastic model, given β and σ2, if we assume also that ‖β‖ ≤ B and ‖β̂‖ =",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"‖(XTX)−1XTy‖ ≤ B, then w.p. ≥ 1− α− ν",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
it holds that |βj,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
− β̃j,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"| it at most O ( ρ · √( X̃TX −1 j,j + ∆",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
√ p ln(1/ν) · X̃TX −2,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"j,j ) ln(1/α)
20It is easy to see that the l2-global sensitivity of the mapping A 7→ ATA is ∝ B4.",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Fix any A1, A2 that differ on one row which is some vector v with ‖v‖ = B in A1 and the all zero vector in A2.",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Then GS22 = ‖AT1A1 − AT2A2‖2F = ‖vvT ‖2F = trace(vvT · vvT) = (vTv)2 = B4.
+ ∆",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
√ X̃TX −2,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"j,j · ln(1/ν) · (B √ p+ 1) ) where ρ is such that ρ2 is w.h.p an upper bound on σ2, defined as
ρ2 def = ( 1√
n−p−2 √ ln(4/α) )",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"2 ·(
‖̃ζ‖2 − C · ( ∆ B2 √ p
1−η
√ ln(1/ν) + ∆2‖X̃TX −1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
‖F · ln(p/ν) )),D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"for some large constant C.
We comment that in practice, instead of using ρ, it might be better to use the MLE of σ2, namely:
σ2 def = 1n−p
( ‖̃ζ‖2 + ∆2‖X̃TX −1 ‖F )
instead of ρ2, the upper bound we derived for σ2.",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
(Replacing an unknown variable with its MLE estimator is a common approach in applied statistics.),D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Note that the assumption that ‖β‖ ≤ B is fairly benign once we assume each row has bounded l2-norm.,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
The assumption ‖β̂‖,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"≤ B simply assumes that β̂ is a reasonable estimation of β , which is likely to hold if we assume that XTX is well-spread.",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
The assumption about the magnitude of the least singular value of XTX is therefore the major one.,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Nonetheless, in the case we considered before where each row inX is sampled i.i.d from N (0,Σ), this assumption merely means that n is large enough s.t. n",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"= Ω̃(∆ √ p ln(1/ν)
η·σmin(Σ) ).
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"In order to prove Theorem D.1, we require the following proposition.
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Proposition D.2.,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Fix any ν ∈,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"(0, 12 ).",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Fix any matrix M ∈ Rp×p.,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Let v,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
∈,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Rp be a vector with each coordinate sampled independently from a Gaussian N (0,∆2).",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Then we have that Pr [ ‖Mv‖ > ∆ ·,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
‖M‖F √ 2 ln(2p/ν) ],D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"< ν.
Proof.",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Given M , we have that Mv ∼ N (0,∆2 ·MMT).",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Denoting M ’s singular values as sv1, . . .",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
", svp, we can rotate Mv without affecting its l2-norm and infer that ‖Mv|2 is distributed like a sum on p independent Gaussians, each sampled fromN (0,∆2 · sv2i ).",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Standard union bound gives that w.p. ≥ 1 − ν non of the p Gaussians exceeds its standard deviation by a factor of √ 2 ln(2p/ν).,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Hence, w.p.
≥ 1 − ν it holds that ‖Mv‖2 ≤ 2∆2 ∑",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
i,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
sv 2 i ln(2p/ν),D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"= 2∆2 · trace(MMT) · ln(2p/ν).
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Our proof also requires the use of the following equality, that holds for any invertible A and any matrix B s.t.",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"I + B ·A−1 is invertible:
(A+B) −1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
= A−1 −A−1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
( I +BA−1 )−1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"BA−1
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"In our case, we have
X̃TX −1
= (XTX +N)−1
= (XTX)−1 − (XTX)−1 ( I +N(XTX)−1 )−1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"N(XTX)−1
= (XTX)−1 ( I − ( I +N(XTX)−1 )−1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
N(XTX)−1 ),D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"def = (XTX)−1 ( I − Z · (XTX)−1 ) (18)
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Proof of Theorem D.1.,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Fix ν > 0.,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"First, we apply to standard results about Gaussian matrices, such as (Tao, 2012) (used also by (Dwork et al., 2014) in their analysis), to see that w.p. ≥ 1 − ν/6 we have ‖N‖ = O(∆ √ p ln(1/ν)).",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"And so, for the remainder of the proof we fix N subject to having bounded operator norm.",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Note that by fixing N we
fix X̃TX .
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Recall that in the homoscedastic model, y = Xβ + e with each coordinate of e sampled i.i.d from N (0, σ2).",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"We therefore have that
β̃ = X̃TX −1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
(XTy +n) = X̃TX −1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"(XTXβ +XTe +n)
= X̃TX −1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
(X̃TX −N)β + X̃TX −1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
XTe + X̃TX −1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"n
=",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
β − X̃TX −1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Nβ + X̃TX −1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
XTe + X̃TX −1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"n
Denoting the j-th row of X̃TX −1 as X̃TX −1
j→ we deduce:
β̃j = βj − X̃TX −1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
j→Nβ + X̃ TX −1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
j→X Te + X̃TX −1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"j→n
(19)
We naı̈vely bound the size of the term X̃TX −1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
j→Nβ by ∥∥∥∥X̃TX −1j→∥∥∥∥,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"‖N‖‖β‖ =
O (∥∥∥∥X̃TX −1j→∥∥∥∥ ·B∆√p ln(1/ν)).",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"To bound X̃TX −1
j→X Te note that e is cho-
sen independently of X̃TX and since e ∼ N (0, σ2I) we have X̃TX −1
j→X",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Te ∼ N ( 0, σ2 · eTj X̃TX −1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
·XTX · X̃TX −1 ej ) .,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Since
we have
X̃TX −1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"·XTX · X̃TX −1
= X̃TX −1 · (X̃TX −N) · X̃TX −1
= X̃TX −1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
− X̃TX −1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"·N · X̃TX −1
we can bound the variance of X̃TX −1
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
j→X,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Te by
σ2 ( X̃TX −1 j,j + ‖N‖ · ∥∥∥∥X̃TX −1j→∥∥∥∥2 ) .",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Appealing to
Gaussian concentration bounds, we have that w.p. ≥ 1 − α/2 the absolute value of this Gaussian is at most
O √√√√(X̃TX",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"−1j,j + ∆√p ln(1/ν) · ∥∥∥∥X̃TX −1j→∥∥∥∥2 )",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
σ2 ln(1/α) .,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"To bound X̃TX −1
j→n note that n ∼ N (0,∆2I) is sampled independently of X̃TX .",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
We therefore have that X̃TX −1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"j→n ∼ N (0,∆2 ∥∥∥∥X̃TX −1j→∥∥∥∥2).",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Gaussian concentra-
tion bounds give that w.p≥ 1−ν/6 we have |X̃TX −1
j→n| =
O ( ∆ ∥∥∥∥X̃TX −1j→∥∥∥∥√ln(1/ν)).",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Plugging this into our above bounds on all terms that appear in Equation (19) we have that w.p. ≥ 1 − ν/2,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"− α/2 we have that
∣∣∣β̃j − βj∣∣∣ is at most O
(∥∥∥∥X̃TX −1j→∥∥∥∥ ·B∆√p ln(1/ν))",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
+O σ √√√√(X̃TX,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"−1j,j + ∆√p ln(1/ν) ·",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
∥∥∥∥X̃TX −1j→∥∥∥∥2 ),D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"ln(1/α)
 ",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
+O ( ∆ ∥∥∥∥X̃TX,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
−1j→∥∥∥∥√ln(1/,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"ν))
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Note that due to the symmetry of X̃TX,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
we have∥∥∥∥X̃TX −1j→∥∥∥∥2,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
= X̃TX,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"−2j,j (the (j, j)-coordinate of the matrix X̃TX −2 ), thus |β̃j − βj | is at most
O ( σ · √( X̃TX −1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"j,j + ∆",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
√ p ln(1/ν) · X̃TX −2,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"j,j ) ln(1/α)
+ ∆",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
√ X̃TX −2,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"j,j · ln(1/ν) · (B √ p+ 1) ) (20)
All of the terms appearing in Equation (20) are known
given X̃TX , except for σ — which is a parameter of the model.",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Next, we derive an upper bound on σ which we can then plug into Equation (20) to complete the proof of the theorem and derive a confidence interval for βj .
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Recall Equation (17), according to which we have
‖̃ζ‖2 = ỹTy − ỹTX X̃TX −1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"X̃Ty
(18) = yTy +m
− (yTX +nT)(XTX)−1(I",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"− Z · (XTX)−1)(XTy +n) = yTy +m
− yTX(XTX)−1XTy +",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"yTX(XTX)−1Z(XTX)−1XTy
− 2yTX(XTX)−1n + 2yTX(XTX)−1Z(XTX)−1n
−nT(XTX)−1(I − Z · (XTX)−1)n
Recall that β̂ =",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"(XTX)−1XTy , and so we have
= yT",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
( I −X(XTX)−1XT ) y +m− β̂,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"T Zβ̂
− 2β̂ T",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
(,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
I − Z(XTX)−1)n −nTX̃TX −1 n,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"(21)
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"and of course,",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"both n and m are chosen independently of
X̃TX and y .
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Before we bound each term in Equation (21), we first give a bound on ‖Z‖. Recall, Z =",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
( I +N(XTX)−1 )−1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
N .,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Recall our assumption (given in the statement of Theorem D.1) that σmin(XTX) ≥ ∆η √ p ln(1/ν).,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
This implies that ‖N(XTX)−1‖ ≤ ‖N‖·σmin(XTX)−1 = O(η).,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Hence
‖Z‖ ≤ (‖I+N(XTX)−1‖)−1 ·‖N‖ = O ( ∆ √ p ln(1/ν)
1−η )",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Moreover, this implies that ‖Z(XTX)−1‖ ≤",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"O ( η
1−η ) and that ‖I − Z(XTX)−1‖ ≤",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
O,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"( 1
1−η
) .
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Armed with these bounds on the operator norms of Z and (I−Z(XTX)−1) we bound the magnitude of the different terms in Equation (21).
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
• The term yT,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"(I −XX+)y is the exact term from the standard OLS, and we know it is distributed like σ2 · χ2n−p distribution.",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Therefore, it is greater than σ2( √ n− p − 2 √ ln(4/α))2 w.p. ≥ 1− α/2.
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"• The scalar m sampled from m ∼ N (0,∆2) is bounded by O(∆ √ ln(1/ν))",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"w.p. ≥ 1− ν/8.
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
• Since we assume ‖β̂‖,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"≤ B, the term β̂",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
T Zβ̂ is upper bounded by B2‖Z‖ =,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"O ( B2∆ √ p ln(1/ν)
1−η
) .
•",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Denote zTn = 2β̂,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"T
(I−Z(XTX)−1)n.",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"We thus have that zTn ∼ N (0,∆2‖z‖2) and that its magnitude is at
most O(∆ · ‖z‖ √
ln(1/ν))",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
w.p. ≥ 1 − ν/8.,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
We can upper bound ‖z‖ ≤ 2‖β̂‖,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"‖I − Z(XTX)−1‖ = O( B1−η ), and so this term’s magnitude is upper
bounded by O ( ∆·B √ ln(1/ν)
1−η
) .
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
•,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Given our assumption about the least singular value of XTX and with the bound on ‖N‖, we have that σmin(X̃TX) ≥ σmin(XTX) − ‖N‖ > 0",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
and so the symmetric matrix X̃TX is a PSD.,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Therefore,
the term nTX̃TX −1 n",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
= ‖X̃TX −1/2 n‖2 is strictly positive.,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
Applying Proposition D.2 we have that w.p. ≥ 1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"− ν/8 it holds that nTX̃TX −1 n ≤
O ( ∆2‖X̃TX −1",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"‖F · ln(p/ν) ) .
",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"Plugging all of the above bounds into Equation (21) we get that w.p. ≥ 1− ν/2− α/2 it holds that σ2 ≤ (
1√ n−p−2 √ ln(4/α) )2 ·(
‖̃ζ‖2",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
+O ( (1 + B2 √ p+B 1−η )∆,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
√ ln(1/ν) + ∆2‖X̃TX −1,D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"‖F · ln(p/ν) ))
and indeed, the RHS is the definition of ρ2 in the statement of Theorem D.1.",D. Confidence Intervals for “Analyze Gauss” Algorithm,[0],[0]
"To complete our discussion about the experiments we have conducted, we attach here additional figures, plotting both the t-value approximations we get from both algorithms, and the “high-level decision” of whether correctly reject or not-reject the null hypothesis (and with what sign).",E. Experiment: Additional Figures,[0],[0]
"First, we show the distribution of the t-value approximation for coordinates that should be rejected, in Figure 2, and then the decision of whether to reject or not based on this t-value — and whether it was right, conservative (we didn’t reject while we needed to) or wrong (we rejected with the wrong sign, or rejected when we shouldn’t have rejected) in Figure 3.",E. Experiment: Additional Figures,[0],[0]
"As one can see, Algorithm 1 has far lower t-values (as expected) and therefore is much more conservative.",E. Experiment: Additional Figures,[0],[0]
"In fact, it tends to not-reject coordinate 1 of the real-data even on the largest value of n (Figure 3c).
",E. Experiment: Additional Figures,[0],[0]
"However, because Algorithm 1 also has much smaller variance, it also does not reject when it ought to notreject, whereas Algorithm 2 erroneiously rejects the nullhypotheses.",E. Experiment: Additional Figures,[0],[0]
This can be seen in Figures 4 and 5.,E. Experiment: Additional Figures,[0],[0]
"Linear regression is one of the most prevalent techniques in machine learning; however, it is also common to use linear regression for its explanatory capabilities rather than label prediction.",abstractText,[0],[0]
Ordinary Least Squares (OLS) is often used in statistics to establish a correlation between an attribute (e.g. gender) and a label (e.g. income) in the presence of other (potentially correlated) features.,abstractText,[0],[0]
"OLS assumes a particular model that randomly generates the data, and derives tvalues — representing the likelihood of each real value to be the true correlation.",abstractText,[0],[0]
"Using t-values, OLS can release a confidence interval, which is an interval on the reals that is likely to contain the true correlation; and when this interval does not intersect the origin, we can reject the null hypothesis as it is likely that the true correlation is non-zero.",abstractText,[0],[0]
Our work aims at achieving similar guarantees on data under differentially private estimators.,abstractText,[0],[0]
"First, we show that for wellspread data, the Gaussian Johnson-Lindenstrauss Transform (JLT) gives a very good approximation of t-values; secondly, when JLT approximates Ridge regression (linear regression with l2-regularization) we derive, under certain conditions, confidence intervals using the projected data; lastly, we derive, under different conditions, confidence intervals for the “Analyze Gauss” algorithm (Dwork et al., 2014).",abstractText,[0],[0]
Differentially Private Ordinary Least Squares,title,[0],[0]
A set function f : 2V → R is said to be submodular if for all sets S ⊆ T ⊆ V and every element v ∈ V we have f(S ∪ {v}),1. Introduction,[0],[0]
− f(S) ≥ f(T ∪ {v}),1. Introduction,[0],[0]
− f(T ).,1. Introduction,[0],[0]
"That is, the marginal contribution of any element v to the value of the function f(S) diminishes as the input set S increases.",1. Introduction,[0],[0]
"The theory of submodular maximization unifies and generalizes diverse problems in combinatorial optimization, including the Max-Cover, Max-Cut, and Facility Location problems.",1. Introduction,[0],[0]
"In turn, this theory has recently found numerous applications to problems in machine learning, data science, and artificial intelligence.",1. Introduction,[0],[0]
"A few such applications include exemplar-based clustering (Krause & Gomes, 2010), feature selection for classification (Krause & Guestrin, 2005), document and corpus summarization (Lin & Bilmes, 2011;
1Yale University, New Haven, CT, USA 2Princeton University, Princeton, NJ, USA 3ETH Zurich, Zurich, Switzerland.",1. Introduction,[0],[0]
"Correspondence to: Marko Mitrovic <marko.mitrovic@yale.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Kirchhoff & Bilmes, 2014; Sipos et al., 2012), crowd teaching (Singla et al., 2014), and influence maximization in social networks (Kempe et al., 2003).
",1. Introduction,[0],[0]
"Some of the most compelling use cases for these applications concern sensitive data about individuals (Mirzasoleiman et al., 2016a;b).",1. Introduction,[0],[0]
"As a running example, let us consider the specific problem of determining which of a collection of features (e.g. age, height, weight, etc.) are most relevant to a binary classification task (e.g. predicting whether an individual is likely to have diabetes).",1. Introduction,[0],[0]
"In this problem, a sensitive training set takes the form D = {(xi, yi)}ni=1 where each individual i’s data consists of features xi,1, . . .",1. Introduction,[0],[0]
", xi,m together with a class label yi.",1. Introduction,[0],[0]
The goal is to identify a small subset S ⊆,1. Introduction,[0],[0]
"[m] of features which can then be used to build a good classifier for y. Many techniques exist for feature selection, including one based on maximizing a submodular function which captures the mutual information between a subset of features and the class label of interest (Krause & Guestrin, 2005).",1. Introduction,[0],[0]
"However, for both legal (e.g. compliance with HIPAA regulations) and ethical reasons, it is important that the selection of relevant features does not compromise the privacy of any individual who has contributed to the training data set.",1. Introduction,[0],[0]
"Unfortunately, the theory of submodular maximization does not in itself accommodate such privacy concerns.
",1. Introduction,[0],[0]
"To this end, we propose a systematic study of differentially private submodular maximization to enable these applications based on submodular maximization, while provably guaranteeing individual-level privacy.",1. Introduction,[0],[0]
"The notion of differential privacy (Dwork et al., 2006) offers a strong protection of individual-level privacy.",1. Introduction,[0],[0]
"Nevertheless, differential privacy has been shown to permit useful data analysis and machine learning tasks.",1. Introduction,[0],[0]
"In a nutshell, the definition formalizes a guarantee that no individual’s data should have too significant an effect on the outcome of a computation.",1. Introduction,[0],[0]
We provide the formal definition in Section 2.,1. Introduction,[0],[0]
"Such a privacy guarantee is obtained through the introduction of random noise, so private submodular maximization is conceptually related to the problem of submodular maximization in the presence of noise (Cheraghchi, 2012; Hassidim & Singer, 2016).
",1. Introduction,[0],[0]
"In this work, we study the following problem under various conditions on the submodular objective function f (monotone vs. non-monotone), and various choices of the con-
straint C (cardinality, matroid, or p-extendible system).",1. Introduction,[0],[0]
Problem 1.,1. Introduction,[0],[0]
"Given a sensitive dataset D associated to a submodular function fD : 2V → R: Find a subset S ∈ C ⊂ 2V that approximately maximizes fD(S) in a manner that guarantees differential privacy with respect to the input dataset D.
An important special case of this problem was studied in prior work of Gupta et al. (2010).",1. Introduction,[0],[0]
"They considered the “combinatorial public projects” problem (Papadimitriou et al., 2008), where given a dataset D = (x1, . . .",1. Introduction,[0],[0]
", xn), the function fD takes the particular form fD(S)",1. Introduction,[0],[0]
= 1 n,1. Introduction,[0],[0]
"∑n i=1 fxi(S) for monotone submodular functions fxi : 2 V → [0, 1], and is to be maximized subject to a cardinality constraint |S| ≤ k.",1. Introduction,[0],[0]
We call functions of this form decomposable.,1. Introduction,[0],[0]
"They presented a simple greedy algorithm, which will be central to our work, together with a tailored analysis which achieves strong accuracy guarantees in this special case.
",1. Introduction,[0],[0]
"However, there are many cases of Problem 1 which do not fall into the combinatorial public projects framework.",1. Introduction,[0],[0]
"For some problems, including feature selection via mutual information, the submodular function fD of interest depends on the datasetD in ways much more complicated than averaging functions associated to each individual.",1. Introduction,[0],[0]
The focus of our work is on understanding Problem 1 in circumstances which capture a broader class of useful applications and constraints in machine learning.,1. Introduction,[0],[0]
We summarize our specific contributions in Section 1.2.,1. Introduction,[0],[0]
"Even without concern for privacy, the problem of submodular maximization poses computational challenges.",1.1. The greedy paradigm,[0],[0]
"In particular, exact submodular maximization subject to a cardinality constraint is NP-hard.",1.1. The greedy paradigm,[0],[0]
"One of the principal approaches to designing efficient approximation algorithms is to use a greedy strategy (Nemhauser et al., 1978).",1.1. The greedy paradigm,[0],[0]
Consider the problem of maximizing a set function f(S) subject to the cardinality constraint |S| ≤,1.1. The greedy paradigm,[0],[0]
k.,1.1. The greedy paradigm,[0],[0]
"In each of rounds i = 1, . . .",1.1. The greedy paradigm,[0],[0]
", k, the basic greedy algorithm constructs Si from Si−1 by adding the element vi ∈ (V \ Si−1) which maximizes the marginal gain f(Si−1 ∪ {vi})",1.1. The greedy paradigm,[0],[0]
− f(Si−1).,1.1. The greedy paradigm,[0],[0]
"Nemhauser et al. (1978) famously showed that this algorithm yields a (1−1/e)-approximation to the optimal value of f(S) whenever f is a monotone submodular function.
",1.1. The greedy paradigm,[0],[0]
"In the combinatorial public projects setting, Gupta et al. (2010) showed how to make the greedy algorithm compatible with differential privacy by randomizing the procedure for selecting each vi.",1.1. The greedy paradigm,[0],[0]
"This selection procedure is specified by the differentially private exponential mechanism of McSherry & Talwar (2007), which (probabilistically) guarantees that the vi selected in each round is almost as good as the true marginal gain maximizer.",1.1. The greedy paradigm,[0],[0]
"Remarkably, Gupta et al. (2010) show that the cumulative privacy guarantee of the
resulting randomized greedy algorithm is not much worse than that of a single run of the exponential mechanism.",1.1. The greedy paradigm,[0],[0]
This analysis is highly tailored to the structure of the combinatorial public projects problem.,1.1. The greedy paradigm,[0],[0]
"However, replacing this tailored analysis with the more generic “advanced composition theorem” for differential privacy (Dwork et al., 2010), one still obtains useful results for the more general class of “low-sensitivity” submodular functions.",1.1. The greedy paradigm,[0],[0]
"Table 1 summarizes the approximation guarantees we obtain for Problem 1 under increasingly more general classes of submodular functions fD (read top to bottom), and increasingly more general types of constraints (read left to right).",1.2. Our contributions,[0],[0]
"In each entry, OPT denotes the value of the optimal non-private solution.",1.2. Our contributions,[0],[0]
"Below we draw attention to a few particular contributions, including some that are not expressed in Table 1.",1.2. Our contributions,[0],[0]
Non-monotone objective functions.,1.2. Our contributions,[0],[0]
Submodular maximization for non-monotone functions is significantly more challenging than it is for monotone objectives.,1.2. Our contributions,[0],[0]
"In particular, the basic greedy algorithm of Nemahauser et al. fails, and cannot guarantee any constant-factor approximation.",1.2. Our contributions,[0],[0]
"Several works (Feldman et al., 2017; Mirzasoleiman et al., 2016a; Buchbinder et al., 2014; Feldman et al., 2011) have identified variations of the greedy algorithm that do yield constant-factor approximations for non-monotone objectives.",1.2. Our contributions,[0],[0]
"However, it is not clear how to modify any of these algorithms to accommodate differential privacy.
",1.2. Our contributions,[0],[0]
"Our starting point is instead the “stochastic greedy” algorithm of Mirzasoleiman et al. (2015), which was originally designed to perform monotone submodular maximization in linear time.",1.2. Our contributions,[0],[0]
"Drawing ideas from Buchbinder et al. (2014), we give a new analysis of the stochastic greedy algorithm to show that it also gives a 1e (1 − 1/e)approximation for non-monotone submodular functions.",1.2. Our contributions,[0],[0]
"To our knowledge, this is the first algorithm making exactly |V",1.2. Our contributions,[0],[0]
| function evaluations which achieves a constantfactor approximation for either monotone or non-monotone objectives.,1.2. Our contributions,[0],[0]
"Moreover, it is immediately clear how to use the exponential mechanism to make this algorithm differentially private.
",1.2. Our contributions,[0],[0]
"This phenomenon is analogous to how stochastic variants of gradient descent are more naturally suited to providing differential privacy than their deterministic counterparts (Song et al., 2013; Bassily et al., 2014).",1.2. Our contributions,[0],[0]
"That is, our results illustrate how techniques for making algorithms fast are also helpful in making them privacy-preserving.
General constraints.",1.2. Our contributions,[0],[0]
"While a cardinality constraint is perhaps the most natural to place on a submodular maximization problem, some machine learning problems, e.g. personalized data summarization (Mirzasoleiman et al., 2016a), require the use of more general types of con-
straints.",1.2. Our contributions,[0],[0]
"For instance, one may wish to maximize a submodular function f(S) subject to S ∈",1.2. Our contributions,[0],[0]
"I for an arbitrary matroid I, or subject to S being contained in an intersection of p matroids (more generally, a p-extendible system).",1.2. Our contributions,[0],[0]
"For these types of constraints, the greedy algorithm still yields a constant factor approximation for monotone objective functions (Fisher et al., 1978; Jenkyns, 1976; Călinescu et al., 2011).",1.2. Our contributions,[0],[0]
"We show in this work that the analysis provided by Călinescu et al. (2011) for matroids and p-extendible families can be adapted to handle additional error introduced for differential privacy.
",1.2. Our contributions,[0],[0]
General selection procedures.,1.2. Our contributions,[0],[0]
"For worst-case datasets, the exponential mechanism is optimal within each round of private maximization.",1.2. Our contributions,[0],[0]
"However, it may be sub-optimal for datasets enjoying additional structural properties.",1.2. Our contributions,[0],[0]
"Fortunately, the greedy framework we use is flexible with regard to the choice of the selection procedure.",1.2. Our contributions,[0],[0]
"For instance, one can replace the exponential mechanism in a black-box manner with the “large margin mechanism” of Chaudhuri et al. (2014) to obtain error bounds that replace the explicit dependence on log |V | in Table 1 with a term that may be significantly smaller for real datasets.",1.2. Our contributions,[0],[0]
"We give a slightly simplified analysis of the large margin mechanism, and present it in a manner suitable for greedy algorithms which access the same data set multiple times.",1.2. Our contributions,[0],[0]
"(These guarantees are more complicated, but spelled out in Section 5.)",1.2. Our contributions,[0],[0]
"For submodular functions exhibiting additional structure, one may also be able to perform each maximization step with the “choosing mechanism” of Beimel et al. (2016) and Bun et al. (2015).",1.2. Our contributions,[0],[0]
Let V be finite set which we will refer to as the ground set and let X be a finite set which we will refer to as the data universe.,2. Preliminaries,[0],[0]
"A dataset is an n-tuple D = (x1, . . .",2. Preliminaries,[0],[0]
", xn) ∈ Xn.",2. Preliminaries,[0],[0]
Suppose each dataset D is associated to a set function fD :,2. Preliminaries,[0],[0]
"2V → R. The manner in which fD depends on D will be application-specific, but it is assumed that the association between D and fD is public information.",2. Preliminaries,[0],[0]
Definition 2.,2. Preliminaries,[0],[0]
A set function fD :,2. Preliminaries,[0],[0]
"2V → R is submodular if for all sets S ⊆ T ⊆ V and every element v ∈ V , we have fD(S ∪ {v})− fD(S)",2. Preliminaries,[0],[0]
≥,2. Preliminaries,[0],[0]
fD(T ∪ {v})− fD(T ).,2. Preliminaries,[0],[0]
"Moreover, If fD(S) ≤ fD(T ) whenever S ⊆ T , we say fD is monotone.",2. Preliminaries,[0],[0]
"If for every dataset D = (x1, . . .",2. Preliminaries,[0],[0]
", xn), the function fD",2. Preliminaries,[0],[0]
=,2. Preliminaries,[0],[0]
1n,2. Preliminaries,[0],[0]
"∑n i=1 fxi for monotone submodular
functions fxi : 2 V → [0, λ], we say fD is λ-decomposable.",2. Preliminaries,[0],[0]
"The problem of maximizing a decomposable submodular function was considered as the “combinatorial public projects problem” by Papadimitriou et al. (2008).
",2. Preliminaries,[0],[0]
We are interested in the problem of approximately maximizing a submodular function subject to differential privacy.,2. Preliminaries,[0],[0]
"The definition of differential privacy relies on the notion of neighboring datasets, which are simply tuples D,D′ ∈ Xn that differ in at most one entry.",2. Preliminaries,[0],[0]
"If D,D′ are neighboring, we write D ∼ D′. Definition 3.",2. Preliminaries,[0],[0]
"A randomized algorithm M : Xn → R satisfies (ε, δ)-differential privacy if for all measurable sets T ⊆ R and all neighboring datasets D ∼ D′,
Pr[M(D) ∈ T ] ≤ eε Pr[M(D′) ∈ T ] + δ.
",2. Preliminaries,[0],[0]
"Differentially private algorithms must be calibrated to the sensitivity of the function of interest with respect to small changes in the input dataset, defined formally as follows.
",2. Preliminaries,[0],[0]
Definition 4.,2. Preliminaries,[0],[0]
The sensitivity of a set function fD :,2. Preliminaries,[0],[0]
"2V → R (depending on a dataset D) with respect to a constraint C ⊆ 2V is defined as
max D∼D′ max S∈C |fD(S)− fD′(S)|.
",2. Preliminaries,[0],[0]
Composition of Differential Privacy.,2. Preliminaries,[0],[0]
The analyses of our algorithms rely crucially on composition theorems for differential privacy.,2. Preliminaries,[0],[0]
"For a sequence of privacy parameters {(εi, δi)}ki=1, we informally refer to the k-fold adaptive composition of (εi, δi)-differentially private algorithms as the output of a mechanism M∗",2. Preliminaries,[0],[0]
that behaves as follows on an input D:,2. Preliminaries,[0],[0]
"In each of rounds i = 1, . . .",2. Preliminaries,[0],[0]
", k, the algorithm M∗ selects an (εi, δi)-differentially private algorithm Mi possibly depending on the previous outcomes M1(D), . . .",2. Preliminaries,[0],[0]
",Mi(D) (but not directly on the sensitive dataset D itself), and releases Mi(D).",2. Preliminaries,[0],[0]
"For a formal treatment of adaptive composition, see (Dwork et al., 2010; Dwork & Roth, 2014).
",2. Preliminaries,[0],[0]
Theorem 5.,2. Preliminaries,[0],[0]
"(Dwork & Lei, 2009; Dwork et al., 2010; Bun & Steinke, 2016)",2. Preliminaries,[0],[0]
The k,2. Preliminaries,[0],[0]
"-fold adaptive composition of (ε0, δ0)-differentially private algorithms satisfies (ε, δ)differential privacy where
1.",2. Preliminaries,[0],[0]
ε,2. Preliminaries,[0],[0]
= kε0 and δ = kδ0.,2. Preliminaries,[0],[0]
(Basic Composition).,2. Preliminaries,[0],[0]
2.,2. Preliminaries,[0],[0]
ε =,2. Preliminaries,[0],[0]
"12kε 2 0 + √
2 log(1/δ′)ε0 and δ = δ′+ kδ, for any δ′ > 0.",2. Preliminaries,[0],[0]
"(Advanced Composition)
Exponential Mechanism.",2. Preliminaries,[0],[0]
"The exponential mechanism (McSherry & Talwar, 2007) is a general primitive for solving discrete optimization problems.",2. Preliminaries,[0],[0]
Let q : V × Xn → R be a “quality” function measuring how good a solution v ∈ V is with respect to a dataset D ∈ Xn.,2. Preliminaries,[0],[0]
"We say a quality function q has sensitivity λ if for all v ∈ V and all neighboring datasets D ∼ D′, we have |q(v,D)− q(v,D′)| ≤ λ.",2. Preliminaries,[0],[0]
Proposition 6.,2. Preliminaries,[0],[0]
Let ε > 0,2. Preliminaries,[0],[0]
and let q : V ×Xn be a quality function with sensitivity λ.,2. Preliminaries,[0],[0]
"Define the exponential mechanism as the algorithm which selects every v ∈ V with probability proportional to exp(εq(v,D)/2λ).",2. Preliminaries,[0],[0]
•,2. Preliminaries,[0],[0]
"The exponential mechanism provides (ε, 0)-
differential privacy.",2. Preliminaries,[0],[0]
•,2. Preliminaries,[0],[0]
"For every D ∈ Xn,
E[q(v̂, D)]",2. Preliminaries,[0],[0]
"≥ max v∈V q(v,D)− 2λ ·",2. Preliminaries,[0],[0]
ln |V,2. Preliminaries,[0],[0]
"| ε ,
where v̂ is the output of the exponential mechanism on dataset D.",2. Preliminaries,[0],[0]
The privacy guarantee and a “with high probability” utility guarantee of the exponential mechanism are due to McSherry & Talwar (2007).,2. Preliminaries,[0],[0]
"A simple proof of the utility guarantee in expectation appears in (Bassily et al., 2016).",2. Preliminaries,[0],[0]
"In this section, we present a variant of the basic greedy algorithm which will enable maximization of monotone submodular functions.",3. Monotone Submodular Maximization,[0],[0]
This algorithm simply replaces each greedy selection step with a privacy-preserving selection algorithm denoted O. The selection function O takes as input a quality function q :,3. Monotone Submodular Maximization,[0],[0]
U ×,3. Monotone Submodular Maximization,[0],[0]
"Xn → R and a dataset D, as well as privacy parameters ε0, δ0, and outputs an element u ∈ U .",3. Monotone Submodular Maximization,[0],[0]
We begin in the simplest case of monotone submodular maximization with a cardinality constraint (Algorithm 1).,3. Monotone Submodular Maximization,[0],[0]
"The algorithm for more general constraints appears in Section 3.1.
",3. Monotone Submodular Maximization,[0],[0]
"Algorithm 1 was already studied by Gupta et al. (2010) in the special case where fD is decomposable, and O is the exponential mechanism.",3. Monotone Submodular Maximization,[0],[0]
"We generalize their result to the much broader class of low-sensitivity monotone submodular functions.
",3. Monotone Submodular Maximization,[0],[0]
Algorithm 1 Diff.,3. Monotone Submodular Maximization,[0],[0]
"Private Greedy (Cardinality) GO
Input: Submodular function fD :",3. Monotone Submodular Maximization,[0],[0]
"2V → R, dataset D, cardinality constraint k, privacy parameters ε0, δ0 Output: Size k subset of V
1.",3. Monotone Submodular Maximization,[0],[0]
Initialize S0 = ∅ 2.,3. Monotone Submodular Maximization,[0],[0]
"For i = 1, . . .",3. Monotone Submodular Maximization,[0],[0]
", k:
•",3. Monotone Submodular Maximization,[0],[0]
"Define qi : (V \Si−1)×Xn → R via qi(v, D̃) = fD̃(Si−1 ∪ {v})− fD̃(Si−1) •",3. Monotone Submodular Maximization,[0],[0]
"Compute vi ←R O(qi, D; ε0, δ0) •",3. Monotone Submodular Maximization,[0],[0]
"Update Si ← (Si−1 ∪ {vi})
3.",3. Monotone Submodular Maximization,[0],[0]
"Return Sk
Theorem 7.",3. Monotone Submodular Maximization,[0],[0]
"(Gupta et al., 2010) Suppose fD :",3. Monotone Submodular Maximization,[0],[0]
2V → R is λ-decomposable (cf.,3. Monotone Submodular Maximization,[0],[0]
Definition 2).,3. Monotone Submodular Maximization,[0],[0]
Let δ > 0,3. Monotone Submodular Maximization,[0],[0]
and let ε0 ≥ 0 be such that ε = 2 · ε0 · (e− 1) ln(3e/δ) ≤ 1.,3. Monotone Submodular Maximization,[0],[0]
"Then instantiating Algorithm 1 with O = EM and parameter ε0 > 0 provides (ε, δ)-differential privacy.
",3. Monotone Submodular Maximization,[0],[0]
"Moreover, for every D ∈ Xn, E [fD(Sk)] ≥ ( 1− 1
e
) OPT−2λk ln |V",3. Monotone Submodular Maximization,[0],[0]
"|
ε0 where Sk ←R GEM(D).",3. Monotone Submodular Maximization,[0],[0]
"Unfortunately, the privacy analysis of Theorem 7 makes essential use of the decomposability of fD, and does not directly generalize to arbitrary submodular functions of lowsensitivity.",3. Monotone Submodular Maximization,[0],[0]
"Replacing the privacy analysis of (Gupta et al., 2010) with the Composition Theorem 5 instead gives Theorem 8.",3. Monotone Submodular Maximization,[0],[0]
Suppose fD :,3. Monotone Submodular Maximization,[0],[0]
2V → R is monotone and has sensitivity λ.,3. Monotone Submodular Maximization,[0],[0]
"Then instantiating Algorithm 1 withO = EM and parameter ε0 > 0 provides (ε = kε0, δ = 0)- differential privacy.",3. Monotone Submodular Maximization,[0],[0]
"It also provides (ε, δ)-differential privacy for every δ > 0",3. Monotone Submodular Maximization,[0],[0]
"with ε = kε20/2 + ε0 · √ 2k ln(1/δ).
",3. Monotone Submodular Maximization,[0],[0]
"Moreover, for every D ∈ Xn, E [fD(Sk)] ≥ ( 1− 1
e
) OPT−2λk ln |V",3. Monotone Submodular Maximization,[0],[0]
"|
ε0 where Sk ←R GEM(D).
",3. Monotone Submodular Maximization,[0],[0]
3.1.,3. Monotone Submodular Maximization,[0],[0]
Matroid and p-Extendible System Constraints We now show how to extend Algorithm 1 to privately maximize monotone submodular functions subject to more general constraints.,3. Monotone Submodular Maximization,[0],[0]
"To start, we review the definition of a pextendible system.",3. Monotone Submodular Maximization,[0],[0]
Consider a ground set V and a nonempty downward-closed family of subsets I ⊆ 2V (,3. Monotone Submodular Maximization,[0],[0]
"i.e. if T ∈ I, then S ∈",3. Monotone Submodular Maximization,[0],[0]
I for every S ⊆ T ).,3. Monotone Submodular Maximization,[0],[0]
Such an I is called a family of independent sets.,3. Monotone Submodular Maximization,[0],[0]
"The pair (V, I) is said to be a pextendible system (Mestre, 2006) if for all S ⊂ T ∈",3. Monotone Submodular Maximization,[0],[0]
"I, and v ∈ V such that S∪{v} ∈",3. Monotone Submodular Maximization,[0],[0]
"I, there exists a set Z ⊆ (T \S) such that |Z| ≤ p and (T \ Z) ∪ {v} ∈ I. Let r(I) denote the size of the largest independent set in I.
The definition of a matroid coincides with that of a 1- extendible system (with rank r(I)).",3. Monotone Submodular Maximization,[0],[0]
"For p ≥ 2, the notion of a p-extendible system strictly generalizes that of an intersection of p matroids.",3. Monotone Submodular Maximization,[0],[0]
"A slight modification of Algorithm 1 gives a unified algorithm for privately maximizing a monotone submodular function subject to matroid and pextendible system constraints, presented as Algorithm 2.",3. Monotone Submodular Maximization,[0],[0]
Theorem 9.,3. Monotone Submodular Maximization,[0],[0]
Suppose fD :,3. Monotone Submodular Maximization,[0],[0]
2V → R is λ-decomposable (cf.,3. Monotone Submodular Maximization,[0],[0]
Definition 2).,3. Monotone Submodular Maximization,[0],[0]
Let δ > 0,3. Monotone Submodular Maximization,[0],[0]
and let ε0 ≥ 0 be such that ε = 2 · ε0 · (e − 1) ln(3e/δ) ≤ 1.,3. Monotone Submodular Maximization,[0],[0]
"Then instantiating Algorithm 2 with O = EM and parameter ε0 > 0 provides (ε, δ)-differential privacy.",3. Monotone Submodular Maximization,[0],[0]
"Moreover, for every D ∈ Xn,
E [fD(S)] ≥ 1 p+ 1 ·OPT− p p+ 1
( 2λr(I) ln |V",3. Monotone Submodular Maximization,[0],[0]
"|
ε0 ) where S ←R GEM(D).
",3. Monotone Submodular Maximization,[0],[0]
"Algorithm 2 Differentially Private Greedy (p-system) GO
Input: Submodular function fD :",3. Monotone Submodular Maximization,[0],[0]
"2V → R, dataset D, pextendible family (V, I), privacy parameters ε0, δ0 Output: Maximal independent subset of V
1.",3. Monotone Submodular Maximization,[0],[0]
Initialize S = ∅ 2.,3. Monotone Submodular Maximization,[0],[0]
"While S ∈ I is not maximal:
•",3. Monotone Submodular Maximization,[0],[0]
Define q : (V \ S) ×,3. Monotone Submodular Maximization,[0],[0]
"Xn → R via q(v, D̃) = fD̃(S ∪ {v})− fD̃(S) •",3. Monotone Submodular Maximization,[0],[0]
Compute vi ←R,3. Monotone Submodular Maximization,[0],[0]
"O(q,D; ε0, δ0) •",3. Monotone Submodular Maximization,[0],[0]
"Update S ← (S ∪ {vi})
3.",3. Monotone Submodular Maximization,[0],[0]
"Return S
Theorem 10.",3. Monotone Submodular Maximization,[0],[0]
Suppose fD :,3. Monotone Submodular Maximization,[0],[0]
2V → R has sensitivity λ.,3. Monotone Submodular Maximization,[0],[0]
"Then instantiating Algorithm 2 with O = EM and parameter ε0 > 0 provides (ε = r(I)ε0, δ = 0)-differential privacy.",3. Monotone Submodular Maximization,[0],[0]
"It also provides (ε, δ)-differential privacy for every δ > 0",3. Monotone Submodular Maximization,[0],[0]
"with ε = r(I)ε2/2 + ε · √ 2r(I) ln(1/δ).
",3. Monotone Submodular Maximization,[0],[0]
"Moreover, for every D ∈ Xn,
E [fD(S)] ≥ 1 p+ 1 ·OPT− p p+ 1
( 2λr(I) ln |V",3. Monotone Submodular Maximization,[0],[0]
"|
ε0 ) where S ←R GEM(D).",3. Monotone Submodular Maximization,[0],[0]
"We now consider the problem of privately maximizing an arbitrary, possibly non-monotone, submodular function under a cardinality constraint.",4. Non-Monotone Submodular Maximization,[0],[0]
"In general, the greedy algorithm presented in Section 3 fails to give any constantfactor approximation.",4. Non-Monotone Submodular Maximization,[0],[0]
"Instead, our algorithm in this section will be based on the “stochastic greedy” algorithm first studied by Mirzasoleiman et al. (2015).",4. Non-Monotone Submodular Maximization,[0],[0]
"In each round, the stochastic greedy algorithm first subsamples a random 1 k · ln(1/α) fraction of the ground set for some α > 0, and then greedily selects the item from this subsample that maximizes marginal gain.",4. Non-Monotone Submodular Maximization,[0],[0]
"Mirzasoleiman et al. (2015) showed that for a monotone objective function f , this algorithm provides a (1− 1/e− α)-approximation to the optimal solution.",4. Non-Monotone Submodular Maximization,[0],[0]
"Their original motivation was to improve the running time of the greedy algorithm: fromO(|V | ·k) evaluations of the objective function to linearO(|V | · ln(1/α)).
",4. Non-Monotone Submodular Maximization,[0],[0]
"Unfortunately, the stochastic greedy algorithm does not provide any approximation guarantee for non-monotone submodular functions.",4. Non-Monotone Submodular Maximization,[0],[0]
"Buchbinder et al. (2014) instead proposed a “random greedy” algorithm that, in each iteration, randomly selects one of the k elements with the highest marginal gain.",4. Non-Monotone Submodular Maximization,[0],[0]
"Buchbinder et al. (2014) showed that the random greedy algorithm achieves a 1/e approximation to the optimal solution (in expectation), using k|V | function evaluations.",4. Non-Monotone Submodular Maximization,[0],[0]
"However, it is not clear how to adapt this algorithm to accommodate differential privacy, since its analysis has a brittle dependence on the sampling procedure.
",4. Non-Monotone Submodular Maximization,[0],[0]
"We make two main contributions to the analysis of the
stochastic greedy and random greedy algorithms.",4. Non-Monotone Submodular Maximization,[0],[0]
"First, we show that running the stochastic greedy algorithm on an exact 1k fraction of the ground set per iteration still gives a (0.468)-approximation for monotone objectives, and moreover, gives a 1e (1 − 1/e)-approximation even for non-monotone objectives.",4. Non-Monotone Submodular Maximization,[0],[0]
"Note that this algorithm evaluates the objective function on only |V | elements, and still provides a constant factor approximation guarantee.",4. Non-Monotone Submodular Maximization,[0],[0]
This makes our “subsample-greedy” algorithm the fastest algorithm for maximizing a general submodular function subject to a cardinality constraint (albeit with slightly worse approximation guarantees).,4. Non-Monotone Submodular Maximization,[0],[0]
"Second, we show that the guarantees of this algorithm are robust to using a randomized greedy selection procedure (e.g. the exponential or large margin mechanism), and hence it can be adapted to ensure differential privacy.
",4. Non-Monotone Submodular Maximization,[0],[0]
We present the subsample-greedy algorithm as Algorithm 3 below.,4. Non-Monotone Submodular Maximization,[0],[0]
"Assume that V is augmented by enough “dummy elements” to ensure that |V |/k is an integer; each dummy element u is defined so that fD(S ∪ {u}) = fD(S) for every set S. We also explicitly account for an additional set U of k dummy elements, and ensure that at least one appears in every subsample.
",4. Non-Monotone Submodular Maximization,[0],[0]
Algorithm 3 Diff.,4. Non-Monotone Submodular Maximization,[0],[0]
"Private “Subsample-Greedy” SGO
Input: Submodular function fD :",4. Non-Monotone Submodular Maximization,[0],[0]
"2V → R, dataset D, cardinality constraint k, privacy parameters ε0, δ0 Output: Size k subset of V
1.",4. Non-Monotone Submodular Maximization,[0],[0]
"Initialize S0 = ∅, dummy elements U = {u1, . . .",4. Non-Monotone Submodular Maximization,[0],[0]
", uk}
2.",4. Non-Monotone Submodular Maximization,[0],[0]
"For i = 1, . . .",4. Non-Monotone Submodular Maximization,[0],[0]
", k: • Sample Vi ⊂ V a uniformly random subset of
size |V |/k and ui a random dummy element •",4. Non-Monotone Submodular Maximization,[0],[0]
"Define qi : (Vi∪{ui})×Xn → R via qi(v, D̃) = fD̃(Si−1 ∪ {v})− fD̃(Si−1) •",4. Non-Monotone Submodular Maximization,[0],[0]
"Compute vi ←R O(qi, D; ε0, δ0) •",4. Non-Monotone Submodular Maximization,[0],[0]
"Update Si ← (Si−1 ∪ {vi})
3.",4. Non-Monotone Submodular Maximization,[0],[0]
"Return Sk with all dummy elements removed
Theorem 11.",4. Non-Monotone Submodular Maximization,[0],[0]
Suppose fD :,4. Non-Monotone Submodular Maximization,[0],[0]
2V → R has sensitivity λ.,4. Non-Monotone Submodular Maximization,[0],[0]
"Then instantiating Algorithm 3 with O = EM provides (ε, δ)-differential privacy, and for every D ∈ Xn,
E [fD(S)]",4. Non-Monotone Submodular Maximization,[0],[0]
"≥ 1
e
( 1− 1
e
) OPT−2λk ln |V",4. Non-Monotone Submodular Maximization,[0],[0]
"|
ε
where S ←R SGEM(D).",4. Non-Monotone Submodular Maximization,[0],[0]
"Moreover, if fD is monotone, then E [fD(S)]",4. Non-Monotone Submodular Maximization,[0],[0]
≥ ( 1− e−(1−1/e) ) OPT−2λk ln |V,4. Non-Monotone Submodular Maximization,[0],[0]
"|
ε
≈ 0.468OPT−2λk ln |V",4. Non-Monotone Submodular Maximization,[0],[0]
"| ε .
",4. Non-Monotone Submodular Maximization,[0],[0]
The guarantees of Theorem 11 are of interest even without privacy.,4. Non-Monotone Submodular Maximization,[0],[0]
"Letting MAX denote the selection procedure which simply outputs the true maximizer (equivalently,
which runs the exponential mechanism with ε0 = +∞), we obtain the following non-private algorithm for maximizing a submodular function fD:
Corollary 12.",4. Non-Monotone Submodular Maximization,[0],[0]
Let fD :,4. Non-Monotone Submodular Maximization,[0],[0]
2V → R be any submodular function.,4. Non-Monotone Submodular Maximization,[0],[0]
"Instantiating Algorithm 3 with O = MAX gives
E [fD(S)]",4. Non-Monotone Submodular Maximization,[0],[0]
"≥ 1
e
( 1− 1
e
)",4. Non-Monotone Submodular Maximization,[0],[0]
"OPT
where S ←R SGMAX(D).",4. Non-Monotone Submodular Maximization,[0],[0]
"Moreover, if fD is monotone, then
E [fD(S)]",4. Non-Monotone Submodular Maximization,[0],[0]
≥ ( 1− e−(1−1/e) ),4. Non-Monotone Submodular Maximization,[0],[0]
OPT ≈ 0.468OPT .,4. Non-Monotone Submodular Maximization,[0],[0]
"The accuracy guarantee of the exponential mechanism can be pessimistic on datasets where q(·, D) exhibits additional structure.",5. The Large Margin Mechanism,[0],[0]
"For example, suppose that when the elements of V are sorted so that q(v1, D) ≥ q(v2, D) ≥ · · · ≥ q(v|V |, D), there exists an ` such that q(v1, D) q(v`+1, D).",5. The Large Margin Mechanism,[0],[0]
"Then only the top ` ground set items are relevant to the optimization problem, so running the exponential mechanism on these should maintain differential privacy, but with error proportional to ln ` rather than to ln |V |.",5. The Large Margin Mechanism,[0],[0]
"The large margin mechanism of Chaudhuri et al. (2014), like the exponential mechanism, generically solves discrete optimization problems.",5. The Large Margin Mechanism,[0],[0]
"However, it automatically leverages this additional margin structure whenever it exists.",5. The Large Margin Mechanism,[0],[0]
"Asymptotically, the error guarantee of the large margin mechanism is always at most that of the exponential mechanism, but can be much smaller when the data exhibits a margin for small `.
",5. The Large Margin Mechanism,[0],[0]
"Formally, given a quality function q :",5. The Large Margin Mechanism,[0],[0]
"V × Xn → R and parameters ` ∈ N, γ > 0, a dataset D satisfies the (`, γ)margin condition if q(v`+1, D) < q(v1, D)− γ.
",5. The Large Margin Mechanism,[0],[0]
"For each ` = 1, . . .",5. The Large Margin Mechanism,[0],[0]
", |V |, define
g` = λ · ( 3 + 4 ln(2`/δ)
ε )",5. The Large Margin Mechanism,[0],[0]
"G` = 8λ ln(2/δ)
",5. The Large Margin Mechanism,[0],[0]
"ε +
16λ ln(7`2/δ)
ε",5. The Large Margin Mechanism,[0],[0]
+ g,5. The Large Margin Mechanism,[0],[0]
"`.
Recall that the Laplace distribution Lap(b) is specified by the density function 12b exp(−|x|/b).
",5. The Large Margin Mechanism,[0],[0]
"Replacing the exponential mechanism with the large margin mechanism gives analogues of our results for monotone submodular maximization with a cardinality constraint, monotone submodular maximization over a p-extendible system, and non-monotone submodular maximization with a cardinality constraint:
Theorem 13.",5. The Large Margin Mechanism,[0],[0]
Suppose fD :,5. The Large Margin Mechanism,[0],[0]
2V → R is monotone and has sensitivity λ.,5. The Large Margin Mechanism,[0],[0]
"Then instantiating Algorithm 1 with O = LMM and parameters ε0, δ0 = 0 provides (kε0, kδ0)-differential privacy.",5. The Large Margin Mechanism,[0],[0]
"It also provides (ε, δ′ +
kδ0)-differential privacy for every δ′ > 0 with ε = kε2/2+ ε · √ 2k ln(1/δ′).
",5. The Large Margin Mechanism,[0],[0]
"Moreover, for every D ∈ Xn, there exists an event E with Pr[E] ≥ 1− β such that
E",5. The Large Margin Mechanism,[0],[0]
"[fD(Sk)|E] ≥ ( 1− 1
e
)",5. The Large Margin Mechanism,[0],[0]
OPT− k∑ i=1,5. The Large Margin Mechanism,[0],[0]
4λ,5. The Large Margin Mechanism,[0],[0]
"ln `i ε0
where Sk ←R GLMM(D), and D satisfies the (`i, γi)margin condition with respect to every function of the form qi(v,D) = fD(Ŝi−1 ∪ {v})",5. The Large Margin Mechanism,[0],[0]
"− fD(Ŝi−1), with γi = 24λ ln(k/β)/ε+G`i .
Theorem 14.",5. The Large Margin Mechanism,[0],[0]
"Instantiating Algorithm 2 with O = LMM under all of the conditions of Theorem 13 gives the same privacy guarantee (replacing k with r(I)) and gives
E [fD(S)|E] ≥ 1
p+ 1 ·OPT− r(I)∑ i=1",5. The Large Margin Mechanism,[0],[0]
4λ,5. The Large Margin Mechanism,[0],[0]
"ln `i ε0 .
",5. The Large Margin Mechanism,[0],[0]
Theorem 15.,5. The Large Margin Mechanism,[0],[0]
"Instantiating Algorithm 3 with O = LMM under all of the conditions of Theorem 13 gives the same privacy guarantee and gives
E",5. The Large Margin Mechanism,[0],[0]
"[fD(Sk)|E] ≥ 1
e
( 1− 1
e
)",5. The Large Margin Mechanism,[0],[0]
OPT− k∑ i=1,5. The Large Margin Mechanism,[0],[0]
4λ,5. The Large Margin Mechanism,[0],[0]
"ln `i ε0 .
",5. The Large Margin Mechanism,[0],[0]
"Moreover, if fD is monotone, then E",5. The Large Margin Mechanism,[0],[0]
[fD(Sk)|E] ≥ 0.468OPT− k∑ i=1,5. The Large Margin Mechanism,[0],[0]
4λ,5. The Large Margin Mechanism,[0],[0]
ln `i ε0 .,5. The Large Margin Mechanism,[0],[0]
In this section we describe two concrete applications of our mechanisms.,6. Experimental Results,[0],[0]
"We analyze a dataset of 10,000 Uber pickups in Manhattan in April 2014 (UberDataset).",6.1. Location Privacy,[0],[0]
Each individual entry in the dataset consists of the longitude and latitude coordinates of the pickup location.,6.1. Location Privacy,[0],[0]
"We want to use this dataset to select k public locations as waiting spots for idle Uber drivers, while also guaranteeing differential privacy for the passengers whose locations appear in this dataset.1 We consider two different public sets of locations L:
• LPopular is a set of 33 popular locations in Manhattan.",6.1. Location Privacy,[0],[0]
•,6.1. Location Privacy,[0],[0]
"LGrid is a set of 33 locations spread evenly across
Manhattan in a grid-like manner.
",6.1. Location Privacy,[0],[0]
"We define a utility function M(i, j) to be the normalized Manhattan distance between a pickup location i and the waiting location j. That is, if pickup location i is located at coordinates (i1, i2) and the waiting location j is located at coordinates (j1, j2), then M(i, j) = |i1",6.1. Location Privacy,[0],[0]
"− j1|+ |i2 − j2|
m ,
where m = 0.266 is simply the Manhattan distance between the two furthest spread apart points in Manhattan.
",6.1. Location Privacy,[0],[0]
"1Under the assumption that each pickup corresponds to a unique individual.
",6.1. Location Privacy,[0],[0]
"This normalization ensures that 0 ≤ M(i, j) ≤ 1, for all i, j. In order to make sure we have a maximization problem, we define the following objective function: fD(S) = n−
∑ i∈D min j∈S M(i, j), where n = |D| = 10000.
",6.1. Location Privacy,[0],[0]
Observation 16.,6.1. Location Privacy,[0],[0]
"The function fD is λ-decomposable for λ = 1 (and hence has sensitivity 1).
",6.1. Location Privacy,[0],[0]
This form of objective function is known to be monotone submodular and so we can use the greedy algorithms studied in this paper.,6.1. Location Privacy,[0],[0]
We use = 0.1 and δ = 2−20.,6.1. Location Privacy,[0],[0]
"For our settings of parameters, “basic composition” outperforms “advanced composition,” so the privacy budget of = 0.1 is split equally across the k iterations, meaning the mechanism at each iteration uses 0 = k .",6.1. Location Privacy,[0],[0]
"Our figures plot the average utility across 100 simulations.
",6.1. Location Privacy,[0],[0]
From Figures 1(a) and (b) we see that the results for both LPopular and LGrid are relatively similar and unsurprising.,6.1. Location Privacy,[0],[0]
"The non-private greedy algorithm achieves the highest utility, but both the exponential mechanism (EM)-based greedy and large margin mechanism (LMM)-based greedy algorithms exhibit comparable utility while preserving a high level of privacy.",6.1. Location Privacy,[0],[0]
"Interestingly, we also see that the utilities of the EM-based and LMM-based algorithms are almost identical for both LPopular and LGrid.",6.1. Location Privacy,[0],[0]
"This indicates that our mechanisms are actually selecting good locations, rather than just getting lucky because there are a lot of good locations to choose from.
",6.1. Location Privacy,[0],[0]
"Figures 1(c) and (d) show how the utility of the EM-based
and LMM-based algorithms vary with the privacy parameter .",6.1. Location Privacy,[0],[0]
We can also think of this as varying the dataset size for a fixed .,6.1. Location Privacy,[0],[0]
We fix k = 3 and take the average of 100 simulations for each value of .,6.1. Location Privacy,[0],[0]
"We see that even for very small , our algorithms outperform fully random selection.",6.1. Location Privacy,[0],[0]
"As increases, so does the utility.",6.1. Location Privacy,[0],[0]
"It is not shown in this figure, but varying δ has very little effect.
",6.1. Location Privacy,[0],[0]
"From Figures 1(e) - (h), we see that the both the non-private and private algorithms select public locations that are relatively close to each other.",6.1. Location Privacy,[0],[0]
"For example, for the LPopular set of locations, the Empire State Building is close to the New York Public Library, the Soho Grand Hotel is close to NYU, and the Grand Army Plaza is close to the UN Headquarters.",6.1. Location Privacy,[0],[0]
"As a result, the private mechanisms manage to achieve comparable utility, while also masking the users’ exact locations.
",6.1. Location Privacy,[0],[0]
"The theory described in Section 5 suggests that, at least asymptotically, the large margin mechanism-based algorithm should outperform the exponential mechanism-based algorithm.",6.1. Location Privacy,[0],[0]
"However, in our experiments, we find that the large margin mechanism is generally only able to find a margin in the first iteration of the greedy algorithm.",6.1. Location Privacy,[0],[0]
"This is because the threshold for finding a margin depends only on , δ, and n and thus it stays the same across all k iterations.",6.1. Location Privacy,[0],[0]
"On the other hand, the marginal gain at each iteration drops very quickly, so the mechanism fails to find a margin and thus samples from all remaining locations.",6.1. Location Privacy,[0],[0]
"However, since the large margin mechanism spends half of its privacy bud-
get to try to find a margin, the sampling step gives slightly worse guarantees than does the plain exponential mechanism, thus giving us the slightly weaker results we see in the figures.",6.1. Location Privacy,[0],[0]
We analyze a dataset created from a combination of National Health Examination Surveys ranging from 2007 to 2014 (NHANESDataset).,6.2. Feature Selection Privacy,[0],[0]
"There are n = 23, 876 individuals in the dataset with information on whether or not they have diabetes, along with m = 23 other potentially related binary health features.",6.2. Feature Selection Privacy,[0],[0]
"Our goal is to privately select k of these features that provide as much information about the diabetes class variable as possible.
",6.2. Feature Selection Privacy,[0],[0]
"More specifically, our goal is to maximize the mutual information between Y and XS , where Y is a binary random variable indicating whether or not an individual has diabetes and XS is a random variable that represents a set S of k binary health features.",6.2. Feature Selection Privacy,[0],[0]
"Mutual information takes the form:
I(Y ;X) = ∑ y∈Y ∑ x∈X p(x, y) log2 ( p(x, y) p(x)p(y) ) .
",6.2. Feature Selection Privacy,[0],[0]
"Under the Naive Bayes assumption, we suppose the joint distribution on (Y,X1, . . .",6.2. Feature Selection Privacy,[0],[0]
", Xk) takes the form
p(y, x1, . . .",6.2. Feature Selection Privacy,[0],[0]
", xk) = p(y) k∏ i=1",6.2. Feature Selection Privacy,[0],[0]
p(xi | y).,6.2. Feature Selection Privacy,[0],[0]
"Therefore, we can easily specify the entire probability distribution by finding each p(xi | y).",6.2. Feature Selection Privacy,[0],[0]
"We estimate each p(xi | y) by counting frequencies in the dataset.
",6.2. Feature Selection Privacy,[0],[0]
Our goal is to choose a size k subset S of the features in order to maximize fD(S) = I(Y ;XS).,6.2. Feature Selection Privacy,[0],[0]
"Mutual information (under the Naive Bayes assumption) for feature selection is known to be monotone submodular in S (Krause & Guestrin, 2005), and thus we can apply the greedy algorithms described in this paper.",6.2. Feature Selection Privacy,[0],[0]
Claim 17.,6.2. Feature Selection Privacy,[0],[0]
"In iteration i of the greedy algorithm, the sensitivity of fD(S) is (2i+1) log2(n) n .",6.2. Feature Selection Privacy,[0],[0]
"We run 1,000 simulations with = 1.0 and δ = 2−20.",6.2. Feature Selection Privacy,[0],[0]
"As we can see from Figure 2(b), our private mechanisms
maintain a comparable utility relative to the non-private algorithm.",6.2. Feature Selection Privacy,[0],[0]
We also observe an interesting phenomenon where the expected utility obtained by our mechanism is not necessarily monotonically increasing with the number of features selected.,6.2. Feature Selection Privacy,[0],[0]
"This is an artifact of the fact that if we are selecting k features, then composition requires us to divide so that each iteration uses privacy budget k .",6.2. Feature Selection Privacy,[0],[0]
This is problematic for this particular application because there happens to be one feature (insulin administration) that has much higher value than the rest.,6.2. Feature Selection Privacy,[0],[0]
"Therefore, the reduced probability of picking this single best feature (as a result of the lower privacy parameter k ) is not compensated for by selecting more features.
",6.2. Feature Selection Privacy,[0],[0]
"From Figure 2(c), we see that both the private and nonprivate mechanisms generally select insulin administration as the top feature.",6.2. Feature Selection Privacy,[0],[0]
"However, while all three of the top features selected by the non-private algorithm are clearly related to diabetes, the non-private mechanisms tend to select one feature (in our case, gender or having received a blood transfusion) that may not be quite as relevant.",6.2. Feature Selection Privacy,[0],[0]
We have presented a general framework for maximizing submodular functions while guaranteeing differential privacy.,7. Conclusion,[0],[0]
"Our results demonstrate that simple and flexible greedy algorithms can preserve privacy while achieving competitive guarantees for a variety of submodular maximization problems: for all functions under cardinality constraints, as well as for monotone functions under matroid and p-extendible system constraints.",7. Conclusion,[0],[0]
"Via our motivation to identify algorithms that could be made differentially private, we discovered a non-monotone submodular maximization algorithm that achieves guarantees that are novel even without concern for privacy.",7. Conclusion,[0],[0]
"Finally, our experiments show that our algorithms are indeed competitive with their non-private counterparts.
Acknowledgments.",7. Conclusion,[0],[0]
"This work was supported by DARPA Young Faculty Award (D16AP00046), Simons-Berkeley fellowship, and ERC StG 307036.",7. Conclusion,[0],[0]
This work was done in part while Amin Karbasi and Andreas Krause were visiting the Simons Institute for the Theory of Computing.,7. Conclusion,[0],[0]
Many data summarization applications are captured by the general framework of submodular maximization.,abstractText,[0],[0]
"As a consequence, a wide range of efficient approximation algorithms have been developed.",abstractText,[0],[0]
"However, when such applications involve sensitive data about individuals, their privacy concerns are not automatically addressed.",abstractText,[0],[0]
"To remedy this problem, we propose a general and systematic study of differentially private submodular maximization.",abstractText,[0],[0]
"We present privacypreserving algorithms for both monotone and non-monotone submodular maximization under cardinality, matroid, and p-extendible system constraints, with guarantees that are competitive with optimal solutions.",abstractText,[0],[0]
"Along the way, we analyze a new algorithm for non-monotone submodular maximization under a cardinality constraint, which is the first (even non-privately) to achieve a constant approximation ratio with a linear number of function evaluations.",abstractText,[0],[0]
We additionally provide two concrete experiments to validate the efficacy of these algorithms.,abstractText,[0],[0]
Differentially Private Submodular Maximization: Data Summarization in Disguise,title,[0],[0]
"Deep Neural Networks (DNNs) have demonstrated excellent performance in solving many complex problems, and have been widely employed for tasks such as speech recognition (Hinton et al., 2012), computer vision (He et al., 2016) and gaming agents (Silver et al., 2016).",1. Introduction,[0],[0]
"DNNs are capable of learning very complex functions, and can generalize well even for a huge number of parameters (Neyshabur et al., 2014).",1. Introduction,[0],[0]
"However, recent studies have shown that DNNs may generalize poorly for datasets which contain a high proportion noisy (incorrect) class labels (Zhang et al., 2017).",1. Introduction,[0],[0]
"It is important to gain a fuller understanding of this phenomenon, with a view to development of new training methods that can
*Equal contribution 1The University of Melbourne, Melbourne, Australia 2Tsinghua University, Beijing, China 3National Institute of Informatics, Tokyo, Japan.",1. Introduction,[0],[0]
"Correspondence to: Yisen Wang <wangys14@mails.tsinghua.edu.cn>, Xingjun Ma <xingjun.ma@unimelb.edu.au>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"achieve good generalization performance in the presence of variable amounts of label noise.
",1. Introduction,[0],[0]
One simple approach for noisy labels is to ask a domain expert to relabel or remove suspect samples in a preprocessing stage.,1. Introduction,[0],[0]
"However, this is infeasible for large datasets and also runs the risk of removing crucial samples.",1. Introduction,[0],[0]
"An alternative is to correct noisy labels to their true labels via a clean label inference step (Vahdat, 2017; Veit et al., 2017; Jiang et al., 2017; Li et al., 2017).",1. Introduction,[0],[0]
Such methods often assume the availability of a supplementary labelled dataset containing pre-identified noisy labels which are used to develop a model of the label noise.,1. Introduction,[0],[0]
"However, their effectiveness is tied to the assumption that the data follow the noise model.",1. Introduction,[0],[0]
"A different approach to tackle noisy labels is to utilize correction methods such as loss correction (Patrini et al., 2017; Ghosh et al., 2017), label correction (Reed et al., 2014), or additional linear correction layers (Sukhbaatar & Fergus, 2014; Goldberger & Ben-Reuven, 2017).
",1. Introduction,[0],[0]
"In this paper, we first investigate the dimensionality of the deep representation subspaces learned by a DNN and provide a dimensionality-driven explanation of DNN generalization behavior in the presence of (class) label noise.",1. Introduction,[0],[0]
"Our analysis employs a dimensionality measure called Local Intrinsic Dimensionality (LID) (Houle, 2013; 2017a), applied to the deep representation subspaces of training examples.",1. Introduction,[0],[0]
"We show that DNNs follow two-stage of learning in this scenario: 1) an early stage of dimensionality compression, that models low-dimensional subspaces that closely match the underlying data distribution, and 2) a later stage of dimensionality expansion, that steadily increases subspace dimensionality in order to overfit noisy labels.",1. Introduction,[0],[0]
This second stage appears to be a key factor behind the poor generalization performance of DNNs for noisy labels.,1. Introduction,[0],[0]
"Based on this finding, we propose a new training strategy, termed Dimensionality-Driven Learning, that avoids the dimensionality expansion stage of learning by adapting the loss function.",1. Introduction,[0],[0]
"Our main contributions are:
• We show that from a dimensionality perspective, DNNs exhibit distinctive learning styles with clean labels versus noisy labels.
",1. Introduction,[0],[0]
"• We show that the local intrinsic dimensionality can
be used to identify the stage shift from dimensionality compression to dimensionality expansion.
",1. Introduction,[0],[0]
"• We propose a Dimensionality-Driven Learning strategy (D2L) that modifies the loss function once the turning point between the two stages of dimensionality compression and expansion is recognized, in an effort to prevent overfitting.
",1. Introduction,[0],[0]
"• We empirically demonstrate on MNIST, SVHN, CIFAR-10 and CIFAR-100 datasets that our Dimensionality-Driven Learning strategy can effectively learn (1) low-dimensional representation subspaces that capture the underlying data distribution, (2) simpler hypotheses, and (3) high-quality deep representations.",1. Introduction,[0],[0]
Zhang et al. (2017) showed that DNNs are capable of memorizing completely random labels and exhibit poor generalization capability.,2.1. Generalization of DNNs,[0],[0]
They argued that DNNs employ case-bycase memorization on training samples and their labels in this scenario.,2.1. Generalization of DNNs,[0],[0]
Krueger et al. (2017) highlighted that DNNs exhibit different learning styles on datasets with clean labels versus those on datasets with noisy inputs or noisy labels.,2.1. Generalization of DNNs,[0],[0]
"They showed that DNNs require more capacity, longer training time to fit noisy labels and the learned hypothesis is more complex.",2.1. Generalization of DNNs,[0],[0]
"Arpit et al. (2017) further substantiated this finding by identifying two stages of learning of DNNs with noisy labels: an early stage of simple pattern learning and refining, and a later stage of label memorization.",2.1. Generalization of DNNs,[0],[0]
They also showed that dropout regularization can hinder overfitting to noisy labels.,2.1. Generalization of DNNs,[0],[0]
"Shwartz-Ziv & Tishby (2017) demonstrated that, on data with clean labels, DNNs with tanh layers undergo an initial label fitting phase and then a subsequent compression phase.",2.1. Generalization of DNNs,[0],[0]
They also argued that information compression is related to the excellent generalization performance of DNNs.,2.1. Generalization of DNNs,[0],[0]
"However, Saxe et al. (2018) conducted experiments where information compression was not found to occur for ReLU (Glorot et al., 2011) DNNs.
",2.1. Generalization of DNNs,[0],[0]
"While these works have studied the differences between learning with clean labels and learning with noisy labels, a full picture of this phenomenon and its implications for DNN generalization is yet to emerge.",2.1. Generalization of DNNs,[0],[0]
"Our study adds another perspective based on subspace dimensionality analysis, and shows how this can lead to the development of an effective learning strategy.",2.1. Generalization of DNNs,[0],[0]
A variety of approaches have been proposed to robustly train DNNs on datasets with noisy labels.,2.2. Noisy Label Learning,[0],[0]
"One strategy is to
explicitly or implicitly formulate the noise model and use a corresponding noise-aware approach.",2.2. Noisy Label Learning,[0],[0]
"Symmetric label noise that is independent of the true label was modeled in (Larsen et al., 1998), and asymmetric label noise that is conditionally independent of individual samples was modeled in (Natarajan et al., 2013; Sukhbaatar et al., 2014).",2.2. Noisy Label Learning,[0],[0]
"There are also more complex noise models for training samples where true labels and noisy labels can be characterized by directed graphical models (Xiao et al., 2015), conditional random fields (Vahdat, 2017), neural networks (Veit et al., 2017; Jiang et al., 2017) or knowledge graphs (Li et al., 2017).",2.2. Noisy Label Learning,[0],[0]
These methods aim to correct noisy labels to their true labels via a clean label inference step or by assigning smaller weights to noisy label samples.,2.2. Noisy Label Learning,[0],[0]
"For the modeling of label noise, they often require an extra dataset with ground truth of pre-identified noisy labels to be available, or an expensive detection process.",2.2. Noisy Label Learning,[0],[0]
They may also rely on specific assumptions about the noise model.,2.2. Noisy Label Learning,[0],[0]
"Another approach is to use a refined training strategy that utilizes correction methods to adjust the loss function to eliminate the influence of noisy samples (Wang et al., 2018).",2.2. Noisy Label Learning,[0],[0]
"Backward and Forward are two such correction methods that use an estimated or learned factor to modify the loss function (Patrini et al., 2017).",2.2. Noisy Label Learning,[0],[0]
"A linear layer is added on top of the network to further augment the correction architecture in (Sukhbaatar & Fergus, 2014; Goldberger & Ben-Reuven, 2017).",2.2. Noisy Label Learning,[0],[0]
"Bootstrap replaces the target labels with a combination of raw target labels and their predicted labels (Reed et al., 2014).
",2.2. Noisy Label Learning,[0],[0]
"Our proposed Dimensionality-Driven Learning strategy is also a loss correction method, one that avoids overfitting by using the estimation of the local intrinsic dimensionality of learned local subspaces to regulate the learning process.",2.2. Noisy Label Learning,[0],[0]
In Section 5 we empirically compare Dimensionality-Driven Learning with other loss correction strategies.,2.2. Noisy Label Learning,[0],[0]
"The Local Intrinsic Dimensionality (LID) model (Houle, 2017a) was recently used for successful detection of adversarial examples for DNNs by (Ma et al., 2018).",2.3. Supervised Learning and Dimensionality,[0],[0]
"This work demonstrates that adversarial perturbations (one type of input noise) tend to increase the dimensionality of the local subspace immediately surrounding a test sample, and that features based on LID can be used for identifying such perturbations.",2.3. Supervised Learning and Dimensionality,[0],[0]
"However, in this paper we show how LID can be used in a new way, as a tool for assessing the learning behavior of a DNN, and developing an adaptive learning strategy against noisy labels.
",2.3. Supervised Learning and Dimensionality,[0],[0]
"Other works have also considered the use of dimensionality measures for regularization in manifold learning (Roweis & Saul, 2000; Belkin et al., 2004; 2006).",2.3. Supervised Learning and Dimensionality,[0],[0]
"For example, an intrinsic geometry regularization over Reproducing Kernel Hilbert Spaces (RKHS) was proposed in (Belkin et al., 2006)
to enforce smoothness of solutions relative to the underlying manifold, and a Laplacian-based regularization using the weighted neighborhood graph was proposed in (Belkin et al., 2004).",2.3. Supervised Learning and Dimensionality,[0],[0]
"In contrast to these works, which treated dimensionality as a characteristic of the global data distribution, we explore how knowledge of local dimensional characteristics can be used to monitor and modify DNN learning behavior for the noisy label scenario.",2.3. Supervised Learning and Dimensionality,[0],[0]
We now briefly introduce the LID measure for assessing the dimensionality of data subspaces residing in the deep representation space of DNNs.,3. Dimensionality of Deep Representation Subspaces,[0],[0]
We then connect dimensionality theory with the learning process of DNNs.,3. Dimensionality of Deep Representation Subspaces,[0],[0]
"Local Intrinsic Dimensionality (LID) is an expansion-based measure of intrinsic dimensionality of the underlying data subspace/submanifold (Houle, 2017a).",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"In the theory of intrinsic dimensionality, classical expansion models (such as the expansion dimension (Karger & Ruhl, 2002) and generalized expansion dimension (Houle et al., 2012)) measure the rate of growth in the number of data objects encountered as the distance from the reference sample increases.",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"Intuitively, in Euclidean space, the volume of an D-dimensional ball grows proportionally to rD when its size is scaled by a factor of r. From the above rate of volume growth with distance, the dimension D can be deduced from two volume measurements as:
V2/V1 = (r2/r1) D ⇒",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
D = ln(V2/V1)/,3.1. Local Intrinsic Dimensionality (LID),[0],[0]
ln(r2/r1).,3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"(1)
The aforementioned expansion-based measures of intrinsic dimensionality would determine D by estimating the volumes in terms of the numbers of data points captured by the balls.",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"Transferring the concept of expansion dimension from the Euclidean space to the statistical setting of continuous distance distributions, the notion of ball volume is replaced by the probability measure associated with the balls.",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"This leads to the formal definition of LID (Houle, 2017a): Definition 1 (Local Intrinsic Dimensionality).",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"Given a data sample x ∈ X , let r > 0 be a random variable denoting the distance from x to other data samples.",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"If the cumulative distribution function F (r) is positive and continuously differentiable at distance r > 0, the LID of x at distance r is given by:
LIDF (r) , lim →0
ln ( F ((1 + )",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
r) / F (r) ),3.1. Local Intrinsic Dimensionality (LID),[0],[0]
ln(1 + ),3.1. Local Intrinsic Dimensionality (LID),[0],[0]
= rF ′(r),3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"F (r) , (2)
whenever the limit exists.",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"The LID at x is in turn defined as the limit of the radius r → 0:
LIDF = lim r→0",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
LIDF (r).,3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"(3)
LIDF describes the relative rate at which its cumulative distance function F (r) increases as the distance r increases.",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"In the ideal case where the data in the vicinity of x are distributed uniformly within a local submanifold, LIDF equals the dimension of the submanifold.",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"Nevertheless, in more general cases, LID also provides a rough indication of the dimension of the submanifold containing x that would best fit the data distribution in the vicinity of x. We refer readers to (Houle, 2017a;b) for more details about LID.
Estimation of LID:",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"Given a reference sample point x ∼ P , where P represents a global data distribution, P induces a distribution of distances relative to x — each sample x∗ ∼ P being associated with the distance value d(x, x∗).",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"With respect to a dataset X drawn from P , the smallest k nearest neighbor distances from x can be regarded as extreme events associated with the lower tail of the induced distance distribution.",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"From the statistical theory of extreme values, the tails of continuous distance distributions can be seen to converge to the Generalized Pareto Distribution (GPD), a form of power-law distribution (Coles et al., 2001; Hill, 1975).",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"Several estimators of LID were developed in (Amsaleg et al., 2015; Levina & Bickel, 2005), of which the Maximum Likelihood Estimator (MLE) exhibited the best trade-off between statistical efficiency and complexity:
L̂ID(x) =",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"−
( 1
k k∑ i=1",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"log ri(x) rmax (x)
)−1 .",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"(4)
Here, ri(x) denotes the distance between x and its i-th nearest neighbor, and rmax (x) denotes the maximum of the neighbor distances.",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"Note that the LID defined in Equation (3) is a distributional quantity, and the L̂ID defined in Equation (4) is its estimate.",3.1. Local Intrinsic Dimensionality (LID),[0],[0]
"Since computing neighborhoods with respect to the entire dataset X can be prohibitively expensive, we will estimate LID of a training example x from its k-nearest neighbor set within a batch randomly selected from X .",3.2. LID Estimation through Batch Sampling,[0],[0]
"Consider a L-layer neural network h : P → Rc, where h(i) is the intermediate transformation of the i-th layer, and c is a positive number indicating the number of classes.",3.2. LID Estimation through Batch Sampling,[0],[0]
"Given a batch of training samples XB ⊆ X , and a reference point x ∼ P (not necessarily a training sample), we estimate the LID score of x as:
L̂ID(x,XB) =",3.2. LID Estimation through Batch Sampling,[0],[0]
"−
( 1
k k∑ i=1",3.2. LID Estimation through Batch Sampling,[0],[0]
"log ri(g(x), g(XB))",3.2. LID Estimation through Batch Sampling,[0],[0]
"rmax (g(x), g(XB))
)−1 ,
(5) where g = h(L−1) is the output of the second-to-last layer of the network, ri(g(x), g(XB)) is the distance of g(x) to its ith nearest neighbor in the transformed set g(XB), and rmax represents the radius of the neighborhood.",3.2. LID Estimation through Batch Sampling,[0],[0]
"L̂ID(x,XB)
reveals the dimensional complexity of the local subspace in the vicinity of x, taken after transformation by g. Provided that the batch is chosen sufficiently large so as to ensure that the k-nearest neighbor sets remain in the vicinity of g(x), the estimate of LID at g(x) within the batch serves as an approximation to the value that would have been computed within the full dataset g(X).",3.2. LID Estimation through Batch Sampling,[0],[0]
"We now show by means of an example how the subspace dimensionality of training and test examples is affected by the quality of label information, as the number of training epochs is increased.",3.3. Subspace Dimensionality and Noisy Labels,[0],[0]
"For our example, we trained a 5-layer Convolutional Neural Network (CNN) on MNIST (an image data set with 10 categories of handwritten digits (LeCun et al., 1998)) and a 12-layer CNN on CIFAR-10 (a natural image data set with 10 categories (Krizhevsky & Hinton, 2009)) using SGD, cross-entropy loss, and two different label quality settings: (1) clean labels for all training samples; (2) noisy labels for 40% of the training samples, generated by uniformly and randomly replacing the correct label with one of the 9 incorrect labels.",3.3. Subspace Dimensionality and Noisy Labels,[0],[0]
"LID values at layer 4 for MNIST and layer 11 for CIFAR-10 were averaged over 10 batches of 128 points each, for a total of 1280 test points.",3.3. Subspace Dimensionality and Noisy Labels,[0],[0]
The resulting LID scores and the train/test accuracies are shown in Figure 1.,3.3. Subspace Dimensionality and Noisy Labels,[0],[0]
"When learning with clean labels, we observe a decreasing trend in LID score and an increasing trend in accuracy as the number of training epochs increases.",3.3. Subspace Dimensionality and Noisy Labels,[0],[0]
"However, when learning with noisy labels, we see a very different trend: first a decrease in LID followed by an increase,
accompanied by an initial increase in test accuracy followed by a decrease.",3.3. Subspace Dimensionality and Noisy Labels,[0],[0]
"We observed similar dimensionality trends for a 6-layer CNN on SVHN (Netzer et al., 2011) and a 44- layer ResNet (He et al., 2016) on CIFAR-100 (Krizhevsky & Hinton, 2009).
",3.3. Subspace Dimensionality and Noisy Labels,[0],[0]
"Clearly, in these two situations, the DNNs are exhibiting different learning styles.",3.3. Subspace Dimensionality and Noisy Labels,[0],[0]
"For training data with clean labels, the network gradually transforms the data to subspaces of low dimensionality.",3.3. Subspace Dimensionality and Noisy Labels,[0],[0]
"Once the subspaces of the lowest dimensionality has been found, the network effectively stops learning: the test accuracy stabilizes at its highest level and the dimensionality stabilizes at its lowest.",3.3. Subspace Dimensionality and Noisy Labels,[0],[0]
"On the other hand, for training data with noisy labels, the network initially learns a transformation of the data to subspaces of lower dimensionality, although not as low as when training on data with clean labels.",3.3. Subspace Dimensionality and Noisy Labels,[0],[0]
"Thereafter, the network progressively attempts to accommodate noisy labels by increasing the subspace dimensionality.",3.3. Subspace Dimensionality and Noisy Labels,[0],[0]
"From the above empirical results, we find that DNNs follow two-stage of learning in the presence of label noise: 1) an early stage of dimensionality compression, in which the dimensionalities associated with the underlying data manifold are learned; and 2) a later stage of dimensionality expansion, in which the subspace dimensionalities steadily increase as the learning process overfits to the noisy data.
",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
One possible explanation for this phenomenon can be found in the effect of transformation on the neighborhood set of test points.,3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"Given a training point x ∈ X , its initial spatial location (before learning) would relate to a low-dimensional local subspace determined by the underlying manifold (call this subspace A).",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"Although the initial neighborhood of x would likely contain many data points that are also close to manifold A, the LID estimate would not necessarily be the exact dimension of A. LID reveals the growth characteristics of the distance distribution from x, which is influenced by — but not equal to — the dimension of the manifold to which x is best associated.
",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"As the learning process progresses, the manifold undergoes a transformation by which it progressively achieves a better fit to the training data.",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"If x is labeled correctly, and if many of its neighbors also have clean labels, the learning process can be expected to converge towards a local subspace of relatively low intrinsic dimensionality (as observed in the left-hand plot of Figure 1); however, it should be noted that the learning process still risks overfitting to the data, if carried out too long.",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"With overfitting, the dimensionality of the local manifold would be expected to rise eventually.
",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"If x is incorrectly labeled, each epoch in the learning process progressively causes x — or more precisely, its transform
(call it x′) — to migrate to a new local subspace (call it A′) associated with members of the same label that was incorrectly applied to x. During this migration, the neighborhood of x′ tends to contain more and more points of A′ that share the same label as x, and fewer and fewer points from the original neighborhood in A. With respect to the points of A′, the mislabeled point x′ is spatially an outlier, since its coordinates relate to A and not A′; thus, the presence of x′ forces the local subspace around it to become more high-dimensional in order to accommodate (or compress)",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
it.,3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"This distortion results in a dimensionality expansion in the vicinity of x′ that would be expected to be reflected in LID estimates based at x′. Stopping the learning process earlier allows x′ to find its neighborhood in A before the local subspace is corrupted by too many neighbors from A′, which thus leads to better learning of the true data distribution and improved generalization to test data.
",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"This explanation of the effect of incorrect labeling in terms of local subspaces is consistent with the one recently given in (Ma et al., 2018) for the effect of adversarial perturbation on DNN classification.",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"In this situation, rather than directly assigning an incorrect label to the test item while leaving its spatial coordinates unchanged, the adversary must instead attempt to move a test point into a region associated with an incorrect class by means of an antagonistic learning process.",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"In both cases, regardless of how the test point is modified, the neighborhoods of the transformed points are affected in a similar manner: as the neighborhood membership evolves, the local intrinsic dimensionality can be expected to rise.",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"The associated changes in LID estimates have been used as the basis for the effective detection of a wide variety of adversarial attacks (Ma et al., 2018).",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"Recent theoretical work for adversarial perturbation in nearest-neighbor classification further supports the relationship between LID and local transformation of data, by showing that the magnitude of the perturbation required in order to subvert the classification diminishes as the local intrinsic dimensionality and data sample size grow (Amsaleg et al., 2017).",3.4. Two-Stage of Learning of DNNs on Noisy Labels,[0],[0]
"In the previous section, we observed that learning in the presence of noisy labels has two stages: dimensional compression, followed by dimensional expansion.",4. Dimensionality-Driven Learning Strategy,[0],[0]
"Motivated by these observations, we propose a Dimensionality-Driven Learning (D2L) strategy whose objective is to avoid the overfitting and loss of test accuracy associated with dimensional expansion.
",4. Dimensionality-Driven Learning Strategy,[0],[0]
"Given a training sample x, we denote its raw label as y and its predicted label as ŷ, where both y and ŷ are ‘onehot’ indicator vectors.",4. Dimensionality-Driven Learning Strategy,[0],[0]
"(L̂ID0, · · · , L̂IDi, · · · , L̂IDT ) is a sequence of LID scores, where L̂IDi represents the LID score computed from the second-to-last DNN layer at the
i-th training epoch (T epochs in total).",4. Dimensionality-Driven Learning Strategy,[0],[0]
Each LID score is produced as follows.,4. Dimensionality-Driven Learning Strategy,[0],[0]
"m batches of samples are randomly selected X1B , . . .",4. Dimensionality-Driven Learning Strategy,[0],[0]
", X m B and for each X i B and each of its members x, L̂ID(x,XiB) is computed.",4. Dimensionality-Driven Learning Strategy,[0],[0]
"This givesm×|XiB | LID estimates, which are then averaged to compute the LID score for the epoch (later, in the experiments, we use m = 10 and |XiB | = 128
To avoid dimensionality expansion during training with noisy labels, we propose to reduce the effect of noisy labels on learning the true data distribution using the following adaptive LID-corrected labels:
y∗ = αiy + (1− αi)ŷ, (6)
where αi is a LID-based factor that updates at the i-th training epoch:
αi = exp ( − λ L̂IDi
mini−1j=0 L̂IDj
) , (7)
where λ = i/T is a weighting that indicates decreasing confidence in the raw labels when the training proceeds to the dimensionality expansion stage (that is, when LID begins to increase).",4. Dimensionality-Driven Learning Strategy,[0],[0]
"The training loss can then be refined as:
L = − 1 N N∑ n=1",4. Dimensionality-Driven Learning Strategy,[0],[0]
∑,4. Dimensionality-Driven Learning Strategy,[0],[0]
y∗n,4. Dimensionality-Driven Learning Strategy,[0],[0]
y∗n,4. Dimensionality-Driven Learning Strategy,[0],[0]
"logP (y ∗ n|xn), (8)
where N is the total number of training samples and P (y∗n|xn) is the predicted class probability of y∗n given xn.
",4. Dimensionality-Driven Learning Strategy,[0],[0]
"Interpreting Equations (6) - (8), we can regard D2L as a simulated annealing algorithm that attempts to find an optimal trade-off between subspace dimensionality and prediction performance.",4. Dimensionality-Driven Learning Strategy,[0],[0]
The role of α is an exponential decay factor that allows for interpolation between raw and predicted label assignments according to the degree of dimensional expansion observed over the learning history.,4. Dimensionality-Driven Learning Strategy,[0],[0]
"Here, dimensional expansion is assessed in terms of the ratio of two average LID scores: the score observed at the current epoch, and the lowest score encountered at earlier epochs.",4. Dimensionality-Driven Learning Strategy,[0],[0]
"As the learning enters the dimensional expansion stage, this ratio exceeds 1, and the exponential decay factor begins to favor the current predicted label.",4. Dimensionality-Driven Learning Strategy,[0],[0]
The complete D2L learning strategy is shown in Algorithm 1.,4. Dimensionality-Driven Learning Strategy,[0],[0]
"Note that the computational cost of LID estimation through batch sampling is low compared to the overall training time (tLID/ttraining ≈ 1− 2%), as it requires only the pairwise distances within a few batches.
",4. Dimensionality-Driven Learning Strategy,[0],[0]
"To identify the turning point between the two stages of learning, we employ an epoch window of size w ∈",4. Dimensionality-Driven Learning Strategy,[0],[0]
"[1, T − 1] so as to allow w epochs of initialization for the network, and to reduce the variation of stochastic optimization.",4. Dimensionality-Driven Learning Strategy,[0],[0]
"The turning point is flagged when the LID score of the current epoch is two standard deviations higher than the mean LID score of
Algorithm 1 Dimensionality-Driven Learning (D2L)",4. Dimensionality-Driven Learning Strategy,[0],[0]
"Input: dataset X , network h(x), total epochs T , epoch window w, number of batches for LID estimation m. Initialize: epoch",4. Dimensionality-Driven Learning Strategy,[0],[0]
"i ← 0, lids ←",4. Dimensionality-Driven Learning Strategy,[0],[0]
"[], α0 ← 1, turning epoch u← −1.",4. Dimensionality-Driven Learning Strategy,[0],[0]
"repeat
Train h(x) for one epoch.",4. Dimensionality-Driven Learning Strategy,[0],[0]
"lid ← 0, λ← i/T .",4. Dimensionality-Driven Learning Strategy,[0],[0]
"for j = 1 to m do
Sample XB from X. lid ← lid + 1|XB",4. Dimensionality-Driven Learning Strategy,[0],[0]
"| ∑|XB | k=1 L̂ID(x,XB).
",4. Dimensionality-Driven Learning Strategy,[0],[0]
end for lids[i ]← lid/m. if i ≥ w and u = −1 and lid,4. Dimensionality-Driven Learning Strategy,[0],[0]
−mean(lids[i− w : i− 1]) > 2 · std(lids[i− w : i− 1]) then u← i− 1.,4. Dimensionality-Driven Learning Strategy,[0],[0]
# turning point found Rollback h(x) to the u-th epoch.,4. Dimensionality-Driven Learning Strategy,[0],[0]
end,4. Dimensionality-Driven Learning Strategy,[0],[0]
if if u > −1,4. Dimensionality-Driven Learning Strategy,[0],[0]
then αi = exp ( −λ · lids[i]/min(lids[0 : i− 1]) ) .,4. Dimensionality-Driven Learning Strategy,[0],[0]
else αi = α0 end if y∗ = αiy + (1− αi)ŷ. Update loss to L = − 1N ∑N n=1 ∑ y∗n y∗n,4. Dimensionality-Driven Learning Strategy,[0],[0]
"logP (y ∗ n|xn).
",4. Dimensionality-Driven Learning Strategy,[0],[0]
i← i+ 1.,4. Dimensionality-Driven Learning Strategy,[0],[0]
"until i = T or early stopping.
",4. Dimensionality-Driven Learning Strategy,[0],[0]
"the w preceding epochs, until which the D2L loss is equivalent to the cross-entropy loss (enforced by setting α equal to 1).",4. Dimensionality-Driven Learning Strategy,[0],[0]
"The epoch at which the turning point is identified can be regarded as the first epoch at which overfitting occurs; for this reason, we roll the model state back to that of the previous epoch, and begin the interpolation between the raw and predicted label assignments.",4. Dimensionality-Driven Learning Strategy,[0],[0]
"Although we find in the experimental results of Section 5 that this strategy works consistently well for a variety of datasets, further variations upon this basic strategy may also be effective.",4. Dimensionality-Driven Learning Strategy,[0],[0]
The D2L code is available at https://github.com/xingjunm/ dimensionality-driven-learning.,4. Dimensionality-Driven Learning Strategy,[0],[0]
"We evaluate our proposed D2L learning strategy, comparing the performance of our model with state-of-the-art baselines for noisy label learning.",5. Experiments,[0],[0]
"We first provide an empirical understanding of the proposed D2L learning strategy on subspace learning, hypothesis learning, representation learning and model analysis.
",5.1. Empirical Understanding of D2L,[0],[0]
"Experimental Setup: The experiments were conducted on the benchmark dataset CIFAR-10 (Krizhevsky & Hinton, 2009).",5.1. Empirical Understanding of D2L,[0],[0]
We used a 12-layer CNN architecture.,5.1. Empirical Understanding of D2L,[0],[0]
"All networks were trained using SGD with momentum 0.9, weight decay 10−4 and an initial learning rate of 0.1.",5.1. Empirical Understanding of D2L,[0],[0]
The learning rate was divided by 10 after epochs 40 and 80 (T = 120 epochs in total).,5.1. Empirical Understanding of D2L,[0],[0]
Simple data augmentations (width/height shift and horizontal flip) were applied.,5.1. Empirical Understanding of D2L,[0],[0]
"Noisy labels were generated by introducing symmetric noise, in which the labels of a given proportion of training samples are flipped to one of the other class label, selected with equal probability.",5.1. Empirical Understanding of D2L,[0],[0]
"In (Vahdat, 2017) this noisy label generation scheme has been verified to be more challenging than that of restricted (asymmetric) label noise, which assumes that mislabelling only occurs within a specific set of classes (Reed et al., 2014; Patrini et al., 2017).
",5.1. Empirical Understanding of D2L,[0],[0]
"Competing Strategies: 1) Backward (Patrini et al., 2017): training via loss correction by multiplying the cross-entropy loss by a noise-aware correction matrix; 2) Forward (Patrini et al., 2017): training with label correction by multiplying the network prediction by a noise-aware correction matrix; 3) Boot-hard (Reed et al., 2014): training with new labels generated by a convex combination (the “hard” version) of the noisy labels and their predicted labels; 4) Boot-soft (Reed et al., 2014): training with new labels generated by a convex combination (the “soft” version) of the noisy labels and their predictions; and 5) Cross-entropy: the conventional approach of training with cross-entropy loss.
",5.1. Empirical Understanding of D2L,[0],[0]
The parameters of the competitors were configured according to their original papers.,5.1. Empirical Understanding of D2L,[0],[0]
"For our proposed D2L, we set k = 20 for LID estimation, and used the average LID score over m = 10 random batches of training samples as the
overall dimensionality of the representation subspaces.
",5.1. Empirical Understanding of D2L,[0],[0]
Effect on Subspace Learning: We illustrate the effect of D2L on subspace learning by investigating the dimensionality (measured by LID) of the deep representation subspaces learned by DNNs and the test accuracy throughout training.,5.1. Empirical Understanding of D2L,[0],[0]
"The results are presented in Figure 2 for the CIFAR-10 dataset, with noisy label proportions set to 40% and to 60%.",5.1. Empirical Understanding of D2L,[0],[0]
"First, examining the test accuracy (the left-hand plots), we see that D2L can stabilize the test accuracy after around 60 epochs regardless of the noise rate, whereas the competitors experience a substantial decrease in test accuracy.",5.1. Empirical Understanding of D2L,[0],[0]
This indicates the effectiveness of D2L in limiting the overfitting to noisy labels.,5.1. Empirical Understanding of D2L,[0],[0]
"Second, we focus on the dimensionality of the representation subspaces learned by different models (the right-hand plots).",5.1. Empirical Understanding of D2L,[0],[0]
We observe that D2L is capable of learning representation subspaces which have significantly lower dimensionality than other models.,5.1. Empirical Understanding of D2L,[0],[0]
It can also be noted that lower-dimensional subspaces lead to better generalization and higher test accuracy.,5.1. Empirical Understanding of D2L,[0],[0]
"This supports our claim that the true data distribution is of low dimensionality, and that D2L is capable of learning the low-dimensional true data distribution even with a large proportion of noisy labels.",5.1. Empirical Understanding of D2L,[0],[0]
"Note that for the case of 60% label noise, the low test accuracy of the ‘backward’ model, as well as the low dimensionality of the learned subspaces, together show that this competitor suffered from underfitting.
",5.1. Empirical Understanding of D2L,[0],[0]
Effect on Hypothesis Learning: We investigate the complexity of the hypotheses learned from different models.,5.1. Empirical Understanding of D2L,[0],[0]
"Given a hypothesis space H, a learned hypothesis h ∈ H from a DNN with lower complexity is expected to generalize better.",5.1. Empirical Understanding of D2L,[0],[0]
"Here, we use the recently proposed Critical Sample Ratio (CSR) (Arpit et al., 2017) as the measure for hypothesis complexity.",5.1. Empirical Understanding of D2L,[0],[0]
"CSR measures the density around the decision boundaries, where a high CSR score indicates a complex decision boundary and hypothesis.
",5.1. Empirical Understanding of D2L,[0],[0]
"As shown in Figure 3, the complexity of the learned hypothesis from D2L is significantly lower than that of its competitors.",5.1. Empirical Understanding of D2L,[0],[0]
"Recalling the results from Figure 2, where D2L achieved the highest test accuracy, we conclude that a simpler hypothesis does lead to better generalization, and that D2L is capable here of learning smoother decision
boundaries and a simpler hypothesis than its competitors.
",5.1. Empirical Understanding of D2L,[0],[0]
"Effect on Representation Learning: To analyze the effectiveness of D2L for representation learning, we visualize dataset representations in 2-dimensional embeddings using t-SNE (Maaten & Hinton, 2008), a commonly-used dimensionality reduction technique for the visualization of high-dimensional data (LeCun et al., 2015).",5.1. Empirical Understanding of D2L,[0],[0]
Figure 4 presents the reduced 2D embeddings of 500 randomly selected samples from each of two classes on CIFAR-10.,5.1. Empirical Understanding of D2L,[0],[0]
"For each class, 40% of the samples were assigned correct labels (the ‘clean’ samples), and 60% were assigned incorrect labels chosen uniformly at random from the 9 other classes (the ‘noisy’ samples).",5.1. Empirical Understanding of D2L,[0],[0]
"We see that D2L (the right-hand plot) can learn high-quality representations that accurately separate the two classes of objects (blue vs red), and can effectively isolate noisy samples (magenta/cyan) from clean samples (blue/red).",5.1. Empirical Understanding of D2L,[0],[0]
"However, for both classes, representations learned by cross-entropy (the left-hand plot) suffer from significant overlapping between clean and noisy samples.",5.1. Empirical Understanding of D2L,[0],[0]
"Note that the representations of noisy samples learned by D2L are more fragmented, since the noisy labels are from many different classes.",5.1. Empirical Understanding of D2L,[0],[0]
"Overall, D2L is able to learn a high-quality representation from noisy datasets.
",5.1. Empirical Understanding of D2L,[0],[0]
Parameter Sensitivity: We assess the sensitivity of D2L to the neighborhood size k and the number of batches m used to compute the mean LID.,5.1. Empirical Understanding of D2L,[0],[0]
Figure 5 shows that D2L is relatively insensitive to these two hyper-parameters on the CIFAR-10 dataset.,5.1. Empirical Understanding of D2L,[0],[0]
We observed similar behavior with the other three datasets.,5.1. Empirical Understanding of D2L,[0],[0]
"Finally, we evaluate the robustness of D2L against noisy labels under varying noise rates (0%, 20%, 40%, and 60%) on several benchmark datasets, comparing to state-of-the-art baselines for noisy label learning.
",5.2. Robustness against Noisy Labels,[0],[0]
"Experimental Setup: Experiments were conducted on several benchmark datasets: MNIST (LeCun et al., 1998), SVHN (Netzer et al., 2011), CIFAR-10 (Krizhevsky & Hinton, 2009) and CIFAR-100 (Krizhevsky & Hinton, 2009).",5.2. Robustness against Noisy Labels,[0],[0]
"We used a LeNet-5 network (LeCun et al., 1998) for MNIST, a 6-layer CNN for SVHN, a 12-layer CNN for CIFAR-10 and a ResNet-44 network (He et al., 2016) for CIFAR-100.",5.2. Robustness against Noisy Labels,[0],[0]
"All networks were trained using SGD with momentum 0.9, weight decay 10−4 and an initial learning rate of 0.1.",5.2. Robustness against Noisy Labels,[0],[0]
"The learning rate is divided by 10 after epochs 20 and 40 for MNIST/SVHN (50 epochs in total), after epochs 40 and 80 for CIFAR-10 (120 epochs in total), and after epochs 80, 120 and 160 for CIFAR-100 (200 epochs in total) (Huang et al., 2016).",5.2. Robustness against Noisy Labels,[0],[0]
Simple data augmentations (width/height shift and horizontal flip) were applied on CIFAR-10 and CIFAR100.,5.2. Robustness against Noisy Labels,[0],[0]
Noisy labels were generated as described in Section 5.1.,5.2. Robustness against Noisy Labels,[0],[0]
"On a particular dataset, the compared methods differ only in their loss functions — they share the same CNN architecture, regularizations (batch normalization and max pooling), and the number of training epochs.",5.2. Robustness against Noisy Labels,[0],[0]
"We repeated the experiments 5 times with different random seeds for network initialization and label noise generation.
",5.2. Robustness against Noisy Labels,[0],[0]
Results: We report the mean test accuracy and standard deviation over 5 repetitions of the experiments in Table 1.,5.2. Robustness against Noisy Labels,[0],[0]
D2L outperforms its competitors consistently across all datasets and across all noise rates tested.,5.2. Robustness against Noisy Labels,[0],[0]
"In particular, the performance gap between D2L and its competitors increases
as the noise rate is increased from 20% to 60%.",5.2. Robustness against Noisy Labels,[0],[0]
"We also note that as the noise rate increases, the accuracy drop of D2L is the smallest among all models.",5.2. Robustness against Noisy Labels,[0],[0]
"Even with 60% label noise, D2L can still obtain a relatively high classification accuracy, which indicates that D2L may have the potential to be an effective strategy for semi-supervised learning.",5.2. Robustness against Noisy Labels,[0],[0]
"In this paper, we have investigated the generalization behavior of DNNs for noisy labels in terms of the intrinsic dimensionality of local subspaces.",6. Discussion and Conclusion,[0],[0]
"We observed that dimensional compression occurs early in the learning process, followed by dimensional expansion as the process begins to overfit.",6. Discussion and Conclusion,[0],[0]
"Employing a simple measure of local intrinsic dimensionality (LID), we proposed a Dimensionality-Driven Learning (D2L) strategy for avoiding overfitting that identifies the learning epoch at which the transition from dimensional compression to dimensional expansion occurs, and then suppresses the subsequent dimensionality expansion.",6. Discussion and Conclusion,[0],[0]
"D2L delivers very strong classification performance across a range of scenarios with high proportions of noisy labels.
",6. Discussion and Conclusion,[0],[0]
We believe that dimensionality-based analysis opens up new directions for understanding and enhancing the behavior of DNNs.,6. Discussion and Conclusion,[0],[0]
"Theoretical formulation of DNN subspace dimensionality, and investigation of the effects of data augmentation and regularization techniques such as batch normalization (Ioffe & Szegedy, 2015) and dropout (Srivastava et al., 2014) are possible directions for future research.",6. Discussion and Conclusion,[0],[0]
Another open issue is the investigation of how other forms of noise such as adversarial or corrupted inputs and asymmetric label noise can affect local subspace dimensionality and DNN learning behavior.,6. Discussion and Conclusion,[0],[0]
James Bailey is in part supported by the Australian Research Council via grant number DP170102472.,Acknowledgements,[0],[0]
Michael E. Houle is partially supported by JSPS Kakenhi Kiban (B) Research Grants 15H02753 and 18H03296.,Acknowledgements,[0],[0]
Shu-Tao Xia is partially supported by the National Natural Science Foundation of China under grant No. 61771273.,Acknowledgements,[0],[0]
Datasets with significant proportions of noisy (incorrect) class labels present challenges for training accurate Deep Neural Networks (DNNs).,abstractText,[0],[0]
"We propose a new perspective for understanding DNN generalization for such datasets, by investigating the dimensionality of the deep representation subspace of training samples.",abstractText,[0],[0]
"We show that from a dimensionality perspective, DNNs exhibit quite distinctive learning styles when trained with clean labels versus when trained with a proportion of noisy labels.",abstractText,[0],[0]
"Based on this finding, we develop a new dimensionality-driven learning strategy, which monitors the dimensionality of subspaces during training and adapts the loss function accordingly.",abstractText,[0],[0]
"We empirically demonstrate that our approach is highly tolerant to significant proportions of noisy labels, and can effectively learn low-dimensional local subspaces that capture the data distribution.",abstractText,[0],[0]
Dimensionality-Driven Learning with Noisy Labels,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 771–777 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
771",text,[0],[0]
Self-labeled data available on the Internet are popular research materials in many NLP areas.,1 Introduction,[0],[0]
"Metadata such as tags and emoticons given by users are considered as labels for training and testing learning-based models, which usually benefit from large amount of data.
",1 Introduction,[0],[0]
"One of the sources of self-labeled data widely used in the research community is Twitter, where the short-text messages tweets written by the crowd are publicly shared.",1 Introduction,[0],[0]
"In a tweet, the author can tag the short text with some hashtags such as #excited, #happy, #UnbornLivesMatter, and #Hillary4President to express their emotion or opinion.",1 Introduction,[0],[0]
"The tweets with a certain types of hashtags are collected as self-label data in a variety of research works including sentiment analysis (Qadir and Riloff, 2014), stance detection (Mohammad et al., 2016; Sobhani et al., 2017), fi-
nancial opinion mining (Cortis et al., 2017), and irony detection (Ghosh et al., 2015; Peled and Reichart, 2017; Hee et al., 2018).",1 Introduction,[0],[0]
"In the case of irony detection, it is impractical to manually annotate the ironic sentences from randomly sampled data due to the relatively low occurrences of irony (Davidov et al., 2010).",1 Introduction,[0],[0]
"Collecting the tweets with the hashtags like #sarcasm, #irony, and #not becomes the mainstream approach to dataset construction (Sulis et al., 2016).",1 Introduction,[0],[0]
"As shown in (S1), the tweet with the hashtag #not is treated as a positive (ironic) instance by removing #not from the text.
",1 Introduction,[0],[0]
(S1) @Anonymous doing a great job...,1 Introduction,[0],[0]
#not What do I pay my extortionate council taxes for?,1 Introduction,[0],[0]
#,1 Introduction,[0],[0]
"Disgrace #OngoingProblem http://t.co/FQZUUwKSoN
However, the reliability of the self-labeled data is an important issue.",1 Introduction,[0],[0]
"As pointed out in the pioneering work, not all tweet writers know the definition of irony (Van Hee et al., 2016b).",1 Introduction,[0],[0]
"For instance, (S2) is tagged with #irony by the writer, but it is just witty and amusing.
",1 Introduction,[0],[0]
(S2),1 Introduction,[0],[0]
BestProAdvice,1 Introduction,[0],[0]
"@Anonymous More clean OR cleaner, never more cleaner.",1 Introduction,[0],[0]
"#irony
When the false-alarm instances like (S2) are collected and mixed in the training and test data, the models that learn from the unreliable data may be misled, and the evaluation is also suspicious.
",1 Introduction,[0],[0]
The other kind of unreliable data comes from the hashtags not only functioning as metadata.,1 Introduction,[0],[0]
"That is, a hashtag in a tweet may also function as a content word in its word form.",1 Introduction,[0],[0]
"For example, the hashtag #irony in (S3) is a part of the sentence “the irony of taking a break...”, in contrast to the hashtag #not in (S1), which can be removed without a change of meaning.
",1 Introduction,[0],[0]
(S3),1 Introduction,[0],[0]
"The #irony of taking a break from reading about #socialmedia to check my social media.
",1 Introduction,[0],[0]
"When the hashtag plays as a content word in a tweet, the tweet is not a good candidate of selflabeled ironic instances because the sentence will be incomplete once the hashtag is removed.
",1 Introduction,[0],[0]
"In this work, both kinds of unreliable data, the tweets with a misused hashtag and the tweets in which the hashtag serves as a content word, are our targets to remove from the training data.",1 Introduction,[0],[0]
"Manual data cleaning is labor-intensive and inefficient (Van Hee et al., 2016a).",1 Introduction,[0],[0]
"Compared to general training data cleaning approaches (Malik and Bhardwaj, 2011; Esuli and Sebastiani, 2013; Fukumoto and Suzuki, 2004) such as boostingbased learning, this work leverages the characteristics of hashtag usages in tweets.",1 Introduction,[0],[0]
"With small amount of golden labeled data, we propose a neural network classifier for pruning the self-labeled tweets, and train an ironic detector on the less but cleaner instances.",1 Introduction,[0],[0]
"This approach is easily to apply to other NLP tasks that rely on self-labeled data.
",1 Introduction,[0],[0]
The contributions of this work are three-fold: (1) We make an empirically study on an issue that is potentially inherited in a number of research topics based on self-labeled data.,1 Introduction,[0],[0]
(2) We propose a model for hashtag disambiguation.,1 Introduction,[0],[0]
"For this task, the human-verified ground-truth is quite limited.",1 Introduction,[0],[0]
"To address the issue of sparsity, a novel neural network model for hashtag disambiguation is proposed.",1 Introduction,[0],[0]
"(3) The data pruning method, in which our model is applied to select reliable self-labeled data, is capable of improving the performance of irony detection.
",1 Introduction,[0],[0]
The rest of this paper is organized as follows.,1 Introduction,[0],[0]
Section 2 describes how we construct a dataset for disambiguating false-alarm hashtag usages based on Tweets.,1 Introduction,[0],[0]
"In Section 3, our model for hashtag disambiguation is proposed.",1 Introduction,[0],[0]
Experimental results of hashtag disambiguation are shown in Section 4.,1 Introduction,[0],[0]
"In addition, we apply our method to prune training data for irony detection.",1 Introduction,[0],[0]
The results are shown in Section 5.,1 Introduction,[0],[0]
Section 6 concludes this paper.,1 Introduction,[0],[0]
The tweets with indication hashtags such as #irony are usually collected as a dataset in previous works on irony detection.,2 Dataset,[0],[0]
"As pointed out in Section 1, the hashtags are treated as ground-truth for training and testing.",2 Dataset,[0],[0]
"To investigate the issue of false-alarm
self-labeled tweets, the tweets with human verification are indispensable.",2 Dataset,[0],[0]
"In this study, we build the ground-truth based on the dataset released for SemEval 2018 Task 3,1 which is targeted for finegrained irony detection (Hee et al., 2018).
",2 Dataset,[0],[0]
"In the SemEval dataset, the tweets with one of the three indication hashtags #not, #sarcasm, and #irony, are collected and human-annotated as one of four types: verbal irony by means of a polarity contrast, other verbal irony, situational irony, and non-ironic.",2 Dataset,[0],[0]
"In other words, the false-alarm tweets, i.e., the non-ironic tweets with indication hashtags, are distinguished from the real ironic tweets in this dataset.",2 Dataset,[0],[0]
"However, the hashtag itself has been removed in the SemEval dataset.",2 Dataset,[0],[0]
"For example, the original tweet (S1) has been modified to (S4), where the hashtag #not disappears.",2 Dataset,[0],[0]
"As a result, the hashtag information, the position and the word form of the hashtag (i.e., not, irony, or sarcasm), is missing from the SemEval dataset.
",2 Dataset,[0],[0]
(S4),2 Dataset,[0],[0]
@Anonymous doing a great job...,2 Dataset,[0],[0]
What do I pay my extortionate council taxes for?,2 Dataset,[0],[0]
#,2 Dataset,[0],[0]
"Disgrace #OngoingProblem http://t.co/FQZUUwKSoN
For hashtag disambiguation, the information of the hashtag in each tweet is mandatory.",2 Dataset,[0],[0]
"Thus, we recover the original tweets by using Twitter search.",2 Dataset,[0],[0]
"As shown in Table 1, a total of 1,359 tweets with hashtags information are adopted as the ground-truth.",2 Dataset,[0],[0]
"Note that more than 20% of selflabeled data are false-alarm, and this can be an issue when they are adopted as training or test data.",2 Dataset,[0],[0]
"For performing the experiment of irony detection in Section 5, we reserve the other 1,072 tweets in the SemEval dataset that are annotated as real ironic as the test data.
",2 Dataset,[0],[0]
"In addition to the issue of hashtag disambiguation, the irony tweets without an indication hashtag, which are regarded as non-irony instances in previous work, are another kind of misleading data for irony detection.",2 Dataset,[0],[0]
"Fortunately, the occurrence of such “false-negative” instances is insignificant due
1https://competitions.codalab.org/competitions/17468
to the relatively low occurrence of irony (Davidov et al., 2010).",2 Dataset,[0],[0]
Figure 1 shows our model for distinguishing the real ironic tweets from the false-alarm ones.,3 Disambiguation of Hashtags,[0],[0]
"Given an instance with the hashtag #irony is given, the preceding and the following word sequences of the hashtag are encoded by separate sub-networks, and both embeddings are concatenated with the handcrafted features and the probabilities of three kinds of part-of-speech (POS) tag sequences.",3 Disambiguation of Hashtags,[0],[0]
"Finally, the sigmoid activation function decides whether the instance is real ironic or false-alarm.",3 Disambiguation of Hashtags,[0],[0]
"The details of each component will be presented in the rest of this section.
",3 Disambiguation of Hashtags,[0],[0]
Word Sequences:,3 Disambiguation of Hashtags,[0],[0]
The word sequences of the context preceding and following the targeting hashtag are separately encoded by neural network sentence encoders.,3 Disambiguation of Hashtags,[0],[0]
"The Penn Treebank Tokenizer provided by NLTK (Bird et al., 2009) is used for tokenization.",3 Disambiguation of Hashtags,[0],[0]
"As a result, each of the left and the right word sequences is encoded as a embedding with a length of 50.
",3 Disambiguation of Hashtags,[0],[0]
"We experiments with convolution neural network (CNN) (Kim, 2014), gated recurrent unit (GRU) (Cho et al., 2014), and attentive-GRU for sentence encoding.",3 Disambiguation of Hashtags,[0],[0]
"CNN for sentence classification has been shown effective in NLP applications such as sentiment analysis (Kim, 2014).",3 Disambiguation of Hashtags,[0],[0]
"Classifiers based on recurrent neural network (RNN)
have also been applied to NLP, especially for sequential modeling.",3 Disambiguation of Hashtags,[0],[0]
"For irony detection, one of the state-of-the-art models is based on the attentive RNN (Huang et al., 2017).",3 Disambiguation of Hashtags,[0],[0]
"The first layer of the CNN, the GRU, and the attenive-GRU model is the 300-dimensional word embedding that is initialized by using the vectors pre-trained on Google News dataset.2
Handcrafted Features: We add the handcrafted features of the tweet in the one-hot representation.",3 Disambiguation of Hashtags,[0],[0]
The features taken into account are listed as follows.,3 Disambiguation of Hashtags,[0],[0]
(1) Lengths of the tweet in words and in characters.,3 Disambiguation of Hashtags,[0],[0]
"(2) Type of the target hashtag (i.e. #not, #sarcasm, or #irony).",3 Disambiguation of Hashtags,[0],[0]
(3) Number of all hashtags in the tweet.,3 Disambiguation of Hashtags,[0],[0]
(4) Whether the targeting hashtag is the first token in the tweet.,3 Disambiguation of Hashtags,[0],[0]
(5) Whether the targeting hashtag is the last token in the tweet.,3 Disambiguation of Hashtags,[0],[0]
(6) Whether the targeting hashtag is the first hashtag in the tweet since a tweet may contain more than one hashtag.,3 Disambiguation of Hashtags,[0],[0]
(7) Whether the targeting hashtag is the last hashtag in the tweet.,3 Disambiguation of Hashtags,[0],[0]
(8) Position of the targeting hashtag in terms of tokens.,3 Disambiguation of Hashtags,[0],[0]
"If the targeting hashtag is the ith token of the tweet with |w| tokens, and this feature is i|w| .",3 Disambiguation of Hashtags,[0],[0]
(9) Position of the targeting hashtag in all hashtags in the tweet.,3 Disambiguation of Hashtags,[0],[0]
"It is computed as j|h| where the targeting hashtag is the jth hashtag in the tweet that contains |h| hashtags.
",3 Disambiguation of Hashtags,[0],[0]
"Language Modeling of POS Sequences: As mentioned in Section 1, a kind of false-alarm hashtag usages is the case that the hashtag also functions as a content word.",3 Disambiguation of Hashtags,[0],[0]
"In this paper, we attempt to measure the grammatical completeness of the tweet with and without the hashtag.",3 Disambiguation of Hashtags,[0],[0]
"Therefore, language model on the level of POS tagging is used.",3 Disambiguation of Hashtags,[0],[0]
"As shown in Figure 1, POS tagging is performed on three versions of the tweet, and based on that three probabilities are measured and taken into account: 1) ph̄: the tweet with the whole hashtag removed.",3 Disambiguation of Hashtags,[0],[0]
2) ps̄: the tweet with the hash symbol # removed only.,3 Disambiguation of Hashtags,[0],[0]
3) pt: the original tweet.,3 Disambiguation of Hashtags,[0],[0]
Our idea is that a tweet will be more grammatical complete with only the hash symbol removed if the hashtag is also a content word.,3 Disambiguation of Hashtags,[0],[0]
"On the other hand, the tweet will be more grammatical complete with the whole hashtag removed since the hashtag is a metadata.
",3 Disambiguation of Hashtags,[0],[0]
"To measure the probability of the POS tag sequence, we integrate a neural network-based language model of POS sequence into our model.",3 Disambiguation of Hashtags,[0],[0]
"RNN-based language models are reportedly capa-
2https://code.google.com/archive/p/word2vec/
ble of modeling the longer dependencies among the sequential tokens (Mikolov et al., 2011).",3 Disambiguation of Hashtags,[0],[0]
Two millions of English tweets that are entirely different from those in the training and test data described in Section 2 are collected and tagged with POS tags.,3 Disambiguation of Hashtags,[0],[0]
We train a GRU language model on the level of POS tags.,3 Disambiguation of Hashtags,[0],[0]
"In this work, all the POS tagging is performed with the Stanford CoreNLP toolkit (Manning et al., 2014).",3 Disambiguation of Hashtags,[0],[0]
"We compare our model with popular neural network-based sentence classifiers including CNN, GRU, and attentive GRU.",4 Experiments,[0],[0]
We also train a logistic regression (LR) classifier with the handcrafted features introduced in Section 3.,4 Experiments,[0],[0]
"For the imbalance data, we assign class-weights inversely proportional to class frequencies.",4 Experiments,[0],[0]
Five-fold crossvalidation is performed.,4 Experiments,[0],[0]
Early-stop is employed with a patience of 5 epoches.,4 Experiments,[0],[0]
"In each fold, we further keep 10% of training data for tuning the model.",4 Experiments,[0],[0]
"The hidden dimension is 50, the batch size is 32, and the Adam optimizer is employed (Kingma and Ba, 2014).
",4 Experiments,[0],[0]
"Table 2 shows the experimental results reported in Precision (P), Recall (R), and F-score (F).",4 Experiments,[0],[0]
Our goal is to select the real ironic tweets for training the irony detection model.,4 Experiments,[0],[0]
"Thus, the real ironic tweets are regarded as positive, and the falsealarm ones are negative.",4 Experiments,[0],[0]
We apply t-test for significance testing.,4 Experiments,[0],[0]
The vanilla GRU and attentive GRU are slightly superior to the logistic regression model.,4 Experiments,[0],[0]
The CNN model performs the worst in this task because it suffers from over-fitting problem.,4 Experiments,[0],[0]
"We explored a number of layouts and hyperparameters for the CNN model, and consistent results are observed.
",4 Experiments,[0],[0]
"Our method is evaluated with either CNN, GRU, or attentive GRU for encoding the context preceding and following the targeting hashtag.",4 Experiments,[0],[0]
"By integrating various kinds of information, our method outperforms all baseline models no matter which encoder is used.",4 Experiments,[0],[0]
"The best model is the one integrating the attentive GRU encoder, which is significantly superior to all baseline models (p < 0.05), achieves an F-score of 88.49%,
To confirm the effectiveness of the language modeling of POS sequence, we also try to exclude the GRU language model from our best model.",4 Experiments,[0],[0]
"Experimental results show that the addition of language model significantly improves the perfor-
mance (p < 0.05).",4 Experiments,[0],[0]
"As shown in the last row of Table 2, the F-score is dropped to 84.17%.
",4 Experiments,[0],[0]
"From the data, we observe that the instances whose ps̄ ph̄ usually contain a indication hashtag function as a content word, and vice versa.",4 Experiments,[0],[0]
"For instances, (S5) and (S6) show the instances with the highest and the lowest ps̄ph̄ , respectively.
(S5) when your #sarcasm is so advanced people actually think you are #stupid ..
(S6) #mtvstars justin bieber #net #not #fast",4 Experiments,[0],[0]
We employ our model to prune self-labeled data for irony detection.,5 Irony Detection,[0],[0]
"As prior work did, we collect a set of tweets that contain indication hashtags as (pseudo) positive instances and also collect a set of tweets that do not contain indication hashtags as negative instances.",5 Irony Detection,[0],[0]
"For each positive instance, our model is performed to predict whether it is a real ironic tweet or false-alarm ones, and the falsealarm ones are discarded.
",5 Irony Detection,[0],[0]
"After pruning, a set of 14,055 tweets containing indication hashtags have been reduced to 4,617 reliable positive instances according to our model.",5 Irony Detection,[0],[0]
We add an equal amount of negative instances randomly selected from the collection of the tweets that do not contain indication hashtags.,5 Irony Detection,[0],[0]
"As a result, the prior- and the post-pruning training data, in the sizes of 28,110 and 9,234, respectively, are prepared for experiments.",5 Irony Detection,[0],[0]
"The dataflow of the training data pruning is shown in Figure 2.
",5 Irony Detection,[0],[0]
"For evaluating the effectiveness of our pruning method, we implement a state-of-the-art irony detector (Huang et al., 2017), which is based on attentive-RNN classifier, and train it on the priorand the post-pruned training data.
",5 Irony Detection,[0],[0]
The test data is made by the procedure as follows.,5 Irony Detection,[0],[0]
"The positive instances in the test data are taken from the 1,072 human-verified ironic tweets
that are reserved for irony detection as mentioned in Section 2.",5 Irony Detection,[0],[0]
The negative instances in the test data are obtained from the tweets that do not contain indication hashtags.,5 Irony Detection,[0],[0]
Note that the negative instances in the test data are isolated from those in the training data.,5 Irony Detection,[0],[0]
Experimental results confirm the benefit of pruning.,5 Irony Detection,[0],[0]
"As shown in Table 3, the irony detection model trained on the less, but cleaner data significantly outperforms the model that is trained on all data (p < 0.05).
",5 Irony Detection,[0],[0]
We compare our pruning method with an alternative approach that trains the irony detector on the human-verified data directly.,5 Irony Detection,[0],[0]
"Under this circumstances, the 1,083 ironic instances for training our hashtag disambiguation model are currently mixed with an equal amount of randomly sampled negative instances, and employed to train the irony detector.",5 Irony Detection,[0],[0]
"As shown in the last row of Table 3, the irony detector trained on the small data does not compete with the models that are trained on larger amount of self-labeled data.",5 Irony Detection,[0],[0]
"In other words, our data pruning strategy forms a semi-supervised learning that benefits from both self-labeled data and human annotation.",5 Irony Detection,[0],[0]
"Note that this task and the dataset are different from those of the official evaluation of SemEval 2018 Task 3, so the experimental results cannot be directly compared.
",5 Irony Detection,[0],[0]
"The calibrated confidence output by the sigmoid layer of our hashtag disambiguation model can be regarded as a measurement of the reliability of an instance (Niculescu-Mizil and Caruana, 2005; Guo et al., 2017).",5 Irony Detection,[0],[0]
"Thus, we can sort
all self-labeled data by their calibrated confidence and control the size of training set by adjusting the threshold.",5 Irony Detection,[0],[0]
"The higher the threshold value is set, the less the training instances remain.",5 Irony Detection,[0],[0]
Figure 3 shows the performances of the irony detector trained on the data filtered with different threshold values.,5 Irony Detection,[0],[0]
"For each threshold value, the bullet symbol (•) indicates the size of training data, and the bar indicates the F-score achieved by the irony detector trained on those data.",5 Irony Detection,[0],[0]
"The best result achieved by the irony detector trained on the 9,234 data filtered by our model with the default threshold value (0.5).",5 Irony Detection,[0],[0]
This confirms that our model is able to select useful training instances in a strict manner.,5 Irony Detection,[0],[0]
Self-labeled data is an accessible and economical resource for a variety of learning-based applications.,6 Conclusion,[0],[0]
"However, directly using the labels made by the crowd as ground-truth for training and testing may lead to inaccurate performance due to the reliability issue.",6 Conclusion,[0],[0]
This paper addresses this issue in the case of irony detection by proposing a model to remove two kinds of false-alarm tweets from the training data.,6 Conclusion,[0],[0]
"Experimental results confirm that the irony detection model benefits from the less, but cleaner training data.",6 Conclusion,[0],[0]
Our approach can be applied to other topics that rely on self-labeled data.,6 Conclusion,[0],[0]
"This research was partially supported by Ministry of Science and Technology, Taiwan, under grants MOST-105-2221-E-002-154-MY3, MOST-1062923-E-002-012-MY3 and MOST-107-2634-F002-011-.",Acknowledgements,[0],[0]
The reliability of self-labeled data is an important issue when the data are regarded as ground-truth for training and testing learning-based models.,abstractText,[0],[0]
This paper addresses the issue of false-alarm hashtags in the self-labeled data for irony detection.,abstractText,[0],[0]
"We analyze the ambiguity of hashtag usages and propose a novel neural networkbased model, which incorporates linguistic information from different aspects, to disambiguate the usage of three hashtags that are widely used to collect the training data for irony detection.",abstractText,[0],[0]
"Furthermore, we apply our model to prune the self-labeled training data.",abstractText,[0],[0]
Experimental results show that the irony detection model trained on the less but cleaner training instances outperforms the models trained on all data.,abstractText,[0],[0]
Disambiguating False-Alarm Hashtag Usages in Tweets for Irony Detection,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 2257–2267 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
2257",text,[0],[0]
"A question that remains unresolved in work on discourse coherence is the nature and number of relations that can hold between clauses in a coherent text (Halliday and Hasan, 1976; Stede, 2012).
",1 Introduction,[0.9999999508640564],"['A question that remains unresolved in work on discourse coherence is the nature and number of relations that can hold between clauses in a coherent text (Halliday and Hasan, 1976; Stede, 2012).']"
"Our earlier work (Rohde et al., 2015, 2016) showed that, in the presence of explicit discourse adverbials, people also infer additional discourse relations that they take to hold jointly with those associated with the adverbials.",1 Introduction,[1.0],"['Our earlier work (Rohde et al., 2015, 2016) showed that, in the presence of explicit discourse adverbials, people also infer additional discourse relations that they take to hold jointly with those associated with the adverbials.']"
"For example, in:
(1) It’s too far to walk.",1 Introduction,[1.0000000518482053],"['For example, in: (1) It’s too far to walk.']"
"Instead let’s take the bus.
",1 Introduction,[0],[0]
"people infer a RESULT relation in the context of the adverbial instead, which itself signals that the bus stands in a SUBSTITUTION relation to walking.",1 Introduction,[1.0],"['people infer a RESULT relation in the context of the adverbial instead, which itself signals that the bus stands in a SUBSTITUTION relation to walking.']"
"We showed this using crowdsourced conjunctioninsertion experiments (Rohde et al., 2015, 2016), in which participants were asked to insert into the gap between two discourse segments, a conjunction that
best expressed how they took the segments to be related.",1 Introduction,[1.0000000846375423],"['We showed this using crowdsourced conjunctioninsertion experiments (Rohde et al., 2015, 2016), in which participants were asked to insert into the gap between two discourse segments, a conjunction that best expressed how they took the segments to be related.']"
Rohde et al. (2017) also asked participants to select any other conjunctions that they took to convey the same sense as their “best” choice.,1 Introduction,[1.0],['Rohde et al. (2017) also asked participants to select any other conjunctions that they took to convey the same sense as their “best” choice.']
"(More details of these experiments are given in Section 3.)
",1 Introduction,[0],[0]
All three studies showed participants selecting conjunctions whose sense differed from that of the explicit discourse adverbial.,1 Introduction,[0],[0]
"But Rohde et al. (2015, 2016) also showed participants often selecting conjunctions that signal different coherence relations than those selected by other participants.",1 Introduction,[1.0],"['But Rohde et al. (2015, 2016) also showed participants often selecting conjunctions that signal different coherence relations than those selected by other participants.']"
And Rohde et al. (2017) showed participants often identifying very different conjunctions as conveying the same meaning.,1 Introduction,[0],[0]
"For example, in passage (2), with the discourse adverbial in other words, one large fraction of participants chose to insert OR, while another large fraction inserted SO.",1 Introduction,[0],[0]
"Since the two are neither synonymous nor representative of the same relation, either the participants have come up with different analyses of the passages (Section 2) or something more surprising is at work.
",1 Introduction,[0],[0]
"(2) Unfortunately, nearly 75,000 acres of tropical forest are converted or deforested every day ______",1 Introduction,[0],[0]
in other words an area the size of Central Park disappears every 16 minutes.,1 Introduction,[0],[0]
"[SO∼OR]
Rohde et al. (2017) noted other cases where different pairs of conjunctions (e.g., BECAUSE and BUT, BUT and OR, and BECAUSE and OR) appear systematically across participants and across passages for particular adverbials, and speculated on what these odd pairings may reveal, but did not provide any empirical evidence for why this happens.",1 Introduction,[0],[0]
"Here we present such evidence from an experiment on three discourse adverbials (in other words, otherwise, and instead).
",1 Introduction,[0],[0]
"After describing related work on multiple discourse relations (Section 2) and then our experimental methodology (Section 3), we step through results for these three adverbials.",1 Introduction,[0],[0]
"As a final piece of evidence, we manipulate the presence and absence of a fourth adverbial, after all, in order to
demonstrate that inference of the relation(s) between segments in a passage is not always driven by the presence of such an adverbial.",1 Introduction,[0],[0]
"This is not the first work on discourse coherence to acknowledge the possibility of multiple relations holding between given discourse segments.
",2 Related Work,[0],[0]
"For example, the developers of Rhetorical Structure Theory acknowledged that even experienced RST analysts may interpret a text differently in terms of the relations they take to hold (Mann and Thompson, 1988, p. 265).",2 Related Work,[0],[0]
"But while RST allows for multiple alternative analyses of a text in terms of discourse relations, in practice, researchers working in the RST framework standardly produce a single analysis of a text, with a single relational labeling, selecting the analysis that is “most plausible in terms of the perceived goals of the writer” (Mann et al., 1989, pp. 34–35).",2 Related Work,[0],[0]
"If that single analysis is later mapped into a different structure to support further processing – e.g., a binary branching tree structure – the mapping does not change the chosen relational labeling.
",2 Related Work,[0],[0]
Multiple relations may additionally hold in theories of discourse coherence that posit multiple levels of text analysis.,2 Related Work,[0],[0]
"For example, following Grosz and Sidner (1986), Moore and Pollack (1992) characterized text as having both an informational structure (relating information conveyed by discourse segments) and an intentional structure (relating the functions of those segments with respect to what the speaker is trying to accomplish through the text).",2 Related Work,[0],[0]
"The kinds of relations at the two levels are different, as can be seen in the following example from (Moore and Pollack, 1992, p. 540):
(3) a. George Bush supports big business.",2 Related Work,[0],[0]
b.,2 Related Work,[0],[0]
"He’s sure to veto House Bill 1711.
",2 Related Work,[0],[0]
"At the level of intentions, (3a) aims to provide EVIDENCE for the claim in (3b), while at an informational level, (3a) serves as the CAUSE of the situation in (3b).",2 Related Work,[0],[0]
"RST would force annotators to choose only the analysis that best reflected the perceived goals of the writer.
",2 Related Work,[0],[0]
"Additionally, multiple relations can hold where there are distinct explicit signals for distinct discourse relations holding between a pair of segments (Cuenca and Marin, 2009; Fraser, 2013), as in:
(4) It’s too far to walk.",2 Related Work,[0],[0]
"So instead let’s take the bus.
where the conjunction so signals a RESULT relation and the adverbial instead signals that taking the bus stands in an SUBSTITUTION relation to walking.
",2 Related Work,[0],[0]
"Finally, a fourth way in which the previous literature has taken multiple discourse relations to hold is when a single phrase or lexico-syntactic construction jointly signals multiple discourse relations as holding over a text – for example, since as a subordinating conjunction may, in particular contexts, signal both a TEMPORAL relation and a CAUSAL relation, rather than just one or the other (Miltsakaki et al., 2005).
",2 Related Work,[0],[0]
"We are aware of only two resources that allow more than one discourse relation to be annotated between two segments – the Penn Discourse TreeBank (PDTB; Prasad et al., 2008, 2014) and, more recently, the BECauSE Corpus 2.0 (Dunietz et al., 2017).",2 Related Work,[0],[0]
The PDTB allows multiple discourse relations of the third and fourth types noted above.,2 Related Work,[0],[0]
"It also allows them to be annotated if there is no explicit connective between a pair of segments but annotators see more than one sense relation as linking them, as in the following variant of (4):
(5) It’s too far to walk.",2 Related Work,[0],[0]
"Let’s take the bus.
",2 Related Work,[0],[0]
"Here a RESULT relation can be associated with an implicit token of so between the clauses, while a SUBSTITUTION relation can be associated with an implicit token of instead.",2 Related Work,[0],[0]
The above are the main cases in which PDTB annotates multiple relations.,2 Related Work,[0],[0]
"Relevant to this paper, the PDTB does not annotate implicit conjunction relations where there is already an explicit discourse adverbial.",2 Related Work,[0],[0]
"Thus the PDTB would either ignore the implicit RESULT relation for (1) or (incorrectly) annotate instead in (1) as conveying both SUBSTITUTION and RESULT.
",2 Related Work,[0],[0]
"Moreover, while the PDTB has been used in training many (but not all) discourse parsers (Marcu, 2000; Lin et al., 2014; Feng and Hirst, 2012; Xue et al., 2015, 2016; Ji and Eisenstein, 2014), discourse parsing has for the most part ignored its annotations of multiple concurrent relations between clauses, except in the case of distinct explicit connectives expressing distinct relations.",2 Related Work,[0],[0]
"Instead, they have arbitrarily taken just a single relation to hold, even though the relations are simply recorded in an a priori canonical order.",2 Related Work,[0],[0]
"This practice is problematic because, for example, there may well be a difference in the properties of segments where two relations are jointly seen to hold, versus those segments in which only one or the other holds.",2 Related Work,[0],[0]
"This can result in unwanted noise in the data and lower the reliability of whatever is induced.
",2 Related Work,[0],[0]
"While our previous studies showed another source of multiple discourse relations holding con-
2259
currently between discourse segments, the work reported here explains how, in the context of multiple relations, participants can take very different conjunctions to be conveying the same relation, and what can change participants’ selection of a conjunction to mark the relation they infer alongside that conveyed by an explicit discourse adverbial.",2 Related Work,[0],[0]
"A locally crowdsourced conjunction-insertion task provided a proxy for labelling relations between adjacent discourse segments within a passage.
",3 Methodology,[0],[0]
"Our materials consisted of passages containing an explicit discourse adverbial, preceded by a gap, which effectively separated the passage into two segments.",3 Methodology,[1.0],"['Our materials consisted of passages containing an explicit discourse adverbial, preceded by a gap, which effectively separated the passage into two segments.']"
"The passages consisted of 16 with in other words, 16 with instead, 16 with after all, and 48 with otherwise.",3 Methodology,[0],[0]
Participants were asked to read each passage and choose the conjunction(s) that best expressed how the two segments link together.,3 Methodology,[1.0],['Participants were asked to read each passage and choose the conjunction(s) that best expressed how the two segments link together.']
"The presentation of conjunction choices varied in order for each participant, but always consisted of AND, BECAUSE, BUT, OR, SO, NONE.",3 Methodology,[0],[0]
"While the task admittedly encourages participants to select one (or more) conjunctions, our prior work has shown that participants are very willing to use NONE if no conjunction is appropriate.",3 Methodology,[0],[0]
We therefore take their insertion of a conjunction as their endorsement of the relation signaled by that conjunction.,3 Methodology,[0],[0]
"To further control data quality, we included 6 catch trials with an expected correct conjunction like “To be ______ not to be”.
",3 Methodology,[0.9999999422496622],"['To further control data quality, we included 6 catch trials with an expected correct conjunction like “To be ______ not to be”.']"
"Three of the explicit discourse adverbials that we chose are anaphoric: in other words, otherwise, and instead (Webber et al., 2000).",3 Methodology,[0],[0]
"Unlike conjunctions such as AND, BECAUSE, BUT, OR and SO, they are not constrained by structure as to what they establish discourse relations with.",3 Methodology,[0],[0]
So a conjunction-insertion task can be used to assess links between the segments (see also Scholman and Demberg 2017).,3 Methodology,[0],[0]
"Our three anaphoric adverbials share a core meaning of ‘otherness’ via their lexical semantics and flexibility in the relations they can participate in, making them a fruitful set to compare.",3 Methodology,[0],[0]
"The fourth adverbial, after all, allows us to test a hypothesis that the inferred connection between clauses is not driven by the adverbial alone.
",3 Methodology,[1.0000000662964037],"['The fourth adverbial, after all, allows us to test a hypothesis that the inferred connection between clauses is not driven by the adverbial alone.']"
"These particular adverbials were selected because they had yielded unexpected combinations of conjunction insertions in our prior work (e.g., OR/SO with in other words).",3 Methodology,[0],[0]
"This is in con-
trast to adverbials like therefore and nevertheless, for which participants’ conjunction combinations could be attributed to variation in the specificity of the conjunctions (SO/AND for therefore, BUT/AND for nevertheless).",3 Methodology,[0],[0]
"For our selection of a set of conjunctions to use as proxies for relation labels, we included all the coordinating conjunctions in English, as well as the subordinating conjunction BECAUSE as EXPLANATION relations are frequent.
",3 Methodology,[0],[0]
All participants (N=28) were monolingual native English speakers who were selected following a pre-test to measure their ability to consistently insert conjunctions that captured the underlying coherence relations in a series of passages.,3 Methodology,[0],[0]
All gave informed consent.,3 Methodology,[0],[0]
They each received £50 for their time.,3 Methodology,[0],[0]
Each participant saw one of two randomly ordered lists.,3 Methodology,[0],[0]
"Passages were presented in batches of 34, one batch per day for three days.
",3 Methodology,[0.9999999720756767],"['Passages were presented in batches of 34, one batch per day for three days.']"
The materials were simplified variants of naturally occurring passages.,3 Methodology,[0],[0]
"Some were also manipulated systematically, in ways aimed at altering the availability of different coherence relations.",3 Methodology,[0],[0]
"Passages are available via the “dataset” link on the paper in the ACL anthology, and predictions about them are laid out in Sections 4.1–4.4.",3 Methodology,[0],[0]
4.1,4 Datasets,[0],[0]
"In other words Dataset
Rohde et al. (2016) report an OR∼SO response split for in other words when participants could insert only their top choice of conjunction.",4 Datasets,[0],[0]
"Figure 1 shows SO dominating participants’ choice in all cases, but OR showing up among their choices in all but one passage (leftmost vertical bar).",4 Datasets,[0],[0]
"Additionally, several passages elicited BUT as the top choice of some participants.
0
7
14
21
28
and because before but or so other noneinstead
0
7
14
21
28
and because before but or so other noneotherwise
2260
The in other words passages of the current experiment tested two linked hypotheses: The first is that OR∼SO response splits arise from two components of the lexical semantics of the adverbial itself: its sense of an evoked alternative and its sense of a consequence via restatement, whereby the truth of the second segment holds because it provides a reformulated restatement of the first segment’s content.",4 Datasets,[0],[0]
"For passage (2), this corresponds to the deforestation of 75,000 acres of tropical forest entailing the disappearance of an area the size of Central Park every 16 minutes.
",4 Datasets,[0],[0]
The second hypothesis is that the prevalence of and substitutability between SO and OR in (2) depends on the immediately adjacency of the two segments.,4 Datasets,[1.0],['The second hypothesis is that the prevalence of and substitutability between SO and OR in (2) depends on the immediately adjacency of the two segments.']
"This was suggested by participant choices of BUT (cf. Figure 1), as well as the observation that in other words does not always license OR via its lexical semantics and SO via entailment, as shown in (6), where BUT has become more available.",4 Datasets,[0],[0]
"Note that none of the relations conveyed by these conjunctions (CONTRAST or CONCESSION for BUT, DISJUNCTION for OR, CONSEQUENCE for SO) are already conveyed by the adverbial itself, which for in other words) would be RESTATEMENT.
",4 Datasets,[0],[0]
"(6) Unfortunately, nearly 75,000 acres of tropical forest are converted or deforested every day.",4 Datasets,[0],[0]
I don’t know where I heard that ______,4 Datasets,[0],[0]
"in other words an area the size of Central Park disappears every 16 minutes.
",4 Datasets,[0],[0]
We tested these hypotheses by creating minimal pairs of 16 passages containing in other words.,4 Datasets,[0],[0]
"The pairs varied in the presence/absence of a metalinguistic comment intervening between the original description and its reformulation, as in (7)–(8).
(7) Typically, a cast-iron wood-burning stove is 60 percent efficient ______",4 Datasets,[0],[0]
"in other words 40 percent of the wood ends up as ash, smoke or lost heat.",4 Datasets,[0],[0]
"(8) Typically, a cast-iron wood-burning stove is 60 percent efficient.",4 Datasets,[1.0],"['(8) Typically, a cast-iron wood-burning stove is 60 percent efficient.']"
How this is measured is unclear ______,4 Datasets,[0],[0]
"in other words 40 percent of the wood ends up as ash, smoke or lost heat.
",4 Datasets,[0],[0]
"For each passage, participants identified their preferred conjunction and then any others that they took to convey the same sense.",4 Datasets,[0],[0]
"Half the participants saw a given passage with no intervening metalinguistic comment, half with.
",4 Datasets,[0],[0]
"If our hypotheses are confirmed, it will show that manipulating the immediately preceding segment can shift participants’ preference from relations associated with OR and SO (ALTERNATIVE and CONSEQUENCE) to relations of CONTRAST or CONCESSION.",4 Datasets,[1.0],"['If our hypotheses are confirmed, it will show that manipulating the immediately preceding segment can shift participants’ preference from relations associated with OR and SO (ALTERNATIVE and CONSEQUENCE) to relations of CONTRAST or CONCESSION.']"
"This would then be evidence that adjacency affects what coherence relations participants take to be available.
0 7 14 21 28
and because before but or so other noneinstead in other words 0 7 14 21 28 and because before but or so other none
4.2 Otherwise Dataset Rohde et al. (2016) report surprising response splits amongst BECAUSE∼BUT∼OR for otherwise in their conjunction-insertion data (Figure 2).",4 Datasets,[0],[0]
"Given that otherwise has several different functions (described below), we hypothesize that different response splits arise from the lexical semantics of otherwise, combined with inference as to the function of the otherwise clause in a given passage.
",4 Datasets,[1.0000000579820192],"['Given that otherwise has several different functions (described below), we hypothesize that different response splits arise from the lexical semantics of otherwise, combined with inference as to the function of the otherwise clause in a given passage.']"
One function of otherwise is in ARGUMENTATION.,4 Datasets,[0],[0]
"Here, an otherwise clause provides a reason for a given claim, as in (9).",4 Datasets,[0],[0]
"Another function is in ENUMERATION, when the speaker first gives some preferred or more salient options, the otherwise clause introduces other alternative options, as in (10).",4 Datasets,[0],[0]
A third use is in expressing an EXCEPTION to a generalization.,4 Datasets,[0],[0]
"Here, the main clause expresses a generalization, while otherwise clause specifies an exception (disjunctive alternative) to it, as in (11).
",4 Datasets,[0],[0]
(9) Proper placement of the testing device is an important issue ______,4 Datasets,[0],[0]
"otherwise the test results will be inaccurate.
",4 Datasets,[0],[0]
"(10) A baked potato, plonked on a side plate with sour cream flecked with chives, is the perfect accompaniment ______",4 Datasets,[0],[0]
"otherwise you could serve a green salad and some good country bread.
",4 Datasets,[0],[0]
"(11) Mr. Lurie and Mr. Jarmusch actually catch a shark, a thrashing 10-footer ______",4 Datasets,[0],[0]
"otherwise the action is light.
",4 Datasets,[0],[0]
"Results presented in (Rohde et al., 2017) for passages like (9) showed participant judgments of OR and BECAUSE, but not BUT.",4 Datasets,[0],[0]
"Passages like (10) yielded pairings of OR and BUT, but not BECAUSE.",4 Datasets,[0],[0]
"Lastly, passages like (11) yielded response splits between BUT and the less specific AND (Knott, 1996).
",4 Datasets,[0],[0]
"Note that due to overlaps in conjunction choice, some conjunctions cannot be unambiguously associated with a single use of otherwise: While BECAUSE may unambiguously signal that a participant has inferred ARGUMENTATION, OR might indicate inference of either ARGUMENTATION or
2261
ENUMERATION.",4 Datasets,[0],[0]
Thus we probe both participant choices of connectives and (via paraphrase),4 Datasets,[0],[0]
"the use of otherwise that they take to hold.
",4 Datasets,[0],[0]
"We chose 16 passages for each use of otherwise, based on our own category judgments.",4 Datasets,[0],[0]
"For each passage, we asked participants to select the conjunction that best expressed how its two segments were related, and then any other connectives that they took to express the same thing.
",4 Datasets,[0],[0]
A paraphrase task was then used as further evidence for the relation participants inferred in the otherwise passages.,4 Datasets,[0],[0]
"After completing a given session’s batch of passages, participants were asked to select which of three options they took to be a valid paraphrase of the passage.",4 Datasets,[0],[0]
"Each use of otherwise was assigned a distinct paraphrase to link the left-hand and right-hand segments (LHS, RHS).
",4 Datasets,[0],[0]
"• ARGUMENTATION: “A reason for 〈LHS〉 is 〈RHS〉.”
",4 Datasets,[0],[0]
• EXCEPTION: “Generally 〈RHS〉.,4 Datasets,[0],[0]
"An exception is when 〈LHS〉.”
• ENUMERATION: “There’s more than one good option for 〈goal〉.",4 Datasets,[0],[0]
"They are: 〈LHS〉, 〈RHS〉.”
",4 Datasets,[0],[0]
"We also allowed participants to choose a second paraphrase if they thought it appropriate.
4.3",4 Datasets,[0],[0]
Instead Dataset Rohde et al. (2016) report a range of participant choices in conjunction-insertion passages involving instead (Figure 3).,4 Datasets,[0],[0]
"For passages on the left of the figure, participants uniformly chose BUT, while the passage on the far right yielded a strong preference for SO.",4 Datasets,[0],[0]
"Elsewhere, some chose BUT and some chose SO.",4 Datasets,[0],[0]
"(For the current experiment, we ignore the fact that AND can contingently substitute for either BUT or SO as a connective in text (Knott, 1996), focussing only on passages where participants explicitly choose BUT and/or SO.)
",4 Datasets,[0],[0]
"Rohde et al. (2017) report even more surprising participant responses to passages such as (12), where some participants selected both BUT and SO as equally expressing how the segments in the passage were related.",4 Datasets,[0],[0]
"(12) There may not be a flight scheduled to Loja today
______",4 Datasets,[0],[0]
instead we can go to Cuenca.,4 Datasets,[0],[0]
"[BUT∼SO]
Neither the inter-participant split between BUT and SO in (Rohde et al., 2016) nor the intraparticipant split between them (Rohde et al., 2017) can be explained in terms of instead itself, since
in other words 0 7 14 21 28
and because before but or so other none
0
7
14
21
28
and because before but or so other noneotherwise
instead simply conveys that what follows is an alternative to an unrealised situation in the context (Prasad et al., 2008; Webber, 2013).",4 Datasets,[0],[0]
"The current experiment tests the hypothesis that this BUT∼SO split is a consequence of inference from properties of the segments themselves.
",4 Datasets,[0],[0]
"To test this hypothesis, we created 16 minimal pairs of passages containing instead, one of which emphasized the information structural parallelism between the clauses, as in (13a), and another variant (13b)",4 Datasets,[0],[0]
"that de-emphasized that parallelism in favor of a causal link implied by a downward-entailing construction such as too X (Webber, 2013).",4 Datasets,[0],[0]
"For each passage, half the participants saw the parallelism variant in the conjunctioninsertion task, while half saw the causal variant.
",4 Datasets,[0],[0]
(13) a. There was no flight scheduled to Loja yesterday ______,4 Datasets,[0],[0]
"instead there were several to Cuenca.
b.",4 Datasets,[0],[0]
There were too few flights scheduled to Loja yesterday ______,4 Datasets,[0],[0]
"instead we went to Cuenca.
4.4",4 Datasets,[0],[0]
"After all Dataset In (Rohde et al., 2017), we reported a BECAUSE∼BUT response split for passages containing after all.",4 Datasets,[0],[0]
"We speculated that this may be because a passage such as (14) below presents an argument in which the second segment serves as a REASON (hence, BECAUSE) for the first segment, but also serves to CONTRAST with it (hence, BUT).",4 Datasets,[0],[0]
(14),4 Datasets,[0],[0]
"Yes, I suppose there’s a certain element of danger in it
______",4 Datasets,[0],[0]
"(after all) there’s a certain amount of danger in living, whatever you do.
",4 Datasets,[0],[0]
"We hypothesize that the BECAUSE∼BUT split cannot be a consequence of the adverbial after all, which the Cambridge Dictionary indicates is “used to add information that shows that what you have just said is true”.1 If REASON and/or CONTRAST
1https://dictionary.cambridge.org/us/dictionary/ english/after-all
are being conveyed, it can’t be a consequence of after all.",4 Datasets,[0],[0]
"As such, this response split must depend on the reasoning that supports the inference of coherence between the two segments, separate from the adverbial itself.
",4 Datasets,[0],[0]
We test the hypothesis that the response split is independent of the presence or absence of after all.,4 Datasets,[0],[0]
"Starting with 16 passages that originally contained after all, we created a variant of each passage without the adverbial.",4 Datasets,[0],[0]
The conjunction insertion task was the same as with the other datasets.,4 Datasets,[0],[0]
"5.1 In other words: Inference and adjacency
Section 4.1 lays out the joint hypotheses that inferred relations in passages with in other words reflect two components of the lexical semantics of the adverbial (leading to the OR∼SO split) and that the presence of intervening material before in other words reduces the availability of those relations, favoring BUT instead.
",5 Results,[0.9999999806084806],"['5.1 In other words: Inference and adjacency Section 4.1 lays out the joint hypotheses that inferred relations in passages with in other words reflect two components of the lexical semantics of the adverbial (leading to the OR∼SO split) and that the presence of intervening material before in other words reduces the availability of those relations, favoring BUT instead.']"
"Figure 4 shows the predicted pattern: The no-intervening-content condition primarily yields OR/SO responses (with variation across passages on the OR-vs.-SO preference) with a relative increase in BUT responses in the intervening-content condition.2 Passage B corresponds to the pair of examples (2)/(6), and passage C reflects (7)/(8).
",5 Results,[0],[0]
"For the analysis here and in Section 5.3, a relevant first-choice conjunction was chosen and the binary outcome of its insertion was modeled with a mixed-effect logistic regression.",5 Results,[0],[0]
"Here, the insertion of OR indeed varied with the presence/absence of intervening material (β = −1.569, p < 0.005).
",5 Results,[0],[0]
"We posit that increases in BUT associated with the intervening content indicate either an interruption of the meta-linguistic tangent or an intention to signal a contrast with the negative affect of the
2For Passage P in Figure 4, participants may have linked the in other words clause to the intervening material itself.
",5 Results,[0],[0]
"tangent itself (e.g., “I don’t know where. . .",5 Results,[0],[0]
"”, “frustrating way of putting it”, “how this is measured is unclear”).",5 Results,[0],[0]
"We speculate that the presence of BECAUSE in passages with intervening content may arise when that content implies that the situation is somehow surprising, which in turn merits explanation (e.g., “it’s an UNUSUAL role for her”, “their ability to actually work sensitively is perhaps QUESTIONABLE”, “it’s STRANGE to think of a planet being born”).",5 Results,[0],[0]
"These hypotheses will themselves need to be tested.
",5 Results,[0],[0]
"5.2 Otherwise: Inference from semantic features of segments
As noted in Section 4.2, passages containing otherwise were used to test how semantic properties of the segments themselves influenced conjunction choice.",5 Results,[0],[0]
"The categorization of passages by the researchers (16 ARGUMENTATION, 16 EXCEPTION, 16 ENUMERATION) predicts the conjunctions chosen by participants.",5 Results,[0],[0]
"In aggregate, ≈99% of responses to ARGUMENTATION passages were BECAUSE or OR or both.",5 Results,[0],[0]
"≈92% of responses to EXCEPTION passages were BUT, AND, or both BUT and AND.",5 Results,[0],[0]
"And ≈98% of responses to ENUMERATION passages were BUT, AND, OR, or some subset thereof.",5 Results,[0],[0]
"For analysis, a mixed-effect logistic regression modeled the binary outcome of BUT insertion and showed significant variation across the three categories (p < 0.001).",5 Results,[0],[0]
This measure captures the difference between pairs of categories: ARGUMENTATION permits BECAUSE and OR (hence BUT is rare) while ENUMERATION permits BUT and OR (hence BUT is present) and EXCEPTION favors BUT (hence BUT is very frequent).,5 Results,[0],[0]
"All pairwise comparisons yielded a main effect of category on this dependent measure (p’s < 0.001).
",5 Results,[0],[0]
"Turning to individual passages, participant choices are shown in Figures 5–7.",5 Results,[0],[0]
"For ARGUMENTATION (Figure 5), the effect is uniformly strong, with all passages showing BECAUSE or OR as
participants’ top choice, with OR or BECAUSE chosen as equivalent (shown in the columns labelled “second”).",5 Results,[0],[0]
"For EXCEPTION (Figure 6), BUT is consistently the participants’ top choice.
",5 Results,[0],[0]
"There are a few deviations from this near uniform endorsement of BUT for EXCEPTION (Figure 6, passages L–P).",5 Results,[0],[0]
"Any hypotheses, however, would require further experimentation to test.",5 Results,[0],[0]
"For example, in passage M (see (15)) and P (see (16)), participants rarely identified any conjunction as conveying the same sense as BUT.",5 Results,[0],[0]
"However, when their top choice was BECAUSE, they also selected OR as conveying the same sense.",5 Results,[0],[0]
"As noted above, BECAUSE and OR predominate with otherwise used in ARGUMENTATION.",5 Results,[0],[0]
"This raises the question of why passages M and P lead some participants to infer ARGUMENTATION and other participants, either EXCEPTION or ENUMERATION.
(15) Democrats insist that the poor should be the priority, and that tax relief should be directed at them _____",5 Results,[0],[0]
"otherwise they lack a cogent vision of the needs of a new economy.
",5 Results,[0],[0]
(16) He said that the proposed bill would give states more flexibility in deciding whether they wanted to use the Federal money for outright grants to municipalities or to set up loan programs _____,5 Results,[0],[0]
"otherwise it left last fall’s Congressional legislation unchanged.
",5 Results,[0],[0]
"Finally, though the pattern for ENUMERATION (Figure 7) is harder to see, combinations of BUT, OR and AND predominate as participants’ top choices, with a few tokens of BECAUSE and SO, but too few to analyse as anything but noise.
",5 Results,[0],[0]
The above results reflect researcher-assigned use labels.,5 Results,[0],[0]
"However, the confusion matrix in Table 1 shows that on the whole, participants agree with
that assignment.",5 Results,[0],[0]
The column labelled Multiple is for cases where participants offered two paraphrases.,5 Results,[0],[0]
"For ARGUMENTATION, at least one paraphrase always corresponded to EXCEPTION, while for ENUMERATION, it did so for most of these tokens (9/14).",5 Results,[1.0],"['For ARGUMENTATION, at least one paraphrase always corresponded to EXCEPTION, while for ENUMERATION, it did so for most of these tokens (9/14).']"
"We comment on this below.
",5 Results,[0],[0]
"While there was less agreement when participants offered multiple paraphrases for researcherassigned EXCEPTION, there may be too few tokens here to draw any kind of conclusion.",5 Results,[1.0],"['While there was less agreement when participants offered multiple paraphrases for researcherassigned EXCEPTION, there may be too few tokens here to draw any kind of conclusion.']"
"In any case, the results for ARGUMENTATION and ENUMERATION agree both across participants (in what paraphrase they choose when they don’t choose the researcher-assigned label) and within participants (in what pairs of paraphrases they gave for the original passage).
",5 Results,[0],[0]
"The above results support our hypothesis that variability in participants’ choice of conjunctions follows from both the lexical semantics of otherwise and the relation that participants infer between the segments in the passage.
5.3 Instead: Inference from a single manipulated property
On aggregate, participants responded very differently to the parallel and causal variants of instead passages (cf. Section 4.3).",5 Results,[0],[0]
"Figure 8 shows that in all cases, the parallel variant yielded more BUT responses, whereas the non-parallel (causal) variant yielded significantly more SO responses (main effect of (non-)parallelism: β=−7.0008, p<0.001).3
Some of these results are very strong.",5 Results,[0],[0]
"For example, Passage A (17) drew all BUT responses for the
3We analyzed only 15 passages for instead and after all, due to a presentation error of the 16th for these adverbials.
parallel variant in (17a) and all SO responses for the causal variant in (17b), as did Passage B.",5 Results,[0],[0]
"In a few cases, however, the parallel variant drew variable responses, even while its causal variant drew strong SO responses.",5 Results,[0],[0]
"This is true of Passage O, with parallel and causal variants in (18a–b).
",5 Results,[0],[0]
(17) a. They could have been playing football in the village green _____,5 Results,[0],[0]
"instead they played in the street.
",5 Results,[0],[0]
b.,5 Results,[0],[0]
They didn’t like playing football in the village green _____,5 Results,[0],[0]
"instead they played in the street.
",5 Results,[0],[0]
(18) a. Smugglers nowadays don’t use overland passages _____,5 Results,[0],[0]
"instead they use the seas to transport their goods.
",5 Results,[0],[0]
b. Smugglers’ overland passages nowadays are too visible _____,5 Results,[0],[0]
"instead they use the seas to transport their goods.
",5 Results,[0],[0]
"One possible explanation is that participants varied in the role they assigned to the positive claim in the second segment of (18a) – either as a reason for the negative claim in the first segment (BECAUSE), as a contrast with that claim (BUT), or as its result (SO).",5 Results,[0],[0]
"Although manipulating the segment to enhance either parallelism or causality can change participant responses, it is clear that parallelism alone doesn’t guarantee contrast.
",5 Results,[0],[0]
5.4 After all: Adverb adds little to inference Figure 9 shows participant choice of conjunction when after all is present and when it is absent.,5 Results,[0],[0]
"Their choice is largely the same for passages A–F and K–N, with and without the adverbial.",5 Results,[0],[0]
"As for passage O, since AND can contingently substitute for BUT (Knott, 1996), the response pattern can be considered the same as well.",5 Results,[0],[0]
"A by-passage correlation between the rate of BUT and BECAUSE responses across the two conditions confirms this similarity (R2=.70, F(1,13)=30.98, p<0.001).",5 Results,[0],[0]
"The outlier is passage G: (19) There was a testy moment driving over the George Wash-
ington Bridge when the toll-taker charged him $24 for his truck and trailer _____",5 Results,[0],[0]
"after all it was New York.
",5 Results,[0],[0]
"With after all, the majority of participants chose BUT as best expressing how the two segments are connected, while without it, the majority chose BECAUSE.",5 Results,[0],[0]
Whatever explanation we gave here would be pure speculation.,5 Results,[0],[0]
We trust that the fact that the other 14 passages demonstrate the predicted effect provides sufficient evidence that splits in participant responses are not simply a result of the presence of a discourse adverbial.,5 Results,[1.0],['We trust that the fact that the other 14 passages demonstrate the predicted effect provides sufficient evidence that splits in participant responses are not simply a result of the presence of a discourse adverbial.']
"While our previous work showed that multiple discourse relations can hold between two segments – relations at the same semantic level, simultaneously available to a reader – we provided no evidence as to what influences the particular relations that are taken to be available.",6 Conclusion,[0],[0]
Our current experiments have provided some such evidence.,6 Conclusion,[0],[0]
"Specifically, we have shown that participant responses to systematically manipulated passages involving discourse adverbials can be explained in terms of both the lexical semantics of discourse adverbials and properties of the passages that contain them.",6 Conclusion,[1.0],"['Specifically, we have shown that participant responses to systematically manipulated passages involving discourse adverbials can be explained in terms of both the lexical semantics of discourse adverbials and properties of the passages that contain them.']"
"As the conjunctions chosen by participants convey senses that differ from those of the discourse adverbials, we also provided evidence for the simultaneous availability of multiple coherence relations that arise from both explicit signals and inference.",6 Conclusion,[1.0],"['As the conjunctions chosen by participants convey senses that differ from those of the discourse adverbials, we also provided evidence for the simultaneous availability of multiple coherence relations that arise from both explicit signals and inference.']"
"We hope the reader is now convinced that, in both psycholinguistic research on discourse coherence and computational work on discourse parsing, one needs to identify and examine evidence for coherence involving more than one discourse relation.",6 Conclusion,[1.0],"['We hope the reader is now convinced that, in both psycholinguistic research on discourse coherence and computational work on discourse parsing, one needs to identify and examine evidence for coherence involving more than one discourse relation.']"
This project has been supported by a grant from the Nuance Foundation.,Acknowledgments,[0],[0]
"In addition, a Leverhulme Trust Prize in Languages & Literatures to H. Rohde has enabled her to devote more time to research.",Acknowledgments,[0],[0]
We thank Amir Zeldes and the anonymous reviewers for their helpful feedback on the paper.,Acknowledgments,[0],[0]
Theories of discourse coherence posit relations between discourse segments as a key feature of coherent text.,abstractText,[0],[0]
Our prior work suggests that multiple discourse relations can be simultaneously operative between two segments for reasons not predicted by the literature.,abstractText,[0],[0]
"Here we test how this joint presence can lead participants to endorse seemingly divergent conjunctions (e.g., but and so) to express the link they see between two segments.",abstractText,[0],[0]
"These apparent divergences are not symptomatic of participant naïveté or bias, but arise reliably from the concurrent availability of multiple relations between segments – some available through explicit signals and some via inference.",abstractText,[0],[0]
We believe that these new results can both inform future progress in theoretical work on discourse coherence and lead to higher levels of performance in discourse parsing.,abstractText,[0],[0]
Discourse Coherence: Concurrent Explicit and Implicit Relations,title,[0],[0]

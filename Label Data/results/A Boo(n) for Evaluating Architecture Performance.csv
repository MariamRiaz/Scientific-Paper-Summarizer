0,1,label2,summary_sentences
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2094–2099, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Neural network translation models, which learn mappings over real-valued vector representations in high-dimensional space, have recently achieved large gains in translation accuracy (Hu et al., 2014; Devlin et al., 2014; Sundermeyer et al., 2014; Auli et al., 2013; Schwenk, 2012; Sutskever et al., 2014; Bahdanau et al., 2015).
",1 Introduction,[0],[0]
"Notably, Devlin et al. (2014) proposed a neural network joint model (NNJM), which augments the n-gram neural network language model (NNLM) with an m-word source context window, as shown in Figure 1a.",1 Introduction,[0],[0]
"While this model is effective, the computation cost of using it in a large-vocabulary SMT task is quite expensive, as probabilities need to be normalized over the entire vocabulary.",1 Introduction,[0],[0]
"To solve this problem, Devlin et al. (2014) presented a technique to train the NNJM to be selfnormalized and avoided the expensive normalization cost during decoding.",1 Introduction,[0],[0]
"However, they also
note that this self-normalization technique sacrifices neural network accuracy, and the training process for the self-normalized neural network is very slow, as with standard maximum likelihood estimation (MLE).
",1 Introduction,[0],[0]
"To remedy the problem of long training times in the context of NNLMs, Vaswani et al. (2013) used a method called noise contrastive estimation (NCE).",1 Introduction,[0],[0]
"Compared with MLE, NCE does not require repeated summations over the whole vocabulary and performs nonlinear logistic regression to discriminate between the observed data and artificially generated noise.
",1 Introduction,[0],[0]
"This paper proposes an alternative framework of binarized NNJMs (BNNJM), which are similar to the NNJM, but use the current target word not as the output, but as the input of the neural network, estimating whether the target word under examination is correct or not, as shown in Figure 1b.",1 Introduction,[0],[0]
"Because the BNNJM uses the current target word as input, the information about the current target word can be combined with the context word information and processed in the hidden layers.
",1 Introduction,[0],[0]
"The BNNJM learns a simple binary classifier, given the context and target words, therefore it can be trained by MLE very efficiently.",1 Introduction,[0],[0]
"“Incorrect” target words for the BNNJM can be generated in the same way as NCE generates noise
2094
for the NNJM.",1 Introduction,[0],[0]
We present a novel noise distribution based on translation probabilities to train the NNJM and the BNNJM efficiently.,1 Introduction,[0],[0]
Let T = t|T |1 be a translation of S = s |S| 1 .,2 Neural Network Joint Model,[0],[0]
"The NNJM (Devlin et al., 2014) defines the following probability,
P (T |S) = ∏|T | i=1",2 Neural Network Joint Model,[0],[0]
"P ( ti|sai+(m−1)/2ai−(m−1)/2, t i−1 i−n+1 ) (1) where target word ti is affiliated with source word sai .",2 Neural Network Joint Model,[0],[0]
Affiliation ai is derived from the word alignments using heuristics1.,2 Neural Network Joint Model,[0],[0]
"To estimate these probabilities, the NNJM uses m source context words and n− 1 target history words as input to a neural network and performs estimation of unnormalized probabilities p (ti|C) before normalizing over all words in the target vocabulary V ,
P (ti|C) = p(ti|C)Z(C) Z (C) = ∑ ti′∈V p (ti′|C) (2)
where C stands for source and target context words as in Equation 1.
",2 Neural Network Joint Model,[0],[0]
"The NNJM can be trained on a word-aligned parallel corpus using standard MLE, but the cost of normalizing over the entire vocabulary to calculate the denominator in Equation 2 is quite large.",2 Neural Network Joint Model,[0],[0]
"Devlin et al. (2014)’s self-normalization technique can avoid normalization cost during decoding, but not during training.
",2 Neural Network Joint Model,[0],[0]
"NCE can be used to train NNLM-style models (Vaswani et al., 2013) to reduce training times.",2 Neural Network Joint Model,[0],[0]
NCE creates a noise distribution q,2 Neural Network Joint Model,[0],[0]
"(ti), selects k noise samples ti1, ..., tik for each ti and introduces a random variable v which is 1 for training examples and 0 for noise samples,
P (v = 1, ti|C)",2 Neural Network Joint Model,[0],[0]
"= 11+k · p(ti|C)Z(C) P (v = 0, ti|C) =",2 Neural Network Joint Model,[0],[0]
"k1+k · q (ti) .
",2 Neural Network Joint Model,[0],[0]
"NCE trains the model to distinguish training data from noise by maximize the conditional likelihood,
L = log P (v = 1|C, ti) + k∑
j=1
log P (v = 0|C, tik).
",2 Neural Network Joint Model,[0],[0]
"The normalization cost can be avoided by using p (ti|C) as an approximation of P (ti|C).2
1If ti aligns to exactly one source word, ai is the index of this source word; If ti aligns to multiple source words, ai is the index of the aligned word in the middle; If ti is unaligned, they inherit its affiliation from the closest aligned word.
",2 Neural Network Joint Model,[0],[0]
"2The theoretical properties of self-normalization techniques, including NCE and Devlin et al. (2014)’s method, are investigated by Andreas and Klein (2015).",2 Neural Network Joint Model,[0],[0]
"In this paper, we propose a new framework of the binarized NNJM (BNNJM), which is similar to the NNJM but learns not to predict the next word given the context, but solves a binary classification problem by adding a variable v ∈ {0, 1} that stands for whether the current target word ti is correctly/wrongly produced in terms of source context words sai+(m−1)/2ai−(m−1)/2 and target history words ti−1i−n+1 ,
P ( v|sai+(m−1)/2ai−(m−1)/2, t i−1 i−n+1, ti ) .
",3 Binarized NNJM,[0],[0]
"The BNNJM is learned by a feedforward neural network with m + n inputs{ s ai+(m−1)/2 ai−(m−1)/2, t i−1 i−n+1, ti } and two outputs for v = 1/0.",3 Binarized NNJM,[0],[0]
"Because the BNNJM uses the current target word as input, the information about the current target word can be combined with the context word information and processed in the hidden layers.",3 Binarized NNJM,[0],[0]
"Thus, the hidden layers can be used to learn the difference between correct target words and noise in the BNNJM, while in the NNJM the hidden layers just contain information about context words and only the output layer can be used to discriminate between the training data and noise, giving the BNNJM more power to learn this classification problem.
",3 Binarized NNJM,[0],[0]
"We can use the BNNJM probability in translation as an approximation for the NNJM as below,
P ( ti|sai+(m−1)/2ai−(m−1)/2, t i−1 i−n+1 )",3 Binarized NNJM,[0],[0]
"≈ P ( v = 1|sai+(m−1)/2ai−(m−1)/2, t i−1 i−n+1, ti ) .
",3 Binarized NNJM,[0],[0]
"As a binary classifier, the gradient for a single example in the BNNJM can be calculated efficiently by MLE without it being necessary to calculate the softmax over the full vocabulary.",3 Binarized NNJM,[0],[0]
"On the other hand, we need to create “positive” and “negative” examples for the classifier.",3 Binarized NNJM,[0],[0]
"Positive examples can be extracted directly from the word-aligned parallel corpus as〈 s ai+(m−1)/2 ai−(m−1)/2, t i−1 i−n+1, ti 〉 ; Negative examples can be generated for each positive example in the same way that NCE generates noise data as〈 s ai+(m−1)/2 ai−(m−1)/2, t i−1 i−n+1, ti ′ 〉 , where ti′ ∈ V \ {ti}.",3 Binarized NNJM,[0],[0]
"Vaswani et al. (2013) adopted the unigram probability distribution (UPD) to sample noise for train-
ing NNLMs with NCE,
q (ti′) = occur(ti ′)∑ ti ′′∈V occur(ti′′)
where occur (ti′) stands for how many times ti′ occurs in the training corpus.",4.1 Unigram Noise,[0],[0]
"In this paper, we propose a noise distribution specialized for translation models, such as the NNJM or BNNJM.
",4.2 Translation Model Noise,[0],[0]
Figure 2 gives a Chinese-to-English parallel sentence pair with word alignments to demonstrate the intuition behind our method.,4.2 Translation Model Noise,[0],[0]
"Focusing on sai=“安排”, this is translated into ti =“arrange”.",4.2 Translation Model Noise,[0],[0]
"For this positive example, UPD is allowed to sample any arbitrary noise, such as ti′ = “banana”.",4.2 Translation Model Noise,[0],[0]
"However, in this case, noise ti′ = “banana” is not useful for model training, as constraints on possible translations given by the phrase table ensure that “安排” will never be translated into “banana”.",4.2 Translation Model Noise,[0],[0]
"On the other hand, noise ti′ = “arranges” and “arrangement” are both possible translations of “安排” and therefore useful training data, that we would like our model to penalize.
",4.2 Translation Model Noise,[0],[0]
"Based on this intuition, we propose the use of another noise distribution that only uses ti′ that are possible translations of sai , i.e., ti ′ ∈",4.2 Translation Model Noise,[0],[0]
"U (sai) \ {ti}, where U (sai) contains all target words aligned to sai in the parallel corpus.
",4.2 Translation Model Noise,[0],[0]
"Because U (sai) may be quite large and contain many wrong translations caused by wrong alignments, “banana” may actually be included in U (“安排”).",4.2 Translation Model Noise,[0],[0]
"To mitigate the effect of uncommon examples, we use a translation probability distribution (TPD) to sample noise ti′ from U (sai)",4.2 Translation Model Noise,[0],[0]
\,4.2 Translation Model Noise,[0],[0]
"{ti} as follows,
q (ti′|sai) = align(sai ,ti′)∑
ti ′′∈U(sai )
align(sai ,ti′′)
where align (sai , ti ′) is how many times ti′ is aligned to sai in the parallel corpus.",4.2 Translation Model Noise,[0],[0]
"Note that ti could be unaligned, in which case we assume that it is aligned to a special null word.",4.2 Translation Model Noise,[0],[0]
Noise for unaligned words is sampled according to the TPD of the null word.,4.2 Translation Model Noise,[0],[0]
"If several target/source words are aligned to one source/target word, we
choose to combine these target/source words as a new target/source word.3",4.2 Translation Model Noise,[0],[0]
"We evaluated the effectiveness of the proposed approach for Chinese-to-English (CE), Japanese-toEnglish (JE) and French-to-English (FE) translation tasks.",5.1 Setting,[0],[0]
"The datasets officially provided for the patent machine translation task at NTCIR-9 (Goto et al., 2011) were used for the CE and JE tasks.",5.1 Setting,[0],[0]
The development and test sets were both provided for the CE task while only the test set was provided for the JE task.,5.1 Setting,[0],[0]
"Therefore, we used the sentences from the NTCIR-8 JE test set as the development set.",5.1 Setting,[0],[0]
"Word segmentation was done by BaseSeg (Zhao et al., 2006) for Chinese and Mecab4 for Japanese.",5.1 Setting,[0],[0]
"For the FE language pair, we used standard data for the WMT 2014 translation task.",5.1 Setting,[0],[0]
"The training sets for CE, JE and FE tasks contain 1M, 3M and 2M sentence pairs, respectively.
",5.1 Setting,[0],[0]
"For each translation task, a recent version of Moses HPB decoder (Koehn et al., 2007) with the training scripts was used as the baseline (Base).",5.1 Setting,[0],[0]
"We used the default parameters for Moses, and a 5-gram language model was trained on the target side of the training corpus using the IRSTLM Toolkit5 with improved Kneser-Ney smoothing.",5.1 Setting,[0],[0]
"Feature weights were tuned by MERT (Och, 2003).
",5.1 Setting,[0],[0]
"The word-aligned training set was used to learn the NNJM and the BNNJM.6 For both NNJM and BNNJM, we set m = 7 and n = 5.",5.1 Setting,[0],[0]
The NNJM was trained by NCE using UPD and TPD as noise distributions.,5.1 Setting,[0],[0]
"The BNNJM was trained by standard MLE using UPD and TPD to generate negative examples.
",5.1 Setting,[0],[0]
The number of noise samples for NCE was set to be 100.,5.1 Setting,[0],[0]
"For the BNNJM, we used only one negative example for each positive example in each training epoch, as the BNNJM needs to calculate
3The processing for multiple alignments helps sample more useful negative examples for TPD, and had little effect on the translation performance when UPD was used as the noise distribution for the NNJM and the BNNJM in our preliminary experiments.
",5.1 Setting,[0],[0]
"4http://sourceforge.net/projects/mecab/files/ 5http://hlt.fbk.eu/en/irstlm 6Both the NNJM and the BNNJM had one hidden layer, 100 hidden nodes, input embedding dimension 50, output embedding dimension 50.",5.1 Setting,[0],[0]
A small set of training data was used as validation data.,5.1 Setting,[0],[0]
"The training process was stopped when validation likelihood stopped increasing.
",5.1 Setting,[0],[0]
the whole neural network (not just the output layer like the NNJM) for each noise sample and thus noise computation is more expensive.,5.1 Setting,[0],[0]
"However, for different epochs, we resampled the negative example for each positive example, so the BNNJM can make use of different negative examples.",5.1 Setting,[0],[0]
"Table 1 shows how many epochs these two models needed and the training time for each epoch on a 10-core 3.47GHz Xeon X5690 machine.7 Translation results are shown in Table 2.
",5.2 Results and Discussion,[0],[0]
"We can see that using TPD instead of UPD as a noise distribution for the NNJM trained by NCE can speed up the training process significantly, with a small improvement in performance.",5.2 Results and Discussion,[0],[0]
"But for the BNNJM, using different noise distributions affects translation performance significantly.",5.2 Results and Discussion,[0],[0]
"The BNNJM with UPD does not improve over the baseline system, likely due to the small number of noise samples used in training the BNNJM, while the BNNJM with TPD achieves good performance, even better than the NNJM with TPD on the Chinese-to-English and French-to-English translation tasks.
",5.2 Results and Discussion,[0],[0]
"From Table 2, the NNJM does not improve translation performance significantly on the FE task.",5.2 Results and Discussion,[0],[0]
"Note that the baseline BLEU for the FE
7The decoding time for the NNJM and the BNNJM were similar, since the NNJM trained by NCE uses p (ti|C) as an approximation of P (ti|C) without normalization and the BNNJM only needs to be normalized over two output neurons.
task is lower than CE and JE tasks, indicating that learning is harder for the FE task than CE and JE tasks.",5.2 Results and Discussion,[0],[0]
"The validation perplexities of the NNJM with UPD for CE, JE and FE tasks are 4.03, 3.49 and 8.37.",5.2 Results and Discussion,[0],[0]
"Despite these difficult learning circumstances and lack of large gains for the NNJM, the BNNJM improves translations significantly for the FE task, suggesting that the BNNJM is more robust to difficult translation tasks that are hard for the NNJM.
",5.2 Results and Discussion,[0],[0]
Table 3 gives Chinese-to-English translation examples to demonstrate how the BNNJM (with TPD) helps to improve translations over the NNJM (with TPD).,5.2 Results and Discussion,[0],[0]
"In this case, the BNNJM helps to translate the phrase “该 移动 持续 到” better.",5.2 Results and Discussion,[0],[0]
Table 4 gives translation scores for these two translations calculated by the NNJM and the BNNJM.,5.2 Results and Discussion,[0],[0]
"Context words are used for predictions but not shown in the table.
",5.2 Results and Discussion,[0],[0]
"As can be seen, the BNNJM prefers T2 while the NNJM prefers T1.",5.2 Results and Discussion,[0],[0]
"Among these predictions, the NNJM and the BNNJM predict the translation for “到” most differently.",5.2 Results and Discussion,[0],[0]
"The NNJM clearly predicts that in this case “到” should be translated into “to” more than “until”, likely because this example rarely occurs in the training corpus.",5.2 Results and Discussion,[0],[0]
"However, the BNNJM prefers “until” more than “to”, which
demonstrates the BNNJM’s robustness to less frequent examples.",5.2 Results and Discussion,[0],[0]
"Finally, we examine the translation results to explore why the BNNJM with TPD did not outperform the NNJM with TPD for the JE translation task, as it did for the other translation tasks.",5.3 Analysis for JE Translation Results,[0],[0]
"We found that using the BNNJM instead of the NNJM on the JE task did improve translation quality significantly for infrequent words, but not for frequent words.
",5.3 Analysis for JE Translation Results,[0],[0]
"First, we describe how we estimate translation quality for infrequent words.",5.3 Analysis for JE Translation Results,[0],[0]
"Suppose we have a test set S, a reference set R and a translation set T with I sentences, Si (1 ≤",5.3 Analysis for JE Translation Results,[0],[0]
i ≤,5.3 Analysis for JE Translation Results,[0],[0]
"I) , Ri (1 ≤",5.3 Analysis for JE Translation Results,[0],[0]
i ≤,5.3 Analysis for JE Translation Results,[0],[0]
"I) , Ti (1 ≤",5.3 Analysis for JE Translation Results,[0],[0]
i ≤,5.3 Analysis for JE Translation Results,[0],[0]
I),5.3 Analysis for JE Translation Results,[0],[0]
"Ti contains J individual words, Wij ∈Words (Ti) To (Wij) is how many times Wij occurs in Ti and Ro (Wij) is how many times Wij occurs in Ri.
",5.3 Analysis for JE Translation Results,[0],[0]
"The general 1-gram translation accuracy (Papineni et al., 2002) is calculated as,
Pg =
I∑ i=1 J∑ j=1 min(To(Wij),Ro(Wij))
I∑ i=1 J∑ j=1 To(Wij)
",5.3 Analysis for JE Translation Results,[0],[0]
"This general 1-gram translation accuracy does not distinguish word frequency.
",5.3 Analysis for JE Translation Results,[0],[0]
"We use a modified 1-gram translation accuracy that weights infrequent words more heavily,
Pc =
I∑ i=1 J∑ j=1 min(To(Wij),Ro(Wij))· 1 Occur(Wij)
I∑ i=1 J∑ j=1 To(Wij)
where Occur (Wij) is how many times Wij occurs in the whole reference set.",5.3 Analysis for JE Translation Results,[0],[0]
"Note Pc will not be 1 even in the case of completely accurate translations, but it can approximately reflect infrequent word translation accuracy, since correct frequent word translations contribute less to Pc.
Table 5 shows Pg and Pc for different translation tasks.",5.3 Analysis for JE Translation Results,[0],[0]
"It can be seen that the BNNJM improves infrequent word translation quality similarly for all translation tasks, but improves general translation quality less for the JE task than the other translation tasks.",5.3 Analysis for JE Translation Results,[0],[0]
"We conjecture that the reason why the BNNJM is less useful for frequent word translations on the JE task is the fact that the JE parallel corpus has less accurate function word alignments than other language pairs, as the
grammatical features of Japanese and English are quite different.8 Wrong function word alignments will make noise sampling less effective and therefore lower the BNNJM performance for function word translations.",5.3 Analysis for JE Translation Results,[0],[0]
"Although wrong word alignments will also make noise sampling less effective for the NNJM, the BNNJM only uses one noise sample for each positive example, so wrong word alignments affect the BNNJM more than the NNJM.",5.3 Analysis for JE Translation Results,[0],[0]
Xu et al. (2011) proposed a method to use binary classifiers to learn NNLMs.,6 Related Work,[0],[0]
"But they also used the current target word in the output, similarly to NCE.",6 Related Work,[0],[0]
"The BNNJM uses the current target word as input, so the information about the current target word can be combined with the context word information and processed in hidden layers.
",6 Related Work,[0],[0]
Mauser et al. (2009) presented discriminative lexicon models to predict target words.,6 Related Work,[0],[0]
"They train a separate classifier for each target word, as these lexicon models use discrete representations of words and different classifiers do not share features.",6 Related Work,[0],[0]
"In contrast, the BNNJM uses real-valued vector representations of words and shares features, so we train one classifier and can use the similarity information between words.",6 Related Work,[0],[0]
"This paper proposes an alternative to the NNJM, the BNNJM, which learns a binary classifier that takes both the context and target words as input and combines all useful information in the hidden layers.",7 Conclusion,[0],[0]
We also present a novel noise distribution based on translation probabilities to train the BNNJM efficiently.,7 Conclusion,[0],[0]
"With the improved noise sampling method, the BNNJM can achieve comparable performance with the NNJM and even improve the translation results over the NNJM on Chineseto-English and French-to-English translations.
",7 Conclusion,[0],[0]
8Infrequent words are usually content words and frequent words are usually function words.,7 Conclusion,[0],[0]
"The neural network joint model (NNJM), which augments the neural network language model (NNLM) with an m-word source context window, has achieved large gains in machine translation accuracy, but also has problems with high normalization cost when using large vocabularies.",abstractText,[0],[0]
"Training the NNJM with noise-contrastive estimation (NCE), instead of standard maximum likelihood estimation (MLE), can reduce computation cost.",abstractText,[0],[0]
"In this paper, we propose an alternative to NCE, the binarized NNJM (BNNJM), which learns a binary classifier that takes both the context and target words as input, and can be efficiently trained using MLE.",abstractText,[0],[0]
We compare the BNNJM and NNJM trained by NCE on various translation tasks.,abstractText,[0],[0]
A Binarized Neural Network Joint Model for Machine Translation,title,[0],[0]
"We are interested in time series settings where we observe data {Yt ∈ Y : t = 1, . . .",1. Introduction - Problem Statement,[0],[0]
", L}.",1. Introduction - Problem Statement,[0],[0]
We consider problems where the observations are explained by a latent structure which assigns objects to features and this feature allocation changes over time.,1. Introduction - Problem Statement,[0],[0]
"For instance, consider the topics covered by a number of newspapers over time; some topics “die” while new ones are “born”.",1. Introduction - Problem Statement,[0],[0]
"The topic coverage of each paper is its latent feature allocation which could be modelled with an Indian buffet process (Griffiths & Ghahramani, 2011, IBP).",1. Introduction - Problem Statement,[0],[0]
"While static feature allocation models are well studied, these are not able to handle the time series nature of many datasets.",1. Introduction - Problem Statement,[0],[0]
"We propose a process that extends the IBP by allowing the feature allocation to evolve over the covariate as a result of “birth” and “death” of features.
1University of Oxford, Oxford, UK 2Stanford University, California, USA 3University of Cambridge, Cambridge, UK 4Uber AI Labs, SF, California, USA.",1. Introduction - Problem Statement,[0],[0]
"Correspondence to: Konstantina Palla <konstantina.palla@gmail.com>.
",1. Introduction - Problem Statement,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction - Problem Statement,[0],[0]
Copyright 2017 by the author(s).,1. Introduction - Problem Statement,[0],[0]
"We target problems where the data depends on a covariate, such as time or space, and is explained by a latent structure, in particular a (multi-membership) clustering of the data points.",2. Related Work,[0],[0]
The observations are result of the underlying partitioning and its evolution over the covariate.,2. Related Work,[0],[0]
Typical models fall in two main categories: clustering and feature allocation.,2. Related Work,[0],[0]
"The former allow each data point to belong to one and only one class (cluster), while the latter let each data point belong to multiple groups (features).",2. Related Work,[0],[0]
"Bayesian nonparametric approaches are primarily based on the Chinese restaurant process (CRP, Aldous, 1983) or the Indian buffet process (IBP, Griffiths & Ghahramani, 2005) corresponding to the two categories.",2. Related Work,[0],[0]
"In particular, a sample from a CRP is an assignment of data points to disjoint classes (a clustering), while a sample from an IBP is an allocation of the data points to (possibly) overlapping classes (a feature allocation).",2. Related Work,[0],[0]
"Dependent nonparametric processes extend distributions over partitions to distributions over collections of partitions indexed by locations in some covariate space, such as R+ (e.g. continuous time), Z (e.g. discrete time), or Rd (e.g. geographical location).",2. Related Work,[0],[0]
"Teh et al. (2013) define such a process based on the duality between Kingman’s coalescent (Kingman, 1982) and the Dirichlet diffusion tree (Neal, 2003).",2. Related Work,[0],[0]
In the resulting “Fragmentation-Coagulation” process (FCP) a partitioning of the data points evolves over the covariate undergoing fragmentation and coagulation events while maintaining CRP marginals.,2. Related Work,[0],[0]
"More recently, Palla et al. (2013) derived a dependent partition-valued process (DPVP) on an arbitrary covariate space which, like the FCP, is exchangeable and has CRP distributed marginals.",2. Related Work,[0],[0]
"In the setting of feature allocations, Williamson et al. (2010) propose a nonparametric process, the dependent IBP (dIBP), with IBP distributed marginals and in which the feature allocations are coupled over the covariate space using a Gaussian process (GP, Rasmussen & Williams, 2006).",2. Related Work,[0],[0]
"In a similar vein, Van Gael et al. (iFHMM, 2009) define the Markov Indian Buffet process (mIBP), a probability distribution over a potentially infinite number of binary Markov chains evolving in discrete time.",2. Related Work,[0],[0]
"They use the mIBP to extend the factorial hidden Markov model (FHMM, Ghahramani & Jordan, 1997) to the infinite FHMM (iFHMM).
",2. Related Work,[0],[0]
"In this paper, we address the problem of dependence for
binary latent feature models.",2. Related Work,[0],[0]
"We propose a process that extends the IBP by allowing features to be “born” and “die” at times learnt by the model, while maintaining the essential mathematical properties of the IBP.",2. Related Work,[0],[0]
The process is a Markov Jump process (MJP) where the events are the birth or the death of a feature.,2. Related Work,[0],[0]
The idea is closely related to the FCP where the events are either a fragmentation of a cluster or a coagulation of two clusters.,2. Related Work,[0],[0]
"The partitions at each location in the FCP are marginally a sample from a Chinese restaurant process, while the feature allocations in the BDFP are marginally samples from an IBP.",2. Related Work,[0],[0]
"Compared to the dIBP, both processes model feature allocations evolving over the covariate.",2. Related Work,[0],[0]
"However, while in the dIBP the assignment of data points to a feature might change over the covariate, in our process, it remains the same until the feature dies.",2. Related Work,[0],[0]
"In the case of the iFHMM, the authors model the dependence of a feature allocation on a discrete time variable as opposed to our process where continuous covariate space is assumed.",2. Related Work,[0],[0]
"Moreover, in the iFHMM, the marginal distribution of a feature allocation is analogous but not equal to an IBP.",2. Related Work,[0],[0]
We call the proposed process the birth-death feature allocation process (BDFP).,2. Related Work,[0],[0]
"The BDFP is exchangeable, projective, stationary and reversible, and its equilibrium distribution is given by the Indian buffet process.",2. Related Work,[0],[0]
Consider a dataset with N data points indexed by integers,3. Feature Allocations and the Indian Buffet Process,[0],[0]
"[N ] := {1, 2, . . .",3. Feature Allocations and the Indian Buffet Process,[0],[0]
", N} (allowing N → ∞).",3. Feature Allocations and the Indian Buffet Process,[0],[0]
Each datapoint n is associated with a binary vector Zn of length K that defines its feature allocation; Znk = 1 if datapoint n has feature k and Znk = 0 otherwise.,3. Feature Allocations and the Indian Buffet Process,[0],[0]
The potential total number of features K may be infinite.,3. Feature Allocations and the Indian Buffet Process,[0],[0]
The binary matrix Z[N ] =,3. Feature Allocations and the Indian Buffet Process,[0],[0]
"[ZT1 ,Z T 2 , . . .",3. Feature Allocations and the Indian Buffet Process,[0],[0]
",Z T N ]",3. Feature Allocations and the Indian Buffet Process,[0],[0]
"T specifies a random feature allocation of [N ], while ZN denotes the space of all feature allocations of [N ], i.e. Z[N ] ∈ ZN .",3. Feature Allocations and the Indian Buffet Process,[0],[0]
"We define mk as the number of datapoints that possess feature k, K+ = ∑2N−1 h=1",3. Feature Allocations and the Indian Buffet Process,[0],[0]
Kh as the number of features for which mk > 0,3. Feature Allocations and the Indian Buffet Process,[0],[0]
"and Kh as the multiplicity of feature h, that is the number of times the same binary column h appears in Z[N ].",3. Feature Allocations and the Indian Buffet Process,[0],[0]
"Under the IBP (Griffiths & Ghahramani, 2011), the probability of a matrix Z[N ] is
g([Z[N ]];α) = αK+∏H h=1Kh!",3. Feature Allocations and the Indian Buffet Process,[0],[0]
exp(−αHN ) K+∏ k=1 (N −mk)!(mk,3. Feature Allocations and the Indian Buffet Process,[0],[0]
"− 1) N !
(1)
where α > 0 is the concentration parameter, HN =∑N j=1 1 j is the N th harmonic number and H ≤ 2
N",3. Feature Allocations and the Indian Buffet Process,[0],[0]
"− 1 is the number of distinct nonzero features in the allocation.
",3. Feature Allocations and the Indian Buffet Process,[0],[0]
"Thibaux & Jordan (2007) showed one can construct the Indian buffet process from a Beta-Bernoulli process using the
following two stage sampling process for n = 1, . . .",3. Feature Allocations and the Indian Buffet Process,[0],[0]
", N :
B|c, µ0 ∼BP(c, µ0) Zn|B ∼ BeP(B) (2) where B = ∑∞",3. Feature Allocations and the Indian Buffet Process,[0],[0]
k=1 ωkδθk and Z = ∑∞,3. Feature Allocations and the Indian Buffet Process,[0],[0]
k=1 fkδθk .,3. Feature Allocations and the Indian Buffet Process,[0],[0]
"First a draw B is sampled from the Beta process BP(cµ0) (Hjort, 1990) with µ0 as the base distribution.",3. Feature Allocations and the Indian Buffet Process,[0],[0]
"B is a set of pairs (ωk, θk) sampled from a Poisson process on the product space",3. Feature Allocations and the Indian Buffet Process,[0],[0]
"[0, 1] × Θ with Lévy intensity ν(dω,dθ) = cω−1(1 − ω)c−1dωµ0(dθ).",3. Feature Allocations and the Indian Buffet Process,[0],[0]
"Then, B is used as the atomic hazard measure for a Bernoulli process BeP(B).",3. Feature Allocations and the Indian Buffet Process,[0],[0]
"Each Zn is a draw from the Bernoulli process and constitutes a collection of atoms of unit mass on Θ. Then, Zn is a binary vector containing the {fk}∞k=1 values resulting from tossing a countably infinite sequence of (conditionally independent) coins with success probabilities ωk, i.e. fk|ωk ∼ Bernoulli(ωk).",3. Feature Allocations and the Indian Buffet Process,[0],[0]
"This construction allows the use of de Finetti’s theorem (de Finetti, 1931) that lets the joint distribution of the rows to be written as
P (Z1, . . .",3. Feature Allocations and the Indian Buffet Process,[0],[0]
",ZN ) = ∫ [ N∏ n=1 P (Zn|B) ] dP",3. Feature Allocations and the Indian Buffet Process,[0],[0]
"(B) (3)
where B is the random measure that renders the variables Zn conditionally independent.",3. Feature Allocations and the Indian Buffet Process,[0],[0]
"Equation (3) shows the exchangeability of the rows of Zn, since they can be described as a mixture of Bernoulli processes.",3. Feature Allocations and the Indian Buffet Process,[0],[0]
We consider a continuous-time Markov process (Z(t))t≥0 in which each Z(t) is a random feature allocation taking values in the discrete space ZN .,4. Birth-Death Process for Feature Allocation,[0],[0]
"The state space is countably infinite; it is determined by all the possible feature allocations defined by N datapoints and K features, where K → ∞. The Markov process (Z(t)) evolves over time jumping to different states (feature allocations).",4. Birth-Death Process for Feature Allocation,[0],[0]
"Let {t1, . . .",4. Birth-Death Process for Feature Allocation,[0],[0]
", tJ ∈ R : J ∈ N} denote the times when the chain jumps such that tj = inf{τ ≥ tj−1 : Z(τ) 6= Z(tj−1)} and Z(tj) ∈ ZN .",4. Birth-Death Process for Feature Allocation,[0],[0]
These jumps are a result of a birth or a death of a feature.,4. Birth-Death Process for Feature Allocation,[0],[0]
"The process (Z(t)) can only jump to neighbouring states, i.e. if the chain is currently at state Z(tj) = s, then at time tj+1 it transitions to Z(tj+1) = s′ where a new feature is created or an existing feature is deleted after a birth or a death event respectively.",4. Birth-Death Process for Feature Allocation,[0],[0]
Let ZsN ⊂ ZN be the discrete space of neighboring states to state s.,4. Birth-Death Process for Feature Allocation,[0],[0]
The process is time homogeneous with transition probabilities P(Z(t + y) = s′|Z(y) = s) = P(Z(t) = s′|Z(0),4. Birth-Death Process for Feature Allocation,[0],[0]
"= s) = pss′(t) for all t, y, where s, s′ ∈ ZN .",4. Birth-Death Process for Feature Allocation,[0],[0]
"At time tj+1 the process jumps to the next state Z(tj+1) = s′ with rate determined by the current state Z(t) = s and the corresponding event, i.e birth or death.",4. Birth-Death Process for Feature Allocation,[0],[0]
"More specifically,
• Birth: Suppose s ∈ ZN is a feature allocation with Ks nonzero features and s′ ∈ ZsN is another feature
allocation that differs from s in having one additional feature of size |a| so that K ′s =",4. Birth-Death Process for Feature Allocation,[0],[0]
Ks + 1.,4. Birth-Death Process for Feature Allocation,[0],[0]
"We choose the transition rate from s to s′ as
qss′ =",4. Birth-Death Process for Feature Allocation,[0],[0]
"R (|a| − 1)!(N − |a|)!
N !",4. Birth-Death Process for Feature Allocation,[0],[0]
"(4)
where R > 0 is a parameter governing the birth rate.",4. Birth-Death Process for Feature Allocation,[0],[0]
The new feature a is a binary column of length N .,4. Birth-Death Process for Feature Allocation,[0],[0]
"There are ( N |a| ) binary formulations for this fea-
ture and 2N",4. Birth-Death Process for Feature Allocation,[0],[0]
− 1 = ∑N n=1 ( N n ),4. Birth-Death Process for Feature Allocation,[0],[0]
"for all possible feature births and thus, the total birth rate from s is∑N n=1 ( N n )",4. Birth-Death Process for Feature Allocation,[0],[0]
R (n−1)!(N−n)!N !,4. Birth-Death Process for Feature Allocation,[0],[0]
= R ∑N n=1 1 n =,4. Birth-Death Process for Feature Allocation,[0],[0]
"R ·HN
where HN = ∑N n=1 1/n is the N -th harmonic num-
ber and n = |a| .",4. Birth-Death Process for Feature Allocation,[0],[0]
•,4. Birth-Death Process for Feature Allocation,[0],[0]
"Death: The rate of transitioning from s′ to s is
qs′s =",4. Birth-Death Process for Feature Allocation,[0],[0]
"Rr
α (5)
",4. Birth-Death Process for Feature Allocation,[0],[0]
where D = Ra is a parameter governing the death rate and r is the multiplicity of the feature in s′ that dies.,4. Birth-Death Process for Feature Allocation,[0],[0]
The multiplicity r is the combinatorial factor that accounts for all the possible ways of obtaining the same equivalence class as defined in Griffiths & Ghahramani (2011) .,4. Birth-Death Process for Feature Allocation,[0],[0]
"There are Ks′ features (including repetitions of the same feature) in s′ that might “die”, thus the total death rate from s′ is RKs′α .
",4. Birth-Death Process for Feature Allocation,[0],[0]
"The total rate of transition out of state s ∈ ZN is the sum of the total birth and death rates, qs = RHN + RKsα =
R ( HN + Ks α ) .",4. Birth-Death Process for Feature Allocation,[0],[0]
"We call (Z(t))t>=0 a birth-death feature allocation process with birth rate R and death rate Rα and write BDFP(α,R).
",4. Birth-Death Process for Feature Allocation,[0],[0]
Theorem 1.,4. Birth-Death Process for Feature Allocation,[0],[0]
The Markov process (Z(t))t≥0 is irreducible and has stationary distribution IBP(α).,4. Birth-Death Process for Feature Allocation,[0],[0]
"Furthermore, it is reversible.
",4. Birth-Death Process for Feature Allocation,[0],[0]
Proof.,4. Birth-Death Process for Feature Allocation,[0],[0]
A continuous time Markov chain is irreducible if it is possible to eventually get from every state to every other state with positive probability.,4. Birth-Death Process for Feature Allocation,[0],[0]
"It is reversible if detailed balance holds, i.e. there is a probability distribution π on ZN such that πsqss′ = πs′qs′s for all s, s′ ∈ ZN .",4. Birth-Death Process for Feature Allocation,[0],[0]
Then π is also the invariant (equilibrium) distribution of the Markov chain.,4. Birth-Death Process for Feature Allocation,[0],[0]
"The chain in BDFP is irreducible, because for any T > 0 and any two distinct feature allocations γ, ρ ∈ ZN , there is a positive probability that if it starts at γ ∈ ZN , it will end at ρ ∈ ZN .",4. Birth-Death Process for Feature Allocation,[0],[0]
Reversibility and the equilibrium distribution can be demonstrated by detailed balance.,4. Birth-Death Process for Feature Allocation,[0],[0]
"Suppose γ, ρ are feature allocations such that γ, ρ ∈ ZN and ρ differs from γ in that it has one additional feature a of size |a|.",4. Birth-Death Process for Feature Allocation,[0],[0]
"The number of (nonzero) features in ρ isKρ = Kγ+1.
",4. Birth-Death Process for Feature Allocation,[0],[0]
"Then,
g(γ;α)qγρ = αKγ
Π",4. Birth-Death Process for Feature Allocation,[0],[0]
Hγ h=1Kh!,4. Birth-Death Process for Feature Allocation,[0],[0]
exp (−αHN ) Kγ∏ k=1 (N −mk)!(mk,4. Birth-Death Process for Feature Allocation,[0],[0]
− 1)!,4. Birth-Death Process for Feature Allocation,[0],[0]
N !,4. Birth-Death Process for Feature Allocation,[0],[0]
R (|a| − 1)!(N − |a|)!,4. Birth-Death Process for Feature Allocation,[0],[0]
"N !
",4. Birth-Death Process for Feature Allocation,[0],[0]
"mKγ+1=|α| = αKγ+1
αΠ",4. Birth-Death Process for Feature Allocation,[0],[0]
Hγ h=1Kh!,4. Birth-Death Process for Feature Allocation,[0],[0]
exp (−αHN ) Kγ+1∏ k=1 (N −mk)!(mk,4. Birth-Death Process for Feature Allocation,[0],[0]
− 1)!,4. Birth-Death Process for Feature Allocation,[0],[0]
N !,4. Birth-Death Process for Feature Allocation,[0],[0]
"R
= αKρ
rαΠ",4. Birth-Death Process for Feature Allocation,[0],[0]
Hγ h=1Kh!,4. Birth-Death Process for Feature Allocation,[0],[0]
exp (−αHN ) Kρ∏,4. Birth-Death Process for Feature Allocation,[0],[0]
k=1,4. Birth-Death Process for Feature Allocation,[0],[0]
(N −mk)!(mk,4. Birth-Death Process for Feature Allocation,[0],[0]
− 1)!,4. Birth-Death Process for Feature Allocation,[0],[0]
N !,4. Birth-Death Process for Feature Allocation,[0],[0]
R α,4. Birth-Death Process for Feature Allocation,[0],[0]
"ra
rα=Kα= αKρ
Π",4. Birth-Death Process for Feature Allocation,[0],[0]
Hρ h=1Kh!,4. Birth-Death Process for Feature Allocation,[0],[0]
exp (−αHN ) Kρ∏,4. Birth-Death Process for Feature Allocation,[0],[0]
k=1,4. Birth-Death Process for Feature Allocation,[0],[0]
(N −mk)!(mk,4. Birth-Death Process for Feature Allocation,[0],[0]
− 1)!,4. Birth-Death Process for Feature Allocation,[0],[0]
N !,4. Birth-Death Process for Feature Allocation,[0],[0]
R α,4. Birth-Death Process for Feature Allocation,[0],[0]
"ra
= g(ρ;α)qργ (6)
where g(γ;α) is the probability of a feature allocation γ under the IBP as defined in Equation (1), qγρ is the transition rate from state γ to state ρ,",4. Birth-Death Process for Feature Allocation,[0],[0]
"Hγ , Hρ are the number of distinct features in states γ and ρ respectively and ra is the multiplicity (the times the feature is present at the current feature allocation) of feature a that dies.",4. Birth-Death Process for Feature Allocation,[0],[0]
"Detailed balance holds, and as such the process is reversible and the equilibrium distribution is IBP[N ](α).
",4. Birth-Death Process for Feature Allocation,[0],[0]
Assume that (z(t)) is a realization of the BDFP (Z(t)) over the finite interval,4. Birth-Death Process for Feature Allocation,[0],[0]
"[0, T ], T > 0",4. Birth-Death Process for Feature Allocation,[0],[0]
and we write (z(t))0≤t≤T .,4. Birth-Death Process for Feature Allocation,[0],[0]
"With probability one the sample path (z(t))0≤t≤T will only contain a finite number of jump events, each of which is either a birth or a death event.",4. Birth-Death Process for Feature Allocation,[0],[0]
"We write B and Q to denote the set of the features created or turned off by birth or death events respectively.
",4. Birth-Death Process for Feature Allocation,[0],[0]
Proposition 1.,4. Birth-Death Process for Feature Allocation,[0],[0]
"Writing q(t) = qz(t) to denote the total transition rate out of state z(t), the probability of a realization (z(t)) under the law of the BDFP is:
R|B|+|Q| αA−|B|−|Q|∏A∗−|B∗| h=1",4. Birth-Death Process for Feature Allocation,[0],[0]
"Kh!
exp (−αHN ) exp ( − ∫ T
0
q(t)dt )",4. Birth-Death Process for Feature Allocation,[0],[0]
× . .,4. Birth-Death Process for Feature Allocation,[0],[0]
".
",4. Birth-Death Process for Feature Allocation,[0],[0]
∏ b∈B∪{z(t=0)} (|b| − 1)!(N − |b|)!,4. Birth-Death Process for Feature Allocation,[0],[0]
N !,4. Birth-Death Process for Feature Allocation,[0],[0]
∏,4. Birth-Death Process for Feature Allocation,[0],[0]
"d∈D rd
(7)
where A = K0 + |B| = KT + |Q|, A∗ = H0 + |B∗| = HT + |Q∗|. B∗, Q∗ are the sets of features with zero multiplicity at their creation time or with multiplicity of one at their death time respectively, and {z(t)} denotes the set of features at time t.",4. Birth-Death Process for Feature Allocation,[0],[0]
The BDFP process can be constructed using a nonhomogenous Poisson process Π. Consider the Lévy measure ν(dωdxdtbdtω) on a product space,4.1. Dependent Beta Process Construction,[0],[0]
"[0, 1] ⊗ X ⊗ R ⊗",4.1. Dependent Beta Process Construction,[0],[0]
"[0,∞).",4.1. Dependent Beta Process Construction,[0],[0]
"A sample corresponds to set of points Π = {ωk, xk, tkb , tkω}k where the range of k is countably infinite.",4.1. Dependent Beta Process Construction,[0],[0]
Each atom corresponds to a feature and is associated with a weight ωk ∈,4.1. Dependent Beta Process Construction,[0],[0]
"[0, 1], a location xk, a birth time tkb ∈ R and a life-span tkω ∈",4.1. Dependent Beta Process Construction,[0],[0]
"[0,∞) (Figure 1).",4.1. Dependent Beta Process Construction,[0],[0]
"The Lévy measure is of the form ν(dωdxdtbdtω) = ρ(dω)µ(dxdtbdtω) and
corresponds to a Beta process on the combined space",4.1. Dependent Beta Process Construction,[0],[0]
Θ = X⊗ R⊗,4.1. Dependent Beta Process Construction,[0],[0]
"[0,∞) with ρ(dω)",4.1. Dependent Beta Process Construction,[0],[0]
= αω−1(1− ω)α−1 and base measure µ(dθ) = µ(dxdtbdtw).,4.1. Dependent Beta Process Construction,[0],[0]
"Setting g(dtb) = dtb and β(dtω) = D exp
−Dtω dtω , the base measure is µ(dθ) = µ0(dx)g(dtb)β(dtω) = µ0(dx)dtbD exp
−Dtω dtω , where D is the death rate.",4.1. Dependent Beta Process Construction,[0],[0]
"The constant measure g(dtb) over the real line R is infinite but σ-finite, that is the total measure g(R)",4.1. Dependent Beta Process Construction,[0],[0]
"= ∞, but there is a measurable partition (Ek) of R with each g(Ek)",4.1. Dependent Beta Process Construction,[0],[0]
< ∞. Since ν(dωdθ) integrates to infinity but satisfies ∫,4.1. Dependent Beta Process Construction,[0],[0]
"[0,1] ∫ Θ
(1 ∧ |ω|)ν(dωdθ) < ∞, a countably infinite number of i.i.d. random points {(ωk,θk)}∞k=1 are obtained from the Poisson process and ∑∞",4.1. Dependent Beta Process Construction,[0],[0]
k=1 ωk is finite with probability one.,4.1. Dependent Beta Process Construction,[0],[0]
"A Beta process is a completely random measure (Kingman, 1967) and, as such, a sample can be expressed as B = ∑∞",4.1. Dependent Beta Process Construction,[0],[0]
"k=1 ωkδθk |α, µ ∼ BP(αµ), where the atoms θk = {xk, tkb , tkω} ∈ Θ and weights",4.1. Dependent Beta Process Construction,[0],[0]
ωk ∈,4.1. Dependent Beta Process Construction,[0],[0]
"[0, 1].
Having drawn a sample B we can construct the feature allocations over an index space R as follows:
B = ∞∑",4.1. Dependent Beta Process Construction,[0],[0]
"k=1 ωkδθk |α, µ ∼ BP(αµ)
",4.1. Dependent Beta Process Construction,[0],[0]
"Sn: = ∞∑ k=1 bnkδθ |B ∼ BeP(ωk) Znk(t) = SnkI(tkb < t < tkb + tkω) (8)
with bnk|ωk ∼ Bernoulli(ωk) and n = 1, . . .",4.1. Dependent Beta Process Construction,[0],[0]
", N .",4.1. Dependent Beta Process Construction,[0],[0]
"The binary matrix S of dimension N ×K, is a feature potential matrix.",4.1. Dependent Beta Process Construction,[0],[0]
Each binary element Snk indicates whether object n possesses feature fk.,4.1. Dependent Beta Process Construction,[0],[0]
S is a global variable and doesn’t depend on time t.,4.1. Dependent Beta Process Construction,[0],[0]
"At any time t, the feature allocation matrix Z(t) is a deterministic function of the current features present at t, that is {fk : tkb < t < tkb + tkw, k = 1, . . .",4.1. Dependent Beta Process Construction,[0],[0]
",∞}
and the feature potential matrix S, i.e. Znk(t) = 1 iff Snk = 1 and tkb < t",4.1. Dependent Beta Process Construction,[0],[0]
<,4.1. Dependent Beta Process Construction,[0],[0]
"t k b + t k ω .
",4.1. Dependent Beta Process Construction,[0],[0]
"The resulting feature allocation process (zn(t))T is equivalent to the following: every time a new feature fk is created, each object n joins with probability ωk, i.e. znk(tkb )|ωk ∼ Bernoulli(ωk).",4.1. Dependent Beta Process Construction,[0],[0]
"If znk(tkb ) = 1, object n will possess feature fk until tkb + t k ω .",4.1. Dependent Beta Process Construction,[0],[0]
Repeat this process for all objects.,4.1. Dependent Beta Process Construction,[0],[0]
Proposition 2.,4.1. Dependent Beta Process Construction,[0],[0]
"The BDFP is exchangeable and the Beta process BP(αµ) on X⊗R⊗[0,∞) describes its underlying mixing measure.
",4.1. Dependent Beta Process Construction,[0],[0]
Proof.,4.1. Dependent Beta Process Construction,[0],[0]
"Consider a sequence of variables (zn(t))T with n = 1, 2, . . .",4.1. Dependent Beta Process Construction,[0],[0]
", N such that each (zn(t))T is the feature allocation evolution of object n over the index space T. These variables are not independent since each (zn(t))T depends on the Z|[n−1](t) =",4.1. Dependent Beta Process Construction,[0],[0]
"(z1:(n−1)(t))T. However, given a sample from the B ∼ BP(αµ) described in Section 4.1, each variable (zn(t))T becomes conditionally independent and the following holds
P ((z1(t))T, (z2(t))T, . . .",4.1. Dependent Beta Process Construction,[0],[0]
", (zN (t))T) = ∫ N∏ n=1 P ((zn(t))T|B)φ(dB)
(9)
where φ = BP(αµ).
",4.1. Dependent Beta Process Construction,[0],[0]
Equation (9) is the de Finetti representation of the BDFP and as such the BDFP is exchangeable and the BP on Θ = X ⊗ R ⊗,4.1. Dependent Beta Process Construction,[0],[0]
"[0,∞) is its underlying mixing measure.",4.1. Dependent Beta Process Construction,[0],[0]
"Restricting our focus on each index t, the overall Beta process BP(αµ) on X⊗ R⊗ [0,∞) results in a set of dependent random measures over X, oneBt for each t ∈ T, such that each Bt is marginally a Beta process.",4.1. Dependent Beta Process Construction,[0],[0]
"Consider a fixed time point t ∈ T and the space [0, 1] ⊗ X (the red vertical plane in Figure 1).",4.1. Dependent Beta Process Construction,[0],[0]
"The point process on this plane (where blue lines intersect the plane) corresponds to features alive at time t, i.e. t ∈",4.1. Dependent Beta Process Construction,[0],[0]
"[tb, tb + tω].",4.1. Dependent Beta Process Construction,[0],[0]
"The Lévy measure on this plane, is calculated by projecting the overall Lévy measure onto the plane,
νt(dωdx) = ∫",4.1. Dependent Beta Process Construction,[0],[0]
"∞ 0 ∫ t t−tω ν(dωdxdtbdtω)
= αω−1(1− ω)α−1µ0(dx) D
(10)
where νt is a measure over [0, 1] ⊗ X for a specific t ∈ T. More specifically, it is the Lévy measure of a Beta process on X with ρ(dω) = αω−1(1 − ω)α−1 and base measure µt(dx)",4.1. Dependent Beta Process Construction,[0],[0]
"=
µ0(dx) D .",4.1. Dependent Beta Process Construction,[0],[0]
"Thus we have that marginally Bt|α, µt ∼ BP(αµt), ∀t ∈ T. (11)
",4.1. Dependent Beta Process Construction,[0],[0]
The restricted and projected measure at any index t ∈ T defines a Beta process.,4.1. Dependent Beta Process Construction,[0],[0]
"Two draws, Bt and Bs, with t, s ∈ T, will be dependent with the amount of dependence decreasing as |s− t| increases.",4.1. Dependent Beta Process Construction,[0],[0]
Proposition 3.,4.1. Dependent Beta Process Construction,[0],[0]
"The dependent Beta process construction presented has IBP marginals at any t.
Proof.",4.1. Dependent Beta Process Construction,[0],[0]
"At any t ∈ T, Bt|α, µt ∼ BP(αµt).",4.1. Dependent Beta Process Construction,[0],[0]
"It is straightforward to see that, marginally, the feature allocation matrix Zt obtained using the generative process in Equation (8) is equivalent to Zt|Bt ∼ BeP(Bt) and therefore Zt ∼ IBP(α), ∀t ∈ T. Corollary 1.",4.1. Dependent Beta Process Construction,[0],[0]
"At any t ∈ T, the feature allocation matrix Zt can be generated by the following generative model as K →∞:
ωk|α ∼ Beta ( R
K
) , Znk|ωk ∼ Bernoulli(ωk) (12)
for k = 1, . . .",4.1. Dependent Beta Process Construction,[0],[0]
",K and n = 1, . . .",4.1. Dependent Beta Process Construction,[0],[0]
", N
The proof of the corollary in included in the supplementary material.",4.1. Dependent Beta Process Construction,[0],[0]
"Note that the above is true only marginally, i.e. at time t ∈ T and it doesn’t generste dependence structure between Zt’s.
",4.1. Dependent Beta Process Construction,[0],[0]
"We underline the dependence of Zs and Zt when |s− t| → 0, ∀s, t ∈ T.",4.1. Dependent Beta Process Construction,[0],[0]
"The closer s, t are, the more the atoms (features)",4.1. Dependent Beta Process Construction,[0],[0]
Bs and Bt share.,4.1. Dependent Beta Process Construction,[0],[0]
"If we independently sampled Zs|Bs ∼ BeP(Bs) and Zt|Bt ∼ BeP(Bt) then Zs, Zt would be dependent, but not equal, even as |s − t| → 0.",4.1. Dependent Beta Process Construction,[0],[0]
"However, in the BDFP the presence of the same features results in the same (not just similar) allocation as |s−t| → 0.",4.1. Dependent Beta Process Construction,[0],[0]
"In both cases, the marginal distribution of the feature allocation matrix at any t ∈ T is Zt|Bt ∼ BeP(Bt) and Zt|α ∼ IBP(α).",4.1. Dependent Beta Process Construction,[0],[0]
"The BDFP results in a continuous evolution of the Z(t) over T: formally Zt d→ Zs as t→ s.
This construction of the BDFP resembles the spatial normalised Gamma process (SNΓP) by (Rao & Teh, 2009).",4.1. Dependent Beta Process Construction,[0],[0]
"The main difference lies in the marginal distribution; the SNΓP admits DP marginals as opposed to the Beta process marginals of the dependent Beta process as shown in Equation (11).
",4.1. Dependent Beta Process Construction,[0],[0]
Proposition 4.,4.1. Dependent Beta Process Construction,[0],[0]
"The feature allocation process described by Equation (8) with B ∼ BP(αµ), has the same birth and death rates as the BDF process.",4.1. Dependent Beta Process Construction,[0],[0]
"For the BDFP, the inference simplifies considerably if we consider a finite approximation which gives the countably infinite model in the limit.",5. Finite Model,[0],[0]
Consider the space S =,5. Finite Model,[0],[0]
"[0, 1] ⊗ X ⊗",5. Finite Model,[0],[0]
"[0, T ] ⊗",5. Finite Model,[0],[0]
"[0,∞), where we restrict the space of tb to be [0, T ] instead of the whole real line R. This accounts for typical applications of the model where we observe data at distinct times over a finite time range.",5. Finite Model,[0],[0]
"Consider the Lévy measure ν(dωdxdtbdtω) on the space S. Then, under the dependent Beta process representation (see section 4.1), the expected number of atoms present in S is
∫ S ν(dωdxdtbdtω) =∫ 1
0 ρ(dω) ∫",5. Finite Model,[0],[0]
X µ0(dx) ∫ T 0,5. Finite Model,[0],[0]
g(dtb) ∫∞ 0 β(dtω),5. Finite Model,[0],[0]
"= KT , where
K → ∞ since ∫ 1
0 ρ(dω) =",5. Finite Model,[0],[0]
"∞. By considering finite K
we allow inference on a finite model which approximates the infinite case with increasing fidelity as K →∞.
The process is depicted in Figure 2 and the infinite case can be derived as the limit K →∞ of the following:
• Consider a time range",5. Finite Model,[0],[0]
"[0, T ] and a set of features F , such that |F| ∼ Poisson(KT ).",5. Finite Model,[0],[0]
"Assign to each feature fk ∈ F , k = 1, . . .",5. Finite Model,[0],[0]
|F|,5. Finite Model,[0],[0]
"a weight ω, such that ωk",5. Finite Model,[0],[0]
"∼ Beta ( R K , 1 ) and Ω =",5. Finite Model,[0],[0]
"[ω1, ω2 . . .",5. Finite Model,[0],[0]
ω|F|].,5. Finite Model,[0],[0]
"• Associate each feature fk ∈ F , k = 1, . . .",5. Finite Model,[0],[0]
|F|,5. Finite Model,[0],[0]
"with a birth time tkb uniformly sampled in [0, T ]; t k b ∼
U(0, T ) and tb",5. Finite Model,[0],[0]
=,5. Finite Model,[0],[0]
[t1b . . .,5. Finite Model,[0],[0]
t |F|,5. Finite Model,[0],[0]
b,5. Finite Model,[0],[0]
"].
",5. Finite Model,[0],[0]
"• For each fk ∈ F , sample its life span tkw ∼ Exponential(D), where D is the death rate.",5. Finite Model,[0],[0]
Define the time of death tkd as t k d = t k b,5. Finite Model,[0],[0]
+,5. Finite Model,[0],[0]
t k w,5. Finite Model,[0],[0]
and tw,5. Finite Model,[0],[0]
"=
[t1w . . .",5. Finite Model,[0],[0]
t |F|,5. Finite Model,[0],[0]
"w ].
",5. Finite Model,[0],[0]
We call the sequence of the above steps Beta Event Process (BEP).,5. Finite Model,[0],[0]
"Putting everything together, generate a sample B = {F ,Ω, tb, tw} ∼ BEP(α,R,K, T ) as follows:
|F| ∼ Poisson(KT )",5. Finite Model,[0],[0]
"ωk ∼ Beta ( R
K , 1
) , tkb ∼ U(0, T ), tkω ∼ Exponential(D)
(13)
for k = 1, . . .",5. Finite Model,[0],[0]
", |F|.",5. Finite Model,[0],[0]
"Having drawn a sample B from the BEP, we can construct the feature allocations over time as follows
Snk|ωk ∼ Bernoulli(ωk) Znk(t) =",5. Finite Model,[0],[0]
"SnkI(tkb < t < tkb + tkω) (14)
",5. Finite Model,[0],[0]
"where n = 1, .",5. Finite Model,[0],[0]
. .,5. Finite Model,[0],[0]
", N .",5. Finite Model,[0],[0]
The feature potential matrix (as defined in section 4.1) has now N × |F| dimensions.,5. Finite Model,[0],[0]
"Moreover, each Z(t) for t ∈ T is a matrix of dimensions N × F (t) and F (t) ≤ |F|.",5. Finite Model,[0],[0]
"Figure 3(a) show the graphical model for the BEP.
",5. Finite Model,[0],[0]
Proposition 5.,5. Finite Model,[0],[0]
"In the finite model, the expected number of features present at any t ∈ T is E[Nf ]",5. Finite Model,[0],[0]
= KD and for D = Rα we have E[Nf ],5. Finite Model,[0],[0]
"= Kα R .
Hyperpriors.",5. Finite Model,[0],[0]
"We put gamma priors on α and R.
Likelihood models.",5. Finite Model,[0],[0]
"We consider two different likelihood models: linear-Gaussian for real data and logistic for binary network data.
",5. Finite Model,[0],[0]
"For the linear-Gaussian likelihood model, consider a sequence of observations {Yt ∈ Y : t = 1, . . .",5. Finite Model,[0],[0]
", L} generated as
Yt = ZtA + t (15)
where Yt is a N ×M observation matrix at each time t = 1, . . .",5. Finite Model,[0],[0]
", L, A is a factor loading matrix of dimension |F|",5. Finite Model,[0],[0]
"× M shared across time and t ∼ N ( 0, σ2 ) is Gaussian white noise.",5. Finite Model,[0],[0]
"We choose a Gaussian prior over A, i.e Afm ∼ N (0, 1).
",5. Finite Model,[0],[0]
"In the case of dynamic binary network data we extend the latent feature relational model (LFRM) proposed by (Miller et al., 2009).",5. Finite Model,[0],[0]
"Let Yt be the N × N binary matrix that contains links, i.e. ytij = Yt(i, j) = 1 iff we observe a link from entity i to entity j at time t. We assume that the matrices Yt are symmetric and ignore diagonal elements (self-links).",5. Finite Model,[0],[0]
The probability of a link from one entity to another is determined by the combined effect of all pairwise feature interactions.,5. Finite Model,[0],[0]
Let Wt be a |F| × |F|,5. Finite Model,[0],[0]
"real-valued weight matrix where Wt(k, k′) is the weight that affects the probability of there being a link from entity i to entity j if entity i has feature k on, i.e. Ztik = Zt(i, k) = 1 and entity j has feature k′ on, i.e. Ztjk′ = Zt(j, k′)",5. Finite Model,[0],[0]
= 1.,5. Finite Model,[0],[0]
"The links are independent conditioned on Zt and Wt, and only the features that are on for the entities i and j at time t influence the probability of a link between those entities at that time (see Figure 3(b)).",5. Finite Model,[0],[0]
"Formally,
P (ytij = 1|Zt,Wt) = σ",5. Finite Model,[0],[0]
"(∑
kl
ZtikZtjlWtkl + s ) (16)
for k, l = 1, .",5. Finite Model,[0],[0]
. .,5. Finite Model,[0],[0]
", |F|, where s is a bias term and σ(x) =",5. Finite Model,[0],[0]
(1 + e−x)−1 is the sigmoid function.,5. Finite Model,[0],[0]
"For completeness, we assume the priors wt(k, l) ∼ N ( µw, σ 2 w ) and s ∼
N ( µs, σ 2 s ) .",5. Finite Model,[0],[0]
"As with many other Bayesian models, exact inference is intractable so we employ Markov Chain Monte Carlo (MCMC) for posterior inference over the latent variables of the finite model.",5.1. Inference,[0],[0]
A detailed description is provided in the supplementary material.,5.1. Inference,[0],[0]
We experimentally evaluate the BEP model on real-world genomics and social network data.,6. Experiments,[0],[0]
"To evaluate the model fit, we compared the BEP model to independent models at each time point.",6. Experiments,[0],[0]
"Here we used a subset of the gene expression data from Piechota et al. (2010), including N = 500 genes in D = 4 different conditions (exposure to different drugs) over L = 24 time intervals.",6.1. Circadian Rhythm Dataset,[0],[0]
The measurements indicate how active a gene is at different times.,6.1. Circadian Rhythm Dataset,[0],[0]
"We created 7 train-test splits holding out 20% of the data, and ran 700 MCMC iterations.",6.1. Circadian Rhythm Dataset,[0],[0]
We see that in terms of predictive performance the BEP outperforms independent IBP models (Table 1).,6.1. Circadian Rhythm Dataset,[0],[0]
The genes belonging to each factor show enrichment for different known biological pathways (Figure 4).,6.1. Circadian Rhythm Dataset,[0],[0]
"Of particular note are the tryptophan metabolism genes enriched in factor 2, given tryptophan’s suspected effects on drowsiness;
the vasopressin regulated water reabsorption, given this hormone’s known circadian regulation (Earnest & Sladek, 1986; Yamaguchi et al., 2013); and the regulation of insulin producing beta cells, another hormone with circadian variation (Shi et al., 2013).",6.1. Circadian Rhythm Dataset,[0],[0]
"For this experiment we used ChIP-seq (chromatin immunoprecipitation sequencing) data downloaded from the ENCODE project (Consortium, 2007), representing histone modifications and transcription factor binding in human neural crest cell lines (see (Park, 2009) for a nice review).
",6.2. ChIP-seq Epigenetic Marks,[0],[0]
The observations involve counts associated with N = 14 (human) cell lines and D = 10 proteins.,6.2. ChIP-seq Epigenetic Marks,[0],[0]
"The counts indicate what proteins, with what chemical modifications, are bound to DNA along the genome.",6.2. ChIP-seq Epigenetic Marks,[0],[0]
"The measurements are stored in N × D matrix of counts Yt: for each cell line, how many reads for each of the 10 proteins mapped to bin t (100 base pair (bp) region of the genome).",6.2. ChIP-seq Epigenetic Marks,[0],[0]
"t = 1, . . .",6.2. ChIP-seq Epigenetic Marks,[0],[0]
", 500 bins were considered at the start of chromosome 1 (50K bp in total).",6.2. ChIP-seq Epigenetic Marks,[0],[0]
In Figure 5(a) each subfigure corresponds to one of the 10 proteins and in each subfigure the counts for the N = 14 cell lines are plotted over the genome section of length 50Kbp.,6.2. ChIP-seq Epigenetic Marks,[0],[0]
"Before inference, the raw counts were square-root transformed (a standard variance stabilizing transform for Poisson data) to make the Gaussian likelihood appropriate.",6.2. ChIP-seq Epigenetic Marks,[0],[0]
"We ran 7 different held-out tests, holding out a different 20% of the data each time.",6.2. ChIP-seq Epigenetic Marks,[0],[0]
"Results, using 700 MCMC iterations, are presented in Table 2.",6.2. ChIP-seq Epigenetic Marks,[0],[0]
"The
BEP outperforms the independent IBP model in both test likelihood and error with a statistically significant difference.",6.2. ChIP-seq Epigenetic Marks,[0],[0]
"The independent IBP appears to have better results in train error and likelihood, again suggesting overfitting.",6.2. ChIP-seq Epigenetic Marks,[0],[0]
"Comparing the plots of the true measurements to the learnt ones by the BEP and independent IBP model in Figure 5 we see that both models successfully reproduce the data but the BEP reconstructions provide a cleaned up picture of the meaningful signal.
",6.2. ChIP-seq Epigenetic Marks,[0],[0]
The features found by the model in the different genome locations correspond to different states associated with the specific genome location.,6.2. ChIP-seq Epigenetic Marks,[0],[0]
"Genes and regulatory DNA elements such as enhancers, silencers and insulators are embedded in genomes.",6.2. ChIP-seq Epigenetic Marks,[0],[0]
"These genomic elements on the DNA have footprints for the transacting proteins involved in transcription, either for the positioning or regulation of the transcriptional machinery.",6.2. ChIP-seq Epigenetic Marks,[0],[0]
"For instance, promoters are regions of DNA which recruit proteins required to initiate transcription of a particular gene and located near the transcription start sites.",6.2. ChIP-seq Epigenetic Marks,[0],[0]
Enhancers are regions of DNA that can be bound by proteins which activate transcription of a distal gene.,6.2. ChIP-seq Epigenetic Marks,[0],[0]
"So a cell line, at specific genome location (recall that here each location corresponds to 100 base pairs), will have underlying feature membership (some promoters and some enhancer for example) that determines whether particular protein are found there using ChIP-seq.
Genomic annotations, from ChromHMM (Ernst et al., 2011), are shown in Figure 8 in the supplementary document for the region we model.",6.2. ChIP-seq Epigenetic Marks,[0],[0]
Different levels of the marks in these different regions are much easier to see in the reconstructed signal using BEP in Figure 5(b).,6.2. ChIP-seq Epigenetic Marks,[0],[0]
"In van de Bunt et al. (1999), 32 university freshman students in a given discipline at a Dutch university were surveyed at seven time points about who in their class they considered as friends.",7. van de Bunt’s Dataset,[0],[0]
"Initially, i.e. t1, most of the students were unknown to each other.",7. van de Bunt’s Dataset,[0],[0]
"The first four time points are three weeks apart, whereas the last three time points are six weeks apart as showin in Figure 11 in the supplementary matrial.",7. van de Bunt’s Dataset,[0],[0]
We symmetrise the matrix by assuming friendship if either individual reported it.,7. van de Bunt’s Dataset,[0],[0]
"We test the performance of BEP using the sigmoid likelihood model as in Equation
(16) by holding out 10% of all links across all time points.",7. van de Bunt’s Dataset,[0],[0]
We ran each model for 1000 MCMC iterations.,7. van de Bunt’s Dataset,[0],[0]
The results are shown in Table 3.,7. van de Bunt’s Dataset,[0],[0]
The independent network LFR models outperform BEP in the train setting and the test error while BEP outperforms in the test likelihood.,7. van de Bunt’s Dataset,[0],[0]
"However, here the results are comparable.",7. van de Bunt’s Dataset,[0],[0]
"Looking at Figure 6, both models provide the same picture of the allocation.",7. van de Bunt’s Dataset,[0],[0]
It is possible the stationary assumption hurts the BEP: in the VDB dataset the number of links almost exclusively increases over time.,7. van de Bunt’s Dataset,[0],[0]
"Many modern machine learning and statistics tasks involve multidimensional data positioned along some linear covariate: we have shown functional genomics data where the covariate is position in the genome, and network data where links change over time.",8. Discussion,[0],[0]
"To model such data we need priors that utilize the dependencies through time, while handling high dimensionality.",8. Discussion,[0],[0]
The BDFP is an expressive new Bayesian non-parametric prior that fulfills these criteria.,8. Discussion,[0],[0]
"It outputs time-evolving feature allocations, which can then be effectively used to model high-dimensional time-series data.",8. Discussion,[0],[0]
"Since the number of latent features is unbounded, like other Bayesian non-parametric methods, the model can adapt its complexity to the data.",8. Discussion,[0],[0]
"While the combinatorial BDFP may seem like a complex object to handle computationally, our theoretical results showing that the de Finetti measure underlying the BDFP is a specific beta process, which can be well approximated by a finite K model, the BEP.",8. Discussion,[0],[0]
"Our experimental results, compared to independent feature allocations, provides evidence that effectively modeling dependency in the feature allocation through the birth-death mechanism is appropriate for a wide range of statistical applications.",8. Discussion,[0],[0]
"Moreover, the BEP provides an interpretable structure using parameters not found, to the best of our knowledge, in existing models, i.e. birth and death rate of features.",8. Discussion,[0],[0]
"We are interested in scaling inference under the BEP to larger datasets, for example using (stochastic) variational inference methods that have been successful for the IBP (Doshi et al., 2009).
",8. Discussion,[0],[0]
Acknowledgements Konstantina’s research leading to these results has received funding from the European Research Council under the European Union’s Seventh Framework Programme (FP7/2007-2013) ERC grant agreement no. 617411.,8. Discussion,[0],[0]
"We propose a Bayesian nonparametric prior over feature allocations for sequential data, the birthdeath feature allocation process (BDFP).",abstractText,[0],[0]
The BDFP models the evolution of the feature allocation of a set of N objects across a covariate (e.g. time) by creating and deleting features.,abstractText,[0],[0]
"A BDFP is exchangeable, projective, stationary and reversible, and its equilibrium distribution is given by the Indian buffet process (IBP).",abstractText,[0],[0]
We show that the Beta process on an extended space is the de Finetti mixing distribution underlying the BDFP.,abstractText,[0],[0]
"Finally, we present the finite approximation of the BDFP, the Beta Event Process (BEP), that permits simplified inference.",abstractText,[0],[0]
The utility of the BDFP as a prior is demonstrated on real world dynamic genomics and social network data.,abstractText,[0],[0]
A Birth-Death Process for Feature Allocation,title,[0],[0]
Replicating results in deep learning research is often hard.,1. Introduction,[0],[0]
"This harms their usefulness to industry, leads to a waste of effort by other researchers, and limits the scientific value of such results.
",1. Introduction,[0],[0]
One reason is that many papers provide information insufficient for replication.,1. Introduction,[0],[0]
"Details of the experimental setup can significantly influence the results (Henderson et al., 2018; Fokkens et al., 2013; Raeder et al., 2010), so the details should be provided at least in appendices, ideally alongside the source code, as was strongly emphasized e.g. by Ince et al. (2012).
",1. Introduction,[0],[0]
"However, an important second factor hinders replicability: most deep learning training methods are inherently stochastic.",1. Introduction,[0],[0]
"This randomness usually comes from random data ordering in stochastic gradient descent and from random parameter initialization, though there can be additional sources of randomness such as dropout or gradient noise.",1. Introduction,[0],[0]
"Consequently, even if we fix the model architecture and the experimental setup (including the hyper-parameters), we obtain a different result each time we run an experiment.",1. Introduction,[0],[0]
Statistical techniques are needed to handle this variability.,1. Introduction,[0],[0]
"However,
1 IBM Watson, Prague AI Research & Development Lab.",1. Introduction,[0],[0]
RK has since moved to Deepmind.,1. Introduction,[0],[0]
Correspondence to: Ondrej Bajgar < OBajgar@cz.ibm.com,1. Introduction,[0],[0]
">.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
in deep learning research, they are heavily underused.",1. Introduction,[0],[0]
"What is usually done instead?
",1. Introduction,[0],[0]
Most empirical deep learning papers simply report the performance of the best single model (we will later show this is the case at least for some sub-domains).,1. Introduction,[0],[0]
"Given the result stochasticity, such method is statistically flawed.",1. Introduction,[0],[0]
"The best model performance is not robust under experiment replication, and its expected value improves with an increasing number of experiments performed, among other problems.",1. Introduction,[0],[0]
"Since many deep learning publications largely ignore these issues, we dedicate the first part of this article to explaining in some detail, and later run experiments to quantify them.
",1. Introduction,[0],[0]
Appropriate statistical techniques are hence necessary for evaluating (and comparing) the performance of machine learning (ML) architectures.,1. Introduction,[0],[0]
Some well-developed methods exist for such comparisons (a great introduction is given for instance by Cohen (1995)).,1. Introduction,[0],[0]
"However, most existing methods focus on comparing the mean performance.",1. Introduction,[0],[0]
"This may be one of the reasons why statistical methods are being underused, since mean may be unattractive to researchers in certain situations.
",1. Introduction,[0],[0]
There are multiple possible reasons for this.,1. Introduction,[0],[0]
"The one that we do consider sound1 is that when deploying models in practice, it is often natural to train multiple instances of a model and then deploy the best one to production based on a validation set evaluation.2 Underperforming models can be discarded, so the final deployed model does come from the higher tier of the model performance population, and
1Other reasons why researchers resort to the best performance as opposed to the mean may come from the current highly competitive atmosphere in the field with (possibly excessive) focus on performance on standard datasets (see Church (2017) or Sculley et al. (2018) for further discussion), which may motivate researchers to publish only their best results.",1. Introduction,[0],[0]
"Also, statistically sound estimation of performance does require repeatedly re-running experiments, which does incur additional cost, which researchers may prefer to invest in additional model tuning, especially in the present situation where reviewers seem not to require statistically sound evaluation of models and on the other hand may favour high-performing models.",1. Introduction,[0],[0]
"Of course, these motives should instead give place to effort to do good science, as opposed to a race on standard benchmarks.
",1. Introduction,[0],[0]
"2In some applications there is focus on speed of training and on reducing computational costs – there it does make sense to focus on the performance of the typical model as opposed to the best out of n, so the use of mean or median is appropriate.
",1. Introduction,[0],[0]
"the use of mean may be inappropriate.
",1. Introduction,[0],[0]
"Hence, rather than to completely abandon reporting the performance of the best model, we propose a way to fix its flaws.",1. Introduction,[0],[0]
"We do this by estimating the expected best-out-of-n (Boon) performance by running more than n experiments, which gives the estimate statistical validity if a sufficient number of experiments are run.",1. Introduction,[0],[0]
"We discuss how this measure relates to the performance distribution of the model, and we also give a method to empirically estimate Boon.
",1. Introduction,[0.9999999458386863],"['We discuss how this measure relates to the performance distribution of the model, and we also give a method to empirically estimate Boon.']"
"The paper proceeds as follows: First, we give a high-level explanation of why reporting performance of the best single model is problematic.",1. Introduction,[1.0],"['The paper proceeds as follows: First, we give a high-level explanation of why reporting performance of the best single model is problematic.']"
"We also give some evidence that it is widely used in the deep learning community, which is why this explanation may be needed.",1. Introduction,[1.0],"['We also give some evidence that it is widely used in the deep learning community, which is why this explanation may be needed.']"
We proceed by presenting Boon as a way to fix the above problems.,1. Introduction,[1.0],['We proceed by presenting Boon as a way to fix the above problems.']
We then give some experimental evidence for the flaws of best-singlemodel reporting and show that Boon does not suffer from them.,1. Introduction,[0],[0]
We wrap up by discussing the place of Boon in a ML researcher’s toolbox alongside traditional measures such as mean or median.,1. Introduction,[0],[0]
"In articles presenting new deep learning architectures, the performance is often reported as the score of the “best single model” or simply “single model”.",2. Best Single Model Performance,[1.0],"['In articles presenting new deep learning architectures, the performance is often reported as the score of the “best single model” or simply “single model”.']"
"In practice, this usually means that the researchers train multiple instances of the proposed architecture (often with different sets of hyperparameters), evaluate these instances on some validation set, and select the best-performing model.",2. Best Single Model Performance,[0],[0]
"This best model is evaluated on a test set, and the resulting test score is then reported as the metric characterizing the architecture and used for comparing it to previous models.",2. Best Single Model Performance,[1.0],"['This best model is evaluated on a test set, and the resulting test score is then reported as the metric characterizing the architecture and used for comparing it to previous models.']"
"If the score is better than those reported in previous work, the architecture is presented as superior.",2. Best Single Model Performance,[1.0],"['If the score is better than those reported in previous work, the architecture is presented as superior.']"
"This practice results in several issues:
Population variance Since results of experiments are stochastic, the performance of a single model is just a single instance drawn from a possibly disparate population.",2. Best Single Model Performance,[0.9999999419255494],"['This practice results in several issues: Population variance Since results of experiments are stochastic, the performance of a single model is just a single instance drawn from a possibly disparate population.']"
"If others train the model on their own, they get another sample from the architecture’s performance distribution, which may substantially differ from the one listed in the original paper.",2. Best Single Model Performance,[1.0],"['If others train the model on their own, they get another sample from the architecture’s performance distribution, which may substantially differ from the one listed in the original paper.']"
"Such paper thus gives insufficient information about what to expect from the new architecture, which should be one of the article’s main points.
",2. Best Single Model Performance,[0],[0]
One may object that the result published in the paper is not chosen from the population at random – it is selected using a validation result.,2. Best Single Model Performance,[0],[0]
"However, the correlation between the validation and test results is generally imperfect; in fact, in some of our experiments, it is almost zero, as we show in Section 4.",2. Best Single Model Performance,[0],[0]
"Furthermore, if we indeed do have a strong
correlation, we get another problem:
Expectation of best result increases with the number of experiments Simply put, the more samples from a population we get, the more extreme the best among them is likely to be.",2. Best Single Model Performance,[0],[0]
"In other words, the expected value of the best result depends on the number of experiments that the researchers run.",2. Best Single Model Performance,[1.0],"['In other words, the expected value of the best result depends on the number of experiments that the researchers run.']"
There are three closely related problems with this:,2. Best Single Model Performance,[0],[0]
"Firstly, this makes the number of experiments run an important explanatory variable; however, this variable is usually unreported, which is a severe methodological flaw in itself.",2. Best Single Model Performance,[0],[0]
"It also leads to the second problem: since each research team runs a different number of experiments, the results are not directly comparable.",2. Best Single Model Performance,[0],[0]
"Thirdly, this motivates researchers to run more experiments and gives an advantage to those who are able to do so.",2. Best Single Model Performance,[0],[0]
"This pushes publishing quantitative results towards a race in computational power rather than a fair comparison of architectures themselves.
",2. Best Single Model Performance,[0.999999975591463],['This pushes publishing quantitative results towards a race in computational power rather than a fair comparison of architectures themselves.']
"Best model performance is not a meaningful characteristic of the performance distribution Even if we knew the underlying theoretical performance distribution – that is, if we had perfect information about the architecture’s performance – it would not be clear what we would mean by ""best model performance"" without specifying the size of the pool from which we are choosing the best model.",2. Best Single Model Performance,[1.0],"['Best model performance is not a meaningful characteristic of the performance distribution Even if we knew the underlying theoretical performance distribution – that is, if we had perfect information about the architecture’s performance – it would not be clear what we would mean by ""best model performance"" without specifying the size of the pool from which we are choosing the best model.']"
Imagine some architecture having a Gaussian performance distribution.,2. Best Single Model Performance,[1.0],['Imagine some architecture having a Gaussian performance distribution.']
"Asking what is the best possible performance does not make sense in such a case, since the support of the distribution is unbounded.",2. Best Single Model Performance,[0],[0]
"Even for capped metrics such as accuracy, where the performance distribution necessarily has bounded support, the best (possible) model3 may be so unlikely, that it would be of no practical importance.",2. Best Single Model Performance,[1.0],"['Even for capped metrics such as accuracy, where the performance distribution necessarily has bounded support, the best (possible) model3 may be so unlikely, that it would be of no practical importance.']"
"Hence, best model performance is not a meaningful characteristic of the performance distribution.
",2. Best Single Model Performance,[0.9999999360666428],"['Hence, best model performance is not a meaningful characteristic of the performance distribution.']"
"Generality / Falsifiability Finally, there is the question of what the authors are trying to express.",2. Best Single Model Performance,[0],[0]
"Using “best single model performance”, they are essentially claiming: “There once existed an instance of our model that once achieved a result X on dataset Y”.",2. Best Single Model Performance,[1.0],"['Using “best single model performance”, they are essentially claiming: “There once existed an instance of our model that once achieved a result X on dataset Y”.']"
"Such fact is not of that much interest to the scientific community, which would rather need to know how the architecture behaves generally.",2. Best Single Model Performance,[1.0],"['Such fact is not of that much interest to the scientific community, which would rather need to know how the architecture behaves generally.']"
"Relatedly, a frequently given characteristic of science is falsifiability of theories (Popper, 1959).",2. Best Single Model Performance,[0],[0]
"A theory claiming that there are invisible unicorns running among us is not science, since we cannot think of any potential empirical evidence that could prove the theory false.",2. Best Single Model Performance,[0],[0]
"Similarly, any number of replication experiments that produce substantially worse results cannot prove the above performance claim wrong.",2. Best Single Model Performance,[1.0],"['Similarly, any number of replication experiments that produce substantially worse results cannot prove the above performance claim wrong.']"
"If, for instance, a confidence interval were given, replications could
3In the sense of validation performance being at or near the supremum of the validation performance distribution’s support.
",2. Best Single Model Performance,[0],[0]
"very quickly show the published result at least extremely implausible, if not false.
",2. Best Single Model Performance,[0],[0]
We will quantify the former two problems for two concrete architectures in Section 4.,2. Best Single Model Performance,[0],[0]
"Despite all these problems, reporting the performance of the best model is still the main way of reporting results in some areas of ML, especially in empirically oriented deep learning papers, and, alarmingly, such practice seems to be tolerated by reviewers even at prime conferences.",2.1. Prevalence,[0],[0]
"For instance, what concerns models published on the popular Children’s Book Test dataset for Reading Comprehension (on which we run experiments later), none of the (more than ten) papers used any form of statistical testing or confidence intervals, and most reported only performance of the best single model without even mentioning the total number of experiments run.",2.1. Prevalence,[0],[0]
"These include papers published at NIPS (Hermann et al., 2015), ICLR (Hill et al., 2016; Munkhdalai & Yu, 2017), ACL (Chen et al., 2016; Dhingra et al., 2017; Cui et al., 2017), or EMNLP (Trischler et al., 2016).
",2.1. Prevalence,[0],[0]
"The same is true for the recently popular SQuAD dataset: for instance, none of the four papers (Yang et al., 2017; Wang & Jiang, 2017; Seo et al., 2017; Xiong et al., 2017) that published results on this dataset at ICLR 2017 has used any statistical testing or confidence intervals nor published mean (or otherwise aggregated) results across multiple runs.
",2.1. Prevalence,[0],[0]
"Let us look more generally at the example of ICLR 2017 (chosen as a deep-learning-focused conference featuring many empirical results – as a rough guide, 174 out of 194 ICLR papers have ""experiment"" in a (sub-)section heading).",2.1. Prevalence,[0],[0]
"Only 11 papers mention terms related to hypothesis testing4 and 11 contain the string ""confidence interval"".",2.1. Prevalence,[0],[0]
"Further details can be found in Appendix B.
While this is a rough and limited survey, it does suggest that while deep learning research is to a large extent an empirical science, statistical methods are often underused.
3.",2.1. Prevalence,[0],[0]
"Expected Best-out-of-n (Boon) Performance
The issues outlined above point to desiderata for a more suitable method of reporting an architecture’s performance.",2.1. Prevalence,[0],[0]
"It should provide information about general behaviour of the architecture under specified conditions, well characterizing
4This was checked by searching for any of the following strings: ""hypothesis test"", ""p-value"", ""t-test"" ""confidence level"", ""significance level"", ""ANOVA"", ""analysis of variance"", ""Wilcoxon"", ""sign test"".
",2.1. Prevalence,[0],[0]
the associated random performance distribution.,2.1. Prevalence,[0],[0]
"It should also be invariant under the number of experiments run and other similar variables.
",2.1. Prevalence,[0],[0]
"Given these requirements, traditional statistical measures, such as mean or median, probably come to mind of many readers.",2.1. Prevalence,[0],[0]
"They do indeed fix the above issues; still, they express only the performance of a typical member of the population.",2.1. Prevalence,[0],[0]
"However, in many ML applications, it may be the best model from a pool that is of interest.",2.1. Prevalence,[0],[0]
"When practitioners are choosing a model for deployment, they train multiple models and deploy the best-performing one 5.",2.1. Prevalence,[1.0],"['When practitioners are choosing a model for deployment, they train multiple models and deploy the best-performing one 5.']"
This gives some justification to reporting the performance of the best model and gives us a reason to attempt to fix its problems rather than completely dismiss it.,2.1. Prevalence,[0],[0]
"Such corrected best-model measure would be more informative than mean or median in these outlined situations.
",2.1. Prevalence,[0.9999999280231188],['Such corrected best-model measure would be more informative than mean or median in these outlined situations.']
"A natural way to improve comparability between models, each evaluated in a different number of experiments, is to normalize the results to the expected result if the number of experiments were the same, say n, which can be easily estimated if we run m experiments, m ≥",2.1. Prevalence,[0],[0]
n.,2.1. Prevalence,[0],[0]
"The greater the number of experiments m, the more robust the estimate of the expected best, which also helps us eliminate the problem of statistical robustness.",2.1. Prevalence,[0],[0]
"We are proposing the expected best-out-of-n performance, Boon, to be used where the performance of the best model from a pool seems as an appropriate measure.
",2.1. Prevalence,[1.000000115636901],"['We are proposing the expected best-out-of-n performance, Boon, to be used where the performance of the best model from a pool seems as an appropriate measure.']"
"Let us first examine how the expected best-out-of-n (Boon) performance relates to the (theoretical) performance distribution we are trying to characterize; we will then proceed with empirical estimation, which is of value in practice.",2.1. Prevalence,[0],[0]
"The calculations are not particularly innovative from statistical point of view and are close to many standard results from the field of Order Statistics (see for instance Arnold et al. (2008) for more context).
3.1.",2.1. Prevalence,[0],[0]
"Boon of a probability distribution
Showing how to calculate Boon of a known theoretical probability distribution will serve two purposes: Firstly, since we are proposing Boon as a way to characterize the performance distribution, this will make the relation between Boon and the performance distribution explicit.",2.1. Prevalence,[0],[0]
"Secondly, in some cases we may be able to make an assumption about the family to which the theoretical distribution belongs (e.g.
5This would usually be the case when a model is trained once and then deployed for longer-term usage, which may be the case for instance for Machine Translation systems.",2.1. Prevalence,[0],[0]
"In other cases, when it is practical to train only as single model instance due to hardware constraints (either because training is extremely costly, or because it needs to be done repeatedly, e.g. for individual customers), we may indeed be interested in a typical model and hence in mean or median performance.
",2.1. Prevalence,[0],[0]
we could assume it is approximately Gaussian).,2.1. Prevalence,[0],[0]
"The analytic calculation below will allow us to leverage this information when empirically estimating Boon by deducing a parametric estimator, which may be especially useful when our sample size m is small.",2.1. Prevalence,[0],[0]
"Let us first look at the simpler case of validation performance (that is, the case where we are choosing the best model with respect to the metric we are reporting) as it is easier to grasp: How do we calculate an expected best Boon(P)6 of independent identically distributed (i.i.d.)",3.1.1. SINGLE EVALUATION,[1.0],"['Let us first look at the simpler case of validation performance (that is, the case where we are choosing the best model with respect to the metric we are reporting) as it is easier to grasp: How do we calculate an expected best Boon(P)6 of independent identically distributed (i.i.d.)']"
"random variables X1, ..., Xn with probability distribution P (the performance distribution of an architecture) with a probability density function (p.d.f.)",3.1.1. SINGLE EVALUATION,[1.0],"['random variables X1, ..., Xn with probability distribution P (the performance distribution of an architecture) with a probability density function (p.d.f.)']"
f and a cumulative distribution function (c.d.f.),3.1.1. SINGLE EVALUATION,[0],[0]
F ?,3.1.1. SINGLE EVALUATION,[0],[0]
"In the case where best means maximal (minimum can be calculated similarly), the maximum max{X1, ..., Xn} has a c.d.f. equal to
Fmax(x) = P[max{X1, ..., Xn} ≤ x] = P[X1 ≤ x, ...,Xn ≤ x] = Fn(x) (1)
using the independence of the Xis in the last step.
",3.1.1. SINGLE EVALUATION,[0],[0]
"In the case of a continuous distribution, we can obtain the p.d.f.",3.1.1. SINGLE EVALUATION,[0],[0]
"of the maximum by simply differentiating with respect to x:
fmax(x) = d
dx Fmax(x) = nf(x)F
n−1(x)
",3.1.1. SINGLE EVALUATION,[0],[0]
"Using the p.d.f., we can now calculate the expected value of the maximum as Boon(P) = ∫ ∞ −∞ xfmax(x)dx = ∫ ∞ −∞ xnf(x)Fn−1(x)dx
(2)
We can get a precise numerical estimate of the above integrals in any major numerical computation package such as numpy.",3.1.1. SINGLE EVALUATION,[0],[0]
"For illustration, for the standard normal distribution we have Boo5 (N (0, 1))",3.1.1. SINGLE EVALUATION,[0],[0]
"≈ 1.163, Boo10 (N (0, 1))",3.1.1. SINGLE EVALUATION,[0],[0]
≈ 1.539.,3.1.1. SINGLE EVALUATION,[0],[0]
"More generally, Boon ( N (µ, σ2) ) can then be expressed as µ + σBoon (N (0, 1)).",3.1.1. SINGLE EVALUATION,[0],[0]
"Thanks to this form we can get numerical estimates of Boon ( N (µ, σ2) )",3.1.1. SINGLE EVALUATION,[0],[0]
"just by estimating the two usual parameters of the Gaussian, Boon (N (0, 1)) becoming just a constant coefficient if we fix n. The full details of calculation for the Gaussian distribution can be found in Appendix A.
",3.1.1. SINGLE EVALUATION,[0],[0]
"In the case of a discrete performance distribution, which will be useful for empirical estimation below, we get a prob-
6Using the overline to distinguish from the double validationtest evaluation case later.
",3.1.1. SINGLE EVALUATION,[0],[0]
"ability mass function
P[max{X1, . . .",3.1.1. SINGLE EVALUATION,[0],[0]
", Xn} = m] = P[max{X1, . . .",3.1.1. SINGLE EVALUATION,[0],[0]
", Xn} ≤ m]−P[max{X1, . . .",3.1.1. SINGLE EVALUATION,[0],[0]
", Xn} < m]
(3)
so if pj is the probability weight associated with value xj , i.e. P[Xi = xj ] = pj for all i, this gives us Boon(P) = ∑ i  ∑ j: xj≤xi pj n",3.1.1. SINGLE EVALUATION,[0],[0]
−  ∑ j: xj<xi pj nxi .,3.1.1. SINGLE EVALUATION,[0],[0]
(4),3.1.1. SINGLE EVALUATION,[0],[0]
"In the previous part, we were choosing the best model with respect to the metric whose expectation we were calculating.",3.2. Validation-test evaluation,[0],[0]
"Hence, that method can be used to calculate the expected best validation performance of n models.",3.2. Validation-test evaluation,[0],[0]
"In practice, the best model is usually chosen with respect to the validation performance, while the primary interest is in the corresponding test performance.",3.2. Validation-test evaluation,[0],[0]
"To calculate the expected test performance of the best-validation model, we need to substitute the direct value of x in Equations 2 and 4, with the expectation of the test performance Xtest conditional on the validation performance xval,
Etv (xval)",3.2. Validation-test evaluation,[0],[0]
":= E [Xtest|Xval = xval]
yielding an expression for the expected test performance of the best-validation model chosen from a pool of size n
Boon(P) = ∫ Etv(xval)dPval(xval) =∫ ∞
−∞ Etv(xval)nfval(xval)F
",3.2. Validation-test evaluation,[0],[0]
"n−1 val (xval)dxval (5)
where Pval is the marginal probability distribution of the validation performance.",3.2. Validation-test evaluation,[0],[0]
"Similar simple substitution can be done in the discrete case.
",3.2. Validation-test evaluation,[0],[0]
"Expanding the expression for the bivariate Gaussian distribution with marginal test performance with mean µtest, standard deviation σtest, and test-validation correlation ρ as in Appendix A.2 yields a convenient expression
Boon = µtest + ρ σtest Boon (N (0, 1)) , (6)
which can again be used for parametric estimation.",3.2. Validation-test evaluation,[0],[0]
We usually do not know the exact performance distribution of the model; we only have samples from this distribution – the results of our experiments.,3.3. Empirical estimation,[0],[0]
"In such case, we can estimate the expected maximum empirically, and in fact it is the
empirical estimates that are likely to be used in practice to compare models.
",3.3. Empirical estimation,[0],[0]
"To get a non-parametric estimator, for which we do not make any assumption about the family of the performance distribution, we take the empirical distribution arising from our sample as an approximation of the architecture’s true performance distribution, similarly to Bootstrap methods.",3.3. Empirical estimation,[0],[0]
The empirical performance distribution P̂ assigns a probability weight of 1m to each of our m samples.,3.3. Empirical estimation,[0],[0]
We approximate Boon of the true performance distribution by Boon of this empirical distribution.,3.3. Empirical estimation,[0],[0]
"For the uniform empirical distribution, all the pi in Equation 4 are equal to 1m .",3.3. Empirical estimation,[0],[0]
"Hence, if we rank our samples from worst-validation to best-validation as (xvalidi1 , x test i1 ), . . .",3.3. Empirical estimation,[0],[0]
", (xvalidim , x test im ), we get
B̂oon ( (xvalid1 , x test 1 ), . . .",3.3. Empirical estimation,[0],[0]
", (x valid m , x test m ) )
",3.3. Empirical estimation,[0],[0]
= m∑ j=1 (( j m )n,3.3. Empirical estimation,[0],[0]
− ( j − 1 m )n),3.3. Empirical estimation,[0],[0]
xtestij .,3.3. Empirical estimation,[0],[0]
"(7)
This estimator does not make any assumption about the performance distribution from which our observations are drawn.",3.3. Empirical estimation,[0],[0]
"If we do use such an assumption (e.g. we know that the performance distribution of our architecture usually belongs to a certain family, e.g. Gaussian), we can add information to our estimator and possibly get an even better estimate (i.e. one with lower sampling error).",3.3. Empirical estimation,[0],[0]
"For the Gaussian distribution, we can use the standard estimators of the parameters in Equation 6 to get a parametric estimator
µ̂test + ρ̂ σ̂test",3.3. Empirical estimation,[0],[0]
"Boon (N (0, 1))
where µ̂test, ρ̂ and σ̂test are standard estimators of mean, correlation, and standard deviation respectively.",3.3. Empirical estimation,[0],[0]
A similar parametric estimator could be calculated for other distributions.,3.3. Empirical estimation,[0],[0]
"Boon eliminates the problem of dependence on the number of experiments run, m. However, we still need to choose n, the number of experiments to which we normalize.",3.4. Choice of n,[0],[0]
"This is similar to the choice one is facing when using a quantile – should one use the 75% one, the 95% one, or some other?
",3.4. Choice of n,[0],[0]
The choice of n most useful to a reader is when n is the number of candidate models that a practitioner would train before choosing the best one for some target application.,3.4. Choice of n,[0],[0]
Such number will differ domain to domain and will heavily depend on the computational cost of training the specific architecture on the specific domain.,3.4. Choice of n,[0],[0]
"The n of interest may differ for each reader – ideally researchers should characterize the architecture’s performance distribution as fully as possible and the readers may be able to deduce the value of Boon for whichever n they choose (up to a limit).
Leaving an additional degree of freedom in the choice of metric creates a risk of cherry picking.",3.4. Choice of n,[0],[0]
"However, in many areas of machine learning, there already are many available metrics.",3.4. Choice of n,[0],[0]
"Still, the main reporting metric seems to quickly converge on each task.",3.4. Choice of n,[0],[0]
The first published paper makes a choice; the subsequent ones usually follow suit (else they risk a suspicion that the architecture is not competitive on the previous metric).,3.4. Choice of n,[0],[0]
"We believe similar convergence is likely for Boon on each task.
",3.4. Choice of n,[0],[0]
"In our experiments, we decided to use n = 5 – the AS Reader model which we use for our experiments takes about 2 hours to train on a single GPU, so someone replicating the Boo5 performance could expect to achieve it overnight, which seems a to be a reasonable requirement.",3.4. Choice of n,[0],[0]
Even Boon is just a single number whose estimate can be noisy.,3.5. Accounting for estimator uncertainty,[0],[0]
"Hence, with Boon, as well as with mean and other ways of aggregating results of a wider population, we should always use appropriate statistical methods when trying to compare the quantitative performance of a new model against a baseline.",3.5. Accounting for estimator uncertainty,[0],[0]
"This can be done using significance testing (such as the t-test), or with the help of confidence intervals, which seems to be the method preferred by a significant part of the scientific community (e.g. Gardner & Altman (1986) or Berrar & Lozano (2013)), since it allows us to disentangle the effect size from the uncertainty associated with noise and sample size.
",3.5. Accounting for estimator uncertainty,[0],[0]
"For some theoretical distributions, there exist ways to calculate the hypothesis test or confidence interval analytically (e.g. using the t-test or standard normal quantiles for the Gaussian).",3.5. Accounting for estimator uncertainty,[0],[0]
"However, in cases where the family of the performance distribution or of the estimator is not known, we need to resort to computational methods - usually Monte Carlo (if we do know at least the family of the performance distribution) or the Bootstrap (Efron, 1979) (if we do not).",3.5. Accounting for estimator uncertainty,[0],[0]
A brief description of how to calculate confidence intervals using the Bootstrap is provided in the Appendix.,3.5. Accounting for estimator uncertainty,[0],[0]
"Note: The data and code for their analysis can be found at http://gitlab.com/obajgar/boon, along with Python functions you can use to calculate Boon.
We have run several experiments to quantify the scope of the problems outlined in Section 2.",4. Experiment Results,[0],[0]
"We just briefly summarize the main results here for illustration; a more detailed description of the experiments and analysis in the form of an iPython notebook can be found in the Gitlab repository.
",4. Experiment Results,[0],[0]
"Performance variation To estimate the random variation of results, we repeatedly 7 trained models from two domains of deep learning: the ResNet (He et al., 2016) on the CIFAR-100 dataset (Krizhevsky & Hinton, 2009) to represent Image Recognition and the Attention Sum Reader (AS Reader) (Kadlec et al., 2016) on the Children’s Book Test Common Nouns (CBT CN) (Hill et al., 2016) to represent Reading Comprehension.",4. Experiment Results,[0],[0]
Each of these trainings generated a pair of a validation and test performances.,4. Experiment Results,[0],[0]
The resulting empirical performance distributions are illustrated in Figure 1.,4. Experiment Results,[0],[0]
"If we fix all hyper-parameters, the interquartile ranges of the models’ accuracies are 0.98% and 1.20% (absolute).",4. Experiment Results,[0],[0]
Compare this to the median differences between published results on these datasets: 0.86% and 1.15% respectively8.,4. Experiment Results,[0],[0]
"Hence, random variation in performance cannot be considered negligible as is now often done.",4. Experiment Results,[0],[0]
"Furthermore, if we allow the hyper-parameters to vary (in our case by random search), the result variance further increases, which further amplifies the outlined effects.",4. Experiment Results,[0],[0]
In the case of the AS Reader the interquartile range increased to 2.9% when we randomly picked hyper-parameters from a range applicable to training the model on a single GPU.,4. Experiment Results,[0],[0]
"However, note that the problem of result incomensurability due to hyper-parameter optimization is not the focus of this work.",4. Experiment Results,[0],[0]
"The method that we present here is still applicable to the problem in the case of random hyper-parameter sampling for which we include results, however we aim to compensate mainly for randomness due to parameter initialization and data shuf-
7Specifically, 74 times for Resnet, 370 times for the AS Reader with fixed hyperparameters, and 197 times for the AS Reader with random hyperparameters.
",4. Experiment Results,[0],[0]
"8We looked at results of successive architectures evaluated on the two tasks as listed in (Huang et al., 2017; Munkhdalai & Yu, 2017).",4. Experiment Results,[0],[0]
We sorted the results with respect to the test performance and then calculated the differences between successive models.,4. Experiment Results,[0],[0]
From these we calculated the median.,4. Experiment Results,[0],[0]
"Full details can be found in the Gitlab repository.
fling – which is however significant in itself, as we have just demonstrated.
",4. Experiment Results,[0],[0]
"Several other articles confirm significant variation in model performance due to different random seeds: e.g van den Berg et al. (2016) in Speech Recognition, Henderson et al. (2018) in Deep Reinforcement Learning, or Reimers & Gurevych (2017) in Named Entity Recognition.",4. Experiment Results,[0],[0]
"They all agree that reporting performance scores of single models is insufficient to characterize architecture performance.
",4. Experiment Results,[0],[0]
Estimator variance Figure 2 shows the 95% confidence intervals of best single model results compared to the Boo5 performance for a range of result-pool sizes m. This is shown for the cases of both strong and weak test-validation correlation.,4. Experiment Results,[0],[0]
In both cases Boo5 is significantly less noisy than the best-single-model result.,4. Experiment Results,[0],[0]
"In fact in the case of random hyper-parameter search, Boon shows even smaller variation than the mean (due to the negative skew of the performance distribution).
",4. Experiment Results,[0],[0]
"Best-model performance improves with the number of experiments We also mentioned that if only the performance of the best model is reported, the more experiments are run, the better the expected result.",4. Experiment Results,[0],[0]
"Figure 2b illustrates that this effect can indeed be fairly strong, if the validation performance is a good predictor of the test performance, as is the case of the AS Reader with random hyper-parameter search, where the expectation of the best single model performance increases from 61.3% if we train it once, to 63.3% if we train it 5 times, to 63.5% for 20 times.",4. Experiment Results,[0],[0]
This effect is further explained e.g. by Jensen & Cohen (2000).,4. Experiment Results,[0],[0]
"It gives a further argument for refraining from using this method and certainly also for publishing the number of experiments run, which is often not done.",4. Experiment Results,[0],[0]
"Boon is not subject to this effect.
",4. Experiment Results,[0],[0]
"10 20 30 40 50 # experiments
0.675
0.680
0.685
0.690
0.695
te st
a cc
ur ac
y
best single boo5 mean
(a) Resnet (fixed hyperparameters; low test-validation correlation)
0 20 40 60 80 100 # experiments
0.58
0.60
0.62
0.64
0.66
te st
a cc
ur ac
y
best single boo5 mean
(b) AS Reader (random hyperparameter sampling; high testvalidation correlation)
",4. Experiment Results,[0],[0]
Figure 2: Averages and 95% confidence intervals of test performance for three ways of aggregating results of multiple experiments for various numbers of experiments run.,4. Experiment Results,[0],[0]
Each confidence interval was constructed using smoothed9 Bootstrap sampling from our pool of 75 for Resnet and 197 experiments for the AS Reader with fixed and random hyperparameters respectively.,4. Experiment Results,[0],[0]
"Since we strongly encourage researchers to provide confidence intervals for their results, we provide and overview of how to construct them using the Bootstrap in Appendix D.1 .
",4. Experiment Results,[0],[0]
"Validation-test correlation However, note that the assumption that validation performance is a good predictor of test performance is sometimes not true.",4. Experiment Results,[0],[0]
"In the two cases with fixed hyper-parameters that we looked at, the Spearman correlation between validation and test results was only 0.10 and 0.18 respectively for the two models.",4. Experiment Results,[0],[0]
The correlation significantly increases if we allow the hyper-parameters to vary – to 0.83 for the AS Reader.,4. Experiment Results,[0],[0]
These results are also illustrated in Figure 1.,4. Experiment Results,[0],[0]
"Larger validation sets are also likely to improve this correlation, which can be understood as the degree of generalization from validation to test.",4. Experiment Results,[0],[0]
Note that the problem of increasing expected performance mentioned above is relevant only in the case of higher correlation between validation and test results.,4. Experiment Results,[0],[0]
"The effect becomes very strong in the case where the performance we are reporting is also used for choosing the best model, which emphasizes the need for honest separation of validation and test data.",4. Experiment Results,[0],[0]
Boon does fix the main flaws of reporting the best single model performance.,5. Discussion,[0],[0]
"However, let us have a look at some of its limitations.
",5. Discussion,[0],[0]
"Hyperparameter tuning This work does not fully compensate for improved expected results due to hyperparameter
9While Boon and mean could be sampled using vanilla Bootstrap, best-validation result is influenced only by a single value from the sample and hence uses only few values from the upper tier of our result pool, which makes our pool size insufficient.",5. Discussion,[0],[0]
"Hence we use Gaussian kernel smoothing (Scott, 1992) to expand our result pool.
tuning, nor was it its primary aim.",5. Discussion,[0],[0]
"Boon is appropriate in the case of random hyperparameter sampling, where the performances in different runs are independent.",5. Discussion,[0],[0]
"However, this is not the case for more advanced hyperparameter optimization methods.",5. Discussion,[0],[0]
"The primary focus of this work was on tackling variability due to random initialization, data shuffling, and similar sources, which we have shown to be significant in itself.",5. Discussion,[0],[0]
"Compensation for more advanced hyperparameter tuning (and ensuring the comparability of models in that case) is certainly a worthwhile area for future research.
",5. Discussion,[0],[0]
"Mean, median, and other alternatives We do not claim our method to be strictly superior to traditional ways of aggregating results, such as mean or quantiles.",5. Discussion,[0],[0]
"However, we have outlined a case where using Boon is justified – situations where a final model to be deployed can be chosen from a pool of trained candidates.",5. Discussion,[0],[0]
"In such case, Boon is easily interpretable and more informative than a performance of a typical model, expressed by mean or median.",5. Discussion,[0],[0]
"Hence, we think Boon is a useful addition to the methodological toolbox along existing methods.
",5. Discussion,[0],[0]
Just a single number Boon is still just a single number whose ability to characterize the performance distribution is limited by its single dimension.,5. Discussion,[0],[0]
"Paper authors should try to characterise the performance distribution as fully as possible, which may involve a histogram, mean, standard deviation, ideally along a dataset containing the results of all experiments, from which an interested reader may be able to deduce whichever characteristic she finds interesting.
",5. Discussion,[0],[0]
"Unfortunately, such characterization is usually lacking.
",5. Discussion,[0],[0]
"However, alongside this detailed characterization, describing an architecture’s performance by a single number still has its appeal, especially for the purpose of comparison among architectures and choosing the best one according to some criterion (in fact, each quantitative score can be understood as a proxy for ordering architectures with respect to such criterion of interest, such as expected performance of the best model out of n).",5. Discussion,[0],[0]
"We have explained why, in some cases, Boon may be useful for such purpose.
",5. Discussion,[0],[0]
"Computational cost Some may deem Boon impractical due to its requirement to train architectures many times, which may be very expensive in some cases.",5. Discussion,[0],[0]
"However, result stochasticity needs to be addressed to produce reliable results, and it is hard to imagine a general method to do so without repeated evaluation10.",5. Discussion,[0],[0]
Researchers can simply focus on architectures which they can evaluate properly given their resources.,5. Discussion,[0],[0]
"However, the main target of our criticism is not projects whose resources are stretched by a single training; it is projects that do have the necessary resources for multiple evaluations but use them to produce better-looking results rather than results that are more informative and robust.",5. Discussion,[0],[0]
Reporting just the best single model performance is not statistically sound.,6. Conclusion,[0],[0]
This practice in machine learning research needs to change if the research is to have lasting value.,6. Conclusion,[0],[0]
"Reviewers can play an important role in bringing this change.
",6. Conclusion,[0],[0]
"Still, asking for the performance of a best model out of n can have valid reasons.",6. Conclusion,[0],[0]
"For the situations where the best-model performance is indeed a good metric, we are suggesting Boon as a way to evaluate it properly.",6. Conclusion,[0],[0]
A. Boon of the Gaussian Distribution In this section we will calculate Boon of the Gaussian distribution.,Appendix,[0],[0]
"This can serve as a basis for a parametric estimator of Boon, when we assume a performance distribution to
be (approximately) Gaussian, which was the case of some of the performance distributions we have examined, for instance the AS Reader with fixed hyper-parameters.
A.1.",Appendix,[0],[0]
"Single evaluation dataset
In the simpler case in which the best model is chosen with respect to the same dataset on which the performance is then reported, we can substitute the p.d.f.",Appendix,[0],[0]
and c.d.f.,Appendix,[0],[0]
of the Gaussian distribution,Appendix,[0],[0]
"into Equation 2 to get
Boon(N (µ, σ2)) =∫ ∞ −∞ xn 1√ 2πσ2 e (x−µ)2 2σ2 Φn−1 ( x− µ σ ) dx (8)
where Φ is the c.d.f. of a standard normal random variable",Appendix,[0],[0]
.,Appendix,[0],[0]
"Substituting z = x−µσ , dx = σdz, yields∫ ∞
−∞ n(µ+ σz) 1√ 2πσ2 e z2 2 Φn−1 (z)σdz =
= µ ∫∞ −∞ n 1√ 2π e z2 2 Φn−1 (z) dz+
+σ ∫ ∞ −∞ nz 1√ 2π e z2 2 Φn−1 (z) dz = µ+σBoon",Appendix,[0],[0]
"(N (0, 1))
(9)
(the first integrand has the form of the p.d.f. found above and hence integrates to one) so the expected maximum is neatly expressed in terms of a maximum of a standard normal and is linearly proportional to both the mean and the standard deviation.",Appendix,[0],[0]
"Once n is fixed for comparison purposes, Boon (N (0, 1)) is just a constant, e.g. Boo5 (N (0, 1))",Appendix,[0],[0]
"≈ 1.163, Boo10 (N (0, 1))",Appendix,[0],[0]
≈ 1.539.,Appendix,[0],[0]
Let us turn to the case of reporting a test set performance of a best-validation model.,A.2. Test-validation evaluation,[0],[0]
"If we model the validation and test performances by a Bivariate Normal Distribution with validtest correlation ρ, means µval, µtest, and variances σ2val, σ 2 test, then given a validation performance xval, the test performance is distributed normally with conditional expectation
Etv(xval) = µtest + ρ σtest σval (xval − µval)
which gives
Boon(N (µ, σ2))",A.2. Test-validation evaluation,[0],[0]
=∫ ∞ −∞ ( µtest + ρ σtest σval (xval − µval) ),A.2. Test-validation evaluation,[0],[0]
n,A.2. Test-validation evaluation,[0],[0]
"·
· 1√ 2πσ2val e (x−µval) 2 2σ2val",A.2. Test-validation evaluation,[0],[0]
Φn−1 ( x− µval σval ),A.2. Test-validation evaluation,[0],[0]
dx .,A.2. Test-validation evaluation,[0],[0]
"(10)
Using the same two tricks as above, this can be simplified to
Boon(N (µ, σ2)) = µtest +ρ σtest Boon (N (0, 1))",A.2. Test-validation evaluation,[0],[0]
"(11)
where Boon (N (0, 1)) is the single-evaluation expected maximum of the standard normal distribution as defined above.",A.2. Test-validation evaluation,[0],[0]
"We downloaded the pdfs of all papers accepted to ICLR 201711, extracted text from them using the OpenSource Xpdf package12 and then searched the resulting text documents using the grep command as follows.
",B. Survey of ICLR 2017 Papers: Method,[0],[0]
"Firstly, to roughly estimate the usage of experiments in the papers, we searched for the capitalized string ""EXPERIMENT"" in the documents, since all (sub-)section headings are capitalized in the ICLR format.",B. Survey of ICLR 2017 Papers: Method,[0],[0]
This was matched in 174 documents.,B. Survey of ICLR 2017 Papers: Method,[0],[0]
"Further 6 contained the string ""EVALUATION"" yielding a total of 180 out of 194 papers containing one of the two strings, which suggests that many ICLR papers indeed have an empirical component, though our rough method is only very approximate.
",B. Survey of ICLR 2017 Papers: Method,[0],[0]
"We then searched for the string ""confidence interval"", which was matched in only 11 papers, and further 11 documents matched one of expressions related to hypothesis testing (curiously, a set completely disjoint from the ""confidence interval"" set).",B. Survey of ICLR 2017 Papers: Method,[0],[0]
"These terms were: ""hypothesis test"", ""p-value"", ""t-test"" ""confidence level"", ""significance level"", ""ANOVA"", ""analysis of variance"", ""Wilcoxon"", and ""sign test"".",B. Survey of ICLR 2017 Papers: Method,[0],[0]
This may actually be only an upper bound since mentioning the term somewhere in the paper does not necessarily mean that the method was employed in the experimental procedure.,B. Survey of ICLR 2017 Papers: Method,[0],[0]
"Note: The data and code for their analysis will be available at http://gitlab.com/obajgar/boon.
",C. Experiments: Details,[0],[0]
Here we provide further details of our experiments quantifying the extent of result stochasticity and the resulting effects.,C. Experiments: Details,[0],[0]
"To run our experiments we have chosen Open Source implementations13 of models from two popular domains of deep learning, namely ResNet (He et al., 2016) on the CIFAR-100 dataset (Krizhevsky & Hinton, 2009) for Image Classifica-
11Downloaded from https://openreview.net/group?id=ICLR.cc/ /2017/conference from sections ""Paper decision: Accept (Oral)"" and ""Paper decision:",C.1. Models,[0],[0]
"Accept (Poster)"".
12http://www.xpdfreader.com/; we used version 4.00.01 on Debian Linux 9.2.
13The source code for Resnet can be found at https://github.com/tensorflow/models/tree/ master/research/resnet; the code for the AS Reader at https://github.com/rkadlec/asreader.
tion and the AS Reader (Kadlec et al., 2016) on the CBT CN dataset (Hill et al., 2016) for Reading Comprehension.",C.1. Models,[0],[0]
"We believe these two models are representative of models in their respective areas – Resnet is based on a deep convolutional network architecture as most recent models in machine vision, while the AS Reader is based on a bidirectional GRU network with attention, as is the case for many models in Natural Language Processing.",C.1. Models,[0],[0]
"To collect the data for our experiments, we repeatedly trained the two models.",C.2. Data collection,[0],[0]
Each training instance had a different random parameter initialization and random data shuffling.,C.2. Data collection,[0],[0]
We evaluated the model on the validation and test datasets at least once per epoch.,C.2. Data collection,[0],[0]
"We then took the validation and test performance at the best-validation epoch as a data point for our further analyses.
",C.2. Data collection,[0],[0]
"All training was done on Ubuntu 14.04 on a single GPU per training, either Nvidia Tesla K80 or GTX 1080.
",C.2. Data collection,[0],[0]
C.2.1.,C.2. Data collection,[0],[0]
"RESNET
Resnet was trained with a single set of hyperparameters, the default ones for the above Open Source implementation.",C.2. Data collection,[0],[0]
That means 5 residual units resulting in a 32-layer Resnet.,C.2. Data collection,[0],[0]
"The model was trained using the 0.9 momentum optimizer, with batch size 128, initial learning rate of 0.1 lowered to 0.01 after 40,000 steps and to 0.001 after 60,000 steps.",C.2. Data collection,[0],[0]
"Data augmentation included padding to 36x36 and then random cropping, horizontal flipping and per-image whitening.",C.2. Data collection,[0],[0]
"L2 regularization weight was set 0.002.
",C.2. Data collection,[0],[0]
Training was done using Tensorflow 1.3.,C.2. Data collection,[0],[0]
The AS Reader was trained in two different settings.,C.3. AS Reader,[0],[0]
"Firstly 370 times with hyper-parameters fixed to embedding dimension of 128 and 384 hidden dimensions in the GRU units, with all other hyper-parameters as used in the original AS Reader paper (Kadlec et al., 2016).
",C.3. AS Reader,[0],[0]
"In the second setting, the hyper-parameters for each training instance were chosen randomly from the following ranges:",C.3. AS Reader,[0],[0]
"The batch size was chosen from the range [16, 128], and the embedding size and hidden state size were each chosen from the range",C.3. AS Reader,[0],[0]
"[16, 512] with the log2 value of the parameter being distributed uniformly in the interval.",C.3. AS Reader,[0],[0]
"Parameters from these ranges worked reasonably well in our preliminary experiments.
",C.3. AS Reader,[0],[0]
"Training was done using Theano 0.9.0 and Blocks 0.2.0.
C.4.",C.3. AS Reader,[0],[0]
"Performance distribution results
Figure 1 plots the histograms of test performances of the evaluated models.",C.3. AS Reader,[0],[0]
"The mean test accuracy for Resnet was 68.41% with standard deviation of 0.67% (absolute), the range was 67.31% − 69.41%.",C.3. AS Reader,[0],[0]
For AS reader with fixed hyperparameters the mean was 63.16% with standard deviation 0.94% and range of 61.52% − 64.60%.,C.3. AS Reader,[0],[0]
"In the case of random hyper-parameter search the mean was 61.26%, standard deviation 2.48%, and values ranged from 56.61% to 64.01%.
",C.3. AS Reader,[0],[0]
"In both cases with fixed hyper-parameters the collected results are consistent with coming from a Gaussian distribution according to the Anderson-Darling test14 (Anderson & Darling, 1954); the histograms also make it appear plausible that the performance distribution is approximately Gaussian.",C.3. AS Reader,[0],[0]
"This is not the case for the random hyper-parameter search where the distribution has a clear negative skew.
",C.3. AS Reader,[0],[0]
"To put the above numbers into context, we also examined the margin of improvement of successive architectures published on the corresponding datasets, as listed in (Munkhdalai & Yu, 2017; Huang et al., 2017).",C.3. AS Reader,[0],[0]
We sorted the results with respect to the test performance and then calculated the differences between successive models.,C.3. AS Reader,[0],[0]
"The median difference was for 0.86% for CIFAR-100 and 1.15% for CBT CN.
",C.3. AS Reader,[0],[0]
Note that the median differences are smaller than two standard deviations for each model.,C.3. AS Reader,[0],[0]
Two standard deviations from the mean approximately give the 95% confidence interval for a Gaussian distribution – hence we could typically fit three successive published results within the width of one such confidence interval.,C.3. AS Reader,[0],[0]
"The magnitude of the performance variation due to random initialization and data shuffling is therefore not negligible compared to the improvements in performance, which often hold an important place within articles in which they are presented.",C.3. AS Reader,[0],[0]
"We hence think it is inappropriate to completely ignore this random variation in evaluation protocols, which is currently the usual practice.",C.3. AS Reader,[0],[0]
The best model is usually selected using validation performance 15.,C.5. Test-validation correlation,[0],[0]
This practice is based on the assumption that the validation accuracy is a reasonably good predictor of test accuracy.,C.5. Test-validation correlation,[0],[0]
"The results of our experiments, illustrated also in Figure 1, suggest that this assumption holds for performance variation due to hyper-parameter choice.",C.5. Test-validation correlation,[0],[0]
"However, if we fix the hyper-parameters, the correlation almost disappears.",C.5. Test-validation correlation,[0],[0]
"To some extent, this implies that selecting the best validation
14That is, despite the relatively large sample sizes, gaussianity cannot be ruled out at 0.05 significance level based on collected evidence.
15Or at least should be.
model means we are picking randomly with respect to the test performance.",C.5. Test-validation correlation,[0],[0]
"Since we are picking from a random test performance distribution, this further calls for better characterization of the distribution than a single instance drawn from it.
",C.5. Test-validation correlation,[0],[0]
"On the other hand if the correlation is strong, as seems to be the case if we do perform hyper-parameter search, we face the second problem with reporting the best-validation performance:
C.6.",C.5. Test-validation correlation,[0],[0]
"Effect of the number of experiments
If the validation performance is a good predictor of the test performance, then the more models we train the better the best-validation model is likely to be even on the test set since we are able to select models high up the right tail of the performance distribution.",C.5. Test-validation correlation,[0],[0]
"This effect has been described in more detail in (Jensen & Cohen, 2000), though with focus on induction algorithms; here we present an estimate of its effect in the case of Resnet and AS Reader.
To test this effect we took the pool of trained models.",C.5. Test-validation correlation,[0],[0]
"For eachm in the range from 1 to 50 (or 100 for the AS Reader), we randomly sampled 100, 000 samples of size m from the pool, and selected the best-validation model from each sample.",C.5. Test-validation correlation,[0],[0]
"The mean test performance across the 100, 000 samples for each m is plotted in Figure 2.
",C.5. Test-validation correlation,[0],[0]
"The results show that when there is suitable correlation between validation and test performances, increasing the number of experiments does increase the expected performance of the best-validation model.",C.5. Test-validation correlation,[0],[0]
"This makes the number of experiments an important explanatory variable, which however usually goes unreported.",C.5. Test-validation correlation,[0],[0]
"Furthermore, it makes results reported by different research teams not directly comparable.",C.5. Test-validation correlation,[0],[0]
"Finally, it gives an advantage to those that can run more experiments.",C.5. Test-validation correlation,[0],[0]
We believe that this again makes the practice of reporting the performance of the best single model unsuitable.,C.5. Test-validation correlation,[0],[0]
"If an estimator characterizing a performance distribution, say B̂oon or average, is calculated from experimental observations, it is subject to random variation, so if another research team tries to reproduce the experiments, they generally get a different estimate.",D.1. Confidence intervals,[0],[0]
"The more observations are collected, the more precise the estimate generally is.",D.1. Confidence intervals,[0],[0]
Confidence intervals provide a natural way to express this uncertainty.,D.1. Confidence intervals,[0],[0]
"Their usage also gives a sense whether the number of performed experiments was sufficient to reduce the uncertainly to a reasonable level, which is again not frequently addressed in ML papers.
",D.1. Confidence intervals,[0],[0]
The construction of the confidence interval would be trivial if we knew the distribution from which our estimate was drawn (as opposed to the distribution of the performance!),D.1. Confidence intervals,[0],[0]
"– it is simply the interval between the appropriate quantiles, e.g. the 2.5th and 97.5th quantiles in the case of the 95% confidence interval.",D.1. Confidence intervals,[0],[0]
Such distribution has been studied extensively for instance in the case of a mean of Gaussian random variables.,D.1. Confidence intervals,[0],[0]
"However, in other cases, it is not known.",D.1. Confidence intervals,[0],[0]
"If we know at least the distribution from which the individual observations were drawn, we can use Monte Carlo methods to precisely estimate the confidence interval; however, if we are not able to make an assumption about the underlying distribution, we need to use only what we have: our samples from the distribution.",D.1. Confidence intervals,[0],[0]
"In such case the variability of our estimator can be approximated using the Bootstrap (Efron, 1979) or similar methods.
",D.1. Confidence intervals,[0],[0]
"The Bootstrap consists of repeatedly sampling with replacement m random observations from our pool of m observations, say B times.",D.1. Confidence intervals,[0],[0]
"Each such sample is then used to calculate an estimate of our quantity of interest, say Boon or mean.",D.1. Confidence intervals,[0],[0]
This creates a sample of B values of the estimator.,D.1. Confidence intervals,[0],[0]
"The confidence interval can then be easily estimated taking the appropriate quantiles from this resulting Bootstrap distribution of the estimator, which should be approximating the unknown underlying sampling distribution.",D.1. Confidence intervals,[0],[0]
"The Bootstrap distribution has been shown to converge to the true underlying performance distribution.
",D.1. Confidence intervals,[0],[0]
"If we know the underlying distribution (up to some parameters), we can estimate its parameters and then generate a simulated Monte Carlo sample from the distribution, which can be used to calculate a sample of the estimator and the corresponding confidence interval in a similar way as above
with the advantage of the distribution being smoother.
",D.1. Confidence intervals,[0],[0]
"Beside estimating the confidence interval for the value of Boon or mean itself, either re-sampling method can be used to construct a confidence interval for the relative improvement of the newly proposed architecture compared to a baseline.",D.1. Confidence intervals,[0],[0]
The improvement can then be considered significant if zero is not included in the confidence interval.,D.1. Confidence intervals,[0],[0]
"More details on constructing Bootstrap confidence intervals can be found in many standard texts on computational statistics, for instance in (Efron, 1987).
",D.1. Confidence intervals,[0],[0]
"For illustration, we calculated the Bootstrap confidence interval for several sample sizes m for Resnet and the AS Reader.",D.1. Confidence intervals,[0],[0]
"Each was constructed using B = 100, 000.",D.1. Confidence intervals,[0],[0]
The results are plotted in Figure 2.,D.1. Confidence intervals,[0],[0]
"Figure 3 shows the comparison of the non-parametric and Gaussian parametric estimators of Boon, both introduced in Section 3.3, in terms of their variance for various sample sizes.",E. Comparison of estimators,[0],[0]
The parametric estimator shows a somewhat lower variance.,E. Comparison of estimators,[0],[0]
"This is an advantage if the performance distribution is indeed approximately Gaussian, which is the case for both cases with fixed hyperparameters that we tested in our experiments.",E. Comparison of estimators,[0],[0]
"However, this can introduce bias if the true performance distribution differs from the theoretical distribution assumed by a parametric estimator, so one should be prudent to use it.",E. Comparison of estimators,[0],[0]
"We point out important problems with the common practice of using the best single model performance for comparing deep learning architectures, and we propose a method that corrects these flaws.",abstractText,[0],[0]
"Each time a model is trained, one gets a different result due to random factors in the training process, which include random parameter initialization and random data shuffling.",abstractText,[0],[0]
Reporting the best single model performance does not appropriately address this stochasticity.,abstractText,[0],[0]
We propose a normalized expected best-out-of-n performance (Boon) as a way to correct these problems.,abstractText,[0],[0]
A Boo(n) for Evaluating Architecture Performance,title,[0],[0]

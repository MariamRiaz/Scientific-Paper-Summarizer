0,1,label2,summary_sentences
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 78–88 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Word Sense Disambiguation (WSD) is a key task in computational lexical semantics, inasmuch as it addresses the lexical ambiguity of text by making explicit the meaning of words occurring in a given context (Navigli, 2009).",1 Introduction,[0],[0]
"Anyone who has struggled with frustratingly unintelligible translations from an automatic system, or with the meaning bias of search engines, can understand the importance for an intelligent system to go beyond the surface appearance of text.
",1 Introduction,[0],[0]
There are two mainstream lines of research in WSD: supervised and knowledge-based WSD.,1 Introduction,[0],[0]
"Supervised WSD frames the problem as a classical machine learning task in which, first a training phase occurs aimed at learning a classification model from sentences annotated with word senses and, second the model is applied to previouslyunseen sentences focused on a target word.",1 Introduction,[0],[0]
"A key
difference from many other problems, however, is that the classes to choose from (i.e., the senses of a target word) vary for each word, therefore requiring a separate training process to be performed on a word by word basis.",1 Introduction,[0],[0]
"As a result, hundreds of training instances are needed for each ambiguous word in the vocabulary.",1 Introduction,[0],[0]
"This would necessitate a million-item training set to be manually created for each language of interest, an endeavour that is currently beyond reach even in resource-rich languages like English.
",1 Introduction,[0],[0]
"The second paradigm, i.e., knowledge-based WSD, takes a radically different approach: the idea is to exploit a general-purpose knowledge resource like WordNet (Fellbaum, 1998) to develop an algorithm which can take advantage of the structural and lexical-semantic information in the resource to choose among the possible senses of a target word occurring in context.",1 Introduction,[0],[0]
"For example, a PageRank-based algorithm can be developed to determine the probability of a given sense being reached starting from the senses of its context words.",1 Introduction,[0],[0]
"Recent approaches of this kind have been shown to obtain competitive results (Agirre et al., 2014; Moro et al., 2014).",1 Introduction,[0],[0]
"However, due to its inherent nature, knowledge-based WSD tends to adopt bag-of-word approaches which do not exploit the local lexical context of a target word, including function and collocation words, which limits this approach in some cases.
",1 Introduction,[0],[0]
"In this paper we get the best of both worlds and present Train-O-Matic, a novel method for generating huge high-quality training sets for all the words in a language’s vocabulary.",1 Introduction,[0],[0]
"The approach is language-independent, thanks to its use of a multilingual knowledge resource, BabelNet (Navigli and Ponzetto, 2012), and it can be applied to any kind of corpus.",1 Introduction,[0],[0]
"The training sets produced with Train-O-Matic are shown to provide competitive performance with those of manually and semi-
78
automatically tagged corpora.",1 Introduction,[0],[0]
"Moreover, state-ofthe-art performance is also reported for low resourced languages (i.e., Italian and Spanish) and domains, where manual training data is not available.",1 Introduction,[0],[0]
"In this Section we present Train-O-Matic, a language-independent approach to the automatic construction of a sense-tagged training set.",2 Building a Training Set from Scratch,[0],[0]
"TrainO-Matic takes as input a corpus C (e.g., Wikipedia) and a semantic network G = (V,E).",2 Building a Training Set from Scratch,[0],[0]
"We assume a WordNet-like structure of G, i.e., V is the set of concepts (i.e., synsets) such that, for each word w in the vocabulary, Senses(w) is the set of vertices in V that are expressed by w, e.g., the WordNet synsets that include w as one of their senses.
",2 Building a Training Set from Scratch,[0],[0]
"Train-O-Matic consists of three steps:
• Lexical profiling: for each vertex in the semantic network, we compute its Personalized PageRank vector, which provides its lexicalsemantic profile (Section 2.1).
",2 Building a Training Set from Scratch,[0],[0]
"• Sentence scoring: For each sentence containing a word w, we compute a probability distribution over all the senses of w based on its context (Section 2.2).
",2 Building a Training Set from Scratch,[0],[0]
"• Sentence ranking and selection: for each sense s of a word w in the vocabulary, we select those sentences that are most likely to use w in the sense of s (Section 2.3).",2 Building a Training Set from Scratch,[0],[0]
In terms of semantic networks the probability of reaching a node v′ starting from v can be interpreted as a measure of relatedness between the synsets v,2.1 Lexical profiling,[0],[0]
and v′.,2.1 Lexical profiling,[0],[0]
"Thus we define the lexical profile of a vertex v in a graph G = (V,E) as the probability distribution over all the vertices v′ in the graph.",2.1 Lexical profiling,[0],[0]
"Such distribution is computed by applying the Personalized PagaRank algorithm, a variant of the traditional PageRank (Brin and Page, 1998).",2.1 Lexical profiling,[0.9583737316215586],"['As discussed by Moosavi and Strube (2017a), there is a large lexical overlap between the coreferring mentions of the CoNLL training and evaluation sets.']"
"While the latter is equivalent to performing random walks with uniform restart probability on every vertex at each step, PPR, on the other hand, makes the restart probability non-uniform, thereby concentrating more probability mass in the surroundings of those vertices having higher restart
probability.",2.1 Lexical profiling,[0],[0]
"Formally, (P)PR is computed as follows:
v(t+1) =",2.1 Lexical profiling,[0],[0]
"(1− α)v(0) + αMv(t) (1)
where M is the row-normalized adjacency matrix of the semantic network, the restart probability distribution is encoded by vector v(0), and α is the well-known damping factor usually set to 0.85 (Brin and Page, 1998).",2.1 Lexical profiling,[0],[0]
"If we set v(0) to a unit probability vector (0, . . .",2.1 Lexical profiling,[0],[0]
", 0, 1, 0, . . .",2.1 Lexical profiling,[0],[0]
", 0), i.e., restart is always on a given vertex, PPR outputs the probability of reaching every vertex starting from the restart vertex after a certain number of steps.",2.1 Lexical profiling,[0],[0]
"This approach has been used in the literature to create semantic signatures (i.e., profiles) of individual concepts, i.e., vertices of the semantic network (Pilehvar et al., 2013), and then to determine the semantic similarity of concepts.",2.1 Lexical profiling,[0],[0]
"As also done by Pilehvar and Collier (2016), we instead use the PPR vector as an estimate of the conditional probability of a word w′",2.1 Lexical profiling,[0],[0]
"given the target sense1 s ∈ V of word w:
P (w′|s, w) = maxs′∈Senses(w′) vs(s ′)
Z (2)
where Z = ∑
w” P (w”|s, w) is a normalization constant, vs is the vector resulting from an adequate number of random walks used to calculate PPR, and vs(s′) is the vector component corresponding to sense s′.",2.1 Lexical profiling,[0],[0]
"To fix the number of iterations needed to have a sufficiently accurate vector, we follow Lofgren et al. (2014) and set the error δ = 0.00001 and the number of iterations to 1 δ = 100, 000.
",2.1 Lexical profiling,[0],[0]
As a result of this lexical profiling step we have a probability distribution over vocabulary words for each given word sense of interest.,2.1 Lexical profiling,[0],[0]
The objective of the second step is to score the importance of word senses for each of the corpus sentences which contain the word of interest.,2.2 Sentence scoring,[0],[0]
Given a sentence σ =,2.2 Sentence scoring,[0],[0]
"w1, w2, . .",2.2 Sentence scoring,[0],[0]
.,2.2 Sentence scoring,[0],[0]
", wn, for a given target wordw in the sentence (w ∈ σ), and for each of its senses s ∈ Senses(w), we compute the probability P (s|σ,w).",2.2 Sentence scoring,[0],[0]
"Thanks to Bayes’ theorem we can determine the probability of sense s of w given the
1Note that we use senses and concepts (synsets) interchangeably, because – given a word – a word sense unambiguously determines a concept (i.e., the synset it is contained in) and vice versa.
sentence as follows:
P (s|σ,w) =",2.2 Sentence scoring,[0],[0]
"P (σ|s, w)P (s|w) P (σ|w) (3)
= P (w1, . . .",2.2 Sentence scoring,[0],[0]
", wn|s, w)P (s|w) P (w1, . . .",2.2 Sentence scoring,[0],[0]
", wn|w) ∝",2.2 Sentence scoring,[0],[0]
"P (w1, . .",2.2 Sentence scoring,[0],[0]
.,2.2 Sentence scoring,[0],[0]
", wn|s, w)P (s|w) (4) ≈ P (w1|s, w) . . .",2.2 Sentence scoring,[0],[0]
"P (wn|s, w)P (s|w)
(5)
where Formula 4 is proportional to the original probability (due to removing the constant in the denominator) and is approximated with Formula 5 due to the assumption of independence of the words in the sentence.",2.2 Sentence scoring,[0],[0]
"P (wi|s, w) is calculated as in Formula 2 and P (s|w) is set to 1/|Senses(w)| (recall that s is a sense of w).",2.2 Sentence scoring,[0],[0]
"For example, given the sentence σ =",2.2 Sentence scoring,[0],[0]
"“A match is a tool for starting a fire”, the target word w = match and its set of senses Smatch = {s1match, s2match}, where s1match is the sense of lighter and s2match is the sense of game match, we want to calculate the probability of each simatch ∈ Smatch of being the correct sense of match in the sentence σ.",2.2 Sentence scoring,[0],[0]
"Following Formula 5 we have:
P (s1match|σ,match)",2.2 Sentence scoring,[0],[0]
"≈ P (tool|s1match,match) · P (start|s1match,match) · P (fire|s1match,match) · P (s1match|match) = 2.1 · 10−4 · 2 · 10−3 · 10−2 · 5 · 10−1 = 2.1 · 10−9
P (s2match|σ,match)",2.2 Sentence scoring,[0],[0]
"≈ P (tool|s2match,match) ·",2.2 Sentence scoring,[0],[0]
"P (start|s2match,match) · P (fire|s2match,match) · P (s2match|match) = 10−5 · 2.9 · 10−4 · 10−6 · 5 · 10−1 = 1.45 · 10−15
As can be seen, the first sense of match has a much higher probability due to its stronger relatedness to the other words in the context (i.e. start, fire and tool).",2.2 Sentence scoring,[0],[0]
Note also that all the probabilities for the second sense are at least one magnitude less than the probability of the first sense.,2.2 Sentence scoring,[0],[0]
"Finally, for a given word w and a given sense s1 ∈ Senses(w), we score each sentence σ in which w appears and s1 is its most likely sense according to a formula that takes into account the difference between the first (i.e., s1) and the second most likely sense of w in σ:
∆s1(σ)",2.3 Sense-based sentence ranking and selection,[0],[0]
"= P (s1|σ,w)− P (s2|σ,w) (6) where s1 = arg maxs∈Senses(w) P (s|σ,w), and s2 = arg maxs∈Senses(w)\{s1} P (s|σ,w).",2.3 Sense-based sentence ranking and selection,[0],[0]
We then sort all sentences based on ∆s1(·) and return a ranked list of sentences where word w is most likely to be sense-annotated with s1.,2.3 Sense-based sentence ranking and selection,[0],[0]
"Although we recognize that other scoring strategies could have been used, this was experimentally the most effective one when compared to alternative strategies, i.e., the sense probability, the number of words related to the target word w, the sentence length or a combination thereof.",2.3 Sense-based sentence ranking and selection,[0],[0]
"In the previous Section we assumed that WordNet was our semantic network, with synsets as vertices and edges represented by its semantic relations.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"However, while its lexical coverage is high, with a rich set of fine-grained synsets, at the relation level WordNet provides mainly paradigmatic information, i.e., relations like hypernymy (is-a) and meronymy (part-of).",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"It lacks, on the other hand, syntagmatic relations, such as those that connect verb synsets to their arguments (e.g., the appropriate senses of eatv and foodn), or pairs of noun synsets (e.g., the appropriate senses of busn and drivern).
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Intuitively, Train-O-Matic would suffer from such a lack of syntagmatic relations, as the relevance of a sense for a given word in a sentence depends directly on the possibility of visiting senses of the other words in the same sentence (cf.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
Formula 5) via random walks as calculated with Formula 1.,3 Creating a Denser and Multilingual Semantic Network,[0],[0]
Such reachability depends on the connections available between synsets.,3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Because syntagmatic relations are sparse in WordNet, if it was used on its own, we would end up with a poor ranking of sentences for any given word sense.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Moreover, even though the methodology presented in Section 2 is languageindependent, Train-O-Matic would lack informa-
tion (e.g. senses for a word in an arbitrary vocabulary) for languages other than English.
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"To cope with these issues, we exploit BabelNet,2 a huge multilingual semantic network obtained from the automatic integration of WordNet, Wikipedia, Wiktionary and other resources (Navigli and Ponzetto, 2012), and create the BabelNet subgraph induced by the WordNet vertices.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
The result is a graph whose vertices are BabelNet synsets that contain at least one WordNet synset and whose edge set includes all those relations in BabelNet coming either from WordNet itself or from links in other resources mapped to WordNet (such as hyperlinks in a Wikipedia article connecting it to other articles).,3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"The greatest contribution of syntagmatic relations comes, indeed, from Wikipedia, as its articles are linked to related articles (e.g., the English Wikipedia Bus article3 is linked to Passenger, Tourism, Bus lane, Timetable, School, and many more).
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Because not all Wikipedia (and other resources’) pages are connected with the same degree of relatedness (e.g., countries are often linked, but they are not necessarily closely related to the source article in which the link occurs), we apply the following weighting strategy to each edge (s, s′) ∈ E of our WordNet-induced subgraph of BabelNet G = (V,E):
w(s, s′) =",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"{ 1 (s, s′) ∈ E(WordNet)",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"WO(s, s′)",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"otherwise
(7) where E(WordNet) is the edge set of the original WordNet graph andWO(s, s′) is the weighted
2http://babelnet.org 3Retrieved on February 3rd, 2017.
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"overlap measure which calculates the similarity between two synsets:
WO(s, s′) = ∑|S|",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"i=1(r 1 i + r
2 i ) −1∑|S|
i=1(2i)−1
where r1i and r 2",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"i are the rankings of the i-th synsets in the set S of the components in common between the vectors associated with s and s′, respectively.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Because at this stage we still have to calculate our synset vector representation, we use the precomputed NASARI vectors (Camacho-Collados et al., 2015) to calculate WO.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"This choice is due to WO’s higher performance over cosine similarity for vectors with explicit dimensions (Pilehvar et al., 2013).
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"As a result, each row of the original adjacency matrix M of G will be replaced with the weights calculated in Formula 7 and then normalized in order to be ready for PPR calculation (see Formula 1).",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"An idea of why a denser semantic network has more useful connections and thus leads to better results is provided by the example in
iment for the animal, and operating system and Windows for the device sense, among others).",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Corpora for sense annotation We used two different corpora to extract sentences: Wikipedia and the United Nations Parallel Corpus (Ziemski et al., 2016).",4 Experimental Setup,[0],[0]
"The first is the largest and most up-to-date encyclopedic resource, containing definitional information, the second, on the other hand, is a public collection of parliamentary documents of the United Nations.",4 Experimental Setup,[0],[0]
"The application of TrainO-Matic to the two corpora produced two senseannotated datasets, which we named T-O-MWiki and T-O-MUN , respectively.
",4 Experimental Setup,[0],[0]
"Semantic Network We created sense-annotated corpora with Train-O-Matic both when using PPR vectors computed from vanilla WordNet and when using WordNetBN , our denser network obtained from the WordNet-induced subgraph of BabelNet (see Section 3).
",4 Experimental Setup,[0],[0]
"Gold standard datasets We performed our evaluations using the framework made available by Raganato et al. (2017a) on five different allwords datasets, namely: the Senseval-2 (Edmonds and Cotton, 2001), Senseval-3 (Snyder and Palmer, 2004), SemEval-2007 (Pradhan et al., 2007), SemEval-2013 (Navigli et al., 2013) and SemEval-2015 (Moro and Navigli, 2015)",4 Experimental Setup,[0],[0]
WSD datasets.,4 Experimental Setup,[0],[0]
"We focused on nouns only, given the fact that Wikipedia provides connections between nominal synsets only, and therefore contributes mainly to syntagmatic relations between nouns.
",4 Experimental Setup,[0],[0]
"Comparison sense-annotated corpora To show the impact of our T-O-M corpora in WSD, we compared its performance on the above gold standard datasets, against training with:
• SemCor (Miller et al., 1993), a corpus containing about 226,000 words annotated manually with WordNet senses.
",4 Experimental Setup,[0],[0]
"• One Million Sense-Tagged Instances (Taghipour and Ng, 2015, OMSTI), a sense-annotated dataset obtained via a semi-automatic approach based on the disambiguation of a parallel corpus, i.e., the United Nations Parallel Corpus, performed by exploiting manually translated word senses.",4 Experimental Setup,[0],[0]
"Because OMSTI integrates SemCor
to increase coverage, to keep a level playing field we excluded the latter from the corpus.
",4 Experimental Setup,[0],[0]
"We note that T-O-M, instead, is fully automatic and does not require any WSD-specific human intervention nor any aligned corpus.
Reference system In all our experiments, we used It Makes Sense (Zhong and Ng, 2010, IMS), a state-of-the-art WSD system based on linear Support Vector Machines, as our reference system for comparing its performance when trained on TO-M, against the same WSD system trained on other sense-annotated corpora (i.e., SemCor and OMSTI).",4 Experimental Setup,[0],[0]
"Following the WSD literature, unless stated otherwise, we report performance in terms of F1, i.e., the harmonic mean of precision and recall.
",4 Experimental Setup,[0],[0]
"We note that it is not the purpose of this paper to show that T-O-M, when integrated into IMS, beats all other configurations or alternative systems, but rather to fully automatize the WSD pipeline with performances which are competitive with the state of the art.
",4 Experimental Setup,[0],[0]
Baseline,4 Experimental Setup,[0],[0]
"As a traditional baseline in WSD, we used the Most Frequent Sense (MFS) baseline given by the first sense in WordNet.",4 Experimental Setup,[0],[0]
"The MFS is a very competitive baseline, due to the sense skewness phenomenon in language (Navigli, 2009).
",4 Experimental Setup,[0],[0]
"Number of training sentences per sense Given a target word w, we sorted its senses Senses(w) following the WordNet ordering and selected the top ki training sentences for the i-th sense according to Formula 6, where:
ki = 1 iz ∗K",4 Experimental Setup,[0],[0]
"(8)
with K = 500 and z = 2 which were tuned on a separate small in-house development dataset5.",4 Experimental Setup,[0],[0]
The first result we report regards the impact of vanilla WordNet vs. our WordNet-induced subgraph of BabelNet (WordNetBN ) when calculating PPR vectors.,5.1 Impact of syntagmatic relations,[0],[0]
"As can be seen from Table 2 – which shows the performance of the T-O-MWiki corpora generated with the two semantic networks – using WordNet for PPR computation decreases
550 word-sense pairs annotated manually.
",5.1 Impact of syntagmatic relations,[0],[0]
"the overall performance of IMS from 0.5 to around 4 points across the five datasets, with an overall loss of 1.6 F1 points.",5.1 Impact of syntagmatic relations,[0],[0]
Similar performance losses were observed when using T-O-MUN (see Table 3).,5.1 Impact of syntagmatic relations,[0],[0]
This corroborates our hunch discussed in Section 3 that a resource like BabelNet can contribute important syntagmatic relations that are beneficial for identifying (and ranking high) sentences which are semantically relevant for the target word sense.,5.1 Impact of syntagmatic relations,[0],[0]
"In the following experiments, we report only results using WordNetBN .",5.1 Impact of syntagmatic relations,[0],[0]
"We now move to comparing the performance of T-O-M, which is fully automatic, against corpora which are annotated manually (SemCor) and semi-automatically (OMSTI).",5.2 Comparison against sense-annotated corpora,[0],[0]
"In Table 3 we show the F1-score of IMS on each gold standard dataset in the evaluation framework and on all datasets merged together (last row), when it is trained with the various corpora described above.
",5.2 Comparison against sense-annotated corpora,[0],[0]
"As can be seen, T-O-MWiki and T-O-MUN obtain higher performance than OMSTI (up to 5.5 points above) on 3 out of 5 datasets, and, overall, T-O-MWiki scores 1 point above OMSTI.",5.2 Comparison against sense-annotated corpora,[0],[0]
"The MFS is in the same ballpark as T-O-MWiki, performing better on some datasets and worse on others.",5.2 Comparison against sense-annotated corpora,[0],[0]
We note that IMS trained on T-O-MWiki succeeds in surpassing or obtaining the same results as IMS trained on SemCor on SemEval15 and SemEval-13.,5.2 Comparison against sense-annotated corpora,[0],[0]
"We view this as a significant achievement given the total absence of manual effort involved in T-O-M. Because overall T-O-MWiki outperforms T-O-MUN , in what follows we report all the results with T-O-MWiki, except for the domain-oriented evaluation (see Section 5.4).",5.2 Comparison against sense-annotated corpora,[0],[0]
"IMS uses the MFS as a backoff strategy when no sense can be output for a target word in context (Zhong and Ng, 2010).",5.3 Performance without backoff strategy,[0],[0]
"Consequently, the performance of the MFS is mixed up with that of the SVM classifier.",5.3 Performance without backoff strategy,[0],[0]
"As shown in Table 4, OMSTI is able to provide annotated sentences for roughly half of the tokens in the datasets.",5.3 Performance without backoff strategy,[0],[0]
"Train-O-Matic, on the other hand, is able to cover almost all words in each dataset with at least one training sentence.",5.3 Performance without backoff strategy,[0],[0]
"This means that in around 50% of cases OMSTI gives an answer based on the IMS backoff strategy.
",5.3 Performance without backoff strategy,[0],[0]
"To determine the real impact of the different training data, we therefore decided to perform an additional analysis of the IMS performance when the MFS backoff strategy is disabled.",5.3 Performance without backoff strategy,[0],[0]
"Because we suspected the system would not always return a sense for each target word, in this experiment we measured precision, recall and their harmonic mean, i.e., F1.",5.3 Performance without backoff strategy,[0],[0]
"The results in Table 5 confirm our hunch, showing that OMSTI’s recall drops heavily, thereby affecting F1 considerably.",5.3 Performance without backoff strategy,[0],[0]
"T-O-M performances, instead, remain high in terms of precision, recall and F1.",5.3 Performance without backoff strategy,[0],[0]
"This confirms that OMSTI relies heavily on data (those obtained for the MFS and from SemCor) that are produced manually, rather than semi-automatically.",5.3 Performance without backoff strategy,[0],[0]
"To further inspect the ability of T-O-M to enable disambiguation in different domains, we decided to evaluate on specific documents from the various gold standard datasets which could be clearly assigned a domain label.",5.4 Domain-oriented WSD,[0],[0]
"Specifically, we tested on 13 SemEval-13 documents from various domains6 and 2 SemEval-15 documents (namely, maths & computers, and biomedicine) and carried out two separate tests and evaluations of T-O-M on each domain: once using the MFS backoff strategy, and once not using it.",5.4 Domain-oriented WSD,[0],[0]
"In Tables 6 and 7 we report the results of both T-O-MWiki and T-O-MUN to determine the impact of the corpus type.
",5.4 Domain-oriented WSD,[0],[0]
"As can be seen in the tables, T-O-MWiki systematically attains higher scores than OMSTI (except for the biology domain), and, in most cases, attains higher scores than MFS when the backoff is used, with a drastic, systematic increase over OMSTI with both Train-O-Matic configurations
6Namely biology, climate, finance, health care, politics, social issues and sport.
in recall and F1 when the backoff strategy is disabled.",5.4 Domain-oriented WSD,[0],[0]
"This demonstrates the usefulness of the corpora annotated by Train-O-Matic not only on open text, but also on specific domains.",5.4 Domain-oriented WSD,[0],[0]
"We note that T-O-MUN obtains the best results in the politics domain, which is the closest domain to the UN corpus from which its training sentences are obtained.",5.4 Domain-oriented WSD,[0],[0]
"Experimental Setup In this section we investigate the ability of Train-O-Matic to scale to lowresourced languages, such as Italian and Spanish, for which training data for WSD is not available.
",6 Scaling up to Multiple Languages,[0],[0]
"Thanks to BabelNet, in fact, Train-O-Matic can
be used to generate sense-annotated data for any language supported by the knowledge base.",6 Scaling up to Multiple Languages,[0],[0]
"Thus, in order to build new training datasets for the two languages, we ran Train-O-Matic on their corresponding versions of Wikipedia, then we tuned the two parameters K and z on an in-house development dataset7.",6 Scaling up to Multiple Languages,[0],[0]
"In contrast to the English setting, in order to calculate Formula 8 we sorted the senses of each word by vertex degree.",6 Scaling up to Multiple Languages,[0],[0]
"Finally we used the output data to train IMS.
Results To perform our evaluation we chose the most recent multilingual task (SemEval 2015 task 13) which includes gold data for Italian and Spanish.",6 Scaling up to Multiple Languages,[0],[0]
"As can be seen from Table 8 TrainO-Matic enabled IMS to perform better than the best participating system (Manion and Sainudiin, 2014, SUDOKU) in all three settings (All domains, Maths & Computer and Biomedicine).",6 Scaling up to Multiple Languages,[0],[0]
"Its performance was in fact, 1 to 3 points higher, with a 6-point peak on Maths & Computer in Spanish and on Biomedicine in Italian.",6 Scaling up to Multiple Languages,[0],[0]
This demonstrates the ability of Train-O-Matic to enable supervised WSD systems to surpass state-of-theart knowledge-based WSD approaches in lowresourced languages without relying on manually curated data for training.,6 Scaling up to Multiple Languages,[0],[0]
There are two mainstream approaches to Word Sense Disambiguation: supervised and knowledge-based approaches.,7 Related Work,[0],[0]
"Both suffer in different ways from the so-called knowledge acquisition bottleneck, that is, the difficulty in obtaining an adequate amount of lexical-semantic data: for training in the case of supervised systems, and for enriching semantic networks in the case of knowledge-based ones (Pilehvar and
7We set K = 100 and z",7 Related Work,[0],[0]
"= 2.3 for Spanish and K = 100 and z = 2.5 for Italian.
Navigli, 2014; Navigli, 2009).
",7 Related Work,[0],[0]
"State-of-the-art supervised systems include Support Vector Machines such as IMS (Zhong and Ng, 2010) and, more recently, LSTM neural networks with attention and multitask learning (Raganato et al., 2017b) as well as LSTMs paired with nearest neighbours classification (Melamud et al., 2016; Yuan et al., 2016).",7 Related Work,[0],[0]
The latter also integrates a label propagation algorithm in order to enrich the sense annotated dataset.,7 Related Work,[0],[0]
"The main difference from our approach is its need for a manually annotated dataset to start the label propagation algorithm, whereas Train-O-Matic is fully automatic.",7 Related Work,[0],[0]
"An evaluation against this system would have been interesting, but neither the proprietary training data nor the code are available at the time of writing.
",7 Related Work,[0],[0]
"In order to generalize effectively, these supervised systems require large numbers of training in-
stances annotated with senses for each target word occurrence.",7 Related Work,[0],[0]
"Overall, this amounts to millions of training instances for each language of interest, a number that is not within reach for any language.",7 Related Work,[0],[0]
"In fact, no supervised system has been submitted in major multilingual WSD competitions for languages other than English (Navigli et al., 2013; Moro and Navigli, 2015).",7 Related Work,[0],[0]
"To overcome this problem, new methodologies have recently been developed which aim to create sense-tagged corpora automatically.",7 Related Work,[0],[0]
Raganato et al. (2016) developed 7 heuristics to grow the number of hyperlinks in Wikipedia pages.,7 Related Work,[0],[0]
"Otegi et al. (2016) applied a different disambiguation pipeline for each language to parallel text in Europarl (Koehn, 2005) and QTLeap (Agirre et al., 2015) in order to enrich them with semantic annotations.",7 Related Work,[0],[0]
"Taghipour and Ng (2015), the work closest to ours, exploits the alignment from English to Chinese sentences of
the United Nation Parallel Corpus (Ziemski et al., 2016) to reduce the ambiguity of English words and sense-tag English sentences.",7 Related Work,[0],[0]
The assumption is that the second language is less ambiguous than the first one and that hand-made translations of senses are available for each WordNet synset.,7 Related Work,[0],[0]
"This approach is, therefore, semi-automatic and relies on certain assumptions, in contrast to TrainO-Matic which is, instead, fully automatic and can be applied to any kind of corpus (and language) depending on the specific need.",7 Related Work,[0],[0]
Earlier attempts at the automatic extraction of training samples were made by Agirre and De Lacalle (2004) and Fernández et al. (2004).,7 Related Work,[0],[0]
"Both exploited the monosemous relatives method (Leacock et al., 1998) in order to retrieve sentences from the Web which contained a given monosemous noun or a relative monosemous word (e.g., a synonym, a hypernym, etc.).",7 Related Work,[0],[0]
"As can be seen in (Fernández et al., 2004)",7 Related Work,[0],[0]
"this approach can lead to the retrieval of very accurate examples, but its main drawback lies in the number of senses covered.",7 Related Work,[0],[0]
"In fact, for all those synsets that do not have any monosemous relative, the system is unable to retrieve examples, thus heavily affecting the performance in terms of recall and F1.",7 Related Work,[0],[0]
"Knowledge-based WSD, instead, bypasses the heavy requirement of sense-annotated corpora by applying algorithms that exploit a general-purpose semantic network, such as WordNet, which encodes the relational information that interconnects synsets via different kinds of relation.",7 Related Work,[0],[0]
"Approaches include variants of Personalized PageRank (Agirre et al., 2014) and densest subgraph approximation algorithms (Moro et al., 2014) which, thanks to the availability of multilingual resources such as BabelNet, can easily be extended to perform WSD in arbitrary languages.",7 Related Work,[0],[0]
Other approaches to knowledge-based WSD exploit the definitional knowledge contained in a dictionary.,7 Related Work,[0],[0]
"The Lesk algorithm (Lesk, 1986) and its variants (Banerjee and Pedersen, 2002; Kilgarriff and Rosenzweig, 2000; Vasilescu et al., 2004) aim to determine the correct sense of a word by comparing each wordsense definition with the context in which the target word appears.",7 Related Work,[0],[0]
"The limit of knowledge-based WSD, however, lies in the absence of mechanisms that can take into account the very local context of a target word occurrence, including non-content words such as prepositions and articles.",7 Related Work,[0],[0]
"Furthermore, recent studies seem to suggest that such
approaches are barely able to surpass supervised WSD systems when they enrich their networks starting from a comparable amount of annotated data (Pilehvar and Navigli, 2014).",7 Related Work,[0],[0]
"With T-O-M, rather than further enriching an existing semantic network, we exploit the information available in the network to annotate raw sentences with sense information and train a state-of-the-art supervised WSD system without task-specific human annotations.",7 Related Work,[0],[0]
"In this paper we presented Train-O-Matic, a novel approach to the automatic construction of large training sets for supervised WSD in an arbitrary language.",8 Conclusion,[0],[0]
"Train-O-Matic removes the burden of manual intervention by leveraging the structural semantic information available in the WordNet graph enriched with additional relational information from BabelNet, and achieves performance competitive to that of semi-automatic approaches and, in some cases, of manually-curated training data.",8 Conclusion,[0],[0]
"T-O-M was shown to provide training data for virtually all the target ambiguous nouns, in marked contrast to alternatives like OMSTI, which covers in many cases around half of the tokens, resorting to the MFS otherwise.",8 Conclusion,[0],[0]
"Moreover Train-O-Matic has proven to scale well to lowresourced languages, for which no manually annotated dataset exists, surpassing the current state of the art of knowledge-based systems.
",8 Conclusion,[0],[0]
"We believe that the ability of T-O-M to overcome the current paucity of annotated data for WSD, coupled with video games with a purpose for validation purposes (Jurgens and Navigli, 2014; Vannella et al., 2014), paves the way for high-quality multilingual supervised WSD.",8 Conclusion,[0.950611446061969],"['We use a discriminative pattern mining approach (Cheng et al., 2007, 2008; Batal and Hauskrecht, 2010) that examines all combinations of feature-values, up to a certain length, and determines which feature-values are informative when they are considered in combination.']"
"All the training corpora, including approximately one million sentences which cover English, Italian and Spanish, are made available to the community at http://trainomatic.org.
",8 Conclusion,[0],[0]
"As future work we plan to extend our approach to verbs, adjectives and adverbs.",8 Conclusion,[0],[0]
Following Bennett et al. (2016) we will also experiment on more realistic estimates of P (s|w) in Formula 5 as well as other assumptions made in our work.,8 Conclusion,[0],[0]
The authors gratefully acknowledge the support of the ERC Consolidator Grant MOUSSE,Acknowledgments,[0],[0]
No.,Acknowledgments,[0],[0]
726487.,Acknowledgments,[0],[0]
Annotating large numbers of sentences with senses is the heaviest requirement of current Word Sense Disambiguation.,abstractText,[0],[0]
"We present Train-O-Matic, a languageindependent method for generating millions of sense-annotated training instances for virtually all meanings of words in a language’s vocabulary.",abstractText,[0],[0]
The approach is fully automatic: no human intervention is required and the only type of human knowledge used is a WordNet-like resource.,abstractText,[0],[0]
"Train-O-Matic achieves consistently state-of-the-art performance across gold standard datasets and languages, while at the same time removing the burden of manual annotation.",abstractText,[0],[0]
All the training data is available for research purposes at http://trainomatic.org.,abstractText,[0],[0]
Train-O-Matic: Large-Scale Supervised Word Sense Disambiguation in Multiple Languages without Manual Training Data,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1968–1978 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
Neural machine translation has recently become a method of choice in machine translation research.,1 Introduction,[0],[0]
"Besides its success in traditional settings of machine translation, that is one-to-one translation between two languages, (Sennrich et al., 2016; Chung et al., 2016), neural machine translation has ventured into more sophisticated settings of machine translation.",1 Introduction,[0],[0]
"For instance, neural machine translation has successfully proven itself to be capable of
handling subword-level representation of sentences (Lee et al., 2016; Luong and Manning, 2016; Sennrich et al., 2015; Costa-Jussa and Fonollosa, 2016; Ling et al., 2015).",1 Introduction,[0],[0]
"Furthermore, several research groups have shown its potential in seamlessly handling multiple languages (Dong et al., 2015; Luong et al., 2015a; Firat et al., 2016a,b; Lee et al., 2016; Ha et al., 2016; Viégas et al., 2016).
",1 Introduction,[0],[0]
A typical scenario of neural machine translation starts with training a model to maximize its log-likelihood.,1 Introduction,[0],[0]
"That is, we often train a model to maximize the conditional probability of a reference translation given a source sentence over a large parallel corpus.",1 Introduction,[0],[0]
"Once the model is trained in this way, it defines the conditional distribution over all possible translations given a source sentence, and the task of translation becomes equivalent to finding a translation to which the model assigns the highest conditional probability.",1 Introduction,[0.9573931673647982],['Coreference resolution is the task of recognizing different expressions that refer to the same entity.']
"Since it is computationally intractable to do so exactly, it is a usual practice to resort to approximate search/decoding algorithms such as greedy decoding or beam search.",1 Introduction,[0],[0]
"In this scenario, we have identified two points where improvements could be made.",1 Introduction,[0],[0]
"They are (1) training (including the selection of a model architecture) and (2) decoding.
",1 Introduction,[0],[0]
"Much of the research on neural machine translation has focused solely on the former, that is, on improving the model architecture.",1 Introduction,[0],[0]
"Neural machine translation started with with a simple encoderdecoder architecture in which a source sentence is encoded into a single, fixed-size vector (Cho et al., 2014; Sutskever et al., 2014; Kalchbrenner and Blunsom, 2013).",1 Introduction,[0],[0]
"It soon evolved with the attention mechanism (Bahdanau et al., 2014).",1 Introduction,[0],[0]
"A few variants of the attention mechanism, or its regularization, have been proposed recently to improve both the translation quality as well as the computational efficiency (Luong et al., 2015b; Cohn et al., 2016; Tu et al., 2016b).",1 Introduction,[0],[0]
"More recently, convolutional net-
1968
works have been adopted either as a replacement of or a complement to a recurrent network in order to efficiently utilize parallel computing (Kalchbrenner et al., 2016; Lee et al., 2016; Gehring et al., 2016).
",1 Introduction,[0],[0]
"On the aspect of decoding, only a few research groups have tackled this problem by incorporating a target decoding algorithm into training.",1 Introduction,[0],[0]
Wiseman and Rush (2016) and Shen et al. (2015) proposed a learning algorithm tailored for beam search.,1 Introduction,[0],[0]
"Ranzato et al. (2015) and (Bahdanau et al., 2016) suggested to use a reinforcement learning algorithm by viewing a neural machine translation model as a policy function.",1 Introduction,[0],[0]
"Investigation on decoding alone has, however, been limited.",1 Introduction,[0],[0]
Cho (2016) showed the limitation of greedy decoding by simply injecting unstructured noise into the hidden state of the neural machine translation system.,1 Introduction,[0],[0]
"Tu et al. (2016a) similarly showed that the exactness of beam search does not correlate well with actual translation quality, and proposed to augment the learning cost function with reconstruction to alleviate this problem.",1 Introduction,[0],[0]
"Li et al. (2016) proposed a modification to the existing beam search algorithm to improve its exploration of the translation space.
",1 Introduction,[0],[0]
"In this paper, we tackle the problem of decoding in neural machine translation by introducing a concept of trainable greedy decoding.",1 Introduction,[0],[0]
"Instead of manually designing a new decoding algorithm suitable for neural machine translation, we propose to learn a decoding algorithm with an arbitrary decoding objective.",1 Introduction,[0],[0]
"More specifically, we introduce a neural-network-based decoding algorithm that works on an already-trained neural machine translation system by observing and manipulating its hidden state.",1 Introduction,[0],[0]
"We treat such a neural network as an agent with a deterministic, continuous action and train it with a variant of the deterministic policy gradient algorithm (Silver et al., 2014).
",1 Introduction,[0],[0]
"We extensively evaluate the proposed trainable greedy decoding on four language pairs (En-Cs, En-De, En-Ru and En-Fi; in both directions) with two different decoding objectives; sentence-level BLEU and negative perplexity.",1 Introduction,[0],[0]
"By training such trainable greedy decoding using deterministic policy gradient with the proposed critic-aware actor learning, we observe that we can improve decoding performance with minimal computational overhead.",1 Introduction,[0],[0]
"Furthermore, the trained actors are found to improve beam search as well, suggesting a future research direction in extending the proposed idea of trainable decoding for more sophisticated
underlying decoding algorithms.",1 Introduction,[0],[0]
"Neural machine translation is a special case of conditional recurrent language modeling, where the source and target are natural language sentences.",2.1 Neural Machine Translation,[0],[0]
"Let us use X = {x1, . . .",2.1 Neural Machine Translation,[0],[0]
", xTs} and Y = {y1, . . .",2.1 Neural Machine Translation,[0],[0]
", yT } to denote source and target sentences, respectively.",2.1 Neural Machine Translation,[0],[0]
"Neural machine translation then models the target sentence given the source sentence as: p(Y |X) = ∏Tt=1 p(yt|y<t, X).",2.1 Neural Machine Translation,[0],[0]
Each term on the r.h.s.,2.1 Neural Machine Translation,[0],[0]
"of the equation above is modelled as a composite of two parametric functions:
p(yt|y<t, X) ∝",2.1 Neural Machine Translation,[0],[0]
"exp (g (yt, zt; θg)) ,
where zt = f(zt−1, yt−1, et(X; θe); θf ).",2.1 Neural Machine Translation,[0],[0]
"g is a read-out function that transforms the hidden state zt into the distribution over all possible symbols, and f is a recurrent function that compresses all the previous target words y<t and the time-dependent representation et(X; θe) of the source sentence X .",2.1 Neural Machine Translation,[0],[0]
"This time-dependent representation et is often implemented as a recurrent network encoder of the source sentence coupled with an attention mechanism (Bahdanau et al., 2014).
",2.1 Neural Machine Translation,[0],[0]
"Maximum Likelihood Learning We train a neural machine translation model, or equivalently estimate the parameters θg, θf and θe, by maximizing the log-probability of a reference translation Ŷ = {ŷ1, ..., ŷT } given a source sentence.",2.1 Neural Machine Translation,[0],[0]
"That is, we maximize the log-likelihood function:
JML(θg, θf , θe) = 1 N N∑ n=1",2.1 Neural Machine Translation,[0],[0]
"Tn∑ t=1 log pθ(ŷnt |ŷn<t, Xn),
given a training set consisting of N source-target sentence pairs.",2.1 Neural Machine Translation,[0],[0]
It is important to note that this maximum likelihood learning does not take into account how a trained model would be used.,2.1 Neural Machine Translation,[0],[0]
"Rather, it is only concerned with learning a distribution over all possible translations.",2.1 Neural Machine Translation,[0],[0]
"Once the model is trained, either by maximum likelihood learning or by any other recently proposed algorithms (Wiseman and Rush, 2016; Shen et al., 2015; Bahdanau et al., 2016; Ranzato et al., 2015), we can let the model translate a given sentence by
finding a translation that maximizes
Ŷ = arg max Y
log pθ(Y |X),
where θ = (θg, θf , θe).",2.2 Decoding,[0],[0]
"This is, however, computationally intractable, and it is a usual practice to resort to approximate decoding algorithms.
",2.2 Decoding,[0],[0]
Greedy Decoding One such approximate decoding algorithm is greedy decoding.,2.2 Decoding,[0],[0]
"In greedy decoding, we follow the conditional dependency path and pick the symbol with the highest conditional probability so far at each node.",2.2 Decoding,[0],[0]
This is equivalent to picking the best symbol one at a time from left to right in conditional language modelling.,2.2 Decoding,[0],[0]
"A decoded translation of greedy decoding is Ŷ = (ŷ1, . . .",2.2 Decoding,[0],[0]
", ŷT ), where
ŷt = arg max y∈V
log pθ(y|ŷ<t, X).",2.2 Decoding,[0],[0]
"(1)
Despite its preferable computational complexity O(|V | × T ), greedy decoding has been over time found to be undesirably sub-optimal.
",2.2 Decoding,[0],[0]
"Beam Search Beam search keeps K > 1 hypotheses, unlike greedy decoding which keeps only a single hypothesis during decoding.",2.2 Decoding,[0],[0]
"At each time step t, beam search picks K hypotheses with the highest scores ( ∏t t′=1 p(yt|y<t, X)).",2.2 Decoding,[0],[0]
"When all the hypotheses terminate (outputting the end-of-thesentence symbol), it returns the hypothesis with the highest log-probability.",2.2 Decoding,[0],[0]
"Despite its superior performance compared to greedy decoding, the computational complexity grows linearly w.r.t.",2.2 Decoding,[0],[0]
"the size of beam K, which makes it less preferable especially in the production environment.",2.2 Decoding,[0],[0]
"Although we have described decoding in neural machine translation as a maximum-a-posteriori estimation in log p(Y |X), this is not necessarily the only nor the desirable decoding objective.
",3.1 Many Decoding Objectives,[0],[0]
"First, each potential scenario in which neural machine translation is used calls for a unique decoding objective.",3.1 Many Decoding Objectives,[0],[0]
"In simultaneous translation/interpretation, which has recently been studied in the context of neural machine translation (Gu et al., 2016), the decoding objective is formulated as a trade-off between the translation quality and delay.",3.1 Many Decoding Objectives,[0],[0]
"On the other hand, when a machine translation system is used as a part of a larger information
extraction system, it is more important to correctly translate named entities and events than to translate syntactic function words.",3.1 Many Decoding Objectives,[0],[0]
"The decoding objective in this case must account for how the translation is used in subsequent modules in a larger system.
",3.1 Many Decoding Objectives,[0],[0]
"Second, the conditional probability assigned by a trained neural machine translation model does not necessarily reflect our perception of translation quality.",3.1 Many Decoding Objectives,[0],[0]
"Although Cho (2016) provided empirical evidence of high correlation between the logprobability and BLEU, a de facto standard metric in machine translation, there have also been reports on large mismatch between the log-probability and BLEU.",3.1 Many Decoding Objectives,[0],[0]
"For instance, Tu et al. (2016a) showed that beam search with a very large beam, which is supposed to find translations with better logprobabilities, suffers from pathological translations of very short length, resulting in low translation quality.",3.1 Many Decoding Objectives,[0],[0]
"This calls for a way to design or learn a decoding algorithm with an objective that is more directly correlated to translation quality.
",3.1 Many Decoding Objectives,[0],[0]
"In short, there is a significant need for designing multiple decoding algorithms for neural machine translation, regardless of how it was trained.",3.1 Many Decoding Objectives,[0],[0]
It is however non-trivial to manually design a new decoding algorithm with an arbitrary objective.,3.1 Many Decoding Objectives,[0],[0]
"This is especially true with neural machine translation, as the underlying structure of the decoding/search process – the high-dimensional hidden state of a recurrent network – is accessible but not interpretable.",3.1 Many Decoding Objectives,[0],[0]
"Instead, in the remainder of this section, we propose our approach of trainable greedy decoding.",3.1 Many Decoding Objectives,[0],[0]
"We start from the noisy, parallel approximate decoding (NPAD) algorithm proposed in (Cho, 2016).",3.2 Trainable Greedy Decoding,[0],[0]
The main idea behind NPAD algorithm is that a better translation with a higher log-probability may be found by injecting unstructured noise in the transition function of a recurrent network.,3.2 Trainable Greedy Decoding,[0],[0]
"That is,
zt = f(zt−1 + t, yt−1, et(X; θe); θf ),
where t ∼ N (0, (σ0/t)2).",3.2 Trainable Greedy Decoding,[0],[0]
NPAD avoids potential degradation of translation quality by running such a noisy greedy decoding process multiple times in parallel.,3.2 Trainable Greedy Decoding,[0],[0]
"An important lesson of NPAD algorithm is that there exists a decoding strategy with the asymptotically same computational complexity that results in a better translation quality, and that such a better translation can be found by manipulating the hidden state of the recurrent network.
",3.2 Trainable Greedy Decoding,[0],[0]
"In this work, we propose to significantly extend NPAD by replacing the unstructured noise t with a parametric function approximator, or an agent, πφ.",3.2 Trainable Greedy Decoding,[0],[0]
"This agent takes as input the previous hidden state zt−1, previously decoded word ŷt−1 and the time-dependent context vector et(X; θe) and outputs a real-valued vectorial action at ∈ Rdim(zt).",3.2 Trainable Greedy Decoding,[0],[0]
"Such an agent is trained such that greedy decoding with the agent finds a translation that maximizes any predefined, arbitrary decoding objective, while the underlying neural machine translation model is pretrained and fixed.",3.2 Trainable Greedy Decoding,[0],[0]
"Once the agent is trained, we generate a translation given a source sentence by greedy decoding however augmented with this agent.",3.2 Trainable Greedy Decoding,[0],[0]
"We call this decoding strategy trainable greedy decoding.
",3.2 Trainable Greedy Decoding,[0],[0]
Related Work:,3.2 Trainable Greedy Decoding,[0],[0]
"Soothsayer prediction function Independently from and concurrently with our work here, Li et al. (2017) proposed, just two weeks earlier, to train a neural network that predicts an arbitrary decoding objective given a source sentence and a partial hypothesis, or a prefix of translation, and to use it as an auxiliary score in beam search.",3.2 Trainable Greedy Decoding,[0],[0]
"For training such a network, referred to as a Q network in their paper, they generate each training example by either running beam search or using a ground-truth translation (when appropriate) for each source sentence.",3.2 Trainable Greedy Decoding,[0],[0]
"This approach allows one to use an arbitrary decoding objective, but it still re-
lies heavily on the log-probability of the underlying neural translation system in actual decoding.",3.2 Trainable Greedy Decoding,[0],[0]
We expect a combination of these and our approaches may further improve decoding for neural machine translation in the future.,3.2 Trainable Greedy Decoding,[0],[0]
"While all the parameters—θg, θf and θe— of the underlying neural translation model are fixed, we only update the parameters φ of the agent π.",3.3 Learning and Challenges,[0],[0]
"This ensures the generality of the pretrained translation model, and allows us to train multiple trainable greedy decoding agents with different decoding objectives, maximizing the utility of a single trained translation model.
",3.3 Learning and Challenges,[0],[0]
Let us denote by R our arbitrary decoding objective as a function that scores a translation generated from trainable greedy decoding.,3.3 Learning and Challenges,[0],[0]
"Then, our learning objective for trainable greedy decoding is
JA(φ) = EŶ=Gπ(X)X∼D",3.3 Learning and Challenges,[0],[0]
"[ R(Ŷ ) ] ,
where we used Gπ(X) as a shorthand for trainable greedy decoding with an agent π.
",3.3 Learning and Challenges,[0],[0]
There are two major challenges in learning an agent with such an objective.,3.3 Learning and Challenges,[0],[0]
"First, the decoding objective R may not be differentiable with respect to the agent.",3.3 Learning and Challenges,[0],[0]
"Especially because our goal is to accommodate an arbitrary decoding objective, this becomes a problem.",3.3 Learning and Challenges,[0],[0]
"For instance, BLEU, a standard
quality metric in machine translation, is a piecewise linear function with zero derivatives almost everywhere.",3.3 Learning and Challenges,[0],[0]
"Second, the agent here is a real-valued, deterministic policy with a very high-dimensional action space (1000s of dimensions), which is well known to be difficult.",3.3 Learning and Challenges,[0],[0]
"In order to alleviate these difficulties, we propose to use a variant of the deterministic policy gradient algorithm (Silver et al., 2014; Lillicrap et al., 2015).",3.3 Learning and Challenges,[0],[0]
"It is highly unlikely for us to have access to the gradient of an arbitrary decoding objective R with respect to the agent π, or its parameters φ.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Furthermore, we cannot estimate it stochastically because our policy π is defined to be deterministic without a predefined nor learned distribution over the action.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Instead, following (Silver et al., 2014; Lillicrap et al., 2015), we use a parametric, differentiable approximator, called a critic Rc, for the non-differentiable objective R. We train the critic by minimizing
JC(ψ)",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
= EŶ=Gπ(X)X∼D [ Rcψ(z1:T )−R(Ŷ ),4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"]2 .
",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"The critic observes the state-action sequence of the agent π via the modified hidden states (z1, . . .",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
", zT )",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"of the recurrent network, and predicts the associated decoding objective.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"By minimizing the mean squared error above, we effectively encourage the critic to approximate the non-differentiable objective as closely as possible in the vicinity of the state-action sequence visited by the agent.
",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"We implement the critic Rc as a recurrent network, similarly to the underlying neural machine translation system.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"This implies that we can compute the derivative of the predicted decoding objective with respect to the input, that is, the state-action sequence z1:T , which allows us to update the actor π, or equivalently its parameters φ, to maximize the predicted decoding objective.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Effectively we avoid the issue of non-differentiability of the original decoding objective by working with its proxy.
",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"With the critic, the learning objective of the actor is now to maximize not the original decoding objective R but its proxy RC such that
ĴA(φ)",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
= EŶ=Gπ(X)X∼D,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"[ RC(Ŷ ) ] .
",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Algorithm 1 Trainable Greedy Decoding Require: NMT θ, actor φ, critic ψ, Nc, Na, Sc, Sa, τ
1: Train θ using MLE on training set D; 2: Initialize φ and ψ; 3:",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
Shuffle D twice into Dφ and Dψ 4: while stopping criterion is not met do 5: for t = 1 :,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Nc do 6: Draw a translation pair: (X,Y ) ∼ Dψ; 7: r, rc = DECODE(Sc, X, Y, 1) 8:",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
Update ψ using∇ψ ∑ k (r c,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
k,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"− rk)2/(Sc + 1)
9: for t = 1 : Na do 10: Draw a translation pair: (X,Y ) ∼ Dφ; 11: r, rc = DECODE(Sa, X, Y, 0) 12: Compute wk = exp
(− (rck − rk)2 /τ) 13: Compute w̃k = wk/ ∑ k wk
14: Update φ using −∑k",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
(w̃k · ∇φrck),4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Function: DECODE(S,X, Y, c)
1: Ys = {}, Zs = {}, r = {}, rc = {}; 2: for k = 1 : S do 3: Sample noise ∼ N (0, σ2) for each action; 4: Greedy decoding Ŷ k = Gθ,φ(X) with ; 5: Collect hidden states zk1:T given X , Ŷ , θ, φ 6: Ys ← Ys ∪ {Y k} 7:",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Zs ← Zs ∪ {zk1:T } 8: if c = 1 then 9: Collect hidden states z1:T given X , Y , θ
10: Ys ← Ys ∪ {Y } 11:",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Zs ← Zs ∪ {z1:T } 12: for Ŷ , Z ∈ Ys, Zs do 13: Compute the critic output rc ← Rcψ(Z, Ŷ ) 14: Compute true reward r ← R(Y, Ŷ ) 15: return r, rc
Unlike the original objective, this objective function is fully differentiable with respect to the agent π.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"We thus use a usual stochastic gradient descent algorithm to train the agent, while simultaneously training the critic.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
We do so by alternating between training the actor and critic.,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Note that we maximize the return of a full episode rather than the Q value, unlike usual approaches in reinforcement learning.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
Challenges The most apparent challenge for training such a deterministic actor with a large action space is that most of action configurations will lead to zero return.,4.2 Critic-Aware Actor Learning,[0],[0]
It is also not trivial to devise an efficient exploration strategy with a deterministic actor with real-valued actions.,4.2 Critic-Aware Actor Learning,[0],[0]
"This issue has however turned out to be less of a problem than in a usual reinforcement learning setting, as the state and action spaces are well structured thanks to pretraining by maximum likelihood learning.",4.2 Critic-Aware Actor Learning,[0],[0]
"As observed by Cho (2016), any reasonable perturbation to the hidden state of the recurrent network generates a reasonable translation which would re-
ceive again a reasonable return.
",4.2 Critic-Aware Actor Learning,[0],[0]
"Although this property of dense reward makes the problem of trainable greedy decoding more manageable, we have observed other issues during our preliminary experiment with the vanilla deterministic policy gradient.",4.2 Critic-Aware Actor Learning,[0],[0]
"In order to avoid these issues that caused instability, we propose the following modifications to the vanilla algorithm.
",4.2 Critic-Aware Actor Learning,[0],[0]
"Critic-Aware Actor Learning A major goal of the critic is not to estimate the return of a given episode, but to estimate the gradient of the return evaluated given an episode.",4.2 Critic-Aware Actor Learning,[0],[0]
"In order to do so, the critic must be trained, or presented, with stateaction sequences z1:T ′ similar though not identical to the state-action sequence generated by the current actor π.",4.2 Critic-Aware Actor Learning,[0],[0]
"This is achieved, in our case, by injecting unstructured noise to the action at each
time step, similar to (Heess et al., 2015):
ãt = φ(zt, at−1) + σ · , (2)
where is a zero-mean, unit-variance normal variable.",4.2 Critic-Aware Actor Learning,[0],[0]
"This noise injection procedure is mainly used when training the critic.
",4.2 Critic-Aware Actor Learning,[0],[0]
We have however observed that the quality of the reward and its gradient estimate of the critic is very noisy even when the critic was trained with this kind of noisy actor.,4.2 Critic-Aware Actor Learning,[0],[0]
This imperfection of the critic often led to the instability in training the actor in our preliminary experiments.,4.2 Critic-Aware Actor Learning,[0],[0]
"In order to avoid this, we describe here a technique which we refer to as critic-aware actor gradient estimation.
",4.2 Critic-Aware Actor Learning,[0],[0]
"Instead of using the point estimate ∂R c
∂φ of the gradient of the predicted objective with respect to the actor’s parameters φ, we propose to use the expected gradient of the predicted objective with
respect to the critic-aware distribution Q.",4.2 Critic-Aware Actor Learning,[0],[0]
"That is,
EQ [ ∂Rcψ ∂φ ] , (3)
where we define the critic-aware distribution Q as
Q( ) ∝",4.2 Critic-Aware Actor Learning,[0],[0]
exp(−(Rcψ −R)2/τ︸,4.2 Critic-Aware Actor Learning,[0],[0]
︷︷ ︸,4.2 Critic-Aware Actor Learning,[0],[0]
"Critic-awareness
) exp(− 2
2σ2︸ ︷︷ ︸ Locality ).",4.2 Critic-Aware Actor Learning,[0],[0]
"(4)
",4.2 Critic-Aware Actor Learning,[0],[0]
"This expectation allows us to incorporate the noisy, non-uniform nature of the critic’s approximation of the objective by up-weighting the gradient computed at a point with a higher critic quality and down-weighting the gradient computed at a point with a lower critic quality.",4.2 Critic-Aware Actor Learning,[0],[0]
"The first term in Q reflects this, while the second term ensures that our estimation is based on a small region around the state-action sequence generated by the current, noise-free actor π.
",4.2 Critic-Aware Actor Learning,[0],[0]
Since it is intractable to compute Eq.,4.2 Critic-Aware Actor Learning,[0],[0]
"(3) exactly, we resort to importance sampling with the proposed distribution equal to the second term in Eq.",4.2 Critic-Aware Actor Learning,[0],[0]
(4).,4.2 Critic-Aware Actor Learning,[0],[0]
"Then, our gradient estimate for the actor becomes the sum of the gradients from multiple realizations of the noisy actor in Eq.",4.2 Critic-Aware Actor Learning,[0],[0]
"(2), where each gradient is weighted by the quality of the critic exp(−(Rcφ − R)2/τ).",4.2 Critic-Aware Actor Learning,[0],[0]
τ is a hyperparameter that controls the smoothness of the weights.,4.2 Critic-Aware Actor Learning,[0],[0]
"We observed in our preliminary experiment that the use of this criticaware actor learning significantly stabilizes general learning of both the actor and critic.
",4.2 Critic-Aware Actor Learning,[0],[0]
"Reference Translations for Training the Critic In our setting of neural machine translation, we have access to a reference translation for each source sentence X , unlike in a usual setting of reinforcement learning.",4.2 Critic-Aware Actor Learning,[0],[0]
"By force-feeding the reference translation into the underlying neural machine translation system (rather than feeding the decoded symbols), we can generate the reference state-action sequence.",4.2 Critic-Aware Actor Learning,[0],[0]
"This sequence is much less correlated with those sequences generated by the actor, and facilitates computing a better estimate of the gradient w.r.t.",4.2 Critic-Aware Actor Learning,[0],[0]
"the critic.
",4.2 Critic-Aware Actor Learning,[0],[0]
"In Alg. 1, we present the complete algorithm.",4.2 Critic-Aware Actor Learning,[0],[0]
"To make the description less cluttered, we only show the version of minibatch size = 1 which can be naturally extended.",4.2 Critic-Aware Actor Learning,[0],[0]
We also illustrate the proposed trainable greedy decoding and the proposed learning strategy in Fig. 1.,4.2 Critic-Aware Actor Learning,[0],[0]
"We empirically evaluate the proposed trainable greedy decoding on four language pairs – EnDe, En-Ru, En-Cs and En-Fi – using a standard attention-based neural machine translation system (Bahdanau et al., 2014).",5 Experimental Settings,[0],[0]
We train underlying neural translation systems using the parallel corpora made available from WMT’15.1 The same set of corpora are used for trainable greedy decoding as well.,5 Experimental Settings,[0],[0]
"All the corpora are tokenized and segmented into subword symbols using byte-pair encoding (BPE) (Sennrich et al., 2015).",5 Experimental Settings,[0],[0]
We use sentences of length up to 50 subword symbols for MLE training and 200 symbols for trainable decoding.,5 Experimental Settings,[0],[0]
"For validation and testing, we use newstest-2013 and newstest-2015, respectively.",5 Experimental Settings,[0],[0]
"Underlying NMT Model For each language pair, we implement an attention-based neural machine translation model whose encoder and decoder recurrent networks have 1,028 gated recurrent units (GRU, Cho et al., 2014) each.",5.1 Model Architectures and Learning,[0],[0]
Source and target symbols are projected into 512-dimensional embedding vectors.,5.1 Model Architectures and Learning,[0],[0]
"We trained each model for approximately 1.5 weeks using Adadelta (Zeiler, 2012).
",5.1 Model Architectures and Learning,[0],[0]
Actor π,5.1 Model Architectures and Learning,[0],[0]
We use a feedforward network with a single hidden layer as the actor.,5.1 Model Architectures and Learning,[0],[0]
"The input is a 2,056-dimensional vector which is the concatenation of the decoder hidden state and the timedependent context vector from the attention mech-
1http://www.statmt.org/wmt15/
anism, and it outputs a 1,028-dimensional action vector for the decoder.",5.1 Model Architectures and Learning,[0],[0]
"We use 32 units for the hidden layer with tanh activations.
",5.1 Model Architectures and Learning,[0],[0]
Critic Rc The critic is implemented as a variant of an attention-based neural machine translation model that takes a reference translation as a source sentence and a state-action sequence from the actor as a target sentence.,5.1 Model Architectures and Learning,[0],[0]
Both the size of GRU units and embedding vectors are the same with the underlying model.,5.1 Model Architectures and Learning,[0],[0]
"Unlike a usual neural machine translation system, the critic does not language-model the target sentence but simply outputs a scalar value to predict the true return.",5.1 Model Architectures and Learning,[0],[0]
"When we predict a bounded return, such as sentence BLEU, we use a sigmoid activation at the output.",5.1 Model Architectures and Learning,[0],[0]
"For other unbounded return like perplexity, we use a linear activation.
",5.1 Model Architectures and Learning,[0],[0]
Learning We train the actor and critic simultaneously by alternating between updating the actor and critic.,5.1 Model Architectures and Learning,[0],[0]
"As the quality of the critic’s approximation of the decoding objective has direct influence on the actor’s learning, we make ten updates to the critic before each time we update the actor once.",5.1 Model Architectures and Learning,[0],[0]
"We use RMSProp (Tieleman and Hinton, 2012) with the initial learning rates of 2× 10−6 and 2× 10−4, respectively, for the actor and critic.
",5.1 Model Architectures and Learning,[0],[0]
We monitor the progress of learning by measuring the decoding objective on the validation set.,5.1 Model Architectures and Learning,[0],[0]
"After training, we pick the actor that results in the best decoding objective on the validation set, and test it on the test set.
",5.1 Model Architectures and Learning,[0],[0]
"Decoding Objectives For each neural machine translation model, pretrained using maximum likelihood criterion, we train two trainable greedy decoding actors.",5.1 Model Architectures and Learning,[0],[0]
"One actor is trained to maximize BLEU (or its smoothed version for sentence-level
scoring (Lin and Och, 2004))",5.1 Model Architectures and Learning,[0],[0]
"as its decoding objective, and the other to minimize perplexity (or equivalently the negative log-probability normalized by the length.)
",5.1 Model Architectures and Learning,[0],[0]
We have chosen the first two decoding objectives for two purposes.,5.1 Model Architectures and Learning,[0],[0]
"First, we demonstrate that it is possible to build multiple trainable decoders with a single underlying model trained using maximum likelihood learning.",5.1 Model Architectures and Learning,[0],[0]
"Second, the comparison between these two objectives provides a glimpse into the relationship between BLEU (the most widely used automatic metric for evaluating translation systems) and log-likelihood (the most widely used learning criterion for neural machine translation).
",5.1 Model Architectures and Learning,[0],[0]
Evaluation We test the trainable greedy decoder with both greedy decoding and beam search.,5.1 Model Architectures and Learning,[0],[0]
"Although our decoder is always trained with greedy decoding, beam search in practice can be used together with the actor of the trainable greedy decoder.",5.1 Model Architectures and Learning,[0],[0]
Beam search is expected to work better especially when our training of the trainable greedy decoder is unlikely to be optimal.,5.1 Model Architectures and Learning,[0],[0]
"In both cases, we report both the perplexity and BLEU.",5.1 Model Architectures and Learning,[0],[0]
We present the improvements of BLEU and perplexity (or its negation) in Fig. 2 for all the language pair-directions.,5.2 Results and Analysis,[0],[0]
It is clear from these plots that the best result is achieved when the trainable greedy decoder was trained to maximize the target decoding objective.,5.2 Results and Analysis,[0],[0]
"When the decoder was trained to maximize sentence-level BLEU, we see the improvement in BLEU but often the degradation in the perplexity (see the left plots in Fig. 2.)",5.2 Results and Analysis,[0],[0]
"On the other hand, when the actor was trained to minimize the perplexity, we only see the improvement in per-
plexity (see the right plots in Fig. 2.)",5.2 Results and Analysis,[0],[0]
"This confirms our earlier claim that it is necessary and desirable to tune for the target decoding objective regardless of what the underlying translation system was trained for, and strongly supports the proposed idea of trainable decoding.
",5.2 Results and Analysis,[0],[0]
"The improvement from using the proposed trainable greedy decoding is smaller when used together with beam search, as seen in Fig. 2 (b).",5.2 Results and Analysis,[0],[0]
"However, we still observe statistically significant improvement in terms of BLEU (marked with red stars.)",5.2 Results and Analysis,[0],[0]
"This suggests a future direction in which we extend the proposed trainable greedy decoding to directly incorporate beam search into its training procedure to further improve the translation quality.
",5.2 Results and Analysis,[0],[0]
It is worthwhile to note that we achieved all of these improvements with negligible computational overhead.,5.2 Results and Analysis,[0],[0]
"This is due to the fact that our actor is a very small, shallow neural network, and that the more complicated critic is thrown away after training.",5.2 Results and Analysis,[0],[0]
We suspect the effectiveness of such a small actor is due to the well-structured hidden state space of the underlying neural machine translation model which was trained with a large amount of parallel corpus.,5.2 Results and Analysis,[0],[0]
"We believe this favourable computational complexity makes the proposed method suitable for production-grade neural machine translation (Wu et al., 2016; Crego et al., 2016).
",5.2 Results and Analysis,[0],[0]
"Importance of Critic-Aware Actor Learning In Fig. 3, we show sample learning curves with and without the proposed critic-aware actor learning.",5.2 Results and Analysis,[0],[0]
Both curves were from the models trained under the same condition.,5.2 Results and Analysis,[0],[0]
"Despite a slower start in the early stage of learning, we see that the critic-aware actor learning has greatly stabilized the learning progress.",5.2 Results and Analysis,[0],[0]
"We emphasize that we would not have been able to train all these 16 actors without the proposed critic-aware actor learning.
",5.2 Results and Analysis,[0],[0]
"Examples In Fig. 4, we present three examples from Ru-En.",5.2 Results and Analysis,[0],[0]
"We defined the influence as the KL divergence between the conditional distributions without the trainable greedy decoding and with the trainable greedy decoding, assuming the fixed previous hidden state and target symbol.",5.2 Results and Analysis,[0],[0]
"We colored a target word with magenta, when the influence of the trainable greedy decoding is large (> 0.001).",5.2 Results and Analysis,[0],[0]
Manual inspection of these examples as well as others has revealed that the trainable greedy decoder focuses on fixing prepositions and removing any unnecessary symbol generation.,5.2 Results and Analysis,[0],[0]
"More in-depth
analysis is however left as future work.",5.2 Results and Analysis,[0],[0]
We proposed trainable greedy decoding as a way to learn a decoding algorithm for neural machine translation with an arbitrary decoding objective.,6 Conclusion,[0],[0]
"The proposed trainable greedy decoder observes and manipulates the hidden state of a trained neural translation system, and is trained by a novel variant of deterministic policy gradient, called critic-aware actor learning.",6 Conclusion,[0],[0]
Our extensive experiments on eight language pair-directions and two objectives confirmed its validity and usefulness.,6 Conclusion,[0],[0]
"The proposed trainable greedy decoding is a generic idea that can be applied to any recurrent language modeling, and we anticipate future research both on the fundamentals of the trainable decoding as well as on the applications to more diverse tasks such as image caption generating and dialogue modeling.",6 Conclusion,[0],[0]
"KC thanks the support by TenCent, eBay, Facebook, Google (Google Faculty Award 2016) and NVidia.",Acknowledgement,[0],[0]
This work was partly supported by Samsung Advanced Institute of Technology (Next Generation Deep Learning: from pattern recognition to AI).,Acknowledgement,[0],[0]
"We sincerely thank Martin Arjovsky, Zihang Dai, Graham Neubig, Pengcheng Yin and Chunting Zhou for helpful discussions and insightful feedbacks.",Acknowledgement,[0],[0]
Recent research in neural machine translation has largely focused on two aspects; neural network architectures and end-toend learning algorithms.,abstractText,[0],[0]
"The problem of decoding, however, has received relatively little attention from the research community.",abstractText,[0],[0]
"In this paper, we solely focus on the problem of decoding given a trained neural machine translation model.",abstractText,[0.9526134059005712],"['In this paper, we show that employing linguistic features in a neural coreference resolver significantly improves generalization.']"
"Instead of trying to build a new decoding algorithm for any specific decoding objective, we propose the idea of trainable decoding algorithm in which we train a decoding algorithm to find a translation that maximizes an arbitrary decoding objective.",abstractText,[0],[0]
"More specifically, we design an actor that observes and manipulates the hidden state of the neural machine translation decoder and propose to train it using a variant of deterministic policy gradient.",abstractText,[0],[0]
"We extensively evaluate the proposed algorithm using four language pairs and two decoding objectives, and show that we can indeed train a trainable greedy decoder that generates a better translation (in terms of a target decoding objective) with minimal computational overhead.",abstractText,[0],[0]
Trainable Greedy Decoding for Neural Machine Translation,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1884–1895 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1884",text,[0],[0]
"The standard protocol for obtaining a labeled dataset is to have a human annotator view each example, assess its relevance, and provide a label (e.g., positive or negative for binary classification).",1 Introduction,[0],[0]
"However, this only provides one bit of information per example.",1 Introduction,[0],[0]
"This invites the question: how can we get more information per example, given that the annotator has already spent the effort reading and understanding an example?
",1 Introduction,[0],[0]
"Previous works have relied on identifying relevant parts of the input such as labeling features (Druck et al., 2009; Raghavan et al., 2005; Liang et al., 2009), highlighting rationale phrases in
text (Zaidan and Eisner, 2008; Arora and Nyberg, 2009), or marking relevant regions in images (Ahn et al., 2006).",1 Introduction,[0],[0]
"But there are certain types of information which cannot be easily reduced to annotating a portion of the input, such as the absence of a certain word, or the presence of at least two words.",1 Introduction,[0],[0]
"In this work, we tap into the power of natural language and allow annotators to provide supervision to a classifier via natural language explanations.
",1 Introduction,[0],[0]
"Specifically, we propose a framework in which annotators provide a natural language explanation for each label they assign to an example (see Figure 1).",1 Introduction,[0],[0]
"These explanations are parsed into logical forms representing labeling functions (LFs), functions that heuristically map examples to labels (Ratner et al., 2016).",1 Introduction,[0],[0]
"The labeling functions are
then executed on many unlabeled examples, resulting in a large, weakly-supervised training set that is then used to train a classifier.
",1 Introduction,[0],[0]
"Semantic parsing of natural language into logical forms is recognized as a challenging problem and has been studied extensively (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011; Liang, 2016).",1 Introduction,[0],[0]
"One of our major findings is that in our setting, even a simple rule-based semantic parser suffices for three reasons: First, we find that the majority of incorrect LFs can be automatically filtered out either semantically (e.g., is it consistent with the associated example?) or pragmatically (e.g., does it avoid assigning the same label to the entire training set?).",1 Introduction,[0],[0]
"Second, LFs near the gold LF in the space of logical forms are often just as accurate (and sometimes even more accurate).",1 Introduction,[0],[0]
"Third, techniques for combining weak supervision sources are built to tolerate some noise (Alfonseca et al., 2012; Takamatsu et al., 2012; Ratner et al., 2018).",1 Introduction,[0],[0]
The significance of this is that we can deploy the same semantic parser across tasks without task-specific training.,1 Introduction,[0],[0]
"We show how we can tackle a real-world biomedical application with the same semantic parser used to extract instances of spouses.
",1 Introduction,[0],[0]
"Our work is most similar to that of Srivastava et al. (2017), who also use natural language explanations to train a classifier, but with two important differences.",1 Introduction,[0],[0]
"First, they jointly train a task-specific semantic parser and classifier, whereas we use a
simple rule-based parser.",1 Introduction,[0],[0]
"In Section 4, we find that in our weak supervision framework, the rule-based semantic parser and the perfect parser yield nearly identical downstream performance.",1 Introduction,[0],[0]
"Second, while they use the logical forms of explanations to produce features that are fed directly to a classifier, we use them as functions for labeling a much larger training set.",1 Introduction,[0],[0]
"In Section 4, we show that using functions yields a 9.5 F1 improvement (26% relative improvement) over features, and that the F1 score scales with the amount of available unlabeled data.
",1 Introduction,[0],[0]
We validate our approach on two existing datasets from the literature (extracting spouses from news articles and disease-causing chemicals from biomedical abstracts) and one real-world use case with our biomedical collaborators at OccamzRazor to extract protein-kinase interactions related to Parkinson’s disease from text.,1 Introduction,[0],[0]
We find empirically that users are able to train classifiers with comparable F1 scores up to two orders of magnitude faster when they provide natural language explanations instead of individual labels.,1 Introduction,[0],[0]
"Our code and data can be found at https:// github.com/HazyResearch/babble.
2",1 Introduction,[0],[0]
"The BabbleLabble Framework
The BabbleLabble framework converts natural language explanations and unlabeled data into a noisily-labeled training set (see Figure 2).",1 Introduction,[0],[0]
"There are three key components: a semantic parser, a filter bank, and a label aggregator.",1 Introduction,[0],[0]
"The semantic
parser converts natural language explanations into a set of logical forms representing labeling functions (LFs).",1 Introduction,[0],[0]
The filter bank removes as many incorrect LFs as possible without requiring ground truth labels.,1 Introduction,[0],[0]
The remaining LFs are applied to unlabeled examples to produce a matrix of labels.,1 Introduction,[0],[0]
"This label matrix is passed into the label aggregator, which combines these potentially conflicting and overlapping labels into one label for each example.",1 Introduction,[0],[0]
The resulting labeled examples are then used to train an arbitrary discriminative model.,1 Introduction,[0],[0]
"To create the input explanations, the user views a subset S of an unlabeled dataset D (where |S| |D|) and provides for each input xi ∈ S a label yi and a natural language explanation ei, a sentence explaining why the example should receive that label.",2.1 Explanations,[0],[0]
"The explanation ei generally refers to specific aspects of the example (e.g., in Figure 2, the location of a specific string “his wife”).",2.1 Explanations,[0],[0]
"The semantic parser takes a natural language explanation ei and returns a set of LFs (logical forms or labeling functions) {f1, . . .",2.2 Semantic Parser,[0],[0]
", fk} of the form fi : X → {−1, 0, 1} in a binary classification setting, with 0 representing abstention.",2.2 Semantic Parser,[0],[0]
"We emphasize that the goal of this semantic parser is not to generate the single correct parse, but rather to have coverage over many potentially useful LFs.1
1Indeed, we find empirically that an incorrect LF nearby the correct one in the space of logical forms actually has higher end-task accuracy 57% of the time (see Section 4.2).
",2.2 Semantic Parser,[0],[0]
We choose a simple rule-based semantic parser that can be used without any training.,2.2 Semantic Parser,[0],[0]
"Formally, the parser uses a set of rules of the form α → β, where α can be replaced by the token(s) in β (see Figure 3 for example rules).",2.2 Semantic Parser,[0],[0]
"To identify candidate LFs, we recursively construct a set of valid parses for each span of the explanation, based on the substitutions defined by the grammar rules.",2.2 Semantic Parser,[0],[0]
"At the end, the parser returns all valid parses (LFs in our case) corresponding to the entire explanation.
",2.2 Semantic Parser,[0],[0]
We also allow an arbitrary number of tokens in a given span to be ignored when looking for a matching rule.,2.2 Semantic Parser,[0],[0]
"This improves the ability of the parser to handle unexpected input, such as unknown words or typos, since the portions of the input that are parseable can still result in a valid parse.",2.2 Semantic Parser,[0],[0]
"For example, in Figure 3, the word “person” is ignored.
",2.2 Semantic Parser,[0],[0]
"All predicates included in our grammar (summarized in Table 1) are provided to annotators, with minimal examples of each in use (Appendix A).",2.2 Semantic Parser,[0],[0]
"Importantly, all rules are domain independent (e.g., all three relation extraction tasks that we tested used the same grammar), making the semantic parser easily transferrable to new domains.",2.2 Semantic Parser,[0],[0]
"Additionally, while this paper focuses on the task of relation extraction, in principle the BabbleLabble framework can be applied to other tasks or settings by extending the grammar with the necessary primitives (e.g., adding primitives for rows and columns to enable explanations about the alignments of words in tables).",2.2 Semantic Parser,[0],[0]
"To guide the construction of the grammar, we collected 500 explanations for the Spouse domain from workers
on Amazon Mechanical Turk and added support for the most commonly used predicates.",2.2 Semantic Parser,[0],[0]
These were added before the experiments described in Section 4.,2.2 Semantic Parser,[0],[0]
Altogether the grammar contains 200 rule templates.,2.2 Semantic Parser,[0],[0]
The input to the filter bank is a set of candidate LFs produced by the semantic parser.,2.3 Filter Bank,[0],[0]
The purpose of the filter bank is to discard as many incorrect LFs as possible without requiring additional labels.,2.3 Filter Bank,[0],[0]
"It consists of two classes of filters: semantic and pragmatic.
",2.3 Filter Bank,[0],[0]
"Recall that each explanation ei is collected in the context of a specific labeled example (xi, yi).",2.3 Filter Bank,[0],[0]
"The semantic filter checks for LFs that are inconsistent with their corresponding example; formally, any LF f for which f(xi) 6=",2.3 Filter Bank,[0],[0]
yi is discarded.,2.3 Filter Bank,[0],[0]
"For example, in the first explanation in Figure 2, the word “right” can be interpreted as either “immediately” (as in “right before”) or simply “to the
right.”",2.3 Filter Bank,[0],[0]
"The latter interpretation results in a function that is inconsistent with the associated example (since “his wife” is actually to the left of person 2), so it can be safely removed.
",2.3 Filter Bank,[0],[0]
"The pragmatic filters removes LFs that are constant, redundant, or correlated.",2.3 Filter Bank,[0],[0]
"For example, in Figure 2, LF 2a is constant, as it labels every example positively (since all examples contain two people from the same sentence).",2.3 Filter Bank,[0],[0]
"LF 3b is redundant, since even though it has a different syntax tree from LF 3a, it labels the training set identically and therefore provides no new signal.
",2.3 Filter Bank,[0],[0]
"Finally, out of all LFs from the same explanation that pass all the other filters, we keep only the most specific (lowest coverage) LF.",2.3 Filter Bank,[0],[0]
"This prevents multiple correlated LFs from a single example from dominating.
",2.3 Filter Bank,[0],[0]
"As we show in Section 4, over three tasks, the filter bank removes 86% of incorrect parses, and the incorrect ones that remain have average endtask accuracy within 2.5% of the corresponding correct parses.",2.3 Filter Bank,[0],[0]
The label aggregator combines multiple (potentially conflicting) suggested labels from the LFs and combines them into a single probabilistic label per example.,2.4 Label Aggregator,[0],[0]
"Concretely, if m LFs pass the filter bank and are applied to n examples, the label aggregator implements a function f : {−1, 0, 1}m×n",2.4 Label Aggregator,[0],[0]
"→ [0, 1]n.
",2.4 Label Aggregator,[0],[0]
"A naive solution would be to use a simple majority vote, but this fails to account for the fact that LFs can vary widely in accuracy and coverage.",2.4 Label Aggregator,[0],[0]
"Instead, we use data programming (Ratner et al., 2016), which models the relationship between the true labels and the output of the labeling functions as a factor graph.",2.4 Label Aggregator,[0],[0]
"More specifically, given the true labels Y ∈ {−1, 1}n (latent) and label matrix Λ ∈ {−1, 0, 1}m×n (observed) where Λi,j = LFi(xj), we define two types of factors representing labeling propensity and accuracy:
φLabi,j (Λ, Y ) = 1{Λi,j 6= 0} (1) φAcci,j (Λ, Y ) = 1{Λi,j = yj}.",2.4 Label Aggregator,[0],[0]
"(2)
Denoting the vector of factors pertaining to a given data point xj as φj(Λ, Y ) ∈ Rm, define the model:
pw(Λ, Y )",2.4 Label Aggregator,[0],[0]
= Z −1 w exp,2.4 Label Aggregator,[0],[0]
"( n∑ j=1 w · φj(Λ, Y ) )",2.4 Label Aggregator,[0],[0]
", (3)
where w ∈ R2m is the weight vector and Zw is the normalization constant.",2.4 Label Aggregator,[0],[0]
"To learn this model without knowing the true labels Y , we minimize the negative log marginal likelihood given the observed labels Λ:
ŵ = arg min w − log ∑ Y pw(Λ, Y ) (4)
using SGD and Gibbs sampling for inference, and then use the marginals pŵ(Y | Λ) as probabilistic training labels.
",2.4 Label Aggregator,[0],[0]
"Intuitively, we infer accuracies of the LFs based on the way they overlap and conflict with one another.",2.4 Label Aggregator,[0],[0]
"Since noisier LFs are more likely to have high conflict rates with others, their corresponding accuracy weights in w will be smaller, reducing their influence on the aggregated labels.",2.4 Label Aggregator,[0],[0]
The noisily-labeled training set that the label aggregator outputs is used to train an arbitrary discriminative model.,2.5 Discriminative Model,[0],[0]
One advantage of training a discriminative model on the task instead of using the label aggregator as a classifier directly is that the label aggregator only takes into account those signals included in the LFs.,2.5 Discriminative Model,[0],[0]
"A discriminative model, on the other hand, can incorporate features that were not identified by the user but are nevertheless informative.2 Consequently, even examples for which all LFs abstained can still be classified correctly.",2.5 Discriminative Model,[0],[0]
"On the three tasks we evaluate, using the discriminative model averages 4.3 F1 points higher than using the label aggregator directly.
",2.5 Discriminative Model,[0],[0]
"For the results reported in this paper, our discriminative model is a simple logistic regression classifier with generic features defined over dependency paths.3 These features include unigrams,
2We give an example of two such features in Section 4.3.",2.5 Discriminative Model,[0],[0]
"3https://github.com/HazyResearch/treedlib
bigrams, and trigrams of lemmas, dependency labels, and part of speech tags found in the siblings, parents, and nodes between the entities in the dependency parse of the sentence.",2.5 Discriminative Model,[0],[0]
"We found this to perform better on average than a biLSTM, particularly for the traditional supervision baselines with small training set sizes; it also provided easily interpretable features for analysis.",2.5 Discriminative Model,[0.959324517109806],"['For linguistic features to be more effective in current coreference resolvers, which rely heavily on lexical features, they should also provide a strong signal for coreference resolution.']"
"We evaluate the accuracy of BabbleLabble on three relation extraction tasks, which we refer to as Spouse, Disease, and Protein.",3 Experimental Setup,[0],[0]
"The goal of each task is to train a classifier for predicting whether the two entities in an example are participating in the relationship of interest, as described below.",3 Experimental Setup,[0],[0]
"Statistics for each dataset are reported in Table 2, with one example and one explanation for each given in Figure 4 and additional explanations shown in Appendix B.
In the Spouse task, annotators were shown a sentence with two highlighted names and asked to label whether the sentence suggests that the two people are spouses.",3.1 Datasets,[0],[0]
"Sentences were pulled from the Signal Media dataset of news articles (Corney
et al., 2016).",3.1 Datasets,[0],[0]
"Ground truth data was collected from Amazon Mechanical Turk workers, accepting the majority label over three annotations.",3.1 Datasets,[0],[0]
"The 30 explanations we report on were sampled randomly from a pool of 200 that were generated by 10 graduate students unfamiliar with BabbleLabble.
",3.1 Datasets,[0],[0]
"In the Disease task, annotators were shown a sentence with highlighted names of a chemical and a disease and asked to label whether the sentence suggests that the chemical causes the disease.",3.1 Datasets,[0],[0]
"Sentences and ground truth labels came from a portion of the 2015 BioCreative chemical-disease relation dataset (Wei et al., 2015), which contains abstracts from PubMed.",3.1 Datasets,[0],[0]
"Because this task requires specialized domain expertise, we obtained explanations by having someone unfamiliar with BabbleLabble translate from Python to natural language labeling functions from an existing publication that explored applying weak supervision to this task (Ratner et al., 2018).
",3.1 Datasets,[0],[0]
"The Protein task was completed in conjunction with OccamzRazor, a neuroscience company targeting biological pathways of Parkinson’s disease.",3.1 Datasets,[0],[0]
"For this task, annotators were shown a sentence from the relevant biomedical literature with highlighted names of a protein and a kinase and asked to label whether or not the kinase influences the protein in terms of a physical interaction or phosphorylation.",3.1 Datasets,[0],[0]
"The annotators had domain expertise but minimal programming experience, making BabbleLabble a natural fit for their use case.",3.1 Datasets,[0],[0]
Text documents are tokenized with spaCy.4,3.2 Experimental Settings,[0],[0]
"The semantic parser is built on top of the Python-based
4https://github.com/explosion/spaCy
implementation SippyCup.5 On a single core, parsing 360 explanations takes approximately two seconds.",3.2 Experimental Settings,[0],[0]
"We use existing implementations of the label aggregator, feature library, and discriminative classifier described in Sections 2.4–2.5 provided by the open-source project Snorkel (Ratner et al., 2018).
",3.2 Experimental Settings,[0],[0]
Hyperparameters for all methods we report were selected via random search over thirty configurations on the same held-out development set.,3.2 Experimental Settings,[0],[0]
"We searched over learning rate, batch size, L2 regularization, and the subsampling rate (for improving balance between classes).6 All reported F1 scores are the average value of 40 runs with random seeds and otherwise identical settings.",3.2 Experimental Settings,[0],[0]
"We evaluate the performance of BabbleLabble with respect to its rate of improvement by number of user inputs, its dependence on correctly parsed logical forms, and the mechanism by which it utilizes logical forms.",4 Experimental Results,[0],[0]
In Table 3 we report the average F1 score of a classifier trained with BabbleLabble using 30 explanations or traditional supervision with the indicated number of labels.,4.1 High Bandwidth Supervision,[0],[0]
"On average, it took the same amount of time to collect 30 explanations as 60 labels.7 We observe that in all three tasks, BabbleLabble achieves a given F1 score with far fewer user inputs than traditional supervision, by
5https://github.com/wcmac/sippycup 6Hyperparameter ranges: learning rate (1e-2 to 1e-4), batch size (32 to 128), L2 regularization (0 to 100), subsampling rate (0 to 0.5)
7Zaidan and Eisner (2008) also found that collecting annotator rationales in the form of highlighted substrings from the sentence only doubled annotation time.
as much as 100 times in the case of the Spouse task.",4.1 High Bandwidth Supervision,[0],[0]
"Because explanations are applied to many unlabeled examples, each individual input from the user can implicitly contribute many (noisy) labels to the learning algorithm.
",4.1 High Bandwidth Supervision,[0],[0]
"We also observe, however, that once the number of labeled examples is sufficiently large, traditional supervision once again dominates, since ground truth labels are preferable to noisy ones generated by labeling functions.",4.1 High Bandwidth Supervision,[0],[0]
"However, in domains where there is much more unlabeled data available than labeled data (which in our experience is most domains), we can gain in supervision efficiency from using BabbleLabble.
",4.1 High Bandwidth Supervision,[0],[0]
"Of those explanations that did not produce a correct LF, 4% were caused by the explanation referring to unsupported concepts (e.g., one explanation referred to “the subject of the sentence,” which our simple parser doesn’t support).",4.1 High Bandwidth Supervision,[0],[0]
Another 2% were caused by human errors (the correct LF for the explanation was inconsistent with the example).,4.1 High Bandwidth Supervision,[0],[0]
"The remainder were due to unrecognized paraphrases (e.g., the explanation said “the order of appearance is X, Y” instead of a supported phrasing like “X comes before Y”).",4.1 High Bandwidth Supervision,[0],[0]
"In Table 4, we report LF summary statistics before and after filtering.",4.2 Utility of Incorrect Parses,[0],[0]
LF correctness is based on exact match with a manually generated parse for each explanation.,4.2 Utility of Incorrect Parses,[0],[0]
"Surprisingly, the simple heuristic-based filter bank successfully removes over 95% of incorrect LFs in all three tasks, resulting in final LF sets that are 86% correct on average.",4.2 Utility of Incorrect Parses,[0],[0]
"Furthermore, among those LFs that pass through the filter bank, we found that the average difference in end-task accuracy between correct and incorrect parses is less than 2.5%.",4.2 Utility of Incorrect Parses,[0],[0]
"Intuitively, the filters are effective because it is quite difficult for an LF to be parsed from the explana-
tion, label its own example correctly (passing the semantic filter), and not label all examples in the training set with the same label or identically to another LF (passing the pragmatic filter).
",4.2 Utility of Incorrect Parses,[0],[0]
"We went one step further: using the LFs that would be produced by a perfect semantic parser as starting points, we searched for “nearby” LFs (LFs differing by only one predicate) with higher endtask accuracy on the test set and succeeded 57% of the time (see Figure 5 for an example).",4.2 Utility of Incorrect Parses,[0],[0]
"In other words, when users provide explanations, the signals they describe provide good starting points, but they are actually unlikely to be optimal.",4.2 Utility of Incorrect Parses,[0],[0]
"This observation is further supported by Table 5, which shows that the filter bank is necessary to remove clearly irrelevant LFs, but with that in place, the simple rule-based semantic parser and a perfect parser have nearly identical average F1 scores.",4.2 Utility of Incorrect Parses,[0],[0]
"Once we have relevant logical forms from userprovided explanations, we have multiple options for how to use them.",4.3 Using LFs as Functions or Features,[0],[0]
Srivastava et al. (2017) propose using these logical forms as features in a linear classifier.,4.3 Using LFs as Functions or Features,[0],[0]
"We choose instead to use them as functions for weakly supervising the creation of a larger training set via data programming (Ratner et al., 2016).",4.3 Using LFs as Functions or Features,[0],[0]
"In Table 6, we compare the two approaches directly, finding that the the data programming approach outperforms a feature-based one by 9.5 F1 points with the rule-based parser, and by 4.5 points with a perfect parser.
",4.3 Using LFs as Functions or Features,[0],[0]
We attribute this difference primarily to the ability of data programming to utilize unlabeled data.,4.3 Using LFs as Functions or Features,[0],[0]
"In Figure 6, we show how the data programming approach improves with the number of unlabeled examples, even as the number of LFs remains constant.",4.3 Using LFs as Functions or Features,[0],[0]
We also observe qualitatively that data programming exposes the classifier to additional patterns that are correlated with our explanations but not mentioned directly.,4.3 Using LFs as Functions or Features,[0],[0]
"For example, in the Disease task, two of the features weighted most
highly by the discriminative model were the presence of the trigrams “could produce a” or “support diagnosis of” between the chemical and disease, despite none of these words occurring in the explanations for that task.",4.3 Using LFs as Functions or Features,[0],[0]
In Table 6 we see a 4.3 F1 point improvement (10%) when we use the discriminative model that can take advantage of these features rather than applying the LFs directly to the test set and making predictions based on the output of the label aggregator.,4.3 Using LFs as Functions or Features,[0],[0]
Our work has two themes: modeling natural language explanations/instructions and learning from weak supervision.,5 Related Work and Discussion,[0],[0]
The closest body of work is on “learning from natural language.”,5 Related Work and Discussion,[0],[0]
"As mentioned earlier, Srivastava et al. (2017) convert natural language explanations into classifier features (whereas we convert them into labeling functions).",5 Related Work and Discussion,[0],[0]
"Goldwasser and Roth (2011) convert natural lan-
guage into concepts (e.g., the rules of a card game).",5 Related Work and Discussion,[0],[0]
Ling and Fidler (2017) use natural language explanations to assist in supervising an image captioning model.,5 Related Work and Discussion,[0],[0]
Weston (2016); Li et al. (2016) learn from natural language feedback in a dialogue.,5 Related Work and Discussion,[0],[0]
"Wang et al. (2017) convert natural language definitions to rules in a semantic parser to build up progressively higher-level concepts.
",5 Related Work and Discussion,[0],[0]
"We lean on the formalism of semantic parsing (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang, 2016).",5 Related Work and Discussion,[0],[0]
"One notable trend is to learn semantic parsers from weak supervision (Clarke et al., 2010; Liang et al., 2011), whereas our goal is to obtain weak supervision signal from semantic parsers.
",5 Related Work and Discussion,[0],[0]
The broader topic of weak supervision has received much attention; we mention some works most related to relation extraction.,5 Related Work and Discussion,[0],[0]
"In distant supervision (Craven et al., 1999; Mintz et al., 2009) and multi-instance learning (Riedel et al., 2010; Hoffmann et al., 2011), an existing knowledge base is used to (probabilistically) impute a training set.",5 Related Work and Discussion,[0],[0]
"Various extensions have focused on aggregating a variety of supervision sources by learning generative models from noisy labels (Alfonseca et al., 2012; Takamatsu et al., 2012; Roth and Klakow, 2013; Ratner et al., 2016; Varma et al., 2017).
",5 Related Work and Discussion,[0],[0]
"Finally, while we have used natural language explanations as input to train models, they can also be output to interpret models (Krening et al., 2017; Lei et al., 2016).",5 Related Work and Discussion,[0],[0]
"More generally, from a machine learning perspective, labels are the primary asset, but they are a low bandwidth signal between annotators and the learning algorithm.",5 Related Work and Discussion,[0],[0]
Natural language opens up a much higher-bandwidth communication channel.,5 Related Work and Discussion,[0],[0]
"We have shown promising results in relation extraction (where one explanation can be “worth” 100 labels), and it would be interesting to extend our framework to other tasks and more interactive settings.",5 Related Work and Discussion,[0],[0]
"The code, data, and experiments for this paper are available on the CodaLab platform at https: //worksheets.codalab.org/worksheets/ 0x900e7e41deaa4ec5b2fe41dc50594548/.",Reproducibility,[0],[0]
We gratefully acknowledge the support of the following organizations: DARPA under No.,Acknowledgments,[0],[0]
"N66001-15-C-4043 (SIMPLEX), No. FA8750-17-2-0095 (D3M), No. FA8750-122-0335 (XDATA), and No. FA8750-13-2-0039 (DEFT), DOE under No. 108845, NIH under No. U54EB020405 (Mobilize), ONR under No. N000141712266 and No. N000141310129, AFOSR under No. 580K753, the Intel/NSF CPS Security grant No. 1505728, the Michael J. Fox Foundation for Parkinsons Research under Grant No. 14672, the Secure Internet of Things Project, Qualcomm, Ericsson, Analog Devices, the Moore Foundation, the Okawa Research Grant, American Family Insurance, Accenture, Toshiba, the National Science Foundation Graduate Research Fellowship under Grant No.",Acknowledgments,[0],[0]
"DGE-114747, the Stanford Finch Family Fellowship, the Joseph W. and Hon Mai Goodman Stanford Graduate Fellowship, an NSF CAREER Award IIS-1552635, and the members of the Stanford DAWN project: Facebook, Google, Intel, Microsoft, NEC, Teradata, and VMware.
",Acknowledgments,[0],[0]
"We thank Alex Ratner and the developers of Snorkel for their assistance with data programming, as well as the many members of the Hazy Research group and Stanford NLP group who provided feedback and tested early prototyptes.",Acknowledgments,[0],[0]
"Thanks as well to the OccamzRazor team: Tarik Koc, Benjamin Angulo, Katharina S. Volz, and Charlotte Brzozowski.
",Acknowledgments,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon.,Acknowledgments,[0],[0]
"Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views, policies, or endorsements, either expressed or implied, of DARPA, DOE, NIH, ONR, AFOSR, NSF, or the U.S. Government.",Acknowledgments,[0],[0]
"Below are the predicates in the rule-based semantic parser grammar, each of which may have many supported paraphrases, only one of which is listed here in a minimal example.",A Predicate Examples,[0],[0]
and: X is true and Y is true or: X is true or Y is true not: X is not true any: Any of X or Y or Z is true all: All of X and Y and Z are true none:,Logic,[0],[0]
None of X or Y or Z is true,Logic,[0],[0]
=: X is equal to Y 6=: X is not Y <: X is smaller than Y ≤: X is no more than Y >: X is larger than Y ≥: X is at least Y,Comparison,[0],[0]
"lower: X is lowercase upper: X is upper case capital: X is capitalized all caps: X is in all caps starts with: X starts with ""cardio"" ends with: X ends with ""itis"" substring: X contains ""-induced""",Syntax,[0],[0]
person:,Named-entity Tags,[0],[0]
A person is between X and Y location: A place is within two words of X date: A date is between X and Y number: There are three numbers in the sentence organization: An organization is right after X,Named-entity Tags,[0],[0]
"list: (X, Y) is in Z set: X, Y, and Z are true count:",Lists,[0],[0]
There is one word between X and Y contains: X is in Y intersection: At least two of X are in Y map: X is at the start of a word in Y filter: There are three capitalized words to the left of X alias: A spouse word is in the sentence (“spouse” is a predefined list from the user),Lists,[0],[0]
word distance: X is two words before Y char distance: X is twenty characters after Y left: X is before Y right: X is after Y between: X is between Y and Z within: X is within five words of Y,Position,[0],[0]
The following are a sample of the explanations provided by users for each task.,B Sample Explanations,[0],[0]
"Users referred to the first person in the sentence as “X” and the second as “Y”.
",Spouse,[0],[0]
"Label true because ""and"" occurs between X and Y and ""marriage"" occurs one word after person1.
",Spouse,[0],[0]
"Label true because person Y is preceded by ‘beau’.
",Spouse,[0],[0]
"Label false because the words ""married"", ""spouse"", ""husband"", and ""wife"" do not occur in the sentence.
",Spouse,[0],[0]
"Label false because there are more than 2 people in the sentence and ""actor"" or ""actress"" is left of person1 or person2.",Spouse,[0],[0]
"Label true because the disease is immediately after the chemical and ’induc’ or ’assoc’ is in the chemical name.
",Disease,[0],[0]
"Label true because a word containing ’develop’ appears somewhere before the chemical, and the word ’following’ is between the disease and the chemical.
",Disease,[0],[0]
"Label true because ""induced by"", ""caused by"", or ""due to"" appears between the chemical and the disease.",Disease,[0],[0]
"""
Label false because ""none"", ""not"", or ""no"" is within 30 characters to the left of the disease.",Disease,[0],[0]
"Label true because ""Ser"" or ""Tyr"" are within 10 characters of the protein.
",Protein,[0],[0]
"Label true because the words ""by"" or ""with"" are between the protein and kinase and the words ""no"", ""not"" or ""none"" are not in between the protein and kinase and the total number of words between them is smaller than 10.
",Protein,[0],[0]
"Label false because the sentence contains ""mRNA"", ""DNA"", or ""RNA"".
",Protein,[0],[0]
"Label false because there are two "","" between the protein and the kinase with less than 30 characters between them.",Protein,[0],[0]
"Training accurate classifiers requires many labels, but each label provides only limited information (one bit for binary classification).",abstractText,[0],[0]
"In this work, we propose BabbleLabble, a framework for training classifiers in which an annotator provides a natural language explanation for each labeling decision.",abstractText,[0],[0]
"A semantic parser converts these explanations into programmatic labeling functions that generate noisy labels for an arbitrary amount of unlabeled data, which is used to train a classifier.",abstractText,[0],[0]
"On three relation extraction tasks, we find that users are able to train classifiers with comparable F1 scores from 5–100 faster by providing explanations instead of just labels.",abstractText,[0],[0]
"Furthermore, given the inherent imperfection of labeling functions, we find that a simple rule-based semantic parser suffices.",abstractText,[0],[0]
Training Classifiers with Natural Language Explanations,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2775–2779 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2775",text,[0],[0]
"End-to-end dialogue systems, based on neural architectures like bidirectional LSTMs or Memory Networks (Sukhbaatar et al., 2015) trained directly by gradient descent on dialogue logs, have been showing promising performance in multiple contexts (Wen et al., 2016; Serban et al., 2016; Bordes et al., 2016).",1 Introduction,[0],[0]
One of their main advantages is that they can rely on large data sources of existing dialogues to learn to cover various domains without requiring any expert knowledge.,1 Introduction,[0],[0]
"However, the flip side is that they also exhibit limited engagement, especially in chit-chat settings: they lack consistency and do not leverage proactive engagement strategies as (even partially) scripted chatbots do.
Zhang et al. (2018) introduced the PERSONACHAT dataset as a solution to cope with this issue.",1 Introduction,[0],[0]
"This dataset consists of dialogues between pairs of agents with text profiles, or personas, attached to
each of them.",1 Introduction,[0],[0]
"As shown in their paper, conditioning an end-to-end system on a given persona improves the engagement of a dialogue agent.",1 Introduction,[0],[0]
"This paves the way to potentially end-to-end personalized chatbots because the personas of the bots, by being short texts, could be easily edited by most users.",1 Introduction,[0],[0]
"However, the PERSONA-CHAT dataset was created using an artificial data collection mechanism based on Mechanical Turk.",1 Introduction,[0],[0]
"As a result, neither dialogs nor personas can be fully representative of real user-bot interactions and the dataset coverage remains limited, containing a bit more than 1k different personas.
",1 Introduction,[0],[0]
"In this paper, we build a very large-scale persona-based dialogue dataset using conversations previously extracted from REDDIT1.",1 Introduction,[0],[0]
"With simple heuristics, we create a corpus of over 5 million personas spanning more than 700 million conversations.",1 Introduction,[0],[0]
We train persona-based end-to-end dialogue models on this dataset.,1 Introduction,[0],[0]
"These models outperform their counterparts that do not have access to personas, confirming results of Zhang et al. (2018).",1 Introduction,[0],[0]
"In addition, the coverage of our dataset seems very good since pre-training on it also leads to state-of-the-art results on the PERSONA-CHAT dataset.",1 Introduction,[0],[0]
"With the rise of end-to-end dialogue systems, personalized trained systems have started to appear.",2 Related work,[0],[0]
Li et al. (2016) proposed to learn latent variables representing each speaker’s bias/personality in a dialogue model.,2 Related work,[0],[0]
"Other classic strategies include extracting explicit variables from structured knowledge bases or other symbolic sources as in (Ghazvininejad et al., 2017; Joshi et al., 2017; Young et al., 2017).",2 Related work,[0],[0]
"Still, in the context of per-
1https://www.reddit.com/r/datasets/ comments/3bxlg7/
sonal chatbots, it might be more desirable to condition on data that can be generated and interpreted by the user itself such as text rather than relying on some knowledge base facts that might not exist for everyone or a great variety of situations.",2 Related work,[0],[0]
"PERSONA-CHAT (Zhang et al., 2018) recently introduced a dataset of conversations revolving around human habits and preferences.",2 Related work,[0],[0]
"In their experiments, they showed that conditioning on a text description of each speaker’s habits, their persona, improved dialogue modeling.
",2 Related work,[0],[0]
"In this paper, we use a pre-existing REDDIT data dump as data source.",2 Related work,[0],[0]
REDDIT is a massive online message board.,2 Related work,[0],[0]
Dodge et al. (2015) used it to assess chit-chat qualities of generic dialogue models.,2 Related work,[0],[0]
Yang et al. (2018) used response prediction on REDDIT as an auxiliary task in order to improve prediction performance on natural language inference problems.,2 Related work,[0],[0]
Our goal is to learn to predict responses based on a persona for a large variety of personas.,3 Building a dataset of millions of persona-based dialogues,[0],[0]
"To that end, we build a dataset of examples of the following form using data from REDDIT:
• Persona:",3 Building a dataset of millions of persona-based dialogues,[0],[0]
"[“I like sport”, “I work a lot”] • Context: “I love running.”",3 Building a dataset of millions of persona-based dialogues,[0],[0]
• Response: “Me too!,3 Building a dataset of millions of persona-based dialogues,[0],[0]
"But only on weekends.”
",3 Building a dataset of millions of persona-based dialogues,[0],[0]
"The persona is a set of sentences representing the personality of the responding agent, the context is the utterance that it responds to, and the response is the answer to be predicted.",3 Building a dataset of millions of persona-based dialogues,[0],[0]
"As in (Dodge et al., 2015), we use a preexisting dump of REDDIT that consists of 1.7 billion comments.",3.1 Preprocessing,[0],[0]
We tokenize sentences by padding all special characters with a space and splitting on whitespace characters.,3.1 Preprocessing,[0],[0]
We create a dictionary containing the 250k most frequent tokens.,3.1 Preprocessing,[0],[0]
We truncate comments that are longer than 100 tokens.,3.1 Preprocessing,[0],[0]
"We construct the persona of a user by gathering all the comments they wrote, splitting them into sentences, and selecting the sentences that satisfy the following rules: (i) each sentence must contain between 4 and 20 words or punctuation marks, (ii) it contains either the word I or my, (iii) at least
one verb, and (iv) at least one noun, pronoun or adjective.
",3.2 Persona extraction,[0],[0]
"To handle the quantity of data involved, we limit the size of a persona to N sentences for each user.",3.2 Persona extraction,[0],[0]
We compare four different setups for persona creation.,3.2 Persona extraction,[0],[0]
"In the rules setup, we select up to N random sentences that satisfy the rules above.",3.2 Persona extraction,[0],[0]
"In the rules + classifier setup, we filter with the rules then score the resulting sentences using a bag-of-words classifier that is trained to discriminate PERSONACHAT persona sentences from random comments.",3.2 Persona extraction,[0],[0]
We manually tune a threshold on the score in order to select sentences.,3.2 Persona extraction,[0],[0]
"If there are more than N eligible persona sentences for a given user, we keep the highest-scored ones.",3.2 Persona extraction,[0],[0]
"In the random from user setup, we randomly select sentences uttered by the user while keeping the sentence length requirement above (we ignore the other rules).",3.2 Persona extraction,[0],[0]
The random from dataset baseline refers to random sentences from the dataset.,3.2 Persona extraction,[0],[0]
They do not necessarily come from the same user.,3.2 Persona extraction,[0],[0]
"This last setup serves as a control mechanism to verify that the gains in prediction accuracy are due to the user-specific information contained in personas.
",3.2 Persona extraction,[0],[0]
"In the example at the beginning of this section, the response is clearly consistent with the persona.",3.2 Persona extraction,[0],[0]
"There may not always be such an obvious relationship between the two: the discussion topic may not be covered by the persona, a single user may write contradictory statements, and due to errors in the extraction process, some persona sentences may not represent a general trait of the user (e.g. I am feeling happy today).",3.2 Persona extraction,[0],[0]
We take each pair of successive comments in a thread to form the context and response of an example.,3.3 Dataset creation,[0],[0]
The persona corresponding to the response is extracted using one of the methods of Section 3.2.,3.3 Dataset creation,[0],[0]
"We split the dataset randomly between training, validation and test.",3.3 Dataset creation,[0],[0]
Validation and test sets contain 50k examples each.,3.3 Dataset creation,[0],[0]
"We extract personas using training data only: test set responses cannot be contained explicitly in the persona.
",3.3 Dataset creation,[0],[0]
"In total, we select personas covering 4.6m users in the rule-based setups and 7.2m users in the random setups.",3.3 Dataset creation,[0],[0]
"This is a sizable fraction of the total 13.2m users of the dataset; depending on the persona selection setup, between 97 and 99.4 % of the training set examples are linked to a persona.",3.3 Dataset creation,[0],[0]
"We model dialogue by next utterance retrieval (Lowe et al., 2016), where a response is picked among a set of candidates and not generated.",4 End-to-end dialogue models,[0],[0]
The overall architecture is depicted in Fig. 1.,4.1 Architecture,[0],[0]
We encode the persona and the context using separate modules.,4.1 Architecture,[0],[0]
"As in Zhang et al. (2018), we combine the encoded context and persona using a 1-hop memory network with a residual connection, using the context as query and the set of persona sentences as memory.",4.1 Architecture,[0],[0]
We also encode all candidate responses and compute the dot-product between all those candidate representations and the joint representation of the context and the persona.,4.1 Architecture,[0],[0]
"The predicted response is the candidate that maximizes the dot product.
",4.1 Architecture,[0],[0]
We train by passing all the dot products through a softmax and maximizing the log-likelihood of the correct responses.,4.1 Architecture,[0],[0]
"We use mini-batches of training examples and, for each example therein, all the responses of the other examples of the same batch are used as negative responses.",4.1 Architecture,[0],[0]
Both context and response encoders share the same architecture and word embeddings but have different weights in the subsequent layers.,4.2 Context and response encoders,[0],[0]
"We train three different encoder architectures.
",4.2 Context and response encoders,[0],[0]
Bag-of-words applies two linear projections separated by a tanh non-linearity to the word embeddings.,4.2 Context and response encoders,[0],[0]
"We then sum the resulting sentence representation across all positions in the sentence and divide the result by √ n where n is the length of the sequence.
",4.2 Context and response encoders,[0],[0]
LSTM applies a 2-layer bidirectional LSTM.,4.2 Context and response encoders,[0],[0]
"We use the last hidden state as encoded sentence.
",4.2 Context and response encoders,[0],[0]
"Transformer is a variation of an End-to-end Memory Network (Sukhbaatar et al., 2015) introduced by Vaswani et al. (2017).",4.2 Context and response encoders,[0],[0]
"Based solely on attention mechanisms, it exhibited state-of-the-art performance on next utterance retrieval tasks in dialogues (Yang et al., 2018).",4.2 Context and response encoders,[0],[0]
Here we use only its encoding module.,4.2 Context and response encoders,[0],[0]
"We subsequently average the resulting representation across all positions in the sentence, yielding a fixed-size representation.",4.2 Context and response encoders,[0],[0]
The persona encoder encodes each persona sentence separately.,4.3 Persona encoder,[0],[0]
It relies on the same word embeddings as the context encoder and applies a linear layer on top of them.,4.3 Persona encoder,[0],[0]
"We then sum the representations across the sentence.
",4.3 Persona encoder,[0],[0]
We deliberately choose a simpler architecture than the other encoders for performance reasons as the number of personas encoded for each batch is an order of magnitude greater than the number of training examples.,4.3 Persona encoder,[0],[0]
Most personas are short sentences; we therefore expect a bag-of-words representation to encode them well.,4.3 Persona encoder,[0],[0]
We train models on the persona-based dialogue dataset described in Section 3.3 and we evaluate its accuracy both on the original task and when transferring onto PERSONA-CHAT.,5 Experiments,[0],[0]
We optimize network parameters using Adamax with a learning rate of 8e−4 on mini-batches of size 512.,5.1 Experimental details,[0],[0]
"We initialize embeddings with FastText word vectors and optimize them during learning.
",5.1 Experimental details,[0],[0]
"REDDIT LSTMs use a hidden size of 150; we concatenate the last hidden states for both directions and layers, resulting in a final representation of size 600.",5.1 Experimental details,[0],[0]
"Transformer architectures on reddit use 4 layers with a hidden size of 300 and 6 attention heads, resulting in a final representation of size 300.",5.1 Experimental details,[0],[0]
We use Spacy for part-of-speech tagging in order to verify the persona extraction rules.,5.1 Experimental details,[0],[0]
"We distribute the training by splitting each batch across 8 GPUs; we stop training after 1 full epoch, which takes about 3 days.
",5.1 Experimental details,[0],[0]
"PERSONA-CHAT We used the revised version of the dataset where the personas have been rephrased, making it a harder task.",5.1 Experimental details,[0],[0]
"The dataset being only a few thousands samples, we had to reduce the architecture to avoid overfitting for the models trained purely on PERSONA-CHAT.",5.1 Experimental details,[0],[0]
"2 layers, 2 attention heads, a dropout of 0.2 and keeping the size of the word embeddings to 300 units yield the highest accuracy on the validation set.
",5.1 Experimental details,[0],[0]
IR Baseline,5.1 Experimental details,[0],[0]
"As basic baseline, we use an information retrieval (IR) system that ranks candidate responses according to a TF-IDF weighted exactmatch similarity with the context alone.",5.1 Experimental details,[0],[0]
Impact of personas We report the accuracy of the different architectures on the reddit task in Table 1.,5.2 Results,[0],[0]
Conditioning on personas improves the prediction performance regardless of the encoder architecture.,5.2 Results,[0],[0]
"Table 2 gives some examples of how the persona affects the predicted answer.
",5.2 Results,[0],[0]
"Influence of the persona extraction In Table 3, we report precision results for several persona extraction setups.",5.2 Results,[0],[0]
"The rules setup improves the results somewhat, however adding the persona classifier actually degrades the results.",5.2 Results,[0],[0]
"A possible interpretation is that the persona classifier is trained only on the PERSONA-CHAT revised personas, and that this selection might be too narrow and lack di-
versity.",5.2 Results,[0],[0]
"Increasing the maximum persona size also improves the prediction performance.
",5.2 Results,[0],[0]
Transfer learning,5.2 Results,[0],[0]
We compare the performance of transformer models trained on REDDIT and on PERSONA-CHAT on both datasets.,5.2 Results,[0],[0]
We report results in Table 4.,5.2 Results,[0],[0]
"This architecture provides a strong improvement over the results of (Zhang et al., 2018), jumping from 35.4% hits@1 to 42.1%.",5.2 Results,[0],[0]
"Pretraining the model on REDDIT and then fine-tuning on PERSONA-CHAT pushes this score to 60.7%, largely improving the state of the art.",5.2 Results,[0],[0]
"As expected, fine-tuning on PERSONA-CHAT reduces the performance on REDDIT.",5.2 Results,[0],[0]
"However, directly testing on PERSONA-CHAT the model trained on REDDIT without fine-tuning yields a very low result.",5.2 Results,[0],[0]
"This could be a consequence of a discrepancy
between the style of personas of the two datasets.",5.2 Results,[0],[0]
This paper shows how to create a very large dataset for persona-based dialogue.,6 Conclusion,[0],[0]
We show that training models to align answers both with the persona of their author and the context improves the predicting performance.,6 Conclusion,[0],[0]
The trained models show promising coverage as exhibited by the stateof-the-art transfer results on the PERSONA-CHAT dataset.,6 Conclusion,[0],[0]
"As pretraining leads to a considerable improvement in performance, future work could be done fine-tuning this model for various dialog systems.",6 Conclusion,[0],[0]
Future work may also entail building more advanced strategies to select a limited number of personas for each user while maximizing the prediction performance.,6 Conclusion,[0],[0]
"Current dialogue systems are not very engaging for users, especially when trained end-toend without relying on proactive reengaging scripted strategies.",abstractText,[0],[0]
Zhang et al. (2018) showed that the engagement level of end-to-end dialogue models increases when conditioning them on text personas providing some personalized back-story to the model.,abstractText,[0],[0]
"However, the dataset used in (Zhang et al., 2018) is synthetic and of limited size as it contains around 1k different personas.",abstractText,[0],[0]
In this paper we introduce a new dataset providing 5 million personas and 700 million persona-based dialogues.,abstractText,[0],[0]
"Our experiments show that, at this scale, training using personas still improves the performance of end-to-end systems.",abstractText,[0],[0]
"In addition, we show that other tasks benefit from the wide coverage of our dataset by fine-tuning our model on the data from (Zhang et al., 2018) and achieving state-of-the-art results.",abstractText,[0],[0]
Training Millions of Personalized Dialogue Agents,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 130–135 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Structured prediction, or the task of predicting multiple inter-dependent variables, is important in many domains, including computer vision, computational biology and natural language processing.",1 Introduction,[0],[0]
"For example, in sequence labelling, image segmentation, and parsing we are given input variables x, and must predict output variables y, where the number of possible y values are typically exponential in the number of variables that comprise it.",1 Introduction,[0],[0]
"Not only does this sometimes give rise to computational difficulties, it also leads to statistical parameter estimation issues, where learning precise models requires large amounts of labeled training data.
",1 Introduction,[0],[0]
"In some cases, unsupervised learning from plentiful unlabeled data may provide helpful outputs (Daumé III, 2009; Ammar et al., 2014).",1 Introduction,[0],[0]
But usually some form of more direct supervision is required to create a model truly useful to the task at hand.,1 Introduction,[0],[0]
In the absence of abundant labeled data we may consider alternative forms of supervision.,1 Introduction,[0],[0]
"For example, rather than providing labeled data instances, humans may more easily inject their
domain knowledge by providing “labels on features,” or “expectations” about correct outputs, as in generalized expectation criteria (Mann and McCallum, 2010), or by providing constraints, as in posterior regularization (Ganchev et al., 2010) or constraint driven learning (Chang et al., 2007).",1 Introduction,[0],[0]
"A major weakness of these methods, however, is that at training time inference must be done in the factor graph encompassing the union of the model’s factor graph and the expectation dependencies— often leading to prohibitively expensive inference.",1 Introduction,[0],[0]
"Moreover, these methods cannot learn from nondecomposable domain knowledge, where the domain knowledge is not in a form of a set of labeled features or constraints.
",1 Introduction,[0],[0]
"An easy way for humans to express domain knowledge is by writing a simple scalar scoring function that indicates preferences among choices for y given x. These human-coded functions may, for example, be based on arbitrary rule systems (or even Turing-complete programs) of the sort written by humans to solve problems before machine learning became so wide-spread.
",1 Introduction,[0],[0]
"In general, the human written domain knowledge functions are not expected to be perfect— most likely only examining a subset of features and not covering all cases.",1 Introduction,[0.9543840409353717],"['However, the incorporated features should be informative enough to be taken into account in the presence of lexical features, which are very strong features in the CoNLL dataset.']"
"Thus we are now faced with two challenges: (1) the domain knowledge functions have limited generalization; (2) the domain knowledge functions provide a ranking, but do not provide an inference (search) procedure.
",1 Introduction,[0],[0]
"This paper presents a new training method for structured prediction energy networks (SPENs) (Belanger and McCallum, 2016; Belanger et al., 2017) that aims to address both these challenges, yielding efficient inference for structured prediction, trained from human-coded domain knowledge plus unlabeled data, but not requiring any labeled data instances.",1 Introduction,[0],[0]
"In SPENs, the factor graph that typically represents
130
output variable dependencies is replaced with a deep neural network that takes y and x as input and outputs a scalar energy score, but is able to learn much richer correlations than are typically captured in factor graphs.",1 Introduction,[0],[0]
"Inference in SPENs is performed by gradient descent in the energy, back-propagated to cause steps in a relaxed y space.",1 Introduction,[0],[0]
"Whereas previous training procedures for SPENs used labeled data, here we train SPENs from only unlabeled data plus human-coded domain knowledge in the form of a scoring function.",1 Introduction,[0],[0]
"We do so by building on SampleRank (Rohanimanesh et al., 2011; Singh et al., 2010), which enforces that the rank of two sampled ys according to the trained factor graph is consistent with their rank according to distance to the labeled, true y.",1 Introduction,[0],[0]
"In our training method, pairs of y’s are obtained from successive steps of training-time gradient-descent inference on y; when their rank is not consistent with that of the domain knowledge function, we accordingly update the energy network parameters.
",1 Introduction,[0],[0]
"We demonstrate our method on a citation field extraction task, for which we learn a neural network (1) that generalizes beyond the original domain knowledge function, and (2) that provides efficient test-time inference by gradient descent.",1 Introduction,[0],[0]
"In general, SPEN parameterizes an energy function Ew(y,x) using deep neural networks over output variables y as well as input variables x, where w denotes the neural network’s parameters.",2 Structured Prediction Energy Networks,[0],[0]
Belanger and McCallum (2016) separate the energy function into global and local terms.,2 Structured Prediction Energy Networks,[0],[0]
"The role of the local terms is to capture the dependency among input x and each individual output variable yi, while the global term aims to capture long-range dependencies among output variables.
",2 Structured Prediction Energy Networks,[0],[0]
Prediction in SPENs requires finding ŷ,2 Structured Prediction Energy Networks,[0],[0]
=,2 Structured Prediction Energy Networks,[0],[0]
argminy∈Y,2 Structured Prediction Energy Networks,[0],[0]
"Ew(y,x)",2 Structured Prediction Energy Networks,[0],[0]
for the given input x.,2 Structured Prediction Energy Networks,[0],[0]
This inference problem is solved using gradient descent.,2 Structured Prediction Energy Networks,[0],[0]
"However, the energy surface is non-convex, which prevents gradient descent inference from finding the exact structure ymin that globally minimizes the energy function.",2 Structured Prediction Energy Networks,[0],[0]
One approach to address this problem is to parameterize the energy function such that the SPEN is convex in the output variables y,2 Structured Prediction Energy Networks,[0],[0]
"(Amos et al., 2017), but this limits the representational power of SPENs.",2 Structured Prediction Energy Networks,[0],[0]
"Al-
though gradient descent inference does not guarantee an exact solution, it has successfully been used in several domains such as multi-label classification (Belanger and McCallum, 2016), imagesegmentation (Gygli et al., 2017), and semantic role labeling (Belanger et al., 2017).",2 Structured Prediction Energy Networks,[0],[0]
"Different methods have been introduced for training SPENs: margin-based training (Belanger and McCallum, 2016), end-to-end learning (Belanger et al., 2017), and value matching (Gygli et al., 2017).",3 Rank-Based Training of SPENs,[0],[0]
"Margin-based training enforces the energy of the ground truth structure to be lower than the energy of every incorrect structure by a margin, which is calculated as the Hamming loss between the two structures.",3 Rank-Based Training of SPENs,[0],[0]
End-to-end learning unrolls the energy minimization into a differentiable computation graph to output the predicted structure.,3 Rank-Based Training of SPENs,[0],[0]
It then trains the model by directly minimizing the loss between the predicted and ground-truth structures.,3 Rank-Based Training of SPENs,[0],[0]
"Finally, the value matching approach trains SPENs such that the energy value matches the value of a given target function, such as the L2 distance between the ground-truth and predicted structures.
",3 Rank-Based Training of SPENs,[0],[0]
All of these methods strongly depend on the existence of the ground truth values either as labeled data or as the value of a function applied to it.,3 Rank-Based Training of SPENs,[0],[0]
"While dependence of the margin-based and endto-end learning approaches on the labeled data is explicit, this dependency in the case of valuematching may not be obvious.",3 Rank-Based Training of SPENs,[0],[0]
"In the absence of labeled data, we have to use the model’s predictions instead, for training.",3 Rank-Based Training of SPENs,[0],[0]
"These predictions are often incorrect, especially at early stages of training.",3 Rank-Based Training of SPENs,[0],[0]
"As a result, value-matching training is constrained to match the score of these predictions with the value of the energy function defined by SPEN.",3 Rank-Based Training of SPENs,[0],[0]
"This requires matching several incorrect structures for a given input, which hinders gradient descent inference from finding the exact solution by introducing many local optima.",3 Rank-Based Training of SPENs,[0],[0]
"To address this problem, we use a ranking objective similar to SampleRank",3 Rank-Based Training of SPENs,[0],[0]
"(Rohanimanesh et al., 2011) such that it preserves the optimum points of the score function.
",3 Rank-Based Training of SPENs,[0],[0]
"In general, if SPEN ranks every pair of output structures identical to the score function, the optimum points of the score function match those of SPEN.",3 Rank-Based Training of SPENs,[0],[0]
"However, forcing the ranking constraint for every pair of output structures is not tractable, so
we need to approximate it by sampling some candidate pairs.",3 Rank-Based Training of SPENs,[0],[0]
"Given a score function V (y,x), we are able to rank every two consecutive candidate structures based on their score values.",3 Rank-Based Training of SPENs,[0],[0]
Consider two candidate output structures y1 and y2 for the given input x.,3 Rank-Based Training of SPENs,[0],[0]
"We define yh and yl based on the score function as the following:
yh = argmax y∈{y1,y2} V (y,x),
yl = argmin y∈{y1,y2} V (y,x).",3 Rank-Based Training of SPENs,[0],[0]
"(1)
We expect that these two structures have the same ranking with respect to Ew(.,x), which can be described as: α(V (yh,x)",3 Rank-Based Training of SPENs,[0],[0]
"− V (yl,x))",3 Rank-Based Training of SPENs,[0],[0]
"< Ew(yh,x)−Ew(yl,x), where α is a tunable positive scalar.",3 Rank-Based Training of SPENs,[0],[0]
"Therefore, the rank-based objective minimizes the constraint violations:
min w
∑ x∈D [α(V (yh,x)− V (yl,x))−
Ew(yh,x) +",3 Rank-Based Training of SPENs,[0],[0]
"Ew(yl,x)]+ (2)
",3 Rank-Based Training of SPENs,[0],[0]
"[.]+ is max(., 0).",3 Rank-Based Training of SPENs,[0],[0]
Figure 1 shows a ranking violation for two structures y1 and y2 for a given x. The arrows indicate the direction of update over the energy surface.,3 Rank-Based Training of SPENs,[0],[0]
"Note that we ignore the dependence of y on w, which introduces approximation in the gradient of Eq. 2.",3 Rank-Based Training of SPENs,[0],[0]
"For the supervised setting, Belanger et al. (2017) address this problem by unrolling the inference steps as an inference network and back-propagating through the inference network.",3 Rank-Based Training of SPENs,[0],[0]
We leave exploring similar approaches for rank-based training for future work.,3 Rank-Based Training of SPENs,[0],[0]
"To compute Eq. 2, we need to find configurations yi and yj such that both are candidate solutions for argminy∈Y Ew(y,x).",3 Rank-Based Training of SPENs,[0],[0]
"If not, the number of required samples would be exponential in |Y|.",3 Rank-Based Training of SPENs,[0],[0]
"Since at test time we use gradient descent inference, a similar method is used for generating candidate structures: the trajectory of points in the inference mechanism is used as the set of possible candidates.",3 Rank-Based Training of SPENs,[0],[0]
The idea of deterministic sampling from SPEN energy surface was first introduced by David Belanger (2017).,3 Rank-Based Training of SPENs,[0],[0]
"We define the inference trajectory, T (x), as a sequence of output structures generated using projected gradient descent inference in order to find the minimum solution of Ew(.,x).
",3 Rank-Based Training of SPENs,[0],[0]
"Given a random initial structure y0, we define the inference trajectory as: T (x) =
{y1, · · · ,ym}, where yt+1 = Py∈∆L(yt − η ∂∂yEw(yt,x)).",3 Rank-Based Training of SPENs,[0],[0]
Py∈∆L projects the values of y onto the probability simplex ∆L overL values that each variable y can take.,3 Rank-Based Training of SPENs,[0],[0]
"For each input x in the training data, we find the first consecutive structures yi, yi+1 ∈ T (x) that violate the ranking constraint, then use Eq. 2 to reduce the number of violations.",3 Rank-Based Training of SPENs,[0],[0]
"Algorithm 1 describes the complete training algorithm.
",3 Rank-Based Training of SPENs,[0],[0]
"Algorithm 1 Rank-based training of SPEN D ← unlabeled mini-batch of training data V (., .)← scoring function Ew(., .)← input SPEN for each x in D do T (x)← samples using GD inference in Ew(.,x).",3 Rank-Based Training of SPENs,[0],[0]
"ξ ← ∅. for each pair (yi,yi+1) in T (x) do
Construct yh and yl using Eq.1 if α(V (yh,x)",3 Rank-Based Training of SPENs,[0],[0]
"− V (yl,x))",3 Rank-Based Training of SPENs,[0],[0]
"> Ew(yh,x)",3 Rank-Based Training of SPENs,[0],[0]
"−
Ew(yl,x) then ξ ← ξ ∪ (x,yh,yl).
end if end for Optimize Eq.2 using ξ.
end for",3 Rank-Based Training of SPENs,[0],[0]
"To show the success of rank-based learning with indirect supervision, we conduct experiments on citation field extraction as an instance of structured prediction problems.",4 Citation Field Extraction,[0],[0]
"The goal of citation field extraction is to segment citation text into its constituent parts such as Author, Title, Journal, Page, and Date.",4 Citation Field Extraction,[0],[0]
"We used the Cora citation dataset (Seymore et al., 1999), which includes 100 labeled examples as the test set and another 100 labeled examples for the validation set.",4 Citation Field Extraction,[0],[0]
"Our training data consists of 300 training examples from the Cora citation data set for which we dismiss the labels,
as well as another 700 unlabeled citations acquired across the web, which adds up to 1000 unlabeled data points.",4 Citation Field Extraction,[0],[0]
Each token can be labeled with one of 13 possible tags.,4 Citation Field Extraction,[0],[0]
"We use fixed-length input data by padding all citation text to the maximum citation length in the dataset, which is 118 tokens.",4 Citation Field Extraction,[0],[0]
"We report token-level accuracy measured on non-pad tokens.
",4 Citation Field Extraction,[0],[0]
We provide the learning algorithm with a human written score function that takes the citation text and predicted tags as input.,4 Citation Field Extraction,[0],[0]
The score function then checks for violations of its rules and penalizes the predicted tags accordingly.,4 Citation Field Extraction,[0],[0]
Figure 2 shows examples of rules in the score function.,4 Citation Field Extraction,[0],[0]
"Our complete score function consists of around 50 rules.
",4 Citation Field Extraction,[0],[0]
We used two 2-layer neural networks with 1000 and 500 hidden nodes to parameterize the local and global energy functions of SPEN.,4 Citation Field Extraction,[0],[0]
"We examine different α (Eq. 2) values of 0.1, 1.0, 2.0, 5.0, and 10.0, and setting α value to 2.0 has the best performance on the validation set.",4 Citation Field Extraction,[0],[0]
"We use gradient descent inference with ten gradient descent steps and η = 0.1 for both training and test.
",4 Citation Field Extraction,[0],[0]
We include the results of generalized expectation (GE) from Mann and McCallum (2010) that use the same dataset and setting.,4 Citation Field Extraction,[0],[0]
"Our results show that R-SPEN achieves significantly better tokenlevel accuracy as compared to GE.
",4 Citation Field Extraction,[0],[0]
We also compare R-SPEN with different inference algorithms that search using the score function to find the best configuration with maximum score.,4 Citation Field Extraction,[0],[0]
The results of these are listed in Table 1.,4 Citation Field Extraction,[0.9558365823100683],['The results of the first evaluation setup are shown in Table 6.']
Greedy search first randomly initializes the output tags and then iteratively replaces each assigned tag with a tag that results in the maximum score until the end of the citation is reached.,4 Citation Field Extraction,[0],[0]
"This process is repeated until convergence, measured by no tag changing in an iteration.",4 Citation Field Extraction,[0],[0]
"To avoid the effects of random initialization, this is repeated with varied number of random restarts, as reported in Table 1, where the best configuration is used in the scores reported.",4 Citation Field Extraction,[0],[0]
"For the baseline that implements beam search, each citation is labeled by employing a beam search on the space of all tags for each token and their subsequent configurations, while keeping track of the best k configurations from one token to the next.",4 Citation Field Extraction,[0],[0]
"This search is further augmented by restarting the search from the best k found after one complete search, for a total of 10 times and 10 random restarts.
",4 Citation Field Extraction,[0],[0]
"Consulting Table 1, we can confirm that both greedy search and beam search find much better output structures in term of score values as compared to R-SPEN; however, they achieve poor accuracy because the domain knowledge function does not comprehensively provide rules regarding all possible output structures.",4 Citation Field Extraction,[0],[0]
We report the average score values of the R-SPEN predictions on test data as a function of training iterations in Figure 3.,4 Citation Field Extraction,[0],[0]
"Within 1000 iterations, R-SPEN is able to achieve a test set accuracy of 38%, outperforming all baselines, while the average score is -18.0.",4 Citation Field Extraction,[0],[0]
"R-SPEN generalizes beyond the domain knowledge function because it successfully captures the correlation among output variables through rank-based training on unlabeled data, so its predictions may have lower score values but are more accurate.
",4 Citation Field Extraction,[0],[0]
The test time inference of R-SPEN is much faster than search algorithms because SPEN provides efficient approximate inference.,4 Citation Field Extraction,[0],[0]
"Generalized Expectation (GE) (Mann and McCallum, 2010), Posterior Regularization (Ganchev et al., 2010) and Constraint Driven Learning (Chang et al., 2007) are among well-known approaches to learn from domain knowledge decomposed over a set of constraints or labeled features.",5 Related Work,[0],[0]
"However, these methods cannot learn from black box domain knowledge based score functions.",5 Related Work,[0],[0]
"Score functions of this type are abundant in
various fields, for example, when the score is the result of evaluating a non-differentiable function over output structures.
",5 Related Work,[0.9505141419781603],"['Besides, for features with multiple values, e.g. mention-based features, only a small subset of values may be informative.']"
Stewart and Ermon (2017) train a neural network using a score function that guides the training based on physics of moving objects.,5 Related Work,[0],[0]
They have defined a differentiable score function which provides the learning algorithm with the gradient of the score function.,5 Related Work,[0],[0]
"However, in our approach the score function could be any complex non-differentiable function.
",5 Related Work,[0],[0]
Peng et al. (2017) and Iyyer et al. (2017) use energy-based max-margin training for learning from an implicit source of supervision.,5 Related Work,[0],[0]
This can be viewed as a score function evaluating the predicted output structure based on some real-world domain.,5 Related Work,[0],[0]
"For example, if the output structure is the SQL query associated with a natural language question, the score function can be specified as the Jaccard similarity of the extracted cells from the table using the generated SQL query and the set of
gold answers for the natural language query as in Iyyer et al (2017).",5 Related Work,[0],[0]
We have introduced a method to train structured prediction energy networks with indirect supervision that is derived from domain knowledge.,6 Conclusion and Future Work,[0],[0]
"This domain knowledge is a scalar function that is represented in the form of certain set of rules, easily provided by humans.",6 Conclusion and Future Work,[0],[0]
"By using a rank-based training we are able to effectively generalize beyond the domain knowledge function in problem instances where we do not have access to labeled data, thus establishing a viable option for solving structured prediction problems in those regimes.
",6 Conclusion and Future Work,[0],[0]
R-SPEN only uses unlabeled data and domain knowledge for training.,6 Conclusion and Future Work,[0],[0]
We should also effectively benefit from annotated data if any is available for the task.,6 Conclusion and Future Work,[0],[0]
"This can be accomplished by augmenting the domain knowledge with rules that take into account the distance between predicted and ground truth labels.
",6 Conclusion and Future Work,[0],[0]
"In the future, we wish to explore the effectiveness of R-SPEN on various tasks using domain knowledge functions with varying degrees of complexity.",6 Conclusion and Future Work,[0],[0]
This research was funded by DARPA grant FA8750-17-C-0106.,Acknowledgments,[0],[0]
"The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of DARPA or the U.S. Government.",Acknowledgments,[0],[0]
This paper introduces rank-based training of structured prediction energy networks (SPENs).,abstractText,[0],[0]
Our method samples from output structures using gradient descent and minimizes the ranking violation of the sampled structures with respect to a scalar scoring function defined using domain knowledge.,abstractText,[0],[0]
"We have successfully trained SPEN for citation field extraction without any labeled data instances, where the only source of supervision is a simple human-written scoring function.",abstractText,[0],[0]
Such scoring functions are often easy to provide; the SPEN then furnishes an efficient structured prediction inference procedure.,abstractText,[0],[0]
Training Structured Prediction Energy Networks with Indirect Supervision,title,[0],[0]
"Inspired by human beings’ capabilities to transfer knowledge across tasks, transfer learning aims to leverage knowledge from a source domain to improve the learning performance or minimize the number of labeled examples required in a target domain.",1. Introduction,[0],[0]
It is of particular significance when tackling tasks with limited labeled examples.,1. Introduction,[0],[0]
"Transfer learning has proved its wide applicability in, for example,
1Hong Kong University of Science and Technology, Hong Kong 2Tencent AI Lab, Shenzhen, China.",1. Introduction,[0],[0]
"Correspondence to: Ying Wei <judyweiying@gmail.com>, Qiang Yang <qyang@cse.ust.hk>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
image classification (Long et al., 2015), sentiment classification (Blitzer et al., 2006), dialog systems (Mo et al., 2016), and urban computing (Wei et al., 2016).
",1. Introduction,[0],[0]
"Three key research issues in transfer learning, pointed by Pan & Yang, are when to transfer, how to transfer, and what to transfer.",1. Introduction,[0],[0]
"Once transfer learning from a source domain is considered to benefit a target domain (when to transfer), an algorithm (how to transfer) discovers the transferable knowledge across domains (what to transfer).",1. Introduction,[0],[0]
"Different algorithms are likely to discover different transferable knowledge, and thereby lead to uneven transfer learning effectiveness which is evaluated by the performance improvement over non-transfer baselines in a target domain.",1. Introduction,[0],[0]
"To achieve the optimal performance improvement for a target domain given a source domain, researchers may try tens to hundreds of transfer learning algorithms covering instance (Dai et al., 2007), parameter (Tommasi et al., 2014), and feature (Pan et al., 2011) based algorithms.",1. Introduction,[0],[0]
Such bruteforce exploration is computationally expensive and practically impossible.,1. Introduction,[0],[0]
"As a tradeoff, a sub-optimal improvement is usually obtained from a heuristically selected algorithm, which unfortunately requires considerable expertise in an ad-hoc and unsystematic manner.
",1. Introduction,[0],[0]
Exploring different algorithms is not the only way to optimize what to transfer.,1. Introduction,[0],[0]
"Previous transfer learning experiences do also help, which has been widely accepted in educational psychology (Luria, 1976; Belmont et al., 1982).",1. Introduction,[0],[0]
Human beings sharpen transfer learning skills of deciding what to transfer by conducting meta-cognitive reflection on diverse transfer learning experiences.,1. Introduction,[0],[0]
"For example, children who are good at playing chess may transfer mathematical skills, visuospatial skills, and decision making skills learned from chess to solve arithmetic problems, to solve pattern matching puzzles, and to play basketball, respectively.",1. Introduction,[0],[0]
"At a later age, it will be easier for them to decide to transfer mathematical and decision making skills learned from chess, rather than visuospatial skills, to market investment.",1. Introduction,[0],[0]
"Unfortunately, all existing transfer learning algorithms transfer from scratch and ignore previous transfer learning experiences.
",1. Introduction,[0],[0]
"Motivated by this, we propose a novel transfer learning framework called Learning to Transfer (L2T).",1. Introduction,[0],[0]
"The key idea of the L2T is to enhance the transfer learning effectiveness from a source to a target domain by leveraging previous
transfer learning experiences to optimize what and how to transfer between them.",1. Introduction,[0],[0]
"To achieve the goal, we establish the L2T in two stages.",1. Introduction,[0],[0]
"During the first stage, we encode each transfer learning experience into three components: a pair of source and target domains, the transferred knowledge between them parameterized as latent feature factors, and performance improvement.",1. Introduction,[0],[0]
We learn from all experiences a reflection function which maps a pair of domains and the transferred knowledge between them to the performance improvement.,1. Introduction,[0],[0]
"The reflection function, therefore, is believed to encrypt transfer learning skills of deciding what and how to transfer.",1. Introduction,[0],[0]
"In the second stage, what to transfer between a newly arrived pair of domains is optimized so that the value of the learned reflection function, matching to the performance improvement, is maximized.
",1. Introduction,[0],[0]
The contribution of this paper lies in that we propose a novel transfer learning framework which opens a new door to improve transfer learning effectiveness by taking advantage of previous transfer learning experiences.,1. Introduction,[0],[0]
The L2T can discover more transferable knowledge in a systematic and automatic fashion without requiring considerable expertise.,1. Introduction,[0],[0]
"We have also provided theoretic analyses to its algorithmic stability and generalization bound, and conducted comprehensive empirical studies showing the L2T’s superiority over state-of-the-art transfer learning algorithms.",1. Introduction,[0],[0]
"Transfer Learning Pan & Yang identified three key research issues in transfer learning as what, how, and when to transfer.",2. Related Work,[0],[0]
"Parameters (Yang et al., 2007a; Tommasi et al., 2014), instances (Dai et al., 2007), or latent feature factors (Pan et al., 2011) can be transferred between domains.",2. Related Work,[0],[0]
"A few works (Yang et al., 2007a; Tommasi et al., 2014) transfer parameters from source domains to regularize parameters of SVM-based models in a target domain.",2. Related Work,[0],[0]
"In (Dai et al., 2007), a basic learner in a target domain is boosted by borrowing the most useful source instances.",2. Related Work,[0],[0]
Various techniques capable of learning transferable latent feature factors between domains have been investigated extensively.,2. Related Work,[0],[0]
"These techniques include manually selected pivot features (Blitzer et al., 2006), dimension reduction (Pan et al., 2011; Baktashmotlagh et al., 2013; 2014), collective matrix factorization (Long et al., 2014), dictionary learning and sparse coding (Raina et al., 2007; Zhang et al., 2016), manifold learning (Gopalan et al., 2011; Gong et al., 2012), and deep learning (Yosinski et al., 2014; Long et al., 2015; Tzeng et al., 2015).",2. Related Work,[0],[0]
"Unlike L2T, all existing transfer learning studies transfer from scratch, i.e., only considering the pair of domains of interest but ignoring previous transfer learning experiences.",2. Related Work,[0],[0]
"Better yet, L2T can even collect all algorithms’ wisdom together, considering that any algorithm mentioned above can be applied in a transfer learning experience.
",2. Related Work,[0],[0]
"Multi-task Learning Multi-task learning (Caruana, 1997; Argyriou et al., 2007) trains multiple related tasks simultaneously and learns shared knowledge among tasks, so that all tasks reinforce each other in generalization abilities.",2. Related Work,[0],[0]
"However, multi-task learning assumes that training and testing examples follow the same distribution, as Figure 1 shows, which is different from transfer learning we focus on.
",2. Related Work,[0],[0]
Lifelong Learning,2. Related Work,[0],[0]
"Assuming a new learning task to lie in the same environment as training tasks, learning to learn (Thrun & Pratt, 1998) or meta-learning (Maurer, 2005; Finn et al., 2017; Al-Shedivat et al., 2018) transfers the knowledge shared among training tasks to the new task.",2. Related Work,[0],[0]
"(Ruvolo & Eaton, 2013; Pentina & Lampert, 2015) consider lifelong learning as online meta-learning.",2. Related Work,[0],[0]
"Though L2T and lifelong (meta) learning both aim to improve a learning system by leveraging histories, L2T differs from them in that each historical experience we consider is a transfer learning task rather than a traditional learning task as Figure 1 illustrates.",2. Related Work,[0],[0]
Thus we learn transfer learning skills instead of task-sharing knowledge.,2. Related Work,[0],[0]
We begin by first briefing the proposed L2T framework.,3. Learning to Transfer,[0],[0]
"Then we detail the two stages in L2T, i.e., learning transfer learning skills from previous transfer learning experiences and applying those skills to infer what and how to transfer for a future pair of source and target domains.",3. Learning to Transfer,[0],[0]
"A L2T agent previously conducted transfer learning several times, and kept a record of Ne transfer learning experiences.",3.1. The L2T Framework,[0],[0]
"We define each transfer learning experience as Ee = (〈Se, Te〉, ae, le) in which Se = {Xse,yse} and Te = {Xte,yte} denote a source domain and a target domain, respectively.",3.1. The L2T Framework,[0],[0]
X∗e ∈,3.1. The L2T Framework,[0],[0]
"Rn ∗ e×m represents the feature matrix if either domain has n∗e examples in a m-dimensional feature space X ∗e , where the superscript ∗ can be either s or t to denote a source or a target domain.",3.1. The L2T Framework,[0],[0]
y∗e ∈ Y∗e denotes the vector of labels with the length being n∗le.,3.1. The L2T Framework,[0],[0]
"The number of target labeled examples is much smaller than that of source labeled examples, i.e., ntle nsle.",3.1. The L2T Framework,[0],[0]
"We focus on the
learned reflection function f ( 1 ), we optimize the transferred knowledge between them, i.e., W∗Ne+1, by maximizing the value of f ( 2 ).
setting X se = X te and Yse = Yte for each pair of domains.",3.1. The L2T Framework,[0],[0]
ae ∈,3.1. The L2T Framework,[0],[0]
"A = {a1, · · · , aNa} denotes a transfer learning algorithm having been applied between Se and Te.",3.1. The L2T Framework,[0],[0]
Suppose that the transferred knowledge by the algorithm ae can be parameterized as We.,3.1. The L2T Framework,[0],[0]
"Finally, each transfer learning experience is labeled by the performance improvement ratio le = pste /p",3.1. The L2T Framework,[0],[0]
"t e, where pte is the learning performance (e.g., classification accuracy) on a test dataset in Te without transfer and pste is that on the same test dataset after transferring We from Se.",3.1. The L2T Framework,[0],[0]
"With Ne transfer learning experiences {E1, · · · , ENe} as the input, the L2T agent learns a function f such that f(Se, Te,We) approximates le as shown in the training stage of Figure 2.",3.1. The L2T Framework,[0],[0]
We call f a reflection function which encrypts meta-cognitive transfer learning skills - what and how to transfer can maximize the improvement ratio given a pair of domains.,3.1. The L2T Framework,[0],[0]
"Whenever a new pair of domains 〈SNe+1, TNe+1〉 arrives, the L2T agent can optimize the knowledge to be transferred, i.e., W∗Ne+1, by maximizing the value of f (see step 2 of the testing stage in Figure 2).",3.1. The L2T Framework,[0],[0]
Transfer learning algorithms applied can vary from experience to experience.,3.2. Parameterizing What to Transfer,[0],[0]
Uniformly parameterizing “what to transfer” for any algorithm out of the base algorithm set A is a prerequisite for learning the reflection function.,3.2. Parameterizing What to Transfer,[0],[0]
"In this work, we consider A to contain algorithms transferring single-level latent feature factors, because existing parameter-based and instance-based algorithms cannot address the transfer learning setting we focus on (i.e., X es = X et and Yes = Yet ).",3.2. Parameterizing What to Transfer,[0],[0]
"Though limited parameter-based algorithms (Yang et al., 2007a; Tommasi et al., 2014) can transfer across domains in heterogeneous label spaces, they can only handle binary classification problems.",3.2. Parameterizing What to Transfer,[0],[0]
"Deep neural network based algorithms (Yosinski et al., 2014; Long et al., 2015; Tzeng et al., 2015) transferring latent feature factors in multiple levels are left for our future research.",3.2. Parameterizing What to Transfer,[0],[0]
"As a result, we parameterize what to transfer with a latent feature factor matrix W which is elaborated in the following.
",3.2. Parameterizing What to Transfer,[0],[0]
Latent feature factor based algorithms aim to learn domaininvariant feature factors across domains.,3.2. Parameterizing What to Transfer,[0],[0]
Consider classifying dog pictures as a source domain and cat pictures as a target domain.,3.2. Parameterizing What to Transfer,[0],[0]
"The domain-invariant feature factors may include eyes, mouth, tails, etc.",3.2. Parameterizing What to Transfer,[0],[0]
"What to transfer, in this case, is the shared feature factors across domains.",3.2. Parameterizing What to Transfer,[0],[0]
"The way of defining domain-invariant feature factors dictates two groups of latent feature factor based algorithms, i.e., common latent space based and manifold ensemble based algorithms.
",3.2. Parameterizing What to Transfer,[0],[0]
"Common Latent Space Based This line of algorithms, including but not limited to TCA (Pan et al., 2011),",3.2. Parameterizing What to Transfer,[0],[0]
"LSDT (Zhang et al., 2016), and DIP (Baktashmotlagh et al., 2013), assumes that domain-invariant feature factors lie in a single shared latent space.",3.2. Parameterizing What to Transfer,[0],[0]
We denote by ϕ,3.2. Parameterizing What to Transfer,[0],[0]
the function mapping original feature representation into the latent space.,3.2. Parameterizing What to Transfer,[0],[0]
"If ϕ is linear, it can be represented as an embedding matrix W ∈ Rm×u where u is the dimensionality of the latent space.",3.2. Parameterizing What to Transfer,[0],[0]
"Therefore, we can parameterize what to transfer we focus on with W which describes u latent feature factors.",3.2. Parameterizing What to Transfer,[0],[0]
"Otherwise, if ϕ is nonlinear, what to transfer can still be parameterized with W. Though a nonlinear ϕ is not explicitly specified in most cases such as LSDT using sparse coding, target examples represented in the latent space Zte=ϕ(X t e)∈Rn t e×u are always available.",3.2. Parameterizing What to Transfer,[0],[0]
"Consequently, we obtain the similarity metric matrix (Cao et al., 2013) in the latent space, i.e., G=(Xte) †Zte(Z t e) T",3.2. Parameterizing What to Transfer,[0],[0]
"[(Xte) T ]†∈Rm×m according to XteG(X t e) T =Zte(Z t e) T , where (Xte) † is the pseudo-inverse of Xte.",3.2. Parameterizing What to Transfer,[0],[0]
"LDL decomposition on G = LDL T brings the latent feature factor matrix W = LD1/2.
",3.2. Parameterizing What to Transfer,[0],[0]
"Manifold Ensemble Based Initiated by Gopalan et al., manifold ensemble based algorithms consider that a source and a target domain share multiple subspaces (of the same dimension) as points on the Grassmann manifold between them.",3.2. Parameterizing What to Transfer,[0],[0]
"The representation of target examples on u domain-invariant latent factors turns to Zt(nu)e =[ϕ1(Xte), · · ·, ϕnu(Xte)] ∈",3.2. Parameterizing What to Transfer,[0],[0]
"Rn t e×nuu, if nu subspaces on the manifold are sampled.",3.2. Parameterizing What to Transfer,[0],[0]
"When all continuous subspaces on the manifold are sampled, i.e., nu →∞, Gong et al. proved
that Zt(∞)e (Z t(∞) e )T =XteG(X t e)
T where G is the similarity metric matrix.",3.2. Parameterizing What to Transfer,[0],[0]
"For computational details of G, please refer to (Gong et al., 2012).",3.2. Parameterizing What to Transfer,[0],[0]
"W=LD1/2 with L and D obtained from performing LDL decomposition on G=LDLT , therefore, is also qualified to represent latent feature factors distributed in a series of subspaces on a manifold.",3.2. Parameterizing What to Transfer,[0],[0]
"The goal here is to learn a reflection function f such that f(Se, Te,We) can approximate le for all experiences {E1, · · · , ENe}.",3.3. Learning from Experiences,[0],[0]
"The improvement ratio le is closely related to two aspects: 1) the difference between a source and a target domain in the shared latent space, and 2) the discriminative ability of a target domain in the latent space.",3.3. Learning from Experiences,[0],[0]
"The smaller difference guarantees more overlap between domains in the latent space, which signifies more transferable latent feature factors and higher improvement ratios as a result.",3.3. Learning from Experiences,[0],[0]
The discriminative ability of a target domain in the latent space is also vital to improve performances.,3.3. Learning from Experiences,[0],[0]
"Therefore, we build f to take both aspects into consideration.
",3.3. Learning from Experiences,[0],[0]
"The Difference between a Source and a Target Domain We follow (Pan et al., 2011) and adopt the maximum mean discrepancy (MMD) (Gretton et al., 2012b) to measure the difference between domains.",3.3. Learning from Experiences,[0],[0]
"By mapping two domains into the reproducing kernel Hilbert space (RKHS), MMD empirically evaluates the distance between the mean of source examples and that of target examples:
d̂2e(X s eWe,X t eWe)
= ∥∥∥∥",3.3. Learning from Experiences,[0],[0]
1nse nse∑ i=1 φ(xseiWe)−,3.3. Learning from Experiences,[0],[0]
1 nte nte∑ j=1 φ(xtejWe) ∥∥∥∥,3.3. Learning from Experiences,[0],[0]
2,3.3. Learning from Experiences,[0],[0]
"H
= 1
(nse)2 nse∑ i,i′=1 K(xseiWe,xsei′We)
",3.3. Learning from Experiences,[0],[0]
"+ 1
(nte)2 nte∑ j,j′=1 K(xtejWe,xtej′We)
",3.3. Learning from Experiences,[0],[0]
"− 2 nsente
nse,n t e∑
i,j=1
K(xseiWe,xtejWe), (1)
where xtej is the j-th example in X t e, and φ maps from the u-dimensional latent space to the RKHS H. K(·, ·) = 〈φ(·), φ(·)〉 is the kernel function.",3.3. Learning from Experiences,[0],[0]
Different kernels K lead to different MMD distances and thereby different values of f .,3.3. Learning from Experiences,[0],[0]
Thus learning the reflection function f is equivalent to optimizing K so that the MMD distance can well characterize the improvement ratio le for all pairs of domains.,3.3. Learning from Experiences,[0],[0]
"Inspired by multi-kernel MMD (Gretton et al., 2012b), we parameterize K as a linear combination of Nk PSD kernels, i.e., K=∑Nkk=1 βkKk (βk≥0, ∀k), and learn the coefficients β=[β1,· · ·, βNk ] instead.",3.3. Learning from Experiences,[0],[0]
"Using β, the MMD can be rewritten as d̂2e(XseWe,XteWe)= ∑Nk k=1 βkd̂ 2 e(k)(X s eWe,X t eWe)=
βT",3.3. Learning from Experiences,[0],[0]
"d̂e, where d̂e=[d̂2e(1),· · ·, d̂2e(Nk)] with d̂ 2 e(k) computed by the k-th kernel Kk.",3.3. Learning from Experiences,[0],[0]
"In this paper, we consider RBF kernels Kk(a,b)=exp(−‖a−b‖2/δk) by varying the bandwidth δk.
",3.3. Learning from Experiences,[0],[0]
"Unfortunately, the MMD alone is insufficient to measure the difference between domains.",3.3. Learning from Experiences,[0],[0]
The distance variance among all pairs of instances across domains is also required to fully characterize the difference.,3.3. Learning from Experiences,[0],[0]
A pair of domains with small MMD but extremely high variance still have little overlap.,3.3. Learning from Experiences,[0],[0]
"Equation (1) is actually the empirical estimation of d2e(XseWe,XteWe) =",3.3. Learning from Experiences,[0],[0]
"Exsexs′e xtext′e h(x s e,x s′ e ,x t e,x t′ e )",3.3. Learning from Experiences,[0],[0]
"(Gretton et al., 2012b) where h(xse,x s′ e ,x t e,x t′ e ) = K(xseWe,xs′e We)+K(xteWe,xt′e",3.3. Learning from Experiences,[0],[0]
"We)− K(xseWe, xt′e",3.3. Learning from Experiences,[0],[0]
We),3.3. Learning from Experiences,[0],[0]
"− K(xs′e We,xteWe).",3.3. Learning from Experiences,[0],[0]
"Consequently, the distance variance, σ2e , equals σ2e(X s eWe,X t eWe) =Exsexs′e xtext′e",3.3. Learning from Experiences,[0],[0]
"[(h(x s e,x s′ e ,x t e,x t′ e )
−Exsexs′e xtext′e h(x s e,x s′ e ,x t e,x t′ e )) 2].
",3.3. Learning from Experiences,[0],[0]
"To be consistent with the MMD characterized with Nk PSD kernels, we rewrite σ2e = βTQeβ where Qe = cov(h) =[
σe(1,1) ··· σe(1,Nk)··· ··· ··· σe(Nk,1) ···σe(Nk,Nk)
] .",3.3. Learning from Experiences,[0],[0]
"Each element σe(k1,k2) = cov(hk1 ,
hk2) =",3.3. Learning from Experiences,[0],[0]
E,3.3. Learning from Experiences,[0],[0]
[(hk1−Ehk1)(hk2−Ehk2)].,3.3. Learning from Experiences,[0],[0]
Note that Ehk1 is shorthand for Exsexs′e xtext′e,3.3. Learning from Experiences,[0],[0]
"hk1(x s e,x s′ e ,x t e,x t′ e ) where hk1 is calculated using the k1-th kernel.",3.3. Learning from Experiences,[0],[0]
"We detail the empirical estimate Q̂e of Qe in the supplementary due to page limit.
",3.3. Learning from Experiences,[0],[0]
"The Discriminative Ability of a Target Domain In view of limited labeled examples in a target domain, we resort to unlabeled examples to evaluate the discriminative ability.",3.3. Learning from Experiences,[0],[0]
The principles of the unlabeled discriminant criterion are two-fold: 1) similar examples should still be neighbours after being embedded into the latent space; and 2) dissimilar examples should be far away.,3.3. Learning from Experiences,[0],[0]
"We adopt the unlabeled discriminant criterion proposed in (Yang et al., 2007b),
τe = tr(WTe S N e We)/tr(W T e S L e We),
where SLe = ∑nte
j,j′=1 Hjj′ (nte) 2",3.3. Learning from Experiences,[0],[0]
(x t ej,3.3. Learning from Experiences,[0],[0]
− xtej′)(xtej,3.3. Learning from Experiences,[0],[0]
"− xtej′)T
is the local scatter covariance matrix with the neighbour information Hjj′ defined as Hjj′ ={ K(xtej ,xtej′), if xtej ∈ Nr(xtej′) and xtej′ ∈ Nr(xtej) 0, otherwise .
",3.3. Learning from Experiences,[0],[0]
"If xtej and x t ej′ are mutual r-nearest neighbours to each other, Hjj′ equals the kernel value K(xtej ,xtej′).",3.3. Learning from Experiences,[0],[0]
"By maximizing the unlabeled discriminant criterion τe, the local scatter covariance matrix guarantees the first principle, while
SNe = ∑nte",3.3. Learning from Experiences,[0],[0]
"j,j′=1 K(xtej ,xtej′ )−Hjj′
(nte) 2 (x
t ej",3.3. Learning from Experiences,[0],[0]
− xtej′)(xtej,3.3. Learning from Experiences,[0],[0]
"− xtej′)T ,
the non-local scatter covariance matrix, enforces the second principle.",3.3. Learning from Experiences,[0],[0]
τe also depends on kernels which in this case indicate different neighbour information and different degrees of similarity between neighboured examples.,3.3. Learning from Experiences,[0],[0]
"With τe(k) obtained from the k-th kernel Kk, the unlabeled discriminant criterion τe can be written as τe = ∑Nk k=1 βkτe(k) = β
T τ e where τ e =",3.3. Learning from Experiences,[0],[0]
"[τe(1), · · · , τe(Nk)].
",3.3. Learning from Experiences,[0],[0]
"The Optimization Problem Combining the two aspects abovementioned to model the reflection function f , we finally formulate the optimization problem as follows,
β∗, λ∗, μ∗, b∗ =
arg min β,λ,μ,",3.3. Learning from Experiences,[0],[0]
b Ne∑ e=1,3.3. Learning from Experiences,[0],[0]
Lh ( βT d̂e,3.3. Learning from Experiences,[0],[0]
+ λβ T Q̂eβ,3.3. Learning from Experiences,[0],[0]
+ μ βT,3.3. Learning from Experiences,[0],[0]
τ,3.3. Learning from Experiences,[0],[0]
"e + b, 1 le )
+ γ1R(β, λ, μ, b),
s.t.",3.3. Learning from Experiences,[0],[0]
"βk ≥ 0, ∀k ∈ {1, · · · , Nk}, λ ≥ 0, μ ≥ 0, (2) where 1/f = βT",3.3. Learning from Experiences,[0],[0]
d̂e +,3.3. Learning from Experiences,[0],[0]
"λβT Q̂eβ + μβT τe + b and Lh(·) is the Huber regression loss (Huber et al., 1964) constraining the value of 1/f to be as close to 1/le as possible.",3.3. Learning from Experiences,[0],[0]
γ1 controls the complexity of the parameters by l2-regularization.,3.3. Learning from Experiences,[0],[0]
"Minimizing the difference between domains, including the MMD distance βT",3.3. Learning from Experiences,[0],[0]
d̂e and the distance variance βT,3.3. Learning from Experiences,[0],[0]
"Q̂eβ, and meanwhile maximizing the discriminant criterion βT τ",3.3. Learning from Experiences,[0],[0]
"e in the target domain will contribute a large performance improvement ratio le (i.e., a small 1/le).",3.3. Learning from Experiences,[0],[0]
"λ and μ balance the importance of the three terms in f , and b is the bias term.",3.3. Learning from Experiences,[0],[0]
"Once the L2T agent has learned the reflection function f(S, T ,W;β∗, λ∗, μ∗, b∗), it takes advantage of the function to optimize what to transfer, i.e., the latent feature factor matrix W, for a newly arrived source domain SNe+1 and a target domain TNe+1.",3.4. Inferring What to Transfer,[0],[0]
The optimal latent feature factor matrix W∗Ne+1 should maximize the value of f .,3.4. Inferring What to Transfer,[0],[0]
"To this end, we optimize the following objective with regard to W, W
∗ Ne+1",3.4. Inferring What to Transfer,[0],[0]
"=argmax W f(SNe+1, TNe+1,W;β ∗ , λ ∗ , μ ∗ , b ∗ )",3.4. Inferring What to Transfer,[0],[0]
"− γ2‖W‖2F
=argmin W
(β ∗ )",3.4. Inferring What to Transfer,[0],[0]
T d̂W + λ ∗ (β ∗ ),3.4. Inferring What to Transfer,[0],[0]
"T Q̂Wβ ∗ + μ ∗ 1 (β∗)T τW + γ2‖W‖2F , (3)
where ‖ · ‖F denotes the matrix Frobenius norm and γ2 controls the complexity of W. The first and second terms in problem (3) can be calculated as
(β ∗ )",3.4. Inferring What to Transfer,[0],[0]
T d̂W = Nk∑ k=1 β,3.4. Inferring What to Transfer,[0],[0]
∗,3.4. Inferring What to Transfer,[0],[0]
"k
[ 1
a2 a∑ i,i′=1 Kk(viW,vi′W)+
1 b2 b∑ j,j′=1 Kk(wjW,wj′W)",3.4. Inferring What to Transfer,[0],[0]
"− 2 ab a,b∑ i,j=1 Kk(viW,wjW) ] ,
(β ∗ )",3.4. Inferring What to Transfer,[0],[0]
"T Q̂Wβ ∗ =
1
n2 − 1 n∑ i,i′=1 Nk∑ k=1 { β ∗",3.4. Inferring What to Transfer,[0],[0]
k,3.4. Inferring What to Transfer,[0],[0]
"[ Kk(viW,vi′W)+
Kk(wiW,wi′W)",3.4. Inferring What to Transfer,[0],[0]
"− 2Kk(viW,wi′W) − 1
n2 n∑ i,i′=1 ( Kk(viW,vi′W)
+ Kk(wiW,wi′W)",3.4. Inferring What to Transfer,[0],[0]
"− 2Kk(viW,wi′W) )",3.4. Inferring What to Transfer,[0],[0]
"]}2 ,
where the shorthand vi = xs(Ne+1)i, vi′ = x s (Ne+1)i′ , wj = xt(Ne+1)j , wj′ =x t (Ne+1)j′ , a=n s Ne+1, and b=n t Ne+1 are used due to space limit.",3.4. Inferring What to Transfer,[0],[0]
"Note that n=min(nsNe+1, n t Ne+1
).",3.4. Inferring What to Transfer,[0],[0]
"The third term in problem (3) can be computed as (β∗)T τW =∑Nk
k=1 β ∗ k tr(WTSNk W) tr(WTSLkW) .",3.4. Inferring What to Transfer,[0],[0]
"We optimize the non-convex prob-
lem (3) w.r.t W by employing a conjugate gradient method in which the gradient is listed in the supplementary material.",3.4. Inferring What to Transfer,[0],[0]
"In this section, we would theoretically investigate how previous transfer learning experiences influence a transfer learning task of interest.",4. Stability and Generalization Bounds,[0],[0]
"We also provide and prove the algorithmic stability and generalization bound for latent feature factor based transfer learning algorithms without experiences considered in the supplementary.
",4. Stability and Generalization Bounds,[0],[0]
"Consider S = {〈S1, T1〉,· · ·, 〈SNe , TNe〉} to be Ne transfer learning experiences or the so-called meta-samples (Maurer, 2005).",4. Stability and Generalization Bounds,[0],[0]
"Let L(S) be our algorithm that learns meta-cognitive knowledge from Ne transfer learning experiences in S and applies the knowledge to the (Ne+1)-th transfer learning task 〈SNe+1, TNe+1〉.",4. Stability and Generalization Bounds,[0],[0]
"To analyse the stability and give the generalization bound, we make an assumption on the distribution from which all Ne transfer learning experiences as meta-samples are sampled.",4. Stability and Generalization Bounds,[0],[0]
"For every environment E we have, all Ne pairs of source and target domains in S are drawn according to an algebraic β-mixing stationary distribution (DE)Ne , which is not i.i.d.. Intuitively, the algebraical β-mixing stationary distribution (see Definition 2 in (Mohri & Rostamizadeh, 2010)) with the β-mixing coefficient β(m)≤β0/mr models the dependence between future samples and past samples by a distance of at least m. The independent block technique (Bernstein, 1927) has been widely adopted to deal with non-i.i.d.",4. Stability and Generalization Bounds,[0],[0]
learning problems.,4. Stability and Generalization Bounds,[0],[0]
"Under this assumption, L(S) is uniformly stable.
",4. Stability and Generalization Bounds,[0],[0]
Theorem 1.,4. Stability and Generalization Bounds,[0],[0]
Suppose that for any xte and for any yte we have ‖xte‖2≤rx and |yte|≤B.,4. Stability and Generalization Bounds,[0],[0]
"Meanwhile, for any e-th transfer learning experience, we assume that the latent feature factor matrix ‖We‖≤ rW .",4. Stability and Generalization Bounds,[0],[0]
"To meet the assumption above, we reasonably simplify L(S) so that the latent feature factor matrix for the (Ne+1)-th transfer learning task is a linear combination of all Ne historical latent factor feature matrices plus a noisy latent feature matrix W satisfying ‖W ‖≤r , i.e., WNe+1= ∑Ne e=1 ceWe+W with each coefficient 0≤ce≤1.",4. Stability and Generalization Bounds,[0],[0]
Our algorithm L(S) is uniformly stable.,4. Stability and Generalization Bounds,[0],[0]
"For any 〈S, T 〉 as the coming transfer learning task, the following inequality holds:∣∣lemp(L(S), (S, T ))",4. Stability and Generalization Bounds,[0],[0]
"− lemp(L(Se0), (S, T ))∣∣
≤",4. Stability and Generalization Bounds,[0],[0]
4(4Ne − 3 + r /rW ),4. Stability and Generalization Bounds,[0],[0]
"B 2rx
λN2e ∼",4. Stability and Generalization Bounds,[0],[0]
O,4. Stability and Generalization Bounds,[0],[0]
"( B2rx λNe ) , (4)
where S = {〈S1, T1〉, · · · , 〈Se0−1, Te0−1〉, 〈Se0 , Te0〉, 〈Se0+1, Te0+1〉, · · · , 〈SNe , TNe〉} denotes the full set of meta-samples, and Se0 = {〈S1, T1〉, · · · , 〈Se0−1, Te0−1〉, 〈Se′0 , Te′0〉, 〈Se0+1, Te0+1〉, · · · , 〈SNe , TNe〉} represents the meta-samples with the e0-th meta-example replaced as 〈Se′0 , Te′0〉.",4. Stability and Generalization Bounds,[0],[0]
"By generalizing S to be meta-samples S and hS to be L2T L(S), we apply Corollary 21 in (Mohri & Rostamizadeh,
2010) to give the generalization bound of our algorithm L(S) in Theorem 2.
Theorem 2.",4. Stability and Generalization Bounds,[0],[0]
Let δ′ = δ−(Ne) 1 2(r+1),4. Stability and Generalization Bounds,[0],[0]
− 14 (r > 1 is required).,4. Stability and Generalization Bounds,[0],[0]
"Then for any sample S of size Ne drawn according to an algebraic β-mixing stationary distribution, and δ ≥ 0 such that δ′ ≥ 0, the following generalization bound holds with probability at least 1− δ: ∣∣R(L(S))−RNe(L(S))∣∣ < O ( (Ne) 1 2(r+1)",4. Stability and Generalization Bounds,[0],[0]
"− 1 4 √ log( 1
δ′ )
) ,
where R(L(S)) and RNe(L(S)) denote the expected risk and the empirical risk of L2T over meta-samples, respectively.",4. Stability and Generalization Bounds,[0],[0]
"A larger mixing parameter r, indicating more independence, would lead to a tighter bound.
",4. Stability and Generalization Bounds,[0],[0]
"Theorem 2 tells that as the number of transfer learning experiences, i.e., Ne, increases, L2T tends to produce a tighter generalization bound.",4. Stability and Generalization Bounds,[0],[0]
This fact lays the foundation for further conducting L2T in an online manner which can gradually assimilate transfer learning experiences and continuously improve.,4. Stability and Generalization Bounds,[0],[0]
The detailed proofs for Theorem 1 and 2 can be found in the supplementary.,4. Stability and Generalization Bounds,[0],[0]
"Datasets We evaluate the L2T framework on two image datasets, Caltech-256 (Griffin et al., 2007) and Sketches (Eitz et al., 2012).",5. Experiments,[0],[0]
"Caltech-256, collected from Google Images, contains a total of 30,607 images in 256 categories.",5. Experiments,[0],[0]
"The Sketches dataset, however, consists of 20,000 unique sketches by human beings that are evenly distributed over 250 different categories.",5. Experiments,[0],[0]
"We construct each pair of source and target domains by randomly sampling three categories from Caltech-256 as the source domain and randomly sampling three categories from Sketches as the target domain, which we give an example in the supplementary material.",5. Experiments,[0],[0]
"Consequently, there are 20, 000/250× 3 = 720 examples in a target domain of each pair.",5. Experiments,[0],[0]
"In total, we generate 1,000 training pairs for preparing transfer learning experiences, 500 validation pairs to determine hyperparameters of the reflection function, and 500 testing pairs to evaluate the reflection function.",5. Experiments,[0],[0]
"We characterize each image from both datasets with 4,096-dimensional features extracted by a convolutional neural network pre-trained by ImageNet.
",5. Experiments,[0],[0]
"In this paper we generate transfer learning experiences by ourselves, because we are the first to consider transfer learning experiences and there exists no off-the-shelf datasets.",5. Experiments,[0],[0]
"In real-world applications, either the number of labeled examples in a target domain or the transfer learning algorithm could vary from experience to experience.",5. Experiments,[0],[0]
"In order to mimic the real environment, we prepare each transfer learning experience by randomly selecting a transfer learning algorithm from a base set A and randomly setting the number of labeled target examples in the range of [3, 120].",5. Experiments,[0],[0]
"The randomly
generated training experiences, lying in the same environment (generated by one dataset), are non i.i.d., which fit the algebraical β-mixing assumption theoretically in Section 4.
",5. Experiments,[0],[0]
"Baselines and Evaluation Metrics We compare L2T with the following nine baseline algorithms in three classes:
• Non-transfer: Original builds a model using labeled data in a target domain only.",5. Experiments,[0],[0]
"• Common latent space based transfer learning algorithms: TCA (Pan et al., 2011), ITL (Shi & Sha, 2012), CMF (Long et al., 2014), LSDT (Zhang et al., 2016), STL (Raina et al., 2007), DIP (Baktashmotlagh et al., 2013) and SIE (Baktashmotlagh et al., 2014).",5. Experiments,[0],[0]
"• Manifold ensemble based algorithms: GFK (Gong et al., 2012).
",5. Experiments,[0],[0]
The eight feature-based transfer learning algorithms also constitute the base set A.,5. Experiments,[0],[0]
"Based on feature representations obtained by different algorithms, we use the nearestneighbor classifier to perform three-class classification for the target domain.
",5. Experiments,[0],[0]
One evaluation metric is classification accuracy on testing examples of a target domain.,5. Experiments,[0],[0]
"However, accuracies are incomparable for different target domains at different levels of difficulty.",5. Experiments,[0],[0]
"The other evaluation metric we adopt is the performance improvement ratio defined in Section 3.1, so as to compare the L2T over different pairs of domains.
",5. Experiments,[0],[0]
"Performance Comparison In this experiment, we learn a reflection function from 1,000 transfer learning experiences, and evaluate the reflection function on 500 testing pairs of source and target domains by comparing the average performance improvement ratio to the baselines.",5. Experiments,[0],[0]
"In building the reflection function, we use 33 RBF kernels with the bandwidth δk in the range of [2−8η : 20.5η : 28η] where η = 1
nsen t eNe
∑Ne e=1 ∑nse,nte i,j=1 ‖xseiW",5. Experiments,[0],[0]
"− xtejW‖22 follows
the median trick (Gretton et al., 2012a).",5. Experiments,[0],[0]
"As Figure 4 shows, on average the proposed L2T framework outperforms the baselines up to 10% when varying the number of labeled samples in the target domain.",5. Experiments,[0],[0]
"As the number of labeled target examples increases from 3 to 120, the performance improvement ratio becomes smaller because the accuracy of Original without transfer tends to increase.",5. Experiments,[0],[0]
"The baseline
algorithms behave differently.",5. Experiments,[0],[0]
"The transferable knowledge learned by LSDT helps a target domain a lot when training examples are scarce, while GFK performs poorly until training examples become more.",5. Experiments,[0],[0]
STL is almost the worst baseline because it learns a dictionary from the source domain only but ignores the target domain.,5. Experiments,[0],[0]
It runs at a high risk of failure especially when two domains are distant.,5. Experiments,[0],[0]
"DIP and SIE, which minimize the MMD and Hellinger distance between domains subject to manifold constraints, are competent.",5. Experiments,[0],[0]
"Note that we have run the paired t-test between L2T and each baseline with all the p-values in the order of 10−12, concluding that the L2T is significantly superior.
",5. Experiments,[0],[0]
We also randomly select six of the 500 testing pairs and compare classification accuracies by different algorithms for each pair in Figure 3.,5. Experiments,[0],[0]
The performance of all baselines varies from pair to pair.,5. Experiments,[0],[0]
"Among all the baseline methods, TCA performs the best when transferring between domains in Figure 3a and LSDT is the most superior in Figure 3c.",5. Experiments,[0],[0]
"However, L2T consistently outperforms the baselines on all the settings.",5. Experiments,[0],[0]
"For some pairs, e.g., Figures 3a, 3c and 3f, the three classes in a target domain are comparably easy to tell apart, hence Original without transfer can achieve even better results than some transfer learning algorithms.",5. Experiments,[0],[0]
"In this case, L2T still improves by discovering the best transferable knowledge from the source domain, especially when the number of labeled examples is small (see Figure 3c and 3f).",5. Experiments,[0],[0]
"If two domains are very related, e.g., the source with “galaxy” and “saturn” and the target with “sun” in Figure 3a, L2T even finds out more transferable knowledge and contributes more significant improvement.
",5. Experiments,[0],[0]
"Varying the Experiences We further investigate how transfer learning experiences used to learn the reflection function influence the performance of L2T. In this experiment, we evaluate on 50 randomly sampled pairs out of the 500 testing pairs in order to efficiently investigate a wide range of cases in the following.",5. Experiments,[0],[0]
"The sampled set is unbiased and sufficient to characterize such influence, evidenced by the asymptotic consistency between the average performance improvement ratio on the 500 pairs in Figure 4 and that on the 50 pairs in the last line of Table 1.",5. Experiments,[0],[0]
"First, we fix the number of transfer learning experiences to be 1,000 and vary the set of base transfer learning algorithms.",5. Experiments,[0],[0]
The results are shown in Table 1.,5. Experiments,[0],[0]
"Even with experiences generated by single base algorithm, e.g., ITL or DIP, the L2T can still learn a reflection function that significantly better (p-value < 0.05) decides what to transfer than using ITL or DIP directly.",5. Experiments,[0],[0]
"With more base algorithms involved, the transfer learning experiences are more diverse to cover more situations of source-target pairs and the knowledge transferred between them.",5. Experiments,[0],[0]
"As a result, the L2T learns a better reflection function and thereby achieves higher performance improvement ratios, which coincides with Theorem 2 where a larger r indicating more independence between experiences gives a tighter bound.",5. Experiments,[0],[0]
"Second, we fix the set of base algorithms to include all the eight baselines and vary the number of transfer learning experiences used for training.",5. Experiments,[0],[0]
"As shown in Figure 5, the average performance improvement ratio achieved by L2T tends to increase as the number of labeled examples in the target domain decreases, given that Original without transfer performs extremely poor with scarce labeled examples.
",5. Experiments,[0],[0]
Figure 6.,5. Experiments,[0],[0]
"Varying the components constituted in the f .
Figure 7.",5. Experiments,[0],[0]
"Varying the number of kernels considered in the f .
",5. Experiments,[0],[0]
"More importantly, it increases as the number of experiences increases, which coincides with Theorem 2.
",5. Experiments,[0],[0]
"Varying the Reflection Function We also study the influence of different configurations of the reflection function on the performance of L2T. First, we vary the components to be considered in building the reflection function f as shown in Figure 6.",5. Experiments,[0],[0]
"Considering single type, either MMD, variance, or the discriminant criterion, brings inferior performance and even negative transfer.",5. Experiments,[0],[0]
"L2T taking all the three factors into consideration outperforms the others, demonstrating that the three components are all necessary and mutually reinforcing.",5. Experiments,[0],[0]
"With all the three components included, we plot values of the learned β∗ in the supplementary material.",5. Experiments,[0],[0]
"Second, we change the kernels used.",5. Experiments,[0],[0]
"In Figure 7, we present results by either narrowing down or extending the range [2−8η : 20.5η : 28η].",5. Experiments,[0],[0]
"Obviously, more kernels (e.g., [2−12η : 20.5η : 212η]), capable of encrypting better trans-
fer learning skills in the reflection function, achieve larger performance improvement ratios.",5. Experiments,[0],[0]
"In this paper, we propose a novel L2T framework for transfer learning which automatically optimizes what and how to transfer between a source and a target domain by leveraging previous transfer learning experiences.",6. Conclusion,[0],[0]
"In particular, L2T learns a reflection function mapping a pair of domains and the knowledge transferred between them to the performance improvement ratio.",6. Conclusion,[0],[0]
"When a new pair of domains arrives, L2T optimizes what and how to transfer by maximizing the value of the learned reflection function.",6. Conclusion,[0],[0]
We believe that L2T opens a new door to improve transfer learning by leveraging transfer learning experiences.,6. Conclusion,[0],[0]
"Many research issues, e.g., incorporating hierarchical latent feature factors as what to transfer and designing online L2T, can be further examined.",6. Conclusion,[0],[0]
We thank the reviewers for their valuable comments to improve this paper.,Acknowledgements,[0],[0]
"The research has been supported by National Grant Fundamental Research (973 Program) of China under Project 2014CB340304, Hong Kong CERG projects 16211214/16209715/16244616, Hong Kong ITF ITS/391/15FX and NSFC 61673202.",Acknowledgements,[0],[0]
"In transfer learning, what and how to transfer are two primary issues to be addressed, as different transfer learning algorithms applied between a source and a target domain result in different knowledge transferred and thereby the performance improvement in the target domain.",abstractText,[0],[0]
Determining the optimal one that maximizes the performance improvement requires either exhaustive exploration or considerable expertise.,abstractText,[0],[0]
"Meanwhile, it is widely accepted in educational psychology that human beings improve transfer learning skills of deciding what to transfer through meta-cognitive reflection on inductive transfer learning practices.",abstractText,[0],[0]
"Motivated by this, we propose a novel transfer learning framework known as Learning to Transfer (L2T) to automatically determine what and how to transfer are the best by leveraging previous transfer learning experiences.",abstractText,[0],[0]
We establish the L2T framework in two stages: 1) we learn a reflection function encrypting transfer learning skills from experiences; and 2) we infer what and how to transfer are the best for a future pair of domains by optimizing the reflection function.,abstractText,[0],[0]
"We also theoretically analyse the algorithmic stability and generalization bound of L2T, and empirically demonstrate its superiority over several state-ofthe-art transfer learning algorithms.",abstractText,[0],[0]
Transfer Learning via Learning to Transfer,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 946–956 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
946",text,[0],[0]
"Target-oriented (also mentioned as “target-level” or “aspect-level” in some works) sentiment classification aims to determine sentiment polarities over “opinion targets” that explicitly appear in the sentences (Liu, 2012).",1 Introduction,[0],[0]
"For example, in the sentence “I am pleased with the fast log on, and the long battery life”, the user mentions two targets
∗The work was done when Xin Li was an intern at Tencent AI Lab.",1 Introduction,[0],[0]
"This project is substantially supported by a grant from the Research Grant Council of the Hong Kong Special Administrative Region, China (Project Code: 14203414).
",1 Introduction,[0],[0]
"1Our code is open-source and available at https:// github.com/lixin4ever/TNet
“log on” and “better life”, and expresses positive sentiments over them.",1 Introduction,[0],[0]
"The task is usually formulated as predicting a sentiment category for a (target, sentence) pair.
",1 Introduction,[0],[0]
"Recurrent Neural Networks (RNNs) with attention mechanism, firstly proposed in machine translation (Bahdanau et al., 2014), is the most commonly-used technique for this task.",1 Introduction,[0],[0]
"For example, Wang et al. (2016); Tang et al. (2016b); Yang et al. (2017); Liu and Zhang (2017); Ma et al. (2017) and Chen et al. (2017) employ attention to measure the semantic relatedness between each context word and the target, and then use the induced attention scores to aggregate contextual features for prediction.",1 Introduction,[0],[0]
"In these works, the attention weight based combination of word-level features for classification may introduce noise and downgrade the prediction accuracy.",1 Introduction,[0],[0]
"For example, in “This dish is my favorite and I always get it and never get tired of it.”, these approaches tend to involve irrelevant words such as “never” and “tired” when they highlight the opinion modifier “favorite”.",1 Introduction,[0],[0]
"To some extent, this drawback is rooted in the attention mechanism, as also observed in machine translation (Luong et al., 2015) and image captioning (Xu et al., 2015).
",1 Introduction,[0],[0]
Another observation is that the sentiment of a target is usually determined by key phrases such as “is my favorite”.,1 Introduction,[0],[0]
"By this token, Convolutional Neural Networks (CNNs)—whose capability for extracting the informative n-gram features (also called “active local features”) as sentence representations has been verified in (Kim, 2014; Johnson and Zhang, 2015)— should be a suitable model for this classification problem.",1 Introduction,[0],[0]
"However, CNN likely fails in cases where a sentence expresses different sentiments over multiple targets, such as “great food but the service was dreadful!”.",1 Introduction,[0],[0]
"One reason is that CNN cannot fully explore the target information as done by RNN-based meth-
ods (Tang et al.,",1 Introduction,[0],[0]
"2016a).2 Moreover, it is hard for vanilla CNN to differentiate opinion words of multiple targets.",1 Introduction,[0],[0]
"Precisely, multiple active local features holding different sentiments (e.g., “great food” and “service was dreadful”) may be captured for a single target, thus it will hinder the prediction.
",1 Introduction,[0],[0]
"We propose a new architecture, named TargetSpecific Transformation Networks (TNet), to solve the above issues in the task of target sentiment classification.",1 Introduction,[0],[0]
TNet firstly encodes the context information into word embeddings and generates the contextualized word representations with LSTMs.,1 Introduction,[0],[0]
"To integrate the target information into the word representations, TNet introduces a novel Target-Specific Transformation (TST) component for generating the target-specific word representations.",1 Introduction,[0],[0]
"Contrary to the previous attention-based approaches which apply the same target representation to determine the attention scores of individual context words, TST firstly generates different representations of the target conditioned on individual context words, then it consolidates each context word with its tailor-made target representation to obtain the transformed word representation.",1 Introduction,[0],[0]
"Considering the context word “long” and the target “battery life” in the above example, TST firstly measures the associations between “long” and individual target words.",1 Introduction,[0],[0]
Then it uses the association scores to generate the target representation conditioned on “long”.,1 Introduction,[0],[0]
"After that, TST transforms the representation of “long” into its target-specific version with the new target representation.",1 Introduction,[0],[0]
"Note that “long” could also indicate a negative sentiment (say for “startup time”), and the above TST is able to differentiate them.
",1 Introduction,[0],[0]
"As the context information carried by the representations from the LSTM layer will be lost after the non-linear TST, we design a contextpreserving mechanism to contextualize the generated target-specific word representations.",1 Introduction,[0],[0]
Such mechanism also allows deep transformation structure to learn abstract features3.,1 Introduction,[0],[0]
"To help the CNN feature extractor locate sentiment indicators more accurately, we adopt a proximity strategy to scale the input of convolutional layer with positional relevance between a word and the target.
",1 Introduction,[0],[0]
"2One method could be concatenating the target representation with each word representation, but the effect as shown in (Wang et al., 2016) is limited.
3Abstract features usually refer to the features ultimately useful for the task (Bengio et al., 2013; LeCun et al., 2015).
",1 Introduction,[0],[0]
"In summary, our contributions are as follows: • TNet adapts CNN to handle target-level sentiment classification, and its performance dominates the state-of-the-art models on benchmark datasets.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
A novel Target-Specific Transformation component is proposed to better integrate target information into the word representations.,1 Introduction,[0],[0]
"• A context-preserving mechanism is designed to forward the context information into a deep transformation architecture, thus, the model can learn more abstract contextualized word features from deeper networks.",1 Introduction,[0],[0]
"Given a target-sentence pair (wτ ,w), where wτ = {wτ1 , wτ2 , ..., wτm} is a sub-sequence of w = {w1, w2, ..., wn}, and the corresponding word embeddings xτ = {xτ1 , xτ2 , ..., xτm} and x = {x1, x2, ..., xn}, the aim of target sentiment classification is to predict the sentiment polarity y ∈ {P,N,O} of the sentence w over the target wτ , where P , N and O denote “positive”, “negative” and “neutral” sentiments respectively.
",2 Model Description,[0],[0]
The architecture of the proposed TargetSpecific Transformation Networks (TNet) is shown in Fig. 1.,2 Model Description,[0],[0]
"The bottom layer is a BiLSTM which transforms the input x = {x1, x2, ..., xn} ∈ Rn×dimw into the contextualized word representations h(0) = {h(0)1 , h (0) 2 , ..., h (0) n } ∈ Rn×2dimh (i.e. hidden states of BiLSTM), where dimw and dimh denote the dimensions of the word embeddings and the hidden representations respectively.",2 Model Description,[0],[0]
"The middle part, the core part of our TNet, consists of L Context-Preserving Transformation (CPT) layers.",2 Model Description,[0],[0]
The CPT layer incorporates the target information into the word representations via a novel Target-Specific Transformation (TST) component.,2 Model Description,[0],[0]
"CPT also contains a contextpreserving mechanism, resembling identity mapping (He et al., 2016a,b) and highway connection (Srivastava et al., 2015a,b), allows preserving the context information and learning more abstract word-level features using a deep network.",2 Model Description,[0],[0]
"The top most part is a position-aware convolutional layer which first encodes positional relevance between a word and a target, and then extracts informative features for classification.",2 Model Description,[0],[0]
"As observed in Lai et al. (2015), combining contextual information with word embeddings is an
effective way to represent a word in convolutionbased architectures.",2.1 Bi-directional LSTM Layer,[0],[0]
"TNet also employs a BiLSTM to accumulate the context information for each word of the input sentence, i.e., the bottom part in Fig. 1.",2.1 Bi-directional LSTM Layer,[0],[0]
"For simplicity and space issue, we denote the operation of an LSTM unit on xi as LSTM(xi).",2.1 Bi-directional LSTM Layer,[0],[0]
"Thus, the contextualized word representation h(0)i ∈ R2dimh is obtained as follows:
h (0)",2.1 Bi-directional LSTM Layer,[0],[0]
i =,2.1 Bi-directional LSTM Layer,[0],[0]
"[ −−−−→ LSTM(xi); ←−−−− LSTM(xi)], i ∈",2.1 Bi-directional LSTM Layer,[0],[0]
"[1, n].",2.1 Bi-directional LSTM Layer,[0],[0]
(1),2.1 Bi-directional LSTM Layer,[0],[0]
The above word-level representation has not considered the target information yet.,2.2 Context-Preserving Transformation,[0],[0]
Traditional attention-based approaches keep the word-level features static and aggregate them with weights as the final sentence representation.,2.2 Context-Preserving Transformation,[0],[0]
"In contrast, as shown in the middle part in Fig. 1, we introduce multiple CPT layers and the detail of a single CPT is shown in Fig. 2.",2.2 Context-Preserving Transformation,[0],[0]
"In each CPT layer, a tailor-made TST component that aims at better consolidating word representation and target representation is proposed.",2.2 Context-Preserving Transformation,[0],[0]
"Moreover, we design a context-preserving mechanism enabling the learning of target-specific word representations in a deep neural architecture.",2.2 Context-Preserving Transformation,[0.9510849871425892],"['As a result of a better generalization, we achieve state-of-the-art results in all examined outof-domain evaluations.']"
TST component is depicted with the TST block in Fig. 2.,2.2.1 Target-Specific Transformation,[0],[0]
The first task of TST is to generate the representation of the target.,2.2.1 Target-Specific Transformation,[0],[0]
"Previous methods (Chen
et al., 2017; Liu and Zhang, 2017) average the embeddings of the target words as the target representation.",2.2.1 Target-Specific Transformation,[0],[0]
This strategy may be inappropriate in some cases because different target words usually do not contribute equally.,2.2.1 Target-Specific Transformation,[0],[0]
"For example, in the target “amd turin processor”, the word “processor” is more important than “amd” and “turin”, because the sentiment is usually conveyed over the phrase head, i.e.,“processor”, but seldom over modifiers (such as brand name “amd”).",2.2.1 Target-Specific Transformation,[0.9578502940330419],"['– Compatible pre-modifiers: the set of premodifiers of one mention is contained in that of the other, e.g. “the red hat that she is wearing” and “the red hat” – Compatible7 gender, e.g. “Mary” and “women” – Compatible number, e.g. “Mary” and “John” – Compatible animacy, e.g. “those hats” and “it” – Compatible attributes: compatible gender, number and animacy, e.g. “Mary” and “she” – Closest antecedent that has the same head and compatible premodifiers, e.g. “this new book” and “This book” in “Take a look at this new book.']"
Ma et al. (2017) attempted to overcome this issue by measuring the importance score between each target word representation and the averaged sentence vector.,2.2.1 Target-Specific Transformation,[0],[0]
"However, it may be ineffective for sentences expressing multiple sentiments (e.g., “Air has higher resolution but the fonts are small.”), because taking the average tends to neutralize different sentiments.
",2.2.1 Target-Specific Transformation,[0],[0]
We propose to dynamically compute the importance of target words based on each sentence word rather than the whole sentence.,2.2.1 Target-Specific Transformation,[0],[0]
"We first employ another BiLSTM to obtain the target word representations hτ ∈ Rm×2dimh :
hτj =",2.2.1 Target-Specific Transformation,[0],[0]
[ −−−−→ LSTM(xτj ); ←−−−− LSTM(xτj ),2.2.1 Target-Specific Transformation,[0],[0]
"], j ∈",2.2.1 Target-Specific Transformation,[0],[0]
"[1,m].",2.2.1 Target-Specific Transformation,[0],[0]
"(2)
Then, we dynamically associate them with each word wi in the sentence to tailor-make target representation rτi at the time step",2.2.1 Target-Specific Transformation,[0],[0]
"i:
rτi = m∑ j=1 hτj ∗ F(h (l) i , h τ j ), (3)
where the function F measures the relatedness between the j-th target word representation hτj and
the i-th word-level representation h(l)i :
F(h(l)i , h τ j ) =
exp (h (l)>",2.2.1 Target-Specific Transformation,[0],[0]
i h τ j ),2.2.1 Target-Specific Transformation,[0],[0]
"∑m
k=1 exp (h (l)>",2.2.1 Target-Specific Transformation,[0],[0]
i h τ k) .,2.2.1 Target-Specific Transformation,[0],[0]
"(4)
Finally, the concatenation of rτi and h (l) i is fed into a fully-connected layer to obtain the i-th targetspecific word representation h̃i (l) :
h̃ (l) i = g(W τ",2.2.1 Target-Specific Transformation,[0],[0]
[h (l) i :,2.2.1 Target-Specific Transformation,[0],[0]
r τ,2.2.1 Target-Specific Transformation,[0],[0]
i ],2.2.1 Target-Specific Transformation,[0],[0]
"+ b τ ), (5)
where g(∗) is a non-linear activation function and “:” denotes vector concatenation.",2.2.1 Target-Specific Transformation,[0],[0]
W τ,2.2.1 Target-Specific Transformation,[0],[0]
and bτ are the weights of the layer.,2.2.1 Target-Specific Transformation,[0],[0]
"After the non-linear TST (see Eq. 5), the context information captured with contextualized representations from the BiLSTM layer will be lost since the mean and the variance of the features within the feature vector will be changed.",2.2.2 Context-Preserving Mechanism,[0],[0]
"To take advantage of the context information, which has been proved to be useful in (Lai et al., 2015), we investigate two strategies: Lossless Forwarding (LF) and Adaptive Scaling (AS), to pass the context information to each following layer, as depicted by the block “LF/AS” in Fig. 2.",2.2.2 Context-Preserving Mechanism,[0],[0]
"Accordingly, the model variants are named TNet-LF and TNet-AS.
Lossless Forwarding.",2.2.2 Context-Preserving Mechanism,[0],[0]
This strategy preserves context information by directly feeding the features before the transformation to the next layer.,2.2.2 Context-Preserving Mechanism,[0],[0]
"Specifically, the input h(l+1)i of the (l+1)-th CPT layer is formulated as:
h (l+1)",2.2.2 Context-Preserving Mechanism,[0],[0]
i = h,2.2.2 Context-Preserving Mechanism,[0],[0]
(l) i + h̃ (l),2.2.2 Context-Preserving Mechanism,[0],[0]
"i , i ∈",2.2.2 Context-Preserving Mechanism,[0],[0]
"[1, n], l ∈",2.2.2 Context-Preserving Mechanism,[0],[0]
"[0, L], (6)
where h(l)i is the input of the l-th layer and h̃ (l) i is the output of TST in this layer.",2.2.2 Context-Preserving Mechanism,[0],[0]
"We unfold the recursive form of Eq. 6 as follows:
h (l+1)",2.2.2 Context-Preserving Mechanism,[0],[0]
i = h (0),2.2.2 Context-Preserving Mechanism,[0],[0]
i +TST(h (0) i )+· · ·+TST(h (l) i ).,2.2.2 Context-Preserving Mechanism,[0],[0]
"(7)
Here, we denote h̃(l)i as TST(h (l) i ).",2.2.2 Context-Preserving Mechanism,[0],[0]
"From Eq. 7, we can see that the output of each layer will contain the contextualized word representations (i.e., h (0) i ), thus, the context information is encoded into the transformed features.",2.2.2 Context-Preserving Mechanism,[0],[0]
"We call this strategy “Lossless Forwarding” because the contextualized representations and the transformed representations (i.e., TST(h(l)i )) are kept unchanged during the feature combination.
",2.2.2 Context-Preserving Mechanism,[0],[0]
Adaptive Scaling.,2.2.2 Context-Preserving Mechanism,[0],[0]
"Lossless Forwarding introduces the context information by directly adding back the contextualized features to the transformed features, which raises a question: Can the weights of the input and the transformed features be adjusted dynamically?",2.2.2 Context-Preserving Mechanism,[0],[0]
"With this motivation, we propose another strategy, named “Adaptive Scaling”.",2.2.2 Context-Preserving Mechanism,[0],[0]
"Similar to the gate mechanism in RNN variants (Jozefowicz et al., 2015), Adaptive Scaling introduces a gating function to control the passed proportions of the transformed features and the input features.",2.2.2 Context-Preserving Mechanism,[0],[0]
"The gate t(l) as follows:
t (l)",2.2.2 Context-Preserving Mechanism,[0],[0]
"i = σ(Wtransh (l) i + btrans), (8)
where t(l)i is the gate for the i-th input of the l-th CPT layer, and σ is the sigmoid activation function.",2.2.2 Context-Preserving Mechanism,[0],[0]
"Then we perform convex combination of h(l)i and h̃(l)i based on the gate:
h (l+1)",2.2.2 Context-Preserving Mechanism,[0],[0]
i = t,2.2.2 Context-Preserving Mechanism,[0],[0]
(l) i h̃ (l) i + (1− t (l) i ),2.2.2 Context-Preserving Mechanism,[0],[0]
h,2.2.2 Context-Preserving Mechanism,[0],[0]
(l) i .,2.2.2 Context-Preserving Mechanism,[0],[0]
"(9)
Here, denotes element-wise multiplication.",2.2.2 Context-Preserving Mechanism,[0],[0]
"The non-recursive form of this equation is as follows (for clarity, we ignore the subscripts):
h(l+1) =",2.2.2 Context-Preserving Mechanism,[0],[0]
"[ l∏ k=0 (1− t(k))] h(0)
+[t(0) l∏
k=1
(1− t(k))]",2.2.2 Context-Preserving Mechanism,[0],[0]
TST(h(0)),2.2.2 Context-Preserving Mechanism,[0],[0]
"+ · · ·
+t(l−1)(1− t(l))",2.2.2 Context-Preserving Mechanism,[0],[0]
TST(h(l−1)),2.2.2 Context-Preserving Mechanism,[0],[0]
"+ t(l) TST(h(l)).
",2.2.2 Context-Preserving Mechanism,[0],[0]
"Thus, the context information is integrated in each upper layer and the proportions of the contextualized representations and the transformed representations are controlled by the computed gates in different transformation layers.",2.2.2 Context-Preserving Mechanism,[0],[0]
Recall that the second issue that blocks CNN to perform well is that vanilla CNN may associate a target with unrelated general opinion words which are frequently used as modifiers for different targets across domains.,2.3 Convolutional Feature Extractor,[0],[0]
"For example, “service” in “Great food but the service is dreadful” may be associated with both “great” and “dreadful”.",2.3 Convolutional Feature Extractor,[0],[0]
"To solve it, we adopt a proximity strategy, which is observed effective in (Chen et al., 2017; Li and Lam, 2017).",2.3 Convolutional Feature Extractor,[0],[0]
"The idea is a closer opinion word is more likely to be the actual modifier of the target.
",2.3 Convolutional Feature Extractor,[0],[0]
"Specifically, we first calculate the position relevance vi between the i-th word and the target4:
vi =  1− (k+m−i)C i < k",2.3 Convolutional Feature Extractor,[0],[0]
+m 1− i−kC k +m ≤,2.3 Convolutional Feature Extractor,[0],[0]
i ≤ n 0,2.3 Convolutional Feature Extractor,[0],[0]
"i > n
(10)
where k is the index of the first target word, C is a pre-specified constant, and m is the length of the target wτ .",2.3 Convolutional Feature Extractor,[0],[0]
"Then, we use v to help CNN locate the correct opinion w.r.t.",2.3 Convolutional Feature Extractor,[0],[0]
"the given target:
ĥ (l) i = h",2.3 Convolutional Feature Extractor,[0],[0]
"(l) i ∗ vi, i ∈",2.3 Convolutional Feature Extractor,[0],[0]
"[1, n], l ∈",2.3 Convolutional Feature Extractor,[0],[0]
"[1, L].",2.3 Convolutional Feature Extractor,[0],[0]
"(11)
",2.3 Convolutional Feature Extractor,[0],[0]
"Based on Eq. 10 and Eq. 11, the words close to the target will be highlighted and those far away will be downgraded.",2.3 Convolutional Feature Extractor,[0],[0]
v is also applied on the intermediate output to introduce the position information into each CPT layer.,2.3 Convolutional Feature Extractor,[0],[0]
"Then we feed the weighted h(L) to the convolutional layer, i.e., the top-most layer in Fig. 1, to generate the feature map c ∈",2.3 Convolutional Feature Extractor,[0],[0]
"Rn−s+1 as follows:
ci = ReLU(w > convh (L) i:i+s−1 + bconv), (12)
where h(L)i:i+s−1 ∈ Rs·dimh is the concatenated vector of ĥ(L)i , · · · , ĥ (L) i+s−1, and s is the kernel size.",2.3 Convolutional Feature Extractor,[0],[0]
wconv ∈ Rs·dimh and bconv ∈ R are learnable weights of the convolutional kernel.,2.3 Convolutional Feature Extractor,[0],[0]
"To capture the most informative features, we apply max pooling (Kim, 2014) and obtain the sentence representation z ∈",2.3 Convolutional Feature Extractor,[0],[0]
"Rnk by employing nk kernels:
z =",2.3 Convolutional Feature Extractor,[0],[0]
"[max(c1), · · · ,max(cnk)]",2.3 Convolutional Feature Extractor,[0],[0]
>.,2.3 Convolutional Feature Extractor,[0],[0]
"(13)
Finally, we pass z to a fully connected layer for sentiment prediction:
p(y|wτ ,w) = Softmax(Wfz + bf ).",2.3 Convolutional Feature Extractor,[0],[0]
"(14)
where Wf and bf are learnable parameters.",2.3 Convolutional Feature Extractor,[0],[0]
"4As we perform sentence padding, it is possible that the index i is larger than the actual length n of the sentence.",2.3 Convolutional Feature Extractor,[0],[0]
"As shown in Table 1, we evaluate the proposed TNet on three benchmark datasets: LAPTOP and REST are from SemEval ABSA challenge (Pontiki et al., 2014), containing user reviews in laptop domain and restaurant domain respectively.",3.1 Experimental Setup,[0],[0]
"We also remove a few examples having the “conflict label” as done in (Chen et al., 2017); TWITTER is built by Dong et al. (2014), containing twitter posts.",3.1 Experimental Setup,[0],[0]
"All tokens are lowercased without removal of stop words, symbols or digits, and sentences are zero-padded to the length of the longest sentence in the dataset.",3.1 Experimental Setup,[0],[0]
Evaluation metrics are Accuracy and Macro-Averaged F1 where the latter is more appropriate for datasets with unbalanced classes.,3.1 Experimental Setup,[0],[0]
"We also conduct pairwise t-test on both Accuracy and Macro-Averaged F1 to verify if the improvements over the compared models are reliable.
",3.1 Experimental Setup,[0],[0]
"TNet is compared with the following methods.
",3.1 Experimental Setup,[0],[0]
"• SVM (Kiritchenko et al., 2014):",3.1 Experimental Setup,[0],[0]
"It is a traditional support vector machine based model with extensive feature engineering;
• AdaRNN (Dong et al., 2014):",3.1 Experimental Setup,[0],[0]
"It learns the sentence representation toward target for sentiment prediction via semantic composition over dependency tree;
• AE-LSTM, and ATAE-LSTM (Wang et al., 2016): AE-LSTM is a simple LSTM model incorporating the target embedding as input, while ATAE-LSTM extends AE-LSTM with attention;
• IAN (Ma et al., 2017): IAN employs two LSTMs to learn the representations of the context and the target phrase interactively;
• CNN-ASP: It is a CNN-based model implemented by us which directly concatenates target representation to each word embedding;
• TD-LSTM (Tang et al., 2016a):",3.1 Experimental Setup,[0],[0]
"It employs two LSTMs to model the left and right contexts of the target separately, then performs predictions based on concatenated context representations;
• MemNet (Tang et al., 2016b):",3.1 Experimental Setup,[0],[0]
"It applies attention mechanism over the word embeddings multiple times and predicts sentiments
based on the top-most sentence representations;
• BILSTM-ATT-G (Liu and Zhang, 2017):",3.1 Experimental Setup,[0],[0]
"It models left and right contexts using two attention-based LSTMs and introduces gates to measure the importance of left context, right context, and the entire sentence for the prediction;
• RAM (Chen et al., 2017): RAM is a multilayer architecture where each layer consists of attention-based aggregation of word features and a GRU cell to learn the sentence representation.
",3.1 Experimental Setup,[0],[0]
"We run the released codes of TD-LSTM and BILSTM-ATT-G to generate results, since their papers only reported results on TWITTER.",3.1 Experimental Setup,[0],[0]
"We also rerun MemNet on our datasets and evaluate it with both accuracy and Macro-Averaged F1.5
We use pre-trained GloVe vectors (Pennington et al., 2014) to initialize the word embeddings and the dimension is 300 (i.e., dimw = 300).",3.1 Experimental Setup,[0],[0]
"For out-of-vocabulary words, we randomly sample their embeddings from the uniform distribution U(−0.25, 0.25), as done in (Kim, 2014).",3.1 Experimental Setup,[0],[0]
"We only use one convolutional kernel size because it was observed that CNN with single optimal kernel size is comparable with CNN having multiple kernel sizes on small datasets (Zhang and Wallace, 2017).",3.1 Experimental Setup,[0],[0]
"To alleviate overfitting, we apply dropout on the input word embeddings of the LSTM and",3.1 Experimental Setup,[0],[0]
the ultimate sentence representation z.,3.1 Experimental Setup,[0],[0]
"All weight matrices are initialized with the uniform distribution U(−0.01, 0.01) and the biases are initialized
5The codes of TD-LSTM/MemNet and BILSTM-ATTG are available at: http://ir.hit.edu.cn/˜dytang and http://leoncrashcode.github.io.",3.1 Experimental Setup,[0],[0]
"Note that MemNet was only evaluated with accuracy.
as zeros.",3.1 Experimental Setup,[0],[0]
"The training objective is cross-entropy, and Adam (Kingma and Ba, 2015) is adopted as the optimizer by following the learning rate and the decay rates in the original paper.
",3.1 Experimental Setup,[0],[0]
The hyper-parameters of TNet-LF and TNetAS are listed in Table 2.,3.1 Experimental Setup,[0],[0]
"Specifically, all hyperparameters are tuned on 20% randomly held-out training data and the hyper-parameter collection producing the highest accuracy score is used for testing.",3.1 Experimental Setup,[0],[0]
Our model has comparable number of parameters compared to traditional LSTM-based models as we reuse parameters in the transformation layers and BiLSTM.6,3.1 Experimental Setup,[0],[0]
"As shown in Table 3, both TNet-LF and TNet-AS consistently achieve the best performance on all datasets, which verifies the efficacy of our whole TNet model.",3.2 Main Results,[0],[0]
"Moreover, TNet can perform well for different kinds of user generated content, such as product reviews with relatively formal sentences in LAPTOP and REST, and tweets with more ungrammatical sentences in TWITTER.",3.2 Main Results,[0],[0]
The reason is the CNN-based feature extractor arms TNet with more power to extract accurate features from ungrammatical sentences.,3.2 Main Results,[0],[0]
"Indeed, we can also observe that another CNN-based baseline, i.e., CNNASP implemented by us, also obtains good results on TWITTER.
",3.2 Main Results,[0],[0]
"On the other hand, the performance of those comparison methods is mostly unstable.",3.2 Main Results,[0],[0]
"For the tweet in TWITTER, the competitive BILSTMATT-G and RAM cannot perform as effective as they do for the reviews in LAPTOP and REST, due to the fact that they are heavily rooted in LSTMs and the ungrammatical sentences hinder their ca-
6All experiments are conducted on a single NVIDIA GTX 1080.",3.2 Main Results,[0],[0]
"The prediction cost of a sentence is about 2 ms.
pability in capturing the context features.",3.2 Main Results,[0],[0]
"Another difficulty caused by the ungrammatical sentences is that the dependency parsing might be errorprone, which will affect those methods such as AdaRNN using dependency information.
",3.2 Main Results,[0],[0]
"From the above observations and analysis, some takeaway message for the task of target sentiment classification could be:
• LSTM-based models relying on sequential information can perform well for formal sentences by capturing more useful context features;
",3.2 Main Results,[0],[0]
"• For ungrammatical text, CNN-based models may have some advantages because CNN aims to extract the most informative n-gram features and is thus less sensitive to informal texts without strong sequential patterns.",3.2 Main Results,[0],[0]
"To investigate the impact of each component such as deep transformation, context-preserving mechanism, and positional relevance, we perform comparison between the full TNet models and its ablations (the third group in Table 3).",3.3 Performance of Ablated TNet,[0],[0]
"After removing the deep transformation (i.e., the techniques introduced in Section 2.2), both TNet-LF and TNetAS are reduced to TNet w/o transformation (where
position relevance is kept), and their results in both accuracy and F1 measure are incomparable with those of TNet.",3.3 Performance of Ablated TNet,[0],[0]
"It shows that the integration of target information into the word-level representations is crucial for good performance.
",3.3 Performance of Ablated TNet,[0],[0]
"Comparing the results of TNet and TNet w/o context (where TST and position relevance are kept), we observe that the performance of TNet w/o context drops significantly on LAPTOP and REST7, while on TWITTER, TNet w/o context performs very competitive (p-values with TNetLF and TNet-AS are 0.066 and 0.053 respectively for Accuracy).",3.3 Performance of Ablated TNet,[0],[0]
"Again, we could attribute this phenomenon to the ungrammatical user generated content of twitter, because the contextpreserving component becomes less important for such data.",3.3 Performance of Ablated TNet,[0],[0]
TNet,3.3 Performance of Ablated TNet,[0],[0]
"w/o context performs consistently better than TNet w/o transformation, which verifies the efficacy of the target specific transformation (TST), before applying context-preserving.
",3.3 Performance of Ablated TNet,[0],[0]
"As for the position information, we conduct statistical t-test between TNet-LF/AS and TNetLF/AS w/o position together with performance comparison.",3.3 Performance of Ablated TNet,[0],[0]
"All of the produced p-values are less than 0.05, suggesting that the improvements brought in by position information are significant.
",3.3 Performance of Ablated TNet,[0],[0]
"7Without specification, the significance level is set to 0.05.",3.3 Performance of Ablated TNet,[0],[0]
"The next interesting question is what if we replace the transformation module (i.e., the CPT layers in Fig.1) of TNet with other commonly-used components?",3.4 CPT versus Alternatives,[0],[0]
"We investigate two alternatives: attention mechanism and fully-connected (FC) layer, resulting in three pipelines as shown in the second group of Table 3 (position relevance is kept for them).
",3.4 CPT versus Alternatives,[0],[0]
"LSTM-ATT-CNN applies attention as the alternative8, and it does not need the contextpreserving mechanism.",3.4 CPT versus Alternatives,[0],[0]
It performs unexceptionally worse than the TNet variants.,3.4 CPT versus Alternatives,[0],[0]
We are surprised that LSTM-ATT-CNN is even worse than TNet w/o transformation (a pipeline simply removing the transformation module) on TWITTER.,3.4 CPT versus Alternatives,[0],[0]
"More concretely, applying attention results in negative effect on TWITTER, which is consistent with the observation that all those attention-based state-of-the-art methods (i.e., TD-LSTM, MemNet, BILSTM-ATT-G, and RAM) cannot perform well on TWITTER.
",3.4 CPT versus Alternatives,[0],[0]
"LSTM-FC-CNN-LF and LSTM-FC-CNN-AS are built by applying FC layer to replace TST and keeping the context-preserving mechanism (i.e., LF and AS).",3.4 CPT versus Alternatives,[0],[0]
"Specifically, the concatenation of word representation and the averaged target vector is fed to the FC layer to obtain targetspecific features.",3.4 CPT versus Alternatives,[0],[0]
Note that LSTM-FC-CNNLF/AS are equivalent to TNet-LF/AS when processing single-word targets (see Eq. 3).,3.4 CPT versus Alternatives,[0],[0]
They obtain competitive results on all datasets: comparable with or better than the state-of-the-art methods.,3.4 CPT versus Alternatives,[0],[0]
"The TNet variants can still outperform LSTMFC-CNN-LF/AS with significant gaps, e.g., on LAPTOP and REST, the accuracy gaps between TNet-LF and LSTM-FC-CNN-LF are 0.42% (p < 0.03) and 0.38% (p < 0.04) respectively.",3.4 CPT versus Alternatives,[0],[0]
"As our TNet involves multiple CPT layers, we investigate the effect of the layer number L. Specifically, we conduct experiments on the held-out training data of LAPTOP and vary L from 2 to 10, increased by 2.",3.5 Impact of CPT Layer Number,[0],[0]
The cases L=1 and L=15 are also included.,3.5 Impact of CPT Layer Number,[0],[0]
The results are illustrated in Figure 3.,3.5 Impact of CPT Layer Number,[0],[0]
We can see that both TNet-LF and TNetAS achieve the best results when L=2.,3.5 Impact of CPT Layer Number,[0],[0]
"While increasing L, the performance is basically becoming worse.",3.5 Impact of CPT Layer Number,[0],[0]
"For large L, the performance of TNet-AS
8We tried different attention mechanisms and report the best one here, namely, dot attention (Luong et al., 2015).
generally becomes more sensitive, it is probably because AS involves extra parameters (see Eq 9) that increase the training difficulty.",3.5 Impact of CPT Layer Number,[0],[0]
Table 4 shows some sample cases.,3.6 Case Study,[0],[0]
The input targets are wrapped in the brackets with true labels given as subscripts.,3.6 Case Study,[0],[0]
"The notations P, N and O in the table represent positive, negative and neutral respectively.",3.6 Case Study,[0],[0]
"For each sentence, we underline the target with a particular color, and the text of its corresponding most informative n-gram feature9 captured by TNet-AS (TNet-LF captures very similar features) is in the same color (so color printing is preferred).",3.6 Case Study,[0],[0]
"For example, for the target “resolution” in the first sentence, the captured feature is “Air has higher”.",3.6 Case Study,[0],[0]
"Note that as discussed above, the CNN layer of TNet captures such features with the size-three kernels, so that the features are trigrams.",3.6 Case Study,[0],[0]
"Each of the last features of the second and seventh sentences contains a padding token, which is not shown.
",3.6 Case Study,[0],[0]
Our TNet variants can predict target sentiment more accurately than RAM and BILSTM-ATT-G in the transitional sentences such as the first sentence by capturing correct trigram features.,3.6 Case Study,[0],[0]
"For the third sentence, its second and third most informative trigrams are “100% .",3.6 Case Study,[0],[0]
"PAD” and “’ s not”, being used together with “features make up”, our models can make correct predictions.",3.6 Case Study,[0],[0]
"Moreover, TNet can still make correct prediction when the explicit opinion is target-specific.",3.6 Case Study,[0],[0]
"For example,
9For each convolutional filter, only one n-gram feature in the feature map will be kept after the max pooling.",3.6 Case Study,[0],[0]
"Among those from different filters, the n-gram with the highest frequency will be regarded as the most informative n-gram w.r.t.",3.6 Case Study,[0],[0]
"the given target.
“long” in the fifth sentence is negative for “startup time”, while it could be positive for other targets such as “battery life” in the sixth sentence.",3.6 Case Study,[0],[0]
The sentiment of target-specific opinion word is conditioned on the given target.,3.6 Case Study,[0],[0]
"Our TNet variants, armed with the word-level feature transformation w.r.t.",3.6 Case Study,[0],[0]
"the target, is capable of handling such case.
",3.6 Case Study,[0],[0]
"We also find that all these models cannot give correct prediction for the last sentence, a commonly used subjunctive style.",3.6 Case Study,[0],[0]
"In this case, the difficulty of prediction does not come from the detection of explicit opinion words but the inference based on implicit semantics, which is still quite challenging for neural network models.",3.6 Case Study,[0],[0]
"Apart from sentence level sentiment classification (Kim, 2014; Shi et al., 2018), aspect/target level sentiment classification is also an important research topic in the field of sentiment analysis.",4 Related Work,[0],[0]
"The early methods mostly adopted supervised learning approach with extensive hand-coded features (Blair-Goldensohn et al., 2008; Titov and McDonald, 2008; Yu et al., 2011; Jiang et al., 2011; Kiritchenko et al., 2014; Wagner et al., 2014; Vo and Zhang, 2015), and they fail to model the semantic relatedness between a target and its context which is critical for target sentiment analysis.",4 Related Work,[0],[0]
Dong et al. (2014) incorporate the target information into the feature learning using dependency trees.,4 Related Work,[0],[0]
"As observed in previous works, the performance heavily relies on the quality of dependency parsing.",4 Related Work,[0],[0]
Tang et al. (2016a) propose to split the context into two parts and associate target with contextual features separately.,4 Related Work,[0],[0]
"Similar to (Tang et al., 2016a), Zhang et al. (2016) develop a three-way gated neural network to model the in-
teraction between the target and its surrounding contexts.",4 Related Work,[0],[0]
"Despite the advantages of jointly modeling target and context, they are not capable of capturing long-range information when some critical context information is far from the target.",4 Related Work,[0],[0]
"To overcome this limitation, researchers bring in the attention mechanism to model target-context association (Tang et al., 2016a,b; Wang et al., 2016; Yang et al., 2017; Liu and Zhang, 2017; Ma et al., 2017; Chen et al., 2017; Zhang et al., 2017; Tay et al., 2017).",4 Related Work,[0],[0]
"Compared with these methods, our TNet avoids using attention for feature extraction so as to alleviate the attended noise.",4 Related Work,[0],[0]
"We re-examine the drawbacks of attention mechanism for target sentiment classification, and also investigate the obstacles that hinder CNN-based models to perform well for this task.",5 Conclusions,[0],[0]
Our TNet model is carefully designed to solve these issues.,5 Conclusions,[0],[0]
"Specifically, we propose target specific transformation component to better integrate target information into the word representation.",5 Conclusions,[0],[0]
"Moreover, we employ CNN as the feature extractor for this classification problem, and rely on the contextpreserving and position relevance mechanisms to maintain the advantages of previous LSTM-based models.",5 Conclusions,[0],[0]
The performance of TNet consistently dominates previous state-of-the-art methods on different types of data.,5 Conclusions,[0],[0]
"The ablation studies show the efficacy of its different modules, and thus verify the rationality of TNet’s architecture.",5 Conclusions,[0],[0]
Target-oriented sentiment classification aims at classifying sentiment polarities over individual opinion targets in a sentence.,abstractText,[0],[0]
"RNN with attention seems a good fit for the characteristics of this task, and indeed it achieves the state-of-the-art performance.",abstractText,[0],[0]
"After re-examining the drawbacks of attention mechanism and the obstacles that block CNN to perform well in this classification task, we propose a new model to overcome these issues.",abstractText,[0],[0]
"Instead of attention, our model employs a CNN layer to extract salient features from the transformed word representations originated from a bi-directional RNN layer.",abstractText,[0],[0]
"Between the two layers, we propose a component to generate target-specific representations of words in the sentence, meanwhile incorporate a mechanism for preserving the original contextual information from the RNN layer.",abstractText,[0],[0]
Experiments show that our model achieves a new state-of-the-art performance on a few benchmarks.1,abstractText,[0],[0]
Transformation Networks for Target-Oriented Sentiment Classification,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2313–2318, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"Transition-based parsing, one of the most prominent dependency parsing techniques, constructs a dependency structure by reading words sequentially from the sentence, and making a series of local decisions (called transitions) which incrementally build the structure.",1 Introduction,[0],[0]
"Transition-based parsing has been shown to be both fast and accurate; the number of transitions required to fully parse the sentence is linear relative to the number of words in the sentence.
",1 Introduction,[0],[0]
"In recent years, the field has seen dramatic improvements in the ability to correctly predict transitions.",1 Introduction,[0],[0]
Recent models include the greedy StackLSTM model of Dyer et al. (2015) and the globally normalized feed-forward networks of Andor et al. (2016).,1 Introduction,[0],[0]
"These models output a local decision at each transition point, so searching the space of possible paths to the predicted tree is an important component of high-accuracy parsers.
",1 Introduction,[0],[0]
One common search technique is beam search.,1 Introduction,[0],[0]
"(Zhang and Clark, 2008; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Zhou et al., 2015; Weiss et al., 2015; Yazdani and Henderson, 2015)",1 Introduction,[0],[0]
"In beamsearch, a fixed number of candidate transition sequences are generated, and the highest-scoring sequence is chosen as the answer.",1 Introduction,[0],[0]
One downside to beam search is that it often results in a significant amount of wasted predictions.,1 Introduction,[0],[0]
"A constant number of beams are explored at all points throughout the sentence, leading to some unnecessary exploration towards the beginning of the sentence, and potentially insufficient exploration towards the end.
",1 Introduction,[0],[0]
"One way that this problem can be mitigated is by using a dynamically-sized beam (Mejia-Lavalle and Ramos, 2013).",1 Introduction,[0],[0]
"When using this technique, at each step, prune all beams whose scores are below some value s, where s is calculated based upon the distribution of scores of available beams.",1 Introduction,[0],[0]
"Common methods for pruning are removing all beams below some percentile, or any beams which scored below some constant percentage of the highest-scoring beam.
",1 Introduction,[0],[0]
Another approach to solving this issue is given by Choi and McCallum (2013).,1 Introduction,[0],[0]
"They introduced selectional branching, which involves performing an initial greedy parse, and then using confidence estimates on each prediction to spawn additional beams.",1 Introduction,[0],[0]
"Relative to standard beam-search, this reduces the average number of predictions required to parse a sentence, resulting in a speed-up.
",1 Introduction,[0],[0]
"In this paper, we introduce heuristic backtracking, which expands on the ideas of selectional branching by integrating a search strategy based on a heuristic function (Pearl, 1984): a function which estimates
2313
the future cost of taking a particular decision.",1 Introduction,[0],[0]
"When paired with a good heuristic, heuristic backtracking maintains the property of reducing wasted predictions, but allows us to more fully explore the space of possible transition sequences (as compared to selectional branching).",1 Introduction,[0],[0]
"In this paper, we use a heuristic based on the confidence of transition predictions.
",1 Introduction,[0],[0]
We also introduce a new optimization: heuristic backtracking with cutoff.,1 Introduction,[0],[0]
"Since heuristic backtracking produces results incrementally, it is possible to stop the search early if we have found an answer that we believe to be the gold parse, saving time proportional to the number of backtracks remaining.
",1 Introduction,[0],[0]
"We compare the performance of these various decoding algorithms with the Stack-LSTM parser (Dyer et al., 2015), and achieve slightly higher accuracy than beam search, in significantly less time.",1 Introduction,[0],[0]
Our starting point is the model described by Dyer et al. (,2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"2015).1 The parser implements the arc-standard algorithm (Nivre, 2004) and it therefore makes use of a stack and a buffer.",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"In (Dyer et al., 2015), the stack and the buffer are encoded with Stack-LSTMs, and a third sequence with the history of actions taken by the parser is encoded with another Stack-LSTM.",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"The three encoded sequences form the parser state pt defined as follows,
pt = max {0,W[st;bt;at] + d} , (1)
where W is a learned parameter matrix, bt, st and at are the stack LSTM encoding of buffer, stack and the history of actions, and d is a bias term.",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"The output pt (after a component-wise rectified linear unit (ReLU) nonlinearity (Glorot et al., 2011)) is then used to compute the probability of the parser action at time t as:
p(zt | pt) = exp
( g>ztpt + qzt ) ∑
z′∈A(S,B) exp",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"( g>z′pt + qz′ ) , (2)
where gz is a column vector representing the (output) embedding of the parser action z, and qz is a bias term for action z.",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"The set A(S,B) represents
1We refer to the original work for details.
",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
the valid transition actions that may be taken in the current state.,2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"The objective function is:
Lθ(w, z) = |z|∑
t=1
log p(zt | pt) (3)
where z refers to parse transitions.",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"Using the Stack-LSTM parsing model of Dyer et al. (2015) to predict each decision greedily yields very high accuracy; however, it can only explore one path, and it therefore can be improved by conducting a larger search over the space of possible parses.",3 Heuristic Backtracking,[0],[0]
"To do this, we introduce a new algorithm, heuristic backtracking.",3 Heuristic Backtracking,[0],[0]
We also introduce a novel cutoff approach to further increase speed.,3 Heuristic Backtracking,[0],[0]
"We model the space of possible parses as a tree, where each node represents a certain parse state (with complete values for stack, buffer, and action history).",3.1 Decoding Strategy,[0],[0]
"Transitions connect nodes of the tree, and leaves of the tree represent final states.
",3.1 Decoding Strategy,[0],[0]
"During the first iteration, we start at the root of the tree, and greedily parse until we reach a leaf.",3.1 Decoding Strategy,[0],[0]
"That is, for each node, we use the Stack-LSTM model to calculate scores for each transition (as described in Section 2), and then execute the highest-scoring transition, generating a child node upon which we repeat the procedure.",3.1 Decoding Strategy,[0],[0]
"Additionally, we save an ordered list of the transition scores, and calculate the confidence of the node (as described in Section 3.2).
",3.1 Decoding Strategy,[0],[0]
"When we reach the leaf node, we backtrack to the location that is most likely to fix a mistake.",3.1 Decoding Strategy,[0],[0]
"To find this, we look at all explored nodes that still have at least one unexplored child, and choose the node with the lowest heuristic confidence (see Section 3.2).",3.1 Decoding Strategy,[0],[0]
"We rewind our stack, buffer, and action history to that state, and execute the highest-scoring transition from that node that has not yet been explored.",3.1 Decoding Strategy,[0],[0]
"At this point, we are again in a fully-unexplored node, and can greedily parse just as before until we reach another leaf.
",3.1 Decoding Strategy,[0],[0]
"Once we have generated b leaves, we score them all and return the transition sequence leading up to the highest-scoring leaf as the answer.",3.1 Decoding Strategy,[0],[0]
"Just as in previous studies (Collins and Roark, 2004), we use the
sum of the log probabilities of all individual transitions as the overall score for the parse.",3.1 Decoding Strategy,[0],[0]
"Let n indicate a node, which consists of a state, a buffer, and an action history.",3.2 Calculating Error Likelihood,[0],[0]
"We may refer to a specific node as nji , which means it has i actions in its action history and it is part of the history of the jth leaf (and possibly subsequent leaves).",3.2 Calculating Error Likelihood,[0],[0]
"Let the function T (n) represent a sorted vector containing all possible transitions from n, and S(n) represent a sorted vector containing the scores of all of these transitions, in terms of log probabilities of each score.",3.2 Calculating Error Likelihood,[0],[0]
"We can index the scores in order of value, so T1(n) is the highest-scoring transition and S1(n) is its score, T2(n) is the second-highest-scoring transition, etc.",3.2 Calculating Error Likelihood,[0],[0]
"Here, let un indicate the ranking of the transition leading to the first unexplored child of a node n. Also, let V (n) represent the total score of all nodes in the history of n, i.e. the sum of all the scores of individual transitions that allowed us to get to n.
To calculate the confidence of an individual node, Choi and McCallum (2013) simply found the score margin, or difference in probability between the topscoring transition and the second-highest scoring transition: C(n) = S1(n)",3.2 Calculating Error Likelihood,[0],[0]
− S2(n).,3.2 Calculating Error Likelihood,[0],[0]
"In selectional branching, the only states for which the confidence was relevant were the states in the first greedy parse, i.e. states n1i for all i. For heuristic backtracking, we wish to generalize this to any state nji for all i and j.
We do this in the following way:
H(nji )",3.2 Calculating Error Likelihood,[0],[0]
=,3.2 Calculating Error Likelihood,[0],[0]
(V (n 1 i ),3.2 Calculating Error Likelihood,[0],[0]
− V (nji )),3.2 Calculating Error Likelihood,[0],[0]
"+ (S(u
n",3.2 Calculating Error Likelihood,[0],[0]
j,3.2 Calculating Error Likelihood,[0],[0]
"i
)−1(n",3.2 Calculating Error Likelihood,[0],[0]
"j i ) + S(u
n j",3.2 Calculating Error Likelihood,[0],[0]
"i
)(n j i ))
",3.2 Calculating Error Likelihood,[0],[0]
"(4) Intuitively, this formula means that the node that will be explored first is the node that will yield a parse that scores as close to the greedy choice as possible.",3.2 Calculating Error Likelihood,[0],[0]
"The first term ensures that it has a history of good choices, and the second term ensures that the new child node being explored will be nearly as good as the prior child.",3.2 Calculating Error Likelihood,[0],[0]
"As discussed earlier, we use number of predictions made by the model as a proxy for the speed; execution speed may vary based on system and algorithmic implementation, but prediction count gives a good estimate of the overall work done by the algorithm.
",3.3 Number of Predictions,[0],[0]
"Consider a sentence of length l, which requires at most 2l transitions with the greedy decoder (Nivre, 2004).",3.3 Number of Predictions,[0],[0]
"The number of predictions required for heuristic backtracking for b leaves is guaranteed to be less than or equal to a beam search with b beams.
",3.3 Number of Predictions,[0],[0]
"When doing a beam search, the first transition will require 1 prediction, and then every subsequent transition will require 1 prediction per beam, or b predictions.",3.3 Number of Predictions,[0],[0]
This results in a total of b(2l,3.3 Number of Predictions,[0],[0]
"− 1) + 1 predictions.
",3.3 Number of Predictions,[0],[0]
"When doing heuristic backtracking, the first greedy search will require 2l predictions.",3.3 Number of Predictions,[0],[0]
"Every
subsequent prediction will require a number of predictions dependent on the target of the backtrack: backtracking to nji will require 2l − (i + 1) predictions.",3.3 Number of Predictions,[0],[0]
Note that 0,3.3 Number of Predictions,[0],[0]
<,3.3 Number of Predictions,[0],[0]
i < 2l.,3.3 Number of Predictions,[0],[0]
"Thus, each backtrack will require at maximum 2l − 1 predictions.",3.3 Number of Predictions,[0],[0]
"Therefore, the maximum total amount of predictions is 2l + (b− 1)(2l",3.3 Number of Predictions,[0],[0]
"− 1) = b(2l − 1) + 1.
",3.3 Number of Predictions,[0],[0]
"However, note that on average, there are significantly fewer.",3.3 Number of Predictions,[0],[0]
"Assuming that all parts of a sentence have approximately equal score distributions, the average backtrack will be where i = l, and reduce predictions by 50%.
",3.3 Number of Predictions,[0],[0]
An intuitive understanding of this difference can be gained by viewing the graphs of various decoding methods in Figure 1.,3.3 Number of Predictions,[0],[0]
"Beam search has many nodes which never yield children that reach an end-state; dynamic beam search has fewer, but still several.",3.3 Number of Predictions,[0],[0]
"Selectional branching has none, but suffers from the restriction that every parse candidate can be no more than one decision away from the greedy parse.",3.3 Number of Predictions,[0],[0]
"With heuristic backtracking, there is no such restriction, but yet every node explored is directly useful for generating a candidate parse.",3.3 Number of Predictions,[0],[0]
Another inefficiency inherent to beam search is the fact that all b beams are always fully explored.,3.4 Early Cutoff,[0],[0]
"Since the beams are calculated in parallel, this is inevitable.",3.4 Early Cutoff,[0],[0]
"However, with heuristic backtracking, the beams are calculated incrementally; this gives us the opportunity to cut off our search at any point.",3.4 Early Cutoff,[0],[0]
"In order to leverage this into more efficient parsing, we constructed a second Stack-LSTM model, which we call the cutoff model.",3.4 Early Cutoff,[0],[0]
"The cutoff model uses a single Stack-LSTM2 that takes as input the sequence of parser states (see Eq 1), and outputs a boolean variable predicting whether the entire parse is correct or incorrect.
",3.4 Early Cutoff,[0],[0]
"To train the cutoff model, we used stochastic gradient descent over the training set.",3.4 Early Cutoff,[0],[0]
"For each training example, we first parse it greedily using the StackLSTM parser.",3.4 Early Cutoff,[0],[0]
"Then, for as long as the parse has at least one mistake, we pass it to the cutoff model as a negative training example.",3.4 Early Cutoff,[0],[0]
"Once the parse is completely correct, we pass it to the cutoff model as a positive training example.",3.4 Early Cutoff,[0],[0]
"The loss function that we
22 layers and 300 dimensions.
use is:
Lθ = − log p(t | s) (5)
where s is the LSTM encoded vector and t is the truth (parse correct/incorrect).
",3.4 Early Cutoff,[0],[0]
"When decoding using early cutoff, we follow the exact same procedure as for normal heuristic backtracking, but after every candidate parse is generated, we use it as input to our cutoff model.",3.4 Early Cutoff,[0],[0]
"When our cutoff model returns our selection as correct, we stop backtracking and return it as the answer.",3.4 Early Cutoff,[0],[0]
"If we make b attempts without finding a correct parse, we follow the same procedure as before.",3.4 Early Cutoff,[0],[0]
"To test the effectiveness of heuristic backtracking, we compare it with other decoding techniques: greedy, beam search,3, dynamic beam search (Mejia-Lavalle and Ramos, 2013), and selectional branching (Choi and McCallum, 2013).",4 Experiments and Results,[0],[0]
"We then try heuristic backtracking (see Section 3.1), and heuristic backtracking with cutoff (see Section 3.4).",4 Experiments and Results,[0],[0]
"Note that beam search was not used for early-update training (Collins and Roark, 2004).",4 Experiments and Results,[0],[0]
"We use the same greedy training strategy for all models, and we only change the decoding strategy.
",4 Experiments and Results,[0],[0]
We tested the performance of these algorithms on the English SD and Chinese CTB.4,4 Experiments and Results,[0],[0]
"A single model was trained using the techniques described in Section 2, and used as the transition model for all decoding algorithms.",4 Experiments and Results,[0],[0]
"Each decoding technique was tested with varying numbers of beams; as b increased, both the predictions per sentence and accuracy trended upwards.",4 Experiments and Results,[0],[0]
"The results are summarized in Table 1.5 Note that we report results for only the highestaccuracy b (in the development set) for each.
",4 Experiments and Results,[0],[0]
We also report the results of the cutoff model in Table 2.,4 Experiments and Results,[0],[0]
"The same greedily-trained model as above was used to generate candidate parses and confidence estimates for each transition, and then the cutoff model was trained to use these confidence esti-
3Greedy and beam-search were already explored by Dyer et al. (2015)
4Using the exact same settings as Dyer et al. (2015) with pretrained embeddings and part-of-speech tags.
",4 Experiments and Results,[0],[0]
"5The development sets are used to set the model parameters; results on the development sets are similar to the ones obtained in the test sets.
",4 Experiments and Results,[0],[0]
mates to discriminate between correctly-parsed and incorrectly-parsed sentences.,4 Experiments and Results,[0],[0]
"In Table 1 we see that in both English and Chinese, the best heuristic backtracking performs approximately as well as the best beam search, while making less than half the predictions.",5 Discussion,[0],[0]
"This supports our hypothesis that heuristic backtracking can perform at the same level as beam search, but with increased efficiency.
",5 Discussion,[0],[0]
"Dynamic beam search also performed as well as full beam search, despite demonstrating a reduction in predictions on par with that of heuristic backtracking.",5 Discussion,[0],[0]
"Since the implementation of dynamic beam search is very straightforward for systems which have already implemented beam search, we believe this will prove to be a useful finding.
",5 Discussion,[0],[0]
"Heuristic backtracking with cutoff outperformed greedy decoding, and reduced transitions by an additional 50%.",5 Discussion,[0],[0]
"However, it increased accuracy slightly less than full heuristic backtracking.",5 Discussion,[0],[0]
"We believe this difference could be mitigated with an improved cutoff model; as can be seen in Table 2, the cutoff model was only able to discriminate between correct and incorrect parses around 75% of the time.",5 Discussion,[0],[0]
"Also, note that while predictions per sentence were low, the overall runtime was increased due to running the cutoff LSTM multiple times per sentence.",5 Discussion,[0],[0]
"Heuristic backtracking is most similar to the work of Choi and McCallum (2013), but is distinguished from theirs by allowing new beams to be initialized from any point in the parse, rather than only from points in the initial greedy parse.",6 Related Work,[0],[0]
"Heuristic backtracking also bears similarity to greedy-best-firstsearch (Pearl, 1984), but is unique in that it guarantees that b candidate solutions will be found within b(2l",6 Related Work,[0],[0]
− 1) + 1 predictions.,6 Related Work,[0],[0]
"Our work also relates to beam-search parsers (Zhang and Clark, 2008, inter alia).",6 Related Work,[0],[0]
"We have introduced a novel decoding algorithm, called heuristic backtracking, and presented evidence that it performs at the same level as beam search for decoding, while being significantly more efficient.",7 Conclusions,[0],[0]
"We have demonstrated this for both English and Chinese, using a parser with strong results with a greedy decoder.",7 Conclusions,[0],[0]
"We expect that heuristic backtracking could be applied to any other transition-based parser with similar benefits.
",7 Conclusions,[0],[0]
"We plan on experimenting with various heuristics and cutoff models, such as adapting the attentionbased models of Bahdanau et al. (2014) to act as a guide for both the heuristic search and cutoff.",7 Conclusions,[0],[0]
Miguel Ballesteros was supported by the European Commission under the contract numbers FP7ICT-610411 (project MULTISENSOR) and H2020RIA-645012 (project KRISTINA).,Acknowledgments,[0],[0]
We introduce a novel approach to the decoding problem in transition-based parsing: heuristic backtracking.,abstractText,[0],[0]
"This algorithm uses a series of partial parses on the sentence to locate the best candidate parse, using confidence estimates of transition decisions as a heuristic to guide the starting points of the search.",abstractText,[0],[0]
"This allows us to achieve a parse accuracy comparable to beam search, despite using fewer transitions.",abstractText,[0],[0]
"When used to augment a Stack-LSTM transition-based parser, the parser shows an unlabeled attachment score of up to 93.30% for English and 87.61% for Chinese.",abstractText,[0],[0]
Transition-Based Dependency Parsing with Heuristic Backtracking,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 232–242 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1022
Several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel. While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge. Here we propose to interpret agents’ messages by translating them. Unlike in typical machine translation problems, we have no parallel data to learn from. Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener. We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmatics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language.1",text,[0],[0]
Several recent papers have described approaches for learning deep communicating policies (DCPs): decentralized representations of behavior that enable multiple agents to communicate via a differentiable channel that can be formulated as a recurrent neural network.,1 Introduction,[0],[0]
"DCPs have been shown to solve a variety of coordination problems, including reference games (Lazaridou et al., 2016b), logic puzzles (Foerster et al., 2016), and simple control (Sukhbaatar et al., 2016).",1 Introduction,[0],[0]
"Appealingly, the agents’ communication protocol can be learned via direct
1 We have released code and data at http://github.",1 Introduction,[0],[0]
"com/jacobandreas/neuralese.
",1 Introduction,[0],[0]
"backpropagation through the communication channel, avoiding many of the challenging inference problems associated with learning in classical decentralized decision processes (Roth et al., 2005).
",1 Introduction,[0],[0]
But analysis of the strategies induced by DCPs has remained a challenge.,1 Introduction,[0],[0]
"As an example, Figure 1 depicts a driving game in which two cars, which are unable to see each other, must both cross an intersection without colliding.",1 Introduction,[0],[0]
"In order to ensure success, it is clear that the cars must communicate with each other.",1 Introduction,[0],[0]
"But a number of successful communication strategies are possible—for example, they might report their exact (x, y) coordinates at every timestep, or they might simply announce whenever they are entering and leaving the intersection.",1 Introduction,[0],[0]
"If these messages were communicated in natural language, it would be straightforward to determine which strategy was being employed.",1 Introduction,[0],[0]
"However, DCP agents instead communicate with an automatically induced protocol of unstructured, real-valued recurrent state vectors—an artificial language we might call “neuralese,” which superficially bears little resemblance to natural language, and thus frustrates attempts at direct interpretation.
232
We propose to understand neuralese messages by translating them.",1 Introduction,[0],[0]
"In this work, we present a simple technique for inducing a dictionary that maps between neuralese message vectors and short natural language strings, given only examples of DCP agents interacting with other agents, and humans interacting with other humans.",1 Introduction,[0],[0]
"Natural language already provides a rich set of tools for describing beliefs, observations, and plans—our thesis is that these tools provide a useful complement to the visualization and ablation techniques used in previous work on understanding complex models (Strobelt et al., 2016; Ribeiro et al., 2016).
",1 Introduction,[0],[0]
"While structurally quite similar to the task of machine translation between pairs of human languages, interpretation of neuralese poses a number of novel challenges.",1 Introduction,[0],[0]
"First, there is no natural source of parallel data: there are no bilingual “speakers” of both neuralese and natural language.",1 Introduction,[0],[0]
"Second, there may not be a direct correspondence between the strategy employed by humans and DCP agents: even if it were constrained to communicate using natural language, an automated agent might choose to produce a different message from humans in a given state.",1 Introduction,[0],[0]
We tackle both of these challenges by appealing to the grounding of messages in gameplay.,1 Introduction,[0],[0]
"Our approach is based on one of the core insights in natural language semantics: messages (whether in neuralese or natural language) have similar meanings when they induce similar beliefs about the state of the world.
",1 Introduction,[0],[0]
"Based on this intuition, we introduce a translation criterion that matches neuralese messages with natural language strings by minimizing statistical distance in a common representation space of distributions over speaker states.",1 Introduction,[0],[0]
"We explore several related questions:
•",1 Introduction,[0],[0]
"What makes a good translation, and under what conditions is translation possible at all?",1 Introduction,[0],[0]
"(Section 4)
",1 Introduction,[0],[0]
• How can we build a model to translate between neuralese and natural language?,1 Introduction,[0],[0]
"(Section 5)
•",1 Introduction,[0],[0]
What kinds of theoretical guarantees can we provide about the behavior of agents communicating via this translation model?,1 Introduction,[0],[0]
"(Section 6)
",1 Introduction,[0],[0]
"Our translation model and analysis are general, and in fact apply equally to human–computer and
human–human translation problems grounded in gameplay.",1 Introduction,[0],[0]
"In this paper, we focus our experiments specifically on the problem of interpreting communication in deep policies, and apply our approach to the driving game in Figure 1 and two reference games of the kind shown in Figure 2.",1 Introduction,[0],[0]
We find that this approach outperforms a more conventional machine translation criterion both when attempting to interoperate with neuralese speakers and when predicting their state.,1 Introduction,[0],[0]
A variety of approaches for learning deep policies with communication were proposed essentially simultaneously in the past year.,2 Related work,[0],[0]
"We have broadly labeled these as “deep communicating policies”; concrete examples include Lazaridou et al. (2016b), Foerster et al. (2016), and Sukhbaatar et al. (2016).",2 Related work,[0],[0]
"The policy representation we employ in this paper is similar to the latter two of these, although the general framework is agnostic to low-level modeling details and could be straightforwardly applied to other architectures.",2 Related work,[0],[0]
"Analysis of communication strategies in all these papers has been largely adhoc, obtained by clustering states from which similar messages are emitted and attempting to manually assign semantics to these clusters.",2 Related work,[0],[0]
"The present work aims at developing tools for performing this analysis automatically.
",2 Related work,[0],[0]
"Most closely related to our approach is that of Lazaridou et al. (2016a), who also develop a model for assigning natural language interpretations to learned messages; however, this approach relies on supervised cluster labels and is targeted specifically towards referring expression games.",2 Related work,[0],[0]
"Here we attempt to develop an approach that can handle general multiagent interactions without assuming a prior discrete structure in space of observations.
",2 Related work,[0],[0]
"The literature on learning decentralized multiagent policies in general is considerably larger (Bernstein et al., 2002; Dibangoye et al., 2016).",2 Related work,[0],[0]
"This includes work focused on communication in multiagent settings (Roth et al., 2005) and even communication using natural language messages (Vogel et al., 2013b).",2 Related work,[0],[0]
"All of these approaches employ structured communication schemes with manually engineered messaging protocols; these are, in some sense, automatically interpretable, but at the cost of introducing considerable complexity into both training and inference.
",2 Related work,[0],[0]
"Our evaluation in this paper investigates communication strategies that arise in a number of different games, including reference games and an extended-horizon driving game.",2 Related work,[0],[0]
"Communication strategies for reference games were previously explored by Vogel et al. (2013a), Andreas and Klein (2016) and Kazemzadeh et al. (2014), and reference games specifically featuring end-to-end communication protocols by Yu et al. (2016).",2 Related work,[0],[0]
"On the control side, a long line of work considers nonverbal communication strategies in multiagent policies (Dragan and Srinivasa, 2013).
",2 Related work,[0],[0]
Another group of related approaches focuses on the development of more general machinery for interpreting deep models in which messages have no explicit semantics.,2 Related work,[0],[0]
"This includes both visualization techniques (Zeiler and Fergus, 2014; Strobelt et al., 2016), and approaches focused on generating explanations in the form of natural language (Hendricks et al., 2016; Vedantam et al., 2017).",2 Related work,[0],[0]
Games Consider a cooperative game with two players a and b of the form given in Figure 3.,3 Problem formulation,[0],[0]
"At every step t of this game, player a makes an observation x(t)a and receives a message z (t−1) b from b.",3 Problem formulation,[0],[0]
It then takes an action u(t)a and sends a message z (t) a to b.,3 Problem formulation,[0],[0]
(The process is symmetric for b.),3 Problem formulation,[0],[0]
"The distributions p(ua|xa, zb) and p(za|xa) together define a policy π which we assume is shared by both players, i.e. p(ua|xa, zb) = p(ub|xb, za) and p(za|xa) = p(zb|xb).",3 Problem formulation,[0],[0]
"As in a standard Markov decision process, the actions (u(t)a , u (t) b ) alter the world state, generating new observations for both players and a reward shared by both.
",3 Problem formulation,[0],[0]
"The distributions p(z|x) and p(u|x, z) may also be viewed as defining a language: they specify how a speaker will generate messages based on world states, and how a listener will respond to these mes-
sages.",3 Problem formulation,[0],[0]
Our goal in this work is to learn to translate between pairs of languages generated by different policies.,3 Problem formulation,[0],[0]
"Specifically, we assume that we have access to two policies for the same game: a “robot policy” πr and a “human policy” πh.",3 Problem formulation,[0],[0]
"We would like to use the representation of πh, the behavior of which is transparent to human users, in order to understand the behavior of πr (which is in general an uninterpretable learned model); we will do this by inducing bilingual dictionaries that map message vectors zr of πr to natural language strings zh of πh and vice-versa.
",3 Problem formulation,[0],[0]
Learned agents πr,3 Problem formulation,[0],[0]
Our goal is to present tools for interpretation of learned messages that are agnostic to the details of the underlying algorithm for acquiring them.,3 Problem formulation,[0],[0]
We use a generic DCP model as a basis for the techniques developed in this paper.,3 Problem formulation,[0],[0]
"Here each agent policy is represented as a deep recurrent Q network (Hausknecht and Stone, 2015).",3 Problem formulation,[0],[0]
This network is built from communicating cells of the kind depicted in Figure 4.,3 Problem formulation,[0],[0]
"At every timestep, this agent receives three pieces of information: an
observation of the current state of the world, the agent’s memory vector from the previous timestep, and a message from the other player.",3 Problem formulation,[0],[0]
"It then produces three outputs: a predicted Q value for every possible action, a new memory vector for the next timestep, and a message to send to the other agent.
",3 Problem formulation,[0],[0]
Sukhbaatar et al. (2016) observe that models of this form may be viewed as specifying a single RNN in which weight matrices have a particular block structure.,3 Problem formulation,[0],[0]
"Such models may thus be trained using the standard recurrent Q-learning objective, with communication protocol learned end-to-end.
",3 Problem formulation,[0],[0]
Human agents πh The translation model we develop requires a representation of the distribution over messages p(za|xa) employed by human speakers (without assuming that humans and agents produce equivalent messages in equivalent contexts).,3 Problem formulation,[0],[0]
"We model the human message generation process as categorical, and fit a simple multilayer perceptron model to map from observations to words and phrases used during human gameplay.",3 Problem formulation,[0],[0]
What does it mean for a message zh to be a “translation” of a message zr?,4 What’s in a translation?,[0],[0]
"In standard machine translation problems, the answer is that zh is likely to co-occur in parallel data with zr; that is, p(zh|zr) is large.",4 What’s in a translation?,[0],[0]
"Here we have no parallel data: even if we could observe natural language and neuralese messages produced by agents in the same state, we would have no guarantee that these messages actually served the same function.",4 What’s in a translation?,[0],[0]
Our answer must instead appeal to the fact that both natural language and neuralese messages are grounded in a common environment.,4 What’s in a translation?,[0],[0]
"For a given neuralese message zr, we will first compute a grounded representation of that message’s meaning; to translate, we find a natural-language message whose meaning is most similar.",4 What’s in a translation?,[0],[0]
The key question is then what form this grounded meaning representation should take.,4 What’s in a translation?,[0],[0]
"The existing literature suggests two broad approaches:
Semantic representation The meaning of a message za is given by its denotations: that is, by the set of world states of which za may be felicitously predicated, given the existing context available to a listener.",4 What’s in a translation?,[0],[0]
"In probabilistic terms, this says that the meaning of a message za is represented by the distribution p(xa|za, xb) it induces over speaker states.",4 What’s in a translation?,[0],[0]
"Examples of this approach include Guerin and Pitt (2001) and Pasupat and Liang (2016).
",4 What’s in a translation?,[0],[0]
Pragmatic representation,4 What’s in a translation?,[0],[0]
The meaning of a message za is given by the behavior it induces in a listener.,4 What’s in a translation?,[0],[0]
"In probabilistic terms, this says that the meaning of a message za is represented by the distribution p(ub|za, xb) it induces over actions given the listener’s observation xb.",4 What’s in a translation?,[0],[0]
"Examples of this approach include Vogel et al. (2013a) and Gauthier and Mordatch (2016).
",4 What’s in a translation?,[0],[0]
These two approaches can give rise to rather different behaviors.,4 What’s in a translation?,[0],[0]
"Consider the following example:
square hexagon circle
few many many
The top language (in blue) has a unique name for every kind of shape, while the bottom language (in red) only distinguishes between shapes with few sides and shapes with many sides.",4 What’s in a translation?,[0],[0]
"Now imagine a simple reference game with the following form: player a is covertly assigned one of these three shapes as a reference target, and communicates that reference to b; b must then pull a lever labeled large or small depending on the size of the target shape.",4 What’s in a translation?,[0],[0]
"Blue language speakers can achieve perfect success at this game, while red language speakers can succeed at best two out of three times.
",4 What’s in a translation?,[0],[0]
How should we translate the blue word hexagon into the red language?,4 What’s in a translation?,[0],[0]
"The semantic approach suggests that we should translate hexagon as many: while many does not uniquely identify the hexagon, it produces a distribution over shapes that is closest to the truth.",4 What’s in a translation?,[0],[0]
"The pragmatic approach instead suggests that we should translate hexagon as few, as this is the only message that guarantees that the listener will pull the correct lever large.",4 What’s in a translation?,[0],[0]
"So in order to produce a correct listener action, the translator might have to “lie” and produce a maximally inaccurate listener belief.
",4 What’s in a translation?,[0],[0]
"If we were exclusively concerned with building a translation layer that allowed humans and DCP agents to interoperate as effectively as possible, it would be natural to adopt a pragmatic representation strategy.",4 What’s in a translation?,[0],[0]
"But our goals here are broader: we also want to facilitate understanding, and specifically to help users of learned systems form true beliefs about the systems’ computational processes and representational abstractions.",4 What’s in a translation?,[0],[0]
"The example above demonstrates that “pragmatically” optimizing directly for task performance can sometimes lead to translations that produce inaccurate beliefs.
",4 What’s in a translation?,[0],[0]
We instead build our approach around semantic representations of meaning.,4 What’s in a translation?,[0],[0]
"By preserving semantics, we allow listeners to reason accurately about the content and interpretation of messages.",4 What’s in a translation?,[0],[0]
"We might worry that by adopting a semantics-first view, we have given up all guarantees of effective interoperation between humans and agents using a translation layer.",4 What’s in a translation?,[0],[0]
"Fortunately, this is not so: as we will see in Section 6, it is possible to show that players communicating via a semantic translator perform only boundedly worse (and sometimes better!)",4 What’s in a translation?,[0],[0]
than pairs of players with a common language.,4 What’s in a translation?,[0],[0]
"In this section, we build on the intuition that messages should be translated via their semantics to define a concrete translation model—a procedure for constructing a natural language ↔ neuralese dictionary given agent and human interactions.
",5 Translation models,[0],[0]
"We understand the meaning of a message za to be represented by the distribution p(xa|za, xb) it induces over speaker states given listener context.",5 Translation models,[0],[0]
"We can formalize this by defining the belief distribution β for a message z and context xb as:
β(za, xb) = p(xa|za, xb) = p(za|xa)p(xb|xa)∑ x′a p(za|x′a)p(xb|x′a)
",5 Translation models,[0],[0]
"Here we have modeled the listener as performing a single step of Bayesian inference, using the listener state and the message generation model (by assumption shared between players) to compute the posterior over speaker states.",5 Translation models,[0],[0]
"While in general neither humans nor DCP agents compute explicit representations of this posterior, past work has found that both humans and suitably-trained neural networks can be modeled as Bayesian reasoners (Frank et al., 2009; Paige and Wood, 2016).
",5 Translation models,[0],[0]
"This provides a context-specific representation of belief, but for messages z and z′ to have the same semantics, they must induce the same belief over all contexts in which they occur.",5 Translation models,[0],[0]
"In our probabilistic formulation, this introduces an outer expectation over contexts, providing a final measure q of the quality of a translation from z to z′:
q(z, z′) =",5 Translation models,[0],[0]
E,5 Translation models,[0],[0]
"[ DKL(β(z,Xb) || β(z′, Xb))",5 Translation models,[0],[0]
"| z, z′ ]
= ∑
xa,xb
p(xa, xb|z, z′)DKL(β(z, xb) || β(z′, xb))
∝",5 Translation models,[0],[0]
"∑
xa,xb p(xa, xb) · p(z|xa) · p(z′|xa) ·",5 Translation models,[0],[0]
"DKL(β(z, xb) || β(z′, xb));",5 Translation models,[0],[0]
"(1)
Algorithm 1 Translating messages
given: a phrase inventory L function TRANSLATE(z)
return argminz′∈L q̂(z, z′)
function q̂(z, z′) // sample contexts and distractors xai, xbi ∼ p(Xa, Xb) for i = 1..n",5 Translation models,[0],[0]
x′ai ∼ p(Xa|xbi) //,5 Translation models,[0],[0]
compute context weights w̃i ← p(z|xai) ·,5 Translation models,[0],[0]
p(z′|xai),5 Translation models,[0],[0]
"wi ← w̃i/ ∑ j w̃j
// compute divergences ki ← ∑ x∈{xa,x′a} p(z|x) log p(z|x) p(z′|x)
return ∑
iwiki
recalling that in this setting
DKL(β || β′)",5 Translation models,[0],[0]
"= ∑
xa
p(xa|z, xb) log p(xa|z, xb) p(xa|z′, xb)
∝",5 Translation models,[0],[0]
"∑
xa
p(xa|xb)p(z|xa) log p(z|xa) p(z′|xa)
(2)
which is zero when the messages z and z′ give rise to identical belief distributions and increases as they grow more dissimilar.",5 Translation models,[0],[0]
"To translate, we would like to compute tr(zr) = argminzh q(zr, zh) and tr(zh) = argminzr q(zh, zr).",5 Translation models,[0],[0]
"Intuitively, Equation 1 says that we will measure the quality of a proposed translation z 7→ z′ by asking the following question: in contexts where z is likely to be used, how frequently does z′ induce the same belief about speaker states as z?
While this translation criterion directly encodes the semantic notion of meaning described in Section 4, it is doubly intractable: the KL divergence and outer expectation involve a sum over all observations xa and xb respectively; these sums are not in general possible to compute efficiently.",5 Translation models,[0],[0]
"To avoid this, we approximate Equation 1 by sampling.",5 Translation models,[0],[0]
"We draw a collection of samples (xa, xb) from the prior over world states, and then generate for each sample a sequence of distractors (x′a, xb) from p(x ′ a|xb)",5 Translation models,[0],[0]
(we assume access to both of these distributions from the problem representation).,5 Translation models,[0],[0]
"The KL term in Equation 1 is computed over each true sample and its distractors, which are then normalized and averaged to compute the final score.
",5 Translation models,[0],[0]
"Sampling accounts for the outer p(xa, xb) in Equation 1 and the inner p(xa|xb) in Equation 2.
",5 Translation models,[0],[0]
The only quantities remaining are of the form p(z|xa).,5 Translation models,[0],[0]
"In the case of neuralese, this distribution already is part of the definition of the agent policy πr and can be reused directly.",5 Translation models,[0],[0]
"For natural language, we use transcripts of human interactions to fit a model that maps from world states to a distribution over frequent utterances as discussed in Section 3.",5 Translation models,[0],[0]
"Details of these model implementations are provided in Appendix B, and the full translation procedure is given in Algorithm 1.",5 Translation models,[0],[0]
The translation criterion in the previous section makes no reference to listener actions at all.,6 Belief and behavior,[0],[0]
The shapes example in Section 4 shows that some model performance might be lost under translation.,6 Belief and behavior,[0],[0]
It is thus reasonable to ask whether this translation model of Section 5 can make any guarantees about the effect of translation on behavior.,6 Belief and behavior,[0],[0]
"In this section we explore the relationship between beliefpreserving translations and the behaviors they produce, by examining the effect of belief accuracy and strategy mismatch on the reward obtained by cooperating agents.
",6 Belief and behavior,[0],[0]
"To facilitate this analysis, we consider a simplified family of communication games with the structure depicted in Figure 5.",6 Belief and behavior,[0],[0]
"These games can be viewed as a subset of the family depicted in Figure 3; and consist of two steps: a listener makes an observation xa and sends a single message z to a speaker, which makes its own observation xb, takes a single action u, and receives a reward.",6 Belief and behavior,[0],[0]
"We emphasize that the results in this section concern the theoretical properties of idealized games, and are presented to provide intuition about high-level properties of our approach.",6 Belief and behavior,[0],[0]
"Section 8 investigates empirical behavior of this approach on real-world tasks where these ideal conditions do not hold.
",6 Belief and behavior,[0],[0]
"Our first result is that translations that minimize semantic dissimilarity q cause the listener to take near-optimal actions:2
2Proof is provided in Appendix A.
Proposition 1.",6 Belief and behavior,[0],[0]
Semantic translations reward rational listeners.,6 Belief and behavior,[0],[0]
"Define a rational listener as one that chooses the best action in expectation over the speaker’s state:
U(z, xb) = argmax u
∑
xa
p(xa|xb, z)r(xa, xb, u)
for a reward function r ∈",6 Belief and behavior,[0],[0]
"[0, 1] that depends only on the two observations and the action.3 Now let a be a speaker of a language r, b be a listener of the same language r, and b′ be a listener of a different language h.",6 Belief and behavior,[0],[0]
Suppose that we wish for a and b′ to interact via the translator tr :,6 Belief and behavior,[0],[0]
"zr 7→ zh (so that a produces a message zr, and b′ takes an action U(zh = tr(zr), xb′)).",6 Belief and behavior,[0],[0]
"If tr respects the semantics of zr, then the bilingual pair a and b′ achieves only boundedly worse reward than the monolingual pair a and",6 Belief and behavior,[0],[0]
"b. Specifically, if q(zr, zh) ≤ D, then
Er(Xa, Xb, U(tr(Z))
",6 Belief and behavior,[0],[0]
"≥ Er(Xa, Xb, U(Z))− √ 2D (3)
",6 Belief and behavior,[0],[0]
"So as discussed in Section 4, even by committing to a semantic approach to meaning representation, we have still succeeded in (approximately) capturing the nice properties of the pragmatic approach.
",6 Belief and behavior,[0],[0]
Section 4 examined the consequences of a mismatch between the set of primitives available in two languages.,6 Belief and behavior,[0],[0]
In general we would like some measure of our approach’s robustness to the lack of an exact correspondence between two languages.,6 Belief and behavior,[0],[0]
"In the case of humans in particular we expect that a variety of different strategies will be employed, many of which will not correspond to the behavior of the learned agent.",6 Belief and behavior,[0],[0]
It is natural to want some assurance that we can identify the DCP’s strategy as long as some human strategy mirrors it.,6 Belief and behavior,[0],[0]
"Our second observation is that it is possible to exactly recover a translation of a DCP strategy from a mixture of humans playing different strategies:
Proposition 2.",6 Belief and behavior,[0],[0]
Semantic translations find hidden correspondences.,6 Belief and behavior,[0],[0]
"Consider a fixed robot policy πr and a set of human policies {πh1 , πh2 , . . . }",6 Belief and behavior,[0],[0]
"(recalling from Section 3 that each π is defined by distributions
3This notion of rationality is a fairly weak one: it permits many suboptimal communication strategies, and requires only that the listener do as well as possible given a fixed speaker— a first-order optimality criterion likely to be satisfied by any richly-parameterized model trained via gradient descent.
",6 Belief and behavior,[0],[0]
"p(z |xa) and p(u |z , xb)).",6 Belief and behavior,[0],[0]
"Suppose further that the messages employed by these human strategies are disjoint; that is, if phi(z |xa)",6 Belief and behavior,[0],[0]
"> 0, then phj (z |xa) = 0 for all j 6=",6 Belief and behavior,[0],[0]
i.,6 Belief and behavior,[0],[0]
"Now suppose that all q(zr , zh) = 0 for all messages in the support of some phi(z |xa) and > 0 for all j 6=",6 Belief and behavior,[0],[0]
i.,6 Belief and behavior,[0],[0]
"Then every message zr is translated into a message produced by πhi , and messages from other strategies are ignored.
",6 Belief and behavior,[0],[0]
"This observation follows immediately from the definition of q(zr, zh), but demonstrates one of the key distinctions between our approach and a conventional machine translation criterion.",6 Belief and behavior,[0],[0]
"Maximizing p(zh|zr) will produce the natural language message most often produced in contexts where zr is observed, regardless of whether that message is useful or informative.",6 Belief and behavior,[0],[0]
"By contrast, minimizing q(zh, zr) will find the zh that corresponds most closely to zr even when zh is rarely used.
",6 Belief and behavior,[0],[0]
"The disjointness condition, while seemingly quite strong, in fact arises naturally in many circumstances—for example, players in the driving game reporting their spatial locations in absolute vs. relative coordinates, or speakers in a color reference game (Figure 6) discriminating based on lightness vs. hue.",6 Belief and behavior,[0],[0]
"It is also possible to relax the above condition to require that strategies be only locally disjoint (i.e. with the disjointness condition holding for each fixed xa), in which case overlapping human strategies are allowed, and the recovered robot strategy is a context-weighted mixture of these.",6 Belief and behavior,[0],[0]
"In the remainder of the paper, we evaluate the empirical behavior of our approach to translation.",7.1 Tasks,[0],[0]
Our evaluation considers two kinds of tasks: reference games and navigation games.,7.1 Tasks,[0],[0]
"In a reference game (e.g. Figure 6a), both players observe a pair of candidate referents.",7.1 Tasks,[0],[0]
"A speaker is assigned a target referent; it must communicate this target to a listener, who then performs a choice action corresponding to its belief about the true target.",7.1 Tasks,[0],[0]
"In this paper we consider two variants on the reference game: a simple color-naming task, and a more complex task involving natural images of birds.",7.1 Tasks,[0],[0]
"For examples of human communication strategies for these tasks, we obtain the XKCD color dataset (McMahan and Stone, 2015; Monroe et al., 2016) and the Caltech Birds dataset (Welinder et al., 2010) with accom-
panying natural language descriptions (Reed et al., 2016).",7.1 Tasks,[0],[0]
"We use standard train / validation / test splits for both of these datasets.
",7.1 Tasks,[0],[0]
The final task we consider is the driving task (Figure 6c) first discussed in the introduction.,7.1 Tasks,[0],[0]
"In this task, two cars, invisible to each other, must each navigate between randomly assigned start and goal positions without colliding.",7.1 Tasks,[0],[0]
"This task takes a number of steps to complete, and potentially involves a much broader range of communication strategies.",7.1 Tasks,[0],[0]
"To obtain human annotations for this task, we recorded both actions and messages generated by pairs of human Amazon Mechanical Turk workers playing the driving game with each other.",7.1 Tasks,[0],[0]
"We collected close to 400 games, with a total of more than 2000 messages exchanged, from which we held out 100 game traces as a test set.",7.1 Tasks,[0],[0]
"A mechanism for understanding the behavior of a learned model should allow a human user both to correctly infer its beliefs and to successfully interoperate with it; we accordingly report results of both “belief” and “behavior” evaluations.
",7.2 Metrics,[0],[0]
"To support easy reproduction and comparison (and in keeping with standard practice in machine
translation), we focus on developing automatic measures of system performance.",7.2 Metrics,[0],[0]
"We use the available training data to develop simulated models of human decisions; by first showing that these models track well with human judgments, we can be confident that their use in evaluations will correlate with human understanding.",7.2 Metrics,[0],[0]
"We employ the following two metrics:
Belief evaluation This evaluation focuses on the denotational perspective in semantics that motivated the initial development of our model.",7.2 Metrics,[0],[0]
We have successfully understood the semantics of a message,7.2 Metrics,[0],[0]
"zr if, after translating zr 7→ zh, a human listener can form a correct belief about the state in which zr was produced.",7.2 Metrics,[0],[0]
"We construct a simple state-guessing game where the listener is presented with a translated message and two state observations, and must guess which state the speaker was in when the message was emitted.
",7.2 Metrics,[0],[0]
"When translating from natural language to neuralese, we use the learned agent model to directly guess the hidden state.",7.2 Metrics,[0],[0]
"For neuralese to natural language we must first construct a “model human listener” to map from strings back to state representations; we do this by using the training data to fit a simple regression model that scores (state, sentence) pairs using a bag-of-words sentence representation.",7.2 Metrics,[0],[0]
"We find that our “model human” matches the judgments of real humans 83% of the time on the colors task, 77% of the time on the birds task, and 77% of the time on the driving task.",7.2 Metrics,[0],[0]
"This gives us confidence that the model human gives a reasonably accurate proxy for human interpretation.
",7.2 Metrics,[0],[0]
Behavior evaluation This evaluation focuses on the cooperative aspects of interpretability: we measure the extent to which learned models are able to interoperate with each other by way of a translation layer.,7.2 Metrics,[0],[0]
"In the case of reference games, the goal of this semantic evaluation is identical to the goal of the game itself (to identify the hidden state of the speaker), so we perform this additional pragmatic evaluation only for the driving game.",7.2 Metrics,[0],[0]
We found that the most data-efficient and reliable way to make use of human game traces was to construct a “deaf” model human.,7.2 Metrics,[0],[0]
"The evaluation selects a full game trace from a human player, and replays both the human’s actions and messages exactly (disregarding any incoming messages); the evaluation measures the quality of the natural-language-toneuralese translator, and the extent to which the
learned agent model can accommodate a (real) human given translations of the human’s messages.
",7.2 Metrics,[0],[0]
"Baselines We compare our approach to two baselines: a random baseline that chooses a translation of each input uniformly from messages observed during training, and a direct baseline that directly maximizes p(z′|z) (by analogy to a conventional machine translation system).",7.2 Metrics,[0],[0]
This is accomplished by sampling from a DCP speaker in training states labeled with natural language strings.,7.2 Metrics,[0],[0]
"In all below, “R” indicates a DCP agent, “H” indicates a real human, and “H*” indicates a model human player.
",8 Results,[0],[0]
Reference games Results for the two reference games are shown in Table 1.,8 Results,[0],[0]
"The end-to-end trained model achieves nearly perfect accuracy in both
cases, while a model trained to communicate in natural language achieves somewhat lower performance.",8 Results,[0],[0]
"Regardless of whether the speaker is a DCP and the listener a model human or vice-versa, translation based on the belief-matching criterion in Section 5 achieves the best performance; indeed, when translating neuralese color names to natural language, the listener is able to achieve a slightly higher score than it is natively.",8 Results,[0],[0]
"This suggests that the automated agent has discovered a more effective strategy than the one demonstrated by humans in the dataset, and that the effectiveness of this strategy is preserved by translation.",8 Results,[0],[0]
"Example translations from the reference games are depicted in Figure 2 and Figure 7.
",8 Results,[0],[0]
"Driving game Behavior evaluation of the driving game is shown in Table 3, and belief evaluation is shown in Table 2.",8 Results,[0],[0]
"Translation of messages in the driving game is considerably more challenging than in the reference games, and scores are uniformly lower; however, a clear benefit from the beliefmatching model is still visible.",8 Results,[0],[0]
"Belief matching leads to higher scores on the belief evaluation in both directions, and allows agents to obtain a higher reward on average (though task completion rates remain roughly the same across all agents).",8 Results,[0],[0]
Some example translations of driving game messages are shown in Figure 8.,8 Results,[0],[0]
We have investigated the problem of interpreting message vectors from deep networks by translating them.,9 Conclusion,[0],[0]
"After introducing a translation criterion based on matching listener beliefs about speaker states, we presented both theoretical and empirical evidence that this criterion outperforms a conventional machine translation approach at recovering the content of message vectors and facilitating collaboration between humans and learned agents.
",9 Conclusion,[0],[0]
"While our evaluation has focused on understanding the behavior of deep communicating policies, the framework proposed in this paper could be much more generally applied.",9 Conclusion,[0],[0]
"Any encoder– decoder model (Sutskever et al., 2014) can be thought of as a kind of communication game played between the encoder and the decoder, so we can analogously imagine computing and translating “beliefs” induced by the encoding to explain what features of the input are being transmitted.",9 Conclusion,[0],[0]
"The current work has focused on learning a purely categorical model of the translation process, supported by an unstructured inventory of translation candidates, and future work could explore the compositional structure of messages, and attempt to synthesize novel natural language or neuralese messages from scratch.",9 Conclusion,[0],[0]
"More broadly, the work here shows that the denotational perspective from formal semantics provides a framework for precisely framing the demands of interpretable machine learning (Wilson et al., 2016), and particularly for ensuring that human users without prior exposure to a learned model are able to interoperate with it, predict its behavior, and diagnose its errors.",9 Conclusion,[0],[0]
JA is supported by a Facebook Graduate Fellowship and a Berkeley AI / Huawei Fellowship.,Acknowledgments,[0],[0]
We are grateful to Lisa Anne Hendricks for assistance with the Caltech Birds dataset.,Acknowledgments,[0],[0]
Several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel.,abstractText,[0],[0]
"While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge.",abstractText,[0],[0]
Here we propose to interpret agents’ messages by translating them.,abstractText,[0],[0]
"Unlike in typical machine translation problems, we have no parallel data to learn from.",abstractText,[0],[0]
Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener.,abstractText,[0],[0]
We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmatics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language.1,abstractText,[0],[0]
Translating Neuralese,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 56–65 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
56",text,[0],[0]
"In recent years, Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2014) has achieved remarkable performance on many translation tasks (Jean et al., 2015; Sennrich et al., 2016; Wu et al., 2016; Sennrich et al., 2017).",1 Introduction,[0],[0]
"Being an end-to-end architecture, an NMT system first encodes the input sentence into a sequence of real vectors, based on which the decoder generates the target sequence word by word with the attention mechanism (Bahdanau et al., 2014; Luong et al., 2015).",1 Introduction,[0],[0]
"During training, NMT systems are optimized to maximize the translation probability of a given language pair
∗Contribution during internship at MSRA.
with the Maximum Likelihood Estimation (MLE) method, which requires large bilingual data to fit the large parameter space.",1 Introduction,[0],[0]
"Without adequate data, which is common especially when it comes to a rare language, NMT usually falls short on low-resource language pairs (Zoph et al., 2016).
",1 Introduction,[0],[0]
"In order to deal with the data sparsity problem for NMT, exploiting monolingual data (Sennrich et al., 2015; Zhang and Zong, 2016; Cheng et al., 2016; Zhang et al., 2018; He et al., 2016) is the most common method.",1 Introduction,[0],[0]
"With monolingual data, the back-translation method (Sennrich et al., 2015) generates pseudo bilingual sentences with a targetto-source translation model to train the source-totarget one.",1 Introduction,[0],[0]
"By extending back-translation, sourceto-target and target-to-source translation models can be jointly trained and boost each other (Cheng et al., 2016; Zhang et al., 2018).",1 Introduction,[0],[0]
"Similar to joint training (Cheng et al., 2016; Zhang et al., 2018), dual learning (He et al., 2016) designs a reinforcement learning framework to better capitalize on monolingual data and jointly train two models.
",1 Introduction,[0],[0]
"Instead of leveraging monolingual data (X or Z) to enrich the low-resource bilingual pair (X,Z), in this paper, we are motivated to introduce another rich language Y , by which additionally acquired bilingual data (Y,Z) and (X,Y ) can be exploited to improve the translation performance of (X,Z).",1 Introduction,[0],[0]
"This requirement is easy to satisfy, especially when Z is a rare language but X is not.",1 Introduction,[0],[0]
"Under this scenario, (X,Y ) can be a rich-resource pair and provide much bilingual data, while (Y,Z) would also be a low-resource pair mostly because Z is rare.",1 Introduction,[0],[0]
"For example, in the dataset IWSLT2012, there are only 112.6K bilingual sentence pairs of English-Hebrew, since Hebrew is a rare language.",1 Introduction,[0],[0]
"If French is introduced as the third language, we can have another lowresource bilingual data of French-Hebrew (116.3K sentence pairs), and easily-acquired bilingual data
of the rich-resource pair English-French.
",1 Introduction,[0],[0]
"With the introduced rich language Y , in this paper, we propose a novel triangular architecture (TA-NMT) to exploit the additional bilingual data of (Y, Z) and (X,Y ), in order to get better translation performance on the low-resource pair (X,Z), as shown in Figure 1.",1 Introduction,[0],[0]
"In this architecture, (Y,Z) is used for training another translation model to score the translation model of (X,Z), while (X,Y ) is used to provide large bilingual data with favorable alignment information.
",1 Introduction,[0],[0]
"Under the motivation to exploit the richresource pair (X,Y ), instead of modeling X ⇒ Z directly, our method starts from modeling the translation task X ⇒ Y while taking Z as a latent variable.",1 Introduction,[0],[0]
"Then, we decompose X ⇒ Y into two phases for training two translation models of low-resource pairs ((X,Z) and (Y,Z)) respectively.",1 Introduction,[0],[0]
"The first translation model generates a sequence in the hidden space of Z from X , based on which the second one generates the translation in Y .",1 Introduction,[0],[0]
These two models can be optimized jointly with an Expectation Maximization (EM) framework with the goal of maximizing the translation probability p(y|x).,1 Introduction,[0],[0]
"In this framework, the two models can boost each other by generating pseudo bilingual data for model training with the weights scored from the other.",1 Introduction,[0],[0]
"By reversing the translation direction of X ⇒ Y , our method can be used to train another two translation models p(z|y) and p(x|z).",1 Introduction,[0],[0]
"Therefore, the four translation models (p(z|x), p(x|z), p(z|y) and p(y|z)) of the rare language Z can be optimized jointly with our proposed unified bidirectional EM algorithm.
",1 Introduction,[0],[0]
Experimental results on the MultiUN and IWSLT2012 datasets demonstrate that our method can achieve significant improvements for rare languages translation.,1 Introduction,[0],[0]
"By incorporating backtranslation (a method leveraging more monolingual data) into our method, TA-NMT can achieve even further improvements.
",1 Introduction,[0],[0]
"Our contributions are listed as follows:
• We propose a novel triangular training architecture (TA-NMT) to effectively tackle the data sparsity problem for rare languages in NMT with an EM framework.
",1 Introduction,[0],[0]
"• Our method can exploit two additional bilingual datasets at both the model and data levels by introducing another rich language.
",1 Introduction,[0],[0]
"• Our method is a unified bidirectional EM algorithm, in which four translation models on two low-resource pairs are trained jointly and boost each other.",1 Introduction,[0],[0]
"As shown in Figure 1, our method tries to leverage (X,Y ) (a rich-resource pair) and (Y, Z) to improve the translation performance of low-resource pair (X,Z), during which translation models of (X,Z) and (Y, Z) can be improved jointly.
",2 Method,[0],[0]
"Instead of directly modeling the translation probabilities of low-resource pairs, we model the rich-resource pair translation X ⇒ Y , with the language Z acting as a bridge to connect X and Y .",2 Method,[0],[0]
We decompose X ⇒ Y into two phases for training two translation models.,2 Method,[0],[0]
"The first model p(z|x) generates the latent translation in Z from the input sentence in X , based on which the second one p(y|z) generate the final translation in language Y .",2 Method,[0],[0]
"Following the standard EM procedure (Borman, 2004) and Jensen’s inequality, we derive the lower bound of p(y|x) over the whole training data D as follows:
L(Θ;D) =",2 Method,[0],[0]
"∑
(x,y)∈D
log p(y|x)
= ∑
(x,y)∈D
log ∑ z p(z|x)p(y|z)
= ∑
(x,y)∈D
log ∑ z Q(z) p(z|x)p(y|z) Q(z)
≥ ∑
(x,y)∈D
∑ z Q(z) log p(z|x)p(y|z) Q(z)
.",2 Method,[0],[0]
"= L(Q)
(1)
where Θ is the model parameters set of p(z|x) and p(y|z), and Q(z) is an arbitrary posterior distribution of z.",2 Method,[0],[0]
"We denote the lower-bound in the last
but one line as L(Q).",2 Method,[0],[0]
"Note that we use an approximation that p(y|x, z)",2 Method,[0],[0]
"≈ p(y|z) due to the semantic equivalence of parallel sentences x and y.
In the following subsections, we will first propose our EM method in subsection 2.1 based on the lower-bound derived above.",2 Method,[0],[0]
"Next, we will extend our method to two directions and give our unified bidirectional EM training in subsection 2.2.",2 Method,[0],[0]
"Then, in subsection 2.3, we will discuss more training details of our method and present our algorithm in the form of pseudo codes.",2 Method,[0],[0]
"To maximize L(Θ;D), the EM algorithm can be leveraged to maximize its lower bound L(Q).",2.1 EM Training,[0],[0]
"In the E-step, we calculate the expectation of the variable z using current estimate for the model, namely find the posterior distribution Q(z).",2.1 EM Training,[0],[0]
"In the M-step, with the expectation Q(z), we maximize the lower bound L(Q).",2.1 EM Training,[0],[0]
"Note that conditioned on the observed data and current model, the calculation of Q(z) is intractable, so we choose Q(z) = p(z|x) approximately.
",2.1 EM Training,[0],[0]
"M-step: In the M-step, we maximize the lower bound L(Q) w.r.t model parameters given Q(z).",2.1 EM Training,[0],[0]
"By substituting Q(z) = p(z|x) into L(Q), we can get the M-step as follows:
Θy|z = arg max Θy|z
L(Q)
= arg max Θy|z ∑ (x,y)∈D ∑ z p(z|x) log p(y|z)
",2.1 EM Training,[0],[0]
"= arg max Θy|z ∑ (x,y)∈D Ez∼p(z|x) log p(y|z)
(2) E-step: The approximate choice of Q(z) brings in a gap between L(Q) and L(Θ;D), which can be minimized in the E-step with Generalized EM method (McLachlan and Krishnan, 2007).",2.1 EM Training,[0],[0]
"According to Bishop (2006), we can write this gap explicitly as follows:
L(Θ;D)− L(Q) = ∑ z Q(z) log Q(z) p(z|y)
= KL(Q(z)||p(z|y))",2.1 EM Training,[0],[0]
"= KL(p(z|x)||p(z|y))
(3)
where KL(·) is the KullbackLeibler divergence, and the approximation that p(z|x, y)",2.1 EM Training,[0],[0]
"≈ p(z|y) is also used above.
",2.1 EM Training,[0],[0]
"In the E-step, we minimize the gap between L(Q) and L(Θ;D) as follows:
Θz|x = arg min Θz|x KL(p(z|x)||p(z|y))",2.1 EM Training,[0],[0]
"(4)
To sum it up, the E-step optimizes the model p(z|x) by minimizing the gap between L(Q) and L(Θ;D) to get a better lower bound L(Q).",2.1 EM Training,[0],[0]
This lower bound is then maximized in the M-step to optimize the model p(y|z).,2.1 EM Training,[0],[0]
"Given the new model p(y|z), the E-step tries to optimize p(z|x) again to find a new lower bound, with which the M-step is re-performed.",2.1 EM Training,[0],[0]
"This iteration process continues until the models converge, which is guaranteed by the convergence of the EM algorithm.",2.1 EM Training,[0],[0]
"The model p(z|y) is used as an approximation of p(z|x, y) in the E-step optimization (Equation 3).",2.2 Unified Bidirectional Training,[0],[0]
"Due to the low resource property of the language pair (Y, Z), p(z|y) cannot be well trained.",2.2 Unified Bidirectional Training,[0],[0]
"To solve this problem, we can jointly optimize p(x|z) and p(z|y) similarly by maximizing the reverse translation probability p(x|y).
",2.2 Unified Bidirectional Training,[0],[0]
"We now give our unified bidirectional generalized EM procedures as follows:
• Direction of X ⇒ Y E: Optimize Θz|x.
arg min Θz|x
KL(p(z|x)||p(z|y))",2.2 Unified Bidirectional Training,[0],[0]
"(5)
M: Optimize Θy|z .
arg max Θy|z ∑ (x,y)∈D Ez∼p(z|x) log p(y|z) (6)
",2.2 Unified Bidirectional Training,[0],[0]
• Direction of Y ⇒,2.2 Unified Bidirectional Training,[0],[0]
X,2.2 Unified Bidirectional Training,[0],[0]
"E: Optimize Θz|y.
arg min Θz|y
KL(p(z|y)||p(z|x))",2.2 Unified Bidirectional Training,[0],[0]
"(7)
M: Optimize Θx|z .
",2.2 Unified Bidirectional Training,[0],[0]
"arg max Θx|z ∑ (x,y)∈D Ez∼p(z|y) log p(x|z)",2.2 Unified Bidirectional Training,[0],[0]
"(8)
Based on the above derivation, the whole architecture of our method can be illustrated in Figure 2, where the dash arrows denote the direction of p(y|x), in which p(z|x) and p(y|z) are trained jointly with the help of p(z|y), while the solid ones denote the direction of p(x|y), in which p(z|y) and p(x|z) are trained jointly with the help of p(z|x).",2.2 Unified Bidirectional Training,[0],[0]
"A major difficulty in our unified bidirectional training is the exponential search space of the translation candidates, which could be addressed by either sampling (Shen et al., 2015; Cheng et al., 2016) or mode approximation (Kim and Rush, 2016).",2.3 Training Details,[0],[0]
"In our experiments, we leverage the sampling method and simply generate the top target sentence for approximation.
",2.3 Training Details,[0],[0]
"In order to perform gradient descend training, the parameter gradients for Equations 5 and 7 are formulated as follows:
∇Θz|xKL(p(z|x)||p(z|y))
",2.3 Training Details,[0],[0]
= Ez∼p(z|x) log p(z|x) p(z|y),2.3 Training Details,[0],[0]
"∇Θz|x log p(z|x)
∇Θz|yKL(p(z|y)||p(z|x))
",2.3 Training Details,[0],[0]
"= Ez∼p(z|y) log p(z|y) p(z|x) ∇Θz|y log p(z|y)
(9)
Similar to reinforcement learning, models p(z|x) and p(z|y) are trained using samples generated by the models themselves.",2.3 Training Details,[0],[0]
"According to our observation, some samples are noisy and detrimental to the training process.",2.3 Training Details,[0],[0]
"One way to tackle this is to filter out the bad ones using some additional metrics (BLEU, etc.).",2.3 Training Details,[0],[0]
"Nevertheless, in our settings, BLEU scores cannot be calculated during training due to the absence of the golden targets (z is generated based on x or y from the richresource pair (x, y)).",2.3 Training Details,[0],[0]
"Therefore we choose IBM model1 scores to weight the generated translation candidates, with the word translation probabilities calculated based on the given bilingual data (the low-resource pair (x, z) or (y, z)).",2.3 Training Details,[0],[0]
"Additionally, to stabilize the training process, the pseudo samples generated by model p(z|x) or p(z|y) are mixed with true bilingual samples in the same mini-batch with the ratio of 1-1.",2.3 Training Details,[0],[0]
"The whole training procedure is described in the following Algorithm 1, where the 5th and 9th steps are generating pseudo data.
",2.3 Training Details,[0],[0]
Algorithm 1 Training low-resource translation models with the triangular architecture,2.3 Training Details,[0],[0]
"Input: Rich-resource bilingual data (x, y); low-
resource bilingual data (x, z) and (y, z) Output:",2.3 Training Details,[0],[0]
"Parameters Θz|x, Θy|z , Θz|y and Θx|z
1: Pre-train p(z|x), p(z|y), p(x|z), p(y|z) 2: while not convergence do 3: Sample (x, y), (x∗, z∗), (y∗, z∗) ∈ D 4: .",2.3 Training Details,[0],[0]
"X ⇒ Y : Optimize Θz|x and Θy|z 5: Generate z′ from p(z′|x) and build the
training batches B1 = (x, z′)∪(x∗, z∗), B2 = (y, z′) ∪ (y∗, z∗) 6: E-step: update Θz|x with B1 (Equation 5) 7: M-step: update Θy|z with B2 (Equation 6) 8: .",2.3 Training Details,[0],[0]
"Y ⇒ X: Optimize Θz|y and Θx|z 9: Generate z′ from p(z′|y) and build the
training batches B3 = (y, z′)∪(y∗, z∗), B4 = (x, z′) ∪ (x∗, z∗) 10:",2.3 Training Details,[0],[0]
"E-step: update Θz|y with B3 (Equation 7) 11: M-step: update Θx|z with B4 (Equation 8) 12: end while 13: return Θz|x, Θy|z , Θz|y and Θx|z",2.3 Training Details,[0],[0]
"In order to verify our method, we conduct experiments on two multilingual datasets.",3.1 Datasets,[0],[0]
"The one is MultiUN (Eisele and Chen, 2010), which is a collection of translated documents from the United Nations, and the other is IWSLT2012 (Cettolo et al., 2012), which is a set of multilingual transcriptions of TED talks.",3.1 Datasets,[0],[0]
"As is mentioned in section 1, our method is compatible with methods exploiting monolingual data.",3.1 Datasets,[0],[0]
"So we also find some extra monolingual data of rare languages in both datasets and conduct experiments incorporating back-translation into our method.
",3.1 Datasets,[0],[0]
"MultiUN: English-French (EN-FR) bilingual data are used as the rich-resource pair (X,Y ).",3.1 Datasets,[0],[0]
"Arabic (AR) and Spanish (ES) are used as two simulated rare languages Z. We randomly choose subsets of bilingual data of (X,Z) and (Y, Z) in the original dataset to simulate low-resource situations, and make sure there is no overlap in Z between chosen data of (X,Z) and (Y,Z).
",3.1 Datasets,[0],[0]
"IWSLT20121: English-French is used as the rich-resource pair (X,Y ), and two rare languages Z are Hebrew (HE) and Romanian (RO) in our
1https://wit3.fbk.eu/mt.php?release=2012-02-plain
choice.",3.1 Datasets,[0],[0]
"Note that in this dataset, low-resource pairs (X,Z) and (Y,Z) are severely overlapped in Z.",3.1 Datasets,[0],[0]
"In addition, English-French bilingual data from WMT2014 dataset are also used to enrich the rich-resource pair.",3.1 Datasets,[0],[0]
"We also use additional EnglishRomanian bilingual data from Europarlv7 dataset (Koehn, 2005).",3.1 Datasets,[0],[0]
"The monolingual data of Z (HE and RO) are taken from the web2.
",3.1 Datasets,[0],[0]
"In both datasets, all sentences are filtered within the length of 5 to 50 after tokenization.",3.1 Datasets,[0],[0]
"Both the validation and the test sets are 2,000 parallel sentences sampled from the bilingual data, with the left as training data.",3.1 Datasets,[0],[0]
The size of training data of all language pairs are shown in Table 1.,3.1 Datasets,[0],[0]
We compare our method with four baseline systems.,3.2 Baselines,[0],[0]
"The first baseline is the RNNSearch model (Bahdanau et al., 2014), which is a sequence-tosequence model with attention mechanism trained with given small-scale bilingual data.",3.2 Baselines,[0],[0]
"The trained translation models are also used as pre-trained models for our subsequent training processes.
",3.2 Baselines,[0],[0]
"The second baseline is PBSMT (Koehn et al., 2003), which is a phrase-based statistical machine translation system.",3.2 Baselines,[0],[0]
"PBSMT is known to perform well on low-resource language pairs, so we want to compare it with our proposed method.",3.2 Baselines,[0],[0]
And we use the public available implementation of Moses5 for training and test in our experiments.,3.2 Baselines,[0],[0]
"The third baseline is a teacher-student alike method (Chen et al., 2017).",3.2 Baselines,[0],[0]
"For the sake of brevity, we will denote it as T-S. The process is illustrated in Figure 3.",3.2 Baselines,[0],[0]
"We treat this method as a second baseline because it can also be regarded as a method exploiting (Y, Z) and (X,Y ) to improve
2https://github.com/ajinkyakulkarni14/TEDMultilingual-Parallel-Corpus
3together with WMT2014 4together with Europarlv7 5http://www.statmt.org/moses/
the translation of (X,Z) if we regard (X,Z) as the zero-resource pair and p(x|y) as the teacher model when training p(z|x) and p(x|z).
",3.2 Baselines,[0],[0]
"The fourth baseline is back-translation (Sennrich et al., 2015).",3.2 Baselines,[0],[0]
We will denote it as BackTrans.,3.2 Baselines,[0],[0]
"More concretely, to train the model p(z|x), we use extra monolingual Z described in Table 1 to do back-translation; to train the model p(x|z), we use monolingual X taken from (X,Y ).",3.2 Baselines,[0],[0]
Procedures for training p(z|y) and p(y|z) are similar.,3.2 Baselines,[0],[0]
This method use extra monolingual data of Z compared with our TA-NMT method.,3.2 Baselines,[0],[0]
But we can incorporate it into our method.,3.2 Baselines,[0],[0]
"Experimental results on both datasets are shown in Table 3 and 4 respectively, in which RNNSearch, PBSMT, T-S and BackTrans are four baselines.",3.3 Overall Results,[0],[0]
"TA-NMT is our proposed method, and TA-NMT(GI) is our method incorporating backtranslation as good initialization.",3.3 Overall Results,[0],[0]
"For the purpose of clarity and a fair comparison, we list the resources that different methods exploit in Table 2.
",3.3 Overall Results,[0],[0]
"From Table 3 on MultiUN, the performance of RNNSearch is relatively poor.",3.3 Overall Results,[0],[0]
"As is expected, PBSMT performs better than RNNSearch on lowresource pairs by the average of 1.78 BLEU.",3.3 Overall Results,[0],[0]
"The T-S method which can doubling the training data
for both (X,Z) and (Y, Z) by generating pseudo data from each other, leads up to 1.1 BLEU points improvement on average over RNNSearch.",3.3 Overall Results,[0],[0]
"Compared with T-S, our method gains a further improvement of about 0.9 BLEU on average, because our method can better leverage the rich-resource pair (X,Y ).",3.3 Overall Results,[0],[0]
"With extra large monolingual Z introduced, BackTrans can improve the performance of p(z|x) and p(z|y) significantly compared with all the methods without monolingual Z. However TA-NMT is comparable with or even better than BackTrans for p(x|z) and p(y|z) because both of the methods leverage resources from richresource pair (X,Y ), but BackTrans does not use the alignment information it provides.",3.3 Overall Results,[0],[0]
"Moreover, with back-translation as good initialization, further improvement is achieved by TA-NMT(GI) of about 0.7 BLEU on average over BackTrans.
",3.3 Overall Results,[0],[0]
"In Table 4, we can draw the similar conclusion.",3.3 Overall Results,[0],[0]
"However, different from MultiUN, in the EN-FR-HE group of IWSLT, (X,Z) and (Y,Z) are severely overlapped in Z. Therefore, T-S cannot improve the performance obviously (only about 0.2 BLEU) on RNNSearch because it fails to essentially double training data via the teacher model.",3.3 Overall Results,[0],[0]
"As for EN-FR-RO, with the additionally introduced EN-RO data from Europarlv7, which has no overlap in RO with FR-RO, T-S can improve the average performance more than the ENFR-HE group.",3.3 Overall Results,[0],[0]
TA-NMT outperforms T-S by 0.93 BLEU on average.,3.3 Overall Results,[0],[0]
"Note that even though Back-
Trans uses extra monolingual Z, the improvements are not so obvious as the former dataset, the reason for which we will delve into in the next subsection.",3.3 Overall Results,[0],[0]
"Again, with back-translation as good initialization, TA-NMT(GI) can get the best result.
",3.3 Overall Results,[0],[0]
Note that BLEU scores of TA-NMT are lower than BackTrans in the directions of X⇒Z and Y⇒Z.,3.3 Overall Results,[0],[0]
"The reason is that the resources used by these two methods are different, as shown in Table 2.",3.3 Overall Results,[0],[0]
"To do back translation in two directions (e.g., X⇒Z and Z⇒X), we need monolingual data from both sides (e.g., X and Z), however, in TA-NMT, the monolingual data of Z is not necessary.",3.3 Overall Results,[0],[0]
"Therefore, in the translation of X⇒Z or Y⇒Z, BackTrans uses additional monolingual data of Z while TA-NMT does not, that is why BackTrans outperforms TA-NMT in these directions.",3.3 Overall Results,[0],[0]
"Our method can leverage back translation as a good initialization, aka TA-NMT(GI) , and outperforms BackTrans on all translation directions.
",3.3 Overall Results,[0],[0]
"The average test BLEU scores of different methods in each data group (EN-FR-AR, EN-FRES, EN-FR-HE, and EN-FR-RO) are listed in the column Ave of the tables for clear comparison.",3.3 Overall Results,[0],[0]
"Comparing the results of BackTrans and TANMT(GI) on both datasets, we notice the improvements of both methods on IWSLT are not as significant as MultiUN.",3.4 The Effect of Extra Monolingual Data,[0],[0]
"We speculate the reason is the relatively less amount of monolingual Z we use in
the experiments on IWSLT as shown in Table 1.",3.4 The Effect of Extra Monolingual Data,[0],[0]
"So we conduct the following experiment to verify the conjecture by changing the scale of monolingual Arabic data in the MultiUN dataset, of which the data utilization rates are set to 0%, 10%, 30%, 60% and 100% respectively.",3.4 The Effect of Extra Monolingual Data,[0],[0]
Then we compare the performance of BackTrans and TA-NMT(GI) in the EN-FR-AR group.,3.4 The Effect of Extra Monolingual Data,[0],[0]
"As Figure 4 shows, the amount of monolingual Z actually has a big effect on the results, which can also verify our conjecture above upon the less significant improvement of BackTrans and TA-NMT(GI) on IWSLT.",3.4 The Effect of Extra Monolingual Data,[0],[0]
"In addition, even with poor ”good-initialization”, TANMT(GI) still get the best results.",3.4 The Effect of Extra Monolingual Data,[0],[0]
"To better illustrate the behavior of our method, we print the training curves in both the M-steps and Esteps of TA-NMT and TA-NMT(GI) in Figure 5 above.",3.5 EM Training Curves,[0],[0]
"The chosen models printed in this figure are EN2AR and AR2FR on MultiUN, and EN2RO and RO2FR on IWLST.
",3.5 EM Training Curves,[0],[0]
"From Figure 5, we can see that the two lowresource translation models are improved nearly simultaneously along with the training process, which verifies our point that two weak models could boost each other in our EM framework.",3.5 EM Training Curves,[0],[0]
"Notice that at the early stage, the performance of all models stagnates for several iterations, especially of TA-NMT.",3.5 EM Training Curves,[0],[0]
"The reason could be that the pseudo bilingual data and the true training data are heterogeneous, and it may take some time for the models to adapt to a new distribution which both models agree.",3.5 EM Training Curves,[0],[0]
"Compared with TA-NMT, TA-NMT(GI) are more stable, because the models may have
adapted to a mixed distribution of heterogeneous data in the preceding back-translation phase.",3.5 EM Training Curves,[0],[0]
"As shown in Equation 9, the E-step actually works as a reinforcement learning (RL) mechanism.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
Models p(z|x) and p(z|y) generate samples by themselves and receive rewards to update their parameters.,3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"Note that the reward here is described by the log terms in Equation 9, which is derived from our EM algorithm rather than defined artificially.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"In Table 5, we do a case study of the EN2ES translation sampled by p(z|x) as well as its time-step rewards during the E-step.
",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"In the first case, the best translation of ”political” is ”polı́ticos”.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"When the model p(z|x) generates an inaccurate one ”polı́ticas”, it receives a negative reward (-0.01), with which the model parameters will be updated accordingly.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"In the sec-
ond case, the output misses important words and is not fluent.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"Rewards received by the model p(z|x) are zero for nearly all tokens in the output, leading to an invalid updating.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"In the last case, the output sentence is identical to the human reference.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"The rewards received are nearly all positive and meaningful, thus the RL rule will update the parameters to encourage this translation candidate.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"NMT systems, relying heavily on the availability of large bilingual data, result in poor translation quality for low-resource pairs (Zoph et al., 2016).",4 Related Work,[0],[0]
This low-resource phenomenon has been observed in much preceding work.,4 Related Work,[0],[0]
"A very common approach is exploiting monolingual data of both source and target languages (Sennrich et al., 2015; Zhang and Zong, 2016; Cheng et al., 2016; Zhang et al., 2018; He et al., 2016).
",4 Related Work,[0],[0]
"As a kind of data augmentation technique, exploiting monolingual data can enrich the training data for low-resource pairs.",4 Related Work,[0],[0]
"Sennrich et al. (2015) propose back-translation, exploits the monolingual data of the target side, which is then used to generate pseudo bilingual data via an additional target-to-source translation model.",4 Related Work,[0],[0]
"Different from back-translation, Zhang and Zong (2016) propose two approaches to use source-side monolingual data, of which the first is employing a self-learning algorithm to generate pseudo data, while the second is using two NMT models to predict the translation and to reorder the source-side monolingual
sentences.",4 Related Work,[0],[0]
"As an extension to these two methods, Cheng et al. (2016) and Zhang et al. (2018) combine two translation directions and propose a training framework to jointly optimize the sourceto-target and target-to-source translation models.",4 Related Work,[0],[0]
"Similar to joint training, He et al. (2016) propose a dual learning framework with a reinforcement learning mechanism to better leverage monolingual data and make two translation models promote each other.",4 Related Work,[0],[0]
"All of these methods are concentrated on exploiting either the monolingual data of the source and target language or both of them.
",4 Related Work,[0],[0]
"Our method takes a different angle but is compatible with existing approaches, we propose a novel triangular architecture to leverage two additional language pairs by introducing a third rich language.",4 Related Work,[0],[0]
"By combining our method with existing approaches such as back-translation, we can make a further improvement.
",4 Related Work,[0],[0]
"Another approach for tackling the low-resource translation problem is multilingual neural machine translation (Firat et al., 2016), where different encoders and decoders for all languages with a shared attention mechanism are trained.",4 Related Work,[0],[0]
This method tends to exploit the network architecture to relate low-resource pairs.,4 Related Work,[0],[0]
"Our method is different from it, which is more like a training method rather than network modification.",4 Related Work,[0],[0]
"In this paper, we propose a triangular architecture (TA-NMT) to effectively tackle the problem
of low-resource pairs translation with a unified bidirectional EM framework.",5 Conclusion,[0],[0]
"By introducing another rich language, our method can better exploit the additional language pairs to enrich the original low-resource pair.",5 Conclusion,[0],[0]
"Compared with the RNNSearch (Bahdanau et al., 2014), a teacherstudent alike method (Chen et al., 2017) and the back-translation (Sennrich et al., 2015) on the same data level, our method achieves significant improvement on the MutiUN and IWSLT2012 datasets.",5 Conclusion,[0],[0]
"Note that our method can be combined with methods exploiting monolingual data for NMT low-resource problem such as backtranslation and make further improvements.
",5 Conclusion,[0],[0]
"In the future, we may extend our architecture to other scenarios, such as totally unsupervised training with no bilingual data for the rare language.",5 Conclusion,[0],[0]
We thank Zhirui Zhang and Shuangzhi Wu for useful discussions.,Acknowledgments,[0],[0]
"This work is supported in part by NSFC U1636210, 973 Program 2014CB340300, and NSFC 61421003.",Acknowledgments,[0],[0]
"Neural Machine Translation (NMT) performs poor on the low-resource language pair (X,Z), especially when Z is a rare language.",abstractText,[0],[0]
"By introducing another rich language Y , we propose a novel triangular training architecture (TA-NMT) to leverage bilingual data (Y,Z) (may be small) and (X,Y ) (can be rich) to improve the translation performance of lowresource pairs.",abstractText,[0],[0]
"In this triangular architecture, Z is taken as the intermediate latent variable, and translation models of Z are jointly optimized with a unified bidirectional EM algorithm under the goal of maximizing the translation likelihood of (X,Y ).",abstractText,[0],[0]
"Empirical results demonstrate that our method significantly improves the translation quality of rare languages on MultiUN and IWSLT2012 datasets, and achieves even better performance combining back-translation methods.",abstractText,[0],[0]
Triangular Architecture for Rare Language Translation,title,[0],[0]
"Deep neural networks have recently received much limelight for their enormous success in a variety of applications across many different areas of artificial intelligence, computer vision, speech recognition, and natural language processing (LeCun et al., 2015; Hinton et al., 2012; Krizhevsky et al., 2012; Bahdanau et al., 2014; Kalchbrenner & Blunsom, 2013).",1. Introduction,[0],[0]
"Nevertheless, it is also well-known that our theoretical understanding of their efficacy remains incomplete.
",1. Introduction,[0],[0]
There have been several attempts to analyze deep neural networks from different perspectives.,1. Introduction,[0],[0]
"Notably, earlier studies have suggested that a deep architecture could use parameters more efficiently and requires exponentially fewer parameters to express certain families of functions than a shallow architecture (Delalleau & Bengio, 2011; Bengio & Delal-
1Department of Computer Science, University of Chicago, Chicago, IL 2Department of Statistics, University of Chicago, Chicago, IL 3Computational and Applied Mathematics Initiative, University of Chicago, Chicago, IL.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Lek-Heng Lim <lekheng@galton.uchicago.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"leau, 2011; Montufar et al., 2014; Eldan & Shamir, 2016; Poole et al., 2016; Arora et al., 2018).",1. Introduction,[0],[0]
"Recent work (Zhang et al., 2016) showed that several successful neural networks possess a high representation power and can easily shatter random data.",1. Introduction,[0],[0]
"However, they also generalize well to data unseen during training stage, suggesting that such networks may have some implicit regularization.",1. Introduction,[0],[0]
Traditional measures of complexity such as VC-dimension and Rademacher complexity fail to explain this phenomenon.,1. Introduction,[0],[0]
"Understanding this implicit regularization that begets the generalization power of deep neural networks remains a challenge.
",1. Introduction,[0],[0]
The goal of our work is to establish connections between neural network and tropical geometry in the hope that they will shed light on the workings of deep neural networks.,1. Introduction,[0],[0]
Tropical geometry is a new area in algebraic geometry that has seen an explosive growth in the recent decade but remains relatively obscure outside pure mathematics.,1. Introduction,[0],[0]
"We will focus on feedforward neural networks with rectified linear units (ReLU) and show that they are analogues of rational functions, i.e., ratios of two multivariate polynomials f, g in variables x1, . . .",1. Introduction,[0],[0]
", xd,
fpx1, . . .",1. Introduction,[0],[0]
", xdq gpx1, . . .",1. Introduction,[0],[0]
", xdq ,
in tropical algebra.",1. Introduction,[0],[0]
"For standard and trigonometric polynomials, it is known that rational approximation — approximating a target function by a ratio of two polynomials instead of a single polynomial — vastly improves the quality of approximation without increasing the degree.",1. Introduction,[0],[0]
"This gives our analogue: An ReLU neural network is the tropical ratio of two tropical polynomials, i.e., a tropical rational function.",1. Introduction,[0],[0]
"More precisely, if we view a neural network as a function ν :",1. Introduction,[0],[0]
"Rd Ñ Rp, x “ px1, . . .",1. Introduction,[0],[0]
", xdq ÞÑ pν1pxq, . . .",1. Introduction,[0],[0]
", νppxqq, then each ν is a tropical rational map, i.e., each νi is a tropical rational function.",1. Introduction,[0],[0]
"In fact, we will show that:
the family of functions represented by feedforward neural networks with rectified linear units and integer weights is exactly the family of tropical rational maps.
",1. Introduction,[0],[0]
It immediately follows that there is a semifield structure on this family of functions.,1. Introduction,[0],[0]
"More importantly, this establishes a
ar X
iv :1
80 5.
07 09
1v 1
[ cs
.L G
] 1
8 M
ay 2
01 8
bridge between neural networks1 and tropical geometry that allows us to view neural networks as well-studied tropical geometric objects.",1. Introduction,[0],[0]
This insight allows us to closely relate boundaries between linear regions of a neural network to tropical hypersurfaces and thereby facilitate studies of decision boundaries of neural networks in classification problems as tropical hypersurfaces.,1. Introduction,[0],[0]
"Furthermore, the number of linear regions, which captures the complexity of a neural network (Montufar et al., 2014; Raghu et al., 2017; Arora et al., 2018), can be bounded by the number of vertices of the polytopes associated with the neural network’s tropical rational representation.",1. Introduction,[0],[0]
"Lastly, a neural network with one hidden layer can be completely characterized by zonotopes, which serve as building blocks for deeper networks.
",1. Introduction,[0],[0]
In Sections 2 and 3 we introduce basic tropical algebra and tropical algebraic geometry of relevance to us.,1. Introduction,[0],[0]
We state our assumptions precisely in Section 4 and establish the connection between tropical geometry and multilayer neural networks in Section 5.,1. Introduction,[0],[0]
"We analyze neural networks with tropical tools in Section 6, proving that a deeper neural network is exponentially more expressive than a shallow network — though our objective is not so much to perform state-of-the-art analysis but to demonstrate that tropical algebraic geometry can provide useful insights.",1. Introduction,[0],[0]
All proofs are deferred to Section D of the supplement.,1. Introduction,[0],[0]
"Roughly speaking, tropical algebraic geometry is an analogue of classical algebraic geometry over C, the field of complex numbers, but where one replaces C by a semifield2 called the tropical semiring, to be defined below.",2. Tropical algebra,[0],[0]
We give a brief review of tropical algebra and introduce some relevant notations.,2. Tropical algebra,[0],[0]
"See (Itenberg et al., 2009; Maclagan & Sturmfels, 2015) for an in-depth treatment.
",2. Tropical algebra,[0],[0]
"The most fundamental component of tropical algebraic geometry is the tropical semiring T :“ ` R Y t´8u,‘,d ˘
.",2. Tropical algebra,[0],[0]
"The two operations ‘ and d, called tropical addition and tropical multiplication respectively, are defined as follows.
",2. Tropical algebra,[0],[0]
Definition 2.1.,2. Tropical algebra,[0],[0]
"For x, y P R, their tropical sum is x‘ y :“ maxtx, yu; their tropical product is x",2. Tropical algebra,[0],[0]
d y :“ x ` y; the tropical quotient of x over y is xm y,2. Tropical algebra,[0],[0]
":“ x´ y.
For any x P R, we have ´8 ‘ x “ 0 d x “ x and ´8d x “ ´8.",2. Tropical algebra,[0],[0]
Thus ´8 is the tropical additive identity and 0 is the tropical multiplicative identity.,2. Tropical algebra,[0],[0]
"Furthermore, these operations satisfy the usual laws of arithmetic: associativity, commutativity, and distributivity.",2. Tropical algebra,[0],[0]
The set RY t´8u is therefore a semiring under the operations‘ andd.,2. Tropical algebra,[0],[0]
"While it is not a ring (lacks additive inverse), one may nonetheless
1Henceforth a “neural network” will always mean a feedforward neural network with ReLU activation.
",2. Tropical algebra,[0],[0]
"2A semifield is a field sans the existence of additive inverses.
",2. Tropical algebra,[0],[0]
"generalize many algebraic objects (e.g., matrices, polynomials, tensors, etc) and notions (e.g., rank, determinant, degree, etc) over the tropical semiring — the study of these, in a nutshell, constitutes the subject of tropical algebra.
",2. Tropical algebra,[0],[0]
Let N “ tn P Z : n ě 0u.,2. Tropical algebra,[0],[0]
"For an integer a P N, raising x P R to the ath power is the same as multiplying x to itself a times.",2. Tropical algebra,[0],[0]
"When standard multiplication is replaced by tropical multiplication, this gives us tropical power:
xda",2. Tropical algebra,[0],[0]
":“ xd ¨ ¨ ¨ d x “ a ¨ x,
where the last ¨ denotes standard product of real numbers; it is extended to RY t´8u by defining, for any a P N,
´8da :“ #
´8 if a ą 0, 0",2. Tropical algebra,[0],[0]
"if a “ 0.
A tropical semiring, while not a field, possesses one quality of a field: Every x P R has a tropical multiplicative inverse given by its standard additive inverse, i.e., xdp´1q :“ ´x. Though not reflected in its name, T is in fact a semifield.
",2. Tropical algebra,[0],[0]
"One may therefore also raise x P R to a negative power a P Z by raising its tropical multiplicative inverse ´x to the positive power ´a, i.e., xda “ p´xqdp´aq.",2. Tropical algebra,[0],[0]
"As is the case in standard real arithmetic, the tropical additive inverse ´8 does not have a tropical multiplicative inverse and ´8da is undefined for a ă 0.",2. Tropical algebra,[0],[0]
"For notational simplicity, we will henceforth write xa instead of xda for tropical power when there is no cause for confusion.",2. Tropical algebra,[0],[0]
"Other algebraic rules of tropical power may be derived from definition; see Section B in the supplement.
",2. Tropical algebra,[0],[0]
We are now in a position to define tropical polynomials and tropical rational functions.,2. Tropical algebra,[0],[0]
"In the following, x and xi will denote variables (i.e., indeterminates).
",2. Tropical algebra,[0],[0]
Definition 2.2.,2. Tropical algebra,[0],[0]
"A tropical monomial in d variables x1, . . .",2. Tropical algebra,[0],[0]
", xd is an expression of the form
cd xa11 d x a2 2 d ¨ ¨ ¨ d x ad d
where c P R Y t´8u and a1, . . .",2. Tropical algebra,[0],[0]
", ad P N.",2. Tropical algebra,[0],[0]
"As a convenient shorthand, we will also write a tropical monomial in multiindex notation as cxα where α “ pa1, . .",2. Tropical algebra,[0],[0]
.,2. Tropical algebra,[0],[0]
", adq P Nd and x “ px1, . . .",2. Tropical algebra,[0],[0]
", xdq.",2. Tropical algebra,[0],[0]
"Note that xα “ 0 d xα as 0 is the tropical multiplicative identity.
",2. Tropical algebra,[0],[0]
Definition 2.3.,2. Tropical algebra,[0],[0]
"Following notations above, a tropical polynomial fpxq “ fpx1, . . .",2. Tropical algebra,[0],[0]
", xdq is a finite tropical sum of tropical monomials
fpxq “ c1xα1 ‘",2. Tropical algebra,[0],[0]
"¨ ¨ ¨ ‘ crxαr ,
where αi “ pai1, . . .",2. Tropical algebra,[0],[0]
", aidq P Nd and ci P R Y t´8u, i “ 1, . . .",2. Tropical algebra,[0],[0]
", r. We will assume that a monomial of a given multiindex appears at most once in the sum, i.e., αi ‰ αj for any i ‰ j.
Definition 2.4.",2. Tropical algebra,[0],[0]
"Following notations above, a tropical rational function is a standard difference, or, equivalently, a tropical quotient of two tropical polynomials fpxq and gpxq: fpxq ´ gpxq “ fpxq m gpxq.",2. Tropical algebra,[0],[0]
"We will denote a tropical rational function by f m g, where f and g are understood to be tropical polynomial functions.
",2. Tropical algebra,[0],[0]
"It is routine to verify that the set of tropical polynomials Trx1, . . .",2. Tropical algebra,[0],[0]
", xds forms a semiring under the standard extension of ‘ and d to tropical polynomials, and likewise the set of tropical rational functions Tpx1, . . .",2. Tropical algebra,[0],[0]
", xdq forms a semifield.",2. Tropical algebra,[0],[0]
"We regard a tropical polynomial f “ f m 0 as a special case of a tropical rational function and thus Trx1, . . .",2. Tropical algebra,[0],[0]
", xds Ď Tpx1, . . .",2. Tropical algebra,[0],[0]
", xdq.",2. Tropical algebra,[0],[0]
"Henceforth any result stated for a tropical rational function would implicitly also hold for a tropical polynomial.
",2. Tropical algebra,[0],[0]
A d-variate tropical polynomial fpxq defines a function f :,2. Tropical algebra,[0],[0]
"Rd Ñ R that is a convex function in the usual sense as taking max and sum of convex functions preserve convexity (Boyd & Vandenberghe, 2004).",2. Tropical algebra,[0],[0]
"As such, a tropical rational function f m g : Rd Ñ R is a DC function or differenceconvex function (Hartman, 1959; Tao & Hoai An, 2005).
",2. Tropical algebra,[0],[0]
We will need a notion of vector-valued tropical polynomials and tropical rational functions.,2. Tropical algebra,[0],[0]
Definition 2.5.,2. Tropical algebra,[0],[0]
F :,2. Tropical algebra,[0],[0]
"Rd Ñ Rp, x “ px1, . . .",2. Tropical algebra,[0],[0]
", xdq ÞÑ pf1pxq, . . .",2. Tropical algebra,[0],[0]
", fppxqq, is called a tropical polynomial map if each fi :",2. Tropical algebra,[0],[0]
"Rd Ñ R is a tropical polynomial, i “ 1, . . .",2. Tropical algebra,[0],[0]
", p, and a tropical rational map if f1, . . .",2. Tropical algebra,[0],[0]
", fp are tropical rational functions.",2. Tropical algebra,[0],[0]
"We will denote the set of tropical polynomial maps by Polpd, pq and the set of tropical rational maps by Ratpd, pq.",2. Tropical algebra,[0],[0]
"So Polpd, 1q “ Trx1, . . .",2. Tropical algebra,[0],[0]
", xds and Ratpd, 1q “ Tpx1, . . .",2. Tropical algebra,[0],[0]
", xdq.",2. Tropical algebra,[0],[0]
"There are tropical analogues of many notions in classical algebraic geometry (Itenberg et al., 2009; Maclagan & Sturmfels, 2015), among which are tropical hypersurfaces, tropical analogues of algebraic curves in classical algebraic geometry.",3. Tropical hypersurfaces,[0],[0]
Tropical hypersurfaces are a principal object of interest in tropical geometry and will prove very useful in our approach towards neural networks.,3. Tropical hypersurfaces,[0],[0]
"Intuitively, the tropical hypersurface of a tropical polynomial f is the set of points x where f is not linear at x. Definition 3.1.",3. Tropical hypersurfaces,[0],[0]
"The tropical hypersurface of a tropical polynomial fpxq “ c1xα1 ‘ ¨ ¨ ¨ ‘ crxαr is
T pfq :“ x P Rd : cixαi “ cjxαj “ fpxq for some αi ‰ αj ( .
i.e., the set of points x at which the value of f at x is attained by two or more monomials in f .
",3. Tropical hypersurfaces,[0],[0]
A tropical hypersurface divides the domain of f into convex cells on each of which f is linear.,3. Tropical hypersurfaces,[0],[0]
"These cells are convex polyhedrons, i.e., defined by linear inequalities with integer coefficients: tx P Rd :",3. Tropical hypersurfaces,[0],[0]
Ax ď bu for A P Zmˆd and b P Rm.,3. Tropical hypersurfaces,[0],[0]
"For example, the cell where a tropical monomial cjx
αj attains its maximum is tx P Rd : cj ` αTjx ě ci ` αTix for all i ‰ ju.",3. Tropical hypersurfaces,[0],[0]
"Tropical hypersurfaces of polynomials in two variables (i.e., in R2) are called tropical curves.
",3. Tropical hypersurfaces,[0],[0]
"Just like standard multivariate polynomials, every tropical polynomial comes with an associated Newton polygon.
",3. Tropical hypersurfaces,[0],[0]
Definition 3.2.,3. Tropical hypersurfaces,[0],[0]
"The Newton polygon of a tropical polynomial fpxq “ c1xα1 ‘ ¨ ¨ ¨ ‘ crxαr is the convex hull of α1, . . .",3. Tropical hypersurfaces,[0],[0]
", αr P Nd, regarded as points in Rd,
∆pfq :“ Conv αi P Rd : ci ‰ ´8, i “ 1, . . .",3. Tropical hypersurfaces,[0],[0]
", r ( .
",3. Tropical hypersurfaces,[0],[0]
"A tropical polynomial f determines a dual subdivision of ∆pfq, constructed as follows.",3. Tropical hypersurfaces,[0],[0]
"First, lift each αi from Rd into Rd`1 by appending ci as the last coordinate.",3. Tropical hypersurfaces,[0],[0]
"Denote the convex hull of the lifted α1, . . .",3. Tropical hypersurfaces,[0],[0]
", αr as
Ppfq :“ Convtpαi, ciq P Rd ˆ R : i “ 1, . . .",3. Tropical hypersurfaces,[0],[0]
", ru. (1)
Next let UF ` Ppfq ˘
denote the collection of upper faces in Ppfq and π : Rd ˆ R Ñ Rd be the projection that drops the last coordinate.",3. Tropical hypersurfaces,[0],[0]
"The dual subdivision determined by f is then
δpfq :“ πppq Ă Rd : p P UF ` Ppfq ˘( .
",3. Tropical hypersurfaces,[0],[0]
δpfq forms a polyhedral complex with support ∆pfq.,3. Tropical hypersurfaces,[0],[0]
"By (Maclagan & Sturmfels, 2015, Proposition 3.1.6), the tropical hypersurface T pfq is the pd´ 1q-skeleton of the polyhedral complex dual to δpfq.",3. Tropical hypersurfaces,[0],[0]
This means that each vertex in δpfq corresponds to one “cell” in Rd where the function f is linear.,3. Tropical hypersurfaces,[0],[0]
"Thus, the number of vertices in Ppfq provides an upper bound on the number of linear regions of f .
",3. Tropical hypersurfaces,[0],[0]
"Figure 1 shows the Newton polygon and dual subdivision for the tropical polynomial fpx1, x2q “ 1d x21 ‘ 1d x22 ‘ 2d x1x2",3. Tropical hypersurfaces,[0],[0]
‘ 2d x1 ‘ 2d x2 ‘ 2.,3. Tropical hypersurfaces,[0],[0]
"Figure 2 shows how we
may find the dual subdivision for this tropical polynomial by following the aforementioned procedures; with step-by-step details given in Section C.1.
",3. Tropical hypersurfaces,[0],[0]
Tropical polynomials and tropical rational functions are clearly piecewise linear functions.,3. Tropical hypersurfaces,[0],[0]
"As such a tropical rational map is a piecewise linear map and the notion of linear region applies.
",3. Tropical hypersurfaces,[0],[0]
Definition 3.3.,3. Tropical hypersurfaces,[0],[0]
"A linear region of F P Ratpd,mq is a maximal connected subset of the domain on which F is linear.",3. Tropical hypersurfaces,[0],[0]
"The number of linear regions of F is denoted N pF q.
Note that a tropical polynomial map F P Polpd,mq has convex linear regions but a tropical rational map F P Ratpd, nq generally has nonconvex linear regions.",3. Tropical hypersurfaces,[0],[0]
"In Section 6.3, we will use N pF q as a measure of complexity for an F P Ratpd, nq given by a neural network.",3. Tropical hypersurfaces,[0],[0]
"Our analysis of neural networks will require figuring out how the polytope Ppfq transforms under tropical power, sum, and product.",3.1. Transformations of tropical polynomials,[0],[0]
"The first is straightforward.
",3.1. Transformations of tropical polynomials,[0],[0]
Proposition 3.1.,3.1. Transformations of tropical polynomials,[0],[0]
"Let f be a tropical polynomial and let a P N. Then
Ppfaq “ aPpfq.
",3.1. Transformations of tropical polynomials,[0],[0]
"aPpfq “ tax : x P Ppfqu Ď Rd`1 is a scaled version of Ppfq with the same shape but different volume.
",3.1. Transformations of tropical polynomials,[0],[0]
"To describe the effect of tropical sum and product, we need a few notions from convex geometry.",3.1. Transformations of tropical polynomials,[0],[0]
"The Minkowski sum of two sets P1 and P2 in Rd is the set
P1 ` P2 :“ x1 ` x2 P Rd :",3.1. Transformations of tropical polynomials,[0],[0]
"x1 P P1, x2 P P2 ( ;
and for λ1, λ2 ě 0, their weighted Minkowski sum is
λ1P1 ` λ2P2 :“ λ1x1 ` λ2x2 P Rd : x1 P P1, x2 P P2 ( .
",3.1. Transformations of tropical polynomials,[0],[0]
Weighted Minkowski sum is clearly commutative and associative and generalizes to more than two sets.,3.1. Transformations of tropical polynomials,[0],[0]
"In particular, the Minkowski sum of line segments is called a zonotope.
Let VpP q denote the set of vertices of a polytope P .",3.1. Transformations of tropical polynomials,[0],[0]
"Clearly, the Minkowski sum of two polytopes is given by the convex hull of the Minkowski sum of their vertex sets, i.e., P1 ` P2 “ Conv ` VpP1q ` VpP2q ˘
.",3.1. Transformations of tropical polynomials,[0],[0]
"With this observation, the following is immediate.
",3.1. Transformations of tropical polynomials,[0],[0]
Proposition 3.2.,3.1. Transformations of tropical polynomials,[0],[0]
"Let f, g P Polpd, 1q “ Trx1, . . .",3.1. Transformations of tropical polynomials,[0],[0]
", xds be tropical polynomials.",3.1. Transformations of tropical polynomials,[0],[0]
"Then
Ppf d gq “ Ppfq ` Ppgq, Ppf ‘ gq “ Conv ` VpPpfqq Y VpPpgqq ˘ .
",3.1. Transformations of tropical polynomials,[0],[0]
"We reproduce below part of (Gritzmann & Sturmfels, 1993, Theorem 2.1.10) and derive a corollary for bounding the number of verticies on the upper faces of a zonotope.
Theorem 3.3 (Gritzmann–Sturmfels).",3.1. Transformations of tropical polynomials,[0],[0]
"Let P1, . . .",3.1. Transformations of tropical polynomials,[0],[0]
", Pk be polytopes in Rd and let m denote the total number of nonparallel edges of P1, . . .",3.1. Transformations of tropical polynomials,[0],[0]
", Pk.",3.1. Transformations of tropical polynomials,[0],[0]
"Then the number of vertices of P1 ` ¨ ¨ ¨ ` Pk does not exceed
2 d´1 ÿ j“0 pm",3.1. Transformations of tropical polynomials,[0],[0]
´,3.1. Transformations of tropical polynomials,[0],[0]
"1j q .
",3.1. Transformations of tropical polynomials,[0],[0]
"The upper bound is attained if all Pi’s are zonotopes and all their generating line segments are in general positions.
",3.1. Transformations of tropical polynomials,[0],[0]
Corollary 3.4.,3.1. Transformations of tropical polynomials,[0],[0]
"Let P Ď Rd`1 be a zonotope generated by m line segments P1, . . .",3.1. Transformations of tropical polynomials,[0],[0]
", Pm.",3.1. Transformations of tropical polynomials,[0],[0]
Let π : Rd ˆ RÑ Rd be the projection.,3.1. Transformations of tropical polynomials,[0],[0]
"Suppose P satisfies:
(i) the generating line segments are in general positions;
(ii) the set of projected vertices tπpvq : v P VpP qu Ď Rd are in general positions.
",3.1. Transformations of tropical polynomials,[0],[0]
"Then P has d ÿ
j“0 pmj q
vertices on its upper faces.",3.1. Transformations of tropical polynomials,[0],[0]
"If either (i) or (ii) is violated, then this becomes an upper bound.
",3.1. Transformations of tropical polynomials,[0],[0]
"As we mentioned, linear regions of a tropical polynomial f correspond to vertices on UF ` Ppfq ˘
and the corollary will be useful for bounding the number of linear regions.",3.1. Transformations of tropical polynomials,[0],[0]
"While we expect our readership to be familiar with feedforward neural networks, we will nevertheless use this short
section to define them, primarily for the purpose of fixing notations and specifying the assumptions that we retain throughout this article.",4. Neural networks,[0],[0]
"We restrict our attention to fully connected feedforward neural networks.
",4. Neural networks,[0],[0]
"Viewed abstractly, an L-layer feedforward neural network is a map ν",4. Neural networks,[0],[0]
: Rd Ñ,4. Neural networks,[0],[0]
"Rp given by a composition of functions
ν “ σpLq ˝ ρpLq ˝",4. Neural networks,[0],[0]
"σpL´1q ˝ ρpL´1q ¨ ¨ ¨ ˝ σp1q ˝ ρp1q.
",4. Neural networks,[0],[0]
"The preactivation functions ρp1q, . . .",4. Neural networks,[0],[0]
", ρpLq are affine transformations to be determined and the activation functions σp1q, . . .",4. Neural networks,[0],[0]
", σpLq are chosen and fixed in advanced.
",4. Neural networks,[0],[0]
"We denote the width, i.e., the number of nodes, of the lth layer by nl, l “ 1, ¨ ¨ ¨ , L´ 1.",4. Neural networks,[0],[0]
"We set n0 :“ d and nL :“ p, respectively the dimensions of the input and output of the network.",4. Neural networks,[0],[0]
"The output from the lth layer will be denoted by
νplq :“ σplq ˝ ρplq ˝",4. Neural networks,[0],[0]
σpl´1q ˝,4. Neural networks,[0],[0]
ρpl´1q ¨ ¨ ¨ ˝ σp1q ˝ ρp1q,4. Neural networks,[0],[0]
",
i.e., it is a map νplq : Rd Ñ Rnl .",4. Neural networks,[0],[0]
"For convenience, we assume νp0qpxq",4. Neural networks,[0],[0]
":“ x.
The affine function ρplq :",4. Neural networks,[0],[0]
"Rnl´1 Ñ Rnl is given by a weight matrix Aplq P Znlˆnl´1 and a bias vector bplq P Rnl :
ρplqpνpl´1qq :“ Aplqνpl´1q ` bplq.
",4. Neural networks,[0],[0]
"The pi, jqth coordinate of Aplq will be denoted aplqij and the ith coordinate of bplq by bplqi .",4. Neural networks,[0],[0]
"Collectively they form the parameters of the lth layer.
",4. Neural networks,[0],[0]
"For a vector input x P Rnl , σplqpxq is understood to be in coordinatewise sense; so σ",4. Neural networks,[0],[0]
:,4. Neural networks,[0],[0]
Rnl Ñ Rnl .,4. Neural networks,[0],[0]
We assume the final output of a neural network νpxq is fed into a score function s : Rp Ñ Rm that is application specific.,4. Neural networks,[0],[0]
"When used as an m-category classifier, s may be chosen, for example, to be a soft-max or sigmoidal function.",4. Neural networks,[0],[0]
The score function is quite often regarded as the last layer of a neural network but this is purely a matter of convenience and we will not assume this.,4. Neural networks,[0],[0]
"We will make the following mild assumptions on the architecture of our feedforward neural networks and explain next why they are indeed mild:
(a) the weight matrices Ap1q, . . .",4. Neural networks,[0],[0]
", ApLq are integer-valued;
(b) the bias vectors bp1q, . . .",4. Neural networks,[0],[0]
", bpLq are real-valued;
(c) the activation functions σp1q, . . .",4. Neural networks,[0],[0]
", σpLq take the form
σplqpxq :“ maxtx, tplqu,
where tplq P pRYt´8uqnl is called a threshold vector.
",4. Neural networks,[0],[0]
"Henceforth all neural networks in our subsequent discussions will be assumed to satisfy (a)–(c).
",4. Neural networks,[0],[0]
"(b) is completely general but there is also no loss of generality in (a), i.e., in restricting the weights Ap1q, . . .",4. Neural networks,[0],[0]
", ApLq from real matrices to integer matrices, as:
• real weights can be approximated arbitrarily closely by rational weights;
• one may then ‘clear denominators’ in these rational weights by multiplying them by the least common multiple of their denominators to obtain integer weights;
• keeping in mind that scaling all weights and biases by the same positive constant has no bearing on the workings of a neural network.
",4. Neural networks,[0],[0]
The activation function in (c) includes both ReLU activation (tplq “ 0) and identity map (tplq “ ´8) as special cases.,4. Neural networks,[0],[0]
"Aside from ReLU, our tropical framework will apply to piecewise linear activations such as leaky ReLU and absolute value, and with some extra effort, may be extended to max pooling, maxout nets, etc.",4. Neural networks,[0],[0]
"But it does not, for example, apply to activations such as hyperbolic tangent and sigmoid.
",4. Neural networks,[0],[0]
"In this work, we view an ReLU network as the simplest and most canonical model of a neural network, from which other variants that are more effective at specific tasks may be derived.",4. Neural networks,[0],[0]
"Given that we seek general theoretical insights and not specific practical efficacy, it makes sense to limit ourselves to this simplest case.",4. Neural networks,[0],[0]
"Moreover, ReLU networks already embody some of the most important elements (and mysteries) common to a wider range of neural networks (e.g., universal approximation, exponential expressiveness); they work well in practice and are often the go-to choice for feedforward networks.",4. Neural networks,[0],[0]
"We are also not alone in limiting our discussions to ReLU networks (Montufar et al., 2014; Arora et al., 2018).",4. Neural networks,[0],[0]
"We now describe our tropical formulation of a multilayer feedforward neural network satisfying (a)–(c).
",5. Tropical algebra of neural networks,[0],[0]
"A multilayer feedforward neural network is generally nonconvex, whereas a tropical polynomial is always convex.",5. Tropical algebra of neural networks,[0],[0]
"Since most nonconvex functions are a difference of two convex functions (Hartman, 1959), a reasonable guess is that a feedforward neural network is the difference of two tropical polynomials, i.e., a tropical rational function.",5. Tropical algebra of neural networks,[0],[0]
"This is indeed the case, as we will see from the following.
",5. Tropical algebra of neural networks,[0],[0]
"Consider the output from the first layer in neural network
νpxq “ maxtAx` b, tu,
where A P Zpˆd, b P Rp, and t P pR Y t´8uqp.",5. Tropical algebra of neural networks,[0],[0]
"We will decompose A as a difference of two nonnegative integervalued matrices, A “ A`´A´ with A`, A´ P Npˆd; e.g., in the standard way with entries
a`ij :“ maxtaij , 0u, a ´ ij :“ maxt´aij , 0u
respectively.",5. Tropical algebra of neural networks,[0],[0]
"Since
maxtAx` b, tu “ maxtA`x` b, A´x` tu ´A´x,
we see that every coordinate of one-layer neural network is a difference of two tropical polynomials.",5. Tropical algebra of neural networks,[0],[0]
"For networks with more layers, we apply this decomposition recursively to obtain the following result.
",5. Tropical algebra of neural networks,[0],[0]
Proposition 5.1.,5. Tropical algebra of neural networks,[0],[0]
"LetA P Zmˆn, b P Rm be the parameters of the pl ` 1qth layer, and let t P pR Y t´8uqm be the threshold vector in the pl` 1qth layer.",5. Tropical algebra of neural networks,[0],[0]
"If the nodes of the lth layer are given by tropical rational functions,
νplqpxq “ F plqpxq mGplqpxq “ F plqpxq ´Gplqpxq,
i.e., each coordinate of F plq and Gplq is a tropical polynomial in x, then the outputs of the preactivation and of the pl ` 1qth layer are given by tropical rational functions
ρpl`1q ˝ νplqpxq “ Hpl`1qpxq ´Gpl`1qpxq, νpl`1qpxq “ σ ˝ ρpl`1q ˝ νplqpxq “ F pl`1qpxq ´Gpl`1qpxq
respectively, where
F pl`1qpxq “ max Hpl`1qpxq, Gpl`1qpxq ` t ( ,
Gpl`1qpxq “ A`Gplqpxq `A´F plqpxq, Hpl`1qpxq “ A`F plqpxq `A´Gplqpxq ` b.
We will write f plqi ,",5. Tropical algebra of neural networks,[0],[0]
"g plq i and h plq i for the ith coordinate of F plq, Gplq and Hplq respectively.",5. Tropical algebra of neural networks,[0],[0]
"In tropical arithmetic, the recurrence above takes the form
f pl`1q i “ h pl`1q",5. Tropical algebra of neural networks,[0],[0]
"i ‘ pg pl`1q i d tiq,
g pl`1q i “
„ n ä
j“1 pf plqj q",5. Tropical algebra of neural networks,[0],[0]
"a´ij
 d „",5. Tropical algebra of neural networks,[0],[0]
"n ä
j“1 pgplqj q a`ij

,
",5. Tropical algebra of neural networks,[0],[0]
h pl`1q,5. Tropical algebra of neural networks,[0],[0]
"i “
„ n ä
j“1 pf plqj q",5. Tropical algebra of neural networks,[0],[0]
"a`ij
 d „",5. Tropical algebra of neural networks,[0],[0]
"n ä
j“1",5. Tropical algebra of neural networks,[0],[0]
"pgplqj q a´ij

d bi.
(2)
Repeated applications of Proposition 5.1 yield the following.
",5. Tropical algebra of neural networks,[0],[0]
Theorem 5.2 (Tropical characterization of neural networks).,5. Tropical algebra of neural networks,[0],[0]
A feedforward neural network under assumptions (a)–(c) is a function ν,5. Tropical algebra of neural networks,[0],[0]
: Rd Ñ,5. Tropical algebra of neural networks,[0],[0]
"Rp whose coordinates are tropical rational functions of the input, i.e.,
νpxq “ F pxq mGpxq “ F pxq ´Gpxq
where F and G are tropical polynomial maps.",5. Tropical algebra of neural networks,[0],[0]
"Thus ν is a tropical rational map.
",5. Tropical algebra of neural networks,[0],[0]
"Note that the tropical rational functions above have real coefficients, not integer coefficients.",5. Tropical algebra of neural networks,[0],[0]
"The integer weights Aplq P Znlˆnl´1 have gone into the powers of tropical monomials in f and g, which is why we require our weights to be integer-valued, although as we have explained, this requirement imposes little loss of generality.
",5. Tropical algebra of neural networks,[0],[0]
"By setting tp1q “ ¨ ¨ ¨ “ tpL´1q “ 0 and tpLq “ ´8, we obtain the following corollary.
",5. Tropical algebra of neural networks,[0],[0]
Corollary 5.3.,5. Tropical algebra of neural networks,[0],[0]
Let ν :,5. Tropical algebra of neural networks,[0],[0]
Rd Ñ R be an ReLU activated feedforward neural network with integer weights and linear output.,5. Tropical algebra of neural networks,[0],[0]
"Then ν is a tropical rational function.
",5. Tropical algebra of neural networks,[0],[0]
"A more remarkable fact is the converse of Corollary 5.3.
",5. Tropical algebra of neural networks,[0],[0]
"Theorem 5.4 (Equivalence of neural networks and tropical rational functions).
",5. Tropical algebra of neural networks,[0],[0]
(i) Let ν,5. Tropical algebra of neural networks,[0],[0]
": Rd Ñ R. Then ν is a tropical rational function if and only if ν is a feedforward neural network satisfying assumptions (a)–(c).
",5. Tropical algebra of neural networks,[0],[0]
"(ii) A tropical rational function f m g can be represented as an L-layer neural network, with
L ď maxtrlog2 rf s, rlog2 rgsu ` 2,
where rf and rg are the number of monomials in the tropical polynomials f and g respectively.
",5. Tropical algebra of neural networks,[0],[0]
"We would like to acknowledge the precedence of (Arora et al., 2018, Theorem 2.1), which demonstrates the equivalence between ReLU-activatedL-layer neural networks with real weights and d-variate continuous piecewise functions with real coefficients, where L ď rlog2pd` 1qs` 1.
",5. Tropical algebra of neural networks,[0],[0]
"By construction, a tropical rational function is a continuous piecewise linear function.",5. Tropical algebra of neural networks,[0],[0]
The continuity of a piecewise linear function automatically implies that each of the pieces on which it is linear is a polyhedral region.,5. Tropical algebra of neural networks,[0],[0]
"As we saw in Section 3, a tropical polynomial f",5. Tropical algebra of neural networks,[0],[0]
: Rd Ñ R gives a tropical hypersurface that divides Rd into convex polyhedral regions defined by linear inequalities with integer coefficients: tx P Rd :,5. Tropical algebra of neural networks,[0],[0]
Ax ď bu with A P Zmˆd and b P Rm.,5. Tropical algebra of neural networks,[0],[0]
"A tropical rational function f m g : Rd Ñ R must also be a continuous piecewise linear function and divide Rd into polyhedral regions on each of which f m g is linear, although these regions are nonconvex in general.",5. Tropical algebra of neural networks,[0],[0]
"We will show the converse — any continuous piecewise linear function with integer coefficients is a tropical rational function.
",5. Tropical algebra of neural networks,[0],[0]
Proposition 5.5.,5. Tropical algebra of neural networks,[0],[0]
Let ν :,5. Tropical algebra of neural networks,[0],[0]
"Rd Ñ R. Then ν is a continuous piecewise linear function with integer coefficients if and only if ν is a tropical rational function.
",5. Tropical algebra of neural networks,[0],[0]
"Corollary 5.3, Theorem 5.4, and Proposition 5.5 collectively imply the equivalence of
(i) tropical rational functions,
(ii) continuous piecewise linear functions with integer coefficients,
(iii) neural networks satisfying assumptions (a)–(c).
",5. Tropical algebra of neural networks,[0],[0]
"An immediate advantage of this characterization is that the set of tropical rational functions Tpx1, . . .",5. Tropical algebra of neural networks,[0],[0]
", xdq has a semifield structure as we pointed out in Section 2, a fact that we have implicitly used in the proof of Proposition 5.5.",5. Tropical algebra of neural networks,[0],[0]
"However, what is more important is not the algebra but the
algebraic geometry that arises from our tropical characterization.",5. Tropical algebra of neural networks,[0],[0]
"We will use tropical algebraic geometry to illuminate our understanding of neural networks in the next section.
",5. Tropical algebra of neural networks,[0],[0]
The need to stay within tropical algebraic geometry is the reason we did not go for a simpler and more general characterization (that does not require the integer coefficients assumption).,5. Tropical algebra of neural networks,[0],[0]
"A tropical signomial takes the form
ϕpxq “ m à
i“1 bi
n ä j“1",5. Tropical algebra of neural networks,[0],[0]
"x aij j ,
where aij P R and bi P R Y t´8u.",5. Tropical algebra of neural networks,[0],[0]
Note that aij is not required to be integer-valued nor nonnegative.,5. Tropical algebra of neural networks,[0],[0]
"A tropical rational signomial is a tropical quotientϕmψ of two tropical signomials ϕ,ψ.",5. Tropical algebra of neural networks,[0],[0]
"A tropical rational signomial map is a function ν “ pν1, . . .",5. Tropical algebra of neural networks,[0],[0]
", νpq :",5. Tropical algebra of neural networks,[0],[0]
Rd Ñ Rp where each νi : Rd Ñ R is a tropical rational signomial νi “ ϕi m ψi.,5. Tropical algebra of neural networks,[0],[0]
The same argument we used to establish Theorem 5.2 gives us the following.,5. Tropical algebra of neural networks,[0],[0]
Proposition 5.6.,5. Tropical algebra of neural networks,[0],[0]
"Every feedforward neural network with ReLU activation is a tropical rational signomial map.
",5. Tropical algebra of neural networks,[0],[0]
Nevertheless tropical signomials fall outside the realm of tropical algebraic geometry and we do not use Proposition 5.6 in the rest of this article.,5. Tropical algebra of neural networks,[0],[0]
"Section 5 defines neural networks via tropical algebra, a perspective that allows us to study them via tropical algebraic geometry.",6. Tropical geometry of neural networks,[0],[0]
We will show that the decision boundary of a neural network is a subset of a tropical hypersurface of a corresponding tropical polynomial (Section 6.1).,6. Tropical geometry of neural networks,[0],[0]
"We will see that, in an appropriate sense, zonotopes form the geometric building blocks for neural networks (Section 6.2).",6. Tropical geometry of neural networks,[0],[0]
We then prove that the geometry of the function represented by a neural network grows vastly more complex as its number of layers increases (Section 6.3).,6. Tropical geometry of neural networks,[0],[0]
"We will use tropical geometry and insights from Section 5 to study decision boundaries of neural networks, focusing on the case of two-category classification for clarity.",6.1. Decision boundaries of a neural network,[0],[0]
"As explained in Section 4, a neural network ν :",6.1. Decision boundaries of a neural network,[0],[0]
Rd Ñ Rp together with a choice of score function s :,6.1. Decision boundaries of a neural network,[0],[0]
Rp Ñ R give us a classifier.,6.1. Decision boundaries of a neural network,[0],[0]
"If the output value spνpxqq exceeds some decision threshold c, then the neural network predicts x is from one class (e.g., x is a CAT image), and otherwise x is from the other category (e.g., a DOG image).",6.1. Decision boundaries of a neural network,[0],[0]
The input space is thereby partitioned into two disjoint subsets by the decision boundary B :“ tx P Rd : νpxq “ s´1pcqu.,6.1. Decision boundaries of a neural network,[0],[0]
"Connected regions with value above the threshold and connected regions with value below the threshold will be called the positive regions and negative regions respectively.
",6.1. Decision boundaries of a neural network,[0],[0]
"We provide bounds on the number of positive and negative regions and show that there is a tropical polynomial whose tropical hypersurface contains the decision boundary.
",6.1. Decision boundaries of a neural network,[0],[0]
Proposition 6.1 (Tropical geometry of decision boundary).,6.1. Decision boundaries of a neural network,[0],[0]
Let ν :,6.1. Decision boundaries of a neural network,[0],[0]
Rd Ñ R be an L-layer neural network satisfying assumptions (a)–(c) with tpLq “ ´8.,6.1. Decision boundaries of a neural network,[0],[0]
Let the score function s : RÑ R be injective with decision threshold c in its range.,6.1. Decision boundaries of a neural network,[0],[0]
"If ν “ f m g where f and g are tropical polynomials, then
(i) its decision boundary B “ tx P Rd : νpxq “ s´1pcqu divides Rd into at most N pfq connected positive regions and at most N pgq connected negative regions;
(ii) its decision boundary is contained in the tropical hypersurface of the tropical polynomial s´1pcq d gpxq ‘ fpxq “ maxtfpxq, gpxq ` s´1pcqu, i.e.,
B Ď T ps´1pcq d g ‘ fq.",6.1. Decision boundaries of a neural network,[0],[0]
"(3)
",6.1. Decision boundaries of a neural network,[0],[0]
The function s´1pcqdg‘f is not necessarily linear on every positive or negative region and so its tropical hypersurface T ps´1pcqdg‘fqmay further divide a positive or negative region derived from B into multiple linear regions.,6.1. Decision boundaries of a neural network,[0],[0]
Hence the “Ď” in (3) cannot in general be replaced by ““”.,6.1. Decision boundaries of a neural network,[0],[0]
"From Section 3, we know that the number of regions a tropical hypersurface T pfq divides the space into equals the number of vertices in the dual subdivision of the Newton polygon associated with the tropical polynomial f .",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"This allows us to bound the number of linear regions of a neural network by bounding the number of vertices in the dual subdivision of the Newton polygon.
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"We start by examining how geometry changes from one layer to the next in a neural network, more precisely:
Question.",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"How are the tropical hypersurfaces of the tropical polynomials in the pl ` 1qth layer of a neural network related to those in the lth layer?
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"The recurrent relation (2) describes how the tropical polynomials occurring in the pl ` 1qth layer are obtained from those in the lth layer, namely, via three operations: tropical sum, tropical product, and tropical powers.",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"Recall that a tropical hypersurface of a tropical polynomial is dual to the dual subdivision of the Newton polytope of the tropical polynomial, which is given by the projection of the upper faces on the polytopes defined by (1).",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"Hence the question boils down to how these three operations transform the polytopes, which is addressed in Propositions 3.1 and 3.2.",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"We follow notations in Proposition 5.1 for the next result.
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
Lemma 6.2.,6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"Let f plqi ,",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"g plq i , h plq i be the tropical polynomials produced by the ith node in the lth layer of a neural network,
i.e., they are defined by (2).",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"Then P ` f plq i ˘ , P ` g plq i ˘ , P ` h plq",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"i ˘ are subsets of Rd`1 given as follows:
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"(i) P ` g p1q i ˘ and P ` h p1q i ˘ are points.
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"(ii) P ` f p1q i ˘ is a line segment.
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
(iii) P ` g p2q,6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
i ˘ and P ` h p2q i ˘ are zonotopes.,6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"(iv) For l ě 1,
P ` f plq i ˘ “ Conv “ P ` g plq i d t plq",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
i ˘ Y P ` h plq,6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"i ˘‰
if tplqi P R, and P ` f plq",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"i ˘ “ P ` h plq i ˘ if tplqi “ ´8.
(v) For l ě 1, P ` g pl`1q i ˘ and P ` h pl`1q i ˘
are weighted Minkowski sums,
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"P ` g pl`1q i ˘
“ nl ÿ
j“1 a´ijP ` f plq j ˘
` nl ÿ
j“1 a`ijP",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"` g plq j ˘ ,
P ` h pl`1q",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"i ˘
“ nl ÿ
j“1 a`ijP ` f plq j ˘
` nl ÿ
j“1 a´ijP",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"` g plq j ˘
` tbieu,
where aij , bi are entries of the weight matrix Apl`1q P Znl`1ˆnl and bias vector bpl`1q P Rnl`1 , and e :“ p0, . . .",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
", 0, 1q P Rd`1.
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
A conclusion of Lemma 6.2 is that zonotopes are the building blocks in the tropical geometry of neural networks.,6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"Zonotopes are studied extensively in convex geometry and, among other things, are intimately related to hyperplane arrangements (Greene & Zaslavsky, 1983; Guibas et al., 2003; McMullen, 1971; Holtz & Ron, 2011).",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
Lemma 6.2 connects neural networks to this extensive body of work but its full implication remains to be explored.,6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"In Section C.2 of the supplement, we show how one may build these polytopes for a two-layer neural network.",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"We apply the tools in Section 3 to study the complexity of a neural network, showing that a deep network is much more expressive than a shallow one.",6.3. Geometric complexity of deep neural networks,[0],[0]
"Our measure of complexity is geometric: we will follow (Montufar et al., 2014; Raghu et al., 2017) and use the number of linear regions of a piecewise linear function ν :",6.3. Geometric complexity of deep neural networks,[0],[0]
"Rd Ñ Rp to measure the complexity of ν.
",6.3. Geometric complexity of deep neural networks,[0],[0]
"We would like to emphasize that our upper bound below does not improve on that obtained in (Raghu et al., 2017) — in fact, our version is more restrictive given that it applies only to neural networks satisfying (a)–(c).",6.3. Geometric complexity of deep neural networks,[0],[0]
"Nevertheless our goal here is to demonstrate how tropical geometry may be used to derive the same bound.
",6.3. Geometric complexity of deep neural networks,[0],[0]
Theorem 6.3.,6.3. Geometric complexity of deep neural networks,[0],[0]
Let ν :,6.3. Geometric complexity of deep neural networks,[0],[0]
Rd Ñ R be an L-layer real-valued feedforward neural network satisfying (a)–(c).,6.3. Geometric complexity of deep neural networks,[0],[0]
"Let tpLq “
´8 and nl ě d for all l “ 1, . . .",6.3. Geometric complexity of deep neural networks,[0],[0]
", L ´ 1.",6.3. Geometric complexity of deep neural networks,[0],[0]
"Then ν “ νpLq has at most
L´1 ź
l“1
d ÿ i“0",6.3. Geometric complexity of deep neural networks,[0],[0]
pnl,6.3. Geometric complexity of deep neural networks,[0],[0]
"i q
linear regions.",6.3. Geometric complexity of deep neural networks,[0],[0]
"In particular, if d ď n1, . . .",6.3. Geometric complexity of deep neural networks,[0],[0]
", nL´1 ď n, the number of linear regions of ν is bounded by O ` ndpL´1q ˘ .
",6.3. Geometric complexity of deep neural networks,[0],[0]
Proof.,6.3. Geometric complexity of deep neural networks,[0],[0]
"If L “ 2, this follows directly from Lemma 6.2 and Corollary 3.4.",6.3. Geometric complexity of deep neural networks,[0],[0]
"The case of L ě 3 is in Section D.7 in the supplement.
",6.3. Geometric complexity of deep neural networks,[0],[0]
"As was pointed out in (Raghu et al., 2017), this upper bound closely matches the lower bound Ω ` pn{dqpL´1qdnd ˘ in (Montufar et al., 2014, Corollary 5) when n1 “ ¨ ¨ ¨ “ nL´1 “ n",6.3. Geometric complexity of deep neural networks,[0],[0]
ě d.,6.3. Geometric complexity of deep neural networks,[0],[0]
Hence we surmise that the number of linear regions of the neural network grows polynomially with the width n and exponentially with the number of layers L.,6.3. Geometric complexity of deep neural networks,[0],[0]
"We argue that feedforward neural networks with rectified linear units are, modulo trivialities, nothing more than tropical rational maps.",7. Conclusion,[0],[0]
"To understand them we often just need to understand the relevant tropical geometry.
",7. Conclusion,[0],[0]
"In this article, we took a first step to provide a proof-ofconcept: questions regarding decision boundaries, linear regions, how depth affect expressiveness, etc, can be translated into questions involving tropical hypersurfaces, dual subdivision of Newton polygon, polytopes constructed from zonotopes, etc.
",7. Conclusion,[0],[0]
"As a new branch of algebraic geometry, the novelty of tropical geometry stems from both the algebra and geometry as well as the interplay between them.",7. Conclusion,[0],[0]
It has connections to many other areas of mathematics.,7. Conclusion,[0],[0]
"Among other things, there is a tropical analogue of linear algebra (Butkovič, 2010) and a tropical analogue of convex geometry (Gaubert & Katz, 2006).",7. Conclusion,[0],[0]
We cannot emphasize enough that we have only touched on a small part of this rich subject.,7. Conclusion,[0],[0]
We hope that further investigation from this tropical angle might perhaps unravel other mysteries of deep neural networks.,7. Conclusion,[0],[0]
"The authors thank Ralph Morrison, Yang Qi, Bernd Sturmfels, and the anonymous referees for their very helpful comments.",Acknowledgments,[0],[0]
"The work in this article is generously supported by DARPA D15AP00109, NSF IIS 1546413, the Eckhardt Faculty Fund, and a DARPA Director’s Fellowship.",Acknowledgments,[0],[0]
"As in Section 2, we write xa “ xda; aside from this slight abuse of notation, ‘ and d denote tropical sum and product, ` and ¨ denote standard sum and product in all other contexts.",B. Tropical power,[0],[0]
"Tropical power evidently has the following properties:
• For x, y P R and a P R, a ě 0,
px‘ yqa “ xa ‘ ya and pxd yqa “ xa d ya.
",B. Tropical power,[0],[0]
"If a is allowed negative values, then we lose the first property.",B. Tropical power,[0],[0]
In general px‘ yqa ‰ xa ‘ ya for a ă 0.,B. Tropical power,[0],[0]
•,B. Tropical power,[0],[0]
"For x P R,
x0 “ 0.
•",B. Tropical power,[0],[0]
"For x P R and a, b P N, pxaqb “ xa¨b.
•",B. Tropical power,[0],[0]
"For x P R and a, b P Z, xa d xb “ xa`b.
•",B. Tropical power,[0],[0]
"For x P R and a, b P Z, xa ‘ xb “ xa d pxa´b ‘ 0q “ xa d p0‘ xa´bq.",B. Tropical power,[0],[0]
C.1.,C. Examples,[0],[0]
"Examples of tropical curves and dual subdivision of Newton polygon
Let f P Polp2, 1q “ Trx1, x2s, i.e., a bivariate tropical polynomial.",C. Examples,[0],[0]
"It follows from our discussions in Section 3 that the tropical hypersurface T pfq is a planar graph dual to the dual subdivision δpfq in the following sense:
(i)",C. Examples,[0],[0]
Each two-dimensional face in δpfq corresponds to a vertex in T pfq.,C. Examples,[0],[0]
(ii) Each one-dimensional edge of a face in δpfq corresponds to an edge in T pfq.,C. Examples,[0],[0]
"In particular, an edge from the Newton
polygon ∆pfq corresponds to an unbounded edge in T pfq while other edges correspond to bounded edges.
",C. Examples,[0],[0]
"Figure 2 illustrates how we may find the dual subdivision for the tropical polynomial fpx1, x2q",C. Examples,[0],[0]
“,C. Examples,[0],[0]
1d x21 ‘ 1d x22 ‘ 2d x1x2,C. Examples,[0],[0]
‘ 2d x1 ‘ 2d x2 ‘ 2.,C. Examples,[0],[0]
"First, find the convex hull
Ppfq “ Convtp2, 0, 1q, p0, 2, 1q, p1, 1, 2q, p1, 0, 2q, p0, 1, 2q, p0, 0, 2qu.
",C. Examples,[0],[0]
"Then, by projecting the upper envelope of Ppfq to R2, we obtain δpfq, the dual subdivision of the Newton polygon.
",C. Examples,[0],[0]
C.2.,C. Examples,[0],[0]
"Polytopes of a two-layer neural network
We illustrate our discussions in Section 6.2 with a two-layer example.",C. Examples,[0],[0]
"Let ν : R2 Ñ R be with n0 “ 2 input nodes, n1 “ 5 nodes in the first layer, and n2 “ 1 nodes in the output:
y “ νp1qpxq “ max
$
’ ’ ’ ’ &
’ ’ ’ ’",C. Examples,[0],[0]
"%
»
— — — — –
´1 1 1 ´3 1 2 ´4 1 3 2
fi
ffi ffi ffi ffi",C. Examples,[0],[0]
"fl „ x1 x2  `
»
— — — — –
1 ´1
2 0 ´2
fi
ffi ffi ffi ffi",C. Examples,[0],[0]
"fl , 0
,
/ / / / .
/ / / / -
,
νp2qpyq",C. Examples,[0],[0]
"“ maxty1 ` 2y2 ` y3 ´ y4 ´ 3y5, 0u.
We first express νp1q and νp2q as tropical rational maps,
νp1q “ F p1q mGp1q, νp2q “ f p2q m gp2q,
where
y :“ F p1qpxq “ Hp1qpxq ‘Gp1qpxq,
z :“ Gp1qpxq “
»
— — — — – x1 x32 0",C. Examples,[0],[0]
"x41 0
fi
ffi ffi ffi ffi",C. Examples,[0],[0]
"fl , Hp1qpxq “
»
— — — — –
1d x2 p´1q",C. Examples,[0],[0]
"d x1 2d x1x22
x2 p´2q",C. Examples,[0],[0]
"d x31x22
fi
ffi ffi ffi ffi",C. Examples,[0],[0]
"fl ,
and
f p2qpxq “ gp2qpxq ‘ hp2qpxq, gp2qpxq",C. Examples,[0],[0]
“ y4 d y35 d z1 d z22 d z3 “ px2 ‘ x41q d pp´2q d x31x22,C. Examples,[0],[0]
"‘ 0q3 d x1 d px32q2, hp2qpxq “ y1 d y22 d y3 d z4 d z35
“ p1d x2 ‘ x1q d pp´1q",C. Examples,[0],[0]
"d x1 ‘ x32q2 d p2d x1x22 ‘ 0q d x41.
",C. Examples,[0],[0]
"We will write F p1q “ pf p1q1 , . . .",C. Examples,[0],[0]
", f p1q 5 q and likewise for Gp1q and Hp1q.",C. Examples,[0],[0]
The monomials occurring in g p1q j pxq and h p1q,C. Examples,[0],[0]
j pxq are all of the form cxa11 x a2 2 .,C. Examples,[0],[0]
"Therefore Ppg p1q j q and Pph p1q j q, j “ 1, . . .",C. Examples,[0],[0]
", 5, are points in R3.
",C. Examples,[0],[0]
"Since F p1q “ Gp1q ‘Hp1q, Ppf p1qj q is a convex hull of two points, and thus a line segment in R3.",C. Examples,[0],[0]
"The Newton polygons associated with f p1qj , equal to their dual subdivisions in this case, are obtained by projecting these line segments back to the plane spanned by a1, a2, as shown on the left in Figure C.1.
",C. Examples,[0],[0]
"The line segments Ppf p1qj q, j “ 1, . . .",C. Examples,[0],[0]
", 5, and points Ppg p1q j q, j “ 1, . . .",C. Examples,[0],[0]
", 5, serve as building blocks for Pphp2qq and Ppgp2qq, which are constructed as weighted Minkowski sums:
Pphp2qq “ Ppf p1q4 q ` 3Ppf p1q 5 q ` Ppg p1q 1 q ` 2Ppg p1q 2 q",C. Examples,[0],[0]
"` Ppg p1q 3 q, Ppgp2qq “ Ppf p1q1 q ` 2Ppf p1q 2 q",C. Examples,[0],[0]
` Ppf p1q 3 q,C. Examples,[0],[0]
"` Ppg p1q 4 q ` 3Ppg p1q 5 q.
Ppgp2qq and the dual subdivision of its Newton polygon are shown on the right in Figure C.1.",C. Examples,[0],[0]
Pphp2qq and the dual subdivision of its Newton polygon are shown on the left in Figure C.2.,C. Examples,[0],[0]
Ppf p2qq is the convex hull of the union of Ppgp2qq and Pphp2qq.,C. Examples,[0],[0]
"The dual subdivision of its Newton polygon is obtained by projecting the upper faces of Ppf p2qq to the plane spanned by a1, a2.",C. Examples,[0],[0]
These are shown on the right in Figure C.2.,C. Examples,[0],[0]
Proof.,D.1. Proof of Corollary 3.4,[0],[0]
Let V1 and V2 be the sets of vertices on the upper and lower envelopes of P respectively.,D.1. Proof of Corollary 3.4,[0],[0]
"By Theorem 3.3, P has
n1 :“ 2 d ÿ j“0 pm",D.1. Proof of Corollary 3.4,[0],[0]
´,D.1. Proof of Corollary 3.4,[0],[0]
"1j q
vertices in total.",D.1. Proof of Corollary 3.4,[0],[0]
"By construction, we have |V1 Y V2| “ n1.",D.1. Proof of Corollary 3.4,[0],[0]
"It is well-known that zonotopes are centrally symmetric and so there are equal number of vertices on the upper and lower envelopes, i.e., |V1| “ |V2|.",D.1. Proof of Corollary 3.4,[0],[0]
Let P 1 :“ πpP q be the projection of P into Rd.,D.1. Proof of Corollary 3.4,[0],[0]
"Since the projected vertices are assumed to be in general positions, P 1 must be a d-dimensional zonotope generated by m nonparallel line segments.",D.1. Proof of Corollary 3.4,[0],[0]
"Hence, by Theorem 3.3 again, P 1 has
n2 :“ 2 d´1 ÿ j“0 pm",D.1. Proof of Corollary 3.4,[0],[0]
´,D.1. Proof of Corollary 3.4,[0],[0]
"1j q
vertices.",D.1. Proof of Corollary 3.4,[0],[0]
"For any vertex v P P , πpvq is a vertex of P 1 if and only if v belongs to both the upper and lower envelopes, i.e., v P V1 X V2.",D.1. Proof of Corollary 3.4,[0],[0]
Therefore the number of vertices on P 1 equals |V1 X V2|.,D.1. Proof of Corollary 3.4,[0],[0]
"By construction, we have |V1 X V2| “ n2.",D.1. Proof of Corollary 3.4,[0],[0]
"Consequently the number of vertices on the upper envelope is
|V1| “ 1
2 p|V1 Y V2| ´ |V1 X V2|q ` |V1 X V2| “
1 2 pn1 ´ n2q ` n2 “
d ÿ j“0 pmj q .",D.1. Proof of Corollary 3.4,[0],[0]
Proof.,D.2. Proof of Proposition 5.1,[0],[0]
"Writing A “ A` ´A´, we have
ρpl`1qpxq “ ` A` ´A´ ˘` F plqpxq ´Gplqpxq ˘ ` b “ ` A`F plqpxq `A´Gplqpxq ` b ˘ ´ ` A`G plqpxq `A´F plqpxq ˘
“ Hpl`1qpxq ´Gpl`1qpxq, νpl`1qpxq “ max ρpl`1qpyq, t (
“ max Hpl`1qpxq ´Gpl`1qpxq, t (
“ max Hpl`1qpxq, Gpl`1qpxq ` t ( ´Gpl`1qpxq “ F pl`1qpxq ´Gpl`1qpxq.",D.2. Proof of Proposition 5.1,[0],[0]
Proof.,D.3. Proof of Theorem 5.4,[0],[0]
It remains to establish the “only if” part.,D.3. Proof of Theorem 5.4,[0],[0]
"We will write σtpxq :“ maxtx, tu.",D.3. Proof of Theorem 5.4,[0],[0]
"Any tropical monomial bixαi is clearly such a neural network as
bix αi “ pσ´8 ˝ ρiqpxq “ maxtαTix` bi,´8u.
",D.3. Proof of Theorem 5.4,[0],[0]
"If two tropical polynomials p and q are represented as neural networks with lp and lq layers respectively,
ppxq “ ` σ´8 ˝ ρplpqp ˝ σ0 ˝ . . .",D.3. Proof of Theorem 5.4,[0],[0]
σ0 ˝,D.3. Proof of Theorem 5.4,[0],[0]
"ρp1qp ˘ pxq, qpxq “ `
σ´8 ˝ ρplqqq ˝ σ0 ˝ . . .",D.3. Proof of Theorem 5.4,[0],[0]
σ0 ˝,D.3. Proof of Theorem 5.4,[0],[0]
"ρp1qq ˘ pxq,
then pp‘ qqpxq “ maxtppxq, qpxqu can also be written as a neural network with maxtlp, lqu ` 1 layers:
pp‘ qqpxq “ σ´8 ` rσ0 ˝ ρ1spypxqq ` rσ0 ˝ ρ2spypxqq ´ rσ0 ˝ ρ3spypxqq ˘ ,
where y : Rd Ñ R2 is given by ypxq “ pppxq, qpxqq and ρi : R2 Ñ R, i “ 1, 2, 3, are linear functions defined by
ρ1pyq",D.3. Proof of Theorem 5.4,[0],[0]
"“ y1 ´ y2, ρ2pyq “ y2, ρ3pyq",D.3. Proof of Theorem 5.4,[0],[0]
"“ ´y2.
",D.3. Proof of Theorem 5.4,[0],[0]
"Thus, by induction, any tropical polynomial can be written as a neural network with ReLU activation.",D.3. Proof of Theorem 5.4,[0],[0]
"Observe also that if a tropical polynomial is the tropical sum of r monomials, then it can be written as a neural network with no more than rlog2 rs` 1 layers.
",D.3. Proof of Theorem 5.4,[0],[0]
Next we consider a tropical rational function ppm qqpxq “ ppxq ´ qpxq where p and q are tropical polynomials.,D.3. Proof of Theorem 5.4,[0],[0]
"Under the same assumptions, we can represent pm q",D.3. Proof of Theorem 5.4,[0],[0]
"as
ppm qqpxq “ σ´8 ` rσ0 ˝ ρ4spypxqq ´ rσ0 ˝ ρ5spypxqq ` rσ0 ˝ ρ6spypxqq ´ rσ0 ˝ ρ7spypxqq ˘
where ρi : R2 Ñ R2, i “ 4, 5, 6, 7, are linear functions defined by
ρ4pyq “ y1, ρ5pyq",D.3. Proof of Theorem 5.4,[0],[0]
"“ ´y1, ρ6pyq",D.3. Proof of Theorem 5.4,[0],[0]
"“ ´y2, ρ7pyq “ y2.
",D.3. Proof of Theorem 5.4,[0],[0]
"Therefore pm q is also a neural network with at most maxtlp, lqu ` 1 layers.
",D.3. Proof of Theorem 5.4,[0],[0]
"Finally, if f and g are tropical polynomials that are respectively tropical sums of rf and rg monomials, then the discussions above show that pf m gqpxq “ fpxq ´ gpxq is a neural network with at most maxtrlog2 rf s, rlog2 rgsu ` 2 layers.",D.3. Proof of Theorem 5.4,[0],[0]
Proof.,D.4. Proof of Proposition 5.5,[0],[0]
It remains to establish the “if” part.,D.4. Proof of Proposition 5.5,[0],[0]
"Let Rd be divided into N polyhedral region on each of which ν restricts to a linear function `ipxq “ aTix` bi, ai P Zd, bi P R, i “ 1, . . .",D.4. Proof of Proposition 5.5,[0],[0]
", L, i.e., for any x P Rd, νpxq “ `ipxq for some i P t1, . . .",D.4. Proof of Proposition 5.5,[0],[0]
", Lu.",D.4. Proof of Proposition 5.5,[0],[0]
"It follows from (Tarela & Martinez, 1999) that we can find N subsets of t1, . . .",D.4. Proof of Proposition 5.5,[0],[0]
", Lu, denoted by Sj , j “ 1, . . .",D.4. Proof of Proposition 5.5,[0],[0]
", N , so that ν has a representation
νpxq “ max j“1,...,N min iPSj `i.
It is clear that each `i is a tropical rational function.",D.4. Proof of Proposition 5.5,[0],[0]
"Now for any tropical rational functions p and q,
mintp, qu “ ´maxt´p,´qu “ 0m rp0m pq ‘ p0m qqs “ rpd qs m rp‘ qs.
",D.4. Proof of Proposition 5.5,[0],[0]
"Since pd q and p‘ q are both tropical rational functions, so is their tropical quotient.",D.4. Proof of Proposition 5.5,[0],[0]
"By induction, miniPSj `i is a tropical rational function for any j “ 1, . . .",D.4. Proof of Proposition 5.5,[0],[0]
", N , and therefore so is their tropical sum ν.",D.4. Proof of Proposition 5.5,[0],[0]
Proof.,D.5. Proof of Proposition 5.6,[0],[0]
"For a one-layer neural network νpxq “ maxtAx ` b, tu “ pν1pxq, . . .",D.5. Proof of Proposition 5.6,[0],[0]
", νppxqq with A P Rpˆd, b P Rp, x P Rd, t P pRY t´8uqp, we have
νkpxq “ ˆ",D.5. Proof of Proposition 5.6,[0],[0]
bk,D.5. Proof of Proposition 5.6,[0],[0]
"d d ä
j“1 x akj j
˙ ‘ tk “ ˆ bk",D.5. Proof of Proposition 5.6,[0],[0]
"d d ä
j“1 x akj j
˙ ‘ ˆ tk d d ä
j“1 x0j
˙
, k “ 1, . . .",D.5. Proof of Proposition 5.6,[0],[0]
", p.
",D.5. Proof of Proposition 5.6,[0],[0]
"So for any k “ 1, . .",D.5. Proof of Proposition 5.6,[0],[0]
.,D.5. Proof of Proposition 5.6,[0],[0]
", p, if we write b̄1 “ bk, b̄2 “ tk, ā1j “ akj , ā2j “ 0, j “ 1, . . .",D.5. Proof of Proposition 5.6,[0],[0]
", d, then
νkpxq “ 2 à
i“1 b̄i
d ä j“1",D.5. Proof of Proposition 5.6,[0],[0]
"x āij j
is clearly a tropical signomial function.",D.5. Proof of Proposition 5.6,[0],[0]
Therefore ν is a tropical signomial map.,D.5. Proof of Proposition 5.6,[0],[0]
"The result for arbitrary number of layers then follows from using the same recurrence as in the proof in Section D.2, except that now the entries in the weight matrix are allowed to take real values, and the maps Hplqpxq, Gplqpxq, F plqpxq are tropical signomial maps.",D.5. Proof of Proposition 5.6,[0],[0]
Hence every layer can be written as a tropical rational signomial map νplq “ F plq mGplq.,D.5. Proof of Proposition 5.6,[0],[0]
"We prove a slightly more general result.
",D.6. Proof of Proposition 6.1,[0],[0]
Proposition D.1 (Level sets).,D.6. Proof of Proposition 6.1,[0],[0]
"Let f m g P Ratpd, 1q “ Tpx1, . . .",D.6. Proof of Proposition 6.1,[0],[0]
", xdq.
(i)",D.6. Proof of Proposition 6.1,[0],[0]
"Given a constant c ą 0, the level set B :“ tx P Rd : fpxq m gpxq “ cu
divides Rd into at most N pfq connected polyhedral regions where fpxq m gpxq ą c, and at most N pgq such regions where fpxq m gpxq ă c.
(ii)",D.6. Proof of Proposition 6.1,[0],[0]
"If c P R is such that there is no tropical monomial in fpxq that differs from any tropical monomial in gpxq by c, then the level set B is contained in a tropical hypersurface,
B Ď T pmaxtfpxq, gpxq ` cuq “ T pcd g ‘ fq.
",D.6. Proof of Proposition 6.1,[0],[0]
Proof.,D.6. Proof of Proposition 6.1,[0],[0]
"We show that the bounds on the numbers of connected positive (i.e., above c) and negative (i.e., below c) regions are as we claimed in (i).",D.6. Proof of Proposition 6.1,[0],[0]
"The tropical hypersurface of f divides Rd into N pfq convex regions C1, . . .",D.6. Proof of Proposition 6.1,[0],[0]
", CN pfq such that f is linear on each Ci.",D.6. Proof of Proposition 6.1,[0],[0]
"As g is piecewise linear and convex over Rd, f m g “ f ´ g is piecewise linear and concave on each Ci.",D.6. Proof of Proposition 6.1,[0],[0]
Since the level set tx : fpxq ´ gpxq “ cu and the superlevel set tx : fpxq ´ gpxq ě cu must be convex by the concavity of f,D.6. Proof of Proposition 6.1,[0],[0]
"´ g, there is at most one positive region in each Ci.",D.6. Proof of Proposition 6.1,[0],[0]
Therefore the total number of connected positive regions cannot exceed N pfq.,D.6. Proof of Proposition 6.1,[0],[0]
"Likewise, the tropical hypersurface of g divides Rd into N pgq convex regions on each of which f m g is convex.",D.6. Proof of Proposition 6.1,[0],[0]
"The same argument shows that the number of connected negative regions does not exceed N pgq.
",D.6. Proof of Proposition 6.1,[0],[0]
We next address (ii).,D.6. Proof of Proposition 6.1,[0],[0]
"Upon rearranging terms, the level set becomes
B “ x P Rd : fpxq “ gpxq ` c ( .
",D.6. Proof of Proposition 6.1,[0],[0]
"Since fpxq and gpxq ` c are both tropical polynomial, we have
fpxq “ b1xα1 ‘ ¨ ¨ ¨ ‘ brxαr , gpxq ` c “ c1xβ1 ‘ ¨ ¨ ¨ ‘ csxβs ,
with appropriate multiindices α1, . . .",D.6. Proof of Proposition 6.1,[0],[0]
", αr, β1, . . .",D.6. Proof of Proposition 6.1,[0],[0]
", βs, and real coefficients b1, . . .",D.6. Proof of Proposition 6.1,[0],[0]
", br, c1, . . .",D.6. Proof of Proposition 6.1,[0],[0]
", cs.",D.6. Proof of Proposition 6.1,[0],[0]
"By the assumption on the monomials, we have that x0 P B only if there exist i, j so that αi ‰ βj",D.6. Proof of Proposition 6.1,[0],[0]
and bixαi0 “ cjx βj 0 .,D.6. Proof of Proposition 6.1,[0],[0]
"This completes the proof since if we combine the monomials of fpxq and gpxq ` c by (tropical) summing them into a single tropical polynomial, maxtfpxq, gpxq ` cu, the above implies that on the level set, the value of the combined tropical polynomial is attained by at least two monomials and therefore x0 P T pmaxtfpxq, gpxq ` cuq.
",D.6. Proof of Proposition 6.1,[0],[0]
Proposition 6.1 follows immediately from Proposition D.1 since the decision boundary tx P Rd : νpxq “ s´1pcqu is a level set of the tropical rational function ν.,D.6. Proof of Proposition 6.1,[0],[0]
"The linear regions of a tropical polynomial map F P Polpd,mq are all convex but this is not necessarily the case for a tropical rational map F P Ratpd, nq.",D.7. Proof of Theorem 6.3,[0],[0]
"Take for example a bivariate real-valued function fpx, yq whose graph in R3 is a pyramid with base tpx, yq P R2 : x, y P r´1, 1su and zero everywhere else, then the linear region where f vanishes is R2ztpx, yq P R2 : x,",D.7. Proof of Theorem 6.3,[0],[0]
"y P r´1, 1su, which is nonconvex.",D.7. Proof of Theorem 6.3,[0],[0]
The nonconvexity invalidates certain geometric arguments that only apply in the convex setting.,D.7. Proof of Theorem 6.3,[0],[0]
Nevertheless there is a way to subdivide each of the nonconvex linear regions into convex ones to get ourselves back into the convex setting.,D.7. Proof of Theorem 6.3,[0],[0]
"We will start with the number of convex linear regions for tropical rational maps although later we will deduce the required results for the number of linear regions (without imposing convexity).
",D.7. Proof of Theorem 6.3,[0],[0]
We first extend the notion of tropical hypersurface to tropical rational maps:,D.7. Proof of Theorem 6.3,[0],[0]
"Given a tropical rational map F P Ratpd,mq, we define T pF q to be the boundaries between adjacent linear regions.",D.7. Proof of Theorem 6.3,[0],[0]
"When F “ pf1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", fmq P Polpd,mq, i.e., a tropical polynomial map, this set is exactly the union of tropical hypersurfaces T pfiq, i “ 1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
",m. Therefore this definition of T pF q extends Definition 3.1.
",D.7. Proof of Theorem 6.3,[0],[0]
"For a tropical rational map F , we will examine the smallest number of convex regions that form a refinement of T pF q. For brevity, we will call this the convex degree of F ; for consistency, the number of linear regions of F we will call its linear degree.",D.7. Proof of Theorem 6.3,[0],[0]
We define convex degree formally below.,D.7. Proof of Theorem 6.3,[0],[0]
We will write F |C to mean the restriction of map F to C Ď Rd.,D.7. Proof of Theorem 6.3,[0],[0]
Definition D.1.,D.7. Proof of Theorem 6.3,[0],[0]
"The convex degree of a tropical rational map F P Ratpd, nq is the minimum division of Rd into convex regions over which F is linear, i.e.
NcpF q",D.7. Proof of Theorem 6.3,[0],[0]
":“ min n : C1 Y ¨ ¨ ¨ Y Cn “ Rd, Ci convex, F |Ci linear ( .
",D.7. Proof of Theorem 6.3,[0],[0]
"Note that C1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", CNcpF q either divide Rd into the same regions as T pF q or form a refinement.
",D.7. Proof of Theorem 6.3,[0],[0]
"For m ď d, we will denote by NcpF",D.7. Proof of Theorem 6.3,[0],[0]
"| mq the maximum convex degree obtained by restricting F to an m-dimensional affine subspace in Rd, i.e.,
NcpF",D.7. Proof of Theorem 6.3,[0],[0]
"| mq :“ max NcpF |Ωq : Ω Ď Rd is an m-dimensional affine space ( .
",D.7. Proof of Theorem 6.3,[0],[0]
"For any F P Ratpd, nq, there is at least one tropical polynomial map that subdivides T pF q, and so convex degree is welldefined (e.g., if F “ pp1 m q1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", pn m qnq P Ratpd, nq, then we may choose P “ pp1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", pn, q1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", qnq P Polpd, 2nq).",D.7. Proof of Theorem 6.3,[0],[0]
"Since the linear regions of a tropical polynomial map are always convex, we have N pF q",D.7. Proof of Theorem 6.3,[0],[0]
"“ NcpF q for any F P Polpd, nq.
Let F “ pf1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", fnq P Ratpd, nq and α “ pa1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", anq P Zn.",D.7. Proof of Theorem 6.3,[0],[0]
"Consider the tropical rational function3
Fα :“ αTF “ a1f1 ` ¨ ¨ ¨ ` anfn “ n ä
j“1 f aj j P Ratpd, 1q.
",D.7. Proof of Theorem 6.3,[0],[0]
"For some α, Fα may have fewer linear regions than F , e.g, α “ p0, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", 0q.",D.7. Proof of Theorem 6.3,[0],[0]
"As such, we need the following notion.",D.7. Proof of Theorem 6.3,[0],[0]
Definition D.2.,D.7. Proof of Theorem 6.3,[0],[0]
"α “ pa1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", anq P Zn is said to be a general exponent of F P Ratpd, nq if the linear regions of Fα and the linear regions of F are identical.
",D.7. Proof of Theorem 6.3,[0],[0]
"We show that general exponent always exists for any F P Ratpd, nq and may be chosen to have all entries nonnegative.",D.7. Proof of Theorem 6.3,[0],[0]
Lemma D.2.,D.7. Proof of Theorem 6.3,[0],[0]
"Let F P Ratpd, nq.",D.7. Proof of Theorem 6.3,[0],[0]
"Then
(i) N pFαq “ N pF q if and only if α is a general exponent; (ii) F has a general exponent α P Nn.
Proof.",D.7. Proof of Theorem 6.3,[0],[0]
It follows from the definition of tropical hypersuface that T pFαq and T pF q comprise respectively the points x P Rd at which Fα and F are not differentiable.,D.7. Proof of Theorem 6.3,[0],[0]
"Hence T pFαq Ď T pF q, which implies that N pFαq ă N pF q unless T pFαq “ T pF q.",D.7. Proof of Theorem 6.3,[0],[0]
"This concludes (i).
",D.7. Proof of Theorem 6.3,[0],[0]
"For (ii), we need to show that there always exists an α P Nn such that Fα divides its domain Rd into the same set of linear regions as F .",D.7. Proof of Theorem 6.3,[0],[0]
"In other words, for every pair of adjacent linear regions of F , the pd ´ 1q-dimensional face in T pF q that separates them is also present in T pFαq and so T pFαq Ě T pF q.
Let L and M be adjacent linear regions of F .",D.7. Proof of Theorem 6.3,[0],[0]
"The differentials of F |L and F |M must have integer coordinates, i.e., dF |L, dF |M P Znˆd.",D.7. Proof of Theorem 6.3,[0],[0]
"Since L and M are distinct linear regions, we must have dF |L ‰ dF |M (or otherwise L and M can be merged into a single linear region).",D.7. Proof of Theorem 6.3,[0],[0]
"Note that the differentials of Fα|L and Fα|M are given by αTdF |L and αTdF |M .
",D.7. Proof of Theorem 6.3,[0],[0]
"To ensure the pd´ 1q-dimensional face separating L and M still exists in T pFαq, we need to choose α so that αTdF |L ‰ αTdF |M .",D.7. Proof of Theorem 6.3,[0],[0]
Observe that the solution to pdF |L,D.7. Proof of Theorem 6.3,[0],[0]
"´ dF |M qTα “ 0 is contained in a one-dimensional subspace of Rn.
Let ApF q be the collection of all pairs of adjacent linear regions of F .",D.7. Proof of Theorem 6.3,[0],[0]
"Since the set of α that degenerates two adjacent linear regions into a single one, i.e.,
S :“ ď
pL,MqPApF q
α P Nn : pdF |L ´ dF |M",D.7. Proof of Theorem 6.3,[0],[0]
q,D.7. Proof of Theorem 6.3,[0],[0]
"Tα “ 0q
(
,
is contained in a union of a finite number of hyperplanes in Rn, S cannot cover the entire lattice of nonnegative integers",D.7. Proof of Theorem 6.3,[0],[0]
Nn.,D.7. Proof of Theorem 6.3,[0],[0]
"Therefore the set Nn X pRnzSq is nonempty and any of its element is a general exponent for F .
",D.7. Proof of Theorem 6.3,[0],[0]
"Lemma D.2 shows that we may study the linear degree of a tropical rational map by studying that of a tropical rational function, for which the results in Section 3.1 apply.
",D.7. Proof of Theorem 6.3,[0],[0]
"We are now ready to prove a key result on the convex degree of composition of tropical rational maps.
",D.7. Proof of Theorem 6.3,[0],[0]
Theorem D.3.,D.7. Proof of Theorem 6.3,[0],[0]
"Let F “ pf1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", fmq P Ratpn,mq and G P Ratpd, nq.",D.7. Proof of Theorem 6.3,[0],[0]
"Define H “ ph1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", hmq P Ratpd,mq by
hi :“ fi ˝G, i “ 1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
",m.
Then N pHq ď NcpHq ď NcpF | dq ¨NcpGq.
",D.7. Proof of Theorem 6.3,[0],[0]
Proof.,D.7. Proof of Theorem 6.3,[0],[0]
Only the upper bound requires a proof.,D.7. Proof of Theorem 6.3,[0],[0]
Let k “ NcpGq.,D.7. Proof of Theorem 6.3,[0],[0]
"By the definition of NcpGq, there exist convex sets C1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", Ck Ď Rd whose union is Rd and on each of which G is linear.",D.7. Proof of Theorem 6.3,[0],[0]
So G|Ci is some affine function ρi.,D.7. Proof of Theorem 6.3,[0],[0]
"For any i,
NcpF ˝ ρiq ď",D.7. Proof of Theorem 6.3,[0],[0]
"NcpF | dq, 3This is in the sense of a tropical power but we stay consistent to our slight abuse of notation and write Fα instead of Fdα.
by the definition of NcpF | dq.",D.7. Proof of Theorem 6.3,[0],[0]
Since F ˝G,D.7. Proof of Theorem 6.3,[0],[0]
"“ F ˝ ρi on Ci, we have
NcpF ˝Gq ď",D.7. Proof of Theorem 6.3,[0],[0]
"k ÿ
i“1 NcpF ˝",D.7. Proof of Theorem 6.3,[0],[0]
"ρiq.
",D.7. Proof of Theorem 6.3,[0],[0]
"Hence
NcpF ˝Gq ď k ÿ
i“1 NcpF ˝ ρiq ď
k ÿ",D.7. Proof of Theorem 6.3,[0],[0]
i“1 NcpF,D.7. Proof of Theorem 6.3,[0],[0]
|,D.7. Proof of Theorem 6.3,[0],[0]
dq,D.7. Proof of Theorem 6.3,[0],[0]
"“ NcpF | dq ¨NcpGq.
",D.7. Proof of Theorem 6.3,[0],[0]
We now apply our observations on tropical rational functions to neural networks.,D.7. Proof of Theorem 6.3,[0],[0]
"The next lemma follows directly from Corollary 3.4.
",D.7. Proof of Theorem 6.3,[0],[0]
Lemma D.4.,D.7. Proof of Theorem 6.3,[0],[0]
Let σplq ˝ ρplq :,D.7. Proof of Theorem 6.3,[0],[0]
Rnl´1 Ñ Rnl where σplq and ρplq are the affine transformation and activation of the lth layer of a neural network.,D.7. Proof of Theorem 6.3,[0],[0]
"If d ď nl, then
Ncpσplq ˝ ρplq | dq ď d ÿ",D.7. Proof of Theorem 6.3,[0],[0]
i“0 pnl,D.7. Proof of Theorem 6.3,[0],[0]
"i q .
",D.7. Proof of Theorem 6.3,[0],[0]
Proof.,D.7. Proof of Theorem 6.3,[0],[0]
"Ncpσplq ˝ ρplq | dq is the maximum convex degree of a tropical rational map F “ pf1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", fnlq : Rd Ñ Rnl of the form
fipxq :“ σplqi ˝ ρ",D.7. Proof of Theorem 6.3,[0],[0]
plq,D.7. Proof of Theorem 6.3,[0],[0]
˝,D.7. Proof of Theorem 6.3,[0],[0]
pb1,D.7. Proof of Theorem 6.3,[0],[0]
"d xα1 , . . .",D.7. Proof of Theorem 6.3,[0],[0]
", bnl´1 d x αnl´1 q, i “ 1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", nl.
",D.7. Proof of Theorem 6.3,[0],[0]
"For a general affine transformation ρplq,
ρplqpb1 d xα1 , . . .",D.7. Proof of Theorem 6.3,[0],[0]
", bnl´1 d x αnl´1 q “ ` b11 d xα 1 1 , . . .",D.7. Proof of Theorem 6.3,[0],[0]
", b1nl d x α1nl ˘ “: Gpxq
for some α11, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", α 1 nl and b11, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", b 1 nl , and we denote this map by G : Rd Ñ Rnl .",D.7. Proof of Theorem 6.3,[0],[0]
"So fi “ σplqi ˝G. By Theorem D.3, we have Ncpσplq ˝ ρplq | dq “ Ncpσplq | dq ¨NcpGq “ Ncpσplq | dq; note that NcpGq “ 1 as G is a linear function.
",D.7. Proof of Theorem 6.3,[0],[0]
"We have thus reduced the problem to determining a bound on the convex degree of a single layer neural network with nl nodes ν “ pν1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", νnlq :",D.7. Proof of Theorem 6.3,[0],[0]
Rd Ñ Rnl .,D.7. Proof of Theorem 6.3,[0],[0]
"Let γ “ pc1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", cnlq P Nnl be a nonnegative general exponent for ν.",D.7. Proof of Theorem 6.3,[0],[0]
"Note that
nl ä j“1",D.7. Proof of Theorem 6.3,[0],[0]
ν,D.7. Proof of Theorem 6.3,[0],[0]
cj,D.7. Proof of Theorem 6.3,[0],[0]
j,D.7. Proof of Theorem 6.3,[0],[0]
“ nl ä j“1,D.7. Proof of Theorem 6.3,[0],[0]
„ˆ d ä i“1 bi d xa ` ji ˙ ‘ ˆ d ä i“1 xa ´ ji,D.7. Proof of Theorem 6.3,[0],[0]
˙ d tj cj ´,D.7. Proof of Theorem 6.3,[0],[0]
nl ä j“1,D.7. Proof of Theorem 6.3,[0],[0]
ˆ d ä i“1,D.7. Proof of Theorem 6.3,[0],[0]
xa,D.7. Proof of Theorem 6.3,[0],[0]
"´ ji ˙cj .
",D.7. Proof of Theorem 6.3,[0],[0]
"Since the last term is linear in x, we may drop it without affecting the convex degree of the entire expression.",D.7. Proof of Theorem 6.3,[0],[0]
"It remains to determine an upper bound for the number of linear regions of the tropical polynomial
hpxq “ nl ä
j“1
„ˆ d ä
i“1 bi d xa
` ji
˙ ‘ ˆ d ä
i“1 xa ´",D.7. Proof of Theorem 6.3,[0],[0]
"ji
˙ d tj cj ,
which we will obtain by counting vertices of the polytope Pphq.",D.7. Proof of Theorem 6.3,[0],[0]
"By Propositions 3.1 and 3.2 the polytope Pphq is given by a weighted Minkowski sum
nl ÿ j“1 cjP",D.7. Proof of Theorem 6.3,[0],[0]
"„ˆ d ä i“1 bi d xa ` ji ˙ ‘ ˆ d ä i“1 xa ´ ji ˙ d tj  .
",D.7. Proof of Theorem 6.3,[0],[0]
"By Proposition 3.2 again,
P „ˆ d ä
i“1 bi d xa
` ji
˙ ‘ ˆ d ä
i“1 xa ´ ji
˙ d tj  “ Conv ` VpPpfqq Y VpPpgqq ˘
where
fpxq “ d ä
i“1 bi d xa
` ji and gpxq “
ˆ",D.7. Proof of Theorem 6.3,[0],[0]
"d ä
i“1 xa ´ ji
˙
d tj
are tropical monomials.",D.7. Proof of Theorem 6.3,[0],[0]
"Therefore Ppfq, Ppgq are just points in Rd`1 and Conv ` VpPpfqq Y VpPpgqq ˘ is a line in Rd`1.",D.7. Proof of Theorem 6.3,[0],[0]
"Hence Pphq is a Minkowski sum of nl line segments in Rd`1, i.e., a zonotope, and Corollary 3.4 completes the proof.
",D.7. Proof of Theorem 6.3,[0],[0]
"Using Lemma D.4, we obtain a bound on the number of linear regions created by one layer of a neural network.
",D.7. Proof of Theorem 6.3,[0],[0]
Theorem D.5.,D.7. Proof of Theorem 6.3,[0],[0]
Let ν :,D.7. Proof of Theorem 6.3,[0],[0]
"Rd Ñ RnL be an L-layer neural network satisfying assumptions (a)–(c) with F plq, Gplq,Hplq, and νplq as defined in Proposition 5.1.",D.7. Proof of Theorem 6.3,[0],[0]
"Let nl ě d for all l “ 1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", L. Then
Ncpνp1qq “ N pGp1qq",D.7. Proof of Theorem 6.3,[0],[0]
"“ N pHp1qq “ 1, Ncpνpl`1qq ď Ncpνplqq ¨ d ÿ i“0 pnl`1",D.7. Proof of Theorem 6.3,[0],[0]
"i q .
",D.7. Proof of Theorem 6.3,[0],[0]
Proof.,D.7. Proof of Theorem 6.3,[0],[0]
"The l “ 1 case follows from the fact that Gp1qpxq “ Ap1q´ x and Hp1qpxq “ A p1q ` x` bp1q are both linear, which in turn forces Ncpνp1qq “ 1 as in the proof of Lemma D.4.",D.7. Proof of Theorem 6.3,[0],[0]
"Since νplq “ pσplq ˝ ρplqq ˝ νpl´1q, the recursive bound follows from Theorem D.3 and Lemma D.4.
",D.7. Proof of Theorem 6.3,[0],[0]
Theorem 6.3 follows from applying Theorem D.5 recursively.,D.7. Proof of Theorem 6.3,[0],[0]
"We establish, for the first time, connections between feedforward neural networks with ReLU activation and tropical geometry — we show that the family of such neural networks is equivalent to the family of tropical rational maps.",abstractText,[0],[0]
"Among other things, we deduce that feedforward ReLU neural networks with one hidden layer can be characterized by zonotopes, which serve as building blocks for deeper networks; we relate decision boundaries of such neural networks to tropical hypersurfaces, a major object of study in tropical geometry; and we prove that linear regions of such neural networks correspond to vertices of polytopes associated with tropical rational functions.",abstractText,[0],[0]
An insight from our tropical formulation is that a deeper network is exponentially more expressive than a shallow network.,abstractText,[0],[0]
Tropical Geometry of Deep Neural Networks,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2931–2937 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics
We present an analytic study on the language of news media in the context of political fact-checking and fake news detection. We compare the language of real news with that of satire, hoaxes, and propaganda to find linguistic characteristics of untrustworthy text. To probe the feasibility of automatic political fact-checking, we also present a case study based on PolitiFact.com using their factuality judgments on a 6-point scale. Experiments show that while media fact-checking remains to be an open research question, stylistic cues can help determine the truthfulness of text.",text,[0],[0]
Words in news media and political discourse have a considerable power in shaping people’s beliefs and opinions.,1 Introduction,[0],[0]
"As a result, their truthfulness is often compromised to maximize impact.",1 Introduction,[0],[0]
"Recently, fake news has captured worldwide interest, and the number of organized efforts dedicated solely to fact-checking has almost tripled since 2014.1 Organizations, such as PolitiFact.com, actively investigate and rate the veracity of comments made by public figures, journalists, and organizations.
",1 Introduction,[0],[0]
Figure 1 shows example quotes rated for truthfulness by PolitiFact.,1 Introduction,[0],[0]
"Per their analysis, one component of the two statements’ ratings is the misleading phrasing (bolded in green in the figure).",1 Introduction,[0],[0]
"For instance, in the first example, the statement is true as stated, though only because the speaker hedged their meaning with the quantifier just.",1 Introduction,[0],[0]
"In the second example, two correlated events – Brexit
1https://www.poynter.org/2017/there-are-now-114-factchecking-initiatives-in-47-countries/450477/
“By declaring that Pluto was no longer a planet, the (International Astronomical Union) put into place a planetary definition that would have even declassified Earth as a planet if it existed as far from the sun as Pluto does.”
",1 Introduction,[0],[0]
"Half TrueTrue False
-Rated Half True by PunditFact, (July 2015)
and Google search trends – are presented ambiguously as if they were directly linked.
",1 Introduction,[0],[0]
"Importantly, like above examples, most factchecked statements on PolitiFact are rated as neither entirely true nor entirely false.",1 Introduction,[0],[0]
"Analysis indicates that falsehoods often arise from subtle differences in phrasing rather than outright fabrication (Rubin et al., 2015).",1 Introduction,[0],[0]
"Compared to most prior work on deception literature that focused on binary categorization of truth and deception, political fact-checking poses a new challenge as it involves a graded notion of truthfulness.
",1 Introduction,[0],[0]
"While political fact-checking generally focuses on examining the accuracy of a single quoted statement by a public figure, the reliability of general news stories is also a concern (Connolly et al., 2016; Perrott, 2016).",1 Introduction,[0],[0]
"Figure 2 illustrates news types categorized along two dimensions: the intent of the authors (desire to deceive) and the content of the articles (true, mixed, false).
",1 Introduction,[0],[0]
"2931
In this paper, we present an analytic study characterizing the language of political quotes and news media written with varying intents and degrees of truth.",1 Introduction,[0],[0]
"We also investigate graded deception detection, determining the truthfulness on a 6-point scale using the political fact-checking database available at PolitiFact.2",1 Introduction,[0],[0]
"News Corpus with Varying Reliability To analyze linguistic patterns across different types of articles, we sampled standard trusted news articles from the English Gigaword corpus and crawled articles from seven different unreliable news sites of differing types.",2 Fake News Analysis,[0],[0]
"Table 1 displays sources identified under each type according to US News & World Report.3 These news types include: • Satire: mimics real news but still cues the reader
that it is not meant to be taken seriously • Hoax: convinces readers of the validity of a
paranoia-fueled story • Propaganda: misleads readers so that they be-
lieve a particular political/social agenda Unlike hoaxes and propaganda, satire is intended to be notably different from real news so that audiences will recognize the humorous intent.",2 Fake News Analysis,[0],[0]
"Hoaxes and satire are more likely to invent stories, while propaganda frequently combines truths, falsehoods, and ambiguities to confound readers.
",2 Fake News Analysis,[0],[0]
"To characterize differences between news types, we applied various lexical resources to trusted and fake news articles.",2 Fake News Analysis,[0],[0]
We draw lexical resources from prior works in communication theory and stylistic analysis in computational linguistics.,2 Fake News Analysis,[0],[0]
"We tokenize
2All resources created for this paper including corpus of news articles from unreliable sources, collection of Politifact ratings, and compiled Wiktionary lexicons have been made publicly available at homes.cs.washington. edu/˜hrashkin/factcheck.html
3www.usnews.com/news/national-news/articles/2016-1114/avoid-these-fake-news-sites-at-all-costs
the text with NLTK (Bird et al., 2009) and compute per-document count for each lexicon, and report averages per article of each type.
",2 Fake News Analysis,[0],[0]
"First among these lexicons is the Linguistic Inquiry and Word Count (LIWC), a lexicon widely used in social science studies (Pennebaker et al., 2015).",2 Fake News Analysis,[0],[0]
"In addition, we estimate the use of strongly and weakly subjective words with a sentiment lexicon (Wilson et al., 2005).",2 Fake News Analysis,[0],[0]
Subjective words can be used to dramatize or sensationalize a news story.,2 Fake News Analysis,[0],[0]
"We also use lexicons for hedging from (Hyland, 2015) because hedging can indicate vague, obscuring language.",2 Fake News Analysis,[0],[0]
"Lastly, we introduce intensifying lexicons that we crawled from Wiktionary based on a hypothesis that fake news articles try to enliven stories to attract readers.",2 Fake News Analysis,[0],[0]
"We compiled five lists from Wiktionary of words that imply a degree a dramatization (comparatives, superlatives, action adverbs, manner adverbs, and modal adverbs) and measured their presence.
",2 Fake News Analysis,[0],[0]
Discussion Table 2 summarizes the ratio of averages between unreliable news and truthful news for a handful of the measured features.,2 Fake News Analysis,[0],[0]
"Ratios greater than one denote features more prominent in fake news, and ratios less than one denote features more prominent in truthful news.",2 Fake News Analysis,[0],[0]
"The ratios between unreliable/reliable news reported are statistically significant (p < 0.01) with Welsch t-test after Bonferroni correction.
",2 Fake News Analysis,[0],[0]
Our results show that first-person and secondperson pronouns are used more in less reliable or deceptive news types.,2 Fake News Analysis,[0],[0]
"This contrasts studies in other domains (Newman et al., 2003), which found fewer self-references in people telling lies about their personal opinions.",2 Fake News Analysis,[0],[0]
"Unlike that domain, news writers are trying to appear indifferent.",2 Fake News Analysis,[0],[0]
"Editors at trustworthy sources are possibly more
rigorous about removing language that seems too personal, which is one reason why this result differs from other lie detection domains.",2 Fake News Analysis,[0],[0]
"This finding instead corroborates previous work in written domains found by Ott et al. (2011) and Rayson et al. (2001), who found that such pronouns were indicative of imaginative writing.",2 Fake News Analysis,[0],[0]
"Perhaps imaginative storytelling domains is a closer match to detecting unreliable news than lie detection on opinions.
",2 Fake News Analysis,[0],[0]
"Our results also show that words that can be used to exaggerate – subjectives, superlatives, and modal adverbs – are all used more by fake news.",2 Fake News Analysis,[0],[0]
"Words used to offer concrete figures – comparatives, money, and numbers – appear more in truthful news.",2 Fake News Analysis,[0],[0]
"This also builds on previous findings by Ott et al. (2011) on the difference between superlative/comparative usage.
",2 Fake News Analysis,[0],[0]
"Trusted sources are more likely to use assertive words and less likely to use hedging words, indicating that they are less vague about describing events, as well.",2 Fake News Analysis,[0],[0]
"This relates to psychology theories (Buller and Burgoon, 1996) that deceivers show more “uncertainty and vagueness” and “indirect forms of expression”.",2 Fake News Analysis,[0],[0]
"Similarly, the trusted sources use the hear category words more often, possibly indicating that they are citing primary sources more often.
",2 Fake News Analysis,[0],[0]
"The last column in Table 2 shows the fake news type that uses the corresponding lexicon most
prominently.",2 Fake News Analysis,[0],[0]
We found that one distinctive feature of satire compared to other types of untrusted news is its prominent use of adverbs.,2 Fake News Analysis,[0],[0]
Hoax stories tend to use fewer superlatives and comparatives.,2 Fake News Analysis,[0],[0]
"In contrast, compared to other types of fake news, propaganda uses relatively more assertive verbs and superlatives.
",2 Fake News Analysis,[0],[0]
"News Reliability Prediction We study the feasibility of predicting the reliability of the news article into four categories: trusted, satire, hoax, or propaganda.",2 Fake News Analysis,[0],[0]
"We split our collected articles into balanced training (20k total articles from the Onion, American News, The Activist, and the Gigaword news excluding ‘APW’, ‘WPB’ sources) and test sets (3k articles from the remaining sources).",2 Fake News Analysis,[0],[0]
"Because articles in the training and test set come from different sources, the models must classify articles without relying on author-specific cues.",2 Fake News Analysis,[0],[0]
We also use 20% of the training articles as an in-domain development set.,2 Fake News Analysis,[0],[0]
"We trained a Max-Entropy classifier with L2 regularization on n-gram tf-idf feature vectors (up to trigrams).4
The model achieves F1 scores of 65% on the out-of-domain test set (Table 3).",2 Fake News Analysis,[0],[0]
"This is a promising result as it is much higher than random, but still leaves room for improvement compared to the
4N-gram tfidf vectors have acted as competitive means of cross-domain text-classification.",2 Fake News Analysis,[0],[0]
"Zhang et al. (2015) found that for data sets smaller than a million examples, this was the best model, outperforming neural models.
",2 Fake News Analysis,[0],[0]
"performance on the development set consisting of articles from in-domain sources.
",2 Fake News Analysis,[0],[0]
We examined the 50 highest weighted n-gram features in the MaxEnt classifier for each class.,2 Fake News Analysis,[0],[0]
"The highest weighted n-grams for trusted news were often specific places (e.g., “washington”) or times (“on monday”).",2 Fake News Analysis,[0],[0]
"Many of the highest weighted from satire were vaguely facetious hearsay (“reportedly”, “confirmed”).",2 Fake News Analysis,[0],[0]
"For hoax articles, heavily weighted features included divisive topics (“liberals”, “trump”) and dramatic cues (“breaking”).",2 Fake News Analysis,[0],[0]
"Heavily weighted features for propaganda tend towards abstract generalities (“truth”, “freedom”) as well as specific issues (“vaccines”, “syria”).",2 Fake News Analysis,[0],[0]
"Interestingly, “youtube” and “video” are highly weighted for the propaganda and hoax classes respectively; indicating that they often rely on video clips as sources.",2 Fake News Analysis,[0],[0]
Politifact Data Related to the issue of identifying the truthfulness of a news article is the factchecking of individual statements made by public figures.,3 Predicting Truthfulness,[0],[0]
"Misleading statements can also have a variety of intents and levels of reliability depending on whom is making the statement.
",3 Predicting Truthfulness,[0],[0]
PolitiFact5 is a site led by Tampa Bay Times journalists who actively fact-check suspicious statements.,3 Predicting Truthfulness,[0],[0]
One unique quality of PolitiFact is that each quote is evaluated on a 6-point scale of truthfulness ranging from “True” (factual) to “Pantson-Fire False” (absurdly false).,3 Predicting Truthfulness,[0],[0]
"This scale allows for distinction between categories like mostly true (the facts are correct but presented in an incomplete manner) or mostly false (the facts are not correct but are connected to a small kernel of truth).
",3 Predicting Truthfulness,[0],[0]
"We collected labelled statements from PolitiFact and its spin-off sites (PunditFact, etc.)",3 Predicting Truthfulness,[0],[0]
"(10,483 statements in total).",3 Predicting Truthfulness,[0],[0]
"We analyze a subset of 4,366 statements that are direct quotes by the original speaker.",3 Predicting Truthfulness,[0],[0]
"The distributions of ratings on the PolitiFact scale for this subset are shown
5www.politifact.com/
in Table 4.",3 Predicting Truthfulness,[0],[0]
"Most statements are labeled as neither completely true nor false.
",3 Predicting Truthfulness,[0],[0]
We formulate a fine-grained truthfulness prediction task with Politifact data.,3 Predicting Truthfulness,[0],[0]
"We split quotes into training/development/test set of {2575, 712, 1074} statements, respectively, so that all of each speaker’s quotes are in a single set.",3 Predicting Truthfulness,[0],[0]
"Given a statement, the model returns a rating for how reliable the statement is (Politifact ratings are used as gold labels).",3 Predicting Truthfulness,[0],[0]
"We ran the experiment in two settings, one considering all 6 classes and the other considering only 2 (treating the top three truthful ratings as true and the lower three as false).
",3 Predicting Truthfulness,[0],[0]
"Model We trained an LSTM model (Hochreiter and Schmidhuber, 1997)",3 Predicting Truthfulness,[0],[0]
that takes the sequence of words as the input and predicts the Politifact rating.,3 Predicting Truthfulness,[0],[0]
"We also compared this model with Maximum Entropy (MaxEnt) and Naive Bayes models, frequently used for text categorization.
",3 Predicting Truthfulness,[0],[0]
"For input to the MaxEnt and Naive Bayes models, we tried two variants: one with the word tfidf vectors as input, and one with the LIWC measurements concatenated to the tf-idf vectors.",3 Predicting Truthfulness,[0],[0]
"For the LSTM model, we used word sequences as input and also a version where LSTM output is concatenated with LIWC feature vectors before undergoing the activation layer.",3 Predicting Truthfulness,[0],[0]
"The LSTM word embeddings are initialized with 100-dim embeddings from GLOVE (Pennington et al., 2014) and fine-tuned during training.",3 Predicting Truthfulness,[0],[0]
The LSTM was implemented with Theano and Keras with 300-dim hidden state and a batch size of 64.,3 Predicting Truthfulness,[0],[0]
"Training was done with ADAM to minimize categorical crossentropy loss over 10 epochs.
",3 Predicting Truthfulness,[0],[0]
Classifier Results Table 5 summarizes the performance on the development set.,3 Predicting Truthfulness,[0],[0]
We report macro averaged F1 score in all tables.,3 Predicting Truthfulness,[0],[0]
"The LSTM outperforms the other models when only using text as input; however the other two models improve substantially with adding LIWC features, particu-
larly in the case of the multinomial naive Bayes model.",3 Predicting Truthfulness,[0],[0]
"In contrast, the LIWC features do not improve the neural model much, indicating that some of this lexical information is perhaps redundant to what the model was already learning from text.
",3 Predicting Truthfulness,[0],[0]
We report results on the test set in Table 6.,3 Predicting Truthfulness,[0],[0]
We again find that LIWC features improves MaxEnt and NB models to perform similarly to the LSTM model.,3 Predicting Truthfulness,[0],[0]
"As in the dev. set results, the LIWC features do not improve the LSTM’s performance, and even seem to hurt the performance slightly.",3 Predicting Truthfulness,[0],[0]
"Deception Detection Psycholinguistic work in interpersonal deception theory (Buller and Burgoon, 1996) has postulated that certain speech patterns can be signs of a speaker trying to purposefully obscure the truth.",4 Related Work,[0],[0]
"Hedge words and other vague qualifiers (Choi et al., 2012; Recasens et al., 2013), for example, may add indirectness to a statement that obscures its meaning.
",4 Related Work,[0],[0]
"Linguistic aspects deception detection has been well-studied in a variety of NLP applications (Ott et al., 2011; Mihalcea and Strapparava, 2009; Jindal and Liu, 2008; Girlea et al., 2016; Zhou et al., 2004).",4 Related Work,[0],[0]
"In these applications, people purposefully tell lies to receive an extrinsic payoff.",4 Related Work,[0],[0]
"In our study, we compare varying types of unreliable news source, created with differing intents and levels of veracity.
",4 Related Work,[0],[0]
"Fact-Checking and Fake News There is research in political science exploring how effective fact-checking is at improving people’s awareness
(Lord et al., 1979; Thorson, 2016; Nyhan and Reifler, 2015).",4 Related Work,[0],[0]
"Prior computational works (Vlachos and Riedel, 2014; Ciampaglia et al., 2015) have proposed fact-checking through entailment from knowledge bases.",4 Related Work,[0],[0]
"Our work takes a more linguistic approach, performing lexical analysis over varying types of falsehood.
",4 Related Work,[0],[0]
"Biyani et al. (2016) examine the unique linguistic styles found in clickbait articles, and Kumar et al. (2016) also characterize hoax documents on Wikipedia.",4 Related Work,[0],[0]
"The differentiation between these fake news types is also proposed in previous work (Rubin et al., 2015).",4 Related Work,[0],[0]
"Our paper extends this work by offering a quantitative study of linguistic differences found in articles of different types of fake news, and build predictive models for graded deception across multiple domains – PolitiFact and news articles.",4 Related Work,[0],[0]
"More recent work (Wang, 2017) has also investigated PolitiFact data though they investigated meta-data features for prediction whereas our investigation is focused on linguistic analysis through stylistic lexicons.",4 Related Work,[0],[0]
"We examine truthfulness and its contributing linguistic attributes across multiple domains e.g., online news sources and public statements.",5 Conclusion,[0],[0]
"We perform multiple prediction tasks on fact-checked statements of varying levels of truth (graded deception) as well as a deeper linguistic comparison of differing types of fake news e.g., propaganda, satire and hoaxes.",5 Conclusion,[0],[0]
We have shown that factchecking is indeed a challenging task but that various lexical features can contribute to our understanding of the differences between more reliable and less reliable digital news sources.,5 Conclusion,[0],[0]
We would like to thank anonymous reviewers for providing insightful feedback.,6 Acknowledgements,[0],[0]
"The research described in this paper was conducted under the Laboratory Directed Research and Development Program at Pacific Northwest National Laboratory, a multiprogram national laboratory operated by Battelle for the U.S. Department of Energy, the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE-1256082, in part by NSF grants IIS-1408287, IIS-1714566, and gifts by Google and Facebook.",6 Acknowledgements,[0],[0]
We present an analytic study on the language of news media in the context of political fact-checking and fake news detection.,abstractText,[0],[0]
"We compare the language of real news with that of satire, hoaxes, and propaganda to find linguistic characteristics of untrustworthy text.",abstractText,[0],[0]
"To probe the feasibility of automatic political fact-checking, we also present a case study based on PolitiFact.com using their factuality judgments on a 6-point scale.",abstractText,[0],[0]
"Experiments show that while media fact-checking remains to be an open research question, stylistic cues can help determine the truthfulness of text.",abstractText,[0],[0]
Truth of Varying Shades: Analyzing Language in Fake News and Political Fact-Checking,title,[0],[0]
"Deep Neural Networks (LeCun et al., 2015) have been successful on numerous difficult machine learning tasks, including image recognition(Krizhevsky et al., 2012; Donahue et al., 2015), speech recognition(Hinton et al., 2012) and natural language processing(Collobert et al., 2011;
",1. Introduction,[0],[0]
"*Equal contribution 1Massachusetts Institute of Technology 2New York University, Facebook AI Research.",1. Introduction,[0],[0]
"Correspondence to: Li Jing <ljing@mit.edu>, Yichen Shen <ycshen@mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Bahdanau et al., 2014; Sutskever et al., 2014).",1. Introduction,[0],[0]
"However, deep neural networks can suffer from vanishing and exploding gradient problems(Hochreiter, 1991; Bengio et al., 1994), which are known to be caused by matrix eigenvalues far from unity being raised to large powers.",1. Introduction,[0],[0]
"Because the severity of these problems grows with the the depth of a neural network, they are particularly grave for Recurrent Neural Networks (RNNs), whose recurrence can be equivalent to thousands or millions of equivalent hidden layers.
",1. Introduction,[0],[0]
Several solutions have been proposed to solve these problems for RNNs.,1. Introduction,[0],[0]
"Long Short Term Memory (LSTM) networks (Hochreiter & Schmidhuber, 1997), which help RNNs contain information inside hidden layers with gates, remains one of the the most popular RNN implementations.",1. Introduction,[0],[0]
"Other recently proposed methods such as GRUs(Cho et al., 2014) and Bidirectional RNNs (Berglund et al., 2015) also perform well in numerous applications.",1. Introduction,[0],[0]
"However, none of these approaches has fundamentally solved the vanishing and exploding gradient problems, and gradient clipping is often required to keep gradients in a reasonable range.
",1. Introduction,[0],[0]
"A recently proposed solution strategy is using orthogonal hidden weight matrices or their complex generalization (unitary matrices) (Saxe et al., 2013; Le et al., 2015; Arjovsky et al., 2015; Henaff et al., 2016), because all their eigenvalues will then have absolute values of unity, and can safely be raised to large powers.",1. Introduction,[0],[0]
"This has been shown to help both when weight matrices are initialized to be unitary (Saxe et al., 2013; Le et al., 2015) and when they are kept unitary during training, either by restricting them to a more tractable matrix subspace (Arjovsky et al., 2015) or by alternating gradient-descent steps with projections onto the unitary subspace (Wisdom et al., 2016).
",1. Introduction,[0],[0]
"In this paper, we will first present an Efficient Unitary Neural Network (EUNN) architecture that parametrizes the entire space of unitary matrices in a complete and computationally efficient way, thereby eliminating the need for time-consuming unitary subspace-projections.",1. Introduction,[0],[0]
Our architecture has a wide range of capacity-tunability to represent subspace unitary models by fixing some of our parameters; the above-mentioned unitary subspace models correspond to special cases of our architecture.,1. Introduction,[0],[0]
"We also implemented
an EUNN with an earlier introduced FFT-like architecture which efficiently approximates the unitary space with minimum number of required parameters(Mathieu & LeCun, 2014b).
",1. Introduction,[0],[0]
"We then benchmark EUNN’s performance on both simulated and real tasks: the standard copying task, the pixelpermuted MNIST task, and speech prediction with the TIMIT dataset (Garofolo et al., 1993).",1. Introduction,[0],[0]
We show that our EUNN algorithm with an O(N) hidden layer size can compute up to the entire N × N gradient matrix using O(1) computational steps and memory access per parameter.,1. Introduction,[0],[0]
"This is superior to theO(N) computational complexity of the existing training method for a full-space unitary network (Wisdom et al., 2016) and O(logN) more efficient than the subspace Unitary RNN(Arjovsky et al., 2015).",1. Introduction,[0],[0]
"A recurrent neural network takes an input sequence and uses the current hidden state to generate a new hidden state during each step, memorizing past information in the hidden layer.",2.1. Basic Recurrent Neural Networks,[0],[0]
"We first review the basic RNN architecture.
",2.1. Basic Recurrent Neural Networks,[0],[0]
"Consider an RNN updated at regular time intervals t = 1, 2, ... whose input is the sequence of vectors x(t) whose hidden layer h(t) is updated according to the following rule:
h(t) = σ(Ux(t) +Wh(t−1)), (1)
where σ is the nonlinear activation function.",2.1. Basic Recurrent Neural Networks,[0],[0]
"The output is generated by
y(t)",2.1. Basic Recurrent Neural Networks,[0],[0]
"= Wh(t) + b, (2)
where b is the bias vector for the hidden-to-output layer.",2.1. Basic Recurrent Neural Networks,[0],[0]
"For t = 0, the hidden layer h(0) can be initialized to some special vector or set as a trainable variable.",2.1. Basic Recurrent Neural Networks,[0],[0]
"For convenience of notation, we define z(t) = Ux(t) + Wh(t−1) so that h(t) = σ(z(t)).",2.1. Basic Recurrent Neural Networks,[0],[0]
"When training the neural network to minimize a cost function C that depends on a parameter vector a, the gradient descent method updates this vector to a − λ∂C∂a , where λ is a fixed learning rate and ∂C∂a ≡ ∇C.",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"For an RNN, the vanishing or exploding gradient problem is most significant during back propagation from hidden to hidden layers, so we will only focus on the gradient for hidden layers.",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"Training the input-to-hidden and hidden-to-output matrices is relatively trivial once the hidden-to-hidden matrix has been successfully optimized.
",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"In order to evaluate ∂C∂Wij , one first computes the derivative
∂C ∂h(t) using the chain rule:
∂C
∂h(t) =
∂C ∂h(T ) ∂h(T ) ∂h(t) (3)
= ∂C
∂h(T )",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"T−1∏ k=t ∂h(k+1) ∂h(k) (4)
= ∂C
∂h(T )",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"T−1∏ k=t D(k)W, (5)
where D(k) = diag{σ′(Ux(k) + Wh(k−1))} is the Jacobian matrix of the pointwise nonlinearity.",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"For large times T , the term ∏ W plays a significant role.",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"As long as the eigenvalues of D(k) are of order unity, then if W has eigenvalues λi 1, they will cause gradient explosion | ∂C ∂h(T )
| → ∞, while if W has eigenvalues λi 1, they can cause gradient vanishing, | ∂C
∂h(T )",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
| → 0.,2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"Either situation
prevents the RNN from working efficiently.",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"In a breakthrough paper, Arjovsky, Shah & Bengio (Arjovsky et al., 2015) showed that unitary RNNs can overcome the exploding and vanishing gradient problems and perform well on long term memory tasks if the hiddento-hidden matrix in parametrized in the following unitary form:
W = D3T2F−1D2ΠT1FD1.",3.1. Partial Space Unitary RNNs,[0],[0]
"(6)
Here D1,2,3 are diagonal matrices with each element eiωj , j = 1, 2, · · · , n. T1,2 are reflection matrices, and T = I − 2 v̂v̂ †
||v̂||2 , where v̂ is a vector with each of its entries as a parameter to be trained.",3.1. Partial Space Unitary RNNs,[0],[0]
Π is a fixed permutation matrix.,3.1. Partial Space Unitary RNNs,[0],[0]
F and F−1 are Fourier and inverse Fourier transform matrices respectively.,3.1. Partial Space Unitary RNNs,[0],[0]
"Since each factor matrix here is unitary, the product W is also a unitary matrix.
",3.1. Partial Space Unitary RNNs,[0],[0]
"This model uses O(N) parameters, which spans merely a part of the whole O(N2)-dimensional space of unitary N × N matrices to enable computational efficiency.",3.1. Partial Space Unitary RNNs,[0],[0]
"Several subsequent papers have tried to expand the space to O(N2) in order to achieve better performance, as summarized below.",3.1. Partial Space Unitary RNNs,[0],[0]
"In order to maximize the power of Unitary RNNs, it is preferable to have the option to optimize the weight matrix W over the full space of unitary matrices rather than a subspace as above.",3.2. Full Space Unitary RNNs,[0],[0]
"A straightforward method for implementing this is by simply updating W with standard backpropagation and then projecting the resulting matrix (which will typically no longer be unitary) back onto to the space
of unitary matrices.",3.2. Full Space Unitary RNNs,[0],[0]
"Defining Gij ≡ ∂C∂Wij as the gradient with respect to W, this can be implemented by the procedure defined by (Wisdom et al., 2016):
A(t) ≡ G(t) † W(t) −W(t) † G(k), (7) W(t+1) ≡",3.2. Full Space Unitary RNNs,[0],[0]
"( I + λ
2 A(t)
)−1",3.2. Full Space Unitary RNNs,[0],[0]
"( I− λ
2 A(t)
) W(t).(8)
",3.2. Full Space Unitary RNNs,[0],[0]
"This method shows that full space unitary networks are superior on many RNN tasks (Wisdom et al., 2016).",3.2. Full Space Unitary RNNs,[0],[0]
"A key limitation is that the back-propation in this method cannot avoid N -dimensional matrix multiplication, incurring O(N3) computational cost.",3.2. Full Space Unitary RNNs,[0],[0]
"In the following, we first describe a general parametrization method able to represent arbitrary unitary matrices with up to N2 degrees of freedom.",4. Efficient Unitary Neural Network (EUNN) Architectures,[0],[0]
"We then present an efficient algorithm for this parametrization scheme, requiring only O(1) computational and memory access steps to obtain the gradient for each parameter.",4. Efficient Unitary Neural Network (EUNN) Architectures,[0],[0]
"Finally, we show that our scheme performs significantly better than the above mentioned methods on a few well-known benchmarks.",4. Efficient Unitary Neural Network (EUNN) Architectures,[0],[0]
"Any N × N unitary matrix WN can be represented as a product of rotation matrices {Rij} and a diagonal matrix D, such that WN = D ∏N i=2 ∏i−1",4.1. Unitary Matrix Parametrization,[0],[0]
"j=1 Rij , where Rij is defined as the N -dimensional identity matrix with the elements Rii, Rij , Rji and Rjj replaced as follows (Reck et al., 1994; Clements et al., 2016):(
Rii Rij Rji Rjj
) =",4.1. Unitary Matrix Parametrization,[0],[0]
"( eiφij cos θij −eiφij sin θij
sin θij cos θij
) .",4.1. Unitary Matrix Parametrization,[0],[0]
"(9)
where θij and φij are unique parameters corresponding to Rij.",4.1. Unitary Matrix Parametrization,[0],[0]
"Each of these matrices performs a U(2) unitary transformation on a two-dimensional subspace of the Ndimensional Hilbert space, leaving an (N−2)-dimensional subspace unchanged.",4.1. Unitary Matrix Parametrization,[0],[0]
"In other words, a series of U(2) rotations can be used to successively make all off-diagonal elements of the given N × N unitary matrix zero.",4.1. Unitary Matrix Parametrization,[0],[0]
This generalizes the familiar factorization of a 3D rotation matrix into 2D rotations parametrized by the three Euler angles.,4.1. Unitary Matrix Parametrization,[0],[0]
"To provide intuition for how this works, let us briefly describe a simple way of doing this that is similar to Gaussian elimination by finishing one column at a time.",4.1. Unitary Matrix Parametrization,[0],[0]
"There are infinitely many alternative decomposition schemes as well; Fig. 1 shows two that are particularly convenient to implement in software (and even in neuromorphic hardware (Shen et al., 2016)).",4.1. Unitary Matrix Parametrization,[0],[0]
"The unitary matrix WN is multiplied from the right by a succession of unitary matrices
RNj for j = N − 1, · · · , 1.",4.1. Unitary Matrix Parametrization,[0],[0]
"Once all elements of the last row except the one on the diagonal are zero, this row will not be affected by later transformations.",4.1. Unitary Matrix Parametrization,[0],[0]
"Since all transformations are unitary, the last column will then also contain only zeros except on the diagonal:
WNRN,N−1RN,N−2 · ·RN,1 = (
WN−1 0 0",4.1. Unitary Matrix Parametrization,[0],[0]
"eiwN
) (10)
The effective dimensionality of the the matrix W is thus reduced toN−1.",4.1. Unitary Matrix Parametrization,[0],[0]
"The same procedure can then be repeated N − 1 times until the effective dimension of W is reduced to 1, leaving us with a diagonal matrix:1
WNRN,N−1RN,N−2 · · ·Ri,jRi,j−1 · · ·R3,1R2,1 = D, (11)
where D is a diagonal matrix whose diagonal elements are eiwj , from which we can write the direct representation of WN as
WN = DR −1 2,1R −1 3,1 . .",4.1. Unitary Matrix Parametrization,[0],[0]
.R −1,4.1. Unitary Matrix Parametrization,[0],[0]
"N,N−2R −1",4.1. Unitary Matrix Parametrization,[0],[0]
"N,N−1
= DR′2,1R ′ 3,1 . .",4.1. Unitary Matrix Parametrization,[0],[0]
.R ′,4.1. Unitary Matrix Parametrization,[0],[0]
"N,N−2R ′ N,N−1.",4.1. Unitary Matrix Parametrization,[0],[0]
"(12)
where
R′ij = R(−θij ,−φij) = R(θij , φij)−1 = R−1ij (13)
1Note that Gaussian Elimination would make merely the upper triangle of a matrix vanish, requiring a subsequent series of rotations (complete Gauss-Jordan Elimination) to zero the lower triangle.",4.1. Unitary Matrix Parametrization,[0],[0]
"We need no such subsequent series because since W is unitary: it is easy to show that if a unitary matrix is triangular, it must be diagonal.
",4.1. Unitary Matrix Parametrization,[0],[0]
"This parametrization thus involves N(N − 1)/2 different θij-values, N(N − 1)/2 different φij-values and N different wi-values, combining to N2 parameters in total and spans the entire unitary space.",4.1. Unitary Matrix Parametrization,[0],[0]
"Note we can always fix a portion of our parameters, to span only a subset of unitary space – indeed, our benchmark test below will show that for certain tasks, full unitary space parametrization is not necessary.",4.1. Unitary Matrix Parametrization,[0],[0]
2,4.1. Unitary Matrix Parametrization,[0],[0]
"The representation in Eq. 12 can be made more compact by reordering and grouping specific rotational matrices, as was shown in the optical community (Reck et al., 1994; Clements et al., 2016) in the context of universal multiport interferometers.",4.2. Tunable space implementation,[0],[0]
"For example (Clements et al., 2016), a unitary matrix can be decomposed as
WN = D ( R (1) 1,2R (1) 3,4 . .",4.2. Tunable space implementation,[0],[0]
.R,4.2. Tunable space implementation,[0],[0]
"(1) N/2−1,N/2 )",4.2. Tunable space implementation,[0],[0]
"× ( R
(2) 2,3R (2) 4,5 . .",4.2. Tunable space implementation,[0],[0]
.R,4.2. Tunable space implementation,[0],[0]
"(2) N/2−2,N/2−1 )",4.2. Tunable space implementation,[0],[0]
"× . . .
",4.2. Tunable space implementation,[0],[0]
= DF (1) A F (2) B . .,4.2. Tunable space implementation,[0],[0]
".F (L) B , (14)
",4.2. Tunable space implementation,[0],[0]
"where every
F (l) A = R (l) 1,2R (l) 3,4 . .",4.2. Tunable space implementation,[0],[0]
.R,4.2. Tunable space implementation,[0],[0]
"(l) N/2−1,N/2
is a block diagonal matrix, with N angle parameters in total, and
",4.2. Tunable space implementation,[0],[0]
F (l) B = R,4.2. Tunable space implementation,[0],[0]
"(l) 2,3R (l) 4,5 . .",4.2. Tunable space implementation,[0],[0]
.R,4.2. Tunable space implementation,[0],[0]
"(l) N/2−2,N/2−1
withN−1 parameters, as is schematically shown in Fig.",4.2. Tunable space implementation,[0],[0]
1a.,4.2. Tunable space implementation,[0],[0]
"By choosing different values for L , WN will span a different subspace of the unitary space.",4.2. Tunable space implementation,[0],[0]
"Specifically,when L = N , WN will span the entire unitary space.
",4.2. Tunable space implementation,[0],[0]
"Following this physics-inspired scheme, we decompose our unitary hidden-to-hidden layer matrix W as
W = DF (1) A F (2) B F (3) A F (4) B · · ·F (L) B .",4.2. Tunable space implementation,[0],[0]
(15),4.2. Tunable space implementation,[0],[0]
"Inspired by (Mathieu & LeCun, 2014a), an alternative way to organize the rotation matrices is implementing an FFTstyle architecture.",4.3. FFT-style approximation,[0],[0]
"Instead of using adjacent rotation matrices, each F here performs a certain distance pairwise rotations as shown in Fig.",4.3. FFT-style approximation,[0],[0]
"1b:
W = DF1F2F3F4 · · ·Flog(N).",4.3. FFT-style approximation,[0],[0]
"(16)
",4.3. FFT-style approximation,[0],[0]
"The rotation matrices in Fi are performed between pairs of coordinates
(2pk + j, p(2k + 1) + j) (17)
2Our preliminary experimental tests even suggest that a fullcapacity unitary RNN is even undesirable for some tasks.
where p = N2i , k ∈ {0, ..., 2 i−1} and j ∈ {1, ..., p}.",4.3. FFT-style approximation,[0],[0]
"This requires only log(N) matrices, so there are a total of N log(N)/2 rotational pairs.",4.3. FFT-style approximation,[0],[0]
"This is also the minimal number of rotations that can have all input coordinates interacting with each other, providing an approximation of arbitrary unitary matrices.",4.3. FFT-style approximation,[0],[0]
"To implement this decomposition efficiently in an RNN, we apply vector element-wise multiplications and permutations: we evaluate the product Fx as
Fx = v1 ∗ x + v2 ∗ permute(x) (18)
where ∗ represents element-wise multiplication, F refers to general rotational matrices such as FA/B in Eq. 14 and Fi in Eq. 16.",4.4. Efficient implementation of rotation matrices,[0],[0]
"For the case of the tunable-space implementation, if we want to implement F(l)A in Eq. 14, we define v and the permutation as follows:
v1 = (e iφ (l) 1 cos θ (l) 1 , cos θ (l) 1 , e iφ (l) 2",4.4. Efficient implementation of rotation matrices,[0],[0]
"cos θ (l) 2 , cos θ (l) 2 , · · · )
v2 = (−eiφ (l) 1 sin θ",4.4. Efficient implementation of rotation matrices,[0],[0]
"(l) 1 , sin θ (l) 1 ,−eiφ (l) 2 sin θ2, sin θ (l) 2 , · · · )
",4.4. Efficient implementation of rotation matrices,[0],[0]
permute(x) =,4.4. Efficient implementation of rotation matrices,[0],[0]
"(x2, x1, x4, x3, x6, x5, · · · ).
",4.4. Efficient implementation of rotation matrices,[0],[0]
"For the FFT-style approach, if we want to implement F1 in Eq 16, we define v and the permutation as follows:
v1 = (e iφ (l) 1",4.4. Efficient implementation of rotation matrices,[0],[0]
"cos θ (l) 1 , e iφ (l) 2 cos θ (l) 2 , · · · , cos θ (l) 1 , · · · )
v2 = (−eiφ (l) 1 sin θ",4.4. Efficient implementation of rotation matrices,[0],[0]
"(l) 1 ,−eiφ (l) 2 sin θ2, · · · , sin θ(l)1 , · · · )
",4.4. Efficient implementation of rotation matrices,[0],[0]
permute(x) =,4.4. Efficient implementation of rotation matrices,[0],[0]
"(xn 2 +1 , xn 2 +2 · · ·xn, x1, x2 · · · ).
",4.4. Efficient implementation of rotation matrices,[0],[0]
"In general, the pseudocode for implementing operation F is as follows:
Algorithm 1 Efficient implementation for F with parameter θi and φi.
",4.4. Efficient implementation of rotation matrices,[0],[0]
"Input: input x, size N ; parameters θ and φ, size N/2; constant permuatation index list ind1 and ind2.",4.4. Efficient implementation of rotation matrices,[0],[0]
"Output: output y, size N .",4.4. Efficient implementation of rotation matrices,[0],[0]
"v1← concatenate(cos θ, cos θ * exp(iφ))",4.4. Efficient implementation of rotation matrices,[0],[0]
v2← concatenate(sin,4.4. Efficient implementation of rotation matrices,[0],[0]
"θ, - sin θ * exp(iφ)) v1← permute(v1, ind1) v2← permute(v2, ind1) y← v1 ∗ x + v2 ∗ permute(x, ind2)
",4.4. Efficient implementation of rotation matrices,[0],[0]
"Note that ind1 and ind2 are different for different F.
From a computational complexity viewpoint, since the operations ∗ and permute take O(N) computational steps, evaluating Fx only requires O(N) steps.",4.4. Efficient implementation of rotation matrices,[0],[0]
"The product Dx is trivial, consisting of an element-wise vector multiplication.",4.4. Efficient implementation of rotation matrices,[0],[0]
"Therefore, the product Wx with the total unitary
matrix W can be computed in only O(NL) steps, and only requires O(NL) memory access (for full-space implementation L = N , for FFT-style approximation gives L = logN ).",4.4. Efficient implementation of rotation matrices,[0],[0]
A detailed comparison on computational complexity of the existing unitary RNN architectures is given in Table 1.,4.4. Efficient implementation of rotation matrices,[0],[0]
"We use the same nonlinearity as (Arjovsky et al., 2015):
(modReLU(z,b))i = zi |zi| ∗ ReLU(|zi|+ bi) (19)
where the bias vector b is a shared trainable parameter, and |zi| is the norm of the complex number zi.
",4.5. Nonlinearity,[0],[0]
"For real number input, modReLU can be simplified to:
(modReLU(z,b))i = sign(zi) ∗ ReLU(|zi|+ bi) (20)
where |zi| is the absolute value of the real number zi.
",4.5. Nonlinearity,[0],[0]
We empirically find that this nonlinearity function performs the best.,4.5. Nonlinearity,[0],[0]
We believe that this function possibly also serves as a forgetting filter that removes the noise using the bias threshold.,4.5. Nonlinearity,[0],[0]
"In this section, we compare the performance of our Efficient Unitary Recurrent Neural Network (EURNN) with
1.",5. Experimental tests of our method,[0],[0]
"an LSTM RNN (Hochreiter & Schmidhuber, 1997),
2.",5. Experimental tests of our method,[0],[0]
"a Partial Space URNN (Arjovsky et al., 2015), and
3.",5. Experimental tests of our method,[0],[0]
"a Projective full-space URNN (Wisdom et al., 2016).
",5. Experimental tests of our method,[0],[0]
"All models are implemented in both Tensorflow and Theano, available from https://github.com/ jingli9111/EUNN-tensorflow and https: //github.com/iguanaus/EUNN-theano.",5. Experimental tests of our method,[0],[0]
"We compare these networks by applying them all to the well defined Copying Memory Task (Hochreiter & Schmidhuber, 1997; Arjovsky et al., 2015; Henaff et al., 2016).",5.1. Copying Memory Task,[0],[0]
"The copying task is a synthetic task that is commonly used to test the network’s ability to remember information seen T time steps earlier.
",5.1. Copying Memory Task,[0],[0]
"Specifically, the task is defined as follows (Hochreiter & Schmidhuber, 1997; Arjovsky et al., 2015; Henaff et al., 2016).",5.1. Copying Memory Task,[0],[0]
"An alphabet consists of symbols {ai}, the first n of which represent data, and the remaining two representing “blank” and “start recall”, respectively; as illustrated by the following example where T = 20 and M = 5:
Input: BACCA--------------------:---Output: -------------------------BACCA
In the above example, n = 3 and {ai} = {A,B,C,−, :}.",5.1. Copying Memory Task,[0],[0]
"The input consists of M random data symbols (M = 5 above) followed by T − 1 blanks, the “start recall” symbol and M more blanks.",5.1. Copying Memory Task,[0],[0]
The desired output consists of M +T blanks followed by the data sequence.,5.1. Copying Memory Task,[0],[0]
"The cost function C is defined as the cross entropy of the input and output sequences, which vanishes for perfect performance.
",5.1. Copying Memory Task,[0],[0]
We use n = 8 and input length M = 10.,5.1. Copying Memory Task,[0],[0]
The symbol for each input is represented by an n-dimensional one-hot vector.,5.1. Copying Memory Task,[0],[0]
We trained all five RNNs for T = 1000 with the same batch size 128 using RMSProp optimization with a learning rate of 0.001.,5.1. Copying Memory Task,[0],[0]
"The decay rate is set to 0.5 for EURNN, and 0.9 for all other models respectively.",5.1. Copying Memory Task,[0],[0]
(Fig. 2).,5.1. Copying Memory Task,[0],[0]
"This results show that the EURNN architectures introduced in both Sec.4.2 (EURNN with N=512, selecting L=2) and Sec.4.3 (FFT-style EURNN with N=512) outperform the LSTM model (which suffers from long term memory problems and only performs well on the copy task for small time delays T ) and all other unitary RNN models, both in-terms of learnability and in-terms of convergence rate.",5.1. Copying Memory Task,[0],[0]
"Note that the only other unitary RNN model that is able to beat the baseline for T = 1000 (Wisdom et al., 2016) is significantly slower than our method.
",5.1. Copying Memory Task,[0],[0]
"Moreover, we find that by either choosing smaller L or by using the FFT-style method (so that W spans a smaller unitary subspace), the EURNN converges toward optimal performance significantly more efficiently (and also faster in wall clock time) than the partial (Arjovsky et al., 2015) and projective (Wisdom et al., 2016) unitary methods.",5.1. Copying Memory Task,[0],[0]
The EURNN also performed more robustly.,5.1. Copying Memory Task,[0],[0]
This means that a fullcapacity unitary matrix is not necessary for this particular task.,5.1. Copying Memory Task,[0],[0]
The MNIST handwriting recognition problem is one of the classic benchmarks for quantifying the learning ability of neural networks.,5.2. Pixel-Permuted MNIST Task,[0],[0]
"MNIST images are formed by a 28×28 grayscale image with a target label between 0 and 9.
",5.2. Pixel-Permuted MNIST Task,[0],[0]
"To test different RNN models, we feed all pixels of the MNIST images into the RNN models in 28×28 time steps, where one pixel at a time is fed in as a floating-point number.",5.2. Pixel-Permuted MNIST Task,[0],[0]
A fixed random permutation is applied to the order of input pixels.,5.2. Pixel-Permuted MNIST Task,[0],[0]
The output is the probability distribution quantifying the digit prediction.,5.2. Pixel-Permuted MNIST Task,[0],[0]
"We used RMSProp with a learning rate of 0.0001 and a decay rate of 0.9, and set the batch size to 128.
",5.2. Pixel-Permuted MNIST Task,[0],[0]
"As shown in Fig. 3, EURNN significantly outperforms LSTM with the same number of parameters.",5.2. Pixel-Permuted MNIST Task,[0],[0]
"It learns faster, in fewer iteration steps, and converges to a higher classifi-
Model hidden size number of validation test (capacity) parameters accuracy accuracy LSTM 80 16k 0.908 0.902 URNN 512 16k 0.942 0.933
PURNN 116 16k 0.922 0.921 EURNN (tunable style) 1024 (2) 13.3k 0.940 0.937
EURNN (FFT style) 512 (FFT) 9.0k 0.928 0.925
cation accuracy.",5.2. Pixel-Permuted MNIST Task,[0],[0]
"In addition, the EURNN reaches a similar accuracy with fewer parameters.",5.2. Pixel-Permuted MNIST Task,[0],[0]
In Table.,5.2. Pixel-Permuted MNIST Task,[0],[0]
"2, we compare the performance of different RNN models on this task.",5.2. Pixel-Permuted MNIST Task,[0],[0]
We also apply our EURNN to real-world speech prediction task and compare its performance to LSTM.,5.3. Speech Prediction on TIMIT dataset,[0],[0]
"The main task we consider is predicting the log-magnitude of future frames of a short-time Fourier transform (STFT) (Wisdom et al., 2016; Sejdi et al., 2009).",5.3. Speech Prediction on TIMIT dataset,[0],[0]
"We use the TIMIT dataset (Garofolo et al., 1993) sampled at 8 kHz.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
The audio .wav file is initially diced into different time frames (all frames have the same duration referring to the Hann analysis window below).,5.3. Speech Prediction on TIMIT dataset,[0],[0]
"The audio amplitude in each frame is then
Fourier transformed into the frequency domain.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
The logmagnitude of the Fourier amplitude is normalized and used as the data for training/testing each model.,5.3. Speech Prediction on TIMIT dataset,[0],[0]
In our STFT operation we uses a Hann analysis window of 256 samples (32 milliseconds) and a window hop of 128 samples (16 milliseconds).,5.3. Speech Prediction on TIMIT dataset,[0],[0]
"The frame prediction task is as follows: given all the log-magnitudes of STFT frames up to time t, predict the log-magnitude of the STFT frame at time t+ 1 that has the minimum mean square error (MSE).",5.3. Speech Prediction on TIMIT dataset,[0],[0]
"We use
a training set with 2400 utterances, a validation set of 600 utterances and an evaluation set of 1000 utterances.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
"The training, validation, and evaluation sets have distinct speakers.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
"We trained all RNNs for with the same batch size 32 using RMSProp optimization with a learning rate of 0.001, a momentum of 0.9 and a decay rate of 0.1.
",5.3. Speech Prediction on TIMIT dataset,[0],[0]
The results are given in Table.,5.3. Speech Prediction on TIMIT dataset,[0],[0]
"3, in terms of the meansquared error (MSE) loss function.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
Figure.,5.3. Speech Prediction on TIMIT dataset,[0],[0]
"4 shows prediction examples from the three types of networks, illustrat-
ing how EURNNs generally perform better than LSTMs.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
"Furthermore, in this particular task, full-capacity EURNNs outperform small capacity EURNNs and FFT-style EURNNs.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
"We have presented a method for implementing an Efficient Unitary Neural Network (EUNN) whose computational cost is merely O(1) per parameter, which is O(logN) more efficient than the other methods discussed above.",6. Conclusion,[0],[0]
"It significantly outperforms existing RNN architectures on the standard Copying Task, and the pixel-permuted MNIST Task using a comparable parameter count, hence demonstrating the highest recorded ability to memorize sequential information over long time periods.
",6. Conclusion,[0],[0]
"It also performs well on real tasks such as speech prediction, outperforming an LSTM on TIMIT data speech prediction.
",6. Conclusion,[0],[0]
We want to emphasize the generality and tunability of our method.,6. Conclusion,[0],[0]
The ordering of the rotation matrices we presented in Fig. 1 are merely two of many possibilities; we used it simply as a concrete example.,6. Conclusion,[0],[0]
"Other ordering options that can result in spanning the full unitary matrix space can be used for our algorithm as well, with identical speed and memory performance.",6. Conclusion,[0],[0]
"This tunability of the span of the unitary space and, correspondingly, the total number of parameters makes it possible to use different capacities for different tasks, thus opening the way to an optimal performance of the EUNN.",6. Conclusion,[0],[0]
"For example, as we have shown, a small subspace of the full unitary space is preferable for the copying task, whereas the MNIST task and TIMIT task are better performed by EUNN covering a considerably larger unitary space.",6. Conclusion,[0],[0]
"Finally, we note that our method remains applicable even if the unitary matrix is decomposed into a different product of matrices (Eq. 12).
",6. Conclusion,[0],[0]
This powerful and robust unitary RNN architecture also might be promising for natural language processing because of its ability to efficiently handle tasks with long-term correlation and very high dimensionality.,6. Conclusion,[0],[0]
"We thank Hugo Larochelle and Yoshua Bengio for helpful discussions and comments.
",Acknowledgment,[0],[0]
"This work was partially supported by the Army Research Office through the Institute for Soldier Nanotechnologies under contract W911NF-13-D0001, the National Science Foundation under Grant No. CCF-1640012 and the Rothberg Family Fund for Cognitive Science.",Acknowledgment,[0],[0]
"Using unitary (instead of general) matrices in artificial neural networks (ANNs) is a promising way to solve the gradient explosion/vanishing problem, as well as to enable ANNs to learn long-term correlations in the data.",abstractText,[0],[0]
This approach appears particularly promising for Recurrent Neural Networks (RNNs).,abstractText,[0],[0]
"In this work, we present a new architecture for implementing an Efficient Unitary Neural Network (EUNNs); its main advantages can be summarized as follows.",abstractText,[0],[0]
"Firstly, the representation capacity of the unitary space in an EUNN is fully tunable, ranging from a subspace of SU(N) to the entire unitary space.",abstractText,[0],[0]
"Secondly, the computational complexity for training an EUNN is merelyO(1) per parameter.",abstractText,[0],[0]
"Finally, we test the performance of EUNNs on the standard copying task, the pixelpermuted MNIST digit recognition benchmark as well as the Speech Prediction Test (TIMIT).",abstractText,[0],[0]
"We find that our architecture significantly outperforms both other state-of-the-art unitary RNNs and the LSTM architecture, in terms of the final performance and/or the wall-clock training speed.",abstractText,[0],[0]
EUNNs are thus promising alternatives to RNNs and LSTMs for a wide variety of applications.,abstractText,[0],[0]
Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1369–1379 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1369",text,[0],[0]
"Now that algorithms have started to produce relevant and realistic natural language that can describe images and videos, we would like to understand what these models truly comprehend.",1 Introduction,[0],[0]
The Visual Question Answering (VQA) task provides a nice tool for fine-grained evaluation of such multimodal algorithms.,1 Introduction,[0],[0]
"VQA systems take as input an image (or video) along with relevant natural language questions, and produce answers to those questions.",1 Introduction,[0],[0]
"By asking algorithms to answer different types of questions, ranging from object identification, counting, or appearance, to more complex questions about interactions, social relationships, or inferences about why or how something is occurring, we can evaluate different aspects of a model’s multimodal semantic understanding.
",1 Introduction,[0],[0]
"As a result, several popular image-based VQA datasets have been introduced, including DAQUAR (Malinowski and Fritz, 2014), COCO-QA (Ren et al., 2015a), FM-IQA (Gao
et al., 2015), Visual Madlibs (Yu et al., 2015), VQA (Antol et al., 2015), Visual7W (Zhu et al., 2016), etc.",1 Introduction,[0],[0]
"In addition, multiple video-based QA datasets have also been collected recently, e.g., MovieQA (Tapaswi et al., 2016), MovieFIB (Maharaj et al., 2017a), PororoQA (Kim et al., 2017), TGIF-QA (Jang et al., 2017), etc.",1 Introduction,[0],[0]
"However, there exist various shortcomings for each such video QA dataset.",1 Introduction,[0],[0]
"For example, MovieFIB’s video clips are typically short (∼4 secs), and focused on purely visual concepts (since they were collected from audio descriptions for the visually impaired); MovieQA collected QAs based on text summaries only, making them very plot-focused and less relevant for visual information; PororoQA’s video domain is cartoon-based; and TGIF-QA used predefined templates for generation on short GIFs.
",1 Introduction,[0],[0]
"With video-QA in particular, as opposed to image-QA, the video itself often comes with associated natural language in the form of (subtitle) dialogue.",1 Introduction,[0],[0]
"We argue that this is an important area to study because it reflects the real world, where people interact through language, and where many computational systems like robots or other intelligent agents will ultimately have to operate.",1 Introduction,[0],[0]
"As such, systems will need to combine information from what they see with what they hear, to pose and answer questions about what is happening.
",1 Introduction,[0],[0]
We aim to provide a dataset that merges the best qualities from all of the previous datasets as well as focus on multimodal compositionality.,1 Introduction,[0],[0]
"In particular, we collect a new large-scale dataset that is built on natural video content with rich dynamics and realistic social interactions, where questionanswer pairs are written by people observing both videos and their accompanying dialogues, encouraging the questions to require both vision and language understanding to answer.",1 Introduction,[0],[0]
"To further encourage this multimodal-QA quality, we ask people to write compositional questions consisting
of two parts, a main question part, e.g. “What are Leonard and Sheldon arguing about” and a grounding part, e.g. “when they are sitting on the couch”.",1 Introduction,[0],[0]
"This also leads to an interesting secondary task of QA temporal localization.
",1 Introduction,[0],[0]
"Our contribution is the TVQA dataset, built on 6 popular TV shows spanning 3 genres: medical dramas, sitcoms, and crime shows.",1 Introduction,[0],[0]
"On this data, we collected 152.5K human-written QA pairs (examples shown in Fig.1).",1 Introduction,[0],[0]
There are 4 salient advantages of our dataset.,1 Introduction,[0],[0]
"First, it is large-scale and natural, containing 21,793 video clips from 925 episodes.",1 Introduction,[0],[0]
"On average, each show has 7.3 seasons, providing long range character interactions and evolving relationships.",1 Introduction,[0],[0]
"Each video clip is associated with 7 questions, with 5 answers (1 correct) for each question.",1 Introduction,[0],[0]
"Second, our video clips are relatively long (60-90 seconds), thereby containing more social interactions and activities, making video understanding more challenging.",1 Introduction,[0],[0]
"Third, we provide the dialogue (character name + subtitle) for each QA video clip.",1 Introduction,[0],[0]
Understanding the relationship between the provided dialogue and the question-answer pairs is crucial for correctly answering many of the collected questions.,1 Introduction,[0],[0]
"Fourth, our questions are compositional, requiring algorithms to localize relevant moments (START and END points are provided for each question).
",1 Introduction,[0],[0]
"With the above rich annotation, our dataset supports three tasks: QA on the grounded clip, question-driven moment localization, and QA on the full video clip.",1 Introduction,[0],[0]
We provide baseline experiments on both QA tasks and introduce a state-ofthe-art language and vision-based model (leaving moment localization for future work).,1 Introduction,[0],[0]
"Visual Question Answering: Several imagebased VQA datasets have recently been constructed, e.g., DAQUAR (Malinowski and Fritz, 2014), VQA (Antol et al., 2015), COCO-Q (Ren et al., 2015a), FM-IQA (Gao et al., 2015), Visual Madlibs (Yu et al., 2015), Visual7W (Zhu et al., 2016), CLEVR (Johnson et al., 2017), etc.",2 Related Work,[0],[0]
"Additionally, several video-based QA datasets have also been proposed, e.g. TGIF-QA (Jang et al., 2017), MovieFIB (Maharaj et al., 2017b), VideoQA",2 Related Work,[0],[0]
"(Zhu et al., 2017), LSMDC (Rohrbach et al., 2015), TRECVID (Over et al., 2014), MovieQA (Tapaswi et al., 2016), PororoQA (Kim et al., 2017) and MarioQA (Mun et al., 2017).",2 Related Work,[0],[0]
"However, none of these datasets provides a truly realistic, multimodal QA scenario where both visual and language understanding are required to answer a large portion of questions, either due to unrealistic video sources (PororoQA, MarioQA) or data collection strategy being more focused on either visual (MovieFIB, VideoQA, TGIF-QA) or language (MovieQA) sources.",2 Related Work,[0],[0]
"In comparison, our TVQA collection strategy takes a directly multimodal approach to construct a large-scale, realvideo dataset by letting humans ask and answer questions while watching TV-show videos with associated dialogues.",2 Related Work,[0],[0]
"Text Question Answering: The related task of text-based question answering has been extensively explored (Richardson et al., 2013; Weston et al., 2015; Rajpurkar et al., 2016; Hermann et al., 2015; Hill et al., 2015).",2 Related Work,[0],[0]
"Richardson et al. (2013) collected MCTest, a multiple choice QA dataset intended for open-domain reading comprehension.
",2 Related Work,[0],[0]
"With the same goal in mind, Rajpurkar et al. (2016) introduced the SQuAD dataset, but their answers are specific spans from long passages.",2 Related Work,[0],[0]
Weston et al. (2015) designed a set of tasks with automatically generated QAs to evaluate the textual reasoning ability of artificial agents and Hermann et al. (2015); Hill et al. (2015) constructed the cloze dataset on top of an existing corpus.,2 Related Work,[0],[0]
"While questions in these text QA datasets are specifically designed for language understanding, TVQA questions require both vision understanding and language understanding.",2 Related Work,[0],[0]
"Although methods developed for text QA are not directly applicable to TVQA tasks, they can provide inspiration for designing suitable models.",2 Related Work,[0],[0]
Natural Language Object Retrieval: Language grounding addresses the task of object or moment localization in an image or video from a natural language description.,2 Related Work,[0],[0]
"For image-based object grounding, there has been much work on phrase grounding (Plummer et al., 2015; Wang et al., 2016b; Rohrbach et al., 2016) and referring expression comprehension (Hu et al., 2016; Yu et al., 2016; Nagaraja et al., 2016; Yu et al., 2017, 2018b).",2 Related Work,[0],[0]
"Recent work (Vasudevan et al., 2018) extends the grounding task to the video domain.",2 Related Work,[0],[0]
"Most recently, moment localization was proposed in (Hendricks et al., 2017; Gao et al., 2017), where the goal is to localize a short moment from a long video sequence given a query description.",2 Related Work,[0],[0]
Accurate temporal grounding is a necessary step to answering our compositional questions.,2 Related Work,[0],[0]
"We collected our dataset on 6 long-running TV shows from 3 genres: 1) sitcoms: The Big Bang Theory, How I Met Your Mother, Friends, 2) medical dramas: Grey’s Anatomy, House, 3) crime drama: Castle.",3.1 Dataset Collection,[0],[0]
There are in total 925 episodes spanning 461 hours.,3.1 Dataset Collection,[0],[0]
Each episode was then segmented into short clips.,3.1 Dataset Collection,[0],[0]
"We first created clips every 60/90 seconds, then shifted temporal boudaries to avoid splitting subtitle sentences between clips.",3.1 Dataset Collection,[0],[0]
"Shows that are mainly conversational based, e.g., The Big Bang Theory, were segmented into 60 seconds clips, while shows that are less cerebral, e.g. Castle, were segmented into 90 seconds clips.",3.1 Dataset Collection,[0],[0]
"In the end, 21,793 clips were prepared for QA collection, accompanied with subtitles and aligned with transcripts to add character names.",3.1 Dataset Collection,[0],[0]
"A
sample clip is shown in Fig. 1.",3.1 Dataset Collection,[0],[0]
"Amazon Mechanical Turk was used for VQA collection on video clips, where workers were presented with both videos and aligned named subtitles, to encourage multimodal questions requiring both vision and language understanding to answer.",3.1 Dataset Collection,[0],[0]
Workers were asked to create questions using a compositional-question format:,3.1 Dataset Collection,[0],[0]
[What/How/Where/Why/...],3.1 Dataset Collection,[0],[0]
[when/before/after] .,3.1 Dataset Collection,[0],[0]
"The second part of each question serves to localize the relevant video moment within a clip, while the first part poses a question about that moment.",3.1 Dataset Collection,[0],[0]
"This compositional format also serves to encourage questions that require both visual and language understanding to answer, since people often naturally use visual signals to ground questions in time, e.g. What was House saying before he leaned over the bed?",3.1 Dataset Collection,[0],[0]
"During data collection, we only used prompt words (when/before/after) to encourage workers to propose the desired, complex compositional questions.",3.1 Dataset Collection,[0],[0]
There were no additional template constraints.,3.1 Dataset Collection,[0],[0]
"Therefore, most of the language in the questions is relatively free-form and complex.
",3.1 Dataset Collection,[0],[0]
"Ultimately, workers pose 7 different questions for each video clip.",3.1 Dataset Collection,[0],[0]
"For each question, we asked workers to annotate the exact video portion required to answer the question by marking the START and END timestamps as in Krishna et al. (2017).",3.1 Dataset Collection,[0],[0]
"In addition, they provide 1 correct and 4 wrong answers for each question.",3.1 Dataset Collection,[0],[0]
Workers get paid $1.3 for a single video clip annotation.,3.1 Dataset Collection,[0],[0]
"The whole collection process took around 3 months.
",3.1 Dataset Collection,[0],[0]
"To ensure the quality of the questions and answers, we set up an online checker in our collection interface to verify the question format, allowing only questions that reflect our two-step format to be submitted.",3.1 Dataset Collection,[0],[0]
The collection was done in batches of 500 videos.,3.1 Dataset Collection,[0],[0]
"For each harvested batch, we sampled 3 pairs of submitted QAs from each worker and checked the semantic correctness of the questions, answers, and timestamps.",3.1 Dataset Collection,[0],[0]
Multiple Choice QAs:,3.2 Dataset Analysis,[0],[0]
"Our QAs are multiple choice questions with 5 candidate answers for each question, for which only one is correct.",3.2 Dataset Analysis,[0],[0]
Table 1 provides statistics of the QAs based on the first question word.,3.2 Dataset Analysis,[0],[0]
"On average, our questions contain 13.5 words, which is fairly long compared to other datasets.",3.2 Dataset Analysis,[0],[0]
"In general, correct answers tend
to be slightly longer than wrong answers.",3.2 Dataset Analysis,[0],[0]
Fig. 2 shows the distribution of different questions types.,3.2 Dataset Analysis,[0],[0]
"Note “what” (Abstract, Object, Action), “who” (Person), “why” (Reasoning) and “where” (Location) questions form a large part of our data.
",3.2 Dataset Analysis,[0],[0]
The negative answers in TVQA are written by human annotators.,3.2 Dataset Analysis,[0],[0]
They are instructed to write false but relevant answers to make the negatives challenging.,3.2 Dataset Analysis,[0],[0]
"Alternative methods include sampling negative answers from other questions’ correct answers, either based on semantic similarity (Das et al., 2017; Jang et al., 2017) or randomly (Antol et al., 2015; Das et al., 2017).",3.2 Dataset Analysis,[0],[0]
"The former is prone to introducing paraphrases of the ground-truth answer (Zhu et al., 2016).",3.2 Dataset Analysis,[0],[0]
"The latter avoids the problem of paraphrasing, but generally produces irrelevant negative choices.",3.2 Dataset Analysis,[0],[0]
We show in Table 8 that our human written negatives are more challenging than randomly sampled negatives.,3.2 Dataset Analysis,[0],[0]
Moment Localization:,3.2 Dataset Analysis,[0],[0]
The second part of our question is used to localize the most relevant video portion to answer the question.,3.2 Dataset Analysis,[0],[0]
"The prompt of “when”, “after”, “before” account for 60.03%, 30.19% and 9.78% respectively of our dataset.",3.2 Dataset Analysis,[0],[0]
TVQA provides the annotated START and END timestamps for each QA.,3.2 Dataset Analysis,[0],[0]
"We show the annotated
segment lengths in Fig. 3.",3.2 Dataset Analysis,[0],[0]
We found most of the questions rely on relatively short moments (less than 15 secs) within a longer clip (60-90 secs).,3.2 Dataset Analysis,[0],[0]
Differences among our 6 TV Shows: The videos used in our dataset are from 6 different TV shows.,3.2 Dataset Analysis,[0],[0]
Table 2 provides statistics for each show.,3.2 Dataset Analysis,[0],[0]
A good way to demonstrate the difference among questions from TV shows is to show their top unique nouns.,3.2 Dataset Analysis,[0],[0]
"In Table 3, we present such an analysis.",3.2 Dataset Analysis,[0],[0]
"The top unique nouns in sitcoms (BBT, Friends, HIMYM) are mostly daily objects, scenes and actions, while medical dramas (Grey, House) questions contain more medical terms, and crime shows (Castle) feature detective terms.",3.2 Dataset Analysis,[0],[0]
"Although similar, there are also notable differences among shows in the same genre.",3.2 Dataset Analysis,[0],[0]
"For example, BBT con-
tains “game” and “laptop” while HIMYM contains “bar” and “beer”, indicating the different major activities and topics in each show.",3.2 Dataset Analysis,[0],[0]
"Additionally, questions about different characters also mention different words, as shown in Table 4.",3.2 Dataset Analysis,[0],[0]
Comparison with Other Datasets: Table 5 presents a comparison of our dataset to some recently proposed video question answering datasets.,3.2 Dataset Analysis,[0],[0]
"In terms of total length of videos, TVQA is the largest, with a total of 461.2 hours of videos.",3.2 Dataset Analysis,[0],[0]
"MovieQA (Tapaswi et al., 2016) is most similar to our dataset, with both multiple choice questions and timestamp annotation.",3.2 Dataset Analysis,[0],[0]
"However, their questions and answers are constructed by people posing questions from a provided plot summary, then later aligned to the video clips, which makes most of their questions text oriented.",3.2 Dataset Analysis,[0],[0]
"Human Evaluation on Usefulness of Video and Subtitle in Dataset: To gain a better understand-
ing of the roles of videos and subtitles in the our dataset, we perform a human study, asking different groups of workers to complete the QA task in settings while observing different sources (subsets) of information:
• Question only.",3.2 Dataset Analysis,[0],[0]
• Video and Question.,3.2 Dataset Analysis,[0],[0]
•,3.2 Dataset Analysis,[0],[0]
Subtitle and Question.,3.2 Dataset Analysis,[0],[0]
"• Video, Subtitle, and Question.
",3.2 Dataset Analysis,[0],[0]
We made sure the workers that have written the questions did not participate in this study and that workers see only one of the above settings for answering each question.,3.2 Dataset Analysis,[0],[0]
Human accuracy on our test set under these 4 settings are reported in Table 5.,3.2 Dataset Analysis,[0],[0]
"As expected, compared to human accuracy based only on question-answer pairs (Q), adding videos (V+Q), or subtitles (S+Q) significantly improves human performance.",3.2 Dataset Analysis,[0],[0]
Adding both videos and subtitles (V+S+Q) brings the accuracy to 89.41%.,3.2 Dataset Analysis,[0],[0]
"This indicates that in order to answer the questions correctly, both visual and textual understanding are essential.",3.2 Dataset Analysis,[0],[0]
"We also observe that workers obtain 31.84% accuracy given questionanswer pairs only, which is higher than random guessing (20%).",3.2 Dataset Analysis,[0],[0]
We ascribe this to people’s prior knowledge about the shows.,3.2 Dataset Analysis,[0],[0]
"Note, timestamp annotations are not provided in these experiments.",3.2 Dataset Analysis,[0],[0]
We introduce a multi-stream end-to-end trainable neural network for Multi-Modal Video Question Answering.,4 Methods,[0],[0]
Fig. 4 gives an overview of our model.,4 Methods,[0],[0]
"Formally, we define the inputs to the model as: a 60-90 second video clip V , a subtitle S, a question q, and five candidate answers {ai}4i=0.",4 Methods,[0],[0]
Frames are extracted at 3 fps.,4.1 Video Features,[0],[0]
"We run Faster RCNN (Ren et al., 2015b) trained on the Visual
Genome (Krishna et al., 2017) to detect object and attribute regions in each frame.",4.1 Video Features,[0],[0]
Both regional features and predicted detection labels can be used as model inputs.,4.1 Video Features,[0],[0]
"We also use ResNet101 (He et al., 2016) trained on ImageNet (Deng et al., 2009) to extract whole image features.",4.1 Video Features,[0],[0]
"Regional Visual Features: On average, our videos contain 229 frames, with 16 detections per frame.",4.1 Video Features,[0],[0]
It is not trivial to model such long sequences.,4.1 Video Features,[0],[0]
"For simplicity, we follow (Anderson et al., 2018; Karpathy and Fei-Fei, 2015) selecting the top-K regions1 from each detected label across all frames.",4.1 Video Features,[0],[0]
Their regional features are L2normalized and stacked together to form our visual representation V reg ∈ Rnreg×2048.,4.1 Video Features,[0],[0]
Here nreg is the number of selected regions.,4.1 Video Features,[0],[0]
"Visual Concept Features: Recent work (Yin and Ordonez, 2017) found that using detected object
1Based on cross-validation, we find K=6 to perform best.
labels as input to an image captioning system gave comparable performance to using CNN features directly.",4.1 Video Features,[0],[0]
"Inspired by this work, we also experiment with using detected labels as visual inputs.",4.1 Video Features,[0],[0]
"As shown in Fig. 5, we are able to detect rich visual concepts, including both objects and attributes, e.g. ”white basket”, which could be used to answer “What is Sheldon holding in his hand when everyone is at the door”.",4.1 Video Features,[0],[0]
We first gather detected concepts over all the frames to represent concept presence.,4.1 Video Features,[0],[0]
"After removing duplicate concepts, we use GloVe (Pennington et al., 2014) to embed the words.",4.1 Video Features,[0],[0]
"The resulting video representation is denoted as V cpt ∈ Rncpt×300, where ncpt is the number of unique concepts.",4.1 Video Features,[0],[0]
ImageNet Features: We extract the pooled 2048D feature of the last block of ResNet101.,4.1 Video Features,[0],[0]
"Features from the same video clip are L2 normalized and stacked, denoted as V img ∈ Rnimg×2048, where nimg is the number of frames extracted from the video clip.",4.1 Video Features,[0],[0]
We use a bi-directional LSTM (BiLSTM) to encode both textual and visual sequences.,4.2 LSTM Encoders for Video and Text,[0],[0]
"A subtitle S, which contains a set of sentences, is flattened into a long sequence of words and GloVe (Pennington et al., 2014) is used to embed the words.",4.2 LSTM Encoders for Video and Text,[0],[0]
"We stack the hidden states of the BiLSTM from both directions at each timestep to obtain the subtitle representation HS ∈ RnS×2d, where nS is the number of subtitle words, d is the hidden size of the BiLSTM (set to 150 in our experiments).",4.2 LSTM Encoders for Video and Text,[0],[0]
"Similarly, we encode question Hq ∈ Rnq×2d, candidate answers Hai ∈ Rnai×2d, and visual con-
cepts Hcpt ∈ Rncpt×2d.",4.2 LSTM Encoders for Video and Text,[0],[0]
"nq and nai are the number of words in question and answer ai, respectively.",4.2 LSTM Encoders for Video and Text,[0],[0]
"Regional features V reg and ImageNet features V img are first projected into word vector space using a non-linear layer with tanh activation, then encoded using the same BiLSTM to obtain the regional representations Hreg ∈ Rnreg×2d and H img ∈ Rnimg×2d, respectively.",4.2 LSTM Encoders for Video and Text,[0],[0]
"We use a context matching module and BiLSTM to jointly model the contextual inputs (subtitle, video) and query (question-answer pair).",4.3 Joint Modeling of Context and Query,[0],[0]
"The context matching module is adopted from the contextquery attention layer from previous works (Seo et al., 2017; Yu et al., 2018a).",4.3 Joint Modeling of Context and Query,[0],[0]
"It takes context vectors and query vectors as inputs and produces a set of context-aware query vectors based on the similarity between each context-query pair.
",4.3 Joint Modeling of Context and Query,[0],[0]
"Taking the regional visual feature stream as an example (Fig. 4 upper stream), where Hreg is used as context input2.",4.3 Joint Modeling of Context and Query,[0],[0]
"The question embedding, Hq, and answer embedding, Hai , are used as queries.",4.3 Joint Modeling of Context and Query,[0],[0]
"After feeding context-query pairs into the context matching module, we obtain a video-aware-question representation, Greg,q ∈ Rnreg×2d, and video-aware-answer representation, Greg,ai ∈ Rnreg×2d, which are then fused with video context:
M reg,ai = [Hreg;Greg,q;Greg,ai ;
Hreg Greg,q;Hreg Greg,ai ],
where is element-wise product.",4.3 Joint Modeling of Context and Query,[0],[0]
"The fused feature, M reg,ai ∈ Rnreg×10d, is fed into another BiLSTM.",4.3 Joint Modeling of Context and Query,[0],[0]
"Its hidden states, U reg,ai ∈ Rnreg×10d, are max-pooled temporally to get the final vector, ureg,ai ∈ R10d, for answer ai.",4.3 Joint Modeling of Context and Query,[0],[0]
"We use a linear layer with softmax to convert {ureg,ai}4i=0 into answer probabilities.",4.3 Joint Modeling of Context and Query,[0],[0]
"Similarly, we can compute the answer probabilities given subtitle as context (Fig. 4 bottom stream).",4.3 Joint Modeling of Context and Query,[0],[0]
"When multiple streams are used, we simply sum up the scores from each stream as the final score (Wang et al., 2016a).",4.3 Joint Modeling of Context and Query,[0],[0]
"For evaluation, we introduce several baselines and compare them to our proposed model.
",5 Experiments,[0],[0]
"2For visual concept features and ImageNet features, we simply replace Hreg with Hcpt or Himg as the context.
",5 Experiments,[0],[0]
"In all experiments, setup is as follows.",5 Experiments,[0],[0]
"We split the TVQA dataset into 80% training, 10% validation, and 10% testing splits such that videos and their corresponding QA pairs appear in only one split.",5 Experiments,[0],[0]
"This results in 122,039 QA pairs for training, 15,253 QA pairs for validation, and 15,253 QA pairs for testing.",5 Experiments,[0],[0]
We evaluate each model using multiple-choice question answering accuracy.,5 Experiments,[0],[0]
"Longest Answer: Table 1 indicates that the average length of the correct answers is longer than the wrong ones; thus, our first baseline simply selects the longest answer for each question.",5.1 Baselines,[0],[0]
"Nearest Neighbor Search: In this baseline, we use Nearest Neighbor Search (NNS) to compute the closest answer to our question or subtitle.",5.1 Baselines,[0],[0]
"We embed sentences into vectors using TFIDF, SkipThought (Kiros et al., 2015), or averaged GloVe (Pennington et al., 2014) word vectors, then compute the cosine similarity for each questionanswer pair or subtitle-answer pair.",5.1 Baselines,[0],[0]
"For TFIDF, we use bag-of-words to represent the sentences, assigning a TFIDF value for each word.",5.1 Baselines,[0],[0]
Retrieval:,5.1 Baselines,[0],[0]
"Due to the size of TVQA, there may exist similar questions and answers in the dataset.",5.1 Baselines,[0],[0]
"Thus, we also implement a baseline two-step retrieval approach: given a question and a set of candidate answers, we first retrieve the most relevant question in the training set, then pick the candidate answer that is closest to the retrieved question’s correct answer.",5.1 Baselines,[0],[0]
"Similar approaches have also been used in dialogue systems (Jafarpour and Burges, 2010; Leuski and Traum, 2011), picking the appropriate responses to an utterance from a predefined human conversational corpus.",5.1 Baselines,[0],[0]
"Similar to NNS, we use TFIDF, SkipThought, and GloVe vectors with cosine similarity.",5.1 Baselines,[0],[0]
Table 6 shows results from baseline methods and our proposed neural model.,5.2 Results,[0],[0]
"Our main results are obtained by using full-length video clips and subtitles, without using timestamps (w/o ts).",5.2 Results,[0],[0]
We also run the same experiments using the localized video and subtitle segment specified by the ground truth timestamps (w/ ts).,5.2 Results,[0],[0]
"If not indicated explicitly, the numbers described below are from the experiments on full-length video clips and subtitles.",5.2 Results,[0],[0]
"Baseline Comparison: Row 1 shows results of the longest answer baseline, achieving 30.41%
(compared to random chance at 20%).",5.2 Results,[0],[0]
"As expected, the retrieval-based methods (row 2-4) and the answer-question similarity based methods (row 5-7) perform rather poorly, since no contexts (video or subtitle) are considered.",5.2 Results,[0],[0]
"When using subtitle-answer similarity to choose correct answers, Glove, SkipThought, and TFIDF based approaches (row 8-10) all achieve significant improvement over question-answer similarity.",5.2 Results,[0],[0]
"Notably, TFIDF (row 10) answers 49.94% of the questions correctly.",5.2 Results,[0],[0]
"Since our questions are raised by people watching the videos, it is natural for them to ask questions about specific and unique objects/locations/etc., mentioned in the subtitle.",5.2 Results,[0],[0]
"Thus, it is not surprising that TFIDF based similarity between answer and subtitle performs so well.",5.2 Results,[0],[0]
Variants of Our Model: Rows 11-18 show results of our model with different contextual inputs and features.,5.2 Results,[0],[0]
The model that only uses questionanswer pairs (row 11) achieves 43.34% accuracy.,5.2 Results,[0],[0]
"Compared to the subtitle model (row 15), adding video as additional sources (row 16-18) improves performance.",5.2 Results,[0],[0]
"Interestingly, adding video to the question only model (row 11) do not work as well (row 12-14).",5.2 Results,[0],[0]
"Our hypothesis is that the video feature streams may be struggling to learn models for answering textual questions, which degrades
their ability to answer visual questions.",5.2 Results,[0],[0]
"Overall, the best performance is achieved by using all the contextual sources, including subtitles and videos (using concept features, row 18).",5.2 Results,[0],[0]
Comparison with Human Performance: Human performance without timestamp annotation is shown in Table 5.,5.2 Results,[0],[0]
"When using only questions (Table 6 row 11), our model outperforms humans (43.34% vs 31.84%) as it has access to all statistics of the questions and answers.",5.2 Results,[0],[0]
"When using videos or subtitles or both, humans perform significantly better than the models.",5.2 Results,[0],[0]
Models with Timestamp Annotation: Columns under w/o ts and w/ ts show a comparison between the same model using full-length videos/subtitles and using timestamp localized videos/subtitles.,5.2 Results,[0],[0]
"With timestamp annotation, the models perform consistently better than their counterpart without this information, indicating that localization is helpful for question answering.",5.2 Results,[0],[0]
"Accuracy for Different Question Types: To gain further insight, we examined the accuracy of our models on different question types on the validation set (results in Table 7), all models using timestamp annotation.",5.2 Results,[0],[0]
"Compared to S+Q model, S+V+Q models get the most improvements on “what” and “where” questions, indicating these questions require additional visual information.",5.2 Results,[0],[0]
"On the other hand, adding video features did not improve S+Q performance on questions relying more on textual reasoning, e.g., “how” questions.",5.2 Results,[0],[0]
"Human-Written Negatives vs. RandomlySampled Negatives For comparison, we create a new answer set by replacing the original human written negative answers with randomly sampled negative answers.",5.2 Results,[0],[0]
"To produce relevant negative answers, for each question, negatives are sampled (from the other QA pairs) within the same show.
",5.2 Results,[0],[0]
Results are shown in Table 8.,5.2 Results,[0],[0]
"Performance on randomly sampled negatives is much higher than that of human written negatives, indicating that human written negatives are more challenging.",5.2 Results,[0],[0]
Qualitative Analysis: Fig. 6 shows example predictions from our S+V+Q model (row 18) using full-length video and subtitle.,5.2 Results,[0],[0]
Fig. 6a and Fig.,5.2 Results,[0],[0]
6b demonstrate its ability to solve both grounded visual questions and textual reasoning question.,5.2 Results,[0],[0]
Bottom row shows two incorrect predictions.,5.2 Results,[0],[0]
We found that wrong inferences are mainly due to incorrect language inferences and the model’s lack of common sense knowledge.,5.2 Results,[0],[0]
"For example, Fig.",5.2 Results,[0],[0]
"6c, the characters are talking about radiology, the model is distracted to believe they are in the radiology department, while Fig. 6d shows a case of questions that need common sense to answer, rather than simply textual or visual cues.",5.2 Results,[0],[0]
"We presented the TVQA dataset, a large-scale, localized, compositional video question answering dataset.",6 Conclusion,[0],[0]
We also proposed two QA tasks (with/without timestamps) and provided baseline experiments as a benchmark for future comparison.,6 Conclusion,[0],[0]
"Our experiments show both visual and textual understanding are necessary for TVQA.
",6 Conclusion,[0],[0]
There is still a significant gap between the proposed baselines and human performance on the QA accuracy.,6 Conclusion,[0],[0]
We hope this novel multimodal dataset and the baselines will encourage the community to develop stronger models in future work.,6 Conclusion,[0],[0]
"To narrow the gap, one possible direction is to enhance the interactions between videos and subtitles to improve multimodal reasoning ability.",6 Conclusion,[0],[0]
"Another direction is to exploit human-object relations in the video and subtitle, as we observe that a large number of questions involve such relations.",6 Conclusion,[0],[0]
"Additionally, temporal reasoning is crucial for answering the TVQA questions.",6 Conclusion,[0],[0]
"Thus, future work also includes integrating better temporal cues.",6 Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful comments and discussions.,Acknowledgments,[0],[0]
"This research is supported by NSF Awards #1633295, 1562098, 1405822 and a Google Faculty Research Award, Bloomberg Data Science Research Grant, and ARO-YIP Award #W911NF-18-1-0336.",Acknowledgments,[0],[0]
The views contained in this article are those of the authors and not of the funding agency.,Acknowledgments,[0],[0]
Recent years have witnessed an increasing interest in image-based question-answering (QA) tasks.,abstractText,[0],[0]
"However, due to data limitations, there has been much less work on video-based QA.",abstractText,[0],[0]
"In this paper, we present TVQA, a largescale video QA dataset based on 6 popular TV shows.",abstractText,[0],[0]
"TVQA consists of 152,545 QA pairs from 21,793 clips, spanning over 460 hours of video.",abstractText,[0],[0]
"Questions are designed to be compositional in nature, requiring systems to jointly localize relevant moments within a clip, comprehend subtitle-based dialogue, and recognize relevant visual concepts.",abstractText,[0],[0]
We provide analyses of this new dataset as well as several baselines and a multi-stream end-to-end trainable neural network framework for the TVQA task.,abstractText,[0],[0]
The dataset is publicly available at http://tvqa.cs.unc.edu.,abstractText,[0],[0]
"TVQA: Localized, Compositional Video Question Answering",title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1415–1425 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1415",text,[0],[0]
"Language on Twitter diverges from well-edited Mainstream American English (MAE, also called Standard American English) in a number of ways, presenting significant challenges to current NLP tools.",1 Introduction,[0],[0]
"It contains, among other phenomena, nonstandard spelling, punctuation, capitalization, and syntax, as well as Twitter-specific conventions such as hashtags, usernames, and retweet tokens (Eisenstein, 2013).",1 Introduction,[0],[0]
"Additionally, it contains an abundance of dialectal language, includ-
ing African-American English (AAE), a dialect of American English spoken by millions of individuals, which contains lexical, phonological, and syntactic features not present in MAE (Green, 2002; Stewart, 2014; Jones, 2015).
",1 Introduction,[0],[0]
"Since standard English NLP tools are typically trained on well-edited MAE text, their performance is degraded on Twitter, and even more so for AAE tweets compared to MAE tweets— gaps exist for part-of-speech tagging (Jørgensen et al., 2016), language identification, and dependency parsing (Blodgett et al., 2016; Blodgett and O’Connor, 2017).",1 Introduction,[0],[0]
"Expanding the linguistic coverage of NLP tools to include minority and colloquial dialects would help support equitable language analysis across sociolinguistic communities, which could help information retrieval, translation, or opinion analysis applications (Jurgens et al., 2017).",1 Introduction,[0],[0]
"For example, sentiment analysis systems ought to count the opinions of all types of people, whether they use standard dialects or not.
",1 Introduction,[0],[0]
"In this work, we broaden Universal Dependencies (Nivre et al., 2016)",1 Introduction,[0],[0]
"parsing1 to better handle social media English, in particular social media AAE.",1 Introduction,[0],[0]
"First, we develop standards to handle Twitter-specific and AAE-specific features within Universal Dependencies 2.0 (§3), by selecting and annotating a new dataset of 500 tweets, 250 of which are in AAE.
",1 Introduction,[0.9504155651845881],"['By setting Θl to five,12 EPM results in 13 pairwise feature-values, 112 POS tags, i.e. 53 POS for anaphors and 59 for antecedents, 25 dependency relations, 26 mention types (mention types or fine mention types), and finally, 14 named entity tags.13 Based on the observation in Section 5, we use the top-pairs model of deep-coref as the baseline to employ additional features, i.e. “+EPM” is the top-pairs model in which EPM feature-values are incorporated.']"
"Second, we evaluate several state-of-the-art dependency parsers, finding that, as expected, they perform poorly on our dataset relative to the UD English Treebank (§4).",1 Introduction,[0],[0]
"Third, since the UD English Treebank contains substantial amounts of traditional MAE data for training, we investigate cross-domain training methods to improve Twitter AAE dependency parsing with no, or very little,
1http://universaldependencies.org/
in-domain labeled data, by using Twitter-specific taggers, embeddings, and a novel heuristic training data synthesis procedure.",1 Introduction,[0],[0]
This helps close some of the gap between MAE and AAE performance.,1 Introduction,[0],[0]
"Finally, we provide an error analysis of the parsers’ performance on AAE lexical and syntactic constructions in our dataset (§5.4).2",1 Introduction,[0],[0]
Parsing for noisy social media data presents interesting and significant challenges.,2.1 Parsing for Twitter,[0],[0]
"Foster et al. (2011) develop a dataset of 519 constituencyannotated English tweets, which were converted to Stanford dependencies.",2.1 Parsing for Twitter,[0],[0]
Their analysis found a substantial drop in performance of an off-the-shelf dependency parser on the new dataset compared to a WSJ test set.,2.1 Parsing for Twitter,[0],[0]
"Sanguinetti et al. (2017) annotated a dataset of 6,738 Italian tweets according to UD 2.0 and examined the performance of two parsers on the dataset, finding that they lagged considerably relative to performance on the Italian UD Treebank.
Kong et al. (2014) develop an English dependency parser designed for Twitter, annotating a dataset of 929 tweets (TWEEBANK V1) according to the unlabeled FUDG dependency formalism (Schneider et al., 2013).",2.1 Parsing for Twitter,[0],[0]
"It has substantially different structure than UD (for example, prepositions head PPs, and auxiliaries govern main verbs).
",2.1 Parsing for Twitter,[0],[0]
"More recently, Liu et al. (2018) developed TWEEBANK V2, fully annotating TWEEBANK V1 according to UD 2.0 and annotating additionally sampled tweets, for a total of 3,550 tweets.",2.1 Parsing for Twitter,[0],[0]
"They found that creating consistent annotations was challenging, due to frequent ambiguities in interpreting tweets; nevertheless, they were able to train a pipeline for tokenizing, tagging, and parsing the tweets, and develop ensemble and distillation models to improve parsing accuracy.",2.1 Parsing for Twitter,[0],[0]
"Our work encounters similar challenges; in our approach, we intentionally oversample AAE-heavy messages for annotation, detail specific annotation decisions for AAE-specific phenomena (§3.2), and analyze parser performance between dialects and for particular constructions (§5.3–5.4).",2.1 Parsing for Twitter,[0],[0]
"Future work may be able to combine these annotations for effective multi-dialect Twitter UD parsers, which
2Our annotated dataset and trained dependency parser are available at http://slanglab.cs.umass.edu/TwitterAAE/ and annotations are available in the public Universal Dependencies repository.
may allow for the use of pre-existing downstream tools like semantic relation extractors (e.g. White et al. (2016)).
",2.1 Parsing for Twitter,[0],[0]
"One line of work for parsing noisy social media data, including Khan et al. (2013) and Nasr et al. (2016), examines the effects of the domain mismatches between traditional sources of training data and social media data, finding that matching the data as closely as possible aids performance.",2.1 Parsing for Twitter,[0],[0]
"Other work focuses on normalization, including Daiber and van der Goot (2016) and van der Goot and van Noord (2017), which develop a dataset of 500 manually normalized and annotated tweets, and uses normalization within a parser.",2.1 Parsing for Twitter,[0],[0]
"Separately, Zhang et al. (2013) created a domain-adaptable, parser-focused system by directly linking parser performance to normalization performance.",2.1 Parsing for Twitter,[0],[0]
"For Arabic dialects, Chiang et al. (2006) parse Levantine Arabic by projecting parses from Modern Standard Arabic translations, while Green and Manning (2010) conduct extensive error analysis of Arabic constituency parsers and the Penn Arabic Treebank.",2.2 Parsing for Dialects,[0],[0]
Scherrer (2011) parse Swiss German dialects by transforming Standard German phrase structures.,2.2 Parsing for Dialects,[0],[0]
"We continue in this line of work in our examination of AAE-specific syntactic structures and generation of synthetic data with such structures (§4.2.1).
",2.2 Parsing for Dialects,[0],[0]
Less work has examined parsing dialectal language on social media.,2.2 Parsing for Dialects,[0],[0]
"Recently, Wang et al. (2017) annotate 1,200 Singlish (Singaporean English) sentences from a Singaporean talk forum, selecting sentences containing uniquely Singaporean vocabulary items.",2.2 Parsing for Dialects,[0],[0]
"Like other work, they observe a drop in performance on dialectal Singlish text, but increase performance through a stacking-based domain adaptation method.",2.2 Parsing for Dialects,[0],[0]
"Our dataset contains 500 tweets, with a total of 5,951 non-punctuation edges, sampled from the publicly available TwitterAAE corpus.3 Each tweet in that corpus is accompanied by a model’s demographically-aligned topic model probabilities jointly inferred from Census demographics and word likelihood by Blodgett et al. (2016), including the African-American and White topics.
",3.1 Dataset,[0],[0]
"3http://slanglab.cs.umass.edu/TwitterAAE/
We create a balanced sample to get a range of dialectal language, sampling 250 tweets from those where the African-American topic has at least 80% probability, and 250 from those where the White topic has at least 80% probability.",3.1 Dataset,[0],[0]
"We refer to these two subcorpora as AA and WH; Blodgett et al. (2016) showed the former exhibits linguistic features typical of AAE.
",3.1 Dataset,[0],[0]
"The 250 AA tweets include many alternate spellings of common words that correspond to well-known phonological phenomena—including da, tha (the), dat, dhat (that), dis, dhis (this), ion, iont (I don’t), ova (over), yo (your), dere, der (there), den, dhen (then), ova (over), and nall, null (no, nah)—where each of the mentioned italicized AAE terms appears in the AAE data, but never in the MAE data.",3.1 Dataset,[0],[0]
We examine these lexical variants more closely in §5.4.,3.1 Dataset,[0],[0]
"Across the AA tweets, 18.0% of tokens were not in a standard English dictionary, while the WH tweets’ OOV rate was 10.7%.4 We further observe a variety of AAE syntactic phenomena in our AA tweets, several of which are described in §3.2 and §5.4.",3.1 Dataset,[0],[0]
"To effectively measure parsing quality and develop better future models, we first focus on developing high-quality annotations for our dataset, for which we faced a variety of challenges.",3.2 Annotation,[0],[0]
"We detail our annotation principles using Universal Dependency 2.0 relations (Nivre et al., 2016).
",3.2 Annotation,[0],[0]
"All tweets were initially annotated by two annotators, and disagreements resolved by one of the annotators.",3.2 Annotation,[0],[0]
"Annotation decisions for several dozen tweets were discussed in a group of three annotators early in the annotation process.
",3.2 Annotation,[0],[0]
"Our annotation principles are in alignment with those proposed by Liu et al. (2018), with the exception of contraction handling, which we discuss briefly in §3.2.2.",3.2 Annotation,[0],[0]
"The AAE dialect is prominently characterized by the drop of copulas, which can occur when the copula is present tense, not first person, not accented, not negative, and expressing neither the habitual nor the remote present perfect tenses (Green, 2002).",3.2.1 Null Copulas,[0],[0]
"We frequently observed null copulas, as in:
4The dictionary of 123,377 words with American spellings was generated using http://wordlist.aspell.net/.
If u wit me den u pose to RESPECT ME
nsubjnsubj
“If you (are) with me, then you (are) supposed to respect me”
The first dropped are is a null copula; UD2.0 would analyze the MAE version as you nsubj←−− me cop−→ are, which we naturally extend to analyze the null copula by simply omitting cop (which is now over a null element, so cannot exist in a dependency graph).",3.2.1 Null Copulas,[0],[0]
"The second are is a null auxiliary (in MAE, you nsubj←−− supposed aux−→ are), a tightly related phenomenon (for example, Green et al. (2007) studies both null copulas and null auxiliary be in infant AAE), which we analyze similarly by simply omitting the aux edge.",3.2.1 Null Copulas,[0],[0]
"We observed AAE verbal auxiliaries, e.g.,
fees be looking upside my head
aux
Now we gone get fucked up
aux
damnnn I done let alot of time pass by
aux
including habitual be (“Continually, over and over, fees are looking at me...”), future gone (“we are going to get...”), and completive done (“I did let time pass by,” emphasizing the speaker completed a time-wasting action).
",3.2.2 AAE Verbal Auxiliaries,[0],[0]
"We attach the auxiliary to the main verb with the aux relation, as UD2.0 analyzes other English auxiliaries (e.g. would or will).",3.2.2 AAE Verbal Auxiliaries,[0],[0]
"We observed many instances of quasi-auxiliary, “- to” shortened verbs such as wanna, gotta, finna, bouta, tryna, gonna, which can be glossed as want to, got to, fixing to, about to, etc.",3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
"They control modality, mood and tense—for example, finna and bouta denote an immediate future tense; Green (2002, ch. 2) describes finna as a preverbal marker.",3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
"From UD’s perspective, it is difficult to decide if they should be subordinate auxiliaries or main verbs.",3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
"In accordance with the UD Treebank’s handling of MAE want to X and going to X as main verbs (want xcomp−−→ X), we analyzed them similarly, e.g.
Lol he bouta piss me off “He is about to piss me off”
xcomp
This is an instance of a general principle that, if there is a shortening of an MAE multiword phrase into a single word, the annotations on that word should mirror the edges in and out of the original phrase’s subgraph (as in Schneider et al. (2013)’s fudge expressions).
",3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
"However, in contrast to the UD Treebank, we did not attempt to split up these words into their component words (e.g. wanna → want to), since to do this well, it would require a more involved segmentation model over the dozens or even hundreds of alternate spellings each of the above can take;5",3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
we instead rely on Owoputi et al. (2013); O’Connor et al. (2010)’s rule-based tokenizer that never attempts to segment within such shortenings.,3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
"This annotation principle is in contrast to that of Liu et al. (2018), which follows UD tokenization for contractions.",3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
We also encountered many issues general to Twitter but not AAE; these are still important to deal with since AAE tweets include more non-standard linguistic phenomena overall.,3.2.4 Non-AAE Twitter issues,[0],[0]
"When possible, we adapted Kong et al. (2014)’s annotation conventions into the Universal Dependencies context, which are the only published conventions we know of for Twitter dependencies (for the FUDG dependency formalism).",3.2.4 Non-AAE Twitter issues,[0],[0]
"Issues include:
• @-mentions, which require different treatment when they are terms of address, versus nominal elements within a sentence.
",3.2.4 Non-AAE Twitter issues,[0],[0]
"• Hashtags, which in their tag-like usage are utterances by themselves (#tweetliketheoppositegender",3.2.4 Non-AAE Twitter issues,[0],[0]
Oh damn .).,3.2.4 Non-AAE Twitter issues,[0],[0]
"or sometimes can be words with standard syntactic relations within the sentence (#She’s A Savage, having #She’s nsubj←−− Savage).",3.2.4 Non-AAE Twitter issues,[0],[0]
"Both hashtag and @- mention ambiguities are handled by Owoputi et al. (2013)’s POS tagger.
",3.2.4 Non-AAE Twitter issues,[0],[0]
"• Multiple utterances, since we do not attempt sentence segmentation, and in many cases sentential utterances are not separated by explicit punctuation.",3.2.4 Non-AAE Twitter issues,[0],[0]
"FUDG allows for multiple roots for a text, but UD does not; instead we follow UD’s convention of the parataxis relation for what they describe as “side-by-side run-on sentences.”
5For example, Owoputi et al. (2013)’s Twitter word cluster 0011000 has 36 forms of gonna alone: http://www.cs.",3.2.4 Non-AAE Twitter issues,[0],[0]
"cmu.edu/∼ark/TweetNLP/cluster viewer.html
• Emoticons and emoji, which we attach as discourse relations to the utterance root, following UD’s treatment of interjections.
",3.2.4 Non-AAE Twitter issues,[0],[0]
"• Collapsed phrases, like omw for “on my way.”",3.2.4 Non-AAE Twitter issues,[0],[0]
"When possible, we used the principle of annotating according to the root of the subtree of the original phrase.",3.2.4 Non-AAE Twitter issues,[0],[0]
"For example, UD 2.0 prescribes way xcomp−−→ get for the sentence",3.2.4 Non-AAE Twitter issues,[0],[0]
"On my way to get...; therefore we use omw xcomp−−→ get for omw to get.
",3.2.4 Non-AAE Twitter issues,[0],[0]
"• Separated words, like uh round for “around,” which we analyze as multiword phrases (flat or compound).
",3.2.4 Non-AAE Twitter issues,[0],[0]
We discuss details for these and other cases in the online appendix.,3.2.4 Non-AAE Twitter issues,[0],[0]
Our experiments use the following two parsers.,4.1 Models,[0],[0]
"UDPipe (Straka et al., 2016) is a neural pipeline containing a tokenizer, morphological analyzer, tagger, and transition-based parser intended to be easily retrainable.",4.1 Models,[0],[0]
"The parser attains 80.2% LAS (labeled attachment score) on the UD English treebank with automatically generated POS tags, and was a baseline system used in the CoNLL 2017 Shared Task (Zeman et al., 2017).6
Deep Biaffine (Dozat et al., 2017; Dozat and Manning, 2016) is a graph-based parser incorporating neural attention and biaffine classifiers for arcs and labels.",4.1 Models,[0],[0]
"We used the version of the parser in the Stanford CoNLL 2017 Shared Task submission, which attained 82.2% LAS on the UD English treebank with automatically generated tags, and achieved the best performance in the task.",4.1 Models,[0],[0]
The model requires pre-trained word embeddings.,4.1 Models,[0],[0]
7,4.1 Models,[0],[0]
"We considered a series of experiments within both a cross-domain scenario (§4.2.1), where we trained only on UD Treebank data, and an indomain scenario (§4.2.2) using small amounts of our labeled data.",4.2 Experimental Setup,[0],[0]
"We use the parsing systems’ default hyperparameters (e.g. minibatch size and learning rate) and the default training/development split of the treebank (both systems perform early stopping based on development set performance).
",4.2 Experimental Setup,[0],[0]
6https://github.com/ufal/udpipe 7https://github.com/tdozat/UnstableParser/,4.2 Experimental Setup,[0],[0]
"Morpho-Tagger vs. ARK POS tags: The UD Treebank contains extensive fine-grained POS and morphological information, on which UDPipe’s morphological analyzer and tagging system is originally trained.",4.2.1 Cross-Domain Settings,[0],[0]
"This rich information should be useful for parsing, but the analyzers may be highly error-prone on out-of-domain, dialectal Twitter data, and contribute to poor parsing performance.",4.2.1 Cross-Domain Settings,[0],[0]
"We hypothesize that higher quality, even if coarser, POS information should improve parsing.
",4.2.1 Cross-Domain Settings,[0],[0]
"To test this, we retrain UDPipe in two different settings.",4.2.1 Cross-Domain Settings,[0],[0]
We first retrain the parser component with fine-grained PTB-style POS tags and morphological information provided by the tagger component;8 we call this the Morpho-Tagger setting.,4.2.1 Cross-Domain Settings,[0],[0]
"Second, we retrain the parser with morphological information stripped and its tags predicted from the ARK Twitter POS tagger (Owoputi et al., 2013), which is both tailored for Twitter and displays a smaller AAE vs MAE performance gap than traditional taggers (Jørgensen et al., 2016); we call this the ARK Tagger setting.9 The ARK Tagger’s linguistic representation is impoverished compared to Morpho-Tagger: its coarse-grained POS tag system does not include tense or number information, for example.10
Synthetic Data:",4.2.1 Cross-Domain Settings,[0],[0]
"Given our knowledge of Twitter- and AAE-specific phenomena that do not occur in the UD Treebank, we implemented a rulebased method to help teach the machine-learned parser these phenomena; we generated synthetic data for three Internet-specific conventions and one set of AAE syntactic features.",4.2.1 Cross-Domain Settings,[0],[0]
(This is inspired by Scherrer (2011)’s rule transforms between Standard and Swiss German.),4.2.1 Cross-Domain Settings,[0],[0]
"We performed each of the following transformations separately on a copy of the UD Treebank data and concatenated the transformed files together for the final training and development files, so that each final file contained several transformed copies of the original UD Treebank data.
1. @-mentions, emojis, emoticons, expressions, and hashtags: For each sentence in the UD Treebank we inserted at least one @-mention, emoji, emoticon, expression (Internet-specific words and
8We also retrained this component, to maintain consistency of training and development split.",4.2.1 Cross-Domain Settings,[0],[0]
"We also remove the universal (coarse) POS tags it produces, replacing them with the same PTB tags.
",4.2.1 Cross-Domain Settings,[0],[0]
"9We strip lemmas from training and development files for both settings.
",4.2.1 Cross-Domain Settings,[0],[0]
"10Derczynski et al. (2013)’s English Twitter tagger, which outputs PTB-style tags, may be of interest for future work.
",4.2.1 Cross-Domain Settings,[0],[0]
"abbreviations such as lol, kmsl, and xoxo), or hashtag, annotated with the correct relation, at the beginning of the sentence.",4.2.1 Cross-Domain Settings,[0],[0]
"An item of the same type was repeated with 50% probability, and a second item was inserted with 50% probability.",4.2.1 Cross-Domain Settings,[0],[0]
@- mentions were inserted using the ATMENTION token and emojis using the EMOJI token.,4.2.1 Cross-Domain Settings,[0],[0]
"Emoticons were inserted from a list of 20 common emoticons, expressions were inserted from a list of 16 common expressions, and hashtags were sampled for insertion according to their frequency in a list of all hashtags observed in the TwitterAAE corpus.
2.",4.2.1 Cross-Domain Settings,[0],[0]
"Syntactically participating @-mentions: To replicate occurrences of syntactically participating @-mentions, for each sentence in the UD Treebank with at least one token annotated with an nsubj or obj relation and an NNP POS tag, we replaced one at random with the ATMENTION token.
3.",4.2.1 Cross-Domain Settings,[0],[0]
"Multiple utterances: To replicate occurrences of multiple utterances, we randomly collapsed pairs of two short sentences (< 15 tokens) together, attaching the root of the second to the root of the first with the parataxis relation.
4.",4.2.1 Cross-Domain Settings,[0],[0]
AAE preverbal markers and auxiliaries: We introduced instances of verbal constructions present in AAE that are infrequent or non-existent in the UD Treebank data.,4.2.1 Cross-Domain Settings,[0],[0]
"First, constructions such as going to, about to, and want to are frequently collapsed to gonna, bouta, and wanna, respectively (see §3.2.2); for each sentence with at least one of these constructions, we randomly chose one to collapse.",4.2.1 Cross-Domain Settings,[0],[0]
"Second, we randomly replaced instances of going to with finna, a preverbal marker occurring in AAE and in the American South (Green, 2002).",4.2.1 Cross-Domain Settings,[0],[0]
"Third, we introduced the auxiliaries gone and done, which denote future tense and past tense, respectively; for the former, for each sentence containing at least one auxiliary will, we replace it with gone, and for the latter, for each sentence containing at least one nonauxiliary, non-passive, past-tense verb, we choose one and insert done before it.",4.2.1 Cross-Domain Settings,[0],[0]
"Finally, for each sentence containing at least one copula, we delete one at random.
",4.2.1 Cross-Domain Settings,[0],[0]
"Word Embeddings: Finally, since a tremendous variety of Twitter lexical items are not present in the UD Treebank, we use 200- dimensional word embeddings that we trained with word2vec11 (Mikolov et al., 2013) on the
11https://github.com/dav/word2vec
TwitterAAE corpus, which contains 60.8 million tweets.",4.2.1 Cross-Domain Settings,[0],[0]
"Before training, we processed the corpus by replacing @-mentions with ATMENTION, replacing emojis with EMOJI, and replacing sequences of more than two repeated letters with two repeated letters (e.g. partyyyyy → partyy).",4.2.1 Cross-Domain Settings,[0],[0]
"This resulted in embeddings for 487,450 words.
",4.2.1 Cross-Domain Settings,[0],[0]
"We retrain and compare UDPipe on each of the Morpho-Tagger and ARK Tagger settings with synthetic data and pre-trained embeddings, and without.",4.2.1 Cross-Domain Settings,[0],[0]
We additionally retrain Deep Biaffine with and without synthetic data and embeddings.12,4.2.1 Cross-Domain Settings,[0],[0]
We additionally investigate the effects of small amounts of in-domain training data from our dataset.,4.2.2 In-domain Training,[0],[0]
"We perform 2-fold cross-validation, randomly partitioning our dataset into two sets of 250 tweets.",4.2.2 In-domain Training,[0],[0]
"We compare two different settings (all using the UDPipe ARK Tagger setting):
Twitter-only: To explore the effect of training with Twitter data alone, for each set of 250 we trained on that set alone, along with our Twitter embeddings, and tested on the remaining 250.
",4.2.2 In-domain Training,[0],[0]
"UDT+Twitter: To explore the additional signal provided by the UD Treebank, for each set of 250 we trained on the UD Treebank concatenated with that set (with the tweets upweighted to approximately match the size of the UD Treebank, in order to use similar hyperparameters) and tested on the remaining 250.",4.2.2 In-domain Training,[0],[0]
"In our evaluation, we ignored punctuation tokens (labeled with punct) in our LAS calculation.",5 Results and Analysis,[0],[0]
Morpho-Tagger vs. ARK,5.1 Effects of Cross-Domain Settings,[0],[0]
"Tagger: As hypothesized, UDPipe’s ARK Tagger setting outperformed the Morpho-Tagger across all settings, ranging from a 2.8% LAS improvement when trained only on the UD Treebank with no pre-trained word embeddings, to 4.7% and 5.4% improvements when trained with Twitter embeddings and both Twitter embeddings and synthetic data, respectively.",5.1 Effects of Cross-Domain Settings,[0],[0]
"The latter improvements suggest that the ARK Tagger setup is able to take better advantage of Twitterspecific lexical information from the embeddings
12As the existing implementation of Deep Biaffine requires pre-trained word embeddings, for the Deep Biaffine baseline experiments we use the CoNLL 2017 Shared Task 100- dimensional embeddings that were pretrained on the English UD Treebank.
and syntactic patterns from the synthetic data.",5.1 Effects of Cross-Domain Settings,[0],[0]
"Table 1 shows the LAS for our various settings.
",5.1 Effects of Cross-Domain Settings,[0],[0]
"After observing the better performance of the ARK Tagger setting, we opted not to retrain the Deep Biaffine parser in any Morpho-Tagger settings due to the model’s significantly longer training time; all our Deep Biaffine results are reported for models trained with an ARK Tagger setting.
",5.1 Effects of Cross-Domain Settings,[0],[0]
"Synthetic data and embeddings: We observed that synthetic data and Twitter-trained embeddings were independently helpful; embeddings provided a 1.4–5.3% boost across the UDPipe and Deep Biaffine models, while synthetic data provided a 1.3– 5.7% additional boost (Table 1).
",5.1 Effects of Cross-Domain Settings,[0],[0]
"UDPipe vs. Deep Biaffine: While the baseline models for UDPipe and Deep Biaffine are not directly comparable (since the latter required pretrained embeddings), in the Twitter embeddings setting Deep Biaffine outperformed UDPipe by 5.1%.",5.1 Effects of Cross-Domain Settings,[0],[0]
"However, given access to both synthetic data and Twitter embeddings, UDPipe’s performance approached that of Deep Biaffine.",5.1 Effects of Cross-Domain Settings,[0],[0]
"Perhaps surprisingly, training with even limited amounts of in-domain training data aided in parsing performance; training with just in-domain data produced an LAS comparable to that of the baseline Deep Biaffine model, and adding UD Treebank data further increased LAS by 8.1%, indicat-
ing that they independently provide critical signal.",5.2 Effects of In-Domain Training,[0],[0]
"For each model in each of the cross-domain settings, we calculated the LAS on the 250 tweets drawn from highly African-American tweets and the 250 from highly White tweets (see §3 for details); we will refer to these as the AA and WH tweets, respectively.",5.3 AAE/MAE Performance Disparity,[0],[0]
"We observed clear disparities in performance between the two sets of tweets, ranging from 5.9% to 15.7% (Table 3).",5.3 AAE/MAE Performance Disparity,[0],[0]
"Additionally, across settings, we observed several patterns.
",5.3 AAE/MAE Performance Disparity,[0],[0]
"First, the UDPipe ARK Tagger settings produced significantly smaller gaps (5.9–8.4%) than the corresponding Morpho-Tagger settings (14.0– 15.7%).",5.3 AAE/MAE Performance Disparity,[0],[0]
"Indeed, most of the performance improvement of the ARK Tagger setting comes from the AA tweets; the LAS on the AA tweets jumps 7.2–9.2% from each Morpho-Tagger setting to the corresponding ARK Tagger setting, compared to differences of −0.9–1.9% for the WH tweets.
",5.3 AAE/MAE Performance Disparity,[0],[0]
"Second, the Deep Biaffine ARK Tagger settings produced larger gaps (8.0–11.6%) than the UDPipe ARK Tagger settings, with the exception of the embeddings-only setting.
",5.3 AAE/MAE Performance Disparity,[0],[0]
"Finally, we observed the surprising result that adding Twitter-trained embeddings and synthetic data, which contains both Twitter-specific and AAE-specific features, increases the performance gap across both UDPipe settings.",5.3 AAE/MAE Performance Disparity,[0],[0]
"We hypothesize that while UDPipe is able to effectively make use of both Twitter-specific lexical items and annotation conventions within MAE-like syntactic structures, it continues to be stymied by AAE-like syntactic structures, and is therefore unable to make use of the additional information.
",5.3 AAE/MAE Performance Disparity,[0],[0]
"We further calculated recall for each relation
type across the AA tweets and WH tweets, and the resulting performance gap, under the UDPipe Morpho-Tagger and ARK Tagger models trained with synthetic data and embeddings.",5.3 AAE/MAE Performance Disparity,[0],[0]
"Table 4 shows these calculations for the 15 relation types for which the performance gap was highest and which had at least 15 instances in each of the AA and WH tweet sets, along with the corresponding calculation under the ARK Tagger model.",5.3 AAE/MAE Performance Disparity,[0],[0]
The amount by which the performance gap is reduced from the first setting to the second setting is also reported.,5.3 AAE/MAE Performance Disparity,[0],[0]
"Of the 15 relations shown, the gap was reduced for 14, and 7 saw a reduction of at least 10%.",5.3 AAE/MAE Performance Disparity,[0],[0]
"In this section, we discuss AAE lexical and syntactic variations observed in our dataset, with the aim of providing insight into decreased AA parsing accuracy, and the impact of various parser settings on their parsing accuracy.
",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"AAE contains a variety of phonological features which present themselves on Twitter through a number of lexical variations (Green, 2002; Jones, 2015), many of which are listed in §3.1, instances of which occur a total of 80 times in the AA tweets; notably, none occur in the WH tweets.
",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"We investigated the accuracy of various crossdomain parser settings on these lexical variants; for each of the baseline Morpho-Tagger, baseline ARK Tagger, ARK Tagger with embeddings, and ARK Tagger with synthetic data and embeddings models, we counted the number of instances of lexical variants from §3.1 for which the model gave the correct head with the correct label.
",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"While the lexical variants challenged all four models, switching from the Morpho-Tagger set-
ting to the ARK Tagger settings produced significant accuracy increases (Table 6).",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
We observed that the greatest improvement came from using the ARK Tagger setting with Twitter-trained embeddings; the Twitter-specific lexical information provided by the embeddings was critical to recognizing the variants.,5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"Surprisingly, adding synthetic data decreased the model’s ability to parse the variants.
",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
We next investigated the presence of AAE syntactic phenomena in our dataset.,5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"Table 5 shows examples of seven well-documented AAE morphological and syntactic features and counts of their occurrences in our AA and WH tweet sets; again, while several of the phenomena, such as dropped
copulas and habitual be, occur frequently in our AA tweets, there is only one instance of any of these features occurring in the WH tweet set.
",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"We measured the parsing accuracy for the two most frequent syntactic features, dropped copulas and habitual be, across the four models; accuracies are given in Table 6.",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"For dropped copulas, we measured parsing correctness by checking if the parser correctly attached the subject to the correct predicate word via the nsubj relation; for the first example in Table 5, for example, we considered the parser correct if it attached bestfrienddd to mad via the nsubj relation.",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"For habitual be, we checked for correct attachment via the aux or cop relations as in the first and second examples in Ta-
ble 5, respectively.",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"As before, we observed significant increases in accuracy moving from the Morpho-Tagger to the ARK Tagger settings.",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"However, neither adding embeddings nor synthetic data appeared to significantly increase accuracy for these features.",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"From manual inspection, most of the dropped copulas errors appear to arise either from challenging questions (e.g. ATMENTION what yo number ?) or from mis-identification of the word to which to attach the subject (e.g. He claim he in love llh, where he was attached to llh rather than to love).",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"While current neural dependency parsers are highly accurate on MAE, our analyses suggest that AAE text presents considerable challenges due to lexical and syntactic features which diverge systematically from MAE.",6 Conclusion,[0],[0]
"While the cross-domain strategies we presented can greatly increase accurate parsing of these features, narrowing the performance gap between AAE- and MAE-like tweets, much work remains to be done for accurate parsing of even linguistically well-documented features.
",6 Conclusion,[0],[0]
"It remains an open question whether it is better to use a model with a smaller accuracy disparity (e.g. UDPipe), or a model with higher average accuracy, but a worse disparity (e.g. Deep Biaffine).",6 Conclusion,[0],[0]
"The emerging literature on fairness in algorithms suggests interesting further challenges; for example, Kleinberg et al. (2017) and CorbettDavies et al. (2017) argue that as various commonly applied notions of fairness are mutually incompatible, algorithm designers must grapple with such trade-offs.",6 Conclusion,[0],[0]
"Regardless, the modeling decision should be made in light of the application of interest; for example, applications like opinion analysis and information retrieval may benefit from equal (and possibly weaker) performance between groups, so that concepts or opinions in-
ferred from groups of authors (e.g. AAE speakers) are not under-counted or under-represented in results returned to a user or analyst.",6 Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
"This work was supported by a Google Faculty Research Award, and a National Science Foundation Graduate Research Fellowship (No. 1451512).",Acknowledgments,[0],[0]
"Due to the presence of both Twitterspecific conventions and non-standard and dialectal language, Twitter presents a significant parsing challenge to current dependency parsing tools.",abstractText,[0],[0]
"We broaden English dependency parsing to handle social media English, particularly social media African-American English (AAE), by developing and annotating a new dataset of 500 tweets, 250 of which are in AAE, within the Universal Dependencies 2.0 framework.",abstractText,[0],[0]
"We describe our standards for handling Twitterand AAE-specific features and evaluate a variety of crossdomain strategies for improving parsing with no, or very little, in-domain labeled data, including a new data synthesis approach.",abstractText,[0],[0]
"We analyze these methods’ impact on performance disparities between AAE and Mainstream American English tweets, and assess parsing accuracy for specific AAE lexical and syntactic features.",abstractText,[0],[0]
Our annotated data and a parsing model are available at: http://slanglab.cs.umass.edu/ TwitterAAE/.,abstractText,[0],[0]
Twitter Universal Dependency Parsing for African-American and Mainstream American English,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 810–820 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
810",text,[0],[0]
In this paper we study two bilingual tasks that strongly depend on bilingual word embeddings (BWEs).,1 Introduction,[0],[0]
"Previously, specialized domain adaptation approaches to such tasks were proposed.",1 Introduction,[0],[0]
We instead show experimentally that a simple adaptation process involving only unlabeled text is highly effective.,1 Introduction,[0],[0]
"We then show that a semisupervised classification method from computer vision can be applied successfully for further gains in cross-lingual classification.
",1 Introduction,[0],[0]
Our BWE adaptation method is delightfully simple.,1 Introduction,[0],[0]
We begin by adapting monolingual word embeddings to the target domain for source and target languages by simply building them using both general and target-domain unlabeled data.,1 Introduction,[0],[0]
"As
a second step we use post-hoc mapping (Mikolov et al., 2013b), i.e., we use a seed lexicon to transform the word embeddings of the two languages into the same vector space.",1 Introduction,[0],[0]
We show experimentally for the first time that the domain-adapted bilingual word embeddings we produce using this extremely simple technique are highly effective.,1 Introduction,[0],[0]
"We study two quite different tasks and domains, where resources are lacking, showing that our simple technique performs well for both of them: cross-lingual twitter sentiment classification and medical bilingual lexicon induction.",1 Introduction,[0],[0]
"In previous work, task-dependent approaches were used for this type of domain adaptation.",1 Introduction,[0],[0]
"Our approach is simple and task independent.
",1 Introduction,[0],[0]
"Second, we adapt the semi-supervised image classification system of Häusser et al. (2017) for NLP problems for the first time.",1 Introduction,[0],[0]
This approach is broadly applicable to many NLP classification tasks where unlabeled data is available.,1 Introduction,[0],[0]
We tailor it to both of our cross-lingual tasks.,1 Introduction,[0],[0]
"The system exploits unlabeled data during the training of classifiers by learning similar features for similar labeled and unlabeled training examples, thereby extracting information from unlabeled examples as well.",1 Introduction,[0],[0]
"As we show experimentally, the system further improves cross-lingual knowledge transfer for both of our tasks.
",1 Introduction,[0],[0]
"After combining both techniques, the results of sentiment analysis are competitive with systems that use annotated data in the target language, an impressive result considering that we require no target-language annotated data.",1 Introduction,[0],[0]
The method also yields impressive improvements for bilingual lexicon induction compared with baselines trained on in-domain data.,1 Introduction,[0],[0]
We show that this system requires the high-quality domain-adapted bilingual word embeddings we previously created to use unlabeled data well.,1 Introduction,[0],[0]
Many approaches have been proposed for creating high quality BWEs using different bilingual signals.,2.1 Bilingual Word Embeddings,[0],[0]
"Following Mikolov et al. (2013b), many authors (Faruqui and Dyer, 2014; Xing et al., 2015; Lazaridou et al., 2015; Vulić and Korhonen, 2016) map monolingual word embeddings (MWEs) into the same bilingual space.",2.1 Bilingual Word Embeddings,[0],[0]
"Others leverage parallel texts (Hermann and Blunsom, 2014; Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vulić and Moens, 2015; Duong et al., 2016) to train BWEs.
",2.1 Bilingual Word Embeddings,[0],[0]
"In contrast, our aim is not to improve the intrinsic quality of BWEs, but to adapt BWEs to specific domains to enhance their performance on bilingual tasks in these domains.",2.1 Bilingual Word Embeddings,[0],[0]
"Faruqui et al. (2015), Gouws and Søgaard (2015), Rothe et al. (2016) have previously studied domain adaptation of bilingual word embeddings, showing it to be highly effective for improving downstream tasks.",2.1 Bilingual Word Embeddings,[0],[0]
"However, importantly, their proposed methods are based on specialized domain lexicons (such as, e.g., sentiment lexicons) which contain task specific word relations.",2.1 Bilingual Word Embeddings,[0],[0]
"Our delightfully simple approach is, in contrast, effectively task independent (in that it only requires unlabeled in-domain text), which is an important strength.",2.1 Bilingual Word Embeddings,[0],[0]
"Sentiment analysis is widely applied, and thus ideally we would have access to high quality supervised models in all human languages.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Unfortunately, good quality labeled datasets are missing for many languages.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
Training models on resource rich languages and applying them to resource poor languages is therefore highly desirable.,2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Crosslingual sentiment classification (CLSC) tackles this problem (Mihalcea et al., 2007; Banea et al., 2010; Wan, 2009; Lu et al., 2011; Balamurali and Joshi, 2012; Gui et al., 2013).",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Recent CLSC approaches use BWEs as features of deep learning architectures which allows us to use a model for target-language sentiment classification, even when the model was trained only using sourcelanguage supervised training data.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
Following this approach we perform CLSC on Spanish tweets using English training data.,2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Even though Spanish is not resource-poor we simulate this by using only English annotated data.
",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Xiao and Guo (2013) proposed a cross-lingual log-bilinear document model to learn distributed representations of words, which can capture both the semantic similarities of words across languages and the predictive information with respect to the classification task.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Similarly, Tang and Wan (2014) jointly embedded texts in different languages into a joint semantic space representing sentiment.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Zhou et al. (2014) employed aligned sentences in the BWE learning process, but in the sentiment classification process only representations in the source language are used for training, and representations in the target language are used for predicting labels.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"An important weakness of these three works was that aligned sentences were required.
",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Some work has trained sentiment-specific BWEs using annotated sentiment information in both languages (Zhou et al., 2015, 2016), which is desirable, but this is not applicable to our scenario.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
Our goal is to adapt BWEs to a specific domain without requiring additional task-specific engineering or knowledge sources beyond having access to plentiful target-language in-domain unlabeled text.,2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Both of the approaches we study in this work fit this criterion, the delightfully simple method for adapting BWEs can improve the performance of any off-the-shelf classifier that is based on BWEs, while the broadly applicable semi-supervised approach of Häusser et al. (2017) can improve the performance of any off-the-shelf classifier.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
BLI is an important task that has been addressed by a large amount of previous work.,2.3 Bilingual Lexicon Induction (BLI),[0],[0]
The goal of BLI is to automatically extract word translation pairs using BWEs.,2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"While BLI is often used to provide an intrinsic evaluation of BWEs (Lazaridou et al., 2015; Vulić and Moens, 2015; Vulić and Korhonen, 2016)",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"it is also useful for tasks such as machine translation (Madhyastha and España Bohnet, 2017).",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
Most work on BLI using BWEs focuses on frequent words in high-resource domains such as parliament proceedings or news texts.,2.3 Bilingual Lexicon Induction (BLI),[0],[0]
Recently Heyman et al. (2017) tackled BLI of words in the medical domain.,2.3 Bilingual Lexicon Induction (BLI),[0],[0]
This task is useful for many applications such as terminology extraction or OOV mining for machine translation of medical texts.,2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"Heyman et al. (2017) show that when only a small amount of medical data is available,
BLI using BWEs tends to perform poorly.",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"Especially BWEs obtained using post-hoc mapping (Mikolov et al., 2013b; Lazaridou et al., 2015) fail on this task.",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"Consequently, Heyman et al. (2017) build BWEs using aligned documents and then engineer a specialized classification-based approach to BLI.",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"In contrast, our delightfully simple approach to create high-quality BWEs for the medical domain requires only monolingual data.",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
We show that our adapted BWEs yield impressive improvements over non-adapted BWEs in this task with both cosine similarity and with the classifier of Heyman et al. (2017).,2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"In addition, we show that the broadly applicable method can push performance further using easily accessible unlabeled data.",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
BWEs trained on general domain texts usually result in lower performance when used in a system for a specific domain.,3 Adaptation of BWEs,[0],[0]
There are two reasons for this.,3 Adaptation of BWEs,[0],[0]
"(i) Vocabularies of specific domains contain words that are not used in the general case, e.g., names of medicines or diseases.",3 Adaptation of BWEs,[0],[0]
"(ii) The meaning of a word varies across domains; e.g., “apple” mostly refers to a fruit in general domains, but is an electronic device in many product reviews.
",3 Adaptation of BWEs,[0],[0]
The delightfully simple method adapts general domain BWEs in a way that preserves the semantic knowledge from general domain data and leverages monolingual domain specific data to create domain-specific BWEs.,3 Adaptation of BWEs,[0],[0]
Our domain-adaptation approach is applicable to any language-pair in which monolingual data is available.,3 Adaptation of BWEs,[0],[0]
"Unlike other methods, our approach is task independent: it only requires unlabeled in-domain target language text.",3 Adaptation of BWEs,[0],[0]
"To create domain adapted BWEs, we first train MWEs (monolingual word embeddings) in both languages and then map those into the same space using post-hoc mapping (Mikolov et al., 2013b).",3.1 Approach,[0],[0]
We train MWEs for both languages by concatenating monolingual out-of-domain and in-domain data.,3.1 Approach,[0],[0]
The out-of-domain data allows us to create accurate distributed representations of common vocabulary while the in-domain data embeds domain specific words.,3.1 Approach,[0],[0]
We then map the two MWEs using a small seed lexicon to create the adapted BWEs.,3.1 Approach,[0],[0]
"Because post-hoc mapping only requires a seed lexicon as bilingual signal it can
easily be used with (cheap) monolingual data.",3.1 Approach,[0],[0]
"For post-hoc mapping, we use Mikolov et al. (2013b)’s approach.",3.1 Approach,[0],[0]
This model assumes a W ∈ Rd1×d2 matrix which maps vectors from the source to the target MWEs where d1 and d2 are the embedding space dimensions.,3.1 Approach,[0],[0]
"A seed lexicon of (xi, yi) ∈ L ⊆ Rd1×Rd2 pairs is needed where xi and yi are source and target MWEs.",3.1 Approach,[0],[0]
"W can be learned using ridge regression by minimizing the L2-regularized mapping error between the source xi and the target yi vectors:
min W ∑ i ||Wxi − yi||22 + λ||W ||22 (1)
where λ is the regularization weight.",3.1 Approach,[0],[0]
"Based on the source embedding x, we then compute a target embedding as Wx.
We create MWEs with word2vec skipgram (Mikolov et al., 2013a)1 and estimate W with scikit-learn (Pedregosa et al., 2011).",3.1 Approach,[0],[0]
We use default parameters.,3.1 Approach,[0],[0]
"In CLSC, an important application of BWEs, we train a supervised sentiment model on training data available in the source (a resource rich language) and apply it to the target (a resource poor language, for which there is typically no training data available).",4 Cross-Lingual Sentiment Classification,[0],[0]
"Because BWEs embed source and target words in the same space, annotations in the source (represented as BWEs) enable transfer learning.",4 Cross-Lingual Sentiment Classification,[0],[0]
"For CLSC of tweets, a drawback of BWEs trained on non-twitter data is that they do not produce embeddings for twitter-specific vocabulary, e.g., slang words like English coool and (Mexican) Spanish chido, resulting in lost information when a sentiment classifier uses them.",4 Cross-Lingual Sentiment Classification,[0],[0]
"As comparable non-twitter data we use OpenSubtitles (Lison and Tiedemann, 2016) which contains 49.2M English and Spanish subtitle sentences respectively (Subtitle).",4.1 Training Data for Twitter Specific BWEs,[0],[0]
The reason behind choosing Subtitles is that although it is out-of-domain it contains slang words similar to tweets thus serving as a strong baseline in our setup.,4.1 Training Data for Twitter Specific BWEs,[0],[0]
"We experiment with two monolingual twitter data sets:
(i) 22M tweets: Downloaded2 English (17.2M) and Spanish (4.8M) tweets using the public
1https://github.com/dav/word2vec 2We downloaded for a month starting on 2016-10-15.
",4.1 Training Data for Twitter Specific BWEs,[0],[0]
"Twitter Streaming API3 with language filters en and es
(ii) a BACKGROUND corpus of 296K English and 150K Spanish (non-annotated) tweets released with the test data of the RepLab task (Amigó et al., 2013) described below
All twitter data was tokenized using Bird et al. (2009) and lowercased.",4.1 Training Data for Twitter Specific BWEs,[0],[0]
"User names, URLs, numbers, emoticons and punctuation were removed.
",4.1 Training Data for Twitter Specific BWEs,[0],[0]
"As lexicon for the mapping, we use the BNC word frequency list (Kilgarriff, 1997), a list of 6,318 frequent English lemmas and their Spanish translations, obtained from Google Translate.",4.1 Training Data for Twitter Specific BWEs,[0],[0]
Note that we do not need a domain-specific lexicon in order to get good quality adapted BWEs.,4.1 Training Data for Twitter Specific BWEs,[0],[0]
"For sentiment classification, we use data from the RepLab 2013 shared task (Amigó et al., 2013).",4.2 Training Data for Sentiment Classifiers,[0],[0]
"The data is annotated with positive, neutral and negative labels and contains English and Spanish tweets.",4.2 Training Data for Sentiment Classifiers,[0],[0]
We used the official English training set (26.6K tweets) and the Spanish test set (14.9K) in the resource-poor setup.,4.2 Training Data for Sentiment Classifiers,[0],[0]
"We only use the 7.2K Spanish labeled training data for comparison reasons in §6.2, which we will discuss later.
",4.2 Training Data for Sentiment Classifiers,[0],[0]
"The shared task was on target-level sentiment analysis, i.e., given a pair (document, target entity), the gold annotation is based on whether the sentiment expressed by the document is about the target.",4.2 Training Data for Sentiment Classifiers,[0],[0]
For example: I cried on the back seat of my BMW!,4.2 Training Data for Sentiment Classifiers,[0],[0]
where BMW is the target would be negative in the sentence-level scenario.,4.2 Training Data for Sentiment Classifiers,[0],[0]
"However, it is neutral in the target-level case because the negative sentiment is not related to BMW.",4.2 Training Data for Sentiment Classifiers,[0],[0]
The reason for using this dataset is that it contains comparable English and Spanish tweets annotated for sentiment.,4.2 Training Data for Sentiment Classifiers,[0],[0]
"There are other twitter datasets for English (Nakov et al., 2016) and Spanish (GarcıaCumbreras et al., 2016), but they were downloaded at different times and were annotated using different annotation methodologies, thus impeding a clean and consistent evaluation.",4.2 Training Data for Sentiment Classifiers,[0],[0]
For evaluating our adapted BWEs on the RepLab dataset we used a target-aware sentiment classifier introduced by Zhang et al. (2016).,4.3 Sentiment Systems,[0],[0]
"The network first embeds input words using pre-trained
3dev.twitter.com/streaming/overview
BWEs and feeds them to a bi-directional gated neural network.",4.3 Sentiment Systems,[0],[0]
Pooling is applied on the hidden representations of the left and right context of the target mention respectively.,4.3 Sentiment Systems,[0],[0]
"Finally, gated neurons are used to model the interaction between the target mention and its surrounding context.",4.3 Sentiment Systems,[0],[0]
"During training we hold our pre-trained BWEs fixed and keep the default parameters of the model.
",4.3 Sentiment Systems,[0],[0]
"We also implement Kim (2014)’s CNN-nonstatic system, which does not use the target information in a given document (target-ignorant).",4.3 Sentiment Systems,[0],[0]
The network first embeds input words using pretrained BWEs and feeds them to a convolutional layer with multiple window sizes.,4.3 Sentiment Systems,[0],[0]
Max pooling is applied on top of convolution followed by a fully connected network with one hidden layer.,4.3 Sentiment Systems,[0],[0]
We used this system as well because it performed comparably to the target-aware system.,4.3 Sentiment Systems,[0],[0]
"The reason for this is that only 1% of the used data contains more than one target and out of these rare cases only 14% have differing sentiment labels in the same sentence, which are the difficult cases of target-level sentiment analysis.",4.3 Sentiment Systems,[0],[0]
"We used the default parameters as described in (Kim, 2014) with the exception of using 1000 feature maps and 30 epochs, based on our initial experiments.",4.3 Sentiment Systems,[0],[0]
Word embeddings are fixed during the training just as for the target-aware classifier.,4.3 Sentiment Systems,[0],[0]
As we previously explained we evaluate our adaptation method on the task of target-level sentiment classification using both target-aware and target-ignorant classifiers.,4.4 Results,[0],[0]
"For all experiments, our two baselines are off-the-shelf classifiers using non-adapted BWEs, i.e., BWEs trained only using Subtitles.",4.4 Results,[0],[0]
Our goal is to show that our BWE adaptation method can improve the performance of such classifiers.,4.4 Results,[0],[0]
We train our adapted BWEs on the concatenation of Subtitle and 22M tweets or BACKGROUND respectively.,4.4 Results,[0],[0]
"In addition, we also report results with BWEs trained only on tweets.
",4.4 Results,[0],[0]
To train the sentiment classifiers we use the English Replab training set and we evaluate on the Spanish test set.,4.4 Results,[0],[0]
"To show the performance that can be reached in a monolingual setup, we report results obtained by using annotated Spanish sentiment data instead of English (oracle).",4.4 Results,[0],[0]
"We train two oracle sentiment classifiers using (i) MWEs trained on only the Spanish part of Subtitle and (ii)
BWEs trained on Subtitle using posthoc mapping.",4.4 Results,[0],[0]
"The difference between the two is that the embeddings of (ii) are enriched with English words which can be beneficial for the classification of Spanish tweets because they often contain a few English words.
",4.4 Results,[0],[0]
We do not compare with word embedding adaptation methods relying on specialized resources.,4.4 Results,[0],[0]
The point of our work is to study task-independent methods and to the best of our knowledge ours is the first such attempt.,4.4 Results,[0],[0]
"Similarly, we do not compare against machine translation based sentiment classifiers (e.g., (Zhou et al., 2016))",4.4 Results,[0],[0]
"because for their adaptation in-domain parallel data would be needed.
",4.4 Results,[0],[0]
Table 1 gives results for both classifiers.,4.4 Results,[0],[0]
It shows that the adaptation of Subtitle based BWEs with data from Twitter (22M tweets and BACKGROUND) clearly outperforms the Baseline in all cases.,4.4 Results,[0],[0]
The target-aware system performed poorly with the baseline BWEs and could benefit significantly from the adaptation approach.,4.4 Results,[0],[0]
The target-ignorant performed better with the baseline BWEs but could also benefit from the adaptation.,4.4 Results,[0],[0]
"Comparing results with the Twitter-dataset-only based BWEs, the 22M tweets performed better even though the BACKGROUND dataset is from the same topic as the RepLab train and test sets.",4.4 Results,[0],[0]
Our conjecture is that the latter is too small to create good BWEs.,4.4 Results,[0],[0]
"In combination with Subtitles, 22M tweets also yields better results than when combined with BACKGROUND.",4.4 Results,[0],[0]
"Although the best accuracy was reached using the 22M tweetsonly based BWEs, it is only slightly better then the adapted Subtitles+22M tweets based BWEs.",4.4 Results,[0],[0]
"In §6 we show that both the semantic knowledge from Subtitles and the domain-specific information from tweets are needed to further improve results.
",4.4 Results,[0],[0]
Comparing the two classifiers we can say that they performed similarly in terms of their best results.,4.4 Results,[0],[0]
"On the other hand, the target-ignorant system had better results on average.",4.4 Results,[0],[0]
This might seem surprising at first because the system does not use the target as information.,4.4 Results,[0],[0]
"But considering the characteristics of RepLab, i.e., that the number of tweets that contains multiple targets is negligible, using the target offers no real advantage.
",4.4 Results,[0],[0]
"Although we did not focus on the impact of the seed lexicon size, we ran post-hoc mapping with different sizes during our preliminary experiments.",4.4 Results,[0],[0]
"With 1,000 and 100 word pairs in the lexicon the target-ignorant system suffered 0.5% and 4.0% drop in average of our setups respectively.
",4.4 Results,[0],[0]
To summarize the result: using adapted BWEs for the Twitter CLSC task improves the performance of off-the-shelf classifiers.,4.4 Results,[0],[0]
Another interesting downstream task for BWEs is bilingual lexicon induction.,5 Medical Bilingual Lexicon Induction,[0],[0]
"Given a list of words in a source language, the goal of BLI is to mine translations for each word in a chosen target language.",5 Medical Bilingual Lexicon Induction,[0],[0]
"The medical bilingual lexicon induction task proposed in (Heyman et al., 2017) aims to mine medical words using BWEs trained on a very small amount of English and Dutch monolingual medical data.",5 Medical Bilingual Lexicon Induction,[0],[0]
"Due to the lack of resources in this domain, good quality BWEs are hard to build using in-domain data only.",5 Medical Bilingual Lexicon Induction,[0],[0]
We show that by enriching BWEs with general domain knowledge (in the form of general domain monolingual corpora) better results can be achieved on this medical domain task.,5 Medical Bilingual Lexicon Induction,[0],[0]
We evaluate our improved BWEs on the dataset provided by Heyman et al. (2017).,5.1 Experimental Setup,[0],[0]
The monolingual medical data consists of English and Dutch medical articles from Wikipedia.,5.1 Experimental Setup,[0],[0]
The English (resp.,5.1 Experimental Setup,[0],[0]
"Dutch) articles contain 52,336 (resp.",5.1 Experimental Setup,[0],[0]
"21,374) sentences.",5.1 Experimental Setup,[0],[0]
"A total of 7,368 manually annotated word translation pairs occurring in the English (source) and Dutch (target) monolingual corpora are provided as gold data.",5.1 Experimental Setup,[0],[0]
This set is split 64%/16%/20% into trn/dev/test.,5.1 Experimental Setup,[0],[0]
20% of the English words have multiple translations.,5.1 Experimental Setup,[0],[0]
"Given an English word, the task is to find the correct Dutch translation.
",5.1 Experimental Setup,[0],[0]
"As monolingual general-domain data we use
the English and Dutch data from Europarl (v7) (Koehn, 2005), a corpus of 2 million sentence pairs.",5.1 Experimental Setup,[0],[0]
"Although Europarl is a parallel corpus, we use it in a monolingual way and shuffle each side of the corpus before training.",5.1 Experimental Setup,[0],[0]
By using massive cheap data we create high-quality MWEs in each language which are still domain-specific (due to inclusion of medical data).,5.1 Experimental Setup,[0],[0]
"To obtain an out-ofdomain seed lexicon, we translated the English words in BNC to Dutch using Google Translate (just as we did before for the Twitter CLSC task).",5.1 Experimental Setup,[0],[0]
We then use the out-of-domain BNC and the indomain medical seed lexicons in separate experiments to create BWEs with post-hoc mapping.,5.1 Experimental Setup,[0],[0]
"Note, we did not concatenate the two lexicons because (i) they have a small common subset of source words which have different target words, thus having a negative effect on the mapping and (ii) we did not want to modify the medical seed lexicon because it was taken from previous work.",5.1 Experimental Setup,[0],[0]
To perform BLI we use two methods.,5.2 BLI Systems,[0],[0]
"Because BWEs represent words from different languages in a shared space, BLI can be performed via cosine similarity in this space.",5.2 BLI Systems,[0],[0]
"In other words, given a BWE representing two languages Vs and Vt, the translation of each word s ∈",5.2 BLI Systems,[0],[0]
"Vs can be induced by taking the word t ∈ Vt whose representation ~xt in the BWE is closest to the representation ~xs.
",5.2 BLI Systems,[0],[0]
As the second approach we use a classifier based system proposed by Heyman et al. (2017).,5.2 BLI Systems,[0],[0]
This neural network based system is comprised of two main modules.,5.2 BLI Systems,[0],[0]
The first is a character-level LSTM which aims to learn orthographic similarity of word pairs.,5.2 BLI Systems,[0],[0]
The other is the concatenation of the embeddings of the two words using embedding layers with the aim of learning the similarity among semantic representations of the words.,5.2 BLI Systems,[0],[0]
Dense layers are applied on top of the two modules before the output soft-max layer.,5.2 BLI Systems,[0],[0]
"The classifier is trained using positive and negative word
pair examples and a pre-trained word embedding model.",5.2 BLI Systems,[0],[0]
Negative examples are randomly generated for each positive one in the training lexicon.,5.2 BLI Systems,[0],[0]
We used default parameters as reported by Heyman et al. (2017) except for the t classification thresholds (used at prediction time).,5.2 BLI Systems,[0],[0]
We finetuned these on dev.,5.2 BLI Systems,[0],[0]
"We note that the system works with pre-trained MWEs as well (and report these as official baseline results) but it requires BWEs for candidate generation at prediction time, thus we use BWEs for the system’s input for all experiments.",5.2 BLI Systems,[0],[0]
"In preliminary work, we had found that MWE and BWE results are similar.",5.2 BLI Systems,[0],[0]
Heyman et al. (2017)’s results are our baseline.,5.3 Results,[0],[0]
"Table 2 compares its performance with our adapted BWEs, with both cosine similarity and classification based systems.",5.3 Results,[0],[0]
“top” F1 scores are based on the most probable word as prediction only; “all” F1 scores use all words as prediction whose probability is above the threshold.,5.3 Results,[0],[0]
It can be seen that the cosine similarity based system using adapted BWEs clearly outperforms the nonadapted BWEs which were trained in a resource poor setup.4,5.3 Results,[0],[0]
"Moreover, the best performance was reached using the general seed lexicon for the mapping which is due to the fact that general domain words have better quality embeddings in the MWE models, which in turn gives a better quality mapping.
",5.3 Results,[0],[0]
The classification based system performs significantly better comparing to cosine similarity by exploiting the seed lexicon better.,5.3 Results,[0],[0]
Using adapted BWEs as input word embeddings for the system further improvements were achieved which shows the better quality of our BWEs.,5.3 Results,[0],[0]
"Simulating an even poorer setup by using a general lexicon, the
4The results for cosine similarity in (Heyman et al., 2017) are based on BWESG-based BWEs (Vulić and Moens, 2016) trained on a small document aligned parallel corpus without using a seed lexicon.
performance gain of the classifier is lower.",5.3 Results,[0],[0]
This shows the significance of the medical seed lexicon for this system.,5.3 Results,[0],[0]
"On the other hand, adapted BWEs have better performance compared to non-adapted ones using the best translation while they have just slightly lower F1 using multiple translations.",5.3 Results,[0],[0]
"This result shows that while with adapted BWEs the system predicts better “top” translations, it has a harder time when predicting “all” due to the increased vocabulary size.
",5.3 Results,[0],[0]
To summarize: we have shown that adapted BWEs increase performance for this task and domain; and they do so independently of the taskspecific system that is used.,5.3 Results,[0],[0]
"In addition to the experiments that show our BWEadaptation method’s task and language independence, we investigate ways to further incorporate unlabeled data to overcome data sparsity.
",6 Semi-Supervised Learning,[0],[0]
Häusser et al. (2017) introduce a semisupervised method for neural networks that makes associations from the vector representation of labeled samples to those of unlabeled ones and back.,6 Semi-Supervised Learning,[0],[0]
This lets the learning exploit unlabeled samples as well.,6 Semi-Supervised Learning,[0],[0]
"While Häusser et al. (2017) use their model for image classification, we adapt it to CLSC of tweets and medical BLI.",6 Semi-Supervised Learning,[0],[0]
We show that our semisupervised model requires adapted BWEs to be effective and yields significant improvements.,6 Semi-Supervised Learning,[0],[0]
This innovative method is general and can be applied to any classification when unlabeled text is available.,6 Semi-Supervised Learning,[0],[0]
"Häusser et al. (2017)’s basic assumption is that the embeddings of labeled and unlabeled samples – i.e., the representations in the neural network on which the classification layer is applied – are similar within the same class.",6.1 Model,[0],[0]
"To achieve this, walking cycles are introduced: a cycle starts from a labeled sample, goes to an unlabeled one and ends at a labeled one.",6.1 Model,[0],[0]
A cycle is correct if the start and end samples are in the same class.,6.1 Model,[0],[0]
The probability of going from sample A to B is proportional to the cosine similarity of their embeddings.,6.1 Model,[0],[0]
"To maximize the number of correct cycles, two loss functions are employed: Walker loss and Visit loss.
",6.1 Model,[0],[0]
"Walker loss penalizes incorrect walks and encourages a uniform probability distribution of
walks to the correct class.",6.1 Model,[0],[0]
"It is defined as:
Lwalker := H(T, P aba) (2)
where H is the cross-entropy function, P abaij is the probability that a cycle starts from sample i and ends at j and T is the uniform target distribution:
",6.1 Model,[0],[0]
"Tij :=
{ 1/(#c(i)) if c(i) = c(j)
0",6.1 Model,[0],[0]
"otherwise (3)
where c(i) is the class of sample i and #c(i) is the number of occurrences of c(i) in the labeled set.
",6.1 Model,[0],[0]
"Visit loss encourages cycles to visit all unlabeled samples, rather than just those which are the most similar to labeled samples.",6.1 Model,[0],[0]
"It is defined as:
Lvisit := H(V, P visit)
P visitj := 〈P abij 〉i (4)
",6.1 Model,[0],[0]
"Vj := 1
U
whereH is cross-entropy, P abij is the probability that a cycle starts from sample i and goes to j and U is the number of unlabeled samples.
",6.1 Model,[0],[0]
"The total loss during training is the sum of the walker, visit and classification (cross-entropy between predicted and gold labels) losses which is minimized using Adam (Kingma and Ba, 2015).
",6.1 Model,[0],[0]
"We adapt this model (including the two losses) to sentiment classification, focusing on the targetignorant classifier, and the classifier based approach for BLI.",6.1 Model,[0],[0]
We will call these systems semisup5.,6.1 Model,[0],[0]
Due to the fact that we initialize the embedding layers for both classifiers with BWEs the models are able to make some correct cycles at the beginning of the training and improve them later on.,6.1 Model,[0],[0]
"We will describe the labeled and unlabeled datasets used in the subsequent sections below.
",6.1 Model,[0],[0]
"We use Häusser et al. (2017)’s implementation of the losses, with 1.0, 0.5 and 1.0 weights for the walker, visit and classification losses, respectively, for CLSC based on preliminary experiments.",6.1 Model,[0],[0]
"We fine-tuned the weights for BLI on dev for each experiment.
",6.1 Model,[0],[0]
5We publicly release our implementation: https:// github.com/hangyav/biadapt,6.1 Model,[0],[0]
"As in §4.4, we use pre-trained BWEs to initialize the classifier and use English sentiment training data as the labeled set.",6.2 Semi-Supervised CLSC,[0],[0]
"Furthermore, we use the Spanish sentiment training data as the unlabeled set, ignoring its annotation.",6.2 Semi-Supervised CLSC,[0],[0]
"This setup is very similar to real-word low-resource scenarios: unlabeled target-language tweets are easy to download while labeled English ones are available.
",6.2 Semi-Supervised CLSC,[0],[0]
Table 3 gives results for adapted BWEs and shows that semisup helps only when word embeddings are adapted to the Twitter domain.,6.2 Semi-Supervised CLSC,[0],[0]
"As mentioned earlier, semisup compares labeled and unlabeled samples based on their vector representations.",6.2 Semi-Supervised CLSC,[0],[0]
"By using BWEs based on only Subtitles, we lose too many embeddings of similar English and Spanish tweets.",6.2 Semi-Supervised CLSC,[0],[0]
"On the other hand, if we use only tweet-based BWEs we lose good quality semantic knowledge which can be learned from more standard text domains.",6.2 Semi-Supervised CLSC,[0],[0]
By combining the two domains we were able to capture both sides.,6.2 Semi-Supervised CLSC,[0],[0]
"For Subtitle+22M tweets, we even get very close to the best oracle (BWE Subtitle) in Table 1 getting only 0.27% less accuracy – an impressive result keeping in mind that we did not use labeled Spanish data.
",6.2 Semi-Supervised CLSC,[0],[0]
"The RepLab dataset contains tweets from 4 topics: automotive, banking, university, music.",6.2 Semi-Supervised CLSC,[0],[0]
We manually analyzed similar tweets from the labeled and unlabeled sets.,6.2 Semi-Supervised CLSC,[0],[0]
"We found that when using semisup, English and Spanish tweets from the same topics are more similar in the embedding space than occurs without the additional losses.",6.2 Semi-Supervised CLSC,[0],[0]
"Topics differ in how they express sentiment – this may explain why semisup increases performance for RepLab.
",6.2 Semi-Supervised CLSC,[0],[0]
Adding supervision.,6.2 Semi-Supervised CLSC,[0],[0]
"To show how well semisup can exploit the unlabeled data we used both English and Spanish sentiment training data together to train the sentiment classifiers.
",6.2 Semi-Supervised CLSC,[0],[0]
Table 4 shows that by using annotated data in both languages we get clearly better results than when using only one language.,6.2 Semi-Supervised CLSC,[0],[0]
"Tables 3 and 4 show that for Subtitle+22M tweets based BWEs, the semisup approach achieved high improvement (2.17%) comparing to targetignorant with English training data only, while it achieved lower improvement (0.97%) with the Subtitle+BACKGROUND based BWEs.",6.2 Semi-Supervised CLSC,[0],[0]
"On the other hand, adding labeled Spanish data caused just a slight increase comparing to semisup with Subtitle+22M tweets based BWEs (0.59%), while in case of Subtitle+BACKGROUND we got significant additional improvement (2.61%).",6.2 Semi-Supervised CLSC,[0],[0]
"This means that with higher quality BWEs, unlabeled target-language data can be exploited better.
",6.2 Semi-Supervised CLSC,[0],[0]
It can also be seen that the target-aware system outperformed the target-ignorant system using additional labeled target-language data.,6.2 Semi-Supervised CLSC,[0],[0]
"The reason could be that it is a more complex network and therefore needs more data to reach high performance.
",6.2 Semi-Supervised CLSC,[0],[0]
The results in table 4 are impressive: our targetlevel system is strongly competitive with the official shared task results.,6.2 Semi-Supervised CLSC,[0],[0]
We achieved high accuracy on the Spanish test set by using only English training data.,6.2 Semi-Supervised CLSC,[0],[0]
"Comparing our best system which used all training data to the official results (Amigó et al., 2013)",6.2 Semi-Supervised CLSC,[0],[0]
we would rank 2nd even though our system is not fine-tuned for the RepLab dataset.,6.2 Semi-Supervised CLSC,[0],[0]
"Furthermore, we also outperformed the oracles when using annotated data from both languages which shows the additional advantage of using BWEs.",6.2 Semi-Supervised CLSC,[0],[0]
For BLI experiments with semisup we used word pairs from the medical seed lexicon as the labeled set (with negative word pairs generated as described in §5.2).,6.3 Semi-Supervised BLI,[0],[0]
"As opposed to CLSC and the work of (Häusser et al., 2017), for this task we do not have an unlabeled set, and therefore we need to generate it.",6.3 Semi-Supervised BLI,[0],[0]
We developed two scenarios.,6.3 Semi-Supervised BLI,[0],[0]
"For the first, BNC, we generate a general unlabeled set using English words from the BNC lexicon and generate 10 pairs out of each word by using the 5 most similar Dutch words based on the corresponding BWEs and 5 random Dutch words.",6.3 Semi-Supervised BLI,[0],[0]
"For the second scenario, medical, we generate an in-domain unlabeled set by generating for each English word in the medical lexicon the 3 most similar Dutch
words based on BWEs and for each of these we use the 5 most similar English words (ignoring the words which are in the original medical lexicon) and 5 negative words.",6.3 Semi-Supervised BLI,[0],[0]
"The idea behind these methods is to automatically generate an unlabeled set that hopefully has a similar positive and negative word pair distribution to the distribution in the labeled set.
",6.3 Semi-Supervised BLI,[0],[0]
Results in Table 5 show that adding semisup to the classifier further increases performance for BLI as well.,6.3 Semi-Supervised BLI,[0],[0]
"For the baseline system, when using only in-domain text for creating BWEs, only the medical unlabeled set was effective, general domain word pairs could not be exploited due to the lack of general semantic knowledge in the BWE model.",6.3 Semi-Supervised BLI,[0],[0]
"On the other hand, by using our domain adapted BWEs, which contain both general domain and in-domain semantical knowledge, we can exploit word pairs from both domains.",6.3 Semi-Supervised BLI,[0],[0]
"Results for adapted BWEs increased in 3 out of 4 cases, where the only exception is when using multiple translations for a given source word (which may have been caused by the bigger vocabulary size).
",6.3 Semi-Supervised BLI,[0],[0]
"These results show that adapted BWEs are needed to exploit unlabeled data well which leads to an impressive overall 3.71 increase compared with the best result in previous work (Heyman et al., 2017), by using only unlabeled data.",6.3 Semi-Supervised BLI,[0],[0]
Bilingual word embeddings trained on general domain data yield poor results in out-of-domain tasks.,7 Conclusion,[0],[0]
We presented experiments on two different low-resource task/domain combinations.,7 Conclusion,[0],[0]
Our delightfully simple task independent method to adapt BWEs to a specific domain uses unlabeled monolingual data only.,7 Conclusion,[0],[0]
We showed that with the support of adapted BWEs the performance of offthe-shelf methods can be increased for both crosslingual Twitter sentiment classification and medical bilingual lexicon induction.,7 Conclusion,[0],[0]
"Furthermore, by adapting the broadly applicable semi-supervised approach of Häusser et al. (2017) (which until now has only been applied in computer vision) we were able to effectively exploit unlabeled data to further improve performance.",7 Conclusion,[0],[0]
"We showed that, when also using high-quality adapted BWEs, the performance of the semi-supervised systems can be significantly increased by using unlabeled data at classifier training time.",7 Conclusion,[0],[0]
"In addition, CLSC results are competitive with a system that uses targetlanguage labeled data, even when we use no such target-language labeled data.",7 Conclusion,[0],[0]
We would like to thank the anonymous reviewers for their valuable input.,Acknowledgments,[0],[0]
This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement№ 640550).,Acknowledgments,[0],[0]
"Bilingual tasks, such as bilingual lexicon induction and cross-lingual classification, are crucial for overcoming data sparsity in the target language.",abstractText,[0],[0]
"Resources required for such tasks are often out-of-domain, thus domain adaptation is an important problem here.",abstractText,[0],[0]
We make two contributions.,abstractText,[0],[0]
"First, we test a delightfully simple method for domain adaptation of bilingual word embeddings.",abstractText,[0],[0]
We evaluate these embeddings on two bilingual tasks involving different domains: cross-lingual twitter sentiment classification and medical bilingual lexicon induction.,abstractText,[0],[0]
"Second, we tailor a broadly applicable semi-supervised classification method from computer vision to these tasks.",abstractText,[0],[0]
We show that this method also helps in low-resource setups.,abstractText,[0],[0]
"Using both methods together we achieve large improvements over our baselines, by using only additional unlabeled data.",abstractText,[0],[0]
Two Methods for Domain Adaptation of Bilingual Tasks: Delightfully Simple and Broadly Applicable,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 105–114 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
105
We propose to consider these two aspects jointly. We develop TWOWINGOS (twowing optimization strategy), a system that, while identifying appropriate evidence for a claim, also determines whether or not the claim is supported by the evidence. Given the claim, TWOWINGOS attempts to identify a subset of the evidence candidates; given the predicted evidence, it then attempts to determine the truth value of the corresponding claim. We treat this challenge as coupled optimization problems, training a joint model for it. TWOWINGOS offers two advantages: (i) Unlike pipeline systems, it facilitates flexible-size evidence set, and (ii) Joint training improves both the claim verification and the evidence identification. Experiments on a benchmark dataset show state-of-the-art performance.1",text,[0],[0]
"A claim, e.g., “Marilyn Monroe worked with Warner Brothers”, is an assertive sentence that may be true or false.",1 Introduction,[0],[0]
"While the task of claim verification will not tell us the absolute truth of this claim, it is expected to determine whether the claim is supported by evidence in a given text collection.",1 Introduction,[0],[0]
"Specifically, given a claim and a text corpus, evidential claim verification, demonstrated in
1cogcomp.org/page/publication_view/847
Figure 1, aims at identifying text snippets in the corpus that act as evidence that supports or refutes the claim.
",1 Introduction,[0],[0]
This problem has broad applications.,1 Introduction,[0],[0]
"For example, knowledge bases (KB), such as Freebase (Bollacker et al., 2008), YAGO (Suchanek et al., 2007), can be augmented with a new relational statement such as “(Afghanistan, is source of, Kushan Dynasty)”.",1 Introduction,[0],[0]
"This needs to be first verified by a claim verification process and supported by evidence (Roth et al., 2009; Chaganty et al., 2017).",1 Introduction,[0],[0]
"More broadly, claim verification is a key component in any technical solution addressing recent concerns about the trustworthiness of online content (Vydiswaran et al., 2011; Pasternack and Roth, 2013; Hovy et al., 2013).",1 Introduction,[0],[0]
"In both scenarios, we care about whether or not a claim holds, and seek reliable evidence in support of this decision.
",1 Introduction,[0],[0]
Evidential claim verification requires that we address three challenges.,1 Introduction,[0],[0]
"First, to locate text snippets in the given corpus that can potentially be used to determine the truth value of the given claim.",1 Introduction,[0],[0]
"This differs from the conventional textual entailment (TE) problem (Dagan et al., 2013) as here we first look for the premises given a hypothesis.",1 Introduction,[0],[0]
"Clearly, the evidence one seeks depends on the claim, as well as on the eventual entailment
decision – the same claim would require different supporting than refuting evidence.",1 Introduction,[0],[0]
This motivates us to develop an approach that can transfer knowledge from claim verification to evidence identification.,1 Introduction,[0],[0]
"Second, the evidence for a claim might require aggregating information from multiple sentences and even multiple documents (rf. #3 in Table 4).",1 Introduction,[0],[0]
"Therefore, a set, rather than a collection of independent text snippets, should be chosen to act as evidence.",1 Introduction,[0],[0]
"And, finally, in difference from TE, given a set of evidence sentences as a premise, the truth value of the claim should depend on all of the evidence, rather than on a single sentence there.
",1 Introduction,[0],[0]
The discussion above suggests that claim verification and evidence identification are tightly coupled.,1 Introduction,[0],[0]
"Claim should influence the identification of appropriate evidence, and “trusted evidence boosts the claim’s veracity” (Vydiswaran et al., 2011).",1 Introduction,[0],[0]
"Consequently, we propose TWOWINGOS, a twowing optimization strategy2, to support this process.",1 Introduction,[0],[0]
"As shown in Figure 2, we consider a set of sentences S as the candidate evidence space, a claim x, and a decision space Y for the claim verification.",1 Introduction,[0],[0]
"In the optimal condition, a one-hot vector over Y indicates which decision to make towards the claim, and a binary vector over S indicates a subset of sentences Se (in blue in Figure 2) to act as evidence.
",1 Introduction,[0],[0]
"Prior work mostly approached this problem as a pipeline procedure – first, given a claim x, determine Se by some similarity matching; then, conduct textual entailment over (Se, x) pairs.",1 Introduction,[0],[0]
"Our framework, TWOWINGOS, optimizes the two
2By “two-wing optimization”, we mean that the same object, i.e., the claim, is mapped into two target spaces in a joint optimization scheme.
subtasks jointly, so that both claim verification and evidence identification can enhance each other.",1 Introduction,[0],[0]
"TWOWINGOS is a generic framework making use of a shared representation of the claim to cotrain evidence identification and claim verification.
",1 Introduction,[0],[0]
"TWOWINGOS is tested on the FEVER benchmark (Thorne et al., 2018), showing≈30% F1 improvement for evidence identification, and ≈23% accuracy increase in claim verification.",1 Introduction,[0],[0]
Our analysis shows that (i) entity mentions in claims provide a strong clue for retrieving relevant passages; (ii) composition of evidence clues across sentences helps claim verification; and that (iii) the joint training scheme provides significant benefits of a pipeline architecture.,1 Introduction,[0],[0]
Most work focuses on the dataset construction while lacking advanced models to handle the problem.,2 Related Work,[0],[0]
"Vlachos and Riedel (2014) propose and define the “fact checking” problem, without a concrete solution.",2 Related Work,[0],[0]
Ferreira and Vlachos (2016) release the dataset “Emergent” for rumor debunking.,2 Related Work,[0],[0]
Each claim is accompanied by an article headline as evidence.,2 Related Work,[0],[0]
Then a three-way logistic regression model is used over some rule-based features.,2 Related Work,[0],[0]
No need to search for evidence.,2 Related Work,[0],[0]
"Wang (2017) release a larger dataset for fake news detection, and propose a hybrid neural network to integrate the statement and the speaker’s meta data to do classification.",2 Related Work,[0],[0]
"However, the presentation of evidences is ignored.",2 Related Work,[0],[0]
"Kobayashi et al. (2017) release a similar dataset to (Thorne et al., 2018), but they do not consider the evaluation of evidence reasoning.
",2 Related Work,[0],[0]
"Some work mainly pays attention to determining whether the claim is true or false, assuming evidence facts are provided or neglecting presenting evidence totally, e.g., (Angeli and Manning, 2014) – given a database of true facts as premises, predicting whether an unseen fact is true and should belong to the database by natural logic inference.",2 Related Work,[0],[0]
"Open-domain question answering (QA) against a text corpus (Yin et al., 2016; Chen et al., 2017; Wang et al., 2018) can also be treated as claim verification problem, if we treat (question, correct answer) as a claim.",2 Related Work,[0],[0]
"However, little work has studied how well a QA system can identify all the answer evidence.
",2 Related Work,[0],[0]
"Only a few works considered improving the evidence presentation in claim verification problems.
",2 Related Work,[0],[0]
"Roth et al. (2009) introduce the task of Entailed Relation Recognition – given a set of short paragraphs and a relational fact in the triple form of (argument1, relation, argument2), finding the paragraphs that can entail this fact.",2 Related Work,[0],[0]
"They first use Expanded Lexical Retrieval to rank and keep the topk paragraphs as candidates, then build a TE classifier over each (candidate, statement) pair.",2 Related Work,[0],[0]
The work directly related to us is by Thorne et al. (2018).,2 Related Work,[0],[0]
"Given claims and a set of Wikipages, Thorne et al. (2018) use a retrieval model based on TF-IDF to locate top-5 sentences in top-5 pages as evidence, then utilize a neural entailment model to classify (evidence, claim) pairs.
",2 Related Work,[0],[0]
"In contrast, our work tries to optimize the claim verification as well as the evidence identification in a joint training scheme, which is more than just supporting or refuting the claims.",2 Related Work,[0],[0]
"Figure 2 illustrates the two-wing optimization problem addressed in this work: given a collection of evidence candidates S={s1, s2, · · · , si, · · · , sm}, a claim x and a decision set Y = {y1 · · · , yn}, the model TWOWINGOS predicts a binary vector p over S and a one-hot vector o over Y against the ground truth, a binary vector q and a one-hot vector z, respectively.",3 The TWOWINGOS Model,[0],[0]
"A binary vector over S means a subset of sentences (Se) act as evidence, and the one-hot vector indicates a single decision (yi) to be made towards the claim x given the evidence Se.",3 The TWOWINGOS Model,[0],[0]
"Next, we use two separate subsections to elaborate the process of evidence identification (i.e., optimize p to q) and the claim verification (i.e., optimize o to z).",3 The TWOWINGOS Model,[0],[0]
"A simple approach to identifying evidence is to detect the top-k sentences that are lexically similar to the claim, as some pipeline systems (Roth et al., 2009; Thorne et al., 2018) do.",3.1 Evidence identification,[0],[0]
"However, a claimunaware fixed k is less optimal, adding noise or missing key supporting factors, consequently limiting the performance.
",3.1 Evidence identification,[0],[0]
"In this work, we approach the evidence by modeling sentences S={s1, · · · , si, · · · , sm} with the claim x as context in a supervised learning scheme.",3.1 Evidence identification,[0],[0]
"For each si, the problem turns out to be learning a probability: how likely si can entail the claim conditioned on other candidates as context, as shown by the blue items in Figure 2.
To start, a piece of text t (t ∈ S ∪ {x}) is represented as a sequence of l hidden states, forming a feature map T ∈ Rd×l, where d is the dimensionality of hidden states.",3.1 Evidence identification,[0],[0]
"We first stack a vanilla CNN (convolution & max-pooling) (LeCun et al., 1998) over T to get a representation for t. As a result, each evidence candidate si has a representation si, and the claim x has a representation x.",3.1 Evidence identification,[0],[0]
"To get a probability for each si, we need first to build its claim-aware representation ri.
Coarse-grained representation.",3.1 Evidence identification,[0],[0]
"We directly concatenate the representation of si and x, generated by the vanilla CNN, as:
ri =",3.1 Evidence identification,[0],[0]
"[si,x, si · xT ]",3.1 Evidence identification,[0],[0]
"(1)
This coarse-grained approach makes use of merely the sentence-level representations while neglecting more fine-grained interactions between the sentences and the claim.
",3.1 Evidence identification,[0],[0]
Fine-grained representation,3.1 Evidence identification,[0],[0]
.,3.1 Evidence identification,[0],[0]
"Instead of directly employing the sentence-level representations, here we explore claim-aware representations for each word in sentence si, then compose them as the sentence representation ri, inspired by the Attentive Convolution (Yin and Schütze, 2017).
",3.1 Evidence identification,[0],[0]
"For each word sji in si, we first calculate its matching score towards each word xz in x, by dot product over their hidden states.",3.1 Evidence identification,[0],[0]
"Then the representation of the claim, as the context for the word sji , is formed as:
cji = ∑ z softmax(sji · (x z)T ) ·",3.1 Evidence identification,[0],[0]
"xz (2)
Now, word sji has left context s j−1 i , right context sj+1i in si, and the claim-aware context c j i from x.",3.1 Evidence identification,[0],[0]
"A convolution encoder generates its claim-aware representation iji :
iji = tanh(W ·",3.1 Evidence identification,[0],[0]
"[s j−1 i , s j i , s j+1 i , c j",3.1 Evidence identification,[0],[0]
"i ] + b) (3) where parameters W ∈ Rd×4d, b ∈ Rd.",3.1 Evidence identification,[0],[0]
"To compose those claim-aware word representations as the representation for sentence si, we use a max-pooling over {iji} along with j, generating ii.
",3.1 Evidence identification,[0],[0]
"We use term fint(si, x) to denote this whole process, so that:
ii = fint(si, x) (4)
",3.1 Evidence identification,[0],[0]
"At this point, the fine-grained representation for evidence candidate si is:
ri =",3.1 Evidence identification,[0],[0]
"[si,x, si · xT , ii] (5)
Loss function.",3.1 Evidence identification,[0],[0]
"With a claim-aware representation ri, the sentence si subsequently gets a probability, acting as the evidence, αi ∈ (0, 1) via a non-linear sigmoid function:
αi = sigmoid(v · rTi ) (6)
where parameter vector v has the same dimensionality as ri.
",3.1 Evidence identification,[0],[0]
"In the end, all evidence candidates in S have a ground-truth binary vector q and the predicted probability vector α; then loss lev (“ev”: evidence) is implemented as a binary cross-entropy:
lev =",3.1 Evidence identification,[0],[0]
m∑ i=1,3.1 Evidence identification,[0],[0]
−(qi log(αi)+(1−qi) log(1−αi)),3.1 Evidence identification,[0],[0]
"(7)
As the output of this evidence identification module, we binarize the probability vector α by pi =",3.1 Evidence identification,[0],[0]
[αi > 0.5] (“[x]” is 1 if x is true or 0 otherwise).,3.1 Evidence identification,[0],[0]
pi indicates si is evidence or not.,3.1 Evidence identification,[0],[0]
All {si} with pi = 1 act as evidence set Se.,3.1 Evidence identification,[0],[0]
"As shown in Figure 2, to figure out an entailment decision yi for the claim x, the evidence Se possibly consists of more than one sentence.",3.2 Claim verification,[0],[0]
"Furthermore, those evidence sentences are not necessarily in textual order nor from the same passage.",3.2 Claim verification,[0],[0]
"So, we need a mechanism that enables each evidence or even each word inside to be aware of the content from other evidence sentences.",3.2 Claim verification,[0],[0]
"Similar to the aforementioned approach to evidence identification, we come up with three methods, with different representation granularity, to learn a representation for (Se, x), i.e., the input for claim verification, shown in Figure 3.
Coarse-grained representation.",3.2 Claim verification,[0],[0]
"In this case, we treat Se as a whole, constructing its representation e by summing up the representations of all sentences in Se in a weighted way:
e =",3.2 Claim verification,[0],[0]
m∑ i=1,3.2 Claim verification,[0],[0]
"αi · pi · si (8)
where αi, from Equation 6, is the probability of si being the evidence.
",3.2 Claim verification,[0],[0]
"Then the (Se, x) pair gets a coarse-grained concatenated representation:",3.2 Claim verification,[0],[0]
"[e,x].",3.2 Claim verification,[0],[0]
It does not model the interactions within the evidence nor the interactions between the evidence and the claim.,3.2 Claim verification,[0],[0]
"Based on our experience in evidence identification
module, the representation of a sentence is better learned by composing context-aware word-level representations.",3.2 Claim verification,[0],[0]
"Next, we introduce how to learn fine-grained representation for the (Se, x) pair.
",3.2 Claim verification,[0],[0]
Single-channel fine-grained representation.,3.2 Claim verification,[0],[0]
"By “single-channel,” we mean each sentence si is aware of the claim x as its single context.
",3.2 Claim verification,[0],[0]
"For a single pair (si, x), we utilize the function fint() in Equation 4 to build the fine-grained representations for both si and x, obtaining ii =
fint(si, x) for si and xi = fint(x, si) for x.",3.2 Claim verification,[0],[0]
"For (Se, x), we compose all the {ii} and all the {xi} along with i, via a weighted max-pooling:
e = maxpooli(αi · pi · ii) (9) x = maxpooli(αi · pi · xi) (10)
",3.2 Claim verification,[0],[0]
This weighted max-pooling ensures that the sentences with higher probabilities of being evidence have a higher chance to present their features.,3.2 Claim verification,[0],[0]
"As a result, (Se, x) gets a concatenated representation:",3.2 Claim verification,[0],[0]
"[e, x]
Two-channel fine-grained representation.",3.2 Claim verification,[0],[0]
"By “two-channel,” we mean that each evidence si is aware of two kinds of context, one from the claim x, the other from the remaining evidences.
",3.2 Claim verification,[0],[0]
Our first step is to accumulate evidence clues within Se.,3.2 Claim verification,[0],[0]
"To start, we concatenate all sentences in Se as a fake long sentence Ŝ consisting of hidden states {ŝ}.",3.2 Claim verification,[0],[0]
"Similar to Equation 2, for each word sji in sentence si, we accumulate all of its related clues (cji ) from Ŝ as follows:
cji = ∑ z softmax(sji · (ŝ z)T ) · ŝz (11)
",3.2 Claim verification,[0],[0]
"Then we update sji , the representation of word sji , by element-wise addition:
sji = s j i ⊕ c j",3.2 Claim verification,[0],[0]
"i (12)
",3.2 Claim verification,[0],[0]
This step enables the word sji to “see” all related clues from Se.,3.2 Claim verification,[0],[0]
The reason we add s j i and c j,3.2 Claim verification,[0],[0]
"i is motivated by a simple experience: Assume the claim “Lily lives in the biggest city in Canada”, and one sentence contains a clue “· · · Lily lives in Toronto · · · ” and another sentence contains a clue “· · · Toronto is Canada’s largest city· · · ”.",3.2 Claim verification,[0],[0]
"The most simple yet effective approach to aggregating the two clues is to sum up their representation vectors (Blacoe and Lapata, 2012) (we do not concatenate them, as those clues have no consistent textual order across different sji ).
",3.2 Claim verification,[0],[0]
"After updating the representation of each word in si, we perform the aforementioned “singlechannel fine-grained representation” between the updated si and the claim x, generating [e, x].
",3.2 Claim verification,[0],[0]
Loss function.,3.2 Claim verification,[0],[0]
"For the claim verification input (Se, x), we forward its representation",3.2 Claim verification,[0],[0]
"[e, x] to a
logistic regression layer in order to infer a probability distribution o over the label space Y :
o = softmax(W ·",3.2 Claim verification,[0],[0]
"[e,x] + b) (13)
where W ∈ Rn×2d, b ∈",3.2 Claim verification,[0],[0]
Rn,3.2 Claim verification,[0],[0]
"The loss lcv (“cv”: claim verification) is implemented as negative log-likelihood:
lcv = − log(o · zT )",3.2 Claim verification,[0],[0]
"(14)
where z is the ground truth one-hot label vector for the claim x on the space Y .",3.2 Claim verification,[0],[0]
"Given the loss lev in evidence identification and the loss lcv in claim verification, the overall training loss is represented by:
l = lev + lcv (15)
",3.3 Joint optimization,[0],[0]
"To ensure that we jointly train the two coupled subtasks with intensive knowledge communication instead of simply putting two pipeline neural networks together, our TWOWINGOS has following configurations: • Both subsystems share the same set of word embeddings as parameters; the vanilla CNNs for learning sentence and claim representations share parameters as well.",3.3 Joint optimization,[0],[0]
•,3.3 Joint optimization,[0],[0]
"The output binary vector p by the evidence identification module is forwarded to the module of claim verification, as shown in Equations 8-10.",3.3 Joint optimization,[0],[0]
•,3.3 Joint optimization,[0],[0]
"Though the representation of a claim’s decision yi is not put explicitly into the module of evidence identification, the claim’s representation x will be fine-tuned by the yi, so that the evidence candidates can get adjustment from the decision yi, since the claims are shared by two modules.",3.3 Joint optimization,[0],[0]
Dataset.,4.1 Setup,[0],[0]
"In this work, we use FEVER (Thorne et al., 2018).",4.1 Setup,[0],[0]
"The claims in FEVER were generated from the introductory parts of about 50K
Wikipedia pages of a June 2017 dump.",4.1 Setup,[0],[0]
Annotators construct claims about a single fact of the title entity with arbitrarily complex expressions and entity forms.,4.1 Setup,[0],[0]
"To increase the claim complexity so that claims would not be trivially verified, annotators adopt two routes: (i) Providing additional knowledge: Annotators can explore a dictionary of terms that were (hyper-)linked, along with their pages; (ii) Mutate claims in six ways: negation, paraphrasing, substitution of a relation/entity with a similar/dissimilar one, and making the claims more general/specific.",4.1 Setup,[0],[0]
All resulting claims have 9.4 tokens in average.,4.1 Setup,[0],[0]
"Apart from claims, FEVER also provides a Wikipedia corpus in size of about 5.4 million.
",4.1 Setup,[0],[0]
"Each claim is labeled as SUPPORTED, REFUTED or NOTENOUGHINFO (NEI).",4.1 Setup,[0],[0]
"In addition, evidence sentences, from any wiki page, are required to be provided for SUPPORTED and REFUTED.",4.1 Setup,[0],[0]
Table 1 lists the data statistics.,4.1 Setup,[0],[0]
Figure 4 shows the distributions of sentence sizes and page sizes in FEVER’s evidence set.,4.1 Setup,[0],[0]
"We can see that roughly 28% of the evidence covers more than one sentence, and approximately 16.3% of the evidence covers more than one wiki page.
",4.1 Setup,[0],[0]
"This task has three evaluations: (i) NOSCOREEV – accuracy of claim verification, neglecting the validity of evidence; (ii) SCOREEV – accuracy of claim verification with a requirement that the predicted evidence fully covers the gold evidence for SUPPORTED and REFUTED; (iii) F1 – between the predicted evidence sentences and the ones chosen by annotators.",4.1 Setup,[0],[0]
"We use the officially released evaluation scorer 3.
",4.1 Setup,[0],[0]
"3https://github.com/sheffieldnlp/fever-scorer
Wiki page retrieval4.",4.1 Setup,[0],[0]
"For each claim, we search in the given dictionary of wiki pages in the form of {title: sentence list}, and keep the top-5 ranked pages for fair comparison with Thorne et al. (2018).",4.1 Setup,[0],[0]
Algorithm 1 briefly shows the steps of wiki page retrieval.,4.1 Setup,[0],[0]
"To speed up, we first build an inverted index from words to titles, then for each claim, we only search in the titles that cover at least one claim word.
",4.1 Setup,[0],[0]
"Input: A claim, wiki={title: page vocab} Output: A ranked top-k wiki titles Generate entity mentions from the claim; while each title do
if claim.vocab∩title.vocab is empty then discard this title else title score = the max recall value of title.vocab
in claim and in entity mentions of the claim; if title score = 1.0 then
title.score = title score else
page score = recall of claim in page vocab;
title.score = title score + page score end
end end Sort titles by title.score in descending order
Algorithm 1: Algorithm description of wiki page retrieval for FEVER claims.
",4.1 Setup,[0],[0]
"All sentences of the top-5 retrieved wiki pages are kept as evidence candidates for claims in train, dev and test.",4.1 Setup,[0],[0]
"It is worth mentioning that this page retrieval step is a reasonable preprocessing which controls the complexity of evidence searching in real-world, such as the big space – 5.4 million – in this work.
",4.1 Setup,[0],[0]
Training setup.,4.1 Setup,[0],[0]
"All words are initialized by 300D Word2Vec (Mikolov et al., 2013) embeddings, and are fine-tuned during training.",4.1 Setup,[0],[0]
"The whole system is trained by AdaGrad (Duchi et al., 2011).",4.1 Setup,[0],[0]
"Other hyperparameter values include: learning rate 0.02, hidden size 300, mini-batch size 50, filter width 3.
Baselines.",4.1 Setup,[0],[0]
"In this work, we first consider the two systems reported by Thorne et al. (2018): (i) MLP: A multi-layer perceptron with one hidden layer, based on TF-IDF cosine similarity between the claim and the evidence (all evidence sentences are concatenated as a longer text piece) (Riedel et al., 2017); (ii) Decomp-Att (Parikh et al., 2016):",4.1 Setup,[0],[0]
"A decomposable attention model that develops atten-
4Our retrieval results are released as well.
tion mechanisms to decompose the problem into subproblems to solve in parallel.",4.1 Setup,[0],[0]
"Note that both systems first employed an IR system to keep top5 relevant sentences from the retrieved top-5 wiki pages as static evidence for claims.
",4.1 Setup,[0],[0]
"We further consider the following variants of our own system TWOWINGOS: • Coarse-coarse: Both evidence identification and claim verification adopt coarse-grained representations.
",4.1 Setup,[0],[0]
"To further study our system, we test this “coarse-coarse” in three setups: (i) “pipeline” – train the two modules independently.",4.1 Setup,[0],[0]
"Forward the predicted evidence to do entailment for claims; (ii) “diff-CNN” – joint training with separate CNN parameters to learn sentence/claim representations; (iii) “share-CNN” – joint training with shared CNN parameters.
",4.1 Setup,[0],[0]
The following variants are in joint training.,4.1 Setup,[0],[0]
"• Fine&sentence-wise: Given the evidence with multiple sentences, a natural baseline is to do entailment reasoning for each (sentence, claim), then compose.",4.1 Setup,[0],[0]
"We do entailment reasoning between each predicted evidence sentence and the claim, generating a probability distribution over the label space Y .",4.1 Setup,[0],[0]
"Then we sum up all the distribution vectors element-wise, as an ensemble system, to predict the label; • Four combinations of different grained representation learning: “coarse&fine(single)”, “coarse&fine(two)”, “fine&coarse” and “fine&fine(two)”.",4.1 Setup,[0],[0]
“Single” and “two” refer to the single/two-channel cases respectively.,4.1 Setup,[0],[0]
Performance of passage retrieval.,4.2 Results,[0],[0]
"Table 2 compares our wikipage retriever with the one in
(Thorne et al., 2018), which used a document retriever5 from DrQA (Chen et al., 2017).
",4.2 Results,[0],[0]
Our document retrieval module surpasses the competitor by a big margin in terms of the coverage of gold passages: 89.63% vs. 55.30% (k = 5 in all experiments).,4.2 Results,[0],[0]
Its powerfulness should be attributed to: (i) Entity mention detection in the claims.,4.2 Results,[0],[0]
"(ii) As wiki titles are entities, we have a bi-channel way to match the claim with the wiki page: one with the title, the other with the page body, as shown in Algorithm 1.
",4.2 Results,[0],[0]
Performance on FEVER Table 3 lists the performances of baselines and the TWOWINGOS variants on FEVER (dev&test).,4.2 Results,[0],[0]
"From the dev block, we observe that: • TWOWINGOS (from “share-CNN”) surpasses prior systems in big margins.",4.2 Results,[0],[0]
"Overall, fine-grained schemes in each subtask contribute more than the coarse-grained counterparts; • In the three setups – “pipeline”, “diff-CNN” and “share-CNN” – of coarse-coarse, “pipeline” gets better scores than (Thorne et al., 2018) in terms of evidence identification.",4.2 Results,[0],[0]
“Share-CNN” has comparable F1 as “diff-CNN” while gaining a lot on NOSCOREEV (72.32 vs. 39.22) and SCOREEV (50.12 vs. 21.04).,4.2 Results,[0],[0]
This clearly shows that the claim verification gains much knowledge transferred from the evidence identification module.,4.2 Results,[0],[0]
Both “diff-CNN” and “share-CNN” perform better than “pipeline” (except for the slight inferiority at SCOREEV: 21.04 vs. 22.26).,4.2 Results,[0],[0]
"• Two-channel fine-grained representations show more effective than the single-channel counterpart in claim verification (NOSCOREEV: 78.77 vs. 75.65, SCOREEV: 53.64 vs. 52.65).",4.2 Results,[0],[0]
"As we expected, evidence sentences should collaborate in inferring the truth value of the claims.",4.2 Results,[0],[0]
Two-channel setup enables an evidence candidate aware of other candidates as well as the claim.,4.2 Results,[0],[0]
"• In the last three rows of dev, there is no clear difference among their evidence identification scores.",4.2 Results,[0],[0]
"Recall that “sent-wise” is essentially an ensemble system over each (sentence, claim) entailment result.",4.2 Results,[0],[0]
"“Coarse-grained”, instead, first sums up all sentence representation, then performs ( ∑
(sentence), claim) reasoning.",4.2 Results,[0],[0]
We can also treat this “sum up” as an ensemble.,4.2 Results,[0],[0]
"Their comparison shows that these two kinds of tricks do not
5It compares passages and claims as TF-IDF weighted bag-of-bigrams.
make much difference.",4.2 Results,[0],[0]
"If we adopt “two-channel fine-grained representation” in claim verification, big improvements are observed in both NOSCOREEV (+7.42%) and SCOREEV (+3%).
",4.2 Results,[0],[0]
"In the test block, our system (fine&fine(two)) beats the prior top system across all measurements by big margins – F1: 47.15 vs. 17.47; SCOREEV: 54.33 vs. 31.87; NOSCOREEV: 75.99 vs. 50.91.
",4.2 Results,[0],[0]
"In both dev and test blocks, we can observe that our evidence identification module consistently
obtains balanced recall and precision.",4.2 Results,[0],[0]
"In contrast, the pipeline system by Thorne et al. (2018) has much higher recall than precision (45.89 vs. 10.79).",4.2 Results,[0],[0]
"It is worth mentioning that the SCOREEV metric is highly influenced by the recall value, since SCOREEV is computed on the claim instances whose evidences are fully retrieved, regardless of the precision.",4.2 Results,[0],[0]
"So, ideally, a system can set all sentences as evidence, so that SCOREEV can be promoted to be equal to NOSCOREEV.",4.2 Results,[0],[0]
"Our system is more reliable in this perspective.
",4.2 Results,[0],[0]
Performance vs. #sent.,4.2 Results,[0],[0]
in evidence.,4.2 Results,[0],[0]
Figure 5 shows the results of the five evaluation measures against different sizes of gold evidence sentences in test set.,4.2 Results,[0],[0]
We observe that: (i),4.2 Results,[0],[0]
"Our system has robust precisions across #sentence; however, the recall decreases.",4.2 Results,[0],[0]
"This is not that surprising, since the more ground-truth sentences in evidence, the harder it is to retrieve all of them; (ii) Due to the decrease in recall, the SCOREEV also gets influenced for bigger #sentence.",4.2 Results,[0],[0]
"Interestingly, high precision and worse recall in evidence with more sentences still make consistently strong overall performance, i.e., NOSCOREEV.",4.2 Results,[0],[0]
"This should be due to the fact that the majority (83.18% (Thorne et al., 2018)) of claims can be correctly entailed by a single ground truth sentence, even if any remaining ground truth sentences are unavailable.
",4.2 Results,[0],[0]
Error analysis.,4.2 Results,[0],[0]
"The case #1 in Table 4 shows that our system identifies two pieces of evidence
(i.e., (Telemundo, 0) and (Telemundo, 4)) correctly; however, it falsely predicts the claim label.",4.2 Results,[0],[0]
"(Telemundo, 0): Telemundo is an American Spanish-language terrestrial television · · · .",4.2 Results,[0],[0]
We can easily find that the keyword “Spanishlanguage” should refute the claim.,4.2 Results,[0],[0]
"However, both “Spanish-language” in this evidence and the “English-language” in the claim are unknown tokens with randomly initialized embeddings.",4.2 Results,[0],[0]
This hints that a more careful data preprocessing may be helpful.,4.2 Results,[0],[0]
"In addition, to refute the claim, another clue comes from the combination of (Telemundo, 4) and (Hispanic and Latino Americans, 0).",4.2 Results,[0],[0]
"(Telemundo, 4): “The channel · · · aimed at Hispanic and Latino American audiences”; (Hispanic and Latino Americans, 0): “Hispanic Americans and Latino Americans · · · are descendants of people from countries of Latin America and Spain.”.",4.2 Results,[0],[0]
"Our system only retrieved (Telemundo, 4).",4.2 Results,[0],[0]
"And this clue is hard to grasp as it requires some background knowledge – people from Latin America and Spain usually are not treated as English-speaking.
",4.2 Results,[0],[0]
"In the case #2, our system fails to identify any evidence.",4.2 Results,[0],[0]
"This is due to the failure of our passage retrieval module: it detects entity mentions “Home”, “Holidays” and “American”, and the top-5 retrieved passages are “Home”, “Home for the Holidays”, “American Home”, “American” and “Home for the Holidays (song)”, which unfortunately cover none of the four ground truth passages.",4.2 Results,[0],[0]
"Interestingly, (i) given the falsely retrieved passages, our system predicts “no sentence is valid evidence” (denoted as ∅ in Table 4); (ii) given the empty evidence, our system predicts “NoEnoughInfo” for this claim.",4.2 Results,[0],[0]
"Both make sense.
",4.2 Results,[0],[0]
"In the case #3, a successful classification of the
claim requires information aggregation over the three gold evidence sentences: (Weekly Idol, 0): “Weekly Idol is a South Korean variety show · · · ”; (Weekly Idol, 1): “The show is hosted by comedian Jeong Hyeong-don and rapper Defconn.”; (Defconn, 0): “Defconn (born Yoo Dae-joon; January 6 , 1977 ) is a · · · ”.",4.2 Results,[0],[0]
To successfully retrieve the three sentences as a whole set of evidence is challenging in evidence identification.,4.2 Results,[0],[0]
"Additionally, this example relies on the recognition and matching of digital numbers (1983 vs. 1977), which is beyond the expressivity of word embeddings, and is expected to be handled by rules more easily.",4.2 Results,[0],[0]
"In this work, we build TWOWINGOS, a two-wing optimization framework to address the claim verification problem by presenting precise evidence.",5 Summary,[0],[0]
"Differing from a pipeline system, TWOWINGOS ensures the evidence identification module and the claim verification module are trained jointly, in an end-to-end scheme.",5 Summary,[0],[0]
Experiments show the superiority of TWOWINGOS in the FEVER benchmark.,5 Summary,[0],[0]
We thank group colleagues (Nitish Gupta and Jennifer Sheffield) and Dr. Mo Yu from IBM AI Foundations Lab for providing insightful comments and critiques.,Acknowledgments,[0],[0]
This work was supported by Contract HR0011-15-2-0025 with the US Defense Advanced Research Projects Agency (DARPA).,Acknowledgments,[0],[0]
"Approved for Public Release, Distribution Unlimited.",Acknowledgments,[0],[0]
The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government.,Acknowledgments,[0],[0]
Determining whether a given claim is supported by evidence is a fundamental NLP problem that is best modeled as Textual Entailment.,abstractText,[0],[0]
"However, given a large collection of text, finding evidence that could support or refute a given claim is a challenge in itself, amplified by the fact that different evidence might be needed to support or refute a claim.",abstractText,[0],[0]
"Nevertheless, most prior work decouples evidence identification from determining the truth value of the claim given the evidence.",abstractText,[0],[0]
We propose to consider these two aspects jointly.,abstractText,[0],[0]
"We develop TWOWINGOS (twowing optimization strategy), a system that, while identifying appropriate evidence for a claim, also determines whether or not the claim is supported by the evidence.",abstractText,[0],[0]
"Given the claim, TWOWINGOS attempts to identify a subset of the evidence candidates; given the predicted evidence, it then attempts to determine the truth value of the corresponding claim.",abstractText,[0],[0]
"We treat this challenge as coupled optimization problems, training a joint model for it.",abstractText,[0],[0]
"TWOWINGOS offers two advantages: (i) Unlike pipeline systems, it facilitates flexible-size evidence set, and (ii) Joint training improves both the claim verification and the evidence identification.",abstractText,[0],[0]
Experiments on a benchmark dataset show state-of-the-art performance.1,abstractText,[0],[0]
TWOWINGOS: A Two-Wing Optimization Strategy for Evidential Claim Verification,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 87–96 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
87",text,[0],[0]
Entities can often be described by very fine grained types.,1 Introduction,[0],[0]
Consider the sentences “Bill robbed John.,1 Introduction,[0],[0]
He was arrested.”,1 Introduction,[0],[0]
"The noun phrases “John,” “Bill,” and “he” have very specific types that can be inferred from the text.",1 Introduction,[0],[0]
"This includes the facts that “Bill” and “he” are both likely “criminal” due to the “robbing” and “arresting,” while “John” is more likely a “victim” because he was “robbed.”",1 Introduction,[0],[0]
"Such fine-grained types (victim, criminal) are important for context-sensitive tasks such
1Our data and model can be downloaded from: http://nlp.cs.washington.edu/entity_type
as coreference resolution and question answering (e.g. “Who was the victim?”).",1 Introduction,[0],[0]
"Inferring such types for each mention (John, he) is not possible given current typing models that only predict relatively coarse types and only consider named entities.
",1 Introduction,[0],[0]
"To address this challenge, we present a new task: given a sentence with a target entity mention, predict free-form noun phrases that describe appropriate types for the role the target entity plays in the sentence.",1 Introduction,[0],[0]
Table 1 shows three examples that exhibit a rich variety of types at different granularities.,1 Introduction,[0],[0]
"Our task effectively subsumes existing finegrained named entity typing formulations due to the use of a very large type vocabulary and the fact that we predict types for all noun phrases, including named entities, nominals, and pronouns.
",1 Introduction,[0],[0]
"Incorporating fine-grained entity types has improved entity-focused downstream tasks, such as relation extraction (Yaghoobzadeh et al., 2017a), question answering (Yavuz et al., 2016),",1 Introduction,[0],[0]
"query analysis (Balog and Neumayer, 2012), and coreference resolution (Durrett and Klein, 2014).",1 Introduction,[0],[0]
These systems used a relatively coarse type ontology.,1 Introduction,[0],[0]
"However, manually designing the ontology is a challenging task, and it is difficult to cover all pos-
12/14/2017 https://homes.cs.washington.edu/~eunsol/finetype_visualization/onto_index.html
https://homes.cs.washington.edu/~eunsol/finetype_visualization/onto_index.html 1/1
sible concepts even within a limited domain.",1 Introduction,[0],[0]
"This can be seen empirically in existing datasets, where the label distribution of fine-grained entity typing datasets is heavily skewed toward coarse-grained types.",1 Introduction,[0],[0]
"For instance, annotators of the OntoNotes dataset (Gillick et al., 2014) marked about half of the mentions as “other,” because they could not find a suitable type in their ontology (see Figure 1 for a visualization and Section 2.2 for details).
",1 Introduction,[0],[0]
"Our more open, ultra-fine vocabulary, where types are free-form noun phrases, alleviates the need for hand-crafted ontologies, thereby greatly increasing overall type coverage.",1 Introduction,[0],[0]
"To better understand entity types in an unrestricted setting, we crowdsource a new dataset of 6,000 examples.",1 Introduction,[0],[0]
"Compared to previous fine-grained entity typing datasets, the label distribution in our data is substantially more diverse and fine-grained.",1 Introduction,[0],[0]
Annotators easily generate a wide range of types and can determine with 85% agreement if a type generated by another annotator is appropriate.,1 Introduction,[0],[0]
"Our evaluation data has over 2,500 unique types, posing a challenging learning problem.
",1 Introduction,[0],[0]
"While our types are harder to predict, they also allow for a new form of contextual distant supervision.",1 Introduction,[0],[0]
"We observe that text often contains cues that explicitly match a mention to its type, in the form of the mention’s head word.",1 Introduction,[0],[0]
"For example, “the incumbent chairman of the African Union” is a type of “chairman.”",1 Introduction,[0],[0]
"This signal complements the supervision derived from linking entities to knowledge bases, which is context-oblivious.",1 Introduction,[0],[0]
"For example, “Clint Eastwood” can be described
with dozens of types, but context-sensitive typing would prefer “director” instead of “mayor” for the sentence “Clint Eastwood won ‘Best Director’ for Million Dollar Baby.”
",1 Introduction,[0],[0]
"We combine head-word supervision, which provides ultra-fine type labels, with traditional signals from entity linking.",1 Introduction,[0],[0]
"Although the problem is more challenging at finer granularity, we find that mixing fine and coarse-grained supervision helps significantly, and that our proposed model with a multitask objective exceeds the performance of existing entity typing models.",1 Introduction,[0],[0]
"Lastly, we show that head-word supervision can be used for previous formulations of entity typing, setting the new state-of-the-art performance on an existing finegrained NER benchmark.",1 Introduction,[0],[0]
"Given a sentence and an entity mention e within it, the task is to predict a set of natural-language phrases T that describe the type of e. The selection of T is context sensitive; for example, in “Bill Gates has donated billions to eradicate malaria,” Bill Gates should be typed as “philanthropist” and not “inventor.”",2 Task and Data,[0],[0]
"This distinction is important for context-sensitive tasks such as coreference resolution and question answering (e.g. “Which philanthropist is trying to prevent malaria?”).
",2 Task and Data,[0],[0]
"We annotate a dataset of about 6,000 mentions via crowdsourcing (Section 2.1), and demonstrate that using an large type vocabulary substantially increases annotation coverage and diversity over existing approaches (Section 2.2).",2 Task and Data,[0],[0]
"To capture multiple domains, we sample sentences from Gigaword (Parker et al., 2011), OntoNotes (Hovy et al., 2006), and web articles (Singh et al., 2012).",2.1 Crowdsourcing Entity Types,[0],[0]
"We select entity mentions by taking maximal noun phrases from a constituency parser (Manning et al., 2014) and mentions from a coreference resolution system (Lee et al., 2017).
",2.1 Crowdsourcing Entity Types,[0],[0]
"We provide the sentence and the target entity mention to five crowd workers on Mechanical Turk, and ask them to annotate the entity’s type.",2.1 Crowdsourcing Entity Types,[0],[0]
"To encourage annotators to generate fine-grained types, we require at least one general type (e.g. person, organization, location) and two specific types (e.g. doctor, fish, religious institute), from a type vocabulary of about 10K frequent noun phrases.",2.1 Crowdsourcing Entity Types,[0],[0]
"We use WordNet (Miller, 1995) to expand these types automatically by generating all their synonyms and hypernyms based on the most common sense, and ask five different annotators to validate the generated types.",2.1 Crowdsourcing Entity Types,[0],[0]
Each pair of annotators agreed on 85% of the binary validation decisions (i.e. whether a type is suitable or not) and 0.47 in Fleiss’s κ.,2.1 Crowdsourcing Entity Types,[0],[0]
"To further improve consistency, the final type set contained only types selected by at least 3/5 annotators.",2.1 Crowdsourcing Entity Types,[0],[0]
"Further crowdsourcing details are available in the supplementary material.
",2.1 Crowdsourcing Entity Types,[0],[0]
Our collection process focuses on precision.,2.1 Crowdsourcing Entity Types,[0],[0]
"Thus, the final set is diverse but not comprehensive, making evaluation non-trivial (see Section 5).",2.1 Crowdsourcing Entity Types,[0],[0]
"We collected about 6,000 examples.",2.2 Data Analysis,[0],[0]
"For analysis, we classified each type into three disjoint bins: • 9 general types: person, location, object, orga-
nization, place, entity, object, time, event • 121 fine-grained types, mapped to fine-grained
entity labels from prior work (Ling and Weld, 2012; Gillick et al., 2014) (e.g. film, athlete) • 10,201 ultra-fine types, encompassing every
other label in the type space (e.g. detective, lawsuit, temple, weapon, composer)
",2.2 Data Analysis,[0],[0]
"On average, each example has 5 labels: 0.9 general, 0.6 fine-grained, and 3.9 ultra-fine types.",2.2 Data Analysis,[0],[0]
"Among the 10,000 ultra-fine types, 2,300 unique types were actually found in the 6,000 crowdsourced examples.",2.2 Data Analysis,[0],[0]
"Nevertheless, our distant supervision data (Section 3) provides positive training examples for every type in the entire vocabulary, and our model (Section 4) can and does predict from a 10K type vocabulary.",2.2 Data Analysis,[0],[0]
"For example,
the model correctly predicts “television network” and “archipelago” for some mentions, even though that type never appears in the 6,000 crowdsourced examples.
",2.2 Data Analysis,[0],[0]
Improving Type Coverage,2.2 Data Analysis,[0],[0]
We observe that prior fine-grained entity typing datasets are heavily focused on coarse-grained types.,2.2 Data Analysis,[0],[0]
"To quantify our observation, we calculate the distribution of types in FIGER (Ling and Weld, 2012), OntoNotes (Gillick et al., 2014), and our data.",2.2 Data Analysis,[0],[0]
"For examples with multiple types (|T | > 1), we counted each type 1/|T | times.
",2.2 Data Analysis,[0],[0]
Figure 2 shows the percentage of labels covered by the top N labels in each dataset.,2.2 Data Analysis,[0],[0]
"In previous enitity typing datasets, the distribution of labels is highly skewed towards the top few labels.",2.2 Data Analysis,[0],[0]
"To cover 80% of the examples, FIGER requires only the top 7 types, while OntoNotes needs only 4; our dataset requires 429 different types.
",2.2 Data Analysis,[0],[0]
"Figure 1 takes a deeper look by visualizing the types that cover 90% of the data, demonstrating the diversity of our dataset.",2.2 Data Analysis,[0],[0]
"It is also striking that more than half of the examples in OntoNotes are classified as “other,” perhaps because of the limitation of its predefined ontology.
",2.2 Data Analysis,[0],[0]
"Improving Mention Coverage Existing datasets focus mostly on named entity mentions, with the exception of OntoNotes, which contained nominal expressions.",2.2 Data Analysis,[0],[0]
"This has implications on the transferability of FIGER/OntoNotes-based models to tasks such as coreference resolution, which need to analyze all types of entity mentions (pronouns, nominal expressions, and named entity
mentions).",2.2 Data Analysis,[0],[0]
"Our new dataset provides a wellrounded benchmark with roughly 40% pronouns, 38% nominal expressions, and 22% named entity mentions.",2.2 Data Analysis,[0],[0]
"The case of pronouns is particularly interesting, since the mention itself provides little information.",2.2 Data Analysis,[0],[0]
Training data for fine-grained NER systems is typically obtained by linking entity mentions and drawing their types from knowledge bases (KBs).,3 Distant Supervision,[0],[0]
"This approach has two limitations: recall can suffer due to KB incompleteness (West et al., 2014), and precision can suffer when the selected types do not fit the context (Ritter et al., 2011).",3 Distant Supervision,[0],[0]
"We alleviate the recall problem by mining entity mentions that were linked to Wikipedia in HTML, and extract relevant types from their encyclopedic definitions (Section 3.1).",3 Distant Supervision,[0],[0]
"To address the precision issue (context-insensitive labeling), we propose a new source of distant supervision: automatically extracted nominal head words from raw text (Section 3.2).",3 Distant Supervision,[0],[0]
Using head words as a form of distant supervision provides fine-grained information about named entities and nominal mentions.,3 Distant Supervision,[0],[0]
"While a KB may link “the 44th president of the United States” to many types such as author, lawyer, and professor, head words provide only the type “president”, which is relevant in the context.
",3 Distant Supervision,[0],[0]
We experiment with the new distant supervision sources as well as the traditional KB supervision.,3 Distant Supervision,[0],[0]
Table 2 shows examples and statistics for each source of supervision.,3 Distant Supervision,[0],[0]
We annotate 100 examples from each source to estimate the noise and usefulness in each signal (precision in Table 2).,3 Distant Supervision,[0],[0]
"For KB supervision, we leveraged training data from prior work (Ling and Weld, 2012; Gillick et al., 2014) by manually mapping their ontology to our 10,000 noun type vocabulary, which covers 130 of our labels (general and fine-grained).2 Section 6 defines this mapping in more detail.
",3.1 Entity Linking,[0],[0]
"To improve both entity and type coverage of KB supervision, we use definitions from Wikipedia.",3.1 Entity Linking,[0],[0]
"We follow Shnarch et al. () who observed that the first sentence of a Wikipedia article often states the entity’s type via an “is a” relation; for example, “Roger Federer is a Swiss professional tennis player.”",3.1 Entity Linking,[0],[0]
"Since we are using a large type vocabulary, we can now mine this typing information.3",3.1 Entity Linking,[0],[0]
"We extracted descriptions for 3.1M entities which contain 4,600 unique type labels such as “competition,” “movement,” and “village.”
",3.1 Entity Linking,[0],[0]
"We bypass the challenge of automatically linking entities to Wikipedia by exploiting existing hyperlinks in web pages (Singh et al., 2012), following prior work (Ling and Weld, 2012; Yosef et al., 2012).",3.1 Entity Linking,[0],[0]
"Since our heuristic extraction of types from the definition sentence is somewhat noisy, we use a more conservative entity linking policy4 that yields a signal with similar overall accuracy to KB-linked data.
2Data from: https://github.com/ shimaokasonse/NFGEC
3We extract types by applying a dependency parser (Manning et al., 2014) to the definition sentence, and taking nouns that are dependents of a copular edge or connected to nouns linked to copulars via appositive or conjunctive edges.
",3.1 Entity Linking,[0],[0]
4Only link if the mention contains the Wikipedia entity’s name and the entity’s name contains the mention’s head.,3.1 Entity Linking,[0],[0]
Many nominal entity mentions include detailed type information within the mention itself.,3.2 Contextualized Supervision,[0],[0]
"For example, when describing Titan V as “the newlyreleased graphics card”, the head words and phrases of this mention (“graphics card” and “card”) provide a somewhat noisy, but very easy to gather, context-sensitive type signal.
",3.2 Contextualized Supervision,[0],[0]
"We extract nominal head words with a dependency parser (Manning et al., 2014) from the Gigaword corpus as well as the Wikilink dataset.",3.2 Contextualized Supervision,[0],[0]
"To support multiword expressions, we included nouns that appear next to the head if they form a phrase in our type vocabulary.",3.2 Contextualized Supervision,[0],[0]
"Finally, we lowercase all words and convert plural to singular.
",3.2 Contextualized Supervision,[0],[0]
Our analysis reveals that this signal has a comparable accuracy to the types extracted from entity linking (around 80%).,3.2 Contextualized Supervision,[0],[0]
"Many errors are from the parser, and some errors stem from idioms and transparent heads (e.g. “parts of capital” labeled as “part”).",3.2 Contextualized Supervision,[0],[0]
"While the headword is given as an input to the model, with heavy regularization and multitasking with other supervision sources, this supervision helps encode the context.",3.2 Contextualized Supervision,[0],[0]
We design a model for predicting sets of types given a mention in context.,4 Model,[0],[0]
"The architecture resembles the recent neural AttentiveNER model (Shimaoka et al., 2017), while improving the sentence and mention representations, and introducing a new multitask objective to handle multiple sources of supervision.",4 Model,[0],[0]
"The hyperparameter settings are listed in the supplementary material.
",4 Model,[0],[0]
"Context Representation Given a sentence x1, . .",4 Model,[0],[0]
.,4 Model,[0],[0]
", xn, we represent each token xi using a pre-trained word embedding wi.",4 Model,[0],[0]
"We concatenate an additional location embedding li which indicates whether xi is before, inside, or after the mention.",4 Model,[0],[0]
"We then use [xi; li] as an input to a bidirectional LSTM, producing a contextualized representation hi for each token; this is different from the architecture of Shimaoka et al. 2017, who used two separate bidirectional LSTMs on each side of the mention.",4 Model,[0],[0]
"Finally, we represent the context c as a weighted sum of the contextualized token representations using MLP-based attention:
ai = SoftMaxi(va · relu(Wahi))
",4 Model,[0],[0]
"Where Wa and va are the parameters of the attention mechanism’s MLP, which allows interaction
between the forward and backward directions of the LSTM before computing the weight factors.
",4 Model,[0],[0]
"Mention Representation We represent the mention m as the concatenation of two items: (a) a character-based representation produced by a CNN on the entire mention span, and (b) a weighted sum of the pre-trained word embeddings in the mention span computed by attention, similar to the mention representation in a recent coreference resolution model (Lee et al., 2017).",4 Model,[0],[0]
The final representation is the concatenation of the context and mention representations: r =,4 Model,[0],[0]
"[c;m].
Label Prediction",4 Model,[0],[0]
We learn a type label embedding matrix Wt ∈ Rn×d where n is the number of labels in the prediction space and d is the dimension of r.,4 Model,[0],[0]
"This matrix can be seen as a combination of three sub matrices, Wgeneral,Wfine,Wultra, each of which contains the representations of the general, fine, and ultra-fine types respectively.",4 Model,[0],[0]
We predict each type’s probability via the sigmoid of its inner product with r: y = σ(Wtr).,4 Model,[0],[0]
"We predict every type t for which yt > 0.5, or argmax yt if there is no such type.
",4 Model,[0],[0]
"Multitask Objective The distant supervision sources provide partial supervision for ultra-fine types; KBs often provide more general types, while head words usually provide only ultra-fine types, without their generalizations.",4 Model,[0],[0]
"In other words, the absence of a type at a different level of abstraction does not imply a negative signal; e.g. when the head word is “inventor”, the model should not be discouraged to predict “person”.
",4 Model,[0],[0]
"Prior work used a customized hinge loss (Abhishek et al., 2017) or max margin loss (Ren et al., 2016a) to improve robustness to noisy or incomplete supervision.",4 Model,[0],[0]
We propose a multitask objective that reflects the characteristic of our training dataset.,4 Model,[0],[0]
"Instead of updating all labels for each example, we divide labels into three bins (general, fine, and ultra-fine), and update labels only in bin containing at least one positive label.",4 Model,[0],[0]
"Specifically, the training objective is to minimize J where t is the target vector at each granularity:
Jall = Jgeneral · 1general(t)",4 Model,[0],[0]
"+ Jfine · 1fine(t) + Jultra · 1ultra(t)
Where 1category(t) is an indicator function that checks if t contains a type in the category, and
Jcategory is the category-specific logistic regression objective:
J =",4 Model,[0],[0]
− ∑ i ti · log(yi) + (1− ti) · log(1− yi),4 Model,[0],[0]
"Experiment Setup The crowdsourced dataset (Section 2.1) was randomly split into train, development, and test sets, each with about 2,000 examples.",5 Evaluation,[0],[0]
We use this relatively small manuallyannotated training set (Crowd in Table 4) alongside the two distant supervision sources: entity linking (KB and Wikipedia definitions) and head words.,5 Evaluation,[0],[0]
"To combine supervision sources of different magnitudes (2K crowdsourced data, 4.7M entity linking data, and 20M head words), we sample a batch of equal size from each source at each iteration.",5 Evaluation,[0],[0]
"We reimplement the recent AttentiveNER model (Shimaoka et al., 2017) for reference.5
We report macro-averaged precision, recall, and F1, and the average mean reciprocal rank (MRR).
",5 Evaluation,[0],[0]
Results Table 3 shows the performance of our model and our reimplementation of AttentiveNER.,5 Evaluation,[0],[0]
"Our model, which uses a multitask objective to learn finer types without punishing more general types, shows recall gains at the cost of drop in precision.",5 Evaluation,[0],[0]
"The MRR score shows that our
5We use the AttentiveNER model with no engineered features or hierarchical label encoding (as a hierarchy is not clear in our label setting) and let it predict from the same label space, training with the same supervision data.
model is slightly better than the baseline at ranking correct types above incorrect ones.
",5 Evaluation,[0],[0]
Table 4 shows the performance breakdown for different type granularity and different supervision.,5 Evaluation,[0],[0]
"Overall, as seen in previous work on finegrained NER literature (Gillick et al., 2014; Ren et al., 2016a), finer labels were more challenging to predict than coarse grained labels, and this issue is exacerbated when dealing with ultra-fine types.",5 Evaluation,[0],[0]
"All sources of supervision appear to be useful, with crowdsourced examples making the biggest impact.",5 Evaluation,[0],[0]
"Head word supervision is particularly helpful for predicting ultra-fine labels, while entity linking improves fine label prediction.",5 Evaluation,[0],[0]
"The low general type performance is partially because of nominal/pronoun mentions (e.g. “it”), and because of the large type inventory (sometimes “location” and “place” are annotated interchangeably).
",5 Evaluation,[0],[0]
"Analysis We manually analyzed 50 examples from the development set, four of which we present in Table 5.",5 Evaluation,[0],[0]
"Overall, the model was able to generate accurate general types and a diverse set of type labels.",5 Evaluation,[0],[0]
"Despite our efforts to annotate a comprehensive type set, the gold labels still miss many potentially correct labels (example (a): “man” is reasonable but counted as incorrect).",5 Evaluation,[0],[0]
"This makes the precision estimates lower than the actual performance level, with about half the precision errors belonging to this category.",5 Evaluation,[0],[0]
"Real precision errors include predicting co-hyponyms (example (b): “accident” instead of “attack”), and types that
may be true, but are not supported by the context.",5 Evaluation,[0],[0]
We found that the model often abstained from predicting any fine-grained types.,5 Evaluation,[0],[0]
"Especially in challenging cases as in example (c), the model predicts only general types, explaining the low recall numbers (28% of examples belong to this category).",5 Evaluation,[0],[0]
"Even when the model generated correct fine-grained types as in example (d), the recall was often fairly low since it did not generate a complete set of related fine-grained labels.
",5 Evaluation,[0],[0]
Estimating the performance of a model in an incomplete label setting and expanding label coverage are interesting areas for future work.,5 Evaluation,[0],[0]
"Our task also poses a potential modeling challenge; sometimes, the model predicts two incongruous types (e.g. “location” and “person”), which points towards modeling the task as a joint set prediction task, rather than predicting labels individually.",5 Evaluation,[0],[0]
We provide sample outputs on the project website.,5 Evaluation,[0],[0]
We show that our model and distant supervision can improve performance on an existing finegrained NER task.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"We chose the widely-used OntoNotes (Gillick et al., 2014) dataset which includes nominal and named entity mentions.6
6While we were inspired by FIGER (Ling and Weld, 2012), the dataset presents technical difficulties.",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"The test set has only 600 examples, and the development set was labeled with distant supervision, not manual annotation.",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"We therefore focus our evaluation on OntoNotes.
",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
Augmenting the Training Data,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
The original OntoNotes training set (ONTO in Tables 6 and 7) is extracted by linking entities to a KB.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
We supplement this dataset with our two new sources of distant supervision: Wikipedia definition sentences (WIKI) and head word supervision (HEAD) (see Section 3).,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"To convert the label space, we manually map a single noun from our natural-language vocabulary to each formal-language type in the OntoNotes ontology.",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"77% of OntoNote’s types directly correspond to suitable noun labels (e.g. “doctor” to “/person/doctor”), whereas the other cases were mapped with minimal manual effort (e.g. “musician” to “person/artist/music”, “politician” to “/person/political figure”).",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
We then expand these labels according to the ontology to include their hypernyms (“/person/political figure” will also generate “/person”).,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Lastly, we create negative examples by assigning the “/other” label to examples that are not mapped to the ontology.",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"The augmented dataset contains 2.5M/0.6M new positive/negative examples, of which 0.9M/0.1M are from Wikipedia definition sentences and 1.6M/0.5M from head words.
",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Experiment Setup We compare performance to other published results and to our reimplementation of AttentiveNER (Shimaoka et al., 2017).",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
We also compare models trained with different sources of supervision.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"For this dataset, we did not use our multitask objective (Section 4), since expanding types to include their ontological hypernyms largely eliminates the partial supervision as-
sumption.",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Following prior work, we report macroand micro-averaged F1 score, as well as accuracy (exact set match).
",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
Results Table 6 shows the overall performance on the test set.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Our combination of model and training data shows a clear improvement from prior work, setting a new state-of-the art result.7
In Table 7, we show an ablation study.",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
Our new supervision sources improve the performance of both the AttentiveNER model and our own.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
We observe that every supervision source improves performance in its own right.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Particularly, the naturally-occurring head-word supervision seems to be the prime source of improvement, increasing performance by about 10% across all metrics.
",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Predicting Miscellaneous Types While analyzing the data, we observed that over half of the mentions in OntoNotes’ development set were annotated only with the miscellaneous type (“/other”).",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"For both models in our evaluation, detecting the miscellaneous category is substantially easier than
7We did not compare to a system from (Yogatama et al., 2015), which reports slightly higher test number (72.98 micro F1) as they used a different, unreleased test set.
",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
producing real types (94% F1 vs. 58% F1 with our best model).,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
We provide further details of this analysis in the supplementary material.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Fine-grained NER has received growing attention, and is used in many applications (Gupta et al., 2017; Ren et al., 2017; Yaghoobzadeh et al., 2017b; Raiman and Raiman, 2018).",7 Related Work,[0],[0]
"Researchers studied typing in varied contexts, including mentions in specific sentences (as we consider) (Ling and Weld, 2012; Gillick et al., 2014; Yogatama et al., 2015; Dong et al., 2015; Schutze et al., 2017), corpus-level prediction (Yaghoobzadeh and Schütze, 2016), and lexicon level (given only a noun phrase with no context) (Yao et al., 2013).
",7 Related Work,[0],[0]
"Recent work introduced fine-grained type ontologies (Rabinovich and Klein, 2017; Murty et al., 2017; Corro et al., 2015), defined using Wikipedia categories (100), Freebase types (1K) and WordNet senses (16K).",7 Related Work,[0],[0]
"However, they focus on named entities, and data has been challenging to gather, often approximating gold annotations with distant supervision.",7 Related Work,[0],[0]
"In contrast, (1) our ontology contains any frequent noun phrases that depicts a type, (2) our task goes beyond named entities, covering every noun phrase (even pronouns), and (3) we provide crowdsourced annotations which provide context-sensitive, fine grained type labels.
",7 Related Work,[0],[0]
"Contextualized fine-grained entity typing is related to selectional preference (Resnik, 1996; Pantel et al., 2007; Zapirain et al., 2013; de Cruys, 2014), where the goal is to induce semantic generalizations on the type of arguments a predicate prefers.",7 Related Work,[0],[0]
"Rather than focusing on predicates, we condition on the entire sentence to deduce the arguments’ types, which allows us to capture more nuanced types.",7 Related Work,[0],[0]
"For example, not every type that fits “He played the violin in his room” is also suitable for “He played the violin in the Carnegie Hall”.",7 Related Work,[0],[0]
"Entity typing here can be connected to argument finding in semantic role labeling.
",7 Related Work,[0],[0]
"To deal with noisy distant supervision for KB population and entity typing, researchers used multi-instance multi-label learning (Surdeanu et al., 2012; Yaghoobzadeh et al., 2017b) or custom losses (Abhishek et al., 2017; Ren et al., 2016a).",7 Related Work,[0],[0]
Our multitask objective handles noisy supervision by pooling different distant supervision sources across different levels of granularity.,7 Related Work,[0],[0]
Using virtually unrestricted types allows us to expand the standard KB-based training methodology with typing information from Wikipedia definitions and naturally-occurring head-word supervision.,8 Conclusion,[0],[0]
These new forms of distant supervision boost performance on our new dataset as well as on an existing fine-grained entity typing benchmark.,8 Conclusion,[0],[0]
"These results set the first performance levels for our evaluation dataset, and suggest that the data will support significant future work.",8 Conclusion,[0],[0]
The research was supported in part the ARO (W911NF-16-1-0121),Acknowledgement,[0],[0]
"the NSF (IIS-1252835, IIS1562364), and an Allen Distinguished Investigator Award.",Acknowledgement,[0],[0]
We would like to thank the reviewers for constructive feedback.,Acknowledgement,[0],[0]
Also thanks to Yotam Eshel and Noam Cohen for providing the Wikilink dataset.,Acknowledgement,[0],[0]
Special thanks to the members of UW NLP for helpful discussions and feedback.,Acknowledgement,[0],[0]
"We introduce a new entity typing task: given a sentence with an entity mention, the goal is to predict a set of free-form phrases (e.g. skyscraper, songwriter, or criminal) that describe appropriate types for the target entity.",abstractText,[0],[0]
"This formulation allows us to use a new type of distant supervision at large scale: head words, which indicate the type of the noun phrases they appear in.",abstractText,[0],[0]
"We show that these ultra-fine types can be crowd-sourced, and introduce new evaluation sets that are much more diverse and fine-grained than existing benchmarks.",abstractText,[0],[0]
"We present a model that can predict open types, and is trained using a multitask objective that pools our new head-word supervision with prior supervision from entity linking.",abstractText,[0],[0]
"Experimental results demonstrate that our model is effective in predicting entity types at varying granularity; it achieves state of the art performance on an existing fine-grained entity typing benchmark, and sets baselines for our newly-introduced datasets.1",abstractText,[0],[0]
Ultra-Fine Entity Typing,title,[0],[0]
Data-driven decision-making has become the subject of increased interest and been used in a number of practical applications.,1. Introduction,[0],[0]
One of the most promising approaches is mathematical programming based on predictive models generated by machine learning.,1. Introduction,[0],[0]
"Recent advances in machine learning have made it easier to create accurate predictive models, and resulting predictions have been used to build mathematical programming problems (we refer to such approaches as predictive optimization).",1. Introduction,[0],[0]
"Predictive optimization is employed in applications for which frequent trial-and-error process are not practical, such as water distribution optimization (Draper et al., 2003), energy generation planning (Baos et al., 2011), retail price optimization (Johnson
1NEC Corporation.",1. Introduction,[0],[0]
"Correspondence to: Shinji Ito <sito@me.jp.nec.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"et al., 2016; Ito & Fujimaki, 2016), supply chain management (Thomas et al., 1996; Jung et al., 2004; Bertsimas & Thiele, 2004), and portfolio optimization (Markowitz, 1952; Chan et al., 1999; Konno & Yamazaki, 1991).",1. Introduction,[0],[0]
"Another important use for data-driven decision-making is in reinforcement learning (Kaelbling et al., 1996; Sutton & Barto, 2013).",1. Introduction,[0],[0]
"Here it is employed in situations mainly in which frequent trial-and-error operations are possible, except for batch reinforcement learning (Lange et al., 2012).",1. Introduction,[0],[0]
"The focus of this paper is on the first approach, i.e., predictive optimization.
",1. Introduction,[0],[0]
"In many practical applications of predictive optimization, it is essential to estimate the quality of the computed strategy because executing a strategy is often costly and risky.",1. Introduction,[0],[0]
"For example, predictive price optimization has been used to estimate revenue functions through regressions of demand as functions of product prices, and then, to optimize pricing strategies by maximizing estimated revenue functions (Johnson et al., 2016; Ito & Fujimaki, 2016; 2017; Yabe et al., 2017).",1. Introduction,[0],[0]
"In practice, users need to assess the return for the computed “optimal” strategy before changing prices, in order to prevent unforeseen heavy losses.",1. Introduction,[0],[0]
"In a situation in which costs for trial-and-error processes are unrealistically high, a key challenge in predictive optimization is how to assess the quality (or expected return) of the “optimal” solution by means of an estimated objective function.
",1. Introduction,[0],[0]
Predictive optimization consists of two steps: estimation and optimization.,1. Introduction,[0],[0]
"In the estimation step, we construct an estimated objective function f(z, θ̂) for the true objective function f(z, θ∗), where θ is a parameter of f , and z is a decision variable corresponding to the strategy to be optimized.",1. Introduction,[0],[0]
"In the optimization step, we compute the estimated optimal strategy ẑ = arg maxz∈Z f(z, θ̂), where Z is the domain of z. Because it would be expensive to observe f(ẑ, θ∗) (i.e., to perform ẑ in a real environment), we usually estimate it by f(ẑ, θ̂), which we call simple evaluation, in order to assess the quality of ẑ.
It has been empirically seen, however, that this simple evaluation tends to be too optimistic.",1. Introduction,[0],[0]
"For example, in the contexts of algorithmic investment and portfolio optimization, it has been reported (Michaud, 1989; Chapados, 2011; Harvey & Liu, 2015) that f(ẑ, θ̂) is much better than the acutual return.",1. Introduction,[0],[0]
"Michaud (Michaud, 1989) argued that this bias ap-
pears because the mean-variance optimizers act as “error maximizers”, i.e., optimizers tend to choose solutions containing large errors.",1. Introduction,[0],[0]
"According to (Harvey & Liu, 2015), a common practice in evaluating trading strategies is simple heuristics that discount the estimated objective to 50%, i.e., consider 0.5f(ẑ, θ̂) to be an estimator of f(ẑ, θ∗).",1. Introduction,[0],[0]
"Heuristics referred to as portfolio resampling techniques (Michaud, 1998; Scherer, 2002) have been studied for nearly 20 years but have not yet to be theoretically justified.",1. Introduction,[0],[0]
"A few recent studies (Bailey & Marcos, 2016; Bailey et al., 2014; Harvey & Liu, 2015) have statistically analyzed and proposed algorithms to mitigate the bias issue, but their algorithms are restricted to particular applications (e.g., algorithmic investment) and, as far as we know, there exists no principled algorithm for an unbiased estimator of f(z, θ∗) in general predictive optimization problems.
",1. Introduction,[0],[0]
"The goal of this study is to address this optimistic bias issue, and to propose methods for unbiased estimation of true objective values.",1. Introduction,[0],[0]
"Our key contributions are summarized as follows.
",1. Introduction,[0],[0]
"First, we prove that the estimated optimal value f(ẑ, θ̂) is biased even if the estimated objective function f(z, θ̂) is an unbiased estimator of the true objective function f(z, θ∗).",1. Introduction,[0],[0]
"Further, we correlate the bias issue to overfitting in machine learning, which yields a valuable insight into bias correction methods.
",1. Introduction,[0],[0]
"Second, we propose two algorithms for estimating the value of true objective functions under mild assumptions.",1. Introduction,[0],[0]
The first algorithm is based on a procedure similar to crossvalidation and has been inspired by the analogy between our problem and overfitting in supervised learning.,1. Introduction,[0],[0]
"This algorithm corrects the optimistic bias, but suffers from pessimistic bias, i.e., the estimated value is biased in a direction suggesting a poorer result, similar to that which occurs in cross-validation.",1. Introduction,[0],[0]
"The magnitude of this pessimistic bias tends to be larger than that of cross-validation, and hence, it is not negligible in many cases.",1. Introduction,[0],[0]
"To mitigate this issue, we propose another algorithm, which we refer to as a parameter perturbation method.",1. Introduction,[0],[0]
"This algorithm employs a resampling technique and is theoretically proven here to achieve asymptotically unbiased estimation.
",1. Introduction,[0],[0]
"Our experimental results show that the proposed algorithms are able to estimate the value of a true objective function more accurately than a state-of-the-art hold-out validation technique commonly used in algorithmic investment (Bailey & Marcos, 2016; Bailey et al., 2014).",1. Introduction,[0],[0]
"In a simulation experiment with real-world retail datasets for price optimization, we have observed that our evaluation algorithms estimate a 17% increase in the gross profit, which seems to be more realistic and convincing than the value estimated without bias correction.
",1. Introduction,[0],[0]
The remainder of this paper is structured as follows.,1. Introduction,[0],[0]
"In Section 2, we introduce the framework of the combination of machine learning and mathematical optimization in examples of usage.",1. Introduction,[0],[0]
We also show that such a framework suffers from bias w.r.t.,1. Introduction,[0],[0]
optimal values.,1. Introduction,[0],[0]
Section 4 gives solutions to this problem and theoretical guarantees for them.,1. Introduction,[0],[0]
"In Section 5, the empirical performance of our algorithms is demonstrated.",1. Introduction,[0],[0]
"Suppose we have a sequence of training data x = (x1, . . .",2. Predictive Optimization,[0],[0]
", xN ) ∈ XN , where N is the number of data instances.",2. Predictive Optimization,[0],[0]
Each xn is generated from a probabilistic model {p(x|θ) : θ ∈ Θ} parameterized by θ ∈ Θ.,2. Predictive Optimization,[0],[0]
"We further suppose having a set of objective functions {f(z, θ) : θ ∈ Θ} where z ∈ Z is a decision variable that corresponds to strategies to be optimized.",2. Predictive Optimization,[0],[0]
"The goal of predictive optimization is to find z∗ ∈ arg maxz∈Z f(z, θ∗), where θ∗ is the true parameter.",2. Predictive Optimization,[0],[0]
"However, such a true parameter is unknown in practice, and therefore we estimate θ∗ by θ̂ from x, and compute the estimated optimal solution ẑ ∈ arg maxz∈Z f(z, θ̂) rather than z∗.",2. Predictive Optimization,[0],[0]
"This section discusses three examples of predictive optimization problems in order to provide a better picture of the process.
",2. Predictive Optimization,[0],[0]
Example 1 (Coin-Tossing).,2. Predictive Optimization,[0],[0]
"Suppose that we have a coin coming up heads with probability θ∗ and tails with probability 1− θ∗, where",2. Predictive Optimization,[0],[0]
"θ∗ ∈ Θ := [0, 1].",2. Predictive Optimization,[0],[0]
Consider predicting heads or tails for this coin.,2. Predictive Optimization,[0],[0]
"If we predict the subsequent face correctly, we win $1, and, otherwise, nothing.",2. Predictive Optimization,[0],[0]
"Predicting heads, then, will result in earning $1 with probability θ∗ and $0 with probability 1 − θ∗, and hence, the expectation value of the earnings for predicting heads is f(‘head’, θ∗) = 1 · θ∗+ 0 · (1− θ∗) = θ∗.",2. Predictive Optimization,[0],[0]
"Similarly, the expected earnings for predicting tails is f(‘tail’, θ∗) = 1− θ∗.",2. Predictive Optimization,[0],[0]
"If we knew the true parameter θ∗, we could maximize the expected earnings by choosing z∗ ∈ arg maxz∈Z f(z, θ∗), where Z = {‘head’, ‘tail’} stands for a set of feasible strategies.",2. Predictive Optimization,[0],[0]
"Since we do not know the true parameter θ∗, however, we use, rather, past data x ∈",2. Predictive Optimization,[0],[0]
"XN := {‘head’, ‘tail’}N of N tossings, for estimating θ∗.
Table 1 illustrates how the optimistic bias occurs in predictive optimization.",2. Predictive Optimization,[0],[0]
Suppose θ∗ = 1/2 (a) and that there are four cases of the observed pattern for three tossings (b).,2. Predictive Optimization,[0],[0]
"The estimators of θ∗ might then be obtained as (c), using maximum likelihood estimation.",2. Predictive Optimization,[0],[0]
"On the basis of θ̂, the “best” strategies are estimated as (d), and the estimated and true optimal values are summarized in (e) and (f).",2. Predictive Optimization,[0],[0]
"It is worth noting that the expectation of (e) over four cases (bottom middle), which is 3/4, is larger than the true expectation (bottom right), which is 1/2 even if the θ̂ is unbiased, i.e., the expectation of θ̂ matches θ∗ (bottom left).
",2. Predictive Optimization,[0],[0]
"Example 2 (Portfolio optimization (Markowitz, 1952)).
",2. Predictive Optimization,[0],[0]
"Suppose that there are d assets, and let Rj stand for the return on each component asset for j ∈ {1, . . .",2. Predictive Optimization,[0],[0]
", d}.",2. Predictive Optimization,[0],[0]
"Let µ∗ = (µ∗1, . . .",2. Predictive Optimization,[0],[0]
", µ ∗ d)",2. Predictive Optimization,[0],[0]
"> ∈ Rd be the expected return for each asset, i.e., µ∗j = E[Rj ].",2. Predictive Optimization,[0],[0]
"Then the portfolio expressed as Rz = ∑d j=1 zjRj , where zj ≥ 0 is the weighting of the j-th component asset and z = (z1, . . .",2. Predictive Optimization,[0],[0]
", zd)> ∈ Rd≥0, has expected return E[Rz] = ∑d j=1 zjµ ∗",2. Predictive Optimization,[0],[0]
"j = µ
∗>z.",2. Predictive Optimization,[0],[0]
"Variance in the portfolio return can be expressed as var[Rz] = z>Σ∗z, where Σ∗ is the covariance matrix of (R1, . . .",2. Predictive Optimization,[0],[0]
", Rd).",2. Predictive Optimization,[0],[0]
"Denote θ∗ = (µ∗,Σ∗).",2. Predictive Optimization,[0],[0]
"Then, with a given risk tolerance λ ≥ 0, the optimal portfolio is obtained as the solution of the following problem:
Maximize f(z, θ∗) := µ∗>z",2. Predictive Optimization,[0],[0]
"− λz>Σ∗z, (1) subject to d∑ j=1",2. Predictive Optimization,[0],[0]
"zj = 1, zj ≥ 0",2. Predictive Optimization,[0],[0]
"(j = 1, . . .",2. Predictive Optimization,[0],[0]
", d).
",2. Predictive Optimization,[0],[0]
"In practice, however, since θ∗ is never available, we estimate it from historical data x = (x1, . . .",2. Predictive Optimization,[0],[0]
", xN ), where xn ∈ Rd is an observation of past returns for individual component assets (Qiu et al., 2015; Agarwal et al., 2006; Li & Hoi, 2012).",2. Predictive Optimization,[0],[0]
"Under the assumption that xn follow the same distribution,1 the estimators of µ∗ and Σ∗ are obtained by µ̂ = 1N ∑N n=1 xn and Σ̂ = 1 N−1 ∑N n=1(xn− µ̂)(xn− µ̂)>.",2. Predictive Optimization,[0],[0]
"We obtain the optimal solution by solving (1) with the replacement of µ∗ and Σ∗ by µ̂ and Σ̂, respectively.
",2. Predictive Optimization,[0],[0]
"Example 3 (Predictive price optimization(Ito & Fujimaki, 2017; 2016)).",2. Predictive Optimization,[0],[0]
"Suppose we have d products whose prices are denoted by z = (z1, . . .",2. Predictive Optimization,[0],[0]
", zd).",2. Predictive Optimization,[0],[0]
Let us denote their sales quantities by q∗(z) =,2. Predictive Optimization,[0],[0]
"(q∗j (z)) d j=1 ∈ Rd, which are functions of the price z.",2. Predictive Optimization,[0],[0]
"The gross revenue function is then defined by f(z, θ∗) = q∗(z)>z, and the true optimal solution is obtained by solving the following problem:
Maximize q∗(z)>z subject to z ∈ Z, (2)
where Z ⊆ Rd is a pre-defined domain of prices (e.g., list price, 3%-off, 5%-off, and so on).",2. Predictive Optimization,[0],[0]
"However, we can never know the true demand-price relationship q∗(z), and
1This condition can easily be relaxed.
",2. Predictive Optimization,[0],[0]
"the predictive price optimization approximates q∗(z) by the following regression functions:
q(z, θ) = K∑ k=1 θkψk(z) + , ∼ N(0,Σ), (3)
where {ψk : Rd → Rd}Kk=1 are fixed basis functions and {θk}Kk=1 ⊆ R are regression coefficients.",2. Predictive Optimization,[0],[0]
"We estimate θ = (θ1, . . .",2. Predictive Optimization,[0],[0]
", θK) as a standard regression problem and then solve (2) after replacing q∗(z) by q(z, θ̂), where θ̂ is the estimator of θ∗.",2. Predictive Optimization,[0],[0]
This section formally proves the existence of optimistic bias in estimated optimal values.,3.1. Existence of Optimistic Bias,[0],[0]
"In the above examples, the objective functions f(z, θ) w.r.t.",3.1. Existence of Optimistic Bias,[0],[0]
θ were affine functions and θ̂ were unbiased estimators of θ∗.,3.1. Existence of Optimistic Bias,[0],[0]
"Hence, the constructed objective function f(z, θ̂) was an unbiased estimator of the true objective function f(z, θ∗), i.e., it holds that
Ex[f(z, θ̂)]",3.1. Existence of Optimistic Bias,[0],[0]
"= Ex[f(z, θ∗)], z ∈ Z. (4)
From this equation, one might expect that Ex[f(ẑ, θ̂)] and f(ẑ, θ̂) would be reasonable estimators of Ex[f(ẑ, θ∗)] and f(ẑ, θ∗), respectively.",3.1. Existence of Optimistic Bias,[0],[0]
"However, the following proposition contradicts this intuition.
",3.1. Existence of Optimistic Bias,[0],[0]
Proposition 1 (Optimistic Bias).,3.1. Existence of Optimistic Bias,[0],[0]
Suppose (4) holds.,3.1. Existence of Optimistic Bias,[0],[0]
"For ẑ ∈ arg maxz∈Z f(z, θ̂) and z∗ ∈ arg maxz∈Z f(z, θ∗), it holds that
Ex[f(ẑ, θ̂)]",3.1. Existence of Optimistic Bias,[0],[0]
"≥ f(z∗, θ∗) ≥",3.1. Existence of Optimistic Bias,[0],[0]
"Ex[f(ẑ, θ∗)].",3.1. Existence of Optimistic Bias,[0],[0]
"(5)
",3.1. Existence of Optimistic Bias,[0],[0]
The right inequality is strict if ẑ is suboptimal w.r.t.,3.1. Existence of Optimistic Bias,[0],[0]
"the true objective function f(z, θ∗) with non-zero probability.
",3.1. Existence of Optimistic Bias,[0],[0]
Proof.,3.1. Existence of Optimistic Bias,[0],[0]
"By taking the expectation of both sides of f(ẑ, θ̂) ≥ f(z∗, θ̂), we obtain the left inequality of (5) as follows:
Ex[f(ẑ, θ̂)]",3.1. Existence of Optimistic Bias,[0],[0]
"≥ Ex[f(z∗, θ̂)]",3.1. Existence of Optimistic Bias,[0],[0]
"= f(z∗, θ∗),
where the equality comes from (4).",3.1. Existence of Optimistic Bias,[0],[0]
"Similarly, the right inequality of (5) comes from f(z∗, θ∗) ≥ f(ẑ, θ∗).",3.1. Existence of Optimistic Bias,[0],[0]
"Further, if ẑ /∈ arg maxz∈Z f(z, θ∗) holds with non-zero probability, then f(z∗, θ∗) > f(ẑ, θ∗) holds with non-zero probability and f(z∗, θ∗) ≥ f(ẑ, θ∗) always holds, which implies f(z∗, θ∗) >",3.1. Existence of Optimistic Bias,[0],[0]
"E[f(ẑ, θ∗)].
",3.1. Existence of Optimistic Bias,[0],[0]
"This proposition implies that the estimated optimal value f(ẑ, θ̂) is not an unbiased estimator of f(ẑ, θ∗) even if the estimated objective function f(z, θ̂) is an unbiased estimator of the true objective function f(z, θ∗).",3.1. Existence of Optimistic Bias,[0],[0]
"This optimistic bias
has been empirically learned in the context of portfolio optimization (Michaud, 1989).",3.1. Existence of Optimistic Bias,[0],[0]
"Recently, (Harvey & Liu, 2015; Harvey et al., 2016) have proposed bias correction methods based on statistical tests, though their methods are applicable only to cases in which the objective function is the Sharpe ratio.",3.1. Existence of Optimistic Bias,[0],[0]
"Other recent studies (Bailey & Marcos, 2016; Bailey et al., 2014) have also focused on the Sharpe ratio and proposed a hold-out validation method.",3.1. Existence of Optimistic Bias,[0],[0]
"Although their methods apply to general predictive optimization problems, they have not been proven to obtain unbiased estimators.",3.1. Existence of Optimistic Bias,[0],[0]
"Note that a similar inequality has been discovered in the context of stochastic programs,2 one that corresponds to the left inequality of (5).",3.1. Existence of Optimistic Bias,[0],[0]
"For the special case in which Z is a finite set, the same inequality as (5) has been shown in the context of decision analysis (Smith & Winkler, 2006).",3.1. Existence of Optimistic Bias,[0],[0]
"This subsection discusses the connection of the optimistic bias issue to overfitting in machine learning, which connection has led to the ideas underlying our proposed algorithms.",3.2. Connection to Empirical Risk Minimization,[0],[0]
"In supervised machine learning, we choose the prediction rule ĥ from a hypothesis space H by minimizing the empirical error, i.e., we let ĥ ∈ arg minh∈H 1 n ∑N n=1 `(h, xn), where xn is the observed data generated from a distribution D and ` is a loss function.",3.2. Connection to Empirical Risk Minimization,[0],[0]
The empirical error 1N ∑N n=1,3.2. Connection to Empirical Risk Minimization,[0],[0]
"`(h, xn) is an unbiased estimator of the generalization error `D(h) := Ex∼D[`(h, x)] for arbitrary fixed prediction rule h, i.e., it holds that Exn∼D[ 1N ∑N n=1 `(h, xn)] =",3.2. Connection to Empirical Risk Minimization,[0],[0]
"`D(h) for any fixed h. De-
spite this equation, the empirical error 1N ∑N n=1 `(ĥ, xn) for the computed parameter ĥ is smaller than the generalization error `D(ĥ) in most cases, because ĥ overfits the observed samples, as is well known (Vapnik, 2013).",3.2. Connection to Empirical Risk Minimization,[0],[0]
"The analogy between the optimistic bias in our setting and the overfitting issue in machine learning suggests the reuse of datasets for estimation of their objective functions and evaluation of objective values.
",3.2. Connection to Empirical Risk Minimization,[0],[0]
A comparison between empirical risk minimization (ERM) and our prediction-based optimization is summarized in Table 2.,3.2. Connection to Empirical Risk Minimization,[0],[0]
"As is shown in the Table, our problem concerning bias in predictive optimization has a structure similar to that of the problem of overfitting in empirical risk minimization.",3.2. Connection to Empirical Risk Minimization,[0],[0]
"Typical methods for estimating generalization error in machine learning would be cross-validation and such asymptotic bias correction as AIC (Akaike, 1973).",3.2. Connection to Empirical Risk Minimization,[0],[0]
"This paper follows the concept of cross-validation in the context of predictive optimization and, in the following section, proposes a more accurate algorithm.
2",3.2. Connection to Empirical Risk Minimization,[0],[0]
"In stochastic programs, the objective is a random function, and it has been shown in, e.g., (Mak et al., 1999), that the expectation of the minimum of the objective is a lower bound of the minimum of the expectation of the objective.",3.2. Connection to Empirical Risk Minimization,[0],[0]
"Our goal is to construct unbiased estimators for the value f(ẑ, θ∗) of the true objective function, i.e., to construct ρ : Xn → R such that Ex[ρ(x)]",4. Bias Correction Algorithms,[0],[0]
"= Ex[f(ẑ, θ∗)], where ẑ ∈ arg max
z∈Z f(z, θ̂) is the computed strategy.",4. Bias Correction Algorithms,[0],[0]
"We assume
the following conditions.
",4. Bias Correction Algorithms,[0],[0]
Assumption 2.,4. Bias Correction Algorithms,[0],[0]
"(i) f(z, θ) is affine in θ, i.e., ∃a : Z → R, ∃b : Z → R, f(z, θ) =",4. Bias Correction Algorithms,[0],[0]
"θ>a(z) + b(z).
",4. Bias Correction Algorithms,[0],[0]
"(ii) The optimal solution z(θ) ∈ arg maxz∈Z f(z, θ) is uniquely determined for almost all θ.
(iii)",4. Bias Correction Algorithms,[0],[0]
"One of the following holds: (iii.a) Z is a finite set, or (iii.b) Z is a compact subset of Rd, and z 7→ (a(z), b(z)) is a continuous injective function.
(iv) θ̂ is an unbiased estimator of θ∗, i.e., we have Ex[θ̂] = θ∗.
The assumptions (i)-(iii) are conditions on mathematical programming problems, and such typical ones as (mixedinteger) linear/quadratic/semidefinite programming problems satisfy these conditions.",4. Bias Correction Algorithms,[0],[0]
"Assumption (iv) is a condition on the machine learning algorithm for estimating the objective function in the optimization problem, and we can employ any standard unbiased estimation algorithm.",4. Bias Correction Algorithms,[0],[0]
Note that the examples in Section 3 satisfy all these assumptions.,4. Bias Correction Algorithms,[0],[0]
"We assume (i) and (iv) in Section 4.1, and assume (i)-(iv) in Section 4.2.",4. Bias Correction Algorithms,[0],[0]
"As noted in Section 3.2, our problem is closely related to the problem of estimating generalization error.",4.1. Cross-Validation Method,[0],[0]
"Inspired by the cross-validation method, one of the most popular methods for estimating generalization error in machine learning, we propose a cross-validation method for estimating the value of the true objective function in predictive optimization.",4.1. Cross-Validation Method,[0],[0]
"In the context of algorithmic investment, a similar method, referred to as the hold-out method is mentioned in (Bailey et al., 2014).",4.1. Cross-Validation Method,[0],[0]
"The method discussed below is essentially an extension of the hold-out method for general predictive optimization problems.
",4.1. Cross-Validation Method,[0],[0]
"One of the reasons that the value f(ẑ, θ̂) contains biases is that ẑ and θ̂ are dependent random variables.",4.1. Cross-Validation Method,[0],[0]
"Indeed,
Algorithm 1 k-fold cross-validation Input: data x ∈ XN , the number K ≥ 2 of partition Divide data x into K parts x1, . . . ,xK .",4.1. Cross-Validation Method,[0],[0]
"for k = 1 to K do
Compute θ̂k, θ̃k from xk,x−k respectively, where we define x−k to be all samples in x except for xk, and compute z̃k ∈ arg maxz∈Z f(z, θ̃k).
end for Output ρCV (x) := 1K ∑K k=1 f(z̃k, θ̂k).
if ẑ and θ̂ are independent, Ex[f(ẑ, θ̂)]",4.1. Cross-Validation Method,[0],[0]
"= Ex[f(ẑ, θ∗)] straightforwardly holds from assumptions (i) and (iv).",4.1. Cross-Validation Method,[0],[0]
The main idea of the cross-validation method (as with the standard cross-validation in machine learning) is to divide the data x ∈ XN into two parts x1 ∈,4.1. Cross-Validation Method,[0],[0]
"XN1 ,x2 ∈",4.1. Cross-Validation Method,[0],[0]
"XN2 , where N1 + N2 = N .",4.1. Cross-Validation Method,[0],[0]
"Note that each element in x1 and x2 follows p(x, θ∗) independently, and, hence, x1 and x2 are independent random variables.",4.1. Cross-Validation Method,[0],[0]
"Let us denote the estimators based on x1 and x2 by θ̂1 and θ̂2, respectively.",4.1. Cross-Validation Method,[0],[0]
"Also, the optimal strategy on each estimator is denoted by ẑi := arg maxz∈Z f(z, θ̂i) for i = 1, 2.",4.1. Cross-Validation Method,[0],[0]
"Then ẑ1 and θ̂2 are independent (the opposite also holds), and we have Ex[f(ẑ1, θ̂2)]",4.1. Cross-Validation Method,[0],[0]
"= Ex1 [f(ẑ1,Ex2 [θ̂2])]",4.1. Cross-Validation Method,[0],[0]
"= Ex1 [f(ẑ1, θ∗)].",4.1. Cross-Validation Method,[0],[0]
"Further, if N1 is sufficiently close to N , Ex1 [f(z̃1, θ∗)] is close to Ex[f(ẑ, θ∗)].",4.1. Cross-Validation Method,[0],[0]
"This idea can be extended to k-fold cross-validation, in which we divide data x ∈ RN into K parts x1, . . .",4.1. Cross-Validation Method,[0],[0]
",xK ∈ RN ′",4.1. Cross-Validation Method,[0],[0]
", where KN ′ = N .",4.1. Cross-Validation Method,[0],[0]
"We compute z̃k from {x1, . . .",4.1. Cross-Validation Method,[0],[0]
",xK} \ {xk}, and compute θ̂k from xk.",4.1. Cross-Validation Method,[0],[0]
"Then the value ρCV (x) := 1K ∑K k=1 f(z̃k, θ̂k) satisfies
Ex[ρCV (x)]",4.1. Cross-Validation Method,[0],[0]
"= Ex′ [f(z̃, θ∗)], (6)
where z̃ stands for the strategy computed from (K − 1)N ′ samples, under assumptions (i) and (iv).
",4.1. Cross-Validation Method,[0],[0]
"A major drawback to Algorithm 1 is that it can only estimate the objective value attained byN −N ′ samples, as is shown in (6), even though the value attained by all N samples is desired.",4.1. Cross-Validation Method,[0],[0]
"In machine learning, to mitigate this gap, a leave-one-out method (i.e., setting N ′",4.1. Cross-Validation Method,[0],[0]
= 1) can be used.,4.1. Cross-Validation Method,[0],[0]
"In predictive optimization, however, the number N ′ of holdout samples needs to be large enough to compute another estimator, θ̂k, which limits the accuracy of the estimation of f(ẑ, θ∗).",4.1. Cross-Validation Method,[0],[0]
The accuracy of Algorithm 1 is considered in Sec. 5 in an empirical evaluation.,4.1. Cross-Validation Method,[0],[0]
This subsection proposes another algorithm that addresses the drawbacks of Algorithm 1.,4.2. Parameter perturbation method,[0],[0]
Denote the error in the estimated parameter by δ := θ̂−θ∗.,4.2. Parameter perturbation method,[0],[0]
The error δ depends on the training data x and can be regarded as a random variable when x is considered to be a random variable.,4.2. Parameter perturbation method,[0],[0]
"For γ ≥ 0,
let us first define η(γ) as follows:
η(γ) = Eδ[f(z(θ∗ + γδ), θ∗)],
where z(θ) := arg maxz∈Z f(z, θ).",4.2. Parameter perturbation method,[0],[0]
"Since ẑ = z(θ̂) = z(θ∗ + δ), we have η(1)",4.2. Parameter perturbation method,[0],[0]
"= E[f(ẑ, θ∗)].",4.2. Parameter perturbation method,[0],[0]
"Hence, our goal, unbiased estimation of f(ẑ, θ∗), is equivalent to unbiased estimation of η(1).",4.2. Parameter perturbation method,[0],[0]
"Let us next define φ(γ) as follows:
φ(γ) = Eδ[f(z(θ∗ + γδ), θ∗ + γδ)].",4.2. Parameter perturbation method,[0],[0]
"(7)
Note that we have φ(1) = E[f(ẑ, θ̂)].",4.2. Parameter perturbation method,[0],[0]
"Further, φ(γ) and η(γ) satisfy φ(0) = η(0)",4.2. Parameter perturbation method,[0],[0]
"= f(z∗, θ∗) and φ(γ) ≥ f(z∗, θ∗) ≥ η(γ) for all γ ≥ 0, which can be proved in a way similar to that of the proof of Proposition 1.
",4.2. Parameter perturbation method,[0],[0]
The following proposition plays a key role in our second algorithm.,4.2. Parameter perturbation method,[0],[0]
Proposition 3.,4.2. Parameter perturbation method,[0],[0]
Suppose that assumptions (i)-(iv) hold.,4.2. Parameter perturbation method,[0],[0]
"For all γ > 0, φ(γ) is differentiable, and its derivative φ′(γ) satisfies
η(γ) = φ(γ)− γφ′(γ).",4.2. Parameter perturbation method,[0],[0]
"(8)
The proof of this proposition is summarized in the supplementary material.
",4.2. Parameter perturbation method,[0],[0]
"Let us explain this proposition using Figure 1, which is based on the simulation experiment for portfolio optimization used in Section 5 and shows how the values of φ and η behave for some γ ≥ 0.",4.2. Parameter perturbation method,[0],[0]
"The tangent to φ(γ) at γ = γ0 (the blue broken-line) has a y-intercept (the red broken-line) equal to the value of η(γ0), for all γ0 > 0.",4.2. Parameter perturbation method,[0],[0]
"From this relationship, the derivative φ′(1) of φ(γ) at γ = 1 satisfies φ′(1) = φ(1)",4.2. Parameter perturbation method,[0],[0]
"− η(1) = E[f(ẑ, θ̂)]",4.2. Parameter perturbation method,[0],[0]
"− E[f(ẑ, θ∗)], i.e., the value of φ′(1) is equal to the value of the bias in our predictive optimization problem.
",4.2. Parameter perturbation method,[0],[0]
"Our problem is now to obtain an unbiased estimator ζ of φ′(1) that will give us an unbiased estimator of f(ẑ, θ∗), i.e. ρ = f(ẑ, θ̂)− ζ.",4.2. Parameter perturbation method,[0],[0]
"From the definition of the derivative, the value of φ′(1) can be approximated by (φ(1+h)−φ(1))/h for small h. Further, from the definition of φ, the estimated optimal value f(ẑ, θ̂) is an unbiased estimator of φ(1).",4.2. Parameter perturbation method,[0],[0]
"Also, the value of φ(1 + h) = E[maxz∈Z f(z, θ∗ + (1 + h)δ)] is the expectation of the optimal value for the objective function with a parameter having an “enhanced” error.",4.2. Parameter perturbation method,[0],[0]
"If we get samples θ̂h following the distribution of θ∗ + (1 + h)δ, we can develop an estimator of φ(1 + h), and accordingly, we can estimate η(1)",4.2. Parameter perturbation method,[0],[0]
"= E[f(ẑ, θ∗)].
",4.2. Parameter perturbation method,[0],[0]
"Suppose that θ̂(1)h , . . .",4.2. Parameter perturbation method,[0],[0]
", θ̂ (s) h follows the distribution of θ ∗ + (1 + h)δ, and define
ρh := 1 + h
h max z∈Z f(z, θ̂)− 1 hs s∑ j=1 max z∈Z f(z, θ̂ (j) h ).",4.2. Parameter perturbation method,[0],[0]
"(9)
The value ρh, then, has the following property.
",4.2. Parameter perturbation method,[0],[0]
Algorithm 2,4.2. Parameter perturbation method,[0],[0]
Parameter perturbation method Input:,4.2. Parameter perturbation method,[0],[0]
"data x ∈ Xn, parameters h > 0, s ∈ {1, 2, . . .",4.2. Parameter perturbation method,[0],[0]
"} Compute θ̂ from x and set v̂0 = maxz∈Z f(z, θ̂).",4.2. Parameter perturbation method,[0],[0]
"Generate {θ̂(j)h }sj=1 by (i) for asymptotic normal estimators or (ii) for M-estimators.
",4.2. Parameter perturbation method,[0],[0]
(i) Set θ̂(j)h to be the estimator computed from N/(1 +,4.2. Parameter perturbation method,[0],[0]
"h)2 samples randomly chosen from x without replacement.
",4.2. Parameter perturbation method,[0],[0]
"(ii) Generate δ̂j by (10), and set θ̂ (j) h = θ̂ + δ̂j .
for j = 1 to s do Set v̂j = maxz∈Z f(z, θ̂ (j) h ).",4.2. Parameter perturbation method,[0],[0]
"end for Output ρh := 1+hh v̂0 − 1 hs ∑s j=1 v̂j .
",4.2. Parameter perturbation method,[0],[0]
Proposition 4.,4.2. Parameter perturbation method,[0],[0]
"Under assumptions (i)-(iv), the value ρh defined by (9) is an asymptotically unbiased estimator of f(ẑ, θ∗), i.e., it holds that limh→0 E [ρh] = E[f(ẑ, θ∗)].
",4.2. Parameter perturbation method,[0],[0]
Proof.,4.2. Parameter perturbation method,[0],[0]
"From the definition of ρh and φ(γ), we have E[ρh]",4.2. Parameter perturbation method,[0],[0]
= ρ(1),4.2. Parameter perturbation method,[0],[0]
− φ(1+h)−φ(1)h .,4.2. Parameter perturbation method,[0],[0]
"Hence, we have limh→0 E",4.2. Parameter perturbation method,[0],[0]
[ρh] = φ(1),4.2. Parameter perturbation method,[0],[0]
− φ′(1).,4.2. Parameter perturbation method,[0],[0]
"From Proposition 3, this value is equal to η(1)",4.2. Parameter perturbation method,[0],[0]
"= E[f(ẑ, θ∗)].
",4.2. Parameter perturbation method,[0],[0]
"The remaining problem is how to obtain samples θ̂h, with enhanced errors, from the distribution of θ∗+(1+h)δ.",4.2. Parameter perturbation method,[0],[0]
"If θ̂ is an asymptotically normal estimator of θ∗, its distribution can be approximated by the normal distribution N (θ∗, 1NΣ
∗), where Σ∗ is a constant matrix not dependent on N .",4.2. Parameter perturbation method,[0],[0]
"Further, when we compute an estimator θ̂h fromN/(1+h)2 data, the distribution of θ̂h can be approximated byN (θ∗, (1+h) 2 N Σ ∗).",4.2. Parameter perturbation method,[0],[0]
This is an approximation of the distribution of θ∗ + (1 + h)δ.,4.2. Parameter perturbation method,[0],[0]
"This procedure for generating θ̂h is used in (i) of Algorithm 2.
",4.2. Parameter perturbation method,[0],[0]
"If θ̂ is an M-estimator, an asymptotically normal estimator commonly used in machine learning, we can eliminate repetitive computation in (i) of Algorithm 2.",4.2. Parameter perturbation method,[0],[0]
"For M-estimators,
Σ̂ is given in a closed form, as described in (van der Vaart, 1998), such that N (0, 1N Σ̂) approximates the error distribution of the estimator.",4.2. Parameter perturbation method,[0],[0]
"Once we have computed Σ̂, we generate samples from an approximated distribution of θ∗ + (1 + h)δ, by adding δ̂ to θ̂, which is obtained by
δ̂ ∼ N (0, (1 + h) 2 − 1
N Σ̂).",4.2. Parameter perturbation method,[0],[0]
"(10)
We can, in fact, confirm that the distribution of θ̂+ δ̂ approximates that of θ∗+ (1 +h)δ by applying the normal approximation to θ̂− θ∗ = δ.",4.2. Parameter perturbation method,[0],[0]
"From the normal approximation δ ∼ N (0, 1N Σ̂), we obtain θ ∗+(1+h)δ ∼ N (θ∗, (1+h) 2 N Σ̂) and θ̂+ δ̂ ∼ N (θ∗+0, 1N Σ̂+ (1+h)2−1 N Σ̂) = N",4.2. Parameter perturbation method,[0],[0]
"(θ ∗, (1+h) 2
N Σ̂).",4.2. Parameter perturbation method,[0],[0]
This procedure corresponds to (ii) in Algorithm 2.,4.2. Parameter perturbation method,[0],[0]
"We have compared our Algorithm 1 and Algorithm 2 with the hold-out method (Bailey & Marcos, 2016; Bailey et al., 2014) and the portfolio resampling method (Scherer, 2002) by means of the simulation models of the examples in Section 2.",5. Experiments,[0],[0]
"We used GUROBI Optimizer 6.0.43 for portfolio optimization, and the algorithm in (Ito & Fujimaki, 2016) for price optimization.",5. Experiments,[0],[0]
"The portfolio optimization problem described in Example 2 of Section 2 was constructed with θ∗ = (µ∗,Σ∗) defined by µ∗ = 1 + and Σ∗",5.1. Predictive Portfolio Optimization,[0],[0]
"= X>X , where ∈ Rd were generated by N(0, I) and each entry of X ∈ RD×D was drawn from N (0, D−1).",5.1. Predictive Portfolio Optimization,[0],[0]
"We generated datasets {xn}Nn=1 following N (µ∗,Σ∗), from which we computed θ̂, as in Example 2, and solved the optimization problem (1) with θ∗ replaced by θ̂, to obtain ẑ. We chose D = 50, N = 20, and λ = 1.0 for our simulation experiments.",5.1. Predictive Portfolio Optimization,[0],[0]
"When using the portfolio resampling method, we computed z̄ by means of 10 bootstrap resamplings and outputted f(z̄, θ̂) ≤ f(ẑ, θ̂).",5.1. Predictive Portfolio Optimization,[0],[0]
"For details regarding portfolio resampling, see, e.g., (Scherer, 2002).",5.1. Predictive Portfolio Optimization,[0],[0]
"For the hold-out validation, we first divided N data into N ′ and N −N ′, then computed ẑ1 from the former N ′ data and estimated θ̂2 from the letter N −N ′ data, and then calculated f(ẑ1, θ̂2).
",5.1. Predictive Portfolio Optimization,[0],[0]
"Accuracy Comparisons Figure 2 shows the means and the standard deviations of computed values of f(z∗, θ∗), f(ẑ, θ̂) and f(ẑ, θ∗) for 400 randomly-initialized datasets.",5.1. Predictive Portfolio Optimization,[0],[0]
"We have observed that:
• f(ẑ, θ̂) was much larger than f(ẑ, θ∗), which is consistent with Proposition 1.",5.1. Predictive Portfolio Optimization,[0],[0]
"• The hold-out method performed much worse than our 3 http://www.gurobi.com/
CV and perturbation methods, though its performance improved with an increasingN ′. Also, the variance in the proposed methods was much smaller.",5.1. Predictive Portfolio Optimization,[0],[0]
Note that we could not set N ′,5.1. Predictive Portfolio Optimization,[0],[0]
to be larger than N ′,5.1. Predictive Portfolio Optimization,[0],[0]
= 18 since the estimation of θ̂1 and θ̂2 would fail.,5.1. Predictive Portfolio Optimization,[0],[0]
•,5.1. Predictive Portfolio Optimization,[0],[0]
"The portfolio resampling method computed slightly less optimistic value than f(ẑ, θ̂), but a large amount of optimistic bias remained.",5.1. Predictive Portfolio Optimization,[0],[0]
• The perturbation method corrected bias better than the CV method w.r.t.,5.1. Predictive Portfolio Optimization,[0],[0]
both bias and variance.,5.1. Predictive Portfolio Optimization,[0],[0]
"Indeed, it almost perfectly corrected the optimistic bias in expectation.",5.1. Predictive Portfolio Optimization,[0],[0]
Note that K = 10 was the largest possible value because at least two samples are necessary for estimating the covariance matrix.,5.1. Predictive Portfolio Optimization,[0],[0]
This means that the value of CV (K = 10) achieved the minimum bias for the CV method.,5.1. Predictive Portfolio Optimization,[0],[0]
•,5.1. Predictive Portfolio Optimization,[0],[0]
"The CV method and the hold-out method produced
conservative estimates.",5.1. Predictive Portfolio Optimization,[0],[0]
"The pessimistic bias in the CV method came from the difference between ẑ ∈ arg maxz∈Z f(z, θ̂) and z̃ in (6).
",5.1. Predictive Portfolio Optimization,[0],[0]
"Note that E[f(ẑ, θ∗)] was poorer than E[f(z∗, θ∗)], where the former was the best objective value achieved with the available finite training samples.",5.1. Predictive Portfolio Optimization,[0],[0]
"This negative difference is unavoidable with our bias correction, which appears to raise an interesting open challenge w.r.t.",5.1. Predictive Portfolio Optimization,[0],[0]
"the combination of our bias correction with robust optimization (Bertsimas et al., 2011), i.e., the former mitigates the optimistic bias, and the later mitigates uncertainty in objective functions.
",5.1. Predictive Portfolio Optimization,[0],[0]
Sensitivity of the Perturbation Method We investigated the sensitivity of the perturbation method w.r.t.,5.1. Predictive Portfolio Optimization,[0],[0]
"h > 0, which is the important trade-off parameter in bias and variance.",5.1. Predictive Portfolio Optimization,[0],[0]
"We applied it to 100 different randomly-initialized datasets, for which we set h = 0.05, 0.10, . . .",5.1. Predictive Portfolio Optimization,[0],[0]
", 0.50.",5.1. Predictive Portfolio Optimization,[0],[0]
"Because s is not sensitive, we fixed it to s = 10.",5.1. Predictive Portfolio Optimization,[0],[0]
"Figure 3 demonstrates the changes in bias and variance (top figure) and RMSE against f(ẑ, θ∗), over h.",5.1. Predictive Portfolio Optimization,[0],[0]
"As the value
of h increased, the bias increased though the variance decreased (top figure), as was implied in Proposition 4, and this resulted in significantly larger RMSE values with smaller values of h. This observation indicates that an appropriate balance between bias and variance must be determined, and that a variance-sensitive measure such as RMSE can be used as a guide to determine the trade-off.",5.1. Predictive Portfolio Optimization,[0],[0]
We applied our algorithms to the predictive price optimization discussed as Example 3 in Section 2.,5.2. Predictive Price Optimization,[0],[0]
"As reported in (Ito & Fujimaki, 2017), the optimal value in this problem contains optimistic bias, which is consistent with Proposition 1.",5.2. Predictive Price Optimization,[0],[0]
"Unlike in the portfolio optimization, the parameter θ̂ is estimated by regression techniques, and the set of feasible strategies Z is discrete.
",5.2. Predictive Price Optimization,[0],[0]
"Simulation Experiment In this experiment, we investigated the effect of the optimistic bias and our bias correction over parameter dimensionality, i.e., the number of products d.",5.2. Predictive Price Optimization,[0],[0]
"We generated the same simulation data as in (Ito & Fujimaki, 2017).",5.2. Predictive Price Optimization,[0],[0]
"The sales quantity qi of the i-th product was generated from the regression model qi = αi + ∑d j=1 βijpj , where αi and βij were generated by uniform distributions, where αi ∈",5.2. Predictive Price Optimization,[0],[0]
"[d, 3d], βij ∈",5.2. Predictive Price Optimization,[0],[0]
"[0, 2] for i 6= j, and βii ∈",5.2. Predictive Price Optimization,[0],[0]
"[−2d,−d].",5.2. Predictive Price Optimization,[0],[0]
"The feasible region Z was defined by Z = {0.6, 0.7, . . .",5.2. Predictive Price Optimization,[0],[0]
", 1.0}d.",5.2. Predictive Price Optimization,[0],[0]
"We chose N = 500 for our experiments.
",5.2. Predictive Price Optimization,[0],[0]
"Figure 4 shows the change in the objective values normalized by the ideal objective value f(z∗, θ∗) over the number
of products d. For Algorithm 1 (CV method), we chose K = 2 so that the hold-out samples would be sufficient to estimate parameters {αi} and {βij}.",5.2. Predictive Price Optimization,[0],[0]
"We observed that:
• f(ẑ, θ∗) degraded against f(z∗, θ∗) with increasing d because the estimation error in machine learning increased.",5.2. Predictive Price Optimization,[0],[0]
•,5.2. Predictive Price Optimization,[0],[0]
"The optimistic bias, f(ẑ, θ̂)− f(ẑ, θ∗), rapidly increased because f(ẑ, θ̂)− f(z∗, θ∗) also increased in addition to the increase in f(z∗, θ∗)− f(ẑ, θ∗).",5.2. Predictive Price Optimization,[0],[0]
•,5.2. Predictive Price Optimization,[0],[0]
"The CV method suffered from pessimistic bias, which increased as d increased.",5.2. Predictive Price Optimization,[0],[0]
•,5.2. Predictive Price Optimization,[0],[0]
"The perturbation method corrected the bias accurately even if the parameter dimensionality, i.e., d, increased.
",5.2. Predictive Price Optimization,[0],[0]
"These results confirm the robustness of our proposed method over parameter dimensionality and also its general applicability to a wide range of problems (the portfolio optimization in Section 5.1 is continuous and convex while the price optimization in this section is discrete and non-convex).
",5.2. Predictive Price Optimization,[0],[0]
Real-World Retail Dataset,5.2. Predictive Price Optimization,[0],[0]
"The real-world retail dataset used in (Ito & Fujimaki, 2017; 2016) contains sales information for a middle-size supermarket located in Tokyo.4 Using this information, we selected 50 regularly-sold beer products.",5.2. Predictive Price Optimization,[0],[0]
The data range was approximately the three years from 2012/01 to 2014/11.,5.2. Predictive Price Optimization,[0],[0]
We used the first 35 months (1063 samples) for training regression models and simulated the best price strategy for the next day 2014/12/1.,5.2. Predictive Price Optimization,[0],[0]
"We estimated parameters in regression models, using the least squares method.",5.2. Predictive Price Optimization,[0],[0]
"The other settings were same as in (Ito & Fujimaki, 2016).
",5.2. Predictive Price Optimization,[0],[0]
"The actual (non-optimized) gross profit in the past data was 106, 348 JPY, while the estimated optimal value f(ẑ, θ̂) was 490, 502 JPY, which represents an approximately 361% increase in gross profit, but this value was obviously unreal-
4 The data were provided by KSP-SP Co., LTD, http:// www.ksp-sp.com.
istically huge and unreliable (price changes alone could not increase a profit 4.6 by times!).",5.2. Predictive Price Optimization,[0],[0]
"The bias-corrected optimal gross profit with the perturbation method at h = 0.1 and s = 100 was 124, 477 JPY, which represents an approximately 17% increase in the gross profit.",5.2. Predictive Price Optimization,[0],[0]
"Although we were unable to confirm the validity of this value since this experiment was conducted on past historical data, intuitively speaking, a 17% increase in gross profit seems much more realistic than one of 361%, and considering the facts noted in the simulation studies, our result would surely seem more convincing to domain users.",5.2. Predictive Price Optimization,[0],[0]
One of important remaining issues in real applications is the estimation of the confidence region.,5.2. Predictive Price Optimization,[0],[0]
"As noted above, we can never learn the value of f(ẑ, θ∗) without performing ẑ, but the user has to make a decision as to whether to perform it or not without knowing the value.",5.2. Predictive Price Optimization,[0],[0]
"In such a case, it would be helpful to provide a confidence region w.r.t.",5.2. Predictive Price Optimization,[0],[0]
"the bias-corrected optimal value, which is available with neither the CV method nor the perturbation method.",5.2. Predictive Price Optimization,[0],[0]
"In this paper, we have focused on the framework of a combination of mathematical optimization and machine learning with which we solve an optimization problem whose objective is formulated with the aid of predictive models or estimators.",6. Conclusion,[0],[0]
We have demonstrated that such a framework suffers from a kind of bias w.r.t. optimal values because of overfitting of the solution to the constructed objective function.,6. Conclusion,[0],[0]
We have proposed a solution to this bias problem by means of developed methods that are guaranteed to compute an asymptotically unbiased estimator of the value of the true objective function.,6. Conclusion,[0],[0]
"Empirical results have demonstrated that the proposed approach results in successful estimates of the value of the true objective function.
",6. Conclusion,[0],[0]
A major open question remaining in this work is how to evaluate and reduce variance in the estimators of objective functions.,6. Conclusion,[0],[0]
"The variance in estimators, i.e., uncertainty in estimation, is essential information for decision makers in many situations, and reducing variance in the estimator would help them make better decisions.",6. Conclusion,[0],[0]
"For data-driven decision-making, one promising approach, called predictive optimization, is to solve maximization problems i n which the objective function to be maximized is estimated from data.",abstractText,[0],[0]
"Predictive optimization, however, suffers from the problem of a calculated optimal solution’s being evaluated too optimistically, i.e., the value of the objective function is overestimated.",abstractText,[0],[0]
This paper investigates such optimistic bias and presents two methods for correcting it.,abstractText,[0],[0]
"The first, which is analogous to cross-validation, successfully corrects the optimistic bias but results in underestimation of the true value.",abstractText,[0],[0]
Our second method employs resampling techniques to avoid both overestimation and underestimation.,abstractText,[0],[0]
"We show that the second method, referred to as the parameter perturbation method, achieves asymptotically unbiased estimation.",abstractText,[0],[0]
Empirical results for both artificial and real-world datasets demonstrate that our proposed approach successfully corrects the optimistic bias.,abstractText,[0],[0]
Unbiased Objective Estimation in Predictive Optimization,title,[0],[0]
The advent of “big data” in recent years has generated countless opportunities for the prediction of real world phenomena with unprecedented accuracy and at unprecedented scale.,1 Introduction,[0],[0]
Statistical methods for prediction exploit associations in existing data to predict some response variable.,1 Introduction,[0],[0]
"However, the task at hand is often not to predict the response variable from pre-existing data, but rather to determine how a change in one or more of the explanatory variables will cause changes in the response variable.
1Department of Mathematics, University of Virginia, Charlottesville, VA 22904, USA 2Department of Computer Science, University of Virginia, Charlottesville, VA 22904, USA.",1 Introduction,[0],[0]
"Correspondence to: Quanquan Gu <qg5w@virginia.edu>.
",1 Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1 Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1 Introduction,[0],[0]
"In statistics, causality is often established by means of a controlled, randomized experiment.",1 Introduction,[0],[0]
"Nevertheless, controlled, randomized experiments are often infeasible, leaving researchers with only access to observational data.",1 Introduction,[0],[0]
This situation arises routinely when working with time series data.,1 Introduction,[0],[0]
"Areas that must cope with this obstacle frequently include genetics (Shojaie & Michailidis, 2010) and neuroscience (Seth et al., 2015).",1 Introduction,[0],[0]
The natural question that arises is: how can one determine which factors cause changes in a certain response variable using only data in which all variables change simultaneously?,1 Introduction,[0],[0]
"Causal inference seeks to address this problem.
",1 Introduction,[0],[0]
"The classic method for causal inference among time series is a concept from econometrics known as Granger causality, named after Nobel Prize winning econometrician Clive Granger (Granger, 1969).",1 Introduction,[0],[0]
"Granger causality formalizes the intuitive notion that in a causal system, the cause must precede the effect, and the cause must hold some unique information that helps predict the effect.",1 Introduction,[0],[0]
"For example, let X
1 , . . .",1 Introduction,[0],[0]
", X T and Y 1 , . . .",1 Introduction,[0],[0]
", Y T be two stationary one-dimensional time series.",1 Introduction,[0],[0]
"We can model time series Y using the following auto-regressive model (Stock & Watson, 2011):
Y t =
pX
i=1
a",1 Introduction,[0],[0]
i Y t,1 Introduction,[0],[0]
"i + ✏t, (1.1)
where a 1 , . .",1 Introduction,[0],[0]
.,1 Introduction,[0],[0]
", a p are the coefficient parameters for the regression, p < T is the maximal lag of the model, and ✏
t is the error term.",1 Introduction,[0],[0]
"To determine whether or not X is a Granger cause of Y , we also form a second auto-regressive model:
Y t =
pX
i=1
b",1 Introduction,[0],[0]
i Y t,1 Introduction,[0],[0]
"i +
pX
i=1
c",1 Introduction,[0],[0]
i X t,1 Introduction,[0],[0]
i + !,1 Introduction,[0],[0]
"t, (1.2)
with coefficient parameters b 1 , . . .",1 Introduction,[0],[0]
", b p , c 1 , . . .",1 Introduction,[0],[0]
", c p , and error term !
t .",1 Introduction,[0],[0]
"In this classical regime, where the number of observations exceeds the number of variables (T p > 2p), one can fit both of these models with ordinary least squares (OLS).",1 Introduction,[0],[0]
"We can conduct an F-test between models (1.1) and (1.2) as well as hypothesis tests on coefficients c
i , 1  i  p, to determine if the extra information encompassed by previous values of X significantly aides in the prediction of
future values of Y .",1 Introduction,[0],[0]
"If this pair of models passes the F-test and at least one of the coefficient hypothesis tests at some significance level ↵, then we may reject the null hypothesis that X is not a Granger cause of Y (Granger, 1969).
",1 Introduction,[0],[0]
"Although the concept of Granger causality has existed for decades, Granger (1969) only rigorously treated the bivariate case.",1 Introduction,[0],[0]
"However, as noted by Arnold et al. (2007), Eichler (2006) provided one framework for multivariate analysis by applying graphical models to Granger causal inference.
",1 Introduction,[0],[0]
"Multivariate Granger causal inference relies on hypothesis testing of model coefficients in a fitted vector-autoregressive (VAR) model (Lutkepohl, 2007).",1 Introduction,[0],[0]
VAR models are fit with OLS.,1 Introduction,[0],[0]
"In the high-dimensional regime, where the number of parameters exceeds the number of observations (T p < pd, where d is the number of time series in the VAR model), OLS estimation is impossible.",1 Introduction,[0],[0]
"Hence, one must employ regularized regression methods.",1 Introduction,[0],[0]
"Perhaps the most wellknown such method is the Lasso (Tibshirani, 1996), which encourages sparsity in the coefficient parameter vector via an `
1 penalty.",1 Introduction,[0],[0]
"To conduct Granger causal inference in the high-dimensional regime, Arnold et al. (2007) proposed the “Lasso Granger” estimator, which we fully specify in (3.3).",1 Introduction,[0],[0]
"Unfortunately, since the limiting distribution of the underlying Lasso estimator is not normal (Knight & Fu, 2000) and intractable in general (Javanmard & Montanari, 2014), one cannot construct confidence intervals or compute test statistics for hypothesis tests of Lasso Granger coefficient point estimates.",1 Introduction,[0],[0]
"Thus, existing methods for high-dimensional Granger causal inference do not allow for the assessment of uncertainty.",1 Introduction,[0],[0]
"Uncertainty characterization proves an important, and often necessary, element of research in the natural sciences.",1 Introduction,[0],[0]
"Therefore, uncertainty assessment techniques would augment the versatility of high-dimensional Granger causal inference methods, and drive their wider adoption by the scientific community.
",1 Introduction,[0],[0]
Another issue in high-dimensional causal inference is how to limit the number of false positives generated when testing a large number of explanatory variables without sacrificing identification of the true causal effects.,1 Introduction,[0],[0]
"That is, the researcher wants to attain high power while still maintaining a low type I error rate.",1 Introduction,[0],[0]
"To this end, false discovery rate (FDR) control (Benjamini & Hochberg, 1995) proves an important part of any method for high-dimensional causal inference.",1 Introduction,[0],[0]
"Unfortunately, existing FDR control methods cannot cope with the two challenges posed by our setting: dependent test statistics and dependent observations.",1 Introduction,[0],[0]
"These methods thus prove unsuitable in many practical applications.
",1 Introduction,[0],[0]
"In this paper, we make two contributions.",1 Introduction,[0],[0]
"First, we propose a novel asymptotically unbiased estimator for highdimensional Granger causal inference inspired by Javanmard & Montanari (2014).",1 Introduction,[0],[0]
"We leverage this estimator’s unbiasedness to construct confidence intervals and p-values
for coefficient point estimates.",1 Introduction,[0],[0]
"In this way, we allow, for the first time, uncertainty characterization in high-dimensional Granger causal inference.",1 Introduction,[0],[0]
"Second, we propose a novel FDR control technique that can cope with dependent test-statistics and dependent observations.",1 Introduction,[0],[0]
"In addition to surmounting these theoretical obstacles to existing methods, our FDR control technique also achieves higher power in multiple testing than existing methods.",1 Introduction,[0],[0]
"Additionally, the proof techniques we use to extend high-dimensional results from the independent and identically distributed (i.i.d.) setting to our time series setting are of independent interest.",1 Introduction,[0],[0]
"Specifically, to establish the asymptotic unbiasedness and normality of our estimator, we appeal to Talagrand’s generic chaining (Talagrand, 2006) and martingale theory.",1 Introduction,[0],[0]
"We further employ martingale theory, along with empirical process theory, to prove the asymptotic validity of our FDR control procedure.
",1 Introduction,[0],[0]
The rest of this paper is organized as follows.,1 Introduction,[0],[0]
Section 2 contextualizes our contributions in the existing literature.,1 Introduction,[0],[0]
Section 3 sets up the problem of high-dimensional Granger causal inference.,1 Introduction,[0],[0]
Section 4 presents our novel de-biased estimator and FDR control procedure.,1 Introduction,[0],[0]
"Section 5 establishes our main theoretical results, which we corroborate empirically in Section 6.",1 Introduction,[0],[0]
Section 7 concludes the paper.,1 Introduction,[0],[0]
"As mentioned above, Clive Granger examined bivariate Granger causality in 1969 (Granger, 1969).",2 Related Work,[0],[0]
"Advances in the area of graphical models provided a strong framework for multivariate causal inference in general (Pearl, 2009).",2 Related Work,[0],[0]
"Graphical models were first applied specifically to Granger causal inference by Eichler (2001) and Eichler (2006), and have provided a foundation for more complex models.
",2 Related Work,[0],[0]
"However, these methods rely on OLS estimation, which is impossible in the high-dimensional regime.",2 Related Work,[0],[0]
Meinshausen & Bühlmann (2006) applied Lasso to the estimation of highdimensional graphical models.,2 Related Work,[0],[0]
"Arnold et al. (2007) then applied the method proposed by Meinshausen & Bühlmann (2006) to multivariate Granger causal inference, and introduced the estimator of primary interest for this work: the Lasso Granger estimator.",2 Related Work,[0],[0]
"The Lasso Granger estimator yields a coefficient vector in which non-zero coefficients indicate conditional Granger causes of the response variable.
",2 Related Work,[0],[0]
Classical methods for uncertainty analysis prove impossible for the Lasso Granger estimator.,2 Related Work,[0],[0]
"Recent work (Lee et al., 2013; Lockhart et al., 2014; Taylor et al., 2014) in the area of high-dimensional inference has made great strides toward addressing this issue.",2 Related Work,[0],[0]
"Early work focussed on constructing pvalues and confidence intervals for Lasso coefficients via the bootstrap (Chatterjee et al., 2013; Liu et al., 2013a).",2 Related Work,[0],[0]
"However, later work found that these methods perform poorly compared to more recent methods (Dezeure et al., 2015), especially in non-i.i.d. settings (Karoui & Purdom, 2016).
",2 Related Work,[0],[0]
"Perhaps the most promising work in high-dimensional inference has emerged from the perspective of bias correction (Bühlmann et al., 2013; Zhang & Zhang, 2014).",2 Related Work,[0],[0]
Subsequent work by Van de Geer et al. (2014) and Javanmard & Montanari (2014) introduced a method to de-bias the Lasso solution to yield asymptotically valid confidence intervals and hypothesis tests for coefficient point estimates.,2 Related Work,[0],[0]
"Nevertheless, these existing methods assume that the observations forming the design matrix are independent, and so cannot tackle causal inference among time series.",2 Related Work,[0],[0]
Our method applies the Lasso de-biasing technique to the original Lasso Granger estimator.,2 Related Work,[0],[0]
We overcome the inability of existing methods to cope with non-i.i.d.,2 Related Work,[0],[0]
"data by using Talagrand’s generic chaining (Talagrand, 2006) and the martingale technique to derive the asymptotic distribution of our novel de-biased Lasso Granger estimator.
",2 Related Work,[0],[0]
Hypothesis testing in the high-dimensional setting raises the need for procedures to address the multiple testing problem.,2 Related Work,[0],[0]
FDR control is one such way to control type I error in multiple testing.,2 Related Work,[0],[0]
Our setting poses two challenges to existing FDR control procedures.,2 Related Work,[0],[0]
"First, the most-widely used methods, such as the Benjamini-Hochberg procedure (Benjamini & Hochberg, 1995), assume the test statistics under consideration are independent.",2 Related Work,[0],[0]
"While Benjamini & Yekutieli (2001) proposed a slight variation on the Benjamini-Hochberg procedure that could control FDR under “positive regression dependency” (e.g., when the covariance matrix of the explanatory variables is strictly positive), in our setting where the explanatory variables interact in complex ways, the test statistics will not satisfy this property.",2 Related Work,[0],[0]
"This version of the Benjamini-Hochberg procedure achieves only low power in the presence of a general dependence structure (Romano et al., 2008), and is thus unsuitable for our setting.",2 Related Work,[0],[0]
"Recent methods from the area of graphical models, which explicitly model the dependency of explanatory variables, have made progress in addressing the case of dependent test statistics (Xie et al., 2011; Liu et al., 2013b).",2 Related Work,[0],[0]
"However, these methods still encounter the second challenge of our setting: dependent observations arising from time series data.",2 Related Work,[0],[0]
"To control FDR for dependent observations, one must resort to assumption-free methods, such as the Bonferroni technique, that achieve low power in practice.",2 Related Work,[0],[0]
"We propose a FDR control procedure that can cope with dependent test statistics and observations, and that achieves high power.
",2 Related Work,[0],[0]
Notation We denote matrix A,2 Related Work,[0],[0]
"= [A i,j ] 2 Rm⇥n and column vector v =",2 Related Work,[0],[0]
"[v
i ] 2 RT .",2 Related Work,[0],[0]
"We write the ` p
norm of vector v as kvk
p
= ⌃
i=T
i=1
|v i |p.",2 Related Work,[0],[0]
"Furthermore, kvk1 denotes the max-norm of vector v: kvk1 = max1iT |vi|.",2 Related Work,[0],[0]
"Additionally, kvk
0 = supp(v) designates the cardinality of the support (the set of all non-zero entries) of v. We represent the the max-norm of matrix A as kAk1 = maxi,j |Ai,j |.",2 Related Work,[0],[0]
"The minimum and maximum singular values of A are denoted by
min (A) and max (A), respectively.",2 Related Work,[0],[0]
"(x) ⌘
(1/ p 2⇡) R x
1 e t2/2dt refers to the cumulative distribu-
tion function of the standard normal distribution.",2 Related Work,[0],[0]
"For a random variable X and a sequence of random variables X
n , we write X n P ! X",2 Related Work,[0],[0]
"if X n
converges in probability to X , and X
n D ! X",2 Related Work,[0],[0]
"if X n
converges in distribution to X .",2 Related Work,[0],[0]
"For sequences of random variables X
n and Y n , we say X
n ⇣ Y n if X n has the “same asymptotic order” as Y n
, that is, if both sequences bound each other up to some universal multiplicative constant.",2 Related Work,[0],[0]
"In this section, we set up the problem of high dimensional Granger causal inference.",3 Granger Causality and its Estimator,[0],[0]
"Denote the design matrix X, the number of parameters d, the number of observations T , and the maximal lag p.",3 Granger Causality and its Estimator,[0],[0]
For a given design matrix X =,3 Granger Causality and its Estimator,[0],[0]
"[X
t,j ] 2 RT⇥d define the sample covariance matrix b⌃ = X>X/T 2 Rd⇥d.",3 Granger Causality and its Estimator,[0],[0]
"The j-th column of X represents time series X
j , 1  j  d.",3 Granger Causality and its Estimator,[0],[0]
"We can further denote lagged versions of each column in the design matrix with fX
t,j
=
(X t p,j , Xt p+1,j , . . .",3 Granger Causality and its Estimator,[0],[0]
",",3 Granger Causality and its Estimator,[0],[0]
"Xt 1,j)> 2",3 Granger Causality and its Estimator,[0],[0]
Rp.,3 Granger Causality and its Estimator,[0],[0]
"Note that Xt 1,j represents the observation immediately before X t,j
in time series X
j .",3 Granger Causality and its Estimator,[0],[0]
"In Granger causal analysis, the response variable is one of the explanatory variables.",3 Granger Causality and its Estimator,[0],[0]
"Hence, we can model an arbitrary variable X
t,j , with 1  j  d and p+ 1  t  T , by using the lagged values of all explanatory variables as predictors:
X t,j =
dX
i=1
✓ j⇤> i f X t,i + ✏ t,j .",3 Granger Causality and its Estimator,[0],[0]
"(3.1)
",3 Granger Causality and its Estimator,[0],[0]
"Here ✓j⇤ i 2 Rp and ✏ t,j ⇠ N(0, 2 j ).",3 Granger Causality and its Estimator,[0],[0]
"Time series X i is a conditional Granger cause of time series X j
(conditioned on the other d - 2 time series) if ✓j⇤
i contains any non-zero elements (i.e., k✓j⇤
i
k 0
> 0).",3 Granger Causality and its Estimator,[0],[0]
"We can vectorize the sets of all ✓j⇤
i
and all fX t,i , for 1  i  d, as ✓j⇤ = (✓j⇤>
1 ,✓j⇤> 2 , . . .",3 Granger Causality and its Estimator,[0],[0]
",✓j⇤> d )",3 Granger Causality and its Estimator,[0],[0]
"> 2 Rpd and fX t =
( f X > t,1 , fX> t,2 , . . .",3 Granger Causality and its Estimator,[0],[0]
", fX> t,d )",3 Granger Causality and its Estimator,[0],[0]
"> 2 Rpd, respectively.",3 Granger Causality and its Estimator,[0],[0]
"Based on (3.1), the Lasso Granger estimator (Arnold et al., 2007) is given by
b ✓ j = argmin
✓j
1 2(T p) TX
t=p+1
(X t,j ✓j>fX t ) 2 + k",3 Granger Causality and its Estimator,[0],[0]
"✓jk 1 ,
where > 0 is the regularization parameter.
",3 Granger Causality and its Estimator,[0],[0]
"Equivalently, letting eX = (fX p+1 , fX p+2 , . . .",3 Granger Causality and its Estimator,[0],[0]
", fX T )",3 Granger Causality and its Estimator,[0],[0]
"> 2 R(T p)⇥pd and Y
j = X p+1:T,j represent the lower T p elements of the j-th column of X , we can re-express our model in more standard notation as:
Y
j
= eX✓j⇤ + ✏, (3.2)
where ✏ ⇠ N(0, 2I (T p)⇥(T p)).",3 Granger Causality and its Estimator,[0],[0]
"We can now re-express
the Lasso Granger estimator as:
b ✓ j = argmin
✓j
",3 Granger Causality and its Estimator,[0],[0]
1 2(T p)kYj eX✓jk2 2 + k✓jk 1 .,3 Granger Causality and its Estimator,[0],[0]
"(3.3)
",3 Granger Causality and its Estimator,[0],[0]
"For ease of presentation, we will henceforth omit the identifying variable j from ✓j⇤, b✓j , and Y
j , and assume we are referring to some arbitrary response variable.",3 Granger Causality and its Estimator,[0],[0]
"Using the above notation, we can now denote the sample covariance matrix of eX as e⌃
n
= eX> eX/(T p) 2 Rpd⇥pd and the true covariance matrix as e⌃ = E[e⌃
n
].",3 Granger Causality and its Estimator,[0],[0]
"In this section, we introduce our de-biased Lasso Granger estimator, and construct confidence intervals and p-values for its elements.",4 Asymptotic Inference for Lasso Granger,[0],[0]
We will then present our method for false discovery rate control in multiple testing.,4 Asymptotic Inference for Lasso Granger,[0],[0]
"In deriving a de-biased version of the Lasso Granger estimator, we employ a variation of the Lasso de-biasing procedure proposed by Javanmard & Montanari (2014).",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"In particular, we define the de-biased Lasso Granger estimator b✓u as follows:
",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"b ✓ u = b ✓ + 1 T pM eX>(Y eXb✓), (4.1)
where b✓ 2 Rpd is the parameter vector yielded when computing the Lasso Granger estimator (3.3) for an arbitrary response variable Y = Y
j .",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"M = (m 1 ,m 2 , . . .",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
",m pd )",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"> 2 Rpd⇥pd is an estimate of e⌃ 1
n , the inverse sample covariance matrix of eX, where each m
i is the solution to the following optimization algorithm:
minimize m> e⌃ n m subject to ke⌃ n",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"m e i k1  µ, (4.2)
where e i 2 Rpd is the i-th column of I pd⇥pd, and the choice of µ will be clear after we deliver theory.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Our unbiased estimator b✓u, though inspired by Javanmard & Montanari (2014), diverges sharply from their work in several respects.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"While Javanmard and Montanari use the observed design matrix X in their estimator, we use the transformed design matrix eX.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Although in our time series setting the rows of design matrix X are already dependent, transforming X to eX exacerbates this dependency and renders the i.i.d. results underpinning Javanmard and Montanari’s work unusable.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Hence, we appeal to Talagrand’s generic chaining (Talagrand, 2006) and martingale theory to establish our theoretical results about b✓u.
Theorem 5.5 in Section 5 below proves that for any i 2 {1, 2, . . .",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
", pd}, the standardized estimate of the i-th element
of b✓u converges in distribution to the standard normal distribution:
p T p
b✓u i ✓",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
⇤,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"i
[Me⌃ n",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
M>]1/2,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"i,i
D !",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"N(0, 1).",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"(4.3)
Unfortunately, the true noise level, denoted here by , is unknown in most real-world applications.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Hence, we replace with a consistent estimator, denoted b , yielded by the Scaled Lasso (Sun & Zhang, 2012):
{b✓( ), b ( )} =
argmin
✓2Rpd, >0
⇢ 1
2 (T P )kY eX",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"✓k2 2 + 2 + k✓k 1 ,
(4.4)
where is the regularization parameter.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
Sun & Zhang (2012) prove b is a consistent estimator of when the penalized loss function is convex.,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
Sun & Zhang (2012) use the i.i.d assumption to establish convexity.,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"In our non-i.i.d. setting, we establish convexity via a restricted eigenvalue condition for martingale difference sequences.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Thus, b is consistent in our setting as well.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Then by the Slutsky Theorem (Van der Vaart, 2000), we can replace in (4.3) with b .
",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"One can easily apply (4.3) to construct confidence intervals for ✓⇤
i , for 1  i  pd.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"If the significance level is ↵ > 0, the 1 ↵ confidence interval for ✓⇤
i
is:
I i =",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"[ b✓u i
(↵, T p), b",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"✓u i
+ (↵, T p)], (4.5) where
(↵, T p) = 1(1 ↵/2)(b /pT p)[Me⌃ n",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
M>]1/2,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"i,i .
",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"We prove the asymptotic validity of this confidence interval in Corollary 5.6.
",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Similarly, we can also conduct hypothesis tests on the individual regression coefficients ✓⇤
i , for 1  i  pd.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"In the context of Granger causality, the relevant null and alternative hypotheses are Hi
0 :",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"✓⇤ i = 0 and Hi a : ✓⇤ i 6= 0, respectively.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
Having zero-coefficients for all variables p(x 1) <,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
i  px implies that time series 1  x  d is not a conditional Granger cause of the response time series.,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Conversely, rejecting Hi
0 for any variable p(x 1)",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
<,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
i  px amounts to rejecting the null hypothesis that time series x is not a Granger cause of the response time series.,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"We thus consider the following test statistic for Hi
0 :",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"✓⇤ i = 0:
cZ i =
b✓u i
p T p
b",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
[Me⌃ n,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
M>]1/2,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"i,i
.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"(4.6)
Note that under the null hypothesis cZ",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
i D !,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"N(0, 1) by (4.3).",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"The hypothesis test at significance level ↵ is thus given by
Z (↵) = 1( |cZ i | < z ↵/2 ), (4.7)
where z ↵/2 is the quantile of the standard normal distribution such that (z
↵/2 )",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
= ↵/2.,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"We reject the null hypothesis if and only if
Z (↵) = 1.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"The p-value for this hypothesis test is
P i = 2(1 (|cZ i |)).",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"(4.8) As usual, one would reject Hi
0 at a pre-specified significance level ↵ if P
i < ↵.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"We establish that the type I error of the hypothesis test
Z (↵) converges to the specified significance level, and that the p-value P
i is asymptotically uniformly distributed in Corollary 5.7.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Having established test statistics for individual coefficients of the de-biased Lasso Granger estimator, we now address the issue of FDR control.",4.2 False Discovery Rate Control,[0],[0]
"First, denote the set of coefficient indices i such that ✓⇤
i
= 0",4.2 False Discovery Rate Control,[0],[0]
"as H 0 = {i|✓⇤ i = 0, 1  i  pd}.",4.2 False Discovery Rate Control,[0],[0]
"Define the complement of this set as H
1 = {i|✓⇤ i 6= 0, 1  i  pd}.",4.2 False Discovery Rate Control,[0],[0]
"We define FDR and false discovery proportion (FDP) as follows:
FDP(⌫) =",4.2 False Discovery Rate Control,[0],[0]
P i2H 0,4.2 False Discovery Rate Control,[0],[0]
1(|cZ,4.2 False Discovery Rate Control,[0],[0]
"i
| ⌫)",4.2 False Discovery Rate Control,[0],[0]
"max{P 1jpd 1(|cZi| ⌫), 1} ,
FDR(⌫) = E[FDP(⌫)].
",4.2 False Discovery Rate Control,[0],[0]
When conducting hypothesis tests at significance 0,4.2 False Discovery Rate Control,[0],[0]
<,4.2 False Discovery Rate Control,[0],[0]
"↵ < 1, we seek the smallest ⌫ such that FDR(⌫)  ↵.",4.2 False Discovery Rate Control,[0],[0]
"In this way, we will be able to reject the null hypothesis as often as possible (i.e., we maximize power) while still guaranteeing that our type I error rate does not exceed ↵.",4.2 False Discovery Rate Control,[0],[0]
"Thus, the ideal choice of ⌫ is
b⌫ = inf ⇢ ⌫",4.2 False Discovery Rate Control,[0],[0]
> 0,4.2 False Discovery Rate Control,[0],[0]
":
P i2H
0
1{|cZ",4.2 False Discovery Rate Control,[0],[0]
"i | ⌫} max{P 1jpd 1{|cZj | ⌫}, 1}  ↵ .
(4.9)
Note that the left hand side of the inequality in (4.9) is FDP, whose expectation is FDR.",4.2 False Discovery Rate Control,[0],[0]
"Unfortunately, b⌫ cannot be computed under the unknown H
0",4.2 False Discovery Rate Control,[0],[0]
"(Liu et al., 2013b).",4.2 False Discovery Rate Control,[0],[0]
"However, following Liu & Luo (2014), we use the asymptotic normality of cZ
i under the null hypothesis to approximateP i2H
0
1{|cZ",4.2 False Discovery Rate Control,[0],[0]
i | ⌫} by 2(1 (⌫))pd.,4.2 False Discovery Rate Control,[0],[0]
"In multiple hypothesis testing, we use b⌫ as the threshold for rejecting the null hypothesis, instead of z
↵/2
, in hypothesis test Z (↵) (4.7).",4.2 False Discovery Rate Control,[0],[0]
Theorem 5.9 below demonstrates the asymptotic validity of this FDR control method.,4.2 False Discovery Rate Control,[0],[0]
"In this section we present our main theoretical results: the test statistic cZ
i from (4.6) converges in distribution to the standard normal under the null hypothesis, and the FDR control procedure presented in (4.9) asymptotically controls both FDR and FDP.",5 Main Theory,[0],[0]
"To begin, we present several definitions.
",5 Main Theory,[0],[0]
Definition 5.1.,5 Main Theory,[0],[0]
"(Vershynin, 2012)",5 Main Theory,[0],[0]
A random variable X is sub-Gaussian if there exists a constant C > 0,5 Main Theory,[0],[0]
"such that
P(|X|",5 Main Theory,[0],[0]
"> t)  2 exp[ t2/C2], for all t > 0.
",5 Main Theory,[0],[0]
"A random vector X 2 Rn is sub-Gaussian if the onedimensional marginals < X,v > are sub-Gaussian random variables for all v 2 Rn.",5 Main Theory,[0],[0]
Definition 5.2.,5 Main Theory,[0],[0]
"(Javanmard & Montanari, 2014)",5 Main Theory,[0],[0]
"The subGaussian norm of a random scalar variable X is:
kXk
2
= sup q 1 q 1/2(E[|X|q])1/q.
",5 Main Theory,[0],[0]
"The sub-Gaussian norm of a random vector X 2 Rn is: kXk
2
= sup u2Sn 1 khX,uik 2 ,
where Sn 1 is the unit sphere in Rn space.
",5 Main Theory,[0],[0]
"Having established these definitions, we impose two assumptions on the design matrix and the true covariance matrix of the design matrix.",5 Main Theory,[0],[0]
Assumption 5.3.,5 Main Theory,[0],[0]
"There exist universal constants C
min , C max such that 0 < C min  min ( e⌃)  ",5 Main Theory,[0],[0]
max ( e⌃)  C max .,5 Main Theory,[0],[0]
Assumption 5.4.,5 Main Theory,[0],[0]
"The rows of eX are sub-Gaussian and the sub-Gaussian norm of each row is bounded by some constant  so that kfX
i
k
2  , for i 2 {1, 2, . . .",5 Main Theory,[0],[0]
", T p}.",5 Main Theory,[0],[0]
"We use Assumption 5.3 to demonstrate that the restricted eigenvalue condition holds for e⌃
n in order to prove the asymptotic unbiasedness of b✓u. Assumption 5.4 plays a role at multiple stages of the proof of Theorem 5.5, including proving the restricted eigenvalue condition for e⌃
n and establishing a high-probability bound for the regularization parameter .",5 Main Theory,[0],[0]
"Both of these assumptions prove common in the high-dimensional inference literature.
",5 Main Theory,[0],[0]
We leverage Assumptions 5.3 and 5.4 to present the following theorem.,5 Main Theory,[0],[0]
Theorem 5.5.,5 Main Theory,[0],[0]
Suppose Assumptions 5.3 and 5.4 are satisfied.,5 Main Theory,[0],[0]
"Let s
0 = supp(✓⇤) ⇣ pT p/ log(pd) and µ ⇣ plog(pd)/(T p).",5 Main Theory,[0],[0]
"Then for any element b✓u
i of the de-biased Lasso Granger estimator b✓u defined in (4.1), we have
p T p
b✓u i ✓⇤ i
[Me⌃ n",5 Main Theory,[0],[0]
M>]1/2,5 Main Theory,[0],[0]
"i,i
D !",5 Main Theory,[0],[0]
"N(0, 1).
",5 Main Theory,[0],[0]
Theorem 5.5 immediately yields several useful results.,5 Main Theory,[0],[0]
"We first demonstrate the asymptotic validity of confidence interval (4.5) for any element of b✓u in the following corollary.
",5 Main Theory,[0],[0]
Corollary 5.6.,5 Main Theory,[0],[0]
"Denote significance level ↵ > 0, and for 1  i  pd, define interval",5 Main Theory,[0],[0]
"I
i
=",5 Main Theory,[0],[0]
"[ b✓u i
(↵, T p), b",5 Main Theory,[0],[0]
"✓u
i + (↵, T p)].",5 Main Theory,[0],[0]
"Here, (↵, T p) = (1 ↵/2)( / p T p)[Me⌃
n",5 Main Theory,[0],[0]
M>]1/2,5 Main Theory,[0],[0]
"i,i .",5 Main Theory,[0],[0]
"Then
lim T p!1 P(✓⇤ i 2",5 Main Theory,[0],[0]
I i ),5 Main Theory,[0],[0]
"= 1 ↵.
",5 Main Theory,[0],[0]
"By Corollary 5.6, the asymptotic coverage probability corresponds the the given confidence level.",5 Main Theory,[0],[0]
Note that we can replace with b by the Slutsky Theorem.,5 Main Theory,[0],[0]
"Similarly, we confirm in the following corollary that the type I error for hypothesis test
Z (↵), introduced in (4.7), matches the given significance level ↵.",5 Main Theory,[0],[0]
"Furthermore, we prove that the CDF of the p-value P
i for Z (↵), which we introduced in (4.8), converges in distribution to a uniform distribution.",5 Main Theory,[0],[0]
Corollary 5.7.,5 Main Theory,[0],[0]
"With
Z (↵) and P i defined as above, and significance level ↵ > 0, we have:
P( Z (↵) = 1|Hi 0 )",5 Main Theory,[0],[0]
(T p)!1 !,5 Main Theory,[0],[0]
↵ and P i D !,5 Main Theory,[0],[0]
U,5 Main Theory,[0],[0]
"[0, 1].
We now turn our attention to demonstrating the asymptotic validity of the FDR control method we present in Section 4.2.",5 Main Theory,[0],[0]
"To control FDR we desire the following property:
P i2H
0
1(|cZ",5 Main Theory,[0],[0]
"i | b⌫) 2|H
0
|(1 (b⌫))",5 Main Theory,[0],[0]
P !,5 Main Theory,[0],[0]
"1. (5.1)
",5 Main Theory,[0],[0]
"Unfortunately, in this application, the test statistics cZ",5 Main Theory,[0],[0]
"i
are correlated, rendering the convergence in (5.1) non-trivial.",5 Main Theory,[0],[0]
"In order to prove (5.1), we will leverage martingale theory, empirical process theory, and the following assumption.",5 Main Theory,[0],[0]
Assumption 5.8.,5 Main Theory,[0],[0]
"For constant c > 2,
X
i2H 1
1
✓ |✓⇤ i
| e⌃ 1/2
i,i
s
c log(pd) (T p) ◆ !",5 Main Theory,[0],[0]
"1,
as (T p, pd) !",5 Main Theory,[0],[0]
1.,5 Main Theory,[0],[0]
Assumption 5.8 implies that the number of true alternative hypotheses approaches infinity.,5 Main Theory,[0],[0]
"This property proves important because, as demonstrated by Liu et al. (2014), FDR control is impossible when the number of true alternative hypotheses is fixed.",5 Main Theory,[0],[0]
This assumption allows us to present the following theorem: Theorem 5.9.,5 Main Theory,[0],[0]
Assume pd  (T p)r and log(pd) = o,5 Main Theory,[0],[0]
( p T p) for some r > 0.,5 Main Theory,[0],[0]
"Furthermore, suppose that Assumption 5.8 and the assumptions of Theorem 5.5 hold.",5 Main Theory,[0],[0]
"Then at significance level ↵,
lim (T p,pd) FDR(b⌫) ↵|H 0 |/(pd) = 1 and FDP(b⌫) ↵|H 0 |/(pd) P ! 1,
as (T p, pd) !",5 Main Theory,[0],[0]
"1.
Theorem 5.9 establishes that the FDR control procedure we present in Section 4.2 asymptotically controls both FDR and FDP.",5 Main Theory,[0],[0]
Note that the upper bound rate imposed on pd is very mild and will pose no issues in the vast majority of applications.,5 Main Theory,[0],[0]
"The assumptions of Theorem 5.5 guarantee the asymptotic normality of test statistic cZ
i
.",5 Main Theory,[0],[0]
"In this section, we establish the effectiveness of our debiased Lasso Granger estimator and our FDR control procedure via experimental results.",6 Numerical Experiments,[0],[0]
We also demonstrate that our methods outperform existing techniques.,6 Numerical Experiments,[0],[0]
"In this section, we corroborate our theoretical results and compare our contributions to existing methods with numerical experiments on synthetic data.",6.1 Synthetic Data,[0],[0]
The data for these experiments are generated by model (3.1).,6.1 Synthetic Data,[0],[0]
"In order to satisfy the assumptions of Theorem 5.5, each ✓j⇤ is a sparse vector such that the probability of each element being non-zero is p T p/(2pd log(pd)) for 1  j  d. We use the R package“flare” (Li et al., 2012) to generate sparse transition matrices, and the “glmnet” package (Friedman et al., 2010) to compute the biased Lasso Granger estimate.",6.1 Synthetic Data,[0],[0]
"We examine multiple different transition matrix patterns (“random” and “cluster”, as generated by the “flare” package) and multiple different configurations of (T, d, p).
",6.1 Synthetic Data,[0],[0]
"In Table 1, we see that the empirical type 1 error of hypothesis test
Z (↵) (4.7) corresponds to the given significance level across multiple configurations of (T, d, p).",6.1 Synthetic Data,[0],[0]
"Figure 1(a) corroborates Theorem 5.5 by demonstrating that the empirical distribution of test statistic cZ
i under the null hypothesis is the standard normal distribution.",6.1 Synthetic Data,[0],[0]
Figure 1(a) also illustrates that coefficient point estimates for the biased Lasso Granger estimator do not follow the standard normal distribution.,6.1 Synthetic Data,[0],[0]
Figure 1(b) validates Corollary 5.7 by demonstrating that the empirical CDF of p-value (4.8) for a true zero parameter is the uniform distribution.,6.1 Synthetic Data,[0],[0]
"Furthermore, Figures 1(c) and 1(d) exhibit that hypothesis test
Z (↵) (4.7) attains higher power than the biased Lasso Granger estimator when testing a single true non-zero parameter.",6.1 Synthetic Data,[0],[0]
"Table 2 demonstrates the accuracy of the de-biased Lasso Granger estimator via computations of the `
1 and ` 2 norms of the
error vector between b✓u and ✓⇤.
",6.1 Synthetic Data,[0],[0]
"Table 3 exhibits that, as suggested by theory, our FDR control procedure outperforms the Bonferroni and BenjaminiHochberg (B-H) (Benjamini & Hochberg, 1995; Benjamini & Yekutieli, 2001) methods in terms of power, while still maintaining low FDP.",6.1 Synthetic Data,[0],[0]
"While the Bonferroni method generally achieves only low power, the Benjamini-Hochberg method performs poorly in this application because the test statistics exhibit complex dependency, and thus violate a theoretical assumption of the Benjamini-Hochberg method.
",6.1 Synthetic Data,[0],[0]
"Lastly, Figure 2 demonstrates that our de-biased Lasso Granger estimator paired with our FDR control procedure outperform the original biased Lasso Granger estimator in terms of precision and recall.",6.1 Synthetic Data,[0],[0]
"Define sets TP = {i 2 H
1 |1(✓⇤ i identified as non-zero)} and FP = {i 2 H
0 |1(✓⇤ i identified as non-zero)}, so precision is |TP|/max{|TP| + |FP|, 1}, and recall is |TP|/|H
1 |.",6.1 Synthetic Data,[0],[0]
Note that precision is equivalent to 1 FDP and recall is equivalent to power.,6.1 Synthetic Data,[0],[0]
We calculate precision and recall at each point along the Lasso-path of the regularization parameter to generate the curves in Figure 2.,6.1 Synthetic Data,[0],[0]
These curves demonstrate that our de-biased Lasso Granger estimator and FDR control procedure achieve higher recall than the original Lasso Granger estimator without sacrificing precision.,6.1 Synthetic Data,[0],[0]
"Thus, not only does our method provide the interpretability and flexibility of uncertainty characterization, it also achieves higher power
than the original Lasso Granger estimator while maintaining low FDP.",6.1 Synthetic Data,[0],[0]
"Therefore, our method proves more suitable for high-dimensional Granger causal inference.",6.1 Synthetic Data,[0],[0]
"To demonstrate the applicability of our method to real-world data, we consider the climatological data set made available by Lozano et al. (2009).",6.2 Real Data,[0],[0]
"This data set contains monthly observations for seventeen climatological variables (e.g., temperature, precipitation, CO2, CH4, etc.) for 128 grid points spanning the continental United States (latitudes 32.975 to 45.475 and longitudes 84.75 to 117.25) from 1990 to
2002.",6.2 Real Data,[0],[0]
"Following the setup from Lozano et al. (2009), we enforce stationarity by deseasonlaizing the data using the R package “deseasonalize” (McLeod & Gweon, 2013).",6.2 Real Data,[0],[0]
We model the monthly temperature change of each grid point as a linear model of the first three lagged values of all explanatory variables in the surrounding 3⇥ 3 grid.,6.2 Real Data,[0],[0]
"Thus, for each of the 81 interior grid points, we obtain design matricies with dimensions T = 13⇥ 12 = 156 (13 years of monthly data), d = 17 ⇥ 9 = 153 (17 climatological variables observed at 9 grid points), and p = 3.",6.2 Real Data,[0],[0]
"For each of these design matricies, we use the R package “glmnet”(Friedman et al., 2010) to produce the biased Lasso Granger estimate from (3.3), and then apply (4.1) to construct the de-biased Lasso Granger estimate.
",6.2 Real Data,[0],[0]
"For each grid point, we test the significance of the three lagged values of monthly changes in Carbon Dioxide (CO2) emissions for that grid point to determine if local CO2 emissions are a Granger cause of temperature changes when conditioned on many other climatological variables.",6.2 Real Data,[0],[0]
Recall that an explanatory variable is a Granger cause of the response variable if and only if any of the coefficients for any of the lags prove significant.,6.2 Real Data,[0],[0]
"We use the Bonferroni method, the Benjamini-Hochberg (B-H) procedure, and our FDR control method from Section 4.2 to control for multiple testing.",6.2 Real Data,[0],[0]
"At significance level ↵ = .05, the Bonferroni and Benjamini-Hochberg methods found that CO2 emissions are a Granger cause of monthly temperature changes for 10 of the 81 grid points, whereas our FDR control method discovered 13 such grid points.",6.2 Real Data,[0],[0]
"We thus corroborate the findings of Lozano et al. (2009), who employed graphical Granger modeling methods to establish Granger causality between CO2 emissions and temperature changes, and those of many climate researchers who have found increased CO2 emissions to “cause” higher temperatures.",6.2 Real Data,[0],[0]
We also find empirical evidence that our FDR control method achieves higher power than the Bonferroni and Benjamini-Hochberg methods.,6.2 Real Data,[0],[0]
Figure 3 displays the results of this simulation.,6.2 Real Data,[0],[0]
"In this paper, we propose a novel unbiased estimator for conducting Granger causal inference in the high-dimensional
(a) Bonferroni, B-H (b) FDR Control
regime.",7 Conclusion,[0],[0]
"We introduce test statistics and confidence intervals for our estimator, thereby accomplishing the previously impossible task of uncertainty characterization in high-dimensional Granger causal inference.",7 Conclusion,[0],[0]
"Additionally, we introduce a novel method for false discovery rate control that achieves higher-power in multiple testing than existing alternatives in our setting.",7 Conclusion,[0],[0]
"Lastly, we validate our theoretical results with experiments on both synthetic data and real-world climatological data.",7 Conclusion,[0],[0]
Future extensions of our work may include generalizations of our method to cope with non-Gaussian noise and non-linear causality.,7 Conclusion,[0],[0]
We would like to thank the anonymous reviewers for their helpful comments.,Acknowledgements,[0],[0]
This research was sponsored in part by the National Science Foundation IIS-1618948 and IIS1652539.,Acknowledgements,[0],[0]
The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies.,Acknowledgements,[0],[0]
Causal inference among high-dimensional time series data proves an important research problem in many fields.,abstractText,[0],[0]
"While in the classical regime one often establishes causality among time series via a concept known as “Granger causality,” existing approaches for Granger causal inference in high-dimensional data lack the means to characterize the uncertainty associated with Granger causality estimates (e.g., p-values and confidence intervals).",abstractText,[0],[0]
We make two contributions in this work.,abstractText,[0],[0]
"First, we introduce a novel asymptotically unbiased Granger causality estimator with corresponding test statistics and confidence intervals to allow, for the first time, uncertainty characterization in high-dimensional Granger causal inference.",abstractText,[0],[0]
"Second, we introduce a novel method for false discovery rate control that achieves higher power in multiple testing than existing techniques and that can cope with dependent test statistics and dependent observations.",abstractText,[0],[0]
We corroborate our theoretical results with experiments on both synthetic data and real-world climatological data.,abstractText,[0],[0]
Uncertainty Assessment and False Discovery Rate Control in High-Dimensional Granger Causal Inference,title,[0],[0]
"A fundamental task in machine learning (ML) is to discover latent patterns underlying data, for instance, extracting topics from documents and communities from social networks.",1. Introduction,[0],[0]
"Latent space models (Bishop, 1998; Knott & Bartholomew, 1999; Blei, 2014) are effective tools to accomplish this task.",1. Introduction,[0],[0]
"An LSM contains a collection of learnable components such as hidden units in neural networks and factors in factor analysis (Harman, 1960).",1. Introduction,[0],[0]
Each component is aimed at capturing a hidden pattern.,1. Introduction,[0],[0]
"In most LSMs, components are parameterized by vectors.
",1. Introduction,[0],[0]
"Among the many challenges encountered in latent space modeling, two of them are of particular interest to us.
",1. Introduction,[0],[0]
"1Machine Learning Department, Carnegie Mellon University 2Petuum Inc.",1. Introduction,[0],[0]
"Correspondence to: Pengtao Xie <pengtaox@cs.cmu.edu>, Eric P. Xing <eric.xing@petuum.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"First, under many circumstances, the frequency of patterns is highly imbalanced.",1. Introduction,[0],[0]
Some patterns have very high frequency while others occur less frequently.,1. Introduction,[0],[0]
"As a typical example, in a news corpus, politics and economics are frequent topics (patterns) while furniture and gardening are infrequent.",1. Introduction,[0],[0]
"Classic LSMs are sensitive to the skewness of pattern frequency and less capable of capturing the infrequent patterns (Wang et al., 2014).",1. Introduction,[0],[0]
"Second, when using LSMs, one needs to carefully balance the tradeoff between model size (precisely, the number of components) and modeling power (Xie, 2015).",1. Introduction,[0],[0]
"Larger-sized LSMs are more expressive, but incur higher computational complexity.",1. Introduction,[0],[0]
"It is desirable but challenging to achieve sufficient modeling power with a small number of components.
",1. Introduction,[0],[0]
"To address these two challenges, recent studies (Zou & Adams, 2012; Cogswell et al., 2015; Xie et al., 2015; 2016) investigate a “diversification” strategy which encourages the components in LSMs to be mutually different, either through frequentist-style regularization (Zou & Adams, 2012; Cogswell et al., 2015; Xie et al., 2015) or Bayesian learning (Xie et al., 2016).",1. Introduction,[0],[0]
"They conjecture that: (1) through “diversification”, some components that are originally aggregated around frequent patterns can be pushed apart to cover infrequent patterns; (2) “diversified” components bear less redundancy and are mutually complementary; a small number of such components are sufficient to model data well.
",1. Introduction,[0],[0]
"Along this line of research, several diversity-promoting regularizers have been proposed, based upon determinantal point process (Kulesza & Taskar, 2012; Zou & Adams, 2012), cosine similarity (Yu et al., 2011; Bao et al., 2013; Xie et al., 2015) and covariance (Malkin & Bilmes, 2008; Cogswell et al., 2015).",1. Introduction,[0],[0]
"While these regularizers demonstrate notable efficacy, they have certain limitations, such as sensitivity to vector scaling (Zou & Adams, 2012; Malkin & Bilmes, 2008), inability to measure diversity in a global manner (Yu et al., 2011; Bao et al., 2013; Xie et al., 2015) and computational inefficiency (Cogswell et al., 2015).",1. Introduction,[0],[0]
"To address these limitations, we propose a new diversity-promoting regularizer gaining inspiration from principal component analysis (Jolliffe, 2002), biological diversity (Magurran, 2013) and information theory (Cover & Thomas, 2012).
",1. Introduction,[0],[0]
We characterize “diversity” by considering two factors: uncorrelation and evenness.,1. Introduction,[0],[0]
"Uncorrelation (Cogswell et al., 2015) encourages the components to be uncorrelated, such that each component can independently capture a unique pattern.",1. Introduction,[0],[0]
"Evenness is inspired from biological diversity (Magurran, 2013) where an ecosystem is deemed to be more diverse if different species contribute equally to the maintenance of biological balance.",1. Introduction,[0],[0]
"Analogously, when measuring component diversity, we assign an “importance” score to each component and encourage these scores to be even.",1. Introduction,[0],[0]
"In the context of latent space modeling, evenness ensures each component plays a significant role in pattern discovery rather than being dominated by others.
",1. Introduction,[0],[0]
We study uncorrelation and evenness from a statistical perspective.,1. Introduction,[0],[0]
The components are considered as random variables and the eigenvalues of their covariance matrix can be leveraged to characterize these two factors.,1. Introduction,[0],[0]
"First, according to Principle Component Analysis (Jolliffe, 2002), the disparity of eigenvalues reflects the correlation among components: the more uniform the eigenvalues, the less correlated the components.",1. Introduction,[0],[0]
"Second, eigenvalues represent the variance along principal directions and can be used to measure the “importance” of components.",1. Introduction,[0],[0]
"Promoting uniform importance amounts to encouraging evenness among eigenvalues.
",1. Introduction,[0],[0]
"To promote uniformity among the eigenvalues, we encourage the discrete distribution parametrized by the normalized eigenvalues to have small Kullback-Leibler divergence with the uniform distribution, based on which, we define a uniform eigenvalue regularizer (UER) and make a connection with the von Neumann entropy (Bengtsson & Zyczkowski, 2007) and with the von Neumann divergence (Kulis et al., 2009).",1. Introduction,[0],[0]
"We apply UER to two LSMs – distance metric learning (DML) (Xing et al., 2002) and long shortterm memory (LSTM) network (Hochreiter & Schmidhuber, 1997) – to encourage their components to be diverse and develop an efficient optimization algorithm.",1. Introduction,[0],[0]
"Experiments on healthcare, image and text data demonstrate that UER (1) greatly improves the performance of LSMs; (2) better captures infrequent patterns; (3) reduces model size without sacrificing modeling power; (4) outperforms other diversity-promoting regularizers.
",1. Introduction,[0],[0]
"The major contributions of this paper are: • We propose a new diversity-promoting regularizer
from the perspectives of uncorrelation and evenness.
",1. Introduction,[0],[0]
"• We propose to simultaneously promote uncorrelation and evenness by encouraging uniformity among the eigenvalues of the covariance matrix of components.
",1. Introduction,[0],[0]
"• We develop an efficient projected gradient descent algorithm to solve UE regularized LSM problems.
",1. Introduction,[0],[0]
"• In experiments, we demonstrate the effectiveness of this regularizer on two LSMs: DML and LSTM.
",1. Introduction,[0],[0]
The rest of the paper is organized as follows.,1. Introduction,[0],[0]
Section 2 reviews related works.,1. Introduction,[0],[0]
Section 3 introduces the uniform eigenvalue regularizer.,1. Introduction,[0],[0]
Section 4 presents experimental results and Section 5 concludes the paper.,1. Introduction,[0],[0]
"Diversity promoting regularization has been widely used in classification (Malkin & Bilmes, 2008), ensemble learning (Yu et al., 2011) and latent space modeling (Zou & Adams, 2012; Xie et al., 2015; 2017).",2. Related Works,[0],[0]
"In the sequel, we present a brief review of existing diversity-promoting regularizers.",2. Related Works,[0],[0]
"Several regularizers (Yu et al., 2011; Bao et al., 2013; Xie et al., 2015; 2017) are based on pairwise dissimilarity of components: if every two components are dissimilar, then overall the set of components are “diverse”.",2. Related Works,[0],[0]
"Given the weight vectors {aj}mj=1 of m components, Yu et al. (2011) define the regularizer as∑
1≤j<k≤m(1−cjk), where cjk is the cosine similarity between component j and k.",2. Related Works,[0],[0]
"In (Bao et al., 2013), the score is defined as − log( 1m(m−1) ∑ 1≤j<k≤m β|cjk|) 1 β where β > 0.",2. Related Works,[0],[0]
"In (Xie et al., 2015), the score is defined as mean of {arccos(|cjk|)} minus the variance of {arccos(|cjk|)}, where the variance term is utilized to encourage the dissimilarity scores {arccos(|cjk|)} to be even.",2. Related Works,[0],[0]
"Xie et al. (2017) define the regularizer as ∑ 1≤i<j≤m k(ai,aj) where k(·, ·) is a kernel function.",2. Related Works,[0],[0]
"These regularizers are applied to classifiers ensemble, neural network and restricted Boltzmann machine.",2. Related Works,[0],[0]
"While these regularizers can capture pairwise dissimilarities between components, they are unable to capture higher-order “diversity”.
",2. Related Works,[0],[0]
"Determinantal Point Process (DPP) (Kulesza & Taskar, 2012) was used by (Zou & Adams, 2012; Mariet & Sra, 2015) to encourage the topic vectors in Latent Dirichlet Allocation (Blei et al., 2003), Gaussian mean vectors in Gaussian Mixture Model and hidden units in neural network to be “diverse”.",2. Related Works,[0],[0]
"The DPP regularizer is defined as − log det(L), where L is a m × m kernel matrix and det(·) denotes the determinant of the matrix.",2. Related Works,[0],[0]
"Lij equals to k(ai,aj) and k(·, ·) is a kernel function.",2. Related Works,[0],[0]
"In geometry, det(L) is the volume of the parallelepiped formed by vectors in the feature space associated with kernel k. Vectors that result in a larger volume are considered to be more “diverse”.",2. Related Works,[0],[0]
"Since volume depends on all vectors simultaneously, DPP is able to measure diversity in a global way.",2. Related Works,[0],[0]
The drawback of DPP lies in its sensitivity to the scaling of vectors.,2. Related Works,[0],[0]
"The volume increases with the `2 norm of vectors, but “diversity” does not.",2. Related Works,[0],[0]
Malkin & Bilmes (2008) propose to promote diversity by maximizing the determinant of vectors’ covariance matrix.,2. Related Works,[0],[0]
"Similar to DPP, this regularizer is sensitive to vector scaling.
",2. Related Works,[0],[0]
"Unlike the aforementioned regularizers which are defined directly on weight vectors, Cogswell et al. (2015) design a
regularizer on hidden activations in the neural network and influence the parameters indirectly.",2. Related Works,[0],[0]
"The number of hidden activations could be much larger than that of weight parameters (like in a convolutional neural network), which may render this regularizer to be computationally inefficient.",2. Related Works,[0],[0]
"In this section, we develop a uniform eigenvalue regularizer and apply it to promote “diversity” in two LSMs.",3. Method,[0],[0]
A latent space model (LSM) is equipped with a set of m components and each component is represented with a vector a ∈ Rd.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"To achieve broader coverage of infrequent patterns and reduce model size without sacrificing modeling power, previous works (Zou & Adams, 2012; Xie et al., 2015) propose to “diversify” the components by imposing a regularizer over them.
",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"As a subjective concept, “diversity” has been defined in various ways as reviewed in Section 2.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"In this paper, we define a new measure of “diversity” by taking two factors into consideration: uncorrelation and evenness.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
Uncorrelation is a measure of how uncorrelated the components are.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Literally, less correlation is equivalent to more diversity.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Evenness is borrowed from biological diversity (Magurran, 2013), which measures how equally important different species are in maintaining the ecological balance within an ecosystem.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"If no species dominates another, the ecosystem is deemed as more diverse.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Likewise, in latent space modeling, we desire the components to play equally important roles and no one dominates another, such that each component contributes significantly to the modeling of data.
",3.1. Uniform Eigenvalue Regularizer,[0],[0]
We characterize the uncorrelation among components from a statistical perspective: treating the components as random variables and measuring their covariance which is proportional to their correlation.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
Let A ∈ Rd×m denote the component matrix where in the k-th column is the parameter vector ak of component k.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Alternatively, we can take a row view (Figure 1(b)) of A: each component is treated as a random variable and each row vector ã>i can be seen as a sample drawn from the random vector formed by the m components.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
Let µ = 1d ∑d i=1,3.1. Uniform Eigenvalue Regularizer,[0],[0]
ãi = 1 dA,3.1. Uniform Eigenvalue Regularizer,[0],[0]
">1 be the sample mean, where the elements of 1 ∈ Rd are all 1.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"We compute the empirical covariance matrix of the components as
G = 1d ∑d i=1(ãi − µ)(ãi − µ)>
= 1dA >A− ( 1dA >1)( 1dA >1)>
(1)
",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Imposing the constraint A>1 = 0, we have G = 1dA >A.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Suppose A is a full rank matrix and m < d, then G is a full-rank matrix with rank m.
For the next step, we show that the eigenvalues of G play important roles in characterizing the uncorrelation and evenness of components.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
We start with uncorrelation.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
Let G = ∑m k=1,3.1. Uniform Eigenvalue Regularizer,[0],[0]
λkuku > k be the eigendecomposition where λk is an eigenvalue and uk is the associated eigenvector.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"As is well known in Principle Component Analysis (Jolliffe, 2002), an eigenvector uk of the covariance matrix G represents a principal direction of the data points and the associated eigenvalue λk tells the variability of points along that direction.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"As shown in Figure 2(a), the larger λk is, the more spread out the points along the direction uk.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"When the eigenvectors (principal directions) are not aligned with coordinate axis (as shown in Figure 2), the level of disparity among eigenvalues indicates the level of correlation among the m components (random variables).",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"The more different the eigenvalues are, the higher the correlation is.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"As shown in Figure 2(a), λ1 is about three times larger than λ2 and there is a high correlation along the direction u1.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"On the other hand, in Figure 2(b), the two eigenvalues are close to each other and the points evenly spread out in both directions with negligible correlation.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"In light of this, we would utilize the uniformity among eigenvalues of G to measure how uncorrelated the components are.
",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Secondly, we relate the eigenvalues with the other factor of diversity: evenness.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"When the eigenvectors are aligned with the coordinate axis (as shown in Figure 3(a)), the components are uncorrelated.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"In this case, we bring in evenness to measure diversity.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"As stated earlier, we first need to assign each component an importance score.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Since the eigenvectors are in parallel to the coordinate axis, the eigenvalues reflect the variance of components.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Analogous to PCA which posits that random variables with larger variance are
more important, we use variance to measure importance.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"As shown in Figure 3(a), component 1 has a larger eigenvalue λ1 and accordingly larger variability, hence is more important than component 2.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"According to the evenness criteria, the components are more diverse if their importance match, which motivates us to encourage the eigenvalues to be uniform.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"As shown in Figure 3(b), the two eigenvalues are close and the two components have roughly the same variability, hence are similarly important.
",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"To sum up, we desire to encourage the eigenvalues to be even in both cases: (1) when the eigenvectors are not aligned with the coordinate axis, they are preferred to be even to reduce the correlation of components; (2) when the eigenvectors are aligned with the coordinate axis, they are encouraged to be even such that different components contribute equally in modeling data.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Previously, encouraging evenness among variances (eigenvalues) is investigated in other problems, such as learning compact representations for efficient hashing (Kong & Li, 2012; Ge et al., 2013).
",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Next, we discuss how to promote uniformity among eigenvalues.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
The basic idea is: we normalize the eigenvalues into a probability simplex and encourage the discrete distribution parameterized by the normalized eigenvalues to have small Kullback-Leibler (KL) divergence with the uniform distribution.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Given the eigenvalues {λk}mk=1, we first normalize them into a probability simplex λ̂k = λk∑m
j=1 λj based on which we define a
distribution on a discrete random variable X = 1, · · · ,m where p(X = k) = λ̂k.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"In addition, to guarantee the eigenvalues are strictly positive, we require A>A to be positive definite.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"To encourage {λ̂k}mk=1 to be uniform, we encourage the distribution p(X) to be “close” to a uniform distribution q(X = k) = 1m , where the “closeness” is measured using KL divergence KL(p||q):∑m k=1",3.1. Uniform Eigenvalue Regularizer,[0],[0]
λ̂k log λ̂k 1/m = ∑m k=1 λk log λk∑m j=1,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"λj −log ∑m j=1 λj+logm.
",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"In this equation, ∑m k=1 λk log λk is equivalent to tr(( 1dA >A)log( 1dA
>A)), where log(·) denotes matrix logarithm.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"To show this, note that log( 1dA
>A) =∑m k=1 log(λk)uku > k , according to the property of matrix logarithm.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Then we have tr(( 1dA >A) log( 1dA
>A)) equals to tr(( ∑m k=1 λkuku > k )",3.1. Uniform Eigenvalue Regularizer,[0],[0]
( ∑m k=1 log(λk)uku > k )),3.1. Uniform Eigenvalue Regularizer,[0],[0]
"which
equals to ∑m",3.1. Uniform Eigenvalue Regularizer,[0],[0]
k=1,3.1. Uniform Eigenvalue Regularizer,[0],[0]
λk log λk.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"According to the property of trace, we have tr( 1dA >A) =",3.1. Uniform Eigenvalue Regularizer,[0],[0]
∑m k=1 λk.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Then the KL divergence can be turned into a diversity-promoting uniform eigenvalue regularizer (UER):
tr(( 1dA >A) log( 1dA >A))
tr( 1dA >A)
",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"− log tr(1 d A>A) (2)
subject to A>A 0 and A>1 = 0.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Compared with previous diversity-promoting regularizers, UER has the following benefits: (1) It measures the diversity of all components in a holistic way, rather than reducing to pairwise
dissimilarities as other regularizers (Yu et al., 2011; Bao et al., 2013; Xie et al., 2015) do.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
This enables UER to capture global relations among components.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"(2) Unlike determinant-based regularizers (Malkin & Bilmes, 2008; Zou & Adams, 2012) that are sensitive to vector scaling, UER is derived from normalized eigenvalues where the normalization effectively removes scaling.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
(3) UER is amenable for computation.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"First, unlike DoCev (Cogswell et al., 2015) that is defined over data-dependent intermediate variables incurring computational inefficiency, UER is directly defined on model parameters independent of data.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Second, unlike the regularizers proposed in (Bao et al., 2013; Xie et al., 2015) that are non-smooth, UER is a smooth function.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
The dominating computation in UER is the matrix logarithm.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"It does not substantially increase computational overhead as long as the number of components is not too large (e.g., less than 1000).
",3.1. Uniform Eigenvalue Regularizer,[0],[0]
We apply UER to promote diversity in LSMs.,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Let L(A) denote the objective function of an LSM, then an UEregularized LSM problem can be defined as
minA L(A) + λ",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"( tr(( 1dA >A) log( 1dA >A))
",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"tr( 1dA >A)
− log tr( 1dA >A))
s.t. A>1 = 0, A>A 0
where λ is the regularization parameter.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Similar to other diversity-promoting regularizers, UER is non-convex.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Since L(A) in most LSMs is non-convex, adding UER does not substantially increase difficulty for optimization.
",3.1. Uniform Eigenvalue Regularizer,[0],[0]
Connection with von Neumann Entropy,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"In this section, we make a connection between UER and von Neumann entropy.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"A matrix M is referred to as a density matrix (Bengtsson & Zyczkowski, 2007) if its eigenvalues are strictly positive and sum to one, equivalently, M 0 and tr(M) = 1.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"The von Neumann entropy (Bengtsson & Zyczkowski, 2007) of M is defined as S(M) = −tr(M log M), which is essentially the Shannon entropy of its eigenvalues.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"If the covariance matrix G of components is a density matrix, then we can use its von Neumann entropy to define a UER.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"To encourage the eigenvalues {λk}mk=1 of G to be even, we directly encourage the KL divergence between the distribution parameterized by the eigenvalues (without normalization) and the uniform distribution to be small: ∑m k=1 λk log λk 1/m = ∑m k=1",3.1. Uniform Eigenvalue Regularizer,[0],[0]
λk log,3.1. Uniform Eigenvalue Regularizer,[0],[0]
"λk+ logm, which is equivalent to encouraging the Shannon entropy of the eigenvalues",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"− ∑m k=1 λk log λk, i.e., the von Neumann entropy of G to be large.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Then a new UER can be defined as the negative von Neumann entropy of G: tr(( 1dA >A) log( 1dA >A)), subject to the constraints: (1) A>A 0; (2) tr( 1dA >A) = 1; (3) A>1 = 0.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"This new UER is a special case of the previous one (Eq.(2)).
",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Connection with von Neumann Divergence Next we make a connection between the UER and von Neumann divergence (Kulis et al., 2009).",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Given two positive defi-
nite matrices X and Y, their von Neumann divergence is defined as tr(X log X −X log Y −X + Y), which measures the closeness between the two matrices.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Given two vectors x,y ∈ Rm, their generalized KL divergence can be defined as ∑m k=1 xk log( xk yk
)",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"− (xk − yk), which measures the closeness between two vectors.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"To encourage uniformity among the eigenvalues of the covariance matrix G, we can decrease the generalized KL divergence between these eigenvalues and an all-1 vector:∑m
k=1 λk log( λk 1 )",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"− (λk − 1)
= tr(( 1dA >A) log( 1dA >A))−",3.1. Uniform Eigenvalue Regularizer,[0],[0]
tr( 1dA >A)),3.1. Uniform Eigenvalue Regularizer,[0],[0]
"+m
(3)
which is the von Neumann divergence between G and an identity matrix.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"Hence, encouraging uniformity among eigenvalues can be achieved by making G to be close to an identity matrix based on the von Neumann divergence.",3.1. Uniform Eigenvalue Regularizer,[0],[0]
"In this section, we apply the uniform eigenvalue regularizer to promote diversity in two latent space models: DML and LSTM.",3.2. Case Studies,[0],[0]
"We also applied it to latent Dirichlet allocation (Blei et al., 2003) and classifier ensemble (Yu et al., 2011).",3.2. Case Studies,[0],[0]
"Due to space limit, the results of the latter two are deferred to the supplements.
",3.2. Case Studies,[0],[0]
Distance Metric Learning (DML),3.2. Case Studies,[0],[0]
"Given data pairs either labeled as “similar” or “dissimilar”, DML (Xing et al., 2002; Davis et al., 2007; Guillaumin et al., 2009) aims to learn a distance metric under which similar pairs would be placed close to each other and dissimilar pairs are separated apart.",3.2. Case Studies,[0],[0]
"The learned distance can benefit a wide range of tasks, including retrieval, clustering and classification.",3.2. Case Studies,[0],[0]
"Following (Weinberger & Saul, 2009), we define the distance metric between x,y ∈ Rd as ‖A>x−A>y‖22 where A ∈ Rd×m is a parameter matrix whose column vectors are components.",3.2. Case Studies,[0],[0]
"Built upon the DML formulation in (Xie, 2015), an uniform-eigenvalue regularized DML (DML-UE) problem can be formulated as
minA ∑
(x,y)∈S ‖A>x−A>y‖22 + ∑
(x,y)∈D max(0, 1− ‖A>x−A>y‖22)
+λ( tr(( 1dA >A) log( 1dA >A))
",3.2. Case Studies,[0],[0]
"tr( 1dA >A)
− log tr( 1dA >A))
s.t. A>1 = 0, A>A 0 (4) where S and D are the set of similar and dissimilar pairs respectively.",3.2. Case Studies,[0],[0]
The first and second term in the objective function encourage similar pairs to have small distance and dissimilar pairs to have large distance respectively.,3.2. Case Studies,[0],[0]
"The learned metrics are applied for information retrieval.
",3.2. Case Studies,[0],[0]
"Long Short-Term Memory (LSTM) Network LSTM (Hochreiter & Schmidhuber, 1997) is a type of recurrent neural network, that is better at capturing long-term dependency in sequential modeling.",3.2. Case Studies,[0],[0]
"At each time step t where
the input is xt, there is an input gate it, a forget gate ft, an output gate ot, a memory cell ct and a hidden state ht.",3.2. Case Studies,[0],[0]
"The transition equations among them are
it = σ(W (i)xt + U (i)ht−1 + b",3.2. Case Studies,[0],[0]
(i)),3.2. Case Studies,[0],[0]
ft = σ(W (f)xt + U (f)ht−1 + b (f)),3.2. Case Studies,[0],[0]
ot = σ(W (o)xt + U (o)ht−1 + b (o)),3.2. Case Studies,[0],[0]
ct = it tanh(W(c)xt + U(c)ht−1 + b(c)),3.2. Case Studies,[0],[0]
"+ ft ct−1 ht = ot tanh(ct)
where W = {W(s)|s ∈ S = {i, f, o, c}} and U = {U(s)|s ∈ S} are gate-specific weight matrices and B",3.2. Case Studies,[0],[0]
= {b(s)|s ∈ S} are bias vectors.,3.2. Case Studies,[0],[0]
The row vectors in W and U are treated as components.,3.2. Case Studies,[0],[0]
"Let L(W,U ,B) denote the loss function of an LSTM network and R(·) denote the UER (including constraints), then a UE-regularized LSTM problem can be defined as
minW,U,B L(W,U ,B) + λ ∑ s∈S(R(W(s))",3.2. Case Studies,[0],[0]
"+R(U(s)))
(5) The LSTM network is applied for cloze-style reading comprehension (CSRC).",3.2. Case Studies,[0],[0]
"The network architecture follows that in (Seo et al., 2017), which achieves the state of the art performance on CSRC.",3.2. Case Studies,[0],[0]
We develop a projected gradient descent (PGD) algorithm to solve the UE-regularized LSM problem in Eq.(5).,3.3. Algorithm,[0],[0]
"The constraint A>A 0 ensures the eigenvalues of A>A are positive, such that log(A>A) is well-defined.",3.3. Algorithm,[0],[0]
"However, it makes optimization very nasty.",3.3. Algorithm,[0],[0]
"To address this issue, we add a small perturbation I over A>A where is a close-to-zero positive scalar and I is an identity matrix, to ensure log(A>A + I) is always well-defined.",3.3. Algorithm,[0],[0]
"Accordingly, the constraint A>A 0 can be eliminated.",3.3. Algorithm,[0],[0]
The PGD algorithm iteratively performs three steps: (1) compute (sub)gradient 4A of the objective function; (2) update A using gradient descent:,3.3. Algorithm,[0],[0]
Ã ← A − η 4 A; (3) project Ã to the constraint set {A|A>1 = 0}.,3.3. Algorithm,[0],[0]
"In step (1), the derivative of tr(( 1dA >A + I) log( 1dA >",3.3. Algorithm,[0],[0]
A + I)) is 2dA(log( 1 dA >,3.3. Algorithm,[0],[0]
A + I) + I).,3.3. Algorithm,[0],[0]
To compute the logarithm of 1dA >,3.3. Algorithm,[0],[0]
"A + I, we perform an eigen-decomposition of this matrix into UΛU>, transform Λ into another diagonal matrix Λ̃",3.3. Algorithm,[0],[0]
"where Λ̃jj = log(Λjj) and then compute log( 1dA
>A + I) as UΛ̃U>.",3.3. Algorithm,[0],[0]
The complexity of eigendecomposing this m-by-m matrix is O(m3).,3.3. Algorithm,[0],[0]
"In our applications, m is no more than 500, so O(m3) is not a big bottleneck.",3.3. Algorithm,[0],[0]
"In addition, this matrix is symmetric and the symmetry can be leveraged for fast eigen-decomposition.",3.3. Algorithm,[0],[0]
"In implementation, we use the MAGMA library that supports efficient eigen-decomposition of symmetric matrices on both CPUs and GPUs.",3.3. Algorithm,[0],[0]
"In step (3), the projection operation amounts to solving the following problem:",3.3. Algorithm,[0],[0]
minA 12‖A,3.3. Algorithm,[0],[0]
"− Ã‖ 2 F subject to A
>1 = 0.",3.3. Algorithm,[0],[0]
"According to KKT conditions (Boyd & Vandenberghe, 2004), we have
A− Ã + 1λ> = 0 and A>1 = 0.",3.3. Algorithm,[0],[0]
"Solving this system of equations, we get A = (I − 1d11
>)",3.3. Algorithm,[0],[0]
"Ã, which centers the row vectors in Ã to have zero mean.",3.3. Algorithm,[0],[0]
"In this section, we present experimental results.
",4. Experiments,[0],[0]
"Dataset We used five datasets in the experiments: an electronic health record dataset MIMIC-III (Johnson et al., 2016); two image datasets Stanford-Cars (Krause et al., 2013) and Caltech-UCSD-Birds (Welinder et al., 2010); two question answering (QA) datasets CNN and DailyMail (Hermann et al., 2015).",4. Experiments,[0],[0]
The first three were used for DML and the last two for LSTM.,4. Experiments,[0],[0]
Their statistics are summarized in Table 1.,4. Experiments,[0],[0]
MIMIC-III contains hospital admissions of patients.,4. Experiments,[0],[0]
The class label of each admission is the primarily diagnosed disease.,4. Experiments,[0],[0]
"For Stanford-Cars, CNN and DailyMail, we use a single train/test split specified by the data providers; for the other two, five random splits are performed and the results are averaged over the five runs.",4. Experiments,[0],[0]
"For the MIMIC-III dataset, we extract 7207-dimensional features: (1) 2 dimensions from demographics, including age and gender; (2) 5300 dimensions from clinical notes, including 5000-dimensional bag-of-words (weighted using tf-idf) and 300-dimensional Word2Vec (Mikolov et al., 2013); (3) 1905-dimensions from lab tests where the zeroorder, first-order and second-order temporal features are extracted for each of the 635 lab items.",4. Experiments,[0],[0]
"For bag-of-words, we remove stop words, then select the 5000 words with largest document frequency.",4. Experiments,[0],[0]
"For Word2Vec, we train 300- dimensional embeddings for each word; to represent a document, we average the embeddings of all words in this document.",4. Experiments,[0],[0]
"For the two image datasets, we use the VGG16 (Simonyan & Zisserman, 2014) convolutional neural network trained on the ImageNet (Deng et al., 2009) dataset to extract features, which are the 4096-dimensional outputs of the second fully-connected layer.",4. Experiments,[0.9609636132734419],"['For representing the input samples, we use the Frequent Pattern Tree (FP-Tree) structure that is the data structure of the FP-Growth algorithm (Han et al., 2004), i.e. one of the most common algorithms for frequent pattern mining.']"
"In the two QA datasets, each instance consists of a passage, a question and an answer.",4. Experiments,[0],[0]
"The question is a cloze-style task where an entity is replaced by a placeholder and the goal is to infer this missing entity (answer) from all the possible entities appearing in the passage.
",4. Experiments,[0],[0]
"Experimental Setup In DML experiments, two samples are labeled as similar if belonging to the same class and dissimilar otherwise.",4. Experiments,[0],[0]
"The learned distance metrics are ap-
plied for retrieval whose performance is evaluated using precision@K. We compare with two sets of regularizers: (1) diversity-promoting regularizers based on determinant of covariance (DC) (Malkin & Bilmes, 2008), cosine similarity (CS) (Yu et al., 2011), determinantal point process (DPP) (Kulesza & Taskar, 2012; Zou & Adams, 2012), InCoherence (IC) (Bao et al., 2013), mutual angles (MA) (Xie et al., 2015), and decorrelation (DeCov) (Cogswell et al., 2015); (2) regularizers that are designed for other purposes, including L2 norm for small norm, L1 norm for sparsity, low-rankness (Recht et al., 2010) and Dropout (Srivastava et al., 2014).",4. Experiments,[0],[0]
All these regularizers are applied to the same DML formulation (Eq.(4) without the regularizer).,4. Experiments,[0],[0]
"In addition, we compare with vanilla Euclidean distance (EUC) and other distance learning methods including information theoretic metric learning (ITML)",4. Experiments,[0],[0]
"(Davis et al., 2007), logistic discriminant metric learning (LDML) (Guillaumin et al., 2009), and geometric mean metric learning (GMML) (Zadeh et al., 2016).",4. Experiments,[0],[0]
"We use 5- fold cross validation to tune the regularization parameter in {10−5, 10−4, · · · , 105} and the number of components in {50, 100, 200, · · · , 500}.",4. Experiments,[0],[0]
"The best tuned regularization parameters of UER are: 0.001 for MIMIC, 0.01 for Cars and Birds.",4. Experiments,[0],[0]
"The best tuned component numbers are: 200 for MIMIC, 100 for Cars and 200 for Birds.",4. Experiments,[0],[0]
"The learning rate of the PGD algorithm is set to 0.001.
",4. Experiments,[0],[0]
"In LSTM experiments, the model architecture and experimental settings follow the Bidirectional Attention Flow (BIDAF) (Seo et al., 2017) model, which consists of the following layers: character embedding, word embedding, contextual embedding, attention flow, modeling and output.",4. Experiments,[0],[0]
"The contextual and modeling layers use long shortterm memory (LSTM) networks (Seo et al., 2017).",4. Experiments,[0],[0]
"In char-
acter embedding based on convolutional neural network, 100 1D filters are used, each with a width of 5.",4. Experiments,[0],[0]
The hidden state size is set to 100.,4. Experiments,[0],[0]
"AdaDelta (Zeiler, 2012) is used for optimization with a minibatch size of 48.",4. Experiments,[0],[0]
"Dropout (Srivastava et al., 2014) with probability 0.2 is used for all LSTM layers.",4. Experiments,[0],[0]
The model is trained for 8 epochs with early stop when the validation accuracy starts to drop.,4. Experiments,[0],[0]
"We compare UER with other diversity-promoting regularizers including DC, CS, DPP, IC, MA and DeCov.
",4. Experiments,[0],[0]
"Results Table 2 shows the retrieval precision (K = 10) on three datasets, where we observe: (1) DML-UE achieves much better precision than DML, proving that UER is an effective regularizer in improving generalization performance; (2) UER outperforms other diversity-promoting regularizers possibly due to its capability to capture global relations among all components and insensitivity to vector scaling; (3) diversity-promoting regularizers perform better than other types of regularizers such as L2, L1, low rank and Dropout, corroborating the efficacy of inducing diversity; (4) DML-UE outperforms other popular distance learning methods such as ITML, LDML and GMML.
",4. Experiments,[0],[0]
Table 3 shows the number of components that achieves the precision in Table 2.,4. Experiments,[0],[0]
"Compared with DML, DMLUE uses much fewer components to achieve better precision.",4. Experiments,[0],[0]
"For example, on the Cars dataset, DML-UE achieves 58.2% precision with 100 components.",4. Experiments,[0],[0]
"In contrast, with more components (300), DML achieves a much lower precision (53.1%).",4. Experiments,[0],[0]
"This demonstrates that by encouraging the components to be diverse, UER is able to reduce model size without sacrificing modeling power.",4. Experiments,[0],[0]
UER encourages equal “importance” among components such that each component plays a significant role in modeling data.,4. Experiments,[0],[0]
"As a result, it suffices to use a small number of components to achieve larger modeling power.",4. Experiments,[0],[0]
"Compared with other diversity-promoting regularizers, UER achieves better precision with fewer components, demonstrating its ability to better promote diversity.
",4. Experiments,[0],[0]
"Next, we verify whether “diversifying” the components in DML can better capture infrequent patterns.",4. Experiments,[0],[0]
"In the MIMICIII dataset, we consider diseases as patterns and consider a disease as “frequent” if more than 1000 hospital admissions are diagnosed with this disease and “infrequent” if otherwise.",4. Experiments,[0],[0]
Table 4 shows the retrieval precision on frequent diseases and infrequent diseases.,4. Experiments,[0],[0]
"As can be seen, compared with the baselines, DML-UE achieves more improvement on infrequent diseases than on frequent diseases.",4. Experiments,[0],[0]
"This indicates that by encouraging the components to diversely spread out, UER is able to better capture infrequent patterns (diseases in this case) without compromising the performance on frequent patterns.",4. Experiments,[0],[0]
"On infrequent diseases, DMLUE outperforms other diversity-promoting methods, showing the advantage of UER over other diversity-promoting regularizers.",4. Experiments,[0],[0]
"To further verify this, we select 3 most frequent diseases (hypertension, AFib, CAD) and randomly select 5 infrequent ones (helicobacter pylori, acute cholecystitis, joint pain-shlder, dysarthria, pressure ulcer), and show the precision@10 on each individual disease in Table 5.",4. Experiments,[0],[0]
"As can be seen, on the five infrequent diseases, DML-UE achieves higher precision than baselines while on the three frequent diseases, DML-UE achieves comparable precision.
",4. Experiments,[0],[0]
We empirically verify whether UER can promote uncorrelation and evenness.,4. Experiments,[0],[0]
"Givenm component vectors, we compute the empirical correlation (cosine similarity) of every two vectors, then average these pairwise correlation scores to measure the overall correlation of m vectors.",4. Experiments,[0],[0]
"We perform the study by learning distance metrics that have 200 components, on the MIMIC-III dataset.",4. Experiments,[0],[0]
The average correlation under unregularized DML and DML-UE is 0.73 and 0.57 respectively.,4. Experiments,[0],[0]
"This shows that UER can reduce corre-
lation.",4. Experiments,[0],[0]
"To measure evenness, we first measure the “importance” of components.",4. Experiments,[0],[0]
"For each component with parameter vector a, we project the training examples {xi}Ni=1 onto a: {x>i a}Ni=1, then use the variance of {x>i a}Ni=1 to measure the importance of this component.",4. Experiments,[0],[0]
"After that, we map these importance scores into a probabilistic simplex using softmax.",4. Experiments,[0],[0]
"Finally, the evenness is measured by the KL divergence between the discrete distribution parameterized by these probabilities and a uniform distribution.",4. Experiments,[0],[0]
A smaller KL divergence indicates larger evenness.,4. Experiments,[0],[0]
"On MIMIC-III with 200 components, the KL divergence under unregularized DML and DML-UE is 3.54 and 2.92 respectively.",4. Experiments,[0],[0]
"This suggests that our regularizer is able to encourage evenness.
",4. Experiments,[0],[0]
Table 6 shows the runtime taken by DML methods to reach convergence.,4. Experiments,[0],[0]
"Compared with unregularized DML, DMLUE does not increase the training time substantially.",4. Experiments,[0],[0]
"The relative increase is 11.2% on MIMIC, 15.4% on Cars and 13.9% on Birds.",4. Experiments,[0],[0]
"The runtime of DML-UE is close to DML regularized by other diversity-promoting regularizers.
",4. Experiments,[0],[0]
"In the LSTM experiments, Table 7 shows state of the art accuracy on the two QA datasets.",4. Experiments,[0],[0]
"Compared with the original BIDAF (Seo et al., 2017), our method BIDAF-UE achieves better accuracy, further demonstrating UER’s ability to improve generalization performance.",4. Experiments,[0],[0]
"Besides, UER outperforms other regularizers.",4. Experiments,[0],[0]
We propose a new diversity-promoting regularizer from the perspectives of uncorrelation which prefers the components in LSMs to be uncorrelated and evenness which encourages the components to contribute equally to the modeling of data.,5. Conclusions,[0],[0]
"Gaining insight from PCA, promoting uncorrelation and evenness both amount to encouraging the covariance matrix of components to have uniform eigenvalues, which leads to a uniform eigenvalue regularizer (UER).",5. Conclusions,[0],[0]
The UER is applied to DML and LSTM.,5. Conclusions,[0],[0]
"Experimental studies reveal that UER greatly boosts the performance of LSMs, better captures infrequent patterns, reduces model size without compromising modeling power and outperforms other diversity-promoting regularizers.",5. Conclusions,[0],[0]
We would like to thank the anonymous reviewers for the helpful suggestions and comments.,Acknowledgements,[0],[0]
"P.X and E.X are supported by National Institutes of Health P30DA035778, R01GM114311, National Science Foundation IIS1617583, DARPA FA872105C0003 and Pennsylvania Department of Health BD4BH4100070287.",Acknowledgements,[0],[0]
Latent space models (LSMs) provide a principled and effective way to extract hidden patterns from observed data.,abstractText,[0],[0]
"To cope with two challenges in LSMs: (1) how to capture infrequent patterns when pattern frequency is imbalanced and (2) how to reduce model size without sacrificing their expressiveness, several studies have been proposed to “diversify” LSMs, which design regularizers to encourage the components therein to be “diverse”.",abstractText,[0],[0]
"In light of the limitations of existing approaches, we design a new diversitypromoting regularizer by considering two factors: uncorrelation and evenness, which encourage the components to be uncorrelated and to play equally important roles in modeling data.",abstractText,[0],[0]
"Formally, this amounts to encouraging the covariance matrix of the components to have more uniform eigenvalues.",abstractText,[0],[0]
We apply the regularizer to two LSMs and develop an efficient optimization algorithm.,abstractText,[0],[0]
"Experiments on healthcare, image and text data demonstrate the effectiveness of the regularizer.",abstractText,[0],[0]
Uncorrelation and Evenness: a New Diversity-Promoting Regularizer,title,[0],[0]
"Keywords. Hawkes Process, Causality Inference, Cumulants, Generalized Method of Moments",text,[0],[0]
"In many applications, one needs to deal with data containing a very large number of irregular timestamped events that are recorded in continuous time.",1 Introduction,[0],[0]
"These events can reflect, for instance, the activity of users on a social network, see Subrahmanian et al. (2016), the high-frequency variations of signals in finance, see Bacry et al. (2015), the earthquakes and aftershocks in geophysics, see Ogata (1998), the crime activity, see Mohler et al. (2011) or the position of genes in genomics, see Reynaud-Bouret and Schbath (2010).",1 Introduction,[0],[0]
The succession of the precise timestamps carries a great deal of information about the dynamics of the underlying systems.,1 Introduction,[0],[0]
"In this context, multidimensional counting processes based models play a paramount role.",1 Introduction,[0],[0]
"Within this framework, an important task is to recover the mutual influence of the nodes (i.e., the different components of the counting process), by leveraging on their timestamp patterns, see, for instance, Bacry and Muzy (2016); Lemonnier and Vayatis (2014); Lewis and Mohler (2011); Zhou et al. (2013a); Gomez-Rodriguez et al. (2013); Farajtabar et al. (2015); Xu et al. (2016).
",1 Introduction,[0],[0]
"Consider a set of nodes I = {1, . . .",1 Introduction,[0],[0]
", d}.",1 Introduction,[0],[0]
For each i ∈,1 Introduction,[0],[0]
"I , we observe a set Zi of events, where each τ ∈ Zi labels the occurrence time of an event related to the activity of i.",1 Introduction,[0],[0]
"The events of all nodes can ∗massil.achab@m4x.org
ar X
iv :1
60 7.
06 33
3v 3
[ st
at .M
L ]
3 0
M ay
be represented as a vector of counting processes N t",1 Introduction,[0],[0]
=,1 Introduction,[0],[0]
"[N1t · · ·Ndt ]>, where N it counts the number of events of node i until time t ∈ R+, namely N it = ∑ τ∈Zi 1{τ≤t}.",1 Introduction,[0],[0]
The vector of stochastic intensities λt =,1 Introduction,[0],[0]
"[λ 1 t · · ·λdt ]> associated with the multivariate counting processN t is defined as
λit = lim dt→0 P(N it+dt −N it = 1|Ft) dt
for i ∈",1 Introduction,[0],[0]
"I , where the filtration Ft encodes the information available up to time t.",1 Introduction,[0],[0]
"The coordinate λit gives the expected instantaneous rate of event occurrence at time t for node i. The vector λt characterizes the distribution of N t, see Daley and Vere-Jones (2003), and patterns in the events time-series can be captured by structuring these intensities.
",1 Introduction,[0],[0]
"The Hawkes process introduced in Hawkes (1971) corresponds to an autoregressive structure of the intensities in order to capture self-excitation and cross-excitation of nodes, which is a phenomenon typically observed, for instance, in social networks, see for instance Crane and Sornette (2008).",1 Introduction,[0],[0]
"Namely, N t is called a Hawkes point process if the stochastic intensities can be written as
λit = µ i + d∑ j=1 ∫ t 0",1 Introduction,[0],[0]
φij(t−,1 Introduction,[0],[0]
"t′)dN jt′ ,
where µi ∈ R+ is an exogenous intensity and φij are positive, integrable and causal (with support in R+) functions called kernels encoding the impact of an action by node j on the activity of node i. Note that when all kernels are zero, the process is a simple homogeneous multivariate Poisson process.
",1 Introduction,[0],[0]
Most of the litterature uses a parametric approach for estimating the kernels.,1 Introduction,[0],[0]
"With no doubt, the most popular parametrization form is the exponential kernel φij(t)",1 Introduction,[0],[0]
"= αijβije−βijt because it definitely simplifies the inference algorithm (e.g., the complexity needed for computing the likelihood is much smaller).",1 Introduction,[0],[0]
"When d is large, in order to reduce the number of parameters, some authors choose to arbitrarily share the kernel shapes across the different nodes.",1 Introduction,[0],[0]
"Thus, for instance, in Yang and Zha (2013); Zhou et al. (2013b); Farajtabar et al. (2015), they choose φij(t) = αijh(t) with αij ∈ R+ quantifies the intensity of the influence of j on i and h(t) a (normalized) function that characterizes the time-profile of this influence and that is shared by all couples of nodes (i, j) (most often, it is chosen to be either exponential h(t) = βe−βt or power law h(t) = βt−(β+1)).",1 Introduction,[0],[0]
"Both approaches are, most of the time, highly non-realistic.",1 Introduction,[0],[0]
"On the one hand there is a priori no reason for assuming that the time-profile of the influence of a node j on a node i does not depend on the pair (i, j).",1 Introduction,[0],[0]
"On the other hand, assuming an exponential shape or a power law shape for a kernel arbitrarily imposes an event impact that is always instantly maximal and that can only decrease with time, while in practice, there may exist a latency between an event and its maximal impact.
",1 Introduction,[0],[0]
"In order to have more flexibility on the shape of the kernels, nonparametric estimation can be considered.",1 Introduction,[0],[0]
Expectation-Maximization algorithms can be found in Lewis and Mohler (2011) (for d = 1) or in Zhou et al. (2013a) (d > 1).,1 Introduction,[0],[0]
An alternative method is proposed in Bacry and Muzy (2016) where the nonparametric estimation is formulated as a numerical solving of a Wiener-Hopf equation.,1 Introduction,[0],[0]
"Another nonparametric strategy considers a decomposition of kernels on a dictionary of function h1, . . .",1 Introduction,[0],[0]
", hK , namely φij(t) = ∑K",1 Introduction,[0],[0]
k=1,1 Introduction,[0],[0]
"a ij k hk(t), where the coefficients a ij k are estimated, see Hansen et al. (2015); Lemonnier and Vayatis (2014) and Xu et al. (2016), where group-lasso is used to induce a sparsity pattern on the coefficients aijk that is shared across k = 1, . . .",1 Introduction,[0],[0]
",K.
Such methods are heavy when d is large, since they rely on likelihood maximization or least squares minimization within an over-parametrized space in order to gain flexibility on the shape of the kernels.",1 Introduction,[0],[0]
"This is problematic, since the original motivation for the use of Hawkes processes is to estimate the influence and causality of nodes, the knowledge of the full parametrization of the model being of little
interest for causality purpose.
",1 Introduction,[0],[0]
Our paper solves this problem with a different and more direct approach.,1 Introduction,[0],[0]
"Instead of trying to estimate the kernels φij , we focus on the direct estimation of their integrals.",1 Introduction,[0],[0]
"Namely, we want to estimate the matrixG =",1 Introduction,[0],[0]
"[gij ] where
gij = ∫",1 Introduction,[0],[0]
+∞ 0 φij(u),1 Introduction,[0],[0]
du ≥ 0 for 1 ≤,1 Introduction,[0],[0]
"i, j ≤ d. (1)
",1 Introduction,[0],[0]
"As it can be seen from the cluster representation of Hawkes processes (Hawkes and Oakes (1974)), this integral represents the mean total number of events of type i directly triggered by an event of type j, and then encodes a notion of causality.",1 Introduction,[0],[0]
"Actually, as detailed below (see Section 2.1), such integral can be related to the Granger causality (Granger (1969)).
",1 Introduction,[0],[0]
The main idea of the method we developed in this paper is to estimate the matrixG directly using a matching cumulants (or moments) method.,1 Introduction,[0],[0]
"Apart from the mean, we shall use second and third-order cumulants which correspond respectively to centered second and third-order moments.",1 Introduction,[0],[0]
We first compute an estimation M̂ of these centered moments M(G) (they are uniquely defined byG).,1 Introduction,[0],[0]
"Then, we look for a matrix Ĝ that minimizes the L2 error ‖M(Ĝ)− M̂‖2.",1 Introduction,[0],[0]
Thus the integral matrix Ĝ is directly estimated without making hardly any assumptions on the shape the involved kernels.,1 Introduction,[0],[0]
"As it will be shown, this approach turns out to be particularly robust to the kernel shapes, which is not the case of all previous Hawkes-based approaches that aim causality recovery.",1 Introduction,[0],[0]
"We call this method NPHC (Non Parametric Hawkes Cumulant), since our approach is of nonparametric nature.",1 Introduction,[0],[0]
We provide a theoretical analysis that proves the consistency of the NPHC estimator.,1 Introduction,[0],[0]
Our proof is based on ideas from the theory of Generalized Method of Moments (GMM) but requires an original technical trick since our setting strongly departs from the standard parametric statistics with i.i.d observations.,1 Introduction,[0],[0]
"Note that moment and cumulant matching techniques proved particularly powerful for latent topic models, in particular Latent Dirichlet Allocation, see Podosinnikova et al. (2015).",1 Introduction,[0],[0]
"A small set of previous works, namely Da Fonseca and Zaatour (2014); Aït-Sahalia et al. (2010), already used method of moments with Hawkes processes, but only in a parametric setting.",1 Introduction,[0],[0]
"Our work is the first to consider such an approach for a nonparametric counting processes framework.
",1 Introduction,[0],[0]
"The paper is organized as follows: in Section 2, we provide the background on the integrated kernels and the integrated cumulants of the Hawkes process.",1 Introduction,[0],[0]
"We then introduce the method, investigate its complexity and explain the consistency result we prove.",1 Introduction,[0],[0]
"In Section 3, we estimate the matrix of Hawkes kernels’ integrals for various simulated datasets and for real datasets, namely the MemeTracker database and financial order book data.",1 Introduction,[0],[0]
We then provide in Section 4 the technical details skipped in the previous parts and the proof of our consistency result.,1 Introduction,[0],[0]
Section 5 contains concluding remarks.,1 Introduction,[0],[0]
"In this Section, we provide the background on integrals of Hawkes kernels and integrals of Hawkes cumulants.",2 NPHC: The Non Parametric Hawkes Cumulant method,[0],[0]
We then explain how the NPHC method enables estimatingG.,2 NPHC: The Non Parametric Hawkes Cumulant method,[0],[0]
"From the definition of Hawkes process as a Poisson cluster process, see Jovanović et al. (2015) or Hawkes and Oakes (1974), gij can be simply interpreted as the average total number of events of node i whose direct ancestor is a given event of node j (by direct we mean that interactions mediated by any other intermediate event are not counted).",2.1 Branching structure and Granger causality,[0],[0]
"In that respect,G not only describes the mutual influences between
nodes, but it also quantifies their direct causal relationships.",2.1 Branching structure and Granger causality,[0],[0]
"Namely, introducing the counting function N i←jt that counts the number of events of i whose direct ancestor is an event of j, we know from Bacry et al. (2015) that
E[dN i←jt ]",2.1 Branching structure and Granger causality,[0],[0]
"= g ijE[dN jt ] = g ijΛjdt, (2)
where we introduced Λi as the intensity expectation, namely satisfying E[dN it ] = Λidt.",2.1 Branching structure and Granger causality,[0],[0]
"Note that Λi does not depend on time by stationarity ofN t, which is known to hold under the stability condition ‖G‖ < 1, where ‖G‖ stands for the spectral norm ofG.",2.1 Branching structure and Granger causality,[0],[0]
"In particular, this condition implies the non-singularity of Id −G.
Since the question of a real causality is too complex in general, most econometricians agreed on the simpler definition of Granger causality Granger (1969).",2.1 Branching structure and Granger causality,[0],[0]
Its mathematical formulation is a statistical hypothesis test: X causes Y in the sense of Granger causality if forecasting future values of Y is more successful while taking X past values into account.,2.1 Branching structure and Granger causality,[0],[0]
"In Eichler et al. (2016), it is shown that for N t a multivariate Hawkes process, N jt does not Granger-cause N i t w.r.t N t if and only if φ
ij(u) = 0 for u ∈ R+.",2.1 Branching structure and Granger causality,[0],[0]
"Since the kernels take positive values, the latter condition is equivalent to ∫∞ 0",2.1 Branching structure and Granger causality,[0],[0]
"φ
ij(u)du = 0.",2.1 Branching structure and Granger causality,[0],[0]
"In the following, we’ll refer to learning the kernels’ integrals as uncovering causality since each integral encodes the notion of Granger causality, and is also linked to the number of events directly caused from a node to another node, as described above at Eq.",2.1 Branching structure and Granger causality,[0],[0]
(2).,2.1 Branching structure and Granger causality,[0],[0]
A general formula for the integral of the cumulants of a multivariate Hawkes process is provided in Jovanović et al. (2015).,2.2 Integrated cumulants of the Hawkes process,[0],[0]
"As explained below, for the purpose of our method, we only need to consider cumulants up to the third order.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
Given 1 ≤,2.2 Integrated cumulants of the Hawkes process,[0],[0]
"i, j, k ≤ d, the first three integrated cumulants of the Hawkes process can be defined as follows thanks to stationarity:
Λidt = E(dN it ) (3)
Cijdt = ∫ τ∈R",2.2 Integrated cumulants of the Hawkes process,[0],[0]
( E(dN itdN j t+τ ),2.2 Integrated cumulants of the Hawkes process,[0],[0]
− E(dN it ),2.2 Integrated cumulants of the Hawkes process,[0],[0]
E(dN j t+τ ) ),2.2 Integrated cumulants of the Hawkes process,[0],[0]
"(4)
Kijkdt = ∫ ∫ τ,τ ′∈R2 ( E(dN itdN j t+τdN k t+τ ′) + 2E(dN i t )",2.2 Integrated cumulants of the Hawkes process,[0],[0]
E(dN j t+τ ),2.2 Integrated cumulants of the Hawkes process,[0],[0]
"E(dN k t+τ ′)
",2.2 Integrated cumulants of the Hawkes process,[0],[0]
− E(dN itdN j t+τ ),2.2 Integrated cumulants of the Hawkes process,[0],[0]
E(dN k t+τ ′)− E(dN itdNkt+τ ′)E(dN,2.2 Integrated cumulants of the Hawkes process,[0],[0]
j t+τ ),2.2 Integrated cumulants of the Hawkes process,[0],[0]
− E(dN j t+τdN k t+τ ′)E(dN,2.2 Integrated cumulants of the Hawkes process,[0],[0]
"i t ) ) ,
(5)
",2.2 Integrated cumulants of the Hawkes process,[0],[0]
where Eq.,2.2 Integrated cumulants of the Hawkes process,[0],[0]
"(3) is the mean intensity of the Hawkes process, the second-order cumulant (4) refers to the integrated covariance density matrix and the third-order cumulant (5) measures the skewness ofN t.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"Using the martingale representation from Bacry and Muzy (2016) or the Poisson cluster process representation from Jovanović et al. (2015), one can obtain an explicit relationship between these integrated cumulants and the matrixG.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"If one sets R = (Id −G)−1, (6) straightforward computations (see Section 4) lead to the following identities:
Λi = d∑
m=1
Rimµm (7)
Cij = d∑ m=1",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"ΛmRimRjm (8)
Kijk = d∑ m=1 (RimRjmCkm +RimCjmRkm + CimRjmRkm − 2ΛmRimRjmRkm).",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"(9)
Equations (8) and (9) are proved in Section 4.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
Our strategy is to use a convenient subset of Eqs.,2.2 Integrated cumulants of the Hawkes process,[0],[0]
"(3), (4) and (5) to define M , while we use Eqs.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"(7), (8) and (9) in order to construct the operator that maps a candidate matrix R to the corresponding cumulants M(R).",2.2 Integrated cumulants of the Hawkes process,[0],[0]
By looking for R̂ that minimizes R 7→ ‖M(R),2.2 Integrated cumulants of the Hawkes process,[0],[0]
"− M̂‖2, we obtain, as illustrated below, good recovery of the ground truth matrix G using Equation (6).
",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"The simplest case d = 1 has been considered in Hardiman and Bouchaud (2014), where it is shown that one can choose M = {C11} in order to compute the kernel integral.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
Eq.,2.2 Integrated cumulants of the Hawkes process,[0],[0]
"(8) then reduces to a simple second-order equation that has a unique solution inR (and consequently a uniqueG) that accounts for the stability condition (‖G‖ < 1).
",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"Unfortunately, for d > 1, the choice M = {Cij}1≤i≤j≤d is not sufficient to uniquely determine the kernels integrals.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"In fact, the integrated covariance matrix provides d(d+ 1)/2 independent coefficients, while d2 parameters are needed.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"It is straightforward to show that the remaining d(d− 1)/2 conditions can be encoded in an orthogonal matrixO, reflecting the fact that Eq. (8) is invariant under the change R→ OR, so that the system is under-determined.
",2.2 Integrated cumulants of the Hawkes process,[0],[0]
Our approach relies on using the third order cumulant tensorK,2.2 Integrated cumulants of the Hawkes process,[0],[0]
=,2.2 Integrated cumulants of the Hawkes process,[0],[0]
"[Kijk] which contains (d3 + 3d2 + 2d)/6 > d2 independent coefficients that are sufficient to uniquely fix the matrixG. This can be justified intuitively as follows: while the integrated covariance only contains symmetric information, and is thus unable to provide causal information, the skewness given by the third order cumulant in the estimation procedure can break the symmetry between past and future so as to uniquely fixG. Thus, our algorithm consists of selecting d2 third-order cumulant components, namely M = {Kiij}1≤i,j≤d.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"In particular, we define the estimator ofR as R̂ ∈ argminRL(R), where
L(R) =",2.2 Integrated cumulants of the Hawkes process,[0],[0]
(1− κ)‖Kc(R)− K̂c‖22 + κ‖C(R)−,2.2 Integrated cumulants of the Hawkes process,[0],[0]
"Ĉ‖22, (10)
where ‖ ·‖2 stands for the Frobenius norm,Kc = {Kiij}1≤i,j≤d is the matrix obtained by the contraction of the tensorK to d2 indices,C is the covariance matrix, while K̂c and Ĉ are their respective estimators, see Equations (12), (13) below.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"It is noteworthy that the above mean square error approach can be seen as a peculiar Generalized Method of Moments (GMM), see Hall (2005).",2.2 Integrated cumulants of the Hawkes process,[0],[0]
This framework allows us to determine the optimal weighting matrix involved in the loss function.,2.2 Integrated cumulants of the Hawkes process,[0],[0]
"However, this approach is unusable in practice, since the associated complexity is too high.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"Indeed, since we have d2 parameters, this matrix has d4 coefficients and GMM calls for computing its inverse leading to a O(d6) complexity.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"In this work, we use the coefficient κ to scale the two terms, as
κ = ‖K̂c‖22
‖K̂c‖22 + ‖Ĉ‖22 ,
see Section 4.4 for an explanation about the link between κ and the weighting matrix.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"Finally, the estimator ofG is straightforwardly obtained as
Ĝ = Id − R̂ −1 ,
from the inversion of Eq.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
(6).,2.2 Integrated cumulants of the Hawkes process,[0],[0]
Let us mention an important point: the matrix inversion in the previous formula is not the bottleneck of the algorithm.,2.2 Integrated cumulants of the Hawkes process,[0],[0]
"Indeed, its has a complexity O(d3)",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"that is cheap compared to the computation of the cumulants when n = maxi |Zi| d, which is the typical scaling satisfied in applications.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"Solving the considered problem on a larger scale, say d 103, is an open question, even with state-of-the-art parametric and nonparametric approaches, see for instance Zhou et al. (2013a); Xu et al. (2016); Zhou et al. (2013b); Bacry and Muzy (2016), where the number of components d in experiments is always around 100 or smaller.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"Note that, actually, our approach leads to a much faster algorithm than the considered state-of-the-art baselines, see Tables 1–4 from Section 3 below.",2.2 Integrated cumulants of the Hawkes process,[0],[0]
"In this section we present explicit formulas to estimate the three moment-based quantities listed in the previous section, namely, Λ, C and K. We first assume there exists H > 0 such that the truncation from (−∞,+∞) to [−H,H] of the domain of integration of the quantities appearing in Eqs.",2.3 Estimation of the integrated cumulants,[0],[0]
"(4) and (5), introduces only a small error.",2.3 Estimation of the integrated cumulants,[0],[0]
"In practice, this amounts to neglecting border effects in the covariance density and in the skewness density that is a good approximation if the support of the kernel φij(t) is smaller than H and the spectral norm ‖G‖ satisfies ‖G‖ < 1.",2.3 Estimation of the integrated cumulants,[0],[0]
"In this case, given a realization of a stationary Hawkes process {N t : t ∈",2.3 Estimation of the integrated cumulants,[0],[0]
"[0, T ]}, as shown in Section 4, we can write the estimators of the first three cumulants (3), (4) and (5) as
Λ̂i = 1
T ∑ τ∈Zi 1 = N iT T
(11)
Ĉij",2.3 Estimation of the integrated cumulants,[0],[0]
"= 1
T ∑ τ∈Zi ( N jτ+H −N j τ−H",2.3 Estimation of the integrated cumulants,[0],[0]
"− 2HΛ̂ j )
(12)
K̂ijk = 1
T ∑ τ∈Zi ( N jτ+H −N j τ−H",2.3 Estimation of the integrated cumulants,[0],[0]
− 2HΛ̂ j ) · ( Nkτ+H −Nkτ−H − 2HΛ̂k ),2.3 Estimation of the integrated cumulants,[0],[0]
"− Λ̂ i
T ∑ τ∈Zj ∑ τ ′∈Zk",2.3 Estimation of the integrated cumulants,[0],[0]
(2H − |τ ′,2.3 Estimation of the integrated cumulants,[0],[0]
− τ |)+ + 4H2Λ̂iΛ̂jΛ̂k.,2.3 Estimation of the integrated cumulants,[0],[0]
"(13)
Let us mention the following facts.
",2.3 Estimation of the integrated cumulants,[0],[0]
Bias.,2.3 Estimation of the integrated cumulants,[0],[0]
"While the first cumulant Λ̂i is an unbiased estimator of Λi, the other estimators Ĉij and K̂ijk introduce a bias.",2.3 Estimation of the integrated cumulants,[0],[0]
"However, as we will show, in practice this bias is small and hardly affects numerical estimations (see Section 3).",2.3 Estimation of the integrated cumulants,[0],[0]
"This is confirmed by our theoretical analysis, which proves that if H does not grow too fast compared to T , then these estimated cumulants are consistent estimators of the theoretical cumulants (see Section 2.6).
",2.3 Estimation of the integrated cumulants,[0],[0]
Complexity.,2.3 Estimation of the integrated cumulants,[0],[0]
"The computations of all the estimators of the first, second and third-order cumulants have complexity respectively O(nd), O(nd2) and O(nd3), where n = maxi |Zi|.",2.3 Estimation of the integrated cumulants,[0],[0]
"However, our algorithm requires a lot less than that: it computes only d2 third-order terms, of the form K̂iij , leaving us with only O(nd2) operations to perform.
Symmetry.",2.3 Estimation of the integrated cumulants,[0],[0]
"While the values of Λi, Cij and Kijk are symmetric under permutation of the indices, their estimators are generally not symmetric.",2.3 Estimation of the integrated cumulants,[0],[0]
We have thus chosen to symmetrize the estimators by averaging their values over permutations of the indices.,2.3 Estimation of the integrated cumulants,[0],[0]
"Worst case is for the estimator of Kc, which involves only an extra factor of 2 in the complexity.",2.3 Estimation of the integrated cumulants,[0],[0]
The objective to minimize in Equation (10) is non-convex.,2.4 The NPHC algorithm,[0],[0]
"More precisely, the loss function is a polynomial ofR of degree 6.",2.4 The NPHC algorithm,[0],[0]
"However, the expectations of cumulants Λ andC defined in Eq.",2.4 The NPHC algorithm,[0],[0]
(4) and (5) that appear in the definition of L(R) are unknown and should be replaced with Λ̂ and Ĉ.,2.4 The NPHC algorithm,[0],[0]
"We denote L̃(R) the objective function, where the expectations of cumulants Λi and Cij have been replaced with their estimators in the right-hand side of Eqs.",2.4 The NPHC algorithm,[0],[0]
"(8) and (9):
L̃(R) =",2.4 The NPHC algorithm,[0],[0]
"(1− κ)‖R 2Ĉ >
+ 2[R (Ĉ −RL̂)]R>",2.4 The NPHC algorithm,[0],[0]
"− K̂c‖22 + κ‖RL̂R> − Ĉ‖22 (14)
As explained in Choromanska et al. (2015), the loss function of a typical multilayer neural network with simple nonlinearities can be expressed as a polynomial function of the weights in the network,
whose degree is the number of layers.",2.4 The NPHC algorithm,[0],[0]
"Since the loss function of NPHC writes as a polynomial of degree 6, we expect good results using optimization methods designed to train deep multilayer neural networks.",2.4 The NPHC algorithm,[0],[0]
"We used the AdaGrad from Duchi et al. (2011), a variant of the Stochastic Gradient Descent with adaptive learning rates.",2.4 The NPHC algorithm,[0],[0]
"AdaGrad scales the learning rates coordinate-wise using the online variance of the previous gradients, in order to incorporate second-order information during training.",2.4 The NPHC algorithm,[0],[0]
"The NPHC method is summarized schematically in Algorithm 1.
",2.4 The NPHC algorithm,[0],[0]
"Algorithm 1 Non Parametric Hawkes Cumulant method Input: N t Output: Ĝ
1: Estimate Λ̂i, Ĉij , K̂iij from Eqs.",2.4 The NPHC algorithm,[0],[0]
"(11, 12, 13) 2: Design L̃(R) using the computed estimators.",2.4 The NPHC algorithm,[0],[0]
"3: Minimize numerically L̃(R) so as to obtain R̂ 4: Return Ĝ = Id − R̂ −1 .
",2.4 The NPHC algorithm,[0],[0]
"Our problem being non-convex, the choice of the starting point has a major effect on the convergence.",2.4 The NPHC algorithm,[0],[0]
"Here, the key is to notice that the matrices R that match Equation (8) writes C1/2OL−1/2, with L = diag(Λ) andO an orthogonal matrix.",2.4 The NPHC algorithm,[0],[0]
Our starting point is then simply chosen by settingO =,2.4 The NPHC algorithm,[0],[0]
"Id in the previous formula, leading to nice convergence results.",2.4 The NPHC algorithm,[0],[0]
"Even though our main concern is to retrieve the matrixG, let us notice we can also obtain an estimation of the baseline intensities’ from Eq.",2.4 The NPHC algorithm,[0],[0]
"(3), which leads to µ̂ = R̂ −1 Λ̂.",2.4 The NPHC algorithm,[0],[0]
"An efficient implementation of this algorithm with TensorFlow, see Abadi et al. (2016), is available on GitHub: https://github.com/achab/nphc.",2.4 The NPHC algorithm,[0],[0]
"Compared with existing state-of-the-art methods to estimate the kernel functions, e.g., the ordinary differential equations-based (ODE) algorithm in Zhou et al. (2013a), the Granger Causality-based algorithm in Xu et al. (2016), the ADM4 algorithm in Zhou et al. (2013b), and the Wiener-Hopf-based algorithm in Bacry and Muzy (2016), our method has a very competitive complexity.",2.5 Complexity of the algorithm,[0],[0]
"This can be understood by the fact that those methods estimate the kernel functions, while in NPHC we only estimate their integrals.",2.5 Complexity of the algorithm,[0],[0]
"The ODE-based algorithm is an EM algorithm that parametrizes the kernel function with M basis functions, each being discretized to L points.",2.5 Complexity of the algorithm,[0],[0]
The basis functions are updated after solving M Euler-Lagrange equations.,2.5 Complexity of the algorithm,[0],[0]
If n denotes the maximum number of events per component (i.e. n = max1≤i≤d |Zi|) then the complexity of one iteration of the algorithm isO(Mn3d2 +ML(nd+n2)).,2.5 Complexity of the algorithm,[0],[0]
"The Granger Causality-based algorithm is similar to the previous one, without the update of the basis functions, that are Gaussian kernels.",2.5 Complexity of the algorithm,[0],[0]
The complexity per iteration is O(Mn3d2).,2.5 Complexity of the algorithm,[0],[0]
"The algorithm ADM4 is similar to the two algorithms above, as EM algorithm as well, with only one exponential kernel as basis function.",2.5 Complexity of the algorithm,[0],[0]
The complexity per iteration is then O(n3d2).,2.5 Complexity of the algorithm,[0],[0]
"The Wiener-Hopf-based algorithm is not iterative, on the contrary to the previous ones.",2.5 Complexity of the algorithm,[0],[0]
"It first computes the empirical conditional laws on many points, and then invert the Wiener-Hopf system, leading to a O(nd2L+ d4L3) computation.",2.5 Complexity of the algorithm,[0],[0]
"Similarly, our method first computes the integrated cumulants, then minimize the objective function with Niter iterations, and invert the resulting matrix R̂ to obtain Ĝ.",2.5 Complexity of the algorithm,[0],[0]
"In the end, the complexity of the NPHC method is O(nd2 +Niterd3).",2.5 Complexity of the algorithm,[0],[0]
"According to this analysis, summarized in Table 1 below, one can see that in the regime n d, the NPHC method outperforms all the other ones.",2.5 Complexity of the algorithm,[0],[0]
The NPHC method can be phrased using the framework of the Generalized Method of Moments (GMM).,2.6 Theoretical guarantee: consistency,[0],[0]
GMM is a generic method for estimating parameters in statistical models.,2.6 Theoretical guarantee: consistency,[0],[0]
"In order to apply GMM,
we have to find a vector-valued function g(X, θ) of the data, where X is distributed with respect to a distribution Pθ0 , which satisfies the moment condition: E[g(X, θ)]",2.6 Theoretical guarantee: consistency,[0],[0]
"= 0 if and only if θ = θ0, where θ0 is the “ground truth” value of the parameter.",2.6 Theoretical guarantee: consistency,[0],[0]
"Based on i.i.d. observed copies x1, . . .",2.6 Theoretical guarantee: consistency,[0],[0]
", xn of X , the GMM method minimizes the norm of the empirical mean over n samples, ‖",2.6 Theoretical guarantee: consistency,[0],[0]
"1n ∑n i=1 g(xi, θ)‖, as a function of θ, to obtain an estimate of θ0.",2.6 Theoretical guarantee: consistency,[0],[0]
"In the theoretical analysis of NPHC, we use ideas from the consistency proof of the GMM, but the proof actually relies on very different arguments.",2.6 Theoretical guarantee: consistency,[0],[0]
"Indeed, the integrated cumulants estimators used in NPHC are not unbiased, as the theory of GMM requires, but asymptotically unbiased.",2.6 Theoretical guarantee: consistency,[0],[0]
"Moreover, the setting considered here, where data consists of a single realization {N t} of a Hawkes process strongly departs from the standard i.i.d setting.",2.6 Theoretical guarantee: consistency,[0],[0]
"Our approach is therefore based on the GMM idea but the proof is actually not using the theory of GMM.
",2.6 Theoretical guarantee: consistency,[0],[0]
"In the following, we use the subscript T to refer to quantities that only depend on the process (Nt) in the interval",2.6 Theoretical guarantee: consistency,[0],[0]
"[0, T ] (e.g., the truncation term HT , the estimated integrated covariance ĈT or the estimated kernel norm matrix ĜT ).",2.6 Theoretical guarantee: consistency,[0],[0]
"In the next equation, stands for the Hadamard product and 2 stands for the entrywise square of a matrix.",2.6 Theoretical guarantee: consistency,[0],[0]
We denoteG0,2.6 Theoretical guarantee: consistency,[0],[0]
"= Id −R−10 the true value ofG, and the R2d×d valued vector functions
g0(R) =
[ C −RLR> Kc −R 2C>",2.6 Theoretical guarantee: consistency,[0],[0]
"− 2[R (C −RL)]R> ]
ĝT (R) =
[ ĈT −RL̂TR>
K̂cT −R 2Ĉ > T",2.6 Theoretical guarantee: consistency,[0],[0]
− 2[R (ĈT −RL̂T ),2.6 Theoretical guarantee: consistency,[0],[0]
"]R> .
]
Using these notations, L̃T (R) can be seen as the weighted squared Frobenius norm of ĝT (R).",2.6 Theoretical guarantee: consistency,[0],[0]
"Moreover, when T → +∞, one has ĝT (R) P→ g0(R) under the conditions of the following theorem, where P→ stands for convergence in probability.
",2.6 Theoretical guarantee: consistency,[0],[0]
Theorem 2.1 (Consistency of NPHC).,2.6 Theoretical guarantee: consistency,[0],[0]
"Suppose that (Nt) is observed on R+ and assume that
1. g0(R) = 0",2.6 Theoretical guarantee: consistency,[0],[0]
"if and only ifR = R0;
2.",2.6 Theoretical guarantee: consistency,[0],[0]
"R ∈ Θ, where Θ is a compact set;
3.",2.6 Theoretical guarantee: consistency,[0],[0]
"the spectral radius of the kernel norm matrix satisfies ‖G0‖ < 1;
4.",2.6 Theoretical guarantee: consistency,[0],[0]
HT →∞ and H2T /T,2.6 Theoretical guarantee: consistency,[0],[0]
"→ 0.
Then
ĜT = Id − (
arg min R∈Θ L̃T (R)
)−1",2.6 Theoretical guarantee: consistency,[0],[0]
"P→ G0.
",2.6 Theoretical guarantee: consistency,[0],[0]
The proof of the Theorem is given in Section 4.5 below.,2.6 Theoretical guarantee: consistency,[0],[0]
"Assumption 3 is mandatory for stability of the Hawkes process, and Assumptions 3 and 4 are sufficient to prove that the estimators of the integrated cumulants defined in Equations (11), (12) and (13) are asymptotically consistent.",2.6 Theoretical guarantee: consistency,[0],[0]
Assumption 2 is a very mild standard technical assumption allowing to prove consistency for estimators based on moments.,2.6 Theoretical guarantee: consistency,[0],[0]
"Assumption 1 is a standard asymptotic moment condition, that allows to identity parameters from the integrated cumulants.",2.6 Theoretical guarantee: consistency,[0],[0]
"In this Section, we provide a comparison of NPHC with the state-of-the art, on simulated datasets with different kernel shapes, the MemeTracker dataset (social networks) and the order book dynamics dataset (finance).
",3 Numerical Experiments,[0],[0]
Simulated datasets.,3 Numerical Experiments,[0],[0]
"We simulated several datasets with Ogata’s Thinning algorithm Ogata (1981) using the open-source library tick1, each corresponding to a shape of kernel: rectangular, exponential or power law kernel, see Figure 1 below.
",3 Numerical Experiments,[0],[0]
"The integral of each kernel on its support equals α, 1/β can be regarded as a characteristic time-scale and γ is the scaling exponent for the power law distribution and a delay parameter for the rectangular one.",3 Numerical Experiments,[0],[0]
"We consider a non-symmetric block-matrix G to show that our method can effectively uncover causality between the nodes, see Figure 3.",3 Numerical Experiments,[0],[0]
"The matrix G has constant entries α on the three blocks - α = gij = 1/6 for dimension 10 and α = gij = 1/10 for dimension 100 -, and zero outside.",3 Numerical Experiments,[0],[0]
The two other parameters’ values are the same for dimensions 10 and 100.,3 Numerical Experiments,[0],[0]
"The parameter γ is set to 1/2 on the three blocks as well, but we set three very different β0, β1 and β2 from one block to the other, with ratio βi+1/βi = 10 and β0 = 0.1.",3 Numerical Experiments,[0],[0]
The number of events is roughly equal to 105 on average over the nodes.,3 Numerical Experiments,[0],[0]
"We ran the algorithm on three simulated datasets: a 10-dimensional process with rectangular kernels named Rect10, a 10-dimensional process with power law kernels named PLaw10 and a 100-dimensional process with exponential kernels named Exp100.
MemeTracker dataset.",3 Numerical Experiments,[0],[0]
We use events of the most active sites from the MemeTracker dataset2.,3 Numerical Experiments,[0],[0]
"This dataset contains the publication times of articles in many websites/blogs from August 2008 to April 2009, and hyperlinks between posts.",3 Numerical Experiments,[0],[0]
"We extract the top 100 media sites with the largest number of documents, with about 7 million of events.",3 Numerical Experiments,[0],[0]
"We use the links to trace the flow of information and establish an estimated ground truth for the matrixG. Indeed, when an hyperlink j appears in a post in website i, the link j can be regarded as a direct ancestor of the event.",3 Numerical Experiments,[0],[0]
"Then, Eq. (2) shows gij can be estimated by N i←jT /N",3 Numerical Experiments,[0],[0]
j T =,3 Numerical Experiments,[0],[0]
"#{links j → i}/N j T .
",3 Numerical Experiments,[0],[0]
"1https://github.com/X-DataInitiative/tick 2https://www.memetracker.org/data.html
Order book dynamics.",3 Numerical Experiments,[0],[0]
"We apply our method to financial data, in order to understand the self and crossinfluencing dynamics of all event types in an order book.",3 Numerical Experiments,[0],[0]
"An order book is a list of buy and sell orders for a specific financial instrument, the list being updated in real-time throughout the day.",3 Numerical Experiments,[0],[0]
"This model has first been introduced in Bacry et al. (2016), and models the order book via the following 8-dimensional point process:",3 Numerical Experiments,[0],[0]
"Nt = (P (a) t , P (b) t , T (a) t , T (b) t , L (a) t , L (b) t , C (a) t , C (b) t ), where P
(a) (resp.",3 Numerical Experiments,[0],[0]
"P (b)) counts the number of upward (resp. downward) price moves, T (a) (resp.",3 Numerical Experiments,[0],[0]
T (b)) counts the number of market orders at the ask3 (resp.,3 Numerical Experiments,[0],[0]
"at the bid) that do not move the price, L(a) (resp. L(b)) counts the number of limit orders at the ask4 (resp.",3 Numerical Experiments,[0],[0]
"at the bid) that do not move the price, and C(a) (resp. C(b)) counts the number of cancel orders at the ask5 (resp.",3 Numerical Experiments,[0],[0]
at the bid) that do not move the price.,3 Numerical Experiments,[0],[0]
"The financial data has been provided by QuantHouse EUROPE/ASIA, and consists of DAX future contracts between 01/01/2014 and 03/01/2014.
Baselines.",3 Numerical Experiments,[0],[0]
"We compare NPHC to state-of-the art baselines: the ODE-based algorithm (ODE) by Zhou et al. (2013a), the Granger Causality-based algorithm (GC) by Xu et al. (2016), the ADM4 algorithm (ADM4) by Zhou et al. (2013b), and the Wiener-Hopf-based algorithm (WH) by Bacry and Muzy (2016).
",3 Numerical Experiments,[0],[0]
Metrics.,3 Numerical Experiments,[0],[0]
"We evaluate the performance of the proposed methods using the computing time, the Relative Error
RelErr(A,B) = 1
d2 ∑ i,j |aij − bij",3 Numerical Experiments,[0],[0]
| |aij | 1{aij,3 Numerical Experiments,[0],[0]
"6=0} + |bij |1{aij=0}
and the Mean Kendall Rank Correlation
MRankCorr(A,B) = 1
d d∑ i=1",3 Numerical Experiments,[0],[0]
"RankCorr([ai•], [bi•]),
where RankCorr(x, y) = 2d(d−1)(Nconcordant(x, y) −Ndiscordant(x, y)) with Nconcordant(x, y)",3 Numerical Experiments,[0],[0]
"the number of pairs (i, j) satisfying xi > xj and yi > yj or xi < xj and yi < yj and Ndiscordant(x, y) the number of pairs (i, j) for which the same condition is not satisfied.
",3 Numerical Experiments,[0],[0]
"Note that RankCorr score is a value between −1 and 1, representing rank matching, but can take smaller values (in absolute value) if the entries of the vectors are not distinct.
3i.e.",3 Numerical Experiments,[0],[0]
buy orders that are executed and removed from the list 4i.e.,3 Numerical Experiments,[0],[0]
buy orders added to the list 5i.e.,3 Numerical Experiments,[0],[0]
"the number of times a limit order at the ask is canceled: in our dataset, almost 95% of limit orders are canceled before
execution.
",3 Numerical Experiments,[0],[0]
Discussion.,3 Numerical Experiments,[0],[0]
"We perform the ADM4 estimation, with exponential kernel, by giving the exact value β = β0 of one block.",3 Numerical Experiments,[0],[0]
"Let us stress that this helps a lot this baseline, in comparison to NPHC where nothing is specified on the shape of the kernel functions.",3 Numerical Experiments,[0],[0]
"We used M = 10 basis functions for both ODE and GC algorithms, and L = 50 quadrature points for WH.",3 Numerical Experiments,[0],[0]
"We did not run WH on the 100-dimensional datasets, for computing time reasons, because its complexity scales with d4.",3 Numerical Experiments,[0],[0]
"We ran multi-processed versions of the baseline methods on 56 cores, to decrease the computing time.
",3 Numerical Experiments,[0],[0]
"Our method consistently performs better than all baselines, on the three synthetic datasets, on MemeTracker and on the financial dataset, both in terms of Kendall rank correlation and estimation error.",3 Numerical Experiments,[0],[0]
"Moreover, we observe that our algorithm is roughly 50 times faster than all the considered baselines.
",3 Numerical Experiments,[0],[0]
"On Rect10, PLaw10 and Exp100 our method gives very impressive results, despite the fact that it does not uses any prior shape on the kernel functions, while for instance the ADM4 baseline do.",3 Numerical Experiments,[0],[0]
"On Figure 3, we observe that the matrix Ĝ estimated with ADM4 recovers well the block for which β = β0, i.e. the value we gave to the method, but does not perform well on the two other blocks, while the matrix Ĝ estimated with NPHC approximately reaches the true value for each of the three blocks.",3 Numerical Experiments,[0],[0]
"On these simulated datasets, NPHC obtains a comparable or slightly better Kendall rank correlation, but improves a lot the relative error.
",3 Numerical Experiments,[0],[0]
"On MemeTracker, the baseline methods obtain a high relative error between 9% and 19% while our method achieves a relative error of 7% which is a strong improvement.",3 Numerical Experiments,[0],[0]
"Moreover, NPHC reaches a much better Kendall rank correlation, which proves that it leads to a much better recovery of the relative order of estimated influences than all the baselines.",3 Numerical Experiments,[0],[0]
"Indeed, it has been shown in Zhou et al. (2013a) that kernels of MemeTracker data are not exponential, nor power law.",3 Numerical Experiments,[0],[0]
"This partly explains why our approach behaves
better.",3 Numerical Experiments,[0],[0]
"On the financial data, the estimated kernel norm matrix obtained via NPHC, see Figure 3, gave some interpretable results (see also Bacry et al. (2016)):
1.",3 Numerical Experiments,[0],[0]
Any 2× 2 sub,3 Numerical Experiments,[0],[0]
-,3 Numerical Experiments,[0],[0]
"matrix with same kind of inputs (i.e. Prices changes, Trades, Limits or Cancels) is symmetric.",3 Numerical Experiments,[0],[0]
"This shows empirically that ask and bid have symmetric roles.
2.",3 Numerical Experiments,[0],[0]
"The prices are mostly cross-excited, which means that a price increase is very likely to be followed by a price decrease, and conversely.",3 Numerical Experiments,[0],[0]
"This is consistent with the wavy prices we observe on financial markets.
",3 Numerical Experiments,[0],[0]
3.,3 Numerical Experiments,[0],[0]
"The market, limit and cancel orders are strongly self-excited.",3 Numerical Experiments,[0],[0]
"This can be explained by the persistence of order flows, and by the splitting of meta-orders into sequences of smaller orders.",3 Numerical Experiments,[0],[0]
"Moreover, we observe that orders impact the price without changing it.",3 Numerical Experiments,[0],[0]
"For example, the increase of cancel orders at the bid causes downward price moves.",3 Numerical Experiments,[0],[0]
"We show in this section how to obtain the equations stated above, the estimators of the integrated cumulants and the scaling coefficient κ that appears in the objective function.",4 Technical details,[0],[0]
"We then prove the theorem of the paper.
",4 Technical details,[0],[0]
"4.1 Proof of Equation (8)
We denote ν(z) the matrix
νij(z) = Lz ( t→ E(dN iudN j u+t)
dudt − ΛiΛj
) ,
where Lz(f) is the Laplace transform of f , and",4 Technical details,[0],[0]
"ψt = ∑ n≥1 φ (?n) t , where φ (?n)",4 Technical details,[0],[0]
"t refers to the n
th autoconvolution of φt.",4 Technical details,[0],[0]
"Then we use the characterization of second-order statistics, first formulated in Hawkes (1971) and fully generalized in Bacry and Muzy (2016),
ν(z) =",4 Technical details,[0],[0]
(Id + L−z(Ψ))L(Id + Lz(Ψ)),4 Technical details,[0],[0]
">,
where Lij = Λiδij with δij the Kronecker symbol.",4 Technical details,[0],[0]
Since Id +Lz(Ψ) =,4 Technical details,[0],[0]
"(Id −Lz(Φ))−1, taking z = 0 in the previous equation gives
ν(0) =",4 Technical details,[0],[0]
"(Id −G)−1L(Id −G>)−1, C = RLR>,
which gives us the result since the entry (i, j) of the last equation gives Cij = ∑
m Λ mRimRjm.
4.2 Proof of Equation (9)
",4 Technical details,[0],[0]
"We start from Jovanović et al. (2015), cf. Eqs.",4 Technical details,[0],[0]
"(48) to (51), and group some terms:
Kijk = ∑ m ΛmRimRjmRkm
+ ∑ m RimRjm ∑ n ΛnRknL0(ψmn)
+ ∑ m RimRkm ∑ n ΛnRjnL0(ψmn)
+ ∑ m RjmRkm ∑ n ΛnRinL0(ψmn).
",4 Technical details,[0],[0]
Using the relations L0(ψmn) =,4 Technical details,[0],[0]
"Rmn − δmn and Cij = ∑ m Λ mRimRjm, proves Equation (9).",4 Technical details,[0],[0]
For H > 0 let us denote ∆HN it = N,4.3 Integrated cumulants estimators,[0],[0]
i t+H −N it−H .,4.3 Integrated cumulants estimators,[0],[0]
"Let us first remark that, if one restricts the integration domain to (−H,H) in Eqs.",4.3 Integrated cumulants estimators,[0],[0]
"(4) and (5), one gets by permuting integrals and expectations:
Λidt = E(dN it )",4.3 Integrated cumulants estimators,[0],[0]
Cijdt = E ( dN it (∆HN j t − 2HΛj) ),4.3 Integrated cumulants estimators,[0],[0]
"Kijkdt = E ( dN it (∆HN j t − 2HΛj)(∆HNkt − 2HΛk)
)",4.3 Integrated cumulants estimators,[0],[0]
"− dtΛiE ( (∆HN j t − 2HΛj)(∆HNkt − 2HΛk) ) .
",4.3 Integrated cumulants estimators,[0],[0]
"The estimators (11) and (12) are then naturally obtained by replacing the expectations by their empirical counterparts, notably
E(dN itf(t))",4.3 Integrated cumulants estimators,[0],[0]
"dt → 1 T ∑ τ∈Zi f(τ).
",4.3 Integrated cumulants estimators,[0],[0]
"For the estimator (13), we shall also notice that
E((∆HN jt",4.3 Integrated cumulants estimators,[0],[0]
"− 2HΛj)(∆HNkt − 2HΛk))
",4.3 Integrated cumulants estimators,[0],[0]
"= ∫ ∫ 1[−H,H](t)1[−H,H](t ′)Cjkt−t′dtdt ′
= ∫",4.3 Integrated cumulants estimators,[0],[0]
"(2H − |t|)+Cjkt dt.
",4.3 Integrated cumulants estimators,[0],[0]
We estimate the last integral with the remark above.,4.3 Integrated cumulants estimators,[0],[0]
"Following the theory of GMM, we denote m(X, θ) a function of the data, where X is distributed with respect to a distribution Pθ0 , which satisfies the moment conditions g(θ) = E[m(X, θ)]",4.4 Choice of the scaling coefficient κ,[0],[0]
"= 0 if and only if θ = θ0, the parameter θ0 being the ground truth.",4.4 Choice of the scaling coefficient κ,[0],[0]
"For x1, . . .",4.4 Choice of the scaling coefficient κ,[0],[0]
", xN observed copies of X , we denote ĝi(θ) = m(xi, θ), the usual choice of weighting matrix is ŴN (θ) = 1N ∑N i=1 ĝi(θ)ĝi(θ)
",4.4 Choice of the scaling coefficient κ,[0],[0]
">, and the objective to minimize is then(
1
N N∑ i=1 ĝi(θ)
)",4.4 Choice of the scaling coefficient κ,[0],[0]
"( ŴN (θ1) )−1( 1 N N∑ i=1 ĝi(θ) ) , (15)
where θ1 is a constant vector.",4.4 Choice of the scaling coefficient κ,[0],[0]
"Instead of computing the inverse weighting matrix, we rather use its projection on {αId : α ∈ R}.",4.4 Choice of the scaling coefficient κ,[0],[0]
It can be shown that the projection choses α as the mean eigenvalue of ŴN (θ1).,4.4 Choice of the scaling coefficient κ,[0],[0]
"We can easily compute the sum of its eigenvalues:
Tr(ŴN (θ1))",4.4 Choice of the scaling coefficient κ,[0],[0]
"= 1
N N∑ i=1 Tr(ĝi(θ1)ĝi(θ1)>)",4.4 Choice of the scaling coefficient κ,[0],[0]
= 1 N N∑ i=1,4.4 Choice of the scaling coefficient κ,[0],[0]
Tr(ĝi(θ1)>ĝi(θ1)),4.4 Choice of the scaling coefficient κ,[0],[0]
= 1 N N∑ i=1,4.4 Choice of the scaling coefficient κ,[0],[0]
"||ĝi(θ1)||22.
",4.4 Choice of the scaling coefficient κ,[0],[0]
"In our case, ĝ(R) =",4.4 Choice of the scaling coefficient κ,[0],[0]
"[ vec[K̂c −Kc(R)], vec[Ĉ −C(R)]",4.4 Choice of the scaling coefficient κ,[0],[0]
]> ∈ R2d2 .,4.4 Choice of the scaling coefficient κ,[0],[0]
"Considering a block-wise
weighting matrix, one block for K̂c−Kc(R) and the other for Ĉ−C(R), the sum of the eigenvalues of the first block becomes ‖K̂c −Kc(R)‖22, and ‖Ĉ −C(R)‖22 for the second.",4.4 Choice of the scaling coefficient κ,[0],[0]
We compute the previous terms withR1 = 0.,4.4 Choice of the scaling coefficient κ,[0],[0]
"All together, the objective function to minimize is
1
‖K̂c‖22 ‖Kc(R)− K̂c‖22",4.4 Choice of the scaling coefficient κ,[0],[0]
"+
1
‖Ĉ‖22 ‖C(R)− Ĉ‖22. (16)
Dividing this function by ( 1/‖K̂c‖22 + 1/‖Ĉ‖22 )−1
, and setting κ = ‖K̂c‖22/(‖K̂c‖22 + ‖Ĉ‖22), we obtaind the loss function given in Equation (10).",4.4 Choice of the scaling coefficient κ,[0],[0]
"The main difference with the usual Generalized Method of Moments, see Hansen (1982), relies in the relaxation of the moment conditions, since we have E[ĝT (θ0)]",4.5 Proof of the Theorem,[0],[0]
= mT 6= 0.,4.5 Proof of the Theorem,[0],[0]
"We adapt the proof of consistency given in Newey and McFadden (1994).
",4.5 Proof of the Theorem,[0],[0]
"We can relate the integral of the Hawkes process’s kernels to the integrals of the cumulant densities, from Jovanović et al. (2015).",4.5 Proof of the Theorem,[0],[0]
"Our cumulant matching method would fall into the usual GMM framework if we could estimate - without bias - the integral of the covariance on R, and the integral of the skewness on R2.",4.5 Proof of the Theorem,[0],[0]
"Unfortunately, we can’t do that easily.",4.5 Proof of the Theorem,[0],[0]
"We can however estimate without bias ∫ fTt C ij t dt
and ∫ fTt K ijk t dt with f
T a compact supported function on [−HT , HT ] that weakly converges to 1, with HT −→ ∞. In most cases we will take fTt = 1[−HT ,HT ](t).",4.5 Proof of the Theorem,[0],[0]
"Denoting Ĉ
ij,(T ) the estimator of∫ fTt C ij t dt, the term |E[Ĉij,(T )]−Cij | = | ∫ fTt C ij t dt−Cij",4.5 Proof of the Theorem,[0],[0]
| can be considered a proxy to the distance to the classical GMM.,4.5 Proof of the Theorem,[0],[0]
"This distance has to go to zero to make the rest of GMM’s proof work: the estimator Ĉij,(T ) is then asymptotically unbiased towards Cij when T goes to infinity.",4.5 Proof of the Theorem,[0],[0]
"We observe the multivariate point process (N t) on R+, with Zi the events of the ith component.",4.5.1 Notations,[0],[0]
We will often write covariance / skewness instead of integrated covariance / skewness.,4.5.1 Notations,[0],[0]
"In the rest of the document, we use the following notations.",4.5.1 Notations,[0],[0]
Hawkes kernels’ integrals Gtrue =,4.5.1 Notations,[0],[0]
∫ Φtdt = ( ∫ φijt dt)ij =,4.5.1 Notations,[0],[0]
"Id − (Rtrue)−1
Theoretical mean matrix L = diag(Λ1, . . .",4.5.1 Notations,[0],[0]
",Λd)
Theoretical covariance C = RtrueL(Rtrue)>
",4.5.1 Notations,[0],[0]
Theoretical skewness Kc = (Kiij)ij = (Rtrue) 2 C> + 2[Rtrue (C −RtrueL)](Rtrue)>,4.5.1 Notations,[0],[0]
Filtering function fT ≥ 0,4.5.1 Notations,[0],[0]
supp(fT ) ⊂,4.5.1 Notations,[0],[0]
"[−HT , HT ] F T = ∫ fTs ds f̃ T t = f T −t
Events sets Zi,T,1 = Zi ∩",4.5.1 Notations,[0],[0]
"[HT , T +HT ] Zj,T,2 = Zj ∩ [0, T + 2HT ]
Estimators of the mean Λ̂i = N iT+HT −N iHT T Λ̃ j = NjT+2HT",4.5.1 Notations,[0],[0]
"T+2HT
Estimator of the covariance Ĉij,(T )",4.5.1 Notations,[0],[0]
"= 1T ∑ τ∈Zi,T,1 (∑ τ ′∈Zj,T,2 fτ ′−τ − Λ̃jF T )
Estimator of the skewness6
K̂ijk,(T )",4.5.1 Notations,[0],[0]
"= 1
T ∑ τ∈Zi,T,1  ∑ τ ′∈Zj,",4.5.1 Notations,[0],[0]
"T,2 fτ ′−τ − Λ̃jF T  ∑ τ ′′∈Zk,T,2 fτ ′−τ − Λ̃kF T  ",4.5.1 Notations,[0],[0]
"− Λ̂ i
T + 2HT ∑ τ ′∈Zj,T,2  ∑ τ ′′∈Zk,T,2 (fT ?",4.5.1 Notations,[0],[0]
f̃T )τ ′−τ ′′,4.5.1 Notations,[0],[0]
"− Λ̃k(F T )2 
6When fTt = 1[−HT ,HT ](t), we remind that (f T ?",4.5.1 Notations,[0],[0]
f̃T )t = (2HT − |t|)+.,4.5.1 Notations,[0],[0]
"This leads to the estimator we showed in the
article.
",4.5.1 Notations,[0],[0]
"GMM related notations
θ = R and θ0 = Rtrue g0(θ) = vec [ C −RLR>
Kc −R 2C>",4.5.1 Notations,[0],[0]
"− 2[R (C −RL)]R>
] ∈ R2d2
ĝT (θ) = vec
[ Ĉ (T ) −RL̂R",4.5.1 Notations,[0],[0]
">
K̂c (T ) −R 2(Ĉ (T ) )",4.5.1 Notations,[0],[0]
>,4.5.1 Notations,[0],[0]
"− 2[R (Ĉ (T ) −RL̂)]R>
] ∈",4.5.1 Notations,[0],[0]
"R2d2
Q0(θ) = g0(θ) >Wg0(θ)",4.5.1 Notations,[0],[0]
Q̂T (θ) = ĝT (θ) >ŴT ĝT (θ),4.5.1 Notations,[0],[0]
"First, let’s remind a useful theorem for consistency in GMM from Newey and McFadden (1994).
",4.5.2 Consistency,[0],[0]
Theorem 4.1.,4.5.2 Consistency,[0],[0]
"If there is a function Q0(θ) such that (i) Q0(θ) is uniquely maximized at θ0; (ii) Θ is compact; (iii) Q0(θ) is continuous; (iv) Q̂T (θ) converges uniformly in probability to Q0(θ), then θ̂T = arg max Q̂T (θ) P−→ θ0.
",4.5.2 Consistency,[0],[0]
"We can now prove the consistency of our estimator.
",4.5.2 Consistency,[0],[0]
Theorem 4.2.,4.5.2 Consistency,[0],[0]
"Suppose that (Nt) is observed on R+, ŴT P−→W , and
1.",4.5.2 Consistency,[0],[0]
W is positive semi-definite and Wg0(θ),4.5.2 Consistency,[0],[0]
= 0,4.5.2 Consistency,[0],[0]
"if and only if θ = θ0,
2. θ ∈ Θ, which is compact,
3.",4.5.2 Consistency,[0],[0]
the spectral radius of the kernel norm matrix satisfies ||Φ||∗,4.5.2 Consistency,[0],[0]
"< 1, 4.",4.5.2 Consistency,[0],[0]
"∀i, j, k ∈",4.5.2 Consistency,[0],[0]
"[d], ∫ fTu C ij u du→ ∫",4.5.2 Consistency,[0],[0]
"Ciju du and ∫ fTu f T v K ijk u,vdudv → ∫ Kijku,vdudv,
5.",4.5.2 Consistency,[0],[0]
"(F T )2/T P−→ 0 and ||f ||∞ = O(1).
",4.5.2 Consistency,[0],[0]
"Then
θ̂T P−→ θ0.
",4.5.2 Consistency,[0],[0]
Remark 1.,4.5.2 Consistency,[0],[0]
"In practice, we use a constant sequence of weighting matrices: ŴT = Id.
Proof.",4.5.2 Consistency,[0],[0]
Proceed by verifying the hypotheses of Theorem 2.1 from Newey and McFadden (1994).,4.5.2 Consistency,[0],[0]
Condition 2.1(i) follows by (i) and by Q0(θ) =,4.5.2 Consistency,[0],[0]
[W 1/2g0(θ)]>[W 1/2g0(θ)],4.5.2 Consistency,[0],[0]
> 0,4.5.2 Consistency,[0],[0]
= Q0(θ0).,4.5.2 Consistency,[0],[0]
"Indeed, there exists a neighborhood N of θ0 such that θ ∈ N\{θ0} and g0(θ) 6= 0",4.5.2 Consistency,[0],[0]
since g0(θ) is a polynom.,4.5.2 Consistency,[0],[0]
Condition 2.1(ii) follows by (ii).,4.5.2 Consistency,[0],[0]
Condition 2.1(iii) is satisfied since Q0(θ) is a polynom.,4.5.2 Consistency,[0],[0]
Condition 2.1(iv) is harder to prove.,4.5.2 Consistency,[0],[0]
"First, since ĝT (θ) is a polynom of θ, we prove easily that E[supθ∈Θ |ĝT (θ)|] <∞. Then, by Θ compact, g0(θ) is bounded on Θ, and by the triangle and Cauchy-Schwarz inequalities,∣∣Q̂T (θ)−Q0(θ)∣∣
≤ ∣∣(ĝT (θ)− g0(θ))>ŴT (ĝT (θ)− g0(θ))∣∣
+ ∣∣g0(θ)>(ŴT + Ŵ>T )(ĝT (θ)− g0(θ))∣∣+ ∣∣g0(θ)>(ŴT −W )",4.5.2 Consistency,[0],[0]
g0(θ)∣∣ ≤ ‖ĝT (θ)− g0(θ)‖2‖ŴT ‖+,4.5.2 Consistency,[0],[0]
2‖g0(θ)‖‖ĝT (θ)− g0(θ)‖‖ŴT ‖+ ‖g0(θ)‖2‖ŴT,4.5.2 Consistency,[0],[0]
"−W‖.
",4.5.2 Consistency,[0],[0]
"To prove supθ∈Θ ∣∣Q̂T (θ)−Q0(θ)∣∣ P−→ 0, we should now prove that supθ∈Θ‖ĝT (θ)− g0(θ)‖ P−→ 0.",4.5.2 Consistency,[0],[0]
"By Θ compact, it is sufficient to prove that ‖L̂−L‖ P−→ 0, ‖Ĉ (T ) −C‖ P−→ 0, and ‖K̂c (T ) −Kc‖",4.5.2 Consistency,[0],[0]
"P−→ 0.
",4.5.2 Consistency,[0],[0]
"Proof that ‖L̂−L‖ P−→ 0
",4.5.2 Consistency,[0],[0]
"The estimator of L is unbiased so let’s focus on the variance of L̂.
E[(Λ̂i",4.5.2 Consistency,[0],[0]
"− Λi)2] = E
[( 1
T ∫ T+HT HT (dN it − Λidt) )2]
= 1
T 2 ∫",4.5.2 Consistency,[0],[0]
T+HT HT ∫ T+HT HT E[(dN,4.5.2 Consistency,[0],[0]
it − Λidt)(dN it′,4.5.2 Consistency,[0],[0]
"− Λidt′)]
= 1
T 2 ∫",4.5.2 Consistency,[0],[0]
T+HT HT ∫ T+HT,4.5.2 Consistency,[0],[0]
"HT Ciit′−tdtdt ′
≤ 1 T 2 ∫",4.5.2 Consistency,[0],[0]
"T+HT HT Ciidt = Cii T −→ 0
By Markov inequality, we have just proved that ‖L̂−L‖ P−→ 0.
",4.5.2 Consistency,[0],[0]
"Proof that ‖Ĉ (T ) −C‖ P−→ 0
First, let’s remind that E(Ĉ (T ) )",4.5.2 Consistency,[0],[0]
6=,4.5.2 Consistency,[0],[0]
"C. Indeed,
E ( Ĉij,(T ) )",4.5.2 Consistency,[0],[0]
"= E ( 1
T ∫ T+HT HT dN it ∫ T+2HT 0 dN jt′ft′−t − Λ̂ iΛ̃jF T ) = E (",4.5.2 Consistency,[0],[0]
"1
T ∫ T+HT HT dN it ∫ T+2HT−t −t dN jt+sfs",4.5.2 Consistency,[0],[0]
− ΛiΛjF T ) +,4.5.2 Consistency,[0],[0]
"ij,T,HTF T
= 1
",4.5.2 Consistency,[0],[0]
T ∫ T+HT HT ∫ HT −HT fsE,4.5.2 Consistency,[0],[0]
( dN itdN j t+s − ΛiΛjds ),4.5.2 Consistency,[0],[0]
"+ ij,T,HTF T
= ∫ fsC ij s ds+ ij,T,HTF T
Now,
ij,T,HT = E",4.5.2 Consistency,[0],[0]
(,4.5.2 Consistency,[0],[0]
"ΛiΛj − Λ̂iΛ̃j )
=",4.5.2 Consistency,[0],[0]
− 1 T 2 ∫,4.5.2 Consistency,[0],[0]
T+HT HT ∫ T+2HT 0 E ( dN itdN j t′,4.5.2 Consistency,[0],[0]
"− Λ iΛjdtdt′ )
",4.5.2 Consistency,[0],[0]
=,4.5.2 Consistency,[0],[0]
− 1 T 2 ∫,4.5.2 Consistency,[0],[0]
T+HT HT ∫ T+2HT 0,4.5.2 Consistency,[0],[0]
"Cijt−t′dtdt ′
=",4.5.2 Consistency,[0],[0]
"− 1 T
∫ ( 1 + (",4.5.2 Consistency,[0],[0]
"HT − |t|
T
)−)+ Cijt dt
Since f satisfies F T = o(T ), we have E(Ĉ (T ) )",4.5.2 Consistency,[0],[0]
−→ C. It remains now to prove that ‖Ĉ (T ),4.5.2 Consistency,[0],[0]
"− E(Ĉ (T )
)‖ P−→ 0.",4.5.2 Consistency,[0],[0]
"Let’s now focus on the variance of Ĉij,(T ) : V(Ĉij,(T ))",4.5.2 Consistency,[0],[0]
"= E ( (Ĉij,(T ))2 )",4.5.2 Consistency,[0],[0]
"− E(Ĉij,(T ))",4.5.2 Consistency,[0],[0]
"2.
",4.5.2 Consistency,[0],[0]
"Now, E ( (Ĉij,(T ))2 )
",4.5.2 Consistency,[0],[0]
"= E  1 T 2 ∑ (τ,η,τ ′,η′)∈(Zi,T,1)2×(Zj,T,2)2 (fτ ′−τ − F T /(T + 2HT ))",4.5.2 Consistency,[0],[0]
"(fη′−η − F T /(T + 2HT ))  = E ( 1
T 2 ∫ t,s∈[HT ,T+HT ] ∫ t′,s′ dN",4.5.2 Consistency,[0],[0]
itdN j t′dN i sdN j s′(ft′−t,4.5.2 Consistency,[0],[0]
"− F T /(T + 2HT ))(fs′−s − F T /(T + 2HT )) )
",4.5.2 Consistency,[0],[0]
"= 1
T 2 ∫ t,s∈[HT ,T+HT ] ∫ t′,s′∈[0,T+2HT ] E ( dN itdN j t′dN i sdN j s′ ) · (ft′−t − F T /(T + 2HT ))(fs′−s − F T /(T + 2HT ))
",4.5.2 Consistency,[0],[0]
"And,
E(Ĉij,(T ))2
= 1
T 2 ∫ t,s∈[HT ,T+HT ] ∫ t′,s′∈[0,T+2HT ] E ( dN itdN j t′ )",4.5.2 Consistency,[0],[0]
E ( dN isdN j s′ ) · (ft′−t − F T /(T + 2HT )),4.5.2 Consistency,[0],[0]
"(fs′−s − F T /(T + 2HT ))
",4.5.2 Consistency,[0],[0]
"Then, the variance involves the integration towards the difference of moments µr,s,t,u − µr,sµt,u. Let’s write it as a sum of cumulants, since cumulants density are integrable.
",4.5.2 Consistency,[0],[0]
"µr,s,t,u − µr,sµt,u = κr,s,t,u + κr,s,tκu[4] + κr,sκt,u[3] + κr,sκtκu[6] + κrκsκtκu",4.5.2 Consistency,[0],[0]
"− (κr,s + κrκs)(κt,u + κtκu) = κr,s,t,u
+ κr,s,tκu + κu,r,sκt + κt,u,rκs + κs,t,uκr
+ κr,tκs,u + κr,uκs,t
+ κr,tκsκu + κr,uκsκt + κs,tκrκu + κs,tκrκu
In the rest of the proof, we denote at = 1t∈[HT ,T+HT ], bt = 1t∈[0,T+2HT ], ct = 1t∈[−HT ,HT ], gt = ft − 1T+2HT F T Before starting the integration of each term, let’s remark that:
1.",4.5.2 Consistency,[0],[0]
"Ψt = ∑ n≥1 Φ (?n) t ≥ 0 since Φt ≥ 0.
2.",4.5.2 Consistency,[0],[0]
"The regular parts ofCiju ,K ijk u,v (skewness density) andM ijkl u,v,w (fourth cumulant density) are positive
as polynoms of integrals of ψab· with positive coefficients.",4.5.2 Consistency,[0],[0]
"The integrals of the singular parts are positive as well.
",4.5.2 Consistency,[0],[0]
3.,4.5.2 Consistency,[0],[0]
(a) ∫ atbt′ft′−tdtdt ′,4.5.2 Consistency,[0],[0]
"= TF T
(b) ∫ atbt′gt′−tdtdt ′",4.5.2 Consistency,[0],[0]
"= 0
(c) ∫ atbt′ |gt′−t|dtdt′ ≤ 2TF",4.5.2 Consistency,[0],[0]
"T
4.",4.5.2 Consistency,[0],[0]
"∀t ∈ R, at(b ?",4.5.2 Consistency,[0],[0]
g̃)t,4.5.2 Consistency,[0],[0]
"= 0, where g̃s = g−s.
Fourth cumulant",4.5.2 Consistency,[0],[0]
"We want here to compute ∫ κi,j,i,jt,t′,s,s′atbt′asbs′gt′−tgs′−sdtdt
′dsds′. We remark that |gt′−tgs′−s| ≤ (||f ||∞(1 + 2HT /T ))2 ≤",4.5.2 Consistency,[0],[0]
"4||f ||2∞.∣∣∣ 1 T 2 ∫ κi,j,i,jt,t′,s,s′atbt′asbs′gt′−tgs′−sdtdt ′dsds′ ∣∣∣ ≤ (2||f ||∞ T )2 ∫ dtat ∫ dt′bt′ ∫",4.5.2 Consistency,[0],[0]
"dsas ∫ ds′bs′M ijij t′−t,s−t,s′−t
≤",4.5.2 Consistency,[0],[0]
"(
2||f ||∞ T
)2 ∫",4.5.2 Consistency,[0],[0]
dtat ∫ dt′bt′ ∫ dsas ∫ dwM,4.5.2 Consistency,[0],[0]
"ijijt′−t,s−t,w
≤ (
2||f ||∞ T
)2 ∫ dtat ∫ M ijiju,v,wdudvdw
≤ 4||f || 2 ∞
T M ijij −→ T→∞ 0
",4.5.2 Consistency,[0],[0]
"Third × First We have four terms, but only two different forms since the roles of (s, s′) and (t, t′) are symmetric.",4.5.2 Consistency,[0],[0]
"First form ∫
κi,j,it,t′,sΛ jGtdt =
Λj
T 2
∫ κi,j,it,t′,satbt′asbs′gt′−tgs′−sdtdt ′dsds′
= Λj
T 2
∫ κi,j,it,t′,satbt′as(b ?",4.5.2 Consistency,[0],[0]
"g̃)sgt′−tdtdt ′ds
= 0",4.5.2 Consistency,[0],[0]
since as(b ?,4.5.2 Consistency,[0],[0]
"g̃)s = 0
Second form∣∣∣ ∫ κi,j,jt,t′,s′ΛiGtdt∣∣∣ = ∣∣∣ΛiT 2 ∫ κi,j,jt,t′,s′atbt′asbs′gt′−tgs′−sdtdt ′dsds′ ∣∣∣
= ∣∣∣Λi T 2 ∫ κi,j,jt,t′,s′atbt′gt′−tbs′(a ?",4.5.2 Consistency,[0],[0]
g)s′dtdt,4.5.2 Consistency,[0],[0]
′ds′ ∣∣∣ ≤,4.5.2 Consistency,[0],[0]
"Λ i
T 2 2||f ||∞
∫ ds′bs′(a ?",4.5.2 Consistency,[0],[0]
"|g|)s′ ∫ dtat ∫ dt′bt′K ijj t′−s′,t−s′
≤",4.5.2 Consistency,[0],[0]
"4||f ||∞KijjΛi F T
T −→ T→∞ 0
",4.5.2 Consistency,[0],[0]
"Second × Second First form ∣∣∣ ∫ κi,it,sκj,jt′,s′Gtdt∣∣∣ ≤ 2||f ||∞T 2 ∫ Ciit−sC jj t′−s′atbt′ |gt′−t|asbs′dtdt ′dsds′
≤ 2||f ||∞",4.5.2 Consistency,[0],[0]
"T 2
CiiCjj ∫ atbt′ |gt′−t|dtdt′
≤ 4||f ||∞CiiCjj F T
T −→ T→∞ 0
Second form ∣∣∣ ∫ κi,jt,s′κi,jt′,sGtdt∣∣∣ ≤",4.5.2 Consistency,[0],[0]
4||f ||∞(Cij)2F TT −→T→∞ 0,4.5.2 Consistency,[0],[0]
"Second × First × First First form ∫
κi,jt,t′Λ",4.5.2 Consistency,[0],[0]
"iΛjGtdt =
ΛiΛj
T 2
∫ κi,jt,t′atbt′gt′−tdtdt ′",4.5.2 Consistency,[0],[0]
∫ asbs′gs′−sdsds ′,4.5.2 Consistency,[0],[0]
"= 0
Second form ∫ κi,it,sΛ",4.5.2 Consistency,[0],[0]
jΛjGtdt,4.5.2 Consistency,[0],[0]
"= ( Λj
T
)2 ∫ κi,it,satbt′gt′−tas(b ?",4.5.2 Consistency,[0],[0]
"g̃)sdtdt ′ds = 0
We have just proved that V(Ĉ (T ) ) P−→",4.5.2 Consistency,[0],[0]
0,4.5.2 Consistency,[0],[0]
.,4.5.2 Consistency,[0],[0]
"By Markov inequality, it ensures us that ‖Ĉ (T ) −E(Ĉ (T ) )",4.5.2 Consistency,[0],[0]
"‖ P−→ 0, and finally that ‖Ĉ (T ) −C‖ P−→ 0.
",4.5.2 Consistency,[0],[0]
Proof that ‖K̂c (T ) −Kc‖,4.5.2 Consistency,[0],[0]
"P−→ 0
",4.5.2 Consistency,[0],[0]
The scheme of the proof is similar to the previous one.,4.5.2 Consistency,[0],[0]
"The upper bounds of the integrals involve the same kind of terms, plus the new term (F T )2/T that goes to zero thanks to the assumption 5 of the theorem.",4.5.2 Consistency,[0],[0]
"In this paper, we introduce a simple nonparametric method (the NPHC algorithm) that leads to a fast and robust estimation of the matrixG of the kernel integrals of a Multivariate Hawkes process that encodes Granger causality between nodes.",5 Conclusion,[0],[0]
"This method relies on the matching of the integrated order 2 and order 3 empirical cumulants, which represent the simplest set of global observables containing sufficient information to recover the matrixG. Since this matrix fully accounts for the self- and cross- influences of the process nodes (that can represent agents or users in applications), our approach can naturally be used to quantify the degree of endogeneity of a system and to uncover the causality structure of a network.
",5 Conclusion,[0],[0]
"By performing numerical experiments involving very different kernel shapes, we show that the baselines, involving either parametric or non-parametric approaches are very sensible to model misspecification, do not lead to accurate estimation, and are numerically expensive, while NPHC provides fast, robust and reliable results.",5 Conclusion,[0],[0]
"This is confirmed on the MemeTracker database, where we show that NPHC outperforms classical approaches based on EM algorithms or the Wiener-Hopf equations.",5 Conclusion,[0],[0]
"Finally, the NPHC algorithm provided very satisfying results on financial data, that are consistent with well-known stylized facts in finance.",5 Conclusion,[0],[0]
"This work benefited from the support of the chair “Changing markets”, CMAP École Polytechnique and École Polytechnique fund raising - Data Science Initiative.
",Acknowledgements,[0],[0]
The authors want to thank Marcello Rambaldi for fruitful discussions on order book data’s experiments.,Acknowledgements,[0],[0]
We design a new nonparametric method that allows one to estimate the matrix of integrated kernels of a multivariate Hawkes process.,abstractText,[0],[0]
"This matrix not only encodes the mutual influences of each node of the process, but also disentangles the causality relationships between them.",abstractText,[0],[0]
Our approach is the first that leads to an estimation of this matrix without any parametric modeling and estimation of the kernels themselves.,abstractText,[0],[0]
"As a consequence, it can give an estimation of causality relationships between nodes (or users), based on their activity timestamps (on a social network for instance), without knowing or estimating the shape of the activities lifetime.",abstractText,[0],[0]
"For that purpose, we introduce a moment matching method that fits the second-order and the third-order integrated cumulants of the process.",abstractText,[0],[0]
A theoretical analysis allows us to prove that this new estimation technique is consistent.,abstractText,[0],[0]
"Moreover, we show, on numerical experiments, that our approach is indeed very robust with respect to the shape of the kernels and gives appealing results on the MemeTracker database and on financial order book data.",abstractText,[0],[0]
Uncovering Causality from Multivariate Hawkes Integrated Cumulants,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 203–208 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2032",text,[0],[0]
Argumentation plays a crucial role in persuasion and decision-making processes.,1 Introduction,[0],[0]
An argument usually consists of a central claim (or conclusion) and several supporting premises.,1 Introduction,[0],[0]
"Constructing arguments of high quality would require the inclusion of diverse information, such as factual evidence and solid reasoning (Rieke et al., 1997; Park and Cardie, 2014).",1 Introduction,[0],[0]
"For instance, as shown in Figure 1, the editor on idebate.org – a Wikipedia-style website for gathering pro and con arguments on controversial issues, utilizes arguments based on study, factual evidence, and expert opinion to support the anti-gun claim “legally owned guns are frequently stolen and used by criminals”.",1 Introduction,[0],[0]
"However, it would require substantial human effort to collect information from diverse resources to support argument construction.",1 Introduction,[0],[0]
"In order to facilitate this process, there is a pressing need for tools that can automatically detect supporting arguments.
",1 Introduction,[0],[0]
"To date, most of the argument mining research focuses on recognizing argumentative components
and their structures from constructed arguments based on curated corpus (Mochales and Moens, 2011; Stab and Gurevych, 2014; Feng and Hirst, 2011; Habernal and Gurevych, 2015; Nguyen and Litman, 2016).",1 Introduction,[0],[0]
Limited work has been done for retrieving supporting arguments from external resources.,1 Introduction,[0],[0]
Initial effort by Rinott et al. (2015) investigates the detection of relevant factual evidence from Wikipedia articles.,1 Introduction,[0],[0]
"However, it is unclear whether their method can perform well on documents of different genres (e.g. news articles vs. blogs) for detecting distinct types of supporting information.
",1 Introduction,[0],[0]
"In this work, we present a novel study on the task of sentence-level supporting argument detection from relevant documents for a user-specified claim.",1 Introduction,[0],[0]
"Take Figure 2 as an example: assume we are given a claim on the topic of “banning cosmetic surgery” and a relevant article (cited for argument construction), we aim to automatically pinpoint the sentence(s) (in italics) among all sentences in the cited article that can be used to back up the claim.",1 Introduction,[0],[0]
We define such tasks as supporting argument detection.,1 Introduction,[0],[0]
"Furthermore, another goal of
203
this work is to understand and characterize different types of supporting arguments.",1 Introduction,[0],[0]
"Indeed, human editors do use different types of information to promote persuasiveness as we will show in Section 3.",1 Introduction,[0],[0]
"Prediction performance also varies among different types of supporting arguments.
",1 Introduction,[0],[0]
"Given that none of the existing datasets is suitable for our study, we collect and annotate a corpus from Idebate, which contains hundreds of debate topics and corresponding claims.1 As is shown in Figure 2, each claim is supported with some human constructed argument, with cited articles marked on sentence level.",1 Introduction,[0],[0]
"After careful inspection on the supporting arguments, we propose to label them as STUDY, FACTUAL, OPINION, or REASONING.",1 Introduction,[0],[0]
"Substantial inter-annotator agreement rate is achieved for both supporting argument labeling (with Cohen’s κ of 0.8) and argument type annotation, on 200 topics with 621 reference articles.
",1 Introduction,[0],[0]
"Based on the new corpus, we first carry out a study on characterizing arguments of different types via type prediction.",1 Introduction,[0],[0]
"We find that arguments
1The labeled dataset along with the annotation guideline will be released at xyhua.me.
of STUDY and FACTUAL tend to use more concrete words, while arguments of OPINION contain more named entities of person names.",1 Introduction,[0],[0]
We then investigate whether argument type can be leveraged to assist supporting argument detection.,1 Introduction,[0],[0]
"Experimental results based on LambdaMART (Burges, 2010) show that utilizing features composite with argument types achieves a Mean Reciprocal Rank (MRR) score of 57.65, which outperforms an unsupervised baseline and the same ranker trained without type information.",1 Introduction,[0],[0]
"Feature analysis also demonstrates that salient features have significantly different distribution over different argument types.
",1 Introduction,[0],[0]
"For the rest of the paper, we summarize related work in Section 2.",1 Introduction,[0],[0]
"The data collection and annotation process is described in Section 3, which is followed by argument type study (Section 4).",1 Introduction,[0],[0]
Experiment on supporting argument detection is presented in Section 5.,1 Introduction,[0],[0]
We finally conclude in Section 6.,1 Introduction,[0],[0]
"Our work is in line with argumentation mining, which has recently attracted significant research interest.",2 Related Work,[0],[0]
"Existing work focuses on argument extraction from news articles, legal documents, or online comments without given userspecified claim (Moens et al., 2007; Palau and Moens, 2009; Mochales and Moens, 2011; Park and Cardie, 2014).",2 Related Work,[0],[0]
"Argument scheme classification is also widely studied (Biran and Rambow, 2011; Feng and Hirst, 2011; Rooney et al., 2012; Stab and Gurevych, 2014; Al Khatib et al., 2016), which emphasizes on distinguishing different types of arguments.",2 Related Work,[0],[0]
"To the best of our knowledge, none of them studies the interaction between types of arguments and their usage to support a user-specified claim.",2 Related Work,[0],[0]
This is the gap we aim to fill.,2 Related Work,[0],[0]
"We rely on data from idebate.org, where human editors construct paragraphs of arguments, either supporting or opposing claims under controversial topics.",3 Data and Annotation,[0],[0]
We also extract textual citation articles as source of information used by editors during argument construction.,3 Data and Annotation,[0],[0]
"In total we collected 383 unique debates, out of which 200 debates are randomly selected for study.",3 Data and Annotation,[0],[0]
"After removing invalid ones, our final dataset includes 450 claims
and 621 citation articles with about 53,000 sentences.",3 Data and Annotation,[0],[0]
Annotation Process.,3 Data and Annotation,[0],[0]
"As shown in Figure 2, we first annotate which sentence(s) from a citation articles is used by the editor as supporting arguments.",3 Data and Annotation,[0],[0]
"Then we annotate the type for each of them as STUDY, FACTUAL, OPINION, or REASONING, based on the scheme in Table 1.2 For instance, the highlighted supporting argument in Figure 2 is labeled as REASONING.
",3 Data and Annotation,[0],[0]
Two experienced annotators were hired to identify supporting arguments by reading through the whole cited article and locating the sentences that best match the reference human constructed argument.,3 Data and Annotation,[0],[0]
"This task is rather complicated since human do not just repeat or directly quote the original sentences from citation articles, they also paraphrase, summarize, and generalize.",3 Data and Annotation,[0],[0]
"For instance, the original sentence is “The global counterfeit drug trade, a billion-dollar industry, is thriving in Africa”, which is paraphrased to “This is exploited by the billion dollar global counterfeit drug trade” in human constructed argument.
",3 Data and Annotation,[0],[0]
"The annotators were asked to annotate independently, then discuss and resolve disagreements and give feedback about current scheme.",3 Data and Annotation,[0],[0]
We compute inter-annotator agreement based on Cohen’s κ for both supporting arguments labeling and argument type annotation.,3 Data and Annotation,[0],[0]
"For supporting arguments we have a high degree of consensus, with Cohen’s κ ranges from 0.76 to 0.83 in all rounds and 0.80 overall.",3 Data and Annotation,[0],[0]
"For argument type annotation, we achieve Cohen’s κ of 0.61 for STUDY, 0.75 for FACTUAL, 0.71 for OPINION, and 0.29 for REASONING3
2We end up with the four-type scheme as a trade-off between complexity and its coverage of the arguments.
",3 Data and Annotation,[0],[0]
"3Many times annotators have different interpretation on REASONING, and frequently label it as OPINION.",3 Data and Annotation,[0],[0]
"This results
Statistics.",3 Data and Annotation,[0],[0]
In total 995 sentences are identified as supporting arguments.,3 Data and Annotation,[0],[0]
"Among those, 95 (9.55%) are labeled as STUDY, 497 (49.95%) as FACTUAL, 363 (36.48%) as OPINION, and 40 (4.02%) as REASONING.
",3 Data and Annotation,[0],[0]
We further analyze the source of the supporting arguments.,3 Data and Annotation,[0],[0]
"Domain names of the citation articles are collected based on their URL, and then categorized into “news”, “organization”, “scientific”, “blog”, “reference”, and others, according to a taxonomy provided by Alexa4 with a few edits to fit our dataset.",3 Data and Annotation,[0],[0]
"News articles are the major source for all types, which account for roughly 50% for each.",3 Data and Annotation,[0],[0]
We show the distribution of other four types in Figure 3.,3 Data and Annotation,[0],[0]
"Arguments of STUDY and REASONING are mostly from “scientific” websites (14.9% and 22.9%), whereas “organization” websites contribute a large portion of arguments of FACTUAL (18.5%) and OPINION (16.7%).",3 Data and Annotation,[0],[0]
Here we characterize arguments of different types based on diverse features under the task of predicting argument types.,4 A Study On Argument Type Prediction,[0],[0]
Supporting arguments identified from previous section are utilized for experiments.,4 A Study On Argument Type Prediction,[0],[0]
"We also leverage the learned classifier in this section to label the sentences that are not supporting arguments, which will be used for supporting argument detection in the next section.",4 A Study On Argument Type Prediction,[0],[0]
Four major types of features are considered.,4 A Study On Argument Type Prediction,[0],[0]
Basic Features.,4 A Study On Argument Type Prediction,[0],[0]
"We calculate frequencies of unigram and bigram words, number of four major types of part-of-speech tags (verb, noun, adjective, and adverb), number of dependency relations, and
in a low agreement for REASONING.",4 A Study On Argument Type Prediction,[0],[0]
"4http://www.alexa.com/topsites/category
number of seven types of named entities (Chinchor and Robinson, 1997).",4 A Study On Argument Type Prediction,[0],[0]
Sentiment Features.,4 A Study On Argument Type Prediction,[0],[0]
"We also compute number of positive, negative and neutral words in MPQA lexicon (Wilson et al., 2005), and number of words from a subset of semantic categories from General Inquirer (Stone et al., 1966).5 Discourse Features.",4 A Study On Argument Type Prediction,[0],[0]
"We use the number of discourse connectives from the top two levels of Penn Discourse Tree Bank (Prasad et al., 2007).",4 A Study On Argument Type Prediction,[0],[0]
Style Features.,4 A Study On Argument Type Prediction,[0],[0]
"We measure word attributes for their concreteness (perceptible vs. conceptual), valence (or pleasantness), arousal (or intensity of emotion), and dominance (or degree of control) based on the lexicons collected by Brysbaert et al. (2014) and Warriner et al. (2013).
",4 A Study On Argument Type Prediction,[0],[0]
We utilize Log-linear model for argument type prediction with one-vs-rest setup.,4 A Study On Argument Type Prediction,[0],[0]
"Three baselines are considered: (1) random guess, (2) majority class, and (3) unigrams and bigrams as features for Log-linear model.",4 A Study On Argument Type Prediction,[0],[0]
"Identified supporting arguments are used for experiments, and divided into training set (50%), validation set (25%) and test set (25%).",4 A Study On Argument Type Prediction,[0],[0]
"From Table 2, we can see that Loglinear model trained with all features outperforms the ones trained with ngram features.",4 A Study On Argument Type Prediction,[0],[0]
"To further characterize arguments of different types, we display sample features with significant different values in Figure 4.",4 A Study On Argument Type Prediction,[0],[0]
"As can be seen, arguments of STUDY and FACTUAL tend to contain more concrete words and named entities.",4 A Study On Argument Type Prediction,[0],[0]
"Arguments of OPINION mention more person names, which implies that expert opinions are commonly quoted.",4 A Study On Argument Type Prediction,[0],[0]
"We cast the sentence-level supporting argument detection problem as a ranking task.6 Features
5Categories used: Strong, Weak, Virtue, Vice, Ovrst (Overstated), Undrst (Understated), Academ (Academic), Doctrin (Doctrine), Econ (Economic), Relig (Religious), Causal, Ought, and Perceiv (Perception).
6Many sentences in the citation article is relevant to the topic to various degrees.",5 Supporting Argument Detection,[0],[0]
"We focus on detecting the most relevant ones, and thus treat it as a ranking problem instead of a
in Section 4 are also utilized here as “Sentence features” with additional features considering the sentence position in the article.",5 Supporting Argument Detection,[0],[0]
"We further employ features that measure similarity between claims and sentences, and the composite features that leverage argument type information.
",5 Supporting Argument Detection,[0],[0]
Similarity Features.,5 Supporting Argument Detection,[0],[0]
We compute similarity between claim and candidate sentence based on TFIDF and average word embeddings.,5 Supporting Argument Detection,[0],[0]
"We also consider ROUGE (Lin, 2004), a recall oriented metric for summarization evaluation.",5 Supporting Argument Detection,[0],[0]
"In particular, ROUGE-L, a variation based on longest common subsequence, is computed by treating claim as reference and each candidate sentence as sample summary.",5 Supporting Argument Detection,[0],[0]
"In similar manner we use BLEU (Papineni et al., 2002), a precision oriented metric.
",5 Supporting Argument Detection,[0],[0]
Composite Features.,5 Supporting Argument Detection,[0],[0]
We adopt composite features to study the interaction of other features with type of the sentence.,5 Supporting Argument Detection,[0],[0]
"Given claim c and sentence s with any feature mentioned above, a composite feature function φM(type, feature)(s, c) is set to the actual feature value if and only if the argument type matches.",5 Supporting Argument Detection,[0],[0]
"For instance, if the ROUGE-L score is 0.2, and s is of type STUDY, then φM(study, ROUGE)(s, c)",5 Supporting Argument Detection,[0],[0]
"= 0.2 φM(factual, ROUGE)(s, c), φM(opinion, ROUGE)(s, c), φM(reasoning, ROUGE)(s, c) are all set to 0.
binary classification task.
",5 Supporting Argument Detection,[0],[0]
"We choose LambdaMART (Burges, 2010) for experiments, which is shown to be successful for many text ranking problems (Chapelle and Chang, 2011).",5 Supporting Argument Detection,[0],[0]
Our model is evaluated by Mean Reciprocal Rank (MRR) and Normalized Discounted Cumulative Gain (NDCG) using 5-fold cross validation.,5 Supporting Argument Detection,[0],[0]
"We compare to TFIDF and Word embedding similarity baselines, and LambdaMART trained with ngrams (unigrams and bigrams).
",5 Supporting Argument Detection,[0],[0]
"Results in Table 3 show that using composite features with argument type information (Comp(type, Sen) +",5 Supporting Argument Detection,[0],[0]
"Comp(type, Simi)) can improve the ranking performance.",5 Supporting Argument Detection,[0],[0]
"Specifically, the best performance is achieved by adding composite features to sentence features, similarity features, and ngram features.",5 Supporting Argument Detection,[0],[0]
"As can be seen, supervised methods outperform unsupervised baseline methods.",5 Supporting Argument Detection,[0],[0]
And similarity features have similar performance as those baselines.,5 Supporting Argument Detection,[0],[0]
"The best performance is achieved by combination of sentence features, Ngrams, similarity, and two composite types, which is boldfaced.",5 Supporting Argument Detection,[0],[0]
"Feature sets that significantly outperform all three baselines are marked with ∗.
For feature analysis, we conduct t-test for individual feature values between supporting arguments and the others.",5 Supporting Argument Detection,[0],[0]
We breakdown features according to their argument types and show top salient composite features in Table 4.,5 Supporting Argument Detection,[0],[0]
"For all sentences of type STUDY, relevant ones tend to contain more “percentage” and more concrete words.",5 Supporting Argument Detection,[0],[0]
We also notice those sentences with more hedging words are more likely to be considered.,5 Supporting Argument Detection,[0],[0]
"For sentences of FACTUAL, position of sentence in article
plays an important role, as well as their similarity to the claim based on ROUGE scores.",5 Supporting Argument Detection,[0],[0]
"For type OPINION, unlike all other types, position of sentence seems to be insignificant.",5 Supporting Argument Detection,[0],[0]
"As we could imagine, opinionated information might scatter around the whole documents.",5 Supporting Argument Detection,[0],[0]
"For sentences of REASONING, the ones that can be used as supporting arguments tend to be less concrete and less emotional, as opposed to opinion.",5 Supporting Argument Detection,[0],[0]
We presented a novel study on the task of sentence-level supporting argument detection from relevant documents for a user-specified claim.,6 Conclusion,[0],[0]
"Based on our newly-collected dataset, we characterized arguments of different types with a rich feature set.",6 Conclusion,[0],[0]
We also showed that leveraging argument type information can further improve the performance of supporting argument detection.,6 Conclusion,[0],[0]
This work was supported in part by National Science Foundation Grant IIS-1566382 and a GPU gift from Nvidia.,Acknowledgments,[0],[0]
We thank Kechen Qin for his help on data collection.,Acknowledgments,[0],[0]
We also appreciate the valuable suggestions on various aspects of this work from three anonymous reviewers.,Acknowledgments,[0],[0]
We investigate the problem of sentence-level supporting argument detection from relevant documents for user-specified claims.,abstractText,[0],[0]
A dataset containing claims and associated citation articles is collected from online debate website idebate.org.,abstractText,[0],[0]
"We then manually label sentence-level supporting arguments from the documents along with their types as STUDY, FACTUAL, OPINION, or REASONING.",abstractText,[0],[0]
"We further characterize arguments of different types, and explore whether leveraging type information can facilitate the supporting arguments detection task.",abstractText,[0],[0]
"Experimental results show that LambdaMART (Burges, 2010) ranker that uses features informed by argument types yields better performance than the same ranker trained without type information.",abstractText,[0],[0]
Understanding and Detecting Supporting Arguments of Diverse Types,title,[0],[0]
A key question often asked of machine learning systems is “Why did the system make this prediction?”,1. Introduction,[0],[0]
We want models that are not just high-performing but also explainable.,1. Introduction,[0],[0]
"By understanding why a model does what it does, we can hope to improve the model (Amershi et al., 2015), discover new science (Shrikumar et al., 2017), and provide end-users with explanations of actions that impact them (Goodman & Flaxman, 2016).
",1. Introduction,[0],[0]
"However, the best-performing models in many domains — e.g., deep neural networks for image and speech recognition (Krizhevsky et al., 2012) — are complicated, blackbox models whose predictions seem hard to explain.",1. Introduction,[0],[0]
"Work on interpreting these black-box models has focused on understanding how a fixed model leads to particular predictions, e.g., by locally fitting a simpler model around the test
1Stanford University, Stanford, CA.",1. Introduction,[0],[0]
"Correspondence to: Pang Wei Koh <pangwei@cs.stanford.edu>, Percy Liang <pliang@cs.stanford.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
point (Ribeiro et al., 2016) or by perturbing the test point to see how the prediction changes (Simonyan et al., 2013; Li et al., 2016b; Datta et al., 2016; Adler et al., 2016).",1. Introduction,[0],[0]
"These works explain the predictions in terms of the model, but how can we explain where the model came from?
",1. Introduction,[0],[0]
"In this paper, we tackle this question by tracing a model’s predictions through its learning algorithm and back to the training data, where the model parameters ultimately derive from.",1. Introduction,[0],[0]
"To formalize the impact of a training point on a prediction, we ask the counterfactual: what would happen if we did not have this training point, or if the values of this training point were changed slightly?
",1. Introduction,[0],[0]
Answering this question by perturbing the data and retraining the model can be prohibitively expensive.,1. Introduction,[0],[0]
"To overcome this problem, we use influence functions, a classic technique from robust statistics (Hampel, 1974) that tells us how the model parameters change as we upweight a training point by an infinitesimal amount.",1. Introduction,[0],[0]
"This allows us to “differentiate through the training” to estimate in closed-form the effect of a variety of training perturbations.
",1. Introduction,[0],[0]
"Despite their rich history in statistics, influence functions have not seen widespread use in machine learning; to the best of our knowledge, the work closest to ours is Wojnowicz et al. (2016), which introduced a method for approximating a quantity related to influence in generalized linear models.",1. Introduction,[0],[0]
"One obstacle to adoption is that influence functions require expensive second derivative calculations and assume model differentiability and convexity, which limits their applicability in modern contexts where models are often non-differentiable, non-convex, and highdimensional.",1. Introduction,[0],[0]
"We address these challenges by showing that we can efficiently approximate influence functions using second-order optimization techniques (Pearlmutter, 1994; Martens, 2010; Agarwal et al., 2016), and that they remain accurate even as the underlying assumptions of differentiability and convexity degrade.
",1. Introduction,[0],[0]
Influence functions capture the core idea of studying models through the lens of their training data.,1. Introduction,[0],[0]
"We show that they are a versatile tool that can be applied to a wide variety of seemingly disparate tasks: understanding model behavior, debugging models, detecting dataset errors, and creating visually-indistinguishable adversarial training examples that can flip neural network test predictions, the training set analogue of Goodfellow et al. (2015).
",1. Introduction,[0],[0]
"ar X
iv :1
70 3.
04 73
0v 3
[ st
at .M
L ]
2 9
D ec
2 02
0",1. Introduction,[0],[0]
"Consider a prediction problem from some input space X (e.g., images) to an output space Y (e.g., labels).",2. Approach,[0],[0]
"We are given training points z1, . . .",2. Approach,[0],[0]
", zn, where zi = (xi, yi) ∈ X × Y .",2. Approach,[0],[0]
"For a point z and parameters θ ∈ Θ, let L(z, θ) be the loss, and let",2. Approach,[0],[0]
1n,2. Approach,[0],[0]
∑n i=1,2. Approach,[0],[0]
"L(zi, θ) be the empirical risk.",2. Approach,[0],[0]
The empirical risk minimizer is given by θ̂ def = arg minθ∈Θ 1 n,2. Approach,[0],[0]
∑n i=1,2. Approach,[0],[0]
"L(zi, θ).
",2. Approach,[0],[0]
1 Assume that the empirical risk is twice-differentiable and strictly convex in θ; in Section 4 we explore relaxing these assumptions.,2. Approach,[0],[0]
Our goal is to understand the effect of training points on a model’s predictions.,2.1. Upweighting a training point,[0],[0]
"We formalize this goal by asking the counterfactual: how would the model’s predictions change if we did not have this training point?
",2.1. Upweighting a training point,[0],[0]
Let us begin by studying the change in model parameters due to removing a point z from the training set.,2.1. Upweighting a training point,[0],[0]
"Formally, this change is θ̂−z − θ̂, where θ̂−z def = arg minθ∈Θ ∑ zi 6=z L(zi, θ).",2.1. Upweighting a training point,[0],[0]
"However, retraining the model for each removed z is prohibitively slow.
",2.1. Upweighting a training point,[0],[0]
"Fortunately, influence functions give us an efficient approximation.",2.1. Upweighting a training point,[0],[0]
"The idea is to compute the parameter change if z were upweighted by some small , giving us new parameters θ̂ ,z def = arg",2.1. Upweighting a training point,[0],[0]
minθ∈Θ 1 n,2.1. Upweighting a training point,[0],[0]
∑n i=1,2.1. Upweighting a training point,[0],[0]
"L(zi, θ) + L(z, θ).",2.1. Upweighting a training point,[0],[0]
"A classic result (Cook & Weisberg, 1982) tells us that the influence of upweighting z on the parameters θ̂ is given by
Iup,params(z) def = dθ̂ ,z d ∣∣∣ =0 = −H−1 θ̂ ∇θL(z, θ̂), (1)
where Hθ̂ def = 1n",2.1. Upweighting a training point,[0],[0]
"∑n i=1∇2θL(zi, θ̂) is the Hessian and is positive definite (PD) by assumption.",2.1. Upweighting a training point,[0],[0]
"In essence, we are forming a quadratic approximation to the empirical risk around θ̂ and take a single Newton step; see appendix A for a derivation.",2.1. Upweighting a training point,[0],[0]
"Since removing a point z is the same as upweighting it by = − 1n , we can linearly approximate the parameter change due to removing z without retraining the model by computing θ̂−z",2.1. Upweighting a training point,[0],[0]
− θ̂,2.1. Upweighting a training point,[0],[0]
"≈ − 1nIup,params(z).
",2.1. Upweighting a training point,[0],[0]
"Next, we apply the chain rule to measure how upweighting z changes functions of θ̂. In particular, the influence of upweighting z on the loss at a test point ztest again has a closed-form expression:
Iup,loss(z, ztest) def =
dL(ztest, θ̂ ,z)
",2.1. Upweighting a training point,[0],[0]
"d
∣∣∣",2.1. Upweighting a training point,[0],[0]
"=0
(2)
= ∇θL(ztest, θ̂)>",2.1. Upweighting a training point,[0],[0]
"dθ̂ ,z d ∣∣∣ =0
= −∇θL(ztest, θ̂)>H−1θ̂ ∇θL(z, θ̂).",2.1. Upweighting a training point,[0],[0]
1We fold in any regularization terms into L.,2.1. Upweighting a training point,[0],[0]
"Let us develop a finer-grained notion of influence by studying a different counterfactual: how would the model’s predictions change if a training input were modified?
",2.2. Perturbing a training input,[0],[0]
"For a training point z = (x, y), define zδ def = (x + δ, y).",2.2. Perturbing a training input,[0],[0]
"Consider the perturbation z 7→ zδ , and let θ̂zδ,−z be the empirical risk minimizer on the training points with zδ in place of z. To approximate its effects, define the parameters resulting from moving mass from z onto zδ: θ̂ ,zδ,−z def = arg minθ∈Θ 1 n",2.2. Perturbing a training input,[0],[0]
∑n i=1,2.2. Perturbing a training input,[0],[0]
"L(zi, θ) + L(zδ, θ)",2.2. Perturbing a training input,[0],[0]
"− L(z, θ).",2.2. Perturbing a training input,[0],[0]
"An analogous calculation to (1) yields:
dθ̂ ,zδ,−z d ∣∣∣ =0 = Iup,params(zδ)− Iup,params(z)
= −H−1 θ̂
( ∇θL(zδ, θ̂)−∇θL(z, θ̂) ) .",2.2. Perturbing a training input,[0],[0]
"(3)
As before, we can make the linear approximation θ̂zδ,−z − θ̂",2.2. Perturbing a training input,[0],[0]
"≈ 1n (Iup,params(zδ) − Iup,params(z)), giving us a closedform estimate of the effect of z 7→ zδ on the model.",2.2. Perturbing a training input,[0],[0]
"Analogous equations also apply for changes in y. While influence functions might appear to only work for infinitesimal (therefore continuous) perturbations, it is important to note that this approximation holds for arbitrary δ: the - upweighting scheme allows us to smoothly interpolate between z and zδ .",2.2. Perturbing a training input,[0],[0]
"This is particularly useful for working with discrete data (e.g., in NLP) or with discrete label changes.
",2.2. Perturbing a training input,[0],[0]
"If x is continuous and δ is small, we can further approximate (3).",2.2. Perturbing a training input,[0],[0]
"Assume that the input domain X ⊆ Rd, the parameters Θ ⊆ Rp, and L is differentiable in θ and x.",2.2. Perturbing a training input,[0],[0]
"As ‖δ‖ → 0,∇θL(zδ, θ̂)−∇θL(z, θ̂)",2.2. Perturbing a training input,[0],[0]
≈,2.2. Perturbing a training input,[0],[0]
"[∇x∇θL(z, θ̂)]δ, where ∇x∇θL(z, θ̂) ∈ Rp×d.",2.2. Perturbing a training input,[0],[0]
"Substituting into (3),
dθ̂ ,zδ,−z d ∣∣∣ =0",2.2. Perturbing a training input,[0],[0]
≈ −H−1 θ̂,2.2. Perturbing a training input,[0],[0]
"[∇x∇θL(z, θ̂)]δ.",2.2. Perturbing a training input,[0],[0]
"(4)
We thus have θ̂zδ,−z − θ̂ ≈",2.2. Perturbing a training input,[0],[0]
− 1nH −1 θ̂,2.2. Perturbing a training input,[0],[0]
"[∇x∇θL(z, θ̂)]δ.",2.2. Perturbing a training input,[0],[0]
Differentiating w.r.t.,2.2. Perturbing a training input,[0],[0]
"δ and applying the chain rule gives us
Ipert,loss(z, ztest) def = ∇δL(ztest, θ̂zδ,−z) ∣∣∣ δ=0
(5)
",2.2. Perturbing a training input,[0],[0]
"= −∇θL(ztest, θ̂)>H−1θ̂ ∇x∇θL(z, θ̂).
",2.2. Perturbing a training input,[0],[0]
"[Ipert,loss(z, ztest)]δ tells us the approximate effect that z 7→",2.2. Perturbing a training input,[0],[0]
z+ δ has on the loss at ztest.,2.2. Perturbing a training input,[0],[0]
"By setting δ in the direction of Ipert,loss(z, ztest)>, we can construct local perturbations of z that maximally increase the loss at ztest.",2.2. Perturbing a training input,[0],[0]
"In Section 5.2, we will use this to construct training-set attacks.",2.2. Perturbing a training input,[0],[0]
"Finally, we note that Ipert,loss(z, ztest) can help us identify the features of z that are most responsible for the prediction on ztest.",2.2. Perturbing a training input,[0],[0]
"To find the training points most relevant to a test point, it is common to look at its nearest neighbors in Euclidean
space",2.3. Relation to Euclidean distance,[0],[0]
"(e.g., Ribeiro et al. (2016)); if all points have the same norm, this is equivalent to choosing x with the largest x ·xtest.",2.3. Relation to Euclidean distance,[0],[0]
"For intuition, we compare this to Iup,loss(z, ztest) on a logistic regression model and show that influence is much more accurate at accounting for the effect of training.
",2.3. Relation to Euclidean distance,[0],[0]
"Let p(y | x) = σ(yθ>x), with y ∈ {−1, 1} and σ(t) = 1 1+exp(−t) .",2.3. Relation to Euclidean distance,[0],[0]
We seek to maximize the probability of the training set.,2.3. Relation to Euclidean distance,[0],[0]
"For a training point z = (x, y), L(z, θ) = log(1 + exp(−yθ>x)), ∇θL(z, θ) = −σ(−yθ>x)yx, and Hθ = 1n",2.3. Relation to Euclidean distance,[0],[0]
∑n i=1,2.3. Relation to Euclidean distance,[0],[0]
"σ(θ
>xi)σ(−θ>xi)xix>i .",2.3. Relation to Euclidean distance,[0],[0]
"From (2), Iup,loss(z, ztest) is:
−ytesty · σ(−ytestθ>xtest) ·",2.3. Relation to Euclidean distance,[0],[0]
σ(−yθ>x) ·,2.3. Relation to Euclidean distance,[0],[0]
"x>testH−1θ̂ x.
We highlight two key differences from x · xtest.",2.3. Relation to Euclidean distance,[0],[0]
"First, σ(−yθ>x) gives points with high training loss more influence, revealing that outliers can dominate the model parameters.",2.3. Relation to Euclidean distance,[0],[0]
"Second, the weighted covariance matrix H−1 θ̂ measures the “resistance” of the other training points to the removal of z; if ∇θL(z, θ̂) points in a direction of little variation, its influence will be higher since moving in that direction will not significantly increase the loss on other training points.",2.3. Relation to Euclidean distance,[0],[0]
"As we show in Fig 1, these differences mean that influence functions capture the effect of model training much more accurately than nearest neighbors.",2.3. Relation to Euclidean distance,[0],[0]
"There are two challenges to efficiently computing Iup,loss(z, ztest) = −∇θL(ztest, θ̂)>H−1θ̂ ∇θL(z, θ̂).",3. Efficiently calculating influence,[0],[0]
"First, it requires forming and inverting Hθ̂",3. Efficiently calculating influence,[0],[0]
"= 1 n ∑n i=1∇2θL(zi, θ̂), the Hessian of the empirical risk.",3. Efficiently calculating influence,[0],[0]
"With n training points and θ ∈ Rp, this requires O(np2 + p3) operations, which
is too expensive for models like deep neural networks with millions of parameters.",3. Efficiently calculating influence,[0],[0]
"Second, we need to calculate Iup,loss(zi, ztest) across all training points zi.
",3. Efficiently calculating influence,[0],[0]
The first problem is well-studied in second-order optimization.,3. Efficiently calculating influence,[0],[0]
"The idea is to avoid explicitly computing H−1
θ̂ ; in-
stead, we use implicit Hessian-vector products (HVPs) to efficiently approximate stest def = H−1
θ̂ ∇θL(ztest, θ̂) and then
compute Iup,loss(z, ztest) = −stest · ∇θL(z, θ̂).",3. Efficiently calculating influence,[0],[0]
"This also solves the second problem: for each test point of interest, we can precompute stest and then efficiently compute −stest · ∇θL(zi, θ̂) for each training point zi.
",3. Efficiently calculating influence,[0],[0]
"We discuss two techniques for approximating stest, both relying on the fact that the HVP of a single term in Hθ̂, [∇2θL(zi, θ̂)]v, can be computed for arbitrary v in the same time that ∇θL(zi, θ̂) would take, which is typically O(p) (Pearlmutter, 1994).
",3. Efficiently calculating influence,[0],[0]
Conjugate gradients (CG).,3. Efficiently calculating influence,[0],[0]
The first technique is a standard transformation of matrix inversion into an optimization problem.,3. Efficiently calculating influence,[0],[0]
Since Hθ̂ 0,3. Efficiently calculating influence,[0],[0]
"by assumption, H −1 θ̂ v ≡ arg mint{t",3. Efficiently calculating influence,[0],[0]
>,3. Efficiently calculating influence,[0],[0]
Hθ̂t − v >t}.,3. Efficiently calculating influence,[0],[0]
"We can solve this with CG approaches that only require the evaluation of Hθ̂t, which takesO(np) time, without explicitly formingHθ̂. While an exact solution takes p CG iterations, in practice we can get a good approximation with fewer iterations; see Martens (2010) for more details.
",3. Efficiently calculating influence,[0],[0]
Stochastic estimation.,3. Efficiently calculating influence,[0],[0]
"With large datasets, standard CG can be slow; each iteration still goes through all n training points.",3. Efficiently calculating influence,[0],[0]
"We use a method developed by Agarwal et al. (2016) to get an estimator that only samples a single point per iteration, which results in significant speedups.
",3. Efficiently calculating influence,[0],[0]
"Dropping the θ̂ subscript for clarity, letH−1j def = ∑j i=0(I− H)i, the first j terms in the Taylor expansion of H−1.",3. Efficiently calculating influence,[0],[0]
Rewrite this recursively as H−1j = I +,3. Efficiently calculating influence,[0],[0]
(I − H)H −1 j−1.,3. Efficiently calculating influence,[0],[0]
"From the validity of the Taylor expansion, H−1j → H−1 as j → ∞.2 The key is that at each iteration, we can substitute the full H with a draw from any unbiased (and fasterto-compute) estimator of H to form H̃j .",3. Efficiently calculating influence,[0],[0]
"Since E[H̃−1j ] = H−1j , we still have E[H̃ −1",3. Efficiently calculating influence,[0],[0]
"j ]→ H−1.
",3. Efficiently calculating influence,[0],[0]
"In particular, we can use ∇2θL(zi, θ̂), for any zi, as an unbiased estimator of H .",3. Efficiently calculating influence,[0],[0]
"This gives us the following procedure: uniformly sample t points zs1 , . . .",3. Efficiently calculating influence,[0],[0]
", zst from the training data; define H̃−10 v = v; and recursively compute H̃−1j v = v",3. Efficiently calculating influence,[0],[0]
"+ ( I − ∇2θL(zsj , θ̂) )",3. Efficiently calculating influence,[0],[0]
"H̃−1j−1v, taking H̃ −1",3. Efficiently calculating influence,[0],[0]
t v,3. Efficiently calculating influence,[0],[0]
as our final unbiased estimate of H−1v.,3. Efficiently calculating influence,[0],[0]
"We pick t to be large enough such that H̃t stabilizes, and to reduce variance we repeat this procedure r times and average results.",3. Efficiently calculating influence,[0],[0]
"Empirically, we found this significantly faster than CG.
",3. Efficiently calculating influence,[0],[0]
"We note that the original method of Agarwal et al. (2016) dealt only with generalized linear models, for which [∇2θL(zi, θ̂)]v can be efficiently computed in O(p) time.",3. Efficiently calculating influence,[0],[0]
"In our case, we rely on Pearlmutter (1994)’s more general algorithm for fast HVPs, described above, to achieve the same time complexity.3
With these techniques, we can compute Iup,loss(zi, ztest) on all training points zi in O(np + rtp) time; we show in Section 4.1 that empirically, choosing rt = O(n) gives accurate results.",3. Efficiently calculating influence,[0],[0]
"Similarly, we can compute Ipert,loss(zi, ztest) =",3. Efficiently calculating influence,[0],[0]
"− 1n∇θL(ztest, θ̂) >H−1 θ̂ ∇x∇θL(zi, θ̂) with two matrix-vector products: we first compute stest, then find s>test∇x∇θL(zi, θ̂) with the same HVP trick.",3. Efficiently calculating influence,[0],[0]
"These computations are easy to implement in auto-grad systems like TensorFlow (Abadi et al., 2015) and Theano (Theano D. Team, 2016), as users need only specify the loss; the rest is automatically handled.",3. Efficiently calculating influence,[0],[0]
"Recall that influence functions are asymptotic approximations of leave-one-out retraining under the assumptions that (i) the model parameters θ̂ minimize the empirical risk, and that (ii) the empirical risk is twice-differentiable and strictly convex.",4. Validation and extensions,[0],[0]
"Here, we empirically show that influence functions are accurate approximations (Section 4.1) that
2We assume w.l.o.g.",4. Validation and extensions,[0],[0]
"that ∀i,∇2θL(zi, θ̂) 4 I; if this is not true, we can scale the loss down without affecting the parameters.",4. Validation and extensions,[0],[0]
"In some cases, we can get an upper bound on∇2θL(zi, θ̂) (e.g., for linear models and bounded input), which makes this easy.",4. Validation and extensions,[0],[0]
"Otherwise, we treat the scaling as a separate hyperparameter and tune it such that the Taylor expansion converges.
",4. Validation and extensions,[0],[0]
"3To increase stability, especially with non-convex models (see Section 4.2), we can also sample a minibatch of training points at each iteration, instead of relying on a single training point.
provide useful information even when these assumptions are violated (Sections 4.2, 4.3).",4. Validation and extensions,[0],[0]
Influence functions assume that the weight on a training point is changed by an infinitesimally small .,4.1. Influence functions vs. leave-one-out retraining,[0],[0]
"To investigate the accuracy of using influence functions to approximate the effect of removing a training point and retraining, we compared − 1nIup,loss(z, ztest) with L(ztest, θ̂−z)",4.1. Influence functions vs. leave-one-out retraining,[0],[0]
"− L(ztest, θ̂) (i.e., actually doing leave-one-out retraining).",4.1. Influence functions vs. leave-one-out retraining,[0],[0]
"With a logistic regression model on 10-class MNIST,4 the predicted and actual changes matched closely (Fig 2-Left).
",4.1. Influence functions vs. leave-one-out retraining,[0],[0]
"The stochastic approximation from Agarwal et al. (2016) was also accurate with r = 10 repeats and t = 5, 000 iterations (Fig 2-Mid).",4.1. Influence functions vs. leave-one-out retraining,[0],[0]
"Since each iteration only requires one HVP [∇2θL(zi, θ̂)]v, this runs quickly: in fact, we accurately estimated H−1v without even looking at every data point, since n = 55, 000 > rt.",4.1. Influence functions vs. leave-one-out retraining,[0],[0]
"Surprisingly, even r = 1 worked; while results were noisier, it was still able to identify the most influential points.",4.1. Influence functions vs. leave-one-out retraining,[0],[0]
"In Section 2, we took θ̂ as the global minimum.",4.2. Non-convexity and non-convergence,[0],[0]
"In practice, if we obtain our parameters θ̃ by running SGD with early stopping or on non-convex objectives, θ̃ 6= θ̂. As a result, Hθ̃ could have negative eigenvalues.",4.2. Non-convexity and non-convergence,[0],[0]
"We show that influence functions on θ̃ still give meaningful results in practice.
",4.2. Non-convexity and non-convergence,[0],[0]
"Our approach is to form a convex quadratic approximation of the loss around θ̃, i.e., L̃(z, θ) = L(z, θ̃) + ∇L(z, θ̃)>(θ− θ̃)+ 12 (θ− θ̃)
>(Hθ̃+λI)(θ− θ̃).",4.2. Non-convexity and non-convergence,[0],[0]
"Here, λ is a damping term that we add ifHθ̃ has negative eigenvalues;
4We trained with L-BFGS (Liu & Nocedal, 1989), with L2 regularization of 0.01, n = 55, 000, and p = 7, 840 parameters.
",4.2. Non-convexity and non-convergence,[0],[0]
this corresponds to adding L2 regularization on the parameters.,4.2. Non-convexity and non-convergence,[0],[0]
"We then calculate Iup,loss using L̃.",4.2. Non-convexity and non-convergence,[0],[0]
"If θ̃ is close to a local minimum, this is correlated with the result of taking a Newton step from θ̃ after removing weight from z (see appendix B).
",4.2. Non-convexity and non-convergence,[0],[0]
"We checked the behavior of Iup,loss in a non-convergent, non-convex setting by training a convolutional neural network for 500k iterations.5",4.2. Non-convexity and non-convergence,[0],[0]
"The model had not converged and Hθ̃ was not PD, so we added a damping term with λ = 0.01.",4.2. Non-convexity and non-convergence,[0],[0]
"Even in this difficult setting, the predicted and actual changes in loss were highly correlated (Pearson’s R = 0.86, Fig 2-Right).",4.2. Non-convexity and non-convergence,[0],[0]
"What happens when the derivatives of the loss, ∇θL and ∇2θL, do not exist?",4.3. Non-differentiable losses,[0],[0]
"In this section, we show that influence functions computed on smooth approximations to non-differentiable losses can predict the behavior of the original, non-differentiable loss under leave-one-out retraining.",4.3. Non-differentiable losses,[0],[0]
"The robustness of this approximation suggests that we can train non-differentiable models and swap out non-differentiable components for smoothed versions for the purposes of calculating influence.
",4.3. Non-differentiable losses,[0],[0]
"To see this, we trained a linear SVM on the same 1s vs. 7s MNIST task in Section 2.3.",4.3. Non-differentiable losses,[0],[0]
"This involves minimizing Hinge(s) = max(0, 1 − s); this simple piece-
5The network had 7 sets of convolutional layers with tanh(·) non-linearities, modeled after the all-convolutional network from (Springenberg et al., 2014).",4.3. Non-differentiable losses,[0],[0]
"For speed, we used 10% of the MNIST training set and only 2,616 parameters, since repeatedly retraining the network was expensive.",4.3. Non-differentiable losses,[0],[0]
"Training was done with mini-batches of 500 examples and the Adam optimizer (Kingma & Ba, 2015).",4.3. Non-differentiable losses,[0],[0]
"The model had not converged after 500k iterations; training it for another 500k iterations, using a full training pass for each iteration, reduced train loss from 0.14 to 0.12.
",4.3. Non-differentiable losses,[0],[0]
"wise linear function is similar to ReLUs, which cause nondifferentiability in neural networks.",4.3. Non-differentiable losses,[0],[0]
"We set the derivatives at the hinge to 0 and calculated Iup,loss.",4.3. Non-differentiable losses,[0],[0]
"As one might expect, this was inaccurate (Fig 3b-Left): the second derivative carries no information about how close a support vector z is to the hinge, so the quadratic approximation of L(z, θ̂) is linear, which leads to Iup,loss(z, ztest) overestimating the influence of z.
For the purposes of calculating influence, we approximated Hinge(s) with SmoothHinge(s, t) =",4.3. Non-differentiable losses,[0],[0]
"t log(1+exp( 1−st )), which approaches the hinge loss as t → 0 (Fig 3a).",4.3. Non-differentiable losses,[0],[0]
"Using the same SVM weights as before, we found that calculating Iup,loss using SmoothHinge(s, 0.001) closely matched the actual change due to retraining in the original Hinge(s) (Pearson’s R = 0.95; Fig 3b-Mid) and remained accurate over a wide range of t (Fig 3b-Right).",4.3. Non-differentiable losses,[0],[0]
"By telling us the training points “responsible” for a given prediction, influence functions reveal insights about how models rely on and extrapolate from the training data.",5.1. Understanding model behavior,[0],[0]
"In this section, we show that two models can make the same correct predictions but get there in very different ways.
",5.1. Understanding model behavior,[0],[0]
"We compared (a) the state-of-the-art Inception v3 network (Szegedy et al., 2016) with all but the top layer frozen6 and (b) an SVM with an RBF kernel on a dog vs. fish image classification dataset we extracted from ImageNet (Russakovsky et al., 2015), with 900 training examples for each class.",5.1. Understanding model behavior,[0],[0]
"Freezing neural networks in this way is not uncommon in computer vision and is equivalent to training a
6We used pre-trained weights from Keras (Chollet, 2015).
",5.1. Understanding model behavior,[0],[0]
"logistic regression model on the bottleneck features (Donahue et al., 2014).",5.1. Understanding model behavior,[0],[0]
"We picked a test image both models got correct (Fig 4-Top) and used SmoothHinge(·, 0.001) to compute the influence for the SVM.
",5.1. Understanding model behavior,[0],[0]
"As expected, Iup,loss in the RBF SVM varied inversely with raw pixel distance, with training images far from the test image in pixel space having almost no influence; the Inception influences were much less correlated with distance in pixel space (Fig 4-Left).",5.1. Understanding model behavior,[0],[0]
"Looking at the two most helpful images (most positive −Iup,loss) for each model in Fig 4-Right, we see that the Inception network picked on the distinctive characteristics of clownfish, whereas the RBF SVM pattern-matched training images superficially.
",5.1. Understanding model behavior,[0],[0]
"Moreover, in the RBF SVM, fish (green points) close to the test image were mostly helpful, while dogs (red) were mostly harmful, with the RBF acting as a soft nearest neighbor function (Fig 4-Left).",5.1. Understanding model behavior,[0],[0]
"In contrast, in the Inception network, fish and dogs could be helpful or harmful for correctly classifying the test image as a fish; in fact, the 5th most helpful training image was a dog that, to the model, looked very different from the test fish (Fig 4-Top).",5.1. Understanding model behavior,[0],[0]
"In this section, we show that models that place a lot of influence on a small number of points can be vulnerable to training input perturbations, posing a serious security risk in real-world ML systems where attackers can influence the training data (Huang et al., 2011).",5.2. Adversarial training examples,[0],[0]
"Recent work has generated adversarial test images that are visually indistinguish-
able from real test images but completely fool a classifier (Goodfellow et al., 2015; Moosavi-Dezfooli et al., 2016).",5.2. Adversarial training examples,[0],[0]
We demonstrate that influence functions can be used to craft adversarial training images that are similarly visuallyindistinguishable and can flip a model’s prediction on a separate test image.,5.2. Adversarial training examples,[0],[0]
"To the best of our knowledge, this is the first proof-of-concept that visually-indistinguishable training attacks can be executed on otherwise highly-accurate neural networks.
",5.2. Adversarial training examples,[0],[0]
"The key idea is that Ipert,loss(z, ztest) tells us how to modify training point z to most increase the loss on ztest.",5.2. Adversarial training examples,[0],[0]
"Concretely, for a target test image ztest, we can construct z̃i, an adversarial version of a training image zi, by initializing z̃i",5.2. Adversarial training examples,[0],[0]
:= zi and then iterating z̃i,5.2. Adversarial training examples,[0],[0]
":= Π(z̃i + α sign(Ipert,loss(z̃i, ztest))), where α is a step size and Π projects onto the set of valid images that share the same 8- bit representation with zi.",5.2. Adversarial training examples,[0],[0]
"After each iteration, we retrain the model.",5.2. Adversarial training examples,[0],[0]
"This is an iterated, training-set analogue of the methods used by, e.g., Goodfellow et al. (2015); MoosaviDezfooli et al. (2016) for test-set attacks.
",5.2. Adversarial training examples,[0],[0]
"We tested these adversarial training perturbations on the same Inception network on dogs vs. fish from Section 5.1, choosing this pair of animals to provide a stark contrast between the classes.",5.2. Adversarial training examples,[0],[0]
We set α = 0.02 and ran the attack for 100 iterations on each test image.,5.2. Adversarial training examples,[0],[0]
"As before, we froze all but the top layer for training; note that computing Ipert,loss still involves differentiating through the entire network.",5.2. Adversarial training examples,[0],[0]
"Originally, the model correctly classified 591 / 600 test images.",5.2. Adversarial training examples,[0],[0]
"For each of these 591 test images, considered separately, we tried to find a visually-indistinguishable perturbation (i.e., same 8-bit representation) to a single training image, out of 1,800 total training images, that would flip the model’s prediction.",5.2. Adversarial training examples,[0],[0]
We were able to do this on 335 (57%) of the 591 test images.,5.2. Adversarial training examples,[0],[0]
"If we perturbed 2 training images for each test image, we could flip predictions on 77% of the 591 test images; and if we perturbed 10 training images, we could flip all but 1 of the 591.",5.2. Adversarial training examples,[0],[0]
"The above results are from attacking each test image separately, i.e., we use a different training set to attack each test image.",5.2. Adversarial training examples,[0],[0]
"We next tried to attack multiple test images simultaneously by increasing their average test loss, and found that single training image perturbations could simultaneously flip multiple test predictions as well (Fig 5).
",5.2. Adversarial training examples,[0],[0]
We make three observations about these attacks.,5.2. Adversarial training examples,[0],[0]
"First, though the change in pixel values is small, the change in the final Inception feature layer is significantly larger: in pixel space and using L2 distance, the training values change by less than 1% of the mean distance of a training point to the class centroid, whereas in Inception feature space, the change is on the same order as the mean distance.",5.2. Adversarial training examples,[0],[0]
"Second, the attack tries to perturb the training example in a direction of low variance, causing the model to overfit in that
direction and consequently incorrectly classify the test images; we expect the attack to become harder as the number of training examples grows.",5.2. Adversarial training examples,[0],[0]
"Third, ambiguous or mislabeled training images are effective points to attack, since the model has low confidence and thus high loss on them, making them highly influential (recall Section 2.3).",5.2. Adversarial training examples,[0],[0]
"For example, the image in Fig 5 contains both a dog and a fish and is highly ambiguous; as a result, it is the training example that the model is least confident on (with a confidence of 77%, compared to the next lowest confidence of 90%).
",5.2. Adversarial training examples,[0],[0]
This attack is mathematically equivalent to the gradientbased training set attacks explored by Biggio et al. (2012); Mei & Zhu (2015b) and others in the context of different models.,5.2. Adversarial training examples,[0],[0]
"Biggio et al. (2012) constructed a dataset poisoning attack against a linear SVM on a two-class MNIST task, but had to modify the training points in an obviously distinguishable way to be effective.",5.2. Adversarial training examples,[0],[0]
"Measuring the magnitude of Ipert,loss gives model developers a way of quantifying how vulnerable their models are to training-set attacks.",5.2. Adversarial training examples,[0],[0]
"Domain mismatch — where the training distribution does not match the test distribution — can cause models with high training accuracy to do poorly on test data (Ben-David et al., 2010).",5.3. Debugging domain mismatch,[0],[0]
"We show that influence functions can identify the training examples most responsible for the errors, helping model developers identify domain mismatch.
",5.3. Debugging domain mismatch,[0],[0]
"As a case study, we predicted whether a patient would be readmitted to a hospital.",5.3. Debugging domain mismatch,[0],[0]
"Domain mismatches are common in biomedical data; for example, different hospitals can serve very different populations, and readmission models trained on one population can do poorly on another (Kansagara et al., 2011).",5.3. Debugging domain mismatch,[0],[0]
"We used logistic regression to predict readmission with a balanced training dataset of 20K diabetic patients from 100+ US hospitals, each represented by 127 features (Strack et al., 2014).7
7Hospital readmission was defined as whether a patient would be readmitted within the next 30 days.",5.3. Debugging domain mismatch,[0],[0]
"Features were demo-
3 out of the 24 children under age 10 in this dataset were re-admitted.",5.3. Debugging domain mismatch,[0],[0]
"To induce a domain mismatch, we filtered out 20 children who were not re-admitted, leaving 3 out of 4 readmitted.",5.3. Debugging domain mismatch,[0],[0]
This caused the model to wrongly classify many children in the test set.,5.3. Debugging domain mismatch,[0],[0]
"Our aim is to identify the 4 children in the training set as being “responsible” for these errors.
",5.3. Debugging domain mismatch,[0],[0]
"As a baseline, we tried the common practice of looking at the learned parameters θ̂ to see if the indicator variable for being a child was obviously different.",5.3. Debugging domain mismatch,[0],[0]
"However, this did not work: 14/127 features had a larger coefficient.
",5.3. Debugging domain mismatch,[0],[0]
"Picking a random child ztest that the model got wrong, we calculated−Iup,loss(zi, ztest) for each training point zi.",5.3. Debugging domain mismatch,[0],[0]
"This clearly highlighted the 4 training children, each of whom were 30-40 times as influential as the next most influential examples.",5.3. Debugging domain mismatch,[0],[0]
"The 1 child in the training set who was not readmitted had a very positive influence, while the other 3 had very negative influences.",5.3. Debugging domain mismatch,[0],[0]
"Calculating Ipert,loss on these 4 children showed that a change in the ‘child’ indicator variable had by far the largest effect on Iup,loss.",5.3. Debugging domain mismatch,[0],[0]
"Labels in the real world are often noisy, especially if crowdsourced (Frénay & Verleysen, 2014), and can even be adversarially corrupted, as in Section 5.2.",5.4. Fixing mislabeled examples,[0],[0]
"Even if a human expert could recognize wrongly labeled examples, it is impossible in many applications to manually review all of the training data.",5.4. Fixing mislabeled examples,[0],[0]
"We show that influence functions can help human experts prioritize their attention, allowing them to inspect only the examples that actually matter.
",5.4. Fixing mislabeled examples,[0],[0]
The key idea is to flag the training points that exert the most influence on the model.,5.4. Fixing mislabeled examples,[0],[0]
"Because we do not have access to the test set, we measure the influence of zi with Iup,loss(zi, zi), which approximates the error incurred on zi if we remove zi from the training set.
",5.4. Fixing mislabeled examples,[0],[0]
"Our case study is email spam classification, which relies
graphic (e.g., age, race, gender), administrative (e.g., length of hospital stay), or medical (e.g., test results).
on user-provided labels and is also vulnerable to adversarial attack (Biggio et al., 2011).",5.4. Fixing mislabeled examples,[0],[0]
"We flipped the labels of a random 10% of the training data and then simulated manually inspecting a fraction of the training points, correcting them if they had been flipped.",5.4. Fixing mislabeled examples,[0],[0]
"Using influence functions to prioritize the training points to inspect allowed us to repair the dataset (Fig 6, blue) without checking too many points, outperforming the baselines of checking points with the highest train loss (Fig 6, green) or at random (Fig 6, red).",5.4. Fixing mislabeled examples,[0],[0]
No method had access to the test data.,5.4. Fixing mislabeled examples,[0],[0]
"The use of influence-based diagnostics originated in statistics in the 70s, driven by the seminal papers of Hampel (1974) and Jaeckel (1972) (where it was called the infinitesimal jackknife).",6. Related work,[0],[0]
"It was further developed in the book by Hampel et al. (1986) and many other contemporary papers (Cook, 1977; Cook & Weisberg, 1980; Pregibon et al., 1981; Cook & Weisberg, 1982).",6. Related work,[0],[0]
"Earlier work focused on removing training points from linear models, with later work extending this to more general models and a wider variety of perturbations (Hampel et al., 1986; Cook, 1986; Thomas & Cook, 1990; Chatterjee & Hadi, 1986; Wei et al., 1998).",6. Related work,[0],[0]
"Prior work mostly focused on experiments with small datasets, e.g., n = 24 and p = 10 in Cook & Weisberg (1980), and thus paid special attention to exact solutions, or if not possible, characterizations of the error terms.
",6. Related work,[0],[0]
"Influence functions have not been used much in the ML literature, with some exceptions.",6. Related work,[0],[0]
Christmann & Steinwart (2004); Debruyne et al. (2008); Liu et al. (2014) use influence functions to study model robustness and to do fast cross-validation in kernel methods.,6. Related work,[0],[0]
"Wojnowicz et al. (2016) use matrix sketching to estimate Cook’s distance,
which is closely related to influence; they focus on prioritizing training points for human attention and derive methods specific to generalized linear models.",6. Related work,[0],[0]
"Kabra et al. (2015) define a different notion of influence that is specialized to finite hypothesis classes.
",6. Related work,[0],[0]
"As noted in Section 5.2, our training-set attack is mathematically equivalent to an approach first explored by Biggio et al. (2012) in the context of SVMs, with follow-up work extending the framework and applying it to linear and logistic regression (Mei & Zhu, 2015b), topic modeling (Mei & Zhu, 2015a), and collaborative filtering (Li et al., 2016a).",6. Related work,[0],[0]
"These papers derived the attack directly from the KKT conditions without considering influence, though for continuous data, the end result is equivalent.",6. Related work,[0],[0]
"Influence functions additionally let us consider attacks on discrete data (Section 2.2), but we have not tested this empirically.",6. Related work,[0],[0]
"Our work connects the literature on trainingset attacks with work on “adversarial examples” (Goodfellow et al., 2015; Moosavi-Dezfooli et al., 2016), visuallyimperceptible perturbations on test inputs.
",6. Related work,[0],[0]
"In contrast to training-set attacks, Cadamuro et al. (2016) consider the task of taking an incorrect test prediction and finding a small subset of training data such that changing the labels on this subset makes the prediction correct.",6. Related work,[0],[0]
They provide a solution for OLS and Gaussian process models when the labels are continuous.,6. Related work,[0],[0]
Our work with influence functions allow us to solve this problem in a much larger range of models and in datasets with discrete labels.,6. Related work,[0],[0]
"We have discussed a variety of applications, from creating training-set attacks to debugging models and fixing datasets.",7. Discussion,[0],[0]
"Underlying each of these applications is a common tool, influence functions, which are based on a simple idea—we can better understand model behavior by looking at how it was derived from its training data.
",7. Discussion,[0],[0]
"At their core, influence functions measure the effect of local changes: what happens when we upweight a point by an infinitesimally-small ?",7. Discussion,[0],[0]
"This locality allows us to derive efficient closed-form estimates, and as we show, they can be surprisingly effective.",7. Discussion,[0],[0]
"However, we might want to ask about more global changes, e.g., how does a subpopulation of patients from this hospital affect the model?",7. Discussion,[0],[0]
"Since influence functions depend on the model not changing too much, how to tackle this is an open question.
",7. Discussion,[0],[0]
"It seems inevitable that high-performing, complex, blackbox models will become increasingly prevalent and important.",7. Discussion,[0],[0]
"We hope that the approach presented here—of looking at the model through the lens of the training data—will become a standard part of the toolkit of developing, understanding, and diagnosing machine learning.
",7. Discussion,[0],[0]
Reproducibility The code and data for replicating our experiments is available on GitHub http://bit.ly/gt-influence and Codalab http://bit.ly/cl-influence.,7. Discussion,[0],[0]
"We thank Jacob Steinhardt, Zhenghao Chen, and Hongseok Namkoong for helpful discussions and comments.",Acknowledgements,[0],[0]
"We are also grateful to Doug Martin, Swee Keat Lim, and Teresa Yeo for finding typos and omissions in a previous version of the manuscript.",Acknowledgements,[0],[0]
"This work was supported by a Future of Life Research Award and a Microsoft Research Faculty Fellowship.
A.",Acknowledgements,[0],[0]
"Deriving the influence function Iup,params For completeness, we provide a standard derivation of the influence function Iup,params in the context of loss minimization (M-estimation).",Acknowledgements,[0],[0]
"This derivation is based on asymptotic arguments and is not fully rigorous; see van der Vaart (1998) and other statistics textbooks for a more thorough treatment.
",Acknowledgements,[0],[0]
"Recall that θ̂ minimizes the empirical risk:
R(θ) def =
1
n n∑ i=1",Acknowledgements,[0],[0]
"L(zi, θ).",Acknowledgements,[0],[0]
"(6)
We further assume that R is twice-differentiable and strongly convex in θ, i.e.,
Hθ̂ def = ∇2R(θ̂) = 1
n n∑ i=1 ∇2θL(zi, θ̂) (7)
exists and is positive definite.",Acknowledgements,[0],[0]
"This guarantees the existence of H−1
θ̂ , which we will use in the subsequent derivation.
",Acknowledgements,[0],[0]
"The perturbed parameters θ̂ ,z can be written as
θ̂ ,z = arg min θ∈Θ {R(θ) + L(z, θ)} .",Acknowledgements,[0],[0]
"(8)
Define the parameter change ∆ = θ̂ ,z",Acknowledgements,[0],[0]
"− θ̂,",Acknowledgements,[0],[0]
"and note that, as θ̂ doesn’t depend on , the quantity we seek to compute can be written in terms of it:
dθ̂ ,z d =",Acknowledgements,[0],[0]
d∆ d .,Acknowledgements,[0],[0]
"(9)
Since θ̂ ,z is a minimizer of (8), let us examine its firstorder optimality conditions:
0 = ∇R(θ̂ ,z) + ∇L(z, θ̂ ,z).",Acknowledgements,[0],[0]
"(10)
Next, since θ̂ ,z → θ̂ as → 0, we perform a Taylor expansion of the right-hand side:
0",Acknowledgements,[0],[0]
"≈ [ ∇R(θ̂) + ∇L(z, θ̂) ]",Acknowledgements,[0],[0]
"+ (11)[
∇2R(θ̂) + ∇2L(z, θ̂) ] ∆ ,
where we have dropped o(‖∆ ‖) terms.
",Acknowledgements,[0],[0]
"Solving for ∆ , we get: ∆",Acknowledgements,[0],[0]
"≈− [ ∇2R(θ̂) + ∇2L(z, θ̂) ]−1 (12)[
∇R(θ̂) + ∇L(z, θ̂) ] .
",Acknowledgements,[0],[0]
"Since θ̂ minimizes R, we have ∇R(θ̂) = 0.",Acknowledgements,[0],[0]
"Dropping o( ) terms, we have
∆ ≈−∇2R(θ̂)−1∇L(z, θ̂) .",Acknowledgements,[0],[0]
"(13)
Combining with (7) and (9), we conclude that:
dθ̂ ,z d ∣∣∣ =0 = −H−1 θ̂ ∇L(z, θ̂) (14)
def = Iup,params(z).",Acknowledgements,[0],[0]
"(15)
B. Influence at non-convergence Consider a training point z.",Acknowledgements,[0],[0]
"When the model parameters θ̃ are close to but not at a local minimum, Iup,params(z) is approximately equal to a constant (which does not depend on z) plus the change in parameters after upweighting z and then taking a single Newton step from θ̃.",Acknowledgements,[0],[0]
"The high-level idea is that even though the gradient of the empirical risk at θ̃ is not 0, the Newton step from θ̃ can be decomposed into a component following the existing gradient (which does not depend on the choice of z) and a second component responding to the upweighted z (which Iup,params(z) tracks).
",Acknowledgements,[0],[0]
Let g def=,Acknowledgements,[0],[0]
1n,Acknowledgements,[0],[0]
"∑n i=1∇θL(zi, θ̃) be the gradient of the empirical risk at θ̃; since θ̃ is not a local minimum, g 6= 0.",Acknowledgements,[0],[0]
"After upweighting z by , the gradient at θ̃ goes from g 7→ g + ∇θL(z, θ̃), and the empirical Hessian goes from Hθ̃ 7→ Hθ̃",Acknowledgements,[0],[0]
"+ ∇2θL(z, θ̃).",Acknowledgements,[0],[0]
"A Newton step from θ̃ therefore changes the parameters by:
N ,z def = −",Acknowledgements,[0],[0]
[ Hθ̃ + ∇ 2,Acknowledgements,[0],[0]
"θL(z, θ̃) ]−1",Acknowledgements,[0],[0]
"[ g + ∇θL(z, θ̃) ] .
(16)
Ignoring terms in g, 2, and higher, we get N ,z",Acknowledgements,[0],[0]
"≈ −H−1
θ̃
( g + ∇θL(z, θ̃) ) .",Acknowledgements,[0],[0]
"Therefore, the actual change
due to a Newton step N ,z is equal to a constant −H−1θ̃ g (that doesn’t depend on z) plus times Iup,params(z) = −H−1
θ̃ ∇θL(z, θ̃) (which captures the contribution of z).",Acknowledgements,[0],[0]
How can we explain the predictions of a blackbox model?,abstractText,[0],[0]
"In this paper, we use influence functions — a classic technique from robust statistics — to trace a model’s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction.",abstractText,[0],[0]
"To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products.",abstractText,[0],[0]
"We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information.",abstractText,[0],[0]
"On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visuallyindistinguishable training-set attacks.",abstractText,[0],[0]
Understanding Black-box Predictions via Influence Functions,title,[0],[0]
"One method for interpreting deep neural networks (DNNs) is to examine model predictions for specific input examples, e.g. testing for shape bias as in Ritter et al. (2017).",1 Introduction,[0],[0]
"In the traditional classification task, the difficulty of the test set examples is not taken into account.",1 Introduction,[0],[0]
The number of correctlylabeled examples is tallied up and reported.,1 Introduction,[0],[0]
"However, we hypothesize that it may be worthwhile to use difficulty when evaluating DNNs.",1 Introduction,[0],[0]
"For example, what does it mean if a trained model answers the more difficult examples correctly, but cannot correctly classify what are seemingly simple cases?",1 Introduction,[0],[0]
"Recent work has shown that for NLP tasks such as Natural Language Inference (NLI), models can achieve strong results by simply using the hypothesis of a premise-hypothesis pair and ignoring the premise entirely (Gururangan et al., 2016; Tsuchiya, 2018; Poliak et al., 2018).
",1 Introduction,[0],[0]
In this work we consider understanding DNNs by looking at the difficulty of specific test set examples and comparing DNN performance under different training scenarios.,1 Introduction,[0],[0]
Do DNN models learn examples of varying difficulty at different rates?,1 Introduction,[0],[0]
"If
a model does well on hard examples and poor on easy examples, then can we say that it has really learned anything?",1 Introduction,[0],[0]
"In contrast, if a model does well on easy items, because a dataset is all easy, have we really “solved” anything?
",1 Introduction,[0],[0]
"To model difficulty we use Item Response Theory (IRT) from psychometrics (Baker and Kim, 2004).",1 Introduction,[0],[0]
IRT models characteristics such as difficulty and discrimination ability of specific examples (called “items”1) in order to estimate a latent ability trait of test-takers.,1 Introduction,[0],[0]
Here we use IRT to model the difficulty of test items to determine how DNNs learn items of varying difficulty.,1 Introduction,[0],[0]
IRT provides a well-studied methodology for modeling item difficulty as opposed to more heuristic-based difficulty estimates such as sentence length.,1 Introduction,[0],[0]
"IRT was previously used to build a new test set for the NLI task (Lalor et al., 2016) and show that model performance is dependent on test set difficulty.",1 Introduction,[0],[0]
"In this work we use IRT to probe specific items to try to analyze model performance at a more finegrained level, and expand the analysis to include the task of SA.
",1 Introduction,[0],[0]
We train three DNNs models with varying training set sizes to compare performance on two NLP tasks: NLI and Sentiment Analysis (SA).,1 Introduction,[0],[0]
Our experiments show that a DNN model’s likelihood of classifying an item correctly is dependent on the item’s difficulty.,1 Introduction,[0],[0]
"In addition, as the models are trained with more data, the odds of answering easy examples correctly increases at a faster rate than the odds of answering a difficult example correctly.",1 Introduction,[0],[0]
"That is, performance starts to look more human, in the sense that humans learn easy items faster than they learn hard items.
",1 Introduction,[0],[0]
That the DNNs are better at easy items than hard items seems intuitive but is a surprising and interesting result since the item difficulties are modeled from human data.,1 Introduction,[0],[0]
"There is no underlying reason
1For the remainder of the paper we will refer to a single test set example as an “item” for consistency.
",1 Introduction,[0],[0]
"ar X
iv :1
70 2.
04 81
1v 3
[ cs
.C",1 Introduction,[0],[0]
"L
] 7
S ep
2 01
8
that the DNNs would find items that are easy for humans inherently easy.",1 Introduction,[0],[0]
To our knowledge this is the first work to use a grounded measure of difficulty learned from human responses to understand DNN performance.,1 Introduction,[0],[0]
"Our contributions are as follows: (i) we use a well-studied methodology, IRT, to estimate item difficulty in two NLP tasks and show that this human-estimated difficulty is a useful predictor of DNN model performance, (ii) we show that as training size increases DNN performance trends towards expected human performance.2",1 Introduction,[0],[0]
"To model item difficulty we use the Three Parameter Logistic (3PL) model from IRT (Baker, 2001; Baker and Kim, 2004; Lalor et al., 2016).",2.1 Estimating Item Difficulty,[0],[0]
"The 3PL model in IRT models an individual’s latent ability (θ) on a task as a function of three item characteristics: discrimination ability (a), difficulty (b), and guessing (c).",2.1 Estimating Item Difficulty,[0],[0]
"For a particular item i, the probability that an individual j will answer item i correctly is a function of the individual’s ability and the three item characteristics:
pij(θj) = ci + 1− ci
1 + e−ai(θj−bi) (1)
where ai is the discrimination parameter (the value of the function slope at it’s steepest point), bi is the difficulty parameter (the value where pij(θj) = 0.5), and ci is the guessing parameter (the lower asymptote of the function).",2.1 Estimating Item Difficulty,[0],[0]
"For a set of items I and a set of individuals J , the likelihood of each individual in J’s responses to the items in I is:
L = J∏ j=1 I∏ i=1 pij(θj) yijqij(θj) (1−yij) (2)
where qij(θj) = 1− pij(θj) and yij = 1 if individual j answered item i correctly and yij = 0 otherwise.",2.1 Estimating Item Difficulty,[0],[0]
"Item parameters and individual ability are jointly estimated from a set of individuals’ response patterns using an Expectation-Maximization algorithm (Bock and Aitkin, 1981).
",2.1 Estimating Item Difficulty,[0],[0]
"In this work we focus on the difficulty parameter bi, which represents the latent ability level at which an individual has a 50% chance of answering item
2Code and data available at http://jplalor.github.io
i correctly.",2.1 Estimating Item Difficulty,[0],[0]
"Low values of bi are associated with easier items (since an individual with low ability has a 50% chance of answering correctly), and higher values of bi represent more difficult items.",2.1 Estimating Item Difficulty,[0],[0]
"To estimate item difficulties for NLI, we used the pre-trained IRT models of Lalor et al. (2016) and extracted the difficulty item parameters.",2.2 Data,[0],[0]
"The data consists of approximately 1000 human annotator responses from Amazon Mechanical Turk (AMT) for a selection of 180 premise-hypothesis pairs from the SNLI data set (Bowman et al., 2015).",2.2 Data,[0],[0]
"Each AMT worker (Turker) was shown the premisehypothesis pairs and was asked to indicate whether, if the premise was taken to be true, the hypothesis was (a) definitely true (entailment), (b) maybe true (neutral), or (c) definitely not true (contradiction).
",2.2 Data,[0],[0]
"For SA, we collected a new data set of labels for 134 examples randomly selected from the Stanford Sentiment Treebank (SSTB) (Socher et al., 2013), using a similar AMT setup as Lalor et al. (2016).",2.2 Data,[0],[0]
"For each randomly selected example, we had 1000 Turkers label the sentence as very negative, negative, neutral, positive, or very positive.",2.2 Data,[0],[0]
"We converted these responses to binary positive/negative labels and fit a new IRT 3PL model (§2.1) using the mirt R package (Chalmers et al., 2015).",2.2 Data,[0],[0]
"Very negative and negative labels were binned together, and neutral, positive, and very positive were binned together.
",2.2 Data,[0],[0]
"Tables 1 and 2 show examples of the items in our data sets, and the difficulty values estimated from the IRT models.",2.2 Data,[0],[0]
"The first example in Table 1 is a clear case of entailment, where if we assume that the premise is true, we can infer that the hypothesis is also true.",2.2 Data,[0],[0]
"The label of the second example in SNLI is contradiction, but in this case the result is not as clear.",2.2 Data,[0],[0]
"There are sports stadiums that offer lawn seating, and therefore this could potentially be a case of entailment (or neutral).",2.2 Data,[0],[0]
"Either way, one could argue that the second example here is more difficult than the first.",2.2 Data,[0],[0]
"Similarly, the first two examples of Table 2 are interesting.",2.2 Data,[0],[0]
Both of these items are labeled as negative examples in the data set.,2.2 Data,[0],[0]
"The first example is clear, but the second one is more ambiguous.",2.2 Data,[0],[0]
"It could be considered a mild complement, since the author still endorses renting the movie.",2.2 Data,[0],[0]
Therefore you could argue again that the second example is more difficult than the first.,2.2 Data,[0],[0]
"The learned difficulty parameters reflect this difference
in difficulty in both cases.",2.2 Data,[0],[0]
Inter-rater reliability scores for the collected annotations are showin in Table 3.,2.2 Data,[0],[0]
"Scores for the NLI annotations were calculated when the original dataset was collected and are reproduced here (Lalor et al., 2016).",2.2 Data,[0],[0]
Human annotations for the SA annotations were converted to binary before calculating the agreement.,2.2 Data,[0],[0]
"We see that the agreement scores are in the range of 0.4 to 0.6 which is considered moderate agreement (Landis and Koch, 1977).",2.2 Data,[0],[0]
With the large number of annotators it is to be expected that there is some disagreement in the labels.,2.2 Data,[0],[0]
"However this disagreement can be interpreted as varying difficulty of the items, which is what we expect when we fit the IRT models.",2.2 Data,[0],[0]
Our goal in this work is to understand how DNN performance on items of varying difficulty changes under different training scenarios.,2.3 Experiments,[0],[0]
"To test this, we trained three DNN models using subsets of the original SNLI and SSTB training data sets: (i) Long Short Term Memory Network (LSTM) (Bowman et al., 2015), (ii) Convolutional Neural Network (CNN) (Kim, 2014), and (iii) Neural Seman-
tic Encoder (NSE), a type of memory-augmented RNN (Munkhdalai and Yu, 2017).3 For each task (NLI and SA), we randomly sampled subsets of training data, from 100 examples up to and including the full training data sets.4",2.3 Experiments,[0],[0]
"We trained each model on the training data subsets, using the original development sets for early stopping to prevent overfitting.",2.3 Experiments,[0],[0]
"The IRT data with difficulty estimates were used as test sets for the trained models.
",2.3 Experiments,[0],[0]
"Once the models were trained and had classified the IRT data sets, we fit logistic regression models to predict whether a DNN model would label an item correctly, using the training set size and item difficulty as the dependent parameters.",2.3 Experiments,[0],[0]
Figure 1 plots the contour plots of our learned regression models.,3 Results,[0],[0]
"The top row plots results for the NLI task, and the bottom row plots results for the SA task.",3 Results,[0],[0]
"From left to right in both rows, the plots show results for the LSTM, CNN, and NSE models.",3 Results,[0],[0]
"In each plot, the x-axis is the training set size, the y-axis is the item difficulty, and the contour lines represent the log-odds that the DNN model would classify an item correctly.",3 Results,[0],[0]
"As the plots show, item difficulty has a clear effect on classification.",3 Results,[0],[0]
Easier items have higher odds of being classified correctly across all of the training set sizes.,3 Results,[0],[0]
"In addition, the slopes of the contour lines are steeper at lower levels of difficulty.",3 Results,[0],[0]
"This indicates that, moving left to right along the x-axis, a model’s odds of answering
3Please refer to the appendix for model details.",3 Results,[0],[0]
"4We sampled 100, 1000, 2000, 5000, 10000, 50000, 100000, 200000, and 500000 examples for NLI, and sampled 100, 1000, 5000, 10000, 50000, and 75000 examples for SA.
an easy item correctly increase more quickly than the odds of answering a harder item correctly.
",3 Results,[0],[0]
"The contour plots for the CNN and NSE models on the SA task (Figure 1, second row middle and right plots) show that the easier items have higher likelihood of being classified correctly, but the odds for the most difficult items decrease as training size increases.",3 Results,[0],[0]
This suggests that these models are learning in such a way that improves performance on easy items but has a negative effect on hard items.,3 Results,[0],[0]
"This result is important for interpretability, as it could inform stakeholder decisions if they need to have difficult examples classified.
",3 Results,[0],[0]
The idea that easy items should be easier than hard items is consistent with learning strategies in humans.,3 Results,[0],[0]
"For example, when teaching new concepts to students, easier concepts are presented first so that the students can learn patterns and core information before moving to more difficult concepts (Collins et al., 1988; Arroyo et al., 2010).",3 Results,[0],[0]
"As students do more examples, all questions get easier, but easy questions get easier at a faster rate.",3 Results,[0],[0]
"Our result is also consistent with the key assumptions of curriculum learning (Bengio et al., 2009).",3 Results,[0],[0]
Lalor et al. (2016) introduced the idea of applying IRT evaluation to NLP tasks.,4 Related Work,[0],[0]
"They built a set of scales using IRT for NLI and evaluated a single LSTM neural network to demonstrate the effectiveness of the evaluation, but did not evaluate other NLP models or tasks.",4 Related Work,[0],[0]
"Martı́nez-Plumed et al. (2016) consider IRT in the context of evaluating ML models, but they do not use a human population to calibrate the models, and obtain results that are difficult to interpret under IRT assumptions.
",4 Related Work,[0],[0]
"There has been work in the NLP community around modeling latent characteristics of data (Bruce and Wiebe, 1999) and annotators (Hovy et al., 2013), but none that apply the resulting metrics to interpret DNN models.",4 Related Work,[0],[0]
"Passonneau and Carpenter (2014) model the probability a label is correct with the probability of an annotator to label an item correctly according to the Dawid and Skene (1979) model, but do not consider difficulty or discriminatory ability of the data points.
",4 Related Work,[0],[0]
"One-shot learning is an attempt to build ML models that can generalize after being trained on one or a few examples of a class as opposed to a large
training set (Lake et al., 2013).",4 Related Work,[0],[0]
"One-shot learning attempts to mimic human learning behaviors (i.e., generalization after being exposed to a small number of training examples) (Lake et al., 2016).",4 Related Work,[0],[0]
"Our work instead looks at comparisons to human performance, where any learning (on the part of models) has been completed beforehand.",4 Related Work,[0],[0]
Our goal is to analyze DNN models and training set variations as they affect ability in the context of IRT.,4 Related Work,[0],[0]
In this work we have shown that DNN model performance is affected by item difficulty as well as training set size.,5 Discussion,[0],[0]
This is the first work that has used a well-established method for estimating difficulty to analyze DNN model performance as opposed to heuristics.,5 Discussion,[0],[0]
"DNN models perform better on easy items, and as more data is introduced in training, easy items are learned more quickly than hard items.",5 Discussion,[0],[0]
Learning easy examples faster than harder examples is what would be expected when examining human response patterns as they learn more about a subject.,5 Discussion,[0],[0]
"However this has not previously been shown to be true in DNN models.
",5 Discussion,[0],[0]
That the results are consistent across NLI and SA shows that the methods can be applied to a number of NLP tasks.,5 Discussion,[0],[0]
The SA results do show that the odds of labeling a difficult item correctly decrease with more training data 1.,5 Discussion,[0],[0]
"It could be the case that these difficult items in the SA task are more subjective than the easier items, for example a review that is fairly neutral and is split between positive and negative annotations.",5 Discussion,[0],[0]
"These cases would be more difficult for a model to label, and are worth examining in more detail.",5 Discussion,[0],[0]
"By identifying items such as these as difficult makes it easier to see where the model is going wrong and allows for research on better way to represent these cases.
",5 Discussion,[0],[0]
This result has implications for how machine learning models are evaluated across tasks.,5 Discussion,[0],[0]
"The traditional assumption that the test data is drawn from the same distribution as the training data, makes it difficult to understand how a model will perform in settings where that assumption does not hold.",5 Discussion,[0],[0]
"However, if the difficulty of test set data is known, we can better understand what kind of examples a given model performs well on, and specific instances where a model underperforms (e.g. the most difficult examples).",5 Discussion,[0],[0]
"In addition, researhers can build test sets that consist of a specific type of data (very easy, very hard, or a mix) to evalu-
ate a trained model under specific assumptions to test generalization ability in a controlled way.",5 Discussion,[0],[0]
"This could allow for more confidence in model performance in more varied deployment settings, since there would be a set of tests a model would have to pass before being deployed.
",5 Discussion,[0],[0]
"It is important to note that the difficulty parameters were estimated from a human population, meaning that those items that are difficult for humans are in fact more difficult for the DNN models as well.",5 Discussion,[0],[0]
"This does not need to be the case given that DNNs learn very different patterns, etc. than humans.",5 Discussion,[0],[0]
In fact there were exceptions in our results which shows that these models should be carefully examined using techniques like those described here.,5 Discussion,[0],[0]
Future work can investigate why this is the case and how we can leverage this information to improve model performance and interpretability.,5 Discussion,[0],[0]
We thank the AMT Turkers who completed our annotation task.,Acknowledgments,[0],[0]
This work was supported in part by the HSR&D award IIR 1I01HX001457 from the United States Department of Veterans Affairs (VA).,Acknowledgments,[0],[0]
We also acknowledge the support of LM012817 from the National Institutes of Health.,Acknowledgments,[0],[0]
This work was also supported in part by the Center for Intelligent Information Retrieval.,Acknowledgments,[0],[0]
"The contents of this paper do not represent the views of CIIR, NIH, VA, or the United States Government.",Acknowledgments,[0],[0]
Here we provide a brief overview of the model architectures for the deep neural network (DNN) models used in our experiments.,A DNN Model Architecture,[0],[0]
"For additional details we refer the reader to the original papers.
",A DNN Model Architecture,[0],[0]
"A.1 Long Short Term Memory
The Long Short Term Memory (LSTM) model used here was provided by (Bowman et al., 2015) with the release of the SNLI corpus.",A DNN Model Architecture,[0],[0]
"The model consists of two LSTM sequence-embedding models (Hochreiter and Schmidhuber, 1997), one to encode the premise and another to encode the hypothesis.",A DNN Model Architecture,[0],[0]
The two sentence encodings are then concatenated and passed through three tanh layers.,A DNN Model Architecture,[0],[0]
"Finally, the output is passed to a softmax classifier layer to output probabilities over the task classes.",A DNN Model Architecture,[0],[0]
"For SA, we kept the same architecture but used a single LSTM layer to encode the input text.
",A DNN Model Architecture,[0],[0]
"A.2 Convolutional Neural Network
We used the convolutional neural network (CNN) model of (Kim, 2014) in our experiments.",A DNN Model Architecture,[0],[0]
"For each input, the word vector representation of the input tokens were concatenated together to form a matrix.",A DNN Model Architecture,[0],[0]
"A series of convolutional operations were applied, followed by a max-pooling operation and a fully connected softmax classifier layer.",A DNN Model Architecture,[0],[0]
"More concretely, for an input sentence x, let xi be the word vector representation of the i-th word in x.",A DNN Model Architecture,[0],[0]
"The convolution operation of filter w over a window of length h starting with word xi results in a context vector ci:
ci = f(w · xi:i+h−1 + b) (3)
where b is a bias term (Kim, 2014).",A DNN Model Architecture,[0],[0]
"The filter is applied over all windows in the sentence to generate a feature-map, and max-pooling is used to identify the feature for this particular filter.",A DNN Model Architecture,[0],[0]
"The process is repeated with multiple filters, and the output features are then passed to a softmax classification layer to output probabilities over the class labels (Kim, 2014).",A DNN Model Architecture,[0],[0]
"For NLI, the premise and hypothesis sentences were concatenated before encoding.
",A DNN Model Architecture,[0],[0]
"A.3 Neural Semantic Encoder
Neural Semantic Encoder (NSE) is a memoryaugmented neural network that uses read, compose, and write operations to evolve and maintain an external memory (Munkhdalai and Yu, 2017):
ot = f LSTM r (xt) (4) zt = softmax(o > t Mt−1) (5)",A DNN Model Architecture,[0],[0]
"mr,t = z > t Mt−1 (6)
",A DNN Model Architecture,[0],[0]
"ct = f MLP c (ot,mr,t) (7) ht = f LSTM w (ct) (8)
Mt =Mt−1(1− (zt ⊗ ek)>)",A DNN Model Architecture,[0],[0]
+ (ht ⊗ el)(zt ⊗ ek)>,A DNN Model Architecture,[0],[0]
"(9)
where fLSTMr is the read function, f MLP c is the composition function, fLSTMw is the write function, Mt is the external memory at time t, and",A DNN Model Architecture,[0],[0]
el ∈ Rl and ek ∈,A DNN Model Architecture,[0],[0]
"Rk are vectors of ones (Munkhdalai and Yu, 2017).
",A DNN Model Architecture,[0],[0]
"For NLI, the premise and hypothesis sentences were each encoded with an NSE module.",A DNN Model Architecture,[0],[0]
The outputs were combined and passed through a softmax classifier layer to output probabilities.,A DNN Model Architecture,[0],[0]
"For SA, we kept the same architecture but used a single NSE layer to encode the input text.",A DNN Model Architecture,[0],[0]
Interpreting the performance of deep learning models beyond test set accuracy is challenging.,abstractText,[0],[0]
"Characteristics of individual data points are often not considered during evaluation, and each data point is treated equally.",abstractText,[0],[0]
We examine the impact of a test set question’s difficulty to determine if there is a relationship between difficulty and performance.,abstractText,[0],[0]
We model difficulty using well-studied psychometric methods on human response patterns.,abstractText,[0],[0]
Experiments on Natural Language Inference (NLI) and Sentiment Analysis (SA) show that the likelihood of answering a question correctly is impacted by the question’s difficulty.,abstractText,[0],[0]
"As DNNs are trained with more data, easy examples are learned more quickly than hard examples.",abstractText,[0],[0]
Understanding Deep Learning Performance through an Examination of Test Set Difficulty: A Psychometric Case Study,title,[0],[0]
"√ θ%̃/n) where θ
denotes freedom degree of the network parameters and %̃ = O(log(∏li=1 bi(ki − si + 1)/p) + log(bl+1)) encapsulates architecture parameters including the kernel size ki, stride si, pooling size p and parameter magnitude bi. To our best knowledge, this is the first generalization bound that only depends on O(log(∏l+1i=1 bi)), tighter than existing ones that all involve an exponential term likeO(∏l+1i=1 bi). Besides, we prove that for an arbitrary gradient descent algorithm, the computed approximate stationary point by minimizing empirical risk is also an approximate stationary point to the population risk. This well explains why gradient descent training algorithms usually perform sufficiently well in practice. Furthermore, we prove the one-to-one correspondence and convergence guarantees for the non-degenerate stationary points between the empirical and population risks. It implies that the computed local minimum for the empirical risk is also close to a local minimum for the population risk, thus ensuring the good generalization performance of CNNs.",text,[0],[0]
"Deep convolutional neural networks (CNNs) have been successfully applied to various fields, such as image classifica-
1Department of Electrical & Computer Engineering (ECE), National University of Singapore, Singapore.",1. Introduction,[0],[0]
"Correspondence to: Pan Zhou <pzhou@u.nus.edu>, Jiashi Feng <elefjia@nus.edu.sg>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
tion (Szegedy et al., 2015; He et al., 2016; Wang et al., 2017), speech recognition (Sainath et al., 2013; Abdel-Hamid et al., 2014), and classic games (Silver et al., 2016; Brown & Sandholm, 2017).",1. Introduction,[0],[0]
"However, theoretical analyses and understandings on deep CNNs still largely lag their practical applications.",1. Introduction,[0],[0]
"Recently, although many works establish theoretical understandings on deep feedforward neural networks (DNNs) from various aspects, e.g. (Neyshabur et al., 2015; Kawaguchi, 2016; Zhou & Feng, 2018; Tian, 2017; Lee et al., 2017), only a few (Sun et al., 2016; Kawaguchi et al., 2017; Du et al., 2017a;b) provide explanations on deep CNNs due to their more complex architectures and operations.",1. Introduction,[0],[0]
"Besides, these existing works all suffer certain discrepancy between their theories and practice.",1. Introduction,[0],[0]
"For example, the developed generalization error bound either exponentially grows along with the depth of a CNN model (Sun et al., 2016) or is data-dependent (Kawaguchi et al., 2017), and the convergence guarantees for optimization algorithms over CNNs are achieved by assuming an over-simplified CNN model consisting of only one non-overlapping convolutional layer (Du et al., 2017a;b).
",1. Introduction,[0],[0]
"As an attempt to explain the practical success of deep CNNs and mitigate the gap between theory and practice, this work aims to provide tighter data-independent generalization error bound and algorithmic optimization guarantees for the commonly used deep CNN models in practice.",1. Introduction,[0],[0]
"Specifically, we theoretically analyze the deep CNNs from following two aspects: (1) how their generalization performance varies with different network architecture choices and (2) why gradient descent based algorithms such as stochastic gradient descend (SGD) (Robbins & Monro, 1951), adam (Kingma & Ba, 2015) and RMSProp (Tieleman & Hinton, 2012), on minimizing empirical risk usually offer models with satisfactory performance.",1. Introduction,[0],[0]
"Moreover, we theoretically demonstrate the benefits of (stride) convolution and pooling operations, which are unique for CNNs, to the generalization performance, compared with feedforward networks.
",1. Introduction,[0],[0]
"Formally, we consider a CNN model g(w;D) parameterized by w ∈ Rd, consisting of l convolutional layers and one subsequent fully connected layer.",1. Introduction,[0],[0]
It maps the input D ∈ Rr0×c0 to an output vector v ∈ Rdl+1 .,1. Introduction,[0],[0]
"Its i-th convolutional layer takes Z(i−1) ∈ Rr̃i−1×c̃i−1×di−1 as input and outputs Z(i) ∈ Rr̃i×c̃i×di through spatial convolution, non-linear activation and pooling operations sequentially.
",1. Introduction,[0],[0]
"ar X
iv :1
80 5.
10 76
7v 1
[ cs
.L G
] 2
8 M
ay 2
01 8
Here r̃i × c̃i and di respectively denote resolution and the number of feature maps.",1. Introduction,[0],[0]
"Specifically, the computation with the i-th convolutional layer is described as
X(i)(:, :, j) = Z(i−1) ~W",1. Introduction,[0],[0]
"j(i) ∈ Rri×ci ,∀j = 1, · · · , di, Y(i) = σ1(X(i))",1. Introduction,[0],[0]
"∈ Rri×ci×di , Z(i) = pool ( Y(i) )",1. Introduction,[0],[0]
"∈ Rr̃i×c̃i×di ,
where X(i)(:, :, j) denotes the j-th feature map output by the i-th layer; W j(i) ∈ Rki×ki×di−1 denotes the j-th convolutional kernel of size ki×ki and there are in total di kernels in the i-th layer; ~, pool (·) and σ1(·) respectively denote the convolutional operation with stride si, pooling operation with window size p × p without overlap and the sigmoid function.",1. Introduction,[0],[0]
"In particular, Z(0) = D is the input sample.",1. Introduction,[0],[0]
"The last layer is a fully connected one and formulated as
u = W(l+1)z(l) ∈ Rdl+1 and v = σ2(u) ∈ Rdl+1 , where z(l) ∈ Rr̃lc̃ldl is vectorization of the output Z(l) of the last convolutional layer; W(l+1) ∈ Rdl+1×r̃lc̃ldl denotes the connection weight matrix; σ2(·) is a softmax activation function (for classification) and dl+1 is the class number.
",1. Introduction,[0],[0]
"In practice, a deep CNN model is trained by minimizing the following empirical risk in terms of squared loss on the training data pairs (D(i),y(i)) drawn from an unknown distribution D,
Q̃n(w) , 1
n
n∑
i=1
f(g(w;D(i)),y(i)), (1)
where f(g(w;D),y) = 12‖v",1. Introduction,[0],[0]
− y‖22 is the squared loss function.,1. Introduction,[0],[0]
One can obtain the model parameter w̃ via SGD or its variants like adam and RMSProp.,1. Introduction,[0],[0]
"However, this empirical solution is different from the desired optimum w∗ that minimizes the population risk:
Q(w) , E(D,y)∼D f(g(w;D),y).",1. Introduction,[0],[0]
"This raises an important question: why CNNs trained by minimizing the empirical risk usually perform well in practice, considering the high model complexity and nonconvexity?",1. Introduction,[0],[0]
"This work answers this question by (1) establishing the generalization performance guarantee for CNNs and (2) expounding why the computed solution w̃ by gradient descent based algorithms for minimizing the empirical risk usually performs sufficiently well in practice.
",1. Introduction,[0],[0]
"To be specific, we present three new theoretical guarantees for CNNs.",1. Introduction,[0],[0]
"First, we prove that the generalization error of deep CNNs decreases at the rate of O( √ θ%̃/(2n))",1. Introduction,[0],[0]
"where θ denotes parameter freedom degree1, and %̃ depends on the
1We use the terminology of “parameter freedom degree” here for characterizing redundancy of parameters.",1. Introduction,[0],[0]
"For example, for a rank-r matrix A ∈ Rm1×m2 , the parameter freedom degree in this work is r(m1 +m2 + 1) instead of the commonly used one r(m1 +m2 − r).
network architecture parameters including the convolutional kernel size ki, stride si, pooling size p, channel number di and parameter magnitudes.",1. Introduction,[0],[0]
"It is worth mentioning that our generalization error bound is the first one that does not exponentially grow with depth.
",1. Introduction,[0],[0]
"Secondly, we prove that for any gradient descent based optimization algorithm, e.g. SGD, RMSProp or adam, if its output w̃ is an approximate stationary point of the empirical risk Q̃n(w), w̃ is also an approximate stationary point of the population risk Q(w).",1. Introduction,[0],[0]
This result is important as it explains why CNNs trained by minimizing the empirical risk have good generalization performance on test samples.,1. Introduction,[0],[0]
"We achieve such results by analyzing the convergence behavior of the empirical gradient to its population counterpart.
",1. Introduction,[0],[0]
"Finally, we go further and quantitatively bound the distance between w̃ and w∗.",1. Introduction,[0],[0]
"We prove that when the samples are sufficient, a non-degenerate stationary point wn of Q̃n(w) uniquely corresponds to a non-degenerate stationary point w∗ of the population risk Q(w), with a distance shrinking at the rate of O((β/ζ) √ d%̃/n) where β also depends on the CNN architecture parameters (see Thereom 2).",1. Introduction,[0],[0]
Here ζ accounts for the geometric topology of non-degenerate stationary points.,1. Introduction,[0],[0]
"Besides, the corresponding pair (wn,w∗) shares the same geometrical property—if one in (wn,w∗) is a local minimum or saddle point, so is the other one.",1. Introduction,[0],[0]
"All these results guarantee that for an arbitrary algorithm provided with sufficient samples, if the computed w̃ is close to the stationary point wn, then w̃ is also close to the optimum w∗ and they share the same geometrical property.
",1. Introduction,[0],[0]
"To sum up, we make multiple contributions to understand deep CNNs theoretically.",1. Introduction,[0],[0]
"To our best knowledge, this work presents the first theoretical guarantees on both generalization error bound without exponential growth over network depth and optimization performance for deep CNNs.",1. Introduction,[0],[0]
"We substantially extend prior works on CNNs (Du et al., 2017a;b) from the over-simplified single-layer models to the multi-layer ones, which is of more practical significance.",1. Introduction,[0],[0]
"Our generalization error bound is much tighter than the one derived from Rademacher complexity (Sun et al., 2016) and is also independent of data and specific training procedure, which distinguishes it from (Kawaguchi et al., 2017).",1. Introduction,[0],[0]
"Recently, many works have been devoted to explaining the remarkable success of deep neural networks.",2. Related Works,[0],[0]
"However, most works only focus on analyzing fully feedforward networks from aspects like generalization performance (Bartlett & Maass, 2003; Neyshabur et al., 2015), loss surface (Saxe et al., 2014; Dauphin et al., 2014; Choromanska et al., 2015; Kawaguchi, 2016; Nguyen & Hein, 2017; Zhou & Feng, 2018), optimization algorithm convergence (Tian, 2017; Li
& Yuan, 2017) and expression ability (Eldan & Shamir, 2016; Soudry & Hoffer, 2017; Lee et al., 2017).
",2. Related Works,[0],[0]
"The literature targeting at analyzing CNNs is very limited, mainly because CNNs have much more complex architectures and computation.",2. Related Works,[0],[0]
"Among the few existing works, Du et al. (2017b) presented results for a simple and shallow CNN consisting of only one non-overlapping convolutional layer and ReLU activations, showing that gradient descent (GD) algorithms with weight normalization can converge to the global minimum.",2. Related Works,[0],[0]
"Similarly, Du et al. (2017a) also analyzed optimization performance of GD and SGD with nonGaussian inputs for CNNs with only one non-overlapping convolutional layer.",2. Related Works,[0],[0]
"By utilizing the kernel method, Zhang et al. (2017) transformed a CNN model into a single-layer convex model which has almost the same loss as the original CNN with high probability and proved that the transformed model has higher learning efficiency.
",2. Related Works,[0],[0]
"Regarding generalization performance of CNNs, Sun et al. (2016) provided the Rademacher complexity of a deep CNN model which is then used to establish the generalization error bound.",2. Related Works,[0],[0]
"But the Rademacher complexity exponentially depends on the magnitude of total parameters per layer, leading to loose results.",2. Related Works,[0],[0]
"In contrast, the generalization error bound established in this work is much tighter, as discussed in details in Sec. 3.",2. Related Works,[0],[0]
"Kawaguchi et al. (2017) introduced two generalization error bounds of CNN, but both depend on a specific dataset as they involve the validation error or the intermediate outputs for the network model on a provided dataset.",2. Related Works,[0],[0]
"They also presented dataset-independent generalization error bound, but with a specific two-phase training procedure required, where the second phase need fix the states of ReLU activation functions.",2. Related Works,[0],[0]
"However, such two-phase training procedure is not used in practice.
",2. Related Works,[0],[0]
There are also some works focusing on convergence behavior of nonconvex empirical risk of a single-layer model to the population risk.,2. Related Works,[0],[0]
Our proof techniques essentially differ from theirs.,2. Related Works,[0],[0]
"For example, (Gonen & Shalev-Shwartz, 2017) proved that the empirical risk converges to the population risk for those nonconvex problems with no degenerated saddle points.",2. Related Works,[0],[0]
"Unfortunately, due to existence of degenerated saddle points in deep networks (Dauphin et al., 2014; Kawaguchi, 2016), their results are not applicable here.",2. Related Works,[0],[0]
"A very recent work (Mei et al., 2017) focuses on single-layer nonconvex problems but requires the gradient and Hessian of the empirical risk to be strong sub-Gaussian and subexponential respectively.",2. Related Works,[0],[0]
"Besides, it assumes a linearity property for the gradient which hardly holds in practice.",2. Related Works,[0],[0]
"Comparatively, our assumptions are much milder.",2. Related Works,[0],[0]
We only assume magnitude of the parameters to be bounded.,2. Related Works,[0],[0]
"Furthermore, we also explore the parameter structures of optimized CNNs, i.e. the low-rankness property, and derive bounds matching empirical observations better.",2. Related Works,[0],[0]
"Finally, we analyze
the convergence rate of the empirical risk and generalization error of CNN which is absent in (Mei et al., 2017).
",2. Related Works,[0],[0]
"Our work is also critically different from the recent work (Zhou & Feng, 2018)",2. Related Works,[0],[0]
although we adopt a similar analysis road map with it.,2. Related Works,[0],[0]
Zhou & Feng (2018) analyzed DNNs while this work focuses on CNNs with more complex architectures and operations which are more challenging and requires different analysis techniques.,2. Related Works,[0],[0]
"Besides, this work provides stronger results in the sense of several tighter bounds with much milder assumptions.",2. Related Works,[0],[0]
"(1) For nonlinear DNNs, Zhou & Feng (2018) assumed the input data to be Gaussian, while this work gets rid of such a restrictive assumption.",2. Related Works,[0],[0]
"(2) The generalization error bound O(r̂l+1 √ d/n) in (Zhou & Feng, 2018) exponentially depends on the upper magnitude bound r̂ of the weight matrix per layer and linearly depends on the total parameter number d, while ours is O( √ θ%̃/n) which only depends on the logarithm term %̃ = log( ∏l+1 i=1 bi) and the freedom degree θ of the network parameters, where bi and bl+1 respectively denote the upper magnitude bounds of each kernel per layer and the weight matrix of the fully connected layer.",2. Related Works,[0],[0]
"Note, the exponential term O(r̂l+1) in (Zhou & Feng, 2018) cannot be further improved due to their proof techniques.",2. Related Works,[0],[0]
"The results on empirical gradient and stationary point pairs in (Zhou & Feng, 2018) rely on O(r̂2(l+1)), while ours is O(∏l+1i=1 bi) which only depends on bi instead of bi2.",2. Related Works,[0],[0]
"(3) This work explores the parameter structures, i.e. the low-rankness property, and derives tighter bounds as the parameter freedom degree θ is usually smaller than the total parameter number d.",2. Related Works,[0],[0]
"In this section, we present the generalization error bound for deep CNNs and reveal effects of different architecture parameters on their generalization performance, providing some principles on model architecture design.",3. Generalization Performance of Deep CNNs,[0],[0]
"We derive these results by establishing uniform convergence of the empirical risk Q̃n(w) to its population one Q(w).
",3. Generalization Performance of Deep CNNs,[0],[0]
We start with explaining our assumptions.,3. Generalization Performance of Deep CNNs,[0],[0]
"Similar to (Xu & Mannor, 2012; Tian, 2017; Zhou & Feng, 2018), we assume that the parameters of the CNN have bounded magnitude.",3. Generalization Performance of Deep CNNs,[0],[0]
"But we get rid of the Gaussian assumptions on the input data, meaning our assumption is milder than the ones in (Tian, 2017; Soudry & Hoffer, 2017; Zhou & Feng, 2018).",3. Generalization Performance of Deep CNNs,[0],[0]
Assumption 1.,3. Generalization Performance of Deep CNNs,[0],[0]
The magnitudes of the j-th kernel W j(i) ∈ Rki×ki×di−1 in the i-th convolutional layer and,3. Generalization Performance of Deep CNNs,[0],[0]
"the weight matrix W(l+1) ∈ Rdl+1×r̃lc̃ldl in the the fully connected layer are respectively bounded as follows
‖W j(i)‖F ≤bi (1≤j≤di;",3. Generalization Performance of Deep CNNs,[0],[0]
"1≤ i≤ l), ‖W(l+1)‖F ≤bl+1, where bi (1 ≤ i ≤ l) and bl+1 are positive constants.
",3. Generalization Performance of Deep CNNs,[0],[0]
"We also assume that the entry value of the target output y
always falls in [0, 1], which can be achieved by scaling the entry value in y conveniently.
",3. Generalization Performance of Deep CNNs,[0],[0]
"In this work, we also consider possible emerging structure of the learned parameters after training—the parameters usually present redundancy and low-rank structures (Lebedev et al., 2014; Jaderberg et al., 2014) due to high model complexity.",3. Generalization Performance of Deep CNNs,[0],[0]
"So we incorporate low-rankness of the parameters or more concretely the parameter matrix consisting of kernels per layer, into our analysis.",3. Generalization Performance of Deep CNNs,[0],[0]
"Denoting by vec(A) the vectorization of a matrix A, we have Assumption 2.
Assumption 2.",3. Generalization Performance of Deep CNNs,[0],[0]
Assume the matrices W̃(i) andW(l+1),3. Generalization Performance of Deep CNNs,[0],[0]
"obey
rank(W̃(i))",3. Generalization Performance of Deep CNNs,[0],[0]
≤ ai (1 ≤ i ≤ l) and rank(W(l+1)),3. Generalization Performance of Deep CNNs,[0],[0]
"≤ al+1,
where W̃(i) =",3. Generalization Performance of Deep CNNs,[0],[0]
"[vec(W 1(i)), vec(W 2 (i)), · · · , vec(W di(i))",3. Generalization Performance of Deep CNNs,[0],[0]
"] ∈ Rk2i di−1×di denotes the matrix consisting of all kernels in the i-th layer (1 ≤ i ≤ l).
",3. Generalization Performance of Deep CNNs,[0],[0]
"The parameter low-rankness can also be defined on kernels individually by using the tensor rank (Tucker, 1966; Zhou et al., 2017; Zhou & Feng, 2017).",3. Generalization Performance of Deep CNNs,[0],[0]
Our proof techniques are extensible to this case and similar results can be expected.,3. Generalization Performance of Deep CNNs,[0],[0]
We now proceed to establish generalization error bound for deep CNNs.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Let S = {(D(1),y(1)), · · · , (D(n),y(n))} denote the set of training samples i.i.d. drawn from D. When the optimal solution w̃ to problem (1) is computed by a deterministic algorithm, the generalization error is defined as g = ∣∣Q̃n(w̃)−Q(w̃) ∣∣.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"But in practice, a CNN model is usually optimized by randomized algorithms, e.g. SGD.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
So we adopt the following generalization error in expectation.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
Definition 1.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"(Generalization error) (Shalev-Shwartz et al., 2010)",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
Assume a randomized algorithm,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"A is employed for optimization over training samples S = {(D(1),y(1)), · · ·, (D(n),y(n))} ∼ D and w̃ = argminwQ̃n(w) is the empirical risk minimizer (ERM).",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
Then if we have ES∼D ∣∣EA(Q(w̃),3.1. Generalization Error Bound for Deep CNNs,[0],[0]
− Q̃n(w̃)) ∣∣,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"≤ k, the ERM is said to have generalization error with rate k under distribution D. We bound the generalization error in expectation for deep CNNs by first establishing uniform convergence of the empirical risk to its corresponding population risk, as stated in Lemma 1 with proof in Sec.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
D.1 in supplement.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
Lemma 1.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Assume that in CNNs, σ1 and σ2 are respectively the sigmoid and softmax activation functions and the loss function f(g(w;D),y) is squared loss.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Under Assumptions 1 and 2, if n ≥ cf ′ l2(bl+1",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"+∑l
i=1 dibi) 2 maxi √ rici/(θ%ε
2) where cf ′ is a universal constant, then with probability at least 1− ε, we have
sup w∈Ω
∣∣∣Q̃n(w)−Q(w) ∣∣∣ ≤
√ θ%+ log ( 4 ε )
",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"2n , (2)
where the total freedom degree θ of the network is θ = al+1(dl+1 + r̃lc̃ldl + 1) + ∑l i=1 ai(ki 2di−1 + di + 1) and % = ∑l i=1log (√dibi(ki−si+1) 4p ) + log(bl+1)",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"+ log ( n 128p2 ) .
",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"To our best knowledge, this generalization error rate is the first one that grows linearly (in contrast to exponentially) with depth",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
l without needing any special training procedure.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"This can be observed from the fact that our result only depends on O(∑li=1 log(bi)), rather than an exponential factor O(∏l+1i=1 bi) which appears in some existing works, e.g. the uniform convergence of the empirical risk in deep CNNs (Sun et al., 2016) and fully feedforward networks (Bartlett & Maass, 2003; Neyshabur et al., 2015; Zhou & Feng, 2018).",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"This faster convergence rate is achieved by adopting similar analysis technique in (Mei et al., 2017; Zhou & Feng, 2018) but we derive tighter bounds on the related parameters featuring distributions of the empirical risk and its gradient, with milder assumptions.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"For instance, both (Zhou & Feng, 2018) and this work show that the empirical risk follows a sub-Gaussian distribution.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
But Zhou & Feng (2018) used Gaussian concentration inequality and thus need Lipschitz constant of loss which exponentially depends on the depth.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"In contrast, we use -net to decouple the dependence between input D and parameter w and then adopt Hoeffding’s inequality, only requiring the constant magnitude bound of loss and geting rid of exponential term.
",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Based on Lemma 1, we derive generalization error of deep CNNs in Theorem 1 with proof in Sec. D.2 in supplement.
",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
Theorem 1.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Assume that in CNNs, σ1 and σ2 are respectively the sigmoid and softmax functions and the loss function f(g(w;D),y) is squared loss.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
Suppose Assumptions 1 and 2 hold.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Then with probability at least 1− ε, the generalization error of a deep CNN model is bounded as
ES∼D ∣∣∣EA ( Q(w̃)− Q̃n(w̃) )",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"∣∣∣ ≤
√ θ%+ log ( 4 ε )
2n ,
where θ and % are given in Lemma 1.
",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"By inspecting Theorem 1, one can find that the generalization error diminishes at the rate of O (1/√n) (up to a log factor).",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Besides, Theorem 1 explicitly reveals the roles of network parameters in determining model generalization performance.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Such transparent results form stark contrast to the works (Sun et al., 2016) and (Kawaguchi et al., 2017) (see more comparison in Sec. 3.2).",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Notice, our technique also applies to other third-order differentiable activation functions, e.g. tanh, and other losses, e.g. cross entropy, with only slight difference in the results.
",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"First, the freedom degree θ of network parameters, which depends on the network size and the redundancy in parameters, plays an important role in the generalization error bound.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"More specifically, to obtain smaller generalization
error, more samples are needed to train a deep CNN model having larger freedom degree θ.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"As aforementioned, although the results in Theorem 1 are obtained under the low-rankness condition defined on the parameter matrix consisting of kernels per layer, they are easily extended to the (tensor) low-rankness defined on each kernel individually.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
The low-rankness captures common parameter redundancy in practice.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"For instance, (Lebedev et al., 2014; Jaderberg et al., 2014) showed that parameter redundancy exists in a trained network model and can be squeezed by low-rank tensor decomposition.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"The classic residual function (He et al., 2016; Zagoruyko & Komodakis, 2016) with three-layer bottleneck architecture (1× 1, 3× 3 and 1× 1 convs) has rank 1 in generalized block term decomposition (Chen et al., 2017; Cohen & Shashua, 2016).",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Similarly, inception networks (Szegedy et al., 2017) explicitly decomposes a convolutional kernel of large size into two separate convolutional kernels of smaller size (e.g. a 7× 7 kernel is replaced by two multiplying kernels of size 7×1 and 1×7).",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
Employing these low-rank approximation techniques helps reduce the freedom degree and provides smaller generalization error.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Notice, the low-rankness assumption only affects the freedom degree θ.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Without this assumption, θ will be replaced by the total parameter number of the network.
",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"From the factor %, one can observe that the kernel size ki and its stride si determine the generalization error but in opposite ways.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Larger kernel size ki leads to larger generalization error, while larger stride si provides smaller one.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"This is because both larger kernel and smaller stride increase the model complexity, since larger kernel means more trainable parameters and smaller stride implies larger size of feature maps in the subsequent layer.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Also, the pooling operation in the first l convolutional layers helps reduce the generalization error, as reflected by the factor 1/p in %.
",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Furthermore, the number of feature maps (i.e. channels) di appearing in the θ",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
and % also affects the generalization error.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
A wider network with larger di requires more samples for training such that it can generalize well.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"This is because (1) a larger di indicates more trainable parameters, which usually increases the freedom degree θ, and (2) a larger di also requires larger kernels W j(i) with more channel-wise dimensions since there are more channels to convolve, leading to a larger magnitude bound bi for the kernel W j (i).",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Therefore, as suggested by Theorem 1, a thin network is more preferable than a fat network.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Such an observation is consistent with other analysis works on the network expression ability (Eldan & Shamir, 2016; Lu et al., 2017) and the architecture-engineering practice, such as (He et al., 2016; Szegedy et al., 2015).",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"By comparing contributions of the architecture and parameter magnitude to the generalization performance, we find that the generalization error usually depends on the network architecture parameters linearly or more heavily, and also on parameter magnitudes but
with a logarithm term log bi.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
This implies the architecture plays a more important role than the parameter magnitudes.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Therefore, for achieving better generalization performance in practice, architecture engineering is indeed essential.
",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Finally, by observing the factor %, we find that imposing certain regularization, such as ‖w‖22, on the trainable parameters is useful.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
The effectiveness of such a regularization will be more significant when imposing on the weight matrix of the fully connected layer due to its large size.,3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"Such a regularization technique, in deep learning literature, is well known as “weight decay”.",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
"This conclusion is consistent with other analysis works on the deep forward networks, such as (Bartlett & Maass, 2003; Neyshabur et al., 2015; Zhou & Feng, 2018).",3.1. Generalization Error Bound for Deep CNNs,[0],[0]
Sun et al. (2016) also analyzed generalization error bound in deep CNNs but employing different techniques.,3.2. Discussions,[0],[0]
They proved that the Rademacher complexity Rm(F) of a deep CNN model with sigmoid activation functions is O(̃bx(2pb̃)l+1 √ log(r0c0)/ √ n) where F denotes the function hypothesis that maps the input data D to v ∈ Rdl+1,3.2. Discussions,[0],[0]
by the analyzed CNN model.,3.2. Discussions,[0],[0]
"Here b̃x denotes the upper bound of the absolute entry values in the input datum D, i.e. b̃x ≥ |Di,j | (∀i, j), and b̃ obeys b̃ ≥ max{maxi ∑di j=1",3.2. Discussions,[0],[0]
"‖W j (i)‖1, ‖W(l+1)‖1}.",3.2. Discussions,[0],[0]
"Sun et al. (2016) showed that with probability at least 1 − ε, the difference between the empirical margin error errγe (g) (g ∈ F) and the population margin error errγp(g) can be bounded as
errγp(g) ≤ inf γ>0
[ errγe (g) +
8dl+1(2dl+1",3.2. Discussions,[0],[0]
"− 1) γ Rm(F)
+
√ log log2(2/γ)
n",3.2. Discussions,[0],[0]
"+
√ log(2/ε)
n
] , (3)
where γ controls the error margin since it obeys γ ≥ vy",3.2. Discussions,[0],[0]
− maxk 6=y vk and y denotes the label of v.,3.2. Discussions,[0],[0]
"However, the bound in Eqn.",3.2. Discussions,[0],[0]
"(3) is practically loose, sinceRm(F) involves the exponential factor (2b̃)l+1 which is usually very large.",3.2. Discussions,[0],[0]
"In this case,Rm(F) is extremely large.",3.2. Discussions,[0],[0]
"By comparison, the bound provided in our Theorem 1 only depends on∑l+1 i=1 log(bi) which avoids the exponential growth along with the depth l, giving a much tighter and more practically meaningful bound.",3.2. Discussions,[0],[0]
"The generalization error bounds in (Kawaguchi et al., 2017) either depend on a specific dataset or rely on restrictive and rarely used training procedure, while our Theorem 1 is independent of any specific dataset or training procedure, rendering itself more general.",3.2. Discussions,[0],[0]
"More importantly, the results in Theorem 1 make the roles of network parameters transparent, which could benefit understanding and architecture design of CNNs.",3.2. Discussions,[0],[0]
"Although deep CNNs are highly non-convex, gradient descent based algorithms usually perform quite well on optimizing the models in practice.",4. Optimization Guarantees for Deep CNNs,[0],[0]
"After characterizing the roles of different network parameters for the generalization performance, here we present optimization guarantees for gradient descent based algorithms in training CNNs.
",4. Optimization Guarantees for Deep CNNs,[0],[0]
"Specifically, in practice one usually adopts SGD or its variants, such as adam and RMSProp, to optimize the CNN models.",4. Optimization Guarantees for Deep CNNs,[0],[0]
Such algorithms usually terminate when the gradient magnitude decreases to a low level and the training hardly proceeds.,4. Optimization Guarantees for Deep CNNs,[0],[0]
"This implies that the algorithms in fact compute an -approximate stationary point w̃ for the loss function Q̃n(w), i.e. ‖∇wQ̃n(w̃)‖22 ≤ .",4. Optimization Guarantees for Deep CNNs,[0],[0]
"Here we explore such a problem: by computing an -stationary point w̃ of the empirical risk Q̃n(w), can we also expect w̃ to be sufficiently good for generalization, or in other words expect that it is also an approximate stationary point for the population risk Q(w)?",4. Optimization Guarantees for Deep CNNs,[0],[0]
"To answer this question, first we analyze the relationship between the empirical gradient∇wQ̃n(w) and its population counterpart∇wQ(w).",4. Optimization Guarantees for Deep CNNs,[0],[0]
"Founded on this, we further establish convergence of the empirical gradient of the computed solution to its corresponding population gradient.",4. Optimization Guarantees for Deep CNNs,[0],[0]
"Finally, we present the bounded distance between the computed solution w̃ and the optimum w∗.
To our best knowledge, this work is the first one that analyzes the optimization behavior of gradient descent based algorithms for training multi-layer CNN models with the commonly used convolutional and pooling operations.",4. Optimization Guarantees for Deep CNNs,[0],[0]
Here we present guarantees on convergence of the empirical gradient to the population one in Theorem 2.,4.1. Convergence Guarantees on Gradients,[0],[0]
"As aforementioned, such results imply good generalization performance of the computed solution w̃ to the empirical risk Q̃n(w).
",4.1. Convergence Guarantees on Gradients,[0],[0]
Theorem 2.,4.1. Convergence Guarantees on Gradients,[0],[0]
"Assume that in CNNs, σ1 and σ2 respectively are the sigmoid and softmax functions and the loss function f(g(w;D),y) is squared loss.",4.1. Convergence Guarantees on Gradients,[0],[0]
Suppose Assumptions 1 and 2 hold.,4.1. Convergence Guarantees on Gradients,[0],[0]
Then the empirical gradient uniformly converges to the population gradient in Euclidean norm.,4.1. Convergence Guarantees on Gradients,[0],[0]
"More specifically, there exist universal constants cg′ and cg such that if n ≥",4.1. Convergence Guarantees on Gradients,[0],[0]
"cg′ l 2bl+1 2(bl+1+ ∑l i=1 dibi) 2(r0c0d0) 4
d40b1 8(d log(6)+θ%)ε2 maxi(rici)
, then
sup w∈Ω
∥∥∥∇wQ̃n(w)−∇wQ(w) ∥∥∥
2 ≤cgβ
√ 2d+θ%+log ( 4 ε )
2n
holds with probability at least 1 − ε, where % is provided in Lemma 1.",4.1. Convergence Guarantees on Gradients,[0],[0]
Here β and d are defined as β =[ rlcldl 8p2 +,4.1. Convergence Guarantees on Gradients,[0],[0]
∑l i=1 bl+1 2di−1,4.1. Convergence Guarantees on Gradients,[0],[0]
"8p2bi2di ri−1ci−1 ∏l j=i djbj 2(kj−sj+1)2 16p2 ]1/2 and d = r̃lc̃ldldl+1 + ∑l i=1 ki 2di−1di, respectively.
",4.1. Convergence Guarantees on Gradients,[0],[0]
Its proof is given in Sec.,4.1. Convergence Guarantees on Gradients,[0],[0]
D.3 in supplement.,4.1. Convergence Guarantees on Gradients,[0],[0]
"From Theorem 2, the empirical gradient converges to the population one at the rate of O(1/√n) (up to a log factor).",4.1. Convergence Guarantees on Gradients,[0],[0]
"In Sec. 3.1, we have discussed the roles of the network architecture parameters in %.",4.1. Convergence Guarantees on Gradients,[0],[0]
Here we further analyze the effects of the network parameters on the optimization behavior through the factor β.,4.1. Convergence Guarantees on Gradients,[0],[0]
"The roles of the kernel size ki, the stride si, the pooling size p and the channel number di in β are consistent with those in Theorem 1.",4.1. Convergence Guarantees on Gradients,[0],[0]
The extra factor rici advocates not building such CNN networks with extremely large feature map sizes.,4.1. Convergence Guarantees on Gradients,[0],[0]
The total number of parameters d is involved here instead of the degree of freedom because the gradient ∇wQ̃n(w) may not have low-rank structures.,4.1. Convergence Guarantees on Gradients,[0],[0]
"Based on Theorem 2, we can further conclude that if the computed solution w̃ is an -approximate stationary point of the empirical risk, then it is also a 4 -approximate stationary point of the population risk.",4.1. Convergence Guarantees on Gradients,[0],[0]
We state this result in Corollary 1 with proof in Sec.,4.1. Convergence Guarantees on Gradients,[0],[0]
D.4 in supplement.,4.1. Convergence Guarantees on Gradients,[0],[0]
Corollary 1.,4.1. Convergence Guarantees on Gradients,[0],[0]
Suppose assumptions in Theorem 2 hold,4.1. Convergence Guarantees on Gradients,[0],[0]
and we have n ≥,4.1. Convergence Guarantees on Gradients,[0],[0]
(d% + log(4/ε))β2/ .,4.1. Convergence Guarantees on Gradients,[0],[0]
"Then if the solution w̃ computed by minimizing the empirical risk obeys ‖∇Q̃n(w̃)‖22 ≤ , we have ‖∇Q(w̃)‖22 ≤ 4 with probability at least 1− ε.
",4.1. Convergence Guarantees on Gradients,[0],[0]
"Corollary 1 shows that by using full gradient descent algorithms to minimize the empirical risk, the computed approximate stationary point w̃ is also close to the desired stationary point w∗ of the population risk.",4.1. Convergence Guarantees on Gradients,[0],[0]
"This guarantee is also applicable to other stochastic gradient descent based algorithms, like SGD, adam and RMSProp, by applying recent results on obtaining -approximate stationary point for nonconvex problems (Ghadimi & Lan, 2013; Tieleman & Hinton, 2012; Kingma & Ba, 2015).",4.1. Convergence Guarantees on Gradients,[0],[0]
"Accordingly, the computed solution w̃ has guaranteed generalization performance on new data.",4.1. Convergence Guarantees on Gradients,[0],[0]
It partially explains the success of gradient descent based optimization algorithms for CNNs.,4.1. Convergence Guarantees on Gradients,[0],[0]
Here we go further and directly characterize the distance between stationary points in the empirical risk Q̃n(w) and its population counterpart Q(w).,4.2. Convergence of Stationary Points,[0],[0]
"Compared with the results for the risk and gradient, the results on stationary points give more direct performance guarantees for CNNs.",4.2. Convergence of Stationary Points,[0],[0]
"Here we only analyze the non-degenerate stationary points including local minimum/maximum and non-degenerate saddle points, as they are geometrically isolated and thus are unique in local regions.",4.2. Convergence of Stationary Points,[0],[0]
We first introduce some necessary definitions.,4.2. Convergence of Stationary Points,[0],[0]
Definition 2.,4.2. Convergence of Stationary Points,[0],[0]
"(Non-degenerate stationary points and saddle points) (Gromoll & Meyer, 1969)",4.2. Convergence of Stationary Points,[0],[0]
"A stationary point w is said to be a non-degenerate stationary point of Q(w) if
inf i
∣∣λi ( ∇2Q(w) )∣∣",4.2. Convergence of Stationary Points,[0],[0]
"≥ ζ,
where λi ( ∇2Q(w) ) is the i-th eigenvalue of the Hessian
∇2Q(w) and ζ is a positive constant.",4.2. Convergence of Stationary Points,[0],[0]
"A stationary point is said to be a saddle point if the smallest eigenvalue of its Hessian∇2Q(w) has a negative value.
",4.2. Convergence of Stationary Points,[0],[0]
"Suppose Q(w) has m non-degenerate stationary points which are denoted as {w(1), w(2), · · · ,w(m)}.",4.2. Convergence of Stationary Points,[0],[0]
We have following results on the geometry of these stationary points in Theorem 3.,4.2. Convergence of Stationary Points,[0],[0]
"The proof is given in Sec. D.5 in supplement.
",4.2. Convergence of Stationary Points,[0],[0]
Theorem 3.,4.2. Convergence of Stationary Points,[0],[0]
"Assume in CNNs, σ1 and σ2 are respectively the sigmoid and softmax activation functions and the loss f(g(w;D),y) is squared loss.",4.2. Convergence of Stationary Points,[0],[0]
Suppose Assumptions 1 and 2 hold.,4.2. Convergence of Stationary Points,[0],[0]
"Then if n ≥ ch max ( d+θ% ζ2 , l2bl+1 2(bl+1+ ∑l i=1 dibi) 2(r0c0d0) 4
d40b1 8d%ε2 maxi(rici)
) where ch is a constant,
for k ∈ {1, · · · ,m}, there exists a non-degenerate stationary point w(k)n of Q̃n(w) which uniquely corresponds to the non-degenerate stationary point w(k) of Q(w) with probability at least 1− ε.",4.2. Convergence of Stationary Points,[0],[0]
"Moreover, with same probability the distance between w(k)n and w(k) is bounded as
‖w(k)n −w(k)‖2≤ 2cgβ
ζ
√ 2d+θ%+log ( 4 ε )
2n , (1≤k≤m),
where % and β are given in Lemma 1 and Theorem 2, respectively.
",4.2. Convergence of Stationary Points,[0],[0]
"Theorem 3 shows that there exists exact one-to-one correspondence between the non-degenerate stationary points of the empirical risk Q̃n(w) and the popular risk Q(w) for CNNs, if the sample size n is sufficiently large.",4.2. Convergence of Stationary Points,[0],[0]
"Moreover, the non-degenerate stationary point w(k)n of Q̃n(w) is very close to its corresponding non-degenerate stationary point w(k) of Q(w).",4.2. Convergence of Stationary Points,[0],[0]
"More importantly, their distance shrinks at the rate of O (1/√n) (up to a log factor).",4.2. Convergence of Stationary Points,[0],[0]
The network parameters have similar influence on the distance bounds as explained in the above subsection.,4.2. Convergence of Stationary Points,[0],[0]
"Compared with gradient convergence rate in Theorem 2, the convergence rate of corresponding stationary point pairs in Theorem 3 has an extra factor 1/ζ that accounts for the geometric topology of non-degenerate stationary points, similar to other works like stochastic optimization analysis (Duchi & Ruan, 2016).
",4.2. Convergence of Stationary Points,[0],[0]
"For degenerate stationary points to which the corresponding Hessian matrix has zero eigenvalues, one cannot expect to establish unique correspondence for stationary points in empirical and population risks, since they are not isolated anymore and may reside in flat regions.",4.2. Convergence of Stationary Points,[0],[0]
But Theorem 2 guarantees that the gradients of Q̃n(w) and Q(w) at these points are close.,4.2. Convergence of Stationary Points,[0],[0]
"This implies a degenerate stationary point of Q(w) will also give a near-zero gradient for Q̃n(w), indicating it is also a stationary point for Q̃n(w).
",4.2. Convergence of Stationary Points,[0],[0]
"Du et al. (2017a;b) showed that for a simple and shallow CNN consisting of only one non-overlapping convolutional layer, (stochastic) gradient descent algorithms with weight
normalization can converge to the global minimum.",4.2. Convergence of Stationary Points,[0],[0]
"In contrast to their simplified models, we analyze complex multi-layer CNNs with the commonly used convolutional and pooling operations.",4.2. Convergence of Stationary Points,[0],[0]
"Besides, we provide results on both gradient and the distance between the computed solution and desired stationary points, which are applicable to arbitrary gradient descent based algorithms.
",4.2. Convergence of Stationary Points,[0],[0]
"Next, based on Theorem 3, we derive that the corresponding pair (w(k)n ,w(k)) in the empirical and population risks shares the same geometrical property stated in Corollary 2.",4.2. Convergence of Stationary Points,[0],[0]
Corollary 2.,4.2. Convergence of Stationary Points,[0],[0]
Suppose the assumptions in Theorem 3 hold.,4.2. Convergence of Stationary Points,[0],[0]
"If any one in the pair (w(k)n ,w(k)) in Theorem 3 is a local minimum or saddle point, so is the other one.
",4.2. Convergence of Stationary Points,[0],[0]
See the proof of Corollary 2 in Sec.,4.2. Convergence of Stationary Points,[0],[0]
D.6 in supplement.,4.2. Convergence of Stationary Points,[0],[0]
"Corollary 2 tells us that the corresponding pair, w(k)n and w(k), has the same geometric property.",4.2. Convergence of Stationary Points,[0],[0]
"Namely, if either one in the pair is a local minimum or saddle point, so is the other one.",4.2. Convergence of Stationary Points,[0],[0]
This result is important for optimization.,4.2. Convergence of Stationary Points,[0],[0]
"If the computed solution w̃ by minimizing the empirical risk Q̃n(w) is a local minimum, then it is also a local minimum of the population risk Q(w).",4.2. Convergence of Stationary Points,[0],[0]
Thus it partially explains why the computed solution w̃ can generalize well on new data.,4.2. Convergence of Stationary Points,[0],[0]
This property also benefits designing new optimization algorithms.,4.2. Convergence of Stationary Points,[0],[0]
"For example, Saxe et al. (2014) and Kawaguchi (2016) pointed out that degenerate stationary points indeed exist for deep linear neural networks and Dauphin et al. (2014) empirically validated that saddle points are usually surrounded by high error plateaus in deep forward neural networks.",4.2. Convergence of Stationary Points,[0],[0]
So it is necessary to avoid the saddle points and find the local minimum of population risk.,4.2. Convergence of Stationary Points,[0],[0]
"From Theorem 3, it is clear that one only needs to find the local minimum of empirical risk by using escaping saddle points algorithms, e.g. (Ge et al., 2015; Jin et al., 2017; Agarwal et al., 2017).",4.2. Convergence of Stationary Points,[0],[0]
"Here we compare deep feedforward neural networks (DNNs) with deep CNNs from their generalization error and optimization guarantees to theoretically explain why CNNs are more preferable than DNNs, to some extent.
",5. Comparison on DNNs And CNNs,[0],[0]
"By assuming the input to be standard Gaussian N (0, τ2), Zhou & Feng (2018) proved that if n ≥ 18r2/(dτ2ε2 log(l+ 1)), with probability 1 − ε, the generalization error of an (l + 1)-layer DNN model with sigmoid activation functions is bounded by n:
n , cnτ √
(1 + crl) max i di
√ d log(n(l+1))",5. Comparison on DNNs And CNNs,[0],[0]
"+ log(4/ε)
n ,
where cn is a universal constant; di denotes the width of the i-th layer; d is the total parameter number of the network; cr = max(r̂2/16, ( r̂2/16 )l ) where r̂ upper bounds Frobenius norm of the weight matrix in each
layer.",5. Comparison on DNNs And CNNs,[0],[0]
"Recall that the generalization bound of CNN provided in this work is O( √ θ%̃/(2n)), where %̃ =∑l
i=1 log (√ dibi(ki − si + 1)/(4p) )",5. Comparison on DNNs And CNNs,[0],[0]
"+ log(bl+1).
",5. Comparison on DNNs And CNNs,[0],[0]
"By observing the above two generalization bounds, one can see when the layer number is fixed, CNN usually has smaller generalization error than DNN because: (1) CNN usually has much fewer parameters, i.e. smaller d, than DNN due to parameter sharing mechanism of convolutions.",5. Comparison on DNNs And CNNs,[0],[0]
(2) The generalization error of CNN has a smaller factor than DNN in the network parameter magnitudes.,5. Comparison on DNNs And CNNs,[0],[0]
"Generalization error bound of CNN depends on a logarithm termO(log∏l+1i=1 bi) of the magnitude bi of each kernel/weight matrix, while the bound for DNN depends on O(r̂l+1).",5. Comparison on DNNs And CNNs,[0],[0]
"Since the kernel size is much smaller than that of the weight matrix in the fully connected layer by unfolding the convolutional layer, the upper magnitude bound bi (i = 1, · · · , l) of each kernel is usually much smaller than r̂. (3) The pooling operation and the stride in convolutional operation in CNN also benefit its generalization performance.",5. Comparison on DNNs And CNNs,[0],[0]
This is because the factor %̃ involves O(2(l + 1) log(1/p)) and (ki − si + 1) which also reduce the generalization error.,5. Comparison on DNNs And CNNs,[0],[0]
"Notice, by applying our analysis technique, it might be possible to remove the exponential term in DNN.",5. Comparison on DNNs And CNNs,[0],[0]
"But as mentioned above, the unique operations, e.g. convolution, pooling and striding, still benefit CNN, making it generalize better than DNN.
",5. Comparison on DNNs And CNNs,[0],[0]
"Because of the above factors, the empirical gradient in CNN converges to its population counterpart faster, as well as the paired non-degenerate stationary points for empirical risk and population risk.",5. Comparison on DNNs And CNNs,[0],[0]
"All these results guarantee that for an arbitrary gradient descent based algorithm, it is faster to compute an approximate stationary point or a local minimum in population risk of CNN compared with DNN.",5. Comparison on DNNs And CNNs,[0],[0]
Here we briefly introduce the proof roadmap.,6. Proof of Roadmap,[0],[0]
"Due to space limitation, all the proofs of our theoretical results are deferred to the supplement.",6. Proof of Roadmap,[0],[0]
"Firstly, our analysis relies on bounding the gradient magnitude and the spectral norm of Hessian of the loss f(g(w;D),y).",6. Proof of Roadmap,[0],[0]
"By considering multilayer architecture of CNN, we establish recursive relation of their magnitudes in the k and k + 1 layers (Lemmas 9 ∼ 14 in supplement) and get their overall magnitude upper bound.
",6. Proof of Roadmap,[0],[0]
"For the uniform convergence supw∈Ω |Q̃n(w) − Q(w)| in Lemma 1, we resort to bound three distances: A1 = supw∈Ω |Q̃n(w) − Q̃n(wkw)|, A2 = supwkw∈Θ |Q̃n(wkw)−EQ̃n(wkw)| and A3 = supw∈Ω |EQ̃n(wkw) −EQ(w)|, where wkw belongs to the -net",6. Proof of Roadmap,[0],[0]
"Θ of parameter domain Ω. Using Markov inequality and Lipschitz property of loss, we can bound A1 and A3.",6. Proof of Roadmap,[0],[0]
"To bound A2, we prove the empirical risk is sub-Gaussian.",6. Proof of Roadmap,[0],[0]
Considering the element wkw in -net,6. Proof of Roadmap,[0],[0]
"Θ is independent of input D, we use Hoeffd-
ing’s inequality to prove empirical risk at point wkw to be sub-Gaussian for any wkw in Θ. By this decoupling of -net, our bound on A2 depends on the constant magnitude of loss and gets rid of exponential term.",6. Proof of Roadmap,[0],[0]
"Combining these bounds together, we obtain the uniform convergence of empirical risk and can derive the generalization bound.
",6. Proof of Roadmap,[0],[0]
We use a similar decomposition and decoupling strategy mentioned above to bound gradient uniform convergence supw∈Ω‖∇wQ̃n(w)−∇wQ(w)‖2 in Theorem 2.,6. Proof of Roadmap,[0],[0]
"But here we need to bound gradient and spectral norm of Hessian.
",6. Proof of Roadmap,[0],[0]
"To prove correspondence and bounded distance of stationary points, we define a set G= {w∈Ω : ||∇Q̃n(w)||≤ and infi |λi(∇2Q̃n(w))|",6. Proof of Roadmap,[0],[0]
≥ ζ} where λi is the i-th eigenvalue of∇2Q̃n(w).,6. Proof of Roadmap,[0],[0]
Then G is decomposed into countable components each of which has one or zero non-degenerate stationary point.,6. Proof of Roadmap,[0],[0]
Next we prove the uniform convergence between empirical and population Hessian by using a similar strategy as above.,6. Proof of Roadmap,[0],[0]
"Combining uniform convergence of gradient and Hessian and the results in differential topology (Lemmas 4 & 5 in supplement), we obtain that for each component of G, if there is a unique non-degenerate stationary point in Q(w), then Q̃n(w) also has a unique one, and vice versa.",6. Proof of Roadmap,[0],[0]
This gives the one-to-one correspondence relation.,6. Proof of Roadmap,[0],[0]
"Finally, the uniform convergence of gradient and Hessian can bound the distance between the corresponding points.",6. Proof of Roadmap,[0],[0]
"In this work, we theoretically analyzed why deep CNNs can achieve remarkable success, from its generalization performance and the optimization guarantees of (stochastic) gradient descent based algorithms.",7. Conclusion,[0],[0]
We proved that the generalization error of deep CNNs can be bounded by a factor which depends on the network parameters.,7. Conclusion,[0],[0]
"Moreover, we analyzed the relationship between the computed solution by minimizing the empirical risk and the optimum solutions in population risk from their gradient and their Euclidean distance.",7. Conclusion,[0],[0]
"All these results show that with sufficient training samples, the generalization performance of deep CNN models can be guaranteed.",7. Conclusion,[0],[0]
"Besides, these results also reveal that the kernel size ki, the stride si, the pooling size p, the channel number di and the freedom degree θ of the network parameters are critical to the generalization performance of deep CNNs.",7. Conclusion,[0],[0]
We also showed that the weight parameter magnitude is also important.,7. Conclusion,[0],[0]
These suggestions on network designs accord with the widely used network architectures.,7. Conclusion,[0],[0]
"Jiashi Feng was partially supported by NUS startup R-263000-C08-133, MOE Tier-I R-263-000-C21-112, NUS IDS R-263-000-C67-646, ECRA R-263-000-C87-133 and MOE Tier-II R-263-000-D17-112.",Acknowledgements,[0],[0]
This document gives some other necessary notations and preliminaries for our analysis in Sec. B.1 and provides auxiliary lemmas in Sec. B.2.,A Structure of This Document,[0],[0]
"Then in Sec. C, we present the technical lemmas for proving our final results and their proofs.",A Structure of This Document,[0],[0]
"Next, in Sec. D, we utilize these technical lemmas to prove our desired results.",A Structure of This Document,[0],[0]
"Finally, we give the proofs of other auxiliary lemmas in Sec.",A Structure of This Document,[0],[0]
"E.
As for the results in manuscript, the proofs of Lemma 1 and Theorem 1 in Sec. 3.1 in the manuscript are respectively provided in Sec.",A Structure of This Document,[0],[0]
D.1 and Sec. D.2.,A Structure of This Document,[0],[0]
"As for the results in Sec. 4 in the manuscript, Sec.",A Structure of This Document,[0],[0]
"D.3 and D.4 present the proofs of Theorem 2 and Corollary 1, respectively.",A Structure of This Document,[0],[0]
"Finally, we respectively introduce the proofs of Theorem 3 and Corollary 2 in Sec. D.5 and D.6.",A Structure of This Document,[0],[0]
"Beyond the notations introduced in the manuscript, we need some other notations used in this document.",B Notations and Preliminary Tools,[0],[0]
Then we introduce several lemmas that will be used later.,B Notations and Preliminary Tools,[0],[0]
"Throughout this document, we use 〈·, ·〉 to denote the inner product and use ~̃ to denote the convolution operation with stride 1.",B.1 Notations,[0],[0]
A⊗C denotes the Kronecker product betweenA,B.1 Notations,[0],[0]
andC.,B.1 Notations,[0],[0]
Note thatA andC inA⊗C can be matrices or vectors.,B.1 Notations,[0],[0]
"For a matrixA ∈ Rn1×n2 , we use ‖A‖F = √∑ i,jA 2 ij to denote its Frobenius norm, whereAij is the (i, j)-th entry of A.",B.1 Notations,[0],[0]
"We use ‖A‖op = maxi |λi(A)| to denote the operation norm of a matrixA ∈ Rn1×n1 , where λi(A) denotes the i-th eigenvalue of the matrixA. For a 3-way tensorA ∈ Rs×t×q , its operation norm is computed as
‖A‖op = sup ‖λ‖2≤1
〈 λ⊗ 3 ,A 〉 = ∑
i,j,k
Aijkλiλjλk,
whereAijk denotes the (i, j, k)-th entry ofA.
For brevity, in this document we use f(w,D) to denote f(g(w;D),y) in the manuscript.",B.1 Notations,[0],[0]
Let w(i) =,B.1 Notations,[0],[0]
(w1(i); · · · ;wdi(i)) ∈,B.1 Notations,[0],[0]
Rki2di−1di,B.1 Notations,[0],[0]
"(i = 1, · · · , l) be the parameter of the i-th layer where wk(i) = vec ( W k(i) )",B.1 Notations,[0],[0]
∈ Rki2di−1 is the vectorization of W k(i).,B.1 Notations,[0],[0]
"Similarly, let w(l+1)",B.1 Notations,[0],[0]
= vec ( W(l+1) ) ∈ Rrlcldldl+1 .,B.1 Notations,[0],[0]
"Then, we further define w = (w(1), · · · ,w(l),w(l+1)) ∈ Rrlcldldl+1+ ∑l i=1 ki
2di−1di which contains all the parameter in the network.",B.1 Notations,[0],[0]
"Here we useW k(i) to denote the k-th kernel in
the i-th convolutional layer.",B.1 Notations,[0],[0]
"For brevity, letW k,j(i) denotes the j-th slice ofW k",B.1 Notations,[0],[0]
"(i), i.e. W k,j (i) =",B.1 Notations,[0],[0]
"W k (i)(:, :, j).
",B.1 Notations,[0],[0]
"For a matrixM ∈ Rs×t, M̂ denotes the matrix which is obtained by rotating the matrixM by 180 degrees.",B.1 Notations,[0],[0]
"Then we use δi to denote the gradient of f(w,D) w.r.t. X(i):
δi = ∇X(i)f(w,D) ∈ Rri×ci×di , (i = 1, · · · , l),
Based on δi, we further define δ̃i ∈ R(r̃i−1−ki+1)×(c̃i−1−ki+1)×di .",B.1 Notations,[0],[0]
Each slice δ̃ki+1 can be computed as follows.,B.1 Notations,[0],[0]
"Firstly, let δ̃ki+1 = δ k i+1.",B.1 Notations,[0],[0]
"Then, we pad zeros of si − 1 rows between the neighboring rows in δ̃ki+1 and similarly we pad zeros of si",B.1 Notations,[0],[0]
− 1 columns between the neighboring columns in δ̃ki+1.,B.1 Notations,[0],[0]
"Accordingly, the size of δ̃ k i+1 is (si(ri − 1) + 1)× (si(ci − 1) + 1).",B.1 Notations,[0],[0]
"Finally, we pad zeros of width ki",B.1 Notations,[0],[0]
− 1 around δ̃ki+1 to obtain new δ̃ki+1 ∈ R(si(ri−1)+2ki−1)×(si(ci−1)+2ki−1).,B.1 Notations,[0],[0]
"Note that since ri+1 = (r̃i − ki+1)/si+1 + 1 and ri+1 = (r̃i − ki+1)/si+1 + 1, we have si(ri − 1) +",B.1 Notations,[0],[0]
2ki,B.1 Notations,[0],[0]
− 1 = r̃i−1,B.1 Notations,[0],[0]
− ki + 1 and si(ci,B.1 Notations,[0],[0]
− 1) +,B.1 Notations,[0],[0]
2ki,B.1 Notations,[0],[0]
− 1 = c̃i−1 − ki + 1.,B.1 Notations,[0],[0]
"Then we define four operators G (·), Q (·), up (·) and vec(·), which are useful for explaining the following analysis.
",B.1 Notations,[0],[0]
Operation G (·): It maps an arbitrary vector z ∈ Rd into a diagonal matrix G (z) ∈ Rd×d with its i-th diagonal entry equal to σ1(zi)(1− σ1(zi)) in which zi denotes the i-th entry of z. Operation Q (·): it maps a vector z ∈ Rd into a matrix of size d2 × d whose ((i − 1)d,B.1 Notations,[0],[0]
+,B.1 Notations,[0],[0]
"i, i) (i = 1, · · · , d) entry equal to σ1(zi)(1− σ1(zi))(1− 2σ1(zi)) and rest entries are all 0.",B.1 Notations,[0],[0]
Operation up (·): up (M) represents conducting upsampling on M ∈ Rs×t×q.,B.1 Notations,[0],[0]
Let N = up (M) ∈ Rps×pt×q.,B.1 Notations,[0],[0]
"Specifically, for each sliceN(:, :, i) (i = 1, · · · , q), we haveN(:, :, i) = up (M(:, :, i)).",B.1 Notations,[0],[0]
"It actually upsamples each entryM(g, h, i) into a matrix of p2 same entries 1p2M(g, h, i).
",B.1 Notations,[0],[0]
"Operation vec(·): For a matrix A ∈ Rs×t, vec(A) is defined as vec(A) =",B.1 Notations,[0],[0]
"(A(:, 1); · · · ;A(:, t)) ∈ Rst that vectorizes A ∈ Rs×t along its columns.",B.1 Notations,[0],[0]
"If A ∈ Rt×s×q is a 3-way tensor, vec(A) =",B.1 Notations,[0],[0]
"[vec(A(:, :, 1)); vec(A(:, : , 2)), · · · , vec(A(:, :, q))]",B.1 Notations,[0],[0]
∈,B.1 Notations,[0],[0]
Rstq .,B.1 Notations,[0],[0]
We first introduce Lemmas 2 and 3 which are respectively used for bounding the `2-norm of a vector and the operation norm of a matrix.,B.2 Auxiliary Lemmas,[0],[0]
Then we introduce Lemmas 4 and 5 which discuss the topology of functions.,B.2 Auxiliary Lemmas,[0],[0]
"In Lemma 6, we introduce the Hoeffding’s inequality which provides an upper bound on the probability that the sum of independent random variables deviates from its expected value.",B.2 Auxiliary Lemmas,[0],[0]
"In Lemma 7, we provide the covering number of an -net for a low-rank matrix.",B.2 Auxiliary Lemmas,[0],[0]
"Finally, several commonly used inequalities are presented in Lemma 8 for our analysis.",B.2 Auxiliary Lemmas,[0],[0]
Lemma 2.,B.2 Auxiliary Lemmas,[0],[0]
"(Vershynin, 2012)",B.2 Auxiliary Lemmas,[0],[0]
"For any vector x ∈ Rd, its `2-norm can be bounded as
‖x‖2 ≤ 1
1−",B.2 Auxiliary Lemmas,[0],[0]
"supλ∈λ 〈λ,x〉 .
where λ = {λ1, . . .",B.2 Auxiliary Lemmas,[0],[0]
",λkw} be an -covering net of Bd(1).",B.2 Auxiliary Lemmas,[0],[0]
Lemma 3.,B.2 Auxiliary Lemmas,[0],[0]
"(Vershynin, 2012)",B.2 Auxiliary Lemmas,[0],[0]
"For any symmetric matrixX ∈ Rd×d, its operator norm can be bounded as
‖X‖op ≤ 1
1− 2 supλ∈λ |〈λ,Xλ〉| .
where λ = {λ1, . . .",B.2 Auxiliary Lemmas,[0],[0]
",λkw} be an -covering net of Bd(1).",B.2 Auxiliary Lemmas,[0],[0]
Lemma 4.,B.2 Auxiliary Lemmas,[0],[0]
"(Mei et al., 2017) Let D ⊆ Rd be a compact set with a C2 boundary ∂D, and f, g : A→ R be C2 functions defined on an open set A, with D ⊆ A. Assume that for all w ∈ ∂D and all t ∈",B.2 Auxiliary Lemmas,[0],[0]
"[0, 1], t∇f(w) + (1 − t)∇g(w) 6= 0.",B.2 Auxiliary Lemmas,[0],[0]
"Finally, assume that the Hessian ∇2f(w) is non-degenerate and has index equal to r for all w ∈",B.2 Auxiliary Lemmas,[0],[0]
"D. Then the following properties hold:
(1)",B.2 Auxiliary Lemmas,[0],[0]
"If g has no critical point in D, then f has no critical point in D.
(2)",B.2 Auxiliary Lemmas,[0],[0]
"If g has a unique critical point w in D that is non-degenerate with an index of r, then f also has a unique critical point w′",B.2 Auxiliary Lemmas,[0],[0]
"in D with the index equal to r.
Lemma 5.",B.2 Auxiliary Lemmas,[0],[0]
"(Mei et al., 2017) Suppose that F (w) :",B.2 Auxiliary Lemmas,[0],[0]
Θ→ R is a C2 function where w ∈,B.2 Auxiliary Lemmas,[0],[0]
"Θ. Assume that {w(1), . . .",B.2 Auxiliary Lemmas,[0],[0]
", w(m)} is its non-degenerate critical points and let D = {w ∈",B.2 Auxiliary Lemmas,[0],[0]
Θ : ‖∇F (w)‖2 < and infi ∣∣λi ( ∇2F (w) )∣∣ ≥ ζ}.,B.2 Auxiliary Lemmas,[0],[0]
"Then D can be decomposed into (at most) countably components, with each component containing either exactly one critical point, or no critical point.",B.2 Auxiliary Lemmas,[0],[0]
"Concretely, there exist disjoint open sets {Dk}k∈N, with Dk possibly empty for k ≥ m+ 1, such that
D = ∪∞k=1Dk .",B.2 Auxiliary Lemmas,[0],[0]
"Furthermore, w(k) ∈ Dk for 1 ≤ k ≤ m and each Di, k ≥",B.2 Auxiliary Lemmas,[0],[0]
"m+ 1 contains no stationary points.
",B.2 Auxiliary Lemmas,[0],[0]
Lemma 6.,B.2 Auxiliary Lemmas,[0],[0]
"(Hoeffding, 1963) Let x1, · · · , xn be independent random variables where xi is bounded by the interval [ai, bi].",B.2 Auxiliary Lemmas,[0],[0]
Suppose sn = 1n,B.2 Auxiliary Lemmas,[0],[0]
∑n i=1,B.2 Auxiliary Lemmas,[0],[0]
"xi, then the following properties hold:
P (sn − Esn ≥ t) ≤ exp ( − 2n
2t2∑n i=1(bi",B.2 Auxiliary Lemmas,[0],[0]
"− ai)2
) .
where t is an arbitrary positive value.
",B.2 Auxiliary Lemmas,[0],[0]
Lemma 7.,B.2 Auxiliary Lemmas,[0],[0]
"(Candes & Plan, 2009) Let Sr = {X ∈ Rn1×n2 :",B.2 Auxiliary Lemmas,[0],[0]
rank (X) ≤,B.2 Auxiliary Lemmas,[0],[0]
"r, ‖X‖F = b}.",B.2 Auxiliary Lemmas,[0],[0]
Then there exists an -net,B.2 Auxiliary Lemmas,[0],[0]
"S̃r for the Frobenius norm obeying
|S̃r| ≤",B.2 Auxiliary Lemmas,[0],[0]
( 9b ),B.2 Auxiliary Lemmas,[0],[0]
"r(n1+n2+1) .
",B.2 Auxiliary Lemmas,[0],[0]
"Then we give a lemma to summarize the properties of G (·), Q (·) and up (·) defined in Section B.1, the convolutional operation ~ defined in manuscript.",B.2 Auxiliary Lemmas,[0],[0]
Lemma 8.,B.2 Auxiliary Lemmas,[0],[0]
"For G (·), Q (·) and up (·) defined in Section B.1, the convolutional operation ~ defined in manuscript, we have the following properties:
(1) For arbitrary vector z, and arbitrary matricesM andN of proper sizes, we have
‖G (z)M‖2F ≤ 1
16 ‖M‖2F and ‖NG (z)‖2F ≤
1
16 ‖N‖2F .
",B.2 Auxiliary Lemmas,[0],[0]
"(2) For arbitrary vector z, and arbitrary matricesM andN of proper sizes, we have
‖Q (z)M‖2F ≤ 26
38 ‖M‖2F and ‖NQ (z)‖2F ≤
26 38 ‖N‖2F .
",B.2 Auxiliary Lemmas,[0],[0]
"(3) For any tensorM ∈ Rs×t×q , we have
‖up (M)‖2F ≤ 1
p2 ‖M‖2F .
",B.2 Auxiliary Lemmas,[0],[0]
(4) For any kernelW ∈ Rki×ki×di and δ̃i+1 ∈,B.2 Auxiliary Lemmas,[0],[0]
"R(r̃i−1−ki+1)×(c̃i−1−ki+1)×di defined in Sec. B.1, then we have
‖δ̃i+1~̃W ‖2F ≤",B.2 Auxiliary Lemmas,[0],[0]
(ki − si + 1)2‖W ‖2F,B.2 Auxiliary Lemmas,[0],[0]
"‖δ̃i+1‖2F .
",B.2 Auxiliary Lemmas,[0],[0]
"(5) For softmax activation function σ2, we can bound the norm of difference between output v and its corresponding ont-hot label as
0 ≤",B.2 Auxiliary Lemmas,[0],[0]
‖v,B.2 Auxiliary Lemmas,[0],[0]
"− y‖22 ≤ 2.
",B.2 Auxiliary Lemmas,[0],[0]
It should be pointed out that we defer the proof of Lemma 8 to Sec. E.,B.2 Auxiliary Lemmas,[0],[0]
Here we present the key lemmas and theorems for proving our desired results.,C Technical Lemmas and Their Proofs,[0],[0]
"For brevity, in this document we use f(w,D) to denote f(g(w;D),y) in the manuscript.
",C Technical Lemmas and Their Proofs,[0],[0]
Lemma 9.,C Technical Lemmas and Their Proofs,[0],[0]
"Suppose that the activation function σ1 is sigmoid and σ2 is softmax, and the loss function f(w,D) is squared loss.",C Technical Lemmas and Their Proofs,[0],[0]
"Then the gradient of f(w,D) with respect to w(j) can be written as
∇W(l+1)f(w,D) =S(v − y)zT(l) ∈ Rdl+1×r̃lc̃ldl , ∇W k,j (i) f(w,D) =Zj(i−1)~̃δ̃ k i ∈",C Technical Lemmas and Their Proofs,[0],[0]
"Rki×ki , (j = 1, · · · , di−1; k = 1, · · · , di; i = 1, · · · , l),
where δki is the k-slice (i.e. δi(:, :, k)) of δi which is defined as
δi = ∇X(i)f(w,D) ∈ Rri×ci×di , (i = 1, · · · , l),
and further satisfies
δji =up
  di+1∑
k=1
δ̃ki+1~̃Ŵ",C Technical Lemmas and Their Proofs,[0],[0]
"k,j(i+1)   σ′1(Xj(i)) ∈ Rri×ci , (j = 1, · · · , di; i = 1, · · · , l − 1),
where the matrix Ŵ k,j(i+1) ∈ Rki+1×ki+1 is obtained by rotatingW k,j (i+1) with 180 degrees.",C Technical Lemmas and Their Proofs,[0],[0]
"Also, δl is computed as follows:
∇uf(w,D) = S(v − y) ∈ Rdl+1",C Technical Lemmas and Their Proofs,[0],[0]
", ∇z(l)f(w,D) = (W(l+1))TS(v",C Technical Lemmas and Their Proofs,[0],[0]
"− y) ∈ Rr̃lc̃ldl , ∇Z(l)f(w,D)= reshape ( ∇z(l)f(w,D) )",C Technical Lemmas and Their Proofs,[0],[0]
"∈ Rr̃l×c̃l×dl , δl=σ′1(X(l))",C Technical Lemmas and Their Proofs,[0],[0]
"up ( ∂f(w,D)
∂Z(l)
) ∈ Rri×ci×di .
where S = G (u).
",C Technical Lemmas and Their Proofs,[0],[0]
Proof.,C Technical Lemmas and Their Proofs,[0],[0]
"We use chain rule to compute the gradient of f(w,D) with respect to Z(i).",C Technical Lemmas and Their Proofs,[0],[0]
We first compute several basis gradient.,C Technical Lemmas and Their Proofs,[0],[0]
"According to the relationship betweenX(i),Y(i),Z(i) and f(w,D), we have
∇uf(w,D) = S(v − y) ∈ Rdl+1 , ∇z(l)f(w,D) =",C Technical Lemmas and Their Proofs,[0],[0]
"(W(l+1))TS(v − y) ∈ Rr̃lc̃ldl , ∇Z(l)f(w,D) = reshape ( ∇z(l)f(w,D) )",C Technical Lemmas and Their Proofs,[0],[0]
"∈ Rr̃l×c̃l×dl ,
∇X(l)f(w,D) = ∂Y(l)
∂X(l)
",C Technical Lemmas and Their Proofs,[0],[0]
"∂Z(l)
∂Y(l)
",C Technical Lemmas and Their Proofs,[0],[0]
"∂f(w,D)
∂Z(l) = σ′1(X(l))",C Technical Lemmas and Their Proofs,[0],[0]
"up
( ∂f(w,D)
∂Z(l)
)",C Technical Lemmas and Their Proofs,[0],[0]
", δl ∈ Rri×ci×di .
",C Technical Lemmas and Their Proofs,[0],[0]
"Then we can further obtain
δji =up
  di+1∑
k=1
δ̃ki+1~̃Ŵ k,j(i+1)   σ′1(Xj(i))",C Technical Lemmas and Their Proofs,[0],[0]
"∈ Rri×ci , (j = 1, · · · , di; i = 1, · · · , l − 1).
where Ŵ k,j(i) denotes the j-th slice Ŵ k (i)(:, : j) of Ŵ k (i).",C Technical Lemmas and Their Proofs,[0],[0]
"Note, we clockwise rotate the matrix W k,j (i+1) by 180 degrees to obtain Ŵ k,j(i+1).",C Technical Lemmas and Their Proofs,[0],[0]
"Finally, we can compute the gradient w.r.t. W(l+1)",C Technical Lemmas and Their Proofs,[0],[0]
"andW (i) (i = 1, · · · , l):
∇W(l+1)f(w,D) =S(v − y)zT(l) ∈ Rdl+1×r̃lc̃ldl , ∇W k,j (i) f(w,D) =Xj(i−1)~̃δ̃",C Technical Lemmas and Their Proofs,[0],[0]
"k i ∈ Rki×ki , (j = 1, · · · , di−1; k = 1, · · · , di; i = 1, · · · , l).
",C Technical Lemmas and Their Proofs,[0],[0]
"The proof is completed.
",C Technical Lemmas and Their Proofs,[0],[0]
Lemma 10.,C Technical Lemmas and Their Proofs,[0],[0]
"Suppose that the activation function σ1 is sigmoid and σ2 is softmax, and the loss function f(w,D) is squared loss.",C Technical Lemmas and Their Proofs,[0],[0]
"Then the gradient of f(w,D) with respect to w(j) can be written as
‖δl‖2F ≤ ϑ
16p2 bl+1
2, ‖δi‖2F ≤ di+1bi+1 2(ki+1",C Technical Lemmas and Their Proofs,[0],[0]
− si+1 + 1)2 16p2 ∥∥δi+1 ∥∥2,C Technical Lemmas and Their Proofs,[0],[0]
"F , ‖δi‖2F ≤ ϑbl+1 2 16p2",C Technical Lemmas and Their Proofs,[0],[0]
"l∏
s=i+1
dsbs 2(ks",C Technical Lemmas and Their Proofs,[0],[0]
"− ss + 1)2
16p2 ,
where ϑ = 1/8.
",C Technical Lemmas and Their Proofs,[0],[0]
Proof.,C Technical Lemmas and Their Proofs,[0],[0]
We first bound δl.,C Technical Lemmas and Their Proofs,[0],[0]
"By Lemma 9, we have
‖δl‖2F = ∥∥∥∥σ′1(X(l)) up ( ∂f(w,D)
∂Z(l)
)∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
¬ ≤ 1
16p2
∥∥∥∥ ∂f(w,D)
∂Z(l)
∥∥∥∥ 2
F
= 1
16p2
∥∥∥∥ ∂f(w,D)
∂z(l)
∥∥∥∥ 2
2
≤ 1 16p2
∥∥(W(l+1))TS(v",C Technical Lemmas and Their Proofs,[0],[0]
"− y) ∥∥2
2
 ≤ ϑ
16p2 bl+1
2,
where ¬ holds since the values of the entries in the tensor σ′1(X(l)) ∈ Rrl×cl×dl belong to [0, 1/4], and the up (·) operation does repeat one entry into p2 entries but the entry value becomes 1/p2 of the original entry value.  holds since we have ‖S(v",C Technical Lemmas and Their Proofs,[0],[0]
− y)‖22 ≤ 1/8 in Lemma 8.,C Technical Lemmas and Their Proofs,[0],[0]
"Also by Lemma 9, we can further bound ‖δji ‖2F",C Technical Lemmas and Their Proofs,[0],[0]
"as follows:
‖δi‖2F = di∑
j=1
∥∥∥δji ∥∥∥ 2
F =
di∑
j=1
∥∥∥∥∥∥ up   di+1∑
k=1
δ̃ki+1~̃Ŵ",C Technical Lemmas and Their Proofs,[0],[0]
"k,j(i+1)   σ′1(Xj(i))",C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ 1 16p2
di∑
j=1
∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"di+1∑
k=1
δ̃ki+1~̃Ŵ",C Technical Lemmas and Their Proofs,[0],[0]
"k,j(i+1) ∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ di+1",C Technical Lemmas and Their Proofs,[0],[0]
"16p2
di∑
j=1
di+1∑
k=1
∥∥∥δ̃ki+1~̃Ŵ",C Technical Lemmas and Their Proofs,[0],[0]
"k,j(i+1) ∥∥∥ 2 F ≤ di+1(ki+1",C Technical Lemmas and Their Proofs,[0],[0]
"− si+1 + 1) 2 16p2 di∑
j=1
di+1∑
k=1
∥∥∥δ̃ki+1 ∥∥∥ 2
F
∥∥∥Ŵ k,j(i+1) ∥∥∥ 2
F
¬ = di+1(ki+1 − si+1 + 1)2
16p2
di+1∑
k=1
∥∥δki+1 ∥∥2",C Technical Lemmas and Their Proofs,[0],[0]
F ∥∥∥W k(i+1),C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥ 2 F ≤ di+1bi+1 2(ki+1,C Technical Lemmas and Their Proofs,[0],[0]
− si+1 + 1)2 16p2 ∥∥δi+1 ∥∥2,C Technical Lemmas and Their Proofs,[0],[0]
"F ,
where Ŵ k,j(i+1) denotes the j-th slice Ŵ k (i+1)(:, :, j) of the tensor Ŵ k (i+1).",C Technical Lemmas and Their Proofs,[0],[0]
"¬ holds since we rotate the matrix W k,j (i+1)
by 180 degrees to obtain Ŵ k(i+1), indicating ‖W k,j (i+1)‖2F = ‖Ŵ k,j (i+1)‖2F and ∑di",C Technical Lemmas and Their Proofs,[0],[0]
"j=1 ∥∥∥W k,j(i+1) ∥∥∥ 2 F = ∥∥∥W k(i+1)",C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥ 2 F ≤ bi+12.,C Technical Lemmas and Their Proofs,[0],[0]
"Accordingly, the above inequality gives
‖δi‖2F ≤ di+1bi+1",C Technical Lemmas and Their Proofs,[0],[0]
2(ki+1,C Technical Lemmas and Their Proofs,[0],[0]
− si+1 + 1)2 16p2 ∥∥δi+1 ∥∥2,C Technical Lemmas and Their Proofs,[0],[0]
"F ≤· · ·≤‖δl‖2F l∏
s=i+1
dsbs 2(ks − ss + 1)2
16p2
≤ϑbl+1 2
16p2
l∏
s=i+1
dsbs 2(ks − ss + 1)2
16p2 .
",C Technical Lemmas and Their Proofs,[0],[0]
"The proof is completed.
",C Technical Lemmas and Their Proofs,[0],[0]
Lemma 11.,C Technical Lemmas and Their Proofs,[0],[0]
"Suppose that the activation function σ1 is sigmoid and σ2 is softmax, and the loss function f(w,D) is squared loss.",C Technical Lemmas and Their Proofs,[0],[0]
"Then the gradient of f(w,D) with respect toW (l+1) and w can be respectively bounded as follows:
∥∥∇W(l+1)f(w,D) ∥∥2",C Technical Lemmas and Their Proofs,[0],[0]
"F ≤ ϑr̃lc̃ldl and ‖∇wf(w,D)‖22 ≤ β2,
where ϑ = 1/8 and β , [ ϑr̃lc̃ldl + ∑l i=1 ϑbl+1 2di−1",C Technical Lemmas and Their Proofs,[0],[0]
p2bi2di ri−1ci−1,C Technical Lemmas and Their Proofs,[0],[0]
"∏l s=i dsbs 2(ks−ss+1)2 16p2 ]1/2 .
",C Technical Lemmas and Their Proofs,[0],[0]
Proof.,C Technical Lemmas and Their Proofs,[0],[0]
"By utilizing Lemma 10, we can bound
l∑
i=1
",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∇w(i)f(w,D) ∥∥2",C Technical Lemmas and Their Proofs,[0],[0]
"F = l∑
i=1
di∑
k=1
di−1∑
j=1
∥∥∥∇W k,j (i) f(w,D) ∥∥∥ 2 F = l∑
i=1
",C Technical Lemmas and Their Proofs,[0],[0]
"di∑
k=1
di−1∑
j=1
∥∥∥Zj(i−1)~̃δki ∥∥∥ 2
F
¬ ≤
l∑
i=1
",C Technical Lemmas and Their Proofs,[0],[0]
"di∑
k=1
di−1∑
j=1
(ki − si + 1)2 ∥∥∥Zj(i−1) ∥∥∥ 2
F
∥∥δki ∥∥2",C Technical Lemmas and Their Proofs,[0],[0]
"F
 ≤
l∑
i=1
di∑
k=1
di−1∑
j=1
r̃i−1c̃i−1(ki − si + 1)2 ∥∥δki",C Technical Lemmas and Their Proofs,[0],[0]
∥∥2,C Technical Lemmas and Their Proofs,[0],[0]
"F
≤ l∑
i=1
r̃i−1c̃i−1di−1(ki",C Technical Lemmas and Their Proofs,[0],[0]
"− si + 1)2 ‖δi‖2F
≤ l∑
i=1
r̃i−1c̃i−1di−1(ki",C Technical Lemmas and Their Proofs,[0],[0]
"− si + 1)2 ϑbl+1
2
16p2
l∏
s=i+1
dsbs 2(ks",C Technical Lemmas and Their Proofs,[0],[0]
"− ss + 1)2
16p2
= l∑
i=1
ϑbl+1 2di−1
p2bi",C Technical Lemmas and Their Proofs,[0],[0]
"2di
ri−1ci−1
l∏
s=i
dsbs 2(ks",C Technical Lemmas and Their Proofs,[0],[0]
"− ss + 1)2
16p2 ,
where ¬ holds since ∥∥∥Zj(i−1)~̃δki ∥∥∥ 2
F ≤",C Technical Lemmas and Their Proofs,[0],[0]
"(ki− si + 1)2
∥∥∥Zj(i−1) ∥∥∥ 2
F
∥∥δki ∥∥2",C Technical Lemmas and Their Proofs,[0],[0]
"F
; and  holds since the values of entries in Zj(i−1) belong to [0, 1].
",C Technical Lemmas and Their Proofs,[0],[0]
"On the other hand, we can bound
∥∥∇W(l+1)f(w,D) ∥∥2",C Technical Lemmas and Their Proofs,[0],[0]
F = ∥∥∥S(v,C Technical Lemmas and Their Proofs,[0],[0]
− y)zT(l),C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥ 2 F ≤ ϑr̃lc̃ldl.
",C Technical Lemmas and Their Proofs,[0],[0]
"So we can bound the `2 norm of the gradient as follows:
‖∇wf(w,D)‖2F =",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∇W(l+1)f(w,x) ∥∥2 F + l∑
i=1
",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∇w(i)f(w,D) ∥∥2",C Technical Lemmas and Their Proofs,[0],[0]
"F
≤ϑr̃lc̃ldl + l∑
i=1
ϑbl+1 2di−1
p2bi",C Technical Lemmas and Their Proofs,[0],[0]
"2di
ri−1ci−1
l∏
s=i
dsbs 2(ks",C Technical Lemmas and Their Proofs,[0],[0]
"− ss + 1)2
16p2 .
",C Technical Lemmas and Their Proofs,[0],[0]
"The proof is completed.
",C Technical Lemmas and Their Proofs,[0],[0]
Lemma 12.,C Technical Lemmas and Their Proofs,[0],[0]
"Suppose that the activation function σ1 is sigmoid and σ2 is softmax, and the loss function f(w,D) is squared loss.",C Technical Lemmas and Their Proofs,[0],[0]
"Then for both cases, the gradient of x(i) with respect to w(j) can be bounded as follows:
∥∥∥∥∥∥ ∂vec ( X(i) ) ∂w(j) ∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
= ∥∥∥∥ ∂x(i)
∂w(j)
∥∥∥∥ 2
F
≤",C Technical Lemmas and Their Proofs,[0],[0]
"diricir̃j−1c̃j−1dj−1(kj − sj + 1)2 i∏
s=j+1
dsbs 2(ks − ss + 1)2
16p2
and
max s ∥∥∥∥∥∥ ∂vec ( Xs(i) ) ∂w(j) ∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
= max s
∥∥∥∥ ∂xs(i)
∂w(j)
∥∥∥∥ 2
F
≤",C Technical Lemmas and Their Proofs,[0],[0]
"ricir̃j−1c̃j−1dj−1(kj − sj + 1)2 i∏
s=j+1
dsbs 2(ks − ss + 1)2
16p2 .
",C Technical Lemmas and Their Proofs,[0],[0]
Proof.,C Technical Lemmas and Their Proofs,[0],[0]
"For brevity, letXk(i)(s, t) denotes the (s, t)-th entry in the matrixX k (i) ∈ Rri×ci .",C Technical Lemmas and Their Proofs,[0],[0]
"We also let φ(i,m) =
∂Xk(i)(s,t)
∂X(m) ∈
Rrm×cm×dm .",C Technical Lemmas and Their Proofs,[0],[0]
"So similar to Lemma 9, we have
φq(i,m) =up
  dm+1∑
k=1
φ̃k(i,m+1)~̃Ŵ k,q (m+1)   σ′1(Xq(m))",C Technical Lemmas and Their Proofs,[0],[0]
"∈ Rrm×cm , (q = 1, · · · , dm),
where the matrix Ŵ k,q(m+1) ∈ Rkm+1×km+1 is obtained by rotating W k,q (m+1) with 180 degrees.",C Technical Lemmas and Their Proofs,[0],[0]
"Then according to the relationship betweenX(j) andW(j), we can compute
∂Xk(i)(s, t)
∂W g,h(j) = Zh(j−1)~̃φ g (i,j) ∈ Rkj×kj , (h = 1, · · · , dj−1; g = 1, · · · , dj).
",C Technical Lemmas and Their Proofs,[0],[0]
"Therefore, we can further obtain ∥∥∥∥∥ ∂Xk(i)(s, t)
∂w(j)
∥∥∥∥∥ 2
F
=
dj∑
g=1
dj−1∑
h=1
∥∥∥∥∥ ∂Xk(i)(s, t)
∂W g,h(j)
",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥ 2
F
=
dj∑
g=1
dj−1∑
h=1
∥∥∥∥∥ ∂Xk(i)(s, t)
∂W",C Technical Lemmas and Their Proofs,[0],[0]
"g,h(j)
",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥ 2
F
=
dj∑
g=1
dj−1∑
h=1
∥∥∥Zh(j−1)~̃φg(i,j) ∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ dj∑
g=1
dj−1∑
h=1
(kj − sj + 1)2 ∥∥∥Zh(j−1) ∥∥∥ 2
F
∥∥∥φg(i,j) ∥∥∥ 2
F ≤ (kj − sj + 1)2
∥∥∥Z(j−1) ∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
∥∥∥φ(i,j) ∥∥∥ 2
F
≤r̃j−1c̃j−1dj−1(kj − sj + 1)2 ∥∥∥φ(i,j) ∥∥∥ 2
F .
",C Technical Lemmas and Their Proofs,[0],[0]
"On the other hand, by Lemma 9, we can further bound ‖φ(i,j)‖2F as follows:
∥∥∥φ(i,m) ∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F =
dm∑
q=1
∥∥∥φq(i,m) ∥∥∥ 2
F =
dm∑
q=1
∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"up   dm+1∑
k=1
φ̃k(i,m+1)~̃Ŵ k,q (m+1)   σ′1(Xq(m))",C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ 1 16p2
dm∑
q=1
∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"dm+1∑
k=1
φ̃k(i,m+1)~̃Ŵ k,q (m+1) ∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ dm+1 16p2
dm∑
q=1
dm+1∑
k=1
∥∥∥φ̃k(i,m+1)~̃Ŵ k,q(m+1) ∥∥∥ 2
F
≤dm+1(km+1",C Technical Lemmas and Their Proofs,[0],[0]
"− sm+1 + 1) 2
16p2
dm∑
q=1
dm+1∑
k=1
∥∥∥φ̃k(i,m+1) ∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
∥∥∥Ŵ k,q(m+1) ∥∥∥ 2
F
¬ = dm+1(km+1",C Technical Lemmas and Their Proofs,[0],[0]
"− sm+1 + 1)2
16p2
dm+1∑
k=1
∥∥∥φ̃k(i,m+1) ∥∥∥ 2
F
∥∥∥Ŵ k(m+1) ∥∥∥ 2
F
≤dm+1bm+1",C Technical Lemmas and Their Proofs,[0],[0]
2(km+1,C Technical Lemmas and Their Proofs,[0],[0]
"− sm+1 + 1)2
16p2
∥∥∥φ(i,m+1) ∥∥∥ 2
F ,
where ¬ holds since ‖W k,q(m+1)‖2F = ‖Ŵ k,q (m+1)‖2F .",C Technical Lemmas and Their Proofs,[0],[0]
"It further yields
∥∥∥φ(i,m) ∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2 F ≤ ∥∥∥φ(i,i) ∥∥∥ 2 F i∏
s=m+1
dsbs 2(ks − ss + 1)2
16p2 ¬ =
i∏
s=m+1
dsbs 2(ks − ss + 1)2
16p2 .
",C Technical Lemmas and Their Proofs,[0],[0]
"where ¬ holds since we have ∥∥∥φ(i,i) ∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F =
∥∥∥∥ ∂Xk(i)(s,t)
∂X(i)
∥∥∥∥ 2
F
= 1.
",C Technical Lemmas and Their Proofs,[0],[0]
"Therefore, we have ∥∥∥∥∥ ∂xk(i)
∂w(j)
∥∥∥∥∥ 2
F
=
ri∑
s=1
ci∑
t=1
∥∥∥∥∥ ∂Xk(i)(s, t)
∂w(j)
∥∥∥∥∥ 2
F
≤ ri∑
s=1
ci∑
t=1
r̃j−1c̃j−1dj−1(kj − sj + 1)2 ∥∥∥φ(i,j) ∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
=ricir̃j−1c̃j−1dj−1(kj − sj + 1)2 ∥∥∥φ(i,j) ∥∥∥ 2
F
≤ricir̃j−1c̃j−1dj−1(kj − sj + 1)2 i∏
s=j+1
dsbs 2(ks − ss + 1)2
16p2 .
",C Technical Lemmas and Their Proofs,[0],[0]
"It further gives ∥∥∥∥ ∂x(i)
∂w(j)
∥∥∥∥ 2
F
=
di∑
s=1
∥∥∥∥ ∂xs(i)
∂w(j)
∥∥∥∥ 2
F
≤ diricir̃j−1c̃j−1dj−1(kj − sj + 1)2 i∏
s=j+1
dsbs 2(ks − ss + 1)2
16p2 .
",C Technical Lemmas and Their Proofs,[0],[0]
"The proof is completed.
",C Technical Lemmas and Their Proofs,[0],[0]
Lemma 13.,C Technical Lemmas and Their Proofs,[0],[0]
"Suppose that the activation function σ1 is sigmoid and σ2 is softmax, and the loss function f(w,D) is squared loss.",C Technical Lemmas and Their Proofs,[0],[0]
"Then the gradient of δsl with respect to w(j) can be bounded as follows:
∥∥∥∥ ∂δsl ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ ϑ̃bl+1 2
16p2
∥∥∥W s(l+1)",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥ 2
F dlrlclr̃j−1c̃j−1dj−1(kj − sj + 1)2
l∏
s=j+1
dsbs 2(ks − ss + 1)2
16p2
and ∥∥∥∥ ∂δl ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ ϑ̃bl+1 4
16p2 dlrlclr̃j−1c̃j−1dj−1(kj − sj + 1)2
l∏
s=j+1
dsbs 2(ks",C Technical Lemmas and Their Proofs,[0],[0]
"− ss + 1)2
16p2 ,
where ϑ̃ = 364 .
",C Technical Lemmas and Their Proofs,[0],[0]
Proof.,C Technical Lemmas and Their Proofs,[0],[0]
Assume thatW(l+1) =,C Technical Lemmas and Their Proofs,[0],[0]
"[W 1(l+1),W 2 (l+1), · · · ,W dl(l+1)] whereW i(l+1) ∈ Rdl+1×r̃lc̃l is a submatrix inW(l+1).",C Technical Lemmas and Their Proofs,[0],[0]
Then we have v = σ2( ∑dl k=1W k,C Technical Lemmas and Their Proofs,[0],[0]
(l+1)z k (l)).,C Technical Lemmas and Their Proofs,[0],[0]
"For brevity, we further define a matrixG(k) as follows:
",C Technical Lemmas and Their Proofs,[0],[0]
"G(k)= [ σ′1 ( x(k) ) , σ′1 ( x(k) ) , · · · , σ′1 ( x(k) ) ︸",C Technical Lemmas and Their Proofs,[0],[0]
"︷︷ ︸
rkck columns
] ∈ Rrkckdk×rkck ,
Then we have
∂
∂z(l)
( ∂f(w,D)
∂zs(l)
) =",C Technical Lemmas and Their Proofs,[0],[0]
[ (v − y)T ⊗ (W s(l+1))T ] Q (u)W(l+1) +,C Technical Lemmas and Their Proofs,[0],[0]
"(W s(l+1)) TG (u)G (u)W(l+1),
where Q (u) is a matrix of size d2l+1 × dl+1",C Technical Lemmas and Their Proofs,[0],[0]
"whose (s, (s− 1)dl+1 + s) entry equal to σ1(us)(1− σ1(us))(1− 2σ1(us)) and rest entries are all 0.",C Technical Lemmas and Their Proofs,[0],[0]
"Accordingly, we have
∥∥∥∥∥ ∂
∂z(l)
( ∂f(w,D)
∂zs(l)
)∥∥∥∥∥ 2
F
≤2 (∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
[ (v − y)T ⊗ (W s(l+1))T ] Q (u)W(l+1) ∥∥∥ 2 F + ∥∥∥(W s(l+1))TG (u)G (u)W(l+1) ∥∥∥ 2 F ) ≤2,C Technical Lemmas and Their Proofs,[0],[0]
"( 26
38 ‖v",C Technical Lemmas and Their Proofs,[0],[0]
"− y‖2F
∥∥∥W s(l+1)",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥ 2
F
∥∥W(l+1)",C Technical Lemmas and Their Proofs,[0],[0]
∥∥2,C Technical Lemmas and Their Proofs,[0],[0]
"F + 1
162
∥∥∥W s(l+1) ∥∥∥ 2
F
∥∥W(l+1) ∥∥2",C Technical Lemmas and Their Proofs,[0],[0]
"F
)
¬ ≤2 ( 27
38 +
1
162
) bl+1 2 ∥∥∥W s(l+1) ∥∥∥ 2
F
≤ 3 64 bl+1
2 ∥∥∥W s(l+1) ∥∥∥ 2
F ,
where we have ‖v − y‖2F ≤ 2 by Lemma 8.",C Technical Lemmas and Their Proofs,[0],[0]
"Then by similar way, we can have
∥∥∥∥ ∂δsl ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
= ∥∥∥∥∥ ∂
∂z(l)
( ∂f(w,D)
∂zs(l)
) ∂z(l)
",C Technical Lemmas and Their Proofs,[0],[0]
∂yl ∂yl ∂x(l),C Technical Lemmas and Their Proofs,[0],[0]
"∂x(l) ∂w(j) ∥∥∥∥∥ 2
F
≤ 3 64 ∗ 16p2 bl+1
2 ∥∥∥W",C Technical Lemmas and Their Proofs,[0],[0]
s(l+1),C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
∥∥∥∥ ∂x(l)
∂w(j)
∥∥∥∥ 2
F
≤ 3 64 ∗ 16p2 bl+1
2 ∥∥∥W s(l+1) ∥∥∥ 2
F dlrlclr̃j−1c̃j−1dj−1(kj − sj + 1)2
l∏
s=j+1
dsbs 2(ks − ss + 1)2
16p2 .
",C Technical Lemmas and Their Proofs,[0],[0]
"Therefore, we can further obtain:
∥∥∥∥ ∂δl ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
=
dl+1∑
s=1
∥∥∥∥ ∂δsl ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ 3 64 ∗ 16p2 bl+1
4dlrlclr̃j−1c̃j−1dj−1(kj − sj + 1)2",C Technical Lemmas and Their Proofs,[0],[0]
"l∏
s=j+1
dsbs 2(ks",C Technical Lemmas and Their Proofs,[0],[0]
"− ss + 1)2
16p2 .
",C Technical Lemmas and Their Proofs,[0],[0]
"The proof is completed.
",C Technical Lemmas and Their Proofs,[0],[0]
Lemma 14.,C Technical Lemmas and Their Proofs,[0],[0]
"Suppose that the activation function σ1 is sigmoid and σ2 is softmax, and the loss function f(w,D) is squared loss.",C Technical Lemmas and Their Proofs,[0],[0]
"Then the Hessian of f(w,x) with respect to w can be bounded as follows:
∥∥∇2wf(w,D) ∥∥2 F ≤",C Technical Lemmas and Their Proofs,[0],[0]
"O (γ2) ,
where γ = ( ϑbl+1
2d20 b14d21",C Technical Lemmas and Their Proofs,[0],[0]
l2r20c 2 0,C Technical Lemmas and Their Proofs,[0],[0]
[∏l s=1 dsbs 2(ks−ss+1)2 8 √ 2p2 ]2)1/2 .,C Technical Lemmas and Their Proofs,[0],[0]
"With the same condition, we can bound the operation norm of
∇3wf(w,D).",C Technical Lemmas and Their Proofs,[0],[0]
"That is, there exists a universal constant ν such that ∥∥∇3wf(w,D) ∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"op ≤ ν.
",C Technical Lemmas and Their Proofs,[0],[0]
Proof.,C Technical Lemmas and Their Proofs,[0],[0]
"From Lemma 9, we can further compute the Hessian matrix ∇2wf(w,D).",C Technical Lemmas and Their Proofs,[0],[0]
"Recall that wk(i) ∈ Rki 2di−1 (k =
1, · · · , dl) is the vectorization of W k(i) ∈ Rki×ki×di−1 , i.e. wk(i) =",C Technical Lemmas and Their Proofs,[0],[0]
"[ vec ( W 1(i)(:, : 1) ) ; · · · ; vec ( W di(i)(:, :, di−1) )] .
",C Technical Lemmas and Their Proofs,[0],[0]
Let w(i) =,C Technical Lemmas and Their Proofs,[0],[0]
"[ w1(i); · · · ;wdi(i) ] ∈ Rki2di−1×di (i = 1, · · · , l).",C Technical Lemmas and Their Proofs,[0],[0]
"Also, w(l+1) ∈ Rr̃lc̃ldldl+1 is the vectorization of the weight matrixW(l+1).",C Technical Lemmas and Their Proofs,[0],[0]
"Then if 1 ≤ i, j ≤",C Technical Lemmas and Their Proofs,[0],[0]
"l, we can have
∂2f(w,D)
∂w(j)∂w",C Technical Lemmas and Their Proofs,[0],[0]
"k (i)
=   ",C Technical Lemmas and Their Proofs,[0],[0]
"∂2f(w,D) ∂w(j)∂w",C Technical Lemmas and Their Proofs,[0],[0]
"k,1 (i) ∂2f(w,D) ∂w(j)∂w",C Technical Lemmas and Their Proofs,[0],[0]
"k,2 (i) ...",C Technical Lemmas and Their Proofs,[0],[0]
"∂2f(w,D)
∂w(j)∂w",C Technical Lemmas and Their Proofs,[0],[0]
"k,di−1 (i)
  =   ∂(vec(Z1(i−1)~̃δ̃ki )) ∂w(j) ∂(vec(Z2(i−1)~̃δ̃ki )) ∂w(j) ... ∂",C Technical Lemmas and Their Proofs,[0],[0]
"( vec ( Z di−1 (i−1)~̃δ̃ki ))
∂w(j)
 
=   P1 ( δ̃ki ) ∂(vec(Z1(i−1))) ∂w(j) +",C Technical Lemmas and Their Proofs,[0],[0]
P2 ( Z1(i−1) ),C Technical Lemmas and Their Proofs,[0],[0]
∂(vec(δ̃ki )) ∂w(j) P1 ( δ̃ki ) ∂(vec(Z2(i−1))) ∂w(j) + P2 ( Z2(i−1) ),C Technical Lemmas and Their Proofs,[0],[0]
"∂(vec(δ̃ki )) ∂w(j) ...
",C Technical Lemmas and Their Proofs,[0],[0]
P1 ( δ̃ki )∂(vec(Zdi−1 (i−1) )) ∂w(j) + P2 ( Z di−1 (i−1) ),C Technical Lemmas and Their Proofs,[0],[0]
"∂(vec(δ̃ki )) ∂w(j)
  ∈ Rki2di−1×kj2djdj−1 ,
(4)
where P1 ( δ̃ki ) ∈ Rki2×r̃i−1c̃i−1di−1 and P2 ( Z di−1 (i−1) ) ∈ Rki2×(r̃i−ki+1)(c̃i−ki+1) satisfy: each row in P1 ( δ̃ki ) contains
the vectorization of (δ̃ki ) T at the right position and the remaining entries are 0s, and each row in P2 ( Z di−1 (i−1) ) is the submatrix in Zdi−1(i−1) that need to conduct inner product with δ̃ k i in turn.",C Technical Lemmas and Their Proofs,[0],[0]
"Note that there are si− 1 rows and columns between
each neighboring nonzero entries inN which is decided by the definition of δ̃i+1 in Sec. B.1.",C Technical Lemmas and Their Proofs,[0],[0]
"Accordingly, we have
∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
P1 ( δ̃ki )∂ ( vec ( Z di−1 (i−1) )) ∂w(j) ∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ (ki − si + 1)2‖δ̃ki ‖2F ∥∥∥∥∥∥ ∂",C Technical Lemmas and Their Proofs,[0],[0]
( vec ( Z di−1 (i−1) )) ∂w(j) ∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
= (ki − si + 1)2‖δki ‖2F ∥∥∥∥∥∥ ∂",C Technical Lemmas and Their Proofs,[0],[0]
( vec ( Z di−1 (i−1) )) ∂w(j) ∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
and
∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
P2 ( Z di−1 (i−1) )∂,C Technical Lemmas and Their Proofs,[0],[0]
( vec ( δ̃ki )) ∂w(j) ∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ (ki − si + 1)2‖Zdi−1(i−1)‖2F ∥∥∥∥∥∥ ∂",C Technical Lemmas and Their Proofs,[0],[0]
( vec ( δ̃ki )) ∂w(j) ∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
= (ki − si + 1)2‖Zdi−1(i−1)‖2F ∥∥∥∥∥ ∂ ( vec ( δki ))
∂w(j)
∥∥∥∥∥ 2
F
.
",C Technical Lemmas and Their Proofs,[0],[0]
"Then in order to bound
‖∇2wf(w,D)‖2F = l+1∑
i=1
l+1∑
j=1
∥∥∥∥ ∂2f(w,D)
∂w(j)∂w(i)
∥∥∥∥ 2
F
,
we try to bound each term separately.",C Technical Lemmas and Their Proofs,[0],[0]
So we consider the following five cases:,C Technical Lemmas and Their Proofs,[0],[0]
l ≥,C Technical Lemmas and Their Proofs,[0],[0]
"i ≥ j, i ≤ j ≤",C Technical Lemmas and Their Proofs,[0],[0]
"l, l + 1 = i > j, l + 1 = j >",C Technical Lemmas and Their Proofs,[0],[0]
i,C Technical Lemmas and Their Proofs,[0],[0]
"and l + 1 = i = j.
Case 1:",C Technical Lemmas and Their Proofs,[0],[0]
l ≥,C Technical Lemmas and Their Proofs,[0],[0]
i ≥,C Technical Lemmas and Their Proofs,[0],[0]
"j
In the following, we first consider the first case, i.e. i ≥ j, and bound ∥∥∥∥∥∥ ∂",C Technical Lemmas and Their Proofs,[0],[0]
( vec ( δ̃ki )) ∂w(j) ∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
= ∥∥∥∥∥ ∂ ( vec ( δki ))
∂w(j)
∥∥∥∥∥ 2
F
= ∥∥∥∥∥∥ ∂ ∂w(j)",C Technical Lemmas and Their Proofs,[0],[0]
"vec  up   di+1∑
s=1
δ̃si+1~̃Ŵ s,k(i+1)   σ′1(Xk(i))   ",C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
¬ ≤ 2
16 ∥∥∥∥∥∥ ∂ ∂w(j) vec  up   di+1∑
s=1
δ̃si+1~̃Ŵ s,k(i+1)     ",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥∥ 2
F
+ 2 ∥∥∥∥∥∥ up   di+1∑
s=1
δ̃si+1~̃Ŵ s,k(i+1)   ",C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
∥∥∥∥∥ ∂σ′1(X",C Technical Lemmas and Their Proofs,[0],[0]
"k (i))
∂w(j)
∥∥∥∥∥ 2
F
= 2
16p2 ∥∥∥∥∥∥ ∂ ∂w(j) vec   di+1∑
s=1
δ̃si+1~̃Ŵ s,k(i+1)   ",C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
+ 2
p2 ∥∥∥∥∥∥ di+1∑
s=1
δ̃si+1~̃Ŵ s,k(i+1) ∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
∥∥∥∥∥∥ ∂vec ( σ′(xk(i)) )",C Technical Lemmas and Their Proofs,[0],[0]
∂xk(i) ∂xk(i) ∂w(j) ∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
 ≤ 2
16p2 ∥∥∥∥∥∥ ∂ ∂w(j) vec   di+1∑
s=1
δ̃si+1~̃Ŵ s,k(i+1)   ",C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
+ 2 · 26 38p2 ∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"di+1∑
s=1
δ̃si+1~̃Ŵ s,k(i+1)",C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
∥∥∥∥∥ ∂Xk(i)
∂w(j)
∥∥∥∥∥ 2
F
® ≤2di+1
16p2 (ki+1−si+1+1)2
di+1∑
s=1
‖Ŵ s,k(i+1)‖2F ∥∥∥∥∥ ∂δ̃si+1 ∂w(j) ∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
+ 2 · 26 38p2 di+1(ki+1−si+1+1)2 di+1∑
s=1
∥∥∥Ŵ s,k(i+1) ∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
∥∥∥δ̃si+1 ∥∥∥ 2
F ∥∥∥∥∥ ∂Xk(i)
∂w(j)
",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥ 2
F
¯ = 2di+1 16p2
(ki+1−si+1+1)2 di+1∑
s=1
‖W s,k(i+1)‖2F ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
∂δsi+1 ∂w(j),C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
+ 2 · 26 38p2 di+1(ki+1−si+1+1)2 di+1∑
s=1
∥∥∥W s,k(i+1) ∥∥∥ 2
F
∥∥δsi+1 ∥∥2 F ∥∥∥∥∥ ∂Xk(i)
∂w(j)
∥∥∥∥∥ 2
F
.
(5)
¬ holds sinceXk(i) is independent onw(j) and the values of entries in σ ′",C Technical Lemmas and Their Proofs,[0],[0]
1(X k,C Technical Lemmas and Their Proofs,[0],[0]
"(i)) is not larger than 1/4 since for any constant a, σ′(a) = σ(a)(1− σ(a)) ≤ 1/4.  ",C Technical Lemmas and Their Proofs,[0],[0]
"holds since for arbitrary tensorM , we have ‖up (M)‖2F ≤ ‖M‖2F /p2",C Technical Lemmas and Their Proofs,[0],[0]
"in Lemma 8, and we also have
∥∥∥∥∥∥ ∂vec ( σ′(xk(i)) )",C Technical Lemmas and Their Proofs,[0],[0]
∂xk(i) ∂xk(i) ∂w(j) ∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
= ∥∥∥∥∥Q ( xk(i) )",C Technical Lemmas and Their Proofs,[0],[0]
"∂xk(i) ∂w(j) ∥∥∥∥∥ 2
F
≤ 2 6
38 ∥∥∥∥∥ ∂xk(i)
∂w(j)
∥∥∥∥∥ 2
F
= 26
38 ∥∥∥∥∥ ∂Xk(i)
∂w(j)
∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
.
® holds since we can just adopt similar strategy in Eqn.",C Technical Lemmas and Their Proofs,[0],[0]
"(4) to separate Ŵ s,k(i+1) and the conclusion in Lemma 8; ¯ holds since the difference between δ̃si+1 and δ s i+1 is that we pad 0 around δ s i+1 to obtain δ̃ s i+1, indicating ‖δsi+1‖2F = ‖δ̃si+1‖2F .
",C Technical Lemmas and Their Proofs,[0],[0]
"Accordingly, we can further bound ∥∥∥∥∥ ∂δ̃i ∂w(j) ∥∥∥∥∥ 2
F
=
di−1∑
k=1
∥∥∥∥∥ ∂ ( vec ( δki ))
∂w(j)
∥∥∥∥∥ 2
F
≤2di+1 16p2
(ki+1−si+1+1)2 di−1∑
k=1
di+1∑
s=1
‖W s,k(i+1)‖2F ∥∥∥∥ ∂δsi+1 ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
+ 2 · 26 38p2 di+1(ki+1−si+1+1)2 di−1∑
k=1
di+1∑
s=1
∥∥∥W s,k(i+1) ∥∥∥ 2
F
∥∥δsi+1 ∥∥2 F ∥∥∥∥∥ ∂Xk(i)
∂w(j)
∥∥∥∥∥ 2
F
≤2di+1 16p2
(ki+1−si+1+1)2 di+1∑
s=1
‖W s(i+1)‖2F ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
∂δsi+1 ∂w(j),C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
+ 2 · 26 38p2 di+1(ki+1−si+1+1)2 ∥∥δi+1",C Technical Lemmas and Their Proofs,[0],[0]
∥∥2,C Technical Lemmas and Their Proofs,[0],[0]
F max s ∥∥∥W s(i+1),C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥ 2 F max k ∥∥∥∥∥ ∂Xk(i)
",C Technical Lemmas and Their Proofs,[0],[0]
"∂w(j)
∥∥∥∥∥ 2
F
¬ ≤2di+1
16p2 (ki+1−si+1+1)2bi+12 ∥∥∥∥ ∂δi+1 ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
+ 2 · 26 38p2 di+1(ki+1−si+1+1)2bi+12 ∥∥δi+1 ∥∥2",C Technical Lemmas and Their Proofs,[0],[0]
"F max k ∥∥∥∥∥ ∂Xk(i)
∂w(j)
",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥ 2
F
 ≤2di+1
16p2 (ki+1−si+1+1)2bi+12 ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"∂δi+1 ∂w(j) ∥∥∥∥ 2
F
+ ϑbl+1 2dj−1 3p2bj 2dj ricirj−1cj−1
l∏
s=j
dsbs 2(ks − ss + 1)2
16p2 ,
where ¬ holds since we have ‖W s(i+1)‖F ≤ rw;  holds due to the bounds of ∥∥δi+1 ∥∥2 F and ∥∥∥∥ ∂Xk(i) ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
in Lemma 10
and 12.
",C Technical Lemmas and Their Proofs,[0],[0]
"Then, we can use the above recursion inequality to further obtain
∥∥∥∥ ∂δi ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ [ i+1∏
s=i+1
2ds 16p2
(ks−ss+1)2bs2 ] 2di+2
16p2 (ki+2−si+2+1)2bi+22 ∥∥∥∥ ∂δi+2 ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
+ ϑbl+1 2dj−1 3p2bj 2dj rj−1cj−1ri+1ci+1
",C Technical Lemmas and Their Proofs,[0],[0]
"l∏
s=j
dsbs 2(ks−ss+1)2
16p2
 
+ ϑbl+1 2dj−1 3p2bj 2dj ricirj−1cj−1
l∏
s=j
dsbs 2(ks − ss + 1)2
16p2
≤",C Technical Lemmas and Their Proofs,[0],[0]
"[ l∏
s=i+1
2ds 16p2 (ks−ss+1)2bs2 ]∥∥∥∥ ∂δl ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
+ ϑbl+1 2dj−1 3p2bj 2dj rj−1cj−1
l∏
s=j
dsbs 2(ks − ss + 1)2
16p2
[ rici + ri+1ci+1",C Technical Lemmas and Their Proofs,[0],[0]
"[ i+1∏
s=i+1
2ds 16p2
(ks−ss+1)2bs2 ]
+ri+2ci+2
[ i+2∏
s=i+1
2ds 16p2
(ks−ss+1)2bs2 ] + · · ·+ rlcl [ l∏
s=i+1
2ds 16p2
(ks−ss+1)2bs2 ]] .
",C Technical Lemmas and Their Proofs,[0],[0]
"By Lemma 13, we have
∥∥∥∥ ∂δl ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ ϑ̃bl+1",C Technical Lemmas and Their Proofs,[0],[0]
"4dj−1
p2bj 2dj
dlrlclrj−1cj−1
l∏
s=j
dsbs 2(ks − ss + 1)2
16p2 ,
where ϑ̃ = 364 .",C Technical Lemmas and Their Proofs,[0],[0]
"Thus, we can establish
∥∥∥∥ ∂δi ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤ ϑ̃bl+1 2dj−1
p2bj 2dj
rj−1cj−1
[ τ
3 + bl+1
2dlrlcl
l∏
s=i+1
dsbs 2(ks − ss + 1)2
16p2
]",C Technical Lemmas and Their Proofs,[0],[0]
"l∏
s=j
dsbs 2(ks",C Technical Lemmas and Their Proofs,[0],[0]
"− ss + 1)2
16p2 .
",C Technical Lemmas and Their Proofs,[0],[0]
where τ = rici + ri+1ci+1,C Technical Lemmas and Their Proofs,[0],[0]
[∏i+1 s=i+1 2ds 16p2 (ks−ss+1)2bs 2 ] + · · ·+ rlcl [∏l s=i+1 2ds 16p2 (ks−ss+1)2bs 2 ] .,C Technical Lemmas and Their Proofs,[0],[0]
"It further gives the bound of ∥∥∥ ∂
2f(w,x) ∂w(j)∂w(i)
∥∥∥ 2
F as follows:
∥∥∥∥ ∂2f(w,D)
∂w(j)∂w(i)
∥∥∥∥ 2
F
=
di−1∑
k=1
∥∥∥∥∥ ∂2f(w,D)
∂w(j)∂w",C Technical Lemmas and Their Proofs,[0],[0]
"k (i)
∥∥∥∥∥ 2
F
=
di−1∑
k=1
di∑
s=1
∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
P1 ( δki )∂,C Technical Lemmas and Their Proofs,[0],[0]
( vec ( Xs(i−1) )) ∂w(j) +,C Technical Lemmas and Their Proofs,[0],[0]
P2 ( Xs(i−1) )∂ ( vec ( δki )) ∂w(j) ∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
≤2 di−1∑
k=1
di∑
s=1
  ∥∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
P1 ( δki )∂,C Technical Lemmas and Their Proofs,[0],[0]
( vec ( Xs(i−1) )) ∂w(j) ∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
+ ∥∥∥∥∥P2 ( Xs(i−1) )∂",C Technical Lemmas and Their Proofs,[0],[0]
"( vec ( δki ))
∂w(j)
∥∥∥∥∥ 2
F
 
≤2(ki−si+1)2 di−1∑
k=1
di∑
s=1
  ∥∥δki ∥∥2",C Technical Lemmas and Their Proofs,[0],[0]
F ∥∥∥∥∥∥ ∂,C Technical Lemmas and Their Proofs,[0],[0]
( vec ( Xs(i−1) )) ∂w(j) ∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
+ ∥∥∥Xs(i−1) ∥∥∥ 2
F ∥∥∥∥∥ ∂ ( vec ( δki ))
∂w(j)
",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥ 2
F
 
≤2(ki−si+1)2  ‖δi‖2F ∥∥∥∥∥∥ ∂",C Technical Lemmas and Their Proofs,[0],[0]
( vec ( X(i−1) )) ∂w(j) ∥∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
+ ∥∥∥X(i−1) ∥∥∥ 2
F ∥∥∥∥ ∂ (vec (δi)) ∂w(j) ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"2
F
 
¬ ≤32ϑbl+1 2di−1 bi 2bj 2didj ri−1ci−1rj−1cj−1
l∏
s=i+1
dsbs 2(ks − ss + 1)2
16p2 + ri−1ci−1di−1 ∥∥∥∥ ∂",C Technical Lemmas and Their Proofs,[0],[0]
(vec (δi)) ∂w(j) ∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"2
F
 ≤O  ϑbl+1
2di−1dj−1 bi 2bj 2didj ri−1ci−1rj−1cj−1
  l∏
s=j
dsbs 2(ks − ss + 1)2
16p2
  [ l∏
s=i
2dsbs 2(ks",C Technical Lemmas and Their Proofs,[0],[0]
"− ss + 1)2
16p2
]  .
",C Technical Lemmas and Their Proofs,[0],[0]
"where ¬ holds because of Lemma 12, while  holds due to 13.
",C Technical Lemmas and Their Proofs,[0],[0]
Case 2: i ≤ j ≤,C Technical Lemmas and Their Proofs,[0],[0]
"l
Since ∂ 2f(w,D) ∂w∂wT is symmetrical, we have ∂ 2f(w,D)
",C Technical Lemmas and Their Proofs,[0],[0]
"∂wT (i) ∂w(j)
=
( ∂2f(w,D)
∂wT (j) ∂w(i)
)T (1 ≤ i, j ≤ l).",C Technical Lemmas and Their Proofs,[0],[0]
"Thus, it yields
∥∥∥∥∥ ∂2f(w,D)
∂wT(i)∂w(j)
∥∥∥∥∥ 2
F
= ∥∥∥∥∥ ∂2f(w,D)
∂wT(j)∂w(i)
∥∥∥∥∥ 2
F
.
",C Technical Lemmas and Their Proofs,[0],[0]
Case 3: l + 1,C Technical Lemmas and Their Proofs,[0],[0]
= i >,C Technical Lemmas and Their Proofs,[0],[0]
"j
In the following, we first consider the first case, i.e. cross entropy and softmax activation, and bound
∥∥∥∥ ∂2f(w,D)
∂w(j)∂w(l+1)
∥∥∥∥ 2
F
= ∥∥∥∥∥ ∂(v",C Technical Lemmas and Their Proofs,[0],[0]
"− y)zT(l)
∂w(j)
∥∥∥∥∥ 2
F
= ∥∥∥∥∥[Ir̃lc̃ldl ⊗ (v − y)]",C Technical Lemmas and Their Proofs,[0],[0]
"∂zT(l)
",C Technical Lemmas and Their Proofs,[0],[0]
"∂x(l)
∂x(l) ∂w(j)",C Technical Lemmas and Their Proofs,[0],[0]
"+ [ z(l) ⊗ Idl+1 ] ∂v ∂z(l) ∂z(l) ∂x(l) ∂x(l) ∂w(j) ∥∥∥∥∥ 2
F
= ∥∥∥∥ũp ( [Ir̃lc̃ldl ⊗ (v − y)] + [ z(l) ⊗ Idl+1 ] diag (σ′2(u))W(l+1) ) G(l) ∂x(l)
∂w(j)
∥∥∥∥ 2
F
,
whereG(l) is defined as
G(l)=",C Technical Lemmas and Their Proofs,[0],[0]
"[ σ′1 ( x(l) ) , σ′1 ( x(l) ) , · · · , σ′1 ( x(l) ) ︸",C Technical Lemmas and Their Proofs,[0],[0]
"︷︷ ︸
rlcl columns
] ∈",C Technical Lemmas and Their Proofs,[0],[0]
"Rrlcldl×rlcl .
",C Technical Lemmas and Their Proofs,[0],[0]
"Thus, we can further obtain ∥∥∥∥ ∂2f(w,D)
∂w(j)∂w(l+1)
∥∥∥∥ 2
F
≤ 1 16p2
∥∥[Ir̃lc̃ldl ⊗ (v − y)] +",C Technical Lemmas and Their Proofs,[0],[0]
[ z(l) ⊗ Idl+1 ] diag (σ′2(u))W(l+1) ∥∥2,C Technical Lemmas and Their Proofs,[0],[0]
"F ∥∥∥∥ ∂x(l)
∂w(j)
∥∥∥∥ 2
F
≤ 2 16p2
( ‖Ir̃lc̃ldl ⊗ (v − y)‖2F + ∥∥[z(l) ⊗ Idl+1 ] diag (σ′2(u))W(l+1) ∥∥2 F )∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"∂x(l)
∂w(j)
∥∥∥∥ 2
F
¬ ≤ 2
16p2
( ‖Ir̃lc̃ldl ⊗ (v − y)‖2F + ∥∥z(l) ⊗",C Technical Lemmas and Their Proofs,[0],[0]
[ diag (σ′2(u))W(l+1) ]∥∥2 F )∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"∂x(l)
∂w(j)
∥∥∥∥ 2
F
 ≤ 1
8p2 r̃lc̃ldl
( 2 + 1
16 bl+1
2 )",C Technical Lemmas and Their Proofs,[0],[0]
"dlrlclr̃j−1c̃j−1dj−1(kj − sj + 1)2 l∏
s=j+1
dsbs 2(ks − ss + 1)2
16p2
= 2dj−1 p4bj 2dj r2l",C Technical Lemmas and Their Proofs,[0],[0]
c 2,C Technical Lemmas and Their Proofs,[0],[0]
"l d 2 l rj−1cj−1
( 2 + 1
16 bl+1
2
)",C Technical Lemmas and Their Proofs,[0],[0]
"l∏
s=j
dsbs 2(ks",C Technical Lemmas and Their Proofs,[0],[0]
"− ss + 1)2
16p2
where ¬ holds since for an arbitrary vector u ∈",C Technical Lemmas and Their Proofs,[0],[0]
Rk and an arbitrary matrixM ∈,C Technical Lemmas and Their Proofs,[0],[0]
"Rk×k, we have (u⊗ Ik)M = u⊗M ;  holds since we use Lemma 12 and the assumption that ‖W(l+1)‖2F ≤ bl+12.",C Technical Lemmas and Their Proofs,[0],[0]
Now we consider the least square loss and softmax activation function.,C Technical Lemmas and Their Proofs,[0],[0]
"In such a case, we can further obtain:
∥∥∥∥ ∂2f(w,D)
∂w(j)∂w(l+1)
∥∥∥∥ 2
F
= ∥∥∥∥∥ ∂(v",C Technical Lemmas and Their Proofs,[0],[0]
"− y)G (u)zT(l)
∂w(j)
∥∥∥∥∥ 2
F
= ∥∥∥∥∥[Ir̃lc̃ldl ⊗ (v − y)] ∂zT(l)
∂x(l)
∂x(l) ∂w(j) + [ z(l) ⊗ (v − y) ] ∂vec (G (u))",C Technical Lemmas and Their Proofs,[0],[0]
"∂u ∂u ∂z(l) ∂z(l) ∂x(l) ∂x(l) ∂w(j) + [ z(l) ⊗ Idl+1 ] ∂v ∂z(l) ∂z(l) ∂x(l) ∂x(l) ∂w(j) ∥∥∥∥∥ 2
F
= ∥∥∥∥ũp",C Technical Lemmas and Their Proofs,[0],[0]
( [Ir̃lc̃ldl ⊗ (v − y)],C Technical Lemmas and Their Proofs,[0],[0]
+ [ z(l) ⊗ (v − y) ],C Technical Lemmas and Their Proofs,[0],[0]
Q (u)W(l+1) +,C Technical Lemmas and Their Proofs,[0],[0]
[ z(l) ⊗ Idl+1 ] Q (u)G (u)W(l+1) ),C Technical Lemmas and Their Proofs,[0],[0]
G(l),C Technical Lemmas and Their Proofs,[0],[0]
"∂x(l)
∂w(j)
∥∥∥∥ 2
F
.
",C Technical Lemmas and Their Proofs,[0],[0]
"Thus, we can further obtain
∥∥∥∥ ∂2f(w,D)
∂w(j)∂w(l+1)
∥∥∥∥ 2
F
≤ 1 16p2
∥∥[Ir̃lc̃ldl ⊗ (v − y)] + [ z(l) ⊗ (v − y) ]",C Technical Lemmas and Their Proofs,[0],[0]
Q (u)W(l+1) +,C Technical Lemmas and Their Proofs,[0],[0]
"[ z(l) ⊗ Idl+1 ] Q (u)G (u)W(l+1) ∥∥2 F ∥∥∥∥ ∂x(l)
∂w(j)
∥∥∥∥ 2
F
≤ 3 16p2
( ‖Ir̃lc̃ldl ⊗ (v − y)‖2F + ∥∥[z(l) ⊗ (v − y) ]",C Technical Lemmas and Their Proofs,[0],[0]
Q (u)W(l+1) ∥∥2 F + ∥∥[z(l),C Technical Lemmas and Their Proofs,[0],[0]
⊗ Idl+1 ],C Technical Lemmas and Their Proofs,[0],[0]
Q (u)G (u)W(l+1) ∥∥2 F )∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"∂x(l)
∂w(j)
∥∥∥∥ 2
F
¬ ≤ 3
16p2 r̃lc̃ldl
( 2 + 3
100 bl+1
2 )",C Technical Lemmas and Their Proofs,[0],[0]
"dlrlclr̃j−1c̃j−1dj−1(kj − sj + 1)2 l∏
s=j+1
dsbs 2(ks − ss + 1)2
16p2
= 3dj−1 p4bj 2dj rj−1cj−1d",C Technical Lemmas and Their Proofs,[0],[0]
2 l r 2,C Technical Lemmas and Their Proofs,[0],[0]
"l c 2 l
( 2 + 27
38 bl+1
2 + 26
16 · 38 bl+1 2
)",C Technical Lemmas and Their Proofs,[0],[0]
"l∏
s=j
dsbs 2(ks",C Technical Lemmas and Their Proofs,[0],[0]
"− ss + 1)2
16p2 ,
where ¬ holds since we use Lemma 12 and the fact that ‖W(l+1)‖2F ≤ bl+12.",C Technical Lemmas and Their Proofs,[0],[0]
"Case 4: i < j = l + 1
Similar to the Case 2, we also can have
∥∥∥∥∥ ∂2f(w,D)
∂wT(i)∂w(j)
∥∥∥∥∥ 2
F
= ∥∥∥∥∥ ∂2f(w,D)
∂wT(j)∂w(i)
∥∥∥∥∥ 2
F
.
",C Technical Lemmas and Their Proofs,[0],[0]
"So in this case, we can just directly use the bound in case 3 to bound ∥∥∥∥ ∂2f(w,D)
∂wT (i) ∂w(j)
∥∥∥∥ 2
F
.
",C Technical Lemmas and Their Proofs,[0],[0]
"Case 5: i = j = l + 1
In the following, we first consider the first case, i.e. i = l + 1, and bound
∥∥∥∥ ∂2f(w,D)
∂w(l+1)∂w(l+1)
",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥ 2
F
= ∥∥∥∥∥ ∂(v",C Technical Lemmas and Their Proofs,[0],[0]
− y)zT(l) ∂w(l+1),C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥ 2
F
= ∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"[ z(l) ⊗ Idl+1
]",C Technical Lemmas and Their Proofs,[0],[0]
"∂v ∂w(l+1)
∥∥∥∥ 2
F
= ∥∥∥ [ z(l) ⊗ Idl+1 ]",C Technical Lemmas and Their Proofs,[0],[0]
G (u) [ z(l) ⊗ Idl+1 ],C Technical Lemmas and Their Proofs,[0],[0]
"T∥∥∥ 2
F
¬ = ∥∥∥∥ [ z(l) ( z(l) ⊗G (u) )T ]T ∥∥∥∥ 2
F
≤ ∥∥z(l)‖4F",C Technical Lemmas and Their Proofs,[0],[0]
‖G (u) ∥∥2 F ≤ 1 16,C Technical Lemmas and Their Proofs,[0],[0]
r̃2l c̃ 2,C Technical Lemmas and Their Proofs,[0],[0]
"l d 2 l dl+1,
where ¬ holds since for an arbitrary vector u ∈",C Technical Lemmas and Their Proofs,[0],[0]
Rk and an arbitrary matrixM ∈,C Technical Lemmas and Their Proofs,[0],[0]
"Rk×k, we have (u⊗ Ik)M = u⊗M .",C Technical Lemmas and Their Proofs,[0],[0]
"Now we can bound ∥∥∥∂
2f(w,D) ∂w∂w
∥∥∥ 2
F as follows:
∥∥∥∥ ∂2f(w,D)
∂w∂w
∥∥∥∥ 2
F
= ∥∥∥∥ ∂2f(w,D)
∂w(l+1)∂w(l+1)
∥∥∥∥ 2
F
+ 2 l∑
j=1
∥∥∥∥ ∂2f(w,D)
∂w(j)∂w(l+1)
∥∥∥∥ 2
F
+ 2 l∑
j=1
l∑
i=j
∥∥∥∥ ∂2f(w,D)
∂w(j)∂w(i)
∥∥∥∥ 2
F
≤O ( l2
k1 4 max1≤i,j≤l
r̃ic̃irjcj bl+1
4
16p2
( rw 2
8 √ 2p2
)2l−2 l∏
s=1
(dsks 2)2
)
",C Technical Lemmas and Their Proofs,[0],[0]
"≤O  ϑbl+1
2d20 b1 4d21 l2r20c 2 0
[ l∏
s=1
dsbs 2(ks − ss + 1)2
8 √ 2p2
]2  .
",C Technical Lemmas and Their Proofs,[0],[0]
"On the other hand, if the activation functions σ1 and σ2 are respectively sigmoid function and softmax function, f(w,D) is infinitely differentiable.",C Technical Lemmas and Their Proofs,[0],[0]
"Also σ(a), σ′(a), σ′′(a) and σ′′′(a) are all bounded.",C Technical Lemmas and Their Proofs,[0],[0]
"This means that ∇3wf(w,D) exists.",C Technical Lemmas and Their Proofs,[0],[0]
"Also since inputD and the parameter w are bounded, we can always find a universal constant ν such that
‖∇3wf(w,D)‖op = sup ‖λ‖2≤1
〈 λ⊗ 3 ,∇3wf(w,D) 〉 = ∑
i,j,k
[∇3wf(w,D)]ijkλiλjλk ≤ ν",C Technical Lemmas and Their Proofs,[0],[0]
"< +∞.
The proof is completed.
",C Technical Lemmas and Their Proofs,[0],[0]
Lemma 15.,C Technical Lemmas and Their Proofs,[0],[0]
"Suppose that the activation function σ1 is sigmoid and σ2 is softmax, and the loss function f(w,D) is squared loss.",C Technical Lemmas and Their Proofs,[0],[0]
Suppose Assumption 1 on the input dataD holds.,C Technical Lemmas and Their Proofs,[0],[0]
"Then for any t > 0, the objective f(w,x) obeys
P
( 1
n
n∑
i=1
( f(w,D(i))−E(f(w,D(i))) )",C Technical Lemmas and Their Proofs,[0],[0]
">t ) ≤ 2 exp ( −2nt 2
α2
) ,
where α = 1.
",C Technical Lemmas and Their Proofs,[0],[0]
Proof.,C Technical Lemmas and Their Proofs,[0],[0]
"Since the input D(i) (i = 1, · · · , n) are independent from each other, then the output f(w,D(i))",C Technical Lemmas and Their Proofs,[0],[0]
"(i = 1, · · · , n) are also independent.",C Technical Lemmas and Their Proofs,[0],[0]
"Meanwhile, when the loss is the square loss, we can easily bound 0 ≤",C Technical Lemmas and Their Proofs,[0],[0]
"f(w,D(i))",C Technical Lemmas and Their Proofs,[0],[0]
= 12‖v,C Technical Lemmas and Their Proofs,[0],[0]
"− y‖22 ≤ 1, since the value of entries in v belongs to [0, 1] and y is a one-hot vector label of v.
Besides, for arbitrary random variable x, |x− Ex| ≤ |x|.",C Technical Lemmas and Their Proofs,[0],[0]
"So by Hoeffding’s inequality in Lemma 6, we have
P
( 1
n
n∑
i=1
( f(w,D(i))−E(f(w,D(i))) )",C Technical Lemmas and Their Proofs,[0],[0]
">t ) ≤ exp ( −2nt 2
α2
) ,
where α = 1.",C Technical Lemmas and Their Proofs,[0],[0]
This means that 1n,C Technical Lemmas and Their Proofs,[0],[0]
∑n i=1,C Technical Lemmas and Their Proofs,[0],[0]
"( f(w,D(i))−E(f(w,D(i))) ) has exponential tails.
",C Technical Lemmas and Their Proofs,[0],[0]
Lemma 16.,C Technical Lemmas and Their Proofs,[0],[0]
"Suppose that the activation function σ1 is sigmoid and σ2 is softmax, and the loss function f(w,D) is squared loss.",C Technical Lemmas and Their Proofs,[0],[0]
Suppose Assumption 1 on the input dataD holds.,C Technical Lemmas and Their Proofs,[0],[0]
Then for any t > 0 and arbitrary unit vector λ ∈,C Technical Lemmas and Their Proofs,[0],[0]
"Sd−1, the gradient ∇f(w,x) obeys
P
( 1
n
n∑
i=1
(〈 λ,∇wf(w,D(i))−ED∼D∇wf(w,D(i)) 〉) >t ) ≤ exp ( − nt 2
2β2
) .
",C Technical Lemmas and Their Proofs,[0],[0]
"where β , [ ϑr̃lc̃ldl + ∑l i=1 ϑbl+1 2di−1",C Technical Lemmas and Their Proofs,[0],[0]
p2bi2di ri−1ci−1,C Technical Lemmas and Their Proofs,[0],[0]
"∏l s=i dsbs 2(ks−ss+1)2 16p2 ]1/2 in which ϑ = 1/8.
",C Technical Lemmas and Their Proofs,[0],[0]
Proof.,C Technical Lemmas and Their Proofs,[0],[0]
"Since the inputD(i) (i = 1, · · · , n) are independent from each other, then the output∇wf(w,D(i))",C Technical Lemmas and Their Proofs,[0],[0]
"(i = 1, · · · , n) are also independent.",C Technical Lemmas and Their Proofs,[0],[0]
"Furthermore, for arbitrary vector x, ‖x−Ex‖22 ≤ ‖x‖22.",C Technical Lemmas and Their Proofs,[0],[0]
"Hence, for an arbitrary unit vector λ ∈ Sd−1 where d = r̃lc̃ldldl+1 + ∑l i=1 ki 2di−1di, we have
〈λ,∇wf(w,D(i))− ED∼D∇wf(w,D(i))〉 ≤‖λ‖2‖∇wf(w,D(i))− ED∼D∇wf(w,D(i))‖2
≤‖λ‖2‖∇wf(w,D(i))‖2 ¬ ≤ β,
where ¬ holds since ‖λ‖2 = 1",C Technical Lemmas and Their Proofs,[0],[0]
"(λ ∈ Sd−1) and by Lemma 11, we have ‖∇wf(w,D(i))‖ ≤ β where β ,[ ϑr̃lc̃ldl + ∑l i=1 ϑbl+1 2di−1",C Technical Lemmas and Their Proofs,[0],[0]
p2bi2di ri−1ci−1,C Technical Lemmas and Their Proofs,[0],[0]
"∏l s=i dsbs 2(ks−ss+1)2 16p2 ]1/2 in which ϑ = 1/8.
",C Technical Lemmas and Their Proofs,[0],[0]
"Thus, we can use Hoeffding’s inequality in Lemma 6 to bound
P
( 1
n
n∑
i=1
(〈 λ,∇wf(w,D(i))−ED∼D∇wf(w,D(i)) 〉) >t ) ≤ exp",C Technical Lemmas and Their Proofs,[0],[0]
"( − nt 2
2β2
) .
",C Technical Lemmas and Their Proofs,[0],[0]
"The proof is completed.
",C Technical Lemmas and Their Proofs,[0],[0]
Lemma 17.,C Technical Lemmas and Their Proofs,[0],[0]
"Suppose that the activation function σ1 is sigmoid and σ2 is softmax, and the loss function f(w,D) is squared loss.",C Technical Lemmas and Their Proofs,[0],[0]
Suppose that Assumption 1 on the input data D and the parameter w holds.,C Technical Lemmas and Their Proofs,[0],[0]
Then for any t > 0 and arbitrary unit vector λ ∈,C Technical Lemmas and Their Proofs,[0],[0]
"Sd−1, the Hessian∇2f(w,D) obeys
P
( 1
n
n∑
i=1
(〈 λ, (∇2wf(w,D(i))− ED∼D∇2wf(w,D(i)))λ 〉) > t )",C Technical Lemmas and Their Proofs,[0],[0]
"≤ 2 exp ( −nt 2
2γ2
) .
",C Technical Lemmas and Their Proofs,[0],[0]
"where γ = ( ϑbl+1
2d20 b14d21",C Technical Lemmas and Their Proofs,[0],[0]
l2r20c 2 0,C Technical Lemmas and Their Proofs,[0],[0]
"[∏l s=1 dsbs 2(ks−ss+1)2 8 √ 2p2 ]2)1/2 .
",C Technical Lemmas and Their Proofs,[0],[0]
Proof.,C Technical Lemmas and Their Proofs,[0],[0]
"Since the inputD(i) (i = 1, · · · , n) are independent from each other, then the output∇wf(w,D(i))",C Technical Lemmas and Their Proofs,[0],[0]
"(i = 1, · · · , n) are also independent.",C Technical Lemmas and Their Proofs,[0],[0]
"On the other hand, for arbitrary random matrix X , ‖X",C Technical Lemmas and Their Proofs,[0],[0]
− EX‖2F ≤ ‖X‖2F .,C Technical Lemmas and Their Proofs,[0],[0]
"Thus, for an arbitrary unit vector λ ∈ Sd−1 where d = r̃lc̃ldldl+1 + ∑l i=1 ki 2di−1di, we have
〈λ, (∇2wf(w,D(i))− ED∼D∇2wf(w,D(i)))λ〉 ≤‖λ‖2‖(∇2wf(w,D(i))− ED∼D∇2wf(w,D(i)))λ‖2 ≤‖∇2wf(w,D(i))− ED∼D∇2wf(w,D(i))‖op‖λ‖2 ≤‖∇2wf(w,D(i))− ED∼D∇2wf(w,D(i))‖F ≤‖∇2wf(w,D(i))‖F ¬ ≤γ,
where ¬ holds since ‖λ‖2 = 1",C Technical Lemmas and Their Proofs,[0],[0]
"(λ ∈ Sd−1) and by Lemma 14, we have ‖∇2wf(w,D(i))‖ ≤ γ where γ =( ϑbl+1
2d20 b14d21",C Technical Lemmas and Their Proofs,[0],[0]
l2r20c 2 0,C Technical Lemmas and Their Proofs,[0],[0]
"[∏l s=1 dsbs 2(ks−ss+1)2 8 √ 2p2 ]2)1/2 .
",C Technical Lemmas and Their Proofs,[0],[0]
"Thus, we can use Hoeffding’s inequality in Lemma 6 to bound
P
( 1
n
n∑
i=1
(〈 λ, (∇2wf(w,D(i))− ED∼D∇2wf(w,D(i)))λ 〉) > t ) ≤ exp",C Technical Lemmas and Their Proofs,[0],[0]
"( −nt 2
2γ2
) .
",C Technical Lemmas and Their Proofs,[0],[0]
"The proof is completed.
",C Technical Lemmas and Their Proofs,[0],[0]
Lemma 18.,C Technical Lemmas and Their Proofs,[0],[0]
"Suppose that the activation function σ1 is sigmoid and σ2 is softmax, and the loss function f(w,D) is squared loss.",C Technical Lemmas and Their Proofs,[0],[0]
Suppose that Assumption 1 on the input dataD and the parameter w holds.,C Technical Lemmas and Their Proofs,[0],[0]
Then the empirical Hessian converges uniformly to the population Hessian in operator norm.,C Technical Lemmas and Their Proofs,[0],[0]
"Specifically, there exit two universal constants cv′ and cv such that if n ≥ cv′ ν",C Technical Lemmas and Their Proofs,[0],[0]
"2
d%ε2 [∏l s=1 dsbs 2(ks−ss+1)2 8 √ 2p2 ]−1 , then with probability at least 1−
sup w∈Ω
∥∥∥∇2Q̃n(w)−∇2Q(w) ∥∥∥
op ≤ cvγ
√ 2d+ θ%+ log ( 4 ε )
",C Technical Lemmas and Their Proofs,[0],[0]
"2n ,
holds with probability at least 1 − ε, where d = r̃lc̃ldldl+1 + ∑l i=1 ki
2di−1di, θ = al+1(dl+1 + r̃lc̃ldl − 2al+1 + 1) + ∑l i=1",C Technical Lemmas and Their Proofs,[0],[0]
ai(ki,C Technical Lemmas and Their Proofs,[0],[0]
2di +,C Technical Lemmas and Their Proofs,[0],[0]
di−1,C Technical Lemmas and Their Proofs,[0],[0]
"− 2ai + 1), % = ∑l i=1log (√ dibi(ki−si+1) 4p ) + log(bl+1)",C Technical Lemmas and Their Proofs,[0],[0]
"+ log ( n 128p2 ) , and
γ =
( ϑbl+1
2d20 b14d21",C Technical Lemmas and Their Proofs,[0],[0]
l2r20c 2 0,C Technical Lemmas and Their Proofs,[0],[0]
"[∏l s=1 dsbs 2(ks−ss+1)2 8 √ 2p2 ]2)1/2 .
",C Technical Lemmas and Their Proofs,[0],[0]
Proof.,C Technical Lemmas and Their Proofs,[0],[0]
"Recall that the weight of each kernel and the feature maps has magnitude bound separately, i.e. wk(i) ∈",C Technical Lemmas and Their Proofs,[0],[0]
"Bki
2di−1(rw)",C Technical Lemmas and Their Proofs,[0],[0]
"(i = 1, · · · , l; k = 1, · · · , di) and w(l+1) ∈ Br̃lc̃ldldl+1(bl+1).",C Technical Lemmas and Their Proofs,[0],[0]
"Since W̃(i) = [vec(W 1(i)), vec(W 2(i)), · · · , vec(W di−1(i) )",C Technical Lemmas and Their Proofs,[0],[0]
],C Technical Lemmas and Their Proofs,[0],[0]
∈,C Technical Lemmas and Their Proofs,[0],[0]
Rk 2,C Technical Lemmas and Their Proofs,[0],[0]
"i di×di−1 , we have ‖W̃(i)‖F ≤ dibi.
",C Technical Lemmas and Their Proofs,[0],[0]
"So here we assume W̃(i, ) is the dibi /(bl+1",C Technical Lemmas and Their Proofs,[0],[0]
+,C Technical Lemmas and Their Proofs,[0],[0]
∑l i=1 dibi)-covering net of the matrix W̃(i),C Technical Lemmas and Their Proofs,[0],[0]
which is the set of all parameters in the i-th layer.,C Technical Lemmas and Their Proofs,[0],[0]
"Then by Lemma 7, we have the covering number
n",C Technical Lemmas and Their Proofs,[0],[0]
"i ≤
( 9(bl+1 + ∑l i=1 dibi) )",C Technical Lemmas and Their Proofs,[0],[0]
"ai(ki2di+di−1−2ai+1) ,
since the rank of W̃(i) obeys rank(W̃(i))",C Technical Lemmas and Their Proofs,[0],[0]
≤ ai for 1 ≤,C Technical Lemmas and Their Proofs,[0],[0]
i ≤,C Technical Lemmas and Their Proofs,[0],[0]
l.,C Technical Lemmas and Their Proofs,[0],[0]
"For the last layer, we also can construct an bl+1 /(bl+1",C Technical Lemmas and Their Proofs,[0],[0]
+∑l i=1 dibi)-covering net for the weight matrixW(l+1).,C Technical Lemmas and Their Proofs,[0],[0]
"Here we have
n l+1 ≤
( 9(bl+1 + ∑l i=1 dibi) )",C Technical Lemmas and Their Proofs,[0],[0]
al+1(dl+1+r̃lc̃ldl−2al+1,C Technical Lemmas and Their Proofs,[0],[0]
"+1) ,
since the rank of W(l+1) obeys rank(W(l+1))",C Technical Lemmas and Their Proofs,[0],[0]
≤ al+1.,C Technical Lemmas and Their Proofs,[0],[0]
"Finally, we arrange them together to construct a set Θ and claim that there is always an -covering net w in Θ for any parameter w. Accordingly, we have
|Θ| ≤ l+1∏
i=1
n i=
( 9(bl+1 + ∑l i=1 dibi) )",C Technical Lemmas and Their Proofs,[0],[0]
al+1(dl+1+r̃lc̃ldl−2al+1,C Technical Lemmas and Their Proofs,[0],[0]
+1)+∑li=1 ai(ki2di+di−1−2ai+1) =,C Technical Lemmas and Their Proofs,[0],[0]
( 9(bl+1 + ∑l i=1 dibi) ),C Technical Lemmas and Their Proofs,[0],[0]
"θ ,
where θ = al+1(dl+1 + r̃lc̃ldl",C Technical Lemmas and Their Proofs,[0],[0]
− 2al+1 + 1) +,C Technical Lemmas and Their Proofs,[0],[0]
∑l i=1,C Technical Lemmas and Their Proofs,[0],[0]
"ai(ki
2di +",C Technical Lemmas and Their Proofs,[0],[0]
di−1,C Technical Lemmas and Their Proofs,[0],[0]
− 2ai + 1) which is the total freedom degree of the network.,C Technical Lemmas and Their Proofs,[0],[0]
So we can always find a vector wkw ∈ Θ such that ‖w −wkw‖2 ≤ .,C Technical Lemmas and Their Proofs,[0],[0]
"Now we use the decomposition strategy to bound our goal:
∥∥∥∇2Q̃n(w)−∇2Q(w) ∥∥∥
op
= ∥∥∥∥∥ 1 n n∑
i=1
∇2f(w,D(i))− ED∼D(∇2f(w,D))",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥
",C Technical Lemmas and Their Proofs,[0],[0]
"op
= ∥∥∥∥∥ 1 n",C Technical Lemmas and Their Proofs,[0],[0]
"n∑
i=1
( ∇2f(w,D(i))−∇2f(wkw ,D(i)) )",C Technical Lemmas and Their Proofs,[0],[0]
"+ 1
n
n∑
i=1
∇2f(wkw ,D(i))− E(∇2f(wkw ,D))
+",C Technical Lemmas and Their Proofs,[0],[0]
"ED∼D(∇2f(wkw ,D))− ED∼D(∇2f(w,D))",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥
",C Technical Lemmas and Their Proofs,[0],[0]
"op
≤ ∥∥∥∥∥ 1 n",C Technical Lemmas and Their Proofs,[0],[0]
"n∑
i=1
( ∇2f(w,D(i))−∇2f(wkw ,D(i)) )∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"op + ∥∥∥∥∥ 1 n n∑ i=1 ∇2f(wkw ,D(i))− ED∼D(∇2f(wkw ,D)) ∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"op
+ ∥∥∥∥∥ED∼D(∇",C Technical Lemmas and Their Proofs,[0],[0]
"2f(wkw ,D))− ED∼D(∇2f(w,D)) ∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"op .
",C Technical Lemmas and Their Proofs,[0],[0]
"Here we also define four events E0, E1, E2 and E3 as
E0 = { sup w∈Ω ∥∥∥∇2Q̃n(w)−∇2Q(w) ∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"op ≥ t } ,
E1 =    supw∈Ω ∥∥∥∥∥ 1 n",C Technical Lemmas and Their Proofs,[0],[0]
"n∑
i=1
( ∇2f(w,D(i))−∇2f(wkw ,D(i)) )",C Technical Lemmas and Their Proofs,[0],[0]
∥∥∥∥∥,C Technical Lemmas and Their Proofs,[0],[0]
"op ≥ t 3    ,
E2 =    supwkw∈Θ ∥∥∥∥∥ 1 n n∑
i=1
∇2f(wkw ,D(i))− ED∼D(∇2f(wkw ,D))",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥
op ≥ t 3
   ,
E3 = { sup w∈Ω ∥∥ED∼D(∇2f(wkw ,D))− ED∼D(∇2f(w,D)) ∥∥",C Technical Lemmas and Their Proofs,[0],[0]
"op ≥ t 3 } .
",C Technical Lemmas and Their Proofs,[0],[0]
"Accordingly, we have P (E0) ≤",C Technical Lemmas and Their Proofs,[0],[0]
"P (E1) + P (E2) + P (E3) .
",C Technical Lemmas and Their Proofs,[0],[0]
"So we can respectively bound P (E1), P (E2) and P (E3) to bound P (E0).
",C Technical Lemmas and Their Proofs,[0],[0]
Step 1.,C Technical Lemmas and Their Proofs,[0],[0]
Bound P (E1):,C Technical Lemmas and Their Proofs,[0],[0]
"We first bound P (E1) as follows:
P (E1) =P ( sup w∈Ω ∥∥∥∥∥",C Technical Lemmas and Their Proofs,[0],[0]
1 n,C Technical Lemmas and Their Proofs,[0],[0]
"n∑
i=1
( ∇2f(w,D(i))−∇2f(wkw ,D(i)) )",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥ 2 ≥ t 3 )
¬ ≤3 t ED∼D ( sup w∈Ω ∥∥∥∥∥ 1 n",C Technical Lemmas and Their Proofs,[0],[0]
"n∑
i=1
( ∇2f(w,D(i))−∇2f(wkw ,D(i)) )",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥ 2 )
",C Technical Lemmas and Their Proofs,[0],[0]
"≤3 t ED∼D ( sup w∈Ω ∥∥∇2f(w,D)−∇2f(wkw ,D) ∥∥ 2 )
",C Technical Lemmas and Their Proofs,[0],[0]
≤3 t ED∼D ( sup w∈Ω ∥∥ 1 n ∑n i=1,C Technical Lemmas and Their Proofs,[0],[0]
"( ∇2f(w,D(i))−∇2f(wkw ,D(i)) )",C Technical Lemmas and Their Proofs,[0],[0]
∥∥ 2 ‖w −wkw‖2,C Technical Lemmas and Their Proofs,[0],[0]
"sup w∈Ω ‖w −wkw‖2 )
 ",C Technical Lemmas and Their Proofs,[0],[0]
"≤3ν
t ,
where ¬ holds since by Markov inequality and  holds because of Lemma 14.",C Technical Lemmas and Their Proofs,[0],[0]
"Therefore, we can set
t ≥ 6ν ε .
",C Technical Lemmas and Their Proofs,[0],[0]
"Then we can bound P(E1): P(E1) ≤ ε
2 .
",C Technical Lemmas and Their Proofs,[0],[0]
Step 2.,C Technical Lemmas and Their Proofs,[0],[0]
"Bound P (E2): By Lemma 3, we know that for any matrixX ∈ Rd×d, its operator norm can be computed as
‖X‖op ≤ 1
1− 2 supλ∈λ |〈λ,Xλ〉| .
where λ = {λ1, . . .",C Technical Lemmas and Their Proofs,[0],[0]
",λkw} be an -covering net of Bd(1).
",C Technical Lemmas and Their Proofs,[0],[0]
"Let λ1/4 be the 14 -covering net of B d(1), where d = r̃lc̃ldldl+1 + ∑l i=1 ki 2di−1di.",C Technical Lemmas and Their Proofs,[0],[0]
Recall that we use Θ to denote the -net of wkw and we have |Θ| ≤ ∏l+1 i=1,C Technical Lemmas and Their Proofs,[0],[0]
n,C Technical Lemmas and Their Proofs,[0],[0]
i =,C Technical Lemmas and Their Proofs,[0],[0]
( 3(bl+1+ ∑l i=1 dibi) ),C Technical Lemmas and Their Proofs,[0],[0]
θ .,C Technical Lemmas and Their Proofs,[0],[0]
"Then we can bound P (E2) as follows:
P (E2) =P ( sup
wkw∈Θ
∥∥∥∥∥ 1 n n∑
i=1
∇2f(wkw ,D(i))− ED∼D(∇2f(wkw ,D))",C Technical Lemmas and Their Proofs,[0],[0]
"∥∥∥∥∥
2
≥ t 3
)
",C Technical Lemmas and Their Proofs,[0],[0]
"≤P (
sup wkw∈Θ,λ∈λ1/4",C Technical Lemmas and Their Proofs,[0],[0]
"2
∣∣∣∣∣ 〈 λ, ( 1 n n∑
i=1
∇2f(wkw ,D(i))− ED∼D ( ∇2f(wkw ,D) ) )",C Technical Lemmas and Their Proofs,[0],[0]
"λ 〉∣∣∣∣∣ ≥ t 3 )
≤12d",C Technical Lemmas and Their Proofs,[0],[0]
( 3(bl+1 + ∑l i=1 dibi) ),C Technical Lemmas and Their Proofs,[0],[0]
"θ sup wkw∈Θ,λ∈λ1/4",C Technical Lemmas and Their Proofs,[0],[0]
"P (∣∣∣∣ 1 n n∑
i=1
〈 λ, ( ∇2f(wkw ,D(i))− ED∼D ( ∇2f(wkw ,D) ))",C Technical Lemmas and Their Proofs,[0],[0]
"λ 〉∣∣∣∣≥ t
6
)
¬ ≤12d
( 3(bl+1 + ∑l i=1 dibi) )",C Technical Lemmas and Their Proofs,[0],[0]
"θ 2 exp ( − nt 2
72γ2
) ,
where ¬ holds since by Lemma 17, we have
P
( 1
n
n∑
i=1
(〈 λ, (∇2wf(w,D(i))− ED∼D∇2wf(w,D(i)))λ 〉) > t ) ≤ exp ( −nt 2
2γ2
) .
where γ = ( ϑbl+1
2d20 b14d21",C Technical Lemmas and Their Proofs,[0],[0]
l2r20c 2 0,C Technical Lemmas and Their Proofs,[0],[0]
"[∏l s=1 dsbs 2(ks−ss+1)2 8 √ 2p2 ]2)1/2 .
",C Technical Lemmas and Their Proofs,[0],[0]
"Thus, if we set
t ≥
√√√√72γ2 ( d log(12) + θ log ( 3(bl+1+ ∑l i=1 dibi) )",C Technical Lemmas and Their Proofs,[0],[0]
"+ log ( 4 ε ))
n ,
then we have P (E2) ≤",C Technical Lemmas and Their Proofs,[0],[0]
"ε
2 .
",C Technical Lemmas and Their Proofs,[0],[0]
Step 3.,C Technical Lemmas and Their Proofs,[0],[0]
Bound P (E3):,C Technical Lemmas and Their Proofs,[0],[0]
"We first bound P (E3) as follows:
P (E3) =P (
sup w∈Ω
∥∥ED∼D(∇2f(wkw ,D))− ED∼D(∇2f(w,D)) ∥∥ 2 ≥ t
3
)
≤P ( ED∼D sup
w∈Ω
∥∥(∇2f(wkw ,D)−∇2f(w,D) ∥∥ 2 ≥ t
3
)
≤P (
sup w∈Ω
∣∣ 1 n ∑n i=1",C Technical Lemmas and Their Proofs,[0],[0]
"( ∇2f(w,D(i))−∇2f(wkw ,D(i)) )∣∣",C Technical Lemmas and Their Proofs,[0],[0]
‖w −wkw‖2,C Technical Lemmas and Their Proofs,[0],[0]
sup w∈Ω ‖w −wkw‖2,C Technical Lemmas and Their Proofs,[0],[0]
≥,C Technical Lemmas and Their Proofs,[0],[0]
"t 3 )
¬ ≤P ( ν ≥ t
3
) ,
where ¬ holds because of Lemma 14.",C Technical Lemmas and Their Proofs,[0],[0]
We set enough small such that ν < t/3 always holds.,C Technical Lemmas and Their Proofs,[0],[0]
"Then it yields P (E3) = 0.
",C Technical Lemmas and Their Proofs,[0],[0]
Step 4.,C Technical Lemmas and Their Proofs,[0],[0]
"Final result: To ensure P(E0) ≤ ε, we just set = 36(bl+1+ ∑l i=1 dibi)
",C Technical Lemmas and Their Proofs,[0],[0]
"ϑ2nbl+1
[∏l s=1 dsbs 2(ks−ss+1)2 8 √ 2p2 ]",C Technical Lemmas and Their Proofs,[0],[0]
− 12 .,C Technical Lemmas and Their Proofs,[0],[0]
"Note that
6 ν ε > 3 ν.",C Technical Lemmas and Their Proofs,[0],[0]
"Thus we can obtain
t ≥ max   6ν
ε ,
√√√√72γ2 ( d log(12) + θ log ( 3(bl+1+ ∑l i=1 dibi) )",C Technical Lemmas and Their Proofs,[0],[0]
"+ log ( 4 ε ))
n
  .
",C Technical Lemmas and Their Proofs,[0],[0]
"Thus, if n ≥ cv′ ν 2
d%ε2 [∏l s=1 dsbs 2(ks−ss+1)2 8 √ 2p2 ]−1 where cv′ is a constant, there exists a universal constant cv such that
sup w∈Ω
∥∥∥∇2Q̃n(w)−∇2Q(w) ∥∥∥
op ≤ĉvγ
√√√√d log(12)",C Technical Lemmas and Their Proofs,[0],[0]
+ θ,C Technical Lemmas and Their Proofs,[0],[0]
(∑l i=1 log (√ dsbs(ks−ss+1) 4p ) + log(bl+1),C Technical Lemmas and Their Proofs,[0],[0]
+ log ( n 128p2 )),C Technical Lemmas and Their Proofs,[0],[0]
"+ log ( 4 ε )
n
=cvγ
√ 2d+ θ%+ log",C Technical Lemmas and Their Proofs,[0],[0]
(,C Technical Lemmas and Their Proofs,[0],[0]
"4 ε )
2n
holds with probability at least 1 − ε, where d = r̃lc̃ldldl+1 + ∑l i=1 ki
2di−1di, θ = al+1(dl+1 + r̃lc̃ldl − 2al+1 + 1) + ∑l i=1",C Technical Lemmas and Their Proofs,[0],[0]
ai(ki,C Technical Lemmas and Their Proofs,[0],[0]
2di +,C Technical Lemmas and Their Proofs,[0],[0]
di−1,C Technical Lemmas and Their Proofs,[0],[0]
"− 2ai + 1), % = ∑l i=1log (√ dibi(ki−si+1) 4p ) + log(bl+1)",C Technical Lemmas and Their Proofs,[0],[0]
"+ log ( n 128p2 ) , and
γ =
( ϑbl+1
2d20 b14d21",C Technical Lemmas and Their Proofs,[0],[0]
l2r20c 2 0,C Technical Lemmas and Their Proofs,[0],[0]
[∏l s=1 dsbs 2(ks−ss+1)2 8 √ 2p2 ]2)1/2 .,C Technical Lemmas and Their Proofs,[0],[0]
The proof is completed.,C Technical Lemmas and Their Proofs,[0],[0]
Proof.,D.1 Proof of Lemma 1,[0],[0]
"Recall that the weight of each kernel and the feature maps has magnitude bound separately, i.e. wk(i) ∈",D.1 Proof of Lemma 1,[0],[0]
"Bki
2di−1(rw)",D.1 Proof of Lemma 1,[0],[0]
"(i = 1, · · · , l; k = 1, · · · , di) and w(l+1) ∈ Br̃lc̃ldldl+1(bl+1).",D.1 Proof of Lemma 1,[0],[0]
"Since W̃(i) = [vec(W 1(i)), vec(W 2(i)), · · · , vec(W di−1(i) )",D.1 Proof of Lemma 1,[0],[0]
],D.1 Proof of Lemma 1,[0],[0]
∈,D.1 Proof of Lemma 1,[0],[0]
Rk 2,D.1 Proof of Lemma 1,[0],[0]
"i di×di−1 , we have ‖W̃(i)‖F ≤ dibi.
",D.1 Proof of Lemma 1,[0],[0]
"So here we assume W̃(i, ) is the dibi /(bl+1",D.1 Proof of Lemma 1,[0],[0]
+,D.1 Proof of Lemma 1,[0],[0]
∑l i=1 dibi)-covering net of the matrix W̃(i),D.1 Proof of Lemma 1,[0],[0]
which is the set of all parameters in the i-th layer.,D.1 Proof of Lemma 1,[0],[0]
"Then by Lemma 7, we have the covering number
n",D.1 Proof of Lemma 1,[0],[0]
"i ≤
( 9(bl+1 + ∑l i=1 dibi) )",D.1 Proof of Lemma 1,[0],[0]
"ai(ki2di+di−1−2ai+1) ,
since the rank of W̃(i) obeys rank(W̃(i))",D.1 Proof of Lemma 1,[0],[0]
≤ ai for 1 ≤,D.1 Proof of Lemma 1,[0],[0]
i ≤,D.1 Proof of Lemma 1,[0],[0]
l.,D.1 Proof of Lemma 1,[0],[0]
"For the last layer, we also can construct an bl+1 /(bl+1",D.1 Proof of Lemma 1,[0],[0]
+∑l i=1 dibi)-covering net for the weight matrixW(l+1).,D.1 Proof of Lemma 1,[0],[0]
"Here we have
n l+1 ≤
( 9(bl+1 + ∑l i=1 dibi) )",D.1 Proof of Lemma 1,[0],[0]
al+1(dl+1+r̃lc̃ldl−2al+1,D.1 Proof of Lemma 1,[0],[0]
"+1) ,
since the rank of W(l+1) obeys rank(W(l+1))",D.1 Proof of Lemma 1,[0],[0]
≤ al+1.,D.1 Proof of Lemma 1,[0],[0]
"Finally, we arrange them together to construct a set Θ and claim that there is always an -covering net w in Θ for any parameter w. Accordingly, we have
|Θ| ≤ l+1∏
i=1
n i=
( 9(bl+1 + ∑l i=1 dibi) )",D.1 Proof of Lemma 1,[0],[0]
al+1(dl+1+r̃lc̃ldl−2al+1,D.1 Proof of Lemma 1,[0],[0]
+1)+∑li=1 ai(ki2di+di−1−2ai+1) =,D.1 Proof of Lemma 1,[0],[0]
( 9(bl+1 + ∑l i=1 dibi) ),D.1 Proof of Lemma 1,[0],[0]
"θ ,
where θ = al+1(dl+1 + r̃lc̃ldl",D.1 Proof of Lemma 1,[0],[0]
− 2al+1 + 1) +,D.1 Proof of Lemma 1,[0],[0]
∑l i=1,D.1 Proof of Lemma 1,[0],[0]
"ai(ki
2di +",D.1 Proof of Lemma 1,[0],[0]
di−1,D.1 Proof of Lemma 1,[0],[0]
− 2ai + 1) which is the total freedom degree of the network.,D.1 Proof of Lemma 1,[0],[0]
So we can always find a vector wkw ∈ Θ such that ‖w −wkw‖2 ≤ .,D.1 Proof of Lemma 1,[0],[0]
"Now we use the decomposition strategy to bound our goal:
∣∣∣Q̃n(w)−Q(w) ∣∣∣= ∣∣∣∣∣",D.1 Proof of Lemma 1,[0],[0]
"1 n n∑
i=1
f(w,D(i))− ED∼D(f(w,D)) ∣∣∣∣∣
= ∣∣∣∣∣ 1 n n∑
i=1
( f(w,D(i))−f(wkw ,D(i)) )",D.1 Proof of Lemma 1,[0],[0]
"+ 1
n
n∑
i=1
f(wkw ,D (i))−Ef(wkw ,D)+ED∼Df(wkw ,D)−ED∼Df(w,D) ∣∣∣∣∣
≤",D.1 Proof of Lemma 1,[0],[0]
∣∣∣∣∣,D.1 Proof of Lemma 1,[0],[0]
1 n,D.1 Proof of Lemma 1,[0],[0]
"n∑
i=1
( f(w,D(i))−f(wkw ,D(i)) )∣∣∣∣∣+ ∣∣∣∣∣",D.1 Proof of Lemma 1,[0],[0]
"1 n n∑
i=1
f(wkw ,D (i))−ED∼Df(wkw ,D) ∣∣∣∣∣
+ ∣∣∣∣∣ED∼Df(wkw ,D)−ED∼Df(w,D) ∣∣∣∣∣.
Then, we define four events E0, E1, E2 and E3 as
E0 = { sup w∈Ω ∣∣∣Q̃n(w)−Q(w) ∣∣∣ ≥ t } ,
E1 = { sup w∈Ω",D.1 Proof of Lemma 1,[0],[0]
∣∣∣∣∣ 1 n,D.1 Proof of Lemma 1,[0],[0]
"n∑
i=1
( f(w,D(i))− f(wkw ,x(i)) )",D.1 Proof of Lemma 1,[0],[0]
∣∣∣∣∣,D.1 Proof of Lemma 1,[0],[0]
"≥ t 3 } ,
E2 =
{ sup
wkw∈Θ
∣∣∣∣∣ 1 n n∑
i=1
f(wkw ,D (i))−ED∼D(f(wkw ,D)) ∣∣∣∣∣≥ t 3 } ,
E3 = { sup w∈Ω ∣∣∣∣∣ED∼D(f(wkw ,",D.1 Proof of Lemma 1,[0],[0]
"D))−ED∼D(f(w,D))",D.1 Proof of Lemma 1,[0],[0]
"∣∣∣∣∣≥ t 3 } .
",D.1 Proof of Lemma 1,[0],[0]
"Accordingly, we have P (E0) ≤",D.1 Proof of Lemma 1,[0],[0]
"P (E1) + P (E2) + P (E3) .
",D.1 Proof of Lemma 1,[0],[0]
"So we can respectively bound P (E1), P (E2) and P (E3) to bound P (E0).
",D.1 Proof of Lemma 1,[0],[0]
Step 1.,D.1 Proof of Lemma 1,[0],[0]
Bound P (E1):,D.1 Proof of Lemma 1,[0],[0]
"We first bound P (E1) as follows:
P (E1) =P ( sup w∈Ω ∣∣∣∣∣",D.1 Proof of Lemma 1,[0],[0]
1 n,D.1 Proof of Lemma 1,[0],[0]
"n∑
i=1
( f(w,D(i))− f(wkw ,D(i)) )",D.1 Proof of Lemma 1,[0],[0]
∣∣∣∣∣,D.1 Proof of Lemma 1,[0],[0]
"≥ t 3 )
¬ ≤3 t ED∼D ( sup w∈Ω",D.1 Proof of Lemma 1,[0],[0]
∣∣∣∣∣ 1 n,D.1 Proof of Lemma 1,[0],[0]
"n∑
i=1
( f(w,D(i))− f(wkw ,D(i)) )",D.1 Proof of Lemma 1,[0],[0]
"∣∣∣∣∣ )
",D.1 Proof of Lemma 1,[0],[0]
≤3 t ED∼D ( sup w∈Ω ∣∣ 1 n,D.1 Proof of Lemma 1,[0],[0]
∑n i=1,D.1 Proof of Lemma 1,[0],[0]
"( f(w,D(i))− f(wkw ,D(i)) )∣∣",D.1 Proof of Lemma 1,[0],[0]
‖w −wkw‖2,D.1 Proof of Lemma 1,[0],[0]
"sup w∈Ω ‖w −wkw‖2 )
",D.1 Proof of Lemma 1,[0],[0]
"≤3 t ED∼D ( sup w∈Ω ∥∥∥∇Q̃n(w,D) ∥∥∥ 2 ) ,
where ¬ holds since by Markov inequality, we have that for an arbitrary nonnegative random variable x, then
P(x ≥ t) ≤ E(x) t .
",D.1 Proof of Lemma 1,[0],[0]
"Now we only need to bound ED∼D ( supw∈Ω ∥∥∥∇Q̃n(w,D) ∥∥∥
2
) .",D.1 Proof of Lemma 1,[0],[0]
"Therefore, by Lemma 11, we have
ED∼D (
sup w∈Ω
∥∥∥∇Q̃n(w,D) ∥∥∥
2
) =ED∼D ( sup w∈Ω ∥∥∥∥∥ 1 n n∑
i=1
∇f(w,D(i))",D.1 Proof of Lemma 1,[0],[0]
"∥∥∥∥∥
",D.1 Proof of Lemma 1,[0],[0]
"2
) ≤ED∼D",D.1 Proof of Lemma 1,[0],[0]
"( sup w∈Ω ‖∇f(w,D)‖2 ) ≤β.
",D.1 Proof of Lemma 1,[0],[0]
"where β , [ ϑr̃lc̃ldl + ∑l i=1 ϑbl+1 2di−1",D.1 Proof of Lemma 1,[0],[0]
p2bi2di ri−1ci−1,D.1 Proof of Lemma 1,[0],[0]
∏l s=i dsbs 2(ks−ss+1)2 16p2 ]1/2 in which ϑ = 1/8.,D.1 Proof of Lemma 1,[0],[0]
"Therefore, we have
P (E1) ≤ 3",D.1 Proof of Lemma 1,[0],[0]
"β
t .
",D.1 Proof of Lemma 1,[0],[0]
"We further let
t ≥ 6 β ε .
",D.1 Proof of Lemma 1,[0],[0]
"Then we can bound P(E1): P(E1) ≤ ε
2 .
",D.1 Proof of Lemma 1,[0],[0]
Step 2.,D.1 Proof of Lemma 1,[0],[0]
Bound P (E2): Recall that we use Θ to denote the index of wkw and we have |Θ| ≤ ∏l+1 i=1,D.1 Proof of Lemma 1,[0],[0]
"n
",D.1 Proof of Lemma 1,[0],[0]
"i =( 9(bl+1+ ∑l i=1 dibi)
)θ .",D.1 Proof of Lemma 1,[0],[0]
"We can bound P (E2) as follows:
P (E2) =P ( sup
wkw∈Θ
∣∣∣∣∣ 1 n n∑
i=1
f(wkw ,D (i))− ED∼D(f(wkw ,D))",D.1 Proof of Lemma 1,[0],[0]
∣∣∣∣∣,D.1 Proof of Lemma 1,[0],[0]
"≥ t 3 )
≤",D.1 Proof of Lemma 1,[0],[0]
( 9(bl+1 + ∑l i=1 dibi) ),D.1 Proof of Lemma 1,[0],[0]
"θ sup
wkw∈Θ P
(∣∣∣ 1 n n∑
i=1
f(wkw ,D (i))− ED∼D(f(wkw ,D))",D.1 Proof of Lemma 1,[0],[0]
"∣∣∣ ≥ t 3
)
¬ ≤ ( 9(bl+1 + ∑l i=1 dibi) )",D.1 Proof of Lemma 1,[0],[0]
"θ 2 exp ( −2nt 2
α2
) ,
where ¬ holds because in Lemma 15, we have
P
( 1
n
n∑
i=1
( f(w,D(i))−E(f(w,D(i))) )",D.1 Proof of Lemma 1,[0],[0]
">t ) ≤ exp ( −2nt 2
α2
) ,
where α = 1.",D.1 Proof of Lemma 1,[0],[0]
"Thus, if we set
t ≥
√√√√α2 ( θ log ( 9(bl+1+ ∑l i=1 dibi) )",D.1 Proof of Lemma 1,[0],[0]
"+ log ( 4 ε ))
",D.1 Proof of Lemma 1,[0],[0]
"2n ,
then we have P (E2) ≤",D.1 Proof of Lemma 1,[0],[0]
"ε
2 .
",D.1 Proof of Lemma 1,[0],[0]
Step 3.,D.1 Proof of Lemma 1,[0],[0]
Bound P (E3):,D.1 Proof of Lemma 1,[0],[0]
"We first bound P (E3) as follows:
P (E3) =P (
sup w∈Ω ‖ED∼D(f(wkw ,D))− ED∼D(f(w,D))‖2 ≥
t
3
)
",D.1 Proof of Lemma 1,[0],[0]
"=P (
sup w∈Ω ‖ED∼D",D.1 Proof of Lemma 1,[0],[0]
"(f(wkw ,D)− f(w,D)‖2) ‖w −wkw‖2",D.1 Proof of Lemma 1,[0],[0]
sup w∈Ω ‖w −wkw‖2,D.1 Proof of Lemma 1,[0],[0]
≥,D.1 Proof of Lemma 1,[0],[0]
"t 3
)
",D.1 Proof of Lemma 1,[0],[0]
"≤P ( ED∼D sup
w∈Ω ‖∇Qw(w,D)‖2 ≥
t
3
)
¬ ≤P ( β ≥ t
3
) ,
where ¬ holds since we utilize Lemma 11.",D.1 Proof of Lemma 1,[0],[0]
We set enough small such that β < t/3 always holds.,D.1 Proof of Lemma 1,[0],[0]
"Then it yields P (E3) = 0.
",D.1 Proof of Lemma 1,[0],[0]
Step 4.,D.1 Proof of Lemma 1,[0],[0]
"Final result: To ensure P(E0) ≤ ε, we just set = 18p 2(bl+1+
∑l i=1 dibi)
",D.1 Proof of Lemma 1,[0],[0]
"ϑ2nbl+1
[∏l s=1 dsbs 2(ks−ss+1)2 16p2 ]",D.1 Proof of Lemma 1,[0],[0]
− 12 .,D.1 Proof of Lemma 1,[0],[0]
"Note that
6 β ε > 3 β due to ε ≤ 1.",D.1 Proof of Lemma 1,[0],[0]
"Thus we can obtain
t≥max   6 β
ε ,
√√√√α2 ( θ log ( 9(bl+1+ ∑l i=1 dibi) )",D.1 Proof of Lemma 1,[0],[0]
"+ log ( 4 ε ))
",D.1 Proof of Lemma 1,[0],[0]
"2n
  .
",D.1 Proof of Lemma 1,[0],[0]
"By comparing the values of α, we can observe that if n ≥ cf ′",D.1 Proof of Lemma 1,[0],[0]
"l 2(bl+1+
∑l i=1 dibi) 2 maxi √ rici
θ%ε2 where cf ′ is a constant, there exists such a universal constant cf such that
sup w∈Ω
∣∣∣Q̃n(w)−Q(w) ∣∣∣≤α
√√√√θ (∑l i=1 log (√ dsbs(ks−ss+1) 4p ) + log(bl+1)+log ( n 128p2 ))",D.1 Proof of Lemma 1,[0],[0]
"+log ( 4 ε )
2n =
√ θ%+log",D.1 Proof of Lemma 1,[0],[0]
"( 4 ε )
2n
holds with probability at least 1 − ε, where θ = al+1(dl+1 + r̃lc̃ldl − 2al+1 + 1) +",D.1 Proof of Lemma 1,[0],[0]
∑l i=1,D.1 Proof of Lemma 1,[0],[0]
"ai(ki
2di +",D.1 Proof of Lemma 1,[0],[0]
di−1,D.1 Proof of Lemma 1,[0],[0]
"− 2ai + 1), % = ∑l i=1log (√ dibi(ki−si+1) 4p ) + log(bl+1)",D.1 Proof of Lemma 1,[0],[0]
"+ log ( n 128p2 ) , and α = 1.",D.1 Proof of Lemma 1,[0],[0]
The proof is completed.,D.1 Proof of Lemma 1,[0],[0]
Proof.,D.2 Proof of Theorem 1,[0],[0]
"By Lemma 1 in the manuscript, we know that if n ≥ cf ′ l2(bl+1",D.2 Proof of Theorem 1,[0],[0]
"+ ∑l i=1 dibi) 2 maxi √ rici/(θ%ε
2) where cf ′ is a universal constant, then with probability at least 1− ε, we have
sup w∈Ω
∣∣∣Q̃n(w)−Q(w) ∣∣∣ ≤
√ θ%+ log ( 4 ε )
2n ,
where the total freedom degree θ of the network is θ = al+1(dl+1 + r̃lc̃ldl + 1) +",D.2 Proof of Theorem 1,[0],[0]
∑l i=1 ai(ki 2di−1 + di + 1) and % = ∑l i=1log (√ dibi(ki−si+1) 4p ) + log(bl+1),D.2 Proof of Theorem 1,[0],[0]
+,D.2 Proof of Theorem 1,[0],[0]
"log ( n 128p2 ) .
",D.2 Proof of Theorem 1,[0],[0]
"Thus based on such a result, we can derive the following generalization bound:
ES∼D ∣∣∣EA(Q(w̃)− Q̃n(w̃))",D.2 Proof of Theorem 1,[0],[0]
∣∣∣ ≤,D.2 Proof of Theorem 1,[0],[0]
"ES∼D (
sup w∈Ω ∣∣∣Q̃n(w)−Q(w) ∣∣∣ )",D.2 Proof of Theorem 1,[0],[0]
≤ sup w∈Ω ∣∣∣Q̃n(w)−Q(w),D.2 Proof of Theorem 1,[0],[0]
"∣∣∣ ≤
√ θ%+ log ( 4 ε )
2n .
",D.2 Proof of Theorem 1,[0],[0]
"Thus, the conclusion holds.",D.2 Proof of Theorem 1,[0],[0]
The proof is completed.,D.2 Proof of Theorem 1,[0],[0]
Proof.,D.3 Proof of Theorem 2,[0],[0]
"Recall that the weight of each kernel and the feature maps has magnitude bound separately, i.e. wk(i) ∈",D.3 Proof of Theorem 2,[0],[0]
"Bki
2di−1(rw)",D.3 Proof of Theorem 2,[0],[0]
"(i = 1, · · · , l; k = 1, · · · , di) and w(l+1) ∈ Br̃lc̃ldldl+1(bl+1).",D.3 Proof of Theorem 2,[0],[0]
"Since W̃(i) = [vec(W 1(i)), vec(W 2(i)), · · · , vec(W di−1(i) )",D.3 Proof of Theorem 2,[0],[0]
],D.3 Proof of Theorem 2,[0],[0]
∈,D.3 Proof of Theorem 2,[0],[0]
Rk 2,D.3 Proof of Theorem 2,[0],[0]
"i di−1×di , we have ‖W̃(i)‖F ≤ dibi.",D.3 Proof of Theorem 2,[0],[0]
"So here we assume W̃(i, ) is the dibi /(bl+1",D.3 Proof of Theorem 2,[0],[0]
+,D.3 Proof of Theorem 2,[0],[0]
∑l i=1 dibi)-covering net of the matrix W̃(i),D.3 Proof of Theorem 2,[0],[0]
which is the set of all parameters in the i-th layer.,D.3 Proof of Theorem 2,[0],[0]
"Then by Lemma 7, we have the covering number
n",D.3 Proof of Theorem 2,[0],[0]
"i ≤
( 9(bl+1 + ∑l i=1 dibi) )",D.3 Proof of Theorem 2,[0],[0]
"ai(ki2di−1+di−2ai+1) ,
since the rank of W̃(i) obeys rank(W̃(i))",D.3 Proof of Theorem 2,[0],[0]
≤ ai for 1 ≤,D.3 Proof of Theorem 2,[0],[0]
i ≤,D.3 Proof of Theorem 2,[0],[0]
l.,D.3 Proof of Theorem 2,[0],[0]
"For the last layer, we also can construct an bl+1 /(bl+1",D.3 Proof of Theorem 2,[0],[0]
+∑l i=1 dibi)-covering net for the weight matrixW(l+1).,D.3 Proof of Theorem 2,[0],[0]
"Here we have
n l+1 ≤
( 9(bl+1 + ∑l i=1 dibi) )",D.3 Proof of Theorem 2,[0],[0]
al+1(dl+1+r̃lc̃ldl−2al+1,D.3 Proof of Theorem 2,[0],[0]
"+1) ,
since the rank of W(l+1) obeys rank(W(l+1))",D.3 Proof of Theorem 2,[0],[0]
≤ al+1.,D.3 Proof of Theorem 2,[0],[0]
"Finally, we arrange them together to construct a set Θ and claim that there is always an -covering net w in Θ for any parameter w. Accordingly, we have
|Θ| ≤ l+1∏
i=1
n i=
( 9(bl+1 + ∑l i=1 dibi) )",D.3 Proof of Theorem 2,[0],[0]
al+1(dl+1+r̃lc̃ldl−2al+1,D.3 Proof of Theorem 2,[0],[0]
+1)+∑li=1 ai(ki2di−1+di−2ai+1) = ( 9(bl+1 + ∑l i=1 dibi) ),D.3 Proof of Theorem 2,[0],[0]
"θ ,
where θ = al+1(dl+1 + r̃lc̃ldl",D.3 Proof of Theorem 2,[0],[0]
− 2al+1 + 1) +,D.3 Proof of Theorem 2,[0],[0]
∑l i=1,D.3 Proof of Theorem 2,[0],[0]
"ai(ki
2di−1 + di − 2ai + 1) which is the total freedom degree of the network.",D.3 Proof of Theorem 2,[0],[0]
So we can always find a vector wkw ∈ Θ such that ‖w − wkw‖2 ≤ .,D.3 Proof of Theorem 2,[0],[0]
"Accordingly, we can decompose∥∥∥∇Q̃n(w)−∇Q(w)
∥∥∥ 2 as
∥∥∥∇Q̃n(w)−∇Q(w) ∥∥∥
2
= ∥∥∥∥∥ 1 n n∑
i=1
∇f(w,D(i))− ED∼D(∇f(w,D))",D.3 Proof of Theorem 2,[0],[0]
"∥∥∥∥∥
",D.3 Proof of Theorem 2,[0],[0]
"2
= ∥∥∥∥∥ 1 n n∑
i=1
( ∇f(w,D(i))−∇f(wkw ,D(i)) )",D.3 Proof of Theorem 2,[0],[0]
"+ 1
n
n∑
i=1
∇f(wkw ,D(i))− ED∼D(∇f(wkw ,D))
",D.3 Proof of Theorem 2,[0],[0]
"+ ED∼D(∇f(wkw ,D))− ED∼D(∇f(w,D))",D.3 Proof of Theorem 2,[0],[0]
"∥∥∥∥∥
",D.3 Proof of Theorem 2,[0],[0]
2 ≤ ∥∥∥∥∥ 1 n,D.3 Proof of Theorem 2,[0],[0]
"n∑
i=1
( ∇f(w,D(i))−∇f(wkw ,D(i)) )",D.3 Proof of Theorem 2,[0],[0]
∥∥∥∥∥ 2,D.3 Proof of Theorem 2,[0],[0]
+ ∥∥∥∥∥ 1 n n∑ i=1,D.3 Proof of Theorem 2,[0],[0]
"∇f(wkw ,D(i))− ED∼D(∇f(wkw ,D))",D.3 Proof of Theorem 2,[0],[0]
∥∥∥∥∥,D.3 Proof of Theorem 2,[0],[0]
"2
+ ∥∥∥∥∥ED∼D(∇f(wkw ,D))− ED∼D(∇f(w,D)) ∥∥∥∥∥
2
.
",D.3 Proof of Theorem 2,[0],[0]
"Here we also define four events E0, E1, E2 and E3 as
E0 = { sup w∈Ω ∥∥∥∇Q̃n(w)−∇Q(w) ∥∥∥ 2 ≥ t } ,
E1 = { sup w∈Ω ∥∥∥∥∥",D.3 Proof of Theorem 2,[0],[0]
"1 n n∑
i=1
( ∇f(w,D(i))−∇f(wkw ,D(i)) )",D.3 Proof of Theorem 2,[0],[0]
∥∥∥∥∥,D.3 Proof of Theorem 2,[0],[0]
"2 ≥ t 3 } ,
E2 =
{ sup
wkw∈Θ
∥∥∥∥∥ 1 n n∑
i=1
∇f(wkw ,D(i))− ED∼D(∇f(wkw ,D))",D.3 Proof of Theorem 2,[0],[0]
"∥∥∥∥∥
2
≥ t 3
} ,
",D.3 Proof of Theorem 2,[0],[0]
"E3 = { sup w∈Ω ∥∥∥∥∥ED∼D(∇f(wkw ,D))−",D.3 Proof of Theorem 2,[0],[0]
"ED∼D(∇f(w,D))",D.3 Proof of Theorem 2,[0],[0]
"∥∥∥∥∥
2
≥ t 3
} .
",D.3 Proof of Theorem 2,[0],[0]
"Accordingly, we have P (E0) ≤",D.3 Proof of Theorem 2,[0],[0]
"P (E1) + P (E2) + P (E3) .
",D.3 Proof of Theorem 2,[0],[0]
"So we can respectively bound P (E1), P (E2) and P (E3) to bound P (E0).
",D.3 Proof of Theorem 2,[0],[0]
Step 1.,D.3 Proof of Theorem 2,[0],[0]
Bound P (E1):,D.3 Proof of Theorem 2,[0],[0]
"We first bound P (E1) as follows:
P (E1) =P ( sup w∈Ω ∥∥∥∥∥",D.3 Proof of Theorem 2,[0],[0]
"1 n n∑
i=1
( ∇f(w,D(i))−∇f(wkw ,D(i)) )",D.3 Proof of Theorem 2,[0],[0]
"∥∥∥∥∥ 2 ≥ t 3 )
¬ ≤3 t ED∼D ( sup w∈Ω ∥∥∥∥∥ 1 n",D.3 Proof of Theorem 2,[0],[0]
"n∑
i=1
( ∇f(w,D(i))−∇f(wkw ,D(i)) )",D.3 Proof of Theorem 2,[0],[0]
"∥∥∥∥∥ 2 )
",D.3 Proof of Theorem 2,[0],[0]
≤3 t ED∼D ( sup w∈Ω ∥∥ 1 n ∑n i=1,D.3 Proof of Theorem 2,[0],[0]
"( ∇f(w,D(i))−∇f(wkw ,D(i)) )",D.3 Proof of Theorem 2,[0],[0]
"∥∥ 2 ‖w −wkw‖2 sup w∈Ω ‖w −wkw‖2 )
",D.3 Proof of Theorem 2,[0],[0]
"≤3 t ED∼D ( sup w∈Ω ∥∥∥∇2Q̃n(w,D) ∥∥∥ 2 ) ,
where ¬ holds since by Markov inequality, we have that for an arbitrary nonnegative random variable x, then P(x ≥ t) ≤ E(x) t .",D.3 Proof of Theorem 2,[0],[0]
"Now we only need to bound ED∼D ( supw∈Ω ∥∥∥∇2Q̃n(w,D) ∥∥∥
2
) .",D.3 Proof of Theorem 2,[0],[0]
"Here we utilize Lemma 14 to achieve this goal:
ED∼D (
sup w∈Ω
∥∥∥∇2Q̃n(w,D) ∥∥∥
2
) ≤ ED∼D",D.3 Proof of Theorem 2,[0],[0]
"( sup w∈Ω ∥∥∇2f(w,D)−∇2f(w∗,D) ∥∥ 2 ) ≤ γ.
where γ = ( ϑbl+1
2d20 b14d21",D.3 Proof of Theorem 2,[0],[0]
l2r20c 2 0,D.3 Proof of Theorem 2,[0],[0]
[∏l s=1 dsbs 2(ks−ss+1)2 8 √ 2p2 ]2)1/2 .,D.3 Proof of Theorem 2,[0],[0]
"Therefore, we have
P (E1) ≤ 3γ
t .
",D.3 Proof of Theorem 2,[0],[0]
"We further let t ≥ 6γ
ε .
",D.3 Proof of Theorem 2,[0],[0]
"Then we can bound P(E1): P(E1) ≤ ε
2 .
",D.3 Proof of Theorem 2,[0],[0]
Step 2.,D.3 Proof of Theorem 2,[0],[0]
"Bound P (E2): By Lemma 2, we know that for any vector x ∈ Rd, its `2-norm can be computed as
‖x‖2 ≤ 1
1− supλ∈λ 〈λ,x〉 .
",D.3 Proof of Theorem 2,[0],[0]
"where λ = {λ1, . . .",D.3 Proof of Theorem 2,[0],[0]
",λkw} be an -covering net of Bd(1).
",D.3 Proof of Theorem 2,[0],[0]
"Let λ be the 12 -covering net of B d(1), where d = r̃lc̃ldldl+1 + ∑l i=1 ki 2di−1di.",D.3 Proof of Theorem 2,[0],[0]
Recall that we use Θ to denote the index of wkw so that ‖w −wkw‖ ≤ .,D.3 Proof of Theorem 2,[0],[0]
"Besides, |Θ| ≤ ∏l+1 i=1",D.3 Proof of Theorem 2,[0],[0]
n,D.3 Proof of Theorem 2,[0],[0]
i =,D.3 Proof of Theorem 2,[0],[0]
( 3(bl+1+ ∑l i=1 dibi) ),D.3 Proof of Theorem 2,[0],[0]
θ .,D.3 Proof of Theorem 2,[0],[0]
"Then we can bound P (E2) as follows:
P (E2) =P ( sup
wkw∈Θ
∥∥∥∥∥ 1 n n∑
i=1
∇f(wkw ,D(i))− ED∼D(∇f(wkw ,D))",D.3 Proof of Theorem 2,[0],[0]
"∥∥∥∥∥
2
≥ t 3
)
",D.3 Proof of Theorem 2,[0],[0]
"=P ( sup
wkw∈Θ,λ∈λ1/2 2
〈 λ, 1
n
n∑
i=1
∇f(wkw ,D(i))− ED∼D (∇f(wkw ,D)) 〉 ≥ t
3
)
",D.3 Proof of Theorem 2,[0],[0]
≤6d ( 9(bl+1 + ∑l i=1 dibi) ),D.3 Proof of Theorem 2,[0],[0]
"θ sup wkw∈Θ,λ∈λ1/2 P ( 1 n n∑
i=1
〈 λ,∇f(wkw ,D(i))− ED∼D (∇f(wkw ,D)) 〉 ≥ t
6
)
¬ ≤6d
( 9(bl+1 + ∑l i=1 dibi) )",D.3 Proof of Theorem 2,[0],[0]
"θ 2 exp ( − nt 2
72β2
) ,
where ¬ holds since by Lemma 16, we have
P
( 1
n
n∑
i=1
(〈 λ,∇wf(w,D(i))−ED∼D∇wf(w,D(i)) 〉) >t ) ≤ exp ( − nt 2
2β2
) .
",D.3 Proof of Theorem 2,[0],[0]
"where β , [ ϑr̃lc̃ldl + ∑l i=1 ϑbl+1 2di−1",D.3 Proof of Theorem 2,[0],[0]
p2bi2di ri−1ci−1,D.3 Proof of Theorem 2,[0],[0]
"∏l s=i dsbs 2(ks−ss+1)2 16p2 ]1/2 in which ϑ = 1/8.
",D.3 Proof of Theorem 2,[0],[0]
"Thus, if we set
t≥
√√√√72β2 ( d log(6) + θ log ( 9(bl+1+ ∑l i=1 dibi) )",D.3 Proof of Theorem 2,[0],[0]
"+ log ( 4 ε ))
n ,
then we have P (E2) ≤",D.3 Proof of Theorem 2,[0],[0]
"ε
2 .
",D.3 Proof of Theorem 2,[0],[0]
Step 3.,D.3 Proof of Theorem 2,[0],[0]
Bound P (E3):,D.3 Proof of Theorem 2,[0],[0]
"We first bound P (E3) as follows:
P (E3) =P (
sup w∈Ω ‖E(∇f(wkw ,x))−",D.3 Proof of Theorem 2,[0],[0]
"ED∼D(∇f(w,x))‖2 ≥
t
3
)
=P (
sup w∈Ω ‖ED∼D",D.3 Proof of Theorem 2,[0],[0]
(,D.3 Proof of Theorem 2,[0],[0]
"∇f(wkw ,x)−∇f(w,x)‖2) ‖w −wkw‖2",D.3 Proof of Theorem 2,[0],[0]
sup w∈Ω ‖w −wkw‖2,D.3 Proof of Theorem 2,[0],[0]
≥,D.3 Proof of Theorem 2,[0],[0]
"t 3
)
",D.3 Proof of Theorem 2,[0],[0]
"≤P ( ED∼D sup
w∈Ω
∥∥∥∇2Q̃n(w,x) ∥∥∥
2 ≥ t 3
)
",D.3 Proof of Theorem 2,[0],[0]
"≤P ( γ ≥ t
3
) .
",D.3 Proof of Theorem 2,[0],[0]
We set enough small such that γ < t/3 always holds.,D.3 Proof of Theorem 2,[0],[0]
"Then it yields P (E3) = 0.
",D.3 Proof of Theorem 2,[0],[0]
Step 4.,D.3 Proof of Theorem 2,[0],[0]
Final result: Note that 6β ε ≥ 3β .,D.3 Proof of Theorem 2,[0],[0]
"Finally, to ensure P(E0)",D.3 Proof of Theorem 2,[0],[0]
"≤ ε, we just set = 18p2(bl+1+ ∑l i=1 dibi)
",D.3 Proof of Theorem 2,[0],[0]
"ϑ2nbl+1
[∏l s=i dsbs 2(ks−ss+1)2 16p2 ]",D.3 Proof of Theorem 2,[0],[0]
"− 12 .
",D.3 Proof of Theorem 2,[0],[0]
"t ≥ max   6γ
ε ,
√√√√72β2 ( d log(6)",D.3 Proof of Theorem 2,[0],[0]
+ θ log ( 9(bl+1+ ∑l i=1 dibi) ),D.3 Proof of Theorem 2,[0],[0]
"+ log ( 4 ε ))
n
  .
",D.3 Proof of Theorem 2,[0],[0]
"By comparing the values of β and γ, we have if n ≥",D.3 Proof of Theorem 2,[0],[0]
"cg′ l 2bl+1
2(bl+1+ ∑l i=1 dibi) 2(r0c0d0) 4
d40b1 8(d log(6)+θ%)ε2 maxi(rici) where cg′ is a universal constant, then there exists a universal constant cg such that
sup w∈Ω
∥∥∥∇wQ̃n(w)−∇wQ(w) ∥∥∥
2 ≤cgβ
√√√√d+ 1log(6)θ [(∑l i=1 log (√ dsbs(ks−ss+1) 4p )",D.3 Proof of Theorem 2,[0],[0]
+log(bl+1)+log ( n 128p2 )),D.3 Proof of Theorem 2,[0],[0]
"+log ( 4 ε )]
n
≤cgβ
√ d+ 12θ%+ 1 2 log ( 4 ε )
n ,
holds with probability at least 1 − ε, where d = r̃lc̃ldldl+1 + ∑l i=1 ki 2di−1di, θ = al+1(dl+1 + r̃lc̃ldl + 1) + ∑l i=1 ai(ki 2di−1 + di + 1), % = ∑l i=1log (√ dibi(ki−si+1) 4p ) + log(bl+1)",D.3 Proof of Theorem 2,[0],[0]
"+ log ( n 128p2 ) , and β , [ ϑr̃lc̃ldl + ∑l i=1 ϑbl+1 2di−1",D.3 Proof of Theorem 2,[0],[0]
p2bi2di ri−1ci−1,D.3 Proof of Theorem 2,[0],[0]
∏l s=i dsbs 2(ks−ss+1)2 16p2 ]1/2 in which ϑ = 1/8.,D.3 Proof of Theorem 2,[0],[0]
The proof is completed.,D.3 Proof of Theorem 2,[0],[0]
Proof.,D.4 Proof of Corollary 1,[0],[0]
"By Theorem 2, we know that there exist universal constants cg′ and cg such that if n ≥ cg′ l2bl+1 2(bl+1+ ∑l i=1 dibi) 2(r0c0d0) 4
d40b1 8(d log(6)+θ%)ε2 maxi(rici)
, then
sup w∈Ω
∥∥∥∇wQ̃n(w)−∇wQ(w) ∥∥∥
2 ≤ cgβ
√ 2d+ θ%+ log ( 4 ε )
2n
holds with probability at least 1 − ε, where % is provided in Lemma 1.",D.4 Proof of Corollary 1,[0],[0]
Here β and d are defined as β =[ rlcldl 8p2 +,D.4 Proof of Corollary 1,[0],[0]
∑l i=1 bl+1 2di−1,D.4 Proof of Corollary 1,[0],[0]
"8p2bi2di ri−1ci−1 ∏l j=i djbj 2(kj−sj+1)2 16p2 ]1/2 and d = r̃lc̃ldldl+1 + ∑l i=1 ki 2di−1di, respectively.
",D.4 Proof of Corollary 1,[0],[0]
"So based on such a result, we can derive that if n ≥ c2g(2d+ θ%+ log(4/ε))β2/(2 ), then we have
‖∇Q(w̃)‖2 ≤ ∥∥∥∇wQ̃n(w̃) ∥∥∥ 2 + ∥∥∥∇wQ̃n(w̃)−∇wQ(w̃)",D.4 Proof of Corollary 1,[0],[0]
∥∥∥ 2 ≤,D.4 Proof of Corollary 1,[0],[0]
"√ + cgβ
√ 2d+ θ%+ log ( 4 ε )
2n ≤ 2√ .
",D.4 Proof of Corollary 1,[0],[0]
"Thus, we have ‖∇Q(w̃)‖22 ≤ 4 , which means that w̃ is a 4 -approximate stationary point in population risk with probability at least 1− ε.",D.4 Proof of Corollary 1,[0],[0]
The proof is completed.,D.4 Proof of Corollary 1,[0],[0]
Proof.,D.5 Proof of Theorem 3,[0],[0]
"Suppose that {w(1),w(2), · · · ,w(m)} are the non-degenerate critical points ofQ(w).",D.5 Proof of Theorem 3,[0],[0]
"So for any w(k), it obeys
inf i
∣∣λki ( ∇2Q(w(k)) )∣∣",D.5 Proof of Theorem 3,[0],[0]
"≥ ζ,
where λki ( ∇2Q(w(k)) ) denotes the i-th eigenvalue of the Hessian ∇2Q(w(k)) and ζ is a constant.",D.5 Proof of Theorem 3,[0],[0]
"We further define a
set D = {w ∈",D.5 Proof of Theorem 3,[0],[0]
Rd,D.5 Proof of Theorem 3,[0],[0]
| ‖∇Q(w)‖2 ≤ and infi |λi ( ∇2Q(w(k)) ),D.5 Proof of Theorem 3,[0],[0]
| ≥ ζ}.,D.5 Proof of Theorem 3,[0],[0]
"According to Lemma 5, D = ∪∞k=1Dk where each Dk is a disjoint component with w(k) ∈ Dk for k ≤ m",D.5 Proof of Theorem 3,[0],[0]
and Dk does not contain any critical point ofQ(w) for k ≥ m+ 1.,D.5 Proof of Theorem 3,[0],[0]
"On the other hand, by the continuity of∇Q(w), it yields ‖∇Q(w)‖2 = for w ∈ ∂Dk.",D.5 Proof of Theorem 3,[0],[0]
"Notice, we set the value of blow which is actually a function related to n.
Then by utilizing Theorem 2, we let sample number n sufficient large such that
sup w∈Ω
∥∥∥∇Q̃n(w)−∇Q(w) ∥∥∥
2 ≤ 2
holds with probability at least 1− ε, where is defined as
2 , cgβ
√√√√d log(6)",D.5 Proof of Theorem 3,[0],[0]
+ θ,D.5 Proof of Theorem 3,[0],[0]
(∑l i=1 log (√ dsbs(ks−ss+1) 4p ) + log(bl+1),D.5 Proof of Theorem 3,[0],[0]
+ log ( n 128p2 )),D.5 Proof of Theorem 3,[0],[0]
"+ log ( 4 ε )
n .
",D.5 Proof of Theorem 3,[0],[0]
This further gives that for arbitrary w ∈,D.5 Proof of Theorem 3,[0],[0]
"Dk, we have
inf w∈Dk
∥∥∥t∇Q̃n(w)",D.5 Proof of Theorem 3,[0],[0]
+ (,D.5 Proof of Theorem 3,[0],[0]
"1− t)∇Q(w) ∥∥∥
2 = inf w∈Dk
∥∥∥t ( ∇Q̃n(w)−∇Q(w) )",D.5 Proof of Theorem 3,[0],[0]
"+∇Q(w) ∥∥∥ 2
≥ inf w∈Dk",D.5 Proof of Theorem 3,[0],[0]
‖∇Q(w)‖2,D.5 Proof of Theorem 3,[0],[0]
"− sup w∈Dk
t ∥∥∥∇Q̃n(w)−∇Q(w) ∥∥∥ 2
≥ 2 .",D.5 Proof of Theorem 3,[0],[0]
"(6)
Similarly, by utilizing Lemma 18, let n be sufficient large such that
sup w∈Ω
∥∥∥∇2Q̃n(w)−∇2Q(w) ∥∥∥
op ≤ ζ 2
holds with probability at least 1− ε, where ζ satisfies
ζ 2 ≥ cvγ
√ d+",D.5 Proof of Theorem 3,[0],[0]
"θ%+ log ( 4 ε )
n .
",D.5 Proof of Theorem 3,[0],[0]
Assume that b ∈ Rd is a vector and satisfies bT b = 1.,D.5 Proof of Theorem 3,[0],[0]
"In this case, we can bound λki ( ∇2Q̃n(w) ) for arbitrary w ∈ Dk as follows:
inf w∈Dk
∣∣∣λki ( ∇2Q̃n(w) )∣∣∣",D.5 Proof of Theorem 3,[0],[0]
"= inf w∈Dk min bT b=1 ∣∣∣bT∇2Q̃n(w)b ∣∣∣
= inf w∈Dk min bT b=1
∣∣∣bT ( ∇2Q̃n(w)−∇2Q(w) )",D.5 Proof of Theorem 3,[0],[0]
"b+ bT∇2Q(w)b ∣∣∣
",D.5 Proof of Theorem 3,[0],[0]
"≥ inf w∈Dk min bT b=1
∣∣bT∇2Q(w)b ∣∣− min
bT b=1
∣∣∣bT ( ∇2Q̃n(w)−∇2Q(w) )",D.5 Proof of Theorem 3,[0],[0]
"b ∣∣∣
≥ inf w∈Dk min bT b=1
∣∣bT∇2Q(w)b ∣∣− max
bT b=1
∣∣∣bT ( ∇2Q̃n(w)−∇2Q(w) )",D.5 Proof of Theorem 3,[0],[0]
"b ∣∣∣
= inf w∈Dk inf i |λki ( ∇2f(w(k),x) )",D.5 Proof of Theorem 3,[0],[0]
| − ∥∥∥∇2Q̃n(w)−∇2Q(w) ∥∥∥,D.5 Proof of Theorem 3,[0],[0]
"op
≥ζ 2 .
(7)
",D.5 Proof of Theorem 3,[0],[0]
"This means that in each set Dk,∇2Q̃n(w) has no zero eigenvalues.",D.5 Proof of Theorem 3,[0],[0]
"Then, combine this and Eqn.",D.5 Proof of Theorem 3,[0],[0]
"(6), by Lemma 4 we know that if the population riskQ(w) has no critical point in Dk, then the empirical risk Q̃n(w) has also no critical point in Dk; otherwise it also holds.
",D.5 Proof of Theorem 3,[0],[0]
Now we bound the distance between the corresponding critical points ofQ(w) and Q̃n(w).,D.5 Proof of Theorem 3,[0],[0]
"Assume that in Dk,Q(w) has a unique critical point w(k) and Q̃n(w) also has a unique critical point w (k) n .",D.5 Proof of Theorem 3,[0],[0]
"Then, there exists t ∈",D.5 Proof of Theorem 3,[0],[0]
"[0, 1] such that for any z ∈ ∂Bd(1), we have ≥‖∇Q(w(k)n )",D.5 Proof of Theorem 3,[0],[0]
"‖2
= max zT z=1
〈∇Q(w(k)n ), z〉
= max zT z=1",D.5 Proof of Theorem 3,[0],[0]
"〈∇Q(w(k)), z〉+ 〈∇2Q(w(k) + t(w(k)n −w(k)))(w(k)n −w(k)), z〉 ¬ ≥ 〈( ∇2Q(w(k)) )",D.5 Proof of Theorem 3,[0],[0]
"2 (w(k)n −w(k)), (w(k)n −w(k))",D.5 Proof of Theorem 3,[0],[0]
"〉1/2
 ",D.5 Proof of Theorem 3,[0],[0]
"≥ζ‖w(k)n −w(k)‖2,
where ¬ holds since ∇Q(w(k))",D.5 Proof of Theorem 3,[0],[0]
= 0 and  holds since w(k) + t(w(k)n −w(k)) is in Dk and for any w ∈,D.5 Proof of Theorem 3,[0],[0]
Dk we have infi |λi ( ∇2Q(w) ),D.5 Proof of Theorem 3,[0],[0]
| ≥ ζ.,D.5 Proof of Theorem 3,[0],[0]
"So if n ≥ ch max ( l2bl+1 2(bl+1+ ∑l i=1 dibi) 2(r0c0d0) 4
d40b1 8d%ε2 maxi(rici)
, d+θ%ζ2 ) where ch is a constant, then
‖w(k)n −w(k)‖2 ≤ 2cgβ
ζ
√√√√d log(6)",D.5 Proof of Theorem 3,[0],[0]
+ θ,D.5 Proof of Theorem 3,[0],[0]
(∑l i=1 log (√ dsbs(ks−ss+1) 4p ) + log(bl+1),D.5 Proof of Theorem 3,[0],[0]
+ log ( n 128p2 )),D.5 Proof of Theorem 3,[0],[0]
"+ log ( 4 ε )
n
holds with probability at least 1− ε.",D.5 Proof of Theorem 3,[0],[0]
Proof.,D.6 Proof of Corollary 2,[0],[0]
"By Theorem 3, we know that the non-degenerate stationary point w(k) in the m non-degenerate stationary points in population risk, denoted by {w(1),w(2), · · · ,w(m)} uniquely corresponding to a non-degenerate stationary point w(k)n in the empirical risk.
",D.6 Proof of Corollary 2,[0],[0]
"On the other hand, for any w(k), it obeys
inf i
∣∣λki ( ∇2Q(w(k)) )∣∣",D.6 Proof of Corollary 2,[0],[0]
"≥ ζ,
where λki ( ∇2Q(w(k)) ) denotes the i-th eigenvalue of the Hessian ∇2Q(w(k)) and ζ is a constant.",D.6 Proof of Corollary 2,[0],[0]
"We further define a
set D = {w ∈",D.6 Proof of Corollary 2,[0],[0]
Rd,D.6 Proof of Corollary 2,[0],[0]
| ‖∇Q(w)‖2 ≤ and infi |λi ( ∇2Q(w(k)) ),D.6 Proof of Corollary 2,[0],[0]
| ≥ ζ}.,D.6 Proof of Corollary 2,[0],[0]
"According to Lemma 5, D = ∪∞k=1Dk where each Dk is a disjoint component with w(k) ∈ Dk for k ≤ m",D.6 Proof of Corollary 2,[0],[0]
and Dk does not contain any critical point ofQ(w) for k ≥ m+ 1.,D.6 Proof of Corollary 2,[0],[0]
Thenw(k)n also belong to the component Dk due to the unique corresponding relation betweenw(k) andw (k) n .,D.6 Proof of Corollary 2,[0],[0]
"Then from Eqn. (6) and (7), we know that if the assumptions in Theorem 3 hold, then for arbitrary w ∈",D.6 Proof of Corollary 2,[0],[0]
"Dk and t ∈ (0, 1),
inf w∈Dk
∥∥∥t∇Q̃n(w)",D.6 Proof of Corollary 2,[0],[0]
+ (,D.6 Proof of Corollary 2,[0],[0]
"1− t)∇Q(w) ∥∥∥
2 ≥ 2 and inf w∈Dk
∣∣∣λki ( ∇2Q̃n(w) )∣∣∣ ≥ ζ 2 ,
where and ζ are constants.",D.6 Proof of Corollary 2,[0],[0]
"This means that in each set Dk,∇2Q̃n(w) has no zero eigenvalues.",D.6 Proof of Corollary 2,[0],[0]
"Then, combine this and Eqn.",D.6 Proof of Corollary 2,[0],[0]
"(6), we can obtain that in Dk, ifQ(w) has a unique critical pointw(k) with non-degenerate index sk, then Q̃n(w) also has a unique critical point wn(k) in Dk with the same non-degenerate index sk.",D.6 Proof of Corollary 2,[0],[0]
"Namely, the number of negative eigenvalues of the Hessian matrices∇2Q(w(k)) and ∇2Q(w(k)n ) are the same.",D.6 Proof of Corollary 2,[0],[0]
"This further gives that if one of the pair (w(k),w(k)n ) is a local minimum or saddle point, then another one is also a local minimum or a saddle point.",D.6 Proof of Corollary 2,[0],[0]
The proof is completed.,D.6 Proof of Corollary 2,[0],[0]
Proof.,E.1 Proof of Lemma 8,[0],[0]
(1) Since G (z) is a diagonal matrix and its diagonal values are upper bounded by σ1(zi)(1− σ1(z)),E.1 Proof of Lemma 8,[0],[0]
"≤ 1/4 where zi denotes the i-th entry of zi, we can conclude
‖G (z)M‖2F ≤ 1
16 ‖M‖2F and ‖NG (z)‖2F ≤
1
16 ‖N‖2F .
",E.1 Proof of Lemma 8,[0],[0]
"(2) The operator Q (·) maps a vector z ∈ Rd into a matrix of size d2 × d whose ((i− 1)d+ i, i) (i = 1, · · · , d) entry equal to σ1(zi)(1− σ1(zi))(1− 2σ1(zi)) and rest entries are all 0.",E.1 Proof of Lemma 8,[0],[0]
"This gives
σ1(zi)(1− σ1(zi))(1− 2σ1(zi))",E.1 Proof of Lemma 8,[0],[0]
"= 1
3 (3σ1(zi))(1− σ1(zi))(1− 2σ1(zi))
",E.1 Proof of Lemma 8,[0],[0]
"≤1 3
( 3σ1(zi) + 1− σ1(zi) + 1− 2σ1(zi)
3
)3
≤2 3
34 .
",E.1 Proof of Lemma 8,[0],[0]
"This means the maximal value in Q (z) is at most 2 3
34 .",E.1 Proof of Lemma 8,[0],[0]
"Consider the structure in Q (z), we can obtain
‖Q (z)M‖2F ≤ 26
38 ‖M‖2F and ‖NQ (z)‖2F ≤
26 38 ‖N‖2F .
",E.1 Proof of Lemma 8,[0],[0]
(3) up (M) represents conducting upsampling on M ∈ Rs×t×q.,E.1 Proof of Lemma 8,[0],[0]
Let N = up (M) ∈ Rps×pt×q.,E.1 Proof of Lemma 8,[0],[0]
"Specifically, for each slice N(:, :, i) (i = 1, · · · , q), we have N(:, :, i) = up (M(:, :, i)).",E.1 Proof of Lemma 8,[0],[0]
"It actually upsamples each entry M(g, h, i) into a matrix of p2 same entries 1p2M(g, h, i).",E.1 Proof of Lemma 8,[0],[0]
"So it is easy to obtain
‖up (M)‖2F ≤ 1
p2 ‖M‖2F .
",E.1 Proof of Lemma 8,[0],[0]
"(4) Let M = W (:, :, i) and N = δ̃i+1(:, : i).",E.1 Proof of Lemma 8,[0],[0]
"Assume that H = M ~N ∈ Rm1×m2 , where m1 = r̃i−1",E.1 Proof of Lemma 8,[0],[0]
− 2ki + 2 and m2 = c̃i−1,E.1 Proof of Lemma 8,[0],[0]
− 2ki + 2.,E.1 Proof of Lemma 8,[0],[0]
"Then we have
‖H‖2F = m1∑
i=1
m2∑
j=1
|H(i, j)|2 = m1∑
i=1
m2∑
j=1
〈MΩi,j ,N〉2 ≤ m1∑
i=1
m2∑
j=1
‖MΩi,j‖2F ‖N‖2F ,
where Ωi,j denotes the entry index ofM for the (i, j)-th convolution operation (i.e. computing theH(i, j)).
",E.1 Proof of Lemma 8,[0],[0]
"Since for each convolution computing, each element in M is involved at most one time, we can claim that any element in M in ∑m1 i=1 ∑m2",E.1 Proof of Lemma 8,[0],[0]
"j=1 ‖MΩi,j‖2F occurs at most (ki − si + 1)2 since there are si − 1 rows and columns between each neighboring nonzero entries inN which is decided by the definition of δ̃i+1 in Sec. B.1.",E.1 Proof of Lemma 8,[0],[0]
"Therefore, we have
m1∑
i=1
m2∑
j=1
‖MΩi,j‖2F ≤ (ki − si + 1)2‖M‖2F ,
which further gives
‖M~̃N‖2F ≤",E.1 Proof of Lemma 8,[0],[0]
"(ki − si + 1)2‖M‖2F ‖N‖2F .
",E.1 Proof of Lemma 8,[0],[0]
"Consider all the slices in δ̃i+1, we can obtain
‖δ̃i+1~̃W ‖2F ≤",E.1 Proof of Lemma 8,[0],[0]
(ki − si + 1)2‖W ‖2F,E.1 Proof of Lemma 8,[0],[0]
"‖δ̃i+1‖2F .
",E.1 Proof of Lemma 8,[0],[0]
"(5) Since for softmax activation function σ2, we have ∑dl+1 i=1",E.1 Proof of Lemma 8,[0],[0]
vi,E.1 Proof of Lemma 8,[0],[0]
= 1 (vi ≥ 0),E.1 Proof of Lemma 8,[0],[0]
"and there is only one nonzero entry (i.e. 1) in y, we can obtain
0 ≤",E.1 Proof of Lemma 8,[0],[0]
‖v,E.1 Proof of Lemma 8,[0],[0]
− y‖22 = ‖v‖22 + ‖y‖22,E.1 Proof of Lemma 8,[0],[0]
"− 2〈v,y〉 = 2− 2〈v,y〉 ≤ 2.
",E.1 Proof of Lemma 8,[0],[0]
The proof is completed.,E.1 Proof of Lemma 8,[0],[0]
This work aims to provide understandings on the remarkable success of deep convolutional neural networks (CNNs) by theoretically analyzing their generalization performance and establishing optimization guarantees for gradient descent based training algorithms.,abstractText,[0],[0]
"Specifically, for a CNN model consisting of l convolutional layers and one fully connected layer, we prove that its generalization error is bounded by O( √ θ%̃/n) where θ denotes freedom degree of the network parameters and %̃ = O(log(li=1 bi(ki",abstractText,[0],[0]
− si + 1)/p) + log(bl+1)),abstractText,[0],[0]
"encapsulates architecture parameters including the kernel size ki, stride si, pooling size p and parameter magnitude bi.",abstractText,[0],[0]
"To our best knowledge, this is the first generalization bound that only depends on O(log(∏l+1 i=1",abstractText,[0],[0]
"bi)), tighter than existing ones that all involve an exponential term likeO(∏l+1 i=1",abstractText,[0],[0]
bi).,abstractText,[0],[0]
"Besides, we prove that for an arbitrary gradient descent algorithm, the computed approximate stationary point by minimizing empirical risk is also an approximate stationary point to the population risk.",abstractText,[0],[0]
This well explains why gradient descent training algorithms usually perform sufficiently well in practice.,abstractText,[0],[0]
"Furthermore, we prove the one-to-one correspondence and convergence guarantees for the non-degenerate stationary points between the empirical and population risks.",abstractText,[0],[0]
"It implies that the computed local minimum for the empirical risk is also close to a local minimum for the population risk, thus ensuring the good generalization performance of CNNs.",abstractText,[0],[0]
Understanding Generalization and Optimization Performance of Deep CNNs,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1131–1141, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"The pattern of language use in a multilingual society is a complex interplay of socio-linguistic, discursive and pragmatic factors.",1 Introduction,[0],[0]
"Sometimes speakers have a preference for a particular language for certain conversational and discourse settings; on other occasions, there is fluid alteration between two or more languages in a single conversation, also known as Code-switching (CS) or Code-mixing1. Under-
∗*",1 Introduction,[0],[0]
"This work was done when the author was a Research Fellow at Microsoft Research Lab India.
",1 Introduction,[0],[0]
"1Although some linguists differentiate between Codeswitching and Code-mixing, this paper will use the two terms interchangeably.
",1 Introduction,[0],[0]
"standing and characterizing language preference in multilingual societies has been the subject matter of linguistic inquiry for over half a century (see Milroy and Muysken (1995) for an overview).
",1 Introduction,[0],[0]
"Conversational phenomena such as CS were observed only in speech and therefore, all previous studies are based on data collected from a small set of speakers or from interviews.",1 Introduction,[0],[0]
"With the growing popularity of social media, we now have an abundance of conversation-like data that exhibit CS and other speech phenomena, hitherto unseen in text (Bali et al., 2014).",1 Introduction,[0],[0]
"Leveraging such data from Twitter, we conduct a large-scale study on language preference, if any, for the expression of opinion and sentiment by Hindi-English (Hi-En) bilinguals.
",1 Introduction,[0],[0]
"We first build a corpus of 430,000 unique Indiaspecific tweets across four domains (sports, entertainment, politics and current events) and automatically classify the tweets by their language: English, Hindi and Hi-En CS.",1 Introduction,[0],[0]
We then develop an opinion detector for each language class to further categorize them into opinionated and non-opinionated tweets.,1 Introduction,[0],[0]
"Sentiment detectors further classify the opinionated tweets as positive, negative or neutral.",1 Introduction,[0],[0]
Our study shows that there is a strong preference towards Hindi (i.e. the native language or L1) over English (L2) for expression of negative opinion.,1 Introduction,[0],[0]
"The effect is clearly visible in CS tweets, where a switch from English to Hindi is often correlated with a switch from a positive to negative sentiment.",1 Introduction,[0],[0]
"This is referred to as the polarity–switch function of CS (Sanchez, 1983).",1 Introduction,[0],[0]
"Using the same experimental technique, we also explore other pragmatic functions of CS, such as reinforcement and narrative–evaluative.
",1 Introduction,[0],[0]
"1131
Apart from being the first large-scale quantitative study of language preference in multilingual societies, this work also has several other contributions: (a) We develop one of the first opinion and sentiment classifiers for Romanized Hindi and CS Hi-En tweets with higher accuracy than the only known previous attempt (Sharma et al., 2015b).",1 Introduction,[0],[0]
"(b) We present a novel methodology for automatically detecting pragmatic functions of codeswitching through opinion and sentiment detection.
",1 Introduction,[0],[0]
"The rest of the paper is organized as follows: Sec. 2 introduces language preference, functions of CS and Hindi-English bilingualism on the web.",1 Introduction,[0],[0]
Sec. 3 formulates the problem and presents the fundamental questions that this paper seeks to answer.,1 Introduction,[0],[0]
Sec. 4 and 5 discuss dataset creation and opinion and sentiment detection techniques respectively.,1 Introduction,[0],[0]
Sec. 6 evaluates the hypotheses in light of the observations on the tweet corpus.,1 Introduction,[0],[0]
"We conclude in Sec. 7, and raise some interesting sociolinguistic questions for future studies.",1 Introduction,[0],[0]
"In order to situate the questions addressed in our work in existing literature, we present a brief overview of the past research in pragmatic and discursive analysis of code-switching, and specifically, on language preference for emotional expression.",2 Background and Related Work,[0],[0]
A primer to Hi-En bilingualism and its presence in social media shall follow.,2 Background and Related Work,[0],[0]
"In multilingual communities, where there are more than one linguistic channels for information exchange, the choice of the channel depends on a variety of factors, and is usually unpredictable (Auer, 1995).",2.1 CS Functions and Language Preference,[0],[0]
"Nevertheless, linguistic studies point out certain frequently-observed patterns.",2.1 CS Functions and Language Preference,[0],[0]
"For instance, certain speech activities might be exclusively or more commonly related to a certain language choice (e.g. Fishman (1971) reports use of English for professional purposes and Spanish for informal chat for English-Spanish bilinguals from Puerto Rico).",2.1 CS Functions and Language Preference,[0],[0]
"Apart from association between such conversational contexts and language preference, language alteration is often found to be used as a signaling device to imply certain pragmatic functions (Barredo, 1997; Sanchez, 1983; Nishimura, 1995; Maschler,
1991; Maschler, 1994) such as: (a) reported speech (b) narrative to evaluative switch (c) reiterations or emphasis (d) topic shift (e) puns and language play (f) topic/comment structuring etc.",2.1 CS Functions and Language Preference,[0],[0]
"Attempts of predicting the preferred language, or even exhaustively listing such functions, have failed.",2.1 CS Functions and Language Preference,[0],[0]
"However, linguists agree that language alteration in multilingual communities is not a random process.
",2.1 CS Functions and Language Preference,[0],[0]
Of specific interest to us are the studies on language preference for expression of emotions.,2.1 CS Functions and Language Preference,[0],[0]
"Through large-scale interviews and two decades of research, Dewaele (2004; 2010) argued that for most multilinguals, L1 (the dominant language, which is often, but not always, the native or mother tongue) is the language preference for emotions, which include emotional inner speech, swearing and even emotional conversations.",2.1 CS Functions and Language Preference,[0],[0]
"Dewaele argues that emotionally charged words in L1 elicit stronger emotions than those in other languages, and hence L1 is preferred for emotion expression.",2.1 CS Functions and Language Preference,[0],[0]
"Around 125 million people in India speak English, half of whom have Hindi as their mother-tongue.",2.2 Hindi-English Bilingualism,[0],[0]
"The large proportion of the remaining half, especially those residing in the metropolitan cities, also know at least some Hindi.",2.2 Hindi-English Bilingualism,[0],[0]
"This makes Hi-En codeswitching, commonly called Hinglish, extremely widespread in India.",2.2 Hindi-English Bilingualism,[0],[0]
"There is historical attestation, as well as recent studies on the growing use of Hinglish in general conversation, and in entertainment and media (see Parshad et al. (2016) and references therein).",2.2 Hindi-English Bilingualism,[0],[0]
"Several recent studies (Bali et al., 2014; Barman et al., 2014; Solorio et al., 2014; Sequiera et al., 2015) also provide evidence of Hinglish and other instances of CS on online social media such as Twitter and Facebook.",2.2 Hindi-English Bilingualism,[0],[0]
"In a Facebook dataset analyzed by Bali et al. (2014), almost all sufficiently long conversation threads were found to be multilingual, and as much as 17% of the comments had CS.",2.2 Hindi-English Bilingualism,[0],[0]
"This study also indicates that on online social media, Hindi is seldom written in the Devanagari script.",2.2 Hindi-English Bilingualism,[0],[0]
"Instead, loose Roman transliteration, or Romanized Hindi, is common, especially when users code-switch between Hindi and English.
",2.2 Hindi-English Bilingualism,[0],[0]
"While there has been some effort towards computational processing of CS text (Solorio and Liu, 2008; Solorio and Liu, 2010; Vyas et al., 2014; Peng
et al., 2014), to the best of our knowledge, there has been no study on automatic identification of functional aspects of CS or any large-scale, data-driven study of language preference.",2.2 Hindi-English Bilingualism,[0],[0]
"The current study adds to the growing repertoire of work on quantitative analysis of social media data for understanding socio-linguistic and pragmatic issues, such as detection of depression (De Choudhury et al., 2013), politeness (Danescu-Niculescu-Mizil et al., 2013), speech acts (Vosoughi and Roy, 2016), and social status (Tchokni et al., 2014).",2.2 Hindi-English Bilingualism,[0],[0]
"Along the lines of (Dewaele, 2010), we ask the following question: Is there a preferred language for expression of opinion and sentiment by the Hi-En bilinguals on Twitter?",3 Problem Formulation,[0],[0]
"More formally, let Λ = {h, e,m} be the set of languages: Hindi (h), English (e) and Mixed (m), i.e., code-switched.",3.1 Definitions,[0],[0]
"Let Σ = {d, r}, be the set of scripts:2 Devanagari (d) and Roman (r).",3.1 Definitions,[0],[0]
"Let us further introduce a set of sentiments, 3 = {+,−, 0,⊗}, where +, − and 0 respectively denote utterances with positive, negative and neutral opinions.",3.1 Definitions,[0],[0]
"⊗ denote non-opinionated (like factual) texts.
",3.1 Definitions,[0],[0]
"Let T = {t1, t2, . . .",3.1 Definitions,[0],[0]
t|T |} be a set of tweets (or any text) generated by Hi-En bilinguals.,3.1 Definitions,[0],[0]
"We define:
• λ(T ), σ(T ) and (T ) as the subsets of T that respectively contain all tweets in language λ, script σ and sentiment .
",3.1 Definitions,[0],[0]
• λσ (T ) = λ(T )∩ σ(T )∩ (T ).,3.1 Definitions,[0],[0]
"Likewise, we also define λ (T ) = λ(T ) ∩ (T ), λσ(T ) =",3.1 Definitions,[0],[0]
"λ(T ) ∩ σ(T ) and σ (T ) = σ(T ) ∩ (T ).
",3.1 Definitions,[0],[0]
"The preference towards a language-script pair λσ for expressing a type of sentiment is given by the probability
pr(λσ| ;T ) = pr( |λσ;T )",3.1 Definitions,[0],[0]
"pr(λσ|T ) pr( |T ) (1)
However, pr(λσ), which defines the prior probability of choosing λσ for a tweet is dependent on a large
2Tweets in mixed script are rare and hence we do not include a symbol for it, though the framework does not preclude such possibilities.
number of socio-linguistic parameters beyond sentiment.",3.1 Definitions,[0],[0]
"For instance, on social media, English is overwhelmingly more common than any Indic language (Bali et al., 2014).",3.1 Definitions,[0],[0]
This is because (a) English tweets come from a large number of users apart from Hi-En bilinguals and (b) English is the preferred language for tweeting even for Hi-En bilinguals because it expands the target audience of the tweet by manifolds.,3.1 Definitions,[0],[0]
"The preference of λσ for expressing , therefore, can be quantified as:
pr( |λσ;T ) = |λσ (T )||λσ(T )| (2)
",3.1 Definitions,[0],[0]
"We say λσ is the preferred language-script choice over λ′σ′ for expressing sentiment if and only if
pr( |λσ;T ) > pr( |λ′σ′;T ) (3)
",3.1 Definitions,[0],[0]
The strength of the preference is directly proportionate the ratio of the probabilities: pr( |λσ;T )/pr( |λ′σ′;T ).,3.1 Definitions,[0],[0]
"An alternative but related way of characterizing the preference is through comparing the odds of choosing a sentiment type to its polar opposite - ′. We say, λσ is the preferred language-script pair for expressing , if
pr( |λσ;T ) pr( ′|λσ;T ) >",3.1 Definitions,[0],[0]
pr( |λ′σ′;T ) pr( ′|λ′σ′;T ) (4),3.1 Definitions,[0],[0]
"Now we can formally define the two hypotheses, we intend to test here.",3.2 Hypotheses,[0],[0]
Hypothesis I:,3.2 Hypotheses,[0],[0]
"For Hi-En bilinguals, Hindi is the preferred language for expression of opinion on Twitter.",3.2 Hypotheses,[0],[0]
"Therefore, we expect
pr({+,−, 0}|hd;T )",3.2 Hypotheses,[0],[0]
"> pr({+,−, 0}|er;T ) (5)
i.e., pr(⊗|hd;T ) < pr(⊗|er;T ) (6) And similarly,
pr(⊗|hr;T ) < pr(⊗|er;T ) (7)
Hypothesis II:",3.2 Hypotheses,[0],[0]
"For Hi-En bilinguals, Hindi is the preferred language for expression of negative sentiment.",3.2 Hypotheses,[0],[0]
"Therefore,
pr(−|hd;T )",3.2 Hypotheses,[0],[0]
≈ pr(−|hr;T ) >,3.2 Hypotheses,[0],[0]
"pr(−|er;T ) (8)
In particular, we would like to hypothesize that the odds of choosing Hindi for negative over positive is really high compared to the odds for English.",3.2 Hypotheses,[0],[0]
"I.e.,
pr(−|hd;T ) pr(+|hd;T )",3.2 Hypotheses,[0],[0]
≈ pr(−|hr;T ) pr(+|hr;T ) >,3.2 Hypotheses,[0],[0]
"pr(−|er;T ) pr(+|er;T ) (9)
",3.2 Hypotheses,[0],[0]
"A special case of the above hypotheses arise in the context of code-mixing, i.e., for the set mr(T ).",3.2 Hypotheses,[0],[0]
"Since the mixed tweets certainly come from proficient bilinguals and have both Hi and En fragments, we can reformulate our hypotheses at a tweet level.",3.2 Hypotheses,[0],[0]
Let mhr(T ) and mer(T ) respectively denote the set of Hi and En fragments in mr(T ).,3.2 Hypotheses,[0],[0]
Hypothesis Ia: Hindi is the preferred language for expression of opinion in Hi-En code-mixed tweets.,3.2 Hypotheses,[0],[0]
"Therefore, we expect
i.e., pr(⊗|mhr;T ) < pr(⊗|mer;T ) (10)
Hypothesis IIa:",3.2 Hypotheses,[0],[0]
Hindi is the preferred language for expression of negative sentiment in Hi-En codeswitched tweets.,3.2 Hypotheses,[0],[0]
"Therefore,
pr(−|mhr;T )",3.2 Hypotheses,[0],[0]
"> pr(−|mer;T ) (11)
pr(−|mhr;T ) pr(+|mhr;T )",3.2 Hypotheses,[0],[0]
"> pr(−|mer;T ) pr(+|mer;T ) (12)
",3.2 Hypotheses,[0],[0]
"Likewise, the above hypotheses also apply for the Devanagari script, though for technical reasons, we do not test them here.
",3.2 Hypotheses,[0],[0]
"Besides comparing aggregate statistics onmr(T ), it is also interesting to look at the sentiment of mhr(ti) andmer(ti) for each tweet ti.",3.2 Hypotheses,[0],[0]
"In particular, for every pair of 6= ′, we want to study the fraction of tweets in mr(T ) where mhr(ti) has sentiment and mer(ti) has ′. Let this fraction be pr(h ↔",3.2 Hypotheses,[0],[0]
e ′;mr(T )).,3.2 Hypotheses,[0],[0]
"Under “no-preference for language” (i.e., the null) hypothesis, we would expect pr(h ↔",3.2 Hypotheses,[0],[0]
e ′;mr(T )),3.2 Hypotheses,[0],[0]
≈ pr(h ′,3.2 Hypotheses,[0],[0]
↔ e ;mr(T )).,3.2 Hypotheses,[0],[0]
"However, if pr(h ↔ ′;mr(T )) is significantly higher than pr(h ′",3.2 Hypotheses,[0],[0]
"↔ e ;mr(T )), it means that speakers prefer to switch from English to Hindi when they want to express a sentiment and vice versa.",3.2 Hypotheses,[0],[0]
"Pragmatic Functions of Code-Switching: When native speakers tend to switch from Hindi to English when they switch from an expression with sentiment to one with ′, or in other words ↔ ′, we
say this is an observed pragmatic function of codeswitching between Hindi and English (note that the order of the languages is important), if and only if
pr(h ↔",3.2 Hypotheses,[0],[0]
e ′;mr(T )) pr(h ′,3.2 Hypotheses,[0],[0]
↔ e ;mr(T )),3.2 Hypotheses,[0],[0]
> 1 (13),3.2 Hypotheses,[0],[0]
"All the statistics defined here are likelihoods; Equations 9, 12 and 13, in particular, state our hypothesis in the form of the Likelihood Ratio Test.",3.3 A Note on Statistical Significance,[0],[0]
"However, the true classes λ and are unknown; we predict the class labels using automatic language and sentiment detection techniques that have non-negligible errors.",3.3 A Note on Statistical Significance,[0],[0]
"Under such a situation, the likelihoods cannot be considered as true test statistics, and consequently, hypothesis testing cannot be done per se.",3.3 A Note on Statistical Significance,[0],[0]
"Nevertheless, we can use these as descriptive statistics and investigate the status of the aforementioned hypotheses.",3.3 A Note on Statistical Significance,[0],[0]
"We collected tweets with certain India-specific hashtags (Table 1) using the Twitter Search API (Twi, 2015b) over three months (December 2014 – February 2015).",4 Datasets,[0],[0]
"In this paper, we use tweets in Devanagari script Hindi (hd), and Roman script English (er), Hindi (hr) and Hi-En Mixed (mr).",4 Datasets,[0],[0]
"English and mixed tweets written in Devanagari are extremely rare (Bali et al., 2014) and we do not study them here.",4 Datasets,[0],[0]
"We filter out tweets labeled by the Twitter API (Twi, 2015a) as German, Spanish, French, Portuguese, Turkish, and all non-Roman script languages (except Hindi).
",4 Datasets,[0],[0]
We experiment on the following different corpora:,4 Datasets,[0],[0]
TAll: All tweets after filtering.,4 Datasets,[0],[0]
"This corpus contains 430,000 unique tweets posted by 1,25,396 unique users.
TBL: Tweets from users who are certainly Hi-En bilinguals, which are approximately 55% (240,000) of the tweets in TAll.",4 Datasets,[0],[0]
"We define a user to be a Hi-En bilingual if there is at least one mr tweet from the user, or if the user has tweeted at least once in Hindi (hd or hr) and once in English (er).",4 Datasets,[0],[0]
"Tspo,Tmov,Tpol,Teve: Topic-wise corpora for sports, movies, politics and events (Table 1).",4 Datasets,[0],[0]
TCS: Tweets with inter-sentential CS.,4 Datasets,[0],[0]
We define these as tweets containing at least one sequence of 5 contiguous Hindi words and one sequence of 5 contiguous English words.,4 Datasets,[0],[0]
"The corpus has 3,357 tweets.
SAC: 1000 monolingual tweets (er, hr, hd) and 260 mixed (mr) tweets manually annotated with sentiment and opinion labels.",4 Datasets,[0],[0]
"These were annotated by two linguists, both fluent Hi-En speakers.",4 Datasets,[0],[0]
"The annotators first checked whether the tweet is opinionated or⊗ and then identified polarity of the opinionated tweets (+, − or 0).",4 Datasets,[0],[0]
"Thus, the tweets are classified into the four classes in the set 3.",4 Datasets,[0],[0]
"If a tweet contains both opinion and ⊗, each fragment was individually annotated.",4 Datasets,[0],[0]
The inter-annotator agreement is 77.5% (κ = 0.59) for opinion annotation and 68.4% (κ = 0.64) over all four classes.,4 Datasets,[0],[0]
A third linguist independently corrected the disagreements.,4 Datasets,[0],[0]
"LLCTest: 141 er, 137 hr, and 241 mr tweets annotated by a Hi-En bilingual form the test set for the Language Labeling system (Sec. 5.1).",4 Datasets,[0],[0]
SAC and LLCTest can be downloaded and used for research purposes3.,4 Datasets,[0],[0]
"Note that apart from SAC and LLCTest, all corpora are subsets of TAll.",4 Datasets,[0],[0]
"For generalizability of our observations, it is important to ensure that the tweets in TAll come from a large number of users and the datasets do not over-represent a small set of users.",4 Datasets,[0],[0]
"In Figure 1, we plot the minimum fraction of users required (x-axis) to cover a certain percentage of the tweets in TAll (y-axis).",4 Datasets,[0],[0]
"Tweets from at least 10%, i.e., 12.5K users are needed to cover 50% of the corpus.",4 Datasets,[0],[0]
"As expected, we do observe a powerlaw-like distribution, where a few users contribute a large number of tweets, and a large number of users contribute a few tweets each.",4 Datasets,[0],[0]
"We believe that 12.5K users is sufficient to ensure an unbiased study.
",4 Datasets,[0],[0]
"Further, we classify the users into three specific groups (i) news channels, (ii) general users (having
3http://www.cnergres.iitkgp.ac.in/codemixing
≤ 10,000 followers), (iii) popular users or celebrities (having > 10,000 followers).",4 Datasets,[0],[0]
"Interestingly, for both TAll, and TBL corpora, we observe that around 98% of all users are general, and 96% of all tweets come from such users.",4 Datasets,[0],[0]
"Hence, most observations from these corpora are expected to be representative of the average online linguistic behavior of a Hi-En bilingual.",4 Datasets,[0],[0]
Fig. 2 diagrammatically summarizes our experimental method.,5 Method,[0],[0]
We identify the language used in each tweet before detecting opinion and sentiment.,5 Method,[0],[0]
"Tweets in Devanagari script are accurately detected by the Twitter API as Hindi tweets – we label these as hd, though a small fraction of them could also be md.",5.1 Language Labeling,[0],[0]
"To classify Roman script tweets as er, hr or mr, we use the system that performed best in the FIRE 2013 shared task for word-level language detection of Hi-En text (Gella et al., 2013).",5.1 Language Labeling,[0],[0]
This system uses character n-gram features with a Maximum Entropy model for labeling each input word with a language label (either English or Hindi).,5.1 Language Labeling,[0],[0]
"We design minor modifications to the system to improve its performance on Twitter data, which are omitted here due to paucity of space.",5.1 Language Labeling,[0],[0]
"Most of the existing research in opinion detection (Qadir, 2009; Brun, 2012; Rajkumar et al.,
2014) and sentiment analysis (Mohammad, 2012; Mohammad et al., 2013; Mittal et al., 2013; Rosenthal et al., 2015) focus on monolingual tweets and sentences.",5.2 Opinion and Sentiment Detection,[0],[0]
"Recently, there has been a couple of studies on sentiment detection of code-switched tweets (Vilares et al., 2015; Sharma et al., 2015b).",5.2 Opinion and Sentiment Detection,[0],[0]
"Sharma et al. (2015b) use Hindi SentiWordNet and normalization techniques to detect sentiment in HiEn CS tweets.
",5.2 Opinion and Sentiment Detection,[0],[0]
We propose a two-step classification model.,5.2 Opinion and Sentiment Detection,[0],[0]
We first identify whether a tweet is opinionated or nonopinionated (⊗).,5.2 Opinion and Sentiment Detection,[0],[0]
"If the tweet is opinionated, we further classify it according to its sentiment (+,− or 0).",5.2 Opinion and Sentiment Detection,[0],[0]
Fig. 2 shows the architecture of the proposed model.,5.2 Opinion and Sentiment Detection,[0],[0]
"Two-step classification was empirically found to be better than a single four-class classifier.
",5.2 Opinion and Sentiment Detection,[0],[0]
"We develop individual classifiers for each language class (er, hr, hd, mr) using an SVM with RBF kernel from Scikit-learn (Pedregosa et al.,
2011).",5.2 Opinion and Sentiment Detection,[0],[0]
We use the SAC dataset (Sec. 4) as training data and features as described in Sec. 5.3.,5.2 Opinion and Sentiment Detection,[0],[0]
"For opinion classification (opinion or ⊗), we propose a set of event-independent lexical features and Twitter-specific features.",5.3 Classifier Features,[0],[0]
(i) Subjective words: Expected to be present in opinion tweets.,5.3 Classifier Features,[0],[0]
We use lexicons from Volkova et al. (2013) for er and Bakliwal et al. (2012) for hd.,5.3 Classifier Features,[0],[0]
"We Romanize the hd lexicon for the hr classifiers (ii) Elongated words: Words with one character repeated more than two times, e.g. sooo, naaahhhhi (iii) Exclamations:",5.3 Classifier Features,[0],[0]
Presence of contiguous exclamation marks (iv) Emoticons4 (v) Question marks: Queries are generally nonopinionated.,5.3 Classifier Features,[0],[0]
"(vi) Wh-words: These are used to form questions (vii) Modal verbs: e.g. should, could, would, cud, shud (viii) Excess hashtags:",5.3 Classifier Features,[0],[0]
"Presence of more than two hashtags (ix) Intensifiers: Generally used to emphasize sentiment, e.g., we shouldn’t get too comfortable (x) Swear words5: Prevalent in opinionated tweets, e.g. that was a f ing no ball!!!!",5.3 Classifier Features,[0],[0]
#indvssa (xi) Hashtags:,5.3 Classifier Features,[0],[0]
"Hashtags might convey user sentiment (Barbosa et al., 2012).",5.3 Classifier Features,[0],[0]
We manually identify hashtags in our corpus that represent explicit opinion.,5.3 Classifier Features,[0],[0]
(xii) Domain lexicon:,5.3 Classifier Features,[0],[0]
"For hr, & hd category tweets, we construct sentiment lexicons from 1000 manually annotated tweets.",5.3 Classifier Features,[0],[0]
"Each word or phrase in this lexicon represents +, or −, or 0 sentiment.",5.3 Classifier Features,[0],[0]
(xiii) Twitter user mentions (xiv) Pronouns:,5.3 Classifier Features,[0],[0]
"Opinion is often in first person using pronouns like I and we.
",5.3 Classifier Features,[0],[0]
"For sentiment classification, we use emoticons, swear words, exclamation marks and elongated words as described above.",5.3 Classifier Features,[0],[0]
"We also use subjective words from various lexicons (Mohammad and Turney, 2013; Volkova et al., 2013; Bakliwal et al., 2012; Sharma et al., 2015a).",5.3 Classifier Features,[0],[0]
"Additionally, we use – (i) Sentiment words: From Hashtag Sentiment and Sentiment140 lexicons (Mohammad et al., 2013).",5.3 Classifier Features,[0],[0]
We also manually annotate hashtags from our dataset that represent sentiment.,5.3 Classifier Features,[0],[0]
(ii) Negation:,5.3 Classifier Features,[0],[0]
"A negated context is tweet segment that begins with a negation word and ends with a punctuation mark (Pang et al., 2002).",5.3 Classifier Features,[0],[0]
"The list of negation words are
4The list of emoticons was extracted from Wikipedia 5Swear word lexicons from noswearing.com, youswear.com
taken from Christopher Potts’ sentiment tutorial6.",5.3 Classifier Features,[0],[0]
"Themr opinion classifier uses the output from the er and hr classifiers as features (Fig. 2), along with an additional feature that represents whether the majority of the words in the tweet are Hindi or not.",5.3 Classifier Features,[0],[0]
A similar strategy is used for mr sentiment detection.,5.3 Classifier Features,[0],[0]
"We evaluated the language labeling system on the LLCTest corpus, on which the precision (recall) values were 0.93(0.91), 0.90(0.85) and 0.88(0.92) for er, hr and mr classes respectively.",5.4 Evaluation,[0],[0]
"The tweetlevel classification accuracy was 89.8%.
",5.4 Evaluation,[0],[0]
The opinion and sentiment classifiers were evaluated using 10-fold cross validation on the SAC dataset.,5.4 Evaluation,[0],[0]
Table 2 details the class-wise accuracy.,5.4 Evaluation,[0],[0]
"For comparison, we also reimplemented the dictionary and dependency-based method by Qadir (2009).",5.4 Evaluation,[0],[0]
"The accuracy of the opinion classifier on the er tweets was found to be 65.7%, 7% lower than our system.",5.4 Evaluation,[0],[0]
We also compared our mr sentiment classifier with that of Sharma et al. (2015b).,5.4 Evaluation,[0],[0]
"As their method performs two class sentiment detection (+ and −), we select such tweets from SAC.",5.4 Evaluation,[0],[0]
"Their system achieves an accuracy of 68.2%, which is 4% lower than the accuracy of our system.
",5.4 Evaluation,[0],[0]
"An analysis of the errors showed more false negatives (i.e., opinions labeled⊗) than false positives in opinion classification.",5.4 Evaluation,[0],[0]
"Sentiment misclassification is uniformly distributed.
",5.4 Evaluation,[0],[0]
Table 3 reports the accuracy of the opinion classifier for feature ablation experiments.,5.4 Evaluation,[0],[0]
"For all three language-script pairs, lexicon and non-word (emoticons, elongated words, hashtags, exclamation) features are the most effective, though all features have some positive contribution towards the final accuracy of opinion detection.",5.4 Evaluation,[0],[0]
"For hr and hd tweets, domain knowledge is significant, as shown by the 4% accuracy drop with removing the domain lexicon.
",5.4 Evaluation,[0],[0]
6http://sentiment.christopherpotts.net/lingstruc.html,5.4 Evaluation,[0],[0]
"In this section, we report our experiments on 430,000 unique tweets (TAll), and its various subsets as defined in Sec 4.",6 Experiments and Observations,[0],[0]
"First, we run the language detection system on the corpora.",6 Experiments and Observations,[0],[0]
Table 4 shows the language-wise distribution.,6 Experiments and Observations,[0],[0]
"We see that language preference varies by topic, which is not surprising.",6 Experiments and Observations,[0],[0]
"Due to paucity of space, the correlation between language usage and topic will not be discussed at length here, but we will highlight cases where the differences are striking.
",6 Experiments and Observations,[0],[0]
We apply the language-specific opinion and sentiment classifiers to tweets detected as the corresponding language class.,6 Experiments and Observations,[0],[0]
"In the following subsections, we empirically investigate the hypotheses.",6 Experiments and Observations,[0],[0]
"Table 5 shows pr(⊗|λσ;T ), pr(−|λσ;T ) and pr(−|λσ;T )/pr(+|λσ;T ) for TAll, TBL and two randomly selected topics – Movie and Politics.",6.1 Status of Hypotheses I and II,[0],[0]
"The statistics are fairly consistent over the corpora, with slight differences but similar trends in Tmov.
",6.1 Status of Hypotheses I and II,[0],[0]
"We need the first statistic in order to investigate Hypothesis I (Eqs. 6 and 7), and the two latter ones for verifying Hypothesis II (Eqs. 8 and 9).
",6.1 Status of Hypotheses I and II,[0],[0]
Contrary to Eqs.,6.1 Status of Hypotheses I and II,[0],[0]
"6 and 7, for all corpora except Tmov, we observe the following trend:
pr(⊗|hd;T ) > pr(⊗|hr;T ) ≥ pr(⊗|er;T )
",6.1 Status of Hypotheses I and II,[0],[0]
"In other words, hd is more commonly preferred for expressing non-opinions than hr and er.",6.1 Status of Hypotheses I and II,[0],[0]
"Hypothesis I is clearly untrue for these corpora, though due to the small differences between hr and er, we cannot claim that English is the preferred language for expressing opinions.",6.1 Status of Hypotheses I and II,[0],[0]
"A closer scrutiny of the corpora revealed that hd tweets mostly come from official sources (news channels, political parties, production houses) and celebrities, which are mostly factual.",6.1 Status of Hypotheses I and II,[0],[0]
hr tweets are from general users and show similar trends as English.,6.1 Status of Hypotheses I and II,[0],[0]
"Thus, in general, there seems to be no preferred language for expressing opinion by the Hi-En bilinguals on Twitter.
",6.1 Status of Hypotheses I and II,[0],[0]
"In the context of Hypothesis II, we see the general pattern (with some topic specific variations):
pr(−|hr;T ) >",6.1 Status of Hypotheses I and II,[0],[0]
pr(−|hd;T ),6.1 Status of Hypotheses I and II,[0],[0]
≥,6.1 Status of Hypotheses I and II,[0],[0]
"pr(−|er;T )
",6.1 Status of Hypotheses I and II,[0],[0]
"The pattern emerges even more strongly, when we look at pr(−|λσ;T )/pr(+|λσ;T ).",6.1 Status of Hypotheses I and II,[0],[0]
"The odds of expressing a negative opinion over positive opinion in Hindi is between 1.5 and 6 (Tmov exhibits a slightly different pattern but similar preference, Tpol shows a stronger preference towards Hindi for negative sentiment), whereas the same for English is between 0.1 and 0.6.",6.1 Status of Hypotheses I and II,[0],[0]
"In other words, English is more preferred
for expressing positive opinion, and Hindi for negative opinion.",6.1 Status of Hypotheses I and II,[0],[0]
These observations provide very strong evidence in favor of Hypothesis II.,6.1 Status of Hypotheses I and II,[0],[0]
"Recall that Hypothesis Ia and Hypothesis IIa are essentially same as Hypotheses I and II, but applied on mhr and mer fragments from the TCS corpus.
Table 6 reports the three statistics necessary for testing these hypotheses.",6.2 Status of Hypotheses Ia and IIa,[0],[0]
"pr(⊗|mer;TCS) is slightly greater than pr(⊗|mhr;TCS), which is what we would expect if Hypothesis Ia was true.",6.2 Status of Hypotheses Ia and IIa,[0],[0]
"However, since the difference is small, we view it as a trend rather than a proof of Hypothesis Ia.
The statistics clearly show that Hypothesis IIa holds true for TCS .",6.2 Status of Hypotheses Ia and IIa,[0],[0]
The fraction of negative sentiment in mhr is over 1.5 times higher than that of mer.,6.2 Status of Hypotheses Ia and IIa,[0],[0]
"Further, the odds of expressing a negative sentiment in Hindi over positive sentiment in Hindi in a code-switched tweet is 6.5 times higher than the same odds for English.",6.2 Status of Hypotheses Ia and IIa,[0],[0]
"Recall that using Eq. 13 (Sec. 3), we can estimate the preference, if any, for switching to a particular language while changing the sentiment.",6.3 Switching Functions,[0],[0]
"In particular, research in socio-linguistics has shown that users often switch between languages when they switch from non-opinion (⊗) to opinion ({+,−, 0}).",6.3 Switching Functions,[0],[0]
"This is called the Narrative-Evaluative function of CS (Sanchez, 1983).",6.3 Switching Functions,[0],[0]
This function appears in 46.1% of the tweets in TCS .,6.3 Switching Functions,[0],[0]
"We find that
pr(h{+,−, 0} ↔ e⊗;TCS) pr(h⊗",6.3 Switching Functions,[0],[0]
"↔ e{+,−, 0};TCS) = 0.86
which indicates that there is no preference for switching to Hindi (or English) while switching between opinion and non-opinion.",6.3 Switching Functions,[0],[0]
"This is also confirmed above in the context of hypotheses I and Ia. While switching between opinion and non-opinion in a tweet, users do switch language.",6.3 Switching Functions,[0],[0]
"However, we
observe no particular preference for the languages chosen for each part.
",6.3 Switching Functions,[0],[0]
"We also report two other pragmatic functions:
pr(h− ↔",6.3 Switching Functions,[0],[0]
"e{+, 0,⊗};TCS)",6.3 Switching Functions,[0],[0]
"pr(h{+, 0,⊗} ↔ e−;TCS) = 1.98
pr(h− ↔ e+;TCS) pr(h+↔ e−;TCS) = 10.27
The latter function is called polarity switch.",6.3 Switching Functions,[0],[0]
"The extremely high value for these ratios is an evidence for a strong preference towards switching language from English to Hindi while switching to negative sentiment (and switching to English when sentiment changes from negative to positive).
",6.3 Switching Functions,[0],[0]
"We also observe cases where there is a language switch, but no sentiment switch and hence, we cannot evaluate language preference using Eq. 13 (because = ′).",6.3 Switching Functions,[0],[0]
"In TCS , 15.3% of the tweets show Positive Reinforcement, where both fragments are of positive sentiment.",6.3 Switching Functions,[0],[0]
Negative Reinforcement is defined similarly and is seen in 8.7% of the tweets.,6.3 Switching Functions,[0],[0]
Other tweets in TCS likely have pragmatic functions that cannot be identified based on sentiment.,6.3 Switching Functions,[0],[0]
"Since there is evidence that the native language (Hindi, in this case) is preferred for swearing (De-
waele, 2004), we computed the fraction of tweets that contain swear words in each language class.",6.4 Language Preference for Swearing,[0],[0]
Fig. 3a shows the distribution across topics.,6.4 Language Preference for Swearing,[0],[0]
The languages hr and mr have a much higher fraction of abusive tweets than er and hd.,6.4 Language Preference for Swearing,[0],[0]
Fig.,6.4 Language Preference for Swearing,[0],[0]
3b shows the distribution of abusive mhr and mer fragments for tweets in TCS .,6.4 Language Preference for Swearing,[0],[0]
"Interestingly, over 90% of the swear words occur in mhr.",6.4 Language Preference for Swearing,[0],[0]
Both distributions strongly suggest a preference for swearing in Hindi.,6.4 Language Preference for Swearing,[0],[0]
"In this paper, through a large scale empirical study of nearly half a million tweets, we tried to answer a fundamental question regarding multilingualism, namely, is there a preferred language for expression of sentiment.",7 Conclusion,[0],[0]
We also looked at some of the pragmatic functions of code-switching.,7 Conclusion,[0],[0]
"Our results indicate a strong preference for using Hindi, L1 for the users from whom these tweets come, for expressing negative sentiment, including swearing.",7 Conclusion,[0],[0]
"However, we do not observe any particular preference towards Hindi for expressing opinions.
",7 Conclusion,[0],[0]
"Previous linguistic studies (Dewaele, 2004; Dewaele, 2010) have already shown a preference for L1 for expressing emotion and swearing.",7 Conclusion,[0],[0]
"However, we observe that for expressing positive emotion, English (which would be L2) is the language of preference.",7 Conclusion,[0],[0]
This raises some intriguing socio-linguistic questions.,7 Conclusion,[0],[0]
"Is it the case that English being the language of aspiration in India, it is preferred for positive expression?",7 Conclusion,[0],[0]
"Or is it because Hindi is specifically preferred for swearing and therefore, is the language of preference for negative emotion?",7 Conclusion,[0],[0]
"How do such preferences vary across topics, users and other multilingual communities?",7 Conclusion,[0],[0]
How representative of the society is this kind of social media study?,7 Conclusion,[0],[0]
"We plan to explore some of these questions in the future.
",7 Conclusion,[0],[0]
"Our study also indicates that inferences drawn on multilingual societies by analyzing data in just one language (usually English), which has been the norm so far, are likely to be incorrect.",7 Conclusion,[0],[0]
Koustav Rudra was supported by a fellowship from Tata Consultancy Services.,Acknowledgement,[0],[0]
"Linguistic research on multilingual societies has indicated that there is usually a preferred language for expression of emotion and sentiment (Dewaele, 2010).",abstractText,[0],[0]
Paucity of data has limited such studies to participant interviews and speech transcriptions from small groups of speakers.,abstractText,[0],[0]
"In this paper, we report a study on 430,000 unique tweets from Indian users, specifically Hindi-English bilinguals, to understand the language of preference, if any, for expressing opinion and sentiment.",abstractText,[0],[0]
"To this end, we develop classifiers for opinion detection in these languages, and further classifying opinionated tweets into positive, negative and neutral sentiments.",abstractText,[0],[0]
"Our study indicates that Hindi (i.e., the native language) is preferred over English for expression of negative opinion and swearing.",abstractText,[0],[0]
"As an aside, we explore some common pragmatic functions of codeswitching through sentiment detection.",abstractText,[0],[0]
Understanding Language Preference for Expression of Opinion and Sentiment: What do Hindi-English Speakers do on Twitter?,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1108–1118, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"Negation is a complex phenomenon present in all human languages, allowing for the uniquely human capacities of denial, contradiction, misrepresentation, lying, and irony (Horn and Wansing, 2015).",1 Introduction,[0],[0]
"Despite negation always being marked—in the absence of a negation cue, statements are positive— acquiring and understanding sentences that contain negation is more challenging than those that do not.",1 Introduction,[0],[0]
"Children acquire negation after learning to communicate (Nordmeyer and Frank, 2013), and adults take longer to process negated statements than positive ones (Clark and Chase, 1972).
",1 Introduction,[0],[0]
"In any given language, humans communicate in positive terms most of the time, and use negation to express something unusual or an exception (Horn, 1989).",1 Introduction,[0],[0]
"Albeit most sentences are affirmative, negation is ubiquitous (Morante and Sporleder, 2012):",1 Introduction,[0],[0]
"In scientific papers, 13.76% of statements contain a negation (Szarvas et al., 2008); in product reviews, 19% (Councill et al., 2010); and in Conan Doyle stories, 22.23% (Morante and Daelemans, 2012).",1 Introduction,[0],[0]
"In
OntoNotes (Hovy et al., 2006), 10.15% of statements contain a verb negated with not, n’t or never.
",1 Introduction,[0],[0]
"From a theoretical point of view, it is accepted that negation conveys positive meaning (Rooth, 1992; Huddleston and Pullum, 2002).",1 Introduction,[0],[0]
"For example, when reading (1) John didn’t order the right parts, humans intuitively understand that (1a) John ordered something, or more specifically, (1b) John ordered the wrong parts.",1 Introduction,[0],[0]
"Interpretation (1a) can be obtained after determining that n’t does not negate verb order, but its THEME, i.e., the right parts.",1 Introduction,[0],[0]
"Interpretation (1b) can be obtained after determining that n’t is actually negating right, an adjective modifying parts.
",1 Introduction,[0],[0]
"Determining which words are intended to be negated—identifying the foci of negation, thereby revealing positive interpretations—is challenging.",1 Introduction,[0],[0]
"First, as exemplified in (1a, 1b), there is a granularity continuum yielding interpretations that entail each other, e.g., (1b) entails (1a).",1 Introduction,[0],[0]
"Second, a single negation often yields several positive interpretations, e.g., from (2) John doesn’t eat meat, we can extract that (2a) John eats something other than meat and (2b)",1 Introduction,[0],[0]
"Some people eat meat, but not John.
",1 Introduction,[0],[0]
This paper presents a methodology to extract positive interpretations from verbal negation.,1 Introduction,[0],[0]
"The main contributions are: (1) deterministic procedure to generate potential interpretations by manipulating syntactic dependencies; (2) analysis showing that dependencies yield finer-grained interpretations and better results than previous work using semantic roles; (3) a corpus of negations and their positive interpretations;1 and (4) experimental results with gold-standard and predicted linguistic information.
",1 Introduction,[0],[0]
"1Available at http://www.cse.unt.edu/˜blanco/
1108",1 Introduction,[0],[0]
"Negation is well-understood in grammars, which detail the valid ways to form a negation (Quirk et al., 2000; van der Wouden, 1997).","2 Terminology, Scope and Focus",[0],[0]
"Negation can be expressed by verbs (e.g., avoid running), nouns (e.g., the absence of evidence), adjectives (e.g., it is pointless), adverbs (e.g., I never tried Persian food before), prepositions (e.g., you can exchange it without a problem), determiners (e.g., the new law has no direct implications), pronouns (e.g., nobody will keep election promises), and others.","2 Terminology, Scope and Focus",[0],[0]
"In this paper, we focus on verbal negation, i.e., when the negation mark—usually an adverb such as never and not—is grammatically associated with a verb.","2 Terminology, Scope and Focus",[0],[0]
Positive Interpretations.,"2 Terminology, Scope and Focus",[0],[0]
"In philosophy and linguistics, it is generally accepted that negation conveys positive meaning (Horn, 1989).","2 Terminology, Scope and Focus",[0],[0]
"This positive meaning ranges from implicatures, i.e., what is suggested in an utterance even though neither expressed nor strictly implied (Blackburn, 2008), to entailments.","2 Terminology, Scope and Focus",[0],[0]
"Other terms used in the literature include implied meanings (Mitkov, 2005), implied alternatives (Rooth, 1985) and semantically similars (Agirre et al., 2013).","2 Terminology, Scope and Focus",[0],[0]
"We do not strictly fit into any of this terminology, we reveal positive interpretations as intuitively done by humans when reading text.","2 Terminology, Scope and Focus",[0],[0]
"From a theoretical perspective, it is accepted that negation has scope and focus, and that the focus— not just the scope—yields positive interpretations (Horn, 1989; Rooth, 1992; Taglicht, 1984).",2.1 Scope and Focus,[0],[0]
"Scope is “the part of the meaning that is negated” and focus “the part of the scope that is most prominently or explicitly negated” (Huddleston and Pullum, 2002).
",2.1 Scope and Focus,[0],[0]
Consider the following statement in the context of the recent refugee crisis: (2) Mr. Haile was not looking for heaven in Europe.,2.1 Scope and Focus,[0],[0]
"By definition, scope refers to “all elements whose individual falsity would make the negated statement strictly true”, and focus is “the element of the scope that is intended to be interpreted as false to make the overall negative true” (Huddleston and Pullum, 2002).",2.1 Scope and Focus,[0],[0]
"The falsity of any of the truth conditions below makes statement (2) true, thus the scope of the negation is (2a–2d): 2a.",2.1 Scope and Focus,[0],[0]
"Somebody was looking for something some-
where.",2.1 Scope and Focus,[0],[0]
"[verb looking]
2b.",2.1 Scope and Focus,[0],[0]
Mr. Haile was looking for something somewhere.,2.1 Scope and Focus,[0],[0]
"[AGENT of looking, Mr. Haile] 2c.",2.1 Scope and Focus,[0],[0]
Somebody was looking for heaven somewhere.,2.1 Scope and Focus,[0],[0]
"[THEME of looking, heaven] 2d.",2.1 Scope and Focus,[0],[0]
Somebody was looking for something in Europe.,2.1 Scope and Focus,[0],[0]
"[LOCATION of looking, in Europe]
Determining the focus is almost always more challenging than the scope.",2.1 Scope and Focus,[0],[0]
"The challenge relies on determining which of the truth conditions (2a–2d) is intended to be interpreted as false to make the negated statement true: all of them qualify, but some are more likely.",2.1 Scope and Focus,[0],[0]
"A natural reading of statement (2) suggests that Mr. Haile was looking for something (a regular life, a job, etc.) in Europe, but not heaven.",2.1 Scope and Focus,[0],[0]
"Determining that the focus is heaven, i.e., that everything in statement (2) is positive except the THEME of looking, is the key to reveal the intended positive interpretation.",2.1 Scope and Focus,[0],[0]
"Note that scope on its own does not identify positive interpretations, and other foci yield unlikely positive interpretations, e.g., Mr. Haile was looking for heaven somewhere, but not in Europe.
",2.1 Scope and Focus,[0],[0]
"It is worth noting that while scope is defined from a logical standpoint, in most negations there are several possible foci and corresponding positive interpretations.",2.1 Scope and Focus,[0],[0]
"For example, given (3) Most jobs now don’t last for decades, the following are valid positive interpretations: (3a) Few jobs now last for decades, (3b) Most jobs in the past lasted for decades, and (3c) Most jobs now last for a few years.",2.1 Scope and Focus,[0],[0]
Granularity of Focus.,2.1 Scope and Focus,[0],[0]
The definition of focus does not provide guidelines about identifying the element of the scope that is the focus.,2.1 Scope and Focus,[0],[0]
"The larger the focus, the more generic the corresponding positive interpretation; and the smaller the focus, the more specific the corresponding positive interpretation.",2.1 Scope and Focus,[0],[0]
Let us consider statement (3) again.,2.1 Scope and Focus,[0],[0]
"A possible focus is Most jobs, yielding the positive interpretation Something now lasts for decades, but not most jobs.",2.1 Scope and Focus,[0],[0]
"Another possible focus is Most, yielding the interpretation Few (not most) jobs now last for decades.",2.1 Scope and Focus,[0],[0]
"We argue that the latter is preferable, as it yields a more specific interpretation and it entails the former: if some jobs last for decades, then something lasts for decades, but not the other way around.
",2.1 Scope and Focus,[0],[0]
"We use the term coarse-grained focus to refer to foci that include all tokens belonging to an argument of a verb (e.g., Most Jobs above), and fine-grained focus to refer to foci that do not (e.g., Most above).",2.1 Scope and Focus,[0],[0]
"Within computational linguistics, approaches to process negation are shallow, or target scope and focus detection.",3 Previous Work,[0],[0]
"Popular semantic representations such as semantic roles (Palmer et al., 2005; Baker et al., 1998) or AMR (Banarescu et al., 2013) do not reveal the positive interpretations we target in this paper.",3 Previous Work,[0],[0]
Shallow approaches are usually application-specific.,3 Previous Work,[0],[0]
"In sentiment and opinion analysis, negation has been reduced to marking as negated all words between a negation cue and the first punctuation mark (Pang et al., 2002), or within a five-word window of a negation cue (Hu and Liu, 2004).",3 Previous Work,[0],[0]
The examples throughout this paper show that these techniques are insufficient to reveal implicit positive interpretations.,3 Previous Work,[0],[0]
"Scope of negation detection has received a lot of attention, mostly using two corpora: BioScope in the medical domain (Szarvas et al., 2008) and CDSCO (Morante and Daelemans, 2012).",3.1 Scope Annotations and Detection,[0],[0]
BioScope annotates negation cues and linguistic scopes exclusively in biomedical texts.,3.1 Scope Annotations and Detection,[0],[0]
"CD-SCO annotates negation cues, scopes, and negated events or properties in selected Conan Doyle stories.
",3.1 Scope Annotations and Detection,[0],[0]
"There have been several supervised proposals to detect the scope of negation using BioScope and CD-SCO (Özgür and Radev, 2009; Øvrelid et al., 2010).",3.1 Scope Annotations and Detection,[0],[0]
"Automatic approaches are mature (AbuJbara and Radev, 2012): F-scores are 0.96 for negation cue detection, and 0.89 for negation cue and scope detection (Velldal et al., 2012; Li et al., 2010).",3.1 Scope Annotations and Detection,[0],[0]
"Fancellu et al. (2016) present the best results to date using CD-SCO, and analyze the main sources of errors.",3.1 Scope Annotations and Detection,[0],[0]
"Outside BioScope and CD-SCO, Reitan et al. (2015) present a negation scope detector for tweets, and show that it improves sentiment analysis.",3.1 Scope Annotations and Detection,[0],[0]
"As shown in Section 2, scope detection is insufficient to reveal positive interpretations from negation.",3.1 Scope Annotations and Detection,[0],[0]
"While focus of negation has been studied for decades in philosophy and linguistics (Section 2), corpora and automated tools are scarce.",3.2 Focus Annotation and Detection,[0],[0]
"Blanco and Moldovan (2011) annotate focus of negation in the 3,993 negations marked with ARGM-NEG semantic role in PropBank (Palmer et al., 2005).",3.2 Focus Annotation and Detection,[0],[0]
"Their an-
notations, PB-FOC, were used in the *SEM-2012 Shared Task (Morante and Blanco, 2012).",3.2 Focus Annotation and Detection,[0],[0]
Their guidelines require annotators to choose as focus the semantic role that “is most prominently negated” or the verb.,3.2 Focus Annotation and Detection,[0],[0]
"If several roles may be the focus, they prioritize “the one that yields the most meaningful implicit [positive] information”, but do not specify what most meaningful means.",3.2 Focus Annotation and Detection,[0],[0]
Their approach has 2 limitations.,3.2 Focus Annotation and Detection,[0],[0]
"First, because they select one focus per negation, they only extract one positive interpretation per negation.",3.2 Focus Annotation and Detection,[0],[0]
"Second, because they select as focus a semantic role, they only consider coarsegrained foci.",3.2 Focus Annotation and Detection,[0],[0]
Consider again statement (3) from Section 2.1.,3.2 Focus Annotation and Detection,[0],[0]
"By design, their approach is limited to extract a single interpretation even though interpretations (3a–3c) are valid.",3.2 Focus Annotation and Detection,[0],[0]
"Similarly, their approach is limited to select as focus Most jobs—all tokens belonging to a semantic role—although Most yields a “more meaningful” interpretation: Something now lasts for decades (generic, worse) vs. Few jobs now last for decades (specific, better).
",3.2 Focus Annotation and Detection,[0],[0]
Blanco and Sarabi (2016) present a complimentary approach to extract and score several positive interpretations from a single verbal negation.,3.2 Focus Annotation and Detection,[0],[0]
Their methodology is grounded on semantic roles and does not consider fine-grained foci.,3.2 Focus Annotation and Detection,[0],[0]
"In this paper, we improve upon their work: we extract both coarse- and fine-grained interpretations, and also extract several interpretations from one negation.
",3.2 Focus Annotation and Detection,[0],[0]
Anand and Martell (2012) reannotate PB-FOC and argue that positive interpretations arising from scalar implicatures and neg-raising predicates should be separated from those arising from focus detection.,3.2 Focus Annotation and Detection,[0],[0]
They argue that 27.4% of negations with a focus annotated in PB-FOC do not have one.,3.2 Focus Annotation and Detection,[0],[0]
"In this paper, we are not concerned about annotating foci per se, but about extracting positive interpretations from negation, as intuitively done by humans.
",3.2 Focus Annotation and Detection,[0],[0]
Automatic systems to detect the focus of negation yield modest results.,3.2 Focus Annotation and Detection,[0],[0]
Blanco and Moldovan (2011) obtain an accuracy of 65.5 using supervised learning and features derived from gold-standard linguistic information.,3.2 Focus Annotation and Detection,[0],[0]
"With predicted linguistic information, Rosenberg and Bergler (2012) report an Fmeasure of 58.4 using 4 linguistically sound heuristics, and Zou et al. (2014) an F-measure of 65.62 using contextual discourse information.",3.2 Focus Annotation and Detection,[0],[0]
"Blanco and Sarabi (2016) obtain Pearson correlation of 0.642
ranking coarse-grained interpretations.",3.2 Focus Annotation and Detection,[0],[0]
"Unlike the work presented here, none of these systems extract fine-grained interpretations from a single negation.",3.2 Focus Annotation and Detection,[0],[0]
Our goal is to create a corpus of negations and their positive interpretations.,4 Corpus Creation,[0],[0]
We put a strong emphasis on automation and simplicity.,4 Corpus Creation,[0],[0]
"First, we deterministically generate potential positive interpretations from verbal negations by manipulating syntactic dependencies (Section 4.1).",4 Corpus Creation,[0],[0]
"Second, we ask annotators to score potential positive interpretations (Section 4.2).",4 Corpus Creation,[0],[0]
Positive interpretations and their scores are later used to learn models to rank potential interpretations automatically (Section 6).,4 Corpus Creation,[0],[0]
Generating potential interpretations deterministically prior to scoring them proved very beneficial.,4 Corpus Creation,[0],[0]
"After pilot experiments, it became clear that asking annotators to propose positive interpretations complicates the annotation effort (lower agreements) as well as learning.
",4 Corpus Creation,[0],[0]
"We decided to work on top of OntoNotes (Hovy et al., 2006)2 instead of plain text or other corpora for several reasons.",4 Corpus Creation,[0],[0]
"First, OntoNotes includes gold linguistic annotations such as part-of-speech tags, parse trees and semantic roles.",4 Corpus Creation,[0],[0]
"Second, unlike BioScope, CD-SCO and PB-FOC (Section 3.2), OntoNotes includes sentences from several genres, e.g., newswire, broadcast news and conversations, magazines, the web.",4 Corpus Creation,[0],[0]
We transformed the parse trees in OntoNotes into syntactic dependencies using Stanford CoreNLP,4 Corpus Creation,[0],[0]
"(Manning et al., 2014).",4 Corpus Creation,[0],[0]
"OntoNotes contains 63,918 sentences.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
Annotating all positive interpretations from all negations is outside the scope of this paper.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"Instead, we target selected representative negations.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
Selecting Negations.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
We first select all verbal negations by retrieving all tokens whose syntactic head is a verb and dependency type neg.3,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"Then, we discard negations from sentences that contain two negations, conditionals, commas or questions.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"Finally, we dis-
2We use the CoNLL-2011 Shared Task distribution (Pradhan et al., 2011), http://conll.cemantix.org/2011/
3The Stanford manual describes and exemplifies all syntactic dependencies (de Marneffe and Manning, 2008).
card negations if the negated verb is to be or it does not have a subject (dependency nsubj or nsubjpass).",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
Converting Negated Statements into their positive counterparts.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"We apply 3 steps inspired after the grammatical rules to form negation detailed by Huddleston and Pullum (2002, Ch. 9):
1.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
Remove the negation mark by deleting the token with syntactic dependency neg.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
2.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"Remove auxiliaries, expand contractions, and fix third-person singular and past tense.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"For example (before: after), doesn’t go: goes, didn’t go: went, won’t go: will go.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"We loop through the tokens whose head is the negated verb with dependency aux, and use a list of irregular verbs and grammar rules to convert to thirdperson singular and past tense.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
3. Rewrite negatively-oriented polarity-sensitive items.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"For example (before: after), anyone: someone, any longer: still, yet: already.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
at all: somewhat.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"We use the correspondences between negatively-oriented and positively-oriented polarity-sensitive items by (Huddleston and Pullum, 2002, pp. 831).",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
Selecting Relevant tokens.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
Verbal negation often occurs in multi-clause sentences.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"In order to identify the relevant (syntactically negated) eventuality, we simplify the original statement by including only the negated verb and all tokens that are dependents of the verb, i.e., tokens reachable from the negated verb traversing dependencies.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"For example, from Individuals familiar with the Justice Department’s policy said that Justice officials hadn’t any knowledge of the IRS’s actions in the last week, after getting the positive counterpart and selecting relevant tokens, we obtain Justice officials had some knowledge of the IRS’s actions in the last week.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
Generating Interpretations.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"Given the simplified positive counterpart, generating all combinations of tokens as potential foci would result in 2t potential positive interpretations for t tokens.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"To avoid a brute-force approach that generates many nonsensical potential interpretations, we define a procedure grounded on syntactic dependencies.
",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
The main idea is to run a modified breadth-first traversal of the dependency tree to select subtrees that are potential foci.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"We start the traversal from the negated verb and stop it at depth 3, selecting as potential foci the subtrees rooted at all tokens except
those whose syntactic dependency is aux, auxpass or punct (auxiliary, passive auxiliary and punctuation).",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"Additionally, we discard potential foci that consist only of (1) the determiners the, a and an, or (2) a single token with part-of-speech tag TO, CC, UH, POS, XX, IN, WP or dependency relation prt.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
These rules were defined after manually observing several examples and concluding that the corresponding positive interpretation was useless.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"For example, from the negated statement And our credit standards haven’t changed one iota, we avoid generating the useless potential interpretation Our credit standards X changed one iota, but not have changed.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"(focus would be have, with dependency aux).",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"Similarly, from It is not supported by the text or history of the Constitution, we avoid generating potential interpretation It is supported by X text or history of the Constitution, but not by the text or history of the Constitution (focus would be the); and from You don’t want to get yourself too upset about these things, potential interpretation You want X get yourself too upset about these things, but not to get (focus would be to, with part-of-speech tag TO).
",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"Once potential foci are selected, we generate positive interpretations by rewriting each focus with “someone/some people/something/etc.”",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
and appending “but not text of focus” at the end.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"Additionally, if the first token of the focus is a preposition, we include it to improve readability, e.g., didn’t
leave [by noon]: left by sometime, but not by noon.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"Note that potential interpretations obtained from foci that are direct syntactic dependents of the negated verb are coarse-grained interpretations, and the rest are fine-grained interpretations.",4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
Table 1 exemplifies the procedure step by step.,4.1 Manipulating Syntactic Dependencies to Generate Potential Positive Interpretations,[0],[0]
"After generating potential positive interpretations automatically, we asked annotators to score them.",4.2 Scoring Potential Positive Interpretations,[0],[0]
"Annotators had access to the original negated sentence, the previous and next sentence as context, and one potential positive interpretation at a time.",4.2 Scoring Potential Positive Interpretations,[0],[0]
"The interface asked Given the three sentences [previous sentence, negated sentence and next sentence] above, do you think the statement [positive interpretation] below is true?",4.2 Scoring Potential Positive Interpretations,[0],[0]
"Annotators were forced to answer with a score from 0 to 5, where 0 means absolutely disagree and 5 means absolutely agree.",4.2 Scoring Potential Positive Interpretations,[0],[0]
We did not provide descriptions for intermediate scores or use categorical labels.,4.2 Scoring Potential Positive Interpretations,[0],[0]
This simple guidelines were sufficient to reliably score plausible positive interpretations automatically generated (Section 5).,4.2 Scoring Potential Positive Interpretations,[0],[0]
The procedure described in Section 4.1 generates 9729 potential positive interpretations (5865 coarsegrained and 3864 fine-grained) from 1671 verbal negations.,5 Corpus Analysis,[0],[0]
"Out of all these potential positive interpretations, we annotate 1700 (1008 coarse- and 692
fine-grained).",5 Corpus Analysis,[0],[0]
"Overall, the mean score is 3.20, and the standard deviation is 1.66.",5 Corpus Analysis,[0],[0]
"Table 2 shows basic statistics for potential foci, where dependency indicates the dependency from the potential focus to a token outside the potential focus.",5 Corpus Analysis,[0],[0]
"Most foci are nsubj, dobj and pobj, and the mean scores and standard deviation are similar for most dependencies.
",5 Corpus Analysis,[0],[0]
Annotation Quality.,5 Corpus Analysis,[0],[0]
"In order to ensure annotation quality, we calculated Pearson correlation.",5 Corpus Analysis,[0],[0]
"Kappa and other measures designed for categorical labels are ill-suited for our annotations, since not all disagreements between numeric scores are the same, e.g., 4 vs. 5 should be counted as higher agreement, than 1 vs. 5.",5 Corpus Analysis,[0],[0]
Overall Pearson correlation was 0.75.,5 Corpus Analysis,[0],[0]
"Table 3 presents 2 statements that contain verbal negation, the list of positive interpretations automatically generated and the annotated scores.
",5.1 Annotation Examples,[0],[0]
"Example (1) is a simple negated clause, yet we generate 7 potential positive interpretations and 3 of them receive high scores (4 or 5).",5.1 Annotation Examples,[0],[0]
"Given You’re not paying me for my overtime work and the previous statement, it is reasonable to believe that the author is in an employee-employer relationship, and the employer is not fair to the employee.",5.1 Annotation Examples,[0],[0]
"Interpretations 1.1, 1.4 and 1.6 are implicit positive interpretations intuitively understood by humans when reading the original negated statement.",5.1 Annotation Examples,[0],[0]
"Namely, Interpretation 1.1: You (the employer) are nickel-and-diming me for my overtime work (focus is paying), Interpretation 1.4:",5.1 Annotation Examples,[0],[0]
"You (the employer) are paying me for something (focus is my overtime work), and Interpretation 1.6: You (the employer) are paying me for my regular work (focus is overtime).",5.1 Annotation Examples,[0],[0]
"These interpretations show the benefits of fine-grained interpretations: Interpretation 1.6 is a refinement of Interpretation 1.4, and the former is more desirable than the latter as it reveals more specific positive knowledge.",5.1 Annotation Examples,[0],[0]
"The remaining interpretations are legible, but do not make sense given the negated statement, e.g., interpretation 1.2:",5.1 Annotation Examples,[0],[0]
"Somebody (but not the employer) pays me for my overtime (focus is You).
",5.1 Annotation Examples,[0],[0]
"Example (2) is also a simple negated clause, and 4 out of 5 interpretations receive high scores, capturing valid positive meaning.",5.1 Annotation Examples,[0],[0]
"Specifically, Interpreta-
tion 2.1: Those concerns are avoided in public (focus is expressed), Interpretation 2.2:",5.1 Annotation Examples,[0],[0]
"Something is expressed in public (focus is Those concerns), Interpretation 2.4: Some concerns (but not problematic or secret concerns) are expressed in public (focus is Those), and Interpretation 2.5: Those concerns are expressed in private (focus is in public).",5.1 Annotation Examples,[0],[0]
The procedure presented in Section 4.1 is not the first to generate potential positive interpretations from negation (Section 3.2).,5.2 Syntactic Dependencies vs. Semantic Roles,[0],[0]
"Our approach has 2 advantages with respect to those grounded on semantic roles (Blanco and Sarabi, 2016): (1) it generates both coarse- and fine-grained interpretations, and (2) learning to score interpretations is easier because state-of-the-art tools extract dependencies more reliably than semantic roles.
",5.2 Syntactic Dependencies vs. Semantic Roles,[0],[0]
"To support claim (1), we compare the interpretations generated with our procedure and previous work using semantic roles.",5.2 Syntactic Dependencies vs. Semantic Roles,[0],[0]
96.12% of interpretations generated using roles are also generated using syntactic dependencies.,5.2 Syntactic Dependencies vs. Semantic Roles,[0],[0]
"Also, using dependencies allow us to generate 67.9% of additional (finegrained) interpretations not obtainable with roles.
",5.2 Syntactic Dependencies vs. Semantic Roles,[0],[0]
"To support claim (2), we compare interpretations generated with gold and predicted linguistic information (roles or dependencies).",5.2 Syntactic Dependencies vs. Semantic Roles,[0],[0]
"The overlap with semantic roles is 70.1%, and with syntactic dependencies, 92.8%.",5.2 Syntactic Dependencies vs. Semantic Roles,[0],[0]
Syntactic dependencies are thus better in a realistic scenario because they allow us to automatically generate (and score) most interpretations.,5.2 Syntactic Dependencies vs. Semantic Roles,[0],[0]
"Positive Interpretations
We follow a standard supervised machine learning approach.",6 Supervised Learning to Score Potential,[0],[0]
"The 1,700 potential positive interpretations along with their scores become instances, and we divide them into training (80%) and test splits (20%) making sure that all interpretations generated from a sentence are assigned to either the training or test splits.",6 Supervised Learning to Score Potential,[0],[0]
"Note that splitting instances randomly would not be sound: training with some interpretations generated from a negation, and testing with the rest of interpretations generated from the same negation would be an unfair evaluation.
",6 Supervised Learning to Score Potential,[0],[0]
"We train a Support Vector Machine for regression with RBF kernel using scikit-learn (Pedregosa et al., 2011), which in turn uses LIBSVM (Chang and Lin, 2011).",6 Supervised Learning to Score Potential,[0],[0]
"SVM parameters (C and γ) were tuned using 10-fold cross-validation with the training set, and results are calculated using the test set.",6 Supervised Learning to Score Potential,[0],[0]
Table 4 presents the full feature set.,6.1 Feature Selection,[0],[0]
"Features are relatively simple and characterize the verbal negation from which a potential interpretation was generated, as well as the interpretation per se, i.e., the dependency subgraph chosen as potential focus.
",6.1 Feature Selection,[0],[0]
"Basic features account for the negation mark, the negation verb (word form and part-of-speech tag) and a binary flag indicating whether we are scoring a coarse- or fine-grained interpretation.
",6.1 Feature Selection,[0],[0]
"Path features are derived from the syntactic path
between the subgraph selected as focus and the verb.",6.1 Feature Selection,[0],[0]
"We include the actual path (concatenation of dependencies and up/down symbols), and the modified path using part-of-speech tags.",6.1 Feature Selection,[0],[0]
"Additionally, we also include the last dependency and part-of-speech tag, i.e., the ones closest to the verb in the path.
",6.1 Feature Selection,[0],[0]
Focus features characterize the dependency subgraph chosen as focus to generate the potential interpretation.,6.1 Feature Selection,[0],[0]
"Specifically, we include the number of tokens, word form and part-of-speech tags of the first and last tokens, and whether the focus occurs before or after the verb.",6.1 Feature Selection,[0],[0]
"We also include features derived form the head of the focus, which we define as the token whose syntactic head is outside the focus.",6.1 Feature Selection,[0],[0]
"We include the word form and part-of-speech of the focus head, as well as its the dependency.",6.1 Feature Selection,[0],[0]
We report results obtained with several combinations of features in Table 5.,7 Experiments and Results,[0],[0]
"We detail results obtained with features extracted from gold-standard and predicted linguistic annotations (part-of-speech tags and syntactic dependencies) as annotated in the gold and auto files from the CoNLL-2011 Shared Task release of OntoNotes (Pradhan et al., 2011).",7 Experiments and Results,[0],[0]
"All models are trained with gold-standard linguistic annotations, and tested with either gold-standard or predicted linguistic annotations.",7 Experiments and Results,[0],[0]
Testing with gold-standard POS tags and syntactic dependencies.,7 Experiments and Results,[0],[0]
"Training with the word form of the negation mark is virtually useless, it yields a Pearson correlation of −0.109.",7 Experiments and Results,[0],[0]
"Basic features (negation mark, verb and flag indicating coarseor fine-grained interpretation) are also ineffective to score potential interpretations (Pearson: 0.033).",7 Experiments and Results,[0],[0]
"Including features derived from the syntactic path yields higher correlation, 0.474, even though these features only capture the syntactic relationship be-
tween the focus from which the interpretation was generated and the verb.",7 Experiments and Results,[0],[0]
"Finally, adding focus features yields the best results (Pearson: 0.53, +11.8%).",7 Experiments and Results,[0],[0]
Testing with predicted POS tags and syntactic dependencies.,7 Experiments and Results,[0],[0]
"We selected 20% of positive interpretations in our corpus as test instances, totalling 379 interpretations (Section 6).",7 Experiments and Results,[0],[0]
"When executing the procedure to generate potential interpretations (Section 4.1) with predicted linguistic information, however, we are unable to generate all of them due to incorrect and missing syntactic dependencies.",7 Experiments and Results,[0],[0]
"Specifically, 352 of the 379 interpretations are generated (92.8%).",7 Experiments and Results,[0],[0]
"While we do not generate 7.2% of instances, this percentage is substantially lower than previous work grounded on semantic roles (Section 5.2).
",7 Experiments and Results,[0],[0]
Pearson correlations with predicted linguistic information are calculated using the 352 instances that were also generated with gold dependencies (and thus assigned a score during the manual annotations).,7 Experiments and Results,[0],[0]
Correlations are slightly higher and follow a similar trend than the correlations obtained with gold-standard linguistic information.,7 Experiments and Results,[0],[0]
"These results should be taken with a grain of salt: the test instances are not exactly the same, and the 352 test instances in this scenario are presumably easier to score than the remainder 27, as dependencies were predicted correctly.",7 Experiments and Results,[0],[0]
Humans intuitively extract positive meaning from negation when reading text.,8 Conclusions,[0],[0]
"This paper presents an automated procedure to generate potential positive interpretations from verbal negation, and score them according to their likelihood.",8 Conclusions,[0],[0]
"Our procedure is grounded on syntactic dependencies, allowing us to extract fine-grained interpretations beyond semantic roles (67.9% additional interpretations).",8 Conclusions,[0],[0]
"Additionally, because dependencies are extracted automatically more reliably than semantic roles, we generate 92.8% of all potential interpretations when using predicted linguistic information, as opposed to 70.1% with semantic roles.
",8 Conclusions,[0],[0]
"On average, we generate 6.4 potential interpretations per verbal negation (coarse-grained: 3.8, finegrained: 2.6).",8 Conclusions,[0],[0]
Manual annotations show that potential interpretations are deemed likely.,8 Conclusions,[0],[0]
"The mean
score is 3.20 (out of 5.0), thus we extract a substantial amount of positive meaning.
",8 Conclusions,[0],[0]
The work presented in this paper is not tied to any existing semantic representation.,8 Conclusions,[0],[0]
"While we rely heavily on syntactic dependencies, positive interpretations are generated in plain text, and they could be processed, along with the original negated statement, with any NLP pipeline.",8 Conclusions,[0],[0]
This paper presents a two-step procedure to extract positive meaning from verbal negation.,abstractText,[0],[0]
We first generate potential positive interpretations manipulating syntactic dependencies.,abstractText,[0],[0]
"Then, we score them according to their likelihood.",abstractText,[0],[0]
Manual annotations show that positive interpretations are ubiquitous and intuitive to humans.,abstractText,[0],[0]
"Experimental results show that dependencies are better suited than semantic roles for this task, and automation is possible.",abstractText,[0],[0]
Understanding Negation in Positive Terms Using Syntactic Dependencies,title,[0],[0]
"Satire is a writing technique for passing criticism using humor, irony or exaggeration.",1 Introduction,[0],[0]
"It is often used in contemporary politics to ridicule individual politicians, political parties or society as a whole.",1 Introduction,[0],[0]
"We restrict ourselves in this paper to such political satire articles, broadly defined as articles whose purpose is not to report real events, but rather to mock their subject matter.",1 Introduction,[0],[0]
"Satirical writing often builds on real facts and expectations, pushed to absurdity to express humorous insights about the situation.",1 Introduction,[0],[0]
"As a result, the difference between real and satirical articles can be subtle and often confusing to readers.",1 Introduction,[0],[0]
"With the recent rise of social media outlets, satirical articles have become increasingly popular and have famously fooled several leading news agencies1.",1 Introduction,[0],[0]
"These misinterpretations can often
1https://newrepublic.com/article/118013/ satire-news-websites-are-cashing-gullibleoutraged-readers
be attributed to careless reading, as there is a clear line between unusual events finding their way to the news and satire, which intentionally places key political figures in unlikely humorous scenarios.",1 Introduction,[0],[0]
"The two can be separated by carefully reading the articles, exposing the satirical nature of the events described in such articles.
",1 Introduction,[0],[0]
In this paper we follow this intuition.,1 Introduction,[0],[0]
"We look into the satire detection task (Burfoot and Baldwin, 2009), predicting if a given news article is real or satirical, and suggest that this prediction task should be defined over common-sense inferences, rather than looking at it as a lexical text classification task (Pang and Lee, 2008; Burfoot and Baldwin, 2009), which bases the decision on word-level features.
",1 Introduction,[0],[0]
"To further motivate this observation, consider the two excerpts in Figure 1.",1 Introduction,[0],[0]
"Both excerpts mention top-ranking politicians (the President and Vice President) in a drug-related context, and contain informal slang utterances, inappropriate for the subjects’
537
Transactions of the Association for Computational Linguistics, vol. 4, pp.",1 Introduction,[0],[0]
"537–549, 2016.",1 Introduction,[0],[0]
Action Editor: Timothy Baldwin.,1 Introduction,[0],[0]
"Submission batch: 1/2016; Revision batch: 5/2016; Published 12/2016.
",1 Introduction,[0],[0]
c©2016 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
position.",1 Introduction,[0],[0]
"The difference between the two examples is apparent when analyzing the situation described in the two articles: The first example (top), describes the Vice President speaking inappropriately in a work setting, clearly an unrealistic situation.",1 Introduction,[0],[0]
"In the second (bottom) the President is spoken to inappropriately, an unlikely, yet not unrealistic, situation.",1 Introduction,[0],[0]
"From the perspective of our prediction task, it is advisable to base the prediction on a structured representation capturing the events and their participants, described in the text.
",1 Introduction,[0],[0]
The absurdity of the situation described in satirical articles is often not unique to the specific individuals appearing in the narrative.,1 Introduction,[0],[0]
"In our example, both politicians are interchangeable: placing the president in the situation described in the first excerpt would not make it less absurd.",1 Introduction,[0],[0]
"It is therefore desirable to make a common-sense inference about high-ranking politicians in this scenario.
",1 Introduction,[0],[0]
We follow these intuitions and suggest a novel approach for the satire prediction task.,1 Introduction,[0],[0]
"Our model, COMSENSE, makes predictions by making common-sense inferences over a simplified narrative representation.",1 Introduction,[0],[0]
"Similarly to prior work (Chambers and Jurafsky, 2008; Goyal et al., 2010; Wang and McAllester, 2015) we represent the narrative structure by capturing the main entities (and tracking their mentions throughout the text), their activities, and their utterances.",1 Introduction,[0],[0]
The result of this process is a Narrative Representation Graph (NRG).,1 Introduction,[0],[0]
"Figure 2 depicts examples of this representation for the excerpts in Figure 1.
",1 Introduction,[0],[0]
"Given an NRG, our model makes inferences quantifying how likely are each of the represented events and interactions to appear in a real, or satirical context.",1 Introduction,[0],[0]
"Annotating the NRG for such inferences is a challenging task, as the space of possible situations is extremely large.",1 Introduction,[0],[0]
"Instead, we frame the required inferences as a highly-structured latent variable model, trained discriminatively as part of the prediction task.",1 Introduction,[0],[0]
"Without explicit supervision, the model assigns categories to the NRG vertices (for example, by grouping politicians into a single category, or by grouping inappropriate slang utterances, regardless of specific word choice).",1 Introduction,[0],[0]
"These category assignments form the infrastructure for higher-level reasoning, as they allows the model to identify the commonalities between unrelated people, their ac-
tions and their words.",1 Introduction,[0],[0]
The model learns commonsense patterns leading to real or satirical decisions based on these categories.,1 Introduction,[0],[0]
"We express these patterns as parametrized rules (acting as global features in the prediction model), and base the prediction on their activation values.",1 Introduction,[0],[0]
"In our example, these rules can capture the combination of (EPolitician) ∧ (Qslang)→ Satire, where EPolitician and Qslang are latent variable assignments to entity and utterance categories respectively.
",1 Introduction,[0],[0]
"Our experiments look into two variants of satire prediction: using full articles, and the more challenging sub-task of predicting if a quote is real given its speaker.",1 Introduction,[0],[0]
We use two datasets collected 6 years apart.,1 Introduction,[0],[0]
"The first collected in 2009 (Burfoot and Baldwin, 2009) and an additional dataset collected recently.",1 Introduction,[0],[0]
"Since satirical articles tend to focus on current events, the two datasets describe different people and world events.",1 Introduction,[0],[0]
"To demonstrate the robustness of our COMSENSE approach we use the first dataset for training, and the second as out-of-domain test data.",1 Introduction,[0],[0]
"We compare COMSENSE to several competing systems including a state-of-the-art Convolutional Neural Network (Kim, 2014).",1 Introduction,[0],[0]
Our experiments show that COMSENSE outperforms all other models.,1 Introduction,[0],[0]
"Most interestingly, it does so with a larger margin when tested over the out-of-domain dataset, demonstrating that it is more resistant to overfitting compared to other models.",1 Introduction,[0],[0]
"The problem of building computational models dealing with humor, satire, irony and sarcasm has attracted considerable interest in the the Natural Language Processing (NLP) and Machine Learning (ML) communities in recent years (Wallace et al., 2014; Riloff et al., 2013; Wallace et al., 2015; Davidov et al., 2010; Karoui et al., 2015; Burfoot and Baldwin, 2009; Tepperman et al., 2006; GonzálezIbánez et al., 2011; Lukin and Walker, 2013; Filatova, 2012; Reyes et al., 2013).",2 Related Work,[0],[0]
"Most work has looked into ironic expressions in shorter texts, such as tweets and forum comments.",2 Related Work,[0],[0]
Most related to our work is Burfoot and Baldwin (2009) which focused on satirical articles.,2 Related Work,[0],[0]
In that work the authors suggest a text classification approach for satire detection.,2 Related Work,[0],[0]
"In addition to using bag-of-words features, the
authors also experiment with semantic validity features which pair entities mentioned in the article, thus capturing combinations unlikely to appear in a real context.",2 Related Work,[0],[0]
"This paper follows a similar intuition; however, it looks into structured representations of this information, and studies their advantages.
",2 Related Work,[0],[0]
"Our structured representation is related to several recent reading comprehension tasks (Richardson et al., 2013; Berant et al., 2014) and work on narrative representation such, as event-chains (Chambers and Jurafsky, 2009; Chambers and Jurafsky, 2008), plotunits (Goyal et al., 2010; Lehnert, 1981) and Story Intention Graphs (Elson, 2012).",2 Related Work,[0],[0]
"Unlike these works, narrative representation is not the focus of this work, but rather provides the basis for making inferences, and as result we choose a simpler (and more robust) representation, most closely resembling event chains (Chambers and Jurafsky, 2008)
",2 Related Work,[0],[0]
"Making common-sense inferences is one of the core missions of AI, applicable to a wide range of tasks.",2 Related Work,[0],[0]
"Early work (Reiter, 1980; McCarthy, 1980; Hobbs et al., 1988) focused on logical inference, and manual construction of such knowledge repositories (Lenat, 1995; Liu and Singh, 2004).",2 Related Work,[0],[0]
"More recently, several researchers have looked into automatic common-sense knowledge construction and expansion using common-sense inferences (Tandon et al., 2011; Bordes et al., 2011; Socher et al., 2013; Angeli and Manning, 2014).",2 Related Work,[0],[0]
"Several works have looked into combining NLP with commonsense (Gerber et al., 2010; Gordon et al., 2011; LoBue and Yates, 2011; Labutov and Lipson, 2012; Gordon et al., 2012).",2 Related Work,[0],[0]
"Most relevant to our work is a SemEval-2012 task (Gordon et al., 2012), looking into common-sense causality identification prediction.
",2 Related Work,[0],[0]
"In this work we focus on a different task, satire detection in news articles.",2 Related Work,[0],[0]
"We argue that this task is inherently a common-sense reasoning task, as identifying the satirical aspects in narrative text does not require any specialized training, but instead relies heavily on common expectations of normative behavior and deviation from it in satirical text.",2 Related Work,[0],[0]
"We design our model to capture these behavioral expectations using (weighted) rules, instead of relying on lexical features as is often the case in text categorization tasks.",2 Related Work,[0],[0]
"Other common-sense frameworks typically build on existing knowledge bases represent-
ing world knowledge; however, specifying in advance the behaviors commonly associated with people based on their background and situational context, to the extent it can provide good coverage for our task, requires considerable effort.",2 Related Work,[0],[0]
"Instead, we suggest to learn this information from data directly, and our model learns jointly to predict and represent the satirical elements of the article.",2 Related Work,[0],[0]
"Given a news article, our COMSENSE system first constructs a graph-based representation of the narrative, denoted Narrative Representation Graph (NRG), capturing its participants, their actions and utterances.",3 Modeling,[0],[0]
We describe this process in more detail in Section 3.1.,3 Modeling,[0],[0]
"Based on the NRG, our model makes a set of inferences, mapping the NRG vertices to general categories abstracting over the specific NRG.",3 Modeling,[0],[0]
These abstractions are formulated as latent variables in our model.,3 Modeling,[0],[0]
"The system makes a prediction by reasoning over the abstract NRG, by
decomposing it into paths, where each path captures a partial view of the abstract NRG.",3 Modeling,[0],[0]
Finally we associate the paths with the satire decision output.,3 Modeling,[0],[0]
"The COMSENSE model then solves a global inference problem, formulated as an Integer Linear Program (ILP) instance, looking for the most likely explanation of the satire prediction output, consistent with the extracted patterns.",3 Modeling,[0],[0]
"We explain this process in detail in Section 3.2.
",3 Modeling,[0],[0]
"NRG Abstraction as Common-Sense The main goal of the COMSENSE approach is to move away from purely lexical models, and instead base its decisions on common-sense inferences.",3 Modeling,[0],[0]
"We formulate these inferences as parameterized rules, mapping elements of the narrative, represented using the NRG, to a classification decision.",3 Modeling,[0],[0]
The rules’ ability to capture common-sense inferences hinges on two key elements.,3 Modeling,[0],[0]
"First, the abstraction of NRG nodes into typed narrative elements allows the model to find commonalities across entities and their actions.",3 Modeling,[0],[0]
This is done by associating each NRG node with a set of latent variables.,3 Modeling,[0],[0]
"Second, constructing the decision rules according to the structure of the NRG graph allows us to model the dependencies between narrative elements.",3 Modeling,[0],[0]
"This is done by following the paths in the abstract NRG, generating rules by combining the latent variables representing nodes on the path, and associating them with a satire decision variable.
",3 Modeling,[0],[0]
"Computational Considerations When setting up the learning system, there is a clear expressivity/efficiency tradeoff over these two elements.",3 Modeling,[0],[0]
Increasing the number of latent variables associated with each NRG node would allow the model to learn a more nuanced representation.,3 Modeling,[0],[0]
"Similarly, generating rules by following longer NRG paths would allow the model to condition its satire decision on multiple entities and events jointly.",3 Modeling,[0],[0]
The added expressivity does not come without price.,3 Modeling,[0],[0]
"Given the limited supervision afforded to the model when learning these rules, additional expressivity would result in a more difficult learning problem which could lead to overfitting.",3 Modeling,[0],[0]
"Our experiments demonstrate this tradeoff, and in Figure 4 we show the effect of increasing the number of latent variables on performance.",3 Modeling,[0],[0]
An additional concern with increasing the model’s expressivity is computational efficiency.,3 Modeling,[0],[0]
"Satire prediction is formulated as an ILP
inference process jointly assigning values to the latent variables and making the satire decision.",3 Modeling,[0],[0]
"Since ILP is exponential in the number of variables, increasing the number of latent variables would be computationally challenging.",3 Modeling,[0],[0]
In this paper we take a straight-forward approach to ensuring computational tractability by limiting the length of NRG paths considered by our model to a constant size c=2.,3 Modeling,[0],[0]
"Assuming that we have m latent categories associated with each node, each path would generate mc ILP variables (see Section 3.3 for details), hence the importance of limiting the length of the path.",3 Modeling,[0],[0]
"In the future we intend to study approximate inference methods that can help alleviate this computational difficultly, such as using LP-approximation (Martins et al., 2009).",3 Modeling,[0],[0]
"The Narrative Representation Graph (NRG) is a simple graph-based representation for narrative text, describing the connections between entities and their actions.",3.1 Narrative Representation Graph for News Articles,[0],[0]
"The key motivation behind NRG was to provide the structure necessary for making inferences, and as a result we chose a simple representation that does not take into account cross-event relationships, and nuanced differences between some of the event argument types.",3.1 Narrative Representation Graph for News Articles,[0],[0]
"While other representations (Mani, 2012; Goyal et al., 2010; Elson, 2012) capture more information, they are harder to construct and more prone to error.",3.1 Narrative Representation Graph for News Articles,[0],[0]
"We will look into adapting these models for our purpose in future work.
",3.1 Narrative Representation Graph for News Articles,[0],[0]
"Since satirical articles tend to focus on political figures, we design the NRG around animate entities that drive the events described in the text, their actions (represented as predicate nodes), their contextualizing information (location-modifiers, temporal modifiers, negations), and their utterances.",3.1 Narrative Representation Graph for News Articles,[0],[0]
We omitted from the graph other non-animate entity types.,3.1 Narrative Representation Graph for News Articles,[0],[0]
"In Figure 2 we show an example of this representation.
",3.1 Narrative Representation Graph for News Articles,[0],[0]
"Similar in spirit to previous work (Goyal et al., 2010; Chambers and Jurafsky, 2008), we represent the relations between the entities that appear in the story using a Semantic Role Labeling system (Punyakanok et al., 2008) and collapse all the entity mentions into a single entity using a Co-Reference resolution system (Manning et al., 2014).",3.1 Narrative Representation Graph for News Articles,[0],[0]
"We attribute
utterances to their speaker based on a previously published rule based system (O’Keefe et al., 2012).
",3.1 Narrative Representation Graph for News Articles,[0],[0]
"Formally, we construct a graph G = {V,E}, where V consists of three types of vertices: ANIMATE ENTITY (e.g., people), PREDICATE (e.g., actions) and ARGUMENT (e.g., utterances, locations).",3.1 Narrative Representation Graph for News Articles,[0],[0]
The edges E capture the relationships between vertices.,3.1 Narrative Representation Graph for News Articles,[0],[0]
The graph contains several different edges.,3.1 Narrative Representation Graph for News Articles,[0],[0]
"COREF edges collapse the mentions of the same entity into a single entity, ARGUMENT-TYPE edges connect ANIMATE ENTITY nodes to PREDICATE nodes2, and PREDICATE nodes to argument nodes (modifiers).",3.1 Narrative Representation Graph for News Articles,[0],[0]
Finally we add QUOTE edges connecting ANIMATE ENTITY nodes to utterances (ARGUMENT).,3.1 Narrative Representation Graph for News Articles,[0],[0]
Satire prediction is inherently a text classification problem.,3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
Such problems are often approached using a Bag-of-Words (BoW) model which ignores the document structure when making predictions.,3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"Instead, the NRG provides a structured representation for making the satire prediction.",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"We begin by showing how the NRG can be used directly and then discuss how to enhance it by mapping the graph into abstract categories.
",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"Directly Using NRG for Satire Prediction We suggest a simple approach for extracting features directly from the NRG, by decomposing it into graph paths, without mapping the graph into abstract categories.",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"This simple, word-based representation for prediction structured according to the NRG (denoted NARRLEX), generates features by using the words in the original document, corresponding to the graph decomposition.",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"For example, consider the path connecting “a man” to an utterance in Figure 2(b).",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"Simple features could associate the utterances words with that entity, rather than with the President.",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"The resulting NARRLEX model generates Bag-of-Words features based on words corresponding to NRG path vertices, conditioned on their connected entity vertex.
",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"Using Common-Sense for Satire Prediction Unlike the NARRLEX model, which relies on directly
2These edges are typed according to their semantic roles.
",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"observed information, our COMSENSE model performs inference over higher level patterns.",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"In this model the prediction is a global inference process, taking into account the relationships between NRG elements (and their abstraction into categories) and the final prediction.",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"This process is described in Figure 3.
",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"First, the model associates a high level category, that can be reused even when other, previously unseen, entities are discussed in the text.",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"We associate a set of Boolean variables with each NRG vertex, capturing higher level abstraction over this node.
",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"We define three types of categories corresponding to the three types of vertices, and denote them E,A,Q for Entity category, Action category and Quote category, respectively.",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
Each category variable can take k different values.,3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"As a convention we denote X = i as category assignment, where X ∈ {E,A,Q} is the category type, and i is its assignment.",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"Since these category assignments are not directly observed, they are treated as latent variables in our model.",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"This process is exemplified at the top right corner of Figure 3.
",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
Combinations of category assignments form patterns used for determining the prediction.,3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
These patterns can be viewed as parameterized rules.,3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
Each weighted rule associates a combination with an output variable (SATIRE or REAL).,3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
Examples of such rules are provided in the middle of the right corner of Figure 3.,3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"We formulate the activations of these rules as Boolean variables, whose assignments are highly interconnected.",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"For example, the variables representing the following rules (E = 0)→ SATIRE and (E = 0)→",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"REAL are mutually exclusive, since assigning a T value to either one entails a satire (or real) prediction.",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"To account for this interdependency, we add constraints capturing the relations between rules.
",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
The model makes predictions by combining the rule weights and predicting the top scoring output value.,3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"The prediction can be viewed as a derivation process, mapping article entities to categories (e.g., ENTITY(“A MAN”)→ (E=0), is an example of such derivation), combinations of categories compose into prediction patterns (e.g., (E=0)→SATIRE).",3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
We use an ILP solver to find the optimal derivation sequence.,3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
We describe the inference process as an Integer Linear Program in the following section.,3.2 Satire Prediction using the Narrative Representation Graph,[0],[0]
"We formulate the decision as a 0-1 Integer Linear Programming problem, consisting of three types of Boolean variables: category assignments indicator variables, indicator variables for common-sense patterns, and finally the output decision variables.",3.3 Identifying Relevant Interactions using Constrained Optimization,[0],[0]
"Each indicator variable is also represented using a feature set, used to score its activation.",3.3 Identifying Relevant Interactions using Constrained Optimization,[0],[0]
"Each node in the NRG is assigned a set of competing variables, mapping the node to different categories according to its type.
",3.3.1 Category Assignment Variables,[0],[0]
"• ANIMATE ENTITY Category Variables, denoted hi,j,E , indicating the Entity category i for NRG vertex j.
• ACTION Category Variables, denoted hi,j,A, indicating the Action category i for NRG vertex j.
• QUOTE Category Variables, denoted hi,j,Q, indicating the Quote category i for NRG vertex j.
The number of possible categories for each variable type is a hyper-parameter of the model.
",3.3.1 Category Assignment Variables,[0],[0]
Variable activation constraints Category assignments to the same node are mutually exclusive (a node can only have a single category).,3.3.1 Category Assignment Variables,[0],[0]
"We encode this fact by constraining the decision with a linear constraint (where X ∈ {E,A,Q}):
∀j ∑
i
hi,j,X = 1.
",3.3.1 Category Assignment Variables,[0],[0]
"Category Assignment Features Each decision variable decomposes into a set of features, φ(x, hi,j,X) capturing the words associated with the j-th vertex, conditioned on X and i.",3.3.1 Category Assignment Variables,[0],[0]
"We represent common-sense prediction rules using an additional set of Boolean variables, connecting the category assignments variables with the output prediction.",3.3.2 Common-sense Patterns Variables,[0],[0]
"The space of possible variables is determined by decomposing the NRG into paths of size up to 2, and associating two Boolean variables with category assignment variables corresponding to the vertices on these paths.",3.3.2 Common-sense Patterns Variables,[0],[0]
"One of the variables associates the sequence of category assignment variables with a REAL output value, and one with a SATIRE output value.
",3.3.2 Common-sense Patterns Variables,[0],[0]
"• Single Vertex Path Patterns Variables, denoted by hBhi,j,X , indicating that the category assignment captured by hi,j,X is associated with output value B (where B∈ {SATIRE, REAL}).
",3.3.2 Common-sense Patterns Variables,[0],[0]
"• Two Vertex Path Patterns Variables, denoted by hB(hi,j,X1),(hk,l,X2 )
, indicating that the pattern captured by category assignment along the NRG path of hi,j,X1 and hi,j,X2 is associated with output value B (where B∈ {SATIRE, REAL}).",3.3.2 Common-sense Patterns Variables,[0],[0]
"Decision Consistency constraints It is clear that the activation of the common-sense Patterns Variables entails the activation of the category assignment variables, corresponding to the elements of the common-sense patterns.",3.3.2 Common-sense Patterns Variables,[0],[0]
"For readability we only write the constraint for the Single Vertex Path Variables:
(hBhi,j,X ) =⇒ (hi,j,X).
",3.3.2 Common-sense Patterns Variables,[0],[0]
"Features Similar to the category assignment variable features, each decision variable decomposes into a set of features, φ(x, hBhi,j,X ).",3.3.2 Common-sense Patterns Variables,[0],[0]
"These features captures the words associated with each of the category assignment variables (in this example, the words associated with the j-th vertex) conditioned on the category assignments and the output prediction value (in this example, X, i and B).",3.3.2 Common-sense Patterns Variables,[0],[0]
"We also add a feature φ(hi,j,X , B) capturing the connection between the output value B, and category assignment.",3.3.2 Common-sense Patterns Variables,[0],[0]
"Finally, we add two more Boolean variables corresponding to the output prediction: hSatire and hReal.",3.3.3 Satire Prediction Variables,[0],[0]
"The activation of these two variables is mutually exclusive, we encode that by adding the constraint:
hSatire + hReal = 1.
",3.3.3 Satire Prediction Variables,[0],[0]
"We ensure the consistency of our model adding constraints forcing agreement between the final prediction variables, and the common-sense patterns variables:
hBhi,j,X =⇒ h B.
Overall Optimization Function The Boolean variables described in the previous section define a space of competing inferences.",3.3.3 Satire Prediction Variables,[0],[0]
"We find the optimal output value derivation by finding the optimal set of variables assignments, by solving the following objective:
max y,h ∑ i hiw Tφ(x, hi, y)
s.t. C, ∀i;hi ∈ {0, 1}, (1)
where hi ∈ H is the set of all variables defined above and C is the set of constraints defined over the activation of these variables.",3.3.3 Satire Prediction Variables,[0],[0]
"w is the weight vector, used to quantify the feature representation of each h, obtained using a feature function φ(·).
",3.3.3 Satire Prediction Variables,[0],[0]
Note that the Boolean variable acts as a 0-1 indicator variable.,3.3.3 Satire Prediction Variables,[0],[0]
We formalize Eq.,3.3.3 Satire Prediction Variables,[0],[0]
"(1) as an ILP instance, which we solve using the highly optimized Gurobi toolkit3.
3http://www.gurobi.com/",3.3.3 Satire Prediction Variables,[0],[0]
"The COMSENSE approach models the decision as interactions between high-level categories of entities, actions and utterances.",4 Parameter Estimation for COMSENSE,[0],[0]
"However, the high level categories assigned to the NRG vertices are not observed, and as a result we view it as a weakly supervised learning problem, where the category assignments correspond to latent variable assignments.",4 Parameter Estimation for COMSENSE,[0],[0]
"We learn the parameters of these assignments by using a discriminative latent structure learning framework.
",4 Parameter Estimation for COMSENSE,[0],[0]
"The training data is a collection D ={(xi, yi)}ni=1, where xi is an article, parsed into an NRG representation, and y is a binary label, indicating if the article is satirical or real.
",4 Parameter Estimation for COMSENSE,[0],[0]
"Given this data we estimate the models’ parameters by minimizing the following objective function.
",4 Parameter Estimation for COMSENSE,[0],[0]
LD(w),4 Parameter Estimation for COMSENSE,[0],[0]
"= min w
λ 2 ||w||2",4 Parameter Estimation for COMSENSE,[0],[0]
"+ 1 n
n∑
i=1
ξi (2)
ξi is the slack variable, capturing the margin violation penalty for a given training example, and defined as follows:
ξi = max y,h f(x,h, y,w) +",4 Parameter Estimation for COMSENSE,[0],[0]
"cost(y, yi)
−max h f(x,h, yi,w),
where f(·) is a scoring function, similar to the one used in Eq. 1.",4 Parameter Estimation for COMSENSE,[0],[0]
"The cost function is the margin that the true prediction must exceed over the competing label, and it is simply defined as the difference between the model prediction and the gold label.",4 Parameter Estimation for COMSENSE,[0],[0]
This formulation is an extension of the hinge loss for latent structure SVM.,4 Parameter Estimation for COMSENSE,[0],[0]
"λ is the regularization parameter controlling the tradeoff between the l2 regularizer and the slack penalty.
",4 Parameter Estimation for COMSENSE,[0],[0]
"We optimize this objective using the stochastic sub-gradient descent algorithm (Ratliff et al., 2007; Felzenszwalb et al., 2009).",4 Parameter Estimation for COMSENSE,[0],[0]
"We can compute the subgradient as follows:
∇LD(w) = λw + n∑
i=1
Φ(xi, yi, y ∗)
Φ(xi, yi, y ∗) = φ(xi,h∗, yi)− φ(xi,h∗, y∗),
where φ(xi,h∗, y∗) is the set of features representing the solution obtained after solving Eq. 14 and
4modified to accommodate the margin constraint
making a prediction.",4 Parameter Estimation for COMSENSE,[0],[0]
"φ(xi,h∗, yi) is the set of features representing the solution obtained by solving Eq. 1 while fixing the outcome of the inference process to the correct prediction (i.e., yi).",4 Parameter Estimation for COMSENSE,[0],[0]
"Intuitively, it can be considered as finding the best explanation for the correct label using the latent variables h.
",4 Parameter Estimation for COMSENSE,[0],[0]
In the stochastic version of the sub gradient descent algorithm we approximate ∇LD(w) by computing the sub gradient of a single example and making a local update.,4 Parameter Estimation for COMSENSE,[0],[0]
"This version resembles the latentstructure perceptron algorithm (Sun et al., 2009).",4 Parameter Estimation for COMSENSE,[0],[0]
"We repeatedly iterate over the training examples and for each example, if the current w leads to a correct prediction (and satisfies the margin constraint), we only shrink w according to λ.",4 Parameter Estimation for COMSENSE,[0],[0]
"If the model makes an incorrect prediction, the model is updated according Φ(xi, yi, y
∗).",4 Parameter Estimation for COMSENSE,[0],[0]
"The optimization objective LD(W ) is not convex, and the optimization procedure is guaranteed to converge to a local minimum.",4 Parameter Estimation for COMSENSE,[0],[0]
We design our experimental evaluation to help clarify several questions.,5 Empirical Study,[0],[0]
"First, we want to understand how our model compares with traditional text classification models.",5 Empirical Study,[0],[0]
"We hypothesize that these methods are more susceptible to overfitting, and design our experiments accordingly.",5 Empirical Study,[0],[0]
"We compare the models’ performance when using in-domain data (test and training data are from the same source), and out-ofdomain data, where the test data is collected from a different source.",5 Empirical Study,[0],[0]
We look into two tasks.,5 Empirical Study,[0],[0]
"One is the Satire detection task (Burfoot and Baldwin, 2009).",5 Empirical Study,[0],[0]
"We also introduce a new task, called “did I say that?” which only focuses on utterances and speakers.
",5 Empirical Study,[0],[0]
The second aspect of our evaluation focuses on the common-sense inferences learned by our model.,5 Empirical Study,[0],[0]
We examine how the size of the set of categories impacts the model performance.,5 Empirical Study,[0],[0]
"We also provide a qualitative analysis of the learned categories using a heat map, capturing the activation strength of learned inferences over the training data.
",5 Empirical Study,[0],[0]
"Prediction tasks We look into two prediction tasks: (1) Satire Detection (denoted SD), a binary classification task, in which the model has access to the complete article (2) “Did I say that?” (denoted DIST), a binary classification task, consisting only
of entities mentions (and their surrounding context in text) and direct quotes.",5 Empirical Study,[0],[0]
"The goal of the DIST is to predict if a given utterance is likely to be real, given its speaker.",5 Empirical Study,[0],[0]
"Since not all document contain direct quotes, we only use a subset of the documents in the SD task.
",5 Empirical Study,[0],[0]
"Datasets In both prediction tasks we look into two settings: (1) In-domain prediction: where the training and test data are collected from the same source, and (2) out-of-domain prediction, where the test data is collected from a different source.",5 Empirical Study,[0],[0]
"We use the data collected by Burfoot and Baldwin (2009) for training the model in both settings, and its test data for in-domain prediction (denoted TRAIN - SD’09, TEST - SD’09, TRAIN - SD’09 - DIST, TEST - SD’09 - DIST, respectively for training and testing in the SD and DIST tasks).",5 Empirical Study,[0],[0]
"In addition, we collected a second dataset of satirical and real articles (denoted SD’16).",5 Empirical Study,[0],[0]
"This collection of articles contains real articles from cnn.com and satirical articles from theonion.com, a well known satirical news website.",5 Empirical Study,[0],[0]
"The articles were published between 2010 to 2015, appearing in the political sections of both news websites.",5 Empirical Study,[0],[0]
"Following other work in the field, all datasets are highly skewed toward the negative class (real articles), as it better characterizes a realistic prediction scenario.",5 Empirical Study,[0],[0]
"The statistics of the datasets are summarized in Table 2.
",5 Empirical Study,[0],[0]
"Evaluated Systems We compare several systems, as follows:
System ALLPOS Always predict Satire
BB’09 Results by (Burfoot and Baldwin, 2009)
",5 Empirical Study,[0],[0]
CONV Convolutional NN.,5 Empirical Study,[0],[0]
"We followed (Kim, 2014), using pre-trained 300-dimensional word vectors (Mikolov et al., 2013).
",5 Empirical Study,[0],[0]
"LEX SVM with unigram (LEXU) or both unigram and bigram (LEXU+B) features
NARRLEX SVM with direct NRG-based features (see Sec 3.2)
",5 Empirical Study,[0],[0]
COMSENSE Our model.,5 Empirical Study,[0],[0]
"We denote the full model as COMSENSEF , and COMSENSEQ when using only the entity+quotes based patterns.
",5 Empirical Study,[0],[0]
"We tuned all the models’ hyper-parameters by using a small validation set, consisting of 15% of the training data.",5 Empirical Study,[0],[0]
"After setting the hyper-parameters, the
model was retrained using the entire dataset.",5 Empirical Study,[0],[0]
We used SVM-light5 to train our lexical baseline systems (LEX and NARRLEX).,5 Empirical Study,[0],[0]
"Since the data is highly skewed towards the negative class (REAL), we adjust the learner objective function cost factor for positive examples to outweigh negative examples.",5 Empirical Study,[0],[0]
The cost factor was tuned using the validation set.,5 Empirical Study,[0],[0]
"Since our goal is to identify satirical articles, given significantly more real articles, we report the Fmeasure of the positive class.",5.1 Experimental Results,[0],[0]
The results are summarized in Tables 1 and 3.,5.1 Experimental Results,[0],[0]
We can see that in all cases the COMSENSE model obtains the best results.,5.1 Experimental Results,[0],[0]
"We note that in both tasks, when learning in the outof-domain settings performance drops sharply, however the gap between the COMSENSE model and other models increases in these settings, showing that it is less prone to overfitting.
",5.1 Experimental Results,[0],[0]
"Interestingly, for the satire detection (SD) task, the COMSENSEQ model performs best for the indomain setting, and COMSENSEF gives the best performance in the out-of-domain settings.",5.1 Experimental Results,[0],[0]
We hypothesize that this is due to a phenomenon we call “overfitting to document structure”.,5.1 Experimental Results,[0],[0]
"Lexical models tend to base the decision on word choices specific to the training data, and as a result when tested on out of domain data, which describes new events and entities, performance drops sharply.",5.1 Experimental Results,[0],[0]
"Instead, the COMSENSEQ model focuses on properties of quotations and entities appearing in the text.",5.1 Experimental Results,[0],[0]
"In the SD’09 datasets, this information helps focus the learner, as the real and satire articles are structured differently (for example, satire articles frequently contain multiple quotes).",5.1 Experimental Results,[0],[0]
"This structure is not maintained when working with out-of-domain data, and indeed in these settings the model benefits from using additional information offered by the full model.
",5.1 Experimental Results,[0],[0]
"Number of Latent Categories Our COMSENSE model is parametrized with the number of latent categories it considers for each entity, predicate and quote.",5.1 Experimental Results,[0],[0]
This hyper-parameter can have a strong influence on the model performance (and running time).,5.1 Experimental Results,[0],[0]
"Increasing it adds to the model’s expressivity allowing it to learn more complex patterns, but also defines a more complex learning
5http://svmlight.joachims.org/
0.31
0.35
0.38
0.42
0.45
0.49
2 3 4 5 6
EV=2 EV=3
EV=1 Lex
Quote Vars
F -
S co
re
Figure 4: Different Number of Latent Categories.",5.1 Experimental Results,[0],[0]
"EV denotes the number entity categories used, and QuoteVars denotes the number of quote categories used.
problem (recall our non-convex learning objective function).",5.1 Experimental Results,[0],[0]
We focused on the DIST task when evaluating different configurations as it converged much faster than the full model.,5.1 Experimental Results,[0],[0]
Figure 4 plots the model behavior when using different numbers of latent categories.,5.1 Experimental Results,[0],[0]
"Interestingly, the number of entity categories saturates faster than the number of quote categories.",5.1 Experimental Results,[0],[0]
"This can be attributed to the limited text describing entities.
",5.1 Experimental Results,[0],[0]
Visualizing Latent COMSENSE Patterns,5.1 Experimental Results,[0],[0]
"Given the assignment to latent categories, our model learns common-sense patterns for identifying satirical and real articles based on these categories.",5.1 Experimental Results,[0],[0]
"Ideally, these patterns could be extracted directly from the data, however providing the resources for this additional prediction task is not straightforward.",5.1 Experimental Results,[0],[0]
"Instead, we view the category assignment as latent variables, which raises the question - what are the categories learned by the model?
",5.1 Experimental Results,[0],[0]
In this section we provide a qualitative evaluation of these categories and the prediction rules identified by the system using the heat map in Figure 5.,5.1 Experimental Results,[0],[0]
"For simplicity, we focus on the DIST task, which only has categories corresponding to entities and quotes.
",5.1 Experimental Results,[0],[0]
"(a) Prediction Rules These patterns are expressed as rules, mapping category assignments to output values.",5.1 Experimental Results,[0],[0]
"In the DIST task, we consider combinations of entity and quote category pairs, denoted Ei,Qj, in the heat map.",5.1 Experimental Results,[0],[0]
"The top part of Figure 5, in red, shows the activation strength of each of the category com-
binations when making predictions over the training data.",5.1 Experimental Results,[0],[0]
"Darker colors correspond to larger values, which were computed as:
cell(CE , CQ, B) = ∑ j hB(hCE,j,E),(hCQ,j,Q) ∑ j,k,l hB(hk,j,E),(hl,j,Q)
Intuitively, each cell value in Figure 5 is the number of times each category pattern appeared in REAL or
SATIRE output predictions, normalized by the overall number of pattern activations for each output.
",5.1 Experimental Results,[0],[0]
"We assume that different patterns will be associated with satirical and real articles, and indeed we can see that most entities and quotes appearing in REAL articles fall into a distinctive category pattern, E0, Q0.",5.1 Experimental Results,[0],[0]
"Interestingly, there is some overlap between the two predictions in the most active SATIRE category (E1, Q0).",5.1 Experimental Results,[0],[0]
"We hypothesize that this is due to the fact that the two article types have some overlap.
",5.1 Experimental Results,[0],[0]
"(b) Associating topic words with learned categories In order to understand the entity and quote categories emerging from the training phase, we look at the activation strength of each category pattern with respect to a set of topic words.",5.1 Experimental Results,[0],[0]
"We manually identified a set of entity types and quote topics, which are likely to appear in political articles.",5.1 Experimental Results,[0],[0]
"We associate a list of words with each one of these types.
",5.1 Experimental Results,[0],[0]
"For example, the entity topic PRESIDENT was associated with words such as president, vice-president, Obama, Biden, Bush, Clinton.",5.1 Experimental Results,[0],[0]
"Similarly, we associated with the quote topic PROFANITY a list of profanity words.",5.1 Experimental Results,[0],[0]
"We associate 7 types with quote categories corresponding to style and topic, namely PROFANITY, DRUGS, POLITENESS, SCIENCE, LEGAL, POLITICS, CONTROVERSY, and another set of seven types with entity types, namely PRESIDENT, LIBERAL, CONSERVATIVE, ANONYMOUS, POLITICS, SPEAKER, LAW ENFORCEMENT.
",5.1 Experimental Results,[0],[0]
"In the bottom left part of Figure 5 (in blue), we show the activation strength of each category with respect to the set of selected quote topics.",5.1 Experimental Results,[0],[0]
"Intuitively, we count the number of times the words associated with a given topic appeared in the text span corresponding to a category assignment pair, separately for each output prediction.",5.1 Experimental Results,[0],[0]
"We normalize this value by the total number of topic word occurrences, over all category assignment pairs.",5.1 Experimental Results,[0],[0]
Note that we only look at the text span corresponding to quote vertices in the NRG.,5.1 Experimental Results,[0],[0]
We provide a similar analysis for entity categories in the bottom right part of Figure 5 (in green).,5.1 Experimental Results,[0],[0]
We show the activation strength of each category with respect to the set of selected entity topic words.,5.1 Experimental Results,[0],[0]
"As can be expected, we can see that profanity words are only associated with satirical categories, and even more interestingly, when words appear in both satirical and real predictions, they tend to fall into different categories.",5.1 Experimental Results,[0],[0]
"For example, the topic words related to DRUGS can appear both in real articles discussing alcohol and drug policies.",5.1 Experimental Results,[0],[0]
But topic words related to drugs also appear in satirical articles portraying politicians using these substances.,5.1 Experimental Results,[0],[0]
"While these are only qualitative results, we believe they provide strong intuitions for future work, especially considering the fact that the activation values do not rely on direct supervision, and only reflect the common-sense patterns emerging from the learned model.",5.1 Experimental Results,[0],[0]
In this paper we presented a latent variable model for satire detection.,6 Summary and Future Work,[0],[0]
"We followed the observation that satire detection is inherently a semantic task and modeled the common-sense inferences required for it using a latent variable framework.
",6 Summary and Future Work,[0],[0]
We designed our experiments specifically to examine if our model can generalize better than unstructured lexical models by testing it on out-ofdomain data.,6 Summary and Future Work,[0],[0]
"Our experiments show that in these challenging settings, the performance gap between our approach and the unstructured models increases, demonstrating the effectiveness of our approach.
",6 Summary and Future Work,[0],[0]
In this paper we restricted ourselves to limited narrative representation.,6 Summary and Future Work,[0],[0]
"In the future we intend to study how to extend this representation to capture more nuanced information.
",6 Summary and Future Work,[0],[0]
Learning common-sense representation for prediction problems has considerable potential for NLP applications.,6 Summary and Future Work,[0],[0]
"As the NLP community considers increasingly challenging tasks focusing on semantic and pragmatic aspects, the importance of finding such common-sense representation will increase.",6 Summary and Future Work,[0],[0]
In this paper we demonstrated the potential of common-sense representations for one application.,6 Summary and Future Work,[0],[0]
We hope these results will serve as a starting point for other studies in this direction.,6 Summary and Future Work,[0],[0]
"Automatic satire detection is a subtle text classification task, for machines and at times, even for humans.",abstractText,[0],[0]
"In this paper we argue that satire detection should be approached using common-sense inferences, rather than traditional text classification methods.",abstractText,[0],[0]
We present a highly structured latent variable model capturing the required inferences.,abstractText,[0],[0]
"The model abstracts over the specific entities appearing in the articles, grouping them into generalized categories, thus allowing the model to adapt to previously unseen situations.",abstractText,[0],[0]
Understanding Satirical Articles Using Common-Sense,title,[0],[0]
"Neural networks can be represented as a graph of computational modules, and training these networks amounts to optimising the weights associated with the modules of this graph to minimise a loss.",1. Introduction,[0],[0]
"At present, training is usually performed with first-order gradient descent style algorithms, where the weights are adjusted along the direction of the negative gradient of the loss.",1. Introduction,[0],[0]
"In order to compute the gra-
1DeepMind, London, United Kingdom.",1. Introduction,[0],[0]
"Correspondence to: WM Czarnecki <lejlot@google.com>.
fi
fi+1
fi+2
…
…
…
…
fi
fi+1
fi+2
…
…
…
…
Mi+1
i ̂i
Mi+2
̂i+1 i+1
(a) (b) (c)
Differentiable
Legend:
fi
fi+1
fi+2
…
…
…
…
Mi+1
i ̂i
(b)
x y
L
h SG
LSG
x y
L
h
Forward connection, differentiable
Forward connection, non-differentiable
Error gradient, non-differentiable
Synthetic error gradient, differentiable
Legend:
Synthetic error gradient, nondifferentiable
Non-differentiable
Forward connection
Error gradient
Synthetic error gradient
Figure 1.",1. Introduction,[0],[0]
"Visualisation of SG-based learning (b) vs. regular backpropagation (a).
dient of the loss with respect to the weights of a module, one performs backpropagation (Williams & Hinton, 1986) – sequentially applying the chain rule to compute the exact gradient of the loss with respect to a module.",1. Introduction,[0],[0]
"However, this scheme has many potential drawbacks, as well as lacking biological plausibility (Marblestone et al., 2016; Bengio et al., 2015).",1. Introduction,[0],[0]
"In particular, backpropagation results in locking – the weights of a network module can only be updated after a full forwards propagation of the data through the network, followed by loss evaluation, then finally after waiting for the backpropagation of error gradients.",1. Introduction,[0],[0]
"This locking constrains us to updating neural network modules in a sequential, synchronous manner.
",1. Introduction,[0],[0]
"One way of overcoming this issue is to apply Synthetic Gradients (SGs) to build Decoupled Neural Interfaces (DNIs) (Jaderberg et al., 2016).",1. Introduction,[0],[0]
"In this approach, models of error gradients are used to approximate the true error gradient.",1. Introduction,[0],[0]
"These models of error gradients are local to the network modules they are predicting the error gradient for, so that an update to the module can be computed by using the predicted, synthetic gradients, thus bypassing the need for subsequent forward execution, loss evaluation, and backpropagation.",1. Introduction,[0],[0]
The gradient models themselves are trained at the same time as the modules they are feeding synthetic gradients to are trained.,1. Introduction,[0],[0]
"The result is effectively a complex
ar X
iv :1
70 3.
00 52
2v 1
[ cs
.L G
] 1
M ar
2 01
7
Understanding Synthetic Gradients and DNIs
dynamical system composed of multiple sub-networks cooperating to minimise the loss.
",1. Introduction,[0],[0]
"There is a very appealing potential of using DNIs e.g. the potential to distribute and parallelise training of networks across multiple GPUs and machines, the ability to asynchronously train multi-network systems, and the ability to extend the temporal modelling capabilities of recurrent networks.",1. Introduction,[0],[0]
"However, it is not clear that introducing DNIs and SGs into a learning system will not negatively impact the learning dynamics and solutions found.",1. Introduction,[0],[0]
"While the empirical evidence in Jaderberg et al. (2016) suggests that SGs do not have a negative impact and that this potential is attainable, this paper will dig deeper and analyse the result of using SGs to accurately answer the question of the impact of synthetic gradients on learning systems.
",1. Introduction,[0],[0]
"In particular, we address the following questions, using feed-forward networks as our probe network architecture: Does introducing SGs change the critical points of the neural network learning system?",1. Introduction,[0],[0]
In Section 3 we show that the critical points of the original optimisation problem are maintained when using SGs.,1. Introduction,[0],[0]
Can we characterise the convergence and learning dynamics for systems that use synthetic gradients in place of true gradients?,1. Introduction,[0],[0]
Section 4 gives first convergence proofs when using synthetic gradients and empirical expositions of the impact of SGs on learning.,1. Introduction,[0],[0]
What is the difference in the representations and functional decomposition of networks learnt with synthetic gradients compared to backpropagation?,1. Introduction,[0],[0]
"Through experiments on deep neural networks in Section 5, we find that while functionally the networks perform identically trained with backpropagation or synthetic gradients, the layer-wise functional decomposition is markedly different due to SGs.
",1. Introduction,[0],[0]
"In addition, in Section 6 we look at formalising the connection between SGs and other forms of approximate error propagation such as Feedback Alignment (Lillicrap et al., 2016), Direct Feedback Alignment (Nøkland, 2016; Baldi et al., 2016), and Kickback (Balduzzi et al., 2014), and show that all these error approximation schemes can be captured in a unified framework, but crucially only using synthetic gradients can one achieve unlocked training.",1. Introduction,[0],[0]
"The key idea of synthetic gradients and DNI is to approximate the true gradient of the loss with a learnt model which predicts gradients without performing full backpropagation.
Consider a feed-forward network consisting of N layers fn, n ∈ {1, . . .",2. DNI using Synthetic Gradients,[0],[0]
", N}, each taking an input hn−1i and producing an output hni = fn(h n−1 i ), where h 0",2. DNI using Synthetic Gradients,[0],[0]
i = xi is the input data point xi.,2. DNI using Synthetic Gradients,[0],[0]
"A loss is defined on the output of the net-
work Li = L(hNi , yi) where yi is the given label or supervision for xi (which comes from some unknown P (y|x)).",2. DNI using Synthetic Gradients,[0],[0]
"Each layer fn has parameters θn that can be trained jointly to minimise Li with the gradient-based update rule
θn ← θn",2. DNI using Synthetic Gradients,[0],[0]
"− α ∂L(hNi , yi)
∂hni
∂hni ∂θn
where α is the learning rate and ∂Li/∂hni is computed with backpropagation.
",2. DNI using Synthetic Gradients,[0],[0]
"The reliance on ∂Li/∂hNi means that an update to layer i can only occur after every subsequent layer fj , j ∈ {i + 1, . .",2. DNI using Synthetic Gradients,[0],[0]
.,2. DNI using Synthetic Gradients,[0],[0]
", N} has been computed, the loss Li has been computed, and the error gradient ∂L/∂hNi backpropgated to get ∂Li/∂h",2. DNI using Synthetic Gradients,[0],[0]
N i .,2. DNI using Synthetic Gradients,[0],[0]
"An update rule such as this is update locked as it depends on computing Li, and also backwards locked as it depends on backpropagation to form ∂Li/∂hni .
",2. DNI using Synthetic Gradients,[0],[0]
"Jaderberg et al. (2016) introduces a learnt prediction of the error gradient, the synthetic gradient SG(hni , yi) = ̂∂Li/∂hni ' ∂Li/∂hni resulting in the update
θk ← θk",2. DNI using Synthetic Gradients,[0],[0]
"− α SG(hni , yi) ∂hni",2. DNI using Synthetic Gradients,[0],[0]
"∂θk ∀k ≤ n
This approximation to the true loss gradient allows us to have both update and backwards unlocking – the update to layer n can be applied without any other network computation as soon as hni has been computed, since the SG module is not a function of the rest of the network (unlike ∂Li/∂hi).",2. DNI using Synthetic Gradients,[0],[0]
"Furthermore, note that since the true ∂Li/∂hni can be described completely as a function of just hni and yi, from a mathematical perspective this approximation is sufficiently parameterised.
",2. DNI using Synthetic Gradients,[0],[0]
"The synthetic gradient module SG(hni , yi) has parameters θSG which must themselves be trained to accurately predict the true gradient by minimising the L2 loss LSGi = ‖SG(hni , yi)− ∂Li/∂hni ‖2.
",2. DNI using Synthetic Gradients,[0],[0]
"The resulting learning system consists of three decoupled parts: first, the part of the network above the SG module which minimises L wrt.",2. DNI using Synthetic Gradients,[0],[0]
"to its parameters {θn+1, ..., θN}, then the SG module that minimises the LSG wrt.",2. DNI using Synthetic Gradients,[0],[0]
to θSG.,2. DNI using Synthetic Gradients,[0],[0]
"Finally the part of the network below the SG module which uses SG(h, y) as the learning signal to train {θ1, ...θn}, thus it is minimising the loss modeled internally by SG.",2. DNI using Synthetic Gradients,[0],[0]
"Throughout the remainder of this paper, we consider the use of a single synthetic gradient module at a single layer k and for a generic data sample j and so refer to h = hj = hkj ; unless specified we drop the superscript k and subscript j. This model is shown in Figure 1 (b).",Assumptions and notation,[0],[0]
"We also focus on SG modules which take the point’s true label/value as conditioning SG(h, y) as opposed to SG(h).",Assumptions and notation,[0],[0]
"Note that without label conditioning, a SG module is trying to approximate
Understanding Synthetic Gradients and DNIs
not ∂L/∂h but rather EP (y|x)∂L/∂h since L is a function of both input and label.",Assumptions and notation,[0],[0]
"In theory, the lack of label is a sufficient parametrisation but learning becomes harder, since the SG module has to additionally learn P (y|x).
",Assumptions and notation,[0],[0]
"We also focus most of our attention on models that employ linear SG modules, SG(h, y) = hA+ yB +C. Such modules have been shown to work well in practice, and furthermore are more tractable to analyse.
",Assumptions and notation,[0],[0]
"As a shorthand, we denote θ<h to denote the subset of the parameters contained in modules up to h (and symmetrically θ>h), i.e. if h is the kth layer then θ<h = {θ1 . . .",Assumptions and notation,[0],[0]
", θk}.",Assumptions and notation,[0],[0]
Consider an N -layer feed-forward network with a single SG module at layer k. This network can be decomposed into two sub-networks: the first takes an input x and produces an output h = Fh(x) = fk(fk−1(. . .,Synthetic gradients in operation,[0],[0]
"(f1(x)))), while the second network takes h as an input, produces an output p = Fp(h) = fN",Synthetic gradients in operation,[0],[0]
(. . .,Synthetic gradients in operation,[0],[0]
(fk+1(h))),Synthetic gradients in operation,[0],[0]
"and incurs a loss L = L(p, y) based on a label y.
With regular backpropagation, the learning signal for the first network Fh is ∂L/∂h, which is a signal that specifies how the input to Fp should be changed in order to reduce the loss.",Synthetic gradients in operation,[0],[0]
"When we attach a linear SG between these two networks, the first sub-network Fh no longer receives the exact learning signal from Fp, but an approximation SG(h, y), which implies that Fh will be minimising an approximation of the loss, because it is using approximate error gradients.",Synthetic gradients in operation,[0],[0]
"Since the SG module is a linear model of ∂L/∂h, the approximation of the true loss that Fh is being optimised for will be a quadratic function of h and y. Note that this is not what a second order method does when a function is locally approximated with a quadratic and used for optimisation – here we are approximating the current loss, which is a function of parameters θ with a quadratic which is a function of h. Three appealing properties of an approximation based on h is that h already encapsulates a lot of non-linearities due to the processing of Fh, h is usually vastly lower dimensional than θ<h which makes learning more tractable, and the error only depends on quantities (h) which are local to this part of the network rather than θ which requires knowledge of the entire network.
",Synthetic gradients in operation,[0],[0]
"With the SG module in place, the learning system decomposes into two tasks: the second sub-network Fp tasked with minimising L given inputs h, while the first subnetwork Fh is tasked with pre-processing x in such a way that the best fitted quadratic approximator of L (wrt. h) is minimised.",Synthetic gradients in operation,[0],[0]
"In addition, the SG module is tasked with best approximating L.
The approximations and changing of learning objectives (described above) that are imposed by using synthetic gradients may appear to be extremely limiting.",Synthetic gradients in operation,[0],[0]
"However, in
both the theoretical and empirical sections of this paper we show that SG models can, and do, learn solutions to highly non-linear problems (such as memorising noise).
",Synthetic gradients in operation,[0],[0]
The crucial mechanism that allows such rich behaviour is to remember that the implicit quadratic approximation to the loss implied by the SG module is local (per data point) and non-stationary – it is continually trained itself.,Synthetic gradients in operation,[0],[0]
"It is not a single quadratic fit to the true loss over the entire optimisation landscape, but a local quadratic approximation specific to each instantaneous moment in optimisation.",Synthetic gradients in operation,[0],[0]
"In addition, because the quadratic approximation is a function only of h and not θ, the loss approximation is still highly non-linear w.r.t.",Synthetic gradients in operation,[0],[0]
"θ.
",Synthetic gradients in operation,[0],[0]
"If, instead of a linear SG module, one uses a more complex function approximator of gradients such as an MLP, the loss is effectively approximated by the integral of the MLP.",Synthetic gradients in operation,[0],[0]
"More formally, the loss implied by the SG module in hypotheses spaceH is of class {l : ∃g ∈ H : ∂l/∂h = g}1.",Synthetic gradients in operation,[0],[0]
"In particular, this shows an attractive mathematical benefit over predicting loss directly: by modelling gradients rather than losses, we get to implicitly model higher order loss functions.",Synthetic gradients in operation,[0],[0]
We now consider the effect SG has on critical points of the optimisation problem.,3. Critical points,[0],[0]
"Concretely, it seems natural to ask whether a model augmented with SG is capable of learning the same functions as the original model.",3. Critical points,[0],[0]
"We ask this question under the assumption of a locally converging training method, such that we always end up in a critical point.",3. Critical points,[0],[0]
"In the case of a SG-based model this implies a set of parameters θ such that ∂L/∂θ>h = 0, SG(h, y)∂h/∂θ<h = 0 and ∂LSG/∂θSG = 0.",3. Critical points,[0],[0]
"In other words we are trying to establish whether SG introduces regularisation to the model class, which changes the critical points, or whether it merely introduces a modification to learning dynamics, but retains the same set of critical points.
",3. Critical points,[0],[0]
"In general, the answer is positive: SG does induce a regularisation effect.",3. Critical points,[0],[0]
"However, in the presence of additional assumptions, we can show families of models and losses for which the original critical points are not affected.
",3. Critical points,[0],[0]
Proposition 1.,3. Critical points,[0],[0]
Every critical point of the original optimisation problem where SG can produce ∂L/∂hi has a corresponding critical point of the SG-based model.,3. Critical points,[0],[0]
Proof.,3. Critical points,[0],[0]
"Directly from the assumption we have that there exists a set of SG parameters such that the loss is minimal, thus ∂LSG/∂θSG = 0 and also SG(h, y) = ∂L/∂h and SG(h, y)∂h/∂θ<h = 0.
",3. Critical points,[0],[0]
The assumptions of this proposition are true for example when L = 0,3. Critical points,[0],[0]
"(one attains global minimum), when
1We mean equality for all points where ∂l/∂h is defined.
",3. Critical points,[0],[0]
"Understanding Synthetic Gradients and DNIs
∂L/∂hi = 0 or a network is a deep linear model trained with MSE and SG is linear.
",3. Critical points,[0],[0]
"In particular, this shows that for a large enough SG module all the critical points of the original problem have a corresponding critical point in the SG-based model.",3. Critical points,[0],[0]
"Limiting the space of SG hypotheses leads to inevitable reduction of number of original critical points, thus acting as a regulariser.",3. Critical points,[0],[0]
"At first this might look like a somewhat negative result, since in practice we rarely use a SG module capable of exactly producing true gradients.",3. Critical points,[0],[0]
"However, there are three important observations to make: (1) Our previous observation reflects having an exact representation of the gradient at the critical point, not in the whole parameter space.",3. Critical points,[0],[0]
"(2) One does preserve all the critical points where the loss is zero, and given current neural network training paradigms these critical points are important.",3. Critical points,[0],[0]
For such cases even if SG is linear the critical points are preserved.,3. Critical points,[0],[0]
(3) In practice one rarely optimises to absolute convergence regardless of the approach taken; rather we obtain numerical convergence meaning that ‖∂L/∂θ‖ is small enough.,3. Critical points,[0],[0]
"Thus, all one needs from SG-based model is to have small enough ‖(∂L/∂h+e)∂h/∂θ<h‖ ≤",3. Critical points,[0],[0]
"‖∂L/∂θ<h‖+‖e‖‖∂h/∂θ<h‖, implying that the approximation error at a critical point just has to be small wrt to ‖∂h/∂θ<h‖ and need not be 0.
",3. Critical points,[0],[0]
To recap: so far we have shown that SG can preserve critical points of the optimisation problem.,3. Critical points,[0],[0]
"However, SG can also introduce new critical points, leading to premature convergence and spurious additional solutions.",3. Critical points,[0],[0]
"As with our previous observation, this does not effect SG modules which are able to represent gradients exactly.",3. Critical points,[0],[0]
"But if the SG hypothesis space does not include a good approximator2 of the true gradient, then we can get new critical points which end up being an equilibrium state between SG modules and the original network.",3. Critical points,[0],[0]
We provide an example of such an equilibrium in the Supplementary Materials Section A.,3. Critical points,[0],[0]
"Having demonstrated that important critical points are preserved and also that new ones might get created, we need a better characterisation of the basins of attraction, and to understand when, in both theory and practice, one can expect convergence to a good solution.",4. Learning dynamics,[0],[0]
We conduct an empirical analysis of the learning dynamics on easily analysable artificial data.,Artificial Data,[0],[0]
"We create 2 and 100 dimensional versions of four basic datasets (details in the Supplementary Materials Section C) and train four simple models (a linear model and a deep linear one with 10 hidden layers, trained to minimise MSE and log loss) with regular backprop and with a SG-based alternative to see
2In this case, our gradient approximation needs to be reasonable at every point through optimisation, not just the critical ones.
whether it (numerically) converges to the same solution.
",Artificial Data,[0],[0]
For MSE and both shallow and deep linear architectures the SG-based model converges to the global optimum (exact numerical results provided in Supplementary Material Table 2).,Artificial Data,[0],[0]
"However, this is not the case for logistic regression.",Artificial Data,[0],[0]
This effect is a direct consequence of a linear SG module being unable to model ∂L/∂p3,Artificial Data,[0],[0]
"(where p = xW + b is the output of logistic regression), which often approaches the step function (when data is linearly separable), and cannot be well approximated with a linear function SG(h, y) =",Artificial Data,[0],[0]
hA+ yB+C.,Artificial Data,[0],[0]
"Once one moves towards problems without this characteristic (e.g. random labeling) the problem vanishes, since now ∂L/∂p can be approximated much better.",Artificial Data,[0],[0]
"While this may not seem particularly significant, it illustrates an important characteristic of SG in the context of the log loss – it will struggle to overfit to training data, since it requires modeling step function type shapes, which is not possible with a linear model.",Artificial Data,[0],[0]
"In particular this means that for best performance one should adapt the SG module architecture to the loss function used —for MSE linear SG is a reasonable choice, however for log loss one should use architectures including a sigmoid σ applied pointwise to a linear SG, such as SG(h, y) = dσ(hA) + yB + C.
As described in Section 2, using a linear SG module makes the implicit assumption that loss is a quadratic function of the activations.",Artificial Data,[0],[0]
"Furthermore, in such setting we can actually reconstruct the loss being used up to some additive constant since ∂L/∂h = hA + yB + C implies that L(h) = 12hAh
T + (yB + C)hT + const.",Artificial Data,[0],[0]
"If we now construct a 2-dimensional dataset, where data points are arranged in a 2D grid, we can visualise the loss implicitly predicted by the SG module and compare it with the true loss for each point.
",Artificial Data,[0],[0]
Figure 2 shows the results of such an experiment when learning a highly non-linear model (5-hidden layer relu network).,Artificial Data,[0],[0]
"As one can see, the quality of the loss approximation has two main components to its dynamics.",Artificial Data,[0],[0]
"First, it is better in layers closer to the true loss (i.e. the topmost layers), which matches observations from Jaderberg et al. (2016) and the intuition that the lower layers solve a more complex problem (since they bootstrap their targets).",Artificial Data,[0],[0]
"Second, the loss is better approximated at the very beginning of the training and the quality of the approximation degrades slowly towards the end.",Artificial Data,[0],[0]
"This is a consequence of the fact that close to the end of training, the highly nonlinear model has quite complex derivatives which cannot be well represented in a space of linear functions.",Artificial Data,[0],[0]
"It is worth noting, that in these experiments, the quality of the loss approximation dropped significantly when the true loss was around 0.001, thus it created good approximations for the majority of the learning process.",Artificial Data,[0],[0]
"There is also an empirical
3∂L/∂p = exp(xW + b)/(1 + exp(xW + b))− y
confirmation of the previous claim, that with log loss and data that can be separated, linear SGs will have problems modeling this relation close to the end of training (Figure 2 (b) left), while there is no such problem for MSE loss (Figure 2 (a) left).",Artificial Data,[0],[0]
"It is trivial to note that if a SG module used is globally convergent to the true gradient, and we only use its output after it converges, then the whole model behaves like the one trained with regular backprop.",Convergence,[0],[0]
"However, in practice we never do this, and instead train the two models in parallel without waiting for convergence of the SG module.",Convergence,[0],[0]
"We now discuss some of the consequences of this, and begin by showing that as long as a synthetic gradient produced is close enough to the true one we still get convergence to the true critical points.",Convergence,[0],[0]
"Namely, only if the error introduced by SG, backpropagated to all the parameters, is consistently smaller than the norm of true gradient multiplied by some positive constant smaller than one, the whole system converges.",Convergence,[0],[0]
"Thus, we essentially need the SG error to vanish around critical points.
",Convergence,[0],[0]
Proposition 2.,Convergence,[0],[0]
"Let us assume that a SG module is trained in each iteration in such a way that it -tracks true gradient, i.e. that ‖SG(h, y)− ∂L/∂h‖ ≤ .",Convergence,[0],[0]
"If ‖∂h/∂θ<h‖ is upper bounded by some K and there exists a constant δ ∈ (0, 1) such that in every iteration K ≤",Convergence,[0],[0]
"‖∂L/∂θ<h‖ 1−δ1+δ , then the whole training process converges to the solution of the
original problem.",Convergence,[0],[0]
Proof.,Convergence,[0],[0]
"Proof follows from showing that, under the assumptions, effectively we are training with noisy gradients, where the noise is small enough for convergence guarantees given by Zoutendijk (1970); Gratton et al. (2011) to apply.",Convergence,[0],[0]
"Details are provided in the Supplementary Materials Section B.
As a consequence of Proposition 2 we can show that with specifically chosen learning rates (not merely ones that are small enough) we obtain convergence for deep linear models.
",Convergence,[0],[0]
Corollary 1.,Convergence,[0],[0]
"For a deep linear model minimising MSE, trained with a linear SG module attached between two of its hidden layers, there exist learning rates in each iteration such that it converges to the critical point of the original problem.",Convergence,[0],[0]
Proof.,Convergence,[0],[0]
Proof follows directly from Propositions 1 and 2.,Convergence,[0],[0]
"Full proof is given in Supplementary Materials Section B.
For a shallow model we can guarantee convergence to the global solution provided we have a small enough learning rate, which is the main theoretical result of this paper.
",Convergence,[0],[0]
Theorem 1.,Convergence,[0],[0]
Let us consider linear regression trained with a linear SG module attached between its output and the loss.,Convergence,[0],[0]
"If one chooses the learning rate of the SG module using line search, then in every iteration there exists small
enough, positive learning rate of the main network such that it converges to the global solution.
",Convergence,[0],[0]
Proof.,Convergence,[0],[0]
"The general idea (full proof in the Supplementary Materials Section B) is to show that with assumed learning rates the sum of norms of network error and SG error decreases in every iteration.
",Convergence,[0],[0]
"Despite covering a quite limited class of models, these are the very first convergence results for SG-based learning.",Convergence,[0],[0]
"Unfortunately, they do not seem to easily generalise to the non-linear cases, which we leave for future research.",Convergence,[0],[0]
We now shift our attention to more realistic data.,5. Trained models,[0],[0]
"We train deep relu networks of varied depth (up to 50 hidden layers) with batch-normalisation and with two different activation functions on MNIST and compare models trained with full backpropagation to variants that employ a SG module in the middle of the hidden stack.
",5. Trained models,[0],[0]
"Figure 4 shows, that SG-based architectures converge well even if there are many hidden layers both below and above the module.",5. Trained models,[0],[0]
"Interestingly, SG-based models actually seem to converge faster (compare for example 20- or 50 layer deep relu network).",5. Trained models,[0],[0]
"We believe this may be due to some amount of loss function smoothing since, as described in Section 2, a linear SG module effectively models the loss function to be quadratic – thus the lower network has a simpler optimisation task and makes faster learning progress.
",5. Trained models,[0],[0]
Obtaining similar errors on MNIST does not necessarily mean that trained models are the same or even similar.,5. Trained models,[0],[0]
"Since the use of synthetic gradients can alter learning dynamics and introduce new critical points, they might converge to different types of models.",5. Trained models,[0],[0]
"Assessing the representational similarity between different models is difficult, however.",5. Trained models,[0],[0]
"One approach is to compute and visualise Representational Dissimilarity Matrices (Kriegeskorte et al., 2008) for our data.",5. Trained models,[0],[0]
"We sample a subset of 400 points from MNIST, order them by label, and then record activations on each hidden layer when the network is presented with these points.",5. Trained models,[0],[0]
"We plot the pairwise correlation matrix for each layer, as shown in Figure 3.",5. Trained models,[0],[0]
"This representation is permutation invariant, and thus the emergence of a block-diagonal correlation matrix means that at a given layer, points from the same class already have very correlated representations.
",5. Trained models,[0],[0]
Under such visualisations one can notice qualitative differences between the representations developed under standard backpropagation training versus those delivered by a SG-based model.,5. Trained models,[0],[0]
"In particular, in the MNIST model with 20 hidden layers trained with standard backpropagation we see that the representation covariance after 9 layers is nearly the same as the final layer’s representation.",5. Trained models,[0],[0]
"However, by contrast, if we consider the same architecture but with a SG module in the middle we see that the layers before the SG module develop a qualitatively different style of representation.",5. Trained models,[0],[0]
Note: this does not mean that layers before SG do not learn anything useful.,5. Trained models,[0],[0]
"To confirm this, we also introduced linear classifier probes (Alain & Bengio, 2016) and observed that, as with the pure backpropagation trained model, such probes can achieve 100% training accuracy after the first two hidden-layers of the SGbased model, as shown in Supplementary Material’s Figure 8.",5. Trained models,[0],[0]
"With 20 SG modules (one between every pair of layers), the representation is scattered even more broadly: we see rather different learning dynamics, with each layer contributing a small amount to the final solution, and there is no longer a point in the progression of layers where the representation is more or less static in terms of correlation structure (see Figure 3).
",5. Trained models,[0],[0]
"Understanding Synthetic Gradients and DNIs
Another way to investigate whether the trained models are qualitatively similar is to examine the norms of the weight matrices connecting consecutive hidden layers, and to assess whether the general shape of such norms are similar.",5. Trained models,[0],[0]
"While this does not definitively say anything about how much of the original classification is being solved in each hidden layer, it is a reasonable surrogate for how much computation is being performed in each layer4.",5. Trained models,[0],[0]
"According
to our experiments (see Figure 5 for visualisation of one of the runs), models trained with backpropagation on MNIST tend to have norms slowly increasing towards the output of the network (with some fluctuations and differences coming from activation functions, random initialisations, etc.).",5. Trained models,[0],[0]
"If we now put a SG in between every two hidden layers, we get norms that start high, and then decrease towards the output of the network (with much more variance now).",5. Trained models,[0],[0]
"Finally, if we have a single SG module we can observe that the behaviour after the SG module resembles, at least to some degree, the distributions of norms obtained with backpropagation, while before the SG it is more chaotic, with some similarities to the distribution of weights with SGs in-between every two layers.
",5. Trained models,[0],[0]
These observations match the results of the previous experiment and the qualitative differences observed.,5. Trained models,[0],[0]
When synthetic gradients are used to deliver full unlocking we obtain a very basic model at the lowest layers and then see iterative corrections in deeper layers.,5. Trained models,[0],[0]
"For a one-point unlocked model with a single SG module, we have two slightly separated models where one behaves similarly to backprop, and the other supports it.",5. Trained models,[0],[0]
"Finally, a fully locked model (i.e. traditional backprop) solves the task relatively early on, and later just increases its confidence.
",5. Trained models,[0],[0]
"4We train with a small L2 penalty added to weights to make norm correspond roughly to amount of computation.
",5. Trained models,[0],[0]
"We note that the results of this section support our previous notion that we are effectively dealing with a multi-agent system, which looks for coordination/equilibrium between components, rather than a single model which simply has some small noise injected into the gradients (and this is especially true for more complex models).",5. Trained models,[0],[0]
We now shift our attention and consider a unified view of several different learning principles that work by replacing true gradients with surrogates.,6. SG and conspiring networks,[0],[0]
"We focus on three such approaches: Feedback Alignment (FA) (Lillicrap et al., 2016), Direct Feedback Alignment (DFA) (Nøkland, 2016), and Kickback (KB) (Balduzzi et al., 2014).",6. SG and conspiring networks,[0],[0]
"FA effectively uses a fixed random matrix during backpropagation, rather than the transpose of the weight matrix used in the forward pass.",6. SG and conspiring networks,[0],[0]
"DFA does the same, except each layer directly uses the learning signal from the output layer rather than the subsequent local one.",6. SG and conspiring networks,[0],[0]
KB also pushes the output learning signal directly but through a predefined matrix instead of a random one.,6. SG and conspiring networks,[0],[0]
"By making appropriate choices for targets, losses, and model structure we can cast all of these methods in the SG framework, and view them as comprising two networks with a SG module in between them, wherein the first module builds a representation which makes the task of the SG predictions easier.
",6. SG and conspiring networks,[0],[0]
We begin by noting that in the SG models described thus far we do not backpropagate the SG error back into the part of the main network preceding the SG module (i.e. we assume ∂LSG/∂h = 0).,6. SG and conspiring networks,[0],[0]
"However, if we relax this restriction, we can use this signal (perhaps with some scaling factor α) and obtain what we will refer to as a SG + prop model.",6. SG and conspiring networks,[0],[0]
"Intuitively, this additional learning signal adds capacity to our SG model and forces both the main network and the SG module to “conspire” towards a common goal of making better gradient predictions.",6. SG and conspiring networks,[0],[0]
"From a practical perspective, according to our experiments, this additional signal heavily stabilises learning system5.",6. SG and conspiring networks,[0],[0]
"However, this comes at the cost of no longer being unlocked.
",6. SG and conspiring networks,[0],[0]
"Our main observation in this section is that FA, DFA, and KB can be expressed in the language of “conspiring” networks (see Table 1), of two-network systems that use a SG module.",6. SG and conspiring networks,[0],[0]
The only difference between these approaches is how one parametrises SG and what target we attempt to fit it to.,6. SG and conspiring networks,[0],[0]
"This comes directly from the construction of these
5 In fact, ignoring the gradients predicted by SG and only using the derivative of the SG loss, i.e. ∂LSG/∂h, still provides enough learning signal to converge to a solution for the original task in the simple classification problems we considered.",6. SG and conspiring networks,[0],[0]
"We posit a simple rationale for this: if one can predict gradients well using a simple transformation of network activations (e.g. a linear mapping), this suggests that the loss itself can be predicted well too, and thus (implicitly) so can the correct outputs.
",6. SG and conspiring networks,[0],[0]
"Understanding Synthetic Gradients and DNIs
Network
fi
fi+1 fi+2
…
…
… … fi fi+1 fi+2
…
…
… …
Mi+1
i ̂i
Mi+2 ̂i+1 i+1
(a) (b) (c)
Differentiable Legend:
x y
L h SG LSG
x y
L h Forward connection, differentiable Forward connection, non-differentiable Error gradient, non-differentiable Synthetic error gradient, differentiable Legend: Synthetic error gradient, nondifferentiable
Non-differentiable Forward connection
Error gradient
Synthetic error gradient
L
h SG
LSG
SG
p
L
h h
LSG
Bprop
p
L
h SG
LSG
SG + prop
p
L
h hA
DFA
p
L
h hA
LSG
FA
p
g=hW
L
h h1
LSG
Kickback
p
LSG
Method
∂̂L/∂h SG(h, y) SG(h, y) + α∂LSG∂h ∂L/∂h (∂L/∂p)A T (∂L/∂g)AT (∂L/∂p)1T SG(h, y) SG(h, y) SG(h, y) h hA hA h1 SG trains",6. SG and conspiring networks,[0],[0]
yes yes,6. SG and conspiring networks,[0],[0]
no no,6. SG and conspiring networks,[0],[0]
no no SG target ∂L/∂h ∂L/∂h −∂L/∂h −∂L/∂p −∂L/∂g −∂L/∂p,6. SG and conspiring networks,[0],[0]
"LSG(t, s) ‖t− s‖2 ‖t− s‖2 −〈t, s〉 −〈t, s〉 −〈t, s〉 −〈t, s〉 Update locked no",6. SG and conspiring networks,[0],[0]
yes*,6. SG and conspiring networks,[0],[0]
yes,6. SG and conspiring networks,[0],[0]
yes yes,6. SG and conspiring networks,[0],[0]
yes Backw.,6. SG and conspiring networks,[0],[0]
locked,6. SG and conspiring networks,[0],[0]
no,6. SG and conspiring networks,[0],[0]
yes*,6. SG and conspiring networks,[0],[0]
yes no,6. SG and conspiring networks,[0],[0]
yes no Direct error,6. SG and conspiring networks,[0],[0]
no no,6. SG and conspiring networks,[0],[0]
no,6. SG and conspiring networks,[0],[0]
"yes no yes
Table 1.",6. SG and conspiring networks,[0],[0]
"Unified view of “conspiring” gradients methods, including backpropagation, synthetic gradients are other error propagating methods.",6. SG and conspiring networks,[0],[0]
"For each of them, one still trains with regular backpropagation (chain rule) however ∂L/∂h is substituted with a particular ∂̂L/∂h.",6. SG and conspiring networks,[0],[0]
"Black lines are forward signals, blue ones are synthetic gradients, and green ones are true gradients.",6. SG and conspiring networks,[0],[0]
Dotted lines represent non-differentiable operations.,6. SG and conspiring networks,[0],[0]
The grey modules are not trainable.,6. SG and conspiring networks,[0],[0]
"A is a fixed, random matrix and 1 is a matrix of ones of an appropriate dimension.",6. SG and conspiring networks,[0],[0]
*,6. SG and conspiring networks,[0],[0]
"In SG+Prop the network is locked if there is a single SG module, however if we have multiple ones, then propagating error signal only locks a module with the next one, not with the entire network.",6. SG and conspiring networks,[0],[0]
"Direct error means that a model tries to solve classification problem directly at layer h.
systems, and the fact that if we treat our targets as constants (as we do in SG methods), then the backpropagated error from each SG module (∂LSG/∂h) matches the prescribed update rule of each of these methods (∂̂L/∂h).",6. SG and conspiring networks,[0],[0]
One direct result from this perspective is the fact that Kickback is essentially DFA with A = 1.,6. SG and conspiring networks,[0],[0]
"For completeness, we note that regular backpropagation can also be expressed in this unified view – to do so, we construct a SG module such that the gradients it produces attempt to align the layer activations with the negation of the true learning signal (−∂L/∂h).",6. SG and conspiring networks,[0],[0]
"In addition to unifying several different approaches, our mapping also illustrates the potential utility and diversity in the generic idea of predicting gradients.",6. SG and conspiring networks,[0],[0]
This paper has presented new theory and analysis for the behaviour of synthetic gradients in feed forward models.,7. Conclusions,[0],[0]
"Firstly, we showed that introducing SG does not necessarily change the critical points of the original problem, however at the same time it can introduce new critical points into the learning process.",7. Conclusions,[0],[0]
This is an important result showing that SG does not act like a typical regulariser despite simplifying the error signals.,7. Conclusions,[0],[0]
"Secondly, we showed that (despite modifying learning dynamics) SG-based models converge
to analogous solutions to the true model under some additional assumptions.",7. Conclusions,[0],[0]
"We proved exact convergence for a simple class of models, and for more complex situations we demonstrated that the implicit loss model captures the characteristics of the true loss surface.",7. Conclusions,[0],[0]
It remains an open question how to characterise the learning dynamics in more general cases.,7. Conclusions,[0],[0]
"Thirdly, we showed that despite these convergence properties the trained networks can be qualitatively different from the ones trained with backpropagation.",7. Conclusions,[0],[0]
"While not necessarily a drawback, this is an important consequence one should be aware of when using synthetic gradients in practice.",7. Conclusions,[0],[0]
"Finally, we provided a unified framework that can be used to describe alternative learning methods such as Synthetic Gradients, FA, DFA, and Kickback, as well as standard Backprop.",7. Conclusions,[0],[0]
The approach taken shows that the language of predicting gradients is suprisingly universal and provides additional intuitions and insights into the models.,7. Conclusions,[0],[0]
"The authors would like to thank James Martens and Ross Goroshin for their valuable remarks and discussions.
",Acknowledgments,[0],[0]
Understanding Synthetic Gradients and DNIs,Acknowledgments,[0],[0]
We can show an example of SG introducing new critical points.,Critical points,[0],[0]
"Consider a small one-dimensional training dataset {−2,−1, 1, 2} ⊂ R, and let us consider a simple system where the model f : R → R is parametrised with two scalars, a and b and produces ax + b.",Critical points,[0],[0]
"We train it to minimise L(a, b) =",Critical points,[0],[0]
∑4 i=1 |axi,Critical points,[0],[0]
+ b|.,Critical points,[0],[0]
"This has a unique minimum which is obtained for a = b = 0, and standard gradient based methods will converge to this solution.",Critical points,[0],[0]
"Let us now attach a SG module betweenf and L. This module produces a (trainable) scalar value c ∈ R (thus it produces a single number, independent from the input).",Critical points,[0],[0]
"Regardless of the value of a, we have a critical point of the SG module when b = 0 and c = 0.",Critical points,[0],[0]
"However, solutions with a = 1 and c = 0 are clearly not critical points of the original system.",Critical points,[0],[0]
Figure 6 shows the loss surface and the fitting of SG module when it introduces new critical point.,Critical points,[0],[0]
Theorem 1 Let us consider linear regression trained with a linear SG module attached between its output and the loss.,B. Proofs,[0],[0]
"If one chooses the learning rate of the SG module using line search, then in every iteration there exists small
Understanding Synthetic Gradients and DNIs
enough, positive learning rate of the main network such that it converges to the global solution.
",B. Proofs,[0],[0]
Proof.,B. Proofs,[0],[0]
Let X = {xs}Ss=1 ∈,B. Proofs,[0],[0]
"Rd×S be the data, let {ys}Ss=1 ∈ R1×S be the labels.",B. Proofs,[0],[0]
Throughout the proof k will be the iteration of training.,B. Proofs,[0],[0]
We denote by 1 ∈ R1×S a row vector in which every element is 1.,B. Proofs,[0],[0]
We also follow the standard convention of including the bias in the weight matrix by augmenting the data X with one extra coordinate always equal to 1.,B. Proofs,[0],[0]
"Thus, we denote X̄ =",B. Proofs,[0],[0]
(,B. Proofs,[0],[0]
"XT |1T )T , X̄ ∈ R(d+1)×S and x̄s-the columns of X̄.",B. Proofs,[0],[0]
"Using that convention, the weight matrix is Wk ∈ R1×(d+1).",B. Proofs,[0],[0]
"We have
psk := Wkx̄ s,
L = 1
2 S∑ s=1 (ys − psk) 2 = 1 2 n∑ i=1",B. Proofs,[0],[0]
"(ys −Wkx̄s)2 .
",B. Proofs,[0],[0]
"Our aim is to find arg min
W,b L.
We use
∂L ∂W = ∂L",B. Proofs,[0],[0]
∂p ∂p ∂W = S∑ s=1,B. Proofs,[0],[0]
"∂L ∂ps ∂ps ∂W =
S∑ s=1",B. Proofs,[0],[0]
"∂L ∂ps x̄s = S∑ s=1 (ys −Wkx̄s) (x̄s)T
∂L ∂p =",B. Proofs,[0],[0]
"( p1 − y1, . . .",B. Proofs,[0],[0]
", pS − yS )",B. Proofs,[0],[0]
We will use the following parametrization of the synthetic gradient ∇̃Lk,B. Proofs,[0],[0]
= (αk+1)pk−(βk+1)y+γk1.,B. Proofs,[0],[0]
"The reason for using this form instead of simply akpk + bky + ck1 is that we are going to show that under DNI this synthetic gradient will converge to the “real gradient” ∂L∂p , which means showing that lim
k→∞ (αk, βk, γk) = (0, 0, 0).",B. Proofs,[0],[0]
"Thanks to this
choice of parameters αk, βk, γk we have the simple expression for the error
Ek = ∥∥∥∥∇̃Lk − ∂L∂p",B. Proofs,[0],[0]
"∥∥∥∥2 2 =
‖(αk + 1)pk − (βk + 1)y + γk1−( p1k",B. Proofs,[0],[0]
"− y1, . . .",B. Proofs,[0],[0]
", pSk − yS )∥∥2 2
=∥∥(αkp1k − βky1 + γk, . . .",B. Proofs,[0],[0]
", αkpSk",B. Proofs,[0],[0]
"− βkyS + γk)∥∥22 Parameters αk, βk, γk will be updated using the gradient descent minimizing the error E. We have
∂E ∂α = S∑ s=1",B. Proofs,[0],[0]
"(αkp s k − βkys + γk)psk
∂E",B. Proofs,[0],[0]
∂β = − S∑ s=1,B. Proofs,[0],[0]
"(αkp s k − βkys + γk)ys
∂E ∂γ",B. Proofs,[0],[0]
"= S∑ s=1 (αkp s k − βkys + γk).
",B. Proofs,[0],[0]
"As prescribed in Jaderberg et al. (2016), we start our iterative procedure from the synthetic gradient being equal to zero and we update the parameters by adding the (negative) gradient multiplied by a learning rate ν.",B. Proofs,[0],[0]
"This means that we apply the iterative procedure:
α0 = −1, β0 = −1, γ0 = 0
Wk+1 =Wk − µ S∑ s=1",B. Proofs,[0],[0]
"((αk + 1)p s k−
(βk + 1)y s + γk) (x̄ s)T
αk+1 =αk − ν S∑ s=1",B. Proofs,[0],[0]
"(αkp s k − βkys + γk)psk
βk+1",B. Proofs,[0],[0]
=βk + ν S∑ s=1,B. Proofs,[0],[0]
"(αkp s k − βkys + γk)ys
γk+1 =γk − ν S∑ s=1 (αkp s k − βkys + γk).
",B. Proofs,[0],[0]
"Using matrix notation
Wk+1 = Wk − µ((αk + 1)pk − (βk + 1)y + γk1)X̄T αk+1 = αk − ν",B. Proofs,[0],[0]
"( αk‖pk‖22 − βk〈y,pk〉+ γk〈1,pk〉 ) βk+1",B. Proofs,[0],[0]
= βk + ν,B. Proofs,[0],[0]
"( αk〈pk,y〉 − βk‖y‖22 + γk〈1,y〉
) γk+1",B. Proofs,[0],[0]
= γk,B. Proofs,[0],[0]
"− ν (αk〈1,pk〉 − βk〈1,y〉+",B. Proofs,[0],[0]
"Sγk)
Note, that the subspace given by α = β = γ = 0 is invariant under this mapping.",B. Proofs,[0],[0]
"As noted before, this corresponds to the synthetic gradient being equal to the real gradient.",B. Proofs,[0],[0]
"Proving the convergence of SG means showing, that a trajectory starting from α0 = −1, β0 = −1, γ0 = 0 converges to W = W0, α = β = γ = 0, where W0 are the “true” weigts of the linear regression.",B. Proofs,[0],[0]
"We are actually going to prove more, we will show that W = W0, α = β = γ = 0 is in fact a global attractor, i.e. that any trajectory converges to that point.",B. Proofs,[0],[0]
Denoting ω =,B. Proofs,[0],[0]
"(α, β, γ)t we get
Wk+1 =",B. Proofs,[0],[0]
Wk − µ((αk + 1)pk,B. Proofs,[0],[0]
− (βk + 1)y + γk1)X̄T ωk+1 =,B. Proofs,[0],[0]
ωk − ν,B. Proofs,[0],[0]
"[ pTk | − yT |1T ]T [ pTk | − yT |1T ] ωk
Wk+1 = Wk − µ(pk − y)X̄T − µωTk",B. Proofs,[0],[0]
"[ pTk | − yT |1T ]T X̄T
ωk+1 =",B. Proofs,[0],[0]
ωk − ν,B. Proofs,[0],[0]
"[ pTk | − yT |1T ]T [ pTk | − yT |1T ] ωk.
",B. Proofs,[0],[0]
Denoting by Ak =,B. Proofs,[0],[0]
"[ pTk | − yT |1T ] we get
Wk+1 = Wk − µ(pk − y)X̄T − µωTATk X̄T
ωk+1 = ωk − νATkAkωk.
",B. Proofs,[0],[0]
"Understanding Synthetic Gradients and DNIs
Multiplying both sides of the first equation by X̄ we obtain
Wk+1X̄ = WkX̄− µ(pk − y)X̄T X̄− µωTATk X̄T X̄",B. Proofs,[0],[0]
ωk+1 = ωk,B. Proofs,[0],[0]
"− νATkAkωk.
",B. Proofs,[0],[0]
Denote B = X̄T X̄.,B. Proofs,[0],[0]
"We get
pk+1 = pk",B. Proofs,[0],[0]
"− µpkB + µyB− µωTkATkB ωk+1 = ωk − νATkAkωk.
",B. Proofs,[0],[0]
"Denoting ek = (y − pk)T we get
ek+1 = ek − µBek + µBAkωk ωk+1 = ωk − νATkAkωk.
",B. Proofs,[0],[0]
We will use the symbol ξ = Akωk.,B. Proofs,[0],[0]
"Then
ek+1 = ek − µBek + µBξk",B. Proofs,[0],[0]
ξk+1,B. Proofs,[0],[0]
= ξk,B. Proofs,[0],[0]
"− νAkATk ξk.
(1)
",B. Proofs,[0],[0]
Every vector v can be uniquely expressed as a sum v = v⊥ + v‖ with X̄v⊥ = 0 and v‖ = X̄T θ for some θ (v‖ is a projection of v onto the linear subspace spanned by the columns of X̄).,B. Proofs,[0],[0]
"Applying this decomposition to ek = e⊥k + e ‖ k we get
e⊥k+1 = e ⊥ k",B. Proofs,[0],[0]
− µ(Bek)⊥,B. Proofs,[0],[0]
+ µ(Bξk)⊥ e ‖ k+1 = e ‖,B. Proofs,[0],[0]
k,B. Proofs,[0],[0]
− µ(Bek) ‖ + µ(Bξk) ‖,B. Proofs,[0],[0]
ξk+1,B. Proofs,[0],[0]
=,B. Proofs,[0],[0]
ξk,B. Proofs,[0],[0]
"− νAkATk ξk.
",B. Proofs,[0],[0]
"Note now, that as B = X̄T X̄, for any vector v there is (Bv)⊥ = 0, and (Bv)‖ = Bv (because the operator v 7→ v‖ is a projection).",B. Proofs,[0],[0]
"Moreover, Bv = Bv‖.",B. Proofs,[0],[0]
"Therefore
e⊥k+1 = e ⊥ k e ‖ k+1 = e ‖ k − µ(Be ‖ k) + µ(Bξk) ‖",B. Proofs,[0],[0]
ξk+1,B. Proofs,[0],[0]
=,B. Proofs,[0],[0]
ξk,B. Proofs,[0],[0]
"− νAkATk ξk.
",B. Proofs,[0],[0]
The value e⊥k does not change.,B. Proofs,[0],[0]
"Thus, we will be omitting the first equation.",B. Proofs,[0],[0]
"Note, that e⊥k is “the residue”, the smallest error that can be obtained by a linear regression.",B. Proofs,[0],[0]
"For the sake of visual appeal we will denote f = e‖k
fk+1 = fk − µBfk + µBξk ξk+1",B. Proofs,[0],[0]
= ξk,B. Proofs,[0],[0]
"− νAkATk ξk.
Taking norms and using ‖u+ v‖ ≤ ‖u‖+ ‖v‖ we obtain
‖fk+1‖2 ≤ ‖fk − µBfk‖2 + µ‖Bξk‖2 ‖ξk+1‖22 = ‖ξk‖22 − 2ν‖ATk ξk‖22 + ν2‖AkATk ξk‖22.
",B. Proofs,[0],[0]
Observe that ‖fk − µBfk‖22 = ‖fk‖22,B. Proofs,[0],[0]
− 2µfkBfk + µ2‖Bfk‖22.,B. Proofs,[0],[0]
"As B is a constant matrix, there exists a constant b > 0",B. Proofs,[0],[0]
"such that vTBv ≥ b‖v‖22 for any v satisfying
v‖ = v. Therefore ‖fk",B. Proofs,[0],[0]
− µBfk‖22 ≤ ‖fk‖22 − 2µb‖fk‖22 + µ2‖B‖2‖fk‖22.,B. Proofs,[0],[0]
"Using that and ‖Bξk‖2 ≤ ‖B‖‖ξk‖2 we get
‖fk+1‖2 ≤",B. Proofs,[0],[0]
"√
1− 2µb+ µ2‖B‖2‖fk‖2 + µ‖B‖‖ξk‖2 ‖ξk+1‖22",B. Proofs,[0],[0]
= ‖ξk‖22,B. Proofs,[0],[0]
"− 2ν‖ATk ξk‖22 + ν2‖AkATk ξk‖22.
",B. Proofs,[0],[0]
Let us assume that AkATk ξk 6= 0.,B. Proofs,[0],[0]
"In that case the righthand side of the second equation is a quadratic function is ν, whose minimum value is attained for ν = ‖A T k ξk‖ 2 2
‖AkATk ξk‖ 2 2 .",B. Proofs,[0],[0]
"For so-chosen ν we have
‖fk+1‖2 ≤ √ 1− 2µb+ µ2‖B‖2‖fk‖2 + µ‖B‖‖ξk‖2
‖ξk+1‖22 =",B. Proofs,[0],[0]
"( 1− ‖A T k ξk‖22
‖AkATk ξk‖22 ‖ATk ξk‖22 ‖ξk‖22
) ‖ξk‖22.
Consider a space {f}⊕{ξ} (concatenation of vectors) with a norm ‖{f} ⊕ {ξ}‖⊕ = ‖f‖2 + ‖ξ‖2.
‖{fk+1} ⊕ {ξk+1}‖⊕ ≤√ 1− 2µb+ µ2‖B‖2‖fk‖2 + µ‖B‖‖ξk‖2",B. Proofs,[0],[0]
+,B. Proofs,[0],[0]
"√
1− ‖ATk ξk‖22 ‖AkATk ξk‖22 ‖ATk ξk‖22 ‖ξk‖22 ‖ξk‖2 ≤
Using √
1− h ≤ 1− 12h we get
‖{fk+1} ⊕ {ξk+1}‖⊕ ≤ √
1− 2µb+ µ2‖B‖2‖fk‖2+( 1− ‖A T k ξk‖22
2‖AkATk ξk‖22 ‖ATk ξk‖22 ‖ξk‖22 + µ
) ‖ξk‖2
Note, that √
1− 2µb+ µ2‖B‖2 < 1 for 0 < µ ≤ b‖B‖2 .",B. Proofs,[0],[0]
"Thus, for
µ < min
{ b
‖B‖2 , 1− ‖A T k ξk‖22 2‖AkATk ξk‖22 ‖ATk ξk‖22 ‖ξk‖22
} ,
for every pair {fk+1} ⊕ {ξk+1} 6= {0} ⊕ {0} (and if they are zeros then we already converged) there is
‖{fk+1} ⊕ {ξk+1}‖⊕ < ‖{fk} ⊕ {ξk}‖⊕.
Therefore, by Theorem 2, the error pair {fk+1} ⊕ {ξk+1} has to converge to 0, which ends the proof in the case AkA T k ξk 6= 0.",B. Proofs,[0],[0]
"It remains to investigate what happens if AkA T k ξk = 0.
",B. Proofs,[0],[0]
We start by observing that either ξk = 0 or ATk ξk 6= 0 and AkA T k ξk 6= 0.,B. Proofs,[0],[0]
This follows directly from the definition ξk = Akωk.,B. Proofs,[0],[0]
"Indeed, if ξk 6= 0 there is 0 <",B. Proofs,[0],[0]
‖Akωk‖22 = ωTkA T k ξk and analogously 0,B. Proofs,[0],[0]
< ‖ATk,B. Proofs,[0],[0]
"ξk‖ = ξTkAkATk ξk.
",B. Proofs,[0],[0]
In case ξk = 0,B. Proofs,[0],[0]
"there is ‖{fk+1} ⊕ {ξk+1}‖⊕ = ‖ fk+1‖2 < √ 1− 2µb+ µ2‖B‖2‖fk‖2 =√
1− 2µb+ µ2‖B‖2‖{fk} ⊕ {ξk}‖⊕ and the theorem follows.
",B. Proofs,[0],[0]
"Understanding Synthetic Gradients and DNIs
Theorem 2.",B. Proofs,[0],[0]
Let B be a finite-dimensional Banach space.,B. Proofs,[0],[0]
Let f : B → B be a continuous map such that for every x ∈ B there is ‖f(x)‖ < ‖x‖.,B. Proofs,[0],[0]
"Then for every x there is lim n→∞ fn(x) = 0.
Proof.",B. Proofs,[0],[0]
Let ω(x) = {y : ∃i1<i2<...,B. Proofs,[0],[0]
lim n→∞ f in(x) = y}.,B. Proofs,[0],[0]
"Because ‖f(x)‖ < ‖x‖, the sequence x, f(x), f2(x), . .",B. Proofs,[0],[0]
.,B. Proofs,[0],[0]
"is contained in a ball of a radius ‖x‖, which due to a finite dimensionality of B is a compact set.",B. Proofs,[0],[0]
"Thus, ω(x) is nonempty.",B. Proofs,[0],[0]
"Moreover, from the definition, ω(x) is a closed set, and therefore it is a compact set.",B. Proofs,[0],[0]
"Let y0 = infy∈ω(x) ‖y‖ – which we know exists, due to the compactness of ω(x) and the continuity of ‖ · ‖ (Weierstraß theorem).",B. Proofs,[0],[0]
"But for every y ∈ ω(x) there is f(y) ∈ ω(x), thus there must be y0 = 0.",B. Proofs,[0],[0]
"By definition, for every ε, there exists n0 such that ‖fn0(x)‖ < ε.",B. Proofs,[0],[0]
"Therefore, for n > n0",B. Proofs,[0],[0]
‖fn(x)‖ < ε.,B. Proofs,[0],[0]
"Therefore, fn(x) must converge to 0.
",B. Proofs,[0],[0]
Proposition 2.,B. Proofs,[0],[0]
"Let us assume that a SG module is trained in each iteration in such a way that it -tracks true gradient, i.e. that ‖SG(h, y)− ∂L/∂h‖ ≤ .",B. Proofs,[0],[0]
"If ‖∂h/∂θ<h‖ is upper bounded by some K and there exists a constant δ ∈ (0, 1) such that in every iteration K ≤",B. Proofs,[0],[0]
"‖∂L/∂θ<h‖ 1−δ1+δ , then the whole training process converges to the solution of the original problem.
",B. Proofs,[0],[0]
Proof.,B. Proofs,[0],[0]
"Directly from construction we get that ‖∂L/∂θ<h− ∂̂L/∂̂θ<h‖ = ‖(∂L/∂h−SG(h, y))∂h/∂θ<h‖ ≤ K thus in each iteration there exists such a vector e, that ‖e‖ ≤ K and ∂̂L/∂̂θ<h = ∂L/∂θ<h + e. Consequently, we get a model trained with noisy gradients, where the noise of the gradient is bounded in norm by K so, directly from assumptions, it is also upper bounded by ‖∂L/∂θ<h‖ 1−δ1+δ",B. Proofs,[0],[0]
"and we we get that the direction followed is sufficient for convergence as this means that cosine between true gradient and synthetic gradient is uniformly bounded away (by δ) from zero (Zoutendijk, 1970; Gratton et al., 2011).",B. Proofs,[0],[0]
"At the same time, due to Proposition 1, we know that the assumptions do not form an empty set as the SG module can stay in an neighborhood of the gradient, and both norm of the synthetic gradient and ‖∂h/∂θ<h‖ can go to zero around the true critical point.
",B. Proofs,[0],[0]
Corollary 1.,B. Proofs,[0],[0]
"For a deep linear model and an MSE objective, trained with a linear SG module attached between two of its hidden layers, there exist learning rates in each iteration such that it converges to the critical point of the original problem.
",B. Proofs,[0],[0]
Proof.,B. Proofs,[0],[0]
"Denote the learning rate of the main model by µ and learning rate of the SG module by ν > 0 and put µ = max(0, ‖e‖ − 1/(3‖∂h/∂θ<h‖)‖∂L/∂θ<h‖), where is a small learning rate (for example found using line search)
and e is the error SG will make in the next iteration.",B. Proofs,[0],[0]
"The constant 1/3 appears here as it is equal to (1− δ)/(1 + δ) for δ = 0.5 which is a constant from Proposition 2, which we will need later on.",B. Proofs,[0],[0]
"Norm of e consists of the error fitting term LSG which we know, and the term depending on the previous µ value, since this is how much the solution for the SG problem evolved over last iteration.",B. Proofs,[0],[0]
"In such a setting, the main model changes iff
‖e‖‖∂h/∂θ<h‖ < 1/3‖∂L/∂θ<h‖. (2)
",B. Proofs,[0],[0]
"First of all, this takes place as long as ν is small enough since the linear SG is enough to represent ∂L/∂h with arbitrary precision (Proposition 1) and it is trained to do so in a way that always converges (as it is a linear regression fitted to a linear function).",B. Proofs,[0],[0]
So in the worst case scenario for a few first iterations we choose very small µ (it always exists since in the worst case scenario µ = 0 agrees with the inequality).,B. Proofs,[0],[0]
"Furthermore, once this happens we follow true gradient on θ>h and a noisy gradient on θ<h. Since the noise is equal to e∂h/∂θ<h we get that
‖e∂h/∂θ<h‖ ≤ ‖e‖‖∂h/∂θ<h‖ < 1/3‖∂L/∂θ<h‖,
which is equivalent to error for θ<h being upper bounded by (1 − δ)/(1 + δ)‖∂L/∂h‖ for δ = 0.5 which matches assumptions of Proposition 2, thus leading to the convergence of the model considered.",B. Proofs,[0],[0]
"If at any moment we lose track of the gradient again – the same mechanism kicks in - µ goes down for as long as the inequality (2) does not hold again (and it has to at some point, given ν is positive and small enough).",B. Proofs,[0],[0]
"All experiments were performed using TensorFlow (Abadi et al., 2016).",C. Technical details,[0.9788775795456872],"['All features are extracted using Stanford CoreNLP (Manning et al., 2014).']"
In all the experiments SG loss is the MSE between synthetic and true gradients.,C. Technical details,[0],[0]
"Since all SGs considered were linear, weights were initialized to zeros so initially SG produces zero gradients, and it does not affect convergence (since linear regression is convex).",C. Technical details,[0],[0]
"Each of the artificial datasets is a classification problem, consisting of X sampled from k-dimensional Gaussian distribution with zero mean and unit standard deviation.",Datasets,[0],[0]
For k = 2 we sample 100 points and for k = 100 we sample 1000.,Datasets,[0],[0]
"Labels y are generated in a way depending on the dataset name:
• lineark - we randomly sample an origin-crossing hyperplane (by sampling its parameters from standard Gaussians) and label points accordingly,
• noisyk - we label points according to lineark and then randomly swap labels of 10% of samples,
• randomk - points are labeled completely randomly.
",Datasets,[0],[0]
"We used one-hot encoding of binary labels to retain compatibility with softmax-based models, which is consistent with the rest of experiments.",Datasets,[0],[0]
However we also tested the same things with a single output neuron and regular sigmoid-based network and obtained analogous results.,Datasets,[0],[0]
"Optimisation is performed using the Adam optimiser (Kingma & Ba, 2014) with a learning rate of 3e−5.",Optimisation,[0],[0]
This applies to both main model and to SG module.,Optimisation,[0],[0]
"Table 2 shows results for training linear regression (shallow MSE), 10 hidden layer deep linear regression (deep MSE), logistic regression (shallow log loss) and 10 hidden layer deep linear classifier (deep log loss).",Artificial datasets,[0],[0]
"Since all these problems (after proper initialisation) converge to the global optima, we report the difference between final loss obtained for SG enriched models and the true global optimum.",Artificial datasets,[0],[0]
Networks used are simple feed forward networks with h layers of 512 hidden relu units followed by batch normalisation layers.,MNIST experiments,[0],[0]
The final layer is a regular 10-class softmax layer.,MNIST experiments,[0],[0]
"Inputs were scaled to [0, 1] interval, besides that there was no preprocessing applied.",MNIST experiments,[0],[0]
"In order to build RSMs for a layer h we sample 400 points (sorted according to their label) from the MNIST dataset, {xi}400i=1 and record activations on each of these points, hi = h(xi).",Representational Dissimilarity Matrices,[0],[0]
"Then we compute a matrix RSM such that RSMij = 1 − corr(hi, hj).",Representational Dissimilarity Matrices,[0],[0]
"Consequently a perfect RSM is a block diagonal matrix, thus elements of the same class have a representation with high correlation and the representations of points from two distinct classes are not correlated.",Representational Dissimilarity Matrices,[0],[0]
"Figure 7 is the extended version of the analogous Figure 3 from the main paper where we show RDMs for backpropagation, a single SG, SG in-between every two layers, and also the DFA model, when training 20 hidden layer deep relu network.
",Representational Dissimilarity Matrices,[0],[0]
"Understanding Synthetic Gradients and DNIs
dataset model MSE log loss
linear2 shallow 0.00000 0.03842 linear100 shallow 0.00002 0.08554 noisy2 shallow 0.00000 0.00036 noisy100 shallow",Representational Dissimilarity Matrices,[0],[0]
0.00002 0.00442 random2 shallow 0.00000 0.00000 random100 shallow 0.00004 0.00003 noisy2 deep 0.00000 0.00000 noisy100 deep 0.00001 0.00293 random2,Representational Dissimilarity Matrices,[0],[0]
"deep 0.00000 0.00000 random100 deep 0.00001 0.00004
Table 2.",Representational Dissimilarity Matrices,[0],[0]
Differences in final losses obtained for various models/datasets when trained with SG as compared to model trained with backpropagation.,Representational Dissimilarity Matrices,[0],[0]
Bolded entries denote experiments which converged to a different solution.,Representational Dissimilarity Matrices,[0],[0]
"lineark is k dimensional, linearly separable dataset, noisy is linearly separable up to 10% label noise, and random has completely random labeling.",Representational Dissimilarity Matrices,[0],[0]
"Shallow models means linear ones, while deep means 10 hidden layer deep linear models.",Representational Dissimilarity Matrices,[0],[0]
Reported differences are averaged across 10 different datasets from the same distributions.,Representational Dissimilarity Matrices,[0],[0]
One way of checking the degree to which the actual classification problem is solved at every layer of a feedforward network is to attach linear classifiers to every hidden layer and train them on the main task without backpropagating through the rest of the network.,Linear classifier/regression probes,[0],[0]
This way we can make a plot of train accuracy obtained from the representation at each layer.,Linear classifier/regression probes,[0],[0]
"As seen in Figure 8 (left) there is not much of the difference between such analysis for backpropagation and a single SG module, confirming our claim in the paper that despite different representations in both sections of SG based module - they are both good enough to solve the main problem.",Linear classifier/regression probes,[0],[0]
"We can also that DFA tries to solve the classification problem bottom-up as opposed to up-bottom – notice that for DFA we can have 100% accuracy after the very first hidden layer, which is not true even for backpropagation.
",Linear classifier/regression probes,[0],[0]
"We also introduced a new kind of linear probe, which tries to capture how much computation (non-linear transformations) are being used in each layer.",Linear classifier/regression probes,[0],[0]
"To achieve this, we at-
tach a linear regressor module after each hidden layer and regress it (with MSE) to the input of the network.",Linear classifier/regression probes,[0],[0]
"This is obviously label agnostic approach, but measures how non-linear the transformations are up to the given hidden layer.",Linear classifier/regression probes,[0],[0]
"Figure 8 (right) again confirms that with a single SG we have two parts of the network (thus results are similar to RDM experiments) which do have slightly different behaviour, and again show clearly that DFA performs lots of non-linear transformations very early on compared to all other methods.",Linear classifier/regression probes,[0],[0]
"In the main paper we show how SG modules using both activations and labels are able to implicitly describe the loss surface reasonably well for most of the training, with different datasets and losses.",Loss estimation,[0],[0]
"For completeness, we also include the same experiment for SG modules which do not use label information (Figure 9 (a) - (d)) as well as a module which does not use activations at all6 (Figure 9 (e) - (h))).",Loss estimation,[0],[0]
There are two important observations here:,Loss estimation,[0],[0]
"Firstly, none of these two approaches provide a loss estimation fidelity comparable with the full SG (conditioned on both activations and labels).",Loss estimation,[0],[0]
This gives another empirical confirmation for correct conditioning of the module.,Loss estimation,[0],[0]
"Secondly, models which used only labels did not converge to a good solutions after 100k iterations, while without the label SG was able to do so (however it took much longer and was far noisier).
",Loss estimation,[0],[0]
6This is more similar to a per-label stale gradient model.,Loss estimation,[0],[0]
"When training neural networks, the use of Synthetic Gradients (SG) allows layers or modules to be trained without update locking – without waiting for a true error gradient to be backpropagated – resulting in Decoupled Neural Interfaces (DNIs).",abstractText,[0],[0]
This unlocked ability of being able to update parts of a neural network asynchronously and with only local information was demonstrated to work empirically in Jaderberg et al. (2016).,abstractText,[0],[0]
"However, there has been very little demonstration of what changes DNIs and SGs impose from a functional, representational, and learning dynamics point of view.",abstractText,[0],[0]
"In this paper, we study DNIs through the use of synthetic gradients on feed-forward networks to better understand their behaviour and elucidate their effect on optimisation.",abstractText,[0],[0]
"We show that the incorporation of SGs does not affect the representational strength of the learning system for a neural network, and prove the convergence of the learning system for linear and deep linear models.",abstractText,[0],[0]
"On practical problems we investigate the mechanism by which synthetic gradient estimators approximate the true loss, and, surprisingly, how that leads to drastically different layer-wise representations.",abstractText,[0],[0]
"Finally, we also expose the relationship of using synthetic gradients to other error approximation techniques and find a unifying language for discussion and comparison.",abstractText,[0],[0]
Understanding Synthetic Gradients and Decoupled Neural Interfaces,title,[0],[0]
"ar X
iv :1
70 4.
05 75
3v 2
[ cs
.C L
] 1
9 O
ct 2
01 7
Linguistically diverse datasets are critical for training and evaluating robust machine learning systems, but data collection is a costly process that often requires experts. Crowdsourcing the process of paraphrase generation is an effective means of expanding natural language datasets, but there has been limited analysis of the trade-offs that arise when designing tasks. In this paper, we present the first systematic study of the key factors in crowdsourcing paraphrase collection. We consider variations in instructions, incentives, data domains, and workflows. We manually analyzed paraphrases for correctness, grammaticality, and linguistic diversity. Our observations provide new insight into the trade-offs between accuracy and diversity in crowd responses that arise as a result of task design, providing guidance for future paraphrase generation procedures.",text,[0],[0]
"Paraphrases are useful for a range of tasks, including machine translation evaluation (Kauchak and Barzilay, 2006), semantic parsing (Wang et al., 2015), and question answering (Fader et al., 2013).",1 Introduction,[0],[0]
"Crowdsourcing has been widely used as a scalable and cost-effective means of generating paraphrases (Negri et al., 2012; Wang et al., 2012; Tschirsich and Hintz, 2013), but there has been limited analysis of the factors influencing diversity and correctness of the paraphrases workers write.
",1 Introduction,[0],[0]
"In this paper, we perform a systematic investigation of design decisions for crowdsourcing paraphrases, including the first exploration of worker incentives for paraphrasing.",1 Introduction,[0],[0]
"For worker incentives, we either provide a bonus payment when a paraphrase is novel (encouraging diversity) or
when it matches a paraphrase from another worker (encouraging agreement/correctness).",1 Introduction,[0],[0]
"We also varied the type of example paraphrases shown to workers, the number of paraphrases requested from each worker per sentence, the subject domain of the data, whether to show answers to questions, and whether the prompt sentence is the same for multiple workers or varies, with alternative prompts drawn from the output of other workers.
",1 Introduction,[0],[0]
Effective paraphrasing has two desired properties: correctness and diversity.,1 Introduction,[0],[0]
"To measure correctness, we hand-labeled all paraphrases with semantic equivalence and grammaticality scores.",1 Introduction,[0],[0]
"For diversity, we measure the fraction of paraphrases that are distinct, as well as Paraphrase In N-gram Changes (PINC), a measure of n-gram variation.",1 Introduction,[0],[0]
"We have released all 2,600 paraphrases along with accuracy annotations.",1 Introduction,[0],[0]
"Our analysis shows that the most important factor is how workers are primed for a task, with the choice of examples and the prompt sentence affecting diversity and correctness significantly.",1 Introduction,[0],[0]
"Previous work on crowdsourced paraphrase generation fits into two categories: work on modifying the creation process or workflow, and studying the effect of prompting or priming on crowd worker output.",2 Related Work,[0],[0]
"Beyond crowdsourced generation, other work has explored using experts or automated systems to generate paraphrases.",2 Related Work,[0],[0]
The most common approach to crowdsourcing paraphrase generation is to provide a sentence as a prompt and request a single paraphrase from a worker.,2.1 Workflows for Crowd-Paraphrasing,[0],[0]
"One frequent addition is to ask a different set of workers to evaluate whether a generated paraphrase is correct (Buzek et al., 2010; Burrows et al., 2013).",2.1 Workflows for Crowd-Paraphrasing,[0],[0]
"Negri et al. (2012) also explored an alternate workflow in which each worker writes
two paraphrases, which are then given to other workers as the prompt sentence, forming a binary tree of paraphrases.",2.1 Workflows for Crowd-Paraphrasing,[0],[0]
"They found that paraphrases deeper in the tree were more diverse, but understanding how correctness and grammaticality vary across such a tree still remains an open question.",2.1 Workflows for Crowd-Paraphrasing,[0],[0]
"Near real-time crowdsourcing (Bigham et al., 2010) allowed Lasecki et al. (2013a) to elicit variations on entire conversations by providing a setting and goal to pairs of crowd workers.",2.1 Workflows for Crowd-Paraphrasing,[0],[0]
"Continuous real-time crowdsourcing (Lasecki et al., 2011) allows Chorus Lasecki et al. (2013b) users to hold conversations with groups of crowd workers as if the crowd was a single individual, allowing for the collection of example conversations in more realistic settings.",2.1 Workflows for Crowd-Paraphrasing,[0],[0]
"The only prior work regarding incentives we are aware of is by Chklovski (2005), who collected paraphrases in a game where the goal was to match an existing paraphrase, with extra points awarded for doing so with fewer hints.",2.1 Workflows for Crowd-Paraphrasing,[0],[0]
The disadvantage of this approach was that 29% of the collected paraphrases were duplicates.,2.1 Workflows for Crowd-Paraphrasing,[0],[0]
"In our experiments, duplication ranged from 1% to 13% in each condition.",2.1 Workflows for Crowd-Paraphrasing,[0],[0]
"When crowd workers perform a task, they are primed (influenced) by the examples, instructions, and context that they see.",2.2 The Effects of Priming,[0],[0]
This priming can result in systematic variations in the resulting paraphrases.,2.2 The Effects of Priming,[0],[0]
"Mitchell et al. (2014) showed that providing context, in the form of previous utterances from a dialogue, only provides benefits once four or more are included.",2.2 The Effects of Priming,[0],[0]
"Kumaran et al. (2014) provided drawings as prompts, obtaining diverse paraphrases, but without exact semantic equivalence.",2.2 The Effects of Priming,[0],[0]
"When each sentence expresses a small set of slot-filler predicates, Wang et al. (2012) found that providing the list of predicates led to slightly faster paraphrasing than giving either a complete sentence or a short sentence for each predicate.",2.2 The Effects of Priming,[0],[0]
We further expand on this work by exploring how the type of examples shown affects paraphrasing.,2.2 The Effects of Priming,[0],[0]
"Finally, there are two general lines of research on paraphrasing not focused on using crowds.",2.3 Expert and Automated Generation,[0],[0]
"The first of these is the automatic collection of paraphrases from parallel data sources, such as translations of the same text or captions for the same image (Ganitkevitch et al., 2013; Chen and Dolan, 2011; Bouamor et al., 2012; Pavlick et al.,
2015).",2.3 Expert and Automated Generation,[0],[0]
"These resources are extremely large, but usually (1) do not provide the strong semantic equivalence we are interested in, and (2) focus on phrases rather than complete sentences.",2.3 Expert and Automated Generation,[0],[0]
"The second line of work explores the creation of lattices that compactly encode hundreds of thousands of paraphrases (Dreyer and Marcu, 2012; Bojar et al., 2013).",2.3 Expert and Automated Generation,[0],[0]
"Unfortunately, these lattices are typically expensive to produce, taking experts one to three hours per sentence.",2.3 Expert and Automated Generation,[0],[0]
We conducted a series of experiments to investigate factors in crowdsourced paraphrase creation.,3 Experimental Design,[0],[0]
"To do so in a controlled manner, we studied a single variation per condition.",3 Experimental Design,[0],[0]
This project was motivated by the need for strongly equivalent paraphrases in semantic parsing datasets.,3.1 Definition of Valid Paraphrases,[0],[0]
"We consider two sentences paraphrases if they would have equivalent interpretations when represented as a structured query, i.e., ”a pair of units of text deemed to be interchangeable” (Dras, 1999).",3.1 Definition of Valid Paraphrases,[0],[0]
"For example:
Prompt: Which upper-level classes are four credits?",3.1 Definition of Valid Paraphrases,[0],[0]
"Are there any four credit upper-level classes?
",3.1 Definition of Valid Paraphrases,[0],[0]
"We considered the above two questions as paraphrases since they are both requests for a list of classes, explicit and implicit, respectively, although the second one is a polar question and the first one is not.",3.1 Definition of Valid Paraphrases,[0],[0]
"However:
Prompt:Which is easier out of EECS 378 and EECS 280?",3.1 Definition of Valid Paraphrases,[0],[0]
"Is EECS 378 easier than EECS 280?
",3.1 Definition of Valid Paraphrases,[0],[0]
"We did not consider the above two questions as paraphrases since the first one is requesting one of
two class options and the second one is requesting a yes or no answer.",3.1 Definition of Valid Paraphrases,[0],[0]
"We used Amazon Mechanical Turk, presenting workers with the instructions and examples in Figure 1.",3.2 Baseline,[0],[0]
"Workers were shown prompt sentences one at a time, and asked to provide two paraphrases for each.",3.2 Baseline,[0],[0]
"To avoid confusion or training effects between different conditions, we only allowed workers to participate once across all conditions.",3.2 Baseline,[0],[0]
"The initial instructions shown to workers were the same across all conditions (variations were only seen after a worker accepted the task).
",3.2 Baseline,[0],[0]
"Workers were paid 5 cents per paraphrase they wrote plus, once all workers were done, a 5 cent bonus for paraphrases that matched another worker’s paraphrase in the same condition.",3.2 Baseline,[0],[0]
"While we do not actually want duplicate paraphrases, this incentive may encourage workers to more closely follow the instructions, producing grammatical and correct sentences.",3.2 Baseline,[0],[0]
"We chose this payment rate to give around minimum wage, estimating time based on prior work.",3.2 Baseline,[0],[0]
"Examples We provided workers with an example prompt sentence and two paraphrases, as shown in Figure 1.",3.3 Conditions,[0],[0]
"We showed either: no examples (No Examples), two examples with lexical changes only (Lexical Examples), one example with lexical changes and one with syntactic changes (Mixed Examples), or two examples that each contained both lexical and syntactic changes (Baseline).",3.3 Conditions,[0],[0]
"The variations between these conditions may prime workers differently, leading them to generate different paraphrases.
",3.3 Conditions,[0],[0]
"Incentive The 5 cent bonus payment per paraphrase was either not included (No Bonus), awarded for each sentence that was a duplicate at the end of the task (Baseline), or awarded for each sentence that did not match any other worker’s paraphrase (Novelty Bonus).",3.3 Conditions,[0],[0]
Bonuses that depend on other workers’ actions may encourage either creativity or conformity.,3.3 Conditions,[0],[0]
"We did not vary the base level of payment because prior work has found that workers work quality is not increased by increased financial incentives due to an anchoring effect relative to the base rate we define (Mason and Watts, 2010).
",3.3 Conditions,[0],[0]
Workflow We considered three variations to workflow.,3.3 Conditions,[0],[0]
"First, for each sentence, we either asked workers to provide two paraphrases (Baseline), or one (One Paraphrase).",3.3 Conditions,[0],[0]
"Asking for multiple paraphrases reduces duplication (since workers will not repeat themselves), but may result in lower diversity.",3.3 Conditions,[0],[0]
"Second, since our baseline prompt sentences are questions, we ran a condition with answers shown to workers (Answers).",3.3 Conditions,[0],[0]
"Third, we started all conditions with the same set of prompt sentences, but once workers had produced paraphrases, we had the option to either prompt future workers with the original prompt, or to use paraphrase from another worker.",3.3 Conditions,[0],[0]
"Treating sentences as points and the act of paraphrasing as creating an edge, the space can be characterized as a graph.",3.3 Conditions,[0],[0]
"We prompted workers with either the original sentences only (Baseline), or formed a chain structured graph by randomly choosing a sentence that was (1) not a duplicate, and (2) furthest from the original sentence (Chain).",3.3 Conditions,[0],[0]
"These changes could impact paraphrasing because the prompt sentence is a form of priming.
Data domains We ran with five data sources: questions about university courses (Baseline), messages from dialogues between two students in a simulated academic advising session (ADVISING), questions about US geography (GEOQUERY Tang and Mooney, 2001), text from the Wall Street Journal section of the Penn Treebank (WSJ Marcus et al., 1993), and discussions on the Ubuntu IRC channel (UBUNTU).",3.3 Conditions,[0],[0]
We randomly selected 20 sentences as prompts from each data source with the lengths representative of the sentence length distribution in that source.,3.3 Conditions,[0],[0]
"Semantic Equivalence For a paraphrase to be valid, its meaning must match the original sentence.",3.4 Metrics,[0],[0]
"To assess this match, two of the authors— one native speaker and one non-native but fluent speaker—rated every sentence independently, then discussed every case of disagreement to determine a consensus judgement.",3.4 Metrics,[0],[0]
"Prior to the consensusfinding step, the inter-annotator agreement kappa scores were .50 for correctness (moderate agreement), and .36 for grammaticality (fair agreement) (Altman, 1990).",3.4 Metrics,[0],[0]
"For the results in Table 1, we used a χ2 test to measure significance, since this is a binary classification process.
",3.4 Metrics,[0],[0]
"Grammaticality We also judged whether the sentences were grammatical, again with two annotators rating every sentence and resolving disagreements.",3.4 Metrics,[0],[0]
"Again, since this was a binary classification, we used a χ2 test for significance.
",3.4 Metrics,[0],[0]
"Time The time it takes to write paraphrases is important for estimating time-to-completion, and ensuring workers receive fair payment.",3.4 Metrics,[0],[0]
We measured the time between when a worker submitted one pair of paraphrases and the next.,3.4 Metrics,[0],[0]
The first paraphrase was excluded since it would skew the data by including the time spent reading the instructions and understanding the task.,3.4 Metrics,[0],[0]
"We report the median time to avoid skewing due to outliers, e.g. a value of five minutes when a worker probably took a break.",3.4 Metrics,[0],[0]
"We apply Mood’s Median test for statistical significance.
",3.4 Metrics,[0],[0]
"Diversity We use two metrics for diversity, measured over correct sentences only.",3.4 Metrics,[0],[0]
"First, a simple measurement of exact duplication: the number of distinct paraphrases divided by the total number of paraphrases, as a percentage (Distinct).",3.4 Metrics,[0],[0]
"Second, a measure of n-gram diversity (PINC Chen and Dolan, 2011)1.",3.4 Metrics,[0],[0]
"In both cases, a higher score means greater diversity.",3.4 Metrics,[0],[0]
"For PINC, we used a ttest for statistical significance, and for Distinct we used a permutation test.",3.4 Metrics,[0],[0]
"We collected 2600 paraphrases: 10 paraphrases per sentence, for 20 sentences, for each of the 13 conditions.",4 Results,[0],[0]
"The cost, including initial testing, was $196.30, of which $20.30 was for bonus payments.",4 Results,[0],[0]
Table 1 shows the results for all metrics.,4 Results,[0],[0]
"Qualitatively, we observed a wide variety of lexical and syntactic changes, as shown by these example prompts and paraphrases (one low PINC and one high PINC in each case):
Prompt: How long has EECS 280 been offered for?",4.1 Discussion: Task Variation,[0],[0]
How long has EECS 280 been offered?,4.1 Discussion: Task Variation,[0],[0]
"EECS 280 has been in the course listings how many years?
",4.1 Discussion: Task Variation,[0],[0]
Prompt: Can I take 280 on Mondays and Wednesdays?,4.1 Discussion: Task Variation,[0],[0]
"On Mondays and Wednesdays, can I take 280?",4.1 Discussion: Task Variation,[0],[0]
"Is 280 available as a Monday/Wednesday class?
",4.1 Discussion: Task Variation,[0],[0]
There was relatively little variation in grammaticality or time across the conditions.,4.1 Discussion: Task Variation,[0],[0]
"The times
1 We also considered BLEU (Papineni et al., 2002), which measures n-gram overlap and is used as a proxy for correctness in MT.",4.1 Discussion: Task Variation,[0],[0]
"As expected, it strongly correlated with PINC.
",4.1 Discussion: Task Variation,[0],[0]
"we observed are consistent with prior work: e.g. Wang et al. (2015) report ∼28 sec/paraphrase.
",4.1 Discussion: Task Variation,[0],[0]
"Priming had a major impact, with the shift to lexical examples leading to a significant improvement in correctness, but much lower diversity.",4.1 Discussion: Task Variation,[0],[0]
The surprising increase in correctness when providing no examples has a p-value of 0.07 and probably reflects random variation in the pool of workers.,4.1 Discussion: Task Variation,[0],[0]
"Meanwhile, changing the incentives by providing either a bonus for novelty, or no bonus at all, did not substantially impact any of the metrics.
",4.1 Discussion: Task Variation,[0],[0]
Changing the number of paraphrases written by each worker did not significantly impact diversity (we worried that collecting more than one may lead to a decrease).,4.1 Discussion: Task Variation,[0],[0]
"We further confirmed this by calculating PINC between the two paraphrases provided by each user, which produced scores similar to comparing with the prompt.",4.1 Discussion: Task Variation,[0],[0]
"However, the One Paraphrase condition did have lower grammaticality, emphasizing the value of evaluating and filtering out workers who write ungrammatical paraphrases.
",4.1 Discussion: Task Variation,[0],[0]
Changing the source of the prompt sentence to create a chain of paraphrases led to a significant increase in diversity.,4.1 Discussion: Task Variation,[0],[0]
This fits our intuition that the prompt is a form of priming.,4.1 Discussion: Task Variation,[0],[0]
"However, correctness decreases along the chain, suggesting the need to check paraphrases against the original sentence during the overall process, possibly using other workers as described in § 2.1.",4.1 Discussion: Task Variation,[0],[0]
"Meanwhile, showing the answer to the question being para-
phrased did not significantly affect correctness or diversity, and in 2.5% of cases workers incorrectly used the answer as part of their paraphrase.
",4.1 Discussion: Task Variation,[0],[0]
We also analyzed the distribution of incorrect or ungrammatical paraphrases by worker.,4.1 Discussion: Task Variation,[0],[0]
"7% of workers accounted for 25% of incorrect paraphrases, while the best 30% of workers made no mistakes at all.",4.1 Discussion: Task Variation,[0],[0]
"Similarly, 8% of workers wrote 50% of the ungrammatical paraphrases, while 70% of workers wrote only grammatical paraphrases.",4.1 Discussion: Task Variation,[0],[0]
"Many crowdsourcing tasks address these issues by showing workers some gold standard instances, to evaluate workers’ performance during annotation.",4.1 Discussion: Task Variation,[0],[0]
"Unfortunately, in paraphrasing there is no single correct answer, though other workers could be used to check outputs.
",4.1 Discussion: Task Variation,[0],[0]
"Finally, we checked the distribution of incorrect paraphrases per prompt sentence.",4.1 Discussion: Task Variation,[0],[0]
"Two prompts accounted for 22% of incorrect paraphrases:
",4.1 Discussion: Task Variation,[0],[0]
Prompt:Which is easier out of EECS 378 and EECS 280?,4.1 Discussion: Task Variation,[0],[0]
"Is EECS 378 easier than EECS 280?
",4.1 Discussion: Task Variation,[0],[0]
Prompt: Is Professor Stout the only person who teaches Algorithms?,4.1 Discussion: Task Variation,[0],[0]
"Are there professors other than Stout who teach Algorithms?
",4.1 Discussion: Task Variation,[0],[0]
"These paraphrases are not semantically equivalent to the original question, but they would elicit equivalent information, which explains why workers provided them.",4.1 Discussion: Task Variation,[0],[0]
Providing negative examples may help guide workers to avoid such mistakes.,4.1 Discussion: Task Variation,[0],[0]
"The bottom section of Table 1 shows measurements using the baseline setup, but with variations in the source domain of data.",4.2 Discussion: Domains,[0],[0]
"The only significant change in correctness is on UBUNTU, which is probably due to the extensive use of jargon in the dataset, for example:
",4.2 Discussion: Domains,[0],[0]
"Prompt: ok, what does journalctl show That journalistic show is about what?
",4.2 Discussion: Domains,[0],[0]
"For grammaticality, GEOQUERY is particularly low; common mistakes included confusion between singular/plural and has/have.",4.2 Discussion: Domains,[0],[0]
WSJ is the domain with the greatest variations.,4.2 Discussion: Domains,[0],[0]
"It has considerably longer sentences on average, which explains the greater time taken.",4.2 Discussion: Domains,[0],[0]
"This could also explain the lower distinctness and PINC score, because workers would often retain large parts of the sentence, sometimes re-arranged, but otherwise unchanged.",4.2 Discussion: Domains,[0],[0]
"While previous work has used crowdsourcing to generate paraphrases, we perform the first systematic study of factors influencing the process.",5 Conclusion,[0],[0]
"We find that the most substantial variations are caused by priming effects: using simpler examples leads to lower diversity, but more frequent semantic equivalence.",5 Conclusion,[0],[0]
"Meanwhile, prompting workers with paraphrases collected from other workers (rather than re-using the original prompt) increases diversity.",5 Conclusion,[0],[0]
"Our findings provide clear guidance for future paraphrase generation, supporting the creation of larger, more diverse future datasets.",5 Conclusion,[0],[0]
"We would like to thank the members of the UMich/IBM Sapphire project, as well as all of our study participants and the anonymous reviewers for their helpful suggestions on this work.
",6 Acknowledgements,[0],[0]
This material is based in part upon work supported by IBM under contract 4915012629 .,6 Acknowledgements,[0],[0]
"Any opinions, findings, conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of IBM.",6 Acknowledgements,[0],[0]
"Linguistically diverse datasets are critical for training and evaluating robust machine learning systems, but data collection is a costly process that often requires experts.",abstractText,[0],[0]
"Crowdsourcing the process of paraphrase generation is an effective means of expanding natural language datasets, but there has been limited analysis of the trade-offs that arise when designing tasks.",abstractText,[0],[0]
"In this paper, we present the first systematic study of the key factors in crowdsourcing paraphrase collection.",abstractText,[0],[0]
"We consider variations in instructions, incentives, data domains, and workflows.",abstractText,[0],[0]
"We manually analyzed paraphrases for correctness, grammaticality, and linguistic diversity.",abstractText,[0],[0]
"Our observations provide new insight into the trade-offs between accuracy and diversity in crowd responses that arise as a result of task design, providing guidance for future paraphrase generation procedures.",abstractText,[0],[0]
Understanding Task Design Trade-offs in Crowdsourced Paraphrase Collection,title,[0],[0]
"Local search algorithms like stochastic gradient descent [4] or variants have gained huge success in training deep neural networks (see, [5];",1 Introduction,[0],[0]
"[6]; [7], for example).",1 Introduction,[0],[0]
"Despite the spurious saddle points and local minima on the loss surface [3], it has been widely conjectured that all local minima of the empirical loss lead to similar training performance [1, 2].",1 Introduction,[0],[0]
"For example, [8] empirically showed that neural networks with identical architectures but different initialization points can converge to local minima with similar classification performance.",1 Introduction,[0],[0]
"However, it still remains a challenge to characterize the theoretical properties of the loss surface for neural networks.
",1 Introduction,[0],[0]
"In the setting of regression problems, theoretical justifications has been established to support the conjecture that all local minima lead to similar training performance.",1 Introduction,[0],[0]
"For shallow models, [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] provide conditions under which the local search algorithms are guaranteed to converge to the globally optimal solution for the regression problem.",1 Introduction,[0],[0]
"For deep linear networks, it has been shown that every local minimum of the empirical loss is a global minimum [21, 22, 23, 24, 25].",1 Introduction,[0],[0]
"In order to characterize the loss surface of more general deep networks for regression tasks, [2] have proposed an interesting approach.",1 Introduction,[0],[0]
"Based on certain constructions on network models and additional assumptions, they relate the loss function to a spin glass model and show that the almost all local minima have similar empirical loss and the number of bad local minima decreases quickly with the distance to the global optimum.",1 Introduction,[0],[0]
"Despite the interesting results, it remains a concern to properly justify their assumptions.",1 Introduction,[0],[0]
"More recently, it has been shown [26, 27] that, when the dataset satisfies certain conditions, if one layer in the multilayer network has more neurons than the number of training samples, then a subset of local minima are global minima.
∗University of Illinois at Urbana-Champaign †Facebook Research
ar X
iv :1
80 3.
00 90
9v 2
[ cs
.L G
] 5
M ar
2 01
Although the loss surfaces in regression tasks have been well studied, the theoretical understanding of loss surfaces in classification tasks is still limited.",1 Introduction,[0],[0]
"[27, 28, 29] treat the classification problem as the regression problem by using quadratic loss, and show that (almost) all local minima are global minima.",1 Introduction,[0],[0]
"However, the global minimum of the quadratic loss does not necessarily have zero misclassification error even in the simplest cases (e.g., every global minimum of quadratic loss can have non-zero misclassification error even when the dataset is linearly separable and the network is a linear network).",1 Introduction,[0],[0]
"This issue was mentioned in [26] and a different loss function was used, but their result only studied the linearly separable case and a subset of the critical points.
",1 Introduction,[0],[0]
"In view of the prior work, the context and contributions of our paper are as follows:
• Prior work on quadratic and related loss functions suggest that one can achieve zero misclassification error at all local minima by overparameterizing the neural network.",1 Introduction,[0],[0]
"The reason for over-parameterization is that the quadratic loss function tries to match the output of the neural network to the label of each training sample.
",1 Introduction,[0],[0]
"• On the other hand, hinge loss-type functions only try to match the sign of the outputs with the labels.",1 Introduction,[0],[0]
So it may be possible to achieve zero misclassification error without over-parametrization.,1 Introduction,[0],[0]
"We provide conditions under which the misclassification error of neural networks is zero at all local minima for hinge-loss functions.
",1 Introduction,[0],[0]
"• Our conditions are roughly in the following form: the neurons have to be increasing and strictly convex, the neural network should either be single-layered or is multi-layered with a shortcut-like connection and the surrogate loss function should be a smooth version of the hinge loss function.
",1 Introduction,[0],[0]
"• We also provide counterexamples to show that when these conditions are relaxed, the result may not hold.
",1 Introduction,[0],[0]
• We establish our results under the assumption that either the dataset is linearly separable or the positively and negatively labeled samples are located on different subspaces.,1 Introduction,[0],[0]
"Whether this assumption is necessary is an open problem, except in the case of certain special neurons.
",1 Introduction,[0],[0]
The outline of this paper is as follows.,1 Introduction,[0],[0]
"In Section 2, we present the necessary definitions.",1 Introduction,[0],[0]
"In Section 3, we present the main results and we discuss each condition in Section 4.",1 Introduction,[0],[0]
Conclusions are presented in Section 5.,1 Introduction,[0],[0]
All proofs are provided in Appendix.,1 Introduction,[0],[0]
Network models.,2 Preliminaries,[0],[0]
"Given an input vector x of dimension d, we consider a neural network with L layers for binary classification.",2 Preliminaries,[0],[0]
We denote by Ml the number of neurons on the l-th layer (note that M0 = d and ML = 1).,2 Preliminaries,[0],[0]
We denote the neuron activation function by σ.,2 Preliminaries,[0],[0]
Let Wl ∈ RMl−1×Ml denote the weight matrix connecting the (l − 1)-th layer and the l-th layer and bl ∈ RMl denote the bias vector for the neurons in the l-th layer.,2 Preliminaries,[0],[0]
"Therefore, the output of the network f : Rd → R can be expressed by
f(x;θ) =",2 Preliminaries,[0],[0]
W>L σ,2 Preliminaries,[0],[0]
"( ...σ(W>1 x+ b1) + bL−1 ) + bL,
where θ denotes all parameters in the neural network.",2 Preliminaries,[0],[0]
Data distribution.,2 Preliminaries,[0],[0]
"In this paper, we consider binary classification tasks where each sample (X,",2 Preliminaries,[0],[0]
Y ) ∈ Rd,2 Preliminaries,[0],[0]
"× {−1, 1} is drawn from an underlying data distribution PX×Y defined on Rd × {−1, 1}.",2 Preliminaries,[0],[0]
"The sample (X, Y ) is considered positive if Y = 1, and negative otherwise.",2 Preliminaries,[0],[0]
"Let E = {e1, ..., ed} denote a set of orthonormal basis on the space Rd.",2 Preliminaries,[0],[0]
"Let U+ and U− denote two subsets of E such that all
positive and negative samples are located on the linear span of the set U+ and U−, respectively, i.e., PX|Y (X ∈ Span(U+)|Y = 1) = 1 and PX|Y (X ∈ Span(U−)|Y = −1) = 1.",2 Preliminaries,[0],[0]
"Let r denote the size of the set U+ ∪ U−, r+ denote the size of the set U+ and r− denote the size of the set U−, respectively.",2 Preliminaries,[0],[0]
Loss and error.,2 Preliminaries,[0],[0]
"Let D = {(xi, yi)}ni=1 denote a dataset with n samples, each independently drawn from the distribution PX×Y .",2 Preliminaries,[0],[0]
"Given a neural network f(x;θ) parameterized by θ and a loss function ` : R → R, in binary classification tasks1, we define the empirical loss L̂n(θ) as the average loss of the network f on a sample in the dataset D, i.e.,
L̂n(θ)",2 Preliminaries,[0],[0]
"= 1
n n∑ i=1",2 Preliminaries,[0],[0]
"`(−yif(xi;θ)).
",2 Preliminaries,[0],[0]
"Furthermore, for a neural network f , we define a binary classifier gf :",2 Preliminaries,[0],[0]
"Rd → {−1, 1} of the form gf = sgn(f), where the sign function sgn(z) = 1, if z ≥ 0, and sgn(z) = 0",2 Preliminaries,[0],[0]
otherwise.,2 Preliminaries,[0],[0]
"We define the training error (also called the misclassification error) R̂n(θ) as the misclassification rate of the neural network f(x;θ) on the dataset D, i.e.,
R̂n(θ)",2 Preliminaries,[0],[0]
"= 1
n n∑ i=1",2 Preliminaries,[0],[0]
"I{yi 6= sgn(f(xi;θ))},
where I{·} is the indicator function.",2 Preliminaries,[0],[0]
The training error R̂n measures the classification performance of the network f on the finite samples in the dataset D.,2 Preliminaries,[0],[0]
"In this section, we present the main results.",3 Main Results,[0],[0]
"We first introduce several important conditions in order to derive the main results, and we will provide further discussions on these conditions in the next section.",3 Main Results,[0],[0]
"To fully specify the problem, we need to specify our assumptions on several components of the model, including: (1) the loss function, (2) the data distribution, (3) the network architecture and (4) the neuron activation function.
",3.1 Conditions,[0],[0]
"Assumption 1 (Loss function) Let `p : R → R denote a loss function satisfying the following conditions: (1) `p is a surrogate loss function, i.e., `p(z) ≥",3.1 Conditions,[0],[0]
"I{z ≥ 0} for all z ∈ R, where I(·) denotes the indicator function; (2) `p has continuous derivatives up to order p on R; (3) `p is non-decreasing (i.e., `′p(z) ≥ 0 for all z ∈ R) and there exists a positive constant z0 such that `′p(z) = 0 iff z ≤ −z0.
",3.1 Conditions,[0],[0]
"The first condition in Assumption 1 ensures that the training error R̂n is always upper bounded by the empirical loss L̂n, i.e., R̂n ≤ L̂n.",3.1 Conditions,[0],[0]
"This guarantees that the neural network can correctly classify all samples in the dataset (i.e., R̂n = 0), when the neural network achieves zero empirical loss (i.e., L̂n = 0).",3.1 Conditions,[0],[0]
The second condition ensures that the empirical loss L̂n has continuous derivatives with respect to the parameters up to a sufficiently high order.,3.1 Conditions,[0],[0]
The third condition ensures that the loss function is non-decreasing and `′p(z) = 0 is achievable if and only if z ≤ −z0.,3.1 Conditions,[0],[0]
"Here, we provide a simple example of the loss function satisfying all conditions in Assumption 1: the polynomial hinge loss, i.e., `p(z) =",3.1 Conditions,[0],[0]
"[max{z + 1, 0}]p+1.",3.1 Conditions,[0],[0]
"We note that, in this paper, we use L̂n(θ; p) to denote the empirical loss
1We note that, in regression tasks, the empirical loss is usually defined as L̂n(θ)",3.1 Conditions,[0],[0]
= 1 n,3.1 Conditions,[0],[0]
∑n i=1,3.1 Conditions,[0],[0]
"`(yi − f(xi;θ)).
",3.1 Conditions,[0],[0]
when the loss function is `p and the network is parametrized by a set of parameters θ.,3.1 Conditions,[0],[0]
"Further results on the impact of loss functions are presented in Section 4.
",3.1 Conditions,[0],[0]
"Assumption 2 (Data distribution) Assume that for random vectors X1, ...,Xr+ independently drawn from the distribution PX|Y=1 and Z1, ...,Zr− independently drawn from the distribution PX|Y=−1, matrices ( X1, ...,Xr+ )",3.1 Conditions,[0],[0]
"∈ Rr+×d and ( Z1, ...,Zr− ) ∈ Rr−×d are full rank matrices with probability one.
",3.1 Conditions,[0],[0]
Assumption 2 states that support of the conditional distribution PX|Y=1 is sufficiently rich so that r+ samples drawn from it will be linearly independent.,3.1 Conditions,[0],[0]
"In other words, by stating this assumption, we are avoiding trivial cases where all the positively labeled points are located in a very small subset of the linear span of U+.",3.1 Conditions,[0],[0]
"Similarly for the negatively labeled samples.
Assumption 3 (Data distribution) Assume |U+ ∪ U−|",3.1 Conditions,[0],[0]
>,3.1 Conditions,[0],[0]
"max{|U+|, |U−|}, i.e., r > max{r+, r−}.
",3.1 Conditions,[0],[0]
Assumption 3 assumes that the positive and negative samples are not located on the same linear subspace.,3.1 Conditions,[0],[0]
"Previous works [30, 31, 32, 30] have observed that some classes of natural images (e.g., images of faces, handwritten digits, etc) can be reconstructed from lower-dimensional representations.",3.1 Conditions,[0],[0]
"For example, using dimensionality reduction methods such as PCA, one can approximately reconstruct the original image from only a small number of principal components [30, 31].",3.1 Conditions,[0],[0]
"Here, Assumption 3 states that both the positively and negatively labeled samples have lower-dimensional representations, and they do not exist in the same lower-dimensional subspace.",3.1 Conditions,[0],[0]
"We provide additional analysis in Section 4, showing how our main results generalize to other data distributions.
",3.1 Conditions,[0],[0]
"Assumption 4 (Network architecture) Assume that the neural network f is a single-layered neural network, or more generally, has shortcut-like connections shown in Fig 1 (b), where fS is a single layer network and fD is a feedforward network.
",3.1 Conditions,[0],[0]
"Shortcut connections are widely used in the modern network architectures (e.g., Highway Networks [34], ResNet [33], DenseNet [35], etc.), where the skip connections allow the deep layers to have direct access to the outputs of shallow layers.",3.1 Conditions,[0],[0]
"For instance, in the residual network, each residual block has a identity shortcut connection, shown in Fig 1 (a), where the output of each residual block is the vector sum of its input and the output of a network H.
Instead of using the identity shortcut connection, in this paper, we first pass the input through a single layer network fS(x;θS) = a0 + a >σ",3.1 Conditions,[0],[0]
"( W>x ) , where vector a denotes the weight vector, matrix W denotes the weight matrix and vector θS denotes the vector containing all parameters in fS .",3.1 Conditions,[0],[0]
"We next add the output of this network to a network fD and use the addition as the output of the whole network, i.e., f(x;θ) = fS(x;θS) + fD(x;θD), where vector θD and θ denote the vector containing all parameters in the
network fD and the whole network f , respectively.",3.1 Conditions,[0],[0]
"We note here that, in this paper, we do not restrict the number of layers and neurons in the network fD and this means that the network fD can be a feedforward network introduced in Section 2 or a single layer network or even a constant.",3.1 Conditions,[0],[0]
"In fact, when the network fD is a single layer network or a constant, the whole network f becomes a single
layer network.",3.1 Conditions,[0],[0]
"Furthermore, we note that, in Section 4, we will show that if we remove this connection or replace this shortcut-like connection with the identity shortcut connection, the main result does not hold.
",3.1 Conditions,[0],[0]
Assumption 5 (Neuron activation) Assume that neurons σ(z) in the network fS are real analytic and satisfy σ′′(z),3.1 Conditions,[0],[0]
> 0,3.1 Conditions,[0],[0]
"for all z ∈ R. Assume that neurons in the network fD are real functions on R.
In Assumption 5, we assume that neurons in the network fS are infinitely differentiable and have positive second order derivatives on R, while neurons in the network fD are real functions.",3.1 Conditions,[0],[0]
"We make the above assumptions to ensure that the loss function L̂n(θS ,θD; p) is partially differentiable w.r.t.",3.1 Conditions,[0],[0]
the parameters θS in the network fS up to a sufficiently high order and allow us to use Taylor expansion in the analysis.,3.1 Conditions,[0],[0]
"Here, we list a few neurons which can be used in the network fS : softplus neuron, i.e., σ(z) = log2(1+e
z), quadratic neuron, i.e, σ(z) = z2, etc.",3.1 Conditions,[0],[0]
"We note that neurons in the network fS and fD do not need to be of the same type and this means that a more general class of neurons can be used in the network fD, e.g., threshold neuron, i.e., σ(z) = I{z ≥ 0}, rectified linear unit σ(z) = max{z, 0}, sigmoid neuron σ(z) = 1
1+e−z , etc.",3.1 Conditions,[0],[0]
Further discussion on the effects of neurons on the main results are provided in Section 4.,3.1 Conditions,[0],[0]
"Now we present the following theorem to show that when assumptions 1-5 are satisfied, every local minimum of the empirical loss function has zero training error if the number of neurons in the network fS are chosen appropriately.
",3.2 Main Results,[0],[0]
Theorem 1 (Linear subspace data) Suppose that assumptions 1-5 are satisfied.,3.2 Main Results,[0],[0]
Assume,3.2 Main Results,[0],[0]
"that samples in the dataset D = {(xi, yi)}ni=1, n",3.2 Main Results,[0],[0]
≥ 1 are independently drawn from the distribution PX×Y .,3.2 Main Results,[0],[0]
"Assume that the number of neurons M in the network fS satisfies M ≥ 2 max{ n∆r , r+, r−}, where ∆r = r − max{r+, r−}.",3.2 Main Results,[0],[0]
"If θ∗ = (θ∗S ,θ∗D) is a local minimum of the loss function L̂n(θS ,θD; p) and p ≥ 6, then R̂n(θ∗S ,θ∗D) = 0 holds with probability one.
",3.2 Main Results,[0],[0]
"Remark: (i) By setting the network fD to a constant, it directly follows from Theorem 1 that if a single layer network fS(x;θS) consisting of neurons satisfying Assumption 5 and all other conditions in Theorem 1 are satisfied, then every local minimum of the empirical loss L̂n(θS ; p) has zero training error.",3.2 Main Results,[0],[0]
(ii),3.2 Main Results,[0],[0]
The positiveness of ∆r is guaranteed by Assumption 3.,3.2 Main Results,[0],[0]
"In the worst case (e.g., ∆r = 1 and ∆r = 2), the number of neurons needs to be at least greater than the number of samples, i.e., M ≥ n.",3.2 Main Results,[0],[0]
"However, when the two orthonormal basis sets U+ and U− differ significantly (i.e., ∆r 1), the number of neurons required by Theorem 1 can be significantly smaller than the number of samples (i.e., n 2n/∆r).",3.2 Main Results,[0],[0]
"In fact, we can show that, when the neuron has quadratic activation function σ(z) = z2, the assumption M ≥ 2n/∆r can be further relaxed such that the number of neurons is independent of the number of samples.",3.2 Main Results,[0],[0]
"We discuss this in the following proposition.
",3.2 Main Results,[0],[0]
Proposition 1 Assume that assumptions 1-5 are satisfied.,3.2 Main Results,[0],[0]
Assume,3.2 Main Results,[0],[0]
"that samples in the dataset D = {(xi, yi)}ni=1, n",3.2 Main Results,[0],[0]
≥ 1 are independently drawn from the distribution PX×Y .,3.2 Main Results,[0],[0]
Assume that neurons in the network fS satisfy σ(z) =,3.2 Main Results,[0],[0]
"z
2 and the number of neurons in the network fS satisfies M > r.",3.2 Main Results,[0],[0]
"If θ∗ = (θ∗S ,θ ∗ D) is a local minimum of the loss function L̂n(θS ,θD; p) and p ≥ 6, then R̂n(θ∗S ,θD) = 0 holds with probability one.
",3.2 Main Results,[0],[0]
"Remark: Proposition 1 shows that if the number of neuron M is greater than the dimension of the subspace, i.e., M > r, then every local minimum of the empirical loss function has zero training error.",3.2 Main Results,[0],[0]
"We note here that although the result is stronger with quadratic neurons, it does not imply that the
quadratic neuron has advantages over the other types of neurons (e.g., softplus neuron, etc).",3.2 Main Results,[0],[0]
"This is due to the fact that when the neuron has positive derivatives on R, the result in Theorem 1 holds for the dataset where positive and negative samples are linearly separable.",3.2 Main Results,[0],[0]
We provide the formal statement of this result in Theorem 2.,3.2 Main Results,[0],[0]
"However, when the neuron has quadratic activation function, the result in Theorem 1 may not hold for linearly separable dataset and we will illustrate this by providing a counterexample in the next section.
",3.2 Main Results,[0],[0]
"As shown in Theorem 1, when the data distribution satisfies Assumption 2 and 3, every local minimum of the empirical loss has zero training error.",3.2 Main Results,[0],[0]
"However, we can easily see that distributions satisfying these two assumptions may not be linearly separable.",3.2 Main Results,[0],[0]
"Therefore, to provide a complementary result to Theorem 1, we consider the case where the data distribution is linearly separable.",3.2 Main Results,[0],[0]
"Before presenting the result, we first present the following assumption on the data distribution.
",3.2 Main Results,[0],[0]
"Assumption 6 (Linear separability) Assume that there exists a vector w ∈ Rd such that the data distribution satisfies PX×Y (Yw>X > 0) = 1.
",3.2 Main Results,[0],[0]
"In Theorem 2, we will show that when the samples drawn from the data distribution are linearly separable, and the network has a shortcut-like connection shown in Figure 1, all local minima of the empirical loss function have zero training errors if the type of the neuron in the network fS are chosen appropriately.
",3.2 Main Results,[0],[0]
Theorem 2 (Linearly separable data) Suppose that the loss function `p satisfies Assumption 1 and the network architecture satisfies Assumption 4.,3.2 Main Results,[0],[0]
Assume,3.2 Main Results,[0],[0]
"that samples in the dataset D = {(xi, yi)}ni=1, n",3.2 Main Results,[0],[0]
≥ 1 are independently drawn from a distribution satisfying Assumption 6.,3.2 Main Results,[0],[0]
Assume that the single layer network fS has M ≥ 1 neurons and neurons σ in the network fS are twice differentiable and satisfy σ′(z),3.2 Main Results,[0],[0]
> 0,3.2 Main Results,[0],[0]
for all z ∈ R.,3.2 Main Results,[0],[0]
"If θ∗ = (θ∗S ,θ∗D) is a local minimum of the loss function L̂n(θS ,θD; p), p ≥ 3, then R̂n(θ∗S ,θ∗D) = 0 holds with probability one.
",3.2 Main Results,[0],[0]
"Remark: Similar to Proposition 1, Theorem 2 does not require the number of neurons to be in scale with the number of samples.",3.2 Main Results,[0],[0]
"In fact, we make a weaker assumption here: the single layer network fS only needs to have at least one neuron, in contrast to at least r neurons required by Proposition 1.",3.2 Main Results,[0],[0]
"Furthermore, we note here that, in Theorem 2, we assume that neurons in the network fS have positive derivatives on R. This implies that Theorem 2 may not hold for a subset of neurons considered in Theorem 1 (e.g., quadratic neuron, etc).",3.2 Main Results,[0],[0]
"We will provide further discussions on the effects of neurons in the next section.
",3.2 Main Results,[0],[0]
"So far, we have provided results showing that under certain constraints on the (1) neuron activation function, (2) network architecture, (3) loss function and (4) data distribution, every local minimum of the empirical loss function has zero training error.",3.2 Main Results,[0],[0]
"In the next section, we will discuss the implications of these conditions on our main results.",3.2 Main Results,[0],[0]
"In this section, we discuss the effects of the (1) neuron activation, (2) shortcut-like connections, (3) loss function and (4) data distribution on the main results, respectively.",4 Discussions,[0],[0]
We show that the result may not hold if these assumptions are relaxed.,4 Discussions,[0],[0]
"To begin with, we discuss whether the results in Theorem 1 and 2 still hold if we vary the neuron activation function in the single layer network fS .",4.1 Neuron Activations,[0],[0]
"Specifically, we consider the following five classes of
neurons: (1) softplus class, (2) rectified linear unit (ReLU) class, (3) leaky rectified linear unit (Leaky ReLU) class, (4) quadratic class and (5) sigmoid class.",4.1 Neuron Activations,[0],[0]
"In the following, for each class of neurons, we show whether the main results hold and provide counterexamples if certain conditions in the main results are violated.",4.1 Neuron Activations,[0],[0]
We summarize our findings in Table 4.1.,4.1 Neuron Activations,[0],[0]
We visualize some neurons activation functions from these five classes in Fig. 2(a).,4.1 Neuron Activations,[0],[0]
"Softplus class contains neurons with real analytic activation functions σ, where σ′(z)",4.1 Neuron Activations,[0],[0]
"> 0, σ′′(z) > 0",4.1 Neuron Activations,[0],[0]
"for all z ∈ R. A widely used neuron in this class is the softplus neuron, i.e., σ(z) =",4.1 Neuron Activations,[0],[0]
"log2(1 + ez), which is a smooth approximation of ReLU.",4.1 Neuron Activations,[0],[0]
We can see that neurons in this class satisfy assumptions in both Theorem 1 and 2 and this indicates that both theorems hold for the neurons in this class.,4.1 Neuron Activations,[0],[0]
"ReLU class contains neurons with σ(z) = 0 for all z ≤ 0 and σ(z) is piece-wise continuous on R. Some commonly adopted neurons in this class include: threshold units, i.e., I{z ≥ 0}, rectified linear units (ReLU), i.e., max{z, 0} and rectified quadratic units (ReQU),",4.1 Neuron Activations,[0],[0]
"i.e., [max{z, 0}]2.",4.1 Neuron Activations,[0],[0]
We can see that neurons in this class do not satisfy neither assumptions in Theorem 1 nor 2.,4.1 Neuron Activations,[0],[0]
"In proposition 2, we show that when the single layer network fS consists of neurons in the ReLU class, even if all other conditions in Theorem 1 or 2 are satisfied, the empirical loss function can have a local minimum with non-zero training error.
",4.1 Neuron Activations,[0],[0]
Proposition 2 Suppose that assumptions 1 and 4 are satisfed.,4.1 Neuron Activations,[0],[0]
Assume that neurons in the network fS satisfy that σ(z) = 0 for all z ≤ 0 and σ(z) is piece-wise continuous on R.,4.1 Neuron Activations,[0],[0]
"Then there exists a network architecture fD and a distribution satisfying assumptions in Theorem 1 or 2 such that with probability one, the empirical loss L̂n(θ; p), p ≥ 2 has a local minima θ∗ = (θ∗S ,θ∗D) satisfying R̂n(θ ∗)",4.1 Neuron Activations,[0],[0]
"≥ min{n+,n−}n , where n+",4.1 Neuron Activations,[0],[0]
"and n− are the number of positive and negative samples, respectively.
",4.1 Neuron Activations,[0],[0]
Remark: (i),4.1 Neuron Activations,[0],[0]
"We note here that the above result holds in the over-parametrized case, where the number of neurons in the network fS is larger than the number of samples in the dataset.",4.1 Neuron Activations,[0],[0]
"In addition, all counterexamples shown in Section 4.1 hold in the over-parametrized case.",4.1 Neuron Activations,[0],[0]
"(ii) We note here that applying the same analysis, we can generalize the above result to a larger class of neurons satisfying the following condition: there exists a scalar z1 such that σ(z) = constant for all z ≤",4.1 Neuron Activations,[0],[0]
z1 and σ(z) is piece-wise continuous on R. (iii) We note that the training error is strictly non-zero when the dataset has both positive and negative samples and this can happen with probability at least 1− e−Ω(n).,4.1 Neuron Activations,[0],[0]
"Leaky-ReLU class contains neurons with σ(z) = z for all z ≥ 0 and σ(z) is piece-wise continuous on R. Some commonly used neurons in this class include ReLU, i.e., max{z, 0}, leaky rectified linear unit (Leaky-ReLU), i.e., σ(z)",4.1 Neuron Activations,[0],[0]
"= z for z ≥ 0, σ = αz for z ≤ 0 and some constant α ∈ (0, 1), exponential linear unit (ELU), i.e., σ(z) = z for z ≥ 0, σ(z) =",4.1 Neuron Activations,[0],[0]
α(exp(z)− 1) for z ≤ 0 and some constant α < 0.,4.1 Neuron Activations,[0],[0]
"We can see that all neurons in this class do not satisfy assumptions in Theorem 1, while some neurons in this class satisfy the condition in Theorem 2 (e.g., linear neuron, σ(z) = z) and some neurons do not (e.g., ReLU).",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"In Proposition 2, we have provided a counterexample showing that Theorem 2 does not hold for some neurons in this class (e.g., ReLU).",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"Next, we will present the following proposition to show that when the network fS consists of neurons in the Leaky-ReLU class, even if all other conditions in Theorem 1 are satisfied, the empirical loss function is likely to have a local minimum with non-zero training error with high probability.
",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
Proposition 3 Suppose that Assumption 1 and 4 are satisfied.,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
Assume that neurons in the network fS satisfy that σ(z) =,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"z for all z ≥ 0 and σ(z) is piece-wise continuous on R. Then there exists a network architecture fD and a distribution satisfying assumptions in Theorem 1 such that, with probability at least 1− e−Ω(n), the empirical loss L̂n(θ; p), p ≥ 2 has a local minima θ∗ = (θ∗S ,θ∗D) with non-zero training error.
",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"Remark: We note that applying the same proof, we can generalize the above result to a larger class of neurons, i.e., neurons satisfying the condition that there exists two scalars z1 and α such that σ(z) = α(z",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
− z1) for all z ≥ 0,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
and σ is piece-wise continuous on R.,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"In addition, we note that the ReLU neuron (but not all neurons in the ReLU class) satisfies the definition of both ReLU class and Leaky-ReLU class, and therefore both Proposition 2 and 3 hold for the ReLU neuron.",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"Sigmoid class contains neurons with σ(z) + σ(−z) ≡ constant on R. We list a few commonly adopted neurons in this family: sigmoid neuron, i.e., σ(z) = 1
1+e−z , hyperbolic tangent neuron, i.e.,
σ(z) = e z−1 ez+1 , arctangent neuron, i.e., σ(z) = tan −1(z) and softsign neuron, i.e., σ(z) = z1+|z| .",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
We note that all real odd functions2 satisfy the conditions of the sigmoid class.,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"We can see that none of the above neurons satisfy assumptions in Theorem 1, since neurons in this class satisfy either σ′′(z) + σ′′(−z) ≡ 0",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
for all z ∈ R or σ(z) is not twice differentiable.,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"For Theorem 2, we can see that some neurons in this class satisfy the condition in Theorem 2 (e.g., sigmoid neuron) and some neurons do not (e.g., constant neuron σ(z) ≡ 0",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
for all z ∈ R).,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"In Proposition 2, we provided a counterexample showing that Theorem 2 does not hold for some neurons in this class (e.g., constant neuron).",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"Next, we present the following proposition showing that when the network fS consists of neurons in the sigmoid class, then there always exists a data distribution satisfying the assumptions in Theorem 1 such that, with a positive probability, the empirical loss has a local minima with non-zero training error.
",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
Proposition 4 Suppose that assumptions 1 and 4 are satisfed.,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
Assume that there exists a constant c ∈ R such that neurons in the network fS satisfy σ(z)+σ(−z) ≡,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
c for all z ∈ R. Assume that the dataset D has 2n samples.,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"There exists a network architecture fD and a distribution satisfying assumptions in Theorem 1 such that, with a positive probability, the empirical loss function L̂2n(θ; p), p ≥ 2 has a local minimum θ∗ = (θ∗S ,θ ∗ D) satisfying R̂2n(θ
∗)",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"≥ min{n−,n+}2n , where n+ and n− denote the number of positive and negative samples in the dataset, respectively.
",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"Remark: Proposition 4 shows that when the network fS consists of neurons in the sigmoid class, even if all other conditions are satisfied, the results in Theorem 1 does not hold with a positive probability.
",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
2A real function f :,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"R→ R is an odd function, if f(x) + f(−x)",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
≡ 0,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"for all x ∈ R.
Quadratic family contains neurons where σ(z) is real analytic and strongly convex on R and has a global minimum at the point z = 0.",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"A simple example of neuron in this family is the quadratic neuron, i.e., σ(z) = z2.",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
It is easy to check that all neurons in this class satisfy the conditions in Theorem 1 but not in Theorem 2.,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"For Theorem 2, we present a counterexample and show that, when the network fS consists of neurons in the quadratic class, even if positive and negative samples are linearly separable, the empirical loss can have a local minimum with non-zero training error.
",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
Proposition 5 Suppose that Assumption 1 and 4 are satisfied.,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
Assume that neurons in fS satisfy that σ is strongly convex and twice differentiable on R and has a global minimum at z = 0.,Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"There exists a network architecture fD and a distribution satisfying assumptions in Theorem 2 such that with probability one, the empirical loss L̂n(θ; p), p ≥ 2 has a local minima θ∗ = (θ∗S ,θ∗D) satisfying R̂n(θ
∗) ≥ min{n+,n−}n , where n+ and n− denote the number of positive and negative samples in the dataset, respectively.",Theorem Softplus ReLU Leaky-ReLU Sigmoid Quadratic,[0],[0]
"In this subsection, we discuss whether the main results still hold if we remove the shortcut-like connections or replace them with the identity shortcut connections used in the residual network [33].",4.2 Shortcut-like Connections,[0],[0]
"Specifically, we provide two counterexamples and show that the main results do not hold if the shortcut-like connections are removed or replaced with the identity shortcut connections.
",4.2 Shortcut-like Connections,[0],[0]
Feed-forward networks.,4.2 Shortcut-like Connections,[0],[0]
"When the shortcut-like connections (i.e., the network fS in Figure 1(b)) are removed, the network architecture can be viewed as a standard feedforward neural network.",4.2 Shortcut-like Connections,[0],[0]
"We provide a counterexample to show that, for a feedforward network with ReLU neurons, even if the other conditions in Theorem 1 or 2 are satisfied, the empirical loss functions is likely to have a local minimum with non-zero training error.",4.2 Shortcut-like Connections,[0],[0]
"In other words, neither Theorem 1 nor 2 holds when the shortcut-like connections are removed.
",4.2 Shortcut-like Connections,[0],[0]
Proposition 6 Suppose that assumption 1 is satisfied.,4.2 Shortcut-like Connections,[0],[0]
Assume that the feedforward network f(x;θ) has at least one hidden layer and at least one neuron in each hidden layer.,4.2 Shortcut-like Connections,[0],[0]
"If neurons in the network f satisfy that σ(z) = 0 for all z ≤ 0 and σ(z) is continuous on R, then for any dataset D with n samples, the empirical loss L̂n(θ; p), p ≥ 2 has a local minima θ∗ with R̂n(θ∗) ≥ min{n+,n−}n , where n+",4.2 Shortcut-like Connections,[0],[0]
"and n− are the number of positive and negative samples in the dataset, respectively.
",4.2 Shortcut-like Connections,[0],[0]
"Remark: The result holds for ReLUs, since it is easy to check that the ReLU neuron satisfies the above assumptions.
",4.2 Shortcut-like Connections,[0],[0]
Identity shortcut connections.,4.2 Shortcut-like Connections,[0],[0]
"As we stated earlier, adding shortcut-like connections to a network can improve the loss surface.",4.2 Shortcut-like Connections,[0],[0]
"However, the shortcut-like connections shown in Fig 1(b) are different from some popular shortcut connections used in the real-world applications, e.g., the identity shortcut connections in the residual network.",4.2 Shortcut-like Connections,[0],[0]
"Thus, a natural question arises: do the main results still hold if we use the identity shortcut connections?",4.2 Shortcut-like Connections,[0],[0]
"To address the question, we provide the following counterexample to show that, when we replace the shortcut-like connections with the identity shortcut connections, even if the other conditions in Theorem 1 are satisfied, the empirical loss function is likely to have a local minimum with non-zero training error.",4.2 Shortcut-like Connections,[0],[0]
"In other words, Theorem 1 does not hold for the identity shortcut connections.
",4.2 Shortcut-like Connections,[0],[0]
Proposition 7 Assume that H : Rd → Rd is a feedforward neural network parameterized by θ and all neurons in H are ReLUs.,4.2 Shortcut-like Connections,[0],[0]
"Define a network f : Rd → R with identity shortcut connections as f(x;a,θ, b) = a>(x + H(x;θ))",4.2 Shortcut-like Connections,[0],[0]
"+ b, a ∈ Rd, b ∈ R.",4.2 Shortcut-like Connections,[0],[0]
"Then there exists a distribution PX×Y satisfying the assumptions in Theorem 1 such that with probability at least 1 − e−Ω(n), the empirical loss L̂n(a,θ, b; p) = 1 n",4.2 Shortcut-like Connections,[0],[0]
∑n i=1,4.2 Shortcut-like Connections,[0],[0]
"`(−yif(xi;θ); p), p ≥ 2 has a local minimum with non-zero training error.",4.2 Shortcut-like Connections,[0],[0]
"In this subsection, we discuss whether the main results still hold if we change the loss function.",4.3 Loss Functions,[0],[0]
We mainly focus on the following two types of surrogate loss functions: quadratic loss and logistic loss.,4.3 Loss Functions,[0],[0]
"We will show that if the loss function is replaced with the quadratic loss or logistic loss, then neither Theorem 1 nor 2 holds.",4.3 Loss Functions,[0],[0]
"In addition, we show that when the loss function is the logistic loss and the network is a feedforward neural network, there are no local minima with zero training error in the real parameter space.",4.3 Loss Functions,[0],[0]
"In Fig. 2(b), we visualize some surrogate loss functions discussed in this subsection.",4.3 Loss Functions,[0],[0]
Quadratic loss.,4.3 Loss Functions,[0],[0]
The quadratic loss `(z) =,4.3 Loss Functions,[0],[0]
(1 + z)2 has been well-studied in prior works.,4.3 Loss Functions,[0],[0]
"It has been shown that when the loss function is quadratic, under certain assumptions, all local minima of the empirical loss are global minima.",4.3 Loss Functions,[0],[0]
"However, the global minimum of the quadratic loss does not necessarily have zero misclassification error, even in the realizable case (i.e., the case where there exists a set of parameters such that the network achieves zero misclassification error on the dataset or the data distriubtion).",4.3 Loss Functions,[0],[0]
"To illustrate this, we provide a simple example where the network is a simplified linear network and the data distribution is linearly separable.
",4.3 Loss Functions,[0],[0]
"Example 1 Let the distribution PX×Y satisfy that P(Y = 1) = P(Y = −1) = 0.5, P(X = 5/4|Y = 1) = 1 and PX|Y=−1 is a uniform distribution on the interval",4.3 Loss Functions,[0],[0]
"[0, 1].",4.3 Loss Functions,[0],[0]
"For a linear model f(x; a, b) = ax+b, a, b ∈ R, every global minimum (a∗, b∗) of the population loss L(a, b) = EX×Y",4.3 Loss Functions,[0],[0]
"[(1−Y f(X; a, b))2] satisfies PX×Y",4.3 Loss Functions,[0],[0]
"[Y 6= sgn(f(X; a∗, b∗))]",4.3 Loss Functions,[0],[0]
"≥ 1/16.
",4.3 Loss Functions,[0],[0]
Remark: The proof of the above result in Appendix B.7 is very straightforward.,4.3 Loss Functions,[0],[0]
"We have only provided it there since we are unable to find a reference which explicitly states such a result, but we will not be surprised if this result has been known to others.",4.3 Loss Functions,[0],[0]
"This example shows that every global minimum of the quadratic loss has non-zero misclassification error, although the linear model is able to achieve zero misclassification error on this data distribution.",4.3 Loss Functions,[0],[0]
"Similarly, one can easily find datasets under which all global minima of the quadratic loss have non-zero training error.
",4.3 Loss Functions,[0],[0]
"In addition, we provide two examples in Appendix B.8 and show that, when the loss function is replaced with the quadratic loss, even if the other conditions in Theorem 1 or 2 are satisfied, every global minimum of the empirical loss has a training error larger than 1/8 with a positive probability.",4.3 Loss Functions,[0],[0]
"In other words, our main results do hold for the quadratic loss.
",4.3 Loss Functions,[0],[0]
The following observation may be of independent interest.,4.3 Loss Functions,[0],[0]
"Different from the quadratic loss, the loss functions conditioned in Assumption 1 have the following two properties: (i) the minimum empirical loss is zero if and only if there exists a set of parameters achieving zero training error; (ii) every global minimum of the empirical loss has zero training error in the realizable case.
",4.3 Loss Functions,[0],[0]
Proposition 8,4.3 Loss Functions,[0],[0]
Let f :,4.3 Loss Functions,[0],[0]
Rd → R denote a feedforward network parameterized by θ and let the dataset have n samples.,4.3 Loss Functions,[0],[0]
"When the loss function `p satisfies Assumption 1 and p ≥ 1, we have minθ L̂n(θ; p) = 0",4.3 Loss Functions,[0],[0]
if and only if minθ R̂n(θ) = 0.,4.3 Loss Functions,[0],[0]
"Furthermore, if minθ R̂n(θ) = 0, every global minimum θ
∗ of the empirical loss L̂n(θ; p) has zero training error, i.e., R̂n(θ ∗) = 0.
",4.3 Loss Functions,[0],[0]
Remark: We note that the network does not need to be a feedforward network.,4.3 Loss Functions,[0],[0]
"In fact, the same results hold for a large class of network architectures, including both architectures shown in Fig 1.",4.3 Loss Functions,[0],[0]
"We provide additional analysis in Appendix B.9.
Logistic loss.",4.3 Loss Functions,[0],[0]
"The logistic loss `(z) = log2 (1 + e z) is different from the loss functions conditioned in Assumption 1, since the logistic loss does not have a global minimum on R. Here, for the logistic loss function, we show that even if the remaining assumptions in Theorem 1 hold, every critical point is a saddle point.",4.3 Loss Functions,[0],[0]
"In other words, Theorem 1 does not hold for logistic loss.",4.3 Loss Functions,[0],[0]
"Additional analysis on Theorem 2 are provided in Appendix B.11.
",4.3 Loss Functions,[0],[0]
"Proposition 9 Assume that the loss function is the logistic loss, i.e., `(z) = log2(1",4.3 Loss Functions,[0],[0]
+ e z).,4.3 Loss Functions,[0],[0]
Assume that assumptions 2-5 are satisfied.,4.3 Loss Functions,[0],[0]
Assume,4.3 Loss Functions,[0],[0]
"that samples in the dataset D = {(xi, yi)}ni=1, n",4.3 Loss Functions,[0],[0]
≥ 1 are independently drawn from the distribution PX×Y .,4.3 Loss Functions,[0],[0]
"Assume that the number of neurons M in the network fS satisfies M ≥ 2 max{ n∆r , r+, r−}, where ∆r = r − max{r+, r−}.",4.3 Loss Functions,[0],[0]
"If θ∗ denotes a critical point of the empirical loss L̂n(θ), then θ ∗ is a saddle point.",4.3 Loss Functions,[0],[0]
"In particular, there are no local minima.
",4.3 Loss Functions,[0],[0]
"Remark: We note here that the result can be generalized to every loss function ` which is real analytic and has a positive derivative on R. Furthermore, we provide the following result to show that when the dataset contains both positive and negative samples, if the loss is the logistic loss, then every critical point of the empirical loss function has non-zero training error.
",4.3 Loss Functions,[0],[0]
"Proposition 10 Assume the dataset D = {(xi, yi)}ni=1 consists of both positive and negative samples.",4.3 Loss Functions,[0],[0]
Assume that f(x;θ) is a feedforward network parameterized by θ.,4.3 Loss Functions,[0],[0]
"Assume that the loss function is logistic, i.e., `(z) = log2 (1 + e
z).",4.3 Loss Functions,[0],[0]
"If the real parameters θ∗ denote a critical point of the empirical loss L̂n(θ ∗), then R̂n(θ ∗)",4.3 Loss Functions,[0],[0]
"> 0.
",4.3 Loss Functions,[0],[0]
Remark: We provide the proof in Appendix B.12.,4.3 Loss Functions,[0],[0]
The above proposition implies every critical point is either a local minimum with non-zero training error or is a saddle point (also with non-zero training error).,4.3 Loss Functions,[0],[0]
"We note here that, similar to Proposition 9, the result can be generalized to every loss function ` that is differentiable and has a positive derivative on R.",4.3 Loss Functions,[0],[0]
"In this paper, we have mainly considered a class of non-linearly separable distribution where positive and negative samples are located on different subspaces.",4.4 Open Problem: Datasets,[0],[0]
"We show that if the samples are drawn from such a distribution, under certain additional conditions, all local minima of the empirical loss have zero training errors.",4.4 Open Problem: Datasets,[0],[0]
"However, one may ask: how well does the result generalize to other non-linearly separable distributions or datasets?",4.4 Open Problem: Datasets,[0],[0]
"Here, we partially answer this question by presenting the following necessary condition on the dataset so that Theorem 1 can hold.
",4.4 Open Problem: Datasets,[0],[0]
"Proposition 11 Suppose that assumptions 1, 4 and 5 are satisfied.",4.4 Open Problem: Datasets,[0],[0]
"For any feedforward architecture fD(x;θD), every local minimum θ ∗ = (θ∗S ,θ ∗ D) of the empirical loss function L̂n(θS ,θD; p), p ≥ 6 satisfies R̂n(θ ∗)",4.4 Open Problem: Datasets,[0],[0]
= 0,4.4 Open Problem: Datasets,[0],[0]
"only if the matrix ∑n i=1 λiyixix > i is neither positive nor negative definite for all
sequences {λi ≥ 0}ni=1",4.4 Open Problem: Datasets,[0],[0]
satisfying ∑ i:yi=1 λi = ∑ i:yi=−1 λi > 0 and ‖ ∑n i=1,4.4 Open Problem: Datasets,[0],[0]
"λiyixi‖2 = 0.
",4.4 Open Problem: Datasets,[0],[0]
"Remark: The proposition implies that when the dataset does not meet this necessary condition, there exists a feedforward architecture fD",4.4 Open Problem: Datasets,[0],[0]
such that the empirical loss function has a local minimum with a non-zero training error.,4.4 Open Problem: Datasets,[0],[0]
We use this implication to prove the counterexamples provided in Appendix B.14 when Assumption 2 or 3 on the dataset is not satisfied.,4.4 Open Problem: Datasets,[0],[0]
"Therefore, Theorem 1 no longer holds when Assumption 2 or 3 is removed.",4.4 Open Problem: Datasets,[0],[0]
We note that the necessary condition shown here is not equivalent to Assumption 2 and 3.,4.4 Open Problem: Datasets,[0],[0]
"Now we present the following result to show the sufficient and necessary condition that the dataset should satisfy so that Proposition 1 can hold.
",4.4 Open Problem: Datasets,[0],[0]
Proposition 12 Suppose that the loss function `p satisfies Assumption 1 and neurons in the network satisfy Assumption 5.,4.4 Open Problem: Datasets,[0],[0]
"Assume that the single layer network fS(x;θS) has M > d neurons and assume that neurons in fS are quadratic neurons, i.e., σ(z) = z
2.",4.4 Open Problem: Datasets,[0],[0]
"For any network architecture fD(x;θD), every local minimum θ ∗ = (θ∗S ,θ ∗ D) of the empirical loss function L̂n(θS ,θD; p), p ≥ 6 satisfies R̂n(θ ∗)",4.4 Open Problem: Datasets,[0],[0]
= 0,4.4 Open Problem: Datasets,[0],[0]
if and only if the matrix,4.4 Open Problem: Datasets,[0],[0]
∑n i=1 λiyixix,4.4 Open Problem: Datasets,[0],[0]
"> i is indefinite for all sequences {λi ≥ 0}ni=1
satisfying ∑
i:yi=1 λi = ∑",4.4 Open Problem: Datasets,[0],[0]
i:,4.4 Open Problem: Datasets,[0],[0]
"yi=−1 λi > 0.
",4.4 Open Problem: Datasets,[0],[0]
Remark: (i),4.4 Open Problem: Datasets,[0],[0]
"This sufficient and necessary condition implies that for any network architecture fD, there exists a set of parameters θ = (θS ,θD) such that the network f(x;θ) = fS(x;θS) + fD(x;θD) can correctly classify all samples in the dataset.",4.4 Open Problem: Datasets,[0],[0]
"This also indicates the existence of a set of parameters achieving zero training error, regardless of the network architecture of fD. We provide the proof in Appendix B.15.",4.4 Open Problem: Datasets,[0],[0]
(ii) We note that Proposition 12 only holds for the quadratic neuron.,4.4 Open Problem: Datasets,[0],[0]
The problem of finding the sufficient and necessary conditions for the other types of neurons is open.,4.4 Open Problem: Datasets,[0],[0]
"In this paper, we studied the surface of a smooth version of the hinge loss function in binary classification problems.",5 Conclusions,[0],[0]
"We provided conditions under which the neural network has zero misclassification error at all local minima and also provide counterexamples to show that when some of these assumptions are relaxed, the result may not hold.",5 Conclusions,[0],[0]
Further work involves exploiting our results to design efficient training algorithms classification tasks using neural networks.,5 Conclusions,[0],[0]
Lemma 1 (Necessary condition.),A.1 Proof of Lemma 1,[0],[0]
Assume that neurons σ in the network fS are twice differentiable and the loss function ` : R→ R has a continuous derivative on R up to the third order.,A.1 Proof of Lemma 1,[0],[0]
"If n ≥ 1 and parameters θ∗ = (θ∗S ,θ ∗ D) denote a local minimum of the loss function L̂n(θ), then for any j = 1, ...,M ,
n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi = 0d.
",A.1 Proof of Lemma 1,[0],[0]
Proof: We first recall some notations defined in the paper.,A.1 Proof of Lemma 1,[0],[0]
"The output of the neural network is
f(x;θ) = fS(x;θS) + fD(x;θD),
where fS(x;θS) is the single layer neural network parameterized by θS , i.e.,
fS(x;θS)",A.1 Proof of Lemma 1,[0],[0]
"= a0 + M∑ j=1 ajσ ( w>j x ) ,
and fD(x;θD) is a deep neural network parameterized by θD.",A.1 Proof of Lemma 1,[0],[0]
"The empirical loss function is given by
L̂n(θ) = L̂n(θS ,θD) = 1
n n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
"`(−yif(xi;θ)).
",A.1 Proof of Lemma 1,[0],[0]
"Since the loss function ` has a continuous derivative on R up to the third order, neurons σ in the network fS are twice differentiable, then the gradient vector ∇θS L̂n(θ∗S ,θ∗D) and the Hessian matrix ∇2θS L̂n(θ ∗ S ,θ ∗ D) exists.",A.1 Proof of Lemma 1,[0],[0]
"Furthermore, by the assumption that θ ∗ = (θ∗S ,θ ∗ D) is a local minima of the loss function L̂n(θ), then we should have for j = 1, ...,M ,
0d = ∇wjLn(θ∗) = n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))(−yi∇wjf(xi;θ∗))
= n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))(−yia∗jσ′(w∗j>xi)xi)
= −a∗j n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi.,A.1 Proof of Lemma 1,[0],[0]
"(1)
Now we need to prove that if θ∗ is a local minima, then
∀j ∈",A.1 Proof of Lemma 1,[0],[0]
"[M ], ∥∥∥∥∥ n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi ∥∥∥∥∥
2
= 0.
",A.1 Proof of Lemma 1,[0],[0]
We prove it by contradiction.,A.1 Proof of Lemma 1,[0],[0]
Assume that there exists j ∈,A.1 Proof of Lemma 1,[0],[0]
[M ] such that∥∥∥∥∥ n∑ i=1,A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi ∥∥∥∥∥
2
6= 0.
",A.1 Proof of Lemma 1,[0],[0]
"Then by equation (1), we have a∗j = 0.",A.1 Proof of Lemma 1,[0],[0]
"Now, we consider the following Hessian matrix H(aj ,wj).",A.1 Proof of Lemma 1,[0],[0]
"Since θ∗ is a local minima of the loss function L̂n(θ), then the matrix H(aj ,wj) should be positive semidefinite at (a∗j ,w ∗ j ).",A.1 Proof of Lemma 1,[0],[0]
"By a ∗ j = 0, we have
∇2wjLn(θ∗) = −a∗j∇wj",A.1 Proof of Lemma 1,[0],[0]
[ n∑ i=1,A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi ] = 0d×d,
∂ [ ∇wjLn(θ∗) ]",A.1 Proof of Lemma 1,[0],[0]
∂aj = − n∑ i=1,A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi
",A.1 Proof of Lemma 1,[0],[0]
"− a∗j ∂
∂aj [ n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi ]
",A.1 Proof of Lemma 1,[0],[0]
= − n∑ i=1,A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi.
",A.1 Proof of Lemma 1,[0],[0]
"In addition, we have
∂2Ln(θ ∗)
∂a2j",A.1 Proof of Lemma 1,[0],[0]
"=
∂
∂aj [ n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
`′(−yif(xi;θ∗))(−yiσ(w∗j>xi)),A.1 Proof of Lemma 1,[0],[0]
"]
= n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
"`′′(−yif(xi;θ∗))σ2(w∗j>xi).
",A.1 Proof of Lemma 1,[0],[0]
"Since the matrix H(a∗j ,w ∗ j ) is positive semidefinite, then for any α ∈ R and ω ∈ Rd,
( α ω> )",A.1 Proof of Lemma 1,[0],[0]
"H(a∗j ,w ∗ j )",A.1 Proof of Lemma 1,[0],[0]
( α ω ),A.1 Proof of Lemma 1,[0],[0]
"≥ 0.
",A.1 Proof of Lemma 1,[0],[0]
"Since
( α ω> ) H(a∗j ,w ∗ j )",A.1 Proof of Lemma 1,[0],[0]
( α ω ),A.1 Proof of Lemma 1,[0],[0]
= α2 n∑ i=1,A.1 Proof of Lemma 1,[0],[0]
"`′′(−yif(xi;θ∗))σ2(w∗j>xi)
− αω> n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi,
and by setting
ω = n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi,
then
( α ω> )",A.1 Proof of Lemma 1,[0],[0]
"H(a∗j ,w ∗ j )",A.1 Proof of Lemma 1,[0],[0]
( α ω ),A.1 Proof of Lemma 1,[0],[0]
= α2 n∑ i=1,A.1 Proof of Lemma 1,[0],[0]
"`′′(−yif(xi;θ∗))σ2(w∗j>xi)
− α ∥∥∥∥∥ n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi ∥∥∥∥∥ 2
2
.
",A.1 Proof of Lemma 1,[0],[0]
"Furthermore, since we assume that∥∥∥∥∥ n∑ i=1",A.1 Proof of Lemma 1,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi ∥∥∥∥∥ 2
2
> 0,
then clearly, there exists α such that
( α ω> )",A.1 Proof of Lemma 1,[0],[0]
"H(a∗j ,w ∗ j )",A.1 Proof of Lemma 1,[0],[0]
( α ω ),A.1 Proof of Lemma 1,[0],[0]
"< 0.
and this leads to the contradiction.",A.1 Proof of Lemma 1,[0],[0]
"Thus, we proved the lemma.",A.1 Proof of Lemma 1,[0],[0]
"Theorem 3 Assume that the loss function `p satisfies assumption 1, the distribution PX×Y satisfies assumption 2 and 3, the network architecture satisfies assumption 4 and neurons in the network satisfy assumption 5.",A.2 Proof of Theorem 1,[0],[0]
Assume,A.2 Proof of Theorem 1,[0],[0]
"that samples in the dataset D = {(xi, yi)}ni=1, n",A.2 Proof of Theorem 1,[0],[0]
≥ 1 are independently drawn from the distribution PX×Y .,A.2 Proof of Theorem 1,[0],[0]
"Assume that the number of neurons M in the network fS satisfies M ≥ 2 max{ n∆r , r+, r−}, where ∆r = r −max{r+, r−}.",A.2 Proof of Theorem 1,[0],[0]
"If the real parameters θ∗ = (θ∗S ,θ∗D) denote a local minimum of the loss function L̂n(θS ,θD; p) and p ≥ 6, then R̂n(θ∗S ,θ∗D) = 0 holds with probability one.
",A.2 Proof of Theorem 1,[0],[0]
Proof: We first present some notations used in this proof.,A.2 Proof of Theorem 1,[0],[0]
"The output of the neural network is
f(x;θ) = fS(x;θS) + fD(x;θD),
where fS(x;θS) is the single layer neural network parameterized by θS , i.e.,
fS(x;θS)",A.2 Proof of Theorem 1,[0],[0]
"= a0 + M∑ j=1 ajσ ( w>j x ) ,
and fD(x;θD) is a deep neural network parameterized by θD.",A.2 Proof of Theorem 1,[0],[0]
"The empirical loss function is given by
L̂n(θ; p) = L̂n(θS ,θD; p)",A.2 Proof of Theorem 1,[0],[0]
"= 1
n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
"`p(−yif(xi;θ))
",A.2 Proof of Theorem 1,[0],[0]
"We first assume that the real parameters θ∗ = (θ∗S ,θ ∗ D) denote a local minima of the loss function L̂n(θ; p).",A.2 Proof of Theorem 1,[0],[0]
"Next, we prove the following two claims: Claim 1: If θ∗ = (θ∗S ,θ ∗ D) is a local minima and there exists j ∈",A.2 Proof of Theorem 1,[0],[0]
"[M ] such that a∗j = 0, then R̂n(θ ∗) = 0.",A.2 Proof of Theorem 1,[0],[0]
Claim 2:,A.2 Proof of Theorem 1,[0],[0]
"If θ∗ = (θ∗S ,θ ∗ D) is a local minima and a ∗ j 6= 0 for all j ∈",A.2 Proof of Theorem 1,[0],[0]
"[M ], then R̂n(θ∗) = 0.",A.2 Proof of Theorem 1,[0],[0]
(a) Proof of claim 1.,A.2 Proof of Theorem 1,[0],[0]
"We prove that if θ∗ = (θ∗S ,θ ∗ D) is a local minima of the loss function L̂n(θ; p) and there exists j ∈",A.2 Proof of Theorem 1,[0],[0]
"[M ] such that a∗j = 0, then R̂n(θ∗) = 0.",A.2 Proof of Theorem 1,[0],[0]
"Without loss of generality, we assume that a∗1 = 0.",A.2 Proof of Theorem 1,[0],[0]
"Since θ ∗ = (θ∗S ,θ ∗ D) is a local minima, then there exists ε0 > 0",A.2 Proof of Theorem 1,[0],[0]
"such that for all small perturbations ∆a1, ∆w1 on the parameters a ∗ 1 and w ∗ 1, i.e., |∆a1|2 + ‖∆w1‖22 ≤ ε20, we have
L̂n(θ̃S ,θ ∗ D; p) ≥ L̂n(θ∗S ,θ∗D; p),
where θ̃S = (ã0, ã1, ..., ãM , w̃1, ..., w̃M ), ã1 = a ∗ 1 + ∆a1, w̃1 = w ∗ 1 + ∆w1 and ãj = a ∗ j , w̃j",A.2 Proof of Theorem 1,[0],[0]
= w ∗ j for j 6= 1.,A.2 Proof of Theorem 1,[0],[0]
"Now we consider the Taylor expansion of L̂n(θ̃S ,θ∗D; p) at the point θ∗ = (θ∗S ,θ∗D).",A.2 Proof of Theorem 1,[0],[0]
"We note here that the Taylor expansion of L̂(θS ,θ ∗ D; p) on θS always exists, since the empirical loss function L̂n has continuous derivatives with respect to fS up to the p-th order and the output of the neural network f(x;θS) is infinitely differentiable with respect to θS due to the fact that neuron activation function σ is real analytic.",A.2 Proof of Theorem 1,[0],[0]
"We first calculate the first order derivatives at the point θ∗,
dL̂n(θ ∗; p)
da1 =
1
n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ ( w∗1 >xi ) = 0, θ∗ is a critical point,
∇w1L̂n(θ∗; p) = a∗1 n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ′ ( w∗1 >xi ) xi = 0d, θ ∗ is a critical point.
",A.2 Proof of Theorem 1,[0],[0]
"Next, we calculate the second order derivatives at the point θ∗,
d2L̂n(θ ∗; p)
",A.2 Proof of Theorem 1,[0],[0]
"da21 =
1
n",A.2 Proof of Theorem 1,[0],[0]
N∑ i=1,A.2 Proof of Theorem 1,[0],[0]
"`′′p(−yif(xi;θ∗))σ2 ( w∗1 >xi ) ≥ 0,
d
da1 (∇w1L̂n(θ∗; p))",A.2 Proof of Theorem 1,[0],[0]
"=
1
n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi)σ′ ( w∗1 >xi ),A.2 Proof of Theorem 1,[0],[0]
"xi
+ a∗1 n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′′p(−yif(xi;θ∗))σ ( w∗1 >xi ),A.2 Proof of Theorem 1,[0],[0]
σ′,A.2 Proof of Theorem 1,[0],[0]
"( w∗1 >xi ) xi
= 0d,
where the first term equals to the zero vector by the necessary condition for a local minima presented in Lemma 1 and the second term equals to the zero vector by the assumption that a∗1 = 0.",A.2 Proof of Theorem 1,[0],[0]
"Furthermore, by the assumption that a∗1 = 0, we have
∇2w1L̂n(θ∗; p) = a∗1 n ∇w1",A.2 Proof of Theorem 1,[0],[0]
[ n∑ i=1,A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ′ ( w∗1 >xi ) xi ] = 0d×d.
",A.2 Proof of Theorem 1,[0],[0]
"Now, we further calculate the third order derivatives
d
da1
[ ∇2w1L̂n(θ∗; p) ]",A.2 Proof of Theorem 1,[0],[0]
"= 1
n
d
da1
[ a∗1∇w1 [ n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi)σ′ ( w∗1 >xi ) xi,A.2 Proof of Theorem 1,[0],[0]
"]]
= ∇w1
[ 1
n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ′ ( w∗1 >xi ) xi ] + 0d×d by a ∗ 1 = 0
= 1
n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi)σ′′ ( w∗1 >xi ) xix >,A.2 Proof of Theorem 1,[0],[0]
"i
+ a∗1 n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′′p(−yif(xi;θ∗)),A.2 Proof of Theorem 1,[0],[0]
[ σ′ ( w∗1 >xi )]2 xix >,A.2 Proof of Theorem 1,[0],[0]
"i
= 1
n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi)σ′′ ( w∗1 >xi ) xix,A.2 Proof of Theorem 1,[0],[0]
>,A.2 Proof of Theorem 1,[0],[0]
"i by a ∗ 1 = 0
and
∇3w1L̂n(θ∗; p) = a∗1 n ∇2w1",A.2 Proof of Theorem 1,[0],[0]
[ n∑ i=1,A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ′ ( w∗1 >xi ) xi ] = 0d×d×d.
",A.2 Proof of Theorem 1,[0],[0]
"In fact, it is easy to show that for any 2 ≤ k ≤ p,
∇kw1L̂n(θ∗; p) = a∗1 n ∇k−1w1",A.2 Proof of Theorem 1,[0],[0]
[ n∑ i=1,A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi)σ′ ( w∗1 >xi ) xi ] = 0d× d× ...× d︸,A.2 Proof of Theorem 1,[0],[0]
"︷︷ ︸
k times
.
",A.2 Proof of Theorem 1,[0],[0]
"Let ε > 0, |∆a1| = ε9/4 and ∆w1 = εu1 for u1 : ‖u1‖2 = 1.",A.2 Proof of Theorem 1,[0],[0]
"Clearly, when ε→ 0, ∆a1 = o(‖∆w1‖2), ∆a1 = o(1) and ‖∆w1‖ = o(1).",A.2 Proof of Theorem 1,[0],[0]
"Then we expand L̂n(θ̃; p) at the point θ∗ up to the sixth order and
thus as ε→ 0,
L̂n(θ̃; p) = L̂n(θ ∗; p) +
1
2!
",A.2 Proof of Theorem 1,[0],[0]
"d2L̂n(θ ∗; p)
d2a1 (∆a1)
2
+ 1
2 ∆a1∆w
> 1
d
da1
[ ∇2w1L̂n(θ∗; p) ]",A.2 Proof of Theorem 1,[0],[0]
"∆w1 + o(|∆a1|2) + o(|∆a1|‖∆w1‖22) + o(‖∆w1‖52)
",A.2 Proof of Theorem 1,[0],[0]
= L̂n(θ ∗),A.2 Proof of Theorem 1,[0],[0]
"+
1
2!
",A.2 Proof of Theorem 1,[0],[0]
"d2L̂n(θ ∗; p)
d2a1 ε9/2
+ 1
2n sgn(∆a1)ε 9/4+2 n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ′′ ( w∗1 >xi ) (u>1 xi) 2
+ o(ε9/2) + o(ε9/4+2) + o(ε5)
= L̂n(θ ∗)",A.2 Proof of Theorem 1,[0],[0]
"+
1
2n sgn(∆a1)ε",A.2 Proof of Theorem 1,[0],[0]
17/4 n∑ i=1,A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ′′ ( w∗1 >xi ) (u>1 xi) 2 + o(ε17/4).
",A.2 Proof of Theorem 1,[0],[0]
"Since ε > 0 and L̂n(θ̃; p) ≥ L̂n(θ∗; p) holds for any u1 : ‖u1‖2 = 1 and any sgn(∆a1) ∈ {−1, 1}, then n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ′′ ( w∗1 >xi ) (u>xi) 2 = 0, for any u ∈ Rd.",A.2 Proof of Theorem 1,[0],[0]
"(2) Therefore, n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi)σ′′ ( w∗1 >xi ) xix >,A.2 Proof of Theorem 1,[0],[0]
i = 0d×d.,A.2 Proof of Theorem 1,[0],[0]
"By assumption that there exists a set of orthogonal basis E = {e1, ..., ed} in Rd and a subset U+ ⊆ E such that PX|Y (X ∈ Span(U1)|Y = 1) = 1 and by assumption that r = |U+ ∪ U−| > max{r+, r−} = max{|U+|, |U−|}, then the set U+\U− is not an empty set.",A.2 Proof of Theorem 1,[0],[0]
"It is easy to show that for any vector v ∈ U+\U−, PX×Y (v>X = 0|Y = 1) = 0.",A.2 Proof of Theorem 1,[0],[0]
We prove it by contradiction.,A.2 Proof of Theorem 1,[0],[0]
"If we assume p = PX×Y (v>X = 0|Y = 1) > 0, then for random vectors X1, ...,X|U+| independently drawn from the conditional distribution PX|Y=1,
PX|Y=1 |U+|⋃ i=1",A.2 Proof of Theorem 1,[0],[0]
{ v>Xi = 0 } ∣∣∣∣∣Y,A.2 Proof of Theorem 1,[0],[0]
= 1  = |U+|∏ i=1,A.2 Proof of Theorem 1,[0],[0]
"PX|Y=1 ( v>Xi = 0|Y = 1 ) = p|U+| > 0.
",A.2 Proof of Theorem 1,[0],[0]
"Furthermore, since X1, ...,X|U+| ∈ Span(U+), v>Xi = 0, i = 1, ..., |U+| and v ∈ U+, then the rank of the matrix ( X1, ...,X|U+| ) is at most |U+| − 1 and this indicates that the matrix is not a full rank matrix with probability p|U+| > 0.",A.2 Proof of Theorem 1,[0],[0]
This leads to the contradiction with the Assumption 2.,A.2 Proof of Theorem 1,[0],[0]
"Thus, with probability 1, v>xi 6= 0 for all i : yi = 1 and v>xi = 0 for all i : yi = −1.",A.2 Proof of Theorem 1,[0],[0]
"Therefore, by setting u = v in Equation (2), we have
0 =",A.2 Proof of Theorem 1,[0],[0]
"− ∑ i:yi=1 `′p(−yif(xi;θ∗))σ′′(w∗1>xi)(v>xi)2 ≤ 0,
where the equality holds if and only if ∀i : yi = 1, `′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
= 0,A.2 Proof of Theorem 1,[0],[0]
"and this further indicates that ∀i : yi = 1, yif(xi;θ∗) ≥ z0 > 0.",A.2 Proof of Theorem 1,[0],[0]
"Furthermore, since θ∗ is a critical point and thus
0 = dL̂n(θ
∗; p)
da0 =
1
n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi) =,A.2 Proof of Theorem 1,[0],[0]
− 1 n ∑,A.2 Proof of Theorem 1,[0],[0]
i:yi=1 `′p(−yif(xi;θ∗)),A.2 Proof of Theorem 1,[0],[0]
+ 1 n ∑,A.2 Proof of Theorem 1,[0],[0]
"i:yi=−1 `′p(−yif(xi;θ∗))
",A.2 Proof of Theorem 1,[0],[0]
"= 1
n",A.2 Proof of Theorem 1,[0],[0]
∑,A.2 Proof of Theorem 1,[0],[0]
"i:yi=−1 `′p(−yif(xi;θ∗)).
",A.2 Proof of Theorem 1,[0],[0]
"Therefore, ∀i : yi = −1, yif(xi;θ∗)",A.2 Proof of Theorem 1,[0],[0]
≥ z0 > 0,A.2 Proof of Theorem 1,[0],[0]
and this indicates that R̂n(θ∗) = 0.,A.2 Proof of Theorem 1,[0],[0]
Proof of Claim 2:,A.2 Proof of Theorem 1,[0],[0]
"First, we define M0 = dM/2e, then
M0 ≥ max{r+, r−}.
",A.2 Proof of Theorem 1,[0],[0]
"In addition, since r = |U+ ∪ U−|, then max{r+, r−}+ min{r+, r−} ≥ r. Therefore,
2M0 ≥ 2 max{r+, r−} > 2r",A.2 Proof of Theorem 1,[0],[0]
− r+ − r− ≥ 2 min{r,A.2 Proof of Theorem 1,[0],[0]
"− r+, r − r−} , 2K,
where we define K = min{r",A.2 Proof of Theorem 1,[0],[0]
"− r+, r − r−}.",A.2 Proof of Theorem 1,[0],[0]
"Since in claim 2, we assume that a∗j 6= 0 for all j ∈",A.2 Proof of Theorem 1,[0],[0]
"[M ], then there exists ai1 , ..., aiM0 , i1 < i2 < ...",A.2 Proof of Theorem 1,[0],[0]
"< iM0 having the same sign, i.e.,
sgn(ai1) = ...",A.2 Proof of Theorem 1,[0],[0]
"= sgn(aiM0 ).
",A.2 Proof of Theorem 1,[0],[0]
"Without loss of generality, we assume that sgn(a1) = ...",A.2 Proof of Theorem 1,[0],[0]
= sgn(aM0) = +1.,A.2 Proof of Theorem 1,[0],[0]
Now we prove the claim 2.,A.2 Proof of Theorem 1,[0],[0]
"First, we consider the Hessian matrix H(w∗1, ...,w ∗ M0 ).",A.2 Proof of Theorem 1,[0],[0]
Since θ∗ is a local minima with R̂n(θ ∗),A.2 Proof of Theorem 1,[0],[0]
"> 0, then the inequality
F (u1, ...,uM0) = M0∑ j=1 M0∑ k=1",A.2 Proof of Theorem 1,[0],[0]
"u>j ∇2wj ,wk L̂n(θ ∗; p)uk ≥ 0
holds for all vectors u1, ...,uM0 ∈ Rd.",A.2 Proof of Theorem 1,[0],[0]
"Since
∇2wj L̂n(θ∗; p) = a∗j n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi)σ′′ ( w∗j >xi ) xix,A.2 Proof of Theorem 1,[0],[0]
>,A.2 Proof of Theorem 1,[0],[0]
"i
+ a∗j 2
n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′′p(−yif(xi;θ∗)),A.2 Proof of Theorem 1,[0],[0]
[ σ′ ( w∗j >xi )]2 xix >,A.2 Proof of Theorem 1,[0],[0]
"i ,
and
∇2wj ,wk L̂n(θ ∗; p) =
a∗ja ∗ k
n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′′p(−yif(xi;θ∗)),A.2 Proof of Theorem 1,[0],[0]
[ σ′ ( w∗j >xi )],A.2 Proof of Theorem 1,[0],[0]
[ σ′ ( w∗k >xi + b ∗ k )],A.2 Proof of Theorem 1,[0],[0]
"xix > i .
",A.2 Proof of Theorem 1,[0],[0]
"Thus, we have for any u1, ...,uM0 ∈ Rd,
F (u1, ...,uM0) =",A.2 Proof of Theorem 1,[0],[0]
"− 1
n M0∑ j=1",A.2 Proof of Theorem 1,[0],[0]
[ a∗j n∑ i=1,A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))yiσ′′ ( w∗j >xi )( u>j xi )2]
+ 1
n M0∑ j=1 M0∑ k=1",A.2 Proof of Theorem 1,[0],[0]
[ a∗ja ∗ k n∑ i=1,A.2 Proof of Theorem 1,[0],[0]
"`′′p(−yif(xi;θ∗))σ′ ( w∗j >xi ) σ′ ( w∗k >xi + b ∗ k )( u>j xi )( u>k xi )]
= − 1 n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))yi M0∑ j=1,A.2 Proof of Theorem 1,[0],[0]
"[ a∗jσ ′′ ( w∗j >xi )( u>j xi )2] + 1
n n∑ i=1 `′′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
M0∑ j=1 a∗jσ ′,A.2 Proof of Theorem 1,[0],[0]
( w∗j >xi )( u>j xi )2 .,A.2 Proof of Theorem 1,[0],[0]
"Now we find some coefficients α1, ..., αM0 , not all zero, and vectors u1, ...,uM0 , not all zero vector, satisfying
M0∑ j=1 αjσ ′",A.2 Proof of Theorem 1,[0],[0]
"( w∗j >xi ) u>j xi = 0, ∀i ∈",A.2 Proof of Theorem 1,[0],[0]
"[n],
and ∀i : yi = −1 and ∀j ∈",A.2 Proof of Theorem 1,[0],[0]
"[M0], u>j xi = 0.
We note here that if sgn(a1) = ...",A.2 Proof of Theorem 1,[0],[0]
"= sgn(aM0) = −1, then we need to find coefficients α1, ..., αM0 , not all zero, and vectors u1, ...,uM0 , not all zero vector, satisfying
M0∑ j=1 αjσ ′",A.2 Proof of Theorem 1,[0],[0]
"( w∗j >xi ) u>j xi = 0, ∀i ∈",A.2 Proof of Theorem 1,[0],[0]
"[n],
and ∀i : yi = 1 and ∀j ∈",A.2 Proof of Theorem 1,[0],[0]
"[M0], u>j xi = 0.",A.2 Proof of Theorem 1,[0],[0]
"Since θ∗ is a local minima, then by Lemma 1, we have
n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))yiσ′(w∗j>xi)xi = 0d.,A.2 Proof of Theorem 1,[0],[0]
"(3)
Furthermore, by the assumption that K = r−max{r+, r−} > 0, then the set U+\U− is not an empty set.",A.2 Proof of Theorem 1,[0],[0]
"Thus, for ∀v ∈ U+\U− ⊂ E , with probability 1, ∀i : yi = −1, v>xi = 0.",A.2 Proof of Theorem 1,[0],[0]
"In addition, by the analysis presented in the proof of claim 1, we have that with probability 1, v>xi 6= 0 for all i : yi = 1.",A.2 Proof of Theorem 1,[0],[0]
"Since
K = r−max{r+, r−} = |U+ ∪U−| −max{|U+|, |U−|} = |U+\U−|+ |U−| −max{|U+|, |U−|} ≤ |U+\U−|,
then without loss of generality, we assume that {e1, ..., eK} ⊆ U+\U− and U+ = {e1, ..., er+}.",A.2 Proof of Theorem 1,[0],[0]
"Thus, with probability 1, ∀j ∈ [K], ∀i : yi = −1, e>j xi = 0 and ∀i : yi = 1, e>j xi 6= 0.",A.2 Proof of Theorem 1,[0],[0]
"Then by Equation (3), now we consider the following set of linear equations
n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))yiσ′(w∗1>xi) ( e>1 xi ) = 0, ..., n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))yiσ′(w∗M0 >xi + b ∗ M0) ( e>1 xi ) = 0,
... n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))yiσ′(w∗1>xi) ( e>Kxi ) = 0, ..., n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
"`′p(−yif(xi;θ∗))yiσ′(w∗M0 >xi + b ∗ M0) ( e>Kxi ) = 0.
",A.2 Proof of Theorem 1,[0],[0]
These equations can be rewritten in a matrix form σ′(w∗1,A.2 Proof of Theorem 1,[0],[0]
>x1) ( e>1 x1 ) ...,A.2 Proof of Theorem 1,[0],[0]
σ′(w∗1,A.2 Proof of Theorem 1,[0],[0]
>xn) ( e>1 xn ) ... ... ...,A.2 Proof of Theorem 1,[0],[0]
σ′(w∗M0,A.2 Proof of Theorem 1,[0],[0]
>x1 + b ∗ M0 ) ( e>1 x1 ) ...,A.2 Proof of Theorem 1,[0],[0]
σ′(w∗M0,A.2 Proof of Theorem 1,[0],[0]
>xn + b ∗ M0 ) ( e>1 xn ) ... ... ...,A.2 Proof of Theorem 1,[0],[0]
σ′(w∗1,A.2 Proof of Theorem 1,[0],[0]
>x1),A.2 Proof of Theorem 1,[0],[0]
( e>Kx1 ) ... σ′(w∗1,A.2 Proof of Theorem 1,[0],[0]
>xn) ( e>Kxn ) ... ...,A.2 Proof of Theorem 1,[0],[0]
"...
σ′(w∗M0",A.2 Proof of Theorem 1,[0],[0]
>x1 + b ∗ M0 ),A.2 Proof of Theorem 1,[0],[0]
( e>Kx1 ) ...,A.2 Proof of Theorem 1,[0],[0]
σ′(w∗M0,A.2 Proof of Theorem 1,[0],[0]
>xn + b ∗ M0 ),A.2 Proof of Theorem 1,[0],[0]
"( e>Kxn )  (KM0×n)︸ ︷︷ ︸
P
 `′p(−y1f(x1;θ∗))y1",A.2 Proof of Theorem 1,[0],[0]
"`′p(−y2f(x2;θ∗))y2 ... ... ... ...
...",A.2 Proof of Theorem 1,[0],[0]
"`′p(−ynf(x1;θ∗))yn  ︸ ︷︷ ︸
q
= 0n
or Pq = 0n.
",A.2 Proof of Theorem 1,[0],[0]
"Since M ≥ 2n∆r = 2nK , then M0K ≥ MK/2",A.2 Proof of Theorem 1,[0],[0]
≥,A.2 Proof of Theorem 1,[0],[0]
n.,A.2 Proof of Theorem 1,[0],[0]
"Clearly, if rank(P )",A.2 Proof of Theorem 1,[0],[0]
"= n, we should have q = 0n and this indicates that `′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
= 0,A.2 Proof of Theorem 1,[0],[0]
for all i ∈,A.2 Proof of Theorem 1,[0],[0]
[n] or R̂n(θ∗) = 0.,A.2 Proof of Theorem 1,[0],[0]
"Thus, we only need to consider
the case where rank(P )",A.2 Proof of Theorem 1,[0],[0]
< n ≤M0K.,A.2 Proof of Theorem 1,[0],[0]
"This means the raw vectors of the matrix P is linearly dependent and thus there exists coefficients vectors (β11, ..., β1K), ..., (βM01, ..., βM0K), not all zero vectors, such that
K∑ s=1 M0∑ j=1 σ′(w∗j >",A.2 Proof of Theorem 1,[0],[0]
"xi)βjs(e > s xi) = 0, ∀i ∈",A.2 Proof of Theorem 1,[0],[0]
"[n],
or M0∑ j=1 a∗jσ ′(w∗j >xi)
( 1
a∗j K∑ s=1 βjses
)>",A.2 Proof of Theorem 1,[0],[0]
xi,A.2 Proof of Theorem 1,[0],[0]
"= 0, ∀i ∈",A.2 Proof of Theorem 1,[0],[0]
"[n],
by assumption that a∗j 6= 0 for all j = 1, ...,M0.",A.2 Proof of Theorem 1,[0],[0]
"Define uj = 1a∗j ∑K s=1 βjses for j = 1, ...,M0, then we have M0∑ j=1 a∗jσ ′(w∗j",A.2 Proof of Theorem 1,[0],[0]
>,A.2 Proof of Theorem 1,[0],[0]
xi)u,A.2 Proof of Theorem 1,[0],[0]
>,A.2 Proof of Theorem 1,[0],[0]
"j xi = 0, ∀i ∈",A.2 Proof of Theorem 1,[0],[0]
[n].,A.2 Proof of Theorem 1,[0],[0]
"(4)
Furthermore, since uj ∈ Span({e1, ..., eK}) and with probability 1, e>j xi = 0, for ∀i : yi = −1, ∀j ∈",A.2 Proof of Theorem 1,[0],[0]
"[K], then ∀j ∈",A.2 Proof of Theorem 1,[0],[0]
"[M ], ∀i : yi = −1, u>j xi = 0.",A.2 Proof of Theorem 1,[0],[0]
"Thus, by setting uj = 1a∗j ∑K s=1 βjses for j = 1, ...,M0, then we have
F (u1, ...,uM0) =",A.2 Proof of Theorem 1,[0],[0]
"− 1
n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))yi M0∑ j=1,A.2 Proof of Theorem 1,[0],[0]
"[ a∗jσ ′′ ( w∗j >xi )( u>j xi )2] + 1
n n∑ i=1 `′′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
M0∑ j=1 a∗jσ ′,A.2 Proof of Theorem 1,[0],[0]
"( w∗j >xi )( u>j xi )2 = − 1
n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))yi M0∑ j=1,A.2 Proof of Theorem 1,[0],[0]
[ a∗jσ ′′ ( w∗j >xi )( u>j xi )2] by Eq.,A.2 Proof of Theorem 1,[0],[0]
(4) =,A.2 Proof of Theorem 1,[0],[0]
"− 1
n ∑",A.2 Proof of Theorem 1,[0],[0]
i:yi=1 `′p(−yif(xi;θ∗)) M0∑ j=1,A.2 Proof of Theorem 1,[0],[0]
[ a∗jσ ′′ ( w∗j >xi )( u>j xi )2] ≥ 0.,A.2 Proof of Theorem 1,[0],[0]
(5),A.2 Proof of Theorem 1,[0],[0]
"In addition, since σ′′(z) > 0",A.2 Proof of Theorem 1,[0],[0]
for all z ∈ R and a∗j > 0 for all j ∈,A.2 Proof of Theorem 1,[0],[0]
"[M0], then we have
`′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
M0∑ j=1,A.2 Proof of Theorem 1,[0],[0]
"[ a∗jσ ′′ ( w∗j >xi )( u>j xi )2] ≥ 0, ∀i : yi = 1
and this leads to F (u1, ...,uM0) ≤ 0.
",A.2 Proof of Theorem 1,[0],[0]
Together with Eq.,A.2 Proof of Theorem 1,[0],[0]
"(5), we have F (u1, ...,uM0) = 0,
and thus
`′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
M0∑ j=1,A.2 Proof of Theorem 1,[0],[0]
"[ a∗jσ ′′ ( w∗j >xi )( u>j xi )2] = 0, ∀i : yi = 1. (6)
Now we split the index {1, ..., n} set into two disjoint subset C0, C1:
C0 = {i ∈",A.2 Proof of Theorem 1,[0],[0]
"[n] : yi = 1, and ∃j ∈",A.2 Proof of Theorem 1,[0],[0]
"[M0],u>j xi 6= 0}, C1 = {i ∈",A.2 Proof of Theorem 1,[0],[0]
[n] : yi = 1 and ∀j ∈,A.2 Proof of Theorem 1,[0],[0]
"[M0],u>j xi = 0}.
",A.2 Proof of Theorem 1,[0],[0]
"Clearly, for all i ∈ C0, by the fact that a∗j > 0 for all j ∈",A.2 Proof of Theorem 1,[0],[0]
[M0] and σ′′(z) > 0,A.2 Proof of Theorem 1,[0],[0]
"for all z ∈ R, we have
M0∑ j=1",A.2 Proof of Theorem 1,[0],[0]
"[ a∗jσ ′′ ( w∗j >xi )( u>j xi )2] > 0,
and by Equation (6), we have `′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
"= 0, ∀i ∈ C0.
",A.2 Proof of Theorem 1,[0],[0]
Now we need to consider the index set C1.,A.2 Proof of Theorem 1,[0],[0]
"First, we show that the following inequality holds with probability 1, |C1| < r+ ≤ max{r+, r−}.",A.2 Proof of Theorem 1,[0],[0]
"Since uj =
1 a∗j
∑K i=1 βjses for j = 1, ...,M0 and coefficient vectors (β11, ..., β1K), ..., (βM01, ..., βM0K) are
not all zero vectors, then the there exists a j0 ∈",A.2 Proof of Theorem 1,[0],[0]
[K] such that the non-zero vector uj0 satisfy u>j0xi = 0 for all i ∈ C1 and uj0 ∈,A.2 Proof of Theorem 1,[0],[0]
"Span({e1, ..., eK}).",A.2 Proof of Theorem 1,[0],[0]
"Furthermore, by assumption U+ = {e1, ..., er+}, thus we have
u>j0xi = K∑ s=1",A.2 Proof of Theorem 1,[0],[0]
(u>j0es)(x >,A.2 Proof of Theorem 1,[0],[0]
i es) = r+∑ s=1 (u>j0es)(x,A.2 Proof of Theorem 1,[0],[0]
>,A.2 Proof of Theorem 1,[0],[0]
"i es) = 0 (7)
holds for all i ∈ C1.",A.2 Proof of Theorem 1,[0],[0]
"If |C1| ≥ r+, then without loss of generality, we assume that {1, ..., r+} ⊆ C1.",A.2 Proof of Theorem 1,[0],[0]
"Thus, with probability 1, the matrix e>1 x1 ...",A.2 Proof of Theorem 1,[0],[0]
"e>r+x1... ... ...
",A.2 Proof of Theorem 1,[0],[0]
e>1 xr+ ...,A.2 Proof of Theorem 1,[0],[0]
e > r+xr+  = x>1...,A.2 Proof of Theorem 1,[0],[0]
"x>r+ (e1 ... er+) has a full rank equal to r+, by the fact that {x1, ..., xr+} ⊂ Span(U+) and ( x1, ..., xr+ ) is a full rank matrix with probability 1.",A.2 Proof of Theorem 1,[0],[0]
"Thus, by Equation (7), we have e>1 x1 ...",A.2 Proof of Theorem 1,[0],[0]
e>r+x1... ... ...,A.2 Proof of Theorem 1,[0],[0]
e>1 xr+ ...,A.2 Proof of Theorem 1,[0],[0]
"e > r+xr+  u>j0e1... u>j0er+
 = 0d and this leads to u>j0es = 0 for all s ∈",A.2 Proof of Theorem 1,[0],[0]
[K].,A.2 Proof of Theorem 1,[0],[0]
This contradicts with the fact that uj0 ∈,A.2 Proof of Theorem 1,[0],[0]
"Span({e1, ..., eK})",A.2 Proof of Theorem 1,[0],[0]
and uj0 is not a zero vector.,A.2 Proof of Theorem 1,[0],[0]
"Therefore, |C1| < r+ ≤ M0.",A.2 Proof of Theorem 1,[0],[0]
"Furthermore, since `′(z) = 0",A.2 Proof of Theorem 1,[0],[0]
"if and only if z ≤ −z0 for some positive z0 > 0, then `′′(z) = 0",A.2 Proof of Theorem 1,[0],[0]
when z ≤ −z0.,A.2 Proof of Theorem 1,[0],[0]
"Now we consider the function F , since ∀i ∈ C0 : `′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
= 0 and `′′p(−yif(xi;θ∗)),A.2 Proof of Theorem 1,[0],[0]
"= 0, then
F (u1, ...,uM0) =",A.2 Proof of Theorem 1,[0],[0]
"− 1
n ∑ i∈C1 `′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
M0∑ j=1,A.2 Proof of Theorem 1,[0],[0]
"[ a∗jσ ′′ ( w∗j >xi )( u>j xi )2] + 1
n ∑ i∈C1 `′′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
M0∑ j=1 a∗jσ ′,A.2 Proof of Theorem 1,[0],[0]
"( w∗j >xi )( u>j xi )2 ≥ 0 holds for all u1, ...,uM0 ∈ Span({e1, ..., eK}).",A.2 Proof of Theorem 1,[0],[0]
"Now we set uj = αje1, j = 1, ...,M0 for some scalar αj .",A.2 Proof of Theorem 1,[0],[0]
"We only need to find α1, ..., αM0 such that
M0∑ j=1 αja ∗",A.2 Proof of Theorem 1,[0],[0]
jσ ′,A.2 Proof of Theorem 1,[0],[0]
"( w∗j >xi ) e>1 xi = 0, ∀i ∈ C1.
",A.2 Proof of Theorem 1,[0],[0]
"Since |C1| < r+ ≤M0, then there exists α∗1, ..., α∗M0 , not all zeros, such that
M0∑ j=1 α∗ja ∗",A.2 Proof of Theorem 1,[0],[0]
jσ ′,A.2 Proof of Theorem 1,[0],[0]
"( w∗j >xi ) e>1 xi = 0, ∀i ∈ C1.
",A.2 Proof of Theorem 1,[0],[0]
"Then by setting uj = α ∗ je1, we have
F (u1, ...,uM0) =",A.2 Proof of Theorem 1,[0],[0]
"− 1
n ∑ i∈C1 `′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
M0∑ j=1 [ |α∗j,A.2 Proof of Theorem 1,[0],[0]
"|2a∗jσ′′ ( w∗j >xi )( e>1 xi )2] ≥ 0. .
",A.2 Proof of Theorem 1,[0],[0]
"Similarly, since |α1|, ..., |αM0",A.2 Proof of Theorem 1,[0],[0]
"| are not all zeros, a∗j > 0",A.2 Proof of Theorem 1,[0],[0]
for all j ∈,A.2 Proof of Theorem 1,[0],[0]
"[M0], σ′′(z) > 0 for all z ∈ R and e>1 xi 6= 0 holds for all i with probability 1, then
`′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
"= 0, ∀i ∈ C1.
",A.2 Proof of Theorem 1,[0],[0]
"Therefore, this indicates that
`′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
"= 0, ∀i : yi = 1.
",A.2 Proof of Theorem 1,[0],[0]
"Furthermore, since θ∗ is a local minima and thus
0 = dL̂n(θ
∗; p)
da0 =
1
n n∑ i=1",A.2 Proof of Theorem 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi) =,A.2 Proof of Theorem 1,[0],[0]
− 1 n ∑,A.2 Proof of Theorem 1,[0],[0]
i:yi=1 `′p(−yif(xi;θ∗)),A.2 Proof of Theorem 1,[0],[0]
+ 1 n ∑,A.2 Proof of Theorem 1,[0],[0]
"i:yi=−1 `′p(−yif(xi;θ∗))
",A.2 Proof of Theorem 1,[0],[0]
"= 1
n",A.2 Proof of Theorem 1,[0],[0]
∑,A.2 Proof of Theorem 1,[0],[0]
"i:yi=−1 `′p(−yif(xi;θ∗)).
",A.2 Proof of Theorem 1,[0],[0]
This means when `′p(−yif(xi;θ∗)),A.2 Proof of Theorem 1,[0],[0]
"= 0 holds for all i : yi = 1, we have `′p(−yif(xi;θ∗))",A.2 Proof of Theorem 1,[0],[0]
= 0,A.2 Proof of Theorem 1,[0],[0]
for all i : yi = −1.,A.2 Proof of Theorem 1,[0],[0]
These two together give us R̂n(θ∗) = 0.,A.2 Proof of Theorem 1,[0],[0]
"Similarly, when sgn(a1) = ... = sgn(aM0) = −1, we have the similar the results.",A.2 Proof of Theorem 1,[0],[0]
"Therefore, θ∗ is a local minima with R̂n(θ ∗) = 0.",A.2 Proof of Theorem 1,[0],[0]
"Proposition 13 Assume that the loss function `p satisfies assumption 1, the distribution PX×Y satisfies assumption 2 and 3, the network architecture satisfies assumption 4 and neurons in the network satisfy assumption 5.",A.3 Proof of Proposition 1,[0],[0]
Assume,A.3 Proof of Proposition 1,[0],[0]
"that samples in the dataset D = {(xi, yi)}ni=1, n",A.3 Proof of Proposition 1,[0],[0]
≥ 1 are independently drawn from the distribution PX×Y .,A.3 Proof of Proposition 1,[0],[0]
Assume that the neuron σ(z) = z2 and the number of neurons M > r.,A.3 Proof of Proposition 1,[0],[0]
"If the real parameters θ∗ = (θ∗S ,θ ∗ D) denote a local minimum of the loss function L̂n(θS ,θD; p) and p ≥ 6, then R̂n(θ∗) = L̂n(θ∗; p) = 0 holds with probability one.
",A.3 Proof of Proposition 1,[0],[0]
Proof: We first recall some notations defined in the paper.,A.3 Proof of Proposition 1,[0],[0]
"The output of the neural network is
f(x;θ) = fS(x;θS) + fD(x;θD),
where fS(x;θS) is the single layer neural network parameterized by θS , i.e.,
fS(x;θS)",A.3 Proof of Proposition 1,[0],[0]
"= a0 + M∑ j=1 ajσ ( w>j x ) ,
and fD(x;θD) is a deep neural network parameterized by θD.",A.3 Proof of Proposition 1,[0],[0]
"The empirical loss function is given by
L̂n(θ; p) = L̂n(θS ,θD; p)",A.3 Proof of Proposition 1,[0],[0]
"= 1
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
"`p(−yif(xi;θ)).
",A.3 Proof of Proposition 1,[0],[0]
"We first assume that the θ∗ = (θ∗S ,θ ∗ D) is a local minima.",A.3 Proof of Proposition 1,[0],[0]
"We next prove the following two claims: Claim 1: If θ∗ = (θ∗S ,θ ∗ D) is a local minima and there exists j ∈",A.3 Proof of Proposition 1,[0],[0]
"[M ] such that a∗j = 0, then R̂n(θ ∗) = 0.",A.3 Proof of Proposition 1,[0],[0]
Claim 2:,A.3 Proof of Proposition 1,[0],[0]
"If θ∗ = (θ∗S ,θ ∗ D) is a local minima and a ∗ j 6= 0 for all j ∈",A.3 Proof of Proposition 1,[0],[0]
"[M ], then R̂n(θ∗) = 0.",A.3 Proof of Proposition 1,[0],[0]
(a) Proof of claim 1.,A.3 Proof of Proposition 1,[0],[0]
"We prove that if θ∗ = (θ∗S ,θ ∗ D) is a local minima and there exists j ∈",A.3 Proof of Proposition 1,[0],[0]
"[M ] such that a∗j = 0, then R̂n(θ ∗) = 0.",A.3 Proof of Proposition 1,[0],[0]
"Without loss of generality, we assume that a∗1 = 0.",A.3 Proof of Proposition 1,[0],[0]
"Since θ∗ = (θ∗S ,θ ∗ D) is a local minima, then there exists ε0 > 0",A.3 Proof of Proposition 1,[0],[0]
"such that for any small perturbations ∆a1, ∆w1 on parameters a ∗ 1 and w ∗ 1, i.e., |∆a1|2 + ‖∆w1‖22 ≤",A.3 Proof of Proposition 1,[0],[0]
"ε20, we have
L̂n(θ̃S ,θ ∗ D) ≥ L̃n(θ∗S ,θ∗D),
where θ̃ = (ã0, ã1, ..., ãM , w̃1, ..., w̃M ), ã1 = a ∗ 1 + ∆a1, w̃1 = w ∗ 1 + ∆w1 and ãj = a ∗ j , w̃j",A.3 Proof of Proposition 1,[0],[0]
= w ∗ j for j 6= 1.,A.3 Proof of Proposition 1,[0],[0]
"Now we consider Taylor expansion of L̃n(θ̃S ,θ∗D) at (θ∗S ,θ∗D).",A.3 Proof of Proposition 1,[0],[0]
"We note here that the Taylor expansion of L̂(θS ,θ ∗ D; p) on θS always exists, since the empirical loss function L̂n has continuous derivatives with respect to fS up to the p-th order and the output of the neural network f(x;θS) is infinitely differentiable with respect to θS due to the fact that neuron activation function σ is real analytic.",A.3 Proof of Proposition 1,[0],[0]
"We first calculate the first order derivatives at the point (θ∗S ,θ ∗ D)
dL̂n(θ ∗)
da1 =
1
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ ( w∗1 >xi ) = 0, θ∗ is a critical point,
∇w1L̂n(θ∗) = a∗1 n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ′ ( w∗1 >xi ) xi = 0d, θ ∗ is a critical point.
",A.3 Proof of Proposition 1,[0],[0]
"Next, we calculate the second order derivatives at the point (θ∗S ,θ ∗ D),
d2L̂(θ∗)
",A.3 Proof of Proposition 1,[0],[0]
"da21 =
1
n",A.3 Proof of Proposition 1,[0],[0]
N∑ i=1,A.3 Proof of Proposition 1,[0],[0]
"`′′p(−yif(xi;θ∗))σ2 ( w∗1 >xi ) ≥ 0,
d
da1 (∇w1L(θ∗))",A.3 Proof of Proposition 1,[0],[0]
"=
1
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi)σ′ ( w∗1 >xi ),A.3 Proof of Proposition 1,[0],[0]
"xi
+ a∗1 n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ∗))σ ( w∗1 >xi ),A.3 Proof of Proposition 1,[0],[0]
σ′,A.3 Proof of Proposition 1,[0],[0]
"( w∗1 >xi ) xi
= 0d,
where the first term equals to the zero vector by the necessary condition for a local minima presented in Lemma 1 and the second term equals to the zero vector by the assumption that a∗1 = 0.",A.3 Proof of Proposition 1,[0],[0]
"Furthermore, by the assumption that a∗1 = 0, we have
∇2w1L̂n(θ∗; p) = a∗1 n ∇w1",A.3 Proof of Proposition 1,[0],[0]
[ n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ))(−yi)σ′ ( w∗1 >xi ) xi ] = 0d×d.
",A.3 Proof of Proposition 1,[0],[0]
"We further calculate the third order derivatives
d
da1
[ ∇2w1L̂n(θ∗; p) ] =",A.3 Proof of Proposition 1,[0],[0]
"d
da1
[ a∗1∇w1 [ 1
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ))(−yi)σ′ ( w∗1 >xi ),A.3 Proof of Proposition 1,[0],[0]
"xi
]]
= ∇w1
[ 1
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ))(−yi)σ′ ( w∗1 >xi ) xi ],A.3 Proof of Proposition 1,[0],[0]
"+ 0d×d by a ∗ 1 = 0
= 1
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ))(−yi)σ′′ ( w∗1 >xi ) xix >,A.3 Proof of Proposition 1,[0],[0]
"i
+ a∗1 n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ)),A.3 Proof of Proposition 1,[0],[0]
[ σ′ ( w∗1 >xi )]2 xix >,A.3 Proof of Proposition 1,[0],[0]
"i
= 1
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ))(−yi)σ′′ ( w∗1 >xi ) xix,A.3 Proof of Proposition 1,[0],[0]
>,A.3 Proof of Proposition 1,[0],[0]
"i by a ∗ 1 = 0
and
∇3w1L̂n(θ∗; p) = a∗1∇2w1
[ 1
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ))(−yi)σ′ ( w∗1 >xi ) xi ] = 0d×d×d.
",A.3 Proof of Proposition 1,[0],[0]
"In fact, it is easy to show that for any 2 ≤ k ≤ p,
∇kw1L̂n(θ∗; p) =",A.3 Proof of Proposition 1,[0],[0]
"a∗1∇k−1w1
[ 1
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ))(−yi)σ′ ( w∗1 >xi ) xi ] = 0d× d× ...× d︸,A.3 Proof of Proposition 1,[0],[0]
"︷︷ ︸
k times
.
",A.3 Proof of Proposition 1,[0],[0]
"Let ε > 0, ∆a1 = sgn(a1)ε 9/4 and ∆w1 = εu1 for u1 : ‖u1‖2 = 1.",A.3 Proof of Proposition 1,[0],[0]
"Clearly, when ε → 0, ∆a1 = o(‖∆w1‖2), ∆a1 = o(1) and ‖∆w1‖ = o(1).",A.3 Proof of Proposition 1,[0],[0]
"Then we expand L̂n(θ̃S ,θ∗D) at the point θ∗ up to the
sixth order and thus as ε→ 0,
L̂n(θ̃S ,θ ∗ D) = L̂n(θ ∗ S ,θ ∗ D) +
1
2!n
d2L̂n(θ ∗)
d2a1 (∆a1)
2
+ 1
2n ∆a1∆w
> 1
d
da1
[ D2w1L̂n(θ ∗; p) ]",A.3 Proof of Proposition 1,[0],[0]
"∆w1 + o(|a1|2) + o(|a1|‖w1‖22) + o(‖∆w1‖52)
",A.3 Proof of Proposition 1,[0],[0]
"= L̂n(θ ∗ S ,θ ∗ D) +
1
2!n
d2L̂n(θ ∗)
d2a1 ε9/2 +
1
2n sgn(a1)ε 9/4+2 n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ))σ′′ ( w∗1 >xi ) (u>1 xi) 2
+ o(ε9/2) + o(ε9/4+2) + o(ε5)
",A.3 Proof of Proposition 1,[0],[0]
"= L̂n(θ ∗ S ,θ ∗ D) +
1
2n sgn(a1)ε",A.3 Proof of Proposition 1,[0],[0]
17/4 n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ))(−yi)σ′′ ( w∗1 >xi ) (u>1 xi) 2 + o(ε17/4)
",A.3 Proof of Proposition 1,[0],[0]
"Since ε > 0 and L̂n(θ̃S ,θ ∗ D; p) ≥ L̂n(θ∗; p) holds for any u1 : ‖u1‖2 = 1 and any sgn(a1) ∈ {−1, 1}, then n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ))(−yi)σ′′ ( w∗1 >xi ) (u>xi) 2 = 0, for any u ∈ Rd.",A.3 Proof of Proposition 1,[0],[0]
"(8) Therefore, n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ))(−yi)σ′′ ( w∗1 >xi ) xix >,A.3 Proof of Proposition 1,[0],[0]
"i = 0d×d.
",A.3 Proof of Proposition 1,[0],[0]
"By assumption that there exists a set of orthogonal basis E = {e1, ..., ed} in Rd and a subset U+ ⊆ E such that PX|Y (X ∈ Span(U1)|Y = 1) = 1 and by assumption that r = |U+ ∪ U−| > max{r+, r−} = max{|U+|, |U−|}, then the set U+\U− is not an empty set.",A.3 Proof of Proposition 1,[0],[0]
"It is easy to show that for any vector v ∈ U+\U−, PX×Y (v>X = 0|Y = 1) = 0.",A.3 Proof of Proposition 1,[0],[0]
"Otherwise, if p = PX×Y (v>X = 0|Y = 1) > 0, then for random vectors X1, ...,X|U+| independently drawn from the conditional distribution PX|Y=1,
PX|Y=1 |U+|⋃ i=1",A.3 Proof of Proposition 1,[0],[0]
{ v>Xi = 0 } ∣∣∣∣∣Y,A.3 Proof of Proposition 1,[0],[0]
= 1  = |U+|∏ i=1,A.3 Proof of Proposition 1,[0],[0]
"PX|Y=1 ( v>Xi = 0|Y = 1 ) = p|U+| > 0.
",A.3 Proof of Proposition 1,[0],[0]
"Furthermore, since X1, ...,X|U+| ∈ Span(U+), v>Xi = 0, i = 1, ..., |U+| and v ∈ U+, then the rank of the matrix ( X1, ...,X|U+| ) is at most |U+| − 1 and this indicates that the matrix is not a full rank matrix with probability p|U+| > 0.",A.3 Proof of Proposition 1,[0],[0]
This leads to the contradiction with the Assumption 2.,A.3 Proof of Proposition 1,[0],[0]
"Thus, with probability 1, v>xi 6= 0 for all i : yi = 1 and v>xi = 0 for all i : yi = −1.",A.3 Proof of Proposition 1,[0],[0]
"Therefore, by setting u = v in Equation (8), we have
0 =",A.3 Proof of Proposition 1,[0],[0]
"− ∑ i:yi=1 `′p(−yif(xi;θ∗))σ′′(w∗1>xi)(v>xi)2 ≤ 0,
where the equality holds if and only if ∀i : yi = 1, `′p(−yif(xi;θ∗))",A.3 Proof of Proposition 1,[0],[0]
= 0,A.3 Proof of Proposition 1,[0],[0]
"and this further indicates that ∀i : yi = 1, yif(xi;θ∗) ≥ z0 > 0.",A.3 Proof of Proposition 1,[0],[0]
"Furthermore, since θ∗ is a critical point and thus
0 = dL̂n(θ
∗; p)
da0 =
1
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi) =,A.3 Proof of Proposition 1,[0],[0]
− 1 n ∑,A.3 Proof of Proposition 1,[0],[0]
i:yi=1 `′p(−yif(xi;θ∗)),A.3 Proof of Proposition 1,[0],[0]
+ 1 n ∑,A.3 Proof of Proposition 1,[0],[0]
"i:yi=−1 `′p(−yif(xi;θ∗))
",A.3 Proof of Proposition 1,[0],[0]
"= 1
n",A.3 Proof of Proposition 1,[0],[0]
∑,A.3 Proof of Proposition 1,[0],[0]
"i:yi=−1 `′p(−yif(xi;θ∗)).
",A.3 Proof of Proposition 1,[0],[0]
"Therefore, ∀i : yi = −1, yif(xi;θ∗)",A.3 Proof of Proposition 1,[0],[0]
≥ z0 > 0,A.3 Proof of Proposition 1,[0],[0]
"and this indicates that R̂n(θ∗) = 0.
(b) Proof of Claim 2: To prove the claim 2, we first prove that if M > r, then there exists coefficients α1, ..., αM , not all zero, such that
(α1w ∗ 1 + ...",A.3 Proof of Proposition 1,[0],[0]
+,A.3 Proof of Proposition 1,[0],[0]
αMw ∗ M ),A.3 Proof of Proposition 1,[0],[0]
> xi,A.3 Proof of Proposition 1,[0],[0]
"= 0, for all i ∈",A.3 Proof of Proposition 1,[0],[0]
"[n].
Since we assume that U+ ⊆ E and U− ⊆ E such that PX|Y (X ∈ Span(U+)|Y = 1) = 1 and PX|Y (X ∈ Span(U−)|Y = −1)",A.3 Proof of Proposition 1,[0],[0]
"= 1, then without loss generality, we assume that xis locate in the linear span of {e1, ..., er} ⊆ {e1, ..., ed} (note that r = |U+ ∪ U−|).",A.3 Proof of Proposition 1,[0],[0]
"Clearly, for any w∗1, ...,w∗M , if M > r, then there exists coefficients α1, ..., αM , not all zero, such that
α1w ∗ 1 + ...",A.3 Proof of Proposition 1,[0],[0]
+,A.3 Proof of Proposition 1,[0],[0]
"αMw ∗ M ∈ Span({er+1, ..., ed}), if r < d, α1w ∗ 1 + ...+ αMw ∗ M = 0d, if r = d.
Therefore, if M > r, then there exists coefficients α1, ..., αM , not all zero, such that
(α1w ∗ 1 + ...+ αMw ∗ M )",A.3 Proof of Proposition 1,[0],[0]
">xi = 0, for all i ∈",A.3 Proof of Proposition 1,[0],[0]
"[n].
Now we prove the claim 2.",A.3 Proof of Proposition 1,[0],[0]
"First, we consider the Hessian matrix H(w∗1, ...,w ∗ M ).",A.3 Proof of Proposition 1,[0],[0]
"Since θ ∗ is a local minima, then
F (u1, ...,uM )",A.3 Proof of Proposition 1,[0],[0]
= M∑ j=1 M∑ k=1,A.3 Proof of Proposition 1,[0],[0]
"u>j ∇2wj ,wk L̂n(θ ∗; p)uk ≥ 0
holds for any vectors u1, ...,uM ∈ Rd.",A.3 Proof of Proposition 1,[0],[0]
"Since σ′′(z) = 2 and σ′(z) = 2z for all z ∈ R, then
∇2wj L̂n(θ∗; p) = a∗j n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi)σ′′ ( w∗j >xi ) xix,A.3 Proof of Proposition 1,[0],[0]
>,A.3 Proof of Proposition 1,[0],[0]
"i
+ a∗j 2
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ∗)),A.3 Proof of Proposition 1,[0],[0]
[ σ′ ( w∗j >xi )]2 xix >,A.3 Proof of Proposition 1,[0],[0]
"i
= − 2a∗j n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))yixix>i + 4a∗j 2 n n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ∗)) ( w∗j >xi )2 xix >,A.3 Proof of Proposition 1,[0],[0]
"i ,
and
∇2wj ,wk L̂n(θ ∗; p) =
a∗ja ∗ k
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ∗)),A.3 Proof of Proposition 1,[0],[0]
[ σ′ ( w∗j >xi )],A.3 Proof of Proposition 1,[0],[0]
[ σ′ ( w∗k >xi )],A.3 Proof of Proposition 1,[0],[0]
xix >,A.3 Proof of Proposition 1,[0],[0]
"i
= 4a∗ja ∗ k
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ∗)) (,A.3 Proof of Proposition 1,[0],[0]
w∗j >xi )( w∗k >xi ) xix,A.3 Proof of Proposition 1,[0],[0]
"> i .
",A.3 Proof of Proposition 1,[0],[0]
"Thus, we have
F (u1, ...,uM )",A.3 Proof of Proposition 1,[0],[0]
= −2,A.3 Proof of Proposition 1,[0],[0]
M∑ j=1,A.3 Proof of Proposition 1,[0],[0]
[ a∗j n n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ∗))yi ( u>j xi )2]
+ 4 M∑ j=1 M∑ k=1
",A.3 Proof of Proposition 1,[0],[0]
"[ a∗ja ∗ k
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ∗)) (,A.3 Proof of Proposition 1,[0],[0]
w∗j >xi )( w∗k >xi ),A.3 Proof of Proposition 1,[0],[0]
"( u>j xi )( u>k xi
)]
= − 2 n M∑ j=1",A.3 Proof of Proposition 1,[0],[0]
[ a∗j n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ∗))yi ( u>j xi )2]
+ 4
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ∗))  ,A.3 Proof of Proposition 1,[0],[0]
M∑ j=1 a∗j ( w∗j >xi ),A.3 Proof of Proposition 1,[0],[0]
"( u>j xi )2 .
",A.3 Proof of Proposition 1,[0],[0]
"Since there exists coefficients α1, ..., αM , not all zero, such that (α1w ∗ 1 + ...+ αMw ∗ M )",A.3 Proof of Proposition 1,[0],[0]
">xi = 0, for all i ∈",A.3 Proof of Proposition 1,[0],[0]
"[n], and a∗j 6= 0",A.3 Proof of Proposition 1,[0],[0]
for all j ∈,A.3 Proof of Proposition 1,[0],[0]
[M ] then by setting uj = αju/a∗j for all j ∈,A.3 Proof of Proposition 1,[0],[0]
"[M ], we have that the inequality
F (u1, ...,uM ) =",A.3 Proof of Proposition 1,[0],[0]
"− 2
n M∑ j=1",A.3 Proof of Proposition 1,[0],[0]
[ a∗j n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))yi ( αj/a ∗ j )2,A.3 Proof of Proposition 1,[0],[0]
"( u>xi )2]
+ 4
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
"`′′p(−yif(xi;θ∗))  M∑ j=1 αj ( w∗j >xi )( u>xi )2 = − 2
n M∑ j=1",A.3 Proof of Proposition 1,[0],[0]
[ a∗j n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))yi ( αj/a ∗ j )2,A.3 Proof of Proposition 1,[0],[0]
"( u>xi )2]
+ 4
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ∗))   M∑ j=1 αjw ∗,A.3 Proof of Proposition 1,[0],[0]
"j > xi  2 ( u>xi )2 = − 2
n M∑ j=1 ( α2j/a ∗ j ) · n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ∗))yi ( u>xi )2 ≥ 0
holds for any u ∈ Rd.",A.3 Proof of Proposition 1,[0],[0]
"Next we consider the following two cases: (1) ∑M j=1 ( α2j/a ∗ j ) 6= 0; (2) ∑Mj=1 (α2j/a∗j) = 0.
",A.3 Proof of Proposition 1,[0],[0]
"Case 1: If ∑M
j=1 ( α2j/a ∗ j ) 6= 0, then without loss of generality, we assume that ∑Mj=1 (α2j/a∗j) < 0.
",A.3 Proof of Proposition 1,[0],[0]
This indicates that n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ∗))yi ( u>xi )2 ≥ 0, for all u ∈ Rd.
",A.3 Proof of Proposition 1,[0],[0]
"By the assumption that there exists two vectors er, es such that ∀i : yi = 1, e>r xi = 0, e>s xi 6= 0 hold with probability 1 and ∀i : yi = −1, e>s xi = 0, e>r xi 6= 0 hold with probability 1, then by setting u =",A.3 Proof of Proposition 1,[0],[0]
"er, we have that
0 ≤ n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))yi ( e>r xi )2 = − ∑ i:yi=−1 `′p(−yif(xi;θ∗)),A.3 Proof of Proposition 1,[0],[0]
"( e>r xi )2 ≤ 0,
where the equality holds if and only if `′p(−yif(xi;θ∗))",A.3 Proof of Proposition 1,[0],[0]
= 0 or yif(xi;θ∗),A.3 Proof of Proposition 1,[0],[0]
≥ z0 > 0 holds for all i : yi = −1.,A.3 Proof of Proposition 1,[0],[0]
"Furthermore, since θ∗ is a local minima and thus
0 = dL̂n(θ
∗; p)
da0 = n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))(−yi) =,A.3 Proof of Proposition 1,[0],[0]
− ∑ i:yi=1 `′p(−yif(xi;θ∗)),A.3 Proof of Proposition 1,[0],[0]
+ ∑,A.3 Proof of Proposition 1,[0],[0]
"i:yi=−1 `′p(−yif(xi;θ∗))
",A.3 Proof of Proposition 1,[0],[0]
=,A.3 Proof of Proposition 1,[0],[0]
"− ∑ i:yi=1 `′p(−yif(xi;θ∗)).
",A.3 Proof of Proposition 1,[0],[0]
This means when `′p(−yif(xi;θ∗)),A.3 Proof of Proposition 1,[0],[0]
"= 0 holds for all i : yi = −1, we have `′p(−yif(xi;θ∗))",A.3 Proof of Proposition 1,[0],[0]
= 0,A.3 Proof of Proposition 1,[0],[0]
for all i : yi = 1.,A.3 Proof of Proposition 1,[0],[0]
These two together give us R̂n(θ ∗) = 0.,A.3 Proof of Proposition 1,[0],[0]
"When ∑M
j=1 ( α2j/a ∗ j ) > 0, by setting u = es
and following the similar analysis presented above, we can obtain the same result.",A.3 Proof of Proposition 1,[0],[0]
"Therefore, when∑M j=1 ( α2j/a ∗ j ) 6= 0, we have R̂n(θ∗) = 0.
",A.3 Proof of Proposition 1,[0],[0]
"Case 2: If ∑M
j=1 ( α2j/a ∗ j ) = 0, then by setting uj = (αj/a ∗ j +vsgn(αj))u for some scalar v and vector
u ∈ Rd, we have
F (v,u) =",A.3 Proof of Proposition 1,[0],[0]
− 2 n M∑ j=1 [ a∗j n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))yi ( (αj/a ∗ j + vsgn(αj))u,A.3 Proof of Proposition 1,[0],[0]
">xi )2]
+ 4
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ∗))  ,A.3 Proof of Proposition 1,[0],[0]
M∑ j=1 a∗j ( w∗j >xi )( (αj/a ∗ j + vsgn(αj))u,A.3 Proof of Proposition 1,[0],[0]
">xi )2 = − 2
n M∑ j=1",A.3 Proof of Proposition 1,[0],[0]
[ a∗j n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))yi ( (αj/a ∗ j + vsgn(αj))u,A.3 Proof of Proposition 1,[0],[0]
">xi )2]
+ 4
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ∗))   M∑ j=1 (αj + vsgn(αj)a ∗ j )w ∗,A.3 Proof of Proposition 1,[0],[0]
j > xi (u>xi)2  =,A.3 Proof of Proposition 1,[0],[0]
"− 2
n M∑ j=1 [ a∗j n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))yi ( (αj/a ∗ j + vsgn(αj))u,A.3 Proof of Proposition 1,[0],[0]
">xi )2]
+ 4v2 n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ∗))   M∑,A.3 Proof of Proposition 1,[0],[0]
j=1 sgn(αj)a ∗ jw ∗,A.3 Proof of Proposition 1,[0],[0]
j > xi  2,A.3 Proof of Proposition 1,[0],[0]
"( u>xi )2 , − 2
n M∑ j=1",A.3 Proof of Proposition 1,[0],[0]
[ a∗j n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))yi ( (αj/a ∗ j + vsgn(αj))u,A.3 Proof of Proposition 1,[0],[0]
">xi )2] + v2R(u),
where we define
R(u) = 4
n n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′′p(−yif(xi;θ∗))   M∑,A.3 Proof of Proposition 1,[0],[0]
j=1 sgn(αj)a ∗ jw ∗,A.3 Proof of Proposition 1,[0],[0]
j > xi  2,A.3 Proof of Proposition 1,[0],[0]
( u>xi )2 .,A.3 Proof of Proposition 1,[0],[0]
"In addition, we have
M∑ j=1",A.3 Proof of Proposition 1,[0],[0]
[ a∗j n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ∗))yi ( (αj/a ∗ j + vsgn(αj))u,A.3 Proof of Proposition 1,[0],[0]
">xi )2]
= n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ))yi(u>xi)2 ·  M∑ j=1 (α2j/a ∗ j + 2vsgn(αj)αj + v 2a∗j )  ,A.3 Proof of Proposition 1,[0],[0]
"=
n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ))yi(u>xi)2 ·  M∑ j=1 (2vsgn(αj)αj + v 2a∗j )  ,A.3 Proof of Proposition 1,[0],[0]
"= 2v
 M∑ j=1 |αj |  n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ))yi(u>xi)2 + v2  M∑ j=1 a∗j  n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ))yi(u>xi)2.
",A.3 Proof of Proposition 1,[0],[0]
"Therefore, we can rewrite F (v,u) as
F (v,u) = −4v n M∑ j=1 |αj",A.3 Proof of Proposition 1,[0],[0]
| n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ))yi(u>xi)2 − 2v2 n M∑ j=1 a∗j · n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ))yi(u>xi)2 + v2R(u)
, −4v n M∑ j=1 |αj | n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ))yi(u>xi)2 + v2R̂(u)
Since F (v,u) ≥ 0 holds for any scalar v and vector u ∈ Rd, then we should have
M∑ j=1 |αj",A.3 Proof of Proposition 1,[0],[0]
| n∑ i=1,A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ))yi(u>xi)2 = 0, for any u ∈ Rd.
",A.3 Proof of Proposition 1,[0],[0]
"Since the coefficient α1, ..., αM are not all zero, then for any u ∈ Rd, we have n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
"`′p(−yif(xi;θ))yi(u>xi)2 = 0.
",A.3 Proof of Proposition 1,[0],[0]
"Since there exists two vectors er, es: ∀i : yi = 1, e>r xi = 0 and e>s xi 6= 0 hold with probability 1 and ∀i : yi = −1, e>s xi = 0 and e>r xi 6= 0 hold with probability 1, then by setting u =",A.3 Proof of Proposition 1,[0],[0]
"er, we have
0 = n∑ i=1",A.3 Proof of Proposition 1,[0],[0]
`′p(−yif(xi;θ))yi(e>r xi)2 =,A.3 Proof of Proposition 1,[0],[0]
"− ∑ i:yi=−1 `′p(−yif(xi;θ))(e>r xi)2 ≤ 0,
where the equality holds if and only if `′p(−yif(xi;θ∗))",A.3 Proof of Proposition 1,[0],[0]
= 0 or yif(xi;θ∗),A.3 Proof of Proposition 1,[0],[0]
≥ z0 > 0 holds for all i : yi = −1.,A.3 Proof of Proposition 1,[0],[0]
"Similar to the case 1, we have that `′p(−yif(xi;θ∗))",A.3 Proof of Proposition 1,[0],[0]
= 0 holds for all i and this leads to R̂n(θ ∗) = 0.,A.3 Proof of Proposition 1,[0],[0]
Theorem 4 Assume that the loss function `p satisfies assumption 1 and the network architecture satisfies assumption 4.,A.4 Proof of Theorem 2,[0],[0]
Assume,A.4 Proof of Theorem 2,[0],[0]
"that samples in the dataset D = {(xi, yi)}ni=1, n",A.4 Proof of Theorem 2,[0],[0]
≥ 1 are independently drawn from a distribution satisfying assumption 6.,A.4 Proof of Theorem 2,[0],[0]
"Assume that the single layer network fS has M ≥ 1 neurons and neurons σ in the network fS are twice differentiable and satisfy σ
′(z)",A.4 Proof of Theorem 2,[0],[0]
> 0,A.4 Proof of Theorem 2,[0],[0]
for all z ∈ R.,A.4 Proof of Theorem 2,[0],[0]
"If a set of real parameters θ∗ = (θ∗S ,θ ∗ D) denotes a local minimum of the loss function L̂n(θS ,θD; p), p ≥ 3, then R̂n(θ∗S ,θ∗D) = 0 holds with probability one.
",A.4 Proof of Theorem 2,[0],[0]
Proof: We first recall some notations defined in the paper.,A.4 Proof of Theorem 2,[0],[0]
"The output of the neural network is
f(x;θ) = fS(x;θS) + fD(x;θD),
where fS(x;θS) is the single layer neural network parameterized by θS , i.e.,
fS(x;θS)",A.4 Proof of Theorem 2,[0],[0]
"= a0 + M∑ j=1 ajσ ( w>j x ) ,
and fD(x;θD) is a deep neural network parameterized by θD.",A.4 Proof of Theorem 2,[0],[0]
"The empirical loss function is given by
L̂n(θ; p) = L̂n(θS ,θD; p)",A.4 Proof of Theorem 2,[0],[0]
"= 1
n n∑ i=1",A.4 Proof of Theorem 2,[0],[0]
"`p(−yif(xi;θ)).
",A.4 Proof of Theorem 2,[0],[0]
"By the assumption that θ∗ = (θ∗S ,θ ∗ D) is a local minima and by the necessary condition presented in Lemma 1, we have
n∑ i=1",A.4 Proof of Theorem 2,[0],[0]
"`′p(−yif(xi;θ∗))yiσ′(w∗j>xi)xi = 0d.
",A.4 Proof of Theorem 2,[0],[0]
Thus,A.4 Proof of Theorem 2,[0],[0]
", for any w ∈ Rd and any j ∈",A.4 Proof of Theorem 2,[0],[0]
"[M ], we have n∑ i=1",A.4 Proof of Theorem 2,[0],[0]
"`′p(−yif(xi;θ∗))σ′(w∗j>xi)yi(w>xi) = 0.
",A.4 Proof of Theorem 2,[0],[0]
"Furthermore, by assumption `′p(z) ≥ 0 and the equality holds if and only if z ≤ −z0.",A.4 Proof of Theorem 2,[0],[0]
"Thus, by assumption that σ′(z) > 0",A.4 Proof of Theorem 2,[0],[0]
"for all z ∈ R and assumption that there exists a vector PX×Y (Yw>X > 0) = 1, then there exists and positive constant c > 0",A.4 Proof of Theorem 2,[0],[0]
"such that
yi(w >xi)",A.4 Proof of Theorem 2,[0],[0]
> c,A.4 Proof of Theorem 2,[0],[0]
"> 0, ∀i ∈",A.4 Proof of Theorem 2,[0],[0]
"[n].
Thus, we have
0 = n∑ i=1",A.4 Proof of Theorem 2,[0],[0]
`′p(−yif(xi;θ∗))σ′(w∗j>xi)yi(w>xi) ≥ c n∑ i=1,A.4 Proof of Theorem 2,[0],[0]
"`′p(−yif(xi;θ∗))σ′(w∗j>xi) ≥ 0,
where the equality holds if and only if `′p(−yif(xi;θ∗))",A.4 Proof of Theorem 2,[0],[0]
= 0,A.4 Proof of Theorem 2,[0],[0]
for all i ∈,A.4 Proof of Theorem 2,[0],[0]
[n].,A.4 Proof of Theorem 2,[0],[0]
"Equivalently, if θ∗ is a local minima, then yif(xi;θ ∗)",A.4 Proof of Theorem 2,[0],[0]
≥ z0 > 0,A.4 Proof of Theorem 2,[0],[0]
for all i ∈,A.4 Proof of Theorem 2,[0],[0]
[n].,A.4 Proof of Theorem 2,[0],[0]
This indicates that Ln(θ∗; p) = R̂n(θ∗) = 0.,A.4 Proof of Theorem 2,[0],[0]
Proposition 14 Assume that assumption 1 and 4 are satisfed.,B.1 Proof of Proposition 2,[0],[0]
Assume that neurons in the network fS satisfy that σ(z) = 0 for all z ≤ 0 and σ(z) is piece-wise continuous on R.,B.1 Proof of Proposition 2,[0],[0]
"Then there exists a feedforward network fD and a distribution satisfying assumptions in Theorem 1 or 2 such that with probability one, the empirical loss L̂n(θ; p), p ≥ 2 has a local minima θ∗ = (θ∗S ,θ∗D) satisfying R̂n(θ ∗)",B.1 Proof of Proposition 2,[0],[0]
"≥ min{n+,n−}n , where n+",B.1 Proof of Proposition 2,[0],[0]
"and n− are the number of positive and negative samples, respectively.
",B.1 Proof of Proposition 2,[0],[0]
Proof: We choose the network architecture fD(x;θD) ≡ 0 for all x ∈ Rd.,B.1 Proof of Proposition 2,[0],[0]
"Then the output of the network is
f(x;θ) = fS(x;θS)",B.1 Proof of Proposition 2,[0],[0]
"= a0 + M∑ j=1 ajσ ( w>j xi ) .
",B.1 Proof of Proposition 2,[0],[0]
"Now we prove the following claim showing that if the dataset contains both positive and negative samples, then the empirical loss has a local minimum with a non-zero training error.
",B.1 Proof of Proposition 2,[0],[0]
Claim 1,B.1 Proof of Proposition 2,[0],[0]
"Under the conditions in proposition 2, if the dataset contains both positive and negative samples and samples in the dataset are drawn in the space Rd−1×{1}×{1,−1}, the empirical loss has a local minimum with a non-zero training error.",B.1 Proof of Proposition 2,[0],[0]
"Furthermore, the training error is no smaller than min{n+,n−}
n .
",B.1 Proof of Proposition 2,[0],[0]
Proof: We construct the local minimum as follows.,B.1 Proof of Proposition 2,[0],[0]
Now we construct a local minimum θ∗ = (θ∗S).,B.1 Proof of Proposition 2,[0],[0]
"The key idea of constructing the local minimum having a training error no smaller than min{n+,n−}n is appropriately choosing wj such that all neurons in the last layer keep inactive on all samples in the dataset.",B.1 Proof of Proposition 2,[0],[0]
This is possible since the number of samples is bounded.,B.1 Proof of Proposition 2,[0],[0]
"Next, for any data set D = {(xi; yi)}ni=1, we define
K = max i∈[n] ‖xi‖2.
",B.1 Proof of Proposition 2,[0],[0]
"Since all samples in the dataset xi ∈ Rd−1 × {1}, then by choosing w∗j = ( w (1) j ∗ , ..., w (d−1) j ∗ , w (d) j ∗) such that
d−1∑",B.1 Proof of Proposition 2,[0],[0]
"k=1 ( w (1) j ∗)2 = 1,
and w (d) j
∗ = −K − 1.",B.1 Proof of Proposition 2,[0],[0]
"Since for all samples in the dataset
w>j xi = d−1∑",B.1 Proof of Proposition 2,[0],[0]
k=1,B.1 Proof of Proposition 2,[0],[0]
w,B.1 Proof of Proposition 2,[0],[0]
(k) j ∗ x (k) i + w (d) j ∗ ≤ K −K,B.1 Proof of Proposition 2,[0],[0]
"− 1 = −1,
then σ(w>j xi) = 0, ∀i ∈",B.1 Proof of Proposition 2,[0],[0]
"[n].
Therefore, the neural network becomes
f(xi;θ ∗)",B.1 Proof of Proposition 2,[0],[0]
"= a∗0, ∀i ∈",B.1 Proof of Proposition 2,[0],[0]
"[n].
Finally, we set a∗0 to the global minimizer of the following convex optimization problem:
min a∈R
1
n n∑ i=1",B.1 Proof of Proposition 2,[0],[0]
"`(−yia).
",B.1 Proof of Proposition 2,[0],[0]
"This indicates that for any a ∈ R,
1
n n∑ i=1",B.1 Proof of Proposition 2,[0],[0]
`(−yia) ≥ 1 n n∑ i=1,B.1 Proof of Proposition 2,[0],[0]
"`(−yia∗0).
",B.1 Proof of Proposition 2,[0],[0]
Now we show that θ∗ is local minimum of the empirical loss function.,B.1 Proof of Proposition 2,[0],[0]
"Now we slightly perturb the parameters a0, ..., aM ,w1, ...,wM by ∆a0, ...,∆aM ,∆w1, ...,∆wM .",B.1 Proof of Proposition 2,[0],[0]
"Define
θ̃ = (a∗0 + ∆a0, ..., a ∗ M + ∆aM ,w ∗ 1 + ∆w1, ...,w ∗ M + ∆wM ).
",B.1 Proof of Proposition 2,[0],[0]
Then,B.1 Proof of Proposition 2,[0],[0]
", if ‖θ − θ̃‖2 ≤ ε and ε is positive and sufficiently small, then for ∀j ∈",B.1 Proof of Proposition 2,[0],[0]
[M ] and ∀ ∈,B.1 Proof of Proposition 2,[0],[0]
"[n], we have
w∗jxi + ∆w",B.1 Proof of Proposition 2,[0],[0]
> j xi ≤ −1,B.1 Proof of Proposition 2,[0],[0]
+ ‖∆wj‖2,B.1 Proof of Proposition 2,[0],[0]
‖xi‖2 ≤ −1,B.1 Proof of Proposition 2,[0],[0]
"+Kε < 0.
",B.1 Proof of Proposition 2,[0],[0]
"This means that if ε is positive and sufficiently small, then
f(xi; θ̃) = a ∗ 0 + ∆a0.
",B.1 Proof of Proposition 2,[0],[0]
"In addition, for all ∆a0 ∈ R,
1
n n∑ i=1",B.1 Proof of Proposition 2,[0],[0]
`(−yia∗ + ∆a0) ≥ 1 n n∑ i=1,B.1 Proof of Proposition 2,[0],[0]
"`(−yia∗0),
therefore for θ̃ : ‖θ̃ − θ∗‖2 ≤ δ(ε) and any a0 ∈ R
L̂n(θ̃) = 1
n n∑ i=1",B.1 Proof of Proposition 2,[0],[0]
`(−yif(xi; θ̃)),B.1 Proof of Proposition 2,[0],[0]
= 1 n n∑ i=1,B.1 Proof of Proposition 2,[0],[0]
"`(−yi(a∗0 + ∆a0))
",B.1 Proof of Proposition 2,[0],[0]
≥ 1 n n∑ i=1,B.1 Proof of Proposition 2,[0],[0]
`(−yia∗0) ≥ 1 n n∑ i=1,B.1 Proof of Proposition 2,[0],[0]
"`(−yif(xi;θ∗)) = L̂n(θ∗).
",B.1 Proof of Proposition 2,[0],[0]
This means that θ∗ is a local minimum of the empirical loss and f(xi;θ ∗),B.1 Proof of Proposition 2,[0],[0]
= a∗0 for all i ∈,B.1 Proof of Proposition 2,[0],[0]
[n].,B.1 Proof of Proposition 2,[0],[0]
"This further indicates that
R̂n(θ ∗) ≥ min{n−, n+}
n .
",B.1 Proof of Proposition 2,[0],[0]
"Now we only need to construct the data distribution satisfying assumptions in Theorem 1 and Theorem 2, respectively, such that with probability at least 1 − e−Ω(n), the dataset drawn from this distribution satisfies the assumption in claim 1.
",B.1 Proof of Proposition 2,[0],[0]
Distribution for Theorem 1:,B.1 Proof of Proposition 2,[0],[0]
"Now we define a distribution as follows, PX|Y=1 is a uniform distribution on the region [−2,−1] ∪ [1, 2] × {0} × {1} × {0}d−3 and PX|Y=−1 is a uniform distribution on the region {0} ×",B.1 Proof of Proposition 2,[0],[0]
"[−2,−1] ∪ [1, 2] × {1} × {0}d−3.",B.1 Proof of Proposition 2,[0],[0]
"In addition, P(Y = 1) = P(Y = −1) = 0.5.",B.1 Proof of Proposition 2,[0],[0]
"It is easy to check that r = 3 > max{r+, r−} = 2 and for any two samples independently drawn from the distribution PX|Y=1 or PX|Y=−1, these two samples are linearly independent.",B.1 Proof of Proposition 2,[0],[0]
This means that this data distribution satisfies the conditions in Theorem 1.,B.1 Proof of Proposition 2,[0],[0]
"In addition, if samples in the dataset are independently drawn from this distribution, then with probability 1− 1
2n−1 , the dataset contains both positive and negative samples.
",B.1 Proof of Proposition 2,[0],[0]
Distribution for Theorem 2:,B.1 Proof of Proposition 2,[0],[0]
"Now we define a distribution as follows, PX|Y=1 is a uniform distribution on the region [−2,−1] × {0} × {1} × {0}d−3 and PX|Y=−1 is a uniform distribution on the region {0}× [−2,−1]×{1}×{0}d−3.",B.1 Proof of Proposition 2,[0],[0]
It is easy to check that This means that this distribution satisfies the conditions in Theorem 2.,B.1 Proof of Proposition 2,[0],[0]
"In addition, if samples in the dataset are independently drawn from this distribution, then with probability 1− 1
2n−1 , the dataset contains both positive and negative samples.",B.1 Proof of Proposition 2,[0],[0]
Proposition 15 Assume that assumption 1 and 4 are satisfed.,B.2 Proof of Proposition 3,[0],[0]
Assume that neurons in the network fS satisfy that σ(z) =,B.2 Proof of Proposition 3,[0],[0]
"z for all z ≥ 0 and σ(z) is piece-wise continuous on R. Then there exists a network architecture fD and a distribution satisfying assumptions in Theorem 1 such that, with probability at least 1− e−Ω(n), the empirical loss L̂n(θ; p), p ≥ 2 has a local minima θ∗ = (θ∗S ,θ∗D) with non-zero training error.
",B.2 Proof of Proposition 3,[0],[0]
Proof: We choose the network architecture fD(x;θD) ≡ 0 for all x ∈ Rd.,B.2 Proof of Proposition 3,[0],[0]
"Then the output of the network is
f(x;θ) = fS(x;θS)",B.2 Proof of Proposition 3,[0],[0]
"= a0 + M∑ j=1 ajσ ( w>j xi ) .
",B.2 Proof of Proposition 3,[0],[0]
"Now we prove the following claim showing that if the dataset contains both positive and negative samples, then the empirical loss has a local minimum with a non-zero training error.
",B.2 Proof of Proposition 3,[0],[0]
Claim 2,B.2 Proof of Proposition 3,[0],[0]
"Under the conditions in proposition 2, if the samples in the dataset are not linearly separable and samples (xi, yi) are drawn in the space Rd−1×{1}×{1,−1}, the empirical loss has a local minimum with a non-zero training error.
",B.2 Proof of Proposition 3,[0],[0]
Proof: We construct the local minimum as follows.,B.2 Proof of Proposition 3,[0],[0]
Now we construct a local minimum θ∗ = (θ∗S).,B.2 Proof of Proposition 3,[0],[0]
"The key idea of constructing the local minimum having a training error no smaller than min{n+,n−}n is appropriately choosing wj such that all neurons in the last layer keep inactive on all samples in the dataset.",B.2 Proof of Proposition 3,[0],[0]
This is possible since the number of samples is bounded.,B.2 Proof of Proposition 3,[0],[0]
"First, let w∗ be a global minimizer of the following convex optimization problem:
min w∈Rd n∑ i=1",B.2 Proof of Proposition 3,[0],[0]
`p(−yi(w>xi)).,B.2 Proof of Proposition 3,[0],[0]
"(9)
Next, for any data set D = {(xi; yi)}ni=1, we define
K = max i∈[n]",B.2 Proof of Proposition 3,[0],[0]
"|w∗>xi| and K1 = max i∈[n] ‖xi‖2.
",B.2 Proof of Proposition 3,[0],[0]
"Since all samples in the dataset xi ∈ Rd−1 × {1}, then by choosing w∗j = ( w (1) j ∗ , ..., w (d−1) j ∗ , w (d) j ∗) such that
w (1) j
∗ = w(1) ∗ , ..., w
(d−1) j
∗ = w(d−1) ∗ , w
(d) j
∗ = w(d) ∗ +K + 1.
",B.2 Proof of Proposition 3,[0],[0]
"Since for all samples in the dataset
w∗j >xi = w ∗>xi +K + 1 ≥ −K +K + 1 = 1, then
σ(w>j xi) = w >xi, ∀i ∈",B.2 Proof of Proposition 3,[0],[0]
"[n].
In addition, let a∗j = 1 M and a ∗ 0 = 0.",B.2 Proof of Proposition 3,[0],[0]
"Therefore, the neural network becomes
f(xi;θ ∗)",B.2 Proof of Proposition 3,[0],[0]
=,B.2 Proof of Proposition 3,[0],[0]
"w>xi, ∀i ∈",B.2 Proof of Proposition 3,[0],[0]
"[n].
Since w∗ is the global optimizer of the convex optimization problem defined in Equation (9), this indicates that for any w ∈ Rd,
1
n n∑ i=1",B.2 Proof of Proposition 3,[0],[0]
`p(−yi(w>xi)),B.2 Proof of Proposition 3,[0],[0]
≥ 1 n n∑ i=1,B.2 Proof of Proposition 3,[0],[0]
"`p(−yi(w∗>xi)).
",B.2 Proof of Proposition 3,[0],[0]
Now we show that θ∗ is local minimum of the empirical loss function.,B.2 Proof of Proposition 3,[0],[0]
"Now we slightly perturb the parameters a0, ..., aM ,w1, ...,wM by ∆a0, ...,∆aM ,∆w1, ...,∆wM .",B.2 Proof of Proposition 3,[0],[0]
"Define
θ̃ = (a∗0 + ∆a0, ..., a ∗ M + ∆aM ,w ∗ 1 + ∆w1, ...,w ∗ M + ∆wM ).
",B.2 Proof of Proposition 3,[0],[0]
Then,B.2 Proof of Proposition 3,[0],[0]
", if ‖θ − θ̃‖2 ≤ ε and ε is positive and sufficiently small, then for ∀j ∈",B.2 Proof of Proposition 3,[0],[0]
[M ] and ∀ ∈,B.2 Proof of Proposition 3,[0],[0]
"[n], we have
w∗jxi + ∆w",B.2 Proof of Proposition 3,[0],[0]
> j xi ≥ 1− ‖∆wj‖2,B.2 Proof of Proposition 3,[0],[0]
‖xi‖2,B.2 Proof of Proposition 3,[0],[0]
"≥ 1−K1ε > 0.
",B.2 Proof of Proposition 3,[0],[0]
"This means that if ε is positive and sufficiently small, then
f(xi; θ̃) = ∆a0 + M∑ j=1 (a∗j + ∆aj)",B.2 Proof of Proposition 3,[0],[0]
"( w>xi + ∆w > j xi ) .
",B.2 Proof of Proposition 3,[0],[0]
This means that f(x; θ̃) behave as a linear model on the dataset.,B.2 Proof of Proposition 3,[0],[0]
"Since w∗ corresponds to the optimal linear model minimizing the empirical loss, then
L̂n(θ̃) = 1
n n∑ i=1",B.2 Proof of Proposition 3,[0],[0]
"`p(−yif(xi; θ̃))
",B.2 Proof of Proposition 3,[0],[0]
≥ 1 n n∑ i=1,B.2 Proof of Proposition 3,[0],[0]
`p(−yi(w>xi)),B.2 Proof of Proposition 3,[0],[0]
≥ 1 n n∑ i=1,B.2 Proof of Proposition 3,[0],[0]
`p(−yif(xi;θ∗)),B.2 Proof of Proposition 3,[0],[0]
"= L̂n(θ∗).
",B.2 Proof of Proposition 3,[0],[0]
This means that θ∗ is a local minimum of the empirical loss and f(xi;θ ∗),B.2 Proof of Proposition 3,[0],[0]
= a∗0 for all i ∈,B.2 Proof of Proposition 3,[0],[0]
[n].,B.2 Proof of Proposition 3,[0],[0]
"This further indicates that
R̂n(θ ∗) ≥ min{n−, n+}
n .
",B.2 Proof of Proposition 3,[0],[0]
"Now we only need to construct the data distribution satisfying assumptions in Theorem 1 such that with probability at least 1− e−Ω(n), the dataset drawn from this distribution satisfies the assumption in claim 2.
",B.2 Proof of Proposition 3,[0],[0]
Distribution for Theorem 1:,B.2 Proof of Proposition 3,[0],[0]
"Now we define a distribution as follows, PX|Y=1 is a uniform distribution on the region [−2,−1] ∪ [1, 2] × {0} × {1} × {0}d−3 and PX|Y=−1 is a uniform distribution on the region {0} ×",B.2 Proof of Proposition 3,[0],[0]
"[−2,−1] ∪ [1, 2] × {1} × {0}d−3.",B.2 Proof of Proposition 3,[0],[0]
"In addition, P(Y = 1) = P(Y = −1) = 0.5.",B.2 Proof of Proposition 3,[0],[0]
"It is easy to check that r = 3 > max{r+, r−} = 2 and for any two samples independently drawn from the distribution PX|Y=1 or PX|Y=−1, these two samples are linearly independent.",B.2 Proof of Proposition 3,[0],[0]
This means that this data distribution satisfies the conditions in Theorem 1.,B.2 Proof of Proposition 3,[0],[0]
"In addition, if samples in the dataset are independently drawn from this distribution, then with probability 1 − e−Ω(n), the dataset contains samples in each of the following four regions: [−2,−1]×{0}×{1}×{0}d−3, [1, 2]×{0}×{1}×{0}d−3, {0}× [1, 2]×{1}× {0}d−3 and {0}× [−2,−1]×{1}× {0}d−3, which makes the samples in the dataset not linearly separable.",B.2 Proof of Proposition 3,[0],[0]
Proposition 16 Assume that assumption 1 and 4 are satisfed.,B.3 Proof of Proposition 4,[0],[0]
Assume that there exists a constant c ∈ R such that neurons in the network fS satisfy σ(z) + σ(−z) ≡,B.3 Proof of Proposition 4,[0],[0]
c for all z ∈ R. Assume that the dataset D has 2n samples.,B.3 Proof of Proposition 4,[0],[0]
"Then there exists a network architecture fD and a distribution satisfying assumptions in Theorem 1 such that, with probability at least Ω(1/n2), the empirical loss function L̂2n(θ; p) has a local minimum θ ∗ = (θ∗S ,θ ∗ D) satisfying R̂2n(θ
∗) ≥ min{n−,n+}2n , where n+ and n− denote the number of positive and negative samples in the dataset, respectively.
",B.3 Proof of Proposition 4,[0],[0]
"Proof: We first prove the following claim showing that when the dataset satisfies certain conditions, there exists a local minimum satisfying R̂2n(θ
∗) ≥ min{n−,n+}2n .",B.3 Proof of Proposition 4,[0],[0]
"Next, we construct a data distribution such that the dataset drawn from the distribution satisfies these conditions with probability Ω(1/n2).
",B.3 Proof of Proposition 4,[0],[0]
Claim 3,B.3 Proof of Proposition 4,[0],[0]
"Assume that for each sample (xi, yi) in the dataset D = {(xi, yi)}2ni=1, there exists a sample (xj , yj) ∈ D such that ‖xi + xj‖2 = 0 and yi = yj.",B.3 Proof of Proposition 4,[0],[0]
If the function σ(z),B.3 Proof of Proposition 4,[0],[0]
"+σ(−z) ≡ constant on R, then the empirical loss function L̂2n(θ) has a local minimum θ ∗ satisfying",B.3 Proof of Proposition 4,[0],[0]
"R̂2n(θ ∗) ≥ min{n−,n+}2n .
",B.3 Proof of Proposition 4,[0],[0]
"Proof: Consider a single layer neural network
f(x;θ) = a0 + M∑ j=1",B.3 Proof of Proposition 4,[0],[0]
"ajσ(w > j x).
",B.3 Proof of Proposition 4,[0],[0]
Now we construct a local minimum θ∗. Let a∗1 = ...,B.3 Proof of Proposition 4,[0],[0]
"= a ∗ M = −1, and w∗1 = ...",B.3 Proof of Proposition 4,[0],[0]
= w∗M = 0d.,B.3 Proof of Proposition 4,[0],[0]
Thus f(x;θ∗) = a∗0 −Mσ(0).,B.3 Proof of Proposition 4,[0],[0]
"Let a∗0 be the global optimizer of the following convex optimization problem.
",B.3 Proof of Proposition 4,[0],[0]
min a 2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
"`p(−yi(a−Mσ(0))).
",B.3 Proof of Proposition 4,[0],[0]
"Thus, we have 2n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi) = 0, (10) and this indicates that∑ i:yi=1",B.3 Proof of Proposition 4,[0],[0]
`′p(−(a∗0 −Mσ(0))),B.3 Proof of Proposition 4,[0],[0]
= ∑,B.3 Proof of Proposition 4,[0],[0]
i:yi=−1 `′p(a ∗ 0 −Mσ(0)) or `′p(−a∗0 +Mσ(0))n+ =,B.3 Proof of Proposition 4,[0],[0]
`′p(a∗0 −Mσ(0))n−. (11),B.3 Proof of Proposition 4,[0],[0]
"In addition, we have, for ∀j ∈",B.3 Proof of Proposition 4,[0],[0]
"[M ],
∂L̂2n(θ ∗)
",B.3 Proof of Proposition 4,[0],[0]
aj = 2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)σ(0) = 0, by Equation (10)
∇wj L̂2n(θ∗) =",B.3 Proof of Proposition 4,[0],[0]
2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)σ′(0)xi,
= σ′(0) 2n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)xi.
",B.3 Proof of Proposition 4,[0],[0]
"By assumption that for each sample (xi, yi) in the dataset, there exists a sample (xj , yj) in the dataset such that xi + xj = 0d",B.3 Proof of Proposition 4,[0],[0]
"and yi = yj , i.e., yixi + yjxj = 0d, thus we have for any j ∈",B.3 Proof of Proposition 4,[0],[0]
"[M ],
∇wj L̂2n(θ∗) = σ′(0)",B.3 Proof of Proposition 4,[0],[0]
2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))(−yi)xi = 0d.,B.3 Proof of Proposition 4,[0],[0]
"(12)
Furthermore, we have
∂L̂2n(θ ∗)
a0 = 2n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi) = 0,
then θ∗ is a critical point.",B.3 Proof of Proposition 4,[0],[0]
Now we only need to show that it is a local minimum.,B.3 Proof of Proposition 4,[0],[0]
We prove it by definition.,B.3 Proof of Proposition 4,[0],[0]
"Consider any perturbation ∆a1, ...,∆aM : |∆aj | < 12 for all j ∈",B.3 Proof of Proposition 4,[0],[0]
"[M ], ∆w1, ...,∆wM ∈ Rd and ∆a0",B.3 Proof of Proposition 4,[0],[0]
"∈ R. Define
θ̃ = (a∗0 + ∆a0, ..., a ∗ M + ∆aM ,w ∗ 1 + ∆w1, ...,w ∗ M + ∆wM ).
",B.3 Proof of Proposition 4,[0],[0]
"Then
2n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
`p(−yif(xi; θ̃))−,B.3 Proof of Proposition 4,[0],[0]
2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
`p(−yif(xi;θ∗)),B.3 Proof of Proposition 4,[0],[0]
= 2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
[ `p(−yif(xi; θ̃))− `p(−yif(xi;θ∗)) ],B.3 Proof of Proposition 4,[0],[0]
"≥
",B.3 Proof of Proposition 4,[0],[0]
2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)[f(xi; θ̃)− f(xi;θ∗)]
= 2n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)[f(xi; θ̃)− a∗0 +Mσ(0)]
",B.3 Proof of Proposition 4,[0],[0]
= 2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃),
where the inequality follows from the convexity of `p, the second equality follows from the fact that f(x;θ∗) ≡",B.3 Proof of Proposition 4,[0],[0]
a∗0 −Mσ(0) and the third equality follows from Equation (10).,B.3 Proof of Proposition 4,[0],[0]
"In addition, we have
2n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃) = 2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)  M∑ j=1 (a∗j + ∆aj)σ ( ∆w>j xi ) + ∆a0
 =
2n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))(−yi)  M∑ j=1 (a∗j + ∆aj)σ ( ∆w>j xi ) by Eq.,B.3 Proof of Proposition 4,[0],[0]
"(10) =
M∑ j=1 −(a∗j + ∆aj)",B.3 Proof of Proposition 4,[0],[0]
[ 2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w>j xi )] .
",B.3 Proof of Proposition 4,[0],[0]
"Now we consider the following term
2n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w>j xi ) .
",B.3 Proof of Proposition 4,[0],[0]
"By assumption that for each sample (xi, yi) in the dataset, there exists a sample (xk, yk) in the dataset such that xi + xk = 0d, yi = yk by the assumption that there exists a constant c0 such that σ(z) + σ(−z) ≡ c0, thus we have for any ∆wj ∈",B.3 Proof of Proposition 4,[0],[0]
"Rd,
yiσ ( ∆w>j xi ) + ykσ",B.3 Proof of Proposition 4,[0],[0]
"( ∆w>j xk ) = yiσ ( ∆w>j xi ) + yiσ ( −∆w>j xi ) = yic0 =
c0 2 (yi + yk),
where the last equality follows from yi = yk.",B.3 Proof of Proposition 4,[0],[0]
"Therefore, we have for all ∆wj ∈ Rd, 2n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
`p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w>j xi ) = c0 2 2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
"`p(−yi(a∗0 −Mσ(0)))yi = 0.
Thus, we have 2n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃) = M∑ j=1 −(a∗j + ∆aj),B.3 Proof of Proposition 4,[0],[0]
[ 2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
`p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w>j xi )],B.3 Proof of Proposition 4,[0],[0]
"= 0,
and this further indicates
2n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
`p(−yif(xi; θ̃))−,B.3 Proof of Proposition 4,[0],[0]
2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
`p(−yif(xi;θ∗)),B.3 Proof of Proposition 4,[0],[0]
≥ 2n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃) = 0.
",B.3 Proof of Proposition 4,[0],[0]
"Therefore, this means that θ∗ is a local minimum.",B.3 Proof of Proposition 4,[0],[0]
"Since f(x;θ∗) = a∗0 −Mσ(0), then clearly,
R̂2n(θ ∗)",B.3 Proof of Proposition 4,[0],[0]
"≥ min{n+, n−}
n .
",B.3 Proof of Proposition 4,[0],[0]
"Now we construct the data distribution PX×Y as follows
P(X = (1, 0), Y = 1) = P(X = (−1, 0), Y = 1) = P(X = (0, 1), Y = −1) = P(X = (0,−1), Y = −1).
",B.3 Proof of Proposition 4,[0],[0]
"Assume that samples in the dataset D = {(xi, yi)}2ni=1 are independently draw from the data distribution PX×Y .",B.3 Proof of Proposition 4,[0],[0]
"Let n(1,0) and n(−1,0) denote the number of samples at the point (1, 0) and (−1, 0), respectively.",B.3 Proof of Proposition 4,[0],[0]
"Let n(0,1) and n(0,−1) denote the number of samples at the point (0, 1) and (0,−1), respectively.",B.3 Proof of Proposition 4,[0],[0]
"Then the probability that n(1,0) = n(−1,0) and n(0,1) = n(0,−1) is
PX×Y",B.3 Proof of Proposition 4,[0],[0]
"[ n(1,0) = n(−1,0) and n(0,1) = n(0,−1) ]",B.3 Proof of Proposition 4,[0],[0]
= n∑ i=1,B.3 Proof of Proposition 4,[0],[0]
( 2n 2i )( 2i i )( 2(n− i),B.3 Proof of Proposition 4,[0],[0]
n−,B.3 Proof of Proposition 4,[0],[0]
"i )( 1 4 )2n =
n∑ i=1
(2n)!",B.3 Proof of Proposition 4,[0],[0]
(2i)!(2n− 2i)!,B.3 Proof of Proposition 4,[0],[0]
(2i)!,B.3 Proof of Proposition 4,[0],[0]
[i!]2 (2n− 2i)!,B.3 Proof of Proposition 4,[0],[0]
"[(n− i)!]2
( 1
16
)n = n∑ i=1
(2n)!",B.3 Proof of Proposition 4,[0],[0]
"[i!(n− i)!]2 1 16n
= (2n)!
16n(n!)2 n∑ i=1
(n!)2
[i!(n− i)!]2 =
(2n)!
16n(n!)2 n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
"( n i )2 = 1
16n
( 2n
n
)2 >
1
(n+ 1)2
by the equality n∑ i=1",B.3 Proof of Proposition 4,[0],[0]
"( n i )2 = ( 2n n ) and the inequality (
2n
n
) >",B.3 Proof of Proposition 4,[0],[0]
"4n
n+ 1 .
",B.3 Proof of Proposition 4,[0],[0]
Now we only need to check whether the distribution PX×Y satisfies the assumptions shown in Theorem 1.,B.3 Proof of Proposition 4,[0],[0]
"Clearly, r+ = r− = 1 < r = 2 and with probability 1, random vector X drawn from distribution PX|Y=1 and random vector Z drawn from distribution PX|Y=−1 has rank one which equals to r+ and r−. Therefore, the distribution constructed here satisfies the assumptions in Theorem 1.",B.3 Proof of Proposition 4,[0],[0]
Proposition 17 Assume that assumption 1 and 4 are satisfed.,B.4 Proof of Proposition 5,[0],[0]
Assume that neurons in fS satisfy that σ is strongly convex and twice differentiable on R and has a global minimum at z = 0.,B.4 Proof of Proposition 5,[0],[0]
"Then there exists a network architecture fD and a distribution satisfying assumptions in Theorem 2 such that with probability one, the empirical loss L̂n(θ; p), p ≥ 2 has a local minima θ∗ = (θ∗S ,θ∗D) satisfying R̂n(θ
∗) ≥ min{n+,n−}n , where n+ and n− denote the number of positive and negative samples in the dataset, respectively.
",B.4 Proof of Proposition 5,[0],[0]
"Proof: We first prove the following claim showing that if the dataset satisfies certain conditions, then the empirical loss has a local minimum satisfying R̂n(θ
∗) ≥ min{n−,n+}n .",B.4 Proof of Proposition 5,[0],[0]
"Next, we construct a data distribution such that the dataset drawn from the distribution PX×Y satisfies these conditions with probability one.",B.4 Proof of Proposition 5,[0],[0]
Claim 4,B.4 Proof of Proposition 5,[0],[0]
If the matrix 1n+ ∑ i:yi=1 xix >,B.4 Proof of Proposition 5,[0],[0]
i − 1n− ∑,B.4 Proof of Proposition 5,[0],[0]
i:,B.4 Proof of Proposition 5,[0],[0]
yi=−1 xix >,B.4 Proof of Proposition 5,[0],[0]
"i is positive or negative definite, then the empirical loss function L̂n(θ) has a local minimum θ ∗ satisfying R̂n(θ ∗) ≥ min{n−,n+}n .
",B.4 Proof of Proposition 5,[0],[0]
Proof: We prove that,B.4 Proof of Proposition 5,[0],[0]
"if the following matrix
1
n+ ∑ i:yi=1",B.4 Proof of Proposition 5,[0],[0]
xix >,B.4 Proof of Proposition 5,[0],[0]
i,B.4 Proof of Proposition 5,[0],[0]
− 1 n− ∑ i:,B.4 Proof of Proposition 5,[0],[0]
yi=−1 xix >,B.4 Proof of Proposition 5,[0],[0]
"i
is either positive definite or negative definite, then there exists a local minima θ∗ having f(x;θ∗) ≡ constant",B.4 Proof of Proposition 5,[0],[0]
"and this leads to R̂n(θ
∗) ≥ min{n+,n−}n .",B.4 Proof of Proposition 5,[0],[0]
"Without loss of generality, we assume that the matrix is positive definite.",B.4 Proof of Proposition 5,[0],[0]
"Consider a single layer neural network
f(x;θ) = a0 + M∑",B.4 Proof of Proposition 5,[0],[0]
"j=1 ajσ ( w>j x ) .
",B.4 Proof of Proposition 5,[0],[0]
Let a∗1 = ...,B.4 Proof of Proposition 5,[0],[0]
= a ∗ M = −1 and w∗1 = ...,B.4 Proof of Proposition 5,[0],[0]
= w∗M = 0d.,B.4 Proof of Proposition 5,[0],[0]
"Therefore, we have f(x;θ∗)",B.4 Proof of Proposition 5,[0],[0]
= a∗0 −Mσ(0).,B.4 Proof of Proposition 5,[0],[0]
"Let a∗0 be the global optimizer of the following convex optimization problem.
",B.4 Proof of Proposition 5,[0],[0]
min a n∑ i=1,B.4 Proof of Proposition 5,[0],[0]
"`p(−yi(a−Mσ(0))).
",B.4 Proof of Proposition 5,[0],[0]
"Thus, we have n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi) = 0, (13) and this indicates that∑ i:yi=1",B.4 Proof of Proposition 5,[0],[0]
`′p(−(a∗0 −Mσ(0))),B.4 Proof of Proposition 5,[0],[0]
= ∑,B.4 Proof of Proposition 5,[0],[0]
i:yi=−1 `′p(a ∗ 0 −Mσ(0)) or `′p(−a∗0 +Mσ(0))n+ =,B.4 Proof of Proposition 5,[0],[0]
`′p(a∗0 −Mσ(0))n−. (14),B.4 Proof of Proposition 5,[0],[0]
"In addition, since for ∀j ∈ [M ],
∂L̂n(θ ∗)
",B.4 Proof of Proposition 5,[0],[0]
∂aj = n∑ i=1,B.4 Proof of Proposition 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)σ(0) = 0, by Equation (13),
∇wj L̂n(θ∗) = n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)σ′(0)xi = 0d, by σ′(0) = 0,
and ∂L̂n(θ ∗)
",B.4 Proof of Proposition 5,[0],[0]
∂a0 = n∑ i=1,B.4 Proof of Proposition 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi) = 0,
then θ∗ is a critical point.",B.4 Proof of Proposition 5,[0],[0]
"Next we show that θ∗ = (a∗0, ..., a ∗ M ,w ∗ 1, ...,w ∗ M ) is a local minima.",B.4 Proof of Proposition 5,[0],[0]
"Consider any perturbation ∆a1, ...,∆aM : |∆aj | < 12 for all j ∈",B.4 Proof of Proposition 5,[0],[0]
"[M ], ∆w1, ...,∆wM ∈ Rd and ∆a0",B.4 Proof of Proposition 5,[0],[0]
"∈ R. Define
θ̃ = (a∗0 + ∆a0, ..., a ∗ M + ∆aM ,w ∗ 1 + ∆w1, ...,w ∗ M + ∆wM ).
",B.4 Proof of Proposition 5,[0],[0]
"Then
n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
`p(−yif(xi; θ̃))− n∑ i=1,B.4 Proof of Proposition 5,[0],[0]
`p(−yif(xi;θ∗)),B.4 Proof of Proposition 5,[0],[0]
= n∑ i=1,B.4 Proof of Proposition 5,[0],[0]
[ `p(−yif(xi; θ̃))− `p(−yif(xi;θ∗)) ],B.4 Proof of Proposition 5,[0],[0]
"≥
n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)[f(xi; θ̃)− f(xi;θ∗)]
= n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)[f(xi; θ̃)− a∗0 +Mσ(0)]
= n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃),
where the inequality follows from the convexity of the loss function `p(z), the second equality follows from the fact that f(x;θ∗) ≡",B.4 Proof of Proposition 5,[0],[0]
a∗0 − Mσ(0) and the third equality follows from Equation (14).,B.4 Proof of Proposition 5,[0],[0]
"In addition, we have
n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃) = n∑ i=1,B.4 Proof of Proposition 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)  M∑ j=1 (a∗j + ∆aj)σ ( ∆w>j xi ) + ∆a0
 =
n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))(−yi)  M∑ j=1 (a∗j + ∆aj)σ ( ∆w>j xi ) by Eq.,B.4 Proof of Proposition 5,[0],[0]
"(14) =
M∑ j=1 −(a∗j + ∆aj)",B.4 Proof of Proposition 5,[0],[0]
[ n∑ i=1,B.4 Proof of Proposition 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w>j xi )] .
",B.4 Proof of Proposition 5,[0],[0]
"Now we define the following function G : Rd → R,
G(u) = n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ ( u>xi ) .
",B.4 Proof of Proposition 5,[0],[0]
"Now we consider the gradient of the function G with respect to the vector u at the point 0d,
∇uG(0d) = n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ′ (0)xi = 0d.
",B.4 Proof of Proposition 5,[0],[0]
"Furthermore, the Hessian matrix ∇2uG(0d) satisfies
∇2uG(0d) = n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))yiσ′′ (0)xix>i = σ′′ (0) n∑ i=1,B.4 Proof of Proposition 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yixix>i
= σ′′(0)  1",B.4 Proof of Proposition 5,[0],[0]
n+ ∑ i:yi=1 xix,B.4 Proof of Proposition 5,[0],[0]
>,B.4 Proof of Proposition 5,[0],[0]
i,B.4 Proof of Proposition 5,[0],[0]
− 1 n− ∑ i:,B.4 Proof of Proposition 5,[0],[0]
yi=−1 xix >,B.4 Proof of Proposition 5,[0],[0]
"i  0, then the function G(u)",B.4 Proof of Proposition 5,[0],[0]
=,B.4 Proof of Proposition 5,[0],[0]
∑n i=1,B.4 Proof of Proposition 5,[0],[0]
`p(−yi(a∗0 −Mσ(0)))yiσ ( u>xi ) has a local minima at u = 0d.,B.4 Proof of Proposition 5,[0],[0]
"This indicates that there exists ε > 0 such that for all ∆w : ‖∆w‖2 ≤ ε, n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w>xi ) ≥ n∑ i=1,B.4 Proof of Proposition 5,[0],[0]
"`p(−yi(a∗0 −Mσ(0)))yiσ (0) = 0.
",B.4 Proof of Proposition 5,[0],[0]
"In addition, since a∗j = −1, |∆aj | < 12 , then for all ∆wj : ‖∆wj‖2 ≤ ε, n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃) = M∑ j=1 −(a∗j + ∆aj),B.4 Proof of Proposition 5,[0],[0]
[ n∑ i=1,B.4 Proof of Proposition 5,[0],[0]
`p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w>j xi )],B.4 Proof of Proposition 5,[0],[0]
"≥ 0.
",B.4 Proof of Proposition 5,[0],[0]
"Therefore, we have n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃) ≥ 0, and this indicates that n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
`p(−yif(xi; θ̃))− n∑ i=1,B.4 Proof of Proposition 5,[0],[0]
`p(−yif(xi;θ∗)),B.4 Proof of Proposition 5,[0],[0]
≥ 0.,B.4 Proof of Proposition 5,[0],[0]
"Thus, θ∗ is a local minima with f(x;θ∗)",B.4 Proof of Proposition 5,[0],[0]
= a∗0 −Mσ(0) = constant.,B.4 Proof of Proposition 5,[0],[0]
"Thus, n∑ i=1",B.4 Proof of Proposition 5,[0],[0]
I{yi 6= sgn(f(xi;θ∗))},B.4 Proof of Proposition 5,[0],[0]
"≥ min{n−, n+} n .
",B.4 Proof of Proposition 5,[0],[0]
Now we define a data distribution as follows.,B.4 Proof of Proposition 5,[0],[0]
Let PY (Y = 1) = P(Y = −1) = 0.5.,B.4 Proof of Proposition 5,[0],[0]
"Let PX|Y=1 be a continuous distribution (e.g., uniform distribution) defined on the interval [2, 3] and PX|Y=−1 be a continuous distribution defined on the interval [−1,−1/2].",B.4 Proof of Proposition 5,[0],[0]
"Then if samples in the dataset D are drawn independently from the this distribution, the scalar 1n+ ∑ i:yi=1 x2i",B.4 Proof of Proposition 5,[0],[0]
− 1n− ∑ i:yi=−1 x 2 i > 0,B.4 Proof of Proposition 5,[0],[0]
if n+ > 0,B.4 Proof of Proposition 5,[0],[0]
"and
the scalar 1n+ ∑ i:yi=1",B.4 Proof of Proposition 5,[0],[0]
x2i,B.4 Proof of Proposition 5,[0],[0]
− 1n− ∑ i:yi=−1 x 2 i < 0,B.4 Proof of Proposition 5,[0],[0]
if n+ = 0.,B.4 Proof of Proposition 5,[0],[0]
This means that the dataset satisfies the conditions in the claim with probability one.,B.4 Proof of Proposition 5,[0],[0]
Proposition 18 Assume that assumption 1 is satisfied.,B.5 Proof of Proposition 6,[0],[0]
Assume that the feedforward neural network f(x;θ) has at least one hidden layer and has at least one neuron in each hidden layer.,B.5 Proof of Proposition 6,[0],[0]
"If neurons in the network f satisfy that σ(z) = 0 for all z ≤ 0 and σ(z) is continuous on R, then the empirical loss L̂n(θ; p), p ≥ 2 has a local minima θ∗ satisfying R̂n(θ∗) ≥ min{n+,n−}n , where n+ and n− denote the number of positive and negative samples in the dataset, respectively.
",B.5 Proof of Proposition 6,[0],[0]
"Proof: Assume that the multilayer neural network f(x;θ) has L ≥ 1 hidden layers, Ml ≥ 1 neurons in the l-th layer.",B.5 Proof of Proposition 6,[0],[0]
Now we let the vector θl contain all parameters in the first l ∈,B.5 Proof of Proposition 6,[0],[0]
[L] layers.,B.5 Proof of Proposition 6,[0],[0]
"Then the output of the neural network can be rewritten as
f(x; a0,θL) = a0 + ML∑",B.5 Proof of Proposition 6,[0],[0]
j=1 ajσ(w > j Φ(x;θL−1),B.5 Proof of Proposition 6,[0],[0]
"+ bj),
where Φ(x;θL−1)",B.5 Proof of Proposition 6,[0],[0]
=,B.5 Proof of Proposition 6,[0],[0]
"(Φ1(x;θL−1), ...,ΦML−1(x;θL−1)) denotes the outputs of the neurons in the layer L − 1.",B.5 Proof of Proposition 6,[0],[0]
"Now we construct a local minimum θ∗ = (a∗0,θ∗L).",B.5 Proof of Proposition 6,[0],[0]
"The key idea of constructing the local minimum having a training error no smaller than min{n+,n−}n is appropriately choosing wj , bj such that all neurons in the last layer keep inactive on all samples in the dataset.",B.5 Proof of Proposition 6,[0],[0]
This is possible since the outputs of the neurons in the layer L− 1 are bounded.,B.5 Proof of Proposition 6,[0],[0]
We first set θL−1 to any unit vector θ ∗,B.5 Proof of Proposition 6,[0],[0]
L−1 : ‖θ∗L−1‖2 = 1.,B.5 Proof of Proposition 6,[0],[0]
"Next, for any data set D = {(xi; yi)}ni=1, we define K = max
i∈[n] ‖Φ(xi;θ∗L−1)‖2.
",B.5 Proof of Proposition 6,[0],[0]
"In addition, it is easy to show that the function ϕij(θ) = Φj(xi;θ) is a continuous function.",B.5 Proof of Proposition 6,[0],[0]
Now we consider the compact set Cδ = {θ : ‖θ,B.5 Proof of Proposition 6,[0],[0]
"− θ∗L−1‖2 ≤ δ}, where δ > 0",B.5 Proof of Proposition 6,[0],[0]
.,B.5 Proof of Proposition 6,[0],[0]
"Since each function ϕij is a continuous function on the compact set C, then by the definition of continuity,
∀ε > 0,∃δij(ε) ∈ (0, 1) : |ϕij(θ)− ϕij(θ∗L−1)| ≤ ε for all θ ∈ Cδij .",B.5 Proof of Proposition 6,[0],[0]
"For a given ε > 0, let
δ(ε) = min i∈[n],j∈[ML−1] δij(ε),
then for all i ∈",B.5 Proof of Proposition 6,[0],[0]
"[n], j ∈ [ML−1] and ∀θ ∈ Cδ, |ϕij(θ)− ϕij(θL−1)| ≤ ε.
",B.5 Proof of Proposition 6,[0],[0]
Now we set wj to some unit vector wj : ‖wj‖2 = 1 for all j ∈,B.5 Proof of Proposition 6,[0],[0]
"[ML−1], and we set bj to a scalar b∗j satisfying
w∗j >Φ(xi;θ ∗ L−1)",B.5 Proof of Proposition 6,[0],[0]
+,B.5 Proof of Proposition 6,[0],[0]
"b ∗ j ≤ −1, for all i ∈",B.5 Proof of Proposition 6,[0],[0]
"[n] and all θ ∈ C.
Therefore, the neural network becomes
f(xi; a0,θ ∗ L) = a0, ∀i ∈",B.5 Proof of Proposition 6,[0],[0]
"[n].
",B.5 Proof of Proposition 6,[0],[0]
"Furthermore, for the δ(ε) defined above and for any parameter vector θ̃L : ‖θ̃L−θ∗L‖2 ≤ δ(ε), we have for all j ∈",B.5 Proof of Proposition 6,[0],[0]
[ML−1] and all i ∈,B.5 Proof of Proposition 6,[0],[0]
"[n],
|w̃>j Φ(xi; θ̃L−1) + b̃j",B.5 Proof of Proposition 6,[0],[0]
−w∗j>Φ(xi;θ∗L−1)− b∗j | ≤,B.5 Proof of Proposition 6,[0],[0]
|w̃>j Φ(xi; θ̃L−1)− w̃>j Φ(xi;θ∗L−1),B.5 Proof of Proposition 6,[0],[0]
+ w̃>j Φ(xi;θ∗L−1)−w∗j>Φ(xi;θ∗L−1)|+ |b̃j,B.5 Proof of Proposition 6,[0],[0]
− bj | ≤ |w̃>j Φ(xi; θ̃L−1)− w̃>j Φ(xi;θ∗L−1)|+,B.5 Proof of Proposition 6,[0],[0]
|w̃>j Φ(xi;θ∗L−1)−w∗j>Φ(xi;θ∗L−1)|+ |b̃j,B.5 Proof of Proposition 6,[0],[0]
− bj | ≤ ‖w̃j‖2‖Φ(xi; θ̃L−1)−Φ(xi;θ∗L−1)‖2 + ‖w̃j −w∗j‖2‖Φ(xi;θ∗L−1)‖2 + |b̃j,B.5 Proof of Proposition 6,[0],[0]
− bj | ≤,B.5 Proof of Proposition 6,[0],[0]
(1 + δ(ε)),B.5 Proof of Proposition 6,[0],[0]
"√ ML−1ε+ εK + ε ≤ (2 √ ML−1 +K + 1)ε.
",B.5 Proof of Proposition 6,[0],[0]
Thus,B.5 Proof of Proposition 6,[0],[0]
", if ε < 1 2(2 √ ML−1+K+1) , then for all θ̃L : ‖θ̃L − θ∗L‖2 ≤ δ(ε), ∀j ∈",B.5 Proof of Proposition 6,[0],[0]
[M ] and ∀i ∈,B.5 Proof of Proposition 6,[0],[0]
"[n]
w̃>j Φ(xi; θ̃L−1) + b̃j ≤ w∗j>Φ(xi;θ∗L−1)",B.5 Proof of Proposition 6,[0],[0]
+ b∗j,B.5 Proof of Proposition 6,[0],[0]
+ 1 2 ≤ −1 2 .,B.5 Proof of Proposition 6,[0],[0]
"(15)
Since σ(z) = 0 for all z ≤ 0, then this indicates that for all θ̃L : ‖θ̃L",B.5 Proof of Proposition 6,[0],[0]
"− θ∗L‖2 ≤ δ(ε),
f(xi; a0, θ̃L−1) = a0, for all",B.5 Proof of Proposition 6,[0],[0]
i ∈,B.5 Proof of Proposition 6,[0],[0]
"[n].
Finally, we set a∗0 to the global minimizer of the following convex optimization problem:
min a∈R
1
n n∑ i=1",B.5 Proof of Proposition 6,[0],[0]
"`(−yia).
",B.5 Proof of Proposition 6,[0],[0]
"This indicates that for any a ∈ R,
1
n n∑ i=1",B.5 Proof of Proposition 6,[0],[0]
`(−yia) ≥ 1 n n∑ i=1,B.5 Proof of Proposition 6,[0],[0]
"`(−yia∗0).
",B.5 Proof of Proposition 6,[0],[0]
"Therefore, for θ̃L : ‖θ̃L − θ∗L‖2 ≤ δ(ε) and any a0 ∈ R
L̂n(a0, θ̃L) = 1
n n∑ i=1",B.5 Proof of Proposition 6,[0],[0]
`(−yif(xi; θ̃L)),B.5 Proof of Proposition 6,[0],[0]
= 1 n n∑ i=1,B.5 Proof of Proposition 6,[0],[0]
"`(−yia0)
≥ 1 n n∑ i=1",B.5 Proof of Proposition 6,[0],[0]
`(−yia∗0) ≥ 1 n n∑ i=1,B.5 Proof of Proposition 6,[0],[0]
"`(−yif(xi; a∗0,θ∗L))",B.5 Proof of Proposition 6,[0],[0]
"= L̂n(a∗0,θ∗L).
",B.5 Proof of Proposition 6,[0],[0]
"This means that (a∗0,θ ∗ L) is a local minima and f(xi; a ∗ 0,θ ∗ L) = a ∗ 0 for all",B.5 Proof of Proposition 6,[0],[0]
i ∈,B.5 Proof of Proposition 6,[0],[0]
[n].,B.5 Proof of Proposition 6,[0],[0]
"This further indicates that
R̂n(θ ∗) ≥ min{n−, n+}
n .",B.5 Proof of Proposition 6,[0],[0]
Proposition 19 Assume that H : Rd → Rd is a feedforward neural network parameterized by θ and all neurons in H are ReLUs.,B.6 Proof of Proposition 7,[0],[0]
"Define a network f : Rd → R with identity shortcut connections as f(x;a,θ, b) = a>(x + H(x;θ))",B.6 Proof of Proposition 7,[0],[0]
"+ b, a ∈ Rd, b ∈ R.",B.6 Proof of Proposition 7,[0],[0]
"Then there exists a distribution PX×Y satisfying the assumptions in Theorem 1 such that with probability at least 1 − e−Ω(n), the empirical loss L̂n(a,θ, b; p) = 1 n",B.6 Proof of Proposition 7,[0],[0]
∑n i=1,B.6 Proof of Proposition 7,[0],[0]
"`(−yif(xi;θ); p), p ≥ 2 has a local minimum with non-zero training error.
",B.6 Proof of Proposition 7,[0],[0]
"Proof: We first show that if the samples in the dataset are not linearly separable, then empirical loss has a local minimum with a non-zero training error.",B.6 Proof of Proposition 7,[0],[0]
"Next, we construct a data distribution such that n samples independently drawn from this data distribution are not linearly separable with probability at least 1− exp(−Ω(n)).
",B.6 Proof of Proposition 7,[0],[0]
Claim 5,B.6 Proof of Proposition 7,[0],[0]
"If the samples in the dataset are not linearly separable, i.e., minw∈Rd,b∈R 1 n",B.6 Proof of Proposition 7,[0],[0]
∑n i=1,B.6 Proof of Proposition 7,[0],[0]
I{yi 6=,B.6 Proof of Proposition 7,[0],[0]
"sgn(w>xi + b)} > 0, then empirical loss has a local minimum with a non-zero training error.
",B.6 Proof of Proposition 7,[0],[0]
"Proof: The proof follows from the proof of Proposition 2 in Appendix B.1 where we show that when the dataset has both positive and negative samples and all neurons in the multilayer network are ReLUs, then the empirical loss has a local minimum with a non-zero training error.",B.6 Proof of Proposition 7,[0],[0]
"Assume that the multilayer neural network H(x;θ) has L ≥ 1 hidden layers, Ml ≥ 1 neurons in the l-th layer in the multilayer neural network H. Clearly,",B.6 Proof of Proposition 7,[0],[0]
ML = d.,B.6 Proof of Proposition 7,[0],[0]
Now we let the vector θl contain all parameters in the first l ∈,B.6 Proof of Proposition 7,[0],[0]
[L] layers.,B.6 Proof of Proposition 7,[0],[0]
"Then the output of the neural network f(x;a,θ, b) can be rewritten as
f(x;a,θ, b) = b+ ML∑ j=1",B.6 Proof of Proposition 7,[0],[0]
ajσ(w > j Φ(x;θL−1),B.6 Proof of Proposition 7,[0],[0]
"+ bj) + a >x,
where Φ(x;θL−1) =",B.6 Proof of Proposition 7,[0],[0]
"(Φ1(x;θL−1), ...,ΦML−1(x;θL−1)) denotes the outputs of the neurons in the layer L − 1.",B.6 Proof of Proposition 7,[0],[0]
"Now we construct a local minimum (a∗,θ∗, b∗).",B.6 Proof of Proposition 7,[0],[0]
The whole idea of constructing the local minimum having a non-zero training error is as follows.,B.6 Proof of Proposition 7,[0],[0]
"We first appropriately choose wj , bj such that all neurons in the last layer of the multilayer network H keep inactive on all samples in the dataset.",B.6 Proof of Proposition 7,[0],[0]
"Then the neural network becomes a linear model
f(x;a∗,θ∗, b∗) = b∗ + a∗>x.
",B.6 Proof of Proposition 7,[0],[0]
"Next we only need to set a∗, b∗ to the global optimizer of the convex optimization problem
min a∈Rd,b∈R
1
n n∑ i=1",B.6 Proof of Proposition 7,[0],[0]
"`p ( −yi(a>xi + b) ) .
",B.6 Proof of Proposition 7,[0],[0]
"Therefore, as we have shown in the proof of Propsition 2, if we slightly perturb the parameter θ∗, the output of the multilayer network H(x; θ̃) on all samples are still zero and this makes f(xi;a
∗, θ̃, b∗) = a∗>xi + b
∗.",B.6 Proof of Proposition 7,[0],[0]
"In addition, if we further perturb the vector a∗ and b∗, the value of the empirical loss will not decrease since a∗ and b∗ are the global optimizer of the empirical loss function.",B.6 Proof of Proposition 7,[0],[0]
Now we present the proof.,B.6 Proof of Proposition 7,[0],[0]
We first set θL−1 to any unit vector θ ∗,B.6 Proof of Proposition 7,[0],[0]
L−1 : ‖θ∗L−1‖2 = 1.,B.6 Proof of Proposition 7,[0],[0]
"Next, for any data set D = {(xi; yi)}ni=1, we define K = max
i∈[n] ‖Φ(xi;θ∗L−1)‖2.
",B.6 Proof of Proposition 7,[0],[0]
"In addition, it is easy to show that the function ϕij(θ) = Φj(xi;θ) is a continuous function.",B.6 Proof of Proposition 7,[0],[0]
Now we consider the compact set Cδ = {θ : ‖θ,B.6 Proof of Proposition 7,[0],[0]
"− θ∗L−1‖2 ≤ δ}, where δ > 0",B.6 Proof of Proposition 7,[0],[0]
.,B.6 Proof of Proposition 7,[0],[0]
"Since each function ϕij is a continuous function on the compact set C, then by the definition of continuity,
∀ε > 0,∃δij(ε) ∈ (0, 1) : |ϕij(θ)− ϕij(θ∗L−1)| ≤ ε for all θ ∈ Cδij .
",B.6 Proof of Proposition 7,[0],[0]
"For a given ε > 0, let δ(ε) =",B.6 Proof of Proposition 7,[0],[0]
"min
i∈[n],j∈[ML−1] δij(ε),
then for all i ∈",B.6 Proof of Proposition 7,[0],[0]
"[n], j ∈ [ML−1] and ∀θ ∈ Cδ,
|ϕij(θ)− ϕij(θL−1)| ≤ ε.
",B.6 Proof of Proposition 7,[0],[0]
Now we set wj to some unit vector wj : ‖wj‖2 = 1 for all j ∈,B.6 Proof of Proposition 7,[0],[0]
"[ML−1], and we set bj to a scalar b∗j satisfying
w∗j >Φ(xi;θ ∗ L−1)",B.6 Proof of Proposition 7,[0],[0]
+,B.6 Proof of Proposition 7,[0],[0]
"b ∗ j ≤ −1, for all i ∈",B.6 Proof of Proposition 7,[0],[0]
"[n] and all θ ∈ C.
Therefore, the neural network becomes
f(xi;a, θ̃, b) = a >xi + b, ∀i ∈",B.6 Proof of Proposition 7,[0],[0]
"[n].
",B.6 Proof of Proposition 7,[0],[0]
"Furthermore, for the δ(ε) defined above and for any parameter vector θ̃L : ‖θ̃L−θ∗L‖2 ≤ δ(ε), we have for all j ∈",B.6 Proof of Proposition 7,[0],[0]
[ML−1] and all i ∈,B.6 Proof of Proposition 7,[0],[0]
"[n],
|w̃>j Φ(xi; θ̃L−1) + b̃j",B.6 Proof of Proposition 7,[0],[0]
−w∗j>Φ(xi;θ∗L−1)− b∗j | ≤,B.6 Proof of Proposition 7,[0],[0]
|w̃>j Φ(xi; θ̃L−1)− w̃>j Φ(xi;θ∗L−1),B.6 Proof of Proposition 7,[0],[0]
+ w̃>j Φ(xi;θ∗L−1)−w∗j>Φ(xi;θ∗L−1)|+ |b̃j,B.6 Proof of Proposition 7,[0],[0]
− bj | ≤ |w̃>j Φ(xi; θ̃L−1)− w̃>j Φ(xi;θ∗L−1)|+,B.6 Proof of Proposition 7,[0],[0]
|w̃>j Φ(xi;θ∗L−1)−w∗j>Φ(xi;θ∗L−1)|+ |b̃j,B.6 Proof of Proposition 7,[0],[0]
− bj | ≤ ‖w̃j‖2‖Φ(xi; θ̃L−1)−Φ(xi;θ∗L−1)‖2 + ‖w̃j −w∗j‖2‖Φ(xi;θ∗L−1)‖2 + |b̃j,B.6 Proof of Proposition 7,[0],[0]
− bj | ≤,B.6 Proof of Proposition 7,[0],[0]
(1 + δ(ε)),B.6 Proof of Proposition 7,[0],[0]
"√ ML−1ε+ εK + ε ≤ (2 √ ML−1 +K + 1)ε.
",B.6 Proof of Proposition 7,[0],[0]
Thus,B.6 Proof of Proposition 7,[0],[0]
", if ε < 1 2(2 √ ML−1+K+1) , then for all θ̃L : ‖θ̃L − θ∗L‖2 ≤ δ(ε), ∀j ∈",B.6 Proof of Proposition 7,[0],[0]
[M ] and ∀i ∈,B.6 Proof of Proposition 7,[0],[0]
"[n]
w̃>j Φ(xi; θ̃L−1) + b̃j ≤ w∗j>Φ(xi;θ∗L−1)",B.6 Proof of Proposition 7,[0],[0]
+ b∗j,B.6 Proof of Proposition 7,[0],[0]
+ 1 2 ≤ −1 2 .,B.6 Proof of Proposition 7,[0],[0]
"(16)
Since σ(z) = 0 for all z ≤ 0, then this indicates that for all θ̃L : ‖θ̃L",B.6 Proof of Proposition 7,[0],[0]
"− θ∗L‖2 ≤ δ(ε),
f(xi;a, θ̃, b) = a >xi + b, for all i ∈",B.6 Proof of Proposition 7,[0],[0]
"[n].
Finally, we set a∗, b∗ to the global minimizer of the following convex optimization problem:
",B.6 Proof of Proposition 7,[0],[0]
"min a∈Rd,b∈R
1
n n∑ i=1",B.6 Proof of Proposition 7,[0],[0]
"`p ( −yi(a>xi + b) ) .
",B.6 Proof of Proposition 7,[0],[0]
"This indicates that for any a ∈ Rd, b ∈ R,
1
n n∑ i=1",B.6 Proof of Proposition 7,[0],[0]
`p(−yi(a>xi + b)),B.6 Proof of Proposition 7,[0],[0]
≥ 1 n n∑ i=1,B.6 Proof of Proposition 7,[0],[0]
"`p(−yi(a∗>xi + b∗)).
",B.6 Proof of Proposition 7,[0],[0]
"Therefore, for θ̃L : ‖θ̃L − θ∗L‖2 ≤ δ(ε) and any a ∈ Rd, b ∈ R
L̂n(a, θ̃L, b; p) = 1
n n∑ i=1",B.6 Proof of Proposition 7,[0],[0]
"`p(−yif(xi;a, θ̃L, b))",B.6 Proof of Proposition 7,[0],[0]
= 1 n n∑ i=1,B.6 Proof of Proposition 7,[0],[0]
"`p(−yi(a>xi + b))
",B.6 Proof of Proposition 7,[0],[0]
≥ 1 n n∑ i=1,B.6 Proof of Proposition 7,[0],[0]
`p(−yi(a∗>xi + b∗)),B.6 Proof of Proposition 7,[0],[0]
≥ 1 n n∑ i=1,B.6 Proof of Proposition 7,[0],[0]
"`p(−yif(xi; a∗0,θ∗L, b∗))",B.6 Proof of Proposition 7,[0],[0]
"= L̂n(a∗,θ∗L, b∗; p).
",B.6 Proof of Proposition 7,[0],[0]
"This means that (a∗,θ∗L, b ∗) is a local minima and f(xi;a ∗,θ∗L, b ∗)",B.6 Proof of Proposition 7,[0],[0]
=,B.6 Proof of Proposition 7,[0],[0]
a∗>xi + b ∗ for all i ∈,B.6 Proof of Proposition 7,[0],[0]
[n].,B.6 Proof of Proposition 7,[0],[0]
"This further indicates that
R̂n(θ ∗) ≥ min
w∈Rd,b∈R
1
n n∑ i=1",B.6 Proof of Proposition 7,[0],[0]
I{yi 6=,B.6 Proof of Proposition 7,[0],[0]
"sgn(w>xi + b)} > 0.
",B.6 Proof of Proposition 7,[0],[0]
Now we consider the following distribution PX×Y defined on the Rd.,B.6 Proof of Proposition 7,[0],[0]
"Let PX|Y=1 is a uniform distribution on the region [1, 2] ∪ [−2,−1] × {0}d−1 and PX|Y=−1 is a uniform distribution on the region {0} ×",B.6 Proof of Proposition 7,[0],[0]
"[1, 2] ∪ [−2,−1] × {0}d−2.",B.6 Proof of Proposition 7,[0],[0]
"In addition, let PY (Y = 1) = PY (Y = −1) = 0.5",B.6 Proof of Proposition 7,[0],[0]
"Clearly, r+ = r− = 1 < r = 2 and this distribution satisfies the assumptions in Theorem 1.",B.6 Proof of Proposition 7,[0],[0]
"Furthermore, with probability at least 1 − 1
4n−1 , there exists at least one sample in the following four regions:",B.6 Proof of Proposition 7,[0],[0]
"[1, 2]×{0}d−1, [−2,−1]×{0}d−1, {0}× [1, 2]×{0}d−2 and {0}× [−2,−1]×{0}d−2 and this makes the samples in the dataset not linearly separable.",B.6 Proof of Proposition 7,[0],[0]
"Example 2 Let the distribution PX×Y satisfy that P(Y = 1) = P(Y = −1) = 0.5, P(X = 5/4|Y = 1) = 1 and P(X|Y = −1) is a uniform distribution on the interval",B.7 Proof of Example 1,[0],[0]
"[0, 1].",B.7 Proof of Example 1,[0],[0]
"For a linear model f(x; a, b) = ax + b, a, b ∈ R, then every global minimum (a∗, b∗) of the population loss L(a, b)",B.7 Proof of Example 1,[0],[0]
= EX×Y,B.7 Proof of Example 1,[0],[0]
"[(1 − Y f(X; a, b))2] satisfies PX×Y",B.7 Proof of Example 1,[0],[0]
"[Y 6= sgn(f(X; a∗, b∗))]",B.7 Proof of Example 1,[0],[0]
"≥ 1/16.
",B.7 Proof of Example 1,[0],[0]
Proof: The proof is simple.,B.7 Proof of Example 1,[0],[0]
We first consider a simpler form of the problem.,B.7 Proof of Example 1,[0],[0]
"Given the distribution PX×Y , the optimal linear estimator Ê[Y |X] is
Ê[Y |X] = E[Y ]",B.7 Proof of Example 1,[0],[0]
"+ Cov(Y,X)V ar−1(X)(X − E[X]).
",B.7 Proof of Example 1,[0],[0]
"Since E[Y ] = 0, Cov(Y,X) =",B.7 Proof of Example 1,[0],[0]
"E[XY ]− E[X]E[Y ] = 1, V ar(X) > 0, E[X] = 7/8, the misclassification rate is 1/16.",B.7 Proof of Example 1,[0],[0]
"In this subsection, we present two counterexamples to show that neither Theorem 1 nor 2 holds if we replace the loss function with the quadratic loss.
",B.8 Proof of Example 3 and 4,[0],[0]
Example 3,B.8 Proof of Example 3 and 4,[0],[0]
"Let the distribution PX×Y defined on R2 × {−1, 1} satisfy that P(Y = 1)",B.8 Proof of Example 3 and 4,[0],[0]
"= P(Y = −1) = 0.5, P(X = (α, 0)|Y = 1) = P(X = (1, 0)|Y = 1) = 0.5 and P(X = (0, α)|Y = −1) = P(X = (0, 1)|Y = −1) = 0.5.",B.8 Proof of Example 3 and 4,[0],[0]
"Assume that samples in the dataset D = {(xi, yi)}4ni=1 are independently drawn from the distribution PX×Y .",B.8 Proof of Example 3 and 4,[0],[0]
"Assume that the network fS has M ≥ 2 neurons and all neurons in the network fS are quadratic neurons, i.e., σ(z) = z
2.",B.8 Proof of Example 3 and 4,[0],[0]
Then there exists an α ∈,B.8 Proof of Example 3 and 4,[0],[0]
"[0, 1] such that every global minimum of the empirical loss function L̂4n(θ)",B.8 Proof of Example 3 and 4,[0],[0]
= 1,B.8 Proof of Example 3 and 4,[0],[0]
4n ∑4n,B.8 Proof of Example 3 and 4,[0],[0]
"i=1(1− yif(xi;θ))2 has a training error greater than 1/8 with probability at least Ω(1/n3).
",B.8 Proof of Example 3 and 4,[0],[0]
Remark: This is a counterexample for Theorem 1.,B.8 Proof of Example 3 and 4,[0],[0]
"It is easy to check that the distribution satisfies assumption 2 and 3, where r = 2 > max{1, 1} = max{r+, r−}.",B.8 Proof of Example 3 and 4,[0],[0]
Proof: Let X =,B.8 Proof of Example 3 and 4,[0],[0]
"(X1, X2).",B.8 Proof of Example 3 and 4,[0],[0]
Set the feedforward network fD to a constant.,B.8 Proof of Example 3 and 4,[0],[0]
"Since the positive and negative samples locate on two orthogonal subspaces, then it is easy to check that under this distribution, for any quadratic function of the form g(X1, X2) = a1X 2 1 + a2X 2 2 + a0, there always exists a neural
network of the form f(X1, X2) = a0 + ∑M j=1 aj(wj1X1 + wj2X2) 2 = a0 + ∑M j=1 aj(w 2 j1X 2 1 + w 2 j2X 2 2 ), M ≥ 2 satisfying PX×Y (f(X) = g(X))",B.8 Proof of Example 3 and 4,[0],[0]
"= 1.
",B.8 Proof of Example 3 and 4,[0],[0]
"In addition, for any neural network f(X1, X2) = a0+ ∑M j=1 aj(wj1X1+wj2X2) 2, there exists a quadratic function of the form g(X1, X2) = a1X 2 1 + a2X 2 2 + a0 satisfying
PX×Y (f(X) = g(X))",B.8 Proof of Example 3 and 4,[0],[0]
"= 1.
",B.8 Proof of Example 3 and 4,[0],[0]
"This indicates that the optimal neural network f(x;θ∗) should be the solution of
min a0∈R,a∈R2
1
4n 4n∑ i=1",B.8 Proof of Example 3 and 4,[0],[0]
( 1− yi ( a0 +,B.8 Proof of Example 3 and 4,[0],[0]
"a1(x (1) i ) 2 + a2(x (2) i ) 2 )) .
",B.8 Proof of Example 3 and 4,[0],[0]
"Let n1, n2, n3 and n4 denote the number of samples at the point (α, 0), (1, 0), (0, α) and (0, 1), respectively.",B.8 Proof of Example 3 and 4,[0],[0]
We only need to focus the case where n1 = n2 = n3 = n4 = n.,B.8 Proof of Example 3 and 4,[0],[0]
"In this case, the optimal linear estimator should be of the form
g(X21 , X 2 2 ; a ∗ 0, a ∗ 1, a ∗ 2) = a ∗",B.8 Proof of Example 3 and 4,[0],[0]
1(X 2 1 − ÊX21 ) +,B.8 Proof of Example 3 and 4,[0],[0]
a∗2(X22,B.8 Proof of Example 3 and 4,[0],[0]
− ÊX22 ),B.8 Proof of Example 3 and 4,[0],[0]
"= a∗1 ( X21 − 1 + α2
4
) +",B.8 Proof of Example 3 and 4,[0],[0]
a∗2 ( X22,B.8 Proof of Example 3 and 4,[0],[0]
"− 1 + α2
4
) .
",B.8 Proof of Example 3 and 4,[0],[0]
"When α = 1/2, then 1+1/44 = 5/16 > 1/4",B.8 Proof of Example 3 and 4,[0],[0]
= α 2 and 1+1/44 = 5/16 < 1.,B.8 Proof of Example 3 and 4,[0],[0]
"Therefore, (1 +α 2)/4 ∈ (α2, 1).",B.8 Proof of Example 3 and 4,[0],[0]
"In this case, for any a∗1, a ∗ 2, the training error cannot be smaller than 1/4.",B.8 Proof of Example 3 and 4,[0],[0]
This can be easily seen by investigating positive and negative samples separately.,B.8 Proof of Example 3 and 4,[0],[0]
"For positive samples at (1, 0), the output of the network is g(1, 0; a∗0, a ∗ 1, a ∗ 2) = a ∗ 1(1− (1 +α2)/4).",B.8 Proof of Example 3 and 4,[0],[0]
"For positive samples at (α, 0), the output of the network is g(α, 0; a∗0, a ∗ 1, a ∗ 2) = a ∗ 1(α
2 − (1 + α2)/4).",B.8 Proof of Example 3 and 4,[0],[0]
Since α2 < 1+α24,B.8 Proof of Example 3 and 4,[0],[0]
"< 1, then if a∗1 6= 0, then the network will misclassify all samples at (α, 0) or (1, 0).",B.8 Proof of Example 3 and 4,[0],[0]
This indicates that a∗1 = 0 or training error is no smaller than 1/4.,B.8 Proof of Example 3 and 4,[0],[0]
"Using the same analysis on the negative samples, we will have a∗2 = 0 or training error is no smaller than 1/4.",B.8 Proof of Example 3 and 4,[0],[0]
"This indicates that the output of the network is a constant equal to zero, which has a training error 1/2.",B.8 Proof of Example 3 and 4,[0],[0]
"In all, the training error is no smaller than 1/4.",B.8 Proof of Example 3 and 4,[0],[0]
"The probability of the case where n1 = n2 = n3 = n4 is(
4n
2n
)( 2n
n )2 1 44n > 42n 2n+ 1",B.8 Proof of Example 3 and 4,[0],[0]
( 4n n+ 1 )2 1 44n = 1 (2n+ 1)(n+,B.8 Proof of Example 3 and 4,[0],[0]
"1)2
Example 4 Let the distribution PX×Y satisfy that P(Y = 1) = P(Y = −1) = 0.5, P(X = 1 + α|Y = 1) = P(X = 1 + 2α|Y = 1) = 0.5 and P(X = 0|Y = −1) = P(X = 1|Y = −1) = 0.5.",B.8 Proof of Example 3 and 4,[0],[0]
"Assume that samples in the dataset D = {(xi, yi)}4ni=1 are independently drawn from the distribution PX×Y .",B.8 Proof of Example 3 and 4,[0],[0]
Assume that the network fS has M ≥ 1 neurons and each neuron is a linear neuron σ(z) = z.,B.8 Proof of Example 3 and 4,[0],[0]
If α ∈,B.8 Proof of Example 3 and 4,[0],[0]
"[0, 1/6], then every global minimum of the empirical loss function L̂4n(θ) = 1",B.8 Proof of Example 3 and 4,[0],[0]
"4n ∑4n i=1(1 − yif(xi; θ))2 has a training error greater than 1/8 with probability at least Ω(1/n3).
",B.8 Proof of Example 3 and 4,[0],[0]
Remark: This is counterexample for Theorem 4.,B.8 Proof of Example 3 and 4,[0],[0]
"It is easy to check that distribution is linearly separable.
",B.8 Proof of Example 3 and 4,[0],[0]
"Proof: Let n−1, n1, n1+α denote the number of samples at the point −1, 1 and 1 + α.",B.8 Proof of Example 3 and 4,[0],[0]
"We only need to focus the case where n−1 = n, n1 = n and n1+α = 2n.",B.8 Proof of Example 3 and 4,[0],[0]
"Since the network is a linear network, then under this distribution, the optimal linear estimator should be of the form
f(x;θ) = a∗ ( x− 3 + 3α
4
) .
",B.8 Proof of Example 3 and 4,[0],[0]
"If a∗ = 0, then the training error is 1/2.",B.8 Proof of Example 3 and 4,[0],[0]
"If a∗ > 0, then the training error is 1/4, due to the misclassification of all points at x = 1.",B.8 Proof of Example 3 and 4,[0],[0]
"If a∗ < 0, then the training error is 3/4, due to the misclassification of all points at x = 1 + α and x = −1.",B.8 Proof of Example 3 and 4,[0],[0]
This means that the training error in this case should be greater or equal to 1/4.,B.8 Proof of Example 3 and 4,[0],[0]
"The probability of this case is(
4n
2n
)( 2n
n )2 1 44n > 42n 2n+ 1 ( 4n n+ 1 )2 1 44n = 1 (2n+ 1)(n+ 1)2",B.8 Proof of Example 3 and 4,[0],[0]
Proposition 20,B.9 Proof of Proposition 8,[0],[0]
Let f :,B.9 Proof of Proposition 8,[0],[0]
Rd → R denote a feedforward network parameterized by θ and let the dataset have n samples.,B.9 Proof of Proposition 8,[0],[0]
"When the loss function `p satisfies assumption 1 and p ≥ 1, we have minθ L̂n(θ; p) = 0",B.9 Proof of Proposition 8,[0],[0]
if and only if minθ R̂n(θ) = 0.,B.9 Proof of Proposition 8,[0],[0]
"Furthermore, if minθ R̂n(θ) = 0, every global minimum θ
∗ of the empirical loss L̂n(θ; p) has zero training error, i.e., R̂n(θ ∗) = 0.
",B.9 Proof of Proposition 8,[0],[0]
"Remark: Using the same proof shown as follows, we can show that Proposition 8 holds for any multilayer network architectures satisfying that for any set of parameters θ and any real numbers a, b ∈ R, there always exists a set of parameters θ̃ such that f(x; θ̃) = a(f(x;θ)− b) holds for all x.",B.9 Proof of Proposition 8,[0],[0]
"It is easy to check that both network architectures in Fig. 1 satisfy this condition.
",B.9 Proof of Proposition 8,[0],[0]
Proof: We first prove the “only if” part.,B.9 Proof of Proposition 8,[0],[0]
"The proof is trivial since, by definition `p(z) ≥ I{z ≥ 0}, then
R̂n(θ) = 1
n n∑ i=1",B.9 Proof of Proposition 8,[0],[0]
I{yi 6= sgn(f(xi;θ))},B.9 Proof of Proposition 8,[0],[0]
≤ 1 n n∑ i=1 I{yif(xi;θ) ≤ 0} ≤ 1 n,B.9 Proof of Proposition 8,[0],[0]
n∑ i=1,B.9 Proof of Proposition 8,[0],[0]
`p(−yif(xi;θ)),B.9 Proof of Proposition 8,[0],[0]
"= L̂n(θ; p).
",B.9 Proof of Proposition 8,[0],[0]
"Therefore, if minθ L̂n(θ; p) = 0 then minθ R̂n(θ) = 0.",B.9 Proof of Proposition 8,[0],[0]
"Next, we prove the “if” part.",B.9 Proof of Proposition 8,[0],[0]
"If minθ R̂n(θ) = 0, then there exists a set of parameter θ ∗ such that I{yi 6= sgn(f(x;θ∗))}",B.9 Proof of Proposition 8,[0],[0]
= 0 holds for all i ∈,B.9 Proof of Proposition 8,[0],[0]
[n].,B.9 Proof of Proposition 8,[0],[0]
This indicates that f(xi;θ∗) ≥ 0,B.9 Proof of Proposition 8,[0],[0]
"for all i : yi = 1 and f(xi;θ
∗)",B.9 Proof of Proposition 8,[0],[0]
< 0,B.9 Proof of Proposition 8,[0],[0]
for all i : yi = −1.,B.9 Proof of Proposition 8,[0],[0]
This means that there exists two real numbers c1 < c2 such that f(xi;θ ∗),B.9 Proof of Proposition 8,[0],[0]
>,B.9 Proof of Proposition 8,[0],[0]
c2 holds for all i : yi = 1 and f(xi;θ ∗),B.9 Proof of Proposition 8,[0],[0]
< c1 holds for all i : yi = −1.,B.9 Proof of Proposition 8,[0],[0]
"Now, we define a new network f(x; θ̃) = α(f(x;θ∗)",B.9 Proof of Proposition 8,[0],[0]
− c1+c22 ).,B.9 Proof of Proposition 8,[0],[0]
"Therefore, for this network f(x; θ̃), we have f(xi; θ̃) > α(c2",B.9 Proof of Proposition 8,[0],[0]
− c1)/2 holds for all i : yi = 1 and f(xi; θ̃) < −α(c2,B.9 Proof of Proposition 8,[0],[0]
− c1)/2 holds for all i : yi = −1.,B.9 Proof of Proposition 8,[0],[0]
"Since `p(z) = 0 iff z ≤ −z0, then by choosing α > 2z0c2−c1 , we have yif(xi; θ̃) > z0 holds for ∀i ∈",B.9 Proof of Proposition 8,[0],[0]
[n].,B.9 Proof of Proposition 8,[0],[0]
This means that L̂n(θ̃; p) = 0.,B.9 Proof of Proposition 8,[0],[0]
"Now we need to show that there exits a set of parameter θ̃ such that
f(x; θ̃) = α",B.9 Proof of Proposition 8,[0],[0]
"( f(x;θ∗)− c1 + c2
2
) .
",B.9 Proof of Proposition 8,[0],[0]
"Since the output of the neural network can be written as
f(x;θ) = a0 + ML∑",B.9 Proof of Proposition 8,[0],[0]
"j=1 ajσ(w > j Φ(x;θ) + bj),
where ML denotes the number of neurons in the last layer and Φ(xi;θ) denotes the outputs from the previous layers.",B.9 Proof of Proposition 8,[0],[0]
"Then by shifting a0 and scaling aj , we have
f(x; θ̃) = α",B.9 Proof of Proposition 8,[0],[0]
"( f(x;θ∗)− c1 + c2
2 )",B.9 Proof of Proposition 8,[0],[0]
= a∗0,B.9 Proof of Proposition 8,[0],[0]
"− α(c1 + c2)
2 + ML∑ j=1 αa∗jσ(w ∗>Φ(x;θ∗) + b∗j )
",B.9 Proof of Proposition 8,[0],[0]
= ã0 + ML∑,B.9 Proof of Proposition 8,[0],[0]
j=1 ãjσ(w ∗>Φ(x;θ∗),B.9 Proof of Proposition 8,[0],[0]
+ b∗j,B.9 Proof of Proposition 8,[0],[0]
").
",B.9 Proof of Proposition 8,[0],[0]
"Therefore, this means that there exists a set of parameters θ̃ such that L̂n(θ̃; p) = 0, i.e., minθ L̂n(θ; p) = 0.",B.9 Proof of Proposition 8,[0],[0]
"This means, the global minimum of the empirical loss L̂n(θ; p) is zero.",B.9 Proof of Proposition 8,[0],[0]
"Furthermore, since R̂n(θ) ≤ L̂n(θ; p) holds for all θ, then every global minimum of the empirical loss has zero training error.",B.9 Proof of Proposition 8,[0],[0]
"Proposition 21 Assume that the loss function is the logistic loss, i.e., `(z) = log2(1",B.10 Proof of Proposition 9,[0],[0]
+ e z).,B.10 Proof of Proposition 9,[0],[0]
Assume that assumptions 2-5 are satisfied.,B.10 Proof of Proposition 9,[0],[0]
Assume,B.10 Proof of Proposition 9,[0],[0]
"that samples in the dataset D = {(xi, yi)}ni=1, n",B.10 Proof of Proposition 9,[0],[0]
≥ 1 are independently drawn from the distribution PX×Y .,B.10 Proof of Proposition 9,[0],[0]
"Assume that the number of neurons M in the network fS satisfies M ≥ 2 max{ n∆r , r+, r−}, where ∆r = r−max{r+, r−}.",B.10 Proof of Proposition 9,[0],[0]
"If a set of real parameters θ∗ denotes a critical point of the empirical loss L̂n(θ), then θ ∗ is a saddle point.
",B.10 Proof of Proposition 9,[0],[0]
Proof: We first recall some notations defined in the paper.,B.10 Proof of Proposition 9,[0],[0]
"The output of the neural network is
f(x;θ) = fS(x;θS) + fD(x;θD),
where fS(x;θS) is the single layer neural network parameterized by θS , i.e.,
fS(x;θS)",B.10 Proof of Proposition 9,[0],[0]
"= a0 + M∑ j=1 ajσ ( w>j x ) ,
and fD(x;θD) is a deep neural network parameterized by θD.",B.10 Proof of Proposition 9,[0],[0]
"The empirical loss function is given by
L̂n(θ) = L̂n(θS ,θD) = 1
n n∑ i=1",B.10 Proof of Proposition 9,[0],[0]
"`(−yif(xi;θ)).
",B.10 Proof of Proposition 9,[0],[0]
"We assume that there exists a local minimum θ∗ = (θ∗S ,θ ∗ D).",B.10 Proof of Proposition 9,[0],[0]
"We next complete the proof by proving the following two claims:
Claim 6",B.10 Proof of Proposition 9,[0],[0]
If there exists j ∈,B.10 Proof of Proposition 9,[0],[0]
"[M ] such that a∗j = 0, then θ∗ is not a local minimum.
",B.10 Proof of Proposition 9,[0],[0]
Claim 7,B.10 Proof of Proposition 9,[0],[0]
If a∗j 6= 0 for all j ∈,B.10 Proof of Proposition 9,[0],[0]
"[M ], then θ∗ is not a local minimum.
",B.10 Proof of Proposition 9,[0],[0]
"Therefore, these two claims contradict with the assumption that θ∗ = (θ∗S ,θ ∗ D) is a local minimum.",B.10 Proof of Proposition 9,[0],[0]
"Therefore, every critical point is not a local minimum.",B.10 Proof of Proposition 9,[0],[0]
"In addition, it is very easy to show that every critical point is not a local maximum, since the loss function is strictly convex with respect to a0.",B.10 Proof of Proposition 9,[0],[0]
"Therefore, every critical point is a saddle point.",B.10 Proof of Proposition 9,[0],[0]
(a) Proof of Claim 6.,B.10 Proof of Proposition 9,[0],[0]
"In this part, we prove that if there exists j ∈",B.10 Proof of Proposition 9,[0],[0]
"[M ] such that a∗j = 0, then θ∗ is not a local minima.",B.10 Proof of Proposition 9,[0],[0]
"Without loss of generality, we assume that a∗1 = 0.",B.10 Proof of Proposition 9,[0],[0]
"Using the same analysis presented in the proof of Theorem 1, we have
n∑ i=1",B.10 Proof of Proposition 9,[0],[0]
`′(−yif(xi;θ))(−yi)σ′′,B.10 Proof of Proposition 9,[0],[0]
( w∗1 >xi ) xix >,B.10 Proof of Proposition 9,[0],[0]
"i = 0d×d.
",B.10 Proof of Proposition 9,[0],[0]
"By assumption that there exists a set of orthogonal basis E = {e1, ..., ed} in Rd and a subset U+ ⊆ E such that PX|Y (X ∈ Span(U1)|Y = 1) = 1 and by assumption that r = |U+ ∪ U−| > max{r+, r−} = max{|U+|, |U−|}, then the set U+\U− is not an empty set.",B.10 Proof of Proposition 9,[0],[0]
"It is easy to show that for any vector v ∈ U+\U−, PX×Y (v>X = 0|Y = 1) = 0.",B.10 Proof of Proposition 9,[0],[0]
We prove it by contradiction.,B.10 Proof of Proposition 9,[0],[0]
"If we assume p = PX×Y (v>X = 0|Y = 1) > 0, then for random vectors X1, ...,X|U+| independently drawn from the conditional distribution PX|Y=1,
PX|Y=1 |U+|⋃ i=1",B.10 Proof of Proposition 9,[0],[0]
{ v>Xi = 0 } ∣∣∣∣∣Y,B.10 Proof of Proposition 9,[0],[0]
= 1  = |U+|∏ i=1,B.10 Proof of Proposition 9,[0],[0]
"PX|Y=1 ( v>Xi = 0|Y = 1 ) = p|U+| > 0.
",B.10 Proof of Proposition 9,[0],[0]
"Furthermore, since X1, ...,X|U+| ∈ Span(U+), v>Xi = 0, i = 1, ..., |U+| and v ∈ U+, then the rank of the matrix ( X1, ...,X|U+| ) is at most |U+| − 1 and this indicates that the matrix is not a full rank matrix with probability p|U+| > 0.",B.10 Proof of Proposition 9,[0],[0]
This leads to the contradiction with the Assumption 2.,B.10 Proof of Proposition 9,[0],[0]
"Thus, with probability 1, v>xi 6= 0 for all i : yi = 1 and v>xi = 0 for all i : yi = −1.",B.10 Proof of Proposition 9,[0],[0]
Proof of Claim 7,B.10 Proof of Proposition 9,[0],[0]
:,B.10 Proof of Proposition 9,[0],[0]
Now we have proved that a∗j 6= 0 for all j ∈,B.10 Proof of Proposition 9,[0],[0]
[M ].,B.10 Proof of Proposition 9,[0],[0]
"Here, we define M0 = dM/2e.",B.10 Proof of Proposition 9,[0],[0]
"Since M0 ≥ max{r+, r−}, and max{r+, r−}+ min{r+, r−} ≥ r, then
2M0 ≥ 2 max{r+, r−} > 2r",B.10 Proof of Proposition 9,[0],[0]
− r+ − r− ≥ 2 min{r,B.10 Proof of Proposition 9,[0],[0]
"− r+, r − r−} , 2K.
Thus, there exists ai1 , ..., aiM0 , i1 < i2 < ...",B.10 Proof of Proposition 9,[0],[0]
"< iM0 such that
sgn(ai1) = ...",B.10 Proof of Proposition 9,[0],[0]
"= sgn(aiM0 ).
",B.10 Proof of Proposition 9,[0],[0]
"Without loss of generality, we assume that sgn(a1) = ...",B.10 Proof of Proposition 9,[0],[0]
= sgn(aM0) = +1.,B.10 Proof of Proposition 9,[0],[0]
Now we prove the claim 7.,B.10 Proof of Proposition 9,[0],[0]
"First, we consider the Hessian matrix H(w∗1, ...,w ∗ M0 ).",B.10 Proof of Proposition 9,[0],[0]
Since θ∗ is a local minima with R̂n(θ ∗),B.10 Proof of Proposition 9,[0],[0]
"> 0, then
F (u1, ...,uM0) = M0∑ j=1 M0∑ k=1",B.10 Proof of Proposition 9,[0],[0]
"u>j ∇2wj ,wk L̂n(θ ∗)uk ≥ 0
holds for any vectors u1, ...,uM0 ∈ Rd.",B.10 Proof of Proposition 9,[0],[0]
"Since
∇2wj L̂n(θ∗) = a∗j n∑ i=1",B.10 Proof of Proposition 9,[0],[0]
`′(−yif(xi;θ∗))(−yi)σ′′ ( w∗j >xi ) xix,B.10 Proof of Proposition 9,[0],[0]
>,B.10 Proof of Proposition 9,[0],[0]
"i
+ a∗j 2 n∑ i=1",B.10 Proof of Proposition 9,[0],[0]
`′′(−yif(xi;θ∗)),B.10 Proof of Proposition 9,[0],[0]
[ σ′ ( w∗j >xi )]2 xix >,B.10 Proof of Proposition 9,[0],[0]
"i ,
and
∇2wj ,wk L̂n(θ ∗; p) =",B.10 Proof of Proposition 9,[0],[0]
a∗ja ∗ k n∑ i=1,B.10 Proof of Proposition 9,[0],[0]
`′′(−yif(xi;θ∗)),B.10 Proof of Proposition 9,[0],[0]
[ σ′ ( w∗j >xi )],B.10 Proof of Proposition 9,[0],[0]
[ σ′ ( w∗k >xi )],B.10 Proof of Proposition 9,[0],[0]
"xix > i .
",B.10 Proof of Proposition 9,[0],[0]
"Thus, we have for any u1, ...,uM0 ∈ Rd,
F (u1, ...,uM0) = −2",B.10 Proof of Proposition 9,[0],[0]
n∑ i=1,B.10 Proof of Proposition 9,[0],[0]
`′(−yif(xi;θ∗))yi M0∑ j=1,B.10 Proof of Proposition 9,[0],[0]
"[ a∗jσ ′′ (w∗jxi) (u>j xi)2] 
+ 4 n∑ i=1",B.10 Proof of Proposition 9,[0],[0]
`′′(−yif(xi;θ∗)) M0∑ j=1 a∗jσ ′,B.10 Proof of Proposition 9,[0],[0]
( w∗j >xi )( u>j xi )2 .,B.10 Proof of Proposition 9,[0],[0]
"Now we find some coefficients α1, ..., αM0 , not all zero and vectors u1, ...,uM0 satisfying
M0∑ j=1 αjσ ′",B.10 Proof of Proposition 9,[0],[0]
"( w∗j >xi ) u>j xi = 0, ∀i ∈",B.10 Proof of Proposition 9,[0],[0]
"[n],
and ∀i : yi = −1 and ∀j ∈",B.10 Proof of Proposition 9,[0],[0]
"[M0], u>j xi = 0.
Since θ∗ is a local minima, then by Lemma 1, we have
n∑ i=1",B.10 Proof of Proposition 9,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi = 0d.
Consider the orthogonal vectors e1, ..., eK from the set of orthogonal basis e1, ..., ed satisfying that, with probability 1",B.10 Proof of Proposition 9,[0],[0]
", ∀j ∈ [K], ∀i : yi = −1, e>j xi = 0 and ∀i : yi = 1, e>j xi 6= 0.",B.10 Proof of Proposition 9,[0],[0]
"Then, considering the following set of linear equations
n∑ i=1",B.10 Proof of Proposition 9,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗1>xi) ( e>1 xi ) = 0, ..., n∑ i=1",B.10 Proof of Proposition 9,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗M0 >xi) ( e>1 xi ) = 0,
... n∑ i=1",B.10 Proof of Proposition 9,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗1>xi) ( e>Kxi ) = 0, ..., n∑ i=1",B.10 Proof of Proposition 9,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗M0 >xi) ( e>Kxi ) = 0.
",B.10 Proof of Proposition 9,[0],[0]
These equations can be rewritten in a matrix form σ′(w∗1,B.10 Proof of Proposition 9,[0],[0]
>x1) ( e>1 x1 ) ...,B.10 Proof of Proposition 9,[0],[0]
σ′(w∗1,B.10 Proof of Proposition 9,[0],[0]
>xn) ( e>1 xn ) ... ... ...,B.10 Proof of Proposition 9,[0],[0]
σ′(w∗M0 >x1) ( e>1 x1 ) ...,B.10 Proof of Proposition 9,[0],[0]
σ′(w∗M0 >xn) ( e>1 xn ) ... ... ...,B.10 Proof of Proposition 9,[0],[0]
σ′(w∗1,B.10 Proof of Proposition 9,[0],[0]
>x1),B.10 Proof of Proposition 9,[0],[0]
( e>Kx1 ) ... σ′(w∗1,B.10 Proof of Proposition 9,[0],[0]
>xn) ( e>Kxn ) ... ...,B.10 Proof of Proposition 9,[0],[0]
"...
σ′(w∗M0 >x1) ( e>Kx1 ) ...",B.10 Proof of Proposition 9,[0],[0]
"σ′(w∗M0 >xn) ( e>Kxn )  (KM0×n)︸ ︷︷ ︸
P
 `′(−y1f(x1;θ∗))y1 `′(−y2f(x2;θ∗))y2 ... ... ... ...
...",B.10 Proof of Proposition 9,[0],[0]
"`′(−ynf(x1;θ∗))yn  ︸ ︷︷ ︸
q
= 0n
or Pq = 0n.
",B.10 Proof of Proposition 9,[0],[0]
"Since M0K ≥ MK/2 ≥ n, then if rank(P )",B.10 Proof of Proposition 9,[0],[0]
"= n, we should have q = 0n and this indicates that `′(−yif(xi;θ∗))",B.10 Proof of Proposition 9,[0],[0]
= 0,B.10 Proof of Proposition 9,[0],[0]
for all i ∈,B.10 Proof of Proposition 9,[0],[0]
[n] and this contradicts with the fact that `′(z) =,B.10 Proof of Proposition 9,[0],[0]
"11+e−z > 0 for all z ∈ R. Therefore, rank(P )",B.10 Proof of Proposition 9,[0],[0]
"< n ≤ M0K. This means the raw vectors of the matrix P is linearly dependent and thus we have that there exists coefficients vectors (β11, ..., β1K), ..., (βM01, ..., βM0K), not all zero vectors, such that
K∑ s=1 M0∑ j=1 σ′(w∗j >",B.10 Proof of Proposition 9,[0],[0]
"xi)βjs(e > s xi) = 0, ∀i ∈",B.10 Proof of Proposition 9,[0],[0]
"[n],
or M0∑ j=1 a∗jσ ′(w∗j >xi)
( 1
a∗j K∑ s=1 βjses
)>",B.10 Proof of Proposition 9,[0],[0]
xi,B.10 Proof of Proposition 9,[0],[0]
"= 0, ∀i ∈",B.10 Proof of Proposition 9,[0],[0]
"[n],
Define uj = 1 a∗j
∑K s=1 βjses for j = 1, ...,M0, then we have
M0∑ j=1 a∗jσ ′(w∗j",B.10 Proof of Proposition 9,[0],[0]
>,B.10 Proof of Proposition 9,[0],[0]
xi)u,B.10 Proof of Proposition 9,[0],[0]
>,B.10 Proof of Proposition 9,[0],[0]
"j xi = 0, ∀i ∈",B.10 Proof of Proposition 9,[0],[0]
[n].,B.10 Proof of Proposition 9,[0],[0]
"(17)
Furthermore, since uj ∈ Span({e1, ..., eK}), and with probability 1, ∀i : yi = −1 and ∀j ∈ [K], e>j xi = 0, then we have that ∀j ∈",B.10 Proof of Proposition 9,[0],[0]
[M ] and ∀i : yi = −1: u>j xi = 0.,B.10 Proof of Proposition 9,[0],[0]
"Thus,
F (u1, ...,uM0) = −2 n∑ i=1",B.10 Proof of Proposition 9,[0],[0]
`′(−yif(xi;θ∗))yi M0∑ j=1,B.10 Proof of Proposition 9,[0],[0]
"[ a∗jσ ′′ (w∗jxi) (u>j xi)2]  by Eq. (17)
= −2",B.10 Proof of Proposition 9,[0],[0]
∑ i:yi=1 `′(−yif(xi;θ∗)),B.10 Proof of Proposition 9,[0],[0]
M0∑ j=1,B.10 Proof of Proposition 9,[0],[0]
[ a∗jσ ′′ (w∗jxi) (u>j xi)2]  ≥ 0.,B.10 Proof of Proposition 9,[0],[0]
"(18)
Since σ′′(z)",B.10 Proof of Proposition 9,[0],[0]
> 0,B.10 Proof of Proposition 9,[0],[0]
for all z ∈ R and a∗j > 0,B.10 Proof of Proposition 9,[0],[0]
for all j ∈,B.10 Proof of Proposition 9,[0],[0]
"[M0], then we have
`′(−yif(xi;θ∗))",B.10 Proof of Proposition 9,[0],[0]
M0∑ j=1,B.10 Proof of Proposition 9,[0],[0]
"[ a∗jσ ′′ (w∗jxi) (u>j xi)2] ≥ 0, ∀i : yi = 1 and this leads to F (u1, ...,uM0) ≤ 0.",B.10 Proof of Proposition 9,[0],[0]
Together with Eq.,B.10 Proof of Proposition 9,[0],[0]
"(18), we have
F (u1, ...,uM0) = 0
and thus
`′(−yif(xi;θ∗))",B.10 Proof of Proposition 9,[0],[0]
M0∑ j=1,B.10 Proof of Proposition 9,[0],[0]
"[ a∗jσ ′′ (w∗jxi) (u>j xi)2] = 0, ∀i : yi = 1. (19) Now we split the index {i ∈",B.10 Proof of Proposition 9,[0],[0]
"[n] : yi = 1} set into two disjoint subset C0, C1:
C0 = {i ∈",B.10 Proof of Proposition 9,[0],[0]
"[n] : yi = 1, and ∃j ∈",B.10 Proof of Proposition 9,[0],[0]
"[M0],u>j xi 6= 0}, C1 = {i ∈",B.10 Proof of Proposition 9,[0],[0]
[n] : yi = 1 and ∀j ∈,B.10 Proof of Proposition 9,[0],[0]
"[M0],u>j xi = 0}.
",B.10 Proof of Proposition 9,[0],[0]
"Clearly, for all i ∈ C0, by the fact that aj > 0 for all j ∈",B.10 Proof of Proposition 9,[0],[0]
[M0] and σ′′(z) > 0,B.10 Proof of Proposition 9,[0],[0]
"for all z ∈ R, we have
M0∑ j=1",B.10 Proof of Proposition 9,[0],[0]
"[ a∗jσ ′′ (w∗jxi) (u>j xi)2] > 0, and this leads to `′(−yif(xi;θ∗))",B.10 Proof of Proposition 9,[0],[0]
"= 0, ∀i ∈ C0, which contradict with the fact that `′(z) > 0",B.10 Proof of Proposition 9,[0],[0]
"for all z ∈ R. Therefore, C0 = ∅. Now we need to consider the index set C1.",B.10 Proof of Proposition 9,[0],[0]
"First, it is easy to show that with probability 1, |C1| < r+ ≤ M0.",B.10 Proof of Proposition 9,[0],[0]
"This is due to the fact that there exists a non-zero vector uj , such that u > j xi = 0 for all i ∈ C1 and that
uj ∈ Span({e1, ..., eK}).",B.10 Proof of Proposition 9,[0],[0]
"Therefore, u>j xi = ∑K s=1(u > j es)(x >",B.10 Proof of Proposition 9,[0],[0]
i es) = ∑r+ s=1(u >,B.10 Proof of Proposition 9,[0],[0]
j es)(x > i es) = 0 holds for all i ∈ C1.,B.10 Proof of Proposition 9,[0],[0]
"If |C1| ≥ r+, then with probability 1, the matrix e>1 x1 ...",B.10 Proof of Proposition 9,[0],[0]
e>r+x1... ... ...,B.10 Proof of Proposition 9,[0],[0]
e>1 xr+ ...,B.10 Proof of Proposition 9,[0],[0]
"e > r+xr+
 has the full rank equal to r+",B.10 Proof of Proposition 9,[0],[0]
and this makes u > j es = 0 for all s ∈,B.10 Proof of Proposition 9,[0],[0]
[k].,B.10 Proof of Proposition 9,[0],[0]
"This contradicts with the fact that uj ∈ Span({e1, ..., eK}) and uj is not a zero vector.",B.10 Proof of Proposition 9,[0],[0]
"Thus, |C1| < r+ ≤ M0.",B.10 Proof of Proposition 9,[0],[0]
"Now we consider
the function F , since ∀i ∈ C0 : `′(−yif(xi;θ∗))",B.10 Proof of Proposition 9,[0],[0]
"= 0, then for all u1, ...,uM0 ,
F (u1, ...,uM0) = −2",B.10 Proof of Proposition 9,[0],[0]
∑ i∈C1 `′(−yif(xi;θ∗)),B.10 Proof of Proposition 9,[0],[0]
M0∑ j=1,B.10 Proof of Proposition 9,[0],[0]
"[ a∗jσ ′′ (w∗jxi) (u>j xi)2] 
+ 4 ∑ i∈C1 `′′(−yif(xi;θ∗))",B.10 Proof of Proposition 9,[0],[0]
M0∑ j=1 a∗jσ ′,B.10 Proof of Proposition 9,[0],[0]
( w∗j >xi )( u>j xi )2,B.10 Proof of Proposition 9,[0],[0]
"Now we set uj = αje1, j = 1, ...,M0 for some scalar αj .",B.10 Proof of Proposition 9,[0],[0]
"Now we only need find α1, ..., αM0 such that
M0∑ j=1 αja ∗",B.10 Proof of Proposition 9,[0],[0]
jσ ′,B.10 Proof of Proposition 9,[0],[0]
"( w∗j >xi ) e>1 xi = 0, ∀i ∈ C1.
",B.10 Proof of Proposition 9,[0],[0]
"Since |C1| ≤M0 − 1 < M0, then there exists α∗1, ..., α∗M0 , not all zeros, such that
M0∑ j=1 α∗ja ∗",B.10 Proof of Proposition 9,[0],[0]
jσ ′,B.10 Proof of Proposition 9,[0],[0]
"( w∗j >xi ) e>1 xi = 0, ∀i ∈ C1.
",B.10 Proof of Proposition 9,[0],[0]
"Then by setting uj = α ∗ je1, we have
F (u1, ...,uM0) = −2",B.10 Proof of Proposition 9,[0],[0]
∑ i∈C1 `′(−yif(xi;θ∗)),B.10 Proof of Proposition 9,[0],[0]
M0∑ j=1 [ |α∗j,B.10 Proof of Proposition 9,[0],[0]
"|2a∗jσ′′ ( w∗jxi ) ( e>1 xi )2] ≥ 0. .
",B.10 Proof of Proposition 9,[0],[0]
"Similarly, since |α1|, ..., |αM0",B.10 Proof of Proposition 9,[0],[0]
"| are not all zeros, a∗j > 0",B.10 Proof of Proposition 9,[0],[0]
for all j ∈,B.10 Proof of Proposition 9,[0],[0]
"[M0], σ′′(z) > 0 for all z ∈ R and e>1 xi 6= 0 holds for all i with probability 1, then
`′(−yif(xi;θ∗))",B.10 Proof of Proposition 9,[0],[0]
"= 0, ∀i ∈ C1.
",B.10 Proof of Proposition 9,[0],[0]
"Therefore, this indicates that `′(−yif(xi;θ∗))",B.10 Proof of Proposition 9,[0],[0]
"= 0, ∀i : yi = 1.
",B.10 Proof of Proposition 9,[0],[0]
"Since `′(z) > 0 holds for all z ∈ R, then this leads to the contradiction.",B.10 Proof of Proposition 9,[0],[0]
"Therefore, θ∗ is not a local minima.",B.10 Proof of Proposition 9,[0],[0]
"Proposition 13 Assume that the loss function ` is the logistic loss, i.e., `(z) = log2(1 + e z).",B.11 Proof of Proposition 13,[0],[0]
Assume that the network architecture satisfies assumption 4.,B.11 Proof of Proposition 13,[0],[0]
Assume,B.11 Proof of Proposition 13,[0],[0]
"that samples in the dataset D = {(xi, yi)}ni=1, n",B.11 Proof of Proposition 13,[0],[0]
≥ 1 are independently drawn from a distribution satisfying assumption 6.,B.11 Proof of Proposition 13,[0],[0]
Assume that the single layer network fS has M ≥ 1 neurons and neurons σ in the network fS are twice differentiable and satisfy σ′(z),B.11 Proof of Proposition 13,[0],[0]
> 0,B.11 Proof of Proposition 13,[0],[0]
for all z ∈ R.,B.11 Proof of Proposition 13,[0],[0]
"If a set of real parameters θ∗ = (θ∗S ,θ∗D) denotes a local minimum of the loss function L̂n(θS ,θD; p), p ≥ 3, then R̂n(θ∗S ,θ∗D) = 0 holds with probability one.
",B.11 Proof of Proposition 13,[0],[0]
"Proof: We first prove that, if a set of real parameters θ∗ denotes a critical point, then θ∗ is a saddle point.",B.11 Proof of Proposition 13,[0],[0]
We prove it by contradiction.,B.11 Proof of Proposition 13,[0],[0]
We assume that θ∗ denotes a local minima.,B.11 Proof of Proposition 13,[0],[0]
"By assumption that θ∗ = (θ∗1,θ ∗ 2) is a local minima and by the necessary condition presented in Lemma 1, we have
n∑ i=1",B.11 Proof of Proposition 13,[0],[0]
"`′(−yif(xi;θ∗))yiσ′(w∗j>xi)xi = 0d.
",B.11 Proof of Proposition 13,[0],[0]
"Thus, for any w ∈ Rd, we have n∑ i=1",B.11 Proof of Proposition 13,[0],[0]
"`′(−yif(xi;θ∗))σ′(w∗j>xi)yi(w>xi) = 0.
",B.11 Proof of Proposition 13,[0],[0]
"Furthermore, for the cross entropy loss function, we have
`′(z) = 1
1 + exp(−z)",B.11 Proof of Proposition 13,[0],[0]
"> 0, ∀z ∈ R.
",B.11 Proof of Proposition 13,[0],[0]
"Thus, by assumption that σ′(z) > 0 for all z ∈ R and assumption that there exists a vector w ∈ Rd such that PX×Y (Y (w>X) > 0) = 1, then there exists a constant c such that for all samples in the dataset",B.11 Proof of Proposition 13,[0],[0]
i ∈,B.11 Proof of Proposition 13,[0],[0]
"[n],
yiw >xi > c > 0.
",B.11 Proof of Proposition 13,[0],[0]
"Thus, we have
0 = n∑ i=1",B.11 Proof of Proposition 13,[0],[0]
`′(−yif(xi;θ∗))σ′(w∗j>xi)yi(w>xi) ≥ c n∑ i=1,B.11 Proof of Proposition 13,[0],[0]
"`′(−yif(xi;θ∗))σ′(w∗j>xi) > 0,
and this leads to the contradiction.",B.11 Proof of Proposition 13,[0],[0]
"Proposition 10 Assume the dataset D = {(xi, yi)}ni=1 is consisted of both positive and negative samples.",B.12 Proof of Proposition 10,[0],[0]
Assume that f(x;θ) is a feedforward network parameterized by θ.,B.12 Proof of Proposition 10,[0],[0]
"Assume that the loss function is logistic, i.e., `(z) = log2 (1 + e
z).",B.12 Proof of Proposition 10,[0],[0]
"If the real parameters θ∗ denote a critical point of the empirical loss L̂n(θ ∗), then R̂n(θ ∗)",B.12 Proof of Proposition 10,[0],[0]
"> 0.
",B.12 Proof of Proposition 10,[0],[0]
Proof: We prove a general statement claiming that the proposition 10 holds for all differentiable loss functions satisfying `′(z),B.12 Proof of Proposition 10,[0],[0]
> 0,B.12 Proof of Proposition 10,[0],[0]
for all z ∈ R.,B.12 Proof of Proposition 10,[0],[0]
"We note that the following claim holds under the assumptions in Proposition 10.
",B.12 Proof of Proposition 10,[0],[0]
Claim 8,B.12 Proof of Proposition 10,[0],[0]
"If the loss function is differentiable and satisfies `′(z) > 0 for all z ∈ R, then R̂n(θ∗) > 0.
Assume that the multilayer neural network f(x;θ) has L ≥ 1 hidden layers, Ml ≥ 1 neurons in the l-th layer.",B.12 Proof of Proposition 10,[0],[0]
Now we let the vector θl contain all parameters in the first l ∈,B.12 Proof of Proposition 10,[0],[0]
[L] layers.,B.12 Proof of Proposition 10,[0],[0]
"Then the output of the neural network can be rewritten as
f(x; a0,θL) = a0 + ML∑",B.12 Proof of Proposition 10,[0],[0]
j=1 ajσ(w > j Φ(x;θL−1),B.12 Proof of Proposition 10,[0],[0]
"+ bj),
where Φ(x;θL−1)",B.12 Proof of Proposition 10,[0],[0]
=,B.12 Proof of Proposition 10,[0],[0]
"(Φ1(x;θL−1), ...,ΦML−1(x;θL−1)) denotes the outputs of the neurons in the layer L− 1.",B.12 Proof of Proposition 10,[0],[0]
"Then the empirical loss is defined as
L̂n(θ)",B.12 Proof of Proposition 10,[0],[0]
"= 1
n n∑ i=1",B.12 Proof of Proposition 10,[0],[0]
"`(−yif(xi;θ))
",B.12 Proof of Proposition 10,[0],[0]
"If the point θ∗ = (a∗0,θ ∗ L) denotes a critical point of the empirical loss function, then we should have, for ∀j ∈",B.12 Proof of Proposition 10,[0],[0]
"[ML],
∂L̂n(θ ∗)
∂a0 =
1
n n∑ i=1",B.12 Proof of Proposition 10,[0],[0]
"`′(−yif(xi;θ∗))(−yi) = 0, (20)
∂L̂n(θ ∗)
",B.12 Proof of Proposition 10,[0],[0]
"∂aj =
1
n n∑ i=1",B.12 Proof of Proposition 10,[0],[0]
"`′(−yif(xi;θ∗))(−yi)σ ( w∗j >Φ(xi;θ ∗ L−1) + bj ) = 0. (21)
",B.12 Proof of Proposition 10,[0],[0]
"In addition, by adding Equations (20) and (21), we have
0 = a∗0 ∂L̂n(θ
∗)
∂a0",B.12 Proof of Proposition 10,[0],[0]
+ ML∑,B.12 Proof of Proposition 10,[0],[0]
j=1 a∗j ∂L̂n(θ ∗),B.12 Proof of Proposition 10,[0],[0]
∂aj = 1 n n∑ i=1,B.12 Proof of Proposition 10,[0],[0]
`′(−yif(xi;θ∗))(−yi) a∗0 + ML∑ j=1 a∗jσ ( w∗j >Φ(xi;θ ∗ L−1) + bj ),B.12 Proof of Proposition 10,[0],[0]
"= 1
n n∑ i=1",B.12 Proof of Proposition 10,[0],[0]
`′(−yif(xi;θ∗))(−yi)f(xi;θ∗).,B.12 Proof of Proposition 10,[0],[0]
"(22)
",B.12 Proof of Proposition 10,[0],[0]
"This indicates that if θ∗ is a critical point of the empirical loss, then the following equation should hold,
1
n n∑ i=1",B.12 Proof of Proposition 10,[0],[0]
`′(−yif(xi;θ∗))yif(xi;θ∗) = 0.,B.12 Proof of Proposition 10,[0],[0]
"(23)
However, if the dataset contains both positive and the negative samples, `′(z)",B.12 Proof of Proposition 10,[0],[0]
> 0,B.12 Proof of Proposition 10,[0],[0]
"for all z ∈ R, then this means that if R̂n(θ ∗) = 0, then
1
n n∑ i=1",B.12 Proof of Proposition 10,[0],[0]
`′(−yif(xi;θ∗))yif(xi;θ∗),B.12 Proof of Proposition 10,[0],[0]
> 0.,B.12 Proof of Proposition 10,[0],[0]
"(24)
We note here that the assumption that the dataset contains both positive and the negative samples is to ensure that when R̂n(θ ∗) = 0, there is at least one sample in the dataset satisfying
yif(xi;θ ∗)",B.12 Proof of Proposition 10,[0],[0]
"> 0.
",B.12 Proof of Proposition 10,[0],[0]
"Therefore, we have the contradiction.",B.12 Proof of Proposition 10,[0],[0]
This indicates that R̂n(θ ∗),B.12 Proof of Proposition 10,[0],[0]
> 0.,B.12 Proof of Proposition 10,[0],[0]
"Proposition 11 Assume that assumptions 1, 4 and 5 are satisfied.",B.13 Proof of Proposition 11,[0],[0]
"For any feedforward architecture fD(x;θD), every local minimum θ ∗ = (θ∗S ,θ ∗ D) of the empirical loss function L̂n(θS ,θD; p), p ≥ 6 satisfies R̂n(θ ∗)",B.13 Proof of Proposition 11,[0],[0]
= 0,B.13 Proof of Proposition 11,[0],[0]
"only if the matrix ∑n i=1 λiyixix > i is neither positive nor negative definite for all
sequences {λi ≥ 0}ni=1",B.13 Proof of Proposition 11,[0],[0]
satisfying ∑ i:yi=1 λi = ∑ i:yi=−1 λi > 0 and ‖ ∑n i=1,B.13 Proof of Proposition 11,[0],[0]
"λiyixi‖2 = 0.
",B.13 Proof of Proposition 11,[0],[0]
Proof: We prove Proposition 11 by proving the following claim.,B.13 Proof of Proposition 11,[0],[0]
Claim 9,B.13 Proof of Proposition 11,[0],[0]
If there exists a sequence {λi ≥ 0}ni=1 satisfying ∑ i:yi=1 λi = ∑ i:yi=−1 λi > 0 and ‖ ∑n i=1,B.13 Proof of Proposition 11,[0],[0]
"λiyixi‖2 =
0 such that the matrix ∑n
i=1",B.13 Proof of Proposition 11,[0],[0]
λiyixix,B.13 Proof of Proposition 11,[0],[0]
"> i is positive or negative positive definite, then there exists a feed-
forward neural architecture fD",B.13 Proof of Proposition 11,[0],[0]
"such that the empirical loss function L̂n(θS ,θD; p), p ≥ 6 has a local minimum with a non-zero training error.
",B.13 Proof of Proposition 11,[0],[0]
"Proof: Let D = {(xi, yi)}ni=1 denote a dataset consisting of n samples.",B.13 Proof of Proposition 11,[0],[0]
"We rewrite the sample x as x = ( x(1), ..., x(d) ) .",B.13 Proof of Proposition 11,[0],[0]
"Consider the following network,
f(x;θ) = fS(x;θS) + fD(x;θD),
where
fS(x;θS)",B.13 Proof of Proposition 11,[0],[0]
= a0 + M∑ j=1,B.13 Proof of Proposition 11,[0],[0]
"ajσ(w > j xi + bj),
and the multilayer network is defined as follows,
fD(x;θD) = fD(x; θ1, ..., θd) = n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
µi d∏,B.13 Proof of Proposition 11,[0],[0]
k=1 1 { x(k) ∈,B.13 Proof of Proposition 11,[0],[0]
"[ x (k) i − θk, x (k) i + θk ]} .",B.13 Proof of Proposition 11,[0],[0]
"(25)
We note here that µ1, ..., µn are not parameters and later we will show that this function can be implemented by a multilayer network consisted of threshold units.",B.13 Proof of Proposition 11,[0],[0]
"A useful property of the function fD(x;θD) is that if all parameters θis are positive and sufficiently smalls, then for each sample (xi, yi) in the dataset,
fD(xi;θD)",B.13 Proof of Proposition 11,[0],[0]
"= µi.
",B.13 Proof of Proposition 11,[0],[0]
"Furthermore, if we slightly perturb all parameters, the output of the function fD on all samples remain the same.",B.13 Proof of Proposition 11,[0],[0]
"In the proof, we use these two properties to construct the local minimum with a non-zero training error.
",B.13 Proof of Proposition 11,[0],[0]
"By assumption, there exists a sequence {λi ≥ 0}ni=1 satisfying ∑ i:yi=1 λi = ∑ i:yi=−1 λi > 0 and
‖∑ni=1 λiyixi‖2 = 0 such that the matrix ∑ni=1 λiyixix",B.13 Proof of Proposition 11,[0],[0]
>i is positive or negative positive definite.,B.13 Proof of Proposition 11,[0],[0]
"Without loss of generality, we assume that the matrix is positive definite.",B.13 Proof of Proposition 11,[0],[0]
Now we construct a local minimum θ∗. Let a∗0 = a ∗ 1 = ...,B.13 Proof of Proposition 11,[0],[0]
"= a ∗ M = −1, w∗1 = ...",B.13 Proof of Proposition 11,[0],[0]
= w∗M = 0d and b∗1 = ...,B.13 Proof of Proposition 11,[0],[0]
= b∗M = 0.,B.13 Proof of Proposition 11,[0],[0]
"Now we set θ∗1, ..., θ ∗ d to be positive and sufficiently small such that for two different samples in the dataset, e.g.,",B.13 Proof of Proposition 11,[0],[0]
"xi 6= xj , the following equations holds,
d∏ k=1 1",B.13 Proof of Proposition 11,[0],[0]
{,B.13 Proof of Proposition 11,[0],[0]
x (k) j ∈,B.13 Proof of Proposition 11,[0],[0]
"[ x (k) i − 2θ∗k, x (k) i + 2θ ∗",B.13 Proof of Proposition 11,[0],[0]
"k ]} = 0, d∏",B.13 Proof of Proposition 11,[0],[0]
k=1 1 { x (k) i ∈,B.13 Proof of Proposition 11,[0],[0]
"[ x (k) j − 2θ∗k, x (k) j + 2θ ∗",B.13 Proof of Proposition 11,[0],[0]
"k ]} = 0.
",B.13 Proof of Proposition 11,[0],[0]
"Now we choose µ1, ..., µn as follows.",B.13 Proof of Proposition 11,[0],[0]
"The output of the neural network on sample xi in the dataset is f(xi;θ
∗) = µi −Mσ(0).",B.13 Proof of Proposition 11,[0],[0]
"We need to choose µ1, ..., µn to satisfy all conditions shown as follows:
(1) There exists i ∈",B.13 Proof of Proposition 11,[0],[0]
[n] such that yi(µi −Mσ(0)),B.13 Proof of Proposition 11,[0],[0]
"< 0.
(2) For all i : yi = 1 and all k : yk = −1,
`′(−yi(µi −Mσ(0)))∑ j:j=1 ` ′(−yi(µi −Mσ(0)))",B.13 Proof of Proposition 11,[0],[0]
"= λi∑ j:j=1 λj , `′(−yk(µk −Mσ(0)))∑ j:j=−1 ` ′(−yi(µi −Mσ(0)))",B.13 Proof of Proposition 11,[0],[0]
"= λk∑ j:j=−1 λj ,
and ∑ j:j=1 `′(−yi(µi −Mσ(0)))",B.13 Proof of Proposition 11,[0],[0]
= ∑,B.13 Proof of Proposition 11,[0],[0]
"j:j=−1 `′(−yi(µi −Mσ(0))).
",B.13 Proof of Proposition 11,[0],[0]
Now we start from the largest element in the sequence {λi}ni=1.,B.13 Proof of Proposition 11,[0],[0]
"Since ∑n
i=1 λi > 0, the define the index imax as the index of the largest element, i.e.,
imax = arg max i λi.
Let λmax = λimax .",B.13 Proof of Proposition 11,[0],[0]
"Now we choose µimax such that
yimax(µimax −Mσ(0))",B.13 Proof of Proposition 11,[0],[0]
"= −1.
",B.13 Proof of Proposition 11,[0],[0]
"Thus, the index imax satisfy the first condition.",B.13 Proof of Proposition 11,[0],[0]
"Then for i 6= imax, we choose µi such that
`′(−yi(µi −Mσ(0)))",B.13 Proof of Proposition 11,[0],[0]
= λi λmax `(−yimax(µimax −Mσ(0))),B.13 Proof of Proposition 11,[0],[0]
= λi λmax `′(1) ≤,B.13 Proof of Proposition 11,[0],[0]
`′(1).,B.13 Proof of Proposition 11,[0],[0]
"(26)
We note here that for each",B.13 Proof of Proposition 11,[0],[0]
i ∈,B.13 Proof of Proposition 11,[0],[0]
"[n], there always exists a µi solving the above equation.",B.13 Proof of Proposition 11,[0],[0]
"This can be seen by the fact that `′ is continuous, `′p(z) ≥ 0 and `′p(z) = 0 iff z ≤ −z0.",B.13 Proof of Proposition 11,[0],[0]
"This indicates that for ∀z > −z0, `′p(z) > 0, i.e., `′(1) > 0 and that `′(−z0) = 0.",B.13 Proof of Proposition 11,[0],[0]
"Since `′(z) is continuous, then for ∀r ∈",B.13 Proof of Proposition 11,[0],[0]
"[0, `′(1)], there always exists z ∈ R such that `′(z) = r, which further indicates that for ∀i ∈",B.13 Proof of Proposition 11,[0],[0]
"[n], there always exists µi ∈ R solving the Equation (37).",B.13 Proof of Proposition 11,[0],[0]
"Under this construction, it is easy to show that the second condition is satisfied as well.",B.13 Proof of Proposition 11,[0],[0]
Now we only need to show that θ∗ is local minimum.,B.13 Proof of Proposition 11,[0],[0]
We first show that θ∗ is a critical point of the empirical loss function.,B.13 Proof of Proposition 11,[0],[0]
"Since for ∀j ∈ [M ],
∂L̂n(θ ∗)
",B.13 Proof of Proposition 11,[0],[0]
∂aj = n∑ i=1,B.13 Proof of Proposition 11,[0],[0]
"`′(−yi(µi −Mσ(0)))(−yi)σ(0)
= σ(0) n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
λi λmax `′(1)(−yi) =,B.13 Proof of Proposition 11,[0],[0]
"− σ(0)`′(1) λmax n∑ i=1 yiλi
= 0 by ∑ i:yi=1 λi = ∑ i:yi=−1 λi
∇wj L̂n(θ∗) = n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
"`′(−yi(µi −Mσ(0)))(−yi)σ′(0)xi
= −σ′(0) n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
λi λmax `′(1)yixi = − σ′(0)`′(1) λmax n∑ i=1,B.13 Proof of Proposition 11,[0],[0]
"λiyixi
= 0d by ∥∥∥∥∥ n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
"λiyixi ∥∥∥∥∥ 2 = 0
and ∂L̂n(θ ∗)
",B.13 Proof of Proposition 11,[0],[0]
∂a0 = n∑ i=1,B.13 Proof of Proposition 11,[0],[0]
`′(−yi(µi −Mσ(0)))(−yi) =,B.13 Proof of Proposition 11,[0],[0]
− `′(1) λmax n∑ i=1,B.13 Proof of Proposition 11,[0],[0]
"yiλi = 0.
",B.13 Proof of Proposition 11,[0],[0]
"In addition, we have stated earlier, if we slightly perturb the parameter θ∗k in the interval",B.13 Proof of Proposition 11,[0],[0]
"[θ ∗ k/2, 3θ ∗ k/2], the output of the function fD(xi;θD) does not change for all i ∈",B.13 Proof of Proposition 11,[0],[0]
"[n], then θ∗ is a critical point.",B.13 Proof of Proposition 11,[0],[0]
Now we show that θ∗ is local minimum.,B.13 Proof of Proposition 11,[0],[0]
"Consider any perturbation ∆a1, ...,∆aM : |∆aj | < 12 for all j ∈",B.13 Proof of Proposition 11,[0],[0]
"[M ], ∆w1, ...,∆wM ∈ Rd, ∆a0 ∈ R, ∆θk :",B.13 Proof of Proposition 11,[0],[0]
|∆θk| ≤ θk/2 for all k ∈,B.13 Proof of Proposition 11,[0],[0]
[n].,B.13 Proof of Proposition 11,[0],[0]
"Define
θ̃ = (a∗0 + ∆a0, ..., a ∗ M + ∆aM ,w ∗ 1 + ∆w1, ...,w ∗ M + ∆wM , θ ∗ 1 + ∆θ ∗ 1, ..., θ ∗ d + ∆θ ∗ d).
",B.13 Proof of Proposition 11,[0],[0]
"Then
n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
`(−yif(xi; θ̃))− n∑ i=1,B.13 Proof of Proposition 11,[0],[0]
`(−yif(xi;θ∗)) = n∑ i=1,B.13 Proof of Proposition 11,[0],[0]
[ `(−yif(xi; θ̃))− `(−yif(xi;θ∗)) ],B.13 Proof of Proposition 11,[0],[0]
"≥
n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
"`′(−yif(xi;θ∗))(−yi)[f(xi; θ̃)− f(xi;θ∗)].
",B.13 Proof of Proposition 11,[0],[0]
"Since for each sample xi in the dataset,
f(xi; θ̃)− f(xi;θ∗)",B.13 Proof of Proposition 11,[0],[0]
= ∆a0 + M∑ j=1 (a∗j + ∆aj)σ(∆w > j xi) +,B.13 Proof of Proposition 11,[0],[0]
µi,B.13 Proof of Proposition 11,[0],[0]
"− µi
= ∆a0 + M∑ j=1 (a∗j + ∆aj)σ(∆w > j xi),
then
n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
`(−yif(xi; θ̃))− n∑ i=1,B.13 Proof of Proposition 11,[0],[0]
"`(−yif(xi;θ∗))
≥ n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
"`′(−yif(xi;θ∗))(−yi)[f(xi; θ̃)− f(xi;θ∗)]
= n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
"`′(−yi(µi −Mσ(0)))(−yi)  M∑ j=1 (a∗j + ∆aj)σ ( ∆w>j xi ) + ∆a0  =
n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
"λi` ′(1) λmax (−yi)  M∑ j=1 (a∗j + ∆aj)σ ( ∆w>j xi ) = `′(1)
λmax M∑ j=1 −(a∗j",B.13 Proof of Proposition 11,[0],[0]
+ ∆aj),B.13 Proof of Proposition 11,[0],[0]
"[ n∑ i=1 λiyiσ ( ∆w>j xi )] .
",B.13 Proof of Proposition 11,[0],[0]
"Now we define the following function G : Rd → R,
G(u) = n∑ i=1 λiyiσ ( u>xi ) .
",B.13 Proof of Proposition 11,[0],[0]
"Now we consider the gradient of the function G with respect to the vector u at the point 0d,
∇uG(0d) = n∑ i=1 λiyiσ ′",B.13 Proof of Proposition 11,[0],[0]
(0)xi = 0d by ∥∥∥∥∥ n∑ i=1,B.13 Proof of Proposition 11,[0],[0]
"λiyixi ∥∥∥∥∥ 2 = 0.
",B.13 Proof of Proposition 11,[0],[0]
"Furthermore, the Hessian matrix ∇2uG(0d) satisfies
∇2uG(0d) = n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
λiyiσ ′′ (0)xix >,B.13 Proof of Proposition 11,[0],[0]
i = σ ′′ (0) n∑ i=1,B.13 Proof of Proposition 11,[0],[0]
λiyixix >,B.13 Proof of Proposition 11,[0],[0]
"i 0,
then the function G(u)",B.13 Proof of Proposition 11,[0],[0]
=,B.13 Proof of Proposition 11,[0],[0]
∑n i=1 λiyiσ ( u>xi ) has a local minima at u = 0d.,B.13 Proof of Proposition 11,[0],[0]
"This indicates that there
exists ε > 0 such that for all (∆w1, ...,∆wM ) : √∑M
j=1 ‖∆wj‖22 ≤ ε, n∑ i=1 λiyiσ ( ∆w>j xi ) ≥ n∑ i=1 λiyiσ (0) = 0,
where the equality holds by the fact that ∑n
i=1 yiλi = 1.",B.13 Proof of Proposition 11,[0],[0]
"In addition, since a ∗ j = −1, |∆aj | < 12 , then
for all ∆wj : ‖∆wj‖2 ≤ ε and ∆bj ∈ R, n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
`(−yif(xi; θ̃))− n∑ i=1,B.13 Proof of Proposition 11,[0],[0]
`(−yif(xi;θ∗)),B.13 Proof of Proposition 11,[0],[0]
"≥ 0.
",B.13 Proof of Proposition 11,[0],[0]
"Thus, θ∗ is a local minima of the empirical loss function with f(xi;θ ∗) = µi −Mσ(0).",B.13 Proof of Proposition 11,[0],[0]
Since there exists a µimax such that yimax(µimax −Mσ(0)),B.13 Proof of Proposition 11,[0],[0]
"= 1, then this means that the neural network makes an incorrect prediction on the sample ximax .",B.13 Proof of Proposition 11,[0],[0]
"This indicates that this local minimum has a non-zero training error.
",B.13 Proof of Proposition 11,[0],[0]
"Finally, we present the way we construct the neural network fD. Since
fD(x;θD) = fD(x; θ1, ..., θd) = n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
µi d∏,B.13 Proof of Proposition 11,[0],[0]
k=1 1 { x(k) ∈,B.13 Proof of Proposition 11,[0],[0]
"[ x (k) i − θk, x (k) i + θk ]} .
",B.13 Proof of Proposition 11,[0],[0]
"Let σth denote the threshold unit, where σth(z) = 1 if z ≥ 0 and σth(z) = 0, otherwise.",B.13 Proof of Proposition 11,[0],[0]
"Therefore, the indicator function can be represented as follows:
1 { x(k) ∈",B.13 Proof of Proposition 11,[0],[0]
"[ x
(k) i − θk, x (k) i + θk",B.13 Proof of Proposition 11,[0],[0]
]} = σth ( x(k),B.13 Proof of Proposition 11,[0],[0]
− x(k)i + θk ),B.13 Proof of Proposition 11,[0],[0]
− σth ( x(k) − x(k)i,B.13 Proof of Proposition 11,[0],[0]
− θk ),B.13 Proof of Proposition 11,[0],[0]
"Therefore,
d∏ k=1 1 { x(k) ∈",B.13 Proof of Proposition 11,[0],[0]
"[ x (k) i − θk, x (k) i + θk",B.13 Proof of Proposition 11,[0],[0]
"]} = σth ( d∑
k=1
[ σth ( x(k) − x(k)i + θk )",B.13 Proof of Proposition 11,[0],[0]
− σth ( x(k) − x(k)i,B.13 Proof of Proposition 11,[0],[0]
− θk )],B.13 Proof of Proposition 11,[0],[0]
"− d+ 1
2
)
Therefore, we have
fD(x;θD) = n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
"µiσth
( d∑
k=1
[ σth ( x(k)",B.13 Proof of Proposition 11,[0],[0]
− x(k)i + θk ),B.13 Proof of Proposition 11,[0],[0]
− σth ( x(k) − x(k)i,B.13 Proof of Proposition 11,[0],[0]
− θk )],B.13 Proof of Proposition 11,[0],[0]
"− d+ 1
2
) .
",B.13 Proof of Proposition 11,[0],[0]
"It is very easy to see that this is a two layer network consisted of threshold units.
",B.13 Proof of Proposition 11,[0],[0]
"Furthermore, we note here that, in the proof shown above, we assume the only parameters in the network fD are θ1, ...,θd.",B.13 Proof of Proposition 11,[0],[0]
"In fact, we can prove a more general statement where the fD is of the form
fD(x;θD) = n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
"µiσth
( d∑
k=1
[ aikσth ( x(k) + uik ) + bikσth ( x(k) + vik )]",B.13 Proof of Proposition 11,[0],[0]
"+ ci ) ,
where aik, bik, uik, vik, ci, i ∈",B.13 Proof of Proposition 11,[0],[0]
"[n], k ∈",B.13 Proof of Proposition 11,[0],[0]
[d] are all parameters.,B.13 Proof of Proposition 11,[0],[0]
"We can show that the neural network
fD(x;θD) = n∑ i=1",B.13 Proof of Proposition 11,[0],[0]
"µiσth
( d∑
k=1
[ σth ( x(k)",B.13 Proof of Proposition 11,[0],[0]
− x(k)i + θk ),B.13 Proof of Proposition 11,[0],[0]
− σth ( x(k) − x(k)i,B.13 Proof of Proposition 11,[0],[0]
− θk )],B.13 Proof of Proposition 11,[0],[0]
"− d+ 1
2
) ,
denotes a local minimum, since any slight perturbations on parameters aik, bik, uik, vik, ci, i ∈",B.13 Proof of Proposition 11,[0],[0]
"[n], k ∈",B.13 Proof of Proposition 11,[0],[0]
[d] do not change the output of the neural network on the samples in the dataset D.,B.13 Proof of Proposition 11,[0],[0]
"In this subsection, we present two examples to show that if either assumption 2 or 3 is not satisfied, even if the other conditions in Theorem 1 are satisfied, Theorem 1 does not hold.
",B.14 Proof of Example 5,[0],[0]
"Example 5 Assume that the distribution PX×Y satisfies that PY (Y = 1) = PY (Y = −1), PX|Y (X = (1, 0)|Y = 1) = PX|Y (X = (−1, 0)|Y = 1) = 0.5 and PX|Y (X = (0, 0)|Y = −1).",B.14 Proof of Example 5,[0],[0]
"Assume that samples in the dataset D = {(xi, yi)}2ni=1 are independently drawn from the distribution PX×Y .",B.14 Proof of Example 5,[0],[0]
"Assume that the network fS has M ≥ 1 neurons and neurons in fS satisfy the condition that σ is analytic and has a positive second order derivative on R. There exists a feedforward network fD such that the empirical loss L̂n(θS ,θD) has a local minimum with non-zero training error with a probability at least Ω(1/n 2).
",B.14 Proof of Example 5,[0],[0]
"Remark: This is a counterexample where Theorem 1 does not hold, when Assumption 3 is satisfied and Assumption 2 is not satisfied.",B.14 Proof of Example 5,[0],[0]
This distribution can be viewed in the following way.,B.14 Proof of Example 5,[0],[0]
"The positive data samples are located on the linear span of the set {(1, 0)}, the negative data samples locate on the linear span of the set {(0, 1)} and all samples are located on the linear span of the set {(1, 0), (0, 1)}.",B.14 Proof of Example 5,[0],[0]
"Therefore, r = 2 > max{r+, r−} = 1.",B.14 Proof of Example 5,[0],[0]
This means that Assumption 3 is satisfied.,B.14 Proof of Example 5,[0],[0]
"In addition, it is easy to check that Assumption 2 is not satisfied, since the matrix (0, 0) has rank zero and thus does not have a full rank.",B.14 Proof of Example 5,[0],[0]
"This means that our main results may not hold when the assumption 2 is not satisfied.
",B.14 Proof of Example 5,[0],[0]
"Proof: Let n1, n0, n−1 denote the number of samples at the point (1, 0), (0, 0), (−1, 0), respectively.",B.14 Proof of Example 5,[0],[0]
It is easy to see that the event that n1 =,B.14 Proof of Example 5,[0],[0]
n−1 > 0 and n0 > 0,B.14 Proof of Example 5,[0],[0]
"happens with probability at least Ω(1/n
2).",B.14 Proof of Example 5,[0],[0]
"We note that this is not a tight bounded, however, we just need to show that this happens with a positive probability.",B.14 Proof of Example 5,[0],[0]
Now we consider the optimization problem under the dataset where n1 =,B.14 Proof of Example 5,[0],[0]
n−1 > 0 and n0 > 0.,B.14 Proof of Example 5,[0],[0]
"We first set the feedforward network fD(x;θD) to constant, i.e., fD(x;θD) ≡ 0",B.14 Proof of Example 5,[0],[0]
for x ∈ R2.,B.14 Proof of Example 5,[0],[0]
"Now the whole network becomes a single layer network,
f(x;θ) = a0 + M∑ j=1 ajσ ( w>j x ) .
",B.14 Proof of Example 5,[0],[0]
Let a∗1 = ...,B.14 Proof of Example 5,[0],[0]
= a ∗ M = −1 and w∗1 = ... = w∗M = 02.,B.14 Proof of Example 5,[0],[0]
"Therefore, we have f(x;θ∗)",B.14 Proof of Example 5,[0],[0]
= a∗0 −Mσ(0).,B.14 Proof of Example 5,[0],[0]
"Let a∗0 be the global optimizer of the following convex optimization problem.
",B.14 Proof of Example 5,[0],[0]
min a 2n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`p(−yi(a−Mσ(0))).
",B.14 Proof of Example 5,[0],[0]
"Thus, we have n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi) = 0, (27)
and this indicates that∑ i:yi=1",B.14 Proof of Example 5,[0],[0]
`′p(−(a∗0 −Mσ(0))),B.14 Proof of Example 5,[0],[0]
= ∑,B.14 Proof of Example 5,[0],[0]
i:yi=−1 `′p(a ∗ 0 −Mσ(0)) or `′p(−a∗0 +Mσ(0))n+ =,B.14 Proof of Example 5,[0],[0]
"`′p(a∗0 −Mσ(0))n−.
(28)
",B.14 Proof of Example 5,[0],[0]
"In addition, since for ∀j ∈ [M ],
∂L̂n(θ ∗)
",B.14 Proof of Example 5,[0],[0]
∂aj = 2n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)σ(0) = 0, by Equation (27),
∇wj L̂n(θ∗) =",B.14 Proof of Example 5,[0],[0]
2n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)σ′(0)xi = 02, by ∑ i:yi=1 xi",B.14 Proof of Example 5,[0],[0]
= ∑,B.14 Proof of Example 5,[0],[0]
i:,B.14 Proof of Example 5,[0],[0]
"yi=−1 xi = 02,
and ∂L̂n(θ ∗)
",B.14 Proof of Example 5,[0],[0]
∂a0 = n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi) = 0,
then θ∗ is a critical point.",B.14 Proof of Example 5,[0],[0]
"Next we show that θ∗ = (a∗0, ..., a ∗ M ,w ∗ 1, ...,w ∗ M ) is a local minima.",B.14 Proof of Example 5,[0],[0]
"Consider any perturbation ∆a1, ...,∆aM : |∆aj | < 12 for all j ∈",B.14 Proof of Example 5,[0],[0]
"[M ], ∆w1, ...,∆wM ∈ R2 and ∆a0 ∈ R. Define
θ̃ = (a∗0 + ∆a0, ..., a ∗ M + ∆aM ,w ∗ 1 + ∆w1, ...,w ∗ M + ∆wM ).
",B.14 Proof of Example 5,[0],[0]
"Then
n∑ i=1",B.14 Proof of Example 5,[0],[0]
`p(−yif(xi; θ̃))− n∑ i=1,B.14 Proof of Example 5,[0],[0]
`p(−yif(xi;θ∗)),B.14 Proof of Example 5,[0],[0]
= n∑ i=1,B.14 Proof of Example 5,[0],[0]
[ `p(−yif(xi; θ̃))− `p(−yif(xi;θ∗)) ],B.14 Proof of Example 5,[0],[0]
"≥
n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)[f(xi; θ̃)− f(xi;θ∗)]
= n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)[f(xi; θ̃)− a∗0 +Mσ(0)]
= n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃),
where the inequality follows from the convexity of the loss function `p(z), the second equality follows from the fact that f(x;θ∗) ≡",B.14 Proof of Example 5,[0],[0]
a∗0 − Mσ(0) and the third equality follows from Equation (28).,B.14 Proof of Example 5,[0],[0]
"In addition, we have
n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃)
= n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)  M∑ j=1 (a∗j + ∆aj)σ ( ∆w>j xi ) + ∆a0  =
n∑ i=1",B.14 Proof of Example 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))(−yi)  M∑ j=1 (a∗j + ∆aj)σ ( ∆w>j xi ) by Eq.,B.14 Proof of Example 5,[0],[0]
"(28) =
M∑ j=1 −(a∗j + ∆aj)",B.14 Proof of Example 5,[0],[0]
[ n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w>j xi )]
= M∑ j=1 −(a∗j + ∆aj)",B.14 Proof of Example 5,[0],[0]
[ n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w (1) j x (1) i )] by x (2) i = 0,∀i ∈",B.14 Proof of Example 5,[0],[0]
"[n].
Now we define the following function G : R→ R,
G(u)",B.14 Proof of Example 5,[0],[0]
= n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ ( ux (1) i ) .
",B.14 Proof of Example 5,[0],[0]
"Now we consider the gradient of the function G with respect to the variable u at the point u = 0,
∇uG(0) = n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ′ (0)x(1)i = 0.
",B.14 Proof of Example 5,[0],[0]
"Furthermore, the second order derivative ∇2uG(0) satisfies
∇2uG(0) = n∑ i=1",B.14 Proof of Example 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))yiσ′′ (0) ( x (1) i )2 = σ′′ (0) n∑ i=1,B.14 Proof of Example 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))yi ( x (1) i )2 = σ′′(0)  1 n+ ∑ i:yi=1 ( x (1) i )2 − 1 n− ∑ i:,B.14 Proof of Example 5,[0],[0]
yi=−1 ( x (1),B.14 Proof of Example 5,[0],[0]
"i
)2 > 0, then the function G(u)",B.14 Proof of Example 5,[0],[0]
=,B.14 Proof of Example 5,[0],[0]
∑n i=1,B.14 Proof of Example 5,[0],[0]
`p(−yi(a∗0 −Mσ(0)))yiσ ( ux (1) i ) has a local minima at u = 0.,B.14 Proof of Example 5,[0],[0]
"This indicates that there exists ε > 0 such that for all ∆w : ‖∆w‖2 ≤ ε, n∑ i=1",B.14 Proof of Example 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w>xi ) ≥ n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`p(−yi(a∗0 −Mσ(0)))yiσ (0) = 0.
",B.14 Proof of Example 5,[0],[0]
"In addition, since a∗j = −1, |∆aj | < 12 , then for all ∆wj : ‖∆wj‖2 ≤ ε, n∑ i=1",B.14 Proof of Example 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃) = M∑ j=1 −(a∗j + ∆aj),B.14 Proof of Example 5,[0],[0]
[ n∑ i=1,B.14 Proof of Example 5,[0],[0]
`p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w>j xi )],B.14 Proof of Example 5,[0],[0]
"≥ 0.
",B.14 Proof of Example 5,[0],[0]
"Therefore, we have n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃) ≥ 0, and this indicates that n∑ i=1",B.14 Proof of Example 5,[0],[0]
`p(−yif(xi; θ̃))− n∑ i=1,B.14 Proof of Example 5,[0],[0]
`p(−yif(xi;θ∗)),B.14 Proof of Example 5,[0],[0]
≥ 0.,B.14 Proof of Example 5,[0],[0]
"Thus, θ∗ is a local minima with f(x;θ∗)",B.14 Proof of Example 5,[0],[0]
= a∗0 −Mσ(0) = constant.,B.14 Proof of Example 5,[0],[0]
"Thus,
1
n n∑ i=1",B.14 Proof of Example 5,[0],[0]
I{yi 6= sgn(f(xi;θ∗))},B.14 Proof of Example 5,[0],[0]
"≥ min{n−, n+} n .
",B.14 Proof of Example 5,[0],[0]
"Since the dataset is consisted of both positive and negative examples, then the training error is nonzero.
",B.14 Proof of Example 5,[0],[0]
Example 6 Assume that the distribution PX×Y satisfies that PY (Y = 1) = PY (Y = −1) and PX|Y (X = 2|Y = 1) = PX|Y (X = −1|Y = 1) = 0.5 and PX|Y (X = 0.5|Y = −1) = 1.,B.14 Proof of Example 5,[0],[0]
"Assume that samples in the dataset D = {(xi, yi)}2ni=1 are independently drawn from the distribution PX×Y .",B.14 Proof of Example 5,[0],[0]
Assume that the network fS has M ≥ 1 neurons and neurons in fS satisfy the condition that σ is analytic and has a positive second order derivative on R. There exists a feedforward network fD,B.14 Proof of Example 5,[0],[0]
"such that the empirical loss L̂n(θS ,θD) has a local minimum with non-zero training error with probability at least Ω(1/n2).
",B.14 Proof of Example 5,[0],[0]
"Remark: This is a counterexample where Theorem 1 does not hold, when Assumption 2 is satisfied and Assumption 3 is not satisfied.",B.14 Proof of Example 5,[0],[0]
This distribution can be viewed in the following way.,B.14 Proof of Example 5,[0],[0]
"The positive data samples locate on the linear span of the set {(1)}, the negative data samples locate on the linear span of the set {(1)} and all samples locate on the linear span of the set {(1)}.",B.14 Proof of Example 5,[0],[0]
It is easy to check that assumption 2 is satisfied.,B.14 Proof of Example 5,[0],[0]
"However, r = 1 = max{r+, r−} = 1.",B.14 Proof of Example 5,[0],[0]
"This means the assumption 3 is not satisfied.
",B.14 Proof of Example 5,[0],[0]
"Proof: Let n2, n−1, n0.5 denote the number of samples at the point (2), (−1), (0.5), respectively.",B.14 Proof of Example 5,[0],[0]
"It is easy to see that the event that n2 = n−1 > 0 and n0.5 > 0 happens with probability at least Ω(1/n
2).",B.14 Proof of Example 5,[0],[0]
"We note that this is not a tight bounded, however, we just need to show that this happens with a positive probability.",B.14 Proof of Example 5,[0],[0]
Now we consider the optimization problem under the dataset where n2 = n−1 > 0 and n0.5 > 0.,B.14 Proof of Example 5,[0],[0]
"We first set the feedforward network fD(x;θD) to constant, i.e., fD(x;θD) ≡ 0",B.14 Proof of Example 5,[0],[0]
for x ∈,B.14 Proof of Example 5,[0],[0]
"R. Now the whole network becomes a single layer network,
f(x;θ) = a0 + M∑ j=1 ajσ (wjx) .
",B.14 Proof of Example 5,[0],[0]
Let a∗1 = ...,B.14 Proof of Example 5,[0],[0]
= a ∗ M = −1 and w∗1 = ...,B.14 Proof of Example 5,[0],[0]
= w∗M = 0.,B.14 Proof of Example 5,[0],[0]
"Therefore, we have f(x;θ∗)",B.14 Proof of Example 5,[0],[0]
= a∗0 −Mσ(0).,B.14 Proof of Example 5,[0],[0]
"Let a∗0 be the global optimizer of the following convex optimization problem.
",B.14 Proof of Example 5,[0],[0]
min a 2n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`p(−yi(a−Mσ(0))).
",B.14 Proof of Example 5,[0],[0]
"Thus, we have n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi) = 0, (29) and this indicates that∑ i:yi=1",B.14 Proof of Example 5,[0],[0]
`′p(−(a∗0 −Mσ(0))),B.14 Proof of Example 5,[0],[0]
= ∑,B.14 Proof of Example 5,[0],[0]
i:yi=−1 `′p(a ∗ 0 −Mσ(0)) or `′p(−a∗0 +Mσ(0))n+ =,B.14 Proof of Example 5,[0],[0]
`′p(a∗0 −Mσ(0))n−. (30),B.14 Proof of Example 5,[0],[0]
"In addition, since for ∀j ∈ [M ],
∂L̂n(θ ∗)
",B.14 Proof of Example 5,[0],[0]
∂aj = 2n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)σ(0) = 0, by Equation (29),
∇wj L̂n(θ∗) =",B.14 Proof of Example 5,[0],[0]
2n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)σ′(0)xi = 0, by ∑ i:yi=1 xi",B.14 Proof of Example 5,[0],[0]
= ∑,B.14 Proof of Example 5,[0],[0]
i:,B.14 Proof of Example 5,[0],[0]
"yi=−1 xi = 0,
and ∂L̂n(θ ∗)
∂a0 = n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi) = 0,
then θ∗ is a critical point.",B.14 Proof of Example 5,[0],[0]
"Next we show that θ∗ = (a∗0, ..., a ∗ M , w ∗ 1, ..., w ∗ M ) is a local minima.",B.14 Proof of Example 5,[0],[0]
"Consider any perturbation ∆a1, ...,∆aM : |∆aj | < 12 for all j ∈",B.14 Proof of Example 5,[0],[0]
"[M ], ∆w1, ...,∆wM ∈ R and ∆a0 ∈ R. Define
θ̃ = (a∗0 + ∆a0, ..., a ∗ M + ∆aM , w ∗ 1 + ∆w1, ..., w ∗",B.14 Proof of Example 5,[0],[0]
"M + ∆wM ).
",B.14 Proof of Example 5,[0],[0]
"Then
n∑ i=1",B.14 Proof of Example 5,[0],[0]
`p(−yif(xi; θ̃))− n∑ i=1,B.14 Proof of Example 5,[0],[0]
`p(−yif(xi;θ∗)),B.14 Proof of Example 5,[0],[0]
= n∑ i=1,B.14 Proof of Example 5,[0],[0]
[ `p(−yif(xi; θ̃))− `p(−yif(xi;θ∗)) ],B.14 Proof of Example 5,[0],[0]
"≥
n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)[f(xi; θ̃)− f(xi;θ∗)]
= n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)[f(xi; θ̃)− a∗0 +Mσ(0)]
= n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃),
where the inequality follows from the convexity of the loss function `p(z), the second equality follows from the fact that f(x;θ∗) ≡",B.14 Proof of Example 5,[0],[0]
a∗0 − Mσ(0) and the third equality follows from Equation (30).,B.14 Proof of Example 5,[0],[0]
"In addition, we have
n∑ i=1",B.14 Proof of Example 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃) = n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)  M∑ j=1 (a∗j + ∆aj)σ (∆wjxi) + ∆a0
 =
n∑ i=1",B.14 Proof of Example 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))(−yi)  M∑ j=1 (a∗j + ∆aj)σ (∆wjxi)  by Eq.,B.14 Proof of Example 5,[0],[0]
"(30) =
M∑ j=1 −(a∗j + ∆aj)",B.14 Proof of Example 5,[0],[0]
[ n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ (∆wjxi) ]
= M∑ j=1 −(a∗j + ∆aj)",B.14 Proof of Example 5,[0],[0]
[ n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ (∆wjxi) ] .
",B.14 Proof of Example 5,[0],[0]
"Now we define the following function G : R→ R,
G(u) = n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ (uxi) .
",B.14 Proof of Example 5,[0],[0]
"Now we consider the gradient of the function G with respect to the variable u at the point u = 0,
∇uG(0) = n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yiσ′ (0)xi
= σ′(0)
( 1
2 `′p(−a∗0 +Mσ(0))n+ −
1 2 `′p(a ∗ 0 −Mσ(0))n−
) = 0,
by Equation (30).",B.14 Proof of Example 5,[0],[0]
"Furthermore, the second order derivative ∇2uG(0) satisfies
∇2uG(0) = n∑ i=1",B.14 Proof of Example 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))yiσ′′ (0) (xi)2 = σ′′ (0) n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))yi (xi)2
= σ′′(0)  1 n+ ∑ i:yi=1 (xi) 2 − 1 n− ∑ i:yi=−1 (xi) 2  > 0, then the function G(u)",B.14 Proof of Example 5,[0],[0]
=,B.14 Proof of Example 5,[0],[0]
∑n i=1,B.14 Proof of Example 5,[0],[0]
`p(−yi(a∗0,B.14 Proof of Example 5,[0],[0]
− Mσ(0)))yiσ (uxi) has a local minima at u = 0.,B.14 Proof of Example 5,[0],[0]
"This indicates that there exists ε > 0 such that for all ∆w : ‖∆w‖2 ≤ ε, n∑ i=1",B.14 Proof of Example 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w>xi ) ≥ n∑ i=1,B.14 Proof of Example 5,[0],[0]
"`p(−yi(a∗0 −Mσ(0)))yiσ (0) = 0.
",B.14 Proof of Example 5,[0],[0]
"In addition, since a∗j = −1, |∆aj | < 12 , then for all ∆wj : ‖∆wj‖2 ≤ ε, n∑ i=1",B.14 Proof of Example 5,[0],[0]
`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃) = M∑ j=1 −(a∗j + ∆aj),B.14 Proof of Example 5,[0],[0]
[ n∑ i=1,B.14 Proof of Example 5,[0],[0]
`p(−yi(a∗0 −Mσ(0)))yiσ ( ∆w>j xi )],B.14 Proof of Example 5,[0],[0]
"≥ 0.
",B.14 Proof of Example 5,[0],[0]
"Therefore, we have n∑ i=1",B.14 Proof of Example 5,[0],[0]
"`′p(−yi(a∗0 −Mσ(0)))(−yi)f(xi; θ̃) ≥ 0, and this indicates that n∑ i=1",B.14 Proof of Example 5,[0],[0]
`p(−yif(xi; θ̃))− n∑ i=1,B.14 Proof of Example 5,[0],[0]
`p(−yif(xi;θ∗)),B.14 Proof of Example 5,[0],[0]
≥ 0.,B.14 Proof of Example 5,[0],[0]
"Thus, θ∗ is a local minima with f(x;θ∗)",B.14 Proof of Example 5,[0],[0]
= a∗0 −Mσ(0) = constant.,B.14 Proof of Example 5,[0],[0]
"Thus,
1
n n∑ i=1",B.14 Proof of Example 5,[0],[0]
I{yi 6= sgn(f(xi;θ∗))},B.14 Proof of Example 5,[0],[0]
"≥ min{n−, n+} n .
",B.14 Proof of Example 5,[0],[0]
"Since the dataset is consisted of both positive and negative examples, then the training error is nonzero.",B.14 Proof of Example 5,[0],[0]
Lemma 2,B.15 Proof of Lemma 2,[0],[0]
"If samples in the dataset D = {(xi, yi)}ni=1 satisfies that the matrix ∑n i=1 λiyixix",B.15 Proof of Lemma 2,[0],[0]
"> i is
indefinite for all sequences {λi ≥ 0}ni=1",B.15 Proof of Lemma 2,[0],[0]
"satisfying ∑ i:yi=1 λi = ∑ i:yi=−1 λi > 0, then there exists a matrix A ∈ Rd×d and two real numbers c1 > 0",B.15 Proof of Lemma 2,[0],[0]
and c2 ∈ R such that yi(x,B.15 Proof of Lemma 2,[0],[0]
>,B.15 Proof of Lemma 2,[0],[0]
i Axi − c2) > c1 holds for all i ∈,B.15 Proof of Lemma 2,[0],[0]
"[n].
",B.15 Proof of Lemma 2,[0],[0]
"Proof: For each sample xi in the dataset, let",B.15 Proof of Lemma 2,[0],[0]
vec(xix > i ) denote the vectorization of the matrix xix >,B.15 Proof of Lemma 2,[0],[0]
i .,B.15 Proof of Lemma 2,[0],[0]
"Since we assume that for any sequence {λi ≥ 0}ni=1 satisfying ∑ i:yi=1 λi = ∑ i:yi=−1 λi = 1, the vector∑n
i=1",B.15 Proof of Lemma 2,[0],[0]
"yiλivec(xix > i ) does not equal to the zero vector 0d2 , then we have that the convex hull of two vector sets C+ = {vec(xix>i )}i:yi=1 and C− = {vec(xix>i )}",B.15 Proof of Lemma 2,[0],[0]
i:yi=−1 are two disjoint closed compact sets.,B.15 Proof of Lemma 2,[0],[0]
"By the hyperplane separation theorem, this indicates that there exists a vector w ∈ Rd2 and two real numbers c̃1 < c̃2 such that w >u > c̃2 and w >v < c̃1 for all u ∈ C+ and v ∈ C−.",B.15 Proof of Lemma 2,[0],[0]
This further indicates that there exists two real numbers c1 > 0 and c2 ∈ R such that yi(x,B.15 Proof of Lemma 2,[0],[0]
>,B.15 Proof of Lemma 2,[0],[0]
i,B.15 Proof of Lemma 2,[0],[0]
Axi− c2) > c1 holds for all i ∈ R.,B.15 Proof of Lemma 2,[0],[0]
"Proposition 12 Assume that the single layer neural network fS(x;θS) has M > d neurons and assume that the neuron σ is quadratic, i.e., σ(z) = z2.",B.16 Proof of Proposition 12,[0],[0]
"Assume that the dataset D = {(xi, yi)}ni=1 is consisted of both positive and negative samples.",B.16 Proof of Proposition 12,[0],[0]
"For all multilayer neural network fD parameterized by θD, every local minimum θ ∗ = (θ∗S ,θ ∗ D) of the empirical loss function L̂n(θS ,θD; p), p ≥ 6 satisfies R̂n(θ ∗)",B.16 Proof of Proposition 12,[0],[0]
= 0,B.16 Proof of Proposition 12,[0],[0]
if and only if the matrix,B.16 Proof of Proposition 12,[0],[0]
∑n i=1 λiyixix,B.16 Proof of Proposition 12,[0],[0]
"> i is indefinite for all sequences {λi ≥ 0}ni=1
satisfying ∑
i:yi=1 λi = ∑",B.16 Proof of Proposition 12,[0],[0]
i:,B.16 Proof of Proposition 12,[0],[0]
yi=−1 λi > 0.,B.16 Proof of Proposition 12,[0],[0]
"(1) Proof of “if”: It follows from Lemma 2 that if the assumptions on the dataset are satisfied, there exists a set of parameter θS such that fS(x;θS) achieves zero training error and this further indicates that for any neural architecture fD, there exists a set of parameter θ ∗ =",Proof:,[0],[0]
"(θ∗S ,θ ∗ D) such that Ln(θ ∗; p) = 0 for all p ≥ 1.",Proof:,[0],[0]
This means that the empirical loss function has a global minimum with a value equal to zero.,Proof:,[0],[0]
"We first assume that the θ∗ = (θ∗1,θ ∗ 2) is a local minimum.",Proof:,[0],[0]
"We next prove the following two claims: Claim 1: If θ∗ = (θ∗S ,θ ∗ D) is a local minimum and there exists j ∈",Proof:,[0],[0]
"[M ] such that a∗j = 0, then R̂n(θ ∗) = 0.",Proof:,[0],[0]
Claim 2:,Proof:,[0],[0]
"If θ∗ = (θ∗S ,θ ∗ D) is a local minimum and a ∗ j 6= 0 for all j ∈",Proof:,[0],[0]
"[M ], then R̂n(θ∗) = 0.",Proof:,[0],[0]
(a) Proof of claim 1.,Proof:,[0],[0]
"We prove that if θ∗ = (θ∗S ,θ ∗ D) is a local minima and there exists j ∈",Proof:,[0],[0]
"[M ] such that a∗j = 0, then R̂n(θ ∗) = 0.",Proof:,[0],[0]
"Without loss of generality, we assume that a∗1 = 0.",Proof:,[0],[0]
"Since θ∗ = (θ∗S ,θ ∗ D) is a local minima, then there exists ε0 > 0",Proof:,[0],[0]
"such that for any small perturbations ∆a1, ∆w1 on parameters a ∗ 1 and w ∗ 1, i.e., |∆a1|2 + ‖∆w1‖22 ≤",Proof:,[0],[0]
"ε20, we have
L̂n(θ̃S ,θ ∗ D) ≥ L̃n(θ∗S ,θ∗D),
where θ̃ = (ã0, ã1, ..., ãM , w̃1, ..., w̃M ), ã1 = a ∗ 1 + ∆a1, w̃1 = w ∗ 1 + ∆w1 and ãj = a ∗ j , w̃j",Proof:,[0],[0]
= w ∗ j for j 6= 1.,Proof:,[0],[0]
"Now we consider Taylor expansion of L̃n(θ̃S ,θ∗D) at (θ∗S ,θ∗D).",Proof:,[0],[0]
"We note here that the Taylor expansion of L̂(θS ,θ ∗ D; p) on θS always exists, since the empirical loss function L̂n has continuous derivatives with respect to fS up to the p-th order and the output of the neural network f(x;θS) is infinitely differentiable with respect to θS due to the fact that neuron activation function σ is real analytic.",Proof:,[0],[0]
"We first calculate the first order derivatives at the point (θ∗1,θ ∗ 2)
dL̂n(θ ∗)
da1 = n∑ i=1",Proof:,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ ( w∗1 >xi ) = 0, θ∗ is a critical point,
∇w1L̂n(θ∗) = a∗1 n∑ i=1",Proof:,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ′ ( w∗1 >xi ) xi = 0d, θ ∗ is a critical point.
",Proof:,[0],[0]
"Next, we calculate the second order derivatives at the point (θ∗1,θ ∗ 2),
d2L̂(θ∗)
",Proof:,[0],[0]
da21 = N∑ i=1,Proof:,[0],[0]
"`′′p(−yif(xi;θ∗))σ2 ( w∗1 >xi ) ≥ 0,
d
da1 (∇w1L(θ∗))",Proof:,[0],[0]
= n∑ i=1,Proof:,[0],[0]
"`′p(−yif(xi;θ∗))(−yi)σ′ ( w∗1 >xi ) xi
+ a∗1 n∑ i=1",Proof:,[0],[0]
`′′p(−yif(xi;θ∗))σ ( w∗1 >xi ),Proof:,[0],[0]
σ′,Proof:,[0],[0]
"( w∗1 >xi ) xi
= 0d,
where the first term equals to the zero vector by the necessary condition for a local minima presented in Lemma 1 and the second term equals to the zero vector by the assumption that a∗1 = 0.",Proof:,[0],[0]
"Furthermore, by the assumption that a∗1 = 0, we have
∇2w1L̂n(θ∗; p) = a∗1∇w1",Proof:,[0],[0]
[ n∑ i=1,Proof:,[0],[0]
"`′p(−yif(xi;θ))(−yi)σ′ ( w∗1 >xi ) xi ] = 0d×d.
",Proof:,[0],[0]
"We further calculate the third order derivatives
d
da1
[ ∇2w1L̂n(θ∗; p) ] =",Proof:,[0],[0]
"d
da1
[ a∗1∇w1 [ n∑ i=1",Proof:,[0],[0]
`′p(−yif(xi;θ))(−yi)σ′ ( w∗1 >xi ) xi,Proof:,[0],[0]
"]]
= ∇w1",Proof:,[0],[0]
[ n∑ i=1,Proof:,[0],[0]
`′p(−yif(xi;θ))(−yi)σ′ ( w∗1 >xi ) xi ],Proof:,[0],[0]
"+ 0d×d by a ∗ 1 = 0
= n∑ i=1",Proof:,[0],[0]
`′p(−yif(xi;θ))(−yi)σ′′ ( w∗1 >xi ) xix >,Proof:,[0],[0]
"i
+ a∗1 n∑ i=1",Proof:,[0],[0]
`′′p(−yif(xi;θ)),Proof:,[0],[0]
[ σ′ ( w∗1 >xi )]2 xix >,Proof:,[0],[0]
"i
= n∑ i=1",Proof:,[0],[0]
`′p(−yif(xi;θ))(−yi)σ′′ ( w∗1 >xi ) xix,Proof:,[0],[0]
>,Proof:,[0],[0]
"i by a ∗ 1 = 0
and
∇3w1L̂n(θ∗; p) = a∗1∇2w1 [ n∑ i=1",Proof:,[0],[0]
"`′p(−yif(xi;θ))(−yi)σ′ ( w∗1 >xi ) xi ] = 0d×d×d.
",Proof:,[0],[0]
"In fact, it is easy to show that for any 2 ≤ k ≤ p,
∇kw1L̂n(θ∗; p) =",Proof:,[0],[0]
a∗1∇k−1w1 [ n∑ i=1,Proof:,[0],[0]
`′p(−yif(xi;θ))(−yi)σ′ ( w∗1 >xi ) xi ] = 0d× d× ...× d︸,Proof:,[0],[0]
"︷︷ ︸
k times
.
",Proof:,[0],[0]
"Let ε > 0, ∆a1 = sgn(a1)ε 9/4 and ∆w1 = εu1 for u1 : ‖u1‖2 = 1.",Proof:,[0],[0]
"Clearly, when ε → 0, ∆a1 = o(‖∆w1‖2), ∆a1 = o(1) and ‖∆w1‖ = o(1).",Proof:,[0],[0]
"Then we expand L̂n(θ̃1,θ∗2) at the point θ∗ up to the sixth order and thus as ε→ 0,
L̂n(θ̃1,θ ∗ 2) = L̂n(θ ∗ 1,θ ∗ 2) +
1
2!
",Proof:,[0],[0]
"d2L̂n(θ ∗)
d2a1 (∆a1)
2
+ 1
2 ∆a1∆w
> 1
d
da1
[ D2w1L̂n(θ ∗; p) ]",Proof:,[0],[0]
"∆w1 + o(|a1|2) + o(|a1|‖w1‖22) + o(‖∆w1‖52)
",Proof:,[0],[0]
"= L̂n(θ ∗ 1,θ ∗ 2) +
1
2!
d2L̂n(θ ∗)
d2a1 ε9/2 +
1 2 sgn(a1)ε 9/4+2 n∑ i=1",Proof:,[0],[0]
"`′p(−yif(xi;θ))σ′′ ( w∗1 >xi ) (u>1 xi) 2
+ o(ε9/2) + o(ε9/4+2) + o(ε5)
= L̂n(θ ∗ 1,θ ∗ 2) +
1 2 sgn(a1)ε 17/4 n∑ i=1",Proof:,[0],[0]
"`′p(−yif(xi;θ))(−yi)σ′′ ( w∗1 >xi ) (u>1 xi) 2 + o(ε17/4)
",Proof:,[0],[0]
"Since ε > 0 and L̂n(θ̃1,θ ∗ 2; p) ≥ L̂n(θ∗; p) holds for any u1 : ‖u1‖2 = 1 and any sgn(a1) ∈ {−1, 1}, then n∑ i=1",Proof:,[0],[0]
"`′p(−yif(xi;θ))(−yi)σ′′ ( w∗1 >xi ) (u>xi) 2 = 0, for any u ∈ Rd.",Proof:,[0],[0]
"(31)
Therefore, n∑ i=1",Proof:,[0],[0]
`′p(−yif(xi;θ))(−yi)σ′′ ( w∗1 >xi ) xix >,Proof:,[0],[0]
i = 0d×d.,Proof:,[0],[0]
"Since σ′′(z) = 2 for all z, then
n∑ i=1",Proof:,[0],[0]
"`′p(−yif(xi;θ))(−yi)xix>i = 0d×d. (32)
",Proof:,[0],[0]
"Furthermore, since θ∗ is a critical point, then
∂L̂n(θ; p)
∂a0 =
1
n n∑ i=1",Proof:,[0],[0]
`′(−yif(xi;θ∗))(−yi) = 0.,Proof:,[0],[0]
"(33)
Now we assume that R̂n(θ ∗)",Proof:,[0],[0]
> 0.,Proof:,[0],[0]
This means that there exists a index i such that yif(xi;θ ∗),Proof:,[0],[0]
< 0 or `′(−yif(xi;θ∗)),Proof:,[0],[0]
> 0.,Proof:,[0],[0]
"Furthermore, since `′(z) ≥ 0, then by setting λi = `′(−yif(xi;θ∗)), we have that there exists a sequence {λi ≥ 0}ni=1 satisfying ∑ i:yi=1 λi = ∑
i:",Proof:,[0],[0]
"yi=−1 λi > 0, where the equality follows from Equation (33) and the positiveness comes from the assumption that `′(−yif(xi;θ∗))",Proof:,[0],[0]
> 0,Proof:,[0],[0]
"for some i, such that
n∑ i=1 λiyixix >",Proof:,[0],[0]
"i = 0d×d,
where the equality follows from Equation (32).",Proof:,[0],[0]
This leads to the contradiction with our assumption that the matrix,Proof:,[0],[0]
∑n i=1 λiyixix,Proof:,[0],[0]
> i should be indefinite for all sequences {λi ≥ 0}ni=1,Proof:,[0],[0]
"satisfying ∑ i:yi=1
λi =∑ i:",Proof:,[0],[0]
yi=−1 λi > 0.,Proof:,[0],[0]
"Therefore, this indicates that R̂n(θ ∗) = 0.",Proof:,[0],[0]
"(b) Proof of Claim 2: To prove the claim 2, we first show that if M > d, then there exists coefficients α1, ..., αM , not all zero, such that
(α1w ∗ 1 + ...+ αMw ∗ M ) >",Proof:,[0],[0]
xi,Proof:,[0],[0]
"= 0, for all i ∈",Proof:,[0],[0]
"[n].
",Proof:,[0],[0]
"Clearly, if M > r, then there exists coefficients α1, ..., αM , not all zero, such that
(α1w ∗ 1 + ...+ αMw ∗ M ) = 0d, for all i ∈",Proof:,[0],[0]
"[n].
Now we prove the claim 2.",Proof:,[0],[0]
"First, we consider the Hessian matrix H(w∗1, ...,w ∗ M ).",Proof:,[0],[0]
"Since θ ∗ is a local minima, then
F (u1, ...,uM )",Proof:,[0],[0]
= M∑ j=1 M∑ k=1,Proof:,[0],[0]
"u>j ∇2wj ,wk L̂n(θ ∗; p)uk ≥ 0
holds for any vectors u1, ...,uM ∈ Rd.",Proof:,[0],[0]
"Since σ′′(z) = 2 and σ′(z) = 2z for all z ∈ R, then
∇2wj L̂n(θ∗; p) = a∗j n∑ i=1",Proof:,[0],[0]
`′p(−yif(xi;θ∗))(−yi)σ′′ ( w∗j >xi ) xix,Proof:,[0],[0]
>,Proof:,[0],[0]
"i
+ a∗j 2 n∑ i=1",Proof:,[0],[0]
`′′p(−yif(xi;θ∗)),Proof:,[0],[0]
[ σ′ ( w∗j >xi )]2 xix >,Proof:,[0],[0]
"i
= −2a∗j n∑ i=1",Proof:,[0],[0]
`′p(−yif(xi;θ∗))yixix>i + 4a∗j 2 n∑ i=1,Proof:,[0],[0]
`′′p(−yif(xi;θ∗)) (,Proof:,[0],[0]
w∗j >xi )2 xix >,Proof:,[0],[0]
"i ,
and
∇2wj ,wk L̂n(θ ∗; p) =",Proof:,[0],[0]
a∗ja ∗ k n∑ i=1,Proof:,[0],[0]
`′′p(−yif(xi;θ∗)),Proof:,[0],[0]
[ σ′ ( w∗j >xi )],Proof:,[0],[0]
[ σ′ ( w∗k >xi )],Proof:,[0],[0]
xix >,Proof:,[0],[0]
"i
= 4a∗ja ∗ k n∑ i=1",Proof:,[0],[0]
`′′p(−yif(xi;θ∗)) (,Proof:,[0],[0]
w∗j >xi )( w∗k >xi ) xix,Proof:,[0],[0]
"> i .
",Proof:,[0],[0]
"Thus, we have
F (u1, ...,uM )",Proof:,[0],[0]
= −2,Proof:,[0],[0]
M∑ j=1 [ a∗j n∑ i=1,Proof:,[0],[0]
"`′p(−yif(xi;θ∗))yi ( u>j xi )2]
+ 4 M∑ j=1 M∑",Proof:,[0],[0]
k=1,Proof:,[0],[0]
[ a∗ja ∗ k n∑ i=1,Proof:,[0],[0]
`′′p(−yif(xi;θ∗)) (,Proof:,[0],[0]
w∗j >xi )( w∗k >xi ),Proof:,[0],[0]
"( u>j xi )( u>k xi )]
= −2 M∑ j=1",Proof:,[0],[0]
[ a∗j n∑ i=1,Proof:,[0],[0]
"`′p(−yif(xi;θ∗))yi ( u>j xi )2]
+ 4 n∑ i=1",Proof:,[0],[0]
`′′p(−yif(xi;θ∗))  ,Proof:,[0],[0]
M∑ j=1 a∗j ( w∗j >xi ),Proof:,[0],[0]
( u>j xi )2 .,Proof:,[0],[0]
"Since there exists coefficients α1, ..., αM , not all zero, such that (α1w ∗ 1 + ...+ αMw ∗ M )",Proof:,[0],[0]
">xi = 0, for all i ∈",Proof:,[0],[0]
"[n], and a∗j 6= 0",Proof:,[0],[0]
for all j ∈,Proof:,[0],[0]
[M ] then by setting uj = αju/a∗j for all j ∈,Proof:,[0],[0]
"[M ], we have that the inequality
F (u1, ...,uM )",Proof:,[0],[0]
= −2,Proof:,[0],[0]
M∑ j=1 [ a∗j n∑ i=1,Proof:,[0],[0]
`′p(−yif(xi;θ∗))yi ( αj/a ∗ j )2,Proof:,[0],[0]
"( u>xi )2]
",Proof:,[0],[0]
+ 4 n∑ i=1,Proof:,[0],[0]
"`′′p(−yif(xi;θ∗))  M∑ j=1 αj ( w∗j >xi )( u>xi )2 = −2
M∑ j=1",Proof:,[0],[0]
[ a∗j n∑ i=1,Proof:,[0],[0]
`′p(−yif(xi;θ∗))yi ( αj/a ∗ j )2,Proof:,[0],[0]
"( u>xi )2]
",Proof:,[0],[0]
+ 4 n∑ i=1,Proof:,[0],[0]
`′′p(−yif(xi;θ∗))   M∑ j=1 αjw ∗,Proof:,[0],[0]
"j > xi  2 ( u>xi )2 = −2
M∑ j=1 ( α2j/a ∗ j ) · n∑ i=1",Proof:,[0],[0]
"`′p(−yif(xi;θ∗))yi ( u>xi )2 ≥ 0
holds for any u ∈ Rd.",Proof:,[0],[0]
"Next we consider the following two cases: (1) ∑M j=1 ( α2j/a ∗ j ) 6= 0; (2) ∑Mj=1 (α2j/a∗j) = 0.
",Proof:,[0],[0]
"Case 1: If ∑M
j=1 ( α2j/a ∗ j ) 6= 0, then without loss of generality, we assume that ∑Mj=1 (α2j/a∗j) < 0.
",Proof:,[0],[0]
This indicates that n∑ i=1,Proof:,[0],[0]
"`′p(−yif(xi;θ∗))yi ( u>xi )2 ≥ 0, for all u ∈ Rd.",Proof:,[0],[0]
"(34)
Since θ∗ is a critical point, then
∂L̂n(θ ∗; p)
∂a0 =
1
n n∑ i=1",Proof:,[0],[0]
`′(−yif(xi;θ∗))(−yi) = 0.,Proof:,[0],[0]
"(35)
Now we assume that R̂n(θ ∗)",Proof:,[0],[0]
> 0.,Proof:,[0],[0]
This means that there exists a index i such that yif(xi;θ ∗),Proof:,[0],[0]
< 0 or `′(−yif(xi;θ∗)),Proof:,[0],[0]
> 0.,Proof:,[0],[0]
"Furthermore, since `′(z) ≥ 0, then by setting λi = `′(−yif(xi;θ∗)), we have that there exists a sequence {λi ≥ 0}ni=1 satisfying ∑ i:yi=1 λi = ∑
i:",Proof:,[0],[0]
"yi=−1 λi > 0, where the equality follows from Equation (33) and the positiveness comes from the assumption that `′(−yif(xi;θ∗))",Proof:,[0],[0]
> 0,Proof:,[0],[0]
"for some i, such that
n∑ i=1 λiyixix >",Proof:,[0],[0]
"i 0,
where the positive semi-definiteness follows from the inequality (34).",Proof:,[0],[0]
This leads to the contradiction with our assumption that the matrix,Proof:,[0],[0]
∑n i=1 λiyixix,Proof:,[0],[0]
"> i should be indefinite for all sequences {λi ≥ 0}ni=1
satisfying ∑
i:yi=1 λi = ∑ i:",Proof:,[0],[0]
yi=−1 λi > 0.,Proof:,[0],[0]
"Therefore, this indicates that R̂n(θ ∗) = 0.
",Proof:,[0],[0]
"Case 2: If ∑M
j=1 ( α2j/a ∗ j ) = 0, then by setting uj = (αj/a ∗ j +vsgn(αj))u for some scalar v and vector
u ∈ Rd, we have
F (v,u) = −2",Proof:,[0],[0]
M∑ j=1 [ a∗j n∑ i=1,Proof:,[0],[0]
`′p(−yif(xi;θ∗))yi ( (αj/a ∗ j + vsgn(αj))u,Proof:,[0],[0]
">xi )2]
+ 4 n∑ i=1",Proof:,[0],[0]
`′′p(−yif(xi;θ∗))  ,Proof:,[0],[0]
M∑ j=1 a∗j ( w∗j >xi )( (αj/a ∗ j + vsgn(αj))u,Proof:,[0],[0]
">xi )2 = −2
M∑ j=1 [ a∗j n∑ i=1",Proof:,[0],[0]
`′p(−yif(xi;θ∗))yi ( (αj/a ∗ j + vsgn(αj))u,Proof:,[0],[0]
">xi )2]
+ 4 n∑ i=1",Proof:,[0],[0]
`′′p(−yif(xi;θ∗))   M∑ j=1 (αj + vsgn(αj)a ∗ j )w ∗,Proof:,[0],[0]
"j > xi (u>xi)2  = −2
M∑ j=1",Proof:,[0],[0]
[ a∗j n∑ i=1,Proof:,[0],[0]
`′p(−yif(xi;θ∗))yi ( (αj/a ∗ j + vsgn(αj))u,Proof:,[0],[0]
">xi )2]
+ 4v2 n∑ i=1",Proof:,[0],[0]
`′′p(−yif(xi;θ∗))   M∑,Proof:,[0],[0]
j=1 sgn(αj)a ∗ jw ∗,Proof:,[0],[0]
j > xi  2,Proof:,[0],[0]
"( u>xi )2 , −2
M∑ j=1",Proof:,[0],[0]
[ a∗j n∑ i=1,Proof:,[0],[0]
`′p(−yif(xi;θ∗))yi ( (αj/a ∗ j + vsgn(αj))u,Proof:,[0],[0]
">xi )2] + v2R(u),
where we define
R(u) = 4 n∑ i=1",Proof:,[0],[0]
`′′p(−yif(xi;θ∗))   M∑,Proof:,[0],[0]
j=1 sgn(αj)a ∗ jw ∗,Proof:,[0],[0]
j > xi  2,Proof:,[0],[0]
"( u>xi )2 .
",Proof:,[0],[0]
"In addition, we have
M∑ j=1",Proof:,[0],[0]
[ a∗j n∑ i=1,Proof:,[0],[0]
`′p(−yif(xi;θ∗))yi ( (αj/a ∗ j + vsgn(αj))u,Proof:,[0],[0]
">xi )2]
= n∑ i=1",Proof:,[0],[0]
`′p(−yif(xi;θ))yi(u>xi)2 ·  M∑ j=1 (α2j/a ∗ j + 2vsgn(αj)αj + v 2a∗j )  ,Proof:,[0],[0]
"=
n∑ i=1",Proof:,[0],[0]
`′p(−yif(xi;θ))yi(u>xi)2 ·  M∑ j=1 (2vsgn(αj)αj + v 2a∗j )  ,Proof:,[0],[0]
"= 2v
 M∑ j=1 |αj |  n∑ i=1",Proof:,[0],[0]
`′p(−yif(xi;θ))yi(u>xi)2 + v2  M∑ j=1 a∗j  n∑ i=1,Proof:,[0],[0]
"`′p(−yif(xi;θ))yi(u>xi)2.
",Proof:,[0],[0]
"Therefore, we can rewrite F (v,u) as
F (v,u) =",Proof:,[0],[0]
2v M∑ j=1 |αj | n∑ i=1,Proof:,[0],[0]
`′p(−yif(xi;θ))yi(u>xi)2 + v2 M∑ j=1 a∗j · n∑ i=1,Proof:,[0],[0]
"`′p(−yif(xi;θ))yi(u>xi)2 + v2R(u)
, 2v M∑ j=1 |αj | n∑ i=1",Proof:,[0],[0]
"`′p(−yif(xi;θ))yi(u>xi)2 + v2R̂(u)
Since F (v,u) ≥ 0 holds for any scalar v and vector u ∈ Rd, then we should have
M∑ j=1 |αj",Proof:,[0],[0]
| n∑ i=1,Proof:,[0],[0]
"`′p(−yif(xi;θ))yi(u>xi)2 = 0, for any u ∈ Rd.
",Proof:,[0],[0]
"Since the coefficient α1, ..., αM are not all zero, then for any u ∈ Rd, we have n∑ i=1",Proof:,[0],[0]
"`′p(−yif(xi;θ))yi(u>xi)2 = 0.
Applying the same analysis shown earlier, we have R̂n(θ ∗) = 0.
",Proof:,[0],[0]
Proof of “only if”: We prove the necessary condition by proving the following claim.,Proof:,[0],[0]
Claim 10,Proof:,[0],[0]
If there exists a sequence {λi ≥ 0}ni=1 satisfying ∑ i:yi=1 λi = ∑ i:,Proof:,[0],[0]
"yi=−1 λi > 0 such that
the matrix ∑n
i=1 λiyixix",Proof:,[0],[0]
"> i is positive or negative positive semi-definite, then there exists a multilayer
neural architecture fD",Proof:,[0],[0]
"such that the empirical loss function L̂n(θS ,θD; p), p ≥ 6 has a local minimum with a non-zero training error.
",Proof:,[0],[0]
"Proof: Let D = {(xi, yi)}ni=1 denote a dataset consisting of n samples.",Proof:,[0],[0]
"We rewrite the sample x as x = ( x(1), ..., x(d) ) .",Proof:,[0],[0]
"Consider the following network,
f(x;θ) = fS(x;θS) + fD(x;θD),
where
fS(x;θS)",Proof:,[0],[0]
= a0 + M∑ j=1,Proof:,[0],[0]
"ajσ(w > j xi + bj),
and the multilayer network is defined as follows,
fD(x;θD) = fD(x; θ1, ..., θd) = n∑ i=1",Proof:,[0],[0]
µi d∏,Proof:,[0],[0]
k=1 1 { x(k) ∈,Proof:,[0],[0]
"[ x (k) i − θk, x (k) i + θk ]} .",Proof:,[0],[0]
"(36)
We note here that µ1, ..., µn are not parameters and later we will show that this function can be implemented by a multilayer network consisted of threshold units.",Proof:,[0],[0]
"A useful property of the function fD(x;θD) is that if all parameters θis are positive and sufficiently smalls, then for each sample (xi, yi) in the dataset,
fD(xi;θD)",Proof:,[0],[0]
"= µi.
",Proof:,[0],[0]
"Furthermore, if we slightly perturb all parameters, the output of the function fD on all samples remain the same.",Proof:,[0],[0]
"In the proof, we use these two properties to construct the local minimum with a non-zero training error.
",Proof:,[0],[0]
"By assumption, there exists a sequence {λi ≥ 0}ni=1 satisfying ∑ i:yi=1 λi = ∑ i:yi=−1 λi > 0",Proof:,[0],[0]
"such that
the matrix ∑n
i=1 λiyixix",Proof:,[0],[0]
>,Proof:,[0],[0]
i is positive or negative semi-definite.,Proof:,[0],[0]
"Without loss of generality, we assume
that the matrix is positive semi-definite.",Proof:,[0],[0]
"Now we construct a local minimum θ∗. Let a∗0 = a ∗ 1 = ... = a∗M = −1, w∗1 = ...",Proof:,[0],[0]
= w∗M = 0d and b∗1 = ...,Proof:,[0],[0]
= b∗M = 0.,Proof:,[0],[0]
"Now we set θ∗1, ..., θ∗d to be positive and sufficiently small such that for two different samples in the dataset, e.g., xi 6= xj , the following equations holds,
d∏",Proof:,[0],[0]
k=1 1 { x (k) j ∈,Proof:,[0],[0]
"[ x (k) i − 2θ∗k, x (k) i + 2θ ∗",Proof:,[0],[0]
"k ]} = 0, d∏",Proof:,[0],[0]
k=1 1 { x (k) i ∈,Proof:,[0],[0]
"[ x (k) j − 2θ∗k, x (k) j + 2θ ∗",Proof:,[0],[0]
"k ]} = 0.
",Proof:,[0],[0]
"Now we choose µ1, ..., µn as follows.",Proof:,[0],[0]
"The output of the neural network on sample xi in the dataset is f(xi;θ
∗) = µi −Mσ(0).",Proof:,[0],[0]
"We need to choose µ1, ..., µn to satisfy all conditions shown as follows:
(1) There exists i ∈",Proof:,[0],[0]
[n] such that yi(µi −Mσ(0)),Proof:,[0],[0]
"< 0.
(2) For all i : yi = 1 and all k : yk = −1,
`′(−yi(µi −Mσ(0)))∑ j:j=1 ` ′(−yi(µi −Mσ(0)))",Proof:,[0],[0]
"= λi∑ j:j=1 λj , `′(−yk(µk −Mσ(0)))∑ j:j=−1 ` ′(−yi(µi −Mσ(0)))",Proof:,[0],[0]
"= λk∑ j:j=−1 λj ,
and ∑ j:j=1 `′(−yi(µi −Mσ(0)))",Proof:,[0],[0]
= ∑,Proof:,[0],[0]
"j:j=−1 `′(−yi(µi −Mσ(0))).
",Proof:,[0],[0]
Now we start from the largest element in the sequence {λi}ni=1.,Proof:,[0],[0]
"Since ∑n
i=1 λi > 0, the define the index imax as the index of the largest element, i.e.,
imax = arg max i λi.
Let λmax = λimax .",Proof:,[0],[0]
"Now we choose µimax such that
yimax(µimax −Mσ(0))",Proof:,[0],[0]
"= −1.
",Proof:,[0],[0]
"Thus, the index imax satisfy the first condition.",Proof:,[0],[0]
"Then for i 6= imax, we choose µi such that
`′(−yi(µi −Mσ(0)))",Proof:,[0],[0]
= λi λmax `(−yimax(µimax −Mσ(0))),Proof:,[0],[0]
= λi λmax `′(1) ≤,Proof:,[0],[0]
`′(1),Proof:,[0],[0]
.,Proof:,[0],[0]
"(37)
",Proof:,[0],[0]
We note here that for each i ∈,Proof:,[0],[0]
"[n], there always exists a µi solving the above equation.",Proof:,[0],[0]
"This can be seen by the fact that `′ is continuous, `′p(z) ≥ 0 and `′p(z) = 0 iff z ≤ −z0.",Proof:,[0],[0]
"This indicates that for ∀z > −z0, `′p(z) > 0, i.e., `′(1) > 0 and that `′(−z0) = 0.",Proof:,[0],[0]
"Since `′(z) is continuous, then for ∀r ∈",Proof:,[0],[0]
"[0, `′(1)], there always exists z ∈ R such that `′(z) = r, which further indicates that for ∀i ∈",Proof:,[0],[0]
"[n], there always exists µi ∈ R solving the Equation (37).",Proof:,[0],[0]
"Under this construction, it is easy to show that the second condition is satisfied as well.",Proof:,[0],[0]
Now we only need to show that θ∗ is local minimum.,Proof:,[0],[0]
We first show that θ∗ is a critical point of the empirical loss function.,Proof:,[0],[0]
"Since for ∀j ∈ [M ],
∂L̂n(θ ∗)
",Proof:,[0],[0]
∂aj = n∑ i=1,Proof:,[0],[0]
"`′(−yi(µi −Mσ(0)))(−yi)σ(0)
= σ(0) n∑ i=1",Proof:,[0],[0]
λi λmax `′(1)(−yi) =,Proof:,[0],[0]
"− σ(0)`′(1) λmax n∑ i=1 yiλi
= 0 by ∑ i:yi=1 λi = ∑ i:yi=−1 λi
∇wj L̂n(θ∗) = n∑ i=1",Proof:,[0],[0]
"`′(−yi(µi −Mσ(0)))(−yi)σ′(0)xi
= −σ′(0) n∑ i=1",Proof:,[0],[0]
λi λmax `′(1)yixi = − σ′(0)`′(1) λmax n∑ i=1,Proof:,[0],[0]
"λiyixi = 0d by σ ′(0) = 0
and ∂L̂n(θ ∗)
",Proof:,[0],[0]
∂a0 = n∑ i=1,Proof:,[0],[0]
`′(−yi(µi −Mσ(0)))(−yi) =,Proof:,[0],[0]
− `′(1) λmax n∑ i=1,Proof:,[0],[0]
"yiλi = 0.
",Proof:,[0],[0]
"In addition, we have stated earlier, if we slightly perturb the parameter θ∗k in the interval",Proof:,[0],[0]
"[θ ∗ k/2, 3θ ∗ k/2], the output of the function fD(xi;θD) does not change for all i ∈",Proof:,[0],[0]
"[n], then θ∗ is a critical point.",Proof:,[0],[0]
Now we show that θ∗ is local minimum.,Proof:,[0],[0]
"Consider any perturbation ∆a1, ...,∆aM : |∆aj | < 12 for all j ∈",Proof:,[0],[0]
"[M ], ∆w1, ...,∆wM ∈ Rd, ∆a0 ∈ R, ∆θk :",Proof:,[0],[0]
|∆θk| ≤ θk/2 for all k ∈,Proof:,[0],[0]
[n].,Proof:,[0],[0]
"Define
θ̃ = (a∗0 + ∆a0, ..., a ∗ M + ∆aM ,w ∗ 1 + ∆w1, ...,w ∗ M + ∆wM , θ ∗ 1 + ∆θ ∗ 1, ..., θ ∗ d + ∆θ ∗ d).
",Proof:,[0],[0]
"Then
n∑ i=1",Proof:,[0],[0]
`(−yif(xi; θ̃))− n∑ i=1,Proof:,[0],[0]
`(−yif(xi;θ∗)) = n∑ i=1,Proof:,[0],[0]
[ `(−yif(xi; θ̃))− `(−yif(xi;θ∗)) ],Proof:,[0],[0]
"≥
n∑ i=1",Proof:,[0],[0]
"`′(−yif(xi;θ∗))(−yi)[f(xi; θ̃)− f(xi;θ∗)].
",Proof:,[0],[0]
"Since for each sample xi in the dataset,
f(xi; θ̃)− f(xi;θ∗)",Proof:,[0],[0]
= ∆a0 + M∑ j=1 (a∗j + ∆aj)σ(∆w > j xi) +,Proof:,[0],[0]
µi,Proof:,[0],[0]
"− µi
= ∆a0 + M∑ j=1 (a∗j + ∆aj)σ(∆w > j xi),
then
n∑ i=1",Proof:,[0],[0]
`(−yif(xi; θ̃))− n∑ i=1,Proof:,[0],[0]
"`(−yif(xi;θ∗))
≥ n∑ i=1",Proof:,[0],[0]
`′(−yif(xi;θ∗))(−yi)[f(xi; θ̃)− f(xi;θ∗)],Proof:,[0],[0]
= n∑ i=1,Proof:,[0],[0]
"`′(−yi(µi −Mσ(0)))(−yi)  M∑ j=1 (a∗j + ∆aj)σ ( ∆w>j xi ) + ∆a0
 =
n∑ i=1",Proof:,[0],[0]
"λi` ′(1) λmax (−yi)  M∑ j=1 (a∗j + ∆aj)σ ( ∆w>j xi ) = `′(1)
λmax M∑ j=1 −(a∗j",Proof:,[0],[0]
+ ∆aj),Proof:,[0],[0]
[ n∑ i=1,Proof:,[0],[0]
"λiyi ( ∆w>j xi )2] .
",Proof:,[0],[0]
"Since by assumption that the matrix ∑n
i=1 λiyixix",Proof:,[0],[0]
"> i is positive semi-definite, then for any ∆w > j ∈ Rd,
n∑ i=1",Proof:,[0],[0]
"λiyi ( ∆w>j xi )2 ≥ 0.
",Proof:,[0],[0]
"In addition, since a∗j = −1, |∆aj | < 12 , then for all ∆wj ∈ Rd, n∑ i=1",Proof:,[0],[0]
`(−yif(xi; θ̃))− n∑ i=1,Proof:,[0],[0]
`(−yif(xi;θ∗)),Proof:,[0],[0]
"≥ 0.
",Proof:,[0],[0]
"Thus, θ∗ is a local minima of the empirical loss function with f(xi;θ ∗) = µi −Mσ(0).",Proof:,[0],[0]
Since there exists a µimax such that yimax(µimax −Mσ(0)),Proof:,[0],[0]
"= 1, then this means that the neural network makes an incorrect prediction on the sample ximax .",Proof:,[0],[0]
"This indicates that this local minimum has a non-zero training error.
",Proof:,[0],[0]
"Finally, we present the way we construct the neural network fD. Since
fD(x;θD) = fD(x; θ1, ..., θd) = n∑ i=1",Proof:,[0],[0]
µi d∏,Proof:,[0],[0]
k=1 1 { x(k) ∈,Proof:,[0],[0]
"[ x (k) i − θk, x (k) i + θk ]} .
",Proof:,[0],[0]
"Let σth denote the threshold unit, where σth(z) = 1 if z ≥ 0 and σth(z) = 0, otherwise.",Proof:,[0],[0]
"Therefore, the indicator function can be represented as follows:
1 { x(k) ∈",Proof:,[0],[0]
"[ x
(k) i − θk, x (k) i + θk",Proof:,[0],[0]
]} = σth ( x(k),Proof:,[0],[0]
− x(k)i + θk ),Proof:,[0],[0]
− σth ( x(k) − x(k)i,Proof:,[0],[0]
− θk ),Proof:,[0],[0]
"Therefore,
d∏ k=1 1 { x(k) ∈",Proof:,[0],[0]
"[ x (k) i − θk, x (k) i + θk",Proof:,[0],[0]
"]} = σth ( d∑
k=1
[ σth ( x(k) − x(k)i + θk )",Proof:,[0],[0]
− σth ( x(k) − x(k)i,Proof:,[0],[0]
− θk )],Proof:,[0],[0]
"− d+ 1
2
)
Therefore, we have
fD(x;θD) = n∑ i=1",Proof:,[0],[0]
"µiσth
( d∑
k=1
[ σth ( x(k)",Proof:,[0],[0]
− x(k)i + θk ),Proof:,[0],[0]
− σth ( x(k) − x(k)i,Proof:,[0],[0]
− θk )],Proof:,[0],[0]
"− d+ 1
2
) .
",Proof:,[0],[0]
"It is very easy to see that this is a two layer network consisted of threshold units.
",Proof:,[0],[0]
"Furthermore, we note here that, in the proof shown above, we assume the only parameters in the network fD are θ1, ...,θd.",Proof:,[0],[0]
"In fact, we can prove a more general statement where the fD is of the form
fD(x;θD) = n∑ i=1",Proof:,[0],[0]
"µiσth
( d∑
k=1
[ aikσth ( x(k) + uik ) + bikσth ( x(k) + vik )]",Proof:,[0],[0]
"+ ci ) ,
where aik, bik, uik, vik, ci, i ∈",Proof:,[0],[0]
"[n], k ∈",Proof:,[0],[0]
[d] are all parameters.,Proof:,[0],[0]
"We can show that the neural network
fD(x;θD) = n∑ i=1",Proof:,[0],[0]
"µiσth
( d∑
k=1
[ σth ( x(k)",Proof:,[0],[0]
− x(k)i + θk ),Proof:,[0],[0]
− σth ( x(k) − x(k)i,Proof:,[0],[0]
− θk )],Proof:,[0],[0]
"− d+ 1
2
) ,
denotes a local minimum, since any slight perturbations on parameters aik, bik, uik, vik, ci, i ∈",Proof:,[0],[0]
"[n], k ∈",Proof:,[0],[0]
[d] do not change the output of the neural network on the samples in the dataset D.,Proof:,[0],[0]
"It is widely conjectured that the reason that training algorithms for neural networks are successful because all local minima lead to similar performance; for example, see [1, 2, 3].",abstractText,[0],[0]
Performance is typically measured in terms of two metrics: training performance and generalization performance.,abstractText,[0],[0]
"Here we focus on the training performance of neural networks for binary classification, and provide conditions under which the training error is zero at all local minima of appropriately chosen surrogate loss functions.",abstractText,[0],[0]
"Our conditions are roughly in the following form: the neurons have to be increasing and strictly convex, the neural network should either be single-layered or is multi-layered with a shortcut-like connection, and the surrogate loss function should be a smooth version of hinge loss.",abstractText,[0],[0]
"We also provide counterexamples to show that, when these conditions are relaxed, the result may not hold.",abstractText,[0],[0]
Understanding the Loss Surface of Neural Networks for Binary Classification,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1946–1956 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"The top systems in recent machine translation evaluation campaigns on various language pairs use ensembles of a number of NMT systems (Bojar et al., 2016; Sennrich et al., 2016a; Chung et al., 2016; Neubig, 2016; Wu et al., 2016; Cromieres et al., 2016; Durrani et al., 2017).",1 Introduction,[0],[0]
"Ensembling (Dietterich, 2000; Hansen and Salamon, 1990) of neural networks is a simple yet very effective technique to improve the accuracy of NMT.
",1 Introduction,[0],[0]
"The decoder makes use of K NMT networks which are either trained independently (Sutskever et al., 2014; Chung et al., 2016; Neubig, 2016; Wu et al., 2016) or share some amount of training iterations (Sennrich et al., 2016b,a; Cromieres et al., 2016; Durrani et al., 2017).",1 Introduction,[0],[0]
"The ensemble decoder computes predictions from each of the individual models which are then combined using the arithmetic average (Sutskever et al., 2014) or the geometric average (Cromieres et al., 2016).
",1 Introduction,[0],[0]
Ensembling consistently outperforms single NMT by a large margin.,1 Introduction,[0],[0]
"However, the decoding speed is significantly worse since the decoder needs to apply K NMT models rather than only one.",1 Introduction,[0],[0]
"Therefore, a recent line of research transfers the idea of knowledge distillation (Bucilu et al., 2006; Hinton et al., 2014) to NMT and trains a smaller network (the student) by minimizing the cross-entropy to the output of the ensemble system (the teacher) (Kim and Rush, 2016; Freitag et al., 2017).",1 Introduction,[0],[0]
This paper presents an alternative to knowledge distillation as we aim to speed up decoding to be comparable to single NMT while retaining the boost in translation accuracy from the ensemble.,1 Introduction,[0],[0]
"In a first step, we describe how to construct a single large neural network which imitates the output of an ensemble of multiple networks with the same topology.",1 Introduction,[0],[0]
We will refer to this process as unfolding.,1 Introduction,[0],[0]
GPU-based decoding with the unfolded network is often much faster than ensemble decoding since more work can be done on the GPU.,1 Introduction,[0],[0]
"In a second step, we explore methods to reduce the size of the unfolded network.",1 Introduction,[0],[0]
"This idea is justified by the fact that ensembled neural networks are often over-parameterized and have a large degree of redundancy (LeCun et al., 1989; Hassibi et al., 1993; Srinivas and Babu, 2015).",1 Introduction,[0],[0]
Shrinking the unfolded network leads to a smaller model which consumes less space on the disk and in the memory; a crucial factor on mobile devices.,1 Introduction,[0],[0]
"More importantly, the
1946
decoding speed on all platforms benefits greatly from the reduced number of neurons.",1 Introduction,[0],[0]
We find that the dimensionality of linear embedding layers in the NMT network can be reduced heavily by lowrank matrix approximation based on singular value decomposition (SVD).,1 Introduction,[0],[0]
"This suggest that high dimensional embedding layers may be needed for training, but do not play an important role for decoding.",1 Introduction,[0],[0]
"The NMT network, however, also consists of complex layers like gated recurrent units (Cho et al., 2014, GRUs) and attention (Bahdanau et al., 2015).",1 Introduction,[0],[0]
"Therefore, we introduce a novel algorithm based on linear combinations of neurons which can be applied either during training (data-bound) or directly on the weight matrices without using training data (data-free).",1 Introduction,[0],[0]
We report that with a mix of the presented shrinking methods we are able to reduce the size of the unfolded network to the size of the single NMT network while keeping the boost in BLEU score from the ensemble.,1 Introduction,[0],[0]
"Depending on the aggressiveness of shrinking, we report either a gain of 2.2 BLEU at the same decoding speed, or a 3.4× CPU decoding speed up with only a minor drop in BLEU compared to the original single NMT system.",1 Introduction,[0],[0]
"Furthermore, it is often much easier to stage a single NMT system than an ensemble in a commercial MT workflow, and it is crucial to be able to optimize quality at specific speed and memory constraints.",1 Introduction,[0],[0]
Unfolding and shrinking address these problems directly.,1 Introduction,[0],[0]
The first concept of our approach is called unfolding.,2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
Unfolding is an alternative to ensembling of multiple neural networks with the same topology.,2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"Rather than averaging their predictions, unfolding constructs a single large neural net out of the indi-
vidual models which has the same number of input and output neurons but larger inner layers.",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"Our main motivation for unfolding is to obtain a single network with ensemble level performance which can be shrunk with the techniques in Sec. 3.
",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
Suppose we ensemble two single layer feedforward neural nets as shown in Fig. 1.,2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"Normally, ensembling is implemented by performing an isolated forward pass through the first network (Fig. 1(a)), another isolated forward pass through the second network (Fig. 1(b)), and averaging the activities in the output layers of both networks.",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
This can be simulated by merging both networks into a single large network as shown in Fig. 1(c).,2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"The first neurons in the hidden layer of the combined network correspond to the hidden layer in the first single network, and the others to the hidden layer of the second network.",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
A single pass through the combined network yields the same output as the ensemble if the output layer is linear (up to a factor 2).,2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
The weight matrices in the unfolded network can be constructed by stacking the corresponding weight matrices (either horizontally or vertically) in network 1 and 2.,2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"This kind of aggregation of multiple networks with the same topology is not only possible for single-layer feedforward architectures but also for complex networks consisting of multiple GRU layers and attention.
",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"For a formal description of unfolding we address layers with indices d = 0, 1, . . .",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
", D. The special layer 0 has a single neuron for modelling bias vectors.",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
Layer 1 holds the input neurons and layer D is the output layer.,2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
We denote the size of a layer in the individual models as s(d).,2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"When combining K networks, the layer size s′(d) in the unfolded network is increased by factor K if d is an inner layer, and equal to s(d) if d is the in-
put or output layer.",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"We denote the weight matrix between two layers d1, d2 ∈",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"[0, D] in the k-th individual model (k ∈",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"[1,K]) as Wk(d1, d2) ∈ Rs(d1)×s(d2), and the corresponding weight matrix in the unfolded network as W ′(d1, d2) ∈ Rs′(d1)×s′(d2).",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
We explicitly allow d1 and d2 to be non-consecutive or reversed to be able to model recurrent networks.,2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
We use the zero-matrix if layers d1 and d2 are not connected.,2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"The construction of the unfolded weight matrix W ′(d1, d2) from the individual matrices Wk(d1, d2) depends on whether the connected layers are inner layers or not.",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"The complete formula is listed in Fig. 2.
",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
Unfolded NMT networks approximate but do not exactly match the output of the ensemble due to two reasons.,2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"First, the unfolded network synchronizes the attentions of the individual models.",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
Each decoding step in the unfolded network computes a single attention weight vector.,2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"In contrast, ensemble decoding would compute one attention weight vector for each of the K input models.",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"A second difference is that the ensemble decoder first applies the softmax at the output layer, and then averages the prediction probabilities.",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"The unfolded network averages the neuron activities (i.e. the logits) first, and then applies the softmax function.",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
"Interestingly, as shown in Sec. 4, these differences do not have any impact on the BLEU score but yield potential speed advantages of unfolding since the computationally expensive softmax layer is only applied once.",2 Unfolding K Networks into a Single Large Neural Network,[0],[0]
After constructing the weight matrices of the unfolded network we reduce the size of it by iteratively shrinking layer sizes.,3 Shrinking the Unfolded Network,[0],[0]
"In this section we denote the incoming weight matrix of the layer to
shrink as U ∈ Rmin×m and the outgoing weight matrix as V ∈ Rm×mout .",3 Shrinking the Unfolded Network,[0],[0]
Our procedure is inspired by the method of Srinivas and Babu (2015).,3 Shrinking the Unfolded Network,[0],[0]
They propose a criterion for removing neurons in inner layers of the network based on two intuitions.,3 Shrinking the Unfolded Network,[0],[0]
"First, similarly to Hebb’s learning rule, they detect redundancy by the principle neurons which fire together, wire together.",3 Shrinking the Unfolded Network,[0],[0]
"If the incoming weight vectors U:,i and U:,j are exactly the same for two neurons i and j, we can remove the neuron j and add its outgoing connections to neuron i (Vi,: ← Vi,: +",3 Shrinking the Unfolded Network,[0],[0]
"Vj,:) without changing the output.1",3 Shrinking the Unfolded Network,[0],[0]
This holds since the activity in neuron j will always be equal to the activity in neuron i.,3 Shrinking the Unfolded Network,[0],[0]
"In practice, Srinivas and Babu use a distance measure based on the difference of the incoming weight vectors to search for similar neurons as exact matches are very rare.
",3 Shrinking the Unfolded Network,[0],[0]
The second intuition of the criterion used by Srinivas and Babu (2015) is that neurons with small outgoing weights contribute very little overall.,3 Shrinking the Unfolded Network,[0],[0]
"Therefore, they search for a pair of neurons i, j ∈",3 Shrinking the Unfolded Network,[0],[0]
"[1,m] according the following term and remove the j-th neuron.2
arg min i,j∈[1,m]
||U:,i",3 Shrinking the Unfolded Network,[0],[0]
"− U:,j ||22||Vj,:||22 (1)
",3 Shrinking the Unfolded Network,[0],[0]
Neuron j is selected for removal if (1) there is another neuron i which has a very similar set of incoming weights and if (2) j has a small outgoing weight vector.,3 Shrinking the Unfolded Network,[0],[0]
"Their criterion is data-free since
1We denote the i-th row vector of a matrix A with Ai,: and the i-th column vector as A:,i.
",3 Shrinking the Unfolded Network,[0],[0]
2Note that the criterion in Eq. 1 generalizes the criterion of Srinivas and Babu (2015) to multiple outgoing weights.,3 Shrinking the Unfolded Network,[0],[0]
Also note that Srinivas and Babu (2015) propose some heuristic improvements to this criterion.,3 Shrinking the Unfolded Network,[0],[0]
"However, these heuristics did not work well in our NMT experiments.
",3 Shrinking the Unfolded Network,[0],[0]
it does not require any training data.,3 Shrinking the Unfolded Network,[0],[0]
For further details we refer to Srinivas and Babu (2015).,3 Shrinking the Unfolded Network,[0],[0]
"Srinivas and Babu (2015) propose to add the outgoing weights of j to the weights of a similar neuron i to compensate for the removal of j. However, we have found that this approach does not work well on NMT networks.",3.1 Data-Free Neuron Removal,[0],[0]
We propose instead to compensate for the removal of a neuron by a linear combination of the remaining neurons in the layer.,3.1 Data-Free Neuron Removal,[0],[0]
Data-free shrinking assumes for the sake of deriving the update rule that the neuron activation function is linear.,3.1 Data-Free Neuron Removal,[0],[0]
We now ask the following question: How can we compensate as well as possible for the loss of neuron j such that the impact on the output of the whole network is minimized?,3.1 Data-Free Neuron Removal,[0],[0]
"Datafree shrinking represents the incoming weight vector of neuron j (U:,j) as linear combination of the incoming weight vectors of the other neurons.",3.1 Data-Free Neuron Removal,[0],[0]
"The linear factors can be found by satisfying the following linear system:
U:,¬jλ = U:,j (2)
where U:,¬j is matrix U without the j-th column.",3.1 Data-Free Neuron Removal,[0],[0]
"In practice, we use the method of ordinary least squares to find λ because the system may be overdetermined.",3.1 Data-Free Neuron Removal,[0],[0]
"The idea is that if we mix the outputs of all neurons in the layer by the λ-weights, we get the output of the j-th neuron.",3.1 Data-Free Neuron Removal,[0],[0]
"The row vector Vj,: contains the contributions of the j-th neuron to each of the neurons in the next layer.",3.1 Data-Free Neuron Removal,[0],[0]
"Rather than using these connections, we approximate their effect by adding some weight to the outgoing connections of the other neurons.",3.1 Data-Free Neuron Removal,[0],[0]
"How much weight depends on λ and the outgoing weights Vj,:.",3.1 Data-Free Neuron Removal,[0],[0]
"The factor Dk,l which we need to add to the outgoing connection of the k-th neuron to compensate for the loss of the j-th neuron on the l-th neuron in the next layer is:
Dk,l = λkVj,l (3)
",3.1 Data-Free Neuron Removal,[0],[0]
"Therefore, the update rule for V is:
V ← V +D (4) In the remainder we will refer to this method as data-free shrinking.",3.1 Data-Free Neuron Removal,[0],[0]
Note that we recover the update rule of Srinivas and Babu (2015) by setting λ to the i-th unit vector.,3.1 Data-Free Neuron Removal,[0],[0]
"Also note that the error introduced by our shrinking method is due to the
fact that we ignore the non-linearity, and that the solution for λ may not be exact.",3.1 Data-Free Neuron Removal,[0],[0]
"The method is error-free on linear layers as long as the residuals of the least-squares analysis in Eq. 2 are zero.
",3.1 Data-Free Neuron Removal,[0],[0]
"GRU layers The terminology of neurons needs some further elaboration for GRU layers which rather consist of update and reset gates and states (Cho et al., 2014).",3.1 Data-Free Neuron Removal,[0],[0]
"On GRU layers, we treat the states as neurons, i.e. the j-th neuron refers to the j-th entry in the GRU state vector.",3.1 Data-Free Neuron Removal,[0],[0]
Input connections to the gates are included in the incoming weight matrix U for estimating λ in Eq. 2.,3.1 Data-Free Neuron Removal,[0],[0]
Removing neuron j in a GRU layer means deleting the j-th entry in the states and both gate vectors.,3.1 Data-Free Neuron Removal,[0],[0]
"Although we find our data-free approach to be a substantial improvement over the methods of Srinivas and Babu (2015) on NMT networks, it still leads to a non-negligible decline in BLEU score when applied to recurrent GRU layers.",3.2 Data-Bound Neuron Removal,[0],[0]
"Our data-free method uses the incoming weights to identify similar neurons, i.e. neurons expected to have similar activities.",3.2 Data-Bound Neuron Removal,[0],[0]
"This works well enough for simple layers, but the interdependencies between the states and the gates inside gated layers like GRUs or LSTMs are complex enough that redundancies cannot be found simply by looking for similar weights.",3.2 Data-Bound Neuron Removal,[0],[0]
"In the spirit of Babaeizadeh et al. (2016), our data-bound version records neuron activities during training to estimate λ.",3.2 Data-Bound Neuron Removal,[0],[0]
We compensate for the removal of the j-th neuron by using a linear combination of the output of remaining neurons with similar activity patterns.,3.2 Data-Bound Neuron Removal,[0],[0]
"In each layer, we prune 40 neurons each 450 training iterations until the target layer size is reached.",3.2 Data-Bound Neuron Removal,[0],[0]
Let A be the matrix which holds the records of neuron activities in the layer since the last removal.,3.2 Data-Bound Neuron Removal,[0],[0]
"For example, for the decoder GRU layer, a batch size of 80, and target sentence lengths of 20,A has 20 · 80 · 450 = 720K rows and m (the number of neurons in the layer)",3.2 Data-Bound Neuron Removal,[0],[0]
"columns.3 Similarly to Eq. 2 we find interpolation weights λ using the method of least squares on the following linear system.
",3.2 Data-Bound Neuron Removal,[0],[0]
"A:,¬jλ = A:,j (5)
",3.2 Data-Bound Neuron Removal,[0],[0]
"The update rule for the outgoing weight matrix is the same as for our data-free method (Eq. 4).
",3.2 Data-Bound Neuron Removal,[0],[0]
"3In practice, we use a random sample of 50K rows rather than the full matrix to keep the complexity of the leastsquares analysis under control.
",3.2 Data-Bound Neuron Removal,[0],[0]
The key difference between data-free and databound shrinking is the way λ is estimated.,3.2 Data-Bound Neuron Removal,[0],[0]
"Datafree shrinking uses the similarities between incoming weights, and data-bound shrinking uses neuron activities recorded during training.",3.2 Data-Bound Neuron Removal,[0],[0]
"Once we select a neuron to remove, we estimate λ, compensate for the removal, and proceed with the shrunk network.",3.2 Data-Bound Neuron Removal,[0],[0]
Both methods are prior to any decoding and result in shrunk parameter files which are then loaded to the decoder.,3.2 Data-Bound Neuron Removal,[0],[0]
"Both methods remove neurons rather than single weights.
",3.2 Data-Bound Neuron Removal,[0],[0]
The data-bound algorithm runs gradient-based optimization on the unfolded network.,3.2 Data-Bound Neuron Removal,[0],[0]
"We use the AdaGrad (Duchi et al., 2011) step rule, a small learning rate of 0.0001, and aggressive step clipping at 0.05 to avoid destroying useful weights which were learned in the individual networks prior to the construction of the unfolded network.
",3.2 Data-Bound Neuron Removal,[0],[0]
Our data-bound algorithm uses a data-bound version of the neuron selection criterion in Eq. 1 which operates on the activity matrix A. We search for the pair,3.2 Data-Bound Neuron Removal,[0],[0]
"i, j ∈",3.2 Data-Bound Neuron Removal,[0],[0]
"[1,m] according the following term and remove neuron j.
arg min i,j∈[1,m]
||A:,i −A:,j ||22||A:,j ||22 (6)",3.2 Data-Bound Neuron Removal,[0],[0]
"The standard attention-based NMT network architecture (Bahdanau et al., 2015) includes three linear layers: the embedding layer in the encoder, and the output and feedback embedding layers in the decoder.",3.3 Shrinking Embedding Layers with SVD,[0],[0]
We have found that linear layers are particularly easy to shrink using low-rank matrix approximation.,3.3 Shrinking Embedding Layers with SVD,[0],[0]
As before we denote the incoming weight matrix as U ∈ Rmin×m and the outgoing weight matrix as V ∈ Rm×mout .,3.3 Shrinking Embedding Layers with SVD,[0],[0]
"Since the layer is linear, we could directly connect the previous layer with the next layer using the product of both weight matrices X = U · V .",3.3 Shrinking Embedding Layers with SVD,[0],[0]
"However, X may be very large.",3.3 Shrinking Embedding Layers with SVD,[0],[0]
"Therefore, we approximate X as a product of two low rank matrices Y ∈ Rmin×m′ and Z ∈ Rm′×mout (X ≈ Y Z) where m′ m is the desired layer size.",3.3 Shrinking Embedding Layers with SVD,[0],[0]
A very common way to find such a matrix factorization is using truncated singular value decomposition (SVD).,3.3 Shrinking Embedding Layers with SVD,[0],[0]
The layer is eventually shrunk by replacing U with Y and V with Z.,3.3 Shrinking Embedding Layers with SVD,[0],[0]
"The individual NMT systems we use as source for constructing the unfolded networks are trained us-
ing AdaDelta (Zeiler, 2012) on the Blocks/Theano implementation (van Merriënboer et al., 2015; Bastien et al., 2012) of the standard attentionbased NMT model (Bahdanau et al., 2015) with: 1000 dimensional GRU layers (Cho et al., 2014) in both the decoder and bidrectional encoder; a single maxout output layer (Goodfellow et al., 2013); and 620 dimensional embedding layers.",4 Results,[0],[0]
We follow Sennrich et al. (2016b) and use subword units based on byte pair encoding rather than words as modelling units.,4 Results,[0],[0]
"Our SGNMT decoder (Stahlberg et al., 2017)4 with a beam size of 12 is used in all experiments.",4 Results,[0],[0]
"Our primary corpus is the Japanese-English (Ja-En) ASPEC data set (Nakazawa et al., 2016).",4 Results,[0],[0]
We select a subset of 500K sentence pairs to train our models as suggested by Neubig et al. (2015).,4 Results,[0],[0]
We report cased BLEU scores calculated with Moses’ multi-bleu.pl to be strictly comparable to the evaluation done in the Workshop of Asian Translation (WAT).,4 Results,[0],[0]
"We also apply our method to the WMT data set for English-German (En-De), using the news-test2014 as a development set, and keeping news-test2015 and news-test2016 as test sets.",4 Results,[0],[0]
En-De BLEU scores are computed using mteval-v13a.pl as in the WMT evaluation.,4 Results,[0],[0]
We set the vocabulary sizes to 30K for Ja-En and 50K for En-De.,4 Results,[0],[0]
We also report the size factor for each model which is the total number of model parameters (sum of all weight matrix sizes) divided by the number of parameters in the original NMT network (86M for Ja-En and 120M for EnDe).,4 Results,[0],[0]
"We choose a widely used, simple ensembling method (prediction averaging) as our baseline.",4 Results,[0],[0]
"We feel that the prevalence of this method makes it a reasonable baseline for our experiments.
",4 Results,[0],[0]
"Shrinking the Unfolded Network First, we investigate which shrinking methods are effective for which layers.",4 Results,[0],[0]
"Tab. 1 summarizes our results on a 2-unfold network for Ja-En, i.e. two separate NMT networks are combined in a single large network as described in Sec. 2.",4 Results,[0],[0]
"The layers in the combined network are shrunk to the size of the original networks using the methods discussed in Sec. 3.
",4 Results,[0],[0]
Shrinking the linear embedding layers with SVD (Sec. 3.3) is very effective.,4 Results,[0],[0]
The unfolded model with shrunk embedding layers performs at the same level as the ensemble (compare rows (b) and (c)).,4 Results,[0],[0]
"In our initial experiments, we applied the method of Srinivas and Babu (2015) to
4‘vanilla’ decoding strategy
shrink the other layers, but their approach performed very poorly on this kind of network: the BLEU score dropped down to 15.5 on the development set when shrinking all layers except the decoder maxout and embedding layers, and to 9.9 BLEU when applying their method only to embedding layers.5 Row (e) in Tab. 1 shows that our data-free algorithm from Sec. 3.1 is better suited for shrinking the GRU and attention layers, leading to a drop of only 1 BLEU point compared to the ensemble (b) (i.e. 0.8 BLEU better than the single system (a)).",4 Results,[0],[0]
"However, using the data-bound version of our shrinking algorithm (Sec. 3.2) for the GRU layers performs best.6",4 Results,[0],[0]
The shrunk model yields about the same BLEU score as the ensemble on the test set (25.2 in (b) and 25.3 in (f)).,4 Results,[0],[0]
"Shrinking the maxout layer remains more of a challenge (rows (g) and (h)), but the number of parameters in this layer is small.",4 Results,[0],[0]
"Therefore, shrinking all layers except the maxout layer leads to almost the same number of parameters (factor 1.05 in row (f))",4 Results,[0],[0]
"as the original NMT network (a), and thus to a similar storage size, memory consumption, and decoding speed, but with a 1.8 BLEU gain.",4 Results,[0],[0]
"Based on these results we fix the shrinking method used for each layer for all remaining experiments as follows: We shrink linear embedding layers with our SVD-based method, GRU layers with our databound method, the attention layer with our datafree method, and do not shrink the maxout layer.
",4 Results,[0],[0]
Our data-bound algorithm from Sec. 3.2 has two mechanisms to compensate for the removal of a neuron.,4 Results,[0],[0]
"First, we use a linear combination of the remaining neurons to update the outgoing weight matrix by imitating its activations (Eq. 4).",4 Results,[0],[0]
"Second, stochastic gradient descent (SGD) fine-tunes all
5Results with the original method of Srinivas and Babu (2015) are not included in Tab. 1.
",4 Results,[0],[0]
"6If we apply different methods to different layers of the same network, we first apply SVD-based shrinking, then the data-free method, and finally the data-bound method.
weights during this process.",4 Results,[0],[0]
"Tab. 2 demonstrates that both mechanisms are crucial for minimizing the effect of shrinking on the BLEU score.
",4 Results,[0],[0]
Decoding Speed,4 Results,[0],[0]
"Our testing environment is an Ubuntu 16.04 with Linux 4.4.0 kernel, 32 GB RAM, an Intel R© Core i7-6700 CPU at 3.40 GHz and an Nvidia GeForce GTX Titan X GPU.",4 Results,[0],[0]
CPU decoding uses a single thread.,4 Results,[0],[0]
"We used the first 500 sentences of the Ja-En WAT development set for the time measurements.
",4 Results,[0],[0]
"Our results in Tab. 3 show that decoding with ensembles (rows (b) and (e)) is slow: combining the predictions of the individual models on the CPU is computationally expensive, and ensemble decoding requires K passes through the softmax layer which is also computationally expensive.",4 Results,[0],[0]
Unfolding the ensemble into a single network and shrinking the embedding and attention layers improves the runtimes on the GPU significantly without noticeable impact on BLEU (rows (c) and (f)).,4 Results,[0],[0]
This can be attributed to the fact that unfolding can reduce the communication overhead between CPU and GPU.,4 Results,[0],[0]
Comparing rows (d) and (g) with row (a) reveals that shrinking the unfolded networks even further speeds up CPU and GPU decoding almost to the level of single system decoding.,4 Results,[0],[0]
"However, more aggressive shrinking yields a BLEU score of 25.3 when combining three systems (row (g)) – 1.8 BLEU better than the single system, but 0.6 BLEU worse than the 3-
ensemble.",4 Results,[0],[0]
"Therefore, we will investigate the impact of shrinking on the different layers in the next sections more thoroughly.
",4 Results,[0],[0]
Degrees of Redundancy in Different Layers We applied our shrinking methods to isolated layers in the 2-Unfold network of Tab. 1 (f).,4 Results,[0],[0]
Fig. 3 plots the BLEU score when isolated layers are shrunk even below their size in the original NMT network.,4 Results,[0],[0]
The attention layer is very robust against shrinking and can be reduced to 100 neurons (10% of the original size) without impacting the BLEU score.,4 Results,[0],[0]
The embedding layers can be reduced to 60% but are sensitive to more aggressive pruning.,4 Results,[0],[0]
"Shrinking the GRU layers affects the BLEU score the most but still outperforms the single system when the GRU layers are shrunk to 30%.
",4 Results,[0],[0]
Adjusting the Target Sizes of Layers Based on our previous experiments we revise our approach to shrink the 3-Unfold system in Tab. 3.,4 Results,[0],[0]
"Instead
of shrinking all layers except the maxout layer to the same degree, we adjust the aggressiveness of shrinking for each layer.",4 Results,[0],[0]
"We suggest three different setups (Normal, Small, and Tiny) with the layer sizes specified in Tab. 4.",4 Results,[0],[0]
"3-Unfold-Normal has the same number of parameters as the original NMT networks (size factor: 1.0), 3-UnfoldSmall is only half their size (size factor: 0.5), and 3-Unfold-Tiny reduces the size by two thirds (size factor: 0.33).",4 Results,[0],[0]
"When comparing rows (a) and (c) in Tab. 5 we observe that 3-Unfold-Normal yields a gain of 2.2 BLEU with respect to the original single system and a slight improvement in decoding speed at the same time.7 Networks with the size factor 1.0 like 3-Unfold-Normal are very likely to yield about the same decoding speed as the Single network regardless of the decoder implementation, machine learning framework, and hardware.",4 Results,[0],[0]
"Therefore, we think that similar results are possible on other platforms as well.
CPU decoding speed directly benefits even more from smaller setups – 3-Unfold-Tiny is only 0.3 BLEU worse than Single but decoding on a single CPU is 3.4 times faster (row (a) vs. row (e) in Tab. 5).",4 Results,[0],[0]
"This is of great practical use: batch decoding with only two CPU threads surpasses production speed which is often set to 2000 words per minute (Beck et al., 2016).",4 Results,[0],[0]
"Our initial experiments in Tab. 6 suggest that the Normal setup is applicable to En-De as well, with substantial improve-
7To validate that the gains come from ensembling and unfolding and not from the layer sizes in 3-Unfold-Normal we trained a network from scratch with the same dimensions.",4 Results,[0],[0]
"This network performed similarly to our Single system.
ments in BLEU compared to Single with about the same decoding speed.",4 Results,[0],[0]
"The idea of pruning neural networks to improve the compactness of the models dates back more than 25 years (LeCun et al., 1989).",5 Related Work,[0],[0]
"The literature is therefore vast (Augasta and Kathirvalavakumar, 2013).",5 Related Work,[0],[0]
One line of research aims to remove unimportant network connections.,5 Related Work,[0],[0]
"The connections can be selected for deletion based on the secondderivative of the training error with respect to the weight (LeCun et al., 1989; Hassibi et al., 1993), or by a threshold criterion on its magnitude (Han et al., 2015).",5 Related Work,[0],[0]
"See et al. (2016) confirmed a high degree of weight redundancy in NMT networks.
",5 Related Work,[0],[0]
In this work we are interested in removing neurons rather than single connections since we strive to shrink the unfolded network such that it resembles the layout of an individual model.,5 Related Work,[0],[0]
We argued in Sec. 4 that removing neurons rather than connections does not only improve the model size but also the memory footprint and decoding speed.,5 Related Work,[0],[0]
"As explained in Sec. 3.1, our data-free method is an extension of the approach by Srinivas and Babu (2015); our extension performs significantly better on NMT networks.",5 Related Work,[0],[0]
"Our data-bound method (Sec. 3.2) is inspired by Babaeizadeh et al. (2016) as we combine neurons with similar activities during training, but we use linear combinations of multiple neurons to compensate for the loss of a neuron rather than merging pairs of neurons.
",5 Related Work,[0],[0]
"Using low rank matrices for neural network compression, particularly approximations via SVD, has been studied widely in the literature (Denil et al., 2013; Denton et al., 2014; Xue et al., 2013; Prabhavalkar et al., 2016; Lu et al., 2016).",5 Related Work,[0],[0]
These approaches often use low rank matrices to approximate a full rank weight matrix in the original network.,5 Related Work,[0],[0]
"In contrast, we shrink an entire linear layer by applying SVD on the product of the incoming and outgoing weight matrices (Sec. 3.3).
",5 Related Work,[0],[0]
"In this paper we mimicked the output of the high performing but cumbersome ensemble by constructing a large unfolded network, and shrank this
network afterwards.",5 Related Work,[0],[0]
"Another approach, known as knowledge distillation, uses the large model (the teacher) to generate soft training labels for the smaller student network (Bucilu et al., 2006; Hinton et al., 2014).",5 Related Work,[0],[0]
The student network is trained by minimizing the cross-entropy to the teacher.,5 Related Work,[0],[0]
"This idea has been applied to sequence modelling tasks such as machine translation and speech recognition (Wong and Gales, 2016; Kim and Rush, 2016; Freitag et al., 2017).",5 Related Work,[0],[0]
"Our approach can be computationally more efficient as the training set does not have to be decoded by the large teacher network.
",5 Related Work,[0],[0]
Junczys-Dowmunt et al. (2016a; 2016b) reported gains from averaging the weight matrices of multiple checkpoints of the same training run.,5 Related Work,[0],[0]
"However, our attempts to replicate their approach were not successful.",5 Related Work,[0],[0]
"Averaging might work well when the behaviour of corresponding units is similar across networks, but that cannot be guaranteed when networks are trained independently.",5 Related Work,[0],[0]
We have described a generic method for improving the decoding speed and BLEU score of single system NMT.,6 Conclusion,[0],[0]
Our approach involves unfolding an ensemble of multiple systems into a single large neural network and shrinking this network by removing redundant neurons.,6 Conclusion,[0],[0]
"Our best results on Japanese-English either yield a gain of 2.2 BLEU compared to the original single NMT network at about the same decoding speed, or a 3.4×CPU decoding speed up with only a minor drop in BLEU.
",6 Conclusion,[0],[0]
The current formulation of unfolding works for networks of the same topology as the concatenation of layers is only possible for analogous layers in different networks.,6 Conclusion,[0],[0]
"Unfolding and shrinking diverse networks could be possible, for example by applying the technique only to the input and output layers or by some other scheme of finding associations between units in different models, but we leave this investigation to future work as models in NMT ensembles in current research usually have the same topology (Bojar et al., 2016; Sennrich et al., 2016a; Chung et al., 2016; Neubig, 2016; Wu et al., 2016; Durrani et al., 2017).",6 Conclusion,[0],[0]
This work was supported by the U.K. Engineering and Physical Sciences Research Council (EPSRC grant EP/L027623/1).,Acknowledgments,[0],[0]
"Data-free and data-bound shrinking can be interpreted as setting the expected difference between network outputs before and after a removal operation to zero under different assumptions.
",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"For simplicity, we focus our probabilistic treatment of shrinking on single layer feedforward networks.",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
Such a network maps an input x ∈ Rmin to an output y ∈ Rmout .,Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"The l-th output yl is computed according the following equation
yl = ∑
k∈[1,m] σ(xuTk )",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"Vk,l (7)
where uk ∈ Rmin is the incoming weight vector of the k-th hidden neuron (denoted as U:,k in the main paper) and V ∈ Rm×mout the outgoing weight matrix of the m-dimensional hidden layer.",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"We now remove the j-th neuron in the hidden layer and modify the outgoing weights to compensate for the removal:
y′l = ∑
k∈[1,m]\{j} σ(xuTk )V
′",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"k,l (8)
where y′l is the output after the removal operation and V ′ ∈ Rm×mout are the modified outgoing weights.",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"Our goal is to choose V ′ such that the expected error introduced by removing neuron j is zero:
Ex(yl − y′l)",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"= 0 (9)
Data-free shrinking Data-free shrinking makes two assumptions to satisfy Eq. 9.",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"First, we assume that the incoming weight vector uj can be represented as linear combination of the other weight vectors.
uj = ∑
k∈[1,m]\{j} λkuk (10)
Second, it assumes that the neuron activation function σ(·) is linear.",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
Starting with Eqs.,Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
7 and 8 we can write Ex(yl − y′l),Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"as
Ex ( σ(xuTj )",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"Vj,l + ∑ k∈[1,m]\{j}
σ(xuTk )(Vk,l − V ′k,l)︸ ︷︷ ︸ :=R
)
Eq. 10 = Ex ( σ(x( ∑ k∈[1,m]\{j} λkuk)T )Vj,l +R )
σ(·) lin. =",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"Ex ( ∑ k∈[1,m]\{j} σ(xuTk )λkVj,l +R )
= ∑ k∈[1,m]\{j} Ex ( σ(xuTk ) )",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"(Vk,l − V ′k,l + λkVj,l)
We set this term to zero (and thus satisfy Eq. 9) by setting each component of the sum to zero.
∀k ∈",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"[1,m] \ {j} : V ′k,l = Vk,l + λkVj,l (11)",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"This condition is directly implemented by the update rule in our shrinking algorithm (Eq. 3 and 4).
",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
Data-bound shrinking Data-bound shrinking does not require linearity in σ(·).,Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"It rather assumes that the expected value of the neuron activity j is a linear combination of the expected values of the other activities:
Ex(σ(xuTj ))",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"= ∑
k∈[1,m]\{j} λkEx(σ(xuTk ))",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"(12)
Ex(·) is estimated using importance sampling:
Êx(σ(xuTk );X )",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"= 1 |X | ∑ x′∈X σ(x′uTk ) (13)
",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"In practice, the samples inX are collected in the activity matrix A from Sec. 3.2.",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"We can satisfy Eq. 9 by using the λ-values from Eq. 12, so that Ex(yl − y′l) becomes
Eqs.",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"7,8 = Ex ( σ(xuTj )",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"Vj,l
+ ∑
k∈[1,m]\{j} σ(xuTk )(Vk,l − V ′k,l) )",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
= Ex(σ(xuTj ),Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"Vj,l)
+ ∑
k∈[1,m]\{j} Ex(σ(xuTk ))",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"(Vk,l − V ′k,l)
Eq. 12 = ∑ k∈[1,m]\{j} Ex(σ(xuTk ))",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
"(Vk,l − V ′k,l + λkVj,l)
Again, we set this to zero using Eq. 11.",Appendix: Probabilistic Interpretation of Data-Free and Data-Bound Shrinking,[0],[0]
Ensembling is a well-known technique in neural machine translation (NMT) to improve system performance.,abstractText,[0],[0]
"Instead of a single neural net, multiple neural nets with the same topology are trained separately, and the decoder generates predictions by averaging over the individual models.",abstractText,[0],[0]
Ensembling often improves the quality of the generated translations drastically.,abstractText,[0],[0]
"However, it is not suitable for production systems because it is cumbersome and slow.",abstractText,[0],[0]
This work aims to reduce the runtime to be on par with a single system without compromising the translation quality.,abstractText,[0],[0]
"First, we show that the ensemble can be unfolded into a single large neural network which imitates the output of the ensemble system.",abstractText,[0],[0]
We show that unfolding can already improve the runtime in practice since more work can be done on the GPU.,abstractText,[0],[0]
We proceed by describing a set of techniques to shrink the unfolded network by reducing the dimensionality of layers.,abstractText,[0],[0]
On JapaneseEnglish we report that the resulting network has the size and decoding speed of a single NMT network but performs on the level of a 3-ensemble system.,abstractText,[0],[0]
Unfolding and Shrinking Neural Machine Translation Ensembles,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1951–1963 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
How should speakers and listeners reason about each other when they communicate?,1 Introduction,[0],[0]
"A core insight of computational pragmatics is that speaker and listener agents operate within a cooperative game-theoretic context, and that each agent benefits from reasoning about others’ intents and actions within that context.",1 Introduction,[0],[0]
"Pragmatic inference has been studied by a long line of work in linguistics, natural language processing, and cognitive science.",1 Introduction,[0],[0]
"In this paper, we present a technique for layering explicit pragmatic inference on top of models for complex, sequential instruction-following and instruction-generation tasks.",1 Introduction,[0],[0]
"We investigate a range of current data sets for both tasks, showing that pragmatic behavior arises naturally from this inference procedure, and gives rise to state-of-theart results in a variety of domains.
",1 Introduction,[0],[0]
"Consider the example shown in Figure 1a, in which a speaker agent must describe a route to
a target position in a hallway.",1 Introduction,[0],[0]
A conventional learned instruction-generating model produces a truthful description of the route (walk forward four times).,1 Introduction,[0],[0]
"But the pragmatic speaker in this paper, which is capable of reasoning about the listener, chooses to also include additional information (the intersection with the bare concrete hall), to reduce potential ambiguity and increase the odds that the listener reaches the correct destination.
",1 Introduction,[0],[0]
This same reasoning procedure also allows a listener agent to overcome ambiguity in instructions by reasoning counterfactually about the speaker (Figure 1b).,1 Introduction,[0],[0]
"Given the command walk along the blue carpet and you pass two objects, a conven-
1951
tional learned instruction-following model is willing to consider all paths that pass two objects, and ultimately arrives at an unintended final position.",1 Introduction,[0],[0]
"But a pragmatic listener that reasons about the speaker can infer that the long path would have been more easily described as go to the sofa, and thus that the shorter path is probably intended.",1 Introduction,[0],[0]
"In these two examples, which are produced by the system we describe in this paper, a unified reasoning process (choose the output sequence which is most preferred by an embedded model of the other agent) produces pragmatic behavior for both speakers and listeners.
",1 Introduction,[0],[0]
"The application of models with explicit pragmatic reasoning abilities has so far been largely restricted to simple reference games, in which the listener’s only task is to select the right item from among a small set of candidate referents given a single short utterance from the speaker.",1 Introduction,[0],[0]
"But as the example shows, there are real-world instruction following and generation tasks with rich action spaces that might also benefit from pragmatic modeling.",1 Introduction,[0],[0]
"Moreover, approaches that learn to map directly between human-annotated instructions and action sequences are ultimately limited by the effectiveness of the humans themselves.",1 Introduction,[0],[0]
"The promise of pragmatic modeling is that we can use these same annotations to build a model with a different (and perhaps even better) mechanism for interpreting and generating instructions.
",1 Introduction,[0],[0]
"The primary contribution of this work is to show how existing models of pragmatic reasoning can be extended to support instruction following and generation for challenging, multi-step, interactive tasks.",1 Introduction,[0],[0]
Our experimental evaluation focuses on four instruction-following domains which have been studied using both semantic parsers and attentional neural models.,1 Introduction,[0],[0]
"We investigate the interrelated tasks of instruction following and instruction generation, and show that incorporating an explicit model of pragmatics helps in both cases.",1 Introduction,[0],[0]
Reasoning about the human listener allows a speaker model to produce instructions that are easier for humans to interpret correctly in all domains (with absolute gains in accuracy ranging from 12% to 46%).,1 Introduction,[0],[0]
"Similarly, reasoning about the human speaker improves the accuracy of the listener models in interpreting instructions in most domains (with gains in accuracy of up to 10%).",1 Introduction,[0],[0]
"In all cases, the resulting systems are competitive with, and in many cases exceed, results from past
state-of-the-art systems for these tasks.1",1 Introduction,[0],[0]
"Consider the instruction following and instruction generation tasks shown in Figure 1, where an agent must produce or interpret instructions about a structured world context (e.g. walk along the blue carpet and you pass two objects).
",2 Problem Formulation,[0],[0]
"In the instruction following task, a listener agent begins in a world state (in Figure 1 an initial map location and orientation).",2 Problem Formulation,[0],[0]
The agent is then tasked with following a sequence of direction sentences d1 . . .,2 Problem Formulation,[0],[0]
dK produced by humans.,2 Problem Formulation,[0],[0]
"At each time t the agent receives a percept yt, which is a feature-based representation of the current world state, and chooses an action at (e.g. move forward, or turn).",2 Problem Formulation,[0],[0]
"The agent succeeds if it is able to reach the correct final state described by the directions.
",2 Problem Formulation,[0],[0]
"In the instruction generation task, the agent receives a sequence of actions a1, · · · aT along with the world state y1, · · · yT at each action, and must generate a sequence of direction sentences d1, . . .",2 Problem Formulation,[0],[0]
dK describing the actions.,2 Problem Formulation,[0],[0]
"The agent succeeds if a human listener is able to correctly follow those directions to the intended final state.
",2 Problem Formulation,[0],[0]
We evaluate models for both tasks in four domains.,2 Problem Formulation,[0],[0]
"The first domain is the SAIL corpus of virtual environments and navigational directions (MacMahon et al., 2006; Chen and Mooney, 2011), where an agent navigates through a twodimensional grid of hallways with patterned walls and floors and a discrete set of objects (Figure 1 shows a portion of one of these hallways).
",2 Problem Formulation,[0],[0]
"In the three SCONE domains (Long et al., 2016), the world contains a number of objects with various properties, such as colored beakers which an agent can combine, drain, and mix.",2 Problem Formulation,[0],[0]
Instructions describe how these objects should be manipulated.,2 Problem Formulation,[0],[0]
"These domains were designed to elicit instructions with a variety of context-dependent language phenomena, including ellipsis and coreference (Long et al., 2016) which we might expect a model of pragmatics to help resolve (Potts, 2011).",2 Problem Formulation,[0],[0]
"The approach in this paper builds upon long lines of work in pragmatic modeling, instruction following, and instruction generation.
",3 Related Work,[0],[0]
"1Source code is available at http://github.com/ dpfried/pragmatic-instructions
Pragmatics Our approach to pragmatics (Grice, 1975) belongs to a general category of rational speech acts models (Frank and Goodman, 2012), in which the interaction between speakers and listeners is modeled as a probabilistic process with Bayesian actors (Goodman and Stuhlmüller, 2013).",3 Related Work,[0],[0]
"Alternative formulations (e.g. with bestresponse rather than probabilistic dynamics) are also possible (Golland et al., 2010).",3 Related Work,[0],[0]
"Inference in these models is challenging even when the space of listener actions is extremely simple (Smith et al., 2013), and one of our goals in the present work is to show how this inference problem can be solved even in much richer action spaces than previously considered in computational pragmatics.",3 Related Work,[0],[0]
"This family of pragmatic models captures a number of important linguistic phenomena, especially those involving conversational implicature (Monroe and Potts, 2015); we note that many other topics studied under the broad heading of “pragmatics,” including presupposition and indexicality, require different machinery.
",3 Related Work,[0],[0]
Williams et al. (2015) use pragmatic reasoning with weighted inference rules to resolve ambiguity and generate clarification requests in a humanrobot dialog task.,3 Related Work,[0],[0]
Other recent work on pragmatic models focuses on the referring expression generation or “contrastive captioning” task introduced by Kazemzadeh et al. (2014).,3 Related Work,[0],[0]
"In this family are approaches that model the listener at training time (Mao et al., 2016), at evaluation time (Andreas and Klein, 2016; Monroe et al., 2017; Vedantam et al., 2017; Su et al., 2017) or both (Yu et al., 2017b; Luo and Shakhnarovich, 2017).
",3 Related Work,[0],[0]
Other conditional sequence rescoring models that are structurally similar but motivated by concerns other than pragmatics include Li et al. (2016) and Yu et al. (2017a).,3 Related Work,[0],[0]
Lewis et al. (2017) perform a similar inference procedure for a competitive negotiation task.,3 Related Work,[0],[0]
The language learning model of Wang et al. (2016) also features a structured output space and uses pragmatics to improve online predictions for a semantic parsing model.,3 Related Work,[0],[0]
"Our approach in this paper performs both generation and interpretation, and investigates both structured and unstructured output representations.
",3 Related Work,[0],[0]
"Instruction following Work on instruction following tasks includes models that parse commands into structured representations processed by a rich execution model (Tellex et al., 2011; Chen, 2012; Artzi and Zettlemoyer, 2013; Guu
et al., 2017), and models that map directly from instructions to a policy over primitive actions (Branavan et al., 2009), possibly mediated by an intermediate alignment or attention variable (Andreas and Klein, 2015; Mei et al., 2016).",3 Related Work,[0],[0]
"We use a model similar to Mei et al. (2016) as our base listener in this paper, evaluating on the SAIL navigation task (MacMahon et al., 2006) as they did, as well as the SCONE context-dependent execution domains (Long et al., 2016).
",3 Related Work,[0],[0]
"Instruction generation Previous work has also investigated the instruction generation task, in particular for navigational directions.",3 Related Work,[0],[0]
"The GIVE shared tasks (Byron et al., 2009; Koller et al., 2010; Striegnitz et al., 2011) have produced a large number of interactive direction-giving systems, both rule-based and learned.",3 Related Work,[0],[0]
"The work most immediately related to the generation task in this paper is that of Daniele et al. (2017), which also focuses on the SAIL dataset but requires substantial additional structured annotation for training, while both our base and pragmatic speaker models learn directly from strings and action sequences.
",3 Related Work,[0],[0]
"Older work has studied the properties of effective human strategies for generating navigational directions (Anderson et al., 1991).",3 Related Work,[0],[0]
"Instructions of this kind can be used to extract templates for generation (Look, 2008; Dale et al., 2005), while here we focus on the more challenging problem of learning to generate new instructions from scratch.",3 Related Work,[0],[0]
"Like our pragmatic speaker model, Goeddel and Olson (2012) also reason about listener behavior when generating navigational instructions, but rely on rule-based models for interpretation.",3 Related Work,[0],[0]
"As a foundation for pragmatic inference, we assume that we have base listener and speaker models to map directions to actions and vice-versa.",4 Pragmatic inference procedure,[0],[0]
(Our notation for referring to models is adapted from Bergen et al. (2016).),4 Pragmatic inference procedure,[0],[0]
"The base listener, L0, produces a probability distribution over sequences of actions, conditioned on a representation of the directions and environment as seen before each action: PL0(a1:T |d1:K , y1:T ).",4 Pragmatic inference procedure,[0],[0]
"Similarly, the base speaker, S0, defines a distribution over possible descriptions conditioned on a representation of the actions and environment: PS0(d1:K |a1:T , y1:T ).
",4 Pragmatic inference procedure,[0],[0]
"Our pragmatic inference procedure requires these base models to produce candidate outputs from a given input (actions from descriptions, for
the listener; descriptions from actions, for the speaker), and calculate the probability of a fixed output given an input, but is otherwise agnostic to the form of the models.
",4 Pragmatic inference procedure,[0],[0]
We use standard sequence-to-sequence models with attention for both the base listener and speaker (described in Section 5).,4 Pragmatic inference procedure,[0],[0]
"Our models use segmented action sequences, with one segment (sub-sequence of actions) aligned with each description sentence dj , for all j ∈ {1 . . .K}.",4 Pragmatic inference procedure,[0],[0]
"This segmentation is either given as part of the training and testing data (in the instruction following task for the SAIL domain, and in both tasks for the SCONE domain, where each sentence corresponds to a single action), or is predicted by a separate segmentation model (in the generation task for the SAIL domain), see Section 5.",4 Pragmatic inference procedure,[0.9510530230413838],"['The best performance on WikiCoref is achieved by Ghaddar and Langlais (2016a) (“G&L” in Table 6) who introduced WikiCoref and design a domain-specific coreference resolver that makes use of the Wikipedia markups of a document as well as links to Freebase, which are annotated in WikiCoref.']"
"Using these base models as self-contained modules, we derive a rational speaker and rational listener that perform inference using embedded instances of these base models (Figure 2a).",4.1 Models,[0],[0]
"When describing an action sequence, a rational speaker S1 chooses a description that has a high chance of causing the listener modeled by L0 to follow the given actions:
S1(a1:T ) =",4.1 Models,[0],[0]
argmax,4.1 Models,[0],[0]
"d1:K
PL0(a1:T |d1:K , y1:T ) (1)
(noting that, in all settings we explore here, the percepts y1:T are completely determined by the actions",4.1 Models,[0],[0]
a1:T ).,4.1 Models,[0],[0]
"Conversely, a rational listener L1 follows a description by choosing an action sequence which has high probability of having caused the
speaker, modeled by S0, to produce the description:
L1(d1:K) = argmax",4.1 Models,[0],[0]
"a1:T
PS0(d1:K |a1:T , y1:T ) (2)
",4.1 Models,[0],[0]
"These optimization problems are intractable to solve for general base listener and speaker agents, including the sequence-to-sequence models we use, as they involve choosing an input (from a combinatorially large space of possible sequences) to maximize the probability of a fixed output sequence.",4.1 Models,[0],[0]
"We instead follow a simple approximate inference procedure, detailed in Section 4.2.
",4.1 Models,[0],[0]
We consider also incorporating the scores of the base model used to produce the candidates.,4.1 Models,[0],[0]
"For the case of the speaker, we define a combined rational speaker, denoted S0 · S1, that selects the candidate that maximizes a weighted product of probabilities under both the base listener and the base speaker:
argmax d1:K
PL0(a1:T |d1:K , y1:T )λ
× PS0(d1:K |a1:T , y1:T )1−λ (3)
for a fixed interpolation hyperparameter λ ∈",4.1 Models,[0],[0]
"[0, 1].",4.1 Models,[0],[0]
There are several motivations for this combination with the base speaker score.,4.1 Models,[0],[0]
"First, as argued by Monroe et al. (2017), we would expect varying degrees of base and reasoned interpretation in human speech acts.",4.1 Models,[0],[0]
"Second, we want the descriptions produced by the model to be fluent descriptions of the actions.",4.1 Models,[0],[0]
"Since the base models are trained discriminatively, maximizing the probability of an output sequence for a fixed input sequence, their scoring behaviors for fixed outputs paired with inputs dissimilar to those seen in the training set may be
poorly calibrated (for example when conditioning on ungrammatical descriptions).",4.1 Models,[0],[0]
"Incorporating the scores of the base model used to produce the candidates aims to prevent this behavior.
",4.1 Models,[0],[0]
"To define rational listeners, we use the symmetric formulation: first, draw candidate action sequences from L0.",4.1 Models,[0],[0]
"For L1, choose the actions that achieve the highest probability under S0; and for the combination model L0 · L1 choose the actions with the highest weighted combination of S0 and L0 (paralleling equation 3).",4.1 Models,[0],[0]
"As in past work (Smith et al., 2013; Andreas and Klein, 2016; Monroe et al., 2017), we approximate the optimization problems in equations 1, 2, and 3: use the base models to generate candidates, and rescore them to find ones that are likely to produce the desired behavior.
",4.2 Inference,[0],[0]
"In the case of the rational speaker S1, we use the base speaker S0 to produce a set of n candidate descriptions w(1)1:K1 . . .",4.2 Inference,[0],[0]
w,4.2 Inference,[0],[0]
"(n) 1:Kn
for the sequences a1:T , y1:T , using beam search.",4.2 Inference,[0],[0]
"We then find the score of each description under PL0 (using it as the input sequence for the observed output actions we want the rational speaker to describe), or a weighted combination of PL0 and the original candidate score PS0 , and choose the description w(j)1:Kj with the largest score, approximately solving the maximizations in equations 1 or 3, respectively.",4.2 Inference,[0],[0]
"We perform a symmetric procedure for the rational listener: produce action sequence candidates from the base listener, and rescore them using the base speaker.2
As the rational speaker must produce long output sequences (with multiple sentences), we interleave the speaker and listener in inference, determining each output sentence sequentially.",4.2 Inference,[0],[0]
"From a list of candidate direction sentences from the base speaker for the current subsequence of actions, we choose the top-scoring direction under the listener model (which may also condition on the directions which have been output previously), and then
2We use ensembles of models for the base listener and speaker (subsection 5.3), and to obtain candidates that are high-scoring under the combination of models in the ensemble, we perform standard beam search using all models in lock-step.",4.2 Inference,[0],[0]
"At every timestep of the beam search, each possible extension of an output sequence is scored using the product of the extension’s conditional probabilities across all models in the ensemble.
move on to the next subsequence of actions.3",4.2 Inference,[0],[0]
"Given this framework, all that remains is to describe the base models L0 and S0.",5 Base model details,[0],[0]
"We implement these as sequence-to-sequence models that map directions to actions (for the listener) or actions to directions (for the speaker), additionally conditioning on the world state at each timestep.",5 Base model details,[0],[0]
"Our base listener model, L0, predicts action sequences conditioned on an encoded representation of the directions and the current world state.",5.1 Base listener,[0],[0]
"In the SAIL domain, this is the model of Mei et al. (2016) (illustrated in green in Figure 2b for a single sentence and its associated actions), see “domain specifics” below.
",5.1 Base listener,[0],[0]
"Encoder Each direction sentence is encoded separately with a bidirectional LSTM (Hochreiter and Schmidhuber, 1997); the LSTM’s hidden states are reset for each sentence.",5.1 Base listener,[0],[0]
"We obtain a representation hek for the kth word in the current sentence by concatenating an embedding for the word with its forward and backward LSTM outputs.
",5.1 Base listener,[0],[0]
Decoder We generate actions incrementally using an LSTM decoder with monotonic alignment between the direction sentences and subsequences of actions; at each timestep the decoder predicts the next action for the current sentence w1:M (including choosing to shift to the next sentence).,5.1 Base listener,[0],[0]
"The decoder takes as input at timestep t the current world state, yt and a representation zt of the current sentence, updates the decoder state hd, and outputs a distribution over possible actions:
hdt = LSTMd(h d t−1, [Wyyt, zt])
qt =Wo(Wyyt +Whh d t +Wzzt)
p(at |",5.1 Base listener,[0],[0]
"a1:t−1, y1:t, w1:M ) ∝ exp(qt)
where all weight matrices W are learned parameters.",5.1 Base listener,[0],[0]
"The sentence representation zt is produced using an attention mechanism (Bahdanau et al., 2015) over the representation vectors he1 . . .",5.1 Base listener,[0],[0]
"h e M
3We also experimented with sampling from the base models to produce these candidate lists, as was done in previous work (Andreas and Klein, 2016; Monroe et al., 2017).",5.1 Base listener,[0],[0]
"In early experiments, however, we found better performance with beam search in the rational models for all tasks.
for words in the current sentence:
",5.1 Base listener,[0],[0]
"αt,k ∝ exp(v · tanh(Wdhdt−1 +Wehek))
",5.1 Base listener,[0],[0]
"zt =
M∑
k=1
αt,kh e k
where the attention weights αt,k are normalized to sum to one across positions k in the input, and weight matrices W and vector v are learned.
",5.1 Base listener,[0],[0]
"Domain specifics For SAIL, we use the alignments between sentences and route segments annotated by Chen and Mooney (2011), which were also used in previous work (Artzi and Zettlemoyer, 2013; Artzi et al., 2014; Mei et al., 2016).",5.1 Base listener,[0],[0]
"Following Mei et al. (2016), we reset the decoder’s hidden state for each sentence.
",5.1 Base listener,[0],[0]
"In the SCONE domains, which have a larger space of possible outputs than SAIL, we extend the decoder by: (i) decomposing each action into an action type and arguments for it, (ii) using separate attention mechanisms for types and arguments and (iii) using state-dependent action embeddings.",5.1 Base listener,[0],[0]
See Appendix A in the supplemental material for details.,5.1 Base listener,[0],[0]
The SCONE domains are constructed so that each sentence corresponds to a single (nondecomposed) action; this provides our segmentation of the action sequence.,5.1 Base listener,[0],[0]
"While previous work (Daniele et al., 2017) has relied on more structured approaches, we construct our base speaker model S0 using largely the same sequence-to-sequence machinery as above.",5.2 Base speaker,[0],[0]
"S0 (illustrated in orange in Figure 2b) encodes a sequence of actions and world states, and then uses a decoder to output a description.
",5.2 Base speaker,[0],[0]
Encoder We encode the sequence of vector embeddings for the actions at and world states yt using a bidirectional LSTM.,5.2 Base speaker,[0],[0]
"Similar to the base listener’s encoder, we then obtain a representation het for timestep t by concatenating at and yt with the LSTM outputs at that position.
",5.2 Base speaker,[0],[0]
Decoder,5.2 Base speaker,[0],[0]
"As in the listener, we use an LSTM decoder with monotonic alignment between direction sentences and subsequences of actions, and attention over the subsequences of actions.",5.2 Base speaker,[0],[0]
"The decoder takes as input at position k an embedding for the previously generated word wk−1 and a representation zk of the current subsequence of
actions and world states, and produces a distribution over words (including ending the description for the current subsequence and advancing to the next).",5.2 Base speaker,[0],[0]
"The decoder’s output distribution is produced by:
hdk = LSTMd(h d k−1, [wk−1, zk]) qk =Whh d k",5.2 Base speaker,[0],[0]
"+Wzzk
p(wk | w1:k−1, a1:T , y1:T ) ∝",5.2 Base speaker,[0],[0]
"exp(qk)
",5.2 Base speaker,[0],[0]
where all weight matrices W are learned parameters.4,5.2 Base speaker,[0],[0]
"As in the base listener, the input representation zk is produced by attending to the vectors he1 . . .",5.2 Base speaker,[0],[0]
"h e T encoding the input sequence (here, encoding the subsequence of actions and world states to be described):
αk,t ∝",5.2 Base speaker,[0],[0]
exp(v · tanh(Wdhdk−1,5.2 Base speaker,[0],[0]
"+Wehet ))
",5.2 Base speaker,[0],[0]
"zk = T∑
t=1
αk,t h e t
",5.2 Base speaker,[0],[0]
"The decoder’s LSTM state is reset at the beginning of each sentence.
",5.2 Base speaker,[0],[0]
"Domain specifics In SAIL, for comparison to the generation system of Daniele et al. (2017) which did not use segmented routes, we train a route segmenter for use at test time.",5.2 Base speaker,[0],[0]
We also represent routes using a collapsed representation of action sequences.,5.2 Base speaker,[0],[0]
"In the SCONE domains, we (i) use the same context-dependent action embeddings used in the listener, and (ii) don’t require an attention mechanism, since only a single action is used to produce a given sentence within the sequence of direction sentences.",5.2 Base speaker,[0],[0]
See Appendix A for more details.,5.2 Base speaker,[0],[0]
The base listener and speaker models are trained independently to maximize the conditional likelihoods of the actions–directions pairs in the training sets.,5.3 Training,[0],[0]
"See Appendix A for details on the optimization, LSTM variant, and hyperparameters.
",5.3 Training,[0],[0]
"We use ensembles for the base listener L0 and base speaker S0, where each ensemble consists of 10 models trained from separate random parameter initializations.",5.3 Training,[0],[0]
"This follows the experimental setup of Mei et al. (2016) for the SAIL base listener.
",5.3 Training,[0],[0]
4All parameters are distinct from those used in the base listener; the listener and speaker are trained separately.,5.3 Training,[0],[0]
We evaluate speaker and listener agents on both the instruction following and instruction generation tasks in the SAIL domain and three SCONE domains (Section 2).,6 Experiments,[0],[0]
"For all domains, we compare the rational listener and speaker against the base listener and speaker, as well as against past state-of-the-art results for each task and domain.",6 Experiments,[0],[0]
"Finally, we examine pragmatic inference from a model combination perspective, comparing the pragmatic reranking procedure to ensembles of a larger number of base speakers or listeners.
",6 Experiments,[0],[0]
"For all experiments, we use beam search both to generate candidate lists for the rational systems (section 4.2) and to generate the base model’s output.",6 Experiments,[0],[0]
"We fix the beam size n to be the same in both the base and rational systems, using n = 20 for the speakers and n = 40 for the listeners.",6 Experiments,[0],[0]
We tune the weight λ in the combined rational agents (L0 · L1 or S0 · S1) to maximize accuracy (for listener models) or BLEU (for speaker models) on each domain’s development data.,6 Experiments,[0],[0]
"We evaluate our listener models by their accuracy in carrying out human instructions: whether the systems were able to reach the final world state which the human was tasked with guiding them to.
",6.1 Instruction following,[0],[0]
"SAIL We follow standard cross-validation evaluation for the instruction following task on the SAIL dataset (Artzi and Zettlemoyer, 2013; Artzi
a red guy appears on the far left then to orange’s other side
et al., 2014; Mei et al., 2016).5 Table 1 shows improvements over the base listener L0 when using the rational listener L0 · L1 in the single- and multi-sentence settings.",6.1 Instruction following,[0],[0]
We also report the best accuracies from past work.,6.1 Instruction following,[0],[0]
"We see that the largest relative gains come in the multi-sentence setting, where handling ambiguity is potentially more important to avoid compounding errors.",6.1 Instruction following,[0],[0]
"The rational model improves on the published results of Mei et al. (2016), and while it is still below the systems of Artzi and Zettlemoyer (2013) and Artzi et al. (2014), which use additional supervision in the form of hand-annotated seed lexicons and logical domain representations, it approaches their results in the single-sentence setting.
",6.1 Instruction following,[0],[0]
"SCONE In the SCONE domains, past work has trained listener models with weak supervision
5Past work has differed in the handling of undetermined orientations in the routes, which occur in the first state for multi-sentence routes and the first segment of their corresponding single-sentence routes.",6.1 Instruction following,[0],[0]
"For comparison to both types of past work, we train and evaluate listeners in two settings: Abs, which sets these undetermined starting orientations to be a fixed absolute orientation, and Rel, where an undetermined starting orientation is set to be a 90 degree rotation from the next state in the true route.
",6.1 Instruction following,[0],[0]
(with no intermediate actions between start and end world states) on a subset of the full SCONE training data.,6.1 Instruction following,[0],[0]
"We use the full training set, and to use a model and training procedure consistent with the SAIL setting, train listener and speaker models using the intermediate actions as supervision as well.6 The evaluation method and test data are the same as in past work on SCONE: models are provided with an initial world state and a sequence of 5 instructions to carry out, and are evaluated on their accuracy in reaching the intended final world state.
",6.1 Instruction following,[0],[0]
Results are reported in Table 2.,6.1 Instruction following,[0],[0]
We see gains from the rational system L0 · L1 in both the Alchemy and Scene domains.,6.1 Instruction following,[0],[0]
The pragmatic inference procedure allows correcting errors or overly-literal interpretations from the base listener.,6.1 Instruction following,[0],[0]
An example is shown in Figure 3.,6.1 Instruction following,[0],[0]
"The base listener (left) interprets then to orange’s other side incorrectly, while the rational listener discounts this interpretation (it could, for example, be better described by to the left of blue) and produces the action the descriptions were meant to describe (right).",6.1 Instruction following,[0],[0]
"To the extent that human annotators already account for pragmatic effects when generating instructions, examples like these suggest that our model’s explicit reasoning is able to capture interpretation behavior that the base sequence-tosequence listener model is unable to model.",6.1 Instruction following,[0],[0]
"As our primary evaluation for the instruction generation task, we had Mechanical Turk workers carry out directions produced by the speaker mod-
6Since the pragmatic inference procedure we use is agnostic to the models’ training method, it could also be applied to the models of Guu et al. (2017); however we find that pragmatic inference can improve even upon our stronger base listener models.
",6.2 Instruction generation,[0],[0]
els (and by other humans) in a simulated version of each domain.,6.2 Instruction generation,[0],[0]
"For SAIL, we use the simulator released by Daniele et al. (2017) which was used in their human evaluation results, and we construct simulators for the three SCONE domains.",6.2 Instruction generation,[0],[0]
"In all settings, we take a sample of 50 action sequences from the domain’s test set (using the same sample as Daniele et al. (2017) for SAIL), and have three separate Turk workers attempt to follow the systems’ directions for the action sequence.
",6.2 Instruction generation,[0],[0]
"Table 3 gives the average accuracy of subjects in reaching the intended final world state across all sampled test instances, for each domain.",6.2 Instruction generation,[0],[0]
The “human-generated” row reports subjects’ accuracy at following the datasets’ reference directions.,6.2 Instruction generation,[0],[0]
"The directions produced by the base speaker S0 are often much harder to follow than those produced by humans (e.g. 29.3% of S0’s directions are correctly interpretable for Alchemy, vs. 83.3% of human directions).",6.2 Instruction generation,[0],[0]
"However, we see substantial gains from the rational speaker S0 ·S1 over S0 in all cases (with absolute gains in accuracy ranging from 12.4% to 46.0%), and the average accuracy of humans at following the rational speaker’s directions is substantially higher than for humanproduced directions in the Tangrams domain.",6.2 Instruction generation,[0],[0]
"In the SAIL evaluation, we also include the directions produced by the system of Daniele et al. (2017) (DBW), and find that the rational speaker’s directions are followable to comparable accuracy.
",6.2 Instruction generation,[0],[0]
"We also compare the directions produced by the systems to the reference instructions given by humans in the dataset, using 4-gram BLEU7 (Pap-
7See Appendix A for details on evaluating BLEU in the SAIL setting, where there may be a different number of reference and predicted sentences for a given example.
",6.2 Instruction generation,[0],[0]
"ineni et al., 2002) in Table 4.",6.2 Instruction generation,[0],[0]
"Consistent with past work (Krahmer and Theune, 2010), we find that BLEU score is a poor indicator of whether the directions can be correctly followed.
",6.2 Instruction generation,[0],[0]
"Qualitatively, the rational inference procedure is most successful in fixing ambiguities in the base speaker model’s descriptions.",6.2 Instruction generation,[0],[0]
Figure 4 gives a typical example of this for the last few timesteps from a Tangrams instance.,6.2 Instruction generation,[0],[0]
"The base speaker correctly describes that the shape should be added back, but does not specify where to add it, which could lead a listener to add it in the same position it was deleted.",6.2 Instruction generation,[0],[0]
The human speaker also makes this mistake in their description.,6.2 Instruction generation,[0],[0]
This speaks to the difficulty of describing complex actions pragmatically even for humans in the Tangrams domain.,6.2 Instruction generation,[0],[0]
The ability of the pragmatic speaker to produce directions that are easier to follow than humans’ in this domain (Table 3) shows that the pragmatic model can generate something different (and in some cases better) than the training data.,6.2 Instruction generation,[0],[0]
"Finally, our rational models can be viewed as pragmatically-motivated model combinations, producing candidates using base listener or speaker models and reranking using a combination of scores from both.",6.3 Pragmatics as model combination,[0],[0]
"We want to verify that a rational listener using n ensembled base listeners and n base speakers outperforms a simple ensemble of 2n base listeners (and similarly for the rational speaker).
",6.3 Pragmatics as model combination,[0],[0]
"Fixing the total number of models to 20 in each
listener experiment, we find that the rational listener (using an ensemble of 10 base listener models and 10 base speaker models) still substantially outperforms the ensembled base listener (using 20 base listener models): accuracy gains are 68.5→ 71.6%, 70.1 → 72.0%, 71.9 → 72.7%, and 69.1 → 69.6% for SAIL single-sentence Rel, Alchemy, Scene, and Tangrams, respectively.
",6.3 Pragmatics as model combination,[0],[0]
"For the speaker experiments, fixing the total number of models to 10 (since inference in the speaker models is more expensive than in the follower models), we find similar gains as well: the rational speaker improves human accuracy at following the generated instructions from 61.9 → 73.4%, 30.7 → 74.7%, 32.0 → 66.0%, 58.7 → 92.7%, for SAIL, Alchemy, Scene, and Tangrams, respectively.8",6.3 Pragmatics as model combination,[0],[0]
"We have demonstrated that a simple procedure for pragmatic inference, with a unified treatment for speakers and listeners, obtains improvements for instruction following as well as instruction generation in multiple settings.",7 Conclusion,[0],[0]
"The inference procedure is capable of reasoning about sequential, interdependent actions in non-trivial world contexts.",7 Conclusion,[0],[0]
"We find that pragmatics improves upon the performance of the base models for both tasks, in most cases substantially.",7 Conclusion,[0],[0]
"While this is perhaps unsurprising for the generation task, which has been discussed from a pragmatic perspective in a variety of recent work in NLP, it is encouraging that pragmatic reasoning can also improve performance for a grounded listening task with sequential, structured output spaces.",7 Conclusion,[0],[0]
"We are grateful to Andrea Daniele for sharing the SAIL simulator and their system’s outputs, to Hongyuan Mei for help with the dataset, and to Tom Griffiths and Chris Potts for helpful comments and discussion.",Acknowledgments,[0],[0]
This work was supported by DARPA through the Explainable Artificial Intelligence (XAI) program.,Acknowledgments,[0],[0]
DF is supported by a Huawei / Berkeley AI fellowship.,Acknowledgments,[0],[0]
"JA is supported by a Facebook graduate fellowship.
8The accuracies for the base speakers are slightly different than in Table 3, despite being produced by the same systems, since we reran experiments to control as much as possible for time variation in the pool of Mechanical Turk workers.",Acknowledgments,[0],[0]
"A.1 SCONE listener details We factor action production in each of the three SCONE domains, separately predicting the action type and the arguments specific to that action type.",A Supplemental Material,[0],[0]
Action types and arguments are listed in the first two columns of Table 5.,A Supplemental Material,[0],[0]
"For example, Alchemy’s actions involve predicting the action type, a potential source beaker index i and target beaker index j, and potential amount to drain a.",A Supplemental Material,[0],[0]
"All factors of the action (the type and options for each argument) are predicted using separate attention mechanisms, which produce a vector qf giving unnormalized scores for factor f (e.g. scoring each possible type, or each possible choice for the argument).
",A Supplemental Material,[0],[0]
"We also obtain state-specific embeddings of actions, to make it easier for the model to learn relevant features from the state embeddings (e.g. rather than needing to learn to select the region of the state vector corresponding to the 5th beaker in the action MIX(5) in Alchemy, this action’s contextual embedding encodes the current content of the 5th beaker).",A Supplemental Material,[0],[0]
"We incorporate these statespecific embeddings into computation of the action probabilities using a bilinear bonus score:
b(a) = q>Wqaa+ w>a a
where q is the concatenation of all qf factor scoring vectors, and Wqa and wa are a learned parameter matrix and vector, respectively.",A Supplemental Material,[0],[0]
"This bonus score b(a) for each action is added to the un-
normalized score for the corresponding action a (computed by summing the entries of the qf vectors which correspond to the factored action components), and the normalized output distribution is then produced using a softmax over all valid actions.
",A Supplemental Material,[0],[0]
"A.2 SAIL speaker details Since our speaker model operates on segmented action sequences, we train a route segmenter on the training data and then predict segmentations for the test data.",A Supplemental Material,[0],[0]
This provides a closer comparison to the generation system of Daniele et al. (2017) which did not use segmented routes.,A Supplemental Material,[0],[0]
"The route segmenter runs a bidirectional LSTM over the concatenated state and action embeddings (as in the speaker encoder), then uses a logistic output layer to classify whether the route should be split at each possible timestep.",A Supplemental Material,[0],[0]
"We also collapse consecutive sequences of forward movement actions into single actions (e.g. MOVE4 representing four consecutive forward movements), which we found helped prevent counting errors (such as outputting move forward three when the correct route moved forward four steps).
",A Supplemental Material,[0],[0]
"A.3 SCONE speaker details We use a one-hot representation of the arguments (see Table 5) and contextual embedding (as described in A.1) for each action at as input to the SCONE speaker encoder at time t (along with the representation et of the world state, as in SAIL).",A Supplemental Material,[0],[0]
"Since SCONE uses a monotonic, one-toone alignment between actions and direction sentences, the decoder does not use a learned attention mechanism but fixes the contextual representation zk to be the encoded vector at the action corresponding to the sentence currently being generated.
",A Supplemental Material,[0],[0]
"A.4 Training details We optimize model parameters using ADAM (Kingma and Ba, 2015) with default hyperparameters and the initialization scheme of Glorot and Bengio (2010).",A Supplemental Material,[0],[0]
All LSTMs have one layer.,A Supplemental Material,[0],[0]
"The LSTM cell in both the listener and the follower use coupled input and forget gates, and peephole connections to the cell state (Greff et al., 2016).",A Supplemental Material,[0],[0]
"We also apply the LSTM variational dropout scheme of Gal and Ghahramani (2016), using the same dropout rate for inputs, outputs, and recurrent connections.",A Supplemental Material,[0],[0]
See Table 6 for hyperparameters.,A Supplemental Material,[0],[0]
"We
perform early stopping using the evaluation metric (accuracy for the listener and BLEU score for the speaker) on the development set.
",A Supplemental Material,[0],[0]
"A.5 Computing BLEU for SAIL To compute BLEU in the SAIL experiments, as the speaker models may choose produce a different number of sentences for each route than in the true description, we obtain a single sequence of words from a multi-sentence description produced for a route by concatenating the sentences, separated by end-of-sentence tokens.",A Supplemental Material,[0],[0]
We then calculate corpus-level 4-gram BLEU between all these sequences in the test set and the true multisentence descriptions (concatenated in the same way).,A Supplemental Material,[0],[0]
"We show that explicit pragmatic inference aids in correctly generating and following natural language instructions for complex, sequential tasks.",abstractText,[0],[0]
"Our pragmatics-enabled models reason about why speakers produce certain instructions, and about how listeners will react upon hearing them.",abstractText,[0],[0]
"Like previous pragmatic models, we use learned base listener and speaker models to build a pragmatic speaker that uses the base listener to simulate the interpretation of candidate descriptions, and a pragmatic listener that reasons counterfactually about alternative descriptions.",abstractText,[0],[0]
We extend these models to tasks with sequential structure.,abstractText,[0],[0]
Evaluation of language generation and interpretation shows that pragmatic inference improves state-of-the-art listener models (at correctly interpreting human instructions) and speaker models (at producing instructions correctly interpreted by humans) in diverse settings.,abstractText,[0],[0]
Unified Pragmatic Models for Generating and Following Instructions,title,[0],[0]
"KDE (Rosenblatt, 1956; Parzen, 1962) is a foundational aspect of nonparametric statistics.",1. Introduction,[0],[0]
It is a powerful method to estimate the probability density function of a random variable.,1. Introduction,[0],[0]
"Moreover, it is simple to compute and has played a significant role in a very wide range of practical applications.",1. Introduction,[0],[0]
"Its convergence properties have been studied for a long time with most of the work dedicated to its asymptotic behavior or mean-squared risk (Tsybakov, 2008).",1. Introduction,[0],[0]
"However, there is still a surprising amount not yet fully understood about its convergence behavior.",1. Introduction,[0],[0]
"In this paper, we focus on the uniform finite-sample facet of KDE convergence theory.",1. Introduction,[0],[0]
We handle the multivariate KDE setting in Rd which allows a d × d bandwidth matrix H. This generalizes the scalar bandwidth h > 0,1. Introduction,[0],[0]
"i.e. H = h2I. Such a generalization is significant to multivariate statistics e.g. Silverman (1986); Simonoff (1996).
",1. Introduction,[0],[0]
Our work begins by using VC-based Bernstein-type uniform convergence bounds to attain finite-sample rates for a fixed unknown density f over Rd (Theorem 1).,1. Introduction,[0],[0]
"These bounds hold with high-probability under general assumptions on f and the kernel i.e. we only require f to be
1Google.",1. Introduction,[0],[0]
"Correspondence to: Heinrich Jiang <heinrich.jiang@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
bounded as well as decay assumptions on the kernel functions.,1. Introduction,[0],[0]
"Moreover, these bounds hold uniformly over Rd and bandwidth matrices H.
We then show the versatility of our results by applying it to the related areas of KDE rates under `∞, mode estimation, density level-set estimation, and class probability estimation.",1. Introduction,[0],[0]
We then extend our analysis to the manifold setting.,1. Introduction,[0],[0]
"Finally, we provide uniform finite-sample results for local intrinsic dimension estimation.",1. Introduction,[0],[0]
Each of these contributions are significant on their own.,1. Introduction,[0],[0]
`∞ bounds for KDE: It must first be noted that bounding |f̂h − f |∞ where f̂h is the KDE of f for scalar h > 0 is a more difficult problem than for example bounding the mean-squared error,2. Contributions and Related Works,[0],[0]
Ef,2. Contributions and Related Works,[0],[0]
[(f̂h − f)2].,2. Contributions and Related Works,[0],[0]
"Gine & Guillon (2002) and Einmahl & Mason (2005) give asymptotic convergence results on KDE for |f̂h − Ef f̂h|∞. In their work about density clustering, Rinaldo & Wasserman (2010) extends the results of the former to obtain high-probability finitesample bounds.",2. Contributions and Related Works,[0],[0]
This is to our knowledge the strongest and most general uniform finite-sample result about KDE thus far.,2. Contributions and Related Works,[0],[0]
We show a general bound of form |f̂h(x) − f(x)| .,2. Contributions and Related Works,[0],[0]
x,2. Contributions and Related Works,[0],[0]
+√ log n/nhd where x is a function of the kernel and the smoothness of f at x which holds with probability 1− 1/n uniformly over x ∈ Rd and h (Theorem 1).,2. Contributions and Related Works,[0],[0]
"An almost direct consequence is that if we take f to be α-Hölder continuous then under the optimal choice for h ≈ n−1/(2α+d), we have |f̂h−f |∞ .",2. Contributions and Related Works,[0],[0]
n−α/(2α+d),2. Contributions and Related Works,[0],[0]
with probability 1−1/n,2. Contributions and Related Works,[0],[0]
(Theorem 2).,2. Contributions and Related Works,[0],[0]
"This matches the known lower bound (Tsybakov, 2008).
",2. Contributions and Related Works,[0],[0]
"When comparing our finite-sample results to that of Rinaldo & Wasserman (2010), there are a few notable differences.",2. Contributions and Related Works,[0],[0]
"Our results hold uniformly across bandwidths and the probability that the bounds hold are independent of the bandwidth (in fact, holds with probability 1 − 1/n).",2. Contributions and Related Works,[0],[0]
"Our results also extends to general bandwidth matrix H.
This can be significant to analyze KDE-based procedures with adaptive bandwidths– i.e. when the bandwidths change depending on the region.",2. Contributions and Related Works,[0],[0]
"Then the need for bounds which hold simultaneously over bandwidth choices be-
comes clear.",2. Contributions and Related Works,[0],[0]
"Such an example includes adaptive or variable KDE (Terrell & Scott, 1992; Botev et al., 2010) which extends KDE to bandwidths that vary over the data space.
",2. Contributions and Related Works,[0],[0]
"Thus our result for uniform finite-sample KDE bounds can be seen as a refinement to existing results.
",2. Contributions and Related Works,[0],[0]
Mode estimation Estimating the modes of a distribution has a long history e.g. Parzen (1962); Chernoff (1964); Eddy (1980); Silverman (1981); Cheng (1995); Abraham et al. (2004); Li et al. (2007); Dasgupta & Kpotufe (2014); Genovese et al. (2015); Jiang & Kpotufe (2017).,2. Contributions and Related Works,[0],[0]
"The modes can be viewed as the central tendancies of a distribution and this line of work has played a significant role in areas such as clustering, image segmentation, and anomaly detection.
",2. Contributions and Related Works,[0],[0]
Much of the early work focused on the estimator argmaxx∈Rd f̂h(x).,2. Contributions and Related Works,[0],[0]
"While many useful insights have come from studying this, it is difficult to algorithmically compute.",2. Contributions and Related Works,[0],[0]
Abraham et al. (2004) turned to the simple estimator argmaxx∈X f̂h(x) and showed that it behaves asymptotically as argmaxx∈Rd f̂h(x) where X is the data.,2. Contributions and Related Works,[0],[0]
"In this paper, we show that this estimator is actually a rate-optimal estimator of the mode under finite samples with appropriate bandwidth choice.",2. Contributions and Related Works,[0],[0]
This would not have been possible without the appropriate bounds on KDE.,2. Contributions and Related Works,[0],[0]
"This approach is similar to that of Dasgupta & Kpotufe (2014), who apply their k-NN density estimation bounds to show that the kNN analogue of the estimator is rate-optimal.
",2. Contributions and Related Works,[0],[0]
"Another approach to mode estimation that must be noted is mean-shift (Fukunaga & Hostetler, 1975; Cheng, 1995; Comaniciu & Meer, 2002; Arias-Castro et al., 2016), which is a popular clustering algorithm amongst practitioners based on performing a gradient-ascent of the KDE.",2. Contributions and Related Works,[0],[0]
Its theoretical analysis however is still far from complete; the difficulty comes from analyzing KDE’s ability to estimate gradients.,2. Contributions and Related Works,[0],[0]
"Here we are focused on density estimation rather than density derivative estimation so our results do not appear immediately applicable to mean-shift.
",2. Contributions and Related Works,[0],[0]
Density level-set estimation The problem of density-level set estimation has been extensively studied e.g. Carmichael et al. (1968); Hartigan (1975); Cuevas & Fraiman (1997); Tsybakov (1997); Cadre (2006); Rigollet & Vert (2009); Singh et al. (2009); Rinaldo & Wasserman (2010); Steinwart (2011); Jiang (2017).,2. Contributions and Related Works,[0],[0]
It involves estimating {x : f(x) ≥ λ} for some λ > 0 and density f based on samples drawn from f .,2. Contributions and Related Works,[0],[0]
This turns out to be one of the earliest and still currently most popular means of modeling clusters in the context of density-based clustering.,2. Contributions and Related Works,[0],[0]
"The level-sets also influenced much of the work on hierarchical clustering (Chaudhuri & Dasgupta, 2010).
",2. Contributions and Related Works,[0],[0]
"Naturally, we must use some density estimator to get a handle on λ.",2. Contributions and Related Works,[0],[0]
"It turns out that in order to obtain the most gen-
eral uniform recovery bounds (e.g. finite-sample Hausdorff rates (Singh et al., 2009)), one also needs similar uniform density estimation bounds.",2. Contributions and Related Works,[0],[0]
The strongest known results thus far use density estimators that are often impractical (e.g. histogram density estimator) in order to obtain these theoretical rates over a practical one such as KDE.,2. Contributions and Related Works,[0],[0]
"Much of the work, especially ones using more practical density estimators have focused on bounding metrics such as symmetric set difference, which are computed as an expectation over f .",2. Contributions and Related Works,[0],[0]
"This is considerably weaker than the Hausdorff metric, which imposes a uniform guarantee over each estimated point and each point in the level-set.
",2. Contributions and Related Works,[0],[0]
"We show that a simple KDE-based estimator is consistent under the Hausdorff metric; moreoever when the bandwidth is appropriately chosen, it attains the minimax optimal rate established by Tsybakov (1997).
",2. Contributions and Related Works,[0],[0]
Class probability estimation Class probability estimation involves estimating the probability distribution over a set of classes for a given input.,2. Contributions and Related Works,[0],[0]
"In other words, it is an approach to classification which involves first estimating the marginal density f(Y |X) (where X is the observation and Y is its category) and then choosing the category with highest probability.",2. Contributions and Related Works,[0],[0]
This density-based approach to classification has been studied in many places under nonparametric assumptions.,2. Contributions and Related Works,[0],[0]
e.g. Rigollet (2007); Chaudhuri et al. (2009).,2. Contributions and Related Works,[0],[0]
"However, there are still aspects about its convergence properties that haven’t been fully understood.",2. Contributions and Related Works,[0],[0]
"In the current work, we give uniform rates on the approximation of f(Y |X).",2. Contributions and Related Works,[0],[0]
Much of the related work assume the binary classification case and derive a hard classifier based on the marginal density and compare the risk between that and the Bayes-optimal classifier.,2. Contributions and Related Works,[0],[0]
"Our work differs in that we give uniform bounds on the recovery of the marginal density, which is a considerably stronger notion of consistency.",2. Contributions and Related Works,[0],[0]
"This is important in situations where a worst-case bound on classifier performance is required.
",2. Contributions and Related Works,[0],[0]
Density Estimation on Manifolds Density estimation on manifolds has received much less attention than the fulldimensional counterpart.,2. Contributions and Related Works,[0],[0]
"However, understanding density estimation in situations where the intrinsic dimension can be much lower than the ambient dimension is becoming ever more important: modern systems are able to capture data at an increasing resolution while the number of degrees of freedom stays relatively constant.",2. Contributions and Related Works,[0],[0]
One of the limiting aspects of density-based approaches is their performance in high dimensions.,2. Contributions and Related Works,[0],[0]
It takes an exponential in dimension number of samples to estimate the density – this is the so-called curse of dimensionality.,2. Contributions and Related Works,[0],[0]
"Here we give results whose rates of convergence depend on the dimension of the manifold dM compared to a much higher ambient dimension d; thus the convergence properties become much more attractive under the manifold hypothesis.
",2. Contributions and Related Works,[0],[0]
Local Intrinsic Dimension Estimation Many learning algorithms require the intrinsic dimension as an input in order to take advantage of the lower dimensional structure that arises.,2. Contributions and Related Works,[0],[0]
"There has been much work on estimating the intrinsic dimension of the data given finite samples e.g. (Kégl, 2003).",2. Contributions and Related Works,[0],[0]
"However, the more interesting problem of estimating the local intrinsic dimension has received much less attention.",2. Contributions and Related Works,[0],[0]
"The bulk of the work in this area e.g. (Costa et al., 2005; Houle, 2013; Amsaleg et al., 2015) provide interesting estimators, but are unable to establish strong finitesample guarantees under nonparametric assumptions.",2. Contributions and Related Works,[0],[0]
"In this paper, we consider a simple notion of local intrinsic dimension based on the doubling dimension and utilize a simple estimator.",2. Contributions and Related Works,[0],[0]
We then give a uniform finite-sample convergence result for the estimator under nonparametric assumptions.,2. Contributions and Related Works,[0],[0]
"To the best of our knowledge, this is perhaps the strongest finite-sample result obtained this far for this problem.",2. Contributions and Related Works,[0],[0]
Definition 1.,3. Background and Setup,[0],[0]
Let f be a probability density over Rd with corresponding distribution F .,3. Background and Setup,[0],[0]
"Let X = {X1, ..., Xn} be n i.i.d.",3. Background and Setup,[0],[0]
samples drawn from it and letFn denote the empirical distribution w.r.t.,3. Background and Setup,[0],[0]
X .,3. Background and Setup,[0],[0]
i.e. Fn(A) = 1n,3. Background and Setup,[0],[0]
∑n i=1,3. Background and Setup,[0],[0]
"1{Xi ∈ A}.
",3. Background and Setup,[0],[0]
"We only require that f is bounded.
Assumption 1.",3. Background and Setup,[0],[0]
||f ||∞ <∞. Definition 2.,3. Background and Setup,[0],[0]
"Define kernel function K : Rd → R≥0 where R≥0 denotes the non-negative real numbers such that∫
Rd K(u)du = 1.
",3. Background and Setup,[0],[0]
"We make the following mild regularity assumptions on K.
Assumption 2.",3. Background and Setup,[0],[0]
(Spherically Symmetric and nonincreasing),3. Background and Setup,[0],[0]
There exists non-increasing function k : R≥0 → R≥0 such that K(u) = k(|u|) for u ∈ Rd.,3. Background and Setup,[0],[0]
Assumption 3.,3. Background and Setup,[0],[0]
(Exponential Decays),3. Background and Setup,[0],[0]
"There exists ρ, Cρ, t0 > 0",3. Background and Setup,[0],[0]
"such that for t > t0,
k(t) ≤ Cρ · exp(−tρ).
",3. Background and Setup,[0],[0]
Remark 1.,3. Background and Setup,[0],[0]
"These assumptions allow the popular kernels such as Gaussian, Exponential, Silverman, uniform, triangular, tricube, Cosine, and Epanechnikov.
",3. Background and Setup,[0],[0]
Assumption 3 implies the next result which will be useful later on.,3. Background and Setup,[0],[0]
"The proof is elementary and is omitted.
",3. Background and Setup,[0],[0]
Lemma 1.,3. Background and Setup,[0],[0]
"For all m > 0, we have∫ Rd K(u)|u|mdu",3. Background and Setup,[0],[0]
"<∞.
Definition 3 (Bandwidth matrix).",3. Background and Setup,[0],[0]
H is a valid bandwidth matrix if it is a positive definite and symmetric d×dmatrix.,3. Background and Setup,[0],[0]
"H0 is a unit bandwidth matrix if it is a valid bandwidth matrix and |H0| = 1.
",3. Background and Setup,[0],[0]
Let σ1(H0) ≥ · · · ≥ σd(H0),3. Background and Setup,[0],[0]
"> 0 be the eigenvalues of H0.
Remark 2.",3. Background and Setup,[0],[0]
"In the scalar bandwidth case, H0 = I. Remark 3.",3. Background and Setup,[0],[0]
"It will be useful later on that if H = h2H0 where H0 is a unit bandwidth, then for u ∈ Rd,√
σd(H0) · h · |u| ≤ |H1/2u| ≤ √ σ1(H0) · h · |u|.
",3. Background and Setup,[0],[0]
Definition 4 (Kernel Density Estimation).,3. Background and Setup,[0],[0]
"Given a kernel K and h > 0 and H0, the KDE for H := h2H0 is given by
f̂H(x) := 1
n · |H|−d/2 n∑ i=1",3. Background and Setup,[0],[0]
K ( H−1/2(x−Xi) ),3. Background and Setup,[0],[0]
"= 1
n · hd n∑ i=1",3. Background and Setup,[0],[0]
"K
( H0 −1/2(x−Xi)
h
) .",3. Background and Setup,[0],[0]
"The following is a paraphrase of Bousquet et al. (2004), which was given in Chaudhuri & Dasgupta (2010).",4. Uniform Convergence Bounds,[0],[0]
Lemma 2.,4. Uniform Convergence Bounds,[0],[0]
"Let G be a class of functions from X to {0, 1} with VC dimension d < ∞, and F a probability distribution on X .",4. Uniform Convergence Bounds,[0],[0]
Let E denote expectation with respect to F .,4. Uniform Convergence Bounds,[0],[0]
Suppose n points are drawn independently at random from F; let En denote expectation with respect to this sample.,4. Uniform Convergence Bounds,[0],[0]
"Then with probability at least 1− 1/n, the following holds for all g ∈ G:
−min{βn √ Eng, β 2 n + βn",4. Uniform Convergence Bounds,[0],[0]
"√ Eg}
≤",4. Uniform Convergence Bounds,[0],[0]
Eg − Eng ≤ min{β2n + βn,4. Uniform Convergence Bounds,[0],[0]
"√ Eng, βn",4. Uniform Convergence Bounds,[0],[0]
"√ Eg},
where βn ≥ √ 4(d+ 3) log 2n/n.
Chaudhuri & Dasgupta (2010) takes G to be the indicator functions over balls.",4. Uniform Convergence Bounds,[0],[0]
Dasgupta & Kpotufe (2014) uses this to provide similar bounds for the k-NN density estimator as in this paper.,4. Uniform Convergence Bounds,[0],[0]
"Here, we extend this idea to ellipsoids by taking G = B (the indicator functions over ellipsoids), which has VC dimension (d2 + 3d)/2 as determined by Akama & Irie (2011).",4. Uniform Convergence Bounds,[0],[0]
Lemma 3.,4. Uniform Convergence Bounds,[0],[0]
"Define ellipsoid BH0(x, r) :",4. Uniform Convergence Bounds,[0],[0]
"= {x′ ∈ Rd : |H0−1/2(x − x′)| ≤ r}, and B := {BH0(x, r) : x ∈ Rd, r >",4. Uniform Convergence Bounds,[0],[0]
"0,H0 is a unit bandwidth}.",4. Uniform Convergence Bounds,[0],[0]
"With probability at least 1 − 1/n, the following holds uniformly for every B ∈ B and γ ≥ 0:
F(B)",4. Uniform Convergence Bounds,[0],[0]
≥ γ ⇒ Fn(B) ≥,4. Uniform Convergence Bounds,[0],[0]
γ − βn √ γ,4. Uniform Convergence Bounds,[0],[0]
"− β2n, F(B)",4. Uniform Convergence Bounds,[0],[0]
≤,4. Uniform Convergence Bounds,[0],[0]
γ ⇒ Fn(B) ≤,4. Uniform Convergence Bounds,[0],[0]
γ + βn,4. Uniform Convergence Bounds,[0],[0]
"√ γ + β2n,
where βn = 8d √ log n/n.
Remark 4.",4. Uniform Convergence Bounds,[0],[0]
We could have alternatively used a fixed confidence δ,4. Uniform Convergence Bounds,[0],[0]
so that our results would hold with probability at least 1 − δ.,4. Uniform Convergence Bounds,[0],[0]
This would only require a modification of βn (e.g. by taking βn = 4d √ 2(log n+ log(1/δ))/n).,4. Uniform Convergence Bounds,[0],[0]
"In this paper, we have simply taken δ = 1/n.",4. Uniform Convergence Bounds,[0],[0]
"Define the following which characterizes how much the density can respectively decrease and increase from x in B(x, r).",5. KDE Bound,[0],[0]
"Definition 5.
ǔx(r) := f(x)− inf x′∈B(x,r)
f(x′).
ûx(r) := sup x′∈B(x,r)
f(x′)− f(x).
",5. KDE Bound,[0],[0]
"The first are general upper and lower bounds for f̂H.
Theorem 1.",5. KDE Bound,[0],[0]
[Uniform Upper and Lower Bounds for f̂H] Let vd be the volume of the unit ball in Rd.,5. KDE Bound,[0],[0]
"Then the following holds uniformly in x ∈ Rd, > 0, unit bandwidths H0, and h > (log n/n)1/d with probability at least 1 − 1/n.",5. KDE Bound,[0],[0]
"Let H := h2H0.
f̂H(x) >",5. KDE Bound,[0],[0]
"f(x)− − C √ log n
n · hd ,
if ∫ Rd K(u) · ǔx(h|u|/ √ σd(H0))du < , and
f̂H(x) < f(x) + + C
√ log n
n · hd ,
if ∫ Rd K(u) ·",5. KDE Bound,[0],[0]
"ûx(h|u|/ √ σd(H0))du < , where C =
8d √ ·vd · ||f ||∞ (∫∞ 0 k(t) ·",5. KDE Bound,[0],[0]
td/2dt+ 1 ) + 64d2 · k(0).,5. KDE Bound,[0],[0]
Remark 5.,5. KDE Bound,[0],[0]
"The conditions on ǔx(h|u|/ √ σd) and ûx(h|u|/ √ σd) can be interpreted as a bound on
their expectations over the probability measure K (i.e.∫ Rd K(u)du = 1).",5. KDE Bound,[0],[0]
"These conditions can be satisfied by taking h sufficiently small.
",5. KDE Bound,[0],[0]
Remark 6.,5. KDE Bound,[0],[0]
The parameter allows us the amount of slack in the estimation errors.,5. KDE Bound,[0],[0]
This is useful in a few aspects.,5. KDE Bound,[0],[0]
"Oftentimes, we don’t require tight bounds, especially when reasoning about low density regions thus having a large allows us to satisfy the conditions more easily.",5. KDE Bound,[0],[0]
"In the case that we want tight bounds, the additive error controlled by the pointwise smoothness of the density can be encoded in , so to not require global smoothness assumptions.
",5. KDE Bound,[0],[0]
Remark 7.,5. KDE Bound,[0],[0]
"Besides the ||f ||∞ factor, the value of C at the end of the theorem statement is a quantity which can be known without any a priori knowledge of f .",5. KDE Bound,[0],[0]
We can bound ||f ||∞ in terms of known quantities given smoothness assumptions near argmaxxf(x).,5. KDE Bound,[0],[0]
"This is used in later results where knowing a value of C is important.
",5. KDE Bound,[0],[0]
"In order to prove Theorem 1, we first define the following two functions which serve to approximateK as a step-wise linear combination of uniform kernels.",5. KDE Bound,[0],[0]
Definition 6.,5. KDE Bound,[0],[0]
Let ∆ >,5. KDE Bound,[0],[0]
"0.
",5. KDE Bound,[0],[0]
K∆(u),5. KDE Bound,[0],[0]
:= ∞∑ j=0 (k(j∆)− k((j + 1)∆)) ·,5. KDE Bound,[0],[0]
"1 {|u| < j∆} ,
K∆(u)",5. KDE Bound,[0],[0]
:= ∞∑ j=0 (k(j∆)− k((j + 1)∆)) ·,5. KDE Bound,[0],[0]
"1 {|u| < (j + 1)∆} .
",5. KDE Bound,[0],[0]
"Then it is clear that the following holds for all ∆ > 0.
K∆(u) ≤ K(u) ≤ K∆(u).
",5. KDE Bound,[0],[0]
"The next Lemma is useful in computing the expectations of functions over the kernel measure.
",5. KDE Bound,[0],[0]
Lemma 4.,5. KDE Bound,[0],[0]
Suppose g is an integrable function over R≥0 and let vd denote the volume of a unit ball in Rd.,5. KDE Bound,[0],[0]
"Then∫
Rd K(u)g(|u|)du = vd · ∫ ∞ 0 k(t) · tdg(|u|)du.
",5. KDE Bound,[0],[0]
Proof of Lemma 4.,5. KDE Bound,[0],[0]
"Let Sd = 2πd/2/Γ(d/2) denote the surface area of the unit ball in Rd.∫
Rd K(u)g(|u|)du = Sd ∫ ∞ 0 k(t) · td−1 · g(|t|)dt
= Sd d ∫ ∞ 0",5. KDE Bound,[0],[0]
(k(t) · g(|t|))tddt = vd ∫ ∞ 0,5. KDE Bound,[0],[0]
"(k(t) · g(|t|))tddt,
where the second last equality follows from integration by parts and the last follows from the fact that vd = Sd/d.
The following follows immediately from Lemma 4.
",5. KDE Bound,[0],[0]
"Corollary 1.∫ Rd K(u)ǔx(h|u|)du = vd · ∫ ∞ 0
k(t) ·",5. KDE Bound,[0],[0]
"td · ǔx(ht)dt,∫ Rd K(u)ûx(h|u|)du = vd · ∫ ∞ 0 k(t) ·",5. KDE Bound,[0],[0]
"td · ûx(ht)dt.
",5. KDE Bound,[0],[0]
Proof of Theorem 1.,5. KDE Bound,[0],[0]
"Assume that the event that Lemma 3 holds, which occurs with probability at least 1 − 1/n. We first show the lower bound for f̂H(x).",5. KDE Bound,[0],[0]
"Define
f̂∆,H(x) := 1 n · hd n∑ i=1",5. KDE Bound,[0],[0]
"K∆
( H0 −1/2(x−Xi)
h
) .
",5. KDE Bound,[0],[0]
"It is clear that f̂H(x) ≥ f̂∆,H(x) for all x ∈ Rd.",5. KDE Bound,[0],[0]
"Let us use the following shorthand ∆k,j := k(j∆).",5. KDE Bound,[0],[0]
"We have
f̂∆,H(x) = 1
hd ∞∑ j=0",5. KDE Bound,[0],[0]
"(∆k,j −∆k,j+1) ·",5. KDE Bound,[0],[0]
"Fn (BH0(x, jh∆)) .
",5. KDE Bound,[0],[0]
"We next get a handle on each Fn (BH0(x, jh∆)).",5. KDE Bound,[0],[0]
"We have
F (BH0(x, jh∆))",5. KDE Bound,[0],[0]
≥ vd · (jh∆) d ·,5. KDE Bound,[0],[0]
"Fj ,
where Fj := max{0, f(x)− ǔx(jh∆/ √ σd(H0))}.",5. KDE Bound,[0],[0]
"Thus, by Lemma 3, we have
Fn (BH0(x, jh∆))",5. KDE Bound,[0],[0]
"≥ vd · (jh∆)d · Fj − βn √ vd · (jh∆)d/2 · √ Fj − β2n
≥ vd · (jh∆)d · Fj − βn √ vd · ||f ||∞ · (jh∆)d/2 − β2n.
",5. KDE Bound,[0],[0]
"Therefore,
f̂∆,h(x)",5. KDE Bound,[0],[0]
≥ vd ∞∑ j=0,5. KDE Bound,[0],[0]
"(∆k,j −∆k,j+1)(j∆)d · f(x)
",5. KDE Bound,[0],[0]
"− vd ∞∑ j=0 (∆k,j −∆k,j+1)(j∆)d · ǔx ( jh∆√ σd(H0) )
",5. KDE Bound,[0],[0]
− βn √ vd · ||f ||∞ hd/2 · ∞∑ j=0,5. KDE Bound,[0],[0]
"(∆k,j −∆k,j+1)(j∆)d/2
− β2n k(0)
hd .
",5. KDE Bound,[0],[0]
We handle each term separately.,5. KDE Bound,[0],[0]
"For the first term, we have
lim ∆→0 vd ∞∑ j=0 (∆k,j −∆k,j+1)(j∆)d
= vd ∫ ∞ 0 k(t)tddt = 1.
where the last equality follows from Lemma 4.",5. KDE Bound,[0],[0]
"Next, we have
lim ∆→0 vd ∞∑ j=0 (∆k,j −∆k,j+1)(j∆)d · ǔx ( jh∆√ σd(H0) )
",5. KDE Bound,[0],[0]
= vd ∫ ∞ 0 k(t) ·,5. KDE Bound,[0],[0]
"td · ǔx(th/ √ σd(H0))dt < .
",5. KDE Bound,[0],[0]
"Finally, we have
lim ∆→0 ∞∑ j=0",5. KDE Bound,[0],[0]
"(∆k,j −∆k,j+1)(j∆)d/2
= ∫ ∞ 0 k(t) ·",5. KDE Bound,[0],[0]
"td/2dt <∞.
Thus, taking ∆→ 0",5. KDE Bound,[0],[0]
we get f̂H(x) ≥ f(x)−,5. KDE Bound,[0],[0]
"− βn √ vd · ||f ||∞ hd/2 · ∫ ∞
0
k(t) ·",5. KDE Bound,[0],[0]
"td/2dt
− β2n k(0)
hd .
",5. KDE Bound,[0],[0]
This gives us the lower bound.,5. KDE Bound,[0],[0]
Next we derive an upper bound.,5. KDE Bound,[0],[0]
"Let us redefine
f̂∆,H(x)",5. KDE Bound,[0],[0]
:= 1 n · hd n∑ i=1,5. KDE Bound,[0],[0]
"Km ( x−Xi h ) .
",5. KDE Bound,[0],[0]
"It is clear that f̂H(x) ≤ f̂∆,H(x) for all x ∈ Rd and
f̂∆,H(x)
",5. KDE Bound,[0],[0]
"= 1
hd ∞∑ j=0",5. KDE Bound,[0],[0]
"(∆k,j −∆k,j+1) ·",5. KDE Bound,[0],[0]
"Fn (BH0(x, (j + 1)h∆)) .
",5. KDE Bound,[0],[0]
"We next get a handle on each Fn (BH0(x, jh∆)).",5. KDE Bound,[0],[0]
"We have
F(BH0(x, jh∆))",5. KDE Bound,[0],[0]
"≤ vd · (jh∆)d · Fj where Fj = min{||f ||∞, f(x) + û(jh∆/ √ σd(H0))}.",5. KDE Bound,[0],[0]
"Thus by Lemma 3 we have
Fn (BH0(x, jh/m))",5. KDE Bound,[0],[0]
≤,5. KDE Bound,[0],[0]
"vd(jh∆)dFj + βn(jh∆)d/2 √ vd · Fj + β2n.
",5. KDE Bound,[0],[0]
"Using this, we now have
f̂∆,H(x) ≤ vd ∞∑ j=0",5. KDE Bound,[0],[0]
"(∆k,j −∆k,j+1)((j + 1) )",5. KDE Bound,[0],[0]
"d · f(x)
+ vd ∞∑ j=0",5. KDE Bound,[0],[0]
"(∆k,j −∆k,j+1)((j + 1)∆)d · ûx",5. KDE Bound,[0],[0]
"( (j + 1)h∆√ σd(H0) )
+ βn √ vd · ||f ||∞ hd/2 · ∞∑ j=0 (∆k,j −∆k,j+1)((j + 1)∆)d/2
+ β2n k(0)
hd .
",5. KDE Bound,[0],[0]
We proceed the same way as the other direction.,5. KDE Bound,[0],[0]
Thus taking ∆→ 0,5. KDE Bound,[0],[0]
"we get
f̂∆,H(x) ≤ f(x) + + βn",5. KDE Bound,[0],[0]
"√ vd · ||f ||∞ hd/2 · ∫ ∞
0
k(t) ·",5. KDE Bound,[0],[0]
"td/2dt
+ β2n k(0)
hd .
",5. KDE Bound,[0],[0]
The result follows.,5. KDE Bound,[0],[0]
Theorem 2.,6. Sup-norm Bounds for KDE,[0],[0]
[`∞ bound for α-Hölder continuous functions],6. Sup-norm Bounds for KDE,[0],[0]
If f is Hölder-continuous (i.e. |f(x),6. Sup-norm Bounds for KDE,[0],[0]
− f(x′)| ≤ Cα|x,6. Sup-norm Bounds for KDE,[0],[0]
"− x|α for x, x′ ∈ Rd and 0 < α ≤ 1), then there exists positive constant C ′ ≡",6. Sup-norm Bounds for KDE,[0],[0]
"C ′(C,Cα, α,K) such that the following holds with probability at least 1 − 1/n uniformly in h > (log n/n)1/d and unit bandwidths H0.",6. Sup-norm Bounds for KDE,[0],[0]
"Let H := h2H0.
sup x∈Rd
|f̂H(x)−",6. Sup-norm Bounds for KDE,[0],[0]
f(x)| < C ′,6. Sup-norm Bounds for KDE,[0],[0]
"·
( hα
σd(H0)α/2 +
√ log n
n · hd
) .
",6. Sup-norm Bounds for KDE,[0],[0]
Remark 8.,6. Sup-norm Bounds for KDE,[0],[0]
Taking h = n−1/(2α+d) in the above r.h.s. optimizes the rates to n−α/(2α+d) (ignoring log factors).,6. Sup-norm Bounds for KDE,[0],[0]
Remark 9.,6. Sup-norm Bounds for KDE,[0],[0]
We can attain similar results (although not uniform in bandwidth) by a straightforward application of Theorem 3.1 of Sriperumbudur & Steinwart (2012) or Proposition 9 of Rinaldo & Wasserman (2010).,6. Sup-norm Bounds for KDE,[0],[0]
The goal of this section is to utilize the KDE to estimate the mode of a uni-modal distribution from its samples.,7. Mode Estimation Results,[0],[0]
"We borrow the estimator from Abraham et al. (2004)
x̂",7. Mode Estimation Results,[0],[0]
":= argmaxx∈X f̂H(x),
where H := h2I.
We adopt the mode estimation framework assumptions from Dasgupta & Kpotufe (2014) which are summarized below.",7. Mode Estimation Results,[0],[0]
Definition 7.,7. Mode Estimation Results,[0],[0]
"x0 is a mode of f if f(x) < f(x0) for all x ∈ B(x0, r)\{x0} for some r > 0.",7. Mode Estimation Results,[0],[0]
Assumption 4.,7. Mode Estimation Results,[0],[0]
"• f has a single mode x0.
",7. Mode Estimation Results,[0],[0]
"• f is twice differentiable in a neighborhood around x0.
",7. Mode Estimation Results,[0],[0]
"• f has a negative-definite Hessian at x0.
",7. Mode Estimation Results,[0],[0]
These assumptions lead to the following.,7. Mode Estimation Results,[0],[0]
"Lemma 5 ((Dasgupta & Kpotufe, 2014)).",7. Mode Estimation Results,[0],[0]
Let f satisfy Assumption 4.,7. Mode Estimation Results,[0],[0]
"Then there exists Ĉ, Č, r0, λ > 0",7. Mode Estimation Results,[0],[0]
"such that the following holds.
",7. Mode Estimation Results,[0],[0]
Č · |x0,7. Mode Estimation Results,[0],[0]
− x|2 ≤ f(x0)− f(x) ≤ Ĉ · |x0,7. Mode Estimation Results,[0],[0]
"− x|2
for all x ∈ Ax where A0 is a connected component of {x : f(x) ≥ λ} and A0 contains B(x0, r0).
",7. Mode Estimation Results,[0],[0]
We obtain the following result for the estimation error of x̂. Theorem 3.,7. Mode Estimation Results,[0],[0]
"Suppose that Assumptions 1, 2, 3, 4 hold.",7. Mode Estimation Results,[0],[0]
Choose h such that (log n)2/ρ ·h→ 0 and log n/(nhd)→ 0,7. Mode Estimation Results,[0],[0]
"as n → ∞. Then, for n sufficiently large depending on d, ||f ||∞,K, Ĉ, Č, r0 the following holds with probability least 1− 1/n.
|x̂− x0|2 ≤",7. Mode Estimation Results,[0],[0]
"max
{ 32Ĉ
Č (log n)4/ρ · h2, 17 · C
√ log n
n · hd
} .
",7. Mode Estimation Results,[0],[0]
Remark 10.,7. Mode Estimation Results,[0],[0]
Taking h = n−1/(4+d) optimizes the above expression so that |x̂− x0| .,7. Mode Estimation Results,[0],[0]
n−1/(4+d) (ignoring log factors) which matches the lower bound rate for mode estimation as established in Tsybakov (1990).,7. Mode Estimation Results,[0],[0]
Remark 11.,7. Mode Estimation Results,[0],[0]
This result can be extended to multi-modal distributions as done by Dasgupta & Kpotufe (2014) by using the connected components of nearest neighbor graphs at appropriate empirical density levels to isolate the modes away from each other.,7. Mode Estimation Results,[0],[0]
"In this section, we estimate the density level set Lf (λ) := {x : f(x) ≥ λ} where λ > 0 is given.",8. Density Level Set Estimation Results,[0],[0]
"We make the following standard regularity assumptions e.g. (Singh et al., 2009).",8. Density Level Set Estimation Results,[0],[0]
"To simplify the analysis, let us take H = h2I.",8. Density Level Set Estimation Results,[0],[0]
It is clear that the results that follow can be extended to arbitrary H0.,8. Density Level Set Estimation Results,[0],[0]
Assumption 5 (β-regularity).,8. Density Level Set Estimation Results,[0],[0]
Let 0,8. Density Level Set Estimation Results,[0],[0]
< β <,8. Density Level Set Estimation Results,[0],[0]
∞.,8. Density Level Set Estimation Results,[0],[0]
There exists 0 <,8. Density Level Set Estimation Results,[0],[0]
"λ0 < λ and Čβ , Ĉβ , r̄ > 0",8. Density Level Set Estimation Results,[0],[0]
"such that the following holds for x ∈ Lf (λ0)\Lf (λ).
",8. Density Level Set Estimation Results,[0],[0]
"Čβ · d(x, Lf (λ))β ≤",8. Density Level Set Estimation Results,[0],[0]
λ− f(x) ≤,8. Density Level Set Estimation Results,[0],[0]
Ĉβ ·,8. Density Level Set Estimation Results,[0],[0]
"d(x, Lf (λ))β ,
",8. Density Level Set Estimation Results,[0],[0]
"where d(x,A) := infx′∈A{|x − x′|}.",8. Density Level Set Estimation Results,[0],[0]
"and B(Lf (λ), r̄) ⊆",8. Density Level Set Estimation Results,[0],[0]
"Lf (λ0) where B(A, r) := {x : d(x,A) ≤ r}.
",8. Density Level Set Estimation Results,[0],[0]
"Then we consider following estimator.
L̂f",8. Density Level Set Estimation Results,[0],[0]
:= { x ∈ X : f̂H(x) >,8. Density Level Set Estimation Results,[0],[0]
"λ− C̃ √ log n
n · hd
} .
where C̃ is obtained by taking C and replacing the ||f ||∞ factor by 1+5 maxx∈Xn0 f̂H(x) whereXn0 is a fixed sample of size n0.",8. Density Level Set Estimation Results,[0],[0]
"Then, C̃ can be viewed as a constant w.r.t. n",8. Density Level Set Estimation Results,[0],[0]
"and can be known without any a priori knowledge of f while ensuring that C̃ ≥ max{1, 2C}.
",8. Density Level Set Estimation Results,[0],[0]
We use the following Hausdorff metric.,8. Density Level Set Estimation Results,[0],[0]
"Definition 8 (Hausdorff Distance).
",8. Density Level Set Estimation Results,[0],[0]
"dH(A,B) := max{sup x∈A d(x,B), sup x∈B d(x,A)}.
",8. Density Level Set Estimation Results,[0],[0]
Theorem 4.,8. Density Level Set Estimation Results,[0],[0]
"Suppose that Assumptions 1, 2, 3, 5 hold and that f is α-Hölder continuous for some 0",8. Density Level Set Estimation Results,[0],[0]
< α ≤ 1.,8. Density Level Set Estimation Results,[0],[0]
Choose h such that (log n)2/ρ · h → 0 and log n/(nhd),8. Density Level Set Estimation Results,[0],[0]
"→ 0 as n → ∞. Then, for n sufficiently large depending on d,C, C̃,K, Ĉβ , Čβ , β, r̄ the following holds with probability least 1− 1/n.
dH(L̂f , Lf (λ)) ≤",8. Density Level Set Estimation Results,[0],[0]
"C ′′ ( (log n)2/ρ · h+ ( log n
n · hd
)1/(2β)) ,
where C ′′ ≡ C ′′(C, C̃, Ĉβ , Čβ , C̃, β).",8. Density Level Set Estimation Results,[0],[0]
Remark 12.,8. Density Level Set Estimation Results,[0],[0]
Choosing h = n−β/(2β+d) gives us a densitylevel set estimation rate of O(n−1/(2β+d)).,8. Density Level Set Estimation Results,[0],[0]
This matches the lower bound (ignoring log factors) determined by Tsybakov (1997).,8. Density Level Set Estimation Results,[0],[0]
Remark 13.,8. Density Level Set Estimation Results,[0],[0]
This result can be extended so that we can recover each component separately (i.e. identify which points correspond to which connected components of Lf (λ)).,8. Density Level Set Estimation Results,[0],[0]
"Similar to the mode estimation result, this can be done using nearest neighbor graphs at the appropriate level to isolate the connected components of Lf (λ) away from each other.",8. Density Level Set Estimation Results,[0],[0]
"This has been done extensively in the related area of cluster tree estimation e.g. (Chaudhuri & Dasgupta, 2010).
",8. Density Level Set Estimation Results,[0],[0]
Remark 14.,8. Density Level Set Estimation Results,[0],[0]
The global α-Hölder continuous assumption is not required and is only here for simplicity.,8. Density Level Set Estimation Results,[0],[0]
"Smoothness in a neighborhood around a maximizer of f is sufficient so that for n0 large enough, C̃ ≥ 2C.",8. Density Level Set Estimation Results,[0],[0]
We consider the setting where we have observations from compact subset X ⊂ Rd and labels y ∈,9. Class Probability Estimation Results,[0],[0]
"{1, ..., L}.",9. Class Probability Estimation Results,[0],[0]
"Given a label y, an instance x ∈ Rd has density fy(x) where fy is w.r.t.",9. Class Probability Estimation Results,[0],[0]
the uniform measure on Rd.,9. Class Probability Estimation Results,[0],[0]
"Instance-label pairs (X,Y ) are thus drawn according to a mixture distribution where Y is chosen from {1, ..., L} with corresponding probabilities π1, ..., πL (i.e. ∑L j=1 πj = 1) and then X is chosen according to fY .
",9. Class Probability Estimation Results,[0],[0]
"Then given x ∈ X , we can define the marginal distribution as follows.
g(x) := (g1(x), ..., gL(x)),
gy(x) := f(Y = y|X = x) = πyfy(x)∑ j πjfj(x) .
",9. Class Probability Estimation Results,[0],[0]
"The goal of class probability estimation is to learn g based on samples (x1, y1), ..., (xn, yn).",9. Class Probability Estimation Results,[0],[0]
We define our estimator naturally as follows.,9. Class Probability Estimation Results,[0],[0]
"Let f̂h,y be the KDE of fy w.r.t.",9. Class Probability Estimation Results,[0],[0]
"to bandwidth matrix H = h2I.
ĝh(x)",9. Class Probability Estimation Results,[0],[0]
":= (ĝh,1(x), ..., ĝh,L(x)),
ĝh,y(x) := π̂y f̂h,y(x)∑ j π̂j f̂h,j(x) and π̂y := 1 n n∑ j=1 1[y = yi].
",9. Class Probability Estimation Results,[0],[0]
"We make the following regularity assumption on fy .
Assumption 6.",9. Class Probability Estimation Results,[0],[0]
(α-Hölder densities),9. Class Probability Estimation Results,[0],[0]
"For each y ∈ {1, ..., L} and x ∈ Rd we have
|fy(x)− fy(x′)| ≤ Cα|x− x′|α,
where 0 < α ≤ 1.
",9. Class Probability Estimation Results,[0],[0]
"We state the result below:
Theorem 5.",9. Class Probability Estimation Results,[0],[0]
"Suppose that Assumptions 1, 2, 3, 6 hold.",9. Class Probability Estimation Results,[0],[0]
"Then for n sufficiently large depending on miny πy , there exists positive constants C ′′ ≡ C",9. Class Probability Estimation Results,[0],[0]
"′′(L,C,Cα, α,K) and",9. Class Probability Estimation Results,[0],[0]
C̃ ≡,9. Class Probability Estimation Results,[0],[0]
"C̃(miny πy, L) such that the following holds with probability at least 1−C̃/n uniformly in h > (log n/n)1/d.
sup x∈Rd
||ĝh(x)− g(x)||∞ ≤ C ′′ · ( hα + √ log n
n · hd
) .
",9. Class Probability Estimation Results,[0],[0]
Remark 15.,9. Class Probability Estimation Results,[0],[0]
This corresponds to an optimized rate of Õ(n−α/(2α+d)).,9. Class Probability Estimation Results,[0],[0]
"This matches the lower bounds up to log factors for misclassification as established in related
works e.g. Audibert et al. (2007); Chaudhuri & Dasgupta (2014).",9. Class Probability Estimation Results,[0],[0]
"Note that misclassification rate for a hard classifier is a slightly different but very related to what is done here, which is directly estimating the marginal density.",9. Class Probability Estimation Results,[0],[0]
"We make the following regularity assumptions which are standard among works in manifold learning e.g. (Baraniuk & Wakin, 2009; Genovese et al., 2012; Balakrishnan et al., 2013).
",10. Extension to Manifolds,[0],[0]
Assumption 7.,10. Extension to Manifolds,[0],[0]
"F is supported on M where:
• M is a dM -dimensional smooth compact Riemannian manifold without boundary embedded in compact subset X ⊆ RD.
•",10. Extension to Manifolds,[0],[0]
"The volume of M is bounded above by a constant.
",10. Extension to Manifolds,[0],[0]
"• M has condition number 1/τ , which controls the curvature and prevents self-intersection.
",10. Extension to Manifolds,[0],[0]
"Let f be the density of F with respect to the uniform measure on M .
",10. Extension to Manifolds,[0],[0]
"In this section, we assume that our density estimator is w.r.t.",10. Extension to Manifolds,[0],[0]
"to dM instead of the ambient dimension d.
f̂H(x) := 1
n · hdM n∑ i=1",10. Extension to Manifolds,[0],[0]
"K
( H0 −1/2(x−Xi)
h
) .
",10. Extension to Manifolds,[0],[0]
Remark 16.,10. Extension to Manifolds,[0],[0]
It is then the case that we must know the intrinsic dimension dM .,10. Extension to Manifolds,[0],[0]
"There are numerous known techniques for doing so e.g. (Kegl, 2002; Levina & Bickel, 2004; Hein & Audibert, 2005; Farahmand et al., 2007).
",10. Extension to Manifolds,[0],[0]
"Next, we need the following guarantee on the volume of the intersection of a Euclidean ball and M ; this is required to get a handle on the true mass of the ball under F in later arguments.",10. Extension to Manifolds,[0],[0]
The upper and lower bounds follow from Chazal (2013) and Lemma 5.3 of Niyogi et al. (2008).,10. Extension to Manifolds,[0],[0]
"The proof can be found in (Jiang, 2017).
",10. Extension to Manifolds,[0],[0]
Lemma 6 (Ball Volume).,10. Extension to Manifolds,[0],[0]
"If 0 < r < min{τ/4dM , 1/τ}, and x ∈M then
1− τ2r2 ≤",10. Extension to Manifolds,[0],[0]
"voldM (B(x, r) ∩M)",10. Extension to Manifolds,[0],[0]
"vdM r dM ≤ 1 + 4dMr/τ,
where voldM is the volume w.r.t.",10. Extension to Manifolds,[0],[0]
"the uniform measure on M .
",10. Extension to Manifolds,[0],[0]
"We then give analogues to Theorem 1 and Theorem 2.
Theorem 6.",10. Extension to Manifolds,[0],[0]
"[Manifold Case Uniform Upper and Lower Bounds for f̂H] There exists CM ≡ CM (dM , d,K, ||f ||∞, τ) such that the following holds
uniformly in x ∈ M , > 0, unit bandwidths H0, and h > (log n/n)1/dM with probability at least 1 − 1/n.",10. Extension to Manifolds,[0],[0]
"Let H := h2H0.
f̂H(x) >",10. Extension to Manifolds,[0],[0]
"f(x)− − CM ( h2 + √ log n
n · hdM
) ,
if ∫ Rd K(u) · ǔx(h|u|/ √ σd(H0))du < , and
f̂H(x) < f(x) + + CM
( h+ √ log n
n · hdM
) ,
if ∫ Rd K(u) ·",10. Extension to Manifolds,[0],[0]
ûx(h|u|/ √ σd(H0))du < .,10. Extension to Manifolds,[0],[0]
Remark 17.,10. Extension to Manifolds,[0],[0]
The extra h2 and h term in the lower and upper bounds respectively come from the approximation of the volume of the full-dimensional balls w.r.t.,10. Extension to Manifolds,[0],[0]
"the uniform measure on M in Lemma 6.
",10. Extension to Manifolds,[0],[0]
Proof Sketch of Theorem 6.,10. Extension to Manifolds,[0],[0]
The proof mirrors that of the full dimensional case so we only highlight the differences.,10. Extension to Manifolds,[0],[0]
"For the lower bound, instead of
F (BH0(x, jhδ))",10. Extension to Manifolds,[0],[0]
"≥ vd · (jhδ) d · Fj ,
we have
F (BH0(x, jhδ))",10. Extension to Manifolds,[0],[0]
"≥ vdM (jhδ) dM Fj(1− τ2(jhδ)2)
",10. Extension to Manifolds,[0],[0]
= vdM (jhδ) dM Fj,10. Extension to Manifolds,[0],[0]
"− hdM+2vdM τ2||f ||∞ (jδ) dM+2 .
",10. Extension to Manifolds,[0],[0]
"The first term can be treated in the same way as before, while the second term contributes in an extra term with an h2 factor after taking the total summation.
",10. Extension to Manifolds,[0],[0]
"For the upper bound, instead of
F(BH0(x, jhδ))",10. Extension to Manifolds,[0],[0]
"≤ vd · (jhδ)d · Fj ,
we have
F(BH0(x, jhδ))",10. Extension to Manifolds,[0],[0]
≤,10. Extension to Manifolds,[0],[0]
"vdM · (jhδ)dM · Fj(1 + 4dM (jhδ)/τ).
",10. Extension to Manifolds,[0],[0]
"Similary, this contributes an extra term with an h factor after taking the total summation.
",10. Extension to Manifolds,[0],[0]
Theorem 7.,10. Extension to Manifolds,[0],[0]
[Manifold Case `∞ bound for α-Hölder continuous functions] If f is Hölder-continuous (i.e. |f(x),10. Extension to Manifolds,[0],[0]
− f(x′)| ≤ Cα|x,10. Extension to Manifolds,[0],[0]
"− x|α for x, x′ ∈ Rd with 0 < α ≤ 1), then there exists positive constant C ′M ≡ C ′M (||f ||∞, Cα, α,K, τ, dM , d, σd(H0)) such that the following holds with probability at least 1− 1/n uniformly in h satisfying (log n/n)1/dM < h < 1.
sup",10. Extension to Manifolds,[0],[0]
x∈M |f̂H(x)−,10. Extension to Manifolds,[0],[0]
"f(x)| < C ′M ·
( hα + √ log n
n · hdM
) .",10. Extension to Manifolds,[0],[0]
"In this section, we only assume a distribution F on Rd whose support is defined asX",11. Local Intrinsic Dimension Estimation,[0],[0]
":= {x ∈ Rd : F(B(x, h))",11. Local Intrinsic Dimension Estimation,[0],[0]
> 0 ∀h > 0} and X is assumed to be compact.,11. Local Intrinsic Dimension Estimation,[0],[0]
"We use the following notion of intrinsic dimension, which is based on the doubling dimension and adapted from previous works such as Houle (2013).
",11. Local Intrinsic Dimension Estimation,[0],[0]
Definition 9.,11. Local Intrinsic Dimension Estimation,[0],[0]
"For x ∈ X , define the following local intrinsic dimension wherever the quantity exists
ID(x)",11. Local Intrinsic Dimension Estimation,[0],[0]
":= lim h→0 log2 ( F(B(x, 2h))",11. Local Intrinsic Dimension Estimation,[0],[0]
"F(B(x, h)) ) .
",11. Local Intrinsic Dimension Estimation,[0],[0]
"We can then define our estimator of local intrinsic dimension at x ∈ X as follows:
ÎDn,h(x) := log2 ( Fn(B(x, 2h))",11. Local Intrinsic Dimension Estimation,[0],[0]
"Fn(B(x, h)) ) .
",11. Local Intrinsic Dimension Estimation,[0],[0]
"The following is a uniform convergence result for ÎDn,h(x).
",11. Local Intrinsic Dimension Estimation,[0],[0]
Theorem 8.,11. Local Intrinsic Dimension Estimation,[0],[0]
"Define the following
IDh(x) := log2 ( F(B(x, 2h))",11. Local Intrinsic Dimension Estimation,[0],[0]
"F(B(x, h)) ) .
",11. Local Intrinsic Dimension Estimation,[0],[0]
Suppose that h > 0 and n satisfy βn,11. Local Intrinsic Dimension Estimation,[0],[0]
"< 1 10 infx′∈X √ F(B(x′, h)).",11. Local Intrinsic Dimension Estimation,[0],[0]
"Then the following holds with probability at least 1− 1/n uniformly in x ∈ X .
",11. Local Intrinsic Dimension Estimation,[0],[0]
"|ÎDn,h(x)− IDh(x)| ≤ 6βn infx′∈X √ F(x′, 2h) .
",11. Local Intrinsic Dimension Estimation,[0],[0]
Remark 18.,11. Local Intrinsic Dimension Estimation,[0],[0]
The r.h.s. goes to 0 as n →,11. Local Intrinsic Dimension Estimation,[0],[0]
"∞. Moreover, if IDh(x) converges to ID(x) uniformly in x ∈ X , then simultaneously taking h → 0 and n → ∞ such that βn· ( infx′∈X √ F(x′, 2h) )−1",11. Local Intrinsic Dimension Estimation,[0],[0]
"→ 0 gives us a finite-sample
uniform convergence rate for local intrinsic dimension estimation.
",11. Local Intrinsic Dimension Estimation,[0],[0]
Remark 19.,11. Local Intrinsic Dimension Estimation,[0],[0]
"If we assume a global intrinsic dimension d0 and a density, the condition βn < 1 10 infx′∈X √ F(B(x′, h)) can be interpreted as logn nhd0 → 0
and the r.h.s.",11. Local Intrinsic Dimension Estimation,[0],[0]
"of the bound is on the order of √
logn nhd0 .
",11. Local Intrinsic Dimension Estimation,[0],[0]
"In fact, this result is similar to the uniform convergence results for the KDE for estimating the smoothed density.",11. Local Intrinsic Dimension Estimation,[0],[0]
e.g. |f̂h − fh|∞ = O,11. Local Intrinsic Dimension Estimation,[0],[0]
(,11. Local Intrinsic Dimension Estimation,[0],[0]
"√ logn nhd ) when (ignoring some log
factors) nhd → ∞ where fh is the density convolved with the uniform kernel with bandwidth h.",11. Local Intrinsic Dimension Estimation,[0],[0]
It is interesting that an analogous result comes up when estimating the intrinsic dimension with our notion of smoothed ID.,11. Local Intrinsic Dimension Estimation,[0],[0]
Kernel density estimation (KDE) is a popular nonparametric density estimation method.,abstractText,[0],[0]
We (1) derive finite-sample high-probability density estimation bounds for multivariate KDE under mild density assumptions which hold uniformly in x ∈ R and bandwidth matrices.,abstractText,[0],[0]
"We apply these results to (2) mode, (3) density level set, and (4) class probability estimation and attain optimal rates up to logarithmic factors.",abstractText,[0],[0]
We then (5) provide an extension of our results under the manifold hypothesis.,abstractText,[0],[0]
"Finally, we (6) give uniform convergence results for local intrinsic dimension estimation.",abstractText,[0],[0]
Uniform Convergence Rates for Kernel Density Estimation,title,[0],[0]
"⇣ m 12 ⌘ com-
pared to the previously known O ⇣ m 14 ⌘
rate. We further show that this rate also depends on the kurtosis — the normalized fourth moment which measures the “tailedness” of the distribution. We also provide improved rates under progressively stronger assumptions, namely, bounded higher moments, subgaussianity and bounded support of the underlying distribution.",text,[0],[0]
Empirical risk minimization — i.e. the training of models on a finite sample drawn i.i.d from an underlying distribution — is a central paradigm in machine learning.,1. Introduction,[0],[0]
The hope is that models trained on the finite sample perform provably well even on previously unseen samples from the underlying distribution.,1. Introduction,[0],[0]
But how many samples m are required to guarantee a low approximation error ✏?,1. Introduction,[0],[0]
Uniform deviation bounds provide the answer.,1. Introduction,[0],[0]
"Informally, they are the worst-case difference across all possible models between the empirical loss of a model and its expected loss.",1. Introduction,[0],[0]
"As such, they determine how many samples are required to achieve a fixed error in terms of the loss function.",1. Introduction,[0],[0]
"In this paper, we consider the popular k-Means clustering problem and provide uniform deviation bounds based on weak assumptions on the underlying data generating distribution.
1Department of Computer Science, ETH Zurich.",1. Introduction,[0],[0]
"Correspondence to: Olivier Bachem <olivier.bachem@inf.ethz.ch>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
Related work.,1. Introduction,[0],[0]
"Traditional Vapnik-Chervonenkis theory provides tools to obtain uniform deviation bounds for binary concept classes such as classification using halfspaces (Vapnik & Chervonenkis, 1971).",1. Introduction,[0],[0]
"While these results have been extended to provide uniform deviation bounds for sets of continuous functions bounded in [0, 1] (Haussler, 1992; Li et al., 2001), these results are not readily applied to kMeans clustering as the underlying loss function in k-Means clustering is continuous and unbounded.
",1. Introduction,[0],[0]
"In their seminal work, Pollard (1981) shows that k-Means clustering is strongly consistent, i.e., that the optimal cluster centers on a random sample converge almost surely to the optimal centers of the distribution under a weak assumption.",1. Introduction,[0],[0]
"This has sparked a long line of research on cluster stability (Ben-David et al., 2006; Rakhlin & Caponnetto, 2007; Shamir & Tishby, 2007; 2008) which investigates the convergence of optimal parameters both asymptotically and for finite samples.",1. Introduction,[0],[0]
"The vector quantization literature offers insights into the convergence of empirically optimal quantizers for k-Means in terms of the objective: A minimax rate of O ⇣ m 12 ⌘
is known if the underlying distribution has bounded support (Linder et al., 1994; Bartlett et al., 1998).",1. Introduction,[0],[0]
"A better rate of O m
1 may be achieved for finite support (Antos et al., 2005) or under both bounded support and regularity assumptions (Levrard et al., 2013).",1. Introduction,[0],[0]
"Ben-David (2007) provides a uniform convergence result for center based clustering under a bounded support assumption and Telgarsky & Dasgupta (2013) prove uniform deviation bounds for k-Means clustering if the underlying distribution satisfies moment assumptions (see Section 4).
",1. Introduction,[0],[0]
"Empirical risk minimization with fat-tailed losses has been studied in Mendelson et al. (2014), Mendelson (2014), Grünwald & Mehta (2016) and Dinh et al. (2016).",1. Introduction,[0],[0]
Dinh et al. (2016) provide fast learning rates for k-Means clustering but under stronger assumptions than the ones considered in this paper.,1. Introduction,[0],[0]
"Guarantees similar to uniform deviation bounds can be obtained using importance sampling in the context of coreset construction (Bachem et al., 2015; Lucic et al., 2016; 2017).
",1. Introduction,[0],[0]
Our contributions.,1. Introduction,[0],[0]
We provide a new framework to obtain uniform deviation bounds for unbounded loss functions.,1. Introduction,[0],[0]
"We apply it to k-Means clustering and provide uniform deviation bounds with a rate of O ⇣ m 12 ⌘ for finite samples
under weak assumptions.",1. Introduction,[0],[0]
"In contrast to prior work, our bounds are all scale-invariant and hold for any set of k cluster centers (not only for a restricted solution set).",1. Introduction,[0],[0]
"We show that convergence depends on the kurtosis of the underlying distribution, which is the normalized fourth moment and measures the “tailedness” of a distribution.",1. Introduction,[0],[0]
"If bounded higher moments are available, we provide improved bounds that depend upon the normalized higher moments and we sharpen them even further under the stronger assumptions of subgaussianity and bounded support.
2.",1. Introduction,[0],[0]
"Problem statement for k-Means We first focus on uniform deviation bounds for k-Means clustering, and defer the (more technical) framework for unbounded loss functions to Section 5.",1. Introduction,[0],[0]
"We consider the d-dimensional Euclidean space and define
d(x,Q)
2
= min q2Q kx qk2 2
for any x 2 Rd and any finite set Q ⇢ Rd.",1. Introduction,[0],[0]
"Furthermore, slightly abusing the notation, for any x, y 2 Rd, we set d(x, y) 2
= d(x, {y})2 = kx yk2 2 .
",1. Introduction,[0],[0]
Statistical k-Means.,1. Introduction,[0],[0]
"Let P be any distribution on Rd with µ = E
P [x] and 2 = E P ⇥ d(x, µ) 2",1. Introduction,[0],[0]
"⇤ 2 (0,1).",1. Introduction,[0],[0]
"For any set
Q ⇢ Rd of k 2 N cluster centers, the expected quantization error is given by E
P
⇥ d(x,Q) 2 ⇤ .",1. Introduction,[0],[0]
"The goal of the statistical
k-Means problem is to find a set of k cluster centers such that the expected quantization error is minimized.
",1. Introduction,[0],[0]
Empirical k-Means.,1. Introduction,[0],[0]
Let X denote a finite set of points in Rd.,1. Introduction,[0],[0]
"The goal of the empirical k-Means problem is to find a set Q of k cluster centers in Rd such that the empirical quantization error X (Q) is minimized, where
X (Q) = 1 |X | X
x2X d(x,Q)
2
.
",1. Introduction,[0],[0]
Empirical risk minimization.,1. Introduction,[0],[0]
"In practice, the underlying data distribution P in statistical learning problems is often unknown.",1. Introduction,[0],[0]
"Instead, one is only able to observe independent samples from P .",1. Introduction,[0],[0]
"The empirical risk minimization principle advocates that finding a good solution on a random sample X
m also provides provably good solutions to certain statistical learning problems if enough samples m are used.
",1. Introduction,[0],[0]
Uniform deviation bounds.,1. Introduction,[0],[0]
"For k-Means, such a result may be shown by bounding the deviation between the expected loss and the empirical error, i.e.,
X
m
(Q) E P ⇥ d(x,Q) 2 ⇤ ,
uniformly for all possible clusterings Q 2 Rd⇥k.",1. Introduction,[0],[0]
"If this difference is sufficiently small for a given m, one may then solve the empirical k-Means problem on X
m and obtain provable guarantees on the expected quantization error.
3.",1. Introduction,[0],[0]
"Uniform deviation bounds for k-Means A simple approach would be to bound the deviation by an absolute error ✏, i.e., to require that
X
m
(Q) E P ⇥ d(x,Q) 2 ⇤  ✏ (1)
uniformly for a set of possible solutions (Telgarsky & Dasgupta, 2013).",1. Introduction,[0],[0]
"However, in this paper, we provide uniform deviation bounds of a more general form: For any distribution P and a sample of m = f(✏, , k, d, P ) points, we require that with probability at least 1 X
m
(Q) E P ⇥ d(x,Q) 2 ⇤  ✏ 2 2 + ✏ 2 E P ⇥ d(x,Q) 2 ⇤
(2) uniformly for all Q 2 Rd⇥k.",1. Introduction,[0],[0]
"The terms on the right-hand side may be interpreted as follows: The first term based on the variance 2 corresponds to a scale-invariant, additive approximation error.",1. Introduction,[0],[0]
The second term is a multiplicative approximation error that allows the guarantee to hold even for solutions Q with a large expected quantization error.,1. Introduction,[0],[0]
"Similar additive error terms were recently explored by Bachem et al. (2016; 2017) in the context of seeding for k-Means.
",1. Introduction,[0],[0]
"There are three key reasons why we choose (2) over (1): First, (1) is not scale-invariant and may thus not hold for classes of distributions that are equal up to scaling.",1. Introduction,[0],[0]
"Second, (1) may not hold for an unbounded solution space, e.g. Rd⇥k. Third, we can always rescale P to unit variance and restrict ourselves to solutions Q with E
P
⇥ d(x,Q) 2 ⇤  2.
",1. Introduction,[0],[0]
"Then, (2) implies (1) for a suitable transformation of P .
",1. Introduction,[0],[0]
Importance of scale-invariance.,1. Introduction,[0],[0]
"If we scale all the points in a data set X and all possible sets of solutions Q by some > 0, then the empirical quantization error is scaled by
2.",1. Introduction,[0],[0]
"Similarly, if we consider the random variable x where x ⇠ P , then the expected quantization error is scaled by
2.",1. Introduction,[0],[0]
"At the same time, the k-Means problem remains the same: an optimal solution of the scaled problem is simply a scaled optimal solution of the original problem.",1. Introduction,[0],[0]
"Crucially, however, it is impossible to achieve the guarantee in (1) for distributions that are equal up to scaling: Suppose that (1) holds for some error tolerance ✏, and sample size m with probability at least 1 .",1. Introduction,[0],[0]
"Consider a distribution P and a solution Q 2 Rd⇥k such that with probability at least
a < X
m
(Q) E P ⇥ d(x,Q) 2 ⇤ .
for some a > 0.1",1. Introduction,[0],[0]
"For > 1p a✏ , let ˜P be the distribution of the random variable x where x ⇠ P and let ˜X
m consist of m samples from ˜P .",1. Introduction,[0],[0]
"Defining ˜Q = { q | q 2 Q}, we have with probability at least
˜X m
⇣ ˜
Q ⌘ E
˜",1. Introduction,[0],[0]
"P
h d ⇣ x, ˜ Q ⌘ 2",1. Introduction,[0],[0]
"i > a 2 > ✏
1For example, let P be a nondegenerate multivariate normal distribution and Q consist of k copies of the origin.
which contradicts (1) for the distribution ˜P and the solution ˜Q.",1. Introduction,[0],[0]
"Hence, (1) cannot hold for both P and its scaled transformation ˜P .
",1. Introduction,[0],[0]
"Unrestricted solution space One way to guarantee scaleinvariance would be require that
X
m
(Q) E P ⇥ d(x,Q) 2 ⇤  ",1. Introduction,[0],[0]
"✏ 2 (3)
for all Q 2 Rd⇥k. However, while (3) is scale-invariant, it is also impossible to achieve for all solutions Q as the following example shows.",1. Introduction,[0],[0]
"For simplicity, consider the 1-Means problem in 1-dimensional space and let P be a distribution with zero mean.",1. Introduction,[0],[0]
"Let X
m denote m independent samples from P and denote by µ̂ the mean of X
m .",1. Introduction,[0],[0]
"For any finite m, suppose that µ̂ 6= 0 with high probability2 and consider a solution Q consisting of a single point q 2 R. We then have
(4)
X
m
({q}) E P ⇥ d(x, {q})2 ⇤
= X
m
({µ̂}) + d(µ̂, q)2 2 d(0, q)2
= X
m
({µ̂}) 2 + q2 2qµ̂+ µ̂2 q2
= X
m
({µ̂}) 2 + µ̂2 2qµ̂
Since µ̂ 6= 0 with high probability, clearly this expression diverges as q !",1. Introduction,[0],[0]
"1 and thus (3) cannot hold for arbitrary solutions Q 2 Rd⇥k. Intuitively, the key issue is that both the empirical and the statistical error become unbounded as q !",1. Introduction,[0],[0]
1.,1. Introduction,[0],[0]
Previous approaches such as Telgarsky & Dasgupta (2013) solve this issue by restricting the solution space from Rd⇥k to solutions that are no worse than some threshold.,1. Introduction,[0],[0]
"In contrast, we allow the deviation between the empirical and the expected quantization error to scale with E
P
⇥ d(x,Q) 2 ⇤ .
",1. Introduction,[0],[0]
Arbitrary distributions.,1. Introduction,[0],[0]
"Finally, we show that we either need to impose assumptions on P or equivalently make the relationship between m, ✏ and in (2) depend on the underlying distribution P .",1. Introduction,[0],[0]
"Suppose that there exists a sample size m 2 N, an error tolerance ✏ 2 (0, 1) and a maximal failure probability 2 (0, 1) such that (2) holds for any distribution P .",1. Introduction,[0],[0]
"Let P be the Bernoulli distribution on {0, 1} ⇢ R with P",1. Introduction,[0],[0]
"[x = 1] = p for p 2 ( 1m , 1).",1. Introduction,[0],[0]
"By design, we have µ = p,
2 = p(1 p) and E P ⇥ d(x, 1) 2 ⇤ =",1. Introduction,[0],[0]
(,1. Introduction,[0],[0]
1 p),1. Introduction,[0],[0]
.,1. Introduction,[0],[0]
"Furthermore,
with probability at least , the set X m of m independent samples from P consists of m copies of a point at one.",1. Introduction,[0],[0]
"Hence, (2) implies that with probability at least 1
X
m
(1) E P ⇥ d(x, 1) 2 ⇤  ✏E P ⇥ d(x, 1) 2 ⇤
since 2  E P ⇥ d(x, 1) 2 ⇤ .",1. Introduction,[0],[0]
"However, with probability at least , we have X m
(1) = 0 which would imply 1  ✏ and thus lead to a contradiction with ✏ 2 (0, 1).
",1. Introduction,[0],[0]
"2For example, if P is the standard normal distribution.
4.",1. Introduction,[0],[0]
"Key results for k-Means In this section, we present our main results for k-Means and defer the analysis and proofs to Sections 6.",1. Introduction,[0],[0]
"Similar to Telgarsky & Dasgupta (2013), the weakest assumption that we require is that the fourth moment of d(x, µ) for x 2 P is bounded.3 Our results are based on the kurtosis of P which we define as
ˆ M
4
=
E P ⇥ d(x, µ) 4 ⇤
4
.
",4.1. Kurtosis bound,[0],[0]
The kurtosis is the normalized fourth moment and is a scaleinvariant measure of the “tailedness” of a distribution.,4.1. Kurtosis bound,[0],[0]
"For example, the normal distribution has a kurtosis of 3, while more heavy tailed distributions such as the t-Student distribution or the Pareto distribution have a potentially unbounded kurtosis.",4.1. Kurtosis bound,[0],[0]
A natural interpretation of the kurtosis is provided by Moors (1986).,4.1. Kurtosis bound,[0],[0]
"For simplicity, consider a data set with unit variance.",4.1. Kurtosis bound,[0],[0]
"Then, the kurtosis may be restated as the shifted variance of d(x, µ)2, i.e.,
ˆ M
4
= Var d(x, µ)
2
+ 1.
",4.1. Kurtosis bound,[0],[0]
"This provides a valuable insight into why the kurtosis is relevant for our setting: For simplicity, suppose we would like to estimate the expected quantization error E
P
⇥ d(x, µ) 2 ⇤
by the empirical quantization error X m ({µ}) on a finite sample X
m .4",4.1. Kurtosis bound,[0],[0]
"Then, the kurtosis measures the dispersion of d(x, µ)2 around its mean E
P
⇥ d(x, µ) 2 ⇤ and provides a
bound on how many samples are required to achieve an error of ✏.",4.1. Kurtosis bound,[0],[0]
"While this simple example provides the key insight for the trivial solution Q = {µ}, it requires a non-trivial effort to extend the guarantee in (2) to hold uniformly for all solutions Q 2 Rd⇥k. With the use of a novel framework to learn unbounded loss functions (presented in Section 5), we are able to provide the following guarantee for k-Means.",4.1. Kurtosis bound,[0],[0]
Theorem 1 (Kurtosis).,4.1. Kurtosis bound,[0],[0]
"Let ✏, 2 (0, 1) and k 2 N. Let P be any distribution on Rd with kurtosis ˆM
4
< 1.",4.1. Kurtosis bound,[0],[0]
"For
m 12800
⇣ 8 + ˆ",4.1. Kurtosis bound,[0],[0]
"M
4
⌘
✏
2
✓ 3 + 30k(d+ 4) log 6k + log 1 ◆
let X = {x 1 , x 2 , . . .",4.1. Kurtosis bound,[0],[0]
", x m } be m independent samples from P .",4.1. Kurtosis bound,[0],[0]
"Then, with probability at least 1 , for all Q 2 Rd⇥k X (Q) EP ⇥ d(x,Q) 2
⇤  ✏ 2 2 + ✏ 2 E P ⇥ d(x,Q) 2 ⇤ .
",4.1. Kurtosis bound,[0],[0]
"3While our random variables x 2 P are potentially multivariate, it suffices to consider the behavior of the univariate random variable d(x, µ) for the assumptions in this section.
",4.1. Kurtosis bound,[0],[0]
"4This is a hypothetical exercise as EP ⇥ d(x, µ) 2",4.1. Kurtosis bound,[0],[0]
⇤ = 1 by design.,4.1. Kurtosis bound,[0],[0]
"However, it provides an insight to the importance of the kurtosis.
",4.1. Kurtosis bound,[0],[0]
The proof is provided in Section 6.1.,4.1. Kurtosis bound,[0],[0]
"The number of sufficient samples
m 2 O
ˆ M
4
✏
2
✓ dk log k + log 1
◆!
",4.1. Kurtosis bound,[0],[0]
"is linear in the kurtosis ˆM 4 and the dimensionality d, nearlinear in the number of clusters k and 1
, and quadratic in 1
✏
.",4.1. Kurtosis bound,[0],[0]
"Intuitively, the bound may be interpreted as follows:
⌦
⇣ ˆ
M4 ✏ 2
⌘ samples are required such that the guarantee holds
for a single solution Q 2 Rd⇥k. Informally, a generalization of the Vapnik Chervonenkis dimension for k-Means clustering may be bounded by O(dk log k) and measures the “complexity” of the learning problem.",4.1. Kurtosis bound,[0],[0]
"The multiplicative dk log k + log 1
term intuitively extends the guarantee uniformly to all possible Q 2 Rd⇥k. Comparison to Telgarsky & Dasgupta (2013).",4.1. Kurtosis bound,[0],[0]
"While we require a bound on the normalized fourth moment, i.e., the kurtosis, Telgarsky & Dasgupta (2013) consider the case where all unnormalized moments up to the fourth are uniformly bounded by some M , i.e.,
E P ⇥ d(x, µ)",4.1. Kurtosis bound,[0],[0]
"l ⇤  M, 1  l  4.
",4.1. Kurtosis bound,[0],[0]
"They provide uniform deviation bounds for all solutions Q such that either X (Q)  c or EP ⇥ d(x,Q) 2 ⇤  c for some c > 0.",4.1. Kurtosis bound,[0],[0]
"To compare our bounds, we consider a data set with unit variance and restrict ourselves to solutions Q 2 Rd⇥k with an expected quantization error of at most the variance, i.e., E
P
⇥ d(x,Q) 2 ⇤  2 = 1.",4.1. Kurtosis bound,[0],[0]
"Consider the deviation
= sup
Q2Rd⇥k:E P [d(x,Q) 2 ]1
X (Q) EP ⇥ d(x,Q) 2 ⇤ .
",4.1. Kurtosis bound,[0],[0]
"Telgarsky & Dasgupta (2013) bound this deviation by
2 O s M 2
p m
✓ dk log(Mdm) + log 1 ◆ + r 1
m
2
! .
",4.1. Kurtosis bound,[0],[0]
"In contrast, our bound in Theorem 1 implies
2 O
0 @ s ˆ M 4
m
✓ dk log k + log 1
◆1
A .
",4.1. Kurtosis bound,[0],[0]
"The key difference lies in how scales with the sample size m. While Telgarsky & Dasgupta (2013) show a rate of 2 O ⇣ m 14 ⌘ , we improve it to 2 O ⇣ m 12 ⌘ .",4.1. Kurtosis bound,[0],[0]
"The tail behavior of d(x, µ) may be characterized by the moments of P .",4.2. Bounded higher moments,[0],[0]
"For p 2 N, consider the standardized p-th moment of P , i.e.,
ˆ M
p
=
E P",4.2. Bounded higher moments,[0],[0]
"[d(x, µ) p ]
p
.
",4.2. Bounded higher moments,[0],[0]
Theorem 2 provides an improved uniform deviation bound if P has bounded higher moments.,4.2. Bounded higher moments,[0],[0]
Theorem 2 (Moment bound).,4.2. Bounded higher moments,[0],[0]
"Let ✏ 2 (0, 1), 2 (0, 1) and k 2 N. Let P be any distribution on Rd with finite p-th order moment bound ˆM
p < 1 for p 2 {4, 8, . . .",4.2. Bounded higher moments,[0],[0]
",1}.",4.2. Bounded higher moments,[0],[0]
"For m max ⇣ 3200m1
✏
2 ,
8 8 p ⌘ with
m
1
= p ✓ 4 + ˆ M
p
4 p ◆✓ 3 + 30k(d+ 4) log 6k + log 1 ◆
let X = {x 1 , x 2 , . . .",4.2. Bounded higher moments,[0],[0]
", x m } be m independent samples from P .",4.2. Bounded higher moments,[0],[0]
"Then, with probability at least 1 , for all Q 2 Rd⇥k X (Q) EP ⇥ d(x,Q) 2
⇤  ✏ 2 2 + ✏ 2 E P ⇥ d(x,Q) 2 ⇤ .
",4.2. Bounded higher moments,[0],[0]
The proof is provided in Section 6.2.,4.2. Bounded higher moments,[0],[0]
"Compared to the previous bound based on the kurtosis, Theorem 2 requires
m 2 ⌦
0
@p ˆ M p
4 p
✏
2
✓ dk log k + log 1 ◆ + ✓ 1 ◆ 8 p
1
A
samples.",4.2. Bounded higher moments,[0],[0]
"With higher order moment bounds, it is easier to achieve high probability results since the dependence on 1 is only of O ⇣ 1 8 p ⌘ compared to near linear for a kurtosis
bound.",4.2. Bounded higher moments,[0],[0]
The quantity ˆM,4.2. Bounded higher moments,[0],[0]
"p 4 p may be interpreted as a bound on the kurtosis ˆM 4 based on the higher order moment ˆM p since
Hoelder’s inequality implies that ˆM 4  ˆM p 4 p .",4.2. Bounded higher moments,[0],[0]
"While the result only holds for p 2 {8, 12, 16, . . .",4.2. Bounded higher moments,[0],[0]
",1}, it is trivially extended to p0 8: Consider Theorem 2 with p = 4 j p 0
4
k
and note that by Hoelder’s inequality ˆM",4.2. Bounded higher moments,[0],[0]
p 4 p  ˆM,4.2. Bounded higher moments,[0],[0]
"p 0 4 p 0 .
",4.2. Bounded higher moments,[0],[0]
Comparison to Telgarsky & Dasgupta (2013).,4.2. Bounded higher moments,[0],[0]
"Again, we consider distributions P that have unit variance and we restrict ourselves to solutions Q 2 Rd⇥k with an expected quantization error of at most the variance, i.e., E P ⇥ d(x,Q) 2 ⇤  2 = 1.",4.2. Bounded higher moments,[0],[0]
"Telgarsky & Dasgupta (2013) require that there exists a bound M
E P ⇥ d(x, µ) l ⇤  M, 1  l  p.
Then, for m sufficiently large, is of
O
0
@
s M 8 p
m
1 4 p
✓ dk ln(M 4 p dm) +",4.2. Bounded higher moments,[0],[0]
"ln 1 ◆ + 2 p 4
m
3 4 2 p
✓ 1 ◆ 4 p
1
A .
",4.2. Bounded higher moments,[0],[0]
"In contrast, we obtain that, for m sufficiently large,
2 O
0
B@
vuutp ˆM",4.2. Bounded higher moments,[0],[0]
"p 4 p
m
✓",4.2. Bounded higher moments,[0],[0]
"dk log k + log 1
◆ 1
CA.
",4.2. Bounded higher moments,[0],[0]
While Telgarsky & Dasgupta (2013) only show a rate of O ⇣ m 12 ⌘ as p !,4.2. Bounded higher moments,[0],[0]
"1, we obtain a 2 O ⇣ m 12 ⌘
rate for all higher moment bounds.",4.2. Bounded higher moments,[0],[0]
"If the distribution P is subgaussian, then all its moments ˆ M
p are bounded.",4.3. Subgaussianity,[0],[0]
"By optimizing p in Theorem 2, we are able to show the following bound.",4.3. Subgaussianity,[0],[0]
Theorem 3 (Subgaussian bound).,4.3. Subgaussianity,[0],[0]
"Let ✏ 2 (0, 1), 2 (0, 1) and k 2 N. Let P be any distribution on Rd with µ = E P",4.3. Subgaussianity,[0],[0]
"[x] and
8t > 0",4.3. Subgaussianity,[0],[0]
": P [d(x, µ) > t ]  a exp ✓ t 2
p b
◆
for some a > 1, b > 0.",4.3. Subgaussianity,[0],[0]
"Let m 3200m1 ✏ 2 with
m
1
= p ✓ 4 + abp 2
4
◆✓ 3 + 30k(d+ 4) log 6k + log 1 ◆ .
and p = 9 + 3 log 1 .",4.3. Subgaussianity,[0],[0]
"Let X = {x 1 , x 2 , . . .",4.3. Subgaussianity,[0],[0]
", x m } be m independent samples from P .",4.3. Subgaussianity,[0],[0]
"Then, with probability at least 1 , for all Q 2 Rd⇥k X (Q) EP ⇥ d(x,Q) 2
⇤  ✏ 2 2 + ✏ 2 E P ⇥ d(x,Q) 2 ⇤ .
",4.3. Subgaussianity,[0],[0]
The proof is provided in Section 6.3.,4.3. Subgaussianity,[0],[0]
"In O(·) notation,
m 2 O ab log
3
1
✏
2
✓ dk log k + log 1
◆!
",4.3. Subgaussianity,[0],[0]
samples are hence sufficient.,4.3. Subgaussianity,[0],[0]
"This result features a polylogarithmic dependence on 1
compared to the polynomial dependence for the bounds based on bounded higher moments.",4.3. Subgaussianity,[0],[0]
The sufficient sample size further scales linearly with the (scale-invariant) subgaussianity parameters a and b.,4.3. Subgaussianity,[0],[0]
"For example, if P is a one-dimensional normal distribution of any scale, we would have a = 2 and b = 1.",4.3. Subgaussianity,[0],[0]
The strongest assumption that we consider is if the support of P is bounded by a hypersphere in Rd with diameter R > 0.,4.4. Bounded support,[0],[0]
"This ensures that almost surely d(x, µ)  R and hence ˆM
4
 R4
4 .",4.4. Bounded support,[0],[0]
This allows us to obtain Theorem 4.,4.4. Bounded support,[0],[0]
Theorem 4 (Bounded support).,4.4. Bounded support,[0],[0]
"Let ✏ 2 (0, 1), 2 (0, 1) and k 2 N. Let P be any distribution on Rd, with µ = E P [x] and 2 = E P ⇥ d(x, µ) 2",4.4. Bounded support,[0],[0]
"⇤ 2 (0,1), whose support is contained in a d-dimensional hypersphere of diameter R > 0.",4.4. Bounded support,[0],[0]
"For
m 12800
⇣ 8 + R 4
4
⌘
✏
2
✓ 3 + 30k(d+ 4) log 6k + log 1 ◆
let X = {x 1 , x 2 , . . .",4.4. Bounded support,[0],[0]
", x m } be m independent samples from P .",4.4. Bounded support,[0],[0]
"Then, with probability at least 1 , for all Q 2 Rd⇥k X (Q) EP ⇥ d(x,Q) 2
⇤  ✏ 2 2 + ✏ 2 E P ⇥ d(x,Q) 2 ⇤ .
",4.4. Bounded support,[0],[0]
The proof is provided in Section 6.4.,4.4. Bounded support,[0],[0]
"Again, the sufficient sample size scales linearly with the kurtosis bound R 4
4 .",4.4. Bounded support,[0],[0]
"However, the bound is only logarithmic in 1 .",4.4. Bounded support,[0],[0]
"To obtain the results presented in Section 4, we propose a novel framework to uniformly approximate the expected values of a set of unbounded functions based on a random sample.",5. Framework for unbounded loss functions,[0],[0]
We consider a function family F mapping from an arbitrary input space X to R 0 and a distribution P on X .,5. Framework for unbounded loss functions,[0],[0]
"We further require a generalization of the VapnikChervonenkis dimension to continuous, unbounded functions5 — the pseudo-dimension.",5. Framework for unbounded loss functions,[0],[0]
Definition 1 (Haussler (1992); Li et al. (2001)).,5. Framework for unbounded loss functions,[0],[0]
"The pseudodimension of a set F of functions from X to R 0, denoted by Pdim(F), is the largest d0 such there is a sequence x
1
, . . .",5. Framework for unbounded loss functions,[0],[0]
", x
d 0 of domain elements from X and a sequence r
1
, . . .",5. Framework for unbounded loss functions,[0],[0]
", r
d 0 of reals such that for each b 1 , . . .",5. Framework for unbounded loss functions,[0],[0]
", b d 0 2 {above, below}, there is an f 2 F such that for all i = 1, . . .",5. Framework for unbounded loss functions,[0],[0]
", d 0, we have f(x i )",5. Framework for unbounded loss functions,[0],[0]
r i () b,5. Framework for unbounded loss functions,[0],[0]
"i = above.
",5. Framework for unbounded loss functions,[0],[0]
"Similar to the VC dimension, the pseudo-dimension measures the cardinality of the largest subset of X that can be shattered by the function family F .",5. Framework for unbounded loss functions,[0],[0]
"Informally, the pseudodimension measures the richness of F and plays a critical role in providing a uniform approximation guarantee across all f 2 F .",5. Framework for unbounded loss functions,[0],[0]
"With this notion, we are able to state the main result in our framework.",5. Framework for unbounded loss functions,[0],[0]
Theorem 5.,5. Framework for unbounded loss functions,[0],[0]
"Let ✏ 2 (0, 1), 2 (0, 1) and t > 0.",5. Framework for unbounded loss functions,[0],[0]
Let F be a family of functions from X to R 0 with Pdim(F ) =,5. Framework for unbounded loss functions,[0],[0]
d < 1.,5. Framework for unbounded loss functions,[0],[0]
Let s : X !,5. Framework for unbounded loss functions,[0],[0]
"R 0 be a function such that s(x) sup
f2F f(x) for all x 2 X .",5. Framework for unbounded loss functions,[0],[0]
"Let P be any distribution on X and for
m 200t ✏ 2
✓ 3 + 5d+ log 1 ◆ ,
let x 1 , x 2 , . . .",5. Framework for unbounded loss functions,[0],[0]
", x 2m be 2m independent samples from P .
",5. Framework for unbounded loss functions,[0],[0]
"Then, if
E P ⇥ s(x) 2 ⇤  t and P
"" 1
2m
2mX
i=1
s(x
i
)
2
> t # 
4
,
(5) it holds with probability at least 1 that
1
m
mX
i=1
f(x
i )",5. Framework for unbounded loss functions,[0],[0]
"E P [f(x)]  ✏, 8f 2 F .",5. Framework for unbounded loss functions,[0],[0]
"(6)
Applying Theorem 5 to a function family F requires three steps: First, one needs to bound the pseudo-dimension of
5The pseudo-dimension was originally defined for sets of functions mapping to [0, 1] (Haussler, 1992; Li et al., 2001).",5. Framework for unbounded loss functions,[0],[0]
"However, it is trivially extended to unbounded functions mapping to R 0.
F .",5. Framework for unbounded loss functions,[0],[0]
"Second, it is necessary to find a function s : X !",5. Framework for unbounded loss functions,[0],[0]
R 0,5. Framework for unbounded loss functions,[0],[0]
"such that
f(x)  s(x), 8x 2 X and 8f 2 F .
",5. Framework for unbounded loss functions,[0],[0]
"Ideally, such a bound should be as tight as possible.",5. Framework for unbounded loss functions,[0],[0]
"Third, one needs to find some t > 0",5. Framework for unbounded loss functions,[0],[0]
"and a sample size
m 200t ✏ 2
✓ 3 + 5d+ log 1 ◆
such that
E P h s(x) 2",5. Framework for unbounded loss functions,[0],[0]
"i  t and P
"" 1
2m
2mX
i=1
s(x
i
)
2
> t # 
4
.
",5. Framework for unbounded loss functions,[0],[0]
Finding such a bound usually entails examining the tail behavior of s(x)2 under P .,5. Framework for unbounded loss functions,[0],[0]
"Furthermore, it is evident that a bound t may only be found if E
P
h s(x) 2",5. Framework for unbounded loss functions,[0],[0]
"i is bounded
and that assumptions on the distribution P are required.",5. Framework for unbounded loss functions,[0],[0]
"In Section 6, we will see that for k-Means a function s(x) with E
P
h s(x) 2",5. Framework for unbounded loss functions,[0],[0]
"i < 1 may be found if the kurtosis of P is
bounded.
",5. Framework for unbounded loss functions,[0],[0]
We defer the proof of Theorem 5 to Section B of the Supplementary Materials and provide a short proof sketch that captures the main insight.,5. Framework for unbounded loss functions,[0],[0]
"The proof is based on symmetrization, the bounding of covering numbers and chaining — common techniques in the empirical process literature (Pollard, 1984; Li et al., 2001; Boucheron et al., 2013; Koltchinskii, 2011; van der Vaart & Wellner, 1996).",5. Framework for unbounded loss functions,[0],[0]
"The novelty lies in considering loss functions f(·) and cover functions s(·) in Theorem 5 that are potentially unbounded.
",5. Framework for unbounded loss functions,[0],[0]
Proof sketch.,5. Framework for unbounded loss functions,[0],[0]
Our proof is based on a double sampling approach.,5. Framework for unbounded loss functions,[0],[0]
"Let x
m+1
, x
m+2
, . . .",5. Framework for unbounded loss functions,[0],[0]
", x
2m be an additional m independent samples from P and let
1
,
2
, . . .",5. Framework for unbounded loss functions,[0],[0]
",
m be independent random variables uniformly sampled from { 1, 1}.",5. Framework for unbounded loss functions,[0],[0]
"Then, we show that, if E
P
h s(x) 2",5. Framework for unbounded loss functions,[0],[0]
"i  t, the probability
of (6) not holding may be bounded by the probability that there exists a f 2 F such that
1
m
mX
i=1
i
(f(x
i ) f(x i+m ))
",5. Framework for unbounded loss functions,[0],[0]
> ✏.,5. Framework for unbounded loss functions,[0],[0]
"(7)
We first provide the intuition for a single function f 2 F and then show how we extend it to all f 2 F .",5. Framework for unbounded loss functions,[0],[0]
"While the function f(x) is not bounded, for a given sample x
1
, x
2
, . . .",5. Framework for unbounded loss functions,[0],[0]
", x
2m , each f(x
i ) is contained within [0, s(x i )].",5. Framework for unbounded loss functions,[0],[0]
"Given the sample x
1
, x
2
, . . .",5. Framework for unbounded loss functions,[0],[0]
", x
2m , the random variable",5. Framework for unbounded loss functions,[0],[0]
"i (f(x i ) f(x i+m )
is bounded in 0±max (s(x i ), s(x i+m )) and has zero mean.",5. Framework for unbounded loss functions,[0],[0]
"Hence, given independent samples x
1
, x
2
, . . .",5. Framework for unbounded loss functions,[0],[0]
", x
2m , the probability of (7) occurring for a single f 2 F can be
bounded using Hoeffding’s inequality by
2 exp
2m✏
2
1
m
P m
i=1
max (s(x
i
), s(x
i+m
))
2
!
 2 exp m✏
2
1
2m
P 2m
i=1
s(x
i
)
2
! .
",5. Framework for unbounded loss functions,[0],[0]
"By (5), with probability at least 1 4 , we have 1
2m
P 2m
i=1
s(x
i
) 2  t and we hence require m 2 ⌦ ⇣ t log 1
✏
2
⌘
samples to guarantee that (7) does not hold for a single f 2 F with probability at least 1
2
.
",5. Framework for unbounded loss functions,[0],[0]
"To bound the probability that there exists any f 2 F such that (7) holds, we show in Lemma 5 (see Section B of the Supplementary Materials) that, given independent samples x
1
, x
2
, . . .",5. Framework for unbounded loss functions,[0],[0]
", x
2m
,
P "" 9f 2 F : 1
m
mX
i=1
i(f(xi) f(xi+m))",5. Framework for unbounded loss functions,[0],[0]
>,5. Framework for unbounded loss functions,[0],[0]
"✏
#
 4 16e2 Pdim(F) e ✏
2 m
200 1 2m P2m i=1",5. Framework for unbounded loss functions,[0],[0]
"s(xi) 2 .
",5. Framework for unbounded loss functions,[0],[0]
"The key difficulty in proving Lemma 5 is that the functions f 2 F are not bounded uniformly in [0, 1].",5. Framework for unbounded loss functions,[0],[0]
"To this end, we provide in Lemma 4 a novel result that bounds the size of ✏-packings of F if the functions f 2 F are bounded in expectation.",5. Framework for unbounded loss functions,[0],[0]
"Based on Lemma 5, we then prove the main claim of Theorem 5.
6.",5. Framework for unbounded loss functions,[0],[0]
"Analysis for k-Means In order to apply Theorem 5 to k-Means clustering, we require a suitable family F , an upper bound s(x) and a bound on E
P
h s(x) 2 i .",5. Framework for unbounded loss functions,[0],[0]
"We provide this in Lemma 1 and defer
bounding 1 2m
P 2m
i=1
s(x
i
) 2 to the proofs of Theorems 2-4.",5. Framework for unbounded loss functions,[0],[0]
Lemma 1 (k-Means).,5. Framework for unbounded loss functions,[0],[0]
"Let k 2 N. Let P be any distribution on Rd with µ = E
P",5. Framework for unbounded loss functions,[0],[0]
"[x], 2 = E P ⇥ d(x, µ) 2 ⇤ 2 (0,1) and
bounded kurtosis ˆM 4 .",5. Framework for unbounded loss functions,[0],[0]
"For any x 2 Rd and any Q 2 Rd⇥k, define
f
Q
(x) =
d(x,Q)
2
1
2
2
+
1
2
E P [d(x,Q) 2 ]
(8)
as well as the function family F = f
Q
(·) | Q 2 Rd⇥k
.",5. Framework for unbounded loss functions,[0],[0]
"Let
s(x) =
4 d(x, µ)
2
2
+ 8.
",5. Framework for unbounded loss functions,[0],[0]
"We then have
Pdim(F)  6k(d+ 4) log 6k, (9)
f
Q
(x)  s(x) (10)
for any x 2 Rd and Q 2 Rd⇥k and
E P h s(x) 2",5. Framework for unbounded loss functions,[0],[0]
i = 128 + 16 ˆ M 4 .,5. Framework for unbounded loss functions,[0],[0]
"(11)
The proof of Lemma 1 is provided in Section C of the Supplementary Materials.",5. Framework for unbounded loss functions,[0],[0]
"The definition of f
Q (x) in (8) is motivated as follows: If we use Theorem 5 to guarantee
mX
i=1
f(x
i ) E P",5. Framework for unbounded loss functions,[0],[0]
[f(x)]  ,5. Framework for unbounded loss functions,[0],[0]
✏ 8f 2 F .,5. Framework for unbounded loss functions,[0],[0]
"(12)
then this implies X (Q) EP ⇥ d(x,Q) 2
⇤  ✏ 2 2 + ✏ 2 E P ⇥",5. Framework for unbounded loss functions,[0],[0]
"d(x,Q) 2",5. Framework for unbounded loss functions,[0],[0]
"⇤
(13) as is required by Theorems 2-4.",5. Framework for unbounded loss functions,[0],[0]
Lemma 1 further shows that E [s(x)]2 is bounded if and only if the kurtosis of P is bounded.,5. Framework for unbounded loss functions,[0],[0]
"This is the reason why a bounded kurtosis is the weakest assumption on P that we require in Section 4.
",5. Framework for unbounded loss functions,[0],[0]
"We now proceed to prove Theorems 2-4 by applying Theorem 5 and examining the tail behavior of 1
2m
P 2m
i=1
s(x
i
) 2.",5. Framework for unbounded loss functions,[0],[0]
"The bound based on the kurtosis follows easily from Markov’s inequality.
",6.1. Proof of Theorem 1 (kurtosis bound),[0],[0]
Proof.,6.1. Proof of Theorem 1 (kurtosis bound),[0],[0]
"We consider the choice t = 4 ⇣ 128 + 16 ˆ M
4
⌘ / .
",6.1. Proof of Theorem 1 (kurtosis bound),[0],[0]
"By Markov’s inequality and linearity of expectation, we then have by Lemma 1 that
P "" 1
2m
2mX
i=1
s(x
i
)
2
> t #  E ⇥ s(x) 2 ⇤
t
=
4
.
",6.1. Proof of Theorem 1 (kurtosis bound),[0],[0]
"Furthermore, E P h s(x) 2",6.1. Proof of Theorem 1 (kurtosis bound),[0],[0]
i  t.,6.1. Proof of Theorem 1 (kurtosis bound),[0],[0]
"Hence, we may apply Theo-
rem 5 to obtain that for
m 12800
⇣ 8 + ˆ",6.1. Proof of Theorem 1 (kurtosis bound),[0],[0]
"M
4
⌘
✏
2
✓ 3 + 30k(d+ 4) log 6k + log 1 ◆ ,
it holds with probability at least 1 that 1
m
mX
i=1
f(x
i
)",6.1. Proof of Theorem 1 (kurtosis bound),[0],[0]
E,6.1. Proof of Theorem 1 (kurtosis bound),[0],[0]
[f(x)]  ,6.1. Proof of Theorem 1 (kurtosis bound),[0],[0]
"✏ 8f 2 F .
",6.1. Proof of Theorem 1 (kurtosis bound),[0],[0]
This implies the main claim and thus concludes the proof.,6.1. Proof of Theorem 1 (kurtosis bound),[0],[0]
"We prove the result by bounding the higher moments of 1
2m
P 2m
i=1
s(x
i
) 2 using the Marcinkiewicz-Zygmund inequality and subsequently applying Markov’s inequality.
",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
Proof.,6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"Hoelder’s inequality implies
ˆ M
4
=
E P ⇥ d(x, µ) 4 ⇤
4
 EP [d(x, µ) p ]
4 p
4
 ˆM p
4 p
Hence, by Lemma 1 we have that E P ⇥ s(x) 2 ⇤  128 +
16
ˆ M
p
4 p Since s(x)2 0 for all x 2 Rd, we have
s(x) 2 E P ⇥ s(x) 2 ⇤  max s(x) 2 ,E P ⇥ s(x) 2 ⇤
 max ✓ s(x) 2 , 128 + 16 ˆ M
p
4 p
◆
 128
+ 16max
✓ ˆ
M
p
4 p
, 2
d(x, µ)
4
4
◆ .
",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"(14)
",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"This implies that
(15)
E P h s(x) 2 E P ⇥ s(x) 2 ⇤ p 4",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"i
 256 p 4 + 32 p 4 max
✓ ˆ
M
p
, 2
p 4 E P [d(x, µ) p ]
p
◆
 256 p 4 + 32 p 4 max
⇣ ˆ
M
p
, 2
p 4 ˆ",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"M
p
⌘
 256 p 4 + 64 p 4 ˆ",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"M
p
.
",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"We apply a variant of the Marcinkiewicz-Zygmund inequality (Ren & Liang, 2001) to the zero-mean random variable s(x) 2 E P ⇥ s(x) 2 ⇤ to obtain
(16)
E P
2
4 1
2m
2mX
i=1
s(x
i
) 2 E P ⇥ s(x) 2 ⇤
p 4
3
5
 ✓
p 4 4 p 2m
◆ p 4
E P h s(x) 2 E P ⇥ s(x)",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
2 ⇤ p 4,6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"i
 ✓
p 4 4 p 2m
◆ p 4 ⇣
256
p 4 + 64 p 4 ˆ M
p
⌘
For u > 0, the Markov inequality implies
(17)
P "" 1
2m
2mX
i=1
s(x
i
) 2 E P ⇥ s(x) 2",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"⇤ > u
#
 ✓
p 4 4u p 2m
◆ p 4 ⇣
256
p 4 + 64 p 4 ˆ M
p
⌘
 ✓
p 4 4u p 2m
◆ p 4
2max ⇣ 256 p 4 , 64 p 4 ˆ M
p
⌘
 2 ✓
p 4 4u p 2m max
✓ 256, 64 ˆ M
p
4 p
◆◆ p 4
 2 ✓
p 4 u p 2m
✓ 64 + 16 ˆ M
p
4 p
◆◆ p 4
.
",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"For u = (p 4) ✓ 64 + 16 ˆ M
p
4 p ◆ , we thus have
P "" 1
2m
2mX
i=1
s(x
i
) 2 E P ⇥ s(x) 2 ⇤ > u #  2m p 8
(18)
",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"Since m 8 8 p , this implies
(19)P "" 1
2m
2mX
i=1
s(x
i
) 2 E P ⇥ s(x) 2 ⇤ > u # 
4
It holds that
u+E P ⇥ s(x) 2 ⇤ =",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"(p 4) ✓ 64+16 ˆ M p 4 p ◆ +128+16 ˆ M p 4 p
 p ✓ 64 + 16 ˆ M
p
4 p
◆
(20)
",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"We set t = p ✓ 64 + 16 ˆ M
p
4 p ◆ and thus have
(21)P "" 1
2m
2mX
i=1
s(x
i
)
2
> t # 
4
In combination with E P h s(x) 2",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"i  t by Lemma 1, we may
thus apply Theorem 5.",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"Since m 3200m1 ✏ 2 with
m
1
= p ✓ 4 + ˆ M
p
4 p ◆✓ 3 + 30k(d+ 4) log 6k + log 1 ◆
it holds with probability at least 1 that 1
m
mX
i=1
f(x
i
)",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
E,6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
[f(x)]  ,6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"✏ 8f 2 F .
",6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
This implies the main claim and thus concludes the proof.,6.2. Proof of Theorem 2 (higher order moment bound),[0],[0]
"Under subgaussianity, all moments of d(x, µ) are bounded.",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
"We show the result by optimizing over p in Theorem 2.
",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
Proof.,6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
"For p 2 {4, 8, . . .",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
",1}, we have
(22)
ˆ M
p = E P
 d(x, µ) p
=
Z 1
0
P  d(x, µ) >",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
"u 1 p du
 Z 1
0
a exp
u
2 p p b
!",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
"du.
Let u(t) = b p 4 t p 2 which implies du/dt = b p 4 p
2
t
p 2 1.",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
"Hence,
ˆ M
p
 ab p 4 p
2
Z 1
0
e t t
p 2 1 dt.
",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
"By the definition of the gamma function and since p is even, we have
Z 1
0
e t t
p 2 1 dt =
⇣ p
2
⌘ = ⇣ p
2
1 ⌘ !",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
"⇣ p
2
⌘ p 2 1
Hence, for p 2 {4, 8, . . .",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
",1}, we have
ˆ M
p
4 p  1
4
a
4 p
bp 2  1 4 abp 2 .
",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
"Let p⇤ = 4 ⌃ 5
4
+
3
4
log
1 ⌥ which implies
p⇤ 5 + 3 log 1
8 log 48 log 8
and thus 8 8 p⇤  48.",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
"We instantiate Theorem 2 with
the p⇤th-order bound ˆMp⇤ of P .",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
"Since 8
8 p⇤  48, the
minimum sample size is thus
3200p⇤ ✏ 2
✓ 4 + abp⇤ 2
4
◆✓ 3 + 30k(d+ 4) log 6k + log 1 ◆ .
",6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
The main claim finally holds since p⇤  p = 9 + 3 log 1 .,6.3. Proof of Theorem 3 (subgaussianity),[0],[0]
Proof.,6.4. Proof of Theorem 4 (bounded support),[0],[0]
Let t = 128 + 64R4/ 4.,6.4. Proof of Theorem 4 (bounded support),[0],[0]
"Since the support of P is bounded, we have s(x)  t for all x 2 Rd.",6.4. Proof of Theorem 4 (bounded support),[0],[0]
"This implies that E
P
h s(x) 2",6.4. Proof of Theorem 4 (bounded support),[0],[0]
"i  t and that 1
2m
P 2m
i=1
s(x
i
) 2  t almost surely.",6.4. Proof of Theorem 4 (bounded support),[0],[0]
The result then follows from Theorem 5.,6.4. Proof of Theorem 4 (bounded support),[0],[0]
We have presented a framework to uniformly approximate the expected value of unbounded functions on a sample.,7. Conclusion,[0],[0]
With this framework we are able to provide theoretical guarantees for empirical risk minimization in k-Means clustering if the kurtosis of the underlying distribution is bounded.,7. Conclusion,[0],[0]
"In particular, we obtain state-of-the art bounds on the sufficient number of samples to achieve a given uniform approximation error.",7. Conclusion,[0],[0]
"If the underlying distribution fulfills stronger assumptions, such as bounded higher moments, subgaussianity or bounded support, our analysis yields progressively better bounds.",7. Conclusion,[0],[0]
"We conjecture that Theorem 5 can be applied to other related problems such as hard and soft Bregman clustering, likelihood estimation of Gaussian mixture models, as well as nonparametric clustering problems.",7. Conclusion,[0],[0]
"However, such results do not follow immediately and require additional arguments beyond the scope of this paper.",7. Conclusion,[0],[0]
"This research was partially supported by SNSF NRP 75, ERC StG 307036, a Google Ph.D. Fellowship and an IBM Ph.D. Fellowship.",Acknowledgements,[0],[0]
This work was done in part while Andreas Krause was visiting the Simons Institute for the Theory of Computing.,Acknowledgements,[0],[0]
Uniform deviation bounds limit the difference between a model’s expected loss and its loss on a random sample uniformly for all models in a learning problem.,abstractText,[0],[0]
"In this paper, we provide a novel framework to obtain uniform deviation bounds for unbounded loss functions.",abstractText,[0],[0]
"As a result, we obtain competitive uniform deviation bounds for k-Means clustering under weak assumptions on the underlying distribution.",abstractText,[0],[0]
"If the fourth moment is bounded, we prove a rate of O ⇣",abstractText,[0],[0]
Uniform Deviation Bounds for k-Means Clustering,title,[0],[0]
Reinforcement learning is a formalism for trial-and-error interaction between an agent and an unknown environment.,1. Introduction,[0],[0]
"This interaction is typically specified by a Markov decision process (MDP), which contains a transition model, reward model, and potentially discount parameters specifying a discount on the sum of future values in the return.",1. Introduction,[0],[0]
Domains are typically separated into two cases: episodic problems (finite horizon) and continuing problems (infinite horizon).,1. Introduction,[0],[0]
"In episodic problems, the agent reaches some terminal state, and is teleported back to a start state.",1. Introduction,[0],[0]
"In continuing problems, the agent interaction is continual, with a discount to ensure a finite total reward (e.g., constant < 1).
",1. Introduction,[0],[0]
"This formalism has a long and successful tradition, but is limited in the problems that can be specified.",1. Introduction,[0],[0]
"Progressively there have been additions to specify a broader range of ob-
1Department of Computer Science, Indiana University.",1. Introduction,[0],[0]
"Correspondence to: Martha White <martha@indiana.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"jectives, including options (Sutton et al., 1999), state-based discounting (Sutton, 1995; Sutton et al., 2011) and interest functions (Reza and Sutton, 2010; Sutton et al., 2016).",1. Introduction,[0],[0]
"These generalizations have particularly been driven by offpolicy learning and the introduction of general value functions for Horde (Sutton et al., 2011; White, 2015), where predictive knowledge can be encoded as more complex prediction and control tasks.",1. Introduction,[0],[0]
"Generalizations to problem specifications provide exciting learning opportunities, but can also reduce clarity and complicate algorithm development and theory.",1. Introduction,[0],[0]
"For example, options and general value functions have significant overlap, but because of different terminology and formalization, the connections are not transparent.",1. Introduction,[0],[0]
"Another example is the classic divide between episodic and continuing problems, which typically require different convergence proofs (Bertsekas and Tsitsiklis, 1996; Tsitsiklis and Van Roy, 1997; Sutton et al., 2009) and different algorithm specifications.
",1. Introduction,[0],[0]
"In this work, we propose a formalism for reinforcement learning task specification that unifies many of these generalizations.",1. Introduction,[0],[0]
The focus of the formalism is to separate the specification of the dynamics of the environment and the specification of the objective within that environment.,1. Introduction,[0],[0]
"Though natural, this represents a significant change in the way tasks are currently specified in reinforcement learning and has important ramifications for simplifying implementation, algorithm development and theory.",1. Introduction,[0],[0]
The paper consists of two main contributions.,1. Introduction,[0],[0]
"First, we demonstrate the utility of this formalism by showing unification of previous tasks specified in reinforcement learning, including options, general value functions and episodic and continuing, and further providing case studies of utility.",1. Introduction,[0],[0]
"We demonstrate how to specify episodic and continuing tasks with only modifications to the discount function, without the addition of states and modifications to the underlying Markov decision process.",1. Introduction,[0],[0]
This enables a unification that significantly simplifies implementation and easily generalizes theory to cover both settings.,1. Introduction,[0],[0]
"Second, we prove novel contraction bounds on the Bellman operator for these generalized RL tasks, and show that previous bounds for both episodic and continuing tasks are subsumed by this more general result.",1. Introduction,[0],[0]
"Overall, our goal is to provide an RL task formalism that requires minimal modifications to previous task specification, with significant gains in simplicity and unification across common settings.",1. Introduction,[0],[0]
"We assume the agent interacts with an environment formalized by a Markov decision process (MDP): (S,A,Pr) where S is the set of states, n = |S|; A is the set of actions; and Pr : S ⇥",2. Generalized problem formulation,[0],[0]
A ⇥ S !,2. Generalized problem formulation,[0],[0]
"[0, 1] is the transition probability function where Pr(s, a, s0) is the probability of transitioning from state s into state s0 when taking action",2. Generalized problem formulation,[0],[0]
"a. A reinforcement learning task (RL task) is specified on top of these transition dynamics, as the tuple (P, r, , i) where
1.",2. Generalized problem formulation,[0],[0]
P is a set of policies ⇡ : S ⇥A !,2. Generalized problem formulation,[0],[0]
"[0, 1];
2.",2. Generalized problem formulation,[0],[0]
the reward function r : S ⇥,2. Generalized problem formulation,[0],[0]
A ⇥ S !,2. Generalized problem formulation,[0],[0]
"R specifies reward received from (s, a, s0);
3.",2. Generalized problem formulation,[0],[0]
: S⇥A⇥S !,2. Generalized problem formulation,[0],[0]
"[0, 1] is a transition-based discount function1;
4.",2. Generalized problem formulation,[0],[0]
i : S !,2. Generalized problem formulation,[0],[0]
"[0,1) is an interest function that specifies the user defined interest in a state.
",2. Generalized problem formulation,[0],[0]
Each task could have different reward functions within the same environment.,2. Generalized problem formulation,[0],[0]
"For example, in a navigation task within an office, one agent could have the goal to navigate to the kitchen and the other the conference room.",2. Generalized problem formulation,[0],[0]
"For a reinforcement learning task, whether prediction or control, a set or class of policies is typically considered.",2. Generalized problem formulation,[0],[0]
"For prediction (policy evaluation), we often select one policy and evaluate its long-term discounted reward.",2. Generalized problem formulation,[0],[0]
"For control, where a policy is learned, the set of policies may consist of all policies parameterized by weights that specify the action-value from states, with the goal to find the weights that yield the optimal policy.",2. Generalized problem formulation,[0],[0]
"For either prediction or control in an RL task, we often evaluate the return of a policy: the cumulative discounted reward obtained from following that policy
Gt =
1X
i=0
0 @ i 1Y
j=0
(st+j , at+j , st+1+j)
1
A Rt+1+i
where Q 1
j=0",2. Generalized problem formulation,[0],[0]
"(st+j , at+j , st+1+j) := 1.",2. Generalized problem formulation,[0],[0]
Note that this subsumes the setting with a constant discount c 2,2. Generalized problem formulation,[0],[0]
"[0, 1), by using (s, a, s0)",2. Generalized problem formulation,[0],[0]
"= c for every s, a, s0 and so givingQi 1
j=0",2. Generalized problem formulation,[0],[0]
"(st+j , at+j , st+1+j) =",2. Generalized problem formulation,[0],[0]
i c for i > 0 and 0c = 1 for i = 0.,2. Generalized problem formulation,[0],[0]
"As another example, the end of the episode, (s, a, s 0 )",2. Generalized problem formulation,[0],[0]
"= 0, making the product of these discounts zero and so terminating the recursion.",2. Generalized problem formulation,[0],[0]
We further explain how transition-based discount enables specification of episodic tasks and discuss the utility of the generalization to transition-based discounting throughout this paper.,2. Generalized problem formulation,[0],[0]
"Finally, the interest function i specifies the degree of importance
1We describe a further probabilistic generalization in Appendix A; much of the treatment remains the same, but the notation becomes cumbersome and the utility obfuscated.
of each state for the task.",2. Generalized problem formulation,[0],[0]
"For example, if an agent is only interested in learning an optimal policy for a subset of the environment, the interest function could be set to one for those states and to zero otherwise.
",2. Generalized problem formulation,[0],[0]
"We first explain the specification and use of such tasks, and then define a generalized Bellman operator and resulting algorithmic extensions and approximation bounds.",2. Generalized problem formulation,[0],[0]
The RL task specification enables episodic and continuing problems to be easily encoded with only modification to the transition-based discount.,2.1. Unifying episodic and continuing specification,[0],[0]
"Previous approaches, including the absorbing state formulation (Sutton and Barto, 1998b) and state-based discounting (Sutton, 1995; Reza and Sutton, 2010; Sutton et al., 2011)(van",2.1. Unifying episodic and continuing specification,[0],[0]
"Hasselt, 2011, Section 2.1.1), require special cases or modifications to the set of states and underlying MDP, coupling task specification and the dynamics of the environment.
",2.1. Unifying episodic and continuing specification,[0],[0]
We demonstrate how transition-based discounting seamlessly enables episodic or continuing tasks to be specified in an MDP via a simple chain world.,2.1. Unifying episodic and continuing specification,[0],[0]
"Consider the chain world with three states s1, s2 and s3 in Figure 1.",2.1. Unifying episodic and continuing specification,[0],[0]
The start state is s1 and the two actions are right and left.,2.1. Unifying episodic and continuing specification,[0],[0]
"The reward is -1 per step, with termination occurring when taking action right from state s3, which causes a transition back to state s1.",2.1. Unifying episodic and continuing specification,[0],[0]
"The discount is 1 for each step, unless specified otherwise.",2.1. Unifying episodic and continuing specification,[0],[0]
"The interest is set to 1 in all states, which is the typical case, meaning performance from each state is equally important.
",2.1. Unifying episodic and continuing specification,[0],[0]
"Figure 1a depicts the classical approach to specifying episodic problems using an absorbing state, drawn as a square.",2.1. Unifying episodic and continuing specification,[0],[0]
"The agent reaches the goal—transitioning right from state s3—then forever stays in the absorbing state, receiving a reward of zero.",2.1. Unifying episodic and continuing specification,[0],[0]
"This encapsulates the definition of the return, but does not allow the agent to start another episode.",2.1. Unifying episodic and continuing specification,[0],[0]
"In practice, when this absorbing state is reached, the agent is “teleported"" to a start state to start another episode.",2.1. Unifying episodic and continuing specification,[0],[0]
"This episodic interaction can instead be represented the same way as a continuing problem, by specifying a transition-based discount (s3, right, s1) = 0.",2.1. Unifying episodic and continuing specification,[0],[0]
"This defines the same return, but now the agent simply transitions normally to a start state, and no hypothetical states are added.
",2.1. Unifying episodic and continuing specification,[0],[0]
"To further understand the equivalence, consider the updates made by TD (see equation (3)).",2.1. Unifying episodic and continuing specification,[0],[0]
Assume linear function approximation with feature function x : S !,2.1. Unifying episodic and continuing specification,[0],[0]
"Rd, with weights w 2 Rd.",2.1. Unifying episodic and continuing specification,[0],[0]
"When the agent takes action right from s3, the agent transitions from s3 to s1 with probability one and so t+1 = (s3, right, s1) = 0.",2.1. Unifying episodic and continuing specification,[0],[0]
"This correctly gives
t = rt+1 + t+1x(s1) >",2.1. Unifying episodic and continuing specification,[0],[0]
"w x(s3)>w = rt+1 x(s3)>w
and correctly clears the eligibility trace for the next step
et+1 = t+1 t+1et + x(s1)",2.1. Unifying episodic and continuing specification,[0],[0]
"= x(s1).
",2.1. Unifying episodic and continuing specification,[0],[0]
"The stationary distribution is also clearly equal to the original episodic task, since the absorbing state is not used in the computation of the stationary distribution.
",2.1. Unifying episodic and continuing specification,[0],[0]
"Another strategy is to still introduce hypothetical states, but use state-based , as discussed in Figure 1c.",2.1. Unifying episodic and continuing specification,[0],[0]
"Unlike absorbing states, the agent does not stay indefinitely in the hypothetical state.",2.1. Unifying episodic and continuing specification,[0],[0]
"When the agent goes right from s3, it transitions to hypothetical state s4, and then transition deterministically to the start state s1, with s(s4) = 0.",2.1. Unifying episodic and continuing specification,[0],[0]
"As before, we get the correct update, because t+1 = s(s4) = 0.",2.1. Unifying episodic and continuing specification,[0],[0]
"Because the stationary distribution has some non-zero probability in the hypothetical state s4, we must set x(s4) = x(s1) (or x(s4) = 0).",2.1. Unifying episodic and continuing specification,[0],[0]
"Otherwise, the value of the hypothetical state will be learned, wasting function approximation resources and potentially modifying the approximation quality of the value in other states.",2.1. Unifying episodic and continuing specification,[0],[0]
We could have tried state-based discounting without adding an additional state s4.,2.1. Unifying episodic and continuing specification,[0],[0]
"However, this leads to incorrect value estimates, as depicted in Figure 1d; the relationship between transition-based and state-based is further discussed in Appendix B.1.",2.1. Unifying episodic and continuing specification,[0],[0]
"Overall, to keep the specification of the RL task and the MDP separate, transition-based discounting is necessary to enable the unified specification of episodic and continuing tasks.",2.1. Unifying episodic and continuing specification,[0],[0]
"The options framework (Sutton et al., 1999) generically covers a wide range of settings, with discussion about macroactions, option models, interrupting options and intra-option value learning.",2.2. Options as RL tasks,[0],[0]
"These concepts at the time merited their own language, but with recent generalizations can be more conveniently cast as RL subtasks.
",2.2. Options as RL tasks,[0],[0]
Proposition 1.,2.2. Options as RL tasks,[0],[0]
"An option, defined as the tuple (Sutton et al., 1999, Section 2) (⇡, , I) with policy ⇡ : S ⇥",2.2. Options as RL tasks,[0],[0]
A !,2.2. Options as RL tasks,[0],[0]
"[0, 1], termination function : S !",2.2. Options as RL tasks,[0],[0]
"[0, 1] and an initiation set I ⇢ S from which the option can be run, can be equivalently cast as an RL task.
",2.2. Options as RL tasks,[0],[0]
"This proof is mainly definitional, but we state it as an explicit proposition for clarity.",2.2. Options as RL tasks,[0],[0]
"The discount function (s, a, s 0 )",2.2. Options as RL tasks,[0],[0]
"= 1 (s0) for all s, a, s0 specifies termination.",2.2. Options as RL tasks,[0],[0]
"The interest function, i(s)",2.2. Options as RL tasks,[0],[0]
= 1 if s 2 I and i(s),2.2. Options as RL tasks,[0],[0]
= 0,2.2. Options as RL tasks,[0],[0]
"otherwise, focuses learning resources on the states of interest.",2.2. Options as RL tasks,[0],[0]
"If a value function for the policy is queried, it would only make sense to query it from these states of interest.",2.2. Options as RL tasks,[0],[0]
"If the policy for this option is optimized for this interest function, the policy should only be run starting from s 2 I, as elsewhere will be poorly learned.",2.2. Options as RL tasks,[0],[0]
"The rewards for the RL task correspond to the rewards associated with the MDP.
RL tasks generalize options, by generalizing termination conditions to transition-based discounting and by providing degrees of interest rather than binary interest.",2.2. Options as RL tasks,[0],[0]
"Further, the policies associated with RL subtasks can be used as macro-
actions, to specify a semi-Markov decision process (Sutton et al., 1999, Theorem 1).",2.2. Options as RL tasks,[0],[0]
"In a similar spirit of abstraction as options, general value functions were introduced for single predictive or goaloriented questions about the world (Sutton et al., 2011).",2.3. General value functions,[0],[0]
"The idea is to encode predictive knowledge in the form of value function predictions: with a collection or horde of prediction demons, this constitutes knowledge (Sutton et al., 2011; Modayil et al., 2014; White, 2015).",2.3. General value functions,[0],[0]
"The work on Horde (Sutton et al., 2011) and nexting (Modayil et al., 2014) provide numerous examples of the utility of the types of questions that can be specified by general value functions, and so by RL tasks, because general value functions can
naturally can be specified as an RL task.
",2.3. General value functions,[0],[0]
The generalization to RL tasks provide additional benefits for predictive knowledge.,2.3. General value functions,[0],[0]
"The separation into underlying MDP dynamics and task specification is particularly useful in off-policy learning, with the Horde formalism, where many demons (value functions) are learned off-policy.",2.3. General value functions,[0],[0]
"These demons share the underlying dynamics, and even feature representation, but have separate prediction and control tasks; keeping these separate from the MDP is key for avoiding complications (see Appendix B.2).",2.3. General value functions,[0],[0]
"Transition-based discounts, over state-based discounts, additionally enable the prediction of a change, caused by transitioning between states.",2.3. General value functions,[0],[0]
"Consider the taxi domain, described more fully in Section 3, where the agent’s goal is to pick up and drop off passengers in a grid world with walls.",2.3. General value functions,[0],[0]
"The taxi agent may wish to predict the probability of hitting a wall, when following a given policy.",2.3. General value functions,[0],[0]
"This can be encoded by setting (s, a, s) = 0",2.3. General value functions,[0],[0]
"if a movement action causes the agent to remain in the same state, which occurs when trying to move through a wall.",2.3. General value functions,[0],[0]
"In addition to episodic problems and hard termination, transition-based questions also enable soft termination for transitions.",2.3. General value functions,[0],[0]
"Hard termination uses (s, a, s0) = 0 and soft termination (s, a, s0) =",2.3. General value functions,[0],[0]
✏ for some small positive value ✏.,2.3. General value functions,[0],[0]
Soft terminations can be useful for incorporating some of the value of a policy right after the soft termination.,2.3. General value functions,[0],[0]
"If two policies are equivalent up to a transition, but have very different returns after the transition, a soft termination will reflect that difference.",2.3. General value functions,[0],[0]
We empirically demonstrate the utility of soft termination in the next section.,2.3. General value functions,[0],[0]
"To better ground this generalized formalism and provide some intuition, we provide a demonstration of RL task specification.",3. Demonstration in the taxi domain,[0],[0]
"We explore different transition-based discounts in the taxi domain (Dietterich, 2000; Diuk et al., 2008).",3. Demonstration in the taxi domain,[0],[0]
"The goal of the agent is to take a passenger from a source platform to a destination platform, depicted in Figure 2.",3. Demonstration in the taxi domain,[0.9529397190107032],['The first step is to train a decision tree on a dataset in which each sample consists of features describing a mention pair.']
"The agent receives a reward of -1 on each step, except for successful pickup and drop-off, giving reward 0.",3. Demonstration in the taxi domain,[0],[0]
"We modify the domain to include the orientation of the taxi, with additional cost for not continuing in the current orientation.",3. Demonstration in the taxi domain,[0],[0]
"This encodes that turning right, left or going backwards are more costly than going forwards, with additional negative rewards of -0.05, -0.1 and -0.2 respectively.",3. Demonstration in the taxi domain,[0],[0]
This additional cost is further multiplied by a factor of 2 when there is a passenger in the vehicle.,3. Demonstration in the taxi domain,[0],[0]
"For grid size g and the number of pickup/dropoff locations l, the full state information is a 5-tuple: (x position of taxi 2 {1, . . .",3. Demonstration in the taxi domain,[0],[0]
", g}, y position of taxi 2 {1, . . .",3. Demonstration in the taxi domain,[0],[0]
", g}, location of passenger 2 {1, . . .",3. Demonstration in the taxi domain,[0],[0]
", l + 1}, location of destination 2 {1, . . .",3. Demonstration in the taxi domain,[0],[0]
", l}, orientation of car 2 {N,E, S,W} ).",3. Demonstration in the taxi domain,[0],[0]
"The location of the passenger can be in one of the pickup/drop-off locations, or in the taxi.",3. Demonstration in the taxi domain,[0],[0]
"Optimal
policies and value functions are computed iteratively, with an extensive number of iterations.
",3. Demonstration in the taxi domain,[0],[0]
"Figure 2 illustrates three policies for one part of the taxi domain, obtained with three different discount functions.",3. Demonstration in the taxi domain,[0],[0]
"The optimal policy is learned using a soft-termination, which takes into consideration the importance of approaching the passenger location with the right orientation to minimize turns after picking up the passenger.",3. Demonstration in the taxi domain,[0],[0]
"A suboptimal policy is in fact learned with hard termination, as the policy prefers to greedily minimize turns to get to the passenger.",3. Demonstration in the taxi domain,[0],[0]
"For further details, refer to the caption in Figure 2.
",3. Demonstration in the taxi domain,[0],[0]
"We also compare to a constant , which corresponds to an average reward goal, as demonstrated in Equation (8).",3. Demonstration in the taxi domain,[0],[0]
The table in Figure 2(e) summarizes the results.,3. Demonstration in the taxi domain,[0],[0]
"Though in theory it should in fact recognize the relative values of orientation before and after picking up a passenger, and obtain the same solution as the soft-termination policy, in practice we find that numerical imprecision actually causes a suboptimal policy to be learned.",3. Demonstration in the taxi domain,[0],[0]
"Because most of the rewards are negative per step, small differences in orientation can be more difficult to distinguish amongst for an infinite discounted sum.",3. Demonstration in the taxi domain,[0],[0]
"This result actually suggests that having multiple subgoals, as one might have with RL subtasks, could enable better chaining of decisions and local evaluation of the optimal action.",3. Demonstration in the taxi domain,[0],[0]
"The utility of learning with a smaller c has been previously described (Jiang et al., 2015), however, here we further advocate that enabling that provides subtasks is another strategy to improve learning.",3. Demonstration in the taxi domain,[0],[0]
"With an intuition for the specification of problems as RL tasks, we now turn to generalizing some key algorithmic concepts to enable learning for RL tasks.",4. Objectives and algorithms,[0],[0]
We first generalize the definition of the Bellman operator for the value function.,4. Objectives and algorithms,[0],[0]
For a policy ⇡ : S ⇥A !,4. Objectives and algorithms,[0],[0]
"[0, 1], define P⇡,P⇡, 2 Rn⇥n and r⇡,v⇡ 2 Rn, indexed by states s, s0 2 S ,
P⇡(s, s 0 ) :",4. Objectives and algorithms,[0],[0]
"=
X
a2A
⇡(s, a)Pr(s, a, s0)
P⇡, (s, s 0 ) :",4. Objectives and algorithms,[0],[0]
"=
X
a2A
⇡(s, a)Pr(s, a, s0) (s, a, s0)
r⇡(s) := X
a2A
⇡(s, a) X
s02S
Pr(s, a, s0)r(s, a, s0)
v⇡(s) := r⇡(s) + X
s02S
P⇡, (s, s 0 )v⇡(s 0 ).
",4. Objectives and algorithms,[0],[0]
"where v⇡(s) is the expected return, starting from a state s 2 S .",4. Objectives and algorithms,[0],[0]
"To compute a value function that satisfies this recursion, we define a Bellman operator.",4. Objectives and algorithms,[0],[0]
The Bellman operator has been generalized to include state-based discounting and a state-based trace parameter2,4. Objectives and algorithms,[0],[0]
"(Sutton et al., 2016, Eq. 29).
",4. Objectives and algorithms,[0],[0]
"2A generalization to state-based trace parameters has been considered (Sutton, 1995; Sutton and Barto, 1998b; Reza and
We further generalize the definition to the transition-based setting.",4. Objectives and algorithms,[0],[0]
The trace parameter : S ⇥,4. Objectives and algorithms,[0],[0]
A ⇥ S !,4. Objectives and algorithms,[0],[0]
"[0, 1] influences the fixed point and provides a modified (biased) return, called the -return; this parameter is typically motivated as a bias-variance trade-off parameter (Kearns and Singh, 2000).",4. Objectives and algorithms,[0],[0]
"Because the focus of this work is on generalizing the discount, we opt for a simple constant c in the main body of the text; we provide generalizations to transition-based trace parameters in the appendix.
",4. Objectives and algorithms,[0],[0]
The generalized Bellman operator T( ) : Rn !,4. Objectives and algorithms,[0],[0]
"Rn is
T ( ) v :",4. Objectives and algorithms,[0],[0]
"= r
⇡ +P ⇡v, 8v 2 Rn (1)
where P ⇡ := (I cP⇡, ) 1
P⇡, (1 c) (2) r
⇡ := (I cP⇡, )
1 r⇡
To see why this is the definition of the Bellman operator, we define the expected -return, v⇡, 2 Rn for a given approximate value function, given by a vector v 2 Rn.
v⇡, (s) := r⇡(s)+
X
s02S P⇡, (s, s
0 )",4. Objectives and algorithms,[0],[0]
"[(1 c)v(s0)+ cv⇡, (s0)]
= r⇡(s) + (1 c)P⇡, (s, :)v + cP⇡, (s, :)v⇡, .
",4. Objectives and algorithms,[0],[0]
"Sutton, 2010; Sutton et al., 2014; Yu, 2012).
",4. Objectives and algorithms,[0],[0]
"Continuing the recursion, we obtain3
v⇡, =
"" 1X
i=0
( cP⇡, ) i # (r⇡ + (1 c)P⇡, v)
= (I cP⇡, ) 1 (r⇡ + (1 c)P⇡, v) = T( )v
The fixed point for this formula satisfies T( )v = v for the Bellman operator defined in Equation (1).
",4. Objectives and algorithms,[0],[0]
"To see how this generalized Bellman operator modifies the algorithms, we consider the extension to temporal difference algorithms.",4. Objectives and algorithms,[0],[0]
"Many algorithms can be easily generalized by replacing c or s(st+1) with transition-based (st, at, st+1).",4. Objectives and algorithms,[0],[0]
"For example, the TD algorithm is generalized by setting the discount on each step to t+1 = (st, at, st+1),
wt+1 = wt + ↵t tet .",4. Objectives and algorithms,[0],[0]
for some step-size ↵t t := rt+1 + t+1x(st+1) >,4. Objectives and algorithms,[0],[0]
"w x(st)>w (3)
et = t",4. Objectives and algorithms,[0],[0]
cet,4. Objectives and algorithms,[0],[0]
"1 + x(st).
",4. Objectives and algorithms,[0],[0]
"3For a matrix M with maximum eigenvalue less than 1,P1 i=0 M i =",4. Objectives and algorithms,[0],[0]
(I M) 1.,4. Objectives and algorithms,[0],[0]
"We show in Lemma 3 that P⇡, satisfies this condition, implying cP⇡, satisfies this condition and so this infinite sum is well-defined.
",4. Objectives and algorithms,[0],[0]
"The generalized TD fixed-point, under linear function approximation, can be expressed as a linear system Aw = b
A = X > D(I cP⇡, ) 1(I P⇡, )X
b = X > D(I cP⇡, )",4. Objectives and algorithms,[0],[0]
"1r⇡
where each row in X 2 Rn⇥d corresponds to features for a state, and D 2 Rn⇥n is a diagonal weighting matrix.",4. Objectives and algorithms,[0],[0]
"Typically, D = diag(dµ), where dµ 2 Rn is the stationary distribution for the behavior policy µ : S ⇥",4. Objectives and algorithms,[0],[0]
A !,4. Objectives and algorithms,[0],[0]
"[0, 1] generating the stream of interaction.",4. Objectives and algorithms,[0],[0]
"In on-policy learning, dµ = d⇡.",4. Objectives and algorithms,[0],[0]
"With the addition of the interest function, this weighting changes to D = diag(dµ i), where denotes element-wise product (Hadamard product).",4. Objectives and algorithms,[0],[0]
"More recently, a new algorithm, emphatic TD (ETD) (Mahmood et al., 2015; Sutton et al., 2016) specified yet another weighting, D = M where M = diag(m) with m = (I P ⇡) 1(dµ i).",4. Objectives and algorithms,[0],[0]
"Importantly, even for off-policy sampling, with this weighting, A is guaranteed to be positive definite.",4. Objectives and algorithms,[0],[0]
"We show in the next section that the generalized Bellman operator for both the on-policy and emphasis weighting is a contraction, and further in the appendix that the emphasis weighting with a transition-based trace function is also a contraction.",4. Objectives and algorithms,[0],[0]
"In this section, we provide a general approach to incorporating transition-based discounting into approximation bounds.",5. Generalized theoretical properties,[0],[0]
Most previous bounds have assumed a constant discount.,5. Generalized theoretical properties,[0],[0]
"For example, ETD was introduced with state-based s; however, (Hallak et al., 2015) analyzed approximation error bounds of ETD using a constant discount c. By using matrix norms on P⇡, , we generalize previous approximation bounds to both the episodic and continuing case.
",5. Generalized theoretical properties,[0],[0]
Define the set of bounded vectors for the general space of value functions V = {v 2 Rn : kvkDµ < 1}.,5. Generalized theoretical properties,[0],[0]
"Let Fv ⇢ V be a subspace of possible solutions, e.g., Fv = {Xw|w 2 Rd, kwk2 < 1}.
",5. Generalized theoretical properties,[0],[0]
A1.,5. Generalized theoretical properties,[0],[0]
"The action space A and state space S are finite.
A2.",5. Generalized theoretical properties,[0],[0]
"For polices µ,⇡ : S ⇥A !",5. Generalized theoretical properties,[0],[0]
"[0, 1], there exist unique invariant distributions dµ,d⇡ such that d⇡P⇡ = d⇡ and dµPµ = dµ.",5. Generalized theoretical properties,[0],[0]
"This assumption is typically satisfied by assuming an ergodic Markov chain for the policy.
A3.",5. Generalized theoretical properties,[0],[0]
"There exist transition s, a, s0 such that (s, a, s0)",5. Generalized theoretical properties,[0],[0]
"< 1 and ⇡(s, a)P (s, a, s0) >",5. Generalized theoretical properties,[0],[0]
0.,5. Generalized theoretical properties,[0],[0]
"This assumptions states that the policy reaches some part of the space where the discount is less than 1.
A4.",5. Generalized theoretical properties,[0],[0]
Assume for any v 2,5. Generalized theoretical properties,[0],[0]
"Fv, if v(s) = 0 for all s 2 S where i(s)",5. Generalized theoretical properties,[0],[0]
"> 0, then v(s) = 0",5. Generalized theoretical properties,[0],[0]
for all s 2 S s.t. i(s) = 0.,5. Generalized theoretical properties,[0],[0]
"For linear function approximation, this requires F = span{x(s) : s 2 S, i(s) 6= 0}.
",5. Generalized theoretical properties,[0],[0]
For weighted norm kvk D = p v >,5. Generalized theoretical properties,[0],[0]
"Dv, if we can take the square root of D, the induced matrix norm is kP ⇡kD = D 1/2 P
⇡D 1/2 sp , where the spectral norm k·ksp is the largest singular value of the matrix.",5. Generalized theoretical properties,[0],[0]
"For simplicity of notation below, define s
D
: = kP ⇡kD. For any diagonalizable, nonnegative matrix D, the projection ⇧
D : V !",5. Generalized theoretical properties,[0],[0]
Fv onto Fv exists and is defined ⇧Dz = argmin v2Fv kz vkD.,5. Generalized theoretical properties,[0],[0]
We first prove that the generalized Bellman operator in Equation 1 is a contraction.,5.1. Approximation bound,[0],[0]
"We extend the bound from (Tsitsiklis and Van Roy, 1997; Hallak et al., 2015) for constant discount and constant trace parameter, to the general transition-based setting.",5.1. Approximation bound,[0],[0]
The normed difference to the true value function could be defined by multiple weightings.,5.1. Approximation bound,[0],[0]
"A well-known result is that for D = D⇡ the Bellman operator is a contraction for constant c and c (Tsitsiklis and Van Roy, 1997); recently, this has been generalized for a variant of ETD to M, still with constant parameters (Hallak et al., 2015).",5.1. Approximation bound,[0],[0]
We extend this result for transition-based for both D⇡ and the transition-based emphasis matrix M. Lemma 1.,5.1. Approximation bound,[0],[0]
"For D = D⇡ or D = M,
s
D = kP ⇡kD < 1.
",5.1. Approximation bound,[0],[0]
Proof: For D = M: let ⇠ 2 Rn be the vector of row sums for P ⇡: P ⇡1 = ⇠.,5.1. Approximation bound,[0],[0]
"Then for any v 2 V , with v 6= 0,
kP ⇡vk2M = X
s2S m(s)
X
s02S P
⇡(s, s
0 )",5.1. Approximation bound,[0],[0]
"v(s 0 )
!",5.1. Approximation bound,[0],[0]
"2
=
X s2S m(s)⇠(s)2 X s02S P ⇡(s, s 0 )",5.1. Approximation bound,[0],[0]
"⇠(s) v(s 0 )
!",5.1. Approximation bound,[0],[0]
"2
 X
s2S m(s)⇠(s)2
X
s02S
P ⇡(s, s
0 )
",5.1. Approximation bound,[0],[0]
"⇠(s) v(s
0 ) 2
=
X
s02S v(s
0 )
2 X
s2S m(s)⇠(s)P ⇡(s, s
0 )
",5.1. Approximation bound,[0],[0]
"= v > diag (m ⇠)>P ⇡ v
where the first inequality follows from Jensen’s inequality, because P ⇡(s, :) is normalized.",5.1. Approximation bound,[0],[0]
"Now because ⇠ has entries that are less than 1, because the row sums of P ⇡ are less than 1 as shown in Lemma 4, and because each of the values in the above product are nonnegative,
v > diag (m ⇠)>P ⇡ v
 v> diag m > P
⇡ v
= v >",5.1. Approximation bound,[0],[0]
diag,5.1. Approximation bound,[0],[0]
m,5.1. Approximation bound,[0],[0]
>,5.1. Approximation bound,[0],[0]
(P ⇡ I),5.1. Approximation bound,[0],[0]
"+m> v
= v > diag (d⇡ i)>",5.1. Approximation bound,[0],[0]
"+m> v
= v > diag m > v v> diag
(d⇡ i)
> v
< kvk2 M
The last inequality is a strict inequality because d⇡ i has at least one positive entry where v has a positive entry.",5.1. Approximation bound,[0],[0]
"Otherwise, if v(s) = 0 everywhere with i(s)",5.1. Approximation bound,[0],[0]
"> 0, then v = 0, which we assumed was not the case.
",5.1. Approximation bound,[0],[0]
"Therefore, kP ⇡vkM < kvkM for any v 6= 0, giving kP ⇡kM := maxv2Rn,v 6=0 kP ⇡vkM kvkM < 1.",5.1. Approximation bound,[0],[0]
"This exact same proof follows through verbatim for the generalization of P ⇡ to transition-based trace .
",5.1. Approximation bound,[0],[0]
"For D = D⇡: Again, we use Jensen’s inequality, but now rely on the property d⇡P⇡ = d⇡.",5.1. Approximation bound,[0],[0]
"Because of Assumption A3, for some s < 1, for any non-negative v+,
d⇡P⇡, v+ =
X
s
X
a
d⇡(s)Pr(s, a, :) (s, a, :)v+
 s X
s
X
a
d⇡(s)Pr(s, a, :)v+ = sd⇡v.
Therefore, because vectors P⇡, v+ are also non-negative,
d⇡P ⇡v+ = d⇡
1X
k=0
(P⇡, c) k P⇡, (1 c) !",5.1. Approximation bound,[0],[0]
"v+
 (1 c) 1X
k=0
(s c) k",5.1. Approximation bound,[0],[0]
"d⇡P⇡, v+
 (1 c)(1 s c) 1sd⇡v+ and so
kP ⇡vk2D⇡  X
s2S d⇡(s)⇠(s)
2 X
s02S
P ⇡(s, s
0 )
",5.1. Approximation bound,[0],[0]
"⇠(s) v(s
0 ) 2
=
X
s02S v(s
0 )
2 X
s2S d⇡(s)⇠(s)P ⇡(s, s
0 )
 ",5.1. Approximation bound,[0],[0]
"X
s02S v(s
0 )
2 X
s2S d⇡(s)P ⇡(s, s
0 )
 ",5.1. Approximation bound,[0],[0]
"s(1 c)1 cs X
s02S d(s
0 )",5.1. Approximation bound,[0],[0]
v(s 0 ),5.1. Approximation bound,[0],[0]
"2
 s s c1 cskvk 2 D⇡
where s s c1 cs < 1 since s < 1.",5.1. Approximation bound,[0],[0]
⌅ Lemma 2.,5.1. Approximation bound,[0],[0]
"Under assumptions A1-A3, the Bellman operator T( ) in Equation (1) is a contraction under a norm weighted by D = D⇡ or D = M⇡ , i.e., for v 2 V
kT( )vk D < kvk D .
",5.1. Approximation bound,[0],[0]
"Further, because the projection ⇧ D is a contraction, ⇧
D
T ( ) is also a contraction and has a unique fixed point ⇧
D
T ( ) v = v for v 2 Fv .
",5.1. Approximation bound,[0],[0]
"Proof: Because any vector v can be written v = v1 v2,
kT( )vk D = kT( )(v1 v2)kD = kP ⇡(v1 v2)kD  kP ⇡kDkvkD < kvk
D
where the last inequality follows from Lemma 1.",5.1. Approximation bound,[0],[0]
"By the Banach Fixed Point theorem, because the Bellman operator is a contraction under D, it has a unique fixed point.",5.1. Approximation bound,[0],[0]
⌅ Theorem 1.,5.1. Approximation bound,[0],[0]
"If D satisfies s
D < 1, then there exists v 2",5.1. Approximation bound,[0],[0]
"Fv such that ⇧
D
T ( ) v = v, and the error to the true value
function is bounded as
kv v⇤k D  (1 s D ) 1k⇧",5.1. Approximation bound,[0],[0]
D v ⇤ v⇤k D .,5.1. Approximation bound,[0],[0]
"(4)
",5.1. Approximation bound,[0],[0]
For constant discount c 2,5.1. Approximation bound,[0],[0]
"[0, 1) and constant trace parameter c 2 [0, 1], this bound reduces to the original bound (Tsitsiklis and Van Roy, 1997, Lemma 6):
(1 s D ) 1  1 c c 1 c .
",5.1. Approximation bound,[0],[0]
"Proof: Let v be the unique fixed point of ⇧ D T ( ), which exists by Lemma 2.
",5.1. Approximation bound,[0],[0]
kv v⇤k D  kv ⇧ D v ⇤k D + k⇧ D,5.1. Approximation bound,[0],[0]
"v ⇤ v⇤k D
= k⇧T( )v ⇧",5.1. Approximation bound,[0],[0]
D v ⇤k D + k⇧ D v ⇤ v,5.1. Approximation bound,[0],[0]
"⇤k D
 kT( )v v⇤k D + k⇧ D",5.1. Approximation bound,[0],[0]
"v ⇤ v⇤k D
= kT( )(v v⇤)k D + k⇧ D v ⇤ v⇤k D",5.1. Approximation bound,[0],[0]
= kP ⇡(v v⇤)kD +,5.1. Approximation bound,[0],[0]
k⇧Dv⇤ v⇤kD = kP ⇡kDkv v⇤kD + k⇧,5.1. Approximation bound,[0],[0]
"Dv⇤ v⇤kD = s
D kv v⇤k D + k⇧ D v ⇤ v⇤k D
where the second inequality is due to k⇧T( )vk D  kT",5.1. Approximation bound,[0],[0]
"( )vk
D , the second equality due to T( )",5.1. Approximation bound,[0],[0]
v⇤ = v⇤ and the third equality due to T( )v T( )v⇤ = P ⇡(v v⇤) because the r⇡ cancels.,5.1. Approximation bound,[0],[0]
"By rearranging terms, we get
(1 s D )kv v⇤k D⇡  k⇧v⇤ v⇤kD⇡
and since s D < 1, we get the final result.
",5.1. Approximation bound,[0],[0]
"For constant c < 1 and c, because P⇡, = P⇡
s
D = kP ⇡kD
= kD1/2 1X
i=0
i c",5.1. Approximation bound,[0],[0]
i cP,5.1. Approximation bound,[0],[0]
i ⇡ !,5.1. Approximation bound,[0],[0]
"c(1 c)P⇡D1/2k2
 c(1 c) 1X
i=0
",5.1. Approximation bound,[0],[0]
"i c i ckD1/2Pi+1⇡ D1/2k2
= c(1 c) 1X
i=0
i c",5.1. Approximation bound,[0],[0]
"i ckPi+1⇡ kD
 c(1 c) 1X
i=0
i c",5.1. Approximation bound,[0],[0]
"i c
= c(1 c) 1 c c ⌅
We provide generalizations to transition-based trace parameters in the appendix, for the emphasis weighting, and also discuss issues with generalizing to state-based termination for a standard weighting with d⇡.",5.1. Approximation bound,[0],[0]
We show that for any transition-based discounting function : S⇥A⇥S !,5.1. Approximation bound,[0],[0]
"[0, 1], the above contraction results hold under emphasis weighting.",5.1. Approximation bound,[0],[0]
"We then provide a general form for an upper bound on kP ⇡kD⇡ for transition-based discounting, based on the contraction properties of two matrices within P ⇡.",5.1. Approximation bound,[0],[0]
"We further provide an example where the Bellman operator is not a contraction even under the simpler generalization to state-based discounting, and discuss the requirements for the transition-based generalizations to ensure a contraction with weighting d⇡.",5.1. Approximation bound,[0],[0]
This further motivates the emphasis weighting as a more flexible scheme for convergence under general setting—both off-policy and transition-based generalization.,5.1. Approximation bound,[0],[0]
"Using this characterization of P ⇡, we can re-examine previous results for temporal difference algorithms that either used state-based or constant discounts.
",5.2. Properties of TD algorithms,[0],[0]
Convergence of Emphatic TD for RL tasks.,5.2. Properties of TD algorithms,[0],[0]
"We can extend previous convergence results for ETD, for learning value functions and action-value functions, for the RL task formalism.",5.2. Properties of TD algorithms,[0],[0]
"For policy evaluation, ETD and ELSTD, the least-squares version of ETD that uses the above defined A and b with D = M, have both been shown to converge with probability one (Yu, 2015).",5.2. Properties of TD algorithms,[0],[0]
"As an important component of this proof is convergence in expectation, which relies on A being positive definite.",5.2. Properties of TD algorithms,[0],[0]
"In particular, for appropriate step-sizes ↵t (see (Yu, 2015)), if A is positive definite, the iterative update is convergent wt+1",5.2. Properties of TD algorithms,[0],[0]
= wt + ↵t(b Awt).,5.2. Properties of TD algorithms,[0],[0]
"For the generalization to transition-based discounting, convergence in expectation extends for the emphatic algorithms.",5.2. Properties of TD algorithms,[0],[0]
"We provide these details in the appendix for completeness, with theorem statement and proof in Appendix F and pseudocode in Appendix D.
Convergence rate of LSTD( ).",5.2. Properties of TD algorithms,[0],[0]
"Tagorti and Scherrer (2015) recently provided convergence rates for LSTD( ) for continuing tasks, for some c < 1.",5.2. Properties of TD algorithms,[0],[0]
These results can be extended to the episodic setting with the generic treatment of P ⇡ .,5.2. Properties of TD algorithms,[0],[0]
"For example, in (Tagorti and Scherrer, 2015, Lemma 1), which describes the sensitivity of LSTD, the proof extends by replacing the matrix (1 c) cP⇡(I c cP⇡) 1 (which they call M in their proof) with the generalization P
⇡, resulting instead in the constant 1 1 sD in the bound rather than 1 c c1 c .",5.2. Properties of TD algorithms,[0],[0]
"Further, this generalizes convergence rate results to emphatic LSTD, since M satisfies the required convergence properties, with rates dictated by s
M
rather than sDµ for standard LSTD.
",5.2. Properties of TD algorithms,[0],[0]
Insights into s D .,5.2. Properties of TD algorithms,[0],[0]
"Though the generalized form enables unified episodic and continuing results, the resulting bound parameter s
D is more difficult to interpret than for constant c, c.",5.2. Properties of TD algorithms,[0],[0]
"With c increasing to one, the constant 1 c c1 c in the upper bound decreased to one.",5.2. Properties of TD algorithms,[0],[0]
"For c decreasing to zero, the bound also decreases to one.",5.2. Properties of TD algorithms,[0],[0]
"These trends are intuitive, as the problem should be simpler when c is small, and bias should be less when c is close to one.",5.2. Properties of TD algorithms,[0],[0]
"More generally, however, the discount can be small or large for different transitions, making it more difficult to intuit the trend.
",5.2. Properties of TD algorithms,[0],[0]
"To gain some intuition for s D , consider a random policy in the taxi domain, with s
D summarized in Table 1.",5.2. Properties of TD algorithms,[0],[0]
"As c goes to one, s
D goes to zero and so (1 s D ) 1 goes to one.",5.2. Properties of TD algorithms,[0],[0]
"Some outcomes of note are that 1) hard or soft termination for the pickup results in the exact same s
D ; 2) for a constant gamma of c = 0.99, the episodic discount had a slightly smaller s
D ; and 3) increasing c has a much stronger effect than including more terminations.",5.2. Properties of TD algorithms,[0],[0]
"Whereas, when we added random terminations, so that from 1% and 10% of the states, termination occurred on at least one path within 5 steps or even more aggressively on every path within 5 steps, the values of s
D
were similar.",5.2. Properties of TD algorithms,[0],[0]
The goal of this paper is to provide intuition and examples of how to use the RL task formalism.,6. Discussion and conclusion,[0],[0]
"Consequently, to avoid jarring the explanation, technical contributions were not emphasized, and in some cases included only in the appendix.",6. Discussion and conclusion,[0],[0]
"For this reason, we would like to highlight and summarize the technical contributions, which include 1) the introduction of the RL task formalism, and of transition-based discounts; 2) an explicit characterization of the relationship between state-based and transition-based discounting; and 3) generalized approximation bounds, applying to both episodic and continuing tasks; and 4) insights into—and issues with—extending contraction results for both statebased and transition-based discounting.",6. Discussion and conclusion,[0],[0]
"Through intuition from simple examples and fundamental theoretical extensions, this work provides a relatively complete characterization of the RL task formalism, as a foundation for use in practice and theory.",6. Discussion and conclusion,[0],[0]
"Thanks to Hado van Hasselt for helpful discussions about transition-based discounting, and probabilistic discounts.",Acknowledgements,[0],[0]
Reinforcement learning tasks are typically specified as Markov decision processes.,abstractText,[0],[0]
"This formalism has been highly successful, though specifications often couple the dynamics of the environment and the learning objective.",abstractText,[0],[0]
"This lack of modularity can complicate generalization of the task specification, as well as obfuscate connections between different task settings, such as episodic and continuing.",abstractText,[0],[0]
"In this work, we introduce the RL task formalism, that provides a unification through simple constructs including a generalization to transition-based discounting.",abstractText,[0],[0]
"Through a series of examples, we demonstrate the generality and utility of this formalism.",abstractText,[0],[0]
"Finally, we extend standard learning constructs, including Bellman operators, and extend some seminal theoretical results, including approximation errors bounds.",abstractText,[0],[0]
"Overall, we provide a well-understood and sound formalism on which to build theoretical results and simplify algorithm use and development.",abstractText,[0],[0]
Unifying Task Specification in Reinforcement Learning,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1260–1272 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1116",text,[0],[0]
Social media sites have become a popular source of information to analyze current opinions of numerous people.,1 Introduction,[0],[0]
Many researchers have worked to realize various automated analytical methods for social media because manual analysis of such vast amounts of data is difficult.,1 Introduction,[0],[0]
Geolocation prediction is one such analytical method that has been studied widely to predict a user location or a document location.,1 Introduction,[0],[0]
"Location information is crucially important information for analyses such as disaster analysis (Sakaki et al., 2010), disease analysis (Culotta, 2010), and political analysis (Tumasjan et al., 2010).",1 Introduction,[0],[0]
"Such information is also useful for analyses such as sentiment analysis (Martı́nez-Cámara et al., 2014) and user attribute analysis (Rao et al., 2010) to undertake detailed region-specific analyses.
",1 Introduction,[0],[0]
"Geolocation prediction has been performed for Wikipedia (Overell, 2009), Flickr (Serdyukov et al., 2009; Crandall et al., 2009), Facebook (Backstrom et al., 2010), and Twitter (Cheng et al., 2010; Eisenstein et al., 2010).
",1 Introduction,[0],[0]
"Among these sources, Twitter is often preferred because of its characteristics, which are suited for geolocation prediction.",1 Introduction,[0],[0]
"First, some tweets include geotags, which are useful as ground truth locations.",1 Introduction,[0],[0]
"Secondly, tweets include metadata such as timezones and self-declared locations that can facilitate geolocation prediction.",1 Introduction,[0],[0]
"Thirdly, a user network is obtainable by consideration of the interaction between two users as a network link.
",1 Introduction,[0],[0]
"Herein, we propose a neural network model to tackle geolocation prediction in Twitter.",1 Introduction,[0],[0]
"Past studies have combined text, metadata, and user network information with ensemble approaches (Han et al., 2013, 2014; Rahimi et al., 2015a; Jayasinghe et al., 2016) to achieve state-of-the-art performance.",1 Introduction,[0],[0]
"Our model combines text, metadata, and user network information using a complex neural network.",1 Introduction,[0],[0]
"Neural networks have recently shown effectiveness to capture complex representations combining simpler representations from large-scale datasets (Goodfellow et al., 2016).",1 Introduction,[0],[0]
"We intend to obtain unified text, metadata, and user network representations with an attention mechanism (Bahdanau et al., 2014) that is superior to the earlier ensemble approaches.",1 Introduction,[0],[0]
"The contributions of this paper are the following:
1.",1 Introduction,[0],[0]
"We propose a neural network model that learns unified text, metadata, and user network representations with an attention mechanism.
2.",1 Introduction,[0],[0]
"We show that the proposed model outperforms the previous ensemble approaches in two open datasets.
3.",1 Introduction,[0],[0]
"We analyze some components of the proposed model to gain insight into the unification processes of the model.
",1 Introduction,[0],[0]
Our model specifically emphasizes geolocation prediction in Twitter to use benefits derived from the characteristics described above.,1 Introduction,[0],[0]
"However, our
1260
model can be readily extended to other social media analyses such as user attribute analysis and political analysis, which can benefit from metadata and user network information.
",1 Introduction,[0],[0]
"In subsequent sections of this paper, we explain the related works in four perspectives in Section 2.",1 Introduction,[0],[0]
The proposed neural network model is described in Section 3 along with two open datasets that we used for evaluations in Section 4.,1 Introduction,[0],[0]
Details of an evaluation are reported in Section 5 with discussions in Section 6.,1 Introduction,[0],[0]
"Finally, Section 7 concludes the paper with some future directions.",1 Introduction,[0],[0]
Probability distributions of words over locations have been used to estimate the geolocations of users.,2.1 Text-based Approach,[0],[0]
"Maximum likelihood estimation approaches (Cheng et al., 2010, 2013) and language modeling approaches minimizing KL-divergence (Wing and Baldridge, 2011; Kinsella et al., 2011; Roller et al., 2012) have succeeded in predicting user locations using word distributions.",2.1 Text-based Approach,[0],[0]
"Topic modeling approaches to extract latent topics with geographical regions (Eisenstein et al., 2010, 2011; Hong et al., 2012; Ahmed et al., 2013) have also been explored considering word distributions.
",2.1 Text-based Approach,[0],[0]
Supervised machine learning methods with word features are also popular in text-based geolocation prediction.,2.1 Text-based Approach,[0],[0]
"Multinomial Naive Bayes (Han et al., 2012, 2014; Wing and Baldridge, 2011), logistic regression (Wing and Baldridge, 2014; Han et al., 2014), hierarchical logistic regression (Wing and Baldridge, 2014), and a multilayer neural network with stacked denoising autoencoder (Liu and Inkpen, 2015) have realized geolocation prediction from text.",2.1 Text-based Approach,[0],[0]
A semi-supervised machine learning approach by Cha et al. (2015) has also been produced using a sparse-coding and dictionary learning.,2.1 Text-based Approach,[0],[0]
Social media often include interactions of several kinds among users.,2.2 User-network-based Approach,[0],[0]
These interactions can be regarded as links that form a network among users.,2.2 User-network-based Approach,[0],[0]
Several studies have used such user network information to predict geolocation.,2.2 User-network-based Approach,[0],[0]
Backstrom et al. (2010) introduced a probabilistic model to predict the location of a user using friendship information in Facebook.,2.2 User-network-based Approach,[0],[0]
"Friend and follower information in Twitter were used to predict user locations with a most frequent friend algorithm
(Davis Jr. et al., 2011), a unified descriptive model (Li et al., 2012b), location-based generative models (Li et al., 2012a), dynamic Bayesian networks (Sadilek et al., 2012), a support vector machine (Rout et al., 2013), and maximum likelihood estimation (McGee et al., 2013).",2.2 User-network-based Approach,[0],[0]
"Mention information in Twitter is also used with label propagation models (Jurgens, 2013; Compton et al., 2014) and an energy and social local coefficient model (Kong et al., 2014).",2.2 User-network-based Approach,[0],[0]
"Jurgens et al. (2015) compared nine user-network-based approaches targeting Twitter, controlling data conditions.",2.2 User-network-based Approach,[0],[0]
Metadata such as location fields are useful as effective clues to predict geolocation.,2.3 Metadata-based Approach,[0],[0]
Hecht et al. (2011) reported that decent accuracy of geolocation prediction can be achieved using location fields.,2.3 Metadata-based Approach,[0],[0]
Approaches to combine metadata with texts are also proposed to extend text-based approaches.,2.3 Metadata-based Approach,[0],[0]
"Combinatory approaches such as a dynamically weighted ensemble method (Mahmud et al., 2012), polygon stacking (Schulz et al., 2013), stacking (Han et al., 2013, 2014), and average pooling with a neural network (Miura et al., 2016) have strengthened geolocation prediction.",2.3 Metadata-based Approach,[0],[0]
Several attempts have been made to combine usernetwork-based approaches with other approaches.,2.4 Combinatory Approach Extending User-network-based Approach,[0],[0]
"A text-based approach with logistic regression was combined with label propagation approaches to enhance geolocation prediction (Rahimi et al., 2015a,b, 2016).",2.4 Combinatory Approach Extending User-network-based Approach,[0],[0]
"Jayasinghe et al. (2016) combined nine components including text-based approaches, metadata-based approaches, and a usernetwork-based approach with a cascade ensemble method.",2.4 Combinatory Approach Extending User-network-based Approach,[0],[0]
"A model we propose in Section 3 which combines text, metadata, and user network information with a neural network, can be regarded as an alternative to approaches using text and metadata (Mahmud et al., 2012; Schulz et al., 2013; Han et al., 2013, 2014; Miura et al., 2016), approaches with text and user network information (Rahimi et al., 2015a,b), and an approach with text, metadata, and user network information (Jayasinghe et al., 2016).",2.5 Comparisons with Proposed Model,[0],[0]
"In Section 5, we demonstrate that our model outperforms earlier models.
",2.5 Comparisons with Proposed Model,[0],[0]
"In terms of machine learning methods, our model is a neural network model that shares some similarity with previous neural network models (Liu and Inkpen, 2015; Miura et al., 2016).",2.5 Comparisons with Proposed Model,[0],[0]
Our model and these previous models have two key differences.,2.5 Comparisons with Proposed Model,[0],[0]
"First, our model integrates user network information along with other information.",2.5 Comparisons with Proposed Model,[0],[0]
"Secondly, our model combines text and metadata with an attention mechanism (Bahdanau et al., 2014).",2.5 Comparisons with Proposed Model,[0],[0]
Figure 1 presents an overview of our model: a complex neural network for classification with a city as a label.,3.1 Proposed Model,[0],[0]
"For each user, the model accepts inputs of messages, a location field, a description field, a timezone, linked users, and the cities of linked users.
",3.1 Proposed Model,[0],[0]
User network information is incorporated by city embeddings and user embeddings of linked users.,3.1 Proposed Model,[0],[0]
User embeddings are introduced along with city embeddings because linked users with city information1 are limited.,3.1 Proposed Model,[0],[0]
We chose to let the model learn geolocation representations of linked users directly via user embeddings.,3.1 Proposed Model,[0],[0]
"The model can be
1City information are provided by a dataset.",3.1 Proposed Model,[0],[0]
"The detail of the city information is explained in Section 4.
broken down to several components, details of which are described in Section 3.1.1–3.1.4.",3.1 Proposed Model,[0],[0]
"We describe the text component of the model, which is the “TEXT” section in Figure 1.",3.1.1 Text Component,[0],[0]
Figure 2 presents an overview of the text component.,3.1.1 Text Component,[0],[0]
"The component consists of a recurrent neural network (RNN) (Graves, 2012) layer and attention layers.",3.1.1 Text Component,[0],[0]
"An input of the component is a timeline of a user, which consists of messages in a time sequence.
",3.1.1 Text Component,[0],[0]
"As an implementation of RNN, we used Gated Recurrent Unit (GRU) (Cho et al., 2014) with a bidirectional setting.",3.1.1 Text Component,[0],[0]
"In the RNN layer, word embeddings x of a message are processed with the following transition functions:
zt = σ",3.1.1 Text Component,[0],[0]
"(W zxt + U zht−1 + bz) (1)
rt = σ",3.1.1 Text Component,[0],[0]
(W rxt +,3.1.1 Text Component,[0],[0]
"U rht−1 + br) (2)
h̃t = tanh",3.1.1 Text Component,[0],[0]
(W hxt,3.1.1 Text Component,[0],[0]
"+ Uh (rt ⊙ ht−1) + bh) (3)
",3.1.1 Text Component,[0],[0]
ht = (1− zt)⊙ ht−1,3.1.1 Text Component,[0],[0]
"+ zt ⊙ h̃t (4)
where zt is an update gate, rt is a reset gate, h̃t is a candidate state, ht is a state, W z,W r,W h,",3.1.1 Text Component,[0],[0]
"U z, U r, Uh are weight matrices, bz, br, bh are bias vectors, σ is a logistic sigmoid function, and ⊙ is an element-wise multiplication operator.",3.1.1 Text Component,[0],[0]
"The bi-directional GRU outputs −→ h
and ←− h are concatenated to form g where gt =−→
ht∥ ←− ht",3.1.1 Text Component,[0],[0]
and are passed to the first attention layer AttentionM. AttentionM,3.1.1 Text Component,[0],[0]
"computes a message representation m as a weighted sum of gt with weight αt:
m = ∑
t
αtgt (5)
αt = exp
( vTαut ) ∑
t exp (v T αut)
(6)
ut = tanh (W αgt + bα) (7)
where vα is a weight vector, W α is a weight matrix, and bα a bias vector.",3.1.1 Text Component,[0],[0]
ut is an attention context vector calculated from gt with a single fullyconnected layer (Eq. 7).,3.1.1 Text Component,[0],[0]
ut is normalized with softmax to obtain αt as a probability (Eq. 6).,3.1.1 Text Component,[0],[0]
The message representation m is passed to the second attention layer AttentionTL to obtain a timeline representation from message representations.,3.1.1 Text Component,[0],[0]
"We describe text and metadata components of the model, which is the “TEXT&META” section in Figure 1.",3.1.2 Text and Metadata Component,[0],[0]
"This component considers the following three types of metadata along with text: location a text field in which a user is allowed to write the user location freely, description a text field a user can use for self-description, and timezone a selective field from which a user can choose a timezone.",3.1.2 Text and Metadata Component,[0],[0]
"Note that certain percentages of these fields are not available2, and unknown tokens are used for inputs in such cases.
",3.1.2 Text and Metadata Component,[0],[0]
"2Han et al. (2014) reported missing percentages of 19% for location, 24% for description, and 25%for timezone.
",3.1.2 Text and Metadata Component,[0],[0]
We process location fields and description fields similarly to messages using an RNN layer and an attention layer.,3.1.2 Text and Metadata Component,[0],[0]
"Because there is only one location and one description per user, a second attention layer is not required, as it is in the text component.",3.1.2 Text and Metadata Component,[0],[0]
"We also chose to share word embeddings among the messages, the location, and the description processes because these inputs are all textual information.",3.1.2 Text and Metadata Component,[0],[0]
"For the timezone, an embedding is assigned for each timezone value.",3.1.2 Text and Metadata Component,[0],[0]
"A processed timeline representation, a location representation, and a description representation are then passed to the attention layer AttentionU with a timezone representation.",3.1.2 Text and Metadata Component,[0],[0]
AttentionU combines these four representations and outputs a user representation.,3.1.2 Text and Metadata Component,[0],[0]
This combination is done as in AttentionTL with four representations as g1 . . .,3.1.2 Text and Metadata Component,[0],[0]
g4 in Eq. 5.,3.1.2 Text and Metadata Component,[0],[0]
"We describe the user network component of the model, which is the “USERNET” section in Figure 1.",3.1.3 User Network Component,[0],[0]
Figure 3 presents an overview of the user network component.,3.1.3 User Network Component,[0],[0]
The model has two inputs linked cities and linked users.,3.1.3 User Network Component,[0],[0]
Users connected with a user network are extracted as linked users.,3.1.3 User Network Component,[0],[0]
We treat their cities3 as linked cities.,3.1.3 User Network Component,[0],[0]
Linked cities and linked users are assigned with city embeddings c and user embeddings a respectively.,3.1.3 User Network Component,[0],[0]
"c and a are then processed to output p = c ⊕ a, where ⊕ is an element-wise addition operator.",3.1.3 User Network Component,[0],[0]
"p is then passed to the subsequent attention layer AttentionN to obtain a user network representa-
3A user with city information implies that the user is included in a training set.
tion as in AttentionU.",3.1.3 User Network Component,[0],[0]
An output of the text and metadata component and an output of the mention network component are further passed to the final attention layer AttentionUN to obtain a merged user representation as in AttentionU. The merged user representation is then connected to labels with a fully connected layer FCUN.,3.1.4 Model Output,[0],[0]
SUB-NN-TEXT We prepare a sub-model SUBNN-TEXT by adding FCU and FCUN to the text component.,3.2 Sub-models of the Proposed Model,[0],[0]
"This sub-model can be considered as a variant of a neural network model by Yang et al. (2016), which learns a representation of hierarchical text.
",3.2 Sub-models of the Proposed Model,[0],[0]
"SUB-NN-UNET We prepare a sub-model SUBNN-UNET by connecting the text component and the user network component with FCU, AttentionUN, and FCUN.",3.2 Sub-models of the Proposed Model,[0],[0]
"This model can be regarded as a model that uses text and user network information.
",3.2 Sub-models of the Proposed Model,[0],[0]
SUB-NN-META We prepare a sub-model SUBNN-META by adding FCU and FCUN to the metadata component.,3.2 Sub-models of the Proposed Model,[0],[0]
This model is a text-metabased model that uses text and metadata.,3.2 Sub-models of the Proposed Model,[0],[0]
"TwitterUS The first dataset we used is TwitterUS assembled by Roller et al. (2012), which consists of 429K training users, 10K development users, and 10K test users in a North American region.",4.1 Dataset Specifications,[0],[0]
The ground truth location of a user is set to the first geotag of the user in the dataset.,4.1 Dataset Specifications,[0],[0]
"We
collected TwitterUS tweets using TwitterAPI to reconstruct TwitterUS to obtain metadata along with text.",4.1 Dataset Specifications,[0],[0]
Up to date versions in November–December 2016 were used for the metadata4.,4.1 Dataset Specifications,[0],[0]
We additionally assigned city centers to ground truth geotags using the city category of Han et al. (2012) to make city prediction possible in this dataset.,4.1 Dataset Specifications,[0],[0]
"TwitterUS (train) in Table 1 presents some properties related to the TwitterUS training set.
",4.1 Dataset Specifications,[0],[0]
"W-NUT The second dataset we used is W-NUT, a user-level dataset of the geolocation prediction shared task of W-NUT 2016 (Han et al., 2016).",4.1 Dataset Specifications,[0],[0]
"The dataset consists of 1M training users, 10K development users, and 10K test users.",4.1 Dataset Specifications,[0],[0]
The ground truth location of a user is decided by majority voting of the closest city center.,4.1 Dataset Specifications,[0],[0]
"Like in TwitterUS, we obtained metadata and texts using TwitterAPI.",4.1 Dataset Specifications,[0],[0]
Up to date versions in August–September 2016 were used for the metadata.,4.1 Dataset Specifications,[0],[0]
W-NUT (train) in Table 1 presents some properties related to the WNUT training set.,4.1 Dataset Specifications,[0],[0]
"We construct mention networks (Jurgens, 2013; Compton et al., 2014; Rahimi et al., 2015a,b) from datasets as user networks.",4.2 Construction of the User Network,[0],[0]
"To do so, we follow the approach of Rahimi et al. (2015a) and Rahimi et al. (2015b) who use uni-directional mention to set edges of a mention network.",4.2 Construction of the User Network,[0],[0]
An edge is set between the two users nodes if a user mentions another user.,4.2 Construction of the User Network,[0],[0]
"The number of unidirectional mention edges for TwitterUS and WNUT can be found in Table 1.
",4.2 Construction of the User Network,[0],[0]
"The uni-directional setting results to large numbers of edges, which often are computationally expensive to process.",4.2 Construction of the User Network,[0],[0]
We restricted edges to satisfy one of the following conditions to reduce the size: (1) both users have ground truth locations or (2) one user has a ground truth location and another user is mentioned 5 times or more in a training set.,4.2 Construction of the User Network,[0],[0]
The number of reduced-edges with these conditions in TwitterUS and W-NUT can be confirmed in Table 1.,4.2 Construction of the User Network,[0],[0]
"LR is an l1-regularized logistic regression model with k-d tree regions (Roller et al., 2012) used
4TwitterAPI returns the current version of metadata even for an old tweet.
in Rahimi et al. (2015a).",5.1.1 LR,[0],[0]
The model uses tfidf weighted bag-of-words unigrams for features.,5.1.1 LR,[0],[0]
"This model is simple, but it has shown state-ofthe-art performance in cases when only text is available.",5.1.1 LR,[0],[0]
"MADCEL-B-LR, a model presented by (Rahimi et al., 2015a), combines LR with Modified Adsorption (MAD) (Talukdar and Crammer, 2009).",5.1.2 MADCEL-B-LR,[0],[0]
"MAD is a graph-based label propagation algorithm that optimizes an objective with a prior term, a smoothness term, and an uninformativeness term.",5.1.2 MADCEL-B-LR,[0],[0]
"LR is combined with MAD by introducing LR results as dongle nodes to MAD.
",5.1.2 MADCEL-B-LR,[0],[0]
This model includes an algorithm for the construction of a mention network.,5.1.2 MADCEL-B-LR,[0],[0]
The algorithm removes celebrity users5 and collapses a mention network6.,5.1.2 MADCEL-B-LR,[0],[0]
We use binary edges for user network edges because they performed slightly better than weighted edges by accuracy@161 metric in Rahimi et al. (2015a).,5.1.2 MADCEL-B-LR,[0],[0]
"LR-STACK is an ensemble learning model that combines four LR classifiers (LR-MSG, LR-LOC, LR-DESC, LR-TZ) with an l2-regularized logistic regression meta-classifier (LR-2ND).",5.1.3 LR-STACK,[0],[0]
"LR-MSG, LR-LOC, LR-DESC, and LR-TZ respectively use messages, location fields, description fields, and timezones as their inputs.",5.1.3 LR-STACK,[0],[0]
"This model is similar to the stacking (Wolpert, 1992) approach taken in Han et al. (2013) and Han et al. (2014), which showed superior performance compared to a feature concatenation approach.
",5.1.3 LR-STACK,[0],[0]
"The model takes the following three steps to combine text and metadata: Step 1 LR-MSG, LRLOC, LR-DESC, and LR-TZ are trained using a training set, Step 2 the outputs of the four classifiers on the training set are obtained with 10-fold cross validation, and Step 3 LR-2ND is trained using the outputs of the four classifiers.",5.1.3 LR-STACK,[0],[0]
MADCEL-B-LR-STACK is a combined model of MADCEL-B-LR and LR-STACK.,5.1.4 MADCEL-B-LR-STACK,[0],[0]
"LR-STACK results are introduced as dongle nodes to MAD instead of LR results to combine text, metadata, and network information.
",5.1.4 MADCEL-B-LR-STACK,[0],[0]
5Users with more than t unique mentions.,5.1.4 MADCEL-B-LR-STACK,[0],[0]
6Users not included in training users or test users are removed and disconnected edges with the removals are converted to direct edges.,5.1.4 MADCEL-B-LR-STACK,[0],[0]
"We applied a lower case conversion, a unicode normalization, a Twitter user name normalization, and a URL normalization for text pre-processing.",5.2.1 Text Processor,[0],[0]
"The pre-processed text is then segmented using Twokenizer (Owoputi et al., 2013) to obtain words.",5.2.1 Text Processor,[0],[0]
"We pre-trained word embeddings using messages, location fields, and description fields of a training set using fastText (Bojanowski et al., 2016) with the skip-gram algorithm.",5.2.2 Pre-training of Embeddings,[0],[0]
"We also pre-trained user embeddings using the non-reduced mention network described in Section 4.2 of a training set with LINE (Tang et al., 2015).",5.2.2 Pre-training of Embeddings,[0],[0]
The detail of pre-training parameters are described in Appendix A.1.,5.2.2 Pre-training of Embeddings,[0],[0]
We chose an objective function of our models to cross-entropy loss.,5.2.3 Neural Network Optimization,[0],[0]
"l2 regularization was applied to the RNN layers, the attention context vectors, and the FC layers of our models to avoid overfitting.",5.2.3 Neural Network Optimization,[0],[0]
"The objective function was minimized through stochastic gradient descent over shuffled mini-batches with Adam (Kingma and Ba, 2014).",5.2.3 Neural Network Optimization,[0],[0]
The layers and the embeddings in our models have unit size and embedding dimension parameters.,5.2.4 Model Parameters,[0],[0]
"Our models and the baseline models have regularization parameter α, which is sensitive to a dataset.",5.2.4 Model Parameters,[0],[0]
"The baseline models have additional k-d tree bucket size c, celebrity threshold t, and MAD parameters µ1, µ2, and µ3, which are also data sensitive.
",5.2.4 Model Parameters,[0],[0]
We chose optimal values for these parameters in terms of accuracy with a grid search using the development sets of TwitterUS and W-NUT.,5.2.4 Model Parameters,[0],[0]
Details of the parameter selection strategies and the selected values are described in Appendix A.2.,5.2.4 Model Parameters,[0],[0]
"We evaluate the models in the following four commonly used metrics in geolocation prediction: accuracy the percentage of correctly predicted cities, accuracy@161 a relaxed accuracy that takes prediction errors within 161 km as correct predictions, median error distance median value of error distances in predictions, and mean error distance mean value of error distances in predictions.",5.2.5 Metrics,[0],[0]
Table 2 presents results of our models and the implemented baseline models on TwitterUS.,5.3 Result Performance on TwitterUS,[0],[0]
"We also list values from earlier reports (Han et al., 2012; Wing and Baldridge, 2014; Rahimi et al., 2015a,b, 2016) to make our results readily comparable with past reported values.
",5.3 Result Performance on TwitterUS,[0],[0]
We performed some statistical significance tests among model pairs that share the same inputs.,5.3 Result Performance on TwitterUS,[0],[0]
The values in the Sign.,5.3 Result Performance on TwitterUS,[0],[0]
Test ID column of Table 2 represent the IDs of these pairs.,5.3 Result Performance on TwitterUS,[0],[0]
"As a preparation of statistical significance tests, accuracies, accuracy@161s, and error distances of each test user were calculated for each model pair.",5.3 Result Performance on TwitterUS,[0],[0]
Twosided Fisher-Pittman Permutation tests were used for testing accuracy and accuracy@161.,5.3 Result Performance on TwitterUS,[0],[0]
Mood’s median test was used for testing error distance in terms of median.,5.3 Result Performance on TwitterUS,[0],[0]
"Paired t-tests were used for testing error distance in terms of mean.
",5.3 Result Performance on TwitterUS,[0],[0]
"We confirmed the significance of improvements
in accuracy@161 and mean distance error for all of our models.",5.3 Result Performance on TwitterUS,[0],[0]
Three of our models also improved in terms of accuracy.,5.3 Result Performance on TwitterUS,[0],[0]
"Especially, the proposed model achieved a 2.8% increase in accuracy and a 2.4% increase in accuracy@161 against the counterpart baseline model MADCEL-B-LRSTACK.",5.3 Result Performance on TwitterUS,[0],[0]
One negative result we found was the median error distance between SUB-NN-META and LR-STACK.,5.3 Result Performance on TwitterUS,[0],[0]
"The baseline model LR-STACK performed 4.5 km significantly better than our model.
",5.3 Result Performance on TwitterUS,[0],[0]
Performance on W-NUT Table 3 presents the results of our models and the implemented baseline models on W-NUT.,5.3 Result Performance on TwitterUS,[0],[0]
"As for TwitterUS, we listed values from Miura et al. (2016) and Jayasinghe et al. (2016).",5.3 Result Performance on TwitterUS,[0],[0]
"We tested the significance of these results in the same way as we did for TwitterUS.
",5.3 Result Performance on TwitterUS,[0],[0]
We confirmed significant improvement in the four metrics for all of our models.,5.3 Result Performance on TwitterUS,[0],[0]
"The proposed model achieved a 4.8% increase in accuracy and a
6.6% increase in accuracy@161 against the counterpart baseline model MADCEL-B-LR-STACK.",5.3 Result Performance on TwitterUS,[0],[0]
"The accuracy is 3.8% higher against the previously reported best value (Jayasinghe et al., 2016) which combined texts, metadata, and user network information with an ensemble method.",5.3 Result Performance on TwitterUS,[0],[0]
"In the evaluation, the proposed model has implicitly shown effectiveness at unifying text, metadata, and user network representations through improvements in the four metrics.",6.1.1 Unification Strategies,[0],[0]
"However, details of the unification processes are not clear from the model outputs because they are merely the probabilities of estimated locations.",6.1.1 Unification Strategies,[0],[0]
"To gain insight into the unification processes, we analyzed the states of two attention layers: AttentionU and AttentionUN in Figure 1.
",6.1.1 Unification Strategies,[0],[0]
"Figure 4 presents the estimated probability density functions (PDFs) of the four input representations for AttentionU. These PDFs are estimated with kernel density estimation from the development sets of TwitterUS and W-NUT, where all four representations are available.",6.1.1 Unification Strategies,[0],[0]
"From the PDFs, it is apparent that the model assigns higher probabilities to time line representations than to other three representations in TwitterUS compared to W-NUT.",6.1.1 Unification Strategies,[0],[0]
"This finding is reasonable because timelines in TwitterUS consist of more tweets (tweet/user in Table 1) and are likely to be more informative than in W-NUT.
",6.1.1 Unification Strategies,[0],[0]
Figure 5 presents the estimated PDFs of user network representations for AttentionUN.,6.1.1 Unification Strategies,[0],[0]
"These
PDFs are estimated from the development sets of TwitterUS and W-NUT, where both input representations are available.",6.1.1 Unification Strategies,[0],[0]
Strong preference of network representation for TwitterUS against WNUT is found in the PDFs.,6.1.1 Unification Strategies,[0],[0]
"This finding is intuitive because TwitterUS has substantially more user network edges (reduced-edge/user in Table 1) than W-NUT, which is likely to benefit more from user network information.",6.1.1 Unification Strategies,[0],[0]
We further analyzed the proposed model by clustering attention probabilities to capture typical attention patterns.,6.1.2 Attention Patterns,[0],[0]
"For each user, we assigned six attention probabilities of AttentionU and AttentionUN as features for a clustering.",6.1.2 Attention Patterns,[0],[0]
A kmeans clustering was performed over these users with 9 clusters.,6.1.2 Attention Patterns,[0],[0]
The clustering clearly separated the users to 5 clusters for TwitterUS users and 4 clusters for W-NUT users.,6.1.2 Attention Patterns,[0],[0]
We extracted typical users of each cluster by selecting the closest users of the cluster centroids.,6.1.2 Attention Patterns,[0],[0]
"Figure 6 shows a clustering result and the attention probabilities of these users.
",6.1.2 Attention Patterns,[0],[0]
These attention probabilities can be considered as typical attention patterns of the proposed model and match with the previously estimated PDFs.,6.1.2 Attention Patterns,[0],[0]
"For example, cluster 2 and 3 represent an attention pattern that processes users by balancing the representations of locations along with the representations of timelines.",6.1.2 Attention Patterns,[0],[0]
"Additionally, the location probabilities in this pattern are in the right tail region of the location PDF.",6.1.2 Attention Patterns,[0],[0]
The evaluation produced improvements in most of our models in the four metrics.,6.2.1 City Prediction,[0],[0]
One exception we found was the median distance error between SUB-NN-META and LR-STACKING in TwitterUS.,6.2.1 City Prediction,[0],[0]
"Because the median distance error of SUB-NN-META was quite low (46.8 km), we
measured the performance of an oracle model where city predictions are all correct (accuracy of 100%) in the test set.
",6.2.1 City Prediction,[0],[0]
Table 4 denotes this oracle performance.,6.2.1 City Prediction,[0],[0]
The oracle mean error distance is 31.4 km.,6.2.1 City Prediction,[0],[0]
Its standard deviation is 30.1.,6.2.1 City Prediction,[0],[0]
Note that ground truth locations of TwitterUS are geotags and will not exactly match the oracle city centers.,6.2.1 City Prediction,[0],[0]
These oracle values imply that the current median error distances are close to the lower bound of the city classification approach and that they are difficult to improve.,6.2.1 City Prediction,[0],[0]
The proposed model still contains 28–30% errors even in accuracy@161.,6.2.2 Errors with High Confidences,[0],[0]
A qualitative analysis of errors with high confidences was performed to investigate cases that the model fails.,6.2.2 Errors with High Confidences,[0],[0]
We found two common types of error in the error analysis.,6.2.2 Errors with High Confidences,[0],[0]
The first is a case when a location field is incorrect due to a reason such as a house move.,6.2.2 Errors with High Confidences,[0],[0]
"For example, the model predicted “Hong Kong” for a user with a location field of “Hong Kong” but has the gold location of “Toronto”.",6.2.2 Errors with High Confidences,[0],[0]
The second is a case when a user tweets a place name of a travel.,6.2.2 Errors with High Confidences,[0],[0]
"For example, the model predicted “San Francisco” for a user who tweeted about a travel to “San Francisco” but has the gold location of “Boston”.
",6.2.2 Errors with High Confidences,[0],[0]
These two types of error are difficult to handle with the current architecture of the proposed model.,6.2.2 Errors with High Confidences,[0],[0]
The architecture only supports single location field which disables the model to track location changes.,6.2.2 Errors with High Confidences,[0],[0]
"The architecture also treats each
tweet independently which forbids the model to express a temporal state like traveling.",6.2.2 Errors with High Confidences,[0],[0]
"As described in this paper, we proposed a complex neural network model for geolocation prediction.",7 Conclusion,[0],[0]
"The model unifies text, metadata, and user network information.",7 Conclusion,[0],[0]
The model achieved the maximum of a 3.8% increase in accuracy and a maximum of 6.6% increase in accuracy@161 against several previous state-of-the-art models.,7 Conclusion,[0],[0]
"We further analyzed the states of several attention layers, which revealed that the probabilities assigned to timeline representations and user network representations match to some statistical characteristics of datasets.
",7 Conclusion,[0],[0]
"As future works of this study, we are planning to expand the proposed model to handle multiple locations and a temporal state to capture location changes and states like traveling.",7 Conclusion,[0],[0]
"Additionally, we plan to apply the proposed model to other social media analyses such as gender analysis and age analysis.",7 Conclusion,[0],[0]
"In these analyses, metadata like location fields and timezones may not be effective like in geolocation prediction.",7 Conclusion,[0],[0]
"However, a user network is known to include various user attributes information including gender and age (McPherson et al., 2001) which suggests the unification of text and user network information to result in a success as in geolocation prediction.",7 Conclusion,[0],[0]
We would like to thank the members of Okumura– Takamura Group at Tokyo Institute of Technology for having insightful discussions about user profiling models in social media.,Acknowledgments,[0],[0]
We would also like to thank the anonymous reviewer for their comments to improve this paper.,Acknowledgments,[0],[0]
"A.1 Parameters of Embedding Pre-training Word embeddings were pre-trained with the parameters of learning rate=0.025, window size=5, negative sample size=5, and epoch=5.",A Supplemental Materials,[0],[0]
"User embeddings were pre-trained with the parameters of initial learning rate=0.025, order=2, negative sample size=5, and training sample size=100M.
A.2 Model Parameters and Parameter Selection Strategies
Unit Sizes, Embedding Dimensions, and a Max Tweet Number The layers and the embeddings in our models have unit size and embedding dimension parameters.",A Supplemental Materials,[0],[0]
We also restricted the maximum number of tweets per user for TwitterUS to reduce memory footprints.,A Supplemental Materials,[0],[0]
Table 5 shows the values for these parameters.,A Supplemental Materials,[0],[0]
Smaller values were set for TwitterUS because TwitterUS is approximately 2.6 times larger in terms of tweet number.,A Supplemental Materials,[0],[0]
"It was computationally expensive to process TwiiterUS in the same settings as W-NUT.
",A Supplemental Materials,[0],[0]
Regularization Parameters and Bucket Sizes We chose optimal values of α using a grid search with the development sets of TwitterUS and WNUT.,A Supplemental Materials,[0],[0]
"The range of α was set as the following: α ∈ {1e−4, 5e−5, 1e−5, 5e−6, 1e−6, 5e−7, 1e−7, 5e−8, 1e−8}.
",A Supplemental Materials,[0],[0]
We also chose optimal values of c using grid search with the development sets of TwitterUS and W-NUT for the baseline models.,A Supplemental Materials,[0],[0]
"The range of c was set as the following for TwitterUS: c ∈ {50, 100, 150, 200, 250, 300, 339}.",A Supplemental Materials,[0],[0]
"The following was set for W-NUT: c ∈ {100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1500, 2000, 2500, 3000, 3028}.",A Supplemental Materials,[0],[0]
"Table 6 presents selected values of α and c. For LR-STACK and MADCEl-B-LR-STACK, different parameters of α and c were selected for each logistic regression classifier.
MAD Parameters and Celebrity Threshold The MAD parameters µ1, µ2, and µ3 and celebrity threshold t were also chosen using grid search with the development sets of TwitterUS and WNUT.",A Supplemental Materials,[0],[0]
"The ranges of µ1, µ2, and µ3 were set as the following: µ1 ∈ {1.0}, µ2 ∈ {0.001, 0.01, 0.1, 1.0, 10.0}, µ3 ∈ {0.0, 0.001, 0.01, 0.1, 1.0, 10.0}.",A Supplemental Materials,[0],[0]
"The range of t for TwitterUS was set as t ∈ {2, . . .",A Supplemental Materials,[0],[0]
", 16}.",A Supplemental Materials,[0],[0]
"The range of t for W-NUT was set
as t ∈ {2, . . .",A Supplemental Materials,[0],[0]
", 6}.",A Supplemental Materials,[0],[0]
"Table 6 presents selected values of µ1, µ2, µ3, and t.",A Supplemental Materials,[0],[0]
We propose a novel geolocation prediction model using a complex neural network.,abstractText,[0],[0]
"Our model unifies text, metadata, and user network representations with an attention mechanism to overcome previous ensemble approaches.",abstractText,[0],[0]
"In an evaluation using two open datasets, the proposed model exhibited a maximum 3.8% increase in accuracy and a maximum of 6.6% increase in accuracy@161 against previous models.",abstractText,[0],[0]
"We further analyzed several intermediate layers of our model, which revealed that their states capture some statistical characteristics of the datasets.",abstractText,[0],[0]
"Unifying Text, Metadata, and User Network Representations with a Neural Network for Geolocation Prediction",title,[0],[0]
Ordinal classification (sometimes called ordinal regression) is a prediction task in which the classes to be predicted are discrete and ordered in some fashion.,1. Introduction,[0],[0]
"This is different from discrete classification in which the classes are not ordered, and different from regression in that we typically do not know the distances between the classes (unlike regression, in which we know the distances because the predictions lie on the real number line).",1. Introduction,[0],[0]
"Some examples of ordinal classification tasks include predicting the stages of disease for a cancer (Gentry et al., 2015), predicting what star rating a user gave to a movie (Koren & Sill, 2011), or predicting the age of a person (Eidinger et al., 2014).
",1. Introduction,[0],[0]
"Two of the easiest techniques used to deal with ordinal problems include either treating the problem as a discrete classification and minimising the cross-entropy loss, or treating the problem as a regression and using the squared error loss.",1. Introduction,[0],[0]
"The former ignores the inherent ordering between the classes, while the latter takes into account the distances between them (due to the square in the error term) but assumes that the labels are actually real-valued – that is, adjacent classes are equally distant.",1. Introduction,[0],[0]
"Furthermore, the cross-entropy loss – under a one-hot target encoding – is formulated such that it only ‘cares’ about the ground truth class, and that probability estimates corresponding to the
1Montréal Institute of Learning Algorithms, Québec, Canada.",1. Introduction,[0],[0]
"Correspondence to: Christopher Beckham <christopher.beckham@polymtl.ca>.
Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
other classes may not necessarily make sense in context.,1. Introduction,[0],[0]
"We present an example of this in Figure 1, showing three probability distributions: A, B, and C, all conditioned on some input image.",1. Introduction,[0],[0]
"Highlighted in orange is the ground truth (i.e. the image is of an adult), and all probability distributions have identical cross-entropy: this is because the loss only takes into account the ground truth class, − log(p(y|x)c), where c = adult, and all three distributions have the same probability mass for the adult class.
",1. Introduction,[0],[0]
"Despite all distributions having the same cross-entropy loss, some distributions are ‘better’ than others.",1. Introduction,[0],[0]
"For example, between A and B, A is preferred, since B puts an unusually high mass on the baby class.",1. Introduction,[0],[0]
"However, A and B are both unusual, because the probability mass does not gradually decrease to the left and right of the ground truth.",1. Introduction,[0],[0]
"In other words, it seems unusual to place more confidence on ‘schooler’ than ‘teen’ (distribution A) considering that a teenager looks more like an adult than a schooler, and it seems unusual to place more confidence on ’baby’ than ’teen’ considering that again, a teenager looks more like an adult than a baby.",1. Introduction,[0],[0]
Distribution C makes the most sense because the probability mass gradually decreases as we move further away from the most confident class.,1. Introduction,[0],[0]
"In this paper, we propose a simple method to enforce this constraint, utilising the probability mass function of either the Poisson or binomial distribution.
",1. Introduction,[0],[0]
"For the remainder of this paper, we will refer to distributions like C as ‘unimodal’ distributions; that is, distributions where the probability mass gradually decreases on both sides of the class that has the majority of the mass.",1. Introduction,[0],[0]
"Our work is inspired by the recent work of Hou et al. (2016), who shed light on the issues associated with different probability distributions having the same cross-entropy loss for ordinal problems.",1.1. Related work,[0],[0]
"In their work, they alleviate this issue by minimising the ‘Earth mover’s distance’, which is defined as the minimum cost needed to transform one probability distribution to another.",1.1. Related work,[0],[0]
Because this metric takes into account the distances between classes – moving probability mass to a far-away class incurs a large cost – the metric is appropriate to minimise for an ordinal problem.,1.1. Related work,[0],[0]
"It turns out that in the case of an ordinal problem, the Earth
distribution A
distribution B
distribution C
mover’s distance reduces down to Mallow’s distance: emd(ŷ,y) =",1.1. Related work,[0],[0]
"( 1 K ) 1 l ||cmf(ŷ)− cmf(y)||l, (1)
where cmf(·) denotes the cumulative mass function for some probability distribution, y denotes the ground truth (one-hot encoded), ŷ",1.1. Related work,[0],[0]
"the corresponding predicted probability distribution, and K the number of classes.",1.1. Related work,[0],[0]
The authors evaluate the EMD loss on two age estimation and one aesthetic estimation dataset and obtain state-of-the-art results.,1.1. Related work,[0],[0]
"However, the authors do not show comparisons between the probability distributions learned between EMD and crossentropy.
",1.1. Related work,[0],[0]
Unimodality has been explored for ordinal neural networks in da Costa et al. (2008).,1.1. Related work,[0],[0]
They explored the use of the binomial and Poisson distributions and a non-parametric way of enforcing unimodal probability distributions (which we do not explore).,1.1. Related work,[0],[0]
"One key difference between their work and ours here is that we evaluate these unimodal distributions in the context of deep learning, where the datasets are generally much larger and have more variability; however, there are numerous other differences which we will highlight throughout this paper.
",1.1. Related work,[0],[0]
Beckham & Pal (2016) explored a loss function with an intermediate form between a cross-entropy and regression loss.,1.1. Related work,[0],[0]
"In their work the squared error loss is still used, but a probability distribution over classes is still learned.",1.1. Related work,[0],[0]
"This is done by adding a regression layer (i.e. a one-unit layer) at the top of what would normally be the classification layer, p(y|x).",1.1. Related work,[0],[0]
"Instead of learning the weight vector a it is fixed to [0, . . .",1.1. Related work,[0],[0]
",K− 1]T and the squared error loss is minimised.",1.1. Related work,[0],[0]
"This can be interpreted as drawing the class label from a Gaussian distribution p(c|x) = N(c;E[a]p(y|x), σ2).",1.1. Related work,[0],[0]
This technique was evaluated against the diabetic retinopathy dataset and beat most of the baselines employed.,1.1. Related work,[0],[0]
"Interestingly, since p(c|x) is a Gaussian, this is also unimodal,
though it is a somewhat odd formulation as it assumes c is continuous when it is really discrete.
",1.1. Related work,[0],[0]
Cheng (2007) proposed the use of binary cross-entropy or squared error on an ordinal encoding scheme rather than the one-hot encoding which is commonly used in discrete classification.,1.1. Related work,[0],[0]
"For example, if we haveK classes, then we have labels of length K − 1, where the first class is [0, . . .",1.1. Related work,[0],[0]
", 0], second class is [1, . . .",1.1. Related work,[0],[0]
", 0], third class is [1, 1, . . .",1.1. Related work,[0],[0]
", 0] and so forth.",1.1. Related work,[0],[0]
"With this formulation, we can think of the i’th output unit as computing the cumulative probability p(y > i|x), where i ∈ {0, . . .",1.1. Related work,[0],[0]
",K − 2}.",1.1. Related work,[0],[0]
"Frank & Hall (2001) also proposed this scheme but in a more general sense by using multiple classifiers (not just neural networks) to model each cumulative probability, and Niu et al. (2016) proposed a similar scheme using CNNs for age estimation.",1.1. Related work,[0],[0]
This technique however suffers from the issue that the cumulative probabilities p(y > 0,1.1. Related work,[0],[0]
"| x), . . .",1.1. Related work,[0],[0]
", p(y > K − 2 | x) are not guaranteed to be monotonically decreasing, which means that if we compute the discrete probabilities p(y = 0 | x), . . .",1.1. Related work,[0],[0]
", p(y = K − 1 | x) these are not guaranteed to be strictly positive.",1.1. Related work,[0],[0]
"To address the monotonicity issue, Schapire et al. (2002) proposed a heuristic solution.
",1.1. Related work,[0],[0]
There are other ordinal techniques but which do not impose unimodal constraints.,1.1. Related work,[0],[0]
"The proportional odds model (POM) and its neural network extensions (POMNN, CHNN (Gutiérrez et al., 2014)) do not suffer from the monotonicity issue due to the utilization of monotonically increasing biases in the calculation of probabilities.",1.1. Related work,[0],[0]
"The stick-breaking approach by Khan et al. (2012), which is a reformulation of the multinomial logit (softmax), could also be used in the ordinal case as it technically imposes an ordering on classes.",1.1. Related work,[0],[0]
"The Poisson distribution is commonly used to model the probability of the number of events, k ∈ N ∪ 0 occurring in a particular interval of time.",1.2. Poisson distribution,[0],[0]
The average frequency of these events is denoted by λ ∈,1.2. Poisson distribution,[0],[0]
R+.,1.2. Poisson distribution,[0],[0]
"The probability mass function is defined as:
p(k;λ) = λk exp(−λ)
k! , (2)
where 0 ≤ k ≤",1.2. Poisson distribution,[0],[0]
K,1.2. Poisson distribution,[0],[0]
− 1.,1.2. Poisson distribution,[0],[0]
"While we are not actually using this distribution to model the occurrence of events, we can make use of its probability mass function (PMF) to enforce discrete unimodal probability distributions.",1.2. Poisson distribution,[0],[0]
"For a purely technical reason, we instead deal with the log of the PMF:
log [λkexp(−λ)
k!
]",1.2. Poisson distribution,[0],[0]
"= log(λkexp(−λ))− log(k!)
= log(λk) + log(exp(−λ))− log(k!)",1.2. Poisson distribution,[0],[0]
"= k log(λ)− λ− log(k!).
",1.2. Poisson distribution,[0],[0]
"(3)
If we let f(x) denote the scalar output of our deep net (where f(x) > 0",1.2. Poisson distribution,[0],[0]
"which can be enforced with the softplus nonlinearity), then we denote h(x)j to be:
j log(f(x))− f(x)− log(j!), (4)
where we have simply replaced the λ in equation (3) with f(x).",1.2. Poisson distribution,[0],[0]
"Then, p(y = j|x) is simply a softmax over h(x):
p(y = j|x) = exp(−h(x)j/τ)∑K i=1",1.2. Poisson distribution,[0],[0]
exp(−h(x)i/,1.2. Poisson distribution,[0],[0]
"τ) , (5)
which is required since the support of the Poisson is infinite.",1.2. Poisson distribution,[0],[0]
"We have also introduced a hyperparameter to the softmax, τ , to control the relative magnitudes of each value of p(y = j|x) (i.e., the variance of the distribution).",1.2. Poisson distribution,[0],[0]
"Note that as τ → ∞, the probability distribution becomes more uniform, and as τ → 0, the distribution becomes more ‘one-hot’ like with respect to the class with the largest presoftmax value.",1.2. Poisson distribution,[0],[0]
"We can illustrate this technique in terms of the layers at the end of the deep network, which is shown in Figure 2.
",1.2. Poisson distribution,[0],[0]
"We note that the term in equation (4) can be re-arranged and simplified to
h(x)j = j log(f(x))− f(x)− log(j!)",1.2. Poisson distribution,[0],[0]
= −f(x) + j log(f(x))− log(j!),1.2. Poisson distribution,[0],[0]
"= −f(x) + bj(f(x)).
(6)
",1.2. Poisson distribution,[0],[0]
"In this form, we can see that the probability of class j is determined by the scalar term f(x) and a bias term that also depends on f(x).",1.2. Poisson distribution,[0],[0]
"Another technique that uses biases to determine class probabilities is the proportional odds model
(POM), also called the ordered logit (McCullagh, 1980), where the cumulative probability of a class depends on a learned bias:
p(y ≤ j | x) = sigm(f(x)− bj), (7)
where b1 < · · · < bK .",1.2. Poisson distribution,[0],[0]
"Unlike our technique however, the bias vector b is not a function of x nor f(x), but a fixed vector that is learned during training, which is interesting.",1.2. Poisson distribution,[0],[0]
"Furthermore, probability distributions computed using this technique are not guaranteed to be unimodal.
",1.2. Poisson distribution,[0],[0]
Figure 5 shows the resulting probability distributions for values of f(x) ∈,1.2. Poisson distribution,[0],[0]
"[0.1, 4.85] when τ = 1.0 and τ = 0.3.",1.2. Poisson distribution,[0],[0]
We can see that all distributions are unimodal and that by gradually increasing f(x) we gradually change which class has the most mass associated with itself.,1.2. Poisson distribution,[0],[0]
The τ is also an important parameter to tune as it alters the variance of the distribution.,1.2. Poisson distribution,[0],[0]
"For example, in Figure 5(a), we can see that if we are confident in predicting the second class, f(x) should be ∼ 2.6, though in this case the other classes receive almost just as much probability mass.",1.2. Poisson distribution,[0],[0]
"If we set τ = 0.3 however (Figure 5(b)), at f(x) = 2.6 the second class has relatively more mass, which is to say we are even more confident that this is the correct class.",1.2. Poisson distribution,[0],[0]
"An unfortunate side effect of using the Poisson distribution is that the variance is equivalent to the mean, λ.",1.2. Poisson distribution,[0],[0]
"This means that in the case of a large number of classes probability mass will be widely distributed, and this can be seen in the K = 8 case in Figure 6.",1.2. Poisson distribution,[0],[0]
"While careful selection of τ can mitigate this, we also use this problem to motivate the use of the binomial distribution.
",1.2. Poisson distribution,[0],[0]
"In the work of da Costa et al. (2008), they address the infinite support problem by using a ‘right-truncated’ Poisson distribution.",1.2. Poisson distribution,[0],[0]
"In this formulation, they simply find the normalization constant such that the probabilities sum to one.",1.2. Poisson distribution,[0],[0]
"This is almost equivalent to what we do, since we use a softmax, although the softmax exponentiates its inputs and we also introduce the temperature parameter τ to control for the variance of the distribution.",1.2. Poisson distribution,[0],[0]
The binomial distribution is used to model the probability of a given number of ‘successes’ out of a given number of trials and some success probability.,1.3. Binomial distribution,[0],[0]
The probability mass function for this distribution – for k successes (where 0 ≤ k ≤,1.3. Binomial distribution,[0],[0]
"K − 1), given K − 1 trials and success probability p – is:
p(k;K",1.3. Binomial distribution,[0],[0]
"− 1, p) =",1.3. Binomial distribution,[0],[0]
"( K − 1 k ) pk(1− p)K−1−k (8)
In the context of applying this to a neural network, k denotes the class we wish to predict, K − 1 denotes the number of classes (minus one since we index from zero), and p = f(x) ∈",1.3. Binomial distribution,[0],[0]
"[0, 1] is the output of the network that we wish to estimate.",1.3. Binomial distribution,[0],[0]
"While no normalisation is theoretically needed since the binomial distribution’s support is finite, we still had to take the log of the PMF and normalise with a softmax to address numeric stability issues.",1.3. Binomial distribution,[0],[0]
"This means the resulting network is equivalent to that shown in Figure 2, but with the log binomial PMF instead of Poisson.",1.3. Binomial distribution,[0],[0]
"Just like with the Poisson formulation, we can introduce the temperature term τ into the resulting softmax to control for the variance of the resulting distribution.
",1.3. Binomial distribution,[0],[0]
Figure 8 shows the resulting distributions achieved by varying p for when K = 4 and K = 8.,1.3. Binomial distribution,[0],[0]
"In this section we go into details of our experiments, including the datasets used and the precise architectures.",2. Methods and Results,[0],[0]
"We make use of two ordinal datasets appropriate for deep neural networks:
• Diabetic retinopathy1.",2.1. Data,[0],[0]
This is a dataset consisting of extremely high-resolution fundus image data.,2.1. Data,[0],[0]
"The training set consists of 17,563 pairs of images (where a pair consists of a left and right eye image corresponding to a patient).",2.1. Data,[0],[0]
"In this dataset, we try and predict from five levels of diabetic retinopathy: no DR (25,810 images), mild DR (2,443 images), moderate DR (5,292 images), severe DR (873 images), or proliferative DR (708 images).",2.1. Data,[0],[0]
"A validation set is set aside, consisting of 10% of the patients in the training set.",2.1. Data,[0],[0]
"The images are pre-processed using the technique proposed by competition winner Graham (2015) and subsequently resized to 256px width and height.
",2.1. Data,[0],[0]
• The Adience face dataset2,2.1. Data,[0],[0]
"(Eidinger et al., 2014).",2.1. Data,[0],[0]
"This dataset consists of 26,580 faces belonging to 2,284
1https://www.kaggle.com/c/diabetic-retinopathy-detection/ 2http://www.openu.ac.il/home/hassner/Adience/data.html
subjects.",2.1. Data,[0],[0]
We use the form of the dataset where faces have been pre-cropped and aligned.,2.1. Data,[0],[0]
We further preprocess the dataset so that the images are 256px in width and height.,2.1. Data,[0],[0]
"The training set consists of merging the first four cross-validation folds together (the last cross-validation fold is the test set), which comprises a total of 15,554 images.",2.1. Data,[0],[0]
"From this, 10% of the images are held out as part of a validation set.",2.1. Data,[0],[0]
"We make use of a modest ResNet (He et al., 2015) architecture to conduct our experiments.",2.2. Network,[0],[0]
Table 1 describes the exact architecture.,2.2. Network,[0],[0]
"We use the ReLU nonlinearity and HeNormal initialization throughout the network.
",2.2. Network,[0],[0]
"We conduct the following experiments for both DR and Adience datasets:
• (Baseline) cross-entropy loss.",2.2. Network,[0],[0]
This simply corresponds to a softmax layer for K classes at the end of the average pooling layer in Table 1.,2.2. Network,[0],[0]
"For Adience and DR, this corresponds to a network with 4,309,896 and 4,309,125 learnable parameters, respectively.
",2.2. Network,[0],[0]
• (Baseline) squared-error loss.,2.2. Network,[0],[0]
"Rather than regress f(x) against y, we regress with (K − 1)sigm(f(x)), since we have observed better results with this formulation in the past.",2.2. Network,[0],[0]
"For Adience and DR, this corresponds t 4,309,905 and 4,309,131 learnable parameters, respectively.
• Cross-entropy loss using the Poisson and binomial extensions at the end of the architecture (see Figure 2).",2.2. Network,[0],[0]
"For Adience and DR, this corresponds to 4,308,097 learnable parameters for both.",2.2. Network,[0],[0]
"Although da Costa
et al. (2008) mention that cross-entropy or squared error can be used, their equations assume a squared error between the (one-hot encoded) ground truth and p(y|x), whereas we use cross-entropy.
",2.2. Network,[0],[0]
• EMD loss (equation 1) where ` = 2 (i.e. Euclidean norm) and the entire term is squared (to get rid of the square root induced by the norm) using Poisson and binomial extensions at the end of architecture.,2.2. Network,[0],[0]
"Again, this corresponds to 4,308,097 learnable parameters for both networks.
",2.2. Network,[0],[0]
"Amongst these experiments, we use τ = 1 and also learn τ as a bias.",2.2. Network,[0],[0]
"When we learn τ , we instead learn sigm(τ) since we found this made training more stable.",2.2. Network,[0],[0]
"Note that we can also go one step further and learn τ as a function of x, though experiments did not show any significant gain over simply learning it as a bias.",2.2. Network,[0],[0]
"However, one advantage of this technique is that the network can quantify its uncertainty on a per-example basis.",2.2. Network,[0],[0]
"It is also worth noting that the Poisson and binomial formulations are slightly underparameterised compared to their baselines, but experiments we ran that addressed this (by matching model capacity) did not yield significantly different results.
",2.2. Network,[0],[0]
"It is also important to note that in the case of ordinal prediction, there are two ways to compute the final prediction: simply taking the argmax of p(y|x) (which is what is simply done in discrete classification), or taking a ‘smoothed’ prediction which is simply the expectation of the integer labels w.r.t.",2.2. Network,[0],[0]
"the probability distribution, i.e., E[0, . . .",2.2. Network,[0],[0]
",K − 1]p(y|x).",2.2. Network,[0],[0]
"For the latter, we call this the ‘expectation trick’.",2.2. Network,[0],[0]
A benefit of the latter is that it computes a prediction that considers the probability mass of all classes.,2.2. Network,[0],[0]
"One benefit of the former however is that we can use it to easily rank our predictions, which can be important if we are interested in computing top-k accuracy (rather than top1).
",2.2. Network,[0],[0]
"We also introduce an ordinal evaluation metric – the quadratic weighted kappa (QWK) (Cohen, 1968) – which has seen recent use on ordinal competitions on Kaggle.",2.2. Network,[0],[0]
"Intuitively, this is a number between [-1,1], where a kappa κ = 0 denotes the model does no better than random chance, κ < 0 denotes worst than random chance, and κ > 0 better than random chance (with κ = 1 being the best score).",2.2. Network,[0],[0]
"The ‘quadratic’ part of the metric imposes a quadratic penalty on misclassifications, making it an appropriate metric to use for ordinal problems.3
All experiments utilise an `2 norm of 10−4, ADAM optimiser (Kingma & Ba, 2014) with initial learning rate 10−3, and batch size 128.",2.2. Network,[0],[0]
"A ‘manual’ learning rate schedule is
3The quadratic penalty is arbitrary but somewhat appropriate for ordinal problems.",2.2. Network,[0],[0]
"One can plug in any cost matrix into the kappa calculation.
employed where we manually divide the learning rate by 10 when either the validation loss or valid set QWK plateaus (whichever plateaus last) down to a minimum of 10−4 for Adience and 10−5 for DR.4",2.2. Network,[0],[0]
"Figure 3 shows the experiments run for the Adience dataset, for when τ = 1.0 (Figure 3(a)) and when τ is learned (Figure 3(b)).",2.3. Experiments,[0],[0]
"We can see that for our methods, careful selection of τ is necessary for the accuracy on the validation set to be on par with that of the cross-entropy baseline.",2.3. Experiments,[0],[0]
"For τ = 1.0, accuracy is poor, but even less so when τ is learned.",2.3. Experiments,[0],[0]
"To some extent, using the smoothed prediction with the expectation trick alleviates this gap.",2.3. Experiments,[0],[0]
"However, because the dataset is ordinal, accuracy can be very misleading, so we should also consider the QWK.",2.3. Experiments,[0],[0]
"For both argmax and expectation, our methods either outperform or are quite competitive with the baselines, with the exception of the QWK argmax plot for when τ = 1, where only our binomial formulations were competitive with the cross-entropy baseline.",2.3. Experiments,[0],[0]
"Overall, considering all plots in Figure 3 it appears the binomial formulation produces better results than Poisson.",2.3. Experiments,[0],[0]
"There also appears to be some benefit gained from using the EMD loss for Poisson, but not for binomial.
",2.3. Experiments,[0],[0]
Figure 4 show the experiments run for diabetic retinopathy.,2.3. Experiments,[0],[0]
"We note that unlike Adience, the validation accuracy does not appear to be so affected across all specifications of τ .",2.3. Experiments,[0],[0]
One potential reason for this is due to Adience having a larger number of classes compared to DR.,2.3. Experiments,[0],[0]
"As we mentioned earlier, the Poisson distribution is somewhat awkward as its variance is equivalent to its mean.",2.3. Experiments,[0],[0]
"Since most of the probability mass sits at the mean, if the mean of the distribution is very high (which is the case for datasets with a large K such as Adience), then the large variance can negatively impact the distribution by taking probability mass away from the correct class.",2.3. Experiments,[0],[0]
We can see this effect by comparing the distributions in Figure 5 (k = 4) and Figure 6 (k = 8).,2.3. Experiments,[0],[0]
"As with the Adience dataset, the use of the expectation trick brings the accuracy of our methods to be almost on-par with the baselines.",2.3. Experiments,[0],[0]
"In terms of QWK, only our binomial formulations appear to be competitive, but only in the argmax case do one of our methods (the binomial formulation) beat the cross-entropy baseline.",2.3. Experiments,[0],[0]
"At least for accuracy, there appears to be some gain in using the EMD loss for the binomial formulation.",2.3. Experiments,[0],[0]
"Because DR is a much larger dataset compared to Adience, it is possible that the deep net is able to learn reasonable and ‘unimodal-like’ probability distributions without it being enforced in the model architecture.
",2.3. Experiments,[0],[0]
"4We also re-ran experiments using an automatic heuristic to change the learning rate, and similar experimental results were obtained.
",2.3. Experiments,[0],[0]
"Overall, across both datasets the QWK for our methods are generally at least competitive with the baselines, especially if we learn τ to control for the variance.",2.3. Experiments,[0],[0]
"In the empirical results of da Costa et al. (2008), they found that the binomial formulation performed better than the Poisson, and when we consider all of our results in Figure 3 and 4 we come to the same conclusion.",2.3. Experiments,[0],[0]
They justify this result by defining the ‘flexibility’ of a discrete probability distribution and show that the binomial distribution is more ‘flexible’ than Poisson.,2.3. Experiments,[0],[0]
"From our results, we believe that these unimodal methods act as a form of regularization which can be useful in regimes where one is interested in top-k accuracy.",2.3. Experiments,[0],[0]
"For example, in the case of top-k accuracy, we want to know if the ground truth was in the top k predictions, and we may be interested in such metrics if it is difficult to achieve good top-1 accuracy.",2.3. Experiments,[0],[0]
"Assume that our probability distribution p(y|x) has most of its mass on the wrong class, but the correct class is on either side of it.",2.3. Experiments,[0],[0]
"Under a unimodal constraint, it is guaranteed that the two classes on either side of the majority class will receive the next greatest amount of probability mass, and this can result in a correct prediction if we consider top-2 or top-3 accuracy.",2.3. Experiments,[0],[0]
"To illustrate this,
we compute the top-k accuracy on the test set of the Adience dataset, shown in Figure 9.",2.3. Experiments,[0],[0]
We can see that even with the worst-performing model – the Poisson formulation with τ = 1 (orange) – produces a better top-3 accuracy than the cross-entropy baseline (blue).,2.3. Experiments,[0],[0]
"In conclusion, we present a simple technique to enforce unimodal ordinal probabilistic predictions through the use of the binomial and Poisson distributions.",3. Conclusion,[0],[0]
This is an important property to consider in ordinal classification because of the inherent ordering between classes.,3. Conclusion,[0],[0]
"We evaluate our technique on two ordinal image datasets and obtain results competitive or superior to the cross-entropy baseline for both the quadratic weighted kappa (QWK) metric and topk accuracy for both cross-entropy and EMD losses, especially under the binomial distribution.",3. Conclusion,[0],[0]
"Lastly, the unimodal constraint can makes the probability distributions behave more sensibly in certain settings.",3. Conclusion,[0],[0]
"However, there may be ordinal problems where a multimodal distribution may be more appropriate.",3. Conclusion,[0],[0]
We leave an exploration of this issue for future work.,3. Conclusion,[0],[0]
Code will be made available here.5,3. Conclusion,[0],[0]
We thank Samsung for funding this research.,4. Acknowledgements,[0],[0]
"We would like to thank the contributors of Theano (Theano Development Team, 2016) and Lasagne (Dieleman et al., 2015) (which this project was developed in predominantly), as well as Keras (Chollet et al., 2015) for extra useful code.",4. Acknowledgements,[0],[0]
"We thank the ICML reviewers for useful feedback, as well as Eibe Frank.
5https://github.com/christopher-beckham/deep-unimodalordinal",4. Acknowledgements,[0],[0]
Probability distributions produced by the crossentropy loss for ordinal classification problems can possess undesired properties.,abstractText,[0],[0]
We propose a straightforward technique to constrain discrete ordinal probability distributions to be unimodal via the use of the Poisson and binomial probability distributions.,abstractText,[0],[0]
"We evaluate this approach in the context of deep learning on two large ordinal image datasets, obtaining promising results.",abstractText,[0],[0]
Unimodal Probability Distributions for Deep Ordinal Classification,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 344–354 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Neural Machine Translation (NMT) (Bahdanau et al., 2015) has achieved remarkable translation quality in various on-line large-scale systems (Wu et al., 2016; Devlin, 2017) as well as achieving state-of-the-art results on Chinese-English translation (Hassan et al., 2018).",1 Introduction,[0],[0]
"With such large systems, NMT showed that it can scale up to immense amounts of parallel data in the order of tens of millions of sentences.",1 Introduction,[0],[0]
"However, such data is not widely available for all language pairs and domains.
∗This work was done while the authors at Microsoft.
",1 Introduction,[0],[0]
"In this paper, we propose a novel universal multilingual NMT approach focusing mainly on low resource languages to overcome the limitations of NMT and leverage the capabilities of multi-lingual NMT in such scenarios.
",1 Introduction,[0],[0]
Our approach utilizes multi-lingual neural translation system to share lexical and sentence level representations across multiple source languages into one target language.,1 Introduction,[0],[0]
"In this setup, some of the source languages may be of extremely limited or even zero data.",1 Introduction,[0],[0]
The lexical sharing is represented by a universal word-level representation where various words from all source languages share the same underlaying representation.,1 Introduction,[0],[0]
The sharing module utilizes monolingual embeddings along with seed parallel data from all languages to build the universal representation.,1 Introduction,[0],[0]
The sentence-level sharing is represented by a model of language experts which enables low-resource languages to utilize the sentence representation of the higher resource languages.,1 Introduction,[0],[0]
"This allows the system to translate from any language even with tiny amount of parallel resources.
",1 Introduction,[0],[0]
We evaluate the proposed approach on 3 different languages with tiny or even zero parallel data.,1 Introduction,[0],[0]
"We show that for the simulated “zero-resource"" settings, our model can consistently outperform a strong multi-lingual NMT baseline with a tiny amount of parallel sentence pairs.",1 Introduction,[0],[0]
"Neural Machine Translation (NMT) (Bahdanau et al., 2015; Sutskever et al., 2014) is based on Sequence-to-Sequence encoder-decoder model along with an attention mechanism to enable better handling of longer sentences (Bahdanau et al., 2015).",2 Motivation,[0],[0]
"Attentional sequence-to-sequence models are modeling the log conditional probability of the
344
translation Y given an input sequence X .",2 Motivation,[0],[0]
"In general, the NMT system θ consists of two components: an encoder θe which transforms the input sequence into an array of continuous representations, and a decoder θd that dynamically reads the encoder’s output with an attention mechanism and predicts the distribution of each target word.",2 Motivation,[0],[0]
"Generally, θ is trained to maximize the likelihood on a training set consisting of N parallel sentences:
L (θ) = 1 N
N∑
n=1
log p ( Y (n)|X(n); θ )
",2 Motivation,[0],[0]
"= 1
N
N∑
n=1
T∑
t=1
log p ( y (n) t |y (n) 1:t−1, f att t (h (n) 1:Ts ) )
",2 Motivation,[0],[0]
"(1)
where at each step, f attt builds the attention mechanism over the encoder’s output h1:Ts .",2 Motivation,[0],[0]
"More precisely, let the vocabulary size of source words as V
h1:",2 Motivation,[0],[0]
Ts = f ext,2 Motivation,[0],[0]
"[ex1 , ..., exTs ] , ex = E I(x) (2)
where EI ∈ RV×d is a look-up table of source embeddings, assigning each individual word a unique embedding vector; f ext is a sentencelevel feature extractor and is usually implemented by a multi-layer bidirectional RNN (Bahdanau et al., 2015; Wu et al., 2016), recent efforts also achieved the state-of-the-art using non-recurrence f ext, e.g. ConvS2S (Gehring et al., 2017) and Transformer (Vaswani et al., 2017).
",2 Motivation,[0],[0]
Extremely Low-Resource NMT Both θe,2 Motivation,[0],[0]
and θd should be trained to converge using parallel training examples.,2 Motivation,[0],[0]
"However, the performance is highly correlated to the amount of training data.",2 Motivation,[0],[0]
As shown in Figure.,2 Motivation,[0],[0]
"1, the system cannot achieve reasonable translation quality when the number of the parallel
examples is extremely small (N ≈ 13k sentences, or not available at all N = 0).
",2 Motivation,[0],[0]
Multi-lingual NMT Lee et al. (2017) and Johnson et al. (2017) have shown that NMT is quite efficient for multilingual machine translation.,2 Motivation,[0],[0]
"Assuming the translation from K source languages into one target language, a system is trained with maximum likelihood on the mixed parallel pairs {X(n,k), Y (n,k)}n=1...Nkk=1...K , that is
L (θ) =",2 Motivation,[0],[0]
"1 N
K∑
k=1
Nk∑
n=1
log p ( Y (n,k)|X(n,k); θ ) (3)
where N = ∑K
k=1Nk.",2 Motivation,[0],[0]
"As the input layer, the system assumes a multilingual vocabulary which is usually the union of all source language vocabularies with a total size as V = ∑K k=1 Vk.",2 Motivation,[0],[0]
"In practice, it is essential to shuffle the multilingual sentence pairs into mini-batches so that different languages can be trained equally.",2 Motivation,[0],[0]
"Multi-lingual NMT is quite appealing for low-resource languages; several papers highlighted the characteristic that make it a good fit for that such as Lee et al. (2017), Johnson et al. (2017), Zoph et al. (2016) and Firat et al. (2016).",2 Motivation,[0],[0]
Multi-lingual NMT utilizes the training examples of multiple languages to regularize the models avoiding over-fitting to the limited data of the smaller languages.,2 Motivation,[0],[0]
"Moreover, the model transfers the translation knowledge from high-resource languages to low-resource ones.",2 Motivation,[0],[0]
"Finlay, the decoder part of the model is sufficiently trained since it shares multilingual examples from all languages.",2 Motivation,[0],[0]
"Despite the success of training multi-lingual NMT systems; there are a couple of challenges to leverage them for zero-resource languages:
Lexical-level Sharing Conventionally, a multilingual NMT model has a vocabulary that represents the union of the vocabularies of all source languages.",2.1 Challenges,[0],[0]
"Therefore, the multi-lingual words do not practically share the same embedding space since each word has its own representation.",2.1 Challenges,[0],[0]
"This does not pose a problem for languages with sufficiently large amount of data, yet it is a major limitation for extremely low resource languages since most of the vocabulary items will not have enough, if any, training examples to get a reliably trained models.
",2.1 Challenges,[0],[0]
"A possible solution is to share the surface form of all source languages through sharing sub-units
such as subwords (Sennrich et al., 2016b) or characters (Kim et al., 2016; Luong and Manning, 2016; Lee et al., 2017).",2.1 Challenges,[0],[0]
"However, for an arbitrary lowresource language we cannot assume significant overlap in the lexical surface forms compared to the high-resource languages.",2.1 Challenges,[0],[0]
The low-resource language may not even share the same character set as any high-resource language.,2.1 Challenges,[0],[0]
"It is crucial to create a shared semantic representation across all languages that does not rely on surface form overlap.
",2.1 Challenges,[0],[0]
Sentence-level Sharing It is also crucial for lowresource languages to share source sentence representation with other similar languages.,2.1 Challenges,[0],[0]
"For example, if a language shares syntactic order with another language it should be feasible for the lowresource language to share such representation with another high recourse language.",2.1 Challenges,[0],[0]
It is also important to utilize monolingual data to learn such representation since the low or zero resource language may have monolingual resources only.,2.1 Challenges,[0],[0]
We propose a Universal NMT system that is focused on the scenario where minimal parallel sentences are available.,3 Universal Neural Machine Translation,[0],[0]
"As shown in Fig. 2, we introduce two components to extend the conventional multi-lingual NMT system (Johnson et al., 2017):",3 Universal Neural Machine Translation,[0],[0]
"Universal Lexical Representation (ULR) and Mixture of Language Experts (MoLE) to enable both word-level and sentence-level sharing, respectively.",3 Universal Neural Machine Translation,[0],[0]
"As we highlighted above, it is not straightforward to have a universal representation for all languages.",3.1 Universal Lexical Representation (ULR),[0],[0]
"One potential approach is to use a shared source vocabulary, but this is not adequate since it assumes significant surface-form overlap in order being able to generalize between high-resource and low-resource languages.",3.1 Universal Lexical Representation (ULR),[0],[0]
"Alternatively, we could train monolingual embeddings in a shared space and use these as the input to our MT system.",3.1 Universal Lexical Representation (ULR),[0],[0]
"However, since these embeddings are trained on a monolingual objective, they will not be optimal for an NMT objective.",3.1 Universal Lexical Representation (ULR),[0],[0]
"If we simply allow them to change during NMT training, then this will not generalize to the low-resource language where many of the words are unseen in the parallel data.",3.1 Universal Lexical Representation (ULR),[0],[0]
"Therefore, our goal is to create a shared embedding space which (a) is trained towards NMT rather than a monolingual objective, (b) is not based on lexical
surface forms, and (c) will generalize from the highresource languages to the low-resource language.
",3.1 Universal Lexical Representation (ULR),[0],[0]
We propose a novel representation for multilingual embedding where each word from any language is represented as a probabilistic mixture of universal-space word embeddings.,3.1 Universal Lexical Representation (ULR),[0],[0]
"In this way, semantically similar words from different languages will naturally have similar representations.",3.1 Universal Lexical Representation (ULR),[0],[0]
"Our method achieves this utilizing a discrete (but probabilistic) “universal token space”, and then learning the embedding matrix for these universal tokens directly in our NMT training.
",3.1 Universal Lexical Representation (ULR),[0],[0]
Lexicon Mapping to the Universal Token Space We first define a discrete universal token set of size M into which all source languages will be projected.,3.1 Universal Lexical Representation (ULR),[0],[0]
"In principle, this could correspond to any human or symbolic language, but all experiments here use English as the basis for the universal token space.",3.1 Universal Lexical Representation (ULR),[0],[0]
"As shown in Figure 2, we have multiple embedding representations.",3.1 Universal Lexical Representation (ULR),[0],[0]
EQ is language-specific embedding trained on monolingual data and EK is universal tokens embedding.,3.1 Universal Lexical Representation (ULR),[0],[0]
The matrices EK and EQ are created beforehand and are not trainable during NMT training.,3.1 Universal Lexical Representation (ULR),[0],[0]
EU is the embedding matrix for these universal tokens which is learned during our NMT training.,3.1 Universal Lexical Representation (ULR),[0],[0]
"It is worth noting that shaded parts in Figure2 are trainable during NMT training process.
",3.1 Universal Lexical Representation (ULR),[0],[0]
"Therefore, each source word ex is represented as a mixture of universal tokens M of EU .
",3.1 Universal Lexical Representation (ULR),[0],[0]
"ex =
M∑
i=1
EU (ui) · q(ui|x) (4)
where EU is an NMT embedding matrix, which is learned during NMT training.
",3.1 Universal Lexical Representation (ULR),[0],[0]
The mapping q projects the multilingual words into the universal space based on their semantic similarity.,3.1 Universal Lexical Representation (ULR),[0],[0]
"That is, q(u|x) is a distribution based on the distance Ds(u, x) between u and x as:
q(ui|x) = eD(ui,x)/τ∑ uj eD(uj ,x)/τ
(5)
where τ is a temperature and D(ui, x) is a scalar score which represents the similarity between source word x and universal token ui:
D(u, x) = EK(u) ·A · EQ(x)T (6)
where EK(u) is the “key” embedding of word u, EQ(x) is the “query” embedding of source word",3.1 Universal Lexical Representation (ULR),[0],[0]
"x.
",3.1 Universal Lexical Representation (ULR),[0],[0]
"The transformation matrixA, which is initialized to the identity matrix, is learned during NMT training and shared across all languages.
",3.1 Universal Lexical Representation (ULR),[0],[0]
"This is a key-value representation, where the queries are the monolingual language-specific embedding, the keys are the universal tokens embeddings and the values are a probabilistic distribution over the universal NMT embeddings.",3.1 Universal Lexical Representation (ULR),[0],[0]
This can represent unlimited multi-lingual vocabulary that has never been observed in the parallel training data.,3.1 Universal Lexical Representation (ULR),[0],[0]
It is worth noting that the trainable transformation matrix A is added to the query matching mechanism with the main purpose to tune the similarity scores towards the translation task.,3.1 Universal Lexical Representation (ULR),[0],[0]
"A is shared across all languages and optimized discriminatively during NMT training such that the system can fine-tune the similarity score q() to be optimal for NMT.
",3.1 Universal Lexical Representation (ULR),[0],[0]
"Shared Monolingual Embeddings In general, we create one EQ matrix per source language, as well as a single EK matrix in our universal token language.",3.1 Universal Lexical Representation (ULR),[0],[0]
"For Equation 6 to make sense and generalize across language pairs, all of these embedding matrices must live in a similar semantic space.",3.1 Universal Lexical Representation (ULR),[0],[0]
"To do this, we first train off-the-shelf monolingual word embeddings in each language, and then learn one projection matrix per source language which maps the original monolingual embeddings into EK space.",3.1 Universal Lexical Representation (ULR),[0],[0]
"Typically, we need a list of source word - universal token pairs (seeds Sk) to train the projection matrix for language k. Since vectors are normalized, learning the optimal projection is equivalent to finding an orthogonal transformation Ok that makes the projected word vectors as close
as to its corresponded universal tokens:
max",3.1 Universal Lexical Representation (ULR),[0],[0]
"Ok
∑
(x̃,ỹ)∈Sk
( EQk(x̃) ·Ok ) · EK(ỹ)T
s.t. OTk",3.1 Universal Lexical Representation (ULR),[0],[0]
"Ok = I, k = 1, ...,K (7)
which can be solved by SVD decomposition based on the seeds (Smith et al., 2017).",3.1 Universal Lexical Representation (ULR),[0],[0]
"In this paper, we chose to use a short list of seeds from automatic word-alignment of parallel sentences to learn the projection.",3.1 Universal Lexical Representation (ULR),[0],[0]
"However, recent efforts (Artetxe et al., 2017; Conneau et al., 2018) also showed that it is possible to learn the transformation without any seeds, which makes it feasible for our proposed method to be utilized in purely zero parallel resource cases.
",3.1 Universal Lexical Representation (ULR),[0],[0]
"It is worth noting that Ok is a language-specific matrix which maps the monolingual embeddings of each source language into a similar semantic space as the universal token language.
",3.1 Universal Lexical Representation (ULR),[0],[0]
Interpolated Embeddings Certain lexical categories (e.g. function words) are poorly captured by Equation 4.,3.1 Universal Lexical Representation (ULR),[0],[0]
"Luckily, function words often have very high frequency, and can be estimated robustly from even a tiny amount of data.",3.1 Universal Lexical Representation (ULR),[0],[0]
"This motivates an interpolated ex where embeddings for very frequent words are optimized directly and not through the universal tokens:
α(x)EI(x) + β(x) M∑
i=1
EU (ui) · q(ui|x) (8)
Where EI(x) is a language-specific embedding of word x which is optimized during NMT training.",3.1 Universal Lexical Representation (ULR),[0],[0]
"In general, we set α(x) to 1.0 for the top k most frequent words in each language, and 0.0 otherwise,
where k is set to 500 in this work.",3.1 Universal Lexical Representation (ULR),[0],[0]
"It is worth noting that we do not use an absolute frequency cutoff because this would cause a mismatch between highresource and low-resource languages, which we want to avoid.",3.1 Universal Lexical Representation (ULR),[0],[0]
"We keep β(x) fixed to 1.0.
",3.1 Universal Lexical Representation (ULR),[0],[0]
"An Example To give a concrete example, imagine that our target language is English (En), our high-resource auxiliary source languages are Spanish (Es) and French (Fr), and our low-resource source language is Romanian (Ro).",3.1 Universal Lexical Representation (ULR),[0],[0]
En is also used for the universal token set.,3.1 Universal Lexical Representation (ULR),[0],[0]
"We assume to have 10M+ parallel Es-En and Fr-En, and a few thousand in Ro-En.",3.1 Universal Lexical Representation (ULR),[0],[0]
"We also have millions of monolingual sentences in each language.
",3.1 Universal Lexical Representation (ULR),[0],[0]
We first train word2vec embeddings on monolingual corpora from each of the four languages.,3.1 Universal Lexical Representation (ULR),[0],[0]
"We next align the Es-En, Fr-En, and Ro-En parallel corpora and extract a seed dictionary of a few hundred words per language, e.g., gato → cat, chien → dog.",3.1 Universal Lexical Representation (ULR),[0],[0]
"We then learn three matrices O1, O2, O3 to project the Es, Fr and Ro embeddings (EQ1 , EQ2 , EQ3), into En (EK) based on these seed dictionaries.",3.1 Universal Lexical Representation (ULR),[0],[0]
"At this point, Equation 5 should produce reasonable alignments between the source languages and En, e.g., q(horse|magar) = 0.5, q(donkey|magar) = 0.3, q(cow|magar) = 0.2, where magar is the Ro word for donkey.",3.1 Universal Lexical Representation (ULR),[0],[0]
As we paved the road for having a universal embedding representation; it is crucial to have a languagesensitive module for the encoder that would help in modeling various language structures which may vary between different languages.,3.2 Mixture of Language Experts (MoLE),[0],[0]
We propose a Mixture of Language Experts (MoLE) to model the sentence-level universal encoder.,3.2 Mixture of Language Experts (MoLE),[0],[0]
"As shown in Fig. 2, an additional module of mixture of experts is used after the last layer of the encoder.",3.2 Mixture of Language Experts (MoLE),[0],[0]
"Similar to (Shazeer et al., 2017), we have a set of expert networks and a gating network to control the weight of each expert.",3.2 Mixture of Language Experts (MoLE),[0],[0]
"More precisely, we have a set of expert networks as f1(h), ..., fK(h) where for each expert, a two-layer feed-forward network which reads the output hidden states h of the encoder is utilized.",3.2 Mixture of Language Experts (MoLE),[0],[0]
"The output of the MoLE module h′ will be a weighted sum of these experts to replace the encoder’s representation:
h′ = K∑
k=1
fk(h) ·",3.2 Mixture of Language Experts (MoLE),[0],[0]
"softmax(g(h))k, (9)
where an one-layer feed-forward network g(h) is used as a gate to compute scores for all the experts.
",3.2 Mixture of Language Experts (MoLE),[0],[0]
"In our case, we create one expert per auxiliary language.",3.2 Mixture of Language Experts (MoLE),[0],[0]
"In other words, we train to only use expert fi when training on a parallel sentence from auxiliary language i. Assume the language 1...K− 1 are the auxiliary languages.",3.2 Mixture of Language Experts (MoLE),[0],[0]
"That is, we have a multi-task objective as:
Lgate = K−1∑
k=1
Nk∑
n=1
log [softmax (g(h))k] (10)
",3.2 Mixture of Language Experts (MoLE),[0],[0]
We do not update the MoLE module for training on a sentence from the low-resource language.,3.2 Mixture of Language Experts (MoLE),[0],[0]
"Intuitively, this allows us to represent each token in the low-resource language as a context-dependent mixture of the auxiliary language experts.",3.2 Mixture of Language Experts (MoLE),[0],[0]
We extensively study the effectiveness of the proposed methods by evaluating on three “almost-zeroresource” language pairs with variant auxiliary languages.,4 Experiments,[0],[0]
The vanilla single-source NMT and the multi-lingual NMT models are used as baselines.,4 Experiments,[0],[0]
Dataset We empirically evaluate the proposed Universal NMT system on 3 languages – Romanian (Ro) / Latvian (Lv) / Korean (Ko) – translating to English (En) in near zero-resource settings.,4.1 Settings,[0],[0]
"To achieve this, single or multiple auxiliary languages from Czech (Cs), German (De), Greek (El), Spanish (Es), Finnish (Fi), French (Fr), Italian (It), Portuguese (Pt) and Russian (Ru) are jointly trained.",4.1 Settings,[0],[0]
"The detailed statistics and sources of the available parallel resource can be found in Table 1, where we further down-sample the corpora for the targeted languages to simulate zero-resource.
",4.1 Settings,[0],[0]
"It also requires additional large amount of monolingual data to obtain the word embeddings for each language, where we use the latest Wikipedia dumps 5 for all the languages.",4.1 Settings,[0],[0]
"Typically, the monolingual corpora are much larger than the parallel corpora.",4.1 Settings,[0],[0]
"For validation and testing, the standard validation and testing sets are utilized for each targeted language.
1http://www.statmt.org/wmt16/translation-task.html 2https://sites.google.com/site/koreanparalleldata/ 3http://www.statmt.org/europarl/ 4http://opus.lingfil.uu.se/MultiUN.php (subset) 5https://dumps.wikimedia.org/
Preprocessing All the data (parallel and monolingual) have been tokenized and segmented into subword symbols using byte-pair encoding (BPE) (Sennrich et al., 2016b).",4.1 Settings,[0],[0]
We use sentences of length up to 50 subword symbols for all languages.,4.1 Settings,[0],[0]
"For each language, a maximum number of 40, 000 BPE operations are learned and applied to restrict the size of the vocabulary.",4.1 Settings,[0],[0]
"We concatenate the vocabularies of all source languages in the multilingual setting where special a “language marker "" have been appended to each word so that there will be no embedding sharing on the surface form.",4.1 Settings,[0],[0]
"Thus, we avoid sharing the representation of words that have similar surface forms though with different meaning in various languages.
",4.1 Settings,[0],[0]
Architecture We implement an attention-based neural machine translation model which consists of a one-layer bidirectional RNN encoder and a two-layer attention-based RNN decoder.,4.1 Settings,[0],[0]
"All RNNs have 512 LSTM units (Hochreiter and Schmidhuber, 1997).",4.1 Settings,[0],[0]
Both the dimensions of the source and target embedding vectors are set to 512.,4.1 Settings,[0],[0]
The dimensionality of universal embeddings is also the same.,4.1 Settings,[0],[0]
"For a fair comparison, the same architecture is also utilized for training both the vanilla and multilingual NMT systems.",4.1 Settings,[0],[0]
"For multilingual experiments, 1 ∼ 5 auxiliary languages are used.",4.1 Settings,[0],[0]
"When training with the universal tokens, the temperature τ",4.1 Settings,[0],[0]
"(in Eq. 6) is fixed to 0.05 for all the experiments.
",4.1 Settings,[0],[0]
"Learning All the models are trained to maximize the log-likelihood using Adam (Kingma and Ba, 2014) optimizer for 1 million steps on the mixed dataset with a batch size of 128.",4.1 Settings,[0],[0]
The dropout rates for both the encoder and the decoder is set to 0.4.,4.1 Settings,[0],[0]
We have open-sourced an implementation of the proposed model.,4.1 Settings,[0],[0]
6,4.1 Settings,[0],[0]
"We utilize back-translation (BT) (Sennrich et al., 2016a) to encourage the model to use more information of the zero-resource languages.",4.2 Back-Translation,[0],[0]
"More concretely, we build the synthetic parallel corpus
6https://github.com/MultiPath/NANMT/tree/universal_translation
by translating on monolingual data7 with a trained translation system and use it to train a backward direction translation model.",4.2 Back-Translation,[0],[0]
"Once trained, the same operation can be used on the forward direction.",4.2 Back-Translation,[0],[0]
"Generally, BT is difficult to apply for zero resource setting since it requires a reasonably good translation system to generate good quality synthetic parallel data.",4.2 Back-Translation,[0],[0]
Such a system may not be feasible with tiny or zero parallel data.,4.2 Back-Translation,[0],[0]
"However, it is possible to start with a trained multi-NMT model.",4.2 Back-Translation,[0],[0]
"Training Monolingual Embeddings We train the monolingual embeddings using fastText8 (Bojanowski et al., 2017) over the Wikipedia corpora of all the languages.",4.3 Preliminary Experiments,[0],[0]
"The vectors are set to 300 dimensions, trained using the default setting of skip-gram .",4.3 Preliminary Experiments,[0],[0]
"All the vectors are normalized to norm 1.
",4.3 Preliminary Experiments,[0],[0]
Pre-projection,4.3 Preliminary Experiments,[0],[0]
"In this paper, the pre-projection requires initial word alignments (seeds) between words of each source language and the universal tokens.",4.3 Preliminary Experiments,[0],[0]
"More precisely, for the experiments of Ro/Ko/Lv-En, we use the target language (En) as the universal tokens; fast_align9 is used to automatically collect the aligned words between the source languages and English.",4.3 Preliminary Experiments,[0],[0]
We show our main results of multiple source languages to English with different auxiliary languages in Table 2.,5 Results,[0],[0]
"To have a fair comparison, we use only 6k sentences corpus for both Ro and Lv with all the settings and 10k for Ko.",5 Results,[0],[0]
"It is obvious that applying both the universal tokens and mixture of experts modules improve the overall translation quality for all the language pairs and the improvements are additive.
",5 Results,[0],[0]
"To examine the influence of auxiliary languages, we tested four sets of different combinations of auxiliary languages for Ro-En and two sets for Lv-En.
7We used News Crawl provided by WMT16 for Ro-En.",5 Results,[0],[0]
"8https://github.com/facebookresearch/fastText 9https://github.com/clab/fast_align
Figure 4: BLEU score vs unknown tokens
It shows that Ro performs best when the auxiliary languages are all selected in the same family (Ro, Es, Fr, It and Pt are all from the Romance family of European languages) which makes sense as more knowledge can be shared across the same family.",5 Results,[0],[0]
"Similarly, for the experiment of Lv-En, improvements are also observed when adding Ru as additional auxiliary language as Lv and Ru share many similarities because of the geo-graphical influence even though they don’t share the same alphabet.
",5 Results,[0],[0]
We also tested a set of Ko-En experiments to examine the generalization capability of our approach on non-European languages while using languages of Romance family as auxiliary languages.,5 Results,[0],[0]
"Although the BLEU score is relatively low, the proposed methods can consistently help translating less-related low-resource languages.",5 Results,[0],[0]
It is more reasonable to have similar languages as auxiliary languages.,5 Results,[0],[0]
"We perform thorough experiments to examine effectiveness of the proposed method; we do ablation study on Ro-En where all the models are trained
Models BLEU Vanilla 1.21 Multi-NMT 14.94 Closest Uni-Token Only 5.83 Multi-NMT + ULR +",5.1 Ablation Study,[0],[0]
"(A=I) 18.61 Multi-NMT + ULR 20.01 Multi-NMT + BT 17.91 Multi-NMT + ULR + BT 22.35 Multi-NMT + ULR + MoLE 20.51 Multi-NMT + ULR + MoLE + BT 22.92 Full data (612k) NMT 28.34
Table 3:",5.1 Ablation Study,[0],[0]
"BLEU scores evaluated on test set (6k), compared with ULR and MoLE.",5.1 Ablation Study,[0],[0]
"“vanilla"" is the standard NMT system trained only on Ro-En training set
based on the same Ro-En corpus with 6k sentences.",5.1 Ablation Study,[0],[0]
"As shown in Table 3, it is obvious that 6k sentences of parallel corpora completely fails to train a vanilla NMT model.",5.1 Ablation Study,[0],[0]
"Using Multi-NMT with the assistance of 7.8M auxiliary language sentence pairs, Ro-En translation performance gets a substantial improvement which, however, is still limited to be usable.",5.1 Ablation Study,[0],[0]
"By contrast, the proposed ULR boosts the Multi-NMT significantly with +5.07 BLEU, which is further boosted to +7.98 BLEU when incorporating sentence-level information using both MoLE and BT.",5.1 Ablation Study,[0],[0]
"Furthermore, it is also shown that ULR works better when a trainable transformation matrix A is used (4th vs 5th row in the table).",5.1 Ablation Study,[0],[0]
"Note that, although still 5 ∼ 6 BLEU scores lower than the full data (×100 large) model.
",5.1 Ablation Study,[0],[0]
"We also measure the translation quality of simply training the vanilla system while replacing each token of the Ro sentence with its closet universal token in the projected embedding space, considering we are using the target languages (En) as
the universal tokens.",5.1 Ablation Study,[0],[0]
"Although the performance is much worse than the baseline Multi-NMT, it still outperforms the vanilla model which implies the effectiveness of the embedding alignments.
",5.1 Ablation Study,[0],[0]
Monolingual Data In Table.,5.1 Ablation Study,[0],[0]
"3, we also showed the performance when incorporating the monolingual Ro corpora to help the UniNMT training in both cases with and without ULR.",5.1 Ablation Study,[0],[0]
"The backtranslation improves in both cases, while the ULR still obtains the best score which indicates that the gains achieved are additive.
",5.1 Ablation Study,[0],[0]
Corpus Size,5.1 Ablation Study,[0],[0]
"As shown in Fig. 3, we also evaluated our methods with varied sizes – 0k10, 6k, 60k and 600k – of the Ro-En corpus.",5.1 Ablation Study,[0],[0]
The vanilla NMT and the multi-lingual NMT are used as baselines.,5.1 Ablation Study,[0],[0]
It is clear in all cases that the performance gets better when the training corpus is larger.,5.1 Ablation Study,[0],[0]
"However, the multilingual with ULR works much better with a small amount of training examples.",5.1 Ablation Study,[0],[0]
"Note that, the usage of ULR universal tokens also enables us to directly work on a “pure zero"" resource translation with a shared multilingual NMT model.
",5.1 Ablation Study,[0],[0]
Unknown Tokens One explanation on how ULR help the translation for almost zero resource languages is it greatly cancel out the effects of missing tokens that would cause out-of-vocabularies during testing.,5.1 Ablation Study,[0],[0]
"As in Fig. 4, the translation performance heavily drops when it has more “unknown"" which cannot be found in the given 6k training set, especially for the typical multilingual NMT.",5.1 Ablation Study,[0],[0]
"Instead, these “unknown"" tokens will naturally have their embeddings based on ULR projected universal tokens even if we never saw them in the training set.",5.1 Ablation Study,[0],[0]
"When we apply back-translation over the monolingual data, the performance further improves which can almost catch up with the model trained with 60k data.",5.1 Ablation Study,[0],[0]
Examples Figure 5 shows some cherry-picked examples for Ro-En.,5.2 Qualitative Analysis,[0],[0]
Example (a) shows how the lexical selection get enriched when introducing ULR (Lex-6K) as well as when adding Back Translation (Lex-6K-BT).,5.2 Qualitative Analysis,[0],[0]
"Example (b) shows the effect of using romance vs non-romance languages as the supporting languages for Ro. Example (c) shows the importance of having a trainable A as have
10For 0k experiments, we used the pre-projection learned from 6k data.",5.2 Qualitative Analysis,[0],[0]
"It is also possible to use unsupervised learned dictionary.
been discussed; without trainable A the model confuses ""india"" and ""china"" as they may have close representation in the mono-lingual embeddings.
",5.2 Qualitative Analysis,[0],[0]
Visualization of MoLE Figure 6 shows the activations along with the same source sentence with various auxiliary languages.,5.2 Qualitative Analysis,[0],[0]
It is clear that MoLE is effectively switching between the experts when dealing with zero-resource language words.,5.2 Qualitative Analysis,[0],[0]
"For this particular example of Ro, we can see that the system is utilizing various auxiliary languages based on their relatedness to the source language.",5.2 Qualitative Analysis,[0],[0]
We can approximately rank the relatedness based of the influence of each language.,5.2 Qualitative Analysis,[0],[0]
"For instance, the influence can be approximately ranked as Es ≈",5.2 Qualitative Analysis,[0],[0]
Pt >,5.2 Qualitative Analysis,[0],[0]
Fr ≈,5.2 Qualitative Analysis,[0],[0]
It >,5.2 Qualitative Analysis,[0],[0]
"Cs ≈ El > De > Fi, which is interestingly close to the grammatical relatedness of Ro to these languages.",5.2 Qualitative Analysis,[0],[0]
"On the other hand, Cs has a strong influence although it does not fall in the same language family with Ro, we think this is due to the geo-graphical influence between the two languages since Cs and Ro share similar phrases and expressions.",5.2 Qualitative Analysis,[0],[0]
This shows that MoLE learns to utilize resources from similar languages.,5.2 Qualitative Analysis,[0],[0]
"All the described experiments above had the low resource languages jointly trained with all the auxiliary high-resource languages, where the training of the large amount of high-resource languages can be seen as a sort of regularization.",5.3 Fine-tuning a Pre-trained Model,[0],[0]
"It is also common to train a model on high-resource languages first, and then fine-tune the model on a small resource language similar to transfer learning approaches (Zoph et al., 2016).",5.3 Fine-tuning a Pre-trained Model,[0],[0]
"However, it is not trivial to effectively fine-tune NMT models on extremely low resource data since the models easily over-fit due to overparameterization of the neural networks.
",5.3 Fine-tuning a Pre-trained Model,[0],[0]
"In this experiment, we have explored the finetuning tasks using our approach.",5.3 Fine-tuning a Pre-trained Model,[0],[0]
"First, we train a Multi-NMT model (with ULR) on {Es, Fr, It, Pt}-En languages only to create a zero-shot setting for Ro-En translation.",5.3 Fine-tuning a Pre-trained Model,[0],[0]
"Then, we start fine-tuning the model with 6k parallel corpora of Ro-En, with and without ULR.",5.3 Fine-tuning a Pre-trained Model,[0],[0]
"As shown in Fig. 7, both models improve a lot over the baseline.",5.3 Fine-tuning a Pre-trained Model,[0],[0]
"With the help of ULR, we can achieve a BLEU score of around 10.7 (also shown in Fig. 3) for Ro-En translation with “zero-resource"" translation.",5.3 Fine-tuning a Pre-trained Model,[0],[0]
The BLEU score can further improve to almost 20 BLEU after 3 epochs of training on 6k sentences using ULR.,5.3 Fine-tuning a Pre-trained Model,[0],[0]
"This is almost 6 BLEU higher than the best score of the
baseline.",5.3 Fine-tuning a Pre-trained Model,[0],[0]
It is worth noting that this fine-tuning is a very efficient process since it only takes less than 2 minutes to train for 3 epochs over such tiny amount of data.,5.3 Fine-tuning a Pre-trained Model,[0],[0]
This is very appealing for practical applications where adapting a per-trained system on-line is a big advantage.,5.3 Fine-tuning a Pre-trained Model,[0],[0]
"As a future work, we will further investigate a better fine-tuning strategy such as meta-learning (Finn et al., 2017) using ULR.",5.3 Fine-tuning a Pre-trained Model,[0],[0]
"Multi-lingual NMT has been extensively studied in a number of papers such as Lee et al. (2017), Johnson et al. (2017), Zoph et al. (2016) and Firat et al.
(2016).",6 Related Work,[0],[0]
"As we discussed, these approaches have significant limitations with zero-resource cases.",6 Related Work,[0],[0]
"Johnson et al. (2017) is more closely related to our current approach, our work is extending it to overcome the limitations with very low-resource languages and enable sharing of lexical and sentence representation across multiple languages.
",6 Related Work,[0],[0]
Two recent related works are targeting the same problem of minimally supervised or totally unsupervised NMT.,6 Related Work,[0],[0]
Artetxe et al. (2018) proposed a totally unsupervised approach depending on multi-lingual embedding similar to ours and duallearning and reconstruction techniques to train the model from mono-lingual data only.,6 Related Work,[0],[0]
Lample et al. (2018) also proposed a quite similar approach while utilizing adversarial learning.,6 Related Work,[0],[0]
"In this paper, we propose a new universal machine translation approach that enables sharing resources between high resource languages and extremely low resource languages.",7 Conclusion,[0],[0]
"Our approach is able to achieve 23 BLEU on Romanian-English WMT2016 using a tiny parallel corpus of 6k sentences, compared to the 18 BLEU of strong multilingual baseline system.",7 Conclusion,[0],[0]
"In this paper, we propose a new universal machine translation approach focusing on languages with a limited amount of parallel data.",abstractText,[0],[0]
Our proposed approach utilizes a transfer-learning approach to share lexical and sentence level representations across multiple source languages into one target language.,abstractText,[0],[0]
The lexical part is shared through a Universal Lexical Representation to support multilingual word-level sharing.,abstractText,[0],[0]
The sentencelevel sharing is represented by a model of experts from all source languages that share the source encoders with all other languages.,abstractText,[0],[0]
This enables the low-resource language to utilize the lexical and sentence representations of the higher resource languages.,abstractText,[0],[0]
"Our approach is able to achieve 23 BLEU on RomanianEnglish WMT2016 using a tiny parallel corpus of 6k sentences, compared to the 18 BLEU of strong baseline system which uses multilingual training and back-translation.",abstractText,[0],[0]
"Furthermore, we show that the proposed approach can achieve almost 20 BLEU on the same dataset through fine-tuning a pre-trained multi-lingual system in a zero-shot setting.",abstractText,[0],[0]
Universal Neural Machine Translation for Extremely Low Resource Languages,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 979–988 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
979",text,[0],[0]
Sentiment-to-sentiment “translation” requires the system to change the underlying sentiment of a sentence while preserving its non-emotional semantic content as much as possible.,1 Introduction,[0],[0]
"It can be regarded as a special style transfer task that is important in Natural Language Processing (NLP) (Hu et al., 2017; Shen et al., 2017; Fu et al., 2018).",1 Introduction,[0],[0]
"It has broad applications, including review sentiment transformation, news rewriting, etc.",1 Introduction,[0],[0]
"Yet the lack of parallel training data poses a great obstacle to a satisfactory performance.
",1 Introduction,[0],[0]
"Recently, several related studies for language style transfer (Hu et al., 2017; Shen et al., 2017) have been proposed.",1 Introduction,[0],[0]
"However, when applied
∗Equal Contribution.",1 Introduction,[0],[0]
"1The released code can be found in
https://github.com/lancopku/unpaired-sentiment-translation
to the sentiment-to-sentiment “translation” task, most existing studies only change the underlying sentiment and fail in keeping the semantic content.",1 Introduction,[0],[0]
"For example, given “The food is delicious” as the source input, the model generates “What a bad movie” as the output.",1 Introduction,[0],[0]
"Although the sentiment is successfully transformed from positive to negative, the output text focuses on a different topic.",1 Introduction,[0],[0]
"The reason is that these methods attempt to implicitly separate the emotional information from the semantic information in the same dense hidden vector, where all information is mixed together in an uninterpretable way.",1 Introduction,[0],[0]
"Due to the lack of supervised parallel data, it is hard to only modify the underlying sentiment without any loss of the nonemotional semantic information.
",1 Introduction,[0],[0]
"To tackle the problem of lacking parallel data, we propose a cycled reinforcement learning approach that contains two parts: a neutralization module and an emotionalization module.",1 Introduction,[0],[0]
The neutralization module is responsible for extracting non-emotional semantic information by explicitly filtering out emotional words.,1 Introduction,[0],[0]
"The advantage is that only emotional words are removed, which does not affect the preservation of non-emotional words.",1 Introduction,[0],[0]
"The emotionalization module is responsible for adding sentiment to the neutralized semantic content for sentiment-to-sentiment translation.
",1 Introduction,[0],[0]
"In cycled training, given an emotional sentence with sentiment s, we first neutralize it to the nonemotional semantic content, and then force the emotionalization module to reconstruct the original sentence by adding the sentiment s. Therefore, the emotionalization module is taught to add sentiment to the semantic context in a supervised way.",1 Introduction,[0],[0]
"By adding opposite sentiment, we can achieve the goal of sentiment-to-sentiment translation.",1 Introduction,[0],[0]
"Because of the discrete choice of neutral words, the gradient is no longer differentiable over the neutralization module.",1 Introduction,[0],[0]
"Thus, we use policy gradient,
one of the reinforcement learning methods, to reward the output of the neutralization module based on the feedback from the emotionalization module.",1 Introduction,[0],[0]
We add different sentiment to the semantic content and use the quality of the generated text as reward.,1 Introduction,[0],[0]
The quality is evaluated by two useful metrics: one for identifying whether the generated text matches the target sentiment; one for evaluating the content preservation performance.,1 Introduction,[0],[0]
The reward guides the neutralization module to better identify non-emotional words.,1 Introduction,[0],[0]
"In return, the improved neutralization module further enhances the emotionalization module.
",1 Introduction,[0],[0]
"Our contributions are concluded as follows:
• For sentiment-to-sentiment translation, we propose a cycled reinforcement learning approach.",1 Introduction,[0],[0]
"It enables training with unpaired data, in which only reviews and sentiment labels are available.
",1 Introduction,[0],[0]
"• Our approach tackles the bottleneck of keeping semantic information by explicitly separating sentiment information from semantic content.
",1 Introduction,[0],[0]
"• Experimental results show that our approach significantly outperforms the state-of-the-art systems, especially in content preservation.",1 Introduction,[0],[0]
"Style transfer in computer vision has been studied (Johnson et al., 2016; Gatys et al., 2016; Liao et al., 2017; Li et al., 2017; Zhu et al., 2017).",2 Related Work,[0],[0]
"The main idea is to learn the mapping between two image domains by capturing shared representations or correspondences of higher-level structures.
",2 Related Work,[0],[0]
There have been some studies on unpaired language style transfer recently.,2 Related Work,[0],[0]
Hu et al. (2017) propose a new neural generative model that combines variational auto-encoders (VAEs) and holistic attribute discriminators for effective imposition of style semantic structures.,2 Related Work,[0],[0]
Fu et al. (2018) propose to use an adversarial network to make sure that the input content does not have style information.,2 Related Work,[0],[0]
Shen et al. (2017) focus on separating the underlying content from style information.,2 Related Work,[0],[0]
They learn an encoder that maps the original sentence to style-independent content and a style-dependent decoder for rendering.,2 Related Work,[0],[0]
"However, their evaluations only consider the transferred style accuracy.",2 Related Work,[0],[0]
We argue that content preservation is also an indispensable evaluation metric.,2 Related Work,[0],[0]
"However, when
applied to the sentiment-to-sentiment translation task, the previously mentioned models share the same problem.",2 Related Work,[0],[0]
"They have the poor preservation of non-emotional semantic content.
",2 Related Work,[0],[0]
"In this paper, we propose a cycled reinforcement learning method to improve sentiment-tosentiment translation in the absence of parallel data.",2 Related Work,[0],[0]
The key idea is to build supervised training pairs by reconstructing the original sentence.,2 Related Work,[0],[0]
"A related study is “back reconstruction” in machine translation (He et al., 2016; Tu et al., 2017).",2 Related Work,[0],[0]
"They couple two inverse tasks: one is for translating a sentence in language A to a sentence in language B; the other is for translating a sentence in language B to a sentence in language A. Different from the previous work, we do not introduce the inverse task, but use collaboration between the neutralization module and the emotionalization module.
",2 Related Work,[0],[0]
"Sentiment analysis is also related to our work (Socher et al., 2011; Pontiki et al., 2015; Rosenthal et al., 2017; Chen et al., 2017; Ma et al., 2017, 2018b).",2 Related Work,[0],[0]
"The task usually involves detecting whether a piece of text expresses positive, negative, or neutral sentiment.",2 Related Work,[0],[0]
The sentiment can be general or about a specific topic.,2 Related Work,[0],[0]
"In this section, we introduce our proposed method.",3 Cycled Reinforcement Learning for Unpaired Sentiment-to-Sentiment Translation,[0],[0]
An overview is presented in Section 3.1.,3 Cycled Reinforcement Learning for Unpaired Sentiment-to-Sentiment Translation,[0],[0]
The details of the neutralization module and the emotionalization module are shown in Section 3.2 and Section 3.3.,3 Cycled Reinforcement Learning for Unpaired Sentiment-to-Sentiment Translation,[0],[0]
The cycled reinforcement learning mechanism is introduced in Section 3.4.,3 Cycled Reinforcement Learning for Unpaired Sentiment-to-Sentiment Translation,[0],[0]
"The proposed approach contains two modules: a neutralization module and an emotionalization module, as shown in Figure 1.",3.1 Overview,[0],[0]
"The neutralization module first extracts non-emotional semantic content, and then the emotionalization module attaches sentiment to the semantic content.",3.1 Overview,[0],[0]
Two modules are trained by the proposed cycled reinforcement learning method.,3.1 Overview,[0],[0]
The proposed method requires the two modules to have initial learning ability.,3.1 Overview,[0],[0]
"Therefore, we propose a novel pre-training method, which uses a self-attention based sentiment classifier (SASC).",3.1 Overview,[0],[0]
A sketch of cycled reinforcement learning is shown in Algorithm 1.,3.1 Overview,[0],[0]
"The
details are introduced as follows.",3.1 Overview,[0],[0]
The neutralization module Nθ is used for explicitly filtering out emotional information.,3.2 Neutralization Module,[0],[0]
"In this paper, we consider this process as an extraction problem.",3.2 Neutralization Module,[0],[0]
The neutralization module first identifies non-emotional words and then feeds them into the emotionalization module.,3.2 Neutralization Module,[0],[0]
We use a single Longshort Term Memory Network (LSTM) to generate the probability of being neutral or being polar for every word in a sentence.,3.2 Neutralization Module,[0],[0]
Given an emotional input sequence x =,3.2 Neutralization Module,[0],[0]
"(x1, x2, . . .",3.2 Neutralization Module,[0],[0]
", xT )",3.2 Neutralization Module,[0],[0]
"of T words from Γ, the vocabulary of words, this module is responsible for producing a neutralized sequence.
",3.2 Neutralization Module,[0],[0]
"Since cycled reinforcement learning requires the modules with initial learning ability, we propose a novel pre-training method to teach the neutralization module to identify non-emotional words.",3.2 Neutralization Module,[0],[0]
We construct a self-attention based sentiment classifier and use the learned attention weight as the supervisory signal.,3.2 Neutralization Module,[0],[0]
"The motivation comes from the fact that, in a well-trained sentiment classification model, the attention weight reflects the sentiment contribution of each word to
Algorithm 1 The cycled reinforcement learning method for training the neutralization module Nθ and the emotionalization module Eφ. 1: Initialize the neutralization module Nθ , the emotional-
ization module Eφ with random weights θ, φ 2: Pre-train Nθ using MLE based on Eq.",3.2 Neutralization Module,[0],[0]
"6 3: Pre-train Eφ using MLE based on Eq. 7 4: for each iteration i = 1, 2, ...,M do 5:",3.2 Neutralization Module,[0],[0]
"Sample a sequence x with sentiment s from X 6: Generate a neutralized sequence x̂ based on Nθ 7: Given x̂ and s, generate an output based on Eφ 8: Compute the gradient of Eφ based on Eq. 8 9: Compute the reward R1 based on Eq. 11
10: s̄ = the opposite sentiment 11: Given x̂ and s̄, generate an output based on Eφ 12: Compute the reward R2 based on Eq. 11 13: Compute the combined reward Rc based on Eq. 10 14: Compute the gradient of Nθ based on Eq. 9 15: Update model parameters θ, φ 16: end for
some extent.",3.2 Neutralization Module,[0],[0]
Emotional words tend to get higher attention weights while neutral words usually get lower weights.,3.2 Neutralization Module,[0],[0]
"The details of sentiment classifier are described as follows.
",3.2 Neutralization Module,[0],[0]
"Given an input sequence x, a sentiment label y is produced as
y = softmax(W · c) (1)
where W is a parameter.",3.2 Neutralization Module,[0],[0]
"The term c is computed as a weighted sum of hidden vectors:
c = T∑ i=0 αihi (2)
where αi is the weight of hi.",3.2 Neutralization Module,[0],[0]
The term hi is the output of LSTM at the i-th word.,3.2 Neutralization Module,[0],[0]
"The term αi is computed as
αi = exp(ei)∑T i=0 exp(ei)
(3)
where ei = f(hi,hT ) is an alignment model.",3.2 Neutralization Module,[0],[0]
"We consider the last hidden state hT as the context vector, which contains all information of an input sequence.",3.2 Neutralization Module,[0],[0]
"The term ei evaluates the contribution of each word for sentiment classification.
",3.2 Neutralization Module,[0],[0]
Our experimental results show that the proposed sentiment classifier achieves the accuracy of 89% and 90% on two datasets.,3.2 Neutralization Module,[0],[0]
"With high classification accuracy, the attention weight produced by the classifier is considered to adequately capture the sentiment information of each word.
",3.2 Neutralization Module,[0],[0]
"To extract non-emotional words based on continuous attention weights, we map attention
weights to discrete values, 0 and 1.",3.2 Neutralization Module,[0],[0]
"Since the discrete method is not the key part is this paper, we only use the following method for simplification.
",3.2 Neutralization Module,[0],[0]
"We first calculate the averaged attention value in a sentence as
ᾱ = 1
T T∑ i=0 αi (4)
where ᾱ is used as the threshold to distinguish non-emotional words from emotional words.",3.2 Neutralization Module,[0],[0]
"The discrete attention weight is calculated as
α̂i = { 1, if αi ≤ ᾱ 0, if αi > ᾱ
(5)
where α̂i is treated as the identifier.",3.2 Neutralization Module,[0],[0]
"For pre-training the neutralization module, we build the training pair of input text x and a discrete attention weight sequence α̂. The cross entropy loss is computed as
Lθ = − T∑ i=1",3.2 Neutralization Module,[0],[0]
PNθ(α̂i|xi) (6),3.2 Neutralization Module,[0],[0]
The emotionalization module Eφ is responsible for adding sentiment to the neutralized semantic content.,3.3 Emotionalization Module,[0],[0]
"In our work, we use a bi-decoder based encoder-decoder framework, which contains one encoder and two decoders.",3.3 Emotionalization Module,[0],[0]
One decoder adds the positive sentiment and the other adds the negative sentiment.,3.3 Emotionalization Module,[0],[0]
The input sentiment signal determines which decoder to use.,3.3 Emotionalization Module,[0],[0]
"Specifically, we use the seq2seq model (Sutskever et al., 2014) for implementation.",3.3 Emotionalization Module,[0],[0]
Both the encoder and decoder are LSTM networks.,3.3 Emotionalization Module,[0],[0]
The encoder learns to compress the semantic content into a dense vector.,3.3 Emotionalization Module,[0],[0]
The decoder learns to add sentiment based on the dense vector.,3.3 Emotionalization Module,[0],[0]
"Given the neutralized semantic content and the target sentiment, this module is responsible for producing an emotional sequence.
",3.3 Emotionalization Module,[0],[0]
"For pre-training the emotionalization module, we first generate a neutralized input sequence x̂ by removing emotional words identified by the proposed sentiment classifier.",3.3 Emotionalization Module,[0],[0]
"Given the training pair of a neutralized sequence x̂ and an original sentence x with sentiment s, the cross entropy loss is computed as
Lφ = − T∑ i=1",3.3 Emotionalization Module,[0],[0]
"PEφ(xi|x̂i, s) (7)
where a positive example goes through the positive decoder and a negative example goes through the negative decoder.
",3.3 Emotionalization Module,[0],[0]
"We also explore a simpler method for pretraining the emotionalization module, which uses the product between a continuous vector 1 − α and a word embedding sequence as the neutralized content where α represents an attention weight sequence.",3.3 Emotionalization Module,[0],[0]
Experimental results show that this method achieves much lower results than explicitly removing emotional words based on discrete attention weights.,3.3 Emotionalization Module,[0],[0]
"Thus, we do not choose this method in our work.",3.3 Emotionalization Module,[0],[0]
Two modules are trained by the proposed cycled method.,3.4 Cycled Reinforcement Learning,[0],[0]
The neutralization module first neutralizes an emotional input to semantic content and then the emotionalization module is forced to reconstruct the original sentence based on the source sentiment and the semantic content.,3.4 Cycled Reinforcement Learning,[0],[0]
"Therefore, the emotionalization module is taught to add sentiment to the semantic content in a supervised way.",3.4 Cycled Reinforcement Learning,[0],[0]
"Because of the discrete choice of neutral words, the loss is no longer differentiable over the neutralization module.",3.4 Cycled Reinforcement Learning,[0],[0]
"Therefore, we formulate it as a reinforcement learning problem and use policy gradient to train the neutralization module.",3.4 Cycled Reinforcement Learning,[0],[0]
"The detailed training process is shown as follows.
",3.4 Cycled Reinforcement Learning,[0],[0]
We refer the neutralization module Nθ as the first agent and the emotionalization module Eφ as the second one.,3.4 Cycled Reinforcement Learning,[0],[0]
"Given a sentence x associated with sentiment s, the term x̂ represents the middle neutralized context extracted by α̂, which is generated by PNθ(α̂|x).
",3.4 Cycled Reinforcement Learning,[0],[0]
"In cycled training, the original sentence can be viewed as the supervision for training the second agent.",3.4 Cycled Reinforcement Learning,[0],[0]
"Thus, the gradient for the second agent is
∇φJ(φ) = ∇φ log(PEφ(x|x̂, s))",3.4 Cycled Reinforcement Learning,[0],[0]
"(8)
We denote x̄ as the output generated by PEφ(x̄|x̂, s).",3.4 Cycled Reinforcement Learning,[0],[0]
"We also denote y as the output generated by PEφ(y|x̂, s̄) where s̄ represents the opposite sentiment.",3.4 Cycled Reinforcement Learning,[0],[0]
"Given x̄ and y, we first calculate rewards for training the neutralized module, R1 and R2.",3.4 Cycled Reinforcement Learning,[0],[0]
The details of calculation process will be introduced in Section 3.4.1.,3.4 Cycled Reinforcement Learning,[0],[0]
"Then, we optimize parameters through policy gradient by maximizing the expected reward to train the neutralization module.",3.4 Cycled Reinforcement Learning,[0],[0]
It guides the neutralization module to identify non-emotional words better.,3.4 Cycled Reinforcement Learning,[0],[0]
"In return, the
improved neutralization module further enhances the emotionalization module.
",3.4 Cycled Reinforcement Learning,[0],[0]
"According to the policy gradient theorem (Williams, 1992), the gradient for the first agent is
∇θJ(θ) = E[Rc · ∇θ log(PNθ(α̂|x))]",3.4 Cycled Reinforcement Learning,[0],[0]
"(9)
where Rc is calculated as
Rc = R1 +R2 (10)
",3.4 Cycled Reinforcement Learning,[0],[0]
"Based on Eq. 8 and Eq. 9, we use the sampling approach to estimate the expected reward.",3.4 Cycled Reinforcement Learning,[0],[0]
This cycled process is repeated until converge.,3.4 Cycled Reinforcement Learning,[0],[0]
"The reward consists of two parts, sentiment confidence and BLEU.",3.4.1 Reward,[0],[0]
Sentiment confidence evaluates whether the generated text matches the target sentiment.,3.4.1 Reward,[0],[0]
We use a pre-trained classifier to make the judgment.,3.4.1 Reward,[0],[0]
"Specially, we use the proposed selfattention based sentiment classifier for implementation.",3.4.1 Reward,[0],[0]
"The BLEU (Papineni et al., 2002) score is used to measure the content preservation performance.",3.4.1 Reward,[0],[0]
"Considering that the reward should encourage the model to improve both metrics, we use the harmonic mean of sentiment confidence and BLEU as reward, which is formulated as
R = (1 + β2) 2 ·BLEU ·",3.4.1 Reward,[0],[0]
"Confid
(β2 ·BLEU) +",3.4.1 Reward,[0],[0]
"Confid (11)
where β is a harmonic weight.",3.4.1 Reward,[0],[0]
"In this section, we evaluate our method on two review datasets.",4 Experiment,[0],[0]
"We first introduce the datasets, the training details, the baselines, and the evaluation metrics.",4 Experiment,[0],[0]
"Then, we compare our approach with the state-of-the-art systems.",4 Experiment,[0],[0]
"Finally, we show the experimental results and provide the detailed analysis of the key components.",4 Experiment,[0],[0]
We conduct experiments on two review datasets that contain user ratings associated with each review.,4.1 Unpaired Datasets,[0],[0]
"Following previous work (Shen et al., 2017), we consider reviews with rating above three as positive reviews and reviews below three as negative reviews.",4.1 Unpaired Datasets,[0],[0]
The positive and negative reviews are not paired.,4.1 Unpaired Datasets,[0],[0]
"Since our approach focuses on sentence-level sentiment-to-sentiment translation
where sentiment annotations are provided at the document level, we process the two datasets with the following steps.",4.1 Unpaired Datasets,[0],[0]
"First, following previous work (Shen et al., 2017), we filter out the reviews that exceed 20 words.",4.1 Unpaired Datasets,[0],[0]
"Second, we construct textsentiment pairs by extracting the first sentence in a review associated with its sentiment label, because the first sentence usually expresses the core idea.",4.1 Unpaired Datasets,[0],[0]
"Finally, we train a sentiment classifier and filter out the text-sentiment pairs with the classifier confidence below 0.8.",4.1 Unpaired Datasets,[0],[0]
"Specially, we use the proposed self-attention based sentiment classifier for implementation.",4.1 Unpaired Datasets,[0],[0]
"The details of the processed datasets are introduced as follows.
",4.1 Unpaired Datasets,[0],[0]
Yelp Review Dataset (Yelp):,4.1 Unpaired Datasets,[0],[0]
"This dataset is provided by Yelp Dataset Challenge.2 The processed Yelp dataset contains 400K, 10K, and 3K pairs for training, validation, and testing, respectively.
",4.1 Unpaired Datasets,[0],[0]
Amazon Food Review Dataset (Amazon): This dataset is provided by McAuley and Leskovec (2013).,4.1 Unpaired Datasets,[0],[0]
It consists of amounts of food reviews from Amazon.3,4.1 Unpaired Datasets,[0],[0]
"The processed Amazon dataset contains 230K, 10K, and 3K pairs for training, validation, and testing, respectively.",4.1 Unpaired Datasets,[0],[0]
We tune hyper-parameters based on the performance on the validation sets.,4.2 Training Details,[0],[0]
The self-attention based sentiment classifier is trained for 10 epochs on two datasets.,4.2 Training Details,[0],[0]
"We set β for calculating reward to 0.5, hidden size to 256, embedding size to 128, vocabulary size to 50K, learning rate to 0.6, and batch size to 64.",4.2 Training Details,[0],[0]
"We use the Adagrad (Duchi et al., 2011) optimizer.",4.2 Training Details,[0],[0]
All of the gradients are clipped when the norm exceeds 2.,4.2 Training Details,[0],[0]
"Before cycled training, the neutralization module and the emotionalization module are pre-trained for 1 and 4 epochs on the yelp dataset, for 3 and 5 epochs on the Amazon dataset.",4.2 Training Details,[0],[0]
"We compare our proposed method with the following state-of-the-art systems.
",4.3 Baselines,[0],[0]
Cross-Alignment Auto-Encoder (CAAE): This method is proposed by Shen et al. (2017).,4.3 Baselines,[0],[0]
"They propose a method that uses refined alignment of latent representations in hidden layers to
2https://www.yelp.com/dataset/ challenge
3http://amazon.com
perform style transfer.",4.3 Baselines,[0],[0]
"We treat this model as a baseline and adapt it by using the released code.
",4.3 Baselines,[0],[0]
Multi-Decoder with Adversarial Learning (MDAL):,4.3 Baselines,[0],[0]
This method is proposed by Fu et al. (2018).,4.3 Baselines,[0],[0]
They use a multi-decoder model with adversarial learning to separate style representations and content representations in hidden layers.,4.3 Baselines,[0],[0]
We adapt this model by using the released code.,4.3 Baselines,[0],[0]
"We conduct two evaluations in this work, including an automatic evaluation and a human evaluation.",4.4 Evaluation Metrics,[0],[0]
The details of evaluation metrics are shown as follows.,4.4 Evaluation Metrics,[0],[0]
We quantitatively measure sentiment transformation by evaluating the accuracy of generating designated sentiment.,4.4.1 Automatic Evaluation,[0],[0]
"For a fair comparison, we do not use the proposed sentiment classification model.",4.4.1 Automatic Evaluation,[0],[0]
"Following previous work (Shen et al., 2017; Hu et al., 2017), we instead use a stateof-the-art sentiment classifier (Vieira and Moura, 2017), called TextCNN, to automatically evaluate the transferred sentiment accuracy.",4.4.1 Automatic Evaluation,[0],[0]
TextCNN achieves the accuracy of 89% and 88% on two datasets.,4.4.1 Automatic Evaluation,[0],[0]
"Specifically, we generate sentences given sentiment s, and use the pre-trained sentiment classifier to assign sentiment labels to the generated sentences.",4.4.1 Automatic Evaluation,[0],[0]
"The accuracy is calculated as the percentage of the predictions that match the sentiment s.
To evaluate the content preservation performance, we use the BLEU score (Papineni et al., 2002) between the transferred sentence and the source sentence as an evaluation metric.",4.4.1 Automatic Evaluation,[0],[0]
"BLEU is a widely used metric for text generation tasks, such as machine translation, summarization, etc.",4.4.1 Automatic Evaluation,[0],[0]
"The metric compares the automatically produced text with the reference text by computing overlapping lexical n-gram units.
",4.4.1 Automatic Evaluation,[0],[0]
"To evaluate the overall performance, we use the geometric mean of ACC and BLEU as an evaluation metric.",4.4.1 Automatic Evaluation,[0],[0]
"The G-score is one of the most commonly used “single number” measures in Information Retrieval, Natural Language Processing, and Machine Learning.",4.4.1 Automatic Evaluation,[0],[0]
"While the quantitative evaluation provides indication of sentiment transfer quality, it can not evaluate the quality of transferred text accurately.
",4.4.2 Human Evaluation,[0],[0]
"Therefore, we also perform a human evaluation on the test set.",4.4.2 Human Evaluation,[0],[0]
We randomly choose 200 items for the human evaluation.,4.4.2 Human Evaluation,[0],[0]
Each item contains the transformed sentences generated by different systems given the same source sentence.,4.4.2 Human Evaluation,[0],[0]
The items are distributed to annotators who have no knowledge about which system the sentence is from.,4.4.2 Human Evaluation,[0],[0]
They are asked to score the transformed text in terms of sentiment and semantic similarity.,4.4.2 Human Evaluation,[0],[0]
Sentiment represents whether the sentiment of the source text is transferred correctly.,4.4.2 Human Evaluation,[0],[0]
Semantic similarity evaluates the context preservation performance.,4.4.2 Human Evaluation,[0],[0]
The score ranges from 1 to 10 (1 is very bad and 10 is very good).,4.4.2 Human Evaluation,[0],[0]
Automatic evaluation results are shown in Table 1.,4.5 Experimental Results,[0],[0]
ACC evaluates sentiment transformation.,4.5 Experimental Results,[0],[0]
BLEU evaluates semantic content preservation.,4.5 Experimental Results,[0],[0]
G-score represents the geometric mean of ACC and BLEU.,4.5 Experimental Results,[0],[0]
"CAAE and MDAL achieve much lower BLEU scores, 1.17 and 1.64 on the Yelp dataset, 0.56 and 0.27 on the Amazon dataset.",4.5 Experimental Results,[0],[0]
The low BLEU scores indicate the worrying content preservation performance to some extent.,4.5 Experimental Results,[0],[0]
"Even with the desired sentiment, the irrelevant generated text leads to worse overall performance.",4.5 Experimental Results,[0],[0]
"In general, these two systems work more like sentiment-aware language models that generate text only based on the target sentiment and neglect the source input.",4.5 Experimental Results,[0],[0]
"The main reason is that these two systems attempt to separate emotional information from non-emotional content in a hidden layer, where all information is complicatedly mixed together.",4.5 Experimental Results,[0],[0]
"It is difficult to only modify emotional information without any loss of non-emotional semantic content.
",4.5 Experimental Results,[0],[0]
"In comparison, our proposed method achieves the best overall performance on the two datasets,
demonstrating the ability of learning knowledge from unpaired data.",4.5 Experimental Results,[0],[0]
This result is attributed to the improved BLEU score.,4.5 Experimental Results,[0],[0]
The BLEU score is largely improved from 1.64 to 22.46 and from 0.56 to 14.06 on the two datasets.,4.5 Experimental Results,[0],[0]
The score improvements mainly come from the fact that we separate emotional information from semantic content by explicitly filtering out emotional words.,4.5 Experimental Results,[0],[0]
The extracted content is preserved and fed into the emotionalization module.,4.5 Experimental Results,[0],[0]
"Given the overall quality of transferred text as the reward, the neutralization module is taught to extract non-emotional semantic content better.
",4.5 Experimental Results,[0],[0]
Table 2 shows the human evaluation results.,4.5 Experimental Results,[0],[0]
It can be clearly seen that the proposed method obviously improves semantic preservation.,4.5 Experimental Results,[0],[0]
"The semantic score is increased from 3.87 to 5.08 on the Yelp dataset, and from 3.22 to 4.67 on the Amazon dataset.",4.5 Experimental Results,[0],[0]
"In general, our proposed model achieves the best overall performance.",4.5 Experimental Results,[0],[0]
"Furthermore, it also needs to be noticed that with the large improvement in content preservation, the sentiment accuracy of the proposed method is lower than that of CAAE on the two datasets.",4.5 Experimental Results,[0],[0]
"It shows that simultaneously promoting sentiment transformation and content preservation remains to be studied further.
",4.5 Experimental Results,[0],[0]
"By comparing two evaluation results, we find that there is an agreement between the human evaluation and the automatic evaluation.",4.5 Experimental Results,[0],[0]
It indicates the usefulness of automatic evaluation metrics.,4.5 Experimental Results,[0],[0]
"However, we also notice that the human evaluation has a smaller performance gap between the baselines and the proposed method than the automatic evaluation.",4.5 Experimental Results,[0],[0]
It shows the limitation of automatic metrics for giving accurate results.,4.5 Experimental Results,[0],[0]
"For evaluating sentiment transformation, even with a high accuracy, the sentiment classifier sometimes generates noisy results, especially for those neutral sentences (e.g., “I ate a cheese sandwich”).",4.5 Experimental Results,[0],[0]
"For evaluating content preservation, the BLEU score
is computed based on the percentage of overlapping n-grams between the generated text and the reference text.",4.5 Experimental Results,[0],[0]
"However, the overlapping n-grams contain not only content words but also function words, bringing the noisy results.",4.5 Experimental Results,[0],[0]
"In general, accurate automatic evaluation metrics are expected in future work.
",4.5 Experimental Results,[0],[0]
Table 3 presents the examples generated by different systems on the Yelp dataset.,4.5 Experimental Results,[0],[0]
"The two baselines change not only the polarity of examples, but also the semantic content.",4.5 Experimental Results,[0],[0]
"In comparison, our method precisely changes the sentiment of sentences (and paraphrases slightly to ensure fluency), while keeping the semantic content unchanged.",4.5 Experimental Results,[0],[0]
"In this section, we conduct a series of experiments to evaluate the contributions of our key components.",4.6 Incremental Analysis,[0],[0]
"The results are shown in Table 4.
",4.6 Incremental Analysis,[0],[0]
We treat the emotionalization module as a baseline where the input is the original emotional sentence.,4.6 Incremental Analysis,[0],[0]
The emotionalization module achieves the highest BLEU score but with much lower sentiment transformation accuracy.,4.6 Incremental Analysis,[0],[0]
"The encoding of the original sentiment leads to the emotional hidden vector that influences the decoding process and results in worse sentiment transformation performance.
",4.6 Incremental Analysis,[0],[0]
It can be seen that the method with all components achieves the best performance.,4.6 Incremental Analysis,[0],[0]
"First, we find that the method that only uses cycled reinforcement learning performs badly because it is hard to guide two randomly initialized modules to teach each other.",4.6 Incremental Analysis,[0],[0]
"Second, the pre-training method brings a slight improvement in overall performance.",4.6 Incremental Analysis,[0],[0]
The G-score is improved from 32.77 to 34.66 and from 26.46 to 27.87 on the two datasets.,4.6 Incremental Analysis,[0],[0]
The bottleneck of this method is the noisy attention weight because of the limited sentiment classification accuracy.,4.6 Incremental Analysis,[0],[0]
"Third, the method that combines cycled reinforcement learning and pre-training achieves the better performance than using one of them.",4.6 Incremental Analysis,[0],[0]
Pre-training gives the two modules initial learning ability.,4.6 Incremental Analysis,[0],[0]
Cycled training teaches the two modules to improve each other based on the feedback signals.,4.6 Incremental Analysis,[0],[0]
"Specially, the G-score is improved from 34.66 to 42.38 and from 27.87 to 31.45 on the two datasets.",4.6 Incremental Analysis,[0],[0]
"Finally, by comparing the methods with and without the neutralization module, we find that the neutralization mechanism improves a lot in sentiment transformation with a slight reduction on content preservation.",4.6 Incremental Analysis,[0],[0]
"It proves the effectiveness of explic-
itly separating sentiment information from semantic content.
",4.6 Incremental Analysis,[0],[0]
"Furthermore, to analyze the neutralization ability in the proposed method, we randomly sample several examples, as shown in Table 5.",4.6 Incremental Analysis,[0],[0]
It can be clearly seen that emotional words are removed accurately almost without loss of non-emotional information.,4.6 Incremental Analysis,[0],[0]
"Although the proposed method outperforms the state-of-the-art systems, we also observe several failure cases, such as sentiment-conflicted sentences (e.g., “Outstanding and bad service”), neutral sentences (e.g., “Our first time here”).",4.7 Error Analysis,[0],[0]
Sentiment-conflicted sentences indicate that the original sentiment is not removed completely.,4.7 Error Analysis,[0],[0]
"This problem occurs when the input contains emotional words that are unseen in the training data, or the sentiment is implicitly expressed.",4.7 Error Analysis,[0],[0]
Handling complex sentiment expressions is an important problem for future work.,4.7 Error Analysis,[0],[0]
Neutral sentences demonstrate that the decoder sometimes fails in adding the target sentiment and only generates text based on the semantic content.,4.7 Error Analysis,[0],[0]
A better sentimentaware decoder is expected to be explored in future work.,4.7 Error Analysis,[0],[0]
"In this paper, we focus on unpaired sentimentto-sentiment translation and propose a cycled reinforcement learning approach that enables training in the absence of parallel training data.",5 Conclusions and Future Work,[0],[0]
We conduct experiments on two review datasets.,5 Conclusions and Future Work,[0],[0]
"Experimental results show that our method substantially outperforms the state-of-the-art systems, especially in terms of semantic preservation.",5 Conclusions and Future Work,[0],[0]
"For future work, we would like to explore a fine-grained version of sentiment-to-sentiment translation that
not only reverses sentiment, but also changes the strength of sentiment.",5 Conclusions and Future Work,[0],[0]
"This work was supported in part by National Natural Science Foundation of China (No. 61673028), National High Technology Research and Development Program of China (863 Program, No. 2015AA015404), and the National Thousand Young Talents Program.",Acknowledgements,[0],[0]
Xu Sun is the corresponding author of this paper.,Acknowledgements,[0],[0]
The goal of sentiment-to-sentiment “translation” is to change the underlying sentiment of a sentence while keeping its content.,abstractText,[0],[0]
The main challenge is the lack of parallel data.,abstractText,[0],[0]
"To solve this problem, we propose a cycled reinforcement learning method that enables training on unpaired data by collaboration between a neutralization module and an emotionalization module.",abstractText,[0],[0]
"We evaluate our approach on two review datasets, Yelp and Amazon.",abstractText,[0],[0]
Experimental results show that our approach significantly outperforms the state-of-the-art systems.,abstractText,[0],[0]
"Especially, the proposed method substantially improves the content preservation performance.",abstractText,[0],[0]
"The BLEU score is improved from 1.64 to 22.46 and from 0.56 to 14.06 on the two datasets, respectively.1",abstractText,[0],[0]
Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach,title,[0],[0]
"Despite over 25 years of research in computational linguistics aimed at acquiring multiword lexicons using corpora statistics, and growing evidence that speakers process language primarily in terms of memorized sequences (Wray, 2008), the individual word nonetheless stubbornly remains the de facto standard processing unit for most research in modern NLP.",1 Introduction,[0],[0]
The potential of multiword knowledge to improve both the automatic processing of language as well as offer new understanding of human acquisition and usage of language is the primary motivator of this work.,1 Introduction,[0],[0]
"Here, we present an effective, expandable, and tractable new approach to comprehensive multiword lexicon acquisition.",1 Introduction,[0],[0]
"Our aim is to find a middle ground between standard MWE acquisition approaches based on association measures
(Ramisch, 2014) and more sophisticated statistical models (Newman et al., 2012) that do not scale to large corpora, the main source of the distributional information in modern NLP systems.
",1 Introduction,[0],[0]
A central challenge in building comprehensive multiword lexicons is paring down the huge space of possibilities without imposing restrictions which disregard a major portion of the multiword vocabulary of a language: allowing for diversity creates significant redundancy among statistically promising candidates.,1 Introduction,[0],[0]
"The lattice model proposed here addresses this primarily by having the candidates— contiguous and non-contiguous n-gram types— compete with each other based on subsumption and overlap relations to be selected as the best (i.e., most parsimonious) explanation for statistical irregularities.",1 Introduction,[0],[0]
"We test this approach across four large corpora in three languages, including two relatively freeword-order languages (Croatian and Japanese), and find that this approach consistency outperforms alternatives, offering scalability and many avenues for future enhancement.",1 Introduction,[0],[0]
"In this paper we will refer to the targets of our lexicon creation efforts as formulaic sequences, following the terminology of Wray (2002; 2008), wherein a formulaic sequence (FS) is defined as “a sequence, continuous or discontinuous, of words or other elements, which is, or appears to be, prefabricated: that is, stored and retrieved whole from memory at the time of use, rather than being subject to generation or analysis by the language grammar.”",2 Background and Related Work,[0],[0]
"That is, an
455
Transactions of the Association for Computational Linguistics, vol. 5, pp.",2 Background and Related Work,[0],[0]
"455–470, 2017.",2 Background and Related Work,[0],[0]
Action Editor: Noah Smith.,2 Background and Related Work,[0],[0]
"Submission batch: 1/2017; Revision batch: 5/2017; Published 11/2017.
",2 Background and Related Work,[0],[0]
c©2017 Association for Computational Linguistics.,2 Background and Related Work,[0],[0]
"Distributed under a CC-BY 4.0 license.
",2 Background and Related Work,[0],[0]
"FS shows signs of being part of a mental lexicon.1 As noted by Wray (2008), formulaic sequence theory is compatible with other highly multiword, lexicalized approaches to language structure, in particular Pattern Grammar (Hunston and Francis, ) and Construction Grammar (Goldberg, 1995); an important distinction, though, is that these sorts of theories often posit entirely abstract grammatical constructions/patterns/frames which do not fit well into the FS framework.",2 Background and Related Work,[0],[0]
"Nevertheless, since many such constructions are composed of sequences of specific words, the FS inventory of a language includes many flexible constructions (e.g., ask ∗ for) along with entirely fixed combinations (e.g., rhetorical question) not typically of interest to grammarians.",2 Background and Related Work,[0],[0]
"Note that the FS framework allows for individual morphemes to be part of a formulaic sequence, but for practical reasons we focus primarily on lemmatized words as the unit out of which FS are built.
",2 Background and Related Work,[0],[0]
"In computational linguistics, the most common term used to describe multiword lexical units is multiword expression (“MWE”: Sag et al. (2002), Baldwin and Kim (2010)), but here we wish to make a principled distinction between at least somewhat non-compositional, strongly lexicalized MWEs and FS, a near superset which includes many MWEs but also compositional linguistic formulas.",2 Background and Related Work,[0],[0]
"This distinction is not a new one; it exists, for example, in the original paper of Sag et al. (2002) in the distinction between lexicalized and institutionalized phrases, and also to some extent in the MWE annotation of Schneider et al. (2014b), who distinguish between weak (collocational)2 and strong (non-compositional) MWEs.",2 Background and Related Work,[0],[0]
"It is our contention, however, that separate, precise terminology is useful for research targeted at either class: we need not strain the concept of MWE to include items which do not require special semantics, nor are we inclined to disregard the larger formulaticity of language simply because it is not the dominant focus of MWE
1Though by this definition individuals or small groups may have their own FS, here we are only interested in FS that are shared by a recognizable language community.
",2 Background and Related Work,[0],[0]
2Here we avoid the term collocation entirely due to confusion with respect to its interpretation.,2 Background and Related Work,[0],[0]
"Though some define it similarly to our definition of FS, it can be applied to any words that show a statistical tendency to appear in the vicinity of one another for any reason: for instance, the pair of words doctor/nurse might be considered a collocation (Ramisch, 2014).
research.",2 Background and Related Work,[0],[0]
"Many MWE researchers might defensibly balk at including in their MWE lexicons and corpus annotations (English) FS such as there is something going on, it is more important than ever to ..., ... do not know what it is like to ..., there is no shortage of ..., the rise and fall of ..., now is not the time to ..., etc. as well as tens of thousands of other such phrases which, along with less compositional MWEs like be worth ...’s weight in gold, fall under the FS umbrella.",2 Background and Related Work,[0],[0]
"Another reason to introduce a different terminology is that there are classes of phrases which are typically considered MWEs that do not fit well into an FS framework, for instance novel compound nouns whose semantics are accessible by analogy (e.g., glass limb, analogous to wooden leg).",2 Background and Related Work,[0],[0]
"We also exclude from the definition of both FS and MWE those named entities which refer to people or places which are little-known and/or whose surface form appears derived (e.g., Mrs. Barbara W. Smith or Smith Garden Supplies Ltd).",2 Background and Related Work,[0],[0]
"Figure 1 shows the conception of the relationship between FS, (multiword) constructions, MWE, and (multiword) named entities that we assume for this paper.
",2 Background and Related Work,[0],[0]
"From a practical perspective, the starting point for multiword lexicon creation has typically been lexical association measures (Church and Hanks, 1990; Dunning, 1993; Schone and Jurafsky, 2001; Evert, 2004; Pecina, 2010; Araujo et al., 2011; Kulkarni and Finlayson, 2011; Ramisch, 2014).",2 Background and Related Work,[0],[0]
"When these methods are used to build a lexicon, particular binary syntactic patterns are typically chosen.",2 Background and Related Work,[0],[0]
"Only some of these measures generalize tractably beyond two words, for example PMI (Church and Hanks, 1990), i.e., the log ratio of the joint probability to the product of the marginal probabilities of the individual words.",2 Background and Related Work,[0],[0]
"Another measure which addresses sequences of longer than two words is the C-value
(Frantzi et al., 2000) which weights term frequency by the log length of the n-gram while penalizing ngrams that appear in frequent larger ones.",2 Background and Related Work,[0],[0]
"Mutual expectation (Dias et al., 1999) involves deriving a normalized statistic that reflects the extent to which a phrase resists the omission of any constituent word.",2 Background and Related Work,[0],[0]
"Similarly, the lexical predictability ratio (LPR) of Brooke et al. (2015) is an association measure applicable to any possible syntactic pattern, which is calculated by discounting syntactic predictability from the overall conditional probability for each word given the other words in the phrase.",2 Background and Related Work,[0],[0]
"Though most association measures involve only usage statistics of the phrase and its subparts, the DRUID measure (Riedl and Biemann, 2015) is an exception which uses distributional semantics around the phrase to identify how easily",2 Background and Related Work,[0],[0]
"an n-gram could be replaced by a single word.
",2 Background and Related Work,[0],[0]
Typically multiword lexicons are created by ranking n-grams according to an association measure and applying a threshold.,2 Background and Related Work,[0],[0]
"The algorithm of da Silva and Lopes (1999) is somewhat more sophisticated, in that it identifies the local maxima of association measures across subsuming n-grams within a sentence to identify MWEs of unrestricted length and syntactic composition; its effectiveness beyond noun phrases, however, seems relatively limited (Ramisch et al., 2012).",2 Background and Related Work,[0],[0]
"Brooke et al. (2014; 2015) developed a heuristic method intended for general FS extraction in larger corpora, first using conditional probabilities to do an initial (single pass) coarse-grained segmentation of the corpus, followed by a pass through the resulting vocabulary, breaking larger units into smaller ones based on a tradeoff between marginal and conditional statistics.",2 Background and Related Work,[0],[0]
"The work of Newman et al. (2012) is an example of an unsupervised approach which does not use association measures: it extends the Bayesian word segmentation approach of Goldwater et al. (2009) to multiword tokenization, applying a generative Dirichlet Process model which jointly constructs a segmentation of the corpus and a corresponding multiword vocabulary.
",2 Background and Related Work,[0],[0]
"Other research in MWEs has tended to be rather focused on particular syntactic patterns such as verbnoun combinations (Fazly et al., 2009).",2 Background and Related Work,[0],[0]
"The system of Schneider et al. (2014a) distinguishes a full range of MWE sequences in the English Web Treebank, including gapped expressions, using a supervised se-
quence tagging model.",2 Background and Related Work,[0],[0]
"Though, in theory, automatic lexical resources could be a useful addition to the Schneider et al. model, which uses only manual lexical resources, attempts to do so have achieved mixed success (Riedl and Biemann, 2016).
",2 Background and Related Work,[0],[0]
"The motivations for building lexicons of FS naturally overlap with those for MWE: models of distributional semantics, in particular, can benefit from sensitivity to multiword units (Cohen and Widdows, 2009), as can parsing (Constant and Nivre, 2016) and topic models (Lau et al., 2013).",2 Background and Related Work,[0],[0]
One major motivation for looking beyond MWEs is the ability to carry out broader linguistic analyses.,2 Background and Related Work,[0],[0]
"Within corpus linguistics, multiword sequences have been studied in the form of lexical bundles (Biber et al., 2004), which are simply n-grams that occur above a certain frequency threshold.",2 Background and Related Work,[0],[0]
"Like FS, lexical bundles generally involve larger phrasal chunks that would be missed by traditional MWE extraction, and so research in this area has tended to focus on how particular formulaic phrases (e.g., if you look at) are indicative of particular genres (e.g., university lectures).",2 Background and Related Work,[0],[0]
"Lexical bundles have been applied, in particular, to learner language: for example, Chen and Baker (2010) show that non-native student writers use a severely restricted range of lexical bundle types, and tend to overuse those types, while Granger and Bestgen (2014) investigate the role of proficiency, demonstrating that intermediate learners underuse lower-frequency bigrams and overuse high-frequency bigrams relative to advanced learners.",2 Background and Related Work,[0],[0]
"Sakaguchi et al. (2016) demonstrate that improving fluency (closely linked to the use of linguistic formulas) is more important than improving strict grammaticality with respect to native speaker judgments of non-native productions; Brooke et al. (2015) explicitly argue for FS lexicons as a way to identify, track, and improve learner proficiency.",2 Background and Related Work,[0],[0]
"Our approach to FS identification involves optimization of the total explanatory power of a lattice, where each node corresponds to an n-gram type.",3 Method,[0],[0]
The explanatory power of the whole lattice is defined simply as a product of the explainedness of the individual nodes.,3 Method,[0],[0]
Each node can be considered either “on” (is an FS) or “off” (is not an FS).,3 Method,[0],[0]
"The basis of the
calculation of explainedness is the syntax-sensitive LPR association measure of Brooke et al. (2015), but it is calculated differently depending on the on/off status of the node as well as the status of the nodes in its vicinity.",3 Method,[0],[0]
"Nodes are linked based on n-gram subsumption and corpus overlap relationships (see Figure 2), with “on” nodes typically explaining other nodes.",3 Method,[0],[0]
"Given these relationships, we iterate over the nodes and greedily optimize the on/off choice relative to explainedness in the local neighborhood of each node, until convergence.",3 Method,[0],[0]
"The first step in the process is to derive a set of ngrams and related statistics from a large, unlabeled corpus of text.",3.1 Collecting statistics,[0],[0]
"Since our primary association measure is an adaption of LPR, our approach in this section mostly follows Brooke et al. (2015) up until the last stage.",3.1 Collecting statistics,[0],[0]
"An initial requirement of any such method is an n-gram frequency threshold, which we set to 1 instance per 10 million words, following Brooke et al. (2015).3
We include gapped or non-contiguous n-grams in our analysis, in acknowledgment of the fact that many languages have MWEs where the components can be “separated”, including verb particle constructions in English (Dehé, 2002), and noun-verb idioms in Japanese (Hashimoto and Kawahara, 2008).",3.1 Collecting statistics,[0],[0]
"Having said this, there are generally strong syntactic and length restrictions on what can constitute a gap (Wasow, 2002), which we capture in the form of a language-specific POS-based regular expression (see Section 4 for details).",3.1 Collecting statistics,[0],[0]
"This greatly lowers the number of potentially gapped n-gram types, increasing precision and efficiency for negligible loss of recall.",3.1 Collecting statistics,[0],[0]
"We also exclude punctuation and lemmatize the corpus, and enforce an n-gram count threshold.",3.1 Collecting statistics,[0],[0]
"As long as the count threshold is substantially above 1, efficient extraction of all n-grams can be done iteratively: in iteration i, i-grams are filtered by the frequency threshold, and then pairs of instances of these i-grams with (i− 1) words of overlap are found, which derives a set of (i + 1)-grams
3Based on manual analysis using the MWE corpus of Schneider et al. (2014b), this achieves very good (over 90%) type-level MWE coverage using the frequency filtered n-gram statistics from the ICWSM blog corpus (see Section 4) after filtering out proper names.
which necessarily includes all those over the frequency threshold.
",3.1 Collecting statistics,[0],[0]
"Once a set of relevant n-grams is identified and counted, other statistics required to calculate the Lexical Predictability Ratio (“LPR”) for each word in the n-gram are collected.",3.1 Collecting statistics,[0],[0]
"LPR is a measure of how predictable a word is in a lexical context, as compared to how predictable it is given only syntactic context (over the same span of words).",3.1 Collecting statistics,[0],[0]
"Formally, the LPR for word wi in the context of a word sequence w1, ..., wi, ..., wn with POS tag sequence t1, ..., tn is given by:
LPR(wi, w1,n) = max 1≤j<k≤n p(wi|wj,k) p(wi|tj,k)
where wj,k denotes the word sequence wj , ..., wi−1, wi+1, ..., wk excluding wi (similarly for tj,k).",3.1 Collecting statistics,[0],[0]
"Note that the lower bound of LPR is 1, since the ratio for a word with no context is trivially 1.",3.1 Collecting statistics,[0],[0]
"We use the same equation for gapped n-grams, with the caveat that quantities involving sequences which include the location where the gap occurs are derived from special gapped n-gram statistics.",3.1 Collecting statistics,[0],[0]
"Note that the identification of the best ratio across all possible choices of context, not just the largest, is important for longer FS, where the entire POS context alone might uniquely identify the phrase, resulting in the minimum LPR of 1 even for entirely formulaic sequences—an undesirable result.
",3.1 Collecting statistics,[0],[0]
"In the segmentation approach of Brooke et al. (2015), LPR for an entire span is calculated as a product of the individual LPRs, but here we will use the minimum LPR across the words in the sequence:
minLPR(w1,n) = min 1≤i≤n LPR(wi, w1,n)
Here, minLPR for a particular n-gram does not reflect the overall degree to which it holds together, but rather focuses on the word which is its weakest link.",3.1 Collecting statistics,[0],[0]
"For example, in the case of be keep ∗ under wraps (Figure 2), a general statistical metric might assign it a high score due to the strong association between keep and under or under and wraps, but minLPR is focused on the weaker relationship between be and the rest of the phrase.",3.1 Collecting statistics,[0],[0]
"This makes it particularly suited to use in a lattice model of competing n-grams, where the choice of be keep ∗ under
wraps versus keep ∗ under wraps should be based exactly on the extent to which be is an essential part of the phrase; the other affinities are, in effect, irrelevant, because they occur in the smaller n-gram as well.",3.1 Collecting statistics,[0],[0]
The n-gram nodes in the lattice are directionally connected to nodes consisting of (n + 1)-grams which subsume them and (n− 1)-grams which they subsume.,3.2 Node interactions,[0],[0]
"For example, as detailed in Figure 2, the (gapped) n",3.2 Node interactions,[0],[0]
-gram keep ∗ under wraps would be connected “upwards” to the node keep everything under wraps and connected “downwards” to under wraps.,3.2 Node interactions,[0],[0]
"These directional relationships allow for two basic interactions between nodes in the lattice when a node is turned on: covering, which inhibits nodes below (subsumed by) a turned-on node (e.g., if keep ∗ under wraps is on, the model will tend not to choose under wraps as an FS); and clearing, which inhibits nodes above a turned-on node (e.g., if keep ∗ under wraps is on, the model would avoid selecting keep everything under wraps as an FS).",3.2 Node interactions,[0],[0]
"A third, undirected mechanism is overlapping, where nodes inhibit each other due to overlaps in the corpus (e.g., having both keep ∗ under wraps and be keep ∗ under as FS will be avoided).",3.2 Node interactions,[0],[0]
"The most important node interaction is covering, which corresponds to discounting or entirely excluding a node due to a node higher in the lattice.",3.2.1 Covering,[0],[0]
"Our model includes two types of covering: hard and soft.
",3.2.1 Covering,[0],[0]
"Hard covering is based on the idea that, due to very similar counts, we can reasonably conclude that the presence of an n-gram in our statistics is a direct result of a subsuming (n+i)-gram.",3.2.1 Covering,[0],[0]
"In Figure 2, e.g.,
if we have 143 counts of keep ∗ under wraps and 152 counts of under wraps, the presence of keep ∗ under wraps almost completely explains under wraps, and we should consider these two n-grams as one.",3.2.1 Covering,[0],[0]
"We do this by permanently disabling any hard covered node, and setting the minLPR of the covering node to the maximum minLPR among all the nodes it covers (including itself); this means that longer ngrams with function words (which often have lower minLPR) can benefit from the strong statistical relationships between open-class lexical features in ngrams that they cover.",3.2.1 Covering,[0],[0]
"This is done as a preprocessing step, and greatly improves the tractability of the iterative optimization of the lattice.",3.2.1 Covering,[0],[0]
"Of course, a threshold for hard covering must be chosen: during development we found that a ratio of 2/3 (corresponding to a significant majority of the counts of a lower node corresponding to the higher node) worked well.",3.2.1 Covering,[0],[0]
"We also use the concept of hard covering to address the issue of pronouns, based on the observation that specific pronouns often have high LPR values due to pragmatic biases (Brooke et al., 2015); for instance, private state verbs like feel tend to have first person singular subjects.",3.2.1 Covering,[0],[0]
"In the lattice, n-grams with pronouns are considered covered (inactive) unless they cover at least one other node which does not have a pronoun, which allows us to limit FS with pronouns without excluding them entirely: they are included only in cases where they are definitively formulaic.
",3.2.1 Covering,[0],[0]
"Soft covering is used in cases when a single ngram does not entirely account for another, but a turned-on n-gram to some extent may explain some of the statistical irregularity of one lower in the lattice.",3.2.1 Covering,[0],[0]
"For instance, in Figure 2 keep ∗ under is not hard-covered by keep ∗ under wraps (since there are FS such as keep ∗ under surveillance and keep it under your hat), but if keep ∗ under wraps is tagged as an FS, we nevertheless want to discount the portion of the keep ∗ under counts that correspond to occurrences of keep ∗ under wraps, with the idea that these occurrences have already been explained by the longer n-gram.",3.2.1 Covering,[0],[0]
"If enough subsuming n-grams are on, then the shorter n-gram will be discounted to the extent that it will be turned off, preventing redundancy.",3.2.1 Covering,[0],[0]
"This effect is accomplished by increasing the turned-off explainedness of keep ∗ under (and thus making turning on less desirable) in the follow-
ing manner: let c(·) be the count function, yi the current FS status for node xi (0 if off, 1 if on) and ab(x) a function which produces the set of indicies of all nodes above node x in the lattice.",3.2.1 Covering,[0],[0]
"Then, the cover(xt) score for a covered node t is:
cover(xt) = max ( 0, c(xt)− ∑ i∈ab(xt) yi · c(xi) c(xt) )
",3.2.1 Covering,[0],[0]
"When applied as an exponent to a minLPR score, it serves as simple, quick-to-calculate approximation of a new minLPR with the counts corresponding to the covering nodes removed from the calculation.",3.2.1 Covering,[0],[0]
"The cover score takes on values in the range 0 to 1, with 1 being the default when no covering occurs.",3.2.1 Covering,[0],[0]
"In general, covering prefers turning on longer, covering n-grams since doing so explains nodes lower in the lattice.",3.2.2 Clearing,[0],[0]
"Not surprisingly, it is generally desirable to have a mechanism working in opposition, i.e., one which views shorter FS as helping to explain the presence of longer n-grams which contain them, beyond the FS-neutral syntactic explanation provided by minLPR.",3.2.2 Clearing,[0],[0]
Clearing does this by increasing the explainedness of nodes higher in the lattice when a lower node is turned-on.,3.2.2 Clearing,[0],[0]
"The basic mechanism is similar to covering, except that counts cannot be made use of in the same way—whereas it makes sense to explain covered nodes in proportion to the counts of their covering nodes (since the counts of the covered n-grams can be directly attributed to the covering n-gram), in the reverse direction this logic fails.
",3.2.2 Clearing,[0],[0]
A simple but effective solution which avoids extra hyperparameters is to make use of the minLPR values of the relevant nodes.,3.2.2 Clearing,[0],[0]
"In the most common two-node situation, we increase the explainedness of the cleared node based on the ratio of the minLPR of two nodes, though only if the minLPR of the lower node is higher.",3.2.2 Clearing,[0],[0]
"Generalized to the (rare) case of multiple clearing nodes, we define clear(xt) as:
clear(xt) = ∏
i∈bl(xt)",3.2.2 Clearing,[0],[0]
"min
( 1,
minLPR(xt) yi ·minLPR(xi)
)
where bl(xt) produces a set of indicies of nodes below xt in the lattice.",3.2.2 Clearing,[0],[0]
"We refer to this mechanism as “clearing” because it tends to clear away a variety of
trivial uses of common FS which may have higher LPR due to the lexical and syntactic specificity of the FS.",3.2.2 Clearing,[0],[0]
"For instance, in Figure 2 if the node keep ∗ under wraps is turned on and has a minLPR of 8, then, if the minLPR of a node such as keep ∗ under wraps for is 4, clear(xt) will be 0.5.",3.2.2 Clearing,[0],[0]
"Like cover, clear takes on values in the range 0 to 1, with 1 being the default when no clearing occurs.",3.2.2 Clearing,[0],[0]
"Note that one major advantage with this particular formulation of clearing is that low-LPR nodes will be unable to clear higher LPR nodes above them in the lattice; otherwise, bad FS like of the might be selected as FS based purely to increase the explainedness of the many n-grams they appear in.",3.2.2 Clearing,[0],[0]
The third mechanism of node interaction involves n-grams which overlap in the corpus.,3.2.3 Overlap,[0],[0]
"In general, independent FS do not consistently overlap.",3.2.3 Overlap,[0],[0]
"For example, given that be keep ∗ under and keep ∗ under wraps often appear together (overlapping on the tokens keep ∗ under), we do not want both being selected as an FS, even in the case that both have high minLPR.",3.2.3 Overlap,[0],[0]
"To address this problem, rather than increasing the explainedness of turned-off nodes, we decrease the explainedness of the overlapping turned-on nodes—a penalty rather than an incentive which expresses the model’s confusion at having overlapping FS.",3.2.3 Overlap,[0],[0]
"For non-subsuming nodes xi and xj , let oc(xi, xj) be the count of instances of xi which contain at least one non-gap token of a corresponding instance of xj .",3.2.3 Overlap,[0],[0]
"For subsuming nodes, though, overlap is treated asymmetrically, with oc(xi, xj) equal to c(xj) (the lower count) if j ∈ ab(xi), but zero if j ∈ bl(xi).",3.2.3 Overlap,[0],[0]
"Given this definition of oc, we define overlap(xt) as:
overlap(xt) = c(xt)
c(xt)− ∑|X|
i=1",3.2.3 Overlap,[0],[0]
"yi · oc(xt, xi) Overlap takes on values in the range 1 to +∞, also defaulting to 1 when no overlaps exist.",3.2.3 Overlap,[0],[0]
"The effect of overlap is hyperbolic: small amounts of overlap have little effect, but nodes with significant overlap will effectively be forced to turn off.",3.2.3 Overlap,[0],[0]
"The objective function maximized by the model is then the explainedness (expl) across all the nodes
of the lattice X , xi, . . .",3.3 Explainedness,[0],[0]
", xN , which can be defined in terms of minLPR, the node interaction functions, and the FS status yi of each node in the lattice:
expl(X) = |X|∏
i=1
yi · C−overlap(xi)
+ (−yi + 1) ·minLPR(xi)−cover(xi)·clear(xi) (1)
When a node is off, its explainedness is the inverse of its minLPR, except if there are covering or clearing nodes which explain it by pushing the exponent of minLPR towards zero.",3.3 Explainedness,[0],[0]
"When the node is on, its explainedness is the inverse of a fixed cost hyperparameterC, though this cost is increased if it overlaps with other active nodes.",3.3 Explainedness,[0],[0]
"All else being equal, when minLPR(t) > C, a node will be selected as an FS, and so, independent of the node interactions, C can be viewed as the threshold for the minLPR association measure under a traditional approach to MWE identification.",3.3 Explainedness,[0],[0]
The dependence of the explainedness of nodes on their neighbors effectively prohibits a global optimization of the lattice.,3.4 Optimization,[0],[0]
"Fortunately, though most of the nodes in the lattice are part of a single connected graph, most of the effects of nodes on each other are relatively local, and effective local optimizations can be made tractable by applying some simple restrictions.",3.4 Optimization,[0],[0]
The main optimization loop consists of iterations over the lattice until complete convergence (no changes in the final iteration).,3.4 Optimization,[0],[0]
"For each iteration over the main loop, each potentially active node is examined in order to evaluate whether its current status is optimal given the current state of the lattice.",3.4 Optimization,[0],[0]
"The order that we perform this has an effect on the result: among the obvious options (LPR, ngram length), in development good results were obtained through ordering nodes by frequency, which gives an implicit advantage to relatively common ngrams.
",3.4 Optimization,[0],[0]
"Given the relationships between nodes, it is obviously not sufficient to consider switching only the present node.",3.4 Optimization,[0],[0]
"If, for instance, one or more of be keep ∗ under wraps, under wraps, or be keep ∗ under has been turned on, the covering, clearing, or overlapping effects of these other nodes will likely prevent
Algorithm 1 Optimization algorithm.",3.4 Optimization,[0],[0]
X is an ordered list of the nodes in the lattice.,3.4 Optimization,[0],[0]
Nodes (designated by x) contain pointers to the nodes immediately linked to them in the lattice.,3.4 Optimization,[0],[0]
States (designated by Y ) indicate whether each node is ON or OFF.,3.4 Optimization,[0],[0]
"Explainedness values are indicated by e. rev = relevant, aff = affected, curr = current
function LOCALOPT(Ystart , x,Xrev , Xaff )",3.4 Optimization,[0],[0]
"Ystart ← SET(Ystart , x,ON) Q← EMPTYQUEUE() ebest ← 0 Ybest ← NULL PUSH(Q,Ystart) repeat
Ycurr ← POP(Q)",3.4 Optimization,[0],[0]
"ecurr ← CALCEXPL(Ycurr , Xaff ) for xrev in Xrev do
Ynew ← SET(Ycurr , xrev ,OFF) enew ← CALCEXPL(Ynew , Xaff ) if enew > ecurr then
PUSH(Q,Ynew ) if enew > ebest then:
ebest ← enew Ybest ← Ynew
until ISEMPTY(Q) return Ybest
FREQUENCYSORTREVERSE(X) s← INITIALIZEALLOFF(X) repeat
Changed ← FALSE for x in X",3.4 Optimization,[0],[0]
"do
Xrev ← GETRELEVANT(x,X)",3.4 Optimization,[0],[0]
"Xaff ← GETAFFECTED(Xrev , X) Ynew ← LOCALOPT(Y, x,Xrev , Xaff )",3.4 Optimization,[0],[0]
if Ynew 6=,3.4 Optimization,[0],[0]
"Y then
Y ← Ynew Changed ← TRUE
until !",3.4 Optimization,[0],[0]
"Changed
a competing node like keep ∗ under wraps from being correctly activated.",3.4 Optimization,[0],[0]
"Instead, the algorithm identifies a small set of “relevant” nodes which are the most important to the status of the node under consideration.",3.4 Optimization,[0],[0]
"Since turned-off nodes have no direct effect on each other, only turned-on nodes above,
below, or overlapping with the current node in the lattice need be considered.",3.4 Optimization,[0],[0]
"Once the relevant nodes have been identified, all nodes (including turned-off nodes) whose explainedness is affected by one or more of the relevant nodes are identified.",3.4 Optimization,[0],[0]
"Next, a search is carried out for the optimal configuration of the relevant nodes, starting from an ‘all-on’ state and iteratively considering new states with one relevant node turned off; the search continues as long as there is an improvement in explainedness.",3.4 Optimization,[0],[0]
"Since the node interactions are roughly cumulative in their effects, this approach will generally identify the optimal state without the need for an exhaustive search.",3.4 Optimization,[0],[0]
"See Algorithm 1 for details.
",3.4 Optimization,[0],[0]
Omitted from Algorithm 1 for clarity are various low-level efficiencies which prevent the algorithm from reconsidering states already checked or from recalculating the explainedness of nodes when unnecessary.,3.4 Optimization,[0],[0]
"We also apply the following efficiency restrictions, which significantly reduce the runtime of the algorithm.",3.4 Optimization,[0],[0]
"In each case, more extreme (less efficient) values were individually tested using a development set and found to provide no benefit in terms of the quality of the output lexicon: • We limit the total number of relevant nodes to
5.",3.4 Optimization,[0],[0]
"When there are more than 5 nodes turned on in the vicinity of the target node, the most relevant nodes are selected by ranking candidates by the absolute difference in explainedness across possible configurations of the target and candidate node considered in isolation; • To avoid having to deal with storing and pro-
cessing trivial overlaps, we exclude overlaps with a count of less than 5 from our lattice; • Many nodes have a minLPR which is slightly
larger than 1 (the lowest possible value).",3.4 Optimization,[0],[0]
"There is very little chance these nodes will be activated by the algorithm, and so after applying hard covering, we do not consider activating nodes with minLPR < 2.",3.4 Optimization,[0],[0]
"We evaluate our approach across three different languages, including evaluation sets derived from four different corpora selected for their size and linguistic diversity.",4 Evaluation,[0],[0]
"In English, we follow Brooke et al. (2015) in using a 890M token filtered portion of the
ICWSM blog corpus (Burton et al., 2009) tagged with the Tree Tagger (Schmid, 1995).",4 Evaluation,[0],[0]
"To facilitate a comparison with Newman et al. (2012), which does not scale up to a corpus as large as the ICWSM, we also build a lexicon using the 100M token British National Corpus (Burnard, 2000), using the standard CLAWS-derived POS tags for the corpus.",4 Evaluation,[0],[0]
Lemmatization included removing all inflectional marking from both words and POS tags.,4 Evaluation,[0],[0]
"For English, gaps are identified using the same POS regex used in Brooke et al. (2015), which includes simple nouns and portions thereof, up to a maximum of 4 words.
",4 Evaluation,[0],[0]
The other two languages we include in our evaluation are Croatian and Japanese.,4 Evaluation,[0],[0]
"Relative to English, both languages have freer word order: we were interested in probing the challenges associated with using an n-gram approach to FS identification in such languages.",4 Evaluation,[0],[0]
"For Croatian, we used the 1.2-billion-token fhrWaC corpus (Šnajder et al., 2013), a filtered version of the Croatian web corpus hrWaC (Ljubešić and Klubička, 2014), which is POS-tagged and lemmatized using the tools of Agić et al. (2013).",4 Evaluation,[0],[0]
"Similar to English, the POS regex for Croatian includes simple nouns, adjectives and pronouns, but also other elements that regularly appear inside FS, including both adverbs and copulas.",4 Evaluation,[0],[0]
"For Japanese, we used a subset of the 100M-page web corpus of Shinzato et al. (2008), which was roughly the same token length as the English corpus.",4 Evaluation,[0],[0]
"We segmented and POS-tagged the corpus with MeCab (Kudo, 2008) using the UNIDIC morphological dictionary (Den et al., 2007).",4 Evaluation,[0],[0]
"The POS regex for Japanese covers the same basic nominal structures as English, but also includes case markers and adverbials.",4 Evaluation,[0],[0]
"Though our processing of Japanese includes basic lemmatization related to superficial elements like the choice of writing script and politeness markers, many elements (such as case marking) which are removed by lemmatization in Croatian are segmented into independent morphological units in the MeCab output, making the task somewhat different for the two languages.
",4 Evaluation,[0],[0]
Brooke et al. (2015) introduced a method for evaluating FS extraction without a reference lexicon or direct annotation of the output of a model.,4 Evaluation,[0],[0]
"Instead, n-grams are sampled after applying the frequency threshold and then annotated as being either an FS or not.",4 Evaluation,[0],[0]
"Benefits of this style of evaluation include
replicability, the diversity of FS, and the ability to calculate a true F-score.",4 Evaluation,[0],[0]
"We use the annotation of 2000 n-grams in the ICWSM corpus from that earlier work, and applied the same annotation methodology to the other three corpora: after training and based on written guidelines derived from the definitions of Wray (2008), three native-speaker, educated annotators judged 500 contiguous n-grams and another 500 gapped n-grams for each corpus.
",4 Evaluation,[0],[0]
"Other than the inclusion of new languages, our test sets differ from Brooke et al. (2015) in two ways.",4 Evaluation,[0],[0]
"One advantage of a type-based annotation approach, particularly with regards to annotation with a known subjective component, is that it is quite sensible to simply discard borderline cases, improving reliability at the cost of some representativeness.",4 Evaluation,[0],[0]
As such we entirely excluded from our test set n-grams which just one annotator marked as FS.,4 Evaluation,[0],[0]
Table 1 contains the counts for the four test sets after this filtering step and Fleiss’ Kappa scores before (“Pre”) and after (“Post”).,4 Evaluation,[0],[0]
The second change is that for the main evaluation we collapsed gapped and contiguous n-grams into a single test set.,4 Evaluation,[0],[0]
"The rationale is that the number of positive gapped examples is too low to provide a reliable independent F-score.
",4 Evaluation,[0],[0]
"Our primary comparison is with the heuristic LPR model of Brooke et al. (2015), which is scalable to large corpora and includes gapped n-grams.",4 Evaluation,[0],[0]
"For the BNC, we also benchmark against the DP-seg model of Newman et al. (2012) with recommended settings, and the LocalMaxs algorithm of da Silva and Lopes (1999) using SCP; neither of these methods scale to the larger corpora.4 Because these other approaches only generate sequential multiword units,
4DP-seg is far too slow, and LocalMaxs, though faster, calculates counts for all n-grams in the corpus, which would require terabytes of RAM for the large corpora.
",4 Evaluation,[0],[0]
we use only the sequential part of the BNC test set for this evaluation.,4 Evaluation,[0],[0]
All comparison approaches have themselves been previously compared against a wide range of association measures.,4 Evaluation,[0],[0]
"As such, we do not repeat all these comparisons here, but we do consider a lexicon built from ranking n-grams according to the measure used in our lattice (minLPR) as well as PMI and raw frequency.",4 Evaluation,[0],[0]
"For each of these association measures we rank all n-grams above the frequency threshold and build a lexicon equal to the size of the lexicon produced by our model.
",4 Evaluation,[0],[0]
We created small development sets for each corpus and used them to do a thorough testing of parameter settings.,4 Evaluation,[0],[0]
"Although it is generally possible to increase precision by increasing C, we found that across corpora we always obtained near-optimal results withC = 4, so to demonstrate the usefulness of the lattice technique as an entirely off-the-shelf tool, we present the results using identical settings for all four corpora.",4 Evaluation,[0],[0]
"We treat covering as a fundamental part of the Lattice model, but to investigate the efficacy of other node interactions within the model we present results with overlap and clearing node interactions turned off.",4 Evaluation,[0],[0]
The main results for FS acquisition across the four corpora are shown in Table 2.,5 Results,[0],[0]
"As noted in Section 2, simple statistical association measures like PMI do poorly when faced with syntactically-unrestricted n-grams of variable length: minLPR is clearly a much better statistic for this purpose.",5 Results,[0],[0]
"The LPRseg method of Brooke et al. (2015) consistently outperforms simple ranking, and the lattice method proposed here does better still, with a margin that is fairly consistent across the languages.",5 Results,[0],[0]
"Generally, clearing and overlap node interactions provide a relatively large increase in precision at the cost of a smaller drop in recall, though the change is fairly symmetrical in Croatian.",5 Results,[0],[0]
"When only covering is used, the results are fairly similar to Brooke et al. (2015), which is unsurprising given the extent to which decomposition and covering are related.",5 Results,[0],[0]
"The Japanese and ICWSM corpora have relatively high precision and low recall, whereas both the BNC and Croatian corpora have low precision and high recall.
",5 Results,[0],[0]
"In the contiguous FS test set for the BNC (Ta-
ble 3), we found that both the LocalMaxs algorithm and the DP-seg method of Newman et al. (2012) were able to beat our other baseline methods with roughly similar F-scores, though both are well below our Lattice method.",5 Results,[0],[0]
"Some of the difference seems attributable to fairly severe precision/recall imbalance, though we were unable to improve the F-score by changing the parameters from recommended settings for either model.",5 Results,[0],[0]
"Though the results across the four corpora are reasonably similar with respect to overall F-score, there are some discrepancies.",6 Discussion,[0],[0]
"By using the standard UNI-
DIC morpheme representation as the base unit for Japanese, the model ends up doing an extra layer of FS identification, one which is provided by word boundaries in the other languages.",6 Discussion,[0],[0]
"The result is that there are relatively more FS for Japanese: precision is high, and recall is comparably low.",6 Discussion,[0],[0]
"Importantly, the initial n-gram statistics actually reflect that Japanese is different: the number of n-gram types over length 4 is almost twice the number in the ICWSM corpus.",6 Discussion,[0],[0]
"One idea for future work is to automatically adapt to the input language/corpus in order to ensure a good balance between precision and recall.
",6 Discussion,[0],[0]
"At the opposite extreme, the low precision of the BNC is almost certainly due to its relatively small size: whereas the n-gram threshold we used here results in minimum counts of roughly 100 for the other three corpora, the BNC statistics include n-grams with counts of less than 10.",6 Discussion,[0],[0]
"At such low counts, LPR is less reliable and more noise gets into the lexicon: the first column of Table 4 shows that the BNC is noticeably larger then the other lexicons, and the higher numbers in columns 2 and 3 (number of POS types and percentage of gapped expressions, resp.) are also indicative of increased noise.",6 Discussion,[0],[0]
This could be resolved by increasing the n-gram threshold.,6 Discussion,[0],[0]
"It might also make sense to simply avoid smaller corpora, though for some applications a smaller corpus
may be unavoidable.",6 Discussion,[0],[0]
"One idea we are pursing is modifying the calculation of the LPR metric to use a more conservative probability estimate than maximum likelihood in the case of low counts.
",6 Discussion,[0],[0]
"We were interested in Croatian and Japanese in part because of their relatively free word order, and whether the handling of gaps would help with identifying FS in these languages.",6 Discussion,[0],[0]
"We discovered, however, that free word order actually results in more of a tendency towards contiguous FS, not less, a fact that is reflected in our test sets (Table 1) as well as the lexicons themselves (Table 4).",6 Discussion,[0],[0]
"Strikingly rare in Croatian, in particular, are expressions where the content of a gap is an argument which must be filled to syntactically complete an expression: it is English whose fixed-word-order constraints often keep elements of an FS distant from each other.",6 Discussion,[0],[0]
The gaps that do happen in Croatian are mostly prosodydriven insertions of other elements into already complete FS.,6 Discussion,[0],[0]
"This phenomena highlights a problem with the current model, in that gapped and contiguous versions of the same n-gram sequence (e.g., take away and take ∗ away) are, at present, considered entirely independently.",6 Discussion,[0],[0]
"Alternatives for dealing with this include collapsing statistics to create a single node in the lattice, creating a promoting link between contiguous and gapped versions of the same n-grams sequence in the lattice model, or switching to a dependency representation (which, we note, requires very little change to the basic model presented here, but would narrow its applicability).
",6 Discussion,[0],[0]
"The statistics in Table 4 otherwise reflect the quantity and diversity of FS across the corpora, particularly in terms of the number of POS patterns represented in the lexicon.",6 Discussion,[0],[0]
"Looking at the most common POS patterns across languages, only noun-noun and adjective-noun combinations ever account for
more than 5% of all word types in any of the lexicons.",6 Discussion,[0],[0]
"Though some of the diversity can of course be attributed to noise, it is safe to say that most FS do not fall into the standard two-word syntactic categories used in MWE work, and therefore identifying them requires a much more general approach like the one presented here.
",6 Discussion,[0],[0]
Table 5 contains 10 randomly selected examples from each of the lexicons produced by our method.,6 Discussion,[0],[0]
"Among the English examples, most of the clear errors are bigrams that reflect particular biases of their respective corpora:",6 Discussion,[0],[0]
"The phrase via slashdot comes from boilerplate text identifying the source of an article, whereas Maureen (from Maureen says) is a character in one of the novels included in the BNC.",6 Discussion,[0],[0]
"The longer FS mostly seem sensible, in that they are plausible lexicalized constructions, though be open to all * in the from the BNC seems too long and is likely the result of noise due to insufficient examples.",6 Discussion,[0],[0]
"Some FS are dialectal variants, for instance license endorsed refers to British traffic violations.",6 Discussion,[0],[0]
"More generally, the FS lexicons created by these two corpora are quite distinct, sharing less than 50% of their entries.
",6 Discussion,[0],[0]
One striking thing about the non-English FS is how poorly they translate: many good FS in these languages become extremely awkward when translated into English.,6 Discussion,[0],[0]
"This is expected, of course, for idioms like biti general poslije bitke “be the general after the battle” (i.e., “hindsight is 20/20”), but it extends to other relatively compositional constructions like こう言う ∗が続く “repeat occurrences of ∗ like this” and 前期比 “first half comparison”.",6 Discussion,[0],[0]
This highlights the potential importance of focusing on FS when learning a language.,6 Discussion,[0],[0]
"Though some of the errors seem to be the result of extra material added to a good FS, for instance promet teretnih vozila",6 Discussion,[0],[0]
"“good
vehicle traffic”, most, again, are somewhat inexplicable artifacts of the corpus they were built from, like austrijski investitor “Austrian investor”.
",6 Discussion,[0],[0]
"Since Zipfian frequency curves naturally extend to multiword vocabulary, our lexicons (and typebased evaluation of them) are of course dominated by rarer terms.",6 Discussion,[0],[0]
"This is not, we would argue, a serious drawback, since in practical terms there is very little value in focusing on common FS like of course which manually-built lexicons already contain; most of the potential in automatic extraction comes from the long tail.",6 Discussion,[0],[0]
"However, we did investigate the other end of the Zipfian curve by extracting the 20 most common MWEs (including both strong and weak) from the Schneider et al. (2014b) corpus.",6 Discussion,[0],[0]
"In the ICWSM lexicon, our recall for these common terms was fairly high (0.7), with errors mostly resulting from longer phrases containing these terms “winning out” (in the lattice) over shorter phrases, which have relatively low LPR due to extremely common constituent words; for example, we missed on time, but had 19 FS which contain it (e.g. right on time, show up on time, and start on time).",6 Discussion,[0],[0]
"In one case which showed this same problem, waste * time, the lexicon did have its ungapped version, highlighting the potential for improved handling of this issue.
",6 Discussion,[0],[0]
"In Section 2, we noted that FS is generally a much broader category than MWE, which we take
as referring to terms which carry significant noncompositional meaning.",6 Discussion,[0],[0]
"We decided to investigate the distinction at a practical level by annotating the positive examples in the ICWSM test set for being MWE or non-MWE FS.5 First, we note that only 28% of our FS types were labeled MWE; this is in contrast to, for instance, the annotation of Schneider et al. (2014b) where “weak” MWE make up a small fraction of MWE types.",6 Discussion,[0],[0]
"Even without any explicit representation of compositionality, our model did much better at identifying MWE FS than nonMWE FS: 0.7 versus 0.32 recall.",6 Discussion,[0],[0]
"This may simply reflect, however, the fact that a disproportionate number of MWEs were noun-noun compounds, which are fairly easy for the model to identify.
",6 Discussion,[0],[0]
"Due to the lack of spaces between words and an agglutinative morphology, the standard approach to tokenization and lemmatization in Japanese involves morphological rather than word segmentation.",6 Discussion,[0],[0]
"In terms of the content of the resulting lexicon we believe the effect of this difference on FS extraction is modest, since much of the extra FS in Japanese would simply be single words in other languages (and considered trivially part of the FS lexicon).",6 Discussion,[0],[0]
"However, from a theoretical perspective
5The set was exhaustively annotated by two native-speaker annotators (κ = 0.73), and conflicts were resolved through discussion.
",6 Discussion,[0],[0]
we might very much prefer to build FS for all languages starting from morphemes rather than words.,6 Discussion,[0],[0]
"Such a framework could, for instance, capture inflectional flexibility versus fixedness directly in the model, with fixed inflectional morphemes included as a distinct element of the FS and flexible morphemes becoming gaps.",6 Discussion,[0],[0]
"However, for many languages this would result in a huge blow up in complexity with only modest increases in the scope of FS identification.",6 Discussion,[0],[0]
"Though it is indisputable that inflectional fixedness is part of the lexical information contained in an FS, in practice this sort of information can be efficiently derived post hoc from the corpus statistics.
",6 Discussion,[0],[0]
"Though we have demonstrated that competition within a lattice is a powerful method for the production of multiword lexicons, its usefulness derives less from the specific choices we have made in this instantiation of the model, and more from the flexiblity that such a model provides for future research.",6 Discussion,[0],[0]
"Not only do alternatives like DP-seg and LocalMaxs fail to scale up to large corpora, there are few obvious ways to improve on their simple underlying algorithms without compromising their elegance and worsening tractability.",6 Discussion,[0],[0]
"Fast and functional, the LPR decomp approach is nevertheless algorithmically ungainly, involving multiple layers of heuristic-driven filtering with no possibility of correcting errors.",6 Discussion,[0],[0]
"Our lattice method is aimed at something between these extremes: a practical, optimizable model, but with various component heuristics that can be improved upon.",6 Discussion,[0],[0]
"For instance, though the current version of clearing is effective and has practical advantages relative to simpler options that we tested, it could be enhanced by more careful investigation of the statistical properties of n-grams which contain FS.
",6 Discussion,[0],[0]
"We can also consider adding new terms to the exponents of the two parts of our objective function, analagous to the cover, clear, and overlap functions, based on other relationships between nodes in the lattice.",6 Discussion,[0],[0]
"One which we have considered is creating new connections between identical or similar syntactic patterns, which could serve to encourage the model to generalize.",6 Discussion,[0],[0]
"In English, for instance, it might learn that verb-particle combinations are generally likely to be FS, whereas verb-determiner combinations are not.",6 Discussion,[0],[0]
"Our initial investigations sug-
gest, however, it may be difficult to apply this idea without merely amplifying existing undesirable biases in the LPR measure.",6 Discussion,[0],[0]
"Bringing in other information such as simple distributional statistics might help the model identify non-compositional semantics, and could, in combination with the existing lattice competition, focus the model on MWEs which could provide a reliable basis for generalization.
",6 Discussion,[0],[0]
"For all four corpora, the lattice optimization algorithm converged within 10 iterations.",6 Discussion,[0],[0]
"Although the optimization of the lattice is several orders of magnitude more complex than the decomposition heuristics of Brooke et al. (2015), the time needed to build and optimize the lattice is a fraction of the time required to collect the statistics for LPR calculation, and so the end-to-end runtimes of the two methods are comparable.",6 Discussion,[0],[0]
"In the BNC, the full lattice method was much faster than LocalMaxs and DP-Seg, though direct runtime comparisons to these methods are of modest value due to differences in both scope and implementation.
",6 Discussion,[0],[0]
"Finally, though the model was designed specifically for FS extraction, we note that it could be useful for related tasks such as unsupervised learning of morphological lexicons, particularly for agglutinative languages.",6 Discussion,[0],[0]
"Character or phoneme n-grams could compete in an identically structured lattice to be chosen as the best morphemes for the language, with LPR adapted to use phonological predictability (i.e., based on vowel/consonant “tags”) instead of syntactic predictability.",6 Discussion,[0],[0]
"It is likely, though, that further algorithmic modifications would be necessary to target morphological phenomena well, which we leave for future work.",6 Discussion,[0],[0]
"We have presented here a new methodology for acquiring comprehensive multiword lexicons from large corpora, using competition in an n-gram lattice.",7 Conclusion,[0],[0]
Our evaluation using annotations of sampled n-grams shows that it consistently outperforms alternatives across several corpora and languages.,7 Conclusion,[0],[0]
"A tool which implements the method, as well as the acquired lexicons, annotation guidelines, and test sets have been made available.6
6https://github.com/julianbrooke/ LatticeFS",7 Conclusion,[0],[0]
"The second author was supported by an Endeavour Research Fellowship from the Australian Government, and in part by the Croatian Science Foundation under project UIP-2014-09-7312.",Acknowledgements,[0],[0]
"We would also like to thank our English, Japanese, and Croatian annotators, and the TACL reviewers and editors for helping shape this paper into its current form.",Acknowledgements,[0],[0]
We present a new model for acquiring comprehensive multiword lexicons from large corpora based on competition among n-gram candidates.,abstractText,[0],[0]
"In contrast to the standard approach of simple ranking by association measure, in our model n-grams are arranged in a lattice structure based on subsumption and overlap relationships, with nodes inhibiting other nodes in their vicinity when they are selected as a lexical item.",abstractText,[0],[0]
"We show how the configuration of such a lattice can be optimized tractably, and demonstrate using annotations of sampled n-grams that our method consistently outperforms alternatives by at least 0.05 F-score across several corpora and languages.",abstractText,[0],[0]
Unsupervised Acquisition of Comprehensive Multiword Lexicons using Competition in an n-gram Lattice,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 621–626 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
621",text,[0],[0]
"Learning the representations of languages is a fundamental problem in natural language processing and most existing methods exploit the hypothesis that words occurring in similar contexts tend to have similar meanings (Pennington et al., 2014; Bojanowski et al., 2017), which could lead word vectors to capture semantic information.",1 Introduction,[0],[0]
Mikolov et al. (2013) first point out that word embeddings learned on separate monolingual corpora exhibit similar structures.,1 Introduction,[0],[0]
"Based on this finding, they suggest it is possible to learn a linear mapping from a source to a target embedding space and then generate bilingual dictionaries.",1 Introduction,[0],[0]
"This simple yet effective approach has led researchers to investigate on improving cross-lingual word embeddings with the help of bilingual word lexicons (Faruqui and Dyer, 2014; Xing et al., 2015).
",1 Introduction,[0],[0]
"For low-resource languages and domains, crosslingual signal would be hard and expensive to obtain, and thus it is necessary to reduce the need for bilingual supervision.",1 Introduction,[0],[0]
"Artetxe et al. (2017) successfully learn bilingual word embeddings with
only a parallel vocabulary of aligned digits.",1 Introduction,[0],[0]
Zhang et al. (2017) utilize adversarial training to obtain cross-lingual word embeddings without any parallel data.,1 Introduction,[0],[0]
"However, their performance is still significantly worse than supervised methods.",1 Introduction,[0],[0]
"By combining the merits of several previous works, Conneau et al. (2018) introduce a model that reaches and even outperforms supervised state-of-the-art methods with no parallel data.
",1 Introduction,[0],[0]
"In recent years, generative models have become more and more powerful.",1 Introduction,[0],[0]
"Both Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) and Variational Autoencoders (VAEs) (Kingma and Welling, 2014) are prominent ones.",1 Introduction,[0],[0]
"In this work, we borrow the ideas from both GANs and VAEs to tackle the problem of bilingual lexicon induction.",1 Introduction,[0],[0]
"The basic idea is to learn latent variables that could capture semantic meaning of words, which would be helpful for bilingual lexicon induction.",1 Introduction,[0],[0]
We also utilize adversarial training for our model and require no form of supervision.,1 Introduction,[0],[0]
We evaluate our approach on several language pairs and experimental results demonstrate that our model could achieve promising performance.,1 Introduction,[0],[0]
We further combine our model with several helpful techniques and show our model could perform competitively and even superiorly compared with several state-of-the-art methods.,1 Introduction,[0],[0]
Extracting bilingual lexica has been studied by researchers for a long time.,2.1 Bilingual Lexicon Induction,[0],[0]
Mikolov et al. (2013) first observe there is isomorphic structure among word embeddings trained separately on monolingual corpora and they learn the linear transformation between languages.,2.1 Bilingual Lexicon Induction,[0],[0]
Zhang et al. (2016b) improve the method by constraining the transformation matrix to be orthogonal.,2.1 Bilingual Lexicon Induction,[0],[0]
"Xing et al. (2015) incorporate length normalization during training and
maximize the cosine similarity instead.",2.1 Bilingual Lexicon Induction,[0],[0]
"They point out that adding an orthogonality constraint can improve performance and has a closed-form solution, which was referred to as Procrustes approach in Smith et al. (2017).",2.1 Bilingual Lexicon Induction,[0],[0]
"Canonical correlation analysis has also been used to map both languages to a shared vector space (Faruqui and Dyer, 2014; Lu et al., 2015).
",2.1 Bilingual Lexicon Induction,[0],[0]
"To reduce the need for supervision signals, Artetxe et al. (2017) use identical digits and numbers to form an initial seed dictionary and then iteratively refine their results until convergence.",2.1 Bilingual Lexicon Induction,[0],[0]
Zhang et al. (2017) apply adversarial training to align monolingual word vector spaces with no supervision.,2.1 Bilingual Lexicon Induction,[0],[0]
"Conneau et al. (2018) improve the model by combining adversarial training and Procrustes approach, and their unsupervised approach could reach and even outperform state-of-the-art supervised approaches.",2.1 Bilingual Lexicon Induction,[0],[0]
"In this work, we make further improvements and enhance the model proposed in (Conneau et al., 2018) with latent variable model and iterative training procedure.",2.1 Bilingual Lexicon Induction,[0],[0]
"VAEs (Kingma and Welling, 2014) represent one of the most successful deep generative models.",2.2 Generative Models,[0],[0]
Standard VAEs assume observed variables are generated from latent variables and the latent variables are sampled from a simple Gaussian distribution.,2.2 Generative Models,[0],[0]
"Typically, VAEs utilize an neural inference model to approximate the intractable posterior, and optimize model parameters jointly with
a reparameterized variational lower bound.",2.2 Generative Models,[0],[0]
"VAEs have been successfully applied in several natural language processing tasks before (Zhang et al., 2016a; Bowman et al., 2016).
",2.2 Generative Models,[0],[0]
"GANs (Goodfellow et al., 2014) are another framework for estimating generative models via an adversarial process and have attracted huge attention.",2.2 Generative Models,[0],[0]
The basic strategy is to train a generative model and a discriminative model simultaneously via an adversarial process.,2.2 Generative Models,[0],[0]
"Adversarial training technique for matching distribution has proven to be powerful in a variety of tasks (Bowman et al., 2016).",2.2 Generative Models,[0],[0]
"Adversarial Autoencoder (Makhzani et al., 2015) is a probabilistic autoencoder that uses the GANs to perform variational inference.",2.2 Generative Models,[0],[0]
"By combining a VAE with a GAN, Larsen et al. (2016) use learned feature representations in the GAN discriminator as the basis for the VAE reconstruction objective.",2.2 Generative Models,[0],[0]
"GANs have been applied in machine translation before (Yang et al., 2018; Lample et al., 2018).",2.2 Generative Models,[0],[0]
"In this section, we first briefly introduce VAEs, and then we illustrate the details and training techniques of our proposed model.",3 Proposed Approach,[0],[0]
Variational Autoencoders (VAEs) are deep generative model which are capable of learning complex density models for data via latent variables.,3.1 Variational Autoencoder,[0],[0]
"Given a nonlinear generative model pθ(x|z) with input x ∈ RD and associated latent variable z ∈ RL drawn from a prior distribution p0(z), the goal of VAEs is to use a recognition model, qφ(z|x) to approximate the posterior distribution of the latent variables by maximizing the following variational lower bound
Lθ,φ = Eqφ(z|x)[log pθ(x|z)]−KL(qφ(z|x)||p0(z)), (1) where KL refers to Kullback-Leibler divergence.",3.1 Variational Autoencoder,[0],[0]
"Basically, our model assumes that the source word embedding {xn} and the target word embedding {yn} could be drawn from a same latent variable space {zn}, where {zn} is capable of capturing semantic meaning of words.
",3.2 Our Model,[0],[0]
"In contrast to the standard VAE prior that assumes each latent embedding zn to be drawn from the same latent Gaussian, our model just requires
the distribution of latent variables for source and target word embeddings to be equal.",3.2 Our Model,[0],[0]
"To achieve such a goal, we utilize adversarial training to guide the two latent distributions to match with each other.
",3.2 Our Model,[0],[0]
"As in adversarial training, we have networks φs and φt for both source and target space, striving to map words into the same latent space, while the discriminator D is a binary classifier which tries to distinguish between the two languages.",3.2 Our Model,[0],[0]
"We also have reconstruction networks θs and θt as in VAEs.
",3.2 Our Model,[0],[0]
"The objective function for the discriminator D could be formulated as
LD = Ezy∼qφt (z|y)[logD(zy)]
+",3.2 Our Model,[0],[0]
Ezx∼qφs (z|x)[log(1−D(zx)),3.2 Our Model,[0],[0]
].,3.2 Our Model,[0],[0]
"(2)
For the source side, the objective is to minimize
Lφs,θs = Ezx∼qφs (z|x)[log pθs(x|zx)]",3.2 Our Model,[0],[0]
"− Ezx∼qφs (z|x)[logD(zx)].
(3)
Here we define qφs(z|x) = N (µs(x),Σs(x)), where µs(x) = Wµsx and Σs(x) = exp(Wσsx); Wµs and Wσs are learned parameters.",3.2 Our Model,[0],[0]
We also define the mean of pθs(x|z) to be WTµsz.,3.2 Our Model,[0],[0]
"The objective function and structure for φt are similar.
",3.2 Our Model,[0],[0]
The basic framework of our model is shown in Figure 1.,3.2 Our Model,[0],[0]
"As we could see from the figure, our model tries to map the source and target word embedding into the same latent space which could capture the semantic meaning of words.
",3.2 Our Model,[0],[0]
Theoretical analysis has revealed that adversarial training tries to minimize the Jensen-Shannon (JS) divergence between the real and fake distribution.,3.2 Our Model,[0],[0]
"Therefore, one can view our model as replace KL divergence in Equation 1 with JS divergence and change the Gaussian prior to the target distribution.",3.2 Our Model,[0],[0]
"Our model has two generators φs and φt, and we have found that training them jointly would be extremely unstable.",3.3 Training Strategy,[0],[0]
"In this paper, we propose an iterative method to train our models.",3.3 Training Strategy,[0],[0]
"Basically, we first initialize Wµt to be identity matrix and train φs and θs on the source side.",3.3 Training Strategy,[0],[0]
"After convergence, we freeze Wµs , and then train φt and θt in the target side.",3.3 Training Strategy,[0],[0]
The pseudo-code for this process is shown in Algorithm 1.,3.3 Training Strategy,[0],[0]
"It should be noted that there is no variance once completing training.
",3.3 Training Strategy,[0],[0]
Algorithm 1 Training Strategy 1:,3.3 Training Strategy,[0],[0]
"Wµt = I 2: for i = 1, · · · , niter do 3: while φs and θs have not converged do 4: Update discriminator D 5: Update φs and θs 6: end while 7: while φt and θt have not converged do 8: Update discriminator D 9: Update φt and θt 10: end while 11: end for",3.3 Training Strategy,[0],[0]
Our experiments could be divided into two parts.,4 Experiment,[0],[0]
"In the first part, we conduct experiments on smallscale datasets and our main baseline is Zhang et al. (2017).",4 Experiment,[0],[0]
"In the second part, we combine our model with several advanced techniques and we compare our model with Conneau et al. (2018) on largescale datasets.",4 Experiment,[0],[0]
"In this section, our experiments focus on smallscale datasets and our main baseline model is adversarial autoencoder (Zhang et al., 2017).",4.1 Small-scale Datasets,[0],[0]
"For justice, we use the same model selection strategy with Zhang et al. (2017), i.e. we choose the model whose sum of reconstruction loss and classification accuracy is the least.",4.1 Small-scale Datasets,[0],[0]
The source and target word embeddings would be first mapped into the latent space.,4.1 Small-scale Datasets,[0],[0]
"For each source word embedding x, it would be first transformed into zx.",4.1 Small-scale Datasets,[0],[0]
The the its k nearest target embeddings would be retrieved and be compared against the entry in a ground truth bilingual lexicon.,4.1 Small-scale Datasets,[0],[0]
Performance is measured by top-1 accuracy.,4.1 Small-scale Datasets,[0],[0]
"For this set of experiments, we use the same data as Zhang et al. (2017).",4.1.1 Experiments on Chinese-English Dataset,[0],[0]
The statistics of the final training data is given in Table 1.,4.1.1 Experiments on Chinese-English Dataset,[0],[0]
"We use Chinese-English Translation Lexicon Version 3.0 (LDC2002L27) as our ground truth bilingual lexicon for evaluation.
",4.1.1 Experiments on Chinese-English Dataset,[0],[0]
"The baseline models are MonoGiza system (Dou et al., 2015), translation matrix (TM) (Mikolov et al., 2013), isometric alignment (IA) (Zhang et al., 2016b) and adversarial training approach (Zhang et al., 2017).
",4.1.1 Experiments on Chinese-English Dataset,[0],[0]
Table 2 summarizes the performance of baseline models and our approach.,4.1.1 Experiments on Chinese-English Dataset,[0],[0]
The results of baseline models are cited from Zhang et al. (2017).,4.1.1 Experiments on Chinese-English Dataset,[0],[0]
"As we can see from the table, our model could achieve superior performance compared with other baseline models.",4.1.1 Experiments on Chinese-English Dataset,[0],[0]
Table 3 lists some word translation examples given by our model.,4.1.1 Experiments on Chinese-English Dataset,[0],[0]
We also conduct experiments on Spanish-English and Italian-English language pairs.,4.1.2 Experiments on Other Language Pairs Datasets,[0],[0]
"Again, we use the same dataset with Zhang et al. (2017).",4.1.2 Experiments on Other Language Pairs Datasets,[0],[0]
and the statistics are shown in Table 1.,4.1.2 Experiments on Other Language Pairs Datasets,[0],[0]
"The ground truth bilingual lexica for Spanish-English and Italian-
English are obtained from Multilingual Unsupervised and Supervised Embeddings (MUSE) 1.
",4.1.2 Experiments on Other Language Pairs Datasets,[0],[0]
The experimental results are shown in Table 4.,4.1.2 Experiments on Other Language Pairs Datasets,[0],[0]
"Because Spanish, Italian and English are closely related languages, the accuracy would be higher than the Chinese-English dataset.",4.1.2 Experiments on Other Language Pairs Datasets,[0],[0]
Our model is able to outperform baseline model in this setting.,4.1.2 Experiments on Other Language Pairs Datasets,[0],[0]
"In this section, we integrate our method with Conneau et al. (2018), whose method improves Zhang et al. (2017) by more sophiscated refinement procedure and validation criterion.",4.2 Large-scale Datasets,[0],[0]
"We replace their first step, namely the adversarial training step, with our model.",4.2 Large-scale Datasets,[0],[0]
"Basically, we first map the source and target embeddings into the latent space using our algorithm, and then fine-tune the identity mapping in the latent space with the closed-form Procrustes solution.",4.2 Large-scale Datasets,[0],[0]
"We use their similarity measure, namely cross-domain similarity local scaling (CSLS), to produce reliable matching pairs and validation criterion for unsupervised model selection.
",4.2 Large-scale Datasets,[0],[0]
"1https://github.com/facebookresearch/MUSE
We conduct experiments on English-Spanish, English-Russian and English-Chinese datasets, which are the same as Conneau et al. (2018).",4.2 Large-scale Datasets,[0],[0]
The results are shown in Table 5.,4.2 Large-scale Datasets,[0],[0]
"As seen, our model could consistently achieve better performance compared with adversarial training.",4.2 Large-scale Datasets,[0],[0]
"After refinement, our model could further achieve competitive and even superior results compared with state-of-the-art unsupervised methods.",4.2 Large-scale Datasets,[0],[0]
This further demonstrates the capacity of our model.,4.2 Large-scale Datasets,[0],[0]
"Based on the assumption that word vectors in different languages could be drawn from a same latent variable space, we propose a novel approach which builds cross-lingual dictionaries via latent variable models and adversarial training with no parallel corpora.",5 Conclusion,[0],[0]
Experimental results on several language pairs have demonstrated the effectiveness and universality of our model.,5 Conclusion,[0],[0]
"We hope our method could be beneficial to other areas such as unsupervised machine translation (Lample et al., 2018).
",5 Conclusion,[0],[0]
"Future directions include validate our model on more realistic scenarios (Dinu et al., 2015) as well as combine our algorithms with more sophiscated adversarial networks (Arjovsky et al., 2017; Gulrajani et al., 2017).",5 Conclusion,[0],[0]
We thank all the anonymous reviewers for their insightful comments.,Acknowledgments,[0],[0]
Bilingual lexicon extraction has been studied for decades and most previous methods have relied on parallel corpora or bilingual dictionaries.,abstractText,[0],[0]
Recent studies have shown that it is possible to build a bilingual dictionary by aligning monolingual word embedding spaces in an unsupervised way.,abstractText,[0],[0]
"With the recent advances in generative models, we propose a novel approach which builds cross-lingual dictionaries via latent variable models and adversarial training with no parallel corpora.",abstractText,[0],[0]
"To demonstrate the effectiveness of our approach, we evaluate our approach on several language pairs and the experimental results show that our model could achieve competitive and even superior performance compared with several state-of-the-art models.",abstractText,[0],[0]
Unsupervised Bilingual Lexicon Induction via Latent Variable Models,title,[0],[0]
"Proceedings of the SIGDIAL 2018 Conference, pages 161–170, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics
161",text,[0],[0]
"Emotionally intelligent systems has high potential as assistive technology in various affective tasks, such as caring for the elderly, low-cost ubiquitous chat therapy, or providing emotional support in general.",1 Intoduction,[0],[0]
"Two of the most studied emotional competences for agents are emotion recognition, which allows a system to discern the user’s
emotions and address them in giving a response (Forbes-Riley and Litman, 2012; Han et al., 2015; Tielman et al., 2014), and emotion simulation, which helps convey non-verbal aspects to the user for a more believable and human-like interaction, for example to show empathy (Higashinaka et al., 2008) or personality (Egges et al., 2004).",1 Intoduction,[0],[0]
"Acosta and Ward (2011) have attempted to connect the two competences to build rapport, by recognizing user’s emotion and reflecting it in the system response.",1 Intoduction,[0],[0]
"Although these competences address some of the user’s emotional needs (Picard and Klein, 2002), they are not sufficient to provide emotional support in an interaction.
",1 Intoduction,[0],[0]
"Recently, there has been an increasing interest in eliciting user’s emotional response via dialogue system interaction, i.e. emotion elicitation.",1 Intoduction,[0],[0]
"Skowron et al. (2013) have studied the impact of different affective personalities in a text-based dialogue system, while Hasegawa et al. (2013) constructed translation-based response generators with various emotion targets.",1 Intoduction,[0],[0]
"Despite the positive results, these approaches have not yet paid attention to the emotional benefit for the users.",1 Intoduction,[0],[0]
"Our work aims to draw on an important overlooked potential of emotion elicitation: its application to improve emotional states, similar to that of emotional support between humans.",1 Intoduction,[0],[0]
"This can be achieved by actively eliciting a more positive emotional valence throughout the interaction, i.e. positive emotion elicitation.",1 Intoduction,[0],[0]
"This takes form as a chat-oriented dialogue system interaction that is layered with an implicit goal to address user’s emotional needs.
",1 Intoduction,[0],[0]
"With recent advancements in neural network research, end-to-end approaches have been reported to show promising results for non-goal oriented dialogue systems (Vinyals and Le, 2015; Serban et al., 2016; Nio et al., 2016).",1 Intoduction,[0],[0]
"However, application of this approach towards positive emotion elicitation is still very lacking.",1 Intoduction,[0],[0]
"Zhou et al. (2017)
have investigated 6 categories to emotionally color the response via the internal state of the decoder.",1 Intoduction,[0],[0]
"However, this study has not yet considered user’s emotion in the response generation process, nor attempted improve emotional experience of user.
",1 Intoduction,[0],[0]
"Towards positive emotion elicitation, Lubis et al. (2018) have recently proposed a model that encodes emotion information from user input and utilizes it in generating response.",1 Intoduction,[0],[0]
"However, the resulting system is still limited to short and generic responses with positive affect, echoing the long standing lack-of-diversity problem in neural network based response generation (Li et al., 2016).",1 Intoduction,[0],[0]
"Furthermore, the reported system has not learn about positive emotion elicitation strategies from an expert as the corpus construction relied on crowd-sourcing workers.
",1 Intoduction,[0],[0]
This points to another problem: the lack of data that shows positive emotion elicitation or emotion recovery in everyday situations.,1 Intoduction,[0],[0]
Learning from expert responses and actions are essential in such a scenario as these potentially differ from standard chat-based scenarios.,1 Intoduction,[0],[0]
"With scarcity of large-scale data, additional knowledge from higher level abstraction, such as dialogue action labels, may be highly beneficial.",1 Intoduction,[0],[0]
"However, such high-level information must rely on human annotations, which are expensive, labor intensive, and often ambiguous.
",1 Intoduction,[0],[0]
"To answer these challenges, first, we construct a corpus containing recordings of a professional counselor and 30 participants in a positive emotion elicitation scenario.",1 Intoduction,[0],[0]
"Second, we extract higher level information from the expert’s responses via unsupervised clustering and use the resulting labels to train a neural dialogue system.",1 Intoduction,[0],[0]
"Lastly, we propose a hierarchical neural dialogue system which considers 1) expert’s action, 2) dialogue context, and 3) user emotion, in generating a response by encoding them from user input.",1 Intoduction,[0],[0]
"Our evaluations show that the proposed method yields lower perplexity, elicits a positive emotional impact, and generates longer responses that improves subjective engagement.",1 Intoduction,[0],[0]
"Even though various affective conversational scenarios have been considered (McKeown et al., 2012; Gratch et al., 2014), there is still a lack of resources that show common emotional problems in everyday social settings.",2 Corpus Construction: Positive Emotion Elicitation by an Expert,[0],[0]
"Furthermore, a great ma-
jority of existing corpora does not involve any professional who is an expert in handling emotional reactions in a conversation.
",2 Corpus Construction: Positive Emotion Elicitation by an Expert,[0],[0]
"To fill these gaps, we design our corpus to 1) contain recordings of spontaneous dyadic interactions before and after a negative emotion exposure, and 2) involve a professional counselor as an expert.",2 Corpus Construction: Positive Emotion Elicitation by an Expert,[0],[0]
"In each interaction, a negative emotion inducer is shown to the dyad, and the goal of the expert is to aid emotion processing and elicit a positive emotional change through the interaction.",2 Corpus Construction: Positive Emotion Elicitation by an Expert,[0],[0]
"From this point, we will refer to this corpus as the counseling corpus.",2 Corpus Construction: Positive Emotion Elicitation by an Expert,[0],[0]
"To induce negative emotion, we opt for short video clips which are a few minutes in length.",2.1 Negative Emotion Inducer,[0],[0]
"This method is well established and has been studied for several decades (Gross and Levenson, 1995; Schaefer et al., 2010).",2.1 Negative Emotion Inducer,[0],[0]
"One study shows that amongst a number of techniques, the use of video clips is the most effective way to induce both positive and negative emotional states (Westermann et al., 1996).",2.1 Negative Emotion Inducer,[0],[0]
"It also offers easy replication in constrained environmental settings, such as the recording room.
",2.1 Negative Emotion Inducer,[0],[0]
"However, in contrast to previous works (Schaefer and Philippot, 2005), we look for clips that depict real life situations and issues, i.e., non-fiction and non-films.",2.1 Negative Emotion Inducer,[0],[0]
"We select short video clips of news reports, interviews, and documentary films as emotion inducers to avoid the unpredictability of subjective emotional response to fictional clips.",2.1 Negative Emotion Inducer,[0],[0]
Non-fictional inducer also reflects real everyday situations better.,2.1 Negative Emotion Inducer,[0],[0]
"We ensure that the clips contain enough information and context to serve as conversation topic throughout the recording session.
",2.1 Negative Emotion Inducer,[0],[0]
We target two emotions with negative valence: anger and sadness.,2.1 Negative Emotion Inducer,[0],[0]
"First, we manually selected 34 of videos with varying relevant topics that are provided freely online.",2.1 Negative Emotion Inducer,[0],[0]
Two human experts are then asked to rate them in terms of intensity and the induced emotion (sadness or anger).,2.1 Negative Emotion Inducer,[0],[0]
"Finally, we selected 20 videos, 10 of each emotion with varied intensity level where the two human ratings agree.",2.1 Negative Emotion Inducer,[0],[0]
"We arrange for the dyad to consist of an expert and a participant, each with a distinct role.",2.2 Data Collection,[0],[0]
"The roles are based on the “social sharing of emotion” scenario, which argues that after an emotional event, a person is inclined to initiate an interaction which
centers on the event and their reactions to it (Rime et al., 1991; Luminet IV et al., 2000).",2.2 Data Collection,[0],[0]
"This form of social sharing is argued to be integral in processing the emotional event (Rime et al., 1991).
",2.2 Data Collection,[0],[0]
"In the interactions, the expert plays the part of the external party who helps facilitate this process following the emotional response of the participant.",2.2 Data Collection,[0],[0]
"We recruit a professional counselor as the expert in the recording, an accredited member of the British Association for Counseling and Psychotherapy with more than 8 years of professional experience.",2.2 Data Collection,[0],[0]
"As participants, we recruit 30 individuals (20 males and 10 females) that speak English fluently as first or second language.
",2.2 Data Collection,[0],[0]
A session starts with an opening talk as a neutral baseline conversation.,2.2 Data Collection,[0],[0]
"Afterwards, we induce negative emotion by showing an emotion inducer to the dyad.",2.2 Data Collection,[0],[0]
"This is followed by a discussion that targets at emotional processing and recovery, during which the expert is given the objective to facilitate the processing of emotional response caused by the emotion induction, and to elicit a positive emotional change.
",2.2 Data Collection,[0],[0]
"In total, we recorded 60 sessions of interactions, 30 with “anger” inducer and 30 with “sadness”.",2.2 Data Collection,[0],[0]
The combined duration of all sessions sums up to 23 hours and 41 minutes of material.,2.2 Data Collection,[0],[0]
"The audio and video recordings are transcribed, including a number of special notations for non-speech sounds such as laughter, back-channels, and throat noise.",2.2 Data Collection,[0],[0]
"We follow the circumplex model of affect (Russell, 1980) in annotating emotion occurrences in the recordings.",2.3 Emotion Annotation,[0],[0]
Two dimensions of emotion are defined: valence and arousal.,2.3 Emotion Annotation,[0],[0]
"Valence measures the positivity or negativity of emotion; e.g., the feeling of joy is indicated by positive valence while fear is negative.",2.3 Emotion Annotation,[0],[0]
"On the other hand, arousal measures the activity of emotion; e.g., depression is low in arousal (passive), while rage is high (active).
",2.3 Emotion Annotation,[0],[0]
"For each recording, the participants self report their emotional state using the FEELtrace system (Cowie et al., 2000) immediately after the interaction.",2.3 Emotion Annotation,[0],[0]
"While an annotator is watching a target person in a recording, he or she is moving a cursor along a linear scale on an adjacent window to indicate the perceived emotional aspect (e.g., valence or arousal) of the target.",2.3 Emotion Annotation,[0],[0]
"This results in a sequence of real numbers ranging from -1 to 1 with a constant time interval, called a trace.",2.3 Emotion Annotation,[0],[0]
"Statistical anal-
yses of validation experiments have confirmed the reliability and indicated the precision of the FEELtrace system (Cowie et al., 2000).",2.3 Emotion Annotation,[0],[0]
"Throughout the study and experiments, we utilize the dialogue triple format, i.e. a sequence of three dialogue turns.",2.4 Dialogue Triples,[0],[0]
"It has been previously utilized for considering dialogue context (Sordoni et al., 2015), filtering multi-party conversation (Lasguido et al., 2014), and observing emotion appraisal (Lubis et al., 2017).",2.4 Dialogue Triples,[0],[0]
"In this study, we exploit it to provide both past and future contexts of an emotion occurrence
We extend and adapt the two-hierarchy view of dialogue (Serban et al., 2016).",2.4 Dialogue Triples,[0],[0]
"We view a dialogue D as a sequence of dialogue turns of arbitrary length M between two speakers, i.e. D = {U1, ..., UM}.",2.4 Dialogue Triples,[0],[0]
"Each utterance in them-th dialogue turn is a sequence of tokens of arbitrary length Nm, i.e. Um = {wm,1, ..., wm,Nm}.",2.4 Dialogue Triples,[0],[0]
"In a triple, D = {U1, U2, U3}, where U1 and U3 are uttered by speaker A, and U2 by speaker B. In particular, we are interested in triturns with counselorparticipant-counselor speaker sequence.",2.4 Dialogue Triples,[0],[0]
"It is practical to view U1, U2, and U3 as dialogue context, query, and response, respectively.",2.4 Dialogue Triples,[0],[0]
"U1 and U3 are the contexts of the emotion occurrence in U2.
",2.4 Dialogue Triples,[0],[0]
"We define the end of a dialogue turn as either 1) natural end of the sentence, or 2) turn taking by the other speaker, whichever comes first.",2.4 Dialogue Triples,[0],[0]
Back channels in the middle of a speaker’s utterance are not considered as turn taking since they instead signal active listening.,2.4 Dialogue Triples,[0],[0]
This also prevents overly fragmented dialogue turns.,2.4 Dialogue Triples,[0],[0]
The backchannels are instead appended into the next dialogue turn once one of the criteria above is met.,2.4 Dialogue Triples,[0],[0]
"We extract a total of 6,064 dialogue triples from the collected data.",2.4 Dialogue Triples,[0],[0]
All U2 are aligned with self-report emotion annotation by the participants.,2.4 Dialogue Triples,[0],[0]
A recurrent neural network (RNN) is a neural network variant that can retain information over sequential data.,3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"In response generation, first, an encoder summarizes an input sequence into a vector representation.",3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
An input sequence at time t is modeled using the information gathered by the RNN up to time t,3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"− 1, contained in the hidden state ht.",3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"Afterwards, a decoder recurrently pre-
dicts the output sequence conditioned by ht and its output from the previous time step.",3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"This architecture was previously proposed as neural conversational model in (Vinyals and Le, 2015).
",3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"Based on the two-hierarchy view of dialogue, the hierarchical recurrent encoder-decoder (HRED) extends the sequence-to-sequence architecture (Serban et al., 2016).",3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
It consists of three RNNs.,3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"An utterance encoder recurrently processes each token in the utterance, encoding it into a vector respresentation hutt.",3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"This information is then passed on to the dialogue encoder, which encodes the sequence of dialogue turns into hdlg.",3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"The utterance decoder, or the response generator, takes hdlg, and then predicts the probability distribution over the tokens in the next utterance.
",3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"Recently, the HRED architecture has been extended to Emo-HRED for the positive emotion elicitation task, exploiting the hierarchical view of dialogue to observe the conversational context of an emotion occurrence (Lubis et al., 2018).",3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
EmoHRED incorporates an emotion encoder which predicts user emotional state and passes this information to the response generation process.,3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"The emotion encoder is placed in the same hierarchy as the dialogue encoder, capturing emotion information at dialogue-turn level hemo and maintaining the emotion context history throughout the dialogue.",3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"Improved naturalness and a more positive emotional impact were reported in the evaluations of Emo-HRED, however the resulting system is still limited to short and generic responses with positive affect.",3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"This echoes the long standing lack-of-diversity problem in neural network based response generation (Li et al., 2016), which is also shared by other models previously discussed.",3 Recurrent Encoder-Decoder for Dialogue Systems,[0],[0]
"In constructing an emotionally intelligent system, learning from expert actions and responses are essential.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"Although statistical learning from raw data has been shown to be sufficient in some cases, it might not be so for positive emotion elicitation task.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"Due to the absence of large scale data, additional knowledge from higher level abstraction, such as dialogue action labels, may be highly beneficial.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"We hypothesize that these labels will reduce data sparsity by categorizing counselor responses and emphasizing this information in the
training and generation process.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"However, procuring such labels is not a trivial task.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"Human annotation is not a practical solution as it is expensive, time-consuming, and labor intensive.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"Especially with subjective aspects such as dialogue act labels, they are often less reliable due to low annotator agreement.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"On the other hand, training an automatic classifier from data with standard dialogue act labels will not cover actions with specific emotion-related intent that are present in the collected data.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"For example, empathy towards negative affect (“That’s sad.”) and positive affect (“I’m happy to hear that.”).
",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
We propose unsupervised clustering of counselor dialogue to obtain dialogue act labels of expert responses.,4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
We collected a total of 6384 counselor utterances from the counseling corpus.,4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
We transform the utterances into vectors by obtaining the embeddings of the words in the utterance and averaging them.,4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"We use a word2vec model pretrained on 100 billion words of Google News (Mikolov et al., 2013).",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
The word and utterance embeddings are of length 300.,4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"We then apply two clustering methods to the vectorized utterances: K-Means and Dirichlet process Gaussian mixture model (DPGMM).
",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"With K-means, we perform hierarchical clustering, starting with an initial K of 8.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
We perform K-means clustering the second time on the clusters which are larger than half the full data size.,4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"In contrast, DPGMM is a non-parametric model, i.e. it attempts to represent the data without prior definition of the model complexity.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
We use the stick-breaking construction for the DPGMM.,4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
A new data point would either join an existing cluster or start a new cluster following some probabilities.,4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
We use diagonal covariance matrices to compensate for the limited amount of data.,4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"Henceforth, we refer to the result of the clustering as cluster label.
",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
Cluster Analysis,4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
We visualize the found clusters using T-SNE in Figure 1.,4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
K-Means clustering shows distinct dialogue acts characteristic in a number of clusters it found.,4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"For example, cluster 0 in Figure 1(a) consists of various utterances signaling active listening, such as follow up questions and short back channels.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"On the other hand, cluster 2 and 6 contains utterance showing confirmation or agreement, such as utterances containing the words “yeah,” “right,” and “yes.”",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"We also obtain
smaller clusters for appreciation or thanking and non-speech sounds, such as laughter and breathing.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"The rest of the utterances which are relatively longer are grouped together in a very large cluster with 4220 members (cluster 5 in Figure 1(a)).
",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
Second clustering on cluster 5 group these utterances into smaller sub-clusters (Figure 1(b)).,4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"“I” is the most frequent word in sub-cluster 0, and “you” in sub-cluster 1.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"Some of the actions from the first clustering are re-discovered during the second clustering, such as thanking and appreciation in sub-cluster 7, and confirmation in subcluster 6.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"The largest sub-cluster is sub-cluster 2 with 1324 members which contain longer utterances, a combination of opinion, questions, and other sentences.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"In total, we obtained 15 clusters from K-means clustering.
",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"On the other hand, the DPGMM clustering results in 13 clusters.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"DPGMM clustering yield a similar result, giving one huge cluster for longer sentences and smaller clusters populated with for back channel, non-speech sounds, thank you, and agreement.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"However, there are several differences between the results from DPGMM and K-means that are worth mentioning.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"First, we notice that the characteristic of each cluster is less salient compared to that of K-Means; e.g. numerous back channels can be found in several other clusters.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"Second, the class size distribution is more uneven: there are 6 clusters with less than 100 members, in contrast to only 1 with K-Means.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"Third, unlike K-Means, re-clustering of the biggest cluster is not possible as it is already represented by one component in the model.",4.1 Unsupervised Clustering of Counselor Dialogue,[0],[0]
"We propose providing higher level knowledge about the response to the model, in form of response cluster labels (Section 4.1), to aid its re-
sponse generation.",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"We propose a neural dialogue system which generate response based on multiple dialogue contexts: 1) dialogue history, 2) user emotional state, and 3) expert’s action label.",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"Henceforth we call this model the multi-context HRED (MC-HRED)
",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
The information flow of the MC-HRED is as follows.,4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"After reading the input sequence Um = {wm,1, ..., wm,Nm}, the dialogue turn is encoded into utterance representation hutt.
",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
hutt = h utt,4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"Nm = f(h utt Nm−1, wm,Nm).",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"(1)
hutt is then fed into the dialogue encoder to model the sequence of dialogue turns into dialogue context hdlg.
",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
hdlg = h,4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
dlg m = f(h,4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"dlg m−1, hutt).",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"(2)
In MC-HRED, the hdlg is then fed into the emotion and action encoders, which will then be used to encode the emotion context hemo as well as the expert action label hact.
",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"henc = f(h enc m−1, henc), (3)
where enc = {emo, act}.",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"The generation process of the response, Um+1, is conditioned by the concatenation of the three contexts: dialogue history, emotion context, and the expert action label.
",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"Pθ(wn+1 = v|w≤n) = exp(g(concat(hdlg, hemo, hact), v))∑ v′ exp(g(concat(hdlg, hemo, hact), v′)) .",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"(4)
Figure 2 shows a schematic view of this architecture.",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"For each the emotion and action encoders, we consider an RNN with gated recurrent unit (GRU) cells and sigmoid activation function.
",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
Both encoders are trained together with the rest of the network.,4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"Each encoder has its own target vector, which is the emotion label of the currently processed dialogue turn U emom and expert action label of the target response Uactm .",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"We modify the definition of the training cost to incorporate the cross entropy losses of the emotion and action encoders.
",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
costenc = ((1− U encm ) · log(1− f(henc))),4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"− (U encm · logf(henc)), (5)
where enc = {emo, act}.",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"The training cost of the MC-HRED is a linear interpolation between the response generation error costutt (i.e. negative log-likelihood of the generated response) and the prediction errors of the encoders costemo and costact with weights α and β which decays after every epoch.
",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
cost = (1− α− β) · costutt + α · costemo + β · costact.,4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
"(6)
The final cost is then propagated to the network and the parameters are optimized as usual with the optimizer algorithm.",4.2 Hierarchical Neural Dialogue System with Multiple Contexts,[0],[0]
Figure 3 illustrates the experimental set up of this work.,5 Experimental Set Up,[0],[0]
Each of the steps will be explained in this section.,5 Experimental Set Up,[0],[0]
The scope of this study is limited to text data.,5 Experimental Set Up,[0],[0]
"Previous works have demonstrated the effectiveness of large scale conversational data in improving the quality of dialogue systems (Banchs and Li, 2012; Ameixa et al., 2014; Serban et al., 2016).",5.1 Pre-trained model,[0],[0]
"In this study, we make use of SubTle (Ameixa et al., 2014), a large scale conversational corpus collected from movie subtitles, to learn the syntactic and semantic knowledge for response generation.",5.1 Pre-trained model,[0],[0]
"The use of movie subtitles is particularly suitable as they are available in large amounts and reflecting natural human communication.
",5.1 Pre-trained model,[0],[0]
"In our experiments, we utilize the HRED trained on the SubTle corpus as our starting model.",5.1 Pre-trained model,[0],[0]
"We follow the data pre-processing method in (Serban et al., 2016).",5.1 Pre-trained model,[0],[0]
"The processed SubTle corpus contained 5,503,741 query-answer pairs in total.",5.1 Pre-trained model,[0],[0]
The triple format is forced onto the pairs by treating the last dialogue turn in the triple as empty.,5.1 Pre-trained model,[0],[0]
"We select the 10,000 most frequent token from the combination of SubTle and the counseling data as system vocabulary.",5.1 Pre-trained model,[0],[0]
"The purpose is twofold: to help widen the intersection of words between the two corpora, and to preserve special token from the counselor corpus such as laughter and other non-speech sounds.
",5.1 Pre-trained model,[0],[0]
"The model is pre-trained by feeding the SubTle dataset sequentially into the network until it converges, taking approximately 2 days to complete.",5.1 Pre-trained model,[0],[0]
"In addition to the model parameters, we also learn the word embeddings of the tokens.",5.1 Pre-trained model,[0],[0]
"We used word embeddings with size 300, utterance vectors of size 600, and dialogue vectors of size 1200.",5.1 Pre-trained model,[0],[0]
"The parameters are randomly initialized, and then trained to optimize the log-likelihood of the training triples using the Adam optimizer.",5.1 Pre-trained model,[0],[0]
"All the models considered in this study are the result of fine-tuning the pre-trained model with the
counseling corpus (Section 2).",5.2 Fine-tuning,[0],[0]
The triples from the corpus are fed sequentially into the network.,5.2 Fine-tuning,[0],[0]
"To investigate the effectiveness of the proposed methods, we train multiple models with combinations of set ups.
",5.2 Fine-tuning,[0],[0]
We consider two different models: Emo-HRED as baseline model and MC-HRED as the proposed model.,5.2 Fine-tuning,[0],[0]
"Emo-HRED considers only dialogue history and emotional context during the response generation, while MC-HRED considers expert action context in addition to the dialogue history and emotional context.",5.2 Fine-tuning,[0],[0]
"For completeness, we also train a model that only utilized dialogue history and action context, which we will call ClustHRED for convenience.
",5.2 Fine-tuning,[0],[0]
"As emotional context, we encode the selfreport emotion annotation into a one-hot vector as follows.",5.2 Fine-tuning,[0],[0]
We first obtain the average valence and arousal values of an utterance.,5.2 Fine-tuning,[0],[0]
"We then discretize these values respectively into three classes: positive, neutral, and negative.",5.2 Fine-tuning,[0],[0]
"The intervals for the classes are [−1,−0.07] for negative, (−0.07, 0.07) for neutral, and [0.07, 1] for positive.",5.2 Fine-tuning,[0],[0]
"We then encode this class information into a one-hot vector of length 9, one element for each of the possible combinations of valence and arousal classes, i.e. positive-positive, positiveneutral, neutral-negative, etc.",5.2 Fine-tuning,[0],[0]
"Preliminary experiments showed that on the counselor corpus, this representation leads to a better performance compared to fixed-length sampling of the emotion trace.
",5.2 Fine-tuning,[0],[0]
"As action context, we simply encode the cluster label of U3, obtain as in Section 4.1, into a one-hot vector.",5.2 Fine-tuning,[0],[0]
"We experimented with two cluster label sets, one produced by hierarchical K-Means clustering (15 clusters), and one by DPGMM clustering (13).
",5.2 Fine-tuning,[0],[0]
"To accommodate this additional information during fine-tuning, we append new randomly initialized parameters to the utterance decoder.",5.2 Fine-tuning,[0],[0]
These parameters are trained exclusively during the finetuning process.,5.2 Fine-tuning,[0],[0]
All models are fine-tuned selectively.,5.2 Fine-tuning,[0],[0]
"That is, we fix the utterance and dialogue encoders parameters, and selectively train only the proposed encoders as well as the decoder.",5.2 Fine-tuning,[0],[0]
"This has been shown to result in a more stable model when fine-tuning with a small amount of data (Lubis et al., 2018).
",5.2 Fine-tuning,[0],[0]
"We partitioned the counseling corpus into 50 recording sessions (5053 triples) for training, 5
(503) for validation, and 5 (508) for testing.",5.2 Fine-tuning,[0],[0]
"We calculate model perplexity, which measures the probability of exactly regenerating the reference response in a triple.",6.1 Perplexity,[0],[0]
"Since the target responses are assumed to be expert’s response, its reproduction by the model is desirable.",6.1 Perplexity,[0],[0]
"Perplexity has also been previously recommended for evaluating generative dialogue systems (Pietquin and Hastie, 2013).
",6.1 Perplexity,[0],[0]
We compute the perplexity for each triple and average it to obtain model perplexity.,6.1 Perplexity,[0],[0]
The model perplexities are summarized in Table 1.,6.1 Perplexity,[0],[0]
"We compute the average test triple length (59.6 tokens), and group the test triples into two: those with below average length as “short” (294 triples), and those above as “long” (186).",6.1 Perplexity,[0],[0]
"Average perplexities are shown for the entire test set (all), the short group, and the long group, separately.
",6.1 Perplexity,[0],[0]
We obtain model with the lowest perplexity when emotion and K-Means labels are both utilized in the training and response generation process.,6.1 Perplexity,[0],[0]
"For all models, the perplexity of long triples is consistently higher than that of short ones.",6.1 Perplexity,[0],[0]
"More significant improvement is observed on long test triples.
",6.1 Perplexity,[0],[0]
"Looking at the perplexity on all test triples, interestingly, the two cluster labels are affected in starkly different ways when combined with emotion labels: K-Means gain significant improvement, while DPGMM slightly suffers.",6.1 Perplexity,[0],[0]
"We found that on long triples, Clust-HRED and MCHRED yield similar performances when using the DPGMM cluster label.",6.1 Perplexity,[0],[0]
"In contrast, when using Kmeans label, MC-HRED shows further improvement from Clust-HRED.
",6.1 Perplexity,[0],[0]
"We separate the test triples based on the average model perplexity to analyze their properties.
",6.1 Perplexity,[0],[0]
"Aside from triple length, no other significant difference was observed.",6.1 Perplexity,[0],[0]
This signals that the ability to capture context is one of the defining characteristic of a strong model for this task.,6.1 Perplexity,[0],[0]
"We present human judges with a dialogue triple and ask them to rate the response in terms of three criteria: 1) naturalness, which evaluates whether the response is intelligible, logically follows the dialogue context, and resembles real human response, 2) emotional impact, to measure whether the response elicits a positive emotional impact or promotes an emotionally positive conversation, and 3) engagement, to evaluate whether the proposed response shows involvement in the dialogue and promotes longer conversation by inviting more response.
",6.2 Human Subjective Evaluation,[0],[0]
We evaluate Emo-HRED and the best performing MC-HRED utilizing K-Means clustering labels.,6.2 Human Subjective Evaluation,[0],[0]
"We evaluate 100 triples from the full test set, where each is judged by 20 human evaluators.",6.2 Human Subjective Evaluation,[0],[0]
"Each triple is presented in A-B-A format, the first two dialogue turns are held fixed according to the test set, and the last turn is the response generated by the evaluated model.",6.2 Human Subjective Evaluation,[0],[0]
"Evaluators are asked to judge the responses by stating their agreement to three statements: 1) A gives a natural response, 2)",6.2 Human Subjective Evaluation,[0],[0]
"A’s response elicits a positive emotional impact in B, and 3) A’s response in engaging.",6.2 Human Subjective Evaluation,[0],[0]
"The agreement is given using a Likert scale, ranging from 1 (strongly disagree) to 5 (strongly agree).",6.2 Human Subjective Evaluation,[0],[0]
"Figure 4 summarizes the subjective evaluation result.
",6.2 Human Subjective Evaluation,[0],[0]
We observe slight improvement on MC-HRED in the emotional impact and a more notable one in the engagement metric.,6.2 Human Subjective Evaluation,[0],[0]
"On average, the responses generated by MC-HRED are 2.53 words longer compared to that of Emo-HRED.",6.2 Human Subjective Evaluation,[0],[0]
"From the ratings, we also found that engagement is moderately correlated with response length, with an average Pearson r of 0.41.",6.2 Human Subjective Evaluation,[0],[0]
"This signals that MC-
HRED is able to produce longer sentences which results in higher engagement, while still maintaining naturalness and emotional impact.",6.2 Human Subjective Evaluation,[0],[0]
Dialogue samples comparing the systems responses are included in Table 2.,6.2 Human Subjective Evaluation,[0],[0]
We construct a corpus containing recordings of a counselor and 30 participants following a negative emotional exposure to learn expert responses in a positive emotion elicitation scenario.,7 Conclusion,[0],[0]
We unsupervisedly cluster the expert’s responses and use the resulting labels to train a dialogue system.,7 Conclusion,[0],[0]
"We proposed a novel hierarchical neural architecture for response generation that is conditioned on 1) expert’s action, 2) dialogue context, and 3) user emotion, encoded from user input.
",7 Conclusion,[0],[0]
The objective evaluation we conducted show that the proposed model yields lower perplexity on a held-out test set.,7 Conclusion,[0],[0]
Subsequent human subjective evaluation shows that MC-HRED is able to produce longer sentences which improve engagement while still maintaining response naturalness and emotional impact.,7 Conclusion,[0],[0]
"In the future, we would like to consider emotional impact explicitly for the emotion elicitation in lieu of a data-driven approach of positive emotion elicitation.",7 Conclusion,[0],[0]
"We would also like to consider other modalitiesm such as speech, for a richer emotion encoding.",7 Conclusion,[0],[0]
We acknowledge that evaluation through real user interaction needs to be carried in the future to test the system in a more realistic scenario.,7 Conclusion,[0],[0]
Part of this work was supported by JSPS KAKENHI Grant Numbers JP17H06101 and JP17K00237.,Acknowledgements,[0],[0]
"Positive emotion elicitation seeks to improve user’s emotional state through dialogue system interaction, where a chatbased scenario is layered with an implicit goal to address user’s emotional needs.",abstractText,[0],[0]
"Standard neural dialogue system approaches still fall short in this situation as they tend to generate only short, generic responses.",abstractText,[0],[0]
"Learning from expert actions is critical, as these potentially differ from standard dialogue acts.",abstractText,[0],[0]
"In this paper, we propose using a hierarchical neural network for response generation that is conditioned on 1) expert’s action, 2) dialogue context, and 3) user emotion, encoded from user input.",abstractText,[0],[0]
We construct a corpus of interactions between a counselor and 30 participants following a negative emotional exposure to learn expert actions and responses in a positive emotion elicitation scenario.,abstractText,[0],[0]
"Instead of relying on the expensive, labor intensive, and often ambiguous human annotations, we unsupervisedly cluster the expert’s responses and use the resulting labels to train the network.",abstractText,[0],[0]
Our experiments and evaluation show that the proposed approach yields lower perplexity and generates a larger variety of responses.,abstractText,[0],[0]
Unsupervised Counselor Dialogue Clustering for Positive Emotion Elicitation in Neural Dialogue System,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2465–2474 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2465",text,[0],[0]
"Word embeddings are well known to capture meaningful representations of words based on large text corpora (Mikolov et al., 2013; Pennington et al., 2014).",1 Introduction,[0],[0]
Training word vectors using monolingual corpora is a common practice in various NLP tasks.,1 Introduction,[0],[0]
"However, how to establish cross-lingual semantic mapping among mono-
lingual embeddings remain an open challenge as the availability of resources and benchmarks are highly imbalanced across languages.
",1 Introduction,[0],[0]
"Recently, increasing effort of research has been motivated to address this challenge.",1 Introduction,[0],[0]
"Successful cross-lingual word mapping will benefit many cross-lingual learning tasks, such as transforming text classification models trained in resourcerich languages to low-resource languages.",1 Introduction,[0],[0]
"Downstream applications include word alignment, text classification, named entity recognition, dependency parsing, POS-tagging, and more (Søgaard et al., 2015).",1 Introduction,[0],[0]
"Most methods for cross-lingual transfer of word embeddings are based on supervised or semi-supervised learning, i.e., they require cross-lingual supervision such as humanannotated bilingual lexicons and parallel corpora (Lu et al., 2015; Smith et al., 2017; Artetxe et al., 2016).",1 Introduction,[0],[0]
"Such a requirement may not be met for many language pairs in the real world.
",1 Introduction,[0],[0]
"This paper proposes an unsupervised approach to the cross-lingual transfer of monolingual word embeddings, which requires zero cross-lingual supervision.",1 Introduction,[0],[0]
"The key idea is to optimize the mapping in both directions for each language pair (say A and B), in the way that the word embedding translated from language A to language B will match the distribution of word embedding in language B.",1 Introduction,[0],[0]
"And when translated back from B to A, the word embedding after two steps of transfer will be maximally close to the original word embedding.",1 Introduction,[0],[0]
A similar property holds for the other direction of the loop (from B to A and then from A back to B).,1 Introduction,[0],[0]
"Specifically, we use the Sinkhorn distance (Cuturi, 2013) to capture the distributional similarity between two set of embeddings after transformation, which we found empirically superior to the KL-divergence (Zhang et al., 2017a) and distance to nearest neighbor (Artetxe et al., 2017; Conneau et al., 2017) with regards to the quality of learned
transformation as well as the robustness under different training conditions.
",1 Introduction,[0],[0]
"Our novel contributions in the proposed work include:
• We propose an unsupervised learning framework which incorporates the Sinkhorn distance as a distributional similarity measure in the back-translation loss function.",1 Introduction,[0],[0]
"• We use a neural network to optimize our
model, especially to implement the Sinkhorn distance whose calculation itself is an optimization problem.",1 Introduction,[0],[0]
"• Unlike previous models which only consider
cross-lingual transformation in a single direction, our model jointly learns the word embedding transfer in both directions for each language pair.",1 Introduction,[0],[0]
"• We present an intensive comparative evalua-
tion where our model achieved the state-ofthe-art performance for many language pairs in cross-lingual tasks.",1 Introduction,[0],[0]
We divide the related work into supervised and unsupervised categories.,2 Related Work,[0],[0]
Representative methods in both categories are included in our comparative evaluation (Section 3.4).,2 Related Work,[0],[0]
"We also discuss some related work in unsupervised domain transfer in addition.
",2 Related Work,[0],[0]
"Supervised Methods: There is a rich body of supervised methods for learning cross-lingual transfer of word embeddings based on bilingual dictionaries (Mikolov et al., 2013; Faruqui and Dyer, 2014; Artetxe et al., 2016; Xing et al., 2015; Duong et al., 2016; Gouws and Søgaard, 2015), sentence-aligned corpora (Kočiskỳ et al., 2014; Hermann and Blunsom, 2014; Gouws et al., 2015) and document-aligned corpora (Vulić and Moens, 2016; Søgaard et al., 2015).",2 Related Work,[0],[0]
The most relevant line of work is that by Mikolov et al. (2013) where they showed monolingual word embeddings are likely to share similar geometric properties across languages although they are trained separately and hence cross-lingual mapping can be captured by a linear transformation across embedding spaces.,2 Related Work,[0],[0]
"Several follow-up studies tried to improve the cross-lingual transformation in various ways (Faruqui and Dyer, 2014; Artetxe et al., 2016; Xing et al., 2015; Duong et al., 2016; Ammar et al., 2016; Artetxe et al., 2016; Zhang et al.,
2016; Shigeto et al., 2015).",2 Related Work,[0],[0]
"Nevertheless, all these methods require bilingual lexicons for supervised learning.",2 Related Work,[0],[0]
"Vulić and Korhonen (2016) showed that 5000 high-quality bilingual lexicons are sufficient for learning a reasonable cross-lingual mapping.
",2 Related Work,[0],[0]
Unsupervised Methods have been studied to establish cross-lingual mapping without any humanannotated supervision.,2 Related Work,[0],[0]
"Earlier work simply relied on word occurrence information only (Rapp, 1995; Fung, 1996) while later efforts have considered more sophisticated statistics in addition (Haghighi et al., 2008).",2 Related Work,[0],[0]
"The main difficulty in unsupervised learning of cross-lingual mapping is the formulation of the objective function, i.e., how to measure the goodness of an induced mapping without any supervision is a non-trivial question.",2 Related Work,[0],[0]
Cao et al. (2016) tried to match the mean and standard deviation of the embedded word vectors in two different languages after mapping the words in the source language to the target language.,2 Related Work,[0],[0]
"However, such an approach has shown to be sub-optimal because the objective function only carries the first and second order statistics of the mapping.",2 Related Work,[0],[0]
Artetxe et al. (2017) tried to impose an orthogonal constraint to their linear transformation model and minimize the distance between the transferred source-word embedding and its nearest neighbor in the target embedding space.,2 Related Work,[0],[0]
"Their method, however, requires a seed bilingual dictionary as the labeled training data and hence is not fully unsupervised.",2 Related Work,[0],[0]
"(Zhang et al., 2017a; Barone, 2016) adapted a generative adversarial network (GAN) to make the transferred embedding of each source-language word indistinguishable from its true translation in the target embedding space (Goodfellow et al., 2014).",2 Related Work,[0],[0]
"The adversarial model could be optimized in a purely unsupervised manner but is often suffered from unstable training, i.e. the adversarial learning does not always improve the performance over simpler baselines.",2 Related Work,[0],[0]
"Zhang et al. (2017b), Conneau et al. (2017) and Artetxe et al. (2017) also tried adversarial approaches for the induction of seed bilingual dictionaries, as a sub-problem in the crosslingual transfer of word embedding.
",2 Related Work,[0],[0]
"Unsupervised Domain Transfer: Generally speaking, learning the cross-lingual transfer of word embedding can be viewed as a domain transfer problem, where the domains are word sets in different languages.",2 Related Work,[0],[0]
"Thus various work in the
field of unsupervised domain adaptation or unsupervised transfer learning can shed light on our problem.",2 Related Work,[0],[0]
"For example, He et al. (2016) proposed a semi-supervised method for machine translation to utilize large monolingual corpora.",2 Related Work,[0],[0]
Shen et al. (2017) used unsupervised learning to transfer sentences of different sentiments.,2 Related Work,[0],[0]
"Recent work in computer vision addresses the problem of image style transfer without any annotated training data (Zhu et al., 2017; Taigman et al., 2016; Yi et al., 2017).",2 Related Work,[0],[0]
"Among those, our work is mostly inspired by the work on CycleGAN (Zhu et al., 2017), and we adopt their cycled consistent loss over images into our back-translation loss.",2 Related Work,[0],[0]
"One key difference of our method from CycleGAN is that they used the training loss of an adversarial classifier as an indicator of the distributional distance, but instead, we introduce the Sinkhorn distance in our objective function and demonstrate its superiority over the representative method using adversarial loss (Zhang et al., 2017a).",2 Related Work,[0],[0]
"Our system takes two sets of monolingual word embeddings of dimension d as input, which are trained separately on two languages.",3 Proposed Method,[0],[0]
"We denote them as X = {xi}ni=1, Y = {yj}mj=1, xi, yj ∈ Rd.",3 Proposed Method,[0],[0]
"During the training of monolingual word embedding for X and Y , we also have the access to the word frequencies, represented by vectors r ∈",3 Proposed Method,[0],[0]
Nn and c ∈,3 Proposed Method,[0],[0]
"Nm for X and Y , respectively.",3 Proposed Method,[0],[0]
"Specifically, ri is the frequency for word (embedding) xi and similarly for cj of yj .",3 Proposed Method,[0],[0]
"As illustrated in Figure 3, our model has two mappings: G : X → Y and F : Y → X .",3 Proposed Method,[0],[0]
We further denote transferred embedding from X as G(X),3 Proposed Method,[0],[0]
":= {G(xi)}ni=1 and correspondingly for F (Y ).
",3 Proposed Method,[0],[0]
"In the unsupervised setting, the goal is to learn the mapping G and F without any paired word translation.",3 Proposed Method,[0],[0]
"To achieve this, our loss function consists of two parts: Sinkhorn distance (Cuturi, 2013) for matching the distribution of transferred embedding to its target embedding distribution; and a back-translation loss for preventing degenerated transformation.",3 Proposed Method,[0],[0]
Sinkhorn distance is a recently proposed distance between probability distributions.,3.1.1 Definition,[0],[0]
"We use the Sinkhorn distance to measure the closeness be-
.
",3.1.1 Definition,[0],[0]
"tween G(X) and Y , and also between F (Y ) and X .",3.1.1 Definition,[0],[0]
"During the training, our model optimizes G and F for lower Sinkhorn distance to make the transferred embeddings match the distribution of the target embeddings.",3.1.1 Definition,[0],[0]
"Here we only illustrate the Sinkhorn distance between G(X) and Y , the derivation for F (Y ) and X is very similar.",3.1.1 Definition,[0],[0]
"Although the vocabulary sizes of two languages could be different, we are able to sample minibatches of equal size from G(X) and Y .",3.1.1 Definition,[0],[0]
"therefore we assume n = m in the following derivation.
",3.1.1 Definition,[0],[0]
"To compute Sinkhorn distance, we firstly compute a distance matrix M (G) ∈ Rn×m between G(X) and Y where M (G)ij is the distance measure between G(xi) and yj .",3.1.1 Definition,[0],[0]
The superscript on M (G) indicates the distance that depends on a parameterized transformation G.,3.1.1 Definition,[0],[0]
"For instance, if we choose Euclidean distance as a measure (see Section 3.1.3 for more discussions), we will have
M (G) ij = ‖G(xi)− yj‖2.
",3.1.1 Definition,[0],[0]
"Given the distance matrix, the Sinkhorn distance between PG(X) and PY is defined as:
dsh(G) := min P∈Uα(r,c)
〈P,M (G)〉 (1)
where 〈·, ·〉 is the Forbenius dot-product and Uα(r, c) is an entropy constrained transport poly-
",3.1.1 Definition,[0],[0]
"Algorithm 1 Computation of Sinkhorn Distance dsh(G)
1: procedure SINKHORN(M (G), r, c, λ, I) 2: K(G) :",3.1.1 Definition,[0],[0]
= e−λM (G) 3: v = 1m/m .,3.1.1 Definition,[0],[0]
normalized one vector 4: i = 0 5:,3.1.1 Definition,[0],[0]
while i < I do .,3.1.1 Definition,[0],[0]
"iterate for I times 6: u = r./K(G)v 7: v = c./K(G) T u
8: i = i+ 1 9: dsh(G) = u T ((K(G) ⊗M",3.1.1 Definition,[0],[0]
"(G))v)
10: return dsh(G) .",3.1.1 Definition,[0],[0]
"The Sinkhorn distance
tope, defined as
Uα(r, c) = {P ∈",3.1.1 Definition,[0],[0]
"R+n×m|P1m = r, P T1n = c, h(P ) ≤ h(r) +",3.1.1 Definition,[0],[0]
"h(c)− α} (2)
Note that P is non-negative and the first two constraints make its element-wise sum be 1.",3.1.1 Definition,[0],[0]
"Therefore, P can be seen as a set of probability distributions.",3.1.1 Definition,[0],[0]
The same applies for r and c since they are frequencies.,3.1.1 Definition,[0],[0]
h is the entropy function defined on any probability distributions and α is a hyperparameter to choose.,3.1.1 Definition,[0],[0]
"For any probabilistic matrix P ∈ Uα(r, c), it can be viewed as the joint probability of (G(X), Y ).",3.1.1 Definition,[0],[0]
The first two constraints ensure that P has marginal distribution on G(X) as PG(X) and on Y as PY .,3.1.1 Definition,[0],[0]
"We can also view Pij as the evidence for establishing a translation between word vector xi and word vector yj .
",3.1.1 Definition,[0],[0]
"An intuitive interpretation of equation (1) is that we are trying to find the optimal transport probability P under the entropy constraint such that the total distance to transport from G(X) to Y is minimized.
",3.1.1 Definition,[0],[0]
"3.1.2 Computing Sinkhorn Distance dsh(G) Cuturi (2013) showed that the optimal solution of formula (1) has the form P ∗ = diag(u)Kdiag(v) , where u and v are some nonnegative vectors and K(G) := e−λM (G) ; λ is the Lagrange multiplier for the entropic constraint in 2 and each α in Equation (1) has one corresponding λ.",3.1.1 Definition,[0],[0]
The Sinkhorn distance can be efficiently computed by a matrix scaling algorithm.,3.1.1 Definition,[0],[0]
We present the pseudo code in Algorithm 1.,3.1.1 Definition,[0],[0]
Note that the computation of dsh(G) only requires matrixvector multiplication.,3.1.1 Definition,[0],[0]
"Therefore, we can compute and back propagate the gradient of dsh(G) with regards to the parameters in G using standard deep
learning libraries.",3.1.1 Definition,[0],[0]
We show our implementation details in Section 3.4 and supplementary material.,3.1.1 Definition,[0],[0]
"In Section 3.1.1, we used the Euclidean distance of vector pairs to define M (G) and Sinkhorn distance dsh(G).",3.1.3 Choice of the Distance Metric,[0],[0]
"However, in our preliminary experiment, we found that Euclidean distance of unnormalized vectors gave poor performance.",3.1.3 Choice of the Distance Metric,[0],[0]
"Therefore, following the common practice, we normalize all word embedding vectors to have a unit L2 norm in the construction of M (G).
",3.1.3 Choice of the Distance Metric,[0],[0]
"As pointed out in Theorem 1 of Cuturi (2013), M (G) must be a valid metric in order to make dsh(G) a valid metric.",3.1.3 Choice of the Distance Metric,[0],[0]
"For example, the commonly used cosine distance, which is defined as CosDist(a, b) = 1− cos(a, b), is not a valid metric because it does not satisfy triangle inequality 1.",3.1.3 Choice of the Distance Metric,[0],[0]
"Thus, for constructing M (G), we propose the square root cosine distance (SqrtCosDist) below:
SqrtCosDist(a, b) := √ 2− 2cos(a, b) (3)
M (G) ij = SqrtCosDist(G(xi), yj) (4)
Theorem 1.",3.1.3 Choice of the Distance Metric,[0],[0]
"SqrtCosDist is a valid metric.
",3.1.3 Choice of the Distance Metric,[0],[0]
Proof.,3.1.3 Choice of the Distance Metric,[0],[0]
"∀a, b ∈ Rd, let â = a‖a‖ , b̂ = b ‖b‖ .",3.1.3 Choice of the Distance Metric,[0],[0]
"We have cos(a, b) = 〈â, b̂〉 and 〈â, â〉 = 〈b̂, b̂〉 = 1.",3.1.3 Choice of the Distance Metric,[0],[0]
"Then
SqrtCosDist(a, b)",3.1.3 Choice of the Distance Metric,[0],[0]
"= √ 2− 2cos(a, b)
",3.1.3 Choice of the Distance Metric,[0],[0]
"= √ 〈â, â〉+ 〈b̂, b̂〉 − 2〈â, b̂〉
= √ 〈â− b̂, â− b̂〉
= ‖â−",3.1.3 Choice of the Distance Metric,[0],[0]
"b̂‖
Obviously, the last term is the Euclidean distance between normalized input vectors â and b̂. Since Euclidean distance is a valid metric, it follows that SqrtCosDist satisfies all the axioms for a valid metric.",3.1.3 Choice of the Distance Metric,[0],[0]
"Given enough capacity, G is capable to transfer X to Y for arbitrary word-to-word mappings.",3.2 Objective Function,[0],[0]
"To ensure that, we learn a meaningful translation and also to regularize the search space of possible transformations, we enforce the word embedding after the forward and the backward transformation
1If we select a =",3.2 Objective Function,[0],[0]
"[1, 0], b = [ √ 2 2 , √ 2 2 ], c =",3.2 Objective Function,[0],[0]
"[0, 1] We have CosDist(a, c) ≥ CosDist(a, b) +",3.2 Objective Function,[0],[0]
"CosDist(b, c) , which violates the triangle inequality.
should not diverge much from its original direction.",3.2 Objective Function,[0],[0]
"We simply choose the back-translation loss based on the cosine similarity:
dbt(G,F ) =",3.2 Objective Function,[0],[0]
"∑ i
1− cos(xi, F (G(xi)))+∑ j 1− cos(yi, G(F (yi)))",3.2 Objective Function,[0],[0]
"(5)
where cos is the cosine similarity.",3.2 Objective Function,[0],[0]
"Putting everything together, we minimize the following objective function.
",3.2 Objective Function,[0],[0]
"LX,Y,r,c(G,F ) = dsh(G)+ dsh(F )",3.2 Objective Function,[0],[0]
"+ βdbt(G,F ) (6) where hyper-parameter β controls the relative weight of the last term against the first two terms in the objective function.",3.2 Objective Function,[0],[0]
"By definition, computation of dsh(G) or dsh(F ) involves another minimization problem as shown in Equation (1).",3.2 Objective Function,[0],[0]
"We solve it using the matrix scaling algorithm in Section 3.1.2, and treat dsh(G) as a deterministic and differentiable function of parameters in G. The same holds for dsh(F ) and F .",3.2 Objective Function,[0],[0]
"In preliminary experiments, we found that our objective 6 is sensitive to the initialization of the weight in G and F in the purely unsupervised setting.",3.3 Wasserstein GAN Training for Good Initial Point,[0],[0]
It requires a good initial setting of the parameters to avoid getting stuck in the poor local minimal.,3.3 Wasserstein GAN Training for Good Initial Point,[0],[0]
"To address this sensitivity issue, we employed a similar approach as in (Zhang et al., 2017b; Aldarmaki et al., 2018) to firstly used an adversarial training approach to learnG and F and use them as the initial point for training our full objective 6.",3.3 Wasserstein GAN Training for Good Initial Point,[0],[0]
"More specifically, we choose to minimize the optimal transport distance below.
dot(G) := min P∈U(r,c)
〈P,M (G)〉 (7)
",3.3 Wasserstein GAN Training for Good Initial Point,[0],[0]
"U is the transport polytope without entropy constraint, defined as follows.
",3.3 Wasserstein GAN Training for Good Initial Point,[0],[0]
U = {P ∈,3.3 Wasserstein GAN Training for Good Initial Point,[0],[0]
"R+n×m|P1m = r, P T1n = c} (8)
We optimize the distance above by its dual form and through adversarial training, which is also known as Wasserstein GAN (WGAN) (Arjovsky et al., 2017).",3.3 Wasserstein GAN Training for Good Initial Point,[0],[0]
"We applied the optimization trick proposed by Gulrajani et al. (2017).
",3.3 Wasserstein GAN Training for Good Initial Point,[0],[0]
"Although the first phase of adversarial training could be unstable, and the performance is lower than using the Sinkhorn distance, the adversarial training narrows down the search space of model parameters and boosting the training of our proposed model.",3.3 Wasserstein GAN Training for Good Initial Point,[0],[0]
We implemented transformation G and F by a linear transformation.,3.4 Implementation,[0],[0]
The dimension of the input and output are the same with the word embedding dimension d.2,3.4 Implementation,[0],[0]
"For all the experiments in the subsequent section, the β in (6) was set to be 0.1.",3.4 Implementation,[0],[0]
"For hyper-parameters from the computation of Sinkhorn distance, we choose λ = 10 and run the matrix scaling algorithm for 20 iterations.",3.4 Implementation,[0],[0]
"Due to the space constraint, a detailed implementation description is presented in the supplementary material.",3.4 Implementation,[0],[0]
The code of our implementation is publicly available 3.,3.4 Implementation,[0],[0]
We conducted an evaluation of our approach in comparison with state-of-the-art supervised/unsupervised methods on several evaluation benchmarks for bilingual lexicon induction (Task 1) and word similarity prediction (Task 2).,4 Experiments,[0],[0]
We include our main results in this section and report the ablation study in the supplementary material.,4 Experiments,[0],[0]
All the methods being evaluated in both tasks take monolingual word embedding in each language as the input data.,4.1.1 Monolingual Word Embedding Data,[0],[0]
"We use publicly available pretrained word embeddings trained on Wikipedia articles: (1) a smaller set of word embeddings of dimension 50 trained on comparable Wikipedia dump in five languages (Zhang et al., 2017a)4 and (2) a larger set of word embeddings of dimension 300 trained on Wikipedia dump in 294 languages (Bojanowski et al., 2016)5.",4.1.1 Monolingual Word Embedding Data,[0],[0]
"For conve-
2We tried more complex non-linear transformations for G and F .",4.1.1 Monolingual Word Embedding Data,[0],[0]
"The performance is slightly worse than the linear case.
",4.1.1 Monolingual Word Embedding Data,[0],[0]
"3Our implementation https: //github.com/xrc10/ unsup-cross-lingual-embedding-transfer
4Available at http://nlp.csai.tsinghua.edu.",4.1.1 Monolingual Word Embedding Data,[0],[0]
"cn/˜zm/UBiLexAT
5Available at https://github.com/ facebookresearch/fastText/blob/master/ pretrained-vectors.md
nience, we name the two sets WE-Z and WE-C, respectively.",4.1.1 Monolingual Word Embedding Data,[0],[0]
We need true translation pairs of words for evaluating methods in bilingual lexicon induction (Task 1).,4.1.2 Bilingual Lexicon Data,[0],[0]
"We followed previous studies and prepared two datasets below.
",4.1.2 Bilingual Lexicon Data,[0],[0]
LEX-Z: Zhang et al. (2017a) constructed the bilingual lexicons from various resources.,4.1.2 Bilingual Lexicon Data,[0],[0]
"Since their ground truth word pairs are not released, we followed their procedure, crawled bilingual dictionaries and randomly separated them into the training and testing set of equal size.6 Note that our proposed method did not utilize the training set.",4.1.2 Bilingual Lexicon Data,[0],[0]
It was only used by supervised baseline methods described in Section 4.2.,4.1.2 Bilingual Lexicon Data,[0],[0]
There are eight language pairs (order counted); the corresponding dataset statistics are summarized in Table 1.,4.1.2 Bilingual Lexicon Data,[0],[0]
"We use WEZ embeddings in this dataset.
LEX-C:",4.1.2 Bilingual Lexicon Data,[0],[0]
This lexicon was constructed by Conneau et al. (2017) and contains more translation pairs than LEX-Z. They divided them into training and testing set.,4.1.2 Bilingual Lexicon Data,[0],[0]
We run our model and the baseline methods on 16 language pairs.,4.1.2 Bilingual Lexicon Data,[0],[0]
"For each language pair, the training set contains 5, 000 unique query words and the testing set has 1, 500 query words.",4.1.2 Bilingual Lexicon Data,[0],[0]
"We followed Conneau et al. (2017) and set the search space of candidate translations to be the 200, 000 most frequent words in each target language.",4.1.2 Bilingual Lexicon Data,[0],[0]
We use WE-C embeddings in this dataset.,4.1.2 Bilingual Lexicon Data,[0],[0]
For bilingual word similarity prediction (Task 2) we need the true labels for evaluation.,4.1.3 Bilingual Word Similarity Data,[0],[0]
"Following Conneau et al. (2017), we used the SemEval 2017 competition dataset, where human annotators measured the cross-lingual similarity of nominal word pairs according to the five-point Likert scale.",4.1.3 Bilingual Word Similarity Data,[0],[0]
"This dataset contains word pairs across five languages: English (en), German (de), Spanish (es), Italian (it), and Farsi (fa).",4.1.3 Bilingual Word Similarity Data,[0],[0]
"Each language pair has about 1,000 word pairs annotated with a real similarity score ranging from 0 to 4.",4.1.3 Bilingual Word Similarity Data,[0],[0]
"We evaluated the same set of supervised and unsupervised baselines for comparative evaluation in
6The bilingual dictionaries we crawled are submitted as supplementary material.
both Task 1 and Task 2.",4.2 Baseline Methods,[0],[0]
"The supervised baselines include the methods of Shigeto et al. (2015); Zhang et al. (2016); Artetxe et al. (2016); Xing et al. (2015); Mikolov et al. (2013); Artetxe et al. (2017).7 We fed all the supervised methods with the bilingual dictionaries in the training portions of the LEX-Z and LEX-C datasets, respectively.
",4.2 Baseline Methods,[0],[0]
"For unsupervised baselines we include the methods of Zhang et al. (2017a) and Conneau et al. (2017), whose source code is publicly available as provided by the authors.8",4.2 Baseline Methods,[0],[0]
Bilingual lexicon induction is a task to induce a translation in the target language for each query word in the source language.,4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"After the query word and the target-language words are represented in the same embedding space (or after our system maps the query word from the source embedding space to the target embedding space), the k nearest target words are retrieved based on their cosine similarity scores with respect to the query vector.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"If the k retrieved target words contain any valid translation according to the gold bilingual lexicon, the translation (retrieval) is considered successful.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"The fraction of the correctly translated source words in the test set is defined as accuracy@k,
7The implementations are available from https:// github.com/artetxem/vecmap.
",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"8We used implementation by Zhang et al. (2017a) from http://nlp.csai.tsinghua.edu.cn/˜zm/ UBiLexAT and that of Conneau et al. (2017) from https: //github.com/facebookresearch/MUSE
Methods tr-en en-tr es-en en-es zh-en en-zh it-en en-it
Supervised
Mikolov et al. (2013) 19.41 10.81 68.73 41.19 45.88 45.37 59.83 41.26 Zhang et al. (2016) 23.39 11.07 72.36 41.19 48.01 42.66 63.19 40.37 Xing et al. (2015) 24.00 10.78 71.92 41.02 48.10 42.90 62.81 40.43 Shigeto et al. (2015) 26.56 8.52 72.23 37.80 49.95 38.15 63.14 35.63 Artetxe et al. (2016) 23.49 10.74 71.98 41.12 48.01 42.66 63.14 40.28 Artetxe et al. (2017) 22.88 10.78 72.61 41.62 47.54 42.82 61.32 39.63
Unsupervised Conneau et al. (2017) 4.09 1.41 60.16 33.58 41.98 34.70 26.98 15.47 Zhang et al. (2017a)",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"15.83 7.41 63.41 37.73 42.08 41.26 54.75 37.17 Ours 23.29 9.96 73.05 41.95 49.03 44.63 61.42 39.63
Table 2",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
": The accuracy@k scores of all methods in bilingual lexicon induction on LEX-Z. The best score for each language pair is bold-faced for the supervised and unsupervised categories, respectively.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Language pair ”A-B” means query words are in language A and the search space of word translations is in language B. Languages are paired among English(en), Turkish (tr), Spanish (es), Chinese (zh) and Italian (it).
",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Methods bg-en en-bg ca-en en-ca sv-en en-sv lv-en en-lv
Supervised
Mikolov et al. (2013) 44.80 48.47 57.73 66.20 43.73 63.73 26.53 28.93 Zhang et al. (2016)",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"50.60 39.73 63.40 58.73 50.87 53.93 34.53 22.87 Xing et al. (2015) 50.33 40.00 63.40 58.53 51.13 53.73 34.27 21.60 Shigeto et al. (2015) 61.00 33.80 69.33 53.60 61.27 41.67 42.20 13.87 Artetxe et al. (2016) 53.27 43.40 65.27 60.87 54.07 55.93 35.80 26.47 Artetxe et al. (2017) 47.27 34.40 61.27 56.73 38.07 44.20 24.07 12.20
Unsupervised Conneau et al. (2017) 26.47 13.87 41.00 33.07 24.27 24.47 - - Zhang et al. (2017a) - - - - - - - - Ours 50.33 34.27 58.60 54.60 48.13 50.47 27.73 13.53
Table 3: The accuracy@k scores of all methods in bilingual lexicon induction on LEX-C. The best score for each language pair is bold-faced for the supervised and unsupervised categories, respectively.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Languages are paired among English(en), Bulgarian(bg), Catalan(ca), Swedish(sv) and Latvian(lv).",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"”-” means that during the training time, the model failed to converge to reasonable local minimal and hence the result is omitted in the table.
which is conventional metric in benchmark evaluations.
",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
Table 2 shows the accuracy@1 for all the methods on LEX-Z in our evaluation.,4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
We can see that our method outperformed the other unsupervised baselines by a large margin on all the eight language pairs.,4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Compared with the supervised methods, our method is still competitive (the best or the second-best scores on four out of eight language pairs), even ours does not require cross-lingual supervision.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Also, we notice the performance variance over different language pairs.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Our method outperforms all the methods (supervised and unsupervised combined) on the English-Spanish (enes) pair, perhaps for the reasons that these two languages are most similar to each other, and that the monolingual word embeddings for this pair
in the comparable corpus are better aligned than the other language pairs.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"On the other hand, all the methods including ours have the worst performance on the English-Turkish (en-tr) pair.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
Another observation is the performance differences in the two directions of the language pair.,4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"For example, the performance of it-en is better than en-it for all methods in table 2.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
A part of the reason is that there are more unique English words than nonEnglish words in the evaluation set.,4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
This would cause direction “xx-en” to be easier than ”en-xx” because there are often multiple valid ground truth English translations for each query in “xx”.,4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
But the same may not hold for the opposite direction of “en-xx”.,4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Nevertheless, the relative performance of our method compared to others is quite robust over different language pairs and different directions of
Methods de-en en-de es-en en-es fr-en en-fr it-en en-it
Supervised
Mikolov et al. (2013) 61.93 73.07 74.00 80.73 71.33 82.20 68.93 77.60 Zhang et al. (2016) 67.67 69.87 77.27 78.53 76.07 78.20 72.40 73.40 Xing et al. (2015) 67.73 69.53 77.20 78.60 76.33 78.67 72.00 73.33 Shigeto et al. (2015) 71.07 63.73 81.07 74.53 79.93 73.13 76.47 68.13 Artetxe et al. (2016) 69.13 72.13 78.27 80.07 77.73 79.20 73.60 74.47 Artetxe et al. (2017) 68.07 69.20 75.60 78.20 74.47 77.67 70.53 71.67
Unsupervised Conneau et al. (2017) 69.87 71.53 78.53 79.40 77.67 78.33 74.60 75.80 Zhang et al. (2017a) - - - - - - - - Ours 67.00 69.33 77.80 79.53 75.47 77.93 72.60 73.47
Table 4:",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"The accuracy@k scores of all methods in bilingual lexicon induction on LEX-C. The best score for each language pair is bold-faced for the supervised and unsupervised categories, respectively.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Languages are paired among English (en), German (de), Spanish (es), French (fr) and Italian (it).",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"”-” means that during the training time, the model failed to converge to reasonable local minimal and hence the result is omitted in the table.
",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
translation.,4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
Table 3 and Table 4 summarize the results of all the methods on the LEX-C dataset.,4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
Several points may be worth noticing.,4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Firstly, the performance scores on LEX-C are not necessarily consistent with those on LEX-Z (Table 2) even if the methods and the language pairs are the same; this is not surprising as the two datasets differ in query words, word embedding quality, and training-set sizes.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Secondly, the performance gap between the best supervised methods and the best unsupervised methods in both Table 3 and Table 4 are larger than that in Table 2.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"This is attributed to the large amount of good-quality supervision in LEX-C (5,000 human-annotated word pairs) and the larger candidate size in WE-C (200, 000 candidates).",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Thirdly, the average performance in Table 3 is lower than that in Table 4, indicating that the language pairs in the former are more difficult than that in the latter.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Nevertheless, we can see that our method has much stronger performance than other unsupervised methods in Table 3, i.e., on the harder language pairs, and that it performed comparably with the model by Conneau et al. (2017) in Table 4 on the easier language pairs.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"Combining all these observations, we see that our method is highly robust for various language pairs and under different training conditions.",4.3 Results in Bilingual Lexicons Induction (Task 1),[0],[0]
"We evaluate models on cross-lingual word similarity prediction (Task 2) to measure how much the predicted cross-language word similarities match
Methods de-en es-en fa-en it-en
Supervised
Mikolov et al. (2013) 0.71 0.72 0.68 0.71 Zhang et al. (2016) 0.71 0.71 0.69 0.71 Xing et al. (2015) 0.72 0.71 0.69 0.72",4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
Shigeto et al. (2015) 0.72 0.72 0.69 0.71,4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
Artetxe et al. (2016) 0.73 0.72 0.70 0.73,4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
"Artetxe et al. (2017) 0.70 0.70 0.67 0.71
Unsupervised Conneau et al. (2017) 0.71 0.71 0.68 0.71 Zhang et al. (2017a) - - - - Ours 0.71 0.71 0.67 0.71
Table 5: Performance (measured using Pearson correlation) of all the methods in cross-lingual semantic word similarity prediction on the benchmark data from Conneau et al. (2017).",4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
"The best score in the supervised and unsupervised category is bold-faced, respectively.",4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
"The languages include English (en), German (de), Spanish (es), Persian (fa) and Italian (it).",4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
"”-” means that the model failed to converge to reasonable local minimal during the training process.
",4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
the ground truth annotated by humans.,4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
"Following the convention in benchmark evaluations for this task, we compute the Pearson correlation between the model-induced similarity scores and the human-annotated similarity scores over testing word pairs for each language pair.",4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
A higher correlation score with the ground truth represents the better quality of induced embeddings.,4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
"All systems use the cosine similarity between the transformed embedding of each query and the word embedding of its paired translation as the predicted similarity score.
",4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
Table 5 summarizes the performance of all the methods in cross-lingual word similarity prediction.,4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
"We can see that the unsupervised methods,
including ours, perform equally well as the supervised methods, which is highly encouraging.",4.4 Results in Cross-lingual Word Similarity Prediction (Task 2),[0],[0]
"In this paper, we presented a novel method for cross-lingual transformation of monolingual embeddings in an unsupervised manner.",5 Conclusion,[0],[0]
By simultaneously optimizing the bi-directional mappings w.r.t.,5 Conclusion,[0],[0]
"Sinkhorn distances and back-translation losses on both ends, our model enjoys its prediction power as well as robustness, with the impressive performance on multiple evaluation benchmarks.",5 Conclusion,[0],[0]
"For future work, we would like to extend this work in the semi-supervised setting where insufficient bilingual dictionaries are available.",5 Conclusion,[0],[0]
We thank the reviewers for their helpful comments.,Acknowledgments,[0],[0]
"This work is supported in part by Defense Advanced Research Projects Agency Information Innovation Oce (I2O), the Low Resource Languages for Emergent Incidents (LORELEI) Program, Issued by DARPA/I2O under Contract No. HR0011-15-C-0114, and in part by the National Science Foundation (NSF) under grant IIS1546329.",Acknowledgments,[0],[0]
Cross-lingual transfer of word embeddings aims to establish the semantic mappings among words in different languages by learning the transformation functions over the corresponding word embedding spaces.,abstractText,[0],[0]
Successfully solving this problem would benefit many downstream tasks such as to translate text classification models from resource-rich languages (e.g. English) to low-resource languages.,abstractText,[0],[0]
"Supervised methods for this problem rely on the availability of cross-lingual supervision, either using parallel corpora or bilingual lexicons as the labeled data for training, which may not be available for many low resource languages.",abstractText,[0],[0]
This paper proposes an unsupervised learning approach that does not require any cross-lingual labeled data.,abstractText,[0],[0]
"Given two monolingual word embedding spaces for any language pair, our algorithm optimizes the transformation functions in both directions simultaneously based on distributional matching as well as minimizing the backtranslation losses.",abstractText,[0],[0]
"We use a neural network implementation to calculate the Sinkhorn distance, a well-defined distributional similarity measure, and optimize our objective through back-propagation.",abstractText,[0],[0]
Our evaluation on benchmark datasets for bilingual lexicon induction and cross-lingual word similarity prediction shows stronger or competitive performance of the proposed method compared to other stateof-the-art supervised and unsupervised baseline methods over many language pairs.,abstractText,[0],[0]
Unsupervised Cross-lingual Transfer of Word Embedding Spaces,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1098–1107 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1098",text,[0],[0]
"Classic dialog systems rely on developing a meaning representation to represent the utterances from both the machine and human users (Larsson and Traum, 2000; Bohus et al., 2007).",1 Introduction,[0],[0]
"The dialog manager of a conventional dialog system outputs the system’s next action in a semantic frame that usually contains hand-crafted dialog acts and slot values (Williams and Young, 2007).",1 Introduction,[0],[0]
Then a natural language generation module is used to generate the system’s output in natural language based on the given semantic frame.,1 Introduction,[0],[0]
"This approach suffers from generalization to more complex domains because it soon become intractable to man-
1Data and code are available at https://github. com/snakeztc/NeuralDialog-LAED.
ually design a frame representation that covers all of the fine-grained system actions.",1 Introduction,[0],[0]
The recently developed neural dialog system is one of the most prominent frameworks for developing dialog agents in complex domains.,1 Introduction,[0],[0]
"The basic model is based on encoder-decoder networks (Cho et al., 2014) and can learn to generate system responses without the need for hand-crafted meaning representations and other annotations.
",1 Introduction,[0],[0]
"Although generative dialog models have advanced rapidly (Serban et al., 2016; Li et al., 2016; Zhao et al., 2017), they cannot provide interpretable system actions as in the conventional dialog systems.",1 Introduction,[0],[0]
This inability limits the effectiveness of generative dialog models in several ways.,1 Introduction,[0],[0]
"First, having interpretable system actions enables human to understand the behavior of a dialog system and better interpret the system intentions.",1 Introduction,[0],[0]
"Also, modeling the high-level decision-making policy in dialogs enables useful generalization and dataefficient domain adaptation (Gašić et al., 2010).",1 Introduction,[0],[0]
"Therefore, the motivation of this paper is to develop an unsupervised neural recognition model that can discover interpretable meaning representations of utterances (denoted as latent actions) as a set of discrete latent variables from a large unlabelled corpus as shown in Figure 1.",1 Introduction,[0],[0]
"The discovered meaning representations will then be integrated with encoder decoder networks to achieve interpretable dialog generation while preserving
all the merit of neural dialog systems.",1 Introduction,[0],[0]
"We focus on learning discrete latent representations instead of dense continuous ones because discrete variables are easier to interpret (van den Oord et al., 2017) and can naturally correspond to categories in natural languages, e.g. topics, dialog acts and etc.",1 Introduction,[0],[0]
"Despite the difficulty of learning discrete latent variables in neural networks, the recently proposed Gumbel-Softmax offers a reliable way to back-propagate through discrete variables (Maddison et al., 2016; Jang et al., 2016).",1 Introduction,[0],[0]
"However, we found a simple combination of sentence variational autoencoders (VAEs) (Bowman et al., 2015) and Gumbel-Softmax fails to learn meaningful discrete representations.",1 Introduction,[0],[0]
We then highlight the anti-information limitation of the evidence lowerbound objective (ELBO) in VAEs and improve it by proposing Discrete Information VAE (DI-VAE) that maximizes the mutual information between data and latent actions.,1 Introduction,[0],[0]
"We further enrich the learning signals beyond auto encoding by extending Skip Thought (Kiros et al., 2015) to Discrete Information Variational Skip Thought (DI-VST) that learns sentence-level distributional semantics.",1 Introduction,[0],[0]
"Finally, an integration mechanism is presented that combines the learned latent actions with encoder decoder models.
",1 Introduction,[0],[0]
The proposed systems are tested on several realworld dialog datasets.,1 Introduction,[0],[0]
Experiments show that the proposed methods significantly outperform the standard VAEs and can discover meaningful latent actions from these datasets.,1 Introduction,[0],[0]
"Also, experiments confirm the effectiveness of the proposed integration mechanism and show that the learned latent actions can control the sentence-level attributes of the generated responses and provide humaninterpretable meaning representations.",1 Introduction,[0],[0]
Our work is closely related to research in latent variable dialog models.,2 Related Work,[0],[0]
"The majority of models are based on Conditional Variational Autoencoders (CVAEs) (Serban et al., 2016; Cao and Clark, 2017) with continuous latent variables to better model the response distribution and encourage diverse responses.",2 Related Work,[0],[0]
"Zhao et al., (2017) further introduced dialog acts to guide the learning of the CVAEs.",2 Related Work,[0],[0]
"Discrete latent variables have also been used for task-oriented dialog systems (Wen et al., 2017), where the latent space is used to represent intention.",2 Related Work,[0],[0]
"The second line of related work
is enriching the dialog context encoder with more fine-grained information than the dialog history.",2 Related Work,[0],[0]
"Li et al., (2016) captured speakers’ characteristics by encoding background information and speaking style into the distributed embeddings.",2 Related Work,[0],[0]
"Xing et al., (2016) maintain topic encoding based on Latent Dirichlet Allocation (LDA) (Blei et al., 2003) of the conversation to encourage the model to output more topic coherent responses.
",2 Related Work,[0],[0]
The proposed method also relates to sentence representation learning using neural networks.,2 Related Work,[0],[0]
"Most work learns continuous distributed representations of sentences from various learning signals (Hill et al., 2016), e.g. the Skip Thought learns representations by predicting the previous and next sentences (Kiros et al., 2015).",2 Related Work,[0],[0]
"Another area of work focused on learning regularized continuous sentence representation, which enables sentence generation by sampling the latent space (Bowman et al., 2015; Kim et al., 2017).",2 Related Work,[0],[0]
There is less work on discrete sentence representations due to the difficulty of passing gradients through discrete outputs.,2 Related Work,[0],[0]
"The recently developed Gumbel Softmax (Jang et al., 2016; Maddison et al., 2016) and vector quantization (van den Oord et al., 2017) enable us to train discrete variables.",2 Related Work,[0],[0]
"Notably, discrete variable models have been proposed to discover document topics (Miao et al., 2016) and semi-supervised sequence transaction (Zhou and Neubig, 2017)
",2 Related Work,[0],[0]
Our work differs from these as follows: (1) we focus on learning interpretable variables; in prior research the semantics of latent variables are mostly ignored in the dialog generation setting.,2 Related Work,[0],[0]
"(2) we improve the learning objective for discrete VAEs and overcome the well-known posterior collapsing issue (Bowman et al., 2015; Chen et al., 2016).",2 Related Work,[0],[0]
(3) we focus on unsupervised learning of salient features in dialog responses instead of hand-crafted features.,2 Related Work,[0],[0]
"Our formulation contains three random variables: the dialog context c, the response x and the latent action z.",3 Proposed Methods,[0],[0]
The context often contains the discourse history in the format of a list of utterances.,3 Proposed Methods,[0],[0]
The response is an utterance that contains a list of word tokens.,3 Proposed Methods,[0],[0]
"The latent action is a set of discrete variables that define high-level attributes of x. Before introducing the proposed framework, we first identify two key properties that are essential in or-
der for z to be interpretable:
1.",3 Proposed Methods,[0],[0]
"z should capture salient sentence-level features about the response x.
2.",3 Proposed Methods,[0],[0]
"The meaning of latent symbols z should be independent of the context c.
The first property is self-evident.",3 Proposed Methods,[0],[0]
The second can be explained: assume z contains a single discrete variable with K classes.,3 Proposed Methods,[0],[0]
"Since the context c can be any dialog history, if the meaning of each class changes given a different context, then it is difficult to extract an intuitive interpretation by only looking at all responses with class k ∈",3 Proposed Methods,[0],[0]
"[1,K].",3 Proposed Methods,[0],[0]
"Therefore, the second property looks for latent actions that have context-independent semantics so that each assignment of z conveys the same meaning in all dialog contexts.
",3 Proposed Methods,[0],[0]
"With the above definition of interpretable latent actions, we first introduce a recognition network R : qR(z|x) and a generation network G.",3 Proposed Methods,[0],[0]
The role of R is to map an sentence to the latent variable z and the generator G defines the learning signals that will be used to train z’s representation.,3 Proposed Methods,[0],[0]
"Notably, our recognition network R does not depend on the context c as has been the case in prior work (Serban et al., 2016).",3 Proposed Methods,[0],[0]
"The motivation of this design is to encourage z to capture context-independent semantics, which are further elaborated in Section 3.4.",3 Proposed Methods,[0],[0]
"With the z learned by R and G, we then introduce an encoder decoder network F : pF(x|z, c) and and a policy network π : pπ(z|c).",3 Proposed Methods,[0],[0]
"At test time, given a context c, the policy network and encoder decoder will work together to generate the next response via x̃ = pF(x|z ∼ pπ(z|c), c).",3 Proposed Methods,[0],[0]
"In short, R, G, F and π are the four components that comprise our proposed framework.",3 Proposed Methods,[0],[0]
The next section will first focus on developing R and G for learning interpretable z and then will move on to integrating R with F and π in Section 3.3.,3 Proposed Methods,[0],[0]
Our baseline model is a sentence VAE with discrete latent space.,3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
We use an RNN as the recognition network to encode the response x.,3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
Its last hidden state hR|x| is used to represent x.,3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
"We define z to be a set of K-way categorical variables z = {z1...zm...zM}, where M is the number of variables.",3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
"For each zm, its posterior distribution is defined as qR(zm|x) =",3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
"Softmax(WqhR|x| + bq).
",3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
"During training, we use the Gumbel-Softmax trick to sample from this distribution and obtain lowvariance gradients.",3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
"To map the latent samples to the initial state of the decoder RNN, we define {e1...",3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
em...eM} where em ∈ RK×D and D is the generator cell size.,3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
Thus the initial state of the generator is: hG0 = ∑M m=1 em(zm).,3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
"Finally, the generator RNN is used to reconstruct the response given hG0 .",3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
"VAEs is trained to maxmimize the evidence lowerbound objective (ELBO) (Kingma and Welling, 2013).",3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
"For simplicity, later discussion drops the subscript m in zm and assumes a single latent z. Since each zm is independent, we can easily extend the results below to multiple variables.",3.1 Learning Sentence Representations from Auto-Encoding,[0],[0]
It is well-known that sentence VAEs are hard to train because of the posterior collapse issue.,3.1.1 Anti-Information Limitation of ELBO,[0],[0]
"Many empirical solutions have been proposed: weakening the decoder, adding auxiliary loss etc.",3.1.1 Anti-Information Limitation of ELBO,[0],[0]
"(Bowman et al., 2015; Chen et al., 2016; Zhao et al., 2017).",3.1.1 Anti-Information Limitation of ELBO,[0],[0]
We argue that the posterior collapse issue lies in ELBO and we offer a novel decomposition to understand its behavior.,3.1.1 Anti-Information Limitation of ELBO,[0],[0]
"First, instead of writing ELBO for a single data point, we write it as an expectation over a dataset:
LVAE = Ex[EqR(z|x)[log pG(x|z)]",3.1.1 Anti-Information Limitation of ELBO,[0],[0]
"− KL(qR(z|x)‖p(z))]
(1)
We can expand the KL term as Eq. 2 (derivations in Appendix A.1) and rewrite ELBO as:
Ex[KL(qR(z|x)‖p(z))]",3.1.1 Anti-Information Limitation of ELBO,[0],[0]
"= (2) I(Z,X)+KL(q(z)‖p(z))
",3.1.1 Anti-Information Limitation of ELBO,[0],[0]
LVAE =Eq(z|x)p(x)[log p(x|z)],3.1.1 Anti-Information Limitation of ELBO,[0],[0]
"− I(Z,X)− KL(q(z)‖p(z)) (3)
where q(z) = Ex[qR(z|x)] and I(Z,X) is the mutual information between Z and X .",3.1.1 Anti-Information Limitation of ELBO,[0],[0]
"This expansion shows that the KL term in ELBO is trying to reduce the mutual information between latent variables and the input data, which explains why VAEs often ignore the latent variable, especially when equipped with powerful decoders.",3.1.1 Anti-Information Limitation of ELBO,[0],[0]
"A natural solution to correct the anti-information issue in Eq. 3 is to maximize both the data likeli-
hood lowerbound and the mutual information between z and the input data:
",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"LVAE + I(Z,X) =",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
EqR(z|x)p(x)[log pG(x|z)]− KL(q(z)‖p(z)),3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"(4)
Therefore, jointly optimizing ELBO and mutual information simply cancels out the informationdiscouraging term.",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"Also, we can still sample from the prior distribution for generation because of KL(q(z)‖p(z)).",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"Eq. 4 is similar to the objectives used in adversarial autoencoders (Makhzani et al., 2015; Kim et al., 2017).",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
Our derivation provides a theoretical justification to their superior performance.,3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"Notably, Eq. 4 arrives at the same loss function proposed in infoVAE (Zhao S et al., 2017).",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"However, our derivation is different, offering a new way to understand ELBO behavior.
",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"The remaining challenge is how to minimize KL(q(z)‖p(z)), since q(z) is an expectation over q(z|x).",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"When z is continuous, prior work has used adversarial training (Makhzani et al., 2015; Kim et al., 2017) or Maximum Mean Discrepancy (MMD) (Zhao S et al., 2017) to regularize q(z).",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
It turns out that minimizing KL(q(z)‖p(z)) for discrete z is much simpler than its continuous counterparts.,3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
Let xn be a sample from a batch of N data points.,3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"Then we have:
q(z) ≈ 1 N N∑ n=1 q(z|xn) = q′(z) (5)
where q′(z) is a mixture of softmax from the posteriors q(z|xn) of each xn.",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"We can approximate KL(q(z)‖p(z)) by:
KL(q′(z)‖p(z))",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"= K∑ k=1 q′(z = k) log q′(z = k) p(z = k)
(6)
",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
We refer to Eq. 6 as Batch Prior Regularization (BPR).,3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"When N approaches infinity, q′(z) approaches the true marginal distribution of q(z).",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"In practice, we only need to use the data from each mini-batch assuming that the mini batches are randomized.",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"Last, BPR is fundamentally different from multiplying a coefficient < 1 to anneal the KL term in VAE (Bowman et al., 2015).",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
This is because BPR is a non-linear operation log sum exp.,3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
"For later discussion, we denote our discrete infoVAE with BPR as DI-VAE.",3.1.2 VAE with Information Maximization and Batch Prior Regularization,[0],[0]
DI-VAE infers sentence representations by reconstruction of the input sentence.,3.2 Learning Sentence Representations from the Context,[0],[0]
"Past research in distributional semantics has suggested the meaning of language can be inferred from the adjacent context (Harris, 1954; Hill et al., 2016).",3.2 Learning Sentence Representations from the Context,[0],[0]
The distributional hypothesis is especially applicable to dialog since the utterance meaning is highly contextual.,3.2 Learning Sentence Representations from the Context,[0],[0]
"For example, the dialog act is a wellknown utterance feature and depends on dialog state (Austin, 1975; Stolcke et al., 2000).",3.2 Learning Sentence Representations from the Context,[0],[0]
"Thus, we introduce a second type of latent action based on sentence-level distributional semantics.
",3.2 Learning Sentence Representations from the Context,[0],[0]
"Skip thought (ST) is a powerful sentence representation that captures contextual information (Kiros et al., 2015).",3.2 Learning Sentence Representations from the Context,[0],[0]
"ST uses an RNN to encode a sentence, and then uses the resulting sentence representation to predict the previous and next sentences.",3.2 Learning Sentence Representations from the Context,[0],[0]
"Inspired by ST’s robust performance across multiple tasks (Hill et al., 2016), we adapt our DI-VAE to Discrete Information Variational Skip Thought (DI-VST) to learn discrete latent actions that model distributional semantics of sentences.",3.2 Learning Sentence Representations from the Context,[0],[0]
We use the same recognition network from DI-VAE to output z’s posterior distribution qR(z|x).,3.2 Learning Sentence Representations from the Context,[0],[0]
"Given the samples from qR(z|x), two RNN generators are used to predict the previous sentence xp and the next sentences xn.",3.2 Learning Sentence Representations from the Context,[0],[0]
"Finally, the learning objective is to maximize:
LDI-VST = EqR(z|x)p(x))[log(p n G(xn|z)p p G(xp|z))",3.2 Learning Sentence Representations from the Context,[0],[0]
"]
− KL(q(z)‖p(z))",3.2 Learning Sentence Representations from the Context,[0],[0]
(7),3.2 Learning Sentence Representations from the Context,[0],[0]
We now describe how to integrate a given qR(z|x) with an encoder decoder and a policy network.,3.3 Integration with Encoder Decoders,[0],[0]
Let the dialog context c be a sequence of utterances.,3.3 Integration with Encoder Decoders,[0],[0]
Then a dialog context encoder network can encode the dialog context into a distributed representation he = Fe(c).,3.3 Integration with Encoder Decoders,[0],[0]
"The decoder Fd can generate the responses x̃ = Fd(he, z) using samples from qR(z|x).",3.3 Integration with Encoder Decoders,[0],[0]
"Meanwhile, we train π to predict the aggregated posterior Ep(x|c)[qR(z|x)] from c via maximum likelihood training.",3.3 Integration with Encoder Decoders,[0],[0]
"This model is referred as Latent Action Encoder Decoder (LAED) with the following objective.
",3.3 Integration with Encoder Decoders,[0],[0]
"LLAED(θF , θπ) = EqR(z|x)p(x,c)[logpπ(z|c) + log pF(x|z, c)]",3.3 Integration with Encoder Decoders,[0],[0]
"(8)
Also simply augmenting the inputs of the decoders with latent action does not guarantee that the generated response exhibits the attributes of the give action.",3.3 Integration with Encoder Decoders,[0],[0]
"Thus we use the controllable text generation framework (Hu et al., 2017) by introducing LAttr, which reuses the same recognition network qR(z|x) as a fixed discriminator to penalize the decoder if its generated responses do not reflect the attributes in z.
LAttr(θF) =",3.3 Integration with Encoder Decoders,[0],[0]
"EqR(z|x)p(c,x)[log qR(z|F(c, z))]",3.3 Integration with Encoder Decoders,[0],[0]
"(9) Since it is not possible to propagate gradients through the discrete outputs at Fd at each word step, we use a deterministic continuous relaxation (Hu et al., 2017) by replacing output of Fd with the probability of each word.",3.3 Integration with Encoder Decoders,[0],[0]
Let ot be the normalized probability at step t ∈,3.3 Integration with Encoder Decoders,[0],[0]
"[1, |x|], the inputs to qR at time t are then the sum of word embeddings weighted by ot, i.e. hRt = RNN(hRt−1,Eot) and E is the word embedding matrix.",3.3 Integration with Encoder Decoders,[0],[0]
"Finally this loss is combined with LLAED and a hyperparameter λ to have Attribute Forcing LAED.
",3.3 Integration with Encoder Decoders,[0],[0]
LattrLAED = LLAED,3.3 Integration with Encoder Decoders,[0],[0]
+ λLAttr,3.3 Integration with Encoder Decoders,[0],[0]
(10),3.3 Integration with Encoder Decoders,[0],[0]
"It is not hard to see LLAED is closely related to the objective of CVAEs for dialog generation (Serban et al., 2016; Zhao et al., 2017), which is:
LCVAE = Eq[log p(x|z, c)]−KL(q(z|x, c)‖p(z|c)) (11) Despite their similarities, we highlight the key differences that prohibit CVAE from achieving interpretable dialog generation.",3.4 Relationship with Conditional VAEs,[0],[0]
"First LCVAE encourages I(x, z|c) (Agakov, 2005), which learns z that capture context-dependent semantics.",3.4 Relationship with Conditional VAEs,[0],[0]
"More intuitively, z in CVAE is trained to generate x via p(x|z, c) so the meaning of learned z can only be interpreted along with its context c.",3.4 Relationship with Conditional VAEs,[0],[0]
Therefore this violates our goal of learning context-independent semantics.,3.4 Relationship with Conditional VAEs,[0],[0]
Our methods learn qR(z|x) that only depends on x and trains qR separately to ensure the semantics of z are interpretable standalone.,3.4 Relationship with Conditional VAEs,[0],[0]
The proposed methods are evaluated on four datasets.,4 Experiments and Results,[0],[0]
"The first corpus is Penn Treebank (PTB) (Marcus et al., 1993) used to evaluate sentence VAEs (Bowman et al., 2015).",4 Experiments and Results,[0],[0]
"We used
the version pre-processed by Mikolov (Mikolov et al., 2010).",4 Experiments and Results,[0],[0]
"The second dataset is the Stanford Multi-Domain Dialog (SMD) dataset that contains 3,031 human-Woz, task-oriented dialogs collected from 3 different domains (navigation, weather and scheduling) (Eric and Manning, 2017).",4 Experiments and Results,[0],[0]
"The other two datasets are chat-oriented data: Daily Dialog (DD) and Switchboard (SW) (Godfrey and Holliman, 1997), which are used to test whether our methods can generalize beyond task-oriented dialogs but also to to open-domain chatting.",4 Experiments and Results,[0],[0]
"DD contains 13,118 multi-turn human-human dialogs annotated with dialog acts and emotions.",4 Experiments and Results,[0],[0]
"(Li et al., 2017).",4 Experiments and Results,[0],[0]
"SW has 2,400 human-human telephone conversations that are annotated with topics and dialog acts.",4 Experiments and Results,[0],[0]
"SW is a more challenging dataset because it is transcribed from speech which contains complex spoken language phenomenon, e.g. hesitation, self-repair etc.",4 Experiments and Results,[0],[0]
The first experiment used PTB and DD to evaluate the performance of the proposed methods in learning discrete sentence representations.,4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"We implemented DI-VAE and DI-VST using GRURNN (Chung et al., 2014) and trained them using Adam (Kingma and Ba, 2014).",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"Besides the proposed methods, the following baselines are compared.",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
Unregularized models: removing the KL(q|p) term from DI-VAE and DI-VST leads to a simple discrete autoencoder (DAE) and discrete skip thought (DST) with stochastic discrete hidden units.,4.1 Comparing Discrete Sentence Representation Models,[0],[0]
ELBO models: the basic discrete sentence VAE (DVAE) or variational skip thought (DVST) that optimizes ELBO with regularization term KL(q(z|x)‖p(z)).,4.1 Comparing Discrete Sentence Representation Models,[0],[0]
We found that standard training failed to learn informative latent actions for either DVAE or DVST because of the posterior collapse.,4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"Therefore, KL-annealing (Bowman et al., 2015) and bag-of-word loss (Zhao et al., 2017) are used to force these two models learn meaningful representations.",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"We also include the results for VAE with continuous latent variables reported on the same PTB (Zhao et al., 2017).",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"Additionally, we report the perplexity from a standard GRU-RNN language model (Zaremba et al., 2014).
",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"The evaluation metrics include reconstruction perplexity (PPL), KL(q(z)‖p(z)) and the mutual information between input data and latent vari-
ables I(x, z).",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"Intuitively a good model should achieve low perplexity and KL distance, and simultaneously achieve high I(x, z).",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
The discrete latent space for all models are M=20 and K=10.,4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"Mini-batch size is 30.
",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"Table 1 shows that all models achieve better perplexity than an RNNLM, which shows they manage to learn meaningful q(z|x).",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"First, for autoencoding models, DI-VAE is able to achieve the best results in all metrics compared other methods.",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"We found DAEs quickly learn to reconstruct the input but they are prone to overfitting during training, which leads to lower performance on the test data compared to DI-VAE.",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"Also, since there is no regularization term in the latent space, q(z) is very different from the p(z) which prohibits us from generating sentences from the latent space.",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"In fact, DI-VAE enjoys the same linear interpolation properties reported in (Bowman et al., 2015) (See Appendix A.2).",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"As for DVAEs, it achieves zero I(x, z) in standard training and only manages to learn some information when training with KL-annealing and bag-of-word loss.",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"On the other hand, our methods achieve robust performance without the need for additional processing.",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"Similarly, the proposed DI-VST is able to achieve the lowest PPL and similar KL compared to the strongly regularized DVST.",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"Interestingly, although DST is able to achieve the highest I(x, z), but PPL is not further improved.",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"These results confirm the effectiveness of the proposed BPR in terms of regularizing q(z) while learning meaningful posterior q(z|x).
",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"In order to understand BPR’s sensitivity to batch size N , a follow-up experiment varied the batch size from 2 to 60 (If N=1, DI-VAE is equivalent to DVAE).",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"Figure 2 show that asN increases,
perplexity, I(x, z) monotonically improves, while KL(q‖p) only increases from 0 to 0.159.",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"After N > 30, the performance plateaus.",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"Therefore, using mini-batch is an efficient trade-off between q(z) estimation and computation speed.
",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
The last experiment in this section investigates the relation between representation learning and the dimension of the latent space.,4.1 Comparing Discrete Sentence Representation Models,[0],[0]
"We set a fixed budget by restricting the maximum number of modes to be about 1000, i.e. KM ≈ 1000.",4.1 Comparing Discrete Sentence Representation Models,[0],[0]
We then vary the latent space size and report the same evaluation metrics.,4.1 Comparing Discrete Sentence Representation Models,[0],[0]
Table 2 shows that models with multiple small latent variables perform significantly better than those with large and few latent variables.,4.1 Comparing Discrete Sentence Representation Models,[0],[0]
The next question is to interpret the meaning of the learned latent action symbols.,4.2 Interpreting Latent Actions,[0],[0]
"To achieve this, the latent action of an utterance xn is obtained from a greedy mapping: an = argmaxk qR(z = k|xn).",4.2 Interpreting Latent Actions,[0],[0]
"We set M=3 and K=5, so that there are at most 125 different latent actions, and each xn can now be represented by a1-a2-a3, e.g. “How are you?”",4.2 Interpreting Latent Actions,[0],[0]
→ 1-4-2.,4.2 Interpreting Latent Actions,[0],[0]
"Assuming that we have access to manually clustered data according to certain classes
(e.g. dialog acts), it is unfair to use classic cluster measures (Vinh et al., 2010) to evaluate the clusters from latent actions.",4.2 Interpreting Latent Actions,[0],[0]
"This is because the uniform prior p(z) evenly distribute the data to all possible latent actions, so that it is expected that frequent classes will be assigned to several latent actions.",4.2 Interpreting Latent Actions,[0],[0]
"Thus we utilize the homogeneity metric (Rosenberg and Hirschberg, 2007) that measures if each latent action contains only members of a single class.",4.2 Interpreting Latent Actions,[0],[0]
"We tested this on the SW and DD, which contain human annotated features and we report the latent actions’ homogeneity w.r.t these features in Table 3.",4.2 Interpreting Latent Actions,[0],[0]
"On DD, results show DI-VST
works better than DI-VAE in terms of creating actions that are more coherent for emotion and dialog acts.",4.2 Interpreting Latent Actions,[0],[0]
The results are interesting on SW since DI-VST performs worse on dialog acts than DIVAE.,4.2 Interpreting Latent Actions,[0],[0]
"One reason is that the dialog acts in SW are more fine-grained (42 acts) than the ones in DD (5 acts) so that distinguishing utterances based on words in x is more important than the information in the neighbouring utterances.
",4.2 Interpreting Latent Actions,[0],[0]
We then apply the proposed methods to SMD which has no manual annotation and contains taskoriented dialogs.,4.2 Interpreting Latent Actions,[0],[0]
Two experts are shown 5 randomly selected utterances from each latent action and are asked to give an action name that can describe as many of the utterances as possible.,4.2 Interpreting Latent Actions,[0],[0]
Then an Amazon Mechanical Turk study is conducted to evaluate whether other utterances from the same latent action match these titles.,4.2 Interpreting Latent Actions,[0],[0]
5 workers see the action name and a different group of 5 utterances from that latent action.,4.2 Interpreting Latent Actions,[0],[0]
"They are asked to select all utterances that belong to the given actions, which tests the homogeneity of the utterances falling in the same cluster.",4.2 Interpreting Latent Actions,[0],[0]
Negative samples are included to prevent random selection.,4.2 Interpreting Latent Actions,[0],[0]
"Table 4 shows that both methods work well and DI-VST achieved better homogeneity than DI-VAE.
",4.2 Interpreting Latent Actions,[0],[0]
"Since DI-VAE is trained to reconstruct its input and DI-VST is trained to model the context, they group utterances in different ways.",4.2 Interpreting Latent Actions,[0],[0]
"For example, DI-VST would group “Can I get a restaurant”, “I am looking for a restaurant” into one action where
DI-VAE may denote two actions for them.",4.2 Interpreting Latent Actions,[0],[0]
"Finally,
Table 4.2 shows sample annotation results, which show cases of the different types of latent actions discovered by our models.
",4.2 Interpreting Latent Actions,[0],[0]
"Model Action Sample utterance DI-VAE scheduling - sys: okay, scheduling a yoga
activity with Tom for the 8th at 2pm.",4.2 Interpreting Latent Actions,[0],[0]
- sys:,4.2 Interpreting Latent Actions,[0],[0]
"okay, scheduling a meeting for 6 pm on Tuesday with your boss to go over the quarterly report.
requests - usr: find out if it ’s supposed to rain - usr: find nearest coffee shop
DI-VST ask schedule info - usr: when is my football activity and who is going with me?",4.2 Interpreting Latent Actions,[0],[0]
"- usr: tell me when my dentist appointment is?
requests - usr: how about other coffee?",4.2 Interpreting Latent Actions,[0],[0]
"- usr: 11 am please
Table 5:",4.2 Interpreting Latent Actions,[0],[0]
Example latent actions discovered in SMD using our methods.,4.2 Interpreting Latent Actions,[0],[0]
Finally we implement an LAED as follows.,4.3 Dialog Response Generation with Latent Actions,[0],[0]
"The encoder is a hierarchical recurrent encoder (Serban et al., 2016) with bi-directional GRU-RNNs as the utterance encoder and a second GRU-RNN as the discourse encoder.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
The discourse encoder output its last hidden state he|x|.,4.3 Dialog Response Generation with Latent Actions,[0],[0]
The decoder is another GRU-RNN and its initial state of the decoder is obtained by hd0 = h e |x|,4.3 Dialog Response Generation with Latent Actions,[0],[0]
+ ∑M,4.3 Dialog Response Generation with Latent Actions,[0],[0]
"m=1 em(zm), where z comes from the recognition network of the proposed methods.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
The policy network π is a 2-layer multi-layer perceptron (MLP) that models pπ(z|he|x|).,4.3 Dialog Response Generation with Latent Actions,[0],[0]
"We use up to the previous 10 utterances as the dialog context and denote the LAED using DI-VAE latent actions as AE-ED and the one uses DI-VST as ST-ED.
",4.3 Dialog Response Generation with Latent Actions,[0],[0]
"First we need to confirm whether an LAED can generate responses that are consistent with the semantics of a given z. To answer this, we use a pre-trained recognition network R to check if a generated response carries the attributes in
the given action.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
"We generate dialog responses on a test dataset via x̃ = F(z ∼ π(c), c) with greedy RNN decoding.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
The generated responses are passed into the R and we measure attribute accuracy by counting x̃ as correct if z = argmaxk qR(k|x̃).,4.3 Dialog Response Generation with Latent Actions,[0],[0]
"Table 4.3 shows our generated
responses are highly consistent with the given latent actions.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
"Also, latent actions from DI-VAE achieve higher attribute accuracy than the ones from DI-VST, because z from auto-encoding is explicitly trained for x reconstruction.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
"Adding Lattr is effective in forcing the decoder to take z into account during its generation, which helps the most in more challenging open-domain chatting data, e.g. SW and DD.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
The accuracy of ST-ED on SW is worse than the other two datasets.,4.3 Dialog Response Generation with Latent Actions,[0],[0]
"The reason is that SW contains many short utterances that can be either a continuation of the same speaker or a new turn from the other speaker, whereas the responses in the other two domains are always followed by a different speaker.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
The more complex context pattern in SW may require special treatment.,4.3 Dialog Response Generation with Latent Actions,[0],[0]
"We leave it for future work.
",4.3 Dialog Response Generation with Latent Actions,[0],[0]
The second experiment checks if the policy network π is able to predict the right latent action given just the dialog context.,4.3 Dialog Response Generation with Latent Actions,[0],[0]
"We report both accuracy, i.e. argmaxk qR(k|x) = argmaxk′ pπ(k′|c) and perplexity of pπ(z|c).",4.3 Dialog Response Generation with Latent Actions,[0],[0]
"The perplexity measure is more useful for open domain dialogs because decision-making in complex dialogs is often one-to-many given a similar context (Zhao et al., 2017).",4.3 Dialog Response Generation with Latent Actions,[0],[0]
"Table 7 shows the prediction scores on
the three dialog datasets.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
"These scores provide
useful insights to understand the complexity of a dialog dataset.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
"For example, accuracy on opendomain chatting is harder than the task-oriented SMD data.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
"Also, it is intuitive that predicting system actions is easier than predicting user actions on SMD.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
"Also, in general the prediction scores for ST-ED are higher the ones for AE-ED.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
The reason is related to our previous discussion about the granularity of the latent actions.,4.3 Dialog Response Generation with Latent Actions,[0],[0]
"Since latent actions from DI-VST mainly model the the type of utterances used in certain types of context, it is easier for the policy network to predict latent actions from DI-VST.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
"Therefore, choosing the type of latent actions is a design choice and depends on the type of interpretability that is needed.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
We finish with an example generated from the two variants of LAED on SMD as shown in Table 8.,4.3 Dialog Response Generation with Latent Actions,[0],[0]
"Given a dialog context, our systems are able to output a probability distribution over different latent actions that have interpretable meaning along with their natural language realizations.",4.3 Dialog Response Generation with Latent Actions,[0],[0]
This paper presents a novel unsupervised framework that enables the discovery of discrete latent actions and interpretable dialog response generation.,5 Conclusion and Future Work,[0],[0]
"Our main contributions reside in the two sentence representation models DI-VAE and DIVST, and their integration with the encoder decoder models.",5 Conclusion and Future Work,[0],[0]
Experiments show the proposed methods outperform strong baselines in learning discrete latent variables and showcase the effectiveness of interpretable dialog response generation.,5 Conclusion and Future Work,[0],[0]
"Our findings also suggest promising future research directions, including learning better context-based latent actions and using reinforce-
ment learning to adapt policy networks.",5 Conclusion and Future Work,[0],[0]
We believe that this work is an important step forward towards creating generative dialog models that can not only generalize to large unlabelled datasets in complex domains but also be explainable to human users.,5 Conclusion and Future Work,[0],[0]
The encoder-decoder dialog model is one of the most prominent methods used to build dialog systems in complex domains.,abstractText,[0],[0]
"Yet it is limited because it cannot output interpretable actions as in traditional systems, which hinders humans from understanding its generation process.",abstractText,[0],[0]
We present an unsupervised discrete sentence representation learning method that can integrate with any existing encoderdecoder dialog models for interpretable response generation.,abstractText,[0],[0]
"Building upon variational autoencoders (VAEs), we present two novel models, DI-VAE and DI-VST that improve VAEs and can discover interpretable semantics via either auto encoding or context predicting.",abstractText,[0],[0]
Our methods have been validated on real-world dialog datasets to discover semantic representations and enhance encoder-decoder models with interpretable generation.1,abstractText,[0],[0]
Unsupervised Discrete Sentence Representation Learning for Interpretable Neural Dialog Generation,title,[0],[0]
"Grammar acquisition or grammar induction (Carroll and Charniak, 1992) has been of interest to linguists and cognitive scientists for decades.",1 Introduction,[0],[0]
"This task is interesting because a well-performing acquisition model can serve as a good baseline for examining factors of grounding (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010), or as a piece of evidence (Clark, 2001; Zuidema, 2003) about the Distributional Hypothesis (Harris, 1954) against the poverty of the stimulus (Chomsky, 1965).",1 Introduction,[0],[0]
"Unfortunately, previous attempts at inducing unbounded context-free grammars (Johnson et al., 2007; Liang
et al., 2009) converged to weak modes of a very multimodal distribution of grammars.",1 Introduction,[0],[0]
"There has been recent interest in applying cognitively- or empirically-motivated bounds on recursion depth to limit the search space of grammar induction models (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016).",1 Introduction,[0],[0]
"Ponvert et al. (2011) and Shain et al. (2016) in particular report benefits for depth bounds on grammar acquisition using hierarchical sequence models, but either without the capacity to learn full grammar rules (e.g. that a noun phrase may consist of a noun phrase followed by a prepositional phrase), or with a very large parameter space that may offset the gains of depth-bounding.",1 Introduction,[0],[0]
"This work extends the depth-bounding approach to directly induce probabilistic context-free grammars,1 which have a smaller parameter space than hierarchical sequence models, and therefore arguably make better use of the space reductions of depthbounding.",1 Introduction,[0],[0]
"This approach employs a procedure for deriving a sequence model from a PCFG (van Schijndel et al., 2013), developed in the context of a supervised learning model, and adapts it to an unsupervised setting.
",1 Introduction,[0],[0]
Results for this model on grammar acquisition from transcribed child-directed speech and newswire text exceed or are competitive with those of other models when evaluated on parse accuracy.,1 Introduction,[0],[0]
"Moreover, grammars acquired from this model demonstrate a consistent use of category labels, as shown in a noun phrase discovery task, something which has not been demonstrated by other acquisition models.
1https://github.com/lifengjin/db-pcfg
211
Transactions of the Association for Computational Linguistics, vol. 6, pp.",1 Introduction,[0],[0]
"211–224, 2018.",1 Introduction,[0],[0]
Action Editor: Xavier Carreras.,1 Introduction,[0],[0]
"Submission batch: 9/2017; Revision batch: 12/2017; Published 4/2018.
",1 Introduction,[0],[0]
c©2018 Association for Computational Linguistics.,1 Introduction,[0],[0]
Distributed under a CC-BY 4.0 license.,1 Introduction,[0],[0]
This paper describes a Bayesian Dirichlet model of depth-bounded probabilistic context-free grammar (PCFG) induction.,2 Related work,[0],[0]
"Bayesian Dirichlet models have been applied to the related area of latent variable PCFG induction (Johnson et al., 2007; Liang et al., 2009), in which subtypes of categories like noun phrases and verb phrases are induced on a given tree structure.",2 Related work,[0],[0]
"The model described in this paper is given only words and not only induces categories for constituents but also tree structures.
",2 Related work,[0],[0]
There are a wide variety of approaches to grammar induction outside the Bayesian modeling paradigm.,2 Related work,[0],[0]
"The CCL system (Seginer, 2007a) uses deterministic scoring systems to generate bracketed output of raw text.",2 Related work,[0],[0]
"UPPARSE (Ponvert et al., 2011) uses a cascade of HMM chunkers to produce syntactic structures.",2 Related work,[0],[0]
BMMM+DMV,2 Related work,[0],[0]
"(Christodoulopoulos et al., 2012) combines an unsupervised partof-speech (POS) tagger BMMM and an unsupervised dependency grammar inducer DMV (Klein and Manning, 2004).",2 Related work,[0],[0]
The BMMM+DMV system alternates between phases of inducing POS tags and inducing dependency structures.,2 Related work,[0],[0]
"A large amount work (Klein and Manning, 2002; Klein and Manning, 2004; Bod, 2006; Berg-kirkpatrick et al., 2010; Gillenwater et al., 2011; Headden et al., 2009; Bisk and Hockenmaier, 2013; Scicluna and de la Higuera, 2014; Jiang et al., 2016; Han et al., 2017) has been on grammar induction with input annotated with POS tags, mostly for dependency grammar induction.",2 Related work,[0],[0]
"Although POS tags can also be induced, this separate induction has been criticized (Pate and Johnson, 2016) for missing an opportunity to leverage information learned in grammar induction to estimate POS tags.",2 Related work,[0],[0]
"Moreover, most of these models explore a search space that includes syntactic analyses that may be extensively center embedded and therefore are unlikely to be produced by human speakers.",2 Related work,[0],[0]
"Unlike most of these approaches, the model described in this paper uses cognitively motivated bounds on the depth of human recursive processing to constrain its search of possible trees for input sentences.
",2 Related work,[0],[0]
"Some previous work uses depth bounds in the form of sequence models (Ponvert et al., 2011; Shain et al., 2016), but these either do not produce
complete phrase structure grammars (Ponvert et al., 2011) or do so at the expense of large parameter sets (Shain et al., 2016).",2 Related work,[0],[0]
"Other work implements depth bounds on left-corner configurations of dependency grammars (Noji and Johnson, 2016), but the use of a dependency grammar makes the system impractical for addressing questions of how category types such as noun phrases may be learned.",2 Related work,[0],[0]
"Unlike these, the model described in this paper induces a PCFG directly and then bounds it with a model-to-model transform, which yields a smaller space of learnable parameters and directly models the acquisition of category types as labels.
",2 Related work,[0],[0]
"Some induction models learn semantic grammars from text annotated with semantic predicates (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2012).",2 Related work,[0],[0]
"There is evidence humans use semantic bootstrapping during grammar acquisition (Naigles, 1990), but these models typically rely on a set of pre-defined universals, such as combinators (Steedman, 2000), which simplify the induction task.",2 Related work,[0],[0]
"In order to help address the question of whether such universals are indeed necessary for grammar induction, the model described in this paper does not assume any strong universals except independently motivated limits on working memory.",2 Related work,[0],[0]
"Like Noji and Johnson (2016) and Shain et al. (2016), the model described in this paper defines bounding depth in terms of memory elements required in a left-corner parse.",3 Background,[0],[0]
"A left-corner parser (Rosenkrantz and Lewis, 1970; JohnsonLaird, 1983; Abney and Johnson, 1991; Resnik, 1992) uses a stack of memory elements to store derivation fragments during incremental processing.",3 Background,[0],[0]
Each derivation fragment represents a disjoint connected component of phrase structure a/b consisting of a top sign a lacking a bottom sign b yet to come.,3 Background,[0],[0]
"For example, Figure 1 shows the derivation fragments in a traversal of a phrase structure tree for the sentence The cart the horse the man bought pulled broke.",3 Background,[0],[0]
"Immediately before processing the word man, the traversal has recognized three fragments of tree structure: two from category NP to category RC (covering the cart and the horse) and one from category NP to category N (cover-
ing the).",3 Background,[0],[0]
"Derivation fragments at every time step are numbered top-down by depth d to a maximum depth of D. A left-corner parser requires more derivation fragments — and thus more memory — to process center-embedded constructions than to process left- or right-embedded constructions, consistent with observations that center embedding is more difficult for humans to process (Chomsky and Miller, 1963; Miller and Isard, 1964).",3 Background,[0],[0]
"Grammar acquisition models (Noji and Johnson, 2016; Shain et al., 2016) then restrict this memory to some low bound, e.g. two derivation fragments.
",3 Background,[0],[0]
For sequences of observed word tokens wt for time steps t ∈,3 Background,[0],[0]
{,3 Background,[0],[0]
"1..T }, sequence models like Ponvert et al. (2011) and Shain et al. (2016) hypothesize sequences of hidden states qt.",3 Background,[0],[0]
"Models like Shain et al. (2016) implement bounded grammar rules as depth bounds on a hierarchical sequence model implementation of a left-corner parser, using random variables within each hidden state qt for:
1.",3 Background,[0],[0]
"preterminal labels pt and labels of top and bottom signs, adt and b d t , of derivation fragments
at each depth level d (which correspond to left and right children in tree structure), and
2.",3 Background,[0],[0]
"Boolean variables for decisions to ‘fork out’ ft and ‘join in’ jt derivation fragments (in
Johnson-Laird (1983) terms, to shift with or without match and to predict with or without match).
",3 Background,[0],[0]
"Probabilities from these distributions are then multiplied together to define a transition model M over hidden states:
M[qt−1,qt] = P(qt | qt−1) (1a) def = P( ft pt jt",3 Background,[0],[0]
a1..,3 Background,[0],[0]
"Dt b 1..D t | qt−1) (1b)
= P( ft | qt−1) ·P(pt | qt−1 ft) ·P( jt | qt−1 ft pt) ·P(a1..Dt | qt−1 ft pt jt) ·P(b1..",3 Background,[0],[0]
Dt | qt−1 ft pt jt,3 Background,[0],[0]
a1..Dt ).,3 Background,[0],[0]
"(1c)
",3 Background,[0],[0]
"For example, just after the word horse is recognized in Figure 1, the parser store contains two derivation fragments yielding the cart and the horse, both with top category NP and bottom category RC.",3 Background,[0],[0]
The parser then decides to fork out the next word the based on the bottom category RC of the last derivation fragment on the store.,3 Background,[0],[0]
Then the parser generates a preterminal category D for this word based on this fork decision and the bottom category of the last derivation fragment on the store.,3 Background,[0],[0]
"Then the parser decides not to join the resulting D directly to the RC above it, based on these fork and preterminal decisions and the bottom category of the store.",3 Background,[0],[0]
"Finally the parser generates NP and N as the top and bottom categories of a new derivation fragment yielding just the new word the based on all these previous decisions, resulting in the store state shown in the figure.
",3 Background,[0],[0]
"The model over the fork decision (shift with or without match) is defined in terms of a depthspecific sub-model θF,d̄, where ⊥ is an empty derivation fragment and d̄ is the depth of the deepest nonempty derivation fragment at time step t − 1:
P( ft | qt−1)def= PθF,d̄ ( ft | bd̄t−1); d̄ =maxd {b d t−1,⊥} (2)
",3 Background,[0],[0]
The model over the preterminal category label is then conditioned on this fork decision.,3 Background,[0],[0]
"When there is no fork, the preterminal category label is deterministically linked to the category label of the bottom sign of the deepest derivation fragment at the previous time step (using ~φ as a deterministic indicator function, equal to one when φ is true and zero
otherwise).",3 Background,[0],[0]
"When there is a fork, the preterminal category label is defined in terms of a depth-specific sub-model θP,d̄: 2
P(pt | qt−1 ft)def=  ~pt=bd̄t−1 if ft = 0 PθP,d̄ (pt | bd̄t−1) if ft = 1.",3 Background,[0],[0]
"(3)
The model over the join decision (predict with or without match) is also defined in terms of a depthspecific sub-model θJ,d̄ with parameters depending on the outcome of the fork decision:3
P( jt | qt−1 ft pt)def= 
PθJ,d̄",3 Background,[0],[0]
"( jt | bd̄−1t−1 ad̄t−1) if ft=0 PθJ,d̄+1( jt | bd̄t−1 pt) if ft=1.
(4)
Decisions about the top categories of derivation fragments a1..",3 Background,[0],[0]
Dt (which correspond to left siblings in tree structures) are decomposed into fork- and joinspecific cases.,3 Background,[0],[0]
"When there is a join, the top category of the deepest derivation fragment deterministically depends on the corresponding value at the previous time step.",3 Background,[0],[0]
"When there is no join, the top category is defined in terms of a depth-specific sub-model:4
PθA(a 1..D t | qt−1 ft pt jt)def= φd̄−2 · ~ad̄−1t =ad̄−1t−1 · ψd̄+0",3 Background,[0],[0]
"if ft, jt =0, 1 φd̄−1 · PθA,d̄ (ad̄t | bd̄−1t−1 ad̄t−1) · ψd̄+1 if ft, jt =0, 0 φd̄−1 ·",3 Background,[0],[0]
"~ad̄t =ad̄t−1 · ψd̄+1 if ft, jt =1, 1 φd̄−0 ·",3 Background,[0],[0]
"PθA,d̄+1(ad̄+1t | bd̄t−1 pt) · ψd̄+2 if ft, jt =1, 0.
(5)
Decisions about the bottom categories b1..",3 Background,[0],[0]
"Dt (which correspond to right children in tree structures) also depend on the outcome of the fork and join variables, but are defined in terms of a side- and depth-specific sub-model in every case:5 PθB(b 1..D t | qt−1 ft pt jt",3 Background,[0],[0]
"a1..Dt )def= φd̄−2 · PθB,R,d̄−1(bd̄−1",3 Background,[0],[0]
t,3 Background,[0],[0]
"| bd̄−1t−1 ad̄t−1) · ψd̄+0 if ft, jt =0, 1 φd̄−1 · PθB,L,d̄ (bd̄t | ad̄t ad̄t−1) · ψd̄+1 if ft, jt =0, 0 φd̄−1 ·",3 Background,[0],[0]
"PθB,R,d̄ (bd̄t | bd̄t−1 pt) · ψd̄+1 if ft, jt =1, 1 φd̄−0 · PθB,L,d̄+1(bd̄+1t | ad̄+1t pt) · ψd̄+2 if ft, jt =1, 0.
(6) 2 Here, again, d̄ =maxd{bdt−1,⊥}.",3 Background,[0],[0]
"3 Again, d̄ =maxd{bdt−1,⊥}.",3 Background,[0],[0]
4,3 Background,[0],[0]
"Here φd̄ = ~a1..d̄t = a 1..d̄ t−1 , ψd̄ = ~a d̄+1..D t = ⊥ , and again,
d̄ =maxd{bdt−1,⊥}. 5",3 Background,[0],[0]
"Here φd̄ = ~b1..d̄t = b 1..d̄ t−1 , ψd̄ = ~b d̄+1..D t = ⊥ , and again, d̄ =maxd{bdt−1,⊥}.
",3 Background,[0],[0]
"In a sequence model inducer like Shain et al. (2016), these depth-specific models are assumed to be independent of each other and fit with a Gibbs sampler, backward sampling hidden variable sequences from forward distributions using this compiled transition model M (Carter and Kohn, 1996), then counting individual sub-model outcomes from sampled hidden variable sequences, then resampling each sub-model using these counts with Dirichlet priors over a, b, and p models and Beta priors over f and j models, then re-compiling these resampled models into a new M.
However, note that with K category labels this model contains DK2 + 3DK3 separate parameters for preterminal categories and top and bottom categories of derivation fragments at every depth level, each of which can be independently learned by the Gibbs sampler.",3 Background,[0],[0]
"Although this allows the hierarchical sequence model to learn grammars that are more expressive than PCFGs, the search space is several times larger than the K3 space of PCFG nonterminal expansions.",3 Background,[0],[0]
"The model described in this paper instead induces a PCFG and derives sequence model distributions from the PCFG, which has fewer parameters, and thus strictly reduces the search space of the model.",3 Background,[0],[0]
The depth-bounded probabilistic context-free grammar (DB-PCFG) model described in this paper directly induces a PCFG and then deterministically derives the parameters of a probabilistic left-corner parser from this single source.,4 The DB-PCFG Model,[0],[0]
"This derivation is based on an existing derivation of probabilistic left-corner parser models from PCFGs (van Schijndel et al., 2013), which was developed in a supervised parsing model, adapted here to run more efficiently within a larger unsupervised grammar induction model.6
A PCFG can be defined in Chomsky normal form as a matrix G of binary rule probabilities with one row for each of K parent symbols c and one column for each of K2+W combinations of left and
6 More specifically, the derivation differs from that of van Schijndel et al. (2013) in that it removes terminal symbols from conditional dependencies of models over fork and join decisions and top and bottom category labels, substantially reducing the size of the derived model that must be run during induction.
",4 The DB-PCFG Model,[0],[0]
"right child symbols a and b, which can be pairs of nonterminals or observed words from vocabulary W followed by null symbols ⊥:7
G = ∑
a,b,c
P(c→ a b | c) δc",4 The DB-PCFG Model,[0],[0]
(δa ⊗ δb)>.,4 The DB-PCFG Model,[0],[0]
"(7)
A depth-bounded grammar is a set of side- and depth-specific distributions:
GD = {Gs,d | s ∈ {L,R}, d ∈ {1..D}}.",4 The DB-PCFG Model,[0],[0]
"(8)
The posterior probability of a depth-bounded model GD given a corpus (sequence) of words w1..T is proportional to the product of a likelihood and a prior:
",4 The DB-PCFG Model,[0],[0]
P(GD |,4 The DB-PCFG Model,[0],[0]
w1..T ) ∝,4 The DB-PCFG Model,[0],[0]
P(w1..T | GD) · P(GD).,4 The DB-PCFG Model,[0],[0]
"(9)
",4 The DB-PCFG Model,[0],[0]
"The likelihood is defined as a marginal over bounded PCFG trees τ of the probability of that tree given the grammar times the product of the probability of the word at each time step or token index t given this tree:8
P(w1..T | GD) = ∑
τ
P(τ | GD) · ∏
t
P(wt | τ).",4 The DB-PCFG Model,[0],[0]
"(10)
The probability of each tree is defined to be the product of the probabilities of each of its branches:9
P(τ | GD) = ∏
τη∈τ",4 The DB-PCFG Model,[0],[0]
PGD(τη →,4 The DB-PCFG Model,[0],[0]
τη0 τη1 | τη).,4 The DB-PCFG Model,[0],[0]
"(11)
7",4 The DB-PCFG Model,[0],[0]
"This definition assumes a Kronecker delta function δi, defined as a vector with value one at index i and zeros everywhere else, and a Kronecker product M ⊗ N over matrices M and N, which tiles copies of N weighted by values in M as follows:
M ⊗ N =  M[1,1] N M[1,2] N · · · M[2,1] N M[2,2] N · · ·
... ...
. . .",4 The DB-PCFG Model,[0],[0]
"
 ",4 The DB-PCFG Model,[0],[0]
.,4 The DB-PCFG Model,[0],[0]
"(1’)
The Kronecker product specializes to vectors as single-column matrices, generating vectors that contain the products of all combinations of elements in the operand vectors.
8",4 The DB-PCFG Model,[0],[0]
"This notation assumes the observed data w1..T is a single long sequence of words, and the hidden variable τ is a single large but depth-bounded tree structure (e.g. a right-branching discourse structure).",4 The DB-PCFG Model,[0],[0]
"Since the implementation is incremental, segmentation decisions may indeed be treated as hidden variables in τ, but the experiments described in Section 5 are run on sentence-segmented input.
",4 The DB-PCFG Model,[0],[0]
"9 Here, η is a node address, with left child η0 and right child η1, or with right child equal to ⊥ if unary.
",4 The DB-PCFG Model,[0],[0]
The probability P(GD) is itself an integral over the product of a deterministic transform φ from an unbounded grammar to a bounded grammar,4 The DB-PCFG Model,[0],[0]
"P(GD | G) = ~GD = φ(G) and a prior over unbounded grammars P(G):
P(GD) = ∫",4 The DB-PCFG Model,[0],[0]
P(GD | G) · P(G) · dG.,4 The DB-PCFG Model,[0],[0]
"(12)
Distributions P(G) for each nonterminal symbol (rows) within this unbounded grammar can then be sampled from a Dirichlet distribution with a symmetric parameter β:
G ∼ Dirichlet(β), (13)
which then yields a corresponding transformed sample in P(GD) for corresponding nonterminals.",4 The DB-PCFG Model,[0],[0]
"Note that this model is different than that of Shain et al. (2016), who induce a hierarchical HMM directly.
",4 The DB-PCFG Model,[0],[0]
A depth-specific grammar GD is (deterministically) derived from G via transform φwith probabilities for expansions constrained to and renormalized over only those outcomes that yield terminals within a particular depth bound D.,4 The DB-PCFG Model,[0],[0]
"This depth-bounded grammar is then used to derive left-corner expectations (anticipated counts of categories appearing as left descendants of other categories), and ultimately the parameters of the depth-bounded leftcorner parser defined in Section 3.",4 The DB-PCFG Model,[0],[0]
"Counts for G are then obtained from sampled hidden state sequences, and rows of G are then directly sampled from the posterior updated by these counts.",4 The DB-PCFG Model,[0],[0]
"In order to ensure the bounded version of G is a consistent probability model, it must be renormalized in transform φ to assign a probability of zero to any derivation that exceeds its depth bound D. For example, if D = 2, then it is not possible to expand a left sibling at depth 2 to anything other than a lexical item, so the probability of any non-lexical expansion must be removed from the depth-bounded model, and the probabilities of all remaining outcomes must be renormalized to a new total without this probability.",4.1 Depth-bounded grammar,[0],[0]
"Following van Schijndel et al. (2013), this can be done by iteratively defining a side- and depthspecific containment likelihood h(i)s,d for left- or rightside siblings s ∈ {L,R} at depth d ∈ {1..D} at each it-
eration i ∈ {1..I},10 as a vector with one row for each nonterminal or terminal symbol (or null symbol ⊥) in G, containing the probability of each symbol generating a complete yield within depth d as an s-side sibling:
h(0)s,d = 0 (14a)
h(i)L,d =  G (1 ⊗ δ⊥ +",4.1 Depth-bounded grammar,[0],[0]
"h(i−1)L,d ⊗ h(i−1)R,d )",4.1 Depth-bounded grammar,[0],[0]
if d ≤ D + 1 0,4.1 Depth-bounded grammar,[0],[0]
"if d > D + 1
(14b)
h(i)R,d =  δT if d = 0 G (1 ⊗ δ⊥ + h(i−1)L,d+1 ⊗ h(i−1)R,d )",4.1 Depth-bounded grammar,[0],[0]
if 0 < d ≤ D 0,4.1 Depth-bounded grammar,[0],[0]
"if d > D.
(14c)
where ‘T’ is a top-level category label at depth zero.",4.1 Depth-bounded grammar,[0],[0]
"A depth-bounded grammar Gs,d can then be defined to be the original grammar G reweighted and renormalized by this containment likelihood:11
GL,d = G diag(1 ⊗ δ⊥ + h(I)L,d ⊗ h(I)R,d)
",4.1 Depth-bounded grammar,[0],[0]
"h(I)L,d (15a)
GR,d = G diag(1 ⊗ δ⊥ + h(I)L,d+1 ⊗ h(I)R,d)
h(I)R,d .",4.1 Depth-bounded grammar,[0],[0]
"(15b)
",4.1 Depth-bounded grammar,[0],[0]
This renormalization ensures the depth-bounded model is consistent.,4.1 Depth-bounded grammar,[0],[0]
"Moreover, this distinction between a learned unbounded grammar G and a derived bounded grammar Gs,d which is used to derive a parsing model may be regarded as an instance of Chomsky’s (1965) distinction between linguistic competence and performance.
",4.1 Depth-bounded grammar,[0],[0]
"The side- and depth-specific grammar can then be used to define expected counts of categories occurring as left descendants (or ‘left corners’) of right-
10 Experiments described in this article use I = 20 following observations of convergence at this point in supervised parsing.
11 where diag(v) is a diagonalization of a vector v:
diag(v) =  v[1] 0 · · · 0 v[2] ... . . .  .",4.1 Depth-bounded grammar,[0],[0]
"(2’)
sibling ancestors:
E(1)d = GR,d (diag(1) ⊗ 1) (16a) E(i)d = E (i−1) d GL,d (diag(1)",4.1 Depth-bounded grammar,[0],[0]
"⊗ 1) (16b)
E+d",4.1 Depth-bounded grammar,[0],[0]
= ∑I i=1,4.1 Depth-bounded grammar,[0],[0]
E (i) d .,4.1 Depth-bounded grammar,[0],[0]
"(16c)
",4.1 Depth-bounded grammar,[0],[0]
"This left-corner expectation will be used to estimate the marginalized probability over all grammar rule expansions between derivation fragments, which must traverse an unknown number of left children of some right-sibling ancestor.",4.1 Depth-bounded grammar,[0],[0]
"Again following van Schijndel et al. (2013), the fork and join decision, and the preterminal, top and bottom category label sub-models described in Section 3 can now be defined in terms of these sideand depth-specific grammars Gs,d and depth-specific left-corner expectations E+d .
",4.2 Depth-bounded parsing,[0],[0]
"First, probabilities for no-fork and yes-fork outcomes below some bottom sign of category b at depth d are defined as the normalized probabilities, respectively, of any lexical expansion of a right sibling b at depth d, and of any lexical expansion following any number of left child expansions from b at depth d:
PθF,d (0 | b) = δb >GR,d (",4.2 Depth-bounded parsing,[0],[0]
"1 ⊗ δ⊥)
δb >",4.2 Depth-bounded parsing,[0],[0]
"(GR,d + E+d GL,d) (1 ⊗ δ⊥)
(17a)
PθF,d (1 | b) = δb >",4.2 Depth-bounded parsing,[0],[0]
E+d,4.2 Depth-bounded parsing,[0],[0]
"GL,d (1 ⊗ δ⊥)
δb >",4.2 Depth-bounded parsing,[0],[0]
"(GR,d + E+d GL,d) (1 ⊗ δ⊥)
.",4.2 Depth-bounded parsing,[0],[0]
"(17b)
",4.2 Depth-bounded parsing,[0],[0]
"The probability of a preterminal p given a bottom category b is simply a normalized left-corner expected count of p under b:
PθP,d (p | b)def= δb",4.2 Depth-bounded parsing,[0],[0]
> E+d,4.2 Depth-bounded parsing,[0],[0]
"δp
δb > E+d 1
.",4.2 Depth-bounded parsing,[0],[0]
"(18)
Yes-join and no-join probabilities below bottom sign b and above top sign a at depth d are then defined similarly to fork probabilities, as the normalized probabilities, respectively, of an expansion to left child a of a right sibling b at depth d, and of an expansion to left child a following any number of
left child expansions from b at depth d:
PθJ,d (1 | b a) = δb >GR,d (δa ⊗ 1)
",4.2 Depth-bounded parsing,[0],[0]
δb >,4.2 Depth-bounded parsing,[0],[0]
"(GR,d + E+d GL,d) (δa ⊗ 1)
(19a)
PθJ,d (0 | b a) = δb >",4.2 Depth-bounded parsing,[0],[0]
E+d,4.2 Depth-bounded parsing,[0],[0]
"GL,d (δa ⊗ 1)
δb >",4.2 Depth-bounded parsing,[0],[0]
"(GR,d + E+d GL,d) (δa ⊗ 1)
.
(19b)
",4.2 Depth-bounded parsing,[0],[0]
"The distribution over category labels for top signs a above some top sign of category c and below a bottom sign of category b at depth d is defined as the normalized distribution over category labels following a chain of left children expanding from b which then expands to have a left child of category c:
PθA,d (a | b c) = δb >E+d diag(δa) GL,d (δc",4.2 Depth-bounded parsing,[0],[0]
"⊗ 1)
δb >E+d diag(1) GL,d (δc ⊗ 1)
.",4.2 Depth-bounded parsing,[0],[0]
"(20)
The distribution over category labels for bottom signs b below some sign a and sibling of top sign c is then defined as the normalized distribution over right children of grammar rules expanding from a to c followed by b:
PθB,s,d (b | a c) = δa >Gs,d (δc ⊗ δb)
",4.2 Depth-bounded parsing,[0],[0]
"δa >Gs,d (δc ⊗ 1) .",4.2 Depth-bounded parsing,[0],[0]
"(21)
Finally, a lexical observation model L is defined as a matrix of unary rule probabilities with one row for each combination of store state and preterminal symbol and one column for each observation symbol: L = 1 ⊗G (diag(1) ⊗ δ⊥).",4.2 Depth-bounded parsing,[0],[0]
(22),4.2 Depth-bounded parsing,[0],[0]
"Grammar induction in this model then follows a forward-filtering backward-sampling algorithm (Carter and Kohn, 1996).",4.3 Gibbs sampling,[0],[0]
"This algorithm first computes a forward distribution vt over hidden states at each time step t from an initial value ⊥:
v0> = δ⊥> (23a)",4.3 Gibbs sampling,[0],[0]
vt> = vt−1>M diag(L δwt ).,4.3 Gibbs sampling,[0],[0]
"(23b)
",4.3 Gibbs sampling,[0],[0]
"The algorithm then samples hidden states backward from a multinomial distribution given the previously sampled state qt+1 at time step t+1 (assuming input parameters to the multinomial function are normalized):
qt ∼ Multinom( diag(vt) M diag(L δwt+1) δqt+1 ).",4.3 Gibbs sampling,[0],[0]
"(24)
Grammar rule applications C are then counted from these sampled sequences:12
C = ∑
t  δbd̄−1t−1 (δad̄t−1 ⊗ δbd̄−1t )",4.3 Gibbs sampling,[0],[0]
"> if ft, jt = 0, 1 δad̄t (δad̄t−1 ⊗ δbd̄t ) > if ft, jt = 0, 0 δbd̄t−1",4.3 Gibbs sampling,[0],[0]
"(δpt ⊗ δbd̄t ) > if ft, jt = 1, 1
δad̄+1t (δpt ⊗ δbd̄+1t )",4.3 Gibbs sampling,[0],[0]
>,4.3 Gibbs sampling,[0],[0]
"if ft, jt = 1, 0
+ ∑
t
δpt (δwt ⊗ δ⊥)>, (25)
and a new grammar G is sampled from a Dirichlet distribution with counts C and a symmetric hyperparameter β as parameters:
G ∼ Dirichlet( C + β ).",4.3 Gibbs sampling,[0],[0]
"(26)
",4.3 Gibbs sampling,[0],[0]
This grammar is then used to define transition and lexical models M and L as defined in Sections 3 through 4.2 to complete the cycle.,4.3 Gibbs sampling,[0],[0]
There are three hyper-parameters in the model.,4.4 Model hyper-parameters and priors,[0],[0]
"K is the number of non-terminal categories in the grammar G, D is the maximum depth, and β is the parameter for the symmetric Dirichlet prior over multinomial distributions in the grammar G.
As seen from the previous subsection, the prior is over all possible rules in an unbounded PCFG grammar.",4.4 Model hyper-parameters and priors,[0],[0]
"Because the number of non-terminal categories of the unbounded PCFG grammar is given as a hyper-parameter, the number of rules in the grammar is always known.",4.4 Model hyper-parameters and priors,[0],[0]
"It is possible to use nonparametric priors over the number of non-terminal categories, however due to the need to dynamically mitigate the computational complexity of filtering and sampling using arbitrarily large category sets, this is left for future work.",4.4 Model hyper-parameters and priors,[0],[0]
"The DB-PCFG model described in Section 4 is evaluated first on synthetic data to determine whether it can reliably learn a recursive grammar from data with a known optimum solution, and to determine the hyper-parameter value for β for doing so.",5 Evaluation,[0],[0]
Two experiments on natural data are then carried out.,5 Evaluation,[0],[0]
"First, the model is run on natural data from the Adam
12 Again, d̄ =maxd{adt−1,⊥}.
and Eve parts of the CHILDES corpus (Macwhinney, 1992) to compare with other grammar induction systems on a human-like acquisition task.",5 Evaluation,[0],[0]
"Then data from the Wall Street Journal section of the Penn Treebank (Marcus et al., 1993) is used for further comparison in a domain for which competing systems are optimized.",5 Evaluation,[0],[0]
"The competing systems include UPPARSE (Ponvert et al., 2011)13, CCL (Seginer, 2007a)14, BMMM+DMV with undirected dependency features (Christodoulopoulos et al., 2012)15 and UHHMM (Shain et al., 2016).16
For the natural language datasets, the variously parametrized DB-PCFG systems17 are first validated on a development set, and the optimal system is then run until convergence with the chosen hyperparameters on the test set.",5 Evaluation,[0],[0]
"In development experiments, the log-likelihood of the dataset plateaus usually after 500 iterations.",5 Evaluation,[0],[0]
"The system is therefore run at least 500 iterations in all test set experiments, with one iteration being a full cycle of Gibbs sampling.",5 Evaluation,[0],[0]
"The system is then checked to see whether the loglikelihood has plateaued, and halted if it has.
",5 Evaluation,[0],[0]
The DB-PCFG model assigns trees sampled from conditional posteriors to all sentences in a dataset in every iteration as part of the inference.,5 Evaluation,[0],[0]
The system is further allowed to run at least 250 iterations after convergence and proposed parses are chosen from the iteration with the greatest log-likelihood after convergence.,5 Evaluation,[0],[0]
"However, once the system reaches convergence, the evaluation scores of parses from different iterations post-convergence appear to differ very little.",5 Evaluation,[0],[0]
"Following Liang et al. (2009) and Scicluna and de la Higuera (2014), an initial set of experiments on synthetic data are used to investigate basic properties of the model—in particular:
13https://github.com/eponvert/upparse 14https://github.com/DrDub/cclparser 15BMMM:https://github.com/christos-c/bmmm
DMV:https://code.google.com/archive/p/ pr-toolkit/
16https://github.com/tmills/uhhmm/tree/
coling16 17The most complex configuration that would run on available GPUs was D=2,K=15.",5.1 Synthetic data,[0],[0]
"Analysis of full WSJ (Schuler et al., 2010) shows 47.38% of sentences require depth 2, 38.32% require depth 3 and 6.26% require depth 4.
",5.1 Synthetic data,[0],[0]
"a) X1
b) X1
c) X2
d) X2
1.",5.1 Synthetic data,[0],[0]
"whether the model is balanced or biased in favor of left- or right-branching solutions,
2.",5.1 Synthetic data,[0],[0]
"whether the model is able to posit recursive structure in appropriate places, and
3.",5.1 Synthetic data,[0],[0]
"what hyper-parameters enable the model to find optimal modes more quickly.
",5.1 Synthetic data,[0],[0]
"The risk of bias in branching structure is important because it might unfairly inflate induction results on languages like English, which are heavily right branching.",5.1 Synthetic data,[0],[0]
"In order to assess its bias, the model is evaluated on two synthetic datasets, each consisting of 200 sentences.",5.1 Synthetic data,[0],[0]
"The first dataset is a leftbranching corpus, which consists of 100 sentences of the form a b and 100 sentences of the form a b b, with optimal tree structures as shown in Figure 2 (a) and (b).",5.1 Synthetic data,[0],[0]
"The second dataset is a right-branching corpus, which consists of 100 sentences of the form a b and 100 sentences of the form a a b, with optimal tree structures as shown in Figure 2 (c) and (d).",5.1 Synthetic data,[0],[0]
"Results show both structures (and both corresponding grammars) are learnable by the model, and result in approximately the same log likelihood.",5.1 Synthetic data,[0],[0]
These synthetic datasets are also used to tune the β hyperparameter of the model (as defined in Section 4) to enable it to find optimal modes more quickly.,5.1 Synthetic data,[0],[0]
"The resulting β setting of 0.2 is then used in induction on the CHILDES and Penn Treebank corpora.
",5.1 Synthetic data,[0],[0]
"After validating that the model is not biased, the model is also evaluated on a synthetic centerembedding corpus consisting of 50 sentences each of the form a b c; a b b c; a b a b c; and a b b a b b c, which has optimal tree structures as shown in Figure 3.18 Note that the (b) and (d) trees have depth 2
18 Here, in order to more closely resemble natural language input, tokens a, b, and c are randomly chosen uniformly from {a1, . . .",5.1 Synthetic data,[0],[0]
", a50}, {b1, . . .",5.1 Synthetic data,[0],[0]
", b50} and {c1, . . .",5.1 Synthetic data,[0],[0]
", c50}, respectively.
because they each have a complex sub-tree spanning a b and a b b embedded in the center of the yield of the root.",5.1 Synthetic data,[0],[0]
"Results show the model is capable of learning depth 2 (recursive) grammars.
",5.1 Synthetic data,[0],[0]
"Finally, as a gauge of the complexity of this task, results of the model described in this paper are compared with those of other grammar induction models on the center-embedding dataset.",5.1 Synthetic data,[0],[0]
"In this experiment, all models are assigned hyper-parameters matching the optimal solution.",5.1 Synthetic data,[0],[0]
The DB-PCFG is run with K=5 and D=2 and β=0.2,5.1 Synthetic data,[0],[0]
"for all priors, the BMMM+DMV (Christodoulopoulos et al., 2012) is run with 3 preterminal categories, and the UHHMM model is run with 2 active states, 4 awaited states and 3 parts of speech.19 Table 1 shows the PARSEVAL scores for parsed trees using the learned grammar from each unsupervised system.",5.1 Synthetic data,[0],[0]
"Only the DBPCFG model is able to recognize the correct tree structures and the correct category labels on this dataset, showing the task is indeed a robust challenge.",5.1 Synthetic data,[0],[0]
"This suggests that hyper-parameters optimized on this dataset may be portable to natural data.
",5.1 Synthetic data,[0],[0]
"19It is not possible to use just 2 awaited states, which is the gold setting, since the UHHMM system errors out when the number of categories is small.",5.1 Synthetic data,[0],[0]
"After setting the β hyperparameter on synthetic datasets, the DB-PCFG model is evaluated on 14,251 sentences of transcribed child-directed speech from the Eve section of the Brown corpus of CHILDES (Macwhinney, 1992).",5.2 Child-directed speech corpus,[0],[0]
"Hyperparameters D and K are set to optimize performance on the Adam section of the Brown Corpus of CHILDES, which is about twice as long as Eve.",5.2 Child-directed speech corpus,[0],[0]
"Following previous work, these experiments leave all punctuation in the input for learning, then remove it in all evaluations on development and test data.
",5.2 Child-directed speech corpus,[0],[0]
"Model performance is evaluated against Penn Treebank style annotations of both Adam and Eve corpora (Pearl and Sprouse, 2013).",5.2 Child-directed speech corpus,[0],[0]
Table 2 shows the PARSEVAL scores of the DB-PCFG system with different hyperparameters on the Adam corpus for development.,5.2 Child-directed speech corpus,[0],[0]
"The simplest configuration, D1K15 (depth 1 only with 15 non-terminal categories), obtains the best score, so this setting is applied to the test corpus, Eve.",5.2 Child-directed speech corpus,[0],[0]
"Results of the D=1,K=15 DB-PCFG model on Eve are then compared against those of other grammar induction systems which use only raw text as input on the same corpus.",5.2 Child-directed speech corpus,[0],[0]
"Following Shain et al. (2016) the BMMM+DMV system is run for 10 iterations with 45 categories and its output is converted from dependency graphs to constituent
trees (Collins et al., 1999).",5.2 Child-directed speech corpus,[0],[0]
"The UHHMM system is run on the Eve corpus using settings in Shain et al. (2016), which also includes a post-process option to flatten trees (reported here as UHHMM-F).
",5.2 Child-directed speech corpus,[0],[0]
Table 3 shows the PARSEVAL scores for all the competing systems on the Eve dataset.,5.2 Child-directed speech corpus,[0],[0]
"The rightbranching baseline is still the most accurate in terms of PARSEVAL scores, presumably because of the highly right-branching structure of child-directed speech in English.",5.2 Child-directed speech corpus,[0],[0]
"The DB-PCFG system with only one memory depth and 15 non-terminal categories achieves the best performance in terms of F1 score and recall among all the competing systems, significantly outperforming other systems (p < 0.0001, permutation test).20
The Eve corpus has about 5,000 sentences with more than one depth level, therefore one might expect a depth-two model to perform better than a depth-one model, but this is not true if only PARSEVAL scores are considered.",5.2 Child-directed speech corpus,[0],[0]
This issue will be revisited in the following section with the noun phrase discovery task.,5.2 Child-directed speech corpus,[0],[0]
"When humans acquire grammar, they do not only learn tree structures, they also learn category types: noun phrases, verb phrases, prepositional phrases, and where each type can and cannot occur.
",5.3 NP discovery on child-directed speech,[0],[0]
20Resulting scores are better when applying Shain et al. (2016) flattening to output binary-branching trees.,5.3 NP discovery on child-directed speech,[0],[0]
"For the D=1, K=15 model, precision and F1 can be raised to 70.31% and 74.33%.",5.3 NP discovery on child-directed speech,[0],[0]
"However, since the flattening is a heuristic which may not apply in all cases, these scores are not considered to be comparable results.
",5.3 NP discovery on child-directed speech,[0],[0]
"Some of these category types — in particular, noun phrases — are fairly universal across languages, and may be useful in downstream tasks such as (unsupervised) named entity recognition.",5.3 NP discovery on child-directed speech,[0],[0]
"The DB-PCFG and other models that can be made to produce category types are therefore evaluated on a noun phrase discovery task.
",5.3 NP discovery on child-directed speech,[0],[0]
Two metrics are used for this evaluation.,5.3 NP discovery on child-directed speech,[0],[0]
"First, the evaluation counts all constituents proposed by the candidate systems, and calculates recall against the gold annotation of noun phrases.",5.3 NP discovery on child-directed speech,[0],[0]
This metric is not affected by which branching paradigm the system is using and reveals more about the systems’ performances.,5.3 NP discovery on child-directed speech,[0],[0]
"This metric differs from that used by Ponvert et al. (2011) in that this metric takes NPs at all levels in gold annotation into account, not just base NPs.21
The second metric, for systems that produce category labels, calculates F1 scores of induced categories that can be mapped to noun phrases.",5.3 NP discovery on child-directed speech,[0],[0]
"The first 4,000 sentences are used as the development set for learning mappings from induced category labels to phrase types.",5.3 NP discovery on child-directed speech,[0],[0]
"The evaluation calculates precision, recall and F1 of all spans of proposed categories against the gold annotations of noun phrases in the development set, and aggregates the categories ranked by their precision scores so that the F1 score of the aggregated category is the highest on the development set.",5.3 NP discovery on child-directed speech,[0],[0]
"The evaluation then calculates the F1 score of this aggregated category on the remainder of the dataset, excluding this development set.
",5.3 NP discovery on child-directed speech,[0],[0]
"21Ponvert et al. (2011) define base NPs as NPs with no NP descendants, a restriction motivated by their particular task (chunking).
",5.3 NP discovery on child-directed speech,[0],[0]
The UHHMM system is the only competing system that is natively able to produce labels for proposed constituents.,5.3 NP discovery on child-directed speech,[0],[0]
"BMMM+DMV does not produce constituents with labels by default, but can be evaluated using this metric by converting dependency graphs into constituent trees, then labeling each constituent with the part-of-speech tag of the head.",5.3 NP discovery on child-directed speech,[0],[0]
"For CCL and UPPARSE, the NP agg F1 scores are not reported because they do not produce labeled constituents.
",5.3 NP discovery on child-directed speech,[0],[0]
Table 4 shows the scores for all systems on the Eve dataset and four runs of the DB-PCFG system on these two evaluation metrics.,5.3 NP discovery on child-directed speech,[0],[0]
"Surprisingly the D=2, K=15 model which has the lowest PARSEVAL scores is most accurate at discovering noun phrases.",5.3 NP discovery on child-directed speech,[0],[0]
It has the highest scores on both evaluation metrics.,5.3 NP discovery on child-directed speech,[0],[0]
"The best model in terms of PARSEVAL scores, the D=1, K=15 DB-PCFG model, performs poorly among the DB-PCFG models, despite the fact that its NP recall is higher than the competing systems.",5.3 NP discovery on child-directed speech,[0],[0]
The low score of NP agg F1 of DB-PCFG at D1K15 shows a diffusion of induced syntactic categories when the model is trying to find a balance among labeling and branching decisions.,5.3 NP discovery on child-directed speech,[0],[0]
"The UPPARSE system, which is proposed as a base NP chunker, is relatively poor at NP recall by this definition.
",5.3 NP discovery on child-directed speech,[0],[0]
The right-branching baseline does not perform well in terms of NP recall.,5.3 NP discovery on child-directed speech,[0],[0]
This is mainly because noun phrases are often left children of some other constituent and the right branching model is unable to incorporate them into the syntactic structures of whole sentences.,5.3 NP discovery on child-directed speech,[0],[0]
"Therefore although the rightbranching model is the best model in terms of PARSEVAL scores, it is not helpful in terms of finding
noun phrases.",5.3 NP discovery on child-directed speech,[0],[0]
"To further facilitate direct comparison to previous work, we run experiments on sentences from the Penn Treebank (Marcus et al., 1993).",5.4 Penn Treebank,[0],[0]
The first experiment uses the sentences from Wall Street Journal part of the Penn Treebank with at most 20 words (WSJ20).,5.4 Penn Treebank,[0],[0]
The first half of the WSJ20 dataset is used as a development set (WSJ20dev) and the second half is used as a test set (WSJ20test).,5.4 Penn Treebank,[0],[0]
We also extract sentences in WSJ20test with at most 10 words from the proposed parses from all systems and report results on them (WSJ10test).,5.4 Penn Treebank,[0],[0]
"WSJ20dev is used for finding the optimal hyperparameters for both DBPCFG and BMMM-DMV systems.22
Table 5 shows the PARSEVAL scores of all systems.",5.4 Penn Treebank,[0],[0]
"The right-branching baseline is relatively weak on these two datasets, mainly because formal writing is more complex and uses more non-rightbranching structures (e.g., subjects with modifiers or parentheticals) than child-directed speech.",5.4 Penn Treebank,[0],[0]
"For WSJ10test, both the DB-PCFG system and CCL are able to outperform the right branching baseline.",5.4 Penn Treebank,[0],[0]
"The F1 difference between the best-performing previouswork system, CCL, and DB-PCFG is highly significant.",5.4 Penn Treebank,[0],[0]
"For WSJ20test, again both CCL and DB-
22Although UHHMM also needs tuning, in practice we find that this system is too inefficient to be tuned on a development set, and it requires too many resources when the hyperparameters become larger than used in previous work.",5.4 Penn Treebank,[0],[0]
"We believe that further increasing the hyperparameters of UHHMM may lead to performance increase, but the released version is not scalable to larger values of these settings.",5.4 Penn Treebank,[0],[0]
We also do not report UHHMM on WSJ20test for the same scalabilty reason.,5.4 Penn Treebank,[0],[0]
"The results of WSJ10test of UHHMM is induced with all WSJ10 sentences.
",5.4 Penn Treebank,[0],[0]
PCFG are above the right-branching baseline.,5.4 Penn Treebank,[0],[0]
"The difference between the F scores of CCL and DBPCFG is very small compared to WSJ10, however it is also significant.
",5.4 Penn Treebank,[0],[0]
It is possible that the DB-PCFG is being penalized for inducing fully binarized parse trees.,5.4 Penn Treebank,[0],[0]
"The accuracy of the DB-PCFG model is dominated by recall rather than precision, whereas CCL and other systems are more balanced.",5.4 Penn Treebank,[0],[0]
"This is an important distinction if it is assumed that phrase structure is binary (Kayne, 1981; Larson, 1988), in which case precision merely scores non-linguistic decisions about whether to suppress annotation of nonmaximal projections.",5.4 Penn Treebank,[0],[0]
"However, since other systems are not optimized for recall, it would not be fair to use only recall as a comparison metric in this study.
",5.4 Penn Treebank,[0],[0]
"Finally, Table 6 shows the published results of different systems on WSJ.",5.4 Penn Treebank,[0],[0]
"The CCL results come from Seginer (2007b), where the CCL system is trained with all sentences from WSJ, and evaluated on sentences with 40 words or fewer from WSJ (WSJ40) and WSJ10.",5.4 Penn Treebank,[0],[0]
"The UPPARSE results come from Ponvert et al. (2011), where the UPPARSE system is trained using 00-21 sections of WSJ, and evaluated on section 23 and the WSJ10 subset of section 23.",5.4 Penn Treebank,[0],[0]
"The DB-PCFG system uses hyperparameters optimized on the WSJ20dev set, and is evaluated on WSJ40 and WSJ10, both excluding WSJ20dev.",5.4 Penn Treebank,[0],[0]
"The results are not directly comparable, but the results from the DB-PCFG system is competitive with the other systems, and numerically have the best recall scores.",5.4 Penn Treebank,[0],[0]
This paper describes a Bayesian Dirichlet model of depth-bounded PCFG induction.,6 Conclusion,[0],[0]
"Unlike earlier work this model implements depth bounds directly
on PCFGs by derivation, reducing the search space of possible trees for input words without exploding the search space of parameters with multiple sideand depth-specific copies of each rule.",6 Conclusion,[0],[0]
Results for this model on grammar acquisition from transcribed child-directed speech and newswire text exceed or are competitive with those of other models when evaluated on parse accuracy.,6 Conclusion,[0],[0]
"Moreover, grammars acquired from this model demonstrate a consistent use of category labels, something which has not been demonstrated by other acquisition models.
",6 Conclusion,[0],[0]
"In addition to its practical merits, this model may offer some theoretical insight for linguists and other cognitive scientists.",6 Conclusion,[0],[0]
"First, the model does not assume any universals except independently motivated limits on working memory, which may help address the question of whether universals are indeed necessary for grammar induction.",6 Conclusion,[0],[0]
"Second, the distinction this model draws between its learned unbounded grammar G and its derived bounded grammar GD seems to align with Chomsky’s (1965) distinction between competence and performance, and has the potential to offer some formal guidance to linguistic inquiry about both kinds of models.",6 Conclusion,[0],[0]
The authors would like to thank Cory Shain and William Bryce for their valuable input.,Acknowledgments,[0],[0]
We would like also to thank the Action Editor Xavier Carreras and the anonymous reviewers for insightful comments.,Acknowledgments,[0],[0]
Computations for this project were partly run on the Ohio Supercomputer Center (1987).,Acknowledgments,[0],[0]
This research was funded by the Defense Advanced Research Projects Agency award HR0011-15-2-0022.,Acknowledgments,[0],[0]
"The content of the information does not necessarily reflect the position or the policy of the Government, and no official endorsement should be inferred.",Acknowledgments,[0],[0]
"There has been recent interest in applying cognitivelyor empirically-motivated bounds on recursion depth to limit the search space of grammar induction models (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016).",abstractText,[0],[0]
"This work extends this depthbounding approach to probabilistic contextfree grammar induction (DB-PCFG), which has a smaller parameter space than hierarchical sequence models, and therefore more fully exploits the space reductions of depthbounding.",abstractText,[0],[0]
Results for this model on grammar acquisition from transcribed child-directed speech and newswire text exceed or are competitive with those of other models when evaluated on parse accuracy.,abstractText,[0],[0]
"Moreover, grammars acquired from this model demonstrate a consistent use of category labels, something which has not been demonstrated by other acquisition models.",abstractText,[0],[0]
Unsupervised Grammar Induction with Depth-bounded PCFG,title,[0],[0]
"ar X
iv :1
60 9.
03 20
5v 1
[ cs
.C L
] 1
1 Se
p 20",text,[0],[0]
"Human-translated texts (in any language) have distinct features that distinguish them from original, non-translated texts.",1 Introduction,[0],[0]
"These differences stem either from the effect of the translation process on the translated outcomes, or from “fingerprints” of the source language on the target language product.",1 Introduction,[0],[0]
"The term translationese was coined to indicate the unique properties of translations.
",1 Introduction,[0],[0]
Awareness to translationese can improve statistical machine translation (SMT).,1 Introduction,[0],[0]
"First, for training
translation models, parallel texts that were translated in the direction of the SMT task are preferable to texts translated in the opposite direction; second, for training language models, monolingual corpora of translated texts are better than original texts.
",1 Introduction,[0],[0]
"It is possible to automatically distinguish between original (O) and translated (T) texts, with very high accuracy, by employing text classification methods.",1 Introduction,[0],[0]
"Existing approaches, however, only employ supervised machine-learning; they therefore suffer from two main drawbacks: (i) they inherently depend on data annotated with the translation direction, and (ii) they may not be generalized to unseen (related or unrelated)",1 Introduction,[0],[0]
domains.1,1 Introduction,[0],[0]
"These shortcomings undermine the usability of supervised methods for translationese identification in a typical real-life scenario, where no labelled in-domain data are available.
",1 Introduction,[0],[0]
In this work we explore unsupervised techniques for reliable discrimination of original and translated texts.,1 Introduction,[0],[0]
"More precisely, we apply dimension reduction and centroid-based clustering methods (enhanced by internal clustering evaluation), for telling O from T in an unsupervised scenario.",1 Introduction,[0],[0]
"Furthermore, we introduce a robust methodology for labelling the obtained clusters, i.e., annotating them as “original” or “translated”, by inspecting similarities between the clustering outcomes and O and T prototypical examples.",1 Introduction,[0],[0]
"Rigorous experiments with four diverse corpora demonstrate that clustering of in-domain texts using lexical, content-independent features systematically yields very high accuracy, only 10 percent points lower than the performance of supervised classification on the same data (in most cases).",1 Introduction,[0],[0]
"Ac-
1We use “domain” rather freely henceforth to indicate not only the topic of a corpus but also its modality (written vs. spoken), register, genre, date, etc.
curacy can be improved even further by clustering consensus techniques.
",1 Introduction,[0],[0]
We further scrutinize the tension between domain-related and translationese-based text properties.,1 Introduction,[0],[0]
"Using a series of experiments in a mixeddomain setup, we show that clustering (in particular, relying on content-independent features) perfectly groups the data into domains, rather than into the (desirable) cross-domain O and T; that is, domainrelated properties clearly dominate and overshadow the translationese-based characteristics of the underlying texts.",1 Introduction,[0],[0]
"We address the challenge of discriminating O from T in a mixed-domain setup by proposing two simple methodologies (flat and two-phase) and empirically demonstrate their soundness.
",1 Introduction,[0],[0]
"The clustering experiments throughout the paper were conducted in a setup similar to that of supervised classification, determining the status (O vs. T) of logical units (chunks) of 2,000 tokens.",1 Introduction,[0],[0]
"We also show that clustering accuracy remains stable even when the number of available chunks decreases dramatically and remains satisfactory when the chunk size is reduced.
",1 Introduction,[0],[0]
"The main contribution of this work is therefore two-fold: (i) we establish a robust approach for reliable unsupervised identification of translated texts, thereby eliminating the need for in-domain labeled data; (ii) we provide an extensive empirical foundation for the dominance of domain-based properties over translationese-related characteristics of a text, and propose a methodology for identification of translationese in a mixed-domain scenario.
",1 Introduction,[0],[0]
"The remainder of the paper is structured as following: after reviewing related work in Section 2, we detail our datasets in Section 3.",1 Introduction,[0],[0]
"In Section 4 we reproduce and extend supervised classification results, and demonstrate the poor cross-domain classification accuracy of supervised methods.",1 Introduction,[0],[0]
Our clustering methodology and experiments are described in Section 5; mixed-domain classification is discussed in Section 6.,1 Introduction,[0],[0]
We conclude with a discussion and suggestions for future research.,1 Introduction,[0],[0]
Much research in Translation Studies indicates that translated texts have unique characteristics.,2 Related Work,[0],[0]
"Translated texts (in any language) constitute a sub-
language (sometimes referred to as a genre, or a dialect) of the target language, presumably reflecting both the artifacts of the translation process and traces of the original language from which the texts were translated (the source language).",2 Related Work,[0],[0]
"Gellerstam (1986) called this sub-language translationese, and suggested that the differences between O and T do not indicate poor translation but rather a statistical phenomenon, caused by a systematic influence of the source language on the target language.
",2 Related Work,[0],[0]
These differences have ramifications for SMT.,2 Related Work,[0],[0]
"Kurokawa et al. (2009) were the first to note it: they showed that translation models trained on Englishtranslated-to-French bitexts were much better than ones trained on French-translated-to-English, when the SMT task is translating English to French.",2 Related Work,[0],[0]
"Lembersky et al. (2012a, 2013) corroborated these results, for more language pairs, and suggested a way to adapt translation models to the properties of translationese.",2 Related Work,[0],[0]
"Furthermore, Lembersky et al. (2011, 2012b) showed that language models compiled from translated texts are better for SMT than ones compiled from original texts.",2 Related Work,[0],[0]
"These results all highlight the practical importance of being able to reliably distinguish between translated and original texts.
",2 Related Work,[0],[0]
"Indeed, translated texts are so markedly different from original ones that automatic classification can identify them with very high accuracy (Baroni and Bernardini, 2006; Ilisei et al., 2010; Ilisei and Inkpen, 2011; Popescu, 2011).",2 Related Work,[0],[0]
"Recently, Volansky et al. (2015) investigated several translation studies hypotheses by performing an extensive exploration of the ability of various feature sets to distinguish between O and T. Using SVM classifiers and ten-fold cross-validation evaluation, they listed several features that yield near perfect accuracy.
",2 Related Work,[0],[0]
Most works mentioned above train and evaluate classifiers on texts drawn from the same corpus.,2 Related Work,[0],[0]
"When these classifiers are tested on texts from different domains, or in a different genre, or translated from a different language, classification accuracy dramatically deteriorates.",2 Related Work,[0],[0]
"Koppel and Ordan (2011) train classifiers on the Europarl corpus (Koehn, 2005), with English translated from five different languages.",2 Related Work,[0],[0]
"When the classifiers are evaluated on English translated from the same language they were
trained on, accuracy is near 100%; but when evaluated on translations from a different language, accuracy drops significantly, in some cases below 60%.",2 Related Work,[0],[0]
This pattern recurs when the test corpus is different from the training corpus (newspaper articles vs. parliament proceedings).,2 Related Work,[0],[0]
"Similarly, Avner et al. (Forthcoming) report excellent (near 100%) results identifying Hebrew translationese on a corpus of literary texts, using very simple word-level features.",2 Related Work,[0],[0]
"Evaluation on different domains (popular science) and on Hebrew translated from French, rather than English, however, shows much poorer results, with accuracies around 60% in many cases.
",2 Related Work,[0],[0]
We hypothesize that the main reason for the deterioration in the accuracy of (supervised) translationese classifiers when evaluated out-of-domain stems from the fact that domain differences overshadow the differences between O and T. Diwersy et al. (2014) studied various sorts of linguistic variation by applying semi-supervised multivariate techniques.,2 Related Work,[0],[0]
"They investigated, among other factors, register variation in English and German originals and translations.",2 Related Work,[0],[0]
"By applying a series of supervised and unsupervised statistical analyses, they demonstrated that register-related properties are much better exhibited by the underlying texts than properties related to the documents’ translation status.",2 Related Work,[0],[0]
"We address the challenge of mixed-domain classification in Section 6.
",2 Related Work,[0],[0]
"One way to overcome the dependence on labeled data and domain-overfitting of supervised classifiers is to use unsupervised methods, in particular clustering.",2 Related Work,[0],[0]
"The only application of clustering to translationese that we are aware of is the work of Nisioi and Dinu (2013), who investigated translationese- and authorship-related characteristics by applying hierarchical clustering to books written by a Russian-English bilingual author.",2 Related Work,[0],[0]
"While they mainly focused on authorship attribution, Nisioi and Dinu (2013) also demonstrated that it is possible to discriminate O from T by applying clustering with lexical features (function words) extracted from complete books (25,000– 180,000 tokens).",2 Related Work,[0],[0]
"We address the challenge of unsupervised identification of translationese using a different methodology and much smaller logical units (2,000 tokens), and further broaden the scope of our work by proposing a methodology for telling O from
T in mixed-domain scenarios.",2 Related Work,[0],[0]
"Unsupervised classification is a well-established discipline; in this work we use KMeans (Lloyd, 1982) for clustering and KMeans++ (Arthur and Vassilvitskii, 2007) as a KMeans initialization method.",2 Related Work,[0],[0]
Our main dataset2 consists of texts originally written in English and texts translated to English from French.,3.1 Datasets,[0],[0]
We use various corpora:(i),3.1 Datasets,[0],[0]
"Europarl, the proceedings of the European Parliament (Koehn, 2005), between the years 2001-2006; (ii) the Canadian Hansard, transcripts of the Canadian Parliament, spanning years 2001-2009; (iii) literary classics written (or translated) mainly in the 19th century; and (iv) transcripts of TED and TEDx talks.",3.1 Datasets,[0],[0]
"This collection suggests diversity in genre, register, modality (written vs. spoken) and era.",3.1 Datasets,[0],[0]
"Table 1 details some statistical data on the corpora (after tokenization).3 We now briefly describe each dataset.
",3.1 Datasets,[0],[0]
"Europarl is probably the most popular parallel corpus in natural language processing, and it was indeed used for many of the translationese tasks surveyed in Section 2.",3.1 Datasets,[0],[0]
"This corpus has been used extensively in SMT (Koehn et al., 2009), and was even adapted specifically for research in translation studies: Islam and Mehler (2012) compiled a customized version of Europarl, where the direction of translation is indicated.",3.1 Datasets,[0],[0]
"We use a version of Europarl (Rabinovich and Wintner, Forthcoming) that aims to further increase the confidence in the direction of translation, through a comprehensive cross-lingual validation of the original language of the speakers.
",3.1 Datasets,[0],[0]
The Hansard is a parallel corpus consisting of transcriptions of the Canadian parliament in English and French between 2001 and 2009.,3.1 Datasets,[0],[0]
This is the largest available source of English–French sentence pairs.,3.1 Datasets,[0],[0]
We use a version that is annotated with the original language of each parallel sentence.,3.1 Datasets,[0],[0]
"Relying on metadata available in the corpus, we filtered out all segments not referring to speech, i.e., retaining
2The dataset is available at http://cl.haifa.ac.il/projects/translationese.
",3.1 Datasets,[0],[0]
"3We use “EUR”, “HAN”, “LIT” and “TED” to denote the four corpora in the discussion below.
",3.1 Datasets,[0],[0]
"only sentences annotated as Content ParaText.
",3.1 Datasets,[0],[0]
The Literature corpus consists of literary classics written (and translated) in the 18th–20th centuries by English and French authors; the raw material is available from the Gutenberg project.,3.1 Datasets,[0],[0]
We use subsets that were manually or automatically paragraph-aligned.,3.1 Datasets,[0],[0]
"Note that classifying literary texts is considered a more challenging task than classifying more “technical” translations, such as parliament proceedings, since translators of literature typically enjoy more literary freedom, thereby rendering the translation product more similar to original writing (Lynch and Vogel, 2012; Avner et al., Forthcoming).
",3.1 Datasets,[0],[0]
Our TED talks corpus consists of talks originally given in English and talks translated to English from French.,3.1 Datasets,[0],[0]
"The quality of translations in this corpus is very high: not only are translators assumed to be competent, but the common practice is that each translation passes through a review before being published.",3.1 Datasets,[0],[0]
"This corpus consists of talks delivered orally, but we assume that they were meticulously prepared, so the language is not spontaneous but rather planned.",3.1 Datasets,[0],[0]
"Compared to the other sub-corpora, the TED dataset has some unique characteristics that stem from the following reasons: (i) its size is relatively small; (ii) it exhibits stylistic disparity between the original and translated texts (the former contains more “oral” markers of a spoken language, while the latter is a written translation); and finally (iii) TED talks are not transcribed but are rather subtitled, so they undergo some editing and rephrasing.4
The vast majority of TED talks are publicly available online, which makes this corpus easily extendable for future research.
4 http://translations.ted.org/",3.1 Datasets,[0],[0]
"All datasets are first tokenized using the Stanford tools (Manning et al., 2014) and then partitioned into chunks of approximately 2000 tokens (ending on a sentence boundary).",3.2 Processing and Tools,[0],[0]
"We assume that translationese-related features are present in the texts across author or speaker, thus we allow some chunks to contain linguistic information from two or more different texts simultaneously.",3.2 Processing and Tools,[0],[0]
"For the main (single-corpus) classification experiments we use 2000 text chunks each from Europarl and Hansard, 800 from Literature and 88 chunks from TED; each sub-corpus consists of an equal number of original and translated chunks.",3.2 Processing and Tools,[0],[0]
"For every classification experiment we use the maximal equal number of chunks from each class, thus we always (randomly) down-sample the datasets in order to have a comparable number of training/testing examples for supervised classification, and comparable cluster size for clustering.
",3.2 Processing and Tools,[0],[0]
"We use Weka (Hall et al., 2009) as the main tool for classification, clustering, and dimension reduction.",3.2 Processing and Tools,[0],[0]
"In all the classification experiments, we use SVM (SMO) as the classification algorithm with the default linear kernel.",3.2 Processing and Tools,[0],[0]
For clustering we use Weka’s KMeans implementation (SimpleKMeans) with the KMeans++ initialization strategy.,3.2 Processing and Tools,[0],[0]
"We use Eucledian distance as the similarity measure for KMeans, and apply a custom clustering-evaluation-based wrapper (see Section 5) to further enhance Weka’s basic clustering implementation.
",3.2 Processing and Tools,[0],[0]
"We use Principal Component Analysis (PCA, Jolliffe (2002)) for dimension reduction.",3.2 Processing and Tools,[0],[0]
"PCA is a statistical procedure that discovers variables with the largest possible variance, i.e., features that account for most variability in the data (principal components).",3.2 Processing and Tools,[0],[0]
"It performs a linear mapping of the data to a lower-dimensional space in a way that maximizes
the variance of the data in the low-dimensional representation, by removing highly correlated or superfluous variables.",3.2 Processing and Tools,[0],[0]
"The outcome of PCA is a new set of features, each of which is a linear combination of the discovered components.",3.2 Processing and Tools,[0],[0]
"The number of the newly generated variables varies from one to the number of variables originally used to describe the data, and is typically controlled by a parameter.
",3.2 Processing and Tools,[0],[0]
"Apart from the enhanced efficiency (due to the reduced computational costs), dimensionality reduction often carries a positive effect on the accuracy of the underlying classification task, especially when the data are meager or feature vectors are sparse.",3.2 Processing and Tools,[0],[0]
"The (accuracy-wise) optimization gains of PCA, when followed by the KMeans clustering algorithm, were reported by Ng et al. (2001).",3.2 Processing and Tools,[0],[0]
"We perform dimension reduction using the Weka implementation of PCA, with the “variance covered” parameter set to 0.1 across all feature types and datasets, prior to applying a clustering procedure.",3.2 Processing and Tools,[0],[0]
"We focus on a set of features that reflect lexical and structural properties of the text, and have been shown to be effective for supervised classification of translationese (Volansky et al., 2015).",3.3 Features,[0],[0]
"Specifically, we use function words (FW), more precisely, the same list that was used in previous works on classification of translationese (Koppel and Ordan, 2011; Volansky et al., 2015).",3.3 Features,[0],[0]
"Feature values are raw counts (further denoted by term frequency, tf ), normalized by the number of tokens in the chunk; the chunk size may slightly vary, since the chunks respect sentence boundaries.",3.3 Features,[0],[0]
"For the clustering experiments we further scale the normalized tf by the inverse document frequency (idf), which offsets the importance of a term by a factor proportional to its frequency in the corpus.",3.3 Features,[0],[0]
"The tf-idf statistic has been shown to be effective with lexical features, and is often used as a weighting factor in information retrieval and text mining.",3.3 Features,[0],[0]
"While function words are assumed to be very frequent, their counts within a text vary greatly (e.g., “the” vs. “whereas”).",3.3 Features,[0],[0]
"We therefore opt for tf-idf weighting of FW across all sub-corpora.
",3.3 Features,[0],[0]
"In addition to function words, we experiment with several other feature sets, including character trigrams, part-of-speech (POS) trigrams, contex-
tual function words and cohesive markers.",3.3 Features,[0],[0]
"Contextual function words are a variation of POS trigrams where a trigram can be anchored by specific function words: these are consecutive triplets 〈w1,w2,w3〉 where at least two of the elements are function words, and at most one is a POS tag.",3.3 Features,[0],[0]
"Cohesive markers are words or phrases that signal the underlying flow of thought: they organize a composition of phrases by specifying the type, purpose or direction of upcoming ideas, and can therefore serve as evidence of the translation process.",3.3 Features,[0],[0]
"We use the list of 40 cohesive markers defined in Volansky et al. (2015).
",3.3 Features,[0],[0]
"Character, POS, and contextual FW trigrams are calculated as detailed in Volansky et al. (2015), but we only consider the 1000 most frequent feature values extracted from each dataset (or a combination of datasets) being classified.",3.3 Features,[0],[0]
"This subset yields the same classification quality as the full set, reducing computation complexity.",3.3 Features,[0],[0]
"We begin with supervised classification, reestablishing the high accuracy of in-domain (supervised) classification of translationese, but highlighting the deterioration in accuracy when cross-domain classification is considered.",4 Supervised Classification,[0],[0]
"We first reproduce the Europarl classification results with the best performing feature sets, as reported by Volansky et al. (2015), and present results for three additional subcorpora: Hansard, Literature and TED.",4 Supervised Classification,[0],[0]
Table 2 lists the ten-fold cross-validation classification accuracy with various features.,4 Supervised Classification,[0],[0]
"All features (except perhaps cohesive markers) yield excellent accuracy.
",4 Supervised Classification,[0],[0]
"A few previous works suggested that crossdomain classification of translationese results in low accuracy (Koppel and Ordan, 2011; Avner et al.,
Forthcoming).",4 Supervised Classification,[0],[0]
"Our experiments corroborate this observation; Table 3 depicts the cross-domain classification accuracy on the Europarl, Hansard and Literature corpora, when training on one corpus and testing on another (using function words).5",4 Supervised Classification,[0],[0]
"A balanced setup for this experiment was generated by randomly selecting 800 chunks from each corpus, divided equally to O and T. The results only slightly outperform chance level, even for the Europarl– Hansard seemingly domain-related pair: we obtain 59.7% to 60.8% accuracy in the two directions.
",4 Supervised Classification,[0],[0]
"Attempting to enrich the classifier’s training “experience” we conducted additional experiments, where we train on two sub-corpora out of Europarl, Hansard and Literature, and test on the remaining one.",4 Supervised Classification,[0],[0]
The results are depicted in Table 4.,4 Supervised Classification,[0],[0]
"Here, too, accuracy is very low, implying that training on diverse data does not necessarily provide a solution for cross-domain classification of translationese.",4 Supervised Classification,[0],[0]
The right-hand column of the table reports ten-fold cross-validation results of the two subcorpora that are subject for training.,4 Supervised Classification,[0],[0]
"Excellent indomain classification results on the one hand and poor cross-domain predictive performance on the other, imply that the model describing the relation in a certain domain is inapplicable to a different (even seemingly similar) domain due to significant differences in the distribution of the underlying data.
",4 Supervised Classification,[0],[0]
"Reflecting the poor generalization capability of translationese features, these results call for developing other methodologies for reliably discriminating O from T, specifically, methodologies that are independent of in-domain labeled data.
",4 Supervised Classification,[0],[0]
"5We focus mainly on function words, because they are known to reflect stylistic differences rather than contents or specific corpus features, and are therefore less susceptible to domain overfitting.",4 Supervised Classification,[0],[0]
Other feature sets yielded similar results.,4 Supervised Classification,[0],[0]
"To overcome the domain-dependence of supervised classification, we experiment in this section with unsupervised methods.",5.1 Initial results,[0],[0]
"We begin with the KMeans clustering algorithm, using KMeans++ initialization policy and dimension reduction.",5.1 Initial results,[0],[0]
"To evaluate the accuracy of the algorithms, each cluster is labeled by the majority of (O or T) instances it includes (using ground truth annotations), and the overall precision is the percentage of instances correctly assigned to their respective clusters (we discuss unsupervised cluster labeling in Section 5.2).
",5.1 Initial results,[0],[0]
"The KMeans clustering algorithm (with any initialization policy) is sensitive to the initial settings of its parameters, in particular the initial choice of centroids.",5.1 Initial results,[0],[0]
A cluster centroid is the geometrical center of all observations within the cluster.,5.1 Initial results,[0],[0]
The result of the KMeans algorithm may significantly vary according to its first step: the initial assignment of (random) points to cluster centroids.,5.1 Initial results,[0],[0]
"We address this potential pitfall by performing N clustering iterations, randomly varying the initial parameter settings, outputting the outcome that exhibits the highest similarity of points within a cluster.",5.1 Initial results,[0],[0]
"Formally, let C
j",5.1 Initial results,[0],[0]
"i denote cluster i in iteration j, and let m j i denote this cluster’s centroid, so that i∈[1,2], and j∈[1..N].",5.1 Initial results,[0],[0]
Sum-of-Square-Error (SSE) is an intrinsic clustering evaluation metric that measures the similarity of elements in a cluster.,5.1 Initial results,[0],[0]
"The SSE of Cji is defined by
SSE j i =
∑
x∈C j
i
(x−mji ) 2
We aim to optimize the clustering result by choosing an outcome that minimizes the accumulative SSE:
argmin j SSEj = argmin j∈[1..N ]
∑
i∈[1,2]
SSE",5.1 Initial results,[0],[0]
"j i
",5.1 Initial results,[0],[0]
The selected clustering outcome represents the result of a single clustering experiment.,5.1 Initial results,[0],[0]
"The described method for selecting a clustering outcome can be viewed as a binary version of the Bisecting KMeans algorithm; it is applied in all experiments throughout the paper, with number of iterations (N ) fixed to 5, following the recommendation by Steinbach et al. (2000, p. 13).
",5.1 Initial results,[0],[0]
We conducted a series of experiments with various feature sets; the main results are depicted in Table 5.,5.1 Initial results,[0],[0]
"The reported numbers reflect the average accuracy over 30 experiments (the only difference being a random choice of the initial conditions).6
First and foremost, the results are very good, ranging from a few percent points lower than supervised classification (Table 2, Europarl and Hansard) to approximately 25 percent points lower in a few cases (e.g., Literature).",5.1 Initial results,[0],[0]
Function words systematically yield very high accuracy; the quality of clustering with other features varies across the sub-corpora.,5.1 Initial results,[0],[0]
"Cohesive markers perform poorly (with a single exception, Hansard), which mirrors the moderate supervised classification precision achieved with the same feature set.
",5.1 Initial results,[0],[0]
"The exceptionally high result of Europarl with POS-trigrams can be attributed to the excessive frequency of specific phrases in the translated Europarl texts (in contrast to their original counterparts).7 We explain the lower precision achieved on the Literature corpus by its diverse character: it comprises works attributed to a variety of authors, periods and genres, which is challenging for the unsupervised algorithm (see Section 6).",5.1 Initial results,[0],[0]
"A notably high accuracy is obtained on the small TED corpus, which implies
6Standard deviation in most experiments was close to 0.",5.1 Initial results,[0],[0]
"7As an example (and in line with van Halteren (2008)), in the 2000 Europarl chunks, the phrase ladies and gentlemen appears 1258 times in T, but only 12 times in O.
the applicability of our clustering methodology to data-meager scenarios.
",5.1 Initial results,[0],[0]
"We conducted an additional set of experiments with unequal proportions of original and translated texts, considering twice the number of O chunks compared to T and vice versa.",5.1 Initial results,[0],[0]
"The average clustering accuracy using FW is similar to that obtained in the balanced setup (Table 5): 87.5% on Europarl, 88.9% on Hansard, 73.2% on Literature, and 88.6% on the TED sub-corpus.",5.1 Initial results,[0],[0]
"As is always the case with unsupervised methods, clustering can divide observations into classes but cannot label those classes.",5.2 Cluster labeling,[0],[0]
"A cluster labeling algorithm examines the contents of each cluster in order to find labels that best summarize its members, and distinguish the clusters from each other.
",5.2 Cluster labeling,[0],[0]
"In the context of translationese identification, the task of cluster labeling is to determine which of the produced clusters represents O, and which T. We address this challenge by exploring similarities between the language models of the obtained clusters, and language models of (presumably) prototypical O and T samples.",5.2 Cluster labeling,[0],[0]
A simple unigram language model assigns each word a probability proportional to its frequency in the underlying text; we use smoothed term frequencies scaled by the inverse total term frequencies.,5.2 Cluster labeling,[0],[0]
"We then compare language models to reveal similarities between the prototypical O and T samples and the chunk sets produced by clustering.
",5.2 Cluster labeling,[0],[0]
"The construction method of prototypical LMs is motivated by (i) abstracting from content, by utilizing only function words for this purpose; and (ii) attempting to avoid the interference of domain-related properties, by considering only (presumably) universal markers: words that share similar frequency patterns in several datasets w.r.t.",5.2 Cluster labeling,[0],[0]
"to O vs. T.
Let Om (O-markers) denote a set of function words that tend to be associated with O. We select this set by picking words whose frequency in O is excessive, compared to T; more precisely, the ratio of their frequency in O and T is above (1+δ), where δ=0.05.",5.2 Cluster labeling,[0],[0]
"Similarly, Tm (T-markers) is a set of words with O-to-T frequency ratio below (1-δ).",5.2 Cluster labeling,[0],[0]
"We create a prototypical O example by the concatenation of Om, and a prototypical T example by the concatenation of Tm.",5.2 Cluster labeling,[0],[0]
"The language model of these examples
is then constructed by the ǫ-smoothed likelihood of each term in the markers vocabulary V = Om ⋃
Tm, where ǫ=0.001.
",5.2 Cluster labeling,[0],[0]
"Formally, for w ∈ V ,
p(w | Om) = tf (w) + ǫ
|Om|+ ǫ× |V",5.2 Cluster labeling,[0],[0]
"|
p(w | Tm) = tf (w) + ǫ
|Tm|+ ǫ× |V",5.2 Cluster labeling,[0],[0]
"|
We denote the resulting language models by PO and PT , respectively.",5.2 Cluster labeling,[0],[0]
"Given two clusters, C1 and C2, we similarly compute their language models, denoted by PC1 and PC2 , respectively, over the vocabulary V .",5.2 Cluster labeling,[0],[0]
"We measure the similarity between a class X (either O or T) and a cluster Ci using the JensenShannon divergence (JSD) (Lin, 1991) on the respective probability distributions.",5.2 Cluster labeling,[0],[0]
"Specifically, we define the distance between the language models as the square root of the divergence value, which is a metric, often referred to as Jensen-Shannon distance (Endres and Schindelin, 2003):
DJS(X,Ci) = 2
√
JSD(PX ||PCi)
",5.2 Cluster labeling,[0],[0]
"The assignment of the label X to the cluster C1 is then supported by both C1’s proximity to the class X and C2’s proximity to the other class:
label(C1)=

 
 
“O” if DJS(O,C1)×DJS(T,C2)<
α×DJS(O,C2)×DJS(T,C1)
“T” otherwise
C2 is assigned the complementary label.",5.2 Cluster labeling,[0],[0]
"The value of α is fixed to 1 in this equation, but we note that it can be varied for further investigation of the relatedness of the underlying language models.
",5.2 Cluster labeling,[0],[0]
We apply the cluster labeling technique described above to determine the labels of generated clusters.,5.2 Cluster labeling,[0],[0]
"We construct prototypical O- and T-texts by selecting O- and T-markers from a random sample of Europarl and Hansard texts, using 600 chunks from each corpus.8",5.2 Cluster labeling,[0],[0]
"We then compare the language models induced by these samples to those of the generated clusters (tested on different chunks, of course)
8This subset of the Europarl and Hansard corpora was used for one-time generation of prototypical O and T language models, and excluded from further use.
to determine the cluster labels; the predicted labels are then verified against the majority-driven labeling, based on ground truth annotations.",5.2 Cluster labeling,[0],[0]
"We apply this procedure to the outcome of all clustering experiments (per domain, using various features), achieving overall precision of 100%.",5.2 Cluster labeling,[0],[0]
"In other words, the labeling procedure yields prefect accuracy not only on Europarl and Hansard texts that were not used for generation of O and T prototypical examples, but also on unseen Literature and TED datasets.",5.2 Cluster labeling,[0],[0]
"We conclude that it is possible, in general, to determine the labels of clusters produced by our clustering algorithm with perfect accuracy.",5.2 Cluster labeling,[0],[0]
"Since different feature sets have different predictions on our data, we hypothesize that consensus voting can improve the accuracy of clustering.",5.3 Clustering consensus among feature sets,[0],[0]
"We treat each individual clustering result (based on a certain feature set) as a judge, voting whether a single text chunk belongs to O or to T. We use the cluster labeling method of Section 5.2 to determine labels.",5.3 Clustering consensus among feature sets,[0],[0]
"The final assignment of a label to a cluster is determined by the majority vote of the various judges.
",5.3 Clustering consensus among feature sets,[0],[0]
Table 6 presents the results of these experiments.,5.3 Clustering consensus among feature sets,[0],[0]
"We compare consensus results to the accuracy achieved by function words, the best-performing single feature set (on average), see Table 5.",5.3 Clustering consensus among feature sets,[0],[0]
Both three judges and five judges yield a consistent increase in accuracy.,5.3 Clustering consensus among feature sets,[0],[0]
"Five judges systematically (and, on Europarl and Hansard, significantly) outperform the result of clustering with functions words only.",5.3 Clustering consensus among feature sets,[0],[0]
"This indicates that various features tend to capture different aspects of translationese, that are eventually leveraged by the “fusion” of different clustering results into a single, higher-quality outcome.",5.3 Clustering consensus among feature sets,[0],[0]
"In supervised classification, the amount of labeled data has a critical effect on the classification accuracy.",5.4 Sensitivity analysis,[0],[0]
This does not seem to be the case with clustering: accuracy remains stable when the number of chunks used for classification decreases (Figure 1a).,5.4 Sensitivity analysis,[0],[0]
"Evidently, as few as 300 chunks are sufficient for excellent classification.9",5.4 Sensitivity analysis,[0],[0]
"We attribute the (slight) fluctuations in the graph to the random choice of the
9The results on the Literature corpus are limited by the amount of available data in this dataset.
subset of chunks that are subject for clustering.",5.4 Sensitivity analysis,[0],[0]
"Naturally, clustering accuracy stabilizes when the number of chunks increases, since the effect of random noise diminishes with more data.",5.4 Sensitivity analysis,[0],[0]
"This result is of clear practical importance, as in real-life situations only a limited amount of data may be available.
",5.4 Sensitivity analysis,[0],[0]
"The accuracy of supervised classification deteriorates when the size of the underlying logical units (here, chunks) decreases (Kurokawa et al., 2009).",5.4 Sensitivity analysis,[0],[0]
"We corroborate this observation in the context of clustering, but note that reasonable accuracy (over 70%) can be obtained even with 1000-token chunks (Figure 1b).",5.4 Sensitivity analysis,[0],[0]
This further supports the applicability of unsupervised classification of translationese to real-world scenarios.,5.4 Sensitivity analysis,[0],[0]
"Poor cross-domain classification results, as described in Section 4, demonstrate that the in-domain discriminative features of translated texts cannot be easily generalized to other, even related, domains.",6 Mixed-domain classification,[0],[0]
"In this section we explore the tension between the discriminative power of domain- and translationeserelated properties, in the unsupervised scenario.",6 Mixed-domain classification,[0],[0]
Our underlying hypothesis is that domain-specific features overshadow the features of translationese.,6 Mixed-domain classification,[0],[0]
The next series of experiments involves (a balanced) combination of various datasets; we excluded the small TED corpus from these experiments to prevent downsampling of other sub-corpora.,6 Mixed-domain classification,[0],[0]
We begin with an investigation of the mutual effect of the domain- and translationese-specific characteristics on the accuracy of clustering.,6.1 Domain-related vs. translationese-based characteristics,[0],[0]
"We first merged equal numbers of O and T chunks from two corpora: 800 chunks each from Europarl and Hansard, yielding 1,600 chunks, half of them O and half T. We applied the clustering algorithm of Section 5 to this dataset; the result was a perfect domain-driven separation of all Europarl and Hansard chunks, yielding poor (chance-level) translationese accuracy.",6.1 Domain-related vs. translationese-based characteristics,[0],[0]
"In other words, we obtained two clusters, one consisting of Europarl chunks and the other of Hansard chunks, independently of their O-vs.-T status.",6.1 Domain-related vs. translationese-based characteristics,[0],[0]
"We repeated the experiment with additional corpus pairs, and further extended it by adding equal numbers of Literature chunks (400 O and 400 T), this time fixing the number of clusters to three.",6.1 Domain-related vs. translationese-based characteristics,[0],[0]
"Again, the result was separation by domain: Europarl, Hansard and Literature chunks were grouped into distinct clusters (Table 7, top).
",6.1 Domain-related vs. translationese-based characteristics,[0],[0]
"As an additional experiment, we attempted to leave the decision on the “best” number of clusters to the algorithm.",6.1 Domain-related vs. translationese-based characteristics,[0],[0]
"To that end, we employed the XMeans clustering procedure (Pelleg and Moore, 2000), which uses KMeans but applies additional statistical cues to decide on the number of clusters that best explain the data.",6.1 Domain-related vs. translationese-based characteristics,[0],[0]
We also applied PCA for dimension reduction prior to XMeans invocation.,6.1 Domain-related vs. translationese-based characteristics,[0],[0]
"We repeated both experiments (two- and threedomain mixes) with XMeans, expecting to obtain two and three clusters, respectively.",6.1 Domain-related vs. translationese-based characteristics,[0],[0]
"The result is a replication of the more constrained KMeans in three out of four cases (Table 7, bottom).
",6.1 Domain-related vs. translationese-based characteristics,[0],[0]
These observations have a crucial effect on understanding the tension between the domain- and translationese-based characteristics of the underlying texts.,6.1 Domain-related vs. translationese-based characteristics,[0],[0]
"Not only are domains accurately separated given a fixed number of clusters, but even when the decision on the number of clusters is left to the clustering procedure, classification into domains explains the data best (as shown by XMeans).",6.1 Domain-related vs. translationese-based characteristics,[0],[0]
"Recall that these experiments all rely on the set of function words: topic-independent features, that have been proven effective for telling O from T in both supervised (Section 2) and unsupervised scenarios (Sec-
tion 5).",6.1 Domain-related vs. translationese-based characteristics,[0],[0]
The fact that this translationese-oriented feature set yields the results presented in Table 7 clearly demonstrates the dominance of domainspecific properties over the characteristics of translationese.10,6.1 Domain-related vs. translationese-based characteristics,[0],[0]
"Driven by the results of Section 6.1, we turn to explore a methodology for identification of translationese in a mixed-domain setup.",6.2 Clustering in a mixed-domain setup,[0],[0]
"We assume that we are given a set of text chunks that come from multiple domains, such that some chunks are O and some are T; the task is to classify the texts to O vs. T, independently of their domain.",6.2 Clustering in a mixed-domain setup,[0],[0]
"For that purpose, we investigate two approaches: two-phase and flat.",6.2 Clustering in a mixed-domain setup,[0],[0]
"Both methods assume that the number of domains, k, is known (it can be discovered by XMeans, as in Section 6.1, or fixed to a somewhat higher value than estimated in order to capture unsuspected differences within domains).",6.2 Clustering in a mixed-domain setup,[0],[0]
"The two-phase method first clusters a mixture of texts into domains (e.g., using KMeans), and then separates each of the resulting (presumably, domain-coherent) clusters into two sub-clusters, presumably O and T. The flat approach applies KMeans, attempting to divide the dataset into 2 × k clusters; that is, we expect classification by domains and by translationese status, simultaneously.
",6.2 Clustering in a mixed-domain setup,[0],[0]
"We experimented with two setups:(i) mixture of two datasets out of Europarl, Hansard and Literature (1600 chunks in total); and (ii) mixture of all
10Other feature sets yielded similar outcomes.
",6.2 Clustering in a mixed-domain setup,[0],[0]
three of them (2400 chunks in total).,6.2 Clustering in a mixed-domain setup,[0],[0]
We applied both methods to each of the two setups.,6.2 Clustering in a mixed-domain setup,[0],[0]
"We invoked PCA prior to clustering in the flat approach; in the two-phase approach, we applied PCA on raw data instances that are subject to clustering at each hierarchy level.11 As our goal is identification of translationese, we define the accuracy of the classification as the ratio of O and T instances classified correctly (i.e., we ignore the accuracy of identifying the correct domain).
",6.2 Clustering in a mixed-domain setup,[0],[0]
Table 8 reports the results.,6.2 Clustering in a mixed-domain setup,[0],[0]
"Both methods yield similarly high accuracy in the Europarl+Hansard setup, and much lower accuracy in the setup of all three datasets (with a single exception of EUR+LIT).",6.2 Clustering in a mixed-domain setup,[0],[0]
This implies that the difficulty of telling O from T increases as the number of domains in the mixed-domain setup grows.,6.2 Clustering in a mixed-domain setup,[0],[0]
"The two-phase approach outperforms the flat one in most cases: the latter attempts to cluster data instances by domain and translation status simultaneously, and is therefore potentially more error-prone.",6.2 Clustering in a mixed-domain setup,[0],[0]
"As a concrete example, in the Europarl+Literature setup, attempting to produce four clusters, we obtained a single cluster of Europarl chunks and three clusters of Literature chunks.",6.2 Clustering in a mixed-domain setup,[0],[0]
"The two-phase approach avoids such pitfalls by explicitly separating the steps of domainand translationese-based clustering.
",6.2 Clustering in a mixed-domain setup,[0],[0]
"Table 8 clearly demonstrates that in a real-world scenario, where a dataset can be assumed to include texts from multiple domains, it is possible to over-
11Note that our two-phase approach differs from the traditional hierarchical clustering in this sense.
come the dominance of domain-related features over translationese-related ones by splitting the task into two.",6.2 Clustering in a mixed-domain setup,[0],[0]
"The result is highly accurate identification of translated texts, even in an extremely challenging setup.",6.2 Clustering in a mixed-domain setup,[0],[0]
"Compare the results of Table 8 to the supervised case (Tables 3, 4): while clustering cannot compete with ten-fold cross-validation results of heterogenous datasets (93–96%), it is far superior to training a classifier on one or more datasets and then using it on a data from a new source (60–64%).",6.2 Clustering in a mixed-domain setup,[0],[0]
"Distinguishing between original and translated texts has been proven useful for SMT, as awareness to translationese can improve the quality of SMT systems.",7 Discussion,[0],[0]
"So far, classifying texts into original vs. translated has been done almost exclusively by supervised methods.",7 Discussion,[0],[0]
In this work we advocate the use of unsupervised classification as an effective way to address this task.,7 Discussion,[0],[0]
"We demonstrate that simple feature sets, coupled with standard clustering algorithms, a novel cluster labeling technique, and voting among several features, can yield very high accuracy, over 90% in several cases.",7 Discussion,[0],[0]
"Using diverse datasets we robustly demonstrate that the approach we advocate is effective for identification of translationese, even when only little data are available, and text chunks are small.",7 Discussion,[0],[0]
"We further highlight the dominance of domain-based characteristics of the texts over their translationese-related properties and propose a sim-
ple methodology for identification of translationese in a mixed-domain setup.",7 Discussion,[0],[0]
"We conclude that the proposed (two-phase) clustering approach is a robust method for distinguishing O from T in heterogenous datasets.
",7 Discussion,[0],[0]
"By conducting a series of experiments with unbalanced proportions of O and T texts, we demonstrate that the proposed methodology is also applicable to scenarios where the original and translated data are unevenly distributed.
",7 Discussion,[0],[0]
We applied PCA for dimension reduction and the tf-idf weighting scheme with FW throughout all experiments in this work.,7 Discussion,[0],[0]
"The latter had a slight positive effect on clustering accuracy in most scenarios, and no impact in some cases.",7 Discussion,[0],[0]
"Dimension reduction improved computational efficiency, especially with large feature sets (e.g., character and POS trigrams).",7 Discussion,[0],[0]
"However, its effect on clustering accuracy was not uniform: the most prominent improvement (over 15 percent points) was obtained on the TED dataset, while a slight accuracy deterioration was observed in a few cases (e.g., 5 percent points on Europarl with FW).",7 Discussion,[0],[0]
"We conclude that while carrying an overall positive value, the application of dimension reduction in similar scenarios calls for further investigation.",7 Discussion,[0],[0]
"To the best of our knowledge, this is the first work to extensively explore unsupervised classification of
translationese.",8 Conclusion,[0],[0]
We only scratched the surface of this research direction.,8 Conclusion,[0],[0]
"In the future, we intend to explore the robustness of our approach even further, with more datasets in various language pairs.",8 Conclusion,[0],[0]
"We will first attempt to identify translationese in French, using the current dataset (in the reverse direction).",8 Conclusion,[0],[0]
"We will also experiment with English-German, in both directions, and hopefully also with EnglishHebrew, a more challenging setup.
",8 Conclusion,[0],[0]
The potential value of unsupervised identification of translationese leaves much room for further exploratory activities.,8 Conclusion,[0],[0]
"Our future plans include using various datasets and reduced amount of data for LMs compiled for cluster labeling; in particular, we plan to explore the correlation between these two parameters and the scaling factor α used for association of a label with a clustering outcome.
",8 Conclusion,[0],[0]
"Furthermore, to highlight the contribution of these results to SMT, we plan to replicate the results of Lembersky et al. (2012b, 2013), using predicted rather than ground-truth indication of the translationese status of the texts that are used to train SMT systems.",8 Conclusion,[0],[0]
We believe that we will be able to show an improvement in the quality of SMT with extremely little supervision.,8 Conclusion,[0],[0]
This research was supported by a grant from the Israeli Ministry of Science and Technology.,Acknowledgements,[0],[0]
"We are grateful to Cyril Goutte, George Foster and Pierre Isabelle for providing us with an annotated version of the Hansard corpus; and to András",Acknowledgements,[0],[0]
Farkas12 and François Yvon for providing us with the Literary corpus.,Acknowledgements,[0],[0]
"Finally, we are indebted to Noam Ordan, Tamir Hazan, Haggai Roitman and Ekaterina Lapshinova-Koltunski for commenting on earlier versions of this article.",Acknowledgements,[0],[0]
"All remaining errors and misconceptions are, of course, our own.",Acknowledgements,[0],[0]
"Translated texts are distinctively different from original ones, to the extent that supervised text classification methods can distinguish between them with high accuracy.",abstractText,[0],[0]
These differences were proven useful for statistical machine translation.,abstractText,[0],[0]
"However, it has been suggested that the accuracy of translation detection deteriorates when the classifier is evaluated outside the domain it was trained on.",abstractText,[0],[0]
"We show that this is indeed the case, in a variety of evaluation scenarios.",abstractText,[0],[0]
We then show that unsupervised classification is highly accurate on this task.,abstractText,[0],[0]
"We suggest a method for determining the correct labels of the clustering outcomes, and then use the labels for voting, improving the accuracy even further.",abstractText,[0],[0]
"Moreover, we suggest a simple method for clustering in the challenging case of mixed-domain datasets, in spite of the dominance of domainrelated features over translation-related ones.",abstractText,[0],[0]
"The result is an effective, fully-unsupervised method for distinguishing between original and translated texts that can be applied to new domains with reasonable accuracy.",abstractText,[0],[0]
Unsupervised Identification of Translationese,title,[0],[0]
"Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1–10, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
"Shallow semantic representations, and semantic role labels in particular, have a long history in linguistics (Fillmore, 1968).",1 Introduction,[0],[0]
"More recently, with an emergence of large annotated resources such as PropBank (Palmer et al., 2005) and FrameNet (Baker et al., 1998), automatic semantic role labeling (SRL) has attracted a lot of attention (Gildea and Jurafsky, 2002; Carreras and Màrquez, 2005; Surdeanu et al., 2008; Hajič",1 Introduction,[0],[0]
"et al., 2009; Das et al., 2010).
",1 Introduction,[0],[0]
"Semantic role representations encode the underlying predicate-argument structure of sentences, or, more specifically, for every predicate in a sentence they identify a set of arguments and associate each argument with an underlying semantic role, such
as an agent (an initiator or doer of the action) or a patient (an affected entity).",1 Introduction,[0],[0]
"Semantic roles have many potential applications in NLP and have been shown to benefit question answering (Shen and Lapata, 2007; Kaisser and Webber, 2007), textual entailment (Sammons et al., 2009), machine translation (Wu and Fung, 2009; Liu and Gildea, 2010; Wu et al., 2011; Gao and Vogel, 2011), and dialogue systems (Basili et al., 2009; van der Plas et al., 2009), among others.
",1 Introduction,[0],[0]
"Most current statistical approaches to SRL are supervised, requiring large quantities of human annotated data to estimate model parameters.",1 Introduction,[0],[0]
"However, such resources are expensive to create and only available for a small number of languages.",1 Introduction,[0],[0]
"Moreover, when moved to a new domain (e.g., from news corpora to blogs or biomedical texts), the performance of these models tends to degrade substantially (Pradhan et al., 2008).",1 Introduction,[0],[0]
"The scarcity of annotated data has motivated the research into unsupervised learning of semantic representations (Swier and Stevenson, 2004; Grenager and Manning, 2006; Lang and Lapata, 2010; Lang and Lapata, 2011a; Lang and Lapata, 2011b; Titov and Klementiev, 2012a; Fürstenau and Rambow, 2012; Garg and Henderson, 2012).",1 Introduction,[0],[0]
The existing methods have a number of serious shortcomings.,1 Introduction,[0],[0]
"First, they make very strong assumptions, for example, assuming that arguments are conditionally independent of each other given the predicate.",1 Introduction,[0],[0]
"Second, unlike state-ofthe-art supervised parsers, they rely on a very simplistic set of features of a sentence.",1 Introduction,[0],[0]
"These factors lead to models being insufficiently expressive to capture the syntax-semantics interface, inadequate
1
handling of language ambiguity and, overall, introduces a restrictive upper bound on their performance.",1 Introduction,[0],[0]
"Moreover, these approaches are especially problematic for languages with freer word order than English, where richer features are necessary to account for interactions between surface realizations, syntax and semantics.",1 Introduction,[0],[0]
"For example, the two most accurate previous models (Titov and Klementiev, 2012a; Lang and Lapata, 2011a) both treat the role induction task as clustering of argument signatures: an argument signature encodes key syntactic properties of an argument realization and consists of a syntactic function of an argument along with additional information such as an argument position with respect to the predicate.",1 Introduction,[0],[0]
"Though it is possible to design signatures which mostly map to a single role, this set-up limits oracle performance even for English, and can be quite restrictive for languages with freer word order.",1 Introduction,[0],[0]
"These shortcomings are inherent limitations of the modeling frameworks used in previous work (primarily generative modeling or agglomerative clustering), and cannot be addressed by simply incorporating more features or relaxing some of the modeling assumptions.
",1 Introduction,[0],[0]
"In this work, we propose a method for effective unsupervised estimation of feature-rich models of semantic roles.",1 Introduction,[0],[0]
"We demonstrate that reconstructionerror objectives, which have been shown to be effective primarily for training neural networks, are well suited for inducing feature-rich log-linear models of semantics.",1 Introduction,[0],[0]
Our model consists of two components: a log-linear feature-rich semantic role labeler and a tensor-factorization model which captures interaction between semantic roles and argument fillers.,1 Introduction,[0],[0]
"When estimated jointly on unlabeled data, roles induced by the model mostly corresponds to roles defined in existing resources by annotators.
",1 Introduction,[0],[0]
"Our method rivals the most accurate semantic role induction methods on English and German (Titov and Klementiev, 2012a; Lang and Lapata, 2011a).",1 Introduction,[0],[0]
"Importantly, no prior knowledge about the languages was incorporated in our feature-rich model, whereas the clustering counterparts relied on language-specific argument signatures.",1 Introduction,[0],[0]
These languages-specific priors were crucial for their success.,1 Introduction,[0],[0]
"For example, using English-specific argument signatures for German with the Bayesian model of Titov and Klementiev (2012a) results in a drop of
performance from clustering F1 of 80.9% to considerably lower 78.3% (our model yields 81.4%).",1 Introduction,[0],[0]
"This confirms the intuition that using richer features helps to capture the syntax-semantics interface in multilingual settings, reducing the need for languagespecific model engineering, as is highly desirable in unsupervised learning.
",1 Introduction,[0],[0]
The rest of the paper is structured as follows.,1 Introduction,[0],[0]
Section 2 begins with a definition of the semantic role labeling task and discusses some specifics of the unsupervised setting.,1 Introduction,[0],[0]
"In Section 3, we describe our approach, starting with a general motivation and proceeding to technical details of the model (Section 3.3) and the learning procedure (Section 3.4).",1 Introduction,[0],[0]
Section 4 provides both evaluation and analysis.,1 Introduction,[0],[0]
"Finally, additional related work is presented in Section 5.",1 Introduction,[0],[0]
"The SRL task involves prediction of predicate argument structure, i.e. both identification of arguments and assignment of labels according to their underlying semantic role.",2 Task Definition,[0],[0]
"For example, in the following sentences:
(a) [Agent Mary] opened [Patient the door].
(b)",2 Task Definition,[0],[0]
"[Patient The door] opened.
",2 Task Definition,[0],[0]
(c),2 Task Definition,[0],[0]
"[Patient The door] was opened [Agent by Mary].
",2 Task Definition,[0],[0]
"Mary always takes an agent role for the predicate open, and door is always a patient.
",2 Task Definition,[0],[0]
In this work we focus on the labeling stage of semantic role labeling.,2 Task Definition,[0],[0]
"Identification, though an important problem, can be tackled with heuristics (Lang and Lapata, 2011a; Grenager and Manning, 2006; de Marneffe et al., 2006), with unsupervised techniques (Abend et al., 2009) or potentially by using a supervised classifier trained on a small amount of data.",2 Task Definition,[0],[0]
At the core of our approach is a statistical model encoding an interdependence between a semantic role structure and its realization in a sentence.,3 Approach,[0],[0]
"In the unsupervised learning setting, sentences, their syntactic representations and argument positions (denoted by x) are observable whereas the associated semantic roles r are latent and need to be induced by the
model.",3 Approach,[0],[0]
The idea which underlines much of latent variable modeling is that a good latent representation is the one which helps us to reconstruct x.,3 Approach,[0],[0]
"In practice, we are not interested in predicting x, as x is observable, but rather interested in inducing appropriate latent representations (i.e. r).",3 Approach,[0],[0]
"Thus, it is crucial to design the model in such a way that the good r (the one predictive of x) indeed encodes roles, rather than some other form of abstraction.
",3 Approach,[0],[0]
"In what follows, we will refer to roles using their names, though, in the unsupervised setting, our method, as any other latent variable model, will not yield human-interpretable labels for them.",3 Approach,[0],[0]
"We will use the following sentence as a motivating example in our discussion of the model:
[Agent The police] charged [Patient the demonstrators]",3 Approach,[0],[0]
"[Instrument with batons].
",3 Approach,[0],[0]
The model consists of two components.,3 Approach,[0],[0]
The first component is responsible for prediction of argument tuples based on roles and the predicate.,3 Approach,[0],[0]
"In our experiments, in this component, we represent arguments as lemmas of their lexical heads (e.g., baton instead of with batons).",3 Approach,[0],[0]
We also restrict ourselves to only verbal predicates.,3 Approach,[0],[0]
"Intuitively, we can think of predicting one argument at a time (see Figure 1(b)): an argument (e.g., demonstrator in our example) is predicted based on the predicate lemma (charge), the role assigned to this argument (i.e. Patient) and other role-argument pairs ((Agent, police) and (Instrument, baton)).",3 Approach,[0],[0]
"While learning to predict arguments, the inference algorithm will search for role assignments which simplify this prediction task as much as possible.",3 Approach,[0],[0]
"Our hypothesis is that these assignments will correspond to roles accepted in linguistic theories (or, more importantly, useful in practical applications).",3 Approach,[0],[0]
Why is this hypothesis plausible?,3 Approach,[0],[0]
Primarily because these semantic representations were introduced as an abstraction capturing the essence of a situation (or a event).,3 Approach,[0],[0]
"And the underlying situation and participant roles in this situation (rather than surface linguistic details like argument order or syntactic functions) are precisely what impose constraints on admissible argument tuples.
",3 Approach,[0],[0]
The reconstruction component is not the only part of the model.,3 Approach,[0],[0]
"Crucially, what we referred to above as ‘searching for role assignments to simplify argument prediction’ would actually correspond to
learning another component: a semantic role labeler which predicts roles relying on a rich set of sentence features.",3 Approach,[0],[0]
These two components will be estimated jointly in such a way as to minimize errors in recovering arguments.,3 Approach,[0],[0]
"The role labeler will be the endproduct of learning: it will be used to process new sentences, and it will be compared to existing methods in our evaluation.",3 Approach,[0],[0]
The above paragraph can be regarded as our desiderata; now we discuss how to achieve them.,3.1 Shortcomings of generative modeling,[0],[0]
"The standard way to approach latent variable modeling is to use the generative framework: that is to define a family of joint models p(x, y|θ) and estimate the parameters θ by, for example, maximizing the likelihood.",3.1 Shortcomings of generative modeling,[0],[0]
"Generative models of semantics (Titov and Klementiev, 2012a; Titov and Klementiev, 2011; Modi et al., 2012; O’Connor, 2013; Kawahara et al., 2014) necessarily make very strong independence assumptions (e.g., arguments are conditionally independent of each other given the predicate) and use simplistic features of x and y.",3.1 Shortcomings of generative modeling,[0],[0]
"Thus, they cannot meet the desiderata stated above.",3.1 Shortcomings of generative modeling,[0],[0]
"Importantly, they are also much more simplistic in their assumptions than state-of-the-art supervised role labelers (Erk and Pado, 2006; Johansson and Nugues, 2008; Das et al., 2010).",3.1 Shortcomings of generative modeling,[0],[0]
Generative modeling is not the only way to learn latent representations.,3.2 Reconstruction error minimization,[0],[0]
"One alternative, popular in the neural network community, is to instead use autoencoders and optimize the reconstruction error (Hinton, 1989; Vincent et al., 2008).",3.2 Reconstruction error minimization,[0],[0]
"In autoencoders, a latent representation y (their hidden layer) is predicted from x by an encoding model and then this y is used to recover x̃with a reconstruction model (see Figure 1(a)).",3.2 Reconstruction error minimization,[0],[0]
"Parameters of the encoding and reconstruction components are chosen so as to minimize some form of the reconstruction error, for example, the Euclidean distance ∆(x, x̃) = ||x−x̃||2.",3.2 Reconstruction error minimization,[0],[0]
"Though currently popular only within the deep learning community, latent variable models other than neural networks can also be trained this way, moreover:
• the encoding and reconstruction models can belong to different model families;
• the reconstruction component may be focused on recovering a part of x rather than the entire x, and, in doing so, can rely not only on y but on the remaining part of x.
These observations are crucial as they allow us to implement our desiderata.",3.2 Reconstruction error minimization,[0],[0]
"More specifically, the encoding model will be a feature-rich classifier which predicts semantic roles for a sentence, and the reconstruction model is the model which predicts an argument given its role, and given the rest of the arguments and their roles.",3.2 Reconstruction error minimization,[0],[0]
The idea of training linear models by minimizing the reconstruction error was previously explored by Daumé (2009) and very recently by Ammar et al. (2014).,3.2 Reconstruction error minimization,[0],[0]
"There are several possible ways to translate the ideas above into a specific method, and we consider one of the simplest instantiations.",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"For simplicity, in the discussion (but not in our experiments), we assume that exactly one predicate is realized in each sentence x.",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"As we mentioned above, we focus only on argument labeling: we assume that arguments a = (a1, . . .",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
", aN ), ai ∈ A, are known, and only their roles r = (r1, . . .",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
", rN ), ri ∈ R need to be induced.",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"For the encoder (i.e. the semantic role labeler), we use a log-linear model:
p(r|x,w) ∝",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"exp(wTg(x, r)), where g(x, r) is a feature vector encoding interactions between sentence x and the semantic role rep-
resentation",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
r.,3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
Any model can be used here as long as the posterior distributions of roles ri can be efficiently computed or approximated (we will see why in Section 3.4).,3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"In our experiments, we used a model which factorizes over individual arguments (i.e. a set of independent logistic regression classifiers).
",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"The reconstruction component predicts an argument (e.g., the ith argument ai) given the semantic roles r, the predicate v and other arguments a−i = (a1, . . .",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
", ai−1, ai+1, . . .",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
", aN ) with a bilinear softmax model:
p(ai|a−i, r,v,C,u)= exp(uTaiC T v,ri ∑ j 6=iCv,rjuaj)
Z(r, v, i) , (1)
ua ∈ Rd (for every a ∈ A) and Cv,r ∈ Rk×d (for every verb v and every role r ∈ R) are model parameters, Z(r, v, i) is the partition function ensuring that the probabilities sum to one.",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"Intuitively, embeddings ua, when learned from data, will encode semantic properties of an argument: for example, embeddings for the words demonstrator and protestor should be somewhere near each other in Rd space, and further away from that for the word cat.",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"The product Cv,rua is a k-dimensional vector encoding beliefs about other arguments based on the argument-role pair (a, r).",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"For example, seeing the argument demonstrator in the Patient position for the predicate charge, one would predict that the Agent is perhaps the word police, and the role Instrument is filled by the word baton or perhaps
(a water) cannon.",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"On the contrary, if the Patient is cat then the Agent is more likely to be dog than police.",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"In turn, the dot product (Cv,riuai)
TCv,rjuaj is large if these expectations are met for the argument pair (ai, aj), and small otherwise.",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"Intuitively, this objective corresponds to scoring argument tuples according to
h(a, r, v, C,u) =",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
∑,3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"i 6=j uTaiC T v,riCv,rjuaj , (2)
hinting at connections to (coupled) tensor and matrix factorization methods (Nickel et al., 2011; Yılmaz et al., 2011; Bordes et al., 2011; Riedel et al., 2013) and distributional semantics (Mikolov et al., 2013; Pennington et al., 2014).",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"Note also that the reconstruction model does not have access to any features of the sentence (e.g., argument order or syntax), forcing the roles to convey all the necessary information.
",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
This factorization can be thought of as a generalization of the notion of selection preferences.,3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"Selectional preferences characterize the set of arguments licensed for a given role of a given predicate: for example, Agent for the predicate charge can be police or dog but not table or idea.",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"In our generalization, we model soft restrictions imposed not only by the role itself but also by other arguments and their assignment to roles.
",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"In practice, we extend the model slightly: (1) we introduce a word-specific bias (a scalar ba for every a ∈ A) in the argument prediction model (equation (1)); (2) we smooth the model by using a sum of predicate-specific and cross-predicate projection matrices (Cv,r + Cr) instead of just Cv,r.",3.3 Modeling semantics within the reconstruction-error framework,[0],[0]
"Parameters of both model components (w, u and C) are learned jointly: the natural objective associated with every sentence would be the following:
N∑ i=1",3.4 Learning,[0],[0]
"log ∑ r p(ai|a−i, r, v, C,u)p(r|x,w).",3.4 Learning,[0],[0]
"(3)
However optimizing this objective is not practical in its exact form for two reasons: (1) marginalization over r is exponential in the number of arguments; (2) the partition function Z(r, v, i) requires summation over the entire set of potential argument
lemmas.",3.4 Learning,[0],[0]
"We use existing techniques to address both challenges.
",3.4 Learning,[0],[0]
"In order to deal with the first challenge, we use a basic mean-field approximation.",3.4 Learning,[0],[0]
"Namely, instead of computing an expectation of p(ai|a−i, r,v,C,u) under p(r|x,w), as in (3), we use the posterior distributions µis = p(ri = s|x,w) and score the argument predictions as
p(ai|a−i,µ,v,C,u) = exp (φi(ai,a−i)) Z(µ, v, i) (4) φi(ai,a−i) = uTai( ∑
s
µisCv,",3.4 Learning,[0],[0]
"s)T
× ∑ j 6=i ( ∑ s µjsCv,s)uaj ,
where µ are the posteriors for all the arguments, and φi(a,a−i) is the score associated with predicting lemma a for the argument i.
",3.4 Learning,[0],[0]
"In order to address the second problem, the computation of Z(µ, v, i), we use a negative sampling technique (see, e.g., Mikolov et al. (2013)).",3.4 Learning,[0],[0]
"More specfically, we get rid of the softmax in equation (4) and optimize the following sentence-level objective:
N∑ i=1",3.4 Learning,[0],[0]
"[log σ(φi(ai,a−i))
",3.4 Learning,[0],[0]
"− ∑ a′∈S log σ(φi(a′,a−i))",3.4 Learning,[0],[0]
"], (5)
where S is a random sample of n elements from the unigram distribution of lemmas, and σ is the logistic sigmoid function.
",3.4 Learning,[0],[0]
"Assuming that the posteriors µ can be derived in a closed form, the gradients of the objective (5) with respect to parameters of both the encoding component (w) and the reconstruction component (C, u and b) can be computed using back propagation.",3.4 Learning,[0],[0]
"In our experiments, we used the AdaGrad algorithm (Duchi et al., 2011) to perform the optimization.
",3.4 Learning,[0],[0]
"The learning algorithm is quite efficient, as the reconstruction computation is bilinear, whereas the computation of the posteriors µ (and the computation of their gradients) from the semantic roler labeling component (encoder) is not much more expensive than discriminative supervised learning of
the role labeler.",3.4 Learning,[0],[0]
"Moreover, the computations can be sped up substantially by observing that the sum∑
s µisCv,s in expression (4) can be precomputed for all i, and reused across predictions of different arguments of the same predicate.",3.4 Learning,[0],[0]
"At test time, only the linear semantic role labeler is used, so the inference is straightforward.",3.4 Learning,[0],[0]
We considered English and German in our experiments.,4.1 Data and evaluation metrics,[0],[0]
"For each language, we replicated experimental set-ups used in previous work.
",4.1 Data and evaluation metrics,[0],[0]
"For English, we followed Lang and Lapata (2010) and used the dependency version of PropBank (Palmer et al., 2005) released for the CoNLL 2008 shared task (Surdeanu et al., 2008).",4.1 Data and evaluation metrics,[0],[0]
The dataset is divided into three segments.,4.1 Data and evaluation metrics,[0],[0]
"As in the previous work on unsupervised role labeling, we used the largest segment (the original CoNLL training set, sections 2-21) both for evaluation and learning.",4.1 Data and evaluation metrics,[0],[0]
This is permissible as unsupervised models do not use gold labels in training.,4.1 Data and evaluation metrics,[0],[0]
The two small segments (sections 22 and 23) were used for model development.,4.1 Data and evaluation metrics,[0],[0]
"In our experiments, we relied on gold standard syntax and gold standard argument identification, as this set-up allows us to evaluate against much of the previous work.",4.1 Data and evaluation metrics,[0],[0]
"We refer the reader to Lang and Lapata (2010) for details of the experimental set-up.
",4.1 Data and evaluation metrics,[0],[0]
"There has not been much work on unsupervised induction of roles for languages other than English, perhaps primarily because of the above-mentioned model limitations.",4.1 Data and evaluation metrics,[0],[0]
"For German, we replicate the set-up considered in Titov and Klementiev (2012b).",4.1 Data and evaluation metrics,[0],[0]
"They used the CoNLL 2009 version (Hajič et al., 2009) of the SALSA corpus (Burchardt et al., 2006).",4.1 Data and evaluation metrics,[0],[0]
"Instead of using syntactic parses provided in the CoNLL dataset, they re-parsed it with the MALT dependency parser (Nivre et al., 2004).",4.1 Data and evaluation metrics,[0],[0]
"Similarly, rather than relying on gold standard annotations for argument identification, they used a supervised classifier to predict argument positions.",4.1 Data and evaluation metrics,[0],[0]
"Details of the preprocessing can be found in Titov and Klementiev (2012b).
",4.1 Data and evaluation metrics,[0],[0]
"As in most previous work on unsupervised SRL, we evaluate our model using purity, collocation and their harmonic mean F1.",4.1 Data and evaluation metrics,[0],[0]
"Purity (PU) measures the
average number of arguments with the same gold role label in each cluster, collocation (CO) measures to what extent a specific gold role is represented by a single cluster.",4.1 Data and evaluation metrics,[0],[0]
"More formally:
PU = 1 N ∑ i max j |Gj ∩ Ci|
where if Ci is the set of arguments in the i-th induced cluster, Gj is the set of arguments in the jth gold cluster, andN is the total number of arguments.",4.1 Data and evaluation metrics,[0],[0]
"Similarly, for collocation:
CO = 1 N ∑ j max i |Gj ∩ Ci|
We compute the aggregate PU, CO, and F1 scores over all predicates in the same way as Lang and Lapata (2010): we weight the scores for each predicate by the number of times its arguments occur and compute the weighted average.",4.1 Data and evaluation metrics,[0],[0]
"For the semantic role labeling (encoding) component, we relied on 14 feature patterns used for argument labeling in a popular supervised role labeler (Johansson and Nugues, 2008).",4.2 Parameters and features,[0],[0]
"These patterns include non-trivial syntactic features, such as a dependency path between the target predicate and the considered argument.",4.2 Parameters and features,[0],[0]
"The resulting feature space is quite large (49,474 feature instantiations for our English dataset) and arguably sufficient to accurately capture syntax-semantics interface for most languages.",4.2 Parameters and features,[0],[0]
"We refer the reader to the original publication for details (Johansson and Nugues, 2008:",4.2 Parameters and features,[0],[0]
Table 2).,4.2 Parameters and features,[0],[0]
"Importantly, the dimensionality of the feature space is very different from the one used typically in unsupervised SRL.",4.2 Parameters and features,[0],[0]
"In principle, any features could be used here but we chose these 14 feature patterns, as they all are fairly simple and generic.",4.2 Parameters and features,[0],[0]
They can also be easily extracted from any treebank.,4.2 Parameters and features,[0],[0]
We used the same feature patterns both for English and German.,4.2 Parameters and features,[0],[0]
"However, there is little doubt that some language-specific feature engineering and the use of language-specific priors or constraints (e.g., posterior regularization (Ganchev et al., 2010)) would benefit the performance.",4.2 Parameters and features,[0],[0]
"Faithful to our goal of constructing the simplest possible feature-rich model,
we use logistic classifiers independently predicting role distribution for every argument.
",4.2 Parameters and features,[0],[0]
"For the reconstruction component, both for English and German, we set the embedding dimensionality d, the projection dimensionality k and the number of negative samples n to 30, 15 and 20, respectively.",4.2 Parameters and features,[0],[0]
"The model was not sensitive to the parameter |R|, defining the number of roles as long it was large enough (see Section 4.3 for more discussion).",4.2 Parameters and features,[0],[0]
"For training, we used uniform random initialization and AdaGrad (Duchi et al., 2011).",4.2 Parameters and features,[0],[0]
"Any model selections (e.g., choosing the number of epochs) was done on the basis of the respective held-out set.",4.2 Parameters and features,[0],[0]
"Table 1 summarizes the results of our method, as well as those of alternative approaches and baselines.
",4.3.1 English,[0],[0]
"Following (Lang and Lapata, 2010), we use a baseline (SyntF) which simply clusters predicate arguments according to the dependency relation to their head.",4.3.1 English,[0],[0]
A separate cluster is allocated for each of 20 most frequent relations in the dataset and an additional cluster is used for all other relations.,4.3.1 English,[0],[0]
"As observed in the previous work (Lang and Lapata, 2011a), this is a hard baseline to beat.
",4.3.1 English,[0],[0]
"We also compare with previous approaches: the latent logistic classification model (Lang and Lapata, 2010) (labeled LLogistic), the agglomerative clustering method (Lang and Lapata, 2011a) (Agglom), the graph partitioning approach (Lang and Lapata, 2011b) (GraphPart), the global role ordering model (Garg and Henderson, 2012) (RoleOrdering).",4.3.1 English,[0],[0]
"We also report results of an improved version of Agglom, recently reported by Lang and Lapata (2014) (Agglom+).",4.3.1 English,[0],[0]
"The strongest previous model is Bayes: Bayes is the most accurate (‘coupled’) version of the Bayesian model of Titov and Klementiev (2012a), estimated from the CoNLL dataset without relying on any external data.",4.3.1 English,[0],[0]
"Titov and Klementiev (2012a) also showed that using Brown clusters induced from a large external corpus resulted in an 0.5% improvement in F1 but that version is not entirely comparable to other systems induced solely from the CoNLL text.
",4.3.1 English,[0],[0]
"Our model outperforms or performs on par with
best previous models in terms of F1.",4.3.1 English,[0],[0]
"Interestingly, the purity and collocation balance is very different for our model and for the rest of the systems.",4.3.1 English,[0],[0]
"In fact, our model induces at most 4-6 roles (even if |R| is much larger).",4.3.1 English,[0],[0]
"On the contrary, Bayes predicts more than 30 roles for the majority of frequent predicates (e.g., 43 roles for the predicate include or 35 for say).",4.3.1 English,[0],[0]
"Though this tendency reduces the purity scores for our model, this also means that our roles are more human interpretable.",4.3.1 English,[0],[0]
"For example, agents and patients are clearly identifiable in the model predictions.",4.3.1 English,[0],[0]
"Our model has similar purity to the syntactic baseline but outperforms it vastly according to the collocation metric, suggesting that we go substantially beyond recovering syntactic relations.
",4.3.1 English,[0],[0]
"In additional experiments, we observed that our model, in some regimes, starts to induce roles specific to individual verb senses or specific to groups of semantically similar predicates.",4.3.1 English,[0],[0]
This suggests that adding a latent variable capturing predicate senses and conditioning the reconstruction component on this variable may not only result in a more informative semantic representation (i.e. include verb senses) but also improve the role induction performance.,4.3.1 English,[0],[0]
We leave this exploration for future work.,4.3.1 English,[0],[0]
"For German, we replicate the experimental set-up previously used by Titov and Klementiev (2012b).",4.3.2 German,[0],[0]
"As for English, we report results of the syntactic baseline (SyntF).",4.3.2 German,[0],[0]
The results for all approaches are presented in Table 2.,4.3.2 German,[0],[0]
We compare against Bayes (De) – the Bayes model with argument signatures specialized for German (as reported in Titov and Klementiev (2012b)).,4.3.2 German,[0],[0]
"We also consider the original
version of the Bayes model (denoted as Bayes (En)).",4.3.2 German,[0],[0]
"Recently, Lang and Lapata (2014) evaluated their Agglom+ on a version of the same German SALSA dataset.",4.3.2 German,[0],[0]
"Their best result is F1 of 79.2%, however, this score and our results are not directly comparable.",4.3.2 German,[0],[0]
"Instead of using the CoNLL dataset, they processed the corpus themselves.",4.3.2 German,[0],[0]
"They also relied on syntactic features from a constituent parser whereas we used dependency representations.
",4.3.2 German,[0],[0]
The overall picture for German closely resembles the one for English.,4.3.2 German,[0],[0]
Our method achieves results comparable to the best method evaluated in this setting.,4.3.2 German,[0],[0]
"Importantly, parameters and features of our model for German and English are identical.",4.3.2 German,[0],[0]
"On the contrary, one can see that specialization of argument signatures was crucial for the Bayesian model.",4.3.2 German,[0],[0]
"Also, similarly to English, our method induces less fine-grain sets of semantic roles but achieves much higher collocation scores.",4.3.2 German,[0],[0]
"In recent years, unsupervised approaches to semantic role induction have attracted considerable attention.",5 Additional Related Work,[0],[0]
"However, there exist other ways to address lack of coverage provided by existing semanticallyannotated resources.
",5 Additional Related Work,[0],[0]
"One natural direction is semi-supervised role labeling, where both annotated and unannotated data is used to estimate a model.",5 Additional Related Work,[0],[0]
"Previous semisupervised approaches to SRL can be mostly regarded as extensions to supervised learning by either incorporating word features induced from unnannoted texts (Collobert and Weston, 2008; Deschacht and Moens, 2009) or creating some form of ‘surrogate’ supervision (He and Gildea, 2006; Fürstenau and Lapata, 2009).",5 Additional Related Work,[0],[0]
"Benefits from using unlabeled data were moderate, and more significant for the harder SRL version, frame-semantic parsing (Das and Smith, 2011).
",5 Additional Related Work,[0],[0]
"Another important direction includes crosslingual approaches (Pado and Lapata, 2009; van der Plas et al., 2011; Kozhevnikov and Titov, 2013) which leverage resources from resource-rich languages, as well as parallel data, to produce annotation or models for resource-poor languages.",5 Additional Related Work,[0],[0]
"However, both translation shifts and noise in word alignments harm the performance of cross-lingual methods.",5 Additional Related Work,[0],[0]
"Nevertheless, even joint unsupervised induction across languages appears to be beneficial (Titov and Klementiev, 2012b).
",5 Additional Related Work,[0],[0]
"Unsupervised learning has also been one of the central paradigms for the closely-related area of relation extraction (RE), where several techniques have been proposed to cluster semantically similar verbalizations of relations (Lin and Pantel, 2001; Banko et al., 2007; Yao et al., 2011).",5 Additional Related Work,[0],[0]
"Similarly to SRL, unsupervised methods for RE mostly rely on generative modeling and agglomerative clustering.
",5 Additional Related Work,[0],[0]
"From the learning perspective, methods which use the reconstruction-error objective to estimate linear models (Ammar et al., 2014; Daumé III, 2009) are certainly related.",5 Additional Related Work,[0],[0]
"However, they do not consider learning factorization models, and they also do not deal with semantics.",5 Additional Related Work,[0],[0]
"Tensor factorization methods used in the context of modeling knoweldge bases (e.g., (Bordes et al., 2011)) are also close in spirit.",5 Additional Related Work,[0],[0]
"However, they do not deal with inducing semantics but rather factorize existing relations (i.e. rely on semantics).",5 Additional Related Work,[0],[0]
This work introduces a method for inducing featurerich semantic role labelers from unannoated text.,6 Conclusions and Discussion,[0],[0]
"In our approach, we view a semantic role representation as an encoding of a latent relation between a predicate and a tuple of its arguments.",6 Conclusions and Discussion,[0],[0]
We capture this relation with a probabilistic tensor factorization model.,6 Conclusions and Discussion,[0],[0]
The factorization model (relying on semantic roles) and a feature-rich model (predicting the roles) are jointly estimated by optimizing an objective which favours accurate reconstruction of arguments given the latent semantic representation (and other arguments).,6 Conclusions and Discussion,[0],[0]
"Our estimation method yields a semantic role labeler which achieves state-of-the-art results both on English and German.
",6 Conclusions and Discussion,[0],[0]
"Unlike previous work on role induction, in our
approach, virtually any computationally tractable structured model can be used as a role labeler, including almost any semantic role labeler introduced in the context of supervised SRL (see, e.g., CoNLL shared tasks (Carreras and Màrquez, 2005; Surdeanu et al., 2008; Hajič et al., 2009)).",6 Conclusions and Discussion,[0],[0]
This opens interesting possibilities to extend our approach to the semi-supervised setting.,6 Conclusions and Discussion,[0],[0]
Previous unsupervised SRL models make too strong assumption and use too limited features to effectively exploit labeled data.,6 Conclusions and Discussion,[0],[0]
"For our model, the reconstruction objective can be easily combined with the likelihood objective, yielding a potentially powerful semi-supervised method.",6 Conclusions and Discussion,[0],[0]
We leave this direction for future work.,6 Conclusions and Discussion,[0],[0]
This work is partially supported by a Google focused award on natural language understanding.,Acknowledgements,[0],[0]
"The authors thank Dipanjan Das, Ashutosh Modi, Alexis Palmer and the anonymous reviewers for their suggestions.",Acknowledgements,[0],[0]
We introduce a new approach to unsupervised estimation of feature-rich semantic role labeling models.,abstractText,[0],[0]
Our model consists of two components: (1) an encoding component: a semantic role labeling model which predicts roles given a rich set of syntactic and lexical features; (2) a reconstruction component: a tensor factorization model which relies on roles to predict argument fillers.,abstractText,[0],[0]
"When the components are estimated jointly to minimize errors in argument reconstruction, the induced roles largely correspond to roles defined in annotated resources.",abstractText,[0],[0]
"Our method performs on par with most accurate role induction methods on English and German, even though, unlike these previous approaches, we do not incorporate any prior linguistic knowledge about the languages.",abstractText,[0],[0]
Unsupervised Induction of Semantic Roles within a Reconstruction-Error Minimization Framework,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 23–33 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
23",text,[0],[0]
"Word embeddings are vector space representations of word meaning (Mikolov et al., 2013b; Pennington et al., 2014).",1 Introduction,[0],[0]
"A remarkable property of these models is that they capture various lexical relationships, beyond mere similarity.",1 Introduction,[0],[0]
"For example, (Mikolov et al., 2013b) found that analogy questions of the form “a is to b what c is to ?” can often be answered by finding the word d that maximizes cos(wb−wa+wc, wd), where we write wx for the vector representation of a word x.
Intuitively, the word vector wa represents a in terms of its most salient features.",1 Introduction,[0],[0]
"For example, wparis implicitly encodes that Paris is located in France and that it is a capital city, which is intuitively why the ‘capital of’ relation can be modeled in terms of a vector difference.",1 Introduction,[0],[0]
"Other relationships, however, such as the fact that Macron succeeded Hollande as president of France, are un-
likely to be captured by word embeddings.",1 Introduction,[0],[0]
"Relation extraction methods can discover such information by analyzing sentences that contain both of the words or entities involved (Mintz et al., 2009; Riedel et al., 2010; dos Santos et al., 2015), but they typically need a large number of training examples to be effective.
",1 Introduction,[0],[0]
"A third alternative, which we consider in this paper, is to characterize the relatedness between two words s and t by learning a relation vector rst in an unsupervised way from corpus statistics.",1 Introduction,[0],[0]
"Among others, such vectors can be used to find word pairs that are similar to a given word pair (i.e. finding analogies), or to find the most prototypical examples among a given set of relation instances.",1 Introduction,[0],[0]
"They can also be used as an alternative to the aforementioned relation extraction methods, by subsequently training a classifier that uses the relation vectors as input, which might be particularly effective in cases where only limited amounts of training data are available (with the case of analogy finding from a single instance being an extreme example).
",1 Introduction,[0],[0]
"The most common unsupervised approach for learning relation vectors consists of averaging the embeddings of the words that occur in between s and t, in sentences that contain both (Weston et al., 2013; Fan et al., 2015; Hashimoto et al., 2015).",1 Introduction,[0],[0]
"While this strategy is often surprisingly effective (Hill et al., 2016), it is sub-optimal for two reasons.",1 Introduction,[0],[0]
"First, many of the words co-occurring with s and t will be semantically related to s or to t, but will not actually be descriptive for the relationship between s and t; e.g. the vector describing the relation between Paris and France should not be affected by words such as eiffel (which only relates to Paris).",1 Introduction,[0],[0]
"Second, it gives too much weight to stopwords, which cannot be addressed in a straightforward way as some stop-words are actually crucial for modeling relationships (e.g. prepositions such
as ‘in’ or ‘of’ or Hearst patterns (Indurkhya and Damerau, 2010)).
",1 Introduction,[0],[0]
"In this paper, we propose a method for learning relation vectors directly from co-occurrence statistics.",1 Introduction,[0],[0]
"We first introduce a variant of GloVe, in which word vectors can be directly interpreted as smoothed PMI-weighted bag-of-words representations.",1 Introduction,[0],[0]
"We then represent relationships between words as weighted bag-of-words representations, using generalizations of PMI to three arguments, and learn vectors that correspond to smoothed versions of these representations.
",1 Introduction,[0],[0]
"As far as the possible applications of our methodology is concerned, we imagine that relation vectors can be used in various ways to enrich the input to neural network models.",1 Introduction,[0],[0]
"As a simple example, in a question answering system, we could “annotate” mentions of entities with relation vectors encoding their relationship to the different words from the question.",1 Introduction,[0],[0]
"As another example, we could consider a recommendation system which takes advantage of vectors expressing the relationship between items that have been bought (or viewed) by a customer and other items from the catalogue.",1 Introduction,[0],[0]
"Finally, relation vectors should also be useful for knowledge completion, especially in cases where few training examples per relation type are given (meaning that neural network models could not be used) and where relations cannot be predicted from the already available knowledge (meaning that knowledge graph embedding methods could not be used, or are at least not sufficient).",1 Introduction,[0],[0]
The problem of characterizing the relationship between two words has been studied in various settings.,2 Related Work,[0],[0]
"From a learning point of view, the most straightforward setting is where we are given labeled training sentences, with each label explicitly indicating what relationship is expressed in the sentence.",2 Related Work,[0],[0]
"This fully supervised setting has been the focus of several evaluation campaigns, including as part of ACE (Doddington et al., 2004) and at SemEval 2010 (Hendrickx et al., 2010).",2 Related Work,[0],[0]
"A key problem with this setting, however, is that labeled training data is hard to obtain.",2 Related Work,[0],[0]
"A popular alternative is to use known instances of the relations of interest as a form of distant supervision (Mintz et al., 2009; Riedel et al., 2010).",2 Related Work,[0],[0]
"Some authors have also considered unsupervised relation extraction methods (Shinyama and Sekine, 2006;
",2 Related Work,[0],[0]
"Banko et al., 2007), in which case the aim is essentially to find clusters of patterns that express similar relationships, although these relationships may not correspond to the ones that are needed for the considered application.",2 Related Work,[0],[0]
"Finally, several systems have also used bootstrapping strategies (Brin, 1998; Agichtein and Gravano, 2000; Carlson et al., 2010), where a small set of instances are used to find extraction patterns, which are used to find more instances, which can in turn be used to find better extraction patterns, etc.
",2 Related Work,[0],[0]
"Traditionally, relation extraction systems have relied on a variety of linguistic features, such as lexical patterns, part-of-speech tags and dependency parsers.",2 Related Work,[0],[0]
"More recently, several neural network architectures have been proposed for the relation extraction problem.",2 Related Work,[0],[0]
"These architectures rely on word embeddings to represent the words in the input sentence, and manipulate these word vectors to construct a relation vector.",2 Related Work,[0],[0]
"Some approaches simply represent the sentence (or the phrase connecting the entities whose relationship we want to determine) as a sequence of words, and use e.g. convolutional networks to aggregate the vectors of the words in this sequence (Zeng et al., 2014; dos Santos et al., 2015).",2 Related Work,[0],[0]
"Another possibility, explored in (Socher et al., 2012), is to use parse trees to capture the structure of the sentence, and to use recursive neural networks (RNNs) to aggregate the word vectors in a way which respects this structure.",2 Related Work,[0],[0]
"A similar approach is taken in (Xu et al., 2015), where LSTMs are applied to the shortest path between the two target words in a dependency parser.",2 Related Work,[0],[0]
"A straightforward baseline method is to simply take the average of the word vectors (Mitchell and Lapata, 2010).",2 Related Work,[0],[0]
"While conceptually much simpler, variants of this approach have obtained state-of-the-art performance for relation classification (Hashimoto et al., 2015) and a variety of tasks that require sentences to be represented as a vector (Hill et al., 2016).
",2 Related Work,[0],[0]
"Given the effectiveness of word vector averaging, in (Kenter et al., 2016)",2 Related Work,[0],[0]
a model was proposed that explicitly tries to learn word vectors that generalize well when being averaged.,2 Related Work,[0],[0]
"Similarly, the model proposed in (Hashimoto et al., 2015) aims to produce word vectors that perform well for the specific task of relation classification.",2 Related Work,[0],[0]
"The ParagraphVector method from (Le and Mikolov, 2014) is related to the aformentioned approaches, but it explicitly learns a vector representation for each
paragraph along with the word embeddings.",2 Related Work,[0],[0]
"However, this method is computationally expensive, and often fails to outperform simpler approaches (Hill et al., 2016).
",2 Related Work,[0],[0]
"To the best of our knowledge, existing methods for learning relation vectors are all based on manipulating pre-trained word vectors.",2 Related Work,[0],[0]
"In contrast, we will directly learn relation vectors from corpus statistics, which will have the important advantage that we can focus on words that describe the interaction between the two words s and t, i.e. words that commonly occur in sentences that contain both s and t, but are comparatively rare in sentences that only contain s or only contain t.
Finally, note that our work is fundamentally different from Knowledge Graph Embedding (KGE) (Wang et al., 2014b), (Wang et al., 2014a), (Bordes et al., 2011) in at least two ways: (i) KGE models start from a structured knowledge graph whereas we only take a text corpus as input, and (ii) KGE models represent relations as geometric objects in the “entity embedding” itself (e.g. as translations, linear maps, combinations of projections and translations, etc), whereas we represent words and relations in different vector spaces.",2 Related Work,[0],[0]
"Our approach to relation embedding is based on a variant of the GloVe word embedding model (Pennington et al., 2014).",3 Word Vectors as PMI Encodings,[0],[0]
"In this section, we first briefly recall the GloVe model itself, after which we discuss our proposed variant.",3 Word Vectors as PMI Encodings,[0],[0]
"A key advantage of this variant is that it allows us to directly interpret word vectors in terms of the Pointwise Mutual Information (PMI), which will be central to the way in which we learn relation vectors.",3 Word Vectors as PMI Encodings,[0],[0]
"The GloVe model (Pennington et al., 2014) learns a vector wi for each word i in the vocabulary, based on a matrix of co-occurrence counts, encoding how often two words appear within a given window.",3.1 Background,[0],[0]
Let us write xij for the number of times word j appears in the context of word i in some text corpus.,3.1 Background,[0],[0]
"More precisely, assume that there are m sentences in the corpus, and letP li ⊆ {1, ..., nl} be the set of positions from the lth sentence where the word i can be found (with nl the length of the
sentence).",3.1 Background,[0],[0]
"Then xij is defined as follows:
m∑ l=1 ∑ p∈Pli ∑ q∈Plj weight(p, q)
where weight(p, q) = 1|p−q| if 0 < |p − q| ≤ W , and weight(p, q) = 0",3.1 Background,[0],[0]
"otherwise, where the window size W is usually set to 5 or 10.
",3.1 Background,[0],[0]
"The GloVe model learns for each word i two vectors wi and w̃i by optimizing the following objective:∑
i ∑ j:xij 6=0 f(xij)(wi·w̃j +",3.1 Background,[0],[0]
bi + b̃j,3.1 Background,[0],[0]
"− log xij)2
where f is a weighting function, aimed at reducing the impact of rare terms, and bi and b̃j are bias terms.",3.1 Background,[0],[0]
"The GloVe model is closely related to the notion of pointwise mutual information (PMI), which is defined for two words i and j as PMI(i, j) = log ( P (i,j) P (i)P (j) ) , where P (i, j) is the probability of seeing the words i and j if we randomly pick a word position from the corpus and a second word position within distance W from the first position.",3.1 Background,[0],[0]
"The PMI between i and j is usually estimated as follows:
PMIX(i, j) = log ( xijx∗∗ xi∗x∗j )",3.1 Background,[0],[0]
"where xi∗ = ∑ j xij , x∗j = ∑ i xij and x∗∗ =∑
i ∑ j xij .",3.1 Background,[0],[0]
"In particular, it is straightforward to see that after the reparameterization given by bi 7→ bi + log xi∗",3.1 Background,[0],[0]
"− log x∗∗ and bj 7→ bj + log x∗j , the GloVe model is equivalent to∑",3.1 Background,[0],[0]
"i ∑ j
xij 6=0
f(xij)(wi·w̃j + bi + b̃j",3.1 Background,[0],[0]
"− PMIX(i, j))2
(1)",3.1 Background,[0],[0]
"In this paper, we will use the following variant of the formulation in (1):∑
i ∑ j∈Ji 1 σ2j (wi·w̃j + b̃j",3.2 A Variant of GloVe,[0],[0]
"− PMIS(i, j))2 (2)
Despite its similarity, this formulation differs from the GloVe model in a number of important ways.",3.2 A Variant of GloVe,[0],[0]
"First, we use smoothed frequency counts instead of the observed frequency counts xij .",3.2 A Variant of GloVe,[0],[0]
"In particular, the PMI between words i and j is given as:
PMIS(i, j) = log ( P (i, j)
P (i)P (j)
)
where the probabilities are estimated as follows:
P (i) = xi∗ + α
x∗∗ + nα P (j) =
x∗j + α
x∗∗ + nα
P (i, j) =",3.2 A Variant of GloVe,[0],[0]
"xij + α
x∗∗ + n2α
where α ≥ 0 is a parameter controlling the amount of smoothing and n is the size of the vocabulary.",3.2 A Variant of GloVe,[0],[0]
"This ensures that the estimation of PMI(i, j) is well-defined even in cases where xij = 0, meaning that we no longer have to restrict the inner summation to those j for which xij > 0.",3.2 A Variant of GloVe,[0],[0]
"For efficiency reasons, in practice, we only consider a small subset of all context words j for which xij = 0, which is similar in spirit to the use of negative sampling in Skip-gram (Mikolov et al., 2013b).",3.2 A Variant of GloVe,[0],[0]
"In particular, the set Ji contains each j such that xij > 0 as well as M uniformly1 sampled context words j for which xij = 0, where we choose M = 2 · |{j : xij > 0}|.
",3.2 A Variant of GloVe,[0],[0]
"Second, following (Jameel and Schockaert, 2016), the weighting function f(xij) has been replaced by 1
σ2j , where σ2j is the residual variance of
the regression problem for context word j, estimated follows:
σ2j = 1
|J−1j | ∑ i∈J−1j (wi · w̃j + b̃j",3.2 A Variant of GloVe,[0],[0]
"− PMIS(i, j))2
with J−1j",3.2 A Variant of GloVe,[0],[0]
= {i : j ∈ Ji}.,3.2 A Variant of GloVe,[0],[0]
"Since we need the word vectors to estimate this residual variance, we reestimate σ2j after every five iterations of the SGD optimization.",3.2 A Variant of GloVe,[0],[0]
"For the first 5 iterations, where no estimation for σ2j is available, we use the GloVe weighting function.
",3.2 A Variant of GloVe,[0],[0]
The use of smoothed frequency counts and residual variance based weighting make the word embedding model more robust for rare words.,3.2 A Variant of GloVe,[0],[0]
"For instance, if w only co-occurs with a handful of other terms, it is important to prioritize the most informative context words, which is exactly what the use of the residual variance achieves, i.e. σ2j is small for informative terms and large for stop words; see (Jameel and Schockaert, 2016).",3.2 A Variant of GloVe,[0],[0]
"This will be important for modeling relations, as the relation vectors will often have to be estimated from very sparse co-occurrence counts.
",3.2 A Variant of GloVe,[0],[0]
"1While the negative sampling method used in Skip-gram favors more frequent words, initial experiments suggested that deviating from a uniform distribution almost had no impact in our setting.
",3.2 A Variant of GloVe,[0],[0]
"Finally, the bias term bi has been omitted from the model in (2).",3.2 A Variant of GloVe,[0],[0]
"We have empirically found that omitting this bias term does not affect the performance of the model, while it allows us to have a more direct connection between the vector wi and the corresponding PMI scores.",3.2 A Variant of GloVe,[0],[0]
"Let us define PMIW as follows:
PMIW (i, j) = wi·w̃j",3.3 Word Vectors and PMI,[0],[0]
"+ b̃j
Clearly, when the word vectors are trained according to (2), it holds that PMIW (i, j)",3.3 Word Vectors and PMI,[0],[0]
"≈ PMIS(i, j).",3.3 Word Vectors and PMI,[0],[0]
"In other words, we can think of the word vector wi as a low-dimensional encoding of the vector (PMIS(i, 1), ...,PMIS(i, n)), with n the number of words in the vocabulary.",3.3 Word Vectors and PMI,[0],[0]
This view allows us to assign a natural interpretation to some word vector operations.,3.3 Word Vectors and PMI,[0],[0]
"In particular, the vector difference wi−wk is commonly used as a model for the relationship between words i and k.",3.3 Word Vectors and PMI,[0],[0]
"For a given context word j, we have
(wi − wk) · w̃j",3.3 Word Vectors and PMI,[0],[0]
"= PMIW (i, j)− PMIW (k, j)",3.3 Word Vectors and PMI,[0],[0]
"The latter is an estimation of log (
P (i,j) P (i)P (j)
)",3.3 Word Vectors and PMI,[0],[0]
"−
log (
P (k,j) P (k)P (j)
) = log ( P (j|i) P (j|k) ) .",3.3 Word Vectors and PMI,[0],[0]
"In other words,
the vector translation wi − wk encodes for each context word j the (log) ratio of the probability of seeing j in the context of i and in the context of k, which is in line with the original motivation underlying the GloVe model (Pennington et al., 2014).",3.3 Word Vectors and PMI,[0],[0]
"In the following section, we will propose a number of alternative vector representations for the relationship between two words, based on generalizations of PMI to three arguments.",3.3 Word Vectors and PMI,[0],[0]
We now turn to the problem of learning a vector rik that encodes how the source word i and target word k are related.,4 Learning Global Relation Vectors,[0],[0]
"The main underlying idea is that rik will capture which context words j are most closely associated with the word pair (i, k).",4 Learning Global Relation Vectors,[0],[0]
"Whereas the GloVe model is based on statistics about (main word, context word) pairs, here we will need statistics on (source word, context word, target word) triples.",4 Learning Global Relation Vectors,[0],[0]
"First, we discuss how cooccurrence statistics among three words can be expressed using generalizations of PMI to three arguments.",4 Learning Global Relation Vectors,[0],[0]
Then we explain how this can be used to learn relation vectors in natural way.,4 Learning Global Relation Vectors,[0],[0]
"Let P li ⊆ {1, ..., nl} again be the set of positions from the lth sentence corresponding to word i.",4.1 Co-occurrence Statistics for Triples,[0],[0]
"We define:
yijk = m∑ l=1 ∑ p∈Pli ∑ q∈Plj ∑ r∈Plk weight(p, q, r)
where weight(p, q, r) = max( 1q−p , 1 r−q )",4.1 Co-occurrence Statistics for Triples,[0],[0]
if p < q,4.1 Co-occurrence Statistics for Triples,[0],[0]
< r,4.1 Co-occurrence Statistics for Triples,[0],[0]
and r−p,4.1 Co-occurrence Statistics for Triples,[0],[0]
"≤W , and weight(p, q, r) = 0",4.1 Co-occurrence Statistics for Triples,[0],[0]
otherwise.,4.1 Co-occurrence Statistics for Triples,[0],[0]
"In other words, yijk reflects the (weighted) number of times word j appears between words i and k in a sentence in which i and k occur sufficiently close to each other, in that order.",4.1 Co-occurrence Statistics for Triples,[0],[0]
"Note that by taking word order into account in this way, we will be able to model asymmetric relationships.
",4.1 Co-occurrence Statistics for Triples,[0],[0]
"To model how strongly a context word j is associated with the word pair (i, k), we will consider the following two well-known generalizations of PMI to three arguments (Van de Cruys, 2011):
SI1(i, j, k) = log ( P (i, j)P (i, k)P (j, k)
P (i)P (j)P (k)P (i, j, k) )",4.1 Co-occurrence Statistics for Triples,[0],[0]
"SI2(i, j, k) = log ( P (i, j, k)
P (i)P (j)P (k) ) where P (i, j, k) is the probability of seeing the word triple (i, j, k) when randomly choosing a sentence and three (ordered) word positions in that sentence within a window size of W .",4.1 Co-occurrence Statistics for Triples,[0],[0]
"In addition we will also consider two ways in which PMI can be used more directly:
SI3(i, j, k) = log ( P (i, j, k)
",4.1 Co-occurrence Statistics for Triples,[0],[0]
"P (i, k)P (j) )",4.1 Co-occurrence Statistics for Triples,[0],[0]
"SI4(i, j, k) = log ( P (i, k|j)
P (i|j)P (k|j) )",4.1 Co-occurrence Statistics for Triples,[0],[0]
"Note that SI3(i, j, k) corresponds to the PMI between (i, k) and j, whereas SI4(i, j, k) is the PMI between i and k conditioned on the fact that j occurs.",4.1 Co-occurrence Statistics for Triples,[0],[0]
The measures SI3 and SI4 are closely related to SI1 and SI2 respectively2.,4.1 Co-occurrence Statistics for Triples,[0],[0]
"In particular, the following identities are easy to show:
PMI(i, j) + PMI(j, k)− SI1(i, j, k) = SI3(i, j, k) SI2(i, j, k)− PMI(i, j)− PMI(j, k) = SI4(i, j, k)
2Note that probabilities of the form P (i, j) or P (i) here refer to marginal probabilities over ordered triples.",4.1 Co-occurrence Statistics for Triples,[0],[0]
"In contrast, the PMI scores from the word embedding model are based on probabilities over unordered word pairs, as is common for word embeddings.
",4.1 Co-occurrence Statistics for Triples,[0],[0]
"Using smoothed versions of the counts yijk, we can use the following probability estimates for SI1(i, j, k)–SI4(i, j, k):
P (i, j, k) = yijk + α
y∗∗∗ + n3α P (i, j) =
yij∗ + α
y∗∗∗ + n2α
P (i, k) =",4.1 Co-occurrence Statistics for Triples,[0],[0]
"yi∗k + α
y∗∗∗ + n2α P (j, k) =
y∗jk + α
y∗∗∗ + n2α
P (i) = yi∗∗ +",4.1 Co-occurrence Statistics for Triples,[0],[0]
"α
y∗∗∗ + nα",4.1 Co-occurrence Statistics for Triples,[0],[0]
"P (j) =
y∗j∗ + α
y∗∗∗ + nα
P (k) = y∗∗k + α
y∗∗∗ + nα where yij∗ = ∑
k yijk, and similar for the other counts.",4.1 Co-occurrence Statistics for Triples,[0],[0]
"For efficiency reasons, the counts of the form yij∗, yi∗k and y∗jk are pre-computed for all word pairs, which can be done efficiently due to the sparsity of co-occurrence counts (i.e. these counts will be 0 for most pairs of words), similarly to how to the counts xij are computed in GloVe.",4.1 Co-occurrence Statistics for Triples,[0],[0]
"From these counts, we can also efficiently pre-compute the counts yi∗∗, y∗j∗, y∗∗k and y∗∗∗. On the other hand, the counts yijk cannot be precomputed, since the total number of triples for which yijk 6= 0 is prohibitively high in a typical corpus.",4.1 Co-occurrence Statistics for Triples,[0],[0]
"However, using an inverted index, we can efficiently retrieve the sentences that contain the words i and k, and since this number of sentences is typically small, we can efficiently obtain the counts yijk corresponding to a given pair (i, k) whenever they are needed.",4.1 Co-occurrence Statistics for Triples,[0],[0]
"Our aim is to learn a vector rik that models the relationship between i and k. Computing such a vector for each pair of words (which co-occur at least once) is not feasible, given the number of triples (i, j, k) that would need to be considered.",4.2 Relation Vectors,[0],[0]
"Instead, we first learn a word embedding, by optimizing (2).",4.2 Relation Vectors,[0],[0]
"Then, fixing the context vectors w̃j and bias terms bj , we learn a vector representation for a given pair (i, k) of interest by solving the following objective:∑
j∈Ji,k
(rik·w̃j + b̃j",4.2 Relation Vectors,[0],[0]
"− SI(i, j, k))2 (3)
where SI refers to one of SI1S , SI 2 S , SI 3 S , SI 4 S .",4.2 Relation Vectors,[0],[0]
"Note that (3) is essentially the counterpart of (1), where we have replaced the role of the PMI measure by SI.",4.2 Relation Vectors,[0],[0]
"In this way, we can exploit the representations of the context words from the word embedding model for learning relation vectors.",4.2 Relation Vectors,[0],[0]
"Note that the
factor 1 σ2j has been omitted.",4.2 Relation Vectors,[0],[0]
"This is because words j that are normally relatively uninformative (e.g. stop words), for which σ2j would be high, can actually be very important for characterizing the relationship between i and k.",4.2 Relation Vectors,[0],[0]
"For instance, the phrase “X such as Y ” clearly suggests a hyponomy relationship between X and Y , but both ‘such’ and ‘as’ would be associated with a high residual variance σ2j .",4.2 Relation Vectors,[0],[0]
"The set Ji,k contains every j for which yijk > 0 as well as a random sample of m words for which yijk = 0, where m = 2 · |{j : yijk > 0|.",4.2 Relation Vectors,[0],[0]
"Note that because w̃j is now fixed, (3) is a linear least squares regression problem, which can be solved exactly and efficiently.
",4.2 Relation Vectors,[0],[0]
The vector rik is based on words that appear between i and k.,4.2 Relation Vectors,[0],[0]
"In the same way, we can learn a vector sik based on the words that appear before i and a vector tik based on the words that appear after k, in sentences where i occurs before k.",4.2 Relation Vectors,[0],[0]
"Furthermore, we also learn vectors rki, ski and tki from the sentences where k occurs before i. As the final representation Rik of the relationship between i and k, we concatenate the vectors rik, rki, sik, ski, tik, tki as well as the word vectors wi and wk.",4.2 Relation Vectors,[0],[0]
"We write Rlik to denote the vector that results from using measure SIl (l ∈ {1, 2, 3, 4}).",4.2 Relation Vectors,[0],[0]
"In our experiments, we have used the Wikipedia dump from November 2nd, 2015, which consists of 1,335,766,618 tokens.",5 Experimental Results,[0],[0]
"We have removed punctuations and HTML/XML tags, and we have lowercased all tokens.",5 Experimental Results,[0],[0]
Words with fewer than 10 occurrences have been removed from the corpus.,5 Experimental Results,[0],[0]
"To detect sentence boundaries, we have used the Apache sentence segmentation tool.",5 Experimental Results,[0],[0]
"In all our experiments, we have set the number of dimensions to 300, which was found to be a good choice in previous work, e.g. (Pennington et al., 2014).",5 Experimental Results,[0],[0]
We use a context window size W of 10 words.,5 Experimental Results,[0],[0]
The number of iterations for SGD was set to 50.,5 Experimental Results,[0],[0]
"For our model, we have tuned the smoothing parameter α based on held-out tuning data, considering values from {0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001}.",5 Experimental Results,[0],[0]
We have noticed that in most of the cases the value of α was automatically selected as 0.00001.,5 Experimental Results,[0],[0]
"To efficiently compute the triples, we have used the Zettair3 retrieval engine.
",5 Experimental Results,[0],[0]
"As our main baselines, we use three popular unsupervised methods for constructing relation vec-
3http://www.seg.rmit.edu.au/zettair/
tors.",5 Experimental Results,[0],[0]
"First, Diff uses the vector difference wk−wi, following the common strategy of modeling relations as vector differences, as e.g. in (Vylomova et al., 2016).",5 Experimental Results,[0],[0]
"Second, Conc uses the concatenation ofwi andwk.",5 Experimental Results,[0],[0]
"This model is more general than Diff but it uses twice as many dimensions, which may make it harder to learn a good classifier from few examples.",5 Experimental Results,[0],[0]
"The use of concatenations is popular e.g. in the context of hypernym detection (Baroni et al., 2012).",5 Experimental Results,[0],[0]
"Finally, Avg averages the vector representations of the words occurring in sentences that Diff, contain i and k.",5 Experimental Results,[0],[0]
"In particular, let ravgik be obtained by averaging the word vectors of the context words appearing between i and k for each sentence containing i and k (in that order), and then averaging the vectors obtained from each of these sentences.",5 Experimental Results,[0],[0]
Let savgik and t avg ik be similarly obtained from the words occurring before i and the words occurring after k respectively.,5 Experimental Results,[0],[0]
"The considered relation vector is then defined as the concatenation of ravgik , r avg ki , s avg ik , s avg ki , t avg ik , t avg ki , wi and wk.",5 Experimental Results,[0],[0]
The Avg will allow us to directly compare how much we can improve relation vectors by deviating from the common strategy of averaging word vectors.,5 Experimental Results,[0],[0]
"In the relation induction task, we are given word pairs (s1, t1), ..., (sk, tk) that are related in some way, and the task is to decide for a number of test examples (s, t) whether they also have this relationship.",5.1 Relation Induction,[0],[0]
"Among others, this task was considered in (Vylomova et al., 2016), and a ranking version of this task was studied in (Drozd et al., 2016).",5.1 Relation Induction,[0],[0]
"As test sets we use the Google Analogy Test Set (Mikolov et al., 2013a), which contains instances of 14 different types of relations, and the DiffVec dataset, which was introduced in (Vylomova et al., 2016).",5.1 Relation Induction,[0],[0]
"This dataset contains instances of 36 dif-
ferent types of relations4.",5.1 Relation Induction,[0],[0]
"Note that both datasets contain a mix of semantic and syntactic relations.
",5.1 Relation Induction,[0],[0]
"In our evaluation, we have used 10-fold crossvalidation (or leave-one-out for relations with fewer than 10 instances).",5.1 Relation Induction,[0],[0]
"In the experiments, we consider for each relation in the test set a separate binary classification task, which was found to be considerably more challenging than a multi-class classification setting in (Vylomova et al., 2016).",5.1 Relation Induction,[0],[0]
"To generate negative examples in the training data (resp. test data), we have used three strategies, following (Vylomova et al., 2016).",5.1 Relation Induction,[0],[0]
"First, for a given positive example (s, t) of the considered relation, we add (t, s) as a negative example.",5.1 Relation Induction,[0],[0]
"Second, for each positive example (s, t), we generate two negative examples (s, t1) and (s, t2) by randomly selecting two tail words t1, t2 from the other training (resp. test) examples of the same relation.",5.1 Relation Induction,[0],[0]
"Finally, for each positive example, we also generate a negative example by randomly selecting two words from the vocabulary.",5.1 Relation Induction,[0],[0]
"For each relation, we then train a linear SVM classifier.",5.1 Relation Induction,[0],[0]
"To set the parameters of the SVM, we initially use 25% of the training data for tuning, and then retrain the SVM with the optimal parameters on the full training data.
",5.1 Relation Induction,[0],[0]
"The results are summarized in Table 1 in terms of accuracy and (macro-averaged) precision, recall and F1 score.",5.1 Relation Induction,[0],[0]
"As can be observed, our model outperforms the baselines on both datasets, with the R2ik variant outperforming the others.
",5.1 Relation Induction,[0],[0]
"To analyze the benefit of our proposed word embedding variant, Table 2 shows the results that were obtained when we use standard word embedding models.",5.1 Relation Induction,[0],[0]
"In particular, we show results for the standard GloVe model, SkipGram and the Continuous Bag of Words (CBOW) model.",5.1 Relation Induction,[0],[0]
"As can be observed, our variant leads to better results than the original GloVe model, even for the baselines.
",5.1 Relation Induction,[0],[0]
"4Note that in contrast to (Vylomova et al., 2016)",5.1 Relation Induction,[0],[0]
"we use all 36 relations from this dataset, including those with very few instances.
",5.1 Relation Induction,[0],[0]
The difference is particularly noticeable for DiffVec.,5.1 Relation Induction,[0],[0]
"The difference is also larger for our relation vectors than for the baselines, which is expected as our method is based on the assumption that context word vectors can be interpreted in terms of PMI scores, which is only true for our variant.
",5.1 Relation Induction,[0],[0]
"Similar as in the GloVe model, the context words in our model are weighted based on their distance to the nearest target word.",5.1 Relation Induction,[0],[0]
"Table 3 shows the results of our model without this weighting, for the relation induction task.",5.1 Relation Induction,[0],[0]
Comparing these results with those in Table 1 shows that the weighting scheme indeed leads to a small improvement (except for the accuracy of R1ik for DiffVec).,5.1 Relation Induction,[0],[0]
"Similarly, in Table 3, we show what happens if the relation vectors sik, ski, tik and tki are omitted.",5.1 Relation Induction,[0],[0]
"In other words, for the results in Table 3, we only use context words that appear between the two target words.",5.1 Relation Induction,[0],[0]
"Again, the results are worse than those in Table 1 (with the accuracy ofR1ik for DiffVec again being an exception), although the differences are very small in this case.",5.1 Relation Induction,[0],[0]
"While including the vectors sik, ski, tik, tki should be helpful, it also significantly increases the dimensionality of the vectors Rlik.",5.1 Relation Induction,[0],[0]
"Given that the number of instances per relation is typically quite small for this
task, this can also make it harder to learn a suitable classifier.",5.1 Relation Induction,[0],[0]
Instances of relations can often have different degrees of prototypicality.,5.2 Measuring Degrees of Prototypicality,[0],[0]
"For example, for the relation “X characteristically makes the sound Y ”, the pair (dog,bark) should be considered more prototypical than the pair (floor,squeak), even though both pairs might be considered to be instances of the relation (Jurgens et al., 2012).",5.2 Measuring Degrees of Prototypicality,[0],[0]
A suitable relation vector should allow us to rank word pairs according to how prototypical they are as instances of that relation.,5.2 Measuring Degrees of Prototypicality,[0],[0]
We evaluate this ability using a dataset that was produced in the aftermath of SemEval 2012 Task 2.,5.2 Measuring Degrees of Prototypicality,[0],[0]
"In particular, we have used the “Phase2AnswerScaled” data from the platinum rankings dataset, which is available from the SemEval 2012 Task 2 website5.",5.2 Measuring Degrees of Prototypicality,[0],[0]
"In this dataset, 79 ranked list of word pairs are provided, each of which corresponds to a particular relation.",5.2 Measuring Degrees of Prototypicality,[0],[0]
"For each relation, we first split the associated ranking into 60% training, 20% tuning, and 20% testing (i.e. we randomly select 60% of the word pairs and use their ranking as training data, and similar for tuning and test data).",5.2 Measuring Degrees of Prototypicality,[0],[0]
We then train a linear SVM regression model on the ranked word pairs.,5.2 Measuring Degrees of Prototypicality,[0],[0]
"Note that this task slightly differs from the task that was considered at SemEval 2012, to allow us to use an SVM based model for consistency with the rest of the paper.
",5.2 Measuring Degrees of Prototypicality,[0],[0]
We report results using Spearman’s ρ in Table 4.,5.2 Measuring Degrees of Prototypicality,[0],[0]
"Our model again outperforms the baselines, with R2ik again being the best variant.",5.2 Measuring Degrees of Prototypicality,[0],[0]
"Interestingly, in this case, the Avg baseline is considerably stronger than Diff and Conc.",5.2 Measuring Degrees of Prototypicality,[0],[0]
"Intuitively, we might indeed expect that this ranking problem requires a more fine-grained representation than the relation induction setting.",5.2 Measuring Degrees of Prototypicality,[0],[0]
"Note that the Diff representations were found to achieve near state-of-theart performance on a closely related task in (Zhila et al., 2013).",5.2 Measuring Degrees of Prototypicality,[0],[0]
"The only model that was found to perform (slightly) better was a hybrid model, combining Diff representations with linguistic patterns
5https://sites.google.com/site/semeval2012task2/download
(inspired by (Rink and Harabagiu, 2012)) and lexical databases, among others.",5.2 Measuring Degrees of Prototypicality,[0],[0]
"Finally, we consider the problem of relation extraction from a text corpus.",5.3 Relation Extraction,[0],[0]
"Specifically, we consider the task proposed in (Riedel et al., 2010), which is to extract (subject,predicate,object) triples from the New York Times (NYT) corpus.",5.3 Relation Extraction,[0],[0]
"Rather than having labelled sentences as training data, the task requires using the existing triples from Freebase as a form of distant supervision, i.e. for some pairs of entities we know some of the relations that hold between them, but not which sentences assert these relationships (if any).",5.3 Relation Extraction,[0],[0]
"To be consistent with published results for this task, we have used a word embedding that was trained from the NYT corpus6, rather than Wikipedia (using the same preprocessing and set-up).",5.3 Relation Extraction,[0],[0]
"We have used the training and test data that was shared publicly for this task7, which consist of sentences from articles published in 2005-2006 and in 2007, respectively.",5.3 Relation Extraction,[0],[0]
"Each of these sentences contains two entities, which are already linked to Freebase.",5.3 Relation Extraction,[0],[0]
"We learn relation vectors from the sentences in the training and test sets, and learn a linear SVM classifier based on the Freebase triples that are available in the training set.",5.3 Relation Extraction,[0],[0]
"Initially, we split the training data into 75% training and 25% tuning to find the optimal parameters of the linear SVM model.",5.3 Relation Extraction,[0],[0]
"We tuned the parameters for each test fold sepa-
6https://catalog.ldc.upenn.edu/LDC2008T19 7http://iesl.cs.umass.edu/riedel/ecml/
rately.",5.3 Relation Extraction,[0],[0]
"For each test fold, we used 25% of the 9 training folds as tuning data.",5.3 Relation Extraction,[0],[0]
"After the optimal parameters have been determined, we retrain the model on the full training data, and apply it on the test fold.",5.3 Relation Extraction,[0],[0]
We used this approach (rather than e.g. fixing a train/tune/test split) because the total number of examples for some of the relations is very small.,5.3 Relation Extraction,[0],[0]
"After tuning, we re-train the SVM models on the full training data.",5.3 Relation Extraction,[0],[0]
"As the number of training examples is larger for this task, we also consider SVMs with a quadratic kernel.
",5.3 Relation Extraction,[0],[0]
"Following earlier work on this task, we report our results on the test set as a precisionrecall graph in Figure 1.",5.3 Relation Extraction,[0],[0]
"This shows that the best performance is again achieved by R2ik, especially for larger recall values.",5.3 Relation Extraction,[0],[0]
"Furthermore, using a quadratic kernel (only shown for R2ik) outperforms the linear SVM models.",5.3 Relation Extraction,[0],[0]
"Note that the differences between the baselines are more pronounced in this task, with Avg being clearly better than Diff, which is in turn better than Conc.",5.3 Relation Extraction,[0],[0]
"For this relation extraction task, a large number of methods have already been proposed in the literature, with variants of convolutional neural network models with attention mechanisms achieving state-of-the-art performance8.",5.3 Relation Extraction,[0],[0]
A comparison with these models9 is shown in Figure 2.,5.3 Relation Extraction,[0],[0]
"The performance of R2ik is comparable with the state-of-
8Note that such models would not be suitable for the evaluation tasks in Sections 5.1 and 5.2, due to the very limited number of training examples.
",5.3 Relation Extraction,[0],[0]
"9Results for the neural network models have been obtained from https://github.com/thunlp/ TensorFlow-NRE/tree/master/data.
",5.3 Relation Extraction,[0],[0]
"the-art PCNN+ATT model (Lin et al., 2016), outperforming it for larger recall values.",5.3 Relation Extraction,[0],[0]
"This is remarkable, as our model is conceptually much simpler, and has not been specifically tuned for this task.",5.3 Relation Extraction,[0],[0]
"For instance, it could easily be improved by incorporating the attention mechanism from the PCNN+ATT model to focus the relation vectors on the considered task.",5.3 Relation Extraction,[0],[0]
"Similarly, we could consider a supervised variant of (3), in which a learned relation-specific weight is added to each term.",5.3 Relation Extraction,[0],[0]
We have proposed an unsupervised method which uses co-occurrences statistics to represent the relationship between a given pair of words as a vector.,6 Conclusions,[0],[0]
"In contrast to neural network models for relation extraction, our model learns relation vectors in an unsupervised way, which means that it can be used for measuring relational similarities and related tasks.",6 Conclusions,[0],[0]
"Moreover, even in (distantly) supervised tasks (where we need to learn a classifier on top of the unsupervised relation vectors), our model has proven competitive with state-of-the-art neural network models.",6 Conclusions,[0],[0]
"Compared to approaches that rely on averaging word vectors, our method is able to learn more faithful representations by focusing on the words that are most strongly related to the considered relationship.",6 Conclusions,[0],[0]
This work was supported by ERC Starting Grant 637277.,Acknowledgments,[0],[0]
"Experiments in this work were performed using the computational facilities of the Advanced Research Computing at Cardiff (ARCCA) Division, Cardiff University and the ICARUS computational facility from Information Services, at the University of Kent.",Acknowledgments,[0],[0]
Word embedding models such as GloVe rely on co-occurrence statistics to learn vector representations of word meaning.,abstractText,[0],[0]
"While we may similarly expect that cooccurrence statistics can be used to capture rich information about the relationships between different words, existing approaches for modeling such relationships are based on manipulating pre-trained word vectors.",abstractText,[0],[0]
"In this paper, we introduce a novel method which directly learns relation vectors from co-occurrence statistics.",abstractText,[0],[0]
"To this end, we first introduce a variant of GloVe, in which there is an explicit connection between word vectors and PMI weighted co-occurrence vectors.",abstractText,[0],[0]
We then show how relation vectors can be naturally embedded into the resulting vector space.,abstractText,[0],[0]
Unsupervised Learning of Distributional Relation Vectors,title,[0],[0]
"This paper focuses on unsupervised modeling of morphological families, collectively comprising a forest over the language vocabulary. This formulation enables us to capture edgewise properties reflecting single-step morphological derivations, along with global distributional properties of the entire forest. These global properties constrain the size of the affix set and encourage formation of tight morphological families. The resulting objective is solved using Integer Linear Programming (ILP) paired with contrastive estimation. We train the model by alternating between optimizing the local log-linear model and the global ILP objective. We evaluate our system on three tasks: root detection, clustering of morphological families, and segmentation. Our experiments demonstrate that our model yields consistent gains in all three tasks compared with the best published results.1",text,[0],[0]
The morphological study of a language inherently draws upon the existence of families of related words.,1 Introduction,[0],[0]
"All words within a family can be derived from a common root via a series of transformations, whether inflectional or derivational.",1 Introduction,[0],[0]
"Figure 1 depicts one such family, originating from the word faith.",1 Introduction,[0],[0]
"This representation can benefit a range of applications, including segmentation, root detection and clustering of morphological families.
",1 Introduction,[0],[0]
"1Code is available at https://github.com/ j-luo93/MorphForest.
",1 Introduction,[0],[0]
"Using graph terminology, a full morphological assignment of the words in a language can be represented as a forest.2 Valid forests of morphological families exhibit a number of well-known regularities.",1 Introduction,[0],[0]
"At the global level, the number of roots is limited, and only constitute a small fraction of the vocabulary.",1 Introduction,[0],[0]
"A similar constraint applies to the number of possible affixes, shared across families.",1 Introduction,[0],[0]
"At the local edge level, we prefer derivations that follow regular orthographic patterns and preserve semantic relatedness.",1 Introduction,[0],[0]
"We hypothesize that enforcing these constraints as part of the forest induction pro-
2The correct mathematical term for the structure in Figure 1 is a directed 1-forest or functional graph.",1 Introduction,[0],[0]
"For simplicity, we shall use the terms forest and tree to refer to a directed 1-forest or a directed 1-tree because of the cycle at the root.
353
Transactions of the Association for Computational Linguistics, vol. 5, pp. 353–364, 2017.",1 Introduction,[0],[0]
Action Editor: Eric Fosler-Lussier.,1 Introduction,[0],[0]
"Submission batch: 10/2016; Revision batch: 12/2016; Published 10/2017.
",1 Introduction,[0],[0]
c©2017 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
cess will allow us to accurately learn morphological structures in an unsupervised fashion.
",1 Introduction,[0],[0]
"To test this hypothesis, we define an objective over the entire forest representation.",1 Introduction,[0],[0]
"The proposed objective is designed to maximize the likelihood of local derivations, while constraining the overall number of affixes and encouraging tighter morphological families.",1 Introduction,[0],[0]
"We optimize this objective using Integer Linear Programming (ILP), which is commonly employed to handle global constraints.",1 Introduction,[0],[0]
"While in prior work, ILP has often been employed in supervised settings, we explore its effectiveness in unsupervised learning.",1 Introduction,[0],[0]
"We induce a forest by alternating between learning local edge probabilities using a log-linear model, and enforcing global constraints with the ILP-based decoder.",1 Introduction,[0],[0]
"With each iteration, the model progresses towards more consistent forests.
",1 Introduction,[0],[0]
"We evaluate our model on three tasks: root detection, clustering of morphologically related families, and segmentation.",1 Introduction,[0],[0]
"The last task has been extensively studied in recent literature, providing us with the opportunity to compare the model with multiple unsupervised techniques.",1 Introduction,[0],[0]
"On benchmark datasets representing four languages, our model outperforms the baselines, yielding new state-of-the-art results.",1 Introduction,[0],[0]
"For instance, we improve segmentation performance on Turkish by 4.4% and on English by 3.7%, relative to the best published results (Narasimhan et al., 2015).",1 Introduction,[0],[0]
"Similarly, our model exhibits superior performance on the other two tasks.",1 Introduction,[0],[0]
We also provide analysis of the model behavior which reveals that most of the gain comes from enforcing global constraints on the number of unique affixes.,1 Introduction,[0],[0]
"Unsupervised morphological segmentation Most top performing algorithms for unsupervised segmentation today center around modeling singlestep derivations (Poon et al., 2009; Naradowsky and Toutanova, 2011; Narasimhan et al., 2015).",2 Related Work,[0],[0]
A commonly used log-linear formulation enables these models to consider a rich set of features ranging from orthographic patterns to semantic relatedness.,2 Related Work,[0],[0]
"However, these models generally bypass global constraints (Narasimhan et al., 2015) or require performing inference over very large spaces (Poon et al., 2009).",2 Related Work,[0],[0]
"As we show in our
analysis (Section 5), this omission negatively affects model performance.
",2 Related Work,[0],[0]
"In contrast, earlier work focuses on modeling global morphological assignment, using generative probabilistic models (Creutz and Lagus, 2007; Snyder and Barzilay, 2008; Goldwater et al., 2009; Sirts and Goldwater, 2013).",2 Related Work,[0],[0]
"These models are inherently limited in their ability to incorporate diverse features that are effectively utilized by local discriminative models.
",2 Related Work,[0],[0]
"Our proposed approach attempts to combine the advantages of both approaches, by defining an objective that incorporates both levels of linguistic properties over the entire forest representation, and adopting an alternating training regime for optimization.
",2 Related Work,[0],[0]
"Graph-based representations in computational morphology Variants of a graph-based representation have been used to model various morphological phenomena (Dreyer and Eisner, 2009; Peng et al., 2015; Soricut and Och, 2015; Faruqui et al., 2016).",2 Related Work,[0],[0]
The graph induction methods vary widely depending on the task and the available supervision.,2 Related Work,[0],[0]
"The distinctive feature of our work is the use of global constraints to guide the learning of local, edge-level derivations.
",2 Related Work,[0],[0]
"ILP for capturing global properties Integer Linear Programming has been successfully employed to capture global constraints across multiple applications such as information extraction (Roth and Yih, 2001), sentence compression (Clarke and Lapata, 2008), and textual entailment (Berant et al., 2011).",2 Related Work,[0],[0]
"In all of these applications, the ILP formulation is used with a supervised classifier.",2 Related Work,[0],[0]
"Our work demonstrates that this framework continues to be effective in an unsupervised setting, providing strong guidance for a local, unsupervised classifier.",2 Related Work,[0],[0]
"Our model considers a full morphological assignment for all the words in a language, representing it as a forest.",3 Model,[0],[0]
"Let F = (V,E) be a directed graph where each word corresponds to a node v ∈ V .",3 Model,[0],[0]
"A directed edge e = (vc, vp) ∈ E encodes a single morphological derivation from a parent word vp to a child word vc.",3 Model,[0],[0]
"Edges also reflect the type of the
underlying derivation (e.g., prefixation), and an associated probability Pr(e).",3 Model,[0],[0]
Note that the root of a tree is always marked with a self-directed (i.e. vc = vp) edge associated with the label stop.,3 Model,[0],[0]
Figure 1 illustrates a single tree in the forest.,3 Model,[0],[0]
"We postulate that a valid assignment yields forests with the following properties:
1.",3.1 Inducing morphological forests,[0],[0]
Increased edge weights Edge weights reflect probabilities of single-step derivations based on the local features including orthographic patterns and semantic relatedness.,3.1 Inducing morphological forests,[0],[0]
"This local information helps identify that the edge (painter, paint) should be preferred over (painter, pain), because −er is a valid suffix and paint is semantically closer to painter.
2.",3.1 Inducing morphological forests,[0],[0]
Minimized number of affixes Prior research has shown that local models tend to greatly overestimate the number of suffixes.,3.1 Inducing morphological forests,[0],[0]
"For instance, the model of Narasimhan et al. (2015) produces 617 unique affixes when segmenting 10000 English words.",3.1 Inducing morphological forests,[0],[0]
"Thus, we explicitly encourage the model towards assignments with the least number of affixes.
3.",3.1 Inducing morphological forests,[0],[0]
"Minimized number of roots relatively to vocabulary size Similarly, the number of roots, and consequently the number of morphological families is markedly smaller than the size of the vocabulary.
",3.1 Inducing morphological forests,[0],[0]
"The first property is local in nature, while the last two are global and embody the principle of Minimum Description Length (MDL).",3.1 Inducing morphological forests,[0],[0]
"Based on these properties, we formulate an objective function S(F ) over a forest F :
S(F ) =",3.1 Inducing morphological forests,[0],[0]
"− ∑
e∈E log Pr(e) |E| +α|Affix|+β |F | |V | , (1)
where |·| denotes set cardinality, Affix = {ak}Kk=1 is the set of all affixes, and |F | is the number of trees in F .",3.1 Inducing morphological forests,[0],[0]
|E| and |V,3.1 Inducing morphological forests,[0],[0]
"| are the size of the edge set and vocabulary, respectively.",3.1 Inducing morphological forests,[0],[0]
"The hyperparameters α and β capture the relative importance of the three terms.
",3.1 Inducing morphological forests,[0],[0]
"By minimizing this objective, we encourage assignments with high edge probabilities (first term),
while limiting the number of affixes and morphological families (second and third terms, respectively).",3.1 Inducing morphological forests,[0],[0]
"This objective can also be viewed as a simple log-likelihood objective regularized by the last two terms in Equation (1).
",3.1 Inducing morphological forests,[0],[0]
"To illustrate the interaction between local and global constraints in this objective, consider an example in Figure 2.",3.1 Inducing morphological forests,[0],[0]
"If the model selects a different edge – e.g. (paint, pain) instead, all the terms in Equation (1) will be affected.",3.1 Inducing morphological forests,[0],[0]
"We now describe how to parameterize Pr(e), which captures the likelihood of a single-step morphological derivation between two words.",3.2 Computing local probabilities,[0],[0]
"Following prior
work (Narasimhan et al., 2015), we model this probability using a log-linear model:
Pr(w, z) ∝",3.2 Computing local probabilities,[0],[0]
"exp(θ · φ(w, z)), (2)
where θ is the set of parameters to be learned, and φ(w, z) is the feature vector extracted from w and z.",3.2 Computing local probabilities,[0],[0]
"Each candidate z is a tuple (string, label), where label refers to the label of the potential edge.
",3.2 Computing local probabilities,[0],[0]
"As a result, the marginal probability is
Pr(w) = ∑
z∈C(w) Pr(w, z)
= ∑ z∈C(w) exp(θ · φ(w, z))∑
w′∈Σ∗ ∑ z′∈C(w′)",3.2 Computing local probabilities,[0],[0]
exp(θ ·,3.2 Computing local probabilities,[0],[0]
"φ(w′, z′)) ,
where Σ∗ is the set of all possible strings.",3.2 Computing local probabilities,[0],[0]
Computing the sum in the denominator is infeasible.,3.2 Computing local probabilities,[0],[0]
"Instead, we make use of contrastive estimation (Smith and Eisner, 2005), substituting Σ∗ with a (limited) set of neighbor strings N(w) that are orthographically close to w. This technique distributes the probability mass among neighboring words and forces the model to identify meaningful discriminative features.",3.2 Computing local probabilities,[0],[0]
"We obtain N(w) by transposing characters in w, following the method described in Narasimhan et al. (2015).
",3.2 Computing local probabilities,[0],[0]
"Now for the forest over the set of nodes V , the log-likelihood loss function is defined as: L(V ; θ) =",3.2 Computing local probabilities,[0],[0]
"− ∑
v∈V log Pr(v)
=",3.2 Computing local probabilities,[0],[0]
"− ∑
v∈V
[ log ∑
z∈C(v) exp(θ · φ(v, z))
",3.2 Computing local probabilities,[0],[0]
"− log ∑
v′∈N(v)
∑
z′∈C(v′) exp(θ · φ(v′, z′))
] ,
(3)
",3.2 Computing local probabilities,[0],[0]
"This objective can be minimized by gradient descent.
",3.2 Computing local probabilities,[0],[0]
Space of Possible Candidates We only consider assignments where the parent word is strictly shorter than the child word to prevent cycles of length two or more.,3.2 Computing local probabilities,[0],[0]
"In addition to suffixation and prefixation, we also consider three types of transformations introduced in Goldwater and Johnson (2004): repetition, deletion, and modification.",3.2 Computing local probabilities,[0],[0]
"We also handle compounding, where two stems are combined to form a
new word (e.g., football).",3.2 Computing local probabilities,[0],[0]
One of these stems carries the main semantic meaning of the compound and is considered to be the parent of the word.,3.2 Computing local probabilities,[0],[0]
"Note that stems are not considered affixes, so this does not affect the affix list.
",3.2 Computing local probabilities,[0],[0]
"We allow parents to be words outside V , since many legitimate word forms might never appear in the corpus.",3.2 Computing local probabilities,[0],[0]
"For instance, if we have V = {painter, paints}, the optimal solution would add an unseen word paint to the forest, and choose edges (painter, paint) and (paints, paint).
",3.2 Computing local probabilities,[0],[0]
"Features We use the same set of features shown to be effective in prior work (Narasimhan et al., 2015), including word vector similarity, beginning and ending character bigrams, word frequencies and affixes.",3.2 Computing local probabilities,[0],[0]
Affix features are automatically extracted from the corpus based on string difference and are thresholded based on frequency.,3.2 Computing local probabilities,[0],[0]
We also include an additional sibling feature that counts how many words are siblings of word w in its tree.,3.2 Computing local probabilities,[0],[0]
"Siblings are words that are derived from the same parent, e.g., faithful and faithless, both from the word faith.",3.2 Computing local probabilities,[0],[0]
"Minimizing the objective in Equation (1) is challenging because the second and third terms capture discrete global properties of the forest, which prevents us from performing gradient descent directly.",3.3 ILP formulation,[0],[0]
"Instead, we formulate this optimization problem as Integer Linear Programming (ILP), where these two terms can be cast as constraints.3
For each child word vi ∈ V , we have a bounded set of its candidate outgoing edges C(vi) = {zji }, where zji is the j-th candidate for vi. C(vi) is the same set as defined in Section 3.2.",3.3 ILP formulation,[0],[0]
"Each edge is associated with pij , which is computed as log Pr(zji |vi).",3.3 ILP formulation,[0],[0]
Let xij be a binary variable that has value 1 if and only if zji is chosen to be in the forest.,3.3 ILP formulation,[0],[0]
"Without loss of generality, we assume the first candidate edge is always the self-edge (or stop case), i.e., z1i = (vi, stop).",3.3 ILP formulation,[0],[0]
"We also use a set of binary variables {yk} to indicate whether affix ak is used at
3If we had prior knowledge of words belonging to the same family, we can frame the problem as growing a Minimum Spanning Tree (MST), and use Chu-Liu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967) to solve it.",3.3 ILP formulation,[0],[0]
"However, this information is not available to us.
least once in F (i.e. required to explain a morphological change).
",3.3 ILP formulation,[0],[0]
Now let us consider how to derive our ILP formulation using the notations above.,3.3 ILP formulation,[0],[0]
"Note that |F | is equal to the number of self-edges ∑ i xi1, and also a valid forest will satisfy |V",3.3 ILP formulation,[0],[0]
| = |E|.,3.3 ILP formulation,[0],[0]
"Combining these pieces, we can rewrite the objective in Equation (1) and arrive at the following ILP formulation:
minimize xij ,yk
− 1|V | ∑
ij
xijpij +",3.3 ILP formulation,[0],[0]
"α ∑
k
yk + β |V",3.3 ILP formulation,[0],[0]
"| ∑
i
xi1
subject to xij , yk ∈ {0, 1},∑
j
xij = 1,∀i, (4)
xij ≤ yk, if ak is involved in zji .",3.3 ILP formulation,[0],[0]
"(5)
Constraint 4 states that exactly one of the candidate edges should be chosen for each word.",3.3 ILP formulation,[0],[0]
The last constraint implies that we can only consider this candidate (and construct the corresponding edge) when the involved affix4 is used at least once in the forest representation.,3.3 ILP formulation,[0],[0]
"The objective function contains two sets of parameters: a continuous weight vector θ that parameterizes edge probabilities, and binary variables {xij} and {yk} in ILP.",3.4 Alternating training,[0],[0]
"Due to the discordance between continuous and discrete variables, we need to optimize the objective in an alternating manner.",3.4 Alternating training,[0],[0]
Algorithm 1 details the training procedure.,3.4 Alternating training,[0],[0]
"After automatically extracting affixes from the corpus, we alternate between learning the local edge probabilities (line 3) and solving ILP (line 4).
",3.4 Alternating training,[0],[0]
The feedback from solving ILP with the global constraints can help us refine the learning of local probabilities by removing incorrect affixes (line 5).,3.4 Alternating training,[0],[0]
"For instance, automatic extraction based on frequencies can include -ers as an English suffix.",3.4 Alternating training,[0],[0]
"This is likely to be eliminated by ILP, since all occurrences of -ers can be explained away without adding a new affix by concatenating -er and -s, two very common suffixes.",3.4 Alternating training,[0],[0]
"After refining the affix set, we remove all candidates that involve any affix discarded by ILP.",3.4 Alternating training,[0],[0]
This corresponds to reducing the size of C(w) in Equation (3).,3.4 Alternating training,[0],[0]
"We then train the log-linear model
4For English and German, where non-concatenative transformations are possible such as deletion of ending e (taking → take), we also include them in Affix.
again using the newly-pruned candidate set.",3.4 Alternating training,[0],[0]
"By doing so, we force the model to learn from better contrastive signals, and focus on affixes of higher quality, resulting in a new set of probabilities {pij}.",3.4 Alternating training,[0],[0]
This procedure is repeated until no more affixes are rejected.5,3.4 Alternating training,[0],[0]
"We evaluate our model on three tasks: segmentation, morphological family clustering, and root detection.",4 Experiments,[0],[0]
"While the first task has been extensively studied in the prior literature, we consider two additional tasks to assess the flexibility of the derived representation.",4 Experiments,[0],[0]
"Data We choose four languages with distinct morphological properties: English, Turkish, Arabic, and German.",4.1 Morphological segmentation,[0],[0]
Our training data consists of standard datasets used in prior work.,4.1 Morphological segmentation,[0],[0]
Statistics for all datasets are summarized in Table 1.,4.1 Morphological segmentation,[0],[0]
"Note that for the Arabic test set, we filtered out duplicate words, and we reran the baselines to obtain comparable results.
",4.1 Morphological segmentation,[0],[0]
"Following Narasimhan et al. (2015), we reduce the noise by truncating the training word list to the top K frequent words.",4.1 Morphological segmentation,[0],[0]
"In addition, we train word vectors (Mikolov et al., 2013) to obtain cosine similarity features.",4.1 Morphological segmentation,[0],[0]
"Statistics for all datasets are summarized in Table 1.
",4.1 Morphological segmentation,[0],[0]
"Baselines We compare our approach against the state-of-the-art unsupervised method of Narasimhan et al. (2015) which outperforms a number of alternative approaches (Creutz and Lagus, 2005; Virpioja et al., 2013; Sirts and Goldwater, 2013; Lee et al., 2011; Stallard et al., 2012; Poon et al., 2009).",4.1 Morphological segmentation,[0],[0]
"For this baseline, we report the results of the publicly available implementation of the technique (NBJ’15), as well as our own improved reimplementation (NBJ-Imp).",4.1 Morphological segmentation,[0],[0]
"Specifically in NBJ-Imp, we expanded the original algorithm to handle compounding, along with sibling features as described in Section 3.2, making it essentially an ablation of our model without ILP and alternating training.",4.1 Morphological segmentation,[0],[0]
"We employ grid search to find the optimal hyperparameter setting.6
5Typically the model converges after 5 rounds 6K ∈ {2500, 5000, 10000}, number of automatically ex-
tracted affixes ∈ {100, 200, 300, 400, 500}
Algorithm 1",4.1 Morphological segmentation,[0],[0]
"Morphological Forest Induction Input: wordlist V Output: Forest representation of V
1: Affix← ExtractAffixes(W ) .",4.1 Morphological segmentation,[0],[0]
Extract common patterns as affixes from the wordlist 2: for t← 1 to T do .,4.1 Morphological segmentation,[0],[0]
"Alternating training for T iterations 3: ptij ← ContrastiveEstimation(W,Affix) .",4.1 Morphological segmentation,[0],[0]
"Compute local probabilities, cf.",4.1 Morphological segmentation,[0],[0]
"Section 3.2 4: y∗t, F t ← ILP(ptij) .",4.1 Morphological segmentation,[0],[0]
"Get indicators for affixes, and the forest, cf.",4.1 Morphological segmentation,[0],[0]
"Section 3.3 5: PruneAffixSet(Affix, y∗t) .",4.1 Morphological segmentation,[0],[0]
"Prune affix set using the output from ILP, cf.",4.1 Morphological segmentation,[0],[0]
"Section 3.4
return F T
Language Train Test WordVec#Words",4.1 Morphological segmentation,[0],[0]
"#Words #Words
English MC-10 MC-05:10 Wikipedia 878K 2212 129M
Turkish MC-10 MC-05:10 BOUN 617K 2531 361M
Arabic Gigaword ATB Gigaword
3.83M 21085 1.22G
German MC-10 Dsolve Wikipedia 2.34M 15522 589M
Table 1: Data statistics: MC-10 = MorphoChallenge 2010 , MC:05-10 = aggregated from MorphoChallenge 2005-2010, BOUN = BOUN corpus (Sak et al., 2008), Gigaword = Arabic Gigaword corpus (Parker et al., 2011), ATB = Arabic Treebank (Maamouri et al., 2003).",4.1 Morphological segmentation,[0],[0]
Duplicates in Arabic test set are filtered.,4.1 Morphological segmentation,[0],[0]
"Dsolve is the dataset released by Würzner and Jurish (2015), and for training German vectors, we use the pre-processed Wikipedia dump from (Al-Rfou et al., 2013).
",4.1 Morphological segmentation,[0],[0]
"We also include a supervised counterpart, which uses the same set of features as NBJ-Imp but has access to gold segmentation during training (we perform 5-fold cross-validation using the same data).",4.1 Morphological segmentation,[0],[0]
"We obtain the gold standard parent-child pairs required for training from the segmented words in a straightforward fashion.
",4.1 Morphological segmentation,[0],[0]
"Evaluation metric Following prior work (Virpioja et al., 2011), we evaluate all models using the standard boundary precision and recall (BPR).",4.1 Morphological segmentation,[0],[0]
"This measure assesses the accuracy of individual segmentation points, producing IR-style Precision, Recall and F1 scores.
",4.1 Morphological segmentation,[0],[0]
"Language #Words #Clusters #Wordsper Cluster English 75,416 20,249 3.72 German 367,967 28,198 13.05
Table 2: Data statistics for the family clustering task (CELEX).",4.1 Morphological segmentation,[0],[0]
"We only evaluate on English and German, since these are the languages MorphoChallenge has segmentations for.
",4.1 Morphological segmentation,[0],[0]
"Training For unsupervised training, we use the gradient descent method ADAM (Kingma and Ba, 2014) and optimize over the whole batch of training words.",4.1 Morphological segmentation,[0],[0]
We use a Gurobi7 solver for the ILP.,4.1 Morphological segmentation,[0],[0]
Morphological family clustering is the task of clustering morphologically related word forms.,4.2 Morphological family clustering,[0],[0]
"For instance, we want to group paint, paints and pain into two clusters: {paint, paints} and {pain}.",4.2 Morphological family clustering,[0],[0]
"To derive clusters from the forest representation, we assume that all the words in the same tree form a cluster.
",4.2 Morphological family clustering,[0],[0]
"Data To obtain gold information about morphological clusters, we use CELEX (Baayen et al., 1993).",4.2 Morphological family clustering,[0],[0]
Data statistics are summarized in Table 2.,4.2 Morphological family clustering,[0],[0]
"We remove words without stems from CELEX.8
Baseline We compare our model against NBJ-Imp described above.",4.2 Morphological family clustering,[0],[0]
"We select the best variant of our model and the base model based on their respective performance on the segmentation task.
",4.2 Morphological family clustering,[0],[0]
Evaluation We use the metrics proposed by Schone and Jurafsky (2000).,4.2 Morphological family clustering,[0],[0]
"Specifically, let Xw
7http://www.gurobi.com/ 8An example is aerodrome, where both aero- and drome are
affixes.
",4.2 Morphological family clustering,[0],[0]
"and Yw be the clusters for word w in our predictions and gold standard, respectively.",4.2 Morphological family clustering,[0],[0]
"We compute the number of correct (C), inserted (I) and deleted (D) words for the clusters as follows:
C = ∑
w∈W
|Xw ∩ Yw|",4.2 Morphological family clustering,[0],[0]
"|Yw|
I = ∑
w∈W
|Xw \ Yw|",4.2 Morphological family clustering,[0],[0]
"|Yw|
D = ∑
w∈W
|Yw \Xw| |Yw|
Then we compute precision = CC+I , recall = C C+D , F1 = 2 precision·recall precision+recall .",4.2 Morphological family clustering,[0],[0]
"In addition, we evaluate how accurately our model can predict the root of any given word.
",4.3 Root detection,[0],[0]
"Data We report the results on the Chipmunk dataset (Cotterell et al., 2015) which has been used for evaluating supervised models for root detection.",4.3 Root detection,[0],[0]
"Since our model is unsupervised, we report the performance both on the test set only, and on the entire dataset, combining the train/test split.",4.3 Root detection,[0],[0]
Statistics for the dataset are shown in Table 3.,4.3 Root detection,[0],[0]
"In the following subsections, we report model performance on each one of the three evaluation tasks.",5 Results,[0],[0]
9We used cosine similarity features in all experiments.,5.1 Segmentation,[0],[0]
"But the root forms of German verbs are rarely used, except in imperative sentences.",5.1 Segmentation,[0],[0]
"Consequently they have barely trained word vectors, contributing to the low recall value.",5.1 Segmentation,[0],[0]
"We suspect better treatment with word vectors can further improve the results.
",5.1 Segmentation,[0],[0]
10http://www.mathcracker.com/sign-test.,5.1 Segmentation,[0],[0]
"php
From Table 4, we observe that our model consistently outperforms the baselines on all four lan-
guages.",5.1 Segmentation,[0],[0]
"Compared to NBJ’15, our model has a higher F1 score by 3.7%, 4.4%, 2.9% and 27.7% on English, Turkish, Arabic and German, respectively.",5.1 Segmentation,[0],[0]
"While the improved implementation NBJ-Imp benefits from the addition of compounding and sibling features, our model still delivers an absolute increase in F1 score, ranging from 1.8% to 7.7% over NBJImp.",5.1 Segmentation,[0],[0]
"Note that our model achieves higher scores even without tuning the threshold K or the number of affixes, whereas the baselines have optimal hyperparameter settings via grid search.
",5.1 Segmentation,[0],[0]
"To understand the importance of global constraints (the last two terms of Equation (1)), we analyze our model’s performance with different values of α and β (see Figure 3).",5.1 Segmentation,[0],[0]
"The first constraint, which controls the size of the affix set, plays a more dominant role than the second.",5.1 Segmentation,[0],[0]
"By setting α = 0.0, the model scores at best 75.7% on English and 63.2% on Turkish, lower than the baseline.",5.1 Segmentation,[0],[0]
"While the value of β also affects the F1 score, its role is secondary in achieving optimal performance.
",5.1 Segmentation,[0],[0]
The results also demonstrate that language properties can greatly affect the feature set choice.,5.1 Segmentation,[0],[0]
"For fusional languages such as English, computing of sibling features is unreliable.",5.1 Segmentation,[0],[0]
"For example, two descendants of the same parent spot – spotless and spotty – may not be necessarily identified as such by a simple sibling computation algorithm, since they undergo different changes.",5.1 Segmentation,[0],[0]
"In contrast, Turkish is highly agglutinative, with minimal (if any) transformations, but each word can have up to hundreds of related forms.",5.1 Segmentation,[0],[0]
"Consequently, sibling features have different effects on English and Turkish, leading to changes of −0.3% and +2.1% in F1 score respectively.
",5.1 Segmentation,[0],[0]
Understanding model behavior We find that much of the gain in model performance comes from the first two rounds of training.,5.1 Segmentation,[0],[0]
"As Figure 4 shows, the improvement mainly stems from solving ILP in the first round, followed by training the log-linear model in the second round after removing affixes and pruning candidate sets.",5.1 Segmentation,[0],[0]
This is exactly what we expect from the ILP formulation – to globally adjust the forest by reducing the number of unique affixes.,5.1 Segmentation,[0],[0]
"We find this to be quite effective – in English, out of 500 prefixes, only 6 remain: de, dis, im, in, re, and un.",5.1 Segmentation,[0],[0]
"Similarly, only 72 out of 500 suffixes survive
after this reduction.
",5.1 Segmentation,[0],[0]
Robustness We also investigate how robust our model is to the choice of hyperparameters.,5.1 Segmentation,[0],[0]
Figure 3 illustrates that we can obtain a sizable boost over the baseline by choosing α and β within a fairly wide region.,5.1 Segmentation,[0],[0]
"Note that α takes on a much smaller value than β, to maintain the two constraints (|Affix| and |F | |V | ) at comparable magnitudes.
",5.1 Segmentation,[0],[0]
"Narasimhan et al. (2015) observe that after including more than K = 10, 000 words, the performance of the unsupervised model drops noticeably.",5.1 Segmentation,[0],[0]
"In contrast, our model handles training noise more robustly, resulting in a steady boost or not too big drop in performance with increasing training size (Figure 5).",5.1 Segmentation,[0],[0]
"In fact, it scores 83.0% with K = 40, 000 on English, a 6.0% increase in absolute value over the baseline.
",5.1 Segmentation,[0],[0]
"Qualitative analysis Table 5 shows examples of English words that our model segments correctly, while NBJ’15 fails on them.",5.1 Segmentation,[0],[0]
We present them in three categories (top to bottom) based on the component of our model that contributes to the successful segmentation.,5.1 Segmentation,[0],[0]
"The first category benefits from a refinement of the affix set, by removing noisy affixes, such as -nce, -ch, and k-.",5.1 Segmentation,[0],[0]
"This leads to correct stopping as in the case of knuckle or induction of the right suffix, as in divergence.",5.1 Segmentation,[0],[0]
"Further, a smaller affix set also leads to more concentrated weights for the remaining affixes.",5.1 Segmentation,[0],[0]
"For example, the feature weight for -ive jumps from 0.06 to 0.25, so that the derivation negative → negate is favored, as shown in the second category.",5.1 Segmentation,[0],[0]
"Finally, the last category lists some compound words that our model successfully segments.",5.1 Segmentation,[0],[0]
We show the results for morphological family clustering in Table 6.,5.2 Morphological family clustering,[0],[0]
"For both languages, our model increases precision by a wide margin, with a modest boost for recall as well.",5.2 Morphological family clustering,[0],[0]
"This corroborates our findings in the segmentation task, where our model can effectively remove incorrect affixes while still encouraging words to form tight, cohesive families.",5.2 Morphological family clustering,[0],[0]
Table 7 summarizes the results for the root detection task.,5.3 Root detection,[0],[0]
Our model shows consistent improvements over the baseline on all three languages.,5.3 Root detection,[0],[0]
"We also include the results on the test set of two supervised systems: Morfette (Chrupala et al., 2008) and Chipmunk (Cotterell et al., 2015).",5.3 Root detection,[0],[0]
Morfette is a string transducer while Chipmunk is a segmenter.,5.3 Root detection,[0],[0]
"Both systems have access to morphologically annotated corpora.
",5.3 Root detection,[0],[0]
Our model is quite competitive against Morfette.,5.3 Root detection,[0],[0]
"In fact, it achieves higher accuracy for English and Turkish.",5.3 Root detection,[0],[0]
"Compared with Chipmunk, our model
scores 0.65 versus 0.70 on English, bridging the gap significantly.",5.3 Root detection,[0],[0]
"However, the high accuracy for morphologically complex languages such as Turkish and German suggests that unsupervised root detection remains a hard task.",5.3 Root detection,[0],[0]
"In this work, we focus on unsupervised modeling of morphological families, collectively defining a forest over the language vocabulary.",6 Conclusions,[0],[0]
This formulation enables us to incorporate both local and global properties of morphological assignment.,6 Conclusions,[0],[0]
The resulting objective is solved using Integer Linear Programming (ILP) paired with contrastive estimation.,6 Conclusions,[0],[0]
Our experiments demonstrate that our model yields consistent gains in three morphological tasks compared with the best published results.,6 Conclusions,[0],[0]
"We thank Tao Lei, Yuan Zhang and the members of the MIT NLP group for helpful discussions and
feedback.",Acknowledgement,[0],[0]
We are also grateful to anonymous reviewers for their insightful comments.,Acknowledgement,[0],[0]
"This paper focuses on unsupervised modeling of morphological families, collectively comprising a forest over the language vocabulary.",abstractText,[0],[0]
"This formulation enables us to capture edgewise properties reflecting single-step morphological derivations, along with global distributional properties of the entire forest.",abstractText,[0],[0]
These global properties constrain the size of the affix set and encourage formation of tight morphological families.,abstractText,[0],[0]
The resulting objective is solved using Integer Linear Programming (ILP) paired with contrastive estimation.,abstractText,[0],[0]
We train the model by alternating between optimizing the local log-linear model and the global ILP objective.,abstractText,[0],[0]
"We evaluate our system on three tasks: root detection, clustering of morphological families, and segmentation.",abstractText,[0],[0]
Our experiments demonstrate that our model yields consistent gains in all three tasks compared with the best published results.1,abstractText,[0],[0]
Unsupervised Learning of Morphological Forests,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1292–1302 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1292",text,[0],[0]
Data annotation is a major bottleneck for the application of supervised learning approaches to many problems.,1 Introduction,[0],[0]
"As a result, unsupervised methods that learn directly from unlabeled data are increasingly important.",1 Introduction,[0],[0]
"For tasks related to unsupervised syntactic analysis, discrete generative models have dominated in recent years – for example, for both part-of-speech (POS) induction (Blunsom and Cohn, 2011; Stratos et al., 2016) and unsupervised dependency parsing (Klein and Manning,
1Code is available at https://github.com/jxhe/structlearning-with-flow.
(a) Traditional pre-trained skip-gram embeddings (b) Learned latent embeddings from our approach
Figure 1:",1 Introduction,[0],[0]
Visualization (t-SNE) of skip-gram embeddings (trained on one billion words with context window size equal to 1) and latent embeddings learned by our approach with a Markov-structured prior.,1 Introduction,[0],[0]
"Each node represents a word and is colored according to the most likely gold POS tag from the Penn Treebank (best seen in color).
2004; Cohen and Smith, 2009; Pate and Johnson, 2016).",1 Introduction,[0],[0]
"While similar models have had success on a range of unsupervised tasks, they have mostly ignored the apparent utility of continuous word representations evident from supervised NLP applications (He et al., 2017; Peters et al., 2018).",1 Introduction,[0],[0]
"In this work, we focus on leveraging and explicitly representing continuous word embeddings within unsupervised models of syntactic structure.
",1 Introduction,[0],[0]
"Pre-trained word embeddings from massive unlabeled corpora offer a compact way of injecting a prior notion of word similarity into models that would otherwise treat words as discrete, isolated categories.",1 Introduction,[0],[0]
"However, the specific properties of language captured by any particular embedding scheme can be difficult to control, and, further, may not be ideally suited to the task at hand.",1 Introduction,[0],[0]
"For example, pre-trained skip-gram embeddings (Mikolov et al., 2013) with small context window size are found to capture the syntactic properties of language well (Bansal et al., 2014; Lin et al., 2015).",1 Introduction,[0],[0]
"However, if our goal is to separate syntactic categories, this embedding space is not ideal – POS categories correspond to overlap-
ping interspersed regions in the embedding space, evident in Figure 1(a).
",1 Introduction,[0],[0]
"In our approach, we propose to learn a new latent embedding space as a projection of pretrained embeddings (depicted in Figure 1(b)), while jointly learning latent syntactic structure – for example, POS categories or syntactic dependencies.",1 Introduction,[0],[0]
"To this end, we introduce a new generative model (shown in Figure 2) that first generates a latent syntactic representation (e.g. a dependency parse) from a discrete structured prior (which we also call the “syntax model”), then, conditioned on this representation, generates a sequence of latent embedding random variables corresponding to each word, and finally produces the observed (pre-trained) word embeddings by projecting these latent vectors through a parameterized non-linear function.",1 Introduction,[0],[0]
"The latent embeddings can be jointly learned with the structured syntax model in a completely unsupervised fashion.
",1 Introduction,[0],[0]
"By choosing an invertible neural network as our non-linear projector, and then parameterizing our model in terms of the projection’s inverse, we are able to derive tractable exact inference and marginal likelihood computation procedures so long as inference is tractable in the underlying syntax model.",1 Introduction,[0],[0]
"In §3.1 we show that this derivation corresponds to an alternate view of our approach whereby we jointly learn a mapping of observed word embeddings to a new embedding space that is more suitable for the syntax model, but include an additional Jacobian regularization term to prevent information loss.
",1 Introduction,[0],[0]
"Recent work has sought to take advantage of word embeddings in unsupervised generative
models with alternate approaches (Lin et al., 2015; Tran et al., 2016; Jiang et al., 2016; Han et al., 2017).",1 Introduction,[0],[0]
"Lin et al. (2015) build an HMM with Gaussian emissions on observed word embeddings, but they do not attempt to learn new embeddings.",1 Introduction,[0],[0]
"Tran et al. (2016), Jiang et al. (2016), and Han et al. (2017) extend HMM or dependency model with valence (DMV) (Klein and Manning, 2004) with multinomials that use word (or tag) embeddings in their parameterization.",1 Introduction,[0],[0]
"However, they do not represent the embeddings as latent variables.
",1 Introduction,[0],[0]
"In experiments, we instantiate our approach using both a Markov-structured syntax model and a tree-structured syntax model – specifically, the DMV.",1 Introduction,[0],[0]
We evaluate on two tasks: part-of-speech (POS) induction and unsupervised dependency parsing without gold POS tags.,1 Introduction,[0],[0]
"Experimental results on the Penn Treebank (Marcus et al., 1993) demonstrate that our approach improves the basic HMM and DMV by a large margin, leading to the state-of-the-art results on POS induction, and state-of-the-art results on unsupervised dependency parsing in the difficult training scenario where neither gold POS annotation nor punctuation-based constraints are available.",1 Introduction,[0],[0]
"As an illustrative example, we first present a baseline model for Markov syntactic structure (POS induction) that treats a sequence of pre-trained word embeddings as observations.",2 Model,[0],[0]
"Then, we propose our novel approach, again using Markov structure, that introduces latent word embedding variables and a neural projector.",2 Model,[0],[0]
"Lastly, we extend our approach to more general syntactic structures.",2 Model,[0],[0]
"We start by describing the Gaussian hidden Markov model introduced by Lin et al. (2015), which is a locally normalized model with multinomial transitions and Gaussian emissions.",2.1 Example: Gaussian HMM,[0],[0]
"Given a sentence of length `, we denote the latent POS tags as z = {zi}`i=1, observed (pre-trained) word embeddings as x = {xi}`i=1, transition parameters as θ, and Gaussian emission parameters as η.",2.1 Example: Gaussian HMM,[0],[0]
"The joint distribution of data and latent variables factors as:
p(z,x;θ,η) = ∏`
i=1 pθ(zi|zi−1)pη(xi|zi), (1)
where pθ(zi|zi−1) is the multinomial transition probability and pη(xi|zi) is the multivariate Gaussian emission probability.
",2.1 Example: Gaussian HMM,[0],[0]
While the observed word embeddings do inform this model with a notion of word similarity – lacking in the basic multinomial HMM – the Gaussian emissions may not be sufficiently flexible to separate some syntactic categories in the complex pretrained embedding space – for example the skipgram embedding space as visualized in Figure 1(a) where different POS categories overlap.,2.1 Example: Gaussian HMM,[0],[0]
Next we introduce a new approach that adds flexibility to the emission distribution by incorporating new latent embedding variables.,2.1 Example: Gaussian HMM,[0],[0]
"To flexibly model observed embeddings and yield a new representation space that is more suitable for the syntax model, we propose to cascade a neural network as a projection function, deterministically transforming the simple space defined by the Gaussian HMM to the observed embedding space.",2.2 Markov Structure with Neural Projector,[0],[0]
"We denote the latent embedding of the ith word in a sentence as ei ∈ Rde , and the neural projection function as f , parameterized by φ.",2.2 Markov Structure with Neural Projector,[0],[0]
"In the case of sequential Markov structure, our new model corresponds to the following generative process:
For each time step i = 1, 2, · · · , `,
• Draw the latent state zi ∼ pθ(zi|zi−1) •",2.2 Markov Structure with Neural Projector,[0],[0]
"Draw the latent embedding ei ∼ N (µzi ,Σzi) •",2.2 Markov Structure with Neural Projector,[0],[0]
"Deterministically produce embedding xi = fφ(ei)
",2.2 Markov Structure with Neural Projector,[0],[0]
The graphical model is depicted in Figure 2.,2.2 Markov Structure with Neural Projector,[0],[0]
"The deterministic projection can also be viewed as sampling each observation from a point mass at
fφ(ei).",2.2 Markov Structure with Neural Projector,[0],[0]
"The joint distribution of our model is:
p(z, e,x;θ,η,φ) = ∏`
i=1",2.2 Markov Structure with Neural Projector,[0],[0]
"[pθ(zi|zi−1)pη(ei|zi)pφ(xi|ei)],
(2)
where pη(·|zi) is a conditional Gaussian distribution, and pφ(xi|ei) is the Dirac delta function centered at fφ(ei):
pφ(xi|ei) = δ(xi−fφ(ei))",2.2 Markov Structure with Neural Projector,[0],[0]
= { ∞ xi = fφ(ei) 0,2.2 Markov Structure with Neural Projector,[0],[0]
"otherwise
(3)",2.2 Markov Structure with Neural Projector,[0],[0]
Our approach can be applied to a broad family of structured syntax models.,2.3 General Structure with Neural Projector,[0],[0]
"We denote latent embedding variables as e = {ei}`i=1, discrete latent variables in the syntax model as z = {zk}Kk=1 (K > `), where z1, z2, . . .",2.3 General Structure with Neural Projector,[0],[0]
", z` are conditioned to generate e1, e2, . . .",2.3 General Structure with Neural Projector,[0],[0]
", e`.",2.3 General Structure with Neural Projector,[0],[0]
"The joint probability of our model factors as:
p(z, e,x;θ,η,φ) = ∏`
i=1
[ pη(ei|zi)pφ(xi|ei) ] · psyntax(z;θ), (4)
where psyntax(z;θ) represents the probability of the syntax model, and can encode any syntactic structure – though, its factorization structure will determine whether inference is tractable in our full model.",2.3 General Structure with Neural Projector,[0],[0]
"As shown in Figure 2, we focus on two syntax models for syntactic analysis in this paper.",2.3 General Structure with Neural Projector,[0],[0]
"The first is Markov-structured, which we use for POS induction, and the second is DMV-structured, which we use to learn dependency parses without supervision.
",2.3 General Structure with Neural Projector,[0],[0]
"The marginal data likelihood of our model is: p(x) = ∑
z
( psyntax(z;θ)
· ∏`
i=1",2.3 General Structure with Neural Projector,[0],[0]
"[ ∫ ei
pη(ei|zi)pφ(xi|ei)dei︸ ︷︷ ︸ p(xi|zi)
]) .
",2.3 General Structure with Neural Projector,[0],[0]
"(5)
While the discrete variables z can be marginalized out with dynamic program in many cases, it is generally intractable to marginalize out the latent continuous variables, ei, for an arbitrary projection f in Eq.",2.3 General Structure with Neural Projector,[0],[0]
"(5), which means inference and learning may be difficult.",2.3 General Structure with Neural Projector,[0],[0]
"In §3, we address this issue by constraining f to be invertible, and show that this constraint enables tractable exact inference and marginal likelihood computation.",2.3 General Structure with Neural Projector,[0],[0]
"In this section, we introduce an invertibility condition for our neural projector to tackle the optimization challenge.",3 Learning & Inference,[0],[0]
"Specifically, we constrain our neural projector with two requirements: (1) dim(x) = dim(e) and (2) f−1φ exists.",3 Learning & Inference,[0],[0]
"Invertible transformations have been explored before in independent components analysis (Hyvärinen et al., 2004), gaussianization (Chen and Gopinath, 2001), and deep density models (Dinh et al., 2014, 2016; Kingma and Dhariwal, 2018), for unstructured data.",3 Learning & Inference,[0],[0]
"Here, we generalize this style of approach to structured learning, and augment it with discrete latent variables (zi).",3 Learning & Inference,[0],[0]
"Under the invertibility condition, we derive a learning algorithm and give another view of our approach revealed by the objective function.",3 Learning & Inference,[0],[0]
"Then, we present the architecture of a neural projector we use in experiments: a volume-preserving invertible neural network proposed by Dinh et al. (2014) for independent components estimation.",3 Learning & Inference,[0],[0]
"For ease of exposition, we explain the learning algorithm in terms of Markov structure without loss of generality.",3.1 Learning with Invertibility,[0],[0]
As shown in Eq.,3.1 Learning with Invertibility,[0],[0]
"(5), the optimization challenge in our approach comes from the intractability of the marginalized emission factor p(xi|zi).",3.1 Learning with Invertibility,[0],[0]
"If we can marginalize out ei and compute p(xi|zi), then the posterior and marginal likelihood of our Markov-structured model can be computed with the forward-backward algorithm.",3.1 Learning with Invertibility,[0],[0]
We can apply Eq.,3.1 Learning with Invertibility,[0],[0]
"(3) and obtain :
p(xi|zi;η,φ) = ∫ ei pη(ei|zi)δ(xi − fφ(ei))dei.
",3.1 Learning with Invertibility,[0],[0]
"By using the change of variable rule to the integration, which allows the integration variable ei to be replaced by x′i = fφ(ei), the marginal emission factor can be computed in closed-form when the invertibility condition is satisfied:
p(xi|zi;η,φ)
",3.1 Learning with Invertibility,[0],[0]
= ∫ x′i pη(f −1 φ (x ′ i)|zi)δ(xi,3.1 Learning with Invertibility,[0],[0]
− x′i) ∣∣∣det∂f−1φ ∂x′i ∣∣∣dx′i = pη(f −1 φ,3.1 Learning with Invertibility,[0],[0]
"(xi)|zi) ∣∣∣det∂f−1φ ∂xi
∣∣∣, (6) where pη(·|z) is a conditional Gaussian distribution, ∂f−1φ ∂xi is the Jacobian matrix of function f−1φ
at xi, and ∣∣det∂f−1φ∂xi ∣∣ represents the absolute value of its determinant.",3.1 Learning with Invertibility,[0],[0]
"This Jacobian term is nonzero and differentiable if and only if f−1φ exists.
",3.1 Learning with Invertibility,[0],[0]
Eq. (6) shows that we can directly calculate the marginal emission distribution p(xi|zi).,3.1 Learning with Invertibility,[0],[0]
"Denote the marginal data likelihood of Gaussian HMM as pHMM(x), then the log marginal data likelihood of our model can be directly written as:
log p(x) = log pHMM(f −1 φ (x))
",3.1 Learning with Invertibility,[0],[0]
"+ ∑` i=1 log ∣∣∣det∂f−1φ
∂xi ∣∣∣, (7) where f−1φ (x) represents the new sequence of embeddings after applying f−1φ to each xi. Eq. (7) shows that the training objective of our model is simply the Gaussian HMM log likelihood with an additional Jacobian regularization term.",3.1 Learning with Invertibility,[0],[0]
"From this view, our approach can be seen as equivalent to reversely projecting the data through f−1φ to another manifold e that is directly modeled by the Gaussian HMM, with a regularization term.",3.1 Learning with Invertibility,[0],[0]
"Intuitively, we optimize the reverse projection f−1φ to modify the e space, making it more appropriate for the syntax model.",3.1 Learning with Invertibility,[0],[0]
The Jacobian regularization term accounts for the volume expansion or contraction behavior of the projection.,3.1 Learning with Invertibility,[0],[0]
Maximizing it can be thought of as preventing information loss.,3.1 Learning with Invertibility,[0],[0]
"In the extreme case, the Jacobian determinant is equal to zero, which means the projection is non-invertible and thus information is being lost through the projection.",3.1 Learning with Invertibility,[0],[0]
"Such “information preserving” regularization is crucial during optimization, otherwise the trivial solution of always projecting data to the same single point to maximize likelihood is viable.2
More generally, for an arbitrary syntax model the data likelihood of our approach is: p(x) = ∑
z
( psyntax(z)
· ∏`
i=1",3.1 Learning with Invertibility,[0],[0]
"pη(f
−1 φ",3.1 Learning with Invertibility,[0],[0]
(xi)|zi) ∣∣∣det∂f−1φ ∂xi ∣∣∣).,3.1 Learning with Invertibility,[0],[0]
"(8) If the syntax model itself allows for tractable inference and marginal likelihood computation, the same dynamic program can be used to marginalize out z. Therefore, our joint model inherits the tractability of the underlying syntax model.
",3.1 Learning with Invertibility,[0],[0]
"2For example, all ei could learn to be zero vectors, leading to the trivial solution of learning zero mean and zero variance Gaussian emissions achieving infinite data likelihood.",3.1 Learning with Invertibility,[0],[0]
"For the projection we can use an arbitrary invertible function, and given the representational power of neural networks they seem a natural choice.",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"However, calculating the inverse and Jacobian of an arbitrary neural network can be difficult, as it requires that all component functions be invertible and also requires storage of large Jacobian matrices, which is memory intensive.",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"To address this issue, several recent papers propose specially designed invertible networks that are easily trainable yet still powerful (Dinh et al., 2014, 2016; Jacobsen et al., 2018).",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"Inspired by these works, we use the invertible transformation proposed by Dinh et al. (2014), which consists of a series of “coupling layers”.",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"This architecture is specially designed to guarantee a unit Jacobian determinant (and thus the invertibility property).
",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
From Eq.,3.2 Invertible Volume-Preserving Neural Net,[0],[0]
(8) we know that only f−1φ is required for accomplishing learning and inference; we never need to explicitly construct fφ.,3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"Thus, we directly define the architecture of f−1φ .",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"As shown in Figure 3, the nonlinear transformation from the observed embedding xi to h (1) i represents the first coupling layer.",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"The input in this layer is partitioned into left and right halves of dimensions, xi,l and xi,r, respectively.",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"A single coupling layer is defined as:
h (1) i,l = xi,l, h (1) i,r = xi,r + g(xi,l), (9)
where g : Rdx/2 → Rdx/2 is the coupling function and can be any nonlinear form.",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
This transformation satisfies dim(h(1)),3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"= dim(x), and Dinh et al. (2014) show that its Jacobian matrix is tri-
angular with all ones on the main diagonal.",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"Thus the Jacobian determinant is always equal to one (i.e. volume-preserving) and the invertibility condition is naturally satisfied.
",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"To be sufficiently expressive, we compose multiple coupling layers as suggested in Dinh et al. (2014).",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"Specifically, we exchange the role of left and right half vectors at each layer as shown in Figure 3.",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"For instance, from xi to h (1) i the left subset",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"xi,l is unchanged, while from h (1) i to h (2)",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"i the right subset h (1) i,r remains the same.",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
Also note that composing multiple coupling layers does not change the volume-preserving and invertibility properties.,3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"Such a sequence of invertible transformations from the data space x to e is also called normalizing flow (Rezende and Mohamed, 2015).",3.2 Invertible Volume-Preserving Neural Net,[0],[0]
"In this section, we first describe our datasets and experimental setup.",4 Experiments,[0],[0]
"We then instantiate our approach with Markov and DMV-structured syntax models, and report results on POS tagging and dependency grammar induction respectively.",4 Experiments,[0],[0]
"Lastly, we analyze the learned latent embeddings.",4 Experiments,[0],[0]
"For both POS tagging and dependency parsing, we run experiments on the Wall Street Journal (WSJ) portion of the Penn Treebank.3 To create the observed data embeddings, we train skip-gram word embeddings (Mikolov et al., 2013) that are found to capture syntactic properties well when trained with small context window (Bansal et al., 2014; Lin et al., 2015).",4.1 Data,[0],[0]
"Following Lin et al. (2015), the dimensionality dx is set to 100, and the training context window size is set to 1 to encode more syntactic information.",4.1 Data,[0],[0]
"The skip-gram embeddings are trained on the one billion word language modeling benchmark dataset (Chelba et al., 2013) in addition to the WSJ corpus.",4.1 Data,[0],[0]
"For the neural projector, we employ rectified networks as coupling function g following Dinh et al. (2014).",4.2 General Experimental Setup,[0],[0]
"We use a rectified network with an input layer, one hidden layer, and linear output units, the number of hidden units is set to the same as the number of input units.",4.2 General Experimental Setup,[0],[0]
"The number of coupling layers are varied as 4, 8, 16 for both tasks.
",4.2 General Experimental Setup,[0],[0]
"3Preprocessing is different for the two tasks, we describe the details in the following subsections.
",4.2 General Experimental Setup,[0],[0]
"We optimize marginal data likelihood directly using Adam (Kingma and Ba, 2014).",4.2 General Experimental Setup,[0],[0]
"For both tasks in the fully unsupervised setting, we do not tune the hyper-parameters using supervised data.",4.2 General Experimental Setup,[0],[0]
"For unsupervised POS tagging, we use a Markovstructured syntax model in our approach, which is a popular structure for unsupervised tagging tasks (Lin et al., 2015; Tran et al., 2016).
",4.3 Unsupervised POS tagging,[0],[0]
Setup.,4.3 Unsupervised POS tagging,[0],[0]
"Following existing literature, we train and test on the entire WSJ corpus (49208 sentences, 1M tokens).",4.3 Unsupervised POS tagging,[0],[0]
"We use 45 tag clusters, the number of POS tags that appear in WSJ corpus.",4.3 Unsupervised POS tagging,[0],[0]
"We train the discrete HMM and the Gaussian HMM (Lin et al., 2015) as baselines.",4.3 Unsupervised POS tagging,[0],[0]
"For the Gaussian HMM, mean vectors of Gaussian emissions are initialized with the empirical mean of all word vectors with an additive noise.",4.3 Unsupervised POS tagging,[0],[0]
We assume diagonal covariance matrix for p(ei|zi) and initialize it with the empirical variance of the word vectors.,4.3 Unsupervised POS tagging,[0],[0]
"Following Lin et al. (2015), the covariance matrix is fixed during training.",4.3 Unsupervised POS tagging,[0],[0]
"The multinomial probabilities are initialized as θkv ∝ exp(ukv), where ukv ∼ U [0, 1].",4.3 Unsupervised POS tagging,[0],[0]
"For our approach, we initialize the syntax model and Gaussian parameters with the pre-trained Gaussian HMM.",4.3 Unsupervised POS tagging,[0],[0]
"The weights of layers in the rectified network are initialized from a uniform distribution with mean zero and a standard deviation of √ 1/nin, where nin is the input dimension.4",4.3 Unsupervised POS tagging,[0],[0]
"We evaluate the performance of POS tagging with both Many-to-One (M-1) accuracy (Johnson, 2007) and V-Measure (VM) (Rosenberg and Hirschberg, 2007).",4.3 Unsupervised POS tagging,[0],[0]
"Given a model we found that the tagging performance is well-correlated with the training data likelihood, thus we use training data likelihood as a unsupervised criterion to select the trained model over 10 random restarts after training 50 epochs.",4.3 Unsupervised POS tagging,[0],[0]
"We repeat this process 5 times and report the mean and standard deviation of performance.
Results.",4.3 Unsupervised POS tagging,[0],[0]
"We compare our approach with basic HMM, Gaussian HMM, and several stateof-the-art systems, including sophisticated HMM variants and clustering techniques with handengineered features.",4.3 Unsupervised POS tagging,[0],[0]
The results are presented in Table 1.,4.3 Unsupervised POS tagging,[0],[0]
"Through the introduced latent embeddings and additional neural projection, our approach improves over the Gaussian HMM by 5.4 points in M-1 and 5.6 points in VM.",4.3 Unsupervised POS tagging,[0],[0]
"Neural HMM
4This is the default parameter initialization in PyTorch.
",4.3 Unsupervised POS tagging,[0],[0]
"(NHMM) (Tran et al., 2016) is a baseline that also learns word representation jointly.",4.3 Unsupervised POS tagging,[0],[0]
Both their basic model and extended Conv version does not outperform the Gaussian HMM.,4.3 Unsupervised POS tagging,[0],[0]
"Their best model incorporates another LSTM to model long distance dependency and breaks the Markov assumption, yet our approach still achieves substantial improvement over it without considering more context information.",4.3 Unsupervised POS tagging,[0],[0]
"Moreover, our method outperforms the best published result that benefits from hand-engineered features (Yatbaz et al., 2012) by 2.0 points on VM.
Confusion Matrix.",4.3 Unsupervised POS tagging,[0],[0]
We found that most tagging errors happen in noun subcategories.,4.3 Unsupervised POS tagging,[0],[0]
"Therefore, we do the one-to-one mapping between gold POS tags and induced clusters and plot the normalized confusion matrix of noun subcategories in Figure 4.",4.3 Unsupervised POS tagging,[0],[0]
"The Gaussian HMM fails to identify “NN” and “NNS” correctly for most cases, and it often recognizes “NNPS” as “NNP”.",4.3 Unsupervised POS tagging,[0],[0]
"In contrast, our approach corrects these errors well.",4.3 Unsupervised POS tagging,[0],[0]
"For the task of unsupervised dependency parse induction, we employ the Dependency Model with Valence (DMV) (Klein and Manning, 2004) as the syntax model in our approach.",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"DMV is a generative model that defines a probability distribution over dependency parse trees and syntactic categories, generating tokens and dependencies in a head-outward fashion.",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"While, traditionally, DMV is trained using gold POS tags as observed syntactic categories, in our approach, we treat each tag as a latent variable, as described in §2.3.
",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
Most existing approaches to this task are not fully unsupervised since they rely on gold POS tags following the original experimental setup for DMV.,4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"This is partially because automatically parsing from words is difficult even when using unsupervised syntactic categories (Spitkovsky et al., 2011a).",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"However, inducing dependencies from words alone represents a more realistic experimental condition since gold POS tags are often unavailable in practice.",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"Previous work that has trained from words alone often requires additional linguistic constraints (like sentence internal boundaries) (Spitkovsky et al., 2011a,b, 2012, 2013), acoustic cues (Pate and Goldwater, 2013), additional training data (Pate and Johnson, 2016), or annotated data from related languages (Cohen et al., 2011).",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"Our approach is naturally designed to train on word embeddings directly, thus we attempt to induce dependencies without using gold POS tags or other extra linguistic information.
",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
Setup.,4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"Like previous work we use sections 02- 21 of WSJ corpus as training data and evaluate on section 23, we remove punctuations and train the models on sentences of length 6 10, “headpercolation” rules (Collins, 1999) are applied to obtain gold dependencies for evaluation.",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"We train basic DMV, extended DMV (E-DMV) (Headden III et al., 2009) and Gaussian DMV (which treats POS tag as unknown latent variables and generates observed word embeddings directly conditioned on them following Gaussian distribution) as baselines.",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"Basic DMV and E-DMV are trained with Viterbi EM (Spitkovsky et al., 2010) on unsupervised POS tags induced from our Markov-structured model described in §4.3.",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
Multinomial parameters of the syntax model in both Gaussian DMV and our model are initialized with the pre-trained DMV baseline.,4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"Other
parameters are initialized in the same way as in the POS tagging experiment.",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
The directed dependency accuracy (DDA) is used for evaluation and we report accuracy on sentences of length 6 10 and all lengths.,4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"We train the parser until training data likelihood converges, and report the mean and standard deviation over 20 random restarts.
",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
Comparison with other related work.,4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
Our model directly observes word embeddings and does not require gold POS tags during training.,4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"Thus, results from related work trained on gold tags are not directly comparable.",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"However, to measure how these systems might perform without gold tags, we run three recent state-of-theart systems in our experimental setting: URA E-DMV (Tu and Honavar, 2012), Neural EDMV (Jiang et al., 2016), and CRF Autoencoder (CRFAE) (Cai et al., 2017).5",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"We use unsupervised POS tags (induced from our Markov-structured model) in place of gold tags.6 We also train basic DMV on gold tags and include several stateof-the-art results on gold tags as reference points.
Results.",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"As shown in Table 2, our approach is able to improve over the Gaussian DMV by 4.8 points on length 6 10 and 4.8 points on all
5For the three systems, we use implementations from the original papers (via personal correspondence with the authors), and tune their hyperparameters on section 22 of WSJ.
6Using words directly is not practical because these systems often require a transition probability matrix between input symbols, which requires too much memory.
lengths, which suggests the additional latent embedding layer and neural projector are helpful.",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"The proposed approach yields, to the best of our knowledge,7 state-of-the-art performance without gold POS annotation and without sentenceinternal boundary information.",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"DMV, UR-A EDMV, Neural E-DMV, and CRFAE suffer a large decrease in performance when trained on unsupervised tags – an effect also seen in previous work (Spitkovsky et al., 2011a; Cohen et al., 2011).",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
"Since our approach induces latent POS tags jointly with dependency trees, it may be able to learn POS clusters that are more amenable to grammar induction than the unsupervised tags.",4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
We observe that CRFAE underperforms its goldtag counterpart substantially.,4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
This may largely be a result of the model’s reliance on prior linguistic rules that become unavailable when gold POS tag types are unknown.,4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
Many extensions to DMV can be considered orthogonal to our approach – they essentially focus on improving the syntax model.,4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
It is possible that incorporating these more sophisticated syntax models into our approach may lead to further improvements.,4.4 Unsupervised Dependency Parsing without gold POS tags,[0],[0]
Impact of Initialization.,4.5 Sensitivity Analysis,[0],[0]
"In the above experiments we initialize the structured syntax components with the pre-trained Gaussian or discrete baseline, which is shown as a useful technique to help train our deep models.",4.5 Sensitivity Analysis,[0],[0]
We further study the results with fully random initialization.,4.5 Sensitivity Analysis,[0],[0]
"In the POS tagging experiment, we report the results in Table 3.",4.5 Sensitivity Analysis,[0],[0]
"While the performance with 4 layers is comparable to the pre-trained Gaussian initialization, deeper projections (8 or 16 layers) result in a dramatic drop in performance.",4.5 Sensitivity Analysis,[0],[0]
"This suggests that the structured syntax model with very deep projections is difficult to train from scratch, and a simpler projection might be a good compromise in the random initialization setting.
",4.5 Sensitivity Analysis,[0],[0]
"Different from the Markov prior in POS tag7We tried to be as thorough as possible in evaluation by running top performing systems using our more difficult training setup when this was feasible – but it was not possible to evaluate them all.
ging experiments, our parsing model seems to be quite sensitive to the initialization.",4.5 Sensitivity Analysis,[0],[0]
"For example, directed accuracy of our approach on sentences of length 6 10 is below 40.0 with random initialization.",4.5 Sensitivity Analysis,[0],[0]
"This is consistent with previous work that has noted the importance of careful initialization for DMV-based models such as the commonly used harmonic initializer (Klein and Manning, 2004).",4.5 Sensitivity Analysis,[0],[0]
"However, it is not straightforward to apply the harmonic initializer for DMV directly in our model without using some kind of pre-training since we do not observe gold POS.
Impact of Observed Embeddings.",4.5 Sensitivity Analysis,[0],[0]
We investigate the effect of the choice of pre-trained embedding on performance while using our approach.,4.5 Sensitivity Analysis,[0],[0]
"To this end, we additionally include results using fastText embeddings (Bojanowski et al., 2017) – which, in contrast with skip-gram embeddings, include character-level information.",4.5 Sensitivity Analysis,[0],[0]
"We set the context windows size to 1 and the dimension size to 100 as in the skip-gram training, while keeping other parameters set to their defaults.",4.5 Sensitivity Analysis,[0],[0]
These results are summarized in Table 4 and Table 5.,4.5 Sensitivity Analysis,[0],[0]
"While fastText embeddings lead to reduced performance with our model, our approach still yields an improvement over the Gaussian baseline with the new observed embeddings space.",4.5 Sensitivity Analysis,[0],[0]
We perform qualitative analysis to understand how the latent embeddings help induce syntactic structures.,4.6 Qualitative Analysis of Embeddings,[0],[0]
"First we filter out low-frequency words and punctuations in WSJ, and visualize the rest words (10k) with t-SNE (Maaten and Hinton, 2008) under different embeddings.",4.6 Qualitative Analysis of Embeddings,[0],[0]
"We assign each word with its most likely gold POS tags in WSJ and color them according to the gold POS tags.
",4.6 Qualitative Analysis of Embeddings,[0],[0]
"For our Markov-structured model, we have displayed the embedding space in Figure 1(b), where the gold POS clusters are well-formed.",4.6 Qualitative Analysis of Embeddings,[0],[0]
"Further, we present five example target words and their five nearest neighbors in terms of cosine similarity.",4.6 Qualitative Analysis of Embeddings,[0],[0]
"As shown in Table 6, the skip-gram embedding captures both semantic and syntactic aspects to some degree, yet our embeddings are able to focus especially on the syntactic aspects of words, in an unsupervised fashion without using any extra morphological information.
",4.6 Qualitative Analysis of Embeddings,[0],[0]
In Figure 5 we depict the learned latent embeddings with the DMV-structured syntax model.,4.6 Qualitative Analysis of Embeddings,[0],[0]
"Unlike the Markov structure, the DMV structure maps a large subset of singular and plural nouns to the same overlapping region.",4.6 Qualitative Analysis of Embeddings,[0],[0]
"However, two clusters of singular and plural nouns are actually separated.",4.6 Qualitative Analysis of Embeddings,[0],[0]
"We inspect the two clusters and the overlapping region in Figure 5, it turns out that the nouns in the separated clusters are words that can appear as subjects and, therefore, for which verb agreement is important to model.",4.6 Qualitative Analysis of Embeddings,[0],[0]
"In contrast, the nouns
in the overlapping region are typically objects.",4.6 Qualitative Analysis of Embeddings,[0],[0]
"This demonstrates that the latent embeddings are focusing on aspects of language that are specifically important for modeling dependency without ever having seen examples of dependency parses.
",4.6 Qualitative Analysis of Embeddings,[0],[0]
"Some previous work has deliberately created embeddings to capture different notions of similarity (Levy and Goldberg, 2014; Cotterell and Schütze, 2015), while they use extra morphology or dependency annotations to guide the embedding learning, our approach provides a potential alternative to create new embeddings that are guided by structured syntax model, only using unlabeled text corpora.",4.6 Qualitative Analysis of Embeddings,[0],[0]
"Our approach is related to flow-based generative models, which are first described in NICE (Dinh et al., 2014) and have recently received more attention (Dinh et al., 2016; Jacobsen et al., 2018; Kingma and Dhariwal, 2018).",5 Related Work,[0],[0]
This relevant work mostly adopts simple (e.g. Gaussian) and fixed priors and does not attempt to learn interpretable latent structures.,5 Related Work,[0],[0]
"Another related generative model class is variational auto-encoders (VAEs) (Kingma and Welling, 2013) that optimize a lower bound on the marginal data likelihood, and can be extended to learn latent structures (Miao and Blunsom, 2016; Yin et al., 2018).",5 Related Work,[0],[0]
"Against the flow-based models, VAEs remove the invertibility constraint but sacrifice the merits of exact inference and exact log likelihood computation, which potentially results in optimization challenges (Kingma et al., 2016).",5 Related Work,[0],[0]
"Our approach can also be viewed in connection with generative adversarial networks (GANs) (Goodfellow et al., 2014) that is a likelihood-free framework to learn implicit generative models.",5 Related Work,[0],[0]
"However, it is nontrivial for a gradient-based method like GANs to propagate gradients through discrete structures.",5 Related Work,[0],[0]
"In this work, we define a novel generative approach to leverage continuous word representations for unsupervised learning of syntactic structure.",6 Conclusion,[0],[0]
Experiments on both POS induction and unsupervised dependency parsing tasks demonstrate the effectiveness of our proposed approach.,6 Conclusion,[0],[0]
"Future work might explore more sophisticated invertible projections, or recurrent projections that jointly transform the entire input sequence.",6 Conclusion,[0],[0]
Unsupervised learning of syntactic structure is typically performed using generative models with discrete latent variables and multinomial parameters.,abstractText,[0],[0]
"In most cases, these models have not leveraged continuous word representations.",abstractText,[0],[0]
"In this work, we propose a novel generative model that jointly learns discrete syntactic structure and continuous word representations in an unsupervised fashion by cascading an invertible neural network with a structured generative prior.",abstractText,[0],[0]
We show that the invertibility condition allows for efficient exact inference and marginal likelihood computation in our model so long as the prior is well-behaved.,abstractText,[0],[0]
"In experiments we instantiate our approach with both Markov and tree-structured priors, evaluating on two tasks: part-of-speech (POS) induction, and unsupervised dependency parsing without gold POS annotation.",abstractText,[0],[0]
"On the Penn Treebank, our Markov-structured model surpasses state-of-the-art results on POS induction.",abstractText,[0],[0]
"Similarly, we find that our tree-structured model achieves state-of-the-art performance on unsupervised dependency parsing for the difficult training condition where neither gold POS annotation nor punctuation-based constraints are available.1",abstractText,[0],[0]
Unsupervised Learning of Syntactic Structure with Invertible Neural Projections,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 46–55 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
46",text,[0],[0]
"Neural machine translation (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2014), directly applying a single neural network to transform the source sentence into the target sentence, has now reached impressive performance (Shen et al., 2015; Wu et al., 2016; Johnson et al., 2016; Gehring et al., 2017; Vaswani et al., 2017).",1 Introduction,[0],[0]
The NMT typically consists of two sub neural networks.,1 Introduction,[0],[0]
"The encoder network reads and encodes the source sentence into a
1Feng Wang is the corresponding author of this paper
context vector, and the decoder network generates the target sentence iteratively based on the context vector.",1 Introduction,[0],[0]
NMT can be studied in supervised and unsupervised learning settings.,1 Introduction,[0],[0]
"In the supervised setting, bilingual corpora is available for training the NMT model.",1 Introduction,[0],[0]
"In the unsupervised setting, we only have two independent monolingual corpora with one for each language and there is no bilingual training example to provide alignment information for the two languages.",1 Introduction,[0],[0]
"Due to lack of alignment information, the unsupervised NMT is considered more challenging.",1 Introduction,[0],[0]
"However, this task is very promising, since the monolingual corpora is usually easy to be collected.
",1 Introduction,[0],[0]
"Motivated by recent success in unsupervised cross-lingual embeddings (Artetxe et al., 2016; Zhang et al., 2017b; Conneau et al., 2017), the models proposed for unsupervised NMT often assume that a pair of sentences from two different languages can be mapped to a same latent representation in a shared-latent space (Lample et al., 2017; Artetxe et al., 2017b).",1 Introduction,[0],[0]
"Following this assumption, Lample et al. (2017) use a single encoder and a single decoder for both the source and target languages.",1 Introduction,[0],[0]
"The encoder and decoder, acting as a standard auto-encoder (AE), are trained to reconstruct the inputs.",1 Introduction,[0],[0]
And Artetxe et al. (2017b) utilize a shared encoder but two independent decoders.,1 Introduction,[0],[0]
"With some good performance, they share a glaring defect, i.e., only one encoder is shared by the source and target languages.",1 Introduction,[0],[0]
"Although the shared encoder is vital for mapping sentences from different languages into the shared-latent space, it is weak in keeping the uniqueness and internal characteristics of each language, such as the style, terminology and sentence structure.",1 Introduction,[0],[0]
"Since each language has its own characteristics, the source and target languages should be encoded and learned independently.",1 Introduction,[0],[0]
"Therefore, we conjecture that the shared encoder may be a factor limit-
ing the potential translation performance.",1 Introduction,[0],[0]
"In order to address this issue, we extend the encoder-shared model, i.e., the model with one shared encoder, by leveraging two independent encoders with each for one language.",1 Introduction,[0],[0]
"Similarly, two independent decoders are utilized.",1 Introduction,[0],[0]
"For each language, the encoder and its corresponding decoder perform an AE, where the encoder generates the latent representations from the perturbed input sentences and the decoder reconstructs the sentences from the latent representations.",1 Introduction,[0],[0]
"To map the latent representations from different languages to a shared-latent space, we propose the weightsharing constraint to the two AEs.",1 Introduction,[0],[0]
"Specifically, we share the weights of the last few layers of two encoders that are responsible for extracting highlevel representations of input sentences.",1 Introduction,[0],[0]
"Similarly, we share the weights of the first few layers of two decoders.",1 Introduction,[0],[0]
"To enforce the shared-latent space, the word embeddings are used as a reinforced encoding component in our encoders.",1 Introduction,[0],[0]
"For cross-language translation, we utilize the backtranslation following (Lample et al., 2017).",1 Introduction,[0],[0]
"Additionally, two different generative adversarial networks (GAN) (Yang et al., 2017), namely the local and global GAN, are proposed to further improve the cross-language translation.",1 Introduction,[0],[0]
"We utilize the local GAN to constrain the source and target latent representations to have the same distribution, whereby the encoder tries to fool a local discriminator which is simultaneously trained to distinguish the language of a given latent representation.",1 Introduction,[0],[0]
"We apply the global GAN to finetune the corresponding generator, i.e., the composition of the encoder and decoder of the other language, where a global discriminator is leveraged to guide the training of the generator by assessing how far the generated sentence is from the true data distribution 1.",1 Introduction,[0],[0]
"In summary, we mainly make the following contributions:
• We propose the weight-sharing constraint to unsupervised NMT, enabling the model to utilize an independent encoder for each language.",1 Introduction,[0],[0]
"To enforce the shared-latent space, we also propose the embedding-reinforced encoders and two different GANs for our model.
",1 Introduction,[0],[0]
"• We conduct extensive experiments on 1The code that we utilized to train and evaluate our models can be found at https://github.com/ZhenYangIACAS/unsupervised-NMT
English-German, English-French and Chinese-to-English translation tasks.",1 Introduction,[0],[0]
"Experimental results show that the proposed approach consistently achieves great success.
",1 Introduction,[0],[0]
"• Last but not least, we introduce the directional self-attention to model temporal order information for the proposed model.",1 Introduction,[0],[0]
Experimental results reveal that it deserves more efforts for researchers to investigate the temporal order information within self-attention layers of NMT.,1 Introduction,[0],[0]
Several approaches have been proposed to train NMT models without direct parallel corpora.,2 Related Work,[0],[0]
The scenario that has been widely investigated is one where two languages have little parallel data between them but are well connected by one pivot language.,2 Related Work,[0],[0]
"The most typical approach in this scenario is to independently translate from the source language to the pivot language and from the pivot language to the target language (Saha et al., 2016; Cheng et al., 2017).",2 Related Work,[0],[0]
"To improve the translation performance, Johnson et al. (2016) propose a multilingual extension of a standard NMT model and they achieve substantial improvement for language pairs without direct parallel training data.
",2 Related Work,[0],[0]
"Recently, motivated by the success of crosslingual embeddings, researchers begin to show interests in exploring the more ambitious scenario where an NMT model is trained from monolingual corpora only.",2 Related Work,[0],[0]
"Lample et al. (2017) and Artetxe et al. (2017b) simultaneously propose an approach for this scenario, which is based on pre-trained cross lingual embeddings.",2 Related Work,[0],[0]
Lample et al. (2017) utilizes a single encoder and a single decoder for both languages.,2 Related Work,[0],[0]
The entire system is trained to reconstruct its perturbed input.,2 Related Work,[0],[0]
"For cross-lingual translation, they incorporate back-translation into the training procedure.",2 Related Work,[0],[0]
"Different from (Lample et al., 2017), Artetxe et al. (2017b) use two independent decoders with each for one language.",2 Related Work,[0],[0]
The two works mentioned above both use a single shared encoder to guarantee the shared latent space.,2 Related Work,[0],[0]
"However, a concomitant defect is that the shared encoder is weak in keeping the uniqueness of each language.",2 Related Work,[0],[0]
"Our work also belongs to this more ambitious scenario, and to the best of our knowledge, we are one among the first endeavors to investigate how to train an NMT model with monolingual corpora only.
",2 Related Work,[0],[0]
t are self-reconstructed sentences in each language.,2 Related Work,[0],[0]
"x̃
Encs−Dect
s is
the translated sentence from source to target and x̃Enct−Decst is the translation in reversed direction.
",2 Related Work,[0],[0]
Dl is utilized to assess whether the hidden representation of the encoder is from the source or target language.,2 Related Work,[0],[0]
Dg1 and Dg2 are used to evaluate whether the translated sentences are realistic for each language respectively.,2 Related Work,[0],[0]
Z represents the shared-latent space.,2 Related Work,[0],[0]
"The model architecture, as illustrated in figure 1, is based on the AE and GAN.",3.1 Model Architecture,[0],[0]
"It consists of seven sub networks: including two encoders Encs and Enct, two decoders Decs and Dect, the local discriminator Dl, and the global discriminators Dg1 and Dg2.",3.1 Model Architecture,[0],[0]
"For the encoder and decoder, we follow the newly emerged Transformer (Vaswani et al., 2017).",3.1 Model Architecture,[0],[0]
"Specifically, the encoder is composed of a stack of four identical layers 2.",3.1 Model Architecture,[0],[0]
Each layer consists of a multi-head self-attention and a simple position-wise fully connected feed-forward network.,3.1 Model Architecture,[0],[0]
The decoder is also composed of four identical layers.,3.1 Model Architecture,[0],[0]
"In addition to the two sub-layers in each encoder layer, the decoder inserts a third sublayer, which performs multi-head attention over the output of the encoder stack.",3.1 Model Architecture,[0],[0]
"For more details about the multi-head self-attention layer, we refer the reader to (Vaswani et al., 2017).",3.1 Model Architecture,[0],[0]
We implement the local discriminator as a multi-layer perceptron and implement the global discriminator based on the convolutional neural network (CNN).,3.1 Model Architecture,[0],[0]
Several ways exist to interpret the roles of the sub networks are summarised in table 1.,3.1 Model Architecture,[0],[0]
"The proposed system has several striking components , which are critical either for the system to be trained in an unsu-
2The layer number is selected according to our preliminary experiment, which is presented in appendix ??.
pervised manner or for improving the translation performance.
",3.1 Model Architecture,[0],[0]
Directional self-attention,3.1 Model Architecture,[0],[0]
"Compared to recurrent neural network, a disadvantage of the simple self-attention mechanism is that the temporal order information is lost.",3.1 Model Architecture,[0],[0]
"Although the Transformer applies the positional encoding to the sequence before processed by the self-attention, how to model temporal order information within an attention is still an open question.",3.1 Model Architecture,[0],[0]
"Following (Shen et al., 2017), we build the encoders in our model on the directional self-attention which utilizes the positional masks to encode temporal order information into attention output.",3.1 Model Architecture,[0],[0]
"More concretely, two positional masks, namely the forward mask Mf and
backward mask M b, are calculated as:
Mfij =
{ 0 i < j
−∞ otherwise (1)
M bij =
{ 0",3.1 Model Architecture,[0],[0]
"i > j
−∞ otherwise (2)
",3.1 Model Architecture,[0],[0]
"With the forward mask Mf , the later token only makes attention connections to the early tokens in the sequence, and vice versa with the backward mask.",3.1 Model Architecture,[0],[0]
"Similar to (Zhou et al., 2016; Wang et al., 2017), we utilize a self-attention network to process the input sequence in forward direction.",3.1 Model Architecture,[0],[0]
"The output of this layer is taken by an upper self-attention network as input, processed in the reverse direction.
",3.1 Model Architecture,[0],[0]
Weight sharing,3.1 Model Architecture,[0],[0]
"Based on the shared-latent space assumption, we apply the weight sharing constraint to relate the two AEs.",3.1 Model Architecture,[0],[0]
"Specifically, we share the weights of the last few layers of the Encs and Enct, which are responsible for extracting high-level representations of the input sentences.",3.1 Model Architecture,[0],[0]
"Similarly, we also share the first few layers of the Decs and Dect, which are expected to decode high-level representations that are vital for reconstructing the input sentences.",3.1 Model Architecture,[0],[0]
"Compared to (Cheng et al., 2016; Saha et al., 2016) which use the fully shared encoder, we only share partial weights for the encoders and decoders.",3.1 Model Architecture,[0],[0]
"In the proposed model, the independent weights of the two encoders are expected to learn and encode the hidden features about the internal characteristics of each language, such as the terminology, style, and sentence structure.",3.1 Model Architecture,[0],[0]
"The shared weights are utilized to map the hidden features extracted by the independent weights to the shared-latent space.
",3.1 Model Architecture,[0],[0]
Embedding reinforced encoder We use pretrained cross-lingual embeddings in the encoders that are kept fixed during training.,3.1 Model Architecture,[0],[0]
And the fixed embeddings are used as a reinforced encoding component in our encoder.,3.1 Model Architecture,[0],[0]
"Formally, given the input sequence embedding vectors E = {e1, . . .",3.1 Model Architecture,[0],[0]
", et} and the initial output sequence of the encoder stack H = {h1, . . .",3.1 Model Architecture,[0],[0]
", ht}, we compute Hr as: Hr = g H + (1− g) E (3) where Hr is the final output sequence of the encoder which will be attended by the decoder (In Transformer, H is the final output of the encoder), g is a gate unit and computed as:
g = σ(W1E +W2H + b) (4)
where W1, W2 and b are trainable parameters and they are shared by the two encoders.",3.1 Model Architecture,[0],[0]
The motivation behind is twofold.,3.1 Model Architecture,[0],[0]
"Firstly, taking the fixed cross-lingual embedding as the other encoding component is helpful to reinforce the sharedlatent space.",3.1 Model Architecture,[0],[0]
"Additionally, from the point of multichannel encoders (Xiong et al., 2017), providing encoding components with different levels of composition enables the decoder to take pieces of source sentence at varying composition levels suiting its own linguistic structure.",3.1 Model Architecture,[0],[0]
"Based on the architecture proposed above, we train the NMT model with the monolingual corpora only using the following four strategies:
Denoising auto-encoding Firstly, we train the two AEs to reconstruct their inputs respectively.",3.2 Unsupervised Training,[0],[0]
"In this form, each encoder should learn to compose the embeddings of its corresponding language and each decoder is expected to learn to decompose this representation into its corresponding language.",3.2 Unsupervised Training,[0],[0]
"Nevertheless, without any constraint, the AE quickly learns to merely copy every word one by one, without capturing any internal structure of the language involved.",3.2 Unsupervised Training,[0],[0]
"To address this problem, we utilize the same strategy of denoising AE (Vincent et al., 2008) and add some noise to the input sentences (Hill et al., 2016; Artetxe et al., 2017b).",3.2 Unsupervised Training,[0],[0]
"To this end, we shuffle the input sentences randomly.",3.2 Unsupervised Training,[0],[0]
"Specifically, we apply a random permutation ε to the input sentence, verifying the condition:
|ε(i)− i| ≤ min(k([steps s ] + 1), n), ∀i ∈ {1, n} (5) where n is the length of the input sentence, steps is the global steps the model has been updated, k and s are the tunable parameters which can be set by users beforehand.",3.2 Unsupervised Training,[0],[0]
"This way, the system needs to learn some useful structure of the involved languages to be able to recover the correct word order.",3.2 Unsupervised Training,[0],[0]
"In practice, we set k = 2 and s = 100000.
",3.2 Unsupervised Training,[0],[0]
"Back-translation In spite of denoising autoencoding, the training procedure still involves a single language at each time, without considering our final goal of mapping an input sentence from the source/target language to the target/source language.",3.2 Unsupervised Training,[0],[0]
"For the cross language training, we utilize the back-translation approach for our unsupervised training procedure.",3.2 Unsupervised Training,[0],[0]
"Back-translation has shown its great effectiveness on improving NMT
model with monolingual data and has been widely investigated by (Sennrich et al., 2015a; Zhang and Zong, 2016).",3.2 Unsupervised Training,[0],[0]
"In our approach, given an input sentence in a given language, we apply the corresponding encoder and the decoder of the other language to translate it to the other language 3.",3.2 Unsupervised Training,[0],[0]
"By combining the translation with its original sentence, we get a pseudo-parallel corpus which is utilized to train the model to reconstruct the original sentence from its translation.
",3.2 Unsupervised Training,[0],[0]
Local GAN,3.2 Unsupervised Training,[0],[0]
"Although the weight sharing constraint is vital for the shared-latent space assumption, it alone does not guarantee that the corresponding sentences in two languages will have the same or similar latent code.",3.2 Unsupervised Training,[0],[0]
"To further enforce the shared-latent space, we train a discriminative neural network, referred to as the local discriminator, to classify between the encoding of source sentences and the encoding of target sentences.",3.2 Unsupervised Training,[0],[0]
"The local discriminator, implemented as a multilayer perceptron with two hidden layers of size 256, takes the output of the encoder, i.e., Hr calculated as equation 3, as input, and produces a binary prediction about the language of the input sentence.",3.2 Unsupervised Training,[0],[0]
"The local discriminator is trained to predict the language by minimizing the following crossentropy loss:
LDl(θDl) =
− Ex∈xs",3.2 Unsupervised Training,[0],[0]
[log p(f = s|Encs(x))],3.2 Unsupervised Training,[0],[0]
− Ex∈xt,3.2 Unsupervised Training,[0],[0]
[log p(f = t|Enct(x)),3.2 Unsupervised Training,[0],[0]
"]
(6)
where θDl represents the parameters of the local discriminator and f ∈ {s, t}.",3.2 Unsupervised Training,[0],[0]
"The encoders are trained to fool the local discriminator:
LEncs(θEncs) =
− Ex∈xs",3.2 Unsupervised Training,[0],[0]
[log p(f = t|Encs(x))],3.2 Unsupervised Training,[0],[0]
"(7)
LEnct(θEnct) =
− Ex∈xt",3.2 Unsupervised Training,[0],[0]
[log p(f = s|Enct(x))],3.2 Unsupervised Training,[0],[0]
"(8)
where θEncs and θEnct are the parameters of the two encoders.
",3.2 Unsupervised Training,[0],[0]
"Global GAN We apply the global GANs to fine tune the whole model so that the model is able to generate sentences undistinguishable from the true data, i.e., sentences in the training corpus.",3.2 Unsupervised Training,[0],[0]
"Different from the local GANs which updates the parameters of the encoders locally, the global GANs are
3Since the quality of the translation shows little effect on the performance of the model (Sennrich et al., 2015a), we simply use greedy decoding for speed.
utilized to update the whole parameters of the proposed model, including the parameters of encoders and decoders.",3.2 Unsupervised Training,[0],[0]
The proposed model has two global GANs: GANg1 and GANg2.,3.2 Unsupervised Training,[0],[0]
"In GANg1, the Enct and Decs act as the generator, which generates the sentence x̃t 4 from xt.",3.2 Unsupervised Training,[0],[0]
"The Dg1, implemented based on CNN, assesses whether the generated sentence x̃t is the true target-language sentence or the generated sentence.",3.2 Unsupervised Training,[0],[0]
"The global discriminator aims to distinguish among the true sentences and generated sentences, and it is trained to minimize its classification error rate.",3.2 Unsupervised Training,[0],[0]
"During training, the Dg1 feeds back its assessment to finetune the encoder Enct and decoder Decs.",3.2 Unsupervised Training,[0],[0]
"Since the machine translation is a sequence generation problem, following (Yang et al., 2017), we leverage policy gradient reinforcement training to back-propagate the assessment.",3.2 Unsupervised Training,[0],[0]
We apply a similar processing to GANg2 (The details about the architecture of the global discriminator and the training procedure of the global GANs can be seen in appendix ??,3.2 Unsupervised Training,[0],[0]
"and ??).
",3.2 Unsupervised Training,[0],[0]
There are two stages in the proposed unsupervised training.,3.2 Unsupervised Training,[0],[0]
"In the first stage, we train the proposed model with denoising auto-encoding, backtranslation and the local GANs, until no improvement is achieved on the development set.",3.2 Unsupervised Training,[0],[0]
"Specifically, we perform one batch of denoising autoencoding for the source and target languages, one batch of back-translation for the two languages, and another batch of local GAN for the two languages.",3.2 Unsupervised Training,[0],[0]
"In the second stage, we fine tune the proposed model with the global GANs.",3.2 Unsupervised Training,[0],[0]
"We evaluate the proposed approach on EnglishGerman, English-French and Chinese-to-English translation tasks 5.",4 Experiments and Results,[0],[0]
"We firstly describe the datasets, pre-processing and model hyper-parameters we used, then we introduce the baseline systems, and finally we present our experimental results.",4 Experiments and Results,[0],[0]
"In English-German and English-French translation, we make our experiments comparable with previous work by using the datasets from the
4The x̃t is x̃Enct−Decst in figure 1.",4.1 Data Sets and Preprocessing,[0],[0]
"We omit the superscript for simplicity.
",4.1 Data Sets and Preprocessing,[0],[0]
"5The reason that we do not conduct experiments on English-to-Chinese translation is that we do not get public test sets for English-to-Chinese.
",4.1 Data Sets and Preprocessing,[0],[0]
WMT 2014 and WMT 2016 shared tasks respectively.,4.1 Data Sets and Preprocessing,[0],[0]
"For Chinese-to-English translation, we use the datasets from LDC, which has been widely utilized by previous works (Tu et al., 2017; Zhang et al., 2017a).
",4.1 Data Sets and Preprocessing,[0],[0]
"WMT14 English-French Similar to (Lample et al., 2017), we use the full training set of 36M sentence pairs and we lower-case them and remove sentences longer than 50 words, resulting in a parallel corpus of about 30M pairs of sentences.",4.1 Data Sets and Preprocessing,[0],[0]
"To guarantee no exact correspondence between the source and target monolingual sets, we build monolingual corpora by selecting English sentences from 15M random pairs, and selecting the French sentences from the complementary set.",4.1 Data Sets and Preprocessing,[0],[0]
"Sentences are encoded with byte-pair encoding (Sennrich et al., 2015b), which has an English vocabulary of about 32000 tokens, and French vocabulary of about 33000 tokens.",4.1 Data Sets and Preprocessing,[0],[0]
"We report results on newstest2014.
",4.1 Data Sets and Preprocessing,[0],[0]
"WMT16 English-German We follow the same procedure mentioned above to create monolingual training corpora for English-German translation, and we get two monolingual training data of 1.8M sentences each.",4.1 Data Sets and Preprocessing,[0],[0]
The two languages share a vocabulary of about 32000 tokens.,4.1 Data Sets and Preprocessing,[0],[0]
"We report results on newstest2016.
",4.1 Data Sets and Preprocessing,[0],[0]
"LDC Chinese-English For Chinese-to-English translation, our training data consists of 1.6M sentence pairs randomly extracted from LDC corpora 6.",4.1 Data Sets and Preprocessing,[0],[0]
"Since the data set is not big enough, we just build the monolingual data set by randomly shuffling the Chinese and English sentences respectively.",4.1 Data Sets and Preprocessing,[0],[0]
"In spite of the fact that some correspondence between examples in these two monolingual sets may exist, we never utilize this alignment information in our training procedure (see Section 3.2).",4.1 Data Sets and Preprocessing,[0],[0]
Both the Chinese and English sentences are encoded with byte-pair encoding.,4.1 Data Sets and Preprocessing,[0],[0]
"We get an English vocabulary of about 34000 tokens, and Chinese vocabulary of about 38000 tokens.",4.1 Data Sets and Preprocessing,[0],[0]
"The results are reported on NIST02.
",4.1 Data Sets and Preprocessing,[0],[0]
"Since the proposed system relies on the pretrained cross-lingual embeddings, we utilize the monolingual corpora described above to train the embeddings for each language independently by using word2vec (Mikolov et al., 2013).",4.1 Data Sets and Preprocessing,[0],[0]
"We then apply the public implementation 7 of the method proposed by (Artetxe et al., 2017a) to map these
6LDC2002L27, LDC2002T01, LDC2002E18, LDC2003E07, LDC2004T08, LDC2004E12, LDC2005T10
7https://github.com/artetxem/vecmap
embeddings to a shared-latent space 8.",4.1 Data Sets and Preprocessing,[0],[0]
"Following the base model in (Vaswani et al., 2017), we set the dimension of word embedding as 512, dropout rate as 0.1 and the head number as 8.",4.2 Model Hyper-parameters and Evaluation,[0],[0]
We use beam search with a beam size of 4 and length penalty α = 0.6.,4.2 Model Hyper-parameters and Evaluation,[0],[0]
"The model is implemented in TensorFlow (Abadi et al., 2015) and trained on up to four K80 GPUs synchronously in a multi-GPU setup on a single machine.
",4.2 Model Hyper-parameters and Evaluation,[0],[0]
"For model selection, we stop training when the model achieves no improvement for the tenth evaluation on the development set, which is comprised of 3000 source and target sentences extracted randomly from the monolingual training corpora.",4.2 Model Hyper-parameters and Evaluation,[0],[0]
"Following (Lample et al., 2017), we translate the source sentences to the target language, and then translate the resulting sentences back to the source language.",4.2 Model Hyper-parameters and Evaluation,[0],[0]
The quality of the model is then evaluated by computing the BLEU score over the original inputs and their reconstructions via this two-step translation process.,4.2 Model Hyper-parameters and Evaluation,[0],[0]
"The performance is finally averaged over two directions, i.e., from source to target and from target to source.",4.2 Model Hyper-parameters and Evaluation,[0],[0]
"BLEU (Papineni et al., 2002) is utilized as the evaluation metric.",4.2 Model Hyper-parameters and Evaluation,[0],[0]
"For Chinese-to-English, we apply the script mteval-v11b.pl to evaluate the translation performance.",4.2 Model Hyper-parameters and Evaluation,[0],[0]
"For English-German and English-French, we evaluate the translation performance with the script multi-belu.pl 9.",4.2 Model Hyper-parameters and Evaluation,[0],[0]
Word-by-word translation (WBW),4.3 Baseline Systems,[0],[0]
The first baseline we consider is a system that performs word-by-word translations using the inferred bilingual dictionary.,4.3 Baseline Systems,[0],[0]
"Specifically, it translates a sentence word-by-word, replacing each word with its nearest neighbor in the other language.
",4.3 Baseline Systems,[0],[0]
Lample et al. (2017),4.3 Baseline Systems,[0],[0]
The second baseline is a previous work that uses the same training and testing sets with this paper.,4.3 Baseline Systems,[0],[0]
"Their model belongs to the standard attention-based encoder-decoder framework, which implements the encoder using a bidirectional long short term memory network (LSTM) and implements the decoder using a simple forward LSTM.",4.3 Baseline Systems,[0],[0]
"They apply one single encoder and
8The configuration we used to run these open-source toolkits can be found in appendix ??
",4.3 Baseline Systems,[0],[0]
"9https://github.com/mosessmt/mosesdecoder/blob/617e8c8/scripts/generic/multibleu.perl;mteval-v11b.pl
decoder for the source and target languages.",4.3 Baseline Systems,[0],[0]
"Supervised training We finally consider exactly the same model as ours, but trained using the standard cross-entropy loss on the original parallel sentences.",4.3 Baseline Systems,[0],[0]
This model can be viewed as an upper bound for the proposed unsupervised model.,4.3 Baseline Systems,[0],[0]
We firstly investigate how the number of weightsharing layers affects the translation performance.,4.4.1 Number of weight-sharing layers,[0],[0]
"In this experiment, we vary the number of weightsharing layers in the AEs from 0 to 4.",4.4.1 Number of weight-sharing layers,[0],[0]
"Sharing one layer in AEs means sharing one layer for the encoders and in the meanwhile, sharing one layer for the decoders.",4.4.1 Number of weight-sharing layers,[0],[0]
"The BLEU scores of English-to-German, English-to-French and Chinese-to-English translation tasks are reported in figure 2.",4.4.1 Number of weight-sharing layers,[0],[0]
Each curve corresponds to a different translation task and the x-axis denotes the number of weight-sharing layers for the AEs.,4.4.1 Number of weight-sharing layers,[0],[0]
We find that the number of weight-sharing layers shows much effect on the translation performance.,4.4.1 Number of weight-sharing layers,[0],[0]
And the best translation performance is achieved when only one layer is shared in our system.,4.4.1 Number of weight-sharing layers,[0],[0]
"When all of the four layers are shared, i.e., only one shared encoder is utilized, we get poor translation performance in all of the three translation tasks.",4.4.1 Number of weight-sharing layers,[0],[0]
This verifies our conjecture that the shared encoder is detrimental to the performance of unsupervised NMT especially for the translation tasks on distant language pairs.,4.4.1 Number of weight-sharing layers,[0],[0]
"More concretely, for the related language pair translation, i.e., English-toFrench, the encoder-shared model achieves -0.53 BLEU points decline than the best model where only one layer is shared.",4.4.1 Number of weight-sharing layers,[0],[0]
"For the more distant language pair English-to-German, the encoder-shared model achieves more significant decline, i.e., -0.85 BLEU points decline.",4.4.1 Number of weight-sharing layers,[0],[0]
"And for the most distant language pair Chinese-to-English, the decline is
as large as -1.66 BLEU points.",4.4.1 Number of weight-sharing layers,[0],[0]
"We explain this as that the more distant the language pair is, the more different characteristics they have.",4.4.1 Number of weight-sharing layers,[0],[0]
And the shared encoder is weak in keeping the unique characteristic of each language.,4.4.1 Number of weight-sharing layers,[0],[0]
"Additionally, we also notice that using two completely independent encoders, i.e., setting the number of weight-sharing layers as 0, results in poor translation performance too.",4.4.1 Number of weight-sharing layers,[0],[0]
This confirms our intuition that the shared layers are vital to map the source and target latent representations to a shared-latent space.,4.4.1 Number of weight-sharing layers,[0],[0]
"In the rest of our experiments, we set the number of weightsharing layer as 1.",4.4.1 Number of weight-sharing layers,[0],[0]
"Table 2 shows the BLEU scores on EnglishGerman, English-French and English-to-Chinese test sets.",4.4.2 Translation results,[0],[0]
"As it can be seen, the proposed approach obtains significant improvements than the word-by-word baseline system, with at least +5.01 BLEU points in English-to-German translation and up to +13.37 BLEU points in English-toFrench translation.",4.4.2 Translation results,[0],[0]
"This shows that the proposed model only trained with monolingual data effec-
tively learns to use the context information and the internal structure of each language.",4.4.2 Translation results,[0],[0]
"Compared to the work of (Lample et al., 2017), our model also achieves up to +1.92 BLEU points improvement on English-to-French translation task.",4.4.2 Translation results,[0],[0]
We believe that the unsupervised NMT is very promising.,4.4.2 Translation results,[0],[0]
"However, there is still a large room for improvement compared to the supervised upper bound.",4.4.2 Translation results,[0],[0]
The gap between the supervised and unsupervised model is as large as 12.3-25.5 BLEU points depending on the language pair and translation direction.,4.4.2 Translation results,[0],[0]
"To understand the importance of different components of the proposed system, we perform an ablation study by training multiple versions of our model with some missing components: the local GANs, the global GANs, the directional self-attention, the weight-sharing, the embeddingreinforced encoders, etc.",4.4.3 Ablation study,[0],[0]
Results are reported in table 3.,4.4.3 Ablation study,[0],[0]
"We do not test the the importance of the auto-encoding, back-translation and the pretrained embeddings because they have been widely tested in (Lample et al., 2017; Artetxe et al., 2017b).",4.4.3 Ablation study,[0],[0]
Table 3 shows that the best performance is obtained with the simultaneous use of all the tested elements.,4.4.3 Ablation study,[0],[0]
"The most critical component is the weight-sharing constraint, which is vital to map sentences of different languages to the sharedlatent space.",4.4.3 Ablation study,[0],[0]
The embedding-reinforced encoder also brings some improvement on all of the translation tasks.,4.4.3 Ablation study,[0],[0]
"When we remove the directional selfattention, we get up to -0.3 BLEU points decline.",4.4.3 Ablation study,[0],[0]
This indicates that it deserves more efforts to investigate the temporal order information in selfattention mechanism.,4.4.3 Ablation study,[0],[0]
The GANs also significantly improve the translation performance of our system.,4.4.3 Ablation study,[0],[0]
"Specifically, the global GANs achieve improvement up to +0.78 BLEU points on English-
to-French translation and the local GANs also obtain improvement up to +0.57 BLEU points on English-to-French translation.",4.4.3 Ablation study,[0],[0]
This reveals that the proposed model benefits a lot from the crossdomain loss defined by GANs.,4.4.3 Ablation study,[0],[0]
The models proposed recently for unsupervised NMT use a single encoder to map sentences from different languages to a shared-latent space.,5 Conclusion and Future work,[0],[0]
We conjecture that the shared encoder is problematic for keeping the unique and inherent characteristic of each language.,5 Conclusion and Future work,[0],[0]
"In this paper, we propose the weight-sharing constraint in unsupervised NMT to address this issue.",5 Conclusion and Future work,[0],[0]
"To enhance the cross-language translation performance, we also propose the embedding-reinforced encoders, local GAN and global GAN into the proposed system.",5 Conclusion and Future work,[0],[0]
"Additionally, the directional self-attention is introduced to model the temporal order information for our system.
",5 Conclusion and Future work,[0],[0]
"We test the proposed model on EnglishGerman, English-French and Chinese-to-English translation tasks.",5 Conclusion and Future work,[0],[0]
The experimental results reveal that our approach achieves significant improvement and verify our conjecture that the shared encoder is really a bottleneck for improving the unsupervised NMT.,5 Conclusion and Future work,[0],[0]
"The ablation study shows that each component of our system achieves some improvement for the final translation performance.
",5 Conclusion and Future work,[0],[0]
Unsupervised NMT opens exciting opportunities for the future research.,5 Conclusion and Future work,[0],[0]
"However, there is still a large room for improvement compared to the supervised NMT.",5 Conclusion and Future work,[0],[0]
"In the future, we would like to investigate how to utilize the monolingual data more effectively, such as incorporating the language model and syntactic information into unsupervised NMT.",5 Conclusion and Future work,[0],[0]
"Besides, we decide to make more efforts to explore how to reinforce the temporal or-
der information for the proposed model.",5 Conclusion and Future work,[0],[0]
"This work is supported by the National Key Research and Development Program of China under Grant No. 2017YFB1002102, and Beijing Engineering Research Center under Grant No. Z171100002217015.",Acknowledgements,[0],[0]
We would like to thank Xu Shuang for her preparing data used in this work.,Acknowledgements,[0],[0]
"Additionally, we also want to thank Jiaming Xu, Suncong Zheng and Wenfu Wang for their invaluable discussions on this work.",Acknowledgements,[0],[0]
Unsupervised neural machine translation (NMT) is a recently proposed approach for machine translation which aims to train the model without using any labeled data.,abstractText,[0],[0]
"The models proposed for unsupervised NMT often use only one shared encoder to map the pairs of sentences from different languages to a shared-latent space, which is weak in keeping the unique and internal characteristics of each language, such as the style, terminology, and sentence structure.",abstractText,[0],[0]
"To address this issue, we introduce an extension by utilizing two independent encoders but sharing some partial weights which are responsible for extracting high-level representations of the input sentences.",abstractText,[0],[0]
"Besides, two different generative adversarial networks (GANs), namely the local GAN and global GAN, are proposed to enhance the cross-language translation.",abstractText,[0],[0]
"With this new approach, we achieve significant improvements on English-German, EnglishFrench and Chinese-to-English translation tasks.",abstractText,[0],[0]
Unsupervised Neural Machine Translation with Weight Sharing,title,[0],[0]
"Machine translation (MT) systems usually require a large amount of bilingual data, produced by humans, as supervision for training.",1 Introduction,[0],[0]
"However, finding such data remains challenging for most language pairs, as it may not exist or may be too costly to manually produce.
",1 Introduction,[0],[0]
"In contrast, a large amount of monolingual data can be easily collected for many languages, for instance from the Web.1 Previous work proposed many ways for taking advantage of the monolingual data in order to improve translation models trained on bilingual data.",1 Introduction,[0],[0]
"These methods usually exploit existing accurate translation models and have shown to be useful especially when targeting
1See for instance the Common Crawl project: http:// commoncrawl.org/
low-resource language pairs and domains.",1 Introduction,[0],[0]
"However, they usually fail when the available bilingual data is too noisy or too small to train useful translation models.",1 Introduction,[0],[0]
"In such scenarios, the use of pivot languages or unsupervised machine translation are possible alternatives.
",1 Introduction,[0],[0]
Recent work has shown remarkable results in training MT systems using only monolingual data in the source and target languages.,1 Introduction,[0],[0]
"Unsupervised statistical (USMT) and neural (UNMT) machine translation have been proposed (Artetxe et al., 2018b; Lample et al., 2018b).",1 Introduction,[0],[0]
"State-of-theart USMT (Artetxe et al., 2018b; Lample et al., 2018b) uses a phrase table induced from source and target phrases, extracted from the monolingual data, paired and scored using bilingual word, or n-gram, embeddings trained without supervision.",1 Introduction,[0],[0]
"This phrase table is plugged in a standard phrasebased SMT framework that is used to translate target monolingual data into the source language, i.e., performing a so-called back-translation.",1 Introduction,[0],[0]
The translated target sentences and their translations in the source language are paired to form synthetic parallel data and to train a source-to-target USMT system.,1 Introduction,[0],[0]
"This back-translation/re-training step is repeated for several iterations to refine the translation model of the system.2 On the other hand, state-of-the-art UNMT (Lample et al., 2018b) uses bilingual sub-word embeddings.",1 Introduction,[0],[0]
"They are trained on the concatenation of source and target monolingual data in which tokens have been segmented into sub-word units using, for instance, byte-pairencoding (BPE) (Sennrich et al., 2016b).",1 Introduction,[0],[0]
This method can learn bilingual embeddings if the source and target languages have in common some sub-word units.,1 Introduction,[0],[0]
The sub-word embeddings are then used to initialize the lookup tables in the encoder and decoder of the UNMT system.,1 Introduction,[0],[0]
"Follow-
",1 Introduction,[0],[0]
"2Previous work did not address the issue of convergence and rather fixed the number of iterations to perform for these refinement steps.
",1 Introduction,[0],[0]
"ar X
iv :1
81 0.
12 70
3v 1
[ cs
.C",1 Introduction,[0],[0]
"L
] 3
0",1 Introduction,[0],[0]
"O
ct 2
01 8
ing this initialization step, UNMT mainly relies on denoising autoencoder as language model during training and on latent representation shared across the source and target languages for the encoder and the decoder.
",1 Introduction,[0],[0]
"While the primary target of USMT and UNMT is low-resource language pairs, their possible applications for these language pairs remain challenging, especially for distant languages,3 and have yet to be demonstrated.",1 Introduction,[0],[0]
"On the other hand, unsupervised MT achieves impressive results on resource-rich language pairs, with recent and quick progresses, suggesting that it may become competitive, or more likely complementary, to supervised MT in the near future.
",1 Introduction,[0],[0]
"In this preliminary work, we propose a new approach for unsupervised MT to further reduce the gap between supervised and unsupervised MT.",1 Introduction,[0],[0]
Our approach exploits a new framework in which UNMT is bootstrapped by USMT and uses only synthetic parallel data as supervision for training.,1 Introduction,[0],[0]
"The main outcomes of our work are as follows:
• We propose a simplified USMT framework.",1 Introduction,[0],[0]
It is easier to set up and train.,1 Introduction,[0],[0]
"We also show that using back-translation to train USMT is not suitable and underperform.
",1 Introduction,[0],[0]
• We propose to use supervised NMT framework for the unsupervised NMT scenarios by simply replacing true parallel data with synthetic parallel data generated by USMT.,1 Introduction,[0],[0]
"This strategy enables the use of well-established NMT architectures with all their features, without assuming any relatedness between source and target languages in contrast to previous work.
",1 Introduction,[0],[0]
"• We empirically show that our framework leads to significantly better UNMT than USMT on the WMT16 German–English news translation task, for both translation directions.",1 Introduction,[0],[0]
"Since the term “unsupervised” may be misleading, we present in this section what aspects of this work are truly unsupervised.
",2 What is truly unsupervised in this paper?,[0],[0]
"3Mainly due to the difficulty of training accurate unsupervised bilingual word/sub-word embeddings for distant languages (Søgaard et al., 2018).
",2 What is truly unsupervised in this paper?,[0],[0]
"As previous work, we define “unsupervised MT” as MT that does not use human-made translation pairs as bilingual data for training.",2 What is truly unsupervised in this paper?,[0],[0]
"Nonetheless, MT still needs some supervision for training.",2 What is truly unsupervised in this paper?,[0],[0]
"Our approach uses as supervision synthetic bilingual data generated from monolingual data.
",2 What is truly unsupervised in this paper?,[0],[0]
“Unsupervised” qualifies only the training of MT systems on bilingual parallel data of which at least one side is synthetic.,2 What is truly unsupervised in this paper?,[0],[0]
"For tuning, it is arguably unsupervised in some of our experiments or supervised using a small set of human-made bilingual sentence pairs.",2 What is truly unsupervised in this paper?,[0],[0]
We discuss “unsupervised tuning” in Section 3.2.,2 What is truly unsupervised in this paper?,[0],[0]
"For evaluation, it is fully supervised, as in previous work, since we use a human-made test set to evaluate the translation quality.
",2 What is truly unsupervised in this paper?,[0],[0]
"Even if our systems are trained without humanmade bilingual data, we can still argue that the monolingual corpora used to generate synthetic parallel data have been produced by humans.",2 What is truly unsupervised in this paper?,[0],[0]
Source and target monolingual corpora in our experiments (see Section 5.1) could include some comparable parts.,2 What is truly unsupervised in this paper?,[0],[0]
"Moreover, we cannot ensure that they do not contain any human-made translations from which our systems can take advantage during training.",2 What is truly unsupervised in this paper?,[0],[0]
"Finally, we use SMT and NMT architectures, set and use their hyper-parameters (for instance, the default parameters of the Transformer model) in our framework that have already shown to give good results in supervised MT.",2 What is truly unsupervised in this paper?,[0],[0]
"Our USMT framework is based on the same architecture proposed by previous work (Artetxe et al., 2018b; Lample et al., 2018b): a phrase table is induced from monolingual data and used to compose the initial USMT system that is then refined iteratively using synthetic parallel data.",3 Simplified USMT,[0],[0]
"We propose the following improvements and discussions to simplify the framework and make it faster with lighter models (see also Figure 1):
• Section 3.1: we propose several modifications to rely more on compositional phrases and to simplify the phrase table induction compared to the method proposed by Artetxe et al. (2018b)
",3 Simplified USMT,[0],[0]
"• Section 3.2: we discuss the feasibility of unsupervised tuning.
",3 Simplified USMT,[0],[0]
"• Section 3.3: we propose to replace the backtranslation in the refinement steps with for-
ward translation to improve translation quality and to remove the need of simultaneously training models for both translation directions.
",3 Simplified USMT,[0],[0]
• Section 3.4: we propose to prune the phrase table to speed up the generation of synthetic parallel data during the refinement steps.,3 Simplified USMT,[0],[0]
"As proposed by Artetxe et al. (2018b) and Lample et al. (2018b), the first step of our approach for USMT is an unsupervised phrase table induction that only takes as inputs a set of source phrases, a set of target phrases, and their respective embeddings, as illustrated by Figure 2.",3.1 Phrase table induction,[0],[0]
"Artetxe et al. (2018b) regarded the most frequent unigrams, bigrams, and trigrams in the monolingual data as phrases.",3.1 Phrase table induction,[0],[0]
"The embedding of each n-gram is computed with a generalization of the skipgram algorithm (Mikolov et al., 2013).",3.1 Phrase table induction,[0],[0]
"Then, source and target n-gram embedding spaces are aligned in the same bilingual embedding space without supervision (Artetxe et al., 2018a).",3.1 Phrase table induction,[0],[0]
"Lample et al. (2018b)’s method also works at n-gram level, but computes phrase embeddings as proposed by Zhao et al. (2015): performing the element-wise addition of the embeddings of the
component words of the phrase, also trained on the monolingual data and aligned in the same bilingual embedding space.",3.1 Phrase table induction,[0],[0]
This method can estimate embedding for compositional phrases but not for non-compositional phrases unlike Artetxe et al. (2018b)’s method.,3.1 Phrase table induction,[0],[0]
"Interestingly, Artetxe et al. (2018b)’s method yields significantly better results at the first iteration of USMT, that uses the induced phrase table, but performs similarly to Lample et al. (2018b)’s method after several refinement steps (see Section 3.3).
",3.1 Phrase table induction,[0],[0]
We choose to build USMT with an alternative method for phrase table induction.,3.1 Phrase table induction,[0],[0]
"We adopt the method proposed by Marie and Fujita (2018), except that we remove the supervision using a bilingual word lexicon.",3.1 Phrase table induction,[0],[0]
"First, phrases are collected using the following equation (Mikolov et al., 2013):
score(wiwj) =",3.1 Phrase table induction,[0],[0]
"freq(wiwj)− δ
freq(wi)× freq(wj) , (1)
where wi and wj are two consecutive tokens or phrases in the monolingual data, freq(·) the frequency of the given token or phrase, and δ a discounting coefficient for preventing the retrieval of phrases composed of very infrequent tokens.",3.1 Phrase table induction,[0],[0]
"Consecutive tokens/phrases having a higher score than a pre-defined threshold are regarded as new phrases,4 and a new pass is performed to obtain longer phrases.",3.1 Phrase table induction,[0],[0]
"The iteration results in the collection of much longer and meaningful phrases, i.e., not only very frequent sequences of grammatical words, rather than only short n-grams.",3.1 Phrase table induction,[0],[0]
"In our experiments, we perform 6 iterations to collect phrases of up to 6 tokens.5",3.1 Phrase table induction,[0],[0]
"Equation (1) was
4This transformation is performed by simply replacing the space between the two tokens/phrases with an underscore.
",3.1 Phrase table induction,[0],[0]
"5We chose a maximum phrase length of 6, since this value
originally proposed to identify non-compositional phrases.",3.1 Phrase table induction,[0],[0]
"However, we choose to enforce the collection of more compositional phrases with a low δ6 for the following reasons:
• very few phrases are actually noncompositional in standard SMT systems (Zens et al., 2012),
• most of them are not very frequent, and • useful representation of compositional
phrases can easily be obtained compositionally (Zhao et al., 2015).
",3.1 Phrase table induction,[0],[0]
"To obtain the pairs of source and target phrases that populate the induced phrase table, we used the Equation proposed by Lample et al. (2018b):7
p(tj |si) = exp (β cos(emb(tj), emb(si)))∑ k exp (β cos(emb(tk), emb(si))) ,
(2) where tj is the j-th phrase in the target phrase list and si the i-th phrase in the source phrase list, β a parameter to tune the peakiness of the distribution8 (Smith et al., 2017), and emb(·) a function returning the bilingual embedding of a given phrase.
",3.1 Phrase table induction,[0],[0]
"In this work, for a reasonably fast computation, we retained only the 300k most frequent phrases in each language and retained for each of them the 300-best target phrases according to Equation (2).
",3.1 Phrase table induction,[0],[0]
"Standard phrase-based SMT uses the following four translation probabilities for each phrase pair.
",3.1 Phrase table induction,[0],[0]
"(a) p(tj |si): forward phrase translation probability
(b) p(si|tj): backward phrase translation probability
(c) lex(tj |si): forward lexical translation probability
(d) lex(si|tj): backward lexical translation probability
is usually used as the maximum length in most state-of-theart SMT frameworks.
",3.1 Phrase table induction,[0],[0]
6We set δ = 10 in all our experiments.,3.1 Phrase table induction,[0],[0]
7We could not obtain results similar to the results reported in Lample et al. (2018b) (the second version of their arXiv paper) by using their Equation (3) with β = 30 as they proposed.,3.1 Phrase table induction,[0],[0]
"We have confirmed through personal communications with the authors that Equation (2), as we wrote, with β = 30, generates the expected results.",3.1 Phrase table induction,[0],[0]
"We did not use the Equation computing φ in Artetxe et al. (2018b), since it produces negative value as a probability when cosine similarity is negative.
",3.1 Phrase table induction,[0],[0]
8We set β = 30 since it is the default value proposed in the code released by Smith et al. (2017): https://github.com/Babylonpartners/,3.1 Phrase table induction,[0],[0]
"fastText_multilingual
These probabilities, except (a), need to be computed only for the 300-best target phrases for each source phrase that are already determined using (a).",3.1 Phrase table induction,[0],[0]
(b) is given by switching si and tj in Equation (2).,3.1 Phrase table induction,[0],[0]
"To compute lexical translation probabilities, (c) and (d), given the significant filtering of candidate target phrases, we can adopt a more costly but better similarity score.",3.1 Phrase table induction,[0],[0]
"In this work, we compute them using word embeddings as proposed by Song and Roth (2015):
lex(tj |si) = 1
L L∏ l=1",3.1 Phrase table induction,[0],[0]
"K max k=1 p(tkj |sli) (3)
where K and L are the number of words in tj and si, respectively, and p(tkj |sli) the translation probability of the k-th target word tkj of tj given the l-th source word sli of si given by Equation (2).",3.1 Phrase table induction,[0],[0]
This phrase-level lexical translation probability is computed for both translation directions.,3.1 Phrase table induction,[0],[0]
"Note that, unlike Song and Roth (2015) and Kajiwara and Komachi (2016), we do not use a threshold value under which p(tkj |sli) is ignored, since it would require some supervised fine-tuning to be set according to the translation task.",3.1 Phrase table induction,[0],[0]
"In practice, even without this threshold value, our preliminary experiments showed significant improvements of translation quality by incorporating lex(tj |si) and lex(si|tj) into the induced phrase table.
",3.1 Phrase table induction,[0],[0]
"After the computation of the above four scores for each phrase pair in the induced phrase table, the phrase table is plugged in an SMT system to perform what we denote in the remainder of this paper as iteration 0 of USMT.
",3.1 Phrase table induction,[0],[0]
Computing lexicalized reordering models for the phrase pairs in the induced phrase table from monolingual data is feasible and helpful as shown by Klementiev et al. (2012).,3.1 Phrase table induction,[0],[0]
"However, for the sake of simplicity, we do not compute these lexical reordering models for iteration 0.",3.1 Phrase table induction,[0],[0]
"State-of-the-art supervised SMT performs the weighted log-linear combination of different models (Och and Ney, 2002).",3.2 Discussion about unsupervised tuning,[0],[0]
The model weights are tuned given a small development set of bilingual sentence pairs.,3.2 Discussion about unsupervised tuning,[0],[0]
"For completely unsupervised SMT, we cannot assume the availability of this development set.",3.2 Discussion about unsupervised tuning,[0],[0]
"In other words, model weights must be tuned without the supervision of manually produced bilingual data.
",3.2 Discussion about unsupervised tuning,[0],[0]
Lample et al. (2018b) used some pre-existing default weights that work reasonably well.,3.2 Discussion about unsupervised tuning,[0],[0]
"On the other hand, Artetxe et al. (2018b) obtained better results by using 10k monolingual sentences paired with their back-translations as a development set.",3.2 Discussion about unsupervised tuning,[0],[0]
"Nonetheless, to create this development set, they also relied on the same pre-exisintg default weights used by Lample et al. (2018b).",3.2 Discussion about unsupervised tuning,[0],[0]
"To be precise, both used the default weights of the Moses framework (Koehn et al., 2007).",3.2 Discussion about unsupervised tuning,[0],[0]
"In this preliminary work, we present results with supervised tuning and with the Moses’s default weights.
",3.2 Discussion about unsupervised tuning,[0],[0]
"However, regarding the use of default weights as “unsupervised tuning” is arguable, since these default weights have been determined manually to work well for European languages.",3.2 Discussion about unsupervised tuning,[0],[0]
"For translation between much more distant languages,9 these default weights would likely result in a very poor translation quality.",3.2 Discussion about unsupervised tuning,[0],[0]
"We argue that unsupervised tuning remains one of the main issues in current approaches for USMT.
",3.2 Discussion about unsupervised tuning,[0],[0]
"Note that while creating large training bilingual data manually for a particular language pairs is very costly, which is one of the fundamental motivations of unsupervised MT, we can assume that a small set of sentence pairs required for tuning can be created at a reasonable cost.",3.2 Discussion about unsupervised tuning,[0],[0]
Artetxe et al. (2018b) and Lample et al. (2018b) presented the same idea of performing so-called refinement steps.,3.3 Refinement without back-translation,[0],[0]
"Those steps use USMT to generate synthetic parallel data to train a new phrase table, with refined translation probabilities.",3.3 Refinement without back-translation,[0],[0]
This can be repeated for several iterations to improve USMT.,3.3 Refinement without back-translation,[0],[0]
"The initial system at iteration 0 uses the induced phrase table (see Section 3.1), while the following iterations use only a phrase table and a lexicalized reordering model trained on the synthetic parallel data generated by USMT.",3.3 Refinement without back-translation,[0],[0]
"They both fixed the number of iterations.
",3.3 Refinement without back-translation,[0],[0]
"Artetxe et al. (2018b) and Lample et al. (2018b) generated the synthetic parallel data through backtranslation: a target-to-source USMT system was used to back-translate sentences in the target language, then the pairs of each sentence in the target language and its USMT output in the source language were used as synthetic parallel data to train a new source-to-target USMT system.",3.3 Refinement without back-translation,[0],[0]
"This way
9For instance, Lample et al. (2018b) presented for Urdu– English only the results with supervised tuning.
of using back-translation has originally been proposed to improve NMT systems (Sennrich et al., 2016a) with a specific motivation to enhance the decoder by exploiting fluent sentences in the target language.",3.3 Refinement without back-translation,[0],[0]
"In contrast, however, using backtranslation for USMT lacks motivation.",3.3 Refinement without back-translation,[0],[0]
"Since the source side of the synthetic parallel data, i.e., decoded results of USMT, is not fluent, USMT will learn a phrase table with many ungrammatical source phrases, or foreign words, that will never be seen in the source language, meaning that many phrase pairs in the phrase table will never be used.",3.3 Refinement without back-translation,[0],[0]
"Moreover, possible and frequent source phrases, or even source words, may not be generated via back-translation and will be consequently absent from the trained phrase table.
",3.3 Refinement without back-translation,[0],[0]
We rather consider that the language model already trained on a large monolingual corpus in the target language can play a much more important role in generating more fluent translations.,3.3 Refinement without back-translation,[0],[0]
"This motivates us to perform the refinement steps on synthetic parallel data made of source sentences translated into the target language by the sourceto-target system, i.e., “forward translation,” as opposed to back-translation.",3.3 Refinement without back-translation,[0],[0]
"In fact, the idea of retraining an SMT system on synthetic parallel data generated by a source-to-target system has already been proven beneficial (Ueffing et al., 2007).
",3.3 Refinement without back-translation,[0],[0]
"At each iteration, we randomly sample new N source sentences from the monolingual corpus and translate them with the latest USMT system to generate synthetic parallel data.",3.3 Refinement without back-translation,[0],[0]
"Generating synthetic parallel data through decoding millions of sentences is one of the most computationally expensive parts of the refinement steps, requiring also a large memory to store the whole phrase table.10 In SMT, decoding speed can be improved by reducing the size of the phrase table.",3.4 Phrase table pruning,[0],[0]
"The phrase tables trained during the re-
10To decode a particular test set, usually consisting of thousands of sentences, the phrase table can be drastically filtered by keeping only the phrase pairs applicable to the source sentences to translate.",3.4 Phrase table pruning,[0],[0]
"For the refinement steps of USMT, this filtering is impractical since we need to translate a very large number of sentences.",3.4 Phrase table pruning,[0],[0]
"In other words, it would still remain a large number of phrase pairs.",3.4 Phrase table pruning,[0],[0]
Another alternative is to binarize the phrase table so that the system can load only applicable phrase pairs on-demand at decoding time.,3.4 Phrase table pruning,[0],[0]
"However, we did not consider it in our framework since the binarization is itself very costly to perform, and more importantly, the phrase table of each refinement step is used only once.
finement steps are expected to be very noisy and very large since they are trained on noisy parallel data.",3.4 Phrase table pruning,[0],[0]
"Therefore, we assume that a large number of phrase pairs can be removed without sacrificing translation quality.",3.4 Phrase table pruning,[0],[0]
"On this assumption, we use the well-known algorithm for pruning phrase table (Johnson et al., 2007), which has shown good performance in removing less reliable phrase pairs without any significant drop of the translation quality.",3.4 Phrase table pruning,[0],[0]
"This pruning can be done for each refinement step to reduce the phrase table size, and consequently to speed up the decoding.",3.4 Phrase table pruning,[0],[0]
"Note that we cannot prune the induced phrase table used at iteration 0, since it was not learned from parallel data: we do not have co-occurrence statistics for the phrase pairs.",3.4 Phrase table pruning,[0],[0]
"To make NMT able to learn how to translate from monolingual data only, previous work on UNMT (Artetxe et al., 2018c; Lample et al., 2018a,b; Yang et al., 2018) proposed dedicated architectures, such as denoising autoencoders, shared latent representations, weight sharing, pre-trained sub-word embeddings, and adversarial training.
",4 UNMT as NMT trained exclusively on synthetic parallel data,[0],[0]
"In this paper, we propose to train UNMT systems exclusively on synthetic parallel data, using existing frameworks for supervised NMT.",4 UNMT as NMT trained exclusively on synthetic parallel data,[0],[0]
"Specifically, we train the first UNMT system on synthetic parallel data generated by USMT through back-translating monolingual sentences in the target language, expecting that they are of a better quality than those generated by existing UNMT frameworks.
",4 UNMT as NMT trained exclusively on synthetic parallel data,[0],[0]
Our approach is significantly different from Lample et al. (2018b)’s “PBSMT+NMT” configuration in the following two aspects.,4 UNMT as NMT trained exclusively on synthetic parallel data,[0],[0]
"First, while it uses synthetic parallel data generated by USMT only to further tune their UNMT system, ours uses it for initialization.",4 UNMT as NMT trained exclusively on synthetic parallel data,[0],[0]
"Second, they assumed certain level of relatedness between source and target languages, which is a prerequisite to jointly pre-train bilingual sub-word embeddings.",4 UNMT as NMT trained exclusively on synthetic parallel data,[0],[0]
"Our approach does not make this assumption.
",4 UNMT as NMT trained exclusively on synthetic parallel data,[0],[0]
"However, training an NMT system only on synthetic parallel data generated by USMT, as we proposed, will hardly make an UNMT system significantly better than USMT systems.",4 UNMT as NMT trained exclusively on synthetic parallel data,[0],[0]
"To obtain better UNMT systems, we propose the following (see also Figure 3).
",4 UNMT as NMT trained exclusively on synthetic parallel data,[0],[0]
"• Section 4.1: we propose an incremental training strategy for UNMT that gradually increases the quality and the quantity of synthetic parallel data.
",4 UNMT as NMT trained exclusively on synthetic parallel data,[0],[0]
"• Section 4.2: we propose to filter the synthetic parallel data to remove before training the sentence pairs with the noisiest synthetic sentences, aiming at speeding up training and improving translation quality.",4 UNMT as NMT trained exclusively on synthetic parallel data,[0],[0]
"To train UNMT, we first use the synthetic parallel data generated by the last refinement step of our USMT system.",4.1 Incremental training,[0],[0]
"Since it has been shown that backtranslated monolingual data significantly improves translation quality in NMT, as opposed to the refinement of our USMT (see Section 3.3), we train source-to-target and target-to-source UNMT systems on synthetic parallel data respectively generated by a target-to-source and source-to-target USMT systems.
",4.1 Incremental training,[0],[0]
"In contrast to supervised NMT where synthetic parallel data are used in combination with humanmade parallel data, we can presumably use as much synthetic parallel data as possible, since seeing more and more fluent target sentences will be helpful to train a better decoder while we can assume that the quality of synthetic source side remains constant.",4.1 Incremental training,[0],[0]
"In practice, generating a large quantity of synthetic parallel data is costly.",4.1 Incremental training,[0],[0]
"Therefore, to train the first UNMT system, we use the
same number, N , of synthetic sentence pairs generated by the final USMT system.
",4.1 Incremental training,[0],[0]
"Since the source side of the synthetic parallel data is generated by USMT, it is expected to be of worse quality than those that state-of-the-art supervised NMT can generate.",4.1 Incremental training,[0],[0]
"Therefore, we propose to refine UNMT through gradually increasing the quality and quantity of synthetic parallel data.",4.1 Incremental training,[0],[0]
"First, we back-translate a new set of N monolingual sentences using our UNMT systems at iteration 1 in order to generate new synthetic parallel data.",4.1 Incremental training,[0],[0]
"Then, new UNMT systems at iteration 2 are trained from scratch on the 2N synthetic sentence pairs consisting of the new N synthetic data and N synthetic data generated by USMT.",4.1 Incremental training,[0],[0]
Note that we do not re-back-translate the monolingual data used at iteration 1 but keep them as they are for iteration 2 to reduce the computational cost.,4.1 Incremental training,[0],[0]
"Similarly to the refinement steps of USMT, we can again perform this back-translation/re-training step for a pre-defined number of iterations to keep improving the quality of the source side of the synthetic data while increasing the number of new target sentences.",4.1 Incremental training,[0],[0]
"At each iteration i, (N×i) synthetic sentence pairs are used for training.
",4.1 Incremental training,[0],[0]
"This can be seen as an extension of Hoang et al. (2018)’s work, which performs a so-called iterative back-translation to improve NMT.",4.1 Incremental training,[0],[0]
"The difference is that we introduce better synthetic parallel data, with new target sentences, at each iteration.",4.1 Incremental training,[0],[0]
Our UNMT system is trained on purely synthetic parallel data in which a large proportion of source sentences may be very noisy.,4.2 Filtering of synthetic parallel data,[0],[0]
We assume that removing the sentence pairs with the noisiest source sentences will improve translation quality.,4.2 Filtering of synthetic parallel data,[0],[0]
"Inevitably it also reduces the training time.
",4.2 Filtering of synthetic parallel data,[0],[0]
"Each sentence pair in the synthetic parallel data is evaluated by the following normalized source language model score:
ppl(S) = lm(S)
len(S) + 1 (4)
where S is a (synthetic) source sentence, lm(·) the language model score, and len(·) a function returning the number of tokens in the sentence.",4.2 Filtering of synthetic parallel data,[0],[0]
We add 1 to the number of tokens to account for the special token used by NMT that marks the end of a sentence.,4.2 Filtering of synthetic parallel data,[0],[0]
"This scoring function has a negligible computational cost, but has shown satisfying performances in our preliminary experiments.",4.2 Filtering of synthetic parallel data,[0],[0]
"While
we do not limit the language model to be specific type, in our experiment, we use a recurrent neural network (RNN) language model trained on the entire source monolingual data.
",4.2 Filtering of synthetic parallel data,[0],[0]
There are many ways to make use of the above score during NMT training.,4.2 Filtering of synthetic parallel data,[0],[0]
"For instance, weighting the sentence pairs with this score during training is a possible alternative, and this idea is close to one used by Cheng et al. (2017) in their joint training framework for NMT.",4.2 Filtering of synthetic parallel data,[0],[0]
"However, given that many of the source sentences would be noisy, we rather choose to discard potentially noisy pairs for training.",4.2 Filtering of synthetic parallel data,[0],[0]
"It would also remove potentially useful target sentences, but we assume that the impact of this removal could be compensated at the succeeding iterations of UNMT, where we incrementally introduce new target sentences.
",4.2 Filtering of synthetic parallel data,[0],[0]
"At each iteration i of incremental training, we keep only the cleanest (α ×N × i) synthetic sentence pairs11 selected according to the score computed by Equation (4), where α (0 < α ≤ 1) is the filtering ratio.12",4.2 Filtering of synthetic parallel data,[0],[0]
This aggressive filtering will speed up training while relying only on the most fluent sentence pairs.,4.2 Filtering of synthetic parallel data,[0],[0]
"In this section, we present experiments for evaluating our USMT and UNMT systems.",5 Experiments,[0],[0]
"For these preliminary experiments, we chose the language pair English–German (en-de) and the evaluation task WMT16 (newstest2016) for both translation directions, following previous work (Artetxe et al., 2018b; Lample et al., 2018b).",5.1 Experimental settings,[0],[0]
"To train our USMT and UNMT, we used only monolingual data: English and German News Crawl corpora respectively containing around 238M and 237M sentences.13 All our data were tokenized and truecased with Moses’s tokenizer14 and truecaser, respectively.",5.1 Experimental settings,[0],[0]
"The statistics for truecasing were learned from 10M sentences randomly sampled from the monolingual data.
",5.1 Experimental settings,[0],[0]
"11We considered both the sentence pairs used to initialize UNMT and all the sentence pairs generated by each iteration of UNMT in the set of sentence pairs to filter.
",5.1 Experimental settings,[0],[0]
12We used α = 0.5 in our experiments.,5.1 Experimental settings,[0],[0]
"13http://www.statmt.org/wmt18/
translation-task.html 14We escaped special characters but did not use the option for “aggressive” tokenization.
",5.1 Experimental settings,[0],[0]
"For the phrase table induction, the source and target word embeddings were learned from the entire monolingual data with the default parameters of fasttext (Bojanowski et al., 2017),15 except that we set to 200 the number of dimensions.16 For a reasonably fast computation, we retained only the embeddings for the 300k most frequent words.",5.1 Experimental settings,[0],[0]
"Word embeddings for two languages were then aligned in the same space using the -unsupervised option of vecmap.17 From the entire monolingual data, we also collected phrases of up to 6 tokens in each language using word2phrase.18 To maintain the experiments feasible and to make sure that we have a word embedding for all of the constituent words, we retained only 300k most frequent phrases made of words among the 300k most frequent words.",5.1 Experimental settings,[0],[0]
"We conserved the 300-best target phrases for each source phrase, according to Equation (2), consequently resulting in the initial phrase table for USMT containing 90M (300k×300) phrase pairs.
",5.1 Experimental settings,[0],[0]
We used Moses and its default parameters to conduct experiments for USMT.,5.1 Experimental settings,[0],[0]
"The language models used by our USMT systems were 4-gram models trained with LMPLZ (Heafield et al., 2013) on the entire monolingual data.",5.1 Experimental settings,[0],[0]
"In each refinement step, we trained a phrase table and a lexicalized reordering model on synthetic parallel data using mgiza.19",5.1 Experimental settings,[0],[0]
We compared USMT systems with and without supervised tuning.,5.1 Experimental settings,[0],[0]
"For supervised tuning, we used kb-mira (Cherry and Foster, 2012) and the WMT15 newstest (newstest2015).",5.1 Experimental settings,[0],[0]
"For the configurations without tuning, we used Moses’s default weights as in previous work.
",5.1 Experimental settings,[0],[0]
"For UNMT, we used the Transformer (Vaswani et al., 2017) model implemented in Marian (Junczys-Dowmunt et al., 2018)20 with the hyperparameters proposed by Vaswani et al. (2017).21
15https://fasttext.cc/ 16While Artetxe et al. (2018b) and Lample et al. (2018b) used 300 and 512 dimensions, respectively, we chose a smaller number of dimensions for faster computation, even though this might lead to lower quality.
",5.1 Experimental settings,[0],[0]
"17https://github.com/artetxem/vecmap 18https://code.google.com/archive/p/
word2vec/ 19fast_align (Dyer et al., 2013) is a significantly faster alternative for a similar performance on en-de (Durrani et al., 2014).",5.1 Experimental settings,[0],[0]
"We used mgiza since it is integrated in Moses.
20https://marian-nmt.github.io/, version 1.6.",5.1 Experimental settings,[0],[0]
"21Considering the computational cost of our approach for UNMT, we did not experiment with the “big” version of the Transformer model while it would probably have resulted in a better translation quality.
",5.1 Experimental settings,[0],[0]
We reduced the vocabulary size by using bytepair-encoding (BPE) with 8k symbols jointly learned for English and German from 10M sentences sampled from the monolingual data.,5.1 Experimental settings,[0],[0]
BPE was then applied to the entire source and target monolingual data.22,5.1 Experimental settings,[0],[0]
We used the same BPE vocabulary throughout our UNMT experiments.23 We validated our model during UNMT training as proposed by Lample et al. (2018b): we did a supervised validation using 100 human-made sentence pairs randomly extracted from newstest2015.,5.1 Experimental settings,[0],[0]
We consistently used the same validation set throughout our UNMT experiments.,5.1 Experimental settings,[0],[0]
"To filter the synthetic parallel sentences (see Section 4.2), we used an RNN language model trained on the entire monolingual data, without BPE, with a vocabulary size of 100k.24
For each of USMT and UNMT, we performed 4 refinement iterations.",5.1 Experimental settings,[0],[0]
"USMT has one more system in the beginning, which exploits an induced phrase table.",5.1 Experimental settings,[0],[0]
"At each iteration, we sampled new 3M monolingual sentences: i.e., N = 3000000.25
For reference, we also trained supervised NMT with Marian on 5.6M, 2.8M, and 1.4M humanmade parallel sentences provided by the WMT18 conference for the German–English news translation task.26
We evaluated our systems with detokenized and detruecased BLEU-cased (Papineni et al., 2002).",5.1 Experimental settings,[0],[0]
Note that our results should not be directly compared with the tokenized BLEU scores reported in Artetxe et al. (2018b) and Lample et al. (2018b).,5.1 Experimental settings,[0],[0]
"Our results for USMT and UNMT are presented in Table 1.
",5.2 Results,[0],[0]
"We can first observe that supervised tuning for USMT improves translation quality, with 2.0 BLEU points of improvements, for instance between systems #5 and #6.",5.2 Results,[0],[0]
Another interesting observation is that this improvement is carried on until the final iteration of UNMT (#11 and #12).,5.2 Results,[0],[0]
"These results show the importance of development data for tuning that could be created at a reason-
22We did not use BPE for USMT.",5.2 Results,[0],[0]
"23Re-training BPE at each iteration of UNMT on synthetic data did not improve the translation quality in our preliminary experiments.
",5.2 Results,[0],[0]
24We used also Marian to train the RNN language models.,5.2 Results,[0],[0]
"25Artetxe et al. (2018b) and Lample et al. (2018b) respec-
tively sampled 2M and 5M monolingual sentences.",5.2 Results,[0],[0]
"26We did not use the ParaCrawl corpus.
able cost (see Section 3.2).
",5.2 Results,[0],[0]
"Our USMT systems benefited more from forward translation (#5 and #6) than back-translation (#3 and #4) during the refinement steps, with an improvement of 1.6 and 0.4 BLEU points for de→en and en→de (with supervised tuning), respectively.",5.2 Results,[0],[0]
Pruning the phrase table (see Section 3.4) did not hurt translation quality but removed around 93% of the phrase pairs in the phrase tables for each refinement step.,5.2 Results,[0],[0]
"Nonetheless, our USMT systems seem to significantly underperform the state-of-the-art USMT proposed by Lample et al. (2018b) (#1) and Artetxe et al. (2018b) (#2).",5.2 Results,[0],[0]
"This is potentially the consequence of the following: we used much lower dimensions for our word embeddings and much less phrases (300k source and target phrases), than in Artetxe et al. (2018b) (1M source and target phrases).",5.2 Results,[0],[0]
"In our future work, we will investigate whether their parameters improve the performance of our USMT systems.
",5.2 Results,[0],[0]
"While our USMT systems do not seem to outperform previous work, we can observe that the synthetic parallel data that they generated are of
sufficient quality to initialize our UNMT.",5.2 Results,[0],[0]
Incremental training improved significantly translation quality.,5.2 Results,[0],[0]
"To the best of our knowledge, we report the best results of unsupervised MT for this task which is, for de→en, only 3.7 BLEU points lower (#11) than a supervised NMT system trained on 1.4M parallel sentences (#13).27 Our best UNMT systems (#11 and #12) significantly outperformed our USMT systems (#5 and #6) by more than 6.0 BLEU points, for de→en.",5.2 Results,[0],[0]
Filtering the synthetic parallel sentences at each iteration significantly improved the training speed28 for a comparable or better translation quality for both translation directions.,5.2 Results,[0],[0]
"The results confirm the importance of filtering the very noisy synthetic source sentences generated by back-translation.
27A fair supervised NMT baseline should also use, in addition to human-made parallel sentences, back-translated data for training.
",5.2 Results,[0],[0]
"28For instance, for the last iteration of UNMT for de→en, the training using 4 GPUs consumed 30 hours with filtering while it took 52 hours without filtering.",5.2 Results,[0],[0]
"In this section, we present the evolution of the translation quality during training of USMT and UNMT.
",5.3 Learning curves,[0],[0]
"The learning curves of our systems, for the same experiments presented in Section 5.1, are given in Figures 4a and 4b for de→en and en→de, respectively.",5.3 Learning curves,[0],[0]
"Iteration 0 of our USMT, using an induced phrase table, performed very poorly; for instance systems without supervised tuning (leftmost points of blue lines) achieved only 11.2 and 7.3 absolute BLEU points for de→en and en→de, respectively.",5.3 Learning curves,[0],[0]
Iterations 1 and 2 of USMT were very effective and covered most of the improvements between iteration 0 and iteration 4.,5.3 Learning curves,[0],[0]
"After 4 iterations, we observed improvements of 9.0 and 8.1 BLEU points for de→en and en→de, respectively.
",5.3 Learning curves,[0],[0]
The learning curves of UNMT were very different for the two translation directions.,5.3 Learning curves,[0],[0]
"The first iteration of UNMT, trained on the synthetic parallel data generated by USMT, performed slightly lower than USMT for de→en while for en→de we observed around 2.0 BLEU points of improvements.",5.3 Learning curves,[0],[0]
"This confirms the ability of NMT in generating significantly better sentences than SMT for morphologically-rich target languages (Bentivogli et al., 2016).",5.3 Learning curves,[0],[0]
"Then, the second iteration of UNMT improved the translation quality significantly for de→en, but much more moderately for en→de.",5.3 Learning curves,[0],[0]
"For instance, in the configuration without supervised tuning and with language model filtering (blue solid lines), we observed 5.4 and 0.9 BLEU
points of improvements for de→en and en→de, respectively.",5.3 Learning curves,[0],[0]
"Succeeding iterations continued to improve translation quality but more moderately.
",5.3 Learning curves,[0],[0]
"For both translation directions, the learning curves highlighted that improving the synthetic parallel data generated by USMT, and used to initialize UNMT, is critical to improve UNMT:",5.3 Learning curves,[0],[0]
synthetic parallel data generated with tuned USMT were consistently more useful for UNMT than the synthetic parallel data of lower quality generated by USMT without tuning.,5.3 Learning curves,[0],[0]
We proposed a new approach for UNMT that can be straightforwardly exploited with wellestablished architectures and frameworks used for supervised NMT without any modifications.,6 Conclusion an future work,[0],[0]
"It only assumes for initialization the availability of synthetic parallel data that can be, for instance, easily generated by USMT.",6 Conclusion an future work,[0],[0]
We showed that improving the quality of the synthetic parallel data used for initialization is crucial to improve UNMT.,6 Conclusion an future work,[0],[0]
"We obtained with our approach a new state-ofthe-art performance for unsupervised MT on the WMT16 German–English news translation task.
",6 Conclusion an future work,[0],[0]
"For future work, we will extend our experiments to cover many more language pairs, including distant language pairs for which we expect that our approach will perform better than previous work that assumes the relatedness between source and target languages.",6 Conclusion an future work,[0],[0]
We will also analyze the impact of using synthetic parallel data of a much better quality to initialize UNMT.,6 Conclusion an future work,[0],[0]
"Moreover, we
would like to investigate the use of much noisier and not comparable source and target monolingual corpora to train USMT and UNMT, since we consider it as a more realistic scenario when dealing with truly low-resource languages.",6 Conclusion an future work,[0],[0]
We will also study our approach in the semi-supervised scenario where we assume the availability of some human-made bilingual sentence pairs for training.,6 Conclusion an future work,[0],[0]
"Recent work achieved remarkable results in training neural machine translation (NMT) systems in a fully unsupervised way, with new and dedicated architectures that rely on monolingual corpora only.",abstractText,[0],[0]
"In this work, we propose to define unsupervised NMT (UNMT) as NMT trained with the supervision of synthetic bilingual data.",abstractText,[0],[0]
Our approach straightforwardly enables the use of state-of-the-art architectures proposed for supervised NMT by replacing human-made bilingual data with synthetic bilingual data for training.,abstractText,[0],[0]
We propose to initialize the training of UNMT with synthetic bilingual data generated by unsupervised statistical machine translation (USMT).,abstractText,[0],[0]
The UNMT system is then incrementally improved using back-translation.,abstractText,[0],[0]
"Our preliminary experiments show that our approach achieves a new state-of-the-art for unsupervised machine translation on the WMT16 German– English news translation task, for both translation directions.",abstractText,[0],[0]
Unsupervised Neural Machine Translation Initialized by Unsupervised Statistical Machine Translation,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2343–2349, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
This paper presents a generic approach to content selection for creating timelines from individual history articles for which no external information about the same topic is available. This scenario is in contrast to existing works on timeline generation, which require the presence of a large corpus of news articles. To identify salient events in a given history article, we exploit lexical cues about the article’s subject area, as well as time expressions that are syntactically attached to an event word. We also test different methods of ensuring timeline coverage of the entire historical time span described. Our best-performing method outperforms a new unsupervised baseline and an improved version of an existing supervised approach. We see our work as a step towards more semantically motivated approaches to single-document summarisation.",text,[0],[0]
"While there has been much work on generating history timelines automatically, these approaches are commonly evaluated on events that took place in recent decades, as they depend on the availability of large numbers of articles describing the same historical period.",1 Introduction,[0],[0]
"If such a rich data source is available, it is possible to exploit document creation times, redundancy across documents, as well as back-references to earlier events in order to identify salient events.",1 Introduction,[0],[0]
"For instance, the start of the Iraq War in 2003 is mentioned frequently in a general news corpus, including in articles published years after the
event took place.",1 Introduction,[0],[0]
"The high number of mentions suggests that the beginning of the Iraq War was an important historical event.
",1 Introduction,[0],[0]
"However, for most historical periods covered in history articles (e.g., Antiquity or the Middle Ages), such cues are not commonly available, as no news articles from these eras exist.",1 Introduction,[0],[0]
"Generating event timelines for arbitrary historical periods is therefore a much harder problem, which requires methods that rely less heavily on the types of rich, parallel and dense information contained in news clusters.
",1 Introduction,[0],[0]
"To investigate this problem, we approach timeline generation as a special single-document summarisation task.",1 Introduction,[0],[0]
"In other words, we assume that the information to be summarised is contained in a single history article, and that no further mentions of specific events exist externally.",1 Introduction,[0],[0]
"This is a realistic scenario, for instance, for a specialist article describing the history of music in Ancient China.
",1 Introduction,[0],[0]
"We introduce a method for selecting salient content in history articles of any subject area, as long as the events in the text are roughly ordered chronologically.",1 Introduction,[0],[0]
The hypothesis is that knowledge of an text’s subject area can help decide which content should be selected.,1 Introduction,[0],[0]
Another intuition is that certain combinations of events should be avoided in a timeline.,1 Introduction,[0],[0]
We therefore investigate ways of encouraging a balanced selection of content from all parts of the text.,1 Introduction,[0],[0]
"Timeline extraction has mostly been explored in a multi-document summarisation setting using corpora of news articles (Tran et al., 2015; Swan and Allan, 2000; Yan et al., 2011; Chieu and Lee, 2004;
2343
Allan et al., 2001).",2 Related work,[0],[0]
This task definition allows the exploitation of features such as document creation times and headlines.,2 Related work,[0],[0]
"The most important feature is redundancy between articles, which facilitates the identification of salient events.
",2 Related work,[0],[0]
A second important strand of work focuses on extracting all events from a single input text and anchoring them in time.,2 Related work,[0],[0]
"The creation of the TimeML specification language (Pustejovsky et al., 2003) laid the foundations for the TempEval series of shared tasks (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), in which systems had to identify TimeML events and temporal expressions in free-form text.",2 Related work,[0],[0]
Further subtasks included the normalisation of temporal expressions and the creation of links between events and temporal expressions.,2 Related work,[0],[0]
"A further shared task investigated the use of TimeML annotation for the downstream task of question answering (Llorens et al., 2015).",2 Related work,[0],[0]
Kolomiyets et al. (2012) created a connected timeline for a text based on TimeML annotations; a dependency parser infers dependency structures between events.,2 Related work,[0],[0]
"Finally, a recent SemEval task (Minard et al., 2015) explored the related problem of cross-document event ordering.",2 Related work,[0],[0]
"Here, relevant events and temporal expressions concerning a single target entity of interest have to be identified in more than one input document.
",2 Related work,[0],[0]
"Chasin et al. (2014) try to identify important events in single texts, but their approach is limited to articles on wars and battles, and the problem is not approached as a summarisation task.",2 Related work,[0],[0]
"Their method is lightly supervised, using features such as the presence of negation or past tense verbs in the sentence, and TextRank (Mihalcea and Tarau, 2004) for identifying salient sentences.",2 Related work,[0],[0]
We use an improved version of this system as a baseline.,2 Related work,[0],[0]
Our problem is that of finding an optimal sequence of events (of a given maximum length) in a given input article.,3 Overall approach,[0],[0]
"We follow the literature on event extraction and use TimeML events (Pustejovsky et al., 2003).",3 Overall approach,[0],[0]
"Most TimeML events are verbs, but some are nominalisations such as “invasion” or other event-like words such as “war”.",3 Overall approach,[0],[0]
"The use of TimeML events, aside from the practical advantage that commonly-available event extraction algo-
rithms exist, allows us to evaluate content selection at the event rather than at the sentence level.
",3 Overall approach,[0],[0]
We assume that there are both local and global factors that determine which events should be contained in the timeline.,3 Overall approach,[0],[0]
Local factors reflect how important an event is in its own right.,3 Overall approach,[0],[0]
Global factors represent intuitions about which combinations of events should or should not be selected.,3 Overall approach,[0],[0]
"Our approach, which is unsupervised, takes into account the factors described in what follows.",3 Overall approach,[0],[0]
"Intuitively, we expect that many important events have a date attached to them, as authors tend to give the reader this information if it is available.",3.1 Date presence,[0],[0]
"This is true for all historical periods from prehistory onwards, since for most events at least an approximate date is known.",3.1 Date presence,[0],[0]
"We considered two alternatives: The simplest approach is to only use sentences that contain a date, regardless of where in the sentence the date is located.",3.1 Date presence,[0],[0]
"A more sophisticated alternative verifies that the date is syntactically attached to the event, such as in “Richelieu died in 1642”.",3.1 Date presence,[0],[0]
"To identify such cases, we constructed a parse tree using the C&C dependency parser (Clark and Curran, 2007) and only considered a TimeML event to be “dated” if it is at most two outgoing dependencies away from a temporal expression.",3.1 Date presence,[0],[0]
"We used HeidelTime (Strötgen and Gertz, 2013), a the state-of-theart temporal expression software package, to identify such temporal expressions.",3.1 Date presence,[0],[0]
The key component we use to judge the importance of any event are lexical cues about the input text’s subject area.,3.2 Lexical cues,[0],[0]
Examples of such subject areas include INVENTION and FOOD/DRINK.,3.2 Lexical cues,[0],[0]
The subject area of a text should give us prior knowledge about which types of events are likely to be important.,3.2 Lexical cues,[0],[0]
"For instance, we would expect that a timeline describing the history of a country should contain information about revolutions, invasions, elections and similar events, whereas a timeline about science will instead focus on discoveries, publications, and Nobel prizes.
",3.2 Lexical cues,[0],[0]
"To mine knowledge about such subject-areaspecific preferences, we make use of Wikipedia as a background corpus.",3.2 Lexical cues,[0],[0]
"Only history-specific articles whose title starts with “History of” are considered.
",3.2 Lexical cues,[0],[0]
"We start by generating sets of all Wikipedia history articles belonging to a given subject area, e.g. AGPE or AINVENTION.",3.2 Lexical cues,[0],[0]
"To do this, we make use of the Wikipedia category system.",3.2 Lexical cues,[0],[0]
"For instance, for constructing a set of articles for the subject area FIELD OF SCIENCE, we collected all history articles that belong to the Wikipedia category “History of science by discipline”.",3.2 Lexical cues,[0],[0]
"For each subject area g, we then calculate a preference score for each word lemma l found in any of the articles in the corresponding list Ag, using the following formula:
sc(g, l) = freq(Ag ,l) freq(Ag ,∗) freq(∗,l) freq(∗,∗)
where freq(Ag, l) is the summed frequency of word lemma l in all documents belonging to subject area g, and “*” stands for any.",3.2 Lexical cues,[0],[0]
"The numerator denotes how often lemma l appears in the subject-areaspecific set of articles Ag, normalised by the total number of tokens found in this set.",3.2 Lexical cues,[0],[0]
The denominator is invariant across all subject areas.,3.2 Lexical cues,[0],[0]
"If the ratio is high, lemma l is more likely to appear in articles of subject area g than in Wikipedia overall, suggesting that it is typical for the given subject area.
",3.2 Lexical cues,[0],[0]
"For each event e in the input text, a local importance score imp(e) is calculated as
imp(e) =
∑ w∈R(e) sc(g,l) 1+dist(we,w)
N
where R(e) is a window of words around the word representing the event (including the event word we itself), and dist(w1, w2) refers to the absolute distance in words between two words w1 and w2.",3.2 Lexical cues,[0],[0]
imp(e) is a weighted average of the preference scores of all words in a window.,3.2 Lexical cues,[0],[0]
The intuition is that context words of the event word can also be expected to be indicative of the subject area (consider “publish a paper”) in many cases.,3.2 Lexical cues,[0],[0]
"1+dist(we, w) is used as a distance penalty in order to give more importance to words that are closer to the event word we.",3.2 Lexical cues,[0],[0]
"N is a constant which normalises the score by the sum of all distance penalties, to account for cases where the event word occurs at the beginning or end of a sentence.",3.2 Lexical cues,[0],[0]
Table 1 shows examples of words with high and low preference scores.,3.2 Lexical cues,[0],[0]
"We would like to avoid cases where too many events are selected from a small portion of the document,
even if all these events are relevant.",3.3 Temporal coverage,[0],[0]
"For instance, an article might list all a country’s elections of the past few years, while mentioning only very important elections in earlier time periods.",3.3 Temporal coverage,[0],[0]
"In this case, knowing that elections are important in the history of a country is not helpful, since this would lead to insufficient coverage of the remaining events in the article.",3.3 Temporal coverage,[0],[0]
We therefore take into account global factors as well.,3.3 Temporal coverage,[0],[0]
"We experiment with two different methods:
Exploiting document structure.",3.3 Temporal coverage,[0],[0]
We select salient events from each section of the Wikipedia article in a round-robin fashion.,3.3 Temporal coverage,[0],[0]
"The algorithm operates in a greedy fashion by selecting the most locally important remaining event for each section, until the desired timeline length has been reached.
",3.3 Temporal coverage,[0],[0]
Integer linear program.,3.3 Temporal coverage,[0],[0]
We use an integer linear program to encode the intuition that no two timeline entries should have the same year.,3.3 Temporal coverage,[0],[0]
"The ILP maximises the following objective function for each article (E refers to the set of all dated events):
∑ ei∈E xi · imp(ei)− ∑ ei∈E ∑ ej∈E bij · pen(ei, ej)
subject to the constraints:
bij ≤ xi",3.3 Temporal coverage,[0],[0]
"∀i, j ∈ E xi + xj",3.3 Temporal coverage,[0],[0]
"− bij ≤ 1 ∀i, j ∈ E
xi ∈ {0, 1} ∀i ∈ E bij ∈ {0, 1} ∀i, j ∈ E∑",3.3 Temporal coverage,[0],[0]
"ei∈E xi = Lmax
This is similar to the model used by McDonald (2007) for multi-document summarisation.",3.3 Temporal coverage,[0],[0]
The model tries to find a set of locally important events while discouraging the selection of events that have the same date.,3.3 Temporal coverage,[0],[0]
xi is a variable denoting whether the corresponding event ei has been selected.,3.3 Temporal coverage,[0],[0]
bij is a variable which is 1 if and only if both events i and j have been selected.,3.3 Temporal coverage,[0],[0]
"pen(ei, ej) is a penalty function that is 1 if the two events ei and ej have
the same date, otherwise 0.",3.3 Temporal coverage,[0],[0]
Each event was linked to the preceding temporal expression identified by HeidelTime; this heuristic was found to work well.,3.3 Temporal coverage,[0],[0]
"The last constraint ensures that not more than Lmax events are chosen, where Lmax is the desired timeline length for the article considered.",3.3 Temporal coverage,[0],[0]
"For evaluating our algorithms, the methodology we introduced in (Bauer and Teufel, 2015) is used, along with the accompanying Cambridge SingleDocument Timeline Corpus (CSDTC, version 2.0), which has been made publicly available1.",4 Evaluation,[0],[0]
"The CSDTC contains 10 articles from 3 subject areas: GPE (geo-political entities such as countries and cities), FIELD OF SCIENCE and INVENTION.",4.1 Cambridge Single-Document Timeline Corpus,[0],[0]
"To tune our algorithms, we constructed a development set of a further 30 annotated history articles from the subject areas in the CSDTC and one additional subject area (FOOD/DRINK).",4.1 Cambridge Single-Document Timeline Corpus,[0],[0]
"Due to the high annotation cost, only a single timeline creator was used.",4.1 Cambridge Single-Document Timeline Corpus,[0],[0]
"Important events were directly marked up in the source text (as opposed to the CSDTC, where timeline entries were written by hand), and exactly one HCU2 was created per event.",4.1 Cambridge Single-Document Timeline Corpus,[0],[0]
"Using this development corpus, the window size of words considered for calculating local importance scores (cf. Section 3.2) was set to 3.",4.1 Cambridge Single-Document Timeline Corpus,[0],[0]
"We report the performance of all algorithms on both the development set and the test set (the CSDTC).
",4.1 Cambridge Single-Document Timeline Corpus,[0],[0]
"Although the number of subject areas in the two corpora is rather small owing to the considerable annotation effort, we believe that the resulting system would generalise rather well to other subject areas, were they added, as the subject areas in the corpus are very different in nature from each other.",4.1 Cambridge Single-Document Timeline Corpus,[0],[0]
"Care was taken when constructing the CSDTC to use a set of subject areas that is representative for humanwritten timelines on the Web.
1The corpus is available on the first author’s website: http://www.cl.cam.ac.uk/˜smb89/form.html
2As opposed to the CSDTC, HCUs in the development set always have a weight of 1, as only timeline writer was used.",4.1 Cambridge Single-Document Timeline Corpus,[0],[0]
The evaluation is based on abstract (“deep”) meaning units called Historical Content Units (HCUs).,4.2 Evaluation based on Historical Content Units,[0],[0]
HCUs were derived on the basis of human-created timelines.,4.2 Evaluation based on Historical Content Units,[0],[0]
"Between 32 and 80 HCUs per article were annotated for the articles in the CSDTC.
",4.2 Evaluation based on Historical Content Units,[0],[0]
Each HCU is weighted by the number of timeline creators who expressed its semantic content in their timelines.,4.2 Evaluation based on Historical Content Units,[0],[0]
"Because HCUs are linked to TimeML events in the surface text, it is possible to perform automatic deep evaluation without requiring any manual annotation of system summaries.
",4.2 Evaluation based on Historical Content Units,[0],[0]
"Algorithms are evaluated on a given input article using an adapted version of the pyramid score (Nenkova and Passonneau, 2004), which is calculated as the ratio between the sum of all rewards for HCUs chosen by the algorithm normalised by the maximum possible score scoremax:
score =
∑ h∈HCUs wh·Cov(h,E,T )
scoremax
where wh is the weight of HCU h (a number between 1 and the number of annotators), E is the set of events in the article, T are the events in the system timeline, and the coverage score Cov(h,E, T ) is a number between 0 and 1 that indicates to what extent the events chosen by the algorithm jointly express the semantic content of HCU",4.2 Evaluation based on Historical Content Units,[0],[0]
h.,4.2 Evaluation based on Historical Content Units,[0],[0]
"The basic version of Cov(h,E, T ) is defined as follows:
Cov(h,E, T ) =",4.2 Evaluation based on Historical Content Units,[0],[0]
"min(1.0, ∑
ej∈E vh,ej · s(T, ej)) where vh,ej is an anchor weight between 0 and 1 which denotes to what extent event ej expresses the semantic content of HCU h, and s(T, e) is a helper function that returns 1 if the set of selected events T includes event e, and 0 otherwise.
",4.2 Evaluation based on Historical Content Units,[0],[0]
The coverage score for each HCU is calculated by summing up the anchor weights of those events that the algorithm has selected.,4.2 Evaluation based on Historical Content Units,[0],[0]
"A coverage score of 0 means that the events mentioned in the timeline do not express the HCU’s semantic content at all, while a score of 1 occurs where the HCU’s content is fully expressed by the timeline.",4.2 Evaluation based on Historical Content Units,[0],[0]
Scores between 0 and 1 occur in a large number of cases.,4.2 Evaluation based on Historical Content Units,[0],[0]
"For instance, an HCU may express the fact that a country was invaded and destroyed.",4.2 Evaluation based on Historical Content Units,[0],[0]
"If the system timeline merely contains a TimeML event that refers to the invasion, it is assigned a coverage score of 0.5 for this HCU,
as it expresses only half of the HCU’s semantic content.",4.2 Evaluation based on Historical Content Units,[0],[0]
"Where the sum exceeds 1, the coverage score is set to a hard upper limit of 1.",4.2 Evaluation based on Historical Content Units,[0],[0]
This ensures that algorithms are not doubly rewarded for selecting multiple TimeML events expressing the same semantic content.,4.2 Evaluation based on Historical Content Units,[0],[0]
"The final formula we used to calculate coverage scores is slightly more complex, as some TimeML events in the CSDTC have been grouped together into event groups.",4.2 Evaluation based on Historical Content Units,[0],[0]
"A detailed description is given in the documentation of the corpus.
",4.2 Evaluation based on Historical Content Units,[0],[0]
"Pyramid scores are recall-based: The evaluation assumes a maximum number of timeline entries n, and the maximum possible score is the sum of the HCU weights of the n most highly weighted HCUs.",4.2 Evaluation based on Historical Content Units,[0],[0]
The values for n are given in the CSDTC.,4.2 Evaluation based on Historical Content Units,[0],[0]
We report the performance of two systems.,4.3 System and baselines,[0],[0]
"Both systems first remove all events that do not have a date, or whose date is too far away, as described in Section 3.1.",4.3 System and baselines,[0],[0]
"Our first system (“ILP-based”) selects events based on the integer linear program described, while the second system (“Round-robin”) selects locally important events per section.
",4.3 System and baselines,[0],[0]
We have speculated above that dates are important for our task.,4.3 System and baselines,[0],[0]
We therefore compare against a date baseline which selects events randomly from the list of all dated events.,4.3 System and baselines,[0],[0]
"We also compare against several modified versions of our method: To investigate the influence of the parser in identifying suitable dated events, we report the results for a simpler method which considers all events that have a date in the same sentence (“Round-robin, simple date criterion”).",4.3 System and baselines,[0],[0]
"Two alternative systems select locally important events from all (not only dated) events (“Roundrobin, without date criterion”) or salient dated events from the entire article without considering document structure (“Local importance + date criterion”).
",4.3 System and baselines,[0],[0]
"The supervised baseline (“Chasin et al. (2014)”) was re-implemented using LibSVM (Chang and Lin, 2011), and SVM parameters were tuned using grid search.",4.3 System and baselines,[0],[0]
25 of the 30 articles were used for training and 5 for development.,4.3 System and baselines,[0],[0]
We improved their system by defining some of their sentence-level features at the event level.,4.3 System and baselines,[0],[0]
Probability estimates as described by Platt (2000) were used as importance scores.,4.3 System and baselines,[0],[0]
"The results in Table 2 show that only a combination of all three factors (date presence, local importance, coverage) results in a statistically significant improvement over the date baseline at α = 0.05 according to Wilcoxon’s signed-rank test on the test set.",4.4 Results,[0],[0]
Both our systems perform comparably on the test set; removing any of the three components results in lower performance.,4.4 Results,[0],[0]
"Using a parser to identify dated events has a strong positive effect (see “Round-robin, simple date criterion”).",4.4 Results,[0],[0]
Our system also outperforms the improved supervised baseline by a large margin.,4.4 Results,[0],[0]
"The fact that a completely unsupervised system performs best is encouraging, as training data for this task is very expensive to obtain.",4.4 Results,[0],[0]
Our results suggest that it might be worth investigating other types of prior knowledge about the semantics of an input text in further research.,4.4 Results,[0],[0]
"The crucial advantage of such generic methods is that no texts on exactly the same topic are needed, which is a requirement with texts about niche topics.",4.4 Results,[0],[0]
"We have introduced an unsupervised method for the challenging problem of timeline generation from single history articles, a scenario where parallel texts cannot be assumed to exist.",5 Conclusion,[0],[0]
Our method results in a significant improvement over a novel unsupervised baseline as well as an existing supervised approach.,5 Conclusion,[0],[0]
"The first author received financial support from Microsoft Research, St John’s College Cambridge and the Cambridge University Computer Laboratory.",Acknowledgments,[0],[0]
This paper presents a generic approach to content selection for creating timelines from individual history articles for which no external information about the same topic is available.,abstractText,[0],[0]
"This scenario is in contrast to existing works on timeline generation, which require the presence of a large corpus of news articles.",abstractText,[0],[0]
"To identify salient events in a given history article, we exploit lexical cues about the article’s subject area, as well as time expressions that are syntactically attached to an event word.",abstractText,[0],[0]
We also test different methods of ensuring timeline coverage of the entire historical time span described.,abstractText,[0],[0]
Our best-performing method outperforms a new unsupervised baseline and an improved version of an existing supervised approach.,abstractText,[0],[0]
We see our work as a step towards more semantically motivated approaches to single-document summarisation.,abstractText,[0],[0]
Unsupervised Timeline Generation for Wikipedia History Articles,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2923–2930 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Schizophrenia is a severe mental disorder that has a devastating impact on those who suffer from it, as well as on their families and communities.",1 Introduction,[0],[0]
"Schizophrenia is characterized by psychotic behaviors (hallucinations, delusions, thought disorders, movement disorders), flat affect and anhedonia, and trouble with focusing and executive functioning, among other symptoms (American Psychiatric Association, 2013).",1 Introduction,[0],[0]
"It afflicts over 21 million people worldwide, and is associated with a 100-150 percent increase in early mortality (Goff et al., 2005; World Health Organization, 2016; Simeone et al., 2015).",1 Introduction,[0],[0]
"As a result, diagnosis and treatment of schizophrenia has important public health consequences.",1 Introduction,[0],[0]
"Unfortunately, practitioners who are qualified to diagnose and treat serious mental health issues such as schizophrenia are
in chronically short supply, and their accumulated knowledge cannot be easily formalized into reproducible metrics (Patel et al., 2007).
",1 Introduction,[0],[0]
"However, clinical research into the symptoms and mechanisms of schizophrenia suggests that disturbances in language use, and especially in metaphor use and affect, characterize schizophrenia.",1 Introduction,[0],[0]
This suggests that automated NLP methods may have the potential to help in diagnosis and prognosis of schizophrenia.,1 Introduction,[0],[0]
"In this paper, we work from open-ended transcripts of patients interviewed by non-specialists.",1 Introduction,[0],[0]
"We then apply NLP algorithms for metaphor identification and sentiment analysis to automatically generate features for a classifier that, with high accuracy, can predict which patients will develop schizophrenia and which patients would currently be diagnosed with schizophrenia by psychiatrists.",1 Introduction,[0],[0]
Several recent studies have proven that NLP textanalysis techniques can be successfully applied to predict mental illness.,2.1 NLP and Computational Psychiatry,[0],[0]
Vincze et al. (2016) use linguistic and demographic features to predict whether a speech transcript was produced by an individual with mild cognitive impairment or by a healthy control.,2.1 NLP and Computational Psychiatry,[0],[0]
"To our knowledge, Elvevåg et al. (2007) were the first to use automated NLP methods to predict whether or not patients suffered from schizophrenia.",2.1 NLP and Computational Psychiatry,[0],[0]
"The technical specifics of their method are unclear, as the paper was intended for a clinical audience, but they use a k-nearest neighbors algorithm in a feature space made up of n-gram features and distributional semantic features to classify 26 schizophrenia patients and 25 healthy controls.",2.1 NLP and Computational Psychiatry,[0],[0]
They achieve classification accuracy of 78.4% on this task.,2.1 NLP and Computational Psychiatry,[0],[0]
"Mota et al. (2012) employ a graph-based method to classify transcripts taken from interviews with eight patients with
2923
schizophrenia, eight healthy controls, and eight manic patients, achieving both precision and recall of 0.875.",2.1 NLP and Computational Psychiatry,[0],[0]
Bedi et al. (2015) apply semantic coherence measures and measures based on part-ofspeech tags to predict whether 34 youths at risk of psychosis would have a psychotic episode within 2.5 years of being interviewed (five of whom did transition within the study period).,2.1 NLP and Computational Psychiatry,[0],[0]
They correctly classify 100% of participants.,2.1 NLP and Computational Psychiatry,[0],[0]
Mental-health clinicians have long had intuitions that schizophrenia patients differ from healthy individuals in their use of metaphor.,"2.2 Metaphor, Affect and Schizophrenia",[0],[0]
A survey by Kuperberg (2010) of over 50 years of observations in the schizophrenia literature concludes that schizophrenia patients “may use common words in an idiosyncratic or bizarre manner.”,"2.2 Metaphor, Affect and Schizophrenia",[0],[0]
"Particularly colorful (and metaphorical) examples of bizarre speech recorded by Andreasen (1986) include patients who referred to watches as “time vessels” and to gloves as “hand shoes.”
","2.2 Metaphor, Affect and Schizophrenia",[0],[0]
Billow et al. (1997) carried out the first experimental exploration of this phenomenon.,"2.2 Metaphor, Affect and Schizophrenia",[0],[0]
They measure the metaphor production of patients with schizophrenia and healthy controls during free responses to a structured interview.,"2.2 Metaphor, Affect and Schizophrenia",[0],[0]
"They find that patients with schizophrenia produce comparable rates of felicitous, coherent metaphors as healthy controls, but produce deviant metaphorical speech with significantly greater frequency.
","2.2 Metaphor, Affect and Schizophrenia",[0],[0]
"It is not clear what could account for these differences in metaphor production, but neuroscientific studies of patients with schizophrenia offer some clues.","2.2 Metaphor, Affect and Schizophrenia",[0],[0]
"Research shows that schizophrenia is associated with dysfunction of the amygdala, a brain structure responsible for regulating emotion (Rasetti et al., 2009).","2.2 Metaphor, Affect and Schizophrenia",[0],[0]
"Other work demonstrates impairments in emotion perception and production in patients with schizophrenia (Vaskinn et al., 2008) and even demonstrates that face emotion recognition deficits are a predictor of psychosis onset (Corcoran et al., 2015).","2.2 Metaphor, Affect and Schizophrenia",[0],[0]
"Based on these findings, and recognizing the important role that metaphor plays in emotional language (see (Kövecses, 2003)), Elvevåg et al. (2011) hypothesize that metaphor production disturbances in patients with schizophrenia are deeply tied to “emotional” language (i.e., language with high affective polarity).","2.2 Metaphor, Affect and Schizophrenia",[0],[0]
"However, it should be noted in this regard that most work on metaphor processing has focused on cortical regions involved (Chen et al., 2008; Schmidt et al., 2010; Benedek et al., 2014).","2.2 Metaphor, Affect and Schizophrenia",[0],[0]
"Sentiment analysis is a natural-language processing task that involves determining, for given text, whether the text conveys a positive or negative sentiment, and how positive or negative the sentiment is.",2.3 Sentiment Analysis & Metaphor Detection Algorithms,[0],[0]
"The book by Liu (2015) gives a comprehensive overview of sentiment analysis.
",2.3 Sentiment Analysis & Metaphor Detection Algorithms,[0],[0]
"Metaphor detection is the task of determining whether a given word, phrase, or passage is being used metaphorically or literally.",2.3 Sentiment Analysis & Metaphor Detection Algorithms,[0],[0]
"It is an emerging field in NLP, with research still in relatively early stages.",2.3 Sentiment Analysis & Metaphor Detection Algorithms,[0],[0]
"A variety of different machine-learning and statistical methods have been applied to the task, including clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010; Shutova and Sun, 2013); topic models (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a,b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013, 2014; Klebanov et al.).",2.3 Sentiment Analysis & Metaphor Detection Algorithms,[0],[0]
"Metaphor detection methods differ in how they define the task of metaphor detection–for instance, some algorithms seek to determine whether a phrase (such as sweet victory) is metaphorical (Krishnakumaran and Zhu, 2007; Turney et al., 2011; Tsvetkov et al., 2014; Bracewell et al., 2014; Gutiérrez et al., 2016), while others attempt to tag metaphoricity at the level of the utterance (Dunn, 2013a), or at the level of individual tokens in running text (Klebanov et al.;",2.3 Sentiment Analysis & Metaphor Detection Algorithms,[0],[0]
"Schulder and Hovy, 2014; Do Dinh and Gurevych, 2016).",2.3 Sentiment Analysis & Metaphor Detection Algorithms,[0],[0]
"For a recent review, see Shutova (2015).",2.3 Sentiment Analysis & Metaphor Detection Algorithms,[0],[0]
"For our purposes, we decided that tokenlevel metaphor detection offered the most appropriate level of granularity, and we chose the algorithm of (Do Dinh and Gurevych, 2016) because of its state-of-the-art performance at this task at the time we began this project.",2.3 Sentiment Analysis & Metaphor Detection Algorithms,[0],[0]
"Our main data set1 consists of interviews with 17 patients who have suffered a first episode of schizophrenia (denoted by 1EP+) and 15 healthy
1Patient data are confidential and can only be used via a Data-Sharing Agreement with authors Corcoran and Corlett; please contact these authors for more information.
controls (denoted by 1EP-).",3.1 First-Episode Schizophrenia Transcripts,[0],[0]
"Healthy controls were obtained from the same source population as patients with schizophrenia in the metropolitan New York City region, using web-based advertising on Craigslist, as well as by posting of flyers in and around the region.",3.1 First-Episode Schizophrenia Transcripts,[0],[0]
"Participants engaged in open-ended interviews lasting approximately one hour, during which they were encouraged to express themselves narratively.",3.1 First-Episode Schizophrenia Transcripts,[0],[0]
"Participants were queried on four topics, for which interviewers provided clarifying questions if they were not spontaneously discussed.",3.1 First-Episode Schizophrenia Transcripts,[0],[0]
"The four discussion topics, as well as details of interviewer training and participant selection criteria, are discussed in more detail in the supplementary materials as well as in (BenDavid et al., 2014).",3.1 First-Episode Schizophrenia Transcripts,[0],[0]
Independent transcribers transcribed the interviews.,3.1 First-Episode Schizophrenia Transcripts,[0],[0]
Participants were matched for socioeconomic characteristics and education level.,3.1 First-Episode Schizophrenia Transcripts,[0],[0]
"The average age of the 1EP- cohort was 35, and the average age of the 1EP+ cohort was 39.",3.1 First-Episode Schizophrenia Transcripts,[0],[0]
"However, the 1EP- cohort was 47% male, while the 1EP+ cohort was 76% male.",3.1 First-Episode Schizophrenia Transcripts,[0],[0]
We refer to this data set as 1EP.,3.1 First-Episode Schizophrenia Transcripts,[0],[0]
"We use the data set introduced by Bedi et al. (2015) of transcripts from 34 youths at clinical high risk (CHR) for psychosis, based on the Structured Interview for Prodromal Syndromes (Miller et al., 2003).",3.2 Prodromal Psychosis Transcripts,[0],[0]
Demographic details are provided in Bedi et al. (2015).,3.2 Prodromal Psychosis Transcripts,[0],[0]
"There were no significant differences for age, gender, ethnicity or medication usage between CHR converters vs. CHR nonconverters.",3.2 Prodromal Psychosis Transcripts,[0],[0]
"Notably, all CHR participants were ascertained using gold-standard clinical measures for which the researchers obtained excellent interrater reliability with other CHR programs in North America.",3.2 Prodromal Psychosis Transcripts,[0],[0]
Open-ended baseline interviews were collected from the participants using the same protocol as above.,3.2 Prodromal Psychosis Transcripts,[0],[0]
Participants were then assessed quarterly for 2.5 years to determine whether they had transitioned to psychosis.,3.2 Prodromal Psychosis Transcripts,[0],[0]
Five of the participants suffered a first episode of psychosis within the assessment period (denoted by CHR+); the remainder did not (denoted by CHR-).,3.2 Prodromal Psychosis Transcripts,[0],[0]
The review of the literature in §2.2 suggests that a constellation of disturbances in metaphor use and extremeness/lability of sentiment may characterize schizophrenia.,4 Experiments,[0],[0]
"In order to assess whether these phenomena can truly distinguish patients
with schizophrenia from healthy controls or to predict future schizophrenic episodes, we produce five features.",4 Experiments,[0],[0]
"Four of these features are derived from sentiment scores produced by a sentiment analysis algorithm, and one is derived from metaphor tags produced by a metaphor identification algorithm.",4 Experiments,[0],[0]
Metaphoricity We hope to detect the alteration in metaphor production observed in patients with schizophrenia by Billow et al. (1997) using an automated metaphor detection algorithm that tag word tokens as metaphorical or not.,4.1 Feature Set,[0],[0]
We adapt the token-level metaphor identification algorithm of Do Dinh and Gurevych (2016) to our task.,4.1 Feature Set,[0],[0]
"In particular, we use a multilayer perceptron (MLP) architecture with three layers.",4.1 Feature Set,[0],[0]
"The input layer is comprised of the concatenation of the word embeddings for each token and the two tokens before and after (not including non-content tokens, and padded with a randomly created embedding at sentence beginnings and endings).",4.1 Feature Set,[0],[0]
"The vector for each token is composed of the word’s 300- dimensional Word2Vec skip-gram negative sampling word embedding 2, concatenated with a onehot binary vector that indicates the token’s part of speech.",4.1 Feature Set,[0],[0]
The hidden layer has ten fully connected hidden units with the hyperbolic tangent activation function.,4.1 Feature Set,[0],[0]
"The output node classifies a token as literal or metaphorical using the softmax activation function.
",4.1 Feature Set,[0],[0]
"Training is accomplished by minimizing a cross-entropy objective using stochastic gradient descent; the learning rate is decremented linearly during each epoch, for a maximum of 100 epochs.",4.1 Feature Set,[0],[0]
"As in Do Dinh and Gurevych (2016), the MLP is trained on the VU Amsterdam Metaphor Corpus (VUAMC), a subset of the BNC where each token has been annotated as metaphorical or not (Steen et al., 2010), using cross-validation with an 80%- 20% train-test split to optimize the regularization and learning rate parameters.
",4.1 Feature Set,[0],[0]
"We then measure the percentage of all tokens labeled metaphorical by the metaphor identification algorithm in each transcript, denoting it by Met.",4.1 Feature Set,[0],[0]
We present an example text tagged by this algorithm in figure 1.,4.1 Feature Set,[0],[0]
"Notably, the algorithm mistakenly tags the adverbially used preposition up in ended up as metaphorical; Do Dinh and Gurevych
2http://drive.google.com/file/d/ 0B7XkCwpI5KDYNlNUTTlSS21pQmM/
(2016) cite this as one of the common failure modes of their algorithm, along with failure to detect metaphors that are only clearly metaphorical from a large amount of surrounding context.
",4.1 Feature Set,[0],[0]
"Sentiment We posit that the sentiment scores produced by automated sentiment analysis algorithms should be able to detect disturbances in the production of emotional language, particularly in regard to metaphor.",4.1 Feature Set,[0],[0]
"To this end, we create two features that summarize the distribution of sentiment scores in each transcript.",4.1 Feature Set,[0],[0]
"In order to obtain tokenand phrase-level sentiment scores, we use the implementation of the Recursive Neural Tensor Network sentiment analysis algorithm (Socher et al., 2012) that is included in the Stanford CoreNLP toolkit, with default settings.",4.1 Feature Set,[0],[0]
This implementation comes pre-trained on the Stanford Sentiment Treebank.,4.1 Feature Set,[0],[0]
Tokens are tagged on an integer scale from 1 (Very Negative) to 5 (Very Positive).,4.1 Feature Set,[0],[0]
"For each transcript, we take the percentage of all tokenlevel sentiment scores that were either extremely positive (score of 1) or extremely negative (score of 5), which we denote by SentTok and similarly compute the percentage of all phrase-level sentiment scores, which we denote by SentPhr.",4.1 Feature Set,[0],[0]
"We also compute sentiment coherence as
1 N N∑ i=1",4.1 Feature Set,[0],[0]
|si,4.1 Feature Set,[0],[0]
"− si−1|
where the si denotes either the sentiment score for token i (to compute CohTok), or the sentiment score for phrase i (to compute CohPhr).",4.1 Feature Set,[0],[0]
"For all algorithms and data sets, we present results produced by leave-one-out cross-validation because of the small number of transcripts available.",4.2 Classification Algorithms,[0],[0]
We use a radial-basis-function supportvector classifier and a convex-hull classifier to classify transcripts based on the variables above.,4.2 Classification Algorithms,[0],[0]
The convex-hull classifier was previously used by Bedi et al. (2015).,4.2 Classification Algorithms,[0],[0]
"A test point is classified as originating from a CHR- participant if it lies within
the convex-hull of all the CHR- data points in the training set; otherwise, it is classified as CHR+.",4.2 Classification Algorithms,[0],[0]
"The intuition behind the convex-hull approach is that individuals that eventually develop psychosis do not necessarily do so following a unique path to conversion, and moreover psychosis itself cannot be considered a well-defined single condition (Binbay et al., 2012); thus it is reasonable to hypothesize that the “breakdown” of mental abilities may occur along different trajectories for individual CHR+ patients.",4.2 Classification Algorithms,[0],[0]
"As predicted, we find that the metaphor identification algorithm does indeed tag a significantly higher proportion of the tokens in the transcripts of patients with schizophrenia as metaphorical (6.3%) than in the healthy controls’ transcripts (5.2%); (t = 3.76, p < .001).",5.1 Statistical Analysis,[0],[0]
No significant difference was found between the other variables of interest between patients with schizophrenia and healthy controls.,5.1 Statistical Analysis,[0],[0]
"No significant difference was found between males and females in metaphor use frequency (t = 1.105, p = 0.28).",5.1 Statistical Analysis,[0],[0]
"First-Episode Schizophrenia Transcripts Table 1 shows the performance of classifiers that individually use each of the five features §4.1 as predictors, as well as the classifier that uses all five in tandem (All)3.",5.2 Classification Performance,[0],[0]
"Baseline represents the results of a simple majority classifier (because 18 of the 33 transcripts belonged to patients with schizophrenia, this entails classifying all transcripts as belonging to patients with schizophrenia).",5.2 Classification Performance,[0],[0]
"Because the 1EP set was not balanced for gender or age, we also present the results of classifying men as having schizophrenia and women as not having schizophrenia (Gender) as well as the results of training a classifier on age (Age).",5.2 Classification Performance,[0],[0]
"Bedi and Mota represent the classification results attained by applying the features/method of Bedi et al. (2015) and Mota et al. (2012), respectively.",5.2 Classification Performance,[0],[0]
Using all of the features to train the support-vector classifier performed better than using any of the features individually.,5.2 Classification Performance,[0],[0]
"The accuracy of the classifier based on all the features was significantly better than baseline (Fisher’s exact test, p < .005).",5.2 Classification Performance,[0],[0]
"Notably, our features outperformed the features
3The All classifier does not use gender or age features.
suggested by Bedi et al. (2015) and by Mota et al. (2012).
",5.2 Classification Performance,[0],[0]
"Prodromal Psychosis Transcripts On the prodromal transcripts, a classifier trained on all the features once again outperformed classifiers on any of the features individually, which performed at or near baseline.",5.2 Classification Performance,[0],[0]
"Interestingly, the convex-hull classifier outperformed the support vector classifier on this data.",5.2 Classification Performance,[0],[0]
The convex-hull classifier trained on all five features correctly identified the outcome of 33 of the 34 CHR patients (97.1% accuracy).,5.2 Classification Performance,[0],[0]
The sole patient who was misclassified belonged to the CHR+ group.,5.2 Classification Performance,[0],[0]
"This is comparable to the 100% accuracy of the Bedi et al. (2015) method and superior to the 79.4% accuracy of the Mota et al. (2012) method.
",5.2 Classification Performance,[0],[0]
"In order to explore the relationship between the two data sets, we also applied the best classifier trained on the 1EP data to the prodromal data.",5.2 Classification Performance,[0],[0]
"Interestingly, the 1EP classifier tagged 29 of the 34 CHR patients as patients with schizophrenia, including all five patients in the CHR+ group.",5.2 Classification Performance,[0],[0]
The hypersensitivity of the 1EP classifier when applied to the prodromal data suggests that the cues that discriminate between patients with first-episode schizophrenia and healthy controls tend to place CHR patients into the same category as patients with first-episode schizophrenia.,5.2 Classification Performance,[0],[0]
It is worth noting that the classifier tagged all of the CHR+ patients as 1EP+.,5.2 Classification Performance,[0],[0]
We believe this indicates that our method would be useful as a tool meant to channel limited attention and resources toward patients with particularly high risk (above and beyond the criteria that currently flag a patient as being CHR).,5.2 Classification Performance,[0],[0]
"To our knowledge, this study is the first to demonstrate the utility of automated metaphor identification algorithms in a public-health setting,
and particularly for the prediction or detection of schizophrenia.",6 Conclusion,[0],[0]
"Our algorithm’s performance on the task of schizophrenia diagnosis from transcripts outperforms the two existing methods detailed in existing literature.
",6 Conclusion,[0],[0]
"Our results also contribute to clinical knowledge of the nature of language-use abnormalities in schizophrenia, as they support previous research which finds that those suffering from schizophrenia produce more metaphors in free speech than healthy controls.",6 Conclusion,[0],[0]
"Previously it was only possible to measure such disturbances by labor-intensive and subjective hand-coding of transcripts for metaphoricity, or by the assessment of expert clinicians, whose time is limited.",6 Conclusion,[0],[0]
"This work breaks new ground by showing that such disturbances can be measured in an automated and reproducible fashion, using features generated via machine learning.
",6 Conclusion,[0],[0]
Our work is somewhat constrained by the small sample size available to us.,6 Conclusion,[0],[0]
"As our data comes from a vulnerable population, obtaining a larger data set is challenging, but essential for future work.",6 Conclusion,[0],[0]
"In fact, two of the authors are in the process of collecting data from a total of 120 CHR individuals.",6 Conclusion,[0],[0]
"This would enable a more thorough investigation of a larger and more sophisticated suite of linguistic features, and especially a more finegrained analysis of the interaction of metaphor and emotional language in schizophrenia.",6 Conclusion,[0],[0]
This work was funded in part via NIMH grants R01MH107558 and R03MH108933.,Acknowledgments,[0],[0]
The authors have no conflicts to declare.,Acknowledgments,[0],[0]
The diagnosis of serious mental health conditions such as schizophrenia is based on the judgment of clinicians whose training takes many years and cannot be easily formalized into objective measures.,abstractText,[0],[0]
"However, clinical research suggests there are disturbances in aspects of the language use of patients with schizophrenia, which opens a door for the use of NLP tools in schizophrenia diagnosis and prognosis.",abstractText,[0],[0]
"Using metaphor-identification and sentiment-analysis algorithms to automatically generate features, we create a classifier that, with high accuracy, can predict which patients will develop (or currently suffer from) schizophrenia.",abstractText,[0],[0]
"To our knowledge, this study is the first to demonstrate the utility of automated metaphor identification algorithms for detection or prediction of disease.",abstractText,[0],[0]
Using Automated Metaphor Identification to Aid in Detection and Prediction of First-Episode Schizophrenia,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 33–43, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
Center-embedding is difficult to process and is known as a rare syntactic construction across languages. In this paper we describe a method to incorporate this assumption into the grammar induction tasks by restricting the search space of a model to trees with limited centerembedding. The key idea is the tabulation of left-corner parsing, which captures the degree of center-embedding of a parse via its stack depth. We apply the technique to learning of famous generative model, the dependency model with valence (Klein and Manning, 2004). Cross-linguistic experiments on Universal Dependencies show that often our method boosts the performance from the baseline, and competes with the current state-ofthe-art model in a number of languages.",text,[0],[0]
"Human languages in the world are divergent, but they also exhibit many striking similarities (Greenberg, 1963; Hawkins, 2014).",1 Introduction,[0],[0]
"At the level of syntax, one attractive hypothesis for such regularities is that any grammars of languages have evolved under the pressures, or biases, to avoid structures that are difficult to process.",1 Introduction,[0],[0]
"For example it is known that many languages have a preference for shorter dependencies (Gildea and Temperley, 2010; Futrell et al., 2015), which originates from the difficulty in processing longer dependencies (Gibson, 2000).
",1 Introduction,[0],[0]
"Such syntactic regularities can also be useful in applications, in particular in unsupervised (Klein and Manning, 2004; Mareček and Žabokrtský,
2012; Bisk and Hockenmaier, 2013) or weaklysupervised (Garrette et al., 2015) grammar induction tasks, where the models try to recover the syntactic structure of language without access to the syntactically annotated data, e.g., from raw or partof-speech tagged text only.",1 Introduction,[0],[0]
"In these settings, finding better syntactic regularities universal across languages is essential, as they work as a small cue to the correct linguistic structures.",1 Introduction,[0],[0]
"A preference exploited in many previous works is favoring shorter dependencies, which has been encoded in various ways, e.g., initialization of EM (Klein and Manning, 2004), or model parameters (Smith and Eisner, 2006), and this has been the key to success of learning (Gimpel and Smith, 2012).
",1 Introduction,[0],[0]
"In this paper, we explore the utility for another universal syntactic bias that has not yet been exploited in grammar induction: a bias against centerembedding.",1 Introduction,[0],[0]
Center-embedding is a syntactic construction on which a clause is embedded into another one.,1 Introduction,[0],[0]
"An example is “The reporter [who the senator [who Mary met] attacked] ignored the president.”, where “who Mary met” is embedded in a larger relative clause.",1 Introduction,[0],[0]
"These constructions are known to cause memory overflow (Miller and Chomsky, 1963; Gibson, 2000), and also are rarely observed crosslinguistically (Karlsson, 2007; Noji and Miyao, 2014).",1 Introduction,[0],[0]
Our learning method exploits this universal property of language.,1 Introduction,[0],[0]
"Intuitively during learning our models explore the restricted search space, which excludes linguistically implausible trees, i.e., those with deeper levels of center-embedding.
",1 Introduction,[0],[0]
We describe how these constraints can be imposed in EM with the inside-outside algorithm.,1 Introduction,[0],[0]
"The central
33
idea is to tabulate left-corner parsing, on which its stack depth captures the degree of center-embedding of a partial parse.",1 Introduction,[0],[0]
Each chart item keeps the current stack depth and we discard all items where the depth exceeds some threshold.,1 Introduction,[0],[0]
"The technique is general and can be applicable to any model on PCFG; in this paper, specifically, we describe how to apply the idea on the dependency model with valence (DMV) (Klein and Manning, 2004), a famous generative model for dependency grammar induction.
",1 Introduction,[0],[0]
"We focus our evaluation on grammar induction from part-of-speech tagged text, comparing the effect of several biases including the one against longer dependencies.",1 Introduction,[0],[0]
"Our main empirical finding is that though two biases, avoiding center-embedding and favoring shorter dependencies, are conceptually similar (both favor simpler grammars), often they capture different aspects of syntax, leading to different grammars.",1 Introduction,[0],[0]
"In particular our bias cooperates well with additional small syntactic cue such as the one that the sentence root tends to be a verb or a noun, with which our models compete with the strong baseline relying on a larger number of hand crafted rules on POS tags (Naseem et al., 2010).
",1 Introduction,[0],[0]
"Our contributions are: the idea to utilize leftcorner parsing for a tool to constrain the models of syntax (Section 3), the formulation of this idea for DMV (Section 4), and cross-linguistic experiments across 25 languages to evaluate the universality of the proposed approach (Sections 5 and 6).",1 Introduction,[0],[0]
"We first describe (arc-eager) left-corner (LC) parsing as a push-down automaton (PDA), and then reformulate it as a grammar transform.",2 Left-corner parsing,[0],[0]
"In previous work this algorithm has been called right-corner parsing (e.g., Schuler et al. (2010)); we avoid this term and instead treat it as a variant of LC parsing following more recent studies, e.g., van Schijndel
and Schuler (2013).",2 Left-corner parsing,[0],[0]
The central motivation for this technique is to detect center-embedding in a parse efficiently.,2 Left-corner parsing,[0],[0]
We describe this mechanism after providing the algorithm itself.,2 Left-corner parsing,[0],[0]
"We then give historical notes on LC parsing at the end of this section.
",2 Left-corner parsing,[0],[0]
"PDA Let us assume a CFG is given, and it is in CNF.",2 Left-corner parsing,[0],[0]
"We formulate LC parsing as a set of transitions between configurations, each of which is a pair of the stack and the input position (next input symbol).",2 Left-corner parsing,[0],[0]
"In Figure 1 a transition σ1
a7−→ σ2 means that the stack is changed from σ1 to σ2 by reading the next input symbol a.",2 Left-corner parsing,[0],[0]
"We use a vertical bar to signify the append operation, e.g., σ = σ′|σ1 denotes σ1 is the topmost symbol of σ.",2 Left-corner parsing,[0],[0]
"Each stack symbol is either a nonterminal, or a pair of nonterminals, e.g., A/B, which represents a subtree rooted at A and is awaiting symbol B. We also decorate each symbol with depth; for example, σd−1|Ad means the current stack depth is d, and the depth of the topmost symbol in σ is d− 1.",2 Left-corner parsing,[0],[0]
The bottom symbol on the stack is always the empty symbol ε0 with depth 0.,2 Left-corner parsing,[0],[0]
Parsing begins with ε0.,2 Left-corner parsing,[0],[0]
"Given the start symbol of CFG S, it finishes when S1 is found on the stack.
",2 Left-corner parsing,[0],[0]
The key transition here is COMP (Figure 2).1,2 Left-corner parsing,[0],[0]
Basically the algorithm builds a tree by expanding the hypothesis from left to right.,2 Left-corner parsing,[0],[0]
"In COMP, a subtree rooted at A is combined with the second top subtree (D/B) on the stack.",2 Left-corner parsing,[0],[0]
This can be done by first predicting that A’s parent symbol is B and its sibling is C; then it unifies two different Bs to combine them.,2 Left-corner parsing,[0],[0]
"PRED is simpler, and it just predicts the parent and sibling symbols of A. The input symbols are read by SHIFT and SCAN: SHIFT addes a new element on the stack while SCAN fills in the predicted sibling symbol.",2 Left-corner parsing,[0],[0]
"For an example, Figure 3 shows how
1van Schijndel and Schuler (2013) employ different transition names, e.g., L- and L+; we avoid them as they are less informative.
",2 Left-corner parsing,[0],[0]
"this PDA works for parsing a tree in Figure 4(a).
",2 Left-corner parsing,[0],[0]
"Grammar transform The algorithm above can be reformulated as a grammar transform, which becomes the starting point for our application to grammar induction.",2 Left-corner parsing,[0],[0]
"This can be done by extracting the operated top symbols on the stack in each transition:
SHIFT:",2 Left-corner parsing,[0],[0]
Ad → a (A→ a ∈ P ); SCAN:,2 Left-corner parsing,[0],[0]
Bd → B/Ad a (A→ a ∈ P );,2 Left-corner parsing,[0],[0]
"PRED: B/Cd → Ad (B → A C ∈ P ); COMP: D/Cd → D/Bd Ad+1 (B → A C ∈ P ).
where a rule on the right side is a condition given the set of rules P in the CFG.
",2 Left-corner parsing,[0],[0]
Figure 4 shows an example of this transform.,2 Left-corner parsing,[0],[0]
The essential point is that each CFG rule in the transformed parse (b) corresponds to a transition in the original algorithm (Figure 1).,2 Left-corner parsing,[0],[0]
For example a rule D/C1 → D/B1 A2 in the parse indicates that the stack configuration D/B1|A2 occurs during parsing (just corresponding to the step 5 in Figure 3) and COMP is then applied.,2 Left-corner parsing,[0],[0]
"This can also be seen as an instantiation of Figure 2.
",2 Left-corner parsing,[0],[0]
"Stack depth and center-embedding We use the term center-embedding to distinguish just the tree structures, i.e., ignoring symbols.",2 Left-corner parsing,[0],[0]
"That is, the tree
in Figure 4(a) is the minimal, one degree of centerembedded tree, where the constituent rooted at A is embedded into a larger constituent rooted at D. Multiple, or degree ≥ 2 of center-embedding occurs if this constituent is also embedded into another larger constituent.
",2 Left-corner parsing,[0],[0]
Note that it is only COMP that consumes the top two symbols on the stack.,2 Left-corner parsing,[0],[0]
This means that a larger stack depth occurs only when COMP is needed.,2 Left-corner parsing,[0],[0]
"Furthermore, from Figure 2 COMP always induces a subtree involving new center-embedding, and this is the underlying mechanism that the stack depth of the algorithm captures the degree of center-embedding.
",2 Left-corner parsing,[0],[0]
"One thing to note is that to precisely associate the stack depth and the degree of center-embedding the depth calculation in COMP should be revised as:
COMP: D/Cd → D/Bd Ad′ (B → A C ∈ P )
d′ = {
d (SPANLEN(A) = 1) d+ 1 (otherwise), (1)
where SPANLEN(A) calculates the span length of the constituent rooted atA, which is 2 in Figure 4(b).",2 Left-corner parsing,[0],[0]
"This modification is necessary since COMP for a single token occurs for building purely right-branching structures.2 Formally, then, given a tree with degree λ of center-embedding the largest stack depth d∗ during parsing this tree is: d∗ = λ+ 1.
",2 Left-corner parsing,[0],[0]
Schuler et al. (2010) found that on English treebanks larger stack depth such as 3 or 4 rarely occurs while Noji and Miyao (2014) validated the language universality of this observation through crosslinguistic experiments.,2 Left-corner parsing,[0],[0]
"These suggest we may utilize LC parsing as a tool for exploiting universal syntactic biases as we discuss in Section 3.
",2 Left-corner parsing,[0],[0]
Historical notes Rosenkrantz and Lewis (1970) first presented the idea of LC parsing as a grammar transform.,2 Left-corner parsing,[0],[0]
"This is arc-standard, and has no relevance to center-embedding; Resnik (1992) and Johnson (1998) formulated an arc-eager variant by extending this algorithm.",2 Left-corner parsing,[0],[0]
"The presented algorithm here is the same as Schuler et al. (2010), and is slightly different from Johnson (1998).",2 Left-corner parsing,[0],[0]
"The difference is in the start and end conditions: while
2Schuler et al. (2010) skip this subtlety by only concerning stack depth after PRED or COMP.",2 Left-corner parsing,[0],[0]
"We do not take this approach since ours allows a flexible extension described in Section 3.
",2 Left-corner parsing,[0],[0]
"our parser begins with an empty symbol, Johnson’s parser begins with the predicted start symbol, and finishes with an empty symbol.",2 Left-corner parsing,[0],[0]
Now we discuss how to utilize LC parsing for grammar induction in general.,3 Learning with structural constraints,[0],[0]
"An important observation in the above transform is that if we perform chart parsing, e.g., CKY, we can detect center-embedded trees efficiently in a chart.",3 Learning with structural constraints,[0],[0]
"For example, by setting a threshold of stack depth δ, we can eliminate any parses involving center-embedding up to degree δ−1.",3 Learning with structural constraints,[0],[0]
"Note that in a probabilistic setting, each weight of a transformed rule comes from the corresponding underlying CFG rule (i.e., the condition).
",3 Learning with structural constraints,[0],[0]
"For learning, our goal is to estimate θ of a generative model p(z, x|θ) for parse z and its yields (words) x.",3 Learning with structural constraints,[0],[0]
"We take an EM-based simplest approach, and multiply the original model by a constraint factor f(z, x) ∈",3 Learning with structural constraints,[0],[0]
"[0, 1] to obtain a new model:
p′(z, x|θ) ∝",3 Learning with structural constraints,[0],[0]
"p(z, x|θ)f(z, x), (2)
and then optimize θ based on p′(z, x|θ).",3 Learning with structural constraints,[0],[0]
This is essentially the same approach as Smith and Eisner (2006).,3 Learning with structural constraints,[0],[0]
"As shown in Smith (2006), when training with EM we can increase the likelihood of p′(z, x|θ) by just using the expected counts from an E-step on the unnormalized distribution p(z, x|θ)f(z, x).
",3 Learning with structural constraints,[0],[0]
"We investigate the following constraints in our experiments:
f(z, x) = { 0 (d∗z > δ) 1 (otherwise),
(3)
where d∗z is the largest stack depth for z in LC parsing and δ is the threshold.",3 Learning with structural constraints,[0],[0]
"This is a hard constraint, and can easily be achieved by removing all chart items (of LC transformed grammar) on which the depth of the symbol exceeds δ.",3 Learning with structural constraints,[0],[0]
"For example, when δ = 1 the model only explores trees without centerembedding, i.e., right- or left-linear trees.
",3 Learning with structural constraints,[0],[0]
"Length-based constraints By δ = 2, the model is allowed to explore trees with one degree of centerembedding.",3 Learning with structural constraints,[0],[0]
"Besides these simple ones, we also investigate relaxing δ",3 Learning with structural constraints,[0],[0]
= 1 that results in an intermediate between δ = 1 and 2.,3 Learning with structural constraints,[0],[0]
"Specifically, we relax the
depth calculation in COMP (Eq. 1) as follows:
d′ = {
d (SPANLEN(A) ≤ ξ) d+ 1 (otherwise),
(4)
where ξ ≥ 1 controls the minimal length of a span regarded as embedded into another one.",3 Learning with structural constraints,[0],[0]
"For example, when ξ = 2, the parse in Figure 4(a) is not regarded as center-embedded because the span length of the constituent reduced by COMP (i.e., A) is 2.
",3 Learning with structural constraints,[0],[0]
"This modification is motivated with our observation that in many cases center-embedded constructions arise due to embedding of small chunks, rather than clauses.",3 Learning with structural constraints,[0],[0]
"An example is “... prepared [the cat ’s] dinner”, where “the cat ’s” is center-embedded in our definition.",3 Learning with structural constraints,[0],[0]
"For this sentence, by relaxing the condition with, e.g., ξ = 3, we can suppress the increase of stack depth.",3 Learning with structural constraints,[0],[0]
"We treat ξ as a hyperparameter in our experiments, and in practice, we find that this relaxed constraint leads to higher performance.",3 Learning with structural constraints,[0],[0]
"In this section we discuss how we can formulate the dependency model with valence (DMV) (Klein and Manning, 2004), a famous generative model for dependency grammar induction, on LC parsing.",4 Dependency grammar induction,[0],[0]
"Though as we will see, applying LC parsing for a dependency model is a little involved compared to simple PCFG models, dependency models have been the central for the grammar induction tasks, and we consider it is most appropriate for assessing effectiveness of our approach.
",4 Dependency grammar induction,[0],[0]
"DMV is a head-outward generative model of a dependency tree, controlled by two types of multinomial distributions.",4 Dependency grammar induction,[0],[0]
"For stop ∈ {STOP,¬STOP}, θS(stop|h, dir, adj) is a Bernoulli random variable to decide whether or not to attach further dependents in dir ∈ {←,→} direction.",4 Dependency grammar induction,[0],[0]
"The adjacency adj ∈ {TRUE, FALSE} is the key factor to distinguish the distributions of the first and the other dependents, which is TRUE if h has no dependent yet in dir direction.",4 Dependency grammar induction,[0],[0]
"Another type of parameter is θA(a|h, dir), a probability that h takes a as a dependent in dir direction.
",4 Dependency grammar induction,[0],[0]
"For this particular model, we take the following approach to formulate it in LC parsing: 1) converting a dependency tree into a binary CFG parse; 2) applying LC transform on it; and 3) encoding DMV
parameters into each CFG rule of the transformed grammar.3",4 Dependency grammar induction,[0],[0]
"Below we discuss a problem for (1) and (2), and then consider parameterization.4
Spurious ambiguity The central issue for applying LC parsing is the spurious ambiguity in dependency grammars.",4 Dependency grammar induction,[0],[0]
"That is, there are more than one (binary) CFG parses corresponding to a given dependency tree.",4 Dependency grammar induction,[0],[0]
"This is problematic mainly for two reasons: 1) we cannot specify the degree of centerembedding in a dependency tree uniquely; and 2) this one-to-many mapping prevents the insideoutside algorithm to work correctly (Eisner, 2000).
",4 Dependency grammar induction,[0],[0]
"As a concrete example, Figures 5(a) and 5(c) show two CFG parses corresponding to the dependency tree dogsxranyfast.",4 Dependency grammar induction,[0],[0]
"We approach this problem by first providing a grammar transform, which generates all valid LC transformed parses (e.g., Figures 5(b) and 5(d)) and then restricting the grammar
3Another approach might be just applying the technique in Section 3 to some PCFG that encodes DMV, e.g., Headden III et al. (2009).",4 Dependency grammar induction,[0],[0]
"The problem with this approach, in particular with split-head grammars (Johnson, 2007), is that the calculated stack depth no longer reflects the degree of center-embedding in the original parse correctly.",4 Dependency grammar induction,[0],[0]
"As we discuss later, instead, we can speed up inference by applying head-splitting after obtaining the LC transformed grammar.
",4 Dependency grammar induction,[0],[0]
"4Technical details including the chart algorithm for splithead grammars can be found in the Ph.D. thesis of the first author (Noji, 2016).
for generating particular parses only.
",4 Dependency grammar induction,[0],[0]
"Naive method Let us begin with the grammar below, which suffers from the spurious ambiguity:
SHIFT:",4 Dependency grammar induction,[0],[0]
X[wh]d → wh SCAN: X[wh]d → X[wh/wp]d wp L-PRED: X[wp/wp]d → X[wh]d (wxh wp); R-PRED: X[wh/wp]d → X[wh]d (wyh wp); L-COMP: X[wh/wp]d → X[wh/wp]dX[wa]d ′,4 Dependency grammar induction,[0],[0]
(wxa wp); R-COMP: X[wh/wa]d → X[wh/wp]dX[wp]d ′,4 Dependency grammar induction,[0],[0]
"(wyp wa).
",4 Dependency grammar induction,[0],[0]
Here X[a/b] denotes X[a]/X[b] while wh denotes the h-th word in the sentence w.,4 Dependency grammar induction,[0],[0]
We can interpret these rules as the operations on chart items (Figure 6).,4 Dependency grammar induction,[0],[0]
Note that only PRED and COMP create new dependency arcs and we divide them depending on the direction of the created arcs (L and R).,4 Dependency grammar induction,[0],[0]
d′ is calculated by Eq. 4.,4 Dependency grammar induction,[0],[0]
"Note also that for L-COMP and RCOMP h might equal p; X[ran/fast]1 → X[ran/ran]1 X[ran]2 in Figure 5(d) is such a case for R-COMP.
",4 Dependency grammar induction,[0],[0]
"Removing spurious ambiguity We can show that by restricting conditions for some rules, the spurious ambiguity can be eliminated (the proof is omitted).
1.",4 Dependency grammar induction,[0],[0]
"Prohibit R-COMP when h = p;
2.",4 Dependency grammar induction,[0],[0]
"Assume the span of X[wp]d ′
is (i, j) (i ≤ p ≤ j).",4 Dependency grammar induction,[0],[0]
"Then allow R-COMP only when i = p.
Intuitively, these conditions constraint the order that each word collects its left and right children.",4 Dependency grammar induction,[0],[0]
"For
example, by the condition 1, this grammar is prohibited to generate the parse of Figure 5(d).
",4 Dependency grammar induction,[0],[0]
Binarization Note that two CFG parses in Figures 5(a) and 5(c) differ in how we binarize a given dependency tree.,4 Dependency grammar induction,[0],[0]
"This observation indicates that our restricted grammar implicitly binarizes a dependency tree, and the incurred stack depth (or the degree of center-embedding) is determined based on the structure of the binarized tree.",4 Dependency grammar induction,[0],[0]
"Specifically, we can show that the presented grammar performs optimal binarization; i.e., it minimizes the incurred stack depth.",4 Dependency grammar induction,[0],[0]
"Figure 7 shows an example, which is not regarded as center-embedded in our procedure.",4 Dependency grammar induction,[0],[0]
"In summary, our method detects center-embedding for a dependency tree, but the degree is determined based on the structure of the binarized CFG parse.
",4 Dependency grammar induction,[0],[0]
Parameterization We can encode DMV parameters into each rule.,4 Dependency grammar induction,[0],[0]
"A new arc is introduced by one of {L/R}-{PRED/COMP}, and the stop probabilities can be assigned appropriately in each rule by calculating the valence from indices in the rule.",4 Dependency grammar induction,[0],[0]
"For example, after L-PRED, wh does not take any right dependents so θS(stop|wh,→, h = j), where j is the right span index of X[wh], is multiplied.
",4 Dependency grammar induction,[0],[0]
"Improvement Though we omit the details, we can improve the time complexity of the above grammar from O(n6) to O(n4) applying the technique similar to Eisner and Satta (1999) without changing the binarization mechanism mentioned above.",4 Dependency grammar induction,[0],[0]
We implemented this improved grammar.,4 Dependency grammar induction,[0],[0]
"A sound evaluation metric in grammar induction is known as an open problem (Schwartz et al., 2011; Bisk and Hockenmaier, 2013), which essentially arises from the ambiguity in the notion of head.",5 Experimental setup,[0],[0]
"For example, Universal dependencies (UD) is the recent standard in annotation and prefers content words to be heads, but as shown below this is very different from the conventional style, e.g., the one in CoNLL shared tasks (Johansson and Nugues, 2007):
Ivan is the best dancer
nsbj cop
det amod
sbj nmod
nmod
prd
UD
CONLL
The problem is that both trees are correct under some linguistic theories but the standard metric, unlabeled attachment score (UAS), only takes into account the annotation of the current gold data.
",5 Experimental setup,[0],[0]
Our goal in this experiment is to assess the effect of our structural constraints.,5 Experimental setup,[0],[0]
"To this end, we try to eliminate such arbitrariness in our evaluation as much as possible in the following way:
• We experiment on UD, in which every treebank follows the consistent UD style annotation.
",5 Experimental setup,[0],[0]
"• We restrict the model to explore only trees that follow the UD style annotation during learning5, by prohibiting every function word6 in a sentence to have any dependents.
",5 Experimental setup,[0],[0]
"• We calculate UAS in a standard way.
",5 Experimental setup,[0],[0]
We use UD of version 1.2.,5 Experimental setup,[0],[0]
"Some treebanks are very small, so we select the top 25 largest languages.",5 Experimental setup,[0],[0]
The input to the model is coarse universal POS tags.,5 Experimental setup,[0],[0]
Punctuations are stripped off.,5 Experimental setup,[0],[0]
"All models are trained on sentences of length ≤ 15 and tested on ≤ 40.
",5 Experimental setup,[0],[0]
"Initialization Much previous work of dependency grammar induction relies on the technique called harmonic initialization, which also biases the model towards shorter dependencies (Klein and Manning, 2004).",5 Experimental setup,[0],[0]
"Since our focus is to see the effect of structural constraints, we do not try this and initialize models uniformly.",5 Experimental setup,[0],[0]
"However, we add a baseline model with this initialization in our comparison to see the relative strength of our approach.
",5 Experimental setup,[0],[0]
"Models For the baseline, we employ a variant of DMV with features (Berg-Kirkpatrick et al., 2010), which is simple yet known to boost the performance well.",5 Experimental setup,[0],[0]
"The feature templates are almost the same; the only change is that we add backoff features for STOP probabilities that ignore both direction and adjacency, which we found slightly improves the performance in a preliminary experiment.",5 Experimental setup,[0],[0]
We set the regularization parameter to 10 though in practice we found the model is less sensitive to this value.,5 Experimental setup,[0],[0]
We run 100 iterations of EM for each setting.,5 Experimental setup,[0],[0]
"The dif-
5We remove the restriction at test time though we found it does not affect the performance.
",5 Experimental setup,[0],[0]
"6A word with one of the following POS tags: ADP, AUX, CONJ, DET, PART, and",5 Experimental setup,[0],[0]
"SCONJ.
ference of each model is then the type of constraints imposed during the E-step7, or initialization:
• Baseline (FUNC): Function word constraints; • HARM:",5 Experimental setup,[0],[0]
FUNC with harmonic initialization; • DEP: FUNC + stack depth constraints (Eq. 3); • LEN:,5 Experimental setup,[0],[0]
"FUNC + soft dependency length bias,
which we describe below.
",5 Experimental setup,[0],[0]
"For DEP, we use δ = 1.ξ to denote the relaxed maximum depth allowing span length up to ξ (Eq. 4).
",5 Experimental setup,[0],[0]
"LEN is the previously explored structural bias (Smith and Eisner, 2006), which penalizes longer dependencies by modifying each attachment score:
θ′A(a|h, dir) =",5 Experimental setup,[0],[0]
"θA(a|h, dir) · e−γ·(|h−a|−1), (5)
where γ (≥ 0) determines the strength of the bias and |h− a| is (string) distance between h and a.
Note that DEP and LEN are closely related; generally center-embedded constructions are accompanied by longer dependencies so LEN also penalizes center-embedding implicitly.",5 Experimental setup,[0],[0]
"However, the opposite is not true and there exist many constructions with longer dependencies without center-embedding.",5 Experimental setup,[0],[0]
"By comparing these two settings, we discuss the worth of focusing on constraining center-embedding relative to the simpler bias on dependency length.
",5 Experimental setup,[0],[0]
Finally we also add the system of Naseem et al. (2010) in our comparison.,5 Experimental setup,[0],[0]
This system encodes many manually crafted rules between POS tags with the posterior regularization technique.,5 Experimental setup,[0],[0]
"For example, the model is encouraged to find NOUN → ADJ relationship.",5 Experimental setup,[0],[0]
"Our systems cannot access to these core grammatical rules so it is our strongest baseline.8
Constraining root word We also see the effects of the constraints when a small amount of grammatical rule is provided.",5 Experimental setup,[0],[0]
"In particular, we restrict the candidate root words of the sentence to a noun or a verb; similar rules have been encoded in past work such as Gimpel and Smith (2012) and the CCG induction system of Bisk and Hockenmaier (2013).
",5 Experimental setup,[0],[0]
"7We again remove the restrictions at decoding as we observed that the effects are very small.
8We encode the customized rules that follow UD scheme.",5 Experimental setup,[0],[0]
"The following 13 rules are used: ROOT → VERB, ROOT → NOUN, VERB→ NOUN, VERB→ ADV, VERB→ VERB, VERB → AUX, NOUN→ ADJ, NOUN→ DET, NOUN→ NUM, NOUN → NOUN, NOUN→ CONJ, NOUN→ ADP, ADJ→ ADV.
",5 Experimental setup,[0],[0]
"Hyperparameters Selecting hyperparameters in multilingual grammar induction is difficult; some works tune values for each language based on the development set (Smith and Eisner, 2006; Bisk et al., 2015), but this violates the assumption of unsupervised learning.",5 Experimental setup,[0],[0]
"We instead follow many works (Mareček and Žabokrtský, 2012; Naseem et al., 2010) and select the values with the English data.",5 Experimental setup,[0],[0]
"For this, we use the WSJ data, which we obtain in UD style from the Stanford CoreNLP (ver. 3.6.0).9",5 Experimental setup,[0],[0]
WSJ Figure 8 shows the result on WSJ.,6 Experiments,[0],[0]
"Both DEP and LEN have one parameter: the maximum depth δ, and γ (Eq. 5), and the figure shows the sensitivity on them.",6 Experiments,[0],[0]
"Note that x-axis = 0 represents FUNC.
",6 Experiments,[0],[0]
"For LEN, we can see the optimal parameter γ is 0.1, and degrades the performance when increasing the value; i.e., the small bias is the best.",6 Experiments,[0],[0]
"For DEP, we find the best setting is 1.3, i.e., allowing embedded constituents of length 3 or less (ξ = 3 in Eq. 4).",6 Experiments,[0],[0]
"We can see that allowing depth 2 degrades the performance, indicating that depth 2 allows too many trees and does not reduce the search space effectively.10
Multilingual results Table 1 shows the main multilingual results.",6 Experiments,[0],[0]
"When we see “No root constraint” block, we notice that our DEP boosts the performance in many languages (e.g., Bulgarian, French,
9Note that the English data in UD is Web Treebank (Silveira et al., 2014), not the standard WSJ Penn treebank.
",6 Experiments,[0],[0]
"10We see the same effects when training with longer sentences (e.g., length ≤ 20).",6 Experiments,[0],[0]
This is probably because a looser constraint does nothing for shorter sentences.,6 Experiments,[0],[0]
"In other words, the model can restrict the search space only for longer sentences, which are relatively small in the data.
",6 Experiments,[0],[0]
"Indonesian, and Portuguese), though LEN performs equally well and in average, LEN performs slightly better.",6 Experiments,[0],[0]
"Harmonic initialization does not work well.
",6 Experiments,[0],[0]
We then move on to the settings with the constraint on root tags.,6 Experiments,[0],[0]
"Interestingly, in these settings DEP performs the best.",6 Experiments,[0],[0]
"The model competes with Naseem et al.’s system in average, and outperforms it in many languages, e.g., Bulgarian, Czech, etc. LEN, on the other hand, decreases the average score.
",6 Experiments,[0],[0]
Analysis Why does DEP perform well in particular with the restriction on root candidates?,6 Experiments,[0],[0]
"To shed light on this, we inspected the output parses of English with no root constraints, and found that the types of errors are very different across constraints.
",6 Experiments,[0],[0]
Figure 9 shows a typical example of the difference.,6 Experiments,[0],[0]
One difference between trees is in the constructions of phrase “On ... pictures”.,6 Experiments,[0],[0]
"LEN predicts that “On the next two” comprises a constituent, which modifies “pictures” while DEP predicts that “the ... pictures” comprises a constituent, which is correct, although the head of the determiner is incorrectly predicted.",6 Experiments,[0],[0]
"On the other hand, LEN works well to find more primitive dependency arcs between POS tags, such as arcs from verbs to nouns, which are often incorrectly recognized by DEP.
",6 Experiments,[0],[0]
"These observations may partially answer the
question above.",6 Experiments,[0],[0]
"The main source of improvements by DEP is detections of constituents, but this constraint itself does not help to resolve some core dependency relationships, e.g., arcs from verbs to nouns.",6 Experiments,[0],[0]
"The constraint on root POS tags is thus orthogonal to this approach, and it may help to find such core dependencies.",6 Experiments,[0],[0]
"On the other hand, the dependency length bias is the most effective to find basic dependency relationships between POS tags while the resulting tree may involve implausible constituents.",6 Experiments,[0],[0]
"Thus the effect of the length bias seems somewhat overlapped with the root POS constraints, which may be the reason why they do not well collaborate with each other.
",6 Experiments,[0],[0]
Bracket scores We verify the above intuition quantitatively.,6 Experiments,[0],[0]
"To this end, we convert both the predicted and gold dependency trees into the unlabeled bracket structures, and then compare them on the standard PARSEVAL metrics.",6 Experiments,[0],[0]
"This bracket tree is not binarized; for example, we extract (X a b (X c d)) from the tree axbycyd.",6 Experiments,[0],[0]
"Table 2 shows the results, and we can see that DEP always performs the best, showing that DEP leads to the models that find better constituent structures.",6 Experiments,[0],[0]
"Of particular note
is in Enlgish the bracket and dependency scores are only loosely correlated.",6 Experiments,[0],[0]
"In Table 1, UASs for FUNC, DEP, and LEN are 37.2, 39.8, and 52.1, respectively, though F1 of DEP is substantially higher.",6 Experiments,[0],[0]
This suggests that DEP often finds more linguistically plausible structures even when the improvement in UAS is modest.,6 Experiments,[0],[0]
"We conjecture that this performance change between constraints essentially arise due to the nature of DEP, which eliminates center-embedding, i.e., implausible constituent structures, rather than dependency arcs.
",6 Experiments,[0],[0]
Combining DEP and LEN These results suggest DEP and LEN capture different aspects of syntax.,6 Experiments,[0],[0]
"To furuther understand this difference, we now evaluate the models with both constraints.",6 Experiments,[0],[0]
Table 3 shows the average scores across languages (without root constraints).,6 Experiments,[0],[0]
"Interestingly, the combination (DEP+LEN) performs the best in UAS while the worst in bracket F1.",6 Experiments,[0],[0]
This indicates the ability of DEP to find good constituent boundaries is diminished by combining LEN.,6 Experiments,[0],[0]
We feel the results are expected observing that center-embedded constructions are a special case of longer dependency constructions.,6 Experiments,[0],[0]
"In other words, LEN is a stronger constraint than DEP in that the structures penalized by DEP are only a subset of structures penalized by LEN.",6 Experiments,[0],[0]
"Thus when LEN and DEP are combined LEN overwhelms, and the advantage of DEP is weakened.",6 Experiments,[0],[0]
This also suggests not penalizing all longer dependencies is important for learning accurate grammars.,6 Experiments,[0],[0]
The improvement of UAS suggests there are also collaborative effects in some aspect.,6 Experiments,[0],[0]
We have shown that a syntactic constraint that eliminates center-embedding is helpful in dependency grammar induction.,7 Conclusion,[0],[0]
"In particular, we found that our method facilitates to find linguistically correct constituent structures, and given an additional cue on dependency, the models compete with the sys-
tem relying on a significant amount of prior linguistic knowledge.",7 Conclusion,[0],[0]
Future work includes applying our DEP constraint into other PCFG-based grammar induction tasks beyond dependency grammars.,7 Conclusion,[0],[0]
"In particular, it would be fruitful to apply our idea into constituent structure induction for which, to our knowledge, there has been no successful PCFGbased learning algorithm.",7 Conclusion,[0],[0]
"As discussed in de Marcken (1999) one reason for the failures of previous work is the lack of necessary syntactic biases, and our approach could be useful to alleviate this issue.",7 Conclusion,[0],[0]
"Finally, though we have focused on unsupervised learning for simplicity, we believe our syntactic bias also leads to better learning in more practical scenarios, e.g., weakly supervised learning (Garrette et al., 2015).",7 Conclusion,[0],[0]
"We would like to thank John Pate for the help in preliminary work, as well as Taylor Berg-Kirkpatric for sharing his code.",Acknowledgements,[0],[0]
We are also grateful to Edson Miyamoto and Makoto Kanazawa for the valuable feedbacks.,Acknowledgements,[0],[0]
"The first author was supported by JSPS KAKENHI Gran-in-Aid for JSPS Fellows (Grant Numbers 15J07986), and MOU Grant in National Institute of Informatics.",Acknowledgements,[0],[0]
Center-embedding is difficult to process and is known as a rare syntactic construction across languages.,abstractText,[0],[0]
In this paper we describe a method to incorporate this assumption into the grammar induction tasks by restricting the search space of a model to trees with limited centerembedding.,abstractText,[0],[0]
"The key idea is the tabulation of left-corner parsing, which captures the degree of center-embedding of a parse via its stack depth.",abstractText,[0],[0]
"We apply the technique to learning of famous generative model, the dependency model with valence (Klein and Manning, 2004).",abstractText,[0],[0]
"Cross-linguistic experiments on Universal Dependencies show that often our method boosts the performance from the baseline, and competes with the current state-ofthe-art model in a number of languages.",abstractText,[0],[0]
Using Left-corner Parsing to Encode Universal Structural Constraints in Grammar Induction,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2288–2297 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2288
laborative process, whereby interlocutors often expand, repair and/or replace referring expressions in an iterative process, converging on conceptual pacts of referring language use in doing so. Nevertheless, much work on exophoric reference resolution (i.e. resolution of references to entities outside of a given text) follows a literary model, whereby individual referring expressions are interpreted as unique identifiers of their referents given the state of the dialog the referring expression is initiated. In this paper, we address this collaborative nature to improve dialogic reference resolution in two ways: First, we trained a words-asclassifiers logistic regression model of word semantics and incrementally adapt the model to idiosyncratic language between dyad partners during evaluation of the dialog. We then used these semantic models to learn the general referring ability of each word, which is independent of referent features. These methods facilitate accurate automatic reference resolution in situated dialog without annotation of referring expressions, even with little background data.",text,[0],[0]
"A crucial part of dialog situated in a physical environment is exophoric references, i.e. language used by the participants to make entities in the shared environment salient to each other for the purposes of communication (Poesio and Vieira, 1998).",1 Introduction,[0],[0]
Several studies in exophoric reference resolution have investigated how referential semantics can be learned automatically via the relationship of a referent’s features to the language referring to it (,1 Introduction,[0],[0]
"cf. Kennington et al., 2015; Shore and Skantze, 2017) or the state of the interaction a dialog is situated in (cf. Prasov and Chai, 2008; Iida
† Deceased 2 July 2018.
",1 Introduction,[0],[0]
"et al., 2010), inferring a relationship between e.g. the word red and the individual features it refers to, e.g. a particular range of hue values.
",1 Introduction,[0],[0]
Most works in exophoric reference resolution have assumed the identification of certain subsets of language known as referring expressions (REs) that have been either manually or automatically annotated (cf.,1 Introduction,[0],[0]
"Schutte et al., 2011; Meena et al., 2012; Zarrieß et al., 2016; Shore and Skantze, 2017).",1 Introduction,[0],[0]
"However, discerning REs from non-referring language in dialog is not trivial.",1 Introduction,[0],[0]
"For example, Figure 1 illustrates an interaction between two participants in a reference communication task like that of Krauss and Weinheimer (1964), whereby speaker A describes a particular
referent which must be resolved by speaker B. 1.
While REs are idealized as contiguous, single noun phrases (NPs) such as the pinkish one, reference in unrestricted, natural dialog is in fact a collaborative process to which both partners in a dyad contribute (Clark and Wilkes-Gibbs, 1986), and not all referring language (RL) is nominal, e.g. big in Figure 1.",1 Introduction,[0],[0]
"Both participants contribute RL in a cumulative fashion, but often no complete nominal RE is produced, e.g. the big pinkish asteroid to the left.",1 Introduction,[0],[0]
"Due to this, it is difficult to infer from syntax alone the referring ability (RA) of language, i.e. the overall ability of a subset of language to unambiguously refer to entities in discourse (Ariel, 1988; Reboul, 1997).",1 Introduction,[0],[0]
"In context (e.g. given the set of possible abstract shapes to choose from), it is easy to infer which words have the greatest RA, but without context this is more difficult.",1 Introduction,[0],[0]
"This makes recognizing “non-ideal” cases of RL difficult, as the boundary between RL and non-RL is often fuzzy.
",1 Introduction,[0],[0]
"Moreover, participants in dialog tend to develop so-called conceptual pacts, which means that they converge on commonly-used RL for unique referents in dialog (Brennan and Clark, 1996).",1 Introduction,[0],[0]
"As an example, they may repeatedly refer to a given entity as e.g. the asteroid even though asteroid may only rarely be used to refer to similar entities in the general population.",1 Introduction,[0],[0]
"Thus, RL varies less within a given dialog than across dialogs, and variation of RL has an inverse relationship with the length of the time two participants interact due to alignment of dialog participants’ use of language (Clark and Wilkes-Gibbs, 1986; Garrod and Anderson, 1987; Brennan, 1996).
",1 Introduction,[0],[0]
"In this paper, we present two contributions to the automatic learning of referential semantics for reference resolution in situated dialog that address these problems: Firstly, we show the benefits of adapting models of RL semantics to a specific dialog as it progresses to accommodate the dyad’s idiosyncratic use of RL.",1 Introduction,[0],[0]
"Secondly, we present a method for deriving a gradient (non-binary) measure of RA in situated dialog.",1 Introduction,[0],[0]
"Thus, instead of first identifying REs and then resolving which entity they refer to, we treat all language in the dialog as being more or less referential, and use this gradual measure together with the referential semantics to derive which entity is being talked about.",1 Introduction,[0],[0]
"Our assumption is that while the exact
1Examples are from the dataset of Shore et al. (2018)
referential semantics of words vary greatly across dyads, the general ability of a given word to successfully refer to entities varies little across dyads.",1 Introduction,[0],[0]
"Thus, it should be possible to statistically measure the ability of a set of language to refer to entities in general, irrespective of the language’s semantic content (e.g. the exact hue understood as pink by a dyad).",1 Introduction,[0],[0]
"This knowledge, combined with dialogic adaptation, facilitates accurate automatic reference resolution in situated dialog without annotation of REs, even with little background data.",1 Introduction,[0],[0]
Both behavioral studies on reference resolution and RL and computational models thereof have illustrated the context-sensitive nature of reference resolution and RL and the gradient nature of RA.,2 Background,[0],[0]
"Traditionally, reference resolution in dialog was analyzed using a literary model of reference, whereby individual REs are seen as unique identifiers of a referent as in written discourse, i.e. each RE is assumed to be “atomic” in its reference to a particular entity (Clark and WilkesGibbs, 1986, 3).",2.1 Collaboration in Reference Resolution,[0],[0]
"However, shortcomings in this approach have long since been identified (cf.",2.1 Collaboration in Reference Resolution,[0],[0]
"Olson, 1970): REs often do not unambiguously identify their referent when initiated but rather comprise a larger process of collaborative reference resolution, whereby multiple dialog participants iteratively extend, repair and even replace REs initiated by themselves or others (Clark and WilkesGibbs, 1986; Heeman and Hirst, 1995).
",2.1 Collaboration in Reference Resolution,[0],[0]
"In Figure 1, speaker A initiates the RE the one to the left and immediately expands it in an episodic manner (Clark and Wilkes-Gibbs, 1986, 4, 17).",2.1 Collaboration in Reference Resolution,[0],[0]
"Given a literary model of reference, they should have supplied exactly enough information to identify the referent and no more (the big pinkish asteroid to the left), adhering to Grice’s (1975) maxim of quantity.",2.1 Collaboration in Reference Resolution,[0],[0]
"However, RL can undergo not only expansion but also replacement: For color, speaker B proposes both purple and pinkish, but only pinkish is then accepted by A.
",2.1 Collaboration in Reference Resolution,[0],[0]
"In contrast to a literary model of reference, a collaborative model represents reference resolution as a process of iteratively presenting RL to the other participant(s) in a dialog, which is then either accepted as being sufficient to identify a referent or rejected as insufficient (Clark and Wilkes-
Gibbs, 1986, 9).",2.1 Collaboration in Reference Resolution,[0],[0]
This more accurately models reference observed in spoken dialog.,2.1 Collaboration in Reference Resolution,[0],[0]
Literary reference models fail to account not only for the collaborative nature of reference resolution but also for the syntactic structure of RL itself:,2.2 Referring Language Syntax,[0],[0]
"Ideally, a reference is expressed linguistically as an NP, but this ideal does not hold in unrestricted dialog (Clark and Wilkes-Gibbs, 1986).
",2.2 Referring Language Syntax,[0],[0]
"Since an RE cannot be defined as an atomic referring unit, a model of RL should ideally be able to measure the RA of any given set of language rather than simply classifying language as (part of) an RE in a binary decision, such as by using handcrafted rules (cf. Shore and Skantze, 2017) or expert annotation (cf. Spanger et al., 2009; Kennington et al., 2015).",2.2 Referring Language Syntax,[0],[0]
There have already been some efforts in automatic annotation of REs:,2.3 Modeling Referring Language,[0],[0]
"For example, Schutte et al. (2011) algorithmically extracted RL as utterance(s) preceding a discrete event in a shared environment within a certain timeframe.",2.3 Modeling Referring Language,[0],[0]
"However, one drawback to this method is that “the references must be contained in instructions that cause events involving the referents” and “it must be possible to automatically detect these events” (Schutte et al., 2011, 189).",2.3 Modeling Referring Language,[0],[0]
"Thus, REs not referring to a detectable event cannot be detected in this manner.",2.3 Modeling Referring Language,[0],[0]
"Moreover, not all language extracted is that of REs:",2.3 Modeling Referring Language,[0],[0]
"For example, in the instruction go through that door, only half of the tokens constitute RL (that door).",2.3 Modeling Referring Language,[0],[0]
"This means that this method must either be supplemented with additional methods to extract RL or tolerate a high noise-to-signal ratio.
",2.3 Modeling Referring Language,[0],[0]
"Other approaches use language structure to infer RL, namely in parsing said language using a combination of statistical or rule-based methods.",2.3 Modeling Referring Language,[0],[0]
"However, both entail that a solution be specialized for language specific to a given domain, such as for route-following instructions (Meena et al., 2012) or for a specific instructor-manipulator pair task (Shore and Skantze, 2017): Meena et al. (2012) used the highly-structured nature of routefollowing instructions to great effect, while Shore and Skantze (2017) used a phrase-structure parser pre-trained on out-of-domain data and supplemented it with hand-crafted rules to extract NPs according to the literary ideal of RL.
",2.3 Modeling Referring Language,[0],[0]
"Finally, many works simply ignore the distinction between RL and non-RL and focus solely on learning reference resolution as a function of language and extra-linguistic knowledge such as entity features (cf. Kennington et al., 2015; Shore and Skantze, 2017), discourse and action history (cf.",2.3 Modeling Referring Language,[0],[0]
"Iida et al., 2010), perception (cf.",2.3 Modeling Referring Language,[0],[0]
"Matuszek et al., 2012) or gesture (cf.",2.3 Modeling Referring Language,[0],[0]
"Matuszek et al., 2014)",2.3 Modeling Referring Language,[0],[0]
.,2.3 Modeling Referring Language,[0],[0]
"Although these methods improve the resolution of what RL refers to, they do not resolve what language is RL.",2.3 Modeling Referring Language,[0],[0]
"Moreover, none of these works address the strong dyadic and dialogic entrainment effects on RL which include the formation of CPs, reinforcing the use of RL specific to a given dialog even if it diverges from population RL use.",2.3 Modeling Referring Language,[0],[0]
"The data used is that of Shore et al. (2018), a set of |D| = 42 task-oriented dialogs (mean duration µ = 15:25 minutes, standard deviation SD = 1:13, total 647:35) in which one participant is an instructor referring to specific pieces on a shared game board which the other participant, the manipulator, must then attempt to resolve by selecting without the aid of extra-linguistic cues (see Figures 1–2): They sit at different locations and communicate solely through an audio channel.",3 Data Description,[0],[0]
"Upon successful selection, the piece moves to a random free place on the board and the participants alternate roles.",3 Data Description,[0],[0]
This dataset is somewhat larger than that for similar tasks (cf.,3 Data Description,[0],[0]
"Iida et al., 2010; Matuszek et al., 2012; Malinowski and Fritz, 2014; Kennington et al., 2015).",3 Data Description,[0],[0]
"However, unlike in many other works, participants
were allowed to refer to pieces in any way they wish and both were allowed to speak freely.
",3 Data Description,[0],[0]
"Each dialog d ∈ D has |R| = 20 randomlygenerated game pieces and is divided into individual game rounds d , 〈d′1 . . .",3 Data Description,[0],[0]
"d ′ n〉, in each of which d′ , (R, r̂, T ) a single entity is pre-selected by the game as the entity r̂ ∈ R which must be successfully resolved for that round.",3 Data Description,[0],[0]
"Each dialog presents the same 20 referents aside from their changing position, so participants must also refer to pieces which have already been referenced before: After 40 rounds, all pieces are guaranteed to have been referred to and so every reference thereafter is a coreference (see Figure 2).
",3 Data Description,[0],[0]
"Each entity r ∈ R has features representing shape, size, color and position during the given round.",3 Data Description,[0],[0]
"A sequence of tokens T was transcribed from the speech of both participants using Penn Treebank tokenization rules (Marcus et al., 1993).",3 Data Description,[0],[0]
See the Supplementary Material for further information on the dataset.,3 Data Description,[0],[0]
"The reference resolution method used as a baseline was a words-as-classifiers (WaC) regression model (cf. Kennington et al., 2015).",4 Baseline,[0],[0]
"In this framework, an individual logistic regression model pt(r) , σ(w T t r + bt) is trained for each token type t, predicting the probability of a given entity r being the token’s TRUE referent r̂, given the feature vector r representing shape, size, color and position (see the Supplementary Material for details).",4 Baseline,[0],[0]
"For example, if trained successfully, the model for the token ”red” should be sensitive to the entity’s hue, but not to its size.",4 Baseline,[0],[0]
"Common nondescriptive words such as ”the” should not be sensitive to any of the entity’s properties, yielding an output of 0.5 for all entities.",4 Baseline,[0],[0]
"The score of a given entity r being the referent r = r̂ of a set of RL tokens T is defined as the normalized linear combination of the tokens’ corresponding classifiers pt(r):
p′(r = r̂, T ) , 1
n
n∑
t∈T
pt(r) (1)
",4 Baseline,[0],[0]
"For training, language in each round (R, r̂, T ) is defined as a bag of words T referring to the referent r̂. For each token t ∈ T , a training example is defined for the referent r̂ (with a target score of 1) as well as for each non-referent entity r ∈ R \ r̂ (with a target score of 0).",4 Baseline,[0],[0]
"To address model bias,
the training example for r̂ is weighted by its complement set size, |R \",4 Baseline,[0],[0]
"r̂| = 19.
",4 Baseline,[0],[0]
Initial experiments showed that lemmatization did not affect the performance on our dataset.,4 Baseline,[0],[0]
"Thus, each inflected lexical form is considered a unique word (i.e., vocabulary item).",4 Baseline,[0],[0]
"Unlike Kennington et al. (2015), no smoothing was used, instead ignoring words of fewer than α , 3 occurrences.",4 Baseline,[0],[0]
"The motivation for this is that a general out-of-vocabulary model is not expected to increase the performance, since it basically learns to ignore entity properties, similar to the models for common words such as ”the”.",4 Baseline,[0],[0]
"This was also confirmed in our initial experiments.
",4 Baseline,[0],[0]
Note that all language from both the instructor and the manipulator in each round is used.,4 Baseline,[0],[0]
"This is unlike Kennington et al. (2015), who only used language from (manually annotated) REs.",4 Baseline,[0],[0]
"As argued above, REs cannot easily be identified in the type of dialog data we are addressing.",4 Baseline,[0],[0]
"This of course makes the task much more challenging, and the baseline performance can be expected to be lower than that reported in Kennington et al. (2015).
",4 Baseline,[0],[0]
"We did 42-fold cross-validation, in each fold using 40 dialogs for training as background data, one for testing and one for use as random data to compare the effects of dialog-specific data to (see Section 5 below).",4 Baseline,[0],[0]
"Each round in the test dialog is evaluated by the reciprocal rank (RR) of the referent r̂ in the set of entities R ordered by their combined score for all word classifiers in the round ∑
t∈T pt(r), and its mean (MRR) is then calculated.
",4 Baseline,[0],[0]
The cross-validation results for the baseline WaC model are shown in Table 1.,4 Baseline,[0],[0]
"As expected, this is indeed worse than e.g. Kennington et al. (2015)’s reported mean rank of 2.16 when only using speech features.",4 Baseline,[0],[0]
"The WaC model is nevertheless a simple and effective representation of referential semantics in domains where features for each individual referent can be easily represented (cf. Kennington and Schlangen, 2015).",4 Baseline,[0],[0]
"Still, it has two shortcomings: Firstly, it infers a static model of referential semantics which is good across di-
alogs but is suboptimal for language within dialogs due to effects of language alignment (Garrod and Anderson, 1987; Brennan, 1996; Brennan and Clark, 1996).",4 Baseline,[0],[0]
"Secondly, it encodes RA only indirectly:",4 Baseline,[0],[0]
"Given a large enough dataset, logistic regression for non-RL such as okay now I’m ready should have an even distribution between TRUE and FALSE classes, i.e. these classifiers should decide nothing.",4 Baseline,[0],[0]
"Conversely, strong RL such as red should entail strong relationships between certain features and decisions.",4 Baseline,[0],[0]
"However, due to the effects of idiosyncrasy and alignment on dialogic language, understanding low-frequency words is crucial despite that they cannot be conditioned for as well as can be done for high-frequency ones.",4 Baseline,[0],[0]
"We evaluated the benefits of adapting reference resolution parameters to the language of individual dialogs by initially conditioning WaC models on the training set as background data and then adapting the model during evaluation by retraining using data from previous states in the dialog being evaluated: The RR for the ith round (R, r̂, T )",5 Dialogic Model Adaptation,[0],[0]
"i is calculated using a model trained on both background data and interaction data defined as the rounds observed thus far in the given dialog (R, r̂, T )i′<i.",5 Dialogic Model Adaptation,[0],[0]
The parameters for the logistic regression models representing individual words are optimized using quasi-Newton hybrid conjugate gradient descent from Weka v3.8.0,5 Dialogic Model Adaptation,[0],[0]
"(Dai and Yuan, 2001; Frank et al., 2016).",5 Dialogic Model Adaptation,[0],[0]
"A ridge λ = 100 was used to avoid over-fitting of models for low-frequency words, tuned using crossvalidation over the dataset (le Cessie and van Houwelingen, 1992).",5 Dialogic Model Adaptation,[0],[0]
"The same cross-validation method determined an optimal interaction data weight of 3 relative to background data, i.e. an observation in a given dialog is three times as relevant as one from the background data2.
",5 Dialogic Model Adaptation,[0],[0]
Figure 3 compares the improvement of RR from adapting model parameters using dialog interaction data (Adt) to the Baseline as well as effects of adding data from a randomly-chosen round from another unseen dialog (RndAdt):,5 Dialogic Model Adaptation,[0],[0]
The condition RndAdt is used to rule out the possibility that model fit improves simply due to more training data in general.,5 Dialogic Model Adaptation,[0],[0]
"We fit a linear mixed model with conditions Adt, RndAdt, Wgt and scaled Tokens as linear fixed effects and game
2Interaction data weight values tested were 1, 3, 5, 7, 10.
round ordinality (ROUND) as a quadratic fixed effect: Wgt denotes weighting word classifiers by RA, which will be discussed in Section 6.",5 Dialogic Model Adaptation,[0],[0]
Tokens denotes the number of word tokens produced by both speakers in the given round3.,5 Dialogic Model Adaptation,[0],[0]
DYAD (the pair of participants in a given dialog) was included as a random intercept with a random slope for Adt and Wgt.,5 Dialogic Model Adaptation,[0],[0]
We selected the bestfitting model using backwards selection with loglikelihood ratio tests:,5 Dialogic Model Adaptation,[0],[0]
"Starting from the maximally complex model (Barr et al., 2013), we first simplified the random structure and then removed fixed effects not contributing to fit.",5 Dialogic Model Adaptation,[0],[0]
"This showed that including RndAdt does not significantly improve fit (χ2 = 0.00003, p = 0.99599), meaning model fit improves from data specific to the given dialog and not merely from more training data.
",5 Dialogic Model Adaptation,[0],[0]
We refit the final model using maximumlikelihood estimation with Satterthwaite approximation to degrees of freedom (see the Supplementary Material for details).,5 Dialogic Model Adaptation,[0],[0]
"Despite that RR correlates with ROUND i even for the baseline method due to dialogic lexical alignment (cf. Shore and Skantze, 2017; Shore et al., 2018), there is a significant improvement in RR from Adt (B = 0.04882, t(40) = 7.65, p < 0.001).
",5 Dialogic Model Adaptation,[0],[0]
"Since adding a small amount of data from a dialog significantly improves reference resolution for that dialog, dialogic reference resolution can be seen as a model adaptation problem, where indomain data (that from the dialog being evaluated)
3Adding the count of coreferences to a given referent as a fixed effect prevented model convergence when included with Tokens.",5 Dialogic Model Adaptation,[0],[0]
"Regardless, adding it in lieu of Tokens did not significantly improve fit (χ2 = 3.7329,, p = 0.05335).
",5 Dialogic Model Adaptation,[0],[0]
is relatively sparse compared to out-of-domain data (that from other dialogs).,5 Dialogic Model Adaptation,[0],[0]
"This suggests that the effect of dyadic alignment on reference resolution is amplified: As ROUND i increases, not only is more data specific to the given dialog available, but the data observed becomes more homogeneous.",5 Dialogic Model Adaptation,[0],[0]
"Thus, the benefit of this method increases with time, as the ratio of interaction to background data increases.",5 Dialogic Model Adaptation,[0],[0]
"While the method above facilitates the adaption of referential semantics models to dyad-specific language, not all language which is rare and/or observed in only one dyad has great RA: For example, in the dataset used, there were 19 observations of the word awesome but 15 of those were in a single dialog.",6 Weighting by Referring Ability,[0],[0]
"Even when evaluating on that dialog, a classifier would be inferred from the 19− 15 > α remaining observations, and even adapting the word models with interaction data as done in Section 5 will only add noise since it only occurs as non-RL (e.g. awesome good work).",6 Weighting by Referring Ability,[0],[0]
"Conversely, a word such as piece is semantically heavy in general English but is by itself a poor signifier of referents given the task at hand.",6 Weighting by Referring Ability,[0],[0]
"So, we evaluated the benefit of weighting word classifiers by their RA in order to mitigate the effects of such spurious observations.",6 Weighting by Referring Ability,[0],[0]
"To do this, we define the RA of a word t as the mean difference between the probability of the actual referent r̂ being TRUE pt(r̂) and the mean probability for all other entities R \ r̂ for every occurrence of the word in the training data:
wt , 1
n
n∑
d∈D (R,r̂,T )∈d
p′′t (R, r̂, T )
",6 Weighting by Referring Ability,[0],[0]
"p′′t (R, r̂, T ) , p ′ t(r̂, T )",6 Weighting by Referring Ability,[0],[0]
"−
1
m
m∑
r∈R\r̂
p′t(r, T )
p′t(r, T ) , pt(r)
",6 Weighting by Referring Ability,[0],[0]
"|T |∑
i=1
",6 Weighting by Referring Ability,[0],[0]
"[Ti = t]
(2)
One alternative to this metric that we considered was the area under the receiver operating characteristic (ROC) curve (AUC).",6 Weighting by Referring Ability,[0],[0]
"However, the metric above is more conservative in cases of word models with few observations by penalizing their score due to the logistic ridge used, thus putting more “trust” in word models with more observations; The AUC does not account for this directly.
",6 Weighting by Referring Ability,[0],[0]
"Although this metric is derived from referential semantics learned for a specific domain, the WaC logistic regression model(s) encoding referential semantics are simple and thus can easily be re-trained for other domains.",6 Weighting by Referring Ability,[0],[0]
"It can also be derived from other models of referential semantics.
",6 Weighting by Referring Ability,[0],[0]
"Figure 4 compares the improvement of RR from weighting each classifier pt(r) by its RA wt (Wgt) to the Baseline and finally to that from combining adaptation from Section 5 with weighting (Adt,Wgt); Using the same linear mixed model described in Section 5, a significant improvement in RR was found for Wgt over the baseline (B = 0.1314, t(39) = 11.79, p < 0.001) although the effect weakens over time.",6 Weighting by Referring Ability,[0],[0]
"However, this is likely not a weakness of the method but rather an effect of repeated reference on participants’ RL use: With repeated reference, the length of RL reduces (Clark and Wilkes-Gibbs, 1986), meaning that the mean RA of each word increases due to fewer tokens of weak RA being uttered.",6 Weighting by Referring Ability,[0],[0]
"Indeed, a significant interaction between Round and Tokens was found in their effects on RA (see Supplementary Material).",6 Weighting by Referring Ability,[0],[0]
Figure 5 shows a significant correlation of ROUND i and mean RA of all tokens for that round 1 n ∑n t∈Ti wt.,6 Weighting by Referring Ability,[0],[0]
"Additionally, Figure 6 shows a significant inverse relationship with token count |Ti|.",6 Weighting by Referring Ability,[0],[0]
"Since the referent r̂ is chosen at random by the game, the amount of references to an entity increases with round ordinality, and so this corresponds with Clark and WilkesGibbs (1986).
",6 Weighting by Referring Ability,[0],[0]
"A qualitative assessment shows that vocabulary items with the great RA are typically nouns
strongly associated with the task at hand: The 31 words with greatest RA are all nouns referring to shapes.",6 Weighting by Referring Ability,[0],[0]
"Despite this, however, great RA is not exclusive to nouns:",6 Weighting by Referring Ability,[0],[0]
"In Table 2, inside, a preposition, is considered semantically lighter in general English than nouns are (Froud, 2001), but has RA greater than the mean (µ = 0.2424, SD = 0.1266).",6 Weighting by Referring Ability,[0],[0]
"On the other hand, the noun color has relatively little RA given the task at hand.
",6 Weighting by Referring Ability,[0],[0]
"Moreover, including Adt and Wgt using dialog interaction data (Adt,Wgt) shows significant improvements over either alone: During model selection, including Wgt significantly improved fit
(χ2 = 61.425, p < 0.001).",6 Weighting by Referring Ability,[0],[0]
"This means that both methods can be used together and complement each other: Weighting is particularly beneficial for shorter interactions, where little in-domain interaction data is present, while adaptation provides greater benefit for longer interactions (cf.",6 Weighting by Referring Ability,[0],[0]
Figure 3).,6 Weighting by Referring Ability,[0],[0]
"In fact, Figure 7 shows that Wgt has better MRR using only 12 randomly-chosen dialogs as background data than the Baseline does with 40, and adaptation and weighting together (Adt,Wgt) has better MRR with only 7.",6 Weighting by Referring Ability,[0],[0]
Figure 8 illustrates the effects of the two conditions on reference resolution in the task used for evaluation: The baseline classifier has a rank of 10 for the referent r̂ out of |R| = 20 possible referents.,6 Weighting by Referring Ability,[0],[0]
"In the baseline (A), the classifier for e.g. color has as much weight as e.g. rectangle although the former is not a useful signifier for the given task.",6 Weighting by Referring Ability,[0],[0]
"When weighting by RA (B), however, the less-useful words contribute less to the total∑ t∈T (pt(r̂) ·",6 Weighting by Referring Ability,[0],[0]
"wt), improving rank to 5.",6 Weighting by Referring Ability,[0],[0]
"Finally, when adapting the model with interaction data (C), models for semantically-heavy words like violet better fit the dyad’s RL use, bringing rank to 1.
",6 Weighting by Referring Ability,[0],[0]
"When both incrementally adapting semantic models with in-domain dialog data and weighting by RA, MRR for reference resolution was improved by 32.5% over the baseline (see Table 3).",6 Weighting by Referring Ability,[0],[0]
"We have shown that it is possible to improve reference resolution for situated dialog by incrementally adapting word semantic model parameters to
a given dialog in order to accommodate idiosyncratic language use by dyad partners, and the effect of the partners’ own alignment makes this method even more beneficial over time.",7 Conclusion and Discussion,[0],[0]
"Additionally, we have defined a metric of word referring ability which is derived from a word’s referential semantics in situated dialog but holds across individual dialogs despite dyadic variation in RL use.",7 Conclusion and Discussion,[0],[0]
"We showed that this metric can be used to automatically determine the usefulness of a given word for reference resolution, meaning that RE annotation is not necessary.",7 Conclusion and Discussion,[0],[0]
"Both of these aspects are beneficial to natural language understanding (NLU) for situated dialog due to the difficulty of acquiring data domain-appropriate data.
",7 Conclusion and Discussion,[0],[0]
"Model adaption using dialogic knowledge can be effective for improving NLU (cf. Riccardi and Gorin, 2000) despite that little work has been done in this regard specifically for reference resolution.",7 Conclusion and Discussion,[0],[0]
"Our experiments with model adaptation in Section 5 suggest that it may be beneficial to treat reference resolution in situated dialog as a model adaptation task, where a given dialog being evalu-
ated is considered “in-domain” data and all other dialogs considered “out-of-domain” data.",7 Conclusion and Discussion,[0],[0]
"Moreover, due to the fact that dialog participants’ use of RL converges over time (Garrod and Anderson, 1987; Brennan, 1996; Brennan and Clark, 1996), the task should adapt a pre-trained reference resolution model not only for a given dialog but also to the given state of that dialog; On the other hand, Iida et al. (2010) incorporate intra-dialogic knowledge but do not adapt to inter-dialogic effects.
",7 Conclusion and Discussion,[0],[0]
"Lastly, weighting by RA wt as derived from logistic word classifier scores pt(r) in Section 6 was shown to be effective and can be easily inferred from data.",7 Conclusion and Discussion,[0],[0]
"However, this inaccurately assumes inter-word independence, since it does not encode a word’s context: For example, the RA of not was 0.0638, which is relatively low.",7 Conclusion and Discussion,[0],[0]
"While it is a poor signifier in itself, it reverses the polarity of the predicate it modifies.",7 Conclusion and Discussion,[0],[0]
"For example, in it’s the baby blue K the light one not the dark one, the NP the dark one should in fact have negative RA: Entities with a low semantic score ∑
t∈〈the,dark,one〉 pt(r) should in fact be preferred over those those with a high score.",7 Conclusion and Discussion,[0],[0]
"This could be addressed via structural prediction (e.g. conditional random fields or neural networks) or even higher-order n-grams, but these methods cannot be easily utilized given the typically small size of situated dialog datasets.",7 Conclusion and Discussion,[0],[0]
This work is supported by the SSF (Swedish Foundation for Strategic Research) project COIN.,Acknowledgments,[0],[0]
"Plots were made with ggplot2 v2.2.1 (Wickham, 2009).",Acknowledgments,[0],[0]
The authors are grateful for Zofia Malisz’s help with model selection.,Acknowledgments,[0],[0]
"Referring to entities in situated dialog is a collaborative process, whereby interlocutors often expand, repair and/or replace referring expressions in an iterative process, converging on conceptual pacts of referring language use in doing so.",abstractText,[0],[0]
"Nevertheless, much work on exophoric reference resolution (i.e. resolution of references to entities outside of a given text) follows a literary model, whereby individual referring expressions are interpreted as unique identifiers of their referents given the state of the dialog the referring expression is initiated.",abstractText,[0],[0]
"In this paper, we address this collaborative nature to improve dialogic reference resolution in two ways: First, we trained a words-asclassifiers logistic regression model of word semantics and incrementally adapt the model to idiosyncratic language between dyad partners during evaluation of the dialog.",abstractText,[0],[0]
"We then used these semantic models to learn the general referring ability of each word, which is independent of referent features.",abstractText,[0],[0]
"These methods facilitate accurate automatic reference resolution in situated dialog without annotation of referring expressions, even with little background data.",abstractText,[0],[0]
Using Lexical Alignment and Referring Ability to Address Data Sparsity in Situated Dialog Reference Resolution,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 193–203 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
193",text,[0],[0]
Coreference resolution is the task of recognizing different expressions that refer to the same entity.,1 Introduction,[0],[0]
The referring expressions are called mentions.,1 Introduction,[0],[0]
"For instance, the sentence “[Susan]1 sent [her]1 daughter to a boarding school” contains two coreferring mentions.",1 Introduction,[0],[0]
"“her” is an anaphor which refers to the antecedent “Susan”.
",1 Introduction,[0],[0]
"The availability of coreference information benefits various Natural Language Processing (NLP) tasks including automatic summarization, question answering, machine translation and information extraction.",1 Introduction,[0],[0]
"Current coreference developments are almost only targeted at improving scores on
∗",1 Introduction,[0],[0]
"This author is currently employed by the Ubiquitous Knowledge Processing (UKP) Lab, Technische Universität Darmstadt, https://www.ukp.tu-darmstadt.de.
",1 Introduction,[0],[0]
the CoNLL official test set.,1 Introduction,[0],[0]
"However, the superiority of a coreference resolver on the CoNLL evaluation sets does not necessarily indicate that it also performs better on new datasets.",1 Introduction,[0],[0]
"For instance, the ranking model of Clark and Manning (2016a), the reinforcement learning model of Clark and Manning (2016b) and the end-to-end model of Lee et al. (2017) are three recent coreference resolvers, among which the model of Lee et al. (2017) performs the best and that of Clark and Manning (2016b) performs the second best on the CoNLL development and test sets.",1 Introduction,[0],[0]
"However, if we evaluate these systems on the WikiCoref dataset (Ghaddar and Langlais, 2016a), which is consistent with CoNLL with regard to coreference definition and annotation scheme, the performance ranking would be in a reverse order1.
",1 Introduction,[0],[0]
"In Moosavi and Strube (2017a), we investigate the generalization problem in coreference resolution and show that there is a large overlap between the coreferring mentions in the CoNLL training and evaluation sets.",1 Introduction,[0],[0]
"Therefore, higher scores on the CoNLL evaluation sets do not necessarily indicate a better coreference model.",1 Introduction,[0],[0]
They may be due to better memorization of the training data.,1 Introduction,[0],[0]
"As a result, despite the remarkable improvements in coreference resolution, the use of coreference resolution in other applications is mainly limited to the use of simple rule-based systems, e.g. Lapata and Barzilay (2005),Yu and Ji (2016), and Elsner and Charniak (2008).
",1 Introduction,[0],[0]
"In this paper, we explore the role of linguistic features for improving generalization.",1 Introduction,[0],[0]
The incorporation of linguistic features is considered as a potential solution for building more generalizable NLP systems2.,1 Introduction,[0],[0]
"While linguistic features3
1The single model of Lee et al. (2017) is used here.",1 Introduction,[0],[0]
2E.g.,1 Introduction,[0],[0]
there is a dedicated workshop for this topic https: //sites.google.com/view/relsnnlp.,1 Introduction,[0],[0]
"3We refer to features that are based on linguistic intu-
were shown to be important for coreference resolution, e.g. Uryupina (2007) and Bengtson and Roth (2008), state-of-the-art systems no longer use them and mainly rely on word embeddings and deep neural networks.",1 Introduction,[0],[0]
"Since all recent systems are using neural networks, we focus on the effect of linguistic features on a neural coreference resolver.
",1 Introduction,[0],[0]
"The contributions of this paper are as follows:
– We show that linguistic features are more beneficial for a neural coreference resolver if we incorporate features and subsets of their values that are informative for discriminating coreference relations.",1 Introduction,[0],[0]
"Otherwise, employing linguistic features with all their values only slightly affects the performance and generalization.
",1 Introduction,[0],[0]
"– We propose an efficient discriminative pattern mining algorithm, called EPM, for determining (feature, value) pairs that are informative for the given task.",1 Introduction,[0],[0]
"We show that while the informativeness of EPM mined patterns is onpar with those of its counterparts, it scales best to large datasets.4
– By improving generalization, we achieve state-of-the-art performance on all examined out-of-domain evaluations.",1 Introduction,[0],[0]
"Our out-ofdomain performance on WikiCoref is on-par with that of Ghaddar and Langlais (2016b)’s coreference resolver, which is a system specifically designed for WikiCoref and uses its domain knowledge.",1 Introduction,[0],[0]
Uryupina (2007)’s thesis is one of the most thorough analyses of linguistically motivated features for coreference resolution.,2 Importance of Features in Coreference,[0],[0]
"She examines a large set of linguistic features, i.e. string match, syntactic knowledge, semantic compatibility, discourse structure and salience, and investigates their interaction with coreference relations.",2 Importance of Features in Coreference,[0],[0]
"She shows that even imperfect linguistic features, which are extracted using error-prone preprocessing modules, boost the performance and argues that coreference resolvers could and should benefit from linguistic theories.",2 Importance of Features in Coreference,[0],[0]
Her claims are based on analyses on the MUC dataset.,2 Importance of Features in Coreference,[0],[0]
"Ng and Cardie (2002), Yang et al. (2004), Ponzetto and Strube (2006), Bengtson and
itions, e.g. string match, or are acquired from linguistic preprocessing modules, e.g. POS tags, as linguistic features.
",2 Importance of Features in Coreference,[0],[0]
4The EPM code is available at https://github.,2 Importance of Features in Coreference,[0],[0]
"com/ns-moosavi/epm
Roth (2008), and Recasens and Hovy (2009) also study the importance of features in coreference resolution.
",2 Importance of Features in Coreference,[0],[0]
"Apart from the mentioned studies, which are mainly about the importance of individual features, studies like Björkelund and Farkas (2012), Fernandes et al. (2012), and Uryupina and Moschitti (2015) generate new features by combining basic features.",2 Importance of Features in Coreference,[0],[0]
Björkelund and Farkas (2012) do not use a systematic approach for combining features.,2 Importance of Features in Coreference,[0],[0]
"Fernandes et al. (2012) use the Entropy guided Feature Induction (EFI) approach (Fernandes and Milidiú, 2012) to automatically generate discriminative feature combinations.",2 Importance of Features in Coreference,[0],[0]
The first step is to train a decision tree on a dataset in which each sample consists of features describing a mention pair.,2 Importance of Features in Coreference,[0],[0]
The EFI approach traverses the tree from the root in a depth-first order and recursively builds feature combinations.,2 Importance of Features in Coreference,[0],[0]
Each pattern that is generated by EFI starts from the root node.,2 Importance of Features in Coreference,[0],[0]
"As a result, EFI tends to generate long patterns.",2 Importance of Features in Coreference,[0],[0]
A decision tree does not represent all patterns of data.,2 Importance of Features in Coreference,[0],[0]
"Therefore, it is not possible to explore all feature combinations from a decision tree.
",2 Importance of Features in Coreference,[0],[0]
Uryupina and Moschitti (2015) propose an alternative approach to EFI.,2 Importance of Features in Coreference,[0],[0]
They formulate the problem of generating feature combinations as a pattern mining approach.,2 Importance of Features in Coreference,[0],[0]
"They use the Jaccard Item Mining (JIM) algorithm5 (Segond and Borgelt, 2011).",2 Importance of Features in Coreference,[0],[0]
They show that the classifier that uses the JIM features significantly outperforms the one that employs the EFI features.,2 Importance of Features in Coreference,[0],[0]
"deep-coref (Clark and Manning, 2016a) and e2ecoref (Lee et al., 2017) are among the best performing coreference resolvers from which e2ecoref performs better on the CoNLL test set.",3 Baseline Coreference Resolver,[0],[0]
"deepcoref is a pipelined system, i.e. a mention detection first determines the list of candidate mentions with their corresponding features.",3 Baseline Coreference Resolver,[0],[0]
"It contains various coreference models including the mention-pair, mention-ranking, and entity-based models.",3 Baseline Coreference Resolver,[0],[0]
"The mention-ranking model of deepcoref has three variations: (1) “ranking” uses the slack-rescaled max-margin training objective of Wiseman et al. (2015), (2) “reinforce” is a variation of the “ranking” model in which the hyperparameters are set in a reinforcement learning framework (Sutton and Barto, 1998), and (3) “top-
5http://www.borgelt.net/jim.html
pairs” is a simple variation of the “ranking” model that uses a probabilistic objective function and is used for pretraining the “ranking” model.
",3 Baseline Coreference Resolver,[0.9999999509365622],"['The mention-ranking model of deepcoref has three variations: (1) “ranking” uses the slack-rescaled max-margin training objective of Wiseman et al. (2015), (2) “reinforce” is a variation of the “ranking” model in which the hyperparameters are set in a reinforcement learning framework (Sutton and Barto, 1998), and (3) “top- pairs” is a simple variation of the “ranking” model that uses a probabilistic objective function and is used for pretraining the “ranking” model.']"
e2e-coref is an end-to-end system that jointly models mention detection and coreference resolution.,3 Baseline Coreference Resolver,[1.0],['e2e-coref is an end-to-end system that jointly models mention detection and coreference resolution.']
"It considers all possible (start, end) word spans of each sentence as candidate mentions.",3 Baseline Coreference Resolver,[0],[0]
"Apart from a single model, e2e-coref includes an ensemble of five models.
",3 Baseline Coreference Resolver,[0.9999999677612997],"['Apart from a single model, e2e-coref includes an ensemble of five models.']"
We use deep-coref as the baseline in our experiments.,3 Baseline Coreference Resolver,[0],[0]
"The reason is that some of the examined features require the head of each mention to be known, e.g. head match, while e2e-coref mentions do not have specific heads and heads are automatically determined using an attention mechanism.",3 Baseline Coreference Resolver,[0],[0]
"We also observe that if we limit e2e-coref candidate spans to those that correspond to deep-coref’s detected mentions, the performance of e2e-coref drops to a level on-par with deep-coref6.",3 Baseline Coreference Resolver,[0],[0]
"The examined linguistic features include string match, syntactic, shallow semantic and discourse features.",4 Examined Features,[1.0],"['The examined linguistic features include string match, syntactic, shallow semantic and discourse features.']"
"Mention-based features include: – Mention type: proper, nominal or pronominal
– Fine mention type: proper, definite or indefinite nominal, or the citation form of pronouns
– Gender: female, male, neutral, unknown
– Number: singular, plural, unknown
– Animacy: animate, inanimate, unknown
– Named entity type: person, location, organization, date, time, number, etc.
– Dependency relation: enhanced dependency relation (Schuster and Manning, 2016) of the head word to its parent
– POS tags of the first, last, head, two words preceding and following of each mention
Pairwise features include: – Head match: both mentions have the same
head, e.g. “red hat” and “the hat”
– String of one mention is contained in the other, e.g. “Mary’s hat” and “Mary”
– Head of one mention is contained in the other, e.g. “Mary’s hat” and “hat”
– Acronym, e.g. “Heidelberg Institute for Theoretical Studies” and “HITS”
6",4 Examined Features,[0.9672901002591016],"['– Dependency relation: enhanced dependency relation (Schuster and Manning, 2016) of the head word to its parent – POS tags of the first, last, head, two words preceding and following of each mention Pairwise features include: – Head match: both mentions have the same head, e.g. “red hat” and “the hat” – String of one mention is contained in the other, e.g. “Mary’s hat” and “Mary” – Head of one mention is contained in the other, e.g. “Mary’s hat” and “hat” – Acronym, e.g. “Heidelberg Institute for Theoretical Studies” and “HITS” 6 The CoNLL score of the e2e-coref single model on the CoNLL development set drops from 67.36 to 65.81, while that of the deep-coref “ranking” model is 66.09.']"
"The CoNLL score of the e2e-coref single model on the CoNLL development set drops from 67.36 to 65.81, while that of the deep-coref “ranking” model is 66.09.
–",4 Examined Features,[0],[0]
Compatible pre,4 Examined Features,[0],[0]
"-modifiers: the set of premodifiers of one mention is contained in that of the other, e.g. “the red hat that she is wearing” and “the red hat”
– Compatible7 gender, e.g. “Mary” and “women”
– Compatible number, e.g. “Mary” and “John”
– Compatible animacy, e.g. “those hats” and “it”
– Compatible attributes: compatible gender, number and animacy, e.g. “Mary” and “she”
– Closest antecedent that has the same head and compatible premodifiers, e.g. “this new book” and “This book” in “Take a look at this new book.",4 Examined Features,[0],[0]
"This book is one of the best sellers.”
– Closest antecedent that has compatible attributes, e.g. the antecedent “Mary” and the anaphor “she” in the sentence “John saw Mary, and she was in a hurry”
– Closest antecedent that has compatible attributes and is a subject, e.g. the antecedent “Mary” and the anaphor “she” in the sentence “Mary saw John, but she was in a hurry”
– Closest antecedent that has compatible attributes and is an object, e.g. “Mary” and “she” in “John saw Mary, and she was in a hurry”
The last three features are similar to the discourselevel features discussed by Uryupina (2007), which are created by combining proximity, agreement and salience properties.",4 Examined Features,[0.9999999873156559],"['This book is one of the best sellers.” – Closest antecedent that has compatible attributes, e.g. the antecedent “Mary” and the anaphor “she” in the sentence “John saw Mary, and she was in a hurry” – Closest antecedent that has compatible attributes and is a subject, e.g. the antecedent “Mary” and the anaphor “she” in the sentence “Mary saw John, but she was in a hurry” – Closest antecedent that has compatible attributes and is an object, e.g. “Mary” and “she” in “John saw Mary, and she was in a hurry” The last three features are similar to the discourselevel features discussed by Uryupina (2007), which are created by combining proximity, agreement and salience properties.']"
She shows that such features are useful for resolving pronouns.,4 Examined Features,[0],[0]
we estimate proximity by considering the distance of two mentions.,4 Examined Features,[0],[0]
The salience is also incorporated by discriminating subject or object antecedents.,4 Examined Features,[0],[0]
We do not use any gold information.,4 Examined Features,[0],[0]
All features are extracted using Stanford CoreNLP,4 Examined Features,[0],[0]
"(Manning et al., 2014).",4 Examined Features,[0],[0]
"In this section, we examine the effect of employing all linguistic features described in Section 4 in a neural coreference resolver, i.e. deep-coref.",5 Impact of Linguistic Features,[0],[0]
"We use MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), CEAFe (Luo, 2005), LEA (Moosavi and Strube, 2016), and the CoNLL score (Pradhan et al., 2014), i.e. the average F1 value of MUC, B3, and CEAFe, for evaluations.
",5 Impact of Linguistic Features,[0],[0]
"The results of employing those features in deepcoref’s “ranking” and “top-pairs” models on the
7One value is unknown, or both values are identical.
",5 Impact of Linguistic Features,[0.9534514213602724],['The results of employing those features in deepcoref’s “ranking” and “top-pairs” models on the CoNLL development set are reported in Table 1.']
"CoNLL development set are reported in Table 1.
",5 Impact of Linguistic Features,[0],[0]
"The rows “ranking” and “top-pairs” show the base results of deep-coref’s “ranking” and “toppairs” models, respectively.",5 Impact of Linguistic Features,[0],[0]
“+linguistic” rows represents the results for each of the mentionranking models in which the feature set of Section 4 is employed.,5 Impact of Linguistic Features,[0],[0]
"The gender, number, animacy and mention type features, which have less than five values, are converted to binary features.",5 Impact of Linguistic Features,[0],[0]
"Named entity and POS tags, and dependency relations are represented as learned embeddings.
",5 Impact of Linguistic Features,[0],[0]
We observe that incorporating all the linguistic features bridges the gap between the performance of “top-pairs” and “ranking”.,5 Impact of Linguistic Features,[1.0],['We observe that incorporating all the linguistic features bridges the gap between the performance of “top-pairs” and “ranking”.']
"However, it does not improve significantly over “ranking”.",5 Impact of Linguistic Features,[0],[0]
"Henceforth, we use the “top-pairs” model of deep-coref as the baseline model to incorporate linguistic features.
",5 Impact of Linguistic Features,[0],[0]
"To assess the impact on generalization, we evaluate “top-pairs” and “+linguistic”8 models that are trained on CoNLL, on WikiCoref (see Table 2).",5 Impact of Linguistic Features,[0],[0]
"We observe that the impact on generalization is also not notable, i.e. the CoNLL score improves only by 0.5pp over “ranking”.
",5 Impact of Linguistic Features,[0],[0]
"Based on an ablation study, while our feature set contains numerous features, the resulting improvements of “linguistic” over “top-pairs” mainly comes from the last four pairwise features in Section 4, which are carefully designed features.",5 Impact of Linguistic Features,[0],[0]
"As discussed by Moosavi and Strube (2017a), there is a large lexical overlap between the coreferring mentions of the CoNLL training and evaluation sets.",6 Better Exploiting Linguistic Features,[0],[0]
"As a result, lexical features provide a
8i.e.",6 Better Exploiting Linguistic Features,[0],[0]
"“top-pairs+linguistic”
very strong signal for resolving coreference relations.
",6 Better Exploiting Linguistic Features,[0],[0]
"For linguistic features to be more effective in current coreference resolvers, which rely heavily on lexical features, they should also provide a strong signal for coreference resolution.
",6 Better Exploiting Linguistic Features,[0],[0]
"Additional linguistic features are not necessarily all informative for coreference resolution, especially if they are extracted automatically and are noisy.",6 Better Exploiting Linguistic Features,[0],[0]
"Besides, for features with multiple values, e.g. mention-based features, only a small subset of values may be informative.
",6 Better Exploiting Linguistic Features,[0],[0]
"To better exploit linguistic features, we only employ (feature, value) pairs9 that are informative for coreference resolution.",6 Better Exploiting Linguistic Features,[1.0],"['To better exploit linguistic features, we only employ (feature, value) pairs9 that are informative for coreference resolution.']"
"Coreference resolution is a complex task in which features have complex interactions (Recasens and Hovy, 2009).",6 Better Exploiting Linguistic Features,[0],[0]
"As a result, we cannot determine the informativeness of feature-values in isolation.
",6 Better Exploiting Linguistic Features,[0],[0]
"We use a discriminative pattern mining approach (Cheng et al., 2007, 2008; Batal and Hauskrecht, 2010) that examines all combinations of feature-values, up to a certain length, and determines which feature-values are informative when they are considered in combination.
",6 Better Exploiting Linguistic Features,[0],[0]
"Due to the large data size (all mention-pairs of the CoNLL training data) and the high dimensionality of feature-values, compared to common evaluation sets of pattern mining methods, the existing discriminative pattern mining approaches were not applicable to our data.",6 Better Exploiting Linguistic Features,[0],[0]
"In this section, we propose an efficient discriminative pattern mining approach, called Efficient Pattern Miner (EPM), that is scalable to large NLP datasets.",6 Better Exploiting Linguistic Features,[0],[0]
"The most important properties of EPM are (1) it examines all frequent feature-values combinations, up to the desired length, (2) it is scalable to large datasets, and (3) it is only data dependent and independent of the coreference resolver.",6 Better Exploiting Linguistic Features,[0],[0]
"We use the following notations and definitions throughout this section:
– D = {Xi, c(Xi)}ni=1: set of n training samples.",6.1 Notation,[0],[0]
Xi is the set of feature-values that describes the ith sample.,6.1 Notation,[0],[0]
"c(Xi) ∈ C is the label of Xi, e.g. coreferent and non-coreferent.",6.1 Notation,[0],[0]
"– A = {a1, . . .",6.1 Notation,[0],[0]
", al}: set of all feature-values present in D. Each ai ∈",6.1 Notation,[0],[0]
"A is called an item, e.g. ai =“anaphor type=proper”.
",6.1 Notation,[0],[0]
"9Henceforth, we refer to them as feature-values.
– p: pattern p = {ai1 , . . .",6.1 Notation,[0],[0]
", aik} is a set of one or more items, e.g. p ={“anaphor type=proper”, “antecedent type=proper”}.
– support(p, ci): the number of samples that contain pattern p and are labeled with ci.",6.1 Notation,[0],[0]
"For representing the input samples, we use the Frequent Pattern Tree (FP-Tree) structure that is the data structure of the FP-Growth algorithm (Han et al., 2004), i.e. one of the most common algorithms for frequent pattern mining.",6.2 Data Structure,[0],[0]
FP-Tree provides a structure for representing all existing patterns of data in a compressed form.,6.2 Data Structure,[0],[0]
Using the FP-Tree structure allows an efficient enumeration of all frequent patterns.,6.2 Data Structure,[0],[0]
"In the FP-Tree structure, items are arranged in descending order of frequency.",6.2 Data Structure,[0],[0]
"Frequency of an item corresponds to∑
ci∈C support(ai, ci).",6.2 Data Structure,[0],[0]
"Except for the root, which is a null node, each node n contains an item ai ∈ A.",6.2 Data Structure,[0],[0]
"It also contains the support values of ai in the subpath of the tree that starts from the root and ends with n, i.e. supportn(ai, cj).
",6.2 Data Structure,[0],[0]
"The FP-Tree construction method (Han et al., 2004) is as follows: (a) scan D to collect the set of all items, i.e. A. Compute support(ai, cj) for each item ai ∈",6.2 Data Structure,[0],[0]
A and label cj ∈,6.2 Data Structure,[0],[0]
C. Sort,6.2 Data Structure,[0],[0]
"A’s members in descending order according to their frequencies, i.e. ∑ ci∈C support(ai, ci).",6.2 Data Structure,[0],[0]
"(b) create a null-labeled node as the root, and (c) scan D again.",6.2 Data Structure,[0],[0]
"For each (Xi, c(Xi)) ∈ D:
1.",6.2 Data Structure,[0],[0]
Order all items,6.2 Data Structure,[0],[0]
aj ∈ Xi,6.2 Data Structure,[0],[0]
"according to the order in A.
2.",6.2 Data Structure,[0],[0]
"Set the current node (T ) to the root.
3.",6.2 Data Structure,[0],[0]
Consider Xi =,6.2 Data Structure,[0],[0]
"[ak|X̄i], where ak is the first (ordered) item of xi , and X̄i = Xi − ak.",6.2 Data Structure,[0],[0]
"If T has a child n that contains ak then increment supportn(ak, c(Xi)) by one.",6.2 Data Structure,[0],[0]
"Otherwise, create a new node n that contains ak with supportn(ak, c(Xi))",6.2 Data Structure,[0],[0]
= 1.,6.2 Data Structure,[0],[0]
"Add n to the tree as a child of T .
4.",6.2 Data Structure,[0],[0]
"If X̄i is non-empty, set T to n. Assign Xi = X̄i and go to step 3.
",6.2 Data Structure,[0],[0]
"As an example, assume D contains the following two samples:
X1={ana-type=NAM, ant-type=NAM, headmatch=F}, C(X1) = 0
X2={ana-type=NAM, ant-type=NAM, headmatch=T}, C(X2) = 1
Based on these samples A={ana-type=NAM, ant-type=NAM, head-match=F, headmatch=T}, support(ai, 0)ai∈A= {1,1,1,0}, and support(ai, 1)ai∈A={1,1,0,1}.",6.2 Data Structure,[0],[0]
"If we sort A based on ai’s frequencies (support(ai, 0) + support(ai, 1)), the ordering of A’s items will remain the same.
",6.2 Data Structure,[0],[0]
The FP-Tree construction steps for the above samples are demonstrated in Figure 1.,6.2 Data Structure,[0],[0]
"ana-type, ant-type, and head-match features are abbreviated as ana, ant, and head, respectively.
",6.2 Data Structure,[0],[0]
"From an initial FP-Tree (T ) that represents all existing patterns, one can easily obtain a new FPTree in which all patterns include a given pattern p.",6.2 Data Structure,[0],[0]
This can be done by only including sub-paths of T that contain pattern p.,6.2 Data Structure,[0],[0]
"The new tree is called conditional FP-Tree of p, Tp.",6.2 Data Structure,[0],[0]
An example of conditional FP-Tree is included in the supplementary materials.,6.2 Data Structure,[0],[0]
We use a discriminative power and an information novelty measure for determining informativeness.,6.3 Informativeness Measures,[0],[0]
We also use a frequency measure which determines the required minimum frequency of a pattern in training samples.,6.3 Informativeness Measures,[0],[0]
It helps to avoid overfitting to the properties of the training data.,6.3 Informativeness Measures,[0],[0]
"Discriminative power: We use the G2 likelihood ratio test (Agresti, 2007) in order to choose patterns whose association with the class variable is statistically significant.10 The G2 test is successfully used for text analysis (Dunning, 1993).",6.3 Informativeness Measures,[0],[0]
"Information Novelty: A large number of redundant patterns can be generated by adding irrelevant items to a base pattern that is discriminative itself.
10A pattern is considered discriminative if the corresponding p-value is less than a fixed threshold (0.01).
",6.3 Informativeness Measures,[0],[0]
"We consider the pattern p as novel if (1) p predicts the target class label c significantly better than all of its containing items, and (2) p predicts c significantly better than all of its sub-patterns that satisfy the frequency, discriminative power, and the first information novelty conditions.",6.3 Informativeness Measures,[0],[0]
"Similar to Batal and Hauskrecht (2010), we employ a binomial distribution to determine information novelty.",6.3 Informativeness Measures,[0],[0]
The EPM algorithm is summarized in Algorithm 1.,6.4 Mining Algorithm,[0],[0]
"It takes FP-Tree T , pattern p on which T is conditioned, and set of items (Aj ⊂",6.4 Mining Algorithm,[0],[0]
A) whose combinations with p will be examined.,6.4 Mining Algorithm,[0],[0]
"Initially, p is empty and the FP-Tree is constructed based on all frequent items of data and Aj = A. Resulting patterns are collected in P .
",6.4 Mining Algorithm,[0],[0]
"For each ai ∈ Aj , the algorithm builds new pattern q by combining ai with p. frequent(q)",6.4 Mining Algorithm,[0.9507119673297415],"['For each ai ∈ Aj , the algorithm builds new pattern q by combining ai with p. frequent(q) checks whether q meets the frequency condition.']"
checks whether q meets the frequency condition.,6.4 Mining Algorithm,[0],[0]
"If q is frequent, the algorithm continues the search process.",6.4 Mining Algorithm,[0],[0]
"Otherwise, it is not possible to build any frequent pattern out of a non-frequent one.",6.4 Mining Algorithm,[0],[0]
"Discriminative power and the first condition of information novelty are then checked for pattern q.
Algorithm EPM(T , p, Aj) foreach ai",6.4 Mining Algorithm,[0],[0]
"∈ Aj do
q = p ∪ {ai} if Frequent(q)",6.4 Mining Algorithm,[0],[0]
"then
if Discriminative(q) then if Novel(q) then
P = P ∪ q end
end if |q| >= Θl then
continue end",6.4 Mining Algorithm,[0],[0]
"construct Tq = q’s conditional tree EPM(Tq, q, ancestors(ai))
",6.4 Mining Algorithm,[0],[0]
"end end Algorithm 1: The EPM algorithm.
",6.4 Mining Algorithm,[0],[0]
We use a threshold (Θl) for the maximum length of mined patterns.,6.4 Mining Algorithm,[0],[0]
"Θl can be set to large values if more complex and specific patterns are desirable.
",6.4 Mining Algorithm,[0],[0]
"If |q| is smaller than Θl, the conditional FP-Tree Tq is built that represents patterns of T that include the pattern q.",6.4 Mining Algorithm,[0],[0]
"The mining algorithm then continues to recursively search for more specific
patterns by combining q with the items included in ancestors(ai), which keeps the list of all ancestors of ai in the original FP-Tree.",6.4 Mining Algorithm,[0],[0]
"EPM examines all frequent patterns of up to length Θl.
",6.4 Mining Algorithm,[0],[0]
"If we use a statistical test multiple times, the risk of making false discoveries increases (Webb, 2006).",6.4 Mining Algorithm,[0],[0]
"To tackle this, we apply the Bonferroni correction for multiple tests in a post-pruning function after the mining process.",6.4 Mining Algorithm,[0],[0]
This function also applies the second information novelty condition on the resulting patterns.,6.4 Mining Algorithm,[0],[0]
"In this section, we explain why EPM is a better alternative compared to its counterparts for large NLP datasets.",7 Why Use EPM?,[0],[0]
"We compare EPM with two efficient discriminative pattern mining algorithms, i.e. Minimal Predictive Patterns (MPP) (Batal and Hauskrecht, 2010) and Direct Discriminative Pattern Mining (DDPMine) (Cheng et al., 2008), on standard machine learning datasets.
",7 Why Use EPM?,[0],[0]
MPP selects patterns that are significantly more predictive than all their sub-patterns.,7 Why Use EPM?,[0],[0]
It measures significance by the binomial distribution.,7 Why Use EPM?,[0],[0]
"For each pattern of length l, MPP checks 2l−1 sub-patterns.",7 Why Use EPM?,[0],[0]
DDPMine is an iterative approach that selects the most discriminative pattern at each iteration and reduces the search space of the next iteration by removing all samples that include the selected pattern.,7 Why Use EPM?,[0],[0]
"DDPMine uses the FP-Tree structure.
",7 Why Use EPM?,[0],[0]
We show that EPM scales best and compares favorably based on the informativeness of resulting patterns.,7 Why Use EPM?,[0],[0]
"Due to its efficiency, EPM can handle large datasets similar to ones that are commonly used in various NLP tasks.",7 Why Use EPM?,[0],[0]
We use the same FP-Tree implementation for DDPMine and EPM.,7.1 Experimental Setup,[0],[0]
"In all algorithms, we consider a pattern as frequent if it occurs in 10% of the samples of one of the classes.",7.1 Experimental Setup,[0],[0]
"We use Θl = 3 for both MPP and EPM.
",7.1 Experimental Setup,[0],[0]
We perform 5-times repeated 5-fold cross validation and the results are averaged.,7.1 Experimental Setup,[0],[0]
"In each validation, all experiments are performed on the same split.",7.1 Experimental Setup,[0],[0]
"We use a linear SVM, i.e. LIBLINEAR 2.11 (Fan et al., 2008), as the baseline classifier.
",7.1 Experimental Setup,[0],[0]
"We use several datasets from the UCI machine learning repository (Lichman, 2013) whose characteristics are presented in the first three columns of Table 3, i.e. the number of (1)
(real/integer/nominal) features (#Features), (2) frequent items (#FI), and (3) samples (n).",7.1 Experimental Setup,[0],[0]
We use one[the minority class]-vs-all technique for datasets with more than two classes.,7.1 Experimental Setup,[0],[0]
"To evaluate the informativeness of mined patterns, the common practice is to add them as new features to the feature set of the baseline classifier; the more informative the patterns, the greater impact they would have on the overall performance.",7.2 How Informative are EPM Patterns?,[0],[0]
"All patterns are added as binary features, i.e. the feature is true for samples that contain all items of the corresponding pattern.
",7.2 How Informative are EPM Patterns?,[0],[0]
"The effect of the patterns of DDPMine, MPP and EPM on the overall accuracy is presented in Table 3.",7.2 How Informative are EPM Patterns?,[0],[0]
The columns #Patterns show the number of patterns mined by each of the algorithms.,7.2 How Informative are EPM Patterns?,[0],[0]
The Orig columns show the results of the SVM using the original feature sets.,7.2 How Informative are EPM Patterns?,[0],[0]
"The DDP, MPP, and EPM columns show the results of the SVM on the datasets for which the feature set is extended by the features mined by DDPMine, MPP, and EPM, respectively.",7.2 How Informative are EPM Patterns?,[0],[0]
"The results of the 5-repeated 5-fold cross validation are reported if each single validation takes less than 10 hours.
",7.2 How Informative are EPM Patterns?,[0],[0]
"Based on the results of Table 3 (1) EPM efficiently scales to larger datasets, (2) MPP and EPM patterns considerably improves the performance, and (3) EPM has on-par results with MPP while it mines considerably fewer patterns.",7.2 How Informative are EPM Patterns?,[0],[0]
Figure 2 compares EPM mining time (in seconds) with those of DDPMine and MPP.,7.3 How Does it Scale?,[0],[0]
"The parameter in the parentheses is the pattern size threshold, e.g. Θl = 4 for EPM(4).",7.3 How Does it Scale?,[0],[0]
The experiments that take more than two days are terminated and are not included.,7.3 How Does it Scale?,[0],[0]
EPM is notably faster in comparison to the other two approaches.,7.3 How Does it Scale?,[0],[0]
"It is notable that the examined datasets are considerably smaller than
the coreference data, which includes more than 33 million samples and 200 frequent feature-values.",7.3 How Does it Scale?,[0],[0]
"For determining informative feature-values, we extract all features for all mention-pairs11 of the CoNLL training data and then apply EPM on this data.",8.1 Experimental Setup,[0],[0]
"In order to prevent learning annotation errors and specific properties of the training data, we consider a pattern as frequent if it occurs in coreference relations of at least m different coreferring anaphors (m = 20).",8.1 Experimental Setup,[0],[0]
"Since the majority of mention-pairs are non-coreferent and we are not interested in patterns for non-coreferring relations, we also consider the coreference probability of each pattern p, i.e. |{Xi|p∈Xi∧c(Xi)=coreferent}||{Xi|p∈Xi}| , in the post-pruning function.",8.1 Experimental Setup,[0],[0]
"The coreference probability should be higher than a threshold (60% in our experiments), so we only mine patterns that are informative for coreferring mentions.
",8.1 Experimental Setup,[0],[0]
"For the coreference resolution experiments, instead of incorporating informative patterns, we incorporate feature-values that are included in the
11Each mention is paired with all the preceding mentions.
informative patterns mined by EPM.",8.1 Experimental Setup,[0],[0]
"The reason is that deep-coref, or any other recent coreference resolver, uses a deep neural network, which has a fully automated feature generation process.",8.1 Experimental Setup,[0],[0]
"We add these feature-values as binary features.
",8.1 Experimental Setup,[0],[0]
"By setting Θl to five,12 EPM results in 13 pairwise feature-values, 112 POS tags, i.e. 53 POS for anaphors and 59 for antecedents, 25 dependency relations, 26 mention types (mention types or fine mention types), and finally, 14 named entity tags.13
Based on the observation in Section 5, we use the top-pairs model of deep-coref as the baseline to employ additional features, i.e. “+EPM” is the top-pairs model in which EPM feature-values are incorporated.",8.1 Experimental Setup,[0],[0]
The performance of the “+EPM” model compared to recent state-of-the-art coreference models on the CoNLL test set is presented in Table 4.,8.2 Impact on In-domain Performance,[0],[0]
"The “single” and “ensemble” rows represent the results of the single and ensemble models of e2e-coref.
",8.2 Impact on In-domain Performance,[0],[0]
"We also compare EPM with the pattern mining approach used by Uryupina and Moschitti (2015), i.e. Jaccard Item Mining (JIM).",8.2 Impact on In-domain Performance,[0],[0]
"For a fair comparison, while Uryupina and Moschitti (2015) used mined patterns for extracting feature templates, we use them for selecting feature-values.",8.2 Impact on In-domain Performance,[0],[0]
"We run the JIM algorithm on the same data and with the same setup as that of EPM.14 This results in nine pair-
12We observe that using larger Θl values will result in many over-specified patterns.
",8.2 Impact on In-domain Performance,[0],[0]
"13Following the previous studies that show different features are of different importance for various types of mentions, e.g. Denis and Baldridge (2008) and Moosavi and Strube (2017b), we mine a separate set of patterns for each type of anaphor.",8.2 Impact on In-domain Performance,[0],[0]
"These resulting feature-values are the union of informative feature-values for all types of anaphora.
",8.2 Impact on In-domain Performance,[0],[0]
"14 We set the minimum frequency, maximum pattern length and score+ threshold parameters of JIM to 20, 5 and
wise features, 260 POS tags, 38 dependency relations, 32 mention types, and 18 named entity tags.",8.2 Impact on In-domain Performance,[0],[0]
The “+JIM” row shows the results of deep-coref top-pairs model in which these feature-values are incorporated.,8.2 Impact on In-domain Performance,[0],[0]
"As we see, EPM feature-values result in significantly better performance than those of JIM while the number of EPM feature-values is considerably less than JIM.
",8.2 Impact on In-domain Performance,[0],[0]
"Feature Ablation Table 5 shows the effect of each group of EPM feature-values, i.e. pairwise features, mention types, dependency relations, named entity tags and POS tags, on the performance of “+EPM”.",8.2 Impact on In-domain Performance,[0],[0]
"The performance of “+EPM” from which each of the above feature groups is removed, one feature group at a time, is represented as “-pairwise”, “-types”, “-dep”, “-NER”, and “-POS”, respectively.",8.2 Impact on In-domain Performance,[0],[0]
The POS and named entity tags have the least and the pairwise features have the most significant effect.,8.2 Impact on In-domain Performance,[0],[0]
"Since pairwise features have the most significant effect, we also perform an experiment in which only pairwise features are incorporated in the “top-pairs” model, i.e. “+pairwise”.",8.2 Impact on In-domain Performance,[0],[0]
"The results of “-pairwise” compared to “+pairwise” show that pairwise feature-values have a significant impact, but only when they are considered in combination with other EPM
0.6.
feature-values.",8.2 Impact on In-domain Performance,[0],[0]
We use the same setup as that of Moosavi and Strube (2017a) for evaluating generalization including (1) training on the CoNLL data and testing on WikiCoref15 and (2) excluding a genre of the CoNLL data from training and development sets and testing on the excluded genre.,8.3 Impact on Generalization,[0],[0]
"Similar to Moosavi and Strube (2017a), we use the pt and wb genres for the latter evaluation setup.
",8.3 Impact on Generalization,[0],[0]
The results of the first evaluation setup are shown in Table 6.,8.3 Impact on Generalization,[0],[0]
"The best performance on WikiCoref is achieved by Ghaddar and Langlais (2016a) (“G&L” in Table 6) who introduced WikiCoref and design a domain-specific coreference resolver that makes use of the Wikipedia markups of a document as well as links to Freebase, which are annotated in WikiCoref.
",8.3 Impact on Generalization,[0],[0]
Incorporating EPM feature-values improves the performance by about three points.,8.3 Impact on Generalization,[0],[0]
"While “+EPM” does not use the WikiCoref data during training, and unlike “G&L”, it does not employ any domain-specific features, it achieves onpar performance with that of “G&L”.",8.3 Impact on Generalization,[1.0],"['While “+EPM” does not use the WikiCoref data during training, and unlike “G&L”, it does not employ any domain-specific features, it achieves onpar performance with that of “G&L”.']"
"This indeed
15WikiCoref only contains 30 documents, which is not enough for training neural coreference resolvers.
shows the effectiveness of informative featurevalues in improving generalization.
",8.3 Impact on Generalization,[0],[0]
The second set of generalization experiments is reported in Table 7.,8.3 Impact on Generalization,[0],[0]
“in-domain” columns show the results when the evaluation genres were included in training and development sets while the “out-of-domain” columns show the results when the evaluation genres were excluded.,8.3 Impact on Generalization,[1.0],['“in-domain” columns show the results when the evaluation genres were included in training and development sets while the “out-of-domain” columns show the results when the evaluation genres were excluded.']
"As we can see, “+EPM” generalizes best, and in out-ofdomain evaluations, it considerably outperforms the ensemble model of e2e-coref, which has the best performance on the CoNLL test set.",8.3 Impact on Generalization,[1.0],"['As we can see, “+EPM” generalizes best, and in out-ofdomain evaluations, it considerably outperforms the ensemble model of e2e-coref, which has the best performance on the CoNLL test set.']"
"In this paper, we show that employing linguistic features in a neural coreference resolver significantly improves generalization.",9 Conclusions,[0],[0]
"However, the incorporated features should be informative enough to be taken into account in the presence of lexical features, which are very strong features in the CoNLL dataset.",9 Conclusions,[0],[0]
We propose an efficient algorithm to determine informative feature-values in large datasets.,9 Conclusions,[1.0],['We propose an efficient algorithm to determine informative feature-values in large datasets.']
"As a result of a better generalization, we achieve state-of-the-art results in all examined outof-domain evaluations.",9 Conclusions,[0],[0]
"The authors would like to thank Mark-Christoph Müller, Benjamin Heinzerling, Alex Judea, Steffen Eger and the anonymous reviewers for their helpful comments and feedbacks.",Acknowledgments,[0],[0]
"This work has been supported by the Klaus Tschira Foundation, Heidelberg, Germany and the German Research Foundation (DFG) as part of the Research Training Group Adaptive Preparation of Information from Heterogeneous Sources (AIPHES) under grant No.",Acknowledgments,[0],[0]
GRK 1994/1.,Acknowledgments,[0],[0]
Coreference resolution is an intermediate step for text understanding.,abstractText,[0],[0]
It is used in tasks and domains for which we do not necessarily have coreference annotated corpora.,abstractText,[0],[0]
"Therefore, generalization is of special importance for coreference resolution.",abstractText,[0],[0]
"However, while recent coreference resolvers have notable improvements on the CoNLL dataset, they struggle to generalize properly to new domains or datasets.",abstractText,[0],[0]
"In this paper, we investigate the role of linguistic features in building more generalizable coreference resolvers.",abstractText,[0],[0]
We show that generalization improves only slightly by merely using a set of additional linguistic features.,abstractText,[0],[0]
"However, employing features and subsets of their values that are informative for coreference resolution, considerably improves generalization.",abstractText,[0],[0]
"Thanks to better generalization, our system achieves state-of-the-art results in out-of-domain evaluations, e.g., on WikiCoref, our system, which is trained on CoNLL, achieves on-par performance with a system designed for this dataset.",abstractText,[0],[0]
Using Linguistic Features to Improve the Generalization Capability of Neural Coreference Resolvers,title,[0],[0]

{"sections": [{"heading": "1. Introduction", "text": "Distributed machine learning is crucial for many settings where the data is possessed by multiple parties or when the quantity of data prohibits processing at a central location. It helps to reduce the computational complexity, improve both the robustness and the scalability of data processing. In a distributed setting, multiple entities/nodes collaboratively work toward a common optimization objective through an\n1Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan, USA. Correspondence to: Xueru Zhang <xueru@umich.edu>, Mohammad Mahdi Khalili <khalili@umich.edu>, Mingyan Liu <mingyan@umich.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\ninteractive process of local computation and message passing, which ideally should result in all nodes converging to a global optimum. Existing approaches to decentralizing an optimization problem primarily consist of subgradientbased algorithms (Nedic et al., 2008; Nedic & Ozdaglar, 2009; Lobel & Ozdaglar, 2011), ADMM-based algorithms (Wei & Ozdaglar, 2012; Ling & Ribeiro, 2014; Shi et al., 2014; Zhang & Kwok, 2014; Ling et al., 2016), and composite of subgradient and ADMM (Bianchi et al., 2014). It has been shown that ADMM-based algorithms can converge at the rate of O( 1k ) while subgradient-based algorithms typically converge at the rate of O( 1\u221a\nk ), where k is the number\nof iterations (Wei & Ozdaglar, 2012). In this study, we will solely focus on ADMM-based algorithms.\nThe information exchanged over the iterative process gives rise to privacy concerns if the local training data is proprietary to each node, especially when it contains sensitive information such as medical or financial records, web search history, and so on. It is therefore highly desirable to ensure such iterative processes are privacy-preserving.\nA widely used notion of privacy is the \u03b5-differential privacy; it is generally achieved by perturbing the algorithm such that the probability distribution of its output is relatively insensitive to any change to a single record in the input (Dwork, 2006). Several differentially private distributed algorithms have been proposed, including (Hale & Egerstedty, 2015; Huang et al., 2015; Han et al., 2017; Zhang & Zhu, 2017; Bellet et al., 2017). While a number of such studies have been done for (sub)gradient-based algorithms, the same is much harder for ADMM-based algorithms due to its computational complexity stemming from the fact that each node is required to solve an optimization problem in each iteration. To the best of our knowledge, only (Zhang & Zhu, 2017) applies differential privacy to ADMM, where the noise is either added to the dual variable (dual variable perturbation) or the primal variable (primal variable perturbation) in ADMM updates. However, (Zhang & Zhu, 2017) could only bound the privacy loss of a single iteration. Since an attacker can potentially use all intermediate results to perform inference, the privacy loss accumulates over time through the iterative process. It turns out that the tradeoff between the utility of the algorithm and its privacy preservation over the entire computational process becomes hard using the existing method. ar X iv :1 80 6.\n02 24\n6v 1\n[ cs\n.L G\n] 6\nJ un\n2 01\n8\nIn this study we propose a perturbation method that could simultaneously improve the accuracy and privacy for ADMM. We start with a modified version of ADMM whereby each node independently decides its own penalty parameter in each iteration; it may also differ from the dual updating step size. For this modified ADMM we establish conditions for convergence and quantify the lower bound of the convergence rate. We then present a penalty perturbation method to provide differential privacy. Our numerical results show that under this method, by increasing the penalty parameter over iterations, we can achieve stronger privacy guarantee as well as better algorithmic performance, i.e., more stable convergence and higher accuracy.\nThe remainder of the paper is organized as follows. We present problem formulation and definition of differential privacy and ADMM in Section 2 and a modified ADMM algorithm along with its convergence analysis in Section 3. A private version of this ADMM algorithm is then introduced in Section 4 and numerical results in Section 5. Discussions are given in Section 6 and Section 7 concludes the paper."}, {"heading": "2. Preliminaries", "text": ""}, {"heading": "2.1. Problem Formulation", "text": "Consider a connected network1 given by an undirected graph G(N ,E ), which consists of a set of nodes N = {1, 2, \u00b7 \u00b7 \u00b7 , N} and a set of edges E = {1, 2, \u00b7 \u00b7 \u00b7 , E}. Two nodes can exchange information if and only if they are connected by an edge. Let Vi denote node i\u2019s set of neighbors, excluding itself. A node i contains a dataset Di = {(xni , yni )|n = 1, 2, \u00b7 \u00b7 \u00b7 , Bi}, where xni \u2208 Rd is the feature vector representing the n-th sample belonging to i, yni \u2208 {\u22121, 1} the corresponding label, and Bi the size of Di.\nConsider the regularized empirical risk minimization (ERM) problems for binary classification defined as follows:\nmin fc OERM (fc, Dall) = N\u2211 i=1 C Bi Bi\u2211 n=1 L (yni f T c x n i )+\u03c1R(fc) (1) where C \u2264 Bi and \u03c1 > 0 are constant parameters of the algorithm, the loss function L (\u00b7) measures the accuracy of classifier, and the regularizer R(\u00b7) helps to prevent overfitting. The goal is to train a (centralized) classifier fc \u2208 Rd over the union of all local datasets Dall = \u222ai\u2208N Di in a distributed manner using ADMM, while providing privacy guarantee for each data sample 2.\n1A connected network is one in which every node is reachable (via a path) from every other node.\n2The proposed penalty perturbation method is not limited to classification problems. It can be applied to general ADMM-based distributed algorithms since the convergence and privacy analysis"}, {"heading": "2.2. Conventional ADMM", "text": "To decentralize (1), let fi be the local classifier of each node i. To achieve consensus, i.e., f1 = f2 = \u00b7 \u00b7 \u00b7 = fN , a set of auxiliary variables {wij |i \u2208 N , j \u2208 Vi} are introduced for every pair of connected nodes. As a result, (1) is reformulated equivalently as:\nmin {fi},{wij} O\u0303ERM ({fi}Ni=1, Dall) = N\u2211 i=1 O(fi, Di)\ns.t. fi = wij , wij = fj , i \u2208 N , j \u2208 Vi\n(2)\nwhere O(fi, Di) = C\nBi\n\u2211Bi n=1 L (y n i f T i x n i ) + \u03c1\nN R(fi).\nThe objective in (2) can be solved using ADMM. Let {fi} be the shorthand for {fi}i\u2208N ; let {wij , \u03bbkij} be the shorthand for {wij , \u03bbkij}i\u2208N ,j\u2208Vi,k\u2208{a,b}, where \u03bbaij , \u03bbbij are dual variables corresponding to equality constraints fi = wij and wij = fj respectively. Then the augmented Lagrangian is as follows:\nL\u03b7({fi}, {wij , \u03bbkij}) = N\u2211 i=1 O(fi, Di)\n+ N\u2211 i=1 \u2211 j\u2208Vi (\u03bbaij) T (fi \u2212 wij) + N\u2211 i=1 \u2211 j\u2208Vi (\u03bbbij) T (wij \u2212 fj) (3)\n+ N\u2211 i=1 \u2211 j\u2208Vi \u03b7 2 (||fi \u2212 wij ||22 + ||wij \u2212 fj ||22) .\nIn the (t + 1)-th iteration, the ADMM updates consist of the following:\nfi(t+ 1) = argmin fi L\u03b7({fi}, {wij(t), \u03bbkij(t)}) ; (4)\nwij(t+ 1) = argmin wij L\u03b7({fi(t+ 1)}, {wij , \u03bbkij(t)}) ; (5)\n\u03bbaij(t+ 1) = \u03bb a ij(t) + \u03b7(fi(t+ 1)\u2212 wij(t+ 1)) ; (6)\n\u03bbbij(t+ 1) = \u03bb b ij(t) + \u03b7(wij(t+ 1)\u2212 fj(t+ 1)) . (7)\nUsing Lemma 3 in (Forero et al., 2010), if dual variables \u03bbaij(t) and \u03bb b ij(t) are initialized to zero for all node pairs (i, j), then \u03bbaij(t) = \u03bb b ij(t) and \u03bb k ij(t) = \u2212\u03bbkji(t) will hold for all iterations with k \u2208 {a, b}, i \u2208 N , j \u2208 Vi.\nLet \u03bbi(t) = \u2211 j\u2208Vi \u03bb a ij(t) = \u2211 j\u2208Vi \u03bb b ij(t), then the ADMM iterations (4)-(7) can be simplified as:\nfi(t+ 1) = argmin fi {O(fi, Di) + 2\u03bbi(t)T fi\n+\u03b7 \u2211 j\u2208Vi ||1 2 (fi(t) + fj(t))\u2212 fi||22 } ; (8)\n\u03bbi(t+ 1) = \u03bbi(t) + \u03b7\n2 \u2211 j\u2208Vi (fi(t+ 1)\u2212 fj(t+ 1)) . (9)\nin Section 3 & 4 remain valid."}, {"heading": "2.3. Differential Privacy", "text": "Differential privacy (Dwork, 2006) can be used to measure the privacy risk of each individual sample in the dataset quantitatively. Mathematically, a randomized algorithm A (\u00b7) taking a dataset as input satisfies \u03b5-differential privacy if for any two datasets D, D\u0302 differing in at most one data point, and for any set of possible outputs S \u2286 range(A ), Pr(A (D) \u2208 S) \u2264 exp(\u03b5)Pr(A (D\u0302) \u2208 S) holds. We call two datasets differing in at most one data point as neighboring datasets. The above definition suggests that for a sufficiently small \u03b5, an adversary will observe almost the same output regardless of the presence (or value change) of any one individual in the dataset; this is what provides privacy protection for that individual."}, {"heading": "2.4. Private ADMM proposed in (Zhang & Zhu, 2017)", "text": "Two randomizations were proposed in (Zhang & Zhu, 2017): (i) dual variable perturbation, where each node i adds a random noise to its dual variable \u03bbi(t) before updating its primal variable fi(t) using (8) in each iteration; and (ii) primal variable perturbation, where after updating primal variable fi(t), each node adds a random noise to it before broadcasting to its neighbors. Both were evaluated for a single iteration for a fixed privacy constraint. As we will see later in numerical experiments, the privacy loss accumulates significantly when inspected over multiple iterations.\nIn contrast, in this study we will explore the use of the penalty parameter \u03b7 to provide privacy. In particular, we will allow this to be private information to every node, i.e., each decides its own \u03b7 in every iteration and it is not exchanged among the nodes. Below we will begin by modifying the ADMM to accommodate private penalty terms."}, {"heading": "3. Modified ADMM (M-ADMM)", "text": ""}, {"heading": "3.1. Making \u03b7 a node\u2019s private information", "text": "Conventional ADMM (Boyd et al., 2011) requires that the penalty parameter \u03b7 be fixed and equal to the dual updating step size for all nodes in all iterations. Varying the penalty parameter to accelerate convergence in ADMM has been proposed in the literature. For instance, (He et al., 2002; Magnu\u0301sson et al., 2014; Aybat & Iyengar, 2015; Xu et al., 2016) vary this penalty parameter in every iteration but keep it the same for different equality constraints in (2). In (Song et al., 2016; Zhang & Wang, 2017) this parameter varies in each iteration and is allowed to differ for different equality constraints. However, all of these modifications are based on the original ADMM (Eqn. (4)-(7)) and not on the simplified version (Eqn. (8)-(9)); the significance of this difference is discussed below in the context of privacy requirement. Moreover, we will decouple \u03b7i(t+1) from the dual updating step size, denoted as \u03b8 below. For simplicity, \u03b8 is fixed for\nall nodes in our analysis, but can also be private information as we show in numerical experiments.\nFirst consider replacing \u03b7 with \u03b7ij(t+ 1) in Eqn. (4)-(5) of the original ADMM (as is done in (Song et al., 2016; Zhang & Wang, 2017)) and replacing \u03b7 with \u03b8 in Eqn. (6)-(7); we obtain the following:\nfi(t+ 1) = argmin fi {O(fi, Di) + 2\u03bbi(t)T fi\n+ \u2211 j\u2208Vi \u03b7ij(t+ 1) + \u03b7ji(t+ 1) 2 ||1 2 (fi(t) + fj(t))\u2212 fi||22} ;\n\u03bbi(t+ 1) = \u03bbi(t) + \u03b8\n2 \u2211 j\u2208Vi (fi(t+ 1)\u2212 fj(t+ 1)) .\nThis however violates our requirement that \u03b7ji(t) be node j\u2019s private information since this is needed by node i to perform the above computation. To resolve this, we instead start from the simplified ADMM, modifying Eqn. (8)-(9):\nfi(t+ 1) = argmin fi {O(fi, Di) + 2\u03bbi(t)T fi\n+\u03b7i(t+ 1) \u2211 j\u2208Vi ||fi \u2212 1 2 (fi(t) + fj(t))||22 } ; (10)\n\u03bbi(t+ 1) = \u03bbi(t) + \u03b8\n2 \u2211 j\u2208Vi (fi(t+ 1)\u2212 fj(t+ 1)) , (11)\nwhere \u03b7i(t+ 1) is now node i\u2019s private information. Indeed \u03b7i(t+ 1) is no longer purely a penalty parameter related to any equality constraint in the original sense. We will however refer to it as the private penalty parameter for simplicity. The above constitutes the M-ADMM algorithm."}, {"heading": "3.2. Convergence Analysis", "text": "We next show that the M-ADMM (Eqn. (10)-(11)) converges to the optimal solution under a set of common technical assumptions. Our proof is based on the method given in (Ling et al., 2016).\nAssumption 1: Function O(fi, Di) is convex and continuously differentiable in fi, \u2200i.\nAssumption 2: The solution set to the original ERM problem (1) is nonempty and there exists at least one bounded element.\nThe KKT optimality condition of the primal update (10) is:\n0 = \u2207O(fi(t+ 1), Di) + 2\u03bbi(t) +\u03b7i(t+ 1) \u2211 j\u2208Vi (2fi(t+ 1)\u2212 (fi(t) + fj(t))) . (12)\nWe next rewrite (11)-(12) in matrix form. Define the adjacency matrix of the network A \u2208 RN\u00d7N as\naij = { 1, if node i and node j are connected 0, otherwise .\nStack the variables fi(t), \u03bbi(t) and \u2207O(fi(t), Di) for i \u2208 N into matrices, i.e.,\nf\u0302(t) =  f1(t) T f2(t) T\n... fN (t) T\n \u2208 RN\u00d7d , \u039b(t) =  \u03bb1(t) T \u03bb2(t) T\n... \u03bbN (t) T\n \u2208 RN\u00d7d\n\u2207O\u0302(f\u0302(t), Dall) =  \u2207O(f1(t), D1)T \u2207O(f2(t), D2)T\n... \u2207O(fN (t), DN )T  \u2208 RN\u00d7d Let Vi = |Vi| be the number of neighbors of node i, and define the degree matrix D = diag([V1;V2; \u00b7 \u00b7 \u00b7 ;VN ]) \u2208 RN\u00d7N . Define for the t-th iteration a penalty-weighted matrix W (t) = diag([\u03b71(t); \u03b72(t); \u00b7 \u00b7 \u00b7 ; \u03b7N (t)]) \u2208 RN\u00d7N . Then the matrix form of (11)-(12) are:\n\u2207O\u0302(f\u0302(t+ 1), Dall) + 2\u039b(t) + 2W (t+ 1)Df\u0302(t+ 1) \u2212W (t+ 1)(D +A)f\u0302(t) = 0N\u00d7d ; (13)\n2\u039b(t+ 1) = 2\u039b(t) + \u03b8(D \u2212A)f\u0302(t+ 1) . (14)\nNote that D \u2212A is the Laplacian matrix and D +A is the signless Laplacian matrix of the network, with the following properties if the network is connected: (i) D \u00b1 A 0 is positive semi-definite; (ii) Null(D \u2212 A) = c1, i.e., every member in the null space of D \u2212A is a scalar multiple of 1 with 1 being the vector of all 1\u2019s (Kelner, 2007). Let \u221a X denote the square root of a symmetric positive semi-definite (PSD) matrix X that is also symmetric PSD, i.e., \u221a X \u221a X = X . Define matrix Y (t) such that 2\u039b(t) =\u221a\nD \u2212AY (t). Since \u039b(0) = zeros(N, d), which is in the column space of D \u2212A, this together with (14) imply that \u039b(t) is in the column space of D \u2212 A and \u221a D \u2212A. This guarantees the existence of Y (t). This allows us to rewrite (13)-(14) as:\n\u2207O\u0302(f\u0302(t+ 1), Dall) + \u221a D \u2212AY (t+ 1)\n+(W (t+ 1)\u2212 \u03b8I)(D \u2212A)f\u0302(t+ 1) +W (t+ 1)(D +A)(f\u0302(t+ 1)\u2212 f\u0302(t)) = 0N\u00d7d ; (15)\nY (t+ 1) = Y (t) + \u03b8 \u221a D \u2212Af\u0302(t+ 1) . (16)\nLemma 3.1 [First-order Optimality Condition (Ling et al., 2016)] Under Assumptions 1 and 2, the following two statements are equivalent:\n\u2022 f\u0302\u2217 = [(f\u22171 )T ; (f\u22172 )T ; \u00b7 \u00b7 \u00b7 ; (f\u2217N )T ] \u2208 RN\u00d7d is consensual, i.e., f\u22171 = f \u2217 2 = \u00b7 \u00b7 \u00b7 = f\u2217N = f\u2217c where f\u2217c is the\noptimal solution to (1).\n\u2022 There exists a pair (f\u0302\u2217, Y \u2217) with Y \u2217 = \u221a D \u2212AX\nfor some X \u2208 RN\u00d7d such that\n\u2207O\u0302(f\u0302\u2217, Dall) + \u221a D \u2212AY \u2217 = 0N\u00d7d ; (17)\u221a D \u2212Af\u0302\u2217 = 0N\u00d7d . (18)\nLemma 3.1 shows that a pair (Y \u2217, f\u0302\u2217) satisfying (17)(18) is equivalent to the optimal solution of our problem, hence the convergence of M-ADMM is proved by showing that (Y (t), f\u0302(t)) converges to a pair (Y \u2217, f\u0302\u2217) satisfying (17)(18).\nTheorem 3.1 Consider the modified ADMM defined by (10)-(11). Let {Y (t), f\u0302(t)} be outputs in each iteration and (Y \u2217, f\u0302\u2217) a pair satisfying (17)-(18). Denote\nZ(t) =\n[ Y (t)\nf\u0302(t)\n] \u2208 R2N\u00d7d, Z\u2217 = [ Y \u2217\nf\u0302\u2217\n] \u2208 R2N\u00d7d\nJ(t) = [ IN\u00d7N \u03b8 0 0 W (t)(D +A) ] \u2208 R2N\u00d72N\nLet \u3008\u00b7, \u00b7\u3009F be the Frobenius inner product of two matrices. We have\n\u3008Z(t+ 1)\u2212Z\u2217, J(t+ 1)(Z(t+ 1)\u2212Z(t))\u3009F \u2264 0 . (19)"}, {"heading": "If \u03b7i(t + 1) \u2265 \u03b7i(t) \u2265 \u03b8 > 0 and \u03b7i(t) < +\u221e, \u2200t, i, then", "text": "(Y (t), f\u0302(t)) converges to (Y \u2217, f\u0302\u2217)."}, {"heading": "3.3. Convergence Rate Analysis", "text": "To further establish the convergence rate of modified ADMM, an additional assumption is used:\nAssumption 3: For all i \u2208 N , O(fi, Di) is strongly convex in fi and has Lipschitz continues gradients, i.e., for any f1i and f 2 i , we have:\n(f1i \u2212f2i )T (\u2207O(f1i , Di)\u2212\u2207O(f2i , Di)) \u2265 mi||f1i \u2212f2i ||22\n||\u2207O(f1i , Di)\u2212\u2207O(f2i , Di)||2 \u2264Mi||f1i \u2212 f2i ||2 (20)\nwhere mi > 0 is the strong convexity constant and 0 < Mi < +\u221e is the Lipschitz constant.\nTheorem 3.2 Define Dm = diag([m1;m2; \u00b7 \u00b7 \u00b7 ;mN ]) \u2208 RN\u00d7N and DM = diag([M21 ;M22 ; \u00b7 \u00b7 \u00b7 ;M2N ]) \u2208 RN\u00d7N with mi > 0 and 0 < Mi < +\u221e as given in Assumption 3. Denote by ||X||2J = \u3008X, JX\u3009F the Frobenius inner product of any matrix X and JX; denote by \u03c3min(\u00b7) and \u03c3max(\u00b7) the smallest nonzero, and the largest, singular values of a matrix, respectively.\nLet \u03c3\u0303max(t) = \u03c3max(W (t)(D +A)), \u03c3\u0304max/min(t) = \u03c3max/min((W (t)\u2212 \u03b8I)(D \u2212A)) and \u00b5 > 1 be an arbitrary constant. Consider any \u03b4(t) that satisfies (21)(22):\n\u03b4(t)\u00b52\u03c3\u0303max(t) \u03b8\u03c3min(D \u2212A) \u2264 1 (21)\nand\n\u03b4(t)( \u00b5\u03c3\u0304max(t) 2IN + \u00b52DM \u03b8\u03c3min(D \u2212A)(\u00b5\u2212 1) +W (t)(D +A))\n2(W (t)\u2212 \u03b8I)(D \u2212A) + 2Dm . (22)"}, {"heading": "If \u03b7i(t + 1) \u2265 \u03b7i(t) \u2265 \u03b8 > 0 and \u03b7i(t) < +\u221e, \u2200t, i, then", "text": "(Y (t), f\u0302(t)) converges to (Y \u2217, f\u0302\u2217) in the following sense:\n(1 + \u03b4(t))||Z(t)\u2212 Z\u2217||2J(t) \u2264 ||Z(t\u2212 1)\u2212 Z \u2217||2J(t) .\nFurthermore, a lower bound on \u03b4(t) is:\nmin{\u03b8\u03c3min(D \u2212A) \u00b52\u03c3\u0303max(t) , 2mo + 2\u03c3\u0304min(t) \u00b52M2O+\u00b5\u03c3\u0304max(t) 2\n\u03b8\u03c3min(D\u2212A)(\u00b5\u22121) + \u03c3\u0303max(t) } (23)\nwhere mo = mini\u2208N {mi} and MO = maxi\u2208N {Mi}.\nAlthough Theorem 3.2 only gives a lower bound on the convergence rate (1 + \u03b4(t)) of the M-ADMM, it reflects the impact of penalty {\u03b7i(t)}Ni=1 on the convergence. Since \u03c3\u0304max(t) = \u03c3max((W (t)\u2212 \u03b8I)(D \u2212A)) and \u03c3\u0303max(t) = \u03c3max(W (t)(D +A)), larger penalty results in larger \u03c3\u0304max(t) and \u03c3\u0303max(t). By (23), the first term,\n\u03b8\u03c3min(D\u2212A) \u00b52\u03c3\u0303max(t)\nis smaller when \u03c3\u0303max(t) is larger. The second term is bounded by \u03b8\u03c3min(D\u2212A)(\u00b5\u22121)(2mo+2\u03c3\u0304min(t))\u00b5\u03c3\u0304max(t)2 , which is smaller when \u03c3\u0304max(t) is larger. Therefore, the convergence rate 1 + \u03b4(t) decreases as {\u03b7i(t)}Ni=1 increase."}, {"heading": "4. Private M-ADMM", "text": "In this section we present a privacy preserving version of MADMM. To begin, a random noise i(t+1) with probability density proportional to exp{\u2212\u03b1i(t + 1)|| i(t + 1)||2} is added to penalty term in the objective function of (10):\nLprivi (t+ 1) = O(fi, Di) + 2\u03bbi(t) T fi +\u03b7i(t+ 1) \u2211 j\u2208Vi ||fi + i(t+ 1)\u2212 1 2 (fi(t) + fj(t))||22\n(24)\nTo generate this noisy vector, choose the norm from the gamma distribution with shape d and scale 1\u03b1i(t+1) and the direction uniformly, where d is the dimension of the feature space. Then node i\u2019s local result is obtained by finding the optimal solution to the private objective function:\nfi(t+ 1) = argmin fi\nLprivi (t+ 1), i \u2208 N . (25)\nIt is equivalent to (26) below when noise \u03b7i(t+1)Vi i(t+1)\nAlgorithm 1 Penalty perturbation (PP) method Parameter: Determine \u03b8 such that 2c1 < BiC ( \u03c1 N + 2\u03b8Vi)\nholds for all i. Initialize: Generate fi(0) randomly and \u03bbi(0) = 0d\u00d71 for every node i \u2208 N , t = 0 Input: {Di}Ni=1, {\u03b1i(1), \u00b7 \u00b7 \u00b7 , \u03b1i(T )}Ni=1 for t = 0 to T \u2212 1 do\nfor i = 1 to N do Generate noise i(t+ 1) \u223c exp(\u2212\u03b1i(t+ 1)|| ||2) Perturb the penalty term according to (24) Update primal variable via (25) end for for i = 1 to N do\nBroadcast fi(t+ 1) to all neighbors j \u2208 Vi end for for i = 1 to N do\nUpdate dual variable according to (11) end for\nend for Output: upper bound of the total privacy loss \u03b2\nis added to the dual variable \u03bbi(t):\nargmin fi\nL\u0303privi (t+ 1) = C\nBi Bi\u2211 n=1 L (yni f T i x n i ) + \u03c1 N R(fi)\n+2(\u03bbi(t) + \u03b7i(t+ 1)Vi i(t+ 1)) T fi +\u03b7i(t+ 1) \u2211 j\u2208Vi ||fi \u2212 1 2 (fi(t) + fj(t))||22 .\nFurther, if \u03b7i(t+1) = \u03b7 = \u03b8,\u2200i, t, then the above is reduced to the dual variable perturbation in (Zhang & Zhu, 2017)3.\nThe complete procedure is shown in Algorithm 1, where the condition used to generate \u03b8 helps bound the worst-case privacy loss but is not necessary in guaranteeing convergence.\nIn a distributed and iterative setting, the \u201coutput\u201d of the algorithm is not merely the end result, but includes all intermediate results generated and exchanged during the iterative process. For this reason, we formally state the differential privacy definition in this setting below.\nDefinition 4.1 Consider a connected network G(N ,E ) with a set of nodes N = {1, 2, \u00b7 \u00b7 \u00b7 , N}. Let f(t) = {fi(t)}Ni=1 denote the information exchange of all nodes in the t-th iteration. A distributed algorithm is said to satisfy \u03b2-differential privacy during T iterations if for any two datasets Dall = \u222aiDi and D\u0302all = \u222aiD\u0302i, differing in at\n3Only a single iteration is considered in (Zhang & Zhu, 2017) while imposing a privacy constraint. Since we consider the entire iterative process, we don\u2019t impose per-iteration privacy constraint but calculate the total privacy loss.\nmost one data point, and for any set of possible outputs S during T iterations, the following holds:\nPr({f(t)}Tt=0 \u2208 S|Dall) Pr({f(t)}Tt=0 \u2208 S|D\u0302all) \u2264 exp(\u03b2)\nWe now state our main result on the privacy property of the penalty perturbation algorithm using the above definition. Additional assumptions on L (\u00b7) and R(\u00b7) are used.\nAssumption 4: The loss function L is strictly convex and twice differentiable. |L \u2032| \u2264 1 and 0 < L \u2032\u2032 \u2264 c1 with c1 being a constant.\nAssumption 5: The regularizer R is 1-strongly convex and twice continuously differentiable.\nTheorem 4.1 Normalize feature vectors in the training set such that ||xni ||2 \u2264 1 for all i \u2208 N and n. Then the private M-ADMM algorithm (PP) satisfies the \u03b2-differential privacy with\n\u03b2 \u2265 max i\u2208N { T\u2211 t=1 C(1.4c1 + \u03b1i(t)) \u03b7i(t)ViBi } . (26)"}, {"heading": "5. Numerical Experiments", "text": "We use the same dataset as (Zhang & Zhu, 2017), i.e., the Adult dataset from the UCI Machine Learning Repository (Lichman, 2013). It consists of personal information of around 48,842 individuals, including age, sex, race, education, occupation, income, etc. The goal is to predict whether the annual income of an individual is above $50,000.\nTo preprocess the data, we (1) remove all individuals with missing values; (2) convert each categorical attribute (with m categories) to a binary vector of length m; (3) normalize columns (features) such that the maximum value of each column is 1; (4) normalize rows (individuals) such that its l2 norm is at most 1; and (5) convert labels {\u2265 50k,\u2264 50k} to {+1,\u22121}. After this preprocessing, the final data includes 45,223 individuals, each represented as a 105-dimensional vector of norm at most 1.\nWe will use as loss function the logistic loss L (z) = log(1 + exp(\u2212z)), with |L \u2032| \u2264 1 and L \u2032\u2032 \u2264 c1 = 14 . The regularizer is R(fi) = 12 ||fi|| 2 2. We will measure the accuracy of the algorithm by the average loss L(t) := 1 N \u2211N i=1 1 Bi \u2211Bi n=1 L (y n i fi(t)\nTxni ) over the training set. We will measure the privacy of the algorithm by the upper bound P (t) := max i\u2208N { \u2211t r=1 C(1.4c1+\u03b1i(r)) \u03b7i(r)ViBi\n}. The smaller L(t) and P (t), the higher accuracy and stronger privacy guarantee."}, {"heading": "5.1. Convergence of M-ADMM", "text": "We consider a five-node network and assign each node the following private penalty parameters: \u03b7i(t) = \u03b7i(1)q t\u22121 i for node i, where [\u03b71(1), \u00b7 \u00b7 \u00b7 , \u03b75(1)] = [0.55, 0.65, 0.6, 0.55, 0.6] and [q1, \u00b7 \u00b7 \u00b7 , q5] = [1.01, 1.03, 1.1, 1.2, 1.02].\nFigure 1(a) shows the convergence of M-ADMM under these parameters while using a fixed dual updating step size \u03b8 = 0.5 across all nodes (blue curve). This is consistent with Theorem 3.1. As mentioned earlier, this step size can also be non-fixed (black) and different (red) for different nodes. In\nFigure 1(b) we let each node use the same penalty \u03b7i(t) = \u03b7(t) = 0.5qt\u221211 and compare the results by increasing q1, q1 \u2265 1. We see that increasing penalty slows down the convergence, and larger increase in q1 slows it down even more, which is consistent with Theorem 3.2."}, {"heading": "5.2. Private M-ADMM", "text": "We next inspect the accuracy and privacy of the penalty perturbation (PP) based private M-ADMM (Algorithm 1) and compare it with the dual variable perturbation (DVP) method proposed in (Zhang & Zhu, 2017). In this set of experiments, for simplicity of presentation we shall fix \u03b8 = 0.5, let \u03b7i(t) = \u03b7(t) = \u03b8qt\u221211 , and noise \u03b1i(t) = \u03b1(t) = \u03b1(1)qt\u221212 for all nodes. We observe similar results when \u03b7i(t) and \u03b1i(t) vary from node to node.\nFor each parameter setting, we perform 10 independent runs of the algorithm, and record both the mean and the range of their accuracy. Specifically, Ll(t) denotes the average loss over the training dataset in the t-th iteration of the l-th experiment (1 \u2264 l \u2264 10). The mean of average loss is then given by Lmean(t) = 110 \u221110 l=1 L\nl(t), and the range Lrange(t) = max\n1\u2264l\u226410 Ll(t) \u2212 min 1\u2264l\u226410 Ll(t). The larger the\nrange Lrange(t) the less stable the algorithm, i.e., under the same parameter setting, the difference in performances (convergence curves) of every two experiments is larger. Each parameter setting also has a corresponding upper bound on the privacy loss denoted by P (t). Figures 2(a)2(b) show both Lmean(t) and Lrange(t) as vertical bars centered at Lmean(t). Their corresponding privacy upper bound is given in Figures 2(c)2(d). The pair 2(a)-2(c) (resp. 2(b)2(d)) is for the same parameter setting.\nFigure 2 compares PP (blue & red, with \u03b7i(t) increasing geometrically) with DVP (black & magenta, with \u03b7i(t) = \u03b8, \u2200i, t). We see that in both cases improved accuracy comes at the expense of higher privacy loss (from magenta to black under DVP, from red to blue under PP). However, we also see that with suitable choices of q1, q2, PP can outperform DVP significantly both in accuracy and in privacy (e.g., red outperforms magenta in both accuracy and privacy, and blue outperforms black in both accuracy and privacy).\nWe also performed experiments with the same dataset on larger networks with tens and hundreds of nodes and with samples evenly and unevenly spread across nodes. In both cases, convergence is attained and our algorithm continues to outperform (Zhang & Zhu, 2017) in a large network (see Figures 3 & 4). Since the privacy loss of the network is dominated by the node with the largest privacy loss and it increases as the number of samples in a node decreases (Theorem 4.1), the loss of privacy in a network with uneven sample size distributions is higher; note that this is a common issue with this type of analysis."}, {"heading": "6. Discussion", "text": "Our numerical results show that increasing the penalty {\u03b7i(t)}Ni=1 over iterations can improve the algorithm\u2019s accuracy and privacy simultaneously. Below we provide some insight on why this is the case and discuss possible generalizations of our method."}, {"heading": "6.1. Higher accuracy", "text": "When the algorithm is perturbed by random noise, which is necessary to achieve privacy, increasing the penalty parameters over iterations makes the algorithm more noise resistant. In particular, for the minimization in (25), larger \u03b7i(t+ 1) results in smaller updates of variables, i.e., smaller distance between fi(t + 1) and fi(t). In the non-private case, since fi(t) always moves toward the optimum, smaller update slows down the process. In the private case, on the other hand, since a random noise is added to each update, fi(t) does not always move toward the optimum in each step. When the overall perturbation has a larger variance, it is more likely that fi(t) could move further away from the optimum in some iterations. Because larger \u03b7i(t) leads to smaller update, it helps prevent fi(t) from moving too far away from the optimum, thus stabilizing the algorithm (smaller Lrange(t))."}, {"heading": "6.2. Stronger privacy", "text": "First of all, more added noise means stronger privacy guarantee. Increasing \u03b7i(t) and \u03b1i(t) in such a way that the overall perturbation 2\u03b7i(t)Vi i(t)T fi(t) in (26) is increasing leads to less privacy loss, as shown in Figure 2. The noise resistance provided by an increasing \u03b7i(t) indeed allows larger noises to be added under PP without jeopardizing convergence as observed in Section 6.1.\nMore interestingly, keeping \u03b7i(t) private further strengthens privacy protection. Consider the following threat model: An attacker knows {(xni , yni )} Bi n=2 and {fj(t)}j\u2208Vi\u222ai for all t, i.e., all data points except for the first data point of node i, as well as all intermediate results of node i and its neighbors. If the attacker also knows the dual updating step size \u03b8 and penalty parameter {\u03b7i(t)}Tt=1 of node i, it can then infer the unknown data point (x1i , y 1 i ) with high confidence by combining the KKT optimality conditions from all iterations (see supplementary material for details). However, if the penalty parameters {\u03b7i(t)}Tt=1 are private to each node, then it is impossible for the attacker to infer the unknown data. Even if the attacker knows the participation of an individual, it remains hard to infer its features."}, {"heading": "6.3. Generalization & comparison", "text": "The main contribution of this paper is the finding that increasing {\u03b7i}Ni=1 improves the algorithm\u2019s ability to resist\nnoise: even though we increase noise in each iteration to improve privacy, the accuracy does not degrade significantly due to this increasing robustness, which improves the privacy-utility tradeoff. This property holds regardless of the noise distribution. While the present privacy analysis uses a similar framework as in (Chaudhuri et al., 2011; Zhang & Zhu, 2017) (objective perturbation with added Gamma noise), we can also use methods from other existing (centralized) ERM differentially private algorithms to every iteration in ADMM. For example, if we allow some probability (\u03b4 > 0) of violating -differential privacy and adopt a weaker variant ( , \u03b4)-differential privacy, we can adopt methods from works such as (Kifer et al., 2012; Jain & Thakurta, 2014; Bassily et al., 2014), by adding Gaussian noise to achieve tighter bounds on privacy loss. However, as noted above, the robustness is improved as {\u03b7i}Ni=1 increases; thus the same conclusion can be reached that both privacy and accuracy can be improved.\nThis idea can also be generalized to other differentially private iterative algorithms. A key observation of our algorithm is that the overall perturbation (2\u03b7i(t)Vi i(t)T fi(t)) is related to the parameter that controls the updating step size (\u03b7i(t)). In general, if the algorithm is perturbed in each iteration with a quantity \u03c6( , \u03be), which is a function of added noise and some parameter \u03be that controls the step size, such that the resulting step size and \u03c6( , \u03be) move in opposite directions (i.e., decreasing step size increases the \u03c6( , \u03be)), then it is possible to simultaneously improve both accuracy and privacy by varying \u03be to decrease the step size over time.\nInterestingly, in a differentially private (sub)gradient-based distributed algorithm (Huang et al., 2015), the step size\nand the overall perturbation move in the same direction (i.e., decreasing step size decreases perturbation). The reason for this difference is that under this subgradient-based algorithm, the sensitivity of the algorithm decreases with decreasing step size, which in turn leads to privacy constraint being satisfied with smaller perturbation. In contrast, for ADMM the sensitivity of the algorithm is independent of the step size, and the perturbation actually needs to increase to improve privacy guarantee; the decreasing step size acts to compensate for this increase in noise to maintain accuracy, as discussed in Section 6.1.\nThis issue of step size never arises in the study of (Zhang & Zhu, 2017) because the analysis is only for a single iteration; however, as we have seen doing so leads to significant total privacy loss over many iterations."}, {"heading": "7. Conclusions", "text": "This paper presents a penalty-perturbation idea to introduce privacy preservation in iterative algorithms. We showed how to modify an ADMM-based distributed algorithm to improve privacy without compromising accuracy. The key idea is to add a perturbation correlated to the step size so that they change in opposite directions. Applying this idea to other iterative algorithms can be part of the future work."}, {"heading": "Acknowledgements", "text": "This work is supported by the NSF under grants CNS1422211, CNS-1646019, CNS-1739517."}, {"heading": "A. Proof of Simplifying ADMM (Forero et al., 2010)", "text": "By KKT condition of (5), there is:\n0 = \u03bbbij(t)\u2212 \u03bbaij(t) + \u03b7(2wij(t+ 1)\u2212 fi(t+ 1)\u2212 fj(t+ 1))\nImplies:\nwij(t+ 1) = 1\n2\u03b7 (\u03bbaij(t)\u2212 \u03bbbij(t)) +\n1 2 (fi(t+ 1) + fj(t+ 1)) (27)\nPlug (27) into (6)(7):\n\u03bbaij(t+ 1) = 1\n2 (\u03bbaij(t) + \u03bb b ij(t)) +\n\u03b7 2 (fi(t+ 1)\u2212 fj(t+ 1)) (28)\n\u03bbbij(t+ 1) = 1\n2 (\u03bbbij(t) + \u03bb a ij(t)) +\n\u03b7 2 (fi(t+ 1)\u2212 fj(t+ 1)) (29)\nIf initialize \u03bbaij(0) = \u03bb b ij(0) to be zero vectors for all node pairs (i, j), (28)(29) imply that \u03bb a ij(t) = \u03bb b ij(t) and \u03bb k ji(t) = \u2212\u03bbkij(t), k \u2208 {a, b} will hold for all t. (27) becomes:\nwij(t+ 1) = 1\n2 (fi(t+ 1) + fj(t+ 1)) (30)\nLet \u03bbij(t) = \u03bbaij(t) = \u03bb b ij(t), (6)(7) can be simplified as:\n\u03bbij(t+ 1) = \u03bbij(t) + \u03b7\n2 (fi(t+ 1)\u2212 fj(t+ 1)) (31)\nPlug (30) into the augmented Lagrangian (3) to simplify it:\nL\u03b7({fi}, {wij , \u03bbkij}) = N\u2211 i=1 O(fi, Di) + N\u2211 i=1 \u2211 j\u2208Vi (\u03bbij(t)) T (fi \u2212 fj)\n+ N\u2211 i=1 \u2211 j\u2208Vi \u03b7 2 (||fi \u2212 1 2 (fi(t) + fj(t))||22) + N\u2211 i=1 \u2211 j\u2208Vi \u03b7 2 (||1 2 (fi(t) + fj(t))\u2212 fj ||22)\n(32)\nSince \u2211N i=1 \u2211 j\u2208Vi \u03bbij(t)fj = \u2211N i=1 \u2211 j\u2208Vi \u03bbji(t)fi and \u03bbij(t) = \u2212\u03bbji(t), the second term in (32) can be simplified:\nN\u2211 i=1 \u2211 j\u2208Vi (\u03bbij(t)) T (fi \u2212 fj) = 2 N\u2211 i=1 \u2211 j\u2208Vi (\u03bbij(t)) T fi\nThe last term can be expressed as:\nN\u2211 i=1 \u2211 j\u2208Vi \u03b7 2 (||1 2 (fi(t) + fj(t))\u2212 fj ||22) = N\u2211 i=1 \u2211 j\u2208Vi \u03b7 2 (||1 2 (fi(t) + fj(t))\u2212 fi||22)\nTherefore, (32) is simplified as:\nL\u03b7({fi}, {wij , \u03bbkij}) = N\u2211 i=1 O(fi, Di) + 2 N\u2211 i=1 \u2211 j\u2208Vi \u03bbij(t) T fi + N\u2211 i=1 \u2211 j\u2208Vi \u03b7(||fi \u2212 1 2 (fi(t) + fj(t))||22) (33)\nDefine \u03bbi(t) = \u2211 j\u2208Vi \u03bbij(t). Based on (31)(33), the original ADMM updates (4)-(7) are simplified as:\nfi(t+ 1) = argmin fi O(fi, Di) + 2\u03bbi(t) T fi + \u03b7 \u2211 j\u2208Vi ||fi \u2212 1 2 (fi(t) + fj(t))||22\n\u03bbi(t+ 1) = \u03bbi(t) + \u03b7\n2 \u2211 j\u2208Vi (fi(t+ 1)\u2212 fj(t+ 1))"}, {"heading": "B. Proof of Theorem 3.1", "text": "Subtract (17) from (15) and (18) from (16):\n\u2207O\u0302(f\u0302(t+ 1), Dall)\u2212\u2207O\u0302(f\u0302\u2217, Dall) + \u221a D \u2212A(Y (t+ 1)\u2212 Y \u2217) + (W (t+ 1)\u2212 \u03b8I)(D \u2212A)f\u0302(t+ 1)\n+W (t+ 1)(D +A)(f\u0302(t+ 1)\u2212 f\u0302(t)) = 0N\u00d7d (34)\nY (t+ 1) = Y (t) + \u03b8 \u221a D \u2212A(f\u0302(t+ 1)\u2212 f\u0302\u2217) (35)\nBy convexity of O(fi, Di), for any f1i and f 2 i , there is:\n(f1i \u2212 f2i )T (\u2207O(f1i , Di)\u2212\u2207O(f2i , Di)) \u2265 0\nLet \u3008\u00b7, \u00b7\u3009F be frobenius inner product of two matrices, there is:\n\u3008f\u0302(t+ 1)\u2212 f\u0302\u2217,\u2207O\u0302(f\u0302(t+ 1), Dall)\u2212\u2207O\u0302(f\u0302\u2217, Dall)\u3009F \u2265 0\nSubstitute \u2207O\u0302(f\u0302(t+ 1), Dall)\u2212\u2207O\u0302(f\u0302\u2217, Dall) from (34):\n0 \u2264 \u3008f\u0302(t+ 1)\u2212 f\u0302\u2217,\u2212 \u221a D \u2212A(Y (t+ 1)\u2212 Y \u2217)\u3009F + \u3008f\u0302(t+ 1)\u2212 f\u0302\u2217,\u2212(W (t+ 1)\u2212 \u03b8I)(D \u2212A)f\u0302(t+ 1)\u3009F +\u3008f\u0302(t+ 1)\u2212 f\u0302\u2217,\u2212W (t+ 1)(D +A)(f\u0302(t+ 1)\u2212 f\u0302(t))\u3009F (36)\nConsider the right hand side of (36). Since D\u2212A is symmetric and PSD, \u221a D \u2212A is also a symmetric matrix and by (35),\n\u3008f\u0302(t+ 1)\u2212 f\u0302\u2217,\u2212 \u221a D \u2212A(Y (t+ 1)\u2212 Y \u2217)\u3009F = \u3008\u2212 \u221a D \u2212A(f\u0302(t+ 1)\u2212 f\u0302\u2217), (Y (t+ 1)\u2212 Y \u2217)\u3009F\n= \u2212\u30081 \u03b8\n(Y (t+ 1)\u2212 Y (t)), Y (t+ 1)\u2212 Y \u2217\u3009F (37)\nRearrange (36) and use (D \u2212A)f\u0302\u2217 = 0N\u00d7d\n0 \u2265 \u3008Z(t+ 1)\u2212 Z\u2217, J(t+ 1)(Z(t+ 1)\u2212 Z(t))\u3009F + \u3008f\u0302(t+ 1)\u2212 f\u0302\u2217, (W (t+ 1)\u2212 \u03b8I)(D \u2212A)(f\u0302(t+ 1)\u2212 f\u0302\u2217)\u3009F (38)\nSuppose \u03b7i(t) \u2265 \u03b8 for all t, i, i.e., the diagonal matrix W (t)\u2212 \u03b8I 0 for all t. Since D\u2212A 0, whose eigenvalues are all non-negative, the eigenvalues of (W (t+ 1)\u2212 \u03b8I)(D \u2212A) are thus also non-negative, i.e., (W (t+ 1)\u2212 \u03b8I)(D \u2212A) 0. Then for the second term of the RHS of (38), there is:\n\u3008f\u0302(t+ 1)\u2212 f\u0302\u2217, (W (t+ 1)\u2212 \u03b8I)(D \u2212A)(f\u0302(t+ 1)\u2212 f\u0302\u2217)\u3009F \u2265 0\nTherefore, \u3008Z(t+ 1)\u2212 Z\u2217, J(t+ 1)(Z(t+ 1)\u2212 Z(t))\u3009F \u2264 0 (39)\nTo simplify the notation, for a matrix X , let ||X||2J = \u3008X, JX\u3009F , then (39) can be represented as:\n1 2 ||Z(t+ 1)\u2212 Z\u2217||2J(t+1) + 1 2 ||Z(t+ 1)\u2212 Z(t)||2J(t+1) \u2212 1 2 ||Z(t)\u2212 Z\u2217||2J(t+1) \u2264 0\nimplies\n||Z(t+ 1)\u2212 Z(t)||2J(t+1) \u2264 \u2212||Z(t+ 1)\u2212 Z \u2217||2J(t+1) + ||Z(t)\u2212 Z \u2217||2J(t) + ||Z(t)\u2212 Z \u2217||2J(t+1) \u2212 ||Z(t)\u2212 Z \u2217||2J(t) (40)\nSuppose \u03b7i(t+ 1) \u2265 \u03b7i(t) for all t and i, i.e., the diagonal matrix W (t+ 1)\u2212W (t) 0 for all t. Since D+A 0, implies (W (t+ 1)\u2212W (t))(D +A) 0. Let U = sup\ni,t,k |(fi(t)\u2212 f\u2217c )k| \u2208 R be the finite upper bound of all nodes i, all iterations t\nand all components k, then\n||Z(t)\u2212 Z\u2217||2J(t+1) \u2212 ||Z(t)\u2212 Z \u2217||2J(t) = Tr((Z(t)\u2212 Z \u2217)T (J(t+ 1)\u2212 J(t))(Z(t)\u2212 Z\u2217))\n= Tr((f\u0302(t)\u2212 f\u0302\u2217)T (W (t+ 1)\u2212W (t))(D +A)(f\u0302(t)\u2212 f\u0302\u2217)) \u2264 U2(||ones(N, d)||2W (t+1)(D+A) \u2212 ones(N, d)|| 2 W (t)(D+A))\n(41)\nwhere ones(N, d) is all one\u2019s matrix of size N \u00d7 d. By (40)(41):\n||Z(t+ 1)\u2212 Z(t)||2J(t+1) \u2264 ||Z(t)\u2212 Z \u2217||2J(t) \u2212 ||Z(t+ 1)\u2212 Z \u2217||2J(t+1) +U2(||ones(N, d)||2W (t+1)(D+A) \u2212 ||ones(N, d)|| 2 W (t)(D+A))\n(42)\nSum up (42) over t from 0 to +\u221e leads to:\n+\u221e\u2211 t=0 ||Z(t+ 1)\u2212 Z(t)||2J(t+1) \u2264 ||Z(0)\u2212 Z \u2217||2J(0) \u2212 ||Z(+\u221e)\u2212 Z \u2217||2J(+\u221e)\n+U2(||ones(N, d)||2W (+\u221e)(D+A) \u2212 ||ones(N, d)|| 2 W (0)(D+A))\n(43)\nSince \u03b7i(t) < +\u221e, the RHS of (43) is finite, implies that limt\u2192+\u221e ||Z(t+ 1)\u2212 Z(t)||2J(t+1) = 0 must hold.\nBy the definition of Z(t), J(t) and ||X||2J = \u3008X, JX\u3009F , the following must hold\nlim t\u2192+\u221e\n||f\u0302(t+ 1)\u2212 f\u0302(t)||2W (t+1)(D+A) = 0 (44)\nlim t\u2192+\u221e\n||Y (t+ 1)\u2212 Y (t)||2F = 0 (45)\n(45) shows that Y (t) converges to a stationary point Y s, along with (16) imply limt\u2192+\u221e \u221a D \u2212Af\u0302(t + 1) = 0. Since Null( \u221a D \u2212A) = c1, f\u0302(t+ 1) must lie in the subspace spanned by 1 as t\u2192\u221e. To satisfy (44), either of the following two statements must hold:\n\u2022 limt\u2192+\u221e(f\u0302(t+ 1)\u2212 f\u0302(t)) = 0N\u00d7d\n\u2022 limt\u2192+\u221eW (t+ 1)(D +A)1 = limt\u2192+\u221eW (t+ 1)A1 + limt\u2192+\u221e \u2211N i=1 \u03b7i(t+ 1)Vi = 0N\u00d71\nSince \u03b7i(t) \u2265 \u03b8 > 0 for all t, implies limt\u2192+\u221e \u2211N i=1 \u03b7i(t+ 1)Vi > 0. The second statement can never be true because all elements of A and W (t+ 1) are non-negative. Hence, f\u0302(t) should also converge to a stationary point f\u0302s.\nNow show that the stationary point (Y s, f\u0302s) is (Y \u2217, f\u0302\u2217).\nTake limit of both sides of (15) (16), substitute f\u0302s, Y s yields\n\u2207O\u0302(f\u0302s, Dall) + \u221a D \u2212AY s + (W (t+ 1)\u2212 \u03b8I)(D \u2212A)f\u0302s = 0N\u00d7d (46)\n\u221a D \u2212Af\u0302s = 0N\u00d7d (47)\nBy (47), (46) turns into: \u2207O\u0302(f\u0302s, Dall) + \u221a D \u2212AY s = 0N\u00d7d (48)\nCompare (47)(48) with (17)(18) in Lemma 3.1 and observe that (Y s, f\u0302s) satisfies the optimality condition (17)(18) and is thus the optimal point. Therefore, f(t) converges to f\u0302\u2217 and Y (t) converges to Y \u2217."}, {"heading": "C. Proof of Theorem 3.2", "text": "According to the Assumption 3 that O(fi, Di) is strongly convex and has Lipschitz continues gradients for all i \u2208 N , define diagonal matrices Dm = diag([m1;m2; \u00b7 \u00b7 \u00b7 ;mN ]) \u2208 RN\u00d7N and DM = diag([M21 ;M22 ; \u00b7 \u00b7 \u00b7 ;M2N ]) \u2208 RN\u00d7N , (20) yield:\n\u3008f\u03021 \u2212 f\u03022,\u2207O\u0302(f\u03021, Dall)\u2212\u2207O\u0302(f\u03022, Dall)\u3009F \u2265 \u3008f\u03021 \u2212 f\u03022, Dm(f\u03021 \u2212 f\u03022)\u3009F (49)\n||\u2207O\u0302(f\u03021, Dall)\u2212\u2207O\u0302(f\u03022, Dall)||2F \u2264 \u3008f\u03021 \u2212 f\u03022, DM (f\u03021 \u2212 f\u03022)\u3009F (50)\nSince for any \u00b5 > 1 and any matrices C1, C2 with the same dimensions, there is:\n||C1 + C2||2F \u2264 \u00b5||C1||2F + \u00b5\n\u00b5\u2212 1 ||C2||2F\nFrom (34), there is:\n|| \u221a D \u2212A(Y (t+ 1)\u2212 Y \u2217)||2F \u2264 \u00b5||\u2207O\u0302(f\u0302(t+ 1), Dall)\u2212\u2207O\u0302(f\u0302\u2217, Dall) +W (t+ 1)(D +A)(f\u0302(t+ 1)\u2212 f\u0302(t))||2F\n+ \u00b5\n\u00b5\u2212 1 ||(W (t+ 1)\u2212 \u03b8I)(D \u2212A)f\u0302(t+ 1)||2F \u2264\n\u00b52\n\u00b5\u2212 1 ||\u2207O\u0302(f\u0302(t+ 1), Dall)\u2212\u2207O\u0302(f\u0302\u2217, Dall)||2F\n+\u00b52||W (t+ 1)(D +A)(f\u0302(t+ 1)\u2212 f\u0302(t))||2F + \u00b5\n\u00b5\u2212 1 ||(W (t+ 1)\u2212 \u03b8I)(D \u2212A)f\u0302(t+ 1)||2F\n(51)\nLet \u03c3min(\u00b7), \u03c3max(\u00b7) denote the smallest nonzero singular value and the largest singular value of a matrix respectively.\nFor any matrices C1, C2, let C1 = U\u03a3V T be SVD of C1, there is:\n||C1C2||2F \u2264 \u03c3max(C1)||C2||2CT1\n\u03c3min(C1) 2||C2||2F \u2264 ||C1C2||2F \u2264 \u03c3max(C1)2||C2||2F\nDenote \u03c3\u0304max(t+ 1) = \u03c3max((W (t+ 1)\u2212 \u03b8I)(D \u2212A)) \u03c3\u0304min(t+ 1) = \u03c3min((W (t+ 1)\u2212 \u03b8I)(D \u2212A))\n\u03c3\u0303max(t+ 1) = \u03c3max(W (t+ 1)(D +A))\nUsing (50) and (D \u2212A)f\u0302\u2217 = 0, (51) is turned into:\n1 \u03b8 ||Y (t+ 1)\u2212 Y \u2217||2F \u2264\n\u00b52\n\u03b8\u03c3min(D \u2212A)(\u00b5\u2212 1) ||f\u0302(t+ 1)\u2212 f\u0302\u2217||2DM\n+ \u00b52\u03c3\u0303max(t+ 1)\n\u03b8\u03c3min(D \u2212A) ||f\u0302(t+ 1)\u2212 f\u0302(t)||2W (t+1)(D+A) +\n\u00b5\u03c3\u0304max(t+ 1) 2\n\u03b8\u03c3min(D \u2212A)(\u00b5\u2212 1) ||(f\u0302(t+ 1)\u2212 f\u0302\u2217)||2F\nAdding ||f\u0302(t+ 1)\u2212 f\u0302\u2217||2W (t+1)(D+A) at both sides leads to:\n||Z(t+ 1)\u2212 Z\u2217||2J(t+1) \u2264 \u00b52\u03c3\u0303max(t+ 1)\n\u03b8\u03c3min(D \u2212A) ||f\u0302(t+ 1)\u2212 f\u0302(t)||2W (t+1)(D+A)\n+||f\u0302(t+ 1)\u2212 f\u0302\u2217||2\u00b52DM+\u00b5\u03c3\u0304max(t+1)2IN \u03b8\u03c3min(D\u2212A)(\u00b5\u22121) +W (t+1)(D+A)\n(52)\nSince \u03b4(t+ 1)\u00b52\u03c3\u0303max(t+ 1)\n\u03b8\u03c3min(D \u2212A) \u2264 1 (53)\nand\n\u03b4(t+ 1)( \u00b5\u03c3\u0304max(t+ 1) 2IN + \u00b52DM \u03b8\u03c3min(D \u2212A)(\u00b5\u2212 1) +W (t+ 1)(D +A)) 2(W (t+ 1)\u2212 \u03b8I)(D \u2212A) + 2Dm (54)\nIt implies from (52) that:\n\u03b4(t+ 1)||Z(t+ 1)\u2212 Z\u2217||2J(t+1) \u2264 ||f\u0302(t+ 1)\u2212 f\u0302(t)|| 2 W (t+1)(D+A) + ||f\u0302(t+ 1)\u2212 f\u0302 \u2217||22(W (t+1)\u2212\u03b8I)(D\u2212A)+2Dm \u2264 ||Z(t+ 1)\u2212 Z(t)||2J(t+1) + ||f\u0302(t+ 1)\u2212 f\u0302 \u2217||22(W (t+1)\u2212\u03b8I)(D\u2212A)+2Dm (55)\nSubstituting f\u03021 with f\u0302(t+ 1) and f\u03022 with f\u0302\u2217 and the gradient difference from (34) in (49) leads to:\n\u3008f\u0302(t+ 1)\u2212 f\u0302\u2217, \u221a D \u2212A(Y (t+ 1)\u2212 Y \u2217)\u3009F + \u3008f\u0302(t+ 1)\u2212 f\u0302\u2217,W (t+ 1)(D +A)(f\u0302(t+ 1)\u2212 f\u0302(t))\u3009F\n+\u3008f\u0302(t+ 1)\u2212 f\u0302\u2217, (W (t+ 1)\u2212 \u03b8I)(D \u2212A)f\u0302(t+ 1)\u3009F \u2264 \u2212\u3008f\u0302(t+ 1)\u2212 f\u0302\u2217, Dm(f\u0302(t+ 1)\u2212 f\u0302\u2217)\u3009F\nSimilar to the proof of Theorem 3.1, using the definition of Z(t+ 1), Z\u2217, J(t+ 1) and (D \u2212A)f\u0302\u2217 = 0, there is:\n||Z(t+ 1)\u2212 Z\u2217||2J(t+1) \u2264 \u2212||Z(t+ 1)\u2212 Z(t)|| 2 J(t+1) + ||Z(t)\u2212 Z \u2217||2J(t+1) \u2212 ||f\u0302(t+ 1)\u2212 f\u0302 \u2217||22Dm+2(W (t+1)\u2212\u03b8I)(D\u2212A)\n(56)\nSum up (55) and (56) gives:\n(1 + \u03b4(t+ 1))||Z(t+ 1)\u2212 Z\u2217||2J(t+1) \u2264 ||Z(t)\u2212 Z \u2217||2J(t+1)\nLet mo = mini\u2208N {mi}, MO = maxi\u2208N {Mi}. One \u03b4(t+ 1) that satisfies (53) and (54) could be:\nmin{\u03b8\u03c3min(D \u2212A) \u00b52\u03c3\u0303max(t+ 1) , 2mo + 2\u03c3\u0304min(t+ 1) \u00b52M2O+\u00b5\u03c3\u0304max(t+1) 2\n\u03b8\u03c3min(D\u2212A)(\u00b5\u22121) + \u03c3\u0303max(t+ 1) }"}, {"heading": "D. Proof of Theorem 4.1", "text": "In the following proof, use the uppercase letters and lowercase letters to denote random variables and the corresponding realizations.\nSince the modified ADMM is randomized, denote Fi(t) as the random variable of the result that node i broadcasts in t-th iteration, of which the realization is fi(t). Define F (t) = {Fi(t)}Ni=1 whose realization is {fi(t)}Ni=1.\nLet FF (0:t)(\u00b7) be the joint probability distribution of F (0 : t) = {F (r)}tr=0, and FF (t)(\u00b7) be the distribution of F (t), by chain rule:\nFF (0:T )({f(r)}Tr=0) = FF (0:T\u22121)({f(r)}T\u22121r=0 ) \u00b7FF (T )(f(T )|{f(r)} T\u22121 r=0 ) = \u00b7 \u00b7 \u00b7\n= FF (0)(f(0)) \u00b7 T\u220f t=1 FF (t)(f(t)|{f(r)}t\u22121r=0)\nFor two neighboring datasets Dall and D\u0302all of the network, the ratio of joint probabilities is given by:\nFF (0:T )({f(r)}Tr=0|Dall) FF (0:T )({f(r)}Tr=0|D\u0302all) = FF (0)(f(0)|Dall) FF (0)(f(0)|D\u0302all) \u00b7 T\u220f t=1 FF (t)(f(t)|{f(r)}t\u22121r=0, Dall) FF (t)(f(t)|{f(r)}t\u22121r=0, D\u0302all)\n(57)\nSince fi(0) is randomly selected for all i, which is independent of dataset, there is FF (0)(f(0)|Dall) = FF (0)(f(0)|D\u0302all).\nFirst only consider t-th iteration, since the primal variable is updated according to (25), by KKT optimality condition, \u2207fiL priv i (t)|fi=fi(t) = 0, implies:\ni(t) = \u2212 1\n2\u03b7i(t)Vi\nC\nBi Bi\u2211 n=1 yni L \u2032(yni fi(t) Txni )x n i \u2212\n1 2\u03b7i(t)Vi ( \u03c1 N \u2207R(fi(t)) + 2\u03bbi(t\u2212 1))\n\u2212 1 2Vi \u2211 j\u2208Vi (2fi(t)\u2212 fi(t\u2212 1)\u2212 fj(t\u2212 1)) (58)\nGiven {fi(r)}t\u22121r=0, Fi(t) and Ei(t) will be bijective:\n\u2022 For any Fi(t) with the realization fi(t), \u2203 an unique Ei(t) = i(t) having the form of (58) such that the KKT condition holds.\n\u2022 Since the Lagrangian Lprivi (t) is strictly convex (by Assumption 4,5), its minimizer is unique, implies that for any Ei(t) with the realization i(t), \u2203 an unique Fi(t) = fi(t) such that the KKT condition holds.\nSince each node i generates i(t) independently, fi(t) is also independent from each other. Let FFi(t)(\u00b7) be the distribution of Fi(t), there is:\nFF (t)(f(t)|{f(r)}t\u22121r=0, Dall) FF (t)(f(t)|{f(r)}t\u22121r=0, D\u0302all) = N\u220f v=1 FFv(t)(fv(t)|{fv(r)} t\u22121 r=0, Dv) FFv(t)(fv(t)|{fv(r)} t\u22121 r=0, D\u0302v) = FFi(t)(fi(t)|{fi(r)} t\u22121 r=0, Di) FFi(t)(fi(t)|{fi(r)} t\u22121 r=0, D\u0302i)\n(59)\nSince two neighboring datasets Dall and D\u0302all only have at most one data point that is different, the second equality holds is because of the fact that this different data point could only be possessed by one node, say node i. Then there is Dj = D\u0302j for j 6= i.\nGiven {fi(r)}t\u22121r=0, let gt(\u00b7, Di) : Rd \u2192 Rd denote the one-to-one mapping from Ei(t) to Fi(t) using dataset Di. Let FEi(t)(\u00b7) be the probability density of Ei(t), by Jacobian transformation, there is4:\nFFi(t)(fi(t)|Di) = FEi(t)(g \u22121 t (fi(t), Di)) \u00b7 | det(J(g\u22121t (fi(t), Di)))| (60)\nwhere g\u22121t (fi(t), Di) is the mapping from Fi(t) to Ei(t) using data Di as shown in (58) and J(g \u22121 t (fi(t), Di)) is the Jacobian matrix of it.\nWithout loss of generality, let Di and D\u0302i be only different in the first data point, say (x1i , y 1 i ) and (x\u0302 1 i , y\u0302 1 i ) respectively. Then by (59)(60), (57) yields:\nFF (0:T )({f(r)}Tr=0|Dall) FF (0:T )({f(r)}Tr=0|D\u0302all) = T\u220f t=1 FEi(t)(g \u22121 t (fi(t), Di)) FEi(t)(g \u22121 t (fi(t), D\u0302i)) \u00b7 T\u220f t=1 |det(J(g\u22121t (fi(t), Di)))| |det(J(g\u22121t (fi(t), D\u0302i)))|\n(61)\n4We believe that there is a critical mistake in (Zhang & Zhu, 2017) and the original paper (Chaudhuri et al., 2011) where the objective perturbation method was proposed. A wrong mapping is used in both work:\nFFi(t)(fi(t)|Di) = FEi(t)(g \u22121 t (fi(t), Di)) \u00b7 | det(J(g\u22121t (fi(t), Di)))|\u22121\nConsider the first part, Ei(t) \u223c exp{\u2212\u03b1i(t)|| ||}, let \u0302i(t) = g\u22121t (fi(t), D\u0302i) and i(t) = g\u22121t (fi(t), Di)\nT\u220f t=1 FEi(t)(g \u22121 t (fi(t), Di)) FEi(t)(g \u22121 t (fi(t), D\u0302i)) = T\u220f t=1 exp(\u03b1i(t)(||\u0302i(t)|| \u2212 || i(t)||)) \u2264 exp( T\u2211 t=1 \u03b1i(t)||\u0302i(t)\u2212 i(t)||) (62)\nBy (58), Assumptions 4 and the facts that ||xni ||2 \u2264 1 (pre-normalization), yni \u2208 {+1,\u22121}.\n||\u0302i(t)\u2212 i(t)|| = 1\n2\u03b7i(t)Vi\nC Bi \u00b7 ||y1iL \u2032(y1i fi(t)Tx1i )x1i \u2212 y\u03021iL \u2032(y\u03021i fi(t)T x\u03021i )x\u03021i || \u2264\nC\n\u03b7i(t)ViBi\n(62) can be bounded: T\u220f t=1 FEi(t)(g \u22121 t (fi(t), Di)) FEi(t)(g \u22121 t (fi(t), D\u0302i)) \u2264 exp( T\u2211 t=1 C\u03b1i(t) \u03b7i(t)ViBi ) (63)\nConsider the second part, the Jacobian matrix J(g\u22121t (fi(t), Di)) is:\nJ(g\u22121t (fi(t), Di)) = \u2212 1\n2\u03b7i(t)Vi\nC\nBi Bi\u2211 n=1 L \u2032\u2032(yni fi(t) Txni )x n i (x n i ) T \u2212 1 2\u03b7i(t)Vi \u03c1 N \u22072R(fi(t))\u2212 Id\nLet G(t) = C2\u03b7i(t)ViBi (L \u2032\u2032(y\u03021i fi(t) T x\u03021i )x\u0302 1 i (x\u0302 1 i ) T \u2212L \u2032\u2032(y1i fi(t)Tx1i )x1i (x1i )T ) and H(t) = \u2212J(g \u22121 t (fi(t), Di)), there is:\n|det(J(g\u22121t (fi(t), Di)))| |det(J(g\u22121t (fi(t), D\u0302i)))| = |det(H(t))| |det(H(t) +G(t))| =\n1\n|det(I +H(t)\u22121G(t))| =\n1 | \u220fr j=1(1 + \u03bbj(H(t) \u22121G(t)))|\nwhere \u03bbj(H(t)\u22121G(t)) denotes the j-th largest eigenvalue of H(t)\u22121G(t). Since G(t) has rank at most 2, implies H(t)\u22121G(t) also has rank at most 2.\nBecause \u03b8 is determined such that 2c1 < BiC ( \u03c1 N + 2\u03b8Vi), and \u03b8 \u2264 \u03b7i(t) holds for all node i and iteration t, which implies:\nc1 Bi C ( \u03c1 N + 2\u03b7i(t)Vi) < 1 2 (64)\nBy Assumptions 4 and 5, the eigenvalue of H(t) and G(t) satisfy:\n\u03bbj(H(t)) \u2265 \u03c1\n2\u03b7i(t)ViN + 1 > 0\n\u2212 Cc1 2\u03b7i(t)ViBi \u2264 \u03bbj(G(t)) \u2264 Cc1 2\u03b7i(t)ViBi\nImplies:\n\u2212 c1 Bi C ( \u03c1 N + 2\u03b7i(t)Vi) \u2264 \u03bbj(H(t)\u22121G(t)) \u2264 c1 Bi C ( \u03c1 N + 2\u03b7i(t)Vi)\nBy (64):\n\u22121 2 \u2264 \u03bbj(H(t)\u22121G(t)) \u2264 1 2\nSince \u03bbmin(H(t)\u22121G(t)) > \u22121, there is:\n1 |1 + \u03bbmax(H(t)\u22121G(t))|2 \u2264 1 |det(I +H(t)\u22121G(t))| \u2264 1 |1 + \u03bbmin(H(t)\u22121G(t))|2\nTherefore,\nT\u220f t=1 |det(J(g\u22121t (fi(t), Di)))| |det(J(g\u22121t (fi(t), D\u0302i)))| \u2264 T\u220f t=1\n1\n|1\u2212 c1Bi C ( \u03c1 N +2\u03b7i(t)Vi)\n|2 = exp(\u2212 T\u2211 t=1 2 ln(1\u2212 c1 Bi C ( \u03c1 N + 2\u03b7i(t)Vi) )) (65)\nSince for any real number x \u2208 [0, 0.5], \u2212 ln(1 \u2212 x) < 1.4x. By condition (64), (65) can be bounded with a simper expression:\nT\u220f t=1 |det(J(g\u22121t (fi(t), Di)))| |det(J(g\u22121t (fi(t), D\u0302i)))| \u2264 exp( T\u2211 t=1 2.8c1 Bi C ( \u03c1 N + 2\u03b7i(t)Vi) ) \u2264 exp( T\u2211 t=1 1.4Cc1 \u03b7i(t)ViBi ) (66)\nCombine (63)(66), (61) can be bounded:\nFF (0:T )({f(r)}Tr=0|Dall) FF (0:T )({f(r)}Tr=0|D\u0302all) \u2264 exp( T\u2211 t=1 ( 1.4Cc1 \u03b7i(t)ViBi + C\u03b1i(t) \u03b7i(t)ViBi )) = exp( T\u2211 t=1\nC\n\u03b7i(t)ViBi (1.4c1 + \u03b1i(t)))\nTherefore, the total privacy loss during T iterations can be bounded by any \u03b2:\n\u03b2 \u2265 max i\u2208N { T\u2211 t=1\nC\n\u03b7i(t)ViBi (1.4c1 + \u03b1i(t))}\nE. Inference of Attackers when \u03b7i(t) is Non-private By KKT optimality condition in each iteration, we have:\ni(t) + 1\n2\u03b7i(t)Vi\nC Bi y1iL \u2032(y1i fi(t) Tx1i )x 1 i = \u2212\n1\n2\u03b7i(t)Vi\nC\nBi Bi\u2211 n=2 yni L \u2032(yni fi(t) Txni )x n i\n\u2212 1 2\u03b7i(t)Vi ( \u03c1 N \u2207R(fi(t)) + 2\u03bbi(t\u2212 1))\u2212 1 2Vi \u2211 j\u2208Vi (2fi(t)\u2212 fi(t\u2212 1)\u2212 fj(t\u2212 1)) .\nIn this case the attacker can compute the RHS of (67) completely. Furthermore, since Ei(t) is zero-mean, over a large number of iterations we will have 1T \u2211T t=1 i(t) \u2248 0 with high probability, which then allows the attacker to determine the features of the unknown individual up to a scaling factor, i.e., it can determine the second term on the LHS as a scalar multiplied with x1i ."}], "year": 2018, "references": [{"title": "An alternating direction method with increasing penalty for stable principal component pursuit", "authors": ["N.S. Aybat", "G. Iyengar"], "venue": "Computational Optimization and Applications,", "year": 2015}, {"title": "Differentially private empirical risk minimization: Efficient algorithms and tight error bounds", "authors": ["R. Bassily", "A. Smith", "A. Thakurta"], "venue": "arXiv preprint arXiv:1405.7085,", "year": 2014}, {"title": "Fast and Differentially Private Algorithms for Decentralized Collaborative Machine Learning", "authors": ["A. Bellet", "R. Guerraoui", "M. Taziki", "M. Tommasi"], "venue": "PhD thesis,", "year": 2017}, {"title": "A stochastic primal-dual algorithm for distributed asynchronous composite optimization", "authors": ["P. Bianchi", "W. Hachem", "F. Iutzeler"], "venue": "In Signal and Information Processing (GlobalSIP),", "year": 2014}, {"title": "Differentially private empirical risk minimization", "authors": ["K. Chaudhuri", "C. Monteleoni", "A.D. Sarwate"], "venue": "Journal of Machine Learning Research,", "year": 2011}, {"title": "Consensusbased distributed support vector machines", "authors": ["P.A. Forero", "A. Cano", "G.B. Giannakis"], "venue": "Journal of Machine Learning Research,", "year": 2010}, {"title": "Differentially private cloudbased multi-agent optimization with constraints", "authors": ["M. Hale", "M. Egerstedty"], "venue": "In American Control Conference (ACC),", "year": 2015}, {"title": "Differentially private distributed constrained optimization", "authors": ["S. Han", "U. Topcu", "G.J. Pappas"], "venue": "IEEE Transactions on Automatic Control,", "year": 2017}, {"title": "A new inexact alternating directions method for monotone variational inequalities", "authors": ["B. He", "Liao", "L.-Z", "D. Han", "H. Yang"], "venue": "Mathematical Programming,", "year": 2002}, {"title": "Differentially private distributed optimization", "authors": ["Z. Huang", "S. Mitra", "N. Vaidya"], "venue": "In Proceedings of the 2015 International Conference on Distributed Computing and Networking,", "year": 2015}, {"title": "near) dimension independent risk bounds for differentially private learning", "authors": ["P. Jain", "A.G. Thakurta"], "venue": "In International Conference on Machine Learning,", "year": 2014}, {"title": "Private convex empirical risk minimization and high-dimensional regression", "authors": ["D. Kifer", "A. Smith", "A. Thakurta"], "venue": "In Conference on Learning Theory, pp", "year": 2012}, {"title": "Decentralized linearized alternating direction method of multipliers", "authors": ["Q. Ling", "A. Ribeiro"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "year": 2014}, {"title": "Weighted admm for fast decentralized network optimization", "authors": ["Q. Ling", "Y. Liu", "W. Shi", "Z. Tian"], "venue": "IEEE Transactions on Signal Processing,", "year": 2016}, {"title": "Distributed subgradient methods for convex optimization over random networks", "authors": ["I. Lobel", "A. Ozdaglar"], "venue": "IEEE Transactions on Automatic Control,", "year": 2011}, {"title": "On the convergence of an alternating direction penalty method for nonconvex problems", "authors": ["S. Magn\u00fasson", "P.C. Weeraddana", "M.G. Rabbat", "C. Fischione"], "venue": "In Signals, Systems and Computers,", "year": 2014}, {"title": "Distributed subgradient methods for multi-agent optimization", "authors": ["A. Nedic", "A. Ozdaglar"], "venue": "IEEE Transactions on Automatic Control,", "year": 2009}, {"title": "Distributed subgradient methods and quantization effects", "authors": ["A. Nedic", "A. Olshevsky", "A. Ozdaglar", "J.N. Tsitsiklis"], "venue": "In Decision and Control,", "year": 2008}, {"title": "On the linear convergence of the admm in decentralized consensus optimization", "authors": ["W. Shi", "Q. Ling", "K. Yuan", "G. Wu", "W. Yin"], "venue": "IEEE Trans. Signal Processing,", "year": 2014}, {"title": "Fast admm algorithm for distributed optimization with adaptive penalty", "authors": ["C. Song", "S. Yoon", "V. Pavlovic"], "venue": "In AAAI,", "year": 2016}, {"title": "Distributed alternating direction method of multipliers", "authors": ["E. Wei", "A. Ozdaglar"], "venue": "In Decision and Control (CDC),", "year": 2012}, {"title": "Adaptive admm with spectral penalty parameter selection", "authors": ["Z. Xu", "M.A. Figueiredo", "T. Goldstein"], "venue": "arXiv preprint arXiv:1605.07246,", "year": 2016}, {"title": "Privacy-preserving decentralized optimization based on admm", "authors": ["C. Zhang", "Y. Wang"], "venue": "arXiv preprint arXiv:1707.04338,", "year": 2017}, {"title": "Asynchronous distributed admm for consensus optimization", "authors": ["R. Zhang", "J. Kwok"], "venue": "In International Conference on Machine Learning,", "year": 2014}, {"title": "Dynamic differential privacy for admm-based distributed classification learning", "authors": ["T. Zhang", "Q. Zhu"], "venue": "IEEE Transactions on Information Forensics and Security,", "year": 2017}], "id": "SP:29b916dfc3561794a0b493e077e6e0aacfe34a5d", "authors": [{"name": "Xueru Zhang", "affiliations": []}, {"name": "Mohammad Mahdi Khalili", "affiliations": []}, {"name": "Mingyan Liu", "affiliations": []}, {"name": "Mahdi Khalili", "affiliations": []}], "abstractText": "Alternating direction method of multiplier (ADMM) is a popular method used to design distributed versions of a machine learning algorithm, whereby local computations are performed on local data with the output exchanged among neighbors in an iterative fashion. During this iterative process the leakage of data privacy arises. A differentially private ADMM was proposed in prior work (Zhang & Zhu, 2017) where only the privacy loss of a single node during one iteration was bounded, a method that makes it difficult to balance the tradeoff between the utility attained through distributed computation and privacy guarantees when considering the total privacy loss of all nodes over the entire iterative process. We propose a perturbation method for ADMM where the perturbed term is correlated with the penalty parameters; this is shown to improve the utility and privacy simultaneously. The method is based on a modified ADMM where each node independently determines its own penalty parameter in every iteration and decouples it from the dual updating step size. The condition for convergence of the modified ADMM and the lower bound on the convergence rate are also derived.", "title": "Improving the Privacy and Accuracy of ADMM-Based Distributed Algorithms "}
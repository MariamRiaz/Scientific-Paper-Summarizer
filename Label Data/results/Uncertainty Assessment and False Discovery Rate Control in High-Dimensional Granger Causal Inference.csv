0,1,label2,summary_sentences
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 78–88 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Word Sense Disambiguation (WSD) is a key task in computational lexical semantics, inasmuch as it addresses the lexical ambiguity of text by making explicit the meaning of words occurring in a given context (Navigli, 2009).",1 Introduction,[0],[0]
"Anyone who has struggled with frustratingly unintelligible translations from an automatic system, or with the meaning bias of search engines, can understand the importance for an intelligent system to go beyond the surface appearance of text.
",1 Introduction,[0],[0]
There are two mainstream lines of research in WSD: supervised and knowledge-based WSD.,1 Introduction,[0],[0]
"Supervised WSD frames the problem as a classical machine learning task in which, first a training phase occurs aimed at learning a classification model from sentences annotated with word senses and, second the model is applied to previouslyunseen sentences focused on a target word.",1 Introduction,[0],[0]
"A key
difference from many other problems, however, is that the classes to choose from (i.e., the senses of a target word) vary for each word, therefore requiring a separate training process to be performed on a word by word basis.",1 Introduction,[0],[0]
"As a result, hundreds of training instances are needed for each ambiguous word in the vocabulary.",1 Introduction,[0],[0]
"This would necessitate a million-item training set to be manually created for each language of interest, an endeavour that is currently beyond reach even in resource-rich languages like English.
",1 Introduction,[0],[0]
"The second paradigm, i.e., knowledge-based WSD, takes a radically different approach: the idea is to exploit a general-purpose knowledge resource like WordNet (Fellbaum, 1998) to develop an algorithm which can take advantage of the structural and lexical-semantic information in the resource to choose among the possible senses of a target word occurring in context.",1 Introduction,[0],[0]
"For example, a PageRank-based algorithm can be developed to determine the probability of a given sense being reached starting from the senses of its context words.",1 Introduction,[0],[0]
"Recent approaches of this kind have been shown to obtain competitive results (Agirre et al., 2014; Moro et al., 2014).",1 Introduction,[0],[0]
"However, due to its inherent nature, knowledge-based WSD tends to adopt bag-of-word approaches which do not exploit the local lexical context of a target word, including function and collocation words, which limits this approach in some cases.
",1 Introduction,[0],[0]
"In this paper we get the best of both worlds and present Train-O-Matic, a novel method for generating huge high-quality training sets for all the words in a language’s vocabulary.",1 Introduction,[0],[0]
"The approach is language-independent, thanks to its use of a multilingual knowledge resource, BabelNet (Navigli and Ponzetto, 2012), and it can be applied to any kind of corpus.",1 Introduction,[0],[0]
"The training sets produced with Train-O-Matic are shown to provide competitive performance with those of manually and semi-
78
automatically tagged corpora.",1 Introduction,[0],[0]
"Moreover, state-ofthe-art performance is also reported for low resourced languages (i.e., Italian and Spanish) and domains, where manual training data is not available.",1 Introduction,[0],[0]
"In this Section we present Train-O-Matic, a language-independent approach to the automatic construction of a sense-tagged training set.",2 Building a Training Set from Scratch,[0],[0]
"TrainO-Matic takes as input a corpus C (e.g., Wikipedia) and a semantic network G = (V,E).",2 Building a Training Set from Scratch,[0],[0]
"We assume a WordNet-like structure of G, i.e., V is the set of concepts (i.e., synsets) such that, for each word w in the vocabulary, Senses(w) is the set of vertices in V that are expressed by w, e.g., the WordNet synsets that include w as one of their senses.
",2 Building a Training Set from Scratch,[0],[0]
"Train-O-Matic consists of three steps:
• Lexical profiling: for each vertex in the semantic network, we compute its Personalized PageRank vector, which provides its lexicalsemantic profile (Section 2.1).
",2 Building a Training Set from Scratch,[0],[0]
"• Sentence scoring: For each sentence containing a word w, we compute a probability distribution over all the senses of w based on its context (Section 2.2).
",2 Building a Training Set from Scratch,[0],[0]
"• Sentence ranking and selection: for each sense s of a word w in the vocabulary, we select those sentences that are most likely to use w in the sense of s (Section 2.3).",2 Building a Training Set from Scratch,[0],[0]
In terms of semantic networks the probability of reaching a node v′ starting from v can be interpreted as a measure of relatedness between the synsets v,2.1 Lexical profiling,[0],[0]
and v′.,2.1 Lexical profiling,[0],[0]
"Thus we define the lexical profile of a vertex v in a graph G = (V,E) as the probability distribution over all the vertices v′ in the graph.",2.1 Lexical profiling,[0],[0]
"Such distribution is computed by applying the Personalized PagaRank algorithm, a variant of the traditional PageRank (Brin and Page, 1998).",2.1 Lexical profiling,[0],[0]
"While the latter is equivalent to performing random walks with uniform restart probability on every vertex at each step, PPR, on the other hand, makes the restart probability non-uniform, thereby concentrating more probability mass in the surroundings of those vertices having higher restart
probability.",2.1 Lexical profiling,[0],[0]
"Formally, (P)PR is computed as follows:
v(t+1) =",2.1 Lexical profiling,[0],[0]
"(1− α)v(0) + αMv(t) (1)
where M is the row-normalized adjacency matrix of the semantic network, the restart probability distribution is encoded by vector v(0), and α is the well-known damping factor usually set to 0.85 (Brin and Page, 1998).",2.1 Lexical profiling,[0],[0]
"If we set v(0) to a unit probability vector (0, . . .",2.1 Lexical profiling,[0],[0]
", 0, 1, 0, . . .",2.1 Lexical profiling,[0],[0]
", 0), i.e., restart is always on a given vertex, PPR outputs the probability of reaching every vertex starting from the restart vertex after a certain number of steps.",2.1 Lexical profiling,[0],[0]
"This approach has been used in the literature to create semantic signatures (i.e., profiles) of individual concepts, i.e., vertices of the semantic network (Pilehvar et al., 2013), and then to determine the semantic similarity of concepts.",2.1 Lexical profiling,[0],[0]
"As also done by Pilehvar and Collier (2016), we instead use the PPR vector as an estimate of the conditional probability of a word w′",2.1 Lexical profiling,[0],[0]
"given the target sense1 s ∈ V of word w:
P (w′|s, w) = maxs′∈Senses(w′) vs(s ′)
Z (2)
where Z = ∑
w” P (w”|s, w) is a normalization constant, vs is the vector resulting from an adequate number of random walks used to calculate PPR, and vs(s′) is the vector component corresponding to sense s′.",2.1 Lexical profiling,[0],[0]
"To fix the number of iterations needed to have a sufficiently accurate vector, we follow Lofgren et al. (2014) and set the error δ = 0.00001 and the number of iterations to 1 δ = 100, 000.
",2.1 Lexical profiling,[0],[0]
As a result of this lexical profiling step we have a probability distribution over vocabulary words for each given word sense of interest.,2.1 Lexical profiling,[0],[0]
The objective of the second step is to score the importance of word senses for each of the corpus sentences which contain the word of interest.,2.2 Sentence scoring,[0],[0]
Given a sentence σ =,2.2 Sentence scoring,[0],[0]
"w1, w2, . .",2.2 Sentence scoring,[0],[0]
.,2.2 Sentence scoring,[0],[0]
", wn, for a given target wordw in the sentence (w ∈ σ), and for each of its senses s ∈ Senses(w), we compute the probability P (s|σ,w).",2.2 Sentence scoring,[0],[0]
"Thanks to Bayes’ theorem we can determine the probability of sense s of w given the
1Note that we use senses and concepts (synsets) interchangeably, because – given a word – a word sense unambiguously determines a concept (i.e., the synset it is contained in) and vice versa.
sentence as follows:
P (s|σ,w) =",2.2 Sentence scoring,[0],[0]
"P (σ|s, w)P (s|w) P (σ|w) (3)
= P (w1, . . .",2.2 Sentence scoring,[0],[0]
", wn|s, w)P (s|w) P (w1, . . .",2.2 Sentence scoring,[0],[0]
", wn|w) ∝",2.2 Sentence scoring,[0],[0]
"P (w1, . .",2.2 Sentence scoring,[0],[0]
.,2.2 Sentence scoring,[0],[0]
", wn|s, w)P (s|w) (4) ≈ P (w1|s, w) . . .",2.2 Sentence scoring,[0],[0]
"P (wn|s, w)P (s|w)
(5)
where Formula 4 is proportional to the original probability (due to removing the constant in the denominator) and is approximated with Formula 5 due to the assumption of independence of the words in the sentence.",2.2 Sentence scoring,[0],[0]
"P (wi|s, w) is calculated as in Formula 2 and P (s|w) is set to 1/|Senses(w)| (recall that s is a sense of w).",2.2 Sentence scoring,[0],[0]
"For example, given the sentence σ =",2.2 Sentence scoring,[0],[0]
"“A match is a tool for starting a fire”, the target word w = match and its set of senses Smatch = {s1match, s2match}, where s1match is the sense of lighter and s2match is the sense of game match, we want to calculate the probability of each simatch ∈ Smatch of being the correct sense of match in the sentence σ.",2.2 Sentence scoring,[0],[0]
"Following Formula 5 we have:
P (s1match|σ,match)",2.2 Sentence scoring,[0],[0]
"≈ P (tool|s1match,match) · P (start|s1match,match) · P (fire|s1match,match) · P (s1match|match) = 2.1 · 10−4 · 2 · 10−3 · 10−2 · 5 · 10−1 = 2.1 · 10−9
P (s2match|σ,match)",2.2 Sentence scoring,[0],[0]
"≈ P (tool|s2match,match) ·",2.2 Sentence scoring,[0],[0]
"P (start|s2match,match) · P (fire|s2match,match) · P (s2match|match) = 10−5 · 2.9 · 10−4 · 10−6 · 5 · 10−1 = 1.45 · 10−15
As can be seen, the first sense of match has a much higher probability due to its stronger relatedness to the other words in the context (i.e. start, fire and tool).",2.2 Sentence scoring,[0],[0]
Note also that all the probabilities for the second sense are at least one magnitude less than the probability of the first sense.,2.2 Sentence scoring,[0],[0]
"Finally, for a given word w and a given sense s1 ∈ Senses(w), we score each sentence σ in which w appears and s1 is its most likely sense according to a formula that takes into account the difference between the first (i.e., s1) and the second most likely sense of w in σ:
∆s1(σ)",2.3 Sense-based sentence ranking and selection,[0],[0]
"= P (s1|σ,w)− P (s2|σ,w) (6) where s1 = arg maxs∈Senses(w) P (s|σ,w), and s2 = arg maxs∈Senses(w)\{s1} P (s|σ,w).",2.3 Sense-based sentence ranking and selection,[0],[0]
We then sort all sentences based on ∆s1(·) and return a ranked list of sentences where word w is most likely to be sense-annotated with s1.,2.3 Sense-based sentence ranking and selection,[0],[0]
"Although we recognize that other scoring strategies could have been used, this was experimentally the most effective one when compared to alternative strategies, i.e., the sense probability, the number of words related to the target word w, the sentence length or a combination thereof.",2.3 Sense-based sentence ranking and selection,[0.9582434332090257],"['Granger causality formalizes the intuitive notion that in a causal system, the cause must precede the effect, and the cause must hold some unique information that helps predict the effect.']"
"In the previous Section we assumed that WordNet was our semantic network, with synsets as vertices and edges represented by its semantic relations.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"However, while its lexical coverage is high, with a rich set of fine-grained synsets, at the relation level WordNet provides mainly paradigmatic information, i.e., relations like hypernymy (is-a) and meronymy (part-of).",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"It lacks, on the other hand, syntagmatic relations, such as those that connect verb synsets to their arguments (e.g., the appropriate senses of eatv and foodn), or pairs of noun synsets (e.g., the appropriate senses of busn and drivern).
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Intuitively, Train-O-Matic would suffer from such a lack of syntagmatic relations, as the relevance of a sense for a given word in a sentence depends directly on the possibility of visiting senses of the other words in the same sentence (cf.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
Formula 5) via random walks as calculated with Formula 1.,3 Creating a Denser and Multilingual Semantic Network,[0],[0]
Such reachability depends on the connections available between synsets.,3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Because syntagmatic relations are sparse in WordNet, if it was used on its own, we would end up with a poor ranking of sentences for any given word sense.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Moreover, even though the methodology presented in Section 2 is languageindependent, Train-O-Matic would lack informa-
tion (e.g. senses for a word in an arbitrary vocabulary) for languages other than English.
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"To cope with these issues, we exploit BabelNet,2 a huge multilingual semantic network obtained from the automatic integration of WordNet, Wikipedia, Wiktionary and other resources (Navigli and Ponzetto, 2012), and create the BabelNet subgraph induced by the WordNet vertices.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
The result is a graph whose vertices are BabelNet synsets that contain at least one WordNet synset and whose edge set includes all those relations in BabelNet coming either from WordNet itself or from links in other resources mapped to WordNet (such as hyperlinks in a Wikipedia article connecting it to other articles).,3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"The greatest contribution of syntagmatic relations comes, indeed, from Wikipedia, as its articles are linked to related articles (e.g., the English Wikipedia Bus article3 is linked to Passenger, Tourism, Bus lane, Timetable, School, and many more).
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Because not all Wikipedia (and other resources’) pages are connected with the same degree of relatedness (e.g., countries are often linked, but they are not necessarily closely related to the source article in which the link occurs), we apply the following weighting strategy to each edge (s, s′) ∈ E of our WordNet-induced subgraph of BabelNet G = (V,E):
w(s, s′) =",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"{ 1 (s, s′) ∈ E(WordNet)",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"WO(s, s′)",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"otherwise
(7) where E(WordNet) is the edge set of the original WordNet graph andWO(s, s′) is the weighted
2http://babelnet.org 3Retrieved on February 3rd, 2017.
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"overlap measure which calculates the similarity between two synsets:
WO(s, s′) = ∑|S|",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"i=1(r 1 i + r
2 i ) −1∑|S|
i=1(2i)−1
where r1i and r 2",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"i are the rankings of the i-th synsets in the set S of the components in common between the vectors associated with s and s′, respectively.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Because at this stage we still have to calculate our synset vector representation, we use the precomputed NASARI vectors (Camacho-Collados et al., 2015) to calculate WO.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"This choice is due to WO’s higher performance over cosine similarity for vectors with explicit dimensions (Pilehvar et al., 2013).
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"As a result, each row of the original adjacency matrix M of G will be replaced with the weights calculated in Formula 7 and then normalized in order to be ready for PPR calculation (see Formula 1).",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"An idea of why a denser semantic network has more useful connections and thus leads to better results is provided by the example in
iment for the animal, and operating system and Windows for the device sense, among others).",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Corpora for sense annotation We used two different corpora to extract sentences: Wikipedia and the United Nations Parallel Corpus (Ziemski et al., 2016).",4 Experimental Setup,[0],[0]
"The first is the largest and most up-to-date encyclopedic resource, containing definitional information, the second, on the other hand, is a public collection of parliamentary documents of the United Nations.",4 Experimental Setup,[0],[0]
"The application of TrainO-Matic to the two corpora produced two senseannotated datasets, which we named T-O-MWiki and T-O-MUN , respectively.
",4 Experimental Setup,[0],[0]
"Semantic Network We created sense-annotated corpora with Train-O-Matic both when using PPR vectors computed from vanilla WordNet and when using WordNetBN , our denser network obtained from the WordNet-induced subgraph of BabelNet (see Section 3).
",4 Experimental Setup,[0],[0]
"Gold standard datasets We performed our evaluations using the framework made available by Raganato et al. (2017a) on five different allwords datasets, namely: the Senseval-2 (Edmonds and Cotton, 2001), Senseval-3 (Snyder and Palmer, 2004), SemEval-2007 (Pradhan et al., 2007), SemEval-2013 (Navigli et al., 2013) and SemEval-2015 (Moro and Navigli, 2015)",4 Experimental Setup,[0],[0]
WSD datasets.,4 Experimental Setup,[0],[0]
"We focused on nouns only, given the fact that Wikipedia provides connections between nominal synsets only, and therefore contributes mainly to syntagmatic relations between nouns.
",4 Experimental Setup,[0],[0]
"Comparison sense-annotated corpora To show the impact of our T-O-M corpora in WSD, we compared its performance on the above gold standard datasets, against training with:
• SemCor (Miller et al., 1993), a corpus containing about 226,000 words annotated manually with WordNet senses.
",4 Experimental Setup,[0],[0]
"• One Million Sense-Tagged Instances (Taghipour and Ng, 2015, OMSTI), a sense-annotated dataset obtained via a semi-automatic approach based on the disambiguation of a parallel corpus, i.e., the United Nations Parallel Corpus, performed by exploiting manually translated word senses.",4 Experimental Setup,[0],[0]
"Because OMSTI integrates SemCor
to increase coverage, to keep a level playing field we excluded the latter from the corpus.
",4 Experimental Setup,[0],[0]
"We note that T-O-M, instead, is fully automatic and does not require any WSD-specific human intervention nor any aligned corpus.
Reference system In all our experiments, we used It Makes Sense (Zhong and Ng, 2010, IMS), a state-of-the-art WSD system based on linear Support Vector Machines, as our reference system for comparing its performance when trained on TO-M, against the same WSD system trained on other sense-annotated corpora (i.e., SemCor and OMSTI).",4 Experimental Setup,[0],[0]
"Following the WSD literature, unless stated otherwise, we report performance in terms of F1, i.e., the harmonic mean of precision and recall.
",4 Experimental Setup,[0],[0]
"We note that it is not the purpose of this paper to show that T-O-M, when integrated into IMS, beats all other configurations or alternative systems, but rather to fully automatize the WSD pipeline with performances which are competitive with the state of the art.
",4 Experimental Setup,[0],[0]
Baseline,4 Experimental Setup,[0],[0]
"As a traditional baseline in WSD, we used the Most Frequent Sense (MFS) baseline given by the first sense in WordNet.",4 Experimental Setup,[0],[0]
"The MFS is a very competitive baseline, due to the sense skewness phenomenon in language (Navigli, 2009).
",4 Experimental Setup,[0],[0]
"Number of training sentences per sense Given a target word w, we sorted its senses Senses(w) following the WordNet ordering and selected the top ki training sentences for the i-th sense according to Formula 6, where:
ki = 1 iz ∗K",4 Experimental Setup,[0],[0]
"(8)
with K = 500 and z = 2 which were tuned on a separate small in-house development dataset5.",4 Experimental Setup,[0],[0]
The first result we report regards the impact of vanilla WordNet vs. our WordNet-induced subgraph of BabelNet (WordNetBN ) when calculating PPR vectors.,5.1 Impact of syntagmatic relations,[0],[0]
"As can be seen from Table 2 – which shows the performance of the T-O-MWiki corpora generated with the two semantic networks – using WordNet for PPR computation decreases
550 word-sense pairs annotated manually.
",5.1 Impact of syntagmatic relations,[0],[0]
"the overall performance of IMS from 0.5 to around 4 points across the five datasets, with an overall loss of 1.6 F1 points.",5.1 Impact of syntagmatic relations,[0],[0]
Similar performance losses were observed when using T-O-MUN (see Table 3).,5.1 Impact of syntagmatic relations,[0],[0]
This corroborates our hunch discussed in Section 3 that a resource like BabelNet can contribute important syntagmatic relations that are beneficial for identifying (and ranking high) sentences which are semantically relevant for the target word sense.,5.1 Impact of syntagmatic relations,[0],[0]
"In the following experiments, we report only results using WordNetBN .",5.1 Impact of syntagmatic relations,[0],[0]
"We now move to comparing the performance of T-O-M, which is fully automatic, against corpora which are annotated manually (SemCor) and semi-automatically (OMSTI).",5.2 Comparison against sense-annotated corpora,[0],[0]
"In Table 3 we show the F1-score of IMS on each gold standard dataset in the evaluation framework and on all datasets merged together (last row), when it is trained with the various corpora described above.
",5.2 Comparison against sense-annotated corpora,[0],[0]
"As can be seen, T-O-MWiki and T-O-MUN obtain higher performance than OMSTI (up to 5.5 points above) on 3 out of 5 datasets, and, overall, T-O-MWiki scores 1 point above OMSTI.",5.2 Comparison against sense-annotated corpora,[0],[0]
"The MFS is in the same ballpark as T-O-MWiki, performing better on some datasets and worse on others.",5.2 Comparison against sense-annotated corpora,[0],[0]
We note that IMS trained on T-O-MWiki succeeds in surpassing or obtaining the same results as IMS trained on SemCor on SemEval15 and SemEval-13.,5.2 Comparison against sense-annotated corpora,[0],[0]
"We view this as a significant achievement given the total absence of manual effort involved in T-O-M. Because overall T-O-MWiki outperforms T-O-MUN , in what follows we report all the results with T-O-MWiki, except for the domain-oriented evaluation (see Section 5.4).",5.2 Comparison against sense-annotated corpora,[0],[0]
"IMS uses the MFS as a backoff strategy when no sense can be output for a target word in context (Zhong and Ng, 2010).",5.3 Performance without backoff strategy,[0],[0]
"Consequently, the performance of the MFS is mixed up with that of the SVM classifier.",5.3 Performance without backoff strategy,[0],[0]
"As shown in Table 4, OMSTI is able to provide annotated sentences for roughly half of the tokens in the datasets.",5.3 Performance without backoff strategy,[0],[0]
"Train-O-Matic, on the other hand, is able to cover almost all words in each dataset with at least one training sentence.",5.3 Performance without backoff strategy,[0],[0]
"This means that in around 50% of cases OMSTI gives an answer based on the IMS backoff strategy.
",5.3 Performance without backoff strategy,[0],[0]
"To determine the real impact of the different training data, we therefore decided to perform an additional analysis of the IMS performance when the MFS backoff strategy is disabled.",5.3 Performance without backoff strategy,[0],[0]
"Because we suspected the system would not always return a sense for each target word, in this experiment we measured precision, recall and their harmonic mean, i.e., F1.",5.3 Performance without backoff strategy,[0],[0]
"The results in Table 5 confirm our hunch, showing that OMSTI’s recall drops heavily, thereby affecting F1 considerably.",5.3 Performance without backoff strategy,[0],[0]
"T-O-M performances, instead, remain high in terms of precision, recall and F1.",5.3 Performance without backoff strategy,[0],[0]
"This confirms that OMSTI relies heavily on data (those obtained for the MFS and from SemCor) that are produced manually, rather than semi-automatically.",5.3 Performance without backoff strategy,[0],[0]
"To further inspect the ability of T-O-M to enable disambiguation in different domains, we decided to evaluate on specific documents from the various gold standard datasets which could be clearly assigned a domain label.",5.4 Domain-oriented WSD,[0],[0]
"Specifically, we tested on 13 SemEval-13 documents from various domains6 and 2 SemEval-15 documents (namely, maths & computers, and biomedicine) and carried out two separate tests and evaluations of T-O-M on each domain: once using the MFS backoff strategy, and once not using it.",5.4 Domain-oriented WSD,[0],[0]
"In Tables 6 and 7 we report the results of both T-O-MWiki and T-O-MUN to determine the impact of the corpus type.
",5.4 Domain-oriented WSD,[0],[0]
"As can be seen in the tables, T-O-MWiki systematically attains higher scores than OMSTI (except for the biology domain), and, in most cases, attains higher scores than MFS when the backoff is used, with a drastic, systematic increase over OMSTI with both Train-O-Matic configurations
6Namely biology, climate, finance, health care, politics, social issues and sport.
in recall and F1 when the backoff strategy is disabled.",5.4 Domain-oriented WSD,[0],[0]
"This demonstrates the usefulness of the corpora annotated by Train-O-Matic not only on open text, but also on specific domains.",5.4 Domain-oriented WSD,[0],[0]
"We note that T-O-MUN obtains the best results in the politics domain, which is the closest domain to the UN corpus from which its training sentences are obtained.",5.4 Domain-oriented WSD,[0],[0]
"Experimental Setup In this section we investigate the ability of Train-O-Matic to scale to lowresourced languages, such as Italian and Spanish, for which training data for WSD is not available.
",6 Scaling up to Multiple Languages,[0],[0]
"Thanks to BabelNet, in fact, Train-O-Matic can
be used to generate sense-annotated data for any language supported by the knowledge base.",6 Scaling up to Multiple Languages,[0],[0]
"Thus, in order to build new training datasets for the two languages, we ran Train-O-Matic on their corresponding versions of Wikipedia, then we tuned the two parameters K and z on an in-house development dataset7.",6 Scaling up to Multiple Languages,[0],[0]
"In contrast to the English setting, in order to calculate Formula 8 we sorted the senses of each word by vertex degree.",6 Scaling up to Multiple Languages,[0],[0]
"Finally we used the output data to train IMS.
Results To perform our evaluation we chose the most recent multilingual task (SemEval 2015 task 13) which includes gold data for Italian and Spanish.",6 Scaling up to Multiple Languages,[0],[0]
"As can be seen from Table 8 TrainO-Matic enabled IMS to perform better than the best participating system (Manion and Sainudiin, 2014, SUDOKU) in all three settings (All domains, Maths & Computer and Biomedicine).",6 Scaling up to Multiple Languages,[0],[0]
"Its performance was in fact, 1 to 3 points higher, with a 6-point peak on Maths & Computer in Spanish and on Biomedicine in Italian.",6 Scaling up to Multiple Languages,[0],[0]
This demonstrates the ability of Train-O-Matic to enable supervised WSD systems to surpass state-of-theart knowledge-based WSD approaches in lowresourced languages without relying on manually curated data for training.,6 Scaling up to Multiple Languages,[0],[0]
There are two mainstream approaches to Word Sense Disambiguation: supervised and knowledge-based approaches.,7 Related Work,[0],[0]
"Both suffer in different ways from the so-called knowledge acquisition bottleneck, that is, the difficulty in obtaining an adequate amount of lexical-semantic data: for training in the case of supervised systems, and for enriching semantic networks in the case of knowledge-based ones (Pilehvar and
7We set K = 100 and z",7 Related Work,[0],[0]
"= 2.3 for Spanish and K = 100 and z = 2.5 for Italian.
Navigli, 2014; Navigli, 2009).
",7 Related Work,[0],[0]
"State-of-the-art supervised systems include Support Vector Machines such as IMS (Zhong and Ng, 2010) and, more recently, LSTM neural networks with attention and multitask learning (Raganato et al., 2017b) as well as LSTMs paired with nearest neighbours classification (Melamud et al., 2016; Yuan et al., 2016).",7 Related Work,[0],[0]
The latter also integrates a label propagation algorithm in order to enrich the sense annotated dataset.,7 Related Work,[0],[0]
"The main difference from our approach is its need for a manually annotated dataset to start the label propagation algorithm, whereas Train-O-Matic is fully automatic.",7 Related Work,[0],[0]
"An evaluation against this system would have been interesting, but neither the proprietary training data nor the code are available at the time of writing.
",7 Related Work,[0],[0]
"In order to generalize effectively, these supervised systems require large numbers of training in-
stances annotated with senses for each target word occurrence.",7 Related Work,[0],[0]
"Overall, this amounts to millions of training instances for each language of interest, a number that is not within reach for any language.",7 Related Work,[0],[0]
"In fact, no supervised system has been submitted in major multilingual WSD competitions for languages other than English (Navigli et al., 2013; Moro and Navigli, 2015).",7 Related Work,[0],[0]
"To overcome this problem, new methodologies have recently been developed which aim to create sense-tagged corpora automatically.",7 Related Work,[0],[0]
Raganato et al. (2016) developed 7 heuristics to grow the number of hyperlinks in Wikipedia pages.,7 Related Work,[0],[0]
"Otegi et al. (2016) applied a different disambiguation pipeline for each language to parallel text in Europarl (Koehn, 2005) and QTLeap (Agirre et al., 2015) in order to enrich them with semantic annotations.",7 Related Work,[0],[0]
"Taghipour and Ng (2015), the work closest to ours, exploits the alignment from English to Chinese sentences of
the United Nation Parallel Corpus (Ziemski et al., 2016) to reduce the ambiguity of English words and sense-tag English sentences.",7 Related Work,[0],[0]
The assumption is that the second language is less ambiguous than the first one and that hand-made translations of senses are available for each WordNet synset.,7 Related Work,[0],[0]
"This approach is, therefore, semi-automatic and relies on certain assumptions, in contrast to TrainO-Matic which is, instead, fully automatic and can be applied to any kind of corpus (and language) depending on the specific need.",7 Related Work,[0],[0]
Earlier attempts at the automatic extraction of training samples were made by Agirre and De Lacalle (2004) and Fernández et al. (2004).,7 Related Work,[0],[0]
"Both exploited the monosemous relatives method (Leacock et al., 1998) in order to retrieve sentences from the Web which contained a given monosemous noun or a relative monosemous word (e.g., a synonym, a hypernym, etc.).",7 Related Work,[0],[0]
"As can be seen in (Fernández et al., 2004)",7 Related Work,[0],[0]
"this approach can lead to the retrieval of very accurate examples, but its main drawback lies in the number of senses covered.",7 Related Work,[0],[0]
"In fact, for all those synsets that do not have any monosemous relative, the system is unable to retrieve examples, thus heavily affecting the performance in terms of recall and F1.",7 Related Work,[0],[0]
"Knowledge-based WSD, instead, bypasses the heavy requirement of sense-annotated corpora by applying algorithms that exploit a general-purpose semantic network, such as WordNet, which encodes the relational information that interconnects synsets via different kinds of relation.",7 Related Work,[0],[0]
"Approaches include variants of Personalized PageRank (Agirre et al., 2014) and densest subgraph approximation algorithms (Moro et al., 2014) which, thanks to the availability of multilingual resources such as BabelNet, can easily be extended to perform WSD in arbitrary languages.",7 Related Work,[0],[0]
Other approaches to knowledge-based WSD exploit the definitional knowledge contained in a dictionary.,7 Related Work,[0],[0]
"The Lesk algorithm (Lesk, 1986) and its variants (Banerjee and Pedersen, 2002; Kilgarriff and Rosenzweig, 2000; Vasilescu et al., 2004) aim to determine the correct sense of a word by comparing each wordsense definition with the context in which the target word appears.",7 Related Work,[0],[0]
"The limit of knowledge-based WSD, however, lies in the absence of mechanisms that can take into account the very local context of a target word occurrence, including non-content words such as prepositions and articles.",7 Related Work,[0],[0]
"Furthermore, recent studies seem to suggest that such
approaches are barely able to surpass supervised WSD systems when they enrich their networks starting from a comparable amount of annotated data (Pilehvar and Navigli, 2014).",7 Related Work,[0],[0]
"With T-O-M, rather than further enriching an existing semantic network, we exploit the information available in the network to annotate raw sentences with sense information and train a state-of-the-art supervised WSD system without task-specific human annotations.",7 Related Work,[0],[0]
"In this paper we presented Train-O-Matic, a novel approach to the automatic construction of large training sets for supervised WSD in an arbitrary language.",8 Conclusion,[0],[0]
"Train-O-Matic removes the burden of manual intervention by leveraging the structural semantic information available in the WordNet graph enriched with additional relational information from BabelNet, and achieves performance competitive to that of semi-automatic approaches and, in some cases, of manually-curated training data.",8 Conclusion,[0],[0]
"T-O-M was shown to provide training data for virtually all the target ambiguous nouns, in marked contrast to alternatives like OMSTI, which covers in many cases around half of the tokens, resorting to the MFS otherwise.",8 Conclusion,[0],[0]
"Moreover Train-O-Matic has proven to scale well to lowresourced languages, for which no manually annotated dataset exists, surpassing the current state of the art of knowledge-based systems.
",8 Conclusion,[0],[0]
"We believe that the ability of T-O-M to overcome the current paucity of annotated data for WSD, coupled with video games with a purpose for validation purposes (Jurgens and Navigli, 2014; Vannella et al., 2014), paves the way for high-quality multilingual supervised WSD.",8 Conclusion,[0],[0]
"All the training corpora, including approximately one million sentences which cover English, Italian and Spanish, are made available to the community at http://trainomatic.org.
",8 Conclusion,[0],[0]
"As future work we plan to extend our approach to verbs, adjectives and adverbs.",8 Conclusion,[0],[0]
Following Bennett et al. (2016) we will also experiment on more realistic estimates of P (s|w) in Formula 5 as well as other assumptions made in our work.,8 Conclusion,[0],[0]
The authors gratefully acknowledge the support of the ERC Consolidator Grant MOUSSE,Acknowledgments,[0],[0]
No.,Acknowledgments,[0],[0]
726487.,Acknowledgments,[0],[0]
Annotating large numbers of sentences with senses is the heaviest requirement of current Word Sense Disambiguation.,abstractText,[0],[0]
"We present Train-O-Matic, a languageindependent method for generating millions of sense-annotated training instances for virtually all meanings of words in a language’s vocabulary.",abstractText,[0],[0]
The approach is fully automatic: no human intervention is required and the only type of human knowledge used is a WordNet-like resource.,abstractText,[0],[0]
"Train-O-Matic achieves consistently state-of-the-art performance across gold standard datasets and languages, while at the same time removing the burden of manual annotation.",abstractText,[0],[0]
All the training data is available for research purposes at http://trainomatic.org.,abstractText,[0],[0]
Train-O-Matic: Large-Scale Supervised Word Sense Disambiguation in Multiple Languages without Manual Training Data,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1968–1978 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
Neural machine translation has recently become a method of choice in machine translation research.,1 Introduction,[0],[0]
"Besides its success in traditional settings of machine translation, that is one-to-one translation between two languages, (Sennrich et al., 2016; Chung et al., 2016), neural machine translation has ventured into more sophisticated settings of machine translation.",1 Introduction,[0],[0]
"For instance, neural machine translation has successfully proven itself to be capable of
handling subword-level representation of sentences (Lee et al., 2016; Luong and Manning, 2016; Sennrich et al., 2015; Costa-Jussa and Fonollosa, 2016; Ling et al., 2015).",1 Introduction,[0],[0]
"Furthermore, several research groups have shown its potential in seamlessly handling multiple languages (Dong et al., 2015; Luong et al., 2015a; Firat et al., 2016a,b; Lee et al., 2016; Ha et al., 2016; Viégas et al., 2016).
",1 Introduction,[0],[0]
A typical scenario of neural machine translation starts with training a model to maximize its log-likelihood.,1 Introduction,[0],[0]
"That is, we often train a model to maximize the conditional probability of a reference translation given a source sentence over a large parallel corpus.",1 Introduction,[0],[0]
"Once the model is trained in this way, it defines the conditional distribution over all possible translations given a source sentence, and the task of translation becomes equivalent to finding a translation to which the model assigns the highest conditional probability.",1 Introduction,[0],[0]
"Since it is computationally intractable to do so exactly, it is a usual practice to resort to approximate search/decoding algorithms such as greedy decoding or beam search.",1 Introduction,[0],[0]
"In this scenario, we have identified two points where improvements could be made.",1 Introduction,[0],[0]
"They are (1) training (including the selection of a model architecture) and (2) decoding.
",1 Introduction,[0],[0]
"Much of the research on neural machine translation has focused solely on the former, that is, on improving the model architecture.",1 Introduction,[0],[0]
"Neural machine translation started with with a simple encoderdecoder architecture in which a source sentence is encoded into a single, fixed-size vector (Cho et al., 2014; Sutskever et al., 2014; Kalchbrenner and Blunsom, 2013).",1 Introduction,[0],[0]
"It soon evolved with the attention mechanism (Bahdanau et al., 2014).",1 Introduction,[0],[0]
"A few variants of the attention mechanism, or its regularization, have been proposed recently to improve both the translation quality as well as the computational efficiency (Luong et al., 2015b; Cohn et al., 2016; Tu et al., 2016b).",1 Introduction,[0],[0]
"More recently, convolutional net-
1968
works have been adopted either as a replacement of or a complement to a recurrent network in order to efficiently utilize parallel computing (Kalchbrenner et al., 2016; Lee et al., 2016; Gehring et al., 2016).
",1 Introduction,[0],[0]
"On the aspect of decoding, only a few research groups have tackled this problem by incorporating a target decoding algorithm into training.",1 Introduction,[0],[0]
Wiseman and Rush (2016) and Shen et al. (2015) proposed a learning algorithm tailored for beam search.,1 Introduction,[0],[0]
"Ranzato et al. (2015) and (Bahdanau et al., 2016) suggested to use a reinforcement learning algorithm by viewing a neural machine translation model as a policy function.",1 Introduction,[0],[0]
"Investigation on decoding alone has, however, been limited.",1 Introduction,[0],[0]
Cho (2016) showed the limitation of greedy decoding by simply injecting unstructured noise into the hidden state of the neural machine translation system.,1 Introduction,[0],[0]
"Tu et al. (2016a) similarly showed that the exactness of beam search does not correlate well with actual translation quality, and proposed to augment the learning cost function with reconstruction to alleviate this problem.",1 Introduction,[0],[0]
"Li et al. (2016) proposed a modification to the existing beam search algorithm to improve its exploration of the translation space.
",1 Introduction,[0],[0]
"In this paper, we tackle the problem of decoding in neural machine translation by introducing a concept of trainable greedy decoding.",1 Introduction,[0],[0]
"Instead of manually designing a new decoding algorithm suitable for neural machine translation, we propose to learn a decoding algorithm with an arbitrary decoding objective.",1 Introduction,[0],[0]
"More specifically, we introduce a neural-network-based decoding algorithm that works on an already-trained neural machine translation system by observing and manipulating its hidden state.",1 Introduction,[0],[0]
"We treat such a neural network as an agent with a deterministic, continuous action and train it with a variant of the deterministic policy gradient algorithm (Silver et al., 2014).
",1 Introduction,[0],[0]
"We extensively evaluate the proposed trainable greedy decoding on four language pairs (En-Cs, En-De, En-Ru and En-Fi; in both directions) with two different decoding objectives; sentence-level BLEU and negative perplexity.",1 Introduction,[0],[0]
"By training such trainable greedy decoding using deterministic policy gradient with the proposed critic-aware actor learning, we observe that we can improve decoding performance with minimal computational overhead.",1 Introduction,[0],[0]
"Furthermore, the trained actors are found to improve beam search as well, suggesting a future research direction in extending the proposed idea of trainable decoding for more sophisticated
underlying decoding algorithms.",1 Introduction,[0],[0]
"Neural machine translation is a special case of conditional recurrent language modeling, where the source and target are natural language sentences.",2.1 Neural Machine Translation,[0],[0]
"Let us use X = {x1, . . .",2.1 Neural Machine Translation,[0],[0]
", xTs} and Y = {y1, . . .",2.1 Neural Machine Translation,[0],[0]
", yT } to denote source and target sentences, respectively.",2.1 Neural Machine Translation,[0],[0]
"Neural machine translation then models the target sentence given the source sentence as: p(Y |X) = ∏Tt=1 p(yt|y<t, X).",2.1 Neural Machine Translation,[0],[0]
Each term on the r.h.s.,2.1 Neural Machine Translation,[0],[0]
"of the equation above is modelled as a composite of two parametric functions:
p(yt|y<t, X) ∝",2.1 Neural Machine Translation,[0],[0]
"exp (g (yt, zt; θg)) ,
where zt = f(zt−1, yt−1, et(X; θe); θf ).",2.1 Neural Machine Translation,[0],[0]
"g is a read-out function that transforms the hidden state zt into the distribution over all possible symbols, and f is a recurrent function that compresses all the previous target words y<t and the time-dependent representation et(X; θe) of the source sentence X .",2.1 Neural Machine Translation,[0],[0]
"This time-dependent representation et is often implemented as a recurrent network encoder of the source sentence coupled with an attention mechanism (Bahdanau et al., 2014).
",2.1 Neural Machine Translation,[0],[0]
"Maximum Likelihood Learning We train a neural machine translation model, or equivalently estimate the parameters θg, θf and θe, by maximizing the log-probability of a reference translation Ŷ = {ŷ1, ..., ŷT } given a source sentence.",2.1 Neural Machine Translation,[0],[0]
"That is, we maximize the log-likelihood function:
JML(θg, θf , θe) = 1 N N∑ n=1",2.1 Neural Machine Translation,[0],[0]
"Tn∑ t=1 log pθ(ŷnt |ŷn<t, Xn),
given a training set consisting of N source-target sentence pairs.",2.1 Neural Machine Translation,[0],[0]
It is important to note that this maximum likelihood learning does not take into account how a trained model would be used.,2.1 Neural Machine Translation,[0],[0]
"Rather, it is only concerned with learning a distribution over all possible translations.",2.1 Neural Machine Translation,[0],[0]
"Once the model is trained, either by maximum likelihood learning or by any other recently proposed algorithms (Wiseman and Rush, 2016; Shen et al., 2015; Bahdanau et al., 2016; Ranzato et al., 2015), we can let the model translate a given sentence by
finding a translation that maximizes
Ŷ = arg max Y
log pθ(Y |X),
where θ = (θg, θf , θe).",2.2 Decoding,[0],[0]
"This is, however, computationally intractable, and it is a usual practice to resort to approximate decoding algorithms.
",2.2 Decoding,[0],[0]
Greedy Decoding One such approximate decoding algorithm is greedy decoding.,2.2 Decoding,[0],[0]
"In greedy decoding, we follow the conditional dependency path and pick the symbol with the highest conditional probability so far at each node.",2.2 Decoding,[0],[0]
This is equivalent to picking the best symbol one at a time from left to right in conditional language modelling.,2.2 Decoding,[0],[0]
"A decoded translation of greedy decoding is Ŷ = (ŷ1, . . .",2.2 Decoding,[0],[0]
", ŷT ), where
ŷt = arg max y∈V
log pθ(y|ŷ<t, X).",2.2 Decoding,[0],[0]
"(1)
Despite its preferable computational complexity O(|V | × T ), greedy decoding has been over time found to be undesirably sub-optimal.
",2.2 Decoding,[0],[0]
"Beam Search Beam search keeps K > 1 hypotheses, unlike greedy decoding which keeps only a single hypothesis during decoding.",2.2 Decoding,[0],[0]
"At each time step t, beam search picks K hypotheses with the highest scores ( ∏t t′=1 p(yt|y<t, X)).",2.2 Decoding,[0],[0]
"When all the hypotheses terminate (outputting the end-of-thesentence symbol), it returns the hypothesis with the highest log-probability.",2.2 Decoding,[0],[0]
"Despite its superior performance compared to greedy decoding, the computational complexity grows linearly w.r.t.",2.2 Decoding,[0],[0]
"the size of beam K, which makes it less preferable especially in the production environment.",2.2 Decoding,[0],[0]
"Although we have described decoding in neural machine translation as a maximum-a-posteriori estimation in log p(Y |X), this is not necessarily the only nor the desirable decoding objective.
",3.1 Many Decoding Objectives,[0],[0]
"First, each potential scenario in which neural machine translation is used calls for a unique decoding objective.",3.1 Many Decoding Objectives,[0],[0]
"In simultaneous translation/interpretation, which has recently been studied in the context of neural machine translation (Gu et al., 2016), the decoding objective is formulated as a trade-off between the translation quality and delay.",3.1 Many Decoding Objectives,[0],[0]
"On the other hand, when a machine translation system is used as a part of a larger information
extraction system, it is more important to correctly translate named entities and events than to translate syntactic function words.",3.1 Many Decoding Objectives,[0],[0]
"The decoding objective in this case must account for how the translation is used in subsequent modules in a larger system.
",3.1 Many Decoding Objectives,[0],[0]
"Second, the conditional probability assigned by a trained neural machine translation model does not necessarily reflect our perception of translation quality.",3.1 Many Decoding Objectives,[0],[0]
"Although Cho (2016) provided empirical evidence of high correlation between the logprobability and BLEU, a de facto standard metric in machine translation, there have also been reports on large mismatch between the log-probability and BLEU.",3.1 Many Decoding Objectives,[0],[0]
"For instance, Tu et al. (2016a) showed that beam search with a very large beam, which is supposed to find translations with better logprobabilities, suffers from pathological translations of very short length, resulting in low translation quality.",3.1 Many Decoding Objectives,[0],[0]
"This calls for a way to design or learn a decoding algorithm with an objective that is more directly correlated to translation quality.
",3.1 Many Decoding Objectives,[0],[0]
"In short, there is a significant need for designing multiple decoding algorithms for neural machine translation, regardless of how it was trained.",3.1 Many Decoding Objectives,[0],[0]
It is however non-trivial to manually design a new decoding algorithm with an arbitrary objective.,3.1 Many Decoding Objectives,[0],[0]
"This is especially true with neural machine translation, as the underlying structure of the decoding/search process – the high-dimensional hidden state of a recurrent network – is accessible but not interpretable.",3.1 Many Decoding Objectives,[0],[0]
"Instead, in the remainder of this section, we propose our approach of trainable greedy decoding.",3.1 Many Decoding Objectives,[0],[0]
"We start from the noisy, parallel approximate decoding (NPAD) algorithm proposed in (Cho, 2016).",3.2 Trainable Greedy Decoding,[0],[0]
The main idea behind NPAD algorithm is that a better translation with a higher log-probability may be found by injecting unstructured noise in the transition function of a recurrent network.,3.2 Trainable Greedy Decoding,[0],[0]
"That is,
zt = f(zt−1 + t, yt−1, et(X; θe); θf ),
where t ∼ N (0, (σ0/t)2).",3.2 Trainable Greedy Decoding,[0],[0]
NPAD avoids potential degradation of translation quality by running such a noisy greedy decoding process multiple times in parallel.,3.2 Trainable Greedy Decoding,[0],[0]
"An important lesson of NPAD algorithm is that there exists a decoding strategy with the asymptotically same computational complexity that results in a better translation quality, and that such a better translation can be found by manipulating the hidden state of the recurrent network.
",3.2 Trainable Greedy Decoding,[0],[0]
"In this work, we propose to significantly extend NPAD by replacing the unstructured noise t with a parametric function approximator, or an agent, πφ.",3.2 Trainable Greedy Decoding,[0],[0]
"This agent takes as input the previous hidden state zt−1, previously decoded word ŷt−1 and the time-dependent context vector et(X; θe) and outputs a real-valued vectorial action at ∈ Rdim(zt).",3.2 Trainable Greedy Decoding,[0],[0]
"Such an agent is trained such that greedy decoding with the agent finds a translation that maximizes any predefined, arbitrary decoding objective, while the underlying neural machine translation model is pretrained and fixed.",3.2 Trainable Greedy Decoding,[0],[0]
"Once the agent is trained, we generate a translation given a source sentence by greedy decoding however augmented with this agent.",3.2 Trainable Greedy Decoding,[0],[0]
"We call this decoding strategy trainable greedy decoding.
",3.2 Trainable Greedy Decoding,[0],[0]
Related Work:,3.2 Trainable Greedy Decoding,[0],[0]
"Soothsayer prediction function Independently from and concurrently with our work here, Li et al. (2017) proposed, just two weeks earlier, to train a neural network that predicts an arbitrary decoding objective given a source sentence and a partial hypothesis, or a prefix of translation, and to use it as an auxiliary score in beam search.",3.2 Trainable Greedy Decoding,[0],[0]
"For training such a network, referred to as a Q network in their paper, they generate each training example by either running beam search or using a ground-truth translation (when appropriate) for each source sentence.",3.2 Trainable Greedy Decoding,[0],[0]
"This approach allows one to use an arbitrary decoding objective, but it still re-
lies heavily on the log-probability of the underlying neural translation system in actual decoding.",3.2 Trainable Greedy Decoding,[0],[0]
We expect a combination of these and our approaches may further improve decoding for neural machine translation in the future.,3.2 Trainable Greedy Decoding,[0],[0]
"While all the parameters—θg, θf and θe— of the underlying neural translation model are fixed, we only update the parameters φ of the agent π.",3.3 Learning and Challenges,[0],[0]
"This ensures the generality of the pretrained translation model, and allows us to train multiple trainable greedy decoding agents with different decoding objectives, maximizing the utility of a single trained translation model.
",3.3 Learning and Challenges,[0],[0]
Let us denote by R our arbitrary decoding objective as a function that scores a translation generated from trainable greedy decoding.,3.3 Learning and Challenges,[0],[0]
"Then, our learning objective for trainable greedy decoding is
JA(φ) = EŶ=Gπ(X)X∼D",3.3 Learning and Challenges,[0],[0]
"[ R(Ŷ ) ] ,
where we used Gπ(X) as a shorthand for trainable greedy decoding with an agent π.
",3.3 Learning and Challenges,[0],[0]
There are two major challenges in learning an agent with such an objective.,3.3 Learning and Challenges,[0],[0]
"First, the decoding objective R may not be differentiable with respect to the agent.",3.3 Learning and Challenges,[0],[0]
"Especially because our goal is to accommodate an arbitrary decoding objective, this becomes a problem.",3.3 Learning and Challenges,[0],[0]
"For instance, BLEU, a standard
quality metric in machine translation, is a piecewise linear function with zero derivatives almost everywhere.",3.3 Learning and Challenges,[0],[0]
"Second, the agent here is a real-valued, deterministic policy with a very high-dimensional action space (1000s of dimensions), which is well known to be difficult.",3.3 Learning and Challenges,[0],[0]
"In order to alleviate these difficulties, we propose to use a variant of the deterministic policy gradient algorithm (Silver et al., 2014; Lillicrap et al., 2015).",3.3 Learning and Challenges,[0],[0]
"It is highly unlikely for us to have access to the gradient of an arbitrary decoding objective R with respect to the agent π, or its parameters φ.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Furthermore, we cannot estimate it stochastically because our policy π is defined to be deterministic without a predefined nor learned distribution over the action.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Instead, following (Silver et al., 2014; Lillicrap et al., 2015), we use a parametric, differentiable approximator, called a critic Rc, for the non-differentiable objective R. We train the critic by minimizing
JC(ψ)",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
= EŶ=Gπ(X)X∼D [ Rcψ(z1:T )−R(Ŷ ),4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"]2 .
",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"The critic observes the state-action sequence of the agent π via the modified hidden states (z1, . . .",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
", zT )",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"of the recurrent network, and predicts the associated decoding objective.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"By minimizing the mean squared error above, we effectively encourage the critic to approximate the non-differentiable objective as closely as possible in the vicinity of the state-action sequence visited by the agent.
",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"We implement the critic Rc as a recurrent network, similarly to the underlying neural machine translation system.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"This implies that we can compute the derivative of the predicted decoding objective with respect to the input, that is, the state-action sequence z1:T , which allows us to update the actor π, or equivalently its parameters φ, to maximize the predicted decoding objective.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Effectively we avoid the issue of non-differentiability of the original decoding objective by working with its proxy.
",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"With the critic, the learning objective of the actor is now to maximize not the original decoding objective R but its proxy RC such that
ĴA(φ)",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
= EŶ=Gπ(X)X∼D,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"[ RC(Ŷ ) ] .
",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Algorithm 1 Trainable Greedy Decoding Require: NMT θ, actor φ, critic ψ, Nc, Na, Sc, Sa, τ
1: Train θ using MLE on training set D; 2: Initialize φ and ψ; 3:",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
Shuffle D twice into Dφ and Dψ 4: while stopping criterion is not met do 5: for t = 1 :,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Nc do 6: Draw a translation pair: (X,Y ) ∼ Dψ; 7: r, rc = DECODE(Sc, X, Y, 1) 8:",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
Update ψ using∇ψ ∑ k (r c,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
k,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"− rk)2/(Sc + 1)
9: for t = 1 : Na do 10: Draw a translation pair: (X,Y ) ∼ Dφ; 11: r, rc = DECODE(Sa, X, Y, 0) 12: Compute wk = exp
(− (rck − rk)2 /τ) 13: Compute w̃k = wk/ ∑ k wk
14: Update φ using −∑k",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
(w̃k · ∇φrck),4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Function: DECODE(S,X, Y, c)
1: Ys = {}, Zs = {}, r = {}, rc = {}; 2: for k = 1 : S do 3: Sample noise ∼ N (0, σ2) for each action; 4: Greedy decoding Ŷ k = Gθ,φ(X) with ; 5: Collect hidden states zk1:T given X , Ŷ , θ, φ 6: Ys ← Ys ∪ {Y k} 7:",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Zs ← Zs ∪ {zk1:T } 8: if c = 1 then 9: Collect hidden states z1:T given X , Y , θ
10: Ys ← Ys ∪ {Y } 11:",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Zs ← Zs ∪ {z1:T } 12: for Ŷ , Z ∈ Ys, Zs do 13: Compute the critic output rc ← Rcψ(Z, Ŷ ) 14: Compute true reward r ← R(Y, Ŷ ) 15: return r, rc
Unlike the original objective, this objective function is fully differentiable with respect to the agent π.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"We thus use a usual stochastic gradient descent algorithm to train the agent, while simultaneously training the critic.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
We do so by alternating between training the actor and critic.,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Note that we maximize the return of a full episode rather than the Q value, unlike usual approaches in reinforcement learning.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
Challenges The most apparent challenge for training such a deterministic actor with a large action space is that most of action configurations will lead to zero return.,4.2 Critic-Aware Actor Learning,[0],[0]
It is also not trivial to devise an efficient exploration strategy with a deterministic actor with real-valued actions.,4.2 Critic-Aware Actor Learning,[0],[0]
"This issue has however turned out to be less of a problem than in a usual reinforcement learning setting, as the state and action spaces are well structured thanks to pretraining by maximum likelihood learning.",4.2 Critic-Aware Actor Learning,[0],[0]
"As observed by Cho (2016), any reasonable perturbation to the hidden state of the recurrent network generates a reasonable translation which would re-
ceive again a reasonable return.
",4.2 Critic-Aware Actor Learning,[0],[0]
"Although this property of dense reward makes the problem of trainable greedy decoding more manageable, we have observed other issues during our preliminary experiment with the vanilla deterministic policy gradient.",4.2 Critic-Aware Actor Learning,[0],[0]
"In order to avoid these issues that caused instability, we propose the following modifications to the vanilla algorithm.
",4.2 Critic-Aware Actor Learning,[0],[0]
"Critic-Aware Actor Learning A major goal of the critic is not to estimate the return of a given episode, but to estimate the gradient of the return evaluated given an episode.",4.2 Critic-Aware Actor Learning,[0],[0]
"In order to do so, the critic must be trained, or presented, with stateaction sequences z1:T ′ similar though not identical to the state-action sequence generated by the current actor π.",4.2 Critic-Aware Actor Learning,[0],[0]
"This is achieved, in our case, by injecting unstructured noise to the action at each
time step, similar to (Heess et al., 2015):
ãt = φ(zt, at−1) + σ · , (2)
where is a zero-mean, unit-variance normal variable.",4.2 Critic-Aware Actor Learning,[0],[0]
"This noise injection procedure is mainly used when training the critic.
",4.2 Critic-Aware Actor Learning,[0],[0]
We have however observed that the quality of the reward and its gradient estimate of the critic is very noisy even when the critic was trained with this kind of noisy actor.,4.2 Critic-Aware Actor Learning,[0],[0]
This imperfection of the critic often led to the instability in training the actor in our preliminary experiments.,4.2 Critic-Aware Actor Learning,[0],[0]
"In order to avoid this, we describe here a technique which we refer to as critic-aware actor gradient estimation.
",4.2 Critic-Aware Actor Learning,[0],[0]
"Instead of using the point estimate ∂R c
∂φ of the gradient of the predicted objective with respect to the actor’s parameters φ, we propose to use the expected gradient of the predicted objective with
respect to the critic-aware distribution Q.",4.2 Critic-Aware Actor Learning,[0],[0]
"That is,
EQ [ ∂Rcψ ∂φ ] , (3)
where we define the critic-aware distribution Q as
Q( ) ∝",4.2 Critic-Aware Actor Learning,[0],[0]
exp(−(Rcψ −R)2/τ︸,4.2 Critic-Aware Actor Learning,[0],[0]
︷︷ ︸,4.2 Critic-Aware Actor Learning,[0],[0]
"Critic-awareness
) exp(− 2
2σ2︸ ︷︷ ︸ Locality ).",4.2 Critic-Aware Actor Learning,[0],[0]
"(4)
",4.2 Critic-Aware Actor Learning,[0],[0]
"This expectation allows us to incorporate the noisy, non-uniform nature of the critic’s approximation of the objective by up-weighting the gradient computed at a point with a higher critic quality and down-weighting the gradient computed at a point with a lower critic quality.",4.2 Critic-Aware Actor Learning,[0],[0]
"The first term in Q reflects this, while the second term ensures that our estimation is based on a small region around the state-action sequence generated by the current, noise-free actor π.
",4.2 Critic-Aware Actor Learning,[0],[0]
Since it is intractable to compute Eq.,4.2 Critic-Aware Actor Learning,[0],[0]
"(3) exactly, we resort to importance sampling with the proposed distribution equal to the second term in Eq.",4.2 Critic-Aware Actor Learning,[0],[0]
(4).,4.2 Critic-Aware Actor Learning,[0],[0]
"Then, our gradient estimate for the actor becomes the sum of the gradients from multiple realizations of the noisy actor in Eq.",4.2 Critic-Aware Actor Learning,[0],[0]
"(2), where each gradient is weighted by the quality of the critic exp(−(Rcφ − R)2/τ).",4.2 Critic-Aware Actor Learning,[0],[0]
τ is a hyperparameter that controls the smoothness of the weights.,4.2 Critic-Aware Actor Learning,[0],[0]
"We observed in our preliminary experiment that the use of this criticaware actor learning significantly stabilizes general learning of both the actor and critic.
",4.2 Critic-Aware Actor Learning,[0],[0]
"Reference Translations for Training the Critic In our setting of neural machine translation, we have access to a reference translation for each source sentence X , unlike in a usual setting of reinforcement learning.",4.2 Critic-Aware Actor Learning,[0],[0]
"By force-feeding the reference translation into the underlying neural machine translation system (rather than feeding the decoded symbols), we can generate the reference state-action sequence.",4.2 Critic-Aware Actor Learning,[0],[0]
"This sequence is much less correlated with those sequences generated by the actor, and facilitates computing a better estimate of the gradient w.r.t.",4.2 Critic-Aware Actor Learning,[0],[0]
"the critic.
",4.2 Critic-Aware Actor Learning,[0],[0]
"In Alg. 1, we present the complete algorithm.",4.2 Critic-Aware Actor Learning,[0],[0]
"To make the description less cluttered, we only show the version of minibatch size = 1 which can be naturally extended.",4.2 Critic-Aware Actor Learning,[0],[0]
We also illustrate the proposed trainable greedy decoding and the proposed learning strategy in Fig. 1.,4.2 Critic-Aware Actor Learning,[0],[0]
"We empirically evaluate the proposed trainable greedy decoding on four language pairs – EnDe, En-Ru, En-Cs and En-Fi – using a standard attention-based neural machine translation system (Bahdanau et al., 2014).",5 Experimental Settings,[0],[0]
We train underlying neural translation systems using the parallel corpora made available from WMT’15.1 The same set of corpora are used for trainable greedy decoding as well.,5 Experimental Settings,[0],[0]
"All the corpora are tokenized and segmented into subword symbols using byte-pair encoding (BPE) (Sennrich et al., 2015).",5 Experimental Settings,[0],[0]
We use sentences of length up to 50 subword symbols for MLE training and 200 symbols for trainable decoding.,5 Experimental Settings,[0],[0]
"For validation and testing, we use newstest-2013 and newstest-2015, respectively.",5 Experimental Settings,[0],[0]
"Underlying NMT Model For each language pair, we implement an attention-based neural machine translation model whose encoder and decoder recurrent networks have 1,028 gated recurrent units (GRU, Cho et al., 2014) each.",5.1 Model Architectures and Learning,[0],[0]
Source and target symbols are projected into 512-dimensional embedding vectors.,5.1 Model Architectures and Learning,[0],[0]
"We trained each model for approximately 1.5 weeks using Adadelta (Zeiler, 2012).
",5.1 Model Architectures and Learning,[0],[0]
Actor π,5.1 Model Architectures and Learning,[0],[0]
We use a feedforward network with a single hidden layer as the actor.,5.1 Model Architectures and Learning,[0],[0]
"The input is a 2,056-dimensional vector which is the concatenation of the decoder hidden state and the timedependent context vector from the attention mech-
1http://www.statmt.org/wmt15/
anism, and it outputs a 1,028-dimensional action vector for the decoder.",5.1 Model Architectures and Learning,[0],[0]
"We use 32 units for the hidden layer with tanh activations.
",5.1 Model Architectures and Learning,[0],[0]
Critic Rc The critic is implemented as a variant of an attention-based neural machine translation model that takes a reference translation as a source sentence and a state-action sequence from the actor as a target sentence.,5.1 Model Architectures and Learning,[0],[0]
Both the size of GRU units and embedding vectors are the same with the underlying model.,5.1 Model Architectures and Learning,[0],[0]
"Unlike a usual neural machine translation system, the critic does not language-model the target sentence but simply outputs a scalar value to predict the true return.",5.1 Model Architectures and Learning,[0],[0]
"When we predict a bounded return, such as sentence BLEU, we use a sigmoid activation at the output.",5.1 Model Architectures and Learning,[0],[0]
"For other unbounded return like perplexity, we use a linear activation.
",5.1 Model Architectures and Learning,[0],[0]
Learning We train the actor and critic simultaneously by alternating between updating the actor and critic.,5.1 Model Architectures and Learning,[0],[0]
"As the quality of the critic’s approximation of the decoding objective has direct influence on the actor’s learning, we make ten updates to the critic before each time we update the actor once.",5.1 Model Architectures and Learning,[0],[0]
"We use RMSProp (Tieleman and Hinton, 2012) with the initial learning rates of 2× 10−6 and 2× 10−4, respectively, for the actor and critic.
",5.1 Model Architectures and Learning,[0],[0]
We monitor the progress of learning by measuring the decoding objective on the validation set.,5.1 Model Architectures and Learning,[0],[0]
"After training, we pick the actor that results in the best decoding objective on the validation set, and test it on the test set.
",5.1 Model Architectures and Learning,[0],[0]
"Decoding Objectives For each neural machine translation model, pretrained using maximum likelihood criterion, we train two trainable greedy decoding actors.",5.1 Model Architectures and Learning,[0],[0]
"One actor is trained to maximize BLEU (or its smoothed version for sentence-level
scoring (Lin and Och, 2004))",5.1 Model Architectures and Learning,[0],[0]
"as its decoding objective, and the other to minimize perplexity (or equivalently the negative log-probability normalized by the length.)
",5.1 Model Architectures and Learning,[0],[0]
We have chosen the first two decoding objectives for two purposes.,5.1 Model Architectures and Learning,[0],[0]
"First, we demonstrate that it is possible to build multiple trainable decoders with a single underlying model trained using maximum likelihood learning.",5.1 Model Architectures and Learning,[0],[0]
"Second, the comparison between these two objectives provides a glimpse into the relationship between BLEU (the most widely used automatic metric for evaluating translation systems) and log-likelihood (the most widely used learning criterion for neural machine translation).
",5.1 Model Architectures and Learning,[0],[0]
Evaluation We test the trainable greedy decoder with both greedy decoding and beam search.,5.1 Model Architectures and Learning,[0],[0]
"Although our decoder is always trained with greedy decoding, beam search in practice can be used together with the actor of the trainable greedy decoder.",5.1 Model Architectures and Learning,[0],[0]
Beam search is expected to work better especially when our training of the trainable greedy decoder is unlikely to be optimal.,5.1 Model Architectures and Learning,[0],[0]
"In both cases, we report both the perplexity and BLEU.",5.1 Model Architectures and Learning,[0],[0]
We present the improvements of BLEU and perplexity (or its negation) in Fig. 2 for all the language pair-directions.,5.2 Results and Analysis,[0],[0]
It is clear from these plots that the best result is achieved when the trainable greedy decoder was trained to maximize the target decoding objective.,5.2 Results and Analysis,[0],[0]
"When the decoder was trained to maximize sentence-level BLEU, we see the improvement in BLEU but often the degradation in the perplexity (see the left plots in Fig. 2.)",5.2 Results and Analysis,[0],[0]
"On the other hand, when the actor was trained to minimize the perplexity, we only see the improvement in per-
plexity (see the right plots in Fig. 2.)",5.2 Results and Analysis,[0],[0]
"This confirms our earlier claim that it is necessary and desirable to tune for the target decoding objective regardless of what the underlying translation system was trained for, and strongly supports the proposed idea of trainable decoding.
",5.2 Results and Analysis,[0],[0]
"The improvement from using the proposed trainable greedy decoding is smaller when used together with beam search, as seen in Fig. 2 (b).",5.2 Results and Analysis,[0],[0]
"However, we still observe statistically significant improvement in terms of BLEU (marked with red stars.)",5.2 Results and Analysis,[0],[0]
"This suggests a future direction in which we extend the proposed trainable greedy decoding to directly incorporate beam search into its training procedure to further improve the translation quality.
",5.2 Results and Analysis,[0],[0]
It is worthwhile to note that we achieved all of these improvements with negligible computational overhead.,5.2 Results and Analysis,[0],[0]
"This is due to the fact that our actor is a very small, shallow neural network, and that the more complicated critic is thrown away after training.",5.2 Results and Analysis,[0],[0]
We suspect the effectiveness of such a small actor is due to the well-structured hidden state space of the underlying neural machine translation model which was trained with a large amount of parallel corpus.,5.2 Results and Analysis,[0],[0]
"We believe this favourable computational complexity makes the proposed method suitable for production-grade neural machine translation (Wu et al., 2016; Crego et al., 2016).
",5.2 Results and Analysis,[0],[0]
"Importance of Critic-Aware Actor Learning In Fig. 3, we show sample learning curves with and without the proposed critic-aware actor learning.",5.2 Results and Analysis,[0],[0]
Both curves were from the models trained under the same condition.,5.2 Results and Analysis,[0],[0]
"Despite a slower start in the early stage of learning, we see that the critic-aware actor learning has greatly stabilized the learning progress.",5.2 Results and Analysis,[0],[0]
"We emphasize that we would not have been able to train all these 16 actors without the proposed critic-aware actor learning.
",5.2 Results and Analysis,[0],[0]
"Examples In Fig. 4, we present three examples from Ru-En.",5.2 Results and Analysis,[0],[0]
"We defined the influence as the KL divergence between the conditional distributions without the trainable greedy decoding and with the trainable greedy decoding, assuming the fixed previous hidden state and target symbol.",5.2 Results and Analysis,[0],[0]
"We colored a target word with magenta, when the influence of the trainable greedy decoding is large (> 0.001).",5.2 Results and Analysis,[0],[0]
Manual inspection of these examples as well as others has revealed that the trainable greedy decoder focuses on fixing prepositions and removing any unnecessary symbol generation.,5.2 Results and Analysis,[0],[0]
"More in-depth
analysis is however left as future work.",5.2 Results and Analysis,[0],[0]
We proposed trainable greedy decoding as a way to learn a decoding algorithm for neural machine translation with an arbitrary decoding objective.,6 Conclusion,[0],[0]
"The proposed trainable greedy decoder observes and manipulates the hidden state of a trained neural translation system, and is trained by a novel variant of deterministic policy gradient, called critic-aware actor learning.",6 Conclusion,[0],[0]
Our extensive experiments on eight language pair-directions and two objectives confirmed its validity and usefulness.,6 Conclusion,[0],[0]
"The proposed trainable greedy decoding is a generic idea that can be applied to any recurrent language modeling, and we anticipate future research both on the fundamentals of the trainable decoding as well as on the applications to more diverse tasks such as image caption generating and dialogue modeling.",6 Conclusion,[0],[0]
"KC thanks the support by TenCent, eBay, Facebook, Google (Google Faculty Award 2016) and NVidia.",Acknowledgement,[0],[0]
This work was partly supported by Samsung Advanced Institute of Technology (Next Generation Deep Learning: from pattern recognition to AI).,Acknowledgement,[0],[0]
"We sincerely thank Martin Arjovsky, Zihang Dai, Graham Neubig, Pengcheng Yin and Chunting Zhou for helpful discussions and insightful feedbacks.",Acknowledgement,[0],[0]
Recent research in neural machine translation has largely focused on two aspects; neural network architectures and end-toend learning algorithms.,abstractText,[0],[0]
"The problem of decoding, however, has received relatively little attention from the research community.",abstractText,[0],[0]
"In this paper, we solely focus on the problem of decoding given a trained neural machine translation model.",abstractText,[0],[0]
"Instead of trying to build a new decoding algorithm for any specific decoding objective, we propose the idea of trainable decoding algorithm in which we train a decoding algorithm to find a translation that maximizes an arbitrary decoding objective.",abstractText,[0],[0]
"More specifically, we design an actor that observes and manipulates the hidden state of the neural machine translation decoder and propose to train it using a variant of deterministic policy gradient.",abstractText,[0],[0]
"We extensively evaluate the proposed algorithm using four language pairs and two decoding objectives, and show that we can indeed train a trainable greedy decoder that generates a better translation (in terms of a target decoding objective) with minimal computational overhead.",abstractText,[0],[0]
Trainable Greedy Decoding for Neural Machine Translation,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1884–1895 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1884",text,[0],[0]
"The standard protocol for obtaining a labeled dataset is to have a human annotator view each example, assess its relevance, and provide a label (e.g., positive or negative for binary classification).",1 Introduction,[0],[0]
"However, this only provides one bit of information per example.",1 Introduction,[0],[0]
"This invites the question: how can we get more information per example, given that the annotator has already spent the effort reading and understanding an example?
",1 Introduction,[0],[0]
"Previous works have relied on identifying relevant parts of the input such as labeling features (Druck et al., 2009; Raghavan et al., 2005; Liang et al., 2009), highlighting rationale phrases in
text (Zaidan and Eisner, 2008; Arora and Nyberg, 2009), or marking relevant regions in images (Ahn et al., 2006).",1 Introduction,[0],[0]
"But there are certain types of information which cannot be easily reduced to annotating a portion of the input, such as the absence of a certain word, or the presence of at least two words.",1 Introduction,[0],[0]
"In this work, we tap into the power of natural language and allow annotators to provide supervision to a classifier via natural language explanations.
",1 Introduction,[0],[0]
"Specifically, we propose a framework in which annotators provide a natural language explanation for each label they assign to an example (see Figure 1).",1 Introduction,[0],[0]
"These explanations are parsed into logical forms representing labeling functions (LFs), functions that heuristically map examples to labels (Ratner et al., 2016).",1 Introduction,[0],[0]
"The labeling functions are
then executed on many unlabeled examples, resulting in a large, weakly-supervised training set that is then used to train a classifier.
",1 Introduction,[0],[0]
"Semantic parsing of natural language into logical forms is recognized as a challenging problem and has been studied extensively (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011; Liang, 2016).",1 Introduction,[0],[0]
"One of our major findings is that in our setting, even a simple rule-based semantic parser suffices for three reasons: First, we find that the majority of incorrect LFs can be automatically filtered out either semantically (e.g., is it consistent with the associated example?) or pragmatically (e.g., does it avoid assigning the same label to the entire training set?).",1 Introduction,[0],[0]
"Second, LFs near the gold LF in the space of logical forms are often just as accurate (and sometimes even more accurate).",1 Introduction,[0],[0]
"Third, techniques for combining weak supervision sources are built to tolerate some noise (Alfonseca et al., 2012; Takamatsu et al., 2012; Ratner et al., 2018).",1 Introduction,[0],[0]
The significance of this is that we can deploy the same semantic parser across tasks without task-specific training.,1 Introduction,[0],[0]
"We show how we can tackle a real-world biomedical application with the same semantic parser used to extract instances of spouses.
",1 Introduction,[0],[0]
"Our work is most similar to that of Srivastava et al. (2017), who also use natural language explanations to train a classifier, but with two important differences.",1 Introduction,[0],[0]
"First, they jointly train a task-specific semantic parser and classifier, whereas we use a
simple rule-based parser.",1 Introduction,[0],[0]
"In Section 4, we find that in our weak supervision framework, the rule-based semantic parser and the perfect parser yield nearly identical downstream performance.",1 Introduction,[0],[0]
"Second, while they use the logical forms of explanations to produce features that are fed directly to a classifier, we use them as functions for labeling a much larger training set.",1 Introduction,[0],[0]
"In Section 4, we show that using functions yields a 9.5 F1 improvement (26% relative improvement) over features, and that the F1 score scales with the amount of available unlabeled data.
",1 Introduction,[0],[0]
We validate our approach on two existing datasets from the literature (extracting spouses from news articles and disease-causing chemicals from biomedical abstracts) and one real-world use case with our biomedical collaborators at OccamzRazor to extract protein-kinase interactions related to Parkinson’s disease from text.,1 Introduction,[0],[0]
We find empirically that users are able to train classifiers with comparable F1 scores up to two orders of magnitude faster when they provide natural language explanations instead of individual labels.,1 Introduction,[0],[0]
"Our code and data can be found at https:// github.com/HazyResearch/babble.
2",1 Introduction,[0],[0]
"The BabbleLabble Framework
The BabbleLabble framework converts natural language explanations and unlabeled data into a noisily-labeled training set (see Figure 2).",1 Introduction,[0],[0]
"There are three key components: a semantic parser, a filter bank, and a label aggregator.",1 Introduction,[0],[0]
"The semantic
parser converts natural language explanations into a set of logical forms representing labeling functions (LFs).",1 Introduction,[0],[0]
The filter bank removes as many incorrect LFs as possible without requiring ground truth labels.,1 Introduction,[0],[0]
The remaining LFs are applied to unlabeled examples to produce a matrix of labels.,1 Introduction,[0],[0]
"This label matrix is passed into the label aggregator, which combines these potentially conflicting and overlapping labels into one label for each example.",1 Introduction,[0],[0]
The resulting labeled examples are then used to train an arbitrary discriminative model.,1 Introduction,[0],[0]
"To create the input explanations, the user views a subset S of an unlabeled dataset D (where |S| |D|) and provides for each input xi ∈ S a label yi and a natural language explanation ei, a sentence explaining why the example should receive that label.",2.1 Explanations,[0],[0]
"The explanation ei generally refers to specific aspects of the example (e.g., in Figure 2, the location of a specific string “his wife”).",2.1 Explanations,[0],[0]
"The semantic parser takes a natural language explanation ei and returns a set of LFs (logical forms or labeling functions) {f1, . . .",2.2 Semantic Parser,[0],[0]
", fk} of the form fi : X → {−1, 0, 1} in a binary classification setting, with 0 representing abstention.",2.2 Semantic Parser,[0],[0]
"We emphasize that the goal of this semantic parser is not to generate the single correct parse, but rather to have coverage over many potentially useful LFs.1
1Indeed, we find empirically that an incorrect LF nearby the correct one in the space of logical forms actually has higher end-task accuracy 57% of the time (see Section 4.2).
",2.2 Semantic Parser,[0],[0]
We choose a simple rule-based semantic parser that can be used without any training.,2.2 Semantic Parser,[0],[0]
"Formally, the parser uses a set of rules of the form α → β, where α can be replaced by the token(s) in β (see Figure 3 for example rules).",2.2 Semantic Parser,[0],[0]
"To identify candidate LFs, we recursively construct a set of valid parses for each span of the explanation, based on the substitutions defined by the grammar rules.",2.2 Semantic Parser,[0],[0]
"At the end, the parser returns all valid parses (LFs in our case) corresponding to the entire explanation.
",2.2 Semantic Parser,[0],[0]
We also allow an arbitrary number of tokens in a given span to be ignored when looking for a matching rule.,2.2 Semantic Parser,[0],[0]
"This improves the ability of the parser to handle unexpected input, such as unknown words or typos, since the portions of the input that are parseable can still result in a valid parse.",2.2 Semantic Parser,[0],[0]
"For example, in Figure 3, the word “person” is ignored.
",2.2 Semantic Parser,[0],[0]
"All predicates included in our grammar (summarized in Table 1) are provided to annotators, with minimal examples of each in use (Appendix A).",2.2 Semantic Parser,[0],[0]
"Importantly, all rules are domain independent (e.g., all three relation extraction tasks that we tested used the same grammar), making the semantic parser easily transferrable to new domains.",2.2 Semantic Parser,[0],[0]
"Additionally, while this paper focuses on the task of relation extraction, in principle the BabbleLabble framework can be applied to other tasks or settings by extending the grammar with the necessary primitives (e.g., adding primitives for rows and columns to enable explanations about the alignments of words in tables).",2.2 Semantic Parser,[0],[0]
"To guide the construction of the grammar, we collected 500 explanations for the Spouse domain from workers
on Amazon Mechanical Turk and added support for the most commonly used predicates.",2.2 Semantic Parser,[0],[0]
These were added before the experiments described in Section 4.,2.2 Semantic Parser,[0],[0]
Altogether the grammar contains 200 rule templates.,2.2 Semantic Parser,[0],[0]
The input to the filter bank is a set of candidate LFs produced by the semantic parser.,2.3 Filter Bank,[0],[0]
The purpose of the filter bank is to discard as many incorrect LFs as possible without requiring additional labels.,2.3 Filter Bank,[0],[0]
"It consists of two classes of filters: semantic and pragmatic.
",2.3 Filter Bank,[0],[0]
"Recall that each explanation ei is collected in the context of a specific labeled example (xi, yi).",2.3 Filter Bank,[0],[0]
"The semantic filter checks for LFs that are inconsistent with their corresponding example; formally, any LF f for which f(xi) 6=",2.3 Filter Bank,[0],[0]
yi is discarded.,2.3 Filter Bank,[0],[0]
"For example, in the first explanation in Figure 2, the word “right” can be interpreted as either “immediately” (as in “right before”) or simply “to the
right.”",2.3 Filter Bank,[0],[0]
"The latter interpretation results in a function that is inconsistent with the associated example (since “his wife” is actually to the left of person 2), so it can be safely removed.
",2.3 Filter Bank,[0],[0]
"The pragmatic filters removes LFs that are constant, redundant, or correlated.",2.3 Filter Bank,[0],[0]
"For example, in Figure 2, LF 2a is constant, as it labels every example positively (since all examples contain two people from the same sentence).",2.3 Filter Bank,[0],[0]
"LF 3b is redundant, since even though it has a different syntax tree from LF 3a, it labels the training set identically and therefore provides no new signal.
",2.3 Filter Bank,[0],[0]
"Finally, out of all LFs from the same explanation that pass all the other filters, we keep only the most specific (lowest coverage) LF.",2.3 Filter Bank,[0],[0]
"This prevents multiple correlated LFs from a single example from dominating.
",2.3 Filter Bank,[0],[0]
"As we show in Section 4, over three tasks, the filter bank removes 86% of incorrect parses, and the incorrect ones that remain have average endtask accuracy within 2.5% of the corresponding correct parses.",2.3 Filter Bank,[0],[0]
The label aggregator combines multiple (potentially conflicting) suggested labels from the LFs and combines them into a single probabilistic label per example.,2.4 Label Aggregator,[0],[0]
"Concretely, if m LFs pass the filter bank and are applied to n examples, the label aggregator implements a function f : {−1, 0, 1}m×n",2.4 Label Aggregator,[0],[0]
"→ [0, 1]n.
",2.4 Label Aggregator,[0],[0]
"A naive solution would be to use a simple majority vote, but this fails to account for the fact that LFs can vary widely in accuracy and coverage.",2.4 Label Aggregator,[0],[0]
"Instead, we use data programming (Ratner et al., 2016), which models the relationship between the true labels and the output of the labeling functions as a factor graph.",2.4 Label Aggregator,[0],[0]
"More specifically, given the true labels Y ∈ {−1, 1}n (latent) and label matrix Λ ∈ {−1, 0, 1}m×n (observed) where Λi,j = LFi(xj), we define two types of factors representing labeling propensity and accuracy:
φLabi,j (Λ, Y ) = 1{Λi,j 6= 0} (1) φAcci,j (Λ, Y ) = 1{Λi,j = yj}.",2.4 Label Aggregator,[0],[0]
"(2)
Denoting the vector of factors pertaining to a given data point xj as φj(Λ, Y ) ∈ Rm, define the model:
pw(Λ, Y )",2.4 Label Aggregator,[0],[0]
= Z −1 w exp,2.4 Label Aggregator,[0],[0]
"( n∑ j=1 w · φj(Λ, Y ) )",2.4 Label Aggregator,[0],[0]
", (3)
where w ∈ R2m is the weight vector and Zw is the normalization constant.",2.4 Label Aggregator,[0],[0]
"To learn this model without knowing the true labels Y , we minimize the negative log marginal likelihood given the observed labels Λ:
ŵ = arg min w − log ∑ Y pw(Λ, Y ) (4)
using SGD and Gibbs sampling for inference, and then use the marginals pŵ(Y | Λ) as probabilistic training labels.
",2.4 Label Aggregator,[0],[0]
"Intuitively, we infer accuracies of the LFs based on the way they overlap and conflict with one another.",2.4 Label Aggregator,[0],[0]
"Since noisier LFs are more likely to have high conflict rates with others, their corresponding accuracy weights in w will be smaller, reducing their influence on the aggregated labels.",2.4 Label Aggregator,[0],[0]
The noisily-labeled training set that the label aggregator outputs is used to train an arbitrary discriminative model.,2.5 Discriminative Model,[0],[0]
One advantage of training a discriminative model on the task instead of using the label aggregator as a classifier directly is that the label aggregator only takes into account those signals included in the LFs.,2.5 Discriminative Model,[0],[0]
"A discriminative model, on the other hand, can incorporate features that were not identified by the user but are nevertheless informative.2 Consequently, even examples for which all LFs abstained can still be classified correctly.",2.5 Discriminative Model,[0],[0]
"On the three tasks we evaluate, using the discriminative model averages 4.3 F1 points higher than using the label aggregator directly.
",2.5 Discriminative Model,[0],[0]
"For the results reported in this paper, our discriminative model is a simple logistic regression classifier with generic features defined over dependency paths.3 These features include unigrams,
2We give an example of two such features in Section 4.3.",2.5 Discriminative Model,[0],[0]
"3https://github.com/HazyResearch/treedlib
bigrams, and trigrams of lemmas, dependency labels, and part of speech tags found in the siblings, parents, and nodes between the entities in the dependency parse of the sentence.",2.5 Discriminative Model,[0],[0]
"We found this to perform better on average than a biLSTM, particularly for the traditional supervision baselines with small training set sizes; it also provided easily interpretable features for analysis.",2.5 Discriminative Model,[0],[0]
"We evaluate the accuracy of BabbleLabble on three relation extraction tasks, which we refer to as Spouse, Disease, and Protein.",3 Experimental Setup,[0],[0]
"The goal of each task is to train a classifier for predicting whether the two entities in an example are participating in the relationship of interest, as described below.",3 Experimental Setup,[0],[0]
"Statistics for each dataset are reported in Table 2, with one example and one explanation for each given in Figure 4 and additional explanations shown in Appendix B.
In the Spouse task, annotators were shown a sentence with two highlighted names and asked to label whether the sentence suggests that the two people are spouses.",3.1 Datasets,[0],[0]
"Sentences were pulled from the Signal Media dataset of news articles (Corney
et al., 2016).",3.1 Datasets,[0],[0]
"Ground truth data was collected from Amazon Mechanical Turk workers, accepting the majority label over three annotations.",3.1 Datasets,[0],[0]
"The 30 explanations we report on were sampled randomly from a pool of 200 that were generated by 10 graduate students unfamiliar with BabbleLabble.
",3.1 Datasets,[0],[0]
"In the Disease task, annotators were shown a sentence with highlighted names of a chemical and a disease and asked to label whether the sentence suggests that the chemical causes the disease.",3.1 Datasets,[0],[0]
"Sentences and ground truth labels came from a portion of the 2015 BioCreative chemical-disease relation dataset (Wei et al., 2015), which contains abstracts from PubMed.",3.1 Datasets,[0],[0]
"Because this task requires specialized domain expertise, we obtained explanations by having someone unfamiliar with BabbleLabble translate from Python to natural language labeling functions from an existing publication that explored applying weak supervision to this task (Ratner et al., 2018).
",3.1 Datasets,[0],[0]
"The Protein task was completed in conjunction with OccamzRazor, a neuroscience company targeting biological pathways of Parkinson’s disease.",3.1 Datasets,[0],[0]
"For this task, annotators were shown a sentence from the relevant biomedical literature with highlighted names of a protein and a kinase and asked to label whether or not the kinase influences the protein in terms of a physical interaction or phosphorylation.",3.1 Datasets,[0],[0]
"The annotators had domain expertise but minimal programming experience, making BabbleLabble a natural fit for their use case.",3.1 Datasets,[0],[0]
Text documents are tokenized with spaCy.4,3.2 Experimental Settings,[0],[0]
"The semantic parser is built on top of the Python-based
4https://github.com/explosion/spaCy
implementation SippyCup.5 On a single core, parsing 360 explanations takes approximately two seconds.",3.2 Experimental Settings,[0],[0]
"We use existing implementations of the label aggregator, feature library, and discriminative classifier described in Sections 2.4–2.5 provided by the open-source project Snorkel (Ratner et al., 2018).
",3.2 Experimental Settings,[0],[0]
Hyperparameters for all methods we report were selected via random search over thirty configurations on the same held-out development set.,3.2 Experimental Settings,[0],[0]
"We searched over learning rate, batch size, L2 regularization, and the subsampling rate (for improving balance between classes).6 All reported F1 scores are the average value of 40 runs with random seeds and otherwise identical settings.",3.2 Experimental Settings,[0],[0]
"We evaluate the performance of BabbleLabble with respect to its rate of improvement by number of user inputs, its dependence on correctly parsed logical forms, and the mechanism by which it utilizes logical forms.",4 Experimental Results,[0],[0]
In Table 3 we report the average F1 score of a classifier trained with BabbleLabble using 30 explanations or traditional supervision with the indicated number of labels.,4.1 High Bandwidth Supervision,[0],[0]
"On average, it took the same amount of time to collect 30 explanations as 60 labels.7 We observe that in all three tasks, BabbleLabble achieves a given F1 score with far fewer user inputs than traditional supervision, by
5https://github.com/wcmac/sippycup 6Hyperparameter ranges: learning rate (1e-2 to 1e-4), batch size (32 to 128), L2 regularization (0 to 100), subsampling rate (0 to 0.5)
7Zaidan and Eisner (2008) also found that collecting annotator rationales in the form of highlighted substrings from the sentence only doubled annotation time.
as much as 100 times in the case of the Spouse task.",4.1 High Bandwidth Supervision,[0],[0]
"Because explanations are applied to many unlabeled examples, each individual input from the user can implicitly contribute many (noisy) labels to the learning algorithm.
",4.1 High Bandwidth Supervision,[0],[0]
"We also observe, however, that once the number of labeled examples is sufficiently large, traditional supervision once again dominates, since ground truth labels are preferable to noisy ones generated by labeling functions.",4.1 High Bandwidth Supervision,[0],[0]
"However, in domains where there is much more unlabeled data available than labeled data (which in our experience is most domains), we can gain in supervision efficiency from using BabbleLabble.
",4.1 High Bandwidth Supervision,[0],[0]
"Of those explanations that did not produce a correct LF, 4% were caused by the explanation referring to unsupported concepts (e.g., one explanation referred to “the subject of the sentence,” which our simple parser doesn’t support).",4.1 High Bandwidth Supervision,[0],[0]
Another 2% were caused by human errors (the correct LF for the explanation was inconsistent with the example).,4.1 High Bandwidth Supervision,[0],[0]
"The remainder were due to unrecognized paraphrases (e.g., the explanation said “the order of appearance is X, Y” instead of a supported phrasing like “X comes before Y”).",4.1 High Bandwidth Supervision,[0],[0]
"In Table 4, we report LF summary statistics before and after filtering.",4.2 Utility of Incorrect Parses,[0],[0]
LF correctness is based on exact match with a manually generated parse for each explanation.,4.2 Utility of Incorrect Parses,[0],[0]
"Surprisingly, the simple heuristic-based filter bank successfully removes over 95% of incorrect LFs in all three tasks, resulting in final LF sets that are 86% correct on average.",4.2 Utility of Incorrect Parses,[0],[0]
"Furthermore, among those LFs that pass through the filter bank, we found that the average difference in end-task accuracy between correct and incorrect parses is less than 2.5%.",4.2 Utility of Incorrect Parses,[0],[0]
"Intuitively, the filters are effective because it is quite difficult for an LF to be parsed from the explana-
tion, label its own example correctly (passing the semantic filter), and not label all examples in the training set with the same label or identically to another LF (passing the pragmatic filter).
",4.2 Utility of Incorrect Parses,[0],[0]
"We went one step further: using the LFs that would be produced by a perfect semantic parser as starting points, we searched for “nearby” LFs (LFs differing by only one predicate) with higher endtask accuracy on the test set and succeeded 57% of the time (see Figure 5 for an example).",4.2 Utility of Incorrect Parses,[0],[0]
"In other words, when users provide explanations, the signals they describe provide good starting points, but they are actually unlikely to be optimal.",4.2 Utility of Incorrect Parses,[0],[0]
"This observation is further supported by Table 5, which shows that the filter bank is necessary to remove clearly irrelevant LFs, but with that in place, the simple rule-based semantic parser and a perfect parser have nearly identical average F1 scores.",4.2 Utility of Incorrect Parses,[0],[0]
"Once we have relevant logical forms from userprovided explanations, we have multiple options for how to use them.",4.3 Using LFs as Functions or Features,[0],[0]
Srivastava et al. (2017) propose using these logical forms as features in a linear classifier.,4.3 Using LFs as Functions or Features,[0],[0]
"We choose instead to use them as functions for weakly supervising the creation of a larger training set via data programming (Ratner et al., 2016).",4.3 Using LFs as Functions or Features,[0],[0]
"In Table 6, we compare the two approaches directly, finding that the the data programming approach outperforms a feature-based one by 9.5 F1 points with the rule-based parser, and by 4.5 points with a perfect parser.
",4.3 Using LFs as Functions or Features,[0],[0]
We attribute this difference primarily to the ability of data programming to utilize unlabeled data.,4.3 Using LFs as Functions or Features,[0],[0]
"In Figure 6, we show how the data programming approach improves with the number of unlabeled examples, even as the number of LFs remains constant.",4.3 Using LFs as Functions or Features,[0],[0]
We also observe qualitatively that data programming exposes the classifier to additional patterns that are correlated with our explanations but not mentioned directly.,4.3 Using LFs as Functions or Features,[0],[0]
"For example, in the Disease task, two of the features weighted most
highly by the discriminative model were the presence of the trigrams “could produce a” or “support diagnosis of” between the chemical and disease, despite none of these words occurring in the explanations for that task.",4.3 Using LFs as Functions or Features,[0],[0]
In Table 6 we see a 4.3 F1 point improvement (10%) when we use the discriminative model that can take advantage of these features rather than applying the LFs directly to the test set and making predictions based on the output of the label aggregator.,4.3 Using LFs as Functions or Features,[0],[0]
Our work has two themes: modeling natural language explanations/instructions and learning from weak supervision.,5 Related Work and Discussion,[0],[0]
The closest body of work is on “learning from natural language.”,5 Related Work and Discussion,[0],[0]
"As mentioned earlier, Srivastava et al. (2017) convert natural language explanations into classifier features (whereas we convert them into labeling functions).",5 Related Work and Discussion,[0],[0]
"Goldwasser and Roth (2011) convert natural lan-
guage into concepts (e.g., the rules of a card game).",5 Related Work and Discussion,[0],[0]
Ling and Fidler (2017) use natural language explanations to assist in supervising an image captioning model.,5 Related Work and Discussion,[0],[0]
Weston (2016); Li et al. (2016) learn from natural language feedback in a dialogue.,5 Related Work and Discussion,[0],[0]
"Wang et al. (2017) convert natural language definitions to rules in a semantic parser to build up progressively higher-level concepts.
",5 Related Work and Discussion,[0],[0]
"We lean on the formalism of semantic parsing (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang, 2016).",5 Related Work and Discussion,[0],[0]
"One notable trend is to learn semantic parsers from weak supervision (Clarke et al., 2010; Liang et al., 2011), whereas our goal is to obtain weak supervision signal from semantic parsers.
",5 Related Work and Discussion,[0],[0]
The broader topic of weak supervision has received much attention; we mention some works most related to relation extraction.,5 Related Work and Discussion,[0],[0]
"In distant supervision (Craven et al., 1999; Mintz et al., 2009) and multi-instance learning (Riedel et al., 2010; Hoffmann et al., 2011), an existing knowledge base is used to (probabilistically) impute a training set.",5 Related Work and Discussion,[0],[0]
"Various extensions have focused on aggregating a variety of supervision sources by learning generative models from noisy labels (Alfonseca et al., 2012; Takamatsu et al., 2012; Roth and Klakow, 2013; Ratner et al., 2016; Varma et al., 2017).
",5 Related Work and Discussion,[0],[0]
"Finally, while we have used natural language explanations as input to train models, they can also be output to interpret models (Krening et al., 2017; Lei et al., 2016).",5 Related Work and Discussion,[0],[0]
"More generally, from a machine learning perspective, labels are the primary asset, but they are a low bandwidth signal between annotators and the learning algorithm.",5 Related Work and Discussion,[0],[0]
Natural language opens up a much higher-bandwidth communication channel.,5 Related Work and Discussion,[0],[0]
"We have shown promising results in relation extraction (where one explanation can be “worth” 100 labels), and it would be interesting to extend our framework to other tasks and more interactive settings.",5 Related Work and Discussion,[0],[0]
"The code, data, and experiments for this paper are available on the CodaLab platform at https: //worksheets.codalab.org/worksheets/ 0x900e7e41deaa4ec5b2fe41dc50594548/.",Reproducibility,[0],[0]
We gratefully acknowledge the support of the following organizations: DARPA under No.,Acknowledgments,[0],[0]
"N66001-15-C-4043 (SIMPLEX), No. FA8750-17-2-0095 (D3M), No. FA8750-122-0335 (XDATA), and No. FA8750-13-2-0039 (DEFT), DOE under No. 108845, NIH under No. U54EB020405 (Mobilize), ONR under No. N000141712266 and No. N000141310129, AFOSR under No. 580K753, the Intel/NSF CPS Security grant No. 1505728, the Michael J. Fox Foundation for Parkinsons Research under Grant No. 14672, the Secure Internet of Things Project, Qualcomm, Ericsson, Analog Devices, the Moore Foundation, the Okawa Research Grant, American Family Insurance, Accenture, Toshiba, the National Science Foundation Graduate Research Fellowship under Grant No.",Acknowledgments,[0],[0]
"DGE-114747, the Stanford Finch Family Fellowship, the Joseph W. and Hon Mai Goodman Stanford Graduate Fellowship, an NSF CAREER Award IIS-1552635, and the members of the Stanford DAWN project: Facebook, Google, Intel, Microsoft, NEC, Teradata, and VMware.
",Acknowledgments,[0],[0]
"We thank Alex Ratner and the developers of Snorkel for their assistance with data programming, as well as the many members of the Hazy Research group and Stanford NLP group who provided feedback and tested early prototyptes.",Acknowledgments,[0],[0]
"Thanks as well to the OccamzRazor team: Tarik Koc, Benjamin Angulo, Katharina S. Volz, and Charlotte Brzozowski.
",Acknowledgments,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon.,Acknowledgments,[0],[0]
"Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views, policies, or endorsements, either expressed or implied, of DARPA, DOE, NIH, ONR, AFOSR, NSF, or the U.S. Government.",Acknowledgments,[0],[0]
"Below are the predicates in the rule-based semantic parser grammar, each of which may have many supported paraphrases, only one of which is listed here in a minimal example.",A Predicate Examples,[0],[0]
and: X is true and Y is true or: X is true or Y is true not: X is not true any: Any of X or Y or Z is true all: All of X and Y and Z are true none:,Logic,[0],[0]
None of X or Y or Z is true,Logic,[0],[0]
=: X is equal to Y 6=: X is not Y <: X is smaller than Y ≤: X is no more than Y >: X is larger than Y ≥: X is at least Y,Comparison,[0],[0]
"lower: X is lowercase upper: X is upper case capital: X is capitalized all caps: X is in all caps starts with: X starts with ""cardio"" ends with: X ends with ""itis"" substring: X contains ""-induced""",Syntax,[0],[0]
person:,Named-entity Tags,[0],[0]
A person is between X and Y location: A place is within two words of X date: A date is between X and Y number: There are three numbers in the sentence organization: An organization is right after X,Named-entity Tags,[0],[0]
"list: (X, Y) is in Z set: X, Y, and Z are true count:",Lists,[0],[0]
There is one word between X and Y contains: X is in Y intersection: At least two of X are in Y map: X is at the start of a word in Y filter: There are three capitalized words to the left of X alias: A spouse word is in the sentence (“spouse” is a predefined list from the user),Lists,[0],[0]
word distance: X is two words before Y char distance: X is twenty characters after Y left: X is before Y right: X is after Y between: X is between Y and Z within: X is within five words of Y,Position,[0],[0]
The following are a sample of the explanations provided by users for each task.,B Sample Explanations,[0],[0]
"Users referred to the first person in the sentence as “X” and the second as “Y”.
",Spouse,[0],[0]
"Label true because ""and"" occurs between X and Y and ""marriage"" occurs one word after person1.
",Spouse,[0],[0]
"Label true because person Y is preceded by ‘beau’.
",Spouse,[0],[0]
"Label false because the words ""married"", ""spouse"", ""husband"", and ""wife"" do not occur in the sentence.
",Spouse,[0],[0]
"Label false because there are more than 2 people in the sentence and ""actor"" or ""actress"" is left of person1 or person2.",Spouse,[0],[0]
"Label true because the disease is immediately after the chemical and ’induc’ or ’assoc’ is in the chemical name.
",Disease,[0],[0]
"Label true because a word containing ’develop’ appears somewhere before the chemical, and the word ’following’ is between the disease and the chemical.
",Disease,[0],[0]
"Label true because ""induced by"", ""caused by"", or ""due to"" appears between the chemical and the disease.",Disease,[0],[0]
"""
Label false because ""none"", ""not"", or ""no"" is within 30 characters to the left of the disease.",Disease,[0],[0]
"Label true because ""Ser"" or ""Tyr"" are within 10 characters of the protein.
",Protein,[0],[0]
"Label true because the words ""by"" or ""with"" are between the protein and kinase and the words ""no"", ""not"" or ""none"" are not in between the protein and kinase and the total number of words between them is smaller than 10.
",Protein,[0],[0]
"Label false because the sentence contains ""mRNA"", ""DNA"", or ""RNA"".
",Protein,[0],[0]
"Label false because there are two "","" between the protein and the kinase with less than 30 characters between them.",Protein,[0],[0]
"Training accurate classifiers requires many labels, but each label provides only limited information (one bit for binary classification).",abstractText,[0],[0]
"In this work, we propose BabbleLabble, a framework for training classifiers in which an annotator provides a natural language explanation for each labeling decision.",abstractText,[0],[0]
"A semantic parser converts these explanations into programmatic labeling functions that generate noisy labels for an arbitrary amount of unlabeled data, which is used to train a classifier.",abstractText,[0],[0]
"On three relation extraction tasks, we find that users are able to train classifiers with comparable F1 scores from 5–100 faster by providing explanations instead of just labels.",abstractText,[0],[0]
"Furthermore, given the inherent imperfection of labeling functions, we find that a simple rule-based semantic parser suffices.",abstractText,[0],[0]
Training Classifiers with Natural Language Explanations,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2775–2779 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2775",text,[0],[0]
"End-to-end dialogue systems, based on neural architectures like bidirectional LSTMs or Memory Networks (Sukhbaatar et al., 2015) trained directly by gradient descent on dialogue logs, have been showing promising performance in multiple contexts (Wen et al., 2016; Serban et al., 2016; Bordes et al., 2016).",1 Introduction,[0],[0]
One of their main advantages is that they can rely on large data sources of existing dialogues to learn to cover various domains without requiring any expert knowledge.,1 Introduction,[0],[0]
"However, the flip side is that they also exhibit limited engagement, especially in chit-chat settings: they lack consistency and do not leverage proactive engagement strategies as (even partially) scripted chatbots do.
Zhang et al. (2018) introduced the PERSONACHAT dataset as a solution to cope with this issue.",1 Introduction,[0],[0]
"This dataset consists of dialogues between pairs of agents with text profiles, or personas, attached to
each of them.",1 Introduction,[0],[0]
"As shown in their paper, conditioning an end-to-end system on a given persona improves the engagement of a dialogue agent.",1 Introduction,[0],[0]
"This paves the way to potentially end-to-end personalized chatbots because the personas of the bots, by being short texts, could be easily edited by most users.",1 Introduction,[0],[0]
"However, the PERSONA-CHAT dataset was created using an artificial data collection mechanism based on Mechanical Turk.",1 Introduction,[0],[0]
"As a result, neither dialogs nor personas can be fully representative of real user-bot interactions and the dataset coverage remains limited, containing a bit more than 1k different personas.
",1 Introduction,[0],[0]
"In this paper, we build a very large-scale persona-based dialogue dataset using conversations previously extracted from REDDIT1.",1 Introduction,[0],[0]
"With simple heuristics, we create a corpus of over 5 million personas spanning more than 700 million conversations.",1 Introduction,[0],[0]
We train persona-based end-to-end dialogue models on this dataset.,1 Introduction,[0],[0]
"These models outperform their counterparts that do not have access to personas, confirming results of Zhang et al. (2018).",1 Introduction,[0],[0]
"In addition, the coverage of our dataset seems very good since pre-training on it also leads to state-of-the-art results on the PERSONA-CHAT dataset.",1 Introduction,[0],[0]
"With the rise of end-to-end dialogue systems, personalized trained systems have started to appear.",2 Related work,[0],[0]
Li et al. (2016) proposed to learn latent variables representing each speaker’s bias/personality in a dialogue model.,2 Related work,[0],[0]
"Other classic strategies include extracting explicit variables from structured knowledge bases or other symbolic sources as in (Ghazvininejad et al., 2017; Joshi et al., 2017; Young et al., 2017).",2 Related work,[0],[0]
"Still, in the context of per-
1https://www.reddit.com/r/datasets/ comments/3bxlg7/
sonal chatbots, it might be more desirable to condition on data that can be generated and interpreted by the user itself such as text rather than relying on some knowledge base facts that might not exist for everyone or a great variety of situations.",2 Related work,[0],[0]
"PERSONA-CHAT (Zhang et al., 2018) recently introduced a dataset of conversations revolving around human habits and preferences.",2 Related work,[0],[0]
"In their experiments, they showed that conditioning on a text description of each speaker’s habits, their persona, improved dialogue modeling.
",2 Related work,[0],[0]
"In this paper, we use a pre-existing REDDIT data dump as data source.",2 Related work,[0],[0]
REDDIT is a massive online message board.,2 Related work,[0],[0]
Dodge et al. (2015) used it to assess chit-chat qualities of generic dialogue models.,2 Related work,[0],[0]
Yang et al. (2018) used response prediction on REDDIT as an auxiliary task in order to improve prediction performance on natural language inference problems.,2 Related work,[0],[0]
Our goal is to learn to predict responses based on a persona for a large variety of personas.,3 Building a dataset of millions of persona-based dialogues,[0],[0]
"To that end, we build a dataset of examples of the following form using data from REDDIT:
• Persona:",3 Building a dataset of millions of persona-based dialogues,[0],[0]
"[“I like sport”, “I work a lot”] • Context: “I love running.”",3 Building a dataset of millions of persona-based dialogues,[0],[0]
• Response: “Me too!,3 Building a dataset of millions of persona-based dialogues,[0],[0]
"But only on weekends.”
",3 Building a dataset of millions of persona-based dialogues,[0],[0]
"The persona is a set of sentences representing the personality of the responding agent, the context is the utterance that it responds to, and the response is the answer to be predicted.",3 Building a dataset of millions of persona-based dialogues,[0],[0]
"As in (Dodge et al., 2015), we use a preexisting dump of REDDIT that consists of 1.7 billion comments.",3.1 Preprocessing,[0],[0]
We tokenize sentences by padding all special characters with a space and splitting on whitespace characters.,3.1 Preprocessing,[0],[0]
We create a dictionary containing the 250k most frequent tokens.,3.1 Preprocessing,[0],[0]
We truncate comments that are longer than 100 tokens.,3.1 Preprocessing,[0],[0]
"We construct the persona of a user by gathering all the comments they wrote, splitting them into sentences, and selecting the sentences that satisfy the following rules: (i) each sentence must contain between 4 and 20 words or punctuation marks, (ii) it contains either the word I or my, (iii) at least
one verb, and (iv) at least one noun, pronoun or adjective.
",3.2 Persona extraction,[0],[0]
"To handle the quantity of data involved, we limit the size of a persona to N sentences for each user.",3.2 Persona extraction,[0],[0]
We compare four different setups for persona creation.,3.2 Persona extraction,[0],[0]
"In the rules setup, we select up to N random sentences that satisfy the rules above.",3.2 Persona extraction,[0],[0]
"In the rules + classifier setup, we filter with the rules then score the resulting sentences using a bag-of-words classifier that is trained to discriminate PERSONACHAT persona sentences from random comments.",3.2 Persona extraction,[0],[0]
We manually tune a threshold on the score in order to select sentences.,3.2 Persona extraction,[0],[0]
"If there are more than N eligible persona sentences for a given user, we keep the highest-scored ones.",3.2 Persona extraction,[0],[0]
"In the random from user setup, we randomly select sentences uttered by the user while keeping the sentence length requirement above (we ignore the other rules).",3.2 Persona extraction,[0],[0]
The random from dataset baseline refers to random sentences from the dataset.,3.2 Persona extraction,[0],[0]
They do not necessarily come from the same user.,3.2 Persona extraction,[0],[0]
"This last setup serves as a control mechanism to verify that the gains in prediction accuracy are due to the user-specific information contained in personas.
",3.2 Persona extraction,[0],[0]
"In the example at the beginning of this section, the response is clearly consistent with the persona.",3.2 Persona extraction,[0],[0]
"There may not always be such an obvious relationship between the two: the discussion topic may not be covered by the persona, a single user may write contradictory statements, and due to errors in the extraction process, some persona sentences may not represent a general trait of the user (e.g. I am feeling happy today).",3.2 Persona extraction,[0],[0]
We take each pair of successive comments in a thread to form the context and response of an example.,3.3 Dataset creation,[0],[0]
The persona corresponding to the response is extracted using one of the methods of Section 3.2.,3.3 Dataset creation,[0],[0]
"We split the dataset randomly between training, validation and test.",3.3 Dataset creation,[0],[0]
Validation and test sets contain 50k examples each.,3.3 Dataset creation,[0],[0]
"We extract personas using training data only: test set responses cannot be contained explicitly in the persona.
",3.3 Dataset creation,[0],[0]
"In total, we select personas covering 4.6m users in the rule-based setups and 7.2m users in the random setups.",3.3 Dataset creation,[0],[0]
"This is a sizable fraction of the total 13.2m users of the dataset; depending on the persona selection setup, between 97 and 99.4 % of the training set examples are linked to a persona.",3.3 Dataset creation,[0],[0]
"We model dialogue by next utterance retrieval (Lowe et al., 2016), where a response is picked among a set of candidates and not generated.",4 End-to-end dialogue models,[0],[0]
The overall architecture is depicted in Fig. 1.,4.1 Architecture,[0],[0]
We encode the persona and the context using separate modules.,4.1 Architecture,[0],[0]
"As in Zhang et al. (2018), we combine the encoded context and persona using a 1-hop memory network with a residual connection, using the context as query and the set of persona sentences as memory.",4.1 Architecture,[0],[0]
We also encode all candidate responses and compute the dot-product between all those candidate representations and the joint representation of the context and the persona.,4.1 Architecture,[0],[0]
"The predicted response is the candidate that maximizes the dot product.
",4.1 Architecture,[0],[0]
We train by passing all the dot products through a softmax and maximizing the log-likelihood of the correct responses.,4.1 Architecture,[0],[0]
"We use mini-batches of training examples and, for each example therein, all the responses of the other examples of the same batch are used as negative responses.",4.1 Architecture,[0],[0]
Both context and response encoders share the same architecture and word embeddings but have different weights in the subsequent layers.,4.2 Context and response encoders,[0],[0]
"We train three different encoder architectures.
",4.2 Context and response encoders,[0],[0]
Bag-of-words applies two linear projections separated by a tanh non-linearity to the word embeddings.,4.2 Context and response encoders,[0],[0]
"We then sum the resulting sentence representation across all positions in the sentence and divide the result by √ n where n is the length of the sequence.
",4.2 Context and response encoders,[0],[0]
LSTM applies a 2-layer bidirectional LSTM.,4.2 Context and response encoders,[0],[0]
"We use the last hidden state as encoded sentence.
",4.2 Context and response encoders,[0],[0]
"Transformer is a variation of an End-to-end Memory Network (Sukhbaatar et al., 2015) introduced by Vaswani et al. (2017).",4.2 Context and response encoders,[0],[0]
"Based solely on attention mechanisms, it exhibited state-of-the-art performance on next utterance retrieval tasks in dialogues (Yang et al., 2018).",4.2 Context and response encoders,[0],[0]
Here we use only its encoding module.,4.2 Context and response encoders,[0],[0]
"We subsequently average the resulting representation across all positions in the sentence, yielding a fixed-size representation.",4.2 Context and response encoders,[0],[0]
The persona encoder encodes each persona sentence separately.,4.3 Persona encoder,[0],[0]
It relies on the same word embeddings as the context encoder and applies a linear layer on top of them.,4.3 Persona encoder,[0],[0]
"We then sum the representations across the sentence.
",4.3 Persona encoder,[0],[0]
We deliberately choose a simpler architecture than the other encoders for performance reasons as the number of personas encoded for each batch is an order of magnitude greater than the number of training examples.,4.3 Persona encoder,[0],[0]
Most personas are short sentences; we therefore expect a bag-of-words representation to encode them well.,4.3 Persona encoder,[0],[0]
We train models on the persona-based dialogue dataset described in Section 3.3 and we evaluate its accuracy both on the original task and when transferring onto PERSONA-CHAT.,5 Experiments,[0],[0]
We optimize network parameters using Adamax with a learning rate of 8e−4 on mini-batches of size 512.,5.1 Experimental details,[0],[0]
"We initialize embeddings with FastText word vectors and optimize them during learning.
",5.1 Experimental details,[0],[0]
"REDDIT LSTMs use a hidden size of 150; we concatenate the last hidden states for both directions and layers, resulting in a final representation of size 600.",5.1 Experimental details,[0],[0]
"Transformer architectures on reddit use 4 layers with a hidden size of 300 and 6 attention heads, resulting in a final representation of size 300.",5.1 Experimental details,[0],[0]
We use Spacy for part-of-speech tagging in order to verify the persona extraction rules.,5.1 Experimental details,[0],[0]
"We distribute the training by splitting each batch across 8 GPUs; we stop training after 1 full epoch, which takes about 3 days.
",5.1 Experimental details,[0],[0]
"PERSONA-CHAT We used the revised version of the dataset where the personas have been rephrased, making it a harder task.",5.1 Experimental details,[0],[0]
"The dataset being only a few thousands samples, we had to reduce the architecture to avoid overfitting for the models trained purely on PERSONA-CHAT.",5.1 Experimental details,[0],[0]
"2 layers, 2 attention heads, a dropout of 0.2 and keeping the size of the word embeddings to 300 units yield the highest accuracy on the validation set.
",5.1 Experimental details,[0],[0]
IR Baseline,5.1 Experimental details,[0],[0]
"As basic baseline, we use an information retrieval (IR) system that ranks candidate responses according to a TF-IDF weighted exactmatch similarity with the context alone.",5.1 Experimental details,[0],[0]
Impact of personas We report the accuracy of the different architectures on the reddit task in Table 1.,5.2 Results,[0],[0]
Conditioning on personas improves the prediction performance regardless of the encoder architecture.,5.2 Results,[0],[0]
"Table 2 gives some examples of how the persona affects the predicted answer.
",5.2 Results,[0],[0]
"Influence of the persona extraction In Table 3, we report precision results for several persona extraction setups.",5.2 Results,[0],[0]
"The rules setup improves the results somewhat, however adding the persona classifier actually degrades the results.",5.2 Results,[0],[0]
"A possible interpretation is that the persona classifier is trained only on the PERSONA-CHAT revised personas, and that this selection might be too narrow and lack di-
versity.",5.2 Results,[0],[0]
"Increasing the maximum persona size also improves the prediction performance.
",5.2 Results,[0],[0]
Transfer learning,5.2 Results,[0],[0]
We compare the performance of transformer models trained on REDDIT and on PERSONA-CHAT on both datasets.,5.2 Results,[0],[0]
We report results in Table 4.,5.2 Results,[0],[0]
"This architecture provides a strong improvement over the results of (Zhang et al., 2018), jumping from 35.4% hits@1 to 42.1%.",5.2 Results,[0],[0]
"Pretraining the model on REDDIT and then fine-tuning on PERSONA-CHAT pushes this score to 60.7%, largely improving the state of the art.",5.2 Results,[0],[0]
"As expected, fine-tuning on PERSONA-CHAT reduces the performance on REDDIT.",5.2 Results,[0],[0]
"However, directly testing on PERSONA-CHAT the model trained on REDDIT without fine-tuning yields a very low result.",5.2 Results,[0],[0]
"This could be a consequence of a discrepancy
between the style of personas of the two datasets.",5.2 Results,[0],[0]
This paper shows how to create a very large dataset for persona-based dialogue.,6 Conclusion,[0],[0]
We show that training models to align answers both with the persona of their author and the context improves the predicting performance.,6 Conclusion,[0],[0]
The trained models show promising coverage as exhibited by the stateof-the-art transfer results on the PERSONA-CHAT dataset.,6 Conclusion,[0],[0]
"As pretraining leads to a considerable improvement in performance, future work could be done fine-tuning this model for various dialog systems.",6 Conclusion,[0],[0]
Future work may also entail building more advanced strategies to select a limited number of personas for each user while maximizing the prediction performance.,6 Conclusion,[0],[0]
"Current dialogue systems are not very engaging for users, especially when trained end-toend without relying on proactive reengaging scripted strategies.",abstractText,[0],[0]
Zhang et al. (2018) showed that the engagement level of end-to-end dialogue models increases when conditioning them on text personas providing some personalized back-story to the model.,abstractText,[0],[0]
"However, the dataset used in (Zhang et al., 2018) is synthetic and of limited size as it contains around 1k different personas.",abstractText,[0],[0]
In this paper we introduce a new dataset providing 5 million personas and 700 million persona-based dialogues.,abstractText,[0],[0]
"Our experiments show that, at this scale, training using personas still improves the performance of end-to-end systems.",abstractText,[0],[0]
"In addition, we show that other tasks benefit from the wide coverage of our dataset by fine-tuning our model on the data from (Zhang et al., 2018) and achieving state-of-the-art results.",abstractText,[0],[0]
Training Millions of Personalized Dialogue Agents,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 130–135 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Structured prediction, or the task of predicting multiple inter-dependent variables, is important in many domains, including computer vision, computational biology and natural language processing.",1 Introduction,[0],[0]
"For example, in sequence labelling, image segmentation, and parsing we are given input variables x, and must predict output variables y, where the number of possible y values are typically exponential in the number of variables that comprise it.",1 Introduction,[0],[0]
"Not only does this sometimes give rise to computational difficulties, it also leads to statistical parameter estimation issues, where learning precise models requires large amounts of labeled training data.
",1 Introduction,[0],[0]
"In some cases, unsupervised learning from plentiful unlabeled data may provide helpful outputs (Daumé III, 2009; Ammar et al., 2014).",1 Introduction,[0],[0]
But usually some form of more direct supervision is required to create a model truly useful to the task at hand.,1 Introduction,[0],[0]
In the absence of abundant labeled data we may consider alternative forms of supervision.,1 Introduction,[0],[0]
"For example, rather than providing labeled data instances, humans may more easily inject their
domain knowledge by providing “labels on features,” or “expectations” about correct outputs, as in generalized expectation criteria (Mann and McCallum, 2010), or by providing constraints, as in posterior regularization (Ganchev et al., 2010) or constraint driven learning (Chang et al., 2007).",1 Introduction,[0],[0]
"A major weakness of these methods, however, is that at training time inference must be done in the factor graph encompassing the union of the model’s factor graph and the expectation dependencies— often leading to prohibitively expensive inference.",1 Introduction,[0],[0]
"Moreover, these methods cannot learn from nondecomposable domain knowledge, where the domain knowledge is not in a form of a set of labeled features or constraints.
",1 Introduction,[0],[0]
"An easy way for humans to express domain knowledge is by writing a simple scalar scoring function that indicates preferences among choices for y given x. These human-coded functions may, for example, be based on arbitrary rule systems (or even Turing-complete programs) of the sort written by humans to solve problems before machine learning became so wide-spread.
",1 Introduction,[0],[0]
"In general, the human written domain knowledge functions are not expected to be perfect— most likely only examining a subset of features and not covering all cases.",1 Introduction,[0],[0]
"Thus we are now faced with two challenges: (1) the domain knowledge functions have limited generalization; (2) the domain knowledge functions provide a ranking, but do not provide an inference (search) procedure.
",1 Introduction,[0],[0]
"This paper presents a new training method for structured prediction energy networks (SPENs) (Belanger and McCallum, 2016; Belanger et al., 2017) that aims to address both these challenges, yielding efficient inference for structured prediction, trained from human-coded domain knowledge plus unlabeled data, but not requiring any labeled data instances.",1 Introduction,[0],[0]
"In SPENs, the factor graph that typically represents
130
output variable dependencies is replaced with a deep neural network that takes y and x as input and outputs a scalar energy score, but is able to learn much richer correlations than are typically captured in factor graphs.",1 Introduction,[0],[0]
"Inference in SPENs is performed by gradient descent in the energy, back-propagated to cause steps in a relaxed y space.",1 Introduction,[0],[0]
"Whereas previous training procedures for SPENs used labeled data, here we train SPENs from only unlabeled data plus human-coded domain knowledge in the form of a scoring function.",1 Introduction,[0],[0]
"We do so by building on SampleRank (Rohanimanesh et al., 2011; Singh et al., 2010), which enforces that the rank of two sampled ys according to the trained factor graph is consistent with their rank according to distance to the labeled, true y.",1 Introduction,[0],[0]
"In our training method, pairs of y’s are obtained from successive steps of training-time gradient-descent inference on y; when their rank is not consistent with that of the domain knowledge function, we accordingly update the energy network parameters.
",1 Introduction,[0],[0]
"We demonstrate our method on a citation field extraction task, for which we learn a neural network (1) that generalizes beyond the original domain knowledge function, and (2) that provides efficient test-time inference by gradient descent.",1 Introduction,[0],[0]
"In general, SPEN parameterizes an energy function Ew(y,x) using deep neural networks over output variables y as well as input variables x, where w denotes the neural network’s parameters.",2 Structured Prediction Energy Networks,[0],[0]
Belanger and McCallum (2016) separate the energy function into global and local terms.,2 Structured Prediction Energy Networks,[0],[0]
"The role of the local terms is to capture the dependency among input x and each individual output variable yi, while the global term aims to capture long-range dependencies among output variables.
",2 Structured Prediction Energy Networks,[0],[0]
Prediction in SPENs requires finding ŷ,2 Structured Prediction Energy Networks,[0],[0]
=,2 Structured Prediction Energy Networks,[0],[0]
argminy∈Y,2 Structured Prediction Energy Networks,[0],[0]
"Ew(y,x)",2 Structured Prediction Energy Networks,[0],[0]
for the given input x.,2 Structured Prediction Energy Networks,[0],[0]
This inference problem is solved using gradient descent.,2 Structured Prediction Energy Networks,[0],[0]
"However, the energy surface is non-convex, which prevents gradient descent inference from finding the exact structure ymin that globally minimizes the energy function.",2 Structured Prediction Energy Networks,[0],[0]
One approach to address this problem is to parameterize the energy function such that the SPEN is convex in the output variables y,2 Structured Prediction Energy Networks,[0],[0]
"(Amos et al., 2017), but this limits the representational power of SPENs.",2 Structured Prediction Energy Networks,[0],[0]
"Al-
though gradient descent inference does not guarantee an exact solution, it has successfully been used in several domains such as multi-label classification (Belanger and McCallum, 2016), imagesegmentation (Gygli et al., 2017), and semantic role labeling (Belanger et al., 2017).",2 Structured Prediction Energy Networks,[0],[0]
"Different methods have been introduced for training SPENs: margin-based training (Belanger and McCallum, 2016), end-to-end learning (Belanger et al., 2017), and value matching (Gygli et al., 2017).",3 Rank-Based Training of SPENs,[0],[0]
"Margin-based training enforces the energy of the ground truth structure to be lower than the energy of every incorrect structure by a margin, which is calculated as the Hamming loss between the two structures.",3 Rank-Based Training of SPENs,[0],[0]
End-to-end learning unrolls the energy minimization into a differentiable computation graph to output the predicted structure.,3 Rank-Based Training of SPENs,[0],[0]
It then trains the model by directly minimizing the loss between the predicted and ground-truth structures.,3 Rank-Based Training of SPENs,[0],[0]
"Finally, the value matching approach trains SPENs such that the energy value matches the value of a given target function, such as the L2 distance between the ground-truth and predicted structures.
",3 Rank-Based Training of SPENs,[0],[0]
All of these methods strongly depend on the existence of the ground truth values either as labeled data or as the value of a function applied to it.,3 Rank-Based Training of SPENs,[0],[0]
"While dependence of the margin-based and endto-end learning approaches on the labeled data is explicit, this dependency in the case of valuematching may not be obvious.",3 Rank-Based Training of SPENs,[0],[0]
"In the absence of labeled data, we have to use the model’s predictions instead, for training.",3 Rank-Based Training of SPENs,[0],[0]
"These predictions are often incorrect, especially at early stages of training.",3 Rank-Based Training of SPENs,[0],[0]
"As a result, value-matching training is constrained to match the score of these predictions with the value of the energy function defined by SPEN.",3 Rank-Based Training of SPENs,[0],[0]
"This requires matching several incorrect structures for a given input, which hinders gradient descent inference from finding the exact solution by introducing many local optima.",3 Rank-Based Training of SPENs,[0],[0]
"To address this problem, we use a ranking objective similar to SampleRank",3 Rank-Based Training of SPENs,[0],[0]
"(Rohanimanesh et al., 2011) such that it preserves the optimum points of the score function.
",3 Rank-Based Training of SPENs,[0],[0]
"In general, if SPEN ranks every pair of output structures identical to the score function, the optimum points of the score function match those of SPEN.",3 Rank-Based Training of SPENs,[0],[0]
"However, forcing the ranking constraint for every pair of output structures is not tractable, so
we need to approximate it by sampling some candidate pairs.",3 Rank-Based Training of SPENs,[0],[0]
"Given a score function V (y,x), we are able to rank every two consecutive candidate structures based on their score values.",3 Rank-Based Training of SPENs,[0],[0]
Consider two candidate output structures y1 and y2 for the given input x.,3 Rank-Based Training of SPENs,[0],[0]
"We define yh and yl based on the score function as the following:
yh = argmax y∈{y1,y2} V (y,x),
yl = argmin y∈{y1,y2} V (y,x).",3 Rank-Based Training of SPENs,[0],[0]
"(1)
We expect that these two structures have the same ranking with respect to Ew(.,x), which can be described as: α(V (yh,x)",3 Rank-Based Training of SPENs,[0],[0]
"− V (yl,x))",3 Rank-Based Training of SPENs,[0],[0]
"< Ew(yh,x)−Ew(yl,x), where α is a tunable positive scalar.",3 Rank-Based Training of SPENs,[0],[0]
"Therefore, the rank-based objective minimizes the constraint violations:
min w
∑ x∈D [α(V (yh,x)− V (yl,x))−
Ew(yh,x) +",3 Rank-Based Training of SPENs,[0],[0]
"Ew(yl,x)]+ (2)
",3 Rank-Based Training of SPENs,[0],[0]
"[.]+ is max(., 0).",3 Rank-Based Training of SPENs,[0],[0]
Figure 1 shows a ranking violation for two structures y1 and y2 for a given x. The arrows indicate the direction of update over the energy surface.,3 Rank-Based Training of SPENs,[0],[0]
"Note that we ignore the dependence of y on w, which introduces approximation in the gradient of Eq. 2.",3 Rank-Based Training of SPENs,[0],[0]
"For the supervised setting, Belanger et al. (2017) address this problem by unrolling the inference steps as an inference network and back-propagating through the inference network.",3 Rank-Based Training of SPENs,[0],[0]
We leave exploring similar approaches for rank-based training for future work.,3 Rank-Based Training of SPENs,[0],[0]
"To compute Eq. 2, we need to find configurations yi and yj such that both are candidate solutions for argminy∈Y Ew(y,x).",3 Rank-Based Training of SPENs,[0],[0]
"If not, the number of required samples would be exponential in |Y|.",3 Rank-Based Training of SPENs,[0],[0]
"Since at test time we use gradient descent inference, a similar method is used for generating candidate structures: the trajectory of points in the inference mechanism is used as the set of possible candidates.",3 Rank-Based Training of SPENs,[0],[0]
The idea of deterministic sampling from SPEN energy surface was first introduced by David Belanger (2017).,3 Rank-Based Training of SPENs,[0],[0]
"We define the inference trajectory, T (x), as a sequence of output structures generated using projected gradient descent inference in order to find the minimum solution of Ew(.,x).
",3 Rank-Based Training of SPENs,[0],[0]
"Given a random initial structure y0, we define the inference trajectory as: T (x) =
{y1, · · · ,ym}, where yt+1 = Py∈∆L(yt − η ∂∂yEw(yt,x)).",3 Rank-Based Training of SPENs,[0],[0]
Py∈∆L projects the values of y onto the probability simplex ∆L overL values that each variable y can take.,3 Rank-Based Training of SPENs,[0],[0]
"For each input x in the training data, we find the first consecutive structures yi, yi+1 ∈ T (x) that violate the ranking constraint, then use Eq. 2 to reduce the number of violations.",3 Rank-Based Training of SPENs,[0],[0]
"Algorithm 1 describes the complete training algorithm.
",3 Rank-Based Training of SPENs,[0],[0]
"Algorithm 1 Rank-based training of SPEN D ← unlabeled mini-batch of training data V (., .)← scoring function Ew(., .)← input SPEN for each x in D do T (x)← samples using GD inference in Ew(.,x).",3 Rank-Based Training of SPENs,[0],[0]
"ξ ← ∅. for each pair (yi,yi+1) in T (x) do
Construct yh and yl using Eq.1 if α(V (yh,x)",3 Rank-Based Training of SPENs,[0],[0]
"− V (yl,x))",3 Rank-Based Training of SPENs,[0],[0]
"> Ew(yh,x)",3 Rank-Based Training of SPENs,[0],[0]
"−
Ew(yl,x) then ξ ← ξ ∪ (x,yh,yl).
end if end for Optimize Eq.2 using ξ.
end for",3 Rank-Based Training of SPENs,[0],[0]
"To show the success of rank-based learning with indirect supervision, we conduct experiments on citation field extraction as an instance of structured prediction problems.",4 Citation Field Extraction,[0],[0]
"The goal of citation field extraction is to segment citation text into its constituent parts such as Author, Title, Journal, Page, and Date.",4 Citation Field Extraction,[0],[0]
"We used the Cora citation dataset (Seymore et al., 1999), which includes 100 labeled examples as the test set and another 100 labeled examples for the validation set.",4 Citation Field Extraction,[0],[0]
"Our training data consists of 300 training examples from the Cora citation data set for which we dismiss the labels,
as well as another 700 unlabeled citations acquired across the web, which adds up to 1000 unlabeled data points.",4 Citation Field Extraction,[0],[0]
Each token can be labeled with one of 13 possible tags.,4 Citation Field Extraction,[0],[0]
"We use fixed-length input data by padding all citation text to the maximum citation length in the dataset, which is 118 tokens.",4 Citation Field Extraction,[0],[0]
"We report token-level accuracy measured on non-pad tokens.
",4 Citation Field Extraction,[0],[0]
We provide the learning algorithm with a human written score function that takes the citation text and predicted tags as input.,4 Citation Field Extraction,[0],[0]
The score function then checks for violations of its rules and penalizes the predicted tags accordingly.,4 Citation Field Extraction,[0],[0]
Figure 2 shows examples of rules in the score function.,4 Citation Field Extraction,[0],[0]
"Our complete score function consists of around 50 rules.
",4 Citation Field Extraction,[0],[0]
We used two 2-layer neural networks with 1000 and 500 hidden nodes to parameterize the local and global energy functions of SPEN.,4 Citation Field Extraction,[0],[0]
"We examine different α (Eq. 2) values of 0.1, 1.0, 2.0, 5.0, and 10.0, and setting α value to 2.0 has the best performance on the validation set.",4 Citation Field Extraction,[0],[0]
"We use gradient descent inference with ten gradient descent steps and η = 0.1 for both training and test.
",4 Citation Field Extraction,[0],[0]
We include the results of generalized expectation (GE) from Mann and McCallum (2010) that use the same dataset and setting.,4 Citation Field Extraction,[0],[0]
"Our results show that R-SPEN achieves significantly better tokenlevel accuracy as compared to GE.
",4 Citation Field Extraction,[0],[0]
We also compare R-SPEN with different inference algorithms that search using the score function to find the best configuration with maximum score.,4 Citation Field Extraction,[0],[0]
The results of these are listed in Table 1.,4 Citation Field Extraction,[0],[0]
Greedy search first randomly initializes the output tags and then iteratively replaces each assigned tag with a tag that results in the maximum score until the end of the citation is reached.,4 Citation Field Extraction,[0],[0]
"This process is repeated until convergence, measured by no tag changing in an iteration.",4 Citation Field Extraction,[0],[0]
"To avoid the effects of random initialization, this is repeated with varied number of random restarts, as reported in Table 1, where the best configuration is used in the scores reported.",4 Citation Field Extraction,[0],[0]
"For the baseline that implements beam search, each citation is labeled by employing a beam search on the space of all tags for each token and their subsequent configurations, while keeping track of the best k configurations from one token to the next.",4 Citation Field Extraction,[0],[0]
"This search is further augmented by restarting the search from the best k found after one complete search, for a total of 10 times and 10 random restarts.
",4 Citation Field Extraction,[0],[0]
"Consulting Table 1, we can confirm that both greedy search and beam search find much better output structures in term of score values as compared to R-SPEN; however, they achieve poor accuracy because the domain knowledge function does not comprehensively provide rules regarding all possible output structures.",4 Citation Field Extraction,[0],[0]
We report the average score values of the R-SPEN predictions on test data as a function of training iterations in Figure 3.,4 Citation Field Extraction,[0],[0]
"Within 1000 iterations, R-SPEN is able to achieve a test set accuracy of 38%, outperforming all baselines, while the average score is -18.0.",4 Citation Field Extraction,[0],[0]
"R-SPEN generalizes beyond the domain knowledge function because it successfully captures the correlation among output variables through rank-based training on unlabeled data, so its predictions may have lower score values but are more accurate.
",4 Citation Field Extraction,[0],[0]
The test time inference of R-SPEN is much faster than search algorithms because SPEN provides efficient approximate inference.,4 Citation Field Extraction,[0],[0]
"Generalized Expectation (GE) (Mann and McCallum, 2010), Posterior Regularization (Ganchev et al., 2010) and Constraint Driven Learning (Chang et al., 2007) are among well-known approaches to learn from domain knowledge decomposed over a set of constraints or labeled features.",5 Related Work,[0],[0]
"However, these methods cannot learn from black box domain knowledge based score functions.",5 Related Work,[0],[0]
"Score functions of this type are abundant in
various fields, for example, when the score is the result of evaluating a non-differentiable function over output structures.
",5 Related Work,[0],[0]
Stewart and Ermon (2017) train a neural network using a score function that guides the training based on physics of moving objects.,5 Related Work,[0],[0]
They have defined a differentiable score function which provides the learning algorithm with the gradient of the score function.,5 Related Work,[0],[0]
"However, in our approach the score function could be any complex non-differentiable function.
",5 Related Work,[0],[0]
Peng et al. (2017) and Iyyer et al. (2017) use energy-based max-margin training for learning from an implicit source of supervision.,5 Related Work,[0],[0]
This can be viewed as a score function evaluating the predicted output structure based on some real-world domain.,5 Related Work,[0],[0]
"For example, if the output structure is the SQL query associated with a natural language question, the score function can be specified as the Jaccard similarity of the extracted cells from the table using the generated SQL query and the set of
gold answers for the natural language query as in Iyyer et al (2017).",5 Related Work,[0],[0]
We have introduced a method to train structured prediction energy networks with indirect supervision that is derived from domain knowledge.,6 Conclusion and Future Work,[0],[0]
"This domain knowledge is a scalar function that is represented in the form of certain set of rules, easily provided by humans.",6 Conclusion and Future Work,[0],[0]
"By using a rank-based training we are able to effectively generalize beyond the domain knowledge function in problem instances where we do not have access to labeled data, thus establishing a viable option for solving structured prediction problems in those regimes.
",6 Conclusion and Future Work,[0],[0]
R-SPEN only uses unlabeled data and domain knowledge for training.,6 Conclusion and Future Work,[0],[0]
We should also effectively benefit from annotated data if any is available for the task.,6 Conclusion and Future Work,[0],[0]
"This can be accomplished by augmenting the domain knowledge with rules that take into account the distance between predicted and ground truth labels.
",6 Conclusion and Future Work,[0],[0]
"In the future, we wish to explore the effectiveness of R-SPEN on various tasks using domain knowledge functions with varying degrees of complexity.",6 Conclusion and Future Work,[0],[0]
This research was funded by DARPA grant FA8750-17-C-0106.,Acknowledgments,[0],[0]
"The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of DARPA or the U.S. Government.",Acknowledgments,[0],[0]
This paper introduces rank-based training of structured prediction energy networks (SPENs).,abstractText,[0],[0]
Our method samples from output structures using gradient descent and minimizes the ranking violation of the sampled structures with respect to a scalar scoring function defined using domain knowledge.,abstractText,[0],[0]
"We have successfully trained SPEN for citation field extraction without any labeled data instances, where the only source of supervision is a simple human-written scoring function.",abstractText,[0],[0]
Such scoring functions are often easy to provide; the SPEN then furnishes an efficient structured prediction inference procedure.,abstractText,[0],[0]
Training Structured Prediction Energy Networks with Indirect Supervision,title,[0],[0]
"Inspired by human beings’ capabilities to transfer knowledge across tasks, transfer learning aims to leverage knowledge from a source domain to improve the learning performance or minimize the number of labeled examples required in a target domain.",1. Introduction,[0],[0]
It is of particular significance when tackling tasks with limited labeled examples.,1. Introduction,[0],[0]
"Transfer learning has proved its wide applicability in, for example,
1Hong Kong University of Science and Technology, Hong Kong 2Tencent AI Lab, Shenzhen, China.",1. Introduction,[0],[0]
"Correspondence to: Ying Wei <judyweiying@gmail.com>, Qiang Yang <qyang@cse.ust.hk>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
image classification (Long et al., 2015), sentiment classification (Blitzer et al., 2006), dialog systems (Mo et al., 2016), and urban computing (Wei et al., 2016).
",1. Introduction,[0],[0]
"Three key research issues in transfer learning, pointed by Pan & Yang, are when to transfer, how to transfer, and what to transfer.",1. Introduction,[0],[0]
"Once transfer learning from a source domain is considered to benefit a target domain (when to transfer), an algorithm (how to transfer) discovers the transferable knowledge across domains (what to transfer).",1. Introduction,[0],[0]
"Different algorithms are likely to discover different transferable knowledge, and thereby lead to uneven transfer learning effectiveness which is evaluated by the performance improvement over non-transfer baselines in a target domain.",1. Introduction,[0],[0]
"To achieve the optimal performance improvement for a target domain given a source domain, researchers may try tens to hundreds of transfer learning algorithms covering instance (Dai et al., 2007), parameter (Tommasi et al., 2014), and feature (Pan et al., 2011) based algorithms.",1. Introduction,[0],[0]
Such bruteforce exploration is computationally expensive and practically impossible.,1. Introduction,[0],[0]
"As a tradeoff, a sub-optimal improvement is usually obtained from a heuristically selected algorithm, which unfortunately requires considerable expertise in an ad-hoc and unsystematic manner.
",1. Introduction,[0],[0]
Exploring different algorithms is not the only way to optimize what to transfer.,1. Introduction,[0],[0]
"Previous transfer learning experiences do also help, which has been widely accepted in educational psychology (Luria, 1976; Belmont et al., 1982).",1. Introduction,[0],[0]
Human beings sharpen transfer learning skills of deciding what to transfer by conducting meta-cognitive reflection on diverse transfer learning experiences.,1. Introduction,[0],[0]
"For example, children who are good at playing chess may transfer mathematical skills, visuospatial skills, and decision making skills learned from chess to solve arithmetic problems, to solve pattern matching puzzles, and to play basketball, respectively.",1. Introduction,[0],[0]
"At a later age, it will be easier for them to decide to transfer mathematical and decision making skills learned from chess, rather than visuospatial skills, to market investment.",1. Introduction,[0],[0]
"Unfortunately, all existing transfer learning algorithms transfer from scratch and ignore previous transfer learning experiences.
",1. Introduction,[0],[0]
"Motivated by this, we propose a novel transfer learning framework called Learning to Transfer (L2T).",1. Introduction,[0],[0]
"The key idea of the L2T is to enhance the transfer learning effectiveness from a source to a target domain by leveraging previous
transfer learning experiences to optimize what and how to transfer between them.",1. Introduction,[0],[0]
"To achieve the goal, we establish the L2T in two stages.",1. Introduction,[0],[0]
"During the first stage, we encode each transfer learning experience into three components: a pair of source and target domains, the transferred knowledge between them parameterized as latent feature factors, and performance improvement.",1. Introduction,[0],[0]
We learn from all experiences a reflection function which maps a pair of domains and the transferred knowledge between them to the performance improvement.,1. Introduction,[0],[0]
"The reflection function, therefore, is believed to encrypt transfer learning skills of deciding what and how to transfer.",1. Introduction,[0],[0]
"In the second stage, what to transfer between a newly arrived pair of domains is optimized so that the value of the learned reflection function, matching to the performance improvement, is maximized.
",1. Introduction,[0],[0]
The contribution of this paper lies in that we propose a novel transfer learning framework which opens a new door to improve transfer learning effectiveness by taking advantage of previous transfer learning experiences.,1. Introduction,[0],[0]
The L2T can discover more transferable knowledge in a systematic and automatic fashion without requiring considerable expertise.,1. Introduction,[0],[0]
"We have also provided theoretic analyses to its algorithmic stability and generalization bound, and conducted comprehensive empirical studies showing the L2T’s superiority over state-of-the-art transfer learning algorithms.",1. Introduction,[0],[0]
"Transfer Learning Pan & Yang identified three key research issues in transfer learning as what, how, and when to transfer.",2. Related Work,[0],[0]
"Parameters (Yang et al., 2007a; Tommasi et al., 2014), instances (Dai et al., 2007), or latent feature factors (Pan et al., 2011) can be transferred between domains.",2. Related Work,[0],[0]
"A few works (Yang et al., 2007a; Tommasi et al., 2014) transfer parameters from source domains to regularize parameters of SVM-based models in a target domain.",2. Related Work,[0],[0]
"In (Dai et al., 2007), a basic learner in a target domain is boosted by borrowing the most useful source instances.",2. Related Work,[0],[0]
Various techniques capable of learning transferable latent feature factors between domains have been investigated extensively.,2. Related Work,[0],[0]
"These techniques include manually selected pivot features (Blitzer et al., 2006), dimension reduction (Pan et al., 2011; Baktashmotlagh et al., 2013; 2014), collective matrix factorization (Long et al., 2014), dictionary learning and sparse coding (Raina et al., 2007; Zhang et al., 2016), manifold learning (Gopalan et al., 2011; Gong et al., 2012), and deep learning (Yosinski et al., 2014; Long et al., 2015; Tzeng et al., 2015).",2. Related Work,[0],[0]
"Unlike L2T, all existing transfer learning studies transfer from scratch, i.e., only considering the pair of domains of interest but ignoring previous transfer learning experiences.",2. Related Work,[0],[0]
"Better yet, L2T can even collect all algorithms’ wisdom together, considering that any algorithm mentioned above can be applied in a transfer learning experience.
",2. Related Work,[0],[0]
"Multi-task Learning Multi-task learning (Caruana, 1997; Argyriou et al., 2007) trains multiple related tasks simultaneously and learns shared knowledge among tasks, so that all tasks reinforce each other in generalization abilities.",2. Related Work,[0],[0]
"However, multi-task learning assumes that training and testing examples follow the same distribution, as Figure 1 shows, which is different from transfer learning we focus on.
",2. Related Work,[0],[0]
Lifelong Learning,2. Related Work,[0],[0]
"Assuming a new learning task to lie in the same environment as training tasks, learning to learn (Thrun & Pratt, 1998) or meta-learning (Maurer, 2005; Finn et al., 2017; Al-Shedivat et al., 2018) transfers the knowledge shared among training tasks to the new task.",2. Related Work,[0],[0]
"(Ruvolo & Eaton, 2013; Pentina & Lampert, 2015) consider lifelong learning as online meta-learning.",2. Related Work,[0],[0]
"Though L2T and lifelong (meta) learning both aim to improve a learning system by leveraging histories, L2T differs from them in that each historical experience we consider is a transfer learning task rather than a traditional learning task as Figure 1 illustrates.",2. Related Work,[0],[0]
Thus we learn transfer learning skills instead of task-sharing knowledge.,2. Related Work,[0],[0]
We begin by first briefing the proposed L2T framework.,3. Learning to Transfer,[0],[0]
"Then we detail the two stages in L2T, i.e., learning transfer learning skills from previous transfer learning experiences and applying those skills to infer what and how to transfer for a future pair of source and target domains.",3. Learning to Transfer,[0],[0]
"A L2T agent previously conducted transfer learning several times, and kept a record of Ne transfer learning experiences.",3.1. The L2T Framework,[0],[0]
"We define each transfer learning experience as Ee = (〈Se, Te〉, ae, le) in which Se = {Xse,yse} and Te = {Xte,yte} denote a source domain and a target domain, respectively.",3.1. The L2T Framework,[0],[0]
X∗e ∈,3.1. The L2T Framework,[0],[0]
"Rn ∗ e×m represents the feature matrix if either domain has n∗e examples in a m-dimensional feature space X ∗e , where the superscript ∗ can be either s or t to denote a source or a target domain.",3.1. The L2T Framework,[0],[0]
y∗e ∈ Y∗e denotes the vector of labels with the length being n∗le.,3.1. The L2T Framework,[0],[0]
"The number of target labeled examples is much smaller than that of source labeled examples, i.e., ntle nsle.",3.1. The L2T Framework,[0],[0]
"We focus on the
learned reflection function f ( 1 ), we optimize the transferred knowledge between them, i.e., W∗Ne+1, by maximizing the value of f ( 2 ).
setting X se = X te and Yse = Yte for each pair of domains.",3.1. The L2T Framework,[0],[0]
ae ∈,3.1. The L2T Framework,[0],[0]
"A = {a1, · · · , aNa} denotes a transfer learning algorithm having been applied between Se and Te.",3.1. The L2T Framework,[0],[0]
Suppose that the transferred knowledge by the algorithm ae can be parameterized as We.,3.1. The L2T Framework,[0],[0]
"Finally, each transfer learning experience is labeled by the performance improvement ratio le = pste /p",3.1. The L2T Framework,[0],[0]
"t e, where pte is the learning performance (e.g., classification accuracy) on a test dataset in Te without transfer and pste is that on the same test dataset after transferring We from Se.",3.1. The L2T Framework,[0],[0]
"With Ne transfer learning experiences {E1, · · · , ENe} as the input, the L2T agent learns a function f such that f(Se, Te,We) approximates le as shown in the training stage of Figure 2.",3.1. The L2T Framework,[0],[0]
We call f a reflection function which encrypts meta-cognitive transfer learning skills - what and how to transfer can maximize the improvement ratio given a pair of domains.,3.1. The L2T Framework,[0],[0]
"Whenever a new pair of domains 〈SNe+1, TNe+1〉 arrives, the L2T agent can optimize the knowledge to be transferred, i.e., W∗Ne+1, by maximizing the value of f (see step 2 of the testing stage in Figure 2).",3.1. The L2T Framework,[0],[0]
Transfer learning algorithms applied can vary from experience to experience.,3.2. Parameterizing What to Transfer,[0],[0]
Uniformly parameterizing “what to transfer” for any algorithm out of the base algorithm set A is a prerequisite for learning the reflection function.,3.2. Parameterizing What to Transfer,[0],[0]
"In this work, we consider A to contain algorithms transferring single-level latent feature factors, because existing parameter-based and instance-based algorithms cannot address the transfer learning setting we focus on (i.e., X es = X et and Yes = Yet ).",3.2. Parameterizing What to Transfer,[0],[0]
"Though limited parameter-based algorithms (Yang et al., 2007a; Tommasi et al., 2014) can transfer across domains in heterogeneous label spaces, they can only handle binary classification problems.",3.2. Parameterizing What to Transfer,[0],[0]
"Deep neural network based algorithms (Yosinski et al., 2014; Long et al., 2015; Tzeng et al., 2015) transferring latent feature factors in multiple levels are left for our future research.",3.2. Parameterizing What to Transfer,[0],[0]
"As a result, we parameterize what to transfer with a latent feature factor matrix W which is elaborated in the following.
",3.2. Parameterizing What to Transfer,[0],[0]
Latent feature factor based algorithms aim to learn domaininvariant feature factors across domains.,3.2. Parameterizing What to Transfer,[0],[0]
Consider classifying dog pictures as a source domain and cat pictures as a target domain.,3.2. Parameterizing What to Transfer,[0],[0]
"The domain-invariant feature factors may include eyes, mouth, tails, etc.",3.2. Parameterizing What to Transfer,[0],[0]
"What to transfer, in this case, is the shared feature factors across domains.",3.2. Parameterizing What to Transfer,[0],[0]
"The way of defining domain-invariant feature factors dictates two groups of latent feature factor based algorithms, i.e., common latent space based and manifold ensemble based algorithms.
",3.2. Parameterizing What to Transfer,[0],[0]
"Common Latent Space Based This line of algorithms, including but not limited to TCA (Pan et al., 2011),",3.2. Parameterizing What to Transfer,[0],[0]
"LSDT (Zhang et al., 2016), and DIP (Baktashmotlagh et al., 2013), assumes that domain-invariant feature factors lie in a single shared latent space.",3.2. Parameterizing What to Transfer,[0],[0]
We denote by ϕ,3.2. Parameterizing What to Transfer,[0],[0]
the function mapping original feature representation into the latent space.,3.2. Parameterizing What to Transfer,[0],[0]
"If ϕ is linear, it can be represented as an embedding matrix W ∈ Rm×u where u is the dimensionality of the latent space.",3.2. Parameterizing What to Transfer,[0],[0]
"Therefore, we can parameterize what to transfer we focus on with W which describes u latent feature factors.",3.2. Parameterizing What to Transfer,[0],[0]
"Otherwise, if ϕ is nonlinear, what to transfer can still be parameterized with W. Though a nonlinear ϕ is not explicitly specified in most cases such as LSDT using sparse coding, target examples represented in the latent space Zte=ϕ(X t e)∈Rn t e×u are always available.",3.2. Parameterizing What to Transfer,[0],[0]
"Consequently, we obtain the similarity metric matrix (Cao et al., 2013) in the latent space, i.e., G=(Xte) †Zte(Z t e) T",3.2. Parameterizing What to Transfer,[0],[0]
"[(Xte) T ]†∈Rm×m according to XteG(X t e) T =Zte(Z t e) T , where (Xte) † is the pseudo-inverse of Xte.",3.2. Parameterizing What to Transfer,[0],[0]
"LDL decomposition on G = LDL T brings the latent feature factor matrix W = LD1/2.
",3.2. Parameterizing What to Transfer,[0],[0]
"Manifold Ensemble Based Initiated by Gopalan et al., manifold ensemble based algorithms consider that a source and a target domain share multiple subspaces (of the same dimension) as points on the Grassmann manifold between them.",3.2. Parameterizing What to Transfer,[0],[0]
"The representation of target examples on u domain-invariant latent factors turns to Zt(nu)e =[ϕ1(Xte), · · ·, ϕnu(Xte)] ∈",3.2. Parameterizing What to Transfer,[0],[0]
"Rn t e×nuu, if nu subspaces on the manifold are sampled.",3.2. Parameterizing What to Transfer,[0],[0]
"When all continuous subspaces on the manifold are sampled, i.e., nu →∞, Gong et al. proved
that Zt(∞)e (Z t(∞) e )T =XteG(X t e)
T where G is the similarity metric matrix.",3.2. Parameterizing What to Transfer,[0],[0]
"For computational details of G, please refer to (Gong et al., 2012).",3.2. Parameterizing What to Transfer,[0],[0]
"W=LD1/2 with L and D obtained from performing LDL decomposition on G=LDLT , therefore, is also qualified to represent latent feature factors distributed in a series of subspaces on a manifold.",3.2. Parameterizing What to Transfer,[0],[0]
"The goal here is to learn a reflection function f such that f(Se, Te,We) can approximate le for all experiences {E1, · · · , ENe}.",3.3. Learning from Experiences,[0],[0]
"The improvement ratio le is closely related to two aspects: 1) the difference between a source and a target domain in the shared latent space, and 2) the discriminative ability of a target domain in the latent space.",3.3. Learning from Experiences,[0],[0]
"The smaller difference guarantees more overlap between domains in the latent space, which signifies more transferable latent feature factors and higher improvement ratios as a result.",3.3. Learning from Experiences,[0],[0]
The discriminative ability of a target domain in the latent space is also vital to improve performances.,3.3. Learning from Experiences,[0],[0]
"Therefore, we build f to take both aspects into consideration.
",3.3. Learning from Experiences,[0],[0]
"The Difference between a Source and a Target Domain We follow (Pan et al., 2011) and adopt the maximum mean discrepancy (MMD) (Gretton et al., 2012b) to measure the difference between domains.",3.3. Learning from Experiences,[0],[0]
"By mapping two domains into the reproducing kernel Hilbert space (RKHS), MMD empirically evaluates the distance between the mean of source examples and that of target examples:
d̂2e(X s eWe,X t eWe)
= ∥∥∥∥",3.3. Learning from Experiences,[0],[0]
1nse nse∑ i=1 φ(xseiWe)−,3.3. Learning from Experiences,[0],[0]
1 nte nte∑ j=1 φ(xtejWe) ∥∥∥∥,3.3. Learning from Experiences,[0],[0]
2,3.3. Learning from Experiences,[0],[0]
"H
= 1
(nse)2 nse∑ i,i′=1 K(xseiWe,xsei′We)
",3.3. Learning from Experiences,[0],[0]
"+ 1
(nte)2 nte∑ j,j′=1 K(xtejWe,xtej′We)
",3.3. Learning from Experiences,[0],[0]
"− 2 nsente
nse,n t e∑
i,j=1
K(xseiWe,xtejWe), (1)
where xtej is the j-th example in X t e, and φ maps from the u-dimensional latent space to the RKHS H. K(·, ·) = 〈φ(·), φ(·)〉 is the kernel function.",3.3. Learning from Experiences,[0],[0]
Different kernels K lead to different MMD distances and thereby different values of f .,3.3. Learning from Experiences,[0],[0]
Thus learning the reflection function f is equivalent to optimizing K so that the MMD distance can well characterize the improvement ratio le for all pairs of domains.,3.3. Learning from Experiences,[0],[0]
"Inspired by multi-kernel MMD (Gretton et al., 2012b), we parameterize K as a linear combination of Nk PSD kernels, i.e., K=∑Nkk=1 βkKk (βk≥0, ∀k), and learn the coefficients β=[β1,· · ·, βNk ] instead.",3.3. Learning from Experiences,[0],[0]
"Using β, the MMD can be rewritten as d̂2e(XseWe,XteWe)= ∑Nk k=1 βkd̂ 2 e(k)(X s eWe,X t eWe)=
βT",3.3. Learning from Experiences,[0],[0]
"d̂e, where d̂e=[d̂2e(1),· · ·, d̂2e(Nk)] with d̂ 2 e(k) computed by the k-th kernel Kk.",3.3. Learning from Experiences,[0],[0]
"In this paper, we consider RBF kernels Kk(a,b)=exp(−‖a−b‖2/δk) by varying the bandwidth δk.
",3.3. Learning from Experiences,[0],[0]
"Unfortunately, the MMD alone is insufficient to measure the difference between domains.",3.3. Learning from Experiences,[0],[0]
The distance variance among all pairs of instances across domains is also required to fully characterize the difference.,3.3. Learning from Experiences,[0],[0]
A pair of domains with small MMD but extremely high variance still have little overlap.,3.3. Learning from Experiences,[0],[0]
"Equation (1) is actually the empirical estimation of d2e(XseWe,XteWe) =",3.3. Learning from Experiences,[0],[0]
"Exsexs′e xtext′e h(x s e,x s′ e ,x t e,x t′ e )",3.3. Learning from Experiences,[0],[0]
"(Gretton et al., 2012b) where h(xse,x s′ e ,x t e,x t′ e ) = K(xseWe,xs′e We)+K(xteWe,xt′e",3.3. Learning from Experiences,[0],[0]
"We)− K(xseWe, xt′e",3.3. Learning from Experiences,[0],[0]
We),3.3. Learning from Experiences,[0],[0]
"− K(xs′e We,xteWe).",3.3. Learning from Experiences,[0],[0]
"Consequently, the distance variance, σ2e , equals σ2e(X s eWe,X t eWe) =Exsexs′e xtext′e",3.3. Learning from Experiences,[0],[0]
"[(h(x s e,x s′ e ,x t e,x t′ e )
−Exsexs′e xtext′e h(x s e,x s′ e ,x t e,x t′ e )) 2].
",3.3. Learning from Experiences,[0],[0]
"To be consistent with the MMD characterized with Nk PSD kernels, we rewrite σ2e = βTQeβ where Qe = cov(h) =[
σe(1,1) ··· σe(1,Nk)··· ··· ··· σe(Nk,1) ···σe(Nk,Nk)
] .",3.3. Learning from Experiences,[0],[0]
"Each element σe(k1,k2) = cov(hk1 ,
hk2) =",3.3. Learning from Experiences,[0],[0]
E,3.3. Learning from Experiences,[0],[0]
[(hk1−Ehk1)(hk2−Ehk2)].,3.3. Learning from Experiences,[0],[0]
Note that Ehk1 is shorthand for Exsexs′e xtext′e,3.3. Learning from Experiences,[0],[0]
"hk1(x s e,x s′ e ,x t e,x t′ e ) where hk1 is calculated using the k1-th kernel.",3.3. Learning from Experiences,[0],[0]
"We detail the empirical estimate Q̂e of Qe in the supplementary due to page limit.
",3.3. Learning from Experiences,[0],[0]
"The Discriminative Ability of a Target Domain In view of limited labeled examples in a target domain, we resort to unlabeled examples to evaluate the discriminative ability.",3.3. Learning from Experiences,[0],[0]
The principles of the unlabeled discriminant criterion are two-fold: 1) similar examples should still be neighbours after being embedded into the latent space; and 2) dissimilar examples should be far away.,3.3. Learning from Experiences,[0],[0]
"We adopt the unlabeled discriminant criterion proposed in (Yang et al., 2007b),
τe = tr(WTe S N e We)/tr(W T e S L e We),
where SLe = ∑nte
j,j′=1 Hjj′ (nte) 2",3.3. Learning from Experiences,[0],[0]
(x t ej,3.3. Learning from Experiences,[0],[0]
− xtej′)(xtej,3.3. Learning from Experiences,[0],[0]
"− xtej′)T
is the local scatter covariance matrix with the neighbour information Hjj′ defined as Hjj′ ={ K(xtej ,xtej′), if xtej ∈ Nr(xtej′) and xtej′ ∈ Nr(xtej) 0, otherwise .
",3.3. Learning from Experiences,[0],[0]
"If xtej and x t ej′ are mutual r-nearest neighbours to each other, Hjj′ equals the kernel value K(xtej ,xtej′).",3.3. Learning from Experiences,[0],[0]
"By maximizing the unlabeled discriminant criterion τe, the local scatter covariance matrix guarantees the first principle, while
SNe = ∑nte",3.3. Learning from Experiences,[0],[0]
"j,j′=1 K(xtej ,xtej′ )−Hjj′
(nte) 2 (x
t ej",3.3. Learning from Experiences,[0],[0]
− xtej′)(xtej,3.3. Learning from Experiences,[0],[0]
"− xtej′)T ,
the non-local scatter covariance matrix, enforces the second principle.",3.3. Learning from Experiences,[0],[0]
τe also depends on kernels which in this case indicate different neighbour information and different degrees of similarity between neighboured examples.,3.3. Learning from Experiences,[0],[0]
"With τe(k) obtained from the k-th kernel Kk, the unlabeled discriminant criterion τe can be written as τe = ∑Nk k=1 βkτe(k) = β
T τ e where τ e =",3.3. Learning from Experiences,[0],[0]
"[τe(1), · · · , τe(Nk)].
",3.3. Learning from Experiences,[0],[0]
"The Optimization Problem Combining the two aspects abovementioned to model the reflection function f , we finally formulate the optimization problem as follows,
β∗, λ∗, μ∗, b∗ =
arg min β,λ,μ,",3.3. Learning from Experiences,[0],[0]
b Ne∑ e=1,3.3. Learning from Experiences,[0],[0]
Lh ( βT d̂e,3.3. Learning from Experiences,[0],[0]
+ λβ T Q̂eβ,3.3. Learning from Experiences,[0],[0]
+ μ βT,3.3. Learning from Experiences,[0],[0]
τ,3.3. Learning from Experiences,[0],[0]
"e + b, 1 le )
+ γ1R(β, λ, μ, b),
s.t.",3.3. Learning from Experiences,[0],[0]
"βk ≥ 0, ∀k ∈ {1, · · · , Nk}, λ ≥ 0, μ ≥ 0, (2) where 1/f = βT",3.3. Learning from Experiences,[0],[0]
d̂e +,3.3. Learning from Experiences,[0],[0]
"λβT Q̂eβ + μβT τe + b and Lh(·) is the Huber regression loss (Huber et al., 1964) constraining the value of 1/f to be as close to 1/le as possible.",3.3. Learning from Experiences,[0],[0]
γ1 controls the complexity of the parameters by l2-regularization.,3.3. Learning from Experiences,[0],[0]
"Minimizing the difference between domains, including the MMD distance βT",3.3. Learning from Experiences,[0],[0]
d̂e and the distance variance βT,3.3. Learning from Experiences,[0],[0]
"Q̂eβ, and meanwhile maximizing the discriminant criterion βT τ",3.3. Learning from Experiences,[0],[0]
"e in the target domain will contribute a large performance improvement ratio le (i.e., a small 1/le).",3.3. Learning from Experiences,[0],[0]
"λ and μ balance the importance of the three terms in f , and b is the bias term.",3.3. Learning from Experiences,[0],[0]
"Once the L2T agent has learned the reflection function f(S, T ,W;β∗, λ∗, μ∗, b∗), it takes advantage of the function to optimize what to transfer, i.e., the latent feature factor matrix W, for a newly arrived source domain SNe+1 and a target domain TNe+1.",3.4. Inferring What to Transfer,[0],[0]
The optimal latent feature factor matrix W∗Ne+1 should maximize the value of f .,3.4. Inferring What to Transfer,[0],[0]
"To this end, we optimize the following objective with regard to W, W
∗ Ne+1",3.4. Inferring What to Transfer,[0],[0]
"=argmax W f(SNe+1, TNe+1,W;β ∗ , λ ∗ , μ ∗ , b ∗ )",3.4. Inferring What to Transfer,[0],[0]
"− γ2‖W‖2F
=argmin W
(β ∗ )",3.4. Inferring What to Transfer,[0],[0]
T d̂W + λ ∗ (β ∗ ),3.4. Inferring What to Transfer,[0],[0]
"T Q̂Wβ ∗ + μ ∗ 1 (β∗)T τW + γ2‖W‖2F , (3)
where ‖ · ‖F denotes the matrix Frobenius norm and γ2 controls the complexity of W. The first and second terms in problem (3) can be calculated as
(β ∗ )",3.4. Inferring What to Transfer,[0],[0]
T d̂W = Nk∑ k=1 β,3.4. Inferring What to Transfer,[0],[0]
∗,3.4. Inferring What to Transfer,[0],[0]
"k
[ 1
a2 a∑ i,i′=1 Kk(viW,vi′W)+
1 b2 b∑ j,j′=1 Kk(wjW,wj′W)",3.4. Inferring What to Transfer,[0],[0]
"− 2 ab a,b∑ i,j=1 Kk(viW,wjW) ] ,
(β ∗ )",3.4. Inferring What to Transfer,[0],[0]
"T Q̂Wβ ∗ =
1
n2 − 1 n∑ i,i′=1 Nk∑ k=1 { β ∗",3.4. Inferring What to Transfer,[0],[0]
k,3.4. Inferring What to Transfer,[0],[0]
"[ Kk(viW,vi′W)+
Kk(wiW,wi′W)",3.4. Inferring What to Transfer,[0],[0]
"− 2Kk(viW,wi′W) − 1
n2 n∑ i,i′=1 ( Kk(viW,vi′W)
+ Kk(wiW,wi′W)",3.4. Inferring What to Transfer,[0],[0]
"− 2Kk(viW,wi′W) )",3.4. Inferring What to Transfer,[0],[0]
"]}2 ,
where the shorthand vi = xs(Ne+1)i, vi′ = x s (Ne+1)i′ , wj = xt(Ne+1)j , wj′ =x t (Ne+1)j′ , a=n s Ne+1, and b=n t Ne+1 are used due to space limit.",3.4. Inferring What to Transfer,[0],[0]
"Note that n=min(nsNe+1, n t Ne+1
).",3.4. Inferring What to Transfer,[0],[0]
"The third term in problem (3) can be computed as (β∗)T τW =∑Nk
k=1 β ∗ k tr(WTSNk W) tr(WTSLkW) .",3.4. Inferring What to Transfer,[0],[0]
"We optimize the non-convex prob-
lem (3) w.r.t W by employing a conjugate gradient method in which the gradient is listed in the supplementary material.",3.4. Inferring What to Transfer,[0],[0]
"In this section, we would theoretically investigate how previous transfer learning experiences influence a transfer learning task of interest.",4. Stability and Generalization Bounds,[0],[0]
"We also provide and prove the algorithmic stability and generalization bound for latent feature factor based transfer learning algorithms without experiences considered in the supplementary.
",4. Stability and Generalization Bounds,[0],[0]
"Consider S = {〈S1, T1〉,· · ·, 〈SNe , TNe〉} to be Ne transfer learning experiences or the so-called meta-samples (Maurer, 2005).",4. Stability and Generalization Bounds,[0],[0]
"Let L(S) be our algorithm that learns meta-cognitive knowledge from Ne transfer learning experiences in S and applies the knowledge to the (Ne+1)-th transfer learning task 〈SNe+1, TNe+1〉.",4. Stability and Generalization Bounds,[0],[0]
"To analyse the stability and give the generalization bound, we make an assumption on the distribution from which all Ne transfer learning experiences as meta-samples are sampled.",4. Stability and Generalization Bounds,[0],[0]
"For every environment E we have, all Ne pairs of source and target domains in S are drawn according to an algebraic β-mixing stationary distribution (DE)Ne , which is not i.i.d.. Intuitively, the algebraical β-mixing stationary distribution (see Definition 2 in (Mohri & Rostamizadeh, 2010)) with the β-mixing coefficient β(m)≤β0/mr models the dependence between future samples and past samples by a distance of at least m. The independent block technique (Bernstein, 1927) has been widely adopted to deal with non-i.i.d.",4. Stability and Generalization Bounds,[0],[0]
learning problems.,4. Stability and Generalization Bounds,[0],[0]
"Under this assumption, L(S) is uniformly stable.
",4. Stability and Generalization Bounds,[0],[0]
Theorem 1.,4. Stability and Generalization Bounds,[0],[0]
Suppose that for any xte and for any yte we have ‖xte‖2≤rx and |yte|≤B.,4. Stability and Generalization Bounds,[0],[0]
"Meanwhile, for any e-th transfer learning experience, we assume that the latent feature factor matrix ‖We‖≤ rW .",4. Stability and Generalization Bounds,[0],[0]
"To meet the assumption above, we reasonably simplify L(S) so that the latent feature factor matrix for the (Ne+1)-th transfer learning task is a linear combination of all Ne historical latent factor feature matrices plus a noisy latent feature matrix W satisfying ‖W ‖≤r , i.e., WNe+1= ∑Ne e=1 ceWe+W with each coefficient 0≤ce≤1.",4. Stability and Generalization Bounds,[0],[0]
Our algorithm L(S) is uniformly stable.,4. Stability and Generalization Bounds,[0],[0]
"For any 〈S, T 〉 as the coming transfer learning task, the following inequality holds:∣∣lemp(L(S), (S, T ))",4. Stability and Generalization Bounds,[0],[0]
"− lemp(L(Se0), (S, T ))∣∣
≤",4. Stability and Generalization Bounds,[0],[0]
4(4Ne − 3 + r /rW ),4. Stability and Generalization Bounds,[0],[0]
"B 2rx
λN2e ∼",4. Stability and Generalization Bounds,[0],[0]
O,4. Stability and Generalization Bounds,[0],[0]
"( B2rx λNe ) , (4)
where S = {〈S1, T1〉, · · · , 〈Se0−1, Te0−1〉, 〈Se0 , Te0〉, 〈Se0+1, Te0+1〉, · · · , 〈SNe , TNe〉} denotes the full set of meta-samples, and Se0 = {〈S1, T1〉, · · · , 〈Se0−1, Te0−1〉, 〈Se′0 , Te′0〉, 〈Se0+1, Te0+1〉, · · · , 〈SNe , TNe〉} represents the meta-samples with the e0-th meta-example replaced as 〈Se′0 , Te′0〉.",4. Stability and Generalization Bounds,[0],[0]
"By generalizing S to be meta-samples S and hS to be L2T L(S), we apply Corollary 21 in (Mohri & Rostamizadeh,
2010) to give the generalization bound of our algorithm L(S) in Theorem 2.
Theorem 2.",4. Stability and Generalization Bounds,[0],[0]
Let δ′ = δ−(Ne) 1 2(r+1),4. Stability and Generalization Bounds,[0],[0]
− 14 (r > 1 is required).,4. Stability and Generalization Bounds,[0],[0]
"Then for any sample S of size Ne drawn according to an algebraic β-mixing stationary distribution, and δ ≥ 0 such that δ′ ≥ 0, the following generalization bound holds with probability at least 1− δ: ∣∣R(L(S))−RNe(L(S))∣∣ < O ( (Ne) 1 2(r+1)",4. Stability and Generalization Bounds,[0],[0]
"− 1 4 √ log( 1
δ′ )
) ,
where R(L(S)) and RNe(L(S)) denote the expected risk and the empirical risk of L2T over meta-samples, respectively.",4. Stability and Generalization Bounds,[0],[0]
"A larger mixing parameter r, indicating more independence, would lead to a tighter bound.
",4. Stability and Generalization Bounds,[0],[0]
"Theorem 2 tells that as the number of transfer learning experiences, i.e., Ne, increases, L2T tends to produce a tighter generalization bound.",4. Stability and Generalization Bounds,[0],[0]
This fact lays the foundation for further conducting L2T in an online manner which can gradually assimilate transfer learning experiences and continuously improve.,4. Stability and Generalization Bounds,[0],[0]
The detailed proofs for Theorem 1 and 2 can be found in the supplementary.,4. Stability and Generalization Bounds,[0],[0]
"Datasets We evaluate the L2T framework on two image datasets, Caltech-256 (Griffin et al., 2007) and Sketches (Eitz et al., 2012).",5. Experiments,[0],[0]
"Caltech-256, collected from Google Images, contains a total of 30,607 images in 256 categories.",5. Experiments,[0],[0]
"The Sketches dataset, however, consists of 20,000 unique sketches by human beings that are evenly distributed over 250 different categories.",5. Experiments,[0],[0]
"We construct each pair of source and target domains by randomly sampling three categories from Caltech-256 as the source domain and randomly sampling three categories from Sketches as the target domain, which we give an example in the supplementary material.",5. Experiments,[0],[0]
"Consequently, there are 20, 000/250× 3 = 720 examples in a target domain of each pair.",5. Experiments,[0],[0]
"In total, we generate 1,000 training pairs for preparing transfer learning experiences, 500 validation pairs to determine hyperparameters of the reflection function, and 500 testing pairs to evaluate the reflection function.",5. Experiments,[0],[0]
"We characterize each image from both datasets with 4,096-dimensional features extracted by a convolutional neural network pre-trained by ImageNet.
",5. Experiments,[0],[0]
"In this paper we generate transfer learning experiences by ourselves, because we are the first to consider transfer learning experiences and there exists no off-the-shelf datasets.",5. Experiments,[0],[0]
"In real-world applications, either the number of labeled examples in a target domain or the transfer learning algorithm could vary from experience to experience.",5. Experiments,[0],[0]
"In order to mimic the real environment, we prepare each transfer learning experience by randomly selecting a transfer learning algorithm from a base set A and randomly setting the number of labeled target examples in the range of [3, 120].",5. Experiments,[0],[0]
"The randomly
generated training experiences, lying in the same environment (generated by one dataset), are non i.i.d., which fit the algebraical β-mixing assumption theoretically in Section 4.
",5. Experiments,[0],[0]
"Baselines and Evaluation Metrics We compare L2T with the following nine baseline algorithms in three classes:
• Non-transfer: Original builds a model using labeled data in a target domain only.",5. Experiments,[0],[0]
"• Common latent space based transfer learning algorithms: TCA (Pan et al., 2011), ITL (Shi & Sha, 2012), CMF (Long et al., 2014), LSDT (Zhang et al., 2016), STL (Raina et al., 2007), DIP (Baktashmotlagh et al., 2013) and SIE (Baktashmotlagh et al., 2014).",5. Experiments,[0],[0]
"• Manifold ensemble based algorithms: GFK (Gong et al., 2012).
",5. Experiments,[0],[0]
The eight feature-based transfer learning algorithms also constitute the base set A.,5. Experiments,[0],[0]
"Based on feature representations obtained by different algorithms, we use the nearestneighbor classifier to perform three-class classification for the target domain.
",5. Experiments,[0],[0]
One evaluation metric is classification accuracy on testing examples of a target domain.,5. Experiments,[0],[0]
"However, accuracies are incomparable for different target domains at different levels of difficulty.",5. Experiments,[0],[0]
"The other evaluation metric we adopt is the performance improvement ratio defined in Section 3.1, so as to compare the L2T over different pairs of domains.
",5. Experiments,[0],[0]
"Performance Comparison In this experiment, we learn a reflection function from 1,000 transfer learning experiences, and evaluate the reflection function on 500 testing pairs of source and target domains by comparing the average performance improvement ratio to the baselines.",5. Experiments,[0],[0]
"In building the reflection function, we use 33 RBF kernels with the bandwidth δk in the range of [2−8η : 20.5η : 28η] where η = 1
nsen t eNe
∑Ne e=1 ∑nse,nte i,j=1 ‖xseiW",5. Experiments,[0],[0]
"− xtejW‖22 follows
the median trick (Gretton et al., 2012a).",5. Experiments,[0],[0]
"As Figure 4 shows, on average the proposed L2T framework outperforms the baselines up to 10% when varying the number of labeled samples in the target domain.",5. Experiments,[0],[0]
"As the number of labeled target examples increases from 3 to 120, the performance improvement ratio becomes smaller because the accuracy of Original without transfer tends to increase.",5. Experiments,[0],[0]
"The baseline
algorithms behave differently.",5. Experiments,[0],[0]
"The transferable knowledge learned by LSDT helps a target domain a lot when training examples are scarce, while GFK performs poorly until training examples become more.",5. Experiments,[0],[0]
STL is almost the worst baseline because it learns a dictionary from the source domain only but ignores the target domain.,5. Experiments,[0],[0]
It runs at a high risk of failure especially when two domains are distant.,5. Experiments,[0],[0]
"DIP and SIE, which minimize the MMD and Hellinger distance between domains subject to manifold constraints, are competent.",5. Experiments,[0],[0]
"Note that we have run the paired t-test between L2T and each baseline with all the p-values in the order of 10−12, concluding that the L2T is significantly superior.
",5. Experiments,[0],[0]
We also randomly select six of the 500 testing pairs and compare classification accuracies by different algorithms for each pair in Figure 3.,5. Experiments,[0],[0]
The performance of all baselines varies from pair to pair.,5. Experiments,[0],[0]
"Among all the baseline methods, TCA performs the best when transferring between domains in Figure 3a and LSDT is the most superior in Figure 3c.",5. Experiments,[0],[0]
"However, L2T consistently outperforms the baselines on all the settings.",5. Experiments,[0],[0]
"For some pairs, e.g., Figures 3a, 3c and 3f, the three classes in a target domain are comparably easy to tell apart, hence Original without transfer can achieve even better results than some transfer learning algorithms.",5. Experiments,[0],[0]
"In this case, L2T still improves by discovering the best transferable knowledge from the source domain, especially when the number of labeled examples is small (see Figure 3c and 3f).",5. Experiments,[0],[0]
"If two domains are very related, e.g., the source with “galaxy” and “saturn” and the target with “sun” in Figure 3a, L2T even finds out more transferable knowledge and contributes more significant improvement.
",5. Experiments,[0],[0]
"Varying the Experiences We further investigate how transfer learning experiences used to learn the reflection function influence the performance of L2T. In this experiment, we evaluate on 50 randomly sampled pairs out of the 500 testing pairs in order to efficiently investigate a wide range of cases in the following.",5. Experiments,[0],[0]
"The sampled set is unbiased and sufficient to characterize such influence, evidenced by the asymptotic consistency between the average performance improvement ratio on the 500 pairs in Figure 4 and that on the 50 pairs in the last line of Table 1.",5. Experiments,[0],[0]
"First, we fix the number of transfer learning experiences to be 1,000 and vary the set of base transfer learning algorithms.",5. Experiments,[0],[0]
The results are shown in Table 1.,5. Experiments,[0],[0]
"Even with experiences generated by single base algorithm, e.g., ITL or DIP, the L2T can still learn a reflection function that significantly better (p-value < 0.05) decides what to transfer than using ITL or DIP directly.",5. Experiments,[0],[0]
"With more base algorithms involved, the transfer learning experiences are more diverse to cover more situations of source-target pairs and the knowledge transferred between them.",5. Experiments,[0],[0]
"As a result, the L2T learns a better reflection function and thereby achieves higher performance improvement ratios, which coincides with Theorem 2 where a larger r indicating more independence between experiences gives a tighter bound.",5. Experiments,[0],[0]
"Second, we fix the set of base algorithms to include all the eight baselines and vary the number of transfer learning experiences used for training.",5. Experiments,[0],[0]
"As shown in Figure 5, the average performance improvement ratio achieved by L2T tends to increase as the number of labeled examples in the target domain decreases, given that Original without transfer performs extremely poor with scarce labeled examples.
",5. Experiments,[0],[0]
Figure 6.,5. Experiments,[0],[0]
"Varying the components constituted in the f .
Figure 7.",5. Experiments,[0],[0]
"Varying the number of kernels considered in the f .
",5. Experiments,[0],[0]
"More importantly, it increases as the number of experiences increases, which coincides with Theorem 2.
",5. Experiments,[0],[0]
"Varying the Reflection Function We also study the influence of different configurations of the reflection function on the performance of L2T. First, we vary the components to be considered in building the reflection function f as shown in Figure 6.",5. Experiments,[0],[0]
"Considering single type, either MMD, variance, or the discriminant criterion, brings inferior performance and even negative transfer.",5. Experiments,[0],[0]
"L2T taking all the three factors into consideration outperforms the others, demonstrating that the three components are all necessary and mutually reinforcing.",5. Experiments,[0],[0]
"With all the three components included, we plot values of the learned β∗ in the supplementary material.",5. Experiments,[0],[0]
"Second, we change the kernels used.",5. Experiments,[0],[0]
"In Figure 7, we present results by either narrowing down or extending the range [2−8η : 20.5η : 28η].",5. Experiments,[0],[0]
"Obviously, more kernels (e.g., [2−12η : 20.5η : 212η]), capable of encrypting better trans-
fer learning skills in the reflection function, achieve larger performance improvement ratios.",5. Experiments,[0],[0]
"In this paper, we propose a novel L2T framework for transfer learning which automatically optimizes what and how to transfer between a source and a target domain by leveraging previous transfer learning experiences.",6. Conclusion,[0],[0]
"In particular, L2T learns a reflection function mapping a pair of domains and the knowledge transferred between them to the performance improvement ratio.",6. Conclusion,[0],[0]
"When a new pair of domains arrives, L2T optimizes what and how to transfer by maximizing the value of the learned reflection function.",6. Conclusion,[0],[0]
We believe that L2T opens a new door to improve transfer learning by leveraging transfer learning experiences.,6. Conclusion,[0],[0]
"Many research issues, e.g., incorporating hierarchical latent feature factors as what to transfer and designing online L2T, can be further examined.",6. Conclusion,[0],[0]
We thank the reviewers for their valuable comments to improve this paper.,Acknowledgements,[0],[0]
"The research has been supported by National Grant Fundamental Research (973 Program) of China under Project 2014CB340304, Hong Kong CERG projects 16211214/16209715/16244616, Hong Kong ITF ITS/391/15FX and NSFC 61673202.",Acknowledgements,[0],[0]
"In transfer learning, what and how to transfer are two primary issues to be addressed, as different transfer learning algorithms applied between a source and a target domain result in different knowledge transferred and thereby the performance improvement in the target domain.",abstractText,[0],[0]
Determining the optimal one that maximizes the performance improvement requires either exhaustive exploration or considerable expertise.,abstractText,[0],[0]
"Meanwhile, it is widely accepted in educational psychology that human beings improve transfer learning skills of deciding what to transfer through meta-cognitive reflection on inductive transfer learning practices.",abstractText,[0],[0]
"Motivated by this, we propose a novel transfer learning framework known as Learning to Transfer (L2T) to automatically determine what and how to transfer are the best by leveraging previous transfer learning experiences.",abstractText,[0],[0]
We establish the L2T framework in two stages: 1) we learn a reflection function encrypting transfer learning skills from experiences; and 2) we infer what and how to transfer are the best for a future pair of domains by optimizing the reflection function.,abstractText,[0],[0]
"We also theoretically analyse the algorithmic stability and generalization bound of L2T, and empirically demonstrate its superiority over several state-ofthe-art transfer learning algorithms.",abstractText,[0],[0]
Transfer Learning via Learning to Transfer,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 946–956 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
946",text,[0],[0]
"Target-oriented (also mentioned as “target-level” or “aspect-level” in some works) sentiment classification aims to determine sentiment polarities over “opinion targets” that explicitly appear in the sentences (Liu, 2012).",1 Introduction,[0],[0]
"For example, in the sentence “I am pleased with the fast log on, and the long battery life”, the user mentions two targets
∗The work was done when Xin Li was an intern at Tencent AI Lab.",1 Introduction,[0],[0]
"This project is substantially supported by a grant from the Research Grant Council of the Hong Kong Special Administrative Region, China (Project Code: 14203414).
",1 Introduction,[0],[0]
"1Our code is open-source and available at https:// github.com/lixin4ever/TNet
“log on” and “better life”, and expresses positive sentiments over them.",1 Introduction,[0],[0]
"The task is usually formulated as predicting a sentiment category for a (target, sentence) pair.
",1 Introduction,[0],[0]
"Recurrent Neural Networks (RNNs) with attention mechanism, firstly proposed in machine translation (Bahdanau et al., 2014), is the most commonly-used technique for this task.",1 Introduction,[0],[0]
"For example, Wang et al. (2016); Tang et al. (2016b); Yang et al. (2017); Liu and Zhang (2017); Ma et al. (2017) and Chen et al. (2017) employ attention to measure the semantic relatedness between each context word and the target, and then use the induced attention scores to aggregate contextual features for prediction.",1 Introduction,[0],[0]
"In these works, the attention weight based combination of word-level features for classification may introduce noise and downgrade the prediction accuracy.",1 Introduction,[0],[0]
"For example, in “This dish is my favorite and I always get it and never get tired of it.”, these approaches tend to involve irrelevant words such as “never” and “tired” when they highlight the opinion modifier “favorite”.",1 Introduction,[0],[0]
"To some extent, this drawback is rooted in the attention mechanism, as also observed in machine translation (Luong et al., 2015) and image captioning (Xu et al., 2015).
",1 Introduction,[0],[0]
Another observation is that the sentiment of a target is usually determined by key phrases such as “is my favorite”.,1 Introduction,[0],[0]
"By this token, Convolutional Neural Networks (CNNs)—whose capability for extracting the informative n-gram features (also called “active local features”) as sentence representations has been verified in (Kim, 2014; Johnson and Zhang, 2015)— should be a suitable model for this classification problem.",1 Introduction,[0],[0]
"However, CNN likely fails in cases where a sentence expresses different sentiments over multiple targets, such as “great food but the service was dreadful!”.",1 Introduction,[0],[0]
"One reason is that CNN cannot fully explore the target information as done by RNN-based meth-
ods (Tang et al.,",1 Introduction,[0],[0]
"2016a).2 Moreover, it is hard for vanilla CNN to differentiate opinion words of multiple targets.",1 Introduction,[0],[0]
"Precisely, multiple active local features holding different sentiments (e.g., “great food” and “service was dreadful”) may be captured for a single target, thus it will hinder the prediction.
",1 Introduction,[0],[0]
"We propose a new architecture, named TargetSpecific Transformation Networks (TNet), to solve the above issues in the task of target sentiment classification.",1 Introduction,[0],[0]
TNet firstly encodes the context information into word embeddings and generates the contextualized word representations with LSTMs.,1 Introduction,[0],[0]
"To integrate the target information into the word representations, TNet introduces a novel Target-Specific Transformation (TST) component for generating the target-specific word representations.",1 Introduction,[0],[0]
"Contrary to the previous attention-based approaches which apply the same target representation to determine the attention scores of individual context words, TST firstly generates different representations of the target conditioned on individual context words, then it consolidates each context word with its tailor-made target representation to obtain the transformed word representation.",1 Introduction,[0],[0]
"Considering the context word “long” and the target “battery life” in the above example, TST firstly measures the associations between “long” and individual target words.",1 Introduction,[0],[0]
Then it uses the association scores to generate the target representation conditioned on “long”.,1 Introduction,[0],[0]
"After that, TST transforms the representation of “long” into its target-specific version with the new target representation.",1 Introduction,[0],[0]
"Note that “long” could also indicate a negative sentiment (say for “startup time”), and the above TST is able to differentiate them.
",1 Introduction,[0],[0]
"As the context information carried by the representations from the LSTM layer will be lost after the non-linear TST, we design a contextpreserving mechanism to contextualize the generated target-specific word representations.",1 Introduction,[0],[0]
Such mechanism also allows deep transformation structure to learn abstract features3.,1 Introduction,[0],[0]
"To help the CNN feature extractor locate sentiment indicators more accurately, we adopt a proximity strategy to scale the input of convolutional layer with positional relevance between a word and the target.
",1 Introduction,[0],[0]
"2One method could be concatenating the target representation with each word representation, but the effect as shown in (Wang et al., 2016) is limited.
3Abstract features usually refer to the features ultimately useful for the task (Bengio et al., 2013; LeCun et al., 2015).
",1 Introduction,[0],[0]
"In summary, our contributions are as follows: • TNet adapts CNN to handle target-level sentiment classification, and its performance dominates the state-of-the-art models on benchmark datasets.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
A novel Target-Specific Transformation component is proposed to better integrate target information into the word representations.,1 Introduction,[0],[0]
"• A context-preserving mechanism is designed to forward the context information into a deep transformation architecture, thus, the model can learn more abstract contextualized word features from deeper networks.",1 Introduction,[0],[0]
"Given a target-sentence pair (wτ ,w), where wτ = {wτ1 , wτ2 , ..., wτm} is a sub-sequence of w = {w1, w2, ..., wn}, and the corresponding word embeddings xτ = {xτ1 , xτ2 , ..., xτm} and x = {x1, x2, ..., xn}, the aim of target sentiment classification is to predict the sentiment polarity y ∈ {P,N,O} of the sentence w over the target wτ , where P , N and O denote “positive”, “negative” and “neutral” sentiments respectively.
",2 Model Description,[0],[0]
The architecture of the proposed TargetSpecific Transformation Networks (TNet) is shown in Fig. 1.,2 Model Description,[0],[0]
"The bottom layer is a BiLSTM which transforms the input x = {x1, x2, ..., xn} ∈ Rn×dimw into the contextualized word representations h(0) = {h(0)1 , h (0) 2 , ..., h (0) n } ∈ Rn×2dimh (i.e. hidden states of BiLSTM), where dimw and dimh denote the dimensions of the word embeddings and the hidden representations respectively.",2 Model Description,[0],[0]
"The middle part, the core part of our TNet, consists of L Context-Preserving Transformation (CPT) layers.",2 Model Description,[0],[0]
The CPT layer incorporates the target information into the word representations via a novel Target-Specific Transformation (TST) component.,2 Model Description,[0],[0]
"CPT also contains a contextpreserving mechanism, resembling identity mapping (He et al., 2016a,b) and highway connection (Srivastava et al., 2015a,b), allows preserving the context information and learning more abstract word-level features using a deep network.",2 Model Description,[0],[0]
"The top most part is a position-aware convolutional layer which first encodes positional relevance between a word and a target, and then extracts informative features for classification.",2 Model Description,[0],[0]
"As observed in Lai et al. (2015), combining contextual information with word embeddings is an
effective way to represent a word in convolutionbased architectures.",2.1 Bi-directional LSTM Layer,[0],[0]
"TNet also employs a BiLSTM to accumulate the context information for each word of the input sentence, i.e., the bottom part in Fig. 1.",2.1 Bi-directional LSTM Layer,[0],[0]
"For simplicity and space issue, we denote the operation of an LSTM unit on xi as LSTM(xi).",2.1 Bi-directional LSTM Layer,[0],[0]
"Thus, the contextualized word representation h(0)i ∈ R2dimh is obtained as follows:
h (0)",2.1 Bi-directional LSTM Layer,[0],[0]
i =,2.1 Bi-directional LSTM Layer,[0],[0]
"[ −−−−→ LSTM(xi); ←−−−− LSTM(xi)], i ∈",2.1 Bi-directional LSTM Layer,[0],[0]
"[1, n].",2.1 Bi-directional LSTM Layer,[0],[0]
(1),2.1 Bi-directional LSTM Layer,[0],[0]
The above word-level representation has not considered the target information yet.,2.2 Context-Preserving Transformation,[0],[0]
Traditional attention-based approaches keep the word-level features static and aggregate them with weights as the final sentence representation.,2.2 Context-Preserving Transformation,[0],[0]
"In contrast, as shown in the middle part in Fig. 1, we introduce multiple CPT layers and the detail of a single CPT is shown in Fig. 2.",2.2 Context-Preserving Transformation,[0],[0]
"In each CPT layer, a tailor-made TST component that aims at better consolidating word representation and target representation is proposed.",2.2 Context-Preserving Transformation,[0],[0]
"Moreover, we design a context-preserving mechanism enabling the learning of target-specific word representations in a deep neural architecture.",2.2 Context-Preserving Transformation,[0],[0]
TST component is depicted with the TST block in Fig. 2.,2.2.1 Target-Specific Transformation,[0],[0]
The first task of TST is to generate the representation of the target.,2.2.1 Target-Specific Transformation,[0],[0]
"Previous methods (Chen
et al., 2017; Liu and Zhang, 2017) average the embeddings of the target words as the target representation.",2.2.1 Target-Specific Transformation,[0],[0]
This strategy may be inappropriate in some cases because different target words usually do not contribute equally.,2.2.1 Target-Specific Transformation,[0],[0]
"For example, in the target “amd turin processor”, the word “processor” is more important than “amd” and “turin”, because the sentiment is usually conveyed over the phrase head, i.e.,“processor”, but seldom over modifiers (such as brand name “amd”).",2.2.1 Target-Specific Transformation,[0],[0]
Ma et al. (2017) attempted to overcome this issue by measuring the importance score between each target word representation and the averaged sentence vector.,2.2.1 Target-Specific Transformation,[0],[0]
"However, it may be ineffective for sentences expressing multiple sentiments (e.g., “Air has higher resolution but the fonts are small.”), because taking the average tends to neutralize different sentiments.
",2.2.1 Target-Specific Transformation,[0],[0]
We propose to dynamically compute the importance of target words based on each sentence word rather than the whole sentence.,2.2.1 Target-Specific Transformation,[0],[0]
"We first employ another BiLSTM to obtain the target word representations hτ ∈ Rm×2dimh :
hτj =",2.2.1 Target-Specific Transformation,[0],[0]
[ −−−−→ LSTM(xτj ); ←−−−− LSTM(xτj ),2.2.1 Target-Specific Transformation,[0],[0]
"], j ∈",2.2.1 Target-Specific Transformation,[0],[0]
"[1,m].",2.2.1 Target-Specific Transformation,[0],[0]
"(2)
Then, we dynamically associate them with each word wi in the sentence to tailor-make target representation rτi at the time step",2.2.1 Target-Specific Transformation,[0],[0]
"i:
rτi = m∑ j=1 hτj ∗ F(h (l) i , h τ j ), (3)
where the function F measures the relatedness between the j-th target word representation hτj and
the i-th word-level representation h(l)i :
F(h(l)i , h τ j ) =
exp (h (l)>",2.2.1 Target-Specific Transformation,[0],[0]
i h τ j ),2.2.1 Target-Specific Transformation,[0],[0]
"∑m
k=1 exp (h (l)>",2.2.1 Target-Specific Transformation,[0],[0]
i h τ k) .,2.2.1 Target-Specific Transformation,[0],[0]
"(4)
Finally, the concatenation of rτi and h (l) i is fed into a fully-connected layer to obtain the i-th targetspecific word representation h̃i (l) :
h̃ (l) i = g(W τ",2.2.1 Target-Specific Transformation,[0],[0]
[h (l) i :,2.2.1 Target-Specific Transformation,[0],[0]
r τ,2.2.1 Target-Specific Transformation,[0],[0]
i ],2.2.1 Target-Specific Transformation,[0],[0]
"+ b τ ), (5)
where g(∗) is a non-linear activation function and “:” denotes vector concatenation.",2.2.1 Target-Specific Transformation,[0],[0]
W τ,2.2.1 Target-Specific Transformation,[0],[0]
and bτ are the weights of the layer.,2.2.1 Target-Specific Transformation,[0],[0]
"After the non-linear TST (see Eq. 5), the context information captured with contextualized representations from the BiLSTM layer will be lost since the mean and the variance of the features within the feature vector will be changed.",2.2.2 Context-Preserving Mechanism,[0],[0]
"To take advantage of the context information, which has been proved to be useful in (Lai et al., 2015), we investigate two strategies: Lossless Forwarding (LF) and Adaptive Scaling (AS), to pass the context information to each following layer, as depicted by the block “LF/AS” in Fig. 2.",2.2.2 Context-Preserving Mechanism,[0],[0]
"Accordingly, the model variants are named TNet-LF and TNet-AS.
Lossless Forwarding.",2.2.2 Context-Preserving Mechanism,[0],[0]
This strategy preserves context information by directly feeding the features before the transformation to the next layer.,2.2.2 Context-Preserving Mechanism,[0],[0]
"Specifically, the input h(l+1)i of the (l+1)-th CPT layer is formulated as:
h (l+1)",2.2.2 Context-Preserving Mechanism,[0],[0]
i = h,2.2.2 Context-Preserving Mechanism,[0],[0]
(l) i + h̃ (l),2.2.2 Context-Preserving Mechanism,[0],[0]
"i , i ∈",2.2.2 Context-Preserving Mechanism,[0],[0]
"[1, n], l ∈",2.2.2 Context-Preserving Mechanism,[0],[0]
"[0, L], (6)
where h(l)i is the input of the l-th layer and h̃ (l) i is the output of TST in this layer.",2.2.2 Context-Preserving Mechanism,[0],[0]
"We unfold the recursive form of Eq. 6 as follows:
h (l+1)",2.2.2 Context-Preserving Mechanism,[0],[0]
i = h (0),2.2.2 Context-Preserving Mechanism,[0],[0]
i +TST(h (0) i )+· · ·+TST(h (l) i ).,2.2.2 Context-Preserving Mechanism,[0],[0]
"(7)
Here, we denote h̃(l)i as TST(h (l) i ).",2.2.2 Context-Preserving Mechanism,[0],[0]
"From Eq. 7, we can see that the output of each layer will contain the contextualized word representations (i.e., h (0) i ), thus, the context information is encoded into the transformed features.",2.2.2 Context-Preserving Mechanism,[0],[0]
"We call this strategy “Lossless Forwarding” because the contextualized representations and the transformed representations (i.e., TST(h(l)i )) are kept unchanged during the feature combination.
",2.2.2 Context-Preserving Mechanism,[0],[0]
Adaptive Scaling.,2.2.2 Context-Preserving Mechanism,[0],[0]
"Lossless Forwarding introduces the context information by directly adding back the contextualized features to the transformed features, which raises a question: Can the weights of the input and the transformed features be adjusted dynamically?",2.2.2 Context-Preserving Mechanism,[0],[0]
"With this motivation, we propose another strategy, named “Adaptive Scaling”.",2.2.2 Context-Preserving Mechanism,[0],[0]
"Similar to the gate mechanism in RNN variants (Jozefowicz et al., 2015), Adaptive Scaling introduces a gating function to control the passed proportions of the transformed features and the input features.",2.2.2 Context-Preserving Mechanism,[0],[0]
"The gate t(l) as follows:
t (l)",2.2.2 Context-Preserving Mechanism,[0],[0]
"i = σ(Wtransh (l) i + btrans), (8)
where t(l)i is the gate for the i-th input of the l-th CPT layer, and σ is the sigmoid activation function.",2.2.2 Context-Preserving Mechanism,[0],[0]
"Then we perform convex combination of h(l)i and h̃(l)i based on the gate:
h (l+1)",2.2.2 Context-Preserving Mechanism,[0],[0]
i = t,2.2.2 Context-Preserving Mechanism,[0],[0]
(l) i h̃ (l) i + (1− t (l) i ),2.2.2 Context-Preserving Mechanism,[0],[0]
h,2.2.2 Context-Preserving Mechanism,[0],[0]
(l) i .,2.2.2 Context-Preserving Mechanism,[0],[0]
"(9)
Here, denotes element-wise multiplication.",2.2.2 Context-Preserving Mechanism,[0],[0]
"The non-recursive form of this equation is as follows (for clarity, we ignore the subscripts):
h(l+1) =",2.2.2 Context-Preserving Mechanism,[0],[0]
"[ l∏ k=0 (1− t(k))] h(0)
+[t(0) l∏
k=1
(1− t(k))]",2.2.2 Context-Preserving Mechanism,[0],[0]
TST(h(0)),2.2.2 Context-Preserving Mechanism,[0],[0]
"+ · · ·
+t(l−1)(1− t(l))",2.2.2 Context-Preserving Mechanism,[0],[0]
TST(h(l−1)),2.2.2 Context-Preserving Mechanism,[0],[0]
"+ t(l) TST(h(l)).
",2.2.2 Context-Preserving Mechanism,[0],[0]
"Thus, the context information is integrated in each upper layer and the proportions of the contextualized representations and the transformed representations are controlled by the computed gates in different transformation layers.",2.2.2 Context-Preserving Mechanism,[0],[0]
Recall that the second issue that blocks CNN to perform well is that vanilla CNN may associate a target with unrelated general opinion words which are frequently used as modifiers for different targets across domains.,2.3 Convolutional Feature Extractor,[0],[0]
"For example, “service” in “Great food but the service is dreadful” may be associated with both “great” and “dreadful”.",2.3 Convolutional Feature Extractor,[0],[0]
"To solve it, we adopt a proximity strategy, which is observed effective in (Chen et al., 2017; Li and Lam, 2017).",2.3 Convolutional Feature Extractor,[0],[0]
"The idea is a closer opinion word is more likely to be the actual modifier of the target.
",2.3 Convolutional Feature Extractor,[0],[0]
"Specifically, we first calculate the position relevance vi between the i-th word and the target4:
vi =  1− (k+m−i)C i < k",2.3 Convolutional Feature Extractor,[0],[0]
+m 1− i−kC k +m ≤,2.3 Convolutional Feature Extractor,[0],[0]
i ≤ n 0,2.3 Convolutional Feature Extractor,[0],[0]
"i > n
(10)
where k is the index of the first target word, C is a pre-specified constant, and m is the length of the target wτ .",2.3 Convolutional Feature Extractor,[0],[0]
"Then, we use v to help CNN locate the correct opinion w.r.t.",2.3 Convolutional Feature Extractor,[0],[0]
"the given target:
ĥ (l) i = h",2.3 Convolutional Feature Extractor,[0],[0]
"(l) i ∗ vi, i ∈",2.3 Convolutional Feature Extractor,[0],[0]
"[1, n], l ∈",2.3 Convolutional Feature Extractor,[0],[0]
"[1, L].",2.3 Convolutional Feature Extractor,[0],[0]
"(11)
",2.3 Convolutional Feature Extractor,[0],[0]
"Based on Eq. 10 and Eq. 11, the words close to the target will be highlighted and those far away will be downgraded.",2.3 Convolutional Feature Extractor,[0],[0]
v is also applied on the intermediate output to introduce the position information into each CPT layer.,2.3 Convolutional Feature Extractor,[0],[0]
"Then we feed the weighted h(L) to the convolutional layer, i.e., the top-most layer in Fig. 1, to generate the feature map c ∈",2.3 Convolutional Feature Extractor,[0],[0]
"Rn−s+1 as follows:
ci = ReLU(w > convh (L) i:i+s−1 + bconv), (12)
where h(L)i:i+s−1 ∈ Rs·dimh is the concatenated vector of ĥ(L)i , · · · , ĥ (L) i+s−1, and s is the kernel size.",2.3 Convolutional Feature Extractor,[0],[0]
wconv ∈ Rs·dimh and bconv ∈ R are learnable weights of the convolutional kernel.,2.3 Convolutional Feature Extractor,[0],[0]
"To capture the most informative features, we apply max pooling (Kim, 2014) and obtain the sentence representation z ∈",2.3 Convolutional Feature Extractor,[0],[0]
"Rnk by employing nk kernels:
z =",2.3 Convolutional Feature Extractor,[0],[0]
"[max(c1), · · · ,max(cnk)]",2.3 Convolutional Feature Extractor,[0],[0]
>.,2.3 Convolutional Feature Extractor,[0],[0]
"(13)
Finally, we pass z to a fully connected layer for sentiment prediction:
p(y|wτ ,w) = Softmax(Wfz + bf ).",2.3 Convolutional Feature Extractor,[0],[0]
"(14)
where Wf and bf are learnable parameters.",2.3 Convolutional Feature Extractor,[0],[0]
"4As we perform sentence padding, it is possible that the index i is larger than the actual length n of the sentence.",2.3 Convolutional Feature Extractor,[0],[0]
"As shown in Table 1, we evaluate the proposed TNet on three benchmark datasets: LAPTOP and REST are from SemEval ABSA challenge (Pontiki et al., 2014), containing user reviews in laptop domain and restaurant domain respectively.",3.1 Experimental Setup,[0],[0]
"We also remove a few examples having the “conflict label” as done in (Chen et al., 2017); TWITTER is built by Dong et al. (2014), containing twitter posts.",3.1 Experimental Setup,[0],[0]
"All tokens are lowercased without removal of stop words, symbols or digits, and sentences are zero-padded to the length of the longest sentence in the dataset.",3.1 Experimental Setup,[0],[0]
Evaluation metrics are Accuracy and Macro-Averaged F1 where the latter is more appropriate for datasets with unbalanced classes.,3.1 Experimental Setup,[0],[0]
"We also conduct pairwise t-test on both Accuracy and Macro-Averaged F1 to verify if the improvements over the compared models are reliable.
",3.1 Experimental Setup,[0],[0]
"TNet is compared with the following methods.
",3.1 Experimental Setup,[0],[0]
"• SVM (Kiritchenko et al., 2014):",3.1 Experimental Setup,[0],[0]
"It is a traditional support vector machine based model with extensive feature engineering;
• AdaRNN (Dong et al., 2014):",3.1 Experimental Setup,[0],[0]
"It learns the sentence representation toward target for sentiment prediction via semantic composition over dependency tree;
• AE-LSTM, and ATAE-LSTM (Wang et al., 2016): AE-LSTM is a simple LSTM model incorporating the target embedding as input, while ATAE-LSTM extends AE-LSTM with attention;
• IAN (Ma et al., 2017): IAN employs two LSTMs to learn the representations of the context and the target phrase interactively;
• CNN-ASP: It is a CNN-based model implemented by us which directly concatenates target representation to each word embedding;
• TD-LSTM (Tang et al., 2016a):",3.1 Experimental Setup,[0],[0]
"It employs two LSTMs to model the left and right contexts of the target separately, then performs predictions based on concatenated context representations;
• MemNet (Tang et al., 2016b):",3.1 Experimental Setup,[0],[0]
"It applies attention mechanism over the word embeddings multiple times and predicts sentiments
based on the top-most sentence representations;
• BILSTM-ATT-G (Liu and Zhang, 2017):",3.1 Experimental Setup,[0],[0]
"It models left and right contexts using two attention-based LSTMs and introduces gates to measure the importance of left context, right context, and the entire sentence for the prediction;
• RAM (Chen et al., 2017): RAM is a multilayer architecture where each layer consists of attention-based aggregation of word features and a GRU cell to learn the sentence representation.
",3.1 Experimental Setup,[0],[0]
"We run the released codes of TD-LSTM and BILSTM-ATT-G to generate results, since their papers only reported results on TWITTER.",3.1 Experimental Setup,[0],[0]
"We also rerun MemNet on our datasets and evaluate it with both accuracy and Macro-Averaged F1.5
We use pre-trained GloVe vectors (Pennington et al., 2014) to initialize the word embeddings and the dimension is 300 (i.e., dimw = 300).",3.1 Experimental Setup,[0],[0]
"For out-of-vocabulary words, we randomly sample their embeddings from the uniform distribution U(−0.25, 0.25), as done in (Kim, 2014).",3.1 Experimental Setup,[0],[0]
"We only use one convolutional kernel size because it was observed that CNN with single optimal kernel size is comparable with CNN having multiple kernel sizes on small datasets (Zhang and Wallace, 2017).",3.1 Experimental Setup,[0],[0]
"To alleviate overfitting, we apply dropout on the input word embeddings of the LSTM and",3.1 Experimental Setup,[0],[0]
the ultimate sentence representation z.,3.1 Experimental Setup,[0],[0]
"All weight matrices are initialized with the uniform distribution U(−0.01, 0.01) and the biases are initialized
5The codes of TD-LSTM/MemNet and BILSTM-ATTG are available at: http://ir.hit.edu.cn/˜dytang and http://leoncrashcode.github.io.",3.1 Experimental Setup,[0],[0]
"Note that MemNet was only evaluated with accuracy.
as zeros.",3.1 Experimental Setup,[0],[0]
"The training objective is cross-entropy, and Adam (Kingma and Ba, 2015) is adopted as the optimizer by following the learning rate and the decay rates in the original paper.
",3.1 Experimental Setup,[0],[0]
The hyper-parameters of TNet-LF and TNetAS are listed in Table 2.,3.1 Experimental Setup,[0],[0]
"Specifically, all hyperparameters are tuned on 20% randomly held-out training data and the hyper-parameter collection producing the highest accuracy score is used for testing.",3.1 Experimental Setup,[0],[0]
Our model has comparable number of parameters compared to traditional LSTM-based models as we reuse parameters in the transformation layers and BiLSTM.6,3.1 Experimental Setup,[0],[0]
"As shown in Table 3, both TNet-LF and TNet-AS consistently achieve the best performance on all datasets, which verifies the efficacy of our whole TNet model.",3.2 Main Results,[0],[0]
"Moreover, TNet can perform well for different kinds of user generated content, such as product reviews with relatively formal sentences in LAPTOP and REST, and tweets with more ungrammatical sentences in TWITTER.",3.2 Main Results,[0],[0]
The reason is the CNN-based feature extractor arms TNet with more power to extract accurate features from ungrammatical sentences.,3.2 Main Results,[0],[0]
"Indeed, we can also observe that another CNN-based baseline, i.e., CNNASP implemented by us, also obtains good results on TWITTER.
",3.2 Main Results,[0],[0]
"On the other hand, the performance of those comparison methods is mostly unstable.",3.2 Main Results,[0],[0]
"For the tweet in TWITTER, the competitive BILSTMATT-G and RAM cannot perform as effective as they do for the reviews in LAPTOP and REST, due to the fact that they are heavily rooted in LSTMs and the ungrammatical sentences hinder their ca-
6All experiments are conducted on a single NVIDIA GTX 1080.",3.2 Main Results,[0],[0]
"The prediction cost of a sentence is about 2 ms.
pability in capturing the context features.",3.2 Main Results,[0],[0]
"Another difficulty caused by the ungrammatical sentences is that the dependency parsing might be errorprone, which will affect those methods such as AdaRNN using dependency information.
",3.2 Main Results,[0],[0]
"From the above observations and analysis, some takeaway message for the task of target sentiment classification could be:
• LSTM-based models relying on sequential information can perform well for formal sentences by capturing more useful context features;
",3.2 Main Results,[0],[0]
"• For ungrammatical text, CNN-based models may have some advantages because CNN aims to extract the most informative n-gram features and is thus less sensitive to informal texts without strong sequential patterns.",3.2 Main Results,[0],[0]
"To investigate the impact of each component such as deep transformation, context-preserving mechanism, and positional relevance, we perform comparison between the full TNet models and its ablations (the third group in Table 3).",3.3 Performance of Ablated TNet,[0],[0]
"After removing the deep transformation (i.e., the techniques introduced in Section 2.2), both TNet-LF and TNetAS are reduced to TNet w/o transformation (where
position relevance is kept), and their results in both accuracy and F1 measure are incomparable with those of TNet.",3.3 Performance of Ablated TNet,[0],[0]
"It shows that the integration of target information into the word-level representations is crucial for good performance.
",3.3 Performance of Ablated TNet,[0],[0]
"Comparing the results of TNet and TNet w/o context (where TST and position relevance are kept), we observe that the performance of TNet w/o context drops significantly on LAPTOP and REST7, while on TWITTER, TNet w/o context performs very competitive (p-values with TNetLF and TNet-AS are 0.066 and 0.053 respectively for Accuracy).",3.3 Performance of Ablated TNet,[0],[0]
"Again, we could attribute this phenomenon to the ungrammatical user generated content of twitter, because the contextpreserving component becomes less important for such data.",3.3 Performance of Ablated TNet,[0],[0]
TNet,3.3 Performance of Ablated TNet,[0],[0]
"w/o context performs consistently better than TNet w/o transformation, which verifies the efficacy of the target specific transformation (TST), before applying context-preserving.
",3.3 Performance of Ablated TNet,[0],[0]
"As for the position information, we conduct statistical t-test between TNet-LF/AS and TNetLF/AS w/o position together with performance comparison.",3.3 Performance of Ablated TNet,[0],[0]
"All of the produced p-values are less than 0.05, suggesting that the improvements brought in by position information are significant.
",3.3 Performance of Ablated TNet,[0],[0]
"7Without specification, the significance level is set to 0.05.",3.3 Performance of Ablated TNet,[0],[0]
"The next interesting question is what if we replace the transformation module (i.e., the CPT layers in Fig.1) of TNet with other commonly-used components?",3.4 CPT versus Alternatives,[0],[0]
"We investigate two alternatives: attention mechanism and fully-connected (FC) layer, resulting in three pipelines as shown in the second group of Table 3 (position relevance is kept for them).
",3.4 CPT versus Alternatives,[0],[0]
"LSTM-ATT-CNN applies attention as the alternative8, and it does not need the contextpreserving mechanism.",3.4 CPT versus Alternatives,[0],[0]
It performs unexceptionally worse than the TNet variants.,3.4 CPT versus Alternatives,[0],[0]
We are surprised that LSTM-ATT-CNN is even worse than TNet w/o transformation (a pipeline simply removing the transformation module) on TWITTER.,3.4 CPT versus Alternatives,[0],[0]
"More concretely, applying attention results in negative effect on TWITTER, which is consistent with the observation that all those attention-based state-of-the-art methods (i.e., TD-LSTM, MemNet, BILSTM-ATT-G, and RAM) cannot perform well on TWITTER.
",3.4 CPT versus Alternatives,[0],[0]
"LSTM-FC-CNN-LF and LSTM-FC-CNN-AS are built by applying FC layer to replace TST and keeping the context-preserving mechanism (i.e., LF and AS).",3.4 CPT versus Alternatives,[0],[0]
"Specifically, the concatenation of word representation and the averaged target vector is fed to the FC layer to obtain targetspecific features.",3.4 CPT versus Alternatives,[0],[0]
Note that LSTM-FC-CNNLF/AS are equivalent to TNet-LF/AS when processing single-word targets (see Eq. 3).,3.4 CPT versus Alternatives,[0],[0]
They obtain competitive results on all datasets: comparable with or better than the state-of-the-art methods.,3.4 CPT versus Alternatives,[0],[0]
"The TNet variants can still outperform LSTMFC-CNN-LF/AS with significant gaps, e.g., on LAPTOP and REST, the accuracy gaps between TNet-LF and LSTM-FC-CNN-LF are 0.42% (p < 0.03) and 0.38% (p < 0.04) respectively.",3.4 CPT versus Alternatives,[0],[0]
"As our TNet involves multiple CPT layers, we investigate the effect of the layer number L. Specifically, we conduct experiments on the held-out training data of LAPTOP and vary L from 2 to 10, increased by 2.",3.5 Impact of CPT Layer Number,[0],[0]
The cases L=1 and L=15 are also included.,3.5 Impact of CPT Layer Number,[0],[0]
The results are illustrated in Figure 3.,3.5 Impact of CPT Layer Number,[0],[0]
We can see that both TNet-LF and TNetAS achieve the best results when L=2.,3.5 Impact of CPT Layer Number,[0],[0]
"While increasing L, the performance is basically becoming worse.",3.5 Impact of CPT Layer Number,[0],[0]
"For large L, the performance of TNet-AS
8We tried different attention mechanisms and report the best one here, namely, dot attention (Luong et al., 2015).
generally becomes more sensitive, it is probably because AS involves extra parameters (see Eq 9) that increase the training difficulty.",3.5 Impact of CPT Layer Number,[0],[0]
Table 4 shows some sample cases.,3.6 Case Study,[0],[0]
The input targets are wrapped in the brackets with true labels given as subscripts.,3.6 Case Study,[0],[0]
"The notations P, N and O in the table represent positive, negative and neutral respectively.",3.6 Case Study,[0],[0]
"For each sentence, we underline the target with a particular color, and the text of its corresponding most informative n-gram feature9 captured by TNet-AS (TNet-LF captures very similar features) is in the same color (so color printing is preferred).",3.6 Case Study,[0],[0]
"For example, for the target “resolution” in the first sentence, the captured feature is “Air has higher”.",3.6 Case Study,[0],[0]
"Note that as discussed above, the CNN layer of TNet captures such features with the size-three kernels, so that the features are trigrams.",3.6 Case Study,[0],[0]
"Each of the last features of the second and seventh sentences contains a padding token, which is not shown.
",3.6 Case Study,[0],[0]
Our TNet variants can predict target sentiment more accurately than RAM and BILSTM-ATT-G in the transitional sentences such as the first sentence by capturing correct trigram features.,3.6 Case Study,[0],[0]
"For the third sentence, its second and third most informative trigrams are “100% .",3.6 Case Study,[0],[0]
"PAD” and “’ s not”, being used together with “features make up”, our models can make correct predictions.",3.6 Case Study,[0],[0]
"Moreover, TNet can still make correct prediction when the explicit opinion is target-specific.",3.6 Case Study,[0],[0]
"For example,
9For each convolutional filter, only one n-gram feature in the feature map will be kept after the max pooling.",3.6 Case Study,[0],[0]
"Among those from different filters, the n-gram with the highest frequency will be regarded as the most informative n-gram w.r.t.",3.6 Case Study,[0],[0]
"the given target.
“long” in the fifth sentence is negative for “startup time”, while it could be positive for other targets such as “battery life” in the sixth sentence.",3.6 Case Study,[0],[0]
The sentiment of target-specific opinion word is conditioned on the given target.,3.6 Case Study,[0],[0]
"Our TNet variants, armed with the word-level feature transformation w.r.t.",3.6 Case Study,[0],[0]
"the target, is capable of handling such case.
",3.6 Case Study,[0],[0]
"We also find that all these models cannot give correct prediction for the last sentence, a commonly used subjunctive style.",3.6 Case Study,[0],[0]
"In this case, the difficulty of prediction does not come from the detection of explicit opinion words but the inference based on implicit semantics, which is still quite challenging for neural network models.",3.6 Case Study,[0],[0]
"Apart from sentence level sentiment classification (Kim, 2014; Shi et al., 2018), aspect/target level sentiment classification is also an important research topic in the field of sentiment analysis.",4 Related Work,[0],[0]
"The early methods mostly adopted supervised learning approach with extensive hand-coded features (Blair-Goldensohn et al., 2008; Titov and McDonald, 2008; Yu et al., 2011; Jiang et al., 2011; Kiritchenko et al., 2014; Wagner et al., 2014; Vo and Zhang, 2015), and they fail to model the semantic relatedness between a target and its context which is critical for target sentiment analysis.",4 Related Work,[0],[0]
Dong et al. (2014) incorporate the target information into the feature learning using dependency trees.,4 Related Work,[0],[0]
"As observed in previous works, the performance heavily relies on the quality of dependency parsing.",4 Related Work,[0],[0]
Tang et al. (2016a) propose to split the context into two parts and associate target with contextual features separately.,4 Related Work,[0],[0]
"Similar to (Tang et al., 2016a), Zhang et al. (2016) develop a three-way gated neural network to model the in-
teraction between the target and its surrounding contexts.",4 Related Work,[0],[0]
"Despite the advantages of jointly modeling target and context, they are not capable of capturing long-range information when some critical context information is far from the target.",4 Related Work,[0],[0]
"To overcome this limitation, researchers bring in the attention mechanism to model target-context association (Tang et al., 2016a,b; Wang et al., 2016; Yang et al., 2017; Liu and Zhang, 2017; Ma et al., 2017; Chen et al., 2017; Zhang et al., 2017; Tay et al., 2017).",4 Related Work,[0],[0]
"Compared with these methods, our TNet avoids using attention for feature extraction so as to alleviate the attended noise.",4 Related Work,[0],[0]
"We re-examine the drawbacks of attention mechanism for target sentiment classification, and also investigate the obstacles that hinder CNN-based models to perform well for this task.",5 Conclusions,[0],[0]
Our TNet model is carefully designed to solve these issues.,5 Conclusions,[0],[0]
"Specifically, we propose target specific transformation component to better integrate target information into the word representation.",5 Conclusions,[0],[0]
"Moreover, we employ CNN as the feature extractor for this classification problem, and rely on the contextpreserving and position relevance mechanisms to maintain the advantages of previous LSTM-based models.",5 Conclusions,[0],[0]
The performance of TNet consistently dominates previous state-of-the-art methods on different types of data.,5 Conclusions,[0],[0]
"The ablation studies show the efficacy of its different modules, and thus verify the rationality of TNet’s architecture.",5 Conclusions,[0],[0]
Target-oriented sentiment classification aims at classifying sentiment polarities over individual opinion targets in a sentence.,abstractText,[0],[0]
"RNN with attention seems a good fit for the characteristics of this task, and indeed it achieves the state-of-the-art performance.",abstractText,[0],[0]
"After re-examining the drawbacks of attention mechanism and the obstacles that block CNN to perform well in this classification task, we propose a new model to overcome these issues.",abstractText,[0],[0]
"Instead of attention, our model employs a CNN layer to extract salient features from the transformed word representations originated from a bi-directional RNN layer.",abstractText,[0],[0]
"Between the two layers, we propose a component to generate target-specific representations of words in the sentence, meanwhile incorporate a mechanism for preserving the original contextual information from the RNN layer.",abstractText,[0],[0]
Experiments show that our model achieves a new state-of-the-art performance on a few benchmarks.1,abstractText,[0],[0]
Transformation Networks for Target-Oriented Sentiment Classification,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2313–2318, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"Transition-based parsing, one of the most prominent dependency parsing techniques, constructs a dependency structure by reading words sequentially from the sentence, and making a series of local decisions (called transitions) which incrementally build the structure.",1 Introduction,[0],[0]
"Transition-based parsing has been shown to be both fast and accurate; the number of transitions required to fully parse the sentence is linear relative to the number of words in the sentence.
",1 Introduction,[0],[0]
"In recent years, the field has seen dramatic improvements in the ability to correctly predict transitions.",1 Introduction,[0],[0]
Recent models include the greedy StackLSTM model of Dyer et al. (2015) and the globally normalized feed-forward networks of Andor et al. (2016).,1 Introduction,[0],[0]
"These models output a local decision at each transition point, so searching the space of possible paths to the predicted tree is an important component of high-accuracy parsers.
",1 Introduction,[0],[0]
One common search technique is beam search.,1 Introduction,[0],[0]
"(Zhang and Clark, 2008; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Zhou et al., 2015; Weiss et al., 2015; Yazdani and Henderson, 2015)",1 Introduction,[0],[0]
"In beamsearch, a fixed number of candidate transition sequences are generated, and the highest-scoring sequence is chosen as the answer.",1 Introduction,[0],[0]
One downside to beam search is that it often results in a significant amount of wasted predictions.,1 Introduction,[0],[0]
"A constant number of beams are explored at all points throughout the sentence, leading to some unnecessary exploration towards the beginning of the sentence, and potentially insufficient exploration towards the end.
",1 Introduction,[0],[0]
"One way that this problem can be mitigated is by using a dynamically-sized beam (Mejia-Lavalle and Ramos, 2013).",1 Introduction,[0],[0]
"When using this technique, at each step, prune all beams whose scores are below some value s, where s is calculated based upon the distribution of scores of available beams.",1 Introduction,[0],[0]
"Common methods for pruning are removing all beams below some percentile, or any beams which scored below some constant percentage of the highest-scoring beam.
",1 Introduction,[0],[0]
Another approach to solving this issue is given by Choi and McCallum (2013).,1 Introduction,[0],[0]
"They introduced selectional branching, which involves performing an initial greedy parse, and then using confidence estimates on each prediction to spawn additional beams.",1 Introduction,[0],[0]
"Relative to standard beam-search, this reduces the average number of predictions required to parse a sentence, resulting in a speed-up.
",1 Introduction,[0],[0]
"In this paper, we introduce heuristic backtracking, which expands on the ideas of selectional branching by integrating a search strategy based on a heuristic function (Pearl, 1984): a function which estimates
2313
the future cost of taking a particular decision.",1 Introduction,[0],[0]
"When paired with a good heuristic, heuristic backtracking maintains the property of reducing wasted predictions, but allows us to more fully explore the space of possible transition sequences (as compared to selectional branching).",1 Introduction,[0],[0]
"In this paper, we use a heuristic based on the confidence of transition predictions.
",1 Introduction,[0],[0]
We also introduce a new optimization: heuristic backtracking with cutoff.,1 Introduction,[0],[0]
"Since heuristic backtracking produces results incrementally, it is possible to stop the search early if we have found an answer that we believe to be the gold parse, saving time proportional to the number of backtracks remaining.
",1 Introduction,[0],[0]
"We compare the performance of these various decoding algorithms with the Stack-LSTM parser (Dyer et al., 2015), and achieve slightly higher accuracy than beam search, in significantly less time.",1 Introduction,[0],[0]
Our starting point is the model described by Dyer et al. (,2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"2015).1 The parser implements the arc-standard algorithm (Nivre, 2004) and it therefore makes use of a stack and a buffer.",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"In (Dyer et al., 2015), the stack and the buffer are encoded with Stack-LSTMs, and a third sequence with the history of actions taken by the parser is encoded with another Stack-LSTM.",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"The three encoded sequences form the parser state pt defined as follows,
pt = max {0,W[st;bt;at] + d} , (1)
where W is a learned parameter matrix, bt, st and at are the stack LSTM encoding of buffer, stack and the history of actions, and d is a bias term.",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"The output pt (after a component-wise rectified linear unit (ReLU) nonlinearity (Glorot et al., 2011)) is then used to compute the probability of the parser action at time t as:
p(zt | pt) = exp
( g>ztpt + qzt ) ∑
z′∈A(S,B) exp",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"( g>z′pt + qz′ ) , (2)
where gz is a column vector representing the (output) embedding of the parser action z, and qz is a bias term for action z.",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"The set A(S,B) represents
1We refer to the original work for details.
",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
the valid transition actions that may be taken in the current state.,2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"The objective function is:
Lθ(w, z) = |z|∑
t=1
log p(zt | pt) (3)
where z refers to parse transitions.",2 Transition-Based Parsing With Stack-LSTM,[0],[0]
"Using the Stack-LSTM parsing model of Dyer et al. (2015) to predict each decision greedily yields very high accuracy; however, it can only explore one path, and it therefore can be improved by conducting a larger search over the space of possible parses.",3 Heuristic Backtracking,[0],[0]
"To do this, we introduce a new algorithm, heuristic backtracking.",3 Heuristic Backtracking,[0],[0]
We also introduce a novel cutoff approach to further increase speed.,3 Heuristic Backtracking,[0],[0]
"We model the space of possible parses as a tree, where each node represents a certain parse state (with complete values for stack, buffer, and action history).",3.1 Decoding Strategy,[0],[0]
"Transitions connect nodes of the tree, and leaves of the tree represent final states.
",3.1 Decoding Strategy,[0],[0]
"During the first iteration, we start at the root of the tree, and greedily parse until we reach a leaf.",3.1 Decoding Strategy,[0],[0]
"That is, for each node, we use the Stack-LSTM model to calculate scores for each transition (as described in Section 2), and then execute the highest-scoring transition, generating a child node upon which we repeat the procedure.",3.1 Decoding Strategy,[0],[0]
"Additionally, we save an ordered list of the transition scores, and calculate the confidence of the node (as described in Section 3.2).
",3.1 Decoding Strategy,[0],[0]
"When we reach the leaf node, we backtrack to the location that is most likely to fix a mistake.",3.1 Decoding Strategy,[0],[0]
"To find this, we look at all explored nodes that still have at least one unexplored child, and choose the node with the lowest heuristic confidence (see Section 3.2).",3.1 Decoding Strategy,[0],[0]
"We rewind our stack, buffer, and action history to that state, and execute the highest-scoring transition from that node that has not yet been explored.",3.1 Decoding Strategy,[0],[0]
"At this point, we are again in a fully-unexplored node, and can greedily parse just as before until we reach another leaf.
",3.1 Decoding Strategy,[0],[0]
"Once we have generated b leaves, we score them all and return the transition sequence leading up to the highest-scoring leaf as the answer.",3.1 Decoding Strategy,[0],[0]
"Just as in previous studies (Collins and Roark, 2004), we use the
sum of the log probabilities of all individual transitions as the overall score for the parse.",3.1 Decoding Strategy,[0],[0]
"Let n indicate a node, which consists of a state, a buffer, and an action history.",3.2 Calculating Error Likelihood,[0],[0]
"We may refer to a specific node as nji , which means it has i actions in its action history and it is part of the history of the jth leaf (and possibly subsequent leaves).",3.2 Calculating Error Likelihood,[0],[0]
"Let the function T (n) represent a sorted vector containing all possible transitions from n, and S(n) represent a sorted vector containing the scores of all of these transitions, in terms of log probabilities of each score.",3.2 Calculating Error Likelihood,[0],[0]
"We can index the scores in order of value, so T1(n) is the highest-scoring transition and S1(n) is its score, T2(n) is the second-highest-scoring transition, etc.",3.2 Calculating Error Likelihood,[0],[0]
"Here, let un indicate the ranking of the transition leading to the first unexplored child of a node n. Also, let V (n) represent the total score of all nodes in the history of n, i.e. the sum of all the scores of individual transitions that allowed us to get to n.
To calculate the confidence of an individual node, Choi and McCallum (2013) simply found the score margin, or difference in probability between the topscoring transition and the second-highest scoring transition: C(n) = S1(n)",3.2 Calculating Error Likelihood,[0],[0]
− S2(n).,3.2 Calculating Error Likelihood,[0],[0]
"In selectional branching, the only states for which the confidence was relevant were the states in the first greedy parse, i.e. states n1i for all i. For heuristic backtracking, we wish to generalize this to any state nji for all i and j.
We do this in the following way:
H(nji )",3.2 Calculating Error Likelihood,[0],[0]
=,3.2 Calculating Error Likelihood,[0],[0]
(V (n 1 i ),3.2 Calculating Error Likelihood,[0],[0]
− V (nji )),3.2 Calculating Error Likelihood,[0],[0]
"+ (S(u
n",3.2 Calculating Error Likelihood,[0],[0]
j,3.2 Calculating Error Likelihood,[0],[0]
"i
)−1(n",3.2 Calculating Error Likelihood,[0],[0]
"j i ) + S(u
n j",3.2 Calculating Error Likelihood,[0],[0]
"i
)(n j i ))
",3.2 Calculating Error Likelihood,[0],[0]
"(4) Intuitively, this formula means that the node that will be explored first is the node that will yield a parse that scores as close to the greedy choice as possible.",3.2 Calculating Error Likelihood,[0],[0]
"The first term ensures that it has a history of good choices, and the second term ensures that the new child node being explored will be nearly as good as the prior child.",3.2 Calculating Error Likelihood,[0],[0]
"As discussed earlier, we use number of predictions made by the model as a proxy for the speed; execution speed may vary based on system and algorithmic implementation, but prediction count gives a good estimate of the overall work done by the algorithm.
",3.3 Number of Predictions,[0],[0]
"Consider a sentence of length l, which requires at most 2l transitions with the greedy decoder (Nivre, 2004).",3.3 Number of Predictions,[0],[0]
"The number of predictions required for heuristic backtracking for b leaves is guaranteed to be less than or equal to a beam search with b beams.
",3.3 Number of Predictions,[0],[0]
"When doing a beam search, the first transition will require 1 prediction, and then every subsequent transition will require 1 prediction per beam, or b predictions.",3.3 Number of Predictions,[0],[0]
This results in a total of b(2l,3.3 Number of Predictions,[0],[0]
"− 1) + 1 predictions.
",3.3 Number of Predictions,[0],[0]
"When doing heuristic backtracking, the first greedy search will require 2l predictions.",3.3 Number of Predictions,[0],[0]
"Every
subsequent prediction will require a number of predictions dependent on the target of the backtrack: backtracking to nji will require 2l − (i + 1) predictions.",3.3 Number of Predictions,[0],[0]
Note that 0,3.3 Number of Predictions,[0],[0]
<,3.3 Number of Predictions,[0],[0]
i < 2l.,3.3 Number of Predictions,[0],[0]
"Thus, each backtrack will require at maximum 2l − 1 predictions.",3.3 Number of Predictions,[0],[0]
"Therefore, the maximum total amount of predictions is 2l + (b− 1)(2l",3.3 Number of Predictions,[0],[0]
"− 1) = b(2l − 1) + 1.
",3.3 Number of Predictions,[0],[0]
"However, note that on average, there are significantly fewer.",3.3 Number of Predictions,[0],[0]
"Assuming that all parts of a sentence have approximately equal score distributions, the average backtrack will be where i = l, and reduce predictions by 50%.
",3.3 Number of Predictions,[0],[0]
An intuitive understanding of this difference can be gained by viewing the graphs of various decoding methods in Figure 1.,3.3 Number of Predictions,[0],[0]
"Beam search has many nodes which never yield children that reach an end-state; dynamic beam search has fewer, but still several.",3.3 Number of Predictions,[0],[0]
"Selectional branching has none, but suffers from the restriction that every parse candidate can be no more than one decision away from the greedy parse.",3.3 Number of Predictions,[0],[0]
"With heuristic backtracking, there is no such restriction, but yet every node explored is directly useful for generating a candidate parse.",3.3 Number of Predictions,[0],[0]
Another inefficiency inherent to beam search is the fact that all b beams are always fully explored.,3.4 Early Cutoff,[0],[0]
"Since the beams are calculated in parallel, this is inevitable.",3.4 Early Cutoff,[0],[0]
"However, with heuristic backtracking, the beams are calculated incrementally; this gives us the opportunity to cut off our search at any point.",3.4 Early Cutoff,[0],[0]
"In order to leverage this into more efficient parsing, we constructed a second Stack-LSTM model, which we call the cutoff model.",3.4 Early Cutoff,[0],[0]
"The cutoff model uses a single Stack-LSTM2 that takes as input the sequence of parser states (see Eq 1), and outputs a boolean variable predicting whether the entire parse is correct or incorrect.
",3.4 Early Cutoff,[0],[0]
"To train the cutoff model, we used stochastic gradient descent over the training set.",3.4 Early Cutoff,[0],[0]
"For each training example, we first parse it greedily using the StackLSTM parser.",3.4 Early Cutoff,[0],[0]
"Then, for as long as the parse has at least one mistake, we pass it to the cutoff model as a negative training example.",3.4 Early Cutoff,[0],[0]
"Once the parse is completely correct, we pass it to the cutoff model as a positive training example.",3.4 Early Cutoff,[0],[0]
"The loss function that we
22 layers and 300 dimensions.
use is:
Lθ = − log p(t | s) (5)
where s is the LSTM encoded vector and t is the truth (parse correct/incorrect).
",3.4 Early Cutoff,[0],[0]
"When decoding using early cutoff, we follow the exact same procedure as for normal heuristic backtracking, but after every candidate parse is generated, we use it as input to our cutoff model.",3.4 Early Cutoff,[0],[0]
"When our cutoff model returns our selection as correct, we stop backtracking and return it as the answer.",3.4 Early Cutoff,[0],[0]
"If we make b attempts without finding a correct parse, we follow the same procedure as before.",3.4 Early Cutoff,[0],[0]
"To test the effectiveness of heuristic backtracking, we compare it with other decoding techniques: greedy, beam search,3, dynamic beam search (Mejia-Lavalle and Ramos, 2013), and selectional branching (Choi and McCallum, 2013).",4 Experiments and Results,[0],[0]
"We then try heuristic backtracking (see Section 3.1), and heuristic backtracking with cutoff (see Section 3.4).",4 Experiments and Results,[0],[0]
"Note that beam search was not used for early-update training (Collins and Roark, 2004).",4 Experiments and Results,[0],[0]
"We use the same greedy training strategy for all models, and we only change the decoding strategy.
",4 Experiments and Results,[0],[0]
We tested the performance of these algorithms on the English SD and Chinese CTB.4,4 Experiments and Results,[0],[0]
"A single model was trained using the techniques described in Section 2, and used as the transition model for all decoding algorithms.",4 Experiments and Results,[0],[0]
"Each decoding technique was tested with varying numbers of beams; as b increased, both the predictions per sentence and accuracy trended upwards.",4 Experiments and Results,[0],[0]
"The results are summarized in Table 1.5 Note that we report results for only the highestaccuracy b (in the development set) for each.
",4 Experiments and Results,[0],[0]
We also report the results of the cutoff model in Table 2.,4 Experiments and Results,[0],[0]
"The same greedily-trained model as above was used to generate candidate parses and confidence estimates for each transition, and then the cutoff model was trained to use these confidence esti-
3Greedy and beam-search were already explored by Dyer et al. (2015)
4Using the exact same settings as Dyer et al. (2015) with pretrained embeddings and part-of-speech tags.
",4 Experiments and Results,[0],[0]
"5The development sets are used to set the model parameters; results on the development sets are similar to the ones obtained in the test sets.
",4 Experiments and Results,[0],[0]
mates to discriminate between correctly-parsed and incorrectly-parsed sentences.,4 Experiments and Results,[0],[0]
"In Table 1 we see that in both English and Chinese, the best heuristic backtracking performs approximately as well as the best beam search, while making less than half the predictions.",5 Discussion,[0],[0]
"This supports our hypothesis that heuristic backtracking can perform at the same level as beam search, but with increased efficiency.
",5 Discussion,[0],[0]
"Dynamic beam search also performed as well as full beam search, despite demonstrating a reduction in predictions on par with that of heuristic backtracking.",5 Discussion,[0],[0]
"Since the implementation of dynamic beam search is very straightforward for systems which have already implemented beam search, we believe this will prove to be a useful finding.
",5 Discussion,[0],[0]
"Heuristic backtracking with cutoff outperformed greedy decoding, and reduced transitions by an additional 50%.",5 Discussion,[0],[0]
"However, it increased accuracy slightly less than full heuristic backtracking.",5 Discussion,[0],[0]
"We believe this difference could be mitigated with an improved cutoff model; as can be seen in Table 2, the cutoff model was only able to discriminate between correct and incorrect parses around 75% of the time.",5 Discussion,[0],[0]
"Also, note that while predictions per sentence were low, the overall runtime was increased due to running the cutoff LSTM multiple times per sentence.",5 Discussion,[0],[0]
"Heuristic backtracking is most similar to the work of Choi and McCallum (2013), but is distinguished from theirs by allowing new beams to be initialized from any point in the parse, rather than only from points in the initial greedy parse.",6 Related Work,[0],[0]
"Heuristic backtracking also bears similarity to greedy-best-firstsearch (Pearl, 1984), but is unique in that it guarantees that b candidate solutions will be found within b(2l",6 Related Work,[0],[0]
− 1) + 1 predictions.,6 Related Work,[0],[0]
"Our work also relates to beam-search parsers (Zhang and Clark, 2008, inter alia).",6 Related Work,[0],[0]
"We have introduced a novel decoding algorithm, called heuristic backtracking, and presented evidence that it performs at the same level as beam search for decoding, while being significantly more efficient.",7 Conclusions,[0],[0]
"We have demonstrated this for both English and Chinese, using a parser with strong results with a greedy decoder.",7 Conclusions,[0],[0]
"We expect that heuristic backtracking could be applied to any other transition-based parser with similar benefits.
",7 Conclusions,[0],[0]
"We plan on experimenting with various heuristics and cutoff models, such as adapting the attentionbased models of Bahdanau et al. (2014) to act as a guide for both the heuristic search and cutoff.",7 Conclusions,[0],[0]
Miguel Ballesteros was supported by the European Commission under the contract numbers FP7ICT-610411 (project MULTISENSOR) and H2020RIA-645012 (project KRISTINA).,Acknowledgments,[0],[0]
We introduce a novel approach to the decoding problem in transition-based parsing: heuristic backtracking.,abstractText,[0],[0]
"This algorithm uses a series of partial parses on the sentence to locate the best candidate parse, using confidence estimates of transition decisions as a heuristic to guide the starting points of the search.",abstractText,[0],[0]
"This allows us to achieve a parse accuracy comparable to beam search, despite using fewer transitions.",abstractText,[0],[0]
"When used to augment a Stack-LSTM transition-based parser, the parser shows an unlabeled attachment score of up to 93.30% for English and 87.61% for Chinese.",abstractText,[0],[0]
Transition-Based Dependency Parsing with Heuristic Backtracking,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 232–242 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1022
Several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel. While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge. Here we propose to interpret agents’ messages by translating them. Unlike in typical machine translation problems, we have no parallel data to learn from. Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener. We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmatics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language.1",text,[0],[0]
Several recent papers have described approaches for learning deep communicating policies (DCPs): decentralized representations of behavior that enable multiple agents to communicate via a differentiable channel that can be formulated as a recurrent neural network.,1 Introduction,[0],[0]
"DCPs have been shown to solve a variety of coordination problems, including reference games (Lazaridou et al., 2016b), logic puzzles (Foerster et al., 2016), and simple control (Sukhbaatar et al., 2016).",1 Introduction,[0],[0]
"Appealingly, the agents’ communication protocol can be learned via direct
1 We have released code and data at http://github.",1 Introduction,[0],[0]
"com/jacobandreas/neuralese.
",1 Introduction,[0],[0]
"backpropagation through the communication channel, avoiding many of the challenging inference problems associated with learning in classical decentralized decision processes (Roth et al., 2005).
",1 Introduction,[0],[0]
But analysis of the strategies induced by DCPs has remained a challenge.,1 Introduction,[0],[0]
"As an example, Figure 1 depicts a driving game in which two cars, which are unable to see each other, must both cross an intersection without colliding.",1 Introduction,[0],[0]
"In order to ensure success, it is clear that the cars must communicate with each other.",1 Introduction,[0],[0]
"But a number of successful communication strategies are possible—for example, they might report their exact (x, y) coordinates at every timestep, or they might simply announce whenever they are entering and leaving the intersection.",1 Introduction,[0],[0]
"If these messages were communicated in natural language, it would be straightforward to determine which strategy was being employed.",1 Introduction,[0],[0]
"However, DCP agents instead communicate with an automatically induced protocol of unstructured, real-valued recurrent state vectors—an artificial language we might call “neuralese,” which superficially bears little resemblance to natural language, and thus frustrates attempts at direct interpretation.
232
We propose to understand neuralese messages by translating them.",1 Introduction,[0],[0]
"In this work, we present a simple technique for inducing a dictionary that maps between neuralese message vectors and short natural language strings, given only examples of DCP agents interacting with other agents, and humans interacting with other humans.",1 Introduction,[0],[0]
"Natural language already provides a rich set of tools for describing beliefs, observations, and plans—our thesis is that these tools provide a useful complement to the visualization and ablation techniques used in previous work on understanding complex models (Strobelt et al., 2016; Ribeiro et al., 2016).
",1 Introduction,[0],[0]
"While structurally quite similar to the task of machine translation between pairs of human languages, interpretation of neuralese poses a number of novel challenges.",1 Introduction,[0],[0]
"First, there is no natural source of parallel data: there are no bilingual “speakers” of both neuralese and natural language.",1 Introduction,[0],[0]
"Second, there may not be a direct correspondence between the strategy employed by humans and DCP agents: even if it were constrained to communicate using natural language, an automated agent might choose to produce a different message from humans in a given state.",1 Introduction,[0],[0]
We tackle both of these challenges by appealing to the grounding of messages in gameplay.,1 Introduction,[0],[0]
"Our approach is based on one of the core insights in natural language semantics: messages (whether in neuralese or natural language) have similar meanings when they induce similar beliefs about the state of the world.
",1 Introduction,[0],[0]
"Based on this intuition, we introduce a translation criterion that matches neuralese messages with natural language strings by minimizing statistical distance in a common representation space of distributions over speaker states.",1 Introduction,[0],[0]
"We explore several related questions:
•",1 Introduction,[0],[0]
"What makes a good translation, and under what conditions is translation possible at all?",1 Introduction,[0],[0]
"(Section 4)
",1 Introduction,[0],[0]
• How can we build a model to translate between neuralese and natural language?,1 Introduction,[0],[0]
"(Section 5)
•",1 Introduction,[0],[0]
What kinds of theoretical guarantees can we provide about the behavior of agents communicating via this translation model?,1 Introduction,[0],[0]
"(Section 6)
",1 Introduction,[0],[0]
"Our translation model and analysis are general, and in fact apply equally to human–computer and
human–human translation problems grounded in gameplay.",1 Introduction,[0],[0]
"In this paper, we focus our experiments specifically on the problem of interpreting communication in deep policies, and apply our approach to the driving game in Figure 1 and two reference games of the kind shown in Figure 2.",1 Introduction,[0],[0]
We find that this approach outperforms a more conventional machine translation criterion both when attempting to interoperate with neuralese speakers and when predicting their state.,1 Introduction,[0],[0]
A variety of approaches for learning deep policies with communication were proposed essentially simultaneously in the past year.,2 Related work,[0],[0]
"We have broadly labeled these as “deep communicating policies”; concrete examples include Lazaridou et al. (2016b), Foerster et al. (2016), and Sukhbaatar et al. (2016).",2 Related work,[0],[0]
"The policy representation we employ in this paper is similar to the latter two of these, although the general framework is agnostic to low-level modeling details and could be straightforwardly applied to other architectures.",2 Related work,[0],[0]
"Analysis of communication strategies in all these papers has been largely adhoc, obtained by clustering states from which similar messages are emitted and attempting to manually assign semantics to these clusters.",2 Related work,[0],[0]
"The present work aims at developing tools for performing this analysis automatically.
",2 Related work,[0],[0]
"Most closely related to our approach is that of Lazaridou et al. (2016a), who also develop a model for assigning natural language interpretations to learned messages; however, this approach relies on supervised cluster labels and is targeted specifically towards referring expression games.",2 Related work,[0],[0]
"Here we attempt to develop an approach that can handle general multiagent interactions without assuming a prior discrete structure in space of observations.
",2 Related work,[0],[0]
"The literature on learning decentralized multiagent policies in general is considerably larger (Bernstein et al., 2002; Dibangoye et al., 2016).",2 Related work,[0],[0]
"This includes work focused on communication in multiagent settings (Roth et al., 2005) and even communication using natural language messages (Vogel et al., 2013b).",2 Related work,[0],[0]
"All of these approaches employ structured communication schemes with manually engineered messaging protocols; these are, in some sense, automatically interpretable, but at the cost of introducing considerable complexity into both training and inference.
",2 Related work,[0],[0]
"Our evaluation in this paper investigates communication strategies that arise in a number of different games, including reference games and an extended-horizon driving game.",2 Related work,[0],[0]
"Communication strategies for reference games were previously explored by Vogel et al. (2013a), Andreas and Klein (2016) and Kazemzadeh et al. (2014), and reference games specifically featuring end-to-end communication protocols by Yu et al. (2016).",2 Related work,[0],[0]
"On the control side, a long line of work considers nonverbal communication strategies in multiagent policies (Dragan and Srinivasa, 2013).
",2 Related work,[0],[0]
Another group of related approaches focuses on the development of more general machinery for interpreting deep models in which messages have no explicit semantics.,2 Related work,[0],[0]
"This includes both visualization techniques (Zeiler and Fergus, 2014; Strobelt et al., 2016), and approaches focused on generating explanations in the form of natural language (Hendricks et al., 2016; Vedantam et al., 2017).",2 Related work,[0],[0]
Games Consider a cooperative game with two players a and b of the form given in Figure 3.,3 Problem formulation,[0],[0]
"At every step t of this game, player a makes an observation x(t)a and receives a message z (t−1) b from b.",3 Problem formulation,[0],[0]
It then takes an action u(t)a and sends a message z (t) a to b.,3 Problem formulation,[0],[0]
(The process is symmetric for b.),3 Problem formulation,[0],[0]
"The distributions p(ua|xa, zb) and p(za|xa) together define a policy π which we assume is shared by both players, i.e. p(ua|xa, zb) = p(ub|xb, za) and p(za|xa) = p(zb|xb).",3 Problem formulation,[0],[0]
"As in a standard Markov decision process, the actions (u(t)a , u (t) b ) alter the world state, generating new observations for both players and a reward shared by both.
",3 Problem formulation,[0],[0]
"The distributions p(z|x) and p(u|x, z) may also be viewed as defining a language: they specify how a speaker will generate messages based on world states, and how a listener will respond to these mes-
sages.",3 Problem formulation,[0],[0]
Our goal in this work is to learn to translate between pairs of languages generated by different policies.,3 Problem formulation,[0],[0]
"Specifically, we assume that we have access to two policies for the same game: a “robot policy” πr and a “human policy” πh.",3 Problem formulation,[0],[0]
"We would like to use the representation of πh, the behavior of which is transparent to human users, in order to understand the behavior of πr (which is in general an uninterpretable learned model); we will do this by inducing bilingual dictionaries that map message vectors zr of πr to natural language strings zh of πh and vice-versa.
",3 Problem formulation,[0],[0]
Learned agents πr,3 Problem formulation,[0],[0]
Our goal is to present tools for interpretation of learned messages that are agnostic to the details of the underlying algorithm for acquiring them.,3 Problem formulation,[0],[0]
We use a generic DCP model as a basis for the techniques developed in this paper.,3 Problem formulation,[0],[0]
"Here each agent policy is represented as a deep recurrent Q network (Hausknecht and Stone, 2015).",3 Problem formulation,[0],[0]
This network is built from communicating cells of the kind depicted in Figure 4.,3 Problem formulation,[0],[0]
"At every timestep, this agent receives three pieces of information: an
observation of the current state of the world, the agent’s memory vector from the previous timestep, and a message from the other player.",3 Problem formulation,[0],[0]
"It then produces three outputs: a predicted Q value for every possible action, a new memory vector for the next timestep, and a message to send to the other agent.
",3 Problem formulation,[0],[0]
Sukhbaatar et al. (2016) observe that models of this form may be viewed as specifying a single RNN in which weight matrices have a particular block structure.,3 Problem formulation,[0],[0]
"Such models may thus be trained using the standard recurrent Q-learning objective, with communication protocol learned end-to-end.
",3 Problem formulation,[0],[0]
Human agents πh The translation model we develop requires a representation of the distribution over messages p(za|xa) employed by human speakers (without assuming that humans and agents produce equivalent messages in equivalent contexts).,3 Problem formulation,[0],[0]
"We model the human message generation process as categorical, and fit a simple multilayer perceptron model to map from observations to words and phrases used during human gameplay.",3 Problem formulation,[0],[0]
What does it mean for a message zh to be a “translation” of a message zr?,4 What’s in a translation?,[0],[0]
"In standard machine translation problems, the answer is that zh is likely to co-occur in parallel data with zr; that is, p(zh|zr) is large.",4 What’s in a translation?,[0],[0]
"Here we have no parallel data: even if we could observe natural language and neuralese messages produced by agents in the same state, we would have no guarantee that these messages actually served the same function.",4 What’s in a translation?,[0],[0]
Our answer must instead appeal to the fact that both natural language and neuralese messages are grounded in a common environment.,4 What’s in a translation?,[0],[0]
"For a given neuralese message zr, we will first compute a grounded representation of that message’s meaning; to translate, we find a natural-language message whose meaning is most similar.",4 What’s in a translation?,[0],[0]
The key question is then what form this grounded meaning representation should take.,4 What’s in a translation?,[0],[0]
"The existing literature suggests two broad approaches:
Semantic representation The meaning of a message za is given by its denotations: that is, by the set of world states of which za may be felicitously predicated, given the existing context available to a listener.",4 What’s in a translation?,[0],[0]
"In probabilistic terms, this says that the meaning of a message za is represented by the distribution p(xa|za, xb) it induces over speaker states.",4 What’s in a translation?,[0],[0]
"Examples of this approach include Guerin and Pitt (2001) and Pasupat and Liang (2016).
",4 What’s in a translation?,[0],[0]
Pragmatic representation,4 What’s in a translation?,[0],[0]
The meaning of a message za is given by the behavior it induces in a listener.,4 What’s in a translation?,[0],[0]
"In probabilistic terms, this says that the meaning of a message za is represented by the distribution p(ub|za, xb) it induces over actions given the listener’s observation xb.",4 What’s in a translation?,[0],[0]
"Examples of this approach include Vogel et al. (2013a) and Gauthier and Mordatch (2016).
",4 What’s in a translation?,[0],[0]
These two approaches can give rise to rather different behaviors.,4 What’s in a translation?,[0],[0]
"Consider the following example:
square hexagon circle
few many many
The top language (in blue) has a unique name for every kind of shape, while the bottom language (in red) only distinguishes between shapes with few sides and shapes with many sides.",4 What’s in a translation?,[0],[0]
"Now imagine a simple reference game with the following form: player a is covertly assigned one of these three shapes as a reference target, and communicates that reference to b; b must then pull a lever labeled large or small depending on the size of the target shape.",4 What’s in a translation?,[0],[0]
"Blue language speakers can achieve perfect success at this game, while red language speakers can succeed at best two out of three times.
",4 What’s in a translation?,[0],[0]
How should we translate the blue word hexagon into the red language?,4 What’s in a translation?,[0],[0]
"The semantic approach suggests that we should translate hexagon as many: while many does not uniquely identify the hexagon, it produces a distribution over shapes that is closest to the truth.",4 What’s in a translation?,[0],[0]
"The pragmatic approach instead suggests that we should translate hexagon as few, as this is the only message that guarantees that the listener will pull the correct lever large.",4 What’s in a translation?,[0],[0]
"So in order to produce a correct listener action, the translator might have to “lie” and produce a maximally inaccurate listener belief.
",4 What’s in a translation?,[0],[0]
"If we were exclusively concerned with building a translation layer that allowed humans and DCP agents to interoperate as effectively as possible, it would be natural to adopt a pragmatic representation strategy.",4 What’s in a translation?,[0],[0]
"But our goals here are broader: we also want to facilitate understanding, and specifically to help users of learned systems form true beliefs about the systems’ computational processes and representational abstractions.",4 What’s in a translation?,[0],[0]
"The example above demonstrates that “pragmatically” optimizing directly for task performance can sometimes lead to translations that produce inaccurate beliefs.
",4 What’s in a translation?,[0],[0]
We instead build our approach around semantic representations of meaning.,4 What’s in a translation?,[0],[0]
"By preserving semantics, we allow listeners to reason accurately about the content and interpretation of messages.",4 What’s in a translation?,[0],[0]
"We might worry that by adopting a semantics-first view, we have given up all guarantees of effective interoperation between humans and agents using a translation layer.",4 What’s in a translation?,[0],[0]
"Fortunately, this is not so: as we will see in Section 6, it is possible to show that players communicating via a semantic translator perform only boundedly worse (and sometimes better!)",4 What’s in a translation?,[0],[0]
than pairs of players with a common language.,4 What’s in a translation?,[0],[0]
"In this section, we build on the intuition that messages should be translated via their semantics to define a concrete translation model—a procedure for constructing a natural language ↔ neuralese dictionary given agent and human interactions.
",5 Translation models,[0],[0]
"We understand the meaning of a message za to be represented by the distribution p(xa|za, xb) it induces over speaker states given listener context.",5 Translation models,[0],[0]
"We can formalize this by defining the belief distribution β for a message z and context xb as:
β(za, xb) = p(xa|za, xb) = p(za|xa)p(xb|xa)∑ x′a p(za|x′a)p(xb|x′a)
",5 Translation models,[0],[0]
"Here we have modeled the listener as performing a single step of Bayesian inference, using the listener state and the message generation model (by assumption shared between players) to compute the posterior over speaker states.",5 Translation models,[0],[0]
"While in general neither humans nor DCP agents compute explicit representations of this posterior, past work has found that both humans and suitably-trained neural networks can be modeled as Bayesian reasoners (Frank et al., 2009; Paige and Wood, 2016).
",5 Translation models,[0],[0]
"This provides a context-specific representation of belief, but for messages z and z′ to have the same semantics, they must induce the same belief over all contexts in which they occur.",5 Translation models,[0],[0]
"In our probabilistic formulation, this introduces an outer expectation over contexts, providing a final measure q of the quality of a translation from z to z′:
q(z, z′) =",5 Translation models,[0],[0]
E,5 Translation models,[0],[0]
"[ DKL(β(z,Xb) || β(z′, Xb))",5 Translation models,[0],[0]
"| z, z′ ]
= ∑
xa,xb
p(xa, xb|z, z′)DKL(β(z, xb) || β(z′, xb))
∝",5 Translation models,[0],[0]
"∑
xa,xb p(xa, xb) · p(z|xa) · p(z′|xa) ·",5 Translation models,[0],[0]
"DKL(β(z, xb) || β(z′, xb));",5 Translation models,[0],[0]
"(1)
Algorithm 1 Translating messages
given: a phrase inventory L function TRANSLATE(z)
return argminz′∈L q̂(z, z′)
function q̂(z, z′) // sample contexts and distractors xai, xbi ∼ p(Xa, Xb) for i = 1..n",5 Translation models,[0],[0]
x′ai ∼ p(Xa|xbi) //,5 Translation models,[0],[0]
compute context weights w̃i ← p(z|xai) ·,5 Translation models,[0],[0]
p(z′|xai),5 Translation models,[0],[0]
"wi ← w̃i/ ∑ j w̃j
// compute divergences ki ← ∑ x∈{xa,x′a} p(z|x) log p(z|x) p(z′|x)
return ∑
iwiki
recalling that in this setting
DKL(β || β′)",5 Translation models,[0],[0]
"= ∑
xa
p(xa|z, xb) log p(xa|z, xb) p(xa|z′, xb)
∝",5 Translation models,[0],[0]
"∑
xa
p(xa|xb)p(z|xa) log p(z|xa) p(z′|xa)
(2)
which is zero when the messages z and z′ give rise to identical belief distributions and increases as they grow more dissimilar.",5 Translation models,[0],[0]
"To translate, we would like to compute tr(zr) = argminzh q(zr, zh) and tr(zh) = argminzr q(zh, zr).",5 Translation models,[0],[0]
"Intuitively, Equation 1 says that we will measure the quality of a proposed translation z 7→ z′ by asking the following question: in contexts where z is likely to be used, how frequently does z′ induce the same belief about speaker states as z?
While this translation criterion directly encodes the semantic notion of meaning described in Section 4, it is doubly intractable: the KL divergence and outer expectation involve a sum over all observations xa and xb respectively; these sums are not in general possible to compute efficiently.",5 Translation models,[0],[0]
"To avoid this, we approximate Equation 1 by sampling.",5 Translation models,[0],[0]
"We draw a collection of samples (xa, xb) from the prior over world states, and then generate for each sample a sequence of distractors (x′a, xb) from p(x ′ a|xb)",5 Translation models,[0],[0]
(we assume access to both of these distributions from the problem representation).,5 Translation models,[0],[0]
"The KL term in Equation 1 is computed over each true sample and its distractors, which are then normalized and averaged to compute the final score.
",5 Translation models,[0],[0]
"Sampling accounts for the outer p(xa, xb) in Equation 1 and the inner p(xa|xb) in Equation 2.
",5 Translation models,[0],[0]
The only quantities remaining are of the form p(z|xa).,5 Translation models,[0],[0]
"In the case of neuralese, this distribution already is part of the definition of the agent policy πr and can be reused directly.",5 Translation models,[0],[0]
"For natural language, we use transcripts of human interactions to fit a model that maps from world states to a distribution over frequent utterances as discussed in Section 3.",5 Translation models,[0],[0]
"Details of these model implementations are provided in Appendix B, and the full translation procedure is given in Algorithm 1.",5 Translation models,[0],[0]
The translation criterion in the previous section makes no reference to listener actions at all.,6 Belief and behavior,[0],[0]
The shapes example in Section 4 shows that some model performance might be lost under translation.,6 Belief and behavior,[0],[0]
It is thus reasonable to ask whether this translation model of Section 5 can make any guarantees about the effect of translation on behavior.,6 Belief and behavior,[0],[0]
"In this section we explore the relationship between beliefpreserving translations and the behaviors they produce, by examining the effect of belief accuracy and strategy mismatch on the reward obtained by cooperating agents.
",6 Belief and behavior,[0],[0]
"To facilitate this analysis, we consider a simplified family of communication games with the structure depicted in Figure 5.",6 Belief and behavior,[0],[0]
"These games can be viewed as a subset of the family depicted in Figure 3; and consist of two steps: a listener makes an observation xa and sends a single message z to a speaker, which makes its own observation xb, takes a single action u, and receives a reward.",6 Belief and behavior,[0],[0]
"We emphasize that the results in this section concern the theoretical properties of idealized games, and are presented to provide intuition about high-level properties of our approach.",6 Belief and behavior,[0],[0]
"Section 8 investigates empirical behavior of this approach on real-world tasks where these ideal conditions do not hold.
",6 Belief and behavior,[0],[0]
"Our first result is that translations that minimize semantic dissimilarity q cause the listener to take near-optimal actions:2
2Proof is provided in Appendix A.
Proposition 1.",6 Belief and behavior,[0],[0]
Semantic translations reward rational listeners.,6 Belief and behavior,[0],[0]
"Define a rational listener as one that chooses the best action in expectation over the speaker’s state:
U(z, xb) = argmax u
∑
xa
p(xa|xb, z)r(xa, xb, u)
for a reward function r ∈",6 Belief and behavior,[0],[0]
"[0, 1] that depends only on the two observations and the action.3 Now let a be a speaker of a language r, b be a listener of the same language r, and b′ be a listener of a different language h.",6 Belief and behavior,[0],[0]
Suppose that we wish for a and b′ to interact via the translator tr :,6 Belief and behavior,[0],[0]
"zr 7→ zh (so that a produces a message zr, and b′ takes an action U(zh = tr(zr), xb′)).",6 Belief and behavior,[0],[0]
"If tr respects the semantics of zr, then the bilingual pair a and b′ achieves only boundedly worse reward than the monolingual pair a and",6 Belief and behavior,[0],[0]
"b. Specifically, if q(zr, zh) ≤ D, then
Er(Xa, Xb, U(tr(Z))
",6 Belief and behavior,[0],[0]
"≥ Er(Xa, Xb, U(Z))− √ 2D (3)
",6 Belief and behavior,[0],[0]
"So as discussed in Section 4, even by committing to a semantic approach to meaning representation, we have still succeeded in (approximately) capturing the nice properties of the pragmatic approach.
",6 Belief and behavior,[0],[0]
Section 4 examined the consequences of a mismatch between the set of primitives available in two languages.,6 Belief and behavior,[0],[0]
In general we would like some measure of our approach’s robustness to the lack of an exact correspondence between two languages.,6 Belief and behavior,[0],[0]
"In the case of humans in particular we expect that a variety of different strategies will be employed, many of which will not correspond to the behavior of the learned agent.",6 Belief and behavior,[0],[0]
It is natural to want some assurance that we can identify the DCP’s strategy as long as some human strategy mirrors it.,6 Belief and behavior,[0],[0]
"Our second observation is that it is possible to exactly recover a translation of a DCP strategy from a mixture of humans playing different strategies:
Proposition 2.",6 Belief and behavior,[0],[0]
Semantic translations find hidden correspondences.,6 Belief and behavior,[0],[0]
"Consider a fixed robot policy πr and a set of human policies {πh1 , πh2 , . . . }",6 Belief and behavior,[0],[0]
"(recalling from Section 3 that each π is defined by distributions
3This notion of rationality is a fairly weak one: it permits many suboptimal communication strategies, and requires only that the listener do as well as possible given a fixed speaker— a first-order optimality criterion likely to be satisfied by any richly-parameterized model trained via gradient descent.
",6 Belief and behavior,[0],[0]
"p(z |xa) and p(u |z , xb)).",6 Belief and behavior,[0],[0]
"Suppose further that the messages employed by these human strategies are disjoint; that is, if phi(z |xa)",6 Belief and behavior,[0],[0]
"> 0, then phj (z |xa) = 0 for all j 6=",6 Belief and behavior,[0],[0]
i.,6 Belief and behavior,[0],[0]
"Now suppose that all q(zr , zh) = 0 for all messages in the support of some phi(z |xa) and > 0 for all j 6=",6 Belief and behavior,[0],[0]
i.,6 Belief and behavior,[0],[0]
"Then every message zr is translated into a message produced by πhi , and messages from other strategies are ignored.
",6 Belief and behavior,[0],[0]
"This observation follows immediately from the definition of q(zr, zh), but demonstrates one of the key distinctions between our approach and a conventional machine translation criterion.",6 Belief and behavior,[0],[0]
"Maximizing p(zh|zr) will produce the natural language message most often produced in contexts where zr is observed, regardless of whether that message is useful or informative.",6 Belief and behavior,[0],[0]
"By contrast, minimizing q(zh, zr) will find the zh that corresponds most closely to zr even when zh is rarely used.
",6 Belief and behavior,[0],[0]
"The disjointness condition, while seemingly quite strong, in fact arises naturally in many circumstances—for example, players in the driving game reporting their spatial locations in absolute vs. relative coordinates, or speakers in a color reference game (Figure 6) discriminating based on lightness vs. hue.",6 Belief and behavior,[0],[0]
"It is also possible to relax the above condition to require that strategies be only locally disjoint (i.e. with the disjointness condition holding for each fixed xa), in which case overlapping human strategies are allowed, and the recovered robot strategy is a context-weighted mixture of these.",6 Belief and behavior,[0],[0]
"In the remainder of the paper, we evaluate the empirical behavior of our approach to translation.",7.1 Tasks,[0],[0]
Our evaluation considers two kinds of tasks: reference games and navigation games.,7.1 Tasks,[0],[0]
"In a reference game (e.g. Figure 6a), both players observe a pair of candidate referents.",7.1 Tasks,[0],[0]
"A speaker is assigned a target referent; it must communicate this target to a listener, who then performs a choice action corresponding to its belief about the true target.",7.1 Tasks,[0],[0]
"In this paper we consider two variants on the reference game: a simple color-naming task, and a more complex task involving natural images of birds.",7.1 Tasks,[0],[0]
"For examples of human communication strategies for these tasks, we obtain the XKCD color dataset (McMahan and Stone, 2015; Monroe et al., 2016) and the Caltech Birds dataset (Welinder et al., 2010) with accom-
panying natural language descriptions (Reed et al., 2016).",7.1 Tasks,[0],[0]
"We use standard train / validation / test splits for both of these datasets.
",7.1 Tasks,[0],[0]
The final task we consider is the driving task (Figure 6c) first discussed in the introduction.,7.1 Tasks,[0],[0]
"In this task, two cars, invisible to each other, must each navigate between randomly assigned start and goal positions without colliding.",7.1 Tasks,[0],[0]
"This task takes a number of steps to complete, and potentially involves a much broader range of communication strategies.",7.1 Tasks,[0],[0]
"To obtain human annotations for this task, we recorded both actions and messages generated by pairs of human Amazon Mechanical Turk workers playing the driving game with each other.",7.1 Tasks,[0],[0]
"We collected close to 400 games, with a total of more than 2000 messages exchanged, from which we held out 100 game traces as a test set.",7.1 Tasks,[0],[0]
"A mechanism for understanding the behavior of a learned model should allow a human user both to correctly infer its beliefs and to successfully interoperate with it; we accordingly report results of both “belief” and “behavior” evaluations.
",7.2 Metrics,[0],[0]
"To support easy reproduction and comparison (and in keeping with standard practice in machine
translation), we focus on developing automatic measures of system performance.",7.2 Metrics,[0],[0]
"We use the available training data to develop simulated models of human decisions; by first showing that these models track well with human judgments, we can be confident that their use in evaluations will correlate with human understanding.",7.2 Metrics,[0],[0]
"We employ the following two metrics:
Belief evaluation This evaluation focuses on the denotational perspective in semantics that motivated the initial development of our model.",7.2 Metrics,[0],[0]
We have successfully understood the semantics of a message,7.2 Metrics,[0],[0]
"zr if, after translating zr 7→ zh, a human listener can form a correct belief about the state in which zr was produced.",7.2 Metrics,[0],[0]
"We construct a simple state-guessing game where the listener is presented with a translated message and two state observations, and must guess which state the speaker was in when the message was emitted.
",7.2 Metrics,[0],[0]
"When translating from natural language to neuralese, we use the learned agent model to directly guess the hidden state.",7.2 Metrics,[0],[0]
"For neuralese to natural language we must first construct a “model human listener” to map from strings back to state representations; we do this by using the training data to fit a simple regression model that scores (state, sentence) pairs using a bag-of-words sentence representation.",7.2 Metrics,[0],[0]
"We find that our “model human” matches the judgments of real humans 83% of the time on the colors task, 77% of the time on the birds task, and 77% of the time on the driving task.",7.2 Metrics,[0],[0]
"This gives us confidence that the model human gives a reasonably accurate proxy for human interpretation.
",7.2 Metrics,[0],[0]
Behavior evaluation This evaluation focuses on the cooperative aspects of interpretability: we measure the extent to which learned models are able to interoperate with each other by way of a translation layer.,7.2 Metrics,[0],[0]
"In the case of reference games, the goal of this semantic evaluation is identical to the goal of the game itself (to identify the hidden state of the speaker), so we perform this additional pragmatic evaluation only for the driving game.",7.2 Metrics,[0],[0]
We found that the most data-efficient and reliable way to make use of human game traces was to construct a “deaf” model human.,7.2 Metrics,[0],[0]
"The evaluation selects a full game trace from a human player, and replays both the human’s actions and messages exactly (disregarding any incoming messages); the evaluation measures the quality of the natural-language-toneuralese translator, and the extent to which the
learned agent model can accommodate a (real) human given translations of the human’s messages.
",7.2 Metrics,[0],[0]
"Baselines We compare our approach to two baselines: a random baseline that chooses a translation of each input uniformly from messages observed during training, and a direct baseline that directly maximizes p(z′|z) (by analogy to a conventional machine translation system).",7.2 Metrics,[0],[0]
This is accomplished by sampling from a DCP speaker in training states labeled with natural language strings.,7.2 Metrics,[0],[0]
"In all below, “R” indicates a DCP agent, “H” indicates a real human, and “H*” indicates a model human player.
",8 Results,[0],[0]
Reference games Results for the two reference games are shown in Table 1.,8 Results,[0],[0]
"The end-to-end trained model achieves nearly perfect accuracy in both
cases, while a model trained to communicate in natural language achieves somewhat lower performance.",8 Results,[0],[0]
"Regardless of whether the speaker is a DCP and the listener a model human or vice-versa, translation based on the belief-matching criterion in Section 5 achieves the best performance; indeed, when translating neuralese color names to natural language, the listener is able to achieve a slightly higher score than it is natively.",8 Results,[0],[0]
"This suggests that the automated agent has discovered a more effective strategy than the one demonstrated by humans in the dataset, and that the effectiveness of this strategy is preserved by translation.",8 Results,[0],[0]
"Example translations from the reference games are depicted in Figure 2 and Figure 7.
",8 Results,[0],[0]
"Driving game Behavior evaluation of the driving game is shown in Table 3, and belief evaluation is shown in Table 2.",8 Results,[0],[0]
"Translation of messages in the driving game is considerably more challenging than in the reference games, and scores are uniformly lower; however, a clear benefit from the beliefmatching model is still visible.",8 Results,[0],[0]
"Belief matching leads to higher scores on the belief evaluation in both directions, and allows agents to obtain a higher reward on average (though task completion rates remain roughly the same across all agents).",8 Results,[0],[0]
Some example translations of driving game messages are shown in Figure 8.,8 Results,[0],[0]
We have investigated the problem of interpreting message vectors from deep networks by translating them.,9 Conclusion,[0],[0]
"After introducing a translation criterion based on matching listener beliefs about speaker states, we presented both theoretical and empirical evidence that this criterion outperforms a conventional machine translation approach at recovering the content of message vectors and facilitating collaboration between humans and learned agents.
",9 Conclusion,[0],[0]
"While our evaluation has focused on understanding the behavior of deep communicating policies, the framework proposed in this paper could be much more generally applied.",9 Conclusion,[0],[0]
"Any encoder– decoder model (Sutskever et al., 2014) can be thought of as a kind of communication game played between the encoder and the decoder, so we can analogously imagine computing and translating “beliefs” induced by the encoding to explain what features of the input are being transmitted.",9 Conclusion,[0],[0]
"The current work has focused on learning a purely categorical model of the translation process, supported by an unstructured inventory of translation candidates, and future work could explore the compositional structure of messages, and attempt to synthesize novel natural language or neuralese messages from scratch.",9 Conclusion,[0],[0]
"More broadly, the work here shows that the denotational perspective from formal semantics provides a framework for precisely framing the demands of interpretable machine learning (Wilson et al., 2016), and particularly for ensuring that human users without prior exposure to a learned model are able to interoperate with it, predict its behavior, and diagnose its errors.",9 Conclusion,[0],[0]
JA is supported by a Facebook Graduate Fellowship and a Berkeley AI / Huawei Fellowship.,Acknowledgments,[0],[0]
We are grateful to Lisa Anne Hendricks for assistance with the Caltech Birds dataset.,Acknowledgments,[0],[0]
Several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel.,abstractText,[0],[0]
"While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge.",abstractText,[0],[0]
Here we propose to interpret agents’ messages by translating them.,abstractText,[0],[0]
"Unlike in typical machine translation problems, we have no parallel data to learn from.",abstractText,[0],[0]
Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener.,abstractText,[0],[0]
We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmatics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language.1,abstractText,[0],[0]
Translating Neuralese,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 56–65 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
56",text,[0],[0]
"In recent years, Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2014) has achieved remarkable performance on many translation tasks (Jean et al., 2015; Sennrich et al., 2016; Wu et al., 2016; Sennrich et al., 2017).",1 Introduction,[0],[0]
"Being an end-to-end architecture, an NMT system first encodes the input sentence into a sequence of real vectors, based on which the decoder generates the target sequence word by word with the attention mechanism (Bahdanau et al., 2014; Luong et al., 2015).",1 Introduction,[0],[0]
"During training, NMT systems are optimized to maximize the translation probability of a given language pair
∗Contribution during internship at MSRA.
with the Maximum Likelihood Estimation (MLE) method, which requires large bilingual data to fit the large parameter space.",1 Introduction,[0],[0]
"Without adequate data, which is common especially when it comes to a rare language, NMT usually falls short on low-resource language pairs (Zoph et al., 2016).
",1 Introduction,[0],[0]
"In order to deal with the data sparsity problem for NMT, exploiting monolingual data (Sennrich et al., 2015; Zhang and Zong, 2016; Cheng et al., 2016; Zhang et al., 2018; He et al., 2016) is the most common method.",1 Introduction,[0],[0]
"With monolingual data, the back-translation method (Sennrich et al., 2015) generates pseudo bilingual sentences with a targetto-source translation model to train the source-totarget one.",1 Introduction,[0],[0]
"By extending back-translation, sourceto-target and target-to-source translation models can be jointly trained and boost each other (Cheng et al., 2016; Zhang et al., 2018).",1 Introduction,[0],[0]
"Similar to joint training (Cheng et al., 2016; Zhang et al., 2018), dual learning (He et al., 2016) designs a reinforcement learning framework to better capitalize on monolingual data and jointly train two models.
",1 Introduction,[0],[0]
"Instead of leveraging monolingual data (X or Z) to enrich the low-resource bilingual pair (X,Z), in this paper, we are motivated to introduce another rich language Y , by which additionally acquired bilingual data (Y,Z) and (X,Y ) can be exploited to improve the translation performance of (X,Z).",1 Introduction,[0],[0]
"This requirement is easy to satisfy, especially when Z is a rare language but X is not.",1 Introduction,[0],[0]
"Under this scenario, (X,Y ) can be a rich-resource pair and provide much bilingual data, while (Y,Z) would also be a low-resource pair mostly because Z is rare.",1 Introduction,[0],[0]
"For example, in the dataset IWSLT2012, there are only 112.6K bilingual sentence pairs of English-Hebrew, since Hebrew is a rare language.",1 Introduction,[0],[0]
"If French is introduced as the third language, we can have another lowresource bilingual data of French-Hebrew (116.3K sentence pairs), and easily-acquired bilingual data
of the rich-resource pair English-French.
",1 Introduction,[0],[0]
"With the introduced rich language Y , in this paper, we propose a novel triangular architecture (TA-NMT) to exploit the additional bilingual data of (Y, Z) and (X,Y ), in order to get better translation performance on the low-resource pair (X,Z), as shown in Figure 1.",1 Introduction,[0],[0]
"In this architecture, (Y,Z) is used for training another translation model to score the translation model of (X,Z), while (X,Y ) is used to provide large bilingual data with favorable alignment information.
",1 Introduction,[0],[0]
"Under the motivation to exploit the richresource pair (X,Y ), instead of modeling X ⇒ Z directly, our method starts from modeling the translation task X ⇒ Y while taking Z as a latent variable.",1 Introduction,[0],[0]
"Then, we decompose X ⇒ Y into two phases for training two translation models of low-resource pairs ((X,Z) and (Y,Z)) respectively.",1 Introduction,[0],[0]
"The first translation model generates a sequence in the hidden space of Z from X , based on which the second one generates the translation in Y .",1 Introduction,[0],[0]
These two models can be optimized jointly with an Expectation Maximization (EM) framework with the goal of maximizing the translation probability p(y|x).,1 Introduction,[0],[0]
"In this framework, the two models can boost each other by generating pseudo bilingual data for model training with the weights scored from the other.",1 Introduction,[0],[0]
"By reversing the translation direction of X ⇒ Y , our method can be used to train another two translation models p(z|y) and p(x|z).",1 Introduction,[0],[0]
"Therefore, the four translation models (p(z|x), p(x|z), p(z|y) and p(y|z)) of the rare language Z can be optimized jointly with our proposed unified bidirectional EM algorithm.
",1 Introduction,[0],[0]
Experimental results on the MultiUN and IWSLT2012 datasets demonstrate that our method can achieve significant improvements for rare languages translation.,1 Introduction,[0],[0]
"By incorporating backtranslation (a method leveraging more monolingual data) into our method, TA-NMT can achieve even further improvements.
",1 Introduction,[0],[0]
"Our contributions are listed as follows:
• We propose a novel triangular training architecture (TA-NMT) to effectively tackle the data sparsity problem for rare languages in NMT with an EM framework.
",1 Introduction,[0],[0]
"• Our method can exploit two additional bilingual datasets at both the model and data levels by introducing another rich language.
",1 Introduction,[0],[0]
"• Our method is a unified bidirectional EM algorithm, in which four translation models on two low-resource pairs are trained jointly and boost each other.",1 Introduction,[0],[0]
"As shown in Figure 1, our method tries to leverage (X,Y ) (a rich-resource pair) and (Y, Z) to improve the translation performance of low-resource pair (X,Z), during which translation models of (X,Z) and (Y, Z) can be improved jointly.
",2 Method,[0],[0]
"Instead of directly modeling the translation probabilities of low-resource pairs, we model the rich-resource pair translation X ⇒ Y , with the language Z acting as a bridge to connect X and Y .",2 Method,[0],[0]
We decompose X ⇒ Y into two phases for training two translation models.,2 Method,[0],[0]
"The first model p(z|x) generates the latent translation in Z from the input sentence in X , based on which the second one p(y|z) generate the final translation in language Y .",2 Method,[0],[0]
"Following the standard EM procedure (Borman, 2004) and Jensen’s inequality, we derive the lower bound of p(y|x) over the whole training data D as follows:
L(Θ;D) =",2 Method,[0],[0]
"∑
(x,y)∈D
log p(y|x)
= ∑
(x,y)∈D
log ∑ z p(z|x)p(y|z)
= ∑
(x,y)∈D
log ∑ z Q(z) p(z|x)p(y|z) Q(z)
≥ ∑
(x,y)∈D
∑ z Q(z) log p(z|x)p(y|z) Q(z)
.",2 Method,[0],[0]
"= L(Q)
(1)
where Θ is the model parameters set of p(z|x) and p(y|z), and Q(z) is an arbitrary posterior distribution of z.",2 Method,[0],[0]
"We denote the lower-bound in the last
but one line as L(Q).",2 Method,[0],[0]
"Note that we use an approximation that p(y|x, z)",2 Method,[0],[0]
"≈ p(y|z) due to the semantic equivalence of parallel sentences x and y.
In the following subsections, we will first propose our EM method in subsection 2.1 based on the lower-bound derived above.",2 Method,[0],[0]
"Next, we will extend our method to two directions and give our unified bidirectional EM training in subsection 2.2.",2 Method,[0],[0]
"Then, in subsection 2.3, we will discuss more training details of our method and present our algorithm in the form of pseudo codes.",2 Method,[0],[0]
"To maximize L(Θ;D), the EM algorithm can be leveraged to maximize its lower bound L(Q).",2.1 EM Training,[0],[0]
"In the E-step, we calculate the expectation of the variable z using current estimate for the model, namely find the posterior distribution Q(z).",2.1 EM Training,[0],[0]
"In the M-step, with the expectation Q(z), we maximize the lower bound L(Q).",2.1 EM Training,[0],[0]
"Note that conditioned on the observed data and current model, the calculation of Q(z) is intractable, so we choose Q(z) = p(z|x) approximately.
",2.1 EM Training,[0],[0]
"M-step: In the M-step, we maximize the lower bound L(Q) w.r.t model parameters given Q(z).",2.1 EM Training,[0],[0]
"By substituting Q(z) = p(z|x) into L(Q), we can get the M-step as follows:
Θy|z = arg max Θy|z
L(Q)
= arg max Θy|z ∑ (x,y)∈D ∑ z p(z|x) log p(y|z)
",2.1 EM Training,[0],[0]
"= arg max Θy|z ∑ (x,y)∈D Ez∼p(z|x) log p(y|z)
(2) E-step: The approximate choice of Q(z) brings in a gap between L(Q) and L(Θ;D), which can be minimized in the E-step with Generalized EM method (McLachlan and Krishnan, 2007).",2.1 EM Training,[0],[0]
"According to Bishop (2006), we can write this gap explicitly as follows:
L(Θ;D)− L(Q) = ∑ z Q(z) log Q(z) p(z|y)
= KL(Q(z)||p(z|y))",2.1 EM Training,[0],[0]
"= KL(p(z|x)||p(z|y))
(3)
where KL(·) is the KullbackLeibler divergence, and the approximation that p(z|x, y)",2.1 EM Training,[0],[0]
"≈ p(z|y) is also used above.
",2.1 EM Training,[0],[0]
"In the E-step, we minimize the gap between L(Q) and L(Θ;D) as follows:
Θz|x = arg min Θz|x KL(p(z|x)||p(z|y))",2.1 EM Training,[0],[0]
"(4)
To sum it up, the E-step optimizes the model p(z|x) by minimizing the gap between L(Q) and L(Θ;D) to get a better lower bound L(Q).",2.1 EM Training,[0],[0]
This lower bound is then maximized in the M-step to optimize the model p(y|z).,2.1 EM Training,[0],[0]
"Given the new model p(y|z), the E-step tries to optimize p(z|x) again to find a new lower bound, with which the M-step is re-performed.",2.1 EM Training,[0],[0]
"This iteration process continues until the models converge, which is guaranteed by the convergence of the EM algorithm.",2.1 EM Training,[0],[0]
"The model p(z|y) is used as an approximation of p(z|x, y) in the E-step optimization (Equation 3).",2.2 Unified Bidirectional Training,[0],[0]
"Due to the low resource property of the language pair (Y, Z), p(z|y) cannot be well trained.",2.2 Unified Bidirectional Training,[0],[0]
"To solve this problem, we can jointly optimize p(x|z) and p(z|y) similarly by maximizing the reverse translation probability p(x|y).
",2.2 Unified Bidirectional Training,[0],[0]
"We now give our unified bidirectional generalized EM procedures as follows:
• Direction of X ⇒ Y E: Optimize Θz|x.
arg min Θz|x
KL(p(z|x)||p(z|y))",2.2 Unified Bidirectional Training,[0],[0]
"(5)
M: Optimize Θy|z .
arg max Θy|z ∑ (x,y)∈D Ez∼p(z|x) log p(y|z) (6)
",2.2 Unified Bidirectional Training,[0],[0]
• Direction of Y ⇒,2.2 Unified Bidirectional Training,[0],[0]
X,2.2 Unified Bidirectional Training,[0],[0]
"E: Optimize Θz|y.
arg min Θz|y
KL(p(z|y)||p(z|x))",2.2 Unified Bidirectional Training,[0],[0]
"(7)
M: Optimize Θx|z .
",2.2 Unified Bidirectional Training,[0],[0]
"arg max Θx|z ∑ (x,y)∈D Ez∼p(z|y) log p(x|z)",2.2 Unified Bidirectional Training,[0],[0]
"(8)
Based on the above derivation, the whole architecture of our method can be illustrated in Figure 2, where the dash arrows denote the direction of p(y|x), in which p(z|x) and p(y|z) are trained jointly with the help of p(z|y), while the solid ones denote the direction of p(x|y), in which p(z|y) and p(x|z) are trained jointly with the help of p(z|x).",2.2 Unified Bidirectional Training,[0],[0]
"A major difficulty in our unified bidirectional training is the exponential search space of the translation candidates, which could be addressed by either sampling (Shen et al., 2015; Cheng et al., 2016) or mode approximation (Kim and Rush, 2016).",2.3 Training Details,[0],[0]
"In our experiments, we leverage the sampling method and simply generate the top target sentence for approximation.
",2.3 Training Details,[0],[0]
"In order to perform gradient descend training, the parameter gradients for Equations 5 and 7 are formulated as follows:
∇Θz|xKL(p(z|x)||p(z|y))
",2.3 Training Details,[0],[0]
= Ez∼p(z|x) log p(z|x) p(z|y),2.3 Training Details,[0],[0]
"∇Θz|x log p(z|x)
∇Θz|yKL(p(z|y)||p(z|x))
",2.3 Training Details,[0],[0]
"= Ez∼p(z|y) log p(z|y) p(z|x) ∇Θz|y log p(z|y)
(9)
Similar to reinforcement learning, models p(z|x) and p(z|y) are trained using samples generated by the models themselves.",2.3 Training Details,[0],[0]
"According to our observation, some samples are noisy and detrimental to the training process.",2.3 Training Details,[0],[0]
"One way to tackle this is to filter out the bad ones using some additional metrics (BLEU, etc.).",2.3 Training Details,[0],[0]
"Nevertheless, in our settings, BLEU scores cannot be calculated during training due to the absence of the golden targets (z is generated based on x or y from the richresource pair (x, y)).",2.3 Training Details,[0],[0]
"Therefore we choose IBM model1 scores to weight the generated translation candidates, with the word translation probabilities calculated based on the given bilingual data (the low-resource pair (x, z) or (y, z)).",2.3 Training Details,[0],[0]
"Additionally, to stabilize the training process, the pseudo samples generated by model p(z|x) or p(z|y) are mixed with true bilingual samples in the same mini-batch with the ratio of 1-1.",2.3 Training Details,[0],[0]
"The whole training procedure is described in the following Algorithm 1, where the 5th and 9th steps are generating pseudo data.
",2.3 Training Details,[0],[0]
Algorithm 1 Training low-resource translation models with the triangular architecture,2.3 Training Details,[0],[0]
"Input: Rich-resource bilingual data (x, y); low-
resource bilingual data (x, z) and (y, z) Output:",2.3 Training Details,[0],[0]
"Parameters Θz|x, Θy|z , Θz|y and Θx|z
1: Pre-train p(z|x), p(z|y), p(x|z), p(y|z) 2: while not convergence do 3: Sample (x, y), (x∗, z∗), (y∗, z∗) ∈ D 4: .",2.3 Training Details,[0],[0]
"X ⇒ Y : Optimize Θz|x and Θy|z 5: Generate z′ from p(z′|x) and build the
training batches B1 = (x, z′)∪(x∗, z∗), B2 = (y, z′) ∪ (y∗, z∗) 6: E-step: update Θz|x with B1 (Equation 5) 7: M-step: update Θy|z with B2 (Equation 6) 8: .",2.3 Training Details,[0],[0]
"Y ⇒ X: Optimize Θz|y and Θx|z 9: Generate z′ from p(z′|y) and build the
training batches B3 = (y, z′)∪(y∗, z∗), B4 = (x, z′) ∪ (x∗, z∗) 10:",2.3 Training Details,[0],[0]
"E-step: update Θz|y with B3 (Equation 7) 11: M-step: update Θx|z with B4 (Equation 8) 12: end while 13: return Θz|x, Θy|z , Θz|y and Θx|z",2.3 Training Details,[0],[0]
"In order to verify our method, we conduct experiments on two multilingual datasets.",3.1 Datasets,[0],[0]
"The one is MultiUN (Eisele and Chen, 2010), which is a collection of translated documents from the United Nations, and the other is IWSLT2012 (Cettolo et al., 2012), which is a set of multilingual transcriptions of TED talks.",3.1 Datasets,[0],[0]
"As is mentioned in section 1, our method is compatible with methods exploiting monolingual data.",3.1 Datasets,[0],[0]
"So we also find some extra monolingual data of rare languages in both datasets and conduct experiments incorporating back-translation into our method.
",3.1 Datasets,[0],[0]
"MultiUN: English-French (EN-FR) bilingual data are used as the rich-resource pair (X,Y ).",3.1 Datasets,[0],[0]
"Arabic (AR) and Spanish (ES) are used as two simulated rare languages Z. We randomly choose subsets of bilingual data of (X,Z) and (Y, Z) in the original dataset to simulate low-resource situations, and make sure there is no overlap in Z between chosen data of (X,Z) and (Y,Z).
",3.1 Datasets,[0],[0]
"IWSLT20121: English-French is used as the rich-resource pair (X,Y ), and two rare languages Z are Hebrew (HE) and Romanian (RO) in our
1https://wit3.fbk.eu/mt.php?release=2012-02-plain
choice.",3.1 Datasets,[0],[0]
"Note that in this dataset, low-resource pairs (X,Z) and (Y,Z) are severely overlapped in Z.",3.1 Datasets,[0],[0]
"In addition, English-French bilingual data from WMT2014 dataset are also used to enrich the rich-resource pair.",3.1 Datasets,[0],[0]
"We also use additional EnglishRomanian bilingual data from Europarlv7 dataset (Koehn, 2005).",3.1 Datasets,[0],[0]
"The monolingual data of Z (HE and RO) are taken from the web2.
",3.1 Datasets,[0],[0]
"In both datasets, all sentences are filtered within the length of 5 to 50 after tokenization.",3.1 Datasets,[0],[0]
"Both the validation and the test sets are 2,000 parallel sentences sampled from the bilingual data, with the left as training data.",3.1 Datasets,[0],[0]
The size of training data of all language pairs are shown in Table 1.,3.1 Datasets,[0],[0]
We compare our method with four baseline systems.,3.2 Baselines,[0],[0]
"The first baseline is the RNNSearch model (Bahdanau et al., 2014), which is a sequence-tosequence model with attention mechanism trained with given small-scale bilingual data.",3.2 Baselines,[0],[0]
"The trained translation models are also used as pre-trained models for our subsequent training processes.
",3.2 Baselines,[0],[0]
"The second baseline is PBSMT (Koehn et al., 2003), which is a phrase-based statistical machine translation system.",3.2 Baselines,[0],[0]
"PBSMT is known to perform well on low-resource language pairs, so we want to compare it with our proposed method.",3.2 Baselines,[0],[0]
And we use the public available implementation of Moses5 for training and test in our experiments.,3.2 Baselines,[0],[0]
"The third baseline is a teacher-student alike method (Chen et al., 2017).",3.2 Baselines,[0],[0]
"For the sake of brevity, we will denote it as T-S. The process is illustrated in Figure 3.",3.2 Baselines,[0],[0]
"We treat this method as a second baseline because it can also be regarded as a method exploiting (Y, Z) and (X,Y ) to improve
2https://github.com/ajinkyakulkarni14/TEDMultilingual-Parallel-Corpus
3together with WMT2014 4together with Europarlv7 5http://www.statmt.org/moses/
the translation of (X,Z) if we regard (X,Z) as the zero-resource pair and p(x|y) as the teacher model when training p(z|x) and p(x|z).
",3.2 Baselines,[0],[0]
"The fourth baseline is back-translation (Sennrich et al., 2015).",3.2 Baselines,[0],[0]
We will denote it as BackTrans.,3.2 Baselines,[0],[0]
"More concretely, to train the model p(z|x), we use extra monolingual Z described in Table 1 to do back-translation; to train the model p(x|z), we use monolingual X taken from (X,Y ).",3.2 Baselines,[0],[0]
Procedures for training p(z|y) and p(y|z) are similar.,3.2 Baselines,[0],[0]
This method use extra monolingual data of Z compared with our TA-NMT method.,3.2 Baselines,[0],[0]
But we can incorporate it into our method.,3.2 Baselines,[0],[0]
"Experimental results on both datasets are shown in Table 3 and 4 respectively, in which RNNSearch, PBSMT, T-S and BackTrans are four baselines.",3.3 Overall Results,[0],[0]
"TA-NMT is our proposed method, and TA-NMT(GI) is our method incorporating backtranslation as good initialization.",3.3 Overall Results,[0],[0]
"For the purpose of clarity and a fair comparison, we list the resources that different methods exploit in Table 2.
",3.3 Overall Results,[0],[0]
"From Table 3 on MultiUN, the performance of RNNSearch is relatively poor.",3.3 Overall Results,[0],[0]
"As is expected, PBSMT performs better than RNNSearch on lowresource pairs by the average of 1.78 BLEU.",3.3 Overall Results,[0],[0]
"The T-S method which can doubling the training data
for both (X,Z) and (Y, Z) by generating pseudo data from each other, leads up to 1.1 BLEU points improvement on average over RNNSearch.",3.3 Overall Results,[0],[0]
"Compared with T-S, our method gains a further improvement of about 0.9 BLEU on average, because our method can better leverage the rich-resource pair (X,Y ).",3.3 Overall Results,[0],[0]
"With extra large monolingual Z introduced, BackTrans can improve the performance of p(z|x) and p(z|y) significantly compared with all the methods without monolingual Z. However TA-NMT is comparable with or even better than BackTrans for p(x|z) and p(y|z) because both of the methods leverage resources from richresource pair (X,Y ), but BackTrans does not use the alignment information it provides.",3.3 Overall Results,[0],[0]
"Moreover, with back-translation as good initialization, further improvement is achieved by TA-NMT(GI) of about 0.7 BLEU on average over BackTrans.
",3.3 Overall Results,[0],[0]
"In Table 4, we can draw the similar conclusion.",3.3 Overall Results,[0],[0]
"However, different from MultiUN, in the EN-FR-HE group of IWSLT, (X,Z) and (Y,Z) are severely overlapped in Z. Therefore, T-S cannot improve the performance obviously (only about 0.2 BLEU) on RNNSearch because it fails to essentially double training data via the teacher model.",3.3 Overall Results,[0],[0]
"As for EN-FR-RO, with the additionally introduced EN-RO data from Europarlv7, which has no overlap in RO with FR-RO, T-S can improve the average performance more than the ENFR-HE group.",3.3 Overall Results,[0],[0]
TA-NMT outperforms T-S by 0.93 BLEU on average.,3.3 Overall Results,[0],[0]
"Note that even though Back-
Trans uses extra monolingual Z, the improvements are not so obvious as the former dataset, the reason for which we will delve into in the next subsection.",3.3 Overall Results,[0],[0]
"Again, with back-translation as good initialization, TA-NMT(GI) can get the best result.
",3.3 Overall Results,[0],[0]
Note that BLEU scores of TA-NMT are lower than BackTrans in the directions of X⇒Z and Y⇒Z.,3.3 Overall Results,[0],[0]
"The reason is that the resources used by these two methods are different, as shown in Table 2.",3.3 Overall Results,[0],[0]
"To do back translation in two directions (e.g., X⇒Z and Z⇒X), we need monolingual data from both sides (e.g., X and Z), however, in TA-NMT, the monolingual data of Z is not necessary.",3.3 Overall Results,[0],[0]
"Therefore, in the translation of X⇒Z or Y⇒Z, BackTrans uses additional monolingual data of Z while TA-NMT does not, that is why BackTrans outperforms TA-NMT in these directions.",3.3 Overall Results,[0],[0]
"Our method can leverage back translation as a good initialization, aka TA-NMT(GI) , and outperforms BackTrans on all translation directions.
",3.3 Overall Results,[0],[0]
"The average test BLEU scores of different methods in each data group (EN-FR-AR, EN-FRES, EN-FR-HE, and EN-FR-RO) are listed in the column Ave of the tables for clear comparison.",3.3 Overall Results,[0],[0]
"Comparing the results of BackTrans and TANMT(GI) on both datasets, we notice the improvements of both methods on IWSLT are not as significant as MultiUN.",3.4 The Effect of Extra Monolingual Data,[0],[0]
"We speculate the reason is the relatively less amount of monolingual Z we use in
the experiments on IWSLT as shown in Table 1.",3.4 The Effect of Extra Monolingual Data,[0],[0]
"So we conduct the following experiment to verify the conjecture by changing the scale of monolingual Arabic data in the MultiUN dataset, of which the data utilization rates are set to 0%, 10%, 30%, 60% and 100% respectively.",3.4 The Effect of Extra Monolingual Data,[0],[0]
Then we compare the performance of BackTrans and TA-NMT(GI) in the EN-FR-AR group.,3.4 The Effect of Extra Monolingual Data,[0],[0]
"As Figure 4 shows, the amount of monolingual Z actually has a big effect on the results, which can also verify our conjecture above upon the less significant improvement of BackTrans and TA-NMT(GI) on IWSLT.",3.4 The Effect of Extra Monolingual Data,[0],[0]
"In addition, even with poor ”good-initialization”, TANMT(GI) still get the best results.",3.4 The Effect of Extra Monolingual Data,[0],[0]
"To better illustrate the behavior of our method, we print the training curves in both the M-steps and Esteps of TA-NMT and TA-NMT(GI) in Figure 5 above.",3.5 EM Training Curves,[0],[0]
"The chosen models printed in this figure are EN2AR and AR2FR on MultiUN, and EN2RO and RO2FR on IWLST.
",3.5 EM Training Curves,[0],[0]
"From Figure 5, we can see that the two lowresource translation models are improved nearly simultaneously along with the training process, which verifies our point that two weak models could boost each other in our EM framework.",3.5 EM Training Curves,[0],[0]
"Notice that at the early stage, the performance of all models stagnates for several iterations, especially of TA-NMT.",3.5 EM Training Curves,[0],[0]
"The reason could be that the pseudo bilingual data and the true training data are heterogeneous, and it may take some time for the models to adapt to a new distribution which both models agree.",3.5 EM Training Curves,[0],[0]
"Compared with TA-NMT, TA-NMT(GI) are more stable, because the models may have
adapted to a mixed distribution of heterogeneous data in the preceding back-translation phase.",3.5 EM Training Curves,[0],[0]
"As shown in Equation 9, the E-step actually works as a reinforcement learning (RL) mechanism.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
Models p(z|x) and p(z|y) generate samples by themselves and receive rewards to update their parameters.,3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"Note that the reward here is described by the log terms in Equation 9, which is derived from our EM algorithm rather than defined artificially.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"In Table 5, we do a case study of the EN2ES translation sampled by p(z|x) as well as its time-step rewards during the E-step.
",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"In the first case, the best translation of ”political” is ”polı́ticos”.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"When the model p(z|x) generates an inaccurate one ”polı́ticas”, it receives a negative reward (-0.01), with which the model parameters will be updated accordingly.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"In the sec-
ond case, the output misses important words and is not fluent.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"Rewards received by the model p(z|x) are zero for nearly all tokens in the output, leading to an invalid updating.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"In the last case, the output sentence is identical to the human reference.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"The rewards received are nearly all positive and meaningful, thus the RL rule will update the parameters to encourage this translation candidate.",3.6 Reinforcement Learning Mechanism in Our Method,[0],[0]
"NMT systems, relying heavily on the availability of large bilingual data, result in poor translation quality for low-resource pairs (Zoph et al., 2016).",4 Related Work,[0],[0]
This low-resource phenomenon has been observed in much preceding work.,4 Related Work,[0],[0]
"A very common approach is exploiting monolingual data of both source and target languages (Sennrich et al., 2015; Zhang and Zong, 2016; Cheng et al., 2016; Zhang et al., 2018; He et al., 2016).
",4 Related Work,[0],[0]
"As a kind of data augmentation technique, exploiting monolingual data can enrich the training data for low-resource pairs.",4 Related Work,[0],[0]
"Sennrich et al. (2015) propose back-translation, exploits the monolingual data of the target side, which is then used to generate pseudo bilingual data via an additional target-to-source translation model.",4 Related Work,[0],[0]
"Different from back-translation, Zhang and Zong (2016) propose two approaches to use source-side monolingual data, of which the first is employing a self-learning algorithm to generate pseudo data, while the second is using two NMT models to predict the translation and to reorder the source-side monolingual
sentences.",4 Related Work,[0],[0]
"As an extension to these two methods, Cheng et al. (2016) and Zhang et al. (2018) combine two translation directions and propose a training framework to jointly optimize the sourceto-target and target-to-source translation models.",4 Related Work,[0],[0]
"Similar to joint training, He et al. (2016) propose a dual learning framework with a reinforcement learning mechanism to better leverage monolingual data and make two translation models promote each other.",4 Related Work,[0],[0]
"All of these methods are concentrated on exploiting either the monolingual data of the source and target language or both of them.
",4 Related Work,[0],[0]
"Our method takes a different angle but is compatible with existing approaches, we propose a novel triangular architecture to leverage two additional language pairs by introducing a third rich language.",4 Related Work,[0],[0]
"By combining our method with existing approaches such as back-translation, we can make a further improvement.
",4 Related Work,[0],[0]
"Another approach for tackling the low-resource translation problem is multilingual neural machine translation (Firat et al., 2016), where different encoders and decoders for all languages with a shared attention mechanism are trained.",4 Related Work,[0],[0]
This method tends to exploit the network architecture to relate low-resource pairs.,4 Related Work,[0],[0]
"Our method is different from it, which is more like a training method rather than network modification.",4 Related Work,[0],[0]
"In this paper, we propose a triangular architecture (TA-NMT) to effectively tackle the problem
of low-resource pairs translation with a unified bidirectional EM framework.",5 Conclusion,[0],[0]
"By introducing another rich language, our method can better exploit the additional language pairs to enrich the original low-resource pair.",5 Conclusion,[0],[0]
"Compared with the RNNSearch (Bahdanau et al., 2014), a teacherstudent alike method (Chen et al., 2017) and the back-translation (Sennrich et al., 2015) on the same data level, our method achieves significant improvement on the MutiUN and IWSLT2012 datasets.",5 Conclusion,[0],[0]
"Note that our method can be combined with methods exploiting monolingual data for NMT low-resource problem such as backtranslation and make further improvements.
",5 Conclusion,[0],[0]
"In the future, we may extend our architecture to other scenarios, such as totally unsupervised training with no bilingual data for the rare language.",5 Conclusion,[0],[0]
We thank Zhirui Zhang and Shuangzhi Wu for useful discussions.,Acknowledgments,[0],[0]
"This work is supported in part by NSFC U1636210, 973 Program 2014CB340300, and NSFC 61421003.",Acknowledgments,[0],[0]
"Neural Machine Translation (NMT) performs poor on the low-resource language pair (X,Z), especially when Z is a rare language.",abstractText,[0],[0]
"By introducing another rich language Y , we propose a novel triangular training architecture (TA-NMT) to leverage bilingual data (Y,Z) (may be small) and (X,Y ) (can be rich) to improve the translation performance of lowresource pairs.",abstractText,[0],[0]
"In this triangular architecture, Z is taken as the intermediate latent variable, and translation models of Z are jointly optimized with a unified bidirectional EM algorithm under the goal of maximizing the translation likelihood of (X,Y ).",abstractText,[0],[0]
"Empirical results demonstrate that our method significantly improves the translation quality of rare languages on MultiUN and IWSLT2012 datasets, and achieves even better performance combining back-translation methods.",abstractText,[0],[0]
Triangular Architecture for Rare Language Translation,title,[0],[0]
"Deep neural networks have recently received much limelight for their enormous success in a variety of applications across many different areas of artificial intelligence, computer vision, speech recognition, and natural language processing (LeCun et al., 2015; Hinton et al., 2012; Krizhevsky et al., 2012; Bahdanau et al., 2014; Kalchbrenner & Blunsom, 2013).",1. Introduction,[0],[0]
"Nevertheless, it is also well-known that our theoretical understanding of their efficacy remains incomplete.
",1. Introduction,[0],[0]
There have been several attempts to analyze deep neural networks from different perspectives.,1. Introduction,[0],[0]
"Notably, earlier studies have suggested that a deep architecture could use parameters more efficiently and requires exponentially fewer parameters to express certain families of functions than a shallow architecture (Delalleau & Bengio, 2011; Bengio & Delal-
1Department of Computer Science, University of Chicago, Chicago, IL 2Department of Statistics, University of Chicago, Chicago, IL 3Computational and Applied Mathematics Initiative, University of Chicago, Chicago, IL.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Lek-Heng Lim <lekheng@galton.uchicago.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"leau, 2011; Montufar et al., 2014; Eldan & Shamir, 2016; Poole et al., 2016; Arora et al., 2018).",1. Introduction,[0],[0]
"Recent work (Zhang et al., 2016) showed that several successful neural networks possess a high representation power and can easily shatter random data.",1. Introduction,[0],[0]
"However, they also generalize well to data unseen during training stage, suggesting that such networks may have some implicit regularization.",1. Introduction,[0],[0]
Traditional measures of complexity such as VC-dimension and Rademacher complexity fail to explain this phenomenon.,1. Introduction,[0],[0]
"Understanding this implicit regularization that begets the generalization power of deep neural networks remains a challenge.
",1. Introduction,[0],[0]
The goal of our work is to establish connections between neural network and tropical geometry in the hope that they will shed light on the workings of deep neural networks.,1. Introduction,[0],[0]
Tropical geometry is a new area in algebraic geometry that has seen an explosive growth in the recent decade but remains relatively obscure outside pure mathematics.,1. Introduction,[0],[0]
"We will focus on feedforward neural networks with rectified linear units (ReLU) and show that they are analogues of rational functions, i.e., ratios of two multivariate polynomials f, g in variables x1, . . .",1. Introduction,[0],[0]
", xd,
fpx1, . . .",1. Introduction,[0],[0]
", xdq gpx1, . . .",1. Introduction,[0],[0]
", xdq ,
in tropical algebra.",1. Introduction,[0],[0]
"For standard and trigonometric polynomials, it is known that rational approximation — approximating a target function by a ratio of two polynomials instead of a single polynomial — vastly improves the quality of approximation without increasing the degree.",1. Introduction,[0],[0]
"This gives our analogue: An ReLU neural network is the tropical ratio of two tropical polynomials, i.e., a tropical rational function.",1. Introduction,[0],[0]
"More precisely, if we view a neural network as a function ν :",1. Introduction,[0],[0]
"Rd Ñ Rp, x “ px1, . . .",1. Introduction,[0],[0]
", xdq ÞÑ pν1pxq, . . .",1. Introduction,[0],[0]
", νppxqq, then each ν is a tropical rational map, i.e., each νi is a tropical rational function.",1. Introduction,[0],[0]
"In fact, we will show that:
the family of functions represented by feedforward neural networks with rectified linear units and integer weights is exactly the family of tropical rational maps.
",1. Introduction,[0],[0]
It immediately follows that there is a semifield structure on this family of functions.,1. Introduction,[0],[0]
"More importantly, this establishes a
ar X
iv :1
80 5.
07 09
1v 1
[ cs
.L G
] 1
8 M
ay 2
01 8
bridge between neural networks1 and tropical geometry that allows us to view neural networks as well-studied tropical geometric objects.",1. Introduction,[0],[0]
This insight allows us to closely relate boundaries between linear regions of a neural network to tropical hypersurfaces and thereby facilitate studies of decision boundaries of neural networks in classification problems as tropical hypersurfaces.,1. Introduction,[0],[0]
"Furthermore, the number of linear regions, which captures the complexity of a neural network (Montufar et al., 2014; Raghu et al., 2017; Arora et al., 2018), can be bounded by the number of vertices of the polytopes associated with the neural network’s tropical rational representation.",1. Introduction,[0],[0]
"Lastly, a neural network with one hidden layer can be completely characterized by zonotopes, which serve as building blocks for deeper networks.
",1. Introduction,[0],[0]
In Sections 2 and 3 we introduce basic tropical algebra and tropical algebraic geometry of relevance to us.,1. Introduction,[0],[0]
We state our assumptions precisely in Section 4 and establish the connection between tropical geometry and multilayer neural networks in Section 5.,1. Introduction,[0],[0]
"We analyze neural networks with tropical tools in Section 6, proving that a deeper neural network is exponentially more expressive than a shallow network — though our objective is not so much to perform state-of-the-art analysis but to demonstrate that tropical algebraic geometry can provide useful insights.",1. Introduction,[0],[0]
All proofs are deferred to Section D of the supplement.,1. Introduction,[0],[0]
"Roughly speaking, tropical algebraic geometry is an analogue of classical algebraic geometry over C, the field of complex numbers, but where one replaces C by a semifield2 called the tropical semiring, to be defined below.",2. Tropical algebra,[0],[0]
We give a brief review of tropical algebra and introduce some relevant notations.,2. Tropical algebra,[0],[0]
"See (Itenberg et al., 2009; Maclagan & Sturmfels, 2015) for an in-depth treatment.
",2. Tropical algebra,[0],[0]
"The most fundamental component of tropical algebraic geometry is the tropical semiring T :“ ` R Y t´8u,‘,d ˘
.",2. Tropical algebra,[0],[0]
"The two operations ‘ and d, called tropical addition and tropical multiplication respectively, are defined as follows.
",2. Tropical algebra,[0],[0]
Definition 2.1.,2. Tropical algebra,[0],[0]
"For x, y P R, their tropical sum is x‘ y :“ maxtx, yu; their tropical product is x",2. Tropical algebra,[0],[0]
d y :“ x ` y; the tropical quotient of x over y is xm y,2. Tropical algebra,[0],[0]
":“ x´ y.
For any x P R, we have ´8 ‘ x “ 0 d x “ x and ´8d x “ ´8.",2. Tropical algebra,[0],[0]
Thus ´8 is the tropical additive identity and 0 is the tropical multiplicative identity.,2. Tropical algebra,[0],[0]
"Furthermore, these operations satisfy the usual laws of arithmetic: associativity, commutativity, and distributivity.",2. Tropical algebra,[0],[0]
The set RY t´8u is therefore a semiring under the operations‘ andd.,2. Tropical algebra,[0],[0]
"While it is not a ring (lacks additive inverse), one may nonetheless
1Henceforth a “neural network” will always mean a feedforward neural network with ReLU activation.
",2. Tropical algebra,[0],[0]
"2A semifield is a field sans the existence of additive inverses.
",2. Tropical algebra,[0],[0]
"generalize many algebraic objects (e.g., matrices, polynomials, tensors, etc) and notions (e.g., rank, determinant, degree, etc) over the tropical semiring — the study of these, in a nutshell, constitutes the subject of tropical algebra.
",2. Tropical algebra,[0],[0]
Let N “ tn P Z : n ě 0u.,2. Tropical algebra,[0],[0]
"For an integer a P N, raising x P R to the ath power is the same as multiplying x to itself a times.",2. Tropical algebra,[0],[0]
"When standard multiplication is replaced by tropical multiplication, this gives us tropical power:
xda",2. Tropical algebra,[0],[0]
":“ xd ¨ ¨ ¨ d x “ a ¨ x,
where the last ¨ denotes standard product of real numbers; it is extended to RY t´8u by defining, for any a P N,
´8da :“ #
´8 if a ą 0, 0",2. Tropical algebra,[0],[0]
"if a “ 0.
A tropical semiring, while not a field, possesses one quality of a field: Every x P R has a tropical multiplicative inverse given by its standard additive inverse, i.e., xdp´1q :“ ´x. Though not reflected in its name, T is in fact a semifield.
",2. Tropical algebra,[0],[0]
"One may therefore also raise x P R to a negative power a P Z by raising its tropical multiplicative inverse ´x to the positive power ´a, i.e., xda “ p´xqdp´aq.",2. Tropical algebra,[0],[0]
"As is the case in standard real arithmetic, the tropical additive inverse ´8 does not have a tropical multiplicative inverse and ´8da is undefined for a ă 0.",2. Tropical algebra,[0],[0]
"For notational simplicity, we will henceforth write xa instead of xda for tropical power when there is no cause for confusion.",2. Tropical algebra,[0],[0]
"Other algebraic rules of tropical power may be derived from definition; see Section B in the supplement.
",2. Tropical algebra,[0],[0]
We are now in a position to define tropical polynomials and tropical rational functions.,2. Tropical algebra,[0],[0]
"In the following, x and xi will denote variables (i.e., indeterminates).
",2. Tropical algebra,[0],[0]
Definition 2.2.,2. Tropical algebra,[0],[0]
"A tropical monomial in d variables x1, . . .",2. Tropical algebra,[0],[0]
", xd is an expression of the form
cd xa11 d x a2 2 d ¨ ¨ ¨ d x ad d
where c P R Y t´8u and a1, . . .",2. Tropical algebra,[0],[0]
", ad P N.",2. Tropical algebra,[0],[0]
"As a convenient shorthand, we will also write a tropical monomial in multiindex notation as cxα where α “ pa1, . .",2. Tropical algebra,[0],[0]
.,2. Tropical algebra,[0],[0]
", adq P Nd and x “ px1, . . .",2. Tropical algebra,[0],[0]
", xdq.",2. Tropical algebra,[0],[0]
"Note that xα “ 0 d xα as 0 is the tropical multiplicative identity.
",2. Tropical algebra,[0],[0]
Definition 2.3.,2. Tropical algebra,[0],[0]
"Following notations above, a tropical polynomial fpxq “ fpx1, . . .",2. Tropical algebra,[0],[0]
", xdq is a finite tropical sum of tropical monomials
fpxq “ c1xα1 ‘",2. Tropical algebra,[0],[0]
"¨ ¨ ¨ ‘ crxαr ,
where αi “ pai1, . . .",2. Tropical algebra,[0],[0]
", aidq P Nd and ci P R Y t´8u, i “ 1, . . .",2. Tropical algebra,[0],[0]
", r. We will assume that a monomial of a given multiindex appears at most once in the sum, i.e., αi ‰ αj for any i ‰ j.
Definition 2.4.",2. Tropical algebra,[0],[0]
"Following notations above, a tropical rational function is a standard difference, or, equivalently, a tropical quotient of two tropical polynomials fpxq and gpxq: fpxq ´ gpxq “ fpxq m gpxq.",2. Tropical algebra,[0],[0]
"We will denote a tropical rational function by f m g, where f and g are understood to be tropical polynomial functions.
",2. Tropical algebra,[0],[0]
"It is routine to verify that the set of tropical polynomials Trx1, . . .",2. Tropical algebra,[0],[0]
", xds forms a semiring under the standard extension of ‘ and d to tropical polynomials, and likewise the set of tropical rational functions Tpx1, . . .",2. Tropical algebra,[0],[0]
", xdq forms a semifield.",2. Tropical algebra,[0],[0]
"We regard a tropical polynomial f “ f m 0 as a special case of a tropical rational function and thus Trx1, . . .",2. Tropical algebra,[0],[0]
", xds Ď Tpx1, . . .",2. Tropical algebra,[0],[0]
", xdq.",2. Tropical algebra,[0],[0]
"Henceforth any result stated for a tropical rational function would implicitly also hold for a tropical polynomial.
",2. Tropical algebra,[0],[0]
A d-variate tropical polynomial fpxq defines a function f :,2. Tropical algebra,[0],[0]
"Rd Ñ R that is a convex function in the usual sense as taking max and sum of convex functions preserve convexity (Boyd & Vandenberghe, 2004).",2. Tropical algebra,[0],[0]
"As such, a tropical rational function f m g : Rd Ñ R is a DC function or differenceconvex function (Hartman, 1959; Tao & Hoai An, 2005).
",2. Tropical algebra,[0],[0]
We will need a notion of vector-valued tropical polynomials and tropical rational functions.,2. Tropical algebra,[0],[0]
Definition 2.5.,2. Tropical algebra,[0],[0]
F :,2. Tropical algebra,[0],[0]
"Rd Ñ Rp, x “ px1, . . .",2. Tropical algebra,[0],[0]
", xdq ÞÑ pf1pxq, . . .",2. Tropical algebra,[0],[0]
", fppxqq, is called a tropical polynomial map if each fi :",2. Tropical algebra,[0],[0]
"Rd Ñ R is a tropical polynomial, i “ 1, . . .",2. Tropical algebra,[0],[0]
", p, and a tropical rational map if f1, . . .",2. Tropical algebra,[0],[0]
", fp are tropical rational functions.",2. Tropical algebra,[0],[0]
"We will denote the set of tropical polynomial maps by Polpd, pq and the set of tropical rational maps by Ratpd, pq.",2. Tropical algebra,[0],[0]
"So Polpd, 1q “ Trx1, . . .",2. Tropical algebra,[0],[0]
", xds and Ratpd, 1q “ Tpx1, . . .",2. Tropical algebra,[0],[0]
", xdq.",2. Tropical algebra,[0],[0]
"There are tropical analogues of many notions in classical algebraic geometry (Itenberg et al., 2009; Maclagan & Sturmfels, 2015), among which are tropical hypersurfaces, tropical analogues of algebraic curves in classical algebraic geometry.",3. Tropical hypersurfaces,[0],[0]
Tropical hypersurfaces are a principal object of interest in tropical geometry and will prove very useful in our approach towards neural networks.,3. Tropical hypersurfaces,[0],[0]
"Intuitively, the tropical hypersurface of a tropical polynomial f is the set of points x where f is not linear at x. Definition 3.1.",3. Tropical hypersurfaces,[0],[0]
"The tropical hypersurface of a tropical polynomial fpxq “ c1xα1 ‘ ¨ ¨ ¨ ‘ crxαr is
T pfq :“ x P Rd : cixαi “ cjxαj “ fpxq for some αi ‰ αj ( .
i.e., the set of points x at which the value of f at x is attained by two or more monomials in f .
",3. Tropical hypersurfaces,[0],[0]
A tropical hypersurface divides the domain of f into convex cells on each of which f is linear.,3. Tropical hypersurfaces,[0],[0]
"These cells are convex polyhedrons, i.e., defined by linear inequalities with integer coefficients: tx P Rd :",3. Tropical hypersurfaces,[0],[0]
Ax ď bu for A P Zmˆd and b P Rm.,3. Tropical hypersurfaces,[0],[0]
"For example, the cell where a tropical monomial cjx
αj attains its maximum is tx P Rd : cj ` αTjx ě ci ` αTix for all i ‰ ju.",3. Tropical hypersurfaces,[0],[0]
"Tropical hypersurfaces of polynomials in two variables (i.e., in R2) are called tropical curves.
",3. Tropical hypersurfaces,[0],[0]
"Just like standard multivariate polynomials, every tropical polynomial comes with an associated Newton polygon.
",3. Tropical hypersurfaces,[0],[0]
Definition 3.2.,3. Tropical hypersurfaces,[0],[0]
"The Newton polygon of a tropical polynomial fpxq “ c1xα1 ‘ ¨ ¨ ¨ ‘ crxαr is the convex hull of α1, . . .",3. Tropical hypersurfaces,[0],[0]
", αr P Nd, regarded as points in Rd,
∆pfq :“ Conv αi P Rd : ci ‰ ´8, i “ 1, . . .",3. Tropical hypersurfaces,[0],[0]
", r ( .
",3. Tropical hypersurfaces,[0],[0]
"A tropical polynomial f determines a dual subdivision of ∆pfq, constructed as follows.",3. Tropical hypersurfaces,[0],[0]
"First, lift each αi from Rd into Rd`1 by appending ci as the last coordinate.",3. Tropical hypersurfaces,[0],[0]
"Denote the convex hull of the lifted α1, . . .",3. Tropical hypersurfaces,[0],[0]
", αr as
Ppfq :“ Convtpαi, ciq P Rd ˆ R : i “ 1, . . .",3. Tropical hypersurfaces,[0],[0]
", ru. (1)
Next let UF ` Ppfq ˘
denote the collection of upper faces in Ppfq and π : Rd ˆ R Ñ Rd be the projection that drops the last coordinate.",3. Tropical hypersurfaces,[0],[0]
"The dual subdivision determined by f is then
δpfq :“ πppq Ă Rd : p P UF ` Ppfq ˘( .
",3. Tropical hypersurfaces,[0],[0]
δpfq forms a polyhedral complex with support ∆pfq.,3. Tropical hypersurfaces,[0],[0]
"By (Maclagan & Sturmfels, 2015, Proposition 3.1.6), the tropical hypersurface T pfq is the pd´ 1q-skeleton of the polyhedral complex dual to δpfq.",3. Tropical hypersurfaces,[0],[0]
This means that each vertex in δpfq corresponds to one “cell” in Rd where the function f is linear.,3. Tropical hypersurfaces,[0],[0]
"Thus, the number of vertices in Ppfq provides an upper bound on the number of linear regions of f .
",3. Tropical hypersurfaces,[0],[0]
"Figure 1 shows the Newton polygon and dual subdivision for the tropical polynomial fpx1, x2q “ 1d x21 ‘ 1d x22 ‘ 2d x1x2",3. Tropical hypersurfaces,[0],[0]
‘ 2d x1 ‘ 2d x2 ‘ 2.,3. Tropical hypersurfaces,[0],[0]
"Figure 2 shows how we
may find the dual subdivision for this tropical polynomial by following the aforementioned procedures; with step-by-step details given in Section C.1.
",3. Tropical hypersurfaces,[0],[0]
Tropical polynomials and tropical rational functions are clearly piecewise linear functions.,3. Tropical hypersurfaces,[0],[0]
"As such a tropical rational map is a piecewise linear map and the notion of linear region applies.
",3. Tropical hypersurfaces,[0],[0]
Definition 3.3.,3. Tropical hypersurfaces,[0],[0]
"A linear region of F P Ratpd,mq is a maximal connected subset of the domain on which F is linear.",3. Tropical hypersurfaces,[0],[0]
"The number of linear regions of F is denoted N pF q.
Note that a tropical polynomial map F P Polpd,mq has convex linear regions but a tropical rational map F P Ratpd, nq generally has nonconvex linear regions.",3. Tropical hypersurfaces,[0],[0]
"In Section 6.3, we will use N pF q as a measure of complexity for an F P Ratpd, nq given by a neural network.",3. Tropical hypersurfaces,[0],[0]
"Our analysis of neural networks will require figuring out how the polytope Ppfq transforms under tropical power, sum, and product.",3.1. Transformations of tropical polynomials,[0],[0]
"The first is straightforward.
",3.1. Transformations of tropical polynomials,[0],[0]
Proposition 3.1.,3.1. Transformations of tropical polynomials,[0],[0]
"Let f be a tropical polynomial and let a P N. Then
Ppfaq “ aPpfq.
",3.1. Transformations of tropical polynomials,[0],[0]
"aPpfq “ tax : x P Ppfqu Ď Rd`1 is a scaled version of Ppfq with the same shape but different volume.
",3.1. Transformations of tropical polynomials,[0],[0]
"To describe the effect of tropical sum and product, we need a few notions from convex geometry.",3.1. Transformations of tropical polynomials,[0],[0]
"The Minkowski sum of two sets P1 and P2 in Rd is the set
P1 ` P2 :“ x1 ` x2 P Rd :",3.1. Transformations of tropical polynomials,[0],[0]
"x1 P P1, x2 P P2 ( ;
and for λ1, λ2 ě 0, their weighted Minkowski sum is
λ1P1 ` λ2P2 :“ λ1x1 ` λ2x2 P Rd : x1 P P1, x2 P P2 ( .
",3.1. Transformations of tropical polynomials,[0],[0]
Weighted Minkowski sum is clearly commutative and associative and generalizes to more than two sets.,3.1. Transformations of tropical polynomials,[0],[0]
"In particular, the Minkowski sum of line segments is called a zonotope.
Let VpP q denote the set of vertices of a polytope P .",3.1. Transformations of tropical polynomials,[0],[0]
"Clearly, the Minkowski sum of two polytopes is given by the convex hull of the Minkowski sum of their vertex sets, i.e., P1 ` P2 “ Conv ` VpP1q ` VpP2q ˘
.",3.1. Transformations of tropical polynomials,[0],[0]
"With this observation, the following is immediate.
",3.1. Transformations of tropical polynomials,[0],[0]
Proposition 3.2.,3.1. Transformations of tropical polynomials,[0],[0]
"Let f, g P Polpd, 1q “ Trx1, . . .",3.1. Transformations of tropical polynomials,[0],[0]
", xds be tropical polynomials.",3.1. Transformations of tropical polynomials,[0],[0]
"Then
Ppf d gq “ Ppfq ` Ppgq, Ppf ‘ gq “ Conv ` VpPpfqq Y VpPpgqq ˘ .
",3.1. Transformations of tropical polynomials,[0],[0]
"We reproduce below part of (Gritzmann & Sturmfels, 1993, Theorem 2.1.10) and derive a corollary for bounding the number of verticies on the upper faces of a zonotope.
Theorem 3.3 (Gritzmann–Sturmfels).",3.1. Transformations of tropical polynomials,[0],[0]
"Let P1, . . .",3.1. Transformations of tropical polynomials,[0],[0]
", Pk be polytopes in Rd and let m denote the total number of nonparallel edges of P1, . . .",3.1. Transformations of tropical polynomials,[0],[0]
", Pk.",3.1. Transformations of tropical polynomials,[0],[0]
"Then the number of vertices of P1 ` ¨ ¨ ¨ ` Pk does not exceed
2 d´1 ÿ j“0 pm",3.1. Transformations of tropical polynomials,[0],[0]
´,3.1. Transformations of tropical polynomials,[0],[0]
"1j q .
",3.1. Transformations of tropical polynomials,[0],[0]
"The upper bound is attained if all Pi’s are zonotopes and all their generating line segments are in general positions.
",3.1. Transformations of tropical polynomials,[0],[0]
Corollary 3.4.,3.1. Transformations of tropical polynomials,[0],[0]
"Let P Ď Rd`1 be a zonotope generated by m line segments P1, . . .",3.1. Transformations of tropical polynomials,[0],[0]
", Pm.",3.1. Transformations of tropical polynomials,[0],[0]
Let π : Rd ˆ RÑ Rd be the projection.,3.1. Transformations of tropical polynomials,[0],[0]
"Suppose P satisfies:
(i) the generating line segments are in general positions;
(ii) the set of projected vertices tπpvq : v P VpP qu Ď Rd are in general positions.
",3.1. Transformations of tropical polynomials,[0],[0]
"Then P has d ÿ
j“0 pmj q
vertices on its upper faces.",3.1. Transformations of tropical polynomials,[0],[0]
"If either (i) or (ii) is violated, then this becomes an upper bound.
",3.1. Transformations of tropical polynomials,[0],[0]
"As we mentioned, linear regions of a tropical polynomial f correspond to vertices on UF ` Ppfq ˘
and the corollary will be useful for bounding the number of linear regions.",3.1. Transformations of tropical polynomials,[0],[0]
"While we expect our readership to be familiar with feedforward neural networks, we will nevertheless use this short
section to define them, primarily for the purpose of fixing notations and specifying the assumptions that we retain throughout this article.",4. Neural networks,[0],[0]
"We restrict our attention to fully connected feedforward neural networks.
",4. Neural networks,[0],[0]
"Viewed abstractly, an L-layer feedforward neural network is a map ν",4. Neural networks,[0],[0]
: Rd Ñ,4. Neural networks,[0],[0]
"Rp given by a composition of functions
ν “ σpLq ˝ ρpLq ˝",4. Neural networks,[0],[0]
"σpL´1q ˝ ρpL´1q ¨ ¨ ¨ ˝ σp1q ˝ ρp1q.
",4. Neural networks,[0],[0]
"The preactivation functions ρp1q, . . .",4. Neural networks,[0],[0]
", ρpLq are affine transformations to be determined and the activation functions σp1q, . . .",4. Neural networks,[0],[0]
", σpLq are chosen and fixed in advanced.
",4. Neural networks,[0],[0]
"We denote the width, i.e., the number of nodes, of the lth layer by nl, l “ 1, ¨ ¨ ¨ , L´ 1.",4. Neural networks,[0],[0]
"We set n0 :“ d and nL :“ p, respectively the dimensions of the input and output of the network.",4. Neural networks,[0],[0]
"The output from the lth layer will be denoted by
νplq :“ σplq ˝ ρplq ˝",4. Neural networks,[0],[0]
σpl´1q ˝,4. Neural networks,[0],[0]
ρpl´1q ¨ ¨ ¨ ˝ σp1q ˝ ρp1q,4. Neural networks,[0],[0]
",
i.e., it is a map νplq : Rd Ñ Rnl .",4. Neural networks,[0],[0]
"For convenience, we assume νp0qpxq",4. Neural networks,[0],[0]
":“ x.
The affine function ρplq :",4. Neural networks,[0],[0]
"Rnl´1 Ñ Rnl is given by a weight matrix Aplq P Znlˆnl´1 and a bias vector bplq P Rnl :
ρplqpνpl´1qq :“ Aplqνpl´1q ` bplq.
",4. Neural networks,[0],[0]
"The pi, jqth coordinate of Aplq will be denoted aplqij and the ith coordinate of bplq by bplqi .",4. Neural networks,[0],[0]
"Collectively they form the parameters of the lth layer.
",4. Neural networks,[0],[0]
"For a vector input x P Rnl , σplqpxq is understood to be in coordinatewise sense; so σ",4. Neural networks,[0],[0]
:,4. Neural networks,[0],[0]
Rnl Ñ Rnl .,4. Neural networks,[0],[0]
We assume the final output of a neural network νpxq is fed into a score function s : Rp Ñ Rm that is application specific.,4. Neural networks,[0],[0]
"When used as an m-category classifier, s may be chosen, for example, to be a soft-max or sigmoidal function.",4. Neural networks,[0],[0]
The score function is quite often regarded as the last layer of a neural network but this is purely a matter of convenience and we will not assume this.,4. Neural networks,[0],[0]
"We will make the following mild assumptions on the architecture of our feedforward neural networks and explain next why they are indeed mild:
(a) the weight matrices Ap1q, . . .",4. Neural networks,[0],[0]
", ApLq are integer-valued;
(b) the bias vectors bp1q, . . .",4. Neural networks,[0],[0]
", bpLq are real-valued;
(c) the activation functions σp1q, . . .",4. Neural networks,[0],[0]
", σpLq take the form
σplqpxq :“ maxtx, tplqu,
where tplq P pRYt´8uqnl is called a threshold vector.
",4. Neural networks,[0],[0]
"Henceforth all neural networks in our subsequent discussions will be assumed to satisfy (a)–(c).
",4. Neural networks,[0],[0]
"(b) is completely general but there is also no loss of generality in (a), i.e., in restricting the weights Ap1q, . . .",4. Neural networks,[0],[0]
", ApLq from real matrices to integer matrices, as:
• real weights can be approximated arbitrarily closely by rational weights;
• one may then ‘clear denominators’ in these rational weights by multiplying them by the least common multiple of their denominators to obtain integer weights;
• keeping in mind that scaling all weights and biases by the same positive constant has no bearing on the workings of a neural network.
",4. Neural networks,[0],[0]
The activation function in (c) includes both ReLU activation (tplq “ 0) and identity map (tplq “ ´8) as special cases.,4. Neural networks,[0],[0]
"Aside from ReLU, our tropical framework will apply to piecewise linear activations such as leaky ReLU and absolute value, and with some extra effort, may be extended to max pooling, maxout nets, etc.",4. Neural networks,[0],[0]
"But it does not, for example, apply to activations such as hyperbolic tangent and sigmoid.
",4. Neural networks,[0],[0]
"In this work, we view an ReLU network as the simplest and most canonical model of a neural network, from which other variants that are more effective at specific tasks may be derived.",4. Neural networks,[0],[0]
"Given that we seek general theoretical insights and not specific practical efficacy, it makes sense to limit ourselves to this simplest case.",4. Neural networks,[0],[0]
"Moreover, ReLU networks already embody some of the most important elements (and mysteries) common to a wider range of neural networks (e.g., universal approximation, exponential expressiveness); they work well in practice and are often the go-to choice for feedforward networks.",4. Neural networks,[0],[0]
"We are also not alone in limiting our discussions to ReLU networks (Montufar et al., 2014; Arora et al., 2018).",4. Neural networks,[0],[0]
"We now describe our tropical formulation of a multilayer feedforward neural network satisfying (a)–(c).
",5. Tropical algebra of neural networks,[0],[0]
"A multilayer feedforward neural network is generally nonconvex, whereas a tropical polynomial is always convex.",5. Tropical algebra of neural networks,[0],[0]
"Since most nonconvex functions are a difference of two convex functions (Hartman, 1959), a reasonable guess is that a feedforward neural network is the difference of two tropical polynomials, i.e., a tropical rational function.",5. Tropical algebra of neural networks,[0],[0]
"This is indeed the case, as we will see from the following.
",5. Tropical algebra of neural networks,[0],[0]
"Consider the output from the first layer in neural network
νpxq “ maxtAx` b, tu,
where A P Zpˆd, b P Rp, and t P pR Y t´8uqp.",5. Tropical algebra of neural networks,[0],[0]
"We will decompose A as a difference of two nonnegative integervalued matrices, A “ A`´A´ with A`, A´ P Npˆd; e.g., in the standard way with entries
a`ij :“ maxtaij , 0u, a ´ ij :“ maxt´aij , 0u
respectively.",5. Tropical algebra of neural networks,[0],[0]
"Since
maxtAx` b, tu “ maxtA`x` b, A´x` tu ´A´x,
we see that every coordinate of one-layer neural network is a difference of two tropical polynomials.",5. Tropical algebra of neural networks,[0],[0]
"For networks with more layers, we apply this decomposition recursively to obtain the following result.
",5. Tropical algebra of neural networks,[0],[0]
Proposition 5.1.,5. Tropical algebra of neural networks,[0],[0]
"LetA P Zmˆn, b P Rm be the parameters of the pl ` 1qth layer, and let t P pR Y t´8uqm be the threshold vector in the pl` 1qth layer.",5. Tropical algebra of neural networks,[0],[0]
"If the nodes of the lth layer are given by tropical rational functions,
νplqpxq “ F plqpxq mGplqpxq “ F plqpxq ´Gplqpxq,
i.e., each coordinate of F plq and Gplq is a tropical polynomial in x, then the outputs of the preactivation and of the pl ` 1qth layer are given by tropical rational functions
ρpl`1q ˝ νplqpxq “ Hpl`1qpxq ´Gpl`1qpxq, νpl`1qpxq “ σ ˝ ρpl`1q ˝ νplqpxq “ F pl`1qpxq ´Gpl`1qpxq
respectively, where
F pl`1qpxq “ max Hpl`1qpxq, Gpl`1qpxq ` t ( ,
Gpl`1qpxq “ A`Gplqpxq `A´F plqpxq, Hpl`1qpxq “ A`F plqpxq `A´Gplqpxq ` b.
We will write f plqi ,",5. Tropical algebra of neural networks,[0],[0]
"g plq i and h plq i for the ith coordinate of F plq, Gplq and Hplq respectively.",5. Tropical algebra of neural networks,[0],[0]
"In tropical arithmetic, the recurrence above takes the form
f pl`1q i “ h pl`1q",5. Tropical algebra of neural networks,[0],[0]
"i ‘ pg pl`1q i d tiq,
g pl`1q i “
„ n ä
j“1 pf plqj q",5. Tropical algebra of neural networks,[0],[0]
"a´ij
 d „",5. Tropical algebra of neural networks,[0],[0]
"n ä
j“1 pgplqj q a`ij

,
",5. Tropical algebra of neural networks,[0],[0]
h pl`1q,5. Tropical algebra of neural networks,[0],[0]
"i “
„ n ä
j“1 pf plqj q",5. Tropical algebra of neural networks,[0],[0]
"a`ij
 d „",5. Tropical algebra of neural networks,[0],[0]
"n ä
j“1",5. Tropical algebra of neural networks,[0],[0]
"pgplqj q a´ij

d bi.
(2)
Repeated applications of Proposition 5.1 yield the following.
",5. Tropical algebra of neural networks,[0],[0]
Theorem 5.2 (Tropical characterization of neural networks).,5. Tropical algebra of neural networks,[0],[0]
A feedforward neural network under assumptions (a)–(c) is a function ν,5. Tropical algebra of neural networks,[0],[0]
: Rd Ñ,5. Tropical algebra of neural networks,[0],[0]
"Rp whose coordinates are tropical rational functions of the input, i.e.,
νpxq “ F pxq mGpxq “ F pxq ´Gpxq
where F and G are tropical polynomial maps.",5. Tropical algebra of neural networks,[0],[0]
"Thus ν is a tropical rational map.
",5. Tropical algebra of neural networks,[0],[0]
"Note that the tropical rational functions above have real coefficients, not integer coefficients.",5. Tropical algebra of neural networks,[0],[0]
"The integer weights Aplq P Znlˆnl´1 have gone into the powers of tropical monomials in f and g, which is why we require our weights to be integer-valued, although as we have explained, this requirement imposes little loss of generality.
",5. Tropical algebra of neural networks,[0],[0]
"By setting tp1q “ ¨ ¨ ¨ “ tpL´1q “ 0 and tpLq “ ´8, we obtain the following corollary.
",5. Tropical algebra of neural networks,[0],[0]
Corollary 5.3.,5. Tropical algebra of neural networks,[0],[0]
Let ν :,5. Tropical algebra of neural networks,[0],[0]
Rd Ñ R be an ReLU activated feedforward neural network with integer weights and linear output.,5. Tropical algebra of neural networks,[0],[0]
"Then ν is a tropical rational function.
",5. Tropical algebra of neural networks,[0],[0]
"A more remarkable fact is the converse of Corollary 5.3.
",5. Tropical algebra of neural networks,[0],[0]
"Theorem 5.4 (Equivalence of neural networks and tropical rational functions).
",5. Tropical algebra of neural networks,[0],[0]
(i) Let ν,5. Tropical algebra of neural networks,[0],[0]
": Rd Ñ R. Then ν is a tropical rational function if and only if ν is a feedforward neural network satisfying assumptions (a)–(c).
",5. Tropical algebra of neural networks,[0],[0]
"(ii) A tropical rational function f m g can be represented as an L-layer neural network, with
L ď maxtrlog2 rf s, rlog2 rgsu ` 2,
where rf and rg are the number of monomials in the tropical polynomials f and g respectively.
",5. Tropical algebra of neural networks,[0],[0]
"We would like to acknowledge the precedence of (Arora et al., 2018, Theorem 2.1), which demonstrates the equivalence between ReLU-activatedL-layer neural networks with real weights and d-variate continuous piecewise functions with real coefficients, where L ď rlog2pd` 1qs` 1.
",5. Tropical algebra of neural networks,[0],[0]
"By construction, a tropical rational function is a continuous piecewise linear function.",5. Tropical algebra of neural networks,[0],[0]
The continuity of a piecewise linear function automatically implies that each of the pieces on which it is linear is a polyhedral region.,5. Tropical algebra of neural networks,[0],[0]
"As we saw in Section 3, a tropical polynomial f",5. Tropical algebra of neural networks,[0],[0]
: Rd Ñ R gives a tropical hypersurface that divides Rd into convex polyhedral regions defined by linear inequalities with integer coefficients: tx P Rd :,5. Tropical algebra of neural networks,[0],[0]
Ax ď bu with A P Zmˆd and b P Rm.,5. Tropical algebra of neural networks,[0],[0]
"A tropical rational function f m g : Rd Ñ R must also be a continuous piecewise linear function and divide Rd into polyhedral regions on each of which f m g is linear, although these regions are nonconvex in general.",5. Tropical algebra of neural networks,[0],[0]
"We will show the converse — any continuous piecewise linear function with integer coefficients is a tropical rational function.
",5. Tropical algebra of neural networks,[0],[0]
Proposition 5.5.,5. Tropical algebra of neural networks,[0],[0]
Let ν :,5. Tropical algebra of neural networks,[0],[0]
"Rd Ñ R. Then ν is a continuous piecewise linear function with integer coefficients if and only if ν is a tropical rational function.
",5. Tropical algebra of neural networks,[0],[0]
"Corollary 5.3, Theorem 5.4, and Proposition 5.5 collectively imply the equivalence of
(i) tropical rational functions,
(ii) continuous piecewise linear functions with integer coefficients,
(iii) neural networks satisfying assumptions (a)–(c).
",5. Tropical algebra of neural networks,[0],[0]
"An immediate advantage of this characterization is that the set of tropical rational functions Tpx1, . . .",5. Tropical algebra of neural networks,[0],[0]
", xdq has a semifield structure as we pointed out in Section 2, a fact that we have implicitly used in the proof of Proposition 5.5.",5. Tropical algebra of neural networks,[0],[0]
"However, what is more important is not the algebra but the
algebraic geometry that arises from our tropical characterization.",5. Tropical algebra of neural networks,[0],[0]
"We will use tropical algebraic geometry to illuminate our understanding of neural networks in the next section.
",5. Tropical algebra of neural networks,[0],[0]
The need to stay within tropical algebraic geometry is the reason we did not go for a simpler and more general characterization (that does not require the integer coefficients assumption).,5. Tropical algebra of neural networks,[0],[0]
"A tropical signomial takes the form
ϕpxq “ m à
i“1 bi
n ä j“1",5. Tropical algebra of neural networks,[0],[0]
"x aij j ,
where aij P R and bi P R Y t´8u.",5. Tropical algebra of neural networks,[0],[0]
Note that aij is not required to be integer-valued nor nonnegative.,5. Tropical algebra of neural networks,[0],[0]
"A tropical rational signomial is a tropical quotientϕmψ of two tropical signomials ϕ,ψ.",5. Tropical algebra of neural networks,[0],[0]
"A tropical rational signomial map is a function ν “ pν1, . . .",5. Tropical algebra of neural networks,[0],[0]
", νpq :",5. Tropical algebra of neural networks,[0],[0]
Rd Ñ Rp where each νi : Rd Ñ R is a tropical rational signomial νi “ ϕi m ψi.,5. Tropical algebra of neural networks,[0],[0]
The same argument we used to establish Theorem 5.2 gives us the following.,5. Tropical algebra of neural networks,[0],[0]
Proposition 5.6.,5. Tropical algebra of neural networks,[0],[0]
"Every feedforward neural network with ReLU activation is a tropical rational signomial map.
",5. Tropical algebra of neural networks,[0],[0]
Nevertheless tropical signomials fall outside the realm of tropical algebraic geometry and we do not use Proposition 5.6 in the rest of this article.,5. Tropical algebra of neural networks,[0],[0]
"Section 5 defines neural networks via tropical algebra, a perspective that allows us to study them via tropical algebraic geometry.",6. Tropical geometry of neural networks,[0],[0]
We will show that the decision boundary of a neural network is a subset of a tropical hypersurface of a corresponding tropical polynomial (Section 6.1).,6. Tropical geometry of neural networks,[0],[0]
"We will see that, in an appropriate sense, zonotopes form the geometric building blocks for neural networks (Section 6.2).",6. Tropical geometry of neural networks,[0],[0]
We then prove that the geometry of the function represented by a neural network grows vastly more complex as its number of layers increases (Section 6.3).,6. Tropical geometry of neural networks,[0],[0]
"We will use tropical geometry and insights from Section 5 to study decision boundaries of neural networks, focusing on the case of two-category classification for clarity.",6.1. Decision boundaries of a neural network,[0],[0]
"As explained in Section 4, a neural network ν :",6.1. Decision boundaries of a neural network,[0],[0]
Rd Ñ Rp together with a choice of score function s :,6.1. Decision boundaries of a neural network,[0],[0]
Rp Ñ R give us a classifier.,6.1. Decision boundaries of a neural network,[0],[0]
"If the output value spνpxqq exceeds some decision threshold c, then the neural network predicts x is from one class (e.g., x is a CAT image), and otherwise x is from the other category (e.g., a DOG image).",6.1. Decision boundaries of a neural network,[0],[0]
The input space is thereby partitioned into two disjoint subsets by the decision boundary B :“ tx P Rd : νpxq “ s´1pcqu.,6.1. Decision boundaries of a neural network,[0],[0]
"Connected regions with value above the threshold and connected regions with value below the threshold will be called the positive regions and negative regions respectively.
",6.1. Decision boundaries of a neural network,[0],[0]
"We provide bounds on the number of positive and negative regions and show that there is a tropical polynomial whose tropical hypersurface contains the decision boundary.
",6.1. Decision boundaries of a neural network,[0],[0]
Proposition 6.1 (Tropical geometry of decision boundary).,6.1. Decision boundaries of a neural network,[0],[0]
Let ν :,6.1. Decision boundaries of a neural network,[0],[0]
Rd Ñ R be an L-layer neural network satisfying assumptions (a)–(c) with tpLq “ ´8.,6.1. Decision boundaries of a neural network,[0],[0]
Let the score function s : RÑ R be injective with decision threshold c in its range.,6.1. Decision boundaries of a neural network,[0],[0]
"If ν “ f m g where f and g are tropical polynomials, then
(i) its decision boundary B “ tx P Rd : νpxq “ s´1pcqu divides Rd into at most N pfq connected positive regions and at most N pgq connected negative regions;
(ii) its decision boundary is contained in the tropical hypersurface of the tropical polynomial s´1pcq d gpxq ‘ fpxq “ maxtfpxq, gpxq ` s´1pcqu, i.e.,
B Ď T ps´1pcq d g ‘ fq.",6.1. Decision boundaries of a neural network,[0],[0]
"(3)
",6.1. Decision boundaries of a neural network,[0],[0]
The function s´1pcqdg‘f is not necessarily linear on every positive or negative region and so its tropical hypersurface T ps´1pcqdg‘fqmay further divide a positive or negative region derived from B into multiple linear regions.,6.1. Decision boundaries of a neural network,[0],[0]
Hence the “Ď” in (3) cannot in general be replaced by ““”.,6.1. Decision boundaries of a neural network,[0],[0]
"From Section 3, we know that the number of regions a tropical hypersurface T pfq divides the space into equals the number of vertices in the dual subdivision of the Newton polygon associated with the tropical polynomial f .",6.2. Zonotopes as geometric building blocks of neural networks,[0.9501101822633888],['We model the monthly temperature change of each grid point as a linear model of the first three lagged values of all explanatory variables in the surrounding 3⇥ 3 grid.']
"This allows us to bound the number of linear regions of a neural network by bounding the number of vertices in the dual subdivision of the Newton polygon.
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"We start by examining how geometry changes from one layer to the next in a neural network, more precisely:
Question.",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"How are the tropical hypersurfaces of the tropical polynomials in the pl ` 1qth layer of a neural network related to those in the lth layer?
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"The recurrent relation (2) describes how the tropical polynomials occurring in the pl ` 1qth layer are obtained from those in the lth layer, namely, via three operations: tropical sum, tropical product, and tropical powers.",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"Recall that a tropical hypersurface of a tropical polynomial is dual to the dual subdivision of the Newton polytope of the tropical polynomial, which is given by the projection of the upper faces on the polytopes defined by (1).",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"Hence the question boils down to how these three operations transform the polytopes, which is addressed in Propositions 3.1 and 3.2.",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"We follow notations in Proposition 5.1 for the next result.
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
Lemma 6.2.,6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"Let f plqi ,",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"g plq i , h plq i be the tropical polynomials produced by the ith node in the lth layer of a neural network,
i.e., they are defined by (2).",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"Then P ` f plq i ˘ , P ` g plq i ˘ , P ` h plq",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"i ˘ are subsets of Rd`1 given as follows:
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"(i) P ` g p1q i ˘ and P ` h p1q i ˘ are points.
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"(ii) P ` f p1q i ˘ is a line segment.
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
(iii) P ` g p2q,6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
i ˘ and P ` h p2q i ˘ are zonotopes.,6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"(iv) For l ě 1,
P ` f plq i ˘ “ Conv “ P ` g plq i d t plq",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
i ˘ Y P ` h plq,6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"i ˘‰
if tplqi P R, and P ` f plq",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"i ˘ “ P ` h plq i ˘ if tplqi “ ´8.
(v) For l ě 1, P ` g pl`1q i ˘ and P ` h pl`1q i ˘
are weighted Minkowski sums,
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"P ` g pl`1q i ˘
“ nl ÿ
j“1 a´ijP ` f plq j ˘
` nl ÿ
j“1 a`ijP",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"` g plq j ˘ ,
P ` h pl`1q",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"i ˘
“ nl ÿ
j“1 a`ijP ` f plq j ˘
` nl ÿ
j“1 a´ijP",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"` g plq j ˘
` tbieu,
where aij , bi are entries of the weight matrix Apl`1q P Znl`1ˆnl and bias vector bpl`1q P Rnl`1 , and e :“ p0, . . .",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
", 0, 1q P Rd`1.
",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
A conclusion of Lemma 6.2 is that zonotopes are the building blocks in the tropical geometry of neural networks.,6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"Zonotopes are studied extensively in convex geometry and, among other things, are intimately related to hyperplane arrangements (Greene & Zaslavsky, 1983; Guibas et al., 2003; McMullen, 1971; Holtz & Ron, 2011).",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
Lemma 6.2 connects neural networks to this extensive body of work but its full implication remains to be explored.,6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"In Section C.2 of the supplement, we show how one may build these polytopes for a two-layer neural network.",6.2. Zonotopes as geometric building blocks of neural networks,[0],[0]
"We apply the tools in Section 3 to study the complexity of a neural network, showing that a deep network is much more expressive than a shallow one.",6.3. Geometric complexity of deep neural networks,[0],[0]
"Our measure of complexity is geometric: we will follow (Montufar et al., 2014; Raghu et al., 2017) and use the number of linear regions of a piecewise linear function ν :",6.3. Geometric complexity of deep neural networks,[0],[0]
"Rd Ñ Rp to measure the complexity of ν.
",6.3. Geometric complexity of deep neural networks,[0],[0]
"We would like to emphasize that our upper bound below does not improve on that obtained in (Raghu et al., 2017) — in fact, our version is more restrictive given that it applies only to neural networks satisfying (a)–(c).",6.3. Geometric complexity of deep neural networks,[0],[0]
"Nevertheless our goal here is to demonstrate how tropical geometry may be used to derive the same bound.
",6.3. Geometric complexity of deep neural networks,[0],[0]
Theorem 6.3.,6.3. Geometric complexity of deep neural networks,[0],[0]
Let ν :,6.3. Geometric complexity of deep neural networks,[0],[0]
Rd Ñ R be an L-layer real-valued feedforward neural network satisfying (a)–(c).,6.3. Geometric complexity of deep neural networks,[0],[0]
"Let tpLq “
´8 and nl ě d for all l “ 1, . . .",6.3. Geometric complexity of deep neural networks,[0],[0]
", L ´ 1.",6.3. Geometric complexity of deep neural networks,[0],[0]
"Then ν “ νpLq has at most
L´1 ź
l“1
d ÿ i“0",6.3. Geometric complexity of deep neural networks,[0],[0]
pnl,6.3. Geometric complexity of deep neural networks,[0],[0]
"i q
linear regions.",6.3. Geometric complexity of deep neural networks,[0],[0]
"In particular, if d ď n1, . . .",6.3. Geometric complexity of deep neural networks,[0],[0]
", nL´1 ď n, the number of linear regions of ν is bounded by O ` ndpL´1q ˘ .
",6.3. Geometric complexity of deep neural networks,[0],[0]
Proof.,6.3. Geometric complexity of deep neural networks,[0],[0]
"If L “ 2, this follows directly from Lemma 6.2 and Corollary 3.4.",6.3. Geometric complexity of deep neural networks,[0],[0]
"The case of L ě 3 is in Section D.7 in the supplement.
",6.3. Geometric complexity of deep neural networks,[0],[0]
"As was pointed out in (Raghu et al., 2017), this upper bound closely matches the lower bound Ω ` pn{dqpL´1qdnd ˘ in (Montufar et al., 2014, Corollary 5) when n1 “ ¨ ¨ ¨ “ nL´1 “ n",6.3. Geometric complexity of deep neural networks,[0],[0]
ě d.,6.3. Geometric complexity of deep neural networks,[0],[0]
Hence we surmise that the number of linear regions of the neural network grows polynomially with the width n and exponentially with the number of layers L.,6.3. Geometric complexity of deep neural networks,[0],[0]
"We argue that feedforward neural networks with rectified linear units are, modulo trivialities, nothing more than tropical rational maps.",7. Conclusion,[0],[0]
"To understand them we often just need to understand the relevant tropical geometry.
",7. Conclusion,[0],[0]
"In this article, we took a first step to provide a proof-ofconcept: questions regarding decision boundaries, linear regions, how depth affect expressiveness, etc, can be translated into questions involving tropical hypersurfaces, dual subdivision of Newton polygon, polytopes constructed from zonotopes, etc.
",7. Conclusion,[0],[0]
"As a new branch of algebraic geometry, the novelty of tropical geometry stems from both the algebra and geometry as well as the interplay between them.",7. Conclusion,[0],[0]
It has connections to many other areas of mathematics.,7. Conclusion,[0],[0]
"Among other things, there is a tropical analogue of linear algebra (Butkovič, 2010) and a tropical analogue of convex geometry (Gaubert & Katz, 2006).",7. Conclusion,[0],[0]
We cannot emphasize enough that we have only touched on a small part of this rich subject.,7. Conclusion,[0],[0]
We hope that further investigation from this tropical angle might perhaps unravel other mysteries of deep neural networks.,7. Conclusion,[0],[0]
"The authors thank Ralph Morrison, Yang Qi, Bernd Sturmfels, and the anonymous referees for their very helpful comments.",Acknowledgments,[0],[0]
"The work in this article is generously supported by DARPA D15AP00109, NSF IIS 1546413, the Eckhardt Faculty Fund, and a DARPA Director’s Fellowship.",Acknowledgments,[0],[0]
"As in Section 2, we write xa “ xda; aside from this slight abuse of notation, ‘ and d denote tropical sum and product, ` and ¨ denote standard sum and product in all other contexts.",B. Tropical power,[0],[0]
"Tropical power evidently has the following properties:
• For x, y P R and a P R, a ě 0,
px‘ yqa “ xa ‘ ya and pxd yqa “ xa d ya.
",B. Tropical power,[0],[0]
"If a is allowed negative values, then we lose the first property.",B. Tropical power,[0],[0]
In general px‘ yqa ‰ xa ‘ ya for a ă 0.,B. Tropical power,[0],[0]
•,B. Tropical power,[0],[0]
"For x P R,
x0 “ 0.
•",B. Tropical power,[0],[0]
"For x P R and a, b P N, pxaqb “ xa¨b.
•",B. Tropical power,[0],[0]
"For x P R and a, b P Z, xa d xb “ xa`b.
•",B. Tropical power,[0],[0]
"For x P R and a, b P Z, xa ‘ xb “ xa d pxa´b ‘ 0q “ xa d p0‘ xa´bq.",B. Tropical power,[0],[0]
C.1.,C. Examples,[0],[0]
"Examples of tropical curves and dual subdivision of Newton polygon
Let f P Polp2, 1q “ Trx1, x2s, i.e., a bivariate tropical polynomial.",C. Examples,[0],[0]
"It follows from our discussions in Section 3 that the tropical hypersurface T pfq is a planar graph dual to the dual subdivision δpfq in the following sense:
(i)",C. Examples,[0],[0]
Each two-dimensional face in δpfq corresponds to a vertex in T pfq.,C. Examples,[0],[0]
(ii) Each one-dimensional edge of a face in δpfq corresponds to an edge in T pfq.,C. Examples,[0],[0]
"In particular, an edge from the Newton
polygon ∆pfq corresponds to an unbounded edge in T pfq while other edges correspond to bounded edges.
",C. Examples,[0],[0]
"Figure 2 illustrates how we may find the dual subdivision for the tropical polynomial fpx1, x2q",C. Examples,[0],[0]
“,C. Examples,[0],[0]
1d x21 ‘ 1d x22 ‘ 2d x1x2,C. Examples,[0],[0]
‘ 2d x1 ‘ 2d x2 ‘ 2.,C. Examples,[0],[0]
"First, find the convex hull
Ppfq “ Convtp2, 0, 1q, p0, 2, 1q, p1, 1, 2q, p1, 0, 2q, p0, 1, 2q, p0, 0, 2qu.
",C. Examples,[0],[0]
"Then, by projecting the upper envelope of Ppfq to R2, we obtain δpfq, the dual subdivision of the Newton polygon.
",C. Examples,[0],[0]
C.2.,C. Examples,[0],[0]
"Polytopes of a two-layer neural network
We illustrate our discussions in Section 6.2 with a two-layer example.",C. Examples,[0],[0]
"Let ν : R2 Ñ R be with n0 “ 2 input nodes, n1 “ 5 nodes in the first layer, and n2 “ 1 nodes in the output:
y “ νp1qpxq “ max
$
’ ’ ’ ’ &
’ ’ ’ ’",C. Examples,[0],[0]
"%
»
— — — — –
´1 1 1 ´3 1 2 ´4 1 3 2
fi
ffi ffi ffi ffi",C. Examples,[0],[0]
"fl „ x1 x2  `
»
— — — — –
1 ´1
2 0 ´2
fi
ffi ffi ffi ffi",C. Examples,[0],[0]
"fl , 0
,
/ / / / .
/ / / / -
,
νp2qpyq",C. Examples,[0],[0]
"“ maxty1 ` 2y2 ` y3 ´ y4 ´ 3y5, 0u.
We first express νp1q and νp2q as tropical rational maps,
νp1q “ F p1q mGp1q, νp2q “ f p2q m gp2q,
where
y :“ F p1qpxq “ Hp1qpxq ‘Gp1qpxq,
z :“ Gp1qpxq “
»
— — — — – x1 x32 0",C. Examples,[0],[0]
"x41 0
fi
ffi ffi ffi ffi",C. Examples,[0],[0]
"fl , Hp1qpxq “
»
— — — — –
1d x2 p´1q",C. Examples,[0],[0]
"d x1 2d x1x22
x2 p´2q",C. Examples,[0],[0]
"d x31x22
fi
ffi ffi ffi ffi",C. Examples,[0],[0]
"fl ,
and
f p2qpxq “ gp2qpxq ‘ hp2qpxq, gp2qpxq",C. Examples,[0],[0]
“ y4 d y35 d z1 d z22 d z3 “ px2 ‘ x41q d pp´2q d x31x22,C. Examples,[0],[0]
"‘ 0q3 d x1 d px32q2, hp2qpxq “ y1 d y22 d y3 d z4 d z35
“ p1d x2 ‘ x1q d pp´1q",C. Examples,[0],[0]
"d x1 ‘ x32q2 d p2d x1x22 ‘ 0q d x41.
",C. Examples,[0],[0]
"We will write F p1q “ pf p1q1 , . . .",C. Examples,[0],[0]
", f p1q 5 q and likewise for Gp1q and Hp1q.",C. Examples,[0],[0]
The monomials occurring in g p1q j pxq and h p1q,C. Examples,[0],[0]
j pxq are all of the form cxa11 x a2 2 .,C. Examples,[0],[0]
"Therefore Ppg p1q j q and Pph p1q j q, j “ 1, . . .",C. Examples,[0],[0]
", 5, are points in R3.
",C. Examples,[0],[0]
"Since F p1q “ Gp1q ‘Hp1q, Ppf p1qj q is a convex hull of two points, and thus a line segment in R3.",C. Examples,[0],[0]
"The Newton polygons associated with f p1qj , equal to their dual subdivisions in this case, are obtained by projecting these line segments back to the plane spanned by a1, a2, as shown on the left in Figure C.1.
",C. Examples,[0],[0]
"The line segments Ppf p1qj q, j “ 1, . . .",C. Examples,[0],[0]
", 5, and points Ppg p1q j q, j “ 1, . . .",C. Examples,[0],[0]
", 5, serve as building blocks for Pphp2qq and Ppgp2qq, which are constructed as weighted Minkowski sums:
Pphp2qq “ Ppf p1q4 q ` 3Ppf p1q 5 q ` Ppg p1q 1 q ` 2Ppg p1q 2 q",C. Examples,[0],[0]
"` Ppg p1q 3 q, Ppgp2qq “ Ppf p1q1 q ` 2Ppf p1q 2 q",C. Examples,[0],[0]
` Ppf p1q 3 q,C. Examples,[0],[0]
"` Ppg p1q 4 q ` 3Ppg p1q 5 q.
Ppgp2qq and the dual subdivision of its Newton polygon are shown on the right in Figure C.1.",C. Examples,[0],[0]
Pphp2qq and the dual subdivision of its Newton polygon are shown on the left in Figure C.2.,C. Examples,[0],[0]
Ppf p2qq is the convex hull of the union of Ppgp2qq and Pphp2qq.,C. Examples,[0],[0]
"The dual subdivision of its Newton polygon is obtained by projecting the upper faces of Ppf p2qq to the plane spanned by a1, a2.",C. Examples,[0],[0]
These are shown on the right in Figure C.2.,C. Examples,[0],[0]
Proof.,D.1. Proof of Corollary 3.4,[0],[0]
Let V1 and V2 be the sets of vertices on the upper and lower envelopes of P respectively.,D.1. Proof of Corollary 3.4,[0],[0]
"By Theorem 3.3, P has
n1 :“ 2 d ÿ j“0 pm",D.1. Proof of Corollary 3.4,[0],[0]
´,D.1. Proof of Corollary 3.4,[0],[0]
"1j q
vertices in total.",D.1. Proof of Corollary 3.4,[0],[0]
"By construction, we have |V1 Y V2| “ n1.",D.1. Proof of Corollary 3.4,[0],[0]
"It is well-known that zonotopes are centrally symmetric and so there are equal number of vertices on the upper and lower envelopes, i.e., |V1| “ |V2|.",D.1. Proof of Corollary 3.4,[0],[0]
Let P 1 :“ πpP q be the projection of P into Rd.,D.1. Proof of Corollary 3.4,[0],[0]
"Since the projected vertices are assumed to be in general positions, P 1 must be a d-dimensional zonotope generated by m nonparallel line segments.",D.1. Proof of Corollary 3.4,[0],[0]
"Hence, by Theorem 3.3 again, P 1 has
n2 :“ 2 d´1 ÿ j“0 pm",D.1. Proof of Corollary 3.4,[0],[0]
´,D.1. Proof of Corollary 3.4,[0],[0]
"1j q
vertices.",D.1. Proof of Corollary 3.4,[0],[0]
"For any vertex v P P , πpvq is a vertex of P 1 if and only if v belongs to both the upper and lower envelopes, i.e., v P V1 X V2.",D.1. Proof of Corollary 3.4,[0],[0]
Therefore the number of vertices on P 1 equals |V1 X V2|.,D.1. Proof of Corollary 3.4,[0],[0]
"By construction, we have |V1 X V2| “ n2.",D.1. Proof of Corollary 3.4,[0],[0]
"Consequently the number of vertices on the upper envelope is
|V1| “ 1
2 p|V1 Y V2| ´ |V1 X V2|q ` |V1 X V2| “
1 2 pn1 ´ n2q ` n2 “
d ÿ j“0 pmj q .",D.1. Proof of Corollary 3.4,[0],[0]
Proof.,D.2. Proof of Proposition 5.1,[0],[0]
"Writing A “ A` ´A´, we have
ρpl`1qpxq “ ` A` ´A´ ˘` F plqpxq ´Gplqpxq ˘ ` b “ ` A`F plqpxq `A´Gplqpxq ` b ˘ ´ ` A`G plqpxq `A´F plqpxq ˘
“ Hpl`1qpxq ´Gpl`1qpxq, νpl`1qpxq “ max ρpl`1qpyq, t (
“ max Hpl`1qpxq ´Gpl`1qpxq, t (
“ max Hpl`1qpxq, Gpl`1qpxq ` t ( ´Gpl`1qpxq “ F pl`1qpxq ´Gpl`1qpxq.",D.2. Proof of Proposition 5.1,[0],[0]
Proof.,D.3. Proof of Theorem 5.4,[0],[0]
It remains to establish the “only if” part.,D.3. Proof of Theorem 5.4,[0],[0]
"We will write σtpxq :“ maxtx, tu.",D.3. Proof of Theorem 5.4,[0],[0]
"Any tropical monomial bixαi is clearly such a neural network as
bix αi “ pσ´8 ˝ ρiqpxq “ maxtαTix` bi,´8u.
",D.3. Proof of Theorem 5.4,[0],[0]
"If two tropical polynomials p and q are represented as neural networks with lp and lq layers respectively,
ppxq “ ` σ´8 ˝ ρplpqp ˝ σ0 ˝ . . .",D.3. Proof of Theorem 5.4,[0],[0]
σ0 ˝,D.3. Proof of Theorem 5.4,[0],[0]
"ρp1qp ˘ pxq, qpxq “ `
σ´8 ˝ ρplqqq ˝ σ0 ˝ . . .",D.3. Proof of Theorem 5.4,[0],[0]
σ0 ˝,D.3. Proof of Theorem 5.4,[0],[0]
"ρp1qq ˘ pxq,
then pp‘ qqpxq “ maxtppxq, qpxqu can also be written as a neural network with maxtlp, lqu ` 1 layers:
pp‘ qqpxq “ σ´8 ` rσ0 ˝ ρ1spypxqq ` rσ0 ˝ ρ2spypxqq ´ rσ0 ˝ ρ3spypxqq ˘ ,
where y : Rd Ñ R2 is given by ypxq “ pppxq, qpxqq and ρi : R2 Ñ R, i “ 1, 2, 3, are linear functions defined by
ρ1pyq",D.3. Proof of Theorem 5.4,[0],[0]
"“ y1 ´ y2, ρ2pyq “ y2, ρ3pyq",D.3. Proof of Theorem 5.4,[0],[0]
"“ ´y2.
",D.3. Proof of Theorem 5.4,[0],[0]
"Thus, by induction, any tropical polynomial can be written as a neural network with ReLU activation.",D.3. Proof of Theorem 5.4,[0],[0]
"Observe also that if a tropical polynomial is the tropical sum of r monomials, then it can be written as a neural network with no more than rlog2 rs` 1 layers.
",D.3. Proof of Theorem 5.4,[0],[0]
Next we consider a tropical rational function ppm qqpxq “ ppxq ´ qpxq where p and q are tropical polynomials.,D.3. Proof of Theorem 5.4,[0],[0]
"Under the same assumptions, we can represent pm q",D.3. Proof of Theorem 5.4,[0],[0]
"as
ppm qqpxq “ σ´8 ` rσ0 ˝ ρ4spypxqq ´ rσ0 ˝ ρ5spypxqq ` rσ0 ˝ ρ6spypxqq ´ rσ0 ˝ ρ7spypxqq ˘
where ρi : R2 Ñ R2, i “ 4, 5, 6, 7, are linear functions defined by
ρ4pyq “ y1, ρ5pyq",D.3. Proof of Theorem 5.4,[0],[0]
"“ ´y1, ρ6pyq",D.3. Proof of Theorem 5.4,[0],[0]
"“ ´y2, ρ7pyq “ y2.
",D.3. Proof of Theorem 5.4,[0],[0]
"Therefore pm q is also a neural network with at most maxtlp, lqu ` 1 layers.
",D.3. Proof of Theorem 5.4,[0],[0]
"Finally, if f and g are tropical polynomials that are respectively tropical sums of rf and rg monomials, then the discussions above show that pf m gqpxq “ fpxq ´ gpxq is a neural network with at most maxtrlog2 rf s, rlog2 rgsu ` 2 layers.",D.3. Proof of Theorem 5.4,[0],[0]
Proof.,D.4. Proof of Proposition 5.5,[0],[0]
It remains to establish the “if” part.,D.4. Proof of Proposition 5.5,[0],[0]
"Let Rd be divided into N polyhedral region on each of which ν restricts to a linear function `ipxq “ aTix` bi, ai P Zd, bi P R, i “ 1, . . .",D.4. Proof of Proposition 5.5,[0],[0]
", L, i.e., for any x P Rd, νpxq “ `ipxq for some i P t1, . . .",D.4. Proof of Proposition 5.5,[0],[0]
", Lu.",D.4. Proof of Proposition 5.5,[0],[0]
"It follows from (Tarela & Martinez, 1999) that we can find N subsets of t1, . . .",D.4. Proof of Proposition 5.5,[0],[0]
", Lu, denoted by Sj , j “ 1, . . .",D.4. Proof of Proposition 5.5,[0],[0]
", N , so that ν has a representation
νpxq “ max j“1,...,N min iPSj `i.
It is clear that each `i is a tropical rational function.",D.4. Proof of Proposition 5.5,[0],[0]
"Now for any tropical rational functions p and q,
mintp, qu “ ´maxt´p,´qu “ 0m rp0m pq ‘ p0m qqs “ rpd qs m rp‘ qs.
",D.4. Proof of Proposition 5.5,[0],[0]
"Since pd q and p‘ q are both tropical rational functions, so is their tropical quotient.",D.4. Proof of Proposition 5.5,[0],[0]
"By induction, miniPSj `i is a tropical rational function for any j “ 1, . . .",D.4. Proof of Proposition 5.5,[0],[0]
", N , and therefore so is their tropical sum ν.",D.4. Proof of Proposition 5.5,[0],[0]
Proof.,D.5. Proof of Proposition 5.6,[0],[0]
"For a one-layer neural network νpxq “ maxtAx ` b, tu “ pν1pxq, . . .",D.5. Proof of Proposition 5.6,[0],[0]
", νppxqq with A P Rpˆd, b P Rp, x P Rd, t P pRY t´8uqp, we have
νkpxq “ ˆ",D.5. Proof of Proposition 5.6,[0],[0]
bk,D.5. Proof of Proposition 5.6,[0],[0]
"d d ä
j“1 x akj j
˙ ‘ tk “ ˆ bk",D.5. Proof of Proposition 5.6,[0],[0]
"d d ä
j“1 x akj j
˙ ‘ ˆ tk d d ä
j“1 x0j
˙
, k “ 1, . . .",D.5. Proof of Proposition 5.6,[0],[0]
", p.
",D.5. Proof of Proposition 5.6,[0],[0]
"So for any k “ 1, . .",D.5. Proof of Proposition 5.6,[0],[0]
.,D.5. Proof of Proposition 5.6,[0],[0]
", p, if we write b̄1 “ bk, b̄2 “ tk, ā1j “ akj , ā2j “ 0, j “ 1, . . .",D.5. Proof of Proposition 5.6,[0],[0]
", d, then
νkpxq “ 2 à
i“1 b̄i
d ä j“1",D.5. Proof of Proposition 5.6,[0],[0]
"x āij j
is clearly a tropical signomial function.",D.5. Proof of Proposition 5.6,[0],[0]
Therefore ν is a tropical signomial map.,D.5. Proof of Proposition 5.6,[0],[0]
"The result for arbitrary number of layers then follows from using the same recurrence as in the proof in Section D.2, except that now the entries in the weight matrix are allowed to take real values, and the maps Hplqpxq, Gplqpxq, F plqpxq are tropical signomial maps.",D.5. Proof of Proposition 5.6,[0],[0]
Hence every layer can be written as a tropical rational signomial map νplq “ F plq mGplq.,D.5. Proof of Proposition 5.6,[0],[0]
"We prove a slightly more general result.
",D.6. Proof of Proposition 6.1,[0],[0]
Proposition D.1 (Level sets).,D.6. Proof of Proposition 6.1,[0],[0]
"Let f m g P Ratpd, 1q “ Tpx1, . . .",D.6. Proof of Proposition 6.1,[0],[0]
", xdq.
(i)",D.6. Proof of Proposition 6.1,[0],[0]
"Given a constant c ą 0, the level set B :“ tx P Rd : fpxq m gpxq “ cu
divides Rd into at most N pfq connected polyhedral regions where fpxq m gpxq ą c, and at most N pgq such regions where fpxq m gpxq ă c.
(ii)",D.6. Proof of Proposition 6.1,[0],[0]
"If c P R is such that there is no tropical monomial in fpxq that differs from any tropical monomial in gpxq by c, then the level set B is contained in a tropical hypersurface,
B Ď T pmaxtfpxq, gpxq ` cuq “ T pcd g ‘ fq.
",D.6. Proof of Proposition 6.1,[0],[0]
Proof.,D.6. Proof of Proposition 6.1,[0],[0]
"We show that the bounds on the numbers of connected positive (i.e., above c) and negative (i.e., below c) regions are as we claimed in (i).",D.6. Proof of Proposition 6.1,[0],[0]
"The tropical hypersurface of f divides Rd into N pfq convex regions C1, . . .",D.6. Proof of Proposition 6.1,[0],[0]
", CN pfq such that f is linear on each Ci.",D.6. Proof of Proposition 6.1,[0],[0]
"As g is piecewise linear and convex over Rd, f m g “ f ´ g is piecewise linear and concave on each Ci.",D.6. Proof of Proposition 6.1,[0],[0]
Since the level set tx : fpxq ´ gpxq “ cu and the superlevel set tx : fpxq ´ gpxq ě cu must be convex by the concavity of f,D.6. Proof of Proposition 6.1,[0],[0]
"´ g, there is at most one positive region in each Ci.",D.6. Proof of Proposition 6.1,[0],[0]
Therefore the total number of connected positive regions cannot exceed N pfq.,D.6. Proof of Proposition 6.1,[0],[0]
"Likewise, the tropical hypersurface of g divides Rd into N pgq convex regions on each of which f m g is convex.",D.6. Proof of Proposition 6.1,[0],[0]
"The same argument shows that the number of connected negative regions does not exceed N pgq.
",D.6. Proof of Proposition 6.1,[0],[0]
We next address (ii).,D.6. Proof of Proposition 6.1,[0],[0]
"Upon rearranging terms, the level set becomes
B “ x P Rd : fpxq “ gpxq ` c ( .
",D.6. Proof of Proposition 6.1,[0],[0]
"Since fpxq and gpxq ` c are both tropical polynomial, we have
fpxq “ b1xα1 ‘ ¨ ¨ ¨ ‘ brxαr , gpxq ` c “ c1xβ1 ‘ ¨ ¨ ¨ ‘ csxβs ,
with appropriate multiindices α1, . . .",D.6. Proof of Proposition 6.1,[0],[0]
", αr, β1, . . .",D.6. Proof of Proposition 6.1,[0],[0]
", βs, and real coefficients b1, . . .",D.6. Proof of Proposition 6.1,[0],[0]
", br, c1, . . .",D.6. Proof of Proposition 6.1,[0],[0]
", cs.",D.6. Proof of Proposition 6.1,[0],[0]
"By the assumption on the monomials, we have that x0 P B only if there exist i, j so that αi ‰ βj",D.6. Proof of Proposition 6.1,[0],[0]
and bixαi0 “ cjx βj 0 .,D.6. Proof of Proposition 6.1,[0],[0]
"This completes the proof since if we combine the monomials of fpxq and gpxq ` c by (tropical) summing them into a single tropical polynomial, maxtfpxq, gpxq ` cu, the above implies that on the level set, the value of the combined tropical polynomial is attained by at least two monomials and therefore x0 P T pmaxtfpxq, gpxq ` cuq.
",D.6. Proof of Proposition 6.1,[0],[0]
Proposition 6.1 follows immediately from Proposition D.1 since the decision boundary tx P Rd : νpxq “ s´1pcqu is a level set of the tropical rational function ν.,D.6. Proof of Proposition 6.1,[0],[0]
"The linear regions of a tropical polynomial map F P Polpd,mq are all convex but this is not necessarily the case for a tropical rational map F P Ratpd, nq.",D.7. Proof of Theorem 6.3,[0],[0]
"Take for example a bivariate real-valued function fpx, yq whose graph in R3 is a pyramid with base tpx, yq P R2 : x, y P r´1, 1su and zero everywhere else, then the linear region where f vanishes is R2ztpx, yq P R2 : x,",D.7. Proof of Theorem 6.3,[0],[0]
"y P r´1, 1su, which is nonconvex.",D.7. Proof of Theorem 6.3,[0],[0]
The nonconvexity invalidates certain geometric arguments that only apply in the convex setting.,D.7. Proof of Theorem 6.3,[0],[0]
Nevertheless there is a way to subdivide each of the nonconvex linear regions into convex ones to get ourselves back into the convex setting.,D.7. Proof of Theorem 6.3,[0],[0]
"We will start with the number of convex linear regions for tropical rational maps although later we will deduce the required results for the number of linear regions (without imposing convexity).
",D.7. Proof of Theorem 6.3,[0],[0]
We first extend the notion of tropical hypersurface to tropical rational maps:,D.7. Proof of Theorem 6.3,[0],[0]
"Given a tropical rational map F P Ratpd,mq, we define T pF q to be the boundaries between adjacent linear regions.",D.7. Proof of Theorem 6.3,[0],[0]
"When F “ pf1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", fmq P Polpd,mq, i.e., a tropical polynomial map, this set is exactly the union of tropical hypersurfaces T pfiq, i “ 1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
",m. Therefore this definition of T pF q extends Definition 3.1.
",D.7. Proof of Theorem 6.3,[0],[0]
"For a tropical rational map F , we will examine the smallest number of convex regions that form a refinement of T pF q. For brevity, we will call this the convex degree of F ; for consistency, the number of linear regions of F we will call its linear degree.",D.7. Proof of Theorem 6.3,[0],[0]
We define convex degree formally below.,D.7. Proof of Theorem 6.3,[0],[0]
We will write F |C to mean the restriction of map F to C Ď Rd.,D.7. Proof of Theorem 6.3,[0],[0]
Definition D.1.,D.7. Proof of Theorem 6.3,[0],[0]
"The convex degree of a tropical rational map F P Ratpd, nq is the minimum division of Rd into convex regions over which F is linear, i.e.
NcpF q",D.7. Proof of Theorem 6.3,[0],[0]
":“ min n : C1 Y ¨ ¨ ¨ Y Cn “ Rd, Ci convex, F |Ci linear ( .
",D.7. Proof of Theorem 6.3,[0],[0]
"Note that C1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", CNcpF q either divide Rd into the same regions as T pF q or form a refinement.
",D.7. Proof of Theorem 6.3,[0],[0]
"For m ď d, we will denote by NcpF",D.7. Proof of Theorem 6.3,[0],[0]
"| mq the maximum convex degree obtained by restricting F to an m-dimensional affine subspace in Rd, i.e.,
NcpF",D.7. Proof of Theorem 6.3,[0],[0]
"| mq :“ max NcpF |Ωq : Ω Ď Rd is an m-dimensional affine space ( .
",D.7. Proof of Theorem 6.3,[0],[0]
"For any F P Ratpd, nq, there is at least one tropical polynomial map that subdivides T pF q, and so convex degree is welldefined (e.g., if F “ pp1 m q1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", pn m qnq P Ratpd, nq, then we may choose P “ pp1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", pn, q1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", qnq P Polpd, 2nq).",D.7. Proof of Theorem 6.3,[0],[0]
"Since the linear regions of a tropical polynomial map are always convex, we have N pF q",D.7. Proof of Theorem 6.3,[0],[0]
"“ NcpF q for any F P Polpd, nq.
Let F “ pf1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", fnq P Ratpd, nq and α “ pa1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", anq P Zn.",D.7. Proof of Theorem 6.3,[0],[0]
"Consider the tropical rational function3
Fα :“ αTF “ a1f1 ` ¨ ¨ ¨ ` anfn “ n ä
j“1 f aj j P Ratpd, 1q.
",D.7. Proof of Theorem 6.3,[0],[0]
"For some α, Fα may have fewer linear regions than F , e.g, α “ p0, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", 0q.",D.7. Proof of Theorem 6.3,[0],[0]
"As such, we need the following notion.",D.7. Proof of Theorem 6.3,[0],[0]
Definition D.2.,D.7. Proof of Theorem 6.3,[0],[0]
"α “ pa1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", anq P Zn is said to be a general exponent of F P Ratpd, nq if the linear regions of Fα and the linear regions of F are identical.
",D.7. Proof of Theorem 6.3,[0],[0]
"We show that general exponent always exists for any F P Ratpd, nq and may be chosen to have all entries nonnegative.",D.7. Proof of Theorem 6.3,[0],[0]
Lemma D.2.,D.7. Proof of Theorem 6.3,[0],[0]
"Let F P Ratpd, nq.",D.7. Proof of Theorem 6.3,[0],[0]
"Then
(i) N pFαq “ N pF q if and only if α is a general exponent; (ii) F has a general exponent α P Nn.
Proof.",D.7. Proof of Theorem 6.3,[0],[0]
It follows from the definition of tropical hypersuface that T pFαq and T pF q comprise respectively the points x P Rd at which Fα and F are not differentiable.,D.7. Proof of Theorem 6.3,[0],[0]
"Hence T pFαq Ď T pF q, which implies that N pFαq ă N pF q unless T pFαq “ T pF q.",D.7. Proof of Theorem 6.3,[0],[0]
"This concludes (i).
",D.7. Proof of Theorem 6.3,[0],[0]
"For (ii), we need to show that there always exists an α P Nn such that Fα divides its domain Rd into the same set of linear regions as F .",D.7. Proof of Theorem 6.3,[0],[0]
"In other words, for every pair of adjacent linear regions of F , the pd ´ 1q-dimensional face in T pF q that separates them is also present in T pFαq and so T pFαq Ě T pF q.
Let L and M be adjacent linear regions of F .",D.7. Proof of Theorem 6.3,[0],[0]
"The differentials of F |L and F |M must have integer coordinates, i.e., dF |L, dF |M P Znˆd.",D.7. Proof of Theorem 6.3,[0],[0]
"Since L and M are distinct linear regions, we must have dF |L ‰ dF |M (or otherwise L and M can be merged into a single linear region).",D.7. Proof of Theorem 6.3,[0],[0]
"Note that the differentials of Fα|L and Fα|M are given by αTdF |L and αTdF |M .
",D.7. Proof of Theorem 6.3,[0],[0]
"To ensure the pd´ 1q-dimensional face separating L and M still exists in T pFαq, we need to choose α so that αTdF |L ‰ αTdF |M .",D.7. Proof of Theorem 6.3,[0],[0]
Observe that the solution to pdF |L,D.7. Proof of Theorem 6.3,[0],[0]
"´ dF |M qTα “ 0 is contained in a one-dimensional subspace of Rn.
Let ApF q be the collection of all pairs of adjacent linear regions of F .",D.7. Proof of Theorem 6.3,[0],[0]
"Since the set of α that degenerates two adjacent linear regions into a single one, i.e.,
S :“ ď
pL,MqPApF q
α P Nn : pdF |L ´ dF |M",D.7. Proof of Theorem 6.3,[0],[0]
q,D.7. Proof of Theorem 6.3,[0],[0]
"Tα “ 0q
(
,
is contained in a union of a finite number of hyperplanes in Rn, S cannot cover the entire lattice of nonnegative integers",D.7. Proof of Theorem 6.3,[0],[0]
Nn.,D.7. Proof of Theorem 6.3,[0],[0]
"Therefore the set Nn X pRnzSq is nonempty and any of its element is a general exponent for F .
",D.7. Proof of Theorem 6.3,[0],[0]
"Lemma D.2 shows that we may study the linear degree of a tropical rational map by studying that of a tropical rational function, for which the results in Section 3.1 apply.
",D.7. Proof of Theorem 6.3,[0],[0]
"We are now ready to prove a key result on the convex degree of composition of tropical rational maps.
",D.7. Proof of Theorem 6.3,[0],[0]
Theorem D.3.,D.7. Proof of Theorem 6.3,[0],[0]
"Let F “ pf1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", fmq P Ratpn,mq and G P Ratpd, nq.",D.7. Proof of Theorem 6.3,[0],[0]
"Define H “ ph1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", hmq P Ratpd,mq by
hi :“ fi ˝G, i “ 1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
",m.
Then N pHq ď NcpHq ď NcpF | dq ¨NcpGq.
",D.7. Proof of Theorem 6.3,[0],[0]
Proof.,D.7. Proof of Theorem 6.3,[0],[0]
Only the upper bound requires a proof.,D.7. Proof of Theorem 6.3,[0],[0]
Let k “ NcpGq.,D.7. Proof of Theorem 6.3,[0],[0]
"By the definition of NcpGq, there exist convex sets C1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", Ck Ď Rd whose union is Rd and on each of which G is linear.",D.7. Proof of Theorem 6.3,[0],[0]
So G|Ci is some affine function ρi.,D.7. Proof of Theorem 6.3,[0],[0]
"For any i,
NcpF ˝ ρiq ď",D.7. Proof of Theorem 6.3,[0],[0]
"NcpF | dq, 3This is in the sense of a tropical power but we stay consistent to our slight abuse of notation and write Fα instead of Fdα.
by the definition of NcpF | dq.",D.7. Proof of Theorem 6.3,[0],[0]
Since F ˝G,D.7. Proof of Theorem 6.3,[0],[0]
"“ F ˝ ρi on Ci, we have
NcpF ˝Gq ď",D.7. Proof of Theorem 6.3,[0],[0]
"k ÿ
i“1 NcpF ˝",D.7. Proof of Theorem 6.3,[0],[0]
"ρiq.
",D.7. Proof of Theorem 6.3,[0],[0]
"Hence
NcpF ˝Gq ď k ÿ
i“1 NcpF ˝ ρiq ď
k ÿ",D.7. Proof of Theorem 6.3,[0],[0]
i“1 NcpF,D.7. Proof of Theorem 6.3,[0],[0]
|,D.7. Proof of Theorem 6.3,[0],[0]
dq,D.7. Proof of Theorem 6.3,[0],[0]
"“ NcpF | dq ¨NcpGq.
",D.7. Proof of Theorem 6.3,[0],[0]
We now apply our observations on tropical rational functions to neural networks.,D.7. Proof of Theorem 6.3,[0],[0]
"The next lemma follows directly from Corollary 3.4.
",D.7. Proof of Theorem 6.3,[0],[0]
Lemma D.4.,D.7. Proof of Theorem 6.3,[0],[0]
Let σplq ˝ ρplq :,D.7. Proof of Theorem 6.3,[0],[0]
Rnl´1 Ñ Rnl where σplq and ρplq are the affine transformation and activation of the lth layer of a neural network.,D.7. Proof of Theorem 6.3,[0],[0]
"If d ď nl, then
Ncpσplq ˝ ρplq | dq ď d ÿ",D.7. Proof of Theorem 6.3,[0],[0]
i“0 pnl,D.7. Proof of Theorem 6.3,[0],[0]
"i q .
",D.7. Proof of Theorem 6.3,[0],[0]
Proof.,D.7. Proof of Theorem 6.3,[0],[0]
"Ncpσplq ˝ ρplq | dq is the maximum convex degree of a tropical rational map F “ pf1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", fnlq : Rd Ñ Rnl of the form
fipxq :“ σplqi ˝ ρ",D.7. Proof of Theorem 6.3,[0],[0]
plq,D.7. Proof of Theorem 6.3,[0],[0]
˝,D.7. Proof of Theorem 6.3,[0],[0]
pb1,D.7. Proof of Theorem 6.3,[0],[0]
"d xα1 , . . .",D.7. Proof of Theorem 6.3,[0],[0]
", bnl´1 d x αnl´1 q, i “ 1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", nl.
",D.7. Proof of Theorem 6.3,[0],[0]
"For a general affine transformation ρplq,
ρplqpb1 d xα1 , . . .",D.7. Proof of Theorem 6.3,[0],[0]
", bnl´1 d x αnl´1 q “ ` b11 d xα 1 1 , . . .",D.7. Proof of Theorem 6.3,[0],[0]
", b1nl d x α1nl ˘ “: Gpxq
for some α11, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", α 1 nl and b11, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", b 1 nl , and we denote this map by G : Rd Ñ Rnl .",D.7. Proof of Theorem 6.3,[0],[0]
"So fi “ σplqi ˝G. By Theorem D.3, we have Ncpσplq ˝ ρplq | dq “ Ncpσplq | dq ¨NcpGq “ Ncpσplq | dq; note that NcpGq “ 1 as G is a linear function.
",D.7. Proof of Theorem 6.3,[0],[0]
"We have thus reduced the problem to determining a bound on the convex degree of a single layer neural network with nl nodes ν “ pν1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", νnlq :",D.7. Proof of Theorem 6.3,[0],[0]
Rd Ñ Rnl .,D.7. Proof of Theorem 6.3,[0],[0]
"Let γ “ pc1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", cnlq P Nnl be a nonnegative general exponent for ν.",D.7. Proof of Theorem 6.3,[0],[0]
"Note that
nl ä j“1",D.7. Proof of Theorem 6.3,[0],[0]
ν,D.7. Proof of Theorem 6.3,[0],[0]
cj,D.7. Proof of Theorem 6.3,[0],[0]
j,D.7. Proof of Theorem 6.3,[0],[0]
“ nl ä j“1,D.7. Proof of Theorem 6.3,[0],[0]
„ˆ d ä i“1 bi d xa ` ji ˙ ‘ ˆ d ä i“1 xa ´ ji,D.7. Proof of Theorem 6.3,[0],[0]
˙ d tj cj ´,D.7. Proof of Theorem 6.3,[0],[0]
nl ä j“1,D.7. Proof of Theorem 6.3,[0],[0]
ˆ d ä i“1,D.7. Proof of Theorem 6.3,[0],[0]
xa,D.7. Proof of Theorem 6.3,[0],[0]
"´ ji ˙cj .
",D.7. Proof of Theorem 6.3,[0],[0]
"Since the last term is linear in x, we may drop it without affecting the convex degree of the entire expression.",D.7. Proof of Theorem 6.3,[0],[0]
"It remains to determine an upper bound for the number of linear regions of the tropical polynomial
hpxq “ nl ä
j“1
„ˆ d ä
i“1 bi d xa
` ji
˙ ‘ ˆ d ä
i“1 xa ´",D.7. Proof of Theorem 6.3,[0],[0]
"ji
˙ d tj cj ,
which we will obtain by counting vertices of the polytope Pphq.",D.7. Proof of Theorem 6.3,[0],[0]
"By Propositions 3.1 and 3.2 the polytope Pphq is given by a weighted Minkowski sum
nl ÿ j“1 cjP",D.7. Proof of Theorem 6.3,[0],[0]
"„ˆ d ä i“1 bi d xa ` ji ˙ ‘ ˆ d ä i“1 xa ´ ji ˙ d tj  .
",D.7. Proof of Theorem 6.3,[0],[0]
"By Proposition 3.2 again,
P „ˆ d ä
i“1 bi d xa
` ji
˙ ‘ ˆ d ä
i“1 xa ´ ji
˙ d tj  “ Conv ` VpPpfqq Y VpPpgqq ˘
where
fpxq “ d ä
i“1 bi d xa
` ji and gpxq “
ˆ",D.7. Proof of Theorem 6.3,[0],[0]
"d ä
i“1 xa ´ ji
˙
d tj
are tropical monomials.",D.7. Proof of Theorem 6.3,[0],[0]
"Therefore Ppfq, Ppgq are just points in Rd`1 and Conv ` VpPpfqq Y VpPpgqq ˘ is a line in Rd`1.",D.7. Proof of Theorem 6.3,[0],[0]
"Hence Pphq is a Minkowski sum of nl line segments in Rd`1, i.e., a zonotope, and Corollary 3.4 completes the proof.
",D.7. Proof of Theorem 6.3,[0],[0]
"Using Lemma D.4, we obtain a bound on the number of linear regions created by one layer of a neural network.
",D.7. Proof of Theorem 6.3,[0],[0]
Theorem D.5.,D.7. Proof of Theorem 6.3,[0],[0]
Let ν :,D.7. Proof of Theorem 6.3,[0],[0]
"Rd Ñ RnL be an L-layer neural network satisfying assumptions (a)–(c) with F plq, Gplq,Hplq, and νplq as defined in Proposition 5.1.",D.7. Proof of Theorem 6.3,[0],[0]
"Let nl ě d for all l “ 1, . . .",D.7. Proof of Theorem 6.3,[0],[0]
", L. Then
Ncpνp1qq “ N pGp1qq",D.7. Proof of Theorem 6.3,[0],[0]
"“ N pHp1qq “ 1, Ncpνpl`1qq ď Ncpνplqq ¨ d ÿ i“0 pnl`1",D.7. Proof of Theorem 6.3,[0],[0]
"i q .
",D.7. Proof of Theorem 6.3,[0],[0]
Proof.,D.7. Proof of Theorem 6.3,[0],[0]
"The l “ 1 case follows from the fact that Gp1qpxq “ Ap1q´ x and Hp1qpxq “ A p1q ` x` bp1q are both linear, which in turn forces Ncpνp1qq “ 1 as in the proof of Lemma D.4.",D.7. Proof of Theorem 6.3,[0],[0]
"Since νplq “ pσplq ˝ ρplqq ˝ νpl´1q, the recursive bound follows from Theorem D.3 and Lemma D.4.
",D.7. Proof of Theorem 6.3,[0],[0]
Theorem 6.3 follows from applying Theorem D.5 recursively.,D.7. Proof of Theorem 6.3,[0],[0]
"We establish, for the first time, connections between feedforward neural networks with ReLU activation and tropical geometry — we show that the family of such neural networks is equivalent to the family of tropical rational maps.",abstractText,[0],[0]
"Among other things, we deduce that feedforward ReLU neural networks with one hidden layer can be characterized by zonotopes, which serve as building blocks for deeper networks; we relate decision boundaries of such neural networks to tropical hypersurfaces, a major object of study in tropical geometry; and we prove that linear regions of such neural networks correspond to vertices of polytopes associated with tropical rational functions.",abstractText,[0],[0]
An insight from our tropical formulation is that a deeper network is exponentially more expressive than a shallow network.,abstractText,[0],[0]
Tropical Geometry of Deep Neural Networks,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2931–2937 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics
We present an analytic study on the language of news media in the context of political fact-checking and fake news detection. We compare the language of real news with that of satire, hoaxes, and propaganda to find linguistic characteristics of untrustworthy text. To probe the feasibility of automatic political fact-checking, we also present a case study based on PolitiFact.com using their factuality judgments on a 6-point scale. Experiments show that while media fact-checking remains to be an open research question, stylistic cues can help determine the truthfulness of text.",text,[0],[0]
Words in news media and political discourse have a considerable power in shaping people’s beliefs and opinions.,1 Introduction,[0],[0]
"As a result, their truthfulness is often compromised to maximize impact.",1 Introduction,[0],[0]
"Recently, fake news has captured worldwide interest, and the number of organized efforts dedicated solely to fact-checking has almost tripled since 2014.1 Organizations, such as PolitiFact.com, actively investigate and rate the veracity of comments made by public figures, journalists, and organizations.
",1 Introduction,[0],[0]
Figure 1 shows example quotes rated for truthfulness by PolitiFact.,1 Introduction,[0],[0]
"Per their analysis, one component of the two statements’ ratings is the misleading phrasing (bolded in green in the figure).",1 Introduction,[0],[0]
"For instance, in the first example, the statement is true as stated, though only because the speaker hedged their meaning with the quantifier just.",1 Introduction,[0],[0]
"In the second example, two correlated events – Brexit
1https://www.poynter.org/2017/there-are-now-114-factchecking-initiatives-in-47-countries/450477/
“By declaring that Pluto was no longer a planet, the (International Astronomical Union) put into place a planetary definition that would have even declassified Earth as a planet if it existed as far from the sun as Pluto does.”
",1 Introduction,[0],[0]
"Half TrueTrue False
-Rated Half True by PunditFact, (July 2015)
and Google search trends – are presented ambiguously as if they were directly linked.
",1 Introduction,[0],[0]
"Importantly, like above examples, most factchecked statements on PolitiFact are rated as neither entirely true nor entirely false.",1 Introduction,[0],[0]
"Analysis indicates that falsehoods often arise from subtle differences in phrasing rather than outright fabrication (Rubin et al., 2015).",1 Introduction,[0],[0]
"Compared to most prior work on deception literature that focused on binary categorization of truth and deception, political fact-checking poses a new challenge as it involves a graded notion of truthfulness.
",1 Introduction,[0],[0]
"While political fact-checking generally focuses on examining the accuracy of a single quoted statement by a public figure, the reliability of general news stories is also a concern (Connolly et al., 2016; Perrott, 2016).",1 Introduction,[0],[0]
"Figure 2 illustrates news types categorized along two dimensions: the intent of the authors (desire to deceive) and the content of the articles (true, mixed, false).
",1 Introduction,[0],[0]
"2931
In this paper, we present an analytic study characterizing the language of political quotes and news media written with varying intents and degrees of truth.",1 Introduction,[0],[0]
"We also investigate graded deception detection, determining the truthfulness on a 6-point scale using the political fact-checking database available at PolitiFact.2",1 Introduction,[0],[0]
"News Corpus with Varying Reliability To analyze linguistic patterns across different types of articles, we sampled standard trusted news articles from the English Gigaword corpus and crawled articles from seven different unreliable news sites of differing types.",2 Fake News Analysis,[0],[0]
"Table 1 displays sources identified under each type according to US News & World Report.3 These news types include: • Satire: mimics real news but still cues the reader
that it is not meant to be taken seriously • Hoax: convinces readers of the validity of a
paranoia-fueled story • Propaganda: misleads readers so that they be-
lieve a particular political/social agenda Unlike hoaxes and propaganda, satire is intended to be notably different from real news so that audiences will recognize the humorous intent.",2 Fake News Analysis,[0],[0]
"Hoaxes and satire are more likely to invent stories, while propaganda frequently combines truths, falsehoods, and ambiguities to confound readers.
",2 Fake News Analysis,[0],[0]
"To characterize differences between news types, we applied various lexical resources to trusted and fake news articles.",2 Fake News Analysis,[0],[0]
We draw lexical resources from prior works in communication theory and stylistic analysis in computational linguistics.,2 Fake News Analysis,[0],[0]
"We tokenize
2All resources created for this paper including corpus of news articles from unreliable sources, collection of Politifact ratings, and compiled Wiktionary lexicons have been made publicly available at homes.cs.washington. edu/˜hrashkin/factcheck.html
3www.usnews.com/news/national-news/articles/2016-1114/avoid-these-fake-news-sites-at-all-costs
the text with NLTK (Bird et al., 2009) and compute per-document count for each lexicon, and report averages per article of each type.
",2 Fake News Analysis,[0],[0]
"First among these lexicons is the Linguistic Inquiry and Word Count (LIWC), a lexicon widely used in social science studies (Pennebaker et al., 2015).",2 Fake News Analysis,[0],[0]
"In addition, we estimate the use of strongly and weakly subjective words with a sentiment lexicon (Wilson et al., 2005).",2 Fake News Analysis,[0],[0]
Subjective words can be used to dramatize or sensationalize a news story.,2 Fake News Analysis,[0],[0]
"We also use lexicons for hedging from (Hyland, 2015) because hedging can indicate vague, obscuring language.",2 Fake News Analysis,[0],[0]
"Lastly, we introduce intensifying lexicons that we crawled from Wiktionary based on a hypothesis that fake news articles try to enliven stories to attract readers.",2 Fake News Analysis,[0],[0]
"We compiled five lists from Wiktionary of words that imply a degree a dramatization (comparatives, superlatives, action adverbs, manner adverbs, and modal adverbs) and measured their presence.
",2 Fake News Analysis,[0],[0]
Discussion Table 2 summarizes the ratio of averages between unreliable news and truthful news for a handful of the measured features.,2 Fake News Analysis,[0],[0]
"Ratios greater than one denote features more prominent in fake news, and ratios less than one denote features more prominent in truthful news.",2 Fake News Analysis,[0],[0]
"The ratios between unreliable/reliable news reported are statistically significant (p < 0.01) with Welsch t-test after Bonferroni correction.
",2 Fake News Analysis,[0],[0]
Our results show that first-person and secondperson pronouns are used more in less reliable or deceptive news types.,2 Fake News Analysis,[0],[0]
"This contrasts studies in other domains (Newman et al., 2003), which found fewer self-references in people telling lies about their personal opinions.",2 Fake News Analysis,[0],[0]
"Unlike that domain, news writers are trying to appear indifferent.",2 Fake News Analysis,[0],[0]
"Editors at trustworthy sources are possibly more
rigorous about removing language that seems too personal, which is one reason why this result differs from other lie detection domains.",2 Fake News Analysis,[0],[0]
"This finding instead corroborates previous work in written domains found by Ott et al. (2011) and Rayson et al. (2001), who found that such pronouns were indicative of imaginative writing.",2 Fake News Analysis,[0],[0]
"Perhaps imaginative storytelling domains is a closer match to detecting unreliable news than lie detection on opinions.
",2 Fake News Analysis,[0],[0]
"Our results also show that words that can be used to exaggerate – subjectives, superlatives, and modal adverbs – are all used more by fake news.",2 Fake News Analysis,[0],[0]
"Words used to offer concrete figures – comparatives, money, and numbers – appear more in truthful news.",2 Fake News Analysis,[0],[0]
"This also builds on previous findings by Ott et al. (2011) on the difference between superlative/comparative usage.
",2 Fake News Analysis,[0],[0]
"Trusted sources are more likely to use assertive words and less likely to use hedging words, indicating that they are less vague about describing events, as well.",2 Fake News Analysis,[0],[0]
"This relates to psychology theories (Buller and Burgoon, 1996) that deceivers show more “uncertainty and vagueness” and “indirect forms of expression”.",2 Fake News Analysis,[0],[0]
"Similarly, the trusted sources use the hear category words more often, possibly indicating that they are citing primary sources more often.
",2 Fake News Analysis,[0],[0]
"The last column in Table 2 shows the fake news type that uses the corresponding lexicon most
prominently.",2 Fake News Analysis,[0],[0]
We found that one distinctive feature of satire compared to other types of untrusted news is its prominent use of adverbs.,2 Fake News Analysis,[0],[0]
Hoax stories tend to use fewer superlatives and comparatives.,2 Fake News Analysis,[0],[0]
"In contrast, compared to other types of fake news, propaganda uses relatively more assertive verbs and superlatives.
",2 Fake News Analysis,[0],[0]
"News Reliability Prediction We study the feasibility of predicting the reliability of the news article into four categories: trusted, satire, hoax, or propaganda.",2 Fake News Analysis,[0],[0]
"We split our collected articles into balanced training (20k total articles from the Onion, American News, The Activist, and the Gigaword news excluding ‘APW’, ‘WPB’ sources) and test sets (3k articles from the remaining sources).",2 Fake News Analysis,[0],[0]
"Because articles in the training and test set come from different sources, the models must classify articles without relying on author-specific cues.",2 Fake News Analysis,[0],[0]
We also use 20% of the training articles as an in-domain development set.,2 Fake News Analysis,[0],[0]
"We trained a Max-Entropy classifier with L2 regularization on n-gram tf-idf feature vectors (up to trigrams).4
The model achieves F1 scores of 65% on the out-of-domain test set (Table 3).",2 Fake News Analysis,[0],[0]
"This is a promising result as it is much higher than random, but still leaves room for improvement compared to the
4N-gram tfidf vectors have acted as competitive means of cross-domain text-classification.",2 Fake News Analysis,[0],[0]
"Zhang et al. (2015) found that for data sets smaller than a million examples, this was the best model, outperforming neural models.
",2 Fake News Analysis,[0],[0]
"performance on the development set consisting of articles from in-domain sources.
",2 Fake News Analysis,[0],[0]
We examined the 50 highest weighted n-gram features in the MaxEnt classifier for each class.,2 Fake News Analysis,[0],[0]
"The highest weighted n-grams for trusted news were often specific places (e.g., “washington”) or times (“on monday”).",2 Fake News Analysis,[0],[0]
"Many of the highest weighted from satire were vaguely facetious hearsay (“reportedly”, “confirmed”).",2 Fake News Analysis,[0],[0]
"For hoax articles, heavily weighted features included divisive topics (“liberals”, “trump”) and dramatic cues (“breaking”).",2 Fake News Analysis,[0],[0]
"Heavily weighted features for propaganda tend towards abstract generalities (“truth”, “freedom”) as well as specific issues (“vaccines”, “syria”).",2 Fake News Analysis,[0],[0]
"Interestingly, “youtube” and “video” are highly weighted for the propaganda and hoax classes respectively; indicating that they often rely on video clips as sources.",2 Fake News Analysis,[0],[0]
Politifact Data Related to the issue of identifying the truthfulness of a news article is the factchecking of individual statements made by public figures.,3 Predicting Truthfulness,[0],[0]
"Misleading statements can also have a variety of intents and levels of reliability depending on whom is making the statement.
",3 Predicting Truthfulness,[0],[0]
PolitiFact5 is a site led by Tampa Bay Times journalists who actively fact-check suspicious statements.,3 Predicting Truthfulness,[0],[0]
One unique quality of PolitiFact is that each quote is evaluated on a 6-point scale of truthfulness ranging from “True” (factual) to “Pantson-Fire False” (absurdly false).,3 Predicting Truthfulness,[0],[0]
"This scale allows for distinction between categories like mostly true (the facts are correct but presented in an incomplete manner) or mostly false (the facts are not correct but are connected to a small kernel of truth).
",3 Predicting Truthfulness,[0],[0]
"We collected labelled statements from PolitiFact and its spin-off sites (PunditFact, etc.)",3 Predicting Truthfulness,[0],[0]
"(10,483 statements in total).",3 Predicting Truthfulness,[0],[0]
"We analyze a subset of 4,366 statements that are direct quotes by the original speaker.",3 Predicting Truthfulness,[0],[0]
"The distributions of ratings on the PolitiFact scale for this subset are shown
5www.politifact.com/
in Table 4.",3 Predicting Truthfulness,[0],[0]
"Most statements are labeled as neither completely true nor false.
",3 Predicting Truthfulness,[0],[0]
We formulate a fine-grained truthfulness prediction task with Politifact data.,3 Predicting Truthfulness,[0],[0]
"We split quotes into training/development/test set of {2575, 712, 1074} statements, respectively, so that all of each speaker’s quotes are in a single set.",3 Predicting Truthfulness,[0],[0]
"Given a statement, the model returns a rating for how reliable the statement is (Politifact ratings are used as gold labels).",3 Predicting Truthfulness,[0],[0]
"We ran the experiment in two settings, one considering all 6 classes and the other considering only 2 (treating the top three truthful ratings as true and the lower three as false).
",3 Predicting Truthfulness,[0],[0]
"Model We trained an LSTM model (Hochreiter and Schmidhuber, 1997)",3 Predicting Truthfulness,[0],[0]
that takes the sequence of words as the input and predicts the Politifact rating.,3 Predicting Truthfulness,[0],[0]
"We also compared this model with Maximum Entropy (MaxEnt) and Naive Bayes models, frequently used for text categorization.
",3 Predicting Truthfulness,[0],[0]
"For input to the MaxEnt and Naive Bayes models, we tried two variants: one with the word tfidf vectors as input, and one with the LIWC measurements concatenated to the tf-idf vectors.",3 Predicting Truthfulness,[0],[0]
"For the LSTM model, we used word sequences as input and also a version where LSTM output is concatenated with LIWC feature vectors before undergoing the activation layer.",3 Predicting Truthfulness,[0],[0]
"The LSTM word embeddings are initialized with 100-dim embeddings from GLOVE (Pennington et al., 2014) and fine-tuned during training.",3 Predicting Truthfulness,[0],[0]
The LSTM was implemented with Theano and Keras with 300-dim hidden state and a batch size of 64.,3 Predicting Truthfulness,[0],[0]
"Training was done with ADAM to minimize categorical crossentropy loss over 10 epochs.
",3 Predicting Truthfulness,[0],[0]
Classifier Results Table 5 summarizes the performance on the development set.,3 Predicting Truthfulness,[0],[0]
We report macro averaged F1 score in all tables.,3 Predicting Truthfulness,[0],[0]
"The LSTM outperforms the other models when only using text as input; however the other two models improve substantially with adding LIWC features, particu-
larly in the case of the multinomial naive Bayes model.",3 Predicting Truthfulness,[0],[0]
"In contrast, the LIWC features do not improve the neural model much, indicating that some of this lexical information is perhaps redundant to what the model was already learning from text.
",3 Predicting Truthfulness,[0],[0]
We report results on the test set in Table 6.,3 Predicting Truthfulness,[0],[0]
We again find that LIWC features improves MaxEnt and NB models to perform similarly to the LSTM model.,3 Predicting Truthfulness,[0],[0]
"As in the dev. set results, the LIWC features do not improve the LSTM’s performance, and even seem to hurt the performance slightly.",3 Predicting Truthfulness,[0],[0]
"Deception Detection Psycholinguistic work in interpersonal deception theory (Buller and Burgoon, 1996) has postulated that certain speech patterns can be signs of a speaker trying to purposefully obscure the truth.",4 Related Work,[0],[0]
"Hedge words and other vague qualifiers (Choi et al., 2012; Recasens et al., 2013), for example, may add indirectness to a statement that obscures its meaning.
",4 Related Work,[0],[0]
"Linguistic aspects deception detection has been well-studied in a variety of NLP applications (Ott et al., 2011; Mihalcea and Strapparava, 2009; Jindal and Liu, 2008; Girlea et al., 2016; Zhou et al., 2004).",4 Related Work,[0],[0]
"In these applications, people purposefully tell lies to receive an extrinsic payoff.",4 Related Work,[0],[0]
"In our study, we compare varying types of unreliable news source, created with differing intents and levels of veracity.
",4 Related Work,[0],[0]
"Fact-Checking and Fake News There is research in political science exploring how effective fact-checking is at improving people’s awareness
(Lord et al., 1979; Thorson, 2016; Nyhan and Reifler, 2015).",4 Related Work,[0],[0]
"Prior computational works (Vlachos and Riedel, 2014; Ciampaglia et al., 2015) have proposed fact-checking through entailment from knowledge bases.",4 Related Work,[0],[0]
"Our work takes a more linguistic approach, performing lexical analysis over varying types of falsehood.
",4 Related Work,[0],[0]
"Biyani et al. (2016) examine the unique linguistic styles found in clickbait articles, and Kumar et al. (2016) also characterize hoax documents on Wikipedia.",4 Related Work,[0],[0]
"The differentiation between these fake news types is also proposed in previous work (Rubin et al., 2015).",4 Related Work,[0],[0]
"Our paper extends this work by offering a quantitative study of linguistic differences found in articles of different types of fake news, and build predictive models for graded deception across multiple domains – PolitiFact and news articles.",4 Related Work,[0],[0]
"More recent work (Wang, 2017) has also investigated PolitiFact data though they investigated meta-data features for prediction whereas our investigation is focused on linguistic analysis through stylistic lexicons.",4 Related Work,[0],[0]
"We examine truthfulness and its contributing linguistic attributes across multiple domains e.g., online news sources and public statements.",5 Conclusion,[0],[0]
"We perform multiple prediction tasks on fact-checked statements of varying levels of truth (graded deception) as well as a deeper linguistic comparison of differing types of fake news e.g., propaganda, satire and hoaxes.",5 Conclusion,[0],[0]
We have shown that factchecking is indeed a challenging task but that various lexical features can contribute to our understanding of the differences between more reliable and less reliable digital news sources.,5 Conclusion,[0],[0]
We would like to thank anonymous reviewers for providing insightful feedback.,6 Acknowledgements,[0],[0]
"The research described in this paper was conducted under the Laboratory Directed Research and Development Program at Pacific Northwest National Laboratory, a multiprogram national laboratory operated by Battelle for the U.S. Department of Energy, the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE-1256082, in part by NSF grants IIS-1408287, IIS-1714566, and gifts by Google and Facebook.",6 Acknowledgements,[0],[0]
We present an analytic study on the language of news media in the context of political fact-checking and fake news detection.,abstractText,[0],[0]
"We compare the language of real news with that of satire, hoaxes, and propaganda to find linguistic characteristics of untrustworthy text.",abstractText,[0],[0]
"To probe the feasibility of automatic political fact-checking, we also present a case study based on PolitiFact.com using their factuality judgments on a 6-point scale.",abstractText,[0],[0]
"Experiments show that while media fact-checking remains to be an open research question, stylistic cues can help determine the truthfulness of text.",abstractText,[0],[0]
Truth of Varying Shades: Analyzing Language in Fake News and Political Fact-Checking,title,[0],[0]
"Deep Neural Networks (LeCun et al., 2015) have been successful on numerous difficult machine learning tasks, including image recognition(Krizhevsky et al., 2012; Donahue et al., 2015), speech recognition(Hinton et al., 2012) and natural language processing(Collobert et al., 2011;
",1. Introduction,[0],[0]
"*Equal contribution 1Massachusetts Institute of Technology 2New York University, Facebook AI Research.",1. Introduction,[0],[0]
"Correspondence to: Li Jing <ljing@mit.edu>, Yichen Shen <ycshen@mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Bahdanau et al., 2014; Sutskever et al., 2014).",1. Introduction,[0],[0]
"However, deep neural networks can suffer from vanishing and exploding gradient problems(Hochreiter, 1991; Bengio et al., 1994), which are known to be caused by matrix eigenvalues far from unity being raised to large powers.",1. Introduction,[0],[0]
"Because the severity of these problems grows with the the depth of a neural network, they are particularly grave for Recurrent Neural Networks (RNNs), whose recurrence can be equivalent to thousands or millions of equivalent hidden layers.
",1. Introduction,[0],[0]
Several solutions have been proposed to solve these problems for RNNs.,1. Introduction,[0],[0]
"Long Short Term Memory (LSTM) networks (Hochreiter & Schmidhuber, 1997), which help RNNs contain information inside hidden layers with gates, remains one of the the most popular RNN implementations.",1. Introduction,[0],[0]
"Other recently proposed methods such as GRUs(Cho et al., 2014) and Bidirectional RNNs (Berglund et al., 2015) also perform well in numerous applications.",1. Introduction,[0],[0]
"However, none of these approaches has fundamentally solved the vanishing and exploding gradient problems, and gradient clipping is often required to keep gradients in a reasonable range.
",1. Introduction,[0],[0]
"A recently proposed solution strategy is using orthogonal hidden weight matrices or their complex generalization (unitary matrices) (Saxe et al., 2013; Le et al., 2015; Arjovsky et al., 2015; Henaff et al., 2016), because all their eigenvalues will then have absolute values of unity, and can safely be raised to large powers.",1. Introduction,[0],[0]
"This has been shown to help both when weight matrices are initialized to be unitary (Saxe et al., 2013; Le et al., 2015) and when they are kept unitary during training, either by restricting them to a more tractable matrix subspace (Arjovsky et al., 2015) or by alternating gradient-descent steps with projections onto the unitary subspace (Wisdom et al., 2016).
",1. Introduction,[0],[0]
"In this paper, we will first present an Efficient Unitary Neural Network (EUNN) architecture that parametrizes the entire space of unitary matrices in a complete and computationally efficient way, thereby eliminating the need for time-consuming unitary subspace-projections.",1. Introduction,[0],[0]
Our architecture has a wide range of capacity-tunability to represent subspace unitary models by fixing some of our parameters; the above-mentioned unitary subspace models correspond to special cases of our architecture.,1. Introduction,[0],[0]
"We also implemented
an EUNN with an earlier introduced FFT-like architecture which efficiently approximates the unitary space with minimum number of required parameters(Mathieu & LeCun, 2014b).
",1. Introduction,[0],[0]
"We then benchmark EUNN’s performance on both simulated and real tasks: the standard copying task, the pixelpermuted MNIST task, and speech prediction with the TIMIT dataset (Garofolo et al., 1993).",1. Introduction,[0],[0]
We show that our EUNN algorithm with an O(N) hidden layer size can compute up to the entire N × N gradient matrix using O(1) computational steps and memory access per parameter.,1. Introduction,[0],[0]
"This is superior to theO(N) computational complexity of the existing training method for a full-space unitary network (Wisdom et al., 2016) and O(logN) more efficient than the subspace Unitary RNN(Arjovsky et al., 2015).",1. Introduction,[0],[0]
"A recurrent neural network takes an input sequence and uses the current hidden state to generate a new hidden state during each step, memorizing past information in the hidden layer.",2.1. Basic Recurrent Neural Networks,[0],[0]
"We first review the basic RNN architecture.
",2.1. Basic Recurrent Neural Networks,[0],[0]
"Consider an RNN updated at regular time intervals t = 1, 2, ... whose input is the sequence of vectors x(t) whose hidden layer h(t) is updated according to the following rule:
h(t) = σ(Ux(t) +Wh(t−1)), (1)
where σ is the nonlinear activation function.",2.1. Basic Recurrent Neural Networks,[0],[0]
"The output is generated by
y(t)",2.1. Basic Recurrent Neural Networks,[0],[0]
"= Wh(t) + b, (2)
where b is the bias vector for the hidden-to-output layer.",2.1. Basic Recurrent Neural Networks,[0],[0]
"For t = 0, the hidden layer h(0) can be initialized to some special vector or set as a trainable variable.",2.1. Basic Recurrent Neural Networks,[0],[0]
"For convenience of notation, we define z(t) = Ux(t) + Wh(t−1) so that h(t) = σ(z(t)).",2.1. Basic Recurrent Neural Networks,[0],[0]
"When training the neural network to minimize a cost function C that depends on a parameter vector a, the gradient descent method updates this vector to a − λ∂C∂a , where λ is a fixed learning rate and ∂C∂a ≡ ∇C.",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"For an RNN, the vanishing or exploding gradient problem is most significant during back propagation from hidden to hidden layers, so we will only focus on the gradient for hidden layers.",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"Training the input-to-hidden and hidden-to-output matrices is relatively trivial once the hidden-to-hidden matrix has been successfully optimized.
",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"In order to evaluate ∂C∂Wij , one first computes the derivative
∂C ∂h(t) using the chain rule:
∂C
∂h(t) =
∂C ∂h(T ) ∂h(T ) ∂h(t) (3)
= ∂C
∂h(T )",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"T−1∏ k=t ∂h(k+1) ∂h(k) (4)
= ∂C
∂h(T )",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"T−1∏ k=t D(k)W, (5)
where D(k) = diag{σ′(Ux(k) + Wh(k−1))} is the Jacobian matrix of the pointwise nonlinearity.",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"For large times T , the term ∏ W plays a significant role.",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"As long as the eigenvalues of D(k) are of order unity, then if W has eigenvalues λi 1, they will cause gradient explosion | ∂C ∂h(T )
| → ∞, while if W has eigenvalues λi 1, they can cause gradient vanishing, | ∂C
∂h(T )",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
| → 0.,2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"Either situation
prevents the RNN from working efficiently.",2.2. The Vanishing and Exploding Gradient Problems,[0],[0]
"In a breakthrough paper, Arjovsky, Shah & Bengio (Arjovsky et al., 2015) showed that unitary RNNs can overcome the exploding and vanishing gradient problems and perform well on long term memory tasks if the hiddento-hidden matrix in parametrized in the following unitary form:
W = D3T2F−1D2ΠT1FD1.",3.1. Partial Space Unitary RNNs,[0],[0]
"(6)
Here D1,2,3 are diagonal matrices with each element eiωj , j = 1, 2, · · · , n. T1,2 are reflection matrices, and T = I − 2 v̂v̂ †
||v̂||2 , where v̂ is a vector with each of its entries as a parameter to be trained.",3.1. Partial Space Unitary RNNs,[0],[0]
Π is a fixed permutation matrix.,3.1. Partial Space Unitary RNNs,[0],[0]
F and F−1 are Fourier and inverse Fourier transform matrices respectively.,3.1. Partial Space Unitary RNNs,[0],[0]
"Since each factor matrix here is unitary, the product W is also a unitary matrix.
",3.1. Partial Space Unitary RNNs,[0],[0]
"This model uses O(N) parameters, which spans merely a part of the whole O(N2)-dimensional space of unitary N × N matrices to enable computational efficiency.",3.1. Partial Space Unitary RNNs,[0],[0]
"Several subsequent papers have tried to expand the space to O(N2) in order to achieve better performance, as summarized below.",3.1. Partial Space Unitary RNNs,[0],[0]
"In order to maximize the power of Unitary RNNs, it is preferable to have the option to optimize the weight matrix W over the full space of unitary matrices rather than a subspace as above.",3.2. Full Space Unitary RNNs,[0],[0]
"A straightforward method for implementing this is by simply updating W with standard backpropagation and then projecting the resulting matrix (which will typically no longer be unitary) back onto to the space
of unitary matrices.",3.2. Full Space Unitary RNNs,[0],[0]
"Defining Gij ≡ ∂C∂Wij as the gradient with respect to W, this can be implemented by the procedure defined by (Wisdom et al., 2016):
A(t) ≡ G(t) † W(t) −W(t) † G(k), (7) W(t+1) ≡",3.2. Full Space Unitary RNNs,[0],[0]
"( I + λ
2 A(t)
)−1",3.2. Full Space Unitary RNNs,[0],[0]
"( I− λ
2 A(t)
) W(t).(8)
",3.2. Full Space Unitary RNNs,[0],[0]
"This method shows that full space unitary networks are superior on many RNN tasks (Wisdom et al., 2016).",3.2. Full Space Unitary RNNs,[0],[0]
"A key limitation is that the back-propation in this method cannot avoid N -dimensional matrix multiplication, incurring O(N3) computational cost.",3.2. Full Space Unitary RNNs,[0],[0]
"In the following, we first describe a general parametrization method able to represent arbitrary unitary matrices with up to N2 degrees of freedom.",4. Efficient Unitary Neural Network (EUNN) Architectures,[0],[0]
"We then present an efficient algorithm for this parametrization scheme, requiring only O(1) computational and memory access steps to obtain the gradient for each parameter.",4. Efficient Unitary Neural Network (EUNN) Architectures,[0],[0]
"Finally, we show that our scheme performs significantly better than the above mentioned methods on a few well-known benchmarks.",4. Efficient Unitary Neural Network (EUNN) Architectures,[0],[0]
"Any N × N unitary matrix WN can be represented as a product of rotation matrices {Rij} and a diagonal matrix D, such that WN = D ∏N i=2 ∏i−1",4.1. Unitary Matrix Parametrization,[0],[0]
"j=1 Rij , where Rij is defined as the N -dimensional identity matrix with the elements Rii, Rij , Rji and Rjj replaced as follows (Reck et al., 1994; Clements et al., 2016):(
Rii Rij Rji Rjj
) =",4.1. Unitary Matrix Parametrization,[0],[0]
"( eiφij cos θij −eiφij sin θij
sin θij cos θij
) .",4.1. Unitary Matrix Parametrization,[0],[0]
"(9)
where θij and φij are unique parameters corresponding to Rij.",4.1. Unitary Matrix Parametrization,[0],[0]
"Each of these matrices performs a U(2) unitary transformation on a two-dimensional subspace of the Ndimensional Hilbert space, leaving an (N−2)-dimensional subspace unchanged.",4.1. Unitary Matrix Parametrization,[0],[0]
"In other words, a series of U(2) rotations can be used to successively make all off-diagonal elements of the given N × N unitary matrix zero.",4.1. Unitary Matrix Parametrization,[0],[0]
This generalizes the familiar factorization of a 3D rotation matrix into 2D rotations parametrized by the three Euler angles.,4.1. Unitary Matrix Parametrization,[0],[0]
"To provide intuition for how this works, let us briefly describe a simple way of doing this that is similar to Gaussian elimination by finishing one column at a time.",4.1. Unitary Matrix Parametrization,[0],[0]
"There are infinitely many alternative decomposition schemes as well; Fig. 1 shows two that are particularly convenient to implement in software (and even in neuromorphic hardware (Shen et al., 2016)).",4.1. Unitary Matrix Parametrization,[0],[0]
"The unitary matrix WN is multiplied from the right by a succession of unitary matrices
RNj for j = N − 1, · · · , 1.",4.1. Unitary Matrix Parametrization,[0],[0]
"Once all elements of the last row except the one on the diagonal are zero, this row will not be affected by later transformations.",4.1. Unitary Matrix Parametrization,[0],[0]
"Since all transformations are unitary, the last column will then also contain only zeros except on the diagonal:
WNRN,N−1RN,N−2 · ·RN,1 = (
WN−1 0 0",4.1. Unitary Matrix Parametrization,[0],[0]
"eiwN
) (10)
The effective dimensionality of the the matrix W is thus reduced toN−1.",4.1. Unitary Matrix Parametrization,[0],[0]
"The same procedure can then be repeated N − 1 times until the effective dimension of W is reduced to 1, leaving us with a diagonal matrix:1
WNRN,N−1RN,N−2 · · ·Ri,jRi,j−1 · · ·R3,1R2,1 = D, (11)
where D is a diagonal matrix whose diagonal elements are eiwj , from which we can write the direct representation of WN as
WN = DR −1 2,1R −1 3,1 . .",4.1. Unitary Matrix Parametrization,[0],[0]
.R −1,4.1. Unitary Matrix Parametrization,[0],[0]
"N,N−2R −1",4.1. Unitary Matrix Parametrization,[0],[0]
"N,N−1
= DR′2,1R ′ 3,1 . .",4.1. Unitary Matrix Parametrization,[0],[0]
.R ′,4.1. Unitary Matrix Parametrization,[0],[0]
"N,N−2R ′ N,N−1.",4.1. Unitary Matrix Parametrization,[0],[0]
"(12)
where
R′ij = R(−θij ,−φij) = R(θij , φij)−1 = R−1ij (13)
1Note that Gaussian Elimination would make merely the upper triangle of a matrix vanish, requiring a subsequent series of rotations (complete Gauss-Jordan Elimination) to zero the lower triangle.",4.1. Unitary Matrix Parametrization,[0],[0]
"We need no such subsequent series because since W is unitary: it is easy to show that if a unitary matrix is triangular, it must be diagonal.
",4.1. Unitary Matrix Parametrization,[0],[0]
"This parametrization thus involves N(N − 1)/2 different θij-values, N(N − 1)/2 different φij-values and N different wi-values, combining to N2 parameters in total and spans the entire unitary space.",4.1. Unitary Matrix Parametrization,[0],[0]
"Note we can always fix a portion of our parameters, to span only a subset of unitary space – indeed, our benchmark test below will show that for certain tasks, full unitary space parametrization is not necessary.",4.1. Unitary Matrix Parametrization,[0],[0]
2,4.1. Unitary Matrix Parametrization,[0],[0]
"The representation in Eq. 12 can be made more compact by reordering and grouping specific rotational matrices, as was shown in the optical community (Reck et al., 1994; Clements et al., 2016) in the context of universal multiport interferometers.",4.2. Tunable space implementation,[0],[0]
"For example (Clements et al., 2016), a unitary matrix can be decomposed as
WN = D ( R (1) 1,2R (1) 3,4 . .",4.2. Tunable space implementation,[0],[0]
.R,4.2. Tunable space implementation,[0],[0]
"(1) N/2−1,N/2 )",4.2. Tunable space implementation,[0],[0]
"× ( R
(2) 2,3R (2) 4,5 . .",4.2. Tunable space implementation,[0],[0]
.R,4.2. Tunable space implementation,[0],[0]
"(2) N/2−2,N/2−1 )",4.2. Tunable space implementation,[0],[0]
"× . . .
",4.2. Tunable space implementation,[0],[0]
= DF (1) A F (2) B . .,4.2. Tunable space implementation,[0],[0]
".F (L) B , (14)
",4.2. Tunable space implementation,[0],[0]
"where every
F (l) A = R (l) 1,2R (l) 3,4 . .",4.2. Tunable space implementation,[0],[0]
.R,4.2. Tunable space implementation,[0],[0]
"(l) N/2−1,N/2
is a block diagonal matrix, with N angle parameters in total, and
",4.2. Tunable space implementation,[0],[0]
F (l) B = R,4.2. Tunable space implementation,[0],[0]
"(l) 2,3R (l) 4,5 . .",4.2. Tunable space implementation,[0],[0]
.R,4.2. Tunable space implementation,[0],[0]
"(l) N/2−2,N/2−1
withN−1 parameters, as is schematically shown in Fig.",4.2. Tunable space implementation,[0],[0]
1a.,4.2. Tunable space implementation,[0],[0]
"By choosing different values for L , WN will span a different subspace of the unitary space.",4.2. Tunable space implementation,[0],[0]
"Specifically,when L = N , WN will span the entire unitary space.
",4.2. Tunable space implementation,[0],[0]
"Following this physics-inspired scheme, we decompose our unitary hidden-to-hidden layer matrix W as
W = DF (1) A F (2) B F (3) A F (4) B · · ·F (L) B .",4.2. Tunable space implementation,[0],[0]
(15),4.2. Tunable space implementation,[0],[0]
"Inspired by (Mathieu & LeCun, 2014a), an alternative way to organize the rotation matrices is implementing an FFTstyle architecture.",4.3. FFT-style approximation,[0],[0]
"Instead of using adjacent rotation matrices, each F here performs a certain distance pairwise rotations as shown in Fig.",4.3. FFT-style approximation,[0],[0]
"1b:
W = DF1F2F3F4 · · ·Flog(N).",4.3. FFT-style approximation,[0],[0]
"(16)
",4.3. FFT-style approximation,[0],[0]
"The rotation matrices in Fi are performed between pairs of coordinates
(2pk + j, p(2k + 1) + j) (17)
2Our preliminary experimental tests even suggest that a fullcapacity unitary RNN is even undesirable for some tasks.
where p = N2i , k ∈ {0, ..., 2 i−1} and j ∈ {1, ..., p}.",4.3. FFT-style approximation,[0],[0]
"This requires only log(N) matrices, so there are a total of N log(N)/2 rotational pairs.",4.3. FFT-style approximation,[0],[0]
"This is also the minimal number of rotations that can have all input coordinates interacting with each other, providing an approximation of arbitrary unitary matrices.",4.3. FFT-style approximation,[0],[0]
"To implement this decomposition efficiently in an RNN, we apply vector element-wise multiplications and permutations: we evaluate the product Fx as
Fx = v1 ∗ x + v2 ∗ permute(x) (18)
where ∗ represents element-wise multiplication, F refers to general rotational matrices such as FA/B in Eq. 14 and Fi in Eq. 16.",4.4. Efficient implementation of rotation matrices,[0],[0]
"For the case of the tunable-space implementation, if we want to implement F(l)A in Eq. 14, we define v and the permutation as follows:
v1 = (e iφ (l) 1 cos θ (l) 1 , cos θ (l) 1 , e iφ (l) 2",4.4. Efficient implementation of rotation matrices,[0],[0]
"cos θ (l) 2 , cos θ (l) 2 , · · · )
v2 = (−eiφ (l) 1 sin θ",4.4. Efficient implementation of rotation matrices,[0],[0]
"(l) 1 , sin θ (l) 1 ,−eiφ (l) 2 sin θ2, sin θ (l) 2 , · · · )
",4.4. Efficient implementation of rotation matrices,[0],[0]
permute(x) =,4.4. Efficient implementation of rotation matrices,[0],[0]
"(x2, x1, x4, x3, x6, x5, · · · ).
",4.4. Efficient implementation of rotation matrices,[0],[0]
"For the FFT-style approach, if we want to implement F1 in Eq 16, we define v and the permutation as follows:
v1 = (e iφ (l) 1",4.4. Efficient implementation of rotation matrices,[0],[0]
"cos θ (l) 1 , e iφ (l) 2 cos θ (l) 2 , · · · , cos θ (l) 1 , · · · )
v2 = (−eiφ (l) 1 sin θ",4.4. Efficient implementation of rotation matrices,[0],[0]
"(l) 1 ,−eiφ (l) 2 sin θ2, · · · , sin θ(l)1 , · · · )
",4.4. Efficient implementation of rotation matrices,[0],[0]
permute(x) =,4.4. Efficient implementation of rotation matrices,[0],[0]
"(xn 2 +1 , xn 2 +2 · · ·xn, x1, x2 · · · ).
",4.4. Efficient implementation of rotation matrices,[0],[0]
"In general, the pseudocode for implementing operation F is as follows:
Algorithm 1 Efficient implementation for F with parameter θi and φi.
",4.4. Efficient implementation of rotation matrices,[0],[0]
"Input: input x, size N ; parameters θ and φ, size N/2; constant permuatation index list ind1 and ind2.",4.4. Efficient implementation of rotation matrices,[0],[0]
"Output: output y, size N .",4.4. Efficient implementation of rotation matrices,[0],[0]
"v1← concatenate(cos θ, cos θ * exp(iφ))",4.4. Efficient implementation of rotation matrices,[0],[0]
v2← concatenate(sin,4.4. Efficient implementation of rotation matrices,[0],[0]
"θ, - sin θ * exp(iφ)) v1← permute(v1, ind1) v2← permute(v2, ind1) y← v1 ∗ x + v2 ∗ permute(x, ind2)
",4.4. Efficient implementation of rotation matrices,[0],[0]
"Note that ind1 and ind2 are different for different F.
From a computational complexity viewpoint, since the operations ∗ and permute take O(N) computational steps, evaluating Fx only requires O(N) steps.",4.4. Efficient implementation of rotation matrices,[0],[0]
"The product Dx is trivial, consisting of an element-wise vector multiplication.",4.4. Efficient implementation of rotation matrices,[0],[0]
"Therefore, the product Wx with the total unitary
matrix W can be computed in only O(NL) steps, and only requires O(NL) memory access (for full-space implementation L = N , for FFT-style approximation gives L = logN ).",4.4. Efficient implementation of rotation matrices,[0],[0]
A detailed comparison on computational complexity of the existing unitary RNN architectures is given in Table 1.,4.4. Efficient implementation of rotation matrices,[0],[0]
"We use the same nonlinearity as (Arjovsky et al., 2015):
(modReLU(z,b))i = zi |zi| ∗ ReLU(|zi|+ bi) (19)
where the bias vector b is a shared trainable parameter, and |zi| is the norm of the complex number zi.
",4.5. Nonlinearity,[0],[0]
"For real number input, modReLU can be simplified to:
(modReLU(z,b))i = sign(zi) ∗ ReLU(|zi|+ bi) (20)
where |zi| is the absolute value of the real number zi.
",4.5. Nonlinearity,[0],[0]
We empirically find that this nonlinearity function performs the best.,4.5. Nonlinearity,[0],[0]
We believe that this function possibly also serves as a forgetting filter that removes the noise using the bias threshold.,4.5. Nonlinearity,[0],[0]
"In this section, we compare the performance of our Efficient Unitary Recurrent Neural Network (EURNN) with
1.",5. Experimental tests of our method,[0],[0]
"an LSTM RNN (Hochreiter & Schmidhuber, 1997),
2.",5. Experimental tests of our method,[0],[0]
"a Partial Space URNN (Arjovsky et al., 2015), and
3.",5. Experimental tests of our method,[0],[0]
"a Projective full-space URNN (Wisdom et al., 2016).
",5. Experimental tests of our method,[0],[0]
"All models are implemented in both Tensorflow and Theano, available from https://github.com/ jingli9111/EUNN-tensorflow and https: //github.com/iguanaus/EUNN-theano.",5. Experimental tests of our method,[0],[0]
"We compare these networks by applying them all to the well defined Copying Memory Task (Hochreiter & Schmidhuber, 1997; Arjovsky et al., 2015; Henaff et al., 2016).",5.1. Copying Memory Task,[0],[0]
"The copying task is a synthetic task that is commonly used to test the network’s ability to remember information seen T time steps earlier.
",5.1. Copying Memory Task,[0],[0]
"Specifically, the task is defined as follows (Hochreiter & Schmidhuber, 1997; Arjovsky et al., 2015; Henaff et al., 2016).",5.1. Copying Memory Task,[0],[0]
"An alphabet consists of symbols {ai}, the first n of which represent data, and the remaining two representing “blank” and “start recall”, respectively; as illustrated by the following example where T = 20 and M = 5:
Input: BACCA--------------------:---Output: -------------------------BACCA
In the above example, n = 3 and {ai} = {A,B,C,−, :}.",5.1. Copying Memory Task,[0],[0]
"The input consists of M random data symbols (M = 5 above) followed by T − 1 blanks, the “start recall” symbol and M more blanks.",5.1. Copying Memory Task,[0],[0]
The desired output consists of M +T blanks followed by the data sequence.,5.1. Copying Memory Task,[0],[0]
"The cost function C is defined as the cross entropy of the input and output sequences, which vanishes for perfect performance.
",5.1. Copying Memory Task,[0],[0]
We use n = 8 and input length M = 10.,5.1. Copying Memory Task,[0],[0]
The symbol for each input is represented by an n-dimensional one-hot vector.,5.1. Copying Memory Task,[0],[0]
We trained all five RNNs for T = 1000 with the same batch size 128 using RMSProp optimization with a learning rate of 0.001.,5.1. Copying Memory Task,[0],[0]
"The decay rate is set to 0.5 for EURNN, and 0.9 for all other models respectively.",5.1. Copying Memory Task,[0],[0]
(Fig. 2).,5.1. Copying Memory Task,[0],[0]
"This results show that the EURNN architectures introduced in both Sec.4.2 (EURNN with N=512, selecting L=2) and Sec.4.3 (FFT-style EURNN with N=512) outperform the LSTM model (which suffers from long term memory problems and only performs well on the copy task for small time delays T ) and all other unitary RNN models, both in-terms of learnability and in-terms of convergence rate.",5.1. Copying Memory Task,[0],[0]
"Note that the only other unitary RNN model that is able to beat the baseline for T = 1000 (Wisdom et al., 2016) is significantly slower than our method.
",5.1. Copying Memory Task,[0],[0]
"Moreover, we find that by either choosing smaller L or by using the FFT-style method (so that W spans a smaller unitary subspace), the EURNN converges toward optimal performance significantly more efficiently (and also faster in wall clock time) than the partial (Arjovsky et al., 2015) and projective (Wisdom et al., 2016) unitary methods.",5.1. Copying Memory Task,[0],[0]
The EURNN also performed more robustly.,5.1. Copying Memory Task,[0],[0]
This means that a fullcapacity unitary matrix is not necessary for this particular task.,5.1. Copying Memory Task,[0],[0]
The MNIST handwriting recognition problem is one of the classic benchmarks for quantifying the learning ability of neural networks.,5.2. Pixel-Permuted MNIST Task,[0],[0]
"MNIST images are formed by a 28×28 grayscale image with a target label between 0 and 9.
",5.2. Pixel-Permuted MNIST Task,[0],[0]
"To test different RNN models, we feed all pixels of the MNIST images into the RNN models in 28×28 time steps, where one pixel at a time is fed in as a floating-point number.",5.2. Pixel-Permuted MNIST Task,[0],[0]
A fixed random permutation is applied to the order of input pixels.,5.2. Pixel-Permuted MNIST Task,[0],[0]
The output is the probability distribution quantifying the digit prediction.,5.2. Pixel-Permuted MNIST Task,[0],[0]
"We used RMSProp with a learning rate of 0.0001 and a decay rate of 0.9, and set the batch size to 128.
",5.2. Pixel-Permuted MNIST Task,[0],[0]
"As shown in Fig. 3, EURNN significantly outperforms LSTM with the same number of parameters.",5.2. Pixel-Permuted MNIST Task,[0],[0]
"It learns faster, in fewer iteration steps, and converges to a higher classifi-
Model hidden size number of validation test (capacity) parameters accuracy accuracy LSTM 80 16k 0.908 0.902 URNN 512 16k 0.942 0.933
PURNN 116 16k 0.922 0.921 EURNN (tunable style) 1024 (2) 13.3k 0.940 0.937
EURNN (FFT style) 512 (FFT) 9.0k 0.928 0.925
cation accuracy.",5.2. Pixel-Permuted MNIST Task,[0],[0]
"In addition, the EURNN reaches a similar accuracy with fewer parameters.",5.2. Pixel-Permuted MNIST Task,[0],[0]
In Table.,5.2. Pixel-Permuted MNIST Task,[0],[0]
"2, we compare the performance of different RNN models on this task.",5.2. Pixel-Permuted MNIST Task,[0],[0]
We also apply our EURNN to real-world speech prediction task and compare its performance to LSTM.,5.3. Speech Prediction on TIMIT dataset,[0],[0]
"The main task we consider is predicting the log-magnitude of future frames of a short-time Fourier transform (STFT) (Wisdom et al., 2016; Sejdi et al., 2009).",5.3. Speech Prediction on TIMIT dataset,[0],[0]
"We use the TIMIT dataset (Garofolo et al., 1993) sampled at 8 kHz.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
The audio .wav file is initially diced into different time frames (all frames have the same duration referring to the Hann analysis window below).,5.3. Speech Prediction on TIMIT dataset,[0],[0]
"The audio amplitude in each frame is then
Fourier transformed into the frequency domain.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
The logmagnitude of the Fourier amplitude is normalized and used as the data for training/testing each model.,5.3. Speech Prediction on TIMIT dataset,[0],[0]
In our STFT operation we uses a Hann analysis window of 256 samples (32 milliseconds) and a window hop of 128 samples (16 milliseconds).,5.3. Speech Prediction on TIMIT dataset,[0],[0]
"The frame prediction task is as follows: given all the log-magnitudes of STFT frames up to time t, predict the log-magnitude of the STFT frame at time t+ 1 that has the minimum mean square error (MSE).",5.3. Speech Prediction on TIMIT dataset,[0],[0]
"We use
a training set with 2400 utterances, a validation set of 600 utterances and an evaluation set of 1000 utterances.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
"The training, validation, and evaluation sets have distinct speakers.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
"We trained all RNNs for with the same batch size 32 using RMSProp optimization with a learning rate of 0.001, a momentum of 0.9 and a decay rate of 0.1.
",5.3. Speech Prediction on TIMIT dataset,[0],[0]
The results are given in Table.,5.3. Speech Prediction on TIMIT dataset,[0],[0]
"3, in terms of the meansquared error (MSE) loss function.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
Figure.,5.3. Speech Prediction on TIMIT dataset,[0],[0]
"4 shows prediction examples from the three types of networks, illustrat-
ing how EURNNs generally perform better than LSTMs.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
"Furthermore, in this particular task, full-capacity EURNNs outperform small capacity EURNNs and FFT-style EURNNs.",5.3. Speech Prediction on TIMIT dataset,[0],[0]
"We have presented a method for implementing an Efficient Unitary Neural Network (EUNN) whose computational cost is merely O(1) per parameter, which is O(logN) more efficient than the other methods discussed above.",6. Conclusion,[0],[0]
"It significantly outperforms existing RNN architectures on the standard Copying Task, and the pixel-permuted MNIST Task using a comparable parameter count, hence demonstrating the highest recorded ability to memorize sequential information over long time periods.
",6. Conclusion,[0],[0]
"It also performs well on real tasks such as speech prediction, outperforming an LSTM on TIMIT data speech prediction.
",6. Conclusion,[0],[0]
We want to emphasize the generality and tunability of our method.,6. Conclusion,[0],[0]
The ordering of the rotation matrices we presented in Fig. 1 are merely two of many possibilities; we used it simply as a concrete example.,6. Conclusion,[0],[0]
"Other ordering options that can result in spanning the full unitary matrix space can be used for our algorithm as well, with identical speed and memory performance.",6. Conclusion,[0],[0]
"This tunability of the span of the unitary space and, correspondingly, the total number of parameters makes it possible to use different capacities for different tasks, thus opening the way to an optimal performance of the EUNN.",6. Conclusion,[0],[0]
"For example, as we have shown, a small subspace of the full unitary space is preferable for the copying task, whereas the MNIST task and TIMIT task are better performed by EUNN covering a considerably larger unitary space.",6. Conclusion,[0],[0]
"Finally, we note that our method remains applicable even if the unitary matrix is decomposed into a different product of matrices (Eq. 12).
",6. Conclusion,[0],[0]
This powerful and robust unitary RNN architecture also might be promising for natural language processing because of its ability to efficiently handle tasks with long-term correlation and very high dimensionality.,6. Conclusion,[0],[0]
"We thank Hugo Larochelle and Yoshua Bengio for helpful discussions and comments.
",Acknowledgment,[0],[0]
"This work was partially supported by the Army Research Office through the Institute for Soldier Nanotechnologies under contract W911NF-13-D0001, the National Science Foundation under Grant No. CCF-1640012 and the Rothberg Family Fund for Cognitive Science.",Acknowledgment,[0],[0]
"Using unitary (instead of general) matrices in artificial neural networks (ANNs) is a promising way to solve the gradient explosion/vanishing problem, as well as to enable ANNs to learn long-term correlations in the data.",abstractText,[0],[0]
This approach appears particularly promising for Recurrent Neural Networks (RNNs).,abstractText,[0],[0]
"In this work, we present a new architecture for implementing an Efficient Unitary Neural Network (EUNNs); its main advantages can be summarized as follows.",abstractText,[0],[0]
"Firstly, the representation capacity of the unitary space in an EUNN is fully tunable, ranging from a subspace of SU(N) to the entire unitary space.",abstractText,[0],[0]
"Secondly, the computational complexity for training an EUNN is merelyO(1) per parameter.",abstractText,[0],[0]
"Finally, we test the performance of EUNNs on the standard copying task, the pixelpermuted MNIST digit recognition benchmark as well as the Speech Prediction Test (TIMIT).",abstractText,[0],[0]
"We find that our architecture significantly outperforms both other state-of-the-art unitary RNNs and the LSTM architecture, in terms of the final performance and/or the wall-clock training speed.",abstractText,[0],[0]
EUNNs are thus promising alternatives to RNNs and LSTMs for a wide variety of applications.,abstractText,[0],[0]
Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1369–1379 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1369",text,[0],[0]
"Now that algorithms have started to produce relevant and realistic natural language that can describe images and videos, we would like to understand what these models truly comprehend.",1 Introduction,[0],[0]
The Visual Question Answering (VQA) task provides a nice tool for fine-grained evaluation of such multimodal algorithms.,1 Introduction,[0],[0]
"VQA systems take as input an image (or video) along with relevant natural language questions, and produce answers to those questions.",1 Introduction,[0],[0]
"By asking algorithms to answer different types of questions, ranging from object identification, counting, or appearance, to more complex questions about interactions, social relationships, or inferences about why or how something is occurring, we can evaluate different aspects of a model’s multimodal semantic understanding.
",1 Introduction,[0],[0]
"As a result, several popular image-based VQA datasets have been introduced, including DAQUAR (Malinowski and Fritz, 2014), COCO-QA (Ren et al., 2015a), FM-IQA (Gao
et al., 2015), Visual Madlibs (Yu et al., 2015), VQA (Antol et al., 2015), Visual7W (Zhu et al., 2016), etc.",1 Introduction,[0],[0]
"In addition, multiple video-based QA datasets have also been collected recently, e.g., MovieQA (Tapaswi et al., 2016), MovieFIB (Maharaj et al., 2017a), PororoQA (Kim et al., 2017), TGIF-QA (Jang et al., 2017), etc.",1 Introduction,[0],[0]
"However, there exist various shortcomings for each such video QA dataset.",1 Introduction,[0],[0]
"For example, MovieFIB’s video clips are typically short (∼4 secs), and focused on purely visual concepts (since they were collected from audio descriptions for the visually impaired); MovieQA collected QAs based on text summaries only, making them very plot-focused and less relevant for visual information; PororoQA’s video domain is cartoon-based; and TGIF-QA used predefined templates for generation on short GIFs.
",1 Introduction,[0],[0]
"With video-QA in particular, as opposed to image-QA, the video itself often comes with associated natural language in the form of (subtitle) dialogue.",1 Introduction,[0],[0]
"We argue that this is an important area to study because it reflects the real world, where people interact through language, and where many computational systems like robots or other intelligent agents will ultimately have to operate.",1 Introduction,[0],[0]
"As such, systems will need to combine information from what they see with what they hear, to pose and answer questions about what is happening.
",1 Introduction,[0],[0]
We aim to provide a dataset that merges the best qualities from all of the previous datasets as well as focus on multimodal compositionality.,1 Introduction,[0],[0]
"In particular, we collect a new large-scale dataset that is built on natural video content with rich dynamics and realistic social interactions, where questionanswer pairs are written by people observing both videos and their accompanying dialogues, encouraging the questions to require both vision and language understanding to answer.",1 Introduction,[0],[0]
"To further encourage this multimodal-QA quality, we ask people to write compositional questions consisting
of two parts, a main question part, e.g. “What are Leonard and Sheldon arguing about” and a grounding part, e.g. “when they are sitting on the couch”.",1 Introduction,[0],[0]
"This also leads to an interesting secondary task of QA temporal localization.
",1 Introduction,[0],[0]
"Our contribution is the TVQA dataset, built on 6 popular TV shows spanning 3 genres: medical dramas, sitcoms, and crime shows.",1 Introduction,[0],[0]
"On this data, we collected 152.5K human-written QA pairs (examples shown in Fig.1).",1 Introduction,[0],[0]
There are 4 salient advantages of our dataset.,1 Introduction,[0],[0]
"First, it is large-scale and natural, containing 21,793 video clips from 925 episodes.",1 Introduction,[0],[0]
"On average, each show has 7.3 seasons, providing long range character interactions and evolving relationships.",1 Introduction,[0],[0]
"Each video clip is associated with 7 questions, with 5 answers (1 correct) for each question.",1 Introduction,[0],[0]
"Second, our video clips are relatively long (60-90 seconds), thereby containing more social interactions and activities, making video understanding more challenging.",1 Introduction,[0],[0]
"Third, we provide the dialogue (character name + subtitle) for each QA video clip.",1 Introduction,[0],[0]
Understanding the relationship between the provided dialogue and the question-answer pairs is crucial for correctly answering many of the collected questions.,1 Introduction,[0],[0]
"Fourth, our questions are compositional, requiring algorithms to localize relevant moments (START and END points are provided for each question).
",1 Introduction,[0],[0]
"With the above rich annotation, our dataset supports three tasks: QA on the grounded clip, question-driven moment localization, and QA on the full video clip.",1 Introduction,[0],[0]
We provide baseline experiments on both QA tasks and introduce a state-ofthe-art language and vision-based model (leaving moment localization for future work).,1 Introduction,[0],[0]
"Visual Question Answering: Several imagebased VQA datasets have recently been constructed, e.g., DAQUAR (Malinowski and Fritz, 2014), VQA (Antol et al., 2015), COCO-Q (Ren et al., 2015a), FM-IQA (Gao et al., 2015), Visual Madlibs (Yu et al., 2015), Visual7W (Zhu et al., 2016), CLEVR (Johnson et al., 2017), etc.",2 Related Work,[0],[0]
"Additionally, several video-based QA datasets have also been proposed, e.g. TGIF-QA (Jang et al., 2017), MovieFIB (Maharaj et al., 2017b), VideoQA",2 Related Work,[0],[0]
"(Zhu et al., 2017), LSMDC (Rohrbach et al., 2015), TRECVID (Over et al., 2014), MovieQA (Tapaswi et al., 2016), PororoQA (Kim et al., 2017) and MarioQA (Mun et al., 2017).",2 Related Work,[0],[0]
"However, none of these datasets provides a truly realistic, multimodal QA scenario where both visual and language understanding are required to answer a large portion of questions, either due to unrealistic video sources (PororoQA, MarioQA) or data collection strategy being more focused on either visual (MovieFIB, VideoQA, TGIF-QA) or language (MovieQA) sources.",2 Related Work,[0],[0]
"In comparison, our TVQA collection strategy takes a directly multimodal approach to construct a large-scale, realvideo dataset by letting humans ask and answer questions while watching TV-show videos with associated dialogues.",2 Related Work,[0],[0]
"Text Question Answering: The related task of text-based question answering has been extensively explored (Richardson et al., 2013; Weston et al., 2015; Rajpurkar et al., 2016; Hermann et al., 2015; Hill et al., 2015).",2 Related Work,[0],[0]
"Richardson et al. (2013) collected MCTest, a multiple choice QA dataset intended for open-domain reading comprehension.
",2 Related Work,[0],[0]
"With the same goal in mind, Rajpurkar et al. (2016) introduced the SQuAD dataset, but their answers are specific spans from long passages.",2 Related Work,[0],[0]
Weston et al. (2015) designed a set of tasks with automatically generated QAs to evaluate the textual reasoning ability of artificial agents and Hermann et al. (2015); Hill et al. (2015) constructed the cloze dataset on top of an existing corpus.,2 Related Work,[0],[0]
"While questions in these text QA datasets are specifically designed for language understanding, TVQA questions require both vision understanding and language understanding.",2 Related Work,[0],[0]
"Although methods developed for text QA are not directly applicable to TVQA tasks, they can provide inspiration for designing suitable models.",2 Related Work,[0],[0]
Natural Language Object Retrieval: Language grounding addresses the task of object or moment localization in an image or video from a natural language description.,2 Related Work,[0],[0]
"For image-based object grounding, there has been much work on phrase grounding (Plummer et al., 2015; Wang et al., 2016b; Rohrbach et al., 2016) and referring expression comprehension (Hu et al., 2016; Yu et al., 2016; Nagaraja et al., 2016; Yu et al., 2017, 2018b).",2 Related Work,[0],[0]
"Recent work (Vasudevan et al., 2018) extends the grounding task to the video domain.",2 Related Work,[0],[0]
"Most recently, moment localization was proposed in (Hendricks et al., 2017; Gao et al., 2017), where the goal is to localize a short moment from a long video sequence given a query description.",2 Related Work,[0],[0]
Accurate temporal grounding is a necessary step to answering our compositional questions.,2 Related Work,[0],[0]
"We collected our dataset on 6 long-running TV shows from 3 genres: 1) sitcoms: The Big Bang Theory, How I Met Your Mother, Friends, 2) medical dramas: Grey’s Anatomy, House, 3) crime drama: Castle.",3.1 Dataset Collection,[0],[0]
There are in total 925 episodes spanning 461 hours.,3.1 Dataset Collection,[0],[0]
Each episode was then segmented into short clips.,3.1 Dataset Collection,[0],[0]
"We first created clips every 60/90 seconds, then shifted temporal boudaries to avoid splitting subtitle sentences between clips.",3.1 Dataset Collection,[0],[0]
"Shows that are mainly conversational based, e.g., The Big Bang Theory, were segmented into 60 seconds clips, while shows that are less cerebral, e.g. Castle, were segmented into 90 seconds clips.",3.1 Dataset Collection,[0],[0]
"In the end, 21,793 clips were prepared for QA collection, accompanied with subtitles and aligned with transcripts to add character names.",3.1 Dataset Collection,[0],[0]
"A
sample clip is shown in Fig. 1.",3.1 Dataset Collection,[0],[0]
"Amazon Mechanical Turk was used for VQA collection on video clips, where workers were presented with both videos and aligned named subtitles, to encourage multimodal questions requiring both vision and language understanding to answer.",3.1 Dataset Collection,[0],[0]
Workers were asked to create questions using a compositional-question format:,3.1 Dataset Collection,[0],[0]
[What/How/Where/Why/...],3.1 Dataset Collection,[0],[0]
[when/before/after] .,3.1 Dataset Collection,[0],[0]
"The second part of each question serves to localize the relevant video moment within a clip, while the first part poses a question about that moment.",3.1 Dataset Collection,[0],[0]
"This compositional format also serves to encourage questions that require both visual and language understanding to answer, since people often naturally use visual signals to ground questions in time, e.g. What was House saying before he leaned over the bed?",3.1 Dataset Collection,[0],[0]
"During data collection, we only used prompt words (when/before/after) to encourage workers to propose the desired, complex compositional questions.",3.1 Dataset Collection,[0],[0]
There were no additional template constraints.,3.1 Dataset Collection,[0],[0]
"Therefore, most of the language in the questions is relatively free-form and complex.
",3.1 Dataset Collection,[0],[0]
"Ultimately, workers pose 7 different questions for each video clip.",3.1 Dataset Collection,[0],[0]
"For each question, we asked workers to annotate the exact video portion required to answer the question by marking the START and END timestamps as in Krishna et al. (2017).",3.1 Dataset Collection,[0],[0]
"In addition, they provide 1 correct and 4 wrong answers for each question.",3.1 Dataset Collection,[0],[0]
Workers get paid $1.3 for a single video clip annotation.,3.1 Dataset Collection,[0],[0]
"The whole collection process took around 3 months.
",3.1 Dataset Collection,[0],[0]
"To ensure the quality of the questions and answers, we set up an online checker in our collection interface to verify the question format, allowing only questions that reflect our two-step format to be submitted.",3.1 Dataset Collection,[0],[0]
The collection was done in batches of 500 videos.,3.1 Dataset Collection,[0],[0]
"For each harvested batch, we sampled 3 pairs of submitted QAs from each worker and checked the semantic correctness of the questions, answers, and timestamps.",3.1 Dataset Collection,[0],[0]
Multiple Choice QAs:,3.2 Dataset Analysis,[0],[0]
"Our QAs are multiple choice questions with 5 candidate answers for each question, for which only one is correct.",3.2 Dataset Analysis,[0],[0]
Table 1 provides statistics of the QAs based on the first question word.,3.2 Dataset Analysis,[0],[0]
"On average, our questions contain 13.5 words, which is fairly long compared to other datasets.",3.2 Dataset Analysis,[0],[0]
"In general, correct answers tend
to be slightly longer than wrong answers.",3.2 Dataset Analysis,[0],[0]
Fig. 2 shows the distribution of different questions types.,3.2 Dataset Analysis,[0],[0]
"Note “what” (Abstract, Object, Action), “who” (Person), “why” (Reasoning) and “where” (Location) questions form a large part of our data.
",3.2 Dataset Analysis,[0],[0]
The negative answers in TVQA are written by human annotators.,3.2 Dataset Analysis,[0],[0]
They are instructed to write false but relevant answers to make the negatives challenging.,3.2 Dataset Analysis,[0],[0]
"Alternative methods include sampling negative answers from other questions’ correct answers, either based on semantic similarity (Das et al., 2017; Jang et al., 2017) or randomly (Antol et al., 2015; Das et al., 2017).",3.2 Dataset Analysis,[0],[0]
"The former is prone to introducing paraphrases of the ground-truth answer (Zhu et al., 2016).",3.2 Dataset Analysis,[0],[0]
"The latter avoids the problem of paraphrasing, but generally produces irrelevant negative choices.",3.2 Dataset Analysis,[0],[0]
We show in Table 8 that our human written negatives are more challenging than randomly sampled negatives.,3.2 Dataset Analysis,[0],[0]
Moment Localization:,3.2 Dataset Analysis,[0],[0]
The second part of our question is used to localize the most relevant video portion to answer the question.,3.2 Dataset Analysis,[0],[0]
"The prompt of “when”, “after”, “before” account for 60.03%, 30.19% and 9.78% respectively of our dataset.",3.2 Dataset Analysis,[0],[0]
TVQA provides the annotated START and END timestamps for each QA.,3.2 Dataset Analysis,[0],[0]
"We show the annotated
segment lengths in Fig. 3.",3.2 Dataset Analysis,[0],[0]
We found most of the questions rely on relatively short moments (less than 15 secs) within a longer clip (60-90 secs).,3.2 Dataset Analysis,[0],[0]
Differences among our 6 TV Shows: The videos used in our dataset are from 6 different TV shows.,3.2 Dataset Analysis,[0],[0]
Table 2 provides statistics for each show.,3.2 Dataset Analysis,[0],[0]
A good way to demonstrate the difference among questions from TV shows is to show their top unique nouns.,3.2 Dataset Analysis,[0],[0]
"In Table 3, we present such an analysis.",3.2 Dataset Analysis,[0],[0]
"The top unique nouns in sitcoms (BBT, Friends, HIMYM) are mostly daily objects, scenes and actions, while medical dramas (Grey, House) questions contain more medical terms, and crime shows (Castle) feature detective terms.",3.2 Dataset Analysis,[0],[0]
"Although similar, there are also notable differences among shows in the same genre.",3.2 Dataset Analysis,[0],[0]
"For example, BBT con-
tains “game” and “laptop” while HIMYM contains “bar” and “beer”, indicating the different major activities and topics in each show.",3.2 Dataset Analysis,[0],[0]
"Additionally, questions about different characters also mention different words, as shown in Table 4.",3.2 Dataset Analysis,[0],[0]
Comparison with Other Datasets: Table 5 presents a comparison of our dataset to some recently proposed video question answering datasets.,3.2 Dataset Analysis,[0],[0]
"In terms of total length of videos, TVQA is the largest, with a total of 461.2 hours of videos.",3.2 Dataset Analysis,[0],[0]
"MovieQA (Tapaswi et al., 2016) is most similar to our dataset, with both multiple choice questions and timestamp annotation.",3.2 Dataset Analysis,[0],[0]
"However, their questions and answers are constructed by people posing questions from a provided plot summary, then later aligned to the video clips, which makes most of their questions text oriented.",3.2 Dataset Analysis,[0],[0]
"Human Evaluation on Usefulness of Video and Subtitle in Dataset: To gain a better understand-
ing of the roles of videos and subtitles in the our dataset, we perform a human study, asking different groups of workers to complete the QA task in settings while observing different sources (subsets) of information:
• Question only.",3.2 Dataset Analysis,[0],[0]
• Video and Question.,3.2 Dataset Analysis,[0],[0]
•,3.2 Dataset Analysis,[0],[0]
Subtitle and Question.,3.2 Dataset Analysis,[0],[0]
"• Video, Subtitle, and Question.
",3.2 Dataset Analysis,[0],[0]
We made sure the workers that have written the questions did not participate in this study and that workers see only one of the above settings for answering each question.,3.2 Dataset Analysis,[0],[0]
Human accuracy on our test set under these 4 settings are reported in Table 5.,3.2 Dataset Analysis,[0],[0]
"As expected, compared to human accuracy based only on question-answer pairs (Q), adding videos (V+Q), or subtitles (S+Q) significantly improves human performance.",3.2 Dataset Analysis,[0],[0]
Adding both videos and subtitles (V+S+Q) brings the accuracy to 89.41%.,3.2 Dataset Analysis,[0],[0]
"This indicates that in order to answer the questions correctly, both visual and textual understanding are essential.",3.2 Dataset Analysis,[0],[0]
"We also observe that workers obtain 31.84% accuracy given questionanswer pairs only, which is higher than random guessing (20%).",3.2 Dataset Analysis,[0],[0]
We ascribe this to people’s prior knowledge about the shows.,3.2 Dataset Analysis,[0],[0]
"Note, timestamp annotations are not provided in these experiments.",3.2 Dataset Analysis,[0],[0]
We introduce a multi-stream end-to-end trainable neural network for Multi-Modal Video Question Answering.,4 Methods,[0],[0]
Fig. 4 gives an overview of our model.,4 Methods,[0],[0]
"Formally, we define the inputs to the model as: a 60-90 second video clip V , a subtitle S, a question q, and five candidate answers {ai}4i=0.",4 Methods,[0],[0]
Frames are extracted at 3 fps.,4.1 Video Features,[0],[0]
"We run Faster RCNN (Ren et al., 2015b) trained on the Visual
Genome (Krishna et al., 2017) to detect object and attribute regions in each frame.",4.1 Video Features,[0],[0]
Both regional features and predicted detection labels can be used as model inputs.,4.1 Video Features,[0],[0]
"We also use ResNet101 (He et al., 2016) trained on ImageNet (Deng et al., 2009) to extract whole image features.",4.1 Video Features,[0],[0]
"Regional Visual Features: On average, our videos contain 229 frames, with 16 detections per frame.",4.1 Video Features,[0],[0]
It is not trivial to model such long sequences.,4.1 Video Features,[0],[0]
"For simplicity, we follow (Anderson et al., 2018; Karpathy and Fei-Fei, 2015) selecting the top-K regions1 from each detected label across all frames.",4.1 Video Features,[0],[0]
Their regional features are L2normalized and stacked together to form our visual representation V reg ∈ Rnreg×2048.,4.1 Video Features,[0],[0]
Here nreg is the number of selected regions.,4.1 Video Features,[0],[0]
"Visual Concept Features: Recent work (Yin and Ordonez, 2017) found that using detected object
1Based on cross-validation, we find K=6 to perform best.
labels as input to an image captioning system gave comparable performance to using CNN features directly.",4.1 Video Features,[0],[0]
"Inspired by this work, we also experiment with using detected labels as visual inputs.",4.1 Video Features,[0],[0]
"As shown in Fig. 5, we are able to detect rich visual concepts, including both objects and attributes, e.g. ”white basket”, which could be used to answer “What is Sheldon holding in his hand when everyone is at the door”.",4.1 Video Features,[0],[0]
We first gather detected concepts over all the frames to represent concept presence.,4.1 Video Features,[0],[0]
"After removing duplicate concepts, we use GloVe (Pennington et al., 2014) to embed the words.",4.1 Video Features,[0],[0]
"The resulting video representation is denoted as V cpt ∈ Rncpt×300, where ncpt is the number of unique concepts.",4.1 Video Features,[0],[0]
ImageNet Features: We extract the pooled 2048D feature of the last block of ResNet101.,4.1 Video Features,[0],[0]
"Features from the same video clip are L2 normalized and stacked, denoted as V img ∈ Rnimg×2048, where nimg is the number of frames extracted from the video clip.",4.1 Video Features,[0],[0]
We use a bi-directional LSTM (BiLSTM) to encode both textual and visual sequences.,4.2 LSTM Encoders for Video and Text,[0],[0]
"A subtitle S, which contains a set of sentences, is flattened into a long sequence of words and GloVe (Pennington et al., 2014) is used to embed the words.",4.2 LSTM Encoders for Video and Text,[0],[0]
"We stack the hidden states of the BiLSTM from both directions at each timestep to obtain the subtitle representation HS ∈ RnS×2d, where nS is the number of subtitle words, d is the hidden size of the BiLSTM (set to 150 in our experiments).",4.2 LSTM Encoders for Video and Text,[0],[0]
"Similarly, we encode question Hq ∈ Rnq×2d, candidate answers Hai ∈ Rnai×2d, and visual con-
cepts Hcpt ∈ Rncpt×2d.",4.2 LSTM Encoders for Video and Text,[0],[0]
"nq and nai are the number of words in question and answer ai, respectively.",4.2 LSTM Encoders for Video and Text,[0],[0]
"Regional features V reg and ImageNet features V img are first projected into word vector space using a non-linear layer with tanh activation, then encoded using the same BiLSTM to obtain the regional representations Hreg ∈ Rnreg×2d and H img ∈ Rnimg×2d, respectively.",4.2 LSTM Encoders for Video and Text,[0],[0]
"We use a context matching module and BiLSTM to jointly model the contextual inputs (subtitle, video) and query (question-answer pair).",4.3 Joint Modeling of Context and Query,[0],[0]
"The context matching module is adopted from the contextquery attention layer from previous works (Seo et al., 2017; Yu et al., 2018a).",4.3 Joint Modeling of Context and Query,[0],[0]
"It takes context vectors and query vectors as inputs and produces a set of context-aware query vectors based on the similarity between each context-query pair.
",4.3 Joint Modeling of Context and Query,[0],[0]
"Taking the regional visual feature stream as an example (Fig. 4 upper stream), where Hreg is used as context input2.",4.3 Joint Modeling of Context and Query,[0],[0]
"The question embedding, Hq, and answer embedding, Hai , are used as queries.",4.3 Joint Modeling of Context and Query,[0],[0]
"After feeding context-query pairs into the context matching module, we obtain a video-aware-question representation, Greg,q ∈ Rnreg×2d, and video-aware-answer representation, Greg,ai ∈ Rnreg×2d, which are then fused with video context:
M reg,ai = [Hreg;Greg,q;Greg,ai ;
Hreg Greg,q;Hreg Greg,ai ],
where is element-wise product.",4.3 Joint Modeling of Context and Query,[0],[0]
"The fused feature, M reg,ai ∈ Rnreg×10d, is fed into another BiLSTM.",4.3 Joint Modeling of Context and Query,[0],[0]
"Its hidden states, U reg,ai ∈ Rnreg×10d, are max-pooled temporally to get the final vector, ureg,ai ∈ R10d, for answer ai.",4.3 Joint Modeling of Context and Query,[0],[0]
"We use a linear layer with softmax to convert {ureg,ai}4i=0 into answer probabilities.",4.3 Joint Modeling of Context and Query,[0],[0]
"Similarly, we can compute the answer probabilities given subtitle as context (Fig. 4 bottom stream).",4.3 Joint Modeling of Context and Query,[0],[0]
"When multiple streams are used, we simply sum up the scores from each stream as the final score (Wang et al., 2016a).",4.3 Joint Modeling of Context and Query,[0],[0]
"For evaluation, we introduce several baselines and compare them to our proposed model.
",5 Experiments,[0],[0]
"2For visual concept features and ImageNet features, we simply replace Hreg with Hcpt or Himg as the context.
",5 Experiments,[0],[0]
"In all experiments, setup is as follows.",5 Experiments,[0],[0]
"We split the TVQA dataset into 80% training, 10% validation, and 10% testing splits such that videos and their corresponding QA pairs appear in only one split.",5 Experiments,[0],[0]
"This results in 122,039 QA pairs for training, 15,253 QA pairs for validation, and 15,253 QA pairs for testing.",5 Experiments,[0],[0]
We evaluate each model using multiple-choice question answering accuracy.,5 Experiments,[0],[0]
"Longest Answer: Table 1 indicates that the average length of the correct answers is longer than the wrong ones; thus, our first baseline simply selects the longest answer for each question.",5.1 Baselines,[0],[0]
"Nearest Neighbor Search: In this baseline, we use Nearest Neighbor Search (NNS) to compute the closest answer to our question or subtitle.",5.1 Baselines,[0],[0]
"We embed sentences into vectors using TFIDF, SkipThought (Kiros et al., 2015), or averaged GloVe (Pennington et al., 2014) word vectors, then compute the cosine similarity for each questionanswer pair or subtitle-answer pair.",5.1 Baselines,[0],[0]
"For TFIDF, we use bag-of-words to represent the sentences, assigning a TFIDF value for each word.",5.1 Baselines,[0],[0]
Retrieval:,5.1 Baselines,[0],[0]
"Due to the size of TVQA, there may exist similar questions and answers in the dataset.",5.1 Baselines,[0],[0]
"Thus, we also implement a baseline two-step retrieval approach: given a question and a set of candidate answers, we first retrieve the most relevant question in the training set, then pick the candidate answer that is closest to the retrieved question’s correct answer.",5.1 Baselines,[0],[0]
"Similar approaches have also been used in dialogue systems (Jafarpour and Burges, 2010; Leuski and Traum, 2011), picking the appropriate responses to an utterance from a predefined human conversational corpus.",5.1 Baselines,[0],[0]
"Similar to NNS, we use TFIDF, SkipThought, and GloVe vectors with cosine similarity.",5.1 Baselines,[0],[0]
Table 6 shows results from baseline methods and our proposed neural model.,5.2 Results,[0],[0]
"Our main results are obtained by using full-length video clips and subtitles, without using timestamps (w/o ts).",5.2 Results,[0],[0]
We also run the same experiments using the localized video and subtitle segment specified by the ground truth timestamps (w/ ts).,5.2 Results,[0],[0]
"If not indicated explicitly, the numbers described below are from the experiments on full-length video clips and subtitles.",5.2 Results,[0],[0]
"Baseline Comparison: Row 1 shows results of the longest answer baseline, achieving 30.41%
(compared to random chance at 20%).",5.2 Results,[0],[0]
"As expected, the retrieval-based methods (row 2-4) and the answer-question similarity based methods (row 5-7) perform rather poorly, since no contexts (video or subtitle) are considered.",5.2 Results,[0],[0]
"When using subtitle-answer similarity to choose correct answers, Glove, SkipThought, and TFIDF based approaches (row 8-10) all achieve significant improvement over question-answer similarity.",5.2 Results,[0],[0]
"Notably, TFIDF (row 10) answers 49.94% of the questions correctly.",5.2 Results,[0],[0]
"Since our questions are raised by people watching the videos, it is natural for them to ask questions about specific and unique objects/locations/etc., mentioned in the subtitle.",5.2 Results,[0],[0]
"Thus, it is not surprising that TFIDF based similarity between answer and subtitle performs so well.",5.2 Results,[0],[0]
Variants of Our Model: Rows 11-18 show results of our model with different contextual inputs and features.,5.2 Results,[0],[0]
The model that only uses questionanswer pairs (row 11) achieves 43.34% accuracy.,5.2 Results,[0],[0]
"Compared to the subtitle model (row 15), adding video as additional sources (row 16-18) improves performance.",5.2 Results,[0],[0]
"Interestingly, adding video to the question only model (row 11) do not work as well (row 12-14).",5.2 Results,[0],[0]
"Our hypothesis is that the video feature streams may be struggling to learn models for answering textual questions, which degrades
their ability to answer visual questions.",5.2 Results,[0],[0]
"Overall, the best performance is achieved by using all the contextual sources, including subtitles and videos (using concept features, row 18).",5.2 Results,[0],[0]
Comparison with Human Performance: Human performance without timestamp annotation is shown in Table 5.,5.2 Results,[0],[0]
"When using only questions (Table 6 row 11), our model outperforms humans (43.34% vs 31.84%) as it has access to all statistics of the questions and answers.",5.2 Results,[0],[0]
"When using videos or subtitles or both, humans perform significantly better than the models.",5.2 Results,[0],[0]
Models with Timestamp Annotation: Columns under w/o ts and w/ ts show a comparison between the same model using full-length videos/subtitles and using timestamp localized videos/subtitles.,5.2 Results,[0],[0]
"With timestamp annotation, the models perform consistently better than their counterpart without this information, indicating that localization is helpful for question answering.",5.2 Results,[0],[0]
"Accuracy for Different Question Types: To gain further insight, we examined the accuracy of our models on different question types on the validation set (results in Table 7), all models using timestamp annotation.",5.2 Results,[0],[0]
"Compared to S+Q model, S+V+Q models get the most improvements on “what” and “where” questions, indicating these questions require additional visual information.",5.2 Results,[0],[0]
"On the other hand, adding video features did not improve S+Q performance on questions relying more on textual reasoning, e.g., “how” questions.",5.2 Results,[0],[0]
"Human-Written Negatives vs. RandomlySampled Negatives For comparison, we create a new answer set by replacing the original human written negative answers with randomly sampled negative answers.",5.2 Results,[0],[0]
"To produce relevant negative answers, for each question, negatives are sampled (from the other QA pairs) within the same show.
",5.2 Results,[0],[0]
Results are shown in Table 8.,5.2 Results,[0],[0]
"Performance on randomly sampled negatives is much higher than that of human written negatives, indicating that human written negatives are more challenging.",5.2 Results,[0],[0]
Qualitative Analysis: Fig. 6 shows example predictions from our S+V+Q model (row 18) using full-length video and subtitle.,5.2 Results,[0],[0]
Fig. 6a and Fig.,5.2 Results,[0],[0]
6b demonstrate its ability to solve both grounded visual questions and textual reasoning question.,5.2 Results,[0],[0]
Bottom row shows two incorrect predictions.,5.2 Results,[0],[0]
We found that wrong inferences are mainly due to incorrect language inferences and the model’s lack of common sense knowledge.,5.2 Results,[0],[0]
"For example, Fig.",5.2 Results,[0],[0]
"6c, the characters are talking about radiology, the model is distracted to believe they are in the radiology department, while Fig. 6d shows a case of questions that need common sense to answer, rather than simply textual or visual cues.",5.2 Results,[0],[0]
"We presented the TVQA dataset, a large-scale, localized, compositional video question answering dataset.",6 Conclusion,[0],[0]
We also proposed two QA tasks (with/without timestamps) and provided baseline experiments as a benchmark for future comparison.,6 Conclusion,[0],[0]
"Our experiments show both visual and textual understanding are necessary for TVQA.
",6 Conclusion,[0],[0]
There is still a significant gap between the proposed baselines and human performance on the QA accuracy.,6 Conclusion,[0],[0]
We hope this novel multimodal dataset and the baselines will encourage the community to develop stronger models in future work.,6 Conclusion,[0],[0]
"To narrow the gap, one possible direction is to enhance the interactions between videos and subtitles to improve multimodal reasoning ability.",6 Conclusion,[0],[0]
"Another direction is to exploit human-object relations in the video and subtitle, as we observe that a large number of questions involve such relations.",6 Conclusion,[0],[0]
"Additionally, temporal reasoning is crucial for answering the TVQA questions.",6 Conclusion,[0],[0]
"Thus, future work also includes integrating better temporal cues.",6 Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful comments and discussions.,Acknowledgments,[0],[0]
"This research is supported by NSF Awards #1633295, 1562098, 1405822 and a Google Faculty Research Award, Bloomberg Data Science Research Grant, and ARO-YIP Award #W911NF-18-1-0336.",Acknowledgments,[0],[0]
The views contained in this article are those of the authors and not of the funding agency.,Acknowledgments,[0],[0]
Recent years have witnessed an increasing interest in image-based question-answering (QA) tasks.,abstractText,[0],[0]
"However, due to data limitations, there has been much less work on video-based QA.",abstractText,[0],[0]
"In this paper, we present TVQA, a largescale video QA dataset based on 6 popular TV shows.",abstractText,[0],[0]
"TVQA consists of 152,545 QA pairs from 21,793 clips, spanning over 460 hours of video.",abstractText,[0],[0]
"Questions are designed to be compositional in nature, requiring systems to jointly localize relevant moments within a clip, comprehend subtitle-based dialogue, and recognize relevant visual concepts.",abstractText,[0],[0]
We provide analyses of this new dataset as well as several baselines and a multi-stream end-to-end trainable neural network framework for the TVQA task.,abstractText,[0],[0]
The dataset is publicly available at http://tvqa.cs.unc.edu.,abstractText,[0],[0]
"TVQA: Localized, Compositional Video Question Answering",title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1415–1425 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1415",text,[0],[0]
"Language on Twitter diverges from well-edited Mainstream American English (MAE, also called Standard American English) in a number of ways, presenting significant challenges to current NLP tools.",1 Introduction,[0],[0]
"It contains, among other phenomena, nonstandard spelling, punctuation, capitalization, and syntax, as well as Twitter-specific conventions such as hashtags, usernames, and retweet tokens (Eisenstein, 2013).",1 Introduction,[0],[0]
"Additionally, it contains an abundance of dialectal language, includ-
ing African-American English (AAE), a dialect of American English spoken by millions of individuals, which contains lexical, phonological, and syntactic features not present in MAE (Green, 2002; Stewart, 2014; Jones, 2015).
",1 Introduction,[0],[0]
"Since standard English NLP tools are typically trained on well-edited MAE text, their performance is degraded on Twitter, and even more so for AAE tweets compared to MAE tweets— gaps exist for part-of-speech tagging (Jørgensen et al., 2016), language identification, and dependency parsing (Blodgett et al., 2016; Blodgett and O’Connor, 2017).",1 Introduction,[0],[0]
"Expanding the linguistic coverage of NLP tools to include minority and colloquial dialects would help support equitable language analysis across sociolinguistic communities, which could help information retrieval, translation, or opinion analysis applications (Jurgens et al., 2017).",1 Introduction,[0],[0]
"For example, sentiment analysis systems ought to count the opinions of all types of people, whether they use standard dialects or not.
",1 Introduction,[0],[0]
"In this work, we broaden Universal Dependencies (Nivre et al., 2016)",1 Introduction,[0],[0]
"parsing1 to better handle social media English, in particular social media AAE.",1 Introduction,[0],[0]
"First, we develop standards to handle Twitter-specific and AAE-specific features within Universal Dependencies 2.0 (§3), by selecting and annotating a new dataset of 500 tweets, 250 of which are in AAE.
",1 Introduction,[0],[0]
"Second, we evaluate several state-of-the-art dependency parsers, finding that, as expected, they perform poorly on our dataset relative to the UD English Treebank (§4).",1 Introduction,[0],[0]
"Third, since the UD English Treebank contains substantial amounts of traditional MAE data for training, we investigate cross-domain training methods to improve Twitter AAE dependency parsing with no, or very little,
1http://universaldependencies.org/
in-domain labeled data, by using Twitter-specific taggers, embeddings, and a novel heuristic training data synthesis procedure.",1 Introduction,[0],[0]
This helps close some of the gap between MAE and AAE performance.,1 Introduction,[0],[0]
"Finally, we provide an error analysis of the parsers’ performance on AAE lexical and syntactic constructions in our dataset (§5.4).2",1 Introduction,[0],[0]
Parsing for noisy social media data presents interesting and significant challenges.,2.1 Parsing for Twitter,[0],[0]
"Foster et al. (2011) develop a dataset of 519 constituencyannotated English tweets, which were converted to Stanford dependencies.",2.1 Parsing for Twitter,[0],[0]
Their analysis found a substantial drop in performance of an off-the-shelf dependency parser on the new dataset compared to a WSJ test set.,2.1 Parsing for Twitter,[0],[0]
"Sanguinetti et al. (2017) annotated a dataset of 6,738 Italian tweets according to UD 2.0 and examined the performance of two parsers on the dataset, finding that they lagged considerably relative to performance on the Italian UD Treebank.
Kong et al. (2014) develop an English dependency parser designed for Twitter, annotating a dataset of 929 tweets (TWEEBANK V1) according to the unlabeled FUDG dependency formalism (Schneider et al., 2013).",2.1 Parsing for Twitter,[0],[0]
"It has substantially different structure than UD (for example, prepositions head PPs, and auxiliaries govern main verbs).
",2.1 Parsing for Twitter,[0],[0]
"More recently, Liu et al. (2018) developed TWEEBANK V2, fully annotating TWEEBANK V1 according to UD 2.0 and annotating additionally sampled tweets, for a total of 3,550 tweets.",2.1 Parsing for Twitter,[0],[0]
"They found that creating consistent annotations was challenging, due to frequent ambiguities in interpreting tweets; nevertheless, they were able to train a pipeline for tokenizing, tagging, and parsing the tweets, and develop ensemble and distillation models to improve parsing accuracy.",2.1 Parsing for Twitter,[0],[0]
"Our work encounters similar challenges; in our approach, we intentionally oversample AAE-heavy messages for annotation, detail specific annotation decisions for AAE-specific phenomena (§3.2), and analyze parser performance between dialects and for particular constructions (§5.3–5.4).",2.1 Parsing for Twitter,[0],[0]
"Future work may be able to combine these annotations for effective multi-dialect Twitter UD parsers, which
2Our annotated dataset and trained dependency parser are available at http://slanglab.cs.umass.edu/TwitterAAE/ and annotations are available in the public Universal Dependencies repository.
may allow for the use of pre-existing downstream tools like semantic relation extractors (e.g. White et al. (2016)).
",2.1 Parsing for Twitter,[0],[0]
"One line of work for parsing noisy social media data, including Khan et al. (2013) and Nasr et al. (2016), examines the effects of the domain mismatches between traditional sources of training data and social media data, finding that matching the data as closely as possible aids performance.",2.1 Parsing for Twitter,[0],[0]
"Other work focuses on normalization, including Daiber and van der Goot (2016) and van der Goot and van Noord (2017), which develop a dataset of 500 manually normalized and annotated tweets, and uses normalization within a parser.",2.1 Parsing for Twitter,[0],[0]
"Separately, Zhang et al. (2013) created a domain-adaptable, parser-focused system by directly linking parser performance to normalization performance.",2.1 Parsing for Twitter,[0],[0]
"For Arabic dialects, Chiang et al. (2006) parse Levantine Arabic by projecting parses from Modern Standard Arabic translations, while Green and Manning (2010) conduct extensive error analysis of Arabic constituency parsers and the Penn Arabic Treebank.",2.2 Parsing for Dialects,[0],[0]
Scherrer (2011) parse Swiss German dialects by transforming Standard German phrase structures.,2.2 Parsing for Dialects,[0],[0]
"We continue in this line of work in our examination of AAE-specific syntactic structures and generation of synthetic data with such structures (§4.2.1).
",2.2 Parsing for Dialects,[0],[0]
Less work has examined parsing dialectal language on social media.,2.2 Parsing for Dialects,[0],[0]
"Recently, Wang et al. (2017) annotate 1,200 Singlish (Singaporean English) sentences from a Singaporean talk forum, selecting sentences containing uniquely Singaporean vocabulary items.",2.2 Parsing for Dialects,[0],[0]
"Like other work, they observe a drop in performance on dialectal Singlish text, but increase performance through a stacking-based domain adaptation method.",2.2 Parsing for Dialects,[0],[0]
"Our dataset contains 500 tweets, with a total of 5,951 non-punctuation edges, sampled from the publicly available TwitterAAE corpus.3 Each tweet in that corpus is accompanied by a model’s demographically-aligned topic model probabilities jointly inferred from Census demographics and word likelihood by Blodgett et al. (2016), including the African-American and White topics.
",3.1 Dataset,[0],[0]
"3http://slanglab.cs.umass.edu/TwitterAAE/
We create a balanced sample to get a range of dialectal language, sampling 250 tweets from those where the African-American topic has at least 80% probability, and 250 from those where the White topic has at least 80% probability.",3.1 Dataset,[0],[0]
"We refer to these two subcorpora as AA and WH; Blodgett et al. (2016) showed the former exhibits linguistic features typical of AAE.
",3.1 Dataset,[0],[0]
"The 250 AA tweets include many alternate spellings of common words that correspond to well-known phonological phenomena—including da, tha (the), dat, dhat (that), dis, dhis (this), ion, iont (I don’t), ova (over), yo (your), dere, der (there), den, dhen (then), ova (over), and nall, null (no, nah)—where each of the mentioned italicized AAE terms appears in the AAE data, but never in the MAE data.",3.1 Dataset,[0],[0]
We examine these lexical variants more closely in §5.4.,3.1 Dataset,[0],[0]
"Across the AA tweets, 18.0% of tokens were not in a standard English dictionary, while the WH tweets’ OOV rate was 10.7%.4 We further observe a variety of AAE syntactic phenomena in our AA tweets, several of which are described in §3.2 and §5.4.",3.1 Dataset,[0],[0]
"To effectively measure parsing quality and develop better future models, we first focus on developing high-quality annotations for our dataset, for which we faced a variety of challenges.",3.2 Annotation,[0],[0]
"We detail our annotation principles using Universal Dependency 2.0 relations (Nivre et al., 2016).
",3.2 Annotation,[0],[0]
"All tweets were initially annotated by two annotators, and disagreements resolved by one of the annotators.",3.2 Annotation,[0],[0]
"Annotation decisions for several dozen tweets were discussed in a group of three annotators early in the annotation process.
",3.2 Annotation,[0],[0]
"Our annotation principles are in alignment with those proposed by Liu et al. (2018), with the exception of contraction handling, which we discuss briefly in §3.2.2.",3.2 Annotation,[0],[0]
"The AAE dialect is prominently characterized by the drop of copulas, which can occur when the copula is present tense, not first person, not accented, not negative, and expressing neither the habitual nor the remote present perfect tenses (Green, 2002).",3.2.1 Null Copulas,[0],[0]
"We frequently observed null copulas, as in:
4The dictionary of 123,377 words with American spellings was generated using http://wordlist.aspell.net/.
If u wit me den u pose to RESPECT ME
nsubjnsubj
“If you (are) with me, then you (are) supposed to respect me”
The first dropped are is a null copula; UD2.0 would analyze the MAE version as you nsubj←−− me cop−→ are, which we naturally extend to analyze the null copula by simply omitting cop (which is now over a null element, so cannot exist in a dependency graph).",3.2.1 Null Copulas,[0],[0]
"The second are is a null auxiliary (in MAE, you nsubj←−− supposed aux−→ are), a tightly related phenomenon (for example, Green et al. (2007) studies both null copulas and null auxiliary be in infant AAE), which we analyze similarly by simply omitting the aux edge.",3.2.1 Null Copulas,[0],[0]
"We observed AAE verbal auxiliaries, e.g.,
fees be looking upside my head
aux
Now we gone get fucked up
aux
damnnn I done let alot of time pass by
aux
including habitual be (“Continually, over and over, fees are looking at me...”), future gone (“we are going to get...”), and completive done (“I did let time pass by,” emphasizing the speaker completed a time-wasting action).
",3.2.2 AAE Verbal Auxiliaries,[0],[0]
"We attach the auxiliary to the main verb with the aux relation, as UD2.0 analyzes other English auxiliaries (e.g. would or will).",3.2.2 AAE Verbal Auxiliaries,[0],[0]
"We observed many instances of quasi-auxiliary, “- to” shortened verbs such as wanna, gotta, finna, bouta, tryna, gonna, which can be glossed as want to, got to, fixing to, about to, etc.",3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
"They control modality, mood and tense—for example, finna and bouta denote an immediate future tense; Green (2002, ch. 2) describes finna as a preverbal marker.",3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
"From UD’s perspective, it is difficult to decide if they should be subordinate auxiliaries or main verbs.",3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
"In accordance with the UD Treebank’s handling of MAE want to X and going to X as main verbs (want xcomp−−→ X), we analyzed them similarly, e.g.
Lol he bouta piss me off “He is about to piss me off”
xcomp
This is an instance of a general principle that, if there is a shortening of an MAE multiword phrase into a single word, the annotations on that word should mirror the edges in and out of the original phrase’s subgraph (as in Schneider et al. (2013)’s fudge expressions).
",3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
"However, in contrast to the UD Treebank, we did not attempt to split up these words into their component words (e.g. wanna → want to), since to do this well, it would require a more involved segmentation model over the dozens or even hundreds of alternate spellings each of the above can take;5",3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
we instead rely on Owoputi et al. (2013); O’Connor et al. (2010)’s rule-based tokenizer that never attempts to segment within such shortenings.,3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
"This annotation principle is in contrast to that of Liu et al. (2018), which follows UD tokenization for contractions.",3.2.3 Verbs: Auxiliaries vs. Main Verbs,[0],[0]
We also encountered many issues general to Twitter but not AAE; these are still important to deal with since AAE tweets include more non-standard linguistic phenomena overall.,3.2.4 Non-AAE Twitter issues,[0],[0]
"When possible, we adapted Kong et al. (2014)’s annotation conventions into the Universal Dependencies context, which are the only published conventions we know of for Twitter dependencies (for the FUDG dependency formalism).",3.2.4 Non-AAE Twitter issues,[0],[0]
"Issues include:
• @-mentions, which require different treatment when they are terms of address, versus nominal elements within a sentence.
",3.2.4 Non-AAE Twitter issues,[0],[0]
"• Hashtags, which in their tag-like usage are utterances by themselves (#tweetliketheoppositegender",3.2.4 Non-AAE Twitter issues,[0],[0]
Oh damn .).,3.2.4 Non-AAE Twitter issues,[0],[0]
"or sometimes can be words with standard syntactic relations within the sentence (#She’s A Savage, having #She’s nsubj←−− Savage).",3.2.4 Non-AAE Twitter issues,[0],[0]
"Both hashtag and @- mention ambiguities are handled by Owoputi et al. (2013)’s POS tagger.
",3.2.4 Non-AAE Twitter issues,[0],[0]
"• Multiple utterances, since we do not attempt sentence segmentation, and in many cases sentential utterances are not separated by explicit punctuation.",3.2.4 Non-AAE Twitter issues,[0],[0]
"FUDG allows for multiple roots for a text, but UD does not; instead we follow UD’s convention of the parataxis relation for what they describe as “side-by-side run-on sentences.”
5For example, Owoputi et al. (2013)’s Twitter word cluster 0011000 has 36 forms of gonna alone: http://www.cs.",3.2.4 Non-AAE Twitter issues,[0],[0]
"cmu.edu/∼ark/TweetNLP/cluster viewer.html
• Emoticons and emoji, which we attach as discourse relations to the utterance root, following UD’s treatment of interjections.
",3.2.4 Non-AAE Twitter issues,[0],[0]
"• Collapsed phrases, like omw for “on my way.”",3.2.4 Non-AAE Twitter issues,[0],[0]
"When possible, we used the principle of annotating according to the root of the subtree of the original phrase.",3.2.4 Non-AAE Twitter issues,[0],[0]
"For example, UD 2.0 prescribes way xcomp−−→ get for the sentence",3.2.4 Non-AAE Twitter issues,[0],[0]
"On my way to get...; therefore we use omw xcomp−−→ get for omw to get.
",3.2.4 Non-AAE Twitter issues,[0],[0]
"• Separated words, like uh round for “around,” which we analyze as multiword phrases (flat or compound).
",3.2.4 Non-AAE Twitter issues,[0],[0]
We discuss details for these and other cases in the online appendix.,3.2.4 Non-AAE Twitter issues,[0],[0]
Our experiments use the following two parsers.,4.1 Models,[0],[0]
"UDPipe (Straka et al., 2016) is a neural pipeline containing a tokenizer, morphological analyzer, tagger, and transition-based parser intended to be easily retrainable.",4.1 Models,[0],[0]
"The parser attains 80.2% LAS (labeled attachment score) on the UD English treebank with automatically generated POS tags, and was a baseline system used in the CoNLL 2017 Shared Task (Zeman et al., 2017).6
Deep Biaffine (Dozat et al., 2017; Dozat and Manning, 2016) is a graph-based parser incorporating neural attention and biaffine classifiers for arcs and labels.",4.1 Models,[0],[0]
"We used the version of the parser in the Stanford CoNLL 2017 Shared Task submission, which attained 82.2% LAS on the UD English treebank with automatically generated tags, and achieved the best performance in the task.",4.1 Models,[0],[0]
The model requires pre-trained word embeddings.,4.1 Models,[0],[0]
7,4.1 Models,[0],[0]
"We considered a series of experiments within both a cross-domain scenario (§4.2.1), where we trained only on UD Treebank data, and an indomain scenario (§4.2.2) using small amounts of our labeled data.",4.2 Experimental Setup,[0],[0]
"We use the parsing systems’ default hyperparameters (e.g. minibatch size and learning rate) and the default training/development split of the treebank (both systems perform early stopping based on development set performance).
",4.2 Experimental Setup,[0],[0]
6https://github.com/ufal/udpipe 7https://github.com/tdozat/UnstableParser/,4.2 Experimental Setup,[0],[0]
"Morpho-Tagger vs. ARK POS tags: The UD Treebank contains extensive fine-grained POS and morphological information, on which UDPipe’s morphological analyzer and tagging system is originally trained.",4.2.1 Cross-Domain Settings,[0],[0]
"This rich information should be useful for parsing, but the analyzers may be highly error-prone on out-of-domain, dialectal Twitter data, and contribute to poor parsing performance.",4.2.1 Cross-Domain Settings,[0],[0]
"We hypothesize that higher quality, even if coarser, POS information should improve parsing.
",4.2.1 Cross-Domain Settings,[0],[0]
"To test this, we retrain UDPipe in two different settings.",4.2.1 Cross-Domain Settings,[0],[0]
We first retrain the parser component with fine-grained PTB-style POS tags and morphological information provided by the tagger component;8 we call this the Morpho-Tagger setting.,4.2.1 Cross-Domain Settings,[0],[0]
"Second, we retrain the parser with morphological information stripped and its tags predicted from the ARK Twitter POS tagger (Owoputi et al., 2013), which is both tailored for Twitter and displays a smaller AAE vs MAE performance gap than traditional taggers (Jørgensen et al., 2016); we call this the ARK Tagger setting.9 The ARK Tagger’s linguistic representation is impoverished compared to Morpho-Tagger: its coarse-grained POS tag system does not include tense or number information, for example.10
Synthetic Data:",4.2.1 Cross-Domain Settings,[0],[0]
"Given our knowledge of Twitter- and AAE-specific phenomena that do not occur in the UD Treebank, we implemented a rulebased method to help teach the machine-learned parser these phenomena; we generated synthetic data for three Internet-specific conventions and one set of AAE syntactic features.",4.2.1 Cross-Domain Settings,[0],[0]
(This is inspired by Scherrer (2011)’s rule transforms between Standard and Swiss German.),4.2.1 Cross-Domain Settings,[0],[0]
"We performed each of the following transformations separately on a copy of the UD Treebank data and concatenated the transformed files together for the final training and development files, so that each final file contained several transformed copies of the original UD Treebank data.
1. @-mentions, emojis, emoticons, expressions, and hashtags: For each sentence in the UD Treebank we inserted at least one @-mention, emoji, emoticon, expression (Internet-specific words and
8We also retrained this component, to maintain consistency of training and development split.",4.2.1 Cross-Domain Settings,[0],[0]
"We also remove the universal (coarse) POS tags it produces, replacing them with the same PTB tags.
",4.2.1 Cross-Domain Settings,[0],[0]
"9We strip lemmas from training and development files for both settings.
",4.2.1 Cross-Domain Settings,[0],[0]
"10Derczynski et al. (2013)’s English Twitter tagger, which outputs PTB-style tags, may be of interest for future work.
",4.2.1 Cross-Domain Settings,[0],[0]
"abbreviations such as lol, kmsl, and xoxo), or hashtag, annotated with the correct relation, at the beginning of the sentence.",4.2.1 Cross-Domain Settings,[0],[0]
"An item of the same type was repeated with 50% probability, and a second item was inserted with 50% probability.",4.2.1 Cross-Domain Settings,[0],[0]
@- mentions were inserted using the ATMENTION token and emojis using the EMOJI token.,4.2.1 Cross-Domain Settings,[0],[0]
"Emoticons were inserted from a list of 20 common emoticons, expressions were inserted from a list of 16 common expressions, and hashtags were sampled for insertion according to their frequency in a list of all hashtags observed in the TwitterAAE corpus.
2.",4.2.1 Cross-Domain Settings,[0],[0]
"Syntactically participating @-mentions: To replicate occurrences of syntactically participating @-mentions, for each sentence in the UD Treebank with at least one token annotated with an nsubj or obj relation and an NNP POS tag, we replaced one at random with the ATMENTION token.
3.",4.2.1 Cross-Domain Settings,[0],[0]
"Multiple utterances: To replicate occurrences of multiple utterances, we randomly collapsed pairs of two short sentences (< 15 tokens) together, attaching the root of the second to the root of the first with the parataxis relation.
4.",4.2.1 Cross-Domain Settings,[0],[0]
AAE preverbal markers and auxiliaries: We introduced instances of verbal constructions present in AAE that are infrequent or non-existent in the UD Treebank data.,4.2.1 Cross-Domain Settings,[0],[0]
"First, constructions such as going to, about to, and want to are frequently collapsed to gonna, bouta, and wanna, respectively (see §3.2.2); for each sentence with at least one of these constructions, we randomly chose one to collapse.",4.2.1 Cross-Domain Settings,[0],[0]
"Second, we randomly replaced instances of going to with finna, a preverbal marker occurring in AAE and in the American South (Green, 2002).",4.2.1 Cross-Domain Settings,[0],[0]
"Third, we introduced the auxiliaries gone and done, which denote future tense and past tense, respectively; for the former, for each sentence containing at least one auxiliary will, we replace it with gone, and for the latter, for each sentence containing at least one nonauxiliary, non-passive, past-tense verb, we choose one and insert done before it.",4.2.1 Cross-Domain Settings,[0],[0]
"Finally, for each sentence containing at least one copula, we delete one at random.
",4.2.1 Cross-Domain Settings,[0],[0]
"Word Embeddings: Finally, since a tremendous variety of Twitter lexical items are not present in the UD Treebank, we use 200- dimensional word embeddings that we trained with word2vec11 (Mikolov et al., 2013) on the
11https://github.com/dav/word2vec
TwitterAAE corpus, which contains 60.8 million tweets.",4.2.1 Cross-Domain Settings,[0],[0]
"Before training, we processed the corpus by replacing @-mentions with ATMENTION, replacing emojis with EMOJI, and replacing sequences of more than two repeated letters with two repeated letters (e.g. partyyyyy → partyy).",4.2.1 Cross-Domain Settings,[0],[0]
"This resulted in embeddings for 487,450 words.
",4.2.1 Cross-Domain Settings,[0],[0]
"We retrain and compare UDPipe on each of the Morpho-Tagger and ARK Tagger settings with synthetic data and pre-trained embeddings, and without.",4.2.1 Cross-Domain Settings,[0],[0]
We additionally retrain Deep Biaffine with and without synthetic data and embeddings.12,4.2.1 Cross-Domain Settings,[0],[0]
We additionally investigate the effects of small amounts of in-domain training data from our dataset.,4.2.2 In-domain Training,[0],[0]
"We perform 2-fold cross-validation, randomly partitioning our dataset into two sets of 250 tweets.",4.2.2 In-domain Training,[0],[0]
"We compare two different settings (all using the UDPipe ARK Tagger setting):
Twitter-only: To explore the effect of training with Twitter data alone, for each set of 250 we trained on that set alone, along with our Twitter embeddings, and tested on the remaining 250.
",4.2.2 In-domain Training,[0],[0]
"UDT+Twitter: To explore the additional signal provided by the UD Treebank, for each set of 250 we trained on the UD Treebank concatenated with that set (with the tweets upweighted to approximately match the size of the UD Treebank, in order to use similar hyperparameters) and tested on the remaining 250.",4.2.2 In-domain Training,[0],[0]
"In our evaluation, we ignored punctuation tokens (labeled with punct) in our LAS calculation.",5 Results and Analysis,[0],[0]
Morpho-Tagger vs. ARK,5.1 Effects of Cross-Domain Settings,[0],[0]
"Tagger: As hypothesized, UDPipe’s ARK Tagger setting outperformed the Morpho-Tagger across all settings, ranging from a 2.8% LAS improvement when trained only on the UD Treebank with no pre-trained word embeddings, to 4.7% and 5.4% improvements when trained with Twitter embeddings and both Twitter embeddings and synthetic data, respectively.",5.1 Effects of Cross-Domain Settings,[0],[0]
"The latter improvements suggest that the ARK Tagger setup is able to take better advantage of Twitterspecific lexical information from the embeddings
12As the existing implementation of Deep Biaffine requires pre-trained word embeddings, for the Deep Biaffine baseline experiments we use the CoNLL 2017 Shared Task 100- dimensional embeddings that were pretrained on the English UD Treebank.
and syntactic patterns from the synthetic data.",5.1 Effects of Cross-Domain Settings,[0],[0]
"Table 1 shows the LAS for our various settings.
",5.1 Effects of Cross-Domain Settings,[0],[0]
"After observing the better performance of the ARK Tagger setting, we opted not to retrain the Deep Biaffine parser in any Morpho-Tagger settings due to the model’s significantly longer training time; all our Deep Biaffine results are reported for models trained with an ARK Tagger setting.
",5.1 Effects of Cross-Domain Settings,[0],[0]
"Synthetic data and embeddings: We observed that synthetic data and Twitter-trained embeddings were independently helpful; embeddings provided a 1.4–5.3% boost across the UDPipe and Deep Biaffine models, while synthetic data provided a 1.3– 5.7% additional boost (Table 1).
",5.1 Effects of Cross-Domain Settings,[0],[0]
"UDPipe vs. Deep Biaffine: While the baseline models for UDPipe and Deep Biaffine are not directly comparable (since the latter required pretrained embeddings), in the Twitter embeddings setting Deep Biaffine outperformed UDPipe by 5.1%.",5.1 Effects of Cross-Domain Settings,[0],[0]
"However, given access to both synthetic data and Twitter embeddings, UDPipe’s performance approached that of Deep Biaffine.",5.1 Effects of Cross-Domain Settings,[0],[0]
"Perhaps surprisingly, training with even limited amounts of in-domain training data aided in parsing performance; training with just in-domain data produced an LAS comparable to that of the baseline Deep Biaffine model, and adding UD Treebank data further increased LAS by 8.1%, indicat-
ing that they independently provide critical signal.",5.2 Effects of In-Domain Training,[0],[0]
"For each model in each of the cross-domain settings, we calculated the LAS on the 250 tweets drawn from highly African-American tweets and the 250 from highly White tweets (see §3 for details); we will refer to these as the AA and WH tweets, respectively.",5.3 AAE/MAE Performance Disparity,[0],[0]
"We observed clear disparities in performance between the two sets of tweets, ranging from 5.9% to 15.7% (Table 3).",5.3 AAE/MAE Performance Disparity,[0],[0]
"Additionally, across settings, we observed several patterns.
",5.3 AAE/MAE Performance Disparity,[0],[0]
"First, the UDPipe ARK Tagger settings produced significantly smaller gaps (5.9–8.4%) than the corresponding Morpho-Tagger settings (14.0– 15.7%).",5.3 AAE/MAE Performance Disparity,[0],[0]
"Indeed, most of the performance improvement of the ARK Tagger setting comes from the AA tweets; the LAS on the AA tweets jumps 7.2–9.2% from each Morpho-Tagger setting to the corresponding ARK Tagger setting, compared to differences of −0.9–1.9% for the WH tweets.
",5.3 AAE/MAE Performance Disparity,[0],[0]
"Second, the Deep Biaffine ARK Tagger settings produced larger gaps (8.0–11.6%) than the UDPipe ARK Tagger settings, with the exception of the embeddings-only setting.
",5.3 AAE/MAE Performance Disparity,[0],[0]
"Finally, we observed the surprising result that adding Twitter-trained embeddings and synthetic data, which contains both Twitter-specific and AAE-specific features, increases the performance gap across both UDPipe settings.",5.3 AAE/MAE Performance Disparity,[0],[0]
"We hypothesize that while UDPipe is able to effectively make use of both Twitter-specific lexical items and annotation conventions within MAE-like syntactic structures, it continues to be stymied by AAE-like syntactic structures, and is therefore unable to make use of the additional information.
",5.3 AAE/MAE Performance Disparity,[0],[0]
"We further calculated recall for each relation
type across the AA tweets and WH tweets, and the resulting performance gap, under the UDPipe Morpho-Tagger and ARK Tagger models trained with synthetic data and embeddings.",5.3 AAE/MAE Performance Disparity,[0],[0]
"Table 4 shows these calculations for the 15 relation types for which the performance gap was highest and which had at least 15 instances in each of the AA and WH tweet sets, along with the corresponding calculation under the ARK Tagger model.",5.3 AAE/MAE Performance Disparity,[0],[0]
The amount by which the performance gap is reduced from the first setting to the second setting is also reported.,5.3 AAE/MAE Performance Disparity,[0],[0]
"Of the 15 relations shown, the gap was reduced for 14, and 7 saw a reduction of at least 10%.",5.3 AAE/MAE Performance Disparity,[0],[0]
"In this section, we discuss AAE lexical and syntactic variations observed in our dataset, with the aim of providing insight into decreased AA parsing accuracy, and the impact of various parser settings on their parsing accuracy.
",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"AAE contains a variety of phonological features which present themselves on Twitter through a number of lexical variations (Green, 2002; Jones, 2015), many of which are listed in §3.1, instances of which occur a total of 80 times in the AA tweets; notably, none occur in the WH tweets.
",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"We investigated the accuracy of various crossdomain parser settings on these lexical variants; for each of the baseline Morpho-Tagger, baseline ARK Tagger, ARK Tagger with embeddings, and ARK Tagger with synthetic data and embeddings models, we counted the number of instances of lexical variants from §3.1 for which the model gave the correct head with the correct label.
",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"While the lexical variants challenged all four models, switching from the Morpho-Tagger set-
ting to the ARK Tagger settings produced significant accuracy increases (Table 6).",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
We observed that the greatest improvement came from using the ARK Tagger setting with Twitter-trained embeddings; the Twitter-specific lexical information provided by the embeddings was critical to recognizing the variants.,5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"Surprisingly, adding synthetic data decreased the model’s ability to parse the variants.
",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
We next investigated the presence of AAE syntactic phenomena in our dataset.,5.4 Lexical and Syntactic Analysis of AAE,[0.9515658417968064],['We prove the asymptotic validity of this confidence interval in Corollary 5.6.']
"Table 5 shows examples of seven well-documented AAE morphological and syntactic features and counts of their occurrences in our AA and WH tweet sets; again, while several of the phenomena, such as dropped
copulas and habitual be, occur frequently in our AA tweets, there is only one instance of any of these features occurring in the WH tweet set.
",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"We measured the parsing accuracy for the two most frequent syntactic features, dropped copulas and habitual be, across the four models; accuracies are given in Table 6.",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"For dropped copulas, we measured parsing correctness by checking if the parser correctly attached the subject to the correct predicate word via the nsubj relation; for the first example in Table 5, for example, we considered the parser correct if it attached bestfrienddd to mad via the nsubj relation.",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"For habitual be, we checked for correct attachment via the aux or cop relations as in the first and second examples in Ta-
ble 5, respectively.",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"As before, we observed significant increases in accuracy moving from the Morpho-Tagger to the ARK Tagger settings.",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"However, neither adding embeddings nor synthetic data appeared to significantly increase accuracy for these features.",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"From manual inspection, most of the dropped copulas errors appear to arise either from challenging questions (e.g. ATMENTION what yo number ?) or from mis-identification of the word to which to attach the subject (e.g. He claim he in love llh, where he was attached to llh rather than to love).",5.4 Lexical and Syntactic Analysis of AAE,[0],[0]
"While current neural dependency parsers are highly accurate on MAE, our analyses suggest that AAE text presents considerable challenges due to lexical and syntactic features which diverge systematically from MAE.",6 Conclusion,[0],[0]
"While the cross-domain strategies we presented can greatly increase accurate parsing of these features, narrowing the performance gap between AAE- and MAE-like tweets, much work remains to be done for accurate parsing of even linguistically well-documented features.
",6 Conclusion,[0],[0]
"It remains an open question whether it is better to use a model with a smaller accuracy disparity (e.g. UDPipe), or a model with higher average accuracy, but a worse disparity (e.g. Deep Biaffine).",6 Conclusion,[0],[0]
"The emerging literature on fairness in algorithms suggests interesting further challenges; for example, Kleinberg et al. (2017) and CorbettDavies et al. (2017) argue that as various commonly applied notions of fairness are mutually incompatible, algorithm designers must grapple with such trade-offs.",6 Conclusion,[0],[0]
"Regardless, the modeling decision should be made in light of the application of interest; for example, applications like opinion analysis and information retrieval may benefit from equal (and possibly weaker) performance between groups, so that concepts or opinions in-
ferred from groups of authors (e.g. AAE speakers) are not under-counted or under-represented in results returned to a user or analyst.",6 Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
"This work was supported by a Google Faculty Research Award, and a National Science Foundation Graduate Research Fellowship (No. 1451512).",Acknowledgments,[0],[0]
"Due to the presence of both Twitterspecific conventions and non-standard and dialectal language, Twitter presents a significant parsing challenge to current dependency parsing tools.",abstractText,[0],[0]
"We broaden English dependency parsing to handle social media English, particularly social media African-American English (AAE), by developing and annotating a new dataset of 500 tweets, 250 of which are in AAE, within the Universal Dependencies 2.0 framework.",abstractText,[0],[0]
"We describe our standards for handling Twitterand AAE-specific features and evaluate a variety of crossdomain strategies for improving parsing with no, or very little, in-domain labeled data, including a new data synthesis approach.",abstractText,[0],[0]
"We analyze these methods’ impact on performance disparities between AAE and Mainstream American English tweets, and assess parsing accuracy for specific AAE lexical and syntactic features.",abstractText,[0],[0]
Our annotated data and a parsing model are available at: http://slanglab.cs.umass.edu/ TwitterAAE/.,abstractText,[0],[0]
Twitter Universal Dependency Parsing for African-American and Mainstream American English,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 810–820 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
810",text,[0],[0]
In this paper we study two bilingual tasks that strongly depend on bilingual word embeddings (BWEs).,1 Introduction,[0],[0]
"Previously, specialized domain adaptation approaches to such tasks were proposed.",1 Introduction,[0],[0]
We instead show experimentally that a simple adaptation process involving only unlabeled text is highly effective.,1 Introduction,[0],[0]
"We then show that a semisupervised classification method from computer vision can be applied successfully for further gains in cross-lingual classification.
",1 Introduction,[0],[0]
Our BWE adaptation method is delightfully simple.,1 Introduction,[0],[0]
We begin by adapting monolingual word embeddings to the target domain for source and target languages by simply building them using both general and target-domain unlabeled data.,1 Introduction,[0],[0]
"As
a second step we use post-hoc mapping (Mikolov et al., 2013b), i.e., we use a seed lexicon to transform the word embeddings of the two languages into the same vector space.",1 Introduction,[0],[0]
We show experimentally for the first time that the domain-adapted bilingual word embeddings we produce using this extremely simple technique are highly effective.,1 Introduction,[0],[0]
"We study two quite different tasks and domains, where resources are lacking, showing that our simple technique performs well for both of them: cross-lingual twitter sentiment classification and medical bilingual lexicon induction.",1 Introduction,[0],[0]
"In previous work, task-dependent approaches were used for this type of domain adaptation.",1 Introduction,[0],[0]
"Our approach is simple and task independent.
",1 Introduction,[0],[0]
"Second, we adapt the semi-supervised image classification system of Häusser et al. (2017) for NLP problems for the first time.",1 Introduction,[0],[0]
This approach is broadly applicable to many NLP classification tasks where unlabeled data is available.,1 Introduction,[0],[0]
We tailor it to both of our cross-lingual tasks.,1 Introduction,[0],[0]
"The system exploits unlabeled data during the training of classifiers by learning similar features for similar labeled and unlabeled training examples, thereby extracting information from unlabeled examples as well.",1 Introduction,[0],[0]
"As we show experimentally, the system further improves cross-lingual knowledge transfer for both of our tasks.
",1 Introduction,[0],[0]
"After combining both techniques, the results of sentiment analysis are competitive with systems that use annotated data in the target language, an impressive result considering that we require no target-language annotated data.",1 Introduction,[0],[0]
The method also yields impressive improvements for bilingual lexicon induction compared with baselines trained on in-domain data.,1 Introduction,[0],[0]
We show that this system requires the high-quality domain-adapted bilingual word embeddings we previously created to use unlabeled data well.,1 Introduction,[0],[0]
Many approaches have been proposed for creating high quality BWEs using different bilingual signals.,2.1 Bilingual Word Embeddings,[0],[0]
"Following Mikolov et al. (2013b), many authors (Faruqui and Dyer, 2014; Xing et al., 2015; Lazaridou et al., 2015; Vulić and Korhonen, 2016) map monolingual word embeddings (MWEs) into the same bilingual space.",2.1 Bilingual Word Embeddings,[0],[0]
"Others leverage parallel texts (Hermann and Blunsom, 2014; Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vulić and Moens, 2015; Duong et al., 2016) to train BWEs.
",2.1 Bilingual Word Embeddings,[0],[0]
"In contrast, our aim is not to improve the intrinsic quality of BWEs, but to adapt BWEs to specific domains to enhance their performance on bilingual tasks in these domains.",2.1 Bilingual Word Embeddings,[0],[0]
"Faruqui et al. (2015), Gouws and Søgaard (2015), Rothe et al. (2016) have previously studied domain adaptation of bilingual word embeddings, showing it to be highly effective for improving downstream tasks.",2.1 Bilingual Word Embeddings,[0],[0]
"However, importantly, their proposed methods are based on specialized domain lexicons (such as, e.g., sentiment lexicons) which contain task specific word relations.",2.1 Bilingual Word Embeddings,[0],[0]
"Our delightfully simple approach is, in contrast, effectively task independent (in that it only requires unlabeled in-domain text), which is an important strength.",2.1 Bilingual Word Embeddings,[0],[0]
"Sentiment analysis is widely applied, and thus ideally we would have access to high quality supervised models in all human languages.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Unfortunately, good quality labeled datasets are missing for many languages.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
Training models on resource rich languages and applying them to resource poor languages is therefore highly desirable.,2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Crosslingual sentiment classification (CLSC) tackles this problem (Mihalcea et al., 2007; Banea et al., 2010; Wan, 2009; Lu et al., 2011; Balamurali and Joshi, 2012; Gui et al., 2013).",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Recent CLSC approaches use BWEs as features of deep learning architectures which allows us to use a model for target-language sentiment classification, even when the model was trained only using sourcelanguage supervised training data.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
Following this approach we perform CLSC on Spanish tweets using English training data.,2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Even though Spanish is not resource-poor we simulate this by using only English annotated data.
",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Xiao and Guo (2013) proposed a cross-lingual log-bilinear document model to learn distributed representations of words, which can capture both the semantic similarities of words across languages and the predictive information with respect to the classification task.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Similarly, Tang and Wan (2014) jointly embedded texts in different languages into a joint semantic space representing sentiment.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Zhou et al. (2014) employed aligned sentences in the BWE learning process, but in the sentiment classification process only representations in the source language are used for training, and representations in the target language are used for predicting labels.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"An important weakness of these three works was that aligned sentences were required.
",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Some work has trained sentiment-specific BWEs using annotated sentiment information in both languages (Zhou et al., 2015, 2016), which is desirable, but this is not applicable to our scenario.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
Our goal is to adapt BWEs to a specific domain without requiring additional task-specific engineering or knowledge sources beyond having access to plentiful target-language in-domain unlabeled text.,2.2 Cross-Lingual Sentiment Analysis,[0],[0]
"Both of the approaches we study in this work fit this criterion, the delightfully simple method for adapting BWEs can improve the performance of any off-the-shelf classifier that is based on BWEs, while the broadly applicable semi-supervised approach of Häusser et al. (2017) can improve the performance of any off-the-shelf classifier.",2.2 Cross-Lingual Sentiment Analysis,[0],[0]
BLI is an important task that has been addressed by a large amount of previous work.,2.3 Bilingual Lexicon Induction (BLI),[0],[0]
The goal of BLI is to automatically extract word translation pairs using BWEs.,2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"While BLI is often used to provide an intrinsic evaluation of BWEs (Lazaridou et al., 2015; Vulić and Moens, 2015; Vulić and Korhonen, 2016)",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"it is also useful for tasks such as machine translation (Madhyastha and España Bohnet, 2017).",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
Most work on BLI using BWEs focuses on frequent words in high-resource domains such as parliament proceedings or news texts.,2.3 Bilingual Lexicon Induction (BLI),[0],[0]
Recently Heyman et al. (2017) tackled BLI of words in the medical domain.,2.3 Bilingual Lexicon Induction (BLI),[0],[0]
This task is useful for many applications such as terminology extraction or OOV mining for machine translation of medical texts.,2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"Heyman et al. (2017) show that when only a small amount of medical data is available,
BLI using BWEs tends to perform poorly.",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"Especially BWEs obtained using post-hoc mapping (Mikolov et al., 2013b; Lazaridou et al., 2015) fail on this task.",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"Consequently, Heyman et al. (2017) build BWEs using aligned documents and then engineer a specialized classification-based approach to BLI.",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"In contrast, our delightfully simple approach to create high-quality BWEs for the medical domain requires only monolingual data.",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
We show that our adapted BWEs yield impressive improvements over non-adapted BWEs in this task with both cosine similarity and with the classifier of Heyman et al. (2017).,2.3 Bilingual Lexicon Induction (BLI),[0],[0]
"In addition, we show that the broadly applicable method can push performance further using easily accessible unlabeled data.",2.3 Bilingual Lexicon Induction (BLI),[0],[0]
BWEs trained on general domain texts usually result in lower performance when used in a system for a specific domain.,3 Adaptation of BWEs,[0],[0]
There are two reasons for this.,3 Adaptation of BWEs,[0],[0]
"(i) Vocabularies of specific domains contain words that are not used in the general case, e.g., names of medicines or diseases.",3 Adaptation of BWEs,[0],[0]
"(ii) The meaning of a word varies across domains; e.g., “apple” mostly refers to a fruit in general domains, but is an electronic device in many product reviews.
",3 Adaptation of BWEs,[0],[0]
The delightfully simple method adapts general domain BWEs in a way that preserves the semantic knowledge from general domain data and leverages monolingual domain specific data to create domain-specific BWEs.,3 Adaptation of BWEs,[0],[0]
Our domain-adaptation approach is applicable to any language-pair in which monolingual data is available.,3 Adaptation of BWEs,[0],[0]
"Unlike other methods, our approach is task independent: it only requires unlabeled in-domain target language text.",3 Adaptation of BWEs,[0],[0]
"To create domain adapted BWEs, we first train MWEs (monolingual word embeddings) in both languages and then map those into the same space using post-hoc mapping (Mikolov et al., 2013b).",3.1 Approach,[0],[0]
We train MWEs for both languages by concatenating monolingual out-of-domain and in-domain data.,3.1 Approach,[0],[0]
The out-of-domain data allows us to create accurate distributed representations of common vocabulary while the in-domain data embeds domain specific words.,3.1 Approach,[0],[0]
We then map the two MWEs using a small seed lexicon to create the adapted BWEs.,3.1 Approach,[0],[0]
"Because post-hoc mapping only requires a seed lexicon as bilingual signal it can
easily be used with (cheap) monolingual data.",3.1 Approach,[0],[0]
"For post-hoc mapping, we use Mikolov et al. (2013b)’s approach.",3.1 Approach,[0],[0]
This model assumes a W ∈ Rd1×d2 matrix which maps vectors from the source to the target MWEs where d1 and d2 are the embedding space dimensions.,3.1 Approach,[0],[0]
"A seed lexicon of (xi, yi) ∈ L ⊆ Rd1×Rd2 pairs is needed where xi and yi are source and target MWEs.",3.1 Approach,[0],[0]
"W can be learned using ridge regression by minimizing the L2-regularized mapping error between the source xi and the target yi vectors:
min W ∑ i ||Wxi − yi||22 + λ||W ||22 (1)
where λ is the regularization weight.",3.1 Approach,[0],[0]
"Based on the source embedding x, we then compute a target embedding as Wx.
We create MWEs with word2vec skipgram (Mikolov et al., 2013a)1 and estimate W with scikit-learn (Pedregosa et al., 2011).",3.1 Approach,[0],[0]
We use default parameters.,3.1 Approach,[0],[0]
"In CLSC, an important application of BWEs, we train a supervised sentiment model on training data available in the source (a resource rich language) and apply it to the target (a resource poor language, for which there is typically no training data available).",4 Cross-Lingual Sentiment Classification,[0],[0]
"Because BWEs embed source and target words in the same space, annotations in the source (represented as BWEs) enable transfer learning.",4 Cross-Lingual Sentiment Classification,[0],[0]
"For CLSC of tweets, a drawback of BWEs trained on non-twitter data is that they do not produce embeddings for twitter-specific vocabulary, e.g., slang words like English coool and (Mexican) Spanish chido, resulting in lost information when a sentiment classifier uses them.",4 Cross-Lingual Sentiment Classification,[0],[0]
"As comparable non-twitter data we use OpenSubtitles (Lison and Tiedemann, 2016) which contains 49.2M English and Spanish subtitle sentences respectively (Subtitle).",4.1 Training Data for Twitter Specific BWEs,[0],[0]
The reason behind choosing Subtitles is that although it is out-of-domain it contains slang words similar to tweets thus serving as a strong baseline in our setup.,4.1 Training Data for Twitter Specific BWEs,[0],[0]
"We experiment with two monolingual twitter data sets:
(i) 22M tweets: Downloaded2 English (17.2M) and Spanish (4.8M) tweets using the public
1https://github.com/dav/word2vec 2We downloaded for a month starting on 2016-10-15.
",4.1 Training Data for Twitter Specific BWEs,[0],[0]
"Twitter Streaming API3 with language filters en and es
(ii) a BACKGROUND corpus of 296K English and 150K Spanish (non-annotated) tweets released with the test data of the RepLab task (Amigó et al., 2013) described below
All twitter data was tokenized using Bird et al. (2009) and lowercased.",4.1 Training Data for Twitter Specific BWEs,[0],[0]
"User names, URLs, numbers, emoticons and punctuation were removed.
",4.1 Training Data for Twitter Specific BWEs,[0],[0]
"As lexicon for the mapping, we use the BNC word frequency list (Kilgarriff, 1997), a list of 6,318 frequent English lemmas and their Spanish translations, obtained from Google Translate.",4.1 Training Data for Twitter Specific BWEs,[0],[0]
Note that we do not need a domain-specific lexicon in order to get good quality adapted BWEs.,4.1 Training Data for Twitter Specific BWEs,[0],[0]
"For sentiment classification, we use data from the RepLab 2013 shared task (Amigó et al., 2013).",4.2 Training Data for Sentiment Classifiers,[0],[0]
"The data is annotated with positive, neutral and negative labels and contains English and Spanish tweets.",4.2 Training Data for Sentiment Classifiers,[0],[0]
We used the official English training set (26.6K tweets) and the Spanish test set (14.9K) in the resource-poor setup.,4.2 Training Data for Sentiment Classifiers,[0],[0]
"We only use the 7.2K Spanish labeled training data for comparison reasons in §6.2, which we will discuss later.
",4.2 Training Data for Sentiment Classifiers,[0],[0]
"The shared task was on target-level sentiment analysis, i.e., given a pair (document, target entity), the gold annotation is based on whether the sentiment expressed by the document is about the target.",4.2 Training Data for Sentiment Classifiers,[0],[0]
For example: I cried on the back seat of my BMW!,4.2 Training Data for Sentiment Classifiers,[0],[0]
where BMW is the target would be negative in the sentence-level scenario.,4.2 Training Data for Sentiment Classifiers,[0],[0]
"However, it is neutral in the target-level case because the negative sentiment is not related to BMW.",4.2 Training Data for Sentiment Classifiers,[0],[0]
The reason for using this dataset is that it contains comparable English and Spanish tweets annotated for sentiment.,4.2 Training Data for Sentiment Classifiers,[0],[0]
"There are other twitter datasets for English (Nakov et al., 2016) and Spanish (GarcıaCumbreras et al., 2016), but they were downloaded at different times and were annotated using different annotation methodologies, thus impeding a clean and consistent evaluation.",4.2 Training Data for Sentiment Classifiers,[0],[0]
For evaluating our adapted BWEs on the RepLab dataset we used a target-aware sentiment classifier introduced by Zhang et al. (2016).,4.3 Sentiment Systems,[0],[0]
"The network first embeds input words using pre-trained
3dev.twitter.com/streaming/overview
BWEs and feeds them to a bi-directional gated neural network.",4.3 Sentiment Systems,[0],[0]
Pooling is applied on the hidden representations of the left and right context of the target mention respectively.,4.3 Sentiment Systems,[0],[0]
"Finally, gated neurons are used to model the interaction between the target mention and its surrounding context.",4.3 Sentiment Systems,[0],[0]
"During training we hold our pre-trained BWEs fixed and keep the default parameters of the model.
",4.3 Sentiment Systems,[0],[0]
"We also implement Kim (2014)’s CNN-nonstatic system, which does not use the target information in a given document (target-ignorant).",4.3 Sentiment Systems,[0],[0]
The network first embeds input words using pretrained BWEs and feeds them to a convolutional layer with multiple window sizes.,4.3 Sentiment Systems,[0],[0]
Max pooling is applied on top of convolution followed by a fully connected network with one hidden layer.,4.3 Sentiment Systems,[0],[0]
We used this system as well because it performed comparably to the target-aware system.,4.3 Sentiment Systems,[0],[0]
"The reason for this is that only 1% of the used data contains more than one target and out of these rare cases only 14% have differing sentiment labels in the same sentence, which are the difficult cases of target-level sentiment analysis.",4.3 Sentiment Systems,[0],[0]
"We used the default parameters as described in (Kim, 2014) with the exception of using 1000 feature maps and 30 epochs, based on our initial experiments.",4.3 Sentiment Systems,[0],[0]
Word embeddings are fixed during the training just as for the target-aware classifier.,4.3 Sentiment Systems,[0],[0]
As we previously explained we evaluate our adaptation method on the task of target-level sentiment classification using both target-aware and target-ignorant classifiers.,4.4 Results,[0],[0]
"For all experiments, our two baselines are off-the-shelf classifiers using non-adapted BWEs, i.e., BWEs trained only using Subtitles.",4.4 Results,[0],[0]
Our goal is to show that our BWE adaptation method can improve the performance of such classifiers.,4.4 Results,[0],[0]
We train our adapted BWEs on the concatenation of Subtitle and 22M tweets or BACKGROUND respectively.,4.4 Results,[0],[0]
"In addition, we also report results with BWEs trained only on tweets.
",4.4 Results,[0],[0]
To train the sentiment classifiers we use the English Replab training set and we evaluate on the Spanish test set.,4.4 Results,[0],[0]
"To show the performance that can be reached in a monolingual setup, we report results obtained by using annotated Spanish sentiment data instead of English (oracle).",4.4 Results,[0],[0]
"We train two oracle sentiment classifiers using (i) MWEs trained on only the Spanish part of Subtitle and (ii)
BWEs trained on Subtitle using posthoc mapping.",4.4 Results,[0],[0]
"The difference between the two is that the embeddings of (ii) are enriched with English words which can be beneficial for the classification of Spanish tweets because they often contain a few English words.
",4.4 Results,[0],[0]
We do not compare with word embedding adaptation methods relying on specialized resources.,4.4 Results,[0],[0]
The point of our work is to study task-independent methods and to the best of our knowledge ours is the first such attempt.,4.4 Results,[0],[0]
"Similarly, we do not compare against machine translation based sentiment classifiers (e.g., (Zhou et al., 2016))",4.4 Results,[0],[0]
"because for their adaptation in-domain parallel data would be needed.
",4.4 Results,[0],[0]
Table 1 gives results for both classifiers.,4.4 Results,[0],[0]
It shows that the adaptation of Subtitle based BWEs with data from Twitter (22M tweets and BACKGROUND) clearly outperforms the Baseline in all cases.,4.4 Results,[0],[0]
The target-aware system performed poorly with the baseline BWEs and could benefit significantly from the adaptation approach.,4.4 Results,[0],[0]
The target-ignorant performed better with the baseline BWEs but could also benefit from the adaptation.,4.4 Results,[0],[0]
"Comparing results with the Twitter-dataset-only based BWEs, the 22M tweets performed better even though the BACKGROUND dataset is from the same topic as the RepLab train and test sets.",4.4 Results,[0],[0]
Our conjecture is that the latter is too small to create good BWEs.,4.4 Results,[0],[0]
"In combination with Subtitles, 22M tweets also yields better results than when combined with BACKGROUND.",4.4 Results,[0],[0]
"Although the best accuracy was reached using the 22M tweetsonly based BWEs, it is only slightly better then the adapted Subtitles+22M tweets based BWEs.",4.4 Results,[0],[0]
"In §6 we show that both the semantic knowledge from Subtitles and the domain-specific information from tweets are needed to further improve results.
",4.4 Results,[0],[0]
Comparing the two classifiers we can say that they performed similarly in terms of their best results.,4.4 Results,[0],[0]
"On the other hand, the target-ignorant system had better results on average.",4.4 Results,[0],[0]
This might seem surprising at first because the system does not use the target as information.,4.4 Results,[0],[0]
"But considering the characteristics of RepLab, i.e., that the number of tweets that contains multiple targets is negligible, using the target offers no real advantage.
",4.4 Results,[0],[0]
"Although we did not focus on the impact of the seed lexicon size, we ran post-hoc mapping with different sizes during our preliminary experiments.",4.4 Results,[0],[0]
"With 1,000 and 100 word pairs in the lexicon the target-ignorant system suffered 0.5% and 4.0% drop in average of our setups respectively.
",4.4 Results,[0],[0]
To summarize the result: using adapted BWEs for the Twitter CLSC task improves the performance of off-the-shelf classifiers.,4.4 Results,[0],[0]
Another interesting downstream task for BWEs is bilingual lexicon induction.,5 Medical Bilingual Lexicon Induction,[0],[0]
"Given a list of words in a source language, the goal of BLI is to mine translations for each word in a chosen target language.",5 Medical Bilingual Lexicon Induction,[0],[0]
"The medical bilingual lexicon induction task proposed in (Heyman et al., 2017) aims to mine medical words using BWEs trained on a very small amount of English and Dutch monolingual medical data.",5 Medical Bilingual Lexicon Induction,[0],[0]
"Due to the lack of resources in this domain, good quality BWEs are hard to build using in-domain data only.",5 Medical Bilingual Lexicon Induction,[0],[0]
We show that by enriching BWEs with general domain knowledge (in the form of general domain monolingual corpora) better results can be achieved on this medical domain task.,5 Medical Bilingual Lexicon Induction,[0],[0]
We evaluate our improved BWEs on the dataset provided by Heyman et al. (2017).,5.1 Experimental Setup,[0],[0]
The monolingual medical data consists of English and Dutch medical articles from Wikipedia.,5.1 Experimental Setup,[0],[0]
The English (resp.,5.1 Experimental Setup,[0],[0]
"Dutch) articles contain 52,336 (resp.",5.1 Experimental Setup,[0],[0]
"21,374) sentences.",5.1 Experimental Setup,[0],[0]
"A total of 7,368 manually annotated word translation pairs occurring in the English (source) and Dutch (target) monolingual corpora are provided as gold data.",5.1 Experimental Setup,[0],[0]
This set is split 64%/16%/20% into trn/dev/test.,5.1 Experimental Setup,[0],[0]
20% of the English words have multiple translations.,5.1 Experimental Setup,[0],[0]
"Given an English word, the task is to find the correct Dutch translation.
",5.1 Experimental Setup,[0],[0]
"As monolingual general-domain data we use
the English and Dutch data from Europarl (v7) (Koehn, 2005), a corpus of 2 million sentence pairs.",5.1 Experimental Setup,[0],[0]
"Although Europarl is a parallel corpus, we use it in a monolingual way and shuffle each side of the corpus before training.",5.1 Experimental Setup,[0],[0]
By using massive cheap data we create high-quality MWEs in each language which are still domain-specific (due to inclusion of medical data).,5.1 Experimental Setup,[0],[0]
"To obtain an out-ofdomain seed lexicon, we translated the English words in BNC to Dutch using Google Translate (just as we did before for the Twitter CLSC task).",5.1 Experimental Setup,[0],[0]
We then use the out-of-domain BNC and the indomain medical seed lexicons in separate experiments to create BWEs with post-hoc mapping.,5.1 Experimental Setup,[0],[0]
"Note, we did not concatenate the two lexicons because (i) they have a small common subset of source words which have different target words, thus having a negative effect on the mapping and (ii) we did not want to modify the medical seed lexicon because it was taken from previous work.",5.1 Experimental Setup,[0],[0]
To perform BLI we use two methods.,5.2 BLI Systems,[0],[0]
"Because BWEs represent words from different languages in a shared space, BLI can be performed via cosine similarity in this space.",5.2 BLI Systems,[0],[0]
"In other words, given a BWE representing two languages Vs and Vt, the translation of each word s ∈",5.2 BLI Systems,[0],[0]
"Vs can be induced by taking the word t ∈ Vt whose representation ~xt in the BWE is closest to the representation ~xs.
",5.2 BLI Systems,[0],[0]
As the second approach we use a classifier based system proposed by Heyman et al. (2017).,5.2 BLI Systems,[0],[0]
This neural network based system is comprised of two main modules.,5.2 BLI Systems,[0],[0]
The first is a character-level LSTM which aims to learn orthographic similarity of word pairs.,5.2 BLI Systems,[0],[0]
The other is the concatenation of the embeddings of the two words using embedding layers with the aim of learning the similarity among semantic representations of the words.,5.2 BLI Systems,[0],[0]
Dense layers are applied on top of the two modules before the output soft-max layer.,5.2 BLI Systems,[0],[0]
"The classifier is trained using positive and negative word
pair examples and a pre-trained word embedding model.",5.2 BLI Systems,[0],[0]
Negative examples are randomly generated for each positive one in the training lexicon.,5.2 BLI Systems,[0],[0]
We used default parameters as reported by Heyman et al. (2017) except for the t classification thresholds (used at prediction time).,5.2 BLI Systems,[0],[0]
We finetuned these on dev.,5.2 BLI Systems,[0],[0]
"We note that the system works with pre-trained MWEs as well (and report these as official baseline results) but it requires BWEs for candidate generation at prediction time, thus we use BWEs for the system’s input for all experiments.",5.2 BLI Systems,[0],[0]
"In preliminary work, we had found that MWE and BWE results are similar.",5.2 BLI Systems,[0],[0]
Heyman et al. (2017)’s results are our baseline.,5.3 Results,[0],[0]
"Table 2 compares its performance with our adapted BWEs, with both cosine similarity and classification based systems.",5.3 Results,[0],[0]
“top” F1 scores are based on the most probable word as prediction only; “all” F1 scores use all words as prediction whose probability is above the threshold.,5.3 Results,[0],[0]
It can be seen that the cosine similarity based system using adapted BWEs clearly outperforms the nonadapted BWEs which were trained in a resource poor setup.4,5.3 Results,[0],[0]
"Moreover, the best performance was reached using the general seed lexicon for the mapping which is due to the fact that general domain words have better quality embeddings in the MWE models, which in turn gives a better quality mapping.
",5.3 Results,[0],[0]
The classification based system performs significantly better comparing to cosine similarity by exploiting the seed lexicon better.,5.3 Results,[0],[0]
Using adapted BWEs as input word embeddings for the system further improvements were achieved which shows the better quality of our BWEs.,5.3 Results,[0],[0]
"Simulating an even poorer setup by using a general lexicon, the
4The results for cosine similarity in (Heyman et al., 2017) are based on BWESG-based BWEs (Vulić and Moens, 2016) trained on a small document aligned parallel corpus without using a seed lexicon.
performance gain of the classifier is lower.",5.3 Results,[0],[0]
This shows the significance of the medical seed lexicon for this system.,5.3 Results,[0],[0]
"On the other hand, adapted BWEs have better performance compared to non-adapted ones using the best translation while they have just slightly lower F1 using multiple translations.",5.3 Results,[0],[0]
"This result shows that while with adapted BWEs the system predicts better “top” translations, it has a harder time when predicting “all” due to the increased vocabulary size.
",5.3 Results,[0],[0]
To summarize: we have shown that adapted BWEs increase performance for this task and domain; and they do so independently of the taskspecific system that is used.,5.3 Results,[0],[0]
"In addition to the experiments that show our BWEadaptation method’s task and language independence, we investigate ways to further incorporate unlabeled data to overcome data sparsity.
",6 Semi-Supervised Learning,[0],[0]
Häusser et al. (2017) introduce a semisupervised method for neural networks that makes associations from the vector representation of labeled samples to those of unlabeled ones and back.,6 Semi-Supervised Learning,[0],[0]
This lets the learning exploit unlabeled samples as well.,6 Semi-Supervised Learning,[0],[0]
"While Häusser et al. (2017) use their model for image classification, we adapt it to CLSC of tweets and medical BLI.",6 Semi-Supervised Learning,[0],[0]
We show that our semisupervised model requires adapted BWEs to be effective and yields significant improvements.,6 Semi-Supervised Learning,[0],[0]
This innovative method is general and can be applied to any classification when unlabeled text is available.,6 Semi-Supervised Learning,[0],[0]
"Häusser et al. (2017)’s basic assumption is that the embeddings of labeled and unlabeled samples – i.e., the representations in the neural network on which the classification layer is applied – are similar within the same class.",6.1 Model,[0],[0]
"To achieve this, walking cycles are introduced: a cycle starts from a labeled sample, goes to an unlabeled one and ends at a labeled one.",6.1 Model,[0],[0]
A cycle is correct if the start and end samples are in the same class.,6.1 Model,[0],[0]
The probability of going from sample A to B is proportional to the cosine similarity of their embeddings.,6.1 Model,[0],[0]
"To maximize the number of correct cycles, two loss functions are employed: Walker loss and Visit loss.
",6.1 Model,[0],[0]
"Walker loss penalizes incorrect walks and encourages a uniform probability distribution of
walks to the correct class.",6.1 Model,[0],[0]
"It is defined as:
Lwalker := H(T, P aba) (2)
where H is the cross-entropy function, P abaij is the probability that a cycle starts from sample i and ends at j and T is the uniform target distribution:
",6.1 Model,[0],[0]
"Tij :=
{ 1/(#c(i)) if c(i) = c(j)
0",6.1 Model,[0],[0]
"otherwise (3)
where c(i) is the class of sample i and #c(i) is the number of occurrences of c(i) in the labeled set.
",6.1 Model,[0],[0]
"Visit loss encourages cycles to visit all unlabeled samples, rather than just those which are the most similar to labeled samples.",6.1 Model,[0],[0]
"It is defined as:
Lvisit := H(V, P visit)
P visitj := 〈P abij 〉i (4)
",6.1 Model,[0],[0]
"Vj := 1
U
whereH is cross-entropy, P abij is the probability that a cycle starts from sample i and goes to j and U is the number of unlabeled samples.
",6.1 Model,[0],[0]
"The total loss during training is the sum of the walker, visit and classification (cross-entropy between predicted and gold labels) losses which is minimized using Adam (Kingma and Ba, 2015).
",6.1 Model,[0],[0]
"We adapt this model (including the two losses) to sentiment classification, focusing on the targetignorant classifier, and the classifier based approach for BLI.",6.1 Model,[0],[0]
We will call these systems semisup5.,6.1 Model,[0],[0]
Due to the fact that we initialize the embedding layers for both classifiers with BWEs the models are able to make some correct cycles at the beginning of the training and improve them later on.,6.1 Model,[0],[0]
"We will describe the labeled and unlabeled datasets used in the subsequent sections below.
",6.1 Model,[0],[0]
"We use Häusser et al. (2017)’s implementation of the losses, with 1.0, 0.5 and 1.0 weights for the walker, visit and classification losses, respectively, for CLSC based on preliminary experiments.",6.1 Model,[0],[0]
"We fine-tuned the weights for BLI on dev for each experiment.
",6.1 Model,[0],[0]
5We publicly release our implementation: https:// github.com/hangyav/biadapt,6.1 Model,[0],[0]
"As in §4.4, we use pre-trained BWEs to initialize the classifier and use English sentiment training data as the labeled set.",6.2 Semi-Supervised CLSC,[0],[0]
"Furthermore, we use the Spanish sentiment training data as the unlabeled set, ignoring its annotation.",6.2 Semi-Supervised CLSC,[0],[0]
"This setup is very similar to real-word low-resource scenarios: unlabeled target-language tweets are easy to download while labeled English ones are available.
",6.2 Semi-Supervised CLSC,[0],[0]
Table 3 gives results for adapted BWEs and shows that semisup helps only when word embeddings are adapted to the Twitter domain.,6.2 Semi-Supervised CLSC,[0],[0]
"As mentioned earlier, semisup compares labeled and unlabeled samples based on their vector representations.",6.2 Semi-Supervised CLSC,[0],[0]
"By using BWEs based on only Subtitles, we lose too many embeddings of similar English and Spanish tweets.",6.2 Semi-Supervised CLSC,[0],[0]
"On the other hand, if we use only tweet-based BWEs we lose good quality semantic knowledge which can be learned from more standard text domains.",6.2 Semi-Supervised CLSC,[0],[0]
By combining the two domains we were able to capture both sides.,6.2 Semi-Supervised CLSC,[0],[0]
"For Subtitle+22M tweets, we even get very close to the best oracle (BWE Subtitle) in Table 1 getting only 0.27% less accuracy – an impressive result keeping in mind that we did not use labeled Spanish data.
",6.2 Semi-Supervised CLSC,[0],[0]
"The RepLab dataset contains tweets from 4 topics: automotive, banking, university, music.",6.2 Semi-Supervised CLSC,[0],[0]
We manually analyzed similar tweets from the labeled and unlabeled sets.,6.2 Semi-Supervised CLSC,[0],[0]
"We found that when using semisup, English and Spanish tweets from the same topics are more similar in the embedding space than occurs without the additional losses.",6.2 Semi-Supervised CLSC,[0],[0]
"Topics differ in how they express sentiment – this may explain why semisup increases performance for RepLab.
",6.2 Semi-Supervised CLSC,[0],[0]
Adding supervision.,6.2 Semi-Supervised CLSC,[0],[0]
"To show how well semisup can exploit the unlabeled data we used both English and Spanish sentiment training data together to train the sentiment classifiers.
",6.2 Semi-Supervised CLSC,[0],[0]
Table 4 shows that by using annotated data in both languages we get clearly better results than when using only one language.,6.2 Semi-Supervised CLSC,[0],[0]
"Tables 3 and 4 show that for Subtitle+22M tweets based BWEs, the semisup approach achieved high improvement (2.17%) comparing to targetignorant with English training data only, while it achieved lower improvement (0.97%) with the Subtitle+BACKGROUND based BWEs.",6.2 Semi-Supervised CLSC,[0],[0]
"On the other hand, adding labeled Spanish data caused just a slight increase comparing to semisup with Subtitle+22M tweets based BWEs (0.59%), while in case of Subtitle+BACKGROUND we got significant additional improvement (2.61%).",6.2 Semi-Supervised CLSC,[0],[0]
"This means that with higher quality BWEs, unlabeled target-language data can be exploited better.
",6.2 Semi-Supervised CLSC,[0],[0]
It can also be seen that the target-aware system outperformed the target-ignorant system using additional labeled target-language data.,6.2 Semi-Supervised CLSC,[0],[0]
"The reason could be that it is a more complex network and therefore needs more data to reach high performance.
",6.2 Semi-Supervised CLSC,[0],[0]
The results in table 4 are impressive: our targetlevel system is strongly competitive with the official shared task results.,6.2 Semi-Supervised CLSC,[0],[0]
We achieved high accuracy on the Spanish test set by using only English training data.,6.2 Semi-Supervised CLSC,[0],[0]
"Comparing our best system which used all training data to the official results (Amigó et al., 2013)",6.2 Semi-Supervised CLSC,[0],[0]
we would rank 2nd even though our system is not fine-tuned for the RepLab dataset.,6.2 Semi-Supervised CLSC,[0],[0]
"Furthermore, we also outperformed the oracles when using annotated data from both languages which shows the additional advantage of using BWEs.",6.2 Semi-Supervised CLSC,[0],[0]
For BLI experiments with semisup we used word pairs from the medical seed lexicon as the labeled set (with negative word pairs generated as described in §5.2).,6.3 Semi-Supervised BLI,[0],[0]
"As opposed to CLSC and the work of (Häusser et al., 2017), for this task we do not have an unlabeled set, and therefore we need to generate it.",6.3 Semi-Supervised BLI,[0],[0]
We developed two scenarios.,6.3 Semi-Supervised BLI,[0],[0]
"For the first, BNC, we generate a general unlabeled set using English words from the BNC lexicon and generate 10 pairs out of each word by using the 5 most similar Dutch words based on the corresponding BWEs and 5 random Dutch words.",6.3 Semi-Supervised BLI,[0],[0]
"For the second scenario, medical, we generate an in-domain unlabeled set by generating for each English word in the medical lexicon the 3 most similar Dutch
words based on BWEs and for each of these we use the 5 most similar English words (ignoring the words which are in the original medical lexicon) and 5 negative words.",6.3 Semi-Supervised BLI,[0],[0]
"The idea behind these methods is to automatically generate an unlabeled set that hopefully has a similar positive and negative word pair distribution to the distribution in the labeled set.
",6.3 Semi-Supervised BLI,[0],[0]
Results in Table 5 show that adding semisup to the classifier further increases performance for BLI as well.,6.3 Semi-Supervised BLI,[0],[0]
"For the baseline system, when using only in-domain text for creating BWEs, only the medical unlabeled set was effective, general domain word pairs could not be exploited due to the lack of general semantic knowledge in the BWE model.",6.3 Semi-Supervised BLI,[0],[0]
"On the other hand, by using our domain adapted BWEs, which contain both general domain and in-domain semantical knowledge, we can exploit word pairs from both domains.",6.3 Semi-Supervised BLI,[0],[0]
"Results for adapted BWEs increased in 3 out of 4 cases, where the only exception is when using multiple translations for a given source word (which may have been caused by the bigger vocabulary size).
",6.3 Semi-Supervised BLI,[0],[0]
"These results show that adapted BWEs are needed to exploit unlabeled data well which leads to an impressive overall 3.71 increase compared with the best result in previous work (Heyman et al., 2017), by using only unlabeled data.",6.3 Semi-Supervised BLI,[0],[0]
Bilingual word embeddings trained on general domain data yield poor results in out-of-domain tasks.,7 Conclusion,[0],[0]
We presented experiments on two different low-resource task/domain combinations.,7 Conclusion,[0],[0]
Our delightfully simple task independent method to adapt BWEs to a specific domain uses unlabeled monolingual data only.,7 Conclusion,[0],[0]
We showed that with the support of adapted BWEs the performance of offthe-shelf methods can be increased for both crosslingual Twitter sentiment classification and medical bilingual lexicon induction.,7 Conclusion,[0],[0]
"Furthermore, by adapting the broadly applicable semi-supervised approach of Häusser et al. (2017) (which until now has only been applied in computer vision) we were able to effectively exploit unlabeled data to further improve performance.",7 Conclusion,[0],[0]
"We showed that, when also using high-quality adapted BWEs, the performance of the semi-supervised systems can be significantly increased by using unlabeled data at classifier training time.",7 Conclusion,[0],[0]
"In addition, CLSC results are competitive with a system that uses targetlanguage labeled data, even when we use no such target-language labeled data.",7 Conclusion,[0],[0]
We would like to thank the anonymous reviewers for their valuable input.,Acknowledgments,[0],[0]
This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement№ 640550).,Acknowledgments,[0],[0]
"Bilingual tasks, such as bilingual lexicon induction and cross-lingual classification, are crucial for overcoming data sparsity in the target language.",abstractText,[0],[0]
"Resources required for such tasks are often out-of-domain, thus domain adaptation is an important problem here.",abstractText,[0],[0]
We make two contributions.,abstractText,[0],[0]
"First, we test a delightfully simple method for domain adaptation of bilingual word embeddings.",abstractText,[0],[0]
We evaluate these embeddings on two bilingual tasks involving different domains: cross-lingual twitter sentiment classification and medical bilingual lexicon induction.,abstractText,[0],[0]
"Second, we tailor a broadly applicable semi-supervised classification method from computer vision to these tasks.",abstractText,[0],[0]
We show that this method also helps in low-resource setups.,abstractText,[0],[0]
"Using both methods together we achieve large improvements over our baselines, by using only additional unlabeled data.",abstractText,[0],[0]
Two Methods for Domain Adaptation of Bilingual Tasks: Delightfully Simple and Broadly Applicable,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 105–114 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
105
We propose to consider these two aspects jointly. We develop TWOWINGOS (twowing optimization strategy), a system that, while identifying appropriate evidence for a claim, also determines whether or not the claim is supported by the evidence. Given the claim, TWOWINGOS attempts to identify a subset of the evidence candidates; given the predicted evidence, it then attempts to determine the truth value of the corresponding claim. We treat this challenge as coupled optimization problems, training a joint model for it. TWOWINGOS offers two advantages: (i) Unlike pipeline systems, it facilitates flexible-size evidence set, and (ii) Joint training improves both the claim verification and the evidence identification. Experiments on a benchmark dataset show state-of-the-art performance.1",text,[0],[0]
"A claim, e.g., “Marilyn Monroe worked with Warner Brothers”, is an assertive sentence that may be true or false.",1 Introduction,[0],[0]
"While the task of claim verification will not tell us the absolute truth of this claim, it is expected to determine whether the claim is supported by evidence in a given text collection.",1 Introduction,[0],[0]
"Specifically, given a claim and a text corpus, evidential claim verification, demonstrated in
1cogcomp.org/page/publication_view/847
Figure 1, aims at identifying text snippets in the corpus that act as evidence that supports or refutes the claim.
",1 Introduction,[0],[0]
This problem has broad applications.,1 Introduction,[0],[0]
"For example, knowledge bases (KB), such as Freebase (Bollacker et al., 2008), YAGO (Suchanek et al., 2007), can be augmented with a new relational statement such as “(Afghanistan, is source of, Kushan Dynasty)”.",1 Introduction,[0],[0]
"This needs to be first verified by a claim verification process and supported by evidence (Roth et al., 2009; Chaganty et al., 2017).",1 Introduction,[0],[0]
"More broadly, claim verification is a key component in any technical solution addressing recent concerns about the trustworthiness of online content (Vydiswaran et al., 2011; Pasternack and Roth, 2013; Hovy et al., 2013).",1 Introduction,[0],[0]
"In both scenarios, we care about whether or not a claim holds, and seek reliable evidence in support of this decision.
",1 Introduction,[0],[0]
Evidential claim verification requires that we address three challenges.,1 Introduction,[0],[0]
"First, to locate text snippets in the given corpus that can potentially be used to determine the truth value of the given claim.",1 Introduction,[0],[0]
"This differs from the conventional textual entailment (TE) problem (Dagan et al., 2013) as here we first look for the premises given a hypothesis.",1 Introduction,[0],[0]
"Clearly, the evidence one seeks depends on the claim, as well as on the eventual entailment
decision – the same claim would require different supporting than refuting evidence.",1 Introduction,[0],[0]
This motivates us to develop an approach that can transfer knowledge from claim verification to evidence identification.,1 Introduction,[0],[0]
"Second, the evidence for a claim might require aggregating information from multiple sentences and even multiple documents (rf. #3 in Table 4).",1 Introduction,[0],[0]
"Therefore, a set, rather than a collection of independent text snippets, should be chosen to act as evidence.",1 Introduction,[0],[0]
"And, finally, in difference from TE, given a set of evidence sentences as a premise, the truth value of the claim should depend on all of the evidence, rather than on a single sentence there.
",1 Introduction,[0],[0]
The discussion above suggests that claim verification and evidence identification are tightly coupled.,1 Introduction,[0],[0]
"Claim should influence the identification of appropriate evidence, and “trusted evidence boosts the claim’s veracity” (Vydiswaran et al., 2011).",1 Introduction,[0],[0]
"Consequently, we propose TWOWINGOS, a twowing optimization strategy2, to support this process.",1 Introduction,[0],[0]
"As shown in Figure 2, we consider a set of sentences S as the candidate evidence space, a claim x, and a decision space Y for the claim verification.",1 Introduction,[0],[0]
"In the optimal condition, a one-hot vector over Y indicates which decision to make towards the claim, and a binary vector over S indicates a subset of sentences Se (in blue in Figure 2) to act as evidence.
",1 Introduction,[0],[0]
"Prior work mostly approached this problem as a pipeline procedure – first, given a claim x, determine Se by some similarity matching; then, conduct textual entailment over (Se, x) pairs.",1 Introduction,[0],[0]
"Our framework, TWOWINGOS, optimizes the two
2By “two-wing optimization”, we mean that the same object, i.e., the claim, is mapped into two target spaces in a joint optimization scheme.
subtasks jointly, so that both claim verification and evidence identification can enhance each other.",1 Introduction,[0],[0]
"TWOWINGOS is a generic framework making use of a shared representation of the claim to cotrain evidence identification and claim verification.
",1 Introduction,[0],[0]
"TWOWINGOS is tested on the FEVER benchmark (Thorne et al., 2018), showing≈30% F1 improvement for evidence identification, and ≈23% accuracy increase in claim verification.",1 Introduction,[0],[0]
Our analysis shows that (i) entity mentions in claims provide a strong clue for retrieving relevant passages; (ii) composition of evidence clues across sentences helps claim verification; and that (iii) the joint training scheme provides significant benefits of a pipeline architecture.,1 Introduction,[0],[0]
Most work focuses on the dataset construction while lacking advanced models to handle the problem.,2 Related Work,[0],[0]
"Vlachos and Riedel (2014) propose and define the “fact checking” problem, without a concrete solution.",2 Related Work,[0],[0]
Ferreira and Vlachos (2016) release the dataset “Emergent” for rumor debunking.,2 Related Work,[0],[0]
Each claim is accompanied by an article headline as evidence.,2 Related Work,[0],[0]
Then a three-way logistic regression model is used over some rule-based features.,2 Related Work,[0],[0]
No need to search for evidence.,2 Related Work,[0],[0]
"Wang (2017) release a larger dataset for fake news detection, and propose a hybrid neural network to integrate the statement and the speaker’s meta data to do classification.",2 Related Work,[0],[0]
"However, the presentation of evidences is ignored.",2 Related Work,[0],[0]
"Kobayashi et al. (2017) release a similar dataset to (Thorne et al., 2018), but they do not consider the evaluation of evidence reasoning.
",2 Related Work,[0],[0]
"Some work mainly pays attention to determining whether the claim is true or false, assuming evidence facts are provided or neglecting presenting evidence totally, e.g., (Angeli and Manning, 2014) – given a database of true facts as premises, predicting whether an unseen fact is true and should belong to the database by natural logic inference.",2 Related Work,[0],[0]
"Open-domain question answering (QA) against a text corpus (Yin et al., 2016; Chen et al., 2017; Wang et al., 2018) can also be treated as claim verification problem, if we treat (question, correct answer) as a claim.",2 Related Work,[0],[0]
"However, little work has studied how well a QA system can identify all the answer evidence.
",2 Related Work,[0],[0]
"Only a few works considered improving the evidence presentation in claim verification problems.
",2 Related Work,[0],[0]
"Roth et al. (2009) introduce the task of Entailed Relation Recognition – given a set of short paragraphs and a relational fact in the triple form of (argument1, relation, argument2), finding the paragraphs that can entail this fact.",2 Related Work,[0],[0]
"They first use Expanded Lexical Retrieval to rank and keep the topk paragraphs as candidates, then build a TE classifier over each (candidate, statement) pair.",2 Related Work,[0],[0]
The work directly related to us is by Thorne et al. (2018).,2 Related Work,[0],[0]
"Given claims and a set of Wikipages, Thorne et al. (2018) use a retrieval model based on TF-IDF to locate top-5 sentences in top-5 pages as evidence, then utilize a neural entailment model to classify (evidence, claim) pairs.
",2 Related Work,[0],[0]
"In contrast, our work tries to optimize the claim verification as well as the evidence identification in a joint training scheme, which is more than just supporting or refuting the claims.",2 Related Work,[0],[0]
"Figure 2 illustrates the two-wing optimization problem addressed in this work: given a collection of evidence candidates S={s1, s2, · · · , si, · · · , sm}, a claim x and a decision set Y = {y1 · · · , yn}, the model TWOWINGOS predicts a binary vector p over S and a one-hot vector o over Y against the ground truth, a binary vector q and a one-hot vector z, respectively.",3 The TWOWINGOS Model,[0],[0]
"A binary vector over S means a subset of sentences (Se) act as evidence, and the one-hot vector indicates a single decision (yi) to be made towards the claim x given the evidence Se.",3 The TWOWINGOS Model,[0],[0]
"Next, we use two separate subsections to elaborate the process of evidence identification (i.e., optimize p to q) and the claim verification (i.e., optimize o to z).",3 The TWOWINGOS Model,[0],[0]
"A simple approach to identifying evidence is to detect the top-k sentences that are lexically similar to the claim, as some pipeline systems (Roth et al., 2009; Thorne et al., 2018) do.",3.1 Evidence identification,[0],[0]
"However, a claimunaware fixed k is less optimal, adding noise or missing key supporting factors, consequently limiting the performance.
",3.1 Evidence identification,[0],[0]
"In this work, we approach the evidence by modeling sentences S={s1, · · · , si, · · · , sm} with the claim x as context in a supervised learning scheme.",3.1 Evidence identification,[0],[0]
"For each si, the problem turns out to be learning a probability: how likely si can entail the claim conditioned on other candidates as context, as shown by the blue items in Figure 2.
To start, a piece of text t (t ∈ S ∪ {x}) is represented as a sequence of l hidden states, forming a feature map T ∈ Rd×l, where d is the dimensionality of hidden states.",3.1 Evidence identification,[0],[0]
"We first stack a vanilla CNN (convolution & max-pooling) (LeCun et al., 1998) over T to get a representation for t. As a result, each evidence candidate si has a representation si, and the claim x has a representation x.",3.1 Evidence identification,[0],[0]
"To get a probability for each si, we need first to build its claim-aware representation ri.
Coarse-grained representation.",3.1 Evidence identification,[0],[0]
"We directly concatenate the representation of si and x, generated by the vanilla CNN, as:
ri =",3.1 Evidence identification,[0],[0]
"[si,x, si · xT ]",3.1 Evidence identification,[0],[0]
"(1)
This coarse-grained approach makes use of merely the sentence-level representations while neglecting more fine-grained interactions between the sentences and the claim.
",3.1 Evidence identification,[0],[0]
Fine-grained representation,3.1 Evidence identification,[0],[0]
.,3.1 Evidence identification,[0],[0]
"Instead of directly employing the sentence-level representations, here we explore claim-aware representations for each word in sentence si, then compose them as the sentence representation ri, inspired by the Attentive Convolution (Yin and Schütze, 2017).
",3.1 Evidence identification,[0],[0]
"For each word sji in si, we first calculate its matching score towards each word xz in x, by dot product over their hidden states.",3.1 Evidence identification,[0],[0]
"Then the representation of the claim, as the context for the word sji , is formed as:
cji = ∑ z softmax(sji · (x z)T ) ·",3.1 Evidence identification,[0],[0]
"xz (2)
Now, word sji has left context s j−1 i , right context sj+1i in si, and the claim-aware context c j i from x.",3.1 Evidence identification,[0],[0]
"A convolution encoder generates its claim-aware representation iji :
iji = tanh(W ·",3.1 Evidence identification,[0],[0]
"[s j−1 i , s j i , s j+1 i , c j",3.1 Evidence identification,[0],[0]
"i ] + b) (3) where parameters W ∈ Rd×4d, b ∈ Rd.",3.1 Evidence identification,[0],[0]
"To compose those claim-aware word representations as the representation for sentence si, we use a max-pooling over {iji} along with j, generating ii.
",3.1 Evidence identification,[0],[0]
"We use term fint(si, x) to denote this whole process, so that:
ii = fint(si, x) (4)
",3.1 Evidence identification,[0],[0]
"At this point, the fine-grained representation for evidence candidate si is:
ri =",3.1 Evidence identification,[0],[0]
"[si,x, si · xT , ii] (5)
Loss function.",3.1 Evidence identification,[0],[0]
"With a claim-aware representation ri, the sentence si subsequently gets a probability, acting as the evidence, αi ∈ (0, 1) via a non-linear sigmoid function:
αi = sigmoid(v · rTi ) (6)
where parameter vector v has the same dimensionality as ri.
",3.1 Evidence identification,[0],[0]
"In the end, all evidence candidates in S have a ground-truth binary vector q and the predicted probability vector α; then loss lev (“ev”: evidence) is implemented as a binary cross-entropy:
lev =",3.1 Evidence identification,[0],[0]
m∑ i=1,3.1 Evidence identification,[0],[0]
−(qi log(αi)+(1−qi) log(1−αi)),3.1 Evidence identification,[0],[0]
"(7)
As the output of this evidence identification module, we binarize the probability vector α by pi =",3.1 Evidence identification,[0],[0]
[αi > 0.5] (“[x]” is 1 if x is true or 0 otherwise).,3.1 Evidence identification,[0],[0]
pi indicates si is evidence or not.,3.1 Evidence identification,[0],[0]
All {si} with pi = 1 act as evidence set Se.,3.1 Evidence identification,[0],[0]
"As shown in Figure 2, to figure out an entailment decision yi for the claim x, the evidence Se possibly consists of more than one sentence.",3.2 Claim verification,[0],[0]
"Furthermore, those evidence sentences are not necessarily in textual order nor from the same passage.",3.2 Claim verification,[0],[0]
"So, we need a mechanism that enables each evidence or even each word inside to be aware of the content from other evidence sentences.",3.2 Claim verification,[0],[0]
"Similar to the aforementioned approach to evidence identification, we come up with three methods, with different representation granularity, to learn a representation for (Se, x), i.e., the input for claim verification, shown in Figure 3.
Coarse-grained representation.",3.2 Claim verification,[0],[0]
"In this case, we treat Se as a whole, constructing its representation e by summing up the representations of all sentences in Se in a weighted way:
e =",3.2 Claim verification,[0],[0]
m∑ i=1,3.2 Claim verification,[0],[0]
"αi · pi · si (8)
where αi, from Equation 6, is the probability of si being the evidence.
",3.2 Claim verification,[0],[0]
"Then the (Se, x) pair gets a coarse-grained concatenated representation:",3.2 Claim verification,[0],[0]
"[e,x].",3.2 Claim verification,[0],[0]
It does not model the interactions within the evidence nor the interactions between the evidence and the claim.,3.2 Claim verification,[0],[0]
"Based on our experience in evidence identification
module, the representation of a sentence is better learned by composing context-aware word-level representations.",3.2 Claim verification,[0],[0]
"Next, we introduce how to learn fine-grained representation for the (Se, x) pair.
",3.2 Claim verification,[0],[0]
Single-channel fine-grained representation.,3.2 Claim verification,[0],[0]
"By “single-channel,” we mean each sentence si is aware of the claim x as its single context.
",3.2 Claim verification,[0],[0]
"For a single pair (si, x), we utilize the function fint() in Equation 4 to build the fine-grained representations for both si and x, obtaining ii =
fint(si, x) for si and xi = fint(x, si) for x.",3.2 Claim verification,[0],[0]
"For (Se, x), we compose all the {ii} and all the {xi} along with i, via a weighted max-pooling:
e = maxpooli(αi · pi · ii) (9) x = maxpooli(αi · pi · xi) (10)
",3.2 Claim verification,[0],[0]
This weighted max-pooling ensures that the sentences with higher probabilities of being evidence have a higher chance to present their features.,3.2 Claim verification,[0],[0]
"As a result, (Se, x) gets a concatenated representation:",3.2 Claim verification,[0],[0]
"[e, x]
Two-channel fine-grained representation.",3.2 Claim verification,[0],[0]
"By “two-channel,” we mean that each evidence si is aware of two kinds of context, one from the claim x, the other from the remaining evidences.
",3.2 Claim verification,[0],[0]
Our first step is to accumulate evidence clues within Se.,3.2 Claim verification,[0],[0]
"To start, we concatenate all sentences in Se as a fake long sentence Ŝ consisting of hidden states {ŝ}.",3.2 Claim verification,[0],[0]
"Similar to Equation 2, for each word sji in sentence si, we accumulate all of its related clues (cji ) from Ŝ as follows:
cji = ∑ z softmax(sji · (ŝ z)T ) · ŝz (11)
",3.2 Claim verification,[0],[0]
"Then we update sji , the representation of word sji , by element-wise addition:
sji = s j i ⊕ c j",3.2 Claim verification,[0],[0]
"i (12)
",3.2 Claim verification,[0],[0]
This step enables the word sji to “see” all related clues from Se.,3.2 Claim verification,[0],[0]
The reason we add s j i and c j,3.2 Claim verification,[0],[0]
"i is motivated by a simple experience: Assume the claim “Lily lives in the biggest city in Canada”, and one sentence contains a clue “· · · Lily lives in Toronto · · · ” and another sentence contains a clue “· · · Toronto is Canada’s largest city· · · ”.",3.2 Claim verification,[0],[0]
"The most simple yet effective approach to aggregating the two clues is to sum up their representation vectors (Blacoe and Lapata, 2012) (we do not concatenate them, as those clues have no consistent textual order across different sji ).
",3.2 Claim verification,[0],[0]
"After updating the representation of each word in si, we perform the aforementioned “singlechannel fine-grained representation” between the updated si and the claim x, generating [e, x].
",3.2 Claim verification,[0],[0]
Loss function.,3.2 Claim verification,[0],[0]
"For the claim verification input (Se, x), we forward its representation",3.2 Claim verification,[0],[0]
"[e, x] to a
logistic regression layer in order to infer a probability distribution o over the label space Y :
o = softmax(W ·",3.2 Claim verification,[0],[0]
"[e,x] + b) (13)
where W ∈ Rn×2d, b ∈",3.2 Claim verification,[0],[0]
Rn,3.2 Claim verification,[0],[0]
"The loss lcv (“cv”: claim verification) is implemented as negative log-likelihood:
lcv = − log(o · zT )",3.2 Claim verification,[0],[0]
"(14)
where z is the ground truth one-hot label vector for the claim x on the space Y .",3.2 Claim verification,[0],[0]
"Given the loss lev in evidence identification and the loss lcv in claim verification, the overall training loss is represented by:
l = lev + lcv (15)
",3.3 Joint optimization,[0],[0]
"To ensure that we jointly train the two coupled subtasks with intensive knowledge communication instead of simply putting two pipeline neural networks together, our TWOWINGOS has following configurations: • Both subsystems share the same set of word embeddings as parameters; the vanilla CNNs for learning sentence and claim representations share parameters as well.",3.3 Joint optimization,[0],[0]
•,3.3 Joint optimization,[0],[0]
"The output binary vector p by the evidence identification module is forwarded to the module of claim verification, as shown in Equations 8-10.",3.3 Joint optimization,[0],[0]
•,3.3 Joint optimization,[0],[0]
"Though the representation of a claim’s decision yi is not put explicitly into the module of evidence identification, the claim’s representation x will be fine-tuned by the yi, so that the evidence candidates can get adjustment from the decision yi, since the claims are shared by two modules.",3.3 Joint optimization,[0],[0]
Dataset.,4.1 Setup,[0],[0]
"In this work, we use FEVER (Thorne et al., 2018).",4.1 Setup,[0],[0]
"The claims in FEVER were generated from the introductory parts of about 50K
Wikipedia pages of a June 2017 dump.",4.1 Setup,[0],[0]
Annotators construct claims about a single fact of the title entity with arbitrarily complex expressions and entity forms.,4.1 Setup,[0],[0]
"To increase the claim complexity so that claims would not be trivially verified, annotators adopt two routes: (i) Providing additional knowledge: Annotators can explore a dictionary of terms that were (hyper-)linked, along with their pages; (ii) Mutate claims in six ways: negation, paraphrasing, substitution of a relation/entity with a similar/dissimilar one, and making the claims more general/specific.",4.1 Setup,[0],[0]
All resulting claims have 9.4 tokens in average.,4.1 Setup,[0],[0]
"Apart from claims, FEVER also provides a Wikipedia corpus in size of about 5.4 million.
",4.1 Setup,[0],[0]
"Each claim is labeled as SUPPORTED, REFUTED or NOTENOUGHINFO (NEI).",4.1 Setup,[0],[0]
"In addition, evidence sentences, from any wiki page, are required to be provided for SUPPORTED and REFUTED.",4.1 Setup,[0],[0]
Table 1 lists the data statistics.,4.1 Setup,[0],[0]
Figure 4 shows the distributions of sentence sizes and page sizes in FEVER’s evidence set.,4.1 Setup,[0],[0]
"We can see that roughly 28% of the evidence covers more than one sentence, and approximately 16.3% of the evidence covers more than one wiki page.
",4.1 Setup,[0],[0]
"This task has three evaluations: (i) NOSCOREEV – accuracy of claim verification, neglecting the validity of evidence; (ii) SCOREEV – accuracy of claim verification with a requirement that the predicted evidence fully covers the gold evidence for SUPPORTED and REFUTED; (iii) F1 – between the predicted evidence sentences and the ones chosen by annotators.",4.1 Setup,[0],[0]
"We use the officially released evaluation scorer 3.
",4.1 Setup,[0],[0]
"3https://github.com/sheffieldnlp/fever-scorer
Wiki page retrieval4.",4.1 Setup,[0],[0]
"For each claim, we search in the given dictionary of wiki pages in the form of {title: sentence list}, and keep the top-5 ranked pages for fair comparison with Thorne et al. (2018).",4.1 Setup,[0],[0]
Algorithm 1 briefly shows the steps of wiki page retrieval.,4.1 Setup,[0],[0]
"To speed up, we first build an inverted index from words to titles, then for each claim, we only search in the titles that cover at least one claim word.
",4.1 Setup,[0],[0]
"Input: A claim, wiki={title: page vocab} Output: A ranked top-k wiki titles Generate entity mentions from the claim; while each title do
if claim.vocab∩title.vocab is empty then discard this title else title score = the max recall value of title.vocab
in claim and in entity mentions of the claim; if title score = 1.0 then
title.score = title score else
page score = recall of claim in page vocab;
title.score = title score + page score end
end end Sort titles by title.score in descending order
Algorithm 1: Algorithm description of wiki page retrieval for FEVER claims.
",4.1 Setup,[0],[0]
"All sentences of the top-5 retrieved wiki pages are kept as evidence candidates for claims in train, dev and test.",4.1 Setup,[0],[0]
"It is worth mentioning that this page retrieval step is a reasonable preprocessing which controls the complexity of evidence searching in real-world, such as the big space – 5.4 million – in this work.
",4.1 Setup,[0],[0]
Training setup.,4.1 Setup,[0],[0]
"All words are initialized by 300D Word2Vec (Mikolov et al., 2013) embeddings, and are fine-tuned during training.",4.1 Setup,[0],[0]
"The whole system is trained by AdaGrad (Duchi et al., 2011).",4.1 Setup,[0],[0]
"Other hyperparameter values include: learning rate 0.02, hidden size 300, mini-batch size 50, filter width 3.
Baselines.",4.1 Setup,[0],[0]
"In this work, we first consider the two systems reported by Thorne et al. (2018): (i) MLP: A multi-layer perceptron with one hidden layer, based on TF-IDF cosine similarity between the claim and the evidence (all evidence sentences are concatenated as a longer text piece) (Riedel et al., 2017); (ii) Decomp-Att (Parikh et al., 2016):",4.1 Setup,[0],[0]
"A decomposable attention model that develops atten-
4Our retrieval results are released as well.
tion mechanisms to decompose the problem into subproblems to solve in parallel.",4.1 Setup,[0],[0]
"Note that both systems first employed an IR system to keep top5 relevant sentences from the retrieved top-5 wiki pages as static evidence for claims.
",4.1 Setup,[0],[0]
"We further consider the following variants of our own system TWOWINGOS: • Coarse-coarse: Both evidence identification and claim verification adopt coarse-grained representations.
",4.1 Setup,[0],[0]
"To further study our system, we test this “coarse-coarse” in three setups: (i) “pipeline” – train the two modules independently.",4.1 Setup,[0],[0]
"Forward the predicted evidence to do entailment for claims; (ii) “diff-CNN” – joint training with separate CNN parameters to learn sentence/claim representations; (iii) “share-CNN” – joint training with shared CNN parameters.
",4.1 Setup,[0],[0]
The following variants are in joint training.,4.1 Setup,[0],[0]
"• Fine&sentence-wise: Given the evidence with multiple sentences, a natural baseline is to do entailment reasoning for each (sentence, claim), then compose.",4.1 Setup,[0],[0]
"We do entailment reasoning between each predicted evidence sentence and the claim, generating a probability distribution over the label space Y .",4.1 Setup,[0],[0]
"Then we sum up all the distribution vectors element-wise, as an ensemble system, to predict the label; • Four combinations of different grained representation learning: “coarse&fine(single)”, “coarse&fine(two)”, “fine&coarse” and “fine&fine(two)”.",4.1 Setup,[0],[0]
“Single” and “two” refer to the single/two-channel cases respectively.,4.1 Setup,[0],[0]
Performance of passage retrieval.,4.2 Results,[0],[0]
"Table 2 compares our wikipage retriever with the one in
(Thorne et al., 2018), which used a document retriever5 from DrQA (Chen et al., 2017).
",4.2 Results,[0],[0]
Our document retrieval module surpasses the competitor by a big margin in terms of the coverage of gold passages: 89.63% vs. 55.30% (k = 5 in all experiments).,4.2 Results,[0],[0]
Its powerfulness should be attributed to: (i) Entity mention detection in the claims.,4.2 Results,[0],[0]
"(ii) As wiki titles are entities, we have a bi-channel way to match the claim with the wiki page: one with the title, the other with the page body, as shown in Algorithm 1.
",4.2 Results,[0],[0]
Performance on FEVER Table 3 lists the performances of baselines and the TWOWINGOS variants on FEVER (dev&test).,4.2 Results,[0],[0]
"From the dev block, we observe that: • TWOWINGOS (from “share-CNN”) surpasses prior systems in big margins.",4.2 Results,[0],[0]
"Overall, fine-grained schemes in each subtask contribute more than the coarse-grained counterparts; • In the three setups – “pipeline”, “diff-CNN” and “share-CNN” – of coarse-coarse, “pipeline” gets better scores than (Thorne et al., 2018) in terms of evidence identification.",4.2 Results,[0],[0]
“Share-CNN” has comparable F1 as “diff-CNN” while gaining a lot on NOSCOREEV (72.32 vs. 39.22) and SCOREEV (50.12 vs. 21.04).,4.2 Results,[0],[0]
This clearly shows that the claim verification gains much knowledge transferred from the evidence identification module.,4.2 Results,[0],[0]
Both “diff-CNN” and “share-CNN” perform better than “pipeline” (except for the slight inferiority at SCOREEV: 21.04 vs. 22.26).,4.2 Results,[0],[0]
"• Two-channel fine-grained representations show more effective than the single-channel counterpart in claim verification (NOSCOREEV: 78.77 vs. 75.65, SCOREEV: 53.64 vs. 52.65).",4.2 Results,[0],[0]
"As we expected, evidence sentences should collaborate in inferring the truth value of the claims.",4.2 Results,[0],[0]
Two-channel setup enables an evidence candidate aware of other candidates as well as the claim.,4.2 Results,[0],[0]
"• In the last three rows of dev, there is no clear difference among their evidence identification scores.",4.2 Results,[0],[0]
"Recall that “sent-wise” is essentially an ensemble system over each (sentence, claim) entailment result.",4.2 Results,[0],[0]
"“Coarse-grained”, instead, first sums up all sentence representation, then performs ( ∑
(sentence), claim) reasoning.",4.2 Results,[0],[0]
We can also treat this “sum up” as an ensemble.,4.2 Results,[0],[0]
"Their comparison shows that these two kinds of tricks do not
5It compares passages and claims as TF-IDF weighted bag-of-bigrams.
make much difference.",4.2 Results,[0],[0]
"If we adopt “two-channel fine-grained representation” in claim verification, big improvements are observed in both NOSCOREEV (+7.42%) and SCOREEV (+3%).
",4.2 Results,[0],[0]
"In the test block, our system (fine&fine(two)) beats the prior top system across all measurements by big margins – F1: 47.15 vs. 17.47; SCOREEV: 54.33 vs. 31.87; NOSCOREEV: 75.99 vs. 50.91.
",4.2 Results,[0],[0]
"In both dev and test blocks, we can observe that our evidence identification module consistently
obtains balanced recall and precision.",4.2 Results,[0],[0]
"In contrast, the pipeline system by Thorne et al. (2018) has much higher recall than precision (45.89 vs. 10.79).",4.2 Results,[0],[0]
"It is worth mentioning that the SCOREEV metric is highly influenced by the recall value, since SCOREEV is computed on the claim instances whose evidences are fully retrieved, regardless of the precision.",4.2 Results,[0],[0]
"So, ideally, a system can set all sentences as evidence, so that SCOREEV can be promoted to be equal to NOSCOREEV.",4.2 Results,[0],[0]
"Our system is more reliable in this perspective.
",4.2 Results,[0],[0]
Performance vs. #sent.,4.2 Results,[0],[0]
in evidence.,4.2 Results,[0],[0]
Figure 5 shows the results of the five evaluation measures against different sizes of gold evidence sentences in test set.,4.2 Results,[0],[0]
We observe that: (i),4.2 Results,[0],[0]
"Our system has robust precisions across #sentence; however, the recall decreases.",4.2 Results,[0],[0]
"This is not that surprising, since the more ground-truth sentences in evidence, the harder it is to retrieve all of them; (ii) Due to the decrease in recall, the SCOREEV also gets influenced for bigger #sentence.",4.2 Results,[0],[0]
"Interestingly, high precision and worse recall in evidence with more sentences still make consistently strong overall performance, i.e., NOSCOREEV.",4.2 Results,[0],[0]
"This should be due to the fact that the majority (83.18% (Thorne et al., 2018)) of claims can be correctly entailed by a single ground truth sentence, even if any remaining ground truth sentences are unavailable.
",4.2 Results,[0],[0]
Error analysis.,4.2 Results,[0],[0]
"The case #1 in Table 4 shows that our system identifies two pieces of evidence
(i.e., (Telemundo, 0) and (Telemundo, 4)) correctly; however, it falsely predicts the claim label.",4.2 Results,[0],[0]
"(Telemundo, 0): Telemundo is an American Spanish-language terrestrial television · · · .",4.2 Results,[0],[0]
We can easily find that the keyword “Spanishlanguage” should refute the claim.,4.2 Results,[0],[0]
"However, both “Spanish-language” in this evidence and the “English-language” in the claim are unknown tokens with randomly initialized embeddings.",4.2 Results,[0],[0]
This hints that a more careful data preprocessing may be helpful.,4.2 Results,[0],[0]
"In addition, to refute the claim, another clue comes from the combination of (Telemundo, 4) and (Hispanic and Latino Americans, 0).",4.2 Results,[0],[0]
"(Telemundo, 4): “The channel · · · aimed at Hispanic and Latino American audiences”; (Hispanic and Latino Americans, 0): “Hispanic Americans and Latino Americans · · · are descendants of people from countries of Latin America and Spain.”.",4.2 Results,[0],[0]
"Our system only retrieved (Telemundo, 4).",4.2 Results,[0],[0]
"And this clue is hard to grasp as it requires some background knowledge – people from Latin America and Spain usually are not treated as English-speaking.
",4.2 Results,[0],[0]
"In the case #2, our system fails to identify any evidence.",4.2 Results,[0],[0]
"This is due to the failure of our passage retrieval module: it detects entity mentions “Home”, “Holidays” and “American”, and the top-5 retrieved passages are “Home”, “Home for the Holidays”, “American Home”, “American” and “Home for the Holidays (song)”, which unfortunately cover none of the four ground truth passages.",4.2 Results,[0],[0]
"Interestingly, (i) given the falsely retrieved passages, our system predicts “no sentence is valid evidence” (denoted as ∅ in Table 4); (ii) given the empty evidence, our system predicts “NoEnoughInfo” for this claim.",4.2 Results,[0],[0]
"Both make sense.
",4.2 Results,[0],[0]
"In the case #3, a successful classification of the
claim requires information aggregation over the three gold evidence sentences: (Weekly Idol, 0): “Weekly Idol is a South Korean variety show · · · ”; (Weekly Idol, 1): “The show is hosted by comedian Jeong Hyeong-don and rapper Defconn.”; (Defconn, 0): “Defconn (born Yoo Dae-joon; January 6 , 1977 ) is a · · · ”.",4.2 Results,[0],[0]
To successfully retrieve the three sentences as a whole set of evidence is challenging in evidence identification.,4.2 Results,[0],[0]
"Additionally, this example relies on the recognition and matching of digital numbers (1983 vs. 1977), which is beyond the expressivity of word embeddings, and is expected to be handled by rules more easily.",4.2 Results,[0],[0]
"In this work, we build TWOWINGOS, a two-wing optimization framework to address the claim verification problem by presenting precise evidence.",5 Summary,[0],[0]
"Differing from a pipeline system, TWOWINGOS ensures the evidence identification module and the claim verification module are trained jointly, in an end-to-end scheme.",5 Summary,[0],[0]
Experiments show the superiority of TWOWINGOS in the FEVER benchmark.,5 Summary,[0],[0]
We thank group colleagues (Nitish Gupta and Jennifer Sheffield) and Dr. Mo Yu from IBM AI Foundations Lab for providing insightful comments and critiques.,Acknowledgments,[0],[0]
This work was supported by Contract HR0011-15-2-0025 with the US Defense Advanced Research Projects Agency (DARPA).,Acknowledgments,[0],[0]
"Approved for Public Release, Distribution Unlimited.",Acknowledgments,[0],[0]
The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government.,Acknowledgments,[0],[0]
Determining whether a given claim is supported by evidence is a fundamental NLP problem that is best modeled as Textual Entailment.,abstractText,[0],[0]
"However, given a large collection of text, finding evidence that could support or refute a given claim is a challenge in itself, amplified by the fact that different evidence might be needed to support or refute a claim.",abstractText,[0],[0]
"Nevertheless, most prior work decouples evidence identification from determining the truth value of the claim given the evidence.",abstractText,[0],[0]
We propose to consider these two aspects jointly.,abstractText,[0],[0]
"We develop TWOWINGOS (twowing optimization strategy), a system that, while identifying appropriate evidence for a claim, also determines whether or not the claim is supported by the evidence.",abstractText,[0],[0]
"Given the claim, TWOWINGOS attempts to identify a subset of the evidence candidates; given the predicted evidence, it then attempts to determine the truth value of the corresponding claim.",abstractText,[0],[0]
"We treat this challenge as coupled optimization problems, training a joint model for it.",abstractText,[0],[0]
"TWOWINGOS offers two advantages: (i) Unlike pipeline systems, it facilitates flexible-size evidence set, and (ii) Joint training improves both the claim verification and the evidence identification.",abstractText,[0],[0]
Experiments on a benchmark dataset show state-of-the-art performance.1,abstractText,[0],[0]
TWOWINGOS: A Two-Wing Optimization Strategy for Evidential Claim Verification,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 87–96 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
87",text,[0],[0]
Entities can often be described by very fine grained types.,1 Introduction,[0],[0]
Consider the sentences “Bill robbed John.,1 Introduction,[0],[0]
He was arrested.”,1 Introduction,[0],[0]
"The noun phrases “John,” “Bill,” and “he” have very specific types that can be inferred from the text.",1 Introduction,[0],[0]
"This includes the facts that “Bill” and “he” are both likely “criminal” due to the “robbing” and “arresting,” while “John” is more likely a “victim” because he was “robbed.”",1 Introduction,[0],[0]
"Such fine-grained types (victim, criminal) are important for context-sensitive tasks such
1Our data and model can be downloaded from: http://nlp.cs.washington.edu/entity_type
as coreference resolution and question answering (e.g. “Who was the victim?”).",1 Introduction,[0],[0]
"Inferring such types for each mention (John, he) is not possible given current typing models that only predict relatively coarse types and only consider named entities.
",1 Introduction,[0],[0]
"To address this challenge, we present a new task: given a sentence with a target entity mention, predict free-form noun phrases that describe appropriate types for the role the target entity plays in the sentence.",1 Introduction,[0],[0]
Table 1 shows three examples that exhibit a rich variety of types at different granularities.,1 Introduction,[0],[0]
"Our task effectively subsumes existing finegrained named entity typing formulations due to the use of a very large type vocabulary and the fact that we predict types for all noun phrases, including named entities, nominals, and pronouns.
",1 Introduction,[0],[0]
"Incorporating fine-grained entity types has improved entity-focused downstream tasks, such as relation extraction (Yaghoobzadeh et al., 2017a), question answering (Yavuz et al., 2016),",1 Introduction,[0],[0]
"query analysis (Balog and Neumayer, 2012), and coreference resolution (Durrett and Klein, 2014).",1 Introduction,[0],[0]
These systems used a relatively coarse type ontology.,1 Introduction,[0],[0]
"However, manually designing the ontology is a challenging task, and it is difficult to cover all pos-
12/14/2017 https://homes.cs.washington.edu/~eunsol/finetype_visualization/onto_index.html
https://homes.cs.washington.edu/~eunsol/finetype_visualization/onto_index.html 1/1
sible concepts even within a limited domain.",1 Introduction,[0],[0]
"This can be seen empirically in existing datasets, where the label distribution of fine-grained entity typing datasets is heavily skewed toward coarse-grained types.",1 Introduction,[0],[0]
"For instance, annotators of the OntoNotes dataset (Gillick et al., 2014) marked about half of the mentions as “other,” because they could not find a suitable type in their ontology (see Figure 1 for a visualization and Section 2.2 for details).
",1 Introduction,[0],[0]
"Our more open, ultra-fine vocabulary, where types are free-form noun phrases, alleviates the need for hand-crafted ontologies, thereby greatly increasing overall type coverage.",1 Introduction,[0],[0]
"To better understand entity types in an unrestricted setting, we crowdsource a new dataset of 6,000 examples.",1 Introduction,[0],[0]
"Compared to previous fine-grained entity typing datasets, the label distribution in our data is substantially more diverse and fine-grained.",1 Introduction,[0],[0]
Annotators easily generate a wide range of types and can determine with 85% agreement if a type generated by another annotator is appropriate.,1 Introduction,[0],[0]
"Our evaluation data has over 2,500 unique types, posing a challenging learning problem.
",1 Introduction,[0],[0]
"While our types are harder to predict, they also allow for a new form of contextual distant supervision.",1 Introduction,[0],[0]
"We observe that text often contains cues that explicitly match a mention to its type, in the form of the mention’s head word.",1 Introduction,[0],[0]
"For example, “the incumbent chairman of the African Union” is a type of “chairman.”",1 Introduction,[0],[0]
"This signal complements the supervision derived from linking entities to knowledge bases, which is context-oblivious.",1 Introduction,[0],[0]
"For example, “Clint Eastwood” can be described
with dozens of types, but context-sensitive typing would prefer “director” instead of “mayor” for the sentence “Clint Eastwood won ‘Best Director’ for Million Dollar Baby.”
",1 Introduction,[0],[0]
"We combine head-word supervision, which provides ultra-fine type labels, with traditional signals from entity linking.",1 Introduction,[0],[0]
"Although the problem is more challenging at finer granularity, we find that mixing fine and coarse-grained supervision helps significantly, and that our proposed model with a multitask objective exceeds the performance of existing entity typing models.",1 Introduction,[0],[0]
"Lastly, we show that head-word supervision can be used for previous formulations of entity typing, setting the new state-of-the-art performance on an existing finegrained NER benchmark.",1 Introduction,[0],[0]
"Given a sentence and an entity mention e within it, the task is to predict a set of natural-language phrases T that describe the type of e. The selection of T is context sensitive; for example, in “Bill Gates has donated billions to eradicate malaria,” Bill Gates should be typed as “philanthropist” and not “inventor.”",2 Task and Data,[0],[0]
"This distinction is important for context-sensitive tasks such as coreference resolution and question answering (e.g. “Which philanthropist is trying to prevent malaria?”).
",2 Task and Data,[0],[0]
"We annotate a dataset of about 6,000 mentions via crowdsourcing (Section 2.1), and demonstrate that using an large type vocabulary substantially increases annotation coverage and diversity over existing approaches (Section 2.2).",2 Task and Data,[0],[0]
"To capture multiple domains, we sample sentences from Gigaword (Parker et al., 2011), OntoNotes (Hovy et al., 2006), and web articles (Singh et al., 2012).",2.1 Crowdsourcing Entity Types,[0],[0]
"We select entity mentions by taking maximal noun phrases from a constituency parser (Manning et al., 2014) and mentions from a coreference resolution system (Lee et al., 2017).
",2.1 Crowdsourcing Entity Types,[0],[0]
"We provide the sentence and the target entity mention to five crowd workers on Mechanical Turk, and ask them to annotate the entity’s type.",2.1 Crowdsourcing Entity Types,[0],[0]
"To encourage annotators to generate fine-grained types, we require at least one general type (e.g. person, organization, location) and two specific types (e.g. doctor, fish, religious institute), from a type vocabulary of about 10K frequent noun phrases.",2.1 Crowdsourcing Entity Types,[0],[0]
"We use WordNet (Miller, 1995) to expand these types automatically by generating all their synonyms and hypernyms based on the most common sense, and ask five different annotators to validate the generated types.",2.1 Crowdsourcing Entity Types,[0],[0]
Each pair of annotators agreed on 85% of the binary validation decisions (i.e. whether a type is suitable or not) and 0.47 in Fleiss’s κ.,2.1 Crowdsourcing Entity Types,[0],[0]
"To further improve consistency, the final type set contained only types selected by at least 3/5 annotators.",2.1 Crowdsourcing Entity Types,[0],[0]
"Further crowdsourcing details are available in the supplementary material.
",2.1 Crowdsourcing Entity Types,[0],[0]
Our collection process focuses on precision.,2.1 Crowdsourcing Entity Types,[0],[0]
"Thus, the final set is diverse but not comprehensive, making evaluation non-trivial (see Section 5).",2.1 Crowdsourcing Entity Types,[0],[0]
"We collected about 6,000 examples.",2.2 Data Analysis,[0],[0]
"For analysis, we classified each type into three disjoint bins: • 9 general types: person, location, object, orga-
nization, place, entity, object, time, event • 121 fine-grained types, mapped to fine-grained
entity labels from prior work (Ling and Weld, 2012; Gillick et al., 2014) (e.g. film, athlete) • 10,201 ultra-fine types, encompassing every
other label in the type space (e.g. detective, lawsuit, temple, weapon, composer)
",2.2 Data Analysis,[0],[0]
"On average, each example has 5 labels: 0.9 general, 0.6 fine-grained, and 3.9 ultra-fine types.",2.2 Data Analysis,[0],[0]
"Among the 10,000 ultra-fine types, 2,300 unique types were actually found in the 6,000 crowdsourced examples.",2.2 Data Analysis,[0],[0]
"Nevertheless, our distant supervision data (Section 3) provides positive training examples for every type in the entire vocabulary, and our model (Section 4) can and does predict from a 10K type vocabulary.",2.2 Data Analysis,[0],[0]
"For example,
the model correctly predicts “television network” and “archipelago” for some mentions, even though that type never appears in the 6,000 crowdsourced examples.
",2.2 Data Analysis,[0],[0]
Improving Type Coverage,2.2 Data Analysis,[0],[0]
We observe that prior fine-grained entity typing datasets are heavily focused on coarse-grained types.,2.2 Data Analysis,[0],[0]
"To quantify our observation, we calculate the distribution of types in FIGER (Ling and Weld, 2012), OntoNotes (Gillick et al., 2014), and our data.",2.2 Data Analysis,[0],[0]
"For examples with multiple types (|T | > 1), we counted each type 1/|T | times.
",2.2 Data Analysis,[0],[0]
Figure 2 shows the percentage of labels covered by the top N labels in each dataset.,2.2 Data Analysis,[0],[0]
"In previous enitity typing datasets, the distribution of labels is highly skewed towards the top few labels.",2.2 Data Analysis,[0],[0]
"To cover 80% of the examples, FIGER requires only the top 7 types, while OntoNotes needs only 4; our dataset requires 429 different types.
",2.2 Data Analysis,[0],[0]
"Figure 1 takes a deeper look by visualizing the types that cover 90% of the data, demonstrating the diversity of our dataset.",2.2 Data Analysis,[0],[0]
"It is also striking that more than half of the examples in OntoNotes are classified as “other,” perhaps because of the limitation of its predefined ontology.
",2.2 Data Analysis,[0],[0]
"Improving Mention Coverage Existing datasets focus mostly on named entity mentions, with the exception of OntoNotes, which contained nominal expressions.",2.2 Data Analysis,[0],[0]
"This has implications on the transferability of FIGER/OntoNotes-based models to tasks such as coreference resolution, which need to analyze all types of entity mentions (pronouns, nominal expressions, and named entity
mentions).",2.2 Data Analysis,[0],[0]
"Our new dataset provides a wellrounded benchmark with roughly 40% pronouns, 38% nominal expressions, and 22% named entity mentions.",2.2 Data Analysis,[0],[0]
"The case of pronouns is particularly interesting, since the mention itself provides little information.",2.2 Data Analysis,[0],[0]
Training data for fine-grained NER systems is typically obtained by linking entity mentions and drawing their types from knowledge bases (KBs).,3 Distant Supervision,[0],[0]
"This approach has two limitations: recall can suffer due to KB incompleteness (West et al., 2014), and precision can suffer when the selected types do not fit the context (Ritter et al., 2011).",3 Distant Supervision,[0],[0]
"We alleviate the recall problem by mining entity mentions that were linked to Wikipedia in HTML, and extract relevant types from their encyclopedic definitions (Section 3.1).",3 Distant Supervision,[0],[0]
"To address the precision issue (context-insensitive labeling), we propose a new source of distant supervision: automatically extracted nominal head words from raw text (Section 3.2).",3 Distant Supervision,[0],[0]
Using head words as a form of distant supervision provides fine-grained information about named entities and nominal mentions.,3 Distant Supervision,[0],[0]
"While a KB may link “the 44th president of the United States” to many types such as author, lawyer, and professor, head words provide only the type “president”, which is relevant in the context.
",3 Distant Supervision,[0],[0]
We experiment with the new distant supervision sources as well as the traditional KB supervision.,3 Distant Supervision,[0],[0]
Table 2 shows examples and statistics for each source of supervision.,3 Distant Supervision,[0],[0]
We annotate 100 examples from each source to estimate the noise and usefulness in each signal (precision in Table 2).,3 Distant Supervision,[0],[0]
"For KB supervision, we leveraged training data from prior work (Ling and Weld, 2012; Gillick et al., 2014) by manually mapping their ontology to our 10,000 noun type vocabulary, which covers 130 of our labels (general and fine-grained).2 Section 6 defines this mapping in more detail.
",3.1 Entity Linking,[0],[0]
"To improve both entity and type coverage of KB supervision, we use definitions from Wikipedia.",3.1 Entity Linking,[0],[0]
"We follow Shnarch et al. () who observed that the first sentence of a Wikipedia article often states the entity’s type via an “is a” relation; for example, “Roger Federer is a Swiss professional tennis player.”",3.1 Entity Linking,[0],[0]
"Since we are using a large type vocabulary, we can now mine this typing information.3",3.1 Entity Linking,[0],[0]
"We extracted descriptions for 3.1M entities which contain 4,600 unique type labels such as “competition,” “movement,” and “village.”
",3.1 Entity Linking,[0],[0]
"We bypass the challenge of automatically linking entities to Wikipedia by exploiting existing hyperlinks in web pages (Singh et al., 2012), following prior work (Ling and Weld, 2012; Yosef et al., 2012).",3.1 Entity Linking,[0],[0]
"Since our heuristic extraction of types from the definition sentence is somewhat noisy, we use a more conservative entity linking policy4 that yields a signal with similar overall accuracy to KB-linked data.
2Data from: https://github.com/ shimaokasonse/NFGEC
3We extract types by applying a dependency parser (Manning et al., 2014) to the definition sentence, and taking nouns that are dependents of a copular edge or connected to nouns linked to copulars via appositive or conjunctive edges.
",3.1 Entity Linking,[0],[0]
4Only link if the mention contains the Wikipedia entity’s name and the entity’s name contains the mention’s head.,3.1 Entity Linking,[0],[0]
Many nominal entity mentions include detailed type information within the mention itself.,3.2 Contextualized Supervision,[0],[0]
"For example, when describing Titan V as “the newlyreleased graphics card”, the head words and phrases of this mention (“graphics card” and “card”) provide a somewhat noisy, but very easy to gather, context-sensitive type signal.
",3.2 Contextualized Supervision,[0],[0]
"We extract nominal head words with a dependency parser (Manning et al., 2014) from the Gigaword corpus as well as the Wikilink dataset.",3.2 Contextualized Supervision,[0],[0]
"To support multiword expressions, we included nouns that appear next to the head if they form a phrase in our type vocabulary.",3.2 Contextualized Supervision,[0],[0]
"Finally, we lowercase all words and convert plural to singular.
",3.2 Contextualized Supervision,[0],[0]
Our analysis reveals that this signal has a comparable accuracy to the types extracted from entity linking (around 80%).,3.2 Contextualized Supervision,[0],[0]
"Many errors are from the parser, and some errors stem from idioms and transparent heads (e.g. “parts of capital” labeled as “part”).",3.2 Contextualized Supervision,[0],[0]
"While the headword is given as an input to the model, with heavy regularization and multitasking with other supervision sources, this supervision helps encode the context.",3.2 Contextualized Supervision,[0],[0]
We design a model for predicting sets of types given a mention in context.,4 Model,[0],[0]
"The architecture resembles the recent neural AttentiveNER model (Shimaoka et al., 2017), while improving the sentence and mention representations, and introducing a new multitask objective to handle multiple sources of supervision.",4 Model,[0],[0]
"The hyperparameter settings are listed in the supplementary material.
",4 Model,[0],[0]
"Context Representation Given a sentence x1, . .",4 Model,[0],[0]
.,4 Model,[0],[0]
", xn, we represent each token xi using a pre-trained word embedding wi.",4 Model,[0],[0]
"We concatenate an additional location embedding li which indicates whether xi is before, inside, or after the mention.",4 Model,[0],[0]
"We then use [xi; li] as an input to a bidirectional LSTM, producing a contextualized representation hi for each token; this is different from the architecture of Shimaoka et al. 2017, who used two separate bidirectional LSTMs on each side of the mention.",4 Model,[0],[0]
"Finally, we represent the context c as a weighted sum of the contextualized token representations using MLP-based attention:
ai = SoftMaxi(va · relu(Wahi))
",4 Model,[0],[0]
"Where Wa and va are the parameters of the attention mechanism’s MLP, which allows interaction
between the forward and backward directions of the LSTM before computing the weight factors.
",4 Model,[0],[0]
"Mention Representation We represent the mention m as the concatenation of two items: (a) a character-based representation produced by a CNN on the entire mention span, and (b) a weighted sum of the pre-trained word embeddings in the mention span computed by attention, similar to the mention representation in a recent coreference resolution model (Lee et al., 2017).",4 Model,[0],[0]
The final representation is the concatenation of the context and mention representations: r =,4 Model,[0],[0]
"[c;m].
Label Prediction",4 Model,[0],[0]
We learn a type label embedding matrix Wt ∈ Rn×d where n is the number of labels in the prediction space and d is the dimension of r.,4 Model,[0],[0]
"This matrix can be seen as a combination of three sub matrices, Wgeneral,Wfine,Wultra, each of which contains the representations of the general, fine, and ultra-fine types respectively.",4 Model,[0],[0]
We predict each type’s probability via the sigmoid of its inner product with r: y = σ(Wtr).,4 Model,[0],[0]
"We predict every type t for which yt > 0.5, or argmax yt if there is no such type.
",4 Model,[0],[0]
"Multitask Objective The distant supervision sources provide partial supervision for ultra-fine types; KBs often provide more general types, while head words usually provide only ultra-fine types, without their generalizations.",4 Model,[0],[0]
"In other words, the absence of a type at a different level of abstraction does not imply a negative signal; e.g. when the head word is “inventor”, the model should not be discouraged to predict “person”.
",4 Model,[0],[0]
"Prior work used a customized hinge loss (Abhishek et al., 2017) or max margin loss (Ren et al., 2016a) to improve robustness to noisy or incomplete supervision.",4 Model,[0],[0]
We propose a multitask objective that reflects the characteristic of our training dataset.,4 Model,[0],[0]
"Instead of updating all labels for each example, we divide labels into three bins (general, fine, and ultra-fine), and update labels only in bin containing at least one positive label.",4 Model,[0],[0]
"Specifically, the training objective is to minimize J where t is the target vector at each granularity:
Jall = Jgeneral · 1general(t)",4 Model,[0],[0]
"+ Jfine · 1fine(t) + Jultra · 1ultra(t)
Where 1category(t) is an indicator function that checks if t contains a type in the category, and
Jcategory is the category-specific logistic regression objective:
J =",4 Model,[0],[0]
− ∑ i ti · log(yi) + (1− ti) · log(1− yi),4 Model,[0],[0]
"Experiment Setup The crowdsourced dataset (Section 2.1) was randomly split into train, development, and test sets, each with about 2,000 examples.",5 Evaluation,[0],[0]
We use this relatively small manuallyannotated training set (Crowd in Table 4) alongside the two distant supervision sources: entity linking (KB and Wikipedia definitions) and head words.,5 Evaluation,[0],[0]
"To combine supervision sources of different magnitudes (2K crowdsourced data, 4.7M entity linking data, and 20M head words), we sample a batch of equal size from each source at each iteration.",5 Evaluation,[0],[0]
"We reimplement the recent AttentiveNER model (Shimaoka et al., 2017) for reference.5
We report macro-averaged precision, recall, and F1, and the average mean reciprocal rank (MRR).
",5 Evaluation,[0],[0]
Results Table 3 shows the performance of our model and our reimplementation of AttentiveNER.,5 Evaluation,[0],[0]
"Our model, which uses a multitask objective to learn finer types without punishing more general types, shows recall gains at the cost of drop in precision.",5 Evaluation,[0],[0]
"The MRR score shows that our
5We use the AttentiveNER model with no engineered features or hierarchical label encoding (as a hierarchy is not clear in our label setting) and let it predict from the same label space, training with the same supervision data.
model is slightly better than the baseline at ranking correct types above incorrect ones.
",5 Evaluation,[0],[0]
Table 4 shows the performance breakdown for different type granularity and different supervision.,5 Evaluation,[0],[0]
"Overall, as seen in previous work on finegrained NER literature (Gillick et al., 2014; Ren et al., 2016a), finer labels were more challenging to predict than coarse grained labels, and this issue is exacerbated when dealing with ultra-fine types.",5 Evaluation,[0],[0]
"All sources of supervision appear to be useful, with crowdsourced examples making the biggest impact.",5 Evaluation,[0],[0]
"Head word supervision is particularly helpful for predicting ultra-fine labels, while entity linking improves fine label prediction.",5 Evaluation,[0],[0]
"The low general type performance is partially because of nominal/pronoun mentions (e.g. “it”), and because of the large type inventory (sometimes “location” and “place” are annotated interchangeably).
",5 Evaluation,[0],[0]
"Analysis We manually analyzed 50 examples from the development set, four of which we present in Table 5.",5 Evaluation,[0],[0]
"Overall, the model was able to generate accurate general types and a diverse set of type labels.",5 Evaluation,[0],[0]
"Despite our efforts to annotate a comprehensive type set, the gold labels still miss many potentially correct labels (example (a): “man” is reasonable but counted as incorrect).",5 Evaluation,[0],[0]
"This makes the precision estimates lower than the actual performance level, with about half the precision errors belonging to this category.",5 Evaluation,[0],[0]
"Real precision errors include predicting co-hyponyms (example (b): “accident” instead of “attack”), and types that
may be true, but are not supported by the context.",5 Evaluation,[0],[0]
We found that the model often abstained from predicting any fine-grained types.,5 Evaluation,[0],[0]
"Especially in challenging cases as in example (c), the model predicts only general types, explaining the low recall numbers (28% of examples belong to this category).",5 Evaluation,[0],[0]
"Even when the model generated correct fine-grained types as in example (d), the recall was often fairly low since it did not generate a complete set of related fine-grained labels.
",5 Evaluation,[0],[0]
Estimating the performance of a model in an incomplete label setting and expanding label coverage are interesting areas for future work.,5 Evaluation,[0],[0]
"Our task also poses a potential modeling challenge; sometimes, the model predicts two incongruous types (e.g. “location” and “person”), which points towards modeling the task as a joint set prediction task, rather than predicting labels individually.",5 Evaluation,[0],[0]
We provide sample outputs on the project website.,5 Evaluation,[0],[0]
We show that our model and distant supervision can improve performance on an existing finegrained NER task.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"We chose the widely-used OntoNotes (Gillick et al., 2014) dataset which includes nominal and named entity mentions.6
6While we were inspired by FIGER (Ling and Weld, 2012), the dataset presents technical difficulties.",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"The test set has only 600 examples, and the development set was labeled with distant supervision, not manual annotation.",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"We therefore focus our evaluation on OntoNotes.
",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
Augmenting the Training Data,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
The original OntoNotes training set (ONTO in Tables 6 and 7) is extracted by linking entities to a KB.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
We supplement this dataset with our two new sources of distant supervision: Wikipedia definition sentences (WIKI) and head word supervision (HEAD) (see Section 3).,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"To convert the label space, we manually map a single noun from our natural-language vocabulary to each formal-language type in the OntoNotes ontology.",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"77% of OntoNote’s types directly correspond to suitable noun labels (e.g. “doctor” to “/person/doctor”), whereas the other cases were mapped with minimal manual effort (e.g. “musician” to “person/artist/music”, “politician” to “/person/political figure”).",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
We then expand these labels according to the ontology to include their hypernyms (“/person/political figure” will also generate “/person”).,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Lastly, we create negative examples by assigning the “/other” label to examples that are not mapped to the ontology.",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"The augmented dataset contains 2.5M/0.6M new positive/negative examples, of which 0.9M/0.1M are from Wikipedia definition sentences and 1.6M/0.5M from head words.
",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Experiment Setup We compare performance to other published results and to our reimplementation of AttentiveNER (Shimaoka et al., 2017).",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
We also compare models trained with different sources of supervision.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"For this dataset, we did not use our multitask objective (Section 4), since expanding types to include their ontological hypernyms largely eliminates the partial supervision as-
sumption.",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Following prior work, we report macroand micro-averaged F1 score, as well as accuracy (exact set match).
",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
Results Table 6 shows the overall performance on the test set.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Our combination of model and training data shows a clear improvement from prior work, setting a new state-of-the art result.7
In Table 7, we show an ablation study.",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
Our new supervision sources improve the performance of both the AttentiveNER model and our own.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
We observe that every supervision source improves performance in its own right.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Particularly, the naturally-occurring head-word supervision seems to be the prime source of improvement, increasing performance by about 10% across all metrics.
",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Predicting Miscellaneous Types While analyzing the data, we observed that over half of the mentions in OntoNotes’ development set were annotated only with the miscellaneous type (“/other”).",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"For both models in our evaluation, detecting the miscellaneous category is substantially easier than
7We did not compare to a system from (Yogatama et al., 2015), which reports slightly higher test number (72.98 micro F1) as they used a different, unreleased test set.
",6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
producing real types (94% F1 vs. 58% F1 with our best model).,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
We provide further details of this analysis in the supplementary material.,6 Improving Existing Fine-Grained NER with Better Distant Supervision,[0],[0]
"Fine-grained NER has received growing attention, and is used in many applications (Gupta et al., 2017; Ren et al., 2017; Yaghoobzadeh et al., 2017b; Raiman and Raiman, 2018).",7 Related Work,[0],[0]
"Researchers studied typing in varied contexts, including mentions in specific sentences (as we consider) (Ling and Weld, 2012; Gillick et al., 2014; Yogatama et al., 2015; Dong et al., 2015; Schutze et al., 2017), corpus-level prediction (Yaghoobzadeh and Schütze, 2016), and lexicon level (given only a noun phrase with no context) (Yao et al., 2013).
",7 Related Work,[0],[0]
"Recent work introduced fine-grained type ontologies (Rabinovich and Klein, 2017; Murty et al., 2017; Corro et al., 2015), defined using Wikipedia categories (100), Freebase types (1K) and WordNet senses (16K).",7 Related Work,[0],[0]
"However, they focus on named entities, and data has been challenging to gather, often approximating gold annotations with distant supervision.",7 Related Work,[0],[0]
"In contrast, (1) our ontology contains any frequent noun phrases that depicts a type, (2) our task goes beyond named entities, covering every noun phrase (even pronouns), and (3) we provide crowdsourced annotations which provide context-sensitive, fine grained type labels.
",7 Related Work,[0],[0]
"Contextualized fine-grained entity typing is related to selectional preference (Resnik, 1996; Pantel et al., 2007; Zapirain et al., 2013; de Cruys, 2014), where the goal is to induce semantic generalizations on the type of arguments a predicate prefers.",7 Related Work,[0],[0]
"Rather than focusing on predicates, we condition on the entire sentence to deduce the arguments’ types, which allows us to capture more nuanced types.",7 Related Work,[0],[0]
"For example, not every type that fits “He played the violin in his room” is also suitable for “He played the violin in the Carnegie Hall”.",7 Related Work,[0],[0]
"Entity typing here can be connected to argument finding in semantic role labeling.
",7 Related Work,[0],[0]
"To deal with noisy distant supervision for KB population and entity typing, researchers used multi-instance multi-label learning (Surdeanu et al., 2012; Yaghoobzadeh et al., 2017b) or custom losses (Abhishek et al., 2017; Ren et al., 2016a).",7 Related Work,[0],[0]
Our multitask objective handles noisy supervision by pooling different distant supervision sources across different levels of granularity.,7 Related Work,[0],[0]
Using virtually unrestricted types allows us to expand the standard KB-based training methodology with typing information from Wikipedia definitions and naturally-occurring head-word supervision.,8 Conclusion,[0],[0]
These new forms of distant supervision boost performance on our new dataset as well as on an existing fine-grained entity typing benchmark.,8 Conclusion,[0],[0]
"These results set the first performance levels for our evaluation dataset, and suggest that the data will support significant future work.",8 Conclusion,[0],[0]
The research was supported in part the ARO (W911NF-16-1-0121),Acknowledgement,[0],[0]
"the NSF (IIS-1252835, IIS1562364), and an Allen Distinguished Investigator Award.",Acknowledgement,[0],[0]
We would like to thank the reviewers for constructive feedback.,Acknowledgement,[0],[0]
Also thanks to Yotam Eshel and Noam Cohen for providing the Wikilink dataset.,Acknowledgement,[0],[0]
Special thanks to the members of UW NLP for helpful discussions and feedback.,Acknowledgement,[0],[0]
"We introduce a new entity typing task: given a sentence with an entity mention, the goal is to predict a set of free-form phrases (e.g. skyscraper, songwriter, or criminal) that describe appropriate types for the target entity.",abstractText,[0],[0]
"This formulation allows us to use a new type of distant supervision at large scale: head words, which indicate the type of the noun phrases they appear in.",abstractText,[0],[0]
"We show that these ultra-fine types can be crowd-sourced, and introduce new evaluation sets that are much more diverse and fine-grained than existing benchmarks.",abstractText,[0],[0]
"We present a model that can predict open types, and is trained using a multitask objective that pools our new head-word supervision with prior supervision from entity linking.",abstractText,[0],[0]
"Experimental results demonstrate that our model is effective in predicting entity types at varying granularity; it achieves state of the art performance on an existing fine-grained entity typing benchmark, and sets baselines for our newly-introduced datasets.1",abstractText,[0],[0]
Ultra-Fine Entity Typing,title,[0],[0]
Data-driven decision-making has become the subject of increased interest and been used in a number of practical applications.,1. Introduction,[0],[0]
One of the most promising approaches is mathematical programming based on predictive models generated by machine learning.,1. Introduction,[0],[0]
"Recent advances in machine learning have made it easier to create accurate predictive models, and resulting predictions have been used to build mathematical programming problems (we refer to such approaches as predictive optimization).",1. Introduction,[0],[0]
"Predictive optimization is employed in applications for which frequent trial-and-error process are not practical, such as water distribution optimization (Draper et al., 2003), energy generation planning (Baos et al., 2011), retail price optimization (Johnson
1NEC Corporation.",1. Introduction,[0],[0]
"Correspondence to: Shinji Ito <sito@me.jp.nec.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"et al., 2016; Ito & Fujimaki, 2016), supply chain management (Thomas et al., 1996; Jung et al., 2004; Bertsimas & Thiele, 2004), and portfolio optimization (Markowitz, 1952; Chan et al., 1999; Konno & Yamazaki, 1991).",1. Introduction,[0],[0]
"Another important use for data-driven decision-making is in reinforcement learning (Kaelbling et al., 1996; Sutton & Barto, 2013).",1. Introduction,[0],[0]
"Here it is employed in situations mainly in which frequent trial-and-error operations are possible, except for batch reinforcement learning (Lange et al., 2012).",1. Introduction,[0],[0]
"The focus of this paper is on the first approach, i.e., predictive optimization.
",1. Introduction,[0],[0]
"In many practical applications of predictive optimization, it is essential to estimate the quality of the computed strategy because executing a strategy is often costly and risky.",1. Introduction,[0],[0]
"For example, predictive price optimization has been used to estimate revenue functions through regressions of demand as functions of product prices, and then, to optimize pricing strategies by maximizing estimated revenue functions (Johnson et al., 2016; Ito & Fujimaki, 2016; 2017; Yabe et al., 2017).",1. Introduction,[0],[0]
"In practice, users need to assess the return for the computed “optimal” strategy before changing prices, in order to prevent unforeseen heavy losses.",1. Introduction,[0],[0]
"In a situation in which costs for trial-and-error processes are unrealistically high, a key challenge in predictive optimization is how to assess the quality (or expected return) of the “optimal” solution by means of an estimated objective function.
",1. Introduction,[0],[0]
Predictive optimization consists of two steps: estimation and optimization.,1. Introduction,[0],[0]
"In the estimation step, we construct an estimated objective function f(z, θ̂) for the true objective function f(z, θ∗), where θ is a parameter of f , and z is a decision variable corresponding to the strategy to be optimized.",1. Introduction,[0],[0]
"In the optimization step, we compute the estimated optimal strategy ẑ = arg maxz∈Z f(z, θ̂), where Z is the domain of z. Because it would be expensive to observe f(ẑ, θ∗) (i.e., to perform ẑ in a real environment), we usually estimate it by f(ẑ, θ̂), which we call simple evaluation, in order to assess the quality of ẑ.
It has been empirically seen, however, that this simple evaluation tends to be too optimistic.",1. Introduction,[0],[0]
"For example, in the contexts of algorithmic investment and portfolio optimization, it has been reported (Michaud, 1989; Chapados, 2011; Harvey & Liu, 2015) that f(ẑ, θ̂) is much better than the acutual return.",1. Introduction,[0],[0]
"Michaud (Michaud, 1989) argued that this bias ap-
pears because the mean-variance optimizers act as “error maximizers”, i.e., optimizers tend to choose solutions containing large errors.",1. Introduction,[0],[0]
"According to (Harvey & Liu, 2015), a common practice in evaluating trading strategies is simple heuristics that discount the estimated objective to 50%, i.e., consider 0.5f(ẑ, θ̂) to be an estimator of f(ẑ, θ∗).",1. Introduction,[0],[0]
"Heuristics referred to as portfolio resampling techniques (Michaud, 1998; Scherer, 2002) have been studied for nearly 20 years but have not yet to be theoretically justified.",1. Introduction,[0],[0]
"A few recent studies (Bailey & Marcos, 2016; Bailey et al., 2014; Harvey & Liu, 2015) have statistically analyzed and proposed algorithms to mitigate the bias issue, but their algorithms are restricted to particular applications (e.g., algorithmic investment) and, as far as we know, there exists no principled algorithm for an unbiased estimator of f(z, θ∗) in general predictive optimization problems.
",1. Introduction,[0],[0]
"The goal of this study is to address this optimistic bias issue, and to propose methods for unbiased estimation of true objective values.",1. Introduction,[0],[0]
"Our key contributions are summarized as follows.
",1. Introduction,[0],[0]
"First, we prove that the estimated optimal value f(ẑ, θ̂) is biased even if the estimated objective function f(z, θ̂) is an unbiased estimator of the true objective function f(z, θ∗).",1. Introduction,[0],[0]
"Further, we correlate the bias issue to overfitting in machine learning, which yields a valuable insight into bias correction methods.
",1. Introduction,[0],[0]
"Second, we propose two algorithms for estimating the value of true objective functions under mild assumptions.",1. Introduction,[0],[0]
The first algorithm is based on a procedure similar to crossvalidation and has been inspired by the analogy between our problem and overfitting in supervised learning.,1. Introduction,[0],[0]
"This algorithm corrects the optimistic bias, but suffers from pessimistic bias, i.e., the estimated value is biased in a direction suggesting a poorer result, similar to that which occurs in cross-validation.",1. Introduction,[0],[0]
"The magnitude of this pessimistic bias tends to be larger than that of cross-validation, and hence, it is not negligible in many cases.",1. Introduction,[0],[0]
"To mitigate this issue, we propose another algorithm, which we refer to as a parameter perturbation method.",1. Introduction,[0],[0]
"This algorithm employs a resampling technique and is theoretically proven here to achieve asymptotically unbiased estimation.
",1. Introduction,[0],[0]
"Our experimental results show that the proposed algorithms are able to estimate the value of a true objective function more accurately than a state-of-the-art hold-out validation technique commonly used in algorithmic investment (Bailey & Marcos, 2016; Bailey et al., 2014).",1. Introduction,[0],[0]
"In a simulation experiment with real-world retail datasets for price optimization, we have observed that our evaluation algorithms estimate a 17% increase in the gross profit, which seems to be more realistic and convincing than the value estimated without bias correction.
",1. Introduction,[0],[0]
The remainder of this paper is structured as follows.,1. Introduction,[0],[0]
"In Section 2, we introduce the framework of the combination of machine learning and mathematical optimization in examples of usage.",1. Introduction,[0],[0]
We also show that such a framework suffers from bias w.r.t.,1. Introduction,[0],[0]
optimal values.,1. Introduction,[0],[0]
Section 4 gives solutions to this problem and theoretical guarantees for them.,1. Introduction,[0],[0]
"In Section 5, the empirical performance of our algorithms is demonstrated.",1. Introduction,[0],[0]
"Suppose we have a sequence of training data x = (x1, . . .",2. Predictive Optimization,[0],[0]
", xN ) ∈ XN , where N is the number of data instances.",2. Predictive Optimization,[0],[0]
Each xn is generated from a probabilistic model {p(x|θ) : θ ∈ Θ} parameterized by θ ∈ Θ.,2. Predictive Optimization,[0],[0]
"We further suppose having a set of objective functions {f(z, θ) : θ ∈ Θ} where z ∈ Z is a decision variable that corresponds to strategies to be optimized.",2. Predictive Optimization,[0],[0]
"The goal of predictive optimization is to find z∗ ∈ arg maxz∈Z f(z, θ∗), where θ∗ is the true parameter.",2. Predictive Optimization,[0],[0]
"However, such a true parameter is unknown in practice, and therefore we estimate θ∗ by θ̂ from x, and compute the estimated optimal solution ẑ ∈ arg maxz∈Z f(z, θ̂) rather than z∗.",2. Predictive Optimization,[0],[0]
"This section discusses three examples of predictive optimization problems in order to provide a better picture of the process.
",2. Predictive Optimization,[0],[0]
Example 1 (Coin-Tossing).,2. Predictive Optimization,[0],[0]
"Suppose that we have a coin coming up heads with probability θ∗ and tails with probability 1− θ∗, where",2. Predictive Optimization,[0],[0]
"θ∗ ∈ Θ := [0, 1].",2. Predictive Optimization,[0],[0]
Consider predicting heads or tails for this coin.,2. Predictive Optimization,[0],[0]
"If we predict the subsequent face correctly, we win $1, and, otherwise, nothing.",2. Predictive Optimization,[0],[0]
"Predicting heads, then, will result in earning $1 with probability θ∗ and $0 with probability 1 − θ∗, and hence, the expectation value of the earnings for predicting heads is f(‘head’, θ∗) = 1 · θ∗+ 0 · (1− θ∗) = θ∗.",2. Predictive Optimization,[0],[0]
"Similarly, the expected earnings for predicting tails is f(‘tail’, θ∗) = 1− θ∗.",2. Predictive Optimization,[0],[0]
"If we knew the true parameter θ∗, we could maximize the expected earnings by choosing z∗ ∈ arg maxz∈Z f(z, θ∗), where Z = {‘head’, ‘tail’} stands for a set of feasible strategies.",2. Predictive Optimization,[0],[0]
"Since we do not know the true parameter θ∗, however, we use, rather, past data x ∈",2. Predictive Optimization,[0],[0]
"XN := {‘head’, ‘tail’}N of N tossings, for estimating θ∗.
Table 1 illustrates how the optimistic bias occurs in predictive optimization.",2. Predictive Optimization,[0],[0]
Suppose θ∗ = 1/2 (a) and that there are four cases of the observed pattern for three tossings (b).,2. Predictive Optimization,[0],[0]
"The estimators of θ∗ might then be obtained as (c), using maximum likelihood estimation.",2. Predictive Optimization,[0],[0]
"On the basis of θ̂, the “best” strategies are estimated as (d), and the estimated and true optimal values are summarized in (e) and (f).",2. Predictive Optimization,[0],[0]
"It is worth noting that the expectation of (e) over four cases (bottom middle), which is 3/4, is larger than the true expectation (bottom right), which is 1/2 even if the θ̂ is unbiased, i.e., the expectation of θ̂ matches θ∗ (bottom left).
",2. Predictive Optimization,[0],[0]
"Example 2 (Portfolio optimization (Markowitz, 1952)).
",2. Predictive Optimization,[0],[0]
"Suppose that there are d assets, and let Rj stand for the return on each component asset for j ∈ {1, . . .",2. Predictive Optimization,[0],[0]
", d}.",2. Predictive Optimization,[0],[0]
"Let µ∗ = (µ∗1, . . .",2. Predictive Optimization,[0],[0]
", µ ∗ d)",2. Predictive Optimization,[0],[0]
"> ∈ Rd be the expected return for each asset, i.e., µ∗j = E[Rj ].",2. Predictive Optimization,[0],[0]
"Then the portfolio expressed as Rz = ∑d j=1 zjRj , where zj ≥ 0 is the weighting of the j-th component asset and z = (z1, . . .",2. Predictive Optimization,[0],[0]
", zd)> ∈ Rd≥0, has expected return E[Rz] = ∑d j=1 zjµ ∗",2. Predictive Optimization,[0],[0]
"j = µ
∗>z.",2. Predictive Optimization,[0],[0]
"Variance in the portfolio return can be expressed as var[Rz] = z>Σ∗z, where Σ∗ is the covariance matrix of (R1, . . .",2. Predictive Optimization,[0],[0]
", Rd).",2. Predictive Optimization,[0],[0]
"Denote θ∗ = (µ∗,Σ∗).",2. Predictive Optimization,[0],[0]
"Then, with a given risk tolerance λ ≥ 0, the optimal portfolio is obtained as the solution of the following problem:
Maximize f(z, θ∗) := µ∗>z",2. Predictive Optimization,[0],[0]
"− λz>Σ∗z, (1) subject to d∑ j=1",2. Predictive Optimization,[0],[0]
"zj = 1, zj ≥ 0",2. Predictive Optimization,[0],[0]
"(j = 1, . . .",2. Predictive Optimization,[0],[0]
", d).
",2. Predictive Optimization,[0],[0]
"In practice, however, since θ∗ is never available, we estimate it from historical data x = (x1, . . .",2. Predictive Optimization,[0],[0]
", xN ), where xn ∈ Rd is an observation of past returns for individual component assets (Qiu et al., 2015; Agarwal et al., 2006; Li & Hoi, 2012).",2. Predictive Optimization,[0],[0]
"Under the assumption that xn follow the same distribution,1 the estimators of µ∗ and Σ∗ are obtained by µ̂ = 1N ∑N n=1 xn and Σ̂ = 1 N−1 ∑N n=1(xn− µ̂)(xn− µ̂)>.",2. Predictive Optimization,[0],[0]
"We obtain the optimal solution by solving (1) with the replacement of µ∗ and Σ∗ by µ̂ and Σ̂, respectively.
",2. Predictive Optimization,[0],[0]
"Example 3 (Predictive price optimization(Ito & Fujimaki, 2017; 2016)).",2. Predictive Optimization,[0],[0]
"Suppose we have d products whose prices are denoted by z = (z1, . . .",2. Predictive Optimization,[0],[0]
", zd).",2. Predictive Optimization,[0],[0]
Let us denote their sales quantities by q∗(z) =,2. Predictive Optimization,[0],[0]
"(q∗j (z)) d j=1 ∈ Rd, which are functions of the price z.",2. Predictive Optimization,[0],[0]
"The gross revenue function is then defined by f(z, θ∗) = q∗(z)>z, and the true optimal solution is obtained by solving the following problem:
Maximize q∗(z)>z subject to z ∈ Z, (2)
where Z ⊆ Rd is a pre-defined domain of prices (e.g., list price, 3%-off, 5%-off, and so on).",2. Predictive Optimization,[0],[0]
"However, we can never know the true demand-price relationship q∗(z), and
1This condition can easily be relaxed.
",2. Predictive Optimization,[0],[0]
"the predictive price optimization approximates q∗(z) by the following regression functions:
q(z, θ) = K∑ k=1 θkψk(z) + , ∼ N(0,Σ), (3)
where {ψk : Rd → Rd}Kk=1 are fixed basis functions and {θk}Kk=1 ⊆ R are regression coefficients.",2. Predictive Optimization,[0],[0]
"We estimate θ = (θ1, . . .",2. Predictive Optimization,[0],[0]
", θK) as a standard regression problem and then solve (2) after replacing q∗(z) by q(z, θ̂), where θ̂ is the estimator of θ∗.",2. Predictive Optimization,[0],[0]
This section formally proves the existence of optimistic bias in estimated optimal values.,3.1. Existence of Optimistic Bias,[0],[0]
"In the above examples, the objective functions f(z, θ) w.r.t.",3.1. Existence of Optimistic Bias,[0],[0]
θ were affine functions and θ̂ were unbiased estimators of θ∗.,3.1. Existence of Optimistic Bias,[0],[0]
"Hence, the constructed objective function f(z, θ̂) was an unbiased estimator of the true objective function f(z, θ∗), i.e., it holds that
Ex[f(z, θ̂)]",3.1. Existence of Optimistic Bias,[0],[0]
"= Ex[f(z, θ∗)], z ∈ Z. (4)
From this equation, one might expect that Ex[f(ẑ, θ̂)] and f(ẑ, θ̂) would be reasonable estimators of Ex[f(ẑ, θ∗)] and f(ẑ, θ∗), respectively.",3.1. Existence of Optimistic Bias,[0],[0]
"However, the following proposition contradicts this intuition.
",3.1. Existence of Optimistic Bias,[0],[0]
Proposition 1 (Optimistic Bias).,3.1. Existence of Optimistic Bias,[0],[0]
Suppose (4) holds.,3.1. Existence of Optimistic Bias,[0],[0]
"For ẑ ∈ arg maxz∈Z f(z, θ̂) and z∗ ∈ arg maxz∈Z f(z, θ∗), it holds that
Ex[f(ẑ, θ̂)]",3.1. Existence of Optimistic Bias,[0],[0]
"≥ f(z∗, θ∗) ≥",3.1. Existence of Optimistic Bias,[0],[0]
"Ex[f(ẑ, θ∗)].",3.1. Existence of Optimistic Bias,[0],[0]
"(5)
",3.1. Existence of Optimistic Bias,[0],[0]
The right inequality is strict if ẑ is suboptimal w.r.t.,3.1. Existence of Optimistic Bias,[0],[0]
"the true objective function f(z, θ∗) with non-zero probability.
",3.1. Existence of Optimistic Bias,[0],[0]
Proof.,3.1. Existence of Optimistic Bias,[0],[0]
"By taking the expectation of both sides of f(ẑ, θ̂) ≥ f(z∗, θ̂), we obtain the left inequality of (5) as follows:
Ex[f(ẑ, θ̂)]",3.1. Existence of Optimistic Bias,[0],[0]
"≥ Ex[f(z∗, θ̂)]",3.1. Existence of Optimistic Bias,[0],[0]
"= f(z∗, θ∗),
where the equality comes from (4).",3.1. Existence of Optimistic Bias,[0],[0]
"Similarly, the right inequality of (5) comes from f(z∗, θ∗) ≥ f(ẑ, θ∗).",3.1. Existence of Optimistic Bias,[0],[0]
"Further, if ẑ /∈ arg maxz∈Z f(z, θ∗) holds with non-zero probability, then f(z∗, θ∗) > f(ẑ, θ∗) holds with non-zero probability and f(z∗, θ∗) ≥ f(ẑ, θ∗) always holds, which implies f(z∗, θ∗) >",3.1. Existence of Optimistic Bias,[0],[0]
"E[f(ẑ, θ∗)].
",3.1. Existence of Optimistic Bias,[0],[0]
"This proposition implies that the estimated optimal value f(ẑ, θ̂) is not an unbiased estimator of f(ẑ, θ∗) even if the estimated objective function f(z, θ̂) is an unbiased estimator of the true objective function f(z, θ∗).",3.1. Existence of Optimistic Bias,[0],[0]
"This optimistic bias
has been empirically learned in the context of portfolio optimization (Michaud, 1989).",3.1. Existence of Optimistic Bias,[0],[0]
"Recently, (Harvey & Liu, 2015; Harvey et al., 2016) have proposed bias correction methods based on statistical tests, though their methods are applicable only to cases in which the objective function is the Sharpe ratio.",3.1. Existence of Optimistic Bias,[0],[0]
"Other recent studies (Bailey & Marcos, 2016; Bailey et al., 2014) have also focused on the Sharpe ratio and proposed a hold-out validation method.",3.1. Existence of Optimistic Bias,[0],[0]
"Although their methods apply to general predictive optimization problems, they have not been proven to obtain unbiased estimators.",3.1. Existence of Optimistic Bias,[0],[0]
"Note that a similar inequality has been discovered in the context of stochastic programs,2 one that corresponds to the left inequality of (5).",3.1. Existence of Optimistic Bias,[0],[0]
"For the special case in which Z is a finite set, the same inequality as (5) has been shown in the context of decision analysis (Smith & Winkler, 2006).",3.1. Existence of Optimistic Bias,[0],[0]
"This subsection discusses the connection of the optimistic bias issue to overfitting in machine learning, which connection has led to the ideas underlying our proposed algorithms.",3.2. Connection to Empirical Risk Minimization,[0],[0]
"In supervised machine learning, we choose the prediction rule ĥ from a hypothesis space H by minimizing the empirical error, i.e., we let ĥ ∈ arg minh∈H 1 n ∑N n=1 `(h, xn), where xn is the observed data generated from a distribution D and ` is a loss function.",3.2. Connection to Empirical Risk Minimization,[0],[0]
The empirical error 1N ∑N n=1,3.2. Connection to Empirical Risk Minimization,[0],[0]
"`(h, xn) is an unbiased estimator of the generalization error `D(h) := Ex∼D[`(h, x)] for arbitrary fixed prediction rule h, i.e., it holds that Exn∼D[ 1N ∑N n=1 `(h, xn)] =",3.2. Connection to Empirical Risk Minimization,[0],[0]
"`D(h) for any fixed h. De-
spite this equation, the empirical error 1N ∑N n=1 `(ĥ, xn) for the computed parameter ĥ is smaller than the generalization error `D(ĥ) in most cases, because ĥ overfits the observed samples, as is well known (Vapnik, 2013).",3.2. Connection to Empirical Risk Minimization,[0],[0]
"The analogy between the optimistic bias in our setting and the overfitting issue in machine learning suggests the reuse of datasets for estimation of their objective functions and evaluation of objective values.
",3.2. Connection to Empirical Risk Minimization,[0],[0]
A comparison between empirical risk minimization (ERM) and our prediction-based optimization is summarized in Table 2.,3.2. Connection to Empirical Risk Minimization,[0],[0]
"As is shown in the Table, our problem concerning bias in predictive optimization has a structure similar to that of the problem of overfitting in empirical risk minimization.",3.2. Connection to Empirical Risk Minimization,[0],[0]
"Typical methods for estimating generalization error in machine learning would be cross-validation and such asymptotic bias correction as AIC (Akaike, 1973).",3.2. Connection to Empirical Risk Minimization,[0],[0]
"This paper follows the concept of cross-validation in the context of predictive optimization and, in the following section, proposes a more accurate algorithm.
2",3.2. Connection to Empirical Risk Minimization,[0],[0]
"In stochastic programs, the objective is a random function, and it has been shown in, e.g., (Mak et al., 1999), that the expectation of the minimum of the objective is a lower bound of the minimum of the expectation of the objective.",3.2. Connection to Empirical Risk Minimization,[0],[0]
"Our goal is to construct unbiased estimators for the value f(ẑ, θ∗) of the true objective function, i.e., to construct ρ : Xn → R such that Ex[ρ(x)]",4. Bias Correction Algorithms,[0],[0]
"= Ex[f(ẑ, θ∗)], where ẑ ∈ arg max
z∈Z f(z, θ̂) is the computed strategy.",4. Bias Correction Algorithms,[0],[0]
"We assume
the following conditions.
",4. Bias Correction Algorithms,[0],[0]
Assumption 2.,4. Bias Correction Algorithms,[0],[0]
"(i) f(z, θ) is affine in θ, i.e., ∃a : Z → R, ∃b : Z → R, f(z, θ) =",4. Bias Correction Algorithms,[0],[0]
"θ>a(z) + b(z).
",4. Bias Correction Algorithms,[0],[0]
"(ii) The optimal solution z(θ) ∈ arg maxz∈Z f(z, θ) is uniquely determined for almost all θ.
(iii)",4. Bias Correction Algorithms,[0],[0]
"One of the following holds: (iii.a) Z is a finite set, or (iii.b) Z is a compact subset of Rd, and z 7→ (a(z), b(z)) is a continuous injective function.
(iv) θ̂ is an unbiased estimator of θ∗, i.e., we have Ex[θ̂] = θ∗.
The assumptions (i)-(iii) are conditions on mathematical programming problems, and such typical ones as (mixedinteger) linear/quadratic/semidefinite programming problems satisfy these conditions.",4. Bias Correction Algorithms,[0],[0]
"Assumption (iv) is a condition on the machine learning algorithm for estimating the objective function in the optimization problem, and we can employ any standard unbiased estimation algorithm.",4. Bias Correction Algorithms,[0],[0]
Note that the examples in Section 3 satisfy all these assumptions.,4. Bias Correction Algorithms,[0],[0]
"We assume (i) and (iv) in Section 4.1, and assume (i)-(iv) in Section 4.2.",4. Bias Correction Algorithms,[0],[0]
"As noted in Section 3.2, our problem is closely related to the problem of estimating generalization error.",4.1. Cross-Validation Method,[0],[0]
"Inspired by the cross-validation method, one of the most popular methods for estimating generalization error in machine learning, we propose a cross-validation method for estimating the value of the true objective function in predictive optimization.",4.1. Cross-Validation Method,[0],[0]
"In the context of algorithmic investment, a similar method, referred to as the hold-out method is mentioned in (Bailey et al., 2014).",4.1. Cross-Validation Method,[0],[0]
"The method discussed below is essentially an extension of the hold-out method for general predictive optimization problems.
",4.1. Cross-Validation Method,[0],[0]
"One of the reasons that the value f(ẑ, θ̂) contains biases is that ẑ and θ̂ are dependent random variables.",4.1. Cross-Validation Method,[0],[0]
"Indeed,
Algorithm 1 k-fold cross-validation Input: data x ∈ XN , the number K ≥ 2 of partition Divide data x into K parts x1, . . . ,xK .",4.1. Cross-Validation Method,[0],[0]
"for k = 1 to K do
Compute θ̂k, θ̃k from xk,x−k respectively, where we define x−k to be all samples in x except for xk, and compute z̃k ∈ arg maxz∈Z f(z, θ̃k).
end for Output ρCV (x) := 1K ∑K k=1 f(z̃k, θ̂k).
if ẑ and θ̂ are independent, Ex[f(ẑ, θ̂)]",4.1. Cross-Validation Method,[0],[0]
"= Ex[f(ẑ, θ∗)] straightforwardly holds from assumptions (i) and (iv).",4.1. Cross-Validation Method,[0],[0]
The main idea of the cross-validation method (as with the standard cross-validation in machine learning) is to divide the data x ∈ XN into two parts x1 ∈,4.1. Cross-Validation Method,[0],[0]
"XN1 ,x2 ∈",4.1. Cross-Validation Method,[0],[0]
"XN2 , where N1 + N2 = N .",4.1. Cross-Validation Method,[0],[0]
"Note that each element in x1 and x2 follows p(x, θ∗) independently, and, hence, x1 and x2 are independent random variables.",4.1. Cross-Validation Method,[0],[0]
"Let us denote the estimators based on x1 and x2 by θ̂1 and θ̂2, respectively.",4.1. Cross-Validation Method,[0],[0]
"Also, the optimal strategy on each estimator is denoted by ẑi := arg maxz∈Z f(z, θ̂i) for i = 1, 2.",4.1. Cross-Validation Method,[0],[0]
"Then ẑ1 and θ̂2 are independent (the opposite also holds), and we have Ex[f(ẑ1, θ̂2)]",4.1. Cross-Validation Method,[0],[0]
"= Ex1 [f(ẑ1,Ex2 [θ̂2])]",4.1. Cross-Validation Method,[0],[0]
"= Ex1 [f(ẑ1, θ∗)].",4.1. Cross-Validation Method,[0],[0]
"Further, if N1 is sufficiently close to N , Ex1 [f(z̃1, θ∗)] is close to Ex[f(ẑ, θ∗)].",4.1. Cross-Validation Method,[0],[0]
"This idea can be extended to k-fold cross-validation, in which we divide data x ∈ RN into K parts x1, . . .",4.1. Cross-Validation Method,[0],[0]
",xK ∈ RN ′",4.1. Cross-Validation Method,[0],[0]
", where KN ′ = N .",4.1. Cross-Validation Method,[0],[0]
"We compute z̃k from {x1, . . .",4.1. Cross-Validation Method,[0],[0]
",xK} \ {xk}, and compute θ̂k from xk.",4.1. Cross-Validation Method,[0],[0]
"Then the value ρCV (x) := 1K ∑K k=1 f(z̃k, θ̂k) satisfies
Ex[ρCV (x)]",4.1. Cross-Validation Method,[0],[0]
"= Ex′ [f(z̃, θ∗)], (6)
where z̃ stands for the strategy computed from (K − 1)N ′ samples, under assumptions (i) and (iv).
",4.1. Cross-Validation Method,[0],[0]
"A major drawback to Algorithm 1 is that it can only estimate the objective value attained byN −N ′ samples, as is shown in (6), even though the value attained by all N samples is desired.",4.1. Cross-Validation Method,[0],[0]
"In machine learning, to mitigate this gap, a leave-one-out method (i.e., setting N ′",4.1. Cross-Validation Method,[0],[0]
= 1) can be used.,4.1. Cross-Validation Method,[0],[0]
"In predictive optimization, however, the number N ′ of holdout samples needs to be large enough to compute another estimator, θ̂k, which limits the accuracy of the estimation of f(ẑ, θ∗).",4.1. Cross-Validation Method,[0],[0]
The accuracy of Algorithm 1 is considered in Sec. 5 in an empirical evaluation.,4.1. Cross-Validation Method,[0],[0]
This subsection proposes another algorithm that addresses the drawbacks of Algorithm 1.,4.2. Parameter perturbation method,[0],[0]
Denote the error in the estimated parameter by δ := θ̂−θ∗.,4.2. Parameter perturbation method,[0],[0]
The error δ depends on the training data x and can be regarded as a random variable when x is considered to be a random variable.,4.2. Parameter perturbation method,[0],[0]
"For γ ≥ 0,
let us first define η(γ) as follows:
η(γ) = Eδ[f(z(θ∗ + γδ), θ∗)],
where z(θ) := arg maxz∈Z f(z, θ).",4.2. Parameter perturbation method,[0],[0]
"Since ẑ = z(θ̂) = z(θ∗ + δ), we have η(1)",4.2. Parameter perturbation method,[0],[0]
"= E[f(ẑ, θ∗)].",4.2. Parameter perturbation method,[0],[0]
"Hence, our goal, unbiased estimation of f(ẑ, θ∗), is equivalent to unbiased estimation of η(1).",4.2. Parameter perturbation method,[0],[0]
"Let us next define φ(γ) as follows:
φ(γ) = Eδ[f(z(θ∗ + γδ), θ∗ + γδ)].",4.2. Parameter perturbation method,[0],[0]
"(7)
Note that we have φ(1) = E[f(ẑ, θ̂)].",4.2. Parameter perturbation method,[0],[0]
"Further, φ(γ) and η(γ) satisfy φ(0) = η(0)",4.2. Parameter perturbation method,[0],[0]
"= f(z∗, θ∗) and φ(γ) ≥ f(z∗, θ∗) ≥ η(γ) for all γ ≥ 0, which can be proved in a way similar to that of the proof of Proposition 1.
",4.2. Parameter perturbation method,[0],[0]
The following proposition plays a key role in our second algorithm.,4.2. Parameter perturbation method,[0],[0]
Proposition 3.,4.2. Parameter perturbation method,[0],[0]
Suppose that assumptions (i)-(iv) hold.,4.2. Parameter perturbation method,[0],[0]
"For all γ > 0, φ(γ) is differentiable, and its derivative φ′(γ) satisfies
η(γ) = φ(γ)− γφ′(γ).",4.2. Parameter perturbation method,[0],[0]
"(8)
The proof of this proposition is summarized in the supplementary material.
",4.2. Parameter perturbation method,[0],[0]
"Let us explain this proposition using Figure 1, which is based on the simulation experiment for portfolio optimization used in Section 5 and shows how the values of φ and η behave for some γ ≥ 0.",4.2. Parameter perturbation method,[0],[0]
"The tangent to φ(γ) at γ = γ0 (the blue broken-line) has a y-intercept (the red broken-line) equal to the value of η(γ0), for all γ0 > 0.",4.2. Parameter perturbation method,[0],[0]
"From this relationship, the derivative φ′(1) of φ(γ) at γ = 1 satisfies φ′(1) = φ(1)",4.2. Parameter perturbation method,[0],[0]
"− η(1) = E[f(ẑ, θ̂)]",4.2. Parameter perturbation method,[0],[0]
"− E[f(ẑ, θ∗)], i.e., the value of φ′(1) is equal to the value of the bias in our predictive optimization problem.
",4.2. Parameter perturbation method,[0],[0]
"Our problem is now to obtain an unbiased estimator ζ of φ′(1) that will give us an unbiased estimator of f(ẑ, θ∗), i.e. ρ = f(ẑ, θ̂)− ζ.",4.2. Parameter perturbation method,[0],[0]
"From the definition of the derivative, the value of φ′(1) can be approximated by (φ(1+h)−φ(1))/h for small h. Further, from the definition of φ, the estimated optimal value f(ẑ, θ̂) is an unbiased estimator of φ(1).",4.2. Parameter perturbation method,[0],[0]
"Also, the value of φ(1 + h) = E[maxz∈Z f(z, θ∗ + (1 + h)δ)] is the expectation of the optimal value for the objective function with a parameter having an “enhanced” error.",4.2. Parameter perturbation method,[0],[0]
"If we get samples θ̂h following the distribution of θ∗ + (1 + h)δ, we can develop an estimator of φ(1 + h), and accordingly, we can estimate η(1)",4.2. Parameter perturbation method,[0],[0]
"= E[f(ẑ, θ∗)].
",4.2. Parameter perturbation method,[0],[0]
"Suppose that θ̂(1)h , . . .",4.2. Parameter perturbation method,[0],[0]
", θ̂ (s) h follows the distribution of θ ∗ + (1 + h)δ, and define
ρh := 1 + h
h max z∈Z f(z, θ̂)− 1 hs s∑ j=1 max z∈Z f(z, θ̂ (j) h ).",4.2. Parameter perturbation method,[0],[0]
"(9)
The value ρh, then, has the following property.
",4.2. Parameter perturbation method,[0],[0]
Algorithm 2,4.2. Parameter perturbation method,[0],[0]
Parameter perturbation method Input:,4.2. Parameter perturbation method,[0],[0]
"data x ∈ Xn, parameters h > 0, s ∈ {1, 2, . . .",4.2. Parameter perturbation method,[0],[0]
"} Compute θ̂ from x and set v̂0 = maxz∈Z f(z, θ̂).",4.2. Parameter perturbation method,[0],[0]
"Generate {θ̂(j)h }sj=1 by (i) for asymptotic normal estimators or (ii) for M-estimators.
",4.2. Parameter perturbation method,[0],[0]
(i) Set θ̂(j)h to be the estimator computed from N/(1 +,4.2. Parameter perturbation method,[0],[0]
"h)2 samples randomly chosen from x without replacement.
",4.2. Parameter perturbation method,[0],[0]
"(ii) Generate δ̂j by (10), and set θ̂ (j) h = θ̂ + δ̂j .
for j = 1 to s do Set v̂j = maxz∈Z f(z, θ̂ (j) h ).",4.2. Parameter perturbation method,[0],[0]
"end for Output ρh := 1+hh v̂0 − 1 hs ∑s j=1 v̂j .
",4.2. Parameter perturbation method,[0],[0]
Proposition 4.,4.2. Parameter perturbation method,[0],[0]
"Under assumptions (i)-(iv), the value ρh defined by (9) is an asymptotically unbiased estimator of f(ẑ, θ∗), i.e., it holds that limh→0 E [ρh] = E[f(ẑ, θ∗)].
",4.2. Parameter perturbation method,[0],[0]
Proof.,4.2. Parameter perturbation method,[0],[0]
"From the definition of ρh and φ(γ), we have E[ρh]",4.2. Parameter perturbation method,[0],[0]
= ρ(1),4.2. Parameter perturbation method,[0],[0]
− φ(1+h)−φ(1)h .,4.2. Parameter perturbation method,[0],[0]
"Hence, we have limh→0 E",4.2. Parameter perturbation method,[0],[0]
[ρh] = φ(1),4.2. Parameter perturbation method,[0],[0]
− φ′(1).,4.2. Parameter perturbation method,[0],[0]
"From Proposition 3, this value is equal to η(1)",4.2. Parameter perturbation method,[0],[0]
"= E[f(ẑ, θ∗)].
",4.2. Parameter perturbation method,[0],[0]
"The remaining problem is how to obtain samples θ̂h, with enhanced errors, from the distribution of θ∗+(1+h)δ.",4.2. Parameter perturbation method,[0],[0]
"If θ̂ is an asymptotically normal estimator of θ∗, its distribution can be approximated by the normal distribution N (θ∗, 1NΣ
∗), where Σ∗ is a constant matrix not dependent on N .",4.2. Parameter perturbation method,[0],[0]
"Further, when we compute an estimator θ̂h fromN/(1+h)2 data, the distribution of θ̂h can be approximated byN (θ∗, (1+h) 2 N Σ ∗).",4.2. Parameter perturbation method,[0],[0]
This is an approximation of the distribution of θ∗ + (1 + h)δ.,4.2. Parameter perturbation method,[0],[0]
"This procedure for generating θ̂h is used in (i) of Algorithm 2.
",4.2. Parameter perturbation method,[0],[0]
"If θ̂ is an M-estimator, an asymptotically normal estimator commonly used in machine learning, we can eliminate repetitive computation in (i) of Algorithm 2.",4.2. Parameter perturbation method,[0],[0]
"For M-estimators,
Σ̂ is given in a closed form, as described in (van der Vaart, 1998), such that N (0, 1N Σ̂) approximates the error distribution of the estimator.",4.2. Parameter perturbation method,[0],[0]
"Once we have computed Σ̂, we generate samples from an approximated distribution of θ∗ + (1 + h)δ, by adding δ̂ to θ̂, which is obtained by
δ̂ ∼ N (0, (1 + h) 2 − 1
N Σ̂).",4.2. Parameter perturbation method,[0],[0]
"(10)
We can, in fact, confirm that the distribution of θ̂+ δ̂ approximates that of θ∗+ (1 +h)δ by applying the normal approximation to θ̂− θ∗ = δ.",4.2. Parameter perturbation method,[0],[0]
"From the normal approximation δ ∼ N (0, 1N Σ̂), we obtain θ ∗+(1+h)δ ∼ N (θ∗, (1+h) 2 N Σ̂) and θ̂+ δ̂ ∼ N (θ∗+0, 1N Σ̂+ (1+h)2−1 N Σ̂) = N",4.2. Parameter perturbation method,[0],[0]
"(θ ∗, (1+h) 2
N Σ̂).",4.2. Parameter perturbation method,[0],[0]
This procedure corresponds to (ii) in Algorithm 2.,4.2. Parameter perturbation method,[0],[0]
"We have compared our Algorithm 1 and Algorithm 2 with the hold-out method (Bailey & Marcos, 2016; Bailey et al., 2014) and the portfolio resampling method (Scherer, 2002) by means of the simulation models of the examples in Section 2.",5. Experiments,[0],[0]
"We used GUROBI Optimizer 6.0.43 for portfolio optimization, and the algorithm in (Ito & Fujimaki, 2016) for price optimization.",5. Experiments,[0],[0]
"The portfolio optimization problem described in Example 2 of Section 2 was constructed with θ∗ = (µ∗,Σ∗) defined by µ∗ = 1 + and Σ∗",5.1. Predictive Portfolio Optimization,[0],[0]
"= X>X , where ∈ Rd were generated by N(0, I) and each entry of X ∈ RD×D was drawn from N (0, D−1).",5.1. Predictive Portfolio Optimization,[0],[0]
"We generated datasets {xn}Nn=1 following N (µ∗,Σ∗), from which we computed θ̂, as in Example 2, and solved the optimization problem (1) with θ∗ replaced by θ̂, to obtain ẑ. We chose D = 50, N = 20, and λ = 1.0 for our simulation experiments.",5.1. Predictive Portfolio Optimization,[0],[0]
"When using the portfolio resampling method, we computed z̄ by means of 10 bootstrap resamplings and outputted f(z̄, θ̂) ≤ f(ẑ, θ̂).",5.1. Predictive Portfolio Optimization,[0],[0]
"For details regarding portfolio resampling, see, e.g., (Scherer, 2002).",5.1. Predictive Portfolio Optimization,[0],[0]
"For the hold-out validation, we first divided N data into N ′ and N −N ′, then computed ẑ1 from the former N ′ data and estimated θ̂2 from the letter N −N ′ data, and then calculated f(ẑ1, θ̂2).
",5.1. Predictive Portfolio Optimization,[0],[0]
"Accuracy Comparisons Figure 2 shows the means and the standard deviations of computed values of f(z∗, θ∗), f(ẑ, θ̂) and f(ẑ, θ∗) for 400 randomly-initialized datasets.",5.1. Predictive Portfolio Optimization,[0],[0]
"We have observed that:
• f(ẑ, θ̂) was much larger than f(ẑ, θ∗), which is consistent with Proposition 1.",5.1. Predictive Portfolio Optimization,[0],[0]
"• The hold-out method performed much worse than our 3 http://www.gurobi.com/
CV and perturbation methods, though its performance improved with an increasingN ′. Also, the variance in the proposed methods was much smaller.",5.1. Predictive Portfolio Optimization,[0],[0]
Note that we could not set N ′,5.1. Predictive Portfolio Optimization,[0],[0]
to be larger than N ′,5.1. Predictive Portfolio Optimization,[0],[0]
= 18 since the estimation of θ̂1 and θ̂2 would fail.,5.1. Predictive Portfolio Optimization,[0],[0]
•,5.1. Predictive Portfolio Optimization,[0],[0]
"The portfolio resampling method computed slightly less optimistic value than f(ẑ, θ̂), but a large amount of optimistic bias remained.",5.1. Predictive Portfolio Optimization,[0],[0]
• The perturbation method corrected bias better than the CV method w.r.t.,5.1. Predictive Portfolio Optimization,[0],[0]
both bias and variance.,5.1. Predictive Portfolio Optimization,[0],[0]
"Indeed, it almost perfectly corrected the optimistic bias in expectation.",5.1. Predictive Portfolio Optimization,[0],[0]
Note that K = 10 was the largest possible value because at least two samples are necessary for estimating the covariance matrix.,5.1. Predictive Portfolio Optimization,[0],[0]
This means that the value of CV (K = 10) achieved the minimum bias for the CV method.,5.1. Predictive Portfolio Optimization,[0],[0]
•,5.1. Predictive Portfolio Optimization,[0],[0]
"The CV method and the hold-out method produced
conservative estimates.",5.1. Predictive Portfolio Optimization,[0],[0]
"The pessimistic bias in the CV method came from the difference between ẑ ∈ arg maxz∈Z f(z, θ̂) and z̃ in (6).
",5.1. Predictive Portfolio Optimization,[0],[0]
"Note that E[f(ẑ, θ∗)] was poorer than E[f(z∗, θ∗)], where the former was the best objective value achieved with the available finite training samples.",5.1. Predictive Portfolio Optimization,[0],[0]
"This negative difference is unavoidable with our bias correction, which appears to raise an interesting open challenge w.r.t.",5.1. Predictive Portfolio Optimization,[0],[0]
"the combination of our bias correction with robust optimization (Bertsimas et al., 2011), i.e., the former mitigates the optimistic bias, and the later mitigates uncertainty in objective functions.
",5.1. Predictive Portfolio Optimization,[0],[0]
Sensitivity of the Perturbation Method We investigated the sensitivity of the perturbation method w.r.t.,5.1. Predictive Portfolio Optimization,[0],[0]
"h > 0, which is the important trade-off parameter in bias and variance.",5.1. Predictive Portfolio Optimization,[0],[0]
"We applied it to 100 different randomly-initialized datasets, for which we set h = 0.05, 0.10, . . .",5.1. Predictive Portfolio Optimization,[0],[0]
", 0.50.",5.1. Predictive Portfolio Optimization,[0],[0]
"Because s is not sensitive, we fixed it to s = 10.",5.1. Predictive Portfolio Optimization,[0],[0]
"Figure 3 demonstrates the changes in bias and variance (top figure) and RMSE against f(ẑ, θ∗), over h.",5.1. Predictive Portfolio Optimization,[0],[0]
"As the value
of h increased, the bias increased though the variance decreased (top figure), as was implied in Proposition 4, and this resulted in significantly larger RMSE values with smaller values of h. This observation indicates that an appropriate balance between bias and variance must be determined, and that a variance-sensitive measure such as RMSE can be used as a guide to determine the trade-off.",5.1. Predictive Portfolio Optimization,[0],[0]
We applied our algorithms to the predictive price optimization discussed as Example 3 in Section 2.,5.2. Predictive Price Optimization,[0],[0]
"As reported in (Ito & Fujimaki, 2017), the optimal value in this problem contains optimistic bias, which is consistent with Proposition 1.",5.2. Predictive Price Optimization,[0],[0]
"Unlike in the portfolio optimization, the parameter θ̂ is estimated by regression techniques, and the set of feasible strategies Z is discrete.
",5.2. Predictive Price Optimization,[0],[0]
"Simulation Experiment In this experiment, we investigated the effect of the optimistic bias and our bias correction over parameter dimensionality, i.e., the number of products d.",5.2. Predictive Price Optimization,[0],[0]
"We generated the same simulation data as in (Ito & Fujimaki, 2017).",5.2. Predictive Price Optimization,[0],[0]
"The sales quantity qi of the i-th product was generated from the regression model qi = αi + ∑d j=1 βijpj , where αi and βij were generated by uniform distributions, where αi ∈",5.2. Predictive Price Optimization,[0],[0]
"[d, 3d], βij ∈",5.2. Predictive Price Optimization,[0],[0]
"[0, 2] for i 6= j, and βii ∈",5.2. Predictive Price Optimization,[0],[0]
"[−2d,−d].",5.2. Predictive Price Optimization,[0],[0]
"The feasible region Z was defined by Z = {0.6, 0.7, . . .",5.2. Predictive Price Optimization,[0],[0]
", 1.0}d.",5.2. Predictive Price Optimization,[0],[0]
"We chose N = 500 for our experiments.
",5.2. Predictive Price Optimization,[0],[0]
"Figure 4 shows the change in the objective values normalized by the ideal objective value f(z∗, θ∗) over the number
of products d. For Algorithm 1 (CV method), we chose K = 2 so that the hold-out samples would be sufficient to estimate parameters {αi} and {βij}.",5.2. Predictive Price Optimization,[0],[0]
"We observed that:
• f(ẑ, θ∗) degraded against f(z∗, θ∗) with increasing d because the estimation error in machine learning increased.",5.2. Predictive Price Optimization,[0],[0]
•,5.2. Predictive Price Optimization,[0],[0]
"The optimistic bias, f(ẑ, θ̂)− f(ẑ, θ∗), rapidly increased because f(ẑ, θ̂)− f(z∗, θ∗) also increased in addition to the increase in f(z∗, θ∗)− f(ẑ, θ∗).",5.2. Predictive Price Optimization,[0],[0]
•,5.2. Predictive Price Optimization,[0],[0]
"The CV method suffered from pessimistic bias, which increased as d increased.",5.2. Predictive Price Optimization,[0],[0]
•,5.2. Predictive Price Optimization,[0],[0]
"The perturbation method corrected the bias accurately even if the parameter dimensionality, i.e., d, increased.
",5.2. Predictive Price Optimization,[0],[0]
"These results confirm the robustness of our proposed method over parameter dimensionality and also its general applicability to a wide range of problems (the portfolio optimization in Section 5.1 is continuous and convex while the price optimization in this section is discrete and non-convex).
",5.2. Predictive Price Optimization,[0],[0]
Real-World Retail Dataset,5.2. Predictive Price Optimization,[0],[0]
"The real-world retail dataset used in (Ito & Fujimaki, 2017; 2016) contains sales information for a middle-size supermarket located in Tokyo.4 Using this information, we selected 50 regularly-sold beer products.",5.2. Predictive Price Optimization,[0],[0]
The data range was approximately the three years from 2012/01 to 2014/11.,5.2. Predictive Price Optimization,[0],[0]
We used the first 35 months (1063 samples) for training regression models and simulated the best price strategy for the next day 2014/12/1.,5.2. Predictive Price Optimization,[0],[0]
"We estimated parameters in regression models, using the least squares method.",5.2. Predictive Price Optimization,[0],[0]
"The other settings were same as in (Ito & Fujimaki, 2016).
",5.2. Predictive Price Optimization,[0],[0]
"The actual (non-optimized) gross profit in the past data was 106, 348 JPY, while the estimated optimal value f(ẑ, θ̂) was 490, 502 JPY, which represents an approximately 361% increase in gross profit, but this value was obviously unreal-
4 The data were provided by KSP-SP Co., LTD, http:// www.ksp-sp.com.
istically huge and unreliable (price changes alone could not increase a profit 4.6 by times!).",5.2. Predictive Price Optimization,[0],[0]
"The bias-corrected optimal gross profit with the perturbation method at h = 0.1 and s = 100 was 124, 477 JPY, which represents an approximately 17% increase in the gross profit.",5.2. Predictive Price Optimization,[0],[0]
"Although we were unable to confirm the validity of this value since this experiment was conducted on past historical data, intuitively speaking, a 17% increase in gross profit seems much more realistic than one of 361%, and considering the facts noted in the simulation studies, our result would surely seem more convincing to domain users.",5.2. Predictive Price Optimization,[0],[0]
One of important remaining issues in real applications is the estimation of the confidence region.,5.2. Predictive Price Optimization,[0],[0]
"As noted above, we can never learn the value of f(ẑ, θ∗) without performing ẑ, but the user has to make a decision as to whether to perform it or not without knowing the value.",5.2. Predictive Price Optimization,[0],[0]
"In such a case, it would be helpful to provide a confidence region w.r.t.",5.2. Predictive Price Optimization,[0],[0]
"the bias-corrected optimal value, which is available with neither the CV method nor the perturbation method.",5.2. Predictive Price Optimization,[0],[0]
"In this paper, we have focused on the framework of a combination of mathematical optimization and machine learning with which we solve an optimization problem whose objective is formulated with the aid of predictive models or estimators.",6. Conclusion,[0],[0]
We have demonstrated that such a framework suffers from a kind of bias w.r.t. optimal values because of overfitting of the solution to the constructed objective function.,6. Conclusion,[0],[0]
We have proposed a solution to this bias problem by means of developed methods that are guaranteed to compute an asymptotically unbiased estimator of the value of the true objective function.,6. Conclusion,[0],[0]
"Empirical results have demonstrated that the proposed approach results in successful estimates of the value of the true objective function.
",6. Conclusion,[0],[0]
A major open question remaining in this work is how to evaluate and reduce variance in the estimators of objective functions.,6. Conclusion,[0],[0]
"The variance in estimators, i.e., uncertainty in estimation, is essential information for decision makers in many situations, and reducing variance in the estimator would help them make better decisions.",6. Conclusion,[0],[0]
"For data-driven decision-making, one promising approach, called predictive optimization, is to solve maximization problems i n which the objective function to be maximized is estimated from data.",abstractText,[0],[0]
"Predictive optimization, however, suffers from the problem of a calculated optimal solution’s being evaluated too optimistically, i.e., the value of the objective function is overestimated.",abstractText,[0],[0]
This paper investigates such optimistic bias and presents two methods for correcting it.,abstractText,[0],[0]
"The first, which is analogous to cross-validation, successfully corrects the optimistic bias but results in underestimation of the true value.",abstractText,[0],[0]
Our second method employs resampling techniques to avoid both overestimation and underestimation.,abstractText,[0],[0]
"We show that the second method, referred to as the parameter perturbation method, achieves asymptotically unbiased estimation.",abstractText,[0],[0]
Empirical results for both artificial and real-world datasets demonstrate that our proposed approach successfully corrects the optimistic bias.,abstractText,[0],[0]
Unbiased Objective Estimation in Predictive Optimization,title,[0],[0]
The advent of “big data” in recent years has generated countless opportunities for the prediction of real world phenomena with unprecedented accuracy and at unprecedented scale.,1 Introduction,[0],[0]
Statistical methods for prediction exploit associations in existing data to predict some response variable.,1 Introduction,[1.0],['Statistical methods for prediction exploit associations in existing data to predict some response variable.']
"However, the task at hand is often not to predict the response variable from pre-existing data, but rather to determine how a change in one or more of the explanatory variables will cause changes in the response variable.
1Department of Mathematics, University of Virginia, Charlottesville, VA 22904, USA 2Department of Computer Science, University of Virginia, Charlottesville, VA 22904, USA.",1 Introduction,[0],[0]
"Correspondence to: Quanquan Gu <qg5w@virginia.edu>.
",1 Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1 Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1 Introduction,[0],[0]
"In statistics, causality is often established by means of a controlled, randomized experiment.",1 Introduction,[0],[0]
"Nevertheless, controlled, randomized experiments are often infeasible, leaving researchers with only access to observational data.",1 Introduction,[0],[0]
This situation arises routinely when working with time series data.,1 Introduction,[0],[0]
"Areas that must cope with this obstacle frequently include genetics (Shojaie & Michailidis, 2010) and neuroscience (Seth et al., 2015).",1 Introduction,[0],[0]
The natural question that arises is: how can one determine which factors cause changes in a certain response variable using only data in which all variables change simultaneously?,1 Introduction,[0],[0]
"Causal inference seeks to address this problem.
",1 Introduction,[0.9999999967040806],['Causal inference seeks to address this problem.']
"The classic method for causal inference among time series is a concept from econometrics known as Granger causality, named after Nobel Prize winning econometrician Clive Granger (Granger, 1969).",1 Introduction,[1.0],"['The classic method for causal inference among time series is a concept from econometrics known as Granger causality, named after Nobel Prize winning econometrician Clive Granger (Granger, 1969).']"
"Granger causality formalizes the intuitive notion that in a causal system, the cause must precede the effect, and the cause must hold some unique information that helps predict the effect.",1 Introduction,[0],[0]
"For example, let X
1 , . . .",1 Introduction,[0],[0]
", X T and Y 1 , . . .",1 Introduction,[0],[0]
", Y T be two stationary one-dimensional time series.",1 Introduction,[0],[0]
"We can model time series Y using the following auto-regressive model (Stock & Watson, 2011):
Y t =
pX
i=1
a",1 Introduction,[0],[0]
i Y t,1 Introduction,[0],[0]
"i + ✏t, (1.1)
where a 1 , . .",1 Introduction,[0],[0]
.,1 Introduction,[0],[0]
", a p are the coefficient parameters for the regression, p < T is the maximal lag of the model, and ✏
t is the error term.",1 Introduction,[0],[0]
"To determine whether or not X is a Granger cause of Y , we also form a second auto-regressive model:
Y t =
pX
i=1
b",1 Introduction,[0],[0]
i Y t,1 Introduction,[0],[0]
"i +
pX
i=1
c",1 Introduction,[0],[0]
i X t,1 Introduction,[0],[0]
i + !,1 Introduction,[0],[0]
"t, (1.2)
with coefficient parameters b 1 , . . .",1 Introduction,[0],[0]
", b p , c 1 , . . .",1 Introduction,[0],[0]
", c p , and error term !
t .",1 Introduction,[0],[0]
"In this classical regime, where the number of observations exceeds the number of variables (T p > 2p), one can fit both of these models with ordinary least squares (OLS).",1 Introduction,[0],[0]
"We can conduct an F-test between models (1.1) and (1.2) as well as hypothesis tests on coefficients c
i , 1  i  p, to determine if the extra information encompassed by previous values of X significantly aides in the prediction of
future values of Y .",1 Introduction,[0],[0]
"If this pair of models passes the F-test and at least one of the coefficient hypothesis tests at some significance level ↵, then we may reject the null hypothesis that X is not a Granger cause of Y (Granger, 1969).
",1 Introduction,[1.0000000255649113],"['If this pair of models passes the F-test and at least one of the coefficient hypothesis tests at some significance level ↵, then we may reject the null hypothesis that X is not a Granger cause of Y (Granger, 1969).']"
"Although the concept of Granger causality has existed for decades, Granger (1969) only rigorously treated the bivariate case.",1 Introduction,[0],[0]
"However, as noted by Arnold et al. (2007), Eichler (2006) provided one framework for multivariate analysis by applying graphical models to Granger causal inference.
",1 Introduction,[0],[0]
"Multivariate Granger causal inference relies on hypothesis testing of model coefficients in a fitted vector-autoregressive (VAR) model (Lutkepohl, 2007).",1 Introduction,[0],[0]
VAR models are fit with OLS.,1 Introduction,[0],[0]
"In the high-dimensional regime, where the number of parameters exceeds the number of observations (T p < pd, where d is the number of time series in the VAR model), OLS estimation is impossible.",1 Introduction,[0],[0]
"Hence, one must employ regularized regression methods.",1 Introduction,[0],[0]
"Perhaps the most wellknown such method is the Lasso (Tibshirani, 1996), which encourages sparsity in the coefficient parameter vector via an `
1 penalty.",1 Introduction,[0],[0]
"To conduct Granger causal inference in the high-dimensional regime, Arnold et al. (2007) proposed the “Lasso Granger” estimator, which we fully specify in (3.3).",1 Introduction,[0],[0]
"Unfortunately, since the limiting distribution of the underlying Lasso estimator is not normal (Knight & Fu, 2000) and intractable in general (Javanmard & Montanari, 2014), one cannot construct confidence intervals or compute test statistics for hypothesis tests of Lasso Granger coefficient point estimates.",1 Introduction,[0],[0]
"Thus, existing methods for high-dimensional Granger causal inference do not allow for the assessment of uncertainty.",1 Introduction,[0],[0]
"Uncertainty characterization proves an important, and often necessary, element of research in the natural sciences.",1 Introduction,[0],[0]
"Therefore, uncertainty assessment techniques would augment the versatility of high-dimensional Granger causal inference methods, and drive their wider adoption by the scientific community.
",1 Introduction,[0],[0]
Another issue in high-dimensional causal inference is how to limit the number of false positives generated when testing a large number of explanatory variables without sacrificing identification of the true causal effects.,1 Introduction,[0],[0]
"That is, the researcher wants to attain high power while still maintaining a low type I error rate.",1 Introduction,[0],[0]
"To this end, false discovery rate (FDR) control (Benjamini & Hochberg, 1995) proves an important part of any method for high-dimensional causal inference.",1 Introduction,[0],[0]
"Unfortunately, existing FDR control methods cannot cope with the two challenges posed by our setting: dependent test statistics and dependent observations.",1 Introduction,[0],[0]
"These methods thus prove unsuitable in many practical applications.
",1 Introduction,[0],[0]
"In this paper, we make two contributions.",1 Introduction,[0],[0]
"First, we propose a novel asymptotically unbiased estimator for highdimensional Granger causal inference inspired by Javanmard & Montanari (2014).",1 Introduction,[0],[0]
"We leverage this estimator’s unbiasedness to construct confidence intervals and p-values
for coefficient point estimates.",1 Introduction,[0],[0]
"In this way, we allow, for the first time, uncertainty characterization in high-dimensional Granger causal inference.",1 Introduction,[0],[0]
"Second, we propose a novel FDR control technique that can cope with dependent test-statistics and dependent observations.",1 Introduction,[0],[0]
"In addition to surmounting these theoretical obstacles to existing methods, our FDR control technique also achieves higher power in multiple testing than existing methods.",1 Introduction,[0],[0]
"Additionally, the proof techniques we use to extend high-dimensional results from the independent and identically distributed (i.i.d.) setting to our time series setting are of independent interest.",1 Introduction,[0],[0]
"Specifically, to establish the asymptotic unbiasedness and normality of our estimator, we appeal to Talagrand’s generic chaining (Talagrand, 2006) and martingale theory.",1 Introduction,[0],[0]
"We further employ martingale theory, along with empirical process theory, to prove the asymptotic validity of our FDR control procedure.
",1 Introduction,[0],[0]
The rest of this paper is organized as follows.,1 Introduction,[0],[0]
Section 2 contextualizes our contributions in the existing literature.,1 Introduction,[0],[0]
Section 3 sets up the problem of high-dimensional Granger causal inference.,1 Introduction,[0],[0]
Section 4 presents our novel de-biased estimator and FDR control procedure.,1 Introduction,[0],[0]
"Section 5 establishes our main theoretical results, which we corroborate empirically in Section 6.",1 Introduction,[0],[0]
Section 7 concludes the paper.,1 Introduction,[0],[0]
"As mentioned above, Clive Granger examined bivariate Granger causality in 1969 (Granger, 1969).",2 Related Work,[0],[0]
"Advances in the area of graphical models provided a strong framework for multivariate causal inference in general (Pearl, 2009).",2 Related Work,[0],[0]
"Graphical models were first applied specifically to Granger causal inference by Eichler (2001) and Eichler (2006), and have provided a foundation for more complex models.
",2 Related Work,[0],[0]
"However, these methods rely on OLS estimation, which is impossible in the high-dimensional regime.",2 Related Work,[0],[0]
Meinshausen & Bühlmann (2006) applied Lasso to the estimation of highdimensional graphical models.,2 Related Work,[0],[0]
"Arnold et al. (2007) then applied the method proposed by Meinshausen & Bühlmann (2006) to multivariate Granger causal inference, and introduced the estimator of primary interest for this work: the Lasso Granger estimator.",2 Related Work,[0],[0]
"The Lasso Granger estimator yields a coefficient vector in which non-zero coefficients indicate conditional Granger causes of the response variable.
",2 Related Work,[0],[0]
Classical methods for uncertainty analysis prove impossible for the Lasso Granger estimator.,2 Related Work,[0],[0]
"Recent work (Lee et al., 2013; Lockhart et al., 2014; Taylor et al., 2014) in the area of high-dimensional inference has made great strides toward addressing this issue.",2 Related Work,[0],[0]
"Early work focussed on constructing pvalues and confidence intervals for Lasso coefficients via the bootstrap (Chatterjee et al., 2013; Liu et al., 2013a).",2 Related Work,[0],[0]
"However, later work found that these methods perform poorly compared to more recent methods (Dezeure et al., 2015), especially in non-i.i.d. settings (Karoui & Purdom, 2016).
",2 Related Work,[0],[0]
"Perhaps the most promising work in high-dimensional inference has emerged from the perspective of bias correction (Bühlmann et al., 2013; Zhang & Zhang, 2014).",2 Related Work,[0],[0]
Subsequent work by Van de Geer et al. (2014) and Javanmard & Montanari (2014) introduced a method to de-bias the Lasso solution to yield asymptotically valid confidence intervals and hypothesis tests for coefficient point estimates.,2 Related Work,[0],[0]
"Nevertheless, these existing methods assume that the observations forming the design matrix are independent, and so cannot tackle causal inference among time series.",2 Related Work,[0],[0]
Our method applies the Lasso de-biasing technique to the original Lasso Granger estimator.,2 Related Work,[0],[0]
We overcome the inability of existing methods to cope with non-i.i.d.,2 Related Work,[0],[0]
"data by using Talagrand’s generic chaining (Talagrand, 2006) and the martingale technique to derive the asymptotic distribution of our novel de-biased Lasso Granger estimator.
",2 Related Work,[0],[0]
Hypothesis testing in the high-dimensional setting raises the need for procedures to address the multiple testing problem.,2 Related Work,[0],[0]
FDR control is one such way to control type I error in multiple testing.,2 Related Work,[0],[0]
Our setting poses two challenges to existing FDR control procedures.,2 Related Work,[0],[0]
"First, the most-widely used methods, such as the Benjamini-Hochberg procedure (Benjamini & Hochberg, 1995), assume the test statistics under consideration are independent.",2 Related Work,[0],[0]
"While Benjamini & Yekutieli (2001) proposed a slight variation on the Benjamini-Hochberg procedure that could control FDR under “positive regression dependency” (e.g., when the covariance matrix of the explanatory variables is strictly positive), in our setting where the explanatory variables interact in complex ways, the test statistics will not satisfy this property.",2 Related Work,[0],[0]
"This version of the Benjamini-Hochberg procedure achieves only low power in the presence of a general dependence structure (Romano et al., 2008), and is thus unsuitable for our setting.",2 Related Work,[0],[0]
"Recent methods from the area of graphical models, which explicitly model the dependency of explanatory variables, have made progress in addressing the case of dependent test statistics (Xie et al., 2011; Liu et al., 2013b).",2 Related Work,[0],[0]
"However, these methods still encounter the second challenge of our setting: dependent observations arising from time series data.",2 Related Work,[0],[0]
"To control FDR for dependent observations, one must resort to assumption-free methods, such as the Bonferroni technique, that achieve low power in practice.",2 Related Work,[0],[0]
"We propose a FDR control procedure that can cope with dependent test statistics and observations, and that achieves high power.
",2 Related Work,[0],[0]
Notation We denote matrix A,2 Related Work,[0],[0]
"= [A i,j ] 2 Rm⇥n and column vector v =",2 Related Work,[0],[0]
"[v
i ] 2 RT .",2 Related Work,[0],[0]
"We write the ` p
norm of vector v as kvk
p
= ⌃
i=T
i=1
|v i |p.",2 Related Work,[0],[0]
"Furthermore, kvk1 denotes the max-norm of vector v: kvk1 = max1iT |vi|.",2 Related Work,[0],[0]
"Additionally, kvk
0 = supp(v) designates the cardinality of the support (the set of all non-zero entries) of v. We represent the the max-norm of matrix A as kAk1 = maxi,j |Ai,j |.",2 Related Work,[0],[0]
"The minimum and maximum singular values of A are denoted by
min (A) and max (A), respectively.",2 Related Work,[0],[0]
"(x) ⌘
(1/ p 2⇡) R x
1 e t2/2dt refers to the cumulative distribu-
tion function of the standard normal distribution.",2 Related Work,[0],[0]
"For a random variable X and a sequence of random variables X
n , we write X n P ! X",2 Related Work,[0],[0]
"if X n
converges in probability to X , and X
n D ! X",2 Related Work,[0],[0]
"if X n
converges in distribution to X .",2 Related Work,[0],[0]
"For sequences of random variables X
n and Y n , we say X
n ⇣ Y n if X n has the “same asymptotic order” as Y n
, that is, if both sequences bound each other up to some universal multiplicative constant.",2 Related Work,[0],[0]
"In this section, we set up the problem of high dimensional Granger causal inference.",3 Granger Causality and its Estimator,[0],[0]
"Denote the design matrix X, the number of parameters d, the number of observations T , and the maximal lag p.",3 Granger Causality and its Estimator,[0],[0]
For a given design matrix X =,3 Granger Causality and its Estimator,[0],[0]
"[X
t,j ] 2 RT⇥d define the sample covariance matrix b⌃ = X>X/T 2 Rd⇥d.",3 Granger Causality and its Estimator,[0],[0]
"The j-th column of X represents time series X
j , 1  j  d.",3 Granger Causality and its Estimator,[0],[0]
"We can further denote lagged versions of each column in the design matrix with fX
t,j
=
(X t p,j , Xt p+1,j , . . .",3 Granger Causality and its Estimator,[0],[0]
",",3 Granger Causality and its Estimator,[0],[0]
"Xt 1,j)> 2",3 Granger Causality and its Estimator,[0],[0]
Rp.,3 Granger Causality and its Estimator,[0],[0]
"Note that Xt 1,j represents the observation immediately before X t,j
in time series X
j .",3 Granger Causality and its Estimator,[0],[0]
"In Granger causal analysis, the response variable is one of the explanatory variables.",3 Granger Causality and its Estimator,[0],[0]
"Hence, we can model an arbitrary variable X
t,j , with 1  j  d and p+ 1  t  T , by using the lagged values of all explanatory variables as predictors:
X t,j =
dX
i=1
✓ j⇤> i f X t,i + ✏ t,j .",3 Granger Causality and its Estimator,[0],[0]
"(3.1)
",3 Granger Causality and its Estimator,[0],[0]
"Here ✓j⇤ i 2 Rp and ✏ t,j ⇠ N(0, 2 j ).",3 Granger Causality and its Estimator,[0],[0]
"Time series X i is a conditional Granger cause of time series X j
(conditioned on the other d - 2 time series) if ✓j⇤
i contains any non-zero elements (i.e., k✓j⇤
i
k 0
> 0).",3 Granger Causality and its Estimator,[1.0000000365074482],"['Time series X i is a conditional Granger cause of time series X j (conditioned on the other d - 2 time series) if ✓j⇤ i contains any non-zero elements (i.e., k✓j⇤ i k 0 > 0).']"
"We can vectorize the sets of all ✓j⇤
i
and all fX t,i , for 1  i  d, as ✓j⇤ = (✓j⇤>
1 ,✓j⇤> 2 , . . .",3 Granger Causality and its Estimator,[0],[0]
",✓j⇤> d )",3 Granger Causality and its Estimator,[0],[0]
"> 2 Rpd and fX t =
( f X > t,1 , fX> t,2 , . . .",3 Granger Causality and its Estimator,[0],[0]
", fX> t,d )",3 Granger Causality and its Estimator,[0],[0]
"> 2 Rpd, respectively.",3 Granger Causality and its Estimator,[0],[0]
"Based on (3.1), the Lasso Granger estimator (Arnold et al., 2007) is given by
b ✓ j = argmin
✓j
1 2(T p) TX
t=p+1
(X t,j ✓j>fX t ) 2 + k",3 Granger Causality and its Estimator,[0],[0]
"✓jk 1 ,
where > 0 is the regularization parameter.
",3 Granger Causality and its Estimator,[0],[0]
"Equivalently, letting eX = (fX p+1 , fX p+2 , . . .",3 Granger Causality and its Estimator,[0.960897083639226],"['Equivalently, letting eX = (fX p+1 ,fX p+2 , .']"
", fX T )",3 Granger Causality and its Estimator,[0],[0]
"> 2 R(T p)⇥pd and Y
j = X p+1:T,j represent the lower T p elements of the j-th column of X , we can re-express our model in more standard notation as:
Y
j
= eX✓j⇤ + ✏, (3.2)
where ✏ ⇠ N(0, 2I (T p)⇥(T p)).",3 Granger Causality and its Estimator,[0.9978790355604298],"[',fX T ) > 2 R(T p)⇥pd and Y j = X p+1:T,j represent the lower T p elements of the j-th column of X , we can re-express our model in more standard notation as: Y j = eX✓j⇤ + ✏, (3.2) where ✏ ⇠ N(0, 2I (T p)⇥(T p)).']"
"We can now re-express
the Lasso Granger estimator as:
b ✓ j = argmin
✓j
",3 Granger Causality and its Estimator,[0],[0]
1 2(T p)kYj eX✓jk2 2 + k✓jk 1 .,3 Granger Causality and its Estimator,[0],[0]
"(3.3)
",3 Granger Causality and its Estimator,[0],[0]
"For ease of presentation, we will henceforth omit the identifying variable j from ✓j⇤, b✓j , and Y
j , and assume we are referring to some arbitrary response variable.",3 Granger Causality and its Estimator,[0],[0]
"Using the above notation, we can now denote the sample covariance matrix of eX as e⌃
n
= eX> eX/(T p) 2 Rpd⇥pd and the true covariance matrix as e⌃ = E[e⌃
n
].",3 Granger Causality and its Estimator,[0],[0]
"In this section, we introduce our de-biased Lasso Granger estimator, and construct confidence intervals and p-values for its elements.",4 Asymptotic Inference for Lasso Granger,[0],[0]
We will then present our method for false discovery rate control in multiple testing.,4 Asymptotic Inference for Lasso Granger,[0],[0]
"In deriving a de-biased version of the Lasso Granger estimator, we employ a variation of the Lasso de-biasing procedure proposed by Javanmard & Montanari (2014).",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"In particular, we define the de-biased Lasso Granger estimator b✓u as follows:
",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"b ✓ u = b ✓ + 1 T pM eX>(Y eXb✓), (4.1)
where b✓ 2 Rpd is the parameter vector yielded when computing the Lasso Granger estimator (3.3) for an arbitrary response variable Y = Y
j .",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"M = (m 1 ,m 2 , . . .",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
",m pd )",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"> 2 Rpd⇥pd is an estimate of e⌃ 1
n , the inverse sample covariance matrix of eX, where each m
i is the solution to the following optimization algorithm:
minimize m> e⌃ n m subject to ke⌃ n",4.1 Confidence Intervals and Hypothesis Tests,[0.9677262169669854],"[',m pd ) > 2 Rpd⇥pd is an estimate of e⌃ 1 n , the inverse sample covariance matrix of eX, where each m i is the solution to the following optimization algorithm: minimize m> e⌃ n m subject to ke⌃ n m e i k1  µ, (4.2) where e i 2 Rpd is the i-th column of I pd⇥pd, and the choice of µ will be clear after we deliver theory.']"
"m e i k1  µ, (4.2)
where e i 2 Rpd is the i-th column of I pd⇥pd, and the choice of µ will be clear after we deliver theory.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Our unbiased estimator b✓u, though inspired by Javanmard & Montanari (2014), diverges sharply from their work in several respects.",4.1 Confidence Intervals and Hypothesis Tests,[1.0],"['Our unbiased estimator b✓u, though inspired by Javanmard & Montanari (2014), diverges sharply from their work in several respects.']"
"While Javanmard and Montanari use the observed design matrix X in their estimator, we use the transformed design matrix eX.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Although in our time series setting the rows of design matrix X are already dependent, transforming X to eX exacerbates this dependency and renders the i.i.d. results underpinning Javanmard and Montanari’s work unusable.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Hence, we appeal to Talagrand’s generic chaining (Talagrand, 2006) and martingale theory to establish our theoretical results about b✓u.
Theorem 5.5 in Section 5 below proves that for any i 2 {1, 2, . . .",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
", pd}, the standardized estimate of the i-th element
of b✓u converges in distribution to the standard normal distribution:
p T p
b✓u i ✓",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
⇤,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"i
[Me⌃ n",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
M>]1/2,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"i,i
D !",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"N(0, 1).",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"(4.3)
Unfortunately, the true noise level, denoted here by , is unknown in most real-world applications.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Hence, we replace with a consistent estimator, denoted b , yielded by the Scaled Lasso (Sun & Zhang, 2012):
{b✓( ), b ( )} =
argmin
✓2Rpd, >0
⇢ 1
2 (T P )kY eX",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"✓k2 2 + 2 + k✓k 1 ,
(4.4)
where is the regularization parameter.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
Sun & Zhang (2012) prove b is a consistent estimator of when the penalized loss function is convex.,4.1 Confidence Intervals and Hypothesis Tests,[1.0],['Sun & Zhang (2012) prove b is a consistent estimator of when the penalized loss function is convex.']
Sun & Zhang (2012) use the i.i.d assumption to establish convexity.,4.1 Confidence Intervals and Hypothesis Tests,[1.0],['Sun & Zhang (2012) use the i.i.d assumption to establish convexity.']
"In our non-i.i.d. setting, we establish convexity via a restricted eigenvalue condition for martingale difference sequences.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Thus, b is consistent in our setting as well.",4.1 Confidence Intervals and Hypothesis Tests,[1.0],"['Thus, b is consistent in our setting as well.']"
"Then by the Slutsky Theorem (Van der Vaart, 2000), we can replace in (4.3) with b .
",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"One can easily apply (4.3) to construct confidence intervals for ✓⇤
i , for 1  i  pd.",4.1 Confidence Intervals and Hypothesis Tests,[0.9999999543046278],"['One can easily apply (4.3) to construct confidence intervals for ✓⇤ i , for 1  i  pd.']"
"If the significance level is ↵ > 0, the 1 ↵ confidence interval for ✓⇤
i
is:
I i =",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"[ b✓u i
(↵, T p), b",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"✓u i
+ (↵, T p)], (4.5) where
(↵, T p) = 1(1 ↵/2)(b /pT p)[Me⌃ n",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
M>]1/2,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"i,i .
",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"We prove the asymptotic validity of this confidence interval in Corollary 5.6.
",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Similarly, we can also conduct hypothesis tests on the individual regression coefficients ✓⇤
i , for 1  i  pd.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"In the context of Granger causality, the relevant null and alternative hypotheses are Hi
0 :",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"✓⇤ i = 0 and Hi a : ✓⇤ i 6= 0, respectively.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
Having zero-coefficients for all variables p(x 1) <,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
i  px implies that time series 1  x  d is not a conditional Granger cause of the response time series.,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Conversely, rejecting Hi
0 for any variable p(x 1)",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
<,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
i  px amounts to rejecting the null hypothesis that time series x is not a Granger cause of the response time series.,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"We thus consider the following test statistic for Hi
0 :",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"✓⇤ i = 0:
cZ i =
b✓u i
p T p
b",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
[Me⌃ n,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
M>]1/2,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"i,i
.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"(4.6)
Note that under the null hypothesis cZ",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
i D !,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"N(0, 1) by (4.3).",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"The hypothesis test at significance level ↵ is thus given by
Z (↵) = 1( |cZ i | < z ↵/2 ), (4.7)
where z ↵/2 is the quantile of the standard normal distribution such that (z
↵/2 )",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
= ↵/2.,4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"We reject the null hypothesis if and only if
Z (↵) = 1.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"The p-value for this hypothesis test is
P i = 2(1 (|cZ i |)).",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"(4.8) As usual, one would reject Hi
0 at a pre-specified significance level ↵ if P
i < ↵.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"We establish that the type I error of the hypothesis test
Z (↵) converges to the specified significance level, and that the p-value P
i is asymptotically uniformly distributed in Corollary 5.7.",4.1 Confidence Intervals and Hypothesis Tests,[0],[0]
"Having established test statistics for individual coefficients of the de-biased Lasso Granger estimator, we now address the issue of FDR control.",4.2 False Discovery Rate Control,[1.0],"['Having established test statistics for individual coefficients of the de-biased Lasso Granger estimator, we now address the issue of FDR control.']"
"First, denote the set of coefficient indices i such that ✓⇤
i
= 0",4.2 False Discovery Rate Control,[0],[0]
"as H 0 = {i|✓⇤ i = 0, 1  i  pd}.",4.2 False Discovery Rate Control,[0],[0]
"Define the complement of this set as H
1 = {i|✓⇤ i 6= 0, 1  i  pd}.",4.2 False Discovery Rate Control,[0],[0]
"We define FDR and false discovery proportion (FDP) as follows:
FDP(⌫) =",4.2 False Discovery Rate Control,[0],[0]
P i2H 0,4.2 False Discovery Rate Control,[0],[0]
1(|cZ,4.2 False Discovery Rate Control,[0],[0]
"i
| ⌫)",4.2 False Discovery Rate Control,[0],[0]
"max{P 1jpd 1(|cZi| ⌫), 1} ,
FDR(⌫) = E[FDP(⌫)].
",4.2 False Discovery Rate Control,[0],[0]
When conducting hypothesis tests at significance 0,4.2 False Discovery Rate Control,[0],[0]
<,4.2 False Discovery Rate Control,[0],[0]
"↵ < 1, we seek the smallest ⌫ such that FDR(⌫)  ↵.",4.2 False Discovery Rate Control,[0],[0]
"In this way, we will be able to reject the null hypothesis as often as possible (i.e., we maximize power) while still guaranteeing that our type I error rate does not exceed ↵.",4.2 False Discovery Rate Control,[0],[0]
"Thus, the ideal choice of ⌫ is
b⌫ = inf ⇢ ⌫",4.2 False Discovery Rate Control,[0],[0]
> 0,4.2 False Discovery Rate Control,[0],[0]
":
P i2H
0
1{|cZ",4.2 False Discovery Rate Control,[0],[0]
"i | ⌫} max{P 1jpd 1{|cZj | ⌫}, 1}  ↵ .
(4.9)
Note that the left hand side of the inequality in (4.9) is FDP, whose expectation is FDR.",4.2 False Discovery Rate Control,[0],[0]
"Unfortunately, b⌫ cannot be computed under the unknown H
0",4.2 False Discovery Rate Control,[0],[0]
"(Liu et al., 2013b).",4.2 False Discovery Rate Control,[0],[0]
"However, following Liu & Luo (2014), we use the asymptotic normality of cZ
i under the null hypothesis to approximateP i2H
0
1{|cZ",4.2 False Discovery Rate Control,[0],[0]
i | ⌫} by 2(1 (⌫))pd.,4.2 False Discovery Rate Control,[0],[0]
"In multiple hypothesis testing, we use b⌫ as the threshold for rejecting the null hypothesis, instead of z
↵/2
, in hypothesis test Z (↵) (4.7).",4.2 False Discovery Rate Control,[0],[0]
Theorem 5.9 below demonstrates the asymptotic validity of this FDR control method.,4.2 False Discovery Rate Control,[0],[0]
"In this section we present our main theoretical results: the test statistic cZ
i from (4.6) converges in distribution to the standard normal under the null hypothesis, and the FDR control procedure presented in (4.9) asymptotically controls both FDR and FDP.",5 Main Theory,[0.9999999301127351],"['In this section we present our main theoretical results: the test statistic cZ i from (4.6) converges in distribution to the standard normal under the null hypothesis, and the FDR control procedure presented in (4.9) asymptotically controls both FDR and FDP.']"
"To begin, we present several definitions.
",5 Main Theory,[0],[0]
Definition 5.1.,5 Main Theory,[0],[0]
"(Vershynin, 2012)",5 Main Theory,[0],[0]
A random variable X is sub-Gaussian if there exists a constant C > 0,5 Main Theory,[0],[0]
"such that
P(|X|",5 Main Theory,[0],[0]
"> t)  2 exp[ t2/C2], for all t > 0.
",5 Main Theory,[0],[0]
"A random vector X 2 Rn is sub-Gaussian if the onedimensional marginals < X,v > are sub-Gaussian random variables for all v 2 Rn.",5 Main Theory,[0],[0]
Definition 5.2.,5 Main Theory,[0],[0]
"(Javanmard & Montanari, 2014)",5 Main Theory,[0],[0]
"The subGaussian norm of a random scalar variable X is:
kXk
2
= sup q 1 q 1/2(E[|X|q])1/q.
",5 Main Theory,[0],[0]
"The sub-Gaussian norm of a random vector X 2 Rn is: kXk
2
= sup u2Sn 1 khX,uik 2 ,
where Sn 1 is the unit sphere in Rn space.
",5 Main Theory,[0],[0]
"Having established these definitions, we impose two assumptions on the design matrix and the true covariance matrix of the design matrix.",5 Main Theory,[0],[0]
Assumption 5.3.,5 Main Theory,[0],[0]
"There exist universal constants C
min , C max such that 0 < C min  min ( e⌃)  ",5 Main Theory,[0],[0]
max ( e⌃)  C max .,5 Main Theory,[0],[0]
Assumption 5.4.,5 Main Theory,[0],[0]
"The rows of eX are sub-Gaussian and the sub-Gaussian norm of each row is bounded by some constant  so that kfX
i
k
2  , for i 2 {1, 2, . . .",5 Main Theory,[0],[0]
", T p}.",5 Main Theory,[0],[0]
"We use Assumption 5.3 to demonstrate that the restricted eigenvalue condition holds for e⌃
n in order to prove the asymptotic unbiasedness of b✓u. Assumption 5.4 plays a role at multiple stages of the proof of Theorem 5.5, including proving the restricted eigenvalue condition for e⌃
n and establishing a high-probability bound for the regularization parameter .",5 Main Theory,[0],[0]
"Both of these assumptions prove common in the high-dimensional inference literature.
",5 Main Theory,[0],[0]
We leverage Assumptions 5.3 and 5.4 to present the following theorem.,5 Main Theory,[0],[0]
Theorem 5.5.,5 Main Theory,[0],[0]
Suppose Assumptions 5.3 and 5.4 are satisfied.,5 Main Theory,[0],[0]
"Let s
0 = supp(✓⇤) ⇣ pT p/ log(pd) and µ ⇣ plog(pd)/(T p).",5 Main Theory,[0],[0]
"Then for any element b✓u
i of the de-biased Lasso Granger estimator b✓u defined in (4.1), we have
p T p
b✓u i ✓⇤ i
[Me⌃ n",5 Main Theory,[0],[0]
M>]1/2,5 Main Theory,[0],[0]
"i,i
D !",5 Main Theory,[0],[0]
"N(0, 1).
",5 Main Theory,[0],[0]
Theorem 5.5 immediately yields several useful results.,5 Main Theory,[0],[0]
"We first demonstrate the asymptotic validity of confidence interval (4.5) for any element of b✓u in the following corollary.
",5 Main Theory,[0],[0]
Corollary 5.6.,5 Main Theory,[0],[0]
"Denote significance level ↵ > 0, and for 1  i  pd, define interval",5 Main Theory,[0],[0]
"I
i
=",5 Main Theory,[0],[0]
"[ b✓u i
(↵, T p), b",5 Main Theory,[0],[0]
"✓u
i + (↵, T p)].",5 Main Theory,[0],[0]
"Here, (↵, T p) = (1 ↵/2)( / p T p)[Me⌃
n",5 Main Theory,[0],[0]
M>]1/2,5 Main Theory,[0],[0]
"i,i .",5 Main Theory,[0],[0]
"Then
lim T p!1 P(✓⇤ i 2",5 Main Theory,[0],[0]
I i ),5 Main Theory,[0],[0]
"= 1 ↵.
",5 Main Theory,[0],[0]
"By Corollary 5.6, the asymptotic coverage probability corresponds the the given confidence level.",5 Main Theory,[0],[0]
Note that we can replace with b by the Slutsky Theorem.,5 Main Theory,[0],[0]
"Similarly, we confirm in the following corollary that the type I error for hypothesis test
Z (↵), introduced in (4.7), matches the given significance level ↵.",5 Main Theory,[0],[0]
"Furthermore, we prove that the CDF of the p-value P
i for Z (↵), which we introduced in (4.8), converges in distribution to a uniform distribution.",5 Main Theory,[0],[0]
Corollary 5.7.,5 Main Theory,[0],[0]
"With
Z (↵) and P i defined as above, and significance level ↵ > 0, we have:
P( Z (↵) = 1|Hi 0 )",5 Main Theory,[0],[0]
(T p)!1 !,5 Main Theory,[0],[0]
↵ and P i D !,5 Main Theory,[0],[0]
U,5 Main Theory,[0],[0]
"[0, 1].
We now turn our attention to demonstrating the asymptotic validity of the FDR control method we present in Section 4.2.",5 Main Theory,[0],[0]
"To control FDR we desire the following property:
P i2H
0
1(|cZ",5 Main Theory,[0],[0]
"i | b⌫) 2|H
0
|(1 (b⌫))",5 Main Theory,[0],[0]
P !,5 Main Theory,[0],[0]
"1. (5.1)
",5 Main Theory,[0],[0]
"Unfortunately, in this application, the test statistics cZ",5 Main Theory,[0],[0]
"i
are correlated, rendering the convergence in (5.1) non-trivial.",5 Main Theory,[0],[0]
"In order to prove (5.1), we will leverage martingale theory, empirical process theory, and the following assumption.",5 Main Theory,[0],[0]
Assumption 5.8.,5 Main Theory,[0],[0]
"For constant c > 2,
X
i2H 1
1
✓ |✓⇤ i
| e⌃ 1/2
i,i
s
c log(pd) (T p) ◆ !",5 Main Theory,[0],[0]
"1,
as (T p, pd) !",5 Main Theory,[0],[0]
1.,5 Main Theory,[0],[0]
Assumption 5.8 implies that the number of true alternative hypotheses approaches infinity.,5 Main Theory,[0],[0]
"This property proves important because, as demonstrated by Liu et al. (2014), FDR control is impossible when the number of true alternative hypotheses is fixed.",5 Main Theory,[0],[0]
This assumption allows us to present the following theorem: Theorem 5.9.,5 Main Theory,[0],[0]
Assume pd  (T p)r and log(pd) = o,5 Main Theory,[0],[0]
( p T p) for some r > 0.,5 Main Theory,[0],[0]
"Furthermore, suppose that Assumption 5.8 and the assumptions of Theorem 5.5 hold.",5 Main Theory,[0],[0]
"Then at significance level ↵,
lim (T p,pd) FDR(b⌫) ↵|H 0 |/(pd) = 1 and FDP(b⌫) ↵|H 0 |/(pd) P ! 1,
as (T p, pd) !",5 Main Theory,[0],[0]
"1.
Theorem 5.9 establishes that the FDR control procedure we present in Section 4.2 asymptotically controls both FDR and FDP.",5 Main Theory,[0],[0]
Note that the upper bound rate imposed on pd is very mild and will pose no issues in the vast majority of applications.,5 Main Theory,[0],[0]
"The assumptions of Theorem 5.5 guarantee the asymptotic normality of test statistic cZ
i
.",5 Main Theory,[0],[0]
"In this section, we establish the effectiveness of our debiased Lasso Granger estimator and our FDR control procedure via experimental results.",6 Numerical Experiments,[0],[0]
We also demonstrate that our methods outperform existing techniques.,6 Numerical Experiments,[0],[0]
"In this section, we corroborate our theoretical results and compare our contributions to existing methods with numerical experiments on synthetic data.",6.1 Synthetic Data,[0],[0]
The data for these experiments are generated by model (3.1).,6.1 Synthetic Data,[0],[0]
"In order to satisfy the assumptions of Theorem 5.5, each ✓j⇤ is a sparse vector such that the probability of each element being non-zero is p T p/(2pd log(pd)) for 1  j  d. We use the R package“flare” (Li et al., 2012) to generate sparse transition matrices, and the “glmnet” package (Friedman et al., 2010) to compute the biased Lasso Granger estimate.",6.1 Synthetic Data,[0],[0]
"We examine multiple different transition matrix patterns (“random” and “cluster”, as generated by the “flare” package) and multiple different configurations of (T, d, p).
",6.1 Synthetic Data,[0],[0]
"In Table 1, we see that the empirical type 1 error of hypothesis test
Z (↵) (4.7) corresponds to the given significance level across multiple configurations of (T, d, p).",6.1 Synthetic Data,[0],[0]
"Figure 1(a) corroborates Theorem 5.5 by demonstrating that the empirical distribution of test statistic cZ
i under the null hypothesis is the standard normal distribution.",6.1 Synthetic Data,[0],[0]
Figure 1(a) also illustrates that coefficient point estimates for the biased Lasso Granger estimator do not follow the standard normal distribution.,6.1 Synthetic Data,[0],[0]
Figure 1(b) validates Corollary 5.7 by demonstrating that the empirical CDF of p-value (4.8) for a true zero parameter is the uniform distribution.,6.1 Synthetic Data,[0],[0]
"Furthermore, Figures 1(c) and 1(d) exhibit that hypothesis test
Z (↵) (4.7) attains higher power than the biased Lasso Granger estimator when testing a single true non-zero parameter.",6.1 Synthetic Data,[0],[0]
"Table 2 demonstrates the accuracy of the de-biased Lasso Granger estimator via computations of the `
1 and ` 2 norms of the
error vector between b✓u and ✓⇤.
",6.1 Synthetic Data,[0],[0]
"Table 3 exhibits that, as suggested by theory, our FDR control procedure outperforms the Bonferroni and BenjaminiHochberg (B-H) (Benjamini & Hochberg, 1995; Benjamini & Yekutieli, 2001) methods in terms of power, while still maintaining low FDP.",6.1 Synthetic Data,[0],[0]
"While the Bonferroni method generally achieves only low power, the Benjamini-Hochberg method performs poorly in this application because the test statistics exhibit complex dependency, and thus violate a theoretical assumption of the Benjamini-Hochberg method.
",6.1 Synthetic Data,[0],[0]
"Lastly, Figure 2 demonstrates that our de-biased Lasso Granger estimator paired with our FDR control procedure outperform the original biased Lasso Granger estimator in terms of precision and recall.",6.1 Synthetic Data,[0],[0]
"Define sets TP = {i 2 H
1 |1(✓⇤ i identified as non-zero)} and FP = {i 2 H
0 |1(✓⇤ i identified as non-zero)}, so precision is |TP|/max{|TP| + |FP|, 1}, and recall is |TP|/|H
1 |.",6.1 Synthetic Data,[0],[0]
Note that precision is equivalent to 1 FDP and recall is equivalent to power.,6.1 Synthetic Data,[0],[0]
We calculate precision and recall at each point along the Lasso-path of the regularization parameter to generate the curves in Figure 2.,6.1 Synthetic Data,[0],[0]
These curves demonstrate that our de-biased Lasso Granger estimator and FDR control procedure achieve higher recall than the original Lasso Granger estimator without sacrificing precision.,6.1 Synthetic Data,[1.0],['These curves demonstrate that our de-biased Lasso Granger estimator and FDR control procedure achieve higher recall than the original Lasso Granger estimator without sacrificing precision.']
"Thus, not only does our method provide the interpretability and flexibility of uncertainty characterization, it also achieves higher power
than the original Lasso Granger estimator while maintaining low FDP.",6.1 Synthetic Data,[0],[0]
"Therefore, our method proves more suitable for high-dimensional Granger causal inference.",6.1 Synthetic Data,[0],[0]
"To demonstrate the applicability of our method to real-world data, we consider the climatological data set made available by Lozano et al. (2009).",6.2 Real Data,[0],[0]
"This data set contains monthly observations for seventeen climatological variables (e.g., temperature, precipitation, CO2, CH4, etc.) for 128 grid points spanning the continental United States (latitudes 32.975 to 45.475 and longitudes 84.75 to 117.25) from 1990 to
2002.",6.2 Real Data,[0],[0]
"Following the setup from Lozano et al. (2009), we enforce stationarity by deseasonlaizing the data using the R package “deseasonalize” (McLeod & Gweon, 2013).",6.2 Real Data,[1.0],"['Following the setup from Lozano et al. (2009), we enforce stationarity by deseasonlaizing the data using the R package “deseasonalize” (McLeod & Gweon, 2013).']"
We model the monthly temperature change of each grid point as a linear model of the first three lagged values of all explanatory variables in the surrounding 3⇥ 3 grid.,6.2 Real Data,[0],[0]
"Thus, for each of the 81 interior grid points, we obtain design matricies with dimensions T = 13⇥ 12 = 156 (13 years of monthly data), d = 17 ⇥ 9 = 153 (17 climatological variables observed at 9 grid points), and p = 3.",6.2 Real Data,[0],[0]
"For each of these design matricies, we use the R package “glmnet”(Friedman et al., 2010) to produce the biased Lasso Granger estimate from (3.3), and then apply (4.1) to construct the de-biased Lasso Granger estimate.
",6.2 Real Data,[0],[0]
"For each grid point, we test the significance of the three lagged values of monthly changes in Carbon Dioxide (CO2) emissions for that grid point to determine if local CO2 emissions are a Granger cause of temperature changes when conditioned on many other climatological variables.",6.2 Real Data,[1.0],"['For each grid point, we test the significance of the three lagged values of monthly changes in Carbon Dioxide (CO2) emissions for that grid point to determine if local CO2 emissions are a Granger cause of temperature changes when conditioned on many other climatological variables.']"
Recall that an explanatory variable is a Granger cause of the response variable if and only if any of the coefficients for any of the lags prove significant.,6.2 Real Data,[0],[0]
"We use the Bonferroni method, the Benjamini-Hochberg (B-H) procedure, and our FDR control method from Section 4.2 to control for multiple testing.",6.2 Real Data,[0],[0]
"At significance level ↵ = .05, the Bonferroni and Benjamini-Hochberg methods found that CO2 emissions are a Granger cause of monthly temperature changes for 10 of the 81 grid points, whereas our FDR control method discovered 13 such grid points.",6.2 Real Data,[1.0],"['At significance level ↵ = .05, the Bonferroni and Benjamini-Hochberg methods found that CO2 emissions are a Granger cause of monthly temperature changes for 10 of the 81 grid points, whereas our FDR control method discovered 13 such grid points.']"
"We thus corroborate the findings of Lozano et al. (2009), who employed graphical Granger modeling methods to establish Granger causality between CO2 emissions and temperature changes, and those of many climate researchers who have found increased CO2 emissions to “cause” higher temperatures.",6.2 Real Data,[1.0],"['We thus corroborate the findings of Lozano et al. (2009), who employed graphical Granger modeling methods to establish Granger causality between CO2 emissions and temperature changes, and those of many climate researchers who have found increased CO2 emissions to “cause” higher temperatures.']"
We also find empirical evidence that our FDR control method achieves higher power than the Bonferroni and Benjamini-Hochberg methods.,6.2 Real Data,[1.0],['We also find empirical evidence that our FDR control method achieves higher power than the Bonferroni and Benjamini-Hochberg methods.']
Figure 3 displays the results of this simulation.,6.2 Real Data,[0],[0]
"In this paper, we propose a novel unbiased estimator for conducting Granger causal inference in the high-dimensional
(a) Bonferroni, B-H (b) FDR Control
regime.",7 Conclusion,[0],[0]
"We introduce test statistics and confidence intervals for our estimator, thereby accomplishing the previously impossible task of uncertainty characterization in high-dimensional Granger causal inference.",7 Conclusion,[0],[0]
"Additionally, we introduce a novel method for false discovery rate control that achieves higher-power in multiple testing than existing alternatives in our setting.",7 Conclusion,[0],[0]
"Lastly, we validate our theoretical results with experiments on both synthetic data and real-world climatological data.",7 Conclusion,[1.0],"['Lastly, we validate our theoretical results with experiments on both synthetic data and real-world climatological data.']"
Future extensions of our work may include generalizations of our method to cope with non-Gaussian noise and non-linear causality.,7 Conclusion,[1.0],['Future extensions of our work may include generalizations of our method to cope with non-Gaussian noise and non-linear causality.']
We would like to thank the anonymous reviewers for their helpful comments.,Acknowledgements,[0],[0]
This research was sponsored in part by the National Science Foundation IIS-1618948 and IIS1652539.,Acknowledgements,[0],[0]
The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies.,Acknowledgements,[0],[0]
Causal inference among high-dimensional time series data proves an important research problem in many fields.,abstractText,[0],[0]
"While in the classical regime one often establishes causality among time series via a concept known as “Granger causality,” existing approaches for Granger causal inference in high-dimensional data lack the means to characterize the uncertainty associated with Granger causality estimates (e.g., p-values and confidence intervals).",abstractText,[0],[0]
We make two contributions in this work.,abstractText,[0],[0]
"First, we introduce a novel asymptotically unbiased Granger causality estimator with corresponding test statistics and confidence intervals to allow, for the first time, uncertainty characterization in high-dimensional Granger causal inference.",abstractText,[0],[0]
"Second, we introduce a novel method for false discovery rate control that achieves higher power in multiple testing than existing techniques and that can cope with dependent test statistics and dependent observations.",abstractText,[0],[0]
We corroborate our theoretical results with experiments on both synthetic data and real-world climatological data.,abstractText,[0],[0]
Uncertainty Assessment and False Discovery Rate Control in High-Dimensional Granger Causal Inference,title,[0],[0]

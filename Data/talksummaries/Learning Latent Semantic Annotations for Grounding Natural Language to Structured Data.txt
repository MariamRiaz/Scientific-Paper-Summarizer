0	16	The meaning of natural language should always be accompanied by a context.
13	12	Such kind of language grounding is important both for natural language understanding and for natural language generation.
19	13	Specifically, we conduct our study on a recently released dataset of descriptions for NBA basketball games with structured tables of game records.
25	25	These labels could be executed to establish direct correspondences to one or more values in the structured table.
67	13	What we are more interested in is where the phrase edge out comes from.
87	42	For example, the tag Team City is used to extract the name of the team in the table that corresponds to the current word span.
89	34	3 For example, the tag Team Points Delta can be executed to return the score difference between two teams.
91	32	Along with all these tags derived from the original data fields, we also include a special NULL tag which are supposed to be assigned to non-informative words or words containing information not contained in the given table.
93	23	We simply over-generate all possible labels, and let the model figure out which part of them should be eventually used.
94	12	Although the only compositional operation we used in this work is numeric subtraction, common operations that could produce string, categorical values or numbers could be easily introduced for other domains.
98	18	One is salience that captures the intuition that some fields should be more frequently mentioned than others (henceforth some latent tags should be more frequently triggered).
100	10	To capture these two phenomena, we define a Markov model: Ps(c, l) = ∏ t P (lt|lt−1) · Ps(ct|lt), where lt is the annotated label at time stamp t, and we assume that the transition probabilities are independent of world state s. It resembles a standard form of HMMs, despite the subscript s in Ps(c|l).
101	11	For different types of correspondences between lt and ct, we define different probability distributions to model Ps(ct|lt): (1) Numerics-to-numerics: The numbers in texts could sometimes be inaccurate due to some rounding customs, thus we use a Gaussian model for this type: SoftIndicator(x, y|σ) = N (x − y|0, σ), where N is the Gaussian density.
102	14	When the output type of tag lt is numeric and the word span ct is a number, we set Ps(c|l) = SoftIndicator(c, vl|σl), where σl is different for different tags, and vl is the corresponded value in the table for tag l. Note that when σ → 0, SoftIndicator reduces to an indicator function that only allows exact matching.
104	102	We simply use string matching to model the probability: Ps(c|l) ∝ Match(vl, c), where the Match function returns the number of shared words between cell value vl and word c. (3) Category-to-string: For labels correspond to discrete categorical values, such as Sunday, PG (point guard, a basketball position), we adopt the same method used by Liang et al. (2009): using a multinomial distribution over all word spans for each possible category: Ps(c|l) = νc,vl , ∑ c νc,v = 1, (1) where vl is again the output value of tag l. (4) Numerics-to-string: When the tag correspond to a numeric value vl while the word span c is not a number, the problem resembles speech modeling (Huang et al., 1990).
117	64	Preliminary experiments suggest that the initial model have too many words assigned to the NULL tag.
119	49	In our model, the transition score of two non-NULL labels can be calculated by skipping all the NULLs in between, as shown in Figure 3.
122	11	This might seem to be wasteful at first sight as we use two-fold latent states, but the Markov property is successfully preserved, therefore simplifying our implementation.
128	25	With posterior regularization, we could add certain types of statistical constraints to the E-step in the EM procedure, while keeping the inference tractable.
130	27	We use projected gradient descent to solve the E-step sub-problem in this work.
131	40	The statistical constraint we add to the posterior is rather simple: For each sentence, we “encourage” at least a proportion of words to be aligned to NULL labels: E[−f(w, l)] ≤ −r0 · n, (3) f(w, l) = n∑ i=1 1(li = NULL), (4) where r0 is a adjustable ratio, n is the length of w. We also tried other constraints but found this simple soft regularization performing well.
132	18	Intuitively, the assigned semantic correspondences could be useful to derive templates and trigger rules for language generation.
134	78	Specifically, we first blank out the correspondences of numerics-to-numerics and string-to-string to be empty slots and replace with the tag names.
135	44	In the example of Figure 1, we could replace Raptors with Team Name, and 120 with Team Points, if they have been correctly aligned.
136	61	We also need to know when to use each template.
137	34	We define a template trigger to be a quadruple (c, l, µc,l, σc,l), where c is a phrase, l is a tag, µc,l and σc,l are estimated Gaussian parameters.
138	13	6 We assign each template with a score to be the minimum probability for all triggers inside: score(s, t) = min i N (ti.l(s); ti.µ, ti.σ), (5) where t = {ti} denotes all possible triggers in the template, and the tag l can be executed over the world state s to retrieve a value l(s).
140	9	Now that the templates and triggers are ready for use, we will experiment with the following straightforward rules to perform data-to-text generation: For every game, we first generate a sentence describing the scoreline result, followed by three sentences describing other information about team performance.
141	12	While keeping that no template is repeatedly used, we will then choose the template with the highest score for top ten players sorted by their game points.
142	22	We conducted experiments on the ROTOWIRE subset of the Wiseman et al. (2017) dataset.

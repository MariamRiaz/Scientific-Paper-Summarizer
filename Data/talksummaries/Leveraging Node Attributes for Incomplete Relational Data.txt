0	22	Relational learning from network data, particularly with probabilistic methods, has gained a wide range of applications such as social network analysis (Xiang et al., 2010), recommender systems (Gopalan et al., 2014b), knowledge graph completion (Hu et al., 2016b), and bioinformatics (Huopaniemi et al., 2010).
1	9	Generally speaking, the goal of relational learning is to discover and analyse latent clusters of entities (i.e., community detection), and predict missing links (i.e., link prediction).
2	13	The standard approach for modelling relational data is latent factor analysis via matrix factorisation and its variations.
3	9	Among the existing approaches, Non-negative Matrix Factorisation (NMF) and the Stochastic Block Model (SBM) are prominent foundational methods.
4	38	NMF is usually used to model relationships between two sets of entities such as users and movies in collaborative filtering (Mnih & Salakhutdinov, 2008).
5	34	While developed independently, SBM (Wang & Wong, 1987; Nowicki & Snijders, 2001) can be viewed as an extension of NMF that introduces a block matrix to capture the interactions between latent factors.
9	45	When a network has less data, relational learning becomes more difficult.
10	22	One extreme case is the cold-start problem (Lin et al., 2013; Sedhain et al., 2014; Zhang & Wang, 2015), where a node has no observed links, making suggestion of links for that node even more challenging.
11	14	In such cases, it is natural to appeal to side information such as node attributes or features.
13	23	It is reasonable to assume that nodes having similar attributes are more likely to relate to each other (i.e., homophily, Nickel et al., 2016).
22	22	With improved scalability, the Structural Side Information Poisson Factorisation (SSI-PF) (Hu et al., 2016a) models directed unweighted networks with node labels, such as citation networks with papers labelled with one of several categories.
23	15	However, its performance remains untested when a node has multiple attributes.
26	25	It works with Poisson gamma relational models to incorporate side information.
28	65	The proposed models have several key properties: (1) Effectively modelling node attributes: the proposed models are able to achieve improved link prediction performance, especially where training data are limited.
37	18	Although our models incorporate binary attributes, categorical attributes and real-valued attributes can be converted into binary values with proper transformations (Kim et al., 2012; Fan et al., 2016; Hu et al., 2016a).
48	21	(5), gi,k is constructed with a log linear combination of fi,l.
50	11	bk acts as an attribute-free bias for each latent factor k. hl,k and bk are gamma distributed with mean 1, hence if attribute l does not contribute to latent factor k or is less useful, hl,k is expected to be near 1 and to have little influence on gi,k.
57	41	This is controlled by the attribute factor loading hl,k in our model.
58	23	Extending the Beta Gamma Gamma Poisson factorisation (BGGPF) (Zhou et al., 2012), Asym-NARM works on di- rected relational networks with node attributes incorporated in a similar way to Sym-NARM.
59	16	Figure 2 shows its generative process.
63	30	For example, in a patent citation network, patents can be labelled with the International Patent Classification (IPC) code, which is a hierarchy of patent categories and sub-categories.
65	49	Our models can be used to incorporate hierarchical node attributes via a straightforward extension: re- place hyper-parameter µ0 in Eq.
78	26	(21), we get the likelihood of hl,k: p ( hl,k ∣∣∣∣ gi,khl,k , t:,k, f:,l ) ∝ (22) e −hl,k log ( 1 1−qk )∑N i=1:fi,l=1 gi,k hl,k h ∑N i=1 fi,lti,k l,k where gi,khl,k is the value of gi,k with hl,k removed when fi,l = 1.
81	13	(15), gi,k can be updated with Eq.
86	29	As the mean of xi,·,k is D/K, sampling the tables T ∈ NN×K takes O(ND) which can be accelerated with the window sampling technique explained above.
87	16	We show the computational complexity of our and related models in Table 1.
88	29	The empirical comparison of running speed is in Section 5.4.
89	98	By taking advantage of both network sparsity and node attribute sparsity, our models are more efficient than the competitors, especially on large sparse networks with large sets of attributes.
104	43	We compare our models with the stateof-the-art relational models, demonstrating that our models outperform the competitors on those datasets in terms of link prediction performance and per-iteration running time.
107	45	For the link prediction task on undirected network data, we compared our Sym-NARM with two models that do not consider node attributes, EPM (Zhou, 2015), a stateof-the-art relational model, and iMMM (Koutsourelakis & Eliassi-Rad, 2008), a non-parametric version of MMSB, and two node attribute models, niMM (Fan et al., 2016), a non-parametric relational model which has been demonstrated to outperform NMDR (Kim et al., 2012), and DMRMMSB, our extension to MMSB using the Dirichlet Multinomial Regression (Mimno & McCallum, 2012).

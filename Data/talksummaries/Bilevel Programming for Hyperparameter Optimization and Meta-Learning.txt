30	1	We observe that these conditions are reasonable and apply to concrete problems relevant to applications.
31	1	4, by taking inspiration on early work on representation learning in the context of multi-task and meta-learning (Baxter, 1995; Caruana, 1998), we instantiate the framework for ML in a simple way treating the weights of the last layer of a neural network as the inner variables and the remaining weights, which parametrize the representation mapping, as the outer variables.
35	1	Note that {Lλ : λ ∈ Λ} is a class of objective functions parameterized by λ.
36	1	Specific instances of this problem include HO and ML, which we discuss next.
38	1	In the context of hyperparameter optimization, we are interested in minimizing the validation error of a model gw : X → Y parameterized by a vector w, with respect to a vector of hyperparameters λ.
43	1	Note that in this setting, the outer objective E does not depend explicitly on the hyperparameters λ, Error since in HO λ is instrumental in finding a good model gw, which is our final goal.
45	1	In meta-learning (ML) the inner and outer objectives are computed by averaging a training and a validation error over multiple tasks, respectively.
48	1	Each dataset Dj = {(xji , y j i )} nj i=1 with (x j i , y j i ) ∈ X × Yj is linked to a specific task.
49	1	Note that the output space is task dependent (e.g. a multi-class classification problem with variable number of classes).
51	1	A key point here is that λ is shared between the tasks.
52	2	With this notation the inner and outer objectives are Lλ(w) = N∑ j=1 Lj(wj , λ,Djtr), (3) E(w, λ) = N∑ j=1 Lj(wj , λ,Djval) (4) respectively.
56	2	The parameter λ indexes an hypothesis space within which the inner objective is minimized.
73	2	A major advantage of this reformulation is that it makes it possible to compute efficiently the gradient of fT , which we call hypergradient, either in time or in memory (Maclaurin et al., 2015; Franceschi et al., 2017), by making use of reverse or forward mode algorithmic differentiation (Griewank and Walther, 2008; Baydin et al., 2017).
104	1	Classical approaches (Baxter, 1995; Caruana, 1998) learn both the weights of the representation mapping and those of the ground classifiers jointly on the same data.
125	1	Motivated by the theoretical findings of Sec.
126	1	3, we empirically investigate how solving the inner problem approximately (i.e. using small T ) affects convergence, generalization performances, and running time.
128	1	In this setting, the bilevel problem reduces to a (non-convex) optimization problem in H .
137	1	However, performing a small number of gradient descent steps for solving the inner problem acts as implicit regularizer.
139	1	This is to be expected since, in this setting, the dimensions of parameters and hyperparameters are of the same order, leading to a concrete possibility of overfitting the outer objective (validation error).
141	1	As T increases, the number of hyperiterations required to reach the maximum test accuracy decreases, further suggesting that there is an interplay between the number of iterations used to solve the inner and the outer objective.
144	1	4 on two different benchmark datasets: • OMNIGLOT (Lake et al., 2015), a dataset that contains examples of 1623 different handwritten characters from 50 alphabets.
145	4	• MINIIMAGENET (Vinyals et al., 2016), a subset of ImageNet (Deng et al., 2009), that contains 60000 downsampled images from 100 different classes.
146	2	Following the experimental protocol used in a number of recent works, we build a meta-training set D, from which we sample datasets to solve Problem (9)-(10), a meta-validation set V for tuning ML hyperparameters, and finally a metatest set T which is used to estimate accuracy.
154	1	We initialize ground models parameters wj to 0 and, according to the observation in Sec.
158	1	Regarding the specific implementation of the representation mapping h, we employ for Omniglot a four-layers convolutional neural network with strided convolutions and 64 filters per layer as in (Vinyals et al., 2016) and other successive works.
185	3	In the case of ML, by adapting classical strategies (Baxter, 1995) to the bilevel framework with training/validation splitting, we present a method for learning hyper-representations which is experimentally effective and supported by our theoretical guarantees.
186	3	Our framework encompasses recently proposed methods for meta-learning, such as learning to optimize, but also suggests different design patterns for the inner learning algorithm which could be interesting to explore in future work.
187	20	The resulting inner problems may not satisfy the assumptions of our convergence analysis, raising the need for further theoretical investigations.
188	139	An additional future direction of research is the study of the statistical properties of bilevel strategies where outer objectives are based on the generalization ability of the inner model to new (validation) data.
189	136	Ideas from (Maurer et al., 2016; Denevi et al., 2018) may be useful in this direction.

8	94	More concretely, our approach would replace the second utterance of the exchange ‘What pizza do you want?’ - ‘I want a vegetarian pizza.’ with an utterance like ‘I don’t like meat’.
16	19	Studies could show that under specific circumstances indirectness is preferred not only from human conversation partners, but also in human-computer interaction (e.g. (Miehle et al., 2016; Pragst et al., 2017)).
38	48	Substituting a direct/indirect utterance with its respective counterpart can be achieved by performing the following steps: Algorithm 1: Pseudocode for exchanging one utterance for another that is functionally similar and of the opposite directness.
40	42	Determine the level of directness of the utterance.
48	18	In our work, we utilise DVMs (Pragst et al., 2018) to that end.
49	25	DVMs are representations of sentences as vectors that captures their semantic meaning in the dialogue context.
55	23	For the estimation of the level of directness an utterance possesses, we choose a supervised learning approach with a RNN.
60	26	To obtain a numerical representation of an utterance that can be used as input to the network, we utilise word vector models (Mikolov et al., 2013a) and DVMs (Pragst et al., 2018).
69	31	Our approach requires a dialogue corpus for several task: as a source for alternative utterances, as training data for the directness classifier, as training data for the DVM and as ground truth for the evaluation.
70	42	To fulfil those tasks, the employed corpus has to meet two requirements: it needs to contain a sufficient amount of examples for functionally similar direct and indirect utterances, and the utterances need to be annotated with their dialogue act and level of directness.
72	34	Furthermore, we dismissed the option to collect and annotate a dialogue corpus ourselves, considering the difficulty to make sure that speakers would use different levels of directness for the same purpose without inhibiting the naturalness of the dialogues.
79	18	The dialogues incorporate typical elements of human conversation: different courses of the dialogue, over-answering, misunderstandings as well as requests for confirmation and corrections, among others.
80	21	The example dialogues also show instances of different wordings for the same purpose, such as several indirect variants of ‘Yes.’, such as ‘Great.’, ‘I’m looking forward to it.’ and ‘That sounds delicious.’ that can be found across the dialogues, and the direct ‘I would like to order pizza.’ in Dialogue 3 that is exchanged for the indirect ‘Can I order pizza from you?’ in Dialogue 4.
81	30	Additionally, the same utterance can have a different level of directness depending on the context: in Dialogue 1, the utterance ‘I haven’t planned anything.’ as response to ‘Do you have time today?’ is indirect, whereas it is direct as response to ‘Do you have plans today?’ in Dialogue 2.
96	49	Nevertheless, we believe that generated dialogues have their benefits: they should not be used to gauge the actual performance of approaches in an applied spoken dialogue system, but rather to appraise their potential.
98	21	While natural dialogues more accurately represent conversations in the real world, automatically generated dialogues offer more control.
101	58	Additionally, by being able to provide the complete data set for a smaller scale use case as defined by the dialogue domain, we can get an idea about the potential performance of an approach given a large amount of data that approaches the state of total coverage.
114	26	As usual, we use ten-fold cross-validation in our evaluation.
115	32	However, instead of only using 90% of the utterances for training and 10% for testing, we also evaluate our approach using 10% of the utterances for training and 90% for testing.
116	26	With this, we want to investigate how our approach performs given only a limited amount of annotated data.
121	24	The DVMs we utilise in our evaluation as similarity measure and as input to the RNN are trained on the presented dialogue corpus.
131	18	Furthermore, adding the linear combination of the word vectors as input improves the performance of the classifier significantly (t(101.347) = 32.434, p < .001).
139	22	Our approach for choosing a valid replacement for an utterance was able to achieves a high accuracy of 0.70 at its best performance.
141	27	Depending on the quality of the employed components, the accuracy ranges from 0.41 to 0.70.
155	33	It is likely that the quality of both the classifier and the DVMs decreases if they are trained on a comparable amount of natural dialogue data compared to artificially generated data.
164	27	While our evaluation shows what accuracy our approach can achieve given different circumstances, we did not yet investigate what accuracy it needs to achieve in actual applications to positively impact the user experience.
168	21	A dialogue corpus that provides a sufficient amount of direct/indirect utterance pairs as well as annotations of the dialogue act and level of directness was generated automatically and utilised to show the high potential of our approach in an evaluation.
171	100	Unsupervised learning approaches will be investigated to eliminate this need.
175	100	It might become necessary to explore the generation of suitable utterances if we find that natural dialogue data does not contain a sufficient amount of direct/indirect utterance pairs.
176	20	Finally, the integration of our approach in an actual dialogue systems can confirm its beneficial effects on the user satisfaction.

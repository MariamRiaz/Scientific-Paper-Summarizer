{"sections": [{"heading": "1. Introduction", "text": "Hamiltonian Monte Carlo is a powerful sampling algorithm which has been shown to outperform many existing MCMC algorithms, especially in problems with highdimensional and correlated distributions (Duane et al., 1987; Neal, 2011). The algorithm mimics the movement of a body balancing potential and kinetic energy by extending the state space to include auxiliary momentum variables and using Hamiltonian dynamics. By traversing long isoprobability contours in this extended state space, HMC is able to move long distances in state space in a single up-\n*Equal contribution 1Program in Computational Biology, Fred Hutchison Cancer Research Center, Seattle, WA, USA 2Department of Statistics, University of Washington, Seattle, WA, USA. Correspondence to: Frederick, A. Matsen IV <matsen@fredhutch.org>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\ndate step, and thus has proved to be more effective than standard MCMC methods in a variety of applications. The method has gained a lot of interest from the scientific community and since then has been extended to tackle the problem of sampling on various geometric structures such as constrained spaces (Lan et al., 2014; Brubaker et al., 2012; Hartmann and Schu\u0308tte, 2005), on general Hilbert space (Beskos et al., 2011) and on Riemannian manifolds (Girolami and Calderhead, 2011; Wang et al., 2013).\nHowever, these extensions are not yet sufficient to apply to all sampling problems, such as in phylogenetics, the inference of evolutionary trees. Phylogenetics is the study of the evolutionary history and relationships among individuals or groups of organisms. In its statistical formulation it is an inference problem on hypotheses of shared history based on observed heritable traits under a model of evolution. Phylogenetics is an essential tool for understanding biological systems and is an important discipline of computational biology. The Bayesian paradigm is now commonly used to assess support for inferred tree structures or to test hypotheses that can be expressed in phylogenetic terms (Huelsenbeck et al., 2001).\nAlthough the last several decades have seen an explosion of advanced methods for sampling from Bayesian posterior distributions, including HMC, phylogenetics still uses relatively classical Markov chain Monte Carlo (MCMC) based methods. This is in part because the number of possible tree topologies (the labeled graphs describing the branching structure of the evolutionary history) explodes combinatorially as the number of species increases. Also, to represent the phylogenetic relation among a fixed number of species, one needs to specify both the tree topology (a discrete object) and the branch lengths (continuous distances). This composite structure has thus far limited sampling methods to relatively classical Markov chain Monte Carlo (MCMC) based methods. One path forward is to use a construction of the set of phylogenetic trees as a single connected space composed of Euclidean spaces glued together in a combinatorial fashion (Kim, 2000; Moulton and Steel, 2004; Billera et al., 2001; Gavryushkin and Drummond, 2016) and try to define an HMC-like algorithm thereupon.\nExperts in HMC are acutely aware of the need to extend HMC to such spaces with intricate combinatorial structure: Betancourt (2017) describes the extension of HMC to dis-\ncrete and tree spaces as a major outstanding challenge for the area. However, there are several challenges to defining a continuous dynamics-based sampling methods on such spaces. These tree spaces are composed of Euclidean components, one for each discrete tree topology, which are glued together in a way that respects natural similarities between trees. These similarities dictate that more than two such Euclidean spaces should get glued together along a common lower-dimensional boundary. The resulting lack of manifold structure poses a problem to the construction of an HMC sampling method on tree space, since up to now, HMC has just been defined on spaces with differential geometry. Similarly, while the posterior function is smooth within each topology, the function\u2019s behavior may be very\ndifferent between topologies. In fact, there is no general notion of differentiability of the posterior function on the whole tree space and any scheme to approximate Hamiltonian dynamics needs to take this issue into account.\nIn this paper, we develop Probabilistic Path Hamiltonian Monte Carlo (PPHMC) as a first step to sampling distributions on spaces with intricate combinatorial structure (Figure 1). After reviewing how the ensemble of phylogenetic trees is naturally described as a geometric structure we identify as an orthant complex (Billera et al., 2001), we define PPHMC for sampling posteriors on orthant complexes along with a probabilistic version of the leapfrog algorithm. This algorithm generalizes previous HMC algorithms by doing classical HMC on the Euclidean components of the orthant complex, but making random choices between alternative paths available at a boundary. We establish that the integrator retains the good theoretical properties of Hamiltonian dynamics in classical settings, namely probabilistic equivalents of time-reversibility, volume preservation, and accessibility, which combined together result in a proof of ergodicity for the resulting Markov chain. Although a direct application of the integrator to the phylogenetic posterior does work, we obtain significantly better performance by using a surrogate function near the boundary between topologies to control approximation error. This approach also addresses a general problem in using Reflective HMC (RHMC; Afshar and Domke, 2015) for energy functions with discontinuous derivatives (for which the accuracy of RHMC is of order O( ), instead of the standard local error O( 3) of HMC on Rn). We provide, validate, and benchmark two independent implementations in open-source software."}, {"heading": "2. Mathematical framework", "text": ""}, {"heading": "2.1. Bayesian learning on phylogenetic tree space", "text": "A phylogenetic tree (\u03c4, q) is a tree graph \u03c4 with N leaves, each of which has a label, and such that each edge e is associated with a non-negative number qe. Trees will be assumed to be bifurcating (internal nodes of degree 3) unless otherwise specified. We denote the number of edges of such a tree by n = 2N \u2212 3. Any edge incident to a leaf is called a pendant edge, and any other edge is called an internal edge. Let TN be the set of all N -leaf phylogenetic trees for which the lengths of pendant edges are bounded from below by some constant e0 > 0. (This lower bound on branch lengths is a technical condition for theoretical development and can be relaxed in practice.)\nWe will use nearest neighbor interchange (NNI) moves (Robinson, 1971) to formalize what tree topologies that are \u201cnear\u201d to each other. An NNI move is a transformation that collapses an internal edge to zero and then expands\nthe resulting degree 4 vertex into an edge and two degree 3 vertices in a new way (Figure 1a). Two tree topologies \u03c41 and \u03c42 are called adjacent topologies if there exists a single NNI move that transforms \u03c41 into \u03c42.\nWe will parameterize TN as Billera-Holmes-Vogtmann (BHV) space (Billera et al., 2001), which we describe as follows. An orthant of dimension n is simply Rn\u22650; each n-dimensional orthant is bounded by a collection of lower dimensional orthant faces. An orthant complex is a geometric object X obtained by gluing various orthants of the same dimension n, indexed by a countable set \u0393, such that: (i) the intersection of any two orthants is a face of both orthants, and (ii) each x \u2208 X belongs to a finite number of orthants. Each state of X is thus represented by a pair (\u03c4, q), where \u03c4 \u2208 \u0393 and q \u2208 Rn\u22650. Generalizing the definitions from phylogenetics, we refer to \u03c4 as its topology and to q as the vector of attributes. The topology of a point in an orthant complex indexes discrete structure, while the attributes formalize the continuous components of the space.\nFor phylogenetics, the complex is constructed by taking one n-dimensional orthant for each of the (2n \u2212 3)!! possible tree topologies, and gluing them together along their common faces. The geometry can also be summarized as follows. In BHV space, each of these orthants parameterizes the set of branch lengths for a single topology (as a technical point, because we are bounding pendant branch lengths below by e0, we can take the corresponding entries in the orthant to parameterize the amount of branch length above e0). Top-dimensional orthants of the complex sharing a facet, i.e. a codimension 1 face, correspond to (NNI) adjacent topologies.\nFor a fixed phylogenetic tree (\u03c4, q), the phylogenetic likelihood is defined as follows and will be denoted by L(\u03c4, p) (see Kenney and Gu, 2012, for a full exposition). Let \u03c8 = (\u03c81, \u03c82, ..., \u03c8S) \u2208 \u2126N\u00d7S be the observed sequences (with characters in \u2126) of length S over N leaves. The likelihood of observing \u03c8 given the tree has the form\nL(\u03c4, q) = S\u220f s=1 \u2211 as \u03b7(as\u03c1) \u220f (u,v)\u2208E(\u03c4,q) Puvasuasv (quv)\nwhere \u03c1 is any internal node of the tree, as ranges over all extensions of \u03c8s to the internal nodes of the tree, asu denotes the assigned state of node u by as, E(\u03c4, q) denotes the set of tree edges, Pij(t) denotes the transition probability from character i to character j across an edge of length t defined by a given evolutionary model and \u03b7 is the stationary distribution of this evolutionary model. For this paper we will assume the simplest Jukes and Cantor (1969) model of a homogeneous continuous-time Markov chain on \u2126 with equal transition rates, noting that inferring parameters of complex substitution models is a vibrant yet separate subject of research (e.g. Zhao et al., 2016).\nGiven a proper prior distribution with density \u03c00 imposed on the branch lengths and on tree topologies, the posterior distribution can be computed as P(\u03c4, q) \u221d L(\u03c4, q)\u03c00(\u03c4, q)."}, {"heading": "2.2. Bayesian learning on orthant complexes", "text": "With the motivation of phylogenetics in mind, we now describe how the phylogenetic problem sits as a specific case of a more general problem of Bayesian learning on orthant complexes, and distill the criteria needed to enable PPHMC on these spaces. This generality will also enable applications of Bayesian learning on similar spaces in other settings. For example in robotics, the state complex can be described by a cubical complexes whose vertices are the states, whose edges correspond to allowable moves, and whose cubes correspond to collections of moves which can be performed simultaneously (Ardila et al., 2014). Similarly, in learning on spaces of treelike shapes, the attributes are open curves translated to start at the origin, described by a fixed number of landmark points (Feragen et al., 2010).\nAn orthant complex, being a union of Euclidean orthants, naturally inherits the Lebesgue measure which we will denote hereafter by \u00b5. Orthant complexes are typically not manifolds, thus to ensure consistency in movements across orthants, we assume that local coordinates of the orthants are defined in such a way that there is a natural one-to-one correspondence between the sets of attributes of any two orthants sharing a common face.\nAssumption 2.1 (Consistency of local coordinates). Given two topologies \u03c4, \u03c4 \u2032 \u2208 \u0393 and state x = (\u03c4, q\u03c4 ) = (\u03c4 \u2032, q\u03c4 \u2032) on the boundary of the orthants for \u03c4 and \u03c4 \u2032, then q\u03c4 = q\u03c4 \u2032 .\nWe show that BHV tree space can be given such coordinates in the Appendix. For the rest of the paper, we define for each state (\u03c4, q) \u2208 X the setN (\u03c4, q) of all neighboring topologies \u03c4 \u2032 such that \u03c4 \u2032 orthant contains (\u03c4, q). Note that N (\u03c4, q) always includes \u03c4 , and if all coordinates of q are positive,N (\u03c4, q) is exactly {\u03c4}. Moreover, if \u03c4 \u2032 \u2208 N (\u03c4, q) and \u03c4 \u2032 6= \u03c4 , we say that \u03c4 and \u03c4 \u2032 are joined by (\u03c4, q). If the intersection of orthants for two topologies is a facet of each, we say that the two topologies are adjacent.\nFinally, let G be the adjacency graph of the orthant complex X , that is, the graph with vertices representing the topologies and edges connecting adjacent topologies. Recalling that the diameter of a graph is the maximum value of the graph distance between any two vertices, we assume that\nAssumption 2.2. The adjacency graph G of X has finite diameter, hereafter denoted by k.\nFor phylogenetics, k is of order O(N logN) (Li et al., 1996).\nWe seek to sample from a posterior distribution P(\u03c4, q) on X . Assume that the negative logarithm of the posterior dis-\ntribution U(\u03c4, q) := \u2212 logP (\u03c4, q) satisfies: Assumption 2.3. U(\u03c4, q) is a continuous function on X , and is smooth up to the boundary of each orthant \u03c4 \u2208 \u0393.\nIn the Appendix, we prove that if the logarithm of the phylogenetic prior distribution \u03c00(\u03c4, q) satisfies Assumption 2.3, then so does the phylogenetic posterior distribution. It is also worth noting that while U(\u03c4, q) is smooth within each orthant, the function\u2019s behavior may be very different between orthants and we do not assume any notion of differentiability of the posterior function on the whole space."}, {"heading": "2.3. Hamiltonian dynamics on orthant complexes", "text": "The HMC state space includes auxiliary momentum variables in addition to the usual state variables. In our framework, the augmented state of this system is represented by the position (\u03c4, q) and the momentum p, an n-dimensional vector. We will denote the set of all possible augmented state (\u03c4, q, p) of the system by T.\nThe Hamiltonian is defined as in the traditional HMC setting: H(\u03c4, q, p) = U(\u03c4, q) +K(p), where K(p) = 12\u2016p\u2016\n2. We will refer to U(\u03c4, q) and K(p) as the potential energy function and the kinetic energy function of the system at the state (\u03c4, q, p), respectively.\nOur stochastic Hamiltonian-type system of equations is:\ndpi dt =\u2212 \u2202U \u2202qi (\u03c4, q) if qi > 0\npi \u2190 \u2212pi; \u03c4 \u223c Z(N (\u03c4, q)) if qi = 0 dqi dt = pi\n(2.1)\nwhere Z(A) denotes the uniform distribution on the set A.\nIf all coordinates of q are positive, the system behaves as in the traditional Hamiltonian setting on Rn. When some attributes hit zero, however, the new orthant is picked randomly from the orthants of neighboring topologies (including the current one), and the momenta corresponding to non-positive attributes are negated.\nAssumption 2.3 implies that despite the non-differentiable changes in the governing equation across orthants, the Hamiltonian of the system along any path is constant:\nLemma 2.1. H is conserved along any system dynamics."}, {"heading": "2.4. A probabilistic \u201cleap-prog\u201d algorithm", "text": "In practice, we approximate Hamiltonian dynamics by the following integrator with step size , which we call \u201cleapprog\u201d as a probabilistic analog of the usual leapfrog algorithm. This extends previous work of (Afshar and Domke, 2015) on RHMC where particles can reflect against planar surfaces of Rn\u22650.\nIn the RHMC formulation, one breaks the step size into smaller sub-steps, each of which correspond to an event when some of the coordinates cross zero. We adapt this idea to HMC on orthant complexes as follows. Every time such an event happens, we reevaluate the values of the position and the momentum vectors, update the topology (uniformly at random from the set of neighboring topologies), reverse the momentum of crossing coordinates and continue the process until a total step size is achieved (Algorithm 1). We note that several topologies might be visited in one leap-prog step.\nIf there are no topological changes in the trajectory to time , this procedure is equivalent to classical HMC. Moreover, since the algorithm only re-evaluates the gradient of the energy function at the end of the step when the final position has been fixed, changes in topology on the path have no effect on the changes of position and momentum. Thus, the projection of the particles (in a single leap-prog step) to the (q, p) space is identical to a leapfrog step of RHMC on Rn\u22650.\nAlgorithm 1 Leap-prog algorithm with step size . p\u2190 p\u2212 \u2207U(\u03c4, q)/2 if FirstUpdateEvent(\u03c4, q, p, ) = \u2205 then q \u2190 q + p\nelse t\u2190 0 while FirstUpdateEvent(\u03c4, q, p, \u2212 t) 6= \u2205 do\n(q, e, I)\u2190 FirstUpdateEvent(\u03c4, q, p, \u2212 t) t\u2190 t+ e \u03c4 \u223c Z(N (\u03c4, q)) pI \u2190 \u2212pI\nend while q \u2190 q + ( \u2212 t)p\nend if p\u2190 p\u2212 \u2207U(\u03c4, q)/2\nHere FirstUpdateEvent(\u03c4, q, p, t) returns x, the position of the first event for which the line segment [q, q+ tp] crosses zero; e, the time when this event happens; and I , the indices of the coordinates crossing zero during this event. If qi and pi are both zero before FirstUpdateEvent is called, i is not considered as a crossing coordinate. If no such an event exists, \u2205 is returned."}, {"heading": "3. Hamiltonian Monte Carlo on orthant complexes", "text": "Probabilistic Path Hamiltonian Monte Carlo (PPHMC) with leap-prog dynamics iterates three steps, similar to that of classical HMC. First, new values for the momentum variables are randomly drawn from their Gaussian distribution, independently of the current values of the posi-\ntion variables. Second, starting with the current augmented state, s = (\u03c4, q, p), the Hamiltonian dynamics is run for a fixed number of steps T using the leap-prog algorithm with fixed step size . The momentum at the end of this trajectory is then negated, giving a proposed augmented state s\u2217 = (\u03c4\u2217, q\u2217, p\u2217). Finally, this proposed augmented state is accepted as the next augmented state of the Markov chain with probability r(s, s\u2217) = min (1, exp(H(s)\u2212H(s\u2217))).\nPPHMC has two natural advantages over MCMC methods for phylogenetic inference: jumps between topologies are guided by the potential surface, and many jumps can be combined into a single proposal with high acceptance probability. Indeed, rather than completely random jumps as used for MCMC, the topological modifications of HMC are guided by the gradient of the potential. This is important because there are an enormous number of phylogenetic trees, namely (2n \u2212 3)!! trees with n leaves. Secondly, HMC can combine a great number of tree modifications into a single step, allowing for large jumps in tree space with high acceptance probability. These two characteristics are analogs of why HMC is superior to conventional MCMC in continuous settings and what we aimed to extend to our problem."}, {"heading": "3.1. Theoretical properties of the leap-prog integrator", "text": "To support the use of this leap-prog integrator for MCMC sampling, we establish that integrator retains analogs of the good theoretical properties of Hamiltonian dynamics in classical settings, namely, time-reversibility, volume preservation and accessibility (proofs in Appendix).\nWe formulate probabilistic reversibility as:\nLemma 3.1 (Reversibility). For a fixed finite time horizon T , we denote by P (s, s\u2032) the probability that the integrator moves s to s\u2032 in a single update step. We have\nP ((\u03c4, q, p), (\u03c4 \u2032, q\u2032, p\u2032)) = P ((\u03c4 \u2032, q\u2032,\u2212p\u2032), (\u03c4, q,\u2212p)).\nfor any augmented states (\u03c4 \u2032, q\u2032, p\u2032) and (\u03c4, q, p) \u2208 T.\nThe central part of proving the detailed balance condition of PPHMC is to verify that Hamiltonian dynamics preserves volume. Unlike the traditional HMC setting where the proposal distribution is a single point mass, in our probabilistic setting, if we start at one augmented state s, we may end up at countably many end points due to stochastic HMC integration. The equation describing volume preservation in this case needs to be generalized to the form of Equation (3.1), where the summations account for the discreteness of the proposal distribution.\nLemma 3.2 (Volume preservation). For every pair of measurable sets A,B \u2282 T and elements s, s\u2032 \u2208 T, we denote by P (s, s\u2032) the probability that the integrator moves s to s\u2032\nin a single update step and define\nB(s) = {s\u2032 \u2208 B : P (s, s\u2032) > 0}\nand A(s\u2032) = {s \u2208 A : P (s, s\u2032) > 0}.\nThen\u222b A \u2211 s\u2032\u2208B(s) P (s, s\u2032) ds = \u222b B \u2211 s\u2208A(s\u2032) P (s\u2032, s) ds\u2032. (3.1)\nIf we restrict to the case of trajectories staying in a single topology, A(s) and B(s\u2032) are singletons and we get back the traditional equation of volume preservation. We also note that the measure ds in Equation (3.1) is the Lebesgue measure: when there is no randomness in the Hamiltonian paths, (3.1) becomes the standard volume preservation condition, where volumes are expressed by the Lebesgue measure.\nTypically, accessibility poses no major problem in various settings of HMC since it is usually clear that one can go between any two positions in a single HMC step. In the case of PPHMC, however, the composition of discrete and continuous structure, along with the possible non-differentiability of the potential energy across orthants, make it challenging to verify this condition. Here we show instead that the PPHMC algorithm can go between any two states with k steps, where k denotes the diameter of adjacency graph G the space X and each PPHMC step consists of T leap-prog steps of size .\nLemma 3.3 (k-accessibility). For a fixed starting state (\u03c4 (0), q(0)), any state (\u03c4 \u2032, q\u2032) \u2208 X can be reached from (\u03c4 (0), q(0)) by running k steps of PPHMC.\nThe proof of this Lemma is based on Assumption 2.2, which asserts that the adjacency graph G of X has finite diameter, and that classical HMC allows the particles to move freely in each orthant by a single HMC step.\nTo show that Markov chains generated by PPHMC are ergodic, we also need to prove that the integrator can reach any subset of positive measure of the augmented state space with positive probability. To enable such a result, we show:\nLemma 3.4. For every sequence of topologies \u03c9 = {\u03c4 (0), \u03c4 (1), . . . , \u03c4 (n\u03c9)} and every set with positive measure B \u2282 X , let B\u03c9 be the set of all (\u03c4 \u2032, q\u2032) \u2208 B such that (\u03c4 \u2032, q\u2032) can be reached from (\u03c4 (0), q(0)) in k PPHMC steps and such that the sequence of topologies crossed by the trajectory is \u03c9. We denote by IB,\u03c9 the set of all sequences of initial momenta for each PPHMC step {p(0), . . . , p(k)} that make such a path possible.\nThen, if \u00b5(IB,\u03c9) = 0, then \u00b5(B\u03c9) = 0.\nWe also need certain sets to be countable. Lemma 3.5. Given s \u2208 T, we denote by R(s) the set of all augmented states s\u2032 such that there is a finite-size leapprog step with path \u03b3 connecting s and s\u2032, and by K(s) the set of all such leap-prog paths \u03b3 connecting s and s\u2032 \u2208 R(s). Then R(s) and K(s) are countable. Moreover, the probability P\u221e(s, s\u2032) of moving from s to s\u2032 via paths with infinite number of topological changes is zero."}, {"heading": "3.2. Ergodicity of Probabilistic Path HMC", "text": "In this section, we establish that a Markov chain generated by PPHMC is ergodic with stationary distribution \u03c0(\u03c4, q) \u221d exp(\u2212U(\u03c4, q)). To do so, we need to verify that the Markov chain generated by PPHMC is aperiodic, because we have shown k-accessibility of the integrator rather than 1-accessibility. Throughout this section, we will use the notation P ((\u03c4, q, p), \u00b7) to denote the one-step proposal distribution of PPHMC starting at augmented state (\u03c4, q, p), and P ((\u03c4, q), \u00b7) to denote the one-step proposal distribution of PPHMC starting at position (\u03c4, q) and with a momentum vector drawn from a Gaussian as described above.\nWe first note that: Lemma 3.6. PPHMC preserves the target distribution \u03c0.\nGiven probabilistic volume preservation (3.2), the proof is standard and is given in the Appendix. Theorem 3.1 (Ergodic). The Markov chain generated by PPHMC is ergodic.\nProof of Theorem 3.1. For every sequence of topologies \u03c9 = {\u03c4 (0), \u03c4 (1), . . . , \u03c4 (n\u03c9)} (finite by Lemma 3.5) and every set with positive measure B \u2282 X , we define B\u03c9 and IB,\u03c9 as in the previous section. By Lemma 3.3, we have\nB = \u22c3 \u03c9 B\u03c9.\nAssume that \u00b5(IB,\u03c9) = 0 for all \u03c9. From Lemma 3.4, we deduce that \u00b5(B\u03c9) = 0 for all \u03c9. This makes \u00b5(B) = 0, which is a contradiction. Hence \u00b5(IB,\u03c9) > 0 for some \u03c9 and Pn\u03c9 ((\u03c4 (0), q(0)), B) is at least the positive quantity\n1\nZ \u222b p\u2208IB,\u03c9 Pn\u03c9 ((\u03c4 (0), q(0), p), B) exp(\u2212K(p))dp\nwhere Z is the normalizing constant. This holds for all sets with positive measure B \u2282 X , so PPHMC is irreducible.\nNow assume that a Markov chain generated by the leapfrog algorithm is periodic. The reversibility of Hamiltonian dynamics implies that the period d must be equal to 2. In other words, there exist two disjoint subsets X1, X2 of X such that \u03c0(X1) > 0, and\nP (x,X2) = 1 \u2200x \u2208 X1, and P (x,X1) = 1 \u2200x \u2208 X2.\nConsider x \u2208 X1 with all positive attributes. There exists a neighborhood Ux around x such that any y \u2208 Ux is reachable from x by Hamiltonian dynamics. Since X1, X2 are disjoint, we deduce that \u00b5(Ux \u2229X1) = 0. Since the neighborhood Ux exists for almost every x \u2208 X1, this implies that \u00b5(X1) = 0, and hence, that \u03c0(X1) = 0, which is a contradiction. We conclude that any Markov chain generated by the leapfrog algorithm is aperiodic.\nLemma 3.6 shows that PPHMC preserves the target distribution \u03c0. This, along with \u03c0-irreducibility and aperiodicity, completes the proof (Roberts and Rosenthal, 2004)."}, {"heading": "3.3. An efficient surrogate smoothing strategy", "text": "One major advantage of HMC methods over traditional approaches is that HMC-proposed states may be distant from the current state but nevertheless have a high probability of acceptance. This partially relies on the fact that the leapfrog algorithm with smooth energy functions has a local approximation error of order O( 3) (which leads to global errorO(T 3), where T is the number of leapfrog steps in a Hamiltonian path).\nHowever, when the potential energy function U(\u03c4, q) is not differentiable on the whole space this low approximation error can break down. Indeed, although PPHMC inherits many nice properties from vanilla HMC and RHMC (Afshar and Domke, 2015), this discontinuity of the derivatives of the potential energy across orthants may result in non-negligible loss of accuracy during numerical simulations of the Hamiltonian dynamics. A careful analysis of the local approximation error of RHMC for potential energy functions with discontinuous first derivatives reveals that it only has an local error rate of order at least \u2126( ) (see proof in Appendix):\nProposition 3.1. Given a potential function V , we denote by V + and V \u2212 the restrictions of V on the half-spaces {x1 \u2265 0} and {x1 \u2264 0} and assume that V + and V \u2212 are smooth up to the boundary of their domains. If the first derivative with respect to the first component of the potential energy V (q) are discontinuous across the hyperplane {x1 = 0} (i.e., (\u2202V +)/(\u2202q1) and (\u2202V \u2212)/(\u2202q1) are not identical on this set), then RHMC on this hyper-plane has a local error of order at least \u2126( ).\nSince PPHMC uses RHMC, when the first derivatives of the potential energy are discontinuous, it also has a global error of orderO(C +T 3), which depends on the number of critical events C along a Hamiltonian path (that is, the number of reflection/refraction events). This makes it difficult to tune the step size for optimal acceptance rate, and requires small , limiting topology exploration.\nTo alleviate this issue, we propose the use of a surrogate induced Hamiltonian dynamics (Strathmann et al., 2015;\nZhang et al., 2016) with the Hamiltonian H\u0303(\u03c4, q, p) = U\u0303(\u03c4, q) +K(p), where the surrogate potential energy is\nU\u0303(\u03c4, q) = U(\u03c4,G(q)), G(q) = (g(q1), . . . , g(qn))\nand g(x) is some positive and smooth approximation of |x| with vanishing gradient at x = 0. One simple example which will be used for the rest of this paper is\ng\u03b4(x) = { x, x \u2265 \u03b4 1 2\u03b4 (x 2 + \u03b42), 0 \u2264 x < \u03b4\nwhere \u03b4 will be called the smoothing threshold.\nDue to the vanishing gradient of g, U\u0303 now has continuous derivatives across orthants. However, U\u0303 is no longer continuous across orthants since g(0) 6= 0 and we thus employ the refraction technique introduced in Afshar and Domke (2015) (see Algorithm 2 for more details). The proposed state s\u2217\u03b4 = (\u03c4 \u2217 \u03b4 , q \u2217 \u03b4 , p \u2217 \u03b4) at the end of the trajectory is accepted with probability according to the original Hamiltonian, that is, min(1, exp(H(s)\u2212H(s\u2217\u03b4))).\nBy following the same framework proposed in previous sections, we can prove that the resulting sampler still samples from the exact posterior distribution P(\u03c4, q). A complete treatment, however, requires more technical adjustments and is beyond the scope of the paper. We will leave this as a subject of future work.\nAlgorithm 2 Refractive Leap-prog with surrogate p\u2190 p\u2212 \u2207U\u0303(\u03c4, q)/2 if FirstUpdateEvent(\u03c4, q, p, ) = \u2205 then q \u2190 q + p\nelse t\u2190 0 while FirstUpdateEvent(q, p, \u2212 t) 6= \u2205 do\n(q, e, I)\u2190 FirstUpdateEvent(\u03c4, q, p, \u2212 t) t\u2190 t+ e \u03c4 \u2032 \u223c Z(N (\u03c4, q)) \u2206E \u2190 U\u0303(\u03c4 \u2032, q)\u2212 U\u0303(\u03c4, q) if \u2016pI\u20162 > 2\u2206E then pI \u2190 \u221a \u2016pI\u20162 \u2212 2\u2206E \u00b7\n\u2212pI \u2016pI\u2016\n\u03c4 \u2190 \u03c4 \u2032 else pI \u2190 \u2212pI\nend if end while q \u2190 q + ( \u2212 t)p\nend if p\u2190 p\u2212 \u2207U\u0303(\u03c4, q)/2\nAs we will illustrate later, compared to the exact potential energy, the continuity of the derivative of the surrogate potential across orthants dramatically reduces the discretiza-\ntion error and allows for high acceptance probability with relatively large step size."}, {"heading": "4. Experiments", "text": "In this section, we demonstrate the validity and efficiency of our PPHMC method by an application to Bayesian phylogenetic inference. We compared our PPHMC implementations to industry-standard MrBayes 3.2.5, which uses MCMC to sample phylogenetic trees (Ronquist et al., 2012). We concentrated on the most challenging part: sampling jointly for the branch lengths and tree topologies, and assumed other parameters (e.g., substitution model, hyper-parameters for the priors) are fixed. More specifically, for all of our experiments we continued to assume the Jukes-Cantor model of DNA substitution and placed a uniform prior on the tree topology \u03c4 \u223c Z (TN ) with branch lengths i.i.d. qi \u223c Exponential (\u03bb = 10), as done by others when measuring the performance of MCMC algorithms for Bayesian phylogenetics (e.g., Whidden and Matsen, 2015). As mentioned earlier, although in the theoretical development we assumed that the lengths of the pendant edges are bounded from below by a positive constant e0 to ensure that the likelihood stays positive on the whole tree space, this condition is not necessary in practice since the Hamiltonian dynamics guide the particles away from regions with zero likelihood (i.e., the region with U =\u221e). We validate the algorithm through two independent implementations in open-source software:\n1. a Scala version available at https://github.com/ armanbilge/phyloHMC that uses the Phylogenetic Likelihood Library1 (Flouri et al., 2015), and\n2. a Python version available at https://github. com/zcrabbit/PhyloInfer that uses the ETE toolkit (Huerta-Cepas et al., 2016) and Biopython (Cock et al., 2009)."}, {"heading": "4.1. Simulated data", "text": "As a proof of concept, we first tested our PPHMC method on a simulated data set. We used a random unrooted tree with N = 50 leaves sampled from the aforementioned prior. 1000 nucleotide observations for each leaf were then generated by simulating the continuous-time Markov model along the tree. This moderate data set provided enough information for model inference while allowing for a relatively rich posterior distribution to sample from.\nWe ran MrBayes for 107 iterations and sampled every 1000 iterations after a burn-in period of the first 25% iterations to establish a ground truth for the posterior distribution.\n1https://github.com/xflouris/libpll\nFor PPHMC, we set the step size = 0.0015 and smoothing threshold \u03b4 = 0.003 to give an overall acceptance rate of about \u03b1 = 0.68 and set the number of leap-prog steps T = 200. We then ran PPHMC for 10, 000 iterations with a burn-in of 25%. We saw that PPHMC indeed samples from the correct posterior distribution (see Figure S1 in the Appendix)."}, {"heading": "4.2. Empirical data", "text": "We also analyzed an empirical data set labeled DS4 by Whidden and Matsen (2015) that has become a standard benchmark for MCMC algorithms for Bayesian phylogenetics since Lakner et al. (2008). DS4 consists of 1137 nucleotide observations per leaf from N = 41 leaves representing different species of fungi. Notably, only 554 of these observations are complete; the remaining 583 are missing a character for one or more leaves so the likelihood is marginalized over all possible characters. Whidden and Matsen (2015) observed that the posterior distribution for DS4 features high-probability trees separated by paths through low-probability trees and thus denoted it a \u201cpeaky\u201d data set that was difficult to sample from using MrBayes.\nTo find the optimal choice of tuning parameters for DS4, we did a grid search on the space of step size and the smoothing threshold\u2013step size ratio \u03b4/ . The number of leap-prog steps T was adjusted to keep the total simulation time T fixed. For each choice of parameters, we estimated the expected acceptance rate \u03b1 by averaging over 20 proposals from the PPHMC transition kernel per state for 100 states sampled from the posterior in a previous, well-mixed run. This strategy enabled us to obtain an accurate estimate of the average acceptance rate without needing to account for the different mixing rates in a full PPHMC run due to the various settings for the tuning parameters.\nThe results suggest that choosing \u03b4 \u2248 2 maximizes the acceptance probability (Figure 2b). Furthermore, when aiming for the optimal acceptance rate of \u03b1 = 0.65 (Neal, 2011), the use of the surrogate function enables a choice of step size nearly 10 times greater than otherwise. In practice, this means that an equivalent proposal requires less leap-prog steps and gives a more efficient sampling algorithm.\nTo see the difference this makes in practice, we ran long trajectories for exact and surrogate-smoothed PPHMC with a relatively large step size = 0.0008. Indeed, we found that the surrogate enables very long trajectories and large number of topology transformations (Figure 2a,c)."}, {"heading": "5. Conclusion", "text": "Sophisticated techniques for sampling posteriors using HMC have thus far been restricted to manifolds with\nboundary. To address this limitation, we have developed \u201cPPHMC,\u201d which is the first extension of HMC to a space with intricate combinatorial structure. The corresponding integrator makes a random choice among alternatives when encountering a boundary. To prove ergodicity, we extend familiar elements of HMC proofs to this probabilistic path setting. We develop a smoothing surrogate function that enables long HMC paths with many boundary transitions across which the posterior is not differentiable. Our surrogate method enables high acceptance probability for RHMC (Afshar and Domke, 2015) in the case of potential functions with discontinuous derivatives; this aspect of our work is independent of the probabilistic nature of PPHMC. Our implementation shows good performance on both simulated and real data. There are many opportunities for future development, including extending the theory to other classes of combinatorially-described spaces and surrogate functions, developing adaptive path length algorithms, as well as extending our implementation for phylogenetics to sample other mutation model and demographic parameters along with topologies."}, {"heading": "Acknowledgements", "text": "This work supported by National Science Foundation grants DMS-1223057, DMS-1341325, and CISE-1564137. The research of Frederick Matsen was supported in part by a Faculty Scholar grant from the Howard Hughes Medical Institute and the Simons Foundation. The authors are grateful to Alex Gavryushkin for helpful discussions about this work."}], "year": 2017, "references": [{"title": "Reflection, refraction, and Hamiltonian Monte Carlo", "authors": ["Hadi Mohasel Afshar", "Justin Domke"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2015}, {"title": "Moving robots efficiently using the combinatorics of cat (0) cubical complexes", "authors": ["Federico Ardila", "Tia Baker", "Rika Yatchak"], "venue": "SIAM Journal on Discrete Mathematics,", "year": 2014}, {"title": "Hybrid Monte Carlo on Hilbert spaces", "authors": ["Alexandros Beskos", "Frank J Pinski", "Jes\u00fas Mar\u0131a Sanz-Serna", "Andrew M Stuart"], "venue": "Stochastic Processes and their Applications,", "year": 2011}, {"title": "A conceptual introduction to Hamiltonian Monte Carlo", "authors": ["Michael Betancourt"], "venue": "arXiv preprint arXiv:1701.02434,", "year": 2017}, {"title": "Geometry of the space of phylogenetic trees", "authors": ["Louis J Billera", "Susan P Holmes", "Karen Vogtmann"], "venue": "Advances in Applied Mathematics,", "year": 2001}, {"title": "A family of MCMC methods on implicitly defined manifolds", "authors": ["Marcus A Brubaker", "Mathieu Salzmann", "Raquel Urtasun"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "year": 2012}, {"title": "The splits in the neighborhood of a tree", "authors": ["David Bryant"], "venue": "Ann. Comb.,", "year": 2004}, {"title": "The recovery of trees from measures of dissimilarity", "authors": ["O Peter Buneman"], "venue": "Mathematics in the archaeological and historical sciences,", "year": 1971}, {"title": "Theoretical and numerical comparison of some sampling methods for molecular dynamics", "authors": ["Eric Cances", "Fr\u00e9d\u00e9ric Legoll", "Gabriel Stoltz"], "venue": "ESAIM: Mathematical Modelling and Numerical Analysis,", "year": 2007}, {"title": "Biopython: freely available python tools for computational molecular biology and bioinformatics", "authors": ["P.A. Cock", "T. Antao", "J.T. Chang", "B.A. Chapman", "C.J. Cox", "A. Dalke", "I. Friedberg", "T. Hamelryck", "F. Kauff", "B. Wilczynski", "M.J.L. de Hoon"], "year": 2009}, {"title": "Hybrid Monte Carlo", "authors": ["S. Duane", "A.D. Kennedy", "B J. Pendleton", "D. Roweth"], "venue": "Physics Letters B,", "year": 1987}, {"title": "Measure theory and fine properties of functions", "authors": ["Lawrence Craig Evans", "Ronald F Gariepy"], "venue": "CRC press,", "year": 2015}, {"title": "Geometries on spaces of treelike shapes", "authors": ["Aasa Feragen", "Francois Lauze", "Pechin Lo", "Marleen de Bruijne", "Mads Nielsen"], "venue": "In Asian Conference on Computer Vision,", "year": 2010}, {"title": "The phylogenetic likelihood library", "authors": ["T. Flouri", "F. Izquierdo-Carrasco", "D. Darriba", "A.J. Aberer", "L.T. Nguyen", "B.Q. Minh", "A. Von Haeseler", "A. Stamatakis"], "venue": "Syst. Bio.,", "year": 2015}, {"title": "The space of ultrametric phylogenetic trees", "authors": ["Alex Gavryushkin", "Alexei J Drummond"], "venue": "J. Theor. Biol., 403:197\u2013208,", "year": 2016}, {"title": "Riemann manifold Langevin and Hamiltonian Monte Carlo methods", "authors": ["Mark Girolami", "Ben Calderhead"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "year": 2011}, {"title": "A constrained hybrid Monte Carlo algorithm and the problem of calculating the free energy in several variables", "authors": ["Carsten Hartmann", "Christof Sch\u00fctte"], "venue": "ZAMM-Journal of Applied Mathematics and Mechanics,", "year": 2005}, {"title": "Bayesian inference of phylogeny and its impact on evolutionary biology", "authors": ["J P Huelsenbeck", "F Ronquist", "R Nielsen", "J P Bollback"], "venue": "Science, 294(5550):2310\u20132314,", "year": 2001}, {"title": "ETE3: Reconstruction, analysis and visualization of phylogenomic data", "authors": ["Jaime Huerta-Cepas", "Francois Serra", "Peek Bork"], "venue": "Mol. Biol. Evol.,", "year": 2016}, {"title": "Evolution of protein molecules", "authors": ["Thomas H. Jukes", "Charles R. Cantor"], "year": 1969}, {"title": "Hessian calculation for phylogenetic likelihood based on the pruning algorithm and its applications", "authors": ["Toby Kenney", "Hong Gu"], "venue": "Stat. Appl. Genet. Mol. Biol.,", "year": 2012}, {"title": "Slicing hyperdimensional oranges: the geometry of phylogenetic estimation", "authors": ["Junhyong Kim"], "venue": "Molecular phylogenetics and evolution,", "year": 2000}, {"title": "Efficiency of markov chain monte carlo tree proposals in bayesian phylogenetics", "authors": ["Clemens Lakner", "Paul van der Mark", "John P Huelsenbeck", "Bret Larget", "Fredrik Ronquist"], "venue": "Syst. Biol.,", "year": 2008}, {"title": "Spherical Hamiltonian Monte Carlo for constrained target distributions", "authors": ["Shiwei Lan", "Bo Zhou", "Babak Shahbaba"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "year": 2014}, {"title": "On the nearest neighbour interchange distance between evolutionary trees", "authors": ["M Li", "J Tromp", "L Zhang"], "venue": "J. Theor. Biol.,", "year": 1996}, {"title": "Peeling phylogenetic oranges", "authors": ["Vincent Moulton", "Mike Steel"], "venue": "Advances in Applied Mathematics,", "year": 2004}, {"title": "MCMC using Hamiltonian dynamics", "authors": ["Radford M Neal"], "venue": "Handbook of Markov Chain Monte Carlo,", "year": 2011}, {"title": "General state space Markov chains and MCMC algorithms", "authors": ["Gareth O Roberts", "Jeffrey S Rosenthal"], "venue": "Probability Surveys,", "year": 2004}, {"title": "Comparison of labeled trees with valency three", "authors": ["David F Robinson"], "venue": "Journal of Combinatorial Theory, Series B,", "year": 1971}, {"title": "Phylogenetics", "authors": ["C Semple", "M Steel"], "year": 2003}, {"title": "Gradient-free Hamiltonian Monte Carlo with efficient kernel exponential families", "authors": ["Heiko Strathmann", "Dino Sejdinovic", "Samuel Livingstone", "Zoltan Szabo", "Arthur Gretton"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2015}, {"title": "Adaptive Hamiltonian and Riemann manifold monte carlo", "authors": ["Ziyu Wang", "Shakir Mohamed", "Nando de Freitas"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "year": 2013}, {"title": "Quantifying MCMC exploration of phylogenetic tree space", "authors": ["Chris Whidden", "IV Matsen", "Frederick A"], "venue": "Syst. Biol.,", "year": 2015}, {"title": "Hamiltonian Monte Carlo acceleration using surrogate functions with random bases", "authors": ["Cheng Zhang", "Babak Shahbaba", "Hongkai Zhao"], "venue": "Statistics and Computing,", "year": 2016}, {"title": "Bayesian analysis of continuous time markov chains with application to phylogenetic modelling", "authors": ["Tingting Zhao", "Ziyu Wang", "Alexander Cumberworth", "Joerg Gsponer", "Nando de Freitas", "Alexandre Bouchard-C\u00f4t\u00e9"], "venue": "Bayesian Anal.,", "year": 2016}], "id": "SP:2680b419ded4530e7e7ae9b05298364cc7a21572", "authors": [{"name": "Vu Dinh", "affiliations": []}, {"name": "Arman Bilge", "affiliations": []}, {"name": "Cheng Zhang", "affiliations": []}, {"name": "Frederick A. Matsen", "affiliations": []}], "abstractText": "Hamiltonian Monte Carlo (HMC) is an efficient and effective means of sampling posterior distributions on Euclidean space, which has been extended to manifolds with boundary. However, some applications require an extension to more general spaces. For example, phylogenetic (evolutionary) trees are defined in terms of both a discrete graph and associated continuous parameters; although one can represent these aspects using a single connected space, this rather complex space is not suitable for existing HMC algorithms. In this paper, we develop Probabilistic Path HMC (PPHMC) as a first step to sampling distributions on spaces with intricate combinatorial structure. We define PPHMC on orthant complexes, show that the resulting Markov chain is ergodic, and provide a promising implementation for the case of phylogenetic trees in opensource software. We also show that a surrogate function to ease the transition across a boundary on which the log-posterior has discontinuous derivatives can greatly improve efficiency.", "title": "Probabilistic Path Hamiltonian Monte Carlo"}
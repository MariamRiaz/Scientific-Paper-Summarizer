25	69	When tested on the WikiSQL (Zhong et al., 2017) dataset, our model increases the query match accuracy of SQLNet (Xu et al., 2017) from 61.3% to 69.0% using on average 2.4 validation questions per query.
48	55	In particular, our goal is to design a dialogue system to extract and validate potential errors in generated queries by asking users multi-choice questions over multiple turns.
54	14	Candidate choices depend on the error category and range over the following possibilities: (i) a column name, (ii) an aggregation operator, or (iii) a where condition.
60	71	We use a template based natural language generation (NLG) component to convert system and user responses into natural language.
62	22	Each example in WikiSQL consists of a natural language question and a table to query from.
67	25	At the start of the dialogue, we synthesize a new query by randomly altering the ground truth query and populating the agenda by the sequence of altering actions.
68	18	Each action launches a sequence of sub-actions: (i) Randomly select an error category and extract a related span from the current query, (ii) randomly generate a valid choice for the chosen span, and (iii) update the current query by replacing the span with the choice.
75	36	In Step-2, the system starts with validating the aggregation with the user simulator.
80	17	DialSQL interacts with the same rule-based simulator during testing and the SQL queries obtained at the end of the dialogues are used to evaluate the model.
83	14	Given a (Q,T, U) triplet, the model first encodes Q, each column name Ti ∈ T , and query U into vector representations in parallel using Recurrent Neural Networks (RNN).
96	40	Encoding System and User Turns Since there is only a single candidate choice during training, we ignore the index and encode user turn by doing an embedding lookup using the validation answer (affirmation or negation).
97	11	Each element (error category, error span, and candidate choice) of the system response is encoded by doing an embedding lookup and different elements are used as input at different layers of our model.
98	95	Encoding Dialogue History At the end of each user turn, we first concatenate the previous error category and the current user turn encodings to generate the turn level input.
107	18	End position j of the error span is predicted by conditioning on the start position ci = ∑ pi ∗HU p̂j = softmax(tanh([h D2 t , ci]L2H U )) where p̂j is the probability of end position over the jth query token.
110	18	Inspired by SQLNet (Xu et al., 2017), we describe our candidate choice decoding approach as follows.
113	25	We first decode the condition column name similar to decoding select column.
120	23	In this section, we evaluate DialSQL on WikiSQL using several evaluation metrics by comparing with previous literature.
124	25	We count the number of turns to analyze whether DialSQL generates any redundant validation questions.
125	31	We use the average number of tokens in the generated validation questions to evaluate if DialSQL can generate simple questions without overwhelming users.
126	28	Since SQLNet and Seq2SQL are single-step models, we can not analyze DialSQL’s performance by comparing against these on the last two metrics.
127	38	We overcome this issue by generating simulated dialogues using an oracle system that has access to the ground truth query.
158	18	We observe that offering even a single candidate improves the performance of SQLNet remarkably, 1.9% and 2.5% for development and test sets, respectively.
167	16	At each turn, we show users the headers of the corresponding table, original question, system response, and list of candidate choices for users to pick.
169	17	Also, we add an additional choice of None of the above so that users can keep the previous prediction unchanged.
182	33	Average MMR is 0.69 with standard deviation of 0.004 which also shows that users generally prefer the choices ranked higher by DialSQL.
184	56	The average score is 2.86 with standard deviation of 0.14, showing users can understand DialSQL responses and can pick a choice confidently.
185	33	We demonstrated the efficacy of the DialSQL, improving the state of the art accuracy from 62.5% to 69.0% on the WikiSQL dataset.
188	62	The model learns from only simulated data which makes it easy to adapt to new domains.
189	44	We further investigate the usability of DialSQL in a real life setting by conducting human evaluations.
190	53	Our results suggest that the accuracy of the generated queries can be improved via real user feedback.

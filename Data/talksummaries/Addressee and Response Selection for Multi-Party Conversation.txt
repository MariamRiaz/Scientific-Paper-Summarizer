0	44	Short text conversation (STC) has been gaining popularity: given an input message, predict an appropriate response in a single-round, two-party conversation (Wang et al., 2013; Shang et al., 2015).
2	11	Beyond two-party conversations, there is also a need for modeling multi-party conversation, a form of conversation with several interlocutors conversing with each other (Traum, 2003; Dignum and Vreeswijk, 2003; Uthus and Aha, 2013).
4	15	Each agent might have one part of the solution, and these pieces have to be combined through conversation in order to come up with the whole solution.
5	28	A unique issue of such multi-party conversations is addressing, a behavior whereby interlocutors indicate to whom they are speaking (Jovanović and Akker, 2004; Akker and Traum, 2009).
6	32	In faceto-face communication, the basic clue for specifying addressees is turning one’s face toward the addressee.
7	48	In contrast, in voice-only or textbased communication, the explicit declaration of addressee’s names is more common.
8	22	In this work, we tackle addressee and response selection for multi-party conversation: given a context, predict an addressee and response.
43	18	In this work, we assume the situation where one specific agent can be the addressee of a response.
44	11	To predict an addressee a as a target output, we select an agent from a set of the agents appearing in a context A(C).
46	18	To predict an appropriate response r, we select a response from a set of candidate responses R, which consists of Q candidates: R = {r1, · · · , rQ} rq = (wq,1, · · · , wq,Nq) where rq is a candidate response, which consists of Nq tokens, and wq,n is an token index in the vocabulary V .
47	28	Our proposed models are extensions of the dual encoder (DE) model in (Lowe et al., 2015).
48	73	The DE model consists of two recurrent neural networks (RNN) that respectively compute the vector representation of an input context and candidate response.
55	29	We present two multi-party modeling frameworks: (i) static modeling and (ii) dynamic modeling, both of which jointly utilize agent and utterance representation for encoding multiple-party conversation.
60	25	The personality-independent representation allows us to handle new agents unseen in the training data.
61	13	2, both of the models calculate the probability that the addressee ap or response rq is the ground-truth given the input x: Pr(y(ap) = 1|x) = σ ([ares ; hc]T Wa ap) (3) Pr(y(rq) = 1|x) = σ ([ares ; hc]T Wr hq) (4) where y is a binary function mapping from ap or rq to {0, 1}, in which 1 represents the ground-truth sample and 0 represents the false one.
63	17	ares ∈ Rda is a responding agent vector, ap ∈ Rda is a candidate addressee vector, hc ∈ Rdh is a context vector, hq ∈ Rdh is a candidate response vector.
67	57	3 and 4, a resulting addressee and response are selected as follows: â = argmax ap∈A(C) Pr(y(ap) = 1|x) (5) r̂ = argmax rq∈R Pr(y(rq) = 1|x) (6) where â is the highest probability addressee of a set of agents in the context A(C), and r̂ is the highest probability response of a set of candidate responses R.
74	34	First, agents in the context A(C) and a responding agent ares are sorted in descending order based on each latest speaking time.
77	37	Similarly, User 1 has the index 2 because he spoke at the second most recent time step t = 5, and User 2 has the index 3 because he spoke at the third t = 3.
78	61	Each speaking-order index am is associated with the am-th column of the agent matrix A: am = A[∗, am] Similarly, a responding agent vector ares and a candidate addressee vector ap in Eqs.
92	41	Then, each agent state is updated by consuming the utter- ance vector at each time step.
98	13	For example, at a time step t = 2 in Figure 3, the agent state vector a1,2 is influenced by its utterance vector u1,2 and updated from the previous state a1,1.
99	36	The agent matrix updated up to the time step T is denoted as AT , which is max-pooled and used as a summarized context vector: hc = max i AT [i] The agent matrix AT is also used for a responding agent vector ares and a candidate addressee vector ap, i.e. ares = AT [∗, ares] and ap = AT [∗, ap].
101	17	We train the model parameters by minimizing the joint loss function: L(θ) = α La(θ) + (1− α) Lr(θ) + λ 2 ||θ||2 whereLa is the loss function for the addressee selection, Lr is the loss function for the response selection, α is the hyper-parameter for the interpolation, and λ is the hyper-parameter for the L2 weight decay.
161	10	The dynamic model achieves the best results in all the metrics.
162	10	The static model outperforms the baseline, but is inferior to the dynamic model.
167	10	In response selection (RES), our models outperform the baseline.
189	18	In this work, we assume that the situations where there is a specific addressee that needs an appropriate response and a system is required to respond.
190	65	In actual multi-party conversation, however, a system sometimes has to wait and listen to the conversation that other participants are engaging in without needless interruption.
191	41	Hence, the prediction of whether to respond in a multi-party conversation would be an important next challenge.

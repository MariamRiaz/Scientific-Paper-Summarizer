15	33	For the third consecutive year, a record number of new drugs (49) were detected in Europe in 2011 (EMCDDA, 2012).
16	37	About two-thirds of these new drugs were synthetic cannabinoids (used as legal marijuana substitutes), which led to 11,000 hospitalizations in the U.S. in 2010 (SAMHSA, 2012).
18	34	Accurate information on drug trends can be obtained by speaking directly with users, e.g. focus groups and interviews (Reyes et al., 2012; Hout and Bingham, 2012), but such studies are slow and costly, and can fail to identify the emergence of new drug classes, such as mephedrone (Dunn et al., 2011).
20	46	By (manually) analyzing YouTube videos, Drugs-Forum (discussed below), and other social media websites and online communities, researchers have uncovered details about the use, effects, and popularity of a variety of new and emerging drugs (Morgan et al., 2010; Corazza et al., 2012; Gallagher et al., 2012), and comprehensive drug reviews now include nonstandard sources such as web forums in addition to standard sources (Hill and Thomas, 2011).
23	54	While topic models are a natural fit for corpus exploration (Eisenstein et al., 2012; Chaney and Blei, 2012), and have been used for similar public health applications (Paul and Dredze, 2011), online forums can be organized in many ways beyond topic.
35	31	Clinical researchers are interested in specific information about drug usage, including drug type, route of administration, and other aspects of drug use (e.g. dosage, side effects).
36	26	Rather than considering these factors independently, we would like to model these in a way that can capture interesting interactions between all three factors, because the effects and other aspects of drugs can vary by route of administration.
38	80	Many mephedrone users report nose bleeds and nasal pain as a health effect of snorting the drug: this could be modeled as the triple (MEPHEDRONE,SNORTING,HEALTH), a particular combination of all three factors.
39	46	To this end, we utilize the multi-dimensional text model factorial LDA (f-LDA) (Paul and Dredze, 2012b), which jointly models multiple semantic factors or dimensions.
41	71	In a standard topic model such as LDA (Blei et al., 2003), each word token is associated with a latent “topic” variable.
42	21	f-LDA is conceptually similar to LDA except that rather than a single topic variable, each token is associated with a K-dimensional vector of latent variables.
45	21	Under this model, words are generated by first sampling a tuple from the document’s tuple distribution, then sampling a word from that tuple’s word distribution.
53	39	One would expect that triples that have components in common should have similar word distributions: (CANNABIS,SMOKING,EFFECTS) is expected to have some commonalities with (CANNABIS,ORAL,EFFECTS).
55	21	Formally, φ~t (the word distribution for tuple ~t) has a Dirichlet(ω̂(~t)) prior, where for each word w in the vector, ω̂( ~t) w is a log-linear function: ω̂( ~t ) w , exp ( ω(B)+ω(0)w +ω (drug) t1w +ω (route) t2w +ω (aspect) t3w ) (1) where ω(B) is a corpus-wide precision scalar (the bias), ω(0)w is a corpus-specific bias for word w, and ω (k) tkw is a bias parameter for word w for component tk of the kth factor.
56	75	That is, each drug, route, and aspect has a weight vector over the vocabulary, and the prior for a particular triple is influenced by the weight vectors of each of the three factors.
65	21	Each element b~t of the array is a real-valued scalar in (0, 1) which is multiplied with α̂(d)~t to adjust the prior for that triple.
68	43	Posterior inference and parameter estimation consist of a Monte Carlo EM algorithm that alternates between an iteration of collapsed Gibbs sampler on the ~z variables (E-step), and an iteration of gradient ascent on the α and ω hyperparameters (M-step).
69	30	See Paul and Dredze (2012b) for more details.
71	57	However, the forums include metadata that can help guide the model: the messages are organized into forums corresponding to drug type (factor 1), and some threads are tagged with labels corresponding to routes of administration and other aspects (factors 2 and 3).
74	89	One could simply use these tags as labels in a simple supervised model—this will be our experimental baseline (§4.1).
86	24	Instead, these weight vectors will merely guide learning as prior knowledge over model parameters ω.
111	42	We also included a GENERAL component in the latter two factors to model word usage which does not pertain to a particular route or aspect; the prior parameters η for these components were simply set to 0.
160	62	For each tuple-specific word distribution (a pair or a triple), we create a “summary” by extracting a set of five text snippets which minimize KL-divergence to the target word distribution.
165	30	Because each reference may be matched to more than one tuple, there may be more than five snippets which correspond to a reference.
166	72	Recall that the reports used as reference summaries were themselves created by reading web forums.
172	27	Three annotators were presented snippets pooled from all four systems we are evaluating alongside the corresponding reference text.
183	41	This suggests that exploring the forums in a targeted way (e.g. through our topic model approach) would be more efficient than exploring the data in a non-targeted way (akin to the random approach).
188	21	We computed ROUGE for both 1-grams and 2- grams.
194	125	f-LDA-1 had slightly better recall (under ROUGE), while f-LDA-2 was slightly better according to the human annotators.
199	37	As a technical contribution, this study lays out practical guidelines for customizing and incorporating prior knowledge into multi-dimensional text models.

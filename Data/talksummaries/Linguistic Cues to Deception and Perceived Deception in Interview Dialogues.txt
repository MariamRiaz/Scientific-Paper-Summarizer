0	38	Deception detection is a critical problem studied by psychologists, criminologists, and computer scientists.
1	25	In recent years the NLP and speech communities have increased their interest in deception detection.
2	24	Language cues are inexpensive and easy to collect, and research examining text-based and speech-based cues to deception has been quite promising.
4	13	In this work we explore the domain of interview dialogues, which are similar to many real-world deception conditions.
7	44	We might know that a particular feature set (e.g. LIWC categories) is useful for deception classification, but we lack insight about the nature of the deceptive and truthful language that makes the feature set useful, and whether the differences in language use are statistically significant.
11	20	We examine a unique dataset that includes information about both the deceiver and the interviewer, along with interviewer judgments of deception.
12	36	Along with an analysis of deceptive and truthful speech, we analyze the believed and disbelieved speech, according to reported interviewer judgments.
17	28	In Section 5, we report on the results of our empirical study of indicators of deception and perceived deception, as well as gender and native language differences.
34	43	For this work, we examined the Columbia XCultural Deception (CXD) Corpus (Levitan et al., 2015a) a collection of within-subject deceptive and non-deceptive speech from native speakers of Standard American English (SAE) and Mandarin Chinese (MC), all speaking in English.
35	15	The corpus contains dialogues between 340 subjects.
41	21	For the first half of the game, one subject assumed the role of the interviewer, while the other answered the biographical questions, lying for half and telling the truth for the other; questions chosen in each category were balanced across the corpus.
50	33	Global labels were provided by the biographical questionnaire, where each of the 24 questions was labeled as truthful or deceptive.
69	49	We performed our analysis and classification on two segmentations of the data using this tagging method: (1) first turn: we analyzed only the single interviewee turn directly following the original question, and (2) multiple turns we analyzed the entire segment of interviewee turns that were responding to the original interviewer question and subsequent follow-up questions.
73	18	LIWC is a text analysis program that computes features consisting of normalized word counts for 93 semantic classes.
89	61	In order to analyze the differences between deceptive and truthful speech, we extracted the above features from each question response-segment, and calculated a series of paired t-tests between the features of truthful speech and deceptive speech.
94	36	In contrast to (DePaulo et al., 2003), we found that the total duration of an interviewee responsesegment was longer for deceptive speech than for truthful speech.
105	25	Words in the LIWC clout category - a category describing words that indicate power of influence - were more prevalent in deceptive responses, suggesting that subjects sounded more confident while lying.
123	83	There were many features that were prevalent in speech that interviewers perceived as deceptive, which were in fact cues to deception.
128	20	There were also features that were significantly different between believed and disbelieved statements, but were not indicators of deception.
137	19	Having discovered many differences between deceptive and truthful language across all speakers, we were interested in analyzing differences in deceptive language across groups of speakers.
152	15	Interviewees were more successful at deceiving native Chinese speakers than at deceiving native English speakers (t(170) = âˆ’2.13, p = 0.033).
154	23	When considering only female interviewers, interviewees were more successful at deceiving nonnative speakers than native speakers, but this difference was not significant when considering only male interviewers.
165	49	Motivated by our analysis showing many significant differences in the language of truthful and deceptive responses to interview questions, we trained machine learning classifiers to automatically distinguish between truthful and deceptive text, using the feature sets described in section 4.
176	23	The Random For- est classifier was consistently the best performing, and we only report those results due to space constraints.
181	18	The performance of classifiers trained on multiple turns was consistently better than those trained on single turns, for all feature sets.
192	14	We also analyzed the linguistic characteristics of speech that is perceived as deceptive and truthful, which is important for understanding the nature of trustworthy speech.
194	44	We built classifiers that use combinations of linguistic features and individual traits to automatically identify deceptive speech.
195	16	We compared the performance of using cues from the single first turn of an interviewee response-segment with using cues from the full context of multiple interviewee turns, achieving performance as high as 72.74% F1-score (about 27% better than human detection performance).
198	20	In addition, we plan to conduct cross-corpus machine learning experiments, to evaluate the robustness of these and other feature sets in deception detection.
199	133	We also would like to explore additional feature combinations, such as adding acoustic-prosodic features.

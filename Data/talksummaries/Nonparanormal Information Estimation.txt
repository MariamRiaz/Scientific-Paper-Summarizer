0	130	This paper is concerned with the problem of estimating entropy or mutual information of an unknown probability density p over RD, given n i.i.d.
1	48	samples from p. Entropy and mutual information are fundamental information theoretic quantities, and consistent estimators for these quantities have a host of applications within machine learning, statistics, and signal processing.
5	21	Motivated by these and other applications, several very recent lines of work (discussed in Section 3) have studied information estimation,1 focusing largely on two settings: 1.
7	10	Nonparametric Setting: If p is assumed to lie in a nonparametric smoothness class, such an s-order2 Hölder or Sobolev class, then the minimax MSE is of asymptotic order max { n−1, n− 8s 4s+D } (Birgé & Massart, 1995).
8	16	In the Gaussian setting, consistent estimation is tractable even in the high-dimensional case whereD increases fairly quickly with n, as long as D/n → 0.
13	33	Given these factors, though the Gaussian and nonparametric cases are fairly well understood in theory, there remains a lack of practical information estimators for the common case where data are neither exactly Gaussian nor very low dimensional.
17	11	The result scales better with dimension than nonparametric models, while being more robust than Gaussian models.
34	27	We now define the class of nonparanormal distributions, from which we assume our data are drawn.
35	20	(Nonparanormal distribution, a.k.a.
36	23	Gaussian copula model) A random vector X = (X1, .
41	32	Minimal assumptions are made on the marginal distributions; any desired continuously differentiable marginal cumulative distribution function (CDF) Fi of variableXi corresponds to marginal transformation fi(x) = Φ−1(Fi(x)) (where Φ is the standard normal CDF).
84	13	In this section, we present three different estimators, IG, Iρ, and Iτ , for the mutual information of a nonparanormal distribution.
90	18	The first estimator Σ̂G of Σ proceeds in two steps.
98	19	ρ and τ generalize to the D-dimensional setting in the form of rank correlation matrices ρ, τ ∈ [−1, 1]D×D with ρj,k = ρ(Xj , Xk) and τj,k = τ(Xj , Xk) for each j, k ∈ [D].
110	15	To correct for this, we propose a regularization step, in which we project each estimated latent covariance matrix onto the (closed) cone S(z) of symmetric matrices with minimum eigenvalue z > 0.
115	14	Here, we provide finite-sample upper bounds on the error of the estimator Îρ based on Spearman’s ρ.
147	17	Thus, it is reasonable to think of lower bounds for rank-based estimators in the Gaussian case as lower bounds for any estimator in the nonparanormal case.
168	18	All experimental results are displayed in Figure 1.
171	25	Experiment 2 (Non-Gaussian Marginals): Next, we show nonparanormal estimators are robust to nonGaussianity of the marginals, unlike Î .
182	25	This mitigate this, we increased k to 20 and ignored trials where ÎkNN = ∞, but ÎkNN ceased to give any finite estimates when β was sufficiently large.
186	15	Adding random (uncorrelated) noise reduces estimated dependence, moving the estimate closer to the true value.
200	26	While the entropy H(X) does depend on the marginal transform f , fortunately, by Eq.
212	21	While the best choice of information estimator inevitably depends on context, as an off-the-shelf guide for practitioners, the estimators we suggest, in order of preference, are: • fully nonparametric if D < 6, n > max{100, 10D}.
213	11	• Îρ if D2/n is small and data may have outliers.
219	35	Can nonparanormal assumptions lead to higher dimensional estimators for the many other useful nonlinear functionals of densities (e.g., Lp norms/distances and more general (e.g., Rényi or Tsallis) entropies, mutual informations, and divergences) that do not decompose?
221	9	Is quadratic dependence on D optimal?
227	10	Besides information estimation, the work of Cai et al. (2015) on estimating log |Σ| in the Gaussian model was motivated by the role of log |Σ| in other multivariate statistical tools, such as quadratic discriminant analysis (QDA) and MANOVA (Anderson, 1984).
228	19	Can our estimators lead to more robust nonparanormal versions of these tools?
229	20	This research is supported in part by DOE grant DESC0011114 and NSF grant IIS1563887 to B.P., and by an NSF Graduate Research Fellowship to S.S. under Grant No.
230	26	Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.

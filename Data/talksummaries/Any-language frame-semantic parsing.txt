0	19	Frame-semantic parsing is the task of automatically finding semantically salient targets in text, disambiguating the targets by assigning a sense (frame) to them, identifying their arguments, and labeling these arguments with appropriate roles.
1	21	The FRAMENET 1.5 lexicon1 provides a fixed repository of semantic frames and roles, which we use in the experiments below.
3	22	In contrast to Propbank-style semantic-role labeling (Titov and Klementiev, 2012), only very limited frame-semantic resources exist for languages other than English.
4	19	We therefore focus on multilingual or cross-language framesemantic parsing, leveraging resources for English and other major languages to build any-language parsers.
5	50	We stress that we learn frame-semantic parsing models that can be applied to any language, rather than cross-lingual transfer models for specific target languages.
9	36	We present a new multilingual frame-annotated corpus covering five topics, two domains (Wikipedia and Twitter), and nine languages.
10	29	We implement a simplified version of the frame-semantic parser introduced in Das et al. (2014).
11	68	Finally, we show how to modify this parser to learn any-language frame-semantic parsing models using inter-lingual word embeddings (Søgaard et al., 2015a).
13	5	The annotator marked two words, Idee and kam, as targets.
14	15	In frame-semantic parsing, target identification is the task of deciding which words (i.e. targets) trigger FRAMENET frames.
16	18	Argument identification is the problem of identifying the arguments of frames, e.g., Idee for COMING_UP_WITH.
20	28	Both data from Wikipedia and Twitter cover the same five topics: Google, Angelina Jolie, Harry Potter, Women’s Rights, and Christiano Ronaldo.
21	11	The topics were chosen to guarantee coverage for all nine languages, both in Wikipedia and Twitter.
24	6	The English, Danish, and Spanish datasets were doubly-annotated in order to compute interannotator agreement (IAA).
34	5	The relatively low reliability compared to previous annotation efforts is due to the cross-lingual pre-annotation step, which was necessary to make annotation feasible.
45	8	We use a multinomial loglinear classifier4 (with default parameters) to decide which of the possible frames evoked by the target word that fits the context best.
48	177	One feature group uses the embedding of the target word directly, while the other is based on distance measures between the target word and the set of English words used as targets for a possible frame.
49	23	We measure the minimum and mean distance (in embedding space) from the target word to the set of English target words, as well as the distances to each word individually.
51	36	We use the Universal Dependencies v1.1 treebanks for the languages in our data to train part-of-speech taggers (TREETAGGER5) and a dependency parser (TURBOPARSER6) to generate the syntactic features.
54	20	Argument identification is concerned with assigning frame arguments to spans of words in the sentence.
58	5	Each word index is associated with a span by the transitive closure of its syntactic dependencies (i.e. subtree).
59	39	Our greedy approach to argument identification thus amounts to scoring the n+ 1 possible realisations of an argument for an n-length sentence (i.e. subtrees plus the empty argument), selecting the highest scoring subtree for each argument type allowed by the frame.
63	21	Positive examples are the observed arguments.
71	7	Our baseline is a more direct application of the SEMAFOR system7 (Das et al., 2014), translating target language text to English using word-to-word translations and projecting annotation back.
75	44	We observe that using BABELNET and our re-implementation of Das et al. (2014) performs considerably better than running SEMAFOR on Wiktionary word-by-word translations.
76	9	Our frame identification results are also presented in Table 2.
84	10	For Danish, the gap is smaller.
85	14	If we compare performance on Wikipedia and Twitter datasets, we see that target identification and frame identification scores are generally higher for Wikipedia, while argument identification scores are higher for Twitter.
87	21	We presented a multi-lingual frame-annotated corpus covering nine languages in two domains.
88	26	With this corpus we performed experiments to predict target, frame and argument identification, outperforming a word-to-word translated baseline running on SEMAFOR.

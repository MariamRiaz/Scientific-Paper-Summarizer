11	30	Action Editor: Luke Zettlemoyer.
20	18	We evaluate this model with a new, psycholinguistically motivated corpus of real-time, dyadic reference games in which the referents are patches of color.
24	32	Experiments on the data in our corpus show that this combined pragmatic model improves accuracy in interpreting human-produced descriptions over the basic RNN listener alone.
27	16	We evaluate our agents on a task of language understanding in a dyadic reference game (Rosenberg and Cohen, 1964; Krauss and Weinheimer, 1964; Paetzel et al., 2014).
30	27	To obtain a corpus of natural color reference data across varying contexts, we recruited 967 unique participants from Amazon Mechanical Turk to play 1,059 games of 50 rounds each, using the open- source framework of Hawkins (2015).
31	64	Participants were sorted into dyads, randomly assigned the role of speaker or listener, and placed in a game environment containing a chat box and an array of three color patches (Figure 1).
35	86	To ensure a range of difficulty, we randomly interspersed an equal number of trials from three different conditions: 1) close, where colors were all within a distance of θ from one another but still perceptible,1 2) split, where one distractor was within a distance of θ of the target, but the other distractor was farther than θ, and 3) far, where all colors were farther than θ from one another.
50	27	Words and characters We expect human speakers to be more verbose in split and close contexts than far contexts; the shortest, simplest color terms for the target may also apply to one or both distractors, thus incentivizing the speaker to use more lengthy descriptions to fully distinguish it.
53	17	Compared to the baseline far context, participants used significantly more words both in the split context (t = 45.85) and the close context (t = 73.06).
62	22	Comparatives were used significantly more often in the split context (z = 4.4), where only one distractor was close to the target, while superlatives were much more likely to be used in the close condition (z = 32.72).3 Negatives In our referential contexts, negation is likely to play a role similar to that of comparatives: a phrase like not the red or blue one singles out the third color, and blue but not bright blue achieves a more nuanced kind of comparison.
97	68	We use the S0 agent both as a base model for a pragmatic listener analogous to l1 in (5) and to acquire sample utterances for approximating the normalization required in defining the s1 agent in (2).
104	25	The values of score(f) for each of the K context colors are normalized in log space to produce a probability distribution over the context colors.
106	26	We also employ an LSTM-based speaker model S0(u | t, C;φ).
107	30	This speaker serves two purposes: 1) it is used to define a pragmatic listener akin to l1 in (5), and 2) it provides samples of alternative utterances for each context, to avoid enumerating the intractably large space of possible utterances.
108	63	The speaker model consists of an LSTM context encoder and an LSTM description decoder (Figure 3b).
113	22	The model is substantively similar to well-known models for image caption generation (Karpathy and Fei-Fei, 2015; Vinyals et al., 2015), which use the output of a convolutional neural network as the representation of an input image and provide this representation to the RNN as an initial state or first word (we represent the context using a second RNN and concatenate the context representation onto each input word vector).
114	70	Using the above base agents, we define a pragmatic speaker S1 and a pragmatic listener L2: S1(u | t, C; θ) = L0(t | u,C; θ)α∑ u′ L0(t | u′, C; θ)α (6) L2(t | u,C; θ) = S1(u | t, C; θ)∑ t′ S1(u | t′, C; θ) (7) These definitions mirror those in (2) and (3) above, with L replaced by the learned weights θ.
131	69	We use ADADELTA (Zeiler, 2012) and Adam (Kingma and Ba, 2014), adaptive variants of stochastic gradient descent (SGD), to train listener and speaker models.
146	26	Our pragmatic speaker’s use of negation shows the same relationship to the context (z = 8.55 and z = 16.61, respectively).
149	105	Table 3 shows the accuracy and perplexity of the base listener L0, the pragmatic listeners L1 and L2, and the blended models La, Lb, and Le at resolving the human-written color references.
154	16	Blending the pragmatic models with the base listener also improves over both individually, although not significantly in the case of Lb over L2.
170	92	Only two utterances in the alternative set (the actual utterance blue and the sampled alternative true blue) result in any appreciable probability mass on the true target, so the pragmatic listener’s model of the speaker predicts that the speaker would usually choose one of these two utterances for the prototypical blue.
179	16	The discrepancy between the two kinds of models in many of these examples can be explained by the fact that the speaker takes the context as input, while the listener does not.
191	21	In fact, if we were not comparing it to the other colors in the context, distractor 2 would be a very good example of a drab green that is not bluish.
192	41	The speaker S0, however, produces utterances conditioned on the context; it has successfully learned that drab would be more likely as a description of the grayish green than as a description of the yellowish one in this context.
207	57	The separation of referent and utterance representation in our base speaker and listener models in principle allows easy substitution of referents other than colors (for example, images), although the performance of the listener agents could be limited by the representation of utterance semantics as a Gaussian distribution in referent representation space.
210	16	Another important next step is to pursue multiturn dialogue.
211	126	As noted in Section 2, both participants in our reference game task could use the chat window at any point, and more than half of dyads had at least one two-way interaction.
212	75	Dialogue agents are more challenging to model than isolated speakers and listeners, requiring long-term planning, remembering previous utterances, and (for the listener) deciding when to ask for clarification or commit to a referent (Lewis, 1979; Brown and Yule, 1983; Clark, 1996; Roberts, 1996).
213	183	We release our dataset11 with the expectation that others may find interest in these challenges as well.

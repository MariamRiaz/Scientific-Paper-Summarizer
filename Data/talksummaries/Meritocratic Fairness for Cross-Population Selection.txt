0	45	Consider the following common academic (or similar) hiring scenario: The dean has promised your department 3 faculty slots, in any areas.
1	19	Your goal is to hire the best candidates possible — but how should you identify them?
2	56	An immediate problem is that candidates are incomparable across subfields, because, among other things, standards of publication, citation counts, and letter-writing styles can vary considerably across subfields.
3	27	An attractive way to rank candidates is according to how strong they are relative to others working in the same field, to whom they are directly comparable.
43	47	For each population j, there is a pool of candidates with their raw scores (and henceforth observations) drawn i.i.d.
69	35	It is not hard to see that satisfying ex-post fairness in the generality that we have defined it is impossible, since it requires perfectly selecting the k true best CDF values from only sample data.
71	31	Unless we specify differently, the term “fair” and “fairness”refer to ex-interim fairness.
72	50	A special class of selection algorithms is the class of oblivious algorithms, which select candidates with probabilities that only depend on their empirical CDF values, not on their observations.
73	46	Definition 2.6 (Oblivious Algorithms).
76	23	As a result, we need to make no assumption on the underlying distributions to achieve both fairness and utility guarantees.
78	49	The expected loss achieved by any oblivious algorithm A is the expected average empirical CCDF values among the selected candidates.
79	22	A very simple example of an oblivious algorithm is GREEDY which selects the k individuals with the highest empirical CDF values (breaking ties uniformly at random).
80	122	Suppose that the populations sizes are the same, that is, mj = m for each j.
83	19	In this section, we provide an algorithm that satisfies approximate fairness in the sense of Definition 2.3.
85	9	First, we provide confidence intervals for the candidates’ CCDF values pij based on their empirical CCDF values p̂ij .
99	8	For each point xij , let pij be its true CCDF value and p̂ij be its empirical CCDF value in Fj .
109	12	, yn} and parameter α For each i ∈ [n]: let ỹi = yi + Lap(α) Output: the k indices with the smallest ỹi Lemma 3.4.
113	11	We will slightly abuse notation and write Pr[R = r] as a shorthand for the pdf of any random variable R evaluated at r. The ratio PiPj can then be written as∫ q∈R Pr[Q = q] (∫ t∈R Pr[ỹj = t] Pr[ỹi < min{t, q}]dt ) dq∫ q∈R Pr[Q = q] (∫ t∈R Pr[ỹi = t] Pr[ỹj < min{t, q}]dt ) dq (1) For any fixed value r ∈ R, we also have the following based on the Laplace distribution, Pr[ỹi = r] Pr[ỹj = r] = 1 2α exp ( − |r−yi|α ) 1 2α exp ( − |r−yj |α ) = exp ( |r − yj | α − |r − yi| α ) By the triangle inequality we know that |r−yj |−|r−yi| ≤ ∆.
114	10	It follows that for any t and q, exp(−∆/α) ≤ Pr[ỹi = t] Pr[ỹj = t] ≤ exp(∆/α) and, Pr[ỹi < min{q, t}] Pr[ỹj < min{q, t}] = ∫ r<min{q,t} Pr[ỹi = r] dr∫ r<min{q,t} Pr[ỹj = r] dr ≤ exp(∆/α) Plugging these bounds into Equation (1), we get PiPj ≤ exp(2∆/α).
117	9	In the light of Lemma 3.2, we will define the following confidence interval width function on the empirical CCDF values c(p̂) = 9 ln(2n/δ) √ p̂/m and a normalized score function s(p̂) = p̂/c(p̂).
119	11	Let x, y ∈ [0, 1] be the (true) CCDF values for two individuals such that x ≤ y.
125	13	This means that for any pair of individuals a and a′ with CCDF values pa < pa′ (that is, a is more qualified than a′), we also have s(p̂a) ≤ s(p̂a′) + 1 by Lemma 3.5.
126	30	Finally, by the result of Lemma 3.4 and the instantiation of NOISYTOP, we guarantee that a′ will not be selected with substantially higher probability: Aa exp(ε) ≥ Aa′ , which recovers the approximate fairness guarantee.
128	33	Then with probability at least 1 − β, the algorithm FAIRTOP instantiated with fairness parameters ε and δ has regret bounded by( 1 ε √( k n + 1 m ) 1 m + 1 mε2 ) · polylog(n, 1/β, 1/δ) Thus for example, as the smallest sampled population size m grows (fixing k and ε), our regret rapidly approaches 0.
129	33	To understand the utility guarantee better, we will state the regret bound for the following natural scaling, which is also examined in the simulations of Section 7: Corollary 3.8.
130	39	Consider an instance with two population of sizesm1 andm2 such thatm1 = αm2 for some constant α ≥ 1.
131	24	Suppose we instantiate FAIRTOP with parameter ε = Θ(1), then the regret is at most Õ (√ k m ) .
132	16	In this section, we provide a variant of the FAIRTOP algorithm that satisfies approximate ex-interim fairness across different populations, but also ex-post fairness within each population.
133	13	The key idea here is that since we know the ranking of the candidates true qualities within each population, we can guarantee ex-post fairness within populations as long as we select a prefix of candidates in each population.
135	16	Similar to FAIRTOP, the algorithm ABOVETHRE (presented in Algorithm 3) also computes the normalized scores for each candidate.

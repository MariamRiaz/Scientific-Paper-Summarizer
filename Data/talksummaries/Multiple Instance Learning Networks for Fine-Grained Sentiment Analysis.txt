0	55	Sentiment analysis has become a fundamental area of research in Natural Language Processing thanks to the proliferation of user-generated content in the form of online reviews, blogs, internet forums, and social media.
1	92	A plethora of methods have been proposed in the literature that attempt to distill sentiment information from text, allowing users and service providers to make opinion-driven decisions.
6	19	The usefulness of finer-grained sentiment analysis is illustrated in the example of Figure 1, where snippets of opposing polarities are extracted from a 2-star restaurant review.
9	21	In this work, we consider the problem of segmentlevel sentiment analysis from the perspective of Multiple Instance Learning (MIL; Keeler, 1991).
18	35	Our contributions in this work are three-fold: a novel multiple instance learning neural model which utilizes document-level sentiment supervision to judge the polarity of its constituent segments; the creation of SPOT, a publicly available dataset which contains Segment-level POlariTy annotations (for sentences and EDUs) and can be used for the evaluation of MIL-style models like ours; and the empirical finding (through automatic and human-based evaluation) that neural multiple instance learning is superior to more conventional neural architectures and other baselines on detecting segment sentiment and extracting informative opinions in reviews.1
22	36	Early work focused on unsupervised methods and the creation of sentiment lexicons (Turney, 2002; Hu and Liu, 2004; Wiebe et al., 2005; Baccianella et al., 2010) based on which the overall polarity of a text can be computed (e,g., by aggregating the sentiment scores of constituent words).
26	18	Kim (2014) introduced a very successful CNN architecture for sentence-level classification, whereas other work (Socher et al., 2011; Socher et al., 2013) uses recursive neural networks to learn sentiment for segments of varying granularity (i.e., words, phrases, and sentences).
62	17	MIL deals with problems where labels are associated with groups of instances or bags (documents in our case), while instance labels (segment-level polarities) are unobserved.
63	17	An aggregation function is used to combine instance predictions and assign labels on the bag level.
92	22	Hierarchical neural models like HIERNET have been used to predict document-level polarity by first encoding sentences and then combining these representations into a document vector.
94	20	Our Multiple Instance Learning Network (henceforth MILNET) is based on the following intuitive assumptions about opinionated text.
95	17	Each segment conveys a degree of sentiment polarity, ranging from very negative to very positive.
97	24	The overarching polarity of a text is an aggregation of segment polarities, weighted by their importance.
101	47	Segment Classification Obtaining a separate representation vi for every segment in a document allows us to produce individual segment sentiment predictions pi = 〈p(1)i , .
120	66	We introduce a method that takes our model’s confidence in the prediction into account, by reducing each segment’s class probability distribution pi to a single real-valued polarity score.
125	29	This forces the polarity scores of segments the model does not attend to closer to 0.
144	17	In order to evaluate model performance on the segment level, we constructed a new dataset named SPOT (as a shorthand for Segment POlariTy) by annotating documents from the Yelp’13 and IMDB collections.
179	19	Real-valued polarity scores produced by the two models are mapped to discrete labels using two appropriate thresholds t1 , t2 ∈ [−1, 1], so that a segment s is classified as negative if polarity(s) < t1, positive if polarity(s) > t2 or neutral otherwise.3 To evaluate performance, we use macro-averaged F1 which is unaffected by class imbalance.
183	17	Seg-CNN is not directly comparable to MILNET (or HIERNET) due to differences in supervision type (segment vs. document labels) and training size (1K-2K segment labels vs. ∼250K document labels).
216	20	A reason for MILNET’s inferior performance on the IMDB corpus (EDU-split) can be lowquality EDUs, due to the noisy and informal style of language used in IMDB reviews.
221	24	In our opinion extraction experiments, AMT workers (all native English speakers) were shown an original review and a set of extractive, bullet-style summaries, produced by competing systems using a 30% compression rate.
232	45	EDU summaries were perceived as significantly better in terms of informativeness and polarity, but not coherence.
234	21	In the fourth block we observe that participants find MILNET more informative and better at distilling polarity compared to the LEAD and RANDOM (EDUs) baselines.
241	54	In this work, we presented a neural network model for fine-grained sentiment analysis within the framework of multiple instance learning.
242	79	Our model can be trained on large scale sentiment classification datasets, without the need for segment-level labels.
243	66	As a departure from the commonly used vector-based composition, our model first predicts sentiment at the sentence- or EDU-level and subsequently combines predictions up the document hierarchy.
244	57	An attention-weighted polarity scoring technique provides a natural way to extract sentimentheavy opinions.
245	52	Experimental results demonstrate the superior performance of our model against more conventional neural architectures.
246	79	Human evaluation studies also show that MILNET opinion extracts are preferred by participants and are effective at capturing informativeness and polarity, especially when using EDU segments.
247	75	In the future, we would like to focus on multi-document, aspect-based extraction (Cao et al., 2017) and ways of improving the coherence of our summaries by taking into account more fine-grained discourse information (Daumé III and Marcu, 2002).

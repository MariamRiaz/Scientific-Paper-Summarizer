20	23	Similarly, an e-commerce bot could exploit the rich information available in product descriptions, reviews, fact tables, etc.
21	10	While the proposed dataset is domain specific, it serves as a good benchmark for developing creative background-knowledge-aware models which can then be ported to different domains by building similar datasets for other domains.
22	21	We establish some initial baselines using three different paradigms to demonstrate the various models that can be developed and evaluated using this dataset.
23	99	For the sake of completeness, the first paradigm is a hierarchical variant of the sequence to sequence architecture which does not exploit any background knowledge.
25	25	The third paradigm borrows from the span prediction based models which are predominantly being used for Question Answering (QA).
26	21	These baseline results along with the dataset would hopefully shape future research in the area of background aware conversation models.
48	27	In the following sub-sections we describe the various stages involved in collecting our dataset.
49	41	We created a list of 921 movies containing (i) top 10 popular movies within the past five years, (ii) top 250 movies as per IMDb rankings, (iii) top 10 movies in popular genres, and (iv) other popular movie lists made available elsewhere on the Internet.
52	41	We considered those movies for which enough background information such as plots, reviews, comments, facts, etc.
55	8	For each movie, we collected the following background knowledge: 1. Review (R): For each movie, we asked some in-house workers to fetch the top 2 most popular reviews for this movie from IMDb using the sort by Total Votes option.
64	14	Meta data or Fact Table (F): For each movie, we also collected factual details about the movie, viz., box office collection, similar movies (for recommendations), awards and tag-lines from the corresponding IMDb pages and Wikipedia Infoboxes.
65	32	Such information would be useful for inserting facts in the conversation, for example, “Did you know that the movie won an Oscar?”.
68	37	To avoid this, we collected opening statements using Amazon Mechanical Turk (AMT) where the task for the workers was to answer the following questions “What is your favorite scene from the movie X ?”, “What is your favorite character from the movie X ?” and “What is your opin- ion about the movie X?” (X is the movie name).
75	13	We did try a few pilot experiments where we setup a server to connect two AMT workers but we found that the probability of two workers simultaneously logging in was very low.
77	15	Finally, we took inspiration from the idea of self chats Krause et al. (2017) in which, the same worker plays the role of both Speaker 1 and Speaker 2 to create the chat.
84	37	Further, Speaker 2 was allowed to add words at the beginning or end of the span selected from the resources to make the chats more coherent and natural (for example, see the prefix in utterance 2 of Speaker 2 in Figure 1).
88	34	Since humans typically tend to paraphrase the background knowledge acquired by reading articles, one could argue that such conversations may not look very natural because of this restriction to copy/modify content from the provided resources.
94	20	The evaluators rated the conversations on a scale of 1 (very poor) to 5 (very good).
140	14	The next two methods mixed-short and mixed-long are created by merging the individual resources.
154	27	One common issue with evaluating dialog systems is that existing datasets typically contain only one reference response whereas in practice several responses can be correct in a given context.
156	8	We show the previous utterances ending with Speaker 1’s response and ask workers to provide three appropriate responses from the given resources.
165	25	This confirms our belief that the natural language generation (NLG) capabilities of current generation based models are far from being acceptable even in case of generateor-copy modes.
184	11	One interesting observation was that it easily learns to copy longer contiguous sequences one word at a time.
190	30	This mimics how humans converse by recalling information from their background knowledge and use it appropriately in the context of the conversation.
191	28	Using this dataset, we evaluated models belonging to three different paradigms, viz., generation based models, generate-or-copy models and span prediction models.
192	25	Our results suggest that the NLG capabilities of existing seq-to-seq models are still far from desirable while span based models which completely bypass the process of NLG show some promise but with clear scope for improvement.
193	206	Going forward, we would like to build models which are a hybrid of span prediction models and generation models.
194	48	Specifically, we would like to build models which can learn to copy a large sequence from the input instead of one word at a time.
196	124	For example, the BiDAF model has an expensive outer product between two large matrices which makes it infeasible for long documents (because the size of these matrices grows with the length of the document).
197	129	Alternately, we would like to build two-stage models which first select the correct resource from which the next response is to be generated and then generate or copy the response from the resource.

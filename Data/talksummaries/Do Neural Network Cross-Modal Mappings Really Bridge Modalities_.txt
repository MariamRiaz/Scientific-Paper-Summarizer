0	20	Neural network mappings are widely used to bridge modalities or spaces in cross-modal retrieval (Qiao et al., 2017; Wang et al., 2016; Zhang et al., 2016), zero-shot learning (Lazaridou et al., 2015b, 2014; Socher et al., 2013) in building multimodal representations (Collell et al., 2017) or in word translation (Lazaridou et al., 2015a), to name a few.
4	18	Thus, the success of such systems relies entirely on the ability of the map to make the predicted vectors similar to the target vectors in terms of semantic or neighborhood structure.1 However, whether neural nets achieve this goal in general has not been investigated yet.
5	54	In fact, recent work evidences that considerable information about the input modality propagates into the predicted modality (Collell et al., 2017; Lazaridou et al., 2015b; Frome et al., 2013).
6	19	To shed light on these questions, we first introduce the (to the best of our knowledge) first existing measure to quantify similarity between the neighborhood structures of two sets of vectors.
7	32	Second, we perform extensive experiments in three benchmarks where we learn image-to-text and text-to-image neural net mappings using a rich variety of state-of-the-art text and image features and loss functions.
9	25	In a second experiment, by using six concept similarity tasks we show that the semantic structure of the input vectors is preserved after mapping them with an untrained network, further evidencing that feed-forward nets naturally preserve semantic information about the input.
11	7	Ultimately, this paper aims at: (1) Encouraging the development of better architectures to bridge modalities / spaces; (2) Advocating for the use of semantic-based criteria to evaluate the quality of predicted vectors such as the neighborhood-based measure proposed here, instead of purely geometric measures such as mean squared error (MSE).
35	54	To bridge modalities X and Y , we consider two popular cross-modal mappings f : X → Y .
36	45	(i) Linear mapping (lin): f(x) =W0x+ b0 with W0 ∈ Rdy×dx , b0 ∈ Rdy , where dx and dy are the input and output dimensions respectively.
38	11	Although single hidden layer networks are already universal approximators (Hornik et al., 1989), we explored whether deeper nets with 3 and 5 hidden layers could improve the fit (see Supplement).
40	10	We also tested other losses such as the cosine: 1 − cos(f(x), y) and the max-margin: max{0, γ + ‖f(x) − y‖ − ‖f(x̃) − y‖}, where x̃ belongs to a different class than (x, y), and γ is the margin.
50	50	We define the nearest neighbor overlap NNOK(vi, zi) as the number of K nearest neighbors that two paired vectors vi, zi share in their respective spaces.
53	24	We define: mNNOK(V,Z) = 1 KN N∑ i=1 NNOK(vi, zi) (1) with NNOK(vi, zi) = |NNK(vi) ∩ NNK(zi)|, where NNK(vi) and NNK(zi) are the indexes of the K nearest neighbors of vi and zi, respectively.
66	11	IAPR TC-12 (Grubinger et al., 2006).
67	19	Contains 20K images (18K train / 2K test) annotated with 255 labels.
68	15	Each image is accompanied with a short description of one to three sentences.
74	13	In ImageNet we use 300-dimensional GloVe4 (Pennington et al., 2014) and 300-d word2vec (Mikolov et al., 2013) word embeddings.
75	14	In IAPR TC-12 and Wiki, we employ stateof-the-art bidirectional gated recurrent unit (biGRU) features (Cho et al., 2014) that we learn with a classification task (see Sect.
83	8	Textual and visual features are the same as described in Sect.
84	24	4.1.3 for the ImageNet dataset.
97	10	Results with 3- and 5-layer nets did not show big differences with the results below (see Supplement).
100	18	Although Lazaridou et al. (2015a) and Weston et al. (2011) find that max-margin performs the best in their tasks, we do not find our result entirely surprising given that max-margin focuses on inter-class differences while we look also at intraclass neighbors (in fact, we do not require classes).
102	28	If we would only look at train performance (and allow train MSE to reach 0) then f(X) = Y and clearly train mNNO(f(X), Y ) = 1 while mNNO(f(X), X) can only be smaller than 1.
103	35	However, the interest is always on test samples, and (near-)perfect test prediction is unrealistic.
105	48	In all the combinations from Tab.
106	42	1, the test mNNO(f(X), Y ) never surpasses test mNNO(f(X), X) for any number of epochs, even with an oracle (not shown).
108	126	Experiment 1 concerns learning, while, by “ablating” the learning part and randomizing weights, Experiment 2 is revealing about the natural tendency of neural nets to preserve semantic information about the input, regardless of the choice of the target vectors and loss function.
110	47	Such finding has been possible thanks to the proposed measure that explicitly quantifies similarity between the neighborhood structure of two sets of vectors.
111	77	While other measures such as mean squared error can be misleading, our measure provides a more realistic estimate of the semantic similarity between predicted and target vectors.
112	41	In fact, it is the semantic structure (or pairwise similarities) what ultimately matters in cross-modal applications.

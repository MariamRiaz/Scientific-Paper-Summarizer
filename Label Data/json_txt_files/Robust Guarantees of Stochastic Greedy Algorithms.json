{"sections": [{"heading": "1. Introduction", "text": "In this paper we study the guarantees of stochastic optimization algorithms for submodular maximization. A function f : 2N \u2192 R is submodular if it exhibits a diminishing returns property. That is, for any S \u2286 T \u2286 N and any a /\u2208 T , the function respects:\nfS(a) \u2265 fT (a)\nwhere fH(x) denotes the marginal contribution of an element x \u2208 N to a set H \u2286 N , i.e. fH(x) = f(H \u222a x) \u2212\n*Equal contribution 1Bar Ilan University and Google 2Harvard University. Correspondence to: Avinatan Hassidim <avinatan@cs.biu.ac.il>, Yaron Singer <yaron@seas.harvard.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nf(H). Many fundamental measures such as entropy, diversity, and clustering can be modeled as submodular functions, and as a result submodular optimization is heavily studied in machine learning for well over a decade now.\nIt is well known that for the problem of maximizing a monotone (S \u2286 T =\u21d2 f(S) \u2264 f(T )) submodular function under a cardinality constraint, the celebrated greedy algorithm which iteratively adds the element whose marginal contribution is maximal, obtains an approximation guarantee of 1\u22121/e (Nemhauser et al., 1978). This is optimal unless P=NP (Feige) or alternatively, assuming polynomiallymany function evaluations (Nemhauser & Wolsey, 1978).\nIn recent years, there have been various adaptations of the classic greedy algorithm to allow for scalable, distributed, and noise-resilient optimization. Most notably, the STOCHASTIC-GREEDY algorithm recently proposed by (Mirzasoleiman et al., 2015) is a linear-time algorithm which at every step takes an element, which approximates in expectation the element with the maximal marginal contribution. Mirzasoleiman et al. show that STOCHASTICGREEDY gives an approximation guarantee which is arbitrarily close to 1 \u2212 1/e in expectation, and does very well in practice (Mirzasoleiman et al., 2015; Lucic et al., 2016). Variants of this algorithm are used in clustering (Malioutov et al., 2016), sparsification (Lindgren et al., 2016), Gaussian RBF kernels (Sharma et al., 2015), sensing (Li et al., 2016), and social data analysis (Zhuang et al., 2016).\nMore generally, a greedy algorithm that iteratively adds elements that are only approximately maximal in expectation, may not necessarily be due to a design decision, but rather an artifact of its application on large and noisy data sets (see e.g. (Azaria et al., 2013)). One can model this uncertainty with a probability distribution D: at every iteration, a value \u03be \u223c D is being sampled, and the greedy algorithm adds an element whose marginal contribution is a \u03be-approximation to the maximal marginal contribution.\nIn general, we refer to an algorithm that iteratively adds an element whose marginal contribution is approximately optimal in expectation as a stochastic greedy algorithm. It is easy to show that stochastic greedy algorithms give an approximation ratio of 1 \u2212 1/e\u00b5 in expectation, where \u00b5 is the mean of the distribution modeling the uncertainty. This however is a weak guarantee as it leaves a non-negligible\nlikelihood that the algorithm terminates with a solution with a poor approximation guarantee. Indeed, as we later show, there are cases where stochastic greedy algorithms have desirable guarantees in expectation, but with constant probability have arbitrarily bad approximation guarantees."}, {"heading": "Do stochastic optimization algorithms for submodular maximization have robust approximation guarantees?", "text": ""}, {"heading": "1.1. Our results", "text": "We prove the following results:\n\u2022 Optimization under cardinality constraints. For the problem of maximizing a monotone submodular function under cardinality constraint k, with uncertainty distributionD with expectation \u00b5, we show that for any \u03b5 \u2208 [0, 1], when k \u2265 1\u00b5\u03b52 a stochastic greedy algorithm obtains an approximation of 1 \u2212 1/e(1\u2212\u03b5)\u00b5 w.p. at least 1\u2212e\u2212\u00b5k\u03b52/2. Furthermore, we prove that this bound is optimal by showing that for any \u03b4 > 0 no algorithm can obtain an approximation ratio better than 1\u2212 1/e(1\u2212\u03b5)\u00b5 w.p. 1\u2212 \u03b4. For the special case in which the function is modular, we prove an improved bound of (1\u2212 \u03b5)\u00b5 w.p. at least 1\u2212 e\u2212\u00b5k\u03b52/2;\n\u2022 Optimization under matroid constraints. To further study the difference between guarantees that occur in expectation and guarantees which appear w.h.p, we study a generalization, where the greedy algorithm is used to maximize a monotone submodular function under intersection of matroid constraints, where a distribution D with mean \u00b5 generates uncertainty. We show that in this case, with P matroids the algorithm obtains an approximation ratio of \u00b5/(P +1) in expectation. However, we show that even for a single matroid no algorithm can give a finite approximate guarantee w.p. at least 1\u2212\u00b5\u2212o(1), implying that in general stochastic greedy algorithms cannot obtain high probability guarantees under general matroid constraints;\n\u2022 Stochastic local search. Finally, a natural alternative to greedy is local search. We show that even for cardinality constraints local search performs poorly, and does not give any meaningful approximation guarantees when there is probabilistic uncertainty about the quality of the elements. We contrast this with the case where there is deterministic uncertainty about the quality of the elements, in which we get an approximation ratio of (1 + 1/\u00b5)\u22121, where \u00b5 is our uncertainty. This implies that local search does not enjoy the same robustness guarantees of the greedy algorithms under uncertainty of the quality of elements."}, {"heading": "1.2. Applications", "text": "The above results have several immediate consequences:\n\u2022 Fast algorithms for submodular optimization. Our analysis applies to the STOCHASTIC-GREEDY algorithm (Mirzasoleiman et al., 2015), thus showing its approximation guarantee holds with high probability, implying it is the optimal algorithm in terms of running time and approximation guarantee for the problem of maximizing a submodular function under a cardinality constraint; 1 The same guarantee holds for the variants studied in (Malioutov et al., 2016; Lindgren et al., 2016; Sharma et al., 2015; Li et al., 2016);\n\u2022 Submodular optimization under noise. In (Hassidim & Singer, 2017) the problem of maximization of submodular functions under a cardinality constraint is considered when given access to a noisy oracle. Our result simplifies the analysis of one of the algorithms in this setting, and gives high probability results for the inconsistent noise model (Singla et al., 2016)."}, {"heading": "1.3. Organization of the paper", "text": "We describe the results for general monotone submodular functions in Section 2, and the improved analysis for modular functions in Section 3. In Section 4 we consider the more general problem of maximizing a submodular function under matroid constraints, and show the inapproximabilities of stochastic local search algorithms in Section 5. Finally, we discuss experiments in Section 6."}, {"heading": "2. Submodular Functions", "text": "In this section we analyze the stochastic greedy algorithm for general monotone submodular functions. We first analyze the algorithm, and then show the bound is tight."}, {"heading": "2.1. Upper bound", "text": "For a given cardinality constraint k, the standard greedy algorithm begins with the empty set as its solution and at each step {1, . . . , k} adds the element whose marginal contribution to the existing solution is largest. In the stochastic version, the algorithm may no longer add the element whose marginal contribution is largest. Rather, the algorithm adds the element whose marginal contribution is at least a factor of \u03be from the maximal marginal contribution, where \u03be is drawn i.i.d from some distribution D with mean \u00b5. We give a formal description below.\n1Formally, the algorithm in (Mirzasoleiman et al., 2015) does not assume that the expected marginal contribution of the element selected is approximately optimal, but rather that in expectation its marginal contribution approximates that of some element in the optimal solution. Nevertheless our analysis still applies.\nAlgorithm 1 STOCHASTIC-GREEDY input k\n1: S \u2190 \u2205 2: while |S| < k do 3: \u03be \u223c D 4: S \u2190 S \u222a arbitrary a s.t. fS(a) \u2265 \u03bemaxx\u2208N fS(x) 5: end while\noutput S\nThe following lemma shows that when the sampled mean of the distribution is close to 1, stochastic greedy algorithms obtain a near optimal performance guarantee.\nLemma 1. Let S be the set of k elements selected by a stochastic greedy algorithm s.t. in each iteration i \u2208 [k] the algorithm selects an element whose marginal contribution is an \u03bei approximation to the marginal contribution of the element with the largest marginal contribution at that stage, and let \u00b5\u0302 = 1k \u2211k i=1 \u03bei. Then:\nf(S) \u2265 ( 1\u2212 1\ne\u00b5\u0302\n) OPT.\nProof. Let Si = {a1, . . . , ai}, and let the optimal solution be O, i.e. O \u2208 argmaxT :|T |\u2264k f(T ). Note that for any i < k we have that:\nf(Si+1)\u2212 f(Si) = fSi(ai+1) \u2265 \u03bei+1 max\no\u2208O fSi(o)\n\u2265 \u03bei+1 k fSi(O) = \u03bei+1 k (f(O \u222a Si)\u2212 f(Si)) \u2265 \u03bei+1 k (f(O)\u2212 f(Si))\nRearranging, we get:\nf(Si+1) \u2265 \u03bei+1 k\n( f(O)\u2212 f(Si) ) + f(Si) (1)\nWe will show by induction that in every iteration i \u2208 [k]:\nf(Si) \u2265 1\u2212 i\u220f j=1 ( 1\u2212 \u03bej k ) f(O) The base case is when i = 1, and S0 = \u2205 and by (1):\nf(S1) \u2265 \u03bei+1 k\n( f(O)\u2212 f(S0) ) = 1\u2212 ( 1\u2212 \u03be1\nk\n) f(O)\nFor a general iteration i+1, applying (1) for iteration i+1\nand using the inductive hypothesis:\nf(Si+1)\n\u2265 \u03bei+1 k f(O) +\n( 1\u2212 \u03bei+1\nk\n) f(Si)\n\u2265 \u03bei+1 k f(O) +\n( 1\u2212 \u03bei+1\nk )1\u2212 i\u220f j=1 ( 1\u2212 \u03bej k ) f(O) =\n1\u2212 i+1\u220f j=1 ( 1\u2212 \u03bej k ) f(O) Since 1\u2212 x \u2264 e\u2212x, the above inequality implies:\nf(S) = f(Sk)\n= 1\u2212 k\u220f j=1 ( 1\u2212 \u03bej k ) f(O) \u2265 ( 1\u2212 e\u2212 1k \u2211k i=1 \u03bei ) f(O)\n= ( 1\u2212 e\u2212\u00b5\u0302 ) f(O).\nWe can now apply concentration bounds on the previous lemma and prove the main theorem.\nTheorem 2. Let f be a monotone submodular function, which is evaluated with uncertainty coming from a distribution D with mean \u00b5. For any \u03b5 \u2208 (0, 1), suppose a stochastic greedy algorithm is being used with k \u2265 2\u03b52\u00b5 . Then, w.p. 1\u2212 e\u2212 \u03b5\u00b5\u00b7k 2 the algorithm returns S s.t.:\nf(S) \u2265 ( 1\u2212 1\ne(1\u2212\u03b5)\u00b5\n) OPT\nProof. Consider an application of the stochastic greedy algorithm with mean \u00b5, and let \u03be1, . . . , \u03bek be the approximations to the marginal contributions made by i.i.d samples from a distribution in all iterations 1, . . . , k. Since all the values {\u03bei}ki=1 drawn from the distribution are bounded from above by 1, by the Chernoff bound we have:\nPr\n[ 1\nk k\u2211 i=1 \u03bei < (1\u2212 \u03b5)\u00b5\n] < e \u03b5\u00b5\u00b7k 2\nBy applying Lemma 1 we get our result."}, {"heading": "2.2. Tight lower bound", "text": "Claim 3. For any \u03b4 \u2208 [0, 1) the competitive ratio of stochastic greedy with mean \u00b5 is at most (1\u22121/e\u00b5)+o(1) with probability at least 1\u2212 \u03b4.\nProof. Consider maximizing a submodular function when the oracle has probability \u00b5 of returning the element with\nthe largest marginal contribution, and probability 1 \u2212 \u00b5 to return a random element. We present an instance where greedy returns an approximation ratio of at most 1\u22121/e\u00b5+ o(1) with probability at least 1\u22121/k. We use the same bad instance regardless of \u00b5.\nThe construction is as follows. There are k special elements, m = 4k3 plain elements and n = 4(m + k)k2 dummy elements (note that the total number of elements is not n). The value f(S) depends only on the number of special elements, plain elements and dummy elements contained in S (all special elements are identical). Moreover, dummy elements contribute nothing to f , and hence, we can write f(S) = f(i, j), where i is the number of special elements in S, and j is the number of plain elements.\nFor i \u2265 1, the value of f depends on j as follows:\nf(i, j) =  kk-(k-1)jkk-j-1(k-i) 0 \u2264 j \u2264 k-1 kk-(k-1)k-2((k-i)(2k-2-j)) k \u2264 j \u2264 2k-3 kk-(k-1)k-2(3k-i-j-3) 2k-2 \u2264 j \u2264 3k-3-i kk 3k \u2212 i \u2212 2 \u2264 j\nNote that for i = 0, we have f(0, j) = f(1, j \u2212 1), and f(0, 0) = 0. Also, one can verify, by case-by-case analysis that this function is indeed monotone and submodular.\nSince f(0, j) = f(1, j \u2212 1) for every j \u2265 1, as long as the greedy algorithm did not choose any special element yet, the marginal contribution of a special elements is equal to the marginal contribution of a plain element.\nLet t be the number of times in which the oracle supplied the greedy algorithm with the element with the maximal marginal contribution. By an additive version of the Chernoff bound we have that with probability at least 1\u2212 24 log k = 1\u2212 k4:\nt < k\u00b5+ 2 \u221a k log k\nWe condition on this event. Next, we argue that with probability at least 1 \u2212 1/3k all the elements for which the algorithm selected a random element (i.e. did not take an element whose marginal contribution is a \u00b5 approximation to the largest marginal contribution) are dummy elements. Consider one of the times in which greedy was given a random element. The probability that it was not a dummy element is at most m+k4(m+k)k2\u2212k . Applying a union bound, the probability that in the k \u2212 t cases in which greedy was supplied with a random element it was always a dummy element is at least 1\u2212 1/3k. We condition on this event.\nWe will now argue that with probability at least 1\u22121/3k all the non-dummy elements selected are plain. Consider the first non dummy element chosen by the algorithm. With probability at least 1 \u2212 k/4k3 it is a plain element. We\ncondition on this event. Assuming by induction that the last i \u2212 1 non dummy elements which were chosen by greedy were plain, the probability that i\u2019th non dummy element is plain is 1 \u2212 k4k3\u22121 . Taking a union bound over all t such elements, gives that with probability 1 \u2212 1/3k all t nondummy elements chosen by greedy were plain.\nCombining this together with a union bound, we get that with probability at least 1 \u2212 1/k greedy chose no special elements, at most t = \u00b5k + 4 \u221a k log k plain elements, and the rest are dummy elements that do not contribute to the value of the function. This means that the value of the solution is at most kk\u2212 (k\u22121)tkk\u2212t, and thus with probability at least 1 \u2212 1/k the ratio between the value of greedy and the optimal value is at least:\nkk \u2212 (k \u2212 1)tkk\u2212t\nkk = 1\u2212 ( k \u2212 1 k )t\n\u2265 1\u2212 (( 1\u2212 1\nk )k)\u00b5+ 4 log k\u221ak \u2265 1\u2212 e\u2212(\u00b5+4 log k/ \u221a k)\n= 1\u2212 e\u2212\u00b5 + o(1)\nChoosing k = 1/\u03b4 we get our desired bound."}, {"heading": "3. Modular Functions", "text": "In this section we show a tight upper bound for the special case in which the function is modular. Recall that a function f : 2N \u2192 R is modular if for every set S \u2286 N we have that f(S) = \u2211 a\u2208S f(a). Note that in this case fS(a) = f(a) for all S \u2286 N and a \u2208 N . Theorem 4. Let S \u2286 N be the set returned when applying a stochastic greedy algorithm with mean \u00b5 \u2208 [0, 1] on a modular function f : 2N \u2192 R. Then, for any \u03b5 \u2208 [0, 1], when k \u2265 2\u03b52\u00b5 w.p. 1\u2212 e \u2212\u00b5k\u03b52/2:\nf(S) \u2265 (1\u2212 \u03b5)\u00b5OPT.\nProof. Suppose that at every stage i \u2208 [k] element ai \u2208 N is selected and its marginal contribution is at least \u03bei of the optimal marginal contribution at that stage. Let O be the optimal solution and o? \u2208 argmaxo\u2208O\\S f(o), where S is the solution retuned by the algorithm, i.e. S = {a1, . . . , ak}. The basic idea in this proof is to observe that since o? is not in the solution and throughout the iterations of the algorithm is always a feasible candidate, this implies that every element ai in the solution S\\O has value at least as large as \u03beif(o?). Intuitively, if there are enough elements in S \\ O for concentration bounds to kick in, we have that 1|S\\O| \u2211 j\u2208S\\O \u03bej = (1 \u2212 \u03b5)\u00b5 and we would be done since f(S) = f(S \\O)+f(O\u2229S) \u2265 (1\u2212 \u03b5)\u00b5f(O).\nThe problem is that S \\O may not be sufficiently large, and we therefore need slightly more nuanced arguments.\nWe will partition O\u2229S to two disjoint sets of low and high valued elements: L = {o \u2208 O \u2229 S : f(o) < f(o?)} and H = {o \u2208 O \u2229 S : f(o) \u2265 f(o?)}. Notice that:\nf(O)\n= f(O \\ S) + f(L) + f(H) = \u2211 o\u2208O\\S f(o) + \u2211 o\u2208L f(o) + \u2211 o\u2208H f(o)\n\u2264 \u2211 o\u2208O\\S f(o?) + \u2211 o\u2208L f(o?) + \u2211 o\u2208H f(o?) + ( f(o)-f(o?) ) = k \u00b7 f(o?) +\n\u2211 o\u2208H (f(o)-f(o?))\nSince o? \u2208 O \\S, it is a feasible choice for the algorithm at every stage, and therefore by the definition of the stochastic greedy algorithm, for every element ai \u2208 S we have that:\nf(ai) \u2265 \u03beimax a\u2208N fS(a) = \u03bei max a\u2208N\\S f(a) \u2265 \u03beif(o?)\nThus, for k \u2265 2/\u03b52 with probability 1\u2212 e\u2212 k\u00b5\u03b52 2 :\nf(S)\n= f(S \\O) + f(H) + f(L) = \u2211\nai\u2208S\\O f(ai) + \u2211 ai\u2208L f(ai) + \u2211 o\u2208H f(o)\n\u2265 \u2211\nai\u2208S\\O\n\u03beif(o ?) + \u2211 ai\u2208L \u03beif(o ?) + \u2211 o\u2208H f(o)\n= f(o?)  \u2211 ai\u2208(S\\O)\u222aL \u03bei +\u2211 o\u2208H f(o)\n= f(o?)  \u2211 ai\u2208(S\\O)\u222aL \u03bei +\u2211 o\u2208H ( f(o?) + f(o)-f(o?) )\n\u2265 f(o?)  \u2211 ai\u2208(S\\O)\u222aL\u222aH \u03bei +\u2211 o\u2208H ( f(o)-f(o?) ) (2)\n\u2265 (1\u2212 \u03b5)\u00b5 \u00b7 kf(o?) + \u2211 o\u2208H ( f(o)-f(o?) ) (3)\n\u2265 (1\u2212 \u03b5)\u00b5 ( kf(o?) +\n\u2211 o\u2208H ( f(o)-f(o?) )) \u2265 (1\u2212 \u03b5)\u00b5f(O)\nwhere inequality (2) is due to the fact that f(o?) \u2265 \u03beif(o?) since \u03bei \u2264 1; inequality (3) is an application of the Chernoff bound for k \u2265 2/\u03b52\u00b5; the last inequality is due to the upper bound we established on f(O).\nThe upper bound is tight. An obvious lower bound holds for the degenerate case where in every stage the marginal contribution of the element returned is a \u00b5 \u2208 [0, 1] approximation to the maximal marginal contribution with probability 1. Clearly in this case, the approximation ratio is no better than \u00b5 (consider n = 2k elements where k elements have value 1 and k elements have value \u00b5)."}, {"heading": "4. General Matroid Constraints", "text": "In this section we consider the more general problem of maximizing a monotone submodular function under matroid constraints. Recall that a matroid is a pair (N, I) where N is the ground set and I is a family of subsets of N called independent that respects two axioms: (1) A \u2208 I, A\u2032 \u2282 A =\u21d2 A\u2032 \u2208 I and (2) if A,B \u2208 I and |B| < |A| then \u2203x \u2208 A \\ B, s.t. B \u222a {x} \u2208 I. The rank of the matroid is the size of the largest set in I. The cardinality constraint, is a special case of optimization under matroid constraints, where the matroid is uniform.\nSubmodular maximization under matroid constraints. The greedy algorithm for maximization under matroid constraints is a simple generalization of the uniform case: the algorithm iteratively identifies the element whose marginal contribution is maximal and adds it to the solution if it does not not violate the matroid constraint (i.e. if adding the element to the set keeps the set in the family of feasible sets I). This algorithm obtains an approximation ratio of 1/2. 2 More generally, for an intersection of P matroids, this algorithm obtains an approximation guarantee of 1/(1 + P ).\nStochastic greedy under intersection of matroids. Consider an intersection of matroids, a monotone submodular function f defined over the independent sets, and an uncertainty distribution D with mean \u00b5. The stochastic greedy algorithm begins with the solution S = \u2205 and set of elements not yet considered X = N . In every iteration the algorithm maintains a solution S of elements that are in the intersection of the P matroids and a value \u03be \u223c D is sampled. The algorithm then considers an arbitrary element a \u2208 X whose marginal contribution is \u03bemaxx\u2208X fS(x), and adds a to S if S \u222a a is independent in all P matroids, and discards a from X ."}, {"heading": "4.1. Stochastic greedy fails with high probability", "text": "We first show that unlike the special case of uniform matroids, even for a single matroid, it is generally impossible to obtain high probability guarantees for maximization un-\n2We note that unlike the uniform case, here greedy is not optimal. The optimal guarantee of 1 \u2212 1/e can be obtained via an algorithm based on a continuous relaxation (Vondr\u00e1k, 2008) or through local search (Filmus & Ward, 2012).\nder matroid constraints, even when the function is modular and the rank of the matroid is sufficiently large. Claim 5. Even for a modular function and arbitrarily large k, a stochastic greedy algorithm with mean \u00b5 cannot obtain an approximation better than 0 with probability greater than \u00b5+ o(1), for maximization under matroid of rank k.\nProof. Consider the following example, where the ground set has two types of elements A = {a1, . . . , am}, and B = {b1, . . . , bk\u22121} where m = k2. The rank of the matroid is k, and a set is independent as long as it contains just a single ai \u2208 A. Define a modular function: f(a1) = 1, but f(aj) = 0 for j 6= 1, and also f(bj) = 0 for any j \u2208 [k\u22121]. The distribution returns 1 w.p. p < 1/2 and 0 otherwise.\nIn the first iteration of the algorithm, the element a1 is correctly evaluated with probability p, and with probability 1 \u2212 p it is evaluated as having value 0, in which case we may assume that a random element is selected instead. Therefore, w.p. p the algorithm takes a1, and obtains the optimal solution. However, if this is not the case, then w.p. m\u22121/(m+k) = (k2\u22121)/(k2+k) the algorithm chooses an element from A whose value is 0. In this case, even if a1 is later correctly evaluated it could not be considered into the solution since its inclusion violates independence. Hence, while the expected value of greedy is slightly larger than p, with probability at least (1\u2212 p)\u2212 o(1) the value of the solution would be 0."}, {"heading": "4.2. The guarantee holds in expectation", "text": "Although the approximation guarantee cannot hold with high probability, we now show that in expectation stochastic greedy algorithms achieves the approximation guarantee of non-stochastic greedy when maximizing a monotone submodular functions under an intersection of P matroids. Theorem 6. Let F denote the intersection of P \u2265 1 matroids on the ground setN , and f : 2N \u2192 R be a monotone submodular function. The stochastic greedy algorithm returns a solution S \u2208 F s.t.:\nE[f(S)] \u2265 \u00b5 (P + 1) OPT\n.\nAn equivalent algorithm. To simplify the analysis, it will be useful to consider the equivalent algorithm, which at every iteration when the existing solution is S, discards all elements x for which S \u222a x /\u2208 F . The following claim due to Nemhauser et al. is later employed in our analysis: Claim 7 (Prop. 2.2 in (Nemhauser et al., 1978)). If for \u2200t \u2208 [k] \u2211t\u22121 i=0 \u03c3i \u2264 t and pi\u22121 \u2265 pi, with \u03c3i, pi \u2265 0 then:\nk\u22121\u2211 i=0 pi\u03c3i \u2264 k\u22121\u2211 i=0 pi.\nAlgorithm 2 STOCHASTIC-MATROID-GREEDY 1: S \u2190 \u2205, X \u2190 N 2: while X 6= S do 3: X \u2190 X \\ {x : S \u222a {x} /\u2208 F} 4: \u03be \u223c D. 5: S \u2190 S \u222a arbitrary a s.t. fS(a) \u2265 \u03bemaxx\u2208X fS(x) 6: end while\nProof of Lemma 6. Consider the value obtained by the following procedure. An adversary chooses some maximal independent set a1, . . . ak. Let Si = {a1, a2, . . . , ai} with S0 = \u2205, and for every i \u2208 [k] let a?i be the element that maximizes the marginal contribution given Si, where the maximization is over elements a such that Si \u222a {a} is independent in all P matroids. That is a?i is defined as:\nmax Si\u222a{a}\u2208F fSi(a)\nThe value of the procedure is then:\nk\u22121\u2211 i=0 fSi(a ? i )\nWe will bound the value obtained by the procedure against that of the optimal solution, and then argue that the value obtained by the stochastic greedy is equivalent.\nLet O denote the optimal solution. We have that:\nf(O) \u2264 f(O \u222a Sk) \u2264 f(Sk) + \u2211\nx\u2208O\\Sk\nfSk(x) (4)\nFor a set S and a matroid Mp in the family F , we define rp(S), called the rank of S in Mp to be the cardinality of the largest subset of S which is independent in Mp, and define spp(S), called the span of S in Mp by:\nspp(S) = {a \u2208 N : rp(S \u222a a) = rp(S)}\nIf S is independent in Mp, we have that rp(spp(S)) = rp(S) = |S|. In particular, we have that rp(spp(Si)) = i for every Si. Now in each 1 \u2264 p \u2264 P , since O is an independent set in Mp we have:\nrp(spp(Si) \u2229 (O)) = |spp(Si) \u2229 (O)|\nwhich implies that |spp(Si) \u2229 (O)| \u2264 i.\nDefine Ui = \u222aPp=1spp(Si), to be the set of elements which are not part of the maximization in step i+ 1 of the procedure, and hence cannot give value at that stage. We have: |Ui\u2229O| = |(\u222aPp=1spp(Si))\u2229O| \u2264 P\u2211 p=1 |spp(Si)\u2229O| \u2264 iP\nLet Vi = (Ui \\ Ui\u22121) \u2229 O be the elements of O which are not part of the maximization in step i, but were part of the maximization in step i\u2212 1. If x \u2208 Vi then it must be that:\nfSk(x) \u2264 fSi(x) \u2264 fSi(a?i )\nsince x was not chosen in step i. Hence, we can upper bound:\n\u2211 x\u2208O\\Sk fSk(x) \u2264 k\u2211 i=1 \u2211 x\u2208Vi fSi(a ? i )\n=\nk\u2211 i=1 |Vi|fSi(a?) \u2264 P k\u2211 i=1 fSi(a ?)\nwhere the last inequality uses \u2211i t=1 |Vt| = |Ui \u2229 O| \u2264 Pi and the arithmetic claim proven in Claim 7 due to (Nemhauser et al., 1978). Together with (4), we get:\nf(O) \u2264 (P + 1) k\u2211 i=1 fSi(a ? i )\nFinally, note that STOCHASTIC-MATROID-GREEDY obtains a \u00b5 = E\u03be\u223cD[\u03be] approximation of the value of the procedure, in expectation. In each stage, one can add the element chosen by the algorithm to the procedure. Hence, at each stage STOCHASTIC-MATROID-GREEDY and the procedure have the same set of elements available, and the same a?i which maximizes the marginal contribution."}, {"heading": "5. Inapproximability of Local Search", "text": "In this section we consider variants of stochastic local search algorithms. We show that unlike the greedy algorithm, stochastic local search algorithms can end up with arbitrarily bad approximation guarantees.\nLocal search for submodular maximization. For N = {a1, . . . , an}, given a set of elements T \u2286 N we will use T\u2212i to denote the set without element ai, i.e. T\u2212i = T \\ {ai}. A solution S is a local maximum if no single element ai in S can be exchanged for another element aj not in S whose marginal contribution to S\u2212i is greater. That is, S is a local maximum if for every ai \u2208 S we have that:\nfS\u2212i(ai) \u2265 max x/\u2208S fS\u2212i(x).\nIt is not hard to show that for any monotone submodular function, if S is a local maximum it is a 1/2 approximation to the optimal solution. A local search algorithm begins with an arbitrarily set of size k, and at every stage exchanges one of its elements with the element whose marginal contribution is maximal to the set, until it reaches a local maximum. To guarantee that local\nsearch algorithms converge in polynomial time, the convention is to seek approximate local maxima. A solution S is an \u03b1-approximate local maximum if no element ai in S can be exchanged for another element aj not in S whose marginal contribution to S\u2212i is greater by a factor of \u03b1. It is easy to show that an \u03b1-approximate local maximum is a (1 + 1/\u03b1)\u22121 approximation (Filmus & Ward, 2012).\nStochastic local search. A natural question is whether local search enjoys the same robustness guarantees as the greedy algorithm. We say that a solution S is a stochastic local maximum up to approximation \u00b5 if no single element in S can be exchanged for another element not in S whose expected marginal contribution is greater by a factor \u00b5. That is, S is a stochastic local maximum with mean \u00b5 if for every ai \u2208 S we have that:\nE[fS\u2212i(ai)] \u2265 \u00b5 \u00b7max x/\u2208S fS\u2212i(x)\nIf we have uncertaintiy modeled by a distribution D \u2286 [0, 1], a solution is a stochastic local maximum w.r.t D if for every element ai in S we draw \u03bei \u223c D s.t.\nfS\u2212i(ai) \u2265 \u03bei \u00b7max b/\u2208S fS\u2212i(b)\nA stochastic local search algorithm will therefore begin from an arbitrary solution S of size k, and at every iteration swap an element from the solution with an element outside the solution if S is not a stochastic local maximum w.r.t. D. More specifically, the stochastic local search algorithm selects an element ai from S and replaces it with another element aj whose expected marginal contribution to S\u2212i is at least fS\u2212i(ai)/\u03bei, and repeats this process until no such elements are found. This is a similar abstraction of stochastic greedy algorithms, applicable in settings when one cannot evaluate the optimal marginal contribution exactly, but approximately well in expectation.\nConsistent and inconsistent stochasticity. We consider two approaches to model the way in which the random variables \u03bei are assigned to an element ai in the solution:\n1. Consistent: For each element ai \u2208 N , \u03bei is a random variable drawn independently from D \u2286 [0, 1], and fixed for the entire run of the algorithm;\n2. Inconsistent: At each step of the algorithm, for every element ai \u2208 S, \u03bei is a random variable drawn independently from D.\nNote that the solution converges, as the distribution D makes the algorithm more conservative.\nInapproximability of stochastic local search. We show that in both consistent and inconsistent models, stochastic local search performs poorly, even for modular functions. Consider a setting where there are n elements, and a modular function. For every i > 1, we have f(ai) = \u03b5/i for some negligible \u03b5 > 0 (e.g. \u03b5 = 2\u2212n), but f(a1) = 1. As for D, w.p. 0.99 it returns 1, and 0 o.w. Assume k = 1. Lemma 8. The expected approximation guarantee of stochastic local search is at most 2\u2212O(n) + \u03b5.\nProof. At the first iteration, local search chooses an. If \u03be = 0, we are done, and this is a local maxima. Otherwise, local search chooses an\u22121. At iteration i local search starts with ai, halts w.p. 0.01 (the probability that D outputs 0), and otherwise continues. The probability that it will not halt for n steps and reach ai is 0.99n = 2\u2212O(n).\nWe note that in the above proof we assumed that the local search algorithm chooses an arbitrary element at every iteration. If one allows the stochastic local search to randomly choose an element in every iteration a similar construction shows an inapproximability of O( lognn ) + \u03b5."}, {"heading": "6. Experiments", "text": "We applied the algorithms to an ego-network from (Leskovec & Krevl, 2014). This network has 333 nodes and 5038 edges. The submodular function we used is coverage, which models influence in social networks. In order to emphasize the implications of having results w.h.p, the graphs do not depict the average of many runs, but instead each graph is a single run of the algorithm. In greedy, we present the value of the solution at each iteration k. In local search and in random we sort elements of the solution according to marginal contributions.\nWe start with greedy and describe the different distributions we used to model uncertainty. The same distributions were used for local search. Both left panes include the greedy algorithm without uncertainty (greedy, blue line), and choosing a random set (random, black line). When running stochastic greedy, we first sample a value \u03be \u2208 D,\nand then pick a random element out of the elements that have marginal contribution at least \u03bemaxa fS(a). The distribution D varies between the different lines. In the leftmost pane, APX (red line) depicts a D which is the constant distribution 0.5. In Stochastic greedy with mean 0.75, D is the uniform distribution on [0.5, 1] (purple line), and in Stochastic greedy with mean 0.5, D is the uniform distribution on [0, 1]. It is expected that APX will behave smoothly, as D is a degenerate distribution in this case (note that there is still randomization in which element to choose at every stage out of the eligible elements). However, we see that the h.p. result kicks in, and the APX line is similar (across many values of k) to stochastic greedy with mean 0.5. Raising the mean to 0.75 makes stochastic greedy behave almost like greedy when k gets large, so in some cases stochastic greedy makes the same choice greedy would make.\nIn the second pane, The purple line (exponential) depicts D as an exponential distribution with \u03bb = 4, which gives a mean of 0.25. The red line is uniform in [0, 5], and the yellow is a Gaussian with \u00b5 = 0.25 and \u03c3 = 0.1. We see that all graphs are further away from Greedy compared to the leftmost pane, and that higher variance is generally not a good thing, although the differences are small.\nThe two right panes depict the same noise distributions as the two left panes, but this time we use local search (or stochastic local search) instead of greedy. It is easy to see that D affects local search more than it affects greedy. The plateau is caused since we sort the final solution and then plot the elements, and since if some elements have a low value of \u03bei they are likely to stay in the solution even if they contribute very little, as in Lemma 8."}, {"heading": "7. Acknowledgements", "text": "A.H. was supported by ISF 1394/16; Y.S. was supported by NSF grant CCF-1301976, CAREER CCF-1452961, a Google Faculty Research Award, and a Facebook Faculty Gift. We thank Andreas Krause for pointing the connection between our result and (Mirzasoleiman et al., 2015)."}], "year": 2017, "references": [{"title": "Movie recommender system for profit maximization", "authors": ["Azaria", "Amos", "Hassidim", "Avinatan", "Kraus", "Sarit", "Eshkol", "Adi", "Weintraub", "Ofer", "Netanely", "Irit"], "venue": "In Proceedings of the 7th ACM conference on Recommender systems,", "year": 2013}, {"title": "A tight combinatorial algorithm for submodular maximization subject to a matroid constraint", "authors": ["Filmus", "Yuval", "Ward", "Justin"], "venue": "In FOCS,", "year": 2012}, {"title": "Submodular optimization under noise", "authors": ["Hassidim", "Avinatan", "Singer", "Yaron"], "venue": "In COLT,", "year": 2017}, {"title": "SNAP Datasets: Stanford large network dataset collection", "authors": ["Leskovec", "Jure", "Krevl", "Andrej"], "venue": "http://snap. stanford.edu/data,", "year": 2014}, {"title": "Gaussian quadrature for matrix inverse forms with applications", "authors": ["Li", "Chengtao", "Sra", "Suvrit", "Jegelka", "Stefanie"], "venue": "In ICML,", "year": 2016}, {"title": "Leveraging sparsity for efficient submodular data summarization", "authors": ["Lindgren", "Erik", "Wu", "Shanshan", "Dimakis", "Alexandros G"], "venue": "In NIPS,", "year": 2016}, {"title": "Horizontally scalable submodular maximization", "authors": ["Lucic", "Mario", "Bachem", "Olivier", "Zadimoghaddam", "Morteza", "Krause", "Andreas"], "venue": "In ICML,", "year": 2016}, {"title": "Large-scale submodular greedy exemplar selection with structured similarity matrices", "authors": ["Malioutov", "Dmitry", "Kumar", "Abhishek", "Yen", "Ian EnHsu"], "venue": "In UAI,", "year": 2016}, {"title": "Lazier than lazy greedy", "authors": ["Mirzasoleiman", "Baharan", "Badanidiyuru", "Ashwinkumar", "Karbasi", "Amin", "Vondr\u00e1k", "Jan", "Krause", "Andreas"], "venue": "In AAAI,", "year": 2015}, {"title": "Best algorithms for approximating the maximum of a submodular set function", "authors": ["Nemhauser", "George L", "Wolsey", "Leonard A"], "venue": "Mathematics of operations research,", "year": 1978}, {"title": "An analysis of approximations for maximizing submodular set functions\u2014i", "authors": ["Nemhauser", "George L", "Wolsey", "Laurence A", "Fisher", "Marshall L"], "venue": "Mathematical Programming,", "year": 1978}, {"title": "On greedy maximization of entropy", "authors": ["Sharma", "Dravyansh", "Kapoor", "Ashish", "Deshpande", "Amit"], "venue": "In ICML,", "year": 2015}, {"title": "Noisy submodular maximization via adaptive sampling with applications to crowdsourced image collection summarization", "authors": ["Singla", "Adish", "Tschiatschek", "Sebastian", "Krause", "Andreas"], "venue": "In AAAI,", "year": 2016}, {"title": "Optimal approximation for the submodular welfare problem in the value oracle model", "authors": ["Vondr\u00e1k", "Jan"], "venue": "In STOC,", "year": 2008}, {"title": "Data summarization with social contexts", "authors": ["Zhuang", "Hao", "Rahman", "Rameez", "Hu", "Xia", "Guo", "Tian", "Hui", "Pan", "Aberer", "Karl"], "venue": "In CIKM,", "year": 2016}], "id": "SP:34c9033fd539c94426f6e9eb8def0f5673d87d08", "authors": [{"name": "Avinatan Hassidim", "affiliations": []}, {"name": "Yaron Singer", "affiliations": []}], "abstractText": "In this paper we analyze the robustness of stochastic variants of the greedy algorithm for submodular maximization. Our main result shows that for maximizing a monotone submodular function under a cardinality constraint, iteratively selecting an element whose marginal contribution is approximately maximal in expectation is a sufficient condition to obtain the optimal approximation guarantee with exponentially high probability, assuming the cardinality is sufficiently large. One consequence of our result is that the linear-time STOCHASTIC-GREEDY algorithm recently proposed in (Mirzasoleiman et al., 2015) achieves the optimal running time while maintaining an optimal approximation guarantee. We also show that high probability guarantees cannot be obtained for stochastic greedy algorithms under matroid constraints, and prove an approximation guarantee which holds in expectation. In contrast to the guarantees of the greedy algorithm, we show that the approximation ratio of stochastic local search is arbitrarily bad, with high probability, as well as in expectation.", "title": "Robust Guarantees of Stochastic Greedy Algorithms"}
0,1,label2,summary_sentences
We consider learning a classifier from logged data.,1. Introduction,[0],[0]
"Here, the learner has access to a logged labeled dataset that has been collected according to a known pre-determined policy, and his goal is to learn a classifier that predicts the labels accurately over the entire population, not just conditioned on the logging policy.
",1. Introduction,[0],[0]
This problem arises frequently in many natural settings.,1. Introduction,[0],[0]
An example is predicting the efficacy of a treatment as a function of patient characteristics based on observed data.,1. Introduction,[0],[0]
Doctors may assign the treatment to patients based on some predetermined rule; recording these patient outcomes produces a logged dataset where outcomes are observed conditioned on the doctors’ assignment.,1. Introduction,[0],[0]
"A second example is recidivism prediction, where the goal is to predict whether a convict will re-offend.",1. Introduction,[0],[0]
"Judges use their own predefined policy to grant parole, and if parole is granted, then an outcome (reoffense or not) is observed.",1. Introduction,[0],[0]
"Thus the observed data records outcomes conditioned on the judges’ parole policy,
1University of California, San Diego.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Songbai Yan <yansongbai@eng.ucsd.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
while the learner’s goal is to learn a predictor over the entire population.
",1. Introduction,[0],[0]
A major challenge in learning from logged data is that the logging policy may leave large areas of the data distribution under-explored.,1. Introduction,[0],[0]
"Consequently, empirical risk minimization (ERM) on the logged data leads to classifiers that may be highly suboptimal on the population.",1. Introduction,[0],[0]
"When the logging policy is known, a second option is to use a weighted ERM, that reweighs each observed labeled data point to ensure that it reflects the underlying population.",1. Introduction,[0],[0]
"However, this may lead to sample inefficiency if the logging policy does not adequately explore essential regions of the population.",1. Introduction,[0],[0]
"A final approach, typically used in clinical trials, is controlled random experimentation – essentially, ignore the logged data, and record outcomes for fresh examples drawn from the population.",1. Introduction,[0],[0]
"This approach is expensive due to the high cost of trials, and wasteful since it ignores the observed data.
",1. Introduction,[0],[0]
"Motivated by these challenges, we propose active learning to combine logged data with a small amount of strategically chosen labeled data that can be used to correct the bias in the logging policy.",1. Introduction,[0],[0]
"This solution has the potential to achieve the best of both worlds by limiting experimentation to achieve higher sample efficiency, and by making the most of the logged data.",1. Introduction,[0],[0]
"Specifically, we assume that in addition to the logged data, the learner has some additional unlabeled data that he can selectively ask an annotator to label.",1. Introduction,[0],[0]
"The learner’s goal is to learn a highly accurate classifier over the entire population by using a combination of the logged data and with as few label queries to the annotator as possible.
",1. Introduction,[0],[0]
How can we utilize logged data for better active learning?,1. Introduction,[0],[0]
This problem has not been studied to the best of our knowledge.,1. Introduction,[0],[0]
A naive approach is to use the logged data to come up with a warm start and then do standard active learning.,1. Introduction,[0],[0]
"In this work, we show that we can do even better.",1. Introduction,[0],[0]
"In addition to the warm start, we show how to use multiple importance sampling estimators to utilize the logged data more efficiently.",1. Introduction,[0],[0]
"Additionally, we introduce a novel debiasing policy that selectively avoids label queries for those examples that are highly represented in the logged data.
",1. Introduction,[0],[0]
"Combining these three approaches, we provide a new algorithm.",1. Introduction,[0],[0]
"We prove that our algorithm is statistically consistent, and has a lower label requirement than simple active learning that uses the logged data as a warm start.",1. Introduction,[0],[0]
"Finally, we
evaluate our algorithm experimentally on various datasets and logging policies.",1. Introduction,[0],[0]
Our experiments show that the performance of our method is either the best or close to the best for a variety of datasets and logging policies.,1. Introduction,[0],[0]
This confirms that active learning to combine logged data with carefully chosen labeled data may indeed yield performance gains.,1. Introduction,[0],[0]
"Instances are drawn from an instance space X and a label space Y = {0, 1}.",2.1. Problem Setup,[0],[0]
There is an underlying data distribution D over X × Y that describes the population.,2.1. Problem Setup,[0],[0]
There is a hypothesis spaceH ⊂ YX .,2.1. Problem Setup,[0],[0]
"For simplicity, we assumeH is a finite set, but our results can be generalized to VC-classes by standard arguments (Vapnik & Chervonenkis, 1971).
",2.1. Problem Setup,[0],[0]
"The learning algorithm has access to two sources of data: logged data, and online data.",2.1. Problem Setup,[0],[0]
"The logged data are generated from m examples {(Xt, Yt)}mt=1 drawn i.i.d.",2.1. Problem Setup,[0],[0]
"from D, and",2.1. Problem Setup,[0],[0]
a logging policy Q0 : X,2.1. Problem Setup,[0],[0]
"→ [0, 1] that determines the probability of observing the label.",2.1. Problem Setup,[0],[0]
"For each example (Xt, Yt) (1 ≤ t ≤ m), an independent Bernoulli random variable Zt is drawn with expectation Q0(Xt), and then the label Yt is revealed to the learning algorithm if Zt = 11.",2.1. Problem Setup,[0],[0]
"We call T0 = {(Xt, Yt, Zt)}mt=1 the logged dataset.",2.1. Problem Setup,[0],[0]
"From the algorithm’s perspective, we assume it knows the logging policy Q0, and only observes instances {Xt}mt=1, decisions of the policy {Zt}mt=1, and revealed labels {Yt | Zt = 1}mt=1.
",2.1. Problem Setup,[0],[0]
The online data are generated as follows.,2.1. Problem Setup,[0],[0]
"Suppose there is a stream of another n examples {(Xt, Yt)}m+nt=m+1 drawn i.i.d.",2.1. Problem Setup,[0],[0]
from distribution D.,2.1. Problem Setup,[0],[0]
"At time t (m < t ≤ m+ n), the algorithm uses its query policy to compute a bit Zt ∈ {0, 1}, and then the label Yt is revealed to the algorithm if Zt = 1.",2.1. Problem Setup,[0],[0]
"The computation of Zt may in general be randomized, and is based on the observed logged data T0, observed instances {Xi}ti=m+1, previous decisions{Zi} t−1 i=m+1, and observed labels {Yi | Zi = 1}t−1i=m+1.
",2.1. Problem Setup,[0],[0]
The goal of the algorithm is to learn a classifier h ∈ H from observed logged data and online data.,2.1. Problem Setup,[0],[0]
"Fixing D, Q0, m, n, the performance measures are: (1) the error rate l(h) :",2.1. Problem Setup,[0],[0]
= PrD(h(X) 6=,2.1. Problem Setup,[0],[0]
"Y ) of the output classifier, and (2) the number of label queries on the online data.",2.1. Problem Setup,[0],[0]
"Note that the error rate is over the entire population D instead of conditioned on the logging policy, and that we assume the logged data T0 come at no cost.",2.1. Problem Setup,[0],[0]
"In this work, we are interested in the situation where n is about the same as or less than m.
1Note that this generating process implies the standard unconfoundedness assumption in the counterfactual inference literature: Pr(Yt, Zt | Xt) = Pr(Yt | Xt) Pr(Zt",2.1. Problem Setup,[0],[0]
"| Xt), that is, given the instance Xt, its label Yt is conditionally independent with the action Zt (whether the label is observed).",2.1. Problem Setup,[0],[0]
"Our algorithm is based on Disagreement-Based Active Learning (DBAL) which has rigorous theoretical guarantees and can be implemented practically (see (Hanneke et al., 2014) for a survey, and (Hanneke & Yang, 2015; Huang et al., 2015) for some recent developments).",2.2. Background on Disagreement-Based Active Learning,[0],[0]
DBAL iteratively maintains a candidate set of classifiers that contains the optimal classifier h?,2.2. Background on Disagreement-Based Active Learning,[0],[0]
:= arg minh∈H l(h) with high probability.,2.2. Background on Disagreement-Based Active Learning,[0],[0]
"At the k-th iteration, the candidate set Vk is constructed as all classifiers which have low estimated error on examples observed up to round k.",2.2. Background on Disagreement-Based Active Learning,[0],[0]
"Based on Vk, the algorithm constructs a disagreement set Dk to be a set of instances on which there are at least two classifiers in Vk that predict different labels.",2.2. Background on Disagreement-Based Active Learning,[0],[0]
"Then the algorithm draws a set Tk of unlabeled examples, where the size of Tk is a parameter of the algorithm.",2.2. Background on Disagreement-Based Active Learning,[0],[0]
"For each instance X ∈ Tk, if it falls into the disagreement region Dk, then the algorithm queries for its label; otherwise, observing that all classifiers in Vk have the same prediction on X , its label is not queried.",2.2. Background on Disagreement-Based Active Learning,[0],[0]
The queried labels are then used to update future candidate sets.,2.2. Background on Disagreement-Based Active Learning,[0],[0]
"Most learning algorithms, including DBAL, require estimating the error rate of a classifier.",2.3. Background on Error Estimators,[0],[0]
A good error estimator should be unbiased and of low variance.,2.3. Background on Error Estimators,[0],[0]
"When instances are observed with different probabilities, a commonly used error estimator is the standard importance sampling estimator that reweighs each observed labeled example according to the inverse probability of observing it.
",2.3. Background on Error Estimators,[0],[0]
Consider a simplified setting where the logged dataset T0 =,2.3. Background on Error Estimators,[0],[0]
"(Xi, Yi, Zi) m i=1",2.3. Background on Error Estimators,[0],[0]
and Pr(Zi = 1 | Xi) = Q0(Xi).,2.3. Background on Error Estimators,[0],[0]
On the online dataset T1 =,2.3. Background on Error Estimators,[0],[0]
"(Xi, Yi, Zi)m+ni=m+1, the algorithm uses a fixed query policy Q1 to determine whether to query for labels, that is, Pr(Zi = 1 | Xi) = Q1(Xi) for m < i ≤",2.3. Background on Error Estimators,[0],[0]
"m+ n. Let S = T0 ∪ T1.
",2.3. Background on Error Estimators,[0],[0]
"In this setting, the standard importance sampling (IS) error estimator for a classifier h is:
lIS(h, S) := 1
m+ n m∑ i=1 1{h(Xi) 6=",2.3. Background on Error Estimators,[0],[0]
"Yi}Zi Q0(Xi)
",2.3. Background on Error Estimators,[0],[0]
"+ 1
m+ n m+n∑ i=m+1 1{h(Xi) 6= Yi}Zi",2.3. Background on Error Estimators,[0],[0]
Q1(Xi) .,2.3. Background on Error Estimators,[0],[0]
"(1)
lIS is unbiased, and its variance is proportional to supi=0,1;x∈X 1 Qi(x)
.",2.3. Background on Error Estimators,[0],[0]
"Although the learning algorithm can choose its query policy Q1 to avoid Q1(Xi) to be too small for i > m, Q0 is the logging policy that cannot be changed.",2.3. Background on Error Estimators,[0],[0]
"When Q0(Xi) is small for some i ≤ m, the estimator in (1) have a high variance such that it may be even better to just ignore the logged dataset T0.
",2.3. Background on Error Estimators,[0],[0]
"An alternative is the multiple importance sampling (MIS) estimator with balanced heuristic (Veach & Guibas, 1995):
lMIS(h, S) := m+n∑ i=1",2.3. Background on Error Estimators,[0],[0]
1{h(Xi) 6=,2.3. Background on Error Estimators,[0],[0]
Yi}Zi mQ0(Xi) + nQ1(Xi) .,2.3. Background on Error Estimators,[0],[0]
"(2)
It can be proved that lMIS(h, S) is indeed an unbiased estimator for l(h).",2.3. Background on Error Estimators,[0],[0]
"Moreover, as proved in (Owen & Zhou, 2000; Agarwal et al., 2017), (2) always has a lower variance than both (1) and the standard importance sampling estimator that ignores the logged data.
",2.3. Background on Error Estimators,[0],[0]
"In this paper, we use multiple importance sampling estimators, and write lMIS(h, S) as l(h, S).
",2.3. Background on Error Estimators,[0],[0]
"Additional Notations In this paper, unless otherwise specified, all probabilities and expectations are over the distribution D, and we drop D from subscripts henceforth.
",2.3. Background on Error Estimators,[0],[0]
"Let ρ(h1, h2)",2.3. Background on Error Estimators,[0],[0]
:= Pr(h1(X) 6=,2.3. Background on Error Estimators,[0],[0]
"h2(X)) be the disagreement mass between h1 and h2, and ρS(h1, h2)",2.3. Background on Error Estimators,[0],[0]
:= 1 N ∑N i=1 1{h1(xi) 6=,2.3. Background on Error Estimators,[0],[0]
"h2(xi)} for S = {x1, x2, . . .",2.3. Background on Error Estimators,[0],[0]
", xN} ⊂ X be the empirical disagreement mass between h1 and h2 on S.
For any h ∈ H, r > 0, define B(h, r) := {h′ ∈ H | ρ(h, h′) ≤",2.3. Background on Error Estimators,[0],[0]
r} to be r-ball around h.,2.3. Background on Error Estimators,[0],[0]
"For any V ⊆ H, define the disagreement region DIS(V )",2.3. Background on Error Estimators,[0],[0]
:= {x ∈ X | ∃h1 6=,2.3. Background on Error Estimators,[0],[0]
h2 ∈ V s.t. h1(x) 6= h2(x)}.,2.3. Background on Error Estimators,[0],[0]
"Our algorithm employs the disagreement-based active learning framework, but modifies the main DBAL algorithm in three key ways.
",3.1. Main Ideas,[0],[0]
"KEY IDEA 1: WARM-START
Our algorithm applies a straightforward way of making use of the logged data T0 inside the DBAL framework: to set the initial candidate set V0 to be the set of classifiers that have a low empirical error on T0.
",3.1. Main Ideas,[0],[0]
KEY IDEA 2: MULTIPLE IMPORTANCE,3.1. Main Ideas,[0],[0]
"SAMPLING
Our algorithm uses multiple importance sampling estimators instead of standard importance sampling estimators.",3.1. Main Ideas,[0],[0]
"As noted in the previous section, in our setting, multiple importance sampling estimators are unbiased and have lower variance, which results in a better performance guarantee.
",3.1. Main Ideas,[0],[0]
We remark that the main purpose of using multiple importance sampling estimators here is to control the variance due to the predetermined logging policy.,3.1. Main Ideas,[0],[0]
"In the classical active learning setting without logged data, standard impor-
tance sampling can give satisfactory performance guarantees (Beygelzimer et al., 2009; 2010; Huang et al., 2015).
",3.1. Main Ideas,[0],[0]
"KEY IDEA 3: A DEBIASING QUERY STRATEGY
",3.1. Main Ideas,[0],[0]
The logging policy Q0 introduces bias into the logged data: some examples may be underrepresented since Q0 chooses to reveal their labels with lower probability.,3.1. Main Ideas,[0],[0]
Our algorithm employs a debiasing query strategy to neutralize this effect.,3.1. Main Ideas,[0],[0]
"For any instance x in the online data, the algorithm would query for its label with a lower probability if Q0(x) is relatively large.
",3.1. Main Ideas,[0],[0]
It is clear that a lower query probability leads to fewer label queries.,3.1. Main Ideas,[0],[0]
"Moreover, we claim that our debiasing strategy, though queries for less labels, does not deteriorate our theoretical guarantee on the error rate of the final output classifier.",3.1. Main Ideas,[0],[0]
"To see this, we note that we can establish a concentration bound for multiple importance sampling estimators that with probability at least 1− δ, for all h ∈ H,
l(h)− l(h?) ≤2(l(h, S)− l(h?, S))
",3.1. Main Ideas,[0],[0]
+γ1 sup x∈X 1{h(x) 6=,3.1. Main Ideas,[0],[0]
h?(x)} log |H|δ mQ0(x) +,3.1. Main Ideas,[0],[0]
"nQ1(x)
+γ1 √ sup x∈X 1{h(x) 6=",3.1. Main Ideas,[0],[0]
h?(x)} log |H|δ mQ0(x) +,3.1. Main Ideas,[0],[0]
"nQ1(x) l(h?)
(3)
where m,n are sizes of logged data and online data respectively, Q0 and Q1 are query policy during the logging phase and the online phase respectively, and γ1 is an absolute constant (see Corollary 15 in Appendix for proof).
",3.1. Main Ideas,[0],[0]
"This concentration bound implies that for any x ∈ X , if Q0(x) is large, we can set Q1(x) to be relatively small (as long as mQ0(x) + nQ1(x) ≥ infx′ mQ0(x′) + nQ1(x′)) while achieving the same concentration bound.",3.1. Main Ideas,[0],[0]
"Consequently, the upper bound on the final error rate that we can establish from this concentration bound would not be impacted by the debiasing querying strategy.
",3.1. Main Ideas,[0],[0]
One technical difficulty of applying both multiple importance sampling and the debiasing strategy to the DBAL framework is adaptivity.,3.1. Main Ideas,[0],[0]
Applying both methods requires that the query policy and consequently the importance weights in the error estimator are updated with observed examples in each iteration.,3.1. Main Ideas,[0],[0]
"In this case, the summands of the error estimator are not independent, and the estimator becomes an adaptive multiple importance sampling estimator whose convergence property is still an open problem (Cornuet et al., 2012).
",3.1. Main Ideas,[0],[0]
"To circumvent this convergence issue and establish rigorous theoretical guarantees, in each iteration, we compute the error estimator from a fresh sample set.",3.1. Main Ideas,[0],[0]
"In particular, we partition the logged data and the online data stream into
disjoint subsets, and we use one logged subset and one online subset for each iteration.",3.1. Main Ideas,[0],[0]
"Algorithm 1 Acitve learning with logged data 1: Input: confidence δ, size of online data n, logging pol-
icy Q0, logged data T0.",3.2. Details of the Algorithm,[0],[0]
2: K ← dlog ne.,3.2. Details of the Algorithm,[0],[0]
3: S̃0 ← T (0)0 ; V0 ← H; D0 ← X ; ξ0 ← infx∈X Q0(x).,3.2. Details of the Algorithm,[0],[0]
"4: for k = 0, . . .",3.2. Details of the Algorithm,[0],[0]
",K − 1 do 5: Define δk ← δ(k+1)(k+2) ; σ(k, δ) ← log |H|/δ mkξk+nk ;
∆k(h, h ′)← γ0(σ(k, δk2 )+",3.2. Details of the Algorithm,[0],[0]
"√ σ(k, δk2 )ρS̃k(h, h
′)).",3.2. Details of the Algorithm,[0],[0]
6: .,3.2. Details of the Algorithm,[0],[0]
γ0 is an absolute constant defined in Lemma 16.,3.2. Details of the Algorithm,[0],[0]
"7: ĥk ← arg minh∈Vk l(h, S̃k).",3.2. Details of the Algorithm,[0],[0]
"8: Define the candidate set
Vk+1",3.2. Details of the Algorithm,[0],[0]
← {h ∈,3.2. Details of the Algorithm,[0],[0]
"Vk | l(h, S̃k) ≤",3.2. Details of the Algorithm,[0],[0]
"l(ĥk, S̃k)+∆k(h, ĥk)}
and its disagreement region Dk+1 ← DIS(Vk+1).",3.2. Details of the Algorithm,[0],[0]
"9: Define ξk+1 ← infx∈Dk+1 Q0(x), and Qk+1(x) ←
1{Q0(x) ≤ ξk+1",3.2. Details of the Algorithm,[0],[0]
+ 1/α}.,3.2. Details of the Algorithm,[0],[0]
"10: Draw nk+1 samples {(Xt, Yt)} m+n1+···+nk+1 t=m+n1···+nk+1, and
present {Xt} m+n1+···+nk+1 t=m+n1+···+nk+1 to the algorithm.
11: for t = m+n1+· · ·+nk+1 to m+n1+· · ·+nk+1 do 12:",3.2. Details of the Algorithm,[0],[0]
Zt ← Qk+1(Xt).,3.2. Details of the Algorithm,[0],[0]
"13: if Zt = 1 then 14: If Xt ∈ Dk+1, query for label: Ỹt ← Yt; otherwise infer Ỹt ← ĥk(Xt).",3.2. Details of the Algorithm,[0],[0]
"15: end if 16: end for 17: T̃k+1 ← {Xt, Ỹt, Zt} m+n1+···+nk+1 t=m+n1+···+nk+1.",3.2. Details of the Algorithm,[0],[0]
"18: S̃k+1 ← T (k+1)0 ∪ T̃k+1. 19: end for 20: Output ĥ = arg minh∈VK l(h, S̃K).
",3.2. Details of the Algorithm,[0],[0]
The Algorithm is shown as Algorithm 1.,3.2. Details of the Algorithm,[0],[0]
Algorithm 1 runs in K iterations where K = dlog ne (recall n is the size of the online data stream).,3.2. Details of the Algorithm,[0],[0]
"For simplicity, we assume n = 2K − 1.
",3.2. Details of the Algorithm,[0],[0]
"As noted in the previous subsection, we require the algorithm to use a disjoint sample set for each iteration.",3.2. Details of the Algorithm,[0],[0]
"Thus, we partition the data as follows.",3.2. Details of the Algorithm,[0],[0]
"The online data stream is partitioned into K parts T1, · · · , TK of sizes n1 = 2
0, · · · , nK = 2K−1.",3.2. Details of the Algorithm,[0],[0]
We define n0 = 0 for completeness.,3.2. Details of the Algorithm,[0],[0]
"The logged data T0 is partitioned into K + 1 parts T
(0) 0 , · · · , T (K) 0 of sizes m0 = m/3,m1 = αn1,m2 = αn2, · · · ,mK = αnK (where α = 2m/3n and we assume α ≥ 1 is an integer for simplicity.",3.2. Details of the Algorithm,[0],[0]
m0 can take other values as long as it is a constant factor of m).,3.2. Details of the Algorithm,[0],[0]
"The algorithm uses T (0)0 to construct an initial candidate set, and uses
Sk := T (k) 0 ∪ Tk in iteration k.
Algorithm 1 uses the disagreement-based active learning framework.",3.2. Details of the Algorithm,[0],[0]
"At iteration k (k = 0, · · · ,K − 1), it first constructs a candidate set Vk+1 which is the set of classifiers whose training error (using the multiple importance sampling estimator) on T (k)0 ∪ T̃k is small, and its disagreement region Dk+1.",3.2. Details of the Algorithm,[0],[0]
"At the end of the k-th iteration, it receives the (k + 1)-th part of the online data stream {Xi} m+n1···+nk+1",3.2. Details of the Algorithm,[0],[0]
i=m+n1···+nk+1 from which it can query for labels.,3.2. Details of the Algorithm,[0],[0]
It only queries for labels inside the disagreement region Dk+1.,3.2. Details of the Algorithm,[0],[0]
"For any example X outside the disagreement region, Algorithm 1 infers its label Ỹ = ĥk(X).",3.2. Details of the Algorithm,[0],[0]
"Throughout this paper, we denote by Tk, Sk the set of examples with original labels, and by T̃k, S̃k the set of examples with inferred labels.",3.2. Details of the Algorithm,[0],[0]
"The algorithm only observes T̃k and S̃k.
",3.2. Details of the Algorithm,[0],[0]
"Algorithm 1 uses aforementioned debiasing query strategy, which leads to fewer label queries than the standard disagreement-based algorithms.",3.2. Details of the Algorithm,[0],[0]
"To simplify our analysis, we round the query probability Qk(x) to be 0 or 1.",3.2. Details of the Algorithm,[0],[0]
"We first introduce some additional quantities.
",4.1. Consistency,[0],[0]
Define h?,4.1. Consistency,[0],[0]
":= minh∈H l(h) to be the best classifier in H, and ν",4.1. Consistency,[0],[0]
:= l(h?) to be its error rate.,4.1. Consistency,[0],[0]
"Let γ2 to be an absolute constant to be specified in Lemma 17 in Appendix.
We introduce some definitions that will be used to upperbound the size of the disagreement sets in our algorithm.",4.1. Consistency,[0],[0]
Let DIS0 := X .,4.1. Consistency,[0],[0]
Recall K = dlog ne.,4.1. Consistency,[0],[0]
"For k = 1, . . .",4.1. Consistency,[0],[0]
",K, let ζk := supx∈DISk−1 log(2|H|/δk) mk−1Q0(x)+nk−1 , k := γ2ζk +
γ2 √ ζkl(h?), DISk := DIS(B(h?, 2ν + k)).",4.1. Consistency,[0],[0]
"Let ζ := supx∈DIS1 1 αQ0(x)+1 .
",4.1. Consistency,[0],[0]
"The following theorem gives statistical consistency of our algorithm.
",4.1. Consistency,[0],[0]
Theorem 1.,4.1. Consistency,[0],[0]
"There is an absolute constant c0 such that for any δ > 0, with probability at least 1− δ,
l(ĥ) ≤l(h?)",4.1. Consistency,[0],[0]
+,4.1. Consistency,[0],[0]
c0 sup x∈DISK,4.1. Consistency,[0],[0]
"log K|H|δ mQ0(x) + n
+ c0
√ sup
x∈DISK",4.1. Consistency,[0],[0]
log K|H|δ mQ0(x) + n l(h?).,4.1. Consistency,[0],[0]
"We first introduce the adjusted disagreement coefficient, which characterizes the rate of decrease of the query region as the candidate set shrinks.
",4.2. Label Complexity,[0],[0]
Definition 2.,4.2. Label Complexity,[0],[0]
"For any measurable set A ⊆ X , define
S(A,α) to be⋃ A′⊆A ( A′ ∩ { x : Q0(x) ≤ inf x∈A′ Q0(x)",4.2. Label Complexity,[0],[0]
"+ 1 α }) .
",4.2. Label Complexity,[0],[0]
"For any r0 ≥ 2ν, α ≥ 1, define the adjusted disagreement coefficient θ̃(r0, α) to be
sup r>r0
1 r Pr(S(DIS(B(h?, r)), α)).
",4.2. Label Complexity,[0],[0]
"The adjusted disagreement coefficient is a generalization of the standard disagreement coefficient (Hanneke, 2007) which has been widely used for analyzing active learning algorithms.",4.2. Label Complexity,[0],[0]
"The standard disagreement coefficient θ(r) can be written as θ(r) = θ̃(r, 1), and clearly θ(r) ≥ θ̃(r, α) for all α ≥ 1.
",4.2. Label Complexity,[0],[0]
We can upper-bound the number of labels queried by our algorithm using the adjusted disagreement coefficient.,4.2. Label Complexity,[0],[0]
"(Recall that we only count labels queried during the online phase, and that α = 2m/3n ≥ 1) Theorem 3.",4.2. Label Complexity,[0],[0]
"There is an absolute constant c1 such that for any δ > 0, with probability at least 1 − δ, the number of labels queried by Algorithm 1 is at most:
c1θ̃(2ν + K , α)(nν + ζ log n log |H| log n
δ
+ log n √ nνζ log
|H| log n δ ).",4.2. Label Complexity,[0],[0]
"As a sanity check, note that when Q0(x) ≡ 1 (i.e., all labels in the logged data are shown), our results reduce to the classical bounds for disagreement-based active learning with a warm-start.
",4.3. Remarks,[0],[0]
"Next, we compare the theoretical guarantees of our algorithm with some alternatives.",4.3. Remarks,[0],[0]
We fix the target error rate to be ν,4.3. Remarks,[0],[0]
"+ , assume we are given m logged data, and compare upper bounds on the number of labels required in the online phase to achieve the target error rate.",4.3. Remarks,[0],[0]
Recall ξ0 = infx∈X Q0(x).,4.3. Remarks,[0],[0]
"Define ξ̃K := infx∈DISK Q0(x), θ̃ := θ̃(2ν, α), θ := θ(2ν).
",4.3. Remarks,[0],[0]
"From Theorem 1 and 3 and some algebra, our algorithm requires Õ ( νθ̃ · (ν+ 2 log |H| δ −mξ̃K) ) labels.
",4.3. Remarks,[0],[0]
The first alternative is passive learning that requests all labels for {Xt}m+nt=m+1 and finds an empirical risk minimizer using both logged data and online data.,4.3. Remarks,[0],[0]
"If standard importance sampling is used, the upper bound is Õ (
1 ξ0 (ν+ 2 log |H| δ −mξ0)
) .",4.3. Remarks,[0],[0]
"If multiple importance sam-
pling is used, the upper bound is Õ ( ν+ 2 log |H| δ −mξ̃K ) .
",4.3. Remarks,[0],[0]
"Both bounds are worse than ours since νθ̃ ≤ 1 and ξ0 ≤ ξ̃K ≤ 1.
",4.3. Remarks,[0],[0]
A second alternative is standard disagreement-based active learning with naive warm-start where the logged data is only used to construct an initial candidate set.,4.3. Remarks,[0],[0]
"For standard importance sampling, the upper bound is Õ ( νθ ξ0 (ν+ 2 log |H| δ −mξ0) ) .",4.3. Remarks,[0],[0]
"For multiple importance sampling (i.e., out algorithm without the debiasing step), the upper bound is Õ ( νθ · (ν+ 2 log |H| δ −mξ̃K) ) .",4.3. Remarks,[0],[0]
"Both
bounds are worse than ours since νθ̃ ≤",4.3. Remarks,[0],[0]
"νθ and ξ0 ≤ ξ̃K ≤ 1.
",4.3. Remarks,[0],[0]
"A third alternative is to merely use past policy to label data – that is, query on x with probability Q0(x) in the online phase.",4.3. Remarks,[0],[0]
"The upper bound here is Õ (
E[Q0(X)]",4.3. Remarks,[0],[0]
"ξ0 (ν+ 2 log |H| δ −mξ0)
) .",4.3. Remarks,[0],[0]
"This is worse than ours
since ξ0 ≤ E[Q0(X)] and ξ0 ≤ ξ̃K ≤ 1.",4.3. Remarks,[0],[0]
We now empirically validate our theoretical results by comparing our algorithm with a few alternatives on several datasets and logging policies.,5. Experiments,[0],[0]
"In particular, we confirm that the test error of our classifier drops faster than several alternatives as the expected number of label queries increases.",5. Experiments,[0],[0]
"Furthermore, we investigate the effectiveness of two key components of our algorithm: multiple importance sampling and the debiasing query strategy.",5. Experiments,[0],[0]
"To the best of our knowledge, no algorithms with theoretical guarantees have been proposed in the literature.",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
We consider the overall performance of our algorithm against two natural baselines: standard passive learning (PASSIVE) and the disagreement-based active learning algorithm with warm start (DBALW).,5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"To understand the contribution of multiple importance sampling and the debiasing query strategy, we also compare the results with the disagreement-based active learning with warm start that uses multiple importance sampling (DBALWM).",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"We do not compare with the standard disagreement-based active learning that ignores the logged data since the contribution of warm start is clear: it always results in a smaller initial candidate set, and thus leads to less label queries.
",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"Precisely, the algorithms we implement are:
• PASSIVE:",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"A passive learning algorithm that queries labels for all examples in the online sequence and uses the standard importance sampling estimator to combine logged data and online data.
",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
• DBALW:,5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"A disagreement-based active learning algorithm that uses the standard importance sampling estimator, and constructs the initial candidate set with logged data.",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"This algorithm only uses only our first key idea – warm start.
",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
• DBALWM:,5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"A disagreement-based active learning algorithm that uses the multiple importance sampling estimator, and constructs the initial candidate set with logged data.",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"This algorithm uses our first and second key ideas, but not the debiasing query strategy.",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"In other words, this method sets Qk ≡ 1 in Algorithm 1.
• IDBAL:",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"The method proposed in this paper: improved disagreement-based active learning algorithm with warm start that uses the multiple importance sampling estimator and the debiasing query strategy.
",5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
Our implementation of above algorithms follows Vowpal Wabbit (vw).,5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
Details can be found in Appendix.,5.1.1. ALGORITHMS AND IMPLEMENTATIONS,[0],[0]
"Due to lack of public datasets for learning with logged data, we convert datasets for standard binary classification into our setting.",5.1.2. DATA,[0],[0]
"Specifically, we first randomly select 80% of the whole dataset as training data and the remaining 20% is test data.",5.1.2. DATA,[0],[0]
"We randomly select 50% of the training set as logged data, and the remaining 50% is online data.",5.1.2. DATA,[0],[0]
"We then run an artificial logging policy (to be specified later) on the logged data to determine whether each label should be revealed to the learning algorithm or not.
",5.1.2. DATA,[0],[0]
"Experiments are conducted on synthetic data and 11 datasets from UCI datasets (Lichman, 2013) and LIBSVM datasets (Chang & Lin, 2011).",5.1.2. DATA,[0],[0]
"The synthetic data is generated as follows: we generate 6000 30-dimensional points uniformly from hypercube [−1, 1]30, and labels are assigned by a random linear classifier and then flipped with probability 0.1 independently.
",5.1.2. DATA,[0],[0]
"We use the following four logging policies:
• IDENTICAL:",5.1.2. DATA,[0],[0]
"Each label is revealed with probability 0.005.
",5.1.2. DATA,[0],[0]
• UNIFORM:,5.1.2. DATA,[0],[0]
We first assign each instance in the instance space to three groups with (approximately) equal probability.,5.1.2. DATA,[0],[0]
"Then the labels in each group are revealed with probability 0.005, 0.05, and 0.5 respectively.
",5.1.2. DATA,[0],[0]
• UNCERTAINTY:,5.1.2. DATA,[0],[0]
We first train a coarse linear classifier using 10% of the data.,5.1.2. DATA,[0],[0]
"Then, for an instance at distance r to the decision boundary, we reveal its label with probability exp(−cr2) where c is some constant.",5.1.2. DATA,[0],[0]
"This policy is intended to simulate uncertainty sampling used in active learning.
",5.1.2. DATA,[0],[0]
• CERTAINTY:,5.1.2. DATA,[0],[0]
We first train a coarse linear classifier using 10% of the data.,5.1.2. DATA,[0],[0]
"Then, for an instance at distance r to the decision boundary, we reveal its label with probability cr2 where c is some constant.",5.1.2. DATA,[0],[0]
This policy is intended to simulate a scenario where an action (i.e. querying for labels in our setting) is taken only if the current model is certain about its consequence.,5.1.2. DATA,[0],[0]
The experiments are conducted as follows.,5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"For a fixed policy, for each dataset d, we repeat the following process 10 times.",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"At time k, we first randomly generate a simulated logged dataset, an online dataset, and a test dataset as stated above.",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"Then for i = 1, 2, · · · , we set the horizon of the online data stream ai = 10 × 2i (in other words, we only allow the algorithm to use first ai examples in the online dataset), and run algorithm A with parameter set p (to be specified later) using the logged dataset and first ai examples in the online dataset.",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"We record n(d, k, i, A, p) to be the number of label queries, and e(d, k, i, A, p) to be the test error of the learned linear classifier.
",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"Let n̄(d, i, A, p) = 110 ∑ k n(d, k, i, A, p), ē(d, i, A, p) =
1 10 ∑ k e(d, k, i, A, p).",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"To evaluate the overall performance of algorithm A with parameter set p, we use the following area under the curve metric (see also (Huang et al., 2015)):
AUC(d,A, p) = ∑ i ē(d, i, A, p) + ē(d, i+ 1, A, p) 2
· (n̄(d, i+ 1, A, p)− n̄(d, i, A, p)).
",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"A small value of AUC means that the test error decays fast as the number of label queries increases.
",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"The parameter set p consists of two parameters:
• Model capacity C (see also item 4 in Appendix F.1).",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"In our theoretical analysis there is a term C := O(log Hδ ) in the bounds, which is known to be loose in practice (Hsu, 2010).",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"Therefore, in experiments, we treat C as a parameter to tune.",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"We try C in {0.01 × 2k | k = 0, 2, 4, . . .",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
", 18}
• Learning rate η (see also item 3 in Appendix F.1).",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
We use online gradient descent with stepsize √ η t+η .,5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"We
try η in {0.0001× 2k | k = 0, 2, 4, . . .",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
", 18}.
",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
"For each policy, we report AUC(d,A) = minp AUC(d,A, p), the AUC under the parameter set that minimizes AUC for dataset d and algorithm A.",5.1.3. METRICS AND PARAMETER TUNING,[0],[0]
We report the AUCs for each algorithm under each policy and each dataset in Tables 1 to 4.,5.2. Results and Discussion,[0],[0]
"The test error curves can be found in Appendix.
",5.2. Results and Discussion,[0],[0]
"Table 1: AUC under Identical policy
Dataset Passive DBALw DBALwm IDBAL
synthetic 121.77 123.61 111.16 106.66 letter 4.40 3.65 3.82 3.48 skin 27.53 27.29 21.48 21.44 magic 109.46 101.77 89.95 83.82 covtype 228.04 209.56 208.82 220.27 mushrooms 19.22 25.29 18.54 23.67 phishing 78.49 73.40 70.54 71.68 splice 65.97 67.54 65.73 65.66 svmguide1 59.36 55.78 46.79 48.04 a5a 53.34 50.8 51.10 51.21 cod-rna 175.88 176.42 167.42 164.96 german 65.76 68.68 59.31 61.54
Table 2: AUC under Uniform policy
Dataset Passive DBALw DBALwm IDBAL
synthetic 113.49 106.24 92.67 88.38 letter 1.68 1.29 1.45 1.59 skin 23.76 21.42 20.67 19.58 magic 53.63 51.43 51.78 50.19 covtype 262.34 287.40 274.81 263.82 mushrooms 7.31 6.81 6.51 6.90 phishing 42.53 39.56 39.19 37.02 splice 88.61 89.61 90.98 87.75 svmguide1 110.06 105.63 98.41 96.46 a5a",5.2. Results and Discussion,[0],[0]
"46.96 48.79 49.50 47.60 cod-rna 63.39 63.30 66.32 58.48 german 63.60 55.87 56.22 55.79
Overall Performance The results confirm that the test error of the classifier output by our algorithm (IDBAL) drops faster than the baselines PASSIVE and DBALW: as demonstrated in Tables 1 to 4, IDBAL achieves lower AUC than both PASSIVE and DBALW for a majority of datasets under all policies.",5.2. Results and Discussion,[0],[0]
We also see that IDBAL performs better than or close to DBALWM for all policies other than Identical.,5.2. Results and Discussion,[0],[0]
"This confirms that among our two key novel ideas, using multiple importance sampling consistently results in a performance gain.",5.2. Results and Discussion,[0],[0]
"Using the debiasing query strategy over multiple importance sampling also leads to performance gains, but these are less consistent.
",5.2. Results and Discussion,[0],[0]
"The Effectiveness of Multiple Importance Sampling As noted in Section 2.3, multiple importance sampling estimators have lower variance than standard importance sampling estimators, and thus can lead to a lower label complexity.",5.2. Results and Discussion,[0],[0]
"This is verified in our experiments that DBALWM (DBAL with multiple importance sampling estimators) has a lower AUC than DBALW (DBAL with standard impor-
tance sampling estimator) on a majority of datasets under all policies.
",5.2. Results and Discussion,[0],[0]
"The Effectiveness of the Debiasing Query Strategy Under Identical policy, all labels in the logged data are revealed with equal probability.",5.2. Results and Discussion,[0],[0]
"In this case, our algorithm IDBAL queries all examples in the disagreement region as DBALWM does.",5.2. Results and Discussion,[0],[0]
"As shown in Table 1, IDBAL and DBALWM achieves the best AUC on similar number of datasets, and both methods outperform DBALW over most datasets.
",5.2. Results and Discussion,[0],[0]
"Under Uniform, Uncertainty, and Certainty policies, labels in the logged data are revealed with different probabilities.",5.2. Results and Discussion,[0],[0]
"In this case, IDBAL’s debiasing query strategy takes effect: it queries less frequently the instances that are wellrepresented in the logged data, and we show that this could lead to a lower label complexity theoretically.",5.2. Results and Discussion,[0],[0]
"In our experiments, as shown in Tables 2 to 4, IDBAL does indeed outperform DBALWM on these policies empirically.",5.2. Results and Discussion,[0],[0]
"Learning from logged observational data is a fundamental problem in machine learning with applications to causal inference (Shalit et al., 2017), information retrieval (Strehl et al., 2010; Li et al., 2015; Hofmann et al., 2016), recommender systems (Li et al., 2010; Schnabel et al., 2016), online learning (Agarwal et al., 2014; Wang et al., 2017), and reinforcement learning (Thomas, 2015; Thomas et al., 2015; Mandel et al., 2016).",6. Related Work,[0],[0]
"This problem is also closely related to covariate shift (Zadrozny, 2004; Sugiyama et al., 2007; Ben-David et al., 2010).",6. Related Work,[0],[0]
"Two variants are widely studied – first, when the logging policy is known, a problem known as learning from logged data (Li et al., 2015; Thomas et al., 2015; Swaminathan & Joachims, 2015a;b), and second, when this policy is unknown (Johansson et al., 2016; Athey & Imbens, 2016; Kallus, 2017; Shalit et al., 2017), a problem known as learning from observational data.",6. Related Work,[0],[0]
"Our work addresses the first problem.
",6. Related Work,[0],[0]
"When the logging policy is unknown, the direct method (Dudı́k et al., 2011) finds a classifier using observed data.",6. Related Work,[0],[0]
"This method, however, is vulnerable to selection bias (Hofmann et al., 2016; Johansson et al., 2016).",6. Related Work,[0],[0]
"Existing debiasing procedures include (Athey & Imbens, 2016; Kallus, 2017), which proposes a tree-based method to partition the data space, and (Johansson et al., 2016; Shalit et al., 2017), which proposes to use deep neural networks to learn a good representation for both the logged and population data.
",6. Related Work,[0],[0]
"When the logging policy is known, we can learn a classifier by optimizing a loss function that is an unbiased estimator of the expected error rate.",6. Related Work,[0],[0]
"Even in this case, however, estimating the expected error rate of a classifier is not completely straightforward and has been one of the central problems in contextual bandit (Wang et al., 2017), off-policy evaluation (Jiang & Li, 2016), and other related fields.",6. Related Work,[0],[0]
"The most common solution is to use importance sampling according to the inverse propensity scores (Rosenbaum & Rubin, 1983).",6. Related Work,[0],[0]
"This method is unbiased when propensity scores are accurate, but may have high variance when some propensity scores are close to zero.",6. Related Work,[0],[0]
"To resolve this, (Bottou et al., 2013; Strehl et al., 2010; Swaminathan & Joachims, 2015a) propose to truncate the inverse propensity score, (Swaminathan & Joachims, 2015b) proposes to use normalized importance sampling, and (Jiang & Li, 2016; Dudı́k et al., 2011; Thomas & Brunskill, 2016; Wang et al., 2017) propose doubly robust estimators.",6. Related Work,[0],[0]
"Recently, (Thomas et al., 2015) and (Agarwal et al., 2017) suggest adjusting the importance weights according to data to further reduce the variance.",6. Related Work,[0],[0]
"We use the multiple importance sampling estimator (which have also been recently studied in (Agarwal et al., 2017) for policy evaluation), and we prove this estimator concentrates around the true expected loss tightly.
",6. Related Work,[0],[0]
"Most existing work on learning with logged data falls into
the passive learning paradigm, that is, they first collect the observational data and then train a classifier.",6. Related Work,[0],[0]
"In this work, we allow for active learning, that is, the algorithm could adaptively collect some labeled data.",6. Related Work,[0],[0]
"It has been shown in the active learning literature that adaptively selecting data to label can achieve high accuracy at low labeling cost (Balcan et al., 2009; Beygelzimer et al., 2010; Hanneke et al., 2014; Zhang & Chaudhuri, 2014; Huang et al., 2015).",6. Related Work,[0],[0]
"Krishnamurthy et al. (2017) study active learning with bandit feedback and give a disagreement-based learning algorithm.
",6. Related Work,[0],[0]
"To the best of our knowledge, there is no prior work with theoretical guarantees that combines passive and active learning with a logged observational dataset.",6. Related Work,[0],[0]
"Beygelzimer et al. (2009) consider active learning with warm-start where the algorithm is presented with a labeled dataset prior to active learning, but the labeled dataset is not observational: it is assumed to be drawn from the same distribution for the entire population, while in our work, we assume the logged dataset is in general drawn from a different distribution by a logging policy.",6. Related Work,[0],[0]
We consider active learning with logged data.,7. Conclusion and Future Work,[0],[0]
The logged data are collected by a predetermined logging policy while the learner’s goal is to learn a classifier over the entire population.,7. Conclusion and Future Work,[0],[0]
"We propose a new disagreement-based active learning algorithm that makes use of warm start, multiple importance sampling, and a debiasing query strategy.",7. Conclusion and Future Work,[0],[0]
We show that theoretically our algorithm achieves better label complexity than alternative methods.,7. Conclusion and Future Work,[0],[0]
"Our theoretical results are further validated by empirical experiments on different datasets and logging policies.
",7. Conclusion and Future Work,[0],[0]
This work can be extended in several ways.,7. Conclusion and Future Work,[0],[0]
"First, the derivation and analysis of the debiasing strategy are based on a variant of the concentration inequality (3) in subsection 3.1.",7. Conclusion and Future Work,[0],[0]
"The inequality relates the generalization error with the best error rate l(h?), but has a looser variance term than some existing bounds (for example (Cortes et al., 2010)).",7. Conclusion and Future Work,[0],[0]
"A more refined analysis on the concentration of weighted estimators could better characterize the performance of the proposed algorithm, and might also improve the debiasing strategy.",7. Conclusion and Future Work,[0],[0]
"Second, due to the dependency of multiple importance sampling, in Algorithm 1, the candidate set Vk+1 is constructed with only the k-th segment of data S̃k instead of all data collected so far ∪ki=0S̃i.",7. Conclusion and Future Work,[0],[0]
One future direction is to investigate how to utilize all collected data while provably controlling the variance of the weighted estimator.,7. Conclusion and Future Work,[0],[0]
"Finally, it would be interesting to investigate how to perform active learning from logged observational data without knowing the logging policy.
",7. Conclusion and Future Work,[0],[0]
Acknowledgements We thank NSF under CCF 1719133 for support.,7. Conclusion and Future Work,[0],[0]
"We thank Chris Meek, Adith Swaminathan, and Chicheng Zhang for helpful discussions.",7. Conclusion and Future Work,[0],[0]
We also thank anonymous reviewers for constructive comments.,7. Conclusion and Future Work,[0],[0]
"We consider active learning with logged data, where labeled examples are drawn conditioned on a predetermined logging policy, and the goal is to learn a classifier on the entire population, not just conditioned on the logging policy.",abstractText,[0],[0]
"Prior work addresses this problem either when only logged data is available, or purely in a controlled random experimentation setting where the logged data is ignored.",abstractText,[0],[0]
"In this work, we combine both approaches to provide an algorithm that uses logged data to bootstrap and inform experimentation, thus achieving the best of both worlds.",abstractText,[0],[0]
"Our work is inspired by a connection between controlled random experimentation and active learning, and modifies existing disagreement-based active learning algorithms to exploit logged data.",abstractText,[0],[0]
Active Learning with Logged Data,title,[0],[0]
"Visual recognition is undergoing a period of transformative progress, due in large part to the success of deep architectures trained on massive datasets with supervision.",1. Introduction,[0],[0]
"While visual data is in ready supply, high-quality supervised labels are not.",1. Introduction,[0],[0]
One attractive solution is the exploration of unsupervised learning.,1. Introduction,[0],[0]
"However, regardless how they are trained, one still needs to evaluate accuracy of the resulting systems.",1. Introduction,[0],[0]
"Given the importance of rigorous, empirical benchmarking, it appears impossible to avoid the costs of assembling high-quality, human-annotated test data for test evaluation.
",1. Introduction,[0],[0]
"Unfortunately, manually annotating ground-truth for largescale test datasets is often prohibitively expensive, particu-
1University of California, Irvine 2Carnegie Mellon University.",1. Introduction,[0],[0]
"Correspondence to: Phuc Nguyen <nguyenpx@uci.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
larly for rich annotations required to evaluate object detection and segmentation.,1. Introduction,[0],[0]
Even simple image tag annotations pose an incredible cost at scale 1.,1. Introduction,[0],[0]
"In contrast, obtaining noisy or partial annotations is often far cheaper or even free.",1. Introduction,[0],[0]
"For example, numerous social media platforms produce image and video data that are dynamically annotated with user-provided tags (Flickr, Vine, Snapchat, Facebook, YouTube).",1. Introduction,[0],[0]
"While much work has explored the use of such massively-large “webly-supervised” data sources for learning (Wu et al., 2015; Yu et al., 2014; Li et al., 2017; Veit et al., 2017), we instead focus on them for evaluation.
",1. Introduction,[0],[0]
How can we exploit such partial or noisy labels during testing?,1. Introduction,[0],[0]
"With a limited budget for vetting noisy groundtruth labels, one may be tempted to simply evaluate performance on a small set of clean data, or alternately just trust the cheap-but-noisy labels on the whole dataset.",1. Introduction,[0],[0]
"However, such approaches can easily give an inaccurate impression of system performance.",1. Introduction,[0],[0]
We show in our experiments that these naive approaches can produce alarmingly-incorrect estimates of comparative model performance.,1. Introduction,[0],[0]
"Even with a significant fraction of vetted data, naive performance esti-
1For example, NUS-WIDE, (Chua et al., 2009) estimated 3000 man-hours to semi-manually annotate a relatively small set of 81 concepts across 270K images
mates can incorrectly rank two algorithms in 15% of trials, while our active testing approach significantly reduces this misranking error to 3%.
",1. Introduction,[0],[0]
"The problem of label noise even exists for “expertly” annotated datasets, whose construction involves manual selection of a test set which is deemed representative in combination with crowd-sourced labeling by multiple experts (Rashtchian et al., 2010; Khattak & Salleb-Aouissi, 2011).",1. Introduction,[0],[0]
"Preserving annotation quality is an area of intense research within the HCI/crowdsourcing community (Kamar et al., 2012; Sheshadri & Lease, 2013).",1. Introduction,[0],[0]
"In practice, annotation errors are often corrected incrementally through multiple rounds of interactive error discovery and visual inspection of algorithm test results over the lifetime of the dataset.",1. Introduction,[0],[0]
"For example, in evaluating object detectors, the careful examination of detector errors on the test set (Hoiem et al., 2012) often reveals missing annotations in widelyused benchmarks (Lin et al., 2014; Everingham et al., 2015; Dollar et al., 2012) and may in turn invoke further iterations of manual corrections (e.g., (Mathias et al., 2014)).",1. Introduction,[0],[0]
"In this work, we formalize such ad-hoc practices in a framework we term active testing, and show that significantly improved estimates of accuracy can be made through simple statistical models and active annotation strategies.",1. Introduction,[0],[0]
Benchmarking:,2. Related Work,[0],[0]
Empirical benchmarking is now widely considered to be an integral tool in the development of vision and learning algorithms.,2. Related Work,[0],[0]
"Rigorous evaluation, often in terms of challenge competitions (Russakovsky et al., 2015; Everingham et al., 2010) on held-out data, serves to formally codify proxies for scientific or application goals and provides quantitative ways to characterize progress towards them.",2. Related Work,[0],[0]
"The importance and difficulties of test dataset construction and annotation are now readily appreciated (Ponce et al., 2006; Torralba & Efros, 2011).
",2. Related Work,[0],[0]
"Benchmark evaluation can be framed in terms of the well-known empirical risk minimization approach to learning (Vapnik, 1992).",2. Related Work,[0],[0]
"Benchmarking seeks to estimate the risk, defined as the expected loss of an algorithm under the true data distribution.",2. Related Work,[0],[0]
"Since the true distribution is unknown, the expected risk is estimated by computing loss a finite sized sample test set.",2. Related Work,[0],[0]
"Traditional losses (such as 0-1 error) decompose over test examples, but we are often interested in multivariate ranking-based metrics that do not decompose (such as Precision@K and Average Precision (Joachims, 2005)).",2. Related Work,[0],[0]
"Defining and estimating expected risk for such metrics is more involved (e.g., Precision@K should be replaced by precision at a specified quantile (Boyd et al., 2012))",2. Related Work,[0],[0]
"but generalization bounds are known (Agarwal et al., 2005; Hill et al., 2002).",2. Related Work,[0],[0]
"For simplicity, we focus on the problem of estimating the empirical risk on a fixed, large but finite
test set.
",2. Related Work,[0],[0]
"Semi-supervised testing: To our knowledge, there have only been a handful of works specifically studying the problem of estimating recognition performance on partially labeled test data.",2. Related Work,[0],[0]
"Anirudh et al. (Anirudh & Turaga, 2014) study the problem of ’test-driving’ a detector to allow the users to get a quick sense of the generalizability of the system.",2. Related Work,[0],[0]
Closer to our approach is that of Welinder et al.,2. Related Work,[0],[0]
"(Welinder et al., 2013), who estimate the performance curves using a generative model for the classifier’s confidence scores.",2. Related Work,[0],[0]
"Their approach leverages ideas from the semi-supervised learning literature while our approach builds on active learning.
",2. Related Work,[0],[0]
The problem of estimating benchmark performance from sampled relevance labels has been explored more extensively in the information retrieval literature where complete annotation was acknowledged as infeasible.,2. Related Work,[0],[0]
"Initial work focused on deriving labeling strategies that produce lowvariance and unbiased estimates (Yilmaz & Aslam, 2006; Aslam et al., 2006) and identifying performant retrieval systems (Moffat et al., 2007).",2. Related Work,[0],[0]
"(Sabharwal & Sedghi, 2017) give error bounds for estimating PR and ROC curves by choosing samples to label based on the system output ranking.",2. Related Work,[0],[0]
"(Gao et al., 2014) estimate performance using an EM algorithm to integrate relevance judgements.",2. Related Work,[0],[0]
"(Li & Kanoulas, 2017) and (Rahman et al., 2018) take a strategy similar to ours in actively selecting test items to label as well as estimating performance on remaining unlabeled data.
",2. Related Work,[0],[0]
Active learning: Our proposed formulation of active testing is closely related to active learning.,2. Related Work,[0],[0]
"From a theoretical perspective, active learning can provide strong guarantees of efficiency under certain restrictions (Balcan & Urner, 2016).",2. Related Work,[0],[0]
"Human-in-the-loop active learning approaches have been well explored for addressing training data collection in visual recognition systems (Branson et al., 2010; Wah et al., 2011; Vijayanarasimhan & Grauman, 2014).",2. Related Work,[0],[0]
"One
can view active testing as a form of active learning where the actively-trained model is a statistical predictor of performance on a test set.",2. Related Work,[0],[0]
"Active learning is typically cast within the standard machine-learning paradigm, where the goal is to (interactively) learn a model that makes accurate per-example predictions on held-out i.i.d data.",2. Related Work,[0],[0]
"In this case, generalization is of paramount importance.",2. Related Work,[0],[0]
"On the other hand, active-testing interactively learns a model that makes aggregate statistical predictions over a fixed dataset.",2. Related Work,[0],[0]
"This means that models learned for active-testing (that say, predict average precision) need not generalize beyond the test set of interest.",2. Related Work,[0],[0]
This suggests that one can be much more aggressive in overfitting to the statistics of the data at hand.,2. Related Work,[0],[0]
"In this section, we introduce the general framework for active testing.",3. Framework for Active Testing,[0],[0]
Figure 1 depicts the overall flow of our approach.,3. Framework for Active Testing,[0],[0]
Our evaluation database initially contains test examples with inaccurate (noisy) annotations.,3. Framework for Active Testing,[0],[0]
"We select a batch of data items whose labels will be manually vetted by an oracle (e.g., in-house annotators or a crowd-sourced platform such as Mechanical Turk).",3. Framework for Active Testing,[0],[0]
Figure 2 shows examples of such noisy labels and queries to Oracle.,3. Framework for Active Testing,[0],[0]
The evaluation database is then updated with these vetted labels to improve estimates of test performance.,3. Framework for Active Testing,[0],[0]
"Active testing consists of two key components: a metric estimator that estimates model performance from test data with a mix of noisy and vetted labels, and a vetting strategy which selects the subset of test data to be labeled in order to achieve the best possible estimate of the true performance.",3. Framework for Active Testing,[0],[0]
We first consider active testing for a simple binary prediction problem and then extend this idea to more complex benchmarking tasks such as multi-label tag prediction and instance segmentation.,3.1. Performance Metric Estimators,[0],[0]
"As a running example, assume that we are evaluating an system that classifies an image (e.g., as containing a cat or not).",3.1. Performance Metric Estimators,[0],[0]
The system returns of confidence score si ∈ R for each test example i ∈ {1 . . .,3.1. Performance Metric Estimators,[0],[0]
N}.,3.1. Performance Metric Estimators,[0],[0]
"Let yi denote a “noisy” binary label for example i (specifying if a cat is present), where the noise could arise from labeling the test set using some weak-but-cheap annotation technique (e.g., user-provided tags, search engine results, or approximate annotations).",3.1. Performance Metric Estimators,[0],[0]
"Finally, let zi be the true latent binary label whose value can be obtained by rigorous human inspection of the test data item.
",3.1. Performance Metric Estimators,[0],[0]
Typical benchmark performance metrics can be written as a function of the true ground-truth labels and system confidences.,3.1. Performance Metric Estimators,[0],[0]
"We focus on metrics that only depend on the rank ordering of the confidence scores and denote such a metric generically as Q({zi}) where for simplicity we hide the dependence on s by assuming that the indices are always
sorted according to si so that s1 ≥ · · · ≥ sN .",3.1. Performance Metric Estimators,[0],[0]
"For example, commonly-used metrics for binary labeling include precision@K and average precision (AP):
Prec@K({z1, . . .",3.1. Performance Metric Estimators,[0],[0]
", zN})",3.1. Performance Metric Estimators,[0],[0]
"= 1
K ∑",3.1. Performance Metric Estimators,[0],[0]
i≤K zi,3.1. Performance Metric Estimators,[0],[0]
"(1)
AP ({z1, . . .",3.1. Performance Metric Estimators,[0],[0]
", zN})",3.1. Performance Metric Estimators,[0],[0]
"= 1
",3.1. Performance Metric Estimators,[0],[0]
Np ∑ k zk k ∑ i≤k zi,3.1. Performance Metric Estimators,[0],[0]
"(2)
whereNp is the number of positives.",3.1. Performance Metric Estimators,[0],[0]
"We include derivations in supplmental material.
",3.1. Performance Metric Estimators,[0],[0]
"Estimation with partially vetted data: In practice, not all the data in our test set will be vetted.",3.1. Performance Metric Estimators,[0],[0]
"Let us divide the test set into two components, the unvetted set U for which we only know the approximate noisy labels yi and the vetted set V , for which we know the ground-truth label.",3.1. Performance Metric Estimators,[0],[0]
"With a slight abuse of notation, we henceforth treat the true label zi as a random variable, and denote its observed realization (on the vetted set) as z̃i.",3.1. Performance Metric Estimators,[0],[0]
"The simplest strategy for estimating the true performance is to ignore unvetted data and only measure performance Q on the vetted subset:
Q({z̃i",3.1. Performance Metric Estimators,[0],[0]
: i ∈ V }),3.1. Performance Metric Estimators,[0],[0]
"[Vetted Only] (3)
",3.1. Performance Metric Estimators,[0],[0]
"This represents the traditional approach to empirical evaluation in which we collect a single, vetted test dataset and ignore other available test data.",3.1. Performance Metric Estimators,[0],[0]
This has the advantage that it is unbiased and converges to the true empirical performance as the whole dataset is vetted.,3.1. Performance Metric Estimators,[0],[0]
"The limitation is that it makes use of only fully-vetted data and the variance in the estimate can be quite large when the vetting budget is limited.
",3.1. Performance Metric Estimators,[0],[0]
A natural alternative is to incorporate the unvetted examples by simply substituting yi as a “best guess” of the true zi.,3.1. Performance Metric Estimators,[0],[0]
"We specify this naive assumption in terms of a distribution over all labels z = {z1, . . .",3.1. Performance Metric Estimators,[0],[0]
", zN}:
pnaive(z) = ∏ i∈U δ(zi = yi) ∏",3.1. Performance Metric Estimators,[0],[0]
"i∈V δ(zi = z̃i) (4)
where z̃i is the label assigned during vetting.",3.1. Performance Metric Estimators,[0],[0]
"Under this assumption we can then compute an expected benchmark performance:
Epnaive(z)
",3.1. Performance Metric Estimators,[0],[0]
[ Q(z) ],3.1. Performance Metric Estimators,[0],[0]
"[Naive Estimator] (5)
which amounts to simply substituting z̃i for vetted examples and yi for unvetted examples.
Unfortunately, the above performance estimate may be greatly affected by noise in the nosiy labels yi.",3.1. Performance Metric Estimators,[0],[0]
"For example, if there are systematic biases in the yi, the performance estimate will similarly be biased.",3.1. Performance Metric Estimators,[0],[0]
"We also consider more general scenarios where side information such as features
Algorithm 1 Active Testing Algorithm Input: unvetted set U , vetted set V , total budget T , vetting strategy V S, system scores S = {si}, estimator pest(z) while T ≥ 0 do
of the test items and distribution of scores of the classifier under test may also be informative.",3.1. Performance Metric Estimators,[0],[0]
"We thus propose computing the expected performance under a more sophisticated estimator:
pest(z) = ∏ i∈U p(zi|O) ∏ i∈V δ(zi = z̃i)",3.1. Performance Metric Estimators,[0],[0]
"(6)
where O is the total set of all observations available to the benchmark system (e.g. noisy labels, vetted labels, classifier scores, data features).",3.1. Performance Metric Estimators,[0],[0]
"We make the plausible assumption that the distribution of unvetted labels factors conditioned on O.
Our proposed active testing framework (see Alg 1) estimates this distribution pest(z) based on available observations and predicts expected benchmark performance under this distribution:
Epest(z)
",3.1. Performance Metric Estimators,[0],[0]
[ Q(z) ],3.1. Performance Metric Estimators,[0],[0]
"[Learned Estimator] (7)
",3.1. Performance Metric Estimators,[0],[0]
Computing expected performance:,3.1. Performance Metric Estimators,[0],[0]
"Given posterior estimates p(zi|O) we can always compute the expected performance metric Q by generating samples from these distributions, computing the metric for each joint sample, and average over samples.",3.1. Performance Metric Estimators,[0],[0]
"Here we introduce two applications (studied in our experiments) where the metric is linear or quadratic in z, allowing us to compute the expected performance in closed-form.
",3.1. Performance Metric Estimators,[0],[0]
Multi-label Tags: Multi-label tag prediction is a common task in video/image retrieval.,3.1. Performance Metric Estimators,[0],[0]
"Following recent work (Joulin et al., 2016; Gong et al., 2013; Izadinia et al., 2015; Guillaumin et al., 2009), we measure accuracy with Precision@K - e.g., what fraction of the topK search results contain the tag of interest?",3.1. Performance Metric Estimators,[0],[0]
"In this setting, noisy labels yi come from user provided tags which may contain errors and are typically incomplete.",3.1. Performance Metric Estimators,[0],[0]
"Conveniently, we can write expected performance Eq. 7 for Precision@K for a single tag in closed form:
E[Prec@K] = 1
K ( ∑ i∈VK z̃i + ∑ i∈UK p(zi = 1|O) ) (8)
where we write VK and UK to denote the vetted and unvetted subsets of K highest-scoring examples in the total set V ∪ U .",3.1. Performance Metric Estimators,[0],[0]
"Some benchmarks compute an aggregate mean precision over all tags under consideration, but since this average is linear, one again obtains a closed form estimate.
",3.1. Performance Metric Estimators,[0],[0]
Instance segmentation:,3.1. Performance Metric Estimators,[0],[0]
Instance segmentation is another natural task for which to apply active testing.,3.1. Performance Metric Estimators,[0],[0]
"It is well known that human annotation is prohibitively expensive – (Cordts et al., 2016) reports that an average of more than 1.5 hours is required to annotate a single image.",3.1. Performance Metric Estimators,[0],[0]
"Widely used benchmarks such as (Cordts et al., 2016) release small fraction of images annotated with high quality, along with a larger set of noisy or “coarse”-quality annotations.",3.1. Performance Metric Estimators,[0],[0]
"Other instance segmentation datasets such as COCO (Lin et al., 2014) are constructed stage-wise by first creating a detection dataset which only indicates rectangular bounding boxes around each object which are subsequently refined into a precise instance segmentations.",3.1. Performance Metric Estimators,[0],[0]
"Fig. 3 shows an example of a partially vetted image in which some instances are only indicated by a bounding box (noisy), while others have a detailed mask (vetted).
",3.1. Performance Metric Estimators,[0],[0]
"When computing Average Precision, a predicted instance segmentation is considered a true positive if it has sufficient intersection-over-union (IoU) overlap with a ground-truth instance.",3.1. Performance Metric Estimators,[0],[0]
"In this setting, we let the variable zi indicate that predicted instance i is matched to a ground-truth instance and has an above threshold overlap.",3.1. Performance Metric Estimators,[0],[0]
"Assuming independence of zi’s, the expected AP can be written as (see supplement for proof):
E[AP ] = 1
Np (∑ k∈V z̃kE[Prec@k]
+ ∑ k∈U p(zk = 1|O)E[Prec@k] )
(9)
",3.1. Performance Metric Estimators,[0],[0]
"In practice, standard instance segmentation benchmarks are somewhat more complicated.",3.1. Performance Metric Estimators,[0],[0]
"In particular, they enforce one-to-one matching between detections and ground-truth.",3.1. Performance Metric Estimators,[0],[0]
"For example, if two detections overlap a ground-truth instance, only one is counted as a true positive while the other
is scored as a false positive.",3.1. Performance Metric Estimators,[0],[0]
"This also holds for multi-class detections - if a detection is labeled as a dog (by matching to a ground-truth dog), it can no longer be labeled as cat.",3.1. Performance Metric Estimators,[0],[0]
"While this interdependence can in principle be modeled by the conditioning variables O which could include information about which class detections overlap, in practice our estimators for p(zi = 1|O) do not take this into account.",3.1. Performance Metric Estimators,[0],[0]
"Nevertheless, we show that such estimators provide remarkably good estimates of performance.
",3.1. Performance Metric Estimators,[0],[0]
Fitting estimators to partially vetted data: We alternate between vetting small batches of data and refitting the estimator to the vetted set.,3.1. Performance Metric Estimators,[0],[0]
"For multi-label tagging, we update estimates for the prior probability that a noisy tag for a particular category will be flipped when vetted p(z̃i 6= yi).",3.1. Performance Metric Estimators,[0],[0]
"For instance segmentation, we train a per-category classifier that uses sizes of the predicted and unvetted ground-truth bounding box to predict whether a detected instance will overlap the ground-truth.",3.1. Performance Metric Estimators,[0],[0]
We discuss the specifics of fitting these particular estimators in the experimental results.,3.1. Performance Metric Estimators,[0],[0]
The second component of the active testing system is a strategy for choosing the “next” data samples to vet.,3.2. Vetting Strategies,[0],[0]
The goal of such a strategy is to produce accurate estimates of benchmark performance with fewest number of vettings.,3.2. Vetting Strategies,[0],[0]
"An alternate, but closely related goal, is to determine the benchmark rankings of a set of recognition systems being compared.",3.2. Vetting Strategies,[0],[0]
"The success of a given strategy depends on the distribution of the data, the chosen estimator, and the system(s) under test.",3.2. Vetting Strategies,[0],[0]
"We consider several selection strategies, motivated by existing data collection practice and modeled after active learning, which adapt to these statistics in order to improve efficiency.
",3.2. Vetting Strategies,[0],[0]
Random Sampling:,3.2. Vetting Strategies,[0],[0]
The simplest vetting strategy is to choose test examples to vet at random.,3.2. Vetting Strategies,[0],[0]
The distribution of examples across categories often follows a long-tail distribution.,3.2. Vetting Strategies,[0],[0]
"To achieve faster uniform convergence of performance
estimates across all categories, we use a hierarchical sampling approach in which we first sample a category and then select a sub-batch of test examples to vet from that category.",3.2. Vetting Strategies,[0],[0]
"This mirrors the way, e.g. image classification and detection datasets are manually curated to assure a minimum number of examples per category.
",3.2. Vetting Strategies,[0],[0]
Most-Confident Mistake (MCM):,3.2. Vetting Strategies,[0],[0]
"This strategy selects unvetted examples for which the system under test reports a high-confidence detection/classification score, but which are considered a mistake according to the current metric estimator.",3.2. Vetting Strategies,[0],[0]
"Specifically, we focus on the strategy of selecting Most-confident Negative which is applicable to image/video tagging where the set of user-provided tags are often incomplete.",3.2. Vetting Strategies,[0],[0]
"The intuition is that, if a high-performance system believes that the current sample is a positive with high probability, it’s likely that the noisy label is at fault.",3.2. Vetting Strategies,[0],[0]
"This strategy is motivated by experience with object detection benchmarks where, e.g., visualizing high-confident false positive face detections often reveals missing annotations in the test set (Mathias et al., 2014).
",3.2. Vetting Strategies,[0],[0]
Maximum Expected Estimator Change (MEEC):,3.2. Vetting Strategies,[0],[0]
"In addition to utilizing the confidence scores produced by the system under test, it is natural to also consider the uncertainty in the learned estimator pest(z).",3.2. Vetting Strategies,[0],[0]
"Exploiting the analogy of active testing with active learning, it is natural to vet samples that are most confusing to the current estimator (e.g., with largest entropy), or ones that will likely generate a large update to the estimator (e.g., largest information gain).
",3.2. Vetting Strategies,[0],[0]
"Specifically, we explore a active selection strategy based on maximum expected model change (Settles, 2010), which in our case corresponds to selecting a sample that yields the largest expected change in our estimate of Q. Let Ep(z|V )",3.2. Vetting Strategies,[0],[0]
[Q(z)] be the expected performance based on the distribution p(z|V ) estimated from the current vetted set V .,3.2. Vetting Strategies,[0],[0]
"Ep(z|V,zi)[Q(z)] be the expected performance after vetting example i and updating the estimator based on the outcome.",3.2. Vetting Strategies,[0],[0]
"The actual change in the estimate of Q depends on the
realization of the random variable zi:
∆i(zi) =",3.2. Vetting Strategies,[0],[0]
"∣∣∣Ep(z|V,zi)[Q(z)]− Ep(z|V )",3.2. Vetting Strategies,[0],[0]
"[Q(z)]∣∣∣ (10)
We can choose the example i with the largest expected change, using the current estimate of the distribution over zi ∼ p(zi|V ) to compute the expected change Ep(zi|V )",3.2. Vetting Strategies,[0],[0]
"[∆i(zi)].
",3.2. Vetting Strategies,[0],[0]
"For Prec@K, this expected change is given by:
Ep(zi|V )",3.2. Vetting Strategies,[0],[0]
[∆i(zi)],3.2. Vetting Strategies,[0],[0]
"= 2
K pi(1− pi) (11)
where we write pi = p(zi = 1|O).",3.2. Vetting Strategies,[0],[0]
"Interestingly, selecting the sample yielded the maximum expected change in the estimator corresponds to a standard maximum entropy selection criteria for active learning.",3.2. Vetting Strategies,[0],[0]
"Similarly, in the supplement we show that for AP :
Ep(zi|V )",3.2. Vetting Strategies,[0],[0]
"[∆i(zi)] = 1
Np ripi(1− pi) (12)
where ri is the proportion of unvetted examples scoring higher than example i.",3.2. Vetting Strategies,[0],[0]
"In this case, we select an example to vet which has high-entropy and for which there is a relatively small proportion of higher-scoring unvetted examples.",3.2. Vetting Strategies,[0],[0]
"We validate our active testing framework on two specific applications, multi-label classification and instance segmentation.",4. Experiments,[0],[0]
"For each of these applications, we describe the datasets and systems evaluated and the specifics of the estimators and vetting strategies used.",4. Experiments,[0],[0]
NUS-WIDE:,4.1. Active Testing for Multi-label Classification,[0],[0]
"This dataset contains 269,648 Flickr images with 5018 unique tags.",4.1. Active Testing for Multi-label Classification,[0],[0]
"The authors also provide a ’semi-
complete’ ground-truth via manual annotations for 81 concepts.",4.1. Active Testing for Multi-label Classification,[0],[0]
We removed images that are no longer available and images that doesn’t contain one of the 81 tags.,4.1. Active Testing for Multi-label Classification,[0],[0]
We are left with around 100K images spanning across 81 concepts.,4.1. Active Testing for Multi-label Classification,[0],[0]
"(Izadinia et al., 2015) analyzed the noisy and missing label statistics for this dataset.",4.1. Active Testing for Multi-label Classification,[0],[0]
"Given that the tag is relevant to the image, there is only 38% chance that it will appear in the noisy tag list.",4.1. Active Testing for Multi-label Classification,[0],[0]
"If the tag does not apply, there’s 1% chance that it appears anyway.",4.1. Active Testing for Multi-label Classification,[0],[0]
"They posited that the missing tags are either non-entry level categories (e.g., person) or they are not important in the scene (e.g., clouds and buildings).
",4.1. Active Testing for Multi-label Classification,[0],[0]
"Micro-videos: Micro-videos have recently become a prevalent form of media on many social platforms, such as Vine, Instagram, and Snapchat.",4.1. Active Testing for Multi-label Classification,[0],[0]
"(Nguyen et al., 2016) formulated a multi-label video-retrieval/annotation task for a large collection of Vine videos.",4.1. Active Testing for Multi-label Classification,[0],[0]
"They introduce a micro-video dataset, MV-85k containing 260K videos with 58K tags.",4.1. Active Testing for Multi-label Classification,[0],[0]
"This dataset, however, only provides exhaustive vetting for a small subset of tags on a small subset of videos.",4.1. Active Testing for Multi-label Classification,[0],[0]
"We vetted 26K video-tag pairs from this dataset, spanning 17503 videos and 875 tags.",4.1. Active Testing for Multi-label Classification,[0],[0]
"Since tags provided by users have little constraints, this dataset suffers from both under-tagging and over-tagging.",4.1. Active Testing for Multi-label Classification,[0],[0]
"Under-tagging comes from not-yet popular concepts, while over-tagging comes from the spamming of extra tags In our experiments we use a subset of 75 tags.
",4.1. Active Testing for Multi-label Classification,[0],[0]
"Recognition systems: To obtain the classification results, we implement two multi-label classification algorithms for images (NUSWIDE) and videos (Microvideos).",4.1. Active Testing for Multi-label Classification,[0],[0]
"For NUSWIDE, we trained a multi-label logistic regression model built on the pretrained ResNet-50",4.1. Active Testing for Multi-label Classification,[0],[0]
"(He et al., 2016) features.",4.1. Active Testing for Multi-label Classification,[0],[0]
"For Micro-videos, we follow the state-of-the-art video action recognition framework (Wang et al., 2016) modified for the multi-label setting to use multiple logistic cross-entropy losses.
",4.1. Active Testing for Multi-label Classification,[0],[0]
Learned Estimators: We use Precision@48 as a evaluation metric.,4.1. Active Testing for Multi-label Classification,[0],[0]
"For tagging, we estimate the posterior over unvetted tags, p(zi|O), based on two pieces of observed information: the statistics of noisy labels yi on vetted examples, and the system confidence score, si.",4.1. Active Testing for Multi-label Classification,[0],[0]
"This posterior probability can be derived as (see supplement for proof):
p(zi|si, yi) = p(yi|zi)p(zi|si)∑
v∈{0,1} p(yi|zi = v)p(zi = v|si) (13)
",4.1. Active Testing for Multi-label Classification,[0],[0]
"Given some vetted data, we fit the tag-flipping priors p(yi|zi) by standard maximum likelihood estimation (counting frequencies).",4.1. Active Testing for Multi-label Classification,[0],[0]
"The posterior probabilities of the true label given the classifier confidence score, p(zi|si), is fit using logistic regression.",4.1. Active Testing for Multi-label Classification,[0],[0]
COCO Minival:,4.2. Object Instance Detection and Segmentation,[0],[0]
"For instance segmentation, we use ‘minival2014’ subset of the COCO dataset (Lin et al., 2014).",4.2. Object Instance Detection and Segmentation,[0],[0]
This subset contains 5k images spanning over 80 categories.,4.2. Object Instance Detection and Segmentation,[0],[0]
"We report the standard COCO metric: Average Precision (averaged over all IoU thresholds).
",4.2. Object Instance Detection and Segmentation,[0],[0]
"To systematically analyze the impact of evaluation on noise and vetting, we focus evaluation efforts on the high quality test set, but simulate noisy annotations by replacing actual instance segmentation masks by their tight-fitting bounding box (the unvetted “noisy” set).",4.2. Object Instance Detection and Segmentation,[0],[0]
"We then simulate active testing where certain instances are vetted, meaning the bounding-box is replaced by the true segmentation mask.
",4.2. Object Instance Detection and Segmentation,[0],[0]
"Detection Systems: We did not implement instance segmentation algorithms ourselves, but instead utilized three sets of detection mask results produced by the authors of Mask R-CNN (He et al., 2017).",4.2. Object Instance Detection and Segmentation,[0],[0]
"These were produced by variants of the instance segmentation systems proposed in (Xie et al., 2017; Lin et al., 2017; He et al., 2017).
",4.2. Object Instance Detection and Segmentation,[0],[0]
"Learned Estimators: To compute the probability whether a detection will pass the IoU threshold with a bounding box unvetted ground-truth instance (p(zi|O) in Eq. 9), we train a χ2-SVM using the vetted portion of the database.",4.2. Object Instance Detection and Segmentation,[0],[0]
"The features for an example includes the category id, the ‘noisy’ IoU estimate, the size of the bounding box containing the detection mask and the size of ground-truth bounding box.",4.2. Object Instance Detection and Segmentation,[0],[0]
"The training label is true whether the true IoU estimate, computed using the vetted ground-truth mask and the detection masks, is above a certain input IoU threshold.",4.2. Object Instance Detection and Segmentation,[0],[0]
We measure the estimation accuracy of different combination of vetting strategies and estimators at different amount of vetting efforts.,4.3. Efficiency of active testing estimates,[0],[0]
We compute the absolute error between the estimated metric and the true (fully vetted) metric and average over all classes.,4.3. Efficiency of active testing estimates,[0],[0]
"Averaging the absolute estimation error across classes prevents over-estimation for one class
canceling out under-estimation from another class.",4.3. Efficiency of active testing estimates,[0],[0]
"We plot the mean and the standard deviation over 50 simulation runs of each active testing approach.
",4.3. Efficiency of active testing estimates,[0],[0]
Performance estimation: Figure 5 shows the results for estimating Prec@48 for NUSWIDE and Microvideos.,4.3. Efficiency of active testing estimates,[0],[0]
The x-axis indicates the percentage of the top-k lists that are vetted.,4.3. Efficiency of active testing estimates,[0],[0]
"For the Prec@K metric, it is only necessary to vet 100% of the top-k lists rather than 100% of the whole test set2.",4.3. Efficiency of active testing estimates,[0],[0]
"A ’random’ strategy with a ‘naive’ estimator follows a
2The “vetted only” estimator is not applicable in this domain until at least K examples in each short list have been vetted and hence doesn’t appear in the plots.
linear trend since each batch of vetted examples contributes on average the same reduction in estimation error.",4.3. Efficiency of active testing estimates,[0],[0]
The most confident mistake (mcm) heuristic works very well for Microvideos due to the substantial amount of undertagging.,4.3. Efficiency of active testing estimates,[0],[0]
"However, in more reasonable balanced settings such as NUS-WIDE, this heuristic does not perform as well.",4.3. Efficiency of active testing estimates,[0],[0]
The MCM vetting strategy does not pair well with a learned estimator due to its biased sampling which quickly results in priors that overestimate the number missing tags.,4.3. Efficiency of active testing estimates,[0],[0]
"In contrast, the random and active MEEC vetting strategies offer good samples for learning a good estimator.",4.3. Efficiency of active testing estimates,[0],[0]
"At 50% vetting effort, MEEC sampling with a learned estimator on average can achieve within 2-3% of the real estimates.
",4.3. Efficiency of active testing estimates,[0],[0]
Figure 6 highlights the relative value of establishing the true vetted label versus the value of vetted data in updating the estimator.,4.3. Efficiency of active testing estimates,[0],[0]
"In some sense, traditional active learning is concerned primarily with the vertical drop (i.e. a better model/estimator), while active testing also takes direct advantage of the slope (i.e. more vetted labels).",4.3. Efficiency of active testing estimates,[0],[0]
"The initial learned estimates have larger error due to small sample size, but the fitting during the first few vetting batches rapidly improves the estimator quality.",4.3. Efficiency of active testing estimates,[0],[0]
"Past 40% vetting effort, the estimator model parameters stabilize and remaining vetting serves to correct labels whose true value can’t be predicted given the low-complexity of the estimator.
",4.3. Efficiency of active testing estimates,[0],[0]
Figure 7 shows similar results for estimating the mAP for instance segmentation on COCO.,4.3. Efficiency of active testing estimates,[0],[0]
The current ‘gold standard’ approach of estimating performance based only on the vetted subset of images leads to large errors in estimation accuracy and high variance from from small sample sizes.,4.3. Efficiency of active testing estimates,[0],[0]
"In the active testing framework, input algorithms are tested using the whole dataset (vetted and unvetted).",4.3. Efficiency of active testing estimates,[0],[0]
"Naive estimation is noticeably more accurate than vetted only and the learned estimator with uncertainty sampling further reduces
both the absolute error and the variance.
",4.3. Efficiency of active testing estimates,[0],[0]
Model ranking: The benefits of active testing are highlighted further when we consider the problem of ranking system performance.,4.3. Efficiency of active testing estimates,[0],[0]
"We are often interested not in the absolute performance number, but rather in the performance gap between different systems.",4.3. Efficiency of active testing estimates,[0],[0]
We find that active testing is also valuable in this setting.,4.3. Efficiency of active testing estimates,[0],[0]
Figure 8 shows the error in estimating the performance gap between two different instance segmentation systems as a function of the amount data vetted.,4.3. Efficiency of active testing estimates,[0],[0]
This follows a similar trend as the single model performance estimation plot.,4.3. Efficiency of active testing estimates,[0],[0]
"Importantly, it highlights that only evaluating vetted data, though unbiased, typically produces a large error in in performance gap between models to high variance in the estimate of each individual models performance.",4.3. Efficiency of active testing estimates,[0],[0]
"In particular, if we use these estimates to rank two models, we will often make errors in model ranking even when relatively large amounts of the data have been vetted.",4.3. Efficiency of active testing estimates,[0],[0]
"Using stronger estimators, actively guided by MEEC sampling provide accurate rankings with substantially less vetting effort.",4.3. Efficiency of active testing estimates,[0],[0]
"With 50% of the data vetted, standard approaches that evaluate on only vetted data (black curve) incorrectly rank algorithms 15% of the time, while our learned estimators with active vetting (red curve) reduce this error to 3% of the time.
",4.3. Efficiency of active testing estimates,[0],[0]
Conclusions We have introduced a general framework for active testing that minimizes human vetting effort by actively selecting test examples to label and using performance estimators that adapt to the statistics of the test data and the systems under test.,4.3. Efficiency of active testing estimates,[0],[0]
Simple implementations of this concept demonstrate the potential for radically decreasing the human labeling effort needed to evaluate system performance for standard computer vision tasks.,4.3. Efficiency of active testing estimates,[0],[0]
"We anticipate this will have substantial practical value in the ongoing construction of such benchmarks.
",4.3. Efficiency of active testing estimates,[0],[0]
Acknowledgement We thank Piotr Dollar and Ross Girshick for providing the instance segmentation results for the COCO dataset.,4.3. Efficiency of active testing estimates,[0],[0]
This project was supported in part by NSF grants IIS-1618806 and IIS-1253538.,4.3. Efficiency of active testing estimates,[0],[0]
"Much recent work on visual recognition aims to scale up learning to massive, noisily-annotated datasets.",abstractText,[0],[0]
We address the problem of scalingup the evaluation of such models to large-scale datasets with noisy labels.,abstractText,[0],[0]
"Current protocols for doing so require a human user to either vet (reannotate) a small fraction of the test set and ignore the rest, or else correct errors in annotation as they are found through manual inspection of results.",abstractText,[0],[0]
"In this work, we re-formulate the problem as one of active testing, and examine strategies for efficiently querying a user so as to obtain an accurate performance estimate with minimal vetting.",abstractText,[0],[0]
"We demonstrate the effectiveness of our proposed active testing framework on estimating two performance metrics, Precision@K and mean Average Precision, for two popular computer vision tasks, multi-label classification and instance segmentation.",abstractText,[0],[0]
We further show that our approach is able to save significant human annotation effort and is more robust than alternative evaluation protocols.,abstractText,[0],[0]
Active Testing: An Efficient and Robust Framework for Estimating Accuracy,title,[0],[0]
Many natural language processing tasks require document creation time (DCT) information as a useful additional metadata.,1 Introduction,[0],[0]
"Tasks such as information retrieval (Li and Croft, 2003; Dakka et al., 2008), temporal scoping of events and facts (Allan et al., 1998; Talukdar et al., 2012b), document summarization (Wan, 2007) and analysis (de Jong et al., 2005a) require precise and validated creation time of the documents.",1 Introduction,[0],[0]
"Most of the documents obtained from the Web either contain DCT that cannot be trusted or contain no DCT information at all (Kanhabua and Nørvåg, 2008).",1 Introduction,[0],[0]
"Thus, predicting the time of these documents based on their content is an important task, often referred to as Document Dating.
",1 Introduction,[0],[0]
"A few generative approaches (de Jong et al., 2005b; Kanhabua and Nørvåg, 2008) as well as a discriminative model (Chambers, 2012) have been previously proposed for this task.",1 Introduction,[0],[0]
"Kotsakos et al. (2014) employs term-burstiness resulting in improved precision on this task.
",1 Introduction,[0],[0]
"Recently proposed NeuralDater (Vashishth et al., 2018) uses a graph convolution network (GCN) based approach for document dating, outperforming all previous models by a significant margin.",1 Introduction,[0],[0]
NeuralDater extensively uses the syntactic and temporal graph structure present within the document itself.,1 Introduction,[0],[0]
"Motivated by NeuralDater, we explicitly develop two different methods: a) Attentive Context Model, and b) Ordered Event Model.",1 Introduction,[0],[0]
"The first component tries to accumulate knowledge across documents, whereas the latter uses the temporal structure of the document for predicting its DCT.
",1 Introduction,[0],[0]
"Motivated by the effectiveness of attention based models in different NLP tasks (Yang et al., 2016a; Bahdanau et al., 2014), we incorporate attention in our method in a principled fashion.",1 Introduction,[0],[0]
"We use attention not only to capture context but also for feature aggregation in the graph convolution network (Hamilton et al., 2017).",1 Introduction,[0],[0]
"Our contributions are as follows.
",1 Introduction,[0],[0]
"• We propose Attentive Deep Document Dater (AD3), the first attention-based neural model for time-stamping documents.
",1 Introduction,[0],[0]
"• We devise a novel method for label based attentive graph convolution over directed graphs and use it for the document dating task.
",1 Introduction,[0],[0]
"• Through extensive experiments on multiple real-world datasets, we demonstrate AD3’s effectiveness over previously proposed methods.
",1 Introduction,[0],[0]
AD3 source code and datasets used in the paper are available at https://github.com/malllabiisc/AD3,1 Introduction,[0],[0]
"Document Time-Stamping: Initial attempts
ar X
iv :1
90 2.
02 16
1v 1
[ cs
.C",2 Related Work,[0],[0]
"L
] 2
1 Ja
n 20
19
made for document time-stamping task include statistical language models proposed by de Jong et al. (2005b) and Kanhabua and Nørvåg (2008).",2 Related Work,[0],[0]
"(Chambers, 2012) use temporal and hand-crafted features extracted from documents to predict DCT.",2 Related Work,[0],[0]
"They propose two models, one of which learns the probabilistic constraints between year mentions and the actual creation time, whereas the other one is a discriminative model trained on hand-crafted features.",2 Related Work,[0],[0]
"Kotsakos et al. (2014) propose a termburstiness (Lappas et al., 2009)",2 Related Work,[0],[0]
based statistical method for the task.,2 Related Work,[0],[0]
"Vashishth et al. (2018) propose a deep learning based model which exploits the temporal and syntactic structure in documents using graph convolutional networks (GCN).
",2 Related Work,[0],[0]
"Event Ordering System: The task of extracting temporally rich events and time expressions and ordering between them is introduced in the TempEval challenge (UzZaman et al., 2013; Verhagen et al., 2010).",2 Related Work,[0],[0]
"Various approaches (McDowell et al., 2017; Mirza and Tonelli, 2016) made for solving the task use sieve-based archi-
tectures, where multiple classifiers are ranked according to their precision and their predictions are weighted accordingly resulting in a temporal graph structure.",2 Related Work,[0],[0]
"A method to extract temporal ordering among relational facts was proposed in (Talukdar et al., 2012a).
",2 Related Work,[0],[0]
"Graph Convolutional Network (GCN): GCN (Kipf and Welling, 2016) is the extension of convolutional networks over graphs.",2 Related Work,[0],[0]
"In different NLP tasks such as semantic-role labeling (Marcheggiani and Titov, 2017), neural machine translation (Bastings et al., 2017), and event detection (Nguyen and Grishman, 2018), GCNs have proved to be effective.",2 Related Work,[0],[0]
"We extensively use GCN for capturing both syntactic and temporal aspect of the document.
",2 Related Work,[0],[0]
"Attention Network: Attention networks have been well exploited for various tasks such as document classification (Yang et al., 2016b), question answering (Yang et al., 2016a), machine translation (Bahdanau et al., 2014; Vaswani et al., 2017).",2 Related Work,[0],[0]
"Recently, attention over graph structure has been
shown to work well by Veličković et al. (2018).",2 Related Work,[0],[0]
"Taking motivation from them, we deploy an attentive convolutional network on temporal graph for the document dating problem.",2 Related Work,[0],[0]
The task of document dating can be modeled as a multi-class classification problem.,3 Background: GCN & NeuralDater,[0],[0]
"Following prior work, we shall focus on DCT prediction at the year-granularity in this paper.",3 Background: GCN & NeuralDater,[0],[0]
"In this section, we summarize the previous state-of-the-art model NeuralDater (Vashishth et al., 2018), before moving onto our method.",3 Background: GCN & NeuralDater,[0],[0]
"An overview of graph convolutional network (GCN) (Kipf and Welling, 2016) is also necessary as it is used in NeuralDater as well as in our model.",3 Background: GCN & NeuralDater,[0],[0]
"GCN for Undirected Graph: Consider an undirected graph, G = (V, E), where V and E are the set of n vertices and set of edges respectively.",3.1 Graph Convolutional Network,[0],[0]
"Matrix X ∈ Rn×m, whose rows are input representation of node u, where xu ∈ Rm, ∀ u ∈ V , is the input feature matrix.",3.1 Graph Convolutional Network,[0],[0]
The output hidden representation hv ∈,3.1 Graph Convolutional Network,[0],[0]
"Rd of a node v after a single layer of graph convolution operation can be obtained by considering only the immediate neighbours of v, as formulated in (Kipf and Welling, 2016).",3.1 Graph Convolutional Network,[0],[0]
"In order to capture information at multi-hop distance, one can stack layers of GCN, one over another.",3.1 Graph Convolutional Network,[0],[0]
"GCN for Directed Graph: Consider a labelled edge from node u to v with label l(u, v), denoted collectively as (u, v, l(u, v)).",3.1 Graph Convolutional Network,[0],[0]
"Based on the assumption that information in a directed edge need not only propagate along its direction, Marcheggiani and Titov (2017) added opposite edges viz., for each (u, v, l(u, v)), (v, u, l(u, v)−1) is added to the edge list.",3.1 Graph Convolutional Network,[0],[0]
Self loops are also added for passing the current embedding information.,3.1 Graph Convolutional Network,[0],[0]
"When GCN is applied over this modified directed graph, the embedding of the node v after kth layer will be,
hk+1v = f  ∑ u∈N (v) ( W kl(u,v)h k u + b",3.1 Graph Convolutional Network,[0],[0]
"k l(u,v) ) .",3.1 Graph Convolutional Network,[0],[0]
"We note that the parameters W kl(u,v) and b k l(u,v) in this case are edge label specific.",3.1 Graph Convolutional Network,[0],[0]
hku is the input to the kth layer.,3.1 Graph Convolutional Network,[0],[0]
"Here, N (v) refers to the set of neighbours of v, according to the updated edge list and f is any non-linear activation function (e.g., ReLU: f(x) = max(0, x)).",3.1 Graph Convolutional Network,[0],[0]
"In this sub-section, we provide a brief overview of the components of the NeuralDater (Vashishth et al., 2018).",3.2 NeuralDater,[0],[0]
"Given a document D with n tokens w1, w2, · · ·wn, NeuralDater extracts a temporally rich embedding of the document in a principled way as explained below:",3.2 NeuralDater,[0],[0]
Bi-directional LSTM is employed for embedding each word with its context.,3.2.1 Context Embedding,[0],[0]
The GloVe representation of the words X ∈ Rn×k is transformed to a context aware representationHcntx ∈,3.2.1 Context Embedding,[0],[0]
Rn×k to get the context embedding.,3.2.1 Context Embedding,[0],[0]
This is essentially shown as the Bi-LSTM in Figure 1.,3.2.1 Context Embedding,[0],[0]
"In this step, the context embeddings are further processed using GCN over the dependency parse tree of the sentences in the document, in order to capture long range connection among words.",3.2.2 Syntactic Embedding,[0],[0]
"The syntactic dependency structure is extracted by Stanford CoreNLP’s dependency parser (Manning et al., 2014).",3.2.2 Syntactic Embedding,[0],[0]
"NeuralDater follows the same formulation of GCN for directed graph as described in Section 3.1, where additional edges are added to the graph to model the information flow.",3.2.2 Syntactic Embedding,[0],[0]
"Again following (Marcheggiani and Titov, 2017), NeuralDater does not allocate separate weight matrices for different types of dependency edge labels, rather it considers only three type of edges: a) edges that exist originally, b) the reverse edges that are added explicitly, and c) self loops.",3.2.2 Syntactic Embedding,[0],[0]
"The S-GCN portion of Figure 1 represents this component.
",3.2.2 Syntactic Embedding,[0],[0]
"More formally, Hcntx ∈",3.2.2 Syntactic Embedding,[0],[0]
Rn×k is transformed to Hsyn ∈ Rn×ksyn by applying S-GCN.,3.2.2 Syntactic Embedding,[0],[0]
"In this layer, NeuralDater exploits the Event-Time graph structure present in the document.",3.2.3 Temporal Embedding,[0],[0]
"CATENA (Mirza and Tonelli, 2016), current state-of-the-art temporal and causal relation extraction algorithm, produces the temporal graph from the event time annotation of the document.",3.2.3 Temporal Embedding,[0],[0]
"GCN applied over this Event-Time graph, namely T-GCN, chooses nT number of tokens out of total n tokens from the document for further revision in their embeddings.",3.2.3 Temporal Embedding,[0],[0]
Note that T is the total number of events and time mentions present in the document.,3.2.3 Temporal Embedding,[0],[0]
A special node DCT is added to the graph and its embedding is jointly learned.,3.2.3 Temporal Embedding,[0],[0]
Note that this layer learns both label and direction specific parameters.,3.2.3 Temporal Embedding,[0],[0]
"Finally, the DCT embedding concatenated with the average pooled syntactic embedding is fed to a softmax layer for classification.",3.2.4 Classifier,[0],[0]
This whole procedure is trained jointly.,3.2.4 Classifier,[0],[0]
"In this section, we describe Attentive Deep Document Dater (AD3), our proposed method.",4 Attentive Deep Document Dater (AD3): Proposed Method,[0],[0]
"AD3 is inspired by NeuralDater, and shares many of its components.",4 Attentive Deep Document Dater (AD3): Proposed Method,[0],[0]
"Just like in NeuralDater, AD3 also leverages two main types of signals from the document – syntactic and event-time – to predict the document’s timestamp.",4 Attentive Deep Document Dater (AD3): Proposed Method,[0],[0]
"However, there are crucial differences between the two systems.",4 Attentive Deep Document Dater (AD3): Proposed Method,[0],[0]
"Firstly, instead of concatenating embeddings learned from these two sources as in NeuralDater, AD3 treats these two models completely separate and combines them at a later stage.",4 Attentive Deep Document Dater (AD3): Proposed Method,[0],[0]
"Secondly, unlike NeuralDater, AD3 employs attention mechanisms in each of these two models.",4 Attentive Deep Document Dater (AD3): Proposed Method,[0],[0]
We call the resulting models Attentive Context Model (AC-GCN) and Ordered Event Model (OE-GCN).,4 Attentive Deep Document Dater (AD3): Proposed Method,[0],[0]
"These two models are described in Section 4.1 and Section 4.2, respectively.",4 Attentive Deep Document Dater (AD3): Proposed Method,[0],[0]
"Recent success of attention-based deep learning models for classification (Yang et al., 2016b), question answering (Yang et al., 2016a), and machine translation (Bahdanau et al., 2014) have motivated us to use attention during document dating.",4.1 Attentive Context Model (AC-GCN),[0],[0]
We extend the syntactic embedding model of NeuralDater (Section 3.2.2) by incorporating an attentive pooling layer.,4.1 Attentive Context Model (AC-GCN),[0],[0]
We call the resulting model ACGCN.,4.1 Attentive Context Model (AC-GCN),[0],[0]
"This model (right side in Figure 1) has two major components.
",4.1 Attentive Context Model (AC-GCN),[0],[0]
"• Context Embedding and Syntactic Embedding: Following NeuralDater, we used Bi-LSTM and S-GCN to capture context and long-range syntactic dependencies in the document (Please refer to Section 3.2.1, Section 3.2.2 for brief description).",4.1 Attentive Context Model (AC-GCN),[0],[0]
"The syntactic embedding, Hsyn ∈ Rn×ksyn is then fed to an Attention Network for further processing.",4.1 Attentive Context Model (AC-GCN),[0],[0]
"Note that, ksyn is the dimension of the output of Syntactic-GCN and n is the number of tokens in the document.
",4.1 Attentive Context Model (AC-GCN),[0],[0]
• Attentive Embedding:,4.1 Attentive Context Model (AC-GCN),[0],[0]
"In this layer, we
learn the representation for the whole document through word level attention network.",4.1 Attentive Context Model (AC-GCN),[0],[0]
"We learn a context vector, us ∈ Rs with respect to which we calculate attention for each token.",4.1 Attentive Context Model (AC-GCN),[0],[0]
"Finally, we aggregate the token features with respect to their attention weights in order to represent the document.",4.1 Attentive Context Model (AC-GCN),[0],[0]
"More formally, let hsynt ∈ Rksyn be the syntactic representation of the tth token in the document.",4.1 Attentive Context Model (AC-GCN),[0],[0]
We take non-linear projection of it in Rs with Ws ∈ Rs×ksyn .,4.1 Attentive Context Model (AC-GCN),[0],[0]
"Attention weight αt for tth token is calculated with respect to the context vector uTt as follows.
",4.1 Attentive Context Model (AC-GCN),[0],[0]
"ut = tanh(Wsh syn t ),
αt =",4.1 Attentive Context Model (AC-GCN),[0],[0]
"exp(uTt us)∑ t exp(u T t us) .
",4.1 Attentive Context Model (AC-GCN),[0],[0]
"Finally, the document representation for the AC-GCN is computed as shown below.
dAC−GCN = ∑ t αth syn t
",4.1 Attentive Context Model (AC-GCN),[0],[0]
"This representation is fed to a softmax layer for the final classification.
",4.1 Attentive Context Model (AC-GCN),[0],[0]
"The final probability distribution over years predicted by the AC-GCN is given below.
PAC−GCN(y|D) =",4.1 Attentive Context Model (AC-GCN),[0],[0]
Softmax(W · dAC−GCN + b).,4.1 Attentive Context Model (AC-GCN),[0],[0]
The OE-GCN model is shown on the left side of Figure 1.,4.2 Ordered Event Model (OE-GCN),[0],[0]
"Just like in AC-GCN, context and syntactic embedding is also part of OE-GCN.",4.2 Ordered Event Model (OE-GCN),[0],[0]
"The syntactic embedding is fed to the Attentive Graph Convolution Network (AT-GCN) where the graph is obtained from the time-event ordering algorithm CATENA (Mirza and Tonelli, 2016).",4.2 Ordered Event Model (OE-GCN),[0],[0]
We describe these components in detail below.,4.2 Ordered Event Model (OE-GCN),[0],[0]
"We use the same process used in NeuralDater (Vashishth et al., 2018) for procuring the Temporal Graph from the document.",4.2.1 Temporal Graph,[0],[0]
"CATENA (Mirza and Tonelli, 2016) generates 9 different temporal links between events and time expressions present in the document.",4.2.1 Temporal Graph,[0],[0]
"Following Vashishth et al. (2018), we choose 5 most frequent ones - AFTER, BEFORE, SIMULTANEOUS, INCLUDES, and IS INCLUDED – as labels.",4.2.1 Temporal Graph,[0],[0]
"The temporal graph
is constructed from the partial ordering between event verbs and time expressions.
",4.2.1 Temporal Graph,[0],[0]
Let ET be the edge list of the Temporal Graph.,4.2.1 Temporal Graph,[0],[0]
"Similar to (Marcheggiani and Titov, 2017; Vashishth et al., 2018), we also add reverse edges for each of the existing edge and self loops for passing current node information as explained in Section 3.1.",4.2.1 Temporal Graph,[0],[0]
"The new edge list E ′T is shown below.
",4.2.1 Temporal Graph,[0],[0]
"E ′T = ET ∪ {(j, i, l(i, j)−1)",4.2.1 Temporal Graph,[0],[0]
"| (i, j, l(i, j)) ∈",4.2.1 Temporal Graph,[0],[0]
"ET} ∪ {(i, i, self)",4.2.1 Temporal Graph,[0],[0]
"| i ∈ V)}.
",4.2.1 Temporal Graph,[0],[0]
"The reverse edges are added with reverse labels like AFTER−1, BEFORE−1 etc .",4.2.1 Temporal Graph,[0],[0]
"Finally, we get 10 labels for our temporal graph and we denote the set of edge labels by L.",4.2.1 Temporal Graph,[0],[0]
"Since the temporal graph is automatically generated, it is likely to have incorrect edges.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"Ideally, we would like to minimize the influence of such noisy edges while computing temporal embedding.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"In order to suppress the noisy edges in the Temporal Graph and detect important edges for reasoning, we use attentive graph convolution (Hamilton et al., 2017) over the Event-Time graph.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
The attention mechanism learns the aggregation function jointly during training.,4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"Here, the main objective is to calculate the attention over the neighbouring nodes with respect to the current node for a given label.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
Then the embedding of the current node is updated by mixing neighbouring node embedding according to their attention scores.,4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"In this respect, we propose a label-specific attentive graph convolution over directed graphs.
",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"Let us consider an edge in the temporal graph from node i to node j with type l, where l ∈ L and L is the label set.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
The label set L can be divided broadly into two coarse labels as done in Section 3.2.2.,4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
The attention weights are specific to only these two type of edges to reduce parameter and prevent overfitting.,4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"For illustration, if there exists an edge from node i to j then the edge types will be,
• L(i, j) =→ if (i, j, l(i, j)) ∈ E ′T , i.e., if the edge is an original event-time edge.
",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"• L(i, j) =← if (i, j, l(i, j)−1) ∈ E ′T , i.e., if the edge is added later.
",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"First, we take a linear projection (W attenL(i,j) ∈ RF×ksyn) of both the nodes in RF in order to map
both of them in the same direction-specific space.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"The concatenated vector [W attenL(i,j) × hi;W atten L(i,j) × hj ], signifies the importance of the node j w.r.t.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"node i. A non linear transformation of this concatenation can be treated as the importance feature vector between i and j.
eij = tanh[W atten L(i,j) × hi;W atten L(i,j) × hj ].
",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"Now, we compute the attention weight of node j for node i with respect to a direction-specific context vector aL(i,",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"j) ∈ R2F , as follows.
",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"α l(i,j) ij =
exp ( aTL(i,j)eij ) ∑
k∈N l(i,·)i
exp ( aTL(i,j)eik ) ,
where, αl(i,j)ij = 0",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"if node i and j is not connected through label l. N l(i,·) denotes the subset of the neighbourhood of node i with label l only.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"Please note that, although the linear transform weight (W attenL(i,j) ∈ R
F×ksyn) is specific to the coarse labels L, but for each finer label l ∈ L we get these convex weights of attentions.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"Figure 2 illustrates the above description w.r.t. edge type BEFORE.
",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"Finally, the feature aggregation is done according to the attention weights.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"Prior to that, another label specific linear transformation is taken to perform the convolution operation.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"Then, the updated feature for node i is calculated as follows.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"hk+1i = f (∑ l∈L ∑
j∈N l(i,·)i α l(i,j) ij
( Wl(i,j)hj + bl(i,j) )) .
",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"where, αii = 1, N l(i,·) denotes the subset of the neighbourhood of node i with label l only.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"Note that, αl(i,j)ij = 0",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"when j /∈ N l(i,·)",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
.,4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"To illustrate formally, from Figure 2, we see that weight α1 and α2 is calculated specific to label type BEFORE and the neighbours which are connected through BEFORE is being multiplied with Wbefore prior to aggregation in the ReLU block.
",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"Now, after applying attentive graph convolution network, we only consider the representation of Document Creation Time (DCT), hDCT , as the document representation itself.",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
hDCT is now passed through a fully connected layer prior to softmax.,4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"Prediction of the OE-GCN for the document D will be given as
POE−GCN(y|D) =",4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
Softmax(W · dDCT + b).,4.2.2 Attentive Graph Convolution (AT-GCN),[0],[0]
"In this section, we propose an unified model by mixing both AC-GCN and OE-GCN.",4.3 AD3: Attentive Deep Document Dater,[0],[0]
"Even on validation data, we see that performance of both the models differ to a large extent.",4.3 AD3: Attentive Deep Document Dater,[0],[0]
This significant difference (McNemar test p < 0.000001) motivated the unification.,4.3 AD3: Attentive Deep Document Dater,[0],[0]
"We take convex combination of the output probabilities of the two models
as shown below.
Pjoint(y|D) = λPAC−GCN(y|D)",4.3 AD3: Attentive Deep Document Dater,[0],[0]
"+ (1− λ)POE−GCN(y|D).
",4.3 AD3: Attentive Deep Document Dater,[0],[0]
The combination hyper-parameter λ is tuned on the validation data.,4.3 AD3: Attentive Deep Document Dater,[0],[0]
"We obtain the value of λ to be 0.52 (Figure 3) and 0.54 for APW and NYT datasets, respectively.",4.3 AD3: Attentive Deep Document Dater,[0],[0]
"This depicts that the two models are capturing significantly different aspects of documents, resulting in a substantial improvement in performance when combined.",4.3 AD3: Attentive Deep Document Dater,[0],[0]
Dataset:,5 Experimental Setup,[0],[0]
"Experiments are carried out on the Associated Press Worldstream (APW) and New York Times (NYT) sections of the Gigaword corpus (Parker et al., 2011).",5 Experimental Setup,[0],[0]
We have used the same 8:1:1 split as Vashishth et al. (2018) for all the models.,5 Experimental Setup,[0],[0]
"For quantitative details please refer to Table 1.
",5 Experimental Setup,[0],[0]
Evaluation Criteria:,5 Experimental Setup,[0],[0]
"In accordance with prior work (Chambers, 2012; Kotsakos et al., 2014; Vashishth et al., 2018)",5 Experimental Setup,[0],[0]
the final task is to predict the publication year of the document.,5 Experimental Setup,[0],[0]
"We give a brief description of the baselines below.
",5 Experimental Setup,[0],[0]
"Baseline Methods:
• MaxEnt-Joint (Chambers, 2012):",5 Experimental Setup,[0],[0]
"This method engineers several hand-crafted temporally influenced features to classify the document using MaxEnt Classifier.
• BurstySimDater (Kotsakos et al., 2014):",5 Experimental Setup,[0],[0]
"This is a purely statistical method which uses lexical similarity and term burstiness (Lappas et al., 2009) for dating documents in arbitrary length time frame.",5 Experimental Setup,[0],[0]
"For our experiments, we used a time frame length of 1 year.
",5 Experimental Setup,[0],[0]
"• NeuralDater (Vashishth et al., 2018):",5 Experimental Setup,[0],[0]
This is the first deep neural network based approach for the document dating task.,5 Experimental Setup,[0],[0]
"Details are provided in Section 3.2.
",5 Experimental Setup,[0],[0]
"Israel's consumer price index increased by 1.2 percent  in December, bringing the overall inflation rate for 1995 to 8.1 percent, well within the government's target rate for the year, officials said Friday.",5 Experimental Setup,[0],[0]
"Israel radio said that it was the lowest annual inflation rate in twenty years.
",5 Experimental Setup,[0],[0]
Figure 5: Visualization of the attention of AC-GCN.,5 Experimental Setup,[0],[0]
ACGCN captures the intuitive tokens as seen in the figure.,5 Experimental Setup,[0],[0]
Darker shade implies higher attention.,5 Experimental Setup,[0],[0]
"The correct DCT is 1996.
",5 Experimental Setup,[0],[0]
Hyperparameters: We use 300-dimensional GloVe embeddings and 128-dimensional hidden state for both GCNs and BiLSTM with 0.8 dropout.,5 Experimental Setup,[0],[0]
"We use Adam (Kingma and Ba, 2014) with 0.001 learning rate for training.",5 Experimental Setup,[0],[0]
For OE-GCN we use 2-layers of AT-GCN.,5 Experimental Setup,[0],[0]
1-layer of S-GCN is used for both the models.,5 Experimental Setup,[0],[0]
"In this section, we compare the effectiveness of our method with that of prior work.",6.1 Performance Analysis,[0],[0]
"The deep network based NeuralDater model in (Vashishth et al., 2018) outperforms previous feature engi-
neered (Chambers, 2012) and statistical methods (Kotsakos et al., 2014) by a large margin.",6.1 Performance Analysis,[0],[0]
We observe a similar trend in our case.,6.1 Performance Analysis,[0],[0]
"Compared to the state-of-the-art model NeuralDater, we gain, on an average, a 3.7% boost in accuracy on both the datasets (Table 2).
",6.1 Performance Analysis,[0],[0]
"Among individual models, OE-GCN performs at par with NeuralDater, while AC-GCN outperforms it.",6.1 Performance Analysis,[0],[0]
The empirical results imply that ACGCN by itself is effective for this task.,6.1 Performance Analysis,[0],[0]
The relatively worse performance of OE-GCN can be attributed to the fact that it only focuses on the Event-Time information and leaves out most of the contextual information.,6.1 Performance Analysis,[0],[0]
"However, it captures various different (p < 0.000001, McNemar’s test, 2-tailed) aspects of the document for classification, which motivated us to propose an ensemble of the two models.",6.1 Performance Analysis,[0],[0]
This explains the significant boost in performance of AD3 over NeuralDater as well as the individual models.,6.1 Performance Analysis,[0],[0]
"It is worth mentioning that although AC-GCN and OE-GCN do not provide significant boosts in accuracy, their predictions have considerably lower mean-absolute-
deviation as shown in Figure 4.",6.1 Performance Analysis,[0],[0]
We concatenated the DCT embedding provided by OE-GCN with the document embedding provided by AC-GCN and trained in an end to end joint fashion like NeuralDater.,6.1 Performance Analysis,[0],[0]
"We see that even with a similar training method, the Attentive NeuralDater model on an average, performs 1.6% better in terms of accuracy, once again proving the efficacy of attention based models over normal models.",6.1 Performance Analysis,[0],[0]
"Attentive Graph Convolution (Section 4.2.2) proves to be effective for OE-GCN, giving a 2% accuracy improvement over non-attentive T-GCN of NeuralDater (Table 3).",6.2 Effectiveness of Attention,[0],[0]
Similarly the efficacy of word level attention is also prominent from Table 3.,6.2 Effectiveness of Attention,[0],[0]
We have also analyzed our models by visualizing attentions over words and attention over graph nodes.,6.2 Effectiveness of Attention,[0],[0]
"Figure 5 shows that AC-GCN focuses on temporally informative words such as ”said” (for tense) or time mentions like “1995”, alongside important contextual words like “inflation”, “Israel” etc.",6.2 Effectiveness of Attention,[0],[0]
"For OE-GCN, from Figure 6 we observe that “DCT” and time-mention ‘1995’ grabs the highest attention.",6.2 Effectiveness of Attention,[0],[0]
"Attention between “DCT” and other event verbs indicating past tense are quite prominent, which helps the model to infer 1996 (which is correct) as the most likely time-stamp of the document.",6.2 Effectiveness of Attention,[0],[0]
These analyses provide us with a good justification for the performance of our attentive models.,6.2 Effectiveness of Attention,[0],[0]
"Apart from empirical improvements over previous models, we also perform a qualitative analysis of the individual models.",7 Discussion,[0],[0]
"Figure 7 shows that the performance of AC-GCN improves with the length of documents, thus indicating that richer context leads to better model prediction.",7 Discussion,[0],[0]
"Figure 8 shows how the performance of OE-GCN improves with the number of event-time mentions in the document, thus further reinforcing our claim that more temporal information improves model performance.
",7 Discussion,[0],[0]
Vashishth et al. (2018) reported that their model got confused by the presence of multiple misleading time mentions.,7 Discussion,[0],[0]
"AD3 overcomes this limitation using attentive graph convolution, which successfully filters out noisy time mentions as is evident
from Figure 8.",7 Discussion,[0],[0]
"We propose AD3, an ensemble model which exploits both syntactic and temporal information in a document explicitly to predict its creation time (DCT).",8 Conclusion,[0],[0]
"To the best of our knowledge, this is the first application of attention based deep models for dating documents.",8 Conclusion,[0],[0]
Our experimental results demonstrate the effectiveness of our model over all previous models.,8 Conclusion,[0],[0]
We also visualize the attention weights to show that the model is able to choose what is important for the task and filter out noise inherent in language.,8 Conclusion,[0],[0]
"As part of future work, we would like to incorporate external knowledge as a side information for improved time-stamping of documents.",8 Conclusion,[0],[0]
"This work is supported by the Ministry of Human Resource Development (MHRD), Government of India.",Acknowledgments,[0],[0]
"Knowledge of the creation date of documents facilitates several tasks such as summarization, event extraction, temporally focused information extraction etc.",abstractText,[0],[0]
"Unfortunately, for most of the documents on the Web, the time-stamp metadata is either missing or can’t be trusted.",abstractText,[0],[0]
"Thus, predicting creation time from document content itself is an important task.",abstractText,[0],[0]
"In this paper, we propose Attentive Deep Document Dater (AD3), an attention-based neural document dating system which utilizes both context and temporal information in documents in a flexible and principled manner.",abstractText,[0],[0]
We perform extensive experimentation on multiple real-world datasets to demonstrate the effectiveness of AD3 over neural and non-neural baselines.,abstractText,[0],[0]
AD3: Attentive Deep Document Dater,title,[0],[0]
"Kernel representations provide an attractive approach to representation learning, by facilitating simple linear prediction algorithms and providing an interpretable representation.",1. Introduction,[0],[0]
"A kernel representation consists of mapping an input observation into similarity features, with similarities to a set of prototypes.",1. Introduction,[0],[0]
"Consequently, for an input observation, a prediction can be attributed to those prototypes that are most similar to the observation.",1. Introduction,[0],[0]
"Further, the transformation to similarity features is non-linear, enabling nonlinear function approximation while using linear learning algorithms that simply optimize for weights on these transformed features.",1. Introduction,[0],[0]
"Kernel representations are universal func-
1Department of Computer Science, Indiana University, Bloomington.",1. Introduction,[0],[0]
"Correspondence to: Martha White <martha@indiana.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"tion approximators1 and the flexibility in choosing the kernel (similarity function) has enabled impressive prediction performance for a range of settings, including speech (Huang et al., 2014), computer vision (Mairal et al., 2014), and object recognition (Lu et al., 2014).
",1. Introduction,[0],[0]
"In a continual learning setting, such as in online learning or reinforcement learning, there is a constant, effectively unending stream of data, necessitating some care when using kernel representations.",1. Introduction,[0],[0]
The issue arises from the choice of prototypes.,1. Introduction,[0],[0]
"Before the advent of huge increases in dataset sizes, a common choice was to use all of the training data as prototypes.",1. Introduction,[0],[0]
"This choice comes from the representer theorem, which states that for a broad class of functions, the empirical risk minimizer is a linear weighting of similarity features, to a set of prototypes that consists of the training data.",1. Introduction,[0],[0]
"For continual learning, however, the update should be independent of the the total number of samples— which is not clearly defined for continual learning.",1. Introduction,[0],[0]
"Conversely, we want to permit selection of a sufficiently large number of prototypes, to maintain sufficient modeling power.",1. Introduction,[0],[0]
"For efficient, continual updating, therefore, we require per-step prototype selection strategies that are approximately linear in the number of prototypes.
",1. Introduction,[0],[0]
"Currently, most algorithms do not satisfy the criteria for a continual learning setting.",1. Introduction,[0],[0]
"Incremental selection of prototypes has been tackled in a wide range of areas, due to the fundamental nature of this problem.",1. Introduction,[0],[0]
"Within the streaming community, approaches typically assume that the batch of data, though large, is accessible and fixed.",1. Introduction,[0],[0]
"The most related of these areas2 include active set selection for Gaussian process regression (Seeger et al., 2003), with streaming submodular maximization approaches (Krause et al., 2008b;a; Badanidiyuru et al., 2014); incremental Nystrom methods within kernel recursive least-squares (KRLS)
1Radial basis function networks are an example of a kernel representation, that have been shown to be universal function approximators (Park & Sandberg, 1991).",1. Introduction,[0],[0]
"Further, the representer theorem further characterizes the approximation capabilities under empirical risk minimization for a broad class of functions.
2Facility location, k-medians and k-centers are three problems that focus on selecting representative instances from a set (c.f. (Guha et al., 2003)).",1. Introduction,[0],[0]
"The criteria and algorithms are not designed with the intention to use the instances for prediction and so we do not consider them further here.
",1. Introduction,[0],[0]
"(Rudi et al., 2015)3; and functional gradients that sample random bases which avoid storing prototypes but require storing n scalars, for n training samples (Dai et al., 2014).
",1. Introduction,[0],[0]
"Kernel representation algorithms designed specifically for the online setting, on the other hand, are typically too computationally expensive in terms of the number of prototypes.",1. Introduction,[0],[0]
"Kernel least-mean squares (KLMS) algorithms use stochastic updates, maintaining the most recent prototypes and truncating coefficients on the oldest (Kivinen et al., 2010; Schraudolph et al., 2006; Cheng et al., 2007); though efficient given sufficient truncation, this truncation can introduce significant errors (Van Vaerenbergh & Santamaria, 2013).",1. Introduction,[0],[0]
"Random feature approximations (Rahimi & Recht, 2007) can be used online, but require a significant number of random features.",1. Introduction,[0],[0]
"Gaussian process regression approaches have online variants (Csató & Opper, 2006; Cheng & Boots, 2016), however, they inherently require at least quadratic computation to update the variance parameters.",1. Introduction,[0],[0]
"KRLS can be applied online, but has a threshold parameter that makes it difficult to control the number of prototypes and requires quadratic computation and space (Engel et al., 2004).",1. Introduction,[0],[0]
"More efficient coherence heuristic have been proposed (Richard et al., 2009; Van Vaerenbergh et al., 2010; Chen et al., 2013; Van Vaerenbergh & Santamaria, 2013), but provide no approximation quality guarantees.
",1. Introduction,[0],[0]
"In this work, we provide a simple and efficient greedy algorithm for selecting prototypes for continual learning, by extending recent work in prototype selection with submodular maximization.",1. Introduction,[0],[0]
"We introduce a generalized coherence criterion for selecting prototypes, which unifies two previously proposed criteria: the coherence criterion and the log determinant.",1. Introduction,[0],[0]
"Because this criterion is (approximately) submodular, we pursue a generalization to streaming submodular maximization algorithms.",1. Introduction,[0],[0]
"We avoid the need for multiple passes over the data—which is not possible in continual learning— by introducing the idea of coverage time, which reflects that areas of the observation space are repeatedly visited under sufficient mixing.",1. Introduction,[0],[0]
"We prove that our online submodular maximization achieves an approximation-ratio of 1/2, with a small additional approximation introduced due to coverage time and from using an estimate of the submodular function.",1. Introduction,[0],[0]
"We then provide a linear-time algorithm for approximating one instance of our submodular criterion, by exploiting the block-diagonal form of the kernel matrix.",1. Introduction,[0],[0]
"We empirically demonstrate that this approximation closely matches the true value, despite using significantly less computation, and show effective prediction performance using the corresponding kernel representation.
",1. Introduction,[0],[0]
"3There is a large literature on fast Nystrom methods using related approaches, such as determinant point processes for sampling landmark points (Li et al., 2016).",1. Introduction,[0],[0]
"The primary goal for these methods, however, is to approximate the full kernel matrix.",1. Introduction,[0],[0]
"A kernel representation is a transformation of observations into similarity features, consisting of similarities to prototypes.",2. Using kernel representations,[0],[0]
"A canonical example of such a representation is a radial basis function network, with radial basis kernels such as the Gaussian kernel; however, more generally any kernel similarity can be chosen.",2. Using kernel representations,[0],[0]
"More formally, for observations x 2 X , the kernel representation consists of similarities to a set of prototypes S = {z1, . . .",2. Using kernel representations,[0],[0]
", zb} ⇢",2. Using kernel representations,[0],[0]
"X
x!",2. Using kernel representations,[0],[0]
"[k(x, z1), . . .",2. Using kernel representations,[0],[0]
", k(x, zb)] 2 Rb.",2. Using kernel representations,[0],[0]
for kernel k : X ⇥ X !,2. Using kernel representations,[0],[0]
R.,2. Using kernel representations,[0],[0]
"The observations need not be numerical; as long as a similarity k can be defined between two observations, kernel representations can be used and conveniently provide a numeric feature vector in Rb.",2. Using kernel representations,[0],[0]
"We use the term prototype, instead of center, to emphasize that the chosen observations are representative instances, that are sub-selected from observed data.
",2. Using kernel representations,[0],[0]
"A fundamental result for kernel representations is the representer theorem, with significant recent generalizations (Argyriou & Dinuzzo, 2014), which states that for a broad class of function spaces H, the empirical risk minimizer f 2 H on a training set {(x
i , y i }n i=1 has the simple form
f(·) = nX
i=1
↵",2. Using kernel representations,[0],[0]
"i k(·,x i ).
",2. Using kernel representations,[0],[0]
"This result makes use of a key property: the kernel function can be expressed as an inner product, k(x
i ,x j ) =
h (x i ), (x j )",2. Using kernel representations,[0],[0]
i for some implicit expansion .,2. Using kernel representations,[0],[0]
"The function f can be written f = P n
i=1",2. Using kernel representations,[0],[0]
"↵i (xj), with
f(x) = h (x), nX
i=1
↵ i (x j
)",2. Using kernel representations,[0],[0]
"i = nX
i=1
↵",2. Using kernel representations,[0],[0]
"i h (x), (x j )i.
",2. Using kernel representations,[0],[0]
"It is typically impractical to use all x i as prototypes, and a subset needs to be chosen.",2. Using kernel representations,[0],[0]
"Recently, there has been several papers (Krause et al., 2008b;a; Krause & Gomes, 2010; Badanidiyuru et al., 2014) showing that prototypes can be effectively selected in the streaming setting using greedy submodular maximization on the log-determinant of the kernel matrix, K
S 2 Rb⇥b where (K S ) ij =",2. Using kernel representations,[0],[0]
k(z,2. Using kernel representations,[0],[0]
"i , z j
).",2. Using kernel representations,[0],[0]
"Given some ground set ⌦ and its powerset P(⌦), submodular functions g : P(⌦) !",2. Using kernel representations,[0],[0]
"R are set functions, with a diminishing returns property: the addition of a point to a given set increases the value less or equal than adding a point to a subset of that set.",2. Using kernel representations,[0],[0]
"For prototype selection, the ground set considered are sets of all observations X , so S ⇢ ⌦ = X .",2. Using kernel representations,[0],[0]
"The log-determinant of the resulting kernel matrix, log detK
S , is a submodular function of S. Though maximizing submodular functions is NP-hard, greedy approximation algorithms have been shown to obtain reasonable approximation ratios, even for the streaming setting
(Krause & Gomes, 2010; Badanidiyuru et al., 2014), and the resulting algorithms are elegantly simple and theoretically sound.
",2. Using kernel representations,[0],[0]
"In the following sections, we derive a novel criterion for prototype selection, that includes the log-determinant as a special case.",2. Using kernel representations,[0],[0]
"Then, we provide an efficient prototype selection algorithm for the continual learning setting, using submodular maximization.",2. Using kernel representations,[0],[0]
Many prototype selection strategies are derived based on diversity measures.,3. Selecting kernel prototypes,[0],[0]
"The coherence criterion (Engel et al., 2004) approximates how effectively the set of prototypes spans the set of given observations.",3. Selecting kernel prototypes,[0],[0]
"The log-determinant measures the spread of eigenvalues for the kernel matrix, and is related to information gain (Seeger, 2004).",3. Selecting kernel prototypes,[0],[0]
"These selection criteria are designed for a finite set of observed points; here, we step back and reconsider a suitable objective for prototype selection for continual learning.
",3. Selecting kernel prototypes,[0],[0]
Our goal is to select prototypes that minimize distance to the optimal function.,3. Selecting kernel prototypes,[0],[0]
"In this section, we begin from this objective and demonstrate that the coherence criterion and log-determinant are actually upper bounds on this objective, and special cases of a more general such upper bound.",3. Selecting kernel prototypes,[0],[0]
"The analysis justifies that the log-determinant is a more suitable criteria for continual learning, which we then pursue in the remainder of this work.",3. Selecting kernel prototypes,[0],[0]
"Let X = {x1, . . .",3.1. Criteria to select prototypes from a finite set,[0],[0]
",xn} be a set of points, with corresponding labels y1, . . .",3.1. Criteria to select prototypes from a finite set,[0],[0]
",yn.",3.1. Criteria to select prototypes from a finite set,[0],[0]
"We will not assume that this is a batch of data, but could rather consist of all possible observations for a finite observation space.",3.1. Criteria to select prototypes from a finite set,[0],[0]
"Ideally, we would learn S = {z1, . . .",3.1. Criteria to select prototypes from a finite set,[0],[0]
", zb} ⇢ X and corresponding f S, (·) =",3.1. Criteria to select prototypes from a finite set,[0],[0]
"Pb i=1 jk(·,xi)",3.1. Criteria to select prototypes from a finite set,[0],[0]
"according to the loss
min S⇢X min 2Rb kf f S, k2 (1)
wherekf f S, k =
nX
i=1
↵ i (x i
) bX
j=1
j (z j )
for the optimal f for the set of points X .",3.1. Criteria to select prototypes from a finite set,[0],[0]
"Because we do not have f , we derive an upper bound on this value.",3.1. Criteria to select prototypes from a finite set,[0],[0]
"Introducing dummy variables (i)
j
2 R such that j =
P n
i=1",3.1. Criteria to select prototypes from a finite set,[0],[0]
"(i) j ,
(1)  min S⇢X , 2Rb
nX
i=1
↵",3.1. Criteria to select prototypes from a finite set,[0],[0]
"i (x i
) bX
j=1
(i) j",3.1. Criteria to select prototypes from a finite set,[0],[0]
"(z j )
2
= min
S⇢X
nX
i=1
min
(i) 1 ,..., (i) b
↵",3.1. Criteria to select prototypes from a finite set,[0],[0]
"i (x i
) bX
j=1
(i) j",3.1. Criteria to select prototypes from a finite set,[0],[0]
"(z j )
2
(2)
",3.1. Criteria to select prototypes from a finite set,[0],[0]
For k i . =,3.1. Criteria to select prototypes from a finite set,[0],[0]
"[k(x i
, z1), . . .",3.1. Criteria to select prototypes from a finite set,[0],[0]
", k(xi, zb)], the interior minimization can be re-written as
min
(i)
↵",3.1. Criteria to select prototypes from a finite set,[0],[0]
"i (x i
) bX
j=1
(i) j",3.1. Criteria to select prototypes from a finite set,[0],[0]
"(z j )
2
= min
(i) >",3.1. Criteria to select prototypes from a finite set,[0],[0]
"K
S
2↵ i
(i) >",3.1. Criteria to select prototypes from a finite set,[0],[0]
"k
i + ↵2",3.1. Criteria to select prototypes from a finite set,[0],[0]
i k(x,3.1. Criteria to select prototypes from a finite set,[0],[0]
"i ,x i )
",3.1. Criteria to select prototypes from a finite set,[0],[0]
"To provide more stable approximations, we regularize
(2) min S⇢X
nX
i=1
min
(i)
",3.1. Criteria to select prototypes from a finite set,[0],[0]
↵,3.1. Criteria to select prototypes from a finite set,[0],[0]
"i (x i
) bX
j=1
(i) j",3.1. Criteria to select prototypes from a finite set,[0],[0]
"(z j )
2
+ k",3.1. Criteria to select prototypes from a finite set,[0],[0]
"(i)k22
= min
S⇢X
nX
i=1
min (i) (i)
>",3.1. Criteria to select prototypes from a finite set,[0],[0]
"(K
S + I) 2↵ i
(i)",3.1. Criteria to select prototypes from a finite set,[0],[0]
>,3.1. Criteria to select prototypes from a finite set,[0],[0]
"k
i
+ ↵2",3.1. Criteria to select prototypes from a finite set,[0],[0]
i,3.1. Criteria to select prototypes from a finite set,[0],[0]
k(x,3.1. Criteria to select prototypes from a finite set,[0],[0]
"i ,x i ).
",3.1. Criteria to select prototypes from a finite set,[0],[0]
"For = 0, the inequality is equality.",3.1. Criteria to select prototypes from a finite set,[0],[0]
"Otherwise adding regularization theoretically increases the upper bound, though in practice will be key for stability.
",3.1. Criteria to select prototypes from a finite set,[0],[0]
Solving gives (i) =,3.1. Criteria to select prototypes from a finite set,[0],[0]
↵,3.1. Criteria to select prototypes from a finite set,[0],[0]
"i (K S + I) 1k i , and so
(i) >",3.1. Criteria to select prototypes from a finite set,[0],[0]
"(K
S + I) 2↵ i
(i)",3.1. Criteria to select prototypes from a finite set,[0],[0]
>,3.1. Criteria to select prototypes from a finite set,[0],[0]
"k
i + ↵2",3.1. Criteria to select prototypes from a finite set,[0],[0]
i k(x,3.1. Criteria to select prototypes from a finite set,[0],[0]
"i ,x i )
= ↵2 i k >",3.1. Criteria to select prototypes from a finite set,[0],[0]
i (K S + I) 1k i 2↵2,3.1. Criteria to select prototypes from a finite set,[0],[0]
i k >,3.1. Criteria to select prototypes from a finite set,[0],[0]
i (K S + I) 1k,3.1. Criteria to select prototypes from a finite set,[0],[0]
"i
+ ↵2 i k(x i ,x i )
= ↵2 i k(x i ,x i ) ↵2 i k >",3.1. Criteria to select prototypes from a finite set,[0],[0]
i (K S + I),3.1. Criteria to select prototypes from a finite set,[0],[0]
1k,3.1. Criteria to select prototypes from a finite set,[0],[0]
"i
We can now simplify the above upper bound
(2)  ",3.1. Criteria to select prototypes from a finite set,[0],[0]
"min S⇢X
nX
i=1
↵2 i k(x",3.1. Criteria to select prototypes from a finite set,[0],[0]
"i ,x i ) ↵2 i k >",3.1. Criteria to select prototypes from a finite set,[0],[0]
"i (K S + I) 1k i
and obtain equivalent optimization
argmax
S⇢X
nX
i=1
↵2",3.1. Criteria to select prototypes from a finite set,[0],[0]
i k >,3.1. Criteria to select prototypes from a finite set,[0],[0]
"i (K S + I) 1k i .
",3.1. Criteria to select prototypes from a finite set,[0],[0]
"This criteria closely resembles the coherence criterion (Engel et al., 2004).",3.1. Criteria to select prototypes from a finite set,[0],[0]
"The key idea for the coherence criterion is to add a prototype x
i , to kernel matrix K S if 1 k
i
K 1 S k",3.1. Criteria to select prototypes from a finite set,[0],[0]
i  ⌫ for some threshold parameter ⌫.,3.1. Criteria to select prototypes from a finite set,[0],[0]
"The coherence criterion,
argmax
S⇢X
nX
i=1
k >",3.1. Criteria to select prototypes from a finite set,[0],[0]
i (K S + I) 1k,3.1. Criteria to select prototypes from a finite set,[0],[0]
"i
therefore, can be seen as an upper bound on the distance the optimal function, with further relaxation because P n
i=1",3.1. Criteria to select prototypes from a finite set,[0],[0]
↵ 2,3.1. Criteria to select prototypes from a finite set,[0],[0]
i k >,3.1. Criteria to select prototypes from a finite set,[0],[0]
i (K S + I),3.1. Criteria to select prototypes from a finite set,[0],[0]
"1k i  max{↵21, . . .",3.1. Criteria to select prototypes from a finite set,[0],[0]
",↵2n} P n i=1",3.1. Criteria to select prototypes from a finite set,[0],[0]
k >,3.1. Criteria to select prototypes from a finite set,[0],[0]
"i (K S + I) 1k i .
",3.1. Criteria to select prototypes from a finite set,[0],[0]
The relationship to another popular criterion—the log determinant— arises when we consider the extension to an infinite state space.,3.1. Criteria to select prototypes from a finite set,[0],[0]
The criterion above can be extended to an uncountably infinite observation space X .,3.2. Criteria to select prototypes from an infinite set,[0],[0]
"For this setting, the optimal f = R X !",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"(x) (x)dx, for a function !",3.2. Criteria to select prototypes from an infinite set,[0],[0]
": R
d !",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"R. Let k(x, S) =",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"[k(x, z1), . . .",3.2. Criteria to select prototypes from an infinite set,[0],[0]
", k(x, zb)]",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"Then, using a similar analysis to above,
min S⇢X min 2Rb kf f S, k2  min S⇢X
Z
X !(x)2k(x,x)dx
Z
X !(x)2k(x, S)>(K S + I) 1k(x, S)dx.
and so the resulting goal is to optimize
argmax
S⇢X
Z
X !(x)2k(x, S)>(K S + I) 1k(x, S)dx.",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"(3)
This provides a nice relation to the log determinant criterion, with normalized kernels4: k(z, z) = 1.",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"If k(x, S) maps to a unique kernel vector k 2",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"[0, 1]b, and the function k(·, S) also maps onto [0, 1]b, then for !(x) = 1,
Z
X !(x)2k(x, S)>(K S + I) 1k(x, S)dx
= Z k",3.2. Criteria to select prototypes from an infinite set,[0],[0]
>,3.2. Criteria to select prototypes from an infinite set,[0],[0]
"(K
S
+ I)",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"1k dk
= det(K
S
+ I).
",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"In general, it is unlikely to have a bijection k(·, S).",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"More generally, we can obtain the above criterion by setting the coefficient function !",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"so that each possible kernel vector k 2 Rb has uniform weighting, or implicitly so the integration is uniformly over k 2",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"[0, 1]b.",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"Because log is monotonically increasing, maximizing det(K
S + I) with a fixed b is equivalent to maximizing log det(K
S
+ I).
",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"This derivation of an upper bound on the distance to the optimal function provides new insights into the properties of the log-determinant, clarifies the connection between the coherence criterion and the log-determinant, and suggesting potential routes for providing criteria based on the prediction utility of a prototype.",3.2. Criteria to select prototypes from an infinite set,[0],[0]
The choice of weighting !,3.2. Criteria to select prototypes from an infinite set,[0],[0]
to obtain the log-determinant removes all information about the utility of a prototype and essentially assumes a uniform distribution over the kernel vectors k.,3.2. Criteria to select prototypes from an infinite set,[0],[0]
"For more general coefficient functions !, let µ(S) =",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"E[k(X, S)] and ⌃(S) = Cov(k(X, S)), where the expectations are according to density !",3.2. Criteria to select prototypes from an infinite set,[0],[0]
2/c for normalizer c = R X !(x)dx.,3.2. Criteria to select prototypes from an infinite set,[0],[0]
"By the quadratic expectations properties (Brookes, 2004)
(3) = argmax S⇢X tr((K S + I) 1⌃(S))
+ µ(S)>(K S + I) 1µ(S).",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"(4)
4A kernel can be normalized by k(x, z)/ p k(z, z)k(x,x).
",3.2. Criteria to select prototypes from an infinite set,[0],[0]
This more general form in (4) enables prototypes to be more highly weighted based on the magnitude of values in !.,3.2. Criteria to select prototypes from an infinite set,[0],[0]
"We focus in this work first on online prototype selection for the popular log-determinant, and leave further investigation into this more general criteria to future work.",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"We nonetheless introduce the form here to better motivate the log-determinant, as well as demonstrate that the above analysis is amenable to a host of potential directions for more directed prototype selection.",3.2. Criteria to select prototypes from an infinite set,[0],[0]
"In this section, we introduce an OnlineGreedy algorithm for submodular maximization, to enable optimization of the prototype selection objective from an online stream of data.",4. Online submodular maximization,[0],[0]
"Current submodular maximization algorithms are designed for the streaming setting, which deals with incrementally processing large but fixed datasets.",4. Online submodular maximization,[0],[0]
"Consequently, the objectives are specified for a finite batch of observations and the algorithms can do multiple passes over the dataset.",4. Online submodular maximization,[0],[0]
"For the online setting, both of these conditions are restrictive.",4. Online submodular maximization,[0],[0]
"We show that, with a minor modification to StreamGreedy (Krause & Gomes, 2010), we can obtain a comparable approximation guarantee that applies to the online setting.
",4. Online submodular maximization,[0],[0]
"We would like to note that there is one streaming algorithm, called Sieve Streaming, designed to only do one pass of the data and avoid too many calls to the submodular function (Badanidiyuru et al., 2014); however, it requires keeping parallel solutions, which introduces significant complexity and which we found prohibitively expensive.",4. Online submodular maximization,[0],[0]
"In our experiments, we show it is significantly slower than our approach and found it typically maintained at least 500 parallel solutions.",4. Online submodular maximization,[0],[0]
"For this reason, we opt to extend the simpler StreamGreedy algorithm, and focus on efficient estimates of the submodular function, since we will require more calls to this function than Sieve Streaming.
",4. Online submodular maximization,[0],[0]
"Our goal is to solve the submodular maximization problem
max S⇢X :|S|b g(S) (5)
where X is a general space of observations and g is a submodular function.",4. Online submodular maximization,[0],[0]
"The key modification is to enable X to be a large, infinite or even uncountable space.",4. Online submodular maximization,[0],[0]
"For such X , we will be unable to see all observations, let alone make multiple passes.",4. Online submodular maximization,[0],[0]
"Instead, we will use a related notion to mixing time, where we see a cover of the space.
",4. Online submodular maximization,[0],[0]
The greedy algorithm consists of greedily adding in a new prototype if it is an improvement on a previous prototype.,4. Online submodular maximization,[0],[0]
"The resulting greedy algorithm—given in Algorithm 1— is similar to StreamGreedy, and so we term it OnlineGreedy.",4. Online submodular maximization,[0],[0]
"The algorithm queries the submodular function on each set, with a previous prototype removed and the new observation added.",4. Online submodular maximization,[0],[0]
"To make this efficient, we will rely on us-
Algorithm 1 OnlineGreedy Input: threshold parameter ✏
t , where a prototype is only added if there is sufficient improvement S0 ;",4. Online submodular maximization,[0],[0]
"for t = 1 : b do S
t
S t 1",4. Online submodular maximization,[0],[0]
"[ {xt}
while interacting, t = b+ 1, . .",4. Online submodular maximization,[0],[0]
.,4. Online submodular maximization,[0],[0]
"do z 0 = argmax
z2St 1 ĝ(S t 1\{z}",4. Online submodular maximization,[0],[0]
[ {xt}) S t S t 1\{z0} [ {xt} if ĝ(S t ) ĝ(S t 1) <,4. Online submodular maximization,[0],[0]
"✏t then
S t
S t 1
ing only an approximation to the submodular function g. We will provide a linear-time algorithm—in the number of prototypes— for querying replacement to all prototypes, as opposed to a naive solution which would be cubic in the number of prototypes.",4. Online submodular maximization,[0],[0]
"This will enable us to use this simple greedy approach, rather than more complex streaming submodular maximization approaches that attempt to reduce the number of calls to the submodular function.
",4. Online submodular maximization,[0],[0]
"We bound approximation error, relative to the optimal solution.",4. Online submodular maximization,[0],[0]
We extend an algorithm that uses multiple passes; our approach suggests more generally how algorithms from the streaming setting can be extended to an online setting.,4. Online submodular maximization,[0],[0]
"To focus the on this extension, we only consider submodular functions here; in Appendix B, we generalize the result to approximately submodular functions.",4. Online submodular maximization,[0],[0]
"Many set functions are approximately submodular, rather than submodular, but still enjoy similar approximation properties.",4. Online submodular maximization,[0],[0]
"The log-determinant is submodular, however, it is more likely that, for the variety of choices for !, the generalized coherence criterion is only approximately submodular.",4. Online submodular maximization,[0],[0]
"For this reason, we provide this generalization to approximate submodularity, as it further justifies the design of (approximately) submodular criteria for prototype selection.
",4. Online submodular maximization,[0],[0]
"We compare our solution to the optimal solution
S⇤ = argmax S⇢X :|S|b g(S) = {z⇤1, . . .",4. Online submodular maximization,[0],[0]
", z⇤b}.
",4. Online submodular maximization,[0],[0]
Assumption 1 (Submodularity).,4. Online submodular maximization,[0],[0]
g is monotone increasing and submodular.,4. Online submodular maximization,[0],[0]
Assumption 2 (Approximation error).,4. Online submodular maximization,[0],[0]
"We have access to a set function ĝ that approximates g: for some ✏
f 0 for all S ⇢ X , with |S|  b,
|ĝ(S) g(S)|  ✏ f
Assumption 3 (Submodular coverage time).",4. Online submodular maximization,[0],[0]
"For a fixed ✏ r
> 0 and > 0 there exists a ⇢ 2 N such that for all S ⇢ X where |S|  b, with probability 1 , for any z⇤ 2 S⇤ an observation x is observed within ⇢ steps (starting from any point in X ) that is similar to z⇤ in that
|g(S",4. Online submodular maximization,[0],[0]
[ {x}) g(S,4. Online submodular maximization,[0],[0]
"[ {z⇤})|  ✏ r .
",4. Online submodular maximization,[0],[0]
"This final assumption characterizes that the environment is sufficiently mixing, to see a cover of the space.",4. Online submodular maximization,[0],[0]
"We introduce the term coverage, instead of cover time for finitestate, to indicate a relaxed notion of observing a covering of the space rather than observing all states.
",4. Online submodular maximization,[0],[0]
"For simplicity of the proof, we characterize the coverage time in terms of the submodular function.",4. Online submodular maximization,[0],[0]
"We show that the submodular function we consider—the log-determinant— satisfies this assumption, given a more intuitive assumption that instead requires that observations be similar according to the kernel.",4. Online submodular maximization,[0],[0]
"The statement and proof are in Appendix A.
Now we prove our main result.",4. Online submodular maximization,[0],[0]
Theorem 1.,4. Online submodular maximization,[0],[0]
Assume Assumptions 1-3 and that g(S⇤) is finite and g(;) 0.,4. Online submodular maximization,[0],[0]
"Then, for t > ⇢g(S⇤)/✏
t , all sets S t
chosen by OnlineGreedy using ĝ satisfy, with probability 1 ,
g(S t ) 1 2 g(S⇤) b 2 (✏ r + 2✏ f + ✏ t )
",4. Online submodular maximization,[0],[0]
"Proof: The proof follows closely to the proof of Krause & Gomes (2010, Theorem 4).",4. Online submodular maximization,[0],[0]
"The key difference is that we cannot do multiple passes through a fixed dataset, and instead use submodular coverage time.
",4. Online submodular maximization,[0],[0]
"Case 1: There have been t ⇢g(S⇤)/✏ t iterations, and S t has always changed within ⇢ iterations (i.e., there has never been ⇢ consecutive iterations where S
t remained the same).",4. Online submodular maximization,[0],[0]
"This mean that for each ⇢ iterations, ĝ(S
t ) must have been improved by at least ✏
t , which is the minimum threshold for improvement.",4. Online submodular maximization,[0],[0]
"This means that over the t iterations, ĝ(S0) has improved by at least ✏
t
each ⇢,
ĝ(S0) +",4. Online submodular maximization,[0],[0]
✏tt/⇢ ✏tt/⇢ = ĝ(S⇤) g(S⇤) ✏f,4. Online submodular maximization,[0],[0]
"The solution is within ✏
f
of g(S⇤), and we are done.
",4. Online submodular maximization,[0],[0]
Case 2:,4. Online submodular maximization,[0],[0]
"At some time t, S t was not changed for ⇢ iterations, i.e., S
t ⇢ = St ⇢ 1 = . . .",4. Online submodular maximization,[0],[0]
"St. Order the prototypes in the set as z
i = argmaxz2St g({z1, . . .",4. Online submodular maximization,[0],[0]
", zi 1} [ {z}), with i
= g({z1, . . .",4. Online submodular maximization,[0],[0]
", zi}) g({z1, . . .",4. Online submodular maximization,[0],[0]
", zi 1}).",4. Online submodular maximization,[0],[0]
"By Lemma 3,
i 1 i. Because the point that was observed",4. Online submodular maximization,[0],[0]
"r
i that was closest to z
⇤",4. Online submodular maximization,[0],[0]
"i was not added to S, we have the following inequalities
|ĝ(S [ {r i }) g(S",4. Online submodular maximization,[0],[0]
[ {r i }),4. Online submodular maximization,[0],[0]
"|  ✏ f
ĝ(S",4. Online submodular maximization,[0],[0]
[ {r i }) ĝ(S,4. Online submodular maximization,[0],[0]
"[ {z b })  ✏ t
|g(S",4. Online submodular maximization,[0],[0]
[ {r i }),4. Online submodular maximization,[0],[0]
g(S,4. Online submodular maximization,[0],[0]
[ {z⇤ i }),4. Online submodular maximization,[0],[0]
"|  ✏ r
where the last inequality is true for all z⇤ i with probability 1 .",4. Online submodular maximization,[0],[0]
"Using these inequalities, as shown more explicitly in the proof in the appendix, we get
g(S",4. Online submodular maximization,[0],[0]
"[ {z⇤ i }) g(S)  b + ✏ r + 2✏ f + ✏ t
Algorithm 2 BlockGreedy: OnlineGreedy for Prototype Selection using a Block-Diagonal Approximation r = block-size, with set of blocks B, S0 ; c, l book-keeping maps, with (c(B), l(B))",4. Online submodular maximization,[0],[0]
"= (z, l) for z leading to smallest utility loss l if removed from block B. g e
0 is the incremental estimate of log-determinant for t = 1 : b do, S
t
S t 1",4. Online submodular maximization,[0],[0]
"[ {xt}
while interacting, t = b+ 1, . .",4. Online submodular maximization,[0],[0]
.,4. Online submodular maximization,[0],[0]
"do if added b new prototypes since last clustering then
cluster S t into bb/rc blocks with k-means, initialize with previous clustering; update c, l, g
e
BlockGreedy-Swap(x t )
",4. Online submodular maximization,[0],[0]
"By the definition of submodularity, g(S [ S⇤) g(S) P b
i=1 g(S",4. Online submodular maximization,[0],[0]
[ {z⇤i }) g(S)).,4. Online submodular maximization,[0],[0]
"Putting this all together, with probability 1 , g(S⇤)  g(S [ S⇤)
 g(S) + bX
i=1
g(S [ {z⇤ i }) g(S))
 g(S) + bX
i=1
( b + ✏ r + 2✏ f + ✏ t )
 g(S) +
bX
i=1
i
!",4. Online submodular maximization,[0],[0]
"+ b(✏
r + 2✏ f + ✏ t )
= g(S) + bX
i=1
g({s1, . . .",4. Online submodular maximization,[0],[0]
", zi}) g({z1, . . .",4. Online submodular maximization,[0],[0]
", zi 1})
+ b(✏ r + 2✏ f + ✏ t )
 g(S) + g({z1, . . .",4. Online submodular maximization,[0],[0]
", zb}) + b(✏r + 2✏f + ✏t)  2g(S
t ) +",4. Online submodular maximization,[0],[0]
"b(✏ r + 2✏ f + ✏ t )
where the last inequality uses g(S)  ",4. Online submodular maximization,[0],[0]
"g(S t
) which follows from monotonicity.",4. Online submodular maximization,[0],[0]
⌅,4. Online submodular maximization,[0],[0]
The computation of the submodular function g is the critical bottleneck in OnlineGreedy and other incremental submodular maximization techniques.,5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"In this section, we propose a time and memory efficient greedy approach to computing a submodular function on K
S , enabling each step of OnlineGreedy to cost O(db), where d is the feature dimension and b is the budget size.",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"The key insight is to take advantage of the block-diagonal structure of the kernel matrix, particularly due to the fact that the greedy algorithm intentionally selects diverse prototypes.",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"Consequently, we can approximately cluster prototypes into small groups of
Algorithm 3 BlockGreedy-Swap(x) B1 get-block(x) .",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"returns the nearest block to x (z1, g1) argmax
z2B1 g(B1\{z} [ {x}) g(B1)
",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"if g e 6= 0 and g1 ge ge < ✏ t then return with no update if low percentage improvement
(B2, g2) argmax",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
B2B\B1 g(B1,5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
[ {x}) l(B) if g1 < g2 then .,5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"remove point from same block
B1 B1\{z1} [ {x} update c(B1) .",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
using Appendix E.3,5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"g e g e
+ g1 else .",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"remove point from a different block
B1 B1 [ {x} B2 B2 \ {c(B2)} update c(B1), c(B2) .",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
using Appendix E.3,5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
g,5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"e g e + g2
size r, and perform updates on only these blocks.
",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"Approximations to the kernel matrix have been extensively explored, but towards the aim of highly accurate approximations for use within prediction.",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"These methods include low-rank approximations (Bach & Jordan, 2005), Nystrom methods (Drineas & Mahoney, 2005; Gittens & Mahoney, 2013) and a block-diagonal method for dense kernel matrices, focused on storage efficiency (Si et al., 2014).",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"Because these approximations are used for prediction and because they are designed for a fixed batch of data and so do not take advantage of incrementally updating values, they are not sufficiently efficient for use on each step, and require at least O(b2) computation.",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"For OnlineGreedy, however, we only need a more coarse approximation to K
S to enable effective prototype selection.",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"By taking advantage of this fact, saving computation with incremental updating and using the fact that our kernel matrix is not dense—making it likely that many off-diagonal elements are near zero— we can reduce storage and computation to linear in b.
The key steps in the algorithm are to maintain a clustering of prototypes, compute all pairwise swaps between prototypes within a block—which is much more efficient than pairwise swaps between all prototypes— and finally perform a single swap between two blocks.",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
The computational complexity of Algorithm 2 on each step is O(bd + r3) for block size r (see Appendix F for an in-depth explanation).,5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"We assume that, with a block-diagonal K
S with blocks B, the submodular function separates into g(S) =P
B2B g(B).",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"For both the log-determinant and the trace of the inverse of K
S , this is the case because the inverse of a block-diagonal matrix corresponds to a blockdiagonal matrix of the inverses of these blocks.",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"Therefore, log det(K
S
)",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"= P B2B log det(KB).
",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
We use this property to avoid all pairwise comparisons.,5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"If x is added to S, it gets clustered into its nearest block, based
on distance to the mean of that cluster.",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"To compute the log-determinant for the new S, we simply need to recompute the log-determinant for the modified block, as the logdeterminant for the remaining blocks is unchanged.",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"Therefore, if K
S really is block-diagonal, computing all pairwise swaps with x is equivalent to first computing the least useful point z in the closest cluster to x, and then determining if g(S [ {x}) would be least reduced by removing z or removing the least useful prototype from another cluster.",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"With some book-keeping, we maintain the least-useful prototype for each cluster, to avoid recomputing it each step.",5. Block-diagonal approximation for efficient computation of the submodular function,[0],[0]
"We empirically illustrate the accuracy and efficiency of our proposed method as compared to OnlineGreedy with no approximation to the submodular function (which we call Full Greedy), Sieve Streaming, and various naive versions of our algorithm.",6. Experiments,[0],[0]
"We also show this method can achieve reasonable regression accuracy as compared with KRLS (Engel et al., 2004).",6. Experiments,[0],[0]
"For these experiments we use four well known datasets: Boston Housing (Lichman, 2015), Parkinson’s Telemonitoring (Tsanas et al., 2010), Sante Fe A (Weigend, 1994) and Census 1990 (Lichman, 2015).",6. Experiments,[0],[0]
"Further details about each dataset are in Appendix C. We use a Gaussian kernel for the first three datasets, and a Hamming distance kernel for Census, which has categorical features.",6. Experiments,[0],[0]
"To investigate the effect of the block-diagonal approximation, we select the log-determinant as the criterion, which is an instance of our criterion, and set = 1.
",6. Experiments,[0],[0]
"Quality of the log-determinant approximation.
",6. Experiments,[0],[0]
"We first investigate the quality of prototypes selection and their runtimes, depicted in Figure 1.",6. Experiments,[0],[0]
"We compare our al-
gorithm with the FullGreedy, SieveStreaming and a random prototype selection baseline.",6. Experiments,[0],[0]
We also use variants of our algorithm including without clustering—naively dividing prototypes into equal-sized blocks—and one where we only consider replacement in the closest block.,6. Experiments,[0],[0]
"We include these variants to indicate the importance of clustering and of searching between blocks as well within blocks, in BlockGreedy.",6. Experiments,[0],[0]
"For all experiments on maximization quality, we use percentage gain with a threshold of ✏
t
= 0.001.
",6. Experiments,[0],[0]
"We plot the log determinant with increasing samples, in Figure 1(a).",6. Experiments,[0],[0]
Experiments on the other datasets are included in Appendix C. BlockGreedy maximizes the submodular function within 1% of the FullGreedy method.,6. Experiments,[0],[0]
"Though BlockGreedy achieves nearly as high a log determinant value, we can see that its approximation of the log determinant is an overestimate for this small block size, r = 5.
",6. Experiments,[0],[0]
"Our next experiment, therefore, focuses on the estimate accuracy of BlockGreedy with increasing block size, in Figure 1(b).",6. Experiments,[0],[0]
"The accuracy is computed by 1 | gactual gestimate
gactual |.",6. Experiments,[0],[0]
"We can see our algorithm, BlockGreedy
performs much better as compared to the other variants, ranging in accuracy from 0.82 to 0.99.",6. Experiments,[0],[0]
"This suggests that one can choose reasonably small block sizes, without incurring a significant penalty in maximizing the log determinant.",6. Experiments,[0],[0]
"In Figure 1(a), the estimate is inaccurate by about 20%, but follows the same trend of the full log determinant and picks similar prototypes to those chosen by FullGreedy.
",6. Experiments,[0],[0]
"The runtime of our algorithm should be much less than that of FullGreedy, and memory overhead much less than SieveStreaming.",6. Experiments,[0],[0]
"In Figure 1(c), we can see our method scales much better than FullGreedy and even has gains in speed over SieveStreaming.",6. Experiments,[0],[0]
"Though not shown, the number of sieves generated by SieveStreaming is large, in many instances well over 600, introducing a significant amount of
overhead.",6. Experiments,[0],[0]
"Overall, by taking advantage of the block structure of the kernel matrix, our algorithm obtains significant runtime and memory improvements, while also producing a highly accurate estimate of the log determinant.
",6. Experiments,[0],[0]
"Learning performance for regression problems.
",6. Experiments,[0],[0]
"While the maximization of the submodular function is useful in creating a diverse collection of prototypes, ultimately we would like to use these representations for prediction.",6. Experiments,[0],[0]
"In Figure 2, we show the effectiveness of solving (K
S +⌘I)w = y for the three regression datasets, by using our algorithm to select prototypes for K
S .",6. Experiments,[0],[0]
"For all regression experiments, we use a threshold of ✏
t = 0.01 unless otherwise specified.
",6. Experiments,[0],[0]
"For Boston housing data, in figure 2(a), we see that BlockGreedy can perform almost as well as FullGreedy and SieveStreaming, and outperforms KRLS at early learning and finally converges to almost same performance.",6. Experiments,[0],[0]
"We set the parameters for KRLS using the same parameter settings for this dataset as in their paper (Engel et al., 2004).",6. Experiments,[0],[0]
"For our algorithms we set the budget size to b = 80, which is smaller than what KRLS used, and chose a block size of 4.",6. Experiments,[0],[0]
"We also have lower learning variance than KRLS, likely because we use explicit regularization, whereas KRLS uses its prototype selection mechanism for regularization.
",6. Experiments,[0],[0]
"On the Telemonitoring dataset, the competitive algorithms all perform equally well, reaching a RMSE of approximately 4.797.",6. Experiments,[0],[0]
"BlockGreedy, however, uses significantly less computation for selecting prototypes.",6. Experiments,[0],[0]
"We used a budget of b = 500, and a block size of r = 25; a block size of r = 5 for this many prototypes impacted the log determinant estimation enough that it was only able to reach a RMSE of about 5.2.",6. Experiments,[0],[0]
"With the larger block size, BlockGreedy obtained a log determinant value within 0.5% of FullGreedy.
",6. Experiments,[0],[0]
"On the benchmark time series data set Santa Fe Data Set A, we train on the first 1000 time steps in the series and predict the next 100 steps, calculating the normalized MSE (NMSE), as stated in the original competition.",6. Experiments,[0],[0]
We set the width parameter and budget size to that used with KRLS after one iteration on the training set.,6. Experiments,[0],[0]
The NMSE of our algorithm and KRLS were 0.0434 and 0.026 respectively.,6. Experiments,[0],[0]
"While our method performs worse, note that KRLS actually runs on 6⇥ 1000 samples according to its description (Engel et al., 2004), but with 1000 samples it performs worse with a NMSE of 0.0661.",6. Experiments,[0],[0]
"We demonstrate the 100-step forecast with BlockGreedy, in Figure 2(c); we include forecast plots for the other algorithms in Figure 4, Appendix C.4.",6. Experiments,[0],[0]
"We developed a memory and computation efficient incremental algorithm, called BlockGreedy, to select centers for kernel representations in a continual learning setting.",7. Conclusion,[0],[0]
"We derived a criterion for prototype selection, and showed that the log-determinant is an instance of this criterion.",7. Conclusion,[0],[0]
"We extended results from streaming submodular maximization, to obtain an approximation ratio for OnlineGreedy.",7. Conclusion,[0],[0]
"We then derived the efficient variant, BlockGreedy, to take advantage of the block-diagonal structure of the kernel matrix, which enables separability of the criteria and faster local computations.",7. Conclusion,[0],[0]
"We demonstrated that, by taking advantage of this structure, BlockGreedy can significantly reduce computation without incurring much penalty in maximizing the log-determinant and maintaining competitive prediction performance.",7. Conclusion,[0],[0]
"Our goal within continual learning was to provide a principled, near-linear time algorithm for prototype selection, in terms of the number of prototypes.",7. Conclusion,[0],[0]
"We believe that BlockGreedy provides one of the first such algorithms, and is an important step towards effective kernel representations for continual learning settings, like online learning and reinforcement learning.",7. Conclusion,[0],[0]
"This research was supported in part by NSF CCF-1525024, IIS-1633215 and the Precision Health Initiative at Indiana University.",Acknowledgements,[0],[0]
We would also like to thank Inhak Hwang for helpful discussions.,Acknowledgements,[0],[0]
"Kernel representations provide a nonlinear representation, through similarities to prototypes, but require only simple linear learning algorithms given those prototypes.",abstractText,[0],[0]
"In a continual learning setting, with a constant stream of observations, it is critical to have an efficient mechanism for sub-selecting prototypes amongst observations.",abstractText,[0],[0]
"In this work, we develop an approximately submodular criterion for this setting, and an efficient online greedy submodular maximization algorithm for optimizing the criterion.",abstractText,[0],[0]
"We extend streaming submodular maximization algorithms to continual learning, by removing the need for multiple passes—which is infeasible—and instead introducing the idea of coverage time.",abstractText,[0],[0]
"We propose a general block-diagonal approximation for the greedy update with our criterion, that enables updates linear in the number of prototypes.",abstractText,[0],[0]
"We empirically demonstrate the effectiveness of this approximation, in terms of approximation quality, significant runtime improvements, and effective prediction performance.",abstractText,[0],[0]
Adapting Kernel Representations Online Using Submodular Maximization,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3285–3295 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3285",text,[0],[0]
"Continuous word representations have demonstrated utility in state-of-the-art neural models for several NLP tasks, such as named entity recognition (NER;Ma andHovy (2016)), machine reading (Tan et al., 2017), sentiment analysis (Tang et al., 2016; Yu et al., 2018), and machine translation (MT; Qi et al. (2018)).",1 Introduction,[0],[0]
"While the training of these word vectors does not rely on explicit human supervision, their quality is highly contingent on the size and quality of the unlabeled corpora available.",1 Introduction,[0],[0]
"There are over 7000 languages in the world (Hammarström et al., 2018), and corpora with sufficient size and coverage are available for just a handful, making it unclear how these methods will perform in the more common low-resource setting.
",1 Introduction,[0],[0]
"Disheartening though this high dependence on resources sounds, several efforts (Adams et al., 2017; Haghighi et al., 2008; Bharadwaj et al., 2016; Mayhew et al., 2017) have shown considerable performance gains across different tasks in the low resource setting by transferring knowledge from related high-resource languages.",1 Introduction,[0],[0]
"Most existing approaches for learning cross-lingual word embeddings (Ruder, 2017) either extend the monolingual objective function by adding a cross-lingual regularization objective which is then jointly optimized or use mapping-based approaches to align similar words across languages.",1 Introduction,[0],[0]
"These post-hoc coordination methods rely on bilingual lexicons or parallel corpora, which are typically of limited quantity and uncertain quality.
",1 Introduction,[0],[0]
"In this paper, we take a different task: focusing instead on the similarity of the surface forms, phonology, or morphology of the two transfer languages.",1 Introduction,[0],[0]
"Specifically, inspired by Ling et al. (2015), who demonstrate the effectiveness of character-level modeling for knowledge sharing in multilingual scenarios, we propose two approaches to transfer word embeddings using different types of linguistically-inspired subword-level information.",1 Introduction,[0],[0]
Both approaches focus on mapping the low resource language embeddings closer to those of the high resource language and are executed using two different training regimes.,1 Introduction,[0],[0]
"We explore the effect of different subword units— characters, lemmas, inflectional properties, and phonemes— as each one offers a unique linguistic insight, discussed more in Section 3.",1 Introduction,[0],[0]
"Our proposed approaches do require language specific resources, but importantly do not depend on crosslingual resources and achieve considerable performance gains over existing methods which do.
",1 Introduction,[0],[0]
"We evaluate our proposed approach on two downstream tasks: NER, which deals with detecting and classifying Named Entities (NEs) into pre-
defined categories (Nadeau and Sekine, 2007), and MT to English.",1 Introduction,[0],[0]
"For the purposes of error analysis and discussion, we focus on the NER task in particular.",1 Introduction,[0],[0]
"NEs are typically noun phrases and occur rarely in the corpus, making the generalization across types and domains difficult.",1 Introduction,[0],[0]
"We chose NER as our test bed because word vectors have a direct impact on NER model performance— as suggested by (Ruder, 2017) and observed by us in Table 3, where themodel without any pre-trained embeddings scores an average of 18 F1 points less.",1 Introduction,[0],[0]
"It thus provides a transparent way to measure the effectiveness of different subword units.
",1 Introduction,[0],[0]
"This paper makes the following contributions:
1.",1 Introduction,[0],[0]
We show that embeddings trained on subword representations yield better task performance than those trained only on whole words.,1 Introduction,[0],[0]
"This is especially true in a transfer setting, where subword representations also outperform a word alignment based method.",1 Introduction,[0],[0]
"We further show that embeddings trained onmorphological representations often outperform those trained only on whole words.
2.",1 Introduction,[0],[0]
"We demonstrate that training embeddings on character-based phonemic representations presents substantial performance advantages over training on orthographic characters in some transfer settings, e.g. when there are script differences across languages.",1 Introduction,[0],[0]
"These advantages are in addition to those from morphological representations (lemmas and morphological properties).
",1 Introduction,[0],[0]
3.,1 Introduction,[0],[0]
"We produce continuous representations for each subword unit, giving researchers the ability to use them in their own tasks as they see fit.",1 Introduction,[0],[0]
The code 1 for training word embeddings and the embeddings 2 which produced the best results are publicly available.,1 Introduction,[0],[0]
We also release morphological analyzers for Hindi and Bengali3.,1 Introduction,[0],[0]
"The two most popular training objectives for monolingual word embeddings are the skipgram and continuous-bag-of-words (CBOW), introduced by Mikolov et al. (2013a).",2 Skipgram Objective,[0],[0]
"The skipgram
1https://github.com/Aditi138/Embeddings 2https://github.com/Aditi138/Embeddings/
tree/master/embeddings_released 3https://github.com/dmort27/mstem
model attempts to predict the context surrounding a word, given the word itself whereas CBOW predicts the word given its context.",2 Skipgram Objective,[0],[0]
"Formally, given a corpus having a sequence of words 𝑤1, 𝑤2, ⋯ , 𝑤𝑇, the skip-grammodel maximizes the following loglikelihood:
𝑇
∑ 𝑖=1 ∑ 𝑣∈𝐶𝑖
log 𝑝(𝑣|𝑤𝑖) (1)
where 𝐶𝑖 are the context tokens, within a specified window of the focus word 𝑤𝑖 and 𝑝(𝑣|𝑤𝑖) is the probability of observing context word 𝑣 given focus word 𝑤𝑖.",2 Skipgram Objective,[0],[0]
"The skipgram was originally defined using the softmax function:
𝑝(𝑣|𝑤𝑖) = 𝑒𝑠(𝑣,𝑤𝑖)
∑𝑊𝑗=1 𝑒 𝑠(𝑤𝑖,𝑗)
(2)
where 𝑠 is a scoring function mapping 𝑣 and 𝑤𝑖 to ℝ. The summation in the denominator is over the entire vocabulary 𝑊 whichmakes this formulation computationally inefficient as cost of gradient computation is proportional to 𝑊 which is quite large (∼ 106).",2 Skipgram Objective,[0],[0]
"Mikolov et al. (2013b) hence employ negative sampling to make this computation efficient and robust (Levy et al., 2015) and give better representations for infrequent words4, which is crucial for the low resource settings.",2 Skipgram Objective,[0],[0]
"Negative sampling represents the above objective function (Equation 1) using a binary logistic loss as shown below:
𝑇
∑ 𝑖=1 ( ∑𝑤𝑐∈𝐶𝑖 𝑙(𝑠(𝑤𝑖, 𝑤𝑐))",2 Skipgram Objective,[0],[0]
"+ ∑ 𝑤𝑛∈𝑁𝑖 𝑙(−𝑠(𝑤𝑖, 𝑤𝑛)))",2 Skipgram Objective,[0],[0]
"(3)
where 𝑁𝑖 are the negative words sampled randomly from vocabulary and 𝑙 is the log-sigmoid function.",2 Skipgram Objective,[0],[0]
"The scoring function 𝑠 is a dot product similarity function given by 𝑠(𝑤𝑖, 𝑤𝑐) = u⊤𝑤𝑖v𝑤𝑐 where u𝑤𝑖 and v𝑤𝑐 are the embeddings of the focus word and its context word respectively.",2 Skipgram Objective,[0],[0]
Mikolov et al. (2013b)’s model fails to capture internal structure of words and does not generalize for out of vocabulary words that may share morphemes with in-vocabulary words.,3 Subword Representation,[0],[0]
"The problems of this method are particularly salient for
4https://code.google.com/archive/p/ word2vec/
morphologically rich languages such as Turkish, Uyghur, Hindi, and Bengali.",3 Subword Representation,[0],[0]
"Although, given a large enough training corpus, most or all morphological forms of a lexeme (of which there may be many) could theoretically learn to have similar vector representations, it will be vastly more data efficient if we can take into account regularities of their form to model morphology explicitly.",3 Subword Representation,[0],[0]
"We explore the following methods for doing so:
Orthographic units: Wieting et al. (2016) and Bojanowski et al. (2016) show the utility of character-level modeling by representing the focus word 𝑤𝑖 as a set of its character ngrams, denoted by u𝑤𝑖 = 1 |𝐺| ∑𝑔∈𝐺",3 Subword Representation,[0],[0]
"x𝑔, where 𝐺 is the set of character ngrams and x𝑔 is the vector representation of ngram 𝑔.",3 Subword Representation,[0],[0]
"Such representations capture morphological information in a brute-force but principled fashion—words that share the same morpheme are more likely to share the same character ngrams than words that do not.
",3 Subword Representation,[0],[0]
"Morphological units: Previous work has found that morphological relationships between words can be captured more directly if embeddings are trained on morphological representations (Luong et al., 2013; Botha and Blunsom, 2014; Cotterell and Schütze, 2015).",3 Subword Representation,[0],[0]
Avraham and Goldberg (2017) explicitly model lemmas (stems or citation forms) and morphological properties (the sets of which are sometimes called “tags”) for training the word embeddings.,3 Subword Representation,[0],[0]
Lemmas capture information about the lexical identity of a word and are closely correlated with the semantics of a word; tags capture information about the syntactic context of a word.,3 Subword Representation,[0],[0]
See Figure 1 for an example.,3 Subword Representation,[0],[0]
"We take inspiration from the above work in adapting these subword units for cross-lingual transfer.
",3 Subword Representation,[0],[0]
Phonological units: Subword units other than tags might seem to be of no use in closely-related languages with different scripts (such as Serbian and Croatian).,3 Subword Representation,[0],[0]
"Following Bharadwaj et al. (2016), we convert text from its orthographic form into a
phonemic representation, stated in terms of the International Phonetic Alphabet (IPA).",3 Subword Representation,[0],[0]
We then train embeddings on this representation.,3 Subword Representation,[0],[0]
"This means that, roughly speaking, morphemes that sound the same will be represented in the same way across languages.",3 Subword Representation,[0],[0]
In this section we discuss in detail both our approaches for cross-lingual transfer along with the relevant baselines.,4 Cross-lingual Transfer,[0],[0]
"We propose to use phoneme ngrams, represented using IPA, in addition to the lemma and morphological tags, to enable effective transfer across languages.",4.1 Proposed Approach,[0],[0]
Tsvetkov and Dyer (2016) demonstrate the effectiveness of projecting words from orthographic space to phonemic space as related languages often share similar phonological patterns.,4.1 Proposed Approach,[0],[0]
"More formally, let 𝑃𝑤 be the set of linguistic properties of a word consisting of the phoneme ngrams (I𝑔) , lemma (L) and individual morphological tags (M𝑚).",4.1 Proposed Approach,[0],[0]
"The focus word is then represented as the average sum of its linguistically motivated subword units:
v𝑤𝑐 = 1
|𝑃𝑤𝑐 | ∑𝑝∈𝑃𝑤𝑐 x𝑝
where x𝑝 is the vector representation of subword unit 𝑝 of word 𝑤𝑐. The average operation is important to remove any bias towards words having too many or too few subword units.",4.1 Proposed Approach,[0],[0]
"For instance, the Uyghur word in Figure 1 is represented using its phoneme-ngrams ranging from 3-grams to 6- grams, lemma and morphological tags as shown in Figure 2.",4.1 Proposed Approach,[0],[0]
"Avraham and Goldberg (2017) instead encode the different morphological inflections as one tag, so that Verb+Pot+Neg+Pres+A3sg would be encoded as 𝑥𝑉𝑒𝑟𝑏+𝑃𝑜𝑡+𝑁𝑒𝑔+𝑃𝑟𝑒𝑠+𝐴3𝑠𝑔. We encode each property in a tag separately to avoid data sparsity issues and empirically find this approach to perform better.
",4.1 Proposed Approach,[0],[0]
"We present two training regimes for transferring knowledge from a related language, namely CT-
Joint and CT-FineTune by explicitly incorporating the subword units.",4.1 Proposed Approach,[0],[0]
"We hypothesize that having word representations of both languages lying in a similar space will aid the low resource language in leveraging resources from the high resource language, including annotations for the downstream task.",4.1 Proposed Approach,[0],[0]
"These two regimes are described below:
CT-Joint: This model explicitly maps the word representations of the two languages into the same space by training simultaneously on both.",4.1 Proposed Approach,[0],[0]
"This is achieved simply by combining the corpora of both the high-resource and the low-resource language and training jointly using the skip-gram objective, discussed above.",4.1 Proposed Approach,[0],[0]
"The central intuition is as follows: once two related languages are placed in the same phonological and morphological space, they will share many subword units in common and this will make joint training profitable.",4.1 Proposed Approach,[0],[0]
"Duong et al. (2016) and Gouws et al. (2015) have previously shown the advantages of joint training and we observe this to be true in our case as well.
",4.1 Proposed Approach,[0],[0]
CT-FineTune: This model implicitly maps the word representations of the two languages into the same space.,4.1 Proposed Approach,[0],[0]
"The model attempts this by taking the learned continuous representations of the high resource subword units, referred to by x𝐻𝑖𝑆𝑊𝑈, and uses them to initialize the model for the low resource language.",4.1 Proposed Approach,[0],[0]
The model is first trained using all subword units on the high resource language and the learned representations are then used for initializing the subword units for the low resource language.,4.1 Proposed Approach,[0],[0]
"To elucidate which pretrained subword helped the most on the low resource language, we use the same model for different experiments, which is trained using all subword units—phoneme-ngrams, lemma and morphological properties.",4.1 Proposed Approach,[0],[0]
The linguistic intuition behind CTFineTune is similar to that behind CT-Joint.,4.1 Proposed Approach,[0],[0]
This idea of transferring parameters from high resource language has been previously explored by Zoph et al. (2016) for low resource neural machine translation which showed considerable improvement.,4.1 Proposed Approach,[0],[0]
"In this section, we first describe the model setup for training word embeddings followed by details on NER and MT experiments.",5 Evaluation,[0],[0]
"We base our model on the C++ implementation of fasttext5(Bojanowski et al., 2016) with modifications as described above.
",5.1 Implementation details,[0],[0]
Data:,5.1 Implementation details,[0],[0]
We represent a word in the training corpus using the format presented by Avraham and Goldberg (2017).,5.1 Implementation details,[0],[0]
"For instance, the Uyghur word in Figure 1 is represented as follows: phoneme ipa: qarijalmajdu, lemma l:qari, and morphological inflections m:Verb+Pot+Neg+Pres+A3sg.",5.1 Implementation details,[0],[0]
We consider phoneme-ngrams ranging from 3-grams to 6- grams and append a special start symbol < and end symbol > to the word.,5.1 Implementation details,[0],[0]
"We discard unigrams and bigram ngrams on the assumption that they don’t contribute much to the word.
",5.1 Implementation details,[0],[0]
Linguistic properties: We experiment with different subword units for both the transfer setting and the monolingual setting.,5.1 Implementation details,[0],[0]
"We use the orthography-to-IPA tool Epitran (Mortensen et al., 2018) to obtain the phonemic representations.",5.1 Implementation details,[0],[0]
The lemmas andmorphological properties for a word in context are obtained using a rule-based morphological analyzer in such a fashion as to produce tags similar to the high resource language.,5.1 Implementation details,[0],[0]
"For Turkish we use the morphological disambiguator developed by (Shen et al., 2016), which in turn is based on an FST-basedmorphological analyzer developed by Oflazer (1994).",5.1 Implementation details,[0],[0]
"For Uyghur, we took a (parser combinator based) morphological analyzer that had been developed for a DARPA LORELEI evaluation and modified it to output part-of-speech tags and to use a property set that was as close as possible to that of the Oflazer Turkish analyzer.",5.1 Implementation details,[0],[0]
"The analyzer for Turkish produces 116 inflectional properties and for Uyghur we get 54 properties, of which 64% are shared with Turkish.",5.1 Implementation details,[0],[0]
"Unfortunately, we did not have access to existing morphological analyzers for Hindi or Bengali.",5.1 Implementation details,[0],[0]
"Many Hindi morphological analyzers exist, but they are not typically released publicly (Malladi and Mannem, 2013; Goyal and Lehal, 2008).",5.1 Implementation details,[0],[0]
"We developed our own analyzers using a stemmer-like framework6 over a span of few weeks (2-3), which gave 8 unique morphological tags for Hindi and 10 for Bengali (for both languages, noun inflection only) of which just 2 were shared with Hindi.
",5.1 Implementation details,[0],[0]
"Morphologically speaking, we only use inflec5https://github.com/facebookresearch/
fastText/ 6https://github.com/dmort27/mstem
tional properties.",5.1 Implementation details,[0],[0]
"For most languages, we considered derivational affixes to be part of the stem, since they change the meaning and grammatical category of the word rather than simply expressing syntactic information.",5.1 Implementation details,[0],[0]
"An exception to this was Turkish, where the available morphological analyzer segments all affixes off from the root.",5.1 Implementation details,[0],[0]
"However, even there we confined our use ofmorphological properties to inflectional properties.",5.1 Implementation details,[0],[0]
"Derivational affixes display scopal behavior; since we wanted to treat the morphological properties of a word as a set, rather than a sequence, we were required to choose this option.
",5.1 Implementation details,[0],[0]
"Hyperparameters: During training, we consider context tokens within a window size 3 of the focus word and we sample 5 negative examples from the vocabulary.",5.1 Implementation details,[0],[0]
We chose a window size of only 3 based on the fact that we are working with morphologically rich languages with a relatively high information to token ratio (otherwise a window size of 5 may be more appropriate).,5.1 Implementation details,[0],[0]
"Subword units are initialized with uniform samples from [ −1𝑑𝑖𝑚 , 1 𝑑𝑖𝑚 ] where 𝑑𝑖𝑚 = 100.",5.1 Implementation details,[0],[0]
We use the same training regime as Bojanowski et al. (2016).,5.1 Implementation details,[0],[0]
"For CT-FineTune, instead of uniform samples we initialize the subword units of the low resource language from the learnt x𝐻𝑖𝑆𝑊𝑈.",5.1 Implementation details,[0],[0]
"For comparison, we train multilingual embeddings using MultiCCA (Ammar et al., 2016) as our baseline.",5.2 Baselines,[0],[0]
"It employs canonical correlation analysis by projecting multiple languages in the same shared space of one language, also referred to as multilanguage space.",5.2 Baselines,[0],[0]
This method learns linear projections for each language into this common language space using bilingual lexicons.,5.2 Baselines,[0],[0]
English is used as a common vector space due to availability of corresponding bilingual lexicons between English and each of our languages.,5.2 Baselines,[0],[0]
"For a fair comparison, we run MultiCCA on monolingual embed-
dings trained with different subword units.",5.2 Baselines,[0],[0]
"We use 100 dimension (Bojanowski et al., 2016) embeddings for English.
",5.2 Baselines,[0],[0]
"For NER, we also compare with Bharadwaj et al. (2016) who use a neural attention model over phonological features and report the best performance for Turkish using transfer from Uzbek and Uyghur, and Mayhew et al. (2017) who use a cheap translation method to translate training data from high-resource language into the lowresource language and report best NER results for Uyghur, as part of the LORELEI program.",5.2 Baselines,[0],[0]
"Our work differs from these primarily on two fronts: a) it is independent of the downstream task and can easily be adapted across various tasks, and b) it doesn’t require parallel corpora or bilingual dictionaries.",5.2 Baselines,[0],[0]
"For our monolingual experiments, we compare our proposed approach with models using subword representations—Bojanowski et al. (2016) and Avraham and Goldberg (2017).",5.2 Baselines,[0],[0]
"We use state-of-the-art NER architecture (Ma and Hovy, 2016) as our model for evaluation.",5.3 Named Entity Recognition Task,[0],[0]
The task is to identify NEs and categorize them into four types.,5.3 Named Entity Recognition Task,[0],[0]
"Since this is a supervised model, the performance is highly contingent on the quality of labeled data.",5.3 Named Entity Recognition Task,[0],[0]
F1 scores are used as the evaluation metric.,5.3 Named Entity Recognition Task,[0],[0]
"Weconduct the twomain sets of NER experiments,
1.",5.3.1 Experiments,[0],[0]
Transfer experiments on the low resource languages—Uyghur and Bengali—using Turkish and Hindi as the high resource languages respectively.,5.3.1 Experiments,[0],[0]
"We show results using both our proposed models, CT-Joint and CT-FineTune.
2.",5.3.1 Experiments,[0],[0]
"Monolingual experiments on all four languages: Uyghur, Turkish, Bengali and Hindi.",5.3.1 Experiments,[0],[0]
"We do an ablation study using different combinations of subword units.
",5.3.1 Experiments,[0],[0]
These language pairs were chosen partly out of convenience—the data were available to us as part of the DARPA LORELEI program—and partly because they satisfied certain deeper desiderata.,5.3.1 Experiments,[0],[0]
"Turkish andUyghur are fairly closely related to one another, as are Hindi and Bengali.",5.3.1 Experiments,[0],[0]
"Despite this relationship, the members of both pairs are written
in different scripts (Roman and Perso-Arabic; Devanagari and Bengali).",5.3.1 Experiments,[0],[0]
"Finally, all four languages are morphologically rich, especially Turkish and Uyghur.",5.3.1 Experiments,[0],[0]
"These qualities allow us to showcase the value of embeddings with subword units.
",5.3.1 Experiments,[0],[0]
"Data Preprocessing: We use data, comprised of unlabeled corpora, English bilingual dictionaries, annotations, from the Linguistic Data Consortium (LDC) language packs—Turkish and Hindi 7, Bengali8, from which we generate train-devtest splits.",5.3.1 Experiments,[0],[0]
"Uyghur data was released as part of LoReHLT16 task, organized by NIST 9 under the aegis of DARPA, and training annotations were acquired using native speakers as part of the task.",5.3.1 Experiments,[0],[0]
"For Uyghur we evaluate on an unsequestered set consisting of 199 annotated evaluation documents, released by NIST.",5.3.1 Experiments,[0],[0]
"For Turkish, Hindi and Bengali, we create our own train-dev-test splits (Table 1).",5.3.1 Experiments,[0],[0]
The exact documents from which Mayhew et al. (2017) and Bharadwaj et al. (2016) created their test set is not apparent.,5.3.1 Experiments,[0],[0]
The Uyghur corpus has 27 million tokens and the Turkish corpus has about 40 million tokens.,5.3.1 Experiments,[0],[0]
"Although Bengali is widely-spoken and the unlabeled corpus
7LDC2014E115,LDC2017E62,http://www.cfilt.",5.3.1 Experiments,[0],[0]
"iitb.ac.in/iitb_parallel/
8LDC2017E60, LDC2015E13 9https://www.nist.gov/
contains more than 140 million tokens, there are very few named entity annotations available, making it a low-resource language for the purposes of this exercise.",5.3.1 Experiments,[0],[0]
"To have a fair experimental setup across language pairs, we sub-sample the Bengali and Hindi corpora to have comparable corpus sizes with Uyghur and Turkish respectively.",5.3.1 Experiments,[0],[0]
"We also up-sample the low resource data for both unlabeled corpora and NER annotations, so the model doesn’t become biased towards the high resource language.
",5.3.1 Experiments,[0],[0]
"NER model setup: We train the model using 100-dimensional word embeddings, pre-trained using the above discussed strategies, and use hidden dimension of size 100 for each direction of the LSTM.",5.3.1 Experiments,[0],[0]
Stochastic gradient descent was used as the optimizer with a learning rate of 0.015.,5.3.1 Experiments,[0],[0]
Dropout of 0.5 was used in the LSTM layer to prevent over-fitting.,5.3.1 Experiments,[0],[0]
"Uyghur and Turkish were trained for 100 epochs, Bengali and Hindi converged after 70 epochs.",5.3.1 Experiments,[0],[0]
"Transfer Experiments: From Table 2 we note that our CT-Joint model trained with phonemengrams, lemma, and morphological tags outperforms the MultiCCA baseline by a significant margin.",5.3.2 Results and Discussion,[0],[0]
"MultiCCA strongly depends on
bilingual dictionaries which is possibly why it performs poorly in our low resource setting, where these dictionaries are not of high quality.",5.3.2 Results and Discussion,[0],[0]
The advantage of phoneme-ngrams over char-ngrams is quite apparent here.,5.3.2 Results and Discussion,[0],[0]
"phonemengrams+lemma+morph performs +5.2 F1 points better than char-ngram+lemma+morph for both Uyghur and Bengali, and similar increase is observed across other combinations, the only exception being the phoneme case for Uyghur which performed -0.5 F1 with respect to its counterpart word.
",5.3.2 Results and Discussion,[0],[0]
We find CT-Joint to be consistently better performing than CT-FineTune.,5.3.2 Results and Discussion,[0],[0]
"Interestingly, the performance of CT-FineTune model converges to the monolingual performance.",5.3.2 Results and Discussion,[0],[0]
"We hypothesize that the model forgets the pre-trained subword units as training progresses.
",5.3.2 Results and Discussion,[0],[0]
"For CT-FineTune, the column subword units in Table 2 refers to the subword units which were pretrained on a high resource related language.",5.3.2 Results and Discussion,[0],[0]
"For example lemma + morph means lemma andmorph embeddings are first pre-trained on the resoucerich language and then used to initialize the respective lemma and morph representations for the low resource language.
",5.3.2 Results and Discussion,[0],[0]
Monolingual Experiments: Table 3 shows our results on all languages.,5.3.2 Results and Discussion,[0],[0]
"We get +5.8 F1 points for Turkish, +4.8 F1 for Uyghur, +0.8 F1 for Hindi and +0.7 F1 for Bengali over the existing methods.",5.3.2 Results and Discussion,[0],[0]
"We observe that a combination of character-ngrams, lemma andmorphological properties gives the best performance for Uyghur and Bengali.",5.3.2 Results and Discussion,[0],[0]
"Adding morph hurts in Turkish, in contrast to Hindi, where it helps.",5.3.2 Results and Discussion,[0],[0]
"Section 5.3.3 discuses plausible reasons for this.
",5.3.2 Results and Discussion,[0],[0]
"We report official NIST scores on the full evaluation set for Uyghur, as part of LORELEI Offical Retest.",5.3.2 Results and Discussion,[0],[0]
"Additionally, we compare our results with
the best results reported on the same LORELEI dataset.",5.3.2 Results and Discussion,[0],[0]
Results are seen in Table 4.,5.3.2 Results and Discussion,[0],[0]
We plot recall curves for all languages.,5.3.3 Error analysis,[0],[0]
"As seen in Figure 3, adding subword units boosts the recall consistently across all languages, more so for Uyghur.",5.3.3 Error analysis,[0],[0]
"For Turkish, lemma performs better than lemma+morph, perhaps because the morphological analyzer outputs so many redundant properties which reduce the distance between words that are not particularly similar.",5.3.3 Error analysis,[0],[0]
"In contrast, morph helps and lemma hurts in Hindi, perhaps because the morph analyzer outputs only a small number of highly informative properties, but is a poor general-purpose lemmatizer.
",5.3.3 Error analysis,[0],[0]
"We analyze our results for Uyghur language, as it was part of the LORELEI challenge and presents a situation close to a real-life application.",5.3.3 Error analysis,[0],[0]
We base our analysis on the unsequestered set since annotations for full test data are not released.,5.3.3 Error analysis,[0],[0]
"There are 1,341 NE’s in this set, 396 of which are covered by the word embeddings when trained with just monolingual corpus.",5.3.3 Error analysis,[0],[0]
"One obvious advantage of jointly training with a resource-rich corpus is that coverage of NEs increases, as validated in our case where jointly training with Turkish corpus adds 114 more NEs.
",5.3.3 Error analysis,[0],[0]
"Figure 4 shows ten named entities in two different embeddings (CT-Joint: phoneme-
ngrams+lemma+morph and monolingual: char-ngram+lemma+morph).",5.3.3 Error analysis,[0],[0]
"The difference is striking—in the monolingual condition, the NEs are widely dispersed, but in the bilingual condition, the NEs cluster together.",5.3.3 Error analysis,[0],[0]
"This suggests that phonologically-mediated transfer through Turkish is resulting in embeddings in which NEs are close to one another, relative to monolingual Uyghur embeddings.",5.3.3 Error analysis,[0],[0]
"In addition to NER, we test the performance of our proposed approaches on the MT task to test generality of our conclusions.",5.4 Machine Translation Task,[0],[0]
"We use XNMT toolkit
(Neubig et al., 2018) to translate sentences from the low-resource language to English.",5.4 Machine Translation Task,[0],[0]
We run similar transfer and monolingual experiments as done for NER.,5.4 Machine Translation Task,[0],[0]
"Due to space limitations, we use select subword combinations for the experiments, details of which can be found in Appendix.",5.4 Machine Translation Task,[0],[0]
"BLEU is used as the evaluation metric.
",5.4 Machine Translation Task,[0],[0]
"From Table 6, we observe that the combination of character-ngrams and lemma performs the best for Uyghur (+0.1) and the combination of character-ngrams, lemma andmorph gives the best performance for Bengali (+1.7), over the word baseline, which demonstrates the importance of subword units for low-resource MT as well.",5.4 Machine Translation Task,[0],[0]
"One likely reason that the combination of characterngrams and lemmas consistently show the best performance is that, together, they capture lexical similarity, which is more important to translation than the syntactic information captured by morphological inflection (“morph”).",5.4 Machine Translation Task,[0],[0]
"However, experiments using CT-Joint and CT-FineTune (Table 5) do not follow the same trend as that of NER.",5.4 Machine Translation Task,[0],[0]
We hypothesize that this is because the MT models were trained on a training set that did not have translation pairs from the high resource language.,5.4 Machine Translation Task,[0],[0]
"As Qi et al. (2018) note, when training MT systems on a single language pair, it is less necessary for the embeddings to be coordinated across the languages.",5.4 Machine Translation Task,[0],[0]
"Word Embedding Models: Most algorithms for learning embeddings take inspiration from language modeling (Bengio et al., 2003), motivated by distributional hypothesis (Harris, 1954), and employ a shallow neural network to map the words into a low dimensional space.",6 Related Work,[0],[0]
"Pennington et al. (2014) built over the above local context window model by combining it with global matrix factorization (Levy and Goldberg, 2014).",6 Related Work,[0],[0]
"Recently, Peters et al. (2018) show significant gains across various tasks by learning word vectors as hidden states of a deep bi-directional language model.",6 Related Work,[0],[0]
"This was originally conceived for resource-abundant languages, hence it is as-of-yet unclear how generalizable they are to low-resource settings.
",6 Related Work,[0],[0]
Modeling subword information: Various methods have validated the importance of modeling subword units in downstream tasks.,6 Related Work,[0],[0]
"Xu et al. (2016); Chen et al. (2015) experiment at the character level whereas Luong et al. (2013) use morphemes as a basic unit in recursive neural
network (RNN) to get morphologically-aware word representations.",6 Related Work,[0],[0]
"Xu and Liu (2017) incorporate the morphemes’ meanings as part of the word representation to implicitly model the morphological knowledge.
",6 Related Work,[0],[0]
Transfer learning: Most recent works using transfer in low resource setting are coupled tightly with the downstream task.,6 Related Work,[0],[0]
Jin and Kann (2017) use morpheme units for cross-lingual transfer in a paradigm completion task using sequence-tosequence models.,6 Related Work,[0],[0]
Tsai et al. (2016) employ a language-independent method for NER by grounding non-English phrases to English Wikipedia.,6 Related Work,[0],[0]
"Interestingly, Kim et al. (2017) use separate encoders for modeling language-specific and languageagnostic features for part-of-speech (POS) tagging, and make use of no cross-lingual resources.",6 Related Work,[0],[0]
"In this paper, we explored two simple methods for cross-lingual transfer, both of which are taskindependent and use transfer learning for leveraging subword information from resource-rich languages, especially through phonological and morphological representations.",7 Conclusion,[0],[0]
"CT-Joint and CTFineTune do not require morphological analyzers, but we have found that even a morphological analyzer built in 2-3 weeks can boost performance and is a worthwhile investment of resources.",7 Conclusion,[0],[0]
Preliminary evaluation on a separate task of MT reconfirms the utility of subword units and further research will reveal what these learned subword representations can contribute to other tasks.,7 Conclusion,[0],[0]
This work is sponsored by Defense Advanced Research Projects Agency Information Innovation Office (I2O).,Acknowledgement,[0],[0]
Program: Low Resource Languages for Emergent Incidents (LORELEI).,Acknowledgement,[0],[0]
Issued by DARPA/I2O under Contract No. HR0011-15C0114.,Acknowledgement,[0],[0]
"The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Government.",Acknowledgement,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on.,Acknowledgement,[0],[0]
"Much work in Natural Language Processing (NLP) has been for resource-rich languages, making generalization to new, less-resourced languages challenging.",abstractText,[0],[0]
"We present two approaches for improving generalization to lowresourced languages by adapting continuous word representations using linguistically motivated subword units: phonemes, morphemes and graphemes.",abstractText,[0],[0]
Our method requires neither parallel corpora nor bilingual dictionaries and provides a significant gain in performance over previous methods relying on these resources.,abstractText,[0],[0]
"We demonstrate the effectiveness of our approaches onNamedEntity Recognition for four languages, namely Uyghur, Turkish, Bengali and Hindi, of which Uyghur and Bengali are low resource languages, and also perform experiments on Machine Translation.",abstractText,[0],[0]
Exploiting subwords with transfer learning gives us a boost of +15.2 NER F1 for Uyghur and +9.7 F1 for Bengali.,abstractText,[0],[0]
We also show improvements in the monolingual setting where we achieve (avg.),abstractText,[0],[0]
+3 F1 and (avg.),abstractText,[0],[0]
+1.35 BLEU.,abstractText,[0],[0]
Adapting Word Embeddings to New Languages with Morphological and Phonological Subword Representations,title,[0],[0]
"The alternating direction method of multipliers (ADMM) is a popular tool for solving problems of the form,
min u∈Rn,v∈Rm f(u) + g(v), subject to Au+Bv = b, (1)
",1. Introduction,[0],[0]
"where f : Rn → R and g : Rm → R are convex functions, A ∈ Rp×n, B ∈ Rp×m, and b ∈",1. Introduction,[0],[0]
"Rp. ADMM was first introduced in (Glowinski & Marroco, 1975) and (Gabay & Mercier, 1976), and has found applications in many optimization problems in machine learning, distributed computing and many other areas (Boyd et al., 2011).
",1. Introduction,[0],[0]
"Consensus ADMM (Boyd et al., 2011) solves minimization problems involving a composite objective f(v) =∑ i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al., 2011; Zhang & Kwok, 2014; Song et al., 2016; Chang et al., 2016; Goldstein et al., 2016; Taylor et al., 2016).",1. Introduction,[0],[0]
"To distribute this problem, consensus methods assign a separate copy of the unknowns, ui, to
1University of Maryland, College Park; 2United States Naval Academy, Annapolis; 3Instituto de Telecomunicações, IST, ULisboa, Portugal; 4Hong Kong Baptist University, Hong Kong.",1. Introduction,[0],[0]
"Correspondence to: Zheng Xu <xuzhustc@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"each worker, and then apply ADMM to solve
min ui∈Rd,v∈Rd N∑ i=1 fi(ui) + g(v), subject to ui = v, (2)
where v is the “central” copy of the unknowns, and g(v) is a regularizer.",1. Introduction,[0],[0]
The consensus problem (2) coincides with (1) by defining u = (u1; . . .,1. Introduction,[0],[0]
"; uN ) ∈ RdN , A = IdN ∈ RdN×dN , and B = −(Id; . . .",1. Introduction,[0],[0]
"; Id) ∈ RdN×d, where Id represents the d× d identity matrix.
",1. Introduction,[0],[0]
ADMM methods rely on a penalty parameter (stepsize) that is chosen by the user.,1. Introduction,[0],[0]
"In theory, ADMM converges for any constant penalty parameter (Eckstein & Bertsekas, 1992; He & Yuan, 2012; Ouyang et al., 2013).",1. Introduction,[0],[0]
"In practice, however, the efficiency of ADMM is highly sensitive to this parameter choice (Nishihara et al., 2015; Ghadimi et al., 2015), and can be improved via adaptive penalty selection methods (He et al., 2000; Song et al., 2016; Xu et al., 2017a).
",1. Introduction,[0],[0]
"One such approach, residual balancing (RB) (He et al., 2000), adapts the penalty parameter so that the residuals (derivatives of the Lagrangian with respect to primal and dual variables) have similar magnitudes.",1. Introduction,[0],[0]
"When the same penalty parameter is used across nodes, RB is known to converge, although without a known rate guarantee.",1. Introduction,[0],[0]
"A more recent approach, AADMM (Xu et al., 2017a), achieves impressive practical convergence speed on many applications, including consensus problems, with adaptive penalty parameters by estimating the local curvature of the dual functions.",1. Introduction,[0],[0]
"However, the dimension of the unknown variables in consensus problems grows with the number of distributed nodes, causing the curvature estimation to be inaccurate and unstable.",1. Introduction,[0],[0]
AADMM uses the same convergence analysis as RB.,1. Introduction,[0],[0]
"Consensus residual balancing (CRB) (Song et al., 2016) extends residual balancing to consensusbased ADMM for distributed optimization by balancing the local primal and dual residuals on each node.",1. Introduction,[0],[0]
"However, convergence guarantees for this method are fairly weak, and adaptive penalties need to be reset after several iterations to guarantee convergence.
",1. Introduction,[0],[0]
"We study the use of adaptive ADMM in the distributed setting, where different workers use different local algorithm parameters to accelerate convergence.",1. Introduction,[0],[0]
"We begin by studying the theory and provide convergence guarantees when
node-specific penalty parameters are used.",1. Introduction,[0],[0]
We demonstrate a O(1/k) convergence rate under mild conditions that is applicable for many forms of adaptive ADMM including all the above methods.,1. Introduction,[0],[0]
"Our theory is more general than the convergence guarantee in (He et al., 2000; Xu et al., 2017a) that only shows convergence when the scalar penalty parameter is adapted.",1. Introduction,[0],[0]
"Next, we propose an adaptive consensus ADMM (ACADMM) method to automate local algorithm parameters selection.",1. Introduction,[0],[0]
"Instead of estimating one global penalty parameter for all workers, different local penalty parameters are estimated using the local curvature of subproblems on each node.",1. Introduction,[0],[0]
"ADMM is known to have aO(1/k) convergence rate under mild conditions for convex problems (He & Yuan, 2012; 2015), while a O(1/k2) rate is possible when at least one of the functions is strongly convex or smooth (Goldfarb et al., 2013; Goldstein et al., 2014; Kadkhodaie et al., 2015; Tian & Yuan, 2016).",2. Related work,[0],[0]
"Linear convergence can be achieved with strong convexity assumptions (Davis & Yin, 2014; Nishihara et al., 2015; Giselsson & Boyd, 2016).",2. Related work,[0],[0]
"All of these results assume constant parameters; to the best of our knowledge, no convergence rate has been proven for ADMM with an adaptive penalty: (He et al., 2000; Xu et al., 2017b) proves convergence without providing a rate, and (Lin et al., 2011; Banert et al., 2016; Goldstein et al., 2015) prove convergence for some particular variants of ADMM (“linearized” or “preconditioned”).
",2. Related work,[0],[0]
"To improve practical convergence of ADMM, fixed optimal parameters are discussed in (Raghunathan & Di Cairano, 2014; Ghadimi et al., 2015; Nishihara et al., 2015; França & Bento, 2016).",2. Related work,[0],[0]
"These methods make strong assumptions about the objective and require information about the spectrum of A and/or B. Additionally, adaptive methods have been proposed; the most closely related work to our own is (Song et al., 2016), which extends the results of (He et al., 2000) to consensus problems, where communication is controlled by predefined network structure and the regularizer g(v) is absent.",2. Related work,[0],[0]
"In contrast to these methods, the proposed ACADMM extends the spectral penalty in (Xu et al., 2017a) to consensus problems and provides convergence theory that can be applied to a broad range of adaptive ADMM variants.",2. Related work,[0],[0]
"In the following, we use the subscript i to denote iterates computed on the ith node, superscript k is the iteration number, λki is the dual vector of Lagrange multipliers, and {τki } are iteration/worker-specific penalty parameters (contrasted with the single constant penalty parameter τ of
“vanilla” ADMM).",3. Consensus ADMM,[0],[0]
"Consensus methods apply ADMM to (2), resulting in the steps
uk+1i = arg minui fi(ui)",3. Consensus ADMM,[0],[0]
"+ τki 2 ‖vk − ui + λki τki ‖2 (3)
vk+1",3. Consensus ADMM,[0],[0]
= arg min v g(v),3. Consensus ADMM,[0],[0]
+ N∑ i=1 τki,3. Consensus ADMM,[0],[0]
2 ‖v,3. Consensus ADMM,[0],[0]
− uk+1i,3. Consensus ADMM,[0],[0]
+ λki τki ‖2 (4),3. Consensus ADMM,[0],[0]
λk+1i = λ k,3. Consensus ADMM,[0],[0]
i,3. Consensus ADMM,[0],[0]
+ τ,3. Consensus ADMM,[0],[0]
k,3. Consensus ADMM,[0],[0]
i (v k+1 − uk+1i ).,3. Consensus ADMM,[0],[0]
"(5)
The primal and dual residuals, rk and dk, are used to monitor convergence.
",3. Consensus ADMM,[0],[0]
"rk = r k 1
...",3. Consensus ADMM,[0],[0]
"rkN
 , dk = d k 1
... dkN
 , {rki = vk",3. Consensus ADMM,[0],[0]
− uki,3. Consensus ADMM,[0],[0]
dki,3. Consensus ADMM,[0],[0]
= τ k,3. Consensus ADMM,[0],[0]
i (v k−1 − vk).,3. Consensus ADMM,[0],[0]
"(6)
The primal residual rk approaches zero when the iterates accurately satisfy the linear constraints in (2), and the dual residual dk approaches zero as the iterates near a minimizer of the objective.",3. Consensus ADMM,[0],[0]
"Iteration can be terminated when
‖rk‖2",3. Consensus ADMM,[0],[0]
"≤ tol max{ ∑N
i=1 ‖uki",3. Consensus ADMM,[0],[0]
"‖2, N‖vk‖2} and ‖dk‖2 ≤ tol ∑N
i=1",3. Consensus ADMM,[0],[0]
‖λki,3. Consensus ADMM,[0],[0]
"‖2,
(7)
where tol is the stopping tolerance.",3. Consensus ADMM,[0],[0]
"The residuals in (6) and stopping criterion in (7) are adopted from the general problem (Boyd et al., 2011) to the consensus problem.",3. Consensus ADMM,[0],[0]
"The observation that residuals rk, dk can be decomposed into “local residuals” rki , d k",3. Consensus ADMM,[0],[0]
"i has been exploited to generalize the residual balancing method (He et al., 2000) for distributed consensus problems (Song et al., 2016).",3. Consensus ADMM,[0],[0]
We now study the convergence of ADMM with nodespecific adaptive penalty parameters.,4. Convergence analysis,[0],[0]
"We provide conditions on penalty parameters that guarantee convergence, and also a convergence rate.",4. Convergence analysis,[0],[0]
The issue of how to automatically tune penalty parameters effectively will be discussed in Section 5.,4. Convergence analysis,[0],[0]
"Let T k = diag(τk1 Id, . . .",4.1. Diagonal penalty parameters for ADMM,[0],[0]
", τ k NId) be a diagonal matrix containing non-negative penalty parameters on iteration k.",4.1. Diagonal penalty parameters for ADMM,[0],[0]
Define the norm ‖u‖2T = uTTu.,4.1. Diagonal penalty parameters for ADMM,[0],[0]
Using the notation defined above with u = (u1; . . .,4.1. Diagonal penalty parameters for ADMM,[0],[0]
"; uN ) ∈ RdN , we can rewrite the consensus ADMM steps (3)–(5) as
uk+1 = arg min u f(u) +",4.1. Diagonal penalty parameters for ADMM,[0],[0]
"〈−Au, λk〉
+ 1/2‖b−Au−Bvk‖2Tk (8)
vk+1 = arg min v g(v) +",4.1. Diagonal penalty parameters for ADMM,[0],[0]
"〈−Bv, λk〉
+ 1/2‖b−Auk+1 −Bv‖2Tk (9)
λk+1 = λk + T k(b−Auk+1 −Bvk+1).",4.1. Diagonal penalty parameters for ADMM,[0],[0]
"(10)
When using a diagonal penalty matrix, the generalized residuals become{
rk = b−Auk −Buk dk = ATT kB(vk − vk−1).",4.1. Diagonal penalty parameters for ADMM,[0],[0]
"(11)
",4.1. Diagonal penalty parameters for ADMM,[0],[0]
The sequel contains a convergence proof for generalized ADMM with adaptive penalty matrix T k.,4.1. Diagonal penalty parameters for ADMM,[0],[0]
"Our proof is inspired by the variational inequality (VI) approach in (He et al., 2000; He & Yuan, 2012; 2015).",4.1. Diagonal penalty parameters for ADMM,[0],[0]
Notation.,4.2. Preliminaries,[0],[0]
We use the following notation to simplify the discussions.,4.2. Preliminaries,[0],[0]
Define the combined variables y = (u; v) ∈,4.2. Preliminaries,[0],[0]
"Rn+m and z = (u; v;λ) ∈ Rn+m+p, and denote iterates as yk = (uk; vk) and zk = (uk; vk;λk).",4.2. Preliminaries,[0],[0]
Let y∗ and z∗ denote optimal primal/dual solutions.,4.2. Preliminaries,[0],[0]
Further define ∆z+k = (∆u + k ; ∆v,4.2. Preliminaries,[0],[0]
+ k ; ∆λ + k ),4.2. Preliminaries,[0],[0]
":= z
k+1 − zk and ∆z∗k = (∆u∗k; ∆v ∗ k; ∆λ ∗ k) :",4.2. Preliminaries,[0],[0]
= z ∗,4.2. Preliminaries,[0],[0]
− zk.,4.2. Preliminaries,[0],[0]
"Set
φ(y) = f(u) + g(v), F (z) =  −ATλ−BTλ",4.2. Preliminaries,[0],[0]
"Au+Bv − b  , Hk=
0 0 00",4.2. Preliminaries,[0],[0]
BTT kB 0 0 0,4.2. Preliminaries,[0],[0]
"(T k)−1 , Mk=",4.2. Preliminaries,[0],[0]
In 0 00,4.2. Preliminaries,[0],[0]
Im 0 0 −T kB Ip .,4.2. Preliminaries,[0],[0]
"Note that F (z) is a monotone operator satisfying ∀z, z′, (z − z′)T (F (z)",4.2. Preliminaries,[0],[0]
− F (z′)),4.2. Preliminaries,[0],[0]
≥ 0.,4.2. Preliminaries,[0],[0]
"We introduce intermediate variable z̃k+1 = (uk+1; vk+1; λ̂k+1), where λ̂k+1 = λk + T k(b−Auk+1 −Bvk).",4.2. Preliminaries,[0],[0]
"We thus have
∆z+k = M k(z̃k+1 − zk).",4.2. Preliminaries,[0],[0]
"(12)
Variational inequality formulation.",4.2. Preliminaries,[0],[0]
"The optimal solution z∗ of problem (1) satisfies the variational inequality (VI),
∀z, φ(y)− φ(y∗)",4.2. Preliminaries,[0],[0]
+ (z − z∗)TF (z∗) ≥ 0.,4.2. Preliminaries,[0],[0]
"(13)
From the optimality conditions for the sub-steps (8, 9), we see that yk+1 satisfies the variational inequalities
∀u, f(u)− f(uk+1) + (u− uk+1)T
(ATT k(Auk+1 +Bvk − b)−ATλk)",4.2. Preliminaries,[0],[0]
≥ 0,4.2. Preliminaries,[0],[0]
"(14)
∀v, g(v)− g(vk+1) + (v − vk+1)T
(BTT k(Auk+1 +Bvk+1 − b)−BTλk) ≥ 0, (15)
which can be combined as
φ(y)− φ(yk+1) +",4.2. Preliminaries,[0],[0]
(z − z̃k+1)T ( F (z̃k+1) +Hk∆z+k ) ≥ 0.,4.2. Preliminaries,[0],[0]
"(16)
Lemmas.",4.2. Preliminaries,[0],[0]
"We present several lemmas to facilitate the proof of our main convergence theory, which extend previous results regarding ADMM (He & Yuan, 2012; 2015) to ADMM with a diagonal penalty matrix.",4.2. Preliminaries,[0],[0]
"Lemma 1 shows the difference between iterates decreases as the iterates approach the true solution, while Lemma 2 implies a contraction in the VI sense.",4.2. Preliminaries,[0],[0]
Full proofs are provided in supplementary material; Eq. (17) and Eq.,4.2. Preliminaries,[0],[0]
"(18) are supported using equations (13, 15, 16) and standard techniques, while Eq. (19) is proven from Eq.",4.2. Preliminaries,[0],[0]
(18).,4.2. Preliminaries,[0],[0]
Lemma 2 is supported by the relationship in Eq.,4.2. Preliminaries,[0],[0]
(12).,4.2. Preliminaries,[0],[0]
Lemma 1.,4.2. Preliminaries,[0],[0]
"The optimal solution z∗ = (u∗; v∗;λ∗) and sequence zk = (uk; vk;λk) of generalized ADMM satisfy
(B∆v+k ) T∆λ+k ≥ 0, (17) ∆z∗k+1H",4.2. Preliminaries,[0],[0]
"k∆z+k ≥ 0, (18)
‖∆z+k ‖ 2 Hk ≤ ‖∆z ∗ k‖2Hk",4.2. Preliminaries,[0],[0]
− ‖∆z ∗ k+1‖2Hk .,4.2. Preliminaries,[0],[0]
"(19)
Lemma 2.",4.2. Preliminaries,[0],[0]
"The sequence z̃k = (uk; vk; λ̂k) and zk = (uk; vk;λk)T from generalized ADMM satisfy, ∀z,
(z̃k+1−z)THk∆z+k ≥ 1
2 (‖zk+1−z‖2Hk−‖z k−z‖2Hk ).",4.2. Preliminaries,[0],[0]
(20),4.2. Preliminaries,[0],[0]
We provide a convergence analysis of ADMM with an adaptive diagonal penalty matrix by showing (i) the norm of the residuals converges to zero; (ii) the method attains a worst-case ergodic O(1/k) convergence rate in the VI sense.,4.3. Convergence criteria,[0],[0]
"The key idea of the proof is to bound the adaptivity of T k so that ADMM is stable enough to converge, which is presented as the following assumption.",4.3. Convergence criteria,[0],[0]
Assumption 1.,4.3. Convergence criteria,[0],[0]
"The adaptivity of the diagonal penalty matrix T k = diag(τki , . . .",4.3. Convergence criteria,[0],[0]
", τ k p ) is bounded by
∞∑ k=1 (ηk)2 <∞, where (ηk)2 = max i∈{1,...,p} {(ηki )2},
(ηki ) 2 = max{τki /τk−1i",4.3. Convergence criteria,[0],[0]
"− 1, τ k−1 i /τ",4.3. Convergence criteria,[0],[0]
k,4.3. Convergence criteria,[0],[0]
i,4.3. Convergence criteria,[0],[0]
"− 1}.
(21)
We can apply Assumption 1 to verify that
1 1 + (ηk)2 ≤",4.3. Convergence criteria,[0],[0]
"τ
k",4.3. Convergence criteria,[0],[0]
"i
τk−1i ≤ 1 + (ηk)2. (22)
which is needed to prove Lemma 3.",4.3. Convergence criteria,[0],[0]
Lemma 3.,4.3. Convergence criteria,[0],[0]
Suppose Assumption 1 holds.,4.3. Convergence criteria,[0],[0]
"Then z = (u; v; λ) and z′ = (u′; v′; λ′) satisfy, ∀z, z′
‖z − z′‖2Hk ≤",4.3. Convergence criteria,[0],[0]
(1 + (η k)2)‖z − z′‖2Hk−1 .,4.3. Convergence criteria,[0],[0]
"(23)
Now we are ready to prove the convergence of generalized ADMM with adaptive penalty under Assumption 1.",4.3. Convergence criteria,[0],[0]
"We prove the following quantity, which is a norm of the residuals, converges to zero.
‖∆z+k ‖ 2 Hk =‖B∆v + k ‖ 2 Tk + ‖∆λ + k ‖ 2 (Tk)−1
=‖(ATT k)†dk‖2Tk + ‖r k‖2Tk ,
(24)
where A† denotes generalized inverse of a matrix A. Note that ‖∆z+k ‖2Hk converges to zero only if ‖r
k‖ and ‖dk‖ converge to zero, provided A and T k are bounded.
",4.3. Convergence criteria,[0],[0]
Theorem 1.,4.3. Convergence criteria,[0],[0]
Suppose Assumption 1 holds.,4.3. Convergence criteria,[0],[0]
"Then the iterates zk = (uk; vk;λk) of generalized ADMM satisfy
lim k→∞
‖∆z+k ‖ 2 Hk = 0.",4.3. Convergence criteria,[0],[0]
"(25)
Proof.",4.3. Convergence criteria,[0],[0]
"Let z = zk, z′ = z∗ in Lemma 3 to achieve
‖∆z∗k‖2Hk ≤ (1 + (η k)2)‖∆z∗k‖2Hk−1 .",4.3. Convergence criteria,[0],[0]
"(26)
Combine (26) with Lemma 1 (19) to get
‖∆z+k ‖ 2 Hk ≤ (1+(η k)2)‖∆z∗k‖2Hk−1−‖∆z ∗ k+1‖2Hk .",4.3. Convergence criteria,[0],[0]
"(27)
Accumulate (27) for k = 1 to l,
l∑ k=1",4.3. Convergence criteria,[0],[0]
l∏,4.3. Convergence criteria,[0],[0]
"t=k+1 (1 + (ηt)2)‖∆z+k ‖ 2 Hk ≤
l∏ t=1",4.3. Convergence criteria,[0],[0]
"(1 + (ηt)2)‖∆z∗1‖2H0 − ‖∆z∗l+1‖2Hl .
(28)
",4.3. Convergence criteria,[0],[0]
"Then we have
l∑ k=1 ‖∆z+k ‖ 2 Hk ≤ l∏ t=1 (1 + (ηt)2)‖∆z∗1‖2H0 .",4.3. Convergence criteria,[0],[0]
"(29)
When l → ∞, Assumption 1 suggests ∏∞ t=1(1",4.3. Convergence criteria,[0],[0]
"+
(ηt)2) < ∞, which means ∑∞",4.3. Convergence criteria,[0],[0]
k=1 ‖∆z,4.3. Convergence criteria,[0],[0]
+ k ‖2Hk,4.3. Convergence criteria,[0],[0]
<,4.3. Convergence criteria,[0],[0]
∞.,4.3. Convergence criteria,[0],[0]
"Hence limk→∞ ‖∆z+k ‖2Hk = 0.
",4.3. Convergence criteria,[0],[0]
"We further exploit Assumption 1 and Lemma 3 to prove Lemma 4, and combine VI (16), Lemma 2, and Lemma 4 to prove the O(1/k) convergence rate in Theorem 2.
",4.3. Convergence criteria,[0],[0]
Lemma 4.,4.3. Convergence criteria,[0],[0]
Suppose Assumption 1 holds.,4.3. Convergence criteria,[0],[0]
"Then z = (u; v;λ) ∈ Rm+n+p and the iterates zk = (uk; vk;λk) of generalized ADMM satisfy, ∀z
l∑",4.3. Convergence criteria,[0],[0]
k=1,4.3. Convergence criteria,[0],[0]
(‖z − zk‖2Hk − ‖z,4.3. Convergence criteria,[0],[0]
"− z k‖2Hk−1) ≤
CΣη C Π η",4.3. Convergence criteria,[0],[0]
"(‖z − z∗‖2H0 + ‖∆z∗1‖2H0) <∞,
(30)
where CΣη = ∑∞",4.3. Convergence criteria,[0],[0]
"k=1(η k)2, CΠη = ∏∞ t=1(1 + (η t)2).
",4.3. Convergence criteria,[0],[0]
Theorem 2.,4.3. Convergence criteria,[0],[0]
Suppose Assumption 1 holds.,4.3. Convergence criteria,[0],[0]
"Consider the sequence z̃k = (uk; vk; λ̂k) of generalized ADMM and define z̄l = 1l ∑l k=1 z̃
k.",4.3. Convergence criteria,[0],[0]
"Then sequence z̄l satisfies the convergence bound
φ(y)− φ(ȳl)",4.3. Convergence criteria,[0],[0]
+ (,4.3. Convergence criteria,[0],[0]
z − z̄l)TF (z̄l) ≥,4.3. Convergence criteria,[0],[0]
"− 1 2 l (‖z − z0‖2H0
+ CΣη C Π η ‖z − z∗‖2H0",4.3. Convergence criteria,[0],[0]
+,4.3. Convergence criteria,[0],[0]
CΣη CΠη ‖∆z∗1‖2H0).,4.3. Convergence criteria,[0],[0]
"(31)
Proof.",4.3. Convergence criteria,[0],[0]
"We can verify with simple algebra that
(z − z′)TF (z) =",4.3. Convergence criteria,[0],[0]
(z − z′)TF (z′).,4.3. Convergence criteria,[0],[0]
"(32)
Apply (32) with z′ = z̃k+1, and combine VI (16) and Lemma 2 to get
φ(y)− φ(yk+1) +",4.3. Convergence criteria,[0],[0]
(z − z̃k+1)TF (z) (33) =φ(y)− φ(yk+1) +,4.3. Convergence criteria,[0],[0]
(z − z̃k+1)TF (z̃k+1) (34) ≥(z̃k+1 − z)THk∆z+k (35),4.3. Convergence criteria,[0],[0]
≥1 2 (‖zk+1,4.3. Convergence criteria,[0],[0]
− z‖2Hk,4.3. Convergence criteria,[0],[0]
− ‖z k − z‖2Hk).,4.3. Convergence criteria,[0],[0]
"(36)
Summing for k = 0 to l − 1 gives us∑l k=1 φ(y)− φ(yk)",4.3. Convergence criteria,[0],[0]
+,4.3. Convergence criteria,[0],[0]
"(z − z̃k)TF (z)
≥1 2 ∑l k=1 (‖z − zk‖2Hk−1",4.3. Convergence criteria,[0],[0]
−,4.3. Convergence criteria,[0],[0]
‖z,4.3. Convergence criteria,[0],[0]
− z k−1‖2Hk−1).,4.3. Convergence criteria,[0],[0]
"(37)
Since φ(y) is convex, the left hand side of (37) satisfies,
LHS = l φ(y)− l∑
k=1
φ(yk)",4.3. Convergence criteria,[0],[0]
+,4.3. Convergence criteria,[0],[0]
(l z,4.3. Convergence criteria,[0],[0]
"− l∑
k=1
z̃k)TF (z)
≤",4.3. Convergence criteria,[0],[0]
l φ(y)− l φ(ȳl),4.3. Convergence criteria,[0],[0]
+,4.3. Convergence criteria,[0],[0]
(l z,4.3. Convergence criteria,[0],[0]
− l z̄l)TF (z).,4.3. Convergence criteria,[0],[0]
"(38)
Applying Lemma 4, we see the right hand side satisfies,
RHS = 1
2 l∑ k=1",4.3. Convergence criteria,[0],[0]
(‖z − zk‖2Hk − ‖z,4.3. Convergence criteria,[0],[0]
"− z k−1‖2Hk−1)+
1
2 l∑ k=1",4.3. Convergence criteria,[0],[0]
(‖z − zk‖2Hk−1,4.3. Convergence criteria,[0],[0]
− ‖z,4.3. Convergence criteria,[0],[0]
"− z k‖2Hk)
(39)
≥1 2 (‖z − zl‖2Hl − ‖z",4.3. Convergence criteria,[0],[0]
"− z 0‖2H0)+
− 1 2 CΣη C Π η (‖z − z∗‖2H0 + ‖∆z∗1‖2H0)
(40)
≥− 1 2 (‖z − z0‖2H0 + CΣη CΠη",4.3. Convergence criteria,[0],[0]
‖z,4.3. Convergence criteria,[0],[0]
"− z∗‖2H0+
CΣη C Π η ‖∆z∗1‖2H0).
",4.3. Convergence criteria,[0],[0]
"(41)
Combining inequalities (37), (38) and (41), and letting z′ = z̄k in (32) yields the O(1/k) convergence rate in (31)",4.3. Convergence criteria,[0],[0]
"To address the issue of how to automatically tune parameters on each node for optimal performance, we propose adaptive consensus ADMM (ACADMM), which sets worker-specific penalty parameters by exploiting curvature information.",5. Adaptive Consensus ADMM (ACADMM),[0],[0]
We derive our method from the dual interpretation of ADMM – Douglas-Rachford splitting (DRS) – using a diagonal penalty matrix.,5. Adaptive Consensus ADMM (ACADMM),[0],[0]
We then derive the spectral stepsizes for consensus problems by assuming the curvatures of the objectives are diagonal matrices with diverse parameters on different nodes.,5. Adaptive Consensus ADMM (ACADMM),[0],[0]
"At last, we discuss the practical computation of the spectral stepsizes from consensus ADMM iterates and apply our theory in Section 4 to guarantee convergence.",5. Adaptive Consensus ADMM (ACADMM),[0],[0]
"The dual form of problem (1) can be written
min λ∈Rp f∗(ATλ)− 〈λ, b〉︸ ︷︷ ︸ f̂(λ) +",5.1. Dual interpretation of generalized ADMM,[0],[0]
"g∗(BTλ)︸ ︷︷ ︸ ĝ(λ) , (42)
where λ denotes the dual variable, while f∗, g∗ denote the Fenchel conjugate of f, g (Rockafellar, 1970).",5.1. Dual interpretation of generalized ADMM,[0],[0]
"It is known that ADMM steps for the primal problem (1) are equivalent to performing Douglas-Rachford splitting (DRS) on the dual problem (42) (Eckstein & Bertsekas, 1992; Xu et al., 2017a).",5.1. Dual interpretation of generalized ADMM,[0],[0]
"In particular, the generalized ADMM iterates satisfy the DRS update formulas
0 ∈",5.1. Dual interpretation of generalized ADMM,[0],[0]
(T k)−1(λ̂k+1,5.1. Dual interpretation of generalized ADMM,[0],[0]
"− λk) + ∂f̂(λ̂k+1) + ∂ĝ(λk) (43)
0 ∈",5.1. Dual interpretation of generalized ADMM,[0],[0]
(T k)−1(λk+1,5.1. Dual interpretation of generalized ADMM,[0],[0]
− λk) + ∂f̂(λ̂k+1) +,5.1. Dual interpretation of generalized ADMM,[0],[0]
"∂ĝ(λk+1), (44)
where λ̂ denotes the intermediate variable defined in Section 4.2.",5.1. Dual interpretation of generalized ADMM,[0],[0]
We prove the equivalence of generalized ADMM and DRS in the supplementary material.,5.1. Dual interpretation of generalized ADMM,[0],[0]
Xu et al. (2017a) first derived spectral penalty parameters for ADMM using the DRS.,5.2. Generalized spectral stepsize rule,[0],[0]
"Proposition 1 in (Xu et al., 2017a) proved that the minimum residual of DRS can be obtained by setting the scalar penalty to τk = 1/ √ αβ, where we assume the subgradients are locally linear as
∂f̂(λ̂) = α λ̂+ Ψ and ∂ĝ(λ)",5.2. Generalized spectral stepsize rule,[0],[0]
"= β λ+ Φ, (45)
α, β ∈ R represent scalar curvatures, and Ψ,Φ ⊂",5.2. Generalized spectral stepsize rule,[0],[0]
"Rp.
We now present generalized spectral stepsize rules that can accomodate consensus problems.
",5.2. Generalized spectral stepsize rule,[0],[0]
Proposition 1 (Generalized spectral DRS).,5.2. Generalized spectral stepsize rule,[0],[0]
"Suppose the generalized DRS steps (43, 44) are used, and assume the subgradients are locally linear,
∂f̂(λ̂) = Mα λ̂+ Ψ and ∂ĝ(λ) = Mβ λ+ Φ. (46)
for matrices Mα = diag(α1Id, . . .",5.2. Generalized spectral stepsize rule,[0],[0]
", αNId) and Mβ = diag(β1Id, . . .",5.2. Generalized spectral stepsize rule,[0],[0]
", βNId),",5.2. Generalized spectral stepsize rule,[0],[0]
"and some Ψ,Φ ⊂",5.2. Generalized spectral stepsize rule,[0],[0]
Rp.,5.2. Generalized spectral stepsize rule,[0],[0]
"Then the minimal residual of f̂(λk+1) + ĝ(λk+1) is obtained by setting τki = 1/ √ αi βi, ∀i = 1, . . .",5.2. Generalized spectral stepsize rule,[0],[0]
", N .
Proof.",5.2. Generalized spectral stepsize rule,[0],[0]
"Substituting subgradients ∂f̂(λ̂), ∂ĝ(λ) into the generalized DRS steps (43, 44), and using our linear assumption (46) yields
0 ∈ (T k)−1(λ̂k+1",5.2. Generalized spectral stepsize rule,[0],[0]
− λk) +,5.2. Generalized spectral stepsize rule,[0],[0]
(Mα λ̂k+1 + Ψ),5.2. Generalized spectral stepsize rule,[0],[0]
+,5.2. Generalized spectral stepsize rule,[0],[0]
(Mβ λk + Φ),5.2. Generalized spectral stepsize rule,[0],[0]
0 ∈ (T k)−1(λk+1,5.2. Generalized spectral stepsize rule,[0],[0]
− λk) +,5.2. Generalized spectral stepsize rule,[0],[0]
(Mα λ̂k+1 + Ψ),5.2. Generalized spectral stepsize rule,[0],[0]
+,5.2. Generalized spectral stepsize rule,[0],[0]
"(Mβ λk+1 + Φ).
",5.2. Generalized spectral stepsize rule,[0],[0]
"Since T k,Mα,Mβ are diagonal matrices, we can split the equations into independent blocks, ∀i = 1, . . .",5.2. Generalized spectral stepsize rule,[0],[0]
", N,
0 ∈ (",5.2. Generalized spectral stepsize rule,[0],[0]
λ̂k+1i − λ k i )/τ,5.2. Generalized spectral stepsize rule,[0],[0]
k,5.2. Generalized spectral stepsize rule,[0],[0]
i + (αi λ̂ k+1 + Ψi) + (βi λ k + Φi) 0 ∈,5.2. Generalized spectral stepsize rule,[0],[0]
(λk+1i − λ k i )/τ,5.2. Generalized spectral stepsize rule,[0],[0]
k,5.2. Generalized spectral stepsize rule,[0],[0]
"i + (αi λ̂ k+1 + Ψi) + (βi λ k+1 + Φi).
",5.2. Generalized spectral stepsize rule,[0],[0]
"Applying Proposition 1 in (Xu et al., 2017a) to each block, τki = 1/ √ αi βi minimizes the block residual represented by rk+1DR,i = ‖(αi + βi)λk+1",5.2. Generalized spectral stepsize rule,[0],[0]
+,5.2. Generalized spectral stepsize rule,[0],[0]
"(ai + bi)‖, where ai ∈",5.2. Generalized spectral stepsize rule,[0],[0]
"Ψi, bi ∈ Φi.",5.2. Generalized spectral stepsize rule,[0],[0]
"Hence the residual norm at step k + 1, which is ‖(Mα +",5.2. Generalized spectral stepsize rule,[0],[0]
Mβ)λk+1,5.2. Generalized spectral stepsize rule,[0],[0]
+ (a + b)‖ = √∑N i=1(r k+1,5.2. Generalized spectral stepsize rule,[0],[0]
"DR,i) 2 is minimized by setting τki = 1/ √ αi βi, ∀i = 1, . . .",5.2. Generalized spectral stepsize rule,[0],[0]
", N .",5.2. Generalized spectral stepsize rule,[0],[0]
"Thanks to the equivalence of ADMM and DRS, Proposition 1 can also be used to guide the selection of the “optimal” penalty parameter.",5.3. Stepsize estimation for consensus problems,[0],[0]
"We now show that the generalized spectral stepsizes can be estimated from the ADMM iterates for the primal consensus problem (2), without explicitly supplying the dual functions.
",5.3. Stepsize estimation for consensus problems,[0],[0]
"The subgradients of dual functions ∂f̂ , ∂ĝ can be computed from the ADMM iterates using the identities derived from (8, 9),
Auk+1",5.3. Stepsize estimation for consensus problems,[0],[0]
− b ∈ ∂f̂(λ̂k+1) and Bvk+1 ∈ ∂ĝ(λk+1).,5.3. Stepsize estimation for consensus problems,[0],[0]
"(47)
For the consensus problem we have A = IdN , B = −(Id; . . .",5.3. Stepsize estimation for consensus problems,[0],[0]
"; Id), and b = 0, and so
(uk+11 ; . . .",5.3. Stepsize estimation for consensus problems,[0],[0]
"; u k+1 N ) ∈ ∂f̂(λ̂ k+1) (48)
−(vk+1; . . .",5.3. Stepsize estimation for consensus problems,[0],[0]
; vk+1︸ ︷︷ ︸ N duplicates of vk+1 ) ∈ ∂ĝ(λk+1).,5.3. Stepsize estimation for consensus problems,[0],[0]
"(49)
If we approximate the behavior of these sub-gradients using the linear approximation (46), and break the subgradients into blocks (one for each worker node), we get (omitting iteration index k for clarity)
ui =",5.3. Stepsize estimation for consensus problems,[0],[0]
αi λ̂i,5.3. Stepsize estimation for consensus problems,[0],[0]
"+ ai and − v = βi λi + bi, ∀i (50)
where αi and βi represent the curvature of local functions f̂i and ĝi on the ith node.
",5.3. Stepsize estimation for consensus problems,[0],[0]
"We select stepsizes with a two step procedure, which follows the spectral stepsize literature.",5.3. Stepsize estimation for consensus problems,[0],[0]
"First, we estimate the local curvature parameters, αi and βi, by finding leastsquares solutions to (50).",5.3. Stepsize estimation for consensus problems,[0],[0]
"Second, we plug these curvature estimates into the formula τki = 1/ √ αi βi.",5.3. Stepsize estimation for consensus problems,[0],[0]
"This formula produces the optimal stepsize when f̂ and ĝ are well approximated by a linear function, as shown in Proposition 1.
",5.3. Stepsize estimation for consensus problems,[0],[0]
"For notational convenience, we work with the quantities α̂ki = 1/αi, β̂",5.3. Stepsize estimation for consensus problems,[0],[0]
"k i = 1/βi, which are estimated on each node using the current iterates uki , v k, λki , λ̂",5.3. Stepsize estimation for consensus problems,[0],[0]
k,5.3. Stepsize estimation for consensus problems,[0],[0]
"i and also an older iterate uk0i , v k0 , λk0i , λ̂",5.3. Stepsize estimation for consensus problems,[0],[0]
"k0 i , k0 < k.",5.3. Stepsize estimation for consensus problems,[0],[0]
Defining,5.3. Stepsize estimation for consensus problems,[0],[0]
∆u k,5.3. Stepsize estimation for consensus problems,[0],[0]
"i = uki − u k0 i , ∆λ̂",5.3. Stepsize estimation for consensus problems,[0],[0]
k i = λ̂ k,5.3. Stepsize estimation for consensus problems,[0],[0]
i − λ̂,5.3. Stepsize estimation for consensus problems,[0],[0]
"k0 i and following the literature for Barzilai-Borwein/spectral stepsize estimation, there are two least squares estimators that can be obtained from (50):
α̂kSD,i = 〈∆λ̂ki ,∆λ̂ki 〉 〈∆uki ,∆λ̂ki 〉 and α̂kMG,i = 〈∆uki ,∆λ̂k〉 〈∆uki ,∆uki 〉 (51)
where SD stands for steepest descent, and MG stands for minimum gradient.",5.3. Stepsize estimation for consensus problems,[0],[0]
"(Zhou et al., 2006) recommend using a hybrid of these two estimators, and choosing
α̂ki =
{ α̂kMG,i",5.3. Stepsize estimation for consensus problems,[0],[0]
"if 2 α̂ k MG,i > α̂ k SD,i
α̂kSD,i − α̂kMG,i/2 otherwise.",5.3. Stepsize estimation for consensus problems,[0],[0]
"(52)
It was observed that this choice worked well for nondistributed ADMM in (Xu et al., 2017a).",5.3. Stepsize estimation for consensus problems,[0],[0]
"We can similarly estimate β̂ki from ∆v k = −vk + vk0 and ∆λki = λki −λ k0 i .
",5.3. Stepsize estimation for consensus problems,[0],[0]
"ACADMM estimates the curvatures in the original ddimensional feature space, and avoids estimating the curvature in the higher Nd-dimensional feature space (which grows with the number of nodes N in AADMM (Xu et al., 2017a)), which is especially useful for heterogeneous data with different distributions allocated to different nodes.",5.3. Stepsize estimation for consensus problems,[0],[0]
"The overhead of our adaptive scheme is only a few inner products, and the computation is naturally distributed on different workers.",5.3. Stepsize estimation for consensus problems,[0],[0]
Spectral stepsizes for gradient descent methods are equipped with safeguarding strategies like backtracking line search to handle inaccurate curvature estimation and to guarantee convergence.,5.4. Safeguarding and convergence,[0],[0]
"To safeguard the proposed spectral penalty parameters, we check whether our linear subgradient assumption is reasonable before updating the stepsizes.",5.4. Safeguarding and convergence,[0],[0]
"We do this by testing that the correlations
αkcor,i = 〈∆uki ,∆λ̂ki 〉 ‖∆uki ‖ ‖∆λ̂ki ‖ and βkcor,i = 〈∆vk,∆λki 〉 ‖∆vk‖ ‖∆λki ‖ , (53)
are bounded away from zero by a fixed threshold.",5.4. Safeguarding and convergence,[0],[0]
"We also bound changes in the penalty parameter by (1 +Ccg/k2) according to Assumption 1, which was shown in Theorem 1
Algorithm 1 Adaptive consensus ADMM (ACADMM)
",5.4. Safeguarding and convergence,[0],[0]
"Input: initialize v0, λ0i , τ0i , k0 =0, 1: while not converge by (7) and k < maxiter do 2: Locally update uki on each node by (3) 3: Globally update vk on central server by (4) 4: Locally update dual variable λki on each node by (5) 5: if mod(k, Tf ) = 1 then 6: Locally update λ̂ki = λ k−1 i",5.4. Safeguarding and convergence,[0],[0]
+ τ,5.4. Safeguarding and convergence,[0],[0]
k,5.4. Safeguarding and convergence,[0],[0]
"i (v
k−1 − uki ) 7: Locally compute spectral stepsizes α̂ki , β̂",5.4. Safeguarding and convergence,[0],[0]
"k i 8: Locally estimate correlations αkcor,i , β k cor,i
9: Locally update τk+1i using (54) 10:",5.4. Safeguarding and convergence,[0],[0]
"k0 ← k 11: else 12: τk+1i ← τki 13: end if 14: k ← k + 1 15: end while
and Theorem 2 to guarantee convergence.",5.4. Safeguarding and convergence,[0],[0]
"The final safeguarded ACADMM rule is
τ̂k+1i =  ",5.4. Safeguarding and convergence,[0],[0]
√ α̂ki β̂,5.4. Safeguarding and convergence,[0],[0]
k,5.4. Safeguarding and convergence,[0],[0]
"i if α k cor,i > cor and βkcor,i > cor α̂ki if α k cor,i > cor and βkcor,i ≤ cor β̂ki if α k cor,i ≤ cor and βkcor,i > cor
τki otherwise,
τk+1i = max{min{τ̂ k+1",5.4. Safeguarding and convergence,[0],[0]
"i , (1 + Ccg k2 )τki } , τki 1 + Ccg/k2 }.
(54)
",5.4. Safeguarding and convergence,[0],[0]
The complete adaptive consensus ADMM is shown in Algorithm 1.,5.4. Safeguarding and convergence,[0],[0]
"We suggest updating the stepsize every Tf = 2 iterations, fixing the safeguarding threshold cor = 0.2, and choosing a large convergence constant Ccg = 1010.",5.4. Safeguarding and convergence,[0],[0]
"We now study the performance of ACADMM on benchmark problems, and compare to other methods.",6. Experiments & Applications,[0],[0]
"Our experiments use the following test problems that are commonly solved using consensus methods.
",6.1. Applications,[0],[0]
Linear regression with elastic net regularizer.,6.1. Applications,[0],[0]
"We consider consensus formulations of the elastic net (Zou & Hastie, 2005) with fi and g defined as,
fi(ui)",6.1. Applications,[0],[0]
"= 1
2 ‖Diui",6.1. Applications,[0],[0]
"− ci‖2, g(v) = ρ1|v|+ ρ2 2 ‖v‖2, (55)
where Di ∈ Rni×m is the data matrix on node i, and ci is a vector of measurements.
",6.1. Applications,[0],[0]
"Sparse logistic regression with `1 regularizer can be written in the consensus form for distributed computing,
fi(ui)",6.1. Applications,[0],[0]
"= ni∑ j=1 log(1 + exp(−ci,jDTi,jui)), g(v) = ρ|v| (56)
",6.1. Applications,[0],[0]
"where Di,j ∈",6.1. Applications,[0],[0]
"Rm is the jth sample, and ci,j ∈ {−1, 1} is the corresponding label.",6.1. Applications,[0],[0]
"The minimization sub-step (3) in this case is solved by L-BFGS (Liu & Nocedal, 1989).
",6.1. Applications,[0],[0]
"Support Vector Machines (SVMs) minimize the distributed objective function (Goldstein et al., 2016)
fi(ui)",6.1. Applications,[0],[0]
"= C ni∑ j=1 max{1− ci,jDTi,jui, 0}, g(v) = 1 2 ‖v‖22 (57)
",6.1. Applications,[0],[0]
"where Di,j ∈",6.1. Applications,[0],[0]
"Rm is the jth sample on the ith node, and ci,j ∈ {−1, 1} is its label.",6.1. Applications,[0],[0]
"The minimization (3) is solved by dual coordinate ascent (Chang & Lin, 2011).
",6.1. Applications,[0],[0]
"Semidefinite programming (SDP) can be distributed as,
fi(Ui) = ι{Di(Ui) = ci}, g(v) = 〈F, V 〉+ ι{V 0} (58)
where ι{S} is a characteristic function that is 0 if condition S is satisfied and infinity otherwise.",6.1. Applications,[0],[0]
V 0 indicates that V is positive semidefinite.,6.1. Applications,[0],[0]
"V, F, Di,j ∈ Rn×n are symmetric matrices, 〈X,Y 〉 = trace(XTY ) denotes the inner product of X and Y , and Di(X) =",6.1. Applications,[0],[0]
"(〈Di,1, X〉; . . .",6.1. Applications,[0],[0]
"; 〈Di,mi , X〉).",6.1. Applications,[0],[0]
We test the problems in Section 6.1 with synthetic and real datasets.,6.2. Experimental Setup,[0],[0]
The number of samples and features are specified in Table 1.,6.2. Experimental Setup,[0],[0]
"Synthetic1 contains samples from a normal distribution, and Synthetic2 contains samples from a
mixture of 10 random Gaussians.",6.2. Experimental Setup,[0],[0]
Synthetic2 is heterogeneous because the data block on each individual node is sampled from only 1 of the 10 Gaussians.,6.2. Experimental Setup,[0],[0]
"We also acquire large empirical datasets from the LIBSVM webpage (Liu et al., 2009), as well as MNIST digital images (LeCun et al., 1998), and CIFAR10 object images (Krizhevsky & Hinton, 2009).",6.2. Experimental Setup,[0],[0]
"For binary classification tasks (SVM and logreg), we equally split the 10 category labels of MNIST and CIFAR into “positive” and “negative” groups.",6.2. Experimental Setup,[0],[0]
"We use a graph from the Seventh DIMACS Implementation Challenge on Semidefinite and Related Optimization Problems following (Burer & Monteiro, 2003) for Semidefinite Programming (SDP).",6.2. Experimental Setup,[0],[0]
"The regularization parameter is fixed at ρ = 10 in all experiments.
",6.2. Experimental Setup,[0],[0]
"Consensus ADMM (CADMM) (Boyd et al., 2011), residual balancing (RB-ADMM) (He et al., 2000), adaptive ADMM (AADMM) (Xu et al., 2017a), and consensus residual balancing (CRB-ADMM) (Song et al., 2016) are implemented and reported for comparison.",6.2. Experimental Setup,[0],[0]
Hyperparameters of these methods are set as suggested by their creators.,6.2. Experimental Setup,[0],[0]
The initial penalty is fixed at τ0 = 1 for all methods unless otherwise specified.,6.2. Experimental Setup,[0],[0]
Table 1 reports the convergence speed in iterations and wall-clock time (secs) for various test cases.,6.3. Convergence results,[0],[0]
These experiments are performed with 128 cores on a Cray XC-30 supercomputer.,6.3. Convergence results,[0],[0]
CADMM with default penalty τ = 1,6.3. Convergence results,[0],[0]
"(Boyd et al., 2011) is often slow to converge.",6.3. Convergence results,[0],[0]
"ACADMM outperforms the other ADMM variants on all the real-world
datasets, and is competitive with AADMM on two homogeneous synthetic datasets where the curvature may be globally estimated with a scalar.
",6.3. Convergence results,[0],[0]
ACADMM is more reliable than AADMM since the curvature estimation becomes difficult for high dimensional variables.,6.3. Convergence results,[0],[0]
"RB is relatively stable but sometimes has difficulty finding the exact optimal penalty, as the adaptation can stop because the difference of residuals are not significant enough to trigger changes.",6.3. Convergence results,[0],[0]
RB does not change the initial penalty in several experiments such as logistic regression on RCV1.,6.3. Convergence results,[0],[0]
"CRB achieves comparable results with RB, which suggests that the relative sizes of local residuals may not always be very informative.",6.3. Convergence results,[0],[0]
ACADMM significantly boosts AADMM and the local curvature estimations are helpful in practice.,6.3. Convergence results,[0],[0]
Fig.,6.4. Robustness and sensitivity,[0],[0]
1a shows that the practical convergence of ADMM is sensitive to the choice of penalty parameter.,6.4. Robustness and sensitivity,[0],[0]
"ACADMM is robust to the selection of the initial penalty parameter and achieves promising results for both homogeneous and heterogeneous data, comparable to ADMM with a fine-tuned penalty parameter.
",6.4. Robustness and sensitivity,[0],[0]
We study scalability of the method by varying the number of workers and training samples (Fig. 1b).,6.4. Robustness and sensitivity,[0],[0]
ACADMM is fairly robust to the scaling factor.,6.4. Robustness and sensitivity,[0],[0]
"AADMM occasion-
",6.4. Robustness and sensitivity,[0],[0]
"ally performs well when small numbers of nodes are used, while ACADMM is much more stable.",6.4. Robustness and sensitivity,[0],[0]
"RB and CRB are more stable than AADMM, but cannot compete with ACADMM.",6.4. Robustness and sensitivity,[0],[0]
Fig.,6.4. Robustness and sensitivity,[0],[0]
"1c (bottom) presents the acceleration in (wall-clock secs) achieved by increasing the number of workers.
",6.4. Robustness and sensitivity,[0],[0]
"Finally, ACADMM is insensitive to the safeguarding hyper-parameters, correlation threshold cor and convergence constant Ccg.",6.4. Robustness and sensitivity,[0],[0]
"Though tuning these parameters may further improve the performance, the fixed default values generally perform well in our experiments and enable ACADMM to run without user oversight.",6.4. Robustness and sensitivity,[0],[0]
"In further experiments in the supplementary material, we also show that ACADMM is fairly insensitive to the regularization parameter ρ in our classification/regression models.",6.4. Robustness and sensitivity,[0],[0]
"We propose ACADMM, a fully automated algorithm for distributed optimization.",7. Conclusion,[0],[0]
Numerical experiments on various applications and real-world datasets demonstrate the efficiency and robustness of ACADMM.,7. Conclusion,[0],[0]
We also prove a O(1/k) convergence rate for ADMM with adaptive penalties under mild conditions.,7. Conclusion,[0],[0]
"By automating the selection of algorithm parameters, adaptive methods make distributed systems more reliable, and more accessible to users that lack expertise in optimization.",7. Conclusion,[0],[0]
"ZX , GT, HL and TG were supported by the US Office of Naval Research under grant N00014-17-1-2078 and by the US National Science Foundation (NSF) under grant CCF1535902.",Acknowledgements,[0],[0]
GT was partially supported by the DOD High Performance Computing Modernization Program.,Acknowledgements,[0],[0]
"MF was partially supported by the Fundação para a Ciência e Tecnologia, grant UID/EEA/5008/2013.",Acknowledgements,[0],[0]
XY was supported by the General Research Fund from Hong Kong Research Grants Council under grant HKBU-12313516.,Acknowledgements,[0],[0]
"The alternating direction method of multipliers (ADMM) is commonly used for distributed model fitting problems, but its performance and reliability depend strongly on userdefined penalty parameters.",abstractText,[0],[0]
We study distributed ADMM methods that boost performance by using different fine-tuned algorithm parameters on each worker node.,abstractText,[0],[0]
"We present a O(1/k) convergence rate for adaptive ADMM methods with node-specific parameters, and propose adaptive consensus ADMM (ACADMM), which automatically tunes parameters without user oversight.",abstractText,[0],[0]
Adaptive Consensus ADMM for Distributed Optimization,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 576–581 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
576",text,[0],[0]
"Question-answering (QA) systems proceed by following a two-staged process (Belkin, 1993): in a first step, a module for document retrieval selects n potentially relevant documents from a given corpus.",1 Introduction,[0],[0]
"Subsequently, a machine comprehension module extracts the final answer from the previously-selected documents.",1 Introduction,[0],[0]
"The latter step often involves hand-written rules or machine learning classifiers (c. f. Shen and Klakow, 2006; Kaisser and Becker, 2004), and recently also deep neural networks (e. g. Chen et al., 2017; Wang et al., 2018)
",1 Introduction,[0],[0]
The number of candidate documents n affects the interplay between both document retrieval and machine comprehension component.,1 Introduction,[0],[0]
"A larger n improves the recall of document retrieval and thus the chance of including the relevant information.
",1 Introduction,[0],[0]
"However, this also increases the noise and might adversely reduce the accuracy of answer extraction.",1 Introduction,[0],[0]
"It was recently shown that a top-1 system can potentially outperform a system selecting more than one document (Kratzwald and Feuerriegel, 2018).",1 Introduction,[0],[0]
"This finding suggests that a static choice of n can result a suboptimal performance.
",1 Introduction,[0],[0]
Contributions.,1 Introduction,[0],[0]
This work analyzes the interplay between document retrieval and machine comprehension inside neural QA systems.,1 Introduction,[0],[0]
We first reason numerically why a fixed choice of n in document retrieval can negatively affect the performance of question answering.,1 Introduction,[0],[0]
We thus propose a novel machine learning model that adaptively selects the optimal ni for each document retrieval.,1 Introduction,[0],[0]
The resulting system outperforms state-of-the-art neural question answering on multiple benchmark datasets.,1 Introduction,[0],[0]
"Notably, the overall size of the corpus affects the optimal n considerably and, as a result, our system evinces as especially superior over a fixed n in settings where the corpus size is unknown or grows dynamically.",1 Introduction,[0],[0]
Taxonomy of QA systems.,2 Related Work,[0],[0]
Question answering systems are frequently categorized into two main paradigms.,2 Related Work,[0],[0]
"On the one hand, knowledge-based systems draw upon manual rules, ontologies and large-scale knowledge graphs in order to deduce answers (e. g. Berant et al., 2013; Lopez et al., 2007; Unger et al., 2012).",2 Related Work,[0],[0]
"On the other hand, QA system incorporate a document retrieval module which selects candidate documents based on a chosen similarity metric, while a subsequent module then processes these in order to extract the answer (e. g. Cao et al., 2011; Harabagiu et al., 2000).
",2 Related Work,[0],[0]
Deep QA.,2 Related Work,[0],[0]
"Recently, Chen et al. (2017) developed a state-of-the-art deep QA system, where the
answer is extracted from the top n = 5 documents.",2 Related Work,[0],[0]
This choice stems from computing the dot product between documents and a query vector; with tf-idf weighting of hashed bi-gram counts.,2 Related Work,[0],[0]
"Wang et al. (2018) extended this approach by implementing a neural re-ranking of the candidate document, yet keeping the fixed number of n selected documents unchanged.",2 Related Work,[0],[0]
"In particular, the interplay between both modules for document retrieval and machine comprehension has not yet been studied.",2 Related Work,[0],[0]
"This especially pertains to the number of candidate documents, n, that should be selected during document retrieval.
",2 Related Work,[0],[0]
Component interactions.,2 Related Work,[0],[0]
"Extensive research has analyzed the interplay of both document retrieval and machine comprehension in the context of knowledge-based systems (c. f. Moldovan et al., 2003) and even retrieval-based systems with machine learning (c. f. Brill et al., 2002).",2 Related Work,[0],[0]
"However, these findings do not translate to machine comprehension with deep learning.",2 Related Work,[0],[0]
"Deep neural networks consist of a complex attention mechanism for selecting the context-specific answer (Hermann et al., 2015) that has not been available to traditional machine learning and, moreover, deep learning is highly sensitive to settings involving multiple input paragraphs, often struggling with selecting the correct answer (Clark and Gardner, 2017).",2 Related Work,[0],[0]
"In the following, we provide empirical evidence why a one-fits-all n can be suboptimal.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"For this
purpose, we run a series of experiments in order to obtain a better understanding of the interplay between document retrieval and machine comprehension modules.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"That is, we specifically compare the recall of document retrieval to the end-toend performance of the complete QA system; see Fig. 1.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"Our experiments study the sensitivity along two dimensions: on the one hand, we change the number of top-n documents that are returned during document retrieval and, on the other hand, we vary the corpus size.
",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
Our experiments utilize the TREC QA dataset as a well-established benchmark for open-domain question answering.,3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
It contains 694 questionanswer pairs that are answered with the help of Wikipedia.,3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
We vary the corpus between a small case (where each question-answer pair contains only one Wikipedia article with the correct answer plus 50 % articles as noise) and the complete Wikipedia dump containing more than five million documents.,3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"Our experiments further draw upon the DrQA system (Chen et al., 2017) for question answering that currently stands as a baseline in deep question answering.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"We further modified it to return different numbers of candidate documents.
",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
Fig. 1 (a) shows the end-to-end performance across different top-n document retrievals as measured by the exact matches with ground truth.,3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"For a small corpus, we clearly register a superior performance for the top-1 system.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"However, we observe a different pattern with increasing corpus size.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"Fig. 1 (b) and (c) shed light into the underlying reason by reporting how frequently the correct answer is returned and, as the correct an-
swer might appear multiple times, how often it is included in the top-n. Evidently, the recall in (b) drops quickly for a top-1 system when augmenting the corpus.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"Yet it remains fairly stable for a top-n system, due to the fact that it is sufficient to have the correct answer in any of the n documents.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"According to (c), the correct answer is often more than once returned by a top-n system, increasing the chance of answer extraction.
",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
The above findings result in a noise-information trade-off.,3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"A top-1 system often identifies the correct answer for a small corpus, whereas a larger corpus introduces additional noise and thus impedes the overall performance.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"Conversely, a top-n system accomplishes a higher density of relevant information for a large corpus as the answer is often contained multiple times.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
This effect is visualized in an additional experiment shown in Fig. 2.,3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"We keep the corpus size fixed and vary only n, i.e. the number of retrieved documents.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"We see the recall converging fast, while the average number of relevant documents keeps growing, leading to a higher density of relevant information.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
"As a result, a top-n system might not be compromised by a declining recall, since it contains the correct answer over-proportionally often.",3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
This logic motivates us in the following to introduce an adaptive ni that optimizes the number of documents retrievals in a top-n system independently for every query qi.,3 Noise-Information Trade-Off in Document Retrieval,[0],[0]
This section advances deep question answering by developing adaptive methods for document retrieval.,4 Adaptive Document Retrieval,[0],[0]
"Our methods differ from conventional document retrieval in which the number of returned documents is set to a fixed n. Conversely, we actively optimize the choice of ni for each document retrieval i. Formally, we select ni between 1 and a maximum τ (e. g. τ",4 Adaptive Document Retrieval,[0],[0]
= 20),4 Adaptive Document Retrieval,[0],[0]
", given documents [d
(1) i , . . .",4 Adaptive Document Retrieval,[0],[0]
", d (τ) i ].",4 Adaptive Document Retrieval,[0],[0]
"These entail further scores denot-
ing the relevance, i. e. si =",4 Adaptive Document Retrieval,[0],[0]
"[s (1) i , . . .",4 Adaptive Document Retrieval,[0],[0]
", s (τ) i ] T with normalization s. t. ∑ j s (j) i = 1.",4 Adaptive Document Retrieval,[0],[0]
The scoring function is treated as a black-box and thus can be based on simple tf-idf similarity but also complex probabilistic models.,4 Adaptive Document Retrieval,[0],[0]
"As a naı̈ve baseline, we propose a simple threshold-based heuristic.",4.1 Threshold-Based Retrieval,[0],[0]
"That is, ni is determined such that the cumulative confidence score reaches a fixed threshold θ ∈ (0, 1].",4.1 Threshold-Based Retrieval,[0],[0]
"Formally, the number ni of retrieved documents is given by
ni = max k k∑ j=1 s (j) i < θ.",4.1 Threshold-Based Retrieval,[0],[0]
"(1)
In other words, the heuristic fills up documents until surpassing a certain confidence threshold.",4.1 Threshold-Based Retrieval,[0],[0]
"For instance, if the document retrieval is certain that the correct answer must be located within a specific document, it automatically selects fewer documents.",4.1 Threshold-Based Retrieval,[0],[0]
We further implement a trainable classifier in the form of an ordinal ridge regression which is tailored to ranking tasks.,4.2 Ordinal Regression,[0],[0]
We further expect the cumulative confidence likely to be linear.,4.2 Ordinal Regression,[0],[0]
The classifier then approximates ni with a prediction yi that denotes the position of the first relevant document containing the desired answer.,4.2 Ordinal Regression,[0],[0]
"As such, we learn a function
yi = f([s",4.2 Ordinal Regression,[0],[0]
"(1) i , . . .",4.2 Ordinal Regression,[0],[0]
", s (τ) i ])",4.2 Ordinal Regression,[0],[0]
= ds T,4.2 Ordinal Regression,[0],[0]
"i βe, (2)
where d. .",4.2 Ordinal Regression,[0],[0]
.e denotes the ceiling function.,4.2 Ordinal Regression,[0],[0]
"The ridge coefficients are learned through a custom loss function
L = ‖dXβe",4.2 Ordinal Regression,[0],[0]
− y‖1,4.2 Ordinal Regression,[0],[0]
+ λ,4.2 Ordinal Regression,[0],[0]
"‖β‖2 , (3)
whereX is a matrix containing scores of our training samples.",4.2 Ordinal Regression,[0],[0]
"In contrast to the classical ridge regression, we introduce a ceiling function and replace the mean squared error by a mean absolute error in order to penalize the difference from the optimal rank.",4.2 Ordinal Regression,[0],[0]
The predicted cut-off n̂i for document retrieval is then computed for new observations s′i via n̂i = ds′Ti β̂e+b.,4.2 Ordinal Regression,[0],[0]
"The linear offset b is added in order to ensures that ni ≤ n̂i holds, i. e. reducing the risk that the first relevant document is not included.
",4.2 Ordinal Regression,[0],[0]
"We additionally experimented with non-linear predictors, including random forests and feedforward neural networks; however; we found no significant improvement that justified the additional model complexity over the linear relationship.",4.2 Ordinal Regression,[0],[0]
We first compare our QA system with adaptive document retrieval against benchmarks from the literature.,5 Experiments,[0],[0]
"Second, we specifically study the sensitivity of our adaptive approach to variations in the corpus size.",5 Experiments,[0],[0]
"All our experiments draw upon the DrQA implementation (Chen et al., 2017), a state-of-the-art system for question answering in which we replaced the default module for document retrieval with our adaptive scheme (but leaving all remaining components unchanged, specifically without altering the document scoring or answer extraction).
",5 Experiments,[0],[0]
"For the threshold-based model, we set τ = 15 and the confidence threshold to θ = 0.75.",5 Experiments,[0],[0]
"For the ordinal regression approach, we choose τ = 20 and use the original SQuAD train-dev split from the full corpus also as the basis for training across all experiments.",5 Experiments,[0],[0]
"In a first series of experiments, we refer to an extensive set of prevalent benchmarks for evaluating QA systems, namely, SQuAD",5.1 Overall Performance,[0],[0]
"(Rajpurkar et al., 2016), Curated TREC (Baudiš and Šedivý, 2015), WikiMovies (Miller et al., 2016) and WebQuestions (Berant et al., 2013) in order to validate the robustness of our findings.",5.1 Overall Performance,[0],[0]
"Based on these, we then evaluate our adaptive QA systems against the naı̈ve DrQA system in order to evaluate the relative performance.",5.1 Overall Performance,[0],[0]
"We included the deep QA system R3 as an additional, top-scoring benchmark from recent literature (Wang et al., 2018) for bet-
ter comparability.",5.1 Overall Performance,[0],[0]
Tbl. 1 reports the ratio of exact matches for the different QA systems.,5.1 Overall Performance,[0],[0]
The results demonstrate the effectiveness of our adaptive scheme: it yields the best-performing system for three out of four datasets.,5.1 Overall Performance,[0],[0]
"On top of that, it outperforms the naı̈ve DrQA system consistently across all datasets.",5.1 Overall Performance,[0],[0]
We earlier observed that the corpus size affects the best choice of n and we thus study the sensitivity with regard to the size.,5.2 Sensitivity: Adaptive QA to Corpus Size,[0],[0]
"For this purpose, we repeat the experiments from Section 3 in order to evaluate the performance gain from our adaptive scheme.",5.2 Sensitivity: Adaptive QA to Corpus Size,[0],[0]
"More precisely, we compare the ordinal regression (b = 1) against document retrieval with a fixed document count n.
Fig. 3 shows the end-to-end performance, confirming the overall superiority of our adaptive document retrieval.",5.2 Sensitivity: Adaptive QA to Corpus Size,[0],[0]
"For instance, the top-1 system reaches a slightly higher rate of exact matches for small corpus sizes, but is ranked last when considering the complete corpus.",5.2 Sensitivity: Adaptive QA to Corpus Size,[0],[0]
"The high performance of the top-1 system partially originates from the design of the experiment itself, where we initially added one correct document per question, which is easy to dissect by adding little additional noise.",5.2 Sensitivity: Adaptive QA to Corpus Size,[0],[0]
"On the other hand, the top-10 system accomplishes the best performance on the complete corpus, whereas it fails to obtain an acceptable performance for smaller corpus sizes.
",5.2 Sensitivity: Adaptive QA to Corpus Size,[0],[0]
"To quantify our observations, we use a notation of regret.",5.2 Sensitivity: Adaptive QA to Corpus Size,[0],[0]
"Formally, let µnm denote the performance of the top-n system on a corpus of size m. Then the regret of choosing system n at evaluation point m is the difference between the best performing system µ∗m and the chosen system rnm = µ∗m − µnm.",5.2 Sensitivity: Adaptive QA to Corpus Size,[0],[0]
"The total regret of system n is computed by averaging the regret over all observations of system n, weighted with the span in-between observations in order to account for the logarithmic intervals.",5.2 Sensitivity: Adaptive QA to Corpus Size,[0],[0]
"The best top-n system yields a regret of 0.83 and 1.12 respectively, whereas our adaptive control improves it down to 0.70.",5.2 Sensitivity: Adaptive QA to Corpus Size,[0],[0]
Experiments so far have been conducted on the DrQA system.,5.3 Robustness Check,[0],[0]
"To show the robustness of our approach, we repeat all experiments on a different QA system.",5.3 Robustness Check,[0],[0]
"Different from DrQA, this system operates on paragraph-level information retrieval and
uses cosine similarity to score tf-idf-weighted bagof-word (unigram) vectors.",5.3 Robustness Check,[0],[0]
"The reader is a modified version of the DrQA document reader with an additional bi-directional attention layer (Seo et al., 2017).",5.3 Robustness Check,[0],[0]
We are testing two different configurations1 of this system: one that selects the top-50 paragraphs and one that selects the top-80 paragraphs against our approach as shown in Tab. 2.,5.3 Robustness Check,[0],[0]
"We see that, owed to the paragraph-level information retrieval, the number of top-n passages gains even more importance.",5.3 Robustness Check,[0],[0]
"Both variations of the system outperform a system without adaptive retrieval, which confirms our findings.",5.3 Robustness Check,[0],[0]
Our contribution is three-fold.,6 Conclusion,[0],[0]
"First, we establish that deep question answering is subject to a noiseinformation trade-off.",6 Conclusion,[0],[0]
"As a consequence, the number of selected documents in deep QA should not be treated as fixed, rather it must be carefully tailored to the QA task.",6 Conclusion,[0],[0]
"Second, we propose adaptive schemes that determine the optimal document
1Best configurations out of {30, 40, 50, 60, 70, 80, 90, and 100} on SQuAD train split.
count.",6 Conclusion,[0],[0]
This can considerably bolster the performance of deep QA systems across multiple benchmarks.,6 Conclusion,[0],[0]
"Third, we further demonstrate how crucial an adaptive document retrieval is in the context of different corpus sizes.",6 Conclusion,[0],[0]
"Here our adaptive strategy presents a flexible strategy that can successfully adapt to it and, compared to a fixed document count, accomplishes the best performance in terms of regret.
",6 Conclusion,[0],[0]
"Reproducibility
Code to integrate adaptive document retrieval in custom QA system and future research is freely available at https://github.com/ bernhard2202/adaptive-ir-for-qa",6 Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research.,Acknowledgments,[0],[0]
Cloud computing resources were provided by a Microsoft Azure for Research award.,Acknowledgments,[0],[0]
"State-of-the-art systems in deep question answering proceed as follows: (1) an initial document retrieval selects relevant documents, which (2) are then processed by a neural network in order to extract the final answer.",abstractText,[0],[0]
"Yet the exact interplay between both components is poorly understood, especially concerning the number of candidate documents that should be retrieved.",abstractText,[0],[0]
We show that choosing a static number of documents – as used in prior research – suffers from a noiseinformation trade-off and yields suboptimal results.,abstractText,[0],[0]
"As a remedy, we propose an adaptive document retrieval model.",abstractText,[0],[0]
"This learns the optimal candidate number for document retrieval, conditional on the size of the corpus and the query.",abstractText,[0],[0]
"We report extensive experimental results showing that our adaptive approach outperforms state-of-the-art methods on multiple benchmark datasets, as well as in the context of corpora with variable sizes.",abstractText,[0],[0]
Adaptive Document Retrieval for Deep Question Answering,title,[0],[0]
"In existing studies of multi-armed bandits (MABs) (Auer et al., 2002; Bubeck & Cesa-Bianchi, 2012), pulling a suboptimal arm results in a constant regret.",1. Introduction,[0],[0]
"While this is a valid assumption in many existing applications, there exists a variety of applications where the actual regret of pulling a suboptimal arm may vary depending on external conditions.",1. Introduction,[0],[0]
"Consider the following application scenarios.
",1. Introduction,[0],[0]
"1Twitter Inc., San Francisco, California, USA; 2University of California, Davis, California, USA.",1. Introduction,[0],[0]
"This work was partially completed while the first author was a postdoctoral researcher at University of California, Davis.",1. Introduction,[0],[0]
"Correspondence to: Xin Liu <xinliu@ucdavis.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
Motivating scenario 1: price variation.,1. Introduction,[0],[0]
"MAB has been widely used in studying effective procedures and treatments (Lai, 1987; Press, 2009; Villar et al., 2015), including in agriculture.",1. Introduction,[0],[0]
"In agriculture, price often varies significantly for produce and livestock.",1. Introduction,[0],[0]
"For example, the pork price varied from $0.46/lb to $1.28/lb, and orange $608/ton to $1140/ton, in 2014-2017 (Index Mundi).",1. Introduction,[0],[0]
"Commodity price forecast has achieved high accuracy and been widely used for production decisions (Brandt & Bessler, 1983).",1. Introduction,[0],[0]
"In this scenario, different treatments can be considered as arms.",1. Introduction,[0],[0]
"The effectiveness of a particular treatment is captured by the value of the arm, and is independent of the market price of the product.",1. Introduction,[0],[0]
"(The latter is true because an experiment in one farm, among tens of thousands of such farms in the US, has negligible impact on the overall production and thus the commodity’s market price.)",1. Introduction,[0],[0]
The monetary reward is proportional to price and to the effectiveness of the treatment.,1. Introduction,[0],[0]
"The goal of a producer is to minimize the overall monetary regret, compared to the oracle.",1. Introduction,[0],[0]
"Therefore, intuitively, when the product price is low, the monetary regret of pulling a suboptimal arm is low, and vice versa.
",1. Introduction,[0],[0]
Motivating scenario 2: load variation.,1. Introduction,[0],[0]
"Network configuration is widely used in wireless networks, data-center networks, and the Internet, in order to control network topology, routing, load balancing, and thus improve the overall performance.",1. Introduction,[0],[0]
"For example, in a cellular network, a cell tower has a number of parameters to configure, including radio spectrum, transmission power, antenna angle and direction, etc.",1. Introduction,[0],[0]
"The configuration of such parameters can greatly impact the overall performance, e.g., coverage, throughput, and service quality.",1. Introduction,[0],[0]
"A network configuration can be considered as an arm, where its performance needs to be learned.",1. Introduction,[0],[0]
"Networks are typically designed and configured to handle the peak load, and thus we hope to learn the best configuration for the peak load.
",1. Introduction,[0],[0]
Network traffic load fluctuates over time.,1. Introduction,[0],[0]
"When the network load is low, we can inject dummy traffic into the network so that the total load, the real load plus the dummy load, resembles the peak load.",1. Introduction,[0],[0]
It allows us to learn the performance of the configuration under the peak load.,1. Introduction,[0],[0]
"At the same time, the regret of using a suboptimal configuration is low because the real load affected is low.",1. Introduction,[0],[0]
"Furthermore, in practice, we can set the priority of the dummy traffic to be lower than that of the real traffic.",1. Introduction,[0],[0]
"Because networks handle high priority
traffic first, low priority traffic results in little or no impact on the high priority traffic (Walraevens et al., 2003).",1. Introduction,[0],[0]
"In this case, the regret on the actual load is further reduced, or even negligible (when the suboptimal configuration is sufficient to handle the real load).
",1. Introduction,[0],[0]
Opportunistic bandits.,1. Introduction,[0],[0]
"Motivated by these application scenarios, we study opportunistic bandits in this paper.",1. Introduction,[0],[0]
"Specifically, we define opportunistic bandit as a bandit problem with the following characteristics: 1) The best arm does not change over time.",1. Introduction,[0],[0]
2),1. Introduction,[0],[0]
The exploration cost (regret) of a suboptimal arm varies depending on a time-varying external condition that we refer to as load (which is the price in the first scenario).,1. Introduction,[0],[0]
3),1. Introduction,[0],[0]
"The load is revealed before an arm is pulled, so that one can decide which arm to pull depending on the load.",1. Introduction,[0],[0]
"As its name suggests, in opportunistic bandits, one can leverage the opportunities of load variation to achieve a lower regret.",1. Introduction,[0],[0]
"In addition to the previous two examples, opportunistic bandit algorithms can be applied to other scenarios that share the above characteristics.
",1. Introduction,[0],[0]
"We note that opportunistic bandits significantly differs from non-stationary bandits (Garivier & Moulines, 2011; Besbes et al., 2014).",1. Introduction,[0],[0]
"In non-stationary bandits, the expected reward of each arm varies and the optimal arm may change over time, e.g., because of the shift of interests.",1. Introduction,[0],[0]
"In opportunistic bandits, the optimal arm does not change over time, but the regret of trying a suboptimal arm changes depending on the load.",1. Introduction,[0],[0]
"In other words, in non-stationary bandits, the dynamics of the optimal arm make finding the optimal arm more challenging.",1. Introduction,[0],[0]
"In contrast, in opportunistic bandits, the time-varying nature of the load provides opportunities to reduce the regret of finding the fixed optimal arm.",1. Introduction,[0],[0]
"Because of such fundamental differences, in non-stationary bandits, one can show polynomial regret (e.g., Ω(T 2/3) (Besbes et al., 2014))",1. Introduction,[0],[0]
because one has to keep track of the optimal arm.,1. Introduction,[0],[0]
"In opportunistic bandits, we can show O(log T ) (or even O(1) in certain special cases) regret because we can push more exploration to slots when the regret is lower.
",1. Introduction,[0],[0]
"We also note the connection and difference between opportunistic bandits and contextual bandits (Zhou, 2015; Wu et al., 2015; Li et al., 2010; Chu et al., 2011).",1. Introduction,[0],[0]
"Broadly speaking, opportunistic bandits can be considered as a special case of contextual bandits where we can consider the load as the context.",1. Introduction,[0],[0]
"However, general contextual bandits do not take advantages of the unique properties of opportunistic bandits, in particular, the optimal bandit remains the same, and regrets differ under different contexts (i.e., load).",1. Introduction,[0],[0]
"To follow this line, the performance of contextual bandits has been compared in Appendix D.3.
Contributions.",1. Introduction,[0],[0]
"In this paper, we propose an Adaptive Upper-Confidence-Bound (AdaUCB) algorithm to dynamically balance the exploration-exploitation tradeoff in opportunistic bandits.",1. Introduction,[0],[0]
"The intuition is clear: we should explore
more when the load is low and exploit more when the load is high.",1. Introduction,[0],[0]
The design challenge is to quantify the right amount of exploration and exploitation depending on the load.,1. Introduction,[0],[0]
The analysis challenge is due to the inherent coupling over time and thus over bandits under different conditions.,1. Introduction,[0],[0]
"In particular, due to the randomness nature of bandits, the empirical estimates of the expected rewards could deviate from the true values, which could lead to suboptimal actions when the load is high.",1. Introduction,[0],[0]
We address these challenges by studying the lower bounds on the number of pulls of the suboptimal arms under low load.,1. Introduction,[0],[0]
"Because the exploration factor is smaller under high load than that under low load, it requires less information accuracy to make the optimal decision under high load.",1. Introduction,[0],[0]
"Thus, with an appropriate lower bound on the number of pulls of the suboptimal arms under low load, we can show that the information obtained from the exploration under the low load is sufficient for accurate decisions under the high load.",1. Introduction,[0],[0]
"As a result, the exploration under high load is reduced and thus so does the overall regret.
",1. Introduction,[0],[0]
"To the best of our knowledge, this is the first work proposing and studying opportunistic bandits that aims to adaptively balance the exploration-exploitation tradeoff considering load-dependent regrets.",1. Introduction,[0],[0]
"We propose AdaUCB, an algorithm that adjusts the exploration-exploitation tradeoff according to the load level.",1. Introduction,[0],[0]
We prove that AdaUCB achieves O(log T ) regret with a smaller coefficient than the traditional UCB algorithm.,1. Introduction,[0],[0]
"Furthermore, AdaUCB achieves O(1) regret with respect to T in the case where the exploration cost is zero when the load level is smaller than a certain threshold.",1. Introduction,[0],[0]
"Using both synthetic and real-world traces, we show that AdaUCB significantly outperforms other bandit algorithms, such as UCB and TS (Thompson Sampling), under large load fluctuations.",1. Introduction,[0],[0]
"We study an opportunistic bandit problem, where the exploration cost varies over time depending on an external condition, called load here.",2. System Model,[0],[0]
"Specifically, consider a Karmed stochastic bandit system.",2. System Model,[0],[0]
"At time t, each arm has a random nominal reward Xk,t, where Xk,t ∈",2. System Model,[0],[0]
"[0, 1] are independent across arms, and i.i.d.",2. System Model,[0],[0]
"over time, with mean value E[Xk,t] = uk.",2. System Model,[0],[0]
Let u∗ =,2. System Model,[0],[0]
maxk uk be the maximum expected reward and k∗ = arg maxuk be the best arm.,2. System Model,[0],[0]
"The arm with the best nominal reward does not depend on the load and does not change over time.
",2. System Model,[0],[0]
"Let Lt ≥ 0 be the load at time t. For simplicity, we assume Lt ∈",2. System Model,[0],[0]
"[0, 1].",2. System Model,[0],[0]
"The agent observes the value of Lt before making the decision; i.e., the agent pulls an arm at based on both Lt and the historical observations, i.e., at = Γ(Lt,Ht−1), where Ht−1 = (L1, a1, Xa1,1, . . .",2. System Model,[0],[0]
", Lt−1, at−1, Xat−1,t−1) represents the historical observations.",2. System Model,[0],[0]
"The agent then receives an actual reward LtXat,t. While the underlying
nominal reward Xat,t is independent of Lt conditioned on at, the actual reward depends on Lt.",2. System Model,[0],[0]
"We also assume that the agent can observe the value of Xat,t after pulling arm at at time t.
This model captures the essence of opportunistic bandits and its assumptions are reasonable.",2. System Model,[0],[0]
"For example, in the agriculture scenario, Xat,t captures the effectiveness of a treatment, e.g., the survival rate or the yield of an antibiotic treatment.",2. System Model,[0],[0]
"The value of Xat,t can always be observed by the agent after applying treatment at at time t. Conditioned on at, Xat,t is also independent of Lt, the price of the commodity.",2. System Model,[0],[0]
"Meanwhile, the actual reward, i.e., the monetary reward, is modulated by Lt (the price) as LtXat,t. In the network configuration example, Xat,t captures the impact of a configuration at the peak load, e.g., success rate, throughput, or service quality score.",2. System Model,[0],[0]
"Because the total load (the real load plus the dummy load) resembles the peak load, Xat,t is independent of the real load Lt conditioned on at, and can always be observed.",2. System Model,[0],[0]
"Further, because the real load is a portion of the total load and the network can identify real traffic from dummy traffic, the actual reward is thus a portion of the total reward, modulated by the real load as LtXat,t.
If system statistics are known a priori, then the agent will always pull the best arm and obtain the expected total reward u∗E",2. System Model,[0],[0]
[ ∑T t=1 Lt].,2. System Model,[0],[0]
"Thus, the regret of a policy Γ is defined as
RΓ(T )",2. System Model,[0],[0]
= u ∗E,2. System Model,[0],[0]
[ T∑ t=1 Lt ],2. System Model,[0],[0]
"− T∑ t=1 E[LtXat,t].",2. System Model,[0],[0]
"(1)
In particular, when Lt is i.i.d.",2. System Model,[0],[0]
"over time with mean value E[Lt] = L̄, the total expected reward for the oracle solution is u∗L̄T and the regret is RΓ(T )",2. System Model,[0],[0]
=,2. System Model,[0],[0]
"u∗L̄T −∑T t=1 E[LtXat,t].",2. System Model,[0],[0]
"Because the action at can depend on Lt, it is likely that E[LtXat,t] 6=",2. System Model,[0],[0]
"L̄E[Xat,t].",2. System Model,[0],[0]
"We first recall a general version of the classic UCB1 (Auer et al., 2002) algorithm, referred to as UCB(α), which always selects the arm with the largest index defined in the following format:
ûk(t) = ūk(t) +
√ α log t
Ck(t− 1) , 1 ≤ k ≤ K,
where α is a constant, Ck(t",3. Adaptive UCB,[0],[0]
"− 1) is the number of pulls for arm-k before t, and ūk(t) = 1Ck(t−1) ∑t−1 τ=1",3. Adaptive UCB,[0],[0]
"1(aτ = k)Xk,τ .",3. Adaptive UCB,[0],[0]
"It has been shown that UCB(α) achieves logarithmic regret in stochastic bandits when α > 1/2 (Bubeck, 2010).",3. Adaptive UCB,[0],[0]
"UCB1 in (Auer et al., 2002) is a special case with α = 2.
",3. Adaptive UCB,[0],[0]
"Algorithm 1 AdaUCB 1: Init: α > 0.5, Ck(t) = 0, ūk(t) = 1. 2: for t = 1 to K do 3:",3. Adaptive UCB,[0],[0]
"Pull each arm once and update Ck(t) and ūk(t) ac-
cordingly; 4: end for 5: for t = K + 1 to T do 6: Observe Lt; 7: Calculate UCB: for k = 1, 2, . . .",3. Adaptive UCB,[0],[0]
",K,
ûk(t) = ūk(t) + √ α(1− L̃t)",3. Adaptive UCB,[0],[0]
"log t Ck(t− 1) , (2)
where L̃t is the normalized load defined in Eq.",3. Adaptive UCB,[0],[0]
"(4); 8: Pull the arm with the largest ûk(t):
at = arg max 1≤k≤K ûk(t); (3)
9: Update ūk(t) and Ck(t); 10: end for
In this work, we propose an AdaUCB algorithm for opportunistic bandits.",3. Adaptive UCB,[0],[0]
"In order to capture different ranges of Lt, we first normalize Lt to be within [0, 1]:
L̃t =",3. Adaptive UCB,[0],[0]
"[Lt]
l(+) l(−)",3. Adaptive UCB,[0],[0]
"− l(−)
l(+)",3. Adaptive UCB,[0],[0]
"− l(−) , (4)
where l(−) and l(+) are the lower and upper thresholds for truncating the load level, and [Lt]l (+)
l(−) =
max{l(−),min(Lt, l(+))}.",3. Adaptive UCB,[0],[0]
Load normalization reduces the impact of different load distributions.,3. Adaptive UCB,[0],[0]
"It also restricts the coefficient of the exploration term in the UCB indices, which avoids under or over explorations.",3. Adaptive UCB,[0],[0]
"To achieve good performance, the truncation thresholds should be appropriately chosen and can be learned online in practice, as discussed in Sec. 4.3.",3. Adaptive UCB,[0],[0]
We note that L̃t is only used in AdaUCB algorithm.,3. Adaptive UCB,[0],[0]
"The rewards and regrets are based on Lt, not L̃t.
",3. Adaptive UCB,[0],[0]
The AdaUCB algorithm adjusts the tradeoff between exploration and exploitation based on the load level Lt.,3. Adaptive UCB,[0],[0]
"Specifically, as shown in Algorithm 1, AdaUCB makes decisions based on the sum of the empirical reward (the exploitation term) ūk(t) and the confidence interval width (the exploration term).",3. Adaptive UCB,[0],[0]
The latter term is proportional to √ 1− L̃t.,3. Adaptive UCB,[0],[0]
"In other words, AdaUCB uses an exploration factor α(1− L̃t)",3. Adaptive UCB,[0],[0]
that is linearly decreasing in L̃t.,3. Adaptive UCB,[0],[0]
"Thus, when the load level is high, the exploration term is relatively small and AdaUCB tends to emphasize exploitation, i.e., choosing the arms that perform well in the past.",3. Adaptive UCB,[0],[0]
"In contrast, when the load level is low, AdaUCB uses a larger exploration term and gives more opportunities to the arms with less explorations.",3. Adaptive UCB,[0],[0]
"Intuitively, with this load-awareness, AdaUCB explores more when the
load is low and leverages the learned statistics to make better decisions when the load is high.",3. Adaptive UCB,[0],[0]
"Since the actual regret is scaled with the load level, AdaUCB can achieve an overall lower regret.",3. Adaptive UCB,[0],[0]
Note that we have experimented a variety of load adaptation functions.,3. Adaptive UCB,[0],[0]
"The current one achieves superior empirical performance and is amenable to analyze, and thus adopted here.",3. Adaptive UCB,[0],[0]
"Although the intuition behind AdaUCB is natural, the rigorous analysis of its regret is challenging.",4. Regret Analysis,[0],[0]
"To analyze the decision in each slot, we require the statistics for the number of pulls of each arm.",4. Regret Analysis,[0],[0]
"Unlike traditional regret analysis, we care about not only the upper bound, but also the lower bound for calculating the confidence level.",4. Regret Analysis,[0],[0]
"However, even for fixed load levels, it is difficult to characterize the total number of pulls for suboptimal arms, i.e., obtaining tight lower and upper bounds for the regret.",4. Regret Analysis,[0],[0]
The gap between the lower and upper bounds makes it more difficult to evaluate the properties of UCB for general random load levels.,4. Regret Analysis,[0],[0]
"To make the intuition more clear and analyses more readable, we start with the case of squared periodic wave load and Dirac rewards to illustrate the behavior of AdaUCB in Sec. 4.1.",4. Regret Analysis,[0],[0]
"Then, we extend the results to the case with random binary-value load and random rewards in Sec. 4.2, and finally analyze the case with continuous load in Sec. 4.3.
",4. Regret Analysis,[0],[0]
"Specifically, we first consider the case with binary-valued load, i.e., Lt ∈ { 0, 1 − 1}, where 0, 1 ∈",4. Regret Analysis,[0],[0]
"[0, 0.5).",4. Regret Analysis,[0],[0]
"For this case, we let l(−) = 0 and l(+) = 1.",4. Regret Analysis,[0],[0]
"Then, L̃t = 0 if Lt = 0, and L̃t = 1− 0− 11− 0 = 1 − 1 1− 0",4. Regret Analysis,[0],[0]
if Lt = 1 − 1,4. Regret Analysis,[0],[0]
.,4. Regret Analysis,[0],[0]
"Therefore, the indices used by AdaUCB are given as follows:
ûk(t) = ūk(t) +",4. Regret Analysis,[0],[0]
"√ α log t Ck(t−1) , if Lt = 0, ūk(t) + √
α 1 log t (1− 0)Ck(t−1) ,",4. Regret Analysis,[0],[0]
"if Lt = 1− 1.
(5)
We investigate the regret of AdaUCB under the binaryvalued load described above in Sec. 4.1 and Sec. 4.2, and then study its performance under continuous load in Sec.",4. Regret Analysis,[0],[0]
4.3 with the insights obtained from the binary-valued load case.,4. Regret Analysis,[0],[0]
We first study a simple case with periodic square wave load and Dirac rewards.,4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"In this scenario, the evolution of the system under AdaUCB is deterministic.",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
The analysis of this deterministic system allows us to better understand AdaUCB and quantify the benefit of load-awareness.,4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"In addition, we focus on 2-armed bandits in analysis for easy illustration in this section.
",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"Specifically, we assume the load is Lt = 0",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"if t is even, and 1− 1 if t is odd.",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"Moreover, the rewards are fixed, i.e., Xk,t = uk for all k and t, but unknown a priori.",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"Without loss of generality, we assume arm-1 has higher reward, i.e., 1 ≥ u1 > u2 ≥ 0, and let ∆ = u1 − u2 be the reward difference.
",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"Under these settings, we can obtain the bounds for the number of pulls for each arm by borrowing the idea from (Salomon et al., 2011; 2013).",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"The proofs of these results are included in Appendix A, which are similar to (Salomon et al., 2011; 2013), except for the effort of addressing the case of Lt = 1− 1.
",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"We first characterize the upper and lower bounds on the total number of pulls for the suboptimal arm.
",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
Lemma 1.,4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"In the opportunistic bandit with periodic square wave load and Dirac rewards, the number of pulls for arm-2 under AdaUCB is bounded as follows: 1)",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
Upper bound for any t ≥ 1: C2(t) ≤ αlogt∆2 + 1; 2),4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
Lower bound for any t = 2τ ≥ 2: C2(2τ),4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"≥ f(τ) = ∫ τ 2
min(h′(s), 1)ds − h(2), where h(s) = α log s∆2 ( 1 + √ 2α log s (2s−1)∆2 )−2 .
",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"Note that C2(2τ) provides the information for making decision in slot 2τ + 1, when Lt = 1 − 1.",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"With the lower bound in Lemma 1, we can show that after a certain time, AdaUCB will always pull the better arm when Lt = 1− 1 with the information provided by C2(2τ).",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"Combining with the upper bound on C2(t), we can obtain the regret bound for AdaUCB:
Theorem 1.",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"In the opportunistic bandit with periodic square wave load and Dirac rewards, the regret of AdaUCB is bounded as: RAdaUCB(T ) ≤ 0α log T∆ +O(1).
",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
Remark 1:,4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"According to (Salomon et al., 2011), the regret of UCB(α) is lower bounded by α log T∆ for fixed load Lt = 1.",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"Without load-awareness, we can expect that the explorations occur roughly uniformly under different load levels.",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"Thus, the regret of UCB(α) in this opportunistic bandit is roughly α(1+ 0− 1) log T2∆ , and is much larger than the regret of AdaUCB for small 0 and 1.",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"As an extreme case, when 0 = 0, the regret of AdaUCB is O(1), while that of UCB(α) is O(log T ).
",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
Remark 2: The above analysis provides us insights about the benefit of load-awareness in opportunistic bandits.,4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"With load-awareness, AdaUCB forces exploration to the slots with lower load and the information obtained there is sufficient to make good decisions in higher-load slots.",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
"Thus, the overall regret of AdaUCB is much smaller than traditional load-agnostic algorithms.",4.1. AdaUCB under Periodic Square Wave Load and Dirac Rewards,[0],[0]
We now consider the more general case with random binaryvalued load and random rewards.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"We assume that load Lt ∈ { 0, 1 − 1} and P{Lt = 0} = ρ ∈",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"(0, 1).",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
We consider i.i.d random reward,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Xk,t ∈",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"[0, 1] and E[Xk,t] = uk, where 1 ≥ u1 > u2 ≥ u3 ≥ ... ≥ uK ≥ 0.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Let ∆k = u1 − uk, and ∆∗ = mink>1 ∆k = ∆2 be the minimum gap between the suboptimal arms and the optimal arm.
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Compared with the deterministic case in Sec. 4.1, the analysis under random load and rewards is much more challenging.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In particular, due to the reward randomness, the empirical value ūk(t) will deviate from its true value uk.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Unlike Dirac reward, this deviation could result in suboptimal decisions even when 0 and 1 are small.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Thus, we need to carefully lower bound the number of pulls for each arm so that the deviation is bounded with high probability.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"We only provide sketches for the proofs here due to the space limit and refer readers to Appendix B for more detailed analyses.
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"We consider a larger α (α > 2 in general, or larger when explicitly stated) for theoretical analysis purpose, similarly to earlier UCB papers such as (Auer et al., 2002).",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"As we will see in the simulations, AdaUCB with α > 1/2 works well under general random load.
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
We first propose a loose but useful bound for the number of pulls for the optimal arm.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Let C(0)k (t) be the number of slots where arm-k is pulled when Lt = 0, i.e., C
(0) k (t) =∑t
τ=1 1(Lτ = 0, aτ = k).",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
Lemma 2.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In the opportunistic bandit with random binaryvalued load and random rewards, for a constant η ∈ (0, ρ), there exists a constant T2, such that under AdaUCB, for all t ≥ T2
P { C
(0) 1 (t) < (ρ− η)t 2 } ≤ e−2η 2t +",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"[2(K − 1)]2α−1
2α− 2",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"[ (ρ− η)t ]−2α+2 .
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Sketch of Proof: The key intuition of proof is that when C
(0) 1 (t) is too small, the optimal arm will be pulled with high probability.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Specifically, let k′",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
>,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
1,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"be the index of arm that has been pulled for the most time among the suboptimal arms before t, and t′ < t be the last slot when k′ is pulled under load Lt = 0 for the last time.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
If C (0) 1 (t) <,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
(,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"ρ−η)t 2 , then Ck′(t′− 1) ≥",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
C(0)k′ (t′− 1) = Θ(t) with high probability.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Using the fact that log tt → 0 as t→∞, we know there exists a constant T2 such that for t ≥ T2, the confidence width √ α log t′
Ck′ (t ′−1) will be sufficiently small compared with
the minimum gap ∆∗ ≤ ∆k.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Moreover, the algorithm will pull the best arm when the UCB deviation is sufficiently small.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Then, we can bound the probability of the event
C (0) 1 (t) <",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"(ρ−η)t 2 by bounding the deviation of UCBs.
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
Next we bound the total number of pulls of the suboptimal arm as follows.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
Lemma 3.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In the opportunistic bandit with random binaryvalued load and random rewards, under AdaUCB, we have
E[Ck(T )]",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"≤ 4α log T
∆2k +O(1), 1 < k ≤ K. (6)
Sketch of Proof: To prove this lemma, we discuss the slots when the suboptimal arm is pulled under low and high load levels, respectively.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"When the load is low, i.e., Lt = 0, AdaUCB becomes UCB(α) and thus we can bound the probability of pulling the suboptimal arm similarly to (Auer et al., 2002).",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"When the load is high, i.e., Lt = 1− 1, the index becomes ûk(t) = ūk(t)+ √ α 1 log t
(1− 0)Ck(t−1) .",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In this case, with high probability, the index of the optimal arm is lower
bounded by u1 − ( 1− √
1 (1− 0) )",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"√ α log t C1(t−1) according to
Lemma 2.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"With similar adjustment on the UCB index for the suboptimal arm, we can bound the probability of pulling the suboptimal arm under high load.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"The conclusion of the lemma then follows by combining the above two cases.
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
Now we further lower bound the pulls of the suboptimal arm with high probability.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
Lemma 4.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In the opportunistic bandit with random binaryvalued load and random rewards, for a positive number δ ∈ (0, 1), we have for any k > 1,
P { Ck(t)",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
<,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"α log t
4(∆k + δ)2 } =",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"O ( t−(2α−3) + t−(2α( 1−δ 2−δ )
2−2)).",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Sketch of Proof: Although the analysis is more difficult, the intuition of proving this lemma is similar to that of Lemma 2: if Ck(t) is too small at a certain slot, then we will pull the suboptimal arm instead of the optimal arm with high probability.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"To be more specific, we focus on the slot t′ when the optimal arm is pulled for the last time before t under load Lt = 0.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"According to Lemma 2, C1(t) ≥ C(0)1 (t) ≥ (ρ−η)t 2 with high probability, indicating t′ ≥ (ρ− η)t/2 with high probability.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Moreover, the index for the optimal arm û1(t′) ≤ u1 + δ",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"with high probability for a sufficiently large t′, because √ log t t → 0 as t → ∞. On the other hand, we can show that for the suboptimal arm, ûk(t
′)",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
> u1 + δ = uk + (∆k + δ) with high probability when Ck(t′ − 1),4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
< α log t4(∆k+δ)2 .,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Thus, the probability of pulling the optimal arm at t′ is bounded by a small value, implying the conclusion of the lemma.
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Using the above lemmas, now we can further refine the upper bound on the regret of AdaUCB and show that AdaUCB achieves smaller regret than traditional UCB.
Theorem 2.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Using AdaUCB in the opportunistic bandit with random binary-valued load and random rewards, if α > 16 and √ 1
1− 0 < 1 8 , we have
RAdaUCB(T ) ≤ 4 0α log T ∑ k>1 1 ∆k +O(1).",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"(7)
Sketch of Proof: The key idea of the proof is to find an appropriate δ ∈ (0,∆∗), such that α > 16(1 + δ∆∗ )
2 and√ 1
1− 0 < ∆∗ 8(∆∗+δ) .",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In fact, the existence of this δ is guaranteed under the assumptions α > 16 and √
1 1− 0",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"< 1 8 .
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Using this δ, we can then use Lemma 4 to bound the probability of pulling the suboptimal arm when the load is high.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"This indicates most explorations occur when the load is low, i.e., Lt = 0.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"The conclusion of this theorem then follows according to Lemma 3.
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
Remark 3:,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Although there is no tight lower bound for the regret of UCB(α), we know that for traditional (loadoblivious) bandit algorithms, E[Ck(T )] is lower bounded by log TKL(uk,u1) (Lai & Robbins, 1985) for large T , where KL(uk, u1) is the Kullback-Leibler divergence.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Without load-awareness, the regret will be roughly lower bounded by (1− 0− 1) log T2 ∑ k>1 ∆k KL(uk,u1)
.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In contrast, with loadawareness, AdaUCB can achieve much lower regret than load-oblivious algorithms, when the load fluctuation is large, i.e., 0 and 1 are small.
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Theorem 2 directly implies the following result.
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
Corollary 1.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Using AdaUCB in the opportunistic bandit with random reward under i.i.d. random binary load where 0 = 0, if α > 16 and 1 < √ 2
4 , we have RAdaUCB(T ) = O(1).
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Remark 4: We note that this O(1) bound is in the sense of expected regret, which is different from the high probability O(1) regret bound (Abbasi-Yadkori et al., 2011).",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Specifically, while the opportunistic bandits can model the whole spectrum of load-dependent regret, Corollary 1 highlights one end of the spectrum where there are “free” learning opportunities.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In this case, we push most explorations to the “free” exploration slots and result in an O(1) expected regret.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Note that even under “free” exploration, we assume here that the value of the arms can be observed as discussed in Sec. 2.
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
It is worth noting that there are realistic scenarios where the exploration cost of a suboptimal arm is zero or close to zero.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
Consider the network configuration case where we use throughput as the reward.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In this case, Xat,t is the percentage of the peak load that configuration at can handle.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Because of the dummy low-priority traffic injected into the network, we can learn the true value of Xat,t under the
peak load.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"At the same time, configuration at, although suboptimal, may completely satisfy the real load Lt because it is high priority and thus served first.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Therefore, although a suboptimal arm, at sacrifices no throughput on the real load Lt, and thus generates a real regret of zero.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In other words, even if the system load is always positive, the chance of zero regret under a suboptimal arm is greater than zero, and in practice, can be non-negligible.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"To capture this effect, we can modify the regret defined in Eq.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"(1) by replacing Lt with 0 when Lt is smaller than a threshold.
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Last, we note that, under the condition of Corollary 1, it is easy to design other heuristic algorithms that can perform well.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"For example, one can do round-robin exploration when the load is zero and chooses the best arm when the load is non-zero.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"However, such naive strategies are difficult to extend to more general cases.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In contrast, AdaUCB applies to a wide range of situations, with both theoretical performance guarantees and desirable empirical performance.
",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Dependence on ρ: In the regret analysis, we focus on the asymptotic behavior of the regret as T goes to infinity.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In the bound, the constant term contains the impact of other factors, in particular the ratio of low load ρ, as shown in Appendix B.5.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"From the analysis, one can see that the constant term increases as ρ → 0.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
It suggests that one should use the traditional UCB when ρ is small because there exists little load fluctuation.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"In practice, AdaUCB achieves much smaller regret than traditional UCB and TS algorithms, even for small values of ρ such as ρ = 0.05 under binary load and ρ = 0.001 under continuous load.",4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
Such analysis and evaluations establish guidelines on when to use UCB or AdaUCB.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
More discussions can be found in Appendix D.,4.2. AdaUCB under Random Binary-Valued Load and Random Rewards,[0],[0]
"Inspired by the insights obtained from the binary-valued load case, we discuss AdaUCB in opportunistic bandits under continuous load in this section.
",4.3. AdaUCB under Continuous Load,[0],[0]
Selection of truncation thresholds.,4.3. AdaUCB under Continuous Load,[0],[0]
"When the load is continuous, we need to choose appropriate l(−) and l(+) for AdaUCB.",4.3. AdaUCB under Continuous Load,[0],[0]
"We first assume that the load distribution is a priori known, and discuss how to choose the thresholds under unknown load distribution later.",4.3. AdaUCB under Continuous Load,[0],[0]
"The analysis under binary-valued load indicates that, the explorations mainly occur in low load slots.",4.3. AdaUCB under Continuous Load,[0],[0]
"To guarantee sufficient explorations for a logarithmic regret, we propose to select the thresholds such that:
• The lower threshold l(−) satisfies P{Lt ≤ l(−)} = ρ > 0;
• The upper threshold l(+) ≥ l(−).
",4.3. AdaUCB under Continuous Load,[0],[0]
"In the special case of l(+) = l(−), we redefine the normalized load L̃t in (4) as L̃t = 0 when Lt ≤ l(−) and L̃t = 1 when Lt > l(−).
",4.3. AdaUCB under Continuous Load,[0],[0]
Regret analysis.,4.3. AdaUCB under Continuous Load,[0],[0]
"Under continuous load, it is hard to obtain regret bound as that in Theorem 2 for general l(−) and l(+) chosen above.",4.3. AdaUCB under Continuous Load,[0],[0]
"Instead, we first show logarithmic regret for general l(−) and l(+), and then illustrate the advantages of AdaUCB for the special case with l(−) = l(+).
",4.3. AdaUCB under Continuous Load,[0],[0]
"First, we show that AdaUCB with appropriate truncation thresholds achieves logarithmic regret as below.",4.3. AdaUCB under Continuous Load,[0],[0]
"This lemma is similar to Lemma 3, and the detailed outline of proof can be found in Appendix C.
Lemma 5.",4.3. AdaUCB under Continuous Load,[0],[0]
"In the opportunistic bandit with random continuous load and random rewards, under AdaUCB with P{Lt ≤ l(−)} = ρ > 0 and l(+) ≥ l(−), we have
E[Ck(T )]",4.3. AdaUCB under Continuous Load,[0],[0]
"≤ 4α log T
∆2k +O(1).",4.3. AdaUCB under Continuous Load,[0],[0]
"(8)
Next, we illustrate the advantages of AdaUCB under continuous load by studying the regret bound for AdaUCB with special thresholds l(+) = l(−).
",4.3. AdaUCB under Continuous Load,[0],[0]
Theorem 3.,4.3. AdaUCB under Continuous Load,[0],[0]
"In the opportunistic bandit with random continuous load and random rewards, under AdaUCB with P{Lt ≤ l(−)} = ρ > 0 and l(+) = l(−) , we have RAdaUCB(T )",4.3. AdaUCB under Continuous Load,[0],[0]
"≤ 4α log TE[Lt|Lt ≤ l(−)] ∑ k>1 1 ∆k +O(1), (9)
where E[Lt|Lt ≤ l(−)] is the expectation of Lt conditioned on Lt ≤ l(−).
",4.3. AdaUCB under Continuous Load,[0],[0]
"Sketch of Proof: Recall that for this special case l(+) = l(−), we let L̃t = 0 for Lt ≤ l(−) and L̃t = 1 for Lt > l(+).",4.3. AdaUCB under Continuous Load,[0],[0]
Then we can prove the theorem analogically to the proof of Theorem 2 for the binary-valued case.,4.3. AdaUCB under Continuous Load,[0],[0]
"Specially, when Lt ≤ l(−), we have L̃t = 0",4.3. AdaUCB under Continuous Load,[0],[0]
and it corresponds to the case of Lt = 0,4.3. AdaUCB under Continuous Load,[0],[0]
(L̃t = 0) in the binary-valued load case.,4.3. AdaUCB under Continuous Load,[0],[0]
"Similarly, the case of Lt > l(+) (L̃t = 1) corresponds to the case of Lt = 1 − 1 under binary-valued load with 1 = 0.",4.3. AdaUCB under Continuous Load,[0],[0]
"Then, we can obtain results similar to Lemma 4 and thus show that the regret under load Lt > l(+) is O(1).",4.3. AdaUCB under Continuous Load,[0],[0]
"Furthermore, the number of pulls under load level Lt ≤ l(−) is bounded according to Lemma 5.",4.3. AdaUCB under Continuous Load,[0],[0]
"The conclusion of the theorem then follows by using the fact that all load below l(−) are treated the same by AdaUCB, i.e., L̃t = 0 for all Lt ≤ l(−).
",4.3. AdaUCB under Continuous Load,[0],[0]
"Remark 5: We compare the regret of AdaUCB and conventional bandit algorithms by an example, where the load level Lt is uniformly distributed in [0, 1].",4.3. AdaUCB under Continuous Load,[0],[0]
"In this simple example, the regret of AdaUCB with thresholds l(+) = l(−)
is bounded by RAdaUCB(T )",4.3. AdaUCB under Continuous Load,[0],[0]
"≤ 4α log T ∑ k>1 1 ∆k · ρ2 + O(1), since E[Lt|Lt ≤ l(−)] = ρ/2 and E[Lt|Lt >
l(−)]",4.3. AdaUCB under Continuous Load,[0],[0]
< 1.,4.3. AdaUCB under Continuous Load,[0],[0]
"However, for any load-oblivious bandit algorithm such as UCB(α) , the regret is lower bounded by log T ∑ k>1 ∆k KL(uk,u1)
· 12 +O(1).",4.3. AdaUCB under Continuous Load,[0],[0]
"Thus, AdaUCB achieves much smaller regret when T is large and ρ is relatively small.
",4.3. AdaUCB under Continuous Load,[0],[0]
"Remark 6: From the above analysis, we can see that the selection of l(+) does not affect the order of the regret (O(log T )).",4.3. AdaUCB under Continuous Load,[0],[0]
"However, for a fixed l(−), we can further adjust l(+) to control the explorations for the load in the range of (l(−), l(+)).",4.3. AdaUCB under Continuous Load,[0],[0]
"Specifically, with a larger l(+), more explorations happen under the load between l(−) and l(+).",4.3. AdaUCB under Continuous Load,[0],[0]
These explorations accelerate the learning speed but may increase the long term regret because we allow more explorations under load l(−) <,4.3. AdaUCB under Continuous Load,[0],[0]
Lt < l(+).,4.3. AdaUCB under Continuous Load,[0],[0]
The behavior is opposite if we use a smaller l(+).,4.3. AdaUCB under Continuous Load,[0],[0]
"In addition, appropriately chosen thresholds also handle the case when the load has little or no fluctuation, i.e., Lt ≈ c.",4.3. AdaUCB under Continuous Load,[0],[0]
"For example, if we set l(−) = c and l(+)",4.3. AdaUCB under Continuous Load,[0],[0]
"= 2c, AdaUCB degenerates to UCB(α).
",4.3. AdaUCB under Continuous Load,[0],[0]
E-AdaUCB.,4.3. AdaUCB under Continuous Load,[0],[0]
"In practice, the load distribution may be unknown a priori and may change over time.",4.3. AdaUCB under Continuous Load,[0],[0]
"To address this issue, we propose a variant, named Empirical-AdaUCB (E-AdaUCB), which adjusts the thresholds l(−) and l(+) based on the empirical load distribution.",4.3. AdaUCB under Continuous Load,[0],[0]
"Specifically, the algorithm maintains the histogram for the load levels (or its moving average version for non-stationary cases), and then select l(−) and l(+) accordingly.",4.3. AdaUCB under Continuous Load,[0],[0]
"For example, we can select l(−) and l(+) such that the empirical probability P̃{Lt ≤ l(−)} = P̃{Lt ≥ l(+)} = 0.05.",4.3. AdaUCB under Continuous Load,[0],[0]
"We can see that, in most simulations, E-AdaUCB performs closely to AdaUCB with thresholds chosen offline.",4.3. AdaUCB under Continuous Load,[0],[0]
"In this section, we evaluate the performance of AdaUCB using both synthetic data and real-world traces.",5. Experiments,[0],[0]
We use the classic UCB(α) and TS (Thompson Sampling) algorithms as comparison baselines.,5. Experiments,[0],[0]
"In both AdaUCB and UCB(α), we set α as α = 0.51, which is close to 1/2 and performs better than a larger α.",5. Experiments,[0],[0]
We note that the gap between AdaUCB and the classic UCB(α) clearly demonstrates the impact of opportunistic learning.,5. Experiments,[0],[0]
"On the other hand, TS is one of the most popular and robust bandit algorithms applied to a wide range of application scenarios.",5. Experiments,[0],[0]
So we apply it here as a reference.,5. Experiments,[0],[0]
"However, because AdaUCB and TS (or other bandit algorithms) improve UCB on different fronts, so their comparison does not clearly show the impact of opportunistic bandit.
AdaUCB under synthetic scenarios.",5. Experiments,[0],[0]
"We consider a 5- armed bandit with Bernoulli rewards, where the expected reward vector is [0.05, 0.1, 0.15, 0.2, 0.25].",5. Experiments,[0],[0]
Fig. 1(a) shows the regrets for different algorithms under random binaryvalue load with 0 = 1 = 0 and ρ = 0.5.,5. Experiments,[0],[0]
"AdaUCB significantly reduces the regret in opportunistic bandits.
",5. Experiments,[0],[0]
"100 102 104 106
Time t
0
50
100
150
R eg
re t
UCB( ) TS",5. Experiments,[0],[0]
"AdaUCB
(a) Binary-valued load
100 102 104 106
Time t
0
20
40
60
80
100
120
140
160
R eg
re t
UCB( ) TS AdaUCB",5. Experiments,[0],[0]
"E-AdaUCB AdaUCB(l(-)=l(+))
",5. Experiments,[0],[0]
"(b) Beta distributed load
Figure 1.",5. Experiments,[0],[0]
Regret under Synthetic Scenarios.,5. Experiments,[0],[0]
"In (a), 0 = 1 = 0, ρ = 0.5.",5. Experiments,[0],[0]
"In (b), for AdaUCB, l(−) = l(−)0.05, l (+) =",5. Experiments,[0],[0]
"l (+) 0.05; for AdaUCB(l (−) = l(+)), l(−) = l(+) = l(−)0.05.
",5. Experiments,[0],[0]
"Specifically, the exploration cost in this case can be zero and AdaUCB achieves O(1) regret.",5. Experiments,[0],[0]
"For continuous load, Fig. 1(b) shows the regrets for different algorithms with beta distributed load.",5. Experiments,[0],[0]
AdaUCB still outperforms the UCB(α) or TS algorithms.,5. Experiments,[0],[0]
"Here, we define l(−)ρ as the lower threshold such that P{Lt ≤",5. Experiments,[0],[0]
"l(−)ρ } = ρ, and l(+)ρ as the upper threshold such that P{Lt ≥",5. Experiments,[0],[0]
l(+)ρ,5. Experiments,[0],[0]
} = ρ.,5. Experiments,[0],[0]
"These simulation results demonstrate that, with appropriately chosen parameters, the proposed AdaUCB and E-AdaUCB algorithms achieve good performance by leveraging the load fluctuation in opportunistic bandits.",5. Experiments,[0],[0]
"As a special case, with a single threshold l(+) = l(−) = l(−)0.05, AdaUCB still outperforms UCB(α) and TS, although it may have higher regret at the beginning.",5. Experiments,[0],[0]
"More simulation results can be found in Appendix D.1, where we study the impact of environment and algorithm parameters such as load fluctuation and the thresholds for load truncation.",5. Experiments,[0],[0]
"In particular, the results show that AdaUCB works well in continuous load when ρ is very small.
AdaUCB applied in MVNO systems.",5. Experiments,[0],[0]
We now evaluate the proposed algorithms using real-world traces.,5. Experiments,[0],[0]
"In an MVNO (Mobile Virtual Network Operator) system, a virtual operator, such as Google Fi (Project Fi, https://fi.google.com), provides services to users by leasing network resources from real mobile operators.",5. Experiments,[0],[0]
"In such a system, the virtual operator would like to provide its users high quality service by accessing the network resources of the real operator with the best network performance.",5. Experiments,[0],[0]
"Therefore, we view each real mobile operator as an arm, and the quality of user experienced on that operator network as the reward.",5. Experiments,[0],[0]
"We use experiment data from Speedometer (Speedometer, https://storage.cloud.google.com/speedometer) and another anonymous operator to conduct the evaluation.",5. Experiments,[0],[0]
More details about the MVNO system can be found in Appendix D.2.,5. Experiments,[0],[0]
"Here, using insights obtained from simulations based on the synthetic data, we choose l(−) and l(+) such that P{Lt ≤ l(−)} = P{Lt ≥ l(+)} = 0.05.",5. Experiments,[0],[0]
"As shown in Fig. 2, the regret of AdaUCB is only about 1/3 of UCB(α),
and the performance of E-AdaUCB is indistinguishable from that of AdaUCB.",5. Experiments,[0],[0]
"This experiment demonstrates the effectiveness of AdaUCB and E-AdaUCB in practical situations, where the load and the reward are continuous and are possibly non-stationary.",5. Experiments,[0],[0]
It also demonstrates the practicality of E-AdaUCB without a priori load distribution information.,5. Experiments,[0],[0]
In this paper we study opportunistic bandits where the regret of pulling a suboptimal arm depends on external conditions such as traffic load or produce price.,6. Conclusions and Future Work,[0],[0]
"We propose AdaUCB that opportunistically chooses between exploration and exploitation based on the load level, i.e., taking the slots with low load level as opportunities for more explorations.",6. Conclusions and Future Work,[0],[0]
"We analyze the regret of AdaUCB, and show that AdaUCB can achieve provable lower regret than the traditional UCB algorithm, and even O(1) regret with respect to time horizon T , under certain conditions.",6. Conclusions and Future Work,[0],[0]
"Experimental results based on both synthetic and real data demonstrate the significant benefits of opportunistic exploration under large load fluctuations.
",6. Conclusions and Future Work,[0],[0]
"This work is a first attempt to study opportunistic bandits, and several open questions remain.",6. Conclusions and Future Work,[0],[0]
"First, although AdaUCB achieves promising experimental performance under general settings, rigorous analysis with tighter performance bound remains challenging.",6. Conclusions and Future Work,[0],[0]
"Furthermore, opportunistic TS-type algorithms are also interesting because TS-type algorithms often performs better than UCB-type algorithms in practice.",6. Conclusions and Future Work,[0],[0]
"Last, we hope to investigate more general relations between the load and actual reward.",6. Conclusions and Future Work,[0],[0]
"This research was supported in part by NSF Grants CCF1423542, CNS-1547461, CNS-1718901.",Acknowledgements,[0],[0]
"The authors would like to thank Prof. Peter Auer (University of Leoben) for his helpful suggestions, and the reviewers for their valuable feedback.",Acknowledgements,[0],[0]
"In this paper, we propose and study opportunistic bandits a new variant of bandits where the regret of pulling a suboptimal arm varies under different environmental conditions, such as network load or produce price.",abstractText,[0],[0]
"When the load/price is low, so is the cost/regret of pulling a suboptimal arm (e.g., trying a suboptimal network configuration).",abstractText,[0],[0]
"Therefore, intuitively, we could explore more when the load/price is low and exploit more when the load/price is high.",abstractText,[0],[0]
"Inspired by this intuition, we propose an Adaptive Upper-Confidence-Bound (AdaUCB) algorithm to adaptively balance the exploration-exploitation tradeoff for opportunistic bandits.",abstractText,[0],[0]
We prove that AdaUCB achieves O(log T ) regret with a smaller coefficient than the traditional UCB algorithm.,abstractText,[0],[0]
"Furthermore, AdaUCB achieves O(1) regret with respect to T if the exploration cost is zero when the load level is below a certain threshold.",abstractText,[0],[0]
"Last, based on both synthetic data and real-world traces, experimental results show that AdaUCB significantly outperforms other bandit algorithms, such as UCB and TS (Thompson Sampling), under large load/price fluctuations.",abstractText,[0],[0]
Adaptive Exploration-Exploitation Tradeoff for Opportunistic Bandits,title,[0],[0]
"Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 861–870, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics",text,[0],[0]
Machine translation (MT) systems suffer from an inconsistent and unstable translation quality.,1 Introduction,[0],[0]
"Depending on the difficulty of the input sentences (sentence length, OOV words, complex sentence structures and the coverage of the MT system’s training data), some translation outputs can be perfect, while others are ungrammatical, missing important words or even totally garbled.",1 Introduction,[0],[0]
"As a result, users do not know whether they can trust the translation output unless they spend time to analyze
∗This work was done when the author was with IBM Research.
the MT output.",1 Introduction,[0],[0]
"This shortcoming is one of the main obstacles for the adoption of MT systems, especially in machine assisted human translation: MT post-editing, where human translators have an option to edit MT proposals or translate from scratch.",1 Introduction,[0],[0]
It has been observed that human translators often discard MT proposals even if some are very accurate.,1 Introduction,[0],[0]
"If MT proposals are used properly, post-editing can increase translators productivity and lead to significant cost savings.",1 Introduction,[0],[0]
"Therefore, it is beneficial to provide MT confidence estimation, to help the translators to decide whether to accept MT proposals, making minor modifications on MT proposals when the quality is high or translating from scratching when the quality is low.",1 Introduction,[0],[0]
"This will save the time of reading and parsing low quality MT and improve user experience.
",1 Introduction,[0],[0]
"In this paper we propose an adaptive quality estimation that predicts sentence-level humantargeted translation error rate (HTER) (Snover et al., 2006) for a document-specific MT post-editing system.",1 Introduction,[0],[0]
HTER is an ideal quality measurement for MT post editing since the reference is obtained from human correction of the MT output.,1 Introduction,[0],[0]
Document-specific MT model is an MT model that is specifically built for the given input document.,1 Introduction,[0],[0]
"It is demonstrated in (Roukos et al., 2012) that document-specific MT models significantly improve the translation quality.",1 Introduction,[0],[0]
"However, this raises two issues for quality estimation.",1 Introduction,[0],[0]
"First, existing approaches to MT quality estimation rely on lexical and syntactical features defined over parallel sentence pairs, which includes source sentences, MT outputs and references, and translation models (Blatz et al., 2004; Ueffing and Ney, 2007; Specia et al., 2009a; Xiong et al., 2010; Soricut and Echihabi, 2010a; Bach et al., 2011).",1 Introduction,[0],[0]
"Therefore, when the MT quality estimation model is trained,
861
it can not be adapted to provide accurate estimates on the outputs of document-specific MT models.",1 Introduction,[0],[0]
"Second, the MT quality estimation might be inconsistent across different document-specific MT models, thus the confidence score is unreliable and not very helpful to users.
",1 Introduction,[0],[0]
"In contrast to traditional static MT quality estimation methods, our approach not only trains the MT quality estimator dynamically for each document-specific MT model to obtain higher prediction accuracy, but also achieves consistency over different document-specific MT models.",1 Introduction,[0],[0]
"The experiments show that our MT quality estimation is highly correlated with human judgment and helps translators to increase the MT proposal adoption rate in post-editing.
",1 Introduction,[0],[0]
We will review related work on MT quality estimation in section 2.,1 Introduction,[0],[0]
In section 3 we will introduce the document-specific MT system built for post-editing.,1 Introduction,[0],[0]
"We describe the static quality estimation method in section 4, and propose the adaptive quality estimation method in section 5.",1 Introduction,[0],[0]
"In section 6 we demonstrate the improvement of MT quality estimation with our method, followed by discussion and conclusion in section 7.",1 Introduction,[0],[0]
There has been a long history of study in confidence estimation of machine translation.,2 Related Work,[0],[0]
"The work of (Blatz et al., 2004) is among the best known study of sentence and word level features for translation error prediction.",2 Related Work,[0],[0]
"Along this line of research, improvements can be obtained by incorporating more features as shown in (Quirk, 2004; Sanchis et al., 2007; Raybaud et al., 2009; Specia et al., 2009b).",2 Related Work,[0],[0]
Soricut and Echihabi (2010b) proposed various regression models to predict the expected BLEU score of a given sentence translation hypothesis.,2 Related Work,[0],[0]
Ueffing and Hey (2007) introduced word posterior probabilities (WPP) features and applied them in the n-best list reranking.,2 Related Work,[0],[0]
"Target part-of-speech and null dependency link are exploited in a MaxEnt classifier to improve the MT quality estimation (Xiong et al., 2010).
",2 Related Work,[0],[0]
"Quality estimation focusing on MT post-editing has been an active research topic, especially after the WMT 2012 (Callison-Burch et al., 2012) and WMT2013 (Bojar et al., 2013) workshops with the “Quality Estimation” shared task.",2 Related Work,[0],[0]
"Biçici et al. (2013) proposes a number of features measuring the similarity of the source sentence to the
source side of the MT training corpus, which, combined with features from translation output, achieved significantly superior performance in the MT QE evaluation.",2 Related Work,[0],[0]
"Felice and Specia (2012) investigates the impact of a large set of linguistically inspired features on quality estimation accuracy, which are not able to outperform the shallower features based on word statistics.",2 Related Work,[0],[0]
GonzálezRubio et al. (2013) proposed a principled method for performing regression for quality estimation using dimensionality reduction techniques based on partial least squares regression.,2 Related Work,[0],[0]
"Given the feature redundancy in MT QE, their approach is able to improve prediction accuracy while significantly reducing the size of the feature sets.",2 Related Work,[0],[0]
"In our MT post-editing setup, we are given documents in the domain of software manuals, technical outlook or customer support materials.",3 Document-specific MT System,[0],[0]
"Each translation request comes as a document with several thousand sentences, focusing on a specific topic, such as the user manual of some software.
",3 Document-specific MT System,[0],[0]
"The input documents are automatically segmented into sentences, which are also called segments.",3 Document-specific MT System,[0],[0]
Thus in the rest of the paper we will use sentences and segments interchangeably.,3 Document-specific MT System,[0],[0]
Our parallel corpora includes tens of millions of sentence pairs covering a wide range of topics.,3 Document-specific MT System,[0],[0]
"Building a general MT system using all the parallel data not only produces a huge translation model (unless with very aggressive pruning), the performance on the given input document is suboptimal due to the unwanted dominance of out-of-domain data.",3 Document-specific MT System,[0],[0]
"Past research suggests using weighted sentences or corpora for domain adaptation (Lu et al., 2007; Matsoukas et al., 2009; Foster et al., 2010).",3 Document-specific MT System,[0],[0]
"Here we adopt the same strategy, building a documentspecific translation model for each input document.
",3 Document-specific MT System,[0],[0]
"The document-specific system is built based on sub-sampling: from the parallel corpora we select sentence pairs that are the most similar to the sentences from the input document, then build the MT system with the sub-sampled sentence pairs.",3 Document-specific MT System,[0],[0]
"The similarity is defined as the number of n-grams that appear in both source sentences, divided by the input sentence’s length, with higher weights assigned to longer n-grams.",3 Document-specific MT System,[0],[0]
"From the extracted sentence pairs, we utilize the standard pipeline in SMT system building: word align-
ment (HMM (Vogel et al., 1996) and MaxEnt (Ittycheriah and Roukos, 2005) alignment models, phrase pair extraction, MT model training (Ittycheriah and Roukos, 2007) and LM model training.",3 Document-specific MT System,[0],[0]
The top region within the dashed line in Figure 1 shows the overall system built pipeline.,3 Document-specific MT System,[0],[0]
"The MT decoder (Ittycheriah and Roukos, 2007) employed in our study extracts various features (source words, morphemes and POS tags, target words and POS tags, etc.) with their weights trained in a maximum entropy framework.",3.1 MT Decoder,[0],[0]
These features are combined with other features used in a typical phrase-based translation system.,3.1 MT Decoder,[0],[0]
"Altogether the decoder incorporates 17 features with weights estimated by PRO (Hopkins and May, 2011) in the decoding process, and achieves state-of-the-art translation performance in various Arabic-English translation evaluations (NIST MT2008, GALE and BOLT projects).",3.1 MT Decoder,[0],[0]
"MT quality estimation is typically formulated as a prediction problem: estimating the confidence
score or translation error rate of the translated sentences or documents based on a set of features.",4 Static MT Quality Estimation,[0],[0]
"In this work, we adopt HTER in (Snover et al., 2006) as our prediction output.",4 Static MT Quality Estimation,[0],[0]
"HTER measures the percentage of insertions, deletions, substitutions and shifts needed to correct the MT outputs.",4 Static MT Quality Estimation,[0],[0]
"In the rest of the paper, we use TER and HTER interchangably.
",4 Static MT Quality Estimation,[0],[0]
"In this section we will first introduce the set of features, and then discuss MT QE problem from classification and regression point of views.",4 Static MT Quality Estimation,[0],[0]
The features for quality estimation should reflect the complexity of the source sentence and the decoding process.,4.1 Features for MT QE,[0],[0]
"Therefore we conduct syntactic analysis on the source sentences, extract features from the decoding process and select the following 26 features:
• 17 decoding features, including phrase translation probabilities (source-to-target and target-to-source), word translation probabilities (also in both directions), maxent probabilities1, word count, phrase count, distor-
1The maxent probability is the translation probability
tion probabilities, as well as a set of language model scores.
",4.1 Features for MT QE,[0],[0]
"• Sentence length, i.e., the number of words in the source sentence.
",4.1 Features for MT QE,[0],[0]
"• Source sentence syntactic features, including the number of noun phrases, verb phrases, adjective phrases, adverb phrases, as inspired by (Green et al., 2013).
",4.1 Features for MT QE,[0],[0]
"• The length of verb phrases, because verbs are typically the roots in dependency structure and they have more varieties during translation.
",4.1 Features for MT QE,[0],[0]
"• The maximum length of source phrases in the final translation, since longer matching source phrase indicates better coverage of the input sentence with possibly better translations.
",4.1 Features for MT QE,[0],[0]
• The number of phrase pairs with high fuzzy match (FM) score.,4.1 Features for MT QE,[0],[0]
The high FM phrases are selected from sentence pairs which are closest in terms of n-gram overlap to the input sentence.,4.1 Features for MT QE,[0],[0]
"These sentences are often found in previous translations of the software manual, and thus are very helpful for translating the current sentence.
",4.1 Features for MT QE,[0],[0]
•,4.1 Features for MT QE,[0],[0]
"The average translation probability of the phrase translation pairs in the final translation, which provides the overall translation quality on the phrase level.
",4.1 Features for MT QE,[0],[0]
"The first 17 features come from the decoding process, which are called “decoding features”.",4.1 Features for MT QE,[0],[0]
The remaining 9 features not related to the decoder are called “external features”.,4.1 Features for MT QE,[0],[0]
"To evaluate the effectiveness of the proposed features, we train various classifiers with different feature configurations to predict whether a translation output is useful (with lower TER) as described in the following section.",4.1 Features for MT QE,[0],[0]
Predicting TER with various input features can be treated as a regression problem.,4.2 MT QE as Classification,[0],[0]
"However for the post-editing task, we argue that it could also be cast as a classification problem: MT system
derived from a Maximum Entropy translation model (Ittycheriah and Roukos, 2005).
users (including the translators) are often interested to know whether a given translation is reasonably good or not.",4.2 MT QE as Classification,[0],[0]
"If useful, they can quickly look through the translation and make minor modifications.",4.2 MT QE as Classification,[0],[0]
"On the other hand, they will just skip reading and parsing the bad translation, and prefer to translate by themselves from scratch.",4.2 MT QE as Classification,[0],[0]
"Therefore we also develop algorithms that classify the translation at different levels, depending on whether the TER is less than a given threshold.",4.2 MT QE as Classification,[0],[0]
"In our experiments, we set TER=0.1 as the threshold.
",4.2 MT QE as Classification,[0],[0]
We randomly select one input document with 2067 sentences for the experiment.,4.2 MT QE as Classification,[0],[0]
"We build a document-specific MT system to translate this document, then ask human translator to correct the translation output.",4.2 MT QE as Classification,[0],[0]
We compute TER for each sentence using the human correction as the reference.,4.2 MT QE as Classification,[0],[0]
"The TER of the whole document is 0.31, which means about 30% errors should be corrected.",4.2 MT QE as Classification,[0],[0]
"In the classification task, our goal is to predict whether a sentence is a Good translation (with TER ≤ 0.1), and label them for human correction.",4.2 MT QE as Classification,[0],[0]
"We adopt a decision tree-based classifier, experimenting with different feature configurations.",4.2 MT QE as Classification,[0],[0]
We select the top 1867 sentences for training and the bottom 200 sentences for test.,4.2 MT QE as Classification,[0],[0]
"In the test set, there are 46 sentences with TER ≤ 0.1.",4.2 MT QE as Classification,[0],[0]
"Table 1 shows the classification accuracy.
",4.2 MT QE as Classification,[0],[0]
"First we can see that as the overall TER is around 0.3, predicting all the sentences being negative already has a strong baseline: 77%.",4.2 MT QE as Classification,[0],[0]
"However this is not helpful for the human translators, because that means they have to translate every sentence from scratch, and consequently there is no productivity gain from MT post-editing.",4.2 MT QE as Classification,[0],[0]
"If we only use the 17 decoding features, it improves the classification accuracy by 9% on the training set, but only 2% on the test set.",4.2 MT QE as Classification,[0],[0]
This is probably due to the overfitting when training the decision tree classifier.,4.2 MT QE as Classification,[0],[0]
"While using the 7 external features, the gain on training set is less but the gain on the test set
is greater (4% improvement), because the translation output is generated based on the log-linear combination of these decoding features, which are biased towards the final translations.",4.2 MT QE as Classification,[0],[0]
"The external features capture the syntactic structure of the source sentence, as well as the coverage of the training data with regard to the input sentence, which are good indicators of the translation quality.",4.2 MT QE as Classification,[0],[0]
"Combining both the decoding features and the external features, we observed the best accuracy on both the training and test set.",4.2 MT QE as Classification,[0],[0]
We will use the combined 26 features in the following work.,4.2 MT QE as Classification,[0],[0]
"For the QE regression task, we predict the TER for each sentence translation using the above 26 features.",4.3 MT QE as Regression,[0],[0]
"We experiment with several classifiers: linear regression model, decision tree based regression model and SVM model.",4.3 MT QE as Regression,[0],[0]
"With the same training and test data set up, we predict the TER for each sentence in the test set, and compute the correlation coefficient (r) and root mean square error (RMSE).",4.3 MT QE as Regression,[0],[0]
Our experiments show that the decision tree-based regression model obtains the highest correlation coefficients (0.53) and lowest RMSE (0.23) in both the training and test sets.,4.3 MT QE as Regression,[0],[0]
We will use this model for the adaptive MT QE in the following work.,4.3 MT QE as Regression,[0],[0]
"The above QE regression model is trained on a portion of the sentences from the input document, and evaluated on the remaining sentences from the same document.",5 Adaptive MT Quality Estimation,[0],[0]
One would like to know whether the trained model can achieve consistent TER prediction accuracy on other documents.,5 Adaptive MT Quality Estimation,[0],[0]
"When we use the cross-document models for prediction, the correlation is significantly worse (the details are discussed in section 6.1).",5 Adaptive MT Quality Estimation,[0],[0]
Therefore it is necessary to build a QE regression model that’s robust to different document-specific translation models.,5 Adaptive MT Quality Estimation,[0],[0]
"To deal with this problem, we propose this adaptive MT QE method described below.
",5 Adaptive MT Quality Estimation,[0],[0]
"Our proposed method is as follows: we select a fixed set of sentence pairs (Sq, Rq) to train the QE model.",5 Adaptive MT Quality Estimation,[0],[0]
The source side of the QE training data Sq is combined with the input document Sd for MT system training data subsampling.,5 Adaptive MT Quality Estimation,[0],[0]
"Once the document-specific MT system is trained, we use it to translate both the input document and the source QE training data, obtaining the translation Td and
Tq .",5 Adaptive MT Quality Estimation,[0],[0]
"We compute the TER of Tq using Rq as the reference, and train a QE regression model with the 26 features proposed in section 4.1.",5 Adaptive MT Quality Estimation,[0],[0]
Then we use this document-specific QE model to predict the TER of the document translation Td.,5 Adaptive MT Quality Estimation,[0],[0]
"As the QE model is adaptively re-trained for each documentspecific MT system, its prediction is more accurate and consistent.",5 Adaptive MT Quality Estimation,[0],[0]
Figure 1 shows the flow of our MT system with the adaptive QE training integrated as part of the built.,5 Adaptive MT Quality Estimation,[0],[0]
"In this section, we first discuss experiments that compare adaptive QE method and static QE method on a few documents, and then present results we obtained after deploying the adaptive QE method in an English-to-Japanese MT PostEditing project.",6 Experiments,[0],[0]
"As mentioned before, the main motivation for us to develop MT QE classification scheme is that translators often discard good MT proposals and translate the segments from scratch.",6 Experiments,[0],[0]
We would like to provide translators with some guidance on reasonably good MT proposals–the sentences with low TERs–to help them increase the leverage on MT proposals to achieve improved productivity.,6 Experiments,[0],[0]
"Our experiment and evaluation is conducted over three documents, each with about 2000 segments.",6.1 Evaluation on Test Set,[0],[0]
"We first build document-specific MT model for each document, then ask human translators to correct the MT outputs and obtain the reference translation.",6.1 Evaluation on Test Set,[0],[0]
"In a typical MT QE scenario, the QE model is pre-trained and applied to various MT outputs, even though the QE training data and MT outputs are generated from different translation models.",6.1 Evaluation on Test Set,[0],[0]
"To evaluate whether such model mismatch matters, we compare the cross-model QE with the same-model QE, where the QE training data and the MT outputs are generated from the same MT model.
",6.1 Evaluation on Test Set,[0],[0]
We select one document LZA with 2067 sentences.,6.1 Evaluation on Test Set,[0],[0]
We use the first 1867 sentences to train the static QE model and the remaining 200 sentences are used as test set for TER prediction.,6.1 Evaluation on Test Set,[0],[0]
"We compute the correlation coefficient (r) between each predicted TER and true TER, as shown in Figure 2.",6.1 Evaluation on Test Set,[0],[0]
"We find that the TER predictions are reasonably correct when the training and test sentences are from the same MT model (the top figure), with correlation coefficients around 0.5.",6.1 Evaluation on Test Set,[0],[0]
"For the crossmodel QE, we train a static QE model with 1867 sentences from another document RTW, and use it to predict the TER of the same 200 sentences from document LZA (the bottom figure).",6.1 Evaluation on Test Set,[0],[0]
"We observe significant degradation of correlation coefficient, dropping from 0.5 to 0.1.",6.1 Evaluation on Test Set,[0],[0]
"This degradation and unstable nature is the prime motivation to develop a more robust MT quality estimation model.
",6.1 Evaluation on Test Set,[0],[0]
"We select 1700 sentences from multiple previously translated documents as the QE training data, which are independent of the test documents.",6.1 Evaluation on Test Set,[0],[0]
"We train the static QE model with this training set, including the source sentences, references and MT outputs (from multiple translation models).",6.1 Evaluation on Test Set,[0],[0]
"To train the adaptive QE model for each test document, we build a translation model whose subsampling data includes source sentences from both the test document and the QE training data.",6.1 Evaluation on Test Set,[0],[0]
"We translate the QE source sentences with this newly built MT model, and the translation output is used to train the QE model specific to each test document.",6.1 Evaluation on Test Set,[0],[0]
"We compare these two QE models on three documents, LZA, RTW and WC7, measuring r and RMSE for each QE model.",6.1 Evaluation on Test Set,[0],[0]
The result is shown in Table 2.,6.1 Evaluation on Test Set,[0],[0]
"We find that the adaptive QE model demonstrates higher r and lower RMSE than the
static QE model for all the test documents.",6.1 Evaluation on Test Set,[0],[0]
"Besides the general correlation with human judgment, we particularly focus on those reasonably good translations, i.e., the sentences with low TERs which can help improve the translator’s productivity most.",6.1 Evaluation on Test Set,[0],[0]
"Here we report the precision, recall and F-score of finding such “Good” sentences (with TER ≤ 0.1) on the three documents in Table 3.",6.1 Evaluation on Test Set,[0],[0]
"Again, the adaptive QE model produces higher recall, mostly higher precision, and significantly improved F-score.",6.1 Evaluation on Test Set,[0],[0]
The overall F-score of the adaptive QE model is 0.282.,6.1 Evaluation on Test Set,[0],[0]
"Compared with the static QE model’s 0.17 F-score, this is relatively 64% improvement.
",6.1 Evaluation on Test Set,[0],[0]
"In the adaptive QE model, the source side QE training data is included in the subsampling process to build the document-specific MT model.",6.1 Evaluation on Test Set,[0],[0]
It would be interesting to know whether this process will negatively affect the MT quality.,6.1 Evaluation on Test Set,[0],[0]
We evaluate the TER of MT outputs with and without the adaptive QE training on the same three documents.,6.1 Evaluation on Test Set,[0],[0]
"As seen in Table 4, we do not notice translation quality degradation.",6.1 Evaluation on Test Set,[0],[0]
"Instead, we observe slightly improvement on two document, with TERs reduction by 0.1-0.4 pt.",6.1 Evaluation on Test Set,[0],[0]
"As our MT model training data include proprietary data, the MT performance is significantly better than publicly available MT software.",6.1 Evaluation on Test Set,[0],[0]
We apply the proposed adaptive QE model to large scale English-to-Japanese MT Post-Editing project on 36 documents with 562K words.,6.2 Impact on Human Translators,[0],[0]
"Each English sentence can be categorized into 3 classes:
• Exact Match (EM): the source sentence is completely covered in the bilingual training corpora thus the corresponding target sentence is returned as the translation;
• Fuzzy Match (FM): the source sentence is similar to some sentence in the training data (similarity measured by string editing distance), the corresponding fuzzy match target sentence (FM proposal) as well as the MT translation output (MT proposal) are returned for human translators to select and correct;
• No Proposal (NP): there is no close match source sentences in the training data (the FM
2The adaptive QE model obtains much higher F-score (80%) on the rest of the sentences (with TER > 0.1).
similarity score of 70% is used as the threshold), therefore only the MT output is returned.
",6.2 Impact on Human Translators,[0],[0]
EM sentences are excluded from the study because in general they do not require editing.,6.2 Impact on Human Translators,[0],[0]
We focus on the FM and NP sentences3.,6.2 Impact on Human Translators,[0],[0]
"In Table 5 we present the precision, recall and F-score of the “Good” sentences in the FM and NP categories, similar to those shown in Table 3.",6.2 Impact on Human Translators,[0],[0]
"We consistently observe higher performance on the FM sentences, in terms of precision, recall and F-score.",6.2 Impact on Human Translators,[0],[0]
This is expected because these sentences are well covered in the training data.,6.2 Impact on Human Translators,[0],[0]
"The overall F-score is in line with the test set results shown in Table 3.
",6.2 Impact on Human Translators,[0],[0]
We are also interested to know whether the proposed adaptive QE method is helpful to human translators in the MT post-editing task.,6.2 Impact on Human Translators,[0],[0]
"Based on the TERs predicted by the adaptive QE model, we assign each MT proposal with a confidence label: High (0 ≤ TER ≤ 0.2), Medium (0.2 < TER ≤ 0.3), or Low (TER > 0.3).",6.2 Impact on Human Translators,[0],[0]
"We present the MT proposals with confidence labels to human translators, then measure the percentage of sentences whose MT proposals are used.",6.2 Impact on Human Translators,[0],[0]
"From Table 6 and 7, we can see that sentences with High and Medium confidence labels are more frequently used by the translators than those with Low labels, for both the FM and NP categories.",6.2 Impact on Human Translators,[0],[0]
"The MT usage for the FM category is less than that for the NP category because translators can choose FM proposals instead of the MT proposals for correction.
",6.2 Impact on Human Translators,[0],[0]
"We also measure the translator’s productivity gain for MT proposals with different confidence
3The word count distribution of EM, FM and NP is 21%, 38% and 41%, respectively.
labels.",6.2 Impact on Human Translators,[0],[0]
The productivity of a translator is defined as the number of source words translated per unit time.,6.2 Impact on Human Translators,[0],[0]
"The post editing tool, IBM TranslationManager, records the time that a translator spends on a segment and computes the number of characters that a translator types on the segment so that we can compute how many words the translator has finished in a given time.
",6.2 Impact on Human Translators,[0],[0]
"We choose the overall productivity of NP0 as the base unit 1, where there is no proposal presents and the translator has to translate the segments from scratch.",6.2 Impact on Human Translators,[0],[0]
"Measured with this unit, for example, the overall productivity of FM0 being 1.14 implies a relative gain of 14% over that of NP0, which demonstrates the effectiveness of FM proposals.
",6.2 Impact on Human Translators,[0],[0]
"Table 6 and 7 also show the productivity gain on sentences with High, Medium and Low labels from FM and NP categories.",6.2 Impact on Human Translators,[0],[0]
"Again, the productivity gain is consistent with the confidence labels from the adaptive QE model’s prediction.",6.2 Impact on Human Translators,[0],[0]
The overall productivity gain with confidence-labeled MT proposals is about 10% (comparing FM1 vs. FM0 and NP1 vs. NP0).,6.2 Impact on Human Translators,[0],[0]
These results clearly demonstrate the effectiveness of the adaptive QE model in aiding the translators to make use of MT proposals and improve productivity.,6.2 Impact on Human Translators,[0],[0]
In this paper we proposed a method to adaptively train a quality estimation model for documentspecific MT post editing.,7 Discussion and Conclusion,[0],[0]
"With the 26 proposed features derived from decoding process and source sentence syntactic analysis, the proposed QE model achieved better TER prediction, higher correlation with human correction of MT output and higher F-score in finding good translations.",7 Discussion and Conclusion,[0],[0]
"The proposed adaptive QE model is deployed to a large scale English-to-Japanese MT post editing project, showing strong correlation with human preference and leading to about 10% gain in human translator productivity.
",7 Discussion and Conclusion,[0],[0]
The training data for QE model can be selected independent of the input document.,7 Discussion and Conclusion,[0],[0]
"With such fixed QE training data, it is possible to measure the consistency of the trained QE models, and to allow the sanity check of the document-specific MT models.",7 Discussion and Conclusion,[0],[0]
"However, adding such data in the subsampling process extracts more bilingual data for building the MT models, which slightly increase the model building time but increased the translation quality.",7 Discussion and Conclusion,[0],[0]
"Another option is to select the sentence pairs from the MT system subsampled training data, which is more similar to the input document thus the trained QE model could be a better match to the input document.",7 Discussion and Conclusion,[0],[0]
"However, the QE model training data is no longer constant.",7 Discussion and Conclusion,[0],[0]
"The model consistency is no longer guaranteed, and the QE training data must be removed from the MT system training data to avoid data contamination.",7 Discussion and Conclusion,[0],[0]
We present an adaptive translation quality estimation (QE) method to predict the human-targeted translation error rate (HTER) for a document-specific machine translation model.,abstractText,[0],[0]
We first introduce features derived internal to the translation decoding process as well as externally from the source sentence analysis.,abstractText,[0],[0]
We show the effectiveness of such features in both classification and regression of MT quality.,abstractText,[0],[0]
"By dynamically training the QE model for the document-specific MT model, we are able to achieve consistency and prediction quality across multiple documents, demonstrated by the higher correlation coefficient and F-scores in finding Good sentences.",abstractText,[0],[0]
"Additionally, the proposed method is applied to IBM English-to-Japanese MT post editing field study and we observe strong correlation with human preference, with a 10% increase in human translators’",abstractText,[0],[0]
Adaptive HTER Estimation for Document-Specific MT Post-Editing,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 656–661 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
656",text,[0],[0]
Neural Machine Translation (NMT) has shown remarkable progress in recent years.,1 Introduction,[1.0],['Neural Machine Translation (NMT) has shown remarkable progress in recent years.']
"However, it requires large amounts of bilingual data to learn a translation model with reasonable quality (Koehn and Knowles, 2017).",1 Introduction,[1.0],"['However, it requires large amounts of bilingual data to learn a translation model with reasonable quality (Koehn and Knowles, 2017).']"
This requirement can be compensated by leveraging curated monolingual linguistic resources in a multi-task learning framework.,1 Introduction,[1.0],['This requirement can be compensated by leveraging curated monolingual linguistic resources in a multi-task learning framework.']
"Essentially, learned knowledge from auxiliary linguistic tasks serves as inductive bias for the translation task to lead to better generalizations.
",1 Introduction,[0],[0]
"Multi-Task Learning (MTL) is an effective approach for leveraging commonalities of related
tasks to improve performance.",1 Introduction,[1.0000000050332092],['Multi-Task Learning (MTL) is an effective approach for leveraging commonalities of related tasks to improve performance.']
"Various recent works have attempted to improve NMT by scaffolding translation task on a single auxiliary task (Domhan and Hieber, 2017; Zhang and Zong, 2016; Dalvi et al., 2017).",1 Introduction,[0],[0]
"Recently, (Niehues and Cho, 2017) have made use of several linguistic tasks to improve NMT.",1 Introduction,[0],[0]
"Their method shares components of the SEQ2SEQ model among the tasks, e.g. encoder, decoder or the attention mechanism.",1 Introduction,[1.0],"['Their method shares components of the SEQ2SEQ model among the tasks, e.g. encoder, decoder or the attention mechanism.']"
"However, this approach has two limitations: (i) it fully shares the components, and (ii) the shared component(s) are shared among all of the tasks.",1 Introduction,[1.0],"['However, this approach has two limitations: (i) it fully shares the components, and (ii) the shared component(s) are shared among all of the tasks.']"
"The first limitation can be addressed using deep stacked layers in encoder/decoder, and sharing the layers partially (Zaremoodi and Haffari, 2018).",1 Introduction,[1.0],"['The first limitation can be addressed using deep stacked layers in encoder/decoder, and sharing the layers partially (Zaremoodi and Haffari, 2018).']"
The second limitation causes this MTL approach to suffer from task interference or inability to leverages commonalities among a subset of tasks.,1 Introduction,[1.0],['The second limitation causes this MTL approach to suffer from task interference or inability to leverages commonalities among a subset of tasks.']
"Recently, (Ruder et al., 2017) tried to address this issue; however, their method is restrictive for SEQ2SEQ scenarios and does not consider the input at each time step to modulate parameter sharing.
",1 Introduction,[0],[0]
"In this paper, we address the task interference problem by learning how to dynamically control the amount of sharing among all tasks.",1 Introduction,[1.0],"['In this paper, we address the task interference problem by learning how to dynamically control the amount of sharing among all tasks.']"
"We extended the recurrent units with multiple blocks along with a routing network to dynamically control sharing of blocks conditioning on the task at hand, the input, and model state.",1 Introduction,[0],[0]
"Empirical results on two low-resource translation scenarios, English to Farsi and Vietnamese, show the effectiveness of the proposed model by achieving +1 BLEU score improvement compared to strong baselines.",1 Introduction,[0],[0]
"Our MTL is based on the sequential encoderdecoder architecture with the attention mecha-
nism (Luong et al., 2015b; Bahdanau et al., 2014).",2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
The encoder/decoder consist of recurrent units to read/generate a sentence sequentially.,2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
Sharing the parameters of the recurrent units among different tasks is indeed sharing the knowledge for controlling the information flow in the hidden states.,2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[1.0],['Sharing the parameters of the recurrent units among different tasks is indeed sharing the knowledge for controlling the information flow in the hidden states.']
"Sharing these parameters among all tasks may, however, lead to task interference or inability to leverages commonalities among subsets of tasks.",2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[1.0],"['Sharing these parameters among all tasks may, however, lead to task interference or inability to leverages commonalities among subsets of tasks.']"
"We address this issue by extending the recurrent units with multiple blocks, each of which processing its own information flow through the time.",2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
The state of the recurrent unit at each time step is composed of the states of these blocks.,2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
The recurrent unit is equipped with a routing mechanism to softly direct the input at each time step to these blocks (see Fig 1).,2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
"Each block mimics an expert in handling different kinds of information, coordinated by the router.",2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
"In MTL, the tasks can use different subsets of these shared experts.
",2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[1.0000000141020897],"['In MTL, the tasks can use different subsets of these shared experts.']"
"(Rosenbaum et al., 2018) uses a routing network for adaptive selection of non-linear functions for MTL.",2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
"However, it is for fixed-size inputs based on a feed-forward architecture, and is not applicable to SEQ2SEQ scenarios such as MT.",2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
"(Shazeer et al., 2017) uses Mixture-of-Experts (feed-forward sub-networks) between stacked layers of recurrent units, to adaptively gate state information vertically.",2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
"This is in contrast to our approach where the horizontal information flow is adaptively modulated, as we would like to minimise the task interference in MTL.
",2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
"Assuming there are n blocks in a recurrent unit, we share n− 1 blocks among the tasks, and let the last one to be task-specific1.",2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
Task-specific block receives the input of the unit directly while shared blocks are fed with modulated input by the routing network.,2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
The state of the unit at each time-step would be the aggregation of blocks’ states.,2 SEQ2SEQ MTL Using Recurrent Unit with Adaptive Routed Blocks,[0],[0]
"At each time step, the routing network is responsible to softly forward the input to the shared blocks conditioning on the input xt, and the previous hidden state of the unit ht−1 as follows:
st = tanh(Wx · xt",2.1 Routing Mechanism,[0],[0]
"+Wh · ht−1 + bs), τt = softmax(Wτ · st + bτ ),
where W ’s and b’s are the parameters.",2.1 Routing Mechanism,[0],[0]
"Then, the i-th shared block is fed with the input of the
1multiple recurrent units can be stacked on top of each other to consist a multi-layer component
unit modulated by the corresponding output of the routing network x̃(i)t = τt[i]xt where τt[i] is the scalar output of the routing network for the i-th block.
",2.1 Routing Mechanism,[0.9999999962822641],"['Then, the i-th shared block is fed with the input of the 1multiple recurrent units can be stacked on top of each other to consist a multi-layer component unit modulated by the corresponding output of the routing network x̃(i)t = τt[i]xt where τt[i] is the scalar output of the routing network for the i-th block.']"
The hidden state of the unit is the concatenation of the hidden state of the shared and taskspecific parts,2.1 Routing Mechanism,[0],[0]
ht =,2.1 Routing Mechanism,[0],[0]
[h (shared) t ;h (task) t ].,2.1 Routing Mechanism,[0],[0]
"The state of task-specific part is the state of the corresponding block h(task)t = h (n+1) t , and the state of the shared part is the sum of states of shared blocks weighted by the outputs of the routing network h (shared) t = ∑n i=1 τt[i]h",2.1 Routing Mechanism,[0.9917439824777435],"['The state of task-specific part is the state of the corresponding block h(task)t = h (n+1) t , and the state of the shared part is the sum of states of shared blocks weighted by the outputs of the routing network h (shared) t = ∑n i=1 τt[i]h (i) t .']"
(i) t .,2.1 Routing Mechanism,[0],[0]
Each block is responsible to control its own flow of information via a standard gating mechanism.,2.2 Block Architecture,[1.0],['Each block is responsible to control its own flow of information via a standard gating mechanism.']
"Our recurrent units are agnostic to the internal architecture of the blocks; we use the gated-recurrent unit (Cho et al., 2014) in this paper.",2.2 Block Architecture,[1.0],"['Our recurrent units are agnostic to the internal architecture of the blocks; we use the gated-recurrent unit (Cho et al., 2014) in this paper.']"
"For the i-th block the corresponding equations are as follows:
z (i) t = σ(W (i) z",2.2 Block Architecture,[0],[0]
x̃ (i) t +U (i),2.2 Block Architecture,[0],[0]
z h,2.2 Block Architecture,[0],[0]
(i) t−1 + b,2.2 Block Architecture,[0],[0]
"(i) z ), r (i) t = σ(W",2.2 Block Architecture,[0],[0]
(i) r x̃,2.2 Block Architecture,[0],[0]
(i) t,2.2 Block Architecture,[0],[0]
+U (i) r h,2.2 Block Architecture,[0],[0]
(i) t−1 + b,2.2 Block Architecture,[0],[0]
"(i) r ), h̃ (i) t =",2.2 Block Architecture,[0],[0]
tanh(W (i) h,2.2 Block Architecture,[0],[0]
x̃ (i) t +U (i),2.2 Block Architecture,[0],[0]
h h,2.2 Block Architecture,[0],[0]
(i) t−1 + b,2.2 Block Architecture,[0],[0]
(i) h ),2.2 Block Architecture,[0],[0]
", h (i) t = z",2.2 Block Architecture,[0],[0]
(i) t h (i) t−1,2.2 Block Architecture,[0],[0]
+ (1− z (i) t ),2.2 Block Architecture,[0],[0]
h̃ (i) t .,2.2 Block Architecture,[0],[0]
"The rest of the model is similar to attentional SEQ2SEQ model (Luong et al., 2015b) which computes the conditional probability of the target sequence given the source Pθ(y|x) =∏ j Pθ(yj |y<jx).",2.3 Training Objective and Schedule.,[0],[0]
"For the case of training M + 1 SEQ2SEQ transduction tasks, each of which is associated with a training set Dm := {(xi,yi)}Nmi=1, the parameters of MTL architecture Θmtl =
{Θm}Mm=0 are learned by maximizing the following objective: Lmtl(Θmtl) := M∑ m=0 γm |Dm| ∑ (x,y)∈Dm logPΘm(y|x)
where |Dm| is the size of the training set for themth task, and γm is responsible to balance the influence of tasks in the training objective.",2.3 Training Objective and Schedule.,[0],[0]
"We explored different values in preliminary experiments, and found that for our training schedule γ = 1 for all tasks results in the best performance.",2.3 Training Objective and Schedule.,[0],[0]
"Generally, γ is useful when the dataset sizes for auxiliary tasks are imbalanced (our training schedule handles the main task).
",2.3 Training Objective and Schedule.,[0],[0]
Variants of stochastic gradient descent (SGD) can be used to optimize the objective function.,2.3 Training Objective and Schedule.,[0],[0]
"In our training schedule, we randomly select a mini-batch from the main task (translation) and another mini-batch from a randomly selected auxiliary task to make the next SGD update.",2.3 Training Objective and Schedule.,[0],[0]
Selecting a mini-batch from the main task in each SGD update ensures that its training signals are not washed out by auxiliary tasks.,2.3 Training Objective and Schedule.,[0],[0]
"We use two language-pairs, translating from English to Farsi and Vietnamese.",3.1 Bilingual Corpora,[0],[0]
We have chosen them to analyze the effect of multi-task learning on languages with different underlying linguistic structures2.,3.1 Bilingual Corpora,[0],[0]
"We apply BPE (Sennrich et al., 2016) on the union of source and target vocabularies for English-Vietnamese, and separate vocabularies for English-Farsi as the alphabets are disjoined (30K BPE operations).",3.1 Bilingual Corpora,[0],[0]
"Further details about the corpora and their pre-processing is as follows:
• The English-Farsi corpus has ∼105K sentence pairs.",3.1 Bilingual Corpora,[0],[0]
"It is assembled from English-Farsi parallel subtitles from the TED corpus (Tiedemann, 2012), accompanied by all the parallel news text in LDC2016E93 Farsi Representative Language Pack from the Linguistic Data Consortium.",3.1 Bilingual Corpora,[1.0],"['It is assembled from English-Farsi parallel subtitles from the TED corpus (Tiedemann, 2012), accompanied by all the parallel news text in LDC2016E93 Farsi Representative Language Pack from the Linguistic Data Consortium.']"
The corpus has been normalized using the Hazm toolkit3.,3.1 Bilingual Corpora,[0],[0]
We have removed sentences with more than 80 tokens in either side (before applying BPE).,3.1 Bilingual Corpora,[0],[0]
"3k and 4k sentence pairs were held out for the purpose of validation and test.
",3.1 Bilingual Corpora,[0],[0]
"2English and Vietnamese are SVO, and Farsi is SOV.",3.1 Bilingual Corpora,[0],[0]
"3www.sobhe.ir/hazm
• The English-Vietnamese has ∼133K training pairs.",3.1 Bilingual Corpora,[0],[0]
"It is the preprocessed version of the IWSLT 2015 translation task provided by (Luong and Manning, 2015).",3.1 Bilingual Corpora,[0],[0]
It consists of subtitles and their corresponding translations of a collection of public speeches from TED and TEDX talks.,3.1 Bilingual Corpora,[0],[0]
"The “tst2012” and “tst2013” parts are used as validation and test sets, respectively.",3.1 Bilingual Corpora,[0],[0]
We have removed sentence pairs which had more than 300 tokens after applying BPE on either sides.,3.1 Bilingual Corpora,[0],[0]
"We have chosen the following auxiliary tasks to leverage the syntactic and semantic knowledge to improve NMT:
Named-Entity Recognition (NER).",3.2 Auxiliary Tasks,[0],[0]
It is expected that learning to recognize named-entities help the model to learn translation pattern by masking out named-entites.,3.2 Auxiliary Tasks,[0],[0]
We have used the NER data comes from the CONLL shared task.4 Sentences in this dataset come from a collection of newswire articles from the Reuters Corpus.,3.2 Auxiliary Tasks,[0],[0]
"These sentences are annotated with four types of named entities: persons, locations, organizations and names of miscellaneous entities.
",3.2 Auxiliary Tasks,[0],[0]
Syntactic Parsing.,3.2 Auxiliary Tasks,[0],[0]
"By learning the phrase structure of the input sentence, the model would be able to learn better re-ordering.",3.2 Auxiliary Tasks,[0],[0]
"Specially, in the case of language pairs with high level of syntactic divergence (e.g. English-Farsi).",3.2 Auxiliary Tasks,[0],[0]
"We have used Penn Tree Bank parsing data with the standard split for training, development, and test (Marcus et al., 1993).",3.2 Auxiliary Tasks,[0],[0]
"We cast syntactic parsing to a SEQ2SEQ transduction task by linearizing constituency trees (Vinyals et al., 2015).
",3.2 Auxiliary Tasks,[0],[0]
Semantic Parsing.,3.2 Auxiliary Tasks,[0],[0]
Learning semantic parsing helps the model to abstract away the meaning from the surface in order to convey it in the target translation.,3.2 Auxiliary Tasks,[0],[0]
"For this task, we have used the Abstract Meaning Representation (AMR) corpus Release 2.0 (LDC2017T10)5.",3.2 Auxiliary Tasks,[1.0],"['For this task, we have used the Abstract Meaning Representation (AMR) corpus Release 2.0 (LDC2017T10)5.']"
"This corpus contains natural language sentences from newswire, weblogs, web discussion forums and broadcast conversations.",3.2 Auxiliary Tasks,[1.0],"['This corpus contains natural language sentences from newswire, weblogs, web discussion forums and broadcast conversations.']"
"We cast this task to a SEQ2SEQ transduction task by linearizing the AMR graphs (Konstas et al., 2017).
",3.2 Auxiliary Tasks,[0],[0]
4https://www.clips.uantwerpen.be/conll2003/ner 5https://catalog.ldc.upenn.edu/LDC2017T10,3.2 Auxiliary Tasks,[0],[0]
"We have implemented the proposed MTL architecture along with the baselines in C++ using DyNet (Neubig et al., 2017) on top of Mantis (Cohn et al., 2016) which is an implementation of the attentional SEQ2SEQ NMT model.",3.3 Models and Baselines,[0],[0]
"For our MTL architecture, we used the proposed recurrent unit with 3 blocks in encoder and decoder.",3.3 Models and Baselines,[0],[0]
"For the fair comparison in terms the of number of parameters, we used 3 stacked layers in both encoder and decoder components for the baselines.",3.3 Models and Baselines,[0],[0]
"We compare against the following baselines:
• Baseline 1: The vanilla SEQ2SEQ model (Luong et al., 2015a) without any auxiliary task.
",3.3 Models and Baselines,[0],[0]
"• Baseline 2: The MTL architecture proposed in (Niehues and Cho, 2017) which fully shares parameters in components.",3.3 Models and Baselines,[0],[0]
We have used their best performing architecture with our training schedule.,3.3 Models and Baselines,[0],[0]
"We have extended their work with deep stacked layers for the sake of comparison.
",3.3 Models and Baselines,[0],[0]
"• Baseline 3: The MTL architecture proposed in (Zaremoodi and Haffari, 2018) which uses deep stacked layers in the components and shares the parameters of the top two/one stacked layers among encoders/decoders of all tasks6.
",3.3 Models and Baselines,[0],[0]
"For the proposed MTL, we use recurrent units with 400 hidden dimensions for each block.",3.3 Models and Baselines,[0],[0]
The encoders and decoders of the baselines use GRU units with 400 hidden dimensions.,3.3 Models and Baselines,[0],[0]
The attention component has 400 dimensions.,3.3 Models and Baselines,[0],[0]
"We use Adam optimizer (Kingma and Ba, 2014) with the initial learning rate of 0.003 for all the tasks.",3.3 Models and Baselines,[1.0],"['We use Adam optimizer (Kingma and Ba, 2014) with the initial learning rate of 0.003 for all the tasks.']"
"Learning
6In preliminary experiments, we have tried different sharing scenarios and this one led to the best results.
rates are halved on the decrease in the performance on the dev set of corresponding task.",3.3 Models and Baselines,[0],[0]
"Mini-batch size is set to 32, and dropout rate is 0.5.",3.3 Models and Baselines,[0],[0]
"All models are trained for 50 epochs and the best models are saved based on the perplexity on the dev set of the translation task.
",3.3 Models and Baselines,[0.9999999459228045],['All models are trained for 50 epochs and the best models are saved based on the perplexity on the dev set of the translation task.']
"For each task, we add special tokens to the beginning of source sequence (similar to (Johnson et al., 2017)) to indicate which task the sequence pair comes from.
",3.3 Models and Baselines,[0],[0]
We used greedy decoding to generate translation.,3.3 Models and Baselines,[0],[0]
"In order to measure translation quality, we use BLEU7 (Papineni et al., 2002) and TER (Snover et al., 2006) scores.",3.3 Models and Baselines,[0],[0]
Table 1 reports the results for the baselines and our proposed method on the two aforementioned translation tasks.,3.4 Results and analysis,[1.0],['Table 1 reports the results for the baselines and our proposed method on the two aforementioned translation tasks.']
"As expected, the performance of MTL models are better than the baseline 1 (only MT task).",3.4 Results and analysis,[0],[0]
"As seen, partial parameter sharing is more effective than fully parameter sharing.",3.4 Results and analysis,[1.0],"['As seen, partial parameter sharing is more effective than fully parameter sharing.']"
"Furthermore, our proposed architecture with adaptive
7Using “multi-bleu.perl” script from Moses (Koehn et al., 2007).
",3.4 Results and analysis,[0],[0]
"sharing performs better than the other MTL methods on all tasks, and achieve +1 BLEU score improvements on the test sets.",3.4 Results and analysis,[0],[0]
"The improvements in the translation quality of NMT models trained by our MTL method may be attributed to less interference with multiple auxiliary tasks.
",3.4 Results and analysis,[0.9999999128276351],['The improvements in the translation quality of NMT models trained by our MTL method may be attributed to less interference with multiple auxiliary tasks.']
"Figure 2 shows the average percentage of block usage for each task in an MTL model with 3 shared blocks, on the English-Farsi test set.",3.4 Results and analysis,[0],[0]
We have aggregated the output of the routing network for the blocks in the encoder recurrent units over all the input tokens.,3.4 Results and analysis,[0],[0]
"Then, it is normalized by dividing on the total number of input tokens.",3.4 Results and analysis,[0],[0]
"Based on Figure 2, the first and third blocks are more specialized (based on their usage) for the translation and NER tasks, respectively.",3.4 Results and analysis,[0],[0]
"The second block is mostly used by the semantic and syntactic parsing tasks, so specialized for them.",3.4 Results and analysis,[1.0],"['The second block is mostly used by the semantic and syntactic parsing tasks, so specialized for them.']"
This confirms our model leverages commonalities among subsets of tasks by dedicating common blocks to them to reduce task interference.,3.4 Results and analysis,[1.0],['This confirms our model leverages commonalities among subsets of tasks by dedicating common blocks to them to reduce task interference.']
"We have presented an effective MTL approach to improve NMT for low-resource languages, by leveraging curated linguistic resources on the source side.",4 Conclusions,[0],[0]
We address the task interference issue in previous MTL models by extending the recurrent units with multiple blocks along with a trainable routing network.,4 Conclusions,[1.0],['We address the task interference issue in previous MTL models by extending the recurrent units with multiple blocks along with a trainable routing network.']
"Our experimental results on low-resource English to Farsi and Vietnamese datasets, show +1 BLEU score improvements compared to strong baselines.",4 Conclusions,[1.0],"['Our experimental results on low-resource English to Farsi and Vietnamese datasets, show +1 BLEU score improvements compared to strong baselines.']"
"The research reported here was initiated at the 2017 Frederick Jelinek Memorial Summer Workshop on Speech and Language Technologies, hosted at Carnegie Mellon University and sponsored by Johns Hopkins University with unrestricted gifts from Amazon, Apple, Facebook, Google, and Microsoft.",Acknowledgments,[0],[0]
We are very grateful to the workshop members for the insightful discussions and data pre-processing.,Acknowledgments,[0],[0]
"This work was supported by the Multi-modal Australian ScienceS Imaging and Visualisation Environment (MASSIVE) (www.massive.org.au), and by the Australian Research Council through DP160102686.",Acknowledgments,[0],[0]
The first author was partly supported by CSIRO’s Data61.,Acknowledgments,[0],[0]
We would like to thank the anonymous reviewers for their constructive feedback.,Acknowledgments,[0],[0]
Neural Machine Translation (NMT) is notorious for its need for large amounts of bilingual data.,abstractText,[0],[0]
An effective approach to compensate for this requirement is MultiTask Learning (MTL) to leverage different linguistic resources as a source of inductive bias.,abstractText,[0],[0]
"Current MTL architectures are based on the SEQ2SEQ transduction, and (partially) share different components of the models among the tasks.",abstractText,[0],[0]
"However, this MTL approach often suffers from task interference, and is not able to fully capture commonalities among subsets of tasks.",abstractText,[0],[0]
We address this issue by extending the recurrent units with multiple blocks along with a trainable routing network.,abstractText,[0],[0]
"The routing network enables adaptive collaboration by dynamic sharing of blocks conditioned on the task at hand, input, and model state.",abstractText,[0],[0]
"Empirical evaluation of two low-resource translation tasks, English to Vietnamese and Farsi, show +1 BLEU score improvements compared to strong baselines.",abstractText,[0],[0]
Adaptive Knowledge Sharing in Multi-Task Learning: Improving Low-Resource Neural Machine Translation,title,[0],[0]

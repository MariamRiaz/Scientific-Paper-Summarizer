0	79	Logic-based semantic representations have played an important role in the study of semantic parsing and inference.
1	58	For English, several methods have been proposed to map outputs of parsers based on syntactic theories like CCG (Steedman, 2000) onto logical formulas (Bos, 2015).
2	11	Output formulas have been used in various tasks, including Question Answering (Lewis and Steedman, 2013) and Recognizing Textual Entailment (RTE) (Bos and Markert, 2005; Beltagy et al., 2013; Bjerva et al., 2014).
4	21	Recently, the method of inducing wide-coverage CCG resources for English (Hockenmaier and Steedman, 2007) has been applied to Japanese and a robust CCG parser based on it has been developed (Uematsu et al., 2015).
5	15	However, building a method to map CCG trees in Japanese onto logical formulas is not a trivial task, mainly due to the differences in syntactic structures between English and Japanese (Section 3).
8	44	Output representations are formulas in higher-order logic (HOL) combined with NeoDavidsonian Event Semantics (Parsons, 1990).
11	18	Although it is usually thought that HOL is unfeasible for practical applications, the results show that the entire system is able to perform efficient logical inference on complex linguistic phenomena such as generalized quantifiers and intensional modifiers — phenomena that pose challenges to the standard first-order-logic-based approaches.
17	13	Accordingly, it has been standard in formal semantics of natural language to use HOL as a representation language (Montague, 1974).
20	28	Recently, based on the evaluation on the FraCaS dataset (Cooper et al., 1994), Mineshima et al. (2015) showed that a higher-order inference system outperformed the Boxer/Nutcracker’s firstorder system (Bos, 2008) in both speed and accuracy.
22	14	There are three main steps in our pipeline.
25	11	We use a Japanese CCG parser Jigg (Noji and Miyao, 2016)1, a statistical parser based on Japanese CCGbank (Uematsu et al., 2015).
51	14	As is seen in (2), we adopt the unique-role requirement for case markers (Carlson, 1984); for instance, the nominative case marker does not denote the relation Nom(v, x), as in the event semantics in Boxer (Bos, 2008), but the function Nom(v)=x.
56	34	VP modifiers such as slowly license an inference from John walked slowly to John walked, an inference correctly captured by the formula in (2).
58	12	Thus, the sentence John almost walked does not entail John walked (Dowty, 1979).
59	27	While it is not easy to provide a desirable analysis in first-order language (Hobbs, 1985), HOL gives a perspicuous representation: (3) ∃v(almost(walk, v)∧ (Nom(v)= john)∧Past(v)) Here, almost is a higher-order predicate having the semantic type (Ev ⇒ Prop) ⇒ Ev ⇒ Prop.
60	11	The meaning assignment to VP modifiers of category S/S in Table 1 is for extensional modifiers; an intensional modifier is assigned the representation λSK.S(λJv.K(Base(J), v)) in the lexical entry, which results in a representation as in (3).
74	30	Following the analysis in Mineshima et al. (2015), we analyze non-first-order generalized quantifier most as having the higher-order logical form Most(F,G), where Most has the type of generalized quantifier (E⇒ Prop)⇒ (E⇒ Prop)⇒ Prop.
77	12	We evaluate our system3 on Japanese Semantics test suite (JSeM)4 (Kawazoe et al., 2015), a Japanese dataset for textual entailment designed in a similar way to the FraCaS dataset for English.
80	31	Each problem has one or more premises, followed by a hypothesis.
81	37	There are three types of answer: yes (entailment), no (contradiction), and unknown (neutral).
90	26	Given premises P1, ... , Pn and a hypothesis H, the system outputs yes (P1∧· · ·∧Pn→H is proved), no (P1∧· · ·∧Pn→¬H is proved), or unknown (neither is proved in a fixed proof-search space).6 We set a 30 seconds timeout for each inference run; the system outputs unknown after it.
93	19	The system with gold syntactic parses achieved 86% accuracy on the total 523 problems, with high precision and reasonable speed.
95	13	SLC refers to the performance of a supervised learning classifier8 based on 5-fold cross-validation for each section.
100	36	The total accuracy of our system is comparable to that of Mineshima et al. (2015).
101	19	Most errors we found are due to syntactic parse errors caused by the CCG parser, where no correct syntactic parses were found in n-best responses.
102	20	Comparison between gold parses and system parses shows that correct syntactic disambiguation improves performance.
103	47	To our knowledge, this study provides the first semantic parsing system based on CCG that compositionally maps real texts in Japanese onto logical forms.
105	28	The evaluation on JSeM showed that our system performs efficient logical inference on various semantic phenomena, including those that challenge the standard FOL.
106	18	The attractiveness of a logic-based system is that it is highly modular and can be extended with other components such as a robust knowledge base (Lewis and Steedman, 2013; Beltagy et al., 2013; Bjerva et al., 2014).
107	122	Such an extension will be a focus of future work.

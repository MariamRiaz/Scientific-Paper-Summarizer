0	84	Human languages exhibit a wide range of phenomena, within some limits.
1	12	However, some structures seem to occur or co-occur more frequently than others.
2	48	Linguistic typology attempts to describe the range of natural variation and seeks to organize and quantify linguistic universals, such as patterns of co-occurrence.
3	39	Perhaps one of the simplest typological questions comes from phonology: which vowels tend to occur and co-occur within the phoneme inventories of different languages?
5	182	It is a typological universal that every language contains both vowels and consonants (Velupillai, 2012).
6	87	But which vowels a language contains is guided by softer constraints, in that certain configurations are more widely attested than others.
9	29	Moreover, while over 600 unique vowel phonemes have been attested cross-linguistically (Moran et al., 2014), certain regions of acoustic space are used much more often than others, e.g., the regions conventionally transcribed as [a], [i], and [u].
21	65	The majority of languages have 5–7 vowels, and there are only a handful of distinct 4-vowel systems attested despite many possibilities.
31	17	We consider each vowel listed in the International Phonetic Alphabet (IPA) to be cross-linguistically characterized by some (F1, F2) pair.
48	33	A good vowel system now consists of vowels that contrast with each other and are individually desirable (Schwartz et al., 1997).
50	12	Given a base set V , a point process is a distribution over its subsets.2 In this paper, we take V to be the set of all IPA symbols corresponding to vowels.
52	47	We will consider three basic point process models for vowel systems: the Bernoulli Point Process, the Markov Point Process and the Determinantal Point Process.
54	21	, vN}, a Bernoulli point process (BPP) makes an independent decision about whether to include each vowel in the subset.
55	42	The probability of a vowel system V ⊆ V is thus p(V ) ∝ ∏ vi∈V φ(vi), (1) where φ is a unary potential function, i.e., φ(vi) ≥ 0.
58	16	The probability that the inventory V contains vi is φ(vi)/(1 + φ(vi)), independent of the other vowels in V .
59	12	Since a BPP predicts each vowel independently, it only models focalization.
60	45	Thus, the model provides an appropriate baseline that will let us measure the importance of the dispersion principle—how far can we get with just focalization?
63	19	A Markov Point Process (MPP) (Van Lieshout, 2000)—also known as a Boltzmann machine (Ackley et al., 1985; Hinton and Sejnowski, 1986)— generalizes the BPP by adding pairwise interactions between vowels.
68	13	Unlike the BPP, the MPP can capture both focalization and dispersion.
69	22	In this work, we will consider a fully connected MPP, i.e., there is a potential function for each pair of vowels in V .
74	16	At each time step, for some random vi ∈ V , it stochastically decides whether to replace the current inventory V with V̄ , where V̄ is a copy of V with vi added (if vi /∈ V ) or removed (if vi ∈ V ).
76	75	Inference requires only a few matrix computations and runs tractably in O(|V|3) time, even though the model may encode a rich set of multi-way interactions.
90	19	At this point it is helpful to introduce the empirical dataset we will model.
121	30	Interpretable Neural Embedding.
122	30	We are interested in the special case of neural embeddings when r = k since then (for any d) the mapping f(vi) 7→ e(vi) is a diffeomorphism:8 a smooth invertible function of Rk.
141	47	The idea is that dispersion is measured in the interpretable space Rk, and focalization is defined by certain “good” regions in that space that are centered at the r prototypes.
144	297	In other words, how likely does our model think unobserved, but attested vowel systems are?
146	65	As a second evaluation, we introduce a vowel system cloze task that could also be used to evaluate non-probabilistic models.
147	19	This task is defined by analogy to the traditional semantic cloze task (Taylor, 1953), where the reader is asked to fill in a missing word in the sentence from the context.
149	27	Consider, as a concrete example, the general American English vowel system (excluding long vowels) {[i], [I], [u], [U], [E], [æ], [O], [A], [@]}.

10	4	While using uncertainties over transition probabilities to avoid worst-case behavior has been well-studied in discrete MDPs (e.g. (Shapiro & Kleywegt, 2002; Nilim & El Ghaoui, 2005; Bagnell et al., 2001), to our knowledge, our work is the first to consider continuous non-linear functions with complex noise.
16	3	The network output is corrupted by the additive noise variable n ∼ N (0,Σ) with diagonal covariance matrix Σ.
23	5	The reader is referred to the work of Hernández-Lobato et al. (2016); Depeweg et al. (2016) for more details on this.
25	3	While other values of α are possible, this specific value produced better uncertainty decompositions in practice: see Section 4 and the supplementary material for results with α = 0.5 and α = 0 (variational Bayes).
39	4	This means that there are two types of uncertainties entangled in our predictons for y?
47	4	Let H(·) compute the differential entropy of a probability distribution.
80	4	(5) can be approximated using standard entropy estimators, e.g. nearest-neighbor methods (Kozachenko & Leonenko, 1987; Kraskov et al., 2004; Gao et al., 2016).
125	7	and compare it with two baselines.
128	7	since in this case the uncertainty decomposition is not necessary because the GP model does not include latent variables.
129	9	The GP model assumes Gaussian noise and is not able to capture complex stochastic patterns.
132	3	We start with the available data shown in the previous figures.
134	11	The selected data is then included in the training set and the log-likelihood is evaluated on a separate test set.
146	4	We assume that the true dynamical system can be expressed by an unknown neural network with latent variables: st = ftrue(st−1,at−1, zt;Wtrue) , zt ∼ N (0, γ) , (7) whereWtrue denotes the weights of the network and st−1, at−1 and zt are the inputs to the network.
147	3	We use BNN+LV from Section 2 to approximate a posterior q(W, z) using the batch D (Depeweg et al., 2016).
160	4	The reason for this is that the latter is a more restrictive criterion since low risk on the ct will imply low risk on C, but not the other way around.
171	4	We call this term the epistemic risk.
175	5	(10), and then summing the resulting expression for t = 1, .
193	12	(12) is impossible to compute in practice because we do not know the ground truth dynamics.
195	4	We can then rewrite Etrue[ct] as E[ct|Wtrue] and since we do not knowWtrue, we can further assume thatWtrue ∼ q(W).
212	3	The behavioral policy has limited randomness and will keep the system dynamics constrained to a reduced manifold in state space.
229	3	The policy that ignores risk (β = γ = 0) results in both high model-bias and high cost when evaluated on the ground truth, which indicates overfitting.
233	4	The nn-baseline shows a similar pattern as the BNN+LV approach, but the trade-off between model-bias and cost is worse.
234	6	Figure 5 shows roll-outs for three different policies and a fixed initial state s0.
243	22	In this case, the best trade-offs between expected cost and model-bias are obtained by the policies with γ = 7.5.
244	17	These policies are noise averse and will try to avoid noisy regions in state space.
245	11	This makes sense because in wind turbines, high noise regions in state space are those where the effect of wind turbulence will have a strong impact on the average cost.
260	5	We have described a decomposition of predictive uncertainty into its epistemic and aleatoric components when working with Bayesian neural networks with latent variables.
261	13	We have shown how this decomposition of uncertainty can be used for active learning, where it naturally arises from an information-theoretic perspective.
262	191	We have also used the decomposition to propose a novel risk-sensitive criterion for model-based reinforcement learning which decomposes risk into model-bias and noise aversion components.
263	192	Our experiments illustrate how the described decomposition of uncertainty is useful for efficient and risk-sensitive learning.

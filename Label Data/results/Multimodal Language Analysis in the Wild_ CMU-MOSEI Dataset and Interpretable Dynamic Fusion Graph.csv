0,1,label2,summary_sentences
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3622–3631 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3622",text,[0],[0]
"Despite the massive success brought by neural machine translation (NMT, Sutskever et al., 2014; Bahdanau et al., 2015; Vaswani et al., 2017), it has been noticed that the vanilla NMT often lags behind conventional machine translation systems, such as statistical phrase-based translation systems (PBMT, Koehn et al., 2003), for low-resource language pairs (see, e.g., Koehn and Knowles, 2017).",1 Introduction,[0],[0]
"In the past few years, various approaches have been proposed to address this issue.",1 Introduction,[0],[0]
"The first attempts at tackling this problem exploited the availability of monolingual corpora (Gulcehre
* Equal contribution.
",1 Introduction,[0],[0]
"et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016).",1 Introduction,[0.9724499355447485],"['Modeling multimodal language has recently become a centric research direction in both NLP and multimodal machine learning (Hazarika et al., 2018; Zadeh et al., 2018a; Poria et al., 2017a; Baltrušaitis et al., 2017; Chen et al., 2017).']"
"It was later followed by approaches based on multilingual translation, in which the goal was to exploit knowledge from high-resource language pairs by training a single NMT system on a mix of high-resource and low-resource language pairs (Firat et al., 2016a,b; Lee et al., 2016; Johnson et al., 2016; Ha et al., 2016b).",1 Introduction,[0],[0]
"Its variant, transfer learning, was also proposed by Zoph et al. (2016), in which an NMT system is pretrained on a high-resource language pair before being finetuned on a target low-resource language pair.
",1 Introduction,[0],[0]
"In this paper, we follow up on these latest approaches based on multilingual NMT and propose a meta-learning algorithm for low-resource neural machine translation.",1 Introduction,[0],[0]
"We start by arguing that the recently proposed model-agnostic meta-learning algorithm (MAML, Finn et al., 2017) could be applied to low-resource machine translation by viewing language pairs as separate tasks.",1 Introduction,[0],[0]
This view enables us to use MAML to find the initialization of model parameters that facilitate fast adaptation for a new language pair with a minimal amount of training examples (§3).,1 Introduction,[0],[0]
"Furthermore, the vanilla MAML however cannot handle tasks with mismatched input and output.",1 Introduction,[0],[0]
"We overcome this limitation by incorporating the universal lexical representation (Gu et al., 2018b) and adapting it for the meta-learning scenario (§3.3).
",1 Introduction,[0],[0]
We extensively evaluate the effectiveness and generalizing ability of the proposed meta-learning algorithm on low-resource neural machine translation.,1 Introduction,[0],[0]
"We utilize 17 languages from Europarl and Russian from WMT as the source tasks and test the meta-learned parameter initialization against five target languages (Ro, Lv, Fi, Tr and Ko), in all cases translating to English.",1 Introduction,[0],[0]
"Our experiments using only up to 160k tokens in each of the target task reveal that the proposed meta-learning approach outperforms the multilingual translation
approach across all the target language pairs, and the gap grows as the number of training examples decreases.",1 Introduction,[0],[0]
Neural Machine Translation (NMT),2 Background,[0],[0]
"Given a source sentence X = {x1, ..., xT 0}, a neural machine translation model factors the distribution over possible output sentences Y = {y1, ..., yT } into a chain of conditional probabilities with a leftto-right causal structure:
p(Y |X; ✓) = T+1Y
t=1
p(yt|y0:t 1, x1:T 0 ; ✓), (1)
where special tokens y0 (hbosi) and yT+1 (heosi) are used to represent the beginning and the end of a target sentence.",2 Background,[0],[0]
These conditional probabilities are parameterized using a neural network.,2 Background,[0],[0]
"Typically, an encoder-decoder architecture (Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015) with a RNN-based decoder is used.",2 Background,[0],[0]
"More recently, architectures without any recurrent structures (Gehring et al., 2017; Vaswani et al., 2017) have been proposed and shown to speed up training while achieving state-of-the-art performance.
",2 Background,[0],[0]
"Low Resource Translation NMT is known to easily over-fit and result in an inferior performance when the training data is limited (Koehn and Knowles, 2017).",2 Background,[0],[0]
"In general, there are two ways for handling the problem of low resource translation: (1) utilizing the resource of unlabeled monolingual data, and (2) sharing the knowledge between low- and high-resource language pairs.",2 Background,[0],[0]
"Many research efforts have been spent on incorporating the monolingual corpora into machine translation, such as multi-task learning (Gulcehre et al., 2015; Zhang and Zong, 2016), back-translation (Sennrich et al., 2015), dual learning (He et al., 2016) and unsupervised machine translation with monolingual corpora only for both sides (Artetxe et al., 2017b; Lample et al., 2017; Yang et al., 2018).
",2 Background,[0],[0]
"For the second approach, prior researches have worked on methods to exploit the knowledge of auxiliary translations, or even auxiliary tasks.",2 Background,[0],[0]
"For instance, Cheng et al. (2016); Chen et al. (2017); Lee et al. (2017); Chen et al. (2018) investigate the use of a pivot to build a translation path between two languages even without any directed resource.",2 Background,[0],[0]
The pivot can be a third language or even an image in multimodal domains.,2 Background,[0],[0]
"When pivots are
not easy to obtain, Firat et al. (2016a); Lee et al. (2016); Johnson et al. (2016) have shown that the structure of NMT is suitable for multilingual machine translation.",2 Background,[0],[0]
"Gu et al. (2018b) also showed that such a multilingual NMT system could improve the performance of low resource translation by using a universal lexical representation to share embedding information across languages.
",2 Background,[0],[0]
"All the previous work for multilingual NMT assume the joint training of multiple high-resource languages naturally results in a universal space (for both the input representation and the model) which, however, is not necessarily true, especially for very low resource cases.
",2 Background,[0],[0]
"Meta Learning In the machine learning community, meta-learning, or learning-to-learn, has recently received interests.",2 Background,[0],[0]
Meta-learning tries to solve the problem of “fast adaptation on new training data.”,2 Background,[0],[0]
"One of the most successful applications of meta-learning has been on few-shot (or oneshot) learning (Lake et al., 2015), where a neural network is trained to readily learn to classify inputs based on only one or a few training examples.",2 Background,[0],[0]
"There are two categories of meta-learning:
1.",2 Background,[0],[0]
"learning a meta-policy for updating model parameters (see, e.g., Andrychowicz et al., 2016; Ha et al., 2016a; Mishra et al., 2017)
2.",2 Background,[0],[0]
"learning a good parameter initialization for fast adaptation (see, e.g., Finn et al., 2017; Vinyals et al., 2016; Snell et al., 2017).
",2 Background,[0],[0]
"In this paper, we propose to use a meta-learning algorithm for low-resource neural machine translation based on the second category.",2 Background,[0],[0]
"More specifically, we extend the idea of model-agnostic metalearning (MAML, Finn et al., 2017) in the multilingual scenario.",2 Background,[0],[0]
"The underlying idea of MAML is to use a set of source tasks T 1, . . .",3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
", T K to find the initialization of parameters ✓0 from which learning a target task T 0 would require only a small number of training examples.",3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
"In the context of machine translation, this amounts to using many high-resource language pairs to find good initial parameters and training a new translation model on a low-resource language starting from the found initial parame-
ters.",3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
"This process can be understood as
✓⇤ = Learn(T 0;MetaLearn(T 1, . . .",3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
", T K)).
",3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
"That is, we meta-learn the initialization from auxiliary tasks and continue to learn the target task.",3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
We refer the proposed meta-learning method for NMT to MetaNMT.,3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
See Fig. 1 for the overall illustration.,3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
"Given any initial parameters ✓0 (which can be either random or meta-learned),
the prior distribution of the parameters of a desired NMT model can be defined as an isotropic Guassian:
✓i ⇠ N (✓0i , 1/ ),
where 1/ is a variance.",3.1 Learn: language-specific learning,[0],[0]
"With this prior distribution, we formulate the language-specific learning process Learn(DT ; ✓0) as maximizing the logposterior of the model parameters given data DT :
Learn(DT ; ✓0) = argmax ✓ LDT (✓)
= argmax
✓
X
(X,Y )2DT
log p(Y |X, ✓) k✓ ✓0k2,
where we assume p(X|✓) to be uniform.",3.1 Learn: language-specific learning,[0],[0]
The first term above corresponds to the maximum likelihood criterion often used for training a usual NMT system.,3.1 Learn: language-specific learning,[0],[0]
"The second term discourages the newly learned model from deviating too much from the initial parameters, alleviating the issue of overfitting when there is not enough training data.",3.1 Learn: language-specific learning,[0],[0]
"In practice, we solve the problem above by maximizing the first term with gradient-based optimization and early-stopping after only a few update steps.
",3.1 Learn: language-specific learning,[0],[0]
"Thus, in the low-resource scenario, finding a good initialization ✓0 strongly correlates the final performance of the resulting model.",3.1 Learn: language-specific learning,[0],[0]
"We find the initialization ✓0 by repeatedly simulating low-resource translation scenarios using auxiliary, high-resource language pairs.",3.2 MetaLearn,[0],[0]
"Following Finn et al. (2017), we achieve this goal by defining the meta-objective function as
L(✓) =EkEDT k ,D0T k (2)2
64 X
(X,Y )2D0 T k
log p(Y |X;Learn(DT k ; ✓))
3
75 ,
where k ⇠ U({1, . . .",3.2 MetaLearn,[0],[0]
",K}) refers to one metalearning episode, and DT , D0T follow the uniform distribution over T ’s data.
",3.2 MetaLearn,[0],[0]
"We maximize the meta-objective function using stochastic approximation (Robbins and Monro, 1951) with gradient descent.",3.2 MetaLearn,[0],[0]
"For each episode, we uniformly sample one source task at random, T k.",3.2 MetaLearn,[0],[0]
"We then sample two subsets of training examples independently from the chosen task, DT k and D0T k .",3.2 MetaLearn,[0],[0]
We use the former to simulate languagespecific learning and the latter to evaluate its outcome.,3.2 MetaLearn,[0],[0]
"Assuming a single gradient step is taken only the with learning rate ⌘, the simulation is:
✓0k = Learn(DT k ;",3.2 MetaLearn,[0],[0]
✓) =,3.2 MetaLearn,[0],[0]
"✓ ⌘r✓LDT k (✓).
",3.2 MetaLearn,[0],[0]
"Once the simulation of learning is done, we evaluate the updated parameters ✓0k on D 0 T k , The gradient computed from this evaluation, which we refer to as meta-gradient, is used to update the
meta model ✓.",3.2 MetaLearn,[0],[0]
"It is possible to aggregate multiple episodes of source tasks before updating ✓:
✓ ✓ ⌘0 X
k
r✓LD 0 T k (✓0k),
where ⌘0 is the meta learning rate.",3.2 MetaLearn,[0],[0]
"Unlike a usual learning scenario, the resulting model ✓0 from this meta-learning procedure is not necessarily a good model on its own.",3.2 MetaLearn,[0],[0]
It is however a good starting point for training a good model using only a few steps of learning.,3.2 MetaLearn,[0],[0]
"In the context of machine translation, this procedure can be understood as finding the initialization of a neural machine translation system that could quickly adapt to a new language pair by simulating such a fast adaptation scenario using many high-resource language pairs.
",3.2 MetaLearn,[0],[0]
"Meta-Gradient We use the following approximation property
H(x)v ⇡ r(x+ ⌫v) r(x) ⌫
to approximate the meta-gradient:1
r✓LD 0",3.2 MetaLearn,[0],[0]
(✓0),3.2 MetaLearn,[0],[0]
= r✓0LD 0,3.2 MetaLearn,[0],[0]
"(✓0)r✓(✓ ⌘r✓LD(✓))
",3.2 MetaLearn,[0],[0]
= r✓0LD 0,3.2 MetaLearn,[0],[0]
(✓0) ⌘,3.2 MetaLearn,[0],[0]
r✓0LD 0,3.2 MetaLearn,[0],[0]
"(✓0)H✓(LD(✓))
⇡ r✓0LD 0",3.2 MetaLearn,[0],[0]
"(✓0) ⌘
⌫
 r✓LD(✓)
",3.2 MetaLearn,[0],[0]
"✓̂ r✓LD(✓) ✓ ,
where ⌫ is a small constant and
ˆ✓ = ✓ + ⌫r",3.2 MetaLearn,[0],[0]
✓0LD 0,3.2 MetaLearn,[0],[0]
"(✓0).
",3.2 MetaLearn,[0],[0]
"In practice, we find that it is also possible to ignore the second-order term, ending up with the following simplified update rule:
r✓LD 0 (✓0) ⇡ r✓0LD 0",3.2 MetaLearn,[0],[0]
(✓0).,3.2 MetaLearn,[0],[0]
"(3)
1We omit the subscript k for simplicity.
",3.2 MetaLearn,[0],[0]
"Related Work: Multilingual Transfer Learning The proposed MetaNMT differs from the existing framework of multilingual translation (Lee et al., 2016; Johnson et al., 2016; Gu et al., 2018b) or transfer learning (Zoph et al., 2016).",3.2 MetaLearn,[0],[0]
"The latter can be thought of as solving the following problem:
max ✓ Lmulti(✓) =",3.2 MetaLearn,[0],[0]
"Ek
2 4 X
(X,Y )2Dk
log p(Y |X; ✓)
3
5 ,
where Dk is the training set of the k-th task, or language pair.",3.2 MetaLearn,[0],[0]
"The target low-resource language pair could either be a part of joint training or be trained separately starting from the solution ✓0 found from solving the above problem.
",3.2 MetaLearn,[0],[0]
"The major difference between the proposed MetaNMT and these multilingual transfer approaches is that the latter do not consider how learning happens with the target, low-resource language pair.",3.2 MetaLearn,[0],[0]
The former explicitly incorporates the learning process within the framework by simulating it repeatedly in Eq.,3.2 MetaLearn,[0],[0]
(2).,3.2 MetaLearn,[0],[0]
"As we will see later in the experiments, this results in a substantial gap in the final performance on the low-resource task.
",3.2 MetaLearn,[0],[0]
"Illustration In Fig. 2, we contrast transfer learning, multilingual learning and meta-learning using three source language pairs (Fr-En, Es-En and Pt-En) and two target pairs (Ro-En and Lv-En).",3.2 MetaLearn,[0],[0]
"Transfer learning trains an NMT system specifically for a source language pair (Es-En) and finetunes the system for each target language pair (RoEn, Lv-En).",3.2 MetaLearn,[0],[0]
"Multilingual learning often trains a single NMT system that can handle many different language pairs (Fr-En, Pt-En, Es-En), which may or may not include the target pairs (Ro-En, LvEn).",3.2 MetaLearn,[0],[0]
"If not, it finetunes the system for each target pair, similarly to transfer learning.",3.2 MetaLearn,[0],[0]
Both of these however aim at directly solving the source tasks.,3.2 MetaLearn,[0],[0]
"On the other hand, meta-learning trains the NMT system to be useful for fine-tuning on various tasks including the source and target tasks.",3.2 MetaLearn,[0],[0]
"This is done by repeatedly simulating the learning process on
low-resource languages using many high-resource language pairs (Fr-En, Pt-En, Es-En).",3.2 MetaLearn,[0],[0]
I/O mismatch across language pairs One major challenge that limits applying meta-learning for low resource machine translation is that the approach outlined above assumes the input and output spaces are shared across all the source and target tasks.,3.3 Unified Lexical Representation,[0],[0]
"This, however, does not apply to machine translation in general due to the vocabulary mismatch across different languages.",3.3 Unified Lexical Representation,[0],[0]
"In multilingual translation, this issue has been tackled by using a vocabulary of sub-words (Sennrich et al., 2015) or characters (Lee et al., 2016) shared across multiple languages.",3.3 Unified Lexical Representation,[0],[0]
"This surface-level sharing is however limited, as it cannot be applied to languages exhibiting distinct orthography (e.g., IndoEuroepan languages vs. Korean.)
",3.3 Unified Lexical Representation,[0],[0]
"Universal Lexical Representation (ULR) We tackle this issue by dynamically building a vocabulary specific to each language using a keyvalue memory network (Miller et al., 2016; Gulcehre et al., 2018), as was done successfully for low-resource machine translation recently by Gu et al. (2018b).",3.3 Unified Lexical Representation,[0],[0]
"We start with multilingual word embedding matrices ✏kquery 2 R|Vk|⇥d pretrained on large monolingual corpora, where Vk is the vocabulary of the k-th language.",3.3 Unified Lexical Representation,[0],[0]
"These embedding vectors can be obtained with small dictionaries of seed word pairs (Artetxe et al., 2017a; Smith et al., 2017) or in a fully unsupervised manner (Zhang et al., 2017; Conneau et al., 2018).",3.3 Unified Lexical Representation,[0],[0]
"We take one of these languages k0 to build universal lexical representation consisting of a universal embedding matrix ✏u 2 RM⇥d and a corresponding key matrix ✏key 2 RM⇥d, where M < |V 0k|.",3.3 Unified Lexical Representation,[0],[0]
Both ✏kquery and ✏key are fixed during meta-learning.,3.3 Unified Lexical Representation,[0],[0]
"We then compute the language-specific embedding of token x from the language k as the convex sum of the universal embedding vectors by
✏0[x] = MX
i=1
↵i✏u[i],
where ↵i / exp 1⌧ ✏key[i]",3.3 Unified Lexical Representation,[0],[0]
>A✏kquery[x] and ⌧ is set to 0.05.,3.3 Unified Lexical Representation,[0],[0]
"This approach allows us to handle languages with different vocabularies using a fixed number of shared parameters (✏u, ✏key and A.)
",3.3 Unified Lexical Representation,[0],[0]
"Learning of ULR It is not desirable to update the universal embedding matrix ✏u when fine-
tuning on a small corpus which contains a limited set of unique tokens in the target language, as it could adversely influence the other tokens’ embedding vectors.",3.3 Unified Lexical Representation,[0],[0]
"We thus estimate the change to each embedding vector induced by languagespecific learning by a separate parameter ✏k[x]:
✏k[x] = ✏0[x] + ✏k[x].
",3.3 Unified Lexical Representation,[0],[0]
"During language-specific learning, the ULR ✏0[x] is held constant, while only ✏k[x] is updated, starting from an all-zero vector.",3.3 Unified Lexical Representation,[0],[0]
"On the other hand, we hold ✏k[x]’s constant while updating ✏u and A during the meta-learning stage.",3.3 Unified Lexical Representation,[0],[0]
"Target Tasks We show the effectiveness of the proposed meta-learning method for low resource NMT with extremely limited training examples on five diverse target languages: Romanian (Ro) from WMT’16,2 Latvian (Lv), Finnish (Fi), Turkish (Tr) from WMT’17,3 and Korean (Ko) from Korean Parallel Dataset.4 We use the officially provided train, dev and test splits for all these languages.",4.1 Dataset,[0],[0]
The statistics of these languages are presented in Table 1.,4.1 Dataset,[0],[0]
"We simulate the low-resource translation scenarios by randomly sub-sampling the training set with different sizes.
",4.1 Dataset,[0],[0]
"Source Tasks We use the following languages from Europarl5: Bulgarian (Bg), Czech (Cs), Danish (Da), German (De), Greek (El), Spanish (Es), Estonian (Et), French (Fr), Hungarian (Hu), Italian (It), Lithuanian (Lt), Dutch (Nl), Polish (Pl), Portuguese (Pt), Slovak (Sk), Slovene (Sl) and
2 http://www.statmt.org/wmt16/translation-task.html 3 http://www.statmt.org/wmt17/translation-task.html 4 https://sites.google.com/site/koreanparalleldata/ 5 http://www.statmt.org/europarl/
Swedish (Sv), in addition to Russian (Ru)6 to learn the intilization for fine-tuning.",4.1 Dataset,[0],[0]
"In our experiments, different combinations of source tasks are explored to see the effects from the source tasks.
",4.1 Dataset,[0],[0]
Validation We pick either Ro-En or Lv-En as a validation set for meta-learning and test the generalization capability on the remaining target tasks.,4.1 Dataset,[0],[0]
"This allows us to study the strict form of metalearning, in which target tasks are unknown during both training and model selection.
",4.1 Dataset,[0],[0]
"Preprocessing and ULR Initialization As described in §3.3, we initialize the query embedding vectors ✏kquery of all the languages.",4.1 Dataset,[0],[0]
"For each language, we use the monolingual corpora built from Wikipedia7 and the parallel corpus.",4.1 Dataset,[0],[0]
"The concatenated corpus is first tokenized and segmented using byte-pair encoding (BPE, Sennrich et al., 2016), resulting in 40, 000 subwords for each language.",4.1 Dataset,[0],[0]
"We then estimate word vectors using fastText (Bojanowski et al., 2016) and align them across all the languages in an unsupervised way
6 A subsample of approximately 2M pairs from WMT’17.",4.1 Dataset,[0],[0]
"7 We use the most recent Wikipedia dump (2018.5) from
https://dumps.wikimedia.org/backup-index.html.
using MUSE (Conneau et al., 2018) to get multilingual word vectors.",4.1 Dataset,[0],[0]
"We use the multilingual word vectors of the 20,000 most frequent words in English to form the universal embedding matrix ✏u.",4.1 Dataset,[0],[0]
"Model We utilize the recently proposed Transformer (Vaswani et al., 2017) as an underlying NMT system.",4.2 Model and Learning,[0],[0]
"We implement Transformer in this paper based on (Gu et al., 2018a)8 and modify it to use the universal lexical representation from §3.3.",4.2 Model and Learning,[0],[0]
"We use the default set of hyperparameters (dmodel = dhidden = 512, nlayer = 6, nhead = 8, nbatch = 4000, twarmup = 16000) for all the language pairs and across all the experimental settings.",4.2 Model and Learning,[0],[0]
"We refer the readers to (Vaswani et al., 2017; Gu et al., 2018a) for the details of the model.",4.2 Model and Learning,[0],[0]
"However, since the proposed metalearning method is model-agnostic, it can be easily extended to any other NMT architectures, e.g. RNN-based sequence-to-sequence models with attention (Bahdanau et al., 2015).
",4.2 Model and Learning,[0],[0]
8,4.2 Model and Learning,[0],[0]
"https://github.com/salesforce/nonauto-nmt
Learning We meta-learn using various sets of source languages to investigate the effect of source task choice.",4.2 Model and Learning,[0],[0]
"For each episode, by default, we use a single gradient step of language-specific learning with Adam (Kingma and Ba, 2014) per computing the meta-gradient, which is computed by the first-order approximation in Eq.",4.2 Model and Learning,[0],[0]
"(3).
",4.2 Model and Learning,[0],[0]
"For each target task, we sample training examples to form a low-resource task.",4.2 Model and Learning,[0],[0]
"We build tasks of 4k, 16k, 40k and 160k English tokens for each language.",4.2 Model and Learning,[0],[0]
We randomly sample the training set five times for each experiment and report the average score and its standard deviation.,4.2 Model and Learning,[0],[0]
"Each fine-tuning is done on a training set, early-stopped on a validation set and evaluated on a test set.",4.2 Model and Learning,[0],[0]
"In default without notation, datasets of 16k tokens are used.
",4.2 Model and Learning,[0],[0]
"Fine-tuning Strategies The transformer consists of three modules; embedding, encoder and decoder.",4.2 Model and Learning,[0],[0]
"We update all three modules during metalearning, but during fine-tuning, we can selectively tune only a subset of these modules.",4.2 Model and Learning,[0],[0]
"Following (Zoph et al., 2016), we consider three fine-tuning
strategies; (1) fine-tuning all the modules (all), (2) fine-tuning the embedding and encoder, but freezing the parameters of the decoder (emb+enc) and (3) fine-tuning the embedding only (emb).",4.2 Model and Learning,[0],[0]
vs. Multilingual Transfer Learning We metalearn the initial models on all the source tasks using either Ro-En or Lv-En as a validation task.,5 Results,[0],[0]
We also train the initial models to be multilingual translation systems.,5 Results,[0],[0]
"We fine-tune them using the four target tasks (Ro-En, Lv-En, Fi-En and Tr-En; 16k tokens each) and compare the proposed meta-learning strategy and the multilingual, transfer learning strategy.",5 Results,[0],[0]
"As presented in Fig. 3, the proposed learning approach significantly outperforms the multilingual, transfer learning strategy across all the target tasks regardless of which target task was used for early stopping.",5 Results,[0],[0]
We also notice that the emb+enc strategy is most effective for both meta-learning and transfer learning approaches.,5 Results,[0],[0]
"With the proposed meta-learning and emb+enc fine-tuning, the final NMT systems trained using only a fraction of all available training examples achieve 2/3 (Ro-En) and 1/2 (Lv-En, Fi-En and Tr-En) of the BLEU score achieved by the models trained with full training sets.
",5 Results,[0],[0]
"vs. Statistical Machine Translation We also test the same Ro-En datasets with 16, 000 target tokens using the default setting of Phrase-based MT (Moses) with the dev set for adjusting the parameters and the test set for calculating the final performance.",5 Results,[0],[0]
"We obtain 4.79(±0.234) BLEU point, which is higher than the standard NMT performance (0 BLEU).",5 Results,[0],[0]
"It is however still lower than both the multi-NMT and meta-NMT.
",5 Results,[0],[0]
"Impact of Validation Tasks Similarly to training any other neural network, meta-learning still requires early-stopping to avoid overfitting to a
specific set of source tasks.",5 Results,[0],[0]
"In doing so, we observe that the choice of a validation task has nonnegligible impact on the final performance.",5 Results,[0],[0]
"For instance, as shown in Fig. 3, Fi-En benefits more when Ro-En is used for validation, while the opposite happens with Tr-En.",5 Results,[0],[0]
"The relationship between the task similarity and the impact of a validation task must be investigated further in the future.
",5 Results,[0],[0]
"Training Set Size We vary the size of the target task’s training set and compare the proposed meta-learning strategy and multilingual, transfer learning strategy.",5 Results,[0],[0]
We use the emb+enc fine-tuning on Ro-En and Fi-En.,5 Results,[0],[0]
Fig. 4 demonstrates that the meta-learning approach is more robust to the drop in the size of the target task’s training set.,5 Results,[0],[0]
"The gap between the meta-learning and transfer learning grows as the size shrinks, confirming the effectiveness of the proposed approach on extremely lowresource language pairs.
",5 Results,[0],[0]
"Impact of Source Tasks In Table 2, we present the results on all five target tasks obtained while varying the source task set.",5 Results,[0],[0]
We first see that it is always beneficial to use more source tasks.,5 Results,[0],[0]
"Although the impact of adding more source tasks varies from one language to another, there is up to 2⇥ improvement going from one source task to 18 source tasks (Lv-En, Fi-En, Tr-En and Ko-En).",5 Results,[0],[0]
"The same trend can be observed even without any fine-tuning (i.e., unsupervised translation, (Lample et al., 2017; Artetxe et al., 2017b)).",5 Results,[0],[0]
"In addition, the choice of source languages has different implications for different target languages.",5 Results,[0],[0]
"For instance, Ro-En benefits more from {Es, Fr, It, Pt} than from {De, Ru}, while the opposite effect is observed with all the other target tasks.
",5 Results,[0],[0]
Training Curves,5 Results,[0],[0]
The benefit of meta-learning over multilingual translation is clearly demonstrated when we look at the training curves in Fig. 5.,5 Results,[0],[0]
"With the multilingual, transfer learning ap-
",5 Results,[0],[0]
"proach, we observe that training rapidly saturates and eventually degrades, as the model overfits to the source tasks.",5 Results,[0],[0]
MetaNMT,5 Results,[0],[0]
"on the other hand continues to improve and never degrades, as the metaobjective ensures that the model is adequate for fine-tuning on target tasks rather than for solving the source tasks.
",5 Results,[0],[0]
Sample Translations We present some sample translations from the tested models in Table 3.,5 Results,[0],[0]
Inspecting these examples provides the insight into the proposed meta-learning algorithm.,5 Results,[0],[0]
"For instance, we observe that the meta-learned model without any fine-tuning produces a word-by-word translation in the first example (Tr-En), which is due to the successful use of the universal lexcial representation and the meta-learned initialization.",5 Results,[0],[0]
"The system however cannot reorder tokens from Turkish to English, as it has not seen any training example of Tr-En.",5 Results,[0],[0]
"After seeing around 600 sentence pairs (16K English tokens), the model rapidly learns to correctly reorder tokens to form a better translation.",5 Results,[0],[0]
A similar phenomenon is observed in the Ko-En example.,5 Results,[0],[0]
These cases could be found across different language pairs.,5 Results,[0],[0]
"In this paper, we proposed a meta-learning algorithm for low-resource neural machine translation that exploits the availability of high-resource languages pairs.",6 Conclusion,[0],[0]
"We based the proposed algorithm on the recently proposed model-agnostic metalearning and adapted it to work with multiple languages that do not share a common vocabulary using the technique of universal lexcal representation, resulting in MetaNMT.",6 Conclusion,[0],[0]
"Our extensive evaluation, using 18 high-resource source tasks and 5 low-resource target tasks, has shown that the proposed MetaNMT significantly outperforms the existing approach of multilingual, transfer learning in low-resource neural machine translation across all the language pairs considered.
",6 Conclusion,[0],[0]
The proposed approach opens new opportunities for neural machine translation.,6 Conclusion,[0],[0]
"First, it is a principled framework for incorporating various extra sources of data, such as source- and targetside monolingual corpora.",6 Conclusion,[0],[0]
"Second, it is a generic framework that can easily accommodate existing and future neural machine translation systems.",6 Conclusion,[0],[0]
This research was supported in part by the Facebook Low Resource Neural Machine Translation Award.,Acknowledgement,[0],[0]
This work was also partly supported by Samsung Advanced Institute of Technology (Next Generation Deep Learning: from pattern recognition to AI) and Samsung Electronics (Improving Deep Learning using Latent Structure).,Acknowledgement,[0],[0]
"KC thanks support by eBay, TenCent, NVIDIA and CIFAR.",Acknowledgement,[0],[0]
"In this paper, we propose to extend the recently introduced model-agnostic meta-learning algorithm (MAML, Finn et al., 2017) for lowresource neural machine translation (NMT).",abstractText,[0],[0]
"We frame low-resource translation as a metalearning problem, and we learn to adapt to low-resource languages based on multilingual high-resource language tasks.",abstractText,[0],[0]
"We use the universal lexical representation (Gu et al., 2018b) to overcome the input-output mismatch across different languages.",abstractText,[0],[0]
"We evaluate the proposed meta-learning strategy using eighteen European languages (Bg, Cs, Da, De, El, Es, Et, Fr, Hu, It, Lt, Nl, Pl, Pt, Sk, Sl, Sv and Ru) as source tasks and five diverse languages (Ro, Lv, Fi, Tr and Ko) as target tasks.",abstractText,[0],[0]
"We show that the proposed approach significantly outperforms the multilingual, transfer learning based approach (Zoph et al., 2016) and enables us to train a competitive NMT system with only a fraction of training examples.",abstractText,[0.9508279318525582],"['Training models on only few speakers can lead to degenerate solutions where models learn the identity of speakers as opposed to a generalizable model of multimodal language (Wang et al., 2016).']"
"For instance, the proposed approach can achieve as high as 22.04 BLEU on Romanian-English WMT’16 by seeing only 16,000 translated words (⇠ 600 parallel sentences).",abstractText,[0],[0]
Meta-Learning for Low-Resource Neural Machine Translation,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 375–385 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Online platforms have revolutionized the way individuals collect and share information (O’Connor et al., 2010; Lee and Ma, 2012; Bakshy et al., 2015), but the vast bulk of online content is irrelevant or unpalatable to any given individual.",1 Introduction,[0],[0]
"A user interested in political discussion, for instance, might prefer content concerning a specific candidate or issue, and only then if discussed in a positive light without controversy (Adamic and Glance, 2005; Bakshy et al., 2015).
",1 Introduction,[0],[0]
"How do individuals facing such large quantities of superfluous material select which conversations to engage in, and how might we better algorithmically recommend conversations suited to individual users?",1 Introduction,[0],[0]
We approach this problem from a microblog conversation recommendation framework.,1 Introduction,[0],[0]
"Where prior work has focused on the content of individual posts for recommendation (Chen
et al., 2012; Yan et al., 2012; Vosecky et al., 2014; He and Tan, 2015), we examine the entire history and context of a conversation, including both topical content and discourse modes such as agreement, question-asking, argument and other dialogue acts (Ritter et al.,",1 Introduction,[0],[0]
"2010).1 And where Backstrom et al. (2013) leveraged conversation reply structure (such as previous user engagement), their model is unable to predict first entry into new conversations, while ours is able to predict both new
1In this paper, discourse mode refers to a certain type of dialogue act, e.g., agreement or argument.",1 Introduction,[0],[0]
"The discourse structure of a conversation means some combination (or a probability distribution) of discourse modes.
375
and repeated entry into conversations based on a combination of topical and discourse features.
",1 Introduction,[0],[0]
"To illustrate the interplay between topics and discourse, Figure 1 displays two snippets of conversations on Twitter collected during the 2016 United States presidential election.",1 Introduction,[0],[0]
User U1 participates in both conversations.,1 Introduction,[0],[0]
"The first conversation is centered around Clinton, and U1, who is more typically involved with conversations about candidate Sanders, does not return.",1 Introduction,[0],[0]
"In the second conversation, however, U1 is involved in a heated back-and-forth debate, and thus is drawn back to a conversation that they may otherwise have abandoned but for their enjoyment of adversarial discourse.
",1 Introduction,[0],[0]
"Effective conversation prediction and recommendation requires an understanding of both user interests and discourse behaviors, such as agreement, disagreement, inquiry, backchanneling, and emotional reactions.",1 Introduction,[0],[0]
"However, acquiring manual labels for both is a time-consuming process and hard to scale for new datasets.",1 Introduction,[0],[0]
"We instead propose a unified statistical learning framework for conversation recommendation, which jointly learns (1) hidden factors that reflect user interests based on conversation history, and (2) topics and discourse modes in ongoing conversations, as discovered by a novel probabilistic latent variable model.",1 Introduction,[0],[0]
"Our model is built on the success of collaborative filtering (CF) in recommendation systems, where latent dimensions of product ratings or movie reviews are extracted to better capture user preferences (Linden et al., 2003; Salakhutdinov and Mnih, 2008; Wang and Blei, 2011; McAuley and Leskovec, 2013).",1 Introduction,[0],[0]
"To the best of our knowledge, we are the first to model both topics and discourse modes as part of a CF framework and apply it to microblog conversation recommendation.2
Experimental results on two Twitter conversation datasets show that our proposed model yields significantly better performance than state-of-theart post-level recommendation systems.",1 Introduction,[0],[0]
"For example, by leveraging both topical content and discourse structure, our model achieves a mean average precision (MAP) of 0.76 on conversations about the U.S. presidential election, compared with 0.70 by McAuley and Leskovec (2013), which only considers topics.",1 Introduction,[0],[0]
"We further con-
2To ensure the general applicability of our approach to domains lacking such information, we do not utilize external features such as network structure, but it may certainly be added in future, more narrowly targeted applications.
ducted detailed analysis on the latent topics and discourse modes and find that our model can discover reasonable topic and discourse representations, which play an important role in characterizing reply behaviors.",1 Introduction,[0],[0]
"Finally, we also provide a pilot study on recommendation for first time replies, which shows that our model outperforms comparable recommendation systems.
",1 Introduction,[0],[0]
The rest of this paper is structured as follows.,1 Introduction,[0],[0]
The related work is discussed in Section 2.,1 Introduction,[0],[0]
We then present our microblog conversation recommendation model in Section 3.,1 Introduction,[0],[0]
The experimental setup and results are described in Sections 4 and 5.,1 Introduction,[0],[0]
"Finally, we conclude in Section 6.",1 Introduction,[0],[0]
"Social media has attracted increasing attention in digital communication research (Agichtein et al., 2008; Kwak et al., 2010; Wu et al., 2011).",2 Related Work,[0],[0]
"The problem studied here is closely related to work on recommendation and response prediction in microblogs (Artzi et al., 2012; Hong et al., 2013), where the goal is to predict whether a user will share or reply to a given post.",2 Related Work,[0],[0]
"Existing methods focus on measuring features that reflect personalized user interests, including topics (Hong et al., 2013) and network structures (Pan et al., 2013; He and Tan, 2015).",2 Related Work,[0],[0]
"These features have been investigated under a learning to rank framework (Duan et al., 2010; Artzi et al., 2012), graph ranking models (Yan et al., 2012; Feng and Wang, 2013; Alawad et al., 2016), and neural network-based representation learning methods (Yu et al., 2016).
",2 Related Work,[0],[0]
"Distinguishing from prior work that focuses on post-level recommendation, we tackle the challenges of predicting user reply behaviors at the conversation-level.",2 Related Work,[0],[0]
"In addition, our model not only captures latent factors such as the topical interests of users, but also leverages the automatically learned discourse structure.",2 Related Work,[0],[0]
"Much of the previous work on discourse structure and dialogue acts has relied on labeled data (Jurafsky et al., 1997; Stolcke et al., 2000), while unsupervised approaches have not been applied to the problem of conversation recommendation (Woszczyna and Waibel, 1994; Crook et al., 2009; Ritter et al., 2010; Joty et al., 2011).
",2 Related Work,[0],[0]
"Our work is also in line with conversation modeling for social media discussions (Ritter et al., 2010; Budak and Agrawal, 2013; Louis and Cohen, 2015; Cheng et al., 2017).",2 Related Work,[0],[0]
"Topic modeling
has been employed to identify conversation content on Twitter (Ritter et al., 2010).",2 Related Work,[0],[0]
"In this work, we propose a probabilistic model to capture both topics and discourse modes as latent variables.",2 Related Work,[0],[0]
"A further line of work studies the reposting and reply structure of conversations (Gómez et al., 2011; Laniado et al., 2011; Backstrom et al., 2013; Budak and Agrawal, 2013).",2 Related Work,[0],[0]
"But none of this work distinguishes the rich discourse functions of replies, which is modeled and exploited in our work.",2 Related Work,[0],[0]
Our proposed microblog conversation recommendation framework is based on collaborative filtering and a novel probabilistic graphical model.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Concretely, our objective function takes the form:
minL+ µ ·NLL(C |Θ) (1)
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
This function encodes two types of information.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"First, L models user reply preference in a similar fashion to collaborative filtering (CF) (Hu et al., 2008; Pan et al., 2008).",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"It captures topics of interests and discourse structures users are commonly involved (e.g., argumentation), and takes the form of mean square error (MSE) based on user reply history.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"This part is detailed in Section 3.1.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"The second term, NLL(C |Θ), denotes the negative log-likelihood of a set of conversations C, with Θ containing all parameters.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"A probabilistic model is described in Section 3.2 that shows how the topical content and discourse structures of conversations are captured by these latent variables.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
The hyperparameter µ controls the trade-off between the two effects.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"`2 regularization is also added for parameters to avoid model overfitting.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"For the rest of this section, we first present the construction of L andNLL(C |Θ) in Sections 3.1 and 3.2.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
We then discuss how these two components can be mutually informed by each other in Section 3.3.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Finally, the generative process and parameter learning are described in Section 3.4.
3.1 Reply Preference (L) Our user reply preference modeling is built on the success of collaborative filtering (CF) for product ratings.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"However, classic CF problems, such as product recommendation, generally rely on explicit user feedback.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Unlike user ratings on products, our input lacks explicit feedback from users about negative preferences and nonresponse.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Therefore, we follow one-class Collaborative Filtering (Hu et al., 2008; Pan et al., 2008),
which weights positive instances higher during training and is thus suited to our data.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Formally, for user u and conversation c, we measure reply preference based on the MSE between predicted preference score pu,c and reply history ru,c. ru,c equals 1 if u is in the conversation history; otherwise, it is 0.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"The first term of objective (Eq. 1) takes the following form:
L = |U|∑
u=1
|C|∑
c=1
fu,c · (pu,c − ru,c)2 (2)
where U consists of users {u} and C is a set of conversations {c} in a dataset.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"fu,c is the corresponding weight for a conversation c and a target user u. Intuitively, it has a large value if positive feedback (user replied) is observed.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Therefore, we adapt the formulation from Pan et al. (2008):
fu,c = { s if ru,c = 1 (i.e., user replied) 1 if ru,c = 0
(3)
where s > 1, an integer hyperparameter to be tuned.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Inspired by prior models (Koren et al., 2009; McAuley and Leskovec, 2013), we propose the following latent factor model to describe pu,c:
pu,c = λ · γUu · γCc + (1− λ) ·",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
δUu · δCc,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"+ bu + bc + a (4)
γUu and γ C c are K-dimensional latent vectors that encode topic-specific information (where K is the number of latent topics) for users and conversations.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Specifically, γUu reflects the topical interests of u, with higher value γUu,k indicating greater interest by u in topic k. γCc captures the extents that topics are discussed in conversation c.
Similarly, D-dimensional vectors δUu and δ C c capture discourse structures in shaping reply behaviors (where D is the number of discourse clusters).",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"δUu reflects the discourse behaviors u prefers, such as u1 often enjoys arguments as in the second conversation of Figure 1, while δCc captures the discourse modes used throughout conversation c. By multiplying user and conversation factors, we can measure the corresponding similarity.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"The predicted score pu,c thereby reflects the tendency for a user u to be involved in conversation c.
As pointed out by McAuley and Leskovec (2013), these latent vectors often encode hidden factors that are hard to interpret under a CF framework.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Therefore, in Section 3.2, we present a novel probabilistic model which can extract interpretable topics and discourse modes as word
distributions.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"We then describe how they can be aligned with the latent vectors of γC and δU .
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Parameter a is an offset parameter, bu and bc are user and conversation biases, and λ ∈",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"[0, 1] serves as the weight for trading offs of topic and discourse factors in reply preference modeling.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
3.2 Corpus Likelihood NLL(C |Θ),3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
Here we present a novel probabilistic model that learns coherent word distributions for latent topics and discourse modes of conversations.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Formally, we assume that each conversation c ∈ C contains Mc messages, and each message m has Nc,m words.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"We distinguish three latent components – discourse, topic, and background – underlying conversations, each with their own type of word distribution.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"At the corpus level, there are K topics represented by word distribution φTk (k = 1, 2, ...,K), while φDd (d = 1, 2, ..., D) represents the D discourse modes embedded in corpus.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"In addition, we add a background word distribution φB to capture general information (e.g., common words), which do not indicate either discourse or topic information.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"φDd , φ T k , and φ
B are all multinomial word distributions over vocabulary size V .",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Below describes more details.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
Message-level Modeling.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Our model assigns two types of message-level multinomial variables to each message: zc,m reflects its latent topic and dc,m represents its discourse mode.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
Topic assignments.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Due to the short nature of microblog posts, we assume each message m in conversation c contains only one topic, indexed as zc,m. This strategy has been proven useful to alleviate data sparsity for topic inference (Quan et al., 2015).",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
We further assume messages in the same conversation would focus on similar topics.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"We thus draw topic zc,m ∼ θc, where θc denotes the fractions of topics discussed in conversation c.
Discourse assignments.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"To capture discourse behaviors of u, distribution πu is used to represent the discourse modes in messages posted by u.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"The discourse mode dc,m for message m is then generated from πuc,m , where uc,m is the author of m in c.
Word-level Modeling.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"We aim to separate discourse, topic, and background information for conversations.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Therefore, for each word wc,m,n of message m, a ternary switcher xc,m,n ∈ {DISC, TOPIC,BACK} controls word wc,m,n to
fall into one of the three types: discourse, topic, and background.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
Discourse words (DISC) are indicative of the discourse modes of messages.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"When xc,m,n = DISC (i.e., wc,m,n is assigned as a discourse word), word wc,m,n is generated from the discourse word distribution φDdc,m where dc,m is discourse assignment to",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"message m.
Topic words (TOPIC) describe the topical focus of a conversation.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"When xc,m,n = TOPIC, wc,m,n is assigned as a topic word and generated from φTzc,m – word distribution given topic of m.
Background words (BACK) capture the general information that is not related to discourse or topic.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"When word wc,m,n is assigned as a background word (xc,m,n = BACK), it is drawn from background distribution φB .
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Switching among Topic, Discourse, and Background.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"We further assume the word type switcher xc,m,n is sampled from a multinomial distribution which depends on the current discourse mode dc,m. The intuition is that messages of different discourse modes may show different distributions of the three word types.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"For instance, a statement message may contain more content words than a rhetorical question.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Specifically, xc,m,n ∼ Multi(τdc,m), where τd is a 3-dimension stochastic vector that expresses the appearing probabilities of three kinds of words (DISC, TOPIC, BACK), when the discourse assignment is d. Stop words and punctuations are forced to be labeled as discourse or background.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"By explicitly distinguishing different types of words with switcher xc,m,n, we can thus separate word distributions that reflect discourse, topic, and background information.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
Likelihood.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Based on the message-level and the word-level generation process, the probability of observing words in the given corpus is:
Pr(C |θ,π,φ, τ , z,d,x)
=
C∏
c=1
Mc∏
m=1
θc,zc,mπuc,m,dc,m
× ∏
xc,m,n=BACK
τdc,m,BACKφ B wc,m,n
× ∏
xc,m,n=DISC
τdc,m,DISCφ D dc,m,wc,m,n
× ∏
xc,m,n=TOPIC
τdc,m,TOPICφ T zc,m,wc,m,n
(5)
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"And we use negative log likelihood to model corpus likelihood effect in Eq. 1, i.e., NLL(C |Θ) =
− log(Pr(C |Θ), where parameters set Θ = {θ,π,φ, τ , z,d,x}.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Latent Variables
As mentioned above, the hidden factors discovered in Section 3.1 lack interpretability, which can be boosted by the learned latent topics and discourse modes in Section 3.2.",3.3 Mutually Informed User Preference and,[0],[0]
"However, it is nontrivial to link the topic-related parameters of γCc to the conversation topic distributions of θc, since the former takes real values from −∞ to +∞ while the latter is a stochastic vector.",3.3 Mutually Informed User Preference and,[0],[0]
"Therefore, we follow the strategy from McAuley and Leskovec (2013) to apply a softmax function over γCc :
θc,k = exp(κT γCc,k)∑K
k′=1 exp(κ T γCc,k′)
(6)
",3.3 Mutually Informed User Preference and,[0],[0]
"We further assume that the discourse mode preference by users, δUu , can also be informed by the discourse mode distribution captured by πu, i.e., a user who enjoys arguments may be willing to participate another.",3.3 Mutually Informed User Preference and,[0],[0]
"So similarly, we define:
πu,d = exp(κDδUu,d)∑D
d′=1 exp(κ DδUu,d′)
(7)
where κT and κD are learnable parameters that control the “peakiness” of the transformation.",3.3 Mutually Informed User Preference and,[0],[0]
"For example, a larger κT indicates a more focused conversation, while a smaller κT means users discuss diverse topics.
",3.3 Mutually Informed User Preference and,[0],[0]
"Finally, softmax transformation is also applied to φTk , φ D d , φ
B , and τd, as done in McAuley and Leskovec (2013), with additional parameters ψTk , ψDd , ψ
B , and χd (as shown in Figure 2).",3.3 Mutually Informed User Preference and,[0],[0]
This is to ensure that the distributions φ∗∗ and τd are stochastic vectors.,3.3 Mutually Informed User Preference and,[0],[0]
"In doing so, these distributions can be learned via optimizing ψ∗∗ and χd, which take any value and thus ensure that the cost function in Eq. 1 is optimized without considering any parameter constraints.",3.3 Mutually Informed User Preference and,[0],[0]
"Our word generation process is displayed in Figure 2 and described as follows:
• Compute topic distribution θc by Eq. 6 •",3.4 Generative Process and Model Learning,[0],[0]
"For message m = 1 to Mc:
– Compute discourse distribution πuc,m by Eq. 7 – Draw topic assignment zc,m ∼Multi(θc) – Draw discourse mode dc,m ∼Multi(πuc,m) –",3.4 Generative Process and Model Learning,[0],[0]
"For word index n = 1 to Nc,m: ∗ Draw word type xc,m,n ∼Multi(τd)
∗",3.4 Generative Process and Model Learning,[0],[0]
"if xc,m,n == BACK:",3.4 Generative Process and Model Learning,[0],[0]
"Draw word wc,m,n ∼Multi(φB) ∗",3.4 Generative Process and Model Learning,[0],[0]
"if xc,m,n == DISC:",3.4 Generative Process and Model Learning,[0],[0]
"Draw word wc,m,n ∼Multi(φDdc,m) ∗",3.4 Generative Process and Model Learning,[0],[0]
"if xc,m,n == TOPIC:",3.4 Generative Process and Model Learning,[0],[0]
"Draw word wc,m,n ∼Multi(φTzc,m)
Parameter Learning.",3.4 Generative Process and Model Learning,[0],[0]
"For learning, we randomly initialize all learnable parameters and then alternate between the following two steps: Step 1.",3.4 Generative Process and Model Learning,[0],[0]
"Fix topic and discourse assignments z and d, and word type switcher x, then optimize the remaining parameters in Eq. 1 by L-BFGS (Nocedal, 1980):
Update a, b, γ∗, δ∗, κ∗, ψ∗, χ = argminL+ µ ·NLL(C |Θ) (8)
Step 2.",3.4 Generative Process and Model Learning,[0],[0]
"Sample topic and discourse assignments z and d at the message level and word type switcher x at the word level, using the distributions, computed according to parameters optimized in step 1:
Sample zc,m, dc,m, xc,m,n with probabilities p(zc,m = k) =",3.4 Generative Process and Model Learning,[0],[0]
"θc,k
p(dc,m = d) = πuc,m,d p(xc,m,n = BACK) = φ B wc,m,nτdc,m,BACK p(xc,m,n = DISC) = φ D dc,m,wc,m,nτdc,m,DISC p(xc,m,n = TOPIC) = φ T zc,m,wc,m,nτdc,m,TOPIC
(9)
Step 2 is analogous to Gibbs Sampling (Griffiths, 2002) in probabilistic graphical models, such as LDA (Blei et al., 2003).",3.4 Generative Process and Model Learning,[0],[0]
"However, distinguishing from previous models, the multinomial distributions in our models are not drawn from a Dirichlet prior.",3.4 Generative Process and Model Learning,[0],[0]
"Instead, they are computed based on the parameters learned in Step 1.
",3.4 Generative Process and Model Learning,[0],[0]
"Our learning process stops when the change of parameters is small (i.e., below a pre-specified
threshold).",3.4 Generative Process and Model Learning,[0],[0]
"Multiple restarts are tried, and similar results are achieved.",3.4 Generative Process and Model Learning,[0],[0]
Datasets.,4 Experimental Setup,[0],[0]
"We collected two microblog conversation datasets from Twitter for experiments3: one contains discussions about the U.S. presidential election (henceforth US Election), the other gathers conversations of diverse topics based on the tweets released by TREC 2011 microblog track (henceforth TREC)4.",4 Experimental Setup,[0],[0]
"US Election was collected from January to June of 2016 using Twitter’s Streaming API5 with a small set of political keywords.6 To recover conversations, Tweet Search API7 was used to retrieve messages with the “inreply-to” relations to collect tweets in a recursive way until full conversations were recovered.
",4 Experimental Setup,[0],[0]
Statistics of the datasets are shown in Table 1.,4 Experimental Setup,[0],[0]
Figure 3 displays the number of conversations individual users participated in.,4 Experimental Setup,[0],[0]
"As can be seen, most users are involved in only a few conversations.",4 Experimental Setup,[0],[0]
"Simply leveraging personal chat history will not produce good performance for conversation
3The datasets are available at http://www.ccs. neu.edu/home/luwang/
4 http://trec.nist.gov/data/tweets/ 5https://developer.twitter.com/
en/docs/tweets/filter-realtime/ api-reference/post-statuses-filter.html
6Keyword list: “trump”, “hillary”, “clinton”, “president”, “politics”, and “election.”
",4 Experimental Setup,[0],[0]
"7https://developer.twitter.com/en/ docs/tweets/search/api-reference/ get-saved_searches-show-id
recommendation.",4 Experimental Setup,[0],[0]
"In our experiments, we predict whether a user will engage in a conversation given the previous messages in that conversation and past conversations the user is involved.",4 Experimental Setup,[0],[0]
"For model training and testing, we divide conversations into three ordered segments, corresponding to training, development, and test sets at 75%, 12.5%, and 12.5%.8
Preprocessing and Hyperparameter Tuning.",4 Experimental Setup,[0],[0]
"For preprocessing, links, mentions (i.e., @username), and hashtags in tweets were replaced with generic tags of “URL”, “MENTION”, and “HASHTAG”.",4 Experimental Setup,[0],[0]
We then utilized the Twitter NLP tool9,4 Experimental Setup,[0],[0]
"(Gimpel et al., 2011; Owoputi et al., 2013) for tokenization and non-alphabetic token removal.",4 Experimental Setup,[0],[0]
We removed stop words and punctuations for all comparisons to ensure comparable performance.,4 Experimental Setup,[0],[0]
"We maintain a vocabulary with the 5,000 most frequent words.
",4 Experimental Setup,[0],[0]
"Our model parameters are tuned on the development set based on grid search, i.e. the parameters that give the lowest value for our objective are selected.",4 Experimental Setup,[0],[0]
"Specifically, the number of discourse modes (D) and topics (K) are tuned to be 10.",4 Experimental Setup,[0],[0]
"The trade-off parameter µ between user preference and corpus negative log-likelihood takes value of 0.1, and λ, the parameter for balancing topic and discourse, is set to 0.5.",4 Experimental Setup,[0],[0]
"Finally, the confidence parameter s takes a value of 200 to give higher weight for positive instances, i.e., a user replied to a conversation.
",4 Experimental Setup,[0],[0]
Evaluation Metrics.,4 Experimental Setup,[0],[0]
"Following prior work on social media post recommendation (Chen et al., 2012; Yan et al., 2012), we treat our task on conversation recommendation as a ranking problem.",4 Experimental Setup,[0],[0]
"Therefore, popular information retrieval evaluation metrics, including precision at K (P@K), mean average precision (MAP) (Manning et al., 2008), and normalized Discounted Cumulative Gain at K (nDCG@K) (Järvelin and Kekäläinen, 2002) are reported.",4 Experimental Setup,[0],[0]
The metrics are computed per user in the dataset and then averaged over all users.,4 Experimental Setup,[0],[0]
"The values range from 0.0 to 1.0, with higher values indicating better performance.
",4 Experimental Setup,[0],[0]
Baselines and Comparisons.,4 Experimental Setup,[0],[0]
"For comparison, we first consider three baselines: 1) ranking
8At least one turn per conversation is retained for training.",4 Experimental Setup,[0],[0]
"It is possible that one user only replies in either development set or test set, but it is rather infrequent.
",4 Experimental Setup,[0],[0]
"9http://www.cs.cmu.edu/˜ark/TweetNLP/
conversations randomly (RANDOM); 2) longer conversations (i.e., more words) ranked higher (LENGTH); 3) conversations with more distinct users ranked higher (POPULARITY).
",4 Experimental Setup,[0],[0]
"We further compare results with three established recommendation models: • OCCF: one-class Collaborative Filtering (Pan et al., 2008), which only considers users’ reply history without modeling content in conversations.",4 Experimental Setup,[0],[0]
• RSVM:,4 Experimental Setup,[0],[0]
"ranking SVM (Joachims, 2002), which ranks conversations for each user with the content and Twitter features as in Duan et al. (2010).",4 Experimental Setup,[0],[0]
"• CTR: messages in one conversation are aggregated into one post and a state-of-the art Collaborative Filtering-based post recommendation model is applied (Chen et al., 2012).
",4 Experimental Setup,[0],[0]
"Finally, we also adapt the “hidden factors as topics” (HFT) model proposed in McAuley and Leskovec (2013) (henceforth ADAPTED HFT).",4 Experimental Setup,[0],[0]
"Because the original model leverages the ratings for all product reviews and does not handle implicit user feedback well, we replace their user preference objective function with ours (Eq. 2).",4 Experimental Setup,[0],[0]
"In this section, we first discuss our main evaluation in Section 5.1.",5 Experimental Results,[0],[0]
"A case study and corresponding discussion are provided in Section 5.2 to provide further insights, which is followed by an analysis of the topics and discourse modes discovered by our model (Section 5.3).",5 Experimental Results,[0],[0]
We also examine our performance on first time replies (Section 5.4).,5 Experimental Results,[0],[0]
"Experimental results are displayed in Table 2, where our model yields statistically significantly better results than baselines and comparisons
(paired t-tests, p < 0.01).",5.1 Conversation Recommendation Results,[0],[0]
"For P@K, we only report P@1, because a significant amount of users participate only in 1 or 2 conversations.",5.1 Conversation Recommendation Results,[0],[0]
"For nDCG@K, different K values are experimented, which results in similar trend, so only nDCG@5 is reported.
",5.1 Conversation Recommendation Results,[0],[0]
"We find that the baselines that rank conversations with simple features (e.g., length or popularity) perform poorly.",5.1 Conversation Recommendation Results,[0],[0]
"This implies that generic algorithms that do not consider conversation content or user preference cannot produce reasonable recommendations.
",5.1 Conversation Recommendation Results,[0],[0]
"Although some non-baseline systems capture content in one way or another, only ADAPTED HFT and our model exploit latent topic models to better represent content in tweets, and outperform other methods.
",5.1 Conversation Recommendation Results,[0],[0]
"Compared to ADAPTED HFT, which only considers latent topics under a collaborative filtering framework, our model extracts both topics and discourse modes as latent variables, and shows superior performance on both datasets.",5.1 Conversation Recommendation Results,[0],[0]
"Our discourse variables go beyond topical content to capture social behaviors that affect user engagement, such as
arguments, question-asking, agreement, and other discourse modes.
",5.1 Conversation Recommendation Results,[0],[0]
Training with Varying Conversation History.,5.1 Conversation Recommendation Results,[0],[0]
"To test the model performance based different levels of user engagement history, we further experiment with varying the length of conversations for training.",5.1 Conversation Recommendation Results,[0],[0]
"Specifically, in addition to using 75% of conversation history, we also extract the first 25% and 50% of history as training.",5.1 Conversation Recommendation Results,[0],[0]
The rest of a conversation is separated equally for development and test.,5.1 Conversation Recommendation Results,[0],[0]
Figure 4 shows the MAP scores for US Election and TREC datasets.,5.1 Conversation Recommendation Results,[0],[0]
"The increasing MAP for all methods as the training history increases indicates that generally, conversation history is essential for recommendation.",5.1 Conversation Recommendation Results,[0],[0]
"Our model performs consistently better over different lengths of conversation histories.
",5.1 Conversation Recommendation Results,[0],[0]
Results for Varying Degree of Data Sparsity.,5.1 Conversation Recommendation Results,[0],[0]
"From Table 1 and Figure 3, we observe that most users in our datasets are involved in only a few conversations.",5.1 Conversation Recommendation Results,[0],[0]
"In order to study the effects of data sparsity on recommendation models, we examine in Figure 5 the MAP scores for users engaged in a varying number of conversations, as measured on the TREC dataset.",5.1 Conversation Recommendation Results,[0],[0]
The results on the US Election dataset have similar distributions.,5.1 Conversation Recommendation Results,[0],[0]
"As we see, the prediction results become worse for users involved in fewer conversations.",5.1 Conversation Recommendation Results,[0],[0]
This indicates that data sparsity serves as a challenge for all recommendation models.,5.1 Conversation Recommendation Results,[0],[0]
We also observe that our model performs consistently better than other models over different degrees of sparsity.,5.1 Conversation Recommendation Results,[0],[0]
"This implies that effectively capturing discourse structure in conversation context is useful to mitigating the effects of
data sparsity on conversation recommendation.",5.1 Conversation Recommendation Results,[0],[0]
Here we present a case study based on the sample conversations in Figure 1.,5.2 Case Study and Discussion,[0],[0]
"Recall that user U1 is interested in conversations about Sanders, and also prefers more argumentative discourse, and thus returns in conversation c2 but not c1.
",5.2 Case Study and Discussion,[0],[0]
"Table 3 shows the predicted scores for the two conversations from OCCF, ADAPTED HFT, and our model (as in Eq. 2).",5.2 Case Study and Discussion,[0],[0]
"Both ADAPTED HFT and our model more accurately recommend c2 over c1, with our model producing a slightly higher recommendation score for c2.
",5.2 Case Study and Discussion,[0],[0]
Table 4 shows the latent dimension values for the learned topics and discourse modes for this user and these two conversations.,5.2 Case Study and Discussion,[0],[0]
"Based on human inspection, topic 1 appears to contain words about Sanders, which is the main topic in conversation c2.",5.2 Case Study and Discussion,[0],[0]
"Topic 2 is about Clinton, which is a dominating topic in conversation c1.",5.2 Case Study and Discussion,[0],[0]
"Our model also picks up user interest in topic 1 (Sanders), and thus assigns γUu1,1 a high value.",5.2 Case Study and Discussion,[0],[0]
"For discourse modes, our model also generates a high score for “argument” discourse (labeled via human inspection) for both the user and c2.",5.2 Case Study and Discussion,[0],[0]
Ablation Study.,5.3 Further Analysis of Topic and Discourse,[0],[0]
"We have shown that joint modeling of topical content and discourse modes produces the superior performance for our model.
",5.3 Further Analysis of Topic and Discourse,[0],[0]
Here we provide an ablation study to examine the relative contributions of those two aspects by setting the trade-off parameter λ to 1.0 (topic only) or 0.0 (discourse only).,5.3 Further Analysis of Topic and Discourse,[0],[0]
"Table 5 shows that topics or discourse individually improve slightly upon the comparison ADAPTED HFT, but only jointly do they improve significantly upon it.
",5.3 Further Analysis of Topic and Discourse,[0],[0]
Topic Coherence.,5.3 Further Analysis of Topic and Discourse,[0],[0]
"To examine the quality of topics found by our model, we use the CV topic coherence score measured via the open-source toolkit Palmetto10, which has been shown to produce evaluation performance comparable to human judgment (Röder et al., 2015).",5.3 Further Analysis of Topic and Discourse,[0],[0]
"Our model achieves topic coherence scores of 0.343 and 0.376 on TREC and US Election datasets, compared to 0.338 and 0.371 for the topics from ADAPTED HFT.
",5.3 Further Analysis of Topic and Discourse,[0],[0]
Sample Discourse Modes.,5.3 Further Analysis of Topic and Discourse,[0],[0]
"While our topic word distributions are relatively unsurprising, of greater interest are the discourse mode word distributions.",5.3 Further Analysis of Topic and Discourse,[0],[0]
Table 6 shows a sample of discourse modes as labeled by human.,5.3 Further Analysis of Topic and Discourse,[0],[0]
"Although this is merely a qualitative human judgment at this point, there does appear to be a notable overlap in discourse modes between the two datasets even though they were learned separately.
",5.3 Further Analysis of Topic and Discourse,[0],[0]
10https://github.com/AKSW/Palmetto/,5.3 Further Analysis of Topic and Discourse,[0],[0]
"From a recommendation perspective, users may be interested in joining new conversations.",5.4 First Time Reply Results,[0],[0]
We thus compare each recommendation system for first time replies.,5.4 First Time Reply Results,[0],[0]
"For each user, we only evaluate for conversations where they are newcomers.",5.4 First Time Reply Results,[0],[0]
"Table 7 shows that, unsurprisingly, all systems perform poorly on this task, though our model performs slightly better.",5.4 First Time Reply Results,[0],[0]
"This suggests that other features, e.g., network structures or other discussion thread features, could usefully be included in future studies that target new conversations.",5.4 First Time Reply Results,[0],[0]
This paper has presented a framework for microblog conversation recommendation via jointly modeling topics and discourse modes.,6 Conclusion,[0],[0]
Experimental results show that our method can outperform competitive approaches that omit user discourse behaviors.,6 Conclusion,[0],[0]
Qualitative analysis shows that our joint model yields meaningful topics and discourse representations.,6 Conclusion,[0],[0]
This work is partly supported by Innovation and Technology Fund (ITF) Project,Acknowledgements,[0],[0]
"No. 6904333, General Research Fund (GRF) Project No. 14232816 (12183516), and National Science Foundation Grant IIS-1566382.",Acknowledgements,[0],[0]
"We thank Shuming Shi, Yan Song, and the three anonymous reviewers for the insightful suggestions on various aspects of this work.",Acknowledgements,[0],[0]
Millions of conversations are generated every day on social media platforms.,abstractText,[0],[0]
"With limited attention, it is challenging for users to select which discussions they would like to participate in.",abstractText,[0],[0]
Here we propose a new method for microblog conversation recommendation.,abstractText,[0],[0]
"While much prior work has focused on postlevel recommendation, we exploit both the conversational context, and user content and behavior preferences.",abstractText,[0],[0]
"We propose a statistical model that jointly captures: (1) topics for representing user interests and conversation content, and (2) discourse modes for describing user replying behavior and conversation dynamics.",abstractText,[0],[0]
Experimental results on two Twitter datasets demonstrate that our system outperforms methods that only model content without considering discourse.,abstractText,[0],[0]
Microblog Conversation Recommendation via Joint Modeling of Topics and Discourse,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 102–112 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"One of the key advantages of word embeddings for natural language processing is that they enable generalization to words that are unseen in labeled training data, by embedding lexical features from large unlabeled datasets into a relatively low-dimensional Euclidean space.",1 Introduction,[0],[0]
"These low-dimensional embeddings are typically trained to capture distributional similarity, so that information can be shared among words that tend to appear in similar contexts.
",1 Introduction,[0],[0]
"However, it is not possible to enumerate the entire vocabulary of any language, and even large unlabeled datasets will miss terms that appear in later applications.",1 Introduction,[0],[0]
The issue of how to handle these out-of-vocabulary (OOV) words poses challenges for embedding-based methods.,1 Introduction,[0],[0]
"These challenges are particularly acute when working with lowresource languages, where even unlabeled data may be difficult to obtain at scale.",1 Introduction,[0],[0]
"A typical solution is to abandon hope, by assigning a single OOV embedding to all terms that do not appear in the unlabeled data.
",1 Introduction,[0],[0]
We approach this challenge from a quasigenerative perspective.,1 Introduction,[0],[0]
"Knowing nothing of a word except for its embedding and its written form, we attempt to learn the former from the latter.",1 Introduction,[0],[0]
"We train a recurrent neural network (RNN) on the character level with the embedding as the target, and use it later to predict vectors for OOV words in any downstream task.",1 Introduction,[0],[0]
"We call this model the MIMICK-RNN, for its ability to read a word’s spelling and mimick its distributional embedding.
",1 Introduction,[0],[0]
"Through nearest-neighbor analysis, we show that vectors learned via this method capture both word-shape features and lexical features.",1 Introduction,[0],[0]
"As a result, we obtain reasonable near-neighbors for OOV abbreviations, names, novel compounds, and orthographic errors.",1 Introduction,[0],[0]
"Quantitative evaluation on the Stanford RareWord dataset (Luong et al., 2013) provides more evidence that these character-based embeddings capture word similarity for rare and unseen words.
",1 Introduction,[0],[0]
"As an extrinsic evaluation, we conduct experiments on joint prediction of part-of-speech tags and morphosyntactic attributes for a diverse set of 23 languages, as provided in the Universal Dependencies dataset (De Marneffe et al., 2014).",1 Introduction,[0],[0]
"Our model shows significant improvement
102
across the board against a single UNK-embedding backoff method, and obtains competitive results against a supervised character-embedding model, which is trained end-to-end on the target task.",1 Introduction,[0],[0]
"In low-resource settings, our approach is particularly effective, and is complementary to supervised character embeddings trained from labeled data.",1 Introduction,[0],[0]
The MIMICK-RNN therefore provides a useful new tool for tagging tasks in settings where there is limited labeled data.,1 Introduction,[0],[0]
Models and code are available at www.github.com/ yuvalpinter/mimick .,1 Introduction,[0],[0]
Compositional models for embedding rare and unseen words.,2 Related Work,[0],[0]
"Several studies make use of morphological or orthographic information when training word embeddings, enabling the prediction of embeddings for unseen words based on their internal structure.",2 Related Work,[0],[0]
Botha and Blunsom (2014) compute word embeddings by summing over embeddings of the morphemes; Luong et al. (2013) construct a recursive neural network over each word’s morphological parse; Bhatia et al. (2016) use morpheme embeddings as a prior distribution over probabilistic word embeddings.,2 Related Work,[0],[0]
"While morphology-based approaches make use of meaningful linguistic substructures, they struggle with names and foreign language words, which include out-of-vocabulary morphemes.",2 Related Work,[0],[0]
"Character-based approaches avoid these problems: for example, Kim et al. (2016) train a recurrent neural network over words, whose embeddings are constructed by convolution over character embeddings; Wieting et al. (2016) learn embeddings of character ngrams, and then sum them into word embeddings.",2 Related Work,[0],[0]
"In all of these cases, the model for composing embeddings of subword units into word embeddings is learned by optimizing an objective over a large unlabeled corpus.",2 Related Work,[0],[0]
"In contrast, our approach is a post-processing step that can be applied to any set of word embeddings, regardless of how they were trained.",2 Related Work,[0],[0]
"This is similar to the “retrofitting” approach of Faruqui et al. (2015), but rather than smoothing embeddings over a graph, we learn a function to build embeddings compositionally.
",2 Related Work,[0],[0]
Supervised subword models.,2 Related Work,[0],[0]
Another class of methods learn task-specific character-based word embeddings within end-to-end supervised systems.,2 Related Work,[0],[0]
"For example, Santos and Zadrozny (2014) build word embeddings by convolution over char-
acters, and then perform part-of-speech (POS) tagging using a local classifier; the tagging objective drives the entire learning process.",2 Related Work,[0],[0]
"Ling et al. (2015) propose a multi-level long shortterm memory (LSTM; Hochreiter and Schmidhuber, 1997), in which word embeddings are built compositionally from an LSTM over characters, and then tagging is performed by an LSTM over words.",2 Related Work,[0],[0]
Plank et al. (2016) show that concatenating a character-level or bit-level LSTM network to a word representation helps immensely in POS tagging.,2 Related Work,[0],[0]
"Because these methods learn from labeled data, they can cover only as much of the lexicon as appears in their labeled training sets.",2 Related Work,[0],[0]
"As we show, they struggle in several settings: lowresource languages, where labeled training data is scarce; morphologically rich languages, where the number of morphemes is large, or where the mapping from form to meaning is complex; and in Chinese, where the number of characters is orders of magnitude larger than in non-logographic scripts.",2 Related Work,[0.9505933519719192],"['However, from a resource perspective, previous multimodal language datasets have severe shortcomings in the following aspects: Diversity in the training samples: The diversity in training samples is crucial for comprehensive multimodal language studies due to the complexity of the underlying distribution.']"
"Furthermore, supervised subword models can be combined with MIMICK, offering additive improvements.
",2 Related Work,[0],[0]
Morphosyntactic attribute tagging.,2 Related Work,[0],[0]
"We evaluate our method on the task of tagging word tokens for their morphosyntactic attributes, such as gender, number, case, and tense.",2 Related Work,[0],[0]
"The task of morpho-syntactic tagging dates back at least to the mid 1990s (Oflazer and Kuruöz, 1994; Hajič and Hladká, 1998), and interest has been rejuvenated by the availability of large-scale multilingual morphosyntactic annotations through the Universal Dependencies (UD) corpus (De Marneffe et al., 2014).",2 Related Work,[0],[0]
"For example, Faruqui et al. (2016) propose a graph-based technique for propagating typelevel morphological information across a lexicon, improving token-level morphosyntactic tagging in 11 languages, using an SVM tagger.",2 Related Work,[0],[0]
"In contrast, we apply a neural sequence labeling approach, inspired by the POS tagger of Plank et al. (2016).",2 Related Work,[0],[0]
"We approach the problem of out-of-vocabulary (OOV) embeddings as a generation problem: regardless of how the original embeddings were created, we assume there is a generative wordformbased protocol for creating these embeddings.",3 MIMICK Word Embeddings,[0],[0]
"By training a model over the existing vocabulary, we can later use that model for predicting the embedding of an unseen word.
",3 MIMICK Word Embeddings,[0],[0]
"Formally: given a language L, a vocabulary V ⊆ L of size V , and a pre-trained embeddings table W ∈ RV×d where each word {wk}Vk=1 is assigned a vector ek of dimension d, our model is trained to find the function f :",3 MIMICK Word Embeddings,[0],[0]
L → Rd such that the projected function f |V approximates the assignments f(wk),3 MIMICK Word Embeddings,[0],[0]
≈ ek.,3 MIMICK Word Embeddings,[0],[0]
"Given such a model, a new word wk∗ ∈ L \ V can now be assigned an embedding ek∗ = f(wk∗).
",3 MIMICK Word Embeddings,[0],[0]
Our predictive function of choice is a Word Type Character Bi-LSTM.,3 MIMICK Word Embeddings,[0],[0]
"Given a word with character sequence w = {ci}n1 , a forward-LSTM and a backward-LSTM are run over the corresponding character embeddings sequence {e(c)i }n1 .",3 MIMICK Word Embeddings,[0],[0]
"Let hnf represent the final hidden vector for the forward-LSTM, and let h0b represent the final hidden vector for the backward-LSTM.",3 MIMICK Word Embeddings,[0],[0]
"The word embedding is computed by a multilayer perceptron:
(1)f(w) = OT · g(Th ·",3 MIMICK Word Embeddings,[0],[0]
"[hnf ; h0b ] + bh) + bT ,
where Th, bh and OT , bT are parameters of affine transformations, and g is a nonlinear elementwise function.",3 MIMICK Word Embeddings,[0],[0]
"The model is presented in Figure 1.
",3 MIMICK Word Embeddings,[0],[0]
The training objective is similar to that of Yin and Schütze (2016).,3 MIMICK Word Embeddings,[0],[0]
"We match the predicted embeddings f(wk) to the pre-trained word embeddings ewk , by minimizing the squared Euclidean distance,
(2)L = ‖f(wk)− ewk‖22 .
",3 MIMICK Word Embeddings,[0],[0]
"By backpropagating from this loss, it is possible to obtain local gradients with respect to the parameters of the LSTMs, the character embeddings, and the output model.",3 MIMICK Word Embeddings,[0],[0]
"The ultimate output of the training phase is the character embeddings matrix C and the parameters of the neural network: M = {C,F,B,Th, bh,OT , bT }, where F,B are the forward and backward LSTM component parameters, respectively.",3 MIMICK Word Embeddings,[0],[0]
"The pretrained embeddings we use in our experiments are obtained from Polyglot (Al-Rfou et al., 2013), a multilingual word embedding effort.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Available for dozens of languages, each dataset contains 64-dimension embeddings for the 100,000 most frequent words in a language’s training corpus (of variable size), as well as an UNK embedding to be used for OOV words.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Even with this vocabulary size, querying words from respective UD corpora (train + dev + test) yields high
OOV rates: in at least half of the 23 languages in our experiments (see Section 5), 29.1% or more of the word types do not appear in the Polyglot vocabulary.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"The token-level median rate is 9.2%.1
Applying our MIMICK algorithm to Polyglot embeddings, we obtain a prediction model for each of the 23 languages.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Based on preliminary testing on randomly selected held-out development sets of 1% from each Polyglot vocabulary (with error calculated as in Equation 2), we set the following hyper-parameters for the remainder of the experiments: character embedding dimension = 20; one LSTM layer with 50 hidden units; 60 training epochs with no dropout; nonlinearity function g =",3.1 MIMICK Polyglot Embeddings,[0],[0]
"tanh.2 We initialize character embeddings randomly, and use DyNet to implement the model (Neubig et al., 2017).
",3.1 MIMICK Polyglot Embeddings,[0],[0]
Nearest-neighbor examination.,3.1 MIMICK Polyglot Embeddings,[0],[0]
"As a preliminary sanity check for the validity of our protocol, we examined nearest-neighbor samples in languages for which speakers were available: English, Hebrew, Tamil, and Spanish.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Table 1 presents selected English OOV words with
1Some OOV counts, and resulting model performance, may be adversely affected by tokenization differences between Polyglot and UD.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Notably, some languages such as Spanish, Hebrew and Italian exhibit relational synthesis wherein words of separate grammatical phrases are joined into one form (e.g. Spanish del = de + el, ‘from the-masc.sg.’).",3.1 MIMICK Polyglot Embeddings,[0],[0]
"For these languages, the UD annotations adhere to the sub-token level, while Polyglot does not perform subtokenization.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"As this is a real-world difficulty facing users of out-of-the-box embeddings, we do not patch it over in our implementations or evaluation.
",3.1 MIMICK Polyglot Embeddings,[0],[0]
"2Other settings, described below, were tuned on the supervised downstream tasks.
",3.1 MIMICK Polyglot Embeddings,[0],[0]
their nearest in-vocabulary Polyglot words computed by cosine similarity.,3.1 MIMICK Polyglot Embeddings,[0],[0]
"These examples demonstrate several properties: (a) word shape is learned well (acronyms, capitalizations, suffixes); (b) the model shows robustness to typos (e.g., developiong, corssing); (c) part-of-speech is learned across multiple suffixes (pesky – euphoric, ghastly); (d) word compounding is detected (e.g., lawnmower – bookmaker, postman); (e) semantics are not learned well (as is to be expected from the lack of context in training), but there are surprises (e.g., flatfish – slimy, watery).",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Table 2 presents examples from Hebrew that show learned properties can be extended to nominal morphosyntactic attributes (gender, number – first two examples) and even relational syntactic subword forms such as genetive markers (third example).",3.1 MIMICK Polyglot Embeddings,[0],[0]
Names are learned (fourth example) despite the lack of casing in the script.,3.1 MIMICK Polyglot Embeddings,[0],[0]
"Spanish examples exhibit wordshape and part-of-speech learning patterns with some loose semantics: for example, the plural adjective form prenatales is similar to other familyrelated plural adjectives such as patrimoniales and generacionales.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Tamil displays some semantic similarities as well: e.g. enjineer (‘engineer’) predicts similarity to other professional terms such as kalviyiyal (‘education’), thozhilnutpa (‘technical’), and iraanuva (‘military’).
",3.1 MIMICK Polyglot Embeddings,[0],[0]
Stanford RareWords.,3.1 MIMICK Polyglot Embeddings,[0],[0]
"The Stanford RareWord evaluation corpus (Luong et al., 2013) focuses on predicting word similarity between pairs involving low-frequency English words, predominantly ones with common morphological affixes.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"As these words are unlikely to be above the cutoff threshold for standard word embedding models, they emphasize the performance on OOV words.
",3.1 MIMICK Polyglot Embeddings,[0],[0]
"For evaluation of our MIMICK model on the RareWord corpus, we trained the Variational Embeddings algorithm (VarEmbed; Bhatia et al., 2016) on a 20-million-token, 100,000- type Wikipedia corpus, obtaining 128-dimension
word embeddings for all words in the test corpus.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"VarEmbed estimates a prior distribution over word embeddings, conditional on the morphological composition.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"For in-vocabulary words, a posterior is estimated from unlabeled data; for outof-vocabulary words, the expected embedding can be obtained from the prior alone.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"In addition, we compare to FastText (Bojanowski et al., 2016), a high-vocabulary, high-dimensionality embedding benchmark.
",3.1 MIMICK Polyglot Embeddings,[0],[0]
"The results, shown in Table 3, demonstrate that the MIMICK RNN recovers about half of the loss in performance incurred by the original Polyglot training model due to out-of-vocabulary words in the “All pairs” condition.",3.1 MIMICK Polyglot Embeddings,[0],[0]
MIMICK also outperforms VarEmbed.,3.1 MIMICK Polyglot Embeddings,[0],[0]
"FastText can be considered an upper bound: with a vocabulary that is 25 times larger than the other models, it was missing words from only 44 pairs on this data.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"The Universal Dependencies (UD) scheme (De Marneffe et al., 2014) features a minimal set of 17 POS tags (Petrov et al., 2012) and supports tagging further language-specific features using attribute-specific inventories.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"For example, a verb in Turkish could be assigned a value for the evidentiality attribute, one which is absent from Danish.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"These additional morphosyntactic attributes are marked in the UD dataset as optional per-token attribute-value pairs.
",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"Our approach for tagging morphosyntactic attributes is similar to the part-of-speech tagging model of Ling et al. (2015), who attach a projection layer to the output of a sentence-level bidirectional LSTM.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
We extend this approach to morphosyntactic tagging by duplicating this projection layer for each attribute type.,4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"The input to our multilayer perceptron (MLP) projection network is the hidden state produced for each token in the sentence by an underlying LSTM, and the output is
attribute-specific probability distributions over the possible values for each attribute on each token in the sequence.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"Formally, for a given attribute a with possible values v ∈ Va, the tagging probability for the i’th word in a sentence is given by:
Pr(awi = v) =",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"(Softmax(φ(hi)))v , (3)
with
(4)φ(hi) = OaW · tanh(Wah ·",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"hi + bah) + baW ,
where hi is the i’th hidden state in the underlying LSTM, and φ(hi) is a two-layer feedforward neural network, with weights Wah and O a W .",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
We apply a softmax transformation to the output; the value at position v is then equal to the probability of attribute v applying to token wi.,4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"The input to the underlying LSTM is a sequence of word embeddings, which are initialized to the Polyglot vectors when possible, and to MIMICK vectors when necessary.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"Alternative initializations are considered in the evaluation, as described in Section 5.2.
",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
Each tagged attribute sequence (including POS tags) produces a loss equal to the sum of negative log probabilities of the true tags.,4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
One way to combine these losses is to simply compute the sum loss.,4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"However, many languages have large differences in sparsity across morpho-syntactic attributes, as apparent from Table 4 (rightmost column).",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"We therefore also compute a weighted sum
loss, in which each attribute is weighted by the proportion of training corpus tokens on which it is assigned a non-NONE value.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"Preliminary experiments on development set data were inconclusive across languages and training set sizes, and so we kept the simpler sum loss objective for the remainder of our study.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"In all cases, part-of-speech tagging was less accurate when learned jointly with morphosyntactic attributes.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
This may be because the attribute loss acts as POS-unrelated “noise” affecting the common LSTM layer and the word embeddings.,4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
The morphological complexity and compositionality of words varies greatly across languages.,5 Experimental Settings,[0],[0]
"While a morphologically-rich agglutinative language such as Hungarian contains words that carry many attributes as fully separable morphemes, a sentence in an analytic language such as Vietnamese may have not a single polymorphemic or inflected word in it.",5 Experimental Settings,[0],[0]
"To see whether this property is influential on our MIMICK model and its performance in the downstream tagging task, we select languages that comprise a sample of multiple morphological patterns.",5 Experimental Settings,[0],[0]
"Language family and script type are other potentially influential factors in an orthography-based approach such as ours, and so we vary along these parameters as well.",5 Experimental Settings,[0],[0]
"We also considered language selection recommendations from de Lhoneux and Nivre (2016) and Schluter and Agić (2017).
",5 Experimental Settings,[0],[0]
"As stated above, our approach is built on the Polyglot word embeddings.",5 Experimental Settings,[0],[0]
The intersection of the Polyglot embeddings and the UD dataset (version 1.4) yields 44 languages.,5 Experimental Settings,[0],[0]
"Of these, many are under-annotated for morphosyntactic attributes; we select twenty-three sufficiently-tagged languages, with the exception of Indonesian.3 Table 4 presents the selected languages and their typological properties.",5 Experimental Settings,[0],[0]
"As an additional proxy for mor-
3Vietnamese has no attributes by design; it is a pure analytic language.
",5 Experimental Settings,[0],[0]
"phological expressiveness, the rightmost column shows the proportion of UD tokens which are annotated with any morphosyntactic attribute.",5 Experimental Settings,[0],[0]
"As noted above, we use the UD datasets for testing our MIMICK algorithm on 23 languages4 with the supplied train/dev/test division.",5.1 Metrics,[0],[0]
"We measure partof-speech tagging by overall token-level accuracy.
",5.1 Metrics,[0],[0]
"For morphosyntactic attributes, there does not seem to be an agreed-upon metric for reporting performance.",5.1 Metrics,[0],[0]
Dzeroski et al. (2000) report pertag accuracies on a morphosyntactically tagged corpus of Slovene.,5.1 Metrics,[0],[0]
"Faruqui et al. (2016) report macro-averages of F1 scores of 11 languages from UD 1.1 for the various attributes (e.g., part-ofspeech, case, gender, tense); recall and precision were calculated for the full set of each attribute’s values, pooled together.5",5.1 Metrics,[0],[0]
Agić,5.1 Metrics,[0],[0]
"et al. (2013) report separately on parts-of-speech and morphosyntactic attribute accuracies in Serbian and Croatian, as well as precision, recall, and F1 scores per tag.",5.1 Metrics,[0],[0]
"Georgiev et al. (2012) report token-level accuracy for exact all-attribute tags (e.g. ‘Ncmsh’ for “Noun short masculine singular definite”) in Bulgarian, reaching a tagset of size 680.",5.1 Metrics,[0],[0]
Müller et al. (2013) do the same for six other languages.,5.1 Metrics,[0],[0]
"We report micro F1: each token’s value for each attribute is compared separately with the gold labeling, where a correct prediction is a matching non-NONE attribute/value assignment.",5.1 Metrics,[0],[0]
"Recall and
4When several datasets are available for a language, we use the unmarked corpus.
5Details were clarified in personal communication with the authors.
precision are calculated over the entire set, with F1 defined as their harmonic mean.",5.1 Metrics,[0],[0]
"We implement and test the following models:
No-Char.",5.2 Models,[0],[0]
"Word embeddings are initialized from Polyglot models, with unseen words assigned the Polyglot-supplied UNK vector.",5.2 Models,[0],[0]
"Following tuning experiments on all languages with cased script, we found it beneficial to first back off to the lowercased form for an OOV word if its embedding exists, and only otherwise assign UNK.
MIMICK.",5.2 Models,[0],[0]
"Word embeddings are initialized from Polyglot, with OOV embeddings inferred from a MIMICK model (Section 3) trained on the Polyglot embeddings.",5.2 Models,[0],[0]
"Unlike the No-Char case, backing off to lowercased embeddings before using the MIMICK output did not yield conclusive benefits and thus we report results for the more straightforward no-backoff implementation.
CHAR→TAG.",5.2 Models,[0],[0]
"Word embeddings are initialized from Polyglot as in the No-Char model (with lowercase backoff), and appended with the output of a character-level LSTM updated during training (Plank et al., 2016).",5.2 Models,[0],[0]
"This additional module causes a threefold increase in training time.
",5.2 Models,[0],[0]
Both.,5.2 Models,[0],[0]
"Word embeddings are initialized as in MIMICK, and appended with the CHAR→TAG LSTM.
",5.2 Models,[0],[0]
Other models.,5.2 Models,[0],[0]
"Several non-Polyglot embedding models were examined, all performed substantially worse than Polyglot.",5.2 Models,[0],[0]
"Two of these
are notable: a random-initialization baseline, and a model initialized from FastText embeddings (tested on English).",5.2 Models,[0],[0]
"FastText supplies 300-dimension embeddings for 2.51 million lowercase-only forms, and no UNK vector.6 Both of these embedding models were attempted with and without CHAR→TAG concatenation.",5.2 Models,[0],[0]
"Another model, initialized from only MIMICK output embeddings, performed well only on the language with smallest Polyglot training corpus (Latvian).",5.2 Models,[0],[0]
"A Polyglot model where OOVs were initialized using an averaged embedding of all Polyglot vectors, rather than the supplied UNK vector, performed worse than our No-Char baseline on a great majority of the languages.
",5.2 Models,[0],[0]
"Last, we do not employ type-based tagset restrictions.",5.2 Models,[0],[0]
All tag inventories are computed from the training sets and each tag selection is performed over the full set.,5.2 Models,[0],[0]
"Based on development set experiments, we set the following hyperparameters for all models on all languages: two LSTM layers of hidden size 128, MLP hidden layers of size equal to the number of each attribute’s possible values; momentum stochastic gradient descent with 0.01 learning rate; 40 training epochs (80 for 5K settings) with a dropout rate of 0.5.",5.3 Hyperparameters,[0],[0]
The CHAR→TAG models use 20-dimension character embeddings and a single hidden layer of size 128.,5.3 Hyperparameters,[0],[0]
We report performance in both low-resource and full-resource settings.,6 Results,[0],[0]
"Low-resource training sets were obtained by randomly sampling training sentences, without replacement, until a predefined token limit was reached.",6 Results,[0],[0]
We report the results on the full sets and on N = 5000 tokens in Table 5 (partof-speech tagging accuracy) and Table 6 (morphosyntactic attribute tagging micro-F1).,6 Results,[0],[0]
"Results for additional training set sizes are shown in Figure 2; space constraints prevent us from showing figures for all languages.
MIMICK as OOV initialization.",6 Results,[0],[0]
"In nearly all experimental settings on both tasks, across languages and training corpus sizes, the MIMICK embeddings significantly improve over the Polyglot UNK embedding for OOV tokens on both
6Vocabulary type-level coverage for the English UD corpus: 55.6% case-sensitive, 87.9% case-insensitive.
",6 Results,[0],[0]
POS and morphosyntactic tagging.,6 Results,[0],[0]
"For POS, the largest margins are in the Slavic languages (Russian, Czech, Bulgarian), where word order is relatively free and thus rich word representations are imperative.",6 Results,[0],[0]
"Chinese also exhibits impressive improvement across all settings, perhaps due to the large character inventory (> 12,000), for which a model such as MIMICK can learn well-informed embeddings using the large Polyglot vocabulary dataset, overcoming both word- and characterlevel sparsity in the UD",6 Results,[0],[0]
"corpus.7 In morphosyntactic tagging, gains are apparent for Slavic languages and Chinese, but also for agglutinative languages — especially Tamil and Turkish — where the stable morpheme representation makes it easy for subword modeling to provide a type-level signal.8 To examine the effects on Slavic and agglutinative languages in a more fine-grained view, we present results of multiple training-set size experiments for each model, averaged over five repetitions (with different corpus samples), in Figure 2.
MIMICK vs. CHAR→TAG.",6 Results,[0],[0]
"In several languages, the MIMICK algorithm fares better than the CHAR→TAG model on part-of-speech tagging in low-resource settings.",6 Results,[0],[0]
"Table 7 presents the POS tagging improvements that MIMICK achieves over the pre-trained Polyglot models, with and without CHAR→TAG concatenation, with 10,000 tokens of training data.",6 Results,[0],[0]
"We obtain statistically significant improvements in most languages, even when CHAR→TAG is included.",6 Results,[0],[0]
"These improvements are particularly substantial for test-set tokens outside the UD training set, as shown in the right two columns.",6 Results,[0],[0]
"While test set OOVs are a strength of the CHAR→TAG model (Plank et al., 2016), in many languages there are still considerable improvements to be obtained from the application of MIMICK initialization.",6 Results,[0],[0]
"This suggests that with limited training data, the end-to-end CHAR→TAG model is unable to learn a sufficiently accurate representational mapping from orthography.",6 Results,[0],[0]
"We present a straightforward algorithm to infer OOV word embedding vectors from pre-trained,
7Character coverage in Chinese Polyglot is surprisingly good: only eight characters from the UD dataset are unseen in Polyglot, across more than 10,000 unseen word types.
",7 Conclusion,[0],[0]
8Persian is officially classified as agglutinative but it is mostly so with respect to derivations.,7 Conclusion,[0],[0]
"Its word-level inflections are rare and usually fusional.
limited-vocabulary models, without need to access the originating corpus.",7 Conclusion,[0],[0]
"This method is particularly useful for low-resource languages and tasks with little labeled data available, and in fact is task-agnostic.",7 Conclusion,[0],[0]
"Our method improves performance over word-based models on annotated sequence-tagging tasks for a large variety of languages across dimensions of family, orthography, and morphology.",7 Conclusion,[0],[0]
"In addition, we present a BiLSTM approach for tagging morphosyntactic attributes at the token level.",7 Conclusion,[0],[0]
"In this paper, the MIMICK model was trained using characters as input, but future work may consider the use of other subword units, such as morphemes, phonemes, or even bitmap representations of ideographic characters (Costa-jussà et al., 2017).",7 Conclusion,[0],[0]
"We thank Umashanthi Pavalanathan, Sandeep Soni, Roi Reichart, and our anonymous reviewers for their valuable input.",8 Acknowledgments,[0],[0]
We thank Manaal Faruqui and Ryan McDonald for their help in understanding the metrics for morphosyntactic tagging.,8 Acknowledgments,[0],[0]
The project was supported by project HDTRA1-15-10019 from the Defense Threat Reduction Agency.,8 Acknowledgments,[0],[0]
"Word embeddings improve generalization over lexical features by placing each word in a lower-dimensional space, using distributional information obtained from unlabeled data.",abstractText,[0],[0]
"However, the effectiveness of word embeddings for downstream NLP tasks is limited by out-of-vocabulary (OOV) words, for which embeddings do not exist.",abstractText,[0],[0]
"In this paper, we present MIMICK, an approach to generating OOV word embeddings compositionally, by learning a function from spellings to distributional embeddings.",abstractText,[0],[0]
"Unlike prior work, MIMICK does not require re-training on the original word embedding corpus; instead, learning is performed at the type level.",abstractText,[0],[0]
Intrinsic and extrinsic evaluations demonstrate the power of this simple approach.,abstractText,[0],[0]
"On 23 languages, MIMICK improves performance over a word-based baseline for tagging part-of-speech and morphosyntactic attributes.",abstractText,[0],[0]
It is competitive with (and complementary to) a supervised characterbased model in low-resource settings.,abstractText,[0],[0]
Mimicking Word Embeddings using Subword RNNs,title,[0],[0]
The sheer number and variety of online social networks (OSN) today is staggering.,1. Introduction,[0],[0]
"Although the purpose and the shaping of these networks vary generously, the majority of them has one aspect in common: the value of most OSNs is in its user data and the information that one can infer from the data.",1. Introduction,[0],[0]
"This, unfortunately, results in a big incentive for culprits to intrude OSNs and manipulate their data.",1. Introduction,[0],[0]
"One popular method of intruding and attacking an OSN is referred to as Sybil attack, where the intruder creates a whole bunch of fake (Sybil) accounts that are all under the attacker’s control.",1. Introduction,[0],[0]
"The intruder’s influence over the OSN
1MathPlan, 10587 Berlin, Germany 2Machine Learning Group, Berlin Institute of Technology, 10587 Berlin, Germany 3Berlin Big Data Center 4Max Planck Society 5Korea University.",1. Introduction,[0],[0]
Correspondence to: János,1. Introduction,[0],[0]
Höner <,1. Introduction,[0],[0]
"janos.hoener@campus.tuberlin.de>, Nico Görnitz <nico.goernitz@tu-berlin.de>, KlausRobert Müller <klaus-robert.mueller@tu-berlin.de>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
is multiplied by the number of accounts created, which opens possibilities of manipulation typically for gaining some monetary advantage in the end.
",1. Introduction,[0],[0]
"The term, Sybil attack, was coined by Douceur (2002) who showed that this kind of attack will be always possible unless a trusted agency certifies identities.",1. Introduction,[0],[0]
"Unfortunately, this approach is orthogonal to how OSNs grow.",1. Introduction,[0],[0]
The threshold of registration must be as low as possible to attract as many new users as possible.,1. Introduction,[0],[0]
"On the other hand, Sybil attacks can damage the value of OSNs significantly, which has been proved by the fact that Facebook shares dropped in 2012 after the company revealed that a significant share of its network is made up by Sybil accounts (The Associated Press, 2012).
",1. Introduction,[0],[0]
"There exists a number of “classic” feature-based solutions (Stein et al., 2011; Cao et al., 2012; Stringhini et al., 2010; Yang et al., 2014).",1. Introduction,[0],[0]
"However, up until now, it remains an unsolved problem as those methods can be evaded by cleverly designed attacking schemes (Bilge et al., 2009; Boshmaf et al., 2011; Wagner et al., 2012; Lowd & Meek, 2005) and manual detection is too expensive, time consuming, and simply unfeasible in large OSNs (Cao et al., 2012).
",1. Introduction,[0],[0]
More recent graph-based Sybil detection methods assume that honest (non-Sybil) nodes form a strongly connected subgraph and attackers can establish a limited amount of edges which leads to a sparse cut between the honest subraph and the Sybil nodes.,1. Introduction,[0],[0]
"The majority of the graph-based methods define trusted nodes, which the defender is sure to be honest, and use random walks (Yu et al., 2010; Danezis, 2009; Cao et al., 2012) or other typical graph-based algorithms like breadth-first-search (Tran et al., 2011) and belief propagation (Gong et al., 2014) to convey trust from the trusted nodes.",1. Introduction,[0],[0]
A node is identified as Sybil if sufficient ammount of trust is not delivered to it.,1. Introduction,[0],[0]
"Among random-walk based approaches, SybilRank is known to be the state-ofthe-art, of which the performance is theoretically guaranteed (Cao et al., 2012).",1. Introduction,[0],[0]
"However, the theory holds only under unrealistic topological assumptions of the network.",1. Introduction,[0],[0]
"In this paper, we show that the same theoretical guarantee can be obtained under more realistic situations.
",1. Introduction,[0],[0]
We further dicuss the robustness of the random walk approach against adversarial strategies.,1. Introduction,[0],[0]
"To this end, we formally introduce adversarial settings for graph-based Sybil
detection and derive an optimal attacking strategy that is based on the exploitation of trust leaks.",1. Introduction,[0],[0]
"Based on our analysis, we propose a transductive Sybil ranking (TSR), an integrated approach capable of adjusting edge weights based on sampled trust leaks.",1. Introduction,[0],[0]
We empirically show good performance of TSR against the state-of-the-art baselines on a variety of attacking scenarios using artificially generated data as well as real-world Facebook data.,1. Introduction,[0],[0]
"We are given a graph G = (V,E) consisting of nodes V and pairwise edges E between nodes.",2. Preliminaries,[0],[0]
"We denote GS = (VS , ES) the Sybil sub-graph, GH = (VH , EH) the disjunct honest sub-graph, and VT ✓ VH our trusted (verified nonSybil nodes) random walk seed nodes.",2. Preliminaries,[0],[0]
EA is the set of edges connecting any node in GS and any node in GH .,2. Preliminaries,[0],[0]
"Sybil Rank is considered the state-of-the-art graph-based method to detect Sybil accounts as it outperformed all its contestants (Cao et al., 2012).",2. Preliminaries,[0],[0]
It is also based on random walks and operates solely on the topology of the graph.,2. Preliminaries,[0],[0]
"Sybil Rank starts from the initial distribution {p(i)0 2 [0, 1]}|V |i=1",2. Preliminaries,[0],[0]
"(without superscript refers to a vector containing all elements), in which “trust” is assigned to the known honest nodes VT :
p (i) 0",2. Preliminaries,[0],[0]
"=
( 1
|VT",2. Preliminaries,[0],[0]
"| if vi 2 VT , 0 otherwise.
(1)
Then, it “propagates” the trust via a short (k steps) random walk:
p > k",2. Preliminaries,[0],[0]
= p >,2. Preliminaries,[0],[0]
k,2. Preliminaries,[0],[0]
"1Q = · · · = p>0 Qk , (2)
where Q 2 R|V |⇥|V",2. Preliminaries,[0],[0]
"| is the transition matrix through the edges with Qi,j = ( P j0 1[(i, j 0 ) 2 E]) 1, if (i, j) 2 E, and else 0.",2. Preliminaries,[0],[0]
"It is known that the stationary distribution ⇡ ⌘ p1 is the normalized degree distribution (Behrends, 2000)
⇡ > = ⇣ deg(v1) Vol(V ) , . . .",2. Preliminaries,[0],[0]
", deg(v|V |) Vol(V ) ⌘ , (3)
where deg(v) is the degree of node v, i.e., the number of all incident edges of v, and Vol(V ) = P v2V deg(v) is the sum of the degrees for all nodes in V .",2. Preliminaries,[0],[0]
"SybilRank conpensates the effect of degrees, and use the degree-normalized probability
p (i) = p",2. Preliminaries,[0],[0]
"(i) k /⇡ (i) (4)
as the ranking score, where a high ranking indicates a high probability of being an honest node.
",2. Preliminaries,[0],[0]
"Essentially, SybilRank relies on the assumption that the total number of attacking edges is bounded.",2. Preliminaries,[0],[0]
"Under this assumption, only a small fraction of the trust is propagated
through the sparse cut between the honest network and the Sybil nodes during the short random walk, while ”trust” go through the ”non-trusted” honest nodes through the dense connections within the the honest subgraph.
",2. Preliminaries,[0],[0]
Boshmaf et al. (2016) developed Integro to cope with a larger number of attacking edges.,2. Preliminaries,[0],[0]
"To this end, Integro introduces weights on the edges to bias the random walk, where the weights are determined after its pre-processing step to detect victims.",2. Preliminaries,[0],[0]
Here a victim is defined as a node that established a connection to one of the Sybil nodes.,2. Preliminaries,[0],[0]
"The set of all victim nodes is defined by Vv = {v 2 Vh : 9(v, s) 2 EA}.",2. Preliminaries,[0],[0]
"After the detection step, Integro lowers the weights to all incident edges to the detected victims, which prevents the trust to propagate through victim nodes.",2. Preliminaries,[0],[0]
"As the victims form a natural border between the honest and the Sybil graph, this reduces the overall flow of trust into the Sybil graph.",2. Preliminaries,[0],[0]
Boshmaf et al. found that traditional feature-based classification methods yield good and robust detection of victims.,2. Preliminaries,[0],[0]
"A notable advantage against the feature-based Sybil detection is that, unlike Sybils, victims generally do not behave adversarial, as they don’t have any incentive to ”hide”.",2. Preliminaries,[0],[0]
"More Realistic Assumptions
Cao et al. (2012) gave a security guarantee for SybilRank.",3. SybilRank’s Security Guarantee Under,[0],[0]
Let g := |EA| be the number of attacking edges and n := |V | be the number of all nodes in the graph.,3. SybilRank’s Security Guarantee Under,[0],[0]
their theory relies on the notion of trust leaks.,3. SybilRank’s Security Guarantee Under,[0],[0]
Definition 1.,3. SybilRank’s Security Guarantee Under,[0],[0]
(Trust leaks) Let rk0 = P i2VH p (i) k0 be the trust that remains in the honest graph after k0 random walk steps.,3. SybilRank’s Security Guarantee Under,[0],[0]
We call l = Pk k0=1(rk0+1 rk0) the absolute trust leak.,3. SybilRank’s Security Guarantee Under,[0],[0]
"Assume that the attacking edges are created randomly, following a distribution ↵(EA).",3. SybilRank’s Security Guarantee Under,[0],[0]
We call CH(k 0 ),3. SybilRank’s Security Guarantee Under,[0],[0]
"= E↵(EA)[ rk0+1 rk0 rk0
] the expected relative trust leak.
",3. SybilRank’s Security Guarantee Under,[0],[0]
CH(k 0 ) is actually a constant with respect to k0 under reasonable assumptions on ↵(EA).,3. SybilRank’s Security Guarantee Under,[0],[0]
The following lemma has been proved: Lemma 1.,3. SybilRank’s Security Guarantee Under,[0],[0]
"(Cao et al., 2012) Assume that the graph G is created randomly, following the configuration model (Molloy & Reed, 1995).",3. SybilRank’s Security Guarantee Under,[0],[0]
"Then, the expected relative trust leak in each iteration is given by CH = gvol(VH) .
",3. SybilRank’s Security Guarantee Under,[0],[0]
This leads to a theoretical guarantee of SybilRank.,3. SybilRank’s Security Guarantee Under,[0],[0]
Theorem 1.,3. SybilRank’s Security Guarantee Under,[0],[0]
"(Cao et al., 2012) Assume that the graph G is created randomly, following the configuration model.",3. SybilRank’s Security Guarantee Under,[0],[0]
The total number of Sybils that are ranked higher than nonSybils by SybilRank is O(g log n).,3. SybilRank’s Security Guarantee Under,[0],[0]
"Theorem 1 implies good performance of SybilRank, but
it holds under the assumption that the attacking edges are created in the same process as the honest graph,1 which is not realistic.
",3. SybilRank’s Security Guarantee Under,[0],[0]
"Below, we show that the same guarantee is obtained under the following more realistic assumption: Assumption 1.",3. SybilRank’s Security Guarantee Under,[0],[0]
"The graph G is constructed by the following steps:
1.",3. SybilRank’s Security Guarantee Under,[0],[0]
"Honest graph GH construction: GH is connected, nonbipartite, and scale free, i.e., the degree distribution follows the power law distribution.
",3. SybilRank’s Security Guarantee Under,[0],[0]
2.,3. SybilRank’s Security Guarantee Under,[0],[0]
"Sybil graph GS construction: The topology of GS is arbitrary.
",3. SybilRank’s Security Guarantee Under,[0],[0]
3.,3. SybilRank’s Security Guarantee Under,[0],[0]
Attacking edges EA generation:,3. SybilRank’s Security Guarantee Under,[0],[0]
"The attacking edges are genarated on all possible edges EA ⇢ VS ⇥ VH between the honest and the Sybil subgraphs with equal propability.
",3. SybilRank’s Security Guarantee Under,[0],[0]
"Under Assumption 1, evaluating the expected trust leak is less straightforward.",3. SybilRank’s Security Guarantee Under,[0],[0]
"Nevertheless, we can show that it results in the same formal security guarantee stated in Theorem 1.
",3. SybilRank’s Security Guarantee Under,[0],[0]
"To properly compute the expected trust leak, the following random variables are defined.",3. SybilRank’s Security Guarantee Under,[0],[0]
"Xv counts the number of attacking edges incident to node v, Yv = ⇡(v)
",3. SybilRank’s Security Guarantee Under,[0],[0]
"Xv deg(v,GH)+Xv = ⇡(v) Xv deg(v,G) is the trust leak in node
v and Z = P
",3. SybilRank’s Security Guarantee Under,[0],[0]
v2VH Yv is the total trust leak.,3. SybilRank’s Security Guarantee Under,[0],[0]
Note that here ⇡(v) is the current amount of trust in node v and not the stationary distribution of the random walk.,3. SybilRank’s Security Guarantee Under,[0],[0]
This notation is used to avoid confusion with the probability mass function denoted by P .,3. SybilRank’s Security Guarantee Under,[0],[0]
"From Assumption 1 it follows that Xv is hypergeometrically distributed (Tuckwell, 1995) with the following parameters: the population size: N = |VH⇥VS |, successes: K = |{v}⇥ VS |, and the draws n = |EA|.",3. SybilRank’s Security Guarantee Under,[0],[0]
Let g := |EA| be the number of attacking edges.,3. SybilRank’s Security Guarantee Under,[0],[0]
"Moreover, let nH := |VH",3. SybilRank’s Security Guarantee Under,[0],[0]
| and nS,3. SybilRank’s Security Guarantee Under,[0],[0]
":= |VS | denote the number of honest nodes and Sybil nodes, respectively.
",3. SybilRank’s Security Guarantee Under,[0],[0]
"The probability mass function of Xv is given by P (Xv =
k) =
✓ K
k ◆✓ N K n k ◆ / ✓ N n",3. SybilRank’s Security Guarantee Under,[0],[0]
◆,3. SybilRank’s Security Guarantee Under,[0],[0]
"and according to Tuckwell
(1995), its expected value can be computed by E[Xv] = n
K N = |EA| |{v}⇥VS ||VH⇥VS | = |EA| |VH",3. SybilRank’s Security Guarantee Under,[0],[0]
"| = g nH
.",3. SybilRank’s Security Guarantee Under,[0],[0]
"The final goal is to compute the expected value of Z. The linearity of the expected value yields E[Z] =
P v2VH E[Yv] and for the
expected value of Yv we get
E[Yv] = ⇡(v)deg(v,G) P1 k=0 kP (Xv = k)
= ⇡(v) deg(v,G)E[Xv] = ⇡(v) deg(v,G) g nH .
",3. SybilRank’s Security Guarantee Under,[0],[0]
"1This assumption is not explicitly stated in Cao et al. (2012), but apparent from their derivation.
",3. SybilRank’s Security Guarantee Under,[0],[0]
"Using this result, the expected value of Z becomes E[Z]",3. SybilRank’s Security Guarantee Under,[0],[0]
"=P v2VH E[Yv] = g nH P v2VH ⇡(v) deg(v,G) , where the right hand side still contains a sum that needs to be evaluated individually for each node to compute its actual value.",3. SybilRank’s Security Guarantee Under,[0],[0]
"In order to “average out” this sum, we rely on the assumption that the honest nodes GH is power law-distributed (Barabási, 2009).",3. SybilRank’s Security Guarantee Under,[0],[0]
"To do this, a new random variable Dv is introduced which measures the degree of v. Then, the assumption results in the probability of a node having a degree of d being P (Dv = d) =",3. SybilRank’s Security Guarantee Under,[0],[0]
"d
⇣( ) , where ⇣ is the Riemann zeta function ⇣(s) := P1 n=0 n s (Barabási, 2009).
",3. SybilRank’s Security Guarantee Under,[0],[0]
"With this expression, it is possible to “average out” the exact topology of the graph by computing the expected value with respect to the newly defined random variable Dv:
E[Z] =",3. SybilRank’s Security Guarantee Under,[0],[0]
gnH P1 d=1 P v2VH ⇡(v) d P,3. SybilRank’s Security Guarantee Under,[0],[0]
(,3. SybilRank’s Security Guarantee Under,[0],[0]
"Dv = d)
= g nH P v2VH ⇡(v) P1 d=1 1 d d ⇣( )
= g nH P v2VH ⇡(v) ⇣( ) P1 d=1 d ( +1)
",3. SybilRank’s Security Guarantee Under,[0],[0]
= g nH ⇣( +1) ⇣,3. SybilRank’s Security Guarantee Under,[0],[0]
"( ) P v2VH ⇡(v).| {z }
Total trust in the honest graph
This yields the following lemma.",3. SybilRank’s Security Guarantee Under,[0],[0]
Lemma 2.,3. SybilRank’s Security Guarantee Under,[0],[0]
"Under Assumption 1 the expected relative trust leak in each iteration of the random walk is given by
˜ CH = g
nH ⇣( +1) ⇣( )| {z } =:e
where e < 1 is a constant that depends on the parameter of the assumed power law distribution for the degree distribution.
",3. SybilRank’s Security Guarantee Under,[0],[0]
"Although Lemma 2 gives a different expected relative trust leak from Lemma 1, the fact that the maximum number of connection for each node is bounded in every OSN and therefore O(nH) = O(vol(VH)) leads to the same asymptotic behavior as Theorem 2: Theorem 2.",3. SybilRank’s Security Guarantee Under,[0],[0]
"Under Assuption 1, the total number of Sybils that are ranked higher than non-Sybils by SybilRank is O(g log n).",3. SybilRank’s Security Guarantee Under,[0],[0]
"This result explicitly shows that, asymptotically, SybilRank’s security guarantee remains unchanged even under more realistic Assumption 1.",3. SybilRank’s Security Guarantee Under,[0],[0]
"In this section, we discuss adversarial strategies against graph-based Sybil detection methods.
",4. Adversarial Strategies,[0],[0]
"Attacker’s Action Although attackers in general can take variety of actions, we restricts their action to adding attacking edges.
",4. Adversarial Strategies,[0],[0]
Definition 2 (Attacking strategy).,4. Adversarial Strategies,[0],[0]
"Given an honest graph GH and a Sybil graph GS , an attacking strategy describes the set of attacking edges established by the intruder.
",4. Adversarial Strategies,[0],[0]
"The cost of action is measured by the number of attacking edges.
",4. Adversarial Strategies,[0],[0]
"Attacker’s Knowledge Generally, we focus on adversarial attacks against random walk based approaches.",4. Adversarial Strategies,[0],[0]
"That is, an attacker’s strategy for establishing edges from Sybil nodes to honest nodes in order to cloak an attacker’s Sybil sub-network.",4. Adversarial Strategies,[0],[0]
"For analysis, we assume different levels of knowledge that the attacker has on the defender’s strategy and information:
A.1 Strategy only.
",4. Adversarial Strategies,[0],[0]
"A.2 Strategy + topology.
",4. Adversarial Strategies,[0],[0]
"A.3 Strategy + topology + trusted nodes (positively labeled nodes).
",4. Adversarial Strategies,[0],[0]
"B.1 Strategy + topology + trusted nodes (positively labeled nodes) + untrusted nodes (negatively labeled nodes).
",4. Adversarial Strategies,[0],[0]
"Here, we divided the level of access to inside information for the attacker into two groups.",4. Adversarial Strategies,[0],[0]
"In group A (i.e., A.1, A.2, A.3) attackers are able to gather sophisticated information based on publicly available sources, whereas in group B (i.e., B.1) either some back-channel provides non-public information (e.g. defender marked Sybil nodes based on their analysis), or, the attackers are provided with all information visible to the defenders.
",4. Adversarial Strategies,[0],[0]
"Clearly, it is too hard, if not impossible, to have an out-ofthe-box solution for the setting described in group B and we therefore resort our analysis on the settings in group A.",4. Adversarial Strategies,[0],[0]
"In the first case (A.1), no efficient adversarial strategies for graph-based random walk approaches is possible.",4. Adversarial Strategies,[0],[0]
The attackers must build up sufficient attacking edges to trusted nodes in order to absorb enough trust.,4. Adversarial Strategies,[0],[0]
"In A.3 (and A.2 as a special case) on the other hand, the attacker gained enough information to guide the creation of attacking edges efficiently.",4. Adversarial Strategies,[0],[0]
This paper focuses on this most interesting situation.,4. Adversarial Strategies,[0],[0]
"More specifically, we assume the following: the intruder knows defender’s strategy (algorithm details), the topology of the honest graph, and the set of trusted nodes, i.e., she knows about GH = (VH , EH) and VT .",4. Adversarial Strategies,[0],[0]
Based on that knowledge the intruder can establish attacking edges to honest nodes of her choice with the goal to create an attacking scenario where the applied defense method fails.,4. Adversarial Strategies,[0],[0]
"Although the exact topology of the Sybil graph is not specified any further, for the following results it is assumed that it is designed in a way that suits the intruder well.
",4. Adversarial Strategies,[0],[0]
"Attacker’s Goal Attackers can have various final goals, e.g., spamming honest users to earn money, feeding wrong information to honest nodes, stealing nonpublic information, damaging countries/companies, etc.",4. Adversarial Strategies,[0],[0]
"Depending on the goal, the objective of the optimal strategy can differ.",4. Adversarial Strategies,[0],[0]
"We assume that attacker’s try to maximize their influence and hence, have an inherent need to increase the number of attacking edges.
",4. Adversarial Strategies,[0],[0]
"Random-walk based approaches such as SybilRank and Integro rely on the fact that the absolute trust leak l from the honest graph to the Sybil graph is small (i.e., below the amount needed to reach the stationary distribution within the Sybil sub-graph) which ensures low trust scores for the Sybil nodes.",4. Adversarial Strategies,[0],[0]
"However, if enough trust is being propagated to the Sybil graph, trust values will be close to the stationary distribution in the Sybil graph as well as in the honest graph.",4. Adversarial Strategies,[0],[0]
"Consequently, the degree-normalized ranking values will be similar to the ones in the honest graph, which makes Sybil nodes indistinguishable from honest nodes and therefore disables the detector.",4. Adversarial Strategies,[0],[0]
Definition 3 (Disabling Attacking Strategy).,4. Adversarial Strategies,[0],[0]
Let GH and GS be the honest graph and the Sybil graph.,4. Adversarial Strategies,[0],[0]
Let l : 2E !,4. Adversarial Strategies,[0],[0]
R be the absolute trust leak as a function of an attacking strategy.,4. Adversarial Strategies,[0],[0]
"Then, an attacking strategy EA ⇢ VH ⇥",4. Adversarial Strategies,[0],[0]
"VS is said to be disabling if
l(EA)",4. Adversarial Strategies,[0],[0]
"td, (5) where td is the disabling threshold, which depends on the topology of the Sybil graph and the detection algorithm.
",4. Adversarial Strategies,[0],[0]
"Surely, an attacker does not aim for just any disabling strategy but for the one that comes at the lowest cost.",4. Adversarial Strategies,[0],[0]
"As the cost of an attacking strategy is assumed to be increasing in the number of attacking edges, an optimal/minimal disabling strategy is given by the following definition.",4. Adversarial Strategies,[0],[0]
Definition 4 (Optimal Disabling Strategy).,4. Adversarial Strategies,[0],[0]
"An attacking strategy AE is said to be optimal if it is the solution to the following optimization problem:
min EA⇢VH⇥VS |EA| (6)
s. t. l(EA) td.
To solve this, the disabling threshold td and the trust leak function must be known to the attacker.",4. Adversarial Strategies,[0],[0]
"Ignoring the edge weights (which are unknown to the attacker) the amount of trust needed within the Sybil graph to reach the stationary distribution of the random walk is given by td =P
vi2VS ⇡i = vol(VS) vol(V ) .",4. Adversarial Strategies,[0],[0]
To exactly evaluate l(EA) the entire random walk needs to be simulated which is infeasible for the attacker without knowing its exact length and the edge weights.,4. Adversarial Strategies,[0],[0]
A useful estimate is to consider only the first iteration.,4. Adversarial Strategies,[0],[0]
"The computation of this value is feasible and the trust leak per attacking edge is by far the
largest in the first iteration because all the trust is concentrated in the relatively small subset of trusted nodes VT .",4. Adversarial Strategies,[0],[0]
"The trust leak in the first iteration ˜l(EA) is given by l(EA) = P v2VT (v) deg(v,GH)+(v)
, where (v) is the attacking degree (i.e., the number of attacking edges) of node v.",4. Adversarial Strategies,[0],[0]
This leads to a greedy strategy where the intruder iteratively adds those attacking edges which produce the largest increase in ˜l.,4. Adversarial Strategies,[0],[0]
In the following the term adversarial strategy/attacker refers to this greedy strategy.,4. Adversarial Strategies,[0],[0]
"In this section, we propose our new method and derive its efficient solver.",5. Proposed Method,[0],[0]
"Our method is specifically designed to cope with a large number of attacking edges by minimizing “trust leaks”, that is, minimizing a sampled trust leak by adjusting the edge weights—a missing mechanism for SybilRank and Integro.
",5. Proposed Method,[0],[0]
"Transductive Sybil Ranking Combining the approach of Backstrom & Leskovec (2011) and SybilRank (Cao et al., 2012), our proposed method, called transductive Sybil ranking (TSR), tries to leverage potential prior knowledge, negative labels, to bias a short random walk so that random walk methods work even with the existence of a large number of attacking edges.
",5. Proposed Method,[0],[0]
Assume that all nodes carry attributes and n  |V,5. Proposed Method,[0],[0]
"| nodes are additionally attached with label information, i.e., the defender knows a subset of nodes are honest, and another subset of nodes are sybil.",5. Proposed Method,[0],[0]
"More formally, the defender is given labeled nodes L := {(xi, yi) 2 X ⇥",5. Proposed Method,[0],[0]
"{+1, 1}}ni=1 and unlabeled nodes U := {xi 2 X}|V |i=n+1.",5. Proposed Method,[0],[0]
"Since only the honest nodes can be trusted, VT ✓ {vi 2 V ; yi = +1} holds.
",5. Proposed Method,[0],[0]
"We define an edge feature function u,v between nodes u and v as u,v : X ⇥ X !",5. Proposed Method,[0],[0]
Y .,5. Proposed Method,[0],[0]
"A corresponding parameterized, non-negative scoring function fw : Y !",5. Proposed Method,[0],[0]
"R+ is learned during training and applied as edge weight au,v = fw( u,v) in the weighted adjacency matrix Q 2 R|V |⇥|V",5. Proposed Method,[0],[0]
"|:
Qu,v =
( au,vP x au,x
if (u, v) 2 E, 0 otherwise.
(7)
",5. Proposed Method,[0],[0]
"Throughout our experiments, we restrict ourselves to the following differentiable edge feature function:
fw( u,v) =",5. Proposed Method,[0],[0]
"(1 exp( w> u,v))",5. Proposed Method,[0],[0]
1.,5. Proposed Method,[0],[0]
"(8) Once the transition matrix is fixed, The remaining procedure is the same as SybilRank.",5. Proposed Method,[0],[0]
"Namely, starting form the initial distribution (1), k-steps random walk (2) is applied with the transition matrix (7).",5. Proposed Method,[0],[0]
"After that, the degreenormalized ranking probability (4) is used for classification.",5. Proposed Method,[0],[0]
"However, we are also given negatively labeled nodes,
which are used to train the parameter w of the edge feature function (8), so that p(i) < p(j), 8 i, j 2 {1, . . .",5. Proposed Method,[0],[0]
", n} with yi = 1 and yj = +1.",5. Proposed Method,[0],[0]
"In the spirit of regularized risk minimization (Vapnik, 1999), this problem is formalized as follows:
Definition 5 (TSR optimization problem).",5. Proposed Method,[0],[0]
"TSR solves a quadratically regularized, non-convex optimization problem with generic loss-functions h :",5. Proposed Method,[0],[0]
"[0, 1]⇥{+1, 1} !",5. Proposed Method,[0],[0]
"R:
minimize w F (w) =
2
kwk2 + nX
i=1
h(p (i) (w), yi) .",5. Proposed Method,[0],[0]
"(9)
Using the notion of p(i)(w) visually indicates that node ranking probabilities p are (non-linearly) dependent on the parameter vector w.",5. Proposed Method,[0],[0]
"As for the choice of loss-functions, we examine the following:
• Wilcoxon-Mann-Whitney (WMW) loss (Yan et al., 2003).",5. Proposed Method,[0],[0]
"WMW maximizes the area under the ROC curve:
h(p, y) =
nX
j=1
1[y = +1^yj = 1] ⇣ 1 + exp p pjb ⌘ 1 .
",5. Proposed Method,[0],[0]
"• Smooth hinge-loss variant A smooth variant of the classical support vector machine hinge-loss with two additional parameters: a decision boundary b 2 R and a scaling parameter a 2 R:
h(p, y) =
8 ><
>: 1 2 y(ap b) if y(ap b)  0, 1 2 (1 y(ap b))2 if 0 < y(ap b)  1, 0 if 1 < y(ap b).
",5. Proposed Method,[0],[0]
"In this work, we focus on smooth, differentiable lossfunctions only, ensuring fast convergence to local optima via gradient-based methods, i.e., fast second-order methods (BFGS).",5. Proposed Method,[0],[0]
"A pivotal point is hence, to assess the gradient w.r.t.",5. Proposed Method,[0],[0]
"w.
Gradient Computation The remaining of this section is dedicated to the derivation of the gradient:
",5. Proposed Method,[0],[0]
"@F (w) @w = @ kwk2 @2w + Pn i @h(p(i)(w),yi) @w ,
where the loss-function h can be further split into @h(p(i)(w),yi)
@w = @h(p(i)(w),yi) @p(i)(w) @p(i)(w) @w .",5. Proposed Method,[0],[0]
"Since we con-
strained ourselves to differentiable loss-function h(p, y), the partial derivative w.r.t.",5. Proposed Method,[0],[0]
p can be calculated rather straightforward.,5. Proposed Method,[0],[0]
"More complicated is the evaluation of
@p(i)
",5. Proposed Method,[0],[0]
@w = @ @w p(i)k,5. Proposed Method,[0],[0]
⇡(i) =,5. Proposed Method,[0],[0]
✓ @p(i)k @w ⇡ (i) p(i)k @⇡ (i) @w ◆ ⇡ (i) 2 .,5. Proposed Method,[0],[0]
"(10)
The derivative of the i-th component of ⇡ is given by:
@⇡(i)
@w =
⇣ @deg⇤(vi) @w vol(V ) @vol(V )@w deg⇤(vi) ⌘ vol(V ) 2,
where @deg ⇤(vi) @w = P e2E vi2e @ae @w = P e2E vi2e @fw( e) @w and @vol(V )",5. Proposed Method,[0],[0]
@w = 2 P e2E @ae @w = 2 P e2E @fw( e) @w .,5. Proposed Method,[0],[0]
As fw is said to be differentiable the only part of Eq.,5. Proposed Method,[0],[0]
"(10) that remains is the Jacobian @pk/@w.
Theorem 3.",5. Proposed Method,[0],[0]
"The derivative @pk/@w for k 1 is given by:
@pk",5. Proposed Method,[0],[0]
@w = ✓ k 1P l=0 plQ k 1 l ◆ @Q @w .,5. Proposed Method,[0],[0]
"(11)
(the proof is given in Appendix A).",5. Proposed Method,[0],[0]
"The derivative of Q, defined in Eq.",5. Proposed Method,[0],[0]
"(7), is given by
@Quv @w =
8 <
:
@auv",5. Proposed Method,[0],[0]
@w P x aux auv P x @aux,5. Proposed Method,[0],[0]
"@w
( P x aux) 2",5. Proposed Method,[0],[0]
"if (u, v) 2 E, 0 otherwise.
",5. Proposed Method,[0],[0]
"This completes the computation of the gradient and enables the application of gradient-based methods, i.e., BFGS to find a (locally) optimal estimate ŵ.",5. Proposed Method,[0],[0]
"By using this estimate, TSR weights the whole graph, with which a short random walk is performed to obtain the final ranking p.
Robustness of TSR against Attacks By using the negative label information, our TSR, in principle, monitors “trust leak” through random walk, and adjusts the edge weights so that the leak is minimized.",5. Proposed Method,[0],[0]
"As a result, the weights tend to be lower on the attacking edges (to reduce the propagation), and higher on the Sybil edges (to boost the stationary distribution).",5. Proposed Method,[0],[0]
"Thus, we can expect that our TSR, which is an advanced integrated method, is more robust against attacks than the SybilRank and the two-step Integro approach.",5. Proposed Method,[0],[0]
"To assess the robustness of the proposed method and the baseline methods, we generate artificially network topology and edge and node attributes in order to have full control of the underlying ground truth.",6. Empirical Evaluation on Synthetic Data,[0],[0]
"We separately create two graphs, the honest and the Sybil graph.",6. Empirical Evaluation on Synthetic Data,[0],[0]
Both use the generation method proposed by Holme & Kim (2002) for scale free networks.,6. Empirical Evaluation on Synthetic Data,[0],[0]
Node features are generated randomly and correlated through dependency injection.,6. Empirical Evaluation on Synthetic Data,[0],[0]
"The edge features function u,v simply stacks node features of the two adjacent nodes xu",6. Empirical Evaluation on Synthetic Data,[0],[0]
and,6. Empirical Evaluation on Synthetic Data,[0],[0]
xv (see Appendix B for more details).,6. Empirical Evaluation on Synthetic Data,[0],[0]
"Connections between Sybil and honest graphs are established according to a random attacking strategy that iteratively adds attacking edges randomly, i.e., equally distributed on the set of all possible attacking edges VH ⇥",6. Empirical Evaluation on Synthetic Data,[0],[0]
"VS
or a adversarial attacking strategy that solves Problem (6) for optimal attacks.",6. Empirical Evaluation on Synthetic Data,[0],[0]
This strategy only chooses an honest node to be attacked next and the corresponding Sybil node is chosen randomly (equally distributed on the set of all Sybil nodes VS).,6. Empirical Evaluation on Synthetic Data,[0],[0]
"We test our method, TSR, using the proposed loss functions and compare against the stateof-the-art methods SybilRank and Integro.",6. Empirical Evaluation on Synthetic Data,[0],[0]
"As Integro depends on a preceding victim prediction, we simulated one that achieves highest possible rankings (ROC-AUC close to 1.0).2
Random Attacking Strategy We generated a sample network (|VH | = 200 and |VS | = 30) and select 15 honest nodes and 8 Sybil nodes randomly, which will be used as labeled examples for our TSR.",6. Empirical Evaluation on Synthetic Data,[0],[0]
The labeled honest nodes are also used as the set VT of trusted seeding nodes for the random walks in all methods.,6. Empirical Evaluation on Synthetic Data,[0],[0]
We evaluate the performance in terms of ROC-AUC-values for the computed ranking.,6. Empirical Evaluation on Synthetic Data,[0],[0]
This procedure was repeated 20 times for varying number of attacking edges (10-200 edges).,6. Empirical Evaluation on Synthetic Data,[0],[0]
Figure 1 shows ROC-AUC curves for all methods under the random attacking setting.,6. Empirical Evaluation on Synthetic Data,[0],[0]
"We can obsreve that our TSR, regardless of the choice of loss function, performs superior to the other methods.",6. Empirical Evaluation on Synthetic Data,[0],[0]
Integro’s accuracy deteriorates fast but still has an edge over SybilRank up to the point where the ROCAUC-value reaches 0.5.,6. Empirical Evaluation on Synthetic Data,[0],[0]
"After that SybilRank and Integro essentially perform similar.
",6. Empirical Evaluation on Synthetic Data,[0],[0]
"Adversarial Attacking Strategy For the adversarial setting, we ran the same benchmarks but this time attacking edges were added according to the adversarial attacking strategy.",6. Empirical Evaluation on Synthetic Data,[0],[0]
"Due to the much more aggressive setting, we varied the number of attacking edges from 1-40 and repeated this procedure 20 times to report averaged ROCAUC accuracies.",6. Empirical Evaluation on Synthetic Data,[0],[0]
The results are depicted in Figure 2.,6. Empirical Evaluation on Synthetic Data,[0],[0]
All choices of loss functions outperform SybilRank and Integro clearly.,6. Empirical Evaluation on Synthetic Data,[0],[0]
The results confirm our considerations that SybilRank’s performance drops fast and steep as soon as a certain amount of attacking edges is established.,6. Empirical Evaluation on Synthetic Data,[0],[0]
"Integro behaves more robust than SybilRank, but, ultimately, must resign after a few more attacking edges.",6. Empirical Evaluation on Synthetic Data,[0],[0]
"Again, our TSR is significantly more robust against adversarial attacks and can withstand higher number of attacking edges until its performance finally deteriorates.",6. Empirical Evaluation on Synthetic Data,[0],[0]
We also evaluated our method on a sample of the Facebook graph Leskovec & Mcauley collected from survey participants using the Facebook app.,7. Empirical Evaluation on Real-world Data,[0],[0]
"The dataset includes the topology (|V | = 4039 users and |E| = 88234 friend-
2SybiRank, Integro, and TSR rely on different information, and therefore, the fairness of comparison is not trivial.",7. Empirical Evaluation on Real-world Data,[0],[0]
"We discuss this issue in Appendix C.
ships) as well as node features for every node (see Table 1 for summary), Figure 3).",7. Empirical Evaluation on Real-world Data,[0],[0]
"Node features are comprised of obfuscated categorical features of users profiles including education, work, hometown, language, last name, etc.",7. Empirical Evaluation on Real-world Data,[0],[0]
"As with most of real world social graphs, the data exhibits strong multi-cluster structure, as seen in Figure 3 and Figure 4.",7. Empirical Evaluation on Real-world Data,[0],[0]
"These clusters pose additional challenges to the application of random walk-based methods as the trust propagation between two loosely inter-connected clusters is low (Cao et al., 2012; Boshmaf et al., 2016).",7. Empirical Evaluation on Real-world Data,[0],[0]
"Hence, trust seeds should be distributed among all clusters.",7. Empirical Evaluation on Real-world Data,[0],[0]
"Following SybilRank and Integro (Cao et al., 2012), we employ the Louvian clustering method (Blondel et al., 2008) first.
",7. Empirical Evaluation on Real-world Data,[0],[0]
"As common, the Sybil graph needs to be generated.",7. Empirical Evaluation on Real-world Data,[0],[0]
"For this purpose, a (small) subgraph was copied and declared as Sybil.",7. Empirical Evaluation on Real-world Data,[0],[0]
The attacking edges were created to link the honest and the Sybil graph following one of the attacking strategies (random or adversarial).,7. Empirical Evaluation on Real-world Data,[0],[0]
It was made sure that no Sybil node attacked one of the direct neighbors of its origin which is reasonable for most social graphs.,7. Empirical Evaluation on Real-world Data,[0],[0]
"Edge features
for TSR are as follows: the number of shared features (in total), the number of shared friends, and the number of shared features within specific categories.",7. Empirical Evaluation on Real-world Data,[0],[0]
"The other experimental setup is the same as the previous section.
",7. Empirical Evaluation on Real-world Data,[0],[0]
Random Attacks,7. Empirical Evaluation on Real-world Data,[0],[0]
The trusted nodes |VT,7. Empirical Evaluation on Real-world Data,[0],[0]
| = 50 were randomly distributed among all clusters and a small subset of Sybils |VD| = 30 was chosen as known Sybil nodes.,7. Empirical Evaluation on Real-world Data,[0],[0]
Attacking edges EA were established following the random attacking strategy ranging from |EA| = 1 to |EA| = 1400.,7. Empirical Evaluation on Real-world Data,[0],[0]
Experiments were repeated 10 times.,7. Empirical Evaluation on Real-world Data,[0],[0]
"Integro was run with
sarial attacking scenario on the Facebook graph.
",7. Empirical Evaluation on Real-world Data,[0],[0]
"two levels of accuracy in simulated victim detection, i.e., perfect (AUROC = 1) and almost perfect (AUROC = 0.9).",7. Empirical Evaluation on Real-world Data,[0],[0]
Figure 5 shows the AUROC-values.,7. Empirical Evaluation on Real-world Data,[0],[0]
The detection performance of SybilRank is the lowest and drops soon as attacking edges increase.,7. Empirical Evaluation on Real-world Data,[0],[0]
"Integro with the perfect victim detection outperforms the other methods, but with just a slight reduction in the victim detection accuracy (AUROC = 0.9), its performance drops significantly.",7. Empirical Evaluation on Real-world Data,[0],[0]
All versions of TSR perform almost on par with perfect version of Integro in the lower range of attacking edges (1—800).,7. Empirical Evaluation on Real-world Data,[0],[0]
"In the higher range (800—1400), the hinge loss drop fast to end up with a performance similar to Integro with the almost perfect victim detection.",7. Empirical Evaluation on Real-world Data,[0],[0]
"However, the variant that uses the WMW-loss does not show this performance drop and stays close to the upper-bound of Integro.
",7. Empirical Evaluation on Real-world Data,[0],[0]
Adversarial Attacks The number of adversarial attack edges ranged from |EA| = 1 to |EA| = 45.,7. Empirical Evaluation on Real-world Data,[0],[0]
"Figure 6 shows
the recorded average AUROC-values.",7. Empirical Evaluation on Real-world Data,[0],[0]
"Again, SybilRank’s performance drops the fastest and steepest and Integro is insignificantly better in this adversarial scenario.",7. Empirical Evaluation on Real-world Data,[0],[0]
Both variants of TSR performs better than the baselines.,7. Empirical Evaluation on Real-world Data,[0],[0]
"However, the WMW-loss variant performs only slightly better than SybilRank and Integro, while the hinge-loss variant keeps good performance even for a large number of attacking edges.",7. Empirical Evaluation on Real-world Data,[0],[0]
"As our future work, we will investigate which loss function should be chosen, depending on data and assumed attacker’s strategy.",7. Empirical Evaluation on Real-world Data,[0],[0]
"Overall, whereas SybilRank’s and Integro’s performance drops to an average AUROC-value below 0.5 at |EA| = 30, the hinge-loss variant of TSR still achieves an average value over 0.9 at the same amount of attacking edges.",7. Empirical Evaluation on Real-world Data,[0],[0]
"In this paper, we studied the problem of Sybil detection.",8. Conclusion & Outlook,[0],[0]
We first refined the security guarantees of random walk approaches towards more realistic assumptions.,8. Conclusion & Outlook,[0],[0]
"Then, we formalized and coined the adversarial setting and introduced optimal strategies for attackers.",8. Conclusion & Outlook,[0],[0]
"Further, we proposed a new method, transductive Sybil ranking (TSR), that leverages prior information, network topology as well as node and edge features.",8. Conclusion & Outlook,[0],[0]
"Unlike Integro, it is fused in a single optimization framework and can be solved efficiently by using gradient-based optimizer.",8. Conclusion & Outlook,[0],[0]
"In our empirical evaluation, we showed the advantages of our method and investigated the susceptibility of our method and baseline competitors to adversarial attacks.",8. Conclusion & Outlook,[0],[0]
"Further research will focus on the application of our method to real-world, large-scale OSNs.",8. Conclusion & Outlook,[0],[0]
"JH was supported by MathPlan GmbH and innoCampus, TU-Berlin.",9. Acknowledgments,[0],[0]
"SN, AB and KRM were supported by the German Ministry for Education and Research as Berlin Big Data Center BBDC, funding mark 01IS14013A. KRM thanks for the Institute for Information & Communications Technology Promotion (IITP) grant funded by the Korea government (No.2017-0-00451).",9. Acknowledgments,[0],[0]
NG was supported by BMBF ALICE II grant 01IB15001B.,9. Acknowledgments,[0],[0]
Sybil detection is a crucial task to protect online social networks (OSNs) against intruders who try to manipulate automatic services provided by OSNs to their customers.,abstractText,[0],[0]
"In this paper, we first discuss the robustness of graph-based Sybil detectors SybilRank and Integro and refine theoretically their security guarantees towards more realistic assumptions.",abstractText,[0],[0]
"After that, we formally introduce adversarial settings for the graph-based Sybil detection problem and derive a corresponding optimal attacking strategy by exploitation of trust leaks.",abstractText,[0],[0]
"Based on our analysis, we propose transductive Sybil ranking (TSR), a robust extension to SybilRank and Integro that directly minimizes trust leaks.",abstractText,[0],[0]
Our empirical evaluation shows significant advantages of TSR over stateof-the-art competitors on a variety of attacking scenarios on artificially generated data and realworld datasets.,abstractText,[0],[0]
Minimizing Trust Leaks for Robust Sybil Detection,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1379–1388, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
Deep inference on a large-scale knowledge base (KB) needs a mass of formulas, but it is almost impossible to create all formulas manually. Data-driven methods have been proposed to mine formulas from KBs automatically, where random sampling and approximate calculation are common techniques to handle big data. Among a series of methods, Random Walk is believed to be suitable for knowledge graph data. However, a pure random walk without goals still has a poor efficiency of mining useful formulas, and even introduces lots of noise which may mislead inference. Although several heuristic rules have been proposed to direct random walks, they do not work well due to the diversity of formulas. To this end, we propose a novel goaldirected inference formula mining algorithm, which directs random walks by the specific inference target at each step. The algorithm is more inclined to visit benefic structures to infer the target, so it can increase efficiency of random walks and avoid noise simultaneously. The experiments on both WordNet and Freebase prove that our approach is has a high efficiency and performs best on the task.",text,[0],[0]
"Recently, various knowledge bases (KBs), such as Freebase (Bollacker et al., 2008), WordNet (Miller, 1995), Yago (Hoffart et al., 2013), have been built, and researchers begin to explore how to make use of structural information to promote performances of several inference-based NLP applications, such as
text entailment, knowledge base completion, question and answering.",1 Introduction,[0],[0]
"Creating useful formulas is one of the most important steps in inference, and an accurate and high coverage formula set will bring a great promotion for an inference system.",1 Introduction,[0],[0]
"For example, Nationality(x, y) ∧ Nationality(z, y) ∧ Language(z, w)⇒ Language(x, w) is a high-quality formula, which means people with the same nationality probably speak the same language.",1 Introduction,[0],[0]
"However, it is a challenge to create formulas for open-domain KBs, where there are a great variety of relation types and it is impossible to construct a complete formula set by hand.
",1 Introduction,[0],[0]
"Several data-driven methods, such as Inductive Logic Programming (ILP) (Muggleton and De Raedt, 1994) and Markov Logic Network (MLN) (Richardson and Domingos, 2006), have been proposed to mine formulas automatically from KB data, which transform frequent sub-structures of KBs, e.g., paths or loops, into formulas.",1 Introduction,[0],[0]
"Figure 1.a shows a sub-graph extracted from Freebase, and the formula mentioned above about Language can be generated from the loop in Figure 1.d.",1 Introduction,[0],[0]
"However, the running time of these traditional probabilistic inference methods is unbearable over large-scale KBs.",1 Introduction,[0],[0]
"For example, MLN needs grounding for each candidate formula, i.e., it needs to enumerate all paths.",1 Introduction,[0],[0]
"Therefore, the computation complexity of MLN increases exponentially with the scale of a KB.
",1 Introduction,[0],[0]
"In order to handle large-scale KBs, the random walk is usually employed to replace enumerating all possible sub-structures.",1 Introduction,[0],[0]
"However, random walk is inefficient to find useful structures due to its completely randomized mechanism.",1 Introduction,[0],[0]
"For example in Fig-
1379
ure 1.b, the target path (yellow one) has a small probability to be visited, the reason is that the algorithm may select all the neighboring entity to transfer with an equal probability.",1 Introduction,[0],[0]
"This phenomenon is very common in KBs, e.g., each entity in Freebase has more than 30 neighbors in average, so there will be about 810,000 paths with length 4, and only several are useful.",1 Introduction,[0],[0]
"There have been two types of methods proposed to improve the efficiency of random walks, but they still meet serious problems, respectively.",1 Introduction,[0],[0]
1),1 Introduction,[0],[0]
Increasing rounds of random walks.,1 Introduction,[0],[0]
"More rounds of random walks will find more structures, but it will simultaneously introduce more noise and thus generate more false formulas.",1 Introduction,[0],[0]
"For example, the loop in Figure 1.c exists in Freebase, but it produces a false formula, Gender(x, y) ∧ Gender(z, y) ∧ Language(z, w)⇒ Language(x, w), which means people with the same gender speak the same language.",1 Introduction,[0],[0]
"This kind of structures frequently occur in KBs even the formulas are mined with a high confidence, because there are a lot of sparse structures in KBs which will lead to inaccurate confidence.",1 Introduction,[0],[0]
"According to our statistics, more than 90 percent of high-confidence formulas produced by random walk are noise.",1 Introduction,[0],[0]
2),1 Introduction,[0],[0]
Employing heuristic rules to direct random walks.,1 Introduction,[0],[0]
"This method directs random walks to find useful structures by rewriting the state transition probability matrix, but the artificial heuristic rules may only apply to a little part of formulas.",1 Introduction,[0],[0]
"For example, PRA (Lao and Cohen, 2010; Lao et al., 2011) assumes the more narrow distributions of elements in a formula are, the higher score the formula will obtain.",1 Introduction,[0],[0]
"However, formulas with high scores in PRA are not always true.",1 Introduction,[0],[0]
"For example, the formula in Figure 1.c has a high score in PRA, but it is not true.",1 Introduction,[0],[0]
"Oppositely, formulas with low scores in PRA are not always useless.",1 Introduction,[0],[0]
"For example, the formula, Father(x, y) ∧ Father(y, z) ⇒ Grandfather(x, t), has a low score when x and y both have several sons, but it obviously is the most effective to infer Grandfather.",1 Introduction,[0],[0]
"According to our investigations, the situations are common in KBs.",1 Introduction,[0],[0]
"In this paper, we propose a Goal-directed Random Walk algorithm to resolve the above problems.",1 Introduction,[0],[0]
The algorithm employs the specific inference target as the direction at each step in the random walk process.,1 Introduction,[0],[0]
"In more detail, to achieve such a goaldirected mechanism, at each step of random walk, the algorithm dynamically estimates the potentials for each neighbor by using the ultimate goal, and assigns higher probabilities to the neighbors with higher potentials.",1 Introduction,[0],[0]
"Therefore, the algorithm is more inclined to visit structures which are beneficial to infer
the target and avoid transferring to noise structures.",1 Introduction,[0],[0]
"For example in Figure 1, when the inference target is what language a person speaks, the algorithm is more inclined to walk along Nationality edge than Gender, because Nationality has greater potential than Gender to infer Language.",1 Introduction,[0],[0]
We build a real potential function based on low-rank distributional representations.,1 Introduction,[0],[0]
The reason of replacing symbols by distributional representations is that the distributional representations have less parameters and latent semantic relationship in them can contribute to estimate potentials more precisely.,1 Introduction,[0],[0]
"In summary, the contributions of this paper are as follows.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"Compared with the basic random walk, our approach direct random walks by the inference target, which increases efficiency of mining useful formulas and has a great capability of resisting noise.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"Compared with the heuristic methods, our approach can learn the strategy of random walk automatically and dynamically adjust the strategy for different inference targets, while the heuristic methods need to write heuristic rules by hand and follow the same rule all the time.",1 Introduction,[0],[0]
"• The experiments on link prediction task prove that our approach has a high efficiency on mining formulas and has a good performance on both WN18 and FB15K datasets.
",1 Introduction,[0],[0]
"The rest of this paper is structured as follows, Section 2 introduces the basic random walk for mining formulas.",1 Introduction,[0],[0]
Section 3 describes our approach in detail.,1 Introduction,[0],[0]
The experimental results and related discussions are shown in Section 4.,1 Introduction,[0],[0]
"Section 5 introduces some related works, and finally, Section 6 concludes this paper.",1 Introduction,[0],[0]
"Mining frequent patterns from source data is a problem that has a long history, and for different specific tasks, there are different types of source data and different definitions of pattern.",2.1 Frequent Pattern Mining,[0],[0]
"Mining formulas is more like frequent subgraph mining, which employs paths or loops as frequent patterns and mines them from a KB.",2.1 Frequent Pattern Mining,[0],[0]
"For each relation type R, the algorithm enumerates paths from entity H to entity T for each triplet R(H,T ).",2.1 Frequent Pattern Mining,[0],[0]
These paths are normalized to formulas by replacing entities to variables.,2.1 Frequent Pattern Mining,[0],[0]
"For example, the loop in Figure 1.d, National-
ity(Bob, America)",2.1 Frequent Pattern Mining,[0],[0]
"∧ Nationality(Stewart, America)",2.1 Frequent Pattern Mining,[0],[0]
"∧ Language(Bob, English) ⇒",2.1 Frequent Pattern Mining,[0],[0]
"Language(Stewart, English), can be normalized to the formula, Nationality(x, y) ∧ Nationality(z, y) ∧ Language(z, w) ⇒",2.1 Frequent Pattern Mining,[0],[0]
"Language(x, w).",2.1 Frequent Pattern Mining,[0],[0]
"Support and confidence are employed to estimate a formula, where the support value of a formula f : X ⇒ Y , noted as Sf , is defined as the proportion of paths in the KB which contains the body X , and the confidence value of X ⇒ Y , noted as Cf , is defined as the proportion of the paths that contains X which also meets X ⇒ Y .",2.1 Frequent Pattern Mining,[0],[0]
"Cf is calculated as follows,
Cf = Nf NX
(1)
",2.1 Frequent Pattern Mining,[0],[0]
whereNf is the total number of instantiated formula f and NX is the total number of instantiated X .,2.1 Frequent Pattern Mining,[0],[0]
Enumerating paths is a time consuming process and does not apply to large-scale KBs.,2.2 Random Walk on Knowledge Graph,[0],[0]
"Therefore, random walk on the graph is proposed to collect frequent paths instead of enumerating.",2.2 Random Walk on Knowledge Graph,[0],[0]
Random walk randomly chooses a neighbor to jump unlike enumerating which needs to search all neighbors.,2.2 Random Walk on Knowledge Graph,[0],[0]
"To estimate a formula f , the algorithm employs f ’s occurrence number during random walks N
′ f to approxi-
mate the total number Nf in Equation (1), and similarly employs N
′ X to approximate NX .",2.2 Random Walk on Knowledge Graph,[0],[0]
"Therefore,
f ’s confidence Cf can be approximatively estimated by N
′ f and N ′ X , noted as C ′ f .
",2.2 Random Walk on Knowledge Graph,[0],[0]
"Random walk maintains a state transition probability matrix P , and Pij means the probability of jumping from entity i to entity j. To make the confidence C
′",2.2 Random Walk on Knowledge Graph,[0],[0]
"f as close to the true confidence Cf as pos-
sible, the algorithm sets P as follows,
Pij = { 1/di, j ∈ Adj(i) 0, j /∈ Adj(i)",2.2 Random Walk on Knowledge Graph,[0],[0]
"(2)
where di is the out-degree of the entity i, Adj(i) is the set of adjacent entities of i, and ∑N j=1 Pij = 1.",2.2 Random Walk on Knowledge Graph,[0],[0]
Such a transition matrix means the algorithm may jump to all the neighboring entities with an equal probability.,2.2 Random Walk on Knowledge Graph,[0],[0]
"Such a random walk is independent from the inference target, so we call this type of random walk as a goalless random walk.",2.2 Random Walk on Knowledge Graph,[0],[0]
The goalless mechanism causes the inefficiency of mining useful structures.,2.2 Random Walk on Knowledge Graph,[0],[0]
"When we want to mine paths for R(H,T ), the algorithm cannot arrive at T from H
in the majority of rounds.",2.2 Random Walk on Knowledge Graph,[0],[0]
"Even though the algorithm recalls several paths for R(H,T ), some of them may generate noisy formulas for inferring R(H,T ).
",2.2 Random Walk on Knowledge Graph,[0],[0]
"To solve the above problem, several methods direct random walks by statically modifying P .",2.2 Random Walk on Knowledge Graph,[0],[0]
"For example, PRA sets Prij = P (j|i;r) |Ri| , P (j|i; r) = r(i,j) r(i,∗) , where P (j|i; r) is the probability of reaching node j from node i under the specific relation r, r(i, ∗) is the number of edges from i under r, and Ri is the number of relation types from i. Such a transition matrix implies the more narrow distributions of elements in a formula are, the higher score the formula will obtain, which can be viewed as the heuristic rule of PRA.",2.2 Random Walk on Knowledge Graph,[0],[0]
"We propose to use the inference target, ρ = R(H,T ), to direct random walks.",3.1 Goal-Directed Random Walk,[0],[0]
"When predicting ρ, our approach always directs random walks to find useful structures which may generate formulas to infer ρ.",3.1 Goal-Directed Random Walk,[0],[0]
"For different ρ, random walks are directed by modifying the transition matrix P in different ways.",3.1 Goal-Directed Random Walk,[0],[0]
"Our approach dynamically calculates Prij when jumping from entity i to entity j under relation r as follows,
",3.1 Goal-Directed Random Walk,[0],[0]
"Prij =    Φ(r(i, j), ρ)∑ k∈Adj(i) Φ(r(i, k), ρ) , j ∈ Adj(i)
0, j /∈ Adj(i)",3.1 Goal-Directed Random Walk,[0],[0]
"(3)
where Φ(r(i, j), ρ) is the r(i, j)’s potential which measures the potential contribution to infer ρ after walking to j.
Intuitively, if r(i, j) exits in a path from H to T and this path can generate a benefic formula to infer R(H,T ), the probability of jumping from i to j should larger and thus Φ(r(i, j), ρ) also should be larger.",3.1 Goal-Directed Random Walk,[0],[0]
"Reversely, if we cannot arrive at T within the maximal steps after jumping to j, or if the path produces a noisy formula leading to a wrong inference, Pij and Φ(r(i, j), ρ) should both be smaller.
",3.1 Goal-Directed Random Walk,[0],[0]
"To explicitly build a bridge between the potential Φ and the inference goal ρ, we maximize the likelihood of paths which can infer ρ.",3.1 Goal-Directed Random Walk,[0],[0]
"First, we recursively define the likelihood of a path from H to t
as PpHt = PpHs ·",3.1 Goal-Directed Random Walk,[0],[0]
"Prst , where Prst is defined in Equation (3).",3.1 Goal-Directed Random Walk,[0],[0]
"We then classify a path pHt into three separate categories: a) t = T and pHt can produce a benefic formula to infer R(H,T ); b) t 6=",3.1 Goal-Directed Random Walk,[0],[0]
T ; c) t = T but pHt may generate a noisy formula which misleads inference.,3.1 Goal-Directed Random Walk,[0],[0]
"Finally, we define the likelihood function as follows,
maxPP = ∏
pHt∈P P apHt(1− PpHt) b+c (4)
where P is all paths found in the process of performing random walks for R(H,T ), and t may be equal to T or not.",3.1 Goal-Directed Random Walk,[0],[0]
"a, b, c are three 0-1 variables corresponding to the above categories a), b), c).",3.1 Goal-Directed Random Walk,[0],[0]
"Only one in a, b, c can be 1 when PHt belongs to the corresponding category.",3.1 Goal-Directed Random Walk,[0],[0]
We then transform maximizing PP to minimizing Lrw = − logPP and employ SGD to train it.,3.1 Goal-Directed Random Walk,[0],[0]
"In practice, there is not a clear-cut boundary between a) and c), so we divide the loss into two parts:",3.1 Goal-Directed Random Walk,[0],[0]
Lrw = Ltrw + λL inf rw .,3.1 Goal-Directed Random Walk,[0],[0]
Ltrw is the loss of that t 6=,3.1 Goal-Directed Random Walk,[0],[0]
"T , and Linfrw is the loss of that pHT generates a noisy formula leading to a wrong inference.",3.1 Goal-Directed Random Walk,[0],[0]
λ is a super parameter to balance the two losses.,3.1 Goal-Directed Random Walk,[0],[0]
Ltrw and Linfrw have the same expression but are optimized in different stages.,3.1 Goal-Directed Random Walk,[0],[0]
"Ltrw can be optimized during random walks, while Linfrw should be optimized in the inference stage.",3.1 Goal-Directed Random Walk,[0],[0]
"We rewrite Lrw for a specific path p as follows,
Lrw(p) = −y logPp − (1− y) log (1− Pp) (5)
where y is the label of the path p and y = 1 if p is beneficial to infer ρ.",3.1 Goal-Directed Random Walk,[0],[0]
"To obtain the best Φ, we compute gradients of Lrw as follows,
∇Lrw(p) =",3.1 Goal-Directed Random Walk,[0],[0]
"(∇Lrw(r12),∇Lrw(r23), ...)
∇Lrw(rij)",3.1 Goal-Directed Random Walk,[0],[0]
"= ( ∂Lrw(rij) ∂Φrij , ∂Lrw(rij) ∂Φrik1 , ∂Lrw(rij) ∂Φrik2 , ...)
∂Lrw(rij)
",3.1 Goal-Directed Random Walk,[0],[0]
∂Φrij =,3.1 Goal-Directed Random Walk,[0],[0]
(Pp − y) · (1− Prij ),3.1 Goal-Directed Random Walk,[0],[0]
"Φrij · (1− Pp)
∂Lrw(rij) ∂Φrik",3.1 Goal-Directed Random Walk,[0],[0]
=,3.1 Goal-Directed Random Walk,[0],[0]
− (Pp − y) ·,3.1 Goal-Directed Random Walk,[0],[0]
"Prij
Φrij · (1− Pp) (6)
where ∇Lrw(rij) is the component of ∇Lrw(p) at rij .",3.1 Goal-Directed Random Walk,[0],[0]
"Φ(r(i,",3.1 Goal-Directed Random Walk,[0],[0]
"j), ρ) and Φ(r(i, k), ρ) are the potentials for all triplets r(i, j) ∈ p and r(i, k) /∈",3.1 Goal-Directed Random Walk,[0],[0]
"p, and rij is short for r(i, j).",3.1 Goal-Directed Random Walk,[0],[0]
"After iteratively updating Φrij and Φrik by the gradient of L t rw, the random walks can
be directed to find more paths fromH to T , and consequently it increases efficiency of the random walk.",3.1 Goal-Directed Random Walk,[0],[0]
"After updating Φrij and Φrik by the gradient ofL inf rw , random walk is more likely to find high-quality paths but not noise.",3.1 Goal-Directed Random Walk,[0],[0]
"Therefore, the goal-directed random walk increases efficiency of mining benefic formulas and has a great capability of resisting noise.",3.1 Goal-Directed Random Walk,[0],[0]
"The potential Φ(r(i, j), ρ) measures an implicit relationship between two triplets in the KB, so the total number of parameters is the square of the KB size.",3.2 Distributional Potential Function,[0],[0]
It is hard to precisely estimate all Φ because of the sparsity of training data.,3.2 Distributional Potential Function,[0],[0]
"To reduce the number of parameters, we represent each entity or relation in the KB as a low-rank numeric vector which is called embeddings (Bordes et al., 2013), and then we build a potential function Ψ on embeddings as Φ(r(i, j), ρ) = Ψ(Er(i,j), ER(H,T )), where Er(i,j) and ER(H,T ) are the embeddings of triplets.",3.2 Distributional Potential Function,[0],[0]
"In practice, we set Er(i,j) =",3.2 Distributional Potential Function,[0],[0]
"[Er, Ej ] and ER(H,T ) =",3.2 Distributional Potential Function,[0],[0]
"[ER, ET ] because Ei is the same for all triplets r(i, ∗), where [] is a concatenation operator.
",3.2 Distributional Potential Function,[0],[0]
"In the view of the neural network, our goaldirected mechanism is analogous to the attention mechanism.",3.2 Distributional Potential Function,[0],[0]
"At each step, the algorithm estimates attentions for each neighboring edges by Ψ. Therefore, there are several existing expressions of Ψ, e.g., the dot product (Sukhbaatar et al., 2015) and the single-layer perceptron (Bahdanau et al., 2015).",3.2 Distributional Potential Function,[0],[0]
"We will not compare different forms of Ψ, the detail comparison has been presented in the work (Luong et al., 2015).",3.2 Distributional Potential Function,[0],[0]
"We directly employ the simplest dot product for Ψ as follows,
Ψ(Er(i,j), ER(H,T ))",3.2 Distributional Potential Function,[0],[0]
"= σ(Er(i,j) · ER(H,T )) (7)
where σ is a nonlinear function and we set it as an exponential function.",3.2 Distributional Potential Function,[0],[0]
Ψ has no parameters beside KB embeddings which are updated during the training period.,3.2 Distributional Potential Function,[0],[0]
"To handle the dependence between goal-directed random walk and subsequent inference, we combine them into an integrated model and optimize them together.",3.3 Integrated Inference Model,[0],[0]
"To predict ρ = R(H,T ), the integrated model first collects formulas for R(H,T ), and then
Algorithm 1:",3.3 Integrated Inference Model,[0],[0]
"Train Integrated Inference Model
Input: KB, Ξ Output: Ψ, W , F 1: For ρ = R(H,T ) ∈ Ξ 2: Repeat ρ-directed Random Walk from H to t 3: Update Ψ by Ltrw 4: If t = T , then F = F ∩ fp 5: Calculate Linf and L inf rw by ρ 6: Update W by Linf 7: Update Ψ by Linfrw 8: Remove f ∈ F with little wf 9: Output Ψ, W , F
merges estimations of different formulas as features into a score function χ,
χ(ρ) =",3.3 Integrated Inference Model,[0],[0]
"∑
f∈Fρ δ(f) (8)
where Fρ is the formula set obtained by random walks for ρ, and δ(f) is an estimation of formula f .",3.3 Integrated Inference Model,[0],[0]
"The original frequent pattern mining algorithm employs formulas’ confidence as δ(f) directly, but it does not produce good results (Galárraga et al., 2013).",3.3 Integrated Inference Model,[0],[0]
"There are two ways to solve the problem: one is selecting another more suitable measure of f as δ(f) (Tan et al., 2002); the other is attaching a weight to each formula and learning weights with supervision, e.g., MLN (Richardson and Domingos, 2006) .",3.3 Integrated Inference Model,[0],[0]
We employ the latter method and set δ(f) =,3.3 Integrated Inference Model,[0],[0]
wf ·nf .,3.3 Integrated Inference Model,[0],[0]
"Finally, we employ a logistic regression classifier to predict R(H,T ), and the posterior probability of R(H,T ) is shown as follows,
P (ρ = y|χ) =",3.3 Integrated Inference Model,[0],[0]
"F(χ)y(1−F(χ))1−y
F(χ) = 1 1 + e−χ
(9)
where y is a 0-1 label of ρ.",3.3 Integrated Inference Model,[0],[0]
"Similar to Ltrw in Equation (5), we treat the negative logarithm of P (ρ = y|χ) as the loss of inference, Linf = − logP (ρ = y|χ), and turn to minimize it.",3.3 Integrated Inference Model,[0],[0]
"Moreover, the loss Linfrw of the above goal-directed random walk is influenced by the result of predicting R(H,T ), so Φrij and Φrik will be also updated.",3.3 Integrated Inference Model,[0],[0]
"Algorithm 1 shows the main process of training, where Ξ is the triplet set for training, Ψ is the potential function in Equation (7), F is the formula set, fp is
a formula generated from the path p, and H,T, t are entities in the KB.",3.3 Integrated Inference Model,[0],[0]
"To predict ρ = R(H,T ), the algorithm first performs multi rounds of random walks, and each random walk can find a path pHt (at line 2).",3.3 Integrated Inference Model,[0],[0]
"Then the algorithm decides to update Ψ by Ltrw based on whether t is T (at line 3), and adds the formula pf into the formula set when t = T (at line 4).",3.3 Integrated Inference Model,[0],[0]
"After random walks, the inference model predicts ρ, and computes Linf and L inf rw according to the prediction result (at line 5).",3.3 Integrated Inference Model,[0],[0]
"FinallyW and Ψ are updated by Linf and L inf rw (at line 6-7), respectively.",3.3 Integrated Inference Model,[0],[0]
"After training by all triplets in Ξ, the algorithm removes formulas with low weights from F (at line 8) and outputs the model (at line 9).",3.3 Integrated Inference Model,[0],[0]
"When we infer a new triplet by this model, the process is similar to Algorithm 1.",3.3 Integrated Inference Model,[0],[0]
We first compare our approach with several state-ofart methods on link prediction task to explore our approach’s overall ability of inference.,4 Experiments,[0],[0]
"Subsequently, we evaluate formulas mined by different random walk methods to explore whether the goal-directed mechanism can increase efficiency of mining useful structures.",4 Experiments,[0],[0]
"Finally, we dive deep into the formulas generated by our approach to analyze the characters of our approach.",4 Experiments,[0],[0]
"We conduct experiments on both WN18 and FB15K datasets which are subsets sampled from WordNet (Miller, 1995) and Freebase (Bollacker et al., 2008), respectively, and Table 1 shows the statistics of them.",4.1 Datasets and Evaluation Setup,[0],[0]
"For the link prediction task, we predict the missing h or t for a triplet r(h, t) in test set.",4.1 Datasets and Evaluation Setup,[0],[0]
"The detail evaluation method is that t in r(h, t) is replaced by all entities in the KB and methods need to rank the right answer at the top of the list, and so does h in r(h, t).",4.1 Datasets and Evaluation Setup,[0],[0]
"We report the mean of those true answer ranks and the Hits@10 under both ’raw’ and ’filter’ as TransE (Bordes et al., 2013) does, where Hits@10 is the proportion of correct entities ranked in the top 10.
sults on relation form of government in FB15K.",4.1 Datasets and Evaluation Setup,[0],[0]
We employ two types of baselines.,4.2 Baselines,[0],[0]
"One type is based on random walks including: a) the basic random walk algorithm whose state transition probability matrix is shown in Equation (2); b) PRA in (Lao et al., 2011) which is a typical heuristic random walk algorithm.",4.2 Baselines,[0],[0]
"The other type is based on KB embeddings including TransE (Bordes et al., 2013), Rescal (Nickel et al., 2011), TransH (Wang et al., 2014b), TransR",4.2 Baselines,[0],[0]
"(Lin et al., 2015b).",4.2 Baselines,[0],[0]
"These embedding-based methods have no explicit formulas, so we will not evaluate their performances on mining formulas.",4.2 Baselines,[0],[0]
We implement three random walk methods under a unified framework.,4.3 Settings,[0],[0]
"To predict r(h, ∗) quickly, we first select Top-K candidate instances, t1→K , by TransE as (Wei et al., 2015), and then the algorithm infers each r(h, ti) and ranks them by inference results.",4.3 Settings,[0],[0]
"We adjust parameters for our approach with the validate dataset, and the optimal configurations are set as follows.",4.3 Settings,[0],[0]
"The rounds of random walk is 10, learning rate is 0.0001, training epoch is 100, the size of candidate set is 500 for WN18 and 100 for FB15K, the embeddings have 50 dimensionalities for WN18 and 100 dimensionalities for FB15K, and the embeddings are initialized by TransE. For some relations, random walk truly finds no practicable formulas, so we employ TransE to improve per-
formance for these relations.",4.3 Settings,[0],[0]
"For embedding-based methods, we use reported results directly since the evaluation datasets are identical.",4.3 Settings,[0],[0]
"We show the results of link prediction for our approach and all baselines in Table 2 (* means the mean of ranks for random walk methods are evaluated in the Top-K subset), and we can obtain the following observations:
1)",4.4 Results on Link Prediction,[0],[0]
"Our approach achieves good performances on both WN18 and FB15K. On the FB15K, our approach outperforms all baselines.",4.4 Results on Link Prediction,[0],[0]
It indicates that our approach is effective for inference.,4.4 Results on Link Prediction,[0],[0]
"On the WN18, three random walk methods have similar performances.",4.4 Results on Link Prediction,[0],[0]
"The reason is that most entities in WN18 only have a small number of neighbors, so RW and PRA can also find useful structures in a few rounds.
2) For FB15K, the performances of RW and PRA are both poor and even worse than a part of embedding-based methods, but the performance of our approach is still the best.",4.4 Results on Link Prediction,[0],[0]
"The reason is that there are too many relation types in FB15K, so goalless random walks introduce lots of noise.",4.4 Results on Link Prediction,[0],[0]
"Oppositely, our approach has a great capability of resisting noise for the goal-directed mechanism.
3) RW and PRA have similar performances on both datasets, which indicates the heuristic rule of PRA does not apply to all relations and formulas.",4.4 Results on Link Prediction,[0],[0]
"To further explore whether the goal-directed mechanism can increase efficiency of mining paths, we compare the three random walk methods by the number of paths mined.",4.5 Paths Recall by Random Walks,[0],[0]
"For each triplet R(H,T )
in the training set, we perform 10 rounds of random walks fromH and record the number of times which arrive at T, noted as Arr@10.",4.5 Paths Recall by Random Walks,[0],[0]
We respectively select one relation type from WN18 and FB15K and show the comparison result in Figure 2.,4.5 Paths Recall by Random Walks,[0],[0]
"We can obtain the following observations:
1) With the increase of training epochs, Arr@10 of the goal-directed random walk first increases and then stays around a high value on both WN18 and FB15K, but the Arr@10 of RW and PRA always stay the same.",4.5 Paths Recall by Random Walks,[0],[0]
"This phenomenon indicates that the goal-directed random walk is a learnable model and can be trained to find more useful structures with epochs increasing, but RW and PRA are not.
2) RW and PRA always have similar Arr@10, which means PRA has not found more formulas.",4.5 Paths Recall by Random Walks,[0],[0]
This indicates that the heuristic rule of PRA is not always be beneficial to mining more structures for all relations.,4.5 Paths Recall by Random Walks,[0],[0]
"In Table 3, we show a small number of formulas mined by our approach from FB15K, and the formulas represent different types.",4.6 Example Formulas,[0],[0]
"Some formulas contain clear logic, e.g, Formula 1 means that if the writer x contributes a story to the film y and y is adapted from the book z, x is the writer of the book z.",4.6 Example Formulas,[0],[0]
"Some formulas have a high probability of being satisfied, e.g., Formula 3 means the wedding place probably is also the burial place for some people, and Formula 7 means the parent of the person x died of the disease and thus the person x has a high risk of suffering from the disease.",4.6 Example Formulas,[0],[0]
"Some formulas depend on synonyms, e.g., story by and works written have the similar meaning in Formula 2.",4.6 Example Formulas,[0],[0]
"However, there are still useless formulas, e.g, Formula 8 is useless be-
cause the body of the formula is same as the head.",4.6 Example Formulas,[0],[0]
"Such useless formula can be removed by a superrule, which is that the head of a formula cannot occur in its body.",4.6 Example Formulas,[0],[0]
"Our work has two aspects, which are related to mining formula automatically and inference on KBs, respectively.
",5 Related Work,[0],[0]
"Inductive Logic Programming (ILP) (Muggleton and De Raedt, 1994) and Association Rule Mining (ARM) (Agrawal et al., 1993) are both early works on mining formulas.",5 Related Work,[0],[0]
"FOIT (Quinlan, 1990) and SHERLOCK (Schoenmackers et al., 2010) are typical ILP systems, but the former one usually need a lot of negative facts and the latter one focuses on mining formulas from text.",5 Related Work,[0],[0]
"AMIE (Galárraga et al., 2013) is based on ARM and proposes a new measure for formulas instead of the confidence.",5 Related Work,[0],[0]
"Several structure learning algorithms (Kok and Domingos, 2005; Kok and Domingos, 2009; Kok and Domingos, 2010) based on Markov Logic Network (MLN) (Richardson and Domingos, 2006) can also learn first order logic formulas automatically, but they are too slow to run on large KBs.",5 Related Work,[0],[0]
"ProPPR (Wang et al., 2013; Wang et al., 2014a) performs structure learning by depth first searching on the knowledge graph, which is still not efficient enough to handle webscale KBs.",5 Related Work,[0],[0]
"PRA (Lao and Cohen, 2010; Lao et al., 2011) is a method based on random walks and employs heuristic rules to direct random walks.",5 Related Work,[0],[0]
"PRA is closely related to our approach, but unlike it, our approach dynamically calculates state transition prob-
abilities.",5 Related Work,[0],[0]
"Another method based on random walks (Wei et al., 2015) merges embedding similarities of candidates into the random walk as a priori, while our approach employs KB embeddings to calculate potentials for neighbors.
",5 Related Work,[0],[0]
"The majority of mining formula methods can perform inference on KBs, and besides them, a dozen methods based KB embeddings can also achieve the inference goal, and the typical ones of them are TransE (Bordes et al., 2013), Rescal (Nickel et al., 2011), TransH (Wang et al., 2014b), TransR",5 Related Work,[0],[0]
"(Lin et al., 2015b).",5 Related Work,[0],[0]
These embedding-based methods take advantage of the implicit relationship between elements of the KB and perform inference by calculating similarities.,5 Related Work,[0],[0]
"There are also methods which combine inference formulas and KB embeddings, such as PTransE (Lin et al., 2015a) and ProPPR+MF (Wang and Cohen, 2016).",5 Related Work,[0],[0]
"In this paper, we introduce a goal-directed random walk algorithm to increase efficiency of mining useful formulas and decrease noise simultaneously.",6 Conclusion and Future Works,[0],[0]
The approach employs the inference target as the direction at each steps in the random walk process and is more inclined to visit structures helpful to inference.,6 Conclusion and Future Works,[0],[0]
"In empirical studies, we show our approach achieves good performances on link prediction task over large-scale KBs.",6 Conclusion and Future Works,[0],[0]
"In the future, we are interested in exploring mining formulas directly in the distributional spaces which may resolve the sparsity of formulas.",6 Conclusion and Future Works,[0],[0]
"This work was supported by the Natural Science Foundation of China (No. 61533018), the National Basic Research Program of China (No. 2014CB340503) and the National Natural Science Foundation of China (No. 61272332).",7 Acknowledgments,[0],[0]
And this work was also supported by Google through focused research awards program.,7 Acknowledgments,[0],[0]
"Deep inference on a large-scale knowledge base (KB) needs a mass of formulas, but it is almost impossible to create all formulas manually.",abstractText,[0],[0]
"Data-driven methods have been proposed to mine formulas from KBs automatically, where random sampling and approximate calculation are common techniques to handle big data.",abstractText,[0],[0]
"Among a series of methods, Random Walk is believed to be suitable for knowledge graph data.",abstractText,[0],[0]
"However, a pure random walk without goals still has a poor efficiency of mining useful formulas, and even introduces lots of noise which may mislead inference.",abstractText,[0],[0]
"Although several heuristic rules have been proposed to direct random walks, they do not work well due to the diversity of formulas.",abstractText,[0],[0]
"To this end, we propose a novel goaldirected inference formula mining algorithm, which directs random walks by the specific inference target at each step.",abstractText,[0],[0]
"The algorithm is more inclined to visit benefic structures to infer the target, so it can increase efficiency of random walks and avoid noise simultaneously.",abstractText,[0],[0]
The experiments on both WordNet and Freebase prove that our approach is has a high efficiency and performs best on the task.,abstractText,[0],[0]
Mining Inference Formulas by Goal-Directed Random Walks,title,[0],[0]
"Proceedings of the SIGDIAL 2015 Conference, pages 22–31, Prague, Czech Republic, 2-4 September 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
Physically situated dialogue differs from traditional human-computer dialogue in that interactions will make use of reference to a dialogue agent’s surroundings.,1 Introduction,[0],[0]
"Tasks may fail due to dependencies on specific environment configurations, such as when a robot’s path to a goal is blocked.",1 Introduction,[0],[0]
"People will often help; in navigation dialogues they tend to ask proactive, task-related questions instead of simply signaling communication failure (Skantze, 2005).",1 Introduction,[0],[0]
They supplement the agent’s representation of the environment and allow it to complete tasks.,1 Introduction,[0],[0]
The current study establishes an empirical basis for grounding in physically situated contexts.,1 Introduction,[0],[0]
"We had people provide recovery strategies for a robot in various situations.
",1 Introduction,[0],[0]
"The focus of this work is on recovery from situated grounding problems, a type of miscommunication that occurs when an agent fails to uniquely map a person’s instructions to its surroundings (Marge and Rudnicky, 2013).",1 Introduction,[0],[0]
"A referential ambiguity is where an instruction resolves to more than one possibility (e.g., “Search the room on the left” when there are multiple rooms on the agent’s left); an impossible-to-execute problem
fails to resolve to any action (e.g., same instruction but there are no rooms on the agent’s left).",1 Introduction,[0],[0]
"A common strategy evidenced in human-human corpora is for people to ask questions to recover from situated grounding problems (Tenbrink et al., 2010).
",1 Introduction,[0],[0]
"Dialogue divides into two levels: that of managing the actual dialogue—determining who has the floor, that an utterance was recognized, etc.—and",1 Introduction,[0],[0]
"the dialogue that serves the main joint activities that dialogue partners are carrying out, like a human-robot team exploring a new area (Bangerter and Clark, 2003).",1 Introduction,[0],[0]
"Most approaches to grounding in dialogue systems are managing the dialogue itself, making use of spoken language input as an indicator of understanding (e.g., (Bohus, 2007; Skantze, 2007)).",1 Introduction,[0.9529015626673262],"['Theories of language origin identify the combination of language and nonverbal behaviors (vision and acoustic modality) as the prime form of communication utilized by humans throughout evolution (Müller, 1866).']"
Situated grounding problems are associated with the main joint activities; to resolve them we believe that the recovery model must be extended to include planning and environment information.,1 Introduction,[0],[0]
"Flexible recovery strategies make this possible by enabling dialogue partners to coordinate their joint activities and accomplish tasks.
",1 Introduction,[0],[0]
We cast the problem space as one where the agent aims to select the most efficient recovery strategy that would resolve a user’s intended referent.,1 Introduction,[0],[0]
We expect that this efficiency is tied to the cognitive load it takes to produce clarifications.,1 Introduction,[0],[0]
Viethen and Dale (2006) suggest a similar prediction in their study comparing human and automatically generated referring expressions of objects and their properties.,1 Introduction,[0],[0]
"We sought to answer the following questions in this work: • How good are people at detecting situated
grounding problems?",1 Introduction,[0],[0]
• How do people organize recovery strategies?,1 Introduction,[0],[0]
"• When resolving ambiguity, which properties do
people use to differentiate referents?",1 Introduction,[0],[0]
"• When resolving impossible-to-execute instruc-
tions, do people use active or passive ways to get the conversation back on track?
",1 Introduction,[0],[0]
"22
We determined the most common recovery strategies for referential ambiguity and impossible-toexecute problems.",1 Introduction,[0],[0]
Several patterns emerged that suggest ways that people expect agents to recover.,1 Introduction,[0],[0]
Ultimately we intend for dialogue systems to use such strategies in physically situated contexts.,1 Introduction,[0],[0]
Researchers have long observed miscommunication and recovery in human-human dialogue corpora.,2 Related Work,[0],[0]
"The HCRC MapTask had a direction giverdirection follower pair navigate two dimensional schematics with slightly different maps (Anderson et al., 1991).",2 Related Work,[0],[0]
Carletta (1992) proposed several recovery strategies following an analysis of this corpus.,2 Related Work,[0],[0]
"The SCARE corpus collected human-human dialogues in a similar scenario where the direction follower was situated in a three-dimensional virtual environment (Stoia et al., 2008).
",2 Related Work,[0],[0]
"The current study follows up an initial proposal set of recovery strategies for physically situated domains (Marge and Rudnicky, 2011).",2 Related Work,[0],[0]
Others have also developed recovery strategies for situated dialogue.,2 Related Work,[0],[0]
Kruijff et al. (2006) developed a framework for a robot mapping an environment that employed conversational strategies as part of the grounding process.,2 Related Work,[0],[0]
"A similar study focused on resolving misunderstandings in the humanrobot domain using the Wizard-of-Oz methodology (Koulouri and Lauria, 2009).",2 Related Work,[0],[0]
"A body of work on referring expression generation uses object attributes to generate descriptions of referents (e.g., (Guhe and Bard, 2008; Garoufi and Koller, 2014)).",2 Related Work,[0],[0]
"Viethen and Dale (2006) compared human-authored referring expressions of objects to existing natural language generation algorithms and found them to have very different content.
",2 Related Work,[0],[0]
Crowdsourcing has been shown to provide useful dialogue data:,2 Related Work,[0],[0]
Manuvinakurike and DeVault (2015) used the technique to collect gameplaying conversations.,2 Related Work,[0],[0]
"Wang et al. (2012) and Mitchell et al. (2014) have used crowdsourced data for training, while others have used it in real time systems (Lasecki et al., 2013; Huang et al., 2014).",2 Related Work,[0],[0]
"In this study, participants came up with phrases that a search-and-rescue robot should say in response to an operator’s command.",3 Method,[0],[0]
"The participant’s task was to view scenes in a virtual envi-
ronment then formulate the robot’s response to an operator’s request.",3 Method,[0],[0]
"Participants listened to an operator’s verbal command then typed in a response.
",3 Method,[0],[0]
"Scenes displayed one of three situations: referential ambiguity (more than one possible action), impossible-to-execute (zero possible actions), and executable (one possible action).",3 Method,[0],[0]
The instructions showed some example problems.,3 Method,[0],[0]
All situations involved one operator and one robot.,3 Method,[0],[0]
"After instructions and a practice trial, participants viewed scenes in one of 10 different environments (see Figure 1).",3.1 Experiment Design,[0],[0]
"They would first watch a flyover video of the robot’s environment, then view a screen showing labels for all possible referable objects in the scene.",3.1 Experiment Design,[0],[0]
The participant would then watch the robot enter the first scene.,3.1 Experiment Design,[0],[0]
"The practice trial and instructions did not provide any examples of questions.
",3.1 Experiment Design,[0],[0]
The robot would stop and a spoken instruction from the operator would be heard.,3.1 Experiment Design,[0],[0]
The participant was free to replay the instruction multiple times.,3.1 Experiment Design,[0],[0]
They would then enter a response (say an acknowledgment or a question).,3.1 Experiment Design,[0],[0]
"Upon completion of the trial, the robot would move to a different scene, where the process was repeated.
",3.1 Experiment Design,[0],[0]
Only self-contained questions that would allow the operator to answer without follow-up were allowed.,3.1 Experiment Design,[0],[0]
Thus generic questions like “which one?” would not allow the operator to give the robot enough useful information to proceed.,3.1 Experiment Design,[0],[0]
"In the instructions, we suggested that participants include some detail about the environment in their ques-
tions.",3.1 Experiment Design,[0],[0]
Participants used a web form1 to view situations and provide responses.,3.1 Experiment Design,[0],[0]
"We recorded demographic information (gender, age, native language, native country) and time on task.",3.1 Experiment Design,[0],[0]
"The instructions had several attention checks (Paolacci et al., 2010) to ensure that participants were focusing on the task.
",3.1 Experiment Design,[0],[0]
We created fifty trials across ten environments.,3.1 Experiment Design,[0],[0]
Each environment had five trials that represented waypoints the robot was to reach.,3.1 Experiment Design,[0],[0]
Participants viewed five different environments (totaling twenty-five trials).,3.1 Experiment Design,[0],[0]
Each command from the remote operator to the robot was a route instruction in the robot navigation domain.,3.1 Experiment Design,[0],[0]
Trials were assembled in two groups and participants were assigned randomly to one (see Table 1).,3.1 Experiment Design,[0],[0]
Trial order was randomized according to a Latin Square.,3.1 Experiment Design,[0],[0]
"Scenes were of a 3D virtual environment at eye level, with the camera one to two meters behind the robot.",3.1.1 Scenes and Environments,[0],[0]
"Camera angle issues with environment objects caused this variation.
",3.1.1 Scenes and Environments,[0],[0]
Participants understood that the fictional operator was not co-located with the robot.,3.1.1 Scenes and Environments,[0],[0]
The USARSim robot simulation toolkit and the UnrealEd game map editor were used to create the environment.,3.1.1 Scenes and Environments,[0],[0]
"Cepstral’s SwiftTalker was used for the operator voice.
",3.1.1 Scenes and Environments,[0],[0]
"Of the fifty scenes, twenty-five (50%) had referential ambiguities, fifteen (30%) were impossible-to-execute, and ten (20%) were executable controls.",3.1.1 Scenes and Environments,[0],[0]
"The selection was weighted to referential ambiguity, as these were expected to produce greater variety in recovery strategies.",3.1.1 Scenes and Environments,[0],[0]
"We randomly assigned each of fifty trials a stimulus type according to this distribution, then divided the list into ten environments.",3.1.1 Scenes and Environments,[0],[0]
"The environments featured objects and doorways appropriate to the trial type, as well as waypoints.
1See http://goo.gl/forms/ZGpK3L1nPh for an example.
",3.1.1 Scenes and Environments,[0],[0]
"Referential Ambiguity We arranged the sources of information participants could use to describe referents, to enable analysis of the relationship between context and recovery strategies.",3.1.1 Scenes and Environments,[0],[0]
"The sources of information (i.e., “situated dimensions”) were: (1) intrinsic properties (either color or size), (2) history (objects that the robot already encountered), (3) egocentric proximity of the robot to candidate referents around it (the robot’s perspective is always taken), and (4) object proximity (proximity of candidate referents to other objects).",3.1.1 Scenes and Environments,[0],[0]
"Table 2 provides additional details.
",3.1.1 Scenes and Environments,[0],[0]
Scenes with referential ambiguity had up to four sources of information available.,3.1.1 Scenes and Environments,[0],[0]
"Information sources were evenly distributed across five trial types: one that included all four sources, and four that included all but one source of information (e.g., one division excluded using history information but did allow proximity, spatial, and object properties, one excluded proximity, etc.).
",3.1.1 Scenes and Environments,[0],[0]
Impossible-to-Execute The impossible-to-execute trials divided into two broad types.,3.1.1 Scenes and Environments,[0],[0]
Nine of the fifteen scenes were impossible because the operator’s command did not match to any referent in the environment.,3.1.1 Scenes and Environments,[0],[0]
"The other six scenes were impossible because a path to get to the matching referent was not possible.
",3.1.1 Scenes and Environments,[0],[0]
Executable Ten scenes were executable for the study and served as controls.,3.1.1 Scenes and Environments,[0],[0]
"The operator’s command mentioned existing, unambiguous referents.",3.1.1 Scenes and Environments,[0],[0]
Participants were aware of the robot’s capabilities before the start of the experiment.,3.1.2 Robot Capabilities,[0],[0]
The instructions said that the robot knew the locations of all objects in the environment and whether doors were closed or open.,3.1.2 Robot Capabilities,[0],[0]
"The robot also knew the color and size of objects in the environment (intrinsic properties), where objects were relative to the robot itself and to other objects (proximity), when objects were right, left, in front, and behind it (spatial terms), the room and hallway locations of objects (location), and the places it has been (history, the robot kept track of which objects it had visited).",3.1.2 Robot Capabilities,[0],[0]
The robot could not pass through closed doors.,3.1.2 Robot Capabilities,[0],[0]
"We made five hypotheses about the organization and content of participant responses to situated grounding problems:
• Hypothesis 1: Participants will have more difficulty detecting impossible-to-execute scenes than ambiguous ones.",3.2 Hypotheses,[0],[0]
"Determining a robot’s tasks to be impossible requires good situation awareness (Nielsen et al., 2007) (i.e., an understanding of surroundings with respect to correctly completing tasks).",3.2 Hypotheses,[0],[0]
"Detecting referential ambiguity requires understanding the operator’s command and visually inspecting the space (Spivey et al., 2002); detecting impossible commands also requires recalling the robot’s capabilities and noticing obstacles.",3.2 Hypotheses,[0],[0]
"Previous research has noted that remote teleoperators have trouble establishing good situation awareness of a robot’s surroundings (Casper and Murphy, 2003; Burke et al., 2004).",3.2 Hypotheses,[0],[0]
"Moreover, obstacles near a robot can be difficult to detect with a restricted view as in the current study (Alfano and Michel, 1990; Arthur, 2000).",3.2 Hypotheses,[0],[0]
•,3.2 Hypotheses,[0],[0]
"Hypotheses 2a and 2b: Responses will more commonly be single, self-contained questions instead of a scene description followed by a question (2a for scenes with referential ambiguity, 2b for scenes that were impossible-toexecute).",3.2 Hypotheses,[0],[0]
"This should reflect the principle of least effort (Clark, 1996), and follow from Carletta’s (1992) observations in a similar dataset.",3.2 Hypotheses,[0],[0]
•,3.2 Hypotheses,[0],[0]
Hypothesis 3: Responses will use the situated dimensions that require the least cognitive effort when disambiguating referents.,3.2 Hypotheses,[0],[0]
Viethen and Dale (2006) suggest that minimizing cognitive load for the speaker or listener would produce more human-like referring expressions.,3.2 Hypotheses,[0],[0]
"We predict that responses will mention visually salient features of the scene, such as color or size of referents, more than history or object proximity.",3.2 Hypotheses,[0],[0]
"Desimone and Duncan (1995) found that color and shape draw more attention than other
properties in visual search tasks when they are highly distinguishable.",3.2 Hypotheses,[0],[0]
•,3.2 Hypotheses,[0],[0]
"Hypothesis 4: In cases of referential ambiguity where two candidate referents are present, responses will confirm one referent in the form of a yes-no question more than presenting a list.",3.2 Hypotheses,[0],[0]
"Results from an analysis of task-oriented dialogue suggests that people are efficient when asking clarification questions (Rieser and Moore, 2005).",3.2 Hypotheses,[0],[0]
"Additionally, Clark’s least effort principle (Clark, 1996) suggests that clarifying one referent using a yes-no confirmation would require less effort than presenting a list in two ways: producing a shorter question and constraining the range of responses to expect.",3.2 Hypotheses,[0],[0]
•,3.2 Hypotheses,[0],[0]
"Hypothesis 5: For impossible-to-execute instructions, responses will most commonly be ways for the robot to proactively work with the operator’s instruction, in an effort to get the conversation back on track.",3.2 Hypotheses,[0],[0]
"The other possible technique, to simply declare that the problem is not possible, will be less common.",3.2 Hypotheses,[0],[0]
This is because participants will believe such a strategy will not align with the task goal of having the robot say something that will allow it to proceed with the task.,3.2 Hypotheses,[0],[0]
"Skantze found that in human-human navigation dialogues, people would prefer to look for alternative ways to proceed rather than simply express nonunderstanding (Skantze, 2005).",3.2 Hypotheses,[0],[0]
"The key independent variable in this study was the stimulus type that the participant viewed (i.e., referential ambiguity, impossible-to-execute, or executable).",3.3 Measures,[0],[0]
"Dependent variables were observational measurements, presented below.",3.3 Measures,[0],[0]
"We report Fleiss’ kappa score for inter-annotator agreement
between three native English speaking annotators on a subset of the data.
",3.3 Measures,[0],[0]
Correctness (κ = 0.77):,3.3 Measures,[0],[0]
"Whether participants correctly determined the situation as ambiguous, impossible, or executable.",3.3 Measures,[0],[0]
Annotators labeled correctness based on the content of participant responses.,3.3 Measures,[0],[0]
This measure assessed participant accuracy for detecting situated grounding problems.,3.3 Measures,[0],[0]
"Either correct or incorrect.
",3.3 Measures,[0],[0]
"Sentence type (κ = 0.82): Either declarative, interrogative, imperative, or exclamatory (Cowan, 2008).
",3.3 Measures,[0],[0]
Question type (κ = 0.92): Sentences that needed an answer from the operator.,3.3 Measures,[0],[0]
"The three types were yes-no questions, alternative questions (which presented a list of options and includes wh- questions that used sources from Table 2), and generic wh- questions (Cowan, 2008).
",3.3 Measures,[0],[0]
Situated dimensions in response (κ = 0.75):,3.3 Measures,[0],[0]
The capability (or capabilities) that the participant mentioned when providing a response.,3.3 Measures,[0],[0]
"The types were intrinsic (color or size), object proximity, egocentric proximity, and history.
",3.3 Measures,[0],[0]
"Projected belief (impossible-to-execute trials only, κ = 0.80):",3.3 Measures,[0],[0]
"The participant’s belief about the next task, given the current operator instruction (projected onto the robot).",3.3 Measures,[0],[0]
"The types were unknown (response indicates participant is unsure what to do next), ask for more (ask for more details), propose alternative (propose alternative object), ask for help (ask operator to physically manipulate environment), and off topic.",3.3 Measures,[0],[0]
We recruited 30 participants.,3.4 Participation,[0],[0]
"All participants completed the web form through the Amazon Mechanical Turk (MTurk) web portal2, all were located in the United States and had a task approval rate ≥95%.",3.4 Participation,[0],[0]
The group included 29 self-reported native English speakers born in the United States; 1 self-reported as a native Bangla speaker born in Bangladesh.,3.4 Participation,[0],[0]
The gender distribution was 15 male to 15 female.,3.4 Participation,[0],[0]
"Participants ranged in age from 22 to 52 (mean: 33 years, std. dev.: 7.7).",3.4 Participation,[0],[0]
They were paid between $1 and $2 for their participation.,3.4 Participation,[0],[0]
"We
2https://www.mturk.com
collected a total of 750 responses.",3.4 Participation,[0],[0]
We analyzed the measures by tabulating frequencies for each possible value.,4 Results,[0],[0]
Table 3 presents some example responses.,4 Results,[0],[0]
"In general, participants were good at detecting situated grounding problems.",4.1 Correctness,[0],[0]
"Out of 750 responses, 667 (89%) implied the correct scene type.",4.1 Correctness,[0],[0]
"We analyzed correctness across actual stimulus types (ambiguous, impossible-to-execute, executable) using a mixed-effects analysis of variance model3, with participant included as a random effect and trial group as a fixed effect.
",4.1 Correctness,[0],[0]
Hypothesis 1 predicted that participants will do better detecting scenes with referential ambiguity than those that were impossible-to-execute; the results support this hypothesis.,4.1 Correctness,[0],[0]
"Actual stimulus type had a significant main effect on correctness (F[2, 58] = 12.3, p < 0.001); trial group did not (F[1, 28] = 0.1, p = 0.72).",4.1 Correctness,[0],[0]
Participants had significantly worse performance detecting impossible-to-execute scenes compared to ambiguous ones (p< 0.001; Tukey HSD test).,4.1 Correctness,[0],[0]
"In fact, they were four times worse; of the impossible-toexecute scenes, participants failed to detect that 22% (50/225) of them were impossible, compared to 5% (17/375) of scenes with referential ambiguity.",4.1 Correctness,[0],[0]
"Of the 150 instructions that were executable, participants failed to detect 11% (16/150) of them as such.",4.1 Correctness,[0],[0]
"We analyzed the 358 responses where participants correctly detected referential ambiguity.
",4.2 Referential Ambiguity,[0],[0]
"3This approach computed standard least squares regression using reduced maximum likelihood (Harville, 1977).
",4.2 Referential Ambiguity,[0],[0]
"Hypothesis 2a predicted that participants would more commonly ask single, self-contained questions instead of describing the scene and asking a question.",4.2 Referential Ambiguity,[0],[0]
We assessed this by counting sentence types within a response.,4.2 Referential Ambiguity,[0],[0]
Responses that had both a declarative sentence and an interrogative would fit this case.,4.2 Referential Ambiguity,[0],[0]
The results confirmed this hypothesis.,4.2 Referential Ambiguity,[0],[0]
"Only 4.5% (16/358) of possible responses had a declarative and an interrogative.
",4.2 Referential Ambiguity,[0],[0]
Hypothesis 3 predicted that participants would use the situated dimensions that require the least cognitive effort when disambiguating referents.,4.2 Referential Ambiguity,[0],[0]
"More specifically, the most common mentions will be those that are visually apparent (intrinsic properties like color and size), while those that require more processing would have fewer mentions (history and to a lesser extent object proximity and egocentric proximity).",4.2 Referential Ambiguity,[0],[0]
"We measured this by tabulating mentions of situated dimensions in all 358 correct participant responses, summarized in Figure 2.",4.2 Referential Ambiguity,[0],[0]
Multiple dimensions could occur in a single response.,4.2 Referential Ambiguity,[0],[0]
The results support this hypothesis.,4.2 Referential Ambiguity,[0],[0]
"By far, across all ambiguous scenarios, the most mentioned dimension was an intrinsic property.",4.2 Referential Ambiguity,[0],[0]
"More than half of all situated dimensions used were intrinsic (59%, 242/410 total mentions).",4.2 Referential Ambiguity,[0],[0]
"This was followed by the dimensions that we hypothesize require more cognitive effort: egocentric proximity had 30% (125/410) of mentions, object proximity 9.5% (39/410), and history 1% (4/410).",4.2 Referential Ambiguity,[0],[0]
"Of the intrinsic dimensions mentioned, most were only color (61%, 148/242), followed by size (33%, 81/242), and using both (5%, 13/242).
",4.2 Referential Ambiguity,[0],[0]
Hypothesis 4 predicted that participants would ask yes-no confirmation questions in favor of presenting lists when disambiguating a referent with exactly two candidates.,4.2 Referential Ambiguity,[0],[0]
"The results suggest that the opposite is true; people strongly preferred to
list options, even when a confirmation question about one would have been sufficient.",4.2 Referential Ambiguity,[0],[0]
"Of the 285 responses that were correctly detected as ambiguous and were for scenes of exactly two possible referents, 74% (212/285) presented a list of options.",4.2 Referential Ambiguity,[0],[0]
Only 14% (39/285) asked yes-no confirmation questions.,4.2 Referential Ambiguity,[0],[0]
The remaining 34 questions (12%) were generic wh-questions.,4.2 Referential Ambiguity,[0],[0]
These results held in scenes where three options were present.,4.2 Referential Ambiguity,[0],[0]
"Overall 72% (259/358) presented a list of options, while 16% (58/358) asked generic wh-questions and 11% (41/358) asked yes-no confirmations.",4.2 Referential Ambiguity,[0],[0]
"We analyzed the 175 responses where participants correctly identified impossible-to-execute situations.
",4.3 Impossible-to-Execute,[0],[0]
Hypothesis 2b predicted that participants would more often only ask a question than also describe the scene.,4.3 Impossible-to-Execute,[0],[0]
Results confirmed this hypothesis.,4.3 Impossible-to-Execute,[0],[0]
"42% (73/175) of responses simply asked a question, while 22% (39/175) used only a declarative.",4.3 Impossible-to-Execute,[0],[0]
"More than a third included a declarative as well (36%, 63/175).",4.3 Impossible-to-Execute,[0],[0]
"The general organization to these was to declare the problem then ask a question about it (89%, 56/63).
",4.3 Impossible-to-Execute,[0],[0]
"Hypothesis 5 predicted that responses for impossible-to-execute instructions will more commonly be proactive and make suggestions, instead of simply declaring that an action was not possible.",4.3 Impossible-to-Execute,[0],[0]
"Table 4 summarizes the results, which confirmed this hypothesis.",4.3 Impossible-to-Execute,[0],[0]
The most common belief that participants had for the robot was to have it propose an alternative referent to the impossible one specified by the operator.,4.3 Impossible-to-Execute,[0],[0]
The next-most common was to have the robot simply express uncertainty about what to do next.,4.3 Impossible-to-Execute,[0],[0]
"Though this belief occurred in about a third of responses, the remaining responses were all proactive ways for the robot to get the conversation back on track (i.e., propose alternative, ask for more, and ask for help).",4.3 Impossible-to-Execute,[0],[0]
"The results largely support the hypotheses, with the exception of Hypothesis 4.",5 Discussion,[0],[0]
"They also provide information about how people expect robots to recover from situated grounding problems.
",5 Discussion,[0],[0]
"Correctness Participants had the most trouble detecting impossible-to-execute scenes, supporting Hypothesis 1.",5 Discussion,[0],[0]
"An error analysis of the 50 responses for this condition had participants responding as if the impossible scenes were possible (62%, 31/50).",5 Discussion,[0],[0]
"The lack of good situation awareness was a factor, which agrees with previous findings in the human-robot interaction literature (Casper and Murphy, 2003; Burke et al., 2004).",5 Discussion,[0.9520778725880876],"['This complexity is rooted in variability of intra-modal and crossmodal dynamics for language, vision and acoustic modalities (Rajagopalan et al., 2016).']"
We found that participants had trouble with a specific scene where they confused the front and back of the robot (9 of the 31 impossibleexecutable responses were for this scene).,5 Discussion,[0],[0]
"Note that all scenes showed the robot entering the room with the same perspective, facing forward.
",5 Discussion,[0],[0]
"Referential Ambiguity Results for Hypothesis 2a showed that participants overwhelmingly asked only a single, self-contained question as opposed to first stating that there was an ambiguity.",5 Discussion,[0],[0]
"Participants also preferred to present a list of options, despite the number of possible candidates.",5 Discussion,[0],[0]
"This contradicted Hypothesis 4. Rieser and Moore (2005) found that in task-oriented human-human dialogues, clarification requests aim to be as efficient as possible; they are mostly partially formed.",5 Discussion,[0],[0]
The results in our study were not of real-time dialogue; we isolated specific parts of what participants believed to be human-computer dialogue.,5 Discussion,[0],[0]
"Moreover, Rieser and Moore were observing clarifications at Bangerter and Clark’s (2003) dialogue management level; we were observing them in service of the joint activity of navigating the robot.",5 Discussion,[0],[0]
"We believe that this difference resulted in participants using caution by disambiguating with lists.
",5 Discussion,[0],[0]
"These results suggest that dialogue systems should present detection of referential ambiguity implicitly, and as a list.",5 Discussion,[0],[0]
"Generic wh- questions (e.g., “which one?” without presenting a followon list) are less desirable because they don’t constrain what the user can say, and don’t provide any indication of what the dialogue system can understand.",5 Discussion,[0],[0]
"A list offers several benefits: it grounds awareness of surroundings, presents a fixed set of options to the user, and constrains the range of
linguistic responses.",5 Discussion,[0],[0]
"This could also extend to general ambiguity, as in when there are a list of matches to a query, but that is outside the scope of this work.",5 Discussion,[0],[0]
"Lists may be less useful as they grow in size; in our study they could not grow beyond three candidates.
",5 Discussion,[0],[0]
The data also supported Hypothesis 3.,5 Discussion,[0],[0]
Participants generally preferred to use situated dimensions that required less effort to describe.,5 Discussion,[0],[0]
"Intrinsic dimensions (color and size) had the greatest count, followed by egocentric proximity, object proximity, and finally using history.",5 Discussion,[0],[0]
"We attribute these results to the salient nature of intrinsic properties compared to ones that must be computed (i.e., egocentric and object proximity require spatial processing, while history requires thinking about previous exchanges).",5 Discussion,[0],[0]
This also speaks to a similar claim by Viethen and Dale (2006).,5 Discussion,[0],[0]
"Responses included color more than any other property, suggesting that an object’s color draws more visual attention than its size.",5 Discussion,[0],[0]
"Bright colors and big shapes stand out most in visual search tasks; we had more of the former than the latter (Desimone and Duncan, 1995).
",5 Discussion,[0],[0]
"For an ambiguous scene, participants appear to traverse a salience hierarchy (Hirst et al., 1994) whereby they select the most visually salient feature that also uniquely teases apart candidates.",5 Discussion,[0],[0]
"While the salience hierarchy varies depending on the current context of a referent, we anticipate such a hierarchy can be defined computationally.",5 Discussion,[0],[0]
"Others have proposed similar processes for referring expression generation (Van Der Sluis, 2005; Guhe and Bard, 2008).",5 Discussion,[0],[0]
One way to rank salience on the hierarchy could be predicted mental load; we speculate that this is a reason why history was barely mentioned to disambiguate.,5 Discussion,[0],[0]
"Another would be to model visual attention, which could explain why color was so dominant.
",5 Discussion,[0],[0]
"Note that only a few dimensions were “competing” at any given time, and their presence in the scenes was equal (save for history, which had slightly fewer due to task design constraints).",5 Discussion,[0],[0]
"Egocentric proximity, which uses spatial language to orient candidate referents relative to the robot, had a moderate presence.",5 Discussion,[0],[0]
"When intrinsic properties were unavailable in the scene, responses most often used this property.",5 Discussion,[0],[0]
"We found that sometimes participants would derive this property even if it wasn’t made prototypical in the scene (e.g., referring to a table as “left” when it was in front and
off to the left side of the robot).",5 Discussion,[0],[0]
This suggests that using egocentric proximity to disambiguate makes a good fallback strategy when nothing else works.,5 Discussion,[0],[0]
"Another situated dimension emerged from the responses, disambiguation by location (e.g., “Do you mean the box in this room or the other one?”).",5 Discussion,[0],[0]
"Though not frequent, it provides another useful technique to disambiguate when visually salient properties are not available.
",5 Discussion,[0],[0]
"Our findings differ from those of Carlson and Hill (2009) who found that salience is not as prominent as spatial relationships between a target (in the current study, this would be the robot) and other objects.",5 Discussion,[0],[0]
Our study did not direct participants to formulate spatial descriptions; they were free to compose responses.,5 Discussion,[0],[0]
"In addition, our work directly compares intrinsic properties for objects of the same broad type (e.g., disambiguation of a doors of different colors).",5 Discussion,[0.9563188751569743],"['In the presence of informative visual information, the model increases the efficacies of (v → τ) although the values of other visual efficacies also increase.']"
"Our findings suggest the opposite of Moratz et al. (2003), who found that when pointing out an object, describing its position may be better than describing its attributes in human-robot interactions.",5 Discussion,[0],[0]
"Their study only had one object type (cube) and did not vary color, size, or proximity to nearby objects.",5 Discussion,[0],[0]
"As a result, participants described objects using spatial terms.",5 Discussion,[0],[0]
"In our study, we explored variation of several attributes to determine participants’ preferences.
",5 Discussion,[0],[0]
Impossible-to-Execute Results supported Hypothesis 2b.,5 Discussion,[0],[0]
Most responses had a single sentence type.,5 Discussion,[0],[0]
"Although unanticipated, a useful strategy emerged: describe the problem that makes the scene impossible, then propose an alternative referent.",5 Discussion,[0],[0]
This type of strategy helped support Hypothesis 5.,5 Discussion,[0],[0]
"Responses for impossible scenes largely had the participant proactively presenting a way to move the task forward, similar to what Skantze (2005) observed in human-human dialogues.",5 Discussion,[0],[0]
This suggests that participants believed the robot should ask directed questions to recover.,5 Discussion,[0],[0]
These questions often took the form of posing alternative options.,5 Discussion,[0],[0]
We used the Amazon Mechanical Turk web portal to gather responses in this study.,5.1 Limitations,[0],[0]
"As such we could not control the participant environment when taking the study, but we did include attention checks.",5.1 Limitations,[0],[0]
"Participants did not interact with a
dialogue system.",5.1 Limitations,[0],[0]
Instead we isolated parts of the interaction that were instances of where the robot would have to say something in response to an instruction.,5.1 Limitations,[0],[0]
We asked participants to provide what they think the robot should say; there was no ongoing interaction.,5.1 Limitations,[0],[0]
"However, we maintained continuity by presenting videos of the robot navigating through the environment as participants completed the task.",5.1 Limitations,[0],[0]
"The robot was represented in a virtual environment, which prevents us from understanding if there are any influencing factors that may impact results if the robot were in physical form or co-present with the participant.",5.1 Limitations,[0],[0]
Recovery strategies allow situated agents like robots to recover from misunderstandings by using the human dialogue partner.,6 Conclusions,[0],[0]
We conducted a study that collected recovery strategies for physically situated dialogue with the goal of establishing an empirical basis for grounding in physically situated contexts.,6 Conclusions,[0],[0]
"We crowdsourced 750 written strategies across 30 participants and analyzed their situated properties and how they were organized.
",6 Conclusions,[0],[0]
We found that participants’ recovery strategies minimize cognitive effort and indicate a desire to successfully complete the task.,6 Conclusions,[0],[0]
"For disambiguation, there was a preference for strategies that use visually salient properties over ones that require additional mental processing, like spatial reasoning or memory recall.",6 Conclusions,[0],[0]
"For impossible-to-execute scenes, responses more often presented alternative referents than just noting non-understanding.",6 Conclusions,[0],[0]
"We should note that some differences between our findings and those of others may in part rest on differences in task and environment, though intrinsic variables such as mental effort will likely persist over different situations.
",6 Conclusions,[0],[0]
"In future work, we intend to use these data to model salience ranking in similar contexts.",6 Conclusions,[0],[0]
We will further assess the hypothesis that participants’ preferences in this study will enhance performance in a spoken dialogue system that deploys similar strategies.,6 Conclusions,[0],[0]
The authors thank Prasanna Kumar Muthukumar and Juneki Hong for helping to annotate recovery strategies.,Acknowledgments,[0],[0]
"We also thank Taylor Cassidy, Arthur William Evans, and the anonymous reviewers for their valuable comments.",Acknowledgments,[0],[0]
We describe an empirical study that crowdsourced human-authored recovery strategies for various problems encountered in physically situated dialogue.,abstractText,[0],[0]
The purpose was to investigate the strategies that people use in response to requests that are referentially ambiguous or impossible to execute.,abstractText,[0],[0]
"Results suggest a general preference for including specific kinds of visual information when disambiguating referents, and for volunteering alternative plans when the original instruction was not possible to carry out.",abstractText,[0],[0]
Miscommunication Recovery in Physically Situated Dialogue,title,[0],[0]
Feature selection is an important step in extracting interpretable patterns from data.,1. Introduction,[0],[0]
"It has numerous applications in a wide range of areas, including natural-language processing, genomics, and chemistry.",1. Introduction,[0],[0]
"Suppose that there are n or-
*These authors contributed equally and are listed alphabetically 1Department of Electrical Engineering, Stanford University, Stanford, California 2Department of Computer Science, Rice University, Houston, Texas 3Department of Electrical and Computer Engineering, Rice University, Houston, Texas.",1. Introduction,[0],[0]
"Correspondence to: Anshumali Shrivastava <anshumali@rice.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"dered pairs (Xi, yi)i∈[n], where Xi ∈ Rp are p-dimensional feature vectors, and yi ∈ R are scalar outputs.",1. Introduction,[0],[0]
"Feature selection aims to identify a small subset of features (coordinates of the p-dimensional feature vector) that best models the relationship between the data Xi and the output yi.
",1. Introduction,[0],[0]
A significant complication that is common in modern engineering and scientific applications is that the feature space p is ultra high-dimensional.,1. Introduction,[0],[0]
"For example, Weinberger introduced a dataset with 16 trillion (p = 1013) unique features (Weinberger et al., 2009).",1. Introduction,[0],[0]
A 16 trillion dimensional feature vector (of double 8 bytes) requires 128 terabytes of working memory.,1. Introduction,[0],[0]
Problems from modern genetics are even more challenging.,1. Introduction,[0],[0]
A particularly useful way to represent a long DNA sequence is by a feature vector that counts the occurrence frequency of all length-K sub-strings called K-mers.,1. Introduction,[0],[0]
"This representation plays an important role in large-scale regression problems in computational biology (Wood & Salzberg, 2014; Bray et al., 2015; Vervier et al., 2016; Aghazadeh et al., 2016).",1. Introduction,[0],[0]
"Typically, K is chosen to be larger than 12, and these strings are composed of all possible combinations of 16 characters ({A,T,C,G} in addition to 12 wild card characters).",1. Introduction,[0],[0]
"In this case, the feature vector dimension is p = 1612 = 248.",1. Introduction,[0],[0]
"A vector of size 248 single-precision variables requires approximately 1 petabyte of space!
",1. Introduction,[0],[0]
"For ultra large-scale feature selection problems, it is impossible to run standard explicit regularization-based methods like `1-regularization (Shalev-Shwartz & Tewari, 2011; Tan et al., 2014) or to select hyperparameters with a constrained amount of memory (Langford et al., 2009).",1. Introduction,[0],[0]
"This is not surprising, because these methods are not scalable in terms of memory and computational time (Duchi et al., 2008).",1. Introduction,[0],[0]
Another important operational concern is that most datasets represent features in the form of strings or tokens.,1. Introduction,[0],[0]
"For example, with DNA or n-gram datasets, features are represented by strings of characters.",1. Introduction,[0],[0]
"Even in click-through data (McMahan et al., 2013), features are indexed by textual tokens.",1. Introduction,[0],[0]
Observe that mapping each of these strings to a vector component requires maintaining a dictionary whose size equals the length of the feature vector.,1. Introduction,[0],[0]
"As a result, one does not even have the capability to create a numerical exact vector representation of the features.
",1. Introduction,[0],[0]
"Typically, when faced with such large machine learning tasks, the practitioner chooses to do feature hashing (Weinberger et al., 2009).",1. Introduction,[0],[0]
Consider a 3-gram string “abc”.,1. Introduction,[0],[0]
"With feature hashing, one uses a lossy, random hash function h : strings → {0, 1, 2, . . .",1. Introduction,[0],[0]
", R} to map “abc” to a feature number h(abc) in the range {0, 1, 2, . .",1. Introduction,[0],[0]
.,1. Introduction,[0],[0]
", R}.",1. Introduction,[0],[0]
This is extremely convenient because it enables one to avoid creating a large look-up dictionary.,1. Introduction,[0],[0]
"Furthermore, this serves as a dimensionality reduction technique, reducing the problem dimension to R. Unfortunately, this convenience comes at a cost.",1. Introduction,[0],[0]
"Given that useful dimensionality reduction is strictly surjective (i.e., R < p), we lose the identity of the original features.",1. Introduction,[0],[0]
"This is not a viable option if one cares about both feature selection and interpretability.
",1. Introduction,[0],[0]
"One reason to remain hopeful is that in such highdimensional problems, the data vectors Xi are extremely sparse (Wood & Salzberg, 2014).",1. Introduction,[0],[0]
"For instance, the DNA sequence of an organism contains only a small fraction (at most the length of the DNA sequence) of p = 1612 features.",1. Introduction,[0],[0]
"The situation is similar whether we are predicting clickthrough rates of users on a website or if we seek n-gram representations of text documents (Mikolov et al., 2013).",1. Introduction,[0],[0]
"In practice, ultra high-dimensional data is almost always ultrasparse.",1. Introduction,[0],[0]
"Thus, loading a sparse data vector into memory is usually not a concern.",1. Introduction,[0],[0]
"The problem arises in the intermediate stages of traditional methods, where dense iterates need to be tracked in the main memory.",1. Introduction,[0],[0]
"One popular approach is to use greedy thresholding methods (Maleki, 2009; Mikolov et al., 2013; Jain et al., 2014; 2017) combined with stochastic gradient descent (SGD) to prevent the feature vector β from becoming too dense and blowing up in memory.",1. Introduction,[0],[0]
"In these methods, the intermediate iterates are regularized at each step, and a full gradient update is never stored nor computed (since this is memory and computation intensive).",1. Introduction,[0],[0]
"However, it is well known that greedy thresholding can be myopic and can result in poor convergence.",1. Introduction,[0],[0]
We clearly observe this phenomenon in our evaluations.,1. Introduction,[0],[0]
"See Section 5 for details.
",1. Introduction,[0],[0]
"In this paper we tackle the ultra large-scale feature selection problem, i.e., feature selection with billions or more dimensions.",1. Introduction,[0],[0]
"We propose a novel feature selection algorithm called MISSION, a Memory-efficient, Iterative Sketching algorithm for Sparse feature selectION.",1. Introduction,[0],[0]
"MISSION, that takes on all the concerns outlined above.",1. Introduction,[0],[0]
"MISSION matches the accuracy performance of existing large-scale machine learning frameworks like Vowpal Wabbit (VW) (Agarwal et al., 2014) on real-world datasets.",1. Introduction,[0],[0]
"However, in contrast to VW, MISSION can perform feature selection exceptionally well.",1. Introduction,[0],[0]
"Furthermore, MISSION significantly surpasses the performance of classical algorithms such as Iterative Hard Thresholding (IHT), which is currently the popular feature selection alternative concerning the problem sizes we consider.
",1. Introduction,[0],[0]
Contributions:,1. Introduction,[0],[0]
"In this work, we show that the two-decade old Count-Sketch data structure (Charikar et al., 2002) from the streaming algorithms literature is ideally suited for ultra large-scale feature selection.",1. Introduction,[0],[0]
The Count-Sketch data structure enables us to retain the convenience of feature hashing along with the identity of important features.,1. Introduction,[0],[0]
"Moreover, Count-Sketch can accumulate gradients updates over several iterations because of linear aggregation.",1. Introduction,[0],[0]
This aggregation eliminates the problem of myopia associated with existing greedy thresholding approaches.,1. Introduction,[0],[0]
"The aggregation phenomenon also extends to recent parallel works which employ count sketches in streaming domain (Tai et al., 2018).
",1. Introduction,[0],[0]
"In particular, we force the parameters (or feature vector) to reside in a memory-efficient Count-Sketch data structure.",1. Introduction,[0],[0]
SGD gradient updates are easily applied to the Count-Sketch.,1. Introduction,[0],[0]
"Instead of moving in the gradient direction and then greedily projecting into a subspace defined by the regularizer (e.g., in the case of LASSO-based methods), MISSION adds the gradient directly into the Count-Sketch data structure, where it aggregates with all the past updates.",1. Introduction,[0],[0]
See Fig. 1 for the schematic.,1. Introduction,[0],[0]
"At any point of time in the iteration, this data structure stores a compressed, randomized, and noisy sketch of the sum of all the gradient updates, while preserving the information of the heavy-hitters—the coordinates that accumulate the highest amount of energy.",1. Introduction,[0],[0]
"In order to find an estimate of the feature vector, MISSION queries the CountSketch.",1. Introduction,[0],[0]
"The Count-Sketch is used in conjunction with a top-k heap, which explicitly stores the features with the heaviest weights.",1. Introduction,[0],[0]
"Only the features in the top-k heap are considered active, and the rest are set to zero.",1. Introduction,[0],[0]
"However, a representation for every weight is stored, in compressed form, inside the Count-Sketch.
",1. Introduction,[0],[0]
"We demonstrate that MISSION surpasses the sparse recovery performance of classical algorithms such as Iterative Hard Thresholding (IHT), which is the only other method we could run at our scale.",1. Introduction,[0],[0]
"In addition, experiments suggest that the memory requirements of MISSION scale well with the dimensionality p of the problem.",1. Introduction,[0],[0]
"MISSION matches the
accuracy of existing large-scale machine learning frameworks like Vowpal Wabbit (VW) on real-world, large-scale datasets.",1. Introduction,[0],[0]
"Moreover, MISSION achieves comparable or even better accuracy while using significantly fewer features.",1. Introduction,[0],[0]
"In the streaming setting, we are given a high-dimensional vector β ∈",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
Rp that is too costly to store in memory.,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
We see only a very long sequence of updates over time.,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"The only information available at time t is of the form (i,∆), which means that coordinate i is incremented (or decremented) by the amount ∆. We are given a limited amount of storage, on the order of O(log p), which means that we can never store the entire sequence of updates.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"Sketching algorithms aim to estimate the value of current item i, after any number of updates using only O(log p) memory.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"Accurate estimation of heavy coordinates is desirable.
",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
Count-Sketch is a popular algorithm for estimation in the streaming setting.,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"Count-Sketch keeps a matrix of counters (or bins) S of size d×w ∼ O(log p), where d andw are chosen based on the accuracy guarantees.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"The algorithm uses d random hash functions hj for j ∈ {1, 2, ..., d} to map the vector’s components to bins w, hj : {1, 2, ..., p} → {1, 2, ..., w} Every component i of the vector is hashed to d different bins.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"In particular, for any row j of sketch S, component i is hashed into bin S(j, hj(i)).",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"In addition to hj , Count-Sketch uses d random sign functions to map the components of the vectors randomly to {+1, −1}, i.e., si : {1, 2, ..., D} → {+1,−1}.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"An illustration of this sketch data structure with three hash functions in shown inside Fig. 1.
",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
The Count-Sketch supports two operations: UPDATE(item,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"i, increment ∆) and QUERY(item i).",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
The UPDATE operation updates the sketch with any observed increment.,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"More formally, for an increment ∆ to an item i, the sketch is updated by adding sj(i)∆ to the cell S(j, hj(i))",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"∀j ∈ {1, 2, ..., d}.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"The QUERY operation returns an estimate for component i, the median of all the d different associated counters.
",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"It has been shown that, for any sequence of streaming updates (addition or subtraction) to the vector β, Count-Sketch provides an unbiased estimate of any component i, β̂i such that the following holds with high probability,
βi",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
− ||β||2 ≤ β̂i ≤,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
βi + ||β||2.,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"(1)
It can be shown that the Eq. (1) is sufficient to achieve near-optimal guarantees for sparse recovery with the given space budget.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"Furthermore, these guarantees also meet the best compressed sensing lower bounds in terms of the number of counters (or measurements) needed for sparse recovery (Indyk, 2013).",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"Consider the feature selection problem in the ultra highdimensional setting: We are given the dataset (Xi, yi) for i ∈",3. Problem Formulation,[0],[0]
"[n] = {1, 2, . . .",3. Problem Formulation,[0],[0]
",",3. Problem Formulation,[0],[0]
"n},",3. Problem Formulation,[0],[0]
where Xi ∈,3. Problem Formulation,[0],[0]
Rp and yi ∈ R denote the ith measured and response variables.,3. Problem Formulation,[0],[0]
We are interested in finding the k-sparse (k non-zero entries) feature vector (or regressor),3. Problem Formulation,[0],[0]
β ∈,3. Problem Formulation,[0],[0]
"Rp from the optimization problem
min ‖β‖0=k
‖y −Xβ‖2, (2)
",3. Problem Formulation,[0],[0]
"where X = {X1,X2, . . .",3. Problem Formulation,[0],[0]
",Xn} and y =",3. Problem Formulation,[0],[0]
"[y1, y1, . . .",3. Problem Formulation,[0],[0]
", yn] denote the data matrix and response vector and the `0-norm ‖β‖0 counts the number of non-zero entries in β.
",3. Problem Formulation,[0],[0]
We are interested in solving the feature selection problem for ultra high-dimensional datasets where the number of features p is so large that a dense vector (or matrix) of size p cannot be stored explicitly in memory.,3. Problem Formulation,[0],[0]
"Among the menagerie of feature selection algorithms, the class of hard thresholding algorithms have the smallest memory footprint: Hard thresholding algorithms retain only the top-k values and indices of the entire feature vector using O(klog(p))",3.1. Hard Thresholding Algorithms,[0],[0]
"memory (Jain et al., 2014; Blumensath & Davies, 2009).",3.1. Hard Thresholding Algorithms,[0],[0]
"The iterative hard thresholding (IHT) algorithm generates the following iterates for the ith variable in an stochastic gradient descent (SGD) framework
βt+1",3.1. Hard Thresholding Algorithms,[0],[0]
← Hk(βt − 2λ,3.1. Hard Thresholding Algorithms,[0],[0]
"( yi −Xiβt )T Xi) (3)
The sparsity of the feature vector βt, enforced by the hard thresholding operator Hk, alleviates the need to store a vector of size O(p) in the memory in order to keep track of the changes of the features over the iterates.
",3.1. Hard Thresholding Algorithms,[0],[0]
"Unfortunately, because it only retains the top-k elements of β, the hard thresholding procedure greedily discards the information of the non top-k coordinates from the previous iteration.",3.1. Hard Thresholding Algorithms,[0],[0]
"In particular, it clips off coordinates that might add to the support set in later iterations.",3.1. Hard Thresholding Algorithms,[0],[0]
"This drastically affects the performance of hard thresholding algorithms in realworld scenarios where the design matrix X is not random, normalized, or well-conditioned.",3.1. Hard Thresholding Algorithms,[0],[0]
"In this regime, the gradient terms corresponding to the true support typically arrive in lagging order and are prematurely clipped in early iterations by Hk.",3.1. Hard Thresholding Algorithms,[0],[0]
"The effect of these lagging gradients is present even in the SGD framework, because the gradients are quite noisy, and only a small fraction of the energy of the true gradient is expressed in each iteration.",3.1. Hard Thresholding Algorithms,[0],[0]
"It is not difficult to see that these small energy, high noise signals can easily cause the greedy hard thresholding operator to make sub-optimal or incorrect decisions.",3.1. Hard Thresholding Algorithms,[0],[0]
"Ideally, we want to accumulate the gradients to get enough confidence in signal and to average out any noise.
",3.1. Hard Thresholding Algorithms,[0],[0]
"Algorithm 1 MISSION Initialize: β0 = 0, S (Count-Sketch), λ (Learning Rate) while not stopping criteria do
Find the gradient update gi = λ",3.1. Hard Thresholding Algorithms,[0],[0]
( 2 (yi −Xiβt) T Xi ),3.1. Hard Thresholding Algorithms,[0],[0]
Add the gradient update to the sketch gi → S Get the top-k heavy-hitters from the sketch βt+1,3.1. Hard Thresholding Algorithms,[0],[0]
"← S end while Return: The top-k heavy-hitters from the Count-Sketch
This aforementioned problem is in fact symptomatic of all other thresholding variants including the Iterative algorithm with inversion (ITI) (Maleki, 2009) and the Partial hard thresholding (PHT) algorithm (Jain et al., 2017).",3.1. Hard Thresholding Algorithms,[0],[0]
We now describe the MISSION algorithm.,4. The MISSION Algorithm,[0],[0]
"First, we initialize the Count-Sketch S and the feature vector βt=0 with zeros entries.",4. The MISSION Algorithm,[0],[0]
The Count-Sketch hashes a p-dimensional vector into O(log2p) buckets (Recall Fig. 1).,4. The MISSION Algorithm,[0],[0]
"We discuss this particular choice for the size of the Count-Sketch and the memory-accuracy trade offs of MISSION in Sections 5.3 and 6.1.
",4. The MISSION Algorithm,[0],[0]
"At iteration t, MISSION selects a random row Xi from the data matrix X and computes the stochastic gradient update term using the learning rate λ via gi = 2λ",4. The MISSION Algorithm,[0],[0]
(yi −Xiβt) T Xi i.e. the usual gradient update that minimizes the unconstrained quadratic loss ‖y−Xβ‖22.,4. The MISSION Algorithm,[0],[0]
The data vector Xi and the corresponding stochastic gradient term are sparse.,4. The MISSION Algorithm,[0],[0]
"We then add the non-zero entries of the stochastic gradient term {gij : ∀j gij > 0} to the Count-Sketch S. Next, MISSION queries the top-k values of the sketch to form βt+1.",4. The MISSION Algorithm,[0],[0]
We repeat the same procedure until convergence.,4. The MISSION Algorithm,[0],[0]
MISSION returns the top-k values of the Count-Sketch as the final output of the algorithm.,4. The MISSION Algorithm,[0],[0]
"The MISSION algorithm is detailed in Alg. 1. MISSION easily extends to other loss functions such as the hinge loss and logistic loss.
",4. The MISSION Algorithm,[0],[0]
MISSION is Different from Greedy Thresholding:,4. The MISSION Algorithm,[0],[0]
Denote the gradient vector update at any iteration t as ut.,4. The MISSION Algorithm,[0],[0]
"It is not difficult to see that starting with an all-zero vector β0, at any point of time t, the Count-Sketch state is equivalent to the sketch of the vector ∑t i=1",4. The MISSION Algorithm,[0],[0]
ut.,4. The MISSION Algorithm,[0],[0]
"In other words, the sketch aggregates the compressed aggregated vector.",4. The MISSION Algorithm,[0],[0]
"Thus, even if an individual SGD update is noisy and contains small signal energy, thresholding the Count-Sketch is based on the average update over time.",4. The MISSION Algorithm,[0],[0]
This averaging produces a robust signal that cancels out the noise.,4. The MISSION Algorithm,[0],[0]
"We can therefore expect MISSION to be superior over thresholding.
",4. The MISSION Algorithm,[0],[0]
"In the supplementary materials, we present initial theoretical results on the convergence of MISSION.",4. The MISSION Algorithm,[0],[0]
"Our results show
that, under certain assumptions, the full-gradient-descent version of MISSION converges geometrically to the true parameter β ∈",4. The MISSION Algorithm,[0],[0]
Rp up to some additive constants.,4. The MISSION Algorithm,[0],[0]
"The exploration of these assumptions and the extension to the SGD version of MISSION are exciting avenues for future work.
",4. The MISSION Algorithm,[0],[0]
"Feature Selection with the Ease of Feature Hashing: As argued earlier, the features are usually represented with strings, and we do not have the capability to map each string to a unique index in a vector without spendingO(p) memory.",4. The MISSION Algorithm,[0],[0]
"Feature hashing is convenient, because we can directly access every feature using hashes.",4. The MISSION Algorithm,[0],[0]
We can use any lossy hash function for strings.,4. The MISSION Algorithm,[0],[0]
MISSION only needs a few independent hash functions (3 in our Count-Sketch implementation) to access any component.,4. The MISSION Algorithm,[0],[0]
"The top-k estimation is done efficiently using a heap data structure of size k. Overall, we only access the data using efficient hash functions, which can be easily implemented in large-scale systems.",4. The MISSION Algorithm,[0],[0]
We designed a set of simulations to evaluate MISSION in a controlled setting.,5. Simulations,[0],[0]
"In contrast to the ultra large-scale, real-world experiments of Section 6, in the section the data matrices are drawn from a random Gaussian distribution and the ground truth features are known.",5. Simulations,[0],[0]
We first demonstrate the advantage of MISSION over greedy thresholding in feature selection.,5.1. Phase Transition,[0],[0]
"For this experiment, we modify MISSION slightly to find the root of the algorithmic advantage of MISSION: we replace the Count-Sketch with an “identity” sketch, or a sketch with a single hash function, h(i) = i.",5.1. Phase Transition,[0],[0]
"In doing so, we eliminate the complexity that Count-Sketch adds to the algorithm, so that the main difference between MISSION and IHT is that MISSION accumulates the gradients.",5.1. Phase Transition,[0],[0]
"To improve stability, we scale the non top-k elements of S by a factor γ ∈ (0, 1) that begins very near 1 and is gradually decreased until the algorithm converges.",5.1. Phase Transition,[0],[0]
"It is also possible to do this scaling in the CountSketch version of MISSION efficiently by exploiting the linearity of the sketch.
",5.1. Phase Transition,[0],[0]
Fig. 2 illustrates the empirical phase transition curves for sparse recovery using MISSION and the hard thresholding algorithms.,5.1. Phase Transition,[0],[0]
The phase transition curves show the points where the algorithm successfully recovers the features in > 50% of the random trails.,5.1. Phase Transition,[0],[0]
"MISSION shows a better phase transition curve compared to IHT by a considerable gap.
",5.1. Phase Transition,[0],[0]
Table 1.,5.1. Phase Transition,[0],[0]
Comparison of MISSION against hard thresholding algorithms in feature selection under adversarial effects.,5.1. Phase Transition,[0],[0]
We first report the percentage of instances in which the algorithms accurately find the solution (ACC) with no attenuation (α = 1) over 100 random trials.,5.1. Phase Transition,[0],[0]
"We then report the mean of the maximum level of attenuation α applied to the columns of design X before the algorithms fail to recover the support of β (over the trials that all algorithms can find the solution with α = 1).
",5.1. Phase Transition,[0],[0]
"(n, k) MISSION IHT ITI PHT",5.1. Phase Transition,[0],[0]
ACCα=1 α,5.1. Phase Transition,[0],[0]
ACCα=1 α,5.1. Phase Transition,[0],[0]
ACCα=1 α,5.1. Phase Transition,[0],[0]
"ACCα=1 α (100, 2) 100% 2.68 ± 0.37 100% 1.49 ± 0.33 91% 1.33 ± 0.23 64% 2.42 ± 0.87 (100, 3) 100% 2.52 ± 0.36 92% 1.36 ± 0.46 70% 1.15 ± 0.20 42% 2.05 ± 0.93 (100, 4) 100% 2.53 ± 0.23 72% 1.92 ± 0.91 37% 1.03 ± 0.09 39% 2.13 ± 1.07 (200, 5) 100% 4.07 ± 0.36 99",5.1. Phase Transition,[0],[0]
"% 2.34 ± 1.12 37% 1.15 ± 0.22 83% 2.75 ± 1.30 (200, 6) 100% 4.17 ± 0.24 97% 2.64 ± 1.14 23% 1.11 ± 0.12 73% 2.26 ± 1.33 (200, 7) 100% 4.07 ± 0.11 83% 1.64 ± 1.01 14% 1.11 ± 0.12 75% 3.39 ± 1.36
0.0 0.2 0.4 0.6 0.8 1.0
n/p
0.0
0.2
0.4
0.6
0.8
1.0
s/ n
MISSION IHT ITI",5.1. Phase Transition,[0],[0]
"PHT
Figure 2.",5.1. Phase Transition,[0],[0]
Empirical phase transition in recovering a binary feature vector β in p = 1000-dimensional space with a Gaussian data matrix X.,5.1. Phase Transition,[0],[0]
We illustrate the empirical 50% probability of success curves averaged over T = 20 trials.,5.1. Phase Transition,[0],[0]
MISSION outperforms the thresholding algorithms by a large margin.,5.1. Phase Transition,[0],[0]
"A major problem with the IHT algorithm, especially in largescale SGD settings, is with thresholding the coordinates with small gradients in the earlier iterations.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"IHT misses these coordinates, since they become prominent only after the gradients accumulate with the progression of the algorithm.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"The problem is amplified with noisy gradient updates such as SGD, which is unavoidable for large datasets.
",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
This phenomenon occurs frequently in sparse recovery problems.,5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"For example, when the coordinates that correspond to the columns of the data matrix with smaller energy lag in the iterations of gradient descent algorithm, IHT thresholds these lagging-gradient coordinates in first few iterations, and they never show up again in the support.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"In contrast, MISSION retains a footprint of the gradients of all the previous iterations in the Count-Sketch.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"When the total sum of the gradient of a coordinate becomes prominent, the coordinate joins the support after querying the top-k heavy hitters from the Count-Sketch.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
We illustrate this phenomena in sparse recovery using synthetic experiments.,5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"We recover sparse vector β from its random linear measurements y = Xβ, where the energy of X is imbalanced across its columns.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"In this case, the gradients corresponding to the
columns (coordinates) with smaller energy typically lag and are thresholded by IHT.
",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"To this end, we first construct a random Gaussian data matrix X ∈ R900×1000, pick a sparse vector β that is supported on an index set I , and then attenuate the energy of the columns of X supported by the indices in I by an attenuation factor of α = {1, 1.25, 1.5, 1.75, 2, . . .",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
", 5}.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
Note that α = 1 implies that no attenuation is applied to the matrix.,5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"In Table 1, we report the maximum attenuation level applied to a column of data matrix X before the algorithms fail to fully recover the support set I from y = βX.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"We observe that MISSION is consistently and up to three times more robust against adversarial attenuation of the columns of the data matrix in various design settings.
",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
The robustness of MISSION to the attenuation of the columns of X in sparse recovery task suggests that the Count-Sketch data structure enables gradient-based optimization methods such as IHT to store a footprint (or sketch) of all the gradients from the previous iterations and deliver them back when they become prominent.,5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"in MISSION
In this section we demonstrate that the memory requirements of MISSION grows polylogarithmically in the dimension of the problem p.",5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
We conduct a feature selection experiment with a data matrix X ∈ R100×p whose entries are drawn from i.i.d. random Gaussian distributions with zero mean and unit variance.,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
"We run MISSION and IHT to recover the feature vector β from the output vector y = Xβ, where the feature vector β is a k = 5-sparse vector with random support.",5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
We repeat the same experiment 1000 times with different realizations for the sparse feature vector β and report the results in Fig. 3.,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
The left plot illustrates the feature selection accuracy of the algorithms as the dimension of the problem p grows.,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
"The right plot illustrates the minimum memory requirements of the algorithms to recover the features with 100% accuracy.
",5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
The size of the Count-Sketch in MISSION scales only polylogarithmically with the dimension of the problem.,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
This is surprising since the aggregate gradient in a classical SGD framework becomes typically dense in early iterations and thus requires a memory of order O(p).,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
"MISSION, however, stores only the essential information of the features in the sketch using a poly-logarithmic sketch size.",5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
Note that IHT sacrifices accuracy to achieve a small memory footprint.,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
At every iteration IHT eliminates all the information except for the top-k features.,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
"We observe that, using only a logarithmic factor more memory, MISSION has a significant advantage over IHT in recovering the ground truth features.",5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
"All experiments were performed on a single machine, 2x Intel Xeon E5-2660 v4 processors (28 cores / 56 threads) with 512 GB of memory.",6. Experiments,[0],[0]
The code1 for training and running our randomized-hashing approach is available online.,6. Experiments,[0],[0]
"We designed the experiments to answer these questions:
1.",6. Experiments,[0],[0]
Does MISSION outperform IHT in terms of classification accuracy?,6. Experiments,[0],[0]
"In particular, how much does myopic thresholding affect IHT in practice?
2.",6. Experiments,[0],[0]
"How well does MISSION match the speed and accuracy of feature hashing (FH)?
3.",6. Experiments,[0],[0]
"How does changing the number of top-k features affect the accuracy and behaviour of the different methods?
4.",6. Experiments,[0],[0]
"What is the effect of changing the memory size of the Count-Sketch data structure on the classification accuracy of MISSION in read-world datasets?
5.",6. Experiments,[0],[0]
"Does MISSION scale well in comparison to the different methods on the ultra large-scale datasets (> 350 GB in size)?
1https://github.com/rdspring1/MISSION",6. Experiments,[0],[0]
"Datasets: We used four datasets in the experiments: 1) KDD2012, 2) RCV1, 3) Webspam–Trigram, 4) DNA2.",6.1. Large-scale Feature Extraction,[0],[0]
"The statistics of these datasets are summarized in Table 2.
",6.1. Large-scale Feature Extraction,[0],[0]
The DNA metagenomics dataset is a multi-class classification task where the model must classify 15 different bacteria species using DNA K-mers.,6.1. Large-scale Feature Extraction,[0],[0]
We sub-sampled the first 15 species from the original dataset containing 193 species.,6.1. Large-scale Feature Extraction,[0],[0]
We use all of the species in the DNA Metagenomics dataset for the large-scale experiments (See Section 6.2).,6.1. Large-scale Feature Extraction,[0],[0]
"Following standard procedures, each bacterial species is associated with a reference genome.",6.1. Large-scale Feature Extraction,[0],[0]
Fragments are sampled from the reference genome until each nucleotide is covered c times on average.,6.1. Large-scale Feature Extraction,[0],[0]
The fragments are then divided into K-mer sub-strings.,6.1. Large-scale Feature Extraction,[0],[0]
We used fragments of length 200 and K-mers of length 12.,6.1. Large-scale Feature Extraction,[0],[0]
"Each model was trained and tested with mean coverage c = {0.1, 1} respectively.",6.1. Large-scale Feature Extraction,[0],[0]
"For more details, see (Vervier et al., 2016).",6.1. Large-scale Feature Extraction,[0],[0]
"The feature extraction task is to find the DNA K-mers that best represent each bacteria class.
",6.1. Large-scale Feature Extraction,[0],[0]
"We implemented the following approaches to compare and contrast against our approach: For all methods, we used the logistic loss for binary classification and the cross-entropy loss for multi-class classification.
MISSION:",6.1. Large-scale Feature Extraction,[0],[0]
As described in Section 4.,6.1. Large-scale Feature Extraction,[0],[0]
"Iterative Hard Thresholding (IHT): An algorithm where, after each gradient update, a hard threshold is applied to the features.",6.1. Large-scale Feature Extraction,[0],[0]
"Only the top-k features are kept active, while the rest are set to zero.",6.1. Large-scale Feature Extraction,[0],[0]
"Since the features are strings or integers, we used a sorted heap to store and manipulate the top-k elements.",6.1. Large-scale Feature Extraction,[0],[0]
This was the only algorithm we could successfully run over the large datasets on our single machine.,6.1. Large-scale Feature Extraction,[0],[0]
Batch IHT: A modification to IHT that uses mini-batches such that the gradient sparsity is the same as the number of elements in the count-sketch.,6.1. Large-scale Feature Extraction,[0],[0]
We accumulate features and then sort and prune to find the top-k features.,6.1. Large-scale Feature Extraction,[0],[0]
"This accumulate, sort, prune process is repeated several times during training.",6.1. Large-scale Feature Extraction,[0],[0]
Note:,6.1. Large-scale Feature Extraction,[0],[0]
"This setup requires significantly more memory than MISSION, because it explicitly stores the feature strings.",6.1. Large-scale Feature Extraction,[0],[0]
The memory cost of maintaining a set of string features can be orders of magnitude more than the flat array used by MISSION.,6.1. Large-scale Feature Extraction,[0],[0]
"See Bloom Filters (Broder & Mitzenmacher, 2004) and related literature.",6.1. Large-scale Feature Extraction,[0],[0]
"This setup is not scalable to large-scale datasets.
",6.1. Large-scale Feature Extraction,[0],[0]
"2http://projects.cbio.mines-paristech.fr/ largescalemetagenomics/
Feature Hashing (FH): A standard machine learning algorithm for dimensionality reduction that reduces the memory cost associated with large datasets.",6.1. Large-scale Feature Extraction,[0],[0]
FH is not a feature selection algorithm and cannot identify important features.,6.1. Large-scale Feature Extraction,[0],[0]
"(Agarwal et al., 2014)
",6.1. Large-scale Feature Extraction,[0],[0]
Experimental Settings: The MISSION and IHT algorithms searched for the same number of top-k features.,6.1. Large-scale Feature Extraction,[0],[0]
"To ensure fair comparisons, the size of the Count-Sketch and the feature vector allocated for the FH model were equal.",6.1. Large-scale Feature Extraction,[0],[0]
The size of the MISSION and FH models were set to the nearest power of 2 greater than the number of features in the dataset.,6.1. Large-scale Feature Extraction,[0],[0]
"For all the experiments, the Count-Sketch data structure used 3 hash functions, and the model weights were divided equally among the hash arrays.",6.1. Large-scale Feature Extraction,[0],[0]
"For example, with the (Tiny) DNA metagenomics dataset, we allocated 24 bits or 16,777,216 weights for the FH model.",6.1. Large-scale Feature Extraction,[0],[0]
"Given 3 hash functions and 15 classes, roughly 372,827 elements were allocated for each class in the Count-Sketch.
MISSION, IHT, FH Comparison: Fig. 4 shows that MISSION surpasses IHT in classification accuracy in all four datasets, regardless of the number of features.",6.1. Large-scale Feature Extraction,[0],[0]
"In addition, MISSION closely matches FH, which is significant because FH is allowed to model a much larger set of features than MISSION or IHT.",6.1. Large-scale Feature Extraction,[0],[0]
"MISSION is 2–4× slower than FH, which is expected given that MISSION has the extra overhead of using a heap to track the top-k features.
MISSION’s accuracy rapidly rises with respect to the number of top-k features, while IHT’s accuracy plateaus and then grows slowly to match MISSION.",6.1. Large-scale Feature Extraction,[0],[0]
This observation corroborates our insight that the greedy nature of IHT hurts performance.,6.1. Large-scale Feature Extraction,[0],[0]
"When the number of top-k elements is small, the capacity of IHT is limited, so it picks the first set of features that provides good performance, ignoring the rest.",6.1. Large-scale Feature Extraction,[0],[0]
"On the other hand, MISSION decouples the memory from the top-k ranking, which is based on the aggregated gradients in the compressed sketch.",6.1. Large-scale Feature Extraction,[0],[0]
"By the linear property of the count-sketch, this ensures that the heavier entries occur in the top-k features with high probability.
",6.1. Large-scale Feature Extraction,[0],[0]
"Count-Sketch Memory Trade-Off: Fig. 5 shows how MISSION’s accuracy degrades gracefully, as the size of the Count-Sketch decreases.",6.1. Large-scale Feature Extraction,[0],[0]
"In this experiment, MISSION only used the top 500K features for classifying the Tiny DNA metagenomics dataset.",6.1. Large-scale Feature Extraction,[0],[0]
"When the top-k to Count-Sketch ratio is 1, then 500K weights were allocated for each class and hash array in the Count-Sketch data structure.",6.1. Large-scale Feature Extraction,[0],[0]
"The Batch IHT baseline was given 8,388,608 memory elements per class, enabling it to accumulate a significant number of features before thresholding to find the top-k features.",6.1. Large-scale Feature Extraction,[0],[0]
"This experiment shows that MISSION immediately outperforms IHT and Batch IHT, once the top-k to Count-Sketch ratio is 1:1.",6.1. Large-scale Feature Extraction,[0],[0]
"Thus, MISSION provides a unique memory-accuracy knob at any given value of top-k.",6.1. Large-scale Feature Extraction,[0],[0]
"Here we demonstrate that MISSION can extract features from three large-scale datasets: Criteo 1TB, Splice-Site, and DNA Metagenomics.
",6.2. Ultra Large-Scale Feature Selection,[0],[0]
Criteo 1TB: The Criteo 1TB3 dataset represents 24 days of click-through logs—23 days (training) + 1 day (testing).,6.2. Ultra Large-Scale Feature Selection,[0],[0]
The task for this dataset is click-through rate (CTR) prediction— How likely is a user to click an ad?,6.2. Ultra Large-Scale Feature Selection,[0],[0]
The dataset contains over 4 billion (training) and 175 million (testing) examples (2.5 TB of disk space).,6.2. Ultra Large-Scale Feature Selection,[0],[0]
The performance metric is Area Under the ROC Curve (AUC).,6.2. Ultra Large-Scale Feature Selection,[0],[0]
The VW baseline4 achieved 0.7570 AUC score.,6.2. Ultra Large-Scale Feature Selection,[0],[0]
"MISSION and IHT scored close to the VW baseline with 0.751 AUC using only the top 250K features.
",6.2. Ultra Large-Scale Feature Selection,[0],[0]
Splice-Site: The task for this dataset is to distinguish between true and fake splice sites using the local context around the splice site in-question.,6.2. Ultra Large-Scale Feature Selection,[0],[0]
"The dataset is highly skewed (few positive, many negative values), and so the performance metric is average precision (AP).",6.2. Ultra Large-Scale Feature Selection,[0],[0]
Average precision is the precision score averaged over all recall scores ranging from 0 to 1.,6.2. Ultra Large-Scale Feature Selection,[0],[0]
The dataset contains over 50 million (training) and 4.6 million (testing) examples (3.2 TB of disk space).,6.2. Ultra Large-Scale Feature Selection,[0],[0]
All the methods were trained for a single epoch with a learning rate of 0.5.,6.2. Ultra Large-Scale Feature Selection,[0],[0]
"MISSION, Batch IHT, and SGD IHT tracked the top 16,384 features.",6.2. Ultra Large-Scale Feature Selection,[0],[0]
"FH, MISSION, and Batch IHT used 786,432 extra memory elements.",6.2. Ultra Large-Scale Feature Selection,[0],[0]
MISSION significantly outperforms Batch IHT and SGD IHT by 2.3%.,6.2. Ultra Large-Scale Feature Selection,[0],[0]
"Also, unlike in Fig. 5, the extra memory did not help Batch IHT, since it performed the same as SGD IHT.",6.2. Ultra Large-Scale Feature Selection,[0],[0]
MISSION (17.5 hours) is 15% slower than FH (15 hours) in wall-clock running time.,6.2. Ultra Large-Scale Feature Selection,[0],[0]
DNA Metagenomics:,AP 0.522 0.510 0.498 0.498,[0],[0]
This experiment evaluates MISSION’s performance on a medium-sized metagenomics dataset.,AP 0.522 0.510 0.498 0.498,[0],[0]
"The parameters from the Tiny (15 species) dataset in Section 6.1 are shared with this experiment, except the
3https://www.kaggle.com/c/criteo-display-ad-challenge 4https://github.com/rambler-digital-solutions/
criteo-1tb-benchmark
DNA - Tiny (15 Species) - Top-K: 500K
number of species is increased to 193.",AP 0.522 0.510 0.498 0.498,[0],[0]
The size of a sample batch with mean coverage c = 1 increased from 7 GB (Tiny) to 68 GB (Medium).,AP 0.522 0.510 0.498 0.498,[0],[0]
Each round (mean coverage c = 0.25) contains 3.45 million examples and about 16.93 million unique non-zero features (p).,AP 0.522 0.510 0.498 0.498,[0],[0]
MISSION and IHT tracked the top 2.5 million features per class.,AP 0.522 0.510 0.498 0.498,[0],[0]
"The FH baseline used 231 weights, about 11.1 million weights per class, and we allocated the same amount of space for the Count-Sketch.",AP 0.522 0.510 0.498 0.498,[0],[0]
"Each model was trained on a dataset with coverage c = 5.
",AP 0.522 0.510 0.498 0.498,[0],[0]
"Fig. 6 shows the evolution of classification accuracy over time for MISSION, IHT, and the FH baseline.",AP 0.522 0.510 0.498 0.498,[0],[0]
"After 5 epochs, MISSION closely matches the FH baseline.",AP 0.522 0.510 0.498 0.498,[0],[0]
"Note: MISSION converges faster than IHT such that MISSION is 1–4 rounds ahead of IHT, with the gap gradually increasing over time.",AP 0.522 0.510 0.498 0.498,[0],[0]
"On average, the running time of MISSION is 1–2× slower than IHT.",AP 0.522 0.510 0.498 0.498,[0],[0]
"However, this experiment demonstrates that since MISSION converges faster, it actually needs less time to reach a certain accuracy level.",AP 0.522 0.510 0.498 0.498,[0],[0]
"Therefore, MISSION is effectively faster and more accurate than IHT.",AP 0.522 0.510 0.498 0.498,[0],[0]
"Scalability and Parallelism: IHT finds the top-k features after each gradient update, which requires sorting the features based on their weights before thresholding.",7. Implementation Details and Discussion,[0],[0]
"The speed of the sorting process is improved by using a heap data
DNA - Medium (193 Species) - Top-K: 2.5M
structure, but it is still costly per update.",7. Implementation Details and Discussion,[0],[0]
"MISSION also uses a heap to store its top-k elements, but it achieves the same accuracy as IHT with far fewer top-k elements because of the Count-Sketch.",7. Implementation Details and Discussion,[0],[0]
"(Recall Section 4)
",7. Implementation Details and Discussion,[0],[0]
Another suggested improvement for the top-k heap is to use lazy updates.,7. Implementation Details and Discussion,[0],[0]
"Updating the weight of a feature does not change its position in the heap very often, but still requires an O(log n) operation.",7. Implementation Details and Discussion,[0],[0]
"With lazy updates, the heap is updated only if it the change is significant.",7. Implementation Details and Discussion,[0],[0]
|xt,7. Implementation Details and Discussion,[0],[0]
"− x0| ≥ , i.e. the new weight at time t exceeds the original value by some threshold.",7. Implementation Details and Discussion,[0],[0]
This tweak significantly reduces the number of heap updates at the cost of slightly distorting the heap.,7. Implementation Details and Discussion,[0],[0]
"In this paper, we presented MISSION, a new framework for ultra large-scale feature selection which maintains an efficient, approximate representation for the features using a Count-Sketch data structure.",8. Conclusion and Future Work,[0],[0]
"MISSION retains the simplicity of feature hashing without sacrificing the interpretability of the features.
",8. Conclusion and Future Work,[0],[0]
"Going forward, we are interested in leveraging our MISSION framework to explore pairwise or higher-order interaction features.",8. Conclusion and Future Work,[0],[0]
"Interaction features are important for scientific discovery, e.g., in genomics (Basu et al., 2018), however, the exponential dimensionality growth of interactions has hindered further progress.",8. Conclusion and Future Work,[0],[0]
We believe MISSION will enable more scientific discoveries from big data in future.,8. Conclusion and Future Work,[0],[0]
"AAA, DL, GD, and RB were supported by the DOD Vannevar Bush Faculty Fellowship grant N00014-18-1-2047, NSF grant CCF-1527501, ARO grant W911NF-15-1-0316, AFOSR grant FA9550-14-1-0088, ONR grant N00014-17-12551, DARPA REVEAL grant HR0011-16-C-0028, and an ONR BRC grant for Randomized Numerical Linear Algebra.",Acknowledgements,[0],[0]
"RS and AS were supported by NSF-1652131, AFOSR-YIP FA9550-18-1-0152, and ONR BRC grant for Randomized Numerical Linear Algebra.",Acknowledgements,[0],[0]
The authors would also like to thank NVIDIA and Amazon for gifting computing resources.,Acknowledgements,[0],[0]
Feature selection is an important challenge in machine learning.,abstractText,[0],[0]
It plays a crucial role in the explainability of machine-driven decisions that are rapidly permeating throughout modern society.,abstractText,[0],[0]
"Unfortunately, the explosion in the size and dimensionality of real-world datasets poses a severe challenge to standard feature selection algorithms.",abstractText,[0],[0]
"Today, it is not uncommon for datasets to have billions of dimensions.",abstractText,[0],[0]
"At such scale, even storing the feature vector is impossible, causing most existing feature selection methods to fail.",abstractText,[0],[0]
"Workarounds like feature hashing, a standard approach to large-scale machine learning, helps with the computational feasibility, but at the cost of losing the interpretability of features.",abstractText,[0],[0]
"In this paper, we present MISSION, a novel framework for ultra large-scale feature selection that performs stochastic gradient descent while maintaining an efficient representation of the features in memory using a Count-Sketch data structure.",abstractText,[0],[0]
MISSION retains the simplicity of feature hashing without sacrificing the interpretability of the features while using only O(log p) working memory.,abstractText,[0],[0]
"We demonstrate that MISSION accurately and efficiently performs feature selection on real-world, large-scale datasets with billions of dimensions.",abstractText,[0],[0]
MISSION: Ultra Large-Scale Feature Selection using Count-Sketches,title,[0],[0]
Many modern data sets consist of data that is gathered adaptively: the choice of whether to collect more data points of a given type depends on the data already collected.,1. Introduction,[0],[0]
"For example, it is common in industry to conduct “A/B” tests to make decisions about many things, including ad targeting, user interface design, and algorithmic modifications, and this A/B testing is often conducted using “bandit learning algorithms”",1. Introduction,[0],[0]
"(Bubeck et al., 2012), which adaptively select treatments to show to users in an effort to find the best treatment as quickly as possible.",1. Introduction,[0],[0]
"Similarly, sequen-
1Department of Statistics, The Wharton School, University of Pennsylvania 2Department of Computer Science, University of Pennsylvania.",1. Introduction,[0],[0]
Correspondence to: Seth Neel,1. Introduction,[0],[0]
"<sethneel93@gmail.com>, Aaron Roth <aaroth@cis.upenn.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"1This extended abstract is missing many details, proofs, and results that can be found in the full version (Neel & Roth, 2018).
",1. Introduction,[0],[0]
"tial clinical trials may halt or re-allocate certain treatment groups due to preliminary results, and empirical scientists may initially try and test multiple hypotheses and multiple treatments, but then decide to gather more data in support of certain hypotheses and not others, based on the results of preliminary statistical tests.
",1. Introduction,[0],[0]
"Unfortunately, as demonstrated by (Nie et al., 2017), the data that results from adaptive data gathering procedures will often exhibit substantial bias.",1. Introduction,[0],[0]
"As a result, subsequent analyses that are conducted on the data gathered by adaptive procedures will be prone to error, unless the bias is explicitly taken into account.",1. Introduction,[0],[0]
This can be difficult.,1. Introduction,[0],[0]
"(Nie et al., 2017) give a selective inference approach: in simple stochastic bandit settings, if the data was gathered by a specific stochastic algorithm that they design, they give an MCMC based procedure to perform maximum likelihood estimation to recover de-biased estimates of the underlying distribution means.",1. Introduction,[0],[0]
"In this paper, we give a related, but orthogonal approach whose simplicity allows for a substantial generalization beyond the simple stochastic bandits setting.",1. Introduction,[0],[0]
"We show that in very general settings, if the data is gathered by a differentially private procedure, then we can place strong bounds on the bias of the data gathered, without needing any additional de-biasing procedure.",1. Introduction,[0],[0]
"Via elementary techniques, this connection implies the existence of simple stochastic bandit algorithms with nearly optimal worst-case regret bounds, with very strong bias guarantees.",1. Introduction,[0],[0]
"By leveraging existing connections between differential privacy and adaptive data analysis (Dwork et al., 2015c; Bassily et al., 2016; Rogers et al., 2016), we can extend the generality of our approach to bound not just bias, but to correct for effects of adaptivity on arbitrary statistics of the gathered data.",1. Introduction,[0],[0]
"Since the data being gathered will generally be useful for some as yet unspecified scientific analysis, rather than just for the narrow problem of mean estimation, our technique allows for substantially broader possibilities compared to past approaches.",1. Introduction,[0],[0]
"This paper has three main contributions:
1.",1.1. Our Results,[0],[0]
"Using elementary techniques, we provide explicit bounds on the bias of empirical arm means maintained by bandit algorithms in the simple stochastic
setting that make their selection decisions as a differentially private function of their observations.",1.1. Our Results,[0],[0]
"Together with existing differentially private algorithms for stochastic bandit problems, this yields an algorithm that obtains an essentially optimal worst-case regret bound, and guarantees minimal bias (on the order of O(1/ √ K · T )) for the empirical mean maintained for every arm.",1.1. Our Results,[0],[0]
"In the full version (Neel & Roth, 2018), we also extend our results to the linear contextual bandit problem, proving new bounds for a private linear UCB algorithm along the way.
2.",1.1. Our Results,[0],[0]
"We then make a general observation, relating adaptive data gathering to an adaptive analysis of a fixed dataset (in which the choice of which query to pose to the dataset is adaptive).",1.1. Our Results,[0],[0]
This lets us apply the large existing literature connecting differential privacy to adaptive data analysis.,1.1. Our Results,[0],[0]
"In particular, it lets us apply the max-information bounds of (Dwork et al., 2015b; Rogers et al., 2016) to our adaptive data gathering setting.",1.1. Our Results,[0],[0]
"This allows us to give much more general guarantees about the data collected by differentially private collection procedures, that extend well beyond bias.",1.1. Our Results,[0],[0]
"For example, it lets us correct the p-values for arbitrary hypothesis tests run on the gathered data.
",1.1. Our Results,[0],[0]
3.,1.1. Our Results,[0],[0]
"Finally, we run a set of experiments that measure the bias incurred by the standard UCB algorithm in the stochastic bandit setting, contrast it with the low bias obtained by a private UCB algorithm, and show that there are settings of the privacy parameter that simultaneously can make bias statistically insignificant, while having competitive empirical regret with the non-private UCB algorithm.",1.1. Our Results,[0],[0]
We also demonstrate in the linear contextual bandit setting how failing to correct for adaptivity can lead to false discovery when applying t-tests for non-zero regression coefficients on an adaptively gathered dataset.,1.1. Our Results,[0],[0]
This paper bridges two recent lines of work.,1.2. Related Work,[0],[0]
"Our starting point is two recent papers: (Villar et al., 2015) empirically demonstrate in the context of clinical trials that a variety of simple stochastic bandit algorithms produce biased sample mean estimates (Similar results have been empirically observed in the context of contextual bandits (Dimakopoulou et al., 2017)).",1.2. Related Work,[0],[0]
"(Nie et al., 2017) prove that simple stochastic bandit algorithms that exhibit two natural properties (satisfied by most commonly used algorithms, including UCB and Thompson Sampling) result in empirical means that exhibit negative bias.",1.2. Related Work,[0],[0]
"They then propose a heuristic algorithm which computes a maximum likelihood estimator for the sample means from the empirical means gathered by a modified UCB algorithm which adds Gumbel noise to
the decision statistics.",1.2. Related Work,[0],[0]
"(Deshpande et al., 2017) propose a debiasing procedure for ordinary least-squares estimates computed from adaptively gathered data that trades off bias for variance, and prove a central limit theorem for their method.",1.2. Related Work,[0],[0]
"In contrast, the methods we propose in this paper are quite different.",1.2. Related Work,[0],[0]
"Rather than giving an ex-post debiasing procedure, we show that if the data were gathered in a differentially private manner, no debiasing is necessary.",1.2. Related Work,[0],[0]
"The strength of our method is both in its simplicity and generality: rather than proving theorems specific to particular estimators, we give methods to correct the p-values for arbitrary hypothesis tests that might be run on the adaptively gathered data.
",1.2. Related Work,[0],[0]
"The second line of work is the recent literature on adaptive data analysis (Dwork et al., 2015c;b; Hardt & Ullman, 2014; Steinke & Ullman, 2015; Russo & Zou, 2016; Wang et al., 2016; Bassily et al., 2016; Hardt & Blum, 2015; Cummings et al., 2016; Feldman & Steinke, 2017a;b) which draws a connection between differential privacy (Dwork et al., 2006) and generalization guarantees for adaptively chosen statistics.",1.2. Related Work,[0],[0]
"The adaptivity in this setting is dual to the setting we study in the present paper: In the adaptive data analysis literature, the dataset itself is fixed, and the goal is to find techniques that can mitigate bias due to the adaptive selection of analyses.",1.2. Related Work,[0.9593711784685804],"['Once the model is trained end to end, we analyze the efficacies in the DFG to study the fusion mechanism learned for modalities in multimodal language.']"
"In contrast, here, we study a setting in which the data gathering procedure is itself adaptive, and can lead to bias even for a fixed set of statistics of interest.",1.2. Related Work,[0],[0]
"However, we show that adaptive data gathering can be re-cast as an adaptive data analysis procedure, and so the results from the adaptive data analysis literature can be ported over.",1.2. Related Work,[0],[0]
"In a simple stochastic bandit problem, there are K unknown distributions Pi over the unit interval [0,1], each with (unknown) mean µi.",2.1. Simple Stochastic Bandit Problems,[0],[0]
"Over a series of rounds t ∈ {1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", T}, an algorithm A chooses an arm it ∈",2.1. Simple Stochastic Bandit Problems,[0],[0]
"[K], and observes a reward yit,t ∼ Pit .",2.1. Simple Stochastic Bandit Problems,[0],[0]
"Given a sequence of choices i1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", iT , the pseudo-regret of an algorithm is defined to be:
Regret((P1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", PK), i1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", iT )",2.1. Simple Stochastic Bandit Problems,[0],[0]
= T ·max i µi − T∑ t=1,2.1. Simple Stochastic Bandit Problems,[0],[0]
"µit
We say that regret is bounded if we can put a bound on the quantity Regret((P1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", PK), i1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", iT ) in the worst case over the choice of distributions P1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", PK , and with high probability or in expectation over the randomness of the algorithm and of the reward sampling.
",2.1. Simple Stochastic Bandit Problems,[0],[0]
"As an algorithm A interacts with a bandit problem, it generates a history Λ , which records the sequence of actions
taken and rewards observed thus far:",2.1. Simple Stochastic Bandit Problems,[0],[0]
"Λt = {(i`, yi`,`)} t−1 `=1.",2.1. Simple Stochastic Bandit Problems,[0],[0]
"We denote the space of histories of length T by HT = ([K]× R)T .
",2.1. Simple Stochastic Bandit Problems,[0],[0]
The definition of an algorithm A induces a sequence of T (possibly randomized) selection functions ft : Ht−1,2.1. Simple Stochastic Bandit Problems,[0],[0]
"→ [K], which map histories onto decisions of which arm to pull at each round.",2.1. Simple Stochastic Bandit Problems,[0],[0]
"In the contextual bandit problem, decisions are endowed with observable features.",2.2. Contextual Bandit Problems,[0],[0]
"Our algorithmic results in this paper focus on the linear contextual bandit problem, but our general connection between adaptive data gathering and differential privacy extends beyond the linear case.",2.2. Contextual Bandit Problems,[0],[0]
"For simplicity of exposition, we specialize to the linear case here.
",2.2. Contextual Bandit Problems,[0],[0]
"There are K arms i, each of which is associated with an unknown d-dimensional linear function represented by a vector of coefficients θi ∈ Rd with ||θi||2 ≤ 1.",2.2. Contextual Bandit Problems,[0],[0]
"In rounds t ∈ {1, . . .",2.2. Contextual Bandit Problems,[0],[0]
", T}, the algorithm is presented with a context xi,t ∈ Rd for each arm i with ||xi,t||2 ≤ 1, which may be selected by an adaptive adversary as a function of the past history of play.",2.2. Contextual Bandit Problems,[0],[0]
"We write xt to denote the set of all K contexts present at round t. As a function of these contexts, the algorithm then selects an arm it, and observes a reward yit,t. The rewards satisfy E [yi,t] = θi·xi,t and are bounded to lie in [0, 1].
",2.2. Contextual Bandit Problems,[0],[0]
"In the contextual setting, histories incorporate observed context information as well:",2.2. Contextual Bandit Problems,[0],[0]
"Λt = {(i`, x`, yi`,`)} t−1 `=1.
",2.2. Contextual Bandit Problems,[0],[0]
"Again, the definition of an algorithmA induces a sequence of T (possibly randomized) selection functions ft : Ht−1× Rd×K → [K], which now maps both a history and a set of contexts at round t to a choice of arm at round t.",2.2. Contextual Bandit Problems,[0],[0]
"Above we’ve characterized a bandit algorithmA as gathering data adaptively using a sequence of selection functions ft, which map the observed history",2.3. Data Gathering in the Query Model,[0],[0]
Λt ∈ Ht−1 to the index of the next arm pulled.,2.3. Data Gathering in the Query Model,[0],[0]
In this model only after the arm is chosen is a reward drawn from the appropriate distribution.,2.3. Data Gathering in the Query Model,[0],[0]
"Then the history is updated, and the process repeats.
",2.3. Data Gathering in the Query Model,[0],[0]
"In this section, we observe that whether the reward is drawn after the arm is “pulled,” or in advance, is a distinction without a difference.",2.3. Data Gathering in the Query Model,[0],[0]
"We cast this same interaction into the setting where an analyst asks an adaptively chosen sequence of queries to a fixed dataset, representing the arm rewards.",2.3. Data Gathering in the Query Model,[0],[0]
The process of running a bandit algorithm A up to time T can be formalized as the adaptive selection of T queries against a single database of size T - fixed in advance.,2.3. Data Gathering in the Query Model,[0],[0]
"The formalization consists of observing two things.
",2.3. Data Gathering in the Query Model,[0],[0]
"First, by the principle of deferred randomness, we can view any (simple or contextual) bandit algorithm as operating in a setting in the rewards available for every arm at every time step have been sampled before the start of the algorithm, rather than online as the algorithm makes its selections.",2.3. Data Gathering in the Query Model,[0],[0]
"Second, the choice of arm pulled at time t by the bandit algorithm can be viewed as the answer to an adaptively selected query against this fixed dataset of rewards.
",2.3. Data Gathering in the Query Model,[0],[0]
"Adaptive data analysis is formalized as an interaction in which a data analystA performs computations on a dataset D, observes the results, and then may choose the identity of the next computation to run as a function of previously computed results (Dwork et al., 2015c;a).",2.3. Data Gathering in the Query Model,[0],[0]
"A sequence of recent results shows that if the queries are differentially private in the dataset D, then they will not in general overfit D, in the sense that the distribution over results induced by computing q(D) will be “similar” to the distribution over results induced if q were run on a new dataset, freshly sampled from the same underlying distribution (Dwork et al., 2015c;a; Bassily et al., 2016; Dwork et al., 2015b; Rogers et al., 2016).",2.3. Data Gathering in the Query Model,[0],[0]
"We will be more precise about what these results say in Section 4.
",2.3. Data Gathering in the Query Model,[0],[0]
"Recall that histories Λ record the choices of the algorithm, in addition to its observations.",2.3. Data Gathering in the Query Model,[0],[0]
It will be helpful to introduce notation that separates out the choices of the algorithm from its observations.,2.3. Data Gathering in the Query Model,[0],[0]
"In the simple stochastic setting and the contextual setting, given a history",2.3. Data Gathering in the Query Model,[0],[0]
"Λt, an action history ΛAt =",2.3. Data Gathering in the Query Model,[0],[0]
"(i1, . . .",2.3. Data Gathering in the Query Model,[0],[0]
", it−1) ∈",2.3. Data Gathering in the Query Model,[0],[0]
"[K]t−1 denotes the portion of the history recording the actions of the algorithm.
",2.3. Data Gathering in the Query Model,[0],[0]
"In the simple stochastic setting, a bandit tableau is a T ×K matrix D ∈",2.3. Data Gathering in the Query Model,[0],[0]
"( [0, 1]K )T .",2.3. Data Gathering in the Query Model,[0],[0]
"Each row Dt of D is a vector of K real numbers, intuitively representing the rewards that would be available to a bandit algorithm at round t for each of the K arms.",2.3. Data Gathering in the Query Model,[0],[0]
"In the contextual setting, a bandit tableau is represented by a pair of T ×K matrices: D ∈",2.3. Data Gathering in the Query Model,[0],[0]
"( [0, 1]K
)T and C ∈ ( (Rd)K )T .",2.3. Data Gathering in the Query Model,[0],[0]
"Intuitively, C represents the contexts presented to a bandit algorithm",2.3. Data Gathering in the Query Model,[0],[0]
"A at each round: each row Ct corresponds to a set of K contexts, one for each arm.",2.3. Data Gathering in the Query Model,[0],[0]
"D again represents the rewards that would be available to the bandit algorithm at round t for each of the K arms.
",2.3. Data Gathering in the Query Model,[0],[0]
"We write Tab to denote a bandit tableau when the setting has not been specified: implicitly, in the simple stochastic case, Tab = D, and in the contextual case, Tab = (D,C).
",2.3. Data Gathering in the Query Model,[0],[0]
Given a bandit tableau and a bandit algorithm,2.3. Data Gathering in the Query Model,[0],[0]
"A, we have the following interaction:
We denote the subset of the reward tableau D corresponding to rewards that would have been revealed to a bandit algorithmA given action history ΛAt , by ΛAt (D).",2.3. Data Gathering in the Query Model,[0],[0]
"Concretely if ΛAt = (i1, . .",2.3. Data Gathering in the Query Model,[0],[0]
.,2.3. Data Gathering in the Query Model,[0],[0]
", it−1) then Λ A t (D) =",2.3. Data Gathering in the Query Model,[0],[0]
"{(i`, yi`,`)} t−1 `=1.",2.3. Data Gathering in the Query Model,[0],[0]
"Given a selection function ft and an action history ΛAt , de-
Interact Inputs: Time horizon T , bandit algorithm A, and bandit tableau Tab (D in the simple stochastic case, (D,C) in the contextual case)
1: for t = 1 to T do 2: (contextual case) ShowA contexts Ct,1, . . .",2.3. Data Gathering in the Query Model,[0],[0]
", Ct,K 3: Let A play action it 4: Show A reward Dt,it 5: end for 6: Return: (i1, . . .",2.3. Data Gathering in the Query Model,[0],[0]
", iT )
fine the query qΛAt as qΛAt (D) = ft(Λ A t (D)).
",2.3. Data Gathering in the Query Model,[0],[0]
We now define Algorithms Bandit and InteractQuery.,2.3. Data Gathering in the Query Model,[0],[0]
"Bandit is a standard contextual bandit algorithm defined by selection functions ft, and InteractQuery is the Interact routine that draws the rewards in advance, and at time t selects action it as the result of query qΛAt .",2.3. Data Gathering in the Query Model,[0],[0]
"With the above definitions in hand, it is straightforward to show that the two Algorithms are equivalent, in that they induce the same joint distribution on their outputs.",2.3. Data Gathering in the Query Model,[0],[0]
"In both algorithms for convenience we assume we are in the linear contextual setting, and we write ηit to denote the i.i.d. error distributions of the rewards, conditional on the contexts.
",2.3. Data Gathering in the Query Model,[0],[0]
"Bandit Inputs: T, k, {xit}, {θi}, ft,Λ0 = ∅
1: for t = 1, . . .",2.3. Data Gathering in the Query Model,[0],[0]
", T : do 2: Let it = ft(Λt−1) 3: Draw yit,t ∼ xit,t · θit + ηit 4: Update Λt = Λt−1 ∪ (it, yit,t) 5: end for 6: Return: ΛT
InteractQuery Inputs: T, k,D : Dit = θi · xit + ηit, ft
1: for t = 1, . . .",2.3. Data Gathering in the Query Model,[0],[0]
", T : do 2: Let qt = qΛAt−1 3: Let it = qt(D) 4: Update ΛAt = Λ",2.3. Data Gathering in the Query Model,[0],[0]
"A t−1 ∪ it 5: end for 6: Return: ΛAT
Claim 1.",2.3. Data Gathering in the Query Model,[0],[0]
"Let P1,t be the joint distribution induced by Algorithm Bandit on Λt at time t, and let P2,t be the joint distribution induced by Algorithm InteractQuery on Λt = Λ A t (D).",2.3. Data Gathering in the Query Model,[0],[0]
"Then ∀t P1,t = P2,t.
",2.3. Data Gathering in the Query Model,[0],[0]
"The upshot of this equivalence is that we can import existing results that hold in the setting in which the dataset
is fixed, and queries are adaptively chosen.",2.3. Data Gathering in the Query Model,[0],[0]
"There are a large collection of results of this form that apply when the queries are differentially private (Dwork et al., 2015c; Bassily et al., 2016; Rogers et al., 2016) which apply directly to our setting.",2.3. Data Gathering in the Query Model,[0],[0]
"In the next section we formally define differential privacy in the simple stochastic and contextual bandit setting, and leave the description of the more general transfer theorems to Section 4.",2.3. Data Gathering in the Query Model,[0],[0]
We will be interested in algorithms that are differentially private.,2.4. Differential Privacy,[0],[0]
"In the simple stochastic bandit setting, we will require differential privacy with respect to the rewards.",2.4. Differential Privacy,[0],[0]
"In the contextual bandit setting, we will also require differential privacy with respect to the rewards, but not necessarily with respect to the contexts.
",2.4. Differential Privacy,[0],[0]
"We now define the neighboring relation we need to define bandit differential privacy:
Definition 1.",2.4. Differential Privacy,[0],[0]
"In the simple stochastic setting, two bandit tableau’s D,D′ are reward neighbors if they differ in at most a single row: i.e. if there exists an index ` such that for all t 6=",2.4. Differential Privacy,[0],[0]
"`, Dt = D′t.
",2.4. Differential Privacy,[0],[0]
"In the contextual setting, two bandit tableau’s (D,C), (D′, C ′) are reward neighbors if C = C ′ and D and D′ differ in at most a single row: i.e. if there exists an index ` such that for all t 6=",2.4. Differential Privacy,[0],[0]
"`, Dt = D′t.
",2.4. Differential Privacy,[0],[0]
"Note that changing a context does not result in a neighboring tableau: this neighboring relation will correspond to privacy for the rewards, but not for the contexts.",2.4. Differential Privacy,[0],[0]
Remark 1.,2.4. Differential Privacy,[0],[0]
"Note that we could have equivalently defined reward neighbors to be tableaus that differ in only a single entry, rather than in an entire row.",2.4. Differential Privacy,[0],[0]
"The distinction is unimportant in a bandit setting, because a bandit algorithm will be able to observe only a single entry in any particular row.
",2.4. Differential Privacy,[0],[0]
Definition 2.,2.4. Differential Privacy,[0],[0]
"A bandit algorithm A is ( , δ) reward differentially private if for every time horizon T and every pair of bandit tableau Tab,Tab′ that are reward neighbors, and every subset S ⊆",2.4. Differential Privacy,[0],[0]
"[K]T :
P [Interact(T,A,Tab) ∈ S] ≤
e P [ Interact(T,A,Tab′) ∈ S ]",2.4. Differential Privacy,[0],[0]
"+ δ
",2.4. Differential Privacy,[0],[0]
"If δ = 0, we say that A is -differentially private.",2.4. Differential Privacy,[0],[0]
We begin by showing that differentially private algorithms that operate in the stochastic bandit setting compute empirical means for their arms that are nearly unbiased.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Together
with known differentially private algorithms for stochastic bandit problems, the result is an algorithm that obtains a nearly optimal (worst-case) regret guarantee while also guaranteeing that the collected data is nearly unbiased.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"We could (and do) obtain these results by combining the reduction to answering adaptively selected queries given by Theorem 1 with the standard generalization theorems in adaptive data analysis (e.g. Corollary 2 in its most general form), but we first prove these de-biasing results from first principles to build intuition.
",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
Theorem 1.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Let A be an ( , δ)-differentially private algorithm in the stochastic bandit setting.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Then, for all i ∈",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"[K], and all t, we have:∣∣∣E [Ŷ ti − µi]∣∣∣ ≤",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
(e − 1 + Tδ)µi Remark 2.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
Note that since µi ∈,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"[0, 1], and for 1, e ≈ 1+ , this theorem bounds the bias by roughly +Tδ.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Often, we will have δ = 0 and so the bias will be bounded by roughly .
",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
Proof.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
First we fix some notation.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Fix any time horizon T , and let (ft)t∈[T ] be the sequence of selection functions induced by algorithm A. Let 1{ft(Λt)=i} be the indicator for the event that arm i is pulled at time t. We can write the random variable representing the sample mean of arm i at time T as
Ŷ Ti = T∑ t=1 1{ft(Λt)=i}∑T t′=1 1{ft′ (Λt′ )",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"=i} yit
where we recall that yi,t is the random variable representing the reward for arm",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"i at time t. Note that the numerator (ft(Λt) = i) is by definition independent of yi,t, but the denominator ( ∑T t′=1 1{ft′ (Λt′ )=i}) is not, because for t
′",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"> tΛt′ depends on yi,t.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"It is this dependence that leads to bias in adaptive data gathering procedures, and that we must argue is mitigated by differential privacy.
",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
We recall that the random variable NTi represents the number of times arm i is pulled through round T : NTi =∑T t′=1 1{ft′ (Λt′ ),3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
=i}.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Using this notation, we write the sample mean of arm i at time T , as:
Ŷ Ti = T∑ t=1 1{ft(Λt)=i} NTi · yit
We can then calculate:
E[Ŷ ti ] = T∑ t=1 E[ 1{ft(Λt)=i} NTi yit]
= T∑ t=1 E yit∼Pi",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"[yit · E A [ 1{ft(Λt)=i} NTi |yit]]
where the first equality follows by the linearity of expectation, and the second follows by the law of iterated expectation.
",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
Our goal is to show that the conditioning in the inner expectation does not substantially change the value of the expectation.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Specifically, we want to show that all t, and any value yit, we have
E[ 1{ft(Λt)=i}
Ni |yit] ≥ e− E[
1{ft(Λt)=i}
NTi ]",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"− δ
If we can show this, then we will have
E[Ŷ Ti ] ≥ (e− T∑ t=1 E[ 1{ft(Λt)=i} NTi ]",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"− Tδ) · µi
= (e− E[ NTi NTi ]",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"− Tδ) · µi = (e− − Tδ) · µi
which is what we want (The reverse inequality is symmetric).
",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
This is what we now show to complete the proof.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Observe that for all t, i, the quantity 1{ft(Λt)=i}Ni can be derived as a post-processing of the sequence of choices (f1(Λ1), . . .",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
", fT (ΛT )), and is therefore differentially private in the observed reward sequence.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Observe also that the quantity 1{ft(Λt)=i}
NTi is bounded in [0, 1].",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Hence (by a
lemma in the full version) for any pair of values yit, y′it, we have E[
1{ft(Λt)=i} NTi |yit] ≥ e− E[ 1{ft(Λt)=i} NTi |y′it]− δ.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"All
that remains is to observe that there must exist some value y′it such that E[ 1{ft(Λt)=i} Ni |y′it] ≥ E[ 1{ft(Λt)=i} Ni ].",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"(Otherwise, this would contradict",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
Ey′it∼Pi,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"[E[ 1{ft(Λt)=i} Ni |y′it]] = E[ 1{ft(Λt)=i}
NTi ])",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Fixing any such y′it implies that for all yit
E[ 1{ft(Λt)=i}
Ni |yit] ≥ e− E[
1{ft(Λt)=i}
NTi |y′i,t]− δ
≥ e− E[ 1{ft(Λt)=i}
NTi ]",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"− δ
as desired.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
The upper bound on the bias follows symmetrically.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"There are existing differentially private variants of the classic UCB algorithm ((Auer et al., 2002; Agrawal, 1995; Lai & Robbins, 1985)), which give a nearly optimal tradeoff between privacy and regret (Mishra & Thakurta, 2014; Tossou & Dimitrakakis, 2017; 2016).",3.1. A Private UCB Algorithm,[0],[0]
"For completeness, we give a simple version of a private UCB algorithm in the full version which we use in our experiments.",3.1. A Private UCB Algorithm,[0],[0]
"Here, we simply quote the relevant theorem, which is a consequence of a theorem in (Tossou & Dimitrakakis, 2016):
Theorem 2.",3.1. A Private UCB Algorithm,[0],[0]
"(Tossou & Dimitrakakis, 2016)",3.1. A Private UCB Algorithm,[0],[0]
"There is an - differentially private algorithm that obtains expected regret bounded by:
O ( max ( lnT · (ln ln(T ) + ln(1/ )) , √ kT log T ))
",3.1. A Private UCB Algorithm,[0],[0]
"Thus, we can take to be as small as = O( ln 1.5 T√ kT )
while still having a regret bound of O( √ kT log T ), which is nearly optimal in the worst case (over instances) (Audibert & Bubeck, 2009).
",3.1. A Private UCB Algorithm,[0],[0]
"Combining the above bound with Theorem 1, and letting =",3.1. A Private UCB Algorithm,[0],[0]
"O( ln
1.5 T√ kT ), we have:
Corollary 1.",3.1. A Private UCB Algorithm,[0],[0]
"There exists a simple stochastic bandit algorithm that simultaneously guarantees that the bias of the empirical average for each arm i is bounded by O(µi · ln
1.5 T√ kT
) and guarantees expected regret bounded by O( √ kT log T ).
",3.1. A Private UCB Algorithm,[0],[0]
"Of course, other tradeoffs are possible using different values of .",3.1. A Private UCB Algorithm,[0],[0]
"For example, the algorithm of (Tossou & Dimitrakakis, 2016) obtains sub-linear regret so long as = ω( ln
2 T T ).",3.1. A Private UCB Algorithm,[0],[0]
"Thus, it is possible to obtain non-trivial regret while guaranteeing that the bias of the empirical means remains as low as polylog(T )/T .",3.1. A Private UCB Algorithm,[0],[0]
"Up through this point, we have focused our attention on showing how the private collection of data mitigates the effect that adaptivity has on bias, in both the stochastic and (in the full version) contextual bandit problems.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"In this section, we draw upon more powerful results from the adaptive data analysis literature to go substantially beyond bias: to correct the p-values of hypothesis tests applied to adaptively gathered data.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"These p-value corrections follow from the connection between differential privacy and a quantity called max information, which controls the extent to which the dependence of selected test on the dataset can distort the statistical validity of the test (Dwork et al., 2015b; Rogers et al., 2016).",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"We briefly define max information, state the connection to differential privacy, and illustrate how max information bounds can be used to perform adaptive analyses in the private data gathering framework.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Definition 3 (Max-Information (Dwork et al., 2015b).).",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Let X,Z be jointly distributed random variables over domain (X ,Z).",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Let X ⊗ Z denote the random variable that draws independent copies of X,Z according to their marginal distributions.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"The β-approximate maxinformation between X,Z, denoted Iβ(X,Z), is defined
as:
Iβ(X,Z) = log sup O⊂(X×Z), P[(X,Z)∈O]>β",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
P,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"[(X,Z) ∈ O]−",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
β P,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
[X ⊗ Z ∈,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"O]
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Following (Rogers et al., 2016), define a test statistic t : D → R, where D is the space of all datasets.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"For D ∈ D, given an output a = t(D), the p-value associated with the test t on dataset D is p(a) =",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
PD∼P0,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"[t(D) ≥ a], where P0 is the null hypothesis distribution.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Consider an algorithm A, mapping a dataset to a test statistic.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Definition 4 (Valid p-value Correction Function (Rogers et al., 2016).).",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
A function γ :,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"[0, 1] → [0, 1] is a valid p-value correction function for A if the procedure:
1.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Select a test statistic t = A(D)
2.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Reject the null hypothesis if p(t(D)) ≤ γ(α)
has probability at most α of rejection, when D ∼ P0.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Then the following theorem gives a valid p-value correction function when (D,A(D)) have bounded β-approximate max information.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Theorem 3 ((Rogers et al., 2016).).",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Let A be a datadependent algorithm for selecting a test statistics such that Iβ(X,A(X))",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
≤,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
k.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Then the following function γ is a valid p-value correction function for A: γ(α) = max(α−β
2k , 0)
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Finally, we can connect max information to differential privacy, which allows us to leverage private algorithms to perform arbitrary valid statistical tests.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Theorem 4 (Theorem 20 from (Dwork et al., 2015b).).",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Let A be an -differentially private algorithm, let P be an arbitrary product distribution over datasets of size n, and let D ∼ P .",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Then for every β > 0:
Iβ(D,A(D)) ≤ log(e)( 2n/2 + √ n log(2/β)/2)
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
Remark 3.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
We note that a hypothesis of this theorem is that the data is drawn from a product distribution.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"In the contextual bandit setting, this corresponds to rows in the bandit tableau being drawn from a product distribution.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"This will be the case if contexts are drawn from a distribution at each round, and then rewards are generated as some fixed stochastic function of the contexts.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Note that contexts (and even rewards) can be correlated with one another within a round, so long as they are selected independently across rounds.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
We now formalize the process of running a hypothesis test against an adaptively collected dataset.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
A bandit algorithm A generates a history ΛT ∈ HT .,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
Let the reward portion of the gathered dataset be denoted by DA.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"We define an adaptive test statistic selector as follows.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
Definition 5.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
Fix the reward portion of a bandit tableau D and bandit algorithmA.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"An adaptive test statistic selector is a function s from action histories to test statistics such that s(ΛAT ) is a real-valued function of the adaptively gathered dataset DA.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Importantly, the selection of the test statistic s(ΛAT ) can depend on the sequence of arms pulled by A (and in the contextual setting, on all contexts observed), but not otherwise on the reward portion of the tableau D. For example, tA = s(Λ",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"A T ) could be the t-statistic corresponding to the null hypothesis that the arm i∗ which was pulled the great-
est number of times has mean µ: tA(DA) = ∑NT i∗ t=1 yi∗t−µ√
NT i∗
By virtue of Theorems 3 and 4, and our view of adaptive data gathering as adaptively selected queries, we get the following corollary:
Corollary 2.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Let A be an reward differentially private bandit algorithm, and let s be an adaptive test statistic selector.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Fix β > 0, and let γ(α) =
α
2log(e)( 2T/2+
√ T log(2/β)/2) , for α ∈",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"[0, 1].",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Then for any adaptively selected statistic tA = s(ΛAT ), and any product distribution P corresponding to the null hypothesis for tA
PD∼P,A [p(tA(D))",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
≤ γ(α)],4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"≤ α
If we set = O(1/ √ T ) in Corollary 2, then γ(α) = O(α)– i.e. a valid p-value correction that only scales α by a constant.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
We first validate our theoretical bounds on bias in the simple stochastic bandit setting.,5. Experiments,[0],[0]
"As expected the standard UCB algorithm underestimates the mean at each arm, while the private UCB algorithm of (?) obtains very low bias.",5. Experiments,[0],[0]
"While using the suggested by the theory effectively reduces bias and achieves near optimal asymptotic regret, the resulting private algorithm only achieves non-trivial regret for large T due to large constants and logarithmic factors in our bounds.",5. Experiments,[0],[0]
"This motivates a heuristic choice of that provides no theoretical guarantees on bias reduction, but leads to regret that is comparable to the non-private UCB algorithm.",5. Experiments,[0],[0]
We find empirically that even with this large choice of we achieve an 8 fold reduction in bias relative to UCB.,5. Experiments,[0],[0]
"This is consistent with the observation that our guarantees hold in the worst-case, and suggests that there is room for improvement in our theoretical bounds — both improving constants in the worst-case bounds on bias and on regret, and for proving instance specific bounds.",5. Experiments,[0],[0]
"Finally, we show that in the linear contextual bandit setting collecting data adaptively with a linear UCB algorithm and then conducting t-tests for regression coefficients yields incorrect inference (absent a p-value correction).",5. Experiments,[0],[0]
"These findings
confirm the necessity of our methods when drawing conclusions from adaptively gathered data.",5. Experiments,[0],[0]
In our first stochastic bandit experiment we set K = 20 and T = 500.,5.1. Stochastic Multi-Armed Bandit,[0],[0]
"The K arm means are equally spaced between 0 and 1 with gap ∆ = .05, with µ0 = 1.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"We run UCB and -private UCB for T rounds with = .05, and after each run compute the difference between the sample mean at each arm and the true mean.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"We repeat this process 10, 000 times, averaging to obtain high confidence estimates of the bias at each arm.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"The average absolute bias over all arms for private UCB was .00176, with the bias for every arm being statistically indistinguishable from 0 at 95% confidence (see Figure 1 for confidence intervals) while the average absolute bias (over arms) for UCB was .0698, or over 40 times higher.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"The most biased arm had a measured bias of roughly 0.14, and except for the top 4 arms, the bias of each arm was statistically significant.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"It is worth noting that private UCB achieves bias significantly lower than the = .05 guaranteed by the theory, indicating that the theoretical bounds on bias obtained from differential privacy are conservative.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"Figures 1, 2 show the bias at each arm for private UCB vs. UCB, with 95% confidence intervals around the bias at each arm.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"Not only is the bias for private UCB an order of magnitude smaller on average, it does not exhibit the systemic negative bias evident in Figure 2.
",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"Noting that the observed reduction in bias for = .05 exceeded that guaranteed by the theory, we run a second experiment withK = 5, T = 100000,∆ = .05, and = 400, averaging results over 1000 iterations.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
Figure 5 shows that private UCB achieves sub-linear regret comparable with UCB.,5.1. Stochastic Multi-Armed Bandit,[0],[0]
"While = 400 provides no meaningful theoretical guarantee, the average absolute bias at each arm mean obtained by the private algorithm was .0015 (statistically indistinguishable from 0 at 95% confidence for each arm), while the non-private UCB algorithm obtained average bias .011, 7.5 times larger.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"The bias reduction for the arm with the smallest mean (for which the bias is the worst with the non private algorithm) was by more than a factor of 10.
",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"Figures 3,4 show the bias at each arm for the private and non-private UCB algorithms together with 95% confidence intervals; again we observe a negative skew in the bias for UCB, consistent with the theory in (Nie et al., 2017).",5.1. Stochastic Multi-Armed Bandit,[0],[0]
Our second experiment confirms that adaptivity leads to bias in the linear contextual bandit setting in the context of hypothesis testing – and in particular can lead to false discovery in testing for non-zero regression coefficients.,5.2. Linear Contextual Bandits,[0],[0]
"The set up is as follows: for K = 5 arms, we observe rewards
yi,t ∼ N (θ′ixit, 1), where θi, xit ∈ R5, ||θi|| = ||xit|| = 1.",5.2. Linear Contextual Bandits,[0],[0]
"For each arm i, we set θi1 = 0.",5.2. Linear Contextual Bandits,[0],[0]
"Subject to these constraints, we pick the θ parameters uniformly at random (once per run), and select the contexts x uniformly at random (at each round).",5.2. Linear Contextual Bandits,[0],[0]
"We run a linear UCB algorithm (OFUL (?)) for T = 500 rounds, and identify the arm i∗ that has been selected most frequently.",5.2. Linear Contextual Bandits,[0],[0]
We then conduct a z-test for whether the first coordinate of θi∗ is equal to 0.,5.2. Linear Contextual Bandits,[0],[0]
"By construction the null hypothesis H0 : θi∗1 = 0 of the experiment is true, and absent adaptivity, the p-value should be distributed uniformly at random.",5.2. Linear Contextual Bandits,[0],[0]
"In particular, for any value of α the probability that the corresponding p-value is less than α is exactly α.",5.2. Linear Contextual Bandits,[0],[0]
"We record the observed p-value, and repeat the experiment 1000 times, displaying the histogram of observed p-values in Figure 6.",5.2. Linear Contextual Bandits,[0],[0]
"As expected, the adaptivity of the data gathering process leads the p-values to exhibit a strong downward skew.",5.2. Linear Contextual Bandits,[0],[0]
The dotted blue line demarcates α = .05.,5.2. Linear Contextual Bandits,[0],[0]
"Rather than probability .05 of falsely rejecting the null hypothesis at 95% confidence, we observe that 76% of the observed p-values fall below the .05 threshold.",5.2. Linear Contextual Bandits,[0],[0]
"This shows that a careful p-value correction in the style of Section 2.3 is essential even for simple testing of regression coefficients, lest bias lead to false discovery.",5.2. Linear Contextual Bandits,[0],[0]
"Data that is gathered adaptively — via bandit algorithms, for example — exhibits bias.",abstractText,[0],[0]
This is true both when gathering simple numeric valued data — the empirical means kept track of by stochastic bandit algorithms are biased downwards — and when gathering more complicated data — running hypothesis tests on complex data gathered via contextual bandit algorithms leads to false discovery.,abstractText,[0],[0]
"In this paper, we show that this problem is mitigated if the data collection procedure is differentially private.",abstractText,[0],[0]
"This lets us both bound the bias of simple numeric valued quantities (like the empirical means of stochastic bandit algorithms), and correct the p-values of hypothesis tests run on the adaptively gathered data.",abstractText,[0],[0]
"Moreover, there exist differentially private bandit algorithms with near optimal regret bounds: we apply existing theorems in the simple stochastic case, and give a new analysis for linear contextual bandits.",abstractText,[0],[0]
We complement our theoretical results with experiments validating our theory1.,abstractText,[0],[0]
Mitigating Bias in Adaptive Data Gathering via Differential Privacy,title,[0],[0]
Estimating generative models from unlabeled data is one of the challenges in unsupervised learning.,1. Introduction,[0],[0]
"Recently, several latent variable approaches have been proposed to learn flexible density estimators together with efficient sampling, such as generative adversarial networks (GANs) (Goodfellow et al., 2014), variational autoencoders (Kingma & Welling, 2014; Rezende et al., 2014), iterative transformation of noise (Sohl-Dickstein et al., 2015), or non-volume preserving transformations (Dinh et al., 2017).
",1. Introduction,[0],[0]
"In this work we focus on GANs, currently the most con-
*Equal contribution 1Université Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, 38000 Grenoble, France. 2Université Paris Sud, INRIA, équipe TAU, Gif-sur-Yvette, 91190, France.",1. Introduction,[0],[0]
"3Facebook Artificial Intelligence Research Paris, France.",1. Introduction,[0],[0]
"Correspondence to: Corentin Tallec <corentin.tallec@inria.fr>, Thomas Lucas <thomas.lucas@inria.fr>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"vincing source of samples of natural images (Karras et al., 2018).",1. Introduction,[0],[0]
GANs consist of a generator and a discriminator network.,1. Introduction,[0],[0]
"The generator maps samples from a latent random variable with a basic prior, such as a multi-variate Gaussian, to the observation space.",1. Introduction,[0],[0]
This defines a probability distribution over the observation space.,1. Introduction,[0],[0]
A discriminator network is trained to distinguish between generated samples and true samples in the observation space.,1. Introduction,[0],[0]
"The generator, on the other hand, is trained to fool the discriminator.",1. Introduction,[0],[0]
"In an idealized setting with unbounded capacity of both networks and infinite training data, the generator should converge to the distribution from which the training data has been sampled.
",1. Introduction,[0],[0]
"In most adversarial setups, the discriminator classifies individual data samples.",1. Introduction,[0],[0]
"Consequently, it cannot directly detect discrepancies between the distribution of generated samples and global statistics of the training distribution, such as its moments or quantiles.",1. Introduction,[0],[0]
"For instance, if the generator models a restricted part of the support of the target distribution very well, this can fool the discriminator at the level of individual samples, a phenomenon known as mode dropping.",1. Introduction,[0],[0]
In such a case there is little incentive for the generator to model other parts of the support of the target distribution.,1. Introduction,[0],[0]
"A more thorough explanation of this effect can be found in (Salimans et al., 2016).
",1. Introduction,[0],[0]
"In order to access global distributional statistics, imagine a discriminator that could somehow take full probability distributions as its input.",1. Introduction,[0],[0]
This is impossible in practice.,1. Introduction,[0],[0]
"Still, it is possible to feed large batches of training or generated samples to the discriminator, as an approximation of the corresponding distributions.",1. Introduction,[0],[0]
The discriminator can compute statistics on those batches and detect discrepancies between the two distributions.,1. Introduction,[0],[0]
"For instance, if a large batch exhibits only one mode from a multimodal distribution, the discriminator would notice the discrepancy right away.",1. Introduction,[0],[0]
"Even though a single batch may not encompass all modes of the distribution, it will still convey more information about missing modes than an individual example.
",1. Introduction,[0],[0]
"Training the discriminator to discriminate “pure” batches with only real or only synthetic samples makes its task too easy, as a single bad sample reveals the whole batch as synthetic.",1. Introduction,[0],[0]
"Instead, we introduce a “mixed” batch discrimination task in which the discriminator needs to predict the ratio of real samples in a batch.
1
This use of batches differs from traditional minibatch learning.",1. Introduction,[0],[0]
"The batch is not used as a computational trick to increase parallelism, but as an approximate distribution, on which to compute global statistics.
",1. Introduction,[0],[0]
"A naive way of doing so would be to concatenate the samples in the batch, feeding the discriminator a single tensor containing all the samples.",1. Introduction,[0],[0]
"However, this is parameterhungry, and the computed statistics are not automatically invariant to the order of samples in the batch.",1. Introduction,[0],[0]
"To compute functions that depend on the samples only through their distribution, it is necessary to restrict the class of discriminator networks to permutation-invariant functions of the batch.",1. Introduction,[0],[0]
"For this, we adapt and extend an architecture from McGregor (2007) to compute symmetric functions of the input.",1. Introduction,[0],[0]
"We show this can be done with minimal modification to existing architectures, at a negligible computational overhead w.r.t.",1. Introduction,[0],[0]
"ordinary batch processing.
",1. Introduction,[0],[0]
"In summary, our contributions are the following:
• Naively training the discriminator to discriminate “pure” batches with only real or only synthetic samples makes its task way too easy.",1. Introduction,[0],[0]
"We introduce a discrimination loss based on mixed batches of true and fake samples, that avoids this pitfall.",1. Introduction,[0],[0]
We derive the associated optimal discriminator.,1. Introduction,[0],[0]
• We provide a principled way of defining neural networks that are permutation-invariant over a batch of samples.,1. Introduction,[0],[0]
"We formally prove that the resulting class of functions comprises all symmetric continuous functions, and only symmetric functions.",1. Introduction,[0],[0]
"• We apply these insights to GANs, with good experimental results, both qualitatively and quantitatively.
",1. Introduction,[0],[0]
"We believe that discriminating between distributions at the batch level provides an equally principled alternative to approaches to GANs based on duality formulas (Nowozin et al., 2016; Gulrajani et al., 2017; Arjovsky et al., 2017).",1. Introduction,[0],[0]
The training of generative models via distributional rather than pointwise information has been explored in several recent contributions.,2. Related work,[0],[0]
"Batch discrimination (Salimans et al., 2016) uses a handmade layer to compute batch statistics which are then combined with sample-specific features to enhance individual sample discrimination.",2. Related work,[0],[0]
Karras et al. (2018) directly compute the standard deviation of features and feed it as an additional feature to the last layer of the network.,2. Related work,[0],[0]
"Both methods use a single layer of handcrafted batch statistics, instead of letting the discriminator learn arbitrary batch statistics useful for discrimination as in our approach.",2. Related work,[0],[0]
"Moreover, in both methods the discriminator still assesses single samples, rather than entire batches.",2. Related work,[0],[0]
"Radford et al. (2015) reported improved results with batch normalization
in the discriminator, which may also be due to reliance on batch statistics.
",2. Related work,[0],[0]
"Other works, such as (Li et al., 2015) and (Dziugaite et al., 2015), replace the discriminator with a fixed distributional loss between true and generated samples, the maximum mean discrepancy, as the criterion to train the generative model.",2. Related work,[0],[0]
"This has the advantage of relieving the inherent instability of GANs, but lacks the flexibility of an adaptive discriminator.
",2. Related work,[0],[0]
The discriminator we introduce treats batches as sets of samples.,2. Related work,[0],[0]
Processing sets prescribes the use of permutation invariant networks.,2. Related work,[0],[0]
"There has been a large body of work around permutation invariant networks, e.g (McGregor, 2007; 2008; Qi et al., 2016; Zaheer et al., 2017; Vaswani et al., 2017).",2. Related work,[0],[0]
"Our processing is inspired by (McGregor, 2007; 2008) which designs a special kind of layer that provides the desired invariance property.",2. Related work,[0],[0]
The network from McGregor (2007) is a multi-layer perceptron in which the single hidden layer performs a batchwise computation that makes the result equivariant by permutation.,2. Related work,[0],[0]
"Here we show that stacking such hidden layers and reducing the final layer with a permutation invariant reduction, covers the whole space of continuous permutation invariant functions.
",2. Related work,[0],[0]
"Zaheer et al. (2017) first process each element of the set independently, then aggregate the resulting representation using a permutation invariant operation, and finally process the permutation invariant quantity.",2. Related work,[0],[0]
"Qi et al. (2016) process 3D point cloud data, and interleave layers that process points independently, and layers that apply equivariant transformations.",2. Related work,[0],[0]
"The output of their networks are either permutation equivariant for pointcloud segmentation, or permutation invariant for shape recognition.",2. Related work,[0],[0]
"In our approach we stack permutation equivariant layers that combine batch
information and sample information at every level, and aggregate these in the final layer using a permutation invariant operation.
",2. Related work,[0],[0]
"More complex approaches to permutation invariance or equivariance appear in (Guttenberg et al., 2016).",2. Related work,[0],[0]
"We prove, however, that our simpler architecture already covers the full space of permutation invariant functions.
",2. Related work,[0],[0]
Improving the training of GANs has received a lot of recent attention.,2. Related work,[0],[0]
"For instance, Arjovsky et al. (2017), Gulrajani et al. (2017) and Miyato et al. (2018) constrain the Lipschitz constant of the network and show that this stabilizes training and improves performance.",2. Related work,[0],[0]
Karras et al. (2018) achieved impressive results by gradually increasing the resolution of the generated images as training progresses.,2. Related work,[0],[0]
"Using a batch of samples rather than individual samples as input to the discriminator can provide global statistics about
the distributions of interest.",3. Adversarial learning with permutation-invariant batch features,[0],[0]
Such statistics could be useful to avoid mode dropping.,3. Adversarial learning with permutation-invariant batch features,[0],[0]
"Adversarial learning (Goodfellow et al., 2014) can easily be extended to the batch discrimination case.",3. Adversarial learning with permutation-invariant batch features,[0],[0]
"For a fixed batch size B, the corresponding two-player optimization procedure becomes
min G max D Ex1,...,xB∼D",3. Adversarial learning with permutation-invariant batch features,[0],[0]
"[logD(x1, . . .",3. Adversarial learning with permutation-invariant batch features,[0],[0]
", xB)]",3. Adversarial learning with permutation-invariant batch features,[0],[0]
"+ (1)
Ez1,...,zB∼Z",3. Adversarial learning with permutation-invariant batch features,[0],[0]
"[log(1−D(G(z1), . . .",3. Adversarial learning with permutation-invariant batch features,[0],[0]
", G(zB)))",3. Adversarial learning with permutation-invariant batch features,[0],[0]
"]
with D the empirical distribution over data, Z a distribution over the latent variable that is the input of the generator, G a pointwise generator and D a batch discriminator.1 This leads to a learning procedure similar to the usual GAN algorithm, except that the loss encourages the discriminator to output 1 when faced with an entire batch of real data, and 0 when faced with an entire batch of generated data.
",3. Adversarial learning with permutation-invariant batch features,[0],[0]
"Unfortunately, this basic procedure makes the work of the discriminator too easy.",3. Adversarial learning with permutation-invariant batch features,[0],[0]
"As the discriminator is only faced with batches that consist of either only training samples or only generated samples, it can base its prediction on any subset of these samples.",3. Adversarial learning with permutation-invariant batch features,[0],[0]
"For example, a single poor generated sample would be enough to reject a batch.",3. Adversarial learning with permutation-invariant batch features,[0],[0]
"To cope with this deficiency, we propose to sample batches that mix both training and generated data.",3. Adversarial learning with permutation-invariant batch features,[0],[0]
"The discriminator’s task is to predict the proportion of real images in the batch, which is clearly a permutation invariant quantity.",3. Adversarial learning with permutation-invariant batch features,[0],[0]
"A naive approach to sampling mixed batches would be, for each batch index, to pick a datapoint from either real or generated images with probability 12 .",3.1. Batch smoothing as a regularizer,[0],[0]
"This is necessarily ill behaved: as the batch size increases, the ratio of training data to generated data in the batch tends to 12 by the law of large numbers.",3.1. Batch smoothing as a regularizer,[0],[0]
"Consequently, a discriminator always predicting 12 would achieve very low error with large batch sizes, and provide no training signal to the generator.
",3.1. Batch smoothing as a regularizer,[0],[0]
"Instead, for each batch we sample a ratio p from a distribution P on [0, 1], and construct a batch by picking real samples with probability p and generated samples with probability 1− p.",3.1. Batch smoothing as a regularizer,[0],[0]
"This forces the discriminator to predict across an entire range of possible values of p.
Formally, suppose we are given a batch of training data x ∈ RB×n",3.1. Batch smoothing as a regularizer,[0],[0]
and a batch of generated data x̃ ∈ RB×n.,3.1. Batch smoothing as a regularizer,[0],[0]
"To mix x and x̃, a binary vector β is sampled from B (p)B , a B-dimensional Bernoulli distribution with parameter p.",3.1. Batch smoothing as a regularizer,[0],[0]
"The mixed batch with mixing vector β is denoted
mβ(x, x̃)",3.1. Batch smoothing as a regularizer,[0],[0]
:= x β + x̃ (1− β).,3.1. Batch smoothing as a regularizer,[0],[0]
"(2) 1The generator G could also be modified to produce batches of data, which can help to cover more modes per batch, but this deviates from the objective of learning a density estimator from which we can draw i.i.d.",3.1. Batch smoothing as a regularizer,[0],[0]
"samples.
",3.1. Batch smoothing as a regularizer,[0],[0]
"This apparently wastes some samples, but we can reuse the discarded samples by using 1− β in the next batch.
",3.1. Batch smoothing as a regularizer,[0],[0]
"The discriminator has to predict the ratio of real images, #βB where #β is the sum of the components of β.",3.1. Batch smoothing as a regularizer,[0],[0]
"As a loss on the predicted ratio, we use the Kullback–Leibler divergence between a Bernoulli distribution with the actual ratio of real images, and a Bernoulli distribution with the predicted ratio.",3.1. Batch smoothing as a regularizer,[0],[0]
"The divergence between Bernoulli distributions with parameters u and v is
KL(B (u) ||",3.1. Batch smoothing as a regularizer,[0],[0]
B (v)),3.1. Batch smoothing as a regularizer,[0],[0]
= u log u v +,3.1. Batch smoothing as a regularizer,[0],[0]
(1− u) log 1− u1− v .,3.1. Batch smoothing as a regularizer,[0],[0]
"(3)
Formally, the discriminator D will minimize the objective
Ep∼P, β∼B(p)B KL ( B (
#β B
)",3.1. Batch smoothing as a regularizer,[0],[0]
||,3.1. Batch smoothing as a regularizer,[0],[0]
"B (D(mβ(x, x̃))) ) ,
(4)
where the expectation is over sampling p from a distribution P , typically uniform on [0, 1], then sampling a mixed minibatch.",3.1. Batch smoothing as a regularizer,[0],[0]
"For clarity, we have omitted the expectation over the sampling of training and generated samples
The generator is trained with the loss
Ep∼P, β∼B(p)B log(D(mβ(x, x̃))).",3.1. Batch smoothing as a regularizer,[0],[0]
"(5)
This loss, which is not the generator loss associated to the min-max optimization problem, is known to saturate less (Goodfellow et al., 2014).
",3.1. Batch smoothing as a regularizer,[0],[0]
"In some experimental cases, using the discriminator loss (4) with P = U([0, 1]) made discriminator training too difficult.",3.1. Batch smoothing as a regularizer,[0],[0]
"To alleviate some of the difficulty, we sampled the mixing variable p from a reduced symmetric union of intervals [0, γ] ∪ [1 − γ, 1].",3.1. Batch smoothing as a regularizer,[0],[0]
"With low γ, all generated batches are nearly purely taken from either real or fake data.",3.1. Batch smoothing as a regularizer,[0],[0]
We refer to this training method as batch smoothing-γ.,3.1. Batch smoothing as a regularizer,[0],[0]
"Batch smoothing-0 corresponds to no mixing, while batch smoothing-0.5 corresponds to equation (4).",3.1. Batch smoothing as a regularizer,[0],[0]
"The optimal discriminator for batch smoothing can be computed explicitly, for p ∼ U([0, 1]), and extends the usual GAN discriminator when B = 1.",3.2. The optimal discriminator for batch smoothing,[0],[0]
Proposition 1.,3.2. The optimal discriminator for batch smoothing,[0],[0]
"The optimal discriminator for the loss (4),
given a batch y ∈ RB×N , is
D∗(y) = 12 punbalanced(y) pbalanced(y)
(6)
where the distribution pbalanced and punbalanced on batches are defined as
pbalanced(y)",3.2. The optimal discriminator for batch smoothing,[0],[0]
"= 1 B + 1 ∑
β∈{0,1}B
p1(y)βp2(y)1−β( B #β )
punbalanced(y) = 2 B + 1 ∑
β∈{0,1}B
p1(y)βp2(y)1−β( B #β )",3.2. The optimal discriminator for batch smoothing,[0],[0]
"#β B .
(7)
in which p1 is the data distribution and p2 the distribution of generated samples, and where p1(y)β is shorthand for p1(y1)β1 . . .",3.2. The optimal discriminator for batch smoothing,[0],[0]
"p1(yB)βB .
",3.2. The optimal discriminator for batch smoothing,[0],[0]
The proof is technical and is deferred to the supplementary material.,3.2. The optimal discriminator for batch smoothing,[0],[0]
"For non-uniform beta distributions on p, a similar result holds, with different coefficients depending on #β and B in the sum.
",3.2. The optimal discriminator for batch smoothing,[0],[0]
These heavy expressions can be interpreted easily.,3.2. The optimal discriminator for batch smoothing,[0],[0]
"First, in the case B = 1, the optimal discriminator reduces to the optimal discriminator for a standard GAN, D∗ = p1(y)p1(y)+p2(y) .
",3.2. The optimal discriminator for batch smoothing,[0],[0]
"Actually pbalanced(y) is simply the distribution of batches y under our procedure of sampling p uniformly, then sampling β ∼ B (p)B .",3.2. The optimal discriminator for batch smoothing,[0],[0]
"The binomial coefficients put on equal footing contributions with different true/fake ratios.
",3.2. The optimal discriminator for batch smoothing,[0],[0]
"The generator loss (5), when faced with the optimal discriminator, is the Kullback–Leibler divergence between pbalanced and punbalanced (up to sign and a constant log(2)).",3.2. The optimal discriminator for batch smoothing,[0],[0]
"Since punbalanced puts more weight on batches with higher #β (more true samples), this brings fake samples closer to true ones.
",3.2. The optimal discriminator for batch smoothing,[0],[0]
"Since pbalanced and punbalanced differ by a factor 2#β/B, the ratio D∗ = 12 punbalanced(y) pbalanced(y) is simply the expectation of #β/B under a probability distribution on β that is proportional to p1(y)βp2(y)1−β(
B #β ) .",3.2. The optimal discriminator for batch smoothing,[0],[0]
"But this is the posterior distribution on
β given the batch y and the uniform prior on the ratio p.",3.2. The optimal discriminator for batch smoothing,[0],[0]
"Thus, the optimal discriminator is just the posterior mean of the ratio of true samples, D∗(y) =",3.2. The optimal discriminator for batch smoothing,[0],[0]
IEβ|y [ #β B ] .,3.2. The optimal discriminator for batch smoothing,[0],[0]
This is standard when minimizing the expected divergence between Bernoulli distributions and the approach can therefore be extended to non-uniform priors on p as shown in section 9.,3.2. The optimal discriminator for batch smoothing,[0],[0]
Computing statistics of probability distributions from batches of i.i.d.,4. Permutation invariant networks,[0],[0]
"samples requires to compute quantities that
are invariant to permuting the order of samples within the batch.",4. Permutation invariant networks,[0],[0]
In this section we propose a permutation equivariant layer that can be used together with a permutation invariant aggregation operation to build networks that are permutation invariant.,4. Permutation invariant networks,[0],[0]
"We also provide a sketch of proof (fully developed in the supplementary material) that this architecture is able to reach all symmetric continuous functions, and only represents such functions.",4. Permutation invariant networks,[0],[0]
"A naive way of achieving invariance to batch permutations is to consider the batch dimension as a regular feature dimension, and to randomly reorder the batches at each step.",4.1. Building a permutation invariant architecture,[0],[0]
"This multiplies the input dimension by the batch size, and thus greatly increases the number of trainable parameters.",4.1. Building a permutation invariant architecture,[0],[0]
"Moreover, this only provides approximate invariance to batch permutation, as the network has to infer the invariance based on the training data.
",4.1. Building a permutation invariant architecture,[0],[0]
"Instead, we propose to directly build invariance into the architecture.",4.1. Building a permutation invariant architecture,[0],[0]
"This method drastically reduces the number of parameters compared to the naive approach, bringing it back in line with ordinary networks, and ensures strict invariance to batch permutation.
",4.1. Building a permutation invariant architecture,[0],[0]
Let us first formalize the notion of batch permutation invariance and equivariance.,4.1. Building a permutation invariant architecture,[0],[0]
"A function f from RB×l to RB×L is batch permutation equivariant if permuting samples in the batch results in the same permutation of the outputs: for any permutation σ of the inputs,
f(xσ(1), . . .",4.1. Building a permutation invariant architecture,[0],[0]
", xσ(B))",4.1. Building a permutation invariant architecture,[0],[0]
"= f(x)σ(1), . . .",4.1. Building a permutation invariant architecture,[0],[0]
", f(x)σ(B).",4.1. Building a permutation invariant architecture,[0],[0]
"(8)
For instance, any regular neural network or other function treating the inputs x1, . . .",4.1. Building a permutation invariant architecture,[0],[0]
", xB independently in parallel, is batch permutation equivariant.
",4.1. Building a permutation invariant architecture,[0],[0]
"A function f from RB×l to RL is batch permutation invariant if permuting the inputs in the batch does not change the output: for any permutation on batch indices σ,
f(xσ(1), . . .",4.1. Building a permutation invariant architecture,[0],[0]
", xσ(B))",4.1. Building a permutation invariant architecture,[0],[0]
"= f(x1, . . .",4.1. Building a permutation invariant architecture,[0],[0]
", xB).",4.1. Building a permutation invariant architecture,[0],[0]
"(9)
The mean, the max or the standard deviation along the batch axis are all batch permutation invariant.
",4.1. Building a permutation invariant architecture,[0],[0]
"Permutation equivariant and permutation invariant functions can be obtained by combining ordinary, parallel treatment of batch samples with an additional batch-averaging operation that performs an average of the activations across the batch direction.",4.1. Building a permutation invariant architecture,[0],[0]
"In our architecture, this averaging is the only form of interaction between different elements of the batch.",4.1. Building a permutation invariant architecture,[0],[0]
"It is one of our main results that such operations are sufficient to recover all invariant functions.
",4.1. Building a permutation invariant architecture,[0],[0]
"Formally, on a batch of data x ∈ RB×n, our proposed batch
permutation invariant network fθ is defined as
fθ(x) = 1 B B∑ b=1",4.1. Building a permutation invariant architecture,[0],[0]
(φθp ◦ φθp−1 ◦ . . .,4.1. Building a permutation invariant architecture,[0],[0]
"◦ φθ0(x))b (10)
where each φθi is a batch permutation equivariant function from RB×li−1 to RB×li , where the li’s are the layer sizes.
",4.1. Building a permutation invariant architecture,[0],[0]
"The equivariant layer operation φθ with l input features and L output features comprises an ordinary weight matrix Λ ∈ Rl×L that treats each data point of the batch independently (“non-batch-mixing”), a batch-mixing weight matrix Γ ∈ Rl×L, and a bias vector β ∈ RL.",4.1. Building a permutation invariant architecture,[0],[0]
"As in regular neural networks, Λ processes each data point in the batch independently.",4.1. Building a permutation invariant architecture,[0],[0]
"On the other hand, the weight matrix Γ operates after computing an average across the whole batch.",4.1. Building a permutation invariant architecture,[0],[0]
"Defining ρ as the batch average for each feature,
ρ(x1, . . .",4.1. Building a permutation invariant architecture,[0],[0]
", xB)",4.1. Building a permutation invariant architecture,[0],[0]
:= 1 B B∑ b=1,4.1. Building a permutation invariant architecture,[0],[0]
"xb (11)
the permutation-equivariant layer φ is formally defined as φθ(x)b := µ ( β + xbΛ + ρ(x)Γ ) (12)
where µ is a nonlinearity, b is a batch index, and the parameter of the layer is θ = (β,Λ,Γ).",4.1. Building a permutation invariant architecture,[0],[0]
The networks constructed above are permutation invariant by construction.,4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"However, it is unclear a priori that all permutation invariant functions can be represented this way: the functions that can be approximated to arbitrary precision by those networks could be a strict subset of the set of permutation invariant functions.",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"The optimal solution for the discriminator could lie outside this subset, making our construction too restrictive.",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"We now show this is not the case: our architecture satisfies a universal approximation theorem for permutation-invariant functions.
",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
Theorem 1.,4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
The set of networks that can be constructed by stacking as in Eq.,4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
(10) the layers φ defined in Eq.,4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"(12), with sigmoid nonlinearities except on the output layer, is dense in the set of permutation-invariant functions (for the topology of uniform convergence on compact sets).
",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"While the case of one-dimensional features is relatively simple, the multidimensional case is more intricate, and the detailed proof is given in the supplementary material.",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"Let us describe the key ideas underlying the proof.
",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"The standard universal approximation theorem for neural networks proves the following: for any continuous function f , we can find a network that given a batch x = (x1, . . .",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
", xB), computes (f(x1), . . .",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
", f(xB)).",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"This is insufficient for our purpose as it provides no way of mixing information between samples in the batch.
",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"First, we prove that the set of functions that can be approximated to arbitrary precision by our networks is an algebra, i.e., a vector space stable under products.",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"From this point on, it remains to be shown that this algebra contains a generative family of the continuous symmetric functions.
",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"To prove that we can compute the sum of two functions f1 and f2, compute f1 and f2 on different channels (this is possible even if f1 and f2 require different numbers of layers, by filling in with the identity if necessary).",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"Then sum across channels, which is possible in (12).
",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"To compute products, first compute f1 and f2 on different channels, then apply the universal approximation theorem to turn this into log f1 and log f2, then add, then take the exponential thanks to the universal approximation theorem.
",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"The key point is then the following: the algebra of all permutation-invariant polynomials over the components of (x1, . . .",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
", xB) is generated as an algebra by the averages 1 B (f(x1) + . .",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
.+ f(xB)),4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
when f ranges over all functions of single batch elements.,4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"This non-trivial algebraic statement is proved in the supplementary material.
",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"By construction, such functions 1B (f(x1)+. .",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
".+f(xB)) are readily available in our architecture, by computing f as in an ordinary network and then applying the batch-averaging operation ρ in the next layer.",4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
Further layers provide sums and products of those thanks to the algebra property.,4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
We can conclude with a symmetric version of the Stone–Weierstrass theorem (polynomials are dense in continuous functions).,4.2. Networks of equivariant layers provide universal approximation of permutation invariant functions,[0],[0]
"In our experiments, we apply the constructions above to standard, deep convolutional neural networks.",4.3. Practical architecture,[0],[0]
"In practice, for the linear operations Λ and Γ in (12) we use convolutional kernels (of size 3× 3) acting over xb and ρ(x) respectively.",4.3. Practical architecture,[0],[0]
Weight tensors Λ and Γ are also reweighted like so that at the start of training ρ(x) does not contribute disproportionately compared with other features:,4.3. Practical architecture,[0],[0]
Λ̃ = |B||B|+1 Λ and Γ̃ = 1|B|+1 Γ where |B| denotes the size of batch B.,4.3. Practical architecture,[0],[0]
"While these coefficients could be learned, we have found this explicit initialization to improve training.",4.3. Practical architecture,[0],[0]
"Figure 1 shows how to modify standard CNN architectures to adapt each layer to our method.
",4.3. Practical architecture,[0],[0]
"In the first setup, which we refer to as BGAN, a permutation invariant reduction is done at the end of the discriminator, yielding a single prediction per batch, which is evaluated with the loss in (4).",4.3. Practical architecture,[0],[0]
"We also introduce a setup, M-BGAN, where we swap the order of averaging and applying the loss.",4.3. Practical architecture,[0],[0]
"2 Namely, letting y be the single target for the batch (in our case, the proportion of real samples), the BGAN case translates into
L((o1, . . .",4.3. Practical architecture,[0],[0]
", oB), y) = ` (
1 B B∑ i=1",4.3. Practical architecture,[0],[0]
"oi, y
) (13)
2This was initially a bug that worked.
while M-BGAN translates to
L((o1, . . .",4.3. Practical architecture,[0],[0]
", oB), y) = 1 B B∑ i=1",4.3. Practical architecture,[0],[0]
"`(oi, y) (14)
where L is the final loss function, ` is the KL loss function used in (4), (o1, . .",4.3. Practical architecture,[0],[0]
.,4.3. Practical architecture,[0],[0]
", ob) is the output of the last equivariant layer, and y is the target for the whole batch.
",4.3. Practical architecture,[0],[0]
Both these losses are permutation invariant.,4.3. Practical architecture,[0],[0]
A more detailled explanation of M-BGAN is given in Section 11.,4.3. Practical architecture,[0],[0]
The synthetic dataset from Zhang et al. (2017) is explicitly designed to test mode dropping.,5.1. Synthetic 2D distributions,[0],[0]
The data are sampled from a mixture of concentrated Gaussians in the 2D plane.,5.1. Synthetic 2D distributions,[0],[0]
"We compare standard GAN training, “mixup” training (Zhang et al., 2017), and batch smoothing using the BGAN from Section 4.3.
",5.1. Synthetic 2D distributions,[0],[0]
"In all cases, the generators and discriminators are three-layer ReLU networks with 512 units per layer.",5.1. Synthetic 2D distributions,[0],[0]
The latent variables of the generator are 2-dimensional standard Gaussians.,5.1. Synthetic 2D distributions,[0],[0]
"The models are trained on their respective losses using the Adam (Kingma & Ba, 2015) optimizer, with default parameters.",5.1. Synthetic 2D distributions,[0],[0]
"The discriminator is trained for five steps for each generator step.
",5.1. Synthetic 2D distributions,[0],[0]
The results are summarized in Figure 3.,5.1. Synthetic 2D distributions,[0],[0]
Batch smoothing and mixup have similar effects.,5.1. Synthetic 2D distributions,[0],[0]
Results for BGAN and M-BGAN are qualitatively similar on this dataset and we only display results for BGAN.,5.1. Synthetic 2D distributions,[0],[0]
"The standard GAN setting quickly diverges, due to its inability to fit several modes simultaneously, while both batch smoothing and mixup successfully fit the majority of modes of the distribution.",5.1. Synthetic 2D distributions,[0],[0]
"Next, we consider image generation on the CIFAR10 dataset.",5.2. Experimental results on CIFAR10,[0],[0]
"We use the simple architecture from (Miyato et al., 2018), minimally modified to obtain permutation invariance thanks to (12).",5.2. Experimental results on CIFAR10,[0],[0]
All other architectural choices are unchanged.,5.2. Experimental results on CIFAR10,[0],[0]
"The same Adam hyperparameters from (Miyato et al., 2018) are used for all models: α = 2e−4, β1 = 0.5, β2 = 0.999, and no learning rate decay.",5.2. Experimental results on CIFAR10,[0],[0]
"We performed hyperparameter search for the number of discrimination steps between each generation step, ndisc, over the range {1, . . .",5.2. Experimental results on CIFAR10,[0],[0]
", 5}, and for the batch smoothing parameter γ over [0.2, 0.5].",5.2. Experimental results on CIFAR10,[0],[0]
"All models are trained for 400, 000 iterations, counting both generation and discrimination steps.",5.2. Experimental results on CIFAR10,[0],[0]
"We compare smoothed BGAN and M-BGAN, and the same network trained with spectral normalization (Miyato et al., 2018) (SN), and gradient penalty (Gulrajani et al., 2017) on both the Wasserstein (Arjovsky et al., 2017) (WGP) and the standard loss (GP).",5.2. Experimental results on CIFAR10,[0],[0]
"We also compare to a model using the batch-discrimination layer from (Salimans et al., 2016), adding a final batch discrimination layer to the architecture of (Miyato et al., 2018).",5.2. Experimental results on CIFAR10,[0],[0]
"All models are evaluated by reporting the Inception Score and the Fréchet Inception Distance (Heusel et al., 2017) and results are summarized in Table 2.",5.2. Experimental results on CIFAR10,[0],[0]
"Figure 4 displays sample images generated with our best model.
",5.2. Experimental results on CIFAR10,[0],[0]
Figure 5.2 highlights the training dynamics of each model3.,5.2. Experimental results on CIFAR10,[0],[0]
"On this architecture, M-BGAN heavily outperforms both batch discrimination and our other variants, and yields results similar to, or slightly better than (Miyato et al., 2018).",5.2. Experimental results on CIFAR10,[0],[0]
"Model trained with batch smoothing display results on par with batch discrimination, and much better than without batch smoothing.
",5.2. Experimental results on CIFAR10,[0],[0]
"3For readability, a slight smoothing is performed on the curves.",5.2. Experimental results on CIFAR10,[0],[0]
"To check the effect of the batch smoothing parameter γ on the loss, we plot the discriminator and generator losses of the network for different γ’s.",5.3. Effect of batch smoothing on the generator and discriminator losses,[0],[0]
"The smaller the γ, the purer the batches.",5.3. Effect of batch smoothing on the generator and discriminator losses,[0],[0]
We would expect discriminator training to be more difficult with larger γ.,5.3. Effect of batch smoothing on the generator and discriminator losses,[0],[0]
The results corroborate this insight (Fig. 2).,5.3. Effect of batch smoothing on the generator and discriminator losses,[0],[0]
BGAN and M-BGAN behave similarly and we only report on BGAN in the figure.,5.3. Effect of batch smoothing on the generator and discriminator losses,[0],[0]
"The discriminator loss is not directly affected by an increase in γ, but the generator loss is lower for larger γ, revealing the relative advantage of the generator on the discriminator.
",5.3. Effect of batch smoothing on the generator and discriminator losses,[0],[0]
"This suggests to increase γ if the discriminator dominates learning, and to decrease γ if the discriminator is stuck at a high value in spite of poor generated samples.",5.3. Effect of batch smoothing on the generator and discriminator losses,[0],[0]
"Finally, on the celebA face dataset, we adapt the simple architecture of (Miyato et al., 2018) to the increased resolution by adding a layer to both networks.",5.4. Qualitative results on celebA,[0],[0]
"For optimization we use Adam with β1 = 0, β2 = 0.9, α = 1e",5.4. Qualitative results on celebA,[0],[0]
"− 4, and ndisc = 1.",5.4. Qualitative results on celebA,[0],[0]
"Fig. 5 dislays BGAN samples with pure batches, and BGAN and M-BGAN samples with γ = .5.",5.4. Qualitative results on celebA,[0],[0]
The visual quality of the samples is reasonable; we believe that an improvement is visible from pure batches to M-BGAN.,5.4. Qualitative results on celebA,[0],[0]
"We introduced a method to feed batches of samples to the discriminator of a GAN in an principled way, based on two observations: feeding all-fake or all-genuine batches to a discriminator makes its task too easy; second, a simple architectural trick makes it possible to provably recover all functions of the batch as an unordered set.",6. Conclusion,[0],[0]
"Experimentally, this provides a new, alternative method to reduce mode dropping and reach good quantitative scores in GAN training.",6. Conclusion,[0],[0]
This work has been partially supported by the grant ANR-16CE23-0006,ACKNOWLEDGMENTS,[0],[0]
“Deep in France” and LabEx PERSYVAL-Lab (ANR-11-LABX-0025-01).,ACKNOWLEDGMENTS,[0],[0]
Generative adversarial networks (GANs) are powerful generative models based on providing feedback to a generative network via a discriminator network.,abstractText,[0],[0]
"However, the discriminator usually assesses individual samples.",abstractText,[0],[0]
"This prevents the discriminator from accessing global distributional statistics of generated samples, and often leads to mode dropping: the generator models only part of the target distribution.",abstractText,[0],[0]
"We propose to feed the discriminator with mixed batches of true and fake samples, and train it to predict the ratio of true samples in the batch.",abstractText,[0],[0]
The latter score does not depend on the order of samples in a batch.,abstractText,[0],[0]
"Rather than learning this invariance, we introduce a generic permutation-invariant discriminator architecture.",abstractText,[0],[0]
This architecture is provably a universal approximator of all symmetric functions.,abstractText,[0],[0]
"Experimentally, our approach reduces mode collapse in GANs on two synthetic datasets, and obtains good results on the CIFAR10 and CelebA datasets, both qualitatively and quantitatively.",abstractText,[0],[0]
Mixed batches and symmetric discriminators for GAN training,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 438–443 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
438
Identifying long-span dependencies between discourse units is crucial to improve discourse parsing performance. Most existing approaches design sophisticated features or exploit various off-the-shelf tools, but achieve little success. In this paper, we propose a new transition-based discourse parser that makes use of memory networks to take discourse cohesion into account. The automatically captured discourse cohesion benefits discourse parsing, especially for long span scenarios. Experiments on the RST discourse treebank show that our method outperforms traditional featured based methods, and the memory based discourse cohesion can improve the overall parsing performance significantly 1.",text,[0],[0]
Discourse parsing aims to identify the structure and relationship between different element discourse units (EDUs).,1 Introduction,[0],[0]
"As a fundamental topic in natural language processing, discourse parsing can assist many down-stream applications such as summarization (Louis et al., 2010), sentiment analysis (Polanyi and van den Berg, 2011) and question-answering (Ferrucci et al., 2010).",1 Introduction,[0],[0]
"However, the performance of discourse parsing is still far from perfect, especially for EDUs that are distant to each other in the discourse.",1 Introduction,[0],[0]
"In fact, as found in (Jia et al., 2018), the discourse parsing performance drops quickly as the dependency span increases.",1 Introduction,[0],[0]
"The reason may be twofold:
1Code for replicating our experiments is available at https://github.com/PKUYeYuan/ACL2018 CFDP.
",1 Introduction,[0],[0]
"Firstly, as discussed in previous works (Joty et al., 2013), it is important to address discourse structure characteristics, e.g., through modeling lexical chains in a discourse, for discourse parsing, especially in dealing with long span scenarios.",1 Introduction,[0],[0]
"However, most existing approaches mainly focus on studying the semantic and syntactic aspects of EDU pairs, in a more local view.",1 Introduction,[0],[0]
"Discourse cohesion reflects the syntactic or semantic relationship between words or phrases in a discourse, and, to some extent, can indicate the topic changing or threads in a discourse.",1 Introduction,[0],[0]
"Discourse cohesion includes five situations, including reference, substitution, ellipsis, conjunction and lexical cohesion (Halliday and Hasan, 1989).",1 Introduction,[0],[0]
"Here, lexical cohesion reflects the semantic relationship of words, and can be modeled as the recurrence of words, synonym and contextual words.
",1 Introduction,[0],[0]
"However, previous works do not well model the discourse cohesion within the discourse parsing task, or do not even take this issue into account.",1 Introduction,[0],[0]
"Morris and Hirst (1991) proposes to utilize Roget thesauri to form lexical chains (sequences of semantically related words that can reflect the topic shifts within a discourse), which are used to extract features to characterize discourse structures.",1 Introduction,[0],[0]
"(Joty et al., 2013) uses lexical chain feature to model multi-sentential relation.",1 Introduction,[0],[0]
"Actually, these simplified cohesion features can already improve parsing performance, especially in long spans.
",1 Introduction,[0],[0]
"Secondly, in modern neural network methods, modeling discourse cohesion as part of the networks is not a trivial task.",1 Introduction,[0],[0]
"One can still use off-the-shell tools to obtain lexical chains, but these tools can not be jointly optimized with the main neural network parser.",1 Introduction,[0],[0]
"We argue that characterizing discourse cohesion implicitly within a unified framework would be more
straightforward and effective for our neural network based parser.",1 Introduction,[0],[0]
"As shown in Figure 1, the 12 EDUs in the given discourse talk about different topics, marked with 3 different colors, which could be captured by a memory network that maintains several memory slots.",1 Introduction,[0],[0]
"In discourse parsing, such an architecture may help to cluster topically similar or related EDUs into the same memory slot, and each slot could be considered as a representation that maintains a specific topic or thread within the current discourse.",1 Introduction,[0],[0]
"Intuitively, we could also treat such a mechanism as a way to capture the cohesion characteristics of the discourse, just like the lexical chain features used in previous works, but without relying on external tools or resources.
",1 Introduction,[0],[0]
"In this paper, we investigate how to exploit discourse cohesion to improve discourse parsing.",1 Introduction,[0],[0]
Our contribution includes: 1) we design a memory network method to capture discourse cohesion implicitly in order to improve discourse parsing.,1 Introduction,[0],[0]
2),1 Introduction,[0],[0]
"We choose bidirectional long-short term memory (LSTM) (Hochreiter and Schmidhuber, 1997) with an attention mechanism to represent EDUs directly from embeddings, and use simple position features to capture shallow discourse structures, without relying on off-the-shelf tools or resources.",1 Introduction,[0],[0]
Experiments on the RST corpus show that the memory based discourse cohesion model can help better capture discourse structure information and lead to significant improvement over traditional feature based discourse parsing methods.,1 Introduction,[0],[0]
"Our parser is an arc-eager style transition system (Nivre, 2003) with 2 stacks and a queue as shown in Figure 2, which is similar in spirit with (Dyer et al., 2015; Ballesteros et al., 2015).",2 Model overview,[0],[0]
"We follow the conventional data structures in transition-based dependency parsing, i.e., a queue (B) of EDUs to be processed, a stack (S) to store the partially constructed discourse trees, and a stack (A) to represent the history of transitions (actions combined with discourse relations).
",2 Model overview,[0],[0]
"In our parser, the transition actions include Shift, Reduce, Left-arc and Right-arc.",2 Model overview,[0],[0]
"At each step, the parser chooses to take one of the four actions and pushes the selected transition into A. Shift pushes the first EDU in queue B to the top of the stack S, while Reduce pops the top item of S. Left-arc connects the first EDU (head) in B to the top EDU (dependent) in S and then pops the top item of S, while Right-arc connects the top EDU (head) of S to the first EDU (dependent) in B and then pushes B’s first EDU to the top of S. A parse tree can be finally constructed until B is empty and S only contains a complete discourse tree.",2 Model overview,[0],[0]
"For more details, please refer to (Nivre, 2003).
",2 Model overview,[0],[0]
"As shown in Figure 2, at time t, we characterize the current parsing process by preserving the top two elements in B, top three elements in A and the root EDU in the partially constructed tree at the top of S. We first concatenate the embeddings of the preserved elements in each data structure to obtain the embeddings of S, B and A.",2 Model overview,[0],[0]
"We then append the three representations with the position2 features (introduced in Section 2.1), respectively.",2 Model overview,[0],[0]
"We pass them through one ReLU layer and two fully connected layers with ReLU as their activation functions to obtain the final state representation pt at time t, which will be used to determine the best transition to take at t.
Next, we apply an affine transformation to pt and feed it to a softmax layer to get the distribution over all possible decisions (actions combined with discourse relations).",2 Model overview,[0],[0]
"We train our model using the automatically generated oracle action sequences as the gold-standard annotations, and utilize cross entropy as the loss function.",2 Model overview,[0],[0]
"We perform greedy search during decoding.
...
...
...
l1
l2
Pt
Word
...
a1 a2 an
POS Position1
slotj
match{ weighted sum
ReLU
FC1(ReLU)
FC2(ReLU)
S B
A
...
...
wi
softmax
RA(Li)SH ...
sloti
...
wi
} match weighted sum
Bi-LSTM
RA(Li)
SH
（1）
（2） （2）
Position2
Memory network1
Memory network2
SRefined BRefined
...",2 Model overview,[0],[0]
"Bi-LSTM
...
Figure 2: Our discourse parsing framework: (1) Basic EDU representation module; (2) Memory networks to capture the discourse cohesion so as to obtain the refined representations of S and B. RA(Li)",2 Model overview,[0],[0]
means that the chosen action is Right-arc and its relation is List.,2 Model overview,[0],[0]
SH means Shift.,2 Model overview,[0],[0]
a1 to an are weights for the attention mechanism of the bidirectional LSTM.,2 Model overview,[0],[0]
"As mentioned in previous work (Jia et al., 2018), when the top EDUs in S and B are far from each other in the discourse, i.e., with a long span, the parser will be prone to making wrong decisions.",2.1 Discourse Structures,[0],[0]
"To deal with these long-span cases, one should take discourse structures into account, e.g., extracting features from the structure of a long discourse or analyzing and characterizing different topics discussed in the discourse.
",2.1 Discourse Structures,[0],[0]
"We, therefore, choose two kinds of position features to reflect the structure information, which can be viewed as a shallow form of discourse cohesion.",2.1 Discourse Structures,[0],[0]
"The first one describes the position of an EDU alone, while the second represents the spatial relationship between the top EDUs of S and B. (1) Position1: the positions of the EDU in the sentence, paragraph and discourse, respectively.",2.1 Discourse Structures,[0],[0]
"(2) Position2: whether the top EDUs of S and B are in the same sentence/paragraph or not, and the distance between them.",2.1 Discourse Structures,[0],[0]
"Basic EDU representation: In our model, the EDUs in both S and B follow the same representation method, and we take an EDU in B as an example as shown in Figure 2.",3 Memory based Discourse Cohesion,[0],[0]
"The basic representation for an EDU is built by concatenating three components, i.e., word, POS and Position1.",3 Memory based Discourse Cohesion,[0],[0]
"Regarding word, we feed the
sequence of words in the EDU to a bi-directional Long Short Term Memory (LSTM) with attention mechanism and obtain the final word representation by concatenating the two final outputs from both directions.",3 Memory based Discourse Cohesion,[0],[0]
"Here, we use pre-trained Glove (Pennington et al., 2014) as the word embeddings.",3 Memory based Discourse Cohesion,[0],[0]
"We get the POS tags from Stanford CoreNLP toolkit (Manning et al., 2014), and similarly, send the POS tag sequence of the EDU to a bi-directional LSTM with attention mechanism to obtain the final POS representation.",3 Memory based Discourse Cohesion,[0],[0]
"For concise, we omit the bi-directional LSTM network structure for POS in Figure 2, which is the same as the one for word.",3 Memory based Discourse Cohesion,[0],[0]
"The Position1 feature vectors are randomly initialized and we expect them to work as a proxy to capture the shallow discourse structure information.
",3 Memory based Discourse Cohesion,[0],[0]
"Memory Refined Representation: Besides the shallow structure features, we design a memory network component to cluster EDUs with similar topics to the same memory slot to alleviate the long span issues, as illustrated in Figure 1.",3 Memory based Discourse Cohesion,[0],[0]
"We expect these memory slots can work as lexical chains, which can maintain different threads within the discourse.",3 Memory based Discourse Cohesion,[0],[0]
"Such a memory mechanism has the advantage that it can perform the clustering automatically and does not rely on extra tools or resources to train.
",3 Memory based Discourse Cohesion,[0],[0]
"Concretely, we match the representations of S and B with their corresponding memory networks, respectively, to get their discourse cohesion clues, which are used to improve the original representations.",3 Memory based Discourse Cohesion,[0],[0]
"Take B as an example, we first compute the similarity between the representation of B (Vb) and each memory slot mi in B’s memory.",3 Memory based Discourse Cohesion,[0],[0]
"We adopt the cosine similarity as our metric as below:
Sim[x, y] = x · y ‖x‖ · ‖y‖
(1)
",3 Memory based Discourse Cohesion,[0],[0]
"Then, we use this cosine similarity to produce a normalized weight wi for each memory slot.",3 Memory based Discourse Cohesion,[0],[0]
"We introduce a strength factor λ to improve the focus.
",3 Memory based Discourse Cohesion,[0],[0]
"wi = exp(λSim[Vb,mi])∑ j exp(λSim[Vb,mj ])
(2)
",3 Memory based Discourse Cohesion,[0],[0]
"Finally, we get the discourse cohesion clue of B (denoted by BCoh) from its memory according to the weighted sum of mi.
BCoh = ∑ i wimi (3)
",3 Memory based Discourse Cohesion,[0],[0]
"We concatenateBCoh (the discourse cohesion clue of B) and the original embedding of B to get the refined representation Brefined for B. Similarly, we concatenate SCoh and the embedding of S to get the refined representation Srefined for S, as shown in Figure 2.",3 Memory based Discourse Cohesion,[0],[0]
"In our experiments, each memory contains 20 slots, which are randomly initialized and optimized during training.",3 Memory based Discourse Cohesion,[0],[0]
Dataset:,4 Evaluation and Results,[0],[0]
"We use the RST Discourse Treebank (Carlson et al., 2001) with the same split as in (Li et al., 2014), i.e., 312 for training, 30 for development and 38 for testing.",4 Evaluation and Results,[0],[0]
"We experiment with two set of relations, the 111 types of fine-grained relations and the 19 types of coarse-grained relations, respectively.
",4 Evaluation and Results,[0],[0]
Evaluation Metrics:,4 Evaluation and Results,[0],[0]
"In the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988), head is the core of a discourse, and a dependent gives supporting evidence to its head with certain relationship.",4 Evaluation and Results,[0],[0]
"We adopt unlabeled accuracy UAS (the ratio of EDUs that correctly identify their heads) and labeled accuracy LAS (the ratio of EDUs that have both correct heads and relations) as our evaluation metrics.
",4 Evaluation and Results,[0],[0]
"Baselines: We compare our method with the following baselines and models: (1) Perceptron: We re-implement the perceptron based arc-eager style dependency discourse parser as mentioned in (Jia et al., 2018) with coarse-grained relation.",4 Evaluation and Results,[0],[0]
"The Perceptron model chooses words, POS tags, positions and length features, totally 100 feature templates, with the early update strategy (Collins and Roark, 2004).",4 Evaluation and Results,[0],[0]
(2) Jia18:,4 Evaluation and Results,[0],[0]
"Jia et al. (2018) implement a transition-based discourse parser with stacked LSTM, where they choose a two-layer LSTM to represent EDUs by encoding four kinds of features including words, POS tags, positions and length features.",4 Evaluation and Results,[0],[0]
(3) Basic EDU representation (Basic): Our discourse parser with the basic EDU representation method mentioned in Section 3.,4 Evaluation and Results,[0],[0]
(4) Memory refined representation (Refined): Our full parser equipped with the basic EDU representation method and the memory networks to capture the discourse cohesion mentioned in Section 3.,4 Evaluation and Results,[0],[0]
"(5) MST-full (Li et al., 2014): a graph-based dependency discourse parser with carefully selected 6 sets of features including words, POS tags, positions,
length, syntactic and semantic similarity features, which achieves the state-of-art performance on the RST Treebank.",4 Evaluation and Results,[0],[0]
We list the overall discourse parsing performance in Table 1.,4.1 Results,[0],[0]
"Here, Jia18, a stack LSTM based method (Jia et al., 2018), outperforms the traditional Perceptron method, but falls behind our Basic model with word, POS tags and Position features.",4.1 Results,[0],[0]
"The reason may be that representing EDUs directly from the sequence of word/POS embeddings could probably capture the semantic meaning of EDUs, which is especially useful for taking into account synonyms or paraphrases that often confuse traditional feature-based methods.",4.1 Results,[0],[0]
"We can also see that Basic(word+pos+position) significantly outperforms Basic(word+pos), as the Position features may play a crucial role in providing useful structural clues to our parser.",4.1 Results,[0],[0]
"Such position information can also be considered as a shallow treatment to capture the discourse cohesion, especially for long span scenarios.",4.1 Results,[0],[0]
"When using the memory network, our Refined method achieves better performance than the Basic(word+pos+position) in both UAS and LAS.",4.1 Results,[0],[0]
"The reason may come from the ability of the memory networks in simulating the lexical chains within a discourse, where the memory networks can model the discourse cohesion so as to provide topical or structural clues to our parser.",4.1 Results,[0],[0]
"We use SIGF V2 (Padó, 2006) to perform significance test for the discussed models.",4.1 Results,[0],[0]
"We find that the Basic(word+pos+position) method significantly outperforms (Jia et al., 2018), and our Refined model performs significantly better than Basic(word+pos+position) (with p < 0.1).
",4.1 Results,[0],[0]
"However, when compared with MST-full (Li et al., 2014), our models still fall behind this state-of-the-art method.",4.1 Results,[0],[0]
"The main reason might be that MST-full follows a global graph-based dependency parsing framework, where their high order methods (in cubic time complexity) can directly analyze the relationship between any EDUs pairs in the discourse, while, we choose the transition-based local method with linear time complexity, which can only investigate the top EDUs in S and B according to the selected actions, thus usually has a lower performance than the global graph-based methods, but with a
lower (linear) time complexity.",4.1 Results,[0],[0]
"On the other hand, the neural network components help us maintain much fewer features than MST-full, which carefully selects 6 different sets of features that are usually obtained using extra tools and resources.",4.1 Results,[0],[0]
"And, the neural network design is flexible enough to incorporate various clues into a uniform framework, just like how we introduce the memory networks as a proxy to capture discourse cohesion.
",4.1 Results,[0],[0]
"In the RST corpus, when the distance between two EDUs is larger, there are usually fewer numbers of such EDU pairs, but the parsing performance for those long span cases drops more significantly.",4.1 Results,[0],[0]
"For example, the LAS is even lower than 5% for those dependencies that have a range of 6 EDUs.",4.1 Results,[0],[0]
We take a detailed look at the parsing performance for dependencies at different lengths (from 1 to 6 as an example) using coarse-grained relations.,4.1 Results,[0],[0]
"As shown in Table 2, compared with the Basic method, both UAS and LAS of the Refined method are improved significantly in almost all spans, where we observe more prominent improvement for the UAS in larger spans such as span 5 and span 6, with about 8.70% and 6.38%, respectively.
",4.1 Results,[0],[0]
"Finally, let us take a detailed comparison between Refined and Basic to investigate the advantages of capturing discourse cohesion.",4.1 Results,[0],[0]
"Note that, our Refined method wins Basic in almost all relations.",4.1 Results,[0],[0]
"Here, we discuss one typical relation List, which often indicates a long span
dependency between a pair of EDUs.",4.1 Results,[0],[0]
"In the test set of RST, the average span for List is 7.55, with the max span of 69.",4.1 Results,[0],[0]
"Our Refined can successfully identify 55 of them, with an average span of 9.02 and the largest one of 63, while, the Basic method can only identify 41 edges labeled with List, which are mostly shorter cases, with an average span of 1.32 and the largest one of 5.",4.1 Results,[0],[0]
"More detailedly, there are 18 edges that are correctly identified by our Refined but missed by the Basic method.",4.1 Results,[0],[0]
The average span of those dependencies is 25.39.,4.1 Results,[0],[0]
"It is easy to find that without further considerations in discourse structures, the Basic method has limited ability in correctly identifying longer span dependencies.",4.1 Results,[0],[0]
"And those comparisons prove again that our Refined can take better advantage of modeling discourse cohesion, which enables our model to perform better in long span scenarios.",4.1 Results,[0],[0]
"In this paper, we propose to utilize memory networks to model discourse cohesion automatically.",5 Conclusions,[0],[0]
"By doing so we could capture the topic change or threads within a discourse, which can further improve the discourse parsing performance, especially for long span scenarios.",5 Conclusions,[0],[0]
Experimental results on the RST Discourse Treebank show that our proposed method can characterize the discourse cohesion efficiently and archive significant improvement over traditional feature based discourse parsing methods.,5 Conclusions,[0],[0]
"We would like to thank our anonymous reviewers, Bingfeng Luo, and Sujian Li for their helpful comments and suggestions, which greatly improved our work.",Acknowledgments,[0],[0]
"This work is supported by National High Technology R&D Program of China (Grant No.2015AA015403), and Natural Science Foundation of China (Grant No. 61672057, 61672058).",Acknowledgments,[0],[0]
"For any correspondence, please contact Yansong Feng.",Acknowledgments,[0],[0]
Identifying long-span dependencies between discourse units is crucial to improve discourse parsing performance.,abstractText,[0],[0]
"Most existing approaches design sophisticated features or exploit various off-the-shelf tools, but achieve little success.",abstractText,[0],[0]
"In this paper, we propose a new transition-based discourse parser that makes use of memory networks to take discourse cohesion into account.",abstractText,[0],[0]
"The automatically captured discourse cohesion benefits discourse parsing, especially for long span scenarios.",abstractText,[0],[0]
"Experiments on the RST discourse treebank show that our method outperforms traditional featured based methods, and the memory based discourse cohesion can improve the overall parsing performance significantly 1.",abstractText,[0],[0]
Modeling Discourse Cohesion for Discourse Parsing via Memory Network,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4758–4765 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4758",text,[0],[0]
Over two decades after the seminal work by Picard (1997),1 Introduction,[0],[0]
"the quest of Affective Computing, to ease the interaction with computers by giving them a sense of how emotions shape our perception and behavior, is still far from being fulfilled.",1 Introduction,[0],[0]
"Undoubtedly, major progress has been made in NLP, with sentiment analysis being one of the most vivid and productive areas in recent years (Liu, 2015).
",1 Introduction,[0],[0]
"However, the vast majority of contributions has focused on polarity prediction, typically only distinguishing between positive and negative feeling
*",1 Introduction,[0],[0]
These authors contributed equally to this work.,1 Introduction,[0],[0]
"Anneke Buffone designed and supervised the crowdsourcing task and the survey described in Section 2, and provided psychological background knowledge.",1 Introduction,[0],[0]
"Sven Buechel was responsible for corpus creation, data analysis, and modeling.",1 Introduction,[0],[0]
"The technical set-up of the crowdsourcing task and the survey was done jointly by both first authors.
",1 Introduction,[0],[0]
"†Work conducted while being at the University of Pennsylvania.
or evaluation, usually in social media postings or product reviews (Rosenthal et al., 2017; Socher et al., 2013).",1 Introduction,[0],[0]
"Only very recently, researchers started exploring more sophisticated models of human emotion on a larger scale (Wang et al., 2016; Abdul-Mageed and Ungar, 2017; Mohammad and Bravo-Marquez, 2017a; Buechel and Hahn, 2017, 2018a,b).",1 Introduction,[0],[0]
"Yet such approaches, often rooted in psychological theory, also turned out to be more challenging in respect to annotation and modeling (Strapparava and Mihalcea, 2007).
",1 Introduction,[0],[0]
"Surprisingly, one of the most valuable affective phenomena for improving human-machine interaction has received surprisingly little attention: Empathy.",1 Introduction,[0],[0]
"Prior work focused mostly on spoken dialogue, commonly addressing conversational agents, psychological interventions, or call center applications (McQuiggan and Lester, 2007; Fung et al., 2016; Pérez-Rosas et al., 2017; Alam et al., 2017).
",1 Introduction,[0],[0]
"In contrast, to the best of our knowledge, only three contributions (Xiao et al., 2012; Gibson et al., 2015; Khanpour et al., 2017) previously addressed text-based empathy prediction1 (see Section 4 for details).",1 Introduction,[0],[0]
"Yet, all of them are limited in three ways: (a) neither of their corpora are available leaving the NLP community without shared data, (b) empathy ratings were provided by others than the one actually experiencing it which qualifies only as a weak form of ground truth, and (c) their notion of empathy is quite basic, falling short of current and past theory.
",1 Introduction,[0],[0]
1 Psychological studies commonly distinguish between state and trait empathy.,1 Introduction,[0],[0]
"While the former construct describes the amount of empathy a person experiences as a direct result of encountering a given stimulus, the latter refers to how empathetic one is on average and across situations.",1 Introduction,[0],[0]
This studies exclusively addresses state empathy.,1 Introduction,[0],[0]
"For a contribution addressing trait empathy from an NLP perspective, see AbdulMageed et al. (2017).
",1 Introduction,[0],[0]
In this contribution we present the first publicly available gold standard for text-based empathy prediction.,1 Introduction,[0],[0]
It is constructed using a novel annotation methodology which reliably captures empathy assessments via multi-item scales.,1 Introduction,[0],[0]
"The corpus as well as our work as a whole is also unique in being—to the best of our knowledge—the first computational approach differentiating multiple types of empathy, empathic concern and personal distress, a distinction well recognized throughout psychology and other disciplines.2",1 Introduction,[0],[0]
Background.,2 Corpus Design and Methodology,[0],[0]
Most psychological theories of empathic states are focused on reactions to negative rather than positive events.,2 Corpus Design and Methodology,[0],[0]
"Empathy for positive events remains less well understood and is thought to be regulated differently (Morelli et al., 2015).",2 Corpus Design and Methodology,[0],[0]
Thus we focus on empathetic reactions to need or suffering.,2 Corpus Design and Methodology,[0],[0]
"Despite the fact that everyone has an immediate, implicit understanding of empathy, research has been vastly inconsistent in its definition and operationalization (Cuff et al., 2016).",2 Corpus Design and Methodology,[0],[0]
"There is agreement, however, that there are multiple forms of empathy (see below).",2 Corpus Design and Methodology,[0],[0]
"The by far most widely cited state empathy scale is Batson’s Empathic Concern – Personal Distress Scale (Batson et al., 1987), henceforth empathy and distress.
",2 Corpus Design and Methodology,[0],[0]
"Distress is a self-focused, negative affective state that occurs when one feels upset due to witnessing an entity’s suffering or need, potentially via “catching” the suffering target’s negative emotions.",2 Corpus Design and Methodology,[0],[0]
"Empathy is a warm, tender, and compassionate feeling for a suffering target.",2 Corpus Design and Methodology,[0],[0]
"It is other-focused, retains self-other separation, and is marked by relatively more positive affect (Batson and Shaw, 1991; Goetz et al., 2010; Mikulincer and Shaver, 2010; Sober and Wilson, 1997).
",2 Corpus Design and Methodology,[0],[0]
Selection of News Stories.,2 Corpus Design and Methodology,[0],[0]
"Two research interns (psychology undergraduates) collected a total of 418 articles from popular online news platforms, selected to likely evoke empathic reactions, after being briefed on the goal and background of this study.",2 Corpus Design and Methodology,[0],[0]
"These articles were then used to elicit empathic responses in participants.
",2 Corpus Design and Methodology,[0],[0]
Acquiring Text and Ratings.,2 Corpus Design and Methodology,[0],[0]
The corpus acquisition was set up as a crowdsourcing task on MTurk.com pointing to a Qualtrics.com questionnaire.,2 Corpus Design and Methodology,[0],[0]
"The participants completed back-
2Data and code are available at: https://github. com/wwbp/empathic_reactions
ground measures on demographics and personality, and then proceeded to the main part of the survey where they read a random selection of five of the news articles.",2 Corpus Design and Methodology,[0],[0]
"After reading each of the articles, participants were asked to rate their level of empathy and distress before describing their thoughts and feelings about it in writing.
",2 Corpus Design and Methodology,[0],[0]
"In contrast to previous work, this set-up allowed us to acquire empathy scores of the actual writer of a text, instead of having to rely on an external evaluation by third parties (often student assistants with background in computer science).",2 Corpus Design and Methodology,[0],[0]
"Arguably, our proposed annotation methodology yields more appropriate gold data, yet also leads to more variance in the relationship between linguistic features and empathic state ratings.",2 Corpus Design and Methodology,[0],[0]
That is because each rating reflects a single individual’s feelings rather than a more stable average assessment by multiple raters.,2 Corpus Design and Methodology,[0],[0]
"To account for this, we use multi-item scales as is common practice in psychology.",2 Corpus Design and Methodology,[0],[0]
"I.e., participants give ratings for multiple items measuring the same construct (e.g., empathy) which are then averaged to obtain more reliable results.",2 Corpus Design and Methodology,[0],[0]
"As far as we know, this is the first time that multiitem scales are used in sentiment analysis.3
In our case, participants used Batson’s Empathic Concern – Personal Distress Scale (see above), i.e, rating 6 items for empathy (e.g., warm, tender, moved) and 8 items for distress (e.g., troubled, disturbed, alarmed) using a 7-point scale for each of those (see Appendix for details).",2 Corpus Design and Methodology,[0],[0]
"After rating their empathy, participants were asked to share their feelings about the article as they would with a friend in a private message or with a group of friends as a social media post in 300 to 800 characters.",2 Corpus Design and Methodology,[0],[0]
"Our final gold standard consists of these messages combined with the numeric ratings for empathy and distress.
",2 Corpus Design and Methodology,[0],[0]
"In sum, 403 participants completed the survey.",2 Corpus Design and Methodology,[0],[0]
"Median completion time was 32 minutes and each participant received 4 USD as compensation.
",2 Corpus Design and Methodology,[0],[0]
Post-Processing.,2 Corpus Design and Methodology,[0],[0]
Each message was manually reviewed by the authors.,2 Corpus Design and Methodology,[0],[0]
"Responses which deviated from the task description (e.g., mere copying from the articles at display) were removed (31 responses, 155 messages), leading to a total 1860 messages in our final corpus.",2 Corpus Design and Methodology,[0],[0]
"Gold ratings for empathy and distress were derived by averaging the respective items of the two multi-item scales.
",2 Corpus Design and Methodology,[0],[0]
"3 Here, we use sentiment as an umbrella term subsuming semantic orientation, emotion, as well as highly related concepts such as empathy.",2 Corpus Design and Methodology,[0],[0]
"For a first impression of the language of our new gold standard, we provide illustrative examples in Table 1.",3 Corpus Analysis,[0],[0]
"The participant in Example (1) displays higher empathy than distress, (2) displays higher distress than empathy, and (3) shows neither empathic state, but employs sarcasm, colloquialisms and social-media-style acronyms to express lack of emotional response to the article.",3 Corpus Analysis,[0],[0]
"As can be seen, the language of our corpus is diverse and authentic, featuring many phenomena of natural language which render its computational understanding difficult, thus constituting a sound but challenging gold standard for empathy prediction.
",3 Corpus Analysis,[0],[0]
Token Counts.,3 Corpus Analysis,[0],[0]
"We tokenized the 1860 messages using NLTK tools (Bird, 2006).",3 Corpus Analysis,[0],[0]
"In total, our corpus amounts to 173, 686 tokens.",3 Corpus Analysis,[0],[0]
"Individual message length varies between 52 and 198 tokens, the median being 84.",3 Corpus Analysis,[0],[0]
"See Appendix for details.
",3 Corpus Analysis,[0],[0]
Rating Distribution.,3 Corpus Analysis,[0],[0]
"Figure 1 displays the bivariate distribution of empathy and distress rat-
ings.",3 Corpus Analysis,[0],[0]
"As can be seen both target variables have a clear linear dependence, yet show only a moderate Pearson correlation of r=.451, similar to what was found in prior research (Batson et al., 1987, 1997).",3 Corpus Analysis,[0],[0]
"This finding supports that the two scales capture distinct affective phenomena and underscores the importance of our decision to describe empathic states in terms of multiple target variables, constituting a clear advancement over previous work.",3 Corpus Analysis,[0],[0]
"Both kinds of ratings show good coverage over the full range of the scales.
",3 Corpus Analysis,[0],[0]
Reliability of Ratings.,3 Corpus Analysis,[0],[0]
"Since each message is annotated by only one rater, its author, typical measures of inter-rater agreement are not applicable.",3 Corpus Analysis,[0],[0]
"Instead, we compute split-half reliability (SHR), a standard approach in psychology (Cronbach, 1947) which also becomes increasingly popular in sentiment analysis (Mohammad and BravoMarquez, 2017a; Buechel and Hahn, 2018a).",3 Corpus Analysis,[0],[0]
"SHR is computed by splitting the ratings for the individual scale items (e.g., warm, tender, etc. for empathy) of all participants randomly into two groups, averaging the individual item ratings for each group and participant, and then measuring the correlation between both groups.",3 Corpus Analysis,[0],[0]
"This process is repeated 100 times with random splits, before again averaging the results.",3 Corpus Analysis,[0],[0]
"Doing so for empathy and distress, we find very high4 SHR values of r=.875 and .924, respectively.",3 Corpus Analysis,[0],[0]
"In this section, we provide experimental results for modeling empathy and distress ratings based on the participants’ messages (see Section 2).",4 Modeling Empathy and Distress,[0],[0]
"We examine three different types of models, varying in
4 For a comparison against previously reported SHR values for different emotional categories, see Mohammad and Bravo-Marquez (2017b).
design complexity.",4 Modeling Empathy and Distress,[0],[0]
"Distinct models were trained for empathy and distress prediction.
",4 Modeling Empathy and Distress,[0],[0]
"First, ten percent of our newly created gold standard were randomly sampled to be used in development experiments.",4 Modeling Empathy and Distress,[0],[0]
"Then, the main experiment was conducted using 10-fold crossvalidation (CV), providing each model with identical train-test splits to increase reliability.",4 Modeling Empathy and Distress,[0],[0]
"The dev set was excluded for the CV experiment.
",4 Modeling Empathy and Distress,[0],[0]
Model performance is measured in terms of Pearson correlation r between predicted values and the human gold ratings.,4 Modeling Empathy and Distress,[0],[0]
"Thus, we phrase the prediction of empathy and distress as regression problems.
",4 Modeling Empathy and Distress,[0],[0]
"The input to our models is based on word embeddings, namely the publicly available FastText embeddings which were trained on Common Crawl (≈600B tokens) (Bojanowski et al., 2017; Mikolov et al., 2018).
",4 Modeling Empathy and Distress,[0],[0]
Ridge.,4 Modeling Empathy and Distress,[0],[0]
"Our first approach is Ridge regression, an `2-regularized version of linear regression.",4 Modeling Empathy and Distress,[0],[0]
The centroid of the word embeddings of the words in a message is used as features (embedding centroid).,4 Modeling Empathy and Distress,[0],[0]
"The regularization coefficient α is automatically chosen from {1, .5, .1, ..., .0001} during training.
FFN.",4 Modeling Empathy and Distress,[0],[0]
"Our second approach is a Feed-Forward Net with two hidden layers (256 and 128 units, respectively) with ReLU activation.",4 Modeling Empathy and Distress,[0],[0]
"Again, the embedding centroid is used as features.
CNN.",4 Modeling Empathy and Distress,[0],[0]
"The last approach is a Convolutional Neural Net.5 We use a single convolutional layer with filter sizes 1 to 3, each with 100 output channels, followed by an average pooling layer and a dense layer of 128 units.",4 Modeling Empathy and Distress,[0],[0]
"ReLUs were used for the convolutional and again for the dense layer.
",4 Modeling Empathy and Distress,[0],[0]
"Both deep learning models were trained using the Adam optimizer (Kingma and Ba, 2015) with a fixed learning rate of 10−3 and a batch size of 32.",4 Modeling Empathy and Distress,[0],[0]
We trained for a maximum of 200 epochs yet applied early stopping if the performance on the validation set did not improve for 20 consecutive epochs.,4 Modeling Empathy and Distress,[0],[0]
"We applied dropout with probabilities of .2, .5",4 Modeling Empathy and Distress,[0],[0]
and .5,4 Modeling Empathy and Distress,[0],[0]
"on input, dense and pooling layers, respectively.",4 Modeling Empathy and Distress,[0],[0]
Moreover `2 regularization of .001 was applied to the weights of conv and dense layers.,4 Modeling Empathy and Distress,[0],[0]
"Word embeddings were not updated.
",4 Modeling Empathy and Distress,[0],[0]
The results are provided in Table 2.,4 Modeling Empathy and Distress,[0],[0]
"As can be seen, all of our models achieve satisfying performance figures ranging between r=.379 and .444,
5 Recurrent models did not perform well during development due to high sequence length.
",4 Modeling Empathy and Distress,[0],[0]
given the assumed difficulty of the task (see Section 3).,4 Modeling Empathy and Distress,[0],[0]
"On average over the two target variables, the CNN performs best, followed by Ridge and the FFN.",4 Modeling Empathy and Distress,[0],[0]
"While the CNN significantly outperforms the other models in every case, the differences between Ridge and the FFN are not statistically significant for either empathy or distress.6",4 Modeling Empathy and Distress,[0],[0]
The improvements of the CNN over the other two approaches are much more pronounced for distress than for empathy.,4 Modeling Empathy and Distress,[0],[0]
"Since only the CNN is able to capture semantic effects from composition and word order, our data suggest that these phenomena are more important for predicting distress, whereas lexical features alone already perform quite well for empathy.
",4 Modeling Empathy and Distress,[0],[0]
Discussion.,4 Modeling Empathy and Distress,[0],[0]
"In comparison to closely related tasks such as emotion prediction (Mohammad and Bravo-Marquez, 2017a)",4 Modeling Empathy and Distress,[0],[0]
our performance figures for empathy and distress prediction are generally lower.,4 Modeling Empathy and Distress,[0],[0]
"However, given the small amount of previous work for the problem at hand, we argue that our results are actually quite strong.",4 Modeling Empathy and Distress,[0],[0]
"This becomes obvious, again, in comparison with emotion analysis where early work achieved correlation values around r=.3 at most (Strapparava and Mihalcea, 2007).",4 Modeling Empathy and Distress,[0],[0]
"Yet state-of-the-art performance literally doubled over the last decade (Beck, 2017), in part due to much larger training sets.
",4 Modeling Empathy and Distress,[0],[0]
"Comparison to the limited body of previous work in text-based empathy prediction is difficult for a number of reasons, e.g., differences in domain, evaluation metric, as well as methodology and linguistic level of annotation.",4 Modeling Empathy and Distress,[0],[0]
"Khanpour et al. (2017) annotate and model empathy in online health communities on the sentence-level, whereas the instances in our corpus are much longer and comprise multiple sentences.",4 Modeling Empathy and Distress,[0],[0]
"In contrast to our work, they treat empathy prediction as a classification problem.",4 Modeling Empathy and Distress,[0],[0]
"Their best performing model, a CNN-LSTM, achieves an F-score of .78.",4 Modeling Empathy and Distress,[0],[0]
"Gibson
6We use a two-tailed t-test for paired samples based on the results of the individual CV runs; p < .05.
et al. (2015) predict therapists’ empathy in motivational interviews.",4 Modeling Empathy and Distress,[0],[0]
Each therapy session transcript received one numeric score.,4 Modeling Empathy and Distress,[0],[0]
"Thus, each prediction is based on much more language data than our individual messages comprise.",4 Modeling Empathy and Distress,[0],[0]
"Their best model achieves a Spearman rank correlation of .61 using n-gram and psycholinguistic features.
",4 Modeling Empathy and Distress,[0],[0]
"Our contribution goes beyond both of these studies by, first, enriching empathy prediction with personal distress and, second, by annotating and modeling the empathic state actually felt by the writer, instead of relying on external assessments.",4 Modeling Empathy and Distress,[0],[0]
"This contribution was the first to attempt empathy prediction in terms of multiple target variables, empathic concern and personal distress.",5 Conclusion,[0],[0]
"We proposed a novel annotation methodology capturing empathic states actually felt by the author of a statement, instead of relying on third-party assessments.",5 Conclusion,[0],[0]
"To ensure high reliability in this singlerating setting, we employ multi-item scales in line with best practices in psychology.",5 Conclusion,[0],[0]
"Hereby we create the first publicly available gold standard for empathy prediction in written language, our survey being set-up and supervised by an expert psychologist.",5 Conclusion,[0],[0]
"Our analysis shows that the data set excels with high rating reliability and an authentic and diverse language, rich of challenging phenomena such as sarcasm.",5 Conclusion,[0],[0]
"We provide experimental results for three different predictive models, our CNN turning out superior.",5 Conclusion,[0],[0]
"Sven Buechel would like to thank his doctoral advisor Udo Hahn, JULIE Lab, for funding his research visit at the University of Pennsylvania.",Acknowledgments,[0],[0]
"Details on Stimulus and Instructions
Before being used in our survey, the selected news articles were categorized by the research interns who gathered them in terms of their intensity of suffering (major or minor), cause of suffering (political, human, nature or other), patient of suffering (humans, animals, environment, or other) and scale of suffering (individual or mass).",A Supplemental Material,[0],[0]
Research interns also provided a short list of key words for each article.,A Supplemental Material,[0],[0]
"This additional information was gathered to examine the influence of these factors on empathy elicitation and modeling performance in later studies.
",A Supplemental Material,[0],[0]
"At the beginning of the survey participants completed background items covering general demographics (including age, gender, and ethnicity), the most commonly used trait empathy scale, the Interpersonal Reactivity Index (Davis, 1980), a brief assessment of the Big 5 personality traits (Gosling et al., 2003), life satisfaction (Diener et al., 1985), as well as a brief measure of generalized trust.
",A Supplemental Material,[0],[0]
"After reading each of the articles, participants rated their level of empathic concern and personal distress using multi-item scales.",A Supplemental Material,[0],[0]
"Figure 2
shows a cropped screenshot of the survey hosted on Qualtrics.com.",A Supplemental Material,[0],[0]
"The first six items (warm, tender, sympathetic, softhearted, moved, and compassionate) refer to empathy.",A Supplemental Material,[0],[0]
"The last eight items (worried, upset, troubled, perturbed, grieved, disturbed, alarmed, and distressed) refer to distress.
",A Supplemental Material,[0],[0]
"After completing the rating items, participants were instructed to describe their reactions in writing as follows: Now that you have read this article, please write a message to a friend or friends about your feelings and thoughts regarding the article you just read.",A Supplemental Material,[0],[0]
This could be a private message to a friend or something you would post on social media.,A Supplemental Material,[0],[0]
Please do not identify your intended friend(s) — just write your thoughts about the article as if you were communicating with them.,A Supplemental Material,[0],[0]
"Please use between 300 and 800 characters.
",A Supplemental Material,[0],[0]
"Further Corpus Analyses
The word clouds in Figure 3 and Figure 4 show 1- grams of our corpus which correlate significantly (Benjamini-Hochberg corrected p < .05) with high empathy and high distress ratings, respectively.",A Supplemental Material,[0],[0]
"In the word clouds, larger size indicates higher correlation and the color scale, gray-bluered, indicates word frequency, dark red being most prevalent.",A Supplemental Material,[0],[0]
"The Differential Language Analysis Toolkit (Schwartz et al., 2017) was utilized for this analysis.",A Supplemental Material,[0],[0]
"As can be seen, the word clouds display high face-validity, giving further evidence for the soundness of our acquisition methodology.
",A Supplemental Material,[0],[0]
Figure 5 displays the distribution of the message length of our corpus in tokens.,A Supplemental Material,[0],[0]
As can be seen the majority of messages contain between 60 and 100 tokens.,A Supplemental Material,[0],[0]
Yet outliers go up to almost 200.,A Supplemental Material,[0],[0]
The introduction of a character cap for the writing task proved successful in comparison to a pilot study where this measure has not been in place.,A Supplemental Material,[0],[0]
"In the latter case, the maximum number of tokens was nearly twice as high due to even stronger outliers.",A Supplemental Material,[0],[0]
Computational detection and understanding of empathy is an important factor in advancing human-computer interaction.,abstractText,[0],[0]
"Yet to date, textbased empathy prediction has the following major limitations: It underestimates the psychological complexity of the phenomenon, adheres to a weak notion of ground truth where empathic states are ascribed by third parties, and lacks a shared corpus.",abstractText,[0],[0]
"In contrast, this contribution presents the first publicly available gold standard for empathy prediction.",abstractText,[0],[0]
It is constructed using a novel annotation methodology which reliably captures empathy assessments by the writer of a statement using multiitem scales.,abstractText,[0],[0]
"This is also the first computational work distinguishing between multiple forms of empathy, empathic concern, and personal distress, as recognized throughout psychology.",abstractText,[0],[0]
"Finally, we present experimental results for three different predictive models, of which a CNN performs the best.",abstractText,[0],[0]
Modeling Empathy and Distress in Reaction to News Stories,title,[0],[0]
"Proceedings of the SIGDIAL 2018 Conference, pages 20–31, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics
20",text,[0],[0]
"Every person is unique, yet they often share general patterns of behavior.",1 Introduction,[0],[0]
"Theories of personality aim to explain these patterns in terms of personality traits, e.g. the Big Five traits of extraversion or agreeableness.",1 Introduction,[0],[0]
"Previous work has shown: (1) the language that people generate includes linguistic features that express these personality traits; (2) it is possible to train models to automatically recognize a person’s personality from his language; and (3) it is possible to automatically train models for natural language generation that express personality traits (Pennebaker and King, 1999; Mairesse et al., 2007; Mairesse and Walker, 2011; Gill et al., 2012).
",1 Introduction,[0],[0]
"A distinct line of work has shown that people adapt to one another’s conversational behaviors and that conversants reliably re-use or mimic many
different aspects of their partner’s verbal and nonverbal behaviors, including lexical and syntactical traits, accent, speech rate, pause length, etc.",1 Introduction,[0],[0]
"(Coupland et al., 1988; Willemyns et al., 1997; Brennan and Clark, 1996; Branigan et al., 2010; Coupland et al., 1988; Parent and Eskenazi, 2010; Reitter et al., 2006a; Chartrand and Bargh, 1999; Hu et al., 2014).",1 Introduction,[0],[0]
"Previous work primarily focuses on developing methods on measuring adaptation in dialog, and studies have shown that adaptation measures are correlated with task success (Reitter and Moore, 2007), and that social variables such as power affect adaptation (Danescu-Niculescu-Mizil et al., 2012).
",1 Introduction,[0],[0]
We posit that it is crucial to enable adaptation in computer agents in order to make them more human-like.,1 Introduction,[0],[0]
"However, we need models to control the amount of adaptation in natural language generation.",1 Introduction,[0],[0]
"A primary challenge is that dialogs exhibit many different types of linguistic features, any or all of which, in principle, could be adapted.",1 Introduction,[0],[0]
"Previous work has often focused on individual features when measuring adaptation, and referring expressions have often been the focus, but the conversants in the dialog in Figure 1 from the ArtWalk Corpus appear to be adapting to the discourse marker okay in D98 and F98, the hedge kinda like in F100, and to the adjectival phrase like a vase in D101.
",1 Introduction,[0],[0]
"Therefore we propose a novel adaptation measure, Dialog Adaptation Score (DAS), which can model adaptation on any subset of linguistic features and can be applied on a turn by turn basis to any segment of dialog.",1 Introduction,[0],[0]
"Consider the example shown in Table 1, where the context (prime) is taken from an actual dialog.",1 Introduction,[0],[0]
"A response (target) with no adaptation makes the utterance stiff (DAS = 0), and too much adaptation (to all four discourse markers in prime, DAS = 1) makes the utterance unnatural.",1 Introduction,[0],[0]
"Our hypothesis is that we can learn models to approximate the appropriate amount of adaptation from the actual human response to the context (to discourse marker “okay”, DAS = 0.25).
",1 Introduction,[0],[0]
Conversants in dialogs express their own personality and adapt to their dialog partners simultaneously.,1 Introduction,[0],[0]
Our measure of adaptation produces models for adaptive natural language generation (NLG) for dialogs that integrates the predictions of both personality theories and adaptation theories.,1 Introduction,[0],[0]
"NLGs need to operate as a dialog unfolds on a turnby-turn basis, thus the requirements for a model of adaptation for NLG are different than simply measuring adaptation.
",1 Introduction,[0],[0]
Context:,1 Introduction,[0],[0]
okay alright,1 Introduction,[0],[0]
so,1 Introduction,[0],[0]
yeah,1 Introduction,[0],[0]
Im looking at 123 Locust right now Linguistic Features:,1 Introduction,[0],[0]
Discourse markers:,1 Introduction,[0],[0]
"okay, alright, so, yeah",1 Introduction,[0],[0]
"Referring expressions: 123 Locust Syntactic structures: VP->VBP+VP, VP->VBG+PP+ADVB ...
",1 Introduction,[0],[0]
We apply our method to multiple corpora to investigate how the dialog situation and speaker roles affect the level and type of adaptation to the other speaker.,1 Introduction,[0],[0]
"We show that:
• Different feature sets and conversational situations can have different adaptation models; • Speakers usually adapt more when they have
the initiative; • The degree of adaptation may vary over the
course of a dialog, and decreases as the adaptation window size increases.",1 Introduction,[0],[0]
Our goal is an algorithm for adaptive natural language generation (NLG) that controls the system output at each step of the dialog.,2 Method and Overview,[0],[0]
Our first aim therefore is a measure of dialog adaptation that can be applied on a turn by turn basis as a dialog unfolds.,2 Method and Overview,[0],[0]
"For this purpose, previous measures of dialog adaptation (Stenchikova and Stent, 2007; Danescu-Niculescu-Mizil et al., 2011) have two limitations: (1) their calculation require the complete dialog, and (2) they focus on single features and do not provide a model to control the interaction of multiple parameters in a single output, while our method measures adaptation with respect to any set of features.",2 Method and Overview,[0],[0]
"We further compare our method to existing measures in Section 6.
",2 Method and Overview,[0],[0]
"Measures of adaptation focus on prime-target pairs: (p, t), in which the prime contains linguistic features that the target may adapt to.",2 Method and Overview,[0],[0]
"While linguistic adaptation occur beyond the next turn, we simplify the calculation by using a window size of 1 for most experiments: for every utterance in the dialog (prime), we consider the next utterance by a different speaker as the target, if any.",2 Method and Overview,[0],[0]
We show the decay of adaptation with increasing window size in a separate experiment.,2 Method and Overview,[0],[0]
"When generating (p, t) pairs, it is possible to consider only speaker A adapting to speaker B (target=A), only speaker B adapting to speaker A (target=B), or both at the same time (target=Both).",2 Method and Overview,[0],[0]
"In the following definition, FCi(p) is the count of features in prime p of the i-th (p, t) pair, n is the total number of prime-target pairs in which FCi(p) 6= 0, similarly, FCi(p ∧ t) is the count of features in both prime p and target t.",2 Method and Overview,[0],[0]
"We define Dialog Adaptation Score (DAS) as:
DAS = 1
n n∑ i=1",2 Method and Overview,[0],[0]
"FCi(p ∧ t) FCi(p)
",2 Method and Overview,[0],[0]
"Within a feature set, DAS reflects the average probability that features in prime are adapted in target across all prime-target pairs in a dialog.",2 Method and Overview,[0],[0]
"Thus our Dialog Adaptation Score (DAS) models adaptation with respect to feature sets, providing a wholedialog adaptation model or a turn-by-turn adaptation model.",2 Method and Overview,[0],[0]
"The strength of DAS is the ability to model different classes of features related to individual differences such as personalities or social variables of interest such as status.
",2 Method and Overview,[0],[0]
DAS scores measured using various feature sets can be used as a vector model to control adaptation in Natural Language Generation (NLG).,2 Method and Overview,[0],[0]
"Although
we leave the application of DAS to NLG to future work, here we describe how we expect to use it.",2 Method and Overview,[0],[0]
"We consider the use of DAS with three NLG architectures: Overgeneration and Rank, Statistical Parameterized NLG, and Neural NLG.",2 Method and Overview,[0],[0]
Overgenerate and Rank.,2 Method and Overview,[0],[0]
"In this approach, different modules propose a possibly large set of next utterances in parallel, which are then fed to a (trained) ranker that outputs the top-ranked utterance.",2 Method and Overview,[0],[0]
"Previous work on adaptation/alignment in NLG has made use of this architecture (Brockmann, 2009; Buschmeier et al., 2010).",2 Method and Overview,[0],[0]
We can rank the generated responses based on the distances between their DAS vectors and learned DAS adaptation model.,2 Method and Overview,[0],[0]
The response with the smallest distance is the response with the best amount of adaptation.,2 Method and Overview,[0],[0]
We can also emphasize specific feature sets by giving weights to different dimensions of the vector and calculating weighted distance.,2 Method and Overview,[0],[0]
"For instance, in order to adapt more to personality and avoid too much lexical mimicry, one could prioritize related LIWC features, and adapt by using words from the same LIWC categories.",2 Method and Overview,[0],[0]
Statistical Parameterized NLG.,2 Method and Overview,[0],[0]
"Some NLG engines provide a list of parameters that can be controlled at generation time (Paiva and Evans, 2004; Lin and Walker, 2017).",2 Method and Overview,[0],[0]
DAS scores can be used as generation decision probabilities.,2 Method and Overview,[0],[0]
A DAS score of 0.48 for the LIWC feature set indicates that the probability of adapting to LIWC features in discourse context (prime) is 0.48.,2 Method and Overview,[0],[0]
"By mapping DAS scores to generation parameters, the generator could be directly controlled to exhibit the correct amount of adaptation for any feature set.",2 Method and Overview,[0],[0]
Neural NLG.,2 Method and Overview,[0],[0]
"Recent work in Neural NLG (NNLG) explores controlling stylistic variation in outputs using a vector to encode style parameters, possibly in combination with the use of a context vector to represent the dialog context (Ficler and Goldberg, 2017; Oraby et al., 2018).",2 Method and Overview,[0],[0]
The vector based probabilities that are represented in the DAS adaptation model could be encoded into the context vector in NNLG.,2 Method and Overview,[0],[0]
"No other known adaptation measures could be used in this way.
",2 Method and Overview,[0],[0]
"We hypothesize that different conversational contexts may lead to more or less adaptive behavior, so we apply DAS on four human-human dialog corpora: two task-oriented dialog corpora that were designed to elicit adaptation (ArtWalk and Walking Around), one topic-centric spontaneous dialog corpus (Switchboard), and the MapTask Corpus used in much previous work.",2 Method and Overview,[0],[0]
"We obtain linguistic
features using fully automatic annotation tools, described in Section 4.",2 Method and Overview,[0],[0]
We learn models of adaptation from these dialogs on various feature sets.,2 Method and Overview,[0],[0]
We first validate the DAS measure by showing that DAS distinguishes original dialogs from dialogs where the orders of the turns have been randomized.,2 Method and Overview,[0],[0]
We then show how DAS varies as a function of the feature sets used and the dialog corpora.,2 Method and Overview,[0],[0]
"We also show how DAS can be used for fine-grained adaptation by applying DAS to individual dialog segments, and individual speakers, and illustrating the differences in adaptation as a function of these variables.",2 Method and Overview,[0],[0]
"Finally, we show how DAS scores decrease as the adaptation window size increases.",2 Method and Overview,[0],[0]
We develop models of adaptation using DAS on the following four corpora.,3 Corpora,[0],[0]
"ArtWalk Corpus (AWC).1 Figure 1 provides a sample of the Artwalk Corpus (Liu et al., 2016), a collection of mobile-to-Skype conversations between friend and stranger dyads performing a real world-situated task that was designed to elicit adaptation behaviors.",3 Corpora,[0],[0]
"Every dialog involves a stationary director on campus, and a follower downtown.",3 Corpora,[0],[0]
"The director provided directions to help the follower find 10 public art pieces such as sculptures, mosaics, or murals in downtown Santa Cruz.",3 Corpora,[0],[0]
The director had access to Google Earth views of the follower’s route and a map with locations and pictures of art pieces.,3 Corpora,[0],[0]
The corpus consists of transcripts of 24 friend and 24 stranger dyads (48 dialogs).,3 Corpora,[0],[0]
"In total, it contains approximately 185,000 words and 23,000 turns, from conversations that ranged from 24 to 55 minutes, or 197 to 691 turns.",3 Corpora,[0],[0]
"It includes referent negotiation, direction-giving, and small talk (non-task talk).2 Walking Around Corpus (WAC).3 The Walking Around Corpus",3 Corpora,[0],[0]
"(Brennan et al., 2013) consists of spontaneous spoken dialogs produced by 36 pairs of people, collected in order to elicit adaptation behaviors, as illustrated by Figure 2.",3 Corpora,[0],[0]
"In each dialog, a director navigates a follower using a mobile phone to 18 destinations on a medium-sized campus.",3 Corpora,[0],[0]
"Directors have access to a digital map marked with
1https://nlds.soe.ucsc.edu/artwalk 2For AWC and WAC, we remove annotations such as speech overlap, noises (laugh, cough) and indicators for short pauses, leaving only clean text.",3 Corpora,[0],[0]
"If more than one consecutive dialog turn has the same speaker, we merge them into one dialog turn.
",3 Corpora,[0],[0]
"3https://catalog.ldc.upenn.edu/ ldc2015s08
target destinations, labels (e.g. “Ship sculpture”), photos and followers’ real time location.",3 Corpora,[0],[0]
"Followers carry a cell phone with GPS, and a camera in order to take pictures of the destinations they visit.",3 Corpora,[0],[0]
Each dialog ranges from 175 to 885 turns.,3 Corpora,[0],[0]
"The major differences between AWC and WAC are (1) in order to elicit novel referring expressions and possible linguistic adaptation, destinations in AWC do not have provided labels; (2) AWC happens in a more open world setting (downtown) compared to WAC (university campus).",3 Corpora,[0],[0]
"Map Task Corpus (MPT).4 The Map Task Corpus (Anderson et al., 1991) is a set of 128 cooperative task-oriented dialogs involving two participants.",3 Corpora,[0],[0]
Each dialog ranges from 32 to 438 turns.,3 Corpora,[0],[0]
A director and a follower sit opposite one another.,3 Corpora,[0],[0]
Each has a paper map which the other cannot see (the maps are not identical).,3 Corpora,[0],[0]
The director has a route marked on their map; the follower has no route.,3 Corpora,[0],[0]
The participants’ goal is to reproduce the director’s route on the follower’s map.,3 Corpora,[0],[0]
"All maps consist of line drawing landmarks labelled with their names, such as “parked van”, “east lake”, or “white mountain”.",3 Corpora,[0],[0]
"Figure 3 shows an excerpt from the Map Task Corpus. Switchboard Corpus (SWBD).5 Switchboard (Godfrey et al., 1992) is a collection of two-speaker telephone conversations from all areas of the United States.",3 Corpora,[0],[0]
"An automatic operator handled the calls (giving recorded prompts, selecting and dialing another speaker, introducing discussion topics and recording the dialog).",3 Corpora,[0],[0]
"70 topics were provided, for example: pets, child care, music, and buying a car.",3 Corpora,[0],[0]
"Each topic has a corresponding prompt message played to the first speaker, e.g. “find out what kind of pets the
4http://groups.inf.ed.ac.uk/maptask/ 5https://catalog.ldc.upenn.edu/
ldc97s62
other caller has.”",3 Corpora,[0],[0]
"A subset of 200K utterances of Switchboard have also been tagged with dialog act tags (Jurafsky et al., 1997).",3 Corpora,[0],[0]
Each dialog contains 14 to 373 turns.,3 Corpora,[0],[0]
"Figure 1 provides an example of dialog act tags, such as b - Acknowledge (Backchannel), sv - Statement-opinion, sd - Statement-non-opinion, and % - Uninterpretable.",3 Corpora,[0],[0]
"We focus on this subset of the corpus.
",3 Corpora,[0],[0]
"Dialogs in SWBD have a different style from the three task-oriented, direction-giving corpora.",3 Corpora,[0],[0]
"Figure 4 illustrates how the SWBD dialogs are often lopsided: from utterance 14 to 18, speaker B states his opinion with verbose dialog turns, whereas speaker A only acknowledges and backchannels; from utterance 19 to 22, speaker A acts as the main speaker, whereas speaker B backchannels.",3 Corpora,[0],[0]
"Some theories of discourse define dialog turns as extending over backchannels, and we posit that this
would allow us to measure adaptation more faithfully, so we utilize the SWBD dialog act tags to filter turns that only contain backchannels, keeping only dialog turns with tags sd (Statement-nonopinion), sv (Statement-opinion), and bf (Summarize/reformulate).6",3 Corpora,[0],[0]
We then merge consecutive dialog turns from the same speaker.,3 Corpora,[0],[0]
"We consider the following feature sets: unigram, bigram, referring expressions, hedges/discourse markers, and Linguistic Inquiry and Word Count (LIWC) features.",4 Experimental Setup,[0],[0]
"Previous computational work on measuring linguistic adaptation in textual corpora have largely focused on lexical and syntactical features, which are included as baselines.",4 Experimental Setup,[0],[0]
"Referring expressions and discourse markers are key features that are commonly studied for adaptation behaviors in task-oriented dialogs, which are often hand annotated.",4 Experimental Setup,[0],[0]
Here we automatically extract these features by rules.,4 Experimental Setup,[0],[0]
"To model adaptation on the personality level, we draw features that correlate significantly with personality ratings from LIWC features.",4 Experimental Setup,[0],[0]
"We hypothesize that our feature sets will demonstrate different adaptation models.
",4 Experimental Setup,[0],[0]
"We lemmatize, POS tag and derive constituency structures using Stanford CoreNLP",4 Experimental Setup,[0],[0]
"(Manning et al., 2014).",4 Experimental Setup,[0],[0]
We then extract the following linguistic features from annotations and raw text.,4 Experimental Setup,[0],[0]
The following example features are based on D137 in Figure 2.,4 Experimental Setup,[0],[0]
Unigram Lemma/POS.,4 Experimental Setup,[0],[0]
We use lemma combined with POS tags to distinguish word senses.,4 Experimental Setup,[0],[0]
"E.g., lemmapos building/NN and lemmapos brick/NNS in D137.",4 Experimental Setup,[0],[0]
Bigram Lemma.,4 Experimental Setup,[0],[0]
"E.g., bigram the-brick and bigram side-of in D137.",4 Experimental Setup,[0],[0]
Syntactic Structure.,4 Experimental Setup,[0],[0]
"Following Reitter et al. (2006b), we take all the subtrees from a constituency parse tree (excluding the leaf nodes that contain words) as features.",4 Experimental Setup,[0],[0]
"E.g., syntax VP->VBP+PP and syntax ADJP-> DT+JJ in D137.",4 Experimental Setup,[0],[0]
The difference is that we use Stanford Parser rather than hand annotations.,4 Experimental Setup,[0],[0]
Referring Expression.,4 Experimental Setup,[0],[0]
Referring expressions are usually noun phrases.,4 Experimental Setup,[0],[0]
"We start by taking all constituency subtrees with root NP, then map the subtrees to their actual phrases in the text and remove all articles from the phrase, e.g., referexp little-concrete
6The filtering process removes 48.1% original dialog turns, but only 12.6% of the words.",4 Experimental Setup,[0],[0]
"Filtered dialogs have 3 to 85 dialog turns each.
and referexp math-building in D137.",4 Experimental Setup,[0],[0]
Hedge/Discourse Marker.,4 Experimental Setup,[0],[0]
"Hedges are mitigating words used to lessen the impact of an utterance, such as “actually” and “somewhat”.",4 Experimental Setup,[0],[0]
"Discourse markers are words or phrases that manage the flow and structure of discourse, such as “you know” and “I mean”.",4 Experimental Setup,[0],[0]
"We construct a dictionary of hedges and discourse markers, and use string matching to extract features, e.g., hedge you-know and hedge like in D137.",4 Experimental Setup,[0],[0]
LIWC.,4 Experimental Setup,[0],[0]
"Linguistic Inquiry and Word Count (Pennebaker et al., 2001) is a text analysis program that counts words in over 80 linguistic (e.g., pronouns, conjunctions), psychological (e.g., anger, positive emotion), and topical (e.g., leisure, money) categories.",4 Experimental Setup,[0],[0]
"E.g., liwc second-person and liwc informal in D137.",4 Experimental Setup,[0],[0]
"Because DAS features are binary, features such as Word Count and Number of New Lines are excluded.",4 Experimental Setup,[0],[0]
Personality LIWC.,4 Experimental Setup,[0],[0]
"Previous work reports for each LIWC feature whether it is significantly correlated with each Big Five trait (Mairesse et al., 2007) on conversational data (Mehl et al., 2006).",4 Experimental Setup,[0],[0]
"For each trait, we create feature sets consisting of such features.",4 Experimental Setup,[0],[0]
See Table 2.,4 Experimental Setup,[0],[0]
"In this section, we apply our DAS measure on the corpora introduced in Section 3.",5 Experiments on Modeling Adaptation,[0],[0]
"We first establish that our novel DAS measure is valid by testing whether it can distinguish dialogs in their original order vs. dialogs with randomly scrambled turns (the order of dialog turns are randomized within speakers), inspired by similar approaches in previous work (Gandhe and Traum, 2008; Ward and Litman, 2007; Barzilay and Lapata, 2005).",5.1 Validity Test: Original vs. Randomized Dialogs,[0],[0]
"We calculate DAS scores for original dialogs and randomized dialogs using target=Both
(Sec. 2) to obtain overall adaptation scores for both speakers.
",5.1 Validity Test: Original vs. Randomized Dialogs,[0],[0]
We first test on lexical features (unigram and bigram) as in previous work.,5.1 Validity Test: Original vs. Randomized Dialogs,[0],[0]
"Then we add additional linguistic features (syntactic structure, referring expression, and discourse marker).",5.1 Validity Test: Original vs. Randomized Dialogs,[0],[0]
These five features (see Section 4) are referred to as “all but LIWC”.,5.1 Validity Test: Original vs. Randomized Dialogs,[0],[0]
"Finally, we test DAS validity using the higher level LIWC features.
",5.1 Validity Test: Original vs. Randomized Dialogs,[0],[0]
"We perform paired t-tests on DAS scores for original dialogs and DAS scores for randomized dialogs, pairing every original dialog with its randomized dialog.",5.1 Validity Test: Original vs. Randomized Dialogs,[0],[0]
"Table 3 shows the number of dialogs in each corpus, the average DAS scores of all dialogs within the corpus and p-values of corresponding t-tests.",5.1 Validity Test: Original vs. Randomized Dialogs,[0],[0]
"Although the differences between the average scores are relatively small, the differences in almost all paired t-tests are extremely statistically significant (cells in bold, p < 0.0001).",5.1 Validity Test: Original vs. Randomized Dialogs,[0],[0]
The paired t-test on MPT using LIWC features shows a significant difference between the two test groups (p < 0.05).,5.1 Validity Test: Original vs. Randomized Dialogs,[0],[0]
The original dialog corpora achieve higher average DAS scores than the randomized corpora for all 12 original-random pairs.,5.1 Validity Test: Original vs. Randomized Dialogs,[0],[0]
"The results show that DAS measure is sensitive to dialog turn order, as it should be if it is measuring dialog coherence and adaptation.",5.1 Validity Test: Original vs. Randomized Dialogs,[0],[0]
This experiment aims to broadly examine the differences in adaptation across different corpora and feature sets.,5.2 Adaptation across corpora and across features,[0],[0]
"We first compute DAS on the whole
dialog level for each feature set from Section 4, and then calculate the average across the corpus.",5.2 Adaptation across corpora and across features,[0],[0]
We use target=Both (Sec 2) to obtain an overall measure of adaptation and leave calculating finegrained DAS measures to Section 5.3.,5.2 Adaptation across corpora and across features,[0],[0]
Table 4 provides results.,5.2 Adaptation across corpora and across features,[0],[0]
"We will refer to features in row 1 to 6 as “linguistic features” and row 7 to 11 as “personality features”.
",5.2 Adaptation across corpora and across features,[0],[0]
"Comparing columns, we first examine the DAS scores across different corpora.",5.2 Adaptation across corpora and across features,[0],[0]
All p-values reported below are from paired t-tests.,5.2 Adaptation across corpora and across features,[0],[0]
"The two most similar corpora, the AWC and WAC, show no significant difference on linguistic features (p = 0.43).",5.2 Adaptation across corpora and across features,[0],[0]
"At the same time, the AWC and WAC do differ from the other two corpora.",5.2 Adaptation across corpora and across features,[0],[0]
This demonstrates that the DAS reflects real similarities and differences across corpora.,5.2 Adaptation across corpora and across features,[0],[0]
"MPT shows lower DAS scores on all linguistic features except for lemma (word repetition), where it achieves the highest DAS score.",5.2 Adaptation across corpora and across features,[0],[0]
"With respect to personality features, WAC has significantly higher DAS scores than AWC (p < 0.05), possibly because of the different experiment settings: college student participants are more comfortable around their own campus than in downtown.",5.2 Adaptation across corpora and across features,[0],[0]
MPT shows significantly lower DAS scores on personality features than AWC and WAC (p < 0.05).,5.2 Adaptation across corpora and across features,[0],[0]
This may be because the MPT setting is the most constrained of the four corpora: being fixed in topic and location means dialogs are less likely to be influenced by environmental factors or to contain social chit chat.,5.2 Adaptation across corpora and across features,[0],[0]
SWBD has the highest DAS scores in all feature sets except for referring expression.,5.2 Adaptation across corpora and across features,[0],[0]
The higher DAS in nonreferring features could be because the social chit chat allows more adaptation to occur.,5.2 Adaptation across corpora and across features,[0],[0]
"In addition, the dialogs we measure in SWBD are backchannelfiltered.",5.2 Adaptation across corpora and across features,[0],[0]
"The lower referring expression (respective to other SWBD scores) could be because SWBD does not require the referring expressions necessary
for the other three task-related corpora.",5.2 Adaptation across corpora and across features,[0],[0]
"We posit that the DAS adaptation models we present can be used in existing NLG architectures, described in Sec. 2.",5.2 Adaptation across corpora and across features,[0],[0]
"The AWC column in Table 4 shows adaptation model in the form of a DAS vector obtained from the ArtWalk Corpus.
",5.2 Adaptation across corpora and across features,[0],[0]
"Comparing rows, we then examine DAS scores among different features sets.",5.2 Adaptation across corpora and across features,[0],[0]
"LIWC has the highest DAS score among linguistic features, ranging from 0.48 to 0.71.",5.2 Adaptation across corpora and across features,[0],[0]
"While other linguistic features are largely content-specific, LIWC consists of higher level features that cover broader categories, thus its high DAS scores are expected.",5.2 Adaptation across corpora and across features,[0],[0]
"The DAS scores for the lemma feature range from 0.14 to 0.29, followed by Syntactic Structure (0.11 to 0.28), Hedge (0.17 to 0.25) and Bigram (0.01 to 0.07).",5.2 Adaptation across corpora and across features,[0],[0]
"Referring Expression has the lowest DAS score (0.01 to 0.03), possibly because our automatic extraction of referring expressions creates numerous subsets of one referring expression.",5.2 Adaptation across corpora and across features,[0],[0]
"Among personality features, Emotion Stability, Agreeableness, and Openness to Experience traits are adapted more than Extraversion and Conscientiousness.",5.2 Adaptation across corpora and across features,[0],[0]
We leave to future work the question of why these traits have higher DAS scores.,5.2 Adaptation across corpora and across features,[0],[0]
Our primary goal is to model adaptation at a finegrained level in order to provide fine-grained control of an NLG engine.,5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
"To that end, we report results for adaptation models on a per dialog-segment and per-speaker basis.
",5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
"Reliable discourse segmentation is notoriously difficult (Passonneau and Litman, 1996), thus we heuristically divide each task-oriented dialog into segments based on number of destinations on the map: this effectively divides the dialog into subtasks.",5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
"Since each dialog in SWBD only has one topic, we divide SWBD into 5 segments.7 We compute DAS for each segment, and take an average across all dialogs in the corpus for each segment.
",5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
We compare all LIWC features vs. extraversion LIWC features because they provide high DAS scores across corpora.,5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
We also aim to explore the dynamics between two conversants on the extraversion scale.,5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
Figure 5 in Appendix illustrates how DAS varies as a function of speaker and dialog segment.,5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
"In AWC, scores for all LIWC features
7To ensure two way adaptation exists in every segment (both speaker A adapting to B, and B adapting to A), the minimum length (number of turns) of each segment is 3.",5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
"Thus we only work with dialogs longer than 15 turns in SWBD.
slightly decrease as dialogs progress (Fig. 5(a)), while extraversion features show a distinct increasing trend with correlation coefficients ranging from 0.7 to 0.86 (Fig. 5(b)), despite being a subset of all LIWC features.8 Average DAS displays the same decreasing trend in all and extraversion LIWC features for SWBD (Fig. 5(g) and 5(h)).",5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
"We speculate that this might be due to the setup of SWBD: as the dialogs progress, conversants have less to discuss about the topic and are less interested.",5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
"We also calculate per segment adaptation in WAC and MPT, but their DAS scores do not show overall trends across the length of the dialog (Fig. 5(c) to 5(f)).
",5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
We also explore whether speaker role and initiative affects adaptation.,5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
"We use target=Both, target=D, and target=F to calculate DAS for each target.9",5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
We hypothesize that directors and followers adapt differently in task-oriented dialogs.,5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
"In all task-oriented corpora (AWC, WAC, and MPT), we observe generally higher DAS scores with target=D, indicating that in order to drive the dialogs, directors adapt more to followers.",5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
"In SWBD, the speaker initiating the call (who brings up the discussion topic and may therefore drive the conversation) generally exhibits more adaptation.",5.3 Adaptation by Dialog Segment and Speaker,[0],[0]
This experiment aims to examine the trend of DAS scores as the window size increases.,5.4 Adaptation on Different Window Sizes,[0],[0]
We begin with a window size of 1 and gradually increase it to 5.,5.4 Adaptation on Different Window Sizes,[0],[0]
"For a window size of n, the target utterance t is paired with the n-th utterance from a different speaker preceding t, if any.",5.4 Adaptation on Different Window Sizes,[0],[0]
"For example, in Figure 1, when window size is 3, target D100 is paired with prime F97; target D99 does not have any prime, thus no pair is formed.
",5.4 Adaptation on Different Window Sizes,[0],[0]
"Similar to Sec. 5.1, we compare DAS scores between dialogs in their original order vs. dialogs with randomly scrambled turns.",5.4 Adaptation on Different Window Sizes,[0],[0]
"We hypothesize that similar to the results of repetition decay measures (Reitter et al., 2006a; Ward and Litman, 2007; Pietsch et al., 2012), the DAS scores of original dialogs would decrease as the window size increases.",5.4 Adaptation on Different Window Sizes,[0],[0]
"We use target=both to obtain overall adaptation scores involving both speakers, and calculate DAS with all but the Personality LIWC feature sets introduced in Sec. 4.",5.4 Adaptation on Different Window Sizes,[0],[0]
"We first compute DAS on the whole dialog level for each window size, and then calculate the average DAS for each window size
8Using Simple Linear Regression in Weka 3.8.1.",5.4 Adaptation on Different Window Sizes,[0],[0]
"9In task-oriented dialogs, D stands for Director, F for Fol-
lower.",5.4 Adaptation on Different Window Sizes,[0],[0]
"In SWBD, D stands for the speaker initiating the call.
across the corpus.",5.4 Adaptation on Different Window Sizes,[0],[0]
"Results show that DAS scores for the original dialogs in all corpora decrease as window size increases, while DAS scores for the randomized dialogs stay relatively stable.",5.4 Adaptation on Different Window Sizes,[0],[0]
Figure 6 in Appendix shows plots of average DAS scores on different window sizes for original and randomized dialogs.,5.4 Adaptation on Different Window Sizes,[0],[0]
Plots of the AWC and WAC show similar trends.,5.4 Adaptation on Different Window Sizes,[0],[0]
Experiments with larger window sizes show that the original and random scores meet at window size 6 - 7 (with different versions of randomized dialogs).,5.4 Adaptation on Different Window Sizes,[0],[0]
"In MapTask, the original and random scores meet at window size 3 - 4.",5.4 Adaptation on Different Window Sizes,[0],[0]
"In SWBD, original and random scores meet at window size 2.",5.4 Adaptation on Different Window Sizes,[0],[0]
"Recent measures of linguistic adaptation fall into three categories: probabilistic measures, repetition decay measures, and document similarity measures (Xu and Reitter, 2015).",6 Related Work,[0],[0]
Probabilistic measures compute the probability of a single linguistic feature appearing in the target after its appearance in the prime.,6 Related Work,[0],[0]
"Some measures in this category focus more on comparing adaptation amongst features and do not handle turn by turn adaptation (Church, 2000; Stenchikova and Stent, 2007).",6 Related Work,[0],[0]
"Moreover, these measures produce scores for individual features, which need aggregation to reflect overall adaptivity (Danescu-Niculescu-Mizil et al., 2011, 2012).",6 Related Work,[0],[0]
"Document similarity measures calculate the similarity between prime and target by measuring the number of features that appear in both prime and target, normalized by the size of the two text sets (Wang et al., 2014).",6 Related Work,[0],[0]
"Both probabilistic measures and document similarity measures require the whole dialog to be complete before calculation.
",6 Related Work,[0],[0]
Repetition decay measures observe the decay rate of repetition probability of linguistic features.,6 Related Work,[0],[0]
"Previous work has fit the probability of linguistic feature repetition decrease with the distance between prime and target in logarithmic decay models (Reitter et al., 2006a,b; Reitter, 2008), linear decay models (Ward and Litman, 2007), and exponential decay models (Pietsch et al., 2012).
",6 Related Work,[0],[0]
Previous work on linguistic adaptation in natural language generation has also attempted to use adaptation models learned from human conversations.,6 Related Work,[0],[0]
"The alignment-capable microplanner SPUD prime (Buschmeier et al., 2009, 2010) uses the repetition decay model from Reitter (2008) as part of the activation functions for linguistic structures.",6 Related Work,[0],[0]
"However, the parameters are not learned from real
data.",6 Related Work,[0],[0]
"Repetition decay models do well in statistical parameterized NLG, but is hard to apply to overgenerate and rank NLG.",6 Related Work,[0],[0]
Isard et al. (2006) apply a pre-trained n-grams adaptation model to generate conversations.,6 Related Work,[0],[0]
"Hu et al. (2014) explore the effects of adaptation to various features by human evaluations, but their generator is not capable of deciding which features to adapt based on input context.",6 Related Work,[0],[0]
Dušek and Jurčı́ček (2016) use a seq2seq model to generate responses adapting to previous context.,6 Related Work,[0],[0]
They utilize an n-gram match ranker that promotes outputs with phrase overlap with context.,6 Related Work,[0],[0]
Our learned adaptation models could serve as a ranker.,6 Related Work,[0],[0]
"In addition to n-grams, DAS could produce models with any combinations of feature sets, providing more versatile adaptation behavior.",6 Related Work,[0],[0]
"To obtain models of linguistic adaptation, most measures could only measure an individual feature at a time, and need the whole dialog to calculate the measure (Church, 2000; Stenchikova and Stent, 2007; Danescu-Niculescu-Mizil et al., 2012; Pietsch et al., 2012; Reitter et al., 2006b; Ward and Litman, 2007).",7 Discussion and Future Work,[0],[0]
"This paper proposes the Dialog Adaptation Score (DAS) measure, which can be applied to NLG because it can be calculated on any segment of a dialog, and for any feature set.
",7 Discussion and Future Work,[0],[0]
"We first validate our measure by showing that the average DAS of original dialogs is significantly higher than randomized dialogs, indicating that it is sensitive to dialog priming as intended.",7 Discussion and Future Work,[0],[0]
"We then use DAS to show that feature sets such as LIWC, Syntactic Structure, and Hedge/Discourse Marker are adapted more than Bigram and Referring Expressions.",7 Discussion and Future Work,[0],[0]
We also demonstrate how we can use DAS to develop fine-grained models of adaptation: e.g. DAS applied to model adaptation in extraversion displays a distinct trend compared to all LIWC features in the task-oriented dialog corpus AWC.,7 Discussion and Future Work,[0],[0]
"Finally, we show that the degree of adaptation decreases as the window size increases.",7 Discussion and Future Work,[0],[0]
We leave to future work the implementation and evaluation of DAS adaptation models in natural language generation systems.,7 Discussion and Future Work,[0],[0]
"This research was supported by NSF CISE RI EAGER #IIS-1044693, NSF CISE CreativeIT #IIS1002921, NSF CHS #IIS-1115742, Nuance Foundation Grant SC-14-74, and auxiliary REU supplements.",Acknowledgement,[0],[0]
Previous work has shown that conversants adapt to many aspects of their partners’ language.,abstractText,[0],[0]
"Other work has shown that while every person is unique, they often share general patterns of behavior.",abstractText,[0],[0]
"Theories of personality aim to explain these shared patterns, and studies have shown that many linguistic cues are correlated with personality traits.",abstractText,[0],[0]
"We propose an adaptation measure for adaptive natural language generation for dialogs that integrates the predictions of both personality theories and adaptation theories, that can be applied as a dialog unfolds, on a turn by turn basis.",abstractText,[0],[0]
"We show that our measure meets criteria for validity, and that adaptation varies according to corpora and task, speaker, and the set of features used to model it.",abstractText,[0],[0]
"We also produce fine-grained models according to the dialog segmentation or the speaker, and demonstrate the decaying trend of adaptation.",abstractText,[0],[0]
Modeling Linguistic and Personality Adaptation for Natural Language Generation,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 2289–2299 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
2289",text,[0],[0]
"Understanding a story requires reasoning about the causal links between the events in the story and the mental states of the characters, even when those relationships are not explicitly stated.",1 Introduction,[0],[0]
"As shown by the commonsense story cloze shared task (Mostafazadeh et al., 2017)",1 Introduction,[0],[0]
", this reasoning is remarkably hard for both statistical and neural machine readers – despite being trivial for humans.",1 Introduction,[0],[0]
This stark performance gap between humans and machines is not surprising as most powerful language models have been designed to effectively learn local fluency patterns.,1 Introduction,[0],[0]
"Consequently, they generally lack the ability to abstract away from surface patterns in text to model more complex implied dynamics, such as intuiting characters’ mental states or predicting their plausible next actions.
",1 Introduction,[0],[0]
"In this paper, we construct a new annotation formalism to densely label commonsense short stories (Mostafazadeh et al., 2016) in terms of the mental states of the characters.",1 Introduction,[0],[0]
"The result-
The band instructor told the band to start playing.",1 Introduction,[0],[0]
"They grew tired and started playing worse after a while.
",He often stopped the music when players were off-tone.,[0],[0]
"The instructor was furious and threw his chair.
",He often stopped the music when players were off-tone.,[0],[0]
"He cancelled practice and expected us to perform
tomorrow.
",He often stopped the music when players were off-tone.,[0],[0]
"Instructor Players
E M E M
E M E M
E M E M
E M E M
E M E M
confide nt
[esteem]",He often stopped the music when players were off-tone.,[0],[0]
"[anger]
need re st
[esteem]
frustrate d
angry afraid
[disgust, fear]
",He often stopped the music when players were off-tone.,[0],[0]
"[esteem]
M EE
M [stability]
Figure 1: A story example with partial annotations for motivations (dashed) and emotional reactions (solid).",He often stopped the music when players were off-tone.,[0],[0]
"Open text explanations are in black (e.g., “frustrated”) and formal theory labels are in blue with brackets (e.g., “[esteem]”).
",He often stopped the music when players were off-tone.,[0],[0]
ing dataset offers three unique properties.,He often stopped the music when players were off-tone.,[0],[0]
"First, as highlighted in Figure 1, the dataset provides a fully-specified chain of motivations and emotional reactions for each story character as preand post-conditions of events.",He often stopped the music when players were off-tone.,[0],[0]
"Second, the annotations include state changes for entities even when they are not mentioned directly in a sentence (e.g., in the fourth sentence in Figure 1, players would feel afraid as a result of the instructor throwing a chair), thereby capturing implied effects unstated in the story.",He often stopped the music when players were off-tone.,[0],[0]
"Finally, the annotations encompass both formal labels from multiple theories of psychology (Maslow, 1943; Reiss, 2004; Plutchik, 1980) as well as open text descriptions of motivations and emotions, providing a comprehensive mapping between open text explanations and label categories (e.g., “to spend time with her son”
!",He often stopped the music when players were off-tone.,[0],[0]
Maslow’s category love).,He often stopped the music when players were off-tone.,[0],[0]
"Our corpus1 spans across 15k stories, amounting to 300k low-level annotations for around 150k character-line pairs.
",He often stopped the music when players were off-tone.,[0],[0]
"Using our new corpus, we present baseline performance on two new tasks focusing on mental state tracking of story characters: categorizing motivations and emotional reactions using theory labels, as well as describing motivations and emotional reactions using open text.",He often stopped the music when players were off-tone.,[0],[0]
Empirical results demonstrate that existing neural network models including those with explicit or latent entity representations achieve promising results.,He often stopped the music when players were off-tone.,[0],[0]
"Understanding people’s actions, motivations, and emotions has been a recurring research focus across several disciplines including philosophy and psychology (Schachter and Singer, 1962; Burke, 1969; Lazarus, 1991; Goldman, 2015).",2 Mental State Representations,[0],[0]
We draw from these prior works to derive a set of categorical labels for annotating the step-by-step causal dynamics between the mental states of story characters and the events they experience.,2 Mental State Representations,[0],[0]
"We use two popular theories of motivation: the “hierarchy of needs” of Maslow (1943) and the “basic motives” of Reiss (2004) to compile 5 coarse-grained and 19 fine-grained motivation categories, shown in Figure 2.",2.1 Motivation Theories,[0],[0]
"Maslow’s “hierarchy of needs” are comprised of five categories, ranging from physiological needs to spiritual growth, which we use as coarse-level categories.",2.1 Motivation Theories,[0],[0]
Reiss (2004) proposes 19 more fine-grained categories that provide a more informative range of motivations.,2.1 Motivation Theories,[0],[0]
"For example, even though they both relate
1We make our dataset publicly available at https:// uwnlp.github.io/storycommonsense/
to the physiological needs Maslow category, the food and rest motives from Reiss (2004) are very different.",2.1 Motivation Theories,[0],[0]
"While the Reiss theory allows for finergrained annotations of motivation, the larger set of abstract concepts can be overwhelming for annotators.",2.1 Motivation Theories,[0],[0]
"Motivated by Straker (2013), we design a hybrid approach, where Reiss labels are annotated as sub-categories of Maslow categories.",2.1 Motivation Theories,[0],[0]
"Among several theories of emotion, we work with the “wheel of emotions” of Plutchik (1980), as it has been a common choice in prior literature on emotion categorization (Mohammad and Turney, 2013; Zhou et al., 2016).",2.2 Emotion Theory,[0],[0]
We use the eight basic emotional dimensions as illustrated in Figure 2.,2.2 Emotion Theory,[0],[0]
"In addition to the motivation and emotion categories derived from psychology theories, we also obtain open text descriptions of character mental states.",2.3 Mental State Explanations,[0],[0]
"These open text descriptions allow learning computational models that can explain the mental states of characters in natural language, which is likely to be more accessible and informative to end users than having theory categories alone.",2.3 Mental State Explanations,[0],[0]
"Collecting both theory categories and open text also allows us to learn the automatic mappings between the two, which generalizes the previous work of Mohammad and Turney (2013) on emotion category mappings.",2.3 Mental State Explanations,[0],[0]
"In this study, we choose to annotate the simple commonsense stories introduced by Mostafazadeh et al. (2016).",3 Annotation Framework,[0],[0]
"Despite their simplicity, these stories pose a significant challenge to natural language understanding models (Mostafazadeh et al., 2017).
",3 Annotation Framework,[0],[0]
"In addition, they depict multiple interactions between story characters, presenting rich opportunities to reason about character motivations and reactions.",3 Annotation Framework,[0],[0]
"Furthermore, there are more than 98k such stories currently available covering a wide range of everyday scenarios.
",3 Annotation Framework,[0],[0]
"Unique Challenges While there have been a variety of annotated resources developed on the related topics of sentiment analysis (Mohammad and Turney, 2013; Deng and Wiebe, 2015), entity tracking (Hoffart et al., 2011; Weston et al., 2015), and story understanding (Goyal et al., 2010; Ouyang and McKeown, 2015; Lukin et al., 2016), our study is the first to annotate the full chains of mental state effects for story characters.",3 Annotation Framework,[0],[0]
"This poses several unique challenges as annotations require (1) interpreting discourse (2) understanding implicit causal effects, and (3) understanding formal psychology theory categories.",3 Annotation Framework,[0],[0]
"In prior literature, annotations of this complexity have typically been performed by experts (Deng and Wiebe, 2015; Ouyang and McKeown, 2015).",3 Annotation Framework,[0],[0]
"While reliable, these annotations are prohibitively expensive to scale up.",3 Annotation Framework,[0],[0]
"Therefore, we introduce a new annotation framework that pipelines a set of smaller isolated tasks as illustrated in Figure 3.",3 Annotation Framework,[0],[0]
All annotations were collected using crowdsourced workers from Amazon Mechanical Turk.,3 Annotation Framework,[0],[0]
We describe the components and workflow of the full annotation pipeline shown in Figure 3 below.,3.1 Annotation Pipeline,[0],[0]
"The example story in the figure is used to illustrate the output of various steps in the pipeline (full annotations for this example are in the appendix).
",3.1 Annotation Pipeline,[0],[0]
(1) Entity Resolution The first task in the pipeline aims to discover (1) the set of characters,3.1 Annotation Pipeline,[0],[0]
Ei in each story i and (2) the set of sentences Sij in which a specific character j 2,3.1 Annotation Pipeline,[0],[0]
"Ei is ex-
plicitly mentioned.",3.1 Annotation Pipeline,[0],[0]
"For example, in the story in Figure 3, the characters identified by annotators are “I/me” and “My cousin”, whom appear in sentences {1, 4, 5} and {1, 2, 3, 4, 5}, respectively.
",3.1 Annotation Pipeline,[0],[0]
We use Sij to control the workflow of later parts of the pipeline by pruning future tasks for sentences that are not tied to characters.,3.1 Annotation Pipeline,[0],[0]
"Because Sij is used to prune follow-up tasks, we take a high recall strategy to include all sentences that at least one annotator selected.
",3.1 Annotation Pipeline,[0],[0]
(2a) Action Resolution The next task identifies whether a character j appearing in a sentence k is taking any action to which a motivation can be attributed.,3.1 Annotation Pipeline,[0],[0]
We perform action resolution only for sentences k 2 Sij .,3.1 Annotation Pipeline,[0],[0]
"In the running example, we would want to know that the cousin in line 2 is not doing anything intentional, allowing us to omit this line in the next pipeline stage (3a) where a character’s motives are annotated.",3.1 Annotation Pipeline,[0],[0]
"Description of state (e.g., “Alex is feeling blue”) or passive event participation (e.g., “Alex trips”) are not considered volitional acts for which the character may have an underlying motive.",3.1 Annotation Pipeline,[0],[0]
"For each line and story character pair, we obtain 4 annotations.",3.1 Annotation Pipeline,[0],[0]
"Because pairs can still be filtered out in the next stage of annotation, we select a generous threshold where only 2 annotators must vote that an intentional action took place for the sentence to be used as an input to the motivation annotation task (3a).
",3.1 Annotation Pipeline,[0],[0]
(2b),3.1 Annotation Pipeline,[0],[0]
Affect Resolution This task aims to identify all of the lines where a story character j has an emotional reaction.,3.1 Annotation Pipeline,[0],[0]
"Importantly, it is often possible to infer the emotional reaction of a character j even when the character does not explicitly appear in a sentence k.",3.1 Annotation Pipeline,[0],[0]
"For instance, in Figure 3, we want to annotate the narrator’s reaction to line 2 even though they are not mentioned because their emotional response is inferrable.",3.1 Annotation Pipeline,[0],[0]
"We obtain 4 an-
notations per character per line.",3.1 Annotation Pipeline,[0],[0]
"The lines with at least 2 annotators voting are used as input for the next task: (3b) emotional reaction.
",3.1 Annotation Pipeline,[0],[0]
(3a) Motivation We use the output from the action resolution stage (2a) to ask workers to annotate character motives in lines where they intentionally initiate an event.,3.1 Annotation Pipeline,[0],[0]
"We provide 3 annotators a line from a story, the preceding lines, and a specific character.",3.1 Annotation Pipeline,[0],[0]
They are asked to produce a free response sentence describing what causes the character’s behavior in that line and to select the most related Maslow categories and Reiss subcategories.,3.1 Annotation Pipeline,[0],[0]
"In Figure 3, an annotator described the motivation of the narrator in line 1 as wanting “to have company” and then selected the love (Maslow) and family (Reiss) as categorical labels.",3.1 Annotation Pipeline,[0],[0]
"Because many annotators are not familiar with motivational theories, we require them to complete a tutorial the first time they attempt the task.
",3.1 Annotation Pipeline,[0],[0]
"(3b) Emotional Reaction Simultaneously, we use the output from the affect resolution stage (2b) to ask workers what the emotional response of a character is immediately following a line in which they are affected.",3.1 Annotation Pipeline,[0],[0]
"As with the motives, we give 3 annotators a line from a story, its previous context, and a specific character.",3.1 Annotation Pipeline,[0],[0]
We ask them to describe in open text how the character will feel following the event in the sentence (up to three emotions).,3.1 Annotation Pipeline,[0],[0]
"As a follow-up, we ask workers to compare their free responses against Plutchik categories by using 3-point likert ratings.",3.1 Annotation Pipeline,[0],[0]
"In Figure 3, we include a response for the emotional reaction of the narrator in line 1.",3.1 Annotation Pipeline,[0],[0]
"Even though the narrator was not mentioned directly in that line, an annotator recorded that they will react to their cousin being a slob by feeling “annoyed” and selected the Plutchik categories for sadness, disgust and anger.",3.1 Annotation Pipeline,[0],[0]
Cost The tasks corresponding to the theory category assignments are the hardest and most expensive in the pipeline (⇠$4 per story).,3.2 Dataset Statistics and Insights,[0],[0]
"Therefore, we obtain theory category labels only for a third of our annotated stories, which we assign to the development and test sets.",3.2 Dataset Statistics and Insights,[0],[0]
"The training data is annotated with a shortened pipeline with only open text descriptions of motivations and emotional reactions from two workers (⇠$1 per story).
",3.2 Dataset Statistics and Insights,[0],[0]
"Scale Our dataset to date includes a total of 300k low-level annotations for motivation and emotion across 15,000 stories (randomly selected from the ROC story training set).",3.2 Dataset Statistics and Insights,[0],[0]
"It covers over 150,000 character-line pairs, in which 56k character-line pairs have an annotated motivation and 105k have an annotated change in emotion (i.e. a label other than none).",3.2 Dataset Statistics and Insights,[0],[0]
"Table 1 shows the break down across training, development, and test splits.",3.2 Dataset Statistics and Insights,[0],[0]
"Figure 4 shows the frequency of different labels being selected for motivational and emotional categories in cases with positive change.
",3.2 Dataset Statistics and Insights,[0],[0]
"Agreements For quality control, we removed workers who consistently produced low-quality work, as discussed in the Appendix.",3.2 Dataset Statistics and Insights,[0],[0]
"In the categorization sets (Maslow, Reiss and Plutchik), we compare the performance of annotators by treating each individual category as a binary label (1
if they included the category in their set of responses) and averaging the agreement per category.",3.2 Dataset Statistics and Insights,[0],[0]
"For Plutchik scores, we count ‘moderately associated’ ratings as agreeing with ‘highly’ associated’ ratings.",3.2 Dataset Statistics and Insights,[0],[0]
The percent agreement and Krippendorff’s alpha are shown in Table 2.,3.2 Dataset Statistics and Insights,[0],[0]
"We also compute the percent agreement between the individual annotations and the majority labels.2
These scores are difficult to interpret by themselves, however, as annotator agreement in our categorization system has a number of properties that are not accounted for by these metrics (disagreement preferences – joy and trust are closer than joy and anger – that are difficult to quantify in a principled way, hierarchical categories map-
2Majority label for the motivation categories is what was agreed upon by at least two annotators per category.",3.2 Dataset Statistics and Insights,[0],[0]
"For emotion categories, we averaged the point-wise ratings and counted a category if the average rating was 2.
",3.2 Dataset Statistics and Insights,[0],[0]
"ping Reiss subcategories from Maslow categories, skewed category distributions that inflate PPA and deflate KA scores, and annotators that could select multiple labels for the same examples).
",3.2 Dataset Statistics and Insights,[0],[0]
"To provide a clearer understanding of agreement within this dataset, we create aggregated confusion matrices for annotator pairs.",3.2 Dataset Statistics and Insights,[0],[0]
"First, we sum the counts of combinations of answers between all paired annotations (excluding none labels).",3.2 Dataset Statistics and Insights,[0],[0]
"If an annotator selected multiple categories, we split the count uniformly among the selected categories.",3.2 Dataset Statistics and Insights,[0],[0]
We compute NPMI over the total confusion matrix.,3.2 Dataset Statistics and Insights,[0],[0]
"In Figure 5, we show the NPMI confusion matrix for motivational categories.
",3.2 Dataset Statistics and Insights,[0],[0]
"In the motivation annotations, we find the highest scores on the diagonal (i.e., Reiss agreement), with most confusions occurring between Reiss motives in the same Maslow category (outlined black in Figure 5).",3.2 Dataset Statistics and Insights,[0],[0]
"Other disagreements generally involve Reiss subcategories that are thematically similar, such as serenity (mental relaxation) and rest (physical relaxation).",3.2 Dataset Statistics and Insights,[0],[0]
"We provide this analysis for Plutchik categories in the appendix, finding high scores along the diagonal with disagreements typically occurring between categories in a “positive emotion” cluster (joy, trust) or a “negative emotion” cluster (anger, disgust,sadness).",3.2 Dataset Statistics and Insights,[0],[0]
The multiple modes covered by the annotations in this new dataset allow for multiple new tasks to be explored.,4 Tasks,[0],[0]
"We outline three task types below, covering a total of eight tasks on which to evaluate.
",4 Tasks,[0],[0]
"Differences between task type inputs and outputs are summarized in Figure 6.
",4 Tasks,[0],[0]
State Classification,4 Tasks,[0],[0]
"The three primary tasks involve categorizing the psychological states of story characters for each of the label sets (Maslow, Reiss, Plutchik) collected for the dev and test splits of our dataset.",4 Tasks,[0],[0]
"In each classification task, a model is given a line of the story (along with optional preceding context lines) and a character and predicts the motivation (or emotional reaction).",4 Tasks,[0],[0]
"A binary label is predicted for each of the Maslow needs, Reiss motives or Plutchik categories.
",4 Tasks,[0],[0]
"Annotation Classification Because the dev and test sets contain paired classification labels and free text explanations, we propose three tasks where a model must predict the correct Maslow/Reiss/Plutchik label given an emotional reaction or motivation explanation.
",4 Tasks,[0],[0]
"Explanation Generation Finally, we can use the free text explanations to train models to describe the psychological state of a character in free text (examples in Figure 4).",4 Tasks,[0],[0]
These explanations allow for two conditional generation tasks where the model must generate the words describing the emotional reaction or motivation of the character.,4 Tasks,[0],[0]
The general model architectures for the three tasks are shown in Figure 6.,5 Baseline Models,[0],[0]
We describe each model component below.,5 Baseline Models,[0],[0]
"The state classification and explanation generation models could be trained separately or in a multi-task set-up.
",5 Baseline Models,[0],[0]
"In the state classification and explanation generation tasks, a model is given a line from a story
x s containing N words {ws0, ws1, . . .",5 Baseline Models,[0],[0]
", wsN} from vocabulary V , a character in that story ej 2 E where E is the set of characters in the story, and (optionally) the preceding sentences in the story C = {x0 . . .",5 Baseline Models,[0],[0]
",xs 1} containing words from vocabulary V .",5 Baseline Models,[0],[0]
"A representation for a character’s psychological state is encoded as:
h e = Encoder(x s,C[ej ]) (1)
where C[ej ] corresponds to the concatenated subset of sentences in C where ej appears.",5 Baseline Models,[0],[0]
"While the end classifier or decoder is different for each task, we use the same set of encoders based on word embeddings, common neural network architectures, or memory networks to formulate a representation of the sentence and character, he.",5.1 Encoders,[0],[0]
"Unless specified, he is computed by encoding separate vector representations for the sentence (xs ! hs) and character-specific context (C[ej ] !",5.1 Encoders,[0],[0]
hc) and concatenating these encodings (he =,5.1 Encoders,[0],[0]
[hc;hs]).,5.1 Encoders,[0],[0]
"We describe the encoders below:
TF-IDF We learn a TD-IDF model on the full training corpus of Mostafazadeh et al. (2016) (excluding the stories in our dev/test sets).",5.1 Encoders,[0],[0]
"To encode the sentence, we extract TF-IDF features for its words, yielding vs 2 RV .",5.1 Encoders,[0],[0]
"A projection and nonlinearity is applied to these features to yield hs:
h s =",5.1 Encoders,[0],[0]
"(Wsv s + bs) (2)
where Ws 2 Rd⇥H .",5.1 Encoders,[0],[0]
"The character vector hc is encoded in the same way on sentences in the context pertaining to the character.
",5.1 Encoders,[0],[0]
"GloVe We extract pretrained Glove vectors (Pennington et al., 2014) for each word in V .",5.1 Encoders,[0],[0]
"The word embeddings are max-pooled, yielding embedding vs 2 RH , where H is the dimensionality of the Glove vectors.",5.1 Encoders,[0],[0]
"Using this max-pooled representation, hs and hc are extracted in the same manner as for TF-IDF features (Equation 2).
",5.1 Encoders,[0],[0]
CNN We implement a CNN text categorization model using the same configuration as Kim (2014) to encode the sentence words.,5.1 Encoders,[0],[0]
"A sentence is represented as a matrix, vs 2 RM⇥d where each row is a word embedding xsn for a word wsn 2 xs.
vs =",5.1 Encoders,[0],[0]
"[xs0, x s 1, . . .",5.1 Encoders,[0],[0]
",",5.1 Encoders,[0],[0]
"x s N ] (3)
h s = CNN(vs) (4)
where CNN represents the categorization model from (Kim, 2014).",5.1 Encoders,[0],[0]
The character vector hc is encoded in the same way with a separate CNN.,5.1 Encoders,[0],[0]
"Implementation details are provided in the appendix.
",5.1 Encoders,[0],[0]
LSTM,5.1 Encoders,[0],[0]
A two-layer bi-LSTM encodes the sentence words and concatenates the final time step hidden states from both directions to yield hs.,5.1 Encoders,[0],[0]
"The character vector hc is encoded the same way.
",5.1 Encoders,[0],[0]
REN We use the “tied” recurrent entity network from Henaff et al. (2017).,5.1 Encoders,[0],[0]
"A memory cell m is initialized for each of the J characters in the story, E = {e0, . . .",5.1 Encoders,[0],[0]
", eJ}.",5.1 Encoders,[0],[0]
The REN reads documents one sentence at a time and updates mj for ej 2 E after reading each sentence.,5.1 Encoders,[0],[0]
"Unlike the previous encoders, all sentences of the context C are given to the REN along with the sentence xs.",5.1 Encoders,[0],[0]
The model learns to distribute encoded information to the correct memory cells.,5.1 Encoders,[0],[0]
"The representation passed to the downstream model is:
h e = {mj}s (5)
where {mj}s is the memory vector in the cell corresponding to ej after reading xs.",5.1 Encoders,[0],[0]
"Implementation details are provided in the appendix.
",5.1 Encoders,[0],[0]
"NPN We also include the neural process network from Bosselut et al. (2018) with “tied” entities, but “untied” actions that are not grounded to particular concepts.",5.1 Encoders,[0],[0]
The memory is initialized and accessed similarly as the REN.,5.1 Encoders,[0],[0]
Exact implementation details are provided in the appendix.,5.1 Encoders,[0],[0]
"Once the sentence-character encoding he is extracted, the state classifier predicts a binary label ŷz for every category z 2 Z where Z is the set of category labels for a particular psychological theory (e.g., disgust, surprise, etc. in the Plutchik wheel).",5.2 State Classifier,[0],[0]
"We use logistic regression as a classifier:
ŷz =",5.2 State Classifier,[0],[0]
"(Wzh e + bz) (6)
where Wz and bz are a label-specific set of weights and biases for classifying each label z 2 Z .",5.2 State Classifier,[0],[0]
"The explanation generator is a single-layer LSTM (Hochreiter and Schmidhuber, 1997) that receives the encoded sentence-character representation he and predicts each word yt in the explanation using the same method from Sutskever et al. (2014).",5.3 Explanation Generator,[0],[0]
Implementation details are provided in the appendix.,5.3 Explanation Generator,[0],[0]
"For annotation classification tasks, words from open-text explanations are encoded with TF-IDF features.",5.4 Annotation Classifier,[0],[0]
The same classifier architecture from Section 5.2 is used to predict the labels.,5.4 Annotation Classifier,[0],[0]
State Classification,6.1 Training,[0],[0]
The dev set D is split into two portions of 80% (D1) and 20% (D2).,6.1 Training,[0],[0]
D1 is used to train the classifier and encoder.,6.1 Training,[0],[0]
D2 is used to tune hyperparameters.,6.1 Training,[0],[0]
"The model is trained to minimize the weighted binary cross entropy of predicting a class label yz for each class z:
L = ZX
z=1
zyz log ŷz+(1 z)(1 yz) log(1 ŷz)
(7) where Z is the number of labels in each of the three classifications tasks and z is defined as:
z = 1 e p P (yz) (8)
where P (yz) is the marginal class probability of a positive label for z in the training set.
",6.1 Training,[0],[0]
Annotation Classification,6.1 Training,[0],[0]
The dev set is split in the same manner as for state classification.,6.1 Training,[0],[0]
The TF-IDF features are trained on the set of training annotations Dt coupled with those from D1.,6.1 Training,[0],[0]
The model must minimize the same loss as in Equation 7.,6.1 Training,[0],[0]
"Details are provided in the appendix.
",6.1 Training,[0],[0]
Explanation Generation We use the training set of open annotations to train a model to predict explanations.,6.1 Training,[0],[0]
"The decoder is trained to minimize the negative loglikelihood of predicting each word in the explanation of a character’s state:
Lgen = TX
t=1
logP (yt|y0, ..., yt 1,he) (9)
where he is the sentence-character representation produced by an encoder from Section 5.1.",6.1 Training,[0],[0]
"Classification For the state and annotation classification task, we report the micro-averaged precision (P), recall (R), and F1 score of the Plutchik, Maslow, and Reiss prediction tasks.",6.2 Metrics,[0],[0]
We report the results of selecting a label at random in the top two rows of Table 3.,6.2 Metrics,[0],[0]
"Note that random is low because the distribution of positive instances for each
category is very uneven: macro-averaged positive class probabilities of 8.2, 1.7, and 9.9% per category for Maslow, Reiss, and Plutchik respectively.
",6.2 Metrics,[0],[0]
"Generation Because explanations tend to be short sequences (Figure 4) with high levels of synonymy, traditional metrics such as BLEU are inadequate for evaluating generation quality.",6.2 Metrics,[0],[0]
We use the vector average and vector extrema metrics from Liu et al. (2016) computed using the Glove vectors of generated and reference words.,6.2 Metrics,[0],[0]
We report results in Table 5 on the dev set and compare to a baseline that randomly samples an example from the dev set as a generated sequence.,6.2 Metrics,[0],[0]
Story Context vs. No Context,6.3 Ablations,[0],[0]
Our dataset is motivated by the importance of interpreting story context to categorize emotional reactions and motivations of characters.,6.3 Ablations,[0],[0]
"To test this importance, we ablate hc, the representation of the context sentences pertaining to the character, as an input to the state classifier for each encoder (except the REN and NPN).",6.3 Ablations,[0],[0]
"In Table 3, this ablation is the first row for each encoder presented.
",6.3 Ablations,[0],[0]
"Explanation Pretraining Because the state classification and explanation generation tasks use the same models to encode the story, we explore initializing a classification encoder with parameters trained on the generation task.",6.3 Ablations,[0],[0]
"For the CNN, LSTM, and REN encoders, we pretrain a generator to produce emotion or motivation explana-
tions.",6.3 Ablations,[0],[0]
We use the parameters from the emotion or motivation explanation generators to initialize the Plutchik or Maslow/Reiss classifiers respectively.,6.3 Ablations,[0],[0]
"State Classification We show results on the test set for categorizing Maslow, Reiss, and Plutchik states in Table 3.",7 Experimental Results,[0],[0]
"Despite the difficulty of the task, all models outperform the random baseline.",7 Experimental Results,[0],[0]
"Interestingly, the performance boost from adding entity-specific contextual information (i.e., not ablating hc) indicates that the models learn to condition on a character’s previous experience to classify its mental state at the current time step.",7 Experimental Results,[0],[0]
This effect can be seen in a story about a man whose flight is cancelled.,7 Experimental Results,[0],[0]
"The model without context predicts the same emotional reactions for the man, his wife and the pilot, but with context correctly predicts that the pilot will not have a reaction while predicting that the man and his wife will feel sad.
",7 Experimental Results,[0],[0]
"For the CNN, LSTM, REN, and NPN models, we also report results from pretraining encoder parameters using the free response annotations from the training set.",7 Experimental Results,[0],[0]
"This pretraining offers a clear performance boost for all models on all three prediction tasks, showing that the parameters of the encoder can be pretrained on auxiliary tasks providing emotional and motivational state signal.
",7 Experimental Results,[0],[0]
"The best performing models in each task are most effective at predicting Maslow physiological needs, Reiss food motives, and Plutchik reactions of joy.",7 Experimental Results,[0],[0]
"The relative ease of predicting motivations
related to food (and physiological needs generally) may be because they involve a more limited and concrete set of actions such as eating or cooking.
",7 Experimental Results,[0],[0]
Annotation Classification Table 4 shows that a simple model can learn to map open text responses to categorical labels.,7 Experimental Results,[0],[0]
"This further supports our hypothesis that pretraining a classification model on the free-response annotations could be helpful in boosting performance on the category prediction.
",7 Experimental Results,[0],[0]
"Explanation Generation Finally, we provide results for the task of generating explanations of motivations and emotions in Table 5.",7 Experimental Results,[0],[0]
"Because the explanations are closely tied to emotional and motivation states, the randomly selected explanation can often be close in embedding space to the reference explanations, making the random baseline fairly competitive.",7 Experimental Results,[0],[0]
"However, all models outperform the strong baseline on both metrics, indicating that the generated short explanations are closer semantically to the reference annotation.",7 Experimental Results,[0],[0]
Mental State Annotations Incorporating emotion theories into NLP tasks has been explored in previous projects.,8 Related work,[0],[0]
"Ghosh et al. (2017) modulate language model distributions by increasing the probability of words that express certain affective LIWC (Tausczik and Pennebaker, 2016) categories.",8 Related work,[0],[0]
"More generally, various projects tackle the problem of generating text from a set of attributes like sentiment or generic-ness (Ficler and Goldberg, 2017; Dong et al., 2017).",8 Related work,[0],[0]
"Similarly,
there is also a body of research in reasoning about commonsense stories and discourse (Li and Jurafsky, 2017; Mostafazadeh et al., 2016) or detecting emotional stimuli in stories (Gui et al., 2017).",8 Related work,[0],[0]
"Previous work in plot units (Lehnert, 1981) developed formalisms for affect and mental state in story narratives that included motivations and reactions.",8 Related work,[0],[0]
"In our work, we collect mental state annotations for stories to used as a new resource in this space.
",8 Related work,[0],[0]
"Modeling Entity State Recently, novel works in language modeling (Ji et al., 2017; Yang et al., 2016), question answering (Henaff et al., 2017), and text generation (Kiddon et al., 2016; Bosselut et al., 2018) have shown that modeling entity state explicitly can boost performance while providing a preliminary interface for interpreting a model’s prediction.",8 Related work,[0],[0]
"Entity modeling in these works, however, was limited to tracking entity reference (Kiddon et al., 2016; Yang et al., 2016; Ji et al., 2017), recognizing entity state similarity (Henaff et al., 2017) or predicting simple attributes from entity states (Bosselut et al., 2018).",8 Related work,[0],[0]
Our work provides a new dataset for tracking emotional reactions and motivations of characters in stories.,8 Related work,[0],[0]
We present a large scale dataset as a resource for training and evaluating mental state tracking of characters in short commonsense stories.,9 Conclusion,[0],[0]
This dataset contains over 300k low-level annotations for character motivations and emotional reactions.,9 Conclusion,[0],[0]
We provide benchmark results on this new resource.,9 Conclusion,[0],[0]
"Importantly, we show that modeling character-specific context and pretraining on freeresponse data can boost labeling performance.",9 Conclusion,[0],[0]
"While our work only use information present in our dataset, we view our dataset as a future testbed for evaluating models trained on any number of resources for learning common sense about emotional reactions and motivations.",9 Conclusion,[0],[0]
We thank the reviewers for their insightful comments.,Acknowledgments,[0],[0]
"We also thank Bowen Wang, xlab members, Martha Palmer, Tim O’Gorman, Susan W. Brown, and Ghazaleh Kazeminejad for helpful discussions on inter-annotator agreement and the annotation pipeline.",Acknowledgments,[0],[0]
"This work was supported in part by NSF GRFP DGE-1256082, NSF IIS1714566, IIS-1524371, Samsung AI, and DARPA CwC (W911NF-15-1-0543).",Acknowledgments,[0],[0]
Understanding a narrative requires reading between the lines and reasoning about the unspoken but obvious implications about events and people’s mental states — a capability that is trivial for humans but remarkably hard for machines.,abstractText,[0],[0]
"To facilitate research addressing this challenge, we introduce a new annotation framework to explain naive psychology of story characters as fully-specified chains of mental states with respect to motivations and emotional reactions.",abstractText,[0],[0]
"Our work presents a new largescale dataset with rich low-level annotations and establishes baseline performance on several new tasks, suggesting avenues for future research.",abstractText,[0],[0]
Modeling Naive Psychology of Characters in Simple Commonsense Stories,title,[0],[0]
"Reasoning about other agents’ intentions and being able to predict their behavior is important in multi-agent systems, in which the agents might have different, and sometimes competing, goals.",1. Introduction,[0],[0]
"In this paper, we introduce a new approach for estimating other agents’ unknown goals from their behavior and using those estimates to choose actions.",1. Introduction,[0],[0]
"We demonstrate that in the proposed tasks, using an explicit model of the other player leads to better performance than simply considering the other agent as part of the environment.
",1. Introduction,[0],[0]
"We frame the problem as a two-player stochastic game (Shapley, 1953), in which each agent is randomly assigned a different goal from a fixed set, which is shared between the agents.",1. Introduction,[0],[0]
"Players have full visibility of the environment, but no direct knowledge of the other’s goal and no communication channel.",1. Introduction,[0],[0]
"The reward obtained by each agent at the end of an episode depends on the goals of both agents, so an optimal policy must take into account both of their goals.
",1. Introduction,[0],[0]
"The key idea of this work is that as a first approximation
1New York University, New York City, USA 2Facebook AI Research, New York City, USA.",1. Introduction,[0],[0]
"Correspondence to: Roberta Raileanu <raileanu@cs.nyu.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
of understanding what the other player is trying to achieve, an agent should ask itself “what would be my goal if I had acted as the other player had?”.",1. Introduction,[0],[0]
We instantiate this idea by parametrizing the agent’s action and value functions with a neural network that takes as input the observation state and a goal.,1. Introduction,[0],[0]
"As the agent plays the game, it uses its own policy (with the input expressed in the other agent’s frame of reference) to maximize the likelihood of the other’s observed actions and optimize directly over the goal representation to infer the other agent’s unknown goal.",1. Introduction,[0],[0]
"In contrast with the current literature, our approach does not require building any model of the other agent in order to infer its intention and predict its behavior.",1. Introduction,[0],[0]
"Background: A two-player Markov game is defined by a set of states S describing the possible configurations of all agents, a set of actions A1,A2 and a set of observations S1,S2 for each agent, and a transition function T : S × A1 ×A2 → S which gives the probability distribution on the next state as a function of current state and actions.",2. Approach,[0],[0]
"Each agent i chooses actions by sampling from a stochastic policy πi : S × Ai → [0, 1].",2. Approach,[0],[0]
The reward function of each agent is: ri : S ×A1 ×A2 → R.,2. Approach,[0],[0]
Each agent i aims to maximize its discounted return from time t onward: Rit = ∑∞ t=0,2. Approach,[0],[0]
"γ
trit, where rit is the reward obtained by agent i at time t and γ ∈ (0, 1] is the discount factor.",2. Approach,[0],[0]
"In this work, we consider both cooperative and adversarial settings.",2. Approach,[0],[0]
"In cooperative games, the agents have the same reward function: r1 = r2.
",2. Approach,[0],[0]
"We now describe Self Other-Modeling (SOM), a new approach for inferring other agents’ goals in an online fashion and using these estimates to choose actions.",2. Approach,[0],[0]
"To decide an action and to estimate the value of a state, we use a neural network f that takes as input its own goal zself , an estimate of the other player’s goal z̃other, and the observation state sself , and outputs a probability distribution over actions π and a value estimate V , such that for each agent i playing the game we have:[
πi V i ] = f(siself , z i self , z̃ i other; θ i) .
",2. Approach,[0],[0]
"Here θi are agent i’s parameters for f , which has one softmax output for the policy, one linear output for the value function, and all the non-output layers shared.",2. Approach,[0],[0]
"The actions
are sampled from policy πi.",2. Approach,[0],[0]
"The state siself contains the observation features from agent i’s viewpoint.
",2. Approach,[0],[0]
We propose that each agent models the behavior of the other player using its own policy.,2. Approach,[0],[0]
"Thus, each agent uses its own network f in two ways: acting mode, in which the agent uses f to choose its actions and inference mode, in which the agent uses f to infer the other agent’s goal.",2. Approach,[0],[0]
"For notation purposes, whenever f is used in acting mode (inference mode) we will refer to it as fself (fother):
acting mode: fself (sself , zself , z̃other; θ) (1)
inference mode: fother(sother, z̃other, zself ; θ).",2. Approach,[0],[0]
"(2)
The two modes have different relative placements of the network’s inputs zself and z̃other.",2. Approach,[0],[0]
"Additionally, since the environment is fully observed, the observation state of the two agents differs only by the specification of the agent’s identity on the map (i.e. each agent will be able to distinguish between its own location and the other’s location).",2. Approach,[0],[0]
"Hence, in acting mode, the network fself will take as input sself (with the identity of the acting agent at the location of the self ) and in inference mode, the network fother will take as input sother (with the identity of the acting agent at the location of the other).
",2. Approach,[0],[0]
"At each step, the agent uses equation (2) to output an estimate of the probability distribution over the other agent’s actions.",2. Approach,[0],[0]
"Then, the agent uses supervision of the other’s true action to backpropagate through fother (without updating its paramters) and directly optimize over its input z̃other, the estimate of the other agent’s goal.",2. Approach,[0],[0]
The number of optimization steps used to update z̃other is a hyperparameter that can vary with the game.,2. Approach,[0],[0]
The new estimate z̃other is used as input to fself in (1) for choosing the self agent’s next action.,2. Approach,[0],[0]
"Figure 1 illustrates this technique.
",2. Approach,[0],[0]
"Note that the network f is never updated during inference mode (i.e. using supervision of the other agent’s actions), f ’s parameters θ are updated only at the end of each episode using Asynchronous Advantage Actor-Critic (A3C) (Mnih et al., 2016) with reward signal obtained by the self agent.",2. Approach,[0],[0]
"In contrast, z̃other is updated (multiple times) at each step in the game.
",2. Approach,[0],[0]
Algorithm 1 represents the pseudo-code for training a SOM agent for one episode.,2. Approach,[0],[0]
The procedure is formulated from the viewpoint of a single agent.,2. Approach,[0],[0]
"Since the goals are discrete in all the tasks considered here, the agent’s goal zself is encoded as a one-hot vector of dimension equal to the total number of possible goals in the game.",2. Approach,[0],[0]
"In line 6, siself is the self’s observation state from the perspective of agent i, which is the same as the other’s observation state from the perspective of agent j, sjother.
",2. Approach,[0],[0]
"We consider a continuous vector z̃other of the same dimension as zself , such that the estimate of the other agent’s
Algorithm 1 SOM training for one episode 1: procedure SELF OTHER-MODELING 2: for k := 1, num players do 3: z̃kother ← 1ngoals1ngoals 4: game.reset() 5: for step := 1, episode length do 6: siself = s j other ← game.get state()
7: z̃OH,iother = one hot(argmax(softmax(z̃",2. Approach,[0],[0]
"i other)) 8: πiself , V i self ← f iself (siself , ziself , z̃ OH,i other; θ i)
9: aiself ∼ πiself 10: game.action(aiself ) 11: for k : = 1, num inference steps do 12: z̃GS,jother = gumbel soft(softmax(z̃",2. Approach,[0],[0]
j other)),2. Approach,[0],[0]
13:,2. Approach,[0],[0]
"π̃jother← f j other(s j other, z̃ GS,j other, z j self ; θ j) 14: loss = cross entropy loss(π̃jother, a i self ) 15: loss.backward() 16: update(z̃jother) 17: for k := 1, num players do 18: policy.update(θk)
goal is a sample from the Categorical distribution with class probabilities softmax(z̃other).",2. Approach,[0],[0]
"Thus, the estimate of the other’s goal is given by the one-hot vector z̃OHother, as shown in line 7.",2. Approach,[0],[0]
"At the beginning of each game, the estimate of the other’s goal z̃OHother is randomly initialized, as illustrated in line 3, where 1ngoals represents a vector of all ones with the size equal to the number of possible goals.
",2. Approach,[0],[0]
"In inference mode, the estimate of the other agent’s goal is expressed as a sample from the Gumbel-Softmax distribution (Jang et al., 2016; Maddison et al., 2016), z̃GSother, as shown in line 12, where gumbel soft(p) = softmax[g + log(p)]), with g sampled from the Gumbel distribution and the softmax temperature τ = 1.",2. Approach,[0],[0]
"To update the estimate of the other’s goal, we directly optimize z̃other by using the cross-entropy loss to backpropagate through fother (lines 14, 15, 16).
",2. Approach,[0],[0]
"The agents’ policies are parametrized by long short-term memory (LSTM) cells (Hochreiter & Schmidhuber, 1997)
with two fully-connected linear layers, and exponential linear unit (ELU) (Clevert et al., 2015) activations.",2. Approach,[0],[0]
"The weights of the networks are initialized with semi-orthogonal matrices, as described in Saxe et al. (2013) and zero bias.",2. Approach,[0],[0]
Multi-Agent Learning.,3. Related Work,[0],[0]
"Recent work in deep multi-agent RL focuses on partially visible, fully cooperative settings (Foerster et al., 2016a;b; Omidshafiei et al., 2017) and emergent communication (Lazaridou et al., 2016; Foerster et al., 2016a; Sukhbaatar et al., 2016; Das et al., 2017; Mordatch & Abbeel, 2017).",3. Related Work,[0],[0]
"Lerer & Peysakhovich (2017) design RL agents that are able to maintain cooperation in complex social dilemmas by generalizing a well-known game theoretic strategy called tit-for-tat (Axelrod, 2006), to multiagent Markov games.",3. Related Work,[0],[0]
Leibo et al. (2017) considers semicooperative multi-agent environments in which the agents develop cooperative or competitive strategies depending on the task type and reward structure.,3. Related Work,[0],[0]
"Similarly, Lowe et al. (2017) proposes a centralized actor-critic architecture for efficient training in settings with such mixed strategies.",3. Related Work,[0],[0]
"Our setting is different since we do not allow communication between the agents, so the players have to indirectly reason about others’ intentions from their observed behavior.
",3. Related Work,[0],[0]
Intent Recognition.,3. Related Work,[0],[0]
"Research on plan, activity, and intent recognition has a long history, but it usually assumes domain knowledge or a form of rationality and uses techniques such as Bayesian inference or Hidden Markov Models (Sukthankar et al., 2014).",3. Related Work,[0],[0]
"The field of inverse reinforcement learning (IRL) (Russell, 1998; Ng et al., 2000; Abbeel & Ng, 2004) is also related to the problem considered here.",3. Related Work,[0],[0]
"IRL’s aim is to infer the reward function of an agent by observing its behavior, which is assumed to be nearly optimal.",3. Related Work,[0],[0]
"In contrast, our approach uses the observed actions of the other player to directly infer its goal in an online manner, which is then used by the agent when acting in the environment.",3. Related Work,[0],[0]
"This avoids the need for collecting offline samples of the other’s (state, action) pairs in order to estimate its reward function and use it to learn a policy.",3. Related Work,[0],[0]
"The more recent papers by Hadfield-Menell et al. (2016; 2017) are also concerned with the problem of inferring intentions, but their focus is on human-robot interaction and value alignment.",3. Related Work,[0],[0]
"Motivated by similar goals, Chandrasekaran et al. (2017) consider the problem of building a theory of AI’s mind, in order to improve human-AI interaction and the interpretability of AI systems.",3. Related Work,[0],[0]
"Recent work in cognitive science attempts to understand human decision-making by using a hierarchical model of social agency that infers human intentions for choosing a strategy (Kleiman-Weiner et al., 2016).",3. Related Work,[0],[0]
"However, none of these papers design algorithms that explicitly model other artificial agents in the environment or estimate their intentions, with the purpose of improving their decision
making.
",3. Related Work,[0],[0]
Modeling Other Agents.,3. Related Work,[0],[0]
Opponent modeling has been extensively studied in games of imperfect information.,3. Related Work,[0],[0]
Yet most previous approaches focuses on developing models with domain-specific probabilistic priors or strategy parametrizations.,3. Related Work,[0],[0]
"In contrast, our work proposes a more general framework for opponent modeling.",3. Related Work,[0],[0]
"Davidson (1999) uses an MLP to predict opponent actions given a game history, but the agents cannot adapt to their opponents’ behavior online.",3. Related Work,[0],[0]
"Lockett et al. (2007) designs a neural network architecture to identify the opponent type by learning a mixture of weights over a given set of cardinal opponents, but the game does not unfold within the RL framework.
",3. Related Work,[0],[0]
The closest work to ours is Foerster et al. (2017) and He et al. (2016).,3. Related Work,[0],[0]
Foerster et al. (2017) designs RL agents that take into account the learning of other agents in the environment when updating their own policies.,3. Related Work,[0],[0]
This enables the agents to discover self-interested yet collaborative strategies such as tit-for-tat in the iterated prisoner’s dilemma.,3. Related Work,[0],[0]
"While our work does not explicitly attempt to shape the learning of other agents, it has the advantage that agents can update their beliefs during an episode and change their strategies online to gain more reward.",3. Related Work,[0.9506783733408051],"['With these observations, we believe that DFG has successfully learned how to manage its internal structure to model human communication.']"
"Our setting is also different in that it considers that each agent has some hidden information needed by the other player to maximize its return.
",3. Related Work,[0],[0]
"Our work is very much in line with He et al. (2016), where the authors build a general framework for modeling other agents in the reinforcement learning setting.",3. Related Work,[0],[0]
He et al. (2016) proposes a model that jointly learns a policy and the behavior of opponents by encoding observations of the opponent into a DQN.,3. Related Work,[0],[0]
Their Mixture of Experts architecture is able to discover different opponent strategy patterns in two competitive tasks.,3. Related Work,[0],[0]
"In our approach, rather than using hand designed features of the other agent’s behavior, the agent models others using its own policy.",3. Related Work,[0],[0]
"Another difference is that in this work, the agent runs an optimization over the input vector to infer the other agent’s hidden goal, rather than using a feed-forward network.",3. Related Work,[0],[0]
"In the experiments below, we show that SOM outperforms an adaptation of the method of He et al. (2016) to our setting.",3. Related Work,[0],[0]
"In this section, we evaluate our model SOM on three tasks:
•",4. Experiments,[0],[0]
"The coin game, in Section 4.2, which is a fully cooperative task where the agents’ roles are symmetric.
",4. Experiments,[0],[0]
"• The recipe game, in Section 4.3, which is adversarial, but with symmetric roles.
",4. Experiments,[0],[0]
"• The door game, in Section 4.4, which is fully cooperative but has asymmetric roles for the two players.
",4. Experiments,[0],[0]
We compare SOM to three other baselines and to a model that has access to the ground truth of the other agent’s goal.,4. Experiments,[0],[0]
"All the tasks considered are created in the Mazebase gridworld environment (Sukhbaatar et al., 2015).",4. Experiments,[0],[0]
"TRUE-OTHER-GOAL (TOG): We provide an upper bound on the performance of our model given by a policy network which takes the other agent’s true goal as input zother, as well as the state features sself and its own goal zself .",4.1. Baselines,[0],[0]
"Since this model has direct access to the true goal of the other agent, it does not need a separate network to model the behavior of the other agent.",4.1. Baselines,[0],[0]
"The architecture of TOG is the same as the one of SOM’s policy network, f .
",4.1. Baselines,[0],[0]
NO-OTHER-MODEL (NOM): The first baseline we use only takes as inputs the observation states sself and its own goal zself .,4.1. Baselines,[0],[0]
"NOM has the same architecture as the one used for SOM’s policy network, fself .",4.1. Baselines,[0],[0]
"This baseline does not explicitly model the other agent’s policy, goal, or actions.
",4.1. Baselines,[0],[0]
"INTEGRATED-POLICY-PREDICTOR (IPP): Starting with the architecture and inputs of NOM, we construct a stronger baseline, IPP, which has an additional final linear layer that outputs a probability distribution over the next action of the other agent.",4.1. Baselines,[0],[0]
"Besides the A3C loss used to train the policy of this network, we also add a cross-entropy loss to train the prediction of the other agent’s action, using observations of its true actions.
",4.1. Baselines,[0],[0]
SEPARATE-POLICY-PREDICTOR (SPP): He et al. (2016) propose an opponent modeling framework based on DQN.,4.1. Baselines,[0],[0]
"In their approach, a neural network (separate from the learned Q-network) is trained to predict the opponents actions given hand crafted state information specific to the opponent.",4.1. Baselines,[0],[0]
"An intermediate hidden representation from this network is given as input to the Q-network.
",4.1. Baselines,[0],[0]
We adapt the model of He et al. (2016) to our setting.,4.1. Baselines,[0],[0]
"In particular, we use A3C instead of DQN",4.1. Baselines,[0],[0]
"and we do not use the task-specific features used to represent the hidden goal of the opponent.
",4.1. Baselines,[0],[0]
"The resulting model, SPP, consists of two separate networks, a policy network for deciding the agent’s actions, and an opponent network for predicting the other agent’s actions.",4.1. Baselines,[0],[0]
"The opponent network takes as input its own state observation sself and goal zself , and outputs a probability distribution for the action taken by the other agent at the next step, as well as its hidden (recurrent) state.",4.1. Baselines,[0],[0]
"As in IPP, we train the opponent policy predictor with a cross-entropy loss using the true actions of the other agent.",4.1. Baselines,[0],[0]
"At each step, the hidden (recurrent) state outputted by this network is taken as input by the agent’s policy network, along with the observation state and its own goal.",4.1. Baselines,[0],[0]
"Both the policy network and the opponent policy predictor are LSTMs with the same
architecture as SOM.
",4.1. Baselines,[0],[0]
"In contrast to SOM, SPP does not explicitly infer the other agent’s goal.",4.1. Baselines,[0],[0]
"Rather, it builds an implicit model of the opponent by predicting the agent’s actions at each time step.",4.1. Baselines,[0],[0]
"In SOM, an inferred goal is given as additional input to the policy network.",4.1. Baselines,[0],[0]
"The analog of the inferred goal in SPP is the hidden (recurrent) state obtained from the opponent policy predictor which is given as an additional input to the policy network.
",4.1. Baselines,[0],[0]
Training Details.,4.1. Baselines,[0],[0]
"In all our experiments, we train the agents’ policies using A3C (Mnih et al., 2016) with an entropy coefficient of 0.01, a value loss coefficient of 0.5, and a discount factor of 0.99.",4.1. Baselines,[0],[0]
"The parameters of the agents’ policies are optimized using Adam (Kingma & Ba, 2014) with β1 = 0.9, β2 = 0.999, = 1×10−8, and weight decay 0.",4.1. Baselines,[0],[0]
"SGD with a learning rate of 0.1 was used for inferring the other agent’s goal, z̃other.
",4.1. Baselines,[0],[0]
The hidden layer dimension of the policy network was 64 for the Coin and Recipe Games and 128 for the Door Game.,4.1. Baselines,[0],[0]
"We use a learning rate of 1×10−4 for all games and models.
",4.1. Baselines,[0],[0]
The observation state s is represented by few-hot vectors indicating the locations of all the objects in the environment (including the other player).,4.1. Baselines,[0],[0]
"The dimension of this input state is 1 × nfeatures, where the number of features is 384, 192, and 900 for the Coin, Recipe, and Door games, respectively.
",4.1. Baselines,[0],[0]
"For each experiment, we trained the models using 5 different random seeds.",4.1. Baselines,[0],[0]
"All the results shown are for 10 optimization updates of z̃other at each step in the game, unless mentioned otherwise.",4.1. Baselines,[0],[0]
"First, we evaluate the model on a fully cooperative task, in which the agents can gain more reward when using both of their goals rather than only their own goal.",4.2. Coin Game.,[0],[0]
So it is in the best interest of each agent to estimate the other player’s goal and use that information when taking actions.,4.2. Coin Game.,[0],[0]
"The game, shown in the left diagram of Figure 4, takes place on a 8× 8 grid containing 12 coins of 3 different colors (4 coins of each color).",4.2. Coin Game.,[0],[0]
"At the beginning of each episode, the agents are randomly assigned one of the three colors.",4.2. Coin Game.,[0],[0]
"The action space consists of: go up, down, left, right, or pass.",4.2. Coin Game.,[0],[0]
"Once an agent steps on a coin, that coin disappears from the grid.",4.2. Coin Game.,[0],[0]
The game ends after 20 steps.,4.2. Coin Game.,[0],[0]
"The reward received by both agents at the end of the game is given by the formula below:
R(cself , cother) =",4.2. Coin Game.,[0],[0]
(n self Cself + notherCself ),4.2. Coin Game.,[0],[0]
"2 + (nselfCother + n other Cother )2
− (nselfCneither + n other Cneither )2,
where notherCself is the number of coins of the self’s goal-color, which were collected by the other agents, and nselfCneither is
the number of coins corresponding to neither of the agents’ goals, collected by the self.",4.2. Coin Game.,[0],[0]
"For the example in Figure 4, agent 1 has Cself = orange and Cother = cyan, while agent 2’s Cself is cyan and Cother is orange.",4.2. Coin Game.,[0],[0]
"Cneither is red for both agents.
",4.2. Coin Game.,[0],[0]
"The role of the penalty for collecting coins that do not correspond to any of the agents’ goals is to avoid convergence to a greedy policy in which the agents can gain a non-negligible amount of reward by collecting all the coins in their proximity, without any regard to their color.
",4.2. Coin Game.,[0],[0]
"To maximize its return, each agent needs maximize the number of collected coins of its own or its collaborator’s color, and minimize the number of coins of the remaining color.",4.2. Coin Game.,[0],[0]
"Hence, when both agents are able to infer their collaborators’ goals with high accuracy and as early as possible in the game, they can use that information to maximize their
shared utility.
",4.2. Coin Game.,[0],[0]
Figure 3 shows the mean and standard deviation of the reward across 5 runs with different random seeds obtained by SOM.,4.2. Coin Game.,[0],[0]
Our model clearly outperforms all other baselines on this task.,4.2. Coin Game.,[0],[0]
"We also show the empirical upper bound on the reward using the model which takes as input the true color assigned to the other agent.
",4.2. Coin Game.,[0],[0]
Figure 2 analyzes the strategies of the different models by looking at the proportion of coins of each type collected by the agents.,4.2. Coin Game.,[0],[0]
"The optimal strategy is for each agent to maximize nselfCself + n self Cother
and minimize nselfCneither .",4.2. Coin Game.,[0],[0]
"Due to the randomness in the initial conditions (in particular, the locations of coins in the environment), this amounts to each agent collecting an equal number of coins of its own and of the other’s color on average, across a large number of episodes (i.e. n̄selfCself = n̄ self Cother ).
",4.2. Coin Game.,[0],[0]
"Indeed, this is the strategy learned by the model with perfect information of the other agent’s goal (TOG).",4.2. Coin Game.,[0],[0]
"SOM also learns to collect significantly more Other than Neither coins (although not as many as Self coins), indicating its ability to distinguish between the two types, at least during some of the episodes.",4.2. Coin Game.,[0],[0]
"This means that SOM can accurately infer the other agent’s goal early enough during the episode and use that information to collect more Other Coins, thus gaining more reward than if it were only using its own goal to direct its actions.
",4.2. Coin Game.,[0],[0]
"In contrast, the agents trained with the three baseline models collect significantly more Self coins, and as many Other as Neither coins on average.",4.2. Coin Game.,[0],[0]
"This shows that they learn to use their own goal for gaining reward, but they are unable to use the hidden goal of the other agent for further increasing their returns.",4.2. Coin Game.,[0],[0]
"Even if IPP and SPP are able to predict the actions of the other player with an accuracy of about 50%, they do not learn to distinguish between the coins that would increase (Other) and those that would decrease (Neither)
their reward.",4.2. Coin Game.,[0],[0]
This shows the weaknesses of using an implicit model of the other agent to maximize reward on certain tasks.,4.2. Coin Game.,[0],[0]
"Agents in adversarial scenarios have competing goals, so the ability of inferring the opponent’s goal could better inform the agent’s actions.",4.3. Recipe Game.,[0],[0]
"With this motivation in mind, we evaluate our model on a game in which the agents have to craft certain compositional recipes, each containing multiple items found in the environment.",4.3. Recipe Game.,[0],[0]
"The agents are given as input the names of their goal-recipes, without the corresponding components needed to make it.",4.3. Recipe Game.,[0],[0]
"The resources in the environment are scarce, so only one of the agents can craft its recipe within one episode.
",4.3. Recipe Game.,[0],[0]
"As illustrated in Figure 4 (center), there are 4 types of items: {sun, star, moon, lightning} and 4 recipes: {sun, sun, star}; {star, star, moon}; {moon, moon, lightning}; {lightning, lightning, sun}.",4.3. Recipe Game.,[0],[0]
"The game is played in a 4× 6 grid, which contains 8 items in total, 2 of each type.
",4.3. Recipe Game.,[0],[0]
"At the beginning of each episode, we randomly assign a recipe to one of the agents, and then we randomly pick a recipe for the other agent so that it has overlapping items with the recipe of the first agent.",4.3. Recipe Game.,[0],[0]
This ensures that the agents are competing for resources within each episode.,4.3. Recipe Game.,[0],[0]
"At the end of the episode, each agent receives a reward of +1 for crafting its own recipe and a penalty of -0.1 for each item it picked up not needed for making its recipe.
",4.3. Recipe Game.,[0],[0]
We designed the layout of the grid so that neither agent has an initial advantage by being closer to the scarce resource.,4.3. Recipe Game.,[0],[0]
"At the beginning of each episode, one of the agents starts on the left-most column of the grid, while the other one starts on the right-most column, at the same y-coordinate.",4.3. Recipe Game.,[0],[0]
Their initial y-coordinate as well as which agent starts on the left/right is randomized.,4.3. Recipe Game.,[0],[0]
"Similarly, one item of each of the 4 different types is placed at random in the grid formed
by the second and third columns of the maze, from left to right.",4.3. Recipe Game.,[0],[0]
"The rest of the items are placed in the forth and fifth columns, so that the symmetry with respect to the vertical axis is preserved (i.e. items of the same type are placed at the same y-coordinate, and symmetric x-coordinates).
",4.3. Recipe Game.,[0],[0]
"Agents have six actions to choose from: pass, go up, down, left, right, or pick up (for picking up an item, which then disappears from the grid).",4.3. Recipe Game.,[0],[0]
The first agent to take an action is randomized.,4.3. Recipe Game.,[0],[0]
"The game ends after 50 steps.
",4.3. Recipe Game.,[0],[0]
"We pretrain all baselines on a version of the game which does not have overlapping recipes, in order to ensure that all the models learn to pick up the corresponding items, given a recipe as goal.",4.3. Recipe Game.,[0],[0]
All of the models learn to craft their assigned recipes ∼ 90% of the time on this simpler task.,4.3. Recipe Game.,[0],[0]
"Then, we continue training the models on the adversarial task in which their recipes overlap in each episode.",4.3. Recipe Game.,[0],[0]
"SOM is initialized with a pretrained NOM network.
",4.3. Recipe Game.,[0],[0]
Figure 5 shows the winning fraction for different pairs played against each other in the Recipe game.,4.3. Recipe Game.,[0],[0]
"For the first 100k episodes, the models are not being trained.",4.3. Recipe Game.,[0],[0]
"We can see that SOM significantly outperfroms NOM, IPP, and SPP, winning ∼ 75 − 80% of the time, while the baselines can only win ∼ 15− 20% of the games.",4.3. Recipe Game.,[0],[0]
"SPP ties against NOM, and TOG outperforms SOM by a large margin.",4.3. Recipe Game.,[0],[0]
We also played the same types of agents against each other and they all win ∼ 40− 50% of the games.,4.3. Recipe Game.,[0],[0]
"In this section, we show that on a collaborative task with asymmetric roles and multiple possible partners, the agents can learn to figure out what role they should be playing in each game based on their partners’ actions.
",4.4. Door Game.,[0],[0]
"In the Door game, two agents are located in a 5 × 9 grid, with 5 goals behind 5 doors on the left wall, and 5 switches on the right wall of the grid.",4.4. Door Game.,[0],[0]
"The game starts with the two players in random squares on the grid, except for the ones occupied by the goals, doors, or switches, as illustrated in Figure 4.",4.4. Door Game.,[0],[0]
"Agents can take any of the five actions: go up, down, left, right or pass.",4.4. Door Game.,[0],[0]
An action is invalid if it moves the player outside of the border or to a square occupied by a block or closed door.,4.4. Door Game.,[0],[0]
Both agents receive +3 reward when either one of them steps on its goal and they are penalized -0.1 for each step they take.,4.4. Door Game.,[0],[0]
The game ends when one of them gets to its goal or after 22 steps.,4.4. Door Game.,[0],[0]
"All the goals are behind doors which are open only as long as one of the agents sits on the corresponding switch for that door.
",4.4. Door Game.,[0],[0]
"At the beginning of an episode, each of the two players is randomly selected from a pool of 5 agents and receives as input a random number from 1 to 5 corresponding to its goal.",4.4. Door Game.,[0],[0]
Each of the 5 agents has its own policy which gets updated at the end of each episode they play.,4.4. Door Game.,[0],[0]
"Note that the agents’
identities are not visible (i.e. there is no indication in the state features that specifies the id’s of the agents playing during a given episode).",4.4. Door Game.,[0],[0]
"This restriction is important in order to ensure that the agents cannot gain advantage by specializing into the two roles needed to win (i.e. goal-goer and switch-puller) and identifying the specialization of the other player by simply observing its unique id.
The agents need to cooperate in order to receive reward.",4.4. Door Game.,[0],[0]
"In contrast to our previous tasks, the two players must take different roles.",4.4. Door Game.,[0],[0]
"In fact, the player who sits on the switch should ignore its own goal and instead infer the other’s goal, while the player who goes to its goal does not need to infer the other’s goal, but only use its own.",4.4. Door Game.,[0],[0]
"In order to sit on the correct switch, an agent has to infer the other player’s goal from their observed actions.",4.4. Door Game.,[0],[0]
"The only way in which an agent can use its own policy to model the other player is if each agent learns to play both roles of the game, i.e. go to its own goal and also open its collaborator’s door by sitting on the corresponding switch.",4.4. Door Game.,[0],[0]
"Indeed, we see that the agents learn to play both roles and they are able to use their own policies to infer the other player’s goals when needed.
",4.4. Door Game.,[0],[0]
Fig 6 shows the mean and standard deviation of the winning fraction obtained by one of the agents on the Door game.,4.4. Door Game.,[0],[0]
"While our model is still able to outperform the three baselines, the gap between the performance of our model and that of IPP or SPP (an approximate version of (He et al., 2016)) is smaller than in the previous tasks.",4.4. Door Game.,[0],[0]
"However, this is a more difficult task for our model since it needs the agent to learn both roles before effectively using its own policy to infer the other agent’s goal.",4.4. Door Game.,[0],[0]
"The plot shows that SOM actually performs worse than IPP and SPP during the initial part of training, before outperforming them.",4.4. Door Game.,[0],[0]
"Nevertheless, we see that SOM training allows the agents to play both roles in an asymmetric cooperative game, and to infer the goal and role of the other player.",4.4. Door Game.,[0],[0]
"In this section we further analyze the ability of the SOM models to infer other’s intended goals.
",4.5. Analyzing the goal inference,[0],[0]
Figure 7 shows the fraction of episodes in which the goal of the other agent is correctly inferred.,4.5. Analyzing the goal inference,[0],[0]
"We consider that the goal is correctly inferred only when the estimate of the other’s goal remains accurate until the end of the game, so that we avoid counting the episodes in which the agent might infer the correct goal by chance at some intermediate step in the game.",4.5. Analyzing the goal inference,[0],[0]
"In all the games, the SOM agent learns to infer the other player’s goal with a mean accuracy ranging
from ∼",4.5. Analyzing the goal inference,[0],[0]
60− 80%.,4.5. Analyzing the goal inference,[0],[0]
"Comparing the second plot in Figure 2 with the left plot in Figure 7, one can observe that the SOM agent starts distinguishing Other from Neither coins after approximately 2M training episodes, which coincides with the time when the mean accuracy of the inferred goal converges to ∼ 75%.",4.5. Analyzing the goal inference,[0],[0]
"The Door Game (right) presents higher variance since the agents learn to use and infer the other’s goal at different stages during training.
",4.5. Analyzing the goal inference,[0],[0]
Figure 8 shows the cumulative distribution of the step at which the goal of the other player is correctly inferred (and remains the same until the end of the game).,4.5. Analyzing the goal inference,[0],[0]
The cumulative distribution is computed over the episodes in which the goal is correctly inferred before the end of the game.,4.5. Analyzing the goal inference,[0],[0]
"In the Coin (blue) and Recipe (red) games, 80% of the times the agent correctly infers the goal of the other, it does so in the first five steps.",4.5. Analyzing the goal inference,[0],[0]
The distribution for the Door (green) game indicates that the agent needs more steps on average to correctly infer the goal.,4.5. Analyzing the goal inference,[0],[0]
This explains in part why the SOM agent only slightly outperforms the SPP baseline.,4.5. Analyzing the goal inference,[0],[0]
"If the agent does not infer the other’s goal early enough in the episode, it cannot efficiently use it to maximize its return.
",4.5. Analyzing the goal inference,[0],[0]
"Figure 9 shows how the performance of the agent varies with
the number of optimization updates performed on z̃other at each step in the game.",4.5. Analyzing the goal inference,[0],[0]
"As expected, the agent’s reward (blue) generally increases with the number of inference steps, as does the fraction of episodes in which the goal is correctly inferred.",4.5. Analyzing the goal inference,[0],[0]
"One should note that increasing the number of inference steps from 10 to 20 only translates into less than 0.45% performance gain, while increasing it from 1 to 5 translates into a performance gain of 6.9% on the Coin game, suggesting that there is a certain threshold above which increasing the number of inference steps will not significantly improve performance.",4.5. Analyzing the goal inference,[0],[0]
Summary.,5. Discussion,[0],[0]
"In this paper, we introduced a new approach for inferring other agents’ hidden goals from their behavior and using those estimates to choose actions.",5. Discussion,[0],[0]
"We demonstrated that the agents are able to estimate others’ hidden goals in both cooperative and competitive settings, which enables them to converge to better policies.",5. Discussion,[0],[0]
"In the proposed tasks, using an explicit model of the other player led to better performance than simply considering the other agent as part of the environment.
Strengths.",5. Discussion,[0],[0]
Some of the main advantages of our method are its simplicity and flexibility.,5. Discussion,[0],[0]
"This method does not require any extra parameters to model other agents in the environment, can be trained with any reinforcement learning algorithm, and can be easily integrated with any network architecture.",5. Discussion,[0],[0]
"SOM can also be adapted to settings with more than two players, since the agent can use its own policy to model the behavior of any number of agents and infer their goals.",5. Discussion,[0],[0]
"Moreover, it can be easily generalized to numerous other environments and tasks.
Limitations.",5. Discussion,[0],[0]
Our approach is based on the assumption that the agents are identical or that their transition functions are independent and identically distributed.,5. Discussion,[0],[0]
"Hence, the framework is expected to be more suitable for symmetric games, in which the agents share a fixed set of goals and have similar abilities, and we expect a degradation of performance for asymmetric games.",5. Discussion,[0],[0]
Our experiments confirm this observation.,5. Discussion,[0],[0]
"Another limitation of SOM is that it requires a longer training time than other baselines, since we backpropagate through the network at each step.",5. Discussion,[0],[0]
"However, their online nature is essential in adapting to the behavior of other agents in the environment.
",5. Discussion,[0],[0]
Future Work.,5. Discussion,[0],[0]
"We plan to extend this work by evaluating the models on more complex environments and model deviations from the assumption that the players have identical policies, given a certain goal and state of the world.",5. Discussion,[0],[0]
"Another important avenue for future research is to design models that can adapt to non-stationary strategies of others in the environment, as well as to tasks with hierarchical goals.",5. Discussion,[0],[0]
This work was partially supported by ONR grant N0001413-1-0646.,Acknowledgements,[0],[0]
The authors wish to thank Alex Peysakhovich and Adam Lerer for helpful discussions.,Acknowledgements,[0],[0]
We consider the multi-agent reinforcement learning setting with imperfect information.,abstractText,[0],[0]
"The reward function depends on the hidden goals of both agents, so the agents must infer the other players’ goals from their observed behavior in order to maximize their returns.",abstractText,[0],[0]
"We propose a new approach for learning in these domains: Self Other-Modeling (SOM), in which an agent uses its own policy to predict the other agent’s actions and update its belief of their hidden goal in an online manner.",abstractText,[0],[0]
"We evaluate this approach on three different tasks and show that the agents are able to learn better policies using their estimate of the other players’ goals, in both cooperative and competitive settings.",abstractText,[0],[0]
Modeling Others using Oneself in Multi-Agent Reinforcement Learning,title,[0],[0]
"Being able to anticipate upcoming content is a core property of human language processing (Kutas et al., 2011; Kuperberg and Jaeger, 2016) that has received a lot of attention in the psycholinguistic literature in recent years.",1 Introduction,[0],[0]
Expectations about upcoming words help humans comprehend language in noisy settings and deal with ungrammatical input.,1 Introduction,[0],[0]
"In this paper, we use a computational model to address the question of how different layers of knowledge (linguistic knowledge as well as common-sense knowledge) influence human anticipation.
",1 Introduction,[0],[0]
Here we focus our attention on semantic predictions of discourse referents for upcoming noun phrases.,1 Introduction,[0],[0]
"This task is particularly interesting because it allows us to separate the semantic task of antic-
ipating an intended referent and the processing of the actual surface form.",1 Introduction,[0],[0]
"For example, in the context of I ordered a medium sirloin steak with fries.",1 Introduction,[0],[0]
"Later, the waiter brought . . .",1 Introduction,[0],[0]
", there is a strong expectation of a specific discourse referent, i.e., the referent introduced by the object NP of the preceding sentence, while the possible referring expression could be either the steak I had ordered, the steak, our food, or it.",1 Introduction,[0],[0]
Existing models of human prediction are usually formulated using the informationtheoretic concept of surprisal.,1 Introduction,[0],[0]
"In recent work, however, surprisal is usually not computed for DRs, which represent the relevant semantic unit, but for the surface form of the referring expressions, even though there is an increasing amount of literature suggesting that human expectations at different levels of representation have separable effects on prediction and, as a consequence, that the modelling of only one level (the linguistic surface form) is insufficient (Kuperberg and Jaeger, 2016; Kuperberg, 2016; Zarcone et al., 2016).",1 Introduction,[0],[0]
"The present model addresses this shortcoming by explicitly modelling and representing common-sense knowledge and conceptually separating the semantic (discourse referent) and the surface level (referring expression) expectations.
",1 Introduction,[0],[0]
"Our discourse referent prediction task is related to the NLP task of coreference resolution, but it substantially differs from that task in the following ways: 1) we use only the incrementally available left context, while coreference resolution uses the full text; 2) coreference resolution tries to identify the DR for a given target NP in context, while we look at the expectations of DRs based only on the context
ar X
iv :1
70 2.
",1 Introduction,[0],[0]
"03 12
1v 1
[ cs
.C",1 Introduction,[0],[0]
"L
] 1
0 Fe
b 20
before the target NP is seen.",1 Introduction,[0],[0]
The distinction between referent prediction and prediction of referring expressions also allows us to study a closely related question in natural language generation: the choice of a type of referring expression based on the predictability of the DR that is intended by the speaker.,1 Introduction,[0],[0]
"This part of our work is inspired by a referent guessing experiment by Tily and Piantadosi (2009), who showed that highly predictable referents were more likely to be realized with a pronoun than unpredictable referents, which were more likely to be realized using a full NP.",1 Introduction,[0],[0]
"The effect they observe is consistent with a Gricean point of view, or the principle of uniform information density (see Section 5.1).",1 Introduction,[0],[0]
"However, Tily and Piantadosi do not provide a computational model for estimating referent predictability.",1 Introduction,[0],[0]
"Also, they do not include selectional preference or common-sense knowledge effects in their analysis.
",1 Introduction,[0],[0]
"We believe that script knowledge, i.e., commonsense knowledge about everyday event sequences, represents a good starting point for modelling conversational anticipation.",1 Introduction,[0],[0]
This type of common-sense knowledge includes temporal structure which is particularly relevant for anticipation in continuous language processing.,1 Introduction,[0],[0]
"Furthermore, our approach can build on progress that has been made in recent years in methods for acquiring large-scale script knowledge; see Section 1.1.",1 Introduction,[0],[0]
Our hypothesis is that script knowledge may be a significant factor in human anticipation of discourse referents.,1 Introduction,[0],[0]
"Explicitly modelling this knowledge will thus allow us to produce more human-like predictions.
",1 Introduction,[0],[0]
"Script knowledge enables our model to generate anticipations about discourse referents that have already been mentioned in the text, as well as anticipations about textually new discourse referents which have been activated due to script knowledge.",1 Introduction,[0],[0]
"By modelling event sequences and event participants, our model captures many more long-range dependencies than normal language models are able to.",1 Introduction,[0],[0]
"As an example, consider the following two alternative text passages:
We got seated, and had to wait for 20 minutes.",1 Introduction,[0],[0]
"Then, the waiter brought the ...
We ordered, and had to wait for 20 minutes.",1 Introduction,[0],[0]
"Then, the waiter brought the ...
Preferred candidate referents for the object posi-
tion of the waiter brought the ... are instances of the food, menu, or bill participant types.",1 Introduction,[0],[0]
"In the context of the alternative preceding sentences, there is a strong expectation of instances of a menu and a food participant, respectively.
",1 Introduction,[0],[0]
This paper represents foundational research investigating human language processing.,1 Introduction,[0],[0]
"However, it also has the potential for application in assistant technology and embodied agents.",1 Introduction,[0],[0]
"The goal is to achieve human-level language comprehension in realistic settings, and in particular to achieve robustness in the face of errors or noise.",1 Introduction,[0],[0]
"Explicitly modelling expectations that are driven by common-sense knowledge is an important step in this direction.
",1 Introduction,[0],[0]
"In order to be able to investigate the influence of script knowledge on discourse referent expectations, we use a corpus that contains frequent reference to script knowledge, and provides annotations for coreference information, script events and participants (Section 2).",1 Introduction,[0],[0]
"In Section 3, we present a large-scale experiment for empirically assessing human expectations on upcoming referents, which allows us to quantify at what points in a text humans have very clear anticipations vs. when they do not.",1 Introduction,[0],[0]
"Our goal is to model human expectations, even if they turn out to be incorrect in a specific instance.",1 Introduction,[0],[0]
The experiment was conducted via Mechanical Turk and follows the methodology of Tily and Piantadosi (2009).,1 Introduction,[0],[0]
"In section 4, we describe our computational model that represents script knowledge.",1 Introduction,[0],[0]
"The model is trained on the gold standard annotations of the corpus, because we assume that human comprehenders usually will have an analysis of the preceding discourse which closely corresponds to the gold standard.",1 Introduction,[0],[0]
"We compare the prediction accuracy of this model to human predictions, as well as to two baseline models in Section 4.3.",1 Introduction,[0],[0]
One of them uses only structural linguistic features for predicting referents; the other uses general script-independent selectional preference features.,1 Introduction,[0],[0]
"In Section 5, we test whether surprisal (as estimated from human guesses vs. computational models) can predict the type of referring expression used in the original texts in the corpus (pronoun vs. full referring expression).",1 Introduction,[0],[0]
"This experiment also has wider implications with respect to the on-going discussion of whether the referring expression choice is dependent on predictability, as predicted by the uniform information density hy-
pothesis.",1 Introduction,[0],[0]
"The contributions of this paper consist of:
• a large dataset of human expectations, in a variety of texts related to every-day activities.",1 Introduction,[0],[0]
"• an implementation of the conceptual distinction
between the semantic level of referent prediction and the type of a referring expression.",1 Introduction,[0],[0]
"• a computational model which significantly im-
proves modelling of human anticipations.",1 Introduction,[0],[0]
"• showing that script knowledge is a significant
factor in human expectations.",1 Introduction,[0],[0]
"• testing the hypothesis of Tily and Piantadosi
that the choice of the type of referring expression (pronoun or full NP) depends on the predictability of the referent.",1 Introduction,[0],[0]
"Scripts represent knowledge about typical event sequences (Schank and Abelson, 1977), for example the sequence of events happening when eating at a restaurant.",1.1 Scripts,[0],[0]
"Script knowledge thereby includes events like order, bring and eat as well as participants of those events, e.g., menu, waiter, food, guest.",1.1 Scripts,[0],[0]
"Existing methods for acquiring script knowledge are based on extracting narrative chains from text (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009; Jans et al., 2012; Pichotta and Mooney, 2014; Rudinger et al., 2015; Modi, 2016; Ahrendt and Demberg, 2016) or by eliciting script knowledge via Crowdsourcing on Mechanical Turk (Regneri et al., 2010; Frermann et al., 2014; Modi and Titov, 2014).
",1.1 Scripts,[0],[0]
"Modelling anticipated events and participants is motivated by evidence showing that event representations in humans contain information not only about the current event, but also about previous and future states, that is, humans generate anticipations about event sequences during normal language
comprehension (Schütz-Bosbach and Prinz, 2007).",1.1 Scripts,[0],[0]
"Script knowledge representations have been shown to be useful in NLP applications for ambiguity resolution during reference resolution (Rahman and Ng, 2012).",1.1 Scripts,[0],[0]
"Ordinary texts, including narratives, encode script structure in a way that is too complex and too implicit at the same time to enable a systematic study of script-based expectation.",2 Data: The InScript Corpus,[0],[0]
"They contain interleaved references to many different scripts, and they usually refer to single scripts in a point-wise fashion only, relying on the ability of the reader to infer the full event chain using their background knowledge.
",2 Data: The InScript Corpus,[0],[0]
"We use the InScript corpus (Modi et al., 2016) to study the predictive effect of script knowledge.",2 Data: The InScript Corpus,[0],[0]
InScript is a crowdsourced corpus of simple narrative texts.,2 Data: The InScript Corpus,[0],[0]
"Participants were asked to write about a specific activity (e.g., a restaurant visit, a bus ride, or a grocery shopping event) which they personally experienced, and they were instructed to tell the story as if explaining the activity to a child.",2 Data: The InScript Corpus,[0],[0]
This resulted in stories that are centered around a specific scenario and that explicitly mention mundane details.,2 Data: The InScript Corpus,[0],[0]
"Thus, they generally realize longer event chains associated with a single script, which makes them particularly appropriate to our purpose.
",2 Data: The InScript Corpus,[0],[0]
"The InScript corpus is labelled with event-type, participant-type, and coreference information.",2 Data: The InScript Corpus,[0],[0]
"Full verbs are labeled with event type information, heads of all noun phrases with participant types, using scenario-specific lists of event types (such as enter bathroom, close drain and fill water for the “taking a bath” scenario) and participant types (such as bather, water and bathtub).",2 Data: The InScript Corpus,[0],[0]
"On average, each template offers a choice of 20 event types and 18 participant
to guess the upcoming referent (indicated by XXXXXX above).",2 Data: The InScript Corpus,[0],[0]
"They can either choose from the previously activated referents, or they can write something new.
types.",2 Data: The InScript Corpus,[0],[0]
The InScript corpus consists of 910 stories addressing 10 scenarios (about 90 stories per scenario).,2 Data: The InScript Corpus,[0],[0]
"The corpus has 200,000 words, 12,000 verb instances with event labels, and 44,000 head nouns with participant instances.",2 Data: The InScript Corpus,[0],[0]
"Modi et al. (2016) report an inter-annotator agreement of 0.64 for event types and 0.77 for participant types (Fleiss’ kappa).
",2 Data: The InScript Corpus,[0],[0]
We use gold-standard event- and participant-type annotation to study the influence of script knowledge on the expectation of discourse referents.,2 Data: The InScript Corpus,[0],[0]
"In addition, InScript provides coreference annotation, which makes it possible to keep track of the mentioned discourse referents at each point in the story.",2 Data: The InScript Corpus,[0],[0]
We use this information in the computational model of DR prediction and in the DR guessing experiment described in the next section.,2 Data: The InScript Corpus,[0.951120458784224],['One such study was presented in this paper where we analyzed the structure of multimodal fusion in sentiment analysis and emotion recognition.']
An example of an annotated InScript story is shown in Figure 1.,2 Data: The InScript Corpus,[0],[0]
"We use the InScript corpus to develop computational models for the prediction of discourse refer-
ents (DRs) and to evaluate their prediction accuracy.",3 Referent Cloze Task,[0],[0]
"This can be done by testing how often our models manage to reproduce the original discourse referent (cf. also the “narrative cloze” task by (Chambers and Jurafsky, 2008) which tests whether a verb together with a role can be correctly guessed by a model).",3 Referent Cloze Task,[0],[0]
"However, we do not only want to predict the “correct” DRs in a text but also to model human expectation of DRs in context.",3 Referent Cloze Task,[0],[0]
"To empirically assess human expectation, we created an additional database of crowdsourced human predictions of discourse referents in context using Amazon Mechanical Turk.",3 Referent Cloze Task,[0],[0]
"The design of our experiment closely resembles the guessing game of (Tily and Piantadosi, 2009) but extends it in a substantial way.
",3 Referent Cloze Task,[0],[0]
"Workers had to read stories of the InScript corpus 1 and guess upcoming participants: for each target NP, workers were shown the story up to this NP excluding the NP itself, and they were asked to guess the next person or object most likely to be referred to.",3 Referent Cloze Task,[0],[0]
"In case they decided in favour of a discourse referent already mentioned, they had to choose among the available discourse referents by clicking an NP in the preceding text, i.e., some noun with a specific, coreference-indicating color; see Figure 2.",3 Referent Cloze Task,[0],[0]
"Otherwise, they would click the “New” button, and would in turn be asked to give a short description of the new person or object they expected to be mentioned.",3 Referent Cloze Task,[0],[0]
"The percentage of guesses that agree with the actually referred entity was taken as a basis for estimating the surprisal.
",3 Referent Cloze Task,[0],[0]
"The experiment was done for all stories of the test set: 182 stories (20%) of the InScript corpus, evenly taken from all scenarios.",3 Referent Cloze Task,[0],[0]
"Since our focus is on the effect of script knowledge, we only considered those NPs as targets that are direct dependents of script-related events.",3 Referent Cloze Task,[0],[0]
Guessing started from the third sentence only in order to ensure that a minimum of context information was available.,3 Referent Cloze Task,[0],[0]
"To keep the complexity of the context manageable, we restricted guessing to a maximum of 30 targets and skipped the rest of the story (this applied to 12% of the stories).",3 Referent Cloze Task,[0],[0]
"We collected 20 guesses per NP for 3346 noun phrase instances, which amounts to a total of around 67K guesses.",3 Referent Cloze Task,[0],[0]
"Workers selected a con-
1The corpus is available at : http://www.sfb1102.",3 Referent Cloze Task,[0],[0]
"uni-saarland.de/?page_id=2582
text NP in 68% of cases and “New” in 32% of cases.",3 Referent Cloze Task,[0],[0]
Our leading hypothesis is that script knowledge substantially influences human expectation of discourse referents.,3 Referent Cloze Task,[0],[0]
The guessing experiment provides a basis to estimate human expectation of already mentioned DRs (the number of clicks on the respective NPs in text).,3 Referent Cloze Task,[0],[0]
"However, we expect that script knowledge has a particularly strong influence in the case of first mentions.",3 Referent Cloze Task,[0],[0]
"Once a script is evoked in a text, we assume that the full script structure, including all participants, is activated and available to the reader.
",3 Referent Cloze Task,[0],[0]
Tily and Piantadosi (2009) are interested in second mentions only and therefore do not make use of the worker-generated noun phrases classified as “New”.,3 Referent Cloze Task,[0],[0]
"To study the effect of activated but not explicitly mentioned participants, we carried out a subsequent annotation step on the worker-generated noun phrases classified as “New”.",3 Referent Cloze Task,[0],[0]
"We presented annotators with these noun phrases in their contexts (with co-referring NPs marked by color, as in the MTurk experiment) and, in addition, displayed all participant types of the relevant script (i.e., the script associated with the text in the InScript corpus).",3 Referent Cloze Task,[0],[0]
Annotators did not see the “correct” target NP.,3 Referent Cloze Task,[0],[0]
"We asked annotators to either (1) select the participant type instantiated by the NP (if any), (2) label the NP as unrelated to the script, or (3), link the NP to an overt antecedent in the text, in the case that the NP is actually a second mention that had been erroneously labeled as new by the worker.",3 Referent Cloze Task,[0],[0]
Option (1) provides a basis for a fine-grained estimation of first-mention DRs.,3 Referent Cloze Task,[0],[0]
"Option (3), which we added when we noticed the considerable number of overlooked antecedents, serves as correction of the results of the M-Turk experiment.",3 Referent Cloze Task,[0],[0]
"Out of the 22K annotated “New” cases, 39% were identified as second mentions, 55% were linked to a participant type, and 6% were classified as really novel.",3 Referent Cloze Task,[0],[0]
"In this section, we describe the model we use to predict upcoming discourse referents (DRs).",4 Referent Prediction Model,[0],[0]
"Our model should not only assign probabilities to DRs already explicitly introduced in the preceding text fragment (e.g., “bath” or “bathroom” for the
cloze task in Figure 2) but also reserve some probability mass for ‘new’ DRs, i.e., DRs activated via the script context or completely novel ones not belonging to the script.",4.1 Model,[0],[0]
"In principle, different variants of the activation mechanism must be distinguished.",4.1 Model,[0],[0]
"For many participant types, a single participant belonging to a specific semantic class is expected (referred to with the bathtub or the soap).",4.1 Model,[0],[0]
"In contrast, the “towel” participant type may activate a set of objects, elements of which then can be referred to with a towel or another towel.",4.1 Model,[0],[0]
"The “bath means” participant type may even activate a group of DRs belonging to different semantic classes (e.g., bubble bath and salts).",4.1 Model,[0],[0]
"Since it is not feasible to enumerate all potential participants, for ‘new’ DRs we only predict their participant type (“bath means” in our example).",4.1 Model,[0],[0]
"In other words, the number of categories in our model is equal to the number of previously introduced DRs plus the number of participant types of the script plus 1, reserved for a new DR not corresponding to any script participant (e.g., cellphone).",4.1 Model,[0],[0]
"In what follows, we slightly abuse the terminology and refer to all these categories as discourse referents.
",4.1 Model,[0],[0]
"Unlike standard co-reference models, which predict co-reference chains relying on the entire document, our model is incremental, that is, when predicting a discourse referent d(t) at a given position t, it can look only in the history h(t) (i.e., the preceding part of the document), excluding the referring expression (RE) for the predicted DR.",4.1 Model,[0],[0]
We also assume that past REs are correctly resolved and assigned to correct participant types (PTs).,4.1 Model,[0],[0]
"Typical NLP applications use automatic coreference resolution systems, but since we want to model human behavior, this might be inappropriate, since an automated system would underestimate human performance.",4.1 Model,[0],[0]
"This may be a strong assumption, but for reasons explained above, we use gold standard past REs.
",4.1 Model,[0],[0]
"We use the following log-linear model (“softmax regression”):
p(d(t) = d|h(t))",4.1 Model,[0],[0]
"= exp(w T f(d, h(t)))∑
d′ exp(w T f(d′, h(t)))
,
where f is the feature function we will discuss in the following subsection, w are model parameters, and the summation in the denominator is over the
set of categories described above.",4.1 Model,[0],[0]
Some of the features included in f are a function of the predicate syntactically governing the unobservable target RE (corresponding to the DR being predicted).,4.1 Model,[0],[0]
"However, in our incremental setting, the predicate is not available in the history h(t) for subject NPs.",4.1 Model,[0],[0]
"In this case, we use an additional probabilistic model, which estimates the probability of the predicate v given the context h(t), and marginalize out its predictions:
p(d(t)=d|h(t))= ∑ v p(v|h(t))",4.1 Model,[0],[0]
"exp(w T f(d, h(t), v))∑ d′ exp(w T f(d′, h(t), v))
",4.1 Model,[0],[0]
"The predicate probabilities p(v|h(t)) are computed based on the sequence of preceding predicates (i.e., ignoring any other words) using the recurrent neural network language model estimated on our training set.2",4.1 Model,[0],[0]
"The expression f(d, h(t), v) denotes the feature function computed for the referent d, given the history composed of h(t) and the predicate v.",4.1 Model,[0],[0]
Our features encode properties of a DR as well as characterize its compatibility with the context.,4.2 Features,[0],[0]
We face two challenges when designing our features.,4.2 Features,[0],[0]
"First, although the sizes of our datasets are respectable from the script annotation perspective, they are too small to learn a richly parameterized model.",4.2 Features,[0],[0]
"For many of our features, we address this challenge by using external word embeddings3 and associate parameters with some simple similarity measures computed using these embeddings.",4.2 Features,[0],[0]
"Con-
",4.2 Features,[0],[0]
"2We used RNNLM toolkit (Mikolov et al., 2011; Mikolov et al., 2010) with default settings.
",4.2 Features,[0],[0]
"3We use 300-dimensional word embeddings estimated on Wikipedia with the skip-gram model of Mikolov et al. (2013): https://code.google.com/p/word2vec/
sequently, there are only a few dozen parameters which need to be estimated from scenario-specific data.",4.2 Features,[0],[0]
"Second, in order to test our hypothesis that script information is beneficial for the DR prediction task, we need to disentangle the influence of script information from general linguistic knowledge.",4.2 Features,[0],[0]
"We address this by carefully splitting the features apart, even if it prevents us from modeling some interplay between the sources of information.",4.2 Features,[0],[0]
We will describe both classes of features below; also see a summary in Table 1.,4.2 Features,[0],[0]
These features are based on Tily and Piantadosi (2009).,4.2.1 Shallow Linguistic Features,[0],[0]
"In addition, we consider a selectional preference feature.",4.2.1 Shallow Linguistic Features,[0],[0]
Recency feature.,4.2.1 Shallow Linguistic Features,[0],[0]
"This feature captures the distance lt(d) between the position t and the last occurrence of the candidate DR d. As a distance measure, we use the number of sentences from the last mention and exponentiate this number to make the dependence more extreme; only very recent DRs will receive a noticeable weight: exp(−lt(d)).",4.2.1 Shallow Linguistic Features,[0],[0]
This feature is set to 0 for new DRs.,4.2.1 Shallow Linguistic Features,[0],[0]
Frequency.,4.2.1 Shallow Linguistic Features,[0],[0]
The frequency feature indicates the number of times the candidate discourse referent d has been mentioned so far.,4.2.1 Shallow Linguistic Features,[0],[0]
We do not perform any bucketing.,4.2.1 Shallow Linguistic Features,[0],[0]
Grammatical function.,4.2.1 Shallow Linguistic Features,[0],[0]
This feature encodes the dependency relation assigned to the head word of the last mention of the DR or a special none label if the DR is new.,4.2.1 Shallow Linguistic Features,[0],[0]
Previous subject indicator.,4.2.1 Shallow Linguistic Features,[0],[0]
This binary feature indicates whether the candidate DR d is coreferential with the subject of the previous verbal predicate.,4.2.1 Shallow Linguistic Features,[0],[0]
Previous object indicator.,4.2.1 Shallow Linguistic Features,[0],[0]
The same but for the object position.,4.2.1 Shallow Linguistic Features,[0],[0]
Previous RE type.,4.2.1 Shallow Linguistic Features,[0],[0]
"This three-valued feature indicates whether the previous mention of the candidate DR d is a pronoun, a non-pronominal noun phrase, or has never been observed before.",4.2.1 Shallow Linguistic Features,[0],[0]
The selectional preference feature captures how well the candidate DR d fits a given syntactic position r of a given verbal predicate v.,4.2.2 Selectional Preferences Feature,[0],[0]
"It is computed as the cosine similarity simcos(xTd ,xv,r) of a vector-space representation of the DR xd and a structured vector-space representation of the pred-
icate xv,r.",4.2.2 Selectional Preferences Feature,[0],[0]
The similarities are calculated using a Distributional Memory approach similar to that of Baroni and Lenci (2010).,4.2.2 Selectional Preferences Feature,[0],[0]
"Their structured vector space representation has been shown to work well on tasks that evaluate correlation with human thematic fit estimates (Baroni and Lenci, 2010; Baroni et al., 2014; Sayeed et al., 2016) and is thus suited to our task.
",4.2.2 Selectional Preferences Feature,[0],[0]
"The representation xd is computed as an average of head word representations of all the previous mentions of DR d, where the word vectors are obtained from the TypeDM model of Baroni and Lenci (2010).",4.2.2 Selectional Preferences Feature,[0],[0]
"This is a count-based, third-order cooccurrence tensor whose indices are a word w0, a second word w1, and a complex syntactic relation r, which is used as a stand-in for a semantic link.",4.2.2 Selectional Preferences Feature,[0],[0]
"The values for each (w0, r, w1) cell of the tensor are the local mutual information (LMI) estimates obtained from a dependency-parsed combination of large corpora (ukWaC, BNC, and Wikipedia).
",4.2.2 Selectional Preferences Feature,[0],[0]
Our procedure has some differences with that of Baroni and Lenci.,4.2.2 Selectional Preferences Feature,[0],[0]
"For example, for estimating the fit of an alternative new DR (in other words, xd based on no previous mentions), we use an average over head words of all REs in the training set, a “null referent.”",4.2.2 Selectional Preferences Feature,[0],[0]
"xv,r is calculated as the average of the top 20 (by LMI) r-fillers for v in TypeDM; in other words, the prototypical instrument of rub may be represented by summing vectors like towel, soap, eraser, coin. . .",4.2.2 Selectional Preferences Feature,[0],[0]
"If the predicate has not yet been encountered (as for subject positions), scores for all scenario-relevant verbs are emitted for marginalization.",4.2.2 Selectional Preferences Feature,[0],[0]
"In this section, we describe features which rely on script information.",4.2.3 Script Features,[0],[0]
Our goal will be to show that such common-sense information is beneficial in performing DR prediction.,4.2.3 Script Features,[0],[0]
"We consider only two script features.
",4.2.3 Script Features,[0],[0]
Participant type fit This feature characterizes how well the participant type (PT) of the candidate DR d fits a specific syntactic role r of the governing predicate v; it can be regarded as a generalization of the selectional preference feature to participant types and also its specialisation to the considered scenario.,4.2.3 Script Features,[0],[0]
"Given the candidate DR d, its participant type p, and the syntactic
relation r, we collect all the predicates in the training set which have the participant type p in the position r.",4.2.3 Script Features,[0],[0]
"The embedding of the DR xp,r is given by the average embedding of these predicates.",4.2.3 Script Features,[0],[0]
"The feature is computed as the dot product of xp,r and the word embedding of the predicate v.
Predicate schemas The following feature captures a specific aspect of knowledge about prototypical sequences of events.",4.2.3 Script Features,[0],[0]
This knowledge is called predicate schemas in the recent co-reference modeling work of Peng et al. (2015).,4.2.3 Script Features,[0],[0]
"In predicate schemas, the goal is to model pairs of events such that if a DR d participated in the first event (in a specific role), it is likely to participate in the second event (again, in a specific role).",4.2.3 Script Features,[0],[0]
"For example, in the restaurant scenario, if one observes a phrase John ordered, one is likely to see John waited somewhere later in the document.",4.2.3 Script Features,[0],[0]
"Specific arguments are not that important (where it is John or some other DR), what is important is that the argument is reused across the predicates.",4.2.3 Script Features,[0],[0]
"This would correspond to the rule X-subject-of-order → X-subject-of-eat.4 Unlike the previous work, our dataset is small, so we cannot induce these rules directly as there will be very few rules, and the model would not generalize to new data well enough.",4.2.3 Script Features,[0],[0]
"Instead, we again encode this intuition using similarities in the real-valued embedding space.
",4.2.3 Script Features,[0],[0]
"Recall that our goal is to compute a feature ϕ(d, h(t))",4.2.3 Script Features,[0],[0]
"indicating how likely a potential DR d is to follow, given the history h(t).",4.2.3 Script Features,[0],[0]
"For example, imag-
4In this work, we limit ourselves to rules where the syntactic function is the same on both sides of the rule.",4.2.3 Script Features,[0],[0]
"In other words, we can, in principle, encode the pattern X pushed Y → X apologized but not the pattern X pushed Y → Y cried.
",4.2.3 Script Features,[0],[0]
ine that the model is asked to predict the DR marked by XXXXXX in Figure 4.,4.2.3 Script Features,[0],[0]
"Predicate-schema rules can only yield previously introduced DRs, so the score ϕ(d, h(t))",4.2.3 Script Features,[0],[0]
= 0 for any new DR d. Let us use “soap” as an example of a previously introduced DR and see how the feature is computed.,4.2.3 Script Features,[0],[0]
"In order to choose which inference rules can be applied to yield “soap”, we can inspect Figure 4.",4.2.3 Script Features,[0],[0]
"There are only two preceding predicates which have DR “soap” as their object (rubbed and grabbed), resulting in two potential rules X-object-of-grabbed→ X-object-of-rinsed and X-object-of-rubbed → X-object-of-rinsed.",4.2.3 Script Features,[0],[0]
"We define the score ϕ(d, h(t))",4.2.3 Script Features,[0],[0]
as the average of the rule scores.,4.2.3 Script Features,[0],[0]
"More formally, we can write
ϕ(d, h(t))= 1 |N(d, h(t))| ∑
(u,v,r)∈N(d,h(t))
ψ(u, v, r), (1)
where ψ(u, v, r) is the score for a rule X-r-of-u → X-r-of-v, N(d, h(t))",4.2.3 Script Features,[0],[0]
"is the set of applicable rules, and |N(d, h(t))| denotes its cardinality.5",4.2.3 Script Features,[0],[0]
"We define ϕ(d, h(t))",4.2.3 Script Features,[0],[0]
"as 0, when the set of applicable rules is empty (i.e. |N(d, h(t))| = 0).
",4.2.3 Script Features,[0],[0]
"The scoring function ψ(u, v, r) as a linear func-
5In all our experiments, rather than considering all potential predicates in the history to instantiate rules, we take into account only 2 preceding verbs.",4.2.3 Script Features,[0],[0]
"In other words, u and v can be interleaved by at most one verb and |N(d, h(t))| is in {0, 1, 2}.
tion of a joint embedding xu,v of verbs u and v:
ψ(u, v, r) =",4.2.3 Script Features,[0],[0]
"αTr xu,v.
The two remaining questions are (1) how to define the joint embeddings xu,v, and (2) how to estimate the parameter vectorαr.",4.2.3 Script Features,[0],[0]
"The joint embedding of two predicates, xu,v, can, in principle, be any composition function of embeddings of u and v, for example their sum or component-wise product.",4.2.3 Script Features,[0],[0]
"Inspired by Bordes et al. (2013), we use the difference between the word embeddings:
ψ(u, v, r) = αTr (xu − xv),
where xu and xv are external embeddings of the corresponding verbs.",4.2.3 Script Features,[0],[0]
Encoding the succession relation as translation in the embedding space has one desirable property: the scoring function will be largely agnostic to the morphological form of the predicates.,4.2.3 Script Features,[0],[0]
"For example, the difference between the embeddings of rinsed and rubbed is very similar to that of rinse and rub (Botha and Blunsom, 2014), so the corresponding rules will receive similar scores.",4.2.3 Script Features,[0],[0]
"Now, we can rewrite the equation (1) as
ϕ(d, h(t))= αT r(h(t))
",4.2.3 Script Features,[0],[0]
"∑ (u,v,r)∈N(d,h(t))",4.2.3 Script Features,[0],[0]
"(xu − xv)
|N(d, h(t))| (2)
where r(h(t)) denotes the syntactic function corresponding to the DR being predicted (object in our example).
",4.2.3 Script Features,[0],[0]
"As for the parameter vector αr, there are again a number of potential ways how it can be estimated.",4.2.3 Script Features,[0],[0]
"For example, one can train a discriminative classifier to estimate the parameters.",4.2.3 Script Features,[0],[0]
"However, we opted for a simpler approach—we set it equal to the empirical estimate of the expected feature vector xu,v on the training set:6
αr = 1
Dr ∑ l,t δr(r(h",4.2.3 Script Features,[0],[0]
"(l,t)))",4.2.3 Script Features,[0],[0]
"∑ (u,v,r′)∈N(d(l,t),h(l,t)) (xu − xv), (3)
where l refers to a document in the training set, t is (as before) a position in the document, h(l,t) and
6This essentially corresponds to using the Naive Bayes model with the simplistic assumption that the score differences are normally distributed with spherical covariance matrices.
",4.2.3 Script Features,[0],[0]
"d(l,t) are the history and the correct DR for this position, respectively.",4.2.3 Script Features,[0],[0]
"The term δr(r′) is the Kronecker delta which equals 1 if r = r′ and 0, otherwise.",4.2.3 Script Features,[0],[0]
"Dr is the total number of rules for the syntactic function r in the training set:
Dr = ∑ l,t δr(r(h",4.2.3 Script Features,[0],[0]
"(l,t)))× |N(d(l,t), h(l,t))|.
",4.2.3 Script Features,[0],[0]
Let us illustrate the computation with an example.,4.2.3 Script Features,[0],[0]
"Imagine that our training set consists of the document in Figure 1, and the trained model is used to predict the upcoming DR in our referent cloze example (Figure 4).",4.2.3 Script Features,[0],[0]
"The training document includes the pair X-object-of-scrubbed→ X-object-of-rinsing, so the corresponding term (xscrubbed - xrinsing) participates in the summation (3) for αobj .",4.2.3 Script Features,[0],[0]
"As we rely on external embeddings, which encode semantic similarities between lexical items, the dot product of this term and (xrubbed - xrinsed) will be high.7 Consequently, ϕ(d, h(t)) is expected to be positive for d = “soap”, thus, predicting “soap” as the likely forthcoming DR.",4.2.3 Script Features,[0],[0]
"Unfortunately, there are other terms (xu − xv) both in expression (3) for αobj and in expression (2) for ϕ(d, h(t)).",4.2.3 Script Features,[0],[0]
"These terms may be
7The score would have been even higher, should the predicate be in the morphological form rinsing rather than rinsed.",4.2.3 Script Features,[0],[0]
"However, embeddings of rinsing and rinsed would still be sufficiently close to each other for our argument to hold.
irrelevant to the current prediction, as X-object-ofplugged → X-object-of-filling from Figure 1, and may not even encode any valid regularities, as Xobject-of-got → X-object-of-scrubbed (again from Figure 1).",4.2.3 Script Features,[0],[0]
This may suggest that our feature will be too contaminated with noise to be informative for making predictions.,4.2.3 Script Features,[0],[0]
"However, recall that independent random vectors in high dimensions are almost orthogonal, and, assuming they are bounded, their dot products are close to zero.",4.2.3 Script Features,[0],[0]
"Consequently, the products of the relevant (“non-random”) terms, in our example (xscrubbed - xrinsing) and (xrubbed - xrinsed), are likely to overcome the (“random”) noise.",4.2.3 Script Features,[0],[0]
"As we will see in the ablation studies, the predicateschema feature is indeed predictive of a DR and contributes to the performance of the full model.",4.2.3 Script Features,[0],[0]
"We would like to test whether our model can produce accurate predictions and whether the model’s guesses correlate well with human predictions for the referent cloze task.
",4.3 Experiments,[0],[0]
"In order to be able to evaluate the effect of script knowledge on referent predictability, we compare three models: our full Script model uses all of the features introduced in section 4.2; the Linguistic model relies only on the ‘linguistic features’ but not the script-specific ones; and the Base model includes all the shallow linguistic features.",4.3 Experiments,[0],[0]
The Base model differs from the linguistic model in that it does not model selectional preferences.,4.3 Experiments,[0],[0]
"Table 2 summarizes features used in different models.
",4.3 Experiments,[0],[0]
"The data set was randomly divided into training (70%), development (10%, 91 stories from 10 sce-
narios), and test (20%, 182 stories from 10 scenarios) sets.",4.3 Experiments,[0],[0]
"The feature weights were learned using L-BFGS (Byrd et al., 1995) to optimize the loglikelihood.",4.3 Experiments,[0],[0]
Evaluation against original referents.,4.3 Experiments,[0],[0]
We calculated the percentage of correct DR predictions.,4.3 Experiments,[0],[0]
See Table 3 for the averages across 10 scenarios.,4.3 Experiments,[0],[0]
We can see that the task appears hard for humans: their average performance reaches only 73% accuracy.,4.3 Experiments,[0],[0]
"As expected, the Base model is the weakest system (the accuracy of 31%).",4.3 Experiments,[0],[0]
Modeling selectional preferences yields an extra 18% in accuracy (Linguistic model).,4.3 Experiments,[0],[0]
"The key finding is that incorporation of script knowledge increases the accuracy by further 13%, although still far behind human performance (62% vs. 73%).",4.3 Experiments,[0],[0]
"Besides accuracy, we use perplexity, which we computed not only for all our models but also for human predictions.",4.3 Experiments,[0],[0]
This was possible as each task was solved by multiple humans.,4.3 Experiments,[0],[0]
We used unsmoothed normalized guess frequencies as the probabilities.,4.3 Experiments,[0],[0]
"As we can see from Table 3, the perplexity scores are consistent with the accuracies: the script model again outperforms other methods, and, as expected, all the models are weaker than humans.
",4.3 Experiments,[0],[0]
"As we used two sets of script features, capturing different aspects of script knowledge, we performed extra ablation studies (Table 4).",4.3 Experiments,[0],[0]
The experiments confirm that both feature sets were beneficial.,4.3 Experiments,[0],[0]
Evaluation against human expectations.,4.3 Experiments,[0],[0]
"In the previous subsection, we demonstrated that the incorporation of selectional preferences and, perhaps more interestingly, the integration of automatically acquired script knowledge lead to improved accuracy in predicting discourse referents.",4.3 Experiments,[0],[0]
Now we turn to another question raised in the introduction: does incorporation of this knowledge make our predictions more human-like?,4.3 Experiments,[0],[0]
"In other words, are we able to accurately estimate human expectations?",4.3 Experiments,[0],[0]
"This includes not only being sufficiently accurate but also making the same kind of incorrect predictions.
",4.3 Experiments,[0],[0]
"In this evaluation, we therefore use human guesses collected during the referent cloze task as our target.",4.3 Experiments,[0],[0]
We then calculate the relative accuracy of each computational model.,4.3 Experiments,[0],[0]
"As can be seen in Figure 5, the Script model, at approx.",4.3 Experiments,[0],[0]
"53% accuracy, is a lot more accurate in predicting human guesses than the Linguistic model and the Base model.",4.3 Experiments,[0],[0]
"We can also
observe that the margin between the Script model and the Linguistic model is a lot larger in this evaluation than between the Base model and the Linguistic model.",4.3 Experiments,[0],[0]
"This indicates that the model which has access to script knowledge is much more similar to human prediction behavior in terms of top guesses than the script-agnostic models.
",4.3 Experiments,[0],[0]
Now we would like to assess if our predictions are similar as distributions rather than only yielding similar top predictions.,4.3 Experiments,[0],[0]
"In order to compare the distributions, we use the Jensen-Shannon divergence (JSD), a symmetrized version of the KullbackLeibler divergence.
",4.3 Experiments,[0],[0]
"Intuitively, JSD measures the distance between two probability distributions.",4.3 Experiments,[0],[0]
A smaller JSD value is indicative of more similar distributions.,4.3 Experiments,[0],[0]
"Figure 6 shows that the probability distributions resulting from the Script model are more similar to human predictions than those of the Linguistic and Base models.
",4.3 Experiments,[0],[0]
"In these experiments, we have shown that script knowledge improves predictions of upcoming referents and that the script model is the best among our models in approximating human referent predictions.",4.3 Experiments,[0],[0]
"Using the referent prediction models, we next attempt to replicate Tily and Piantadosi’s findings that
the choice of the type of referring expression (pronoun or full NP) depends in part on the predictability of the referent.",5 Referring Expression Type Prediction Model (RE Model),[0],[0]
"The uniform information density (UID) hypothesis suggests that speakers tend to convey information at a uniform rate (Jaeger, 2010).",5.1 Uniform Information Density hypothesis,[0],[0]
"Applied to choice of referring expression type, it would predict that a highly predictable referent should be encoded using a short code (here: a pronoun), while an unpredictable referent should be encoded using a longer form (here: a full NP).",5.1 Uniform Information Density hypothesis,[0],[0]
"Information density is measured using the information-theoretic measure of the surprisal S of a message mi:
S(mi) =",5.1 Uniform Information Density hypothesis,[0],[0]
− logP (mi | context) UID has been very successful in explaining a variety of linguistic phenomena; see Jaeger et al. (2016).,5.1 Uniform Information Density hypothesis,[0],[0]
"There is, however, controversy about whether UID affects pronominalization.",5.1 Uniform Information Density hypothesis,[0],[0]
Tily and Piantadosi (2009) report evidence that writers are more likely to refer using a pronoun or proper name when the referent is easy to guess and use a full NP when readers have less certainty about the upcoming referent; see also Arnold (2001).,5.1 Uniform Information Density hypothesis,[0],[0]
"But other experiments (using highly controlled stimuli) have failed to find an effect of predictability on pronominalization (Stevenson et al., 1994; Fukumura and van Gompel, 2010; Rohde and Kehler, 2014).",5.1 Uniform Information Density hypothesis,[0],[0]
The present study hence contributes to the debate on whether UID affects referring expression choice.,5.1 Uniform Information Density hypothesis,[0],[0]
Our goal is to determine whether referent predictability (quantified in terms of surprisal) is correlated with the type of referring expression used in the text.,5.2 A model of Referring Expression Choice,[0],[0]
Here we focus on the distinction between pronouns and full noun phrases.,5.2 A model of Referring Expression Choice,[0],[0]
Our data also contains a small percentage (ca.,5.2 A model of Referring Expression Choice,[0],[0]
1%) of proper names (like “John”).,5.2 A model of Referring Expression Choice,[0],[0]
"Due to this small class size and earlier findings that proper nouns behave much like pronouns (Tily and Piantadosi, 2009), we combined pronouns and proper names into a single class of short encodings.
",5.2 A model of Referring Expression Choice,[0],[0]
"For the referring expression type prediction task, we estimate the surprisal of the referent from each of our computational models from Section 4 as well as the human cloze task.",5.2 A model of Referring Expression Choice,[0],[0]
"The surprisal of an upcoming discourse referent d(t) based on the previous context
h(t) is thereby estimated as: S(d(t)) =",5.2 A model of Referring Expression Choice,[0],[0]
"− log p(d(t) | h(t))
",5.2 A model of Referring Expression Choice,[0],[0]
"In order to determine whether referent predictability has an effect on referring expression type over and above other factors that are known to affect the choice of referring expression, we train a logistic regression model with referring expression type as a response variable and discourse referent predictability as well as a large set of other linguistic factors (based on Tily and Piantadosi, 2009) as explanatory variables.",5.2 A model of Referring Expression Choice,[0],[0]
"The model is defined as follows:
p(n(t) = n|d(t), h(t))",5.2 A model of Referring Expression Choice,[0],[0]
=,5.2 A model of Referring Expression Choice,[0],[0]
"exp(v Tg(n, dt, h(t)))∑
n′",5.2 A model of Referring Expression Choice,[0],[0]
"exp(v Tg(n′, dt, h(t)))
,
where d(t) and h(t) are defined as before, g is the feature function, and v is the vector of model parameters.",5.2 A model of Referring Expression Choice,[0],[0]
The summation in the denominator is over NP types (full NP vs. pronoun/proper noun).,5.2 A model of Referring Expression Choice,[0],[0]
We ran four different logistic regression models.,5.3 RE Model Experiments,[0],[0]
These models all contained exactly the same set of linguistic predictors but differed in the estimates used for referent type surprisal and residual entropy.,5.3 RE Model Experiments,[0],[0]
"One logistic regression model used surprisal estimates based on the human referent cloze task, while the three other models used estimates based on the three computational models (Base, Linguistic and Script).",5.3 RE Model Experiments,[0],[0]
"For our experiment, we are interested in the choice of referring expression type for those occurrences of references, where a “real choice” is possible.",5.3 RE Model Experiments,[0],[0]
We therefore exclude for our analysis reported below all first mentions as well as all first and second person pronouns (because there is no optionality in how to refer to first or second person).,5.3 RE Model Experiments,[0],[0]
This subset contains 1345 data points.,5.3 RE Model Experiments,[0],[0]
The results of all four logistic regression models are shown in Table 5.,5.4 Results,[0],[0]
We first take a look at the results for the linguistic features.,5.4 Results,[0],[0]
"While there is a bit of variability in terms of the exact coefficient estimates between the models (this is simply due to small correlations between these predictors and the predictors for surprisal), the effect of all of these features is largely consistent across models.",5.4 Results,[0],[0]
"For instance, the positive coefficients for the recency feature means that when a previous mention happened
very recently, the referring expression is more likely to be a pronoun (and not a full NP).
",5.4 Results,[0],[0]
"The coefficients for the surprisal estimates of the different models are, however, not significantly different from zero.",5.4 Results,[0],[0]
Model comparison shows that they do not improve model fit.,5.4 Results,[0],[0]
We also used the estimated models to predict referring expression type on new data and again found that surprisal estimates from the models did not improve prediction accuracy.,5.4 Results,[0],[0]
This effect even holds for our human cloze data.,5.4 Results,[0],[0]
"Hence, it cannot be interpreted as a problem with the models—even human predictability estimates are, for this dataset, not predictive of referring expression type.
",5.4 Results,[0],[0]
We also calculated regression models for the full dataset including first and second person pronouns as well as first mentions (3346 data points).,5.4 Results,[0],[0]
"The results for the full dataset are fully consistent with the findings shown in Table 5: there was no significant effect of surprisal on referring expression type.
",5.4 Results,[0],[0]
"This result contrasts with the findings by Tily and Piantadosi (2009), who reported a significant effect of surprisal on RE type for their data.",5.4 Results,[0],[0]
"In order to replicate their settings as closely as possible, we also included residualEntropy as a predictor in our model (see last predictor in Table 5); however, this did not change the results.",5.4 Results,[0],[0]
Our study on incrementally predicting discourse referents showed that script knowledge is a highly important factor in determining human discourse expectations.,6 Discussion and Future Work,[0],[0]
"Crucially, the computational modelling approach allowed us to tease apart the different factors that affect human prediction as we cannot manipulate this in humans directly (by asking them to “switch off” their common-sense knowledge).
",6 Discussion and Future Work,[0],[0]
"By modelling common-sense knowledge in terms of event sequences and event participants, our model captures many more long-range dependencies than normal language models.",6 Discussion and Future Work,[0],[0]
"The script knowledge is automatically induced by our model from crowdsourced scenario-specific text collections.
",6 Discussion and Future Work,[0],[0]
"In a second study, we set out to test the hypothesis that uniform information density affects referring expression type.",6 Discussion and Future Work,[0],[0]
"This question is highly controversial in the literature: while Tily and Piantadosi (2009) find a significant effect of surprisal on referring expression type in a corpus study very similar to ours, other studies that use a more tightly controlled experimental approach have not found an effect of predictability on RE type (Stevenson et al., 1994; Fukumura and van Gompel, 2010; Rohde and Kehler, 2014).",6 Discussion and Future Work,[0],[0]
"The present study, while replicating exactly the setting of T&P in terms of features and analysis, did not find support for a UID effect on RE type.",6 Discussion and Future Work,[0],[0]
"The difference in results between T&P 2009 and our results could be due to the different corpora and text sorts that were used; specifically, we would expect that larger predictability effects might be observable at script boundaries, rather than within a script, as is the case in our stories.
",6 Discussion and Future Work,[0],[0]
A next step in moving our participant prediction model towards NLP applications would be to replicate our modelling results on automatic textto-script mapping instead of gold-standard data as done here (in order to approximate human level of processing).,6 Discussion and Future Work,[0],[0]
"Furthermore, we aim to move to more complex text types that include reference to several scripts.",6 Discussion and Future Work,[0],[0]
"We plan to consider the recently published ROC Stories corpus (Mostafazadeh et al., 2016), a large crowdsourced collection of topically unrestricted short and simple narratives, as a basis for these next steps in our research.",6 Discussion and Future Work,[0],[0]
We thank the editors and the anonymous reviewers for their insightful suggestions.,Acknowledgments,[0],[0]
We would like to thank Florian Pusse for helping with the Amazon Mechanical Turk experiment.,Acknowledgments,[0],[0]
We would also like to thank Simon Ostermann and Tatjana Anikina for helping with the InScript corpus.,Acknowledgments,[0],[0]
"This research was partially supported by the German Research Foundation (DFG) as part of SFB 1102 ‘Information Density and Linguistic Encoding’, European Research Council (ERC) as part of ERC Starting Grant BroadSem (#678254), the Dutch National Science Foundation as part of NWO VIDI 639.022.518, and the DFG once again as part of the MMCI Cluster of Excellence (EXC 284).",Acknowledgments,[0],[0]
Recent research in psycholinguistics has provided increasing evidence that humans predict upcoming content.,abstractText,[0],[0]
Prediction also affects perception and might be a key to robustness in human language processing.,abstractText,[0],[0]
"In this paper, we investigate the factors that affect human prediction by building a computational model that can predict upcoming discourse referents based on linguistic knowledge alone vs. linguistic knowledge jointly with common-sense knowledge in the form of scripts.",abstractText,[0],[0]
We find that script knowledge significantly improves model estimates of human predictions.,abstractText,[0],[0]
"In a second study, we test the highly controversial hypothesis that predictability influences referring expression type but do not find evidence for such an effect.",abstractText,[0],[0]
Modeling Semantic Expectation: Using Script Knowledge for Referent Prediction,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 303–308 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Intuitively, a man can swallow a candy or paintball but not a desk.",1 Introduction,[0],[0]
"Equally so, one cannot plausibly eat a cake and then hold it.",1 Introduction,[0],[0]
What kinds of semantic knowledge are necessary for distinguishing a physically plausible event (or event sequence) from an implausible one?,1 Introduction,[0],[0]
"Semantic plausibility stands in stark contrast to the familiar selectional preference (Erk and Padó, 2010; Van de Cruys, 2014) which is concerned with the typicality of events (Table 1).",1 Introduction,[0],[0]
"For example, candy is a typical entity for man-swallow-* but paintball is not, even though both events are plausible physically.",1 Introduction,[0],[0]
"Also, some events are physically plausible but are never stated because humans avoid stating the obvious.",1 Introduction,[0],[0]
"Critically, semantic plausibility is sensitive to certain properties such as relative object size that are not explicitly encoded by selectional preferences (Bagherinezhad et al., 2016).",1 Introduction,[0],[0]
"Therefore, it is crucial that we learn to model these dimensions in addition to using classical distributional signals.
",1 Introduction,[0],[0]
"Semantic plausibility is pertinent and crucial in a multitude of interesting NLP tasks put forth previously, such as narrative schema (Chambers, 2013), narrative interpolation (Bowman et al., 2016), story understanding (Mostafazadeh et al., 2016), and paragraph reconstruction (Li and Jurafsky, 2017).",1 Introduction,[0],[0]
"Existing methods for these tasks, however, draw predominantly (if not only) on distributional data and produce rather weak performance.",1 Introduction,[0],[0]
"Semantic plausibility over subject-verbobject triples, while simpler than these other tasks, is a key building block that requires many of the same signals and encapsulates complex world knowledge in a binary prediction problem.
",1 Introduction,[0],[0]
"In this work, we show that world knowledge injection is necessary and effective for the semantic plausibility task, for which we create a robust, high-agreement dataset (details in section 3).",1 Introduction,[0],[0]
"Employing methods inspired by the recent work on world knowledge propagation through distributional context (Forbes and Choi, 2017; Wang et al., 2017), we accomplish the goal with minimal effort in manual annotation.",1 Introduction,[0],[0]
"Finally, we perform an indepth error analysis to point to future directions of work on semantic plausibility.
303",1 Introduction,[0],[0]
Simple events (i.e. S-V-O) have seen thorough investigation from the angle of selectional preference.,2 Related Work,[0],[0]
"While early works are resourcebased (Resnik, 1996; Clark and Weir, 2001), later work shows that unsupervised learning with distributional data yields strong performance (O’Seaghdha, 2010; Erk and Padó, 2010), which has recently been further improved upon with neural approaches (Van de Cruys, 2014; Tilk et al., 2016).",2 Related Work,[0],[0]
"Distribution-only models however, as will be shown, fail on the semantic plausibility task we propose.
",2 Related Work,[0],[0]
Physical world knowledge modeling appears frequently in more closely related work.,2 Related Work,[0],[0]
Bagherinezhad et al. (2016) combine computer vision and text-based information extraction to learn the relative sizes of objects; Forbes and Choi (2017) crowdsource physical knowledge along specified dimensions and employ belief propagation to learn relative physical attributes of object pairs.,2 Related Work,[0],[0]
"Wang et al. (2017) propose a multimodal LDA to learn the definitional properties (e.g. animal, fourlegged) of entities.",2 Related Work,[0],[0]
"Zhang et al. (2017) study the role of common-sense knowledge in natural language inference, which is inherently betweenevents rather than single-event focused.",2 Related Work,[0],[0]
"Prior work does not specifically handles the (singleevent) semantic plausibility task and related efforts do not necessarily adapt well to this task, as we will show, suggesting that new approaches are needed.",2 Related Work,[0],[0]
"To study the semantic plausibility of S-V-O events, specifically physical semantic plausibility, we create a dataset1 through Amazon Mechanical Turk with the following criteria in mind: (i) Robustness: Strong inter-annotator agreement; (ii) Diversity: A wide range of typical/atypical, plausible/implausible events; (iii) Balanced: Equal number of plausible and implausible events.
",3 Data,[0],[0]
"In creating physical events, we work with a fixed vocabulary of 150 concrete verbs and 450 concrete nouns from Brysbaert et al. (2014)’s word list, with a concreteness threshold of 4.95 (scale: 0-5).",3 Data,[0],[0]
"We take the following steps:
1Link: https://github.com/suwangcompling/ Modeling-Semantic-Plausibility-NAACL18/ tree/master/data.
",3 Data,[0],[0]
"(a) Have Turkers write down plausible or implausible S-V and V-O selections;
(b) Randomly generate S-V-O triples from collected S-V and V-O pairs;
(c) Send resulting S-V-O triples to Turkers to filter for ones with high agreement (by majority vote).
",3 Data,[0],[0]
(a) ensures diversity and the cleanness of data (compared with noisy selectional preference data collected unsupervised from free text): the Turkers are instructed (with examples) to (i) consider both typical and atypical selections (e.g. manswallow-* with candy or paintball); (ii) disregard metaphorical uses (e.g. feel-blue or fish-idea).,3 Data,[0],[0]
"2,000 pairs are collected in the step, balancing typical and atypical pairs.",3 Data,[0],[0]
"In (b), we manually filter error submissions in triple generation.",3 Data,[0],[0]
"For (c), 5 Turkers provide labels, and we only keep the ones that have ≥ 3 majority votes, resulting with 3,062 triples (of 4,000 annotated triples, plausibleimplausible balanced), with 100% ≥ 3 agreement, 95% ≥ 4 agreement, and 90% 5 agreement.
",3 Data,[0],[0]
"To empirically show the failure of distributiononly methods, we run Van de Cruys (2014)’s neural net classifier (hereforth NN), which is one of the strongest models designed for selectional preference (Figure 1, left-box).",3 Data,[0],[0]
Let x be the concatenation of the embeddings of the three words in an S-V-O triple.,3 Data,[0],[0]
"The prediction P (y|x) is computed as follows:
P (y = 1|x) = σ2(W2σ1(W1x))",3 Data,[0],[0]
"(1) where σ is a nonlinearity, W are weights, and we use 300D pretrained GloVe vectors (Pennington et al., 2014).",3 Data,[0],[0]
"The model achieves an accuracy of 68% (logistic regression baseline: 64%) after finetuning, verifying the intuition that distributional data alone cannot satisfactorily capture the semantics of physical plausibility.",3 Data,[0],[0]
"Recognizing that a distribution-alone method lacks necessary information, we collect a set of world knowledge features.",4 World Knowledge Features,[0],[0]
The feature types derive from inspecting the high agreement event triples for knowledge missing in distributional selection (e.g. relative sizes in man-swallowpaintball/desk).,4 World Knowledge Features,[0],[0]
"Previously, Forbes and Choi (2017) proposed a three level (3-LEVEL) featurization scheme, where an object-pair can take 3
values for, e.g. relative size: {−1, 0, 1} (i.e. lesser, similar, greater).",4 World Knowledge Features,[0],[0]
"This method, however, does not explain many cases we observed.",4 World Knowledge Features,[0],[0]
"For instance, man-hug-cat/ant, man is larger than both cat and ant, but the latter event is implausible.",4 World Knowledge Features,[0],[0]
3-LEVEL is also inefficient: k objects incur O(k2) elicitations.,4 World Knowledge Features,[0],[0]
"We thus propose a binning-by-landmark method, which is sufficiently fine-grained while still being efficient and easy for the annotator: given an entity n, the Turker decides to which of the landmarks n is closest to.",4 World Knowledge Features,[0],[0]
"E.g., for SIZE, we have the landmarks {watch, book, cat, person, jeep, stadium}, in ascending sizes.",4 World Knowledge Features,[0],[0]
"If n = dog, the Turker may put n in the bin corresponding to cat.",4 World Knowledge Features,[0],[0]
"The features2 are listed with their landmarks as follows: • SENTIENCE: rock, tree, ant, cat, chimp, man.",4 World Knowledge Features,[0],[0]
•,4 World Knowledge Features,[0],[0]
MASS-COUNT:,4 World Knowledge Features,[0],[0]
"milk, sand, pebbles, car.",4 World Knowledge Features,[0],[0]
"• PHASE: smoke, milk, wood.",4 World Knowledge Features,[0],[0]
•,4 World Knowledge Features,[0],[0]
"SIZE: watch, book, cat, person, jeep, stadium.",4 World Knowledge Features,[0],[0]
"• WEIGHT: watch, book, dumbbell, man, jeep, stadium.",4 World Knowledge Features,[0],[0]
"• RIGIDITY: water, skin, leather, wood, metal.
5",4 World Knowledge Features,[0],[0]
"Turkers provide annotations for all 450 nouns, and we obtained 93% ≥ 3 agreement, 85% ≥ 4 agreement, and 79% 5 agreement.
",4 World Knowledge Features,[0],[0]
"Our binning is sufficiently granular, which is crucial for semantic plausibility of an event in many cases.",4 World Knowledge Features,[0],[0]
"E.g. for man-hug-cat/ant, man, cat and ant fall in the 4th, 3rd and 1st bin, which suffices to explain why man-hug-cat is plausible while man-hug-ant is not.",4 World Knowledge Features,[0],[0]
"Compared to past work (Forbes and Choi, 2017), it is efficient.",4 World Knowledge Features,[0],[0]
"Each entity only needs one assignment in comparison to the landmarks to be located in a “global scale” (e.g. from the smallest to the largest objects), and even for extreme granularity, it only takes O(k log k) comparisons.",4 World Knowledge Features,[0],[0]
It is also intuitive: differences in bins capture the intuition that one can hug smaller objects as long as those objects are not too small.,4 World Knowledge Features,[0],[0]
We answer two questions: (i) Does world knowledge improve the accuracy of semantic plausibility classification?,5 Models,[0],[0]
"(ii) Can we minimize effort in knowledge feature annotation by learning from a
2We experimented with numerous feature types, e.g. size, temperature, shape, etc. and kept the subset that contributes most substantially to semantic plausibility classification.",5 Models,[0],[0]
"More details on the feature types in supplementary material (https://github.com/suwangcompling/ Modeling-Semantic-Plausibility-NAACL18/ tree/master/supplementary).
",5 Models,[0],[0]
small amount of training data?,5 Models,[0],[0]
"For question (i), we experiment with various methods to incorporate the features on top of the embedding-only NN (Section 3).",5 Models,[0],[0]
"Our architecture3 is outlined in Figure 1, where we ensemble the NN (left-box) and another feedforward net for features (WK, right-box) to produce the final prediction.",5 Models,[0],[0]
"For the feature net, the relative physical attributes of the subject-object pair can be encoded in 3-LEVEL (Section 4) or the bin difference (BINDIFF) scheme.4 For BIN-DIFF, given the two entities in an S-V-O event (i.e. S, O) ant and man, which are in the bins of the landmark watch (i.e. the 1st) and that of person (i.e. the 4th), the pair ant-man gets a BIN-DIFF value of 1−4 = −3.",5 Models,[0],[0]
"Exemplifying the featurization function f(s, o) with SIZE:
f3-L(SIZE(s), SIZE(o)) ∈ {−1, 0, 1} (2) fBIN(SIZE(s), SIZE(o))",5 Models,[0],[0]
"= BIN(s)− BIN(o) (3)
Then, given a featurization scheme, we may feed raw feature values (RAW VEC, for 3-LEVEL, e.g. concatenation of -1, 0 or 1 of all feature types, in that order, and in one-hot format), or feature embeddings (EMBEDDING, e.g. concatenation of embeddings looked up with feature values).",5 Models,[0],[0]
"Fi-
3More configuration details in supplementary material.",5 Models,[0],[0]
"4We also tried using bin numbers directly, however it does not produce ideal results (classification accuracy between 3- LEVEL and BIN-DIFF).",5 Models,[0],[0]
"Thus for brevity we drop this setup.
nally, let aNN,aWK be the penultimate-layer vectors of NN and WK (see Figure 1), we affine transform their concatenation to predict label ŷ with argmax on the final softmax layer:
ŷ",5 Models,[0],[0]
= argmax y softmax(σ(W,5 Models,[0],[0]
"[aNN;aWK] + b)) (4)
where σ is a ReLU nonlinearity.",5 Models,[0],[0]
"We will only report the results from the best-performing model configuration, which has BIN-DIFF + EMBEDDING.",5 Models,[0],[0]
"The model will be listed below as NN + WK-GOLD (i.e. with GOLD, Turker-annotated World Knowledge features).
",5 Models,[0],[0]
"For question (ii), we select a data-efficient feature learning model.",5 Models,[0],[0]
Following Forbes and Choi (2017) we evaluate the models with 5% or 20% of training data.,5 Models,[0],[0]
We experiment with several previously proposed techniques: (a) label spreading; (b) factor graph; (c) multi-LDA.,5 Models,[0],[0]
As a baseline we employ a simple but well-tuned logistic regressor (LR).,5 Models,[0],[0]
"We also initialize the factor graph with this LR, on account of its unexpectedly strong performance.5 Finally, observing that the feature types are inherently ordinal (e.g. SIZE from small to large), we also run ordinal logistic regression (Adeleke and Adepoju, 2010).",5 Models,[0],[0]
"For model selection we first evaluate the object-pair attribute data collected by Forbes and Choi (2017), 2.5k pairs labeled in the 3-LEVEL scheme.",5 Models,[0],[0]
We then compared the the LR and Ordinal-LR (our strongest models6 in this experiment) on 10k randomly generated object-pairs from our annotated nouns.,5 Models,[0],[0]
"The results are summarized in Table 2, where we see
5We verified our setup with the authors and they attributed the higher performance of our LR to hyperparameter choices.",5 Models,[0],[0]
"6Because the factor graph + LR gives very slight improvement, for simplicity we choose LR instead.
",5 Models,[0],[0]
"(i) 3-LEVEL propagation is much easier; (ii) our object-pairs are more challenging, likely due to sparsity with larger vocabulary size; (iii) ordinality information contributes substantially to performance.",5 Models,[0],[0]
The model that uses propagated features (w/ Ordinal-LR) will be listed as NN + WK-PROP.,5 Models,[0],[0]
"We evaluate the models on the task of classifying our 3,062 S-V-O triples by semantic plausibility (10-fold CV, taking the average over 20 runs with the same random seed).",6 Semantic Plausibility Results,[0],[0]
"We compare our three models in the 3-LEVEL and BIN-DIFF schemes, with NN + WK-PROP evaluated in 5% and 20% training conditions.",6 Semantic Plausibility Results,[0],[0]
The results are outlined in Table 3.,6 Semantic Plausibility Results,[0],[0]
Summarizing our findings: (i) world knowledge undoubtedly leads to a strong performance boost (∼8%); (ii) BIN-DIFF scheme works much better than 3-LEVEL — it manages to outperform the latter even with much weaker propagation accuracy; (iii) the accuracy loss with propagated features seems rather mild with 20% labeled training and the best scheme.,6 Semantic Plausibility Results,[0],[0]
"To understand what challenges remain in this task, we run the models above 200 times (10-fold CV, random shuffle at each run), and inspect the top 200 most frequently misclassified cases.",7 Error Analysis,[0],[0]
"The percentage statistics below are from counting the error cases.
",7 Error Analysis,[0],[0]
"In the cases where NN misclassifies while NN + WK-GOLD correctly classifies, 60% relates to SIZE and WEIGHT (e.g. missing man-hug-ant
(bad) or dog-pull-paper (good)).",7 Error Analysis,[0],[0]
PHASE takes up 18% (e.g. missing monkey-puff-smoke (good)).,7 Error Analysis,[0],[0]
"This validates the intuition that distributional contexts do not encode these types of world knowledge.
",7 Error Analysis,[0],[0]
"For cases often misclassified by all the models, we observe two main types of errors: (i) data sparsity; (ii) highly-specific attributes.
",7 Error Analysis,[0],[0]
Data sparsity (32%).,7 Error Analysis,[0],[0]
"man-choke-ant, e.g., is a singleton big-object-choke-small-object instance, and there are no distributionally similar verbs that can help (e.g. suffocate);",7 Error Analysis,[0],[0]
"For sun-heat-water, because the majority of the actions in the data are limited to solid objects, the models tend to predict implausible for whenever a gas/liquid appears as the object.
Highly-specific attributes (68%).",7 Error Analysis,[0],[0]
“long-tailed” physical attributes which are absent from our feature set are required.,7 Error Analysis,[0],[0]
"To exemplify a few:7
• edibility (21%).",7 Error Analysis,[0],[0]
"*-fry-egg (plausible) and *-fry-cup (implausible) are hard to distinguish because egg and cup are similar in SIZE/WEIGHT/..., however introducing large free-text data to help learn edibility misguides our model to mind selectional preference, causing mislabeling of other events.",7 Error Analysis,[0],[0]
• natural vs. artificial (18%).,7 Error Analysis,[0],[0]
"Turkers of-
ten think creating natural objects like moon or mountain is implausible but creating an equally big (but artificial) object like skyscraper is plausible.",7 Error Analysis,[0],[0]
• hollow objects (15%).,7 Error Analysis,[0],[0]
"plane-contain-shell
and purse-contain-scissors are plausible, but the hollow-object-can-contain-things attribute is failed to be captured.",7 Error Analysis,[0],[0]
• forefoot dexterity (5%).,7 Error Analysis,[0],[0]
"horse-hug-man is
implausible but bear-hug-man is plausible; For *-snatch-watch, girl is a plausible subject, but not pig.",7 Error Analysis,[0],[0]
"Obviously the dexterity of the forefoot of the agent matters here.
",7 Error Analysis,[0],[0]
"The analysis shows that the task and the dataset highlights the necessity for more sophisticated knowledge featurization and cleverer learning techniques (e.g. features from computer vision, propagation methods with stronger capacity to generalize) to reduce the cost of manual annotation.",7 Error Analysis,[0],[0]
7Percentages calculated with the 68% as the denominator.,7 Error Analysis,[0],[0]
Full list in supplementary material.,7 Error Analysis,[0],[0]
"We present the novel task of semantic plausibility, which forms the foundation of various interesting and complex NLP tasks in event semantics (Bowman et al., 2016; Mostafazadeh et al., 2016; Li and Jurafsky, 2017).",8 Conclusion,[0],[0]
"We collected a high-quality dedicated dataset, showed empirically that the conventional, distribution data only model fails on the task, and that clever world knowledge injection can help substantially with little annotation cost, which lends initial empirical support for the scalability of our approach in practical applications, i.e. labeling little but propagating well approximates performance with full annotation.",8 Conclusion,[0],[0]
"Granted that annotation-based injection method does not cover the full spectrum of leverageable world knowledge information (alternative/complementary sources being images and videos, e.g. Bagherinezhad et al. 2016), it is indeed irreplaceable in some cases (e.g. features such as WEIGHT or RIGIDITY are not easily learnable through visual modality), and in other cases presents a low-cost and effective option.",8 Conclusion,[0],[0]
"Finally, we also discovered the limitation of existing methods through a detailed error analysis, and thereby invite cross-area effort (e.g. multimodal knowledge features) in the future exploration in automated methods for semantic plausibility learning.",8 Conclusion,[0],[0]
This research was supported by NSF grant IIS 1523637.,Acknowledgments,[0],[0]
"Further, this material is based on research sponsored by DARPA under agreement number FA8750-18- 2-0017.",Acknowledgments,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon.,Acknowledgments,[0],[0]
We acknowledge the Texas Advanced Computing Center for providing grid resources that contributed to these results.,Acknowledgments,[0],[0]
We would also like to thank our reviewers for their insightful comments.,Acknowledgments,[0],[0]
"Distributional data tells us that a man can swallow candy, but not that a man can swallow a paintball, since this is never attested.",abstractText,[0],[0]
However both are physically plausible events.,abstractText,[0],[0]
This paper introduces the task of semantic plausibility: recognizing plausible but possibly novel events.,abstractText,[0],[0]
We present a new crowdsourced dataset of semantic plausibility judgments of single events such as man swallow paintball.,abstractText,[0],[0]
"Simple models based on distributional representations perform poorly on this task, despite doing well on selection preference, but injecting manually elicited knowledge about entity properties provides a substantial performance boost.",abstractText,[0],[0]
Our error analysis shows that our new dataset is a great testbed for semantic plausibility models: more sophisticated knowledge representation and propagation could address many of the remaining errors.,abstractText,[0],[0]
Modeling Semantic Plausibility by Injecting World Knowledge,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 688–697 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1064",text,[0],[0]
"Recently the sequence to sequence model (seq2seq) in neural machine translation (NMT) has achieved certain success over the state-ofthe-art of statistical machine translation (SMT)
∗Work done at Huawei Noah’s Ark Lab, HongKong.
on various language pairs (Bahdanau et al., 2015; Jean et al., 2015; Luong et al., 2015; Luong and Manning, 2015).",1 Introduction,[0],[0]
"However, Shi et al. (2016) show that the seq2seq model still fails to capture a lot of deep structural details, even though it is capable of learning certain implicit source syntax from sentence-aligned parallel corpus.",1 Introduction,[0],[0]
"Moreover, it requires an additional parsing-task-specific training mechanism to recover the hidden syntax in NMT.",1 Introduction,[0],[0]
"As a result, in the absence of explicit linguistic knowledge, the seq2seq model in NMT tends to produce translations that fail to well respect syntax.",1 Introduction,[0],[0]
"In this paper, we show that syntax can be well exploited in NMT explicitly by taking advantage of source-side syntax to improve the translation accuracy.
",1 Introduction,[0],[0]
"In principle, syntax is a promising avenue for translation modeling.",1 Introduction,[0],[0]
"This has been verified by tremendous encouraging studies on syntaxbased SMT that substantially improves translation by integrating various kinds of syntactic knowledge (Liu et al., 2006; Marton and Resnik, 2008;
688
Shen et al., 2008; Li et al., 2013).",1 Introduction,[0],[0]
"While it is yet to be seen how syntax can benefit NMT effectively, we find that translations of NMT sometimes fail to well respect source syntax.",1 Introduction,[0],[0]
Figure 1 (a) shows a Chinese-to-English translation example of NMT.,1 Introduction,[0],[0]
"In this example, the NMT seq2seq model incorrectly translates the Chinese noun phrase (i.e., 新 生/xinsheng 银行/yinhang) into a discontinuous phrase in English (i.e., new ... bank) due to the failure of capturing the internal syntactic structure in the input Chinese sentence.",1 Introduction,[0],[0]
"Statistics on our development set show that one forth of Chinese noun phrases are translated into discontinuous phrases in English, indicating the substantial disrespect of syntax in NMT",1 Introduction,[0],[0]
"translation.1 Figure 1 (b) shows another example with over translation, where the noun phrase 两/liang 个/ge 女孩/nvhai is translated twice in English.",1 Introduction,[0],[0]
"Similar to discontinuous translation, over translation usually happens along with the disrespect of syntax which results in the repeated translation of the same source words in multiple positions of the target sentence.
",1 Introduction,[0],[0]
"In this paper we are not aiming at solving any particular issue, either the discontinuous translation or the over translation.",1 Introduction,[0],[0]
"Alternatively, we address how to incorporate explicitly the source syntax to improve the NMT translation accuracy with the expectation of alleviating the issues above in general.",1 Introduction,[0],[0]
"Specifically, rather than directly assigning each source word with manually designed syntactic labels, as Sennrich and Haddow (2016) do, we linearize a phrase parse tree into a structural label sequence and let the model automatically learn useful syntactic information.",1 Introduction,[0],[0]
"On the basis, we systematically propose and compare several different approaches to incorporating the label sequence into the seq2seq NMT model.",1 Introduction,[0],[0]
Experimentation on Chinese-to-English translation demonstrates that all proposed approaches are able to improve the translation accuracy.,1 Introduction,[0],[0]
"As a background and a baseline, in this section, we briefly describe the NMT model with an attention mechanism by Bahdanau et al. (2015), which mainly consists of an encoder and a decoder, as shown in Figure 2.
",2 Attention-based NMT,[0],[0]
"Encoder The encoding of a source sentence is for1Manually examining 200 random such discontinuously translated noun phrases, we find that 90% of them should be continuously translated according to the reference translation.
mulated using a pair of neural networks, i.e., two recurrent neural networks (denoted bi-RNN): one reads an input sequence x =",2 Attention-based NMT,[0],[0]
"(x1, ..., xm) from left to right and outputs a forward sequence of hidden states ( −→ h1, ..., −→ hm), while the other operates from right to left and outputs a backward sequence ( ←− h1, ..., ←− hm).",2 Attention-based NMT,[0],[0]
Each source word xj is represented as hj (also referred to as word annotation vector): the concatenation of hidden states −→ hj and ←− hj .,2 Attention-based NMT,[0],[0]
"Such bi-RNN encodes not only the word itself but also its left and right context, which can provide important evidence for its translation.
",2 Attention-based NMT,[0],[0]
"Decoder The decoder is also an RNN that predicts a target sequence y = (y1, ..., yn).",2 Attention-based NMT,[0],[0]
"Each target word yi is predicted via a multi-layer perceptron (MLP) component which is based on a recurrent hidden state si, the previous predicted word yi−1, and a source-side context vector ci.",2 Attention-based NMT,[0],[0]
"Here, ci is calculated as a weighted sum over source annotation vectors (h1, ..., hm).",2 Attention-based NMT,[0],[0]
The weight vector αi ∈,2 Attention-based NMT,[0],[0]
"Rm over source annotation vectors is obtained by an attention model, which captures the correspondences between the source and the target languages.",2 Attention-based NMT,[0],[0]
The attention weight αij is computed based on the previous recurrent hidden state si−1 and source annotation vector hj .,2 Attention-based NMT,[0],[0]
"The conventional NMT models treat a sentence as a sequence of words and ignore external knowledge, failing to effectively capture various kinds of inherent structure of the sentence.",3 NMT with Source Syntax,[0],[0]
"To leverage external knowledge, specifically the syntax in the source side, we focus on the parse tree of a sentence and propose three different NMT models that explicitly consider the syntactic structure into encoding.",3 NMT with Source Syntax,[0],[0]
"Our purpose is to inform the NMT model the structural context of each word in its corresponding parse tree with the goal that the learned annotation vectors (h1, ..., hm) encode not
I love dogs
only the information of words and their surroundings, but also structural context in the parse tree.",3 NMT with Source Syntax,[0],[0]
"In the rest of this section, we use English sentences as examples to explain our methods.",3 NMT with Source Syntax,[0],[0]
"To obtain the structural context of a word in its parse tree, ideally the model should not only capture and remember the whole parse tree structure, but also discriminate the contexts of any two different words.",3.1 Syntax Representation,[0],[0]
"However, considering the lack of efficient way to directly model structural information, an alternative way is to linearize the phrase parse tree into a sequence of structural labels and learn the structural context through the sequence.",3.1 Syntax Representation,[0],[0]
"For example, Figure 3(c) shows the structural label sequence of Figure 3(b) in a simple way following a depth-first traversal order.",3.1 Syntax Representation,[0],[0]
"Note that linearizing a parse tree in a depth-first traversal order into a sequence of structural labels has also been widely adopted in recent advances in neural syntactic parsing (Vinyals et al., 2015; Choe and Charniak, 2016), suggesting that the linearized sequence can be viewed as an alternative to its tree structure.2
2We have also tried to include the ending brackets in the structural label sequence, as what (Vinyals et al., 2015; Choe
hwj and
←−−
hwj are the forward and
backward hidden states for word wj ,
−→
hli and
←−
hli are for structural label li, ewj is the word embedding for word wj , and ⊕ is for concatenation operator.
",3.1 Syntax Representation,[0],[0]
There is no doubt that the structural label sequence is much longer than its word sequence.,3.1 Syntax Representation,[0],[0]
"In order to obtain the structural label annotation vector for wi in word sequence, we simply look for wi’s part-of-speech (POS) tag in the label sequence and view the tag’s annotation vector as wi’s label annotation vector.",3.1 Syntax Representation,[0],[0]
This is because wi’s POS tag location can also represent wi’s location in the parse tree.,3.1 Syntax Representation,[0],[0]
"For example, in Figure 3, word w1 in (a) maps to l3 in (c) since l3 is the POS tag of w1.",3.1 Syntax Representation,[0],[0]
"Likewise, w2 maps to l5 and w3 to l7.",3.1 Syntax Representation,[0],[0]
"That is to say, we use l3’s learned annotation vector as w1’s label annotation vector.
and Charniak, 2016) do.",3.1 Syntax Representation,[0],[0]
"However, the performance gap is very small by adding the ending brackets or not.",3.1 Syntax Representation,[0],[0]
"In the next, we first propose two different encoders to augment word annotation vector with its corresponding label annotation vector, each of which consists of two RNNs 3: in one encoder, the two RNNs work independently (i.e., Parallel RNN Encoder) while in another encoder the two RNNs work in a hierarchical way (i.e., Hierarchical RNN Encoder).",3.2 RNN Encoders with Source Syntax,[0],[0]
The difference between the two encoders lies in how the two RNNs interact.,3.2 RNN Encoders with Source Syntax,[0],[0]
"Then, we propose the third encoder with a single RNN, which learns word and label annotation vectors stitchingly (i.e., Mixed RNN Encoder).",3.2 RNN Encoders with Source Syntax,[0],[0]
"Since any of the above three approaches focuses only on the encoder as to generate source annotation vectors along with structural information, we keep the rest part of the NMT models unchanged.
",3.2 RNN Encoders with Source Syntax,[0],[0]
"Parallel RNN Encoder Figure 4 (a) illustrates our Parallel RNN encoder, which includes two parallel RNNs: i.e., a word RNN and a structural label RNN.",3.2 RNN Encoders with Source Syntax,[0],[0]
"On the one hand, the word RNN, as in conventional NMT models, takes a word sequence as input and output a word annotation vector for each word.",3.2 RNN Encoders with Source Syntax,[0],[0]
"On the other hand, the structural label RNN takes the structural label sequence of the word sequence as input and obtains a label annotation vector for each label.",3.2 RNN Encoders with Source Syntax,[0],[0]
"Besides, we concatenate each word’s word annotation vector and its POS tag’s label annotation vector as the final annotation vector for the word.",3.2 RNN Encoders with Source Syntax,[0],[0]
"For example, the final annotation vector for word love in Figure 4 (a) is [ −−→ hw2; ←−− hw2; −→ hl5; ←− hl5], where the first two subitems [ −−→ hw2; ←−− hw2] are the word annotation vector and the rest two subitems",3.2 RNN Encoders with Source Syntax,[0],[0]
"[ −→ hl5; ←− hl5] are its POS tag VBP’s label annotation vector.
",3.2 RNN Encoders with Source Syntax,[0],[0]
"Hierarchical RNN Encoder Partially inspired by the model architecture of GNMT (Wu et al., 2016) which consists of multiple layers of LSTM RNNs, we propose a two-layer model architecture in which the lower layer is the structural label RNN while the upper layer is the word RNN, as shown in Figure 4 (b).",3.2 RNN Encoders with Source Syntax,[0],[0]
"We put the word RNN in the upper layer because each item in the word sequence can map into an item in the structural label sequence, while this does not hold if the order of the two RNNs is reversed.",3.2 RNN Encoders with Source Syntax,[0],[0]
"As shown in Figure 4 (b), for example, the POS tag VBP’s label annotation vector [ −→ hl5, ←− hl5] is concatenated with word
3Hereafter, we simplify bi-RNN as RNN.
",3.2 RNN Encoders with Source Syntax,[0],[0]
"love’s word embedding ew2 to feed as the input to the word RNN.
",3.2 RNN Encoders with Source Syntax,[0],[0]
Mixed RNN Encoder Figure 5 presents our Mixed RNN encoder.,3.2 RNN Encoders with Source Syntax,[0],[0]
"Similarly, the sequence of input is the linearization of its parse tree (as in Figure 3 (b)) following a depth-first traversal order, but being mixed with both words and structural labels in a stitching way.",3.2 RNN Encoders with Source Syntax,[0],[0]
"It shows that the RNN learns annotation vectors for both the words and the structural labels, though only the annotation vectors of words are further fed to decoding (e.g., ([ −→ h4, ←− h4], [ −→ h7, ←− h7], [ −→ h10, ←− h10])).",3.2 RNN Encoders with Source Syntax,[0],[0]
"Even though the annotation vectors of structural labels are not directly fed forward for decoding, the error signal is back propagated along the word sequence and allows the annotation vectors of structural labels being updated accordingly.",3.2 RNN Encoders with Source Syntax,[0],[0]
"Though all the three encoders model both word sequence and structural label sequence, the differences lie in their respective model architecture with respect to the degree of coupling the two sequences:
• In the Parallel RNN encoder, the word RNN and structural label RNN work in a parallel way.",3.3 Comparison of RNN Encoders with Source Syntax,[0],[0]
"That is to say, the error signal back propagated from the word sequence would not affect the structural label RNN, and vice versa.",3.3 Comparison of RNN Encoders with Source Syntax,[0],[0]
"In contrast, in the Hierarchical RNN encoder, the error signal back propagated from the word sequence has a direct impact on the structural label annotation vectors, and thus on the structural label embeddings.",3.3 Comparison of RNN Encoders with Source Syntax,[0],[0]
"Finally, the Mixed RNN encoder ties the structural label sequence and word sequence together in the closest way.",3.3 Comparison of RNN Encoders with Source Syntax,[0],[0]
"Therefore, the degrees of coupling the word and structural
label sequences in these three encoders are like this: Mixed RNN encoder > Hierarchical RNN encoder >",3.3 Comparison of RNN Encoders with Source Syntax,[0],[0]
"Parallel RNN encoder.
",3.3 Comparison of RNN Encoders with Source Syntax,[0],[0]
• Figure 4 and Figure 5 suggest that the Mixed RNN encoder is the simplest.,3.3 Comparison of RNN Encoders with Source Syntax,[0],[0]
"Moreover, comparing to conventional NMT encoders, the difference lies only in the length of the input sequence.",3.3 Comparison of RNN Encoders with Source Syntax,[0],[0]
Statistics on our training data reveal that the Mixed RNN encoder approximately triples the input sequence length compared to conventional NMT encoders.,3.3 Comparison of RNN Encoders with Source Syntax,[0],[0]
We have presented our approaches to incorporating the source syntax into NMT encoders.,4 Experimentation,[0],[0]
"In this section, we evaluate their effectiveness on Chinese-to-English translation.",4 Experimentation,[0],[0]
"Our training data for the translation task consists of 1.25M sentence pairs extracted from LDC corpora, with 27.9M Chinese words and 34.5M English words respectively.4",4.1 Experimental Settings,[0],[0]
"We choose NIST MT 06 dataset (1664 sentence pairs) as our development set, and NIST MT 02, 03, 04, and 05 datasets (878, 919, 1788 and 1082 sentence pairs, respectively) as our test sets.5",4.1 Experimental Settings,[0],[0]
"To get the source syntax for sentences on the source-side, we parse the Chinese sentences with Berkeley Parser 6 (Petrov and Klein, 2007) trained on Chinese TreeBank 7.0 (Xue et al., 2005).",4.1 Experimental Settings,[0],[0]
"We use the case insensitive 4-gram NIST BLEU score (Papineni et al., 2002) for the translation task.
",4.1 Experimental Settings,[0],[0]
"For efficient training of neural networks, we limit the maximum sentence length on both source and target sides to 50.",4.1 Experimental Settings,[0],[0]
"We also limit both the source and target vocabularies to the most frequent 16K words in Chinese and English, covering approximately 95.8% and 98.2% of the two corpora respectively.",4.1 Experimental Settings,[0],[0]
All the out-of-vocabulary words are mapped to a special token UNK.,4.1 Experimental Settings,[0],[0]
"Besides, the word embedding dimension is 620 and the size of a hidden layer is 1000.",4.1 Experimental Settings,[0],[0]
"All the other settings are the same as in Bahdanau et al.(2015).
",4.1 Experimental Settings,[0],[0]
"4The corpora include LDC2002E18, LDC2003E07, LDC2003E14, Hansards portion of LDC2004T07, LDC2004T08 and LDC2005T06.
5http://www.itl.nist.gov/iad/mig/ tests/mt/
6https://github.com/slavpetrov/ berkeleyparser
The inventory of structural labels includes 16 phrase labels and 32 POS tags.",4.1 Experimental Settings,[0],[0]
"In both our Parallel RNN encoder and Hierarchical RNN encoder, we set the embedding dimension of these labels as 100 and the size of a hidden layer as 100.",4.1 Experimental Settings,[0],[0]
"Besides, the maximum structural label sequence length is set to 100.",4.1 Experimental Settings,[0],[0]
"In our Mixed RNN encoder, since we only have one input sequence, we equally treat the structural labels and words (i.e., a structural label is also initialized with 620 dimension embedding).",4.1 Experimental Settings,[0],[0]
"Compared to the baseline NMT model, the only different setting is that we increase the maximum sentence length on source-side from 50 to 150.
",4.1 Experimental Settings,[0],[0]
"We compare our method with two state-of-theart models of SMT and NMT:
• cdec (Dyer et al., 2010): an open source hierarchical phrase-based SMT system (Chiang, 2007) with default configuration and a 4-gram language model trained on the target portion of the training data.7
• RNNSearch: a re-implementation of the attentional NMT system (Bahdanau et al., 2015) with slight changes taken from dl4mt tutorial.8 For the activation function f of an RNN, RNNSearch uses the gated recurrent unit (GRU) recently proposed by (Cho et al., 2014b).",4.1 Experimental Settings,[0],[0]
"It incorporates dropout (Hinton et al., 2012) on the output layer and improves the attention model by feeding the lastly generated word.",4.1 Experimental Settings,[0],[0]
"We use AdaDelta (Zeiler, 2012) to optimize model parameters in training with the mini-batch size of 80.",4.1 Experimental Settings,[0],[0]
"For translation, a beam search with size 10 is employed.",4.1 Experimental Settings,[0],[0]
Table 1 shows the translation performances measured in BLEU score.,4.2 Experiment Results,[0],[0]
"Clearly, all the proposed NMT models with source syntax improve the translation accuracy over all test sets, although there exist considerable differences among different variants.
",4.2 Experiment Results,[0],[0]
Parameters The three proposed models introduce new parameters in different ways.,4.2 Experiment Results,[0],[0]
"As a baseline model, RNNSearch has 60.6M parameters.",4.2 Experiment Results,[0],[0]
"Due to the infrastructure similarity, the Parallel RNN system and the Hierarchical RNN system introduce
7https://github.com/redpony/cdec 8https://github.com/nyu-dl/
dl4mt-tutorial
the similar size of additional parameters, resulting from the RNN model for structural label sequences (about 0.1M parameters) and catering either the augmented annotation vectors (as shown in Figure 4 (a)) or the augmented word embeddings (as shown in Figure 4 (b))",4.2 Experiment Results,[0],[0]
(the remain parameters).,4.2 Experiment Results,[0],[0]
"It is not surprising that the Mixed RNN system does not require any additional parameters since though the input sequence becomes longer, we keep the vocabulary size unchanged, resulting in no additional parameters.
",4.2 Experiment Results,[0],[0]
Speed Introducing the source syntax slightly slows down the training speed.,4.2 Experiment Results,[0],[0]
"When running on a single GPU GeForce GTX 1080, the baseline model speeds 153 minutes per epoch with 14K updates while the proposed structural label RNNs in both Parallel RNN and Hierarchical RNN systems only increases the training time by about 6% (thanks to the small size of structural label embeddings and annotation vectors), and the Mixed RNN system spends 26% more training time to cater the triple sized input sequence.
",4.2 Experiment Results,[0],[0]
"Comparison with the baseline NMT model (RNNSearch) While all the three proposed NMT models outperform RNNSearch, the Parallel RNN system and the Hierarchical RNN system achieve similar accuracy (e.g., 36.6 v.s. 36.7).",4.2 Experiment Results,[0],[0]
"Besides, the Mixed RNN system achieves the best accuracy overall test sets with the only exception of NIST MT 02.",4.2 Experiment Results,[0],[0]
"Over all test sets, it outperforms RNNSearch by 1.4 BLEU points and outperforms the other two improved NMT models by 0.3∼0.4 BLEU points, suggesting the benefits of high degree of coupling the word sequence and the structural label sequence.",4.2 Experiment Results,[0],[0]
"This is very encouraging since the Mixed RNN encoder is the simplest, without introducing new parameters and with only slight additional training time.
",4.2 Experiment Results,[0],[0]
Comparison with the SMT model (cdec),4.2 Experiment Results,[0],[0]
Table 1 also shows that all NMT systems outperform the SMT system.,4.2 Experiment Results,[0],[0]
"This is very consistent with other studies on Chinese-to-English translation (Mi et al., 2016; Tu et al., 2017b; Wang et al., 2017).",4.2 Experiment Results,[0],[0]
"As the proposed Mixed RNN system achieves the best performance, we further look at the RNNSearch system and the Mixed RNN system to explore more on how syntactic information helps in translation.",5 Analysis,[0],[0]
"Following Bahdanau et al. (2015), we group sentences of similar lengths together and compute BLEU scores.",5.1 Effects on Long Sentences,[0],[0]
Figure 6 presents the BLEU scores over different lengths of input sentences.,5.1 Effects on Long Sentences,[0],[0]
It shows that Mixed RNN system outperforms RNNSearch over sentences with all different lengths.,5.1 Effects on Long Sentences,[0],[0]
"It also shows that the performance drops substantially
when the length of input sentences increases.",5.1 Effects on Long Sentences,[0],[0]
"This performance trend over the length is consistent with the findings in (Cho et al., 2014a; Tu et al., 2016, 2017a).",5.1 Effects on Long Sentences,[0],[0]
"We also observe that the NMT systems perform surprisingly bad on sentences over 50 in length, especially compared to the performance of SMT system (i.e., cdec).",5.1 Effects on Long Sentences,[0],[0]
"We think that the bad behavior of NMT systems towards long sentences (e.g., length of 50) is due to the following two reasons: (1) the maximum source sentence length limit is set as 50 in training, 9 making the learned models not ready to translate sentences over the maximum length limit; (2) NMT systems tend to stop early for long input sentences.",5.1 Effects on Long Sentences,[0],[0]
"Due to the capability of carrying syntactic information in source annotation vectors, we conjecture that our model with source syntax is also beneficial for alignment.",5.2 Analysis on Word Alignment,[0],[0]
"To test this hypothesis, we carry out experiments of the word alignment task on the evaluation dataset from Liu and Sun (2015), which contains 900 manually aligned Chinese-English sentence pairs.",5.2 Analysis on Word Alignment,[0],[0]
"We force the decoder to output reference translations, as to get automatic alignments between input sentences and their reference translations.",5.2 Analysis on Word Alignment,[0],[0]
"To evaluate alignment performance, we report the alignment error rate (AER) (Och and Ney, 2003) in Table 2.
",5.2 Analysis on Word Alignment,[0],[0]
Table 2 shows that source syntax information improves the attention model as expected by maintaining an annotation vector summarizing structural information on each source word.,5.2 Analysis on Word Alignment,[0],[0]
The above subsection examines the alignment performance at the word level.,5.3 Analysis on Phrase Alignment,[0],[0]
"In this subsection, we turn to phrase alignment analysis by moving from word unit to phrase unit.",5.3 Analysis on Phrase Alignment,[0],[0]
"Given a source phrase XP, we use word alignments to examine if the phrase is translated continuously (Cont.), or dis-
9Though the maximum source length limit in Mixed RNN system is set to 150, it approximately contains 50 words in maximum.
continuously (Dis.), or if it is not translated at all (Un.).
",5.3 Analysis on Phrase Alignment,[0],[0]
"There are some phrases, such as noun phrases (NPs), prepositional phrases (PPs) that we usually expect to have a continuous translation.",5.3 Analysis on Phrase Alignment,[0],[0]
"With respect to several such types of phrases, Table 3 shows how these phrases are translated.",5.3 Analysis on Phrase Alignment,[0],[0]
"From the table, we see that translations of RNNSearch system do not respect source syntax very well.",5.3 Analysis on Phrase Alignment,[0],[0]
"For example, in RNNSearch translations, 57.3%, 33.6%, and 9.1% of PPs are translated continuously, discontinuously, and untranslated, respectively.",5.3 Analysis on Phrase Alignment,[0],[0]
"Fortunately, our Mixed RNN system is able to have more continuous translation for those phrases.",5.3 Analysis on Phrase Alignment,[0],[0]
Table 3 also suggests that there is still much room for NMT to show more respect to syntax.,5.3 Analysis on Phrase Alignment,[0],[0]
"To estimate the over translation generated by NMT, we propose ratio of over translation (ROT):
ROT =
∑ wi t(wi)
|w| (1)
where |w| is the number of words in consideration, t(wi) is the times of over translation for word wi.",5.4 Analysis on Over Translation,[0],[0]
Given a word w and its translation e = e1e2 . . .,5.4 Analysis on Over Translation,[0],[0]
"en, we have:
t(w) =",5.4 Analysis on Over Translation,[0],[0]
"|e| − |uniq(e)| (2)
where |e| is the number of words in w’s translation e, while |uniq(e)| is the number of unique words in e.",5.4 Analysis on Over Translation,[0],[0]
"For example, if a source word 香
港/xiangkang is translated as hong kong hong kong, we say it being over translated 2 times.
",5.4 Analysis on Over Translation,[0],[0]
Table 4 presents ROT grouped by some typical POS tags.,5.4 Analysis on Over Translation,[0],[0]
It is not surprising that RNNSearch system has high ROT with respect to POS tags of NR (proper noun) and CD (cardinal number): this is due to the fact that the two POS tags include high percentage of unknown words which tend to be translated multiple times in translation.,5.4 Analysis on Over Translation,[0],[0]
Words of DT (determiner) are another source of over translation since they are usually translated to multiple the in English.,5.4 Analysis on Over Translation,[0],[0]
"It also shows that by introducing source syntax, Mixed RNN system alleviates the over translation issue by 18%: ROT drops from 5.5% to 4.5%.",5.4 Analysis on Over Translation,[0],[0]
We analyze the translation of source-side rare words that are mapped to a special token UNK.,5.5 Analysis on Rare Word Translation,[0],[0]
"Given a rare word w, we examine if it is translated into a non-UNK word (non-UNK), UNK (UNK), or if it is not translated at all (Un.).
",5.5 Analysis on Rare Word Translation,[0],[0]
Table 5 shows how source-side rare words are translated.,5.5 Analysis on Rare Word Translation,[0],[0]
The four POS tags listed in the table account for about 90% of all rare words in the test sets.,5.5 Analysis on Rare Word Translation,[0],[0]
It shows that in Mixed RNN system is more likely to translate source-side rare words into UNK on the target side.,5.5 Analysis on Rare Word Translation,[0],[0]
This is reasonable since the source side rare words tends to be translated into rare words in the target side.,5.5 Analysis on Rare Word Translation,[0],[0]
"Moreover, it is hard to obtain its correct non-UNK translation when a source-side rare word is replaced as UNK.
",5.5 Analysis on Rare Word Translation,[0],[0]
Note that our approach is compatible with with approaches of open vocabulary.,5.5 Analysis on Rare Word Translation,[0],[0]
"Taking the sub-
word approach (Sennrich et al., 2016) as an example, for a word on the source side which is divided into several subword units, we can synthesize subPOS nodes that cover these units.",5.5 Analysis on Rare Word Translation,[0],[0]
"For example, if misunderstand/VB is divided into units of mis and understand, we construct substructure (VB (VB-F mis) (VB-I understand)).",5.5 Analysis on Rare Word Translation,[0],[0]
"While there has been substantial work on linguistically motivated SMT, approaches that leverage syntax for NMT start to shed light very recently.",6 Related Work,[0],[0]
"Generally speaking, NMT can provide a flexible mechanism for adding linguistic knowledge, thanks to its strong capability of automatically learning feature representations.
",6 Related Work,[0],[0]
"Eriguchi et al. (2016) propose a tree-tosequence model that learns annotation vectors not only for terminal words, but also for non-terminal nodes.",6 Related Work,[0],[0]
They also allow the attention model to align target words to non-terminal nodes.,6 Related Work,[0],[0]
Our approach is similar to theirs by using source-side phrase parse tree.,6 Related Work,[0],[0]
"However, our Mixed RNN system, for example, incorporates syntax information by learning annotation vectors of syntactic labels and words stitchingly, but is still a sequenceto-sequence model, with no extra parameters and with less increased training time.
",6 Related Work,[0],[0]
Sennrich and Haddow (2016) define a few linguistically motivated features that are attached to each individual words.,6 Related Work,[0],[0]
"Their features include lemmas, subword tags, POS tags, dependency labels, etc.",6 Related Work,[0],[0]
"They concatenate feature embeddings with word embeddings and feed the concatenated em-
beddings into the NMT encoder.",6 Related Work,[0],[0]
"On the contrast, we do not specify any feature, but let the model implicitly learn useful information from the structural label sequence.
",6 Related Work,[0],[0]
Shi et al. (2016) design a few experiments to investigate if the NMT system without external linguistic input is capable of learning syntactic information on the source-side as a by-product of training.,6 Related Work,[0],[0]
"However, their work is not focusing on improving NMT with linguistic input.",6 Related Work,[0],[0]
"Moreover, we analyze what syntax is disrespected in translation from several new perspectives.
",6 Related Work,[0],[0]
Garcı́a-Martı́nez et al. (2016) generalize NMT outputs as lemmas and morphological factors in order to alleviate the issues of large vocabulary and out-of-vocabulary word translation.,6 Related Work,[0],[0]
The lemmas and corresponding factors are then used to generate final words in target language.,6 Related Work,[0],[0]
"Though they use linguistic input on the target side, they are limited to the word level features.",6 Related Work,[0],[0]
"Phrase level, or even sentence level linguistic features are harder to obtain for a generation task such as machine translation, since this would require incremental parsing of the hypotheses at test time.",6 Related Work,[0],[0]
"In this paper, we have investigated whether and how source syntax can explicitly help NMT to improve its translation accuracy.
",7 Conclusion,[0],[0]
"To obtain syntactic knowledge, we linearize a parse tree into a structural label sequence and let the model automatically learn useful information through it.",7 Conclusion,[0],[0]
"Specifically, we have described three different models to capture the syntax knowledge, i.e., Parallel RNN, Hierarchical RNN, and Mixed RNN.",7 Conclusion,[0],[0]
Experimentation on Chinese-to-English translation shows that all proposed models yield improvements over a state-ofthe-art baseline NMT system.,7 Conclusion,[0],[0]
"It is also interesting to note that the simplest model (i.e., Mixed RNN) achieves the best performance, resulting in obtaining significant improvements of 1.4 BLEU points on NIST MT 02 to 05.
",7 Conclusion,[0],[0]
"In this paper, we have also analyzed the translation behavior of our improved system against the state-of-the-art NMT baseline system from several perspectives.",7 Conclusion,[0],[0]
Our analysis shows that there is still much room for NMT translation to be consistent with source syntax.,7 Conclusion,[0],[0]
"In our future work, we expect several developments that will shed more light on utilizing source syntax, e.g., designing novel syn-
tactic features (e.g., features showing the syntactic role that a word is playing) for NMT, and employing the source syntax to constrain and guild the attention models.",7 Conclusion,[0],[0]
"The authors would like to thank three anonymous reviewers for providing helpful comments, and also acknowledge Xing Wang, Xiangyu Duan, Zhengxian Gong for useful discussions.",Acknowledgments,[0],[0]
"This work was supported by National Natural Science Foundation of China (Grant No. 61525205, 61331011, 61401295).",Acknowledgments,[0],[0]
"Even though a linguistics-free sequence to sequence model in neural machine translation (NMT) has certain capability of implicitly learning syntactic information of source sentences, this paper shows that source syntax can be explicitly incorporated into NMT effectively to provide further improvements.",abstractText,[0],[0]
"Specifically, we linearize parse trees of source sentences to obtain structural label sequences.",abstractText,[0],[0]
"On the basis, we propose three different sorts of encoders to incorporate source syntax into NMT: 1) Parallel RNN encoder that learns word and label annotation vectors parallelly; 2) Hierarchical RNN encoder that learns word and label annotation vectors in a two-level hierarchy; and 3) Mixed RNN encoder that stitchingly learns word and label annotation vectors over sequences where words and labels are mixed.",abstractText,[0],[0]
Experimentation on Chinese-to-English translation demonstrates that all the three proposed syntactic encoders are able to improve translation accuracy.,abstractText,[0],[0]
"It is interesting to note that the simplest RNN encoder, i.e., Mixed RNN encoder yields the best performance with an significant improvement of 1.4 BLEU points.",abstractText,[0],[0]
"Moreover, an in-depth analysis from several perspectives is provided to reveal how source syntax benefits NMT.",abstractText,[0],[0]
Modeling Source Syntax for Neural Machine Translation,title,[0],[0]
"In many real-world domains, data acquisition is costly.",1. Introduction,[0],[0]
"For instance, magnetic resonance imaging (MRI) requires scan times proportional to the number of measurements, which can be significant for patients (Lustig et al., 2008).",1. Introduction,[0],[0]
"Geophysical applications like oil drilling require expensive simulation of seismic waves (Qaisar et al., 2013).",1. Introduction,[0],[0]
"Such appli-
1Computer Science Department, Stanford University, CA, USA.",1. Introduction,[0],[0]
"Correspondence to: Manik Dhar <dmanik@cs.stanford.edu>, Aditya Grover",1. Introduction,[0],[0]
"<adityag@cs.stanford.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
cations, among many others, can benefit significantly from compressed sensing techniques to acquire signals efficiently (Candès & Tao, 2005; Donoho, 2006; Candès et al., 2006).
",1. Introduction,[0],[0]
"In compressed sensing, we wish to acquire an n-dimensional signal x ∈ Rn using only m n measurements linear in x.",1. Introduction,[0],[0]
"The measurements could potentially be noisy, but even in the absence of any noise we need to impose additional structure on the signal to guarantee unique recovery.",1. Introduction,[0],[0]
"Classical results on compressed sensing impose structure by assuming the underlying signal to be approximately l-sparse in some known basis, i.e., the l-largest entries dominate the rest.",1. Introduction,[0],[0]
"For instance, images and audio signals are typically sparse in the wavelet and Fourier basis respectively (Mallat, 2008).",1. Introduction,[0],[0]
"If the matrix of linear vectors relating the signal and measurements satisfies certain mild conditions, then one can provably recover x with only m = O(l log nl ) measurements using LASSO (Tibshirani, 1996; Candès & Tao, 2005; Donoho, 2006; Candès et al., 2006; Bickel et al., 2009).
",1. Introduction,[0],[0]
"Alternatively, structural assumptions on the signals being sensed can be learned from data, e.g., using a dataset of typical signals (Baraniuk et al., 2010; Peyre, 2010; Chen et al., 2010; Yu & Sapiro, 2011).",1. Introduction,[0],[0]
"Particularly relevant to this work, Bora et al. (2017) proposed an approach where structure is provided by a deep generative model learned from data.",1. Introduction,[0],[0]
"Specifically, the underlying signal x being sensed is assumed to be close to the range of a deterministic function expressed by a pretrained, latent variable modelG : Rk → Rn such that x ≈ G(z) where z ∈ Rk denote the latent variables.",1. Introduction,[0],[0]
"Consequently, the signal x is recovered by optimizing for a latent vector z that minimizes the `2 distance between the measurements corresponding to G(z) and the actual ones.",1. Introduction,[0],[0]
"Even though the objective being optimized in this case is non-convex, empirical results suggest that the reconstruction error decreases much faster than LASSO-based recovery as we increase the number of measurements.
",1. Introduction,[0],[0]
"A limitation of the above approach is that the recovered signal is constrained to be in the range of the generator function G. Hence, if the true signal being sensed is not in the range of G, the algorithm cannot drive the reconstruction error to zero even when m ≥ n",1. Introduction,[0],[0]
(even if we ignore error due to measurement noise and non-convex optimization).,1. Introduction,[0],[0]
"This is also observed empirically, as the reconstruction error of generative model-based recovery saturates as we keep
increasing the number of measurements m. On the other hand, LASSO-based recovery continues to shrink the error with increasing number of measurements, eventually outperforming the generative model-based recovery.
",1. Introduction,[0],[0]
"To overcome this limitation, we propose a framework that allows recovery of signals with sparse deviations from the set defined by the range of the generator function.",1. Introduction,[0],[0]
"The recovered signals have the general form of G(ẑ) + ν̂, where ν̂ ∈ Rn is a sparse vector.",1. Introduction,[0],[0]
This allows the recovery algorithm to consider signals away from the range of the generator function.,1. Introduction,[0],[0]
"Similar to LASSO, we relax the hardness in optimizing for sparse vectors by minimizing the `1 norm of the deviations.",1. Introduction,[0],[0]
"Unlike LASSO-based recovery, we can exploit the rich structure imposed by a (deep) generative model (at the expense of solving a hard optimization problem if G is non-convex).",1. Introduction,[0],[0]
"In fact, we show that LASSO-based recovery is a special case of our framework if the generator function G maps all z to the origin.",1. Introduction,[0],[0]
"Unlike generative model-based recovery, the signals recovered by our algorithm are not constrained to be in the range of the generator function.
",1. Introduction,[0],[0]
"Our proposed algorithm, referred to as Sparse-Gen, has desirable theoretical properties and empirical performance.",1. Introduction,[0],[0]
"Theoretically, we derive upper bounds on the reconstruction error for an optimal decoder with respect to the proposed model and show that this error vanishes with m = n measurements.",1. Introduction,[0],[0]
"We confirm our theory empirically, wherein we find that recovery using Sparse-Gen with variational autoencoders (Kingma & Welling, 2014) as the underlying generative model outperforms both LASSO-based and generative model-based recovery in terms of the reconstruction errors for the same number of measurements for MNIST and Omniglot datasets.",1. Introduction,[0],[0]
"Additionally, we observe significant improvements in the more practical and novel task of transfer compressed sensing where a generative model on a data-rich, source domain provides a prior for sensing a data-scarce, target domain.",1. Introduction,[0],[0]
"In this section, we review the necessary background and prior work in modeling domain specific structure in compressed sensing.",2. Preliminaries,[0],[0]
"We are interested in solving the following system of equations,
y = Ax (1)
where x ∈ Rn is the signal of interest being sensed through measurements y ∈ Rm, and A ∈ Rm×n is a measurement matrix.",2. Preliminaries,[0],[0]
"For efficient acquisition of signals, we will design measurement matrices such that m n. However, the system is under-determined whenever rank(A) <",2. Preliminaries,[0],[0]
"n. Hence, unique recovery requires additional assumptions on x. We now discuss two ways to model the structure of x.
Sparsity.",2. Preliminaries,[0],[0]
Sparsity in a well-chosen basis is natural in many domains.,2. Preliminaries,[0],[0]
"For instance, natural images are sparse in the wavelet basis whereas audio signals exhibit sparsity in the Fourier basis (Mallat, 2008).",2. Preliminaries,[0],[0]
"Hence, it is natural to assume the domain of signals x we are interested in recovering is
Sl(0) = {x : ‖x− 0‖0 ≤",2. Preliminaries,[0],[0]
l}.,2. Preliminaries,[0],[0]
"(2)
This is the set of l-sparse vectors with the `0 distance measured from the origin.",2. Preliminaries,[0],[0]
"Such assumptions dominate the prior literature in compressed sensing and can be further relaxed to recover approximately sparse signals (Candès & Tao, 2005; Donoho, 2006; Candès et al., 2006).
",2. Preliminaries,[0],[0]
Latent variable generative models.,2. Preliminaries,[0],[0]
"A latent variable model specifies a joint distribution Pθ(x, z) over the observed data x (e.g., images) and a set of latent variables z ∈",2. Preliminaries,[0],[0]
"Rk (e.g., features).",2. Preliminaries,[0],[0]
"Given a training set of signals {x1, · · · , xM}, we can learn the parameters θ of such a model, e.g., via maximum likelihood.",2. Preliminaries,[0],[0]
"When Pθ(x, z) is parameterized using deep neural networks, such generative models can effectively model complex, high-dimensional signal distributions for modalities such as images and audio (Kingma & Welling, 2014; Goodfellow et al., 2014).
",2. Preliminaries,[0],[0]
"Given a pretrained latent variable generative model with parameters θ, we can associate a generative model function G : Rk → Rn mapping a latent vector z to the mean of the conditional distribution Pθ(x|z).",2. Preliminaries,[0],[0]
"Thereafter, the space of signals that can be recovered with such a model is given by the range of the generator function,
SG = {G(z) : z ∈ Rk}.",2. Preliminaries,[0],[0]
"(3)
Note that the set is defined with respect to the latent vectors z, and we omit the dependence of G on the parameters θ (which are fixed for a pretrained model) for brevity.",2. Preliminaries,[0],[0]
"Signal recovery in compressed sensing algorithm typically involves solving an optimization problem consistent with the modeling assumptions on the domain of the signals being sensed.
",2.1. Recovery algorithms,[0],[0]
Sparse vector recovery using LASSO.,2.1. Recovery algorithms,[0],[0]
"Under the assumptions of sparsity, the signal x can be recovered by solving an `0 minimization problem (Candès & Tao, 2005; Donoho, 2006; Candès et al., 2006).
",2.1. Recovery algorithms,[0],[0]
"min x ‖x‖0
s.t.",2.1. Recovery algorithms,[0],[0]
"Ax = y. (4)
",2.1. Recovery algorithms,[0],[0]
"The objective above is however NP-hard to optimize, and hence, it is standard to consider a convex relaxation,
min x ‖x‖1
s.t.",2.1. Recovery algorithms,[0],[0]
"Ax = y. (5)
",2.1. Recovery algorithms,[0],[0]
"In practice, it is common to solve the Lagrangian of the above problem.",2.1. Recovery algorithms,[0],[0]
We refer to this method as LASSO-based recovery due to similarities of the objective in Eq.,2.1. Recovery algorithms,[0],[0]
"(5) to the LASSO regularization used broadly in machine learning (Tibshirani, 1996).",2.1. Recovery algorithms,[0],[0]
"LASSO-based recovery is the predominant technique for recovering sparse signals since it involves solving a tractable convex optimization problem.
",2.1. Recovery algorithms,[0],[0]
In order to guarantee unique recovery to the underdetermined system in Eq.,2.1. Recovery algorithms,[0],[0]
"(1), the measurement matrix A is designed to satisfy the Restricted Isometry Property (RIP) or the Restricted Eigenvalue Condition (REC) for l-sparse matrices with high probability (Candès & Tao, 2005; Bickel et al., 2009).",2.1. Recovery algorithms,[0],[0]
We define these conditions below.,2.1. Recovery algorithms,[0],[0]
Definition 1.,2.1. Recovery algorithms,[0],[0]
Let Sl(0) ⊂,2.1. Recovery algorithms,[0],[0]
Rn be the set of l-sparse vectors.,2.1. Recovery algorithms,[0],[0]
"For some parameter α ∈ (0, 1), a matrix A ∈ Rm×n is said to satisfy RIP(l, α) if ∀ x ∈ Sl(0),
(1− α)‖x‖2 ≤ ‖Ax‖2 ≤ (1 + α)‖x‖2.
",2.1. Recovery algorithms,[0],[0]
Definition 2.,2.1. Recovery algorithms,[0],[0]
Let Sl(0) ⊂,2.1. Recovery algorithms,[0],[0]
Rn be the set of l-sparse vectors.,2.1. Recovery algorithms,[0],[0]
"For some parameter γ > 0, a matrix A ∈ Rm×n is said to satisfy REC(l, γ) if ∀ x ∈ Sl(0),
‖Ax‖2 ≥ γ‖x‖2.
",2.1. Recovery algorithms,[0],[0]
"Intuitively, RIP implies that A approximately preserves Euclidean norms for sparse vectors and REC implies that sparse vectors are far from the nullspace of A. Many classes of matrices satisfy these conditions with high probability, including random Gaussian and Bernoulli matrices where every entry of the matrix is sampled from a standard normal and uniform Bernoulli distribution respectively (Baraniuk et al., 2008).
",2.1. Recovery algorithms,[0],[0]
Generative model vector recovery using gradient descent.,2.1. Recovery algorithms,[0],[0]
If the signals being sensed are assumed to lie close to the range SG of a generative model function G as defined in Eq.,2.1. Recovery algorithms,[0],[0]
"(3) , then we can recover the best approximation to the true signal by `2-minimization over z,
min z ‖AG(z)− y‖22.",2.1. Recovery algorithms,[0],[0]
"(6)
The function G is typically expressed as a deep neural network which makes the overall objective non-convex, but differentiable almost everywhere w.r.t z.",2.1. Recovery algorithms,[0],[0]
"In practice, good reconstructions can be recovered by gradient-based optimization methods.",2.1. Recovery algorithms,[0],[0]
"We refer to this method proposed by Bora et al. (2017) as generative model-based recovery.
",2.1. Recovery algorithms,[0],[0]
"To guarantee unique recovery, generative model-based recovery makes two key assumptions.",2.1. Recovery algorithms,[0],[0]
"First, the generator functionG is assumed to be L-Lipschitz, i.e., ∀ z1, z2 ∈ Rk,
‖G(z1)−G(z2)‖2 ≤ L‖z1",2.1. Recovery algorithms,[0],[0]
"− z2‖2.
",2.1. Recovery algorithms,[0],[0]
"Secondly, the measurement matrix A is designed to satisfy the Set-Restricted Eigenvalue Condition (S-REC) with high probability (Bora et al., 2017).
",2.1. Recovery algorithms,[0],[0]
Definition 3.,2.1. Recovery algorithms,[0],[0]
Let S ⊆ Rn.,2.1. Recovery algorithms,[0],[0]
"For some parameters γ > 0, δ ≥ 0, a matrix A ∈ Rm×n is said to satisfy the SREC(S, γ, δ) if ∀ x1, x2 ∈ S,
‖A(x1 − x2)‖2 ≥",2.1. Recovery algorithms,[0],[0]
γ‖x1,2.1. Recovery algorithms,[0],[0]
− x2‖2,2.1. Recovery algorithms,[0],[0]
"− δ.
",2.1. Recovery algorithms,[0],[0]
S-REC generalizes REC to an arbitrary set of vectors S as opposed to just considering the set of approximately sparse vectors Sl(0) and allowing an additional slack term δ.,2.1. Recovery algorithms,[0],[0]
"In particular, S is chosen to be the range of the generator function G for generative model-based recovery.",2.1. Recovery algorithms,[0],[0]
The modeling assumptions based on sparsity and generative modeling discussed in the previous section can be limiting in many cases.,3. The Sparse-Gen framework,[0],[0]
"On one hand, sparsity assumes a relatively weak prior over the signals being sensed.",3. The Sparse-Gen framework,[0],[0]
"Empirically, we observe that the recovered signals xL have large reconstruction error ‖xL− x‖22 especially when the number of measurements m is small.",3. The Sparse-Gen framework,[0],[0]
"On the other hand, generative models imposes a very strong, but rigid prior which works well when the number of measurements is small.",3. The Sparse-Gen framework,[0],[0]
"However, the performance of the corresponding recovery methods saturates with increasing measurements since the recovered signal xG = G(zG) is constrained to lie in the range of the generator function G. If zG ∈ Rk is the optimum value returned by an optimization procedure for Eq.",3. The Sparse-Gen framework,[0],[0]
"(6), then the reconstruction error ‖xG − x‖22 is limited by the dimensionality of the latent space and the quality of the generator function.
",3. The Sparse-Gen framework,[0],[0]
"To sidestep the above limitations, we consider a strictly more expressive class of signals by allowing sparse deviations from the range of a generator function.",3. The Sparse-Gen framework,[0],[0]
"Formally, the domain of the recovered signals is given by,
Sl,G = ∪z∈Dom(G)Sl(G(z)) (7)
where Sl(G(z)) denotes the set of sparse vectors centered on G(z) and z varies over the domain of G (typically Rk).",3. The Sparse-Gen framework,[0],[0]
"We refer to this modeling assumption and the consequent algorithmic framework for recovery as Sparse-Gen.
Based on this modeling assumption, we will recover signals of the form G(z) + ν for some ν ∈",3. The Sparse-Gen framework,[0],[0]
Rn that is preferably sparse.,3. The Sparse-Gen framework,[0],[0]
"Specifically, we consider the optimization of a hybrid objective,
min z,ν ‖ν‖0
s.t.",3. The Sparse-Gen framework,[0],[0]
"A (G(z) + ν) = y. (8)
In the above optimization problem the objective is nonconvex and non-differentiable, while the constraint is nonconvex (for general G), making the above optimization
problem hard to solve.",3. The Sparse-Gen framework,[0],[0]
"To ease the optimization problem, we propose two modifications.",3. The Sparse-Gen framework,[0],[0]
"First, we relax the `0 minimization to an `1 minimization similar to LASSO.
",3. The Sparse-Gen framework,[0],[0]
"min z,ν",3. The Sparse-Gen framework,[0],[0]
"‖ν‖1
s.t.",3. The Sparse-Gen framework,[0],[0]
"A (G(z) + ν) = y. (9)
",3. The Sparse-Gen framework,[0],[0]
"Next, we square the non-convex constraint on both sides and consider the Lagrangian of the above problem to get the final unconstrained optimization problem for Sparse-Gen,
min z,ν ‖ν‖1 + λ‖A (G(z) + ν)− y‖22 (10)
where λ is the Lagrange multiplier.
",3. The Sparse-Gen framework,[0],[0]
The above optimization problem is non-differentiable w.r.t.,3. The Sparse-Gen framework,[0],[0]
ν and non-convex w.r.t.,3. The Sparse-Gen framework,[0],[0]
z,3. The Sparse-Gen framework,[0],[0]
(if G is non-convex).,3. The Sparse-Gen framework,[0],[0]
"In practice, it can be solved in practice using gradient descent (since the non-differentiability is only at a finite number of points) or using sequential convex programming (SCP).",3. The Sparse-Gen framework,[0],[0]
"SCP is an effective heuristic for non-convex problems where the convex portions of the problem are solved using a standard convex optimization technique (Boyd & Vandenberghe, 2004).",3. The Sparse-Gen framework,[0],[0]
"In the case of Eq. (10), the optimization w.r.t. ν (for fixed z) is a convex optimization problem whereas the non-convexity typically involves differentiable terms (w.r.t. z) if G is a deep neural network.",3. The Sparse-Gen framework,[0],[0]
"Empirically, we find excellent recovery by standard first order gradient-based methods (Duchi et al., 2011; Tieleman & Hinton, 2012; Kingma & Ba, 2015).
",3. The Sparse-Gen framework,[0],[0]
"Unlike LASSO-based recovery which recovers only sparse signals, Sparse-Gen can impose a stronger domain-specific prior using a generative model.",3. The Sparse-Gen framework,[0],[0]
"If we fix the generator function to map all z to the origin, we recover LASSO-based recovery as a special case of Sparse-Gen. Additionally, Sparse-Gen is not constrained to recover signals over the range of G, as in the case of generative model-based recovery.",3. The Sparse-Gen framework,[0],[0]
"In fact, it can recover signals with sparse deviations from the range of G. Note that the sparse deviations can be
defined in a basis different from the canonical basis.",3. The Sparse-Gen framework,[0],[0]
"In such cases, we consider the following optimization problem,
min z,ν ‖Bν‖1 + λ‖A",3. The Sparse-Gen framework,[0],[0]
"(G(z) + ν)− y‖22 (11)
where B is a change of basis matrix that promotes sparsity of the vector Bν",3. The Sparse-Gen framework,[0],[0]
.,3. The Sparse-Gen framework,[0],[0]
Figure 1 illustrates the differences in modeling assumptions between Sparse-Gen and other frameworks.,3. The Sparse-Gen framework,[0],[0]
The proofs for all results in this section are given in the Appendix.,4. Theoretical Analysis,[0],[0]
"Our analysis and experiments account for measurement noise in compressed sensing, i.e.,
y = Ax+ .",4. Theoretical Analysis,[0],[0]
"(12)
Let ∆ :",4. Theoretical Analysis,[0],[0]
Rm → Rn denote an arbitrary decoding function used to recover the true signal x from the measurements y ∈ Rm.,4. Theoretical Analysis,[0],[0]
"Our analysis will upper bound the `2-error in recovery incurred by our proposed framework using mixed norm guarantees (in particular, `2/`1).",4. Theoretical Analysis,[0],[0]
"To this end, we first state some key definitions.",4. Theoretical Analysis,[0],[0]
"Define the least possible `1 error for recovering x under the Sparse-Gen modeling as,
σSl,G(x) = inf x̂∈Sl,G
‖x− x̂‖1
where the optimal x̂ is the closest point to x in the allowed domain Sl,G. We now state the main lemma guiding the theoretical analysis.",4. Theoretical Analysis,[0],[0]
Lemma 1.,4. Theoretical Analysis,[0],[0]
"Given a function G : Rk → Rn and measurement noise with ‖ ‖2 ≤ max, let A be any matrix that satisfies S-REC(S1.5l,G, (1− α), δ) and RIP(2l, α) for some α ∈ (0, 1), l > 0.",4. Theoretical Analysis,[0],[0]
"Then, there exists a decoder ∆ :",4. Theoretical Analysis,[0],[0]
"Rm → Rn such that,
‖x−∆(Ax+ )‖2 ≤ (2l)−1/2C0σl,G(x) +",4. Theoretical Analysis,[0],[0]
"C1 max + δ′
for all x ∈ Rn, where C0 = 2((1+α)(1−α)−1 +1), C1 = 2(1− α)−1, and δ′ = δ(1− α)−1.
",4. Theoretical Analysis,[0],[0]
The above lemma shows that there exists a decoder such that the error in recovery can be upper bounded for measurement matrices satisfying S-REC and RIP.,4. Theoretical Analysis,[0],[0]
Note that Lemma 1 only guarantees the existence of such a decoder and does not prescribe an optimization algorithm for recovery.,4. Theoretical Analysis,[0],[0]
"Apart from the errors due to the bounded measurement noise max and a scaled slack term appearing in the S-REC condition δ′, the major term in the upper bound corresponds to (up to constants) the minimum possible error incurred by the best possible recovery vector in Sl,G given by σl,G(x).",4. Theoretical Analysis,[0],[0]
"Similar terms appear invariably in the compressed sensing literature and are directly related to the modeling assumptions regarding x (for example, Theorem 8.3 in Cohen et al. (2009)).
",4. Theoretical Analysis,[0],[0]
"Our next lemma shows that random Gaussian matrices satisfy the S-REC (over the range of Lipschitz generative model functions) and RIP conditions with high probability for G with bounded domain, both of which together are sufficient conditions for Lemma 1 to hold.
",4. Theoretical Analysis,[0],[0]
Lemma 2.,4. Theoretical Analysis,[0],[0]
LetG : Bk(r)→ Rn be anL-Lipschitz function where Bk(r) = {z | z ∈,4. Theoretical Analysis,[0],[0]
"Rk, ‖z‖2 ≤ r} is the `2-norm ball in Rk.",4. Theoretical Analysis,[0],[0]
"For α ∈ (0, 1), if
m = O
( 1
α2
( k log ( Lr
δ
)",4. Theoretical Analysis,[0],[0]
+,4. Theoretical Analysis,[0],[0]
l log(n/l) )),4. Theoretical Analysis,[0],[0]
"then a random matrix A ∈ Rm×n with i.i.d. entries such that Aij ∼ N ( 0, 1m ) satisfies the S-REC(S1.5l,G, 1− α, δ) and RIP(2l, α) with 1− e−Ω(α2m) probability.
",4. Theoretical Analysis,[0],[0]
"Using Lemma 1 and Lemma 2, we can bound the error due to decoding with generative models and random Gaussian measurement matrices in the following result.
",4. Theoretical Analysis,[0],[0]
Theorem 1.,4. Theoretical Analysis,[0],[0]
Let G : Bk(r)→,4. Theoretical Analysis,[0],[0]
Rn be an L-Lipschitz function.,4. Theoretical Analysis,[0],[0]
"For any α ∈ (0, 1), l > 0, let A ∈ Rm×n be a random Gaussian matrix with
m = O
( 1
α2
( k log ( Lr
δ
) +",4. Theoretical Analysis,[0],[0]
l log(n/l) )),4. Theoretical Analysis,[0],[0]
rows of i.i.d.,4. Theoretical Analysis,[0],[0]
"entries scaled such that Ai,j ∼ N(0, 1/m).",4. Theoretical Analysis,[0],[0]
Let ∆ be the decoder satisfying Lemma 1.,4. Theoretical Analysis,[0],[0]
"Then, we have with 1− e−Ω(α2m) probability,
‖x−∆(Ax+ )",4. Theoretical Analysis,[0],[0]
"‖2 ≤ (2l)−1/2C0σl,G(x) +",4. Theoretical Analysis,[0],[0]
"C1 max + δ′
for all x ∈ Rn, ‖ ‖2 ≤ max, where C0, C1, γ, δ′ are constants defined in Lemma 1.
",4. Theoretical Analysis,[0],[0]
"From the above lemma, we see that the number of measurements needed to guarantee upper bounds on the reconstruction error of any signal with high probability depends on two terms.",4. Theoretical Analysis,[0],[0]
"The first term includes dependence on the Lipschitz constant L of the generative model function G. A high Lipschitz constant makes recovery harder (by requiring a larger
number of measurements), but only contributes logarithmically.",4. Theoretical Analysis,[0],[0]
"The second term, typical of results in sparse vector recovery, shows a logarithmic growth on the dimensionality n of the signals.",4. Theoretical Analysis,[0],[0]
"Ignoring logarithmic dependences and constants, recovery using Sparse-Gen requires about O(k + l) measurements for recovery.",4. Theoretical Analysis,[0],[0]
Note that Theorem 1 assumes access to an optimization oracle for decoding.,4. Theoretical Analysis,[0],[0]
"In practice, we consider the solutions returned by gradient-based optimization methods to a non-convex objective defined in Eq.",4. Theoretical Analysis,[0],[0]
"(11) that are not guaranteed to correspond to the optimal decoding in general.
",4. Theoretical Analysis,[0],[0]
"Finally, we obtain tighter bounds for the special case when G is expressed using a neural network with only ReLU activations.",4. Theoretical Analysis,[0],[0]
"These bounds do not rely explicitly on the Lipschitz constant L or require the domain of G to be bounded.
",4. Theoretical Analysis,[0],[0]
Theorem 2.,4. Theoretical Analysis,[0],[0]
"If G : Rk → Rn is a neural network of depth d with only ReLU activations and at most c nodes in each layer, then the guarantees of Theorem 1 hold for
m = O
( 1
α2
( (k + l)d log",4. Theoretical Analysis,[0],[0]
c+,4. Theoretical Analysis,[0],[0]
(k + l),4. Theoretical Analysis,[0],[0]
"log(n/l) )) .
",4. Theoretical Analysis,[0],[0]
"Our theoretical analysis formalizes the key properties of recovering signals using Sparse-Gen. As shown in Lemma 1, there exists a decoder for recovery based on such modeling assumptions that extends recovery guarantees based on vanilla sparse vector recovery and generative model-based recovery.",4. Theoretical Analysis,[0],[0]
Such recovery requires measurement matrices that satisfy both the RIP and S-REC conditions over the set of vectors that deviate in sparse directions from the range of a generative model function.,4. Theoretical Analysis,[0],[0]
"In Theorems 1-2, we observed that the number of measurements required to guarantee recovery with high probability grow almost linearly (with some logarithmic terms) with the latent space dimensionality k of the generative model and the permissible sparsity l for deviating from the range of the generative model.",4. Theoretical Analysis,[0],[0]
We evaluated Sparse-Gen for compressed sensing of highdimensional signals from the domain of benchmark image datasets.,5. Experimental Evaluation,[0],[0]
"Specifically, we considered the MNIST dataset of handwritten digits (LeCun et al., 2010) and the OMNIGLOT dataset of handwritten characters (Lake et al., 2015).",5. Experimental Evaluation,[0],[0]
"Both these datasets have the same data dimensionality (28× 28), but significantly different characteristics.",5. Experimental Evaluation,[0],[0]
The MNIST dataset has fewer classes (10 digits from 0-9) as opposed to Omniglot which shows greater diversity (1623 characters across 50 alphabets).,5. Experimental Evaluation,[0],[0]
"Additional experiments with generative adversarial networks on the CelebA dataset are reported in the Appendix.
Baselines.",5. Experimental Evaluation,[0],[0]
"We considered methods based on sparse vector recovery using LASSO (Tibshirani, 1996; Candès & Tao,
2005) and generative model based recovery using variational autoencoders (VAE) (Kingma & Welling, 2014; Bora et al., 2017).",5. Experimental Evaluation,[0],[0]
"For VAE training, we used the standard train/held-out splits of both datasets.",5. Experimental Evaluation,[0],[0]
Compressed sensing experiments that we report were performed on the entire test set of images.,5. Experimental Evaluation,[0],[0]
"The architecture and other hyperparameter details are given in the Appendix.
",5. Experimental Evaluation,[0],[0]
Experimental setup.,5. Experimental Evaluation,[0],[0]
"For the held-out set of instances, we artificially generated measurements y through a random matrix A ∈ Rm×n with entries sampled i.i.d.",5. Experimental Evaluation,[0],[0]
from a Gaussian with zero mean and standard deviation of 1/m. Measurement noise is sampled from zero mean and diagonal scalar covariance matrix with entries as 0.01.,5. Experimental Evaluation,[0],[0]
"For evaluation, we report the reconstruction error measured as ‖x̂− x‖p where x̂ is the recovered signal and p is a norm of interest, varying the number of measurementsm from 50 to the highest value of 750.",5. Experimental Evaluation,[0],[0]
"We report results for the p = {1, 2,∞} norms.
",5. Experimental Evaluation,[0],[0]
"We evaluated sensing of both continuous signals (MNIST) with pixel values in range [0, 1] and discrete signals (Omniglot) with binary pixel values {0, 1}.",5. Experimental Evaluation,[0],[0]
"For all algorithms considered, recovery was performed by optimizing over a continuous space.",5. Experimental Evaluation,[0],[0]
"In the case of sparse recovery methods (including Sparse-Gen) it is possible that unconstrained optimization returns signals outside the domain of interest, in which case they are projected to the required domain by simple clipping, i.e., any signal less than zero is clipped to 0 and similarly any signal greater than one is clipped to 1.
Results and Discussion.",5. Experimental Evaluation,[0],[0]
The reconstruction errors for varying number of measurements are given in Figure 2.,5. Experimental Evaluation,[0],[0]
"Consistent with the theory, the strong prior in generative modelbased recovery methods outperforms the LASSO-based methods for sparse vector recovery.",5. Experimental Evaluation,[0],[0]
"In the regime of low measurements, the performance of algorithms that can incorporate the generative model prior dominates over methods modeling sparsity using LASSO.",5. Experimental Evaluation,[0],[0]
"The performance of plain generative model-based methods however saturates with increasing measurements, unlike Sparse-Gen and LASSO which continue to shrink the error.",5. Experimental Evaluation,[0],[0]
"The trends are consistent for both MNIST and Omniglot, although we observe the relative magnitudes of errors in the case of Omniglot are much higher than that of MNIST.",5. Experimental Evaluation,[0],[0]
This is expected due to the increased diversity and variations of the structure of the signals being sensed in the case of Omniglot.,5. Experimental Evaluation,[0],[0]
We also observe the trends to be consistent across the various norms considered.,5. Experimental Evaluation,[0],[0]
One of the primary motivations for compressive sensing is to directly acquire the signals using few measurements.,5.1. Transfer compressed sensing,[0],[0]
"On the contrary, learning a deep generative model requires access to large amounts of training data.",5.1. Transfer compressed sensing,[0],[0]
"In several applications, getting the data for training a generative model might not be feasible.",5.1. Transfer compressed sensing,[0],[0]
"Hence, we test the generative model-based recovery on the novel task of transfer compressed sensing.
",5.1. Transfer compressed sensing,[0],[0]
Experimental setup.,5.1. Transfer compressed sensing,[0],[0]
We train the generative model on a source domain (assumed to be data-rich) and related to a data-hungry target domain we wish to sense.,5.1. Transfer compressed sensing,[0],[0]
"Given the matching dimensions of MNIST and Omniglot, we conduct experiments transferring from MNIST (source) to Omniglot (target) and vice versa.
Results and Discussion.",5.1. Transfer compressed sensing,[0],[0]
The reconstruction errors for the norms considered are given in Figure 3.,5.1. Transfer compressed sensing,[0],[0]
"For both the sourcetarget pairs, we observe that the Sparse-Gen consistently performs well.",5.1. Transfer compressed sensing,[0],[0]
Vanilla generative model-based recovery shows hardly an improvements with increasing measurements.,5.1. Transfer compressed sensing,[0],[0]
We can qualitatively see this phenomena for transferring from MNIST (source) to Omniglot (target) in Figure 4.,5.1. Transfer compressed sensing,[0],[0]
"With only m = 100 measurements, all models perform poorly and generative model based methods particularly continue to sense images similar to MNIST.",5.1. Transfer compressed sensing,[0],[0]
"On the other hand, there is a noticeable transition at m = 200 measurements for SparseVAE where it adapts better to the domain being sensed than plain generative model-based recovery and achieves lower reconstruction error.",5.1. Transfer compressed sensing,[0],[0]
"Since the introduction of compressed sensing over a decade ago, there has been a vast body of research studying various extensions and applications (Candès & Tao, 2005; Donoho,
2006; Candès et al., 2006).",6. Related Work,[0],[0]
"This work explores the effect of modeling different structural assumptions on signals in theory and practice.
",6. Related Work,[0],[0]
Themes around sparsity in a well-chosen basis has driven much of the research in this direction.,6. Related Work,[0],[0]
"For instance, the paradigm of model-based compressed sensing accounts for the interdependencies between the dimensions of a sparse data signal (Baraniuk et al., 2010; Duarte & Eldar, 2011; Gilbert et al., 2017).",6. Related Work,[0],[0]
"Alternatively, adaptive selection of basis vectors from a dictionary that best capture the structure of the particular signal being sensed has also been explored (Peyre, 2010; Tang et al., 2013).",6. Related Work,[0],[0]
"Many of these methods have been extended to recovery of structured tensors (Zhang et al., 2013; 2014).",6. Related Work,[0],[0]
"In another prominent line of research involving Bayesian compressed sensing, the sparseness assumption is formalized by placing sparsenesspromoting priors on the signals (Ji et al., 2008; He & Carin, 2009; Babacan et al., 2010; Baron et al., 2010).
",6. Related Work,[0],[0]
Research exploring structure beyond sparsity is relatively scarce.,6. Related Work,[0],[0]
Early works in this direction can be traced to Baraniuk & Wakin (2009) who proposed algorithms for recovering signals lying on a smooth manifold.,6. Related Work,[0],[0]
The generative model-based recovery methods consider functions that do not necessarily define manifolds since the range of a generator function could intersect with itself.,6. Related Work,[0],[0]
"Yu & Sapiro (2011) coined the term statistical compressed sensing and proposed
algorithms for efficient sensing of signals from a mixture of Gaussians.",6. Related Work,[0],[0]
The recent work in deep generative model-based recovery differs in key theoretical aspects as well in the use of a more expressive family of models based on neural networks.,6. Related Work,[0],[0]
A related recent work by Hand & Voroninski (2017) provides theoretical guarantees on the solution recovered for solving non-convex linear inverse problems with deep generative priors.,6. Related Work,[0],[0]
"Empirical advances based on well-designed deep neural network architectures that sacrifice many of the theoretical guarantees have been proposed for applications such as MRI (Mardani et al., 2017; 2018).",6. Related Work,[0],[0]
"Many recent methods propose to learn mappings of signals to measurements using neural networks, instead of restricting them to be linear, random matrices (Mousavi et al., 2015; Kulkarni et al., 2016; Chang et al., 2017; Lu et al., 2018).
",6. Related Work,[0],[0]
"Our proposed framework bridges the gap between algorithms that model structure using sparsity and enjoy good theoretical properties with advances in deep generative models, in particular their use for compressed sensing.",6. Related Work,[0],[0]
"The use of deep generative models as priors for compressed sensing presents a new outlook on algorithms for inexpen-
sive data acquisition.",7. Conclusion and Future Work,[0],[0]
"In this work, we showed that these priors can be used in conjunction with classical modeling assumptions based on sparsity.",7. Conclusion and Future Work,[0],[0]
"Our proposed framework, Sparse-Gen, generalizes both sparse vector recovery and recovery using generative models by allowing for sparse deviations from the range of a generative model function.",7. Conclusion and Future Work,[0],[0]
"The benefits of using such modeling assumptions are observed both theoretically and empirically.
",7. Conclusion and Future Work,[0],[0]
"In the future, we would like to design algorithms that can better model the structure within sparse deviations.",7. Conclusion and Future Work,[0],[0]
"Followup work in this direction can benefit from the vast body of prior work in structured sparse vector recovery (Duarte & Eldar, 2011).",7. Conclusion and Future Work,[0],[0]
"From a theoretical perspective, a better understanding of the non-convexity resulting from generative model-based recovery can lead to stronger guarantees and consequently better optimization algorithms for recovery.",7. Conclusion and Future Work,[0],[0]
"Finally, it would be interesting to extend Sparse-Gen for compressed sensing of other data modalities such as graphs for applications in network tomography and reconstruction (Xu et al., 2011).",7. Conclusion and Future Work,[0],[0]
"Real-world graph networks are typically sparse in the canonical basis and can be modeled effectively using deep generative models (Grover et al., 2018), which is consistent with the modeling assumptions of the Sparse-Gen framework.",7. Conclusion and Future Work,[0],[0]
"We are thankful to Tri Dao, Jonathan Kuck, Daniel Levy, Aditi Raghunathan, and Yang Song for helpful comments on early drafts.",Acknowledgements,[0],[0]
"This research was supported by Intel Corporation, TRI, a Hellman Faculty Fellowship, ONR, NSF (#1651565, #1522054, #1733686 ) and FLI (#2017-158687).",Acknowledgements,[0],[0]
AG is supported by a Microsoft Research PhD Fellowship.,Acknowledgements,[0],[0]
"In compressed sensing, a small number of linear measurements can be used to reconstruct an unknown signal.",abstractText,[0],[0]
"Existing approaches leverage assumptions on the structure of these signals, such as sparsity or the availability of a generative model.",abstractText,[0],[0]
A domain-specific generative model can provide a stronger prior and thus allow for recovery with far fewer measurements.,abstractText,[0],[0]
"However, unlike sparsity-based approaches, existing methods based on generative models guarantee exact recovery only over their support, which is typically only a small subset of the space on which the signals are defined.",abstractText,[0],[0]
"We propose Sparse-Gen, a framework that allows for sparse deviations from the support set, thereby achieving the best of both worlds by using a domain specific prior and allowing reconstruction over the full space of signals.",abstractText,[0],[0]
"Theoretically, our framework provides a new class of signals that can be acquired using compressed sensing, reducing classic sparse vector recovery to a special case and avoiding the restrictive support due to a generative model prior.",abstractText,[0],[0]
"Empirically, we observe consistent improvements in reconstruction accuracy over competing approaches, especially in the more practical setting of transfer compressed sensing where a generative model for a data-rich, source domain aids sensing on a data-scarce, target domain.",abstractText,[0],[0]
Modeling Sparse Deviations for Compressed Sensing using Generative Models,title,[0],[0]
"Many languages exhibit fluency phenomena that are discontinuous in the surface string, and are thus not modelled well by traditional n-gram language models.",1 Introduction,[0],[0]
"Examples include morphological agreement, e.g. subject-verb agreement in languages that do not (exclusively) follow SVO word order, subcategorisation, and collocations involving distant, but syntactically linked words.
",1 Introduction,[0],[0]
Syntactic language models try to overcome the limitation to a local n-gram context by using syntactically related words (and non-terminals) as context information.,1 Introduction,[0],[0]
"Despite their theoretical attractiveness, it has proven difficult to improve SMT with parsers as language models (Och et al., 2004; Post and Gildea, 2008).
",1 Introduction,[0],[0]
"This paper describes an effective method to model, train, decode with, and weight a syntactic language model for SMT.",1 Introduction,[0],[0]
"While all these aspects are important for successfully applying a syntactic language model, our primary contributions are a novel dependency language model which improves over prior work by making relational modelling assumptions, which we argue are better suited for languages with a (relatively) free word order, and the use of a syntactic evaluation metric for optimizing the loglinear parameters of the SMT model.
",1 Introduction,[0],[0]
"While language models that operate on words linked through a dependency chain – called syntactic n-grams (Sidorov et al., 2013) – can improve translation, some of the improvement is invisible to an n-gram metric such as BLEU.",1 Introduction,[0],[0]
"As a result, tuning to BLEU does not show the full value of a syntactic language model.",1 Introduction,[0],[0]
"What does show its value is an optimization metric that operates on the same syntactic n-grams that are modelled by the dependency LM.
",1 Introduction,[0],[0]
The paper is structured as follows.,1 Introduction,[0],[0]
"Section 2 describes our relational dependency language model; section 3 describes our neural network training procedure, and the integration of the model into an SMT decoder.",1 Introduction,[0],[0]
We describe the syntactic evaluation metric we use for tuning in Section 4.,1 Introduction,[0],[0]
"The language models are evaluated on the basis of perplexity and SMT
169
Transactions of the Association for Computational Linguistics, vol. 3, pp.",1 Introduction,[0],[0]
"169–182, 2015.",1 Introduction,[0],[0]
Action Editor: Philipp Koehn.,1 Introduction,[0],[0]
"Submission batch: 11/2014; Revision batch 2/2015; Published 3/2015.
",1 Introduction,[0],[0]
c©2015 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY-NC-SA 4.0 license.
performance in section 5.",1 Introduction,[0],[0]
"We discuss related work in section 6, and finish with concluding remarks in section 7.",1 Introduction,[0],[0]
"As motivation, and working example for the model description, consider the dependency tree in Figure 1, which is taken from the output of our baseline string-to-tree SMT system.1 The output contains two errors:
• a morphological agreement error between the subject Ergebnisse (plural) and the finite verb wird (singular).
• a subcategorisation error: überraschen is transitive, but the translation has a prepositional phrase instead of an object.
",2 A Relational Dependency Language Model,[0],[0]
"While these errors might not have occurred if the words involved were adjacent to one another here and throughout the training set, non-adjacency is common, especially where the distance between subject and finite verb, or between a full verb and its arguments can be arbitrarily long.
",2 A Relational Dependency Language Model,[0],[0]
"Prior work on syntactic language modelling has typically focused on English, and we argue that some modelling decisions do not transfer well to other languages.",2 A Relational Dependency Language Model,[0],[0]
The dependency models proposed by Shen et al. (2010) and Zhang (2009) rely heavily on structural information such as the direction and distance of the dependent from the parent.,2 A Relational Dependency Language Model,[0],[0]
"In a language where the order of syntactic dependents is more flexible than in English, such as German2, grammatical function (and thus the inflection) is hard to predict from the dependent order.",2 A Relational Dependency Language Model,[0],[0]
"Instead, we make dependency labels, which encode grammatical relations, a core element of our model.3
1The tree is converted into constituency format for compatibility with SCFG decoding algorithms, with dependency edges represented as non-terminal nodes.
",2 A Relational Dependency Language Model,[0],[0]
"2German has a strict word order within noun phrases and for the placement of verbs, but has different word order for main clauses and subordinated clauses, and some flexibility in the order of dependents of a verb.
",2 A Relational Dependency Language Model,[0],[0]
"3Tsarfaty (2010) classifies parsing approaches into configurational approaches that rely on structural information, and relational ones that take grammatical relations as primitives.",2 A Relational Dependency Language Model,[0],[0]
"While she uses dependency syntax as a prototypical example of
Shen et al. (2010) propose a model that estimates probability of each token given its parent and/or preceding siblings.",2 A Relational Dependency Language Model,[0],[0]
"We start with a variant of their model that does not hard-code configurational modelling assumptions, and then extend it by including dependency labels.",2 A Relational Dependency Language Model,[0],[0]
"Let S be a sequence of terminal symbols w1, w2, ..., wn with a dependency topology T , and let hs(i) and ha(i) be lists of heads of preceding siblings and ancestors of wi according to T , from closest to furthest.",2.1 Unlabelled Model,[0],[0]
"In our example in Figure 1:
• w4 = jüngsten
• hs(4) = (der)
• ha(4) =",2.1 Unlabelled Model,[0],[0]
"(Umfrage,Ergebnisse,wird, )",2.1 Unlabelled Model,[0],[0]
Note that ha and its subsequences are instances of syntactic,2.1 Unlabelled Model,[0],[0]
n-grams.,2.1 Unlabelled Model,[0],[0]
"For this model, we follow related work and assume that T is available (Popel and Marecek, 2010), approximating P (S) as P (S|T ).",2.1 Unlabelled Model,[0],[0]
"We make the Markov assumption that the probability of each word only depends on its preceding siblings4 and ancestors, and decompose the probability of a sentence like this:
P (S) = P (w1, w2, ..., wn)
≈ n∏
i=1
P (wi|hs(i), ha(i))",2.1 Unlabelled Model,[0],[0]
"(1)
We further make the Markov assumption that only a fixed window of the closest q siblings, and the closest r ancestors, affect the probability of a word.
",2.1 Unlabelled Model,[0],[0]
"P (S) ≈ n∏
i=1
P (wi|hs(i)q1, ha(i)r1) (2)
",2.1 Unlabelled Model,[0],[0]
"Equation 2 represents our basic, unlabelled model.",2.1 Unlabelled Model,[0],[0]
"It differs from that of Shen et al. (2010) in two ways.
relational approaches, the dependency LM by Shen et al. (2010) would fall into the configurational category, while ours is relational.
",2.1 Unlabelled Model,[0],[0]
"4Shen et al. (2010) use the siblings that are between the word and its parent, i.e. the following siblings if the word comes before its parent.",2.1 Unlabelled Model,[0],[0]
"We believe both preceding and following siblings are potentially useful, but leave expansion of the context to future work.
",2.1 Unlabelled Model,[0],[0]
"die Ergebnisse der jüngsten Umfrage wird für viele überraschen .
",2.1 Unlabelled Model,[0],[0]
"root root
det
subj
det
attr
gmod
pp
pn
aux
sent
punct
$.
vroot
aux
VAFIN
subj
First, it uses separate context windows for siblings and ancestors.",2.1 Unlabelled Model,[0],[0]
"In contrast, Shen et al. (2010) treat the ancestor as the first symbol in a context window that is shared between the ancestor and siblings.",2.1 Unlabelled Model,[0],[0]
"Our formulation encodes our belief that the model should always assume dependence on the r nearest ancestor nodes, regardless of the number of siblings.",2.1 Unlabelled Model,[0],[0]
"Secondly, Shen et al. (2010) separate dependents to the left and to the right of the parent.",2.1 Unlabelled Model,[0],[0]
"While the fixed SVO verb order in English is compatible with such a separation, allowing PL to model subjects, PR to model objects, most arguments can occur before or after the head verb in German main clauses.",2.1 Unlabelled Model,[0],[0]
We thus argue that left and right dependents should be modelled by a single model to allow for sharing of statistical strength.5,2.1 Unlabelled Model,[0],[0]
The motivation for the inclusion of dependency labels is twofold.,2.2 Labelled Model,[0],[0]
"Firstly, having dependency labels in the context serves as a strong signal for the prediction of the correct inflectional form.",2.2 Labelled Model,[0],[0]
"Secondly, dependency labels are the appropriate level of ab-
5Similar arguments have been made for parsing of (relatively) free word-order languages, e.g. by Tsarfaty et al. (2009).
straction to model subcategorisation frames.",2.2 Labelled Model,[0],[0]
"Let D be a sequence of dependency labels l1, l2, ..., ln, with each label li being the label of the incoming arc at position i in T , and ls(i) and la(i) the list of dependency labels of the siblings and ancestors of wi, respectively.",2.2 Labelled Model,[0],[0]
"Continuing the example for w4, these are:
• l4 = attr
• ls(4) =",2.2 Labelled Model,[0],[0]
"(det)
• la(4) =",2.2 Labelled Model,[0],[0]
"(gmod, subj, vroot, sent)
",2.2 Labelled Model,[0],[0]
"We predict both the terminal symbols S and dependency labels D. The latter lets us model subcategorisation by penalizing unlikely relations, e.g. objects whose parent is an intransitive verb.",2.2 Labelled Model,[0],[0]
"We decompose P (S,D) into P (D)× P (S|D) to obtain:
P (S,D) = P (D)× P (S|D)
",2.2 Labelled Model,[0],[0]
"≈ n∏
i=1
",2.2 Labelled Model,[0],[0]
"Pl(i)× Pw(i)
Pl(i) =",2.2 Labelled Model,[0],[0]
"P (li|hs(i)q1, ls(i)q1, ha(i)r1, la(i)r1) Pw(i) =P (wi|hs(i)q1, ls(i)q1, ha(i)r1, la(i)r1, li)
(3)",2.2 Labelled Model,[0],[0]
We here discuss some details for the extraction of the context hs and ha.,2.3 Head and Label Extraction,[0],[0]
"Dependency structures require no language-specific head extraction rules, even in a converted constituency representation.",2.3 Head and Label Extraction,[0],[0]
"In the constituency representation shown in Figure 1, each non-terminal node in the tree that is not a preterminal has exactly one pre-terminal child.",2.3 Head and Label Extraction,[0],[0]
"The head of a non-terminal node can thus be extracted by identifying the pre-terminal child, and taking its terminal symbol as head.",2.3 Head and Label Extraction,[0],[0]
"An exception is the virtual node sent, which is added to the root of the tree to combine subtrees that are not connected in the original grammar, e.g. the main tree and the punctuation symbol.",2.3 Head and Label Extraction,[0],[0]
"If a node has no pre-terminal child, we use a special token as its head.
",2.3 Head and Label Extraction,[0],[0]
"If the sibling of a node is a pre-terminal node, we represent this through a special token in hs and ls.",2.3 Head and Label Extraction,[0],[0]
"We also use special out-of-bound tokens (separate for hs, ha, ls and la) to fill up the context window if the window is larger than the number of siblings and/or ancestors.
",2.3 Head and Label Extraction,[0],[0]
The context extraction rules are languageindependent and can be applied to any dependency structure.,2.3 Head and Label Extraction,[0],[0]
Language-specific or grammar-specific rules are possible in principle.,2.3 Head and Label Extraction,[0],[0]
"For instance, for verbal heads in German, one could consider separable verb prefixes part of the head, and thus model differences in subcategorisation between schlagen (Engl. beat) and schlagen ...",2.3 Head and Label Extraction,[0],[0]
vor (Engl. suggest).,2.3 Head and Label Extraction,[0],[0]
"The model in equation 3 still assumes the topology of the dependency tree to be given, and we remedy this by also predicting pre-terminal nodes, and a virtual STOP node as the last child of each node.",2.4 Predicting the Tree Topology,[0],[0]
"This models the position of the head in a subtree (through the prediction of pre-terminal nodes), and the probability that a word has no more dependents (by assigning probability mass to the STOP node).
",2.4 Predicting the Tree Topology,[0],[0]
"Instead of generating all n terminal symbols as in equation 3, we generate all m nodes in the dependency tree in top-down, depth-first order, with li being PT for pre-terminals, and the node label otherwise, and wi being either the head of the node, or if the node has no pre-terminal child.",2.4 Predicting the Tree Topology,[0],[0]
"Our final model is given in equation 4.
",2.4 Predicting the Tree Topology,[0],[0]
"P (S,D, T )",2.4 Predicting the Tree Topology,[0],[0]
"≈ m∏
i=1
{",2.4 Predicting the Tree Topology,[0],[0]
"Pl(i)× Pw(i), if wi 6= Pl(i), otherwise
(4) Figure 2 illustrates the prediction of a subtree of the dependency tree in Figure 1.",2.4 Predicting the Tree Topology,[0],[0]
"Note that T is encoded implicitly, and can be retrieved from D through a stack to which all nodes (except for preterminal and STOP nodes) are pushed after prediction, and from which the last node is popped when predicting a STOP node.",2.4 Predicting the Tree Topology,[0],[0]
"We extract all training instances from automatically parsed training text, and perform training with a standard feed-forward neural network (Bengio et al., 2003), using the NPLM toolkit (Vaswani et al., 2013).",3 Neural Network Training and SMT Decoding,[0],[0]
"Back-off smoothing schemes are unsatisfactory because it is unclear which part of the context should be forgotten first, and neural networks elegantly solve this problem.",3 Neural Network Training and SMT Decoding,[0],[0]
"We use two separate networks, one for Pw and one for Pl.",3 Neural Network Training and SMT Decoding,[0],[0]
"Both networks share the same input vocabulary, but are trained and applied independently.",3 Neural Network Training and SMT Decoding,[0],[0]
"The model input is a (2q+2r)-word context vector (+1 for Pw to encode li), each word being mapped to a shared embedding layer.",3 Neural Network Training and SMT Decoding,[0],[0]
"We use a single hidden layer with rectifiedlinear activation function, and noise-contrastive estimation (NCE).
",3 Neural Network Training and SMT Decoding,[0],[0]
We integrate our dependency language models into a string-to-tree SMT system as additional feature functions that score each translation hypothesis.,3 Neural Network Training and SMT Decoding,[0],[0]
"The model in equation 4 predicts P (S,D, T ).
",3 Neural Network Training and SMT Decoding,[0],[0]
"Obtaining the probability of the translation hypothesis P (S) would require the (costly) marginalization over all sequences of dependency labels D and topologies T , but like the SMT decoder itself, we approximate the search for the best translation by searching for the highest-scoring derivation, meaning that we directly integrate Pw and Pl as two features into the log-linear SMT model.",3 Neural Network Training and SMT Decoding,[0],[0]
"We use selfnormalized neural networks with precomputation of the hidden layer, which makes the integration into decoding reasonably fast.
",3 Neural Network Training and SMT Decoding,[0],[0]
"The decoder builds the translation bottom-up, and the full context is not available for all symbols in the hypothesis.",3 Neural Network Training and SMT Decoding,[0],[0]
"Vaswani et al. (2013) propose to use a special null word for unavailable context, their embedding being the weighted average of the input embeddings of all other words.",3 Neural Network Training and SMT Decoding,[0],[0]
"We adopt this strategy, with the difference that we use separate null words for each position in the context window in order to reflect distributional differences between the different positions, e.g. between ancestor labels and sibling labels.",3 Neural Network Training and SMT Decoding,[0],[0]
"Symbols are re-scored as more context becomes available in decoding, but poor approximations could affect pruning and thus lead to search errors.",3 Neural Network Training and SMT Decoding,[0],[0]
"In Table 1, we illustrate the use of null words with a 5-gram and a bigram NNLM model.",3 Neural Network Training and SMT Decoding,[0],[0]
"We observe a small increase in entropy when querying the 5-gram model with bigrams, compared to querying a bigram model directly.
",3 Neural Network Training and SMT Decoding,[0],[0]
Some hierarchical SMT systems allow glue rules which concatenate two subtrees.,3 Neural Network Training and SMT Decoding,[0],[0]
"Since the resulting glue structures do not occur in the training data, we do not estimate their probability in our model.",3 Neural Network Training and SMT Decoding,[0],[0]
"When encountering the root of a glue rule in our language model, we recursively evaluate its children, but ignore the glue node itself.",3 Neural Network Training and SMT Decoding,[0],[0]
This could introduce a bias towards using more glue rules during translation.,3 Neural Network Training and SMT Decoding,[0],[0]
"To counter this, and encourage the production of linguistically plausible trees, we assign a fixed, high cost to glue rules.",3 Neural Network Training and SMT Decoding,[0],[0]
"Glue rules thus play a small
role in our systems, with about 100 glue rule applications per 3000 sentences, and could be abandoned entirely.6",3 Neural Network Training and SMT Decoding,[0],[0]
"N-gram based metrics such as BLEU (Papineni et al., 2002) are still predominantly used to optimize the log-linear parameters of SMT systems, and (to a lesser extent) to evaluate the final translation systems.",4 Optimizing Syntactic N-grams,[0],[0]
"However, n-gram metrics are not well suited to measure fluency phenomena with string-level gaps, and there is a danger that BLEU underestimates the modelling power of dependency language models, resulting in a suboptimal assignment of loglinear weights.",4 Optimizing Syntactic N-grams,[0],[0]
"As an alternative metric that operates on the level of syntactic n-grams, we use a variant of the head-word chain metric (HWCM) (Liu and Gildea, 2005).
",4 Optimizing Syntactic N-grams,[0],[0]
"HWCM is a precision metric similar to BLEU, but instead of counting n-gram matches between the translation output and the reference, it compares head-word chains, or syntactic n-grams.",4 Optimizing Syntactic N-grams,[0],[0]
"HWCM is not only suitable for our task because it operates on the same structures as the dependency language models, but also because our string-to-tree SMT architecture produces trees that can be evaluated directly, without requiring a separate parse of the translation output, a task for which few parsers are optimized.",4 Optimizing Syntactic N-grams,[0],[0]
"For extracting syntactic n-grams from the reference translations of the respective development and test sets, we automatically parse them, using the same preprocessing as for training.
",4 Optimizing Syntactic N-grams,[0],[0]
"We count syntactic n-grams of sizes 1 to 4, mirroring the typical usage of BLEU.",4 Optimizing Syntactic N-grams,[0],[0]
"Banerjee and Lavie (2005) have demonstrated the importance of recall in MT evaluation, and we compute the harmonic mean of precision and recall, which we denote HWCMf , instead of the original, precision-based metric.",4 Optimizing Syntactic N-grams,[0],[0]
We perform three evaluations of our dependency language models.,5 Evaluation,[0],[0]
"Our perplexity evaluation measures model perplexity on the 1-best output of a
6For efficiency reasons, our experimental systems only perform SCFG parsing for spans of up to 50 words, and use glue rules to concatenate partial derivations in longer sentences.",5 Evaluation,[0],[0]
"Better decoding algorithms have reduced the need for this limit (Sennrich, 2014).
baseline SMT system and a human reference translation.",5 Evaluation,[0],[0]
Our SMT evaluation integrates the model as a feature function in a string-to-tree SMT system and evaluates its impact on translation quality.,5 Evaluation,[0],[0]
"Finally, we quantify the effect of different language models on grammaticality by measuring the number of agreement errors of our SMT systems.
",5 Evaluation,[0],[0]
"We refer to the unlabelled variant of our model (equation 2) as DLM, and to the labelled variant (equation 4) as RDLM, emphasizing that the latter is a relational dependency LM.",5 Evaluation,[0],[0]
"We perform our experiments on English→German data from the WMT 2014 shared translation task (Bojar et al., 2014), consisting of about 4.5 million sentence pairs of parallel data and 120 million sentences of monolingual German data.",5.1 Data and Methods,[0],[0]
We train all language models on the German side of the parallel text and the monolingual data.,5.1 Data and Methods,[0],[0]
"We also perform some experiments on the English→Russian data from the same translation task, with 2 million sentence pairs of parallel data and 34 million sentences of monolingual Russian data.
",5.1 Data and Methods,[0],[0]
"For a 5-gram Neural Network LM baseline (NNLM), and the dependency language models, we train feed-forward Neural Network language models with the NPLM toolkit.",5.1 Data and Methods,[0],[0]
"We use 150 dimensions for the input embeddings, and a single hidden layer with 750 dimensions.",5.1 Data and Methods,[0],[0]
"We use a vocabulary of 500 000 words (70 for the output vocabulary of Pl), from which we draw 100 noise samples for NCE (50 for Pl).",5.1 Data and Methods,[0],[0]
"We train for two epochs, each epoch being a full traversal of the training text.",5.1 Data and Methods,[0],[0]
"For unknown words, we back-off to a special unk token for the sequence models and Pl, and to the pre-terminal symbol for the other dependency models.",5.1 Data and Methods,[0],[0]
"We report perplexity values with softmax normalization, but disable normalization during decoding, relying on the selfnormalization of NCE for efficiency.",5.1 Data and Methods,[0],[0]
"For the translation experiments with DLM and RDLM, we set the sibling window size q to 1, and the ancestor window size r to 2.7
We train baseline language models with interpolated modified Kneser-Ney smoothing with SRILM
7On our test set, a node has an average of 4.6 ancestors (σ = 2.5), and 1.2 left siblings (σ = 1.3).
",5.1 Data and Methods,[0],[0]
"(Stolcke, 2002).",5.1 Data and Methods,[0],[0]
The model in the SMT baseline uses the full vocabulary and a linear interpolation of component models for domain adaptation.,5.1 Data and Methods,[0],[0]
"For the perplexity evaluation, we use the same vocabulary and training data as for the Neural Network models.
",5.1 Data and Methods,[0],[0]
"For the English→German SMT evaluation, our baseline system is a string-to-tree SMT system with Moses (Koehn et al., 2007), with dependency parsing of the German texts (Sennrich et al., 2013).",5.1 Data and Methods,[0],[0]
"It is described in more detail in (Williams et al., 2014).",5.1 Data and Methods,[0],[0]
This setup was ranked 1–2 (out of 18) in the WMT 2014 shared translation task and is stateof-the art.,5.1 Data and Methods,[0],[0]
"Our biggest deviation from this setup is that we do not enforce the morphological agreement constraints that are provided by a unification grammar (Williams and Koehn, 2011), but use them for analysis instead.",5.1 Data and Methods,[0],[0]
"For English→Russian, we copy the language-independent settings from the the English→German set-up, and perform dependency parsing with a Russian model for the Maltparser (Nivre et al., 2006; Sharoff and Nivre, 2011), applying projectivization after parsing.
",5.1 Data and Methods,[0],[0]
"We tune our system on a development set of 2000 sentences with k-best batch MIRA (Cherry and Foster, 2012) on BLEU and a linear interpolation of BLEU and HWCMf , and report both scores for evaluation.",5.1 Data and Methods,[0],[0]
"We also report METEOR (Denkowski and Lavie, 2011) for German and TER (Snover et al., 2006).",5.1 Data and Methods,[0],[0]
"We control for optimizer instability by running the optimization three times per system and performing significance testing with Multeval (Clark et al., 2011), which we enhanced to also perform significance testing for HWCMf .
",5.1 Data and Methods,[0],[0]
"5.2 Implementation notes on model by Shen et al. (2010)
",5.1 Data and Methods,[0],[0]
We reimplement the model by Shen et al. (2010) for our evaluation.,5.1 Data and Methods,[0],[0]
"The authors did not specify training and smoothing of their model, so we only adopt their definition of the context window, and use the same neural network architecture as for our other models.",5.1 Data and Methods,[0],[0]
"Specifically, we use two neural networks: one for left dependents, and one for right dependents.",5.1 Data and Methods,[0],[0]
"We use maximum-likelihood estimation for the head of root nodes, ignoring unseen events.",5.1 Data and Methods,[0],[0]
"To distinguish between parents and siblings in the context window, we double the input vocabulary and mark parents with a suffix.",5.1 Data and Methods,[0],[0]
"Like Shen et al. (2010), we ignore the
prediction of STOP labels, meaning that our implementation assumes the dependency topology to be given.",5.1 Data and Methods,[0],[0]
We use a trigram model like the original authors.,5.1 Data and Methods,[0],[0]
"Peter et al. (2012) experiment with higher orders variants, but do not consider grandparent nodes.",5.1 Data and Methods,[0],[0]
"We consider scalability to a larger ancestor context a real concern, since another duplication of the vocabulary may be necessary for each ancestor level.",5.1 Data and Methods,[0],[0]
There are a number of factors that make a direct comparison of the reference set perplexity unfair.,5.3 Perplexity,[0],[0]
"Mainly, the unlabelled dependency model DLM and the one by Shen et al. (2010) assume that the dependency topology is given; Pw even assumes this for the dependency labels D. Conversely, the full RDLM predicts the terminal sequence, the dependency labels, and the dependency topology, and we thus expect it to have a higher perplexity.8 Also note that we compare 5-gram n-gram models to 3- and 4- gram dependency models.",5.3 Perplexity,[0],[0]
"A more minor difference is that n-gram models also predict end-of-sentence tokens, which the dependency models do not.
",5.3 Perplexity,[0],[0]
"Rather than directly comparing perplexity between different models, our focus lies on a perplexity comparison between a human reference translation and the 1-best SMT output of a baseline transla-
8For better comparability, we measure perplexity per surface word, not per prediction.
tion system.",5.3 Perplexity,[0],[0]
"Our basic assumption is that the difference in perplexity (or cross-entropy) tells us whether a model contains information that is not already part of the baseline model, and if incorporating it into our SMT system can nudge the system towards producing a translation that is more similar to the reference.
",5.3 Perplexity,[0],[0]
Results for English→German are shown in table 2.,5.3 Perplexity,[0],[0]
"The baseline 5-gram language model with Kneser-Ney smoothing prefers the SMT output over the reference translation, which is natural given that this language model is part of the system producing the SMT output.",5.3 Perplexity,[0],[0]
"The 5-gram NNLM improves over the Kneser-Ney models, and happens to assign almost the same perplexity score to both texts.",5.3 Perplexity,[0],[0]
"This still means that it is less biased towards the SMT output than the baseline model, and can be a valuable addition to the model.
",5.3 Perplexity,[0],[0]
"The dependency language models all show a preference for the reference translation, with DLM having a stronger preference than the model by Shen et al. (2010), and RDLM having the strongest preference.",5.3 Perplexity,[0],[0]
"The direct comparison of DLM and Pw, which is the component of RDLM that predicts the terminal symbols, shows that dependency labels serve as a strong signal for predicting the terminals, confirming our initial hypothesis.",5.3 Perplexity,[0],[0]
The prediction of the dependency topology and labels through Pl means that the full RDLM has the highest perplexity of all models.,5.3 Perplexity,[0],[0]
"However, it also strongly prefers the human reference text over the baseline SMT output.",5.3 Perplexity,[0],[0]
Translation results for English→German with different language models added to our baseline are shown in Table 3.,5.4 Translation Quality,[0],[0]
"Considering the systems tuned on BLEU, we observe that the 5-gram NNLM and RDLM are best in terms of BLEU and TER, but that RDLM is the only winner9 according to HWCMf and METEOR.",5.4 Translation Quality,[0],[0]
"In particular, we observe a sizable gap of 0.6 HWCMf points between the NNLM and the RDLM systems, despite similar BLEU scores.",5.4 Translation Quality,[0],[0]
"The unlabelled DLM and the dependency LM by Shen et al. (2010), which are generally weaker than RDLM, also tend to improve HWCMf more than BLEU.",5.4 Translation Quality,[0],[0]
"This reflects the fact that the dependency
9We denote a system a winner if no other system [in the group of systems under consideration] is significantly better according to significance testing with Multeval.
LMs improve fluency along the syntactic n-grams that HWCM measures, whereas NNLM only improves local fluency, to which BLEU is most sensitive.",5.4 Translation Quality,[0],[0]
"The fact that the models cover different phenomena is also reflected in the fact that we see further gains from combining the 5-gram NNLM with the strongest dependency LM, RDLM, for a total improvement of 0.9–1.1 BLEU over the baseline.
",5.4 Translation Quality,[0],[0]
"If we use BLEU+HWCMf as our tuning objective, the difference between the models increases.",5.4 Translation Quality,[0],[0]
"Compared to the 5-gram NNLM, the RDLM system gains 0.8–0.9 points in HWCMf and 0.3–0.5 points in BLEU.",5.4 Translation Quality,[0],[0]
"Compared to the original baseline, tuned only on BLEU, the system with RDLM that is tuned on BLEU+HWCMf yields an improvement of 1.1– 1.3 BLEU and 1.3–1.4 HWCMf .
",5.4 Translation Quality,[0],[0]
"If we compare the same system being trained on both tuning objectives, we observe that tuning on BLEU+HWCMf , unsurprisingly, yields higher HWCMf scores than tuning on BLEU only.",5.4 Translation Quality,[0],[0]
What is more surprising is that adding HWCMf as a tuning objective also yields significantly higher BLEU on the test sets for 9 out of 10 data points.,5.4 Translation Quality,[0],[0]
The gap is larger for the two systems with RDLM (0.3–0.6 BLEU) than for the baseline or the NNLM system (0.1–0.2 BLEU).,5.4 Translation Quality,[0],[0]
"We hypothesize that the inclusion of HWCMf as a tuning metric reduces overfitting and encourages the production of more grammatically well-formed constructions, which we expect to be a robust objective across different texts, espe-
cially when coupled with a strong dependency language model such as RDLM.
",5.4 Translation Quality,[0],[0]
Some example translations are shown in table 4.,5.4 Translation Quality,[0],[0]
"They illustrate three error types in the baseline system:
1.",5.4 Translation Quality,[0],[0]
"an error in subject-verb agreement.
",5.4 Translation Quality,[0],[0]
2.,5.4 Translation Quality,[0],[0]
"a subcategorisation error: gelten is a valid translation of the intransitive meaning of apply, but cannot be used for transitive constructions, where anwenden is correct.
3.",5.4 Translation Quality,[0],[0]
"a collocation error: two separate collocations are conflated in the baseline translation:
• reach a decision on [...] eine Entscheidung über",5.4 Translation Quality,[0],[0]
"[...] treffen
• reach an agreement on [...] eine Einigung über",5.4 Translation Quality,[0],[0]
"[...] erzielen
All errors are due to inter-dependencies in the sentence that have string-level gaps, but which can be modelled through syntactic n-grams, and are corrected by the system with RDLM and tuning on BLEU+HWCMf .
",5.4 Translation Quality,[0],[0]
We evaluate a subset of the systems on an English→Russian task to test whether the improvements from adding RDLM and tuning on BLEU+HWCMf apply to other language pairs.,5.4 Translation Quality,[0],[0]
Results are shown in Table 5.,5.4 Translation Quality,[0],[0]
"The system with RDLM
is the consistent winner, and significantly outperforms the baseline for all metrics and test sets.",5.4 Translation Quality,[0],[0]
Tuning on BLEU+HWCMf results in further improvements in HWCMf and TER.,5.4 Translation Quality,[0],[0]
"Looking at the combined effect of adding RDLM and changing the tuning objective, we observe gains in BLEU by 0.5–0.9 points, and gains in HWCMf by 2.1–3.4 points.",5.4 Translation Quality,[0],[0]
"We argue that the dependency language models and HWCMf as a tuning metric improve grammaticality, and we are able to quantify one aspect thereof, morphological agreement, for English→German.",5.5 Morphological Agreement,[0],[0]
"Williams and Koehn (2011) introduce a unification grammar with hand-crafted agreement constraints to identify and suppress selected morphological agreement violations in German, namely in regards to noun phrase agreement, prepositional phrase agreement, and subject-verb agreement.",5.5 Morphological Agreement,[0],[0]
We can use their grammar to analyse the effect of different models on morphological agreement by counting the number of translations that violate at least one agreement constraint.,5.5 Morphological Agreement,[0],[0]
"We assume that the number of false posi-
tives (i.e. correct analyses that trigger an agreement violation) remains roughly constant throughout all systems, so that a reduction in the number of agreement violations is an indicator of better grammatical agreement.
",5.5 Morphological Agreement,[0],[0]
Table 6 shows the results.,5.5 Morphological Agreement,[0],[0]
"While the 5-gram NNLM reduces the number of agreement errors somewhat compared to the baseline (-18%), the reduction is greater for DLM (-34%) and RDLM (-46%).",5.5 Morphological Agreement,[0],[0]
"Neither the baseline nor the 5-gram NNLM
profits strongly from tuning on HWCMf , while the number of agreement errors is further reduced for the system with DLM (-41%) and RDLM (-54%).",5.5 Morphological Agreement,[0],[0]
"Adding the 5-gram NNLM to the RDLM system yields no further reduction on the number of agreement errors.
",5.5 Morphological Agreement,[0],[0]
"Enforcing the agreement constraints on the baseline system (tuned on BLEU+HWCMf ) provides us with a gain of 0.3 in both BLEU and HWCMf ; on the RDLM system, only 0.03.",5.5 Morphological Agreement,[0],[0]
"The fact that the benefit of enforcing the agreement constraints drops off more sharply than the number of constraint violations indicates that the remaining violations tend to be harder for the model to correct, e.g. because the translation model has not learned to produce the required inflection of a word, or because some of the remaining violations are false positives.",5.5 Morphological Agreement,[0],[0]
"While the dependency language models’ effect of improving morphological agreement is not (fully) cumulative with the benefit from enforcing the unification constraints formulated by Williams and Koehn (2011), our model has the advantage of being languageindependent, learning from the data itself rather than relying on manually developed, grammar-specific constraints, and covering a wider range of phenomena such as subcategorisation and syntactic collocations.
",5.5 Morphological Agreement,[0],[0]
"The results confirm that the RDLM is more effective at reducing morphological agreement errors than a similarly trained n-gram NNLM and the unlabelled DLM, and that adding HWCMf to the training objective is beneficial.",5.5 Morphological Agreement,[0],[0]
"On a a meta-evaluation level, we compare the rank correlation between the automatic metrics and the numer of agreement errors with Kendall’s τ correlation, and observe that he number of agreement errors is more strongly (negatively) correlated with HWCMf (τ = −0.92) than with BLEU (τ = −0.77), METEOR (τ = −0.54) or TER (τ = 0.69).",5.5 Morphological Agreement,[0],[0]
"This supports our theoretical expectation that HWCMf is more sensitive to morphological agreement, which is enforced along syntactic n-grams, than n-gram metrics such as BLEU, or the unigram metric METEOR.",5.5 Morphological Agreement,[0],[0]
"While there has been a wide range of dependency language models proposed (e.g. (Chelba et al., 1997;
Quirk et al., 2004; Shen et al., 2010; Zhang, 2009; Popel and Marecek, 2010)), there are vast differences in modelling assumptions.",6 Related Work,[0],[0]
"Our work is most similar to the dependency language model described in Shen et al. (2010), or the h-gram model proposed by Zhang (2009), both of which have been used for SMT.",6 Related Work,[0],[0]
"We make different modelling assumptions, relying less on configurational information, but including the prediction of dependency labels in the model.",6 Related Work,[0],[0]
"We argue that our relational modelling assumptions are more suitable for languages with a relatively free word order such as German.
",6 Related Work,[0],[0]
"To a lesser extent, our work is similar to other parsing models that have been used for language modelling, such as lexicalized PCFGs (Charniak, 2001; Collins, 2003; Charniak et al., 2003), or structured language models (Chelba and Jelinek, 2000); previous efforts to include them in the translation process failed to improve translation performance (Och et al., 2004; Post and Gildea, 2008).",6 Related Work,[0],[0]
"Differences in our work that could explain why we see improvements include the use of Neural Networks for training the model on the automatically parsed training text, instead of re-using existing parser models, which could be seen as a form of self-training (McClosky et al., 2006), and the integration of the language model into the decoder instead of n-best reranking.",6 Related Work,[0],[0]
"Also, there are major differences in the parsing models themselves.",6 Related Work,[0],[0]
"For instance, note that the structured LM by Chelba and Jelinek (2000) uses a binary branching structure, and that complex label sets would be required to encode subcategorisation frames in binary trees (Hockenmaier and Steedman, 2002).
",6 Related Work,[0],[0]
Our neural network is a standard feed-forward neural network as introduced by Bengio et al. (2003).,6 Related Work,[0],[0]
"Recently, recursive neural networks have been proposed for syntactic parsing (Socher et al., 2010; Le and Zuidema, 2014).",6 Related Work,[0],[0]
"The recursive nature of such models allows for the encoding of more context; for an efficient integration into the dynamic programming search of SMT decoding, we deem our model, which makes stronger Markov assumptions, more suitable.
",6 Related Work,[0],[0]
"While BLEU has been the standard objective function for tuning the log-linear parameters in SMT systems, recent work has investigated alternative objective functions.",6 Related Work,[0],[0]
"Some authors concluded that none of
the tested alternatives could consistently outperform BLEU (Cer et al., 2010; Callison-Burch et al., 2011).",6 Related Work,[0],[0]
"Liu et al. (2011) report that tuning on the TESLA metric gives better results than tuning on BLEU; Lo et al. (2013) do the same for MEANT.
",6 Related Work,[0],[0]
"There is related work on improving morphological agreement and subcategorisation through postediting (Rosa et al., 2012) or independent models for inflection generation (Toutanova et al., 2008; Weller et al., 2013).",6 Related Work,[0],[0]
"The latter models initially produce a stemmed translation, then predict the inflection through feature-rich sequence models.",6 Related Work,[0],[0]
Such a pipeline of prediction steps is less powerful than our joint prediction of stems and inflection.,6 Related Work,[0],[0]
"For instance, in example 2 in Table 4, our model chooses a different stem to match the subcategorisation frame of the translation; it is not possible to fix the baseline translation with inflection changes alone.",6 Related Work,[0],[0]
The main contribution of this paper is the description of a relational dependency language,7 Conclusion,[0],[0]
"model.10 We show that it is a valuable asset to a state-of-the-art SMT system by comparing perplexity values with other types of languages models, and by its integration into decoding, which results in improvements according to automatic MT metrics and reduces the number of agreement errors.",7 Conclusion,[0],[0]
"We show that the disfluencies that our model captures are qualitatively different from an n-gram Neural Network language model, with our model being more effective at modelling fluency phenomena along syntactic n-grams.
",7 Conclusion,[0],[0]
A second important contribution is the optimization of the log-linear parameters of an SMT system based on syntactic n-grams.,7 Conclusion,[0],[0]
We are to our knowledge the first to tune an SMT system on a non-shallow syntactic similarity metric.,7 Conclusion,[0],[0]
"Apart from showing improvements by tuning on HWCMf , our results also shed light on the interaction between models and tuning metrics.",7 Conclusion,[0],[0]
"With n-gram language models, the choice of tuning metric only had a small effect on the English→German translation results.",7 Conclusion,[0],[0]
"Only with dependency language models, which are able to model the syntactic n-grams that HWCM scores, did we see large improvements from adding
10We have released an implementation of RDLM and tuning on HWCMf as part of the Moses decoder.
HWCMf to the objective function.",7 Conclusion,[0],[0]
"On the one hand, this has implications when evaluating new model components: using an objective function that cannot capture the impact of a model component can result in false negatives because the model component will not receive an appropriate weight, and the model may thus seem to be of little use, even in a human evaluation.",7 Conclusion,[0],[0]
"On the other hand, it is an important finding for the evaluation of objective functions: the performance of an objective function is tied to the power of the underlying model.",7 Conclusion,[0],[0]
"Without a model that is able to model syntactic n-grams, we might have concluded that HWCM is of little help as an objective function.",7 Conclusion,[0],[0]
"Now, we hypothesize that HWCM is well-suited to optimize dependency language models because both operate on syntactic ngrams, just like BLEU and n-gram models are natural counterparts.
",7 Conclusion,[0],[0]
"The approach we present is languageindependent, and we evaluated it on SMT into German and Russian.",7 Conclusion,[0],[0]
"While we have no empirical data on the model’s effectiveness for other target languages, we suspect that syntactic n-grams are especially suited for modelling and evaluating translations into languages with inter-dependencies between distant words and relatively free word order, such as German, Czech, or Russian.
",7 Conclusion,[0],[0]
"In this work, we relied on parse hypotheses being provided by a string-to-tree SMT decoder, but other settings are conceivable for future work, such as performing n-best string reranking by coupling the relational dependency LM with a monolingual parse algorithm.",7 Conclusion,[0],[0]
"Another obvious extension of the relational dependency LM is the inclusion of more context, for instance through larger windows for siblings and ancestors, or source-context as in (Devlin et al., 2014).",7 Conclusion,[0],[0]
"Also, we believe that the model can benefit from further advances in neural network modelling, for instance recent findings that ensembles of networks outperform a single network (Mikolov et al., 2011; Devlin et al., 2014)",7 Conclusion,[0],[0]
I thank Bonnie Webber and the anonymous reviewers for their helpful suggestions and feedback.,Acknowledgements,[0],[0]
This research was funded by the Swiss National Science Foundation under grant P2ZHP1_148717.,Acknowledgements,[0],[0]
"The role of language models in SMT is to promote fluent translation output, but traditional n-gram language models are unable to capture fluency phenomena between distant words, such as some morphological agreement phenomena, subcategorisation, and syntactic collocations with string-level gaps.",abstractText,[0],[0]
Syntactic language models have the potential to fill this modelling gap.,abstractText,[0],[0]
We propose a language model for dependency structures that is relational rather than configurational and thus particularly suited for languages with a (relatively) free word order.,abstractText,[0],[0]
"It is trainable with Neural Networks, and not only improves over standard n-gram language models, but also outperforms related syntactic language models.",abstractText,[0],[0]
We empirically demonstrate its effectiveness in terms of perplexity and as a feature function in string-to-tree SMT from English to German and Russian.,abstractText,[0],[0]
We also show that using a syntactic evaluation metric to tune the log-linear parameters of an SMT system further increases translation quality when coupled with a syntactic language model.,abstractText,[0],[0]
Modelling and Optimizing on Syntactic N-Grams for Statistical Machine Translation,title,[0],[0]
"Proceedings of the SIGDIAL 2017 Conference, pages 360–369, Saarbrücken, Germany, 15-17 August 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Humans appear to organize and remember everyday experiences by imposing a narrative structure on them (Nelson, 1989; Thorne and Nam, 2009; Bruner, 1991; McAdams et al., 2006), and many genres of natural language text are therefore narratively structured, e.g. dinner table conversations, news articles, user reviews and blog posts (Polanyi, 1989; Jurafsky et al., 2014; Bell, 2005; Gordon et al., 2011).",1 Introduction,[0],[0]
"Moreover, there is broad consensus that understanding a narrative involves activating a representation, early in the narrative, of the protagonist and her goals and desires, and then maintaining that representation as the narrative evolves, as a vehicle for explaining the protagonist’s actions and tracking narrative outcomes (Elson, 2012; Rapp and Gerrig, 2006; Trabasso
and van den Broek, 1985; Lehnert, 1981).",1 Introduction,[0],[0]
"To date, there has been limited work on computational models for recognizing the expression of the protagonist’s goals and desires in narrative texts, and tracking their corresponding narrative outcomes.",1 Introduction,[0],[0]
"We introduce a new corpus DesireDB of∼3,500 first-person informal narratives with annotations for desires and their fulfillment status, available online.1 Because first-person narratives often revolve around the narrator’s private states and goals (Labov, 1972), this corpus is highly suitable as a testbed for identifying human desires and their outcomes.",1 Introduction,[0],[0]
"Moreover, first-person narratives allow the narrative protagonist (first-person) to be easily identified and tracked.",1 Introduction,[0],[0]
"Figure 1 illustrates examples of desire and goal expressions in our corpus.
DesireDB is open domain.",1 Introduction,[0],[0]
It contains a broad range of expressions of desires and goal statements in personal narratives.,1 Introduction,[0],[0]
It also includes the narrative context for each desire statement as shown in Figure 2.,1 Introduction,[0],[0]
"We include both prior and
1https://nlds.soe.ucsc.edu/DesireDB
360
post context of the desire expressions, since theories of narrative structure suggest that the evaluation points of a narrative can precede the expression of the events, goals and desires of the narrator (Labov, 1972; Swanson et al., 2014).
",1 Introduction,[0],[0]
"Our approach builds on seminal work on a computational model of Lehnert’s plot units, that applied modern NLP tools to tracking narrative affect states in Aesop’s Fables (Goyal et al., 2010; Lehnert, 1981; Goyal and Riloff, 2013).",1 Introduction,[0],[0]
"Our framing of the problem is also inspired by recent work that identifies three forms of desire expressions in short narratives from MCTest and SimpleWiki and develops models to predict whether desires are fulfilled or unfulfilled (Chaturvedi et al., 2016).",1 Introduction,[0],[0]
"However DesireDB’s narrative and sentence structure is more complex than either MCTest or SimpleWiki (Richardson et al., 2013; Coster and Kauchak, 2011).
",1 Introduction,[0],[0]
"We propose new features (Sec 4.1), as well as testing features used in previous work, and apply different classifiers to model desire fulfillment in our corpus.",1 Introduction,[0],[0]
We also directly compare to results on MCTest and SimpleWiki (Sec 4.4).,1 Introduction,[0],[0]
We apply LSTM models that distinguish between prior and post context and capture the flow of the narrative.,1 Introduction,[0],[0]
"Our best system, a Skip-Thought RNN model, achieves an F-measure of 0.70, while a logistic regression system achieves 0.66.",1 Introduction,[0],[0]
"Our models and features outperform Chaturvedi et al. (2016) on MCTest and SimpleWiki, while providing new results for a new corpus for tracking desires in first-person narratives.",1 Introduction,[0],[0]
"Moreover, analysis of our results shows that features representing the discourse structure (such as overt discourse relation markers) are the best predictors of fulfillment status of a desire or goal.",1 Introduction,[0],[0]
"We also show that both prior and post context are important for this task.
",1 Introduction,[0],[0]
We discuss related work in Sec. 2 and describe our corpus and annotations in Sec. 3.,1 Introduction,[0],[0]
Section 4 presents our features and methods for modeling desire fulfillment in narratives along with the experiments and results including comparison to previous work.,1 Introduction,[0],[0]
"Finally, we present conclusions and future directions in Sec. 5.",1 Introduction,[0],[0]
"There has recently been an upsurge in interest in computational models of narrative structure (Lehnert, 1981; Wilensky, 1982) and story understanding (Rahimtoroghi et al., 2016; Swanson
et al., 2014; Ouyang and McKeown, 2015, 2014).",2 Related Work,[0],[0]
"However there has been limited work on computational models for recognizing the expression of the protagonist’s goals and desires in narrative genres.
",2 Related Work,[0],[0]
"Our approach builds on work by Goyal and Riloff (2013) that applied modern NLP tools to track narrative affect states in Aesop’s Fables (Goyal et al., 2010).",2 Related Work,[0],[0]
They present a system called AESOP that uses a number of existing resources to identify affect states of the characters as part of deriving plot units.,2 Related Work,[0],[0]
"The motivation of modeling plot units is the idea that emotional reactions are central to the notion of a narrative and the main plot of a story can be modeled by tracking the transition between the affect states (Lehnert, 1981).",2 Related Work,[0],[0]
The AESOP system identifies affect states and creates links between them to model plot units and is evaluated on a small set of two-character fables.,2 Related Work,[0],[0]
They performed a manual annotation to examine different types of affect expressions in the narratives.,2 Related Work,[0],[0]
"Their study shows that many affect states arise from events where a character is acted upon in positive or negative ways, not explicit expression of emotions.",2 Related Work,[0],[0]
They also show that most of the affect states emerge by the expression of goals and plans and goal completion.,2 Related Work,[0],[0]
"Some of our features are motivated by the idea that implicit sentiment polarity can represent success or failure of goals and can be used to better model desire and goal
fulfillment in a narrative (Reed et al., 2017), although we cannot directly compare our findings to theirs because their annotations are not publicly available.
",2 Related Work,[0],[0]
"Chaturvedi et al. (2016) exploit two deliberately simplified datasets in order to model desire and its fulfillment: MCTest which contains 660 stories limited to content understandable by 7-year old children, and, SimpleWiki created from a dump of the Simple English Wikipedia discarding all the lists, tables and titles.",2 Related Work,[0],[0]
"They use desire statements matching a list of three verb phrases, wanted to, hoped to, and wished to.",2 Related Work,[0],[0]
Their context representation consists of five or fewer sentences following the desire expression.,2 Related Work,[0],[0]
They use BOW (Bag of Words) as baseline and apply unstructured and structured models for desire fulfillment modeling with different features motivated by narrative structure.,2 Related Work,[0],[0]
Their best result is achieved with a structured prediction model called Latent Structured Narrative Model (LSNM) which models the evolution of the narrative by associating a latent variable with each fragment of the context in the data.,2 Related Work,[0],[0]
"Their best unstructured model is a Logistic Regression classifier that uses all of their features.
",2 Related Work,[0],[0]
"Recent work on computational models of semantics provides an evaluation test for story understanding (Mostafazadeh et al., 2017).",2 Related Work,[0],[0]
"The task includes four-sentence stories, each with two possible endings where only one is correct.",2 Related Work,[0],[0]
"The goal is for each system to select the correct ending of the story by modeling different levels of semantics in narratives, such as lexical, sentential and discourse-level.",2 Related Work,[0],[0]
"The highest performing model with 75% accuracy used a linear regression classifier with several features such as neural language models and stylistic features to model the story coherence (Schwartz et al., 2017).",2 Related Work,[0],[0]
The results from other systems showed that sentiment is an important factor and using only sentiment features could achieve about 65% accuracy on the test.,2 Related Work,[0],[0]
DesireDB aims to provide a testbed for modeling desire and goals in personal narrative and predicting their fulfillment status.,3 DesireDB Corpus,[0],[0]
"We develop a systematic method to identify desire and goal statements, and then collect annotations to create goldstandard labels of fulfillment status as well as spans of text marked as evidence.",3 DesireDB Corpus,[0],[0]
"Our corpus is a subset of the Spinn3r corpus (Burton et al., 2011, 2009), consisting of firstperson narratives from six personal blog domains: livejournal.com, wordpress.com, blogspot.com, spaces.live.com, typepad.com, travelpod.com.",3.1 Identifying Desires and Goals,[0],[0]
"To create our dataset, we select only desire expressions involving some version of the first-person.",3.1 Identifying Desires and Goals,[0],[0]
"In first-person narratives, the narrator and protagonist naturally align which makes it much easier to identify and track the protagonist than in fiction or historical genre.",3.1 Identifying Desires and Goals,[0],[0]
"Thus, selecting narrative passages with expressions of desire relating to the first-person are very likely to discuss subsequent behaviors to achieve that desire and the end result.",3.1 Identifying Desires and Goals,[0],[0]
"Put simply, zooming in on first-person desires means that desire and its aftermath are more likely to be highly topical for the narrative.",3.1 Identifying Desires and Goals,[0],[0]
"This corpus, then, is highly suitable as a testbed for modeling human desires and their fulfillment.
",3.1 Identifying Desires and Goals,[0],[0]
"Human desires and goals can be expressed linguistically in many different ways, including both explicit verbal and nominal markers of desire or necessity (e.g., want, hope) and more general markers of urges (e.g., craving, hunger, thirst).",3.1 Identifying Desires and Goals,[0],[0]
"To systematically discover predicates that specify desires, we browsed FrameNet 1.7 (Baker et al., 1998) selecting frames that seemed likely to contain lexical units specifying desires: Beingnecessary, Desiring, Have-as-a-demand, Needing, Offer, Purpose, Request, Required-event, Scheduling, Seeking, Seeking-to-achieve, Stimulus-focus, Stimulate-emotion, and Worry.",3.1 Identifying Desires and Goals,[0],[0]
"We then selected 100 representative instances of that frame in English Gigaword (Parker et al., 2011) by first selecting the 10 most frequent lexical units in that frame, and then selecting 10 random instances per lexical unit.",3.1 Identifying Desires and Goals,[0],[0]
"One of the authors examined each set of 100 instances, estimating for each sentence whether the predicate specifies a goal that the surrounding text picks up on.",3.1 Identifying Desires and Goals,[0],[0]
"Because we were looking for predicates that reliably specify desires that motivate a protagonist’s actions, we eliminated frames where less than 80% of the sentences showed this characteristic.
",3.1 Identifying Desires and Goals,[0],[0]
"This resulted in a downsample to the following four frames: Desiring, Needing, Purpose, and Request.",3.1 Identifying Desires and Goals,[0],[0]
We selected only the verbal lexical units because we found that verbs were more likely to introduce goals than nouns or adjectives.,3.1 Identifying Desires and Goals,[0],[0]
"We examined 100 instances for each verbal lex-
ical unit, discarding as before.",3.1 Identifying Desires and Goals,[0],[0]
This resulted in 37 verbs.,3.1 Identifying Desires and Goals,[0],[0]
"For each verb, we systematically constructed and coded all past forms of the verb (e.g., was [verb]ing, had [verb]ed, had been [verb]ing, [verb]ed, didn’t",3.1 Identifying Desires and Goals,[0],[0]
"[verb], etc.)",3.1 Identifying Desires and Goals,[0],[0]
"because we posited that morphological form itself may convey likelihood of fulfillment (e.g., a past perfect I had wanted to ... signals that something changed, either the desire or fulfillment).",3.1 Identifying Desires and Goals,[0],[0]
"We initially experimented with both past and (historical) present, but past tense verb patterns resulted in much higher precision.",3.1 Identifying Desires and Goals,[0],[0]
"We counted the instances of these patterns in our dataset, and retained only those lemmas with at least 1000 instances across the corpus.
",3.1 Identifying Desires and Goals,[0],[0]
"We extract stories containing the verbal patterns of desire, with five sentences before and after the desire expression sentence as context (See Fig. 2).",3.1 Identifying Desires and Goals,[0],[0]
Our annotation results provide support that the evidence of desire fulfillment can be expressed before the desire statement.,3.1 Identifying Desires and Goals,[0],[0]
We also study the effect of prior and post context in understanding desire fulfillment in our experiments (Section 4) and show that using the narrative context preceding the desire statement improves the results.,3.1 Identifying Desires and Goals,[0],[0]
"We extracted ∼600K desire expressions with their context, and then sample 3,680 instances for annotation.",3.2 Data Annotation,[0],[0]
"This subset consists of 16 verbal patterns (when collapsing all morphological forms to their
head word).",3.2 Data Annotation,[0],[0]
A group of pre-qualified Mechanical Turkers then labelled each instance.,3.2 Data Annotation,[0],[0]
"The annotators labelled the fulfillment status of the desire expression sentence based on the prior and post context, by choosing from three labels: Fulfilled, Unfulfilled, and Unknown from the context.",3.2 Data Annotation,[0],[0]
They were also asked to mark the evidence for the label they had chosen by specifying a span of text in the narrative.,3.2 Data Annotation,[0],[0]
"For each data instance, we asked the Turkers to mark the subject of the desire expression and determine if the expressed desire is hypothetical (e.g., a conditional sentence) or not.
",3.2 Data Annotation,[0],[0]
The annotators were selected from a list of prequalified workers who had successfully passed a test on a textual entailment task with 100% correct answers.,3.2 Data Annotation,[0],[0]
They were provided with detailed instructions and examples as to how to label the desires and mark the evidence.,3.2 Data Annotation,[0],[0]
We also specified the desire expression verbal pattern using square brackets (as shown in Fig. 1 and 2) for more clarity.,3.2 Data Annotation,[0],[0]
Three annotators were assigned to work on each data instance.,3.2 Data Annotation,[0],[0]
"To generate the gold-standard labels we used majority vote and the cases with no agreement were labeled as ‘None’.
",3.2 Data Annotation,[0],[0]
"Table 1 reports the distribution of data and goldstandard labels (Ful:Fulfilled, Unf:Unfulfilled, Unk:",3.2 Data Annotation,[0],[0]
Unknown from the context).,3.2 Data Annotation,[0],[0]
About half of the desire expressions (53%) were labeled Fulfilled and about one third (31%) were labeled Unfulfilled.,3.2 Data Annotation,[0],[0]
"The annotators didn’t agree on about 2% of the instances, that were labeled None.",3.2 Data Annotation,[0],[0]
"As Tabel 1 shows, the distribution of labels is not uniform across different verbal patterns.",3.2 Data Annotation,[0],[0]
"For in-
stance, decided to and couldn’t wait are highly skewed towards Fulfilled as opposed to hoped to which includes 68% Unfulfilled instances.",3.2 Data Annotation,[0],[0]
"Some patterns seem to be harder to annotate, like wished to, which has the highest rate of Unknown (30%) and None (8%) among all.
",3.2 Data Annotation,[0],[0]
"Other than fulfillment status, for each data instance in our corpus we include the agreementscore which is the number of annotators that agreed on the assigned label.",3.2 Data Annotation,[0],[0]
"In addition, we provide the evidence as a part of the DesireDB data, by merging the text spans marked by the annotators as evidence.",3.2 Data Annotation,[0],[0]
"We compared the evidence spans pairwise to measure the overlap-score, indicating the number of pairs of annotators with overlapping responses.",3.2 Data Annotation,[0],[0]
An example is shown in Figure 3.,3.2 Data Annotation,[0],[0]
"The first part is the extracted data including the desire expression with prior and post context, and the second part is the gold-standard annotations.
",3.2 Data Annotation,[0],[0]
"To assess inter-annotator agreement for Fulfillment, we calculated Krippendorff-alpha Kappa (Krippendorff, 1970, 2004) for pairwise inter-annotator reliability, and, the average of Kappa between each annotator and the majority vote.",3.2 Data Annotation,[0],[0]
These two metrics are 0.63 and 0.88 respectively.,3.2 Data Annotation,[0],[0]
"Overall, 66% of the data was labeled with total agreement (where all three annotators agreed on the same label) and about 32% of data was labeled by two agreements and one disagreement.",3.2 Data Annotation,[0],[0]
We also examined the agreements across each label separately.,3.2 Data Annotation,[0],[0]
"For Fulfilled class, total agreement rate is 75%, which for Unfulfilled is 67%, and on Unknown from the context is 41%.",3.2 Data Annotation,[0],[0]
We believe this indicates that annotating unfulfilled desires was harder than fulfilled cases.,3.2 Data Annotation,[0],[0]
"For evidence marking, in 79% of the data all three annotators marked overlapping spans.",3.2 Data Annotation,[0],[0]
"We conducted a range of experiments on predicting fulfillment status of desires and goals, using different features and models, including LSTM architectures that can encode the sequential structure of the narratives.",4 Modeling Desire Fulfillment,[0],[0]
We first describe our features and models.,4 Modeling Desire Fulfillment,[0],[0]
"Then, we present our feature analysis study to examine their importance in modeling fulfillment.",4 Modeling Desire Fulfillment,[0],[0]
Finally we provide results of direct comparison to previous work on the existing corpora.,4 Modeling Desire Fulfillment,[0],[0]
"In our original informal examination of the DesireDB development data, we noticed several ways that a writer can signal (lack of) fulfillment of a desire like “I hoped to pick up a dictionary”.",4.1 Features Description,[0],[0]
"First, they may mention an outcome that entails (“The book I bought was...”) or strongly implies fulfillment (“I went back home happily.”).",4.1 Features Description,[0],[0]
"However, we noticed that in many cases of fulfillment, the ‘marker’ was simply the absence of any mention that things went wrong.",4.1 Features Description,[0],[0]
"For lack of fulfillment, while we found cases where writers explicitly state that their desire wasn’t met, we noted many instances where evidence came from mentioning that an enabling condition for fulfillment wasn’t met (“The bookstore was closed.”).
",4.1 Features Description,[0],[0]
"True machine understanding of these kinds of narrative structures requires robust models of the complex interplay of semantics (including negation) as well as world knowledge about the scripts for tasks like buying books, including what count as enabling conditions and entailers for fulfillment.",4.1 Features Description,[0],[0]
"While we hope to explore more articulated models in the future, for our experiments we considered reasonable proxies for the conditions mentioned above using existing resources (note that we also tested LSTM models described below, which may implicitly learn such relationships with sufficient data).",4.1 Features Description,[0],[0]
"One set (Desire Features) indexes properties of the desire expression (e.g., the desire verb) as well as overlap between the desired object/event and the surrounding context.",4.1 Features Description,[0],[0]
"The remaining features attempt to find general markers
for success or failure.",4.1 Features Description,[0],[0]
"One set (Discourse Features) looks for overt discourse relation markers that signal violation of expectation (e.g., ‘but’, ‘however’) or its opposite (e.g., ‘so’).",4.1 Features Description,[0],[0]
"Another uses the Connotation Lexicon (Feng et al., 2013) to model whether the context provides a positive or negative event.",4.1 Features Description,[0],[0]
All of these features are inspired by Chaturvedi et al. (2016).,4.1 Features Description,[0],[0]
"Finally, motivated by the AESOP modeling of affect states for identifying plot units (Goyal and Riloff, 2013), one set of features (Sentiment-Flow-Features) indexes whether there has been a change in sentiment in the surrounding context (which might be the mention of a thwarted effort or a hard won victory).",4.1 Features Description,[0],[0]
"Figure 4 provides an example of this.
",4.1 Features Description,[0],[0]
"In addition to a BOW (Bag of Words) baseline, we extracted the four types of features mentioned above.",4.1 Features Description,[0],[0]
"For features that examine the context around the desire expression, our experiments used the pre-context, the post-context, or both, as discussed below; context features are computed per sentence i of the context.",4.1 Features Description,[0],[0]
We also tested various ablations of these features described below as well.,4.1 Features Description,[0],[0]
"We now describe the full set of features in more detail.
",4.1 Features Description,[0],[0]
Desire-Features.,4.1 Features Description,[0],[0]
"From a desire expression of the form ‘X Ved S’, we extract the lexical feature",4.1 Features Description,[0],[0]
"Desire-Verb, the lemma for V. We also extract a list of focal words, the content words in embedded sentence S.",4.1 Features Description,[0],[0]
"In Figure 4, these are ‘do’, ‘go’, and ‘run’.",4.1 Features Description,[0],[0]
"The features Focal{Word,Synonym,Antonym}-Mention-i counts how many times each word, its synonyms, or its antonyms in WordNet (Fellbaum, 1998) are in the context, respectively.",4.1 Features Description,[0],[0]
"Similarly, Desire-SubjectMention-i marks if subject X is mentioned in the context.",4.1 Features Description,[0],[0]
"Finally, boolean First-Person-Subject indicates if X is first person (‘I’, ‘we’).
",4.1 Features Description,[0],[0]
Discourse-Features.,4.1 Features Description,[0],[0]
This class of features count how many of two classes of discourse relation markers (Violated-Expectation–i vs. MeetingExpectation–i) occur in the context.,4.1 Features Description,[0],[0]
"For the classes, we manually coded all overt discourse relation markers in the Penn Discourse",4.1 Features Description,[0],[0]
"Treebank three ways(violation, meeting, or neutral), leading to 15 meeting markers (‘accordingly’, ‘so’, ‘ultimately’, ‘finally’) and 31 violating (‘although’, ‘rather’, ‘yet’, ‘but’).",4.1 Features Description,[0],[0]
"In addition, we also tracked the presence of the most frequent of these (‘so’ and ‘but’, respectively) in the desire sentence itself by the booleans So-Present and But-Present.",4.1 Features Description,[0],[0]
Connotation-Features.,"1,366 953 380 70 2,780",[0],[0]
"Beyond the use of WordNet expansion for Focal-Word-Mention-i, we also used the Connotation Lexicon (Feng et al., 2013), a lexical resource marking very general connotation polarities (positive or negative) of words (as opposed to more specific sentiment lexicons).","1,366 953 380 70 2,780",[0],[0]
Connotation-Agree-i counts for each word w in focal words the number of words in the context that have the same connotation polarity as w. Connotation-Disgree-i is defined similarly.,"1,366 953 380 70 2,780",[0],[0]
Sentiment-Flow-Features.,"1,366 953 380 70 2,780",[0],[0]
"To model affect states, we compute a sentiment score for the desire expression sentence as well as each sentence in the context.","1,366 953 380 70 2,780",[0],[0]
"Then for each sentence of the context, the booleans Sentiment-Agree-i and SentimentDisagree-i mark whether that sentence and the desire expression sentence have the same sentiment polarity (see Figure 4).","1,366 953 380 70 2,780",[0],[0]
"While there is evidence suggesting that models of implicit sentiment (e.g., (Goyal et al., 2010; Reed et al., 2017)) could do much better at tracking affect states, here we use the Stanford Sentiment system (Socher et al., 2013).","1,366 953 380 70 2,780",[0],[0]
Our features are motivated by narrative characteristics but do not directly capture the sequential structure of the narratives.,4.2 LSTM Models,[0],[0]
"We thus apply neural network models suitable for sequence learning, in order to directly encode the order of the sentences in the story and distinguish between prior and post context.",4.2 LSTM Models,[0.9512586167661994],['Variety in annotations Having multiple labels to predict allows for studying the relations between labels.']
"We use two different architectures of LSTM (Long Short-Term Memory) (Hochreiter and Schmidhuber, 1997) models to generate sentence embeddings and then apply a three-layer RNN (Recurrent Neural Network) for classification.",4.2 LSTM Models,[0],[0]
"We used Keras (Chollet, 2015) as a deep learning toolkit for implementing our experiments.",4.2 LSTM Models,[0],[0]
Skip-Thoughts.,4.2 LSTM Models,[0],[0]
"This is a sequential model that uses pre-trained skip-thoughts model (Kiros et al., 2015) as the embedding of sentences.",4.2 LSTM Models,[0],[0]
"It first concatenates features, if any, with embeddings, and then uses LSTM to generate a single representation for the context sequence, which is the output of the last unit.",4.2 LSTM Models,[0],[0]
"That single representation is then
concatenated with embedding-feature concatenation of desire sentence and is fed into a multi-layer network to yield a single binary output.",4.2 LSTM Models,[0],[0]
CNN-RNN.,4.2 LSTM Models,[0],[0]
"The only difference between the CNN-RNN model and Skip-Thought is that it uses the 1-dimensional convolution with maxover-time pooling introduced in (Kim, 2014) to generate the sentence embedding from word embedding, instead of using skip-thoughts.",4.2 LSTM Models,[0],[0]
"We use Google News Vectors (Mikolov et al., 2013) for the word embedding with different sizes from 1 to 7 for the kernel.
",4.2 LSTM Models,[0],[0]
"For our experiments, we first constructed a subset of DesireDB that we will call SimpleDesireDB, in order to be able to compare more directly to the models and data used in previous work.",4.2 LSTM Models,[0],[0]
"Chaturvedi et al. (2016) used three verb phrases to identify desire expressions (wanted to, hoped to, and wished to), so we selected a portion of our corpus including these patterns along with two other expressions (couldn’t wait to and decided to) to have sufficient data for experiments.",4.2 LSTM Models,[0],[0]
Table 2 shows the distribution of labels in this subset.,4.2 LSTM Models,[0],[0]
"For classification experiments we use data labeled as Fulfilled and Unfulfilled, thus the majority class accuracy is 59%.",4.2 LSTM Models,[0],[0]
"We split the data into Train (1,656), Dev (327), and Test (336) sets for the experiments.
",4.2 LSTM Models,[0],[0]
"Results of our two LSTM models for Fulfilled (Ful) and Unfulfilled (Unf) classes and the overall classification task (P:precision, R:recall) on Simple-DesireDB are presented in Table 3.",4.2 LSTM Models,[0],[0]
ALL feature set includes all the features described in Sec. 4.1 (without BOW).,4.2 LSTM Models,[0],[0]
"The results indicate that our features can considerably improve the model, compared to the BOW baseline (F1 improved from
0.65 to 0.70 for Skip-Thought).",4.2 LSTM Models,[0],[0]
"We also conducted 4 sets of experiments to study the importance of prior, post and the whole context in predicting fulfillment status, using our best model.",4.2 LSTM Models,[0],[0]
The results of Skip-Thought using different contextual representations are in Table 4 with ALL features.,4.2 LSTM Models,[0],[0]
The results indicate that adding features from prior context alone improves the results.,4.2 LSTM Models,[0],[0]
"The best results are obtained by including the whole context and desire sentence.
",4.2 LSTM Models,[0],[0]
We then experimented with our best model on all of DesireDB.,4.2 LSTM Models,[0],[0]
"We also trained Naive Bayes, SVM and Logistic Regression (LR) classifiers as baselines, with the best results on the Dev set achieved by Logistic Regression.",4.2 LSTM Models,[0],[0]
Table 5 shows the results of Skip-Thought and LR on DesireDB for different features on the test set.,4.2 LSTM Models,[0],[0]
"Our feature ablation study on the Dev set, discussed in Sec. 4.3, indicates that Discourse features are better predictors of fulfillment status, so we present results using only Discourse features in addition to BOW and ALL.
",4.2 LSTM Models,[0],[0]
All of the results indicate that similar features and methods achieve better results for the Fulfilled class as compared to Unfulfilled.,4.2 LSTM Models,[0],[0]
"We believe the reason is that identifying unfulfillment of a desire or goal is a more difficult task, as discussed in the annotation description in Section 3.2.",4.2 LSTM Models,[0],[0]
"To further our analysis on the annotation disagreements, we examined the cases where only two annotators agreed on the assigned label.",4.2 LSTM Models,[0],[0]
"From the expressions labeled Fulfilled by two annotators, 64% were labeled Unknown from the context by the disagreeing annotator, and only 36% were labeled Unfulfilled.",4.2 LSTM Models,[0],[0]
"However, these numbers for the Unfulfilled class are respectively 49% and 51%, indicating a
stronger disagreement between annotators when labeling Unfulfilled expressions.",4.2 LSTM Models,[0],[0]
We used the InfoGain measure to rank features based on their importance in modeling desire fulfillment.,4.3 Feature Selection Experiments,[0],[0]
"The top 5 features are: But-Present, Post-Context-Connotation-Disagree, Post-Context-Violated-Expectation, Desire-Verb, Is-First-Person.",4.3 Feature Selection Experiments,[0],[0]
We also tested different feature sets separately.,4.3 Feature Selection Experiments,[0],[0]
"We describe our experiment results below.
",4.3 Feature Selection Experiments,[0],[0]
The results of the feature ablation experiments using LR model are shown in Table 6.,4.3 Feature Selection Experiments,[0],[0]
The ALL feature set includes all the features described in Sec. 4.1 (without BOW).,4.3 Feature Selection Experiments,[0],[0]
We obtained high precision and F-measure using the Discourse features.,4.3 Feature Selection Experiments,[0],[0]
"We also experimented with our top feature from the InfoGain analysis, But-Present, which surprisingly achieves a high F-measure, compared to using ALL and Discourse feature sets.",4.3 Feature Selection Experiments,[0],[0]
The last row of Table 6 shows the results of using ALL features excluding But-Present.,4.3 Feature Selection Experiments,[0],[0]
This indicates that features motivated by narrative structure are primarily driving improvement.,4.3 Feature Selection Experiments,[0],[0]
"In previous work Chaturvedi et al. (2016) show that a model representing narrative structure could beat the BOW baseline, but they performed no systematic feature ablation.",4.3 Feature Selection Experiments,[0],[0]
"Our results suggest that ultimately, the presence of “but” is likely a central driver for their improvements as well.",4.3 Feature Selection Experiments,[0],[0]
"We directly compare our methods and features to the most relevant previous work (Chaturvedi et al., 2016).",4.4 Comparison to Previous Work,[0],[0]
They applied their models on two datasets and reported the results for the Fulfilled class.,4.4 Comparison to Previous Work,[0],[0]
"We present the same metrics in Table 7, using our best model Skip-Thought (SkipTh).",4.4 Comparison to Previous Work,[0],[0]
"We also present results of our LR model with our Discourse features, Discourse-LR, trained and tested on their corpora to compare to their features.",4.4 Comparison to Previous Work,[0],[0]
The first three rows show the results from Chaturvedi et al. (2016) for comparison.,4.4 Comparison to Previous Work,[0],[0]
"As described in Sec. 2, they used BOW as baseline, LSNM is their best model, and Unstruct-LR is their unstructured model that uses all of their features with LR.
",4.4 Comparison to Previous Work,[0],[0]
"On both corpora, Discourse-LR outperforms Unstruct-LR, showing that the Discourse features are stronger indicators of the desire fulfillment status when used with LR classifier.",4.4 Comparison to Previous Work,[0],[0]
"In addition, on SimpleWiki, LR-Discourse outperforms their structured model, LSNM (0.46 vs. 0.27 on F-1).",4.4 Comparison to Previous Work,[0],[0]
"We created a novel dataset, DesireDB, for studying the expression of desires and their fulfillment in narrative discourse.",5 Conclusion and Future Work,[0],[0]
"We show that contextual
features help with classification, and that both prior and post context are useful.",5 Conclusion and Future Work,[0],[0]
"Finally, we show that exploiting narrative structure is helpful, both directly in terms of the utility of discourse relation features and indirectly via the superior performance of a Skip-Thought LSTM model.
",5 Conclusion and Future Work,[0],[0]
"In future work, we plan to explore richer features and models for semantic and discourse-based features, as well as the utility of more narrativelyaware features.",5 Conclusion and Future Work,[0],[0]
"For instance, the sentiment flow features roughly track the notion that the arc of a narrative may implicitly reveal resolution of a goal via changes in affect states.",5 Conclusion and Future Work,[0],[0]
"We hope to examine whether there are other similar rough-grained measures of change over the entire narrative that can improve the results.
",5 Conclusion and Future Work,[0],[0]
DesireDB contains annotator-labeled spans for evidence for the annotator’s conclusions.,5 Conclusion and Future Work,[0],[0]
"While we have not used this labeling, we plan to use it in future work.",5 Conclusion and Future Work,[0],[0]
"Finally, we hope to turn to automatically detecting instances of desire expressions that give rise to the kind of goal-oriented narratives DesireDB contains.",5 Conclusion and Future Work,[0],[0]
"Here we have used highprecision search patterns but our annotations show that such patterns still admitted 134 hypothetical desires (e.g., ‘If I had wanted to buy a book’).",5 Conclusion and Future Work,[0],[0]
It would appear that distinguishing hypothetical vs. real desires itself could be an interesting problem.,5 Conclusion and Future Work,[0],[0]
"This research was supported by Nuance Foundation Grant SC-14-74, NSF Grant IIS-1302668-002 and IIS-1321102.",Acknowledgments,[0],[0]
"Many genres of natural language text are narratively structured, a testament to our predilection for organizing our experiences as narratives.",abstractText,[0],[0]
There is broad consensus that understanding a narrative requires identifying and tracking the goals and desires of the characters and their narrative outcomes.,abstractText,[0],[0]
"However, to date, there has been limited work on computational models for this problem.",abstractText,[0],[0]
"We introduce a new dataset, DesireDB, which includes goldstandard labels for identifying statements of desire, textual evidence for desire fulfillment, and annotations for whether the stated desire is fulfilled given the evidence in the narrative context.",abstractText,[0],[0]
"We report experiments on tracking desire fulfillment using different methods, and show that LSTM Skip-Thought model achieves F-measure of 0.7 on our corpus.",abstractText,[0],[0]
Modelling Protagonist Goals and Desires in First-Person Narrative,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1128–1137 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1128
We collect a large corpus of Twitter conversations that include emojis in the response and assume the emojis convey the underlying emotions of the sentence. We investigate several conditional variational autoencoders training on these conversations, which allow us to use emojis to control the emotion of the generated text. Experimentally, we show in our quantitative and qualitative analyses that the proposed models can successfully generate highquality abstractive conversation responses in accordance with designated emotions.",text,[0],[0]
A critical research problem for artificial intelligence is to design intelligent agents that can perceive and generate human emotions.,1 Introduction,[0],[0]
"In the past decade, there has been significant progress in sentiment analysis (Pang et al., 2002, 2008; Liu, 2012) and natural language understanding—e.g., classifying the sentiment of online reviews.",1 Introduction,[0],[0]
"To build empathetic conversational agents, machines must also have the ability to learn to generate emotional sentences.
",1 Introduction,[0],[0]
"One of the major challenges is the lack of largescale, manually labeled emotional text datasets.",1 Introduction,[0],[0]
"Due to the cost and complexity of manual annotation, most prior research studies primarily focus on small-sized labeled datasets (Pang et al., 2002; Maas et al., 2011; Socher et al., 2013), which are not ideal for training deep learning models with a large number of parameters.
",1 Introduction,[0],[0]
"In recent years, a handful of medium to large scale, emotional corpora in the area of emotion analysis (Go et al., 2016) and dialog (Li et al., 2017b) are proposed.",1 Introduction,[0],[0]
"However, all of them are limited to a traditional, small set of labels, for example, “happiness,” “sadness,” “anger,” etc. or simply binary “positive” and “negative.”",1 Introduction,[0],[0]
"Such coarse-grained classification labels make it difficult to capture the nuances of human emotion.
",1 Introduction,[0],[0]
"To avoid the cost of human annotation, we propose the use of naturally-occurring emoji-rich Twitter data.",1 Introduction,[0],[0]
We construct a dataset using Twitter conversations with emojis in the response.,1 Introduction,[0],[0]
"The fine-grained emojis chosen by the users in the response can be seen as the natural label for the emotion of the response.
",1 Introduction,[0],[0]
We assume that the emotions and nuances of emojis are established through the extensive usage by Twitter users.,1 Introduction,[0],[0]
"If we can create agents that
are able to imitate Twitter users’ language style when using those emojis, we claim that, to some extent, we have captured those emotions.",1 Introduction,[0],[0]
"Using a large collection of Twitter conversations, we then trained a conditional generative model to automatically generate the emotional responses.",1 Introduction,[0],[0]
"Figure 1 shows an example.
",1 Introduction,[0],[0]
"To generate emotional responses in dialogs, another technical challenge is to control the target emotion labels.",1 Introduction,[0],[0]
"In contrast to existing work (Huang et al., 2017) that uses information retrieval to generate emotional responses, the research question we are pursuing in this paper, is to design novel techniques that can generate abstractive responses of any given arbitrary emotions, without having human annotators to label a huge amount of training data.
",1 Introduction,[0],[0]
"To control the target emotion of the response, we investigate several encoder-decoder generation models, including a standard attention-based SEQ2SEQ model as the base model, and a more sophisticated CVAE model (Kingma and Welling, 2013; Sohn et al., 2015), as VAE is recently found convenient in dialog generation (Zhao et al., 2017).
",1 Introduction,[0],[0]
"To explicitly improve emotion expression, we then experiment with several extensions to the CVAE model, including a hybrid objective with policy gradient.",1 Introduction,[0],[0]
"The performance in emotion expression is automatically evaluated by a separate sentence-to-emoji classifier (Felbo et al., 2017).",1 Introduction,[0],[0]
"Additionally, we conducted a human evaluation to assess the quality of the generated emotional text.
",1 Introduction,[0],[0]
Results suggest that our method is capable of generating state-of-the-art emotional text at scale.,1 Introduction,[0],[0]
"Our main contributions are three-fold:
• We provide a publicly available, large-scale dataset of Twitter conversation-pairs naturally labeled with fine-grained emojis.
",1 Introduction,[0],[0]
"• We are the first to use naturally labeled emojis for conducting large-scale emotional response generation for dialog.
",1 Introduction,[0],[0]
"• We apply several state-of-the-art generative models to train an emotional response generation system, and analysis confirms that our models deliver strong performance.
",1 Introduction,[0],[0]
"In the next section, we outline related work on sentiment analysis and emoji on Twitter data, as well as neural generative models.",1 Introduction,[0],[0]
"Then, we will
introduce our new emotional research dataset and formalize the task.",1 Introduction,[0],[0]
"Next, we will describe the neural models we applied for the task.",1 Introduction,[0],[0]
"Finally, we will show automatic evaluation and human evaluation results, and some generated examples.",1 Introduction,[0],[0]
Experiment details can be found in supplementary materials.,1 Introduction,[0],[0]
"In natural language processing, sentiment analysis (Pang et al., 2002) is an area that involves designing algorithms for understanding emotional text.",2 Related Work,[0],[0]
Our work is aligned with some recent studies on using emoji-rich Twitter data for sentiment classification.,2 Related Work,[0],[0]
"Eisner et al. (2016) proposes a method for training emoji embedding EMOJI2VEC, and combined with word2vec (Mikolov et al., 2013), they apply the embeddings for sentiment classification.",2 Related Work,[0],[0]
"DeepMoji (Felbo et al., 2017) is closely related to our study: It makes use of a large, naturally labeled Twitter emoji dataset, and train an attentive bi-directional long short-term memory network (Hochreiter and Schmidhuber, 1997) model for sentiment analysis.",2 Related Work,[0],[0]
"Instead of building a sentiment classifier, our work focuses on generating emotional responses, given the context and the target emoji.
",2 Related Work,[0],[0]
"Our work is also in line with the recent progress of the application of Variational Autoencoder (VAE) (Kingma and Welling, 2013) in dialog generation.",2 Related Work,[0],[0]
"VAE (Kingma and Welling, 2013) encodes data in a probability distribution, and then samples from the distribution to generate examples.",2 Related Work,[0],[0]
"However, the original frameworks do not support end-to-end generation.",2 Related Work,[0],[0]
"Conditional VAE (CVAE) (Sohn et al., 2015; Larsen et al., 2015) was proposed to incorporate conditioning option in the generative process.",2 Related Work,[0],[0]
"Recent research in dialog generation shows that language generated by VAE models enjoy significantly greater diversity than traditional SEQ2SEQ models (Zhao et al., 2017), which is a preferable property toward building a true-to-life dialog agents.
",2 Related Work,[0],[0]
"In dialog research, our work aligns with recent advances in sequence-to-sequence models (Sutskever et al., 2014) using long shortterm memory networks (Hochreiter and Schmidhuber, 1997).",2 Related Work,[0],[0]
A slightly altered version of this model serves as our base model.,2 Related Work,[0],[0]
Our modification enabled it to condition on single emojis.,2 Related Work,[0],[0]
"Li
et al. (2016) use a reinforcement learning algorithm to improve the vanilla sequence-to-sequence model for non-task-oriented dialog systems, but their reinforced and its follow-up adversarial models (Li et al., 2017a) also do not model emotions or conditional labels.",2 Related Work,[0],[0]
"Zhao et al. (2017) recently introduced conditional VAE for dialog modeling, but neither did they model emotions in the conversations, nor explore reinforcement learning to improve results.",2 Related Work,[0],[0]
"Given a dialog history, Xie et.",2 Related Work,[0],[0]
al.’s work recommends suitable emojis for current conversation.,2 Related Work,[0],[0]
Xie et.,2 Related Work,[0],[0]
"al. (2016)compress the dialog history to vector representation through a hierarchical RNN and then map it to a emoji by a classifier, while in our model, the representation for original tweet, combined with the emoji embedding, is used to generate a response.",2 Related Work,[0],[0]
We start by describing our dataset and approaches to collecting and processing the data.,3 Dataset,[0],[0]
"Social media is a natural source of conversations, and people use emojis extensively within their posts.",3 Dataset,[0],[0]
"However, not all emojis are used to express emotion and frequency of emojis are unevenly distributed.",3 Dataset,[0],[0]
"Inspired by DeepMoji (Felbo et al., 2017), we use 64 common emojis as labels (see Table 1), and collect a large corpus of Twitter conversations con-
taining those emojis.",3 Dataset,[0],[0]
Note that emojis with the difference only in skin tone are considered the same emoji.,3 Dataset,[0],[0]
"We crawled conversation pairs consisting of an original post and a response on Twitter from 12th to 14th of August, 2017.",3.1 Data Collection,[0],[0]
The response to a conversation must include at least one of the 64 emoji labels.,3.1 Data Collection,[0],[0]
"Due to the limit of Twitter streaming API, tweets are filtered on the basis of words.",3.1 Data Collection,[0],[0]
"In our case, a tweet can be reached only if at least one of the 64 emojis is used as a word, meaning it has to be a single character separated by blank space.",3.1 Data Collection,[0],[0]
"However, this kind of tweets is arguably cleaner, as it is often the case that this emoji is used to wrap up the whole post and clusters of repeated emojis are less likely to appear in such tweets.
",3.1 Data Collection,[0],[0]
"For both original tweets and responses, only English tweets without multimedia contents (such as URL, image or video) are allowed, since we assume that those contents are as important as the text itself for the machine to understand the conversation.",3.1 Data Collection,[0],[0]
"If a tweet contains less than three alphabetical words, the conversation is not included in the dataset.",3.1 Data Collection,[0],[0]
Then we label responses with emojis.,3.2 Emoji Labeling,[0],[0]
"If there are multiple types of emoji in a response, we use the emoji with most occurrences inside the response.",3.2 Emoji Labeling,[0],[0]
"Among those emojis with same occurrences, we choose the least frequent one across the whole corpus, on the hypothesis that less frequent tokens better represent what the user wants to express.",3.2 Emoji Labeling,[0],[0]
See Figure 2 for example.,3.2 Emoji Labeling,[0],[0]
"During preprocessing, all mentions and hashtags are removed, and punctuation1 and emojis are separated if they are adjacent to words.",3.3 Data Preprocessing,[0],[0]
"Words with digits are all treated as the same special token.
",3.3 Data Preprocessing,[0],[0]
"In some cases, users use emojis and symbols in a cluster to express emotion extensively.",3.3 Data Preprocessing,[0],[0]
"To normalize the data, words with more than two repeated letters, symbol strings of more than one repeated punctuation symbols or emojis are shortened, for example, ‘!!!!’",3.3 Data Preprocessing,[0],[0]
"is shortened to ‘!’, and ‘yessss’ to ‘yess’.",3.3 Data Preprocessing,[0],[0]
Note that we do not reduce duplicate letters completely and convert the word to the ‘correct’ spelling (‘yes’ in the example) since the length of repeated letters represents the intensity of emotion.,3.3 Data Preprocessing,[0],[0]
"By distinguishing ‘yess’ from ‘yes’, the emotional intensity is partially preserved in our dataset.
",3.3 Data Preprocessing,[0],[0]
"Then all symbols, emojis, and words are tokenized.",3.3 Data Preprocessing,[0],[0]
"Finally, we build a vocabulary of size 20K according to token frequency.",3.3 Data Preprocessing,[0],[0]
"Any tokens outside the vocabulary are replaced by the same special token.
",3.3 Data Preprocessing,[0],[0]
"We randomly split the corpus into 596,959 /32,600/32,600",3.3 Data Preprocessing,[0],[0]
conversation pairs for train /validation/test set2.,3.3 Data Preprocessing,[0],[0]
Distribution of emoji labels within the corpus is presented in Table 1.,3.3 Data Preprocessing,[0],[0]
"In this work, our goal is to generate emotional responses to tweets with the emotion specified by an emoji label.",4 Generative Models,[0],[0]
We assembled several generative models and trained them on our dataset.,4 Generative Models,[0],[0]
"Traditional studies use deep recurrent architecture and encoder-decoder models to generate conversation responses, mapping original texts to target responses.",4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
"Here we use a sequence-to-sequence (SEQ2SEQ) model (Sutskever et al., 2014) with global attention mechanism (Luong et al., 2015) as our base model (See Figure 3).
",4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
We use randomly initialized embedding vectors to represent each word.,4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
"To specifically model the
1Emoticons (e.g. ‘:)’, ‘(-:’) are made of mostly punctuation marks.",4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
They are not examined in this paper.,4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
"Common emoticons are treated as words during preprocessing.
",4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
2We will release the dataset with all tweets in its original form before preprocessing.,4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
"To comply with Twitter’s policy, we will include the tweet IDs in our release, and provide a script for downloading the tweets using the official API.",4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
"No information of the tweet posters is collected.
",4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
"emotion, we compute the embedding vector of the emoji label the same way as word embeddings.",4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
The emoji embedding is further reduced to smaller size vector ve through a dense layer.,4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
"We pass the embeddings of original tweets through a bidirectional RNN encoder of GRU cells (Schuster and Paliwal, 1997; Chung et al., 2014).",4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
The encoder outputs a vector vo that represents the original tweet.,4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
Then vo and ve are concatenated and fed to a 1-layer RNN decoder of GRU cells.,4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
A response is then generated from the decoder.,4.1 Base: Attention-Based Sequence-to-Sequence Model,[0],[0]
"Having similar encoder-decoder structures, SEQ2SEQ can be easily extended to a Conditional Variational Autoencoder (CVAE) (Sohn et al., 2015).",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"Figure 3 illustrates the model: response encoder, recognition network, and prior network
are added on top of the SEQ2SEQ model.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"Response encoder has the same structure to original tweet encoder, but it has separate parameters.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"We use embeddings to represent Twitter responses and pass them through response encoder.
",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"Mathematically, CVAE is trained by maximizing a variational lower bound on the conditional likelihood of x given c, according to:
p(x|c) = ∫ p(x|z, c)p(z|c)dz (1)
z, c and x are random variables.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
z is the latent variable.,4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"In our case, the condition c =",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"[vo; ve], target x represents the response.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"Decoder is used to approximate p(x|z, c), denoted as pD(x|z, c).",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"Prior network is introduced to approximate p(z|c), denoted as pP (z|c).",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"Recognition network qR(z|x, c) is introduced to approximate true posterior p(z|x, c) and will be absent during generation phase.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"By assuming that the latent variable has a multivariate Gaussian distribution with a diagonal covariance matrix, the lower bound to log p(x|c) can then be written by:
−L(θD, θP , θR;x, c) =",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"KL(qR(z|x, c)||pP (z|c)) −EqR(z|x,c)(log pD(x|z, c))
",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"(2)
θD, θP , θR are parameters of those networks.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"In recognition/prior network, we first pass the variables through an MLP to get the mean and log variance of z’s distribution.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"Then we run a reparameterization trick (Kingma and Welling, 2013) to sample latent variables.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"During training, z by the recognition network is passed to the decoder and trained to approximate z′ by the prior network.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"While during testing, the target response is absent, and z′ by the prior network is passed to the decoder.
",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"Our CVAE inherits the same attention mechanism from the base model connecting the original tweet encoder to the decoder, which makes our model deviate from previous works of CVAE on text data.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"Based on the attention memory as well as c and z, a response is finally generated from the decoder.
",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"When handling text data, the VAE models that apply recurrent neural networks as the structure of their encoders/decoders may first learn to ignore the latent variable, and explain the data with the more easily optimized decoder.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"The latent
variables lose its functionality, and the VAE deteriorates to a plain SEQ2SEQ model mathematically (Bowman et al., 2015).",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
Some previous methods effectively alleviate this problem.,4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"Such methods are also important to keep a balance between the two items of the loss, namely KL loss and reconstruction loss.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"We use techniques of KL annealing, early stopping (Bowman et al., 2015) and bag-of-word loss (Zhao et al., 2017) in our models.",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"The general loss with bag-of-word loss (see supplementary materials for details) is rewritten as:
L′ =",4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
L+ Lbow (3),4.2 Conditional Variational Autoencoder (CVAE),[0],[0]
"In order to further control the emotion of our generation more explicitly, we combine policy gradient techniques on top of the CVAE above and proposed Reinforced CVAE model for our task.",4.3 Reinforced CVAE,[0],[0]
We first train an emoji classifier on our dataset separately and fix its parameters thereafter.,4.3 Reinforced CVAE,[0],[0]
The classifier is used to produce reward for the policy training.,4.3 Reinforced CVAE,[0],[0]
"It is a skip connected model of Bidirectional GRU-RNN layers (Felbo et al., 2017).
",4.3 Reinforced CVAE,[0],[0]
"During the policy training, we first get the generated response x′ by passing x and c through the CVAE, then feeding generation x′ to classifier and get the probability of the emoji label as reward R. Let θ be parameters of our network, REINFORCE algorithm (Williams, 1992) is used to maximize the expected reward of generated responses:
J (θ) = Ep(x|c)(Rθ(x, c))",4.3 Reinforced CVAE,[0],[0]
"(4)
The gradient of Equation 4 is approximated using the likelihood ratio trick (Glynn, 1990; Williams, 1992):
∇J (θ) =",4.3 Reinforced CVAE,[0],[0]
"(R− r)∇ |x|∑ t log p(xt|c, x1:t−1) (5)
r is the baseline value to keep estimate unbiased and reduce its variance.",4.3 Reinforced CVAE,[0],[0]
"In our case, we directly pass x through emoji classifier and compute the probability of the emoji label as r. The model then encourages response generation that has R > r.
As REINFORCE objective is unrelated to response generation, it may make the generation model quickly deteriorate to some generic responses.",4.3 Reinforced CVAE,[0],[0]
"To stabilize the training process, we propose two straightforward techniques to constrain the policy training:
1.",4.3 Reinforced CVAE,[0],[0]
Adjust rewards according to the position of the emoji label when all labels are ranked from high to low in order of the probability given by the emoji classifier.,4.3 Reinforced CVAE,[0],[0]
"When the probability of the emoji label is of high rank among all possible emojis, we assume that the model has succeeded in emotion expression, thus there is no need to adjust parameters toward higher probability in this response.",4.3 Reinforced CVAE,[0],[0]
"Modified policy gradient is written as:
∇J ′(θ) =",4.3 Reinforced CVAE,[0],[0]
"α(R− r)∇ |x|∑ t log p(xt|c, x1:t−1)
(6)
",4.3 Reinforced CVAE,[0],[0]
where α ∈,4.3 Reinforced CVAE,[0],[0]
"[0, 1] is a variant coefficient.",4.3 Reinforced CVAE,[0],[0]
"The higher R ranks in all types of emoji label, the closer α is to 0.
2.",4.3 Reinforced CVAE,[0],[0]
"Train Reinforced CVAE by a hybrid objective of REINFORCE and variational lower bound objective, learning towards both emotion accuracy and response appropriateness:
minθL′′ = L′",4.3 Reinforced CVAE,[0],[0]
− λJ ′,4.3 Reinforced CVAE,[0],[0]
"(7)
λ is a balancing coefficient, which is set to 1 in our experiments.
",4.3 Reinforced CVAE,[0],[0]
The algorithm outlining the training process of Reinforced CVAE can be found in the supplementary materials.,4.3 Reinforced CVAE,[0],[0]
We conducted several experiments to finalize the hyper-parameters of our models (Table 2).,5 Experimental Results and Analyses,[0],[0]
"During training, fully converged base SEQ2SEQ model is used to initialize its counterparts in CVAE models.",5 Experimental Results and Analyses,[0],[0]
Pretraining is vital to the success of our models since it is essentially hard for them to learn a latent variable space from total randomness.,5 Experimental Results and Analyses,[0],[0]
"For more details, please refer to the supplementary materials.
",5 Experimental Results and Analyses,[0],[0]
"In this section, we first report and analyze the general results of our models, including perplexity, loss and emotion accuracy.",5 Experimental Results and Analyses,[0],[0]
Then we take a closer look at the generation quality as well as our models’ capability of expressing emotion.,5 Experimental Results and Analyses,[0],[0]
"To generally evaluate the performance of our models, we use generation perplexity and top-1/top-5
emoji accuracy on the test set.",5.1 General,[0],[0]
Perplexity indicates how much difficulty the model is having when generating responses.,5.1 General,[0],[0]
"We also use top-5 emoji accuracy, since the meaning of different emojis may overlap with only a subtle difference.",5.1 General,[0],[0]
"The machine may learn that similarity and give multiple possible labels as the answer.
",5.1 General,[0],[0]
Note that we use the same emoji classifier for evaluation.,5.1 General,[0],[0]
"Its accuracy (see supplementary materials) may not seem perfect, but it is the stateof-the-art emoji classifier given so many classes.",5.1 General,[0],[0]
"Also, it’s reasonable to use the same classifier in training for automated evaluation, as is in (Hu et al., 2017).",5.1 General,[0],[0]
"We can obtain meaningful results as long as the classifier is able to capture the semantic relationship between emojis (Felbo et al., 2017).
",5.1 General,[0],[0]
"As is shown in Table 2, CVAE significantly reduces the perplexity and increases the emoji accuracy over base model.",5.1 General,[0],[0]
Reinforced CVAE also adds to the emoji accuracy at the cost of a slight increase in perplexity.,5.1 General,[0],[0]
"These results confirm that proposed methods are effective toward the generation of emotional responses.
",5.1 General,[0],[0]
"When converged, the KL loss is 27.0/25.5 for the CVAE/Reinforced CVAE respectively, and reconstruction loss 42.2/40.0.",5.1 General,[0],[0]
"The models achieved a balance between the two items of loss, confirming that they have successfully learned a meaningful latent variable.",5.1 General,[0],[0]
"SEQ2SEQ generates in a monotonous way, as several generic responses occur repeatedly, while the generation of CVAE models is of much more diversity.",5.2 Generation Diversity,[0],[0]
"To showcase this disparity, we calculated the type-token ratios of unigrams/bigrams/trigrams in generated responses as
the order of frequencies in the dataset.",5.2 Generation Diversity,[0],[0]
"No.0 is , for instance, No.1 and so on.",5.2 Generation Diversity,[0],[0]
Top: CVAE v. Base.,5.2 Generation Diversity,[0],[0]
Bottom: Reinforced CVAE v. CVAE.,5.2 Generation Diversity,[0],[0]
"If Reinforced CVAE scores higher, the margin is marked in orange.",5.2 Generation Diversity,[0],[0]
"If lower, in black.
",5.2 Generation Diversity,[0],[0]
the diversity score.,5.2 Generation Diversity,[0],[0]
"As shown in Table 3, results show that CVAE models beat the base models by a large margin.",5.2 Generation Diversity,[0],[0]
Diversity scores of Reinforced CVAE are reasonably compromised since it’s generating more emotional responses.,5.2 Generation Diversity,[0],[0]
There are potentially multiple types of emotion in reaction to an utterance.,5.3 Controllability of Emotions,[0],[0]
Our work makes it possible to generate a response to an arbitrary emotion by conditioning the generation on a specific type of emoji.,5.3 Controllability of Emotions,[0],[0]
"In this section, we generate one response in reply to each original tweet in the dataset and condition on each emoji of the selected 64 emo-
jis.",5.3 Controllability of Emotions,[0],[0]
"We may have recorded some original tweets with different replies in the dataset, but an original tweet only need to be used once for each emoji, so we eliminate duplicate original tweets in the dataset.",5.3 Controllability of Emotions,[0],[0]
"There are 30,299 unique original tweets in the test set.
",5.3 Controllability of Emotions,[0],[0]
Figure 4 shows the top-5 accuracy of each type of the first 32 emoji labels when the models generates responses from the test set conditioning on the same emoji.,5.3 Controllability of Emotions,[0],[0]
The results show that CVAE models increase the accuracy over every type of emoji label.,5.3 Controllability of Emotions,[0],[0]
"Reinforced CVAE model sees a bigger increase on the less common emojis, confirming the effect of the emoji-specified policy training.",5.3 Controllability of Emotions,[0],[0]
"We employed crowdsourced judges to evaluate a random sample of 100 items (Table 4), each being assigned to 5 judges on the Amazon Mechanical Turk.",5.4 Human Evaluation,[0],[0]
We present judges original tweets and generated responses.,5.4 Human Evaluation,[0],[0]
"In the first setting of human evaluation, judges are asked to decide which one of the two generated responses better reply the original tweet.",5.4 Human Evaluation,[0],[0]
"In the second setting, the emoji label is presented with the item discription, and judges are asked to pick one of the two generated responses that they decide better fits this emoji.",5.4 Human Evaluation,[0],[0]
(These two settings of evaluation are conducted separately so that it will not affect judges’ verdicts.),5.4 Human Evaluation,[0],[0]
Order of two generated responses under one item is permuted.,5.4 Human Evaluation,[0],[0]
"Ties are permitted for an-
swers.",5.4 Human Evaluation,[0],[0]
We batch five items as one assignment and insert an item with two identical outputs as the sanity check.,5.4 Human Evaluation,[0],[0]
"Anyone who failed to choose “tie” for that item is considered as a careless judge and is therefore rejected from our test.
",5.4 Human Evaluation,[0],[0]
We then conducted a simplified Turing test.,5.4 Human Evaluation,[0],[0]
"Each item we present judges an original tweet, its reply by a human, and its response generated from Reinforced CVAE model.",5.4 Human Evaluation,[0],[0]
We ask judges to decide which of the two given responses is written by a human.,5.4 Human Evaluation,[0],[0]
Other parts of the setting are similar to above-mentioned tests.,5.4 Human Evaluation,[0],[0]
"It turned out 18% of the test subjects mistakenly chose machine-generated responses as human written, and 27% stated that
they were not able to distinguish between the two responses.
",5.4 Human Evaluation,[0],[0]
"In regard of the inter-rater agreement, there are four cases.",5.4 Human Evaluation,[0],[0]
"The ideal situation is that all five judges choose the same answer for a item, and in the worst-case scenario, at most two judges choose the same answer.",5.4 Human Evaluation,[0],[0]
"In light of this, we have counted that 32%/33%/31%/5% of all items have 5/4/3/2 judges in agreement, showing that our experiment has a reasonably reliable inter-rater agreement.",5.4 Human Evaluation,[0],[0]
"We sampled some generated responses from all three models, and list them in Figure 5.",5.5 Case Study,[0],[0]
"Given
an original tweet, we would like to generate responses with three different target emotions.
",5.5 Case Study,[0],[0]
"SEQ2SEQ only chooses to generate most frequent expressions, forming a predictable pattern for its generation (See how every sampled response by the base model starts with “I’m”).",5.5 Case Study,[0],[0]
"On the contrary, generation from the CVAE model is diverse, which is in line with previous quantitative analysis.",5.5 Case Study,[0],[0]
"However, the generated responses are sometimes too diversified and unlikely to reply to the original tweet.
",5.5 Case Study,[0],[0]
Reinforced CVAE somtetimes tends to generate a lengthy response by stacking up sentences (See the responses to the first tweet when conditioning on the ‘folded hands’ emoji and the ‘sad face’ emoji).,5.5 Case Study,[0],[0]
"It learns to break the length limit of sequence generation during hybrid training, since the variational lower bound objective is competing with REINFORCE objective.",5.5 Case Study,[0],[0]
The situation would be more serious is λ in Equation 7 is set higher.,5.5 Case Study,[0],[0]
"However, this phenomenon does not impair the fluency of generated sentences, as can be seen in
Figure 5.",5.5 Case Study,[0],[0]
"In this paper, we investigate the possibility of using naturally annotated emoji-rich Twitter data for emotional response generation.",6 Conclusion and Future Work,[0],[0]
"More specifically, we collected more than half a million Twitter conversations with emoji in the response and assumed that the fine-grained emoji label chosen by the user expresses the emotion of the tweet.",6 Conclusion and Future Work,[0],[0]
We applied several state-of-the-art neural models to learn a generation system that is capable of giving a response with an arbitrarily designated emotion.,6 Conclusion and Future Work,[0],[0]
We performed automatic and human evaluations to understand the quality of generated responses.,6 Conclusion and Future Work,[0],[0]
We trained a large scale emoji classifier and ran the classifier on the generated responses to evaluate the emotion accuracy of the generated response.,6 Conclusion and Future Work,[0],[0]
"We performed an Amazon Mechanical Turk experiment, by which we compared our models with a baseline sequence-to-sequence model on metrics of relevance and emotion.",6 Conclusion and Future Work,[0],[0]
"Experimentally, it is shown that our model is capable of generating high-quality emotional responses, without the need of laborious human annotations.",6 Conclusion and Future Work,[0],[0]
Our work is a crucial step towards building intelligent dialog agents.,6 Conclusion and Future Work,[0],[0]
"We are also looking forward to transferring the idea of naturally-labeled emojis to task-oriented dialog and multi-turn dialog
generation problems.",6 Conclusion and Future Work,[0],[0]
"Due to the nature of social media text, some emotions, such as fear and disgust, are underrepresented in the dataset, and the distribution of emojis is unbalanced to some extent.",6 Conclusion and Future Work,[0],[0]
"We will keep accumulating data and increase the ratio of underrepresented emojis, and advance toward more sophisticated abstractive generation methods.",6 Conclusion and Future Work,[0],[0]
Generating emotional language is a key step towards building empathetic natural language processing agents.,abstractText,[0],[0]
"However, a major challenge for this line of research is the lack of large-scale labeled training data, and previous studies are limited to only small sets of human annotated sentiment labels.",abstractText,[0],[0]
"Additionally, explicitly controlling the emotion and sentiment of generated text is also difficult.",abstractText,[0],[0]
"In this paper, we take a more radical approach: we exploit the idea of leveraging Twitter data that are naturally labeled with emojis.",abstractText,[0],[0]
We collect a large corpus of Twitter conversations that include emojis in the response and assume the emojis convey the underlying emotions of the sentence.,abstractText,[0],[0]
"We investigate several conditional variational autoencoders training on these conversations, which allow us to use emojis to control the emotion of the generated text.",abstractText,[0],[0]
"Experimentally, we show in our quantitative and qualitative analyses that the proposed models can successfully generate highquality abstractive conversation responses in accordance with designated emotions.",abstractText,[0],[0]
MOJITALK: Generating Emotional Responses at Scale,title,[0],[0]
"Word representation learning has become a research area of central importance in natural language processing (NLP), with its usefulness demonstrated across many application areas such as parsing (Chen and Manning, 2014; Johannsen et al., 2015), machine translation (Zou et al., 2013), and many others (Turian et al., 2010; Collobert et al.,
2011).",1 Introduction,[0],[0]
"Most prominent word representation techniques are grounded in the distributional hypothesis (Harris, 1954), relying on word co-occurrence information in large textual corpora (Curran, 2004; Turney and Pantel, 2010; Mikolov et al., 2013; Mnih and Kavukcuoglu, 2013; Levy and Goldberg, 2014; Schwartz et al., 2015, i.a.).
",1 Introduction,[0],[0]
"Morphologically rich languages, in which “substantial grammatical information. .",1 Introduction,[0],[0]
.,1 Introduction,[0],[0]
"is expressed at word level” (Tsarfaty et al., 2010), pose specific challenges for NLP.",1 Introduction,[0],[0]
"This is not always considered when techniques are evaluated on languages such as English or Chinese, which do not have rich morphology.",1 Introduction,[0],[0]
"In the case of distributional vector space models, morphological complexity brings two challenges to the fore:
1.",1 Introduction,[0],[0]
Estimating Rare Words: A single lemma can have many different surface realisations.,1 Introduction,[0],[0]
Naively treating each realisation as a separate word leads to sparsity problems and a failure to exploit their shared semantics.,1 Introduction,[0],[0]
"On the other hand, lemmatising the entire corpus can obfuscate the differences that exist between different word forms even though they share some aspects of meaning.
2.",1 Introduction,[0],[0]
Embedded Semantics:,1 Introduction,[0],[0]
"Morphology can encode semantic relations such as antonymy (e.g. literate and illiterate, expensive and inexpensive) or (near-)synonymy (north, northern, northerly).
",1 Introduction,[0],[0]
"In this work, we tackle the two challenges jointly by introducing a resource-light vector space finetuning procedure termed morph-fitting.",1 Introduction,[0],[0]
The proposed method does not require curated knowledge bases or gold lexicons.,1 Introduction,[0],[0]
"Instead, it makes use of the observation that morphology implicitly encodes semantic signals pertaining to synonymy (e.g., German word inflections katalanisch, katalanischem, katalanischer denote the same semantic concept in different grammatical roles), and antonymy (e.g., mature vs. immature), capitalising on the
ar X
iv :1
70 6.
00 37
",1 Introduction,[0],[0]
"7v 1
[ cs
.C",1 Introduction,[0],[0]
"L
] 1
J un
2 01
7
proliferation of word forms in morphologically rich languages.",1 Introduction,[0],[0]
"Formalised as an instance of the post-processing semantic specialisation paradigm (Faruqui et al., 2015; Mrkšić et al., 2016), morphfitting is steered by a set of linguistic constraints derived from simple language-specific rules which describe (a subset of) morphological processes in a language.",1 Introduction,[0],[0]
"The constraints emphasise similarity on one side (e.g., by extracting morphological synonyms), and antonymy on the other (by extracting morphological antonyms), see Fig. 1 and Tab. 2.
",1 Introduction,[0],[0]
"The key idea of the fine-tuning process is to pull synonymous examples described by the constraints closer together in the transformed vector space, while at the same time pushing antonymous examples away from each other.",1 Introduction,[0],[0]
"The explicit post-hoc injection of morphological constraints enables: a) the estimation of more accurate vectors for lowfrequency words which are linked to their highfrequency forms by the constructed constraints;1 this tackles the data sparsity problem; and b) specialising the distributional space to distinguish between similarity and relatedness (Kiela et al., 2015), thus supporting language understanding applications such as dialogue state tracking (DST).2
As a post-processor, morph-fitting allows the integration of morphological rules with any distributional vector space in any language: it treats an input distributional word vector space as a black box and fine-tunes it so that the transformed space reflects the knowledge coded in the input morphological constraints (e.g., Italian words rispettoso and irrispetosa should be far apart in the trans-
1For instance, the vector for the word katalanischem which occurs only 9 times in the German Wikipedia will be pulled closer to the more reliable vectors for katalanisch and katalanischer, with frequencies of 2097 and 1383 respectively.
2Representation models that do not distinguish between synonyms and antonyms may have grave implications in downstream language understanding applications such as spoken dialogue systems: a user looking for ‘an affordable Chinese restaurant in west Cambridge’ does not want a recommendation for ‘an expensive Thai place in east Oxford’.
",1 Introduction,[0],[0]
"formed vector space, see Fig. 1).",1 Introduction,[0],[0]
"Tab. 1 illustrates the effects of morph-fitting by qualitative examples in three languages: the vast majority of nearest neighbours are “morphological” synonyms.
",1 Introduction,[0],[0]
"We demonstrate the efficacy of morph-fitting in four languages (English, German, Italian, Russian), yielding large and consistent improvements on benchmarking word similarity evaluation sets such as SimLex-999 (Hill et al., 2015), its multilingual extension (Leviant and Reichart, 2015), and SimVerb-3500 (Gerz et al., 2016).",1 Introduction,[0],[0]
"The improvements are reported for all four languages, and with a variety of input distributional spaces, verifying the robustness of the approach.
",1 Introduction,[0],[0]
"We then show that incorporating morph-fitted vectors into a state-of-the-art neural-network DST model results in improved tracking performance, especially for morphologically rich languages.",1 Introduction,[0],[0]
"We report an improvement of 4% on Italian, and 6% on German when using morph-fitted vectors instead of the distributional ones, setting a new state-of-theart DST performance for the two datasets.3
3There are no readily available DST datasets for Russian.",1 Introduction,[0],[0]
"Preliminaries In this work, we focus on four languages with varying levels of morphological complexity: English (EN), German (DE), Italian (IT), and Russian (RU).",2 Morph-fitting: Methodology,[0],[0]
These correspond to languages in the Multilingual SimLex-999 dataset.,2 Morph-fitting: Methodology,[0],[0]
"Vocabularies Wen, Wde, Wit, Wru are compiled by retaining all word forms from the four Wikipedias with word frequency over 10, see Tab. 3.",2 Morph-fitting: Methodology,[0],[0]
"We then extract sets of linguistic constraints from these (large) vocabularies using a set of simple language-specific if-then-else rules, see Tab. 2.4",2 Morph-fitting: Methodology,[0],[0]
These constraints (Sect. 2.2) are used as input for the vector space post-processing ATTRACT-REPEL algorithm (outlined in Sect. 2.1).,2 Morph-fitting: Methodology,[0],[0]
"The ATTRACT-REPEL model, proposed by Mrkšić et al. (2017b), is an extension of the PARAGRAM procedure proposed by Wieting et al. (2015).",2.1 The ATTRACT-REPEL Model,[0],[0]
It provides a generic framework for incorporating similarity (e.g. successful and accomplished) and antonymy constraints (e.g. nimble and clumsy) into pre-trained word vectors.,2.1 The ATTRACT-REPEL Model,[0],[0]
"Given the initial vector space and collections of ATTRACT and REPEL constraints A and R, the model gradually modifies the space to bring the designated word vectors closer together or further apart.",2.1 The ATTRACT-REPEL Model,[0],[0]
The method’s cost function consists of three terms.,2.1 The ATTRACT-REPEL Model,[0],[0]
"The first term pulls the ATTRACT examples (xl, xr) ∈",2.1 The ATTRACT-REPEL Model,[0],[0]
A closer together.,2.1 The ATTRACT-REPEL Model,[0],[0]
"If BA denotes the current mini-batch of ATTRACT examples, this term can be expressed as:
A(BA) =",2.1 The ATTRACT-REPEL Model,[0],[0]
"∑
(xl,xr)∈BA
(ReLU (δatt + xltl",2.1 The ATTRACT-REPEL Model,[0],[0]
"− xlxr)
+ ReLU (δatt + xrtr − xlxr))
where δatt is the similarity margin which determines how much closer synonymous vectors should be to each other than to each of their respective negative examples.",2.1 The ATTRACT-REPEL Model,[0],[0]
"ReLU(x) = max(0, x) is the standard rectified linear unit (Nair and Hinton, 2010).",2.1 The ATTRACT-REPEL Model,[0],[0]
The ‘negative’ example ti for each word xi in any ATTRACT pair is the word vector closest to xi among the examples in the current minibatch (distinct from its target synonym and xi itself).,2.1 The ATTRACT-REPEL Model,[0],[0]
"This means that this term forces synonymous
4A native speaker can easily come up with these sets of morphological rules (or at least with a reasonable subset of them) without any linguistic training.",2.1 The ATTRACT-REPEL Model,[0],[0]
"What is more, the rules for DE, IT, and RU were created by non-native, non-fluent speakers with a limited knowledge of the three languages, exemplifying the simplicity and portability of the approach.
",2.1 The ATTRACT-REPEL Model,[0],[0]
"words from the in-batch ATTRACT constraints to be closer to one another than to any other word in the current mini-batch.
",2.1 The ATTRACT-REPEL Model,[0],[0]
The second term pushes antonyms away from each other.,2.1 The ATTRACT-REPEL Model,[0],[0]
"If (xl, xr) ∈ BR is the current minibatch of REPEL constraints, this term can be expressed as follows:
R(BR) =",2.1 The ATTRACT-REPEL Model,[0],[0]
"∑
(xl,xr)∈BR
(ReLU (δrpl + xlxr − xltr)
+ ReLU (δrpl + xlxr − xrtr))
",2.1 The ATTRACT-REPEL Model,[0],[0]
"In this case, each word’s ‘negative’ example is the (in-batch) word vector furthest away from it (and distinct from the word’s target antonym).",2.1 The ATTRACT-REPEL Model,[0],[0]
"The intuition is that we want antonymous words from the input REPEL constraints to be further away from each other than from any other word in the current mini-batch; δrpl is now the repel margin.
",2.1 The ATTRACT-REPEL Model,[0],[0]
The final term of the cost function serves to retain the abundance of semantic information encoded in the starting distributional space.,2.1 The ATTRACT-REPEL Model,[0],[0]
"If xiniti is the initial distributional vector and V (B) is the set of all vectors present in the given mini-batch, this term (per mini-batch) is expressed as follows:
R(BA,BR) = ∑
xi∈V (BA∪BR)
",2.1 The ATTRACT-REPEL Model,[0],[0]
"λreg ∥∥∥xiniti − xi∥∥∥ 2
where λreg is the L2 regularisation constant.5",2.1 The ATTRACT-REPEL Model,[0],[0]
"This term effectively pulls word vectors towards their initial (distributional) values, ensuring that relations encoded in initial vectors persist as long as they do not contradict the newly injected ones.",2.1 The ATTRACT-REPEL Model,[0],[0]
"Semantic Specialisation with Constraints The fine-tuning ATTRACT-REPEL procedure is entirely driven by the input ATTRACT and REPEL sets of
5We use hyperparameter values δatt = 0.6, δrpl = 0.0, λreg = 10
−9 from prior work without fine-tuning.",2.2 Language-Specific Rules and Constraints,[0],[0]
"We train all models for 10 epochs with AdaGrad (Duchi et al., 2011).
constraints.",2.2 Language-Specific Rules and Constraints,[0],[0]
"These can be extracted from a variety of semantic databases such as WordNet (Fellbaum, 1998), the Paraphrase Database (Ganitkevitch et al., 2013; Pavlick et al., 2015), or BabelNet (Navigli and Ponzetto, 2012; Ehrmann et al., 2014) as done in prior work (Faruqui et al., 2015; Wieting et al., 2015; Mrkšić et al., 2016, i.a.).",2.2 Language-Specific Rules and Constraints,[0],[0]
"In this work, we investigate another option: extracting constraints without curated knowledge bases in a spectrum of languages by exploiting inherent language-specific properties related to linguistic morphology.",2.2 Language-Specific Rules and Constraints,[0],[0]
"This relaxation ensures a wider portability of ATTRACTREPEL to languages and domains without readily available or adequate resources.
",2.2 Language-Specific Rules and Constraints,[0],[0]
Extracting ATTRACT Pairs,2.2 Language-Specific Rules and Constraints,[0],[0]
"The core difference between inflectional and derivational morphology can be summarised in a few lines as follows: the former refers to a set of processes through which the word form expresses meaningful syntactic information, e.g., verb tense, without any change to the semantics of the word.",2.2 Language-Specific Rules and Constraints,[0],[0]
"On the other hand, the latter refers to the formation of new words with semantic shifts in meaning (Schone and Jurafsky, 2001; Haspelmath and Sims, 2013; Lazaridou et al., 2013; Zeller et al., 2013; Cotterell and Schütze, 2017).
",2.2 Language-Specific Rules and Constraints,[0],[0]
"For the ATTRACT constraints, we focus on inflectional rather than on derivational morphology rules as the former preserve the full meaning of a word, modifying it only to reflect grammatical roles such as verb tense or case markers (e.g., (en_read, en_reads) or (de_katalanisch, de_katalanischer)).",2.2 Language-Specific Rules and Constraints,[0],[0]
"This choice is guided by our intent to fine-tune the original vector space in order to improve the embedded semantic relations.
",2.2 Language-Specific Rules and Constraints,[0],[0]
"We define two rules for English, widely recognised as morphologically simple (Avramidis and Koehn, 2008; Cotterell et al., 2016b).",2.2 Language-Specific Rules and Constraints,[0],[0]
"These are: (R1) if w1, w2 ∈Wen, where w2 = w1 + ing/ed/s, then add (w1, w2) and (w2, w1) to the set of ATTRACT constraints A.",2.2 Language-Specific Rules and Constraints,[0],[0]
"This rule yields pairs such as (look, looks), (look, looking), (look, looked).
",2.2 Language-Specific Rules and Constraints,[0],[0]
"If w[: −1] is a function which strips the last character from word w, the second rule is: (R2)
if w1 ends with the letter e and w1 ∈ Wen and w2 ∈ Wen, where w2 = w1",2.2 Language-Specific Rules and Constraints,[0],[0]
"[: −1] + ing/ed, then add (w1, w2) and (w2, w1) to A.",2.2 Language-Specific Rules and Constraints,[0],[0]
"This creates pairs such as (create, creating) and (create, created).",2.2 Language-Specific Rules and Constraints,[0],[0]
"Naturally, introducing more sophisticated rules is possible in order to cover for other special cases and morphological irregularities (e.g., sweep / swept), but in all our EN experiments, A is based on the two simple EN rules R1 and R2.
",2.2 Language-Specific Rules and Constraints,[0],[0]
"The other three languages, with more complicated morphology, yield a larger number of rules.",2.2 Language-Specific Rules and Constraints,[0],[0]
"In Italian, we rely on the sets of rules spanning: (1) regular formation of plural (libro / libri); (2) regular verb conjugation (aspettare / aspettiamo); (3) regular formation of past participle (aspettare / aspettato); and (4) rules regarding grammatical gender (bianco / bianca).",2.2 Language-Specific Rules and Constraints,[0],[0]
"Besides these, another set of rules is used for German and Russian: (5) regular declension (e.g., asiatisch / asiatischem).
",2.2 Language-Specific Rules and Constraints,[0],[0]
"Extracting REPEL Pairs As another source of implicit semantic signals, W also contains words which represent derivational antonyms: e.g., two words that denote concepts with opposite meanings, generated through a derivational process.",2.2 Language-Specific Rules and Constraints,[0],[0]
"We use a standard set of EN “antonymy” prefixes: APen = {dis, il, un, in, im, ir, mis, non, anti} (Fromkin et al., 2013).",2.2 Language-Specific Rules and Constraints,[0],[0]
"If w1, w2 ∈ Wen, where w2 is generated by adding a prefix from APen to w1, then (w1, w2) and (w2, w1) are added to the set of REPEL constraints R. This rule generates pairs such as (advantage, disadvantage) and (regular, irregular).",2.2 Language-Specific Rules and Constraints,[0],[0]
"An additional rule replaces the suffix -ful with -less, extracting antonyms such as (careful, careless).
",2.2 Language-Specific Rules and Constraints,[0],[0]
"Following the same principle, we use APde = {un, nicht, anti, ir, in, miss}, APit = {in, ir, im, anti}, and APru = {не, анти}.",2.2 Language-Specific Rules and Constraints,[0],[0]
"For instance, this generates an IT pair (rispettoso, irrispettoso)",2.2 Language-Specific Rules and Constraints,[0],[0]
(see Fig. 1).,2.2 Language-Specific Rules and Constraints,[0],[0]
"For DE, we use another rule targeting suffix replacement: -voll is replaced by -los.
",2.2 Language-Specific Rules and Constraints,[0],[0]
We further expand the set of REPEL constraints by transitively combining antonymy pairs from the previous step with inflectional ATTRACT pairs.,2.2 Language-Specific Rules and Constraints,[0],[0]
"This step yields additional constraints such as (rispettosa, irrispettosi) (see Fig. 1).",2.2 Language-Specific Rules and Constraints,[0],[0]
The final A andR constraint counts are given in Tab. 3.,2.2 Language-Specific Rules and Constraints,[0],[0]
The full sets of rules are available as supplemental material.,2.2 Language-Specific Rules and Constraints,[0],[0]
"Training Data and Setup For each of the four languages we train the skip-gram with negative sampling (SGNS) model (Mikolov et al., 2013)
on the latest Wikipedia dump of each language.",3 Experimental Setup,[0],[0]
"We induce 300-dimensional word vectors, with the frequency cut-off set to 10.",3 Experimental Setup,[0],[0]
The vocabulary sizes |W | for each language are provided in Tab. 3.6,3 Experimental Setup,[0],[0]
"We label these collections of vectors SGNS-LARGE.
",3 Experimental Setup,[0],[0]
Other Starting Distributional Vectors We also analyse the impact of morph-fitting on other collections of well-known EN word vectors.,3 Experimental Setup,[0],[0]
These vectors have varying vocabulary coverage and are trained with different architectures.,3 Experimental Setup,[0],[0]
"We test standard distributional models: Common-Crawl GloVe (Pennington et al., 2014), SGNS vectors (Mikolov et al., 2013) with various contexts (BOW = bag-ofwords; DEPS = dependency contexts), and training data (PW = Polyglot Wikipedia from Al-Rfou et al. (2013); 8B = 8 billion token word2vec corpus), following (Levy and Goldberg, 2014) and (Schwartz et al., 2015).",3 Experimental Setup,[0],[0]
"We also test the symmetricpattern based vectors of Schwartz et al. (2016) (SymPat-Emb), count-based PMI-weighted vectors reduced by SVD (Baroni et al., 2014) (Count-SVD), a model which replaces the context modelling function from CBOW with bidirectional LSTMs (Melamud et al., 2016) (Context2Vec), and two sets of EN vectors trained by injecting multilingual information: BiSkip (Luong et al., 2015) and MultiCCA (Faruqui and Dyer, 2014).
",3 Experimental Setup,[0],[0]
"We also experiment with standard well-known distributional spaces in other languages (IT and DE), available from prior work (Dinu et al., 2015; Luong et al., 2015; Vulić and Korhonen, 2016a).
",3 Experimental Setup,[0],[0]
"Morph-fixed Vectors A baseline which utilises an equal amount of knowledge as morph-fitting, termed morph-fixing, fixes the vector of each word to the distributional vector of its most frequent inflectional synonym, tying the vectors of lowfrequency words to their more frequent inflections.",3 Experimental Setup,[0],[0]
"For each word w1, we construct a set of M + 1 words Ww1 = {w1, w′1, . . .",3 Experimental Setup,[0],[0]
", w′M} consisting of the word w1 itself and all M words which cooccur with w1 in the ATTRACT constraints.",3 Experimental Setup,[0],[0]
"We then choose the word w′max from the set Ww1 with the maximum frequency in the training data, and fix all other word vectors in Ww1 to its word vector.",3 Experimental Setup,[0],[0]
"The morph-fixed vectors (MFIX) serve as our primary baseline, as they outperformed another straightforward baseline based on stemming across
6Other SGNS parameters were set to standard values (Baroni et al., 2014; Vulić and Korhonen, 2016b): 15 epochs, 15 negative samples, global learning rate: .025, subsampling rate: 1e− 4.",3 Experimental Setup,[0],[0]
"Similar trends in results persist with d = 100, 500.
",3 Experimental Setup,[0],[0]
"all of our intrinsic and extrinsic experiments.
",3 Experimental Setup,[0],[0]
"Morph-fitting Variants We analyse two variants of morph-fitting: (1) using ATTRACT constraints only (MFIT-A), and (2) using both ATTRACT and REPEL constraints (MFIT-AR).",3 Experimental Setup,[0],[0]
"Evaluation Setup and Datasets The first set of experiments intrinsically evaluates morph-fitted vector spaces on word similarity benchmarks, using Spearman’s rank correlation as the evaluation metric.",4 Intrinsic Evaluation: Word Similarity,[0],[0]
"First, we use the SimLex-999 dataset, as well as SimVerb-3500, a recent EN verb pair similarity dataset providing similarity ratings for 3,500 verb pairs.7 SimLex-999 was translated to DE, IT, and RU by Leviant and Reichart (2015), and they crowdsourced similarity scores from native speakers.",4 Intrinsic Evaluation: Word Similarity,[0],[0]
"We use this dataset for our multilingual evaluation.8
Morph-fitting EN Word Vectors As the first experiment, we morph-fit a wide spectrum of EN distributional vectors induced by various architectures (see Sect. 3).",4 Intrinsic Evaluation: Word Similarity,[0],[0]
The results on SimLex and SimVerb are summarised in Tab. 4.,4 Intrinsic Evaluation: Word Similarity,[0],[0]
The results with EN SGNS-LARGE vectors are shown in Fig. 3a.,4 Intrinsic Evaluation: Word Similarity,[0],[0]
"Morphfitted vectors bring consistent improvement across all experiments, regardless of the quality of the initial distributional space.",4 Intrinsic Evaluation: Word Similarity,[0],[0]
This finding confirms that the method is robust: its effectiveness does not depend on the architecture used to construct the initial space.,4 Intrinsic Evaluation: Word Similarity,[0],[0]
"To illustrate the improvements, note that the best score on SimVerb for a model trained on running text is achieved by Context2vec (ρ = 0.388); injecting morphological constraints into this vector space results in a gain of 7.1 ρ points.
",4 Intrinsic Evaluation: Word Similarity,[0],[0]
"Experiments on Other Languages We next extend our experiments to other languages, testing both morph-fitting variants.",4 Intrinsic Evaluation: Word Similarity,[0],[0]
"The results are summarised in Tab. 5, while Fig. 3a-3d show results for the morph-fitted SGNS-LARGE vectors.",4 Intrinsic Evaluation: Word Similarity,[0],[0]
"These scores confirm the effectiveness and robustness of morph-fitting across languages, suggesting that the idea of fitting to morphological constraints is indeed language-agnostic, given the set of languagespecific rule-based constraints.",4 Intrinsic Evaluation: Word Similarity,[0],[0]
"Fig. 3 also demon-
7Unlike other gold standard resources such as WordSim353 (Finkelstein et al., 2002) or MEN (Bruni et al., 2014), SimLex and SimVerb provided explicit guidelines to discern between semantic similarity and association, so that related but non-similar words (e.g. cup and coffee) have a low rating.
",4 Intrinsic Evaluation: Word Similarity,[0],[0]
"8Since Leviant and Reichart (2015) re-scored the original EN SimLex, we use their EN SimLex version for consistency.
strates that the morph-fitted vector spaces consistently outperform the morph-fixed ones.
",4 Intrinsic Evaluation: Word Similarity,[0],[0]
The comparison between MFIT-A and MFITAR indicates that both sets of constraints are important for the fine-tuning process.,4 Intrinsic Evaluation: Word Similarity,[0],[0]
"MFIT-A yields consistent gains over the initial spaces, and (consistent) further improvements are achieved by also incorporating the antonymous REPEL constraints.",4 Intrinsic Evaluation: Word Similarity,[0],[0]
This demonstrates that both types of constraints are useful for semantic specialisation.,4 Intrinsic Evaluation: Word Similarity,[0],[0]
We also tried using other post-processing specialisation models from the literature in lieu of ATTRACT-REPEL using the same set of “morphological” synonymy and antonymy constraints.,Comparison to Other Specialisation Methods,[0],[0]
"We compare ATTRACT-REPEL to the retrofitting model
of (Faruqui et al., 2015) and counter-fitting (Mrkšić et al., 2017a).",Comparison to Other Specialisation Methods,[0],[0]
The two baselines were trained for 20 iterations using suggested settings.,Comparison to Other Specialisation Methods,[0],[0]
"The results for EN, DE, and IT are summarised in Fig. 2.",Comparison to Other Specialisation Methods,[0],[0]
They clearly indicate that MFIT-AR outperforms the two other post-processors for each language.,Comparison to Other Specialisation Methods,[0],[0]
We hypothesise that the difference in performance mainly stems from context-sensitive vector space updates performed by ATTRACT-REPEL.,Comparison to Other Specialisation Methods,[0],[0]
"Conversely, the other two models perform pairwise updates which do not consider what effect each update has on the example pair’s relation to other word vectors (for a detailed comparison, see (Mrkšić et al., 2017b)).
",Comparison to Other Specialisation Methods,[0],[0]
"Besides their lower performance, the two other specialisation models have additional disadvantages compared to the proposed morph-fitting model.",Comparison to Other Specialisation Methods,[0],[0]
"First, retrofitting is able to incorporate only synonymy/ATTRACT pairs, while our results demonstrate the usefulness of both types of constraints, both for intrinsic evaluation (Tab. 5) and downstream tasks (see later Fig. 3).",Comparison to Other Specialisation Methods,[0],[0]
"Second, counter-fitting is computationally intractable with SGNS-LARGE vectors, as its regularisation term involves the computation of all pairwise distances between words in the vocabulary.
",Comparison to Other Specialisation Methods,[0],[0]
"Further Discussion The simplicity of the used language-specific rules does come at a cost of occasionally generating incorrect linguistic constraints such as (tent, intent), (prove, improve) or (press, impress).",Comparison to Other Specialisation Methods,[0],[0]
"In future work, we will study how to fur-
ther refine extracted sets of constraints.",Comparison to Other Specialisation Methods,[0],[0]
"We also plan to conduct experiments with gold standard morphological lexicons on languages for which such resources exist (Sylak-Glassman et al., 2015; Cotterell et al., 2016b), and investigate approaches which learn morphological inflections and derivations in different languages automatically as another potential source of morphological constraints (Soricut and Och, 2015; Cotterell et al., 2016a; Faruqui et al., 2016; Kann et al., 2017; Aharoni and Goldberg, 2017, i.a.).",Comparison to Other Specialisation Methods,[0],[0]
Goal-oriented dialogue systems provide conversational interfaces for tasks such as booking flights or finding restaurants.,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"In slot-based systems, application domains are specified using ontologies that define the search constraints which users can express.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
An ontology consists of a number of slots and their assorted slot values.,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"In a restaurant search domain, sets of slot-values could include PRICE =",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"[cheap, expensive] or FOOD =",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"[Thai, Indian, ...].
",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"The DST model is the first component of modern dialogue pipelines (Young, 2010).",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
It serves to capture the intents expressed by the user at each dialogue turn and update the belief state.,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
This probability distribution over the possible dialogue states (defined by the domain ontology) is the system’s internal estimate of the user’s goals.,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"It is used by the downstream dialogue manager component to choose the subsequent system response (Su et al., 2016).",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"The following example shows the true dialogue state in a multi-turn dialogue:
",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
User: What’s good in the southern part of town?,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
inform(area=south) System: Vedanta is the top-rated Indian place.,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
User: How about something cheaper?,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"inform(area=south, price=cheap) System: Seven Days is very popular.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
Great hot pot.,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
User:,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
What’s the address?,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"inform(area=south, price=cheap); request(address) System: Seven Days is at 66 Regent Street.
",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"The Dialogue State Tracking Challenge (DSTC) shared task series formalised the evaluation and provided labelled DST datasets (Henderson et al., 2014a,b; Williams et al., 2016).",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"While a plethora of DST models are available based on, e.g., handcrafted rules (Wang et al., 2014) or conditional random fields (Lee and Eskenazi, 2013), the recent DST methodology has seen a shift towards neural-
network architectures (Henderson et al., 2014c,d; Zilka and Jurcicek, 2015; Mrkšić et al., 2015; Perez and Liu, 2017; Liu and Perez, 2017; Vodolán et al., 2017; Mrkšić et al., 2017a, i.a.).
",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"Model: Neural Belief Tracker To detect intents in user utterances, most existing models rely on either (or both): 1) Spoken Language Understanding models which require large amounts of annotated training data; or 2) hand-crafted, domain-specific lexicons which try to capture lexical and morphological variation.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"The Neural Belief Tracker (NBT) is a novel DST model which overcomes both issues by reasoning purely over pre-trained word vectors (Mrkšić et al., 2017a).",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
The NBT learns to compose these vectors into intermediate utterance and context representations.,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
These are then used to decide which of the ontology-defined intents (goals) have been expressed by the user.,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"The NBT model keeps word vectors fixed during training, so that unseen, yet related words can be mapped to the right intent at test time (e.g. northern to north).
",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
Data: Multilingual WOZ 2.0 Dataset,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"Our DST evaluation is based on the WOZ dataset, released by Wen et al. (2017).",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"In this Wizard-of-Oz setup, two Amazon Mechanical Turk workers assumed the role of the user and the system asking/providing information about restaurants in Cambridge (operating over the same ontology and database used for DSTC2 (Henderson et al., 2014a)).",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"Users typed instead of speaking, removing the need to deal with noisy speech recognition.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"In DSTC datasets, users would quickly adapt to the system’s inability to deal with complex queries.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"Conversely, the WOZ setup allowed them to use sophisticated language.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"The WOZ 2.0 release expanded the dataset to 1,200 dialogues (Mrkšić et al., 2017a).",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"In this work, we use translations of this dataset to Italian and German, released by Mrkšić et al. (2017b).
",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"Evaluation Setup The principal metric we use to measure DST performance is the joint goal accuracy, which represents the proportion of test set dialogue turns where all user goals expressed up to that point of the dialogue were decoded correctly (Henderson et al., 2014a).",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"The NBT models for EN, DE and IT are trained using four variants of the SGNS-LARGE vectors: 1) the initial distributional vectors; 2) morph-fixed vectors; 3) and 4) the two variants of morph-fitted vectors (see Sect. 3).
",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"As shown by Mrkšić et al. (2017b), semantic specialisation of the employed word vectors ben-
efits DST performance across all three languages.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"However, large gains on SimLex-999 do not always induce correspondingly large gains in downstream performance.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"In our experiments, we investigate the extent to which morph-fitting improves DST performance, and whether these gains exhibit stronger correlation with intrinsic performance.
Results and Discussion The dark bars (against the right axes) in Fig. 3 show the DST performance of NBT models making use of the four vector collections.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"IT and DE benefit from both kinds of morph-fitting: IT performance increases from 74.1→ 78.1 (MFIT-A) and DE performance rises even more: 60.6→ 66.3 (MFIT-AR), setting a new state-of-the-art score for both datasets.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"The morph-fixed vectors do not enhance DST performance, probably because fixing word vectors to their highest frequency inflectional form eliminates useful semantic content encoded in the original vectors.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"On the other hand, morph-fitting makes use of this information, supplementing it with semantic relations between different morphological forms.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"These conclusions are in line with the SimLex gains, where morph-fitting outperforms both distributional and morph-fixed vectors.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
English performance shows little variation across the four word vector collections investigated here.,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"This corroborates our intuition that, as a morphologically simpler language, English stands to gain less from fine-tuning the morphological variation for downstream applications.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
This result again points at the discrepancy between intrinsic and extrinsic evaluation: the considerable gains in SimLex performance do not necessarily induce similar gains in downstream performance.,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
Additional discrepancies between SimLex and downstream DST performance are detected for German and Italian.,5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"While we observe a slight drop in SimLex performance with the DE MFIT-AR vectors compared to the MFIT-A ones, their relative performance is reversed in the DST task.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"On the other hand, we see the opposite trend in Italian, where the MFITA vectors score lower than the MFIT-AR vectors on SimLex, but higher on the DST task.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"In summary, we believe these results show that SimLex is not a perfect proxy for downstream performance in language understanding tasks.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
"Regardless, its performance does correlate with downstream performance to a large extent, providing a useful indicator for the usefulness of specific word vector
spaces for extrinsic tasks such as DST.",5 Downstream Task: Dialogue State Tracking (DST),[0],[0]
Semantic Specialisation A standard approach to incorporating external information into vector spaces is to pull the representations of similar words closer together.,6 Related Work,[0],[0]
"Some models integrate such constraints into the training procedure, modifying the prior or the regularisation (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015), or using a variant of the SGNS-style objective (Liu et al., 2015; Osborne et al., 2016).",6 Related Work,[0],[0]
"Another class of models, popularly termed retrofitting, injects lexical knowledge from available semantic databases (e.g., WordNet, PPDB) into pre-trained word vectors (Faruqui et al., 2015; Jauhar et al., 2015; Wieting et al., 2015; Nguyen et al., 2016; Mrkšić et al., 2016).",6 Related Work,[0],[0]
Morph-fitting falls into the latter category.,6 Related Work,[0],[0]
"However, instead of resorting to curated knowledge bases, and experimenting solely with English, we show that the morphological richness of any language can be exploited as a source of inexpensive supervision for fine-tuning vector spaces, at the same time specialising them to better reflect true semantic similarity, and learning more accurate representations for low-frequency words.
",6 Related Work,[0],[0]
Word Vectors and Morphology,6 Related Work,[0],[0]
The use of morphological resources to improve the representations of morphemes and words is an active area of research.,6 Related Work,[0],[0]
"The majority of proposed architectures encode morphological information, provided either as gold standard morphological resources (SylakGlassman et al., 2015) such as CELEX (Baayen et al., 1995) or as an external analyser such as Morfessor (Creutz and Lagus, 2007), along with distributional information jointly at training time in the language modelling (LM) objective (Luong et al., 2013; Botha and Blunsom, 2014; Qiu et al., 2014; Cotterell and Schütze, 2015; Bhatia et al., 2016, i.a.).",6 Related Work,[0],[0]
"The key idea is to learn a morphological composition function (Lazaridou et al., 2013; Cotterell and Schütze, 2017) which synthesises the representation of a word given the representations of its constituent morphemes.",6 Related Work,[0],[0]
"Contrary to our work, these models typically coalesce all lexical relations.
",6 Related Work,[0],[0]
"Another class of models, operating at the character level, shares a similar methodology: such models compose token-level representations from subcomponent embeddings (subwords, morphemes, or characters) (dos Santos and Zadrozny, 2014; Ling et al., 2015; Cao and Rei, 2016; Kim et al., 2016;
",6 Related Work,[0],[0]
"Wieting et al., 2016; Verwimp et al., 2017, i.a.).",6 Related Work,[0],[0]
"In contrast to prior work, our model decouples the use of morphological information, now provided in the form of inflectional and derivational rules transformed into constraints, from the actual training.",6 Related Work,[0],[0]
"This pipelined approach results in a simpler, more portable model.",6 Related Work,[0],[0]
"In spirit, our work is similar to Cotterell et al. (2016b), who formulate the idea of post-training specialisation in a generative Bayesian framework.",6 Related Work,[0],[0]
Their work uses gold morphological lexicons; we show that competitive performance can be achieved using a non-exhaustive set of simple rules.,6 Related Work,[0],[0]
"Our framework facilitates the inclusion of antonyms at no extra cost and naturally extends to constraints from other sources (e.g., WordNet) in future work.",6 Related Work,[0],[0]
Another practical difference is that we focus on similarity and evaluate morph-fitting in a well-defined downstream task where the artefacts of the distributional hypothesis are known to prompt statistical system failures.,6 Related Work,[0],[0]
We have presented a novel morph-fitting method which injects morphological knowledge in the form of linguistic constraints into word vector spaces.,7 Conclusion and Future Work,[0],[0]
The method makes use of implicit semantic signals encoded in inflectional and derivational rules which describe the morphological processes in a language.,7 Conclusion and Future Work,[0],[0]
The results in intrinsic word similarity tasks show that morph-fitting improves vector spaces induced by distributional models across four languages.,7 Conclusion and Future Work,[0],[0]
"Finally, we have shown that the use of morph-fitted vectors boosts the performance of downstream language understanding models which rely on word representations as features, especially for morphologically rich languages such as German.
",7 Conclusion and Future Work,[0],[0]
"Future work will focus on other potential sources of morphological knowledge, porting the framework to other morphologically rich languages and downstream tasks, and on further refinements of the post-processing specialisation algorithm and the constraint selection.",7 Conclusion and Future Work,[0],[0]
This work is supported by the ERC Consolidator Grant LEXICAL:,Acknowledgments,[0],[0]
Lexical Acquisition Across Languages (no 648909).,Acknowledgments,[0],[0]
RR is supported by the IntelICRI grant: Hybrid Models for Minimally Supervised Information Extraction from Conversations.,Acknowledgments,[0],[0]
The authors are grateful to the anonymous reviewers for their helpful suggestions.,Acknowledgments,[0],[0]
"In this supplemental material, we provide a short comprehensive overview of simple languagespecific morphological rules in English (EN), German (DE), Italian (UT), and Russian (RU).",Morphological Rules,[0],[0]
These rules were used to build the sets of synonymous ATTRACT and antonymous REPEL constraints for our morph-fitting fine-tuning procedure.,Morphological Rules,[0],[0]
"As discussed in the paper, the linguistic constraints extracted from the rules require only a comprehensive list of vocabulary words in each language.",Morphological Rules,[0],[0]
A native speaker of each language used in our experiments is able to easily come up with these sets of morphological rules (or at least with a reasonable subset of rules) without any linguistic training.,Morphological Rules,[0],[0]
"What is more, the rules for German, Italian, and Russian were created by non-native and non-fluent speakers who have only a passive or limited knowledge of the three languages, exemplifying the simplicity and portability of the fine-tuning approach based on the shallow “morphological supervision”.",Morphological Rules,[0],[0]
"The simplicity is also confirmed by the short time used to compile the rules, ranging from a few minutes for English to approximately two hours for Russian.
",Morphological Rules,[0],[0]
"Different languages differ in their “morphological richness” (e.g., declension, verb conjugation, plural forming, gender) which consequently leads to the varying number of rules in each language.",Morphological Rules,[0],[0]
"However, all four languages in our study display morphological regularities described by simple morphological rules that are exploited to build sets of ATTRACT and REPEL linguistic constraints in each language from scratch.9
Vocabularies W in all four languages are labeled Wen, Wde, Wit, Wru.",Morphological Rules,[0],[0]
"We add the pairs (w1, w2) and (w2, w1) generated by the rules to the sets of constraints iff both w1, w2 ∈W .",Morphological Rules,[0],[0]
"After we generate all such constraints, since some constraints may have been generated by more than one rule, we remove all duplicates from the respective sets of ATTRACT and REPEL constraints.
",Morphological Rules,[0],[0]
"Before we start, we will define two simple functions: (i) the function",Morphological Rules,[0],[0]
"w[: −N ] strips the last
9Note that the rules for extracting ATTRACT constraints were additionally used to generate the Morph-SimLex evaluation set, also provided as supplemental material.
",Morphological Rules,[0],[0]
"N characters from the word w, (ii) the function w.ew(sub) tests if the word w ends with a sequence of characters sub.",Morphological Rules,[0],[0]
"For instance, create[: −1] returns creat, while create.ew(’s’) returns False and create.ew(’e’) returns True.",Morphological Rules,[0],[0]
"Inflectional Synonymy: ATTRACT As discussed in the paper, we rely on only two simple inflectional morphological rules in English: - w2 = w1 + ’s’/’ed’/’ing’.",English Rules,[0],[0]
"This rule yields constraints such as (speak, speaking), (turtle, turtles), or (clean, cleaned).",English Rules,[0],[0]
-,English Rules,[0],[0]
"If w1.ew(’e’), then w2 = w1[: −1] + ’ed’/’ing’.",English Rules,[0],[0]
"This rule yields constraints such as (create, creating), or (generate, generated).
",English Rules,[0],[0]
"Derivational Antonymy: REPEL We assume the following set of standard “antonymy” prefixes in English: APen = {’dis’, ’il’, ’un’, ’in’, ’im’,
’ir’, ’mis’, ’non’, ’anti’}.",English Rules,[0],[0]
"We rely on the following derivational rules to extract REPEL pairs: -w2 = ap +w1, where ap ∈ APen.",English Rules,[0],[0]
"This rule yields constraints such as (mature, immature), (allow, disallow) or (regularity, irregularity).",English Rules,[0],[0]
-,English Rules,[0],[0]
"If w1.ew(’ful’), then w2 = w1[: −3] + ’less’.",English Rules,[0],[0]
"This rule yields constraints such as (cheerful, cheerless).
",English Rules,[0],[0]
"As mentioned in the paper, for all four languages we further expand the set of REPEL constraints by transitively combining antonymy pairs with inflectional ATTRACT pairs.",English Rules,[0],[0]
"In simple words, the friend of my enemy is my enemy.",English Rules,[0],[0]
"This means that, given an ATTRACT pair (allow, allows) and a REPEL pair (allow, disallow), we extract another REPEL pair (allows, disallow).",English Rules,[0],[0]
"Inflectional Synonymy: ATTRACT Being morphologically richer than English, the German language naturally requires more rules to describe its (inflectional) morphological richness and variation.",German Rules,[0],[0]
"First, we capture the regular declension of nouns and adjectives by the following heuristic: - Generate a set of words Ww1 = {w1, w2|w2 = w1 + ’e’/’em’/’en’/’er’/’es’}; take the Cartesian product on Ww1 ×Ww1 and then exclude (wi, wi)
pairs with identical words.",German Rules,[0],[0]
"This rule generates pairs such as (schottisch, schottische), (schottischem, schottischen).
",German Rules,[0],[0]
"The second set of rules describes regular verb morphology, i.e., verb conjugation in the present and past tense, and the formation of regular past participles.",German Rules,[0],[0]
"This set of rules may be expressed as: - If w1.ew(’en’), then w′1 = w1[: −2].",German Rules,[0],[0]
"If w′1.ew(’t’), then generate a set of words Ww1 = {w1, w2|w2 = w1 + ’e’/’st’/’ete’/’etest’/’etet’/’eten’, w2 = ’ge’+w′1+ ’et’}, else (if not w′1.ew(’t’)), generate a set of words Ww1 = {w1, w2|w2 = w1 + ’e’/’st’/’te’/’test’/’tet’/’ten’, w2 = ’ge’+w′1+ ’t’}.",German Rules,[0],[0]
We then take the Cartesian product on Ww1 ×Ww1 .,German Rules,[0],[0]
"Again, all pairs with identical words were discarded.",German Rules,[0],[0]
"This rule yields pairs such as (machen, machten), (mache, gemacht), (kaufst, kauft), or (arbeite, arbeitete) and (arbeiten, gearbeitet).
",German Rules,[0],[0]
"Another set of rules targets the regular formation of plural nouns: - If w1.ew(’ei’) or w1.ew(’heit’) or w1.ew(’keit’) or w1.ew(’schaft’) or w1.ew(’ung’), then w2 = w1 + ’en’.",German Rules,[0],[0]
"This rule yields pairs such as (wahrheit, wahrheiten) or (gemeinschaft, gemeinschaften).",German Rules,[0],[0]
-,German Rules,[0],[0]
"If w1.ew(’in’), then w2 = w1 + ’nen’.",German Rules,[0],[0]
"This rule generates pairs such as (lehrerin, lehrerinnen) or (lektorin, lektorinnen).",German Rules,[0],[0]
- Ifw1.ew(’a’/’i’/’o’/’u’/’y’),German Rules,[0],[0]
thenw2 = w1 + ’s’.,German Rules,[0],[0]
"This rule yields pairs such as (auto, autos).",German Rules,[0],[0]
-,German Rules,[0],[0]
"If w1.ew(’e’), then w2 = w1 + ’n’.",German Rules,[0],[0]
"This rule yields pairs such as (postkarte, postkarten).",German Rules,[0],[0]
- w2 = lumlaut(w1) +,German Rules,[0],[0]
"er, where the function lumlaut(w) replaces the last occurrence of the letter ’a’,’o’ or ’u’ with ’ä’,’ö’ or ’ü’.",German Rules,[0],[0]
"This rule generates pairs such as (wörterbuch, wörterbücher) or (stadt, städter).
",German Rules,[0],[0]
"Derivational Antonymy: REPEL We assume the following set of standard “antonymy” prefixes in German: APde = {’un’, ’nicht’, ’anti’, ’ir’, ’in’,
’miss’}.",German Rules,[0],[0]
"We rely on the following derivational rules to extract REPEL pairs in German: - w2 = ap + w1, where ap ∈",German Rules,[0],[0]
APde.,German Rules,[0],[0]
"This rule yields constraints such as (aktiv, inaktiv), (wandelbar, unwandelbar) or (zyklone, antizyklone).",German Rules,[0],[0]
-,German Rules,[0],[0]
"If w1.ew(’voll’), then w2 = w1[: −4] + ’los’.",German Rules,[0],[0]
"This rule yields constraints such as (geschmackvoll, geschmacklos).
",German Rules,[0],[0]
"The set of REPEL is then again transitively expanded yielding pairs such as (relevant, irrelevanter) or (aktivem, inaktiv).",German Rules,[0],[0]
"Inflectional Synonymy: ATTRACT The first set of rules aims at capturing the regular plural forming in Italian (e.g., libro, libri) and regular differences in gender (e.g., rapido, rapida).",Italian Rules,[0],[0]
"We rely on the simple heuristic which can be expressed as follows: - If w1.ew(’a’/’e’/’o’/’i’), then generate a set of words Ww1 =",Italian Rules,[0],[0]
{w2|w2 = w1,Italian Rules,[0],[0]
"[: −1] + ’a’/’e’/’o’/’i’}, and take the Cartesian product on Ww1 ×Ww1 discarding pairs with identical words.",Italian Rules,[0],[0]
"This rule yields pairs such as (nero, neri) or (generazione, generazioni).",Italian Rules,[0],[0]
-,Italian Rules,[0],[0]
"If w1.ew(’ga’/’ca’), then w2 = w1 + ’he’.",Italian Rules,[0],[0]
"This rule generates pairs such as (tartaruga, tartarughe) or (bianca, bianche).",Italian Rules,[0],[0]
-,Italian Rules,[0],[0]
"If w1.ew(’go’), then w2 = w1 + ’hi’.",Italian Rules,[0],[0]
"This rule generates pairs such as (albergo, alberghi).
",Italian Rules,[0],[0]
The second set of rules targets regular verb conjugation in Italian and the formation of regular past participles.,Italian Rules,[0],[0]
"The following rules are used: - If w1.ew(’are’), then generate a set of words Ww1 = {w1, w2|w2 = w1[: −3] + ’iamo’/’ate’/’ano’/’o’/’i’/’a’/’ato’/’ata’/’ati’/’ate’}; take the Cartesian product on Ww1 ×Ww1 discarding pairs with identical words.",Italian Rules,[0],[0]
"This rule results in pairs such as (aspettare, aspettiamo).",Italian Rules,[0],[0]
-,Italian Rules,[0],[0]
"If w1.ew(’ere’), then generate a set of words Ww1 = {w1, w2|w2 = w1[: −3] + ’iamo’/’ete’/’ono’/’o’/’i’/’e’/’uto’/’uta’/’uti’/’ute’}; take the Cartesian product on Ww1 ×Ww1 discarding pairs with identical words.",Italian Rules,[0],[0]
"This rule results in pairs such as (ricevere, ricevete) or (riceve, ricevuto).",Italian Rules,[0],[0]
-,Italian Rules,[0],[0]
"If w1.ew(’ire’), then generate a set of words Ww1 = {w1, w2|w2 = w1",Italian Rules,[0],[0]
[: −3] + ’iamo’/’ite’/’ono’/’o’/’i’/’e’/’ito’/’ita’/’iti’/’ite’}; take the Cartesian product on Ww1 × Ww1 discarding pairs with identical words.,Italian Rules,[0],[0]
"This rule results in pairs such as (dormire, dormono) or (dormi, dormita).
",Italian Rules,[0],[0]
"Derivational Antonymy: REPEL We assume the following set of standard “antonymy” prefixes: APit = {’in’, ’ir’, ’im’, ’anti’}.",Italian Rules,[0],[0]
"The following derivational rule is used to extract REPEL pairs: - w2 = ap + w1, where ap ∈ APit.",Italian Rules,[0],[0]
"This rule yields constraints such as (attivo, inattivo) or (rispettosa, irrispettosa).
",Italian Rules,[0],[0]
"The set of REPEL was then expanded as before, e.g., with additional pairs such as (rispettosa, irrispettosi) generated.",Italian Rules,[0],[0]
Inflectional Synonymy: ATTRACT The first set of rules in Russian targets the regular forming of plural in Russian.,Russian Rules,[0],[0]
A few simple heuristics are used as follows: - w2 = w1 + ’и’/’ы’.,Russian Rules,[0],[0]
"This rule yields pairs such as (aльбом, aльбомы), transliterated as: (al’bom, al’bomy).",Russian Rules,[0],[0]
"- if w1.ew(’a’/’я’/’ь’), then w2 = w1",Russian Rules,[0],[0]
[: −1] + ’и’/’ы’.,Russian Rules,[0],[0]
"This rule generates pairs such as (песня, песни): (pesnja, pesni).",Russian Rules,[0],[0]
"- if w1.ew(’o’), then w2 = w1",Russian Rules,[0],[0]
[: −1] + ’a’.,Russian Rules,[0],[0]
"This rule generates pairs such as (письмо, письма): (pis’mo, pis’ma).",Russian Rules,[0],[0]
"- if w1.ew(’e’), then w2 = w1[: −1] + ’я’.",Russian Rules,[0],[0]
"This rule generates pairs such as (платье, платья): (plat’e, plat’ja).
",Russian Rules,[0],[0]
The next set of rules targets regular verb conjugation of Russian verbs as well as the regular formation of past participles.,Russian Rules,[0],[0]
"We again build a simple heuristic to extract ATTRACT pairs: - if w1.ew(’ти’/’ть’), then generate a set of words Ww1 = {w1, w2|w2 = w1[: −2] + ’у’/’ю’/’ешь’/’ишь’/’ет’/’ит’/’ем’/’им’, w2 = w1[: −2]+ ’ете’/ите’/’ут’/’ют’/’ат’/’ят’, w2 = w1[: −2] + ’нный’/’нная’} and take the Cartesian product on Ww1 ×Ww1 discarding pairs with identical words.",Russian Rules,[0],[0]
"This rule yields pairs such as (варить, варите) or (заканчиваю, заканчивают), transliterated as: (varit’, varite), (zakanchivaju, zakanchivajut).
",Russian Rules,[0],[0]
"Following that, we also utilise the regularities regarding declension processes in Russian, captured by the following rules: - if w1.ew(’a’), then generate a set of words Ww1 = {w1, w2|w2 = w1[: −1] + ’e’/’y’/’ой’} and take the Cartesian product on Ww1 × Ww1 discarding pairs with identical words.",Russian Rules,[0],[0]
"This rule yields pairs such as (работа, работой): (rabota, rabotoj).",Russian Rules,[0],[0]
"- if w1.ew(’я’), then generate a set of words Ww1 = {w1, w2|w2 = w1[: −1] + ’e’/’ю’/’ей’} and take the Cartesian product on Ww1 ×Ww1 discarding pairs with identical words.",Russian Rules,[0],[0]
"This rule yields pairs such as (линия, линию): (linija, liniju).",Russian Rules,[0],[0]
"- if w1.ew(’ы’), then generate a set of words Ww1 = {w1, w2|w2 = w1[: −1] + ’ам’/’ами’/’ах’} and take the Cartesian product
on Ww1 × Ww1 discarding pairs with identical words.",Russian Rules,[0],[0]
"This rule yields pairs such as (работам, работами): (rabotam, rabotami).",Russian Rules,[0],[0]
"- if w1.ew(’и’), then generate a set of words Ww1 = {w1, w2|w2 = w1[: −1] + ’ь’/’ям’/’ями’/’ях’} and take the Cartesian product on Ww1 ×Ww1 discarding pairs with identical words.",Russian Rules,[0],[0]
"This rule yields pairs such as (работам, работами): (rabotam, rabotami).
",Russian Rules,[0],[0]
"Yet another set of rules targets regular adjective comparison and gender: - if w1.ew(’ый’/’ой’/’ий’), then generate a set of words Ww1 = {w1, w2|w2 = w1[: −2] + ’ь’/’ее’/’ые’}.",Russian Rules,[0],[0]
"This rule yields pairs such as (быстрый, быстрее): (bystryj, bystree).",Russian Rules,[0],[0]
"- if w1.ew(’ая’), then generate a set of words Ww1 = {w1, w2|w2 = w1[: −2] + ’ее’/’ыe’/’ый’}.",Russian Rules,[0],[0]
"This rule yields pairs such as (новая, новыe): (novaja, novye).",Russian Rules,[0],[0]
"- if w1.ew(’oe’), then generate a set of words Ww1 = {w1, w2|w2 = w1[: −2] + ’ый’/’ыe’/’ая’}.",Russian Rules,[0],[0]
"This rule yields pairs such as (новое, новый): (novoe, novyj).
",Russian Rules,[0],[0]
Derivational Antonymy: REPEL We assume the following set of standard “antonymy” prefixes in Russian:,Russian Rules,[0],[0]
"APru = {не, анти’}, and simply use the following rule: - w2 = ap + w1, where ap ∈ APru.",Russian Rules,[0],[0]
"This rule yields constraints such as (адекватный, неадекватный) or (вирусная, антивирусная), transliterated as: (adekvatnyj, neadekvatnyj) and (virusnaja, antivirusnaja).
",Russian Rules,[0],[0]
"The further expansion of REPEL constraints yields pairs such as (адекватный, неадекватная): (adekvatnyj, neadekvatnaja).",Russian Rules,[0],[0]
We stress that the listed rules for all four languages are non-exhaustive and do not cover all possible inflectional and derivational morphological phenomena.,Further Discussion,[0],[0]
"More linguistic constraints may be extracted by resorting to more sophisticated rules covering finer-grained morphological processes (e.g., covering irregular plural forming or irregular verb conjugation and past participle forming, or non-standard declensions).",Further Discussion,[0],[0]
"Further, the listed rules, written by non-native speakers without any linguistic training in a very short time span, do not necessarily rely on established linguistic theories in each language, but are rather simple heuristics aiming to capture morphological regularities.",Further Discussion,[0],[0]
Morphologically rich languages accentuate two properties of distributional vector space models: 1) the difficulty of inducing accurate representations for lowfrequency word forms; and 2) insensitivity to distinct lexical relations that have similar distributional signatures.,abstractText,[0],[0]
"These effects are detrimental for language understanding systems, which may infer that inexpensive is a rephrasing for expensive or may not associate acquire with acquires.",abstractText,[0],[0]
"In this work, we propose a novel morph-fitting procedure which moves past the use of curated semantic lexicons for improving distributional vector spaces.",abstractText,[0],[0]
"Instead, our method injects morphological constraints generated using simple language-specific rules, pulling inflectional forms of the same word close together and pushing derivational antonyms far apart.",abstractText,[0],[0]
"In intrinsic evaluation over four languages, we show that our approach: 1) improves low-frequency word estimates; and 2) boosts the semantic quality of the entire word vector collection.",abstractText,[0],[0]
"Finally, we show that morph-fitted vectors yield large gains in the downstream task of dialogue state tracking, highlighting the importance of morphology for tackling long-tail phenomena in language understanding tasks.",abstractText,[0],[0]
Morph-fitting: Fine-Tuning Word Vector Spaces with Simple Language-Specific Rules,title,[0],[0]
"Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 995–1000, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
"SMT from a morphologically poor language like English into a language with richer morphology continues to be a problem, in particular when training data is sparse and/or the SMT system has insufficient modeling capabilities for morphological variation in the target language.",1 Introduction,[0],[0]
"Most previous approaches to this problem have utilized a translate-and-inflect method, where a first-pass SMT system is trained on lemmatized forms, and the correct inflection for every word is predicted in a second pass by statistical classifiers trained on a combination of source and target language features.",1 Introduction,[0],[0]
"This paper looks at morphological modeling from a different perspective, namely to improve SMT in a real-time speech-
to-speech translation system.",1 Introduction,[0],[0]
Our focus is on resolving those morphological translation errors that are most likely to cause confusions and misunderstandings in machine-translation mediated human-human dialogs.,1 Introduction,[0],[0]
"Due to the constraints imposed by a realtime system, previous approaches that rely on elaborate feature sets and multi-pass processing strategies are unsuitable for this problem.",1 Introduction,[0],[0]
The language pair of interest in this study is English and Iraqi Arabic (IA).,1 Introduction,[0],[0]
The latter is a spoken dialect of Arabic with few existing linguistic resources.,1 Introduction,[0],[0]
We therefore develop a low-resource approach that relies on sourceside dependency parses only.,1 Introduction,[0],[0]
We analyze its performance in combination with different types of parsers and different translation models.,1 Introduction,[0],[0]
Results show a significant improvement in translation performance in both automatic and manual evaluations.,1 Introduction,[0.9501888525194577],['Graph-MFN shows superior performance in sentiment analysis and competitive performance in emotion recognition.']
"Moreover, the proposed method is sufficiently fast for a realtime system.",1 Introduction,[0],[0]
"Much work in SMT has addressed the issue of translating from morphologically-rich languages by preprocessing the source and/or target data by e.g., stemming and morphological decomposition (Popovic and Ney, 2004; Goldwater and McClosky, 2005), compound splitting (Koehn and Knight, 2003), or various forms of tokenization (Lee, 2004; Habash and Sadat, 2006).",2 Prior Work,[0],[0]
"In (Minkov et al., 2007; Toutanova et al., 2008) morphological generation was applied as a postprocessing step for translation into morphologically-rich languages.",2 Prior Work,[0],[0]
"A maximumentropy Markov model was trained to predict the correct inflection for every stemmed word in the
995
machine translation output from a first-pass system, conditioned on a set of lexical, morphological and syntactic features.",2 Prior Work,[0],[0]
"More recently, (Chahuneau et al., 2013) applied a similar translate-and-inflect approach, utilizing unsupervised in addition to supervised morphological analyses.",2 Prior Work,[0],[0]
"Inflection generation models were also used by (Fraser et al., 2012; Weller et al., 2013) for translation into German, and by (El Kholy and Habash, 2012) for Modern Standard Arabic.",2 Prior Work,[0],[0]
"(Sultan, 2011) added both syntactic information on the source side that was used in filtering the phrase table, plus postprocessing on the target side for English-Arabic translation.",2 Prior Work,[0],[0]
"Still other approaches enrich the translation system with morphology-aware feature functions or specific agreement models (Koehn and Hoang, 2007; Green and DeNero, 2012; Williams and Koehn, 2011).
",2 Prior Work,[0],[0]
"In contrast to the above studies, which have concentrated on text translation, this paper focuses on spoken language translation within a bilingual human-human dialog system.",2 Prior Work,[0],[0]
"Thus, our main goal is not to predict the correct morphological form of every word, but to prevent communication errors resulting from the mishandling of morphology.",2 Prior Work,[0],[0]
The intended use in a real-time dialog system imposes additional constraints on morphological modeling: any proposed approach should not add a significant computational burden to the overall system that might result in delays in translation or response generation.,2 Prior Work,[0],[0]
"Our goal is also complicated by the fact that our target language is a spoken dialect of Arabic, for which few linguistic resources (training data, lexicons, morphological analyzers) exist.",2 Prior Work,[0],[0]
"Lastly, Arabic written forms are morphologically highly ambiguous due to the lack of short vowel markers that signal grammatical categories.",2 Prior Work,[0],[0]
The first step in the dialog system used for this study consists of an automatic speech recognition (ASR) component that produces ASR hypotheses for the user’s speech input.,3 Dialog System and Analysis,[0],[0]
Several error detection modules then identify likely out-of-vocabulary and misrecognized words.,3 Dialog System and Analysis,[0],[0]
"This information is used by a clarification module that asks the user to rephrase these error segments; another module then combines the user’s answers into a merged, corrected representa-
tion before sending it to the translation engine.",3 Dialog System and Analysis,[0],[0]
"A machine translation error detection module analyzes the translation to check for errors, such as unknown words.",3 Dialog System and Analysis,[0],[0]
"If an error is found, another clarification subdialog is initiated; otherwise, the translation is sent to a text-to-speech engine to produce the acoustic output in the other language.",3 Dialog System and Analysis,[0],[0]
A schematic representation is shown in Figure 1.,3 Dialog System and Analysis,[0],[0]
"More details about the system can be found in (et al., 2013).",3 Dialog System and Analysis,[0],[0]
The system was evaluated in live mode with native IA speakers as part of the DARPA BOLT Phase-II benchmark evaluations.,3 Dialog System and Analysis,[0],[0]
The predefined scenarios included military and humanitarian assistance/disaster relief scenarios as well as general topics.,3 Dialog System and Analysis,[0],[0]
"All system interactions were logged and evaluated by bilingual human assessors.
",3 Dialog System and Analysis,[0],[0]
"During debriefing sessions with the users, some users voiced dissatisfaction with the translation quality, and a subsequent detailed error analysis was conducted on the logs of 30 interactions.",3 Dialog System and Analysis,[0],[0]
"Similar to previous studies (Condon et al., 2010)",3 Dialog System and Analysis,[0],[0]
we found that a frequently recurring problem was wrong morphological verb forms in the IA output.,3 Dialog System and Analysis,[0],[0]
Some examples are shown in Table 1.,3 Dialog System and Analysis,[0],[0]
"In Example 1, to make sure should be translated by a first-person plural verb but it is translated by a second-person plural form, changing the meaning to (you (pl.) make sure).",3 Dialog System and Analysis,[0],[0]
The desired verb form would be ntAkd.,3 Dialog System and Analysis,[0],[0]
"Similarly, in Example 2 the translation of transport should agree with the translations of someone and the preceding
auxiliary verb can (yqdr).",3 Dialog System and Analysis,[0],[0]
The correct form would be yqlk (he/she transports you) instead of nqlk (we transport you).,3 Dialog System and Analysis,[0],[0]
Such translation errors are confusing to users as they affect the understanding of basic semantic roles.,3 Dialog System and Analysis,[0],[0]
They tend to occur when translating English infinitival constructions (to+verb) or other syntactic constructions where English base verb forms need to be translated by a finite verb in IA.,3 Dialog System and Analysis,[0],[0]
"In these cases, explicit morphological features like person and number are required in Arabic but they are lacking in the English input.",3 Dialog System and Analysis,[0],[0]
An analysis of the SMT component showed that morphological translation errors primarily occur when a head word and its dependent (such as a verbal head and its subject noun dependent) are translated as part of different phrases or rules.,4 Approach,[0],[0]
"In that case, insufficient context is available to produce the correct translation.",4 Approach,[0],[0]
Our approach is to annotate syntactic dependencies on the source side using a statistical parser.,4 Approach,[0],[0]
"Based on the resulting dependency structures the source-side data is then tagged with explicit morphological verbal features using deterministic rules (e.g., subject nouns assign their person/number features to their verbal heads), and a new translation model is trained on this data.",4 Approach,[0],[0]
Our assumption is that words tagged with explicit morphological features will be aligned with their correct translations during training and will thus produce correctly inflected forms during testing even when the syntactic context is not available in the same phrase/rule.,4 Approach,[0],[0]
"For instance, the input sentence in Example 1 in Table 1 would be annotated as: you need-2sg to tell-2sg the locals to evacuate-3pl the area",4 Approach,[0],[0]
so we can-1pl secure-1pl the area to make1pl sure no one gets-3sg hurt.,4 Approach,[0],[0]
"This approach avoids the costly extraction of multiple features, subsequent statistical classification, and inflection generation during run time; moreover, it
does not require target-side annotation tools, an advantage when dealing with under-resourced spoken dialects.",4 Approach,[0],[0]
"There are, however, several potential issues with this approach.",4 Approach,[0],[0]
"First, introducing tags fragments the training data: the same word may receive multiple different tags, either due to genuine ambiguity or because of parser errors.",4 Approach,[0],[0]
"As a result, word alignment and phrase extraction may suffer from data sparsity.",4 Approach,[0],[0]
"Second, new word-tag combinations in the test data that were not observed in the training data will not have an existing translation.",4 Approach,[0],[0]
"Third, the performance of the model is highly dependent on the accuracy of the parser.",4 Approach,[0],[0]
"Finally, we make the assumption that the expression of person and number categories are matched across source and target language – in practice, we have indeed seen very few mismatched cases where e.g., a singular noun phrase in English is translated by a plural noun phrase in IA (see Section 6 below).
",4 Approach,[0],[0]
To address the first point the morph-tagged translation model can be used in a backoff procedure rather than as an alternative model.,4 Approach,[0],[0]
"In this case the baseline model is used by default, and the morphtagged model is only used whenever heads and dependents are translated as part of different phrases.",4 Approach,[0],[0]
Unseen translations for particular word-tag combinations in the test set could in principle be addressed by using a morphological analyzer to generate novel word forms with the desired inflections.,4 Approach,[0],[0]
"However, this would require identifying the correct stem for the word in question, generating all possible morphological forms, and either selecting one or providing all options to the SMT system, which again increases system load.",4 Approach,[0],[0]
We analyzed unseen word-tag combination in the test data but found that their percentage was very small (< 1%).,4 Approach,[0],[0]
"Thus, for these forms we back off to the untagged counterparts rather than generating new inflected forms.",4 Approach,[0],[0]
"To obtain better insight into the effect of parsing accuracy we compared the performance of two parsers in our
annotation pipeline: the Stanford parser (de Marneffe et al., 2006) (version 3.3.1) and the Macaon parser (Nasr et al., 2014).",4 Approach,[0],[0]
"The latter is an implementation of graph-based parsing (McDonald et al., 2005) where a projective dependency tree maximizing a score function is sought in the graph of all possible trees using dynamic programming.",4 Approach,[0],[0]
"It uses a 1st-order decoder, which is more robust to speech input as well as out-of-domain training data.",4 Approach,[0],[0]
"The features implemented reflect those of (Bohnet, 2010) (based on lexemes and part-of-speech tags).",4 Approach,[0],[0]
"The parser was trained on Penn-Treebank data transformed to match speech (lower-cased, no punctuation), with one iteration of self-training on the Transtac training set.",4 Approach,[0],[0]
"We also use the combination of both parsers, where source words are only tagged if the tags derived independently from each parser agree with each other.",4 Approach,[0],[0]
Development experiments were carried out on the Transtac corpus of dialogs in the military and medical domain.,5 Data and Baseline Systems,[0],[0]
"The number of sentence pairs is 762k for the training set, 6.9k for the dev set, 2.8k for eval set 1, and 1.8k for eval set 2.",5 Data and Baseline Systems,[0],[0]
"Eval set 1 has one reference per sentence, eval set 2 has four references.",5 Data and Baseline Systems,[0],[0]
"For the development experiments we used a phrase-based Moses SMT system with a hierarchical reordering model, tested on Eval set 1.",5 Data and Baseline Systems,[0],[0]
The language model was a backoff 6-gram model trained using Kneser-Ney discounting and interpolation of higher- and lower-order n-grams.,5 Data and Baseline Systems,[0],[0]
In addition to automatic evaluation we performed manual analyses of the accuracy of verbal features in the IA translations on a subset of 65 sentences (containing 143 verb forms) from the live evaluations described above.,5 Data and Baseline Systems,[0],[0]
"This analysis counts a verb form as correct if its morphological features for person and number are correct, although it may have the wrong lemma (e.g., wrong word sense).",5 Data and Baseline Systems,[0],[0]
The development experiments were designed to identify the setup that produces the highest verbal inflection accuracy.,5 Data and Baseline Systems,[0],[0]
"For final testing we used a more advanced SMT engine on Eval set 2.This system is the one used in the real-time dialog system; it contains a hierarchical phrase-based translation model, sparse features, and a neural network joint model (NNJM) (Devlin et al., 2014).",5 Data and Baseline Systems,[0],[0]
"Results in Table 2 show the comparison between the baseline, different parsers, and the combined system.",6 Experiments and Results,[0],[0]
We see that verbal inflection accuracy increases substantially from the baseline performance and is best for the Macaon parser.,6 Experiments and Results,[0],[0]
"Improvements over the baseline system without morphology are statistically significant; differences between the individual parsers are not (not, however, that the sample size for manual evaluation was quite small).
",6 Experiments and Results,[0],[0]
"BLEU is not affected negatively but even increases slightly - thus, data fragmentation does not seem to be a problem overall.",6 Experiments and Results,[0],[0]
"This may be due to the nature of the task and domain, which is results in fairly short, simple sentence constructions that can be adequately translated by a concatenation of shorter phrases rather than requiring longer phrases.",6 Experiments and Results,[0],[0]
Back-off systems (indicated by bo) and the combined system improve BLEU only trivially while decreasing verbal inflection accuracy by varying amounts.,6 Experiments and Results,[0],[0]
For testing within the dialog system we thus choose the Macaon parser and utilize a standard translation model rather than a backoff model.,6 Experiments and Results,[0],[0]
An added benefit is that the Macaon parser is already used in other components in the dialog system.,6 Experiments and Results,[0],[0]
"Using this setup we ran two experiments with dialog system’s SMT engine: first, we re-extracted phrases and rules based on the morph-tagged data and reoptimized the feature weights.",6 Experiments and Results,[0],[0]
"In the second experiment, we additionally applied the NNJM to the morph-tagged source text.",6 Experiments and Results,[0],[0]
To this end we include all the morphological variants of the original vocabulary that was used for the NNJM in the untagged baseline system.,6 Experiments and Results,[0],[0]
Table 3 shows the results.,6 Experiments and Results,[0],[0]
"The morph-tagged data improves the BLEU score under both conditions: in Experiment 1, the improve-
ment is almost a full BLEU point (0.91); in Experiment 2 the improvement is even larger (1.13), even though the baseline performance is stronger.",6 Experiments and Results,[0],[0]
"Both results are statistically significant at p = 0.05, using a paired bootstrap resampling test.",6 Experiments and Results,[0],[0]
"The combination of morph-tagged data and the more advanced modeling options (sparse features, NNJM) in this system seem to be beneficial.",6 Experiments and Results,[0],[0]
Improved translation performance may also be captured by the four reference translations as opposed to one in Eval set 1.,6 Experiments and Results,[0],[0]
"In order to assess the added computation cost
of our procedure we computed the decoding speed of the MT component in the dialog system for both the baseline and the morpho-tag systems.",6 Experiments and Results,[0],[0]
"In the baseline MT system (with NNJM) without morphotags, decoding takes 0.01572 seconds per word or 0.15408 seconds per sentence – these numbers were obtained on a Dell Precision M4800",6 Experiments and Results,[0],[0]
Laptop with a quad-core Intel i7-4930MX Processor and 32GB of RAM.,6 Experiments and Results,[0],[0]
Morpho-tagging only adds 0.00031 seconds per word or 0.0024 seconds per sentence.,6 Experiments and Results,[0],[0]
"Thus, our procedure is extremely efficient.
",6 Experiments and Results,[0],[0]
"An analysis of the remaining morphological translation errors not captured by our approach showed that in about 34% of all cases these were due to part-of-speech tagging or parser errors, i.e. verbs were mistagged as nouns rather than verbs and thus did not receive any morphological tags, or the parser hypothesized wrong dependency relations.",6 Experiments and Results,[0],[0]
In 53% of the cases the problem is the lack of more extensive discourse or contextual knowledge.,6 Experiments and Results,[0],[0]
"This includes constructions where there is no overt subject for a verb in the current utterance, and the appropriate underlying subject must be inferred from the preceding discourse or from knowledge of the situational context.",6 Experiments and Results,[0],[0]
"This is an instance of the more general problem of control (see e.g.,(Landau, 2013) for an overview of research in this area).",6 Experiments and Results,[0],[0]
It is exemplified by cases such as the following: 1.,6 Experiments and Results,[0],[0]
"The first step is to make sure that all personnel
are in your debrief.",6 Experiments and Results,[0],[0]
"Here, the underlying subject of “to make sure” could be a range of different candidates (I, you, we, etc.) and must be inferred from context.",6 Experiments and Results,[0],[0]
2.,6 Experiments and Results,[0],[0]
I can provide up to one platoon to help you guys cordon off the area.,6 Experiments and Results,[0],[0]
"In this case the statistical parser identified I as the subject of help, but platoon is more likely to be the controller and was in fact identified as the underlying subject by the annotator.",6 Experiments and Results,[0],[0]
"Such cases could potentially be resolved during the parsing step by integrating semantic information, e.g. as in (Bansal et al., 2014).",6 Experiments and Results,[0],[0]
"However, initial investigations with semantic features in the Macaon parser resulted in a significant slow-down of the parser.",6 Experiments and Results,[0],[0]
"In other cases, more sophisticated modeling of the entities and their relationships in the situational context will be required.",6 Experiments and Results,[0],[0]
"This clearly is an area for future study.
",6 Experiments and Results,[0],[0]
"Finally, in 13% of the cases, mistranslations are caused by a mismatch of number features across languages (e.g. number features for nouns such as family or people).",6 Experiments and Results,[0],[0]
We have shown that significant gains in BLEU and verbal inflection accuracy in speech-to-speech translation for English-IA can be achieved by incorporating morphological tags derived from dependency parse information in the source language.,7 Conclusion,[0],[0]
"The proposed method is fast, low-resource, and can easily be incorporated into a real-time dialog system.",7 Conclusion,[0],[0]
It adds negligible computational cost and does not require any target-language specific annotation tools.,7 Conclusion,[0],[0]
"Possible areas for future study include the use of discourse or and other contextual information to determine morphological agreement, application to other languages pairs/morphological agreement types, and learning the annotation rules from data.",7 Conclusion,[0],[0]
This study was funded by the Defense Advanced Research Projects Agency (DARPA) under contract HR0011-12-C-0016 - subcontract 19-000234.,Acknowledgments,[0],[0]
This paper addresses the problem of morphological modeling in statistical speech-tospeech translation for English to Iraqi Arabic.,abstractText,[0],[0]
An analysis of user data from a real-time MT-based dialog system showed that generating correct verbal inflections is a key problem for this language pair.,abstractText,[0],[0]
We approach this problem by enriching the training data with morphological information derived from sourceside dependency parses.,abstractText,[0],[0]
We analyze the performance of several parsers as well as the effect on different types of translation models.,abstractText,[0],[0]
"Our method achieves an improvement of more than a full BLEU point and a significant increase in verbal inflection accuracy; at the same time, it is computationally inexpensive and does not rely on target-language linguistic tools.",abstractText,[0],[0]
Morphological Modeling for Machine Translation of English-Iraqi Arabic Spoken Dialogs,title,[0],[0]
"ar X
iv :1
91 1.
04 91
6v 2
[ cs
.C L
] 1
2 Fe
b 20
21 Appeared in the proceedings of EMNLP 2016 (Austin, November). This version was
Morphological segmentation has traditionally been modeled with non-hierarchical models, which yield flat segmentations as output. In many cases, however, proper morphological analysis requires hierarchical structure— especially in the case of derivational morphology. In this work, we introduce a discriminative, joint model of morphological segmentation along with the orthographic changes that occur during word formation. To the best of our knowledge, this is the first attempt to approach discriminative segmentation with a context-free model. Additionally, we release an annotated treebank of 7454 English words with constituency parses, encouraging future research in this area.1",text,[0],[0]
"In NLP, supervised morphological segmentation has typically been viewed as either a sequence-labeling or a segmentation task (Ruokolainen et al., 2016).",1 Introduction,[0],[0]
"In contrast, we consider a hierarchical approach, employing a context-free grammar (CFG).",1 Introduction,[0],[0]
"CFGs provide a richer model of morphology: They capture (i) the intuition that words themselves have internal constituents, which belong to different categories, as well as (ii) the order in which affixes are attached.",1 Introduction,[0],[0]
"Moreover, many morphological processes, e.g., compounding and reduplication, are best modeled as hierarchical; thus, context-free models are expressively more appropriate.
",1 Introduction,[0],[0]
"The purpose of morphological segmentation is to decompose words into smaller units, known as morphemes, which are typically taken to be the smallest meaning-bearing units in language.
",1 Introduction,[0],[0]
"1We found post publication that CELEX (Baayen et al., 1993) has annotated words for hierarchical morphological segmentation as well.
",1 Introduction,[0],[0]
This work concerns itself with modeling hierarchical structure over these morphemes.,1 Introduction,[0],[0]
Note a simple flat morphological segmentation can also be straightforwardly derived from the CFG parse tree.,1 Introduction,[0],[0]
"Segmentations have found use in a diverse set of NLP applications, e.g., automatic speech recognition (Afify et al., 2006), keyword spotting (Narasimhan et al., 2014), machine translation (Clifton and Sarkar, 2011) and parsing (Seeker and Çetinoğlu, 2015).",1 Introduction,[0],[0]
"In contrast to prior work, we focus on canonical segmentation, i.e., we seek to jointly model orthographic changes and segmentation.",1 Introduction,[0],[0]
"For instance, the canonical segmentation of untestably is un+test+able+ly, where we map ably to able+ly, restoring the letters le.
",1 Introduction,[0],[0]
We make two contributions: (i) We introduce a joint model for canonical segmentation with a CFG backbone.,1 Introduction,[0],[0]
We experimentally show that this model outperforms a semi-Markov model on flat segmentation.,1 Introduction,[0],[0]
"(ii) We release the first morphology treebank, consisting of 7454 English word types, each annotated with a full constituency parse.",1 Introduction,[0],[0]
Why should we analyze morphology hierarchically?,2 The Case For Hierarchical Structure,[0],[0]
"It is true that we can model much of morphology with finite-state machinery (Beesley and Karttunen, 2003), but there are, nevertheless, many cases where hierarchical structure appears requisite.",2 The Case For Hierarchical Structure,[0],[0]
"For instance, the flat segmentation of the word untestably7→un+test+able+ly is missing important information about how the word was derived.",2 The Case For Hierarchical Structure,[0],[0]
"The correct parse [[un[[test]able]]ly], on the other hand, does tell us that this is the order in which the complex form was derived:
test able 7−−→testable un 7−→untestable ly 7−→untestably.
",2 The Case For Hierarchical Structure,[0],[0]
"This gives us insight into the structure of the
lexicon—we expect that the segment testable exists as an independent word, but ably does not.
",2 The Case For Hierarchical Structure,[0],[0]
"Moreover, a flat segmentation is often semantically ambiguous.",2 The Case For Hierarchical Structure,[0],[0]
There are two potentially valid readings of untestably depending on how the negative prefix un scopes.,2 The Case For Hierarchical Structure,[0],[0]
The correct tree (see Figure 1) yields the reading “in the manner of not able to be tested.”,2 The Case For Hierarchical Structure,[0],[0]
A second—likely infelicitous reading—where the segment untest forms a constituent yields the reading “in a manner of being able to untest.”,2 The Case For Hierarchical Structure,[0],[0]
"Recovering the hierarchical structure allows us to select the correct reading; note there are even cases of true ambiguity; e.g., unlockable has two readings: “unable to be locked” and “able to be unlocked.”
",2 The Case For Hierarchical Structure,[0],[0]
"We also note that theoretical linguists often implicitly assume a context-free treatment of word formation, e.g., by employing brackets to indicate different levels of affixation.",2 The Case For Hierarchical Structure,[0],[0]
"Others have explicitly modeled word-internal structure with grammars (Selkirk, 1982; Marvin, 2002).",2 The Case For Hierarchical Structure,[0],[0]
"A novel component of this work is the development of a discriminative parser (Finkel et al., 2008; Hall et al., 2014) for morphology.",3 Parsing the Lexicon,[0],[0]
"The goal is to define a probability distribution over all trees that could arise from the input word, after reversal of orthographic and phonological processes.",3 Parsing the Lexicon,[0],[0]
We employ the simple grammar shown in Table 1.,3 Parsing the Lexicon,[0],[0]
"Despite its simplicity, it models the order in which morphemes are attached.
",3 Parsing the Lexicon,[0],[0]
"More formally, our goal is to map a surface form w (e.g., w=untestably) into its underlying canonical form u (e.g., u=untestablely) and then into a parse tree t over its morphemes.",3 Parsing the Lexicon,[0],[0]
"We assume u,w ∈ Σ∗, for some discrete alphabet Σ.2 Note
2For efficiency, we assume u ∈ Σ|w|+k , k = 5.
that a parse tree over the string implicitly defines a flat segmentation given our grammar—one can simply extract the characters spanned by all preterminals in the resulting tree.",3 Parsing the Lexicon,[0],[0]
"Before describing the joint model in detail, we first consider its pieces individually.",3 Parsing the Lexicon,[0],[0]
"To extract a canonical segmentation (Naradowsky and Goldwater, 2009; Cotterell et al., 2016), we restore orthographic changes that occur during word formation.",3.1 Restoring Orthographic Changes,[0],[0]
"To this end, we define the score function
scoreη(u, a,w) = exp ( g(u, a,w)⊤η )
(1)
where a is a monotonic alignment between the strings u and w.",3.1 Restoring Orthographic Changes,[0],[0]
"The goal is for scoreη to assign higher values to better matched pairs, e.g., (w=untestably, u=untestablely).",3.1 Restoring Orthographic Changes,[0],[0]
"We refer to Dreyer et al. (2008) for a thorough exposition.
",3.1 Restoring Orthographic Changes,[0],[0]
"For ease of computation, we can encode this function as a weighted finite-state machine (WFST) (Mohri et al., 2002).",3.1 Restoring Orthographic Changes,[0],[0]
"This requires, however, that the feature function g factors over the topology of the finite-state encoding.",3.1 Restoring Orthographic Changes,[0],[0]
"Since our model conditions on the word w, the feature function g can extract features from any part of this string.",3.1 Restoring Orthographic Changes,[0],[0]
"Features on the output string, u, however, are more restricted.",3.1 Restoring Orthographic Changes,[0],[0]
"In this work, we employ a bigram model over output characters.",3.1 Restoring Orthographic Changes,[0],[0]
This implies that each state remembers exactly one character: the previous one.,3.1 Restoring Orthographic Changes,[0],[0]
See Cotterell et al. (2014) for details.,3.1 Restoring Orthographic Changes,[0],[0]
We can compute the score for two strings u and w using a weighted generalization of the Levenshtein algorithm.,3.1 Restoring Orthographic Changes,[0],[0]
"Computing the partition function requires a different dynamic program, which runs in O(|w|2 · |Σ|2) time.",3.1 Restoring Orthographic Changes,[0],[0]
"Note that since |Σ| ≈ 26 (lower case English letters), it takes
roughly 262 = 676 times longer to compute the partition function than to score a pair of strings.
",3.1 Restoring Orthographic Changes,[0],[0]
"Our model includes several simple feature tem-
plates, including features that fire on individual edit actions as well as conjunctions of edit actions and characters in the surrounding context.",3.1 Restoring Orthographic Changes,[0],[0]
See Cotterell et al. (2016) for details.,3.1 Restoring Orthographic Changes,[0],[0]
"Next, we need to score an underlying canonical form (e.g., u=untestablely) together with a parse tree (e.g., t=[[un[[test]able]]ly]).",3.2 Morphological Analysis as Parsing,[0],[0]
"Thus, we define the parser score with the following function
scoreω(t, u) = exp


∑
π∈Π(t)
f(π, u)⊤ω

 (2)
where Π(t) is the set of anchored productions in the tree t. An anchored production π is a grammar rule in Chomsky normal form attached to a span, e.g., Ai,k → Bi,jCj,k.",3.2 Morphological Analysis as Parsing,[0],[0]
"Each π is then assigned a weight by the linear function f(π, u)⊤ω, where the function f extracts relevant features from the anchored production as well as the corresponding span of the underlying form u.",3.2 Morphological Analysis as Parsing,[0],[0]
"This model is typically referred to as a weighted CFG (WCFG) (Smith and Johnson, 2007) or a CRF parser.
",3.2 Morphological Analysis as Parsing,[0],[0]
"For f , we define three span features: (i) indicator features on the span’s segment, (ii) an indicator feature that fires if the segment appears in an external corpus3 and (iii) the conjunction of the segment with the label (e.g., PREFIX) of the subtree root.",3.2 Morphological Analysis as Parsing,[0],[0]
"Following Hall et al. (2014), we employ an indicator feature for each production as well as production backoff features.",3.2 Morphological Analysis as Parsing,[0],[0]
"Our complete model is a joint CRF (Koller and Friedman, 2009) where each of
3We use the Wikipedia dump from 2016-05-01.
",4 A Joint Model,[0],[0]
the above scores are factors.,4 A Joint Model,[0],[0]
"We define the following probability distribution over trees, canonical forms and their alignments to the original word
pθ(t,a, u | w) = (3)
1
Zθ(w) scoreω(t, u) · scoreη(u, a,w)
where θ = {ω,η} is the parameter vector and the normalizing partition function as
Zθ(w) = ∑
u′∈Σ|w|+k
∑
a∈A(u′,w)
(4)
∑
t′∈T (u′)
scoreω(t ′, u′) · scoreη(u ′, a, w)
where T (u) is the set of all parse trees for the string u.",4 A Joint Model,[0],[0]
"This involves a sum over all possible underlying orthographic forms and all parse trees for those forms.
",4 A Joint Model,[0],[0]
The joint approach has the advantage that it allows both factors to work together to influence the choice of the underlying form u.,4 A Joint Model,[0],[0]
This is useful as the parser now has access to which words are attested in the language; this helps guide the relatively weak transduction model.,4 A Joint Model,[0],[0]
"On the downside, the partition function Zθ now involves a sum over all strings in Σ|w|+k and all possible parses of each string!",4 A Joint Model,[0],[0]
"Finally, we define the marginal distribution over trees and underlying forms as
pθ(t, u | w) = ∑
a∈A(u,w)
pθ(t, a, u | w) (5)
where A(u,w) is the set of all monotonic alignments between u and w.",4 A Joint Model,[0],[0]
The marginalized form in eq. (5) is our final model of morphological segmentation since we are not interested in the latent alignments a.,4 A Joint Model,[0],[0]
"We use stochastic gradient descent to optimize the log-probability of the training data ∑N
n=1 log pθ(t (n), u(n) | w(n)); this requires the computation of the gradient of the partition function ∇θ logZθ.",4.1 Learning and Inference,[0],[0]
"We may view this gradient as an expectation:
∇θ logZθ(w) =",4.1 Learning and Inference,[0],[0]
"(6)
E(t,a,u)∼pθ(·|w)


∑
π∈Π(t)
f(π, u)⊤ + g(u, a,w)⊤


We provide the full derivation in Appendix A with an additional Rao-Blackwellization step that we make use of in the implementation.",4.1 Learning and Inference,[0],[0]
"While the sum over all underlying forms and trees in eq. (6) may be achieved in polynomial time (using the Bar-Hillel construction), we make use of an importance-sampling estimator, derived by Cotterell et al. (2016), which is faster in practice.",4.1 Learning and Inference,[0],[0]
"Roughly speaking, we approximate the hard-tosample-from distribution pθ by taking samples from an easy-to-sample-from proposal distribution q. Specifically, we employ a pipeline model for q consisting of WFST and then a WCFG sampled from consecutively.",4.1 Learning and Inference,[0],[0]
We then reweight the samples using the unnormalized score from pθ.,4.1 Learning and Inference,[0],[0]
"Importance sampling has found many uses in NLP ranging from language modeling (Bengio et al., 2003) and neural MT (Jean et al., 2015) to parsing (Dyer et al., 2016).",4.1 Learning and Inference,[0],[0]
"Due to a lack of space, we omit the derivation of the importance-sampled approximate gradient.",4.1 Learning and Inference,[0],[0]
We also decode by importance sampling.,4.2 Decoding,[0],[0]
"Given w, we sample canonical forms u and then run the CKY algorithm to get the highest scoring tree.",4.2 Decoding,[0],[0]
We believe our attempt to train discriminative grammars for morphology is novel.,5 Related Work,[0],[0]
"Nevertheless, other researchers have described parsers for morphology.",5 Related Work,[0],[0]
Most of this work is unsupervised: Johnson et al. (2007) applied a Bayesian PCFG to unsupervised morphological segmentation.,5 Related Work,[0],[0]
"Similarly, Adaptor Grammars (Johnson et al., 2006), a non-parametric Bayesian generalization of PCFGs, have been applied to the unsupervised version of the task (Botha and Blunsom, 2013; Sirts and Goldwater, 2013).",5 Related Work,[0],[0]
"Relatedly, Schmid (2005) performed unsupervised disambiguation of a German morphological analyzer (Schmid et al., 2004) using a PCFG, using the inside-outside algo-
rithm (Baker, 1979).",5 Related Work,[0],[0]
"Also, discriminative parsing approaches have been applied to the related problem of Chinese word segmentation (Zhang et al., 2014).",5 Related Work,[0],[0]
"Supervised morphological segmentation has historically been treated as a segmentation problem, devoid of hierarchical structure.",6 Morphological Treebank,[0],[0]
A core reason behind this is that—to the best of our knowledge— there are no hierarchically annotated corpora for the task.,6 Morphological Treebank,[0],[0]
"To remedy this, we provide tree annotations for a subset of the English portion of CELEX (Baayen et al., 1993).",6 Morphological Treebank,[0],[0]
We reannotated 7454 English types with a full constituency parse.4,6 Morphological Treebank,[0],[0]
The resource will be freely available for future research.,6 Morphological Treebank,[0],[0]
The annotation of the morphology treebank was guided by three core principles.,6.1 Annotation Guidelines,[0],[0]
The first principle concerns productivity: we exclusively annotate productive morphology.,6.1 Annotation Guidelines,[0],[0]
"In the context of morphology, productivity refers to the degree that native speakers actively employ the affix to create new words (Aronoff, 1976).",6.1 Annotation Guidelines,[0],[0]
"We believe that for NLP applications, we should focus on productive affixation.",6.1 Annotation Guidelines,[0],[0]
"Indeed, this sets our corpus apart from many existing morphologically annotated corpora such as CELEX.",6.1 Annotation Guidelines,[0],[0]
"For example, CELEX contains warmth7→warm+th, but th is not a productive suffix and cannot be used to create new words.",6.1 Annotation Guidelines,[0],[0]
"Thus, we do not want to analyze hearth7→hear+th or, in general, allow wug7→wug+th.",6.1 Annotation Guidelines,[0],[0]
"Second, we annotate for semantic coherence.",6.1 Annotation Guidelines,[0],[0]
"When there are several candidate parses, we choose the one that is best compatible with the compositional semantics of the derived form.
",6.1 Annotation Guidelines,[0],[0]
"Interestingly, multiple trees can be considered valid depending on the linguistic tier of interest.",6.1 Annotation Guidelines,[0],[0]
Consider the word unhappier.,6.1 Annotation Guidelines,[0],[0]
"From a semantic
4In many cases, we corrected the flat segmentation as well.
perspective, we have the parse",6.1 Annotation Guidelines,[0],[0]
[[un [happy]] er] which gives us the correct meaning “not happy to a greater degree.”,6.1 Annotation Guidelines,[0],[0]
"However, since the suffix er only attaches to mono- and bisyllabic words, we get [un[[happy] er]] from a phonological perspective.",6.1 Annotation Guidelines,[0],[0]
"In the linguistics literature, this problem is known as the bracketing paradox (Pesetsky, 1985; Embick, 2015).",6.1 Annotation Guidelines,[0],[0]
"We annotate exclusively at the syntactic-semantic tier.
",6.1 Annotation Guidelines,[0],[0]
"Thirdly, in the context of derivational morphology, we force spans to be words themselves.",6.1 Annotation Guidelines,[0],[0]
"Since derivational morphology—by definition—forms new words from existing words (Lieber and Štekauer, 2014), it follows that each span rooted with WORD or ROOT in the correct parse corresponds to a word in the lexicon.",6.1 Annotation Guidelines,[0],[0]
"For example, consider unlickable.",6.1 Annotation Guidelines,[0],[0]
"The correct parse, under our scheme, is [un [[lick] able]].",6.1 Annotation Guidelines,[0],[0]
"Each of the spans (lick, lickable and unlickable) exists as a word.",6.1 Annotation Guidelines,[0],[0]
"By contrast, the parse [[un [lick]] able] contains the span unlick, which is not a word in the lexicon.",6.1 Annotation Guidelines,[0],[0]
"The span in the segmented form may involve changes, e.g., [un [[achieve] able]], where achieveable is not a word, but achievable (after deleting e) is.",6.1 Annotation Guidelines,[0],[0]
We run a simple experiment to show the empirical utility of parsing words—we compare a WCFG-based canonical segmenter with the semiMarkov segmenter introduced in Cotterell et al. (2016).,7 Experiments,[0],[0]
We divide the corpus into 10 distinct train/dev/test splits with 5454 words for train and 1000 for each of dev and test.,7 Experiments,[0],[0]
"We report three evaluation metrics: full form accuracy, morpheme F1 (Van den Bosch and Daelemans, 1999) and average edit distance to the gold segmentation with boundaries marked by a distinguished symbol.",7 Experiments,[0],[0]
"For the WCFG model, we also report constituent F1— typical for sentential constituency parsing— as a baseline for future systems.",7 Experiments,[0],[0]
This F1 measures how well we predict the whole tree (not just a segmentation).,7 Experiments,[0],[0]
"For all models, we use L2 regularization and run 100 epochs of ADAGRAD (Duchi et al., 2011) with early stopping.",7 Experiments,[0],[0]
"We tune the regularization coefficient by grid search considering λ ∈ {0.0, 0.1, 0.2, 0.3, 0.4, 0.5}.",7 Experiments,[0],[0]
Table 2 shows the results.,7.1 Results and Discussion,[0],[0]
"The hierarchical WCFG model outperforms the flat semi-Markov model on
all metrics on the segmentation task.",7.1 Results and Discussion,[0],[0]
"This shows that modeling structure among the morphemes, indeed, does help segmentation.",7.1 Results and Discussion,[0],[0]
The largest improvements are found under the morpheme F1 metric (≈ 6.5 points).,7.1 Results and Discussion,[0],[0]
"In contrast, accuracy improves by < 1%.",7.1 Results and Discussion,[0],[0]
Edit distance is in between with an improvement of 0.2 characters.,7.1 Results and Discussion,[0],[0]
"Accuracy, in general, is an all or nothing metric since it requires getting every canonical segment correct.",7.1 Results and Discussion,[0],[0]
"Morpheme F1, on the other hand, gives us partial credit.",7.1 Results and Discussion,[0],[0]
"Thus, what this shows us is that the WCFG gets a lot more of the morphemes in the held-out set correct, even if it only gets a few more complete forms correct.",7.1 Results and Discussion,[0],[0]
We provide additional results evaluating the entire tree with constituency F1 as a future baseline.,7.1 Results and Discussion,[0],[0]
We presented a discriminative CFG-based model for canonical morphological segmentation and showed empirical improvements on its ability to segment words under three metrics.,8 Conclusion,[0],[0]
We argue that our hierarchical approach to modeling morphemes is more often appropriate than the traditional flat segmentation.,8 Conclusion,[0],[0]
"Additionally, we have annotated 7454 words with a morphological constituency parse.",8 Conclusion,[0],[0]
"The corpus is available online at
http://ryancotterell.github.io/data/morphological-treebank to allow for exact comparison and to spark future research.",8 Conclusion,[0],[0]
The first author was supported by a DAAD LongTerm Research Grant and an NDSEG fellowship.,Acknowledgements,[0],[0]
The third author was supported by DFG (SCHU 2246/10-1).,Acknowledgements,[0],[0]
"Here we provide the gradient of the log-partition function as an expectation:
∇θ logZθ(w) = 1
Zθ(w) ∇θZθ(w) (7)
= 1
Zθ(w) ∇θ


∑
u′∈Σ|w|+k
∑
a∈A(u′,w)
∑
t′∈T (u′)
scoreω(t ′, u′) · scoreη(u ′, a, w)


",A Derivation of Eq. 6,[0],[0]
"= 1
Zθ(w)
∑
u′∈Σ|w|+k
∑
a∈A(u′,w)
∑
t′∈T (u′)
∇θ",A Derivation of Eq. 6,[0],[0]
"( scoreω(t ′, u′) · scoreη(u ′, a, w) )
= 1
Zθ(w)
∑
u′∈Σ|w|+k
∑
a∈A(u′,w)
∑
t′∈T (u′)
(
scoreη(u ′, a, w) ·",A Derivation of Eq. 6,[0],[0]
"∇ωscoreω(t ′, u′)
+ scoreω(t ′, u′) · ∇ηscoreη(u ′, a, w) )
",A Derivation of Eq. 6,[0],[0]
"= 1
Zθ(w)
∑
u′∈Σ|w|+k
∑
a∈A(u′,w)
∑
t′∈T (u′)
scoreη(u ′, a, w) ·",A Derivation of Eq. 6,[0],[0]
"scoreω(t ′, u′)


∑
π∈Π(t′)
f(π, u′)⊤ + g(u′, a, w)⊤


= ∑
u′∈Σ|w|+k
∑
a∈A(u′,w)
∑
t′∈T (u′)
scoreη(u ′, a, w) · scoreω(t ′, u′)
Zθ(w)


∑
π∈Π(t′)
f(π, u)⊤ + g(u′, a, w)⊤


= E(t,a,u)∼pθ(·|w)


∑
π∈Π(t)
f(π, u)⊤ + g(u, a,w)⊤

 (8)
The result above can be further improved through Rao-Blackwellization.",A Derivation of Eq. 6,[0],[0]
"In this case, when we sample a tree–underlying form pair (t, u), we marginalize out all alignments that could have given rise to the sampled pair.",A Derivation of Eq. 6,[0],[0]
"The final derivation is show below:
∇θ logZθ(w) = E(t,a,u)∼pθ(·|w)


∑
π∈Π(t)
f(π, u)⊤ + g(u, a,w)⊤


= E(t,u)∼pθ(·|w)


∑
π∈Π(t)
f(π, u)⊤ + ∑
a∈A(u,w)
pθ(a | u,w)g(u, a,w) ⊤

 (9)
",A Derivation of Eq. 6,[0],[0]
This estimator in eq. (9) will have lower variance than eq.,A Derivation of Eq. 6,[0],[0]
(8).,A Derivation of Eq. 6,[0],[0]
"Morphological segmentation has traditionally been modeled with non-hierarchical models, which yield flat segmentations as output.",abstractText,[0],[0]
"In many cases, however, proper morphological analysis requires hierarchical structure— especially in the case of derivational morphology.",abstractText,[0],[0]
"In this work, we introduce a discriminative, joint model of morphological segmentation along with the orthographic changes that occur during word formation.",abstractText,[0],[0]
"To the best of our knowledge, this is the first attempt to approach discriminative segmentation with a context-free model.",abstractText,[0],[0]
"Additionally, we release an annotated treebank of 7454 English words with constituency parses, encouraging future research in this area.",abstractText,[0],[0]
"Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1066–1076, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics
In this paper we study the task of movie script summarization, which we argue could enhance script browsing, give readers a rough idea of the script’s plotline, and speed up reading time. We formalize the process of generating a shorter version of a screenplay as the task of finding an optimal chain of scenes. We develop a graph-based model that selects a chain by jointly optimizing its logical progression, diversity, and importance. Human evaluation based on a question-answering task shows that our model produces summaries which are more informative compared to competitive baselines.",text,[0],[0]
"Each year, about 50,000 screenplays are registered with the WGA1, the Writers Guild of America.",1 Introduction,[0],[0]
Only a fraction of these make it through to be considered for production and an even smaller fraction to the big screen.,1 Introduction,[0],[0]
How do producers and directors navigate through this vast number of scripts available?,1 Introduction,[0],[0]
"Typically, production companies, agencies, and studios hire script readers, whose job is to analyze screenplays that come in, sorting the hopeful from the hopeless.",1 Introduction,[0],[0]
"Having read the script, a reader will generate a coverage report consisting of a logline (one or two sentences describing the story in a nutshell), a synopsis (a two- to three-page long summary of the script), comments explaining its appeal or problematic aspects, and a final verdict as to whether the script merits further consideration.",1 Introduction,[0],[0]
"A script excerpt
1The WGA is a collective term representing US TV and film writers.
from “Silence of the Lambs”, an American thriller released in 1991, is shown in Figure 1.
",1 Introduction,[0],[0]
"Although there are several screenwriting tools for authors (e.g., Final Draft is a popular application which automatically formats scripts to industry standards, keeps track of revisions, allows insertion of notes, and writing collaboratively online), there is a lack of any kind of script reading aids.",1 Introduction,[0],[0]
"Features of such a tool could be to automatically grade the quality of the script (e.g., thumbs up or down), generate
1066
synopses and loglines, identify main characters and their stories, or facilitate browsing (e.g., “show me every scene where there is a shooting”).",1 Introduction,[0],[0]
In this paper we explore whether current NLP technology can be used to address some of these tasks.,1 Introduction,[0],[0]
"Specifically, we focus on script summarization, which we conceptualize as the process of generating a shorter version of a screenplay, ideally encapsulating its most informative scenes.",1 Introduction,[0],[0]
"The resulting summaries can be used to enhance script browsing, give readers a rough idea of the script’s content and plotline, and speed up reading time.
",1 Introduction,[0],[0]
"So, what makes a good script summary?",1 Introduction,[0],[0]
"According to modern film theory, “all films are about nothing — nothing but character” (Monaco, 1982).",1 Introduction,[0],[0]
"Beyond characters, a summary should also highlight major scenes representative of the story and its progression.",1 Introduction,[0],[0]
"With this in mind, we define a script summary as a chain of scenes which conveys a narrative and smooth transitions from one scene to the next.",1 Introduction,[0],[0]
"At the same time, a good chain should incorporate some diversity (i.e., avoid redundancy), and focus on important scenes and characters.",1 Introduction,[0],[0]
We formalize the problem of selecting a good summary chain using a graph-theoretic approach.,1 Introduction,[0],[0]
"We represent scripts as (directed) bipartite graphs with vertices corresponding to scenes and characters, and edge weights to their strength of correlation.",1 Introduction,[0],[0]
"Intuitively, if two scenes are connected, a random walk starting from one would reach the other frequently.",1 Introduction,[0],[0]
"We find a chain of highly connected scenes by jointly optimizing logical progression, diversity, and importance.
",1 Introduction,[0],[0]
"Our contributions in this work are three-fold: we introduce a novel summarization task, on a new text genre, and formalize scene selection as the problem of finding a chain that represents a film’s story; we propose several novel methods for analyzing script content (e.g., identifying important characters and their interactions); and perform a large-scale human evaluation study using a question-answering task.",1 Introduction,[0],[0]
Experimental results show that our method produces summaries which are more informative compared to several competitive baselines.,1 Introduction,[0],[0]
"Computer-assisted analysis of literary text has a long history, with the first studies dating back to the
1960s (Mosteller and Wallace, 1964).",2 Related Work,[0],[0]
"More recently, the availability of large collections of digitized books and works of fiction has enabled researchers to observe cultural trends, address questions about language use and its evolution, study how individuals rise to and fall from fame, perform gender studies, and so on (Michel et al., 2010).",2 Related Work,[0],[0]
"Most existing work focuses on low-level analysis of word patterns, with a few notable exceptions.",2 Related Work,[0],[0]
Elson et al. (2010) analyze 19th century British novels by constructing a conversational network with vertices corresponding to characters and weighted edges corresponding to the amount of conversational interaction.,2 Related Work,[0],[0]
"Elsner (2012) analyzes characters and their emotional trajectories, whereas Nalisnick and Baird (2013) identify a character’s enemies and allies in plays based on the sentiment of their utterances.",2 Related Work,[0],[0]
"Other work (Bamman et al., 2013, 2014) automatically infers latent character types (e.g., villains or heroes) in novels and movie plot summaries.
",2 Related Work,[0],[0]
"Although we are not aware of any previous approaches to summarize screenplays, the field of computer vision is rife with attempts to summarize video (see Reed 2004 for an overview).",2 Related Work,[0],[0]
"Most techniques are based on visual information and rely on low-level cues such as motion, color, or audio (e.g., Rasheed et al. 2005).",2 Related Work,[0],[0]
Movie summarization is a special type of video summarization which poses many challenges due to the large variety of film styles and genres.,2 Related Work,[0],[0]
"A few recent studies (Weng et al., 2009; Lin et al., 2013) have used concepts from social network analysis to identify lead roles and role communities in order to segment movies into scenes (containing one or more shots) and create more informative summaries.",2 Related Work,[0],[0]
A surprising fact about this line of work is that it does not exploit the movie script in any way.,2 Related Work,[0],[0]
Characters are typically identified using face recognition techniques and scene boundaries are presumed unknown and are automatically detected.,2 Related Work,[0],[0]
"A notable exception are Sang and Xu (2010) who generate video summaries for movies, while taking into account character interaction features which they estimate from the corresponding screenplay.
",2 Related Work,[0],[0]
Our own approach is inspired by work in egocentric video analysis.,2 Related Work,[0],[0]
"An egocentric video offers a first-person view of the world and is captured from a wearable camera focusing on the user’s activities,
social interactions, and interests.",2 Related Work,[0],[0]
"Lu and Grauman (2013) present a summarization model which extracts subshot sequences while finding a balance of important subshots that are both diverse and provide a natural progression through the video, in terms of prominent visual objects (e.g., bottle, mug, television).",2 Related Work,[0],[0]
"We adapt their technique to our task, and show how to estimate character-scene correlations based on linguistic analysis.",2 Related Work,[0],[0]
We also interpret movies as social networks and extract a rich set of features from character interactions and their sentiment which we use to guide the summarization process.,2 Related Work,[0],[0]
"We compiled ScriptBase, a collection of 1,276 movie scripts, by automatically crawling web-sites which host or link entire movie scripts (e.g., imsdb.com).",3 ScriptBase: A Movie Script Corpus,[0],[0]
"The retrieved scripts were then cross-matched against Wikipedia2 and IMDB3 and paired with corresponding user-written summaries, plot sections, loglines and taglines (taglines are short snippets used by marketing departments to promote a movie).",3 ScriptBase: A Movie Script Corpus,[0],[0]
"We also collected metainformation regarding the movie’s genre, its actors, the production year, etc.",3 ScriptBase: A Movie Script Corpus,[0],[0]
"ScriptBase contains movies comprising 23 genres; each movie is on average accompanied by 3 user summaries, 3 loglines, and 3 taglines.",3 ScriptBase: A Movie Script Corpus,[0],[0]
The corpus spans years 1909–2013.,3 ScriptBase: A Movie Script Corpus,[0],[0]
"Some corpus statistics are shown in Figure 2.
",3 ScriptBase: A Movie Script Corpus,[0],[0]
"The scripts were further post-processed with the Stanford CoreNLP pipeline (Manning et al., 2014) to perform tagging, parsing, named entity recognition and coreference resolution.",3 ScriptBase: A Movie Script Corpus,[0],[0]
"They were also annotated with semantic roles (e.g., ARG0, ARG1), using the MATE tools (Björkelund et al., 2009).",3 ScriptBase: A Movie Script Corpus,[0],[0]
Our summarization experiments focused on comedies and thrillers.,3 ScriptBase: A Movie Script Corpus,[0],[0]
"We randomly selected 30 movies
2http://en.wikipedia.org 3http://www.imdb.com/
for training/development and 65 movies for testing.",3 ScriptBase: A Movie Script Corpus,[0],[0]
"As mentioned earlier, we define script summarization as the task of selecting a chain of scenes representing the movie’s most important content.",4 The Scene Extraction Model,[0],[0]
We interpret the term scene in the screenplay sense.,4 The Scene Extraction Model,[0],[0]
A scene is a unit of action that takes place in one location at one time (see Figure 1).,4 The Scene Extraction Model,[0],[0]
"We therefore need not be concerned with scene segmentation; scene boundaries are clearly marked, and constitute the basic units over which our model operates.
",4 The Scene Extraction Model,[0],[0]
"Let M = (S,C) represent a screenplay consisting of a set S = {s1,s2, . . .",4 The Scene Extraction Model,[0],[0]
",sn} of scenes, and a set C = {c1, . . .",4 The Scene Extraction Model,[0],[0]
",cm} of characters.",4 The Scene Extraction Model,[0],[0]
"We are interested in finding a list S′ = {si, . .",4 The Scene Extraction Model,[0],[0]
.sk},4 The Scene Extraction Model,[0],[0]
"of ordered, consecutive scenes subject to a compression rate m (see the example in Figure 3).",4 The Scene Extraction Model,[0],[0]
A natural interpretation of m in our case is the percentage of scenes from the original script retained in the summary.,4 The Scene Extraction Model,[0],[0]
"The extracted chain should contain (a) important scenes (i.e., critical for comprehending the story and its development); (b) diverse scenes that cover different aspects of the story; and (c) scenes which highlight the story’s progression from beginning to end.",4 The Scene Extraction Model,[0],[0]
"We therefore find the chain S′ maximizing the objective function Q(S′) which is the weighted sum of three terms: the story progression P, scene diversity D, and scene importance I:
S∗ = argmax S′⊂S Q(S′)",4 The Scene Extraction Model,[0],[0]
"(1) Q(S′) = λPP(S′)+λDD(S′)+λII(S′) (2)
In the following, we define each of the three terms.
",4 The Scene Extraction Model,[0],[0]
Scene-to-scene Progression The first term in the objective is responsible for selecting chains representing a logically coherent story.,4 The Scene Extraction Model,[0],[0]
"Intuitively, this means that if our chain includes a scene where a character commits an action, then scenes involving affected parties or follow-up actions should also be included.",4 The Scene Extraction Model,[0],[0]
"We operationalize this idea of progression in a story in terms of how strongly the characters in a selected scene si influence the transition to the next scene si+1:
P(S′)",4 The Scene Extraction Model,[0],[0]
"= |S′|−1 ∑ i=0 ∑ c∈Ci INF(si,si+1|c) (3)
We represent screenplays as weighted, bipartite graphs connecting scenes and characters:
B = (V,E) : V = C∪S
E = {(s,c,ws,c)|s ∈ S, c ∈C, ws,c ∈",4 The Scene Extraction Model,[0],[0]
"[0,1]}∪ {(c,s,wc,s)|c ∈C, s ∈ S, wc,s ∈",4 The Scene Extraction Model,[0],[0]
"[0,1]}
The set of vertices V corresponds to the union of characters C and scenes S. We therefore add to the bipartite graph one node per scene and one node per character, and two directed edges for each scene-character and character-scene pair.",4 The Scene Extraction Model,[0],[0]
An example of a bipartite graph is shown in Figure 4.,4 The Scene Extraction Model,[0],[0]
"We further assume that two scenes si and si+1 are tightly connected in such a graph if a random walk with restart (RWR; Tong et al. 2006; Kim et al. 2014) which starts in si has a high probability of ending in si+1.
",4 The Scene Extraction Model,[0],[0]
"In order to calculate the random walk stationary distributions, we must estimate the weights between a character and a scene.",4 The Scene Extraction Model,[0],[0]
"We are interested in how important a character is generally in the movie, and
specifically in a particular scene.",4 The Scene Extraction Model,[0],[0]
"For wc,s, we consider the probability of a character being important, i.e., of them belonging to the set of main characters:
wc,s = P(c ∈ main(M)), ∀(c,s,wc,s) ∈ E (4)
where P(c ∈main(M)) is some probability score associated with c being a main character in script M. For ws,c, we take the number of interactions a character is involved in relative to the total number of interactions in a specific scene as indicative of the character’s importance in that scene.",4 The Scene Extraction Model,[0],[0]
"Interactions refer to conversational interactions as well as relations between characters (e.g., who does what to whom):
ws,c = ∑
c′∈Cs inter(c,c′)
∑ c1,c2∈Cs
inter(c1,c2) , ∀(s,c,ws,c) ∈ E (5)
",4 The Scene Extraction Model,[0],[0]
We defer discussion of how we model probability P(c ∈Main(M)) and obtain interaction counts to Section 5.,4 The Scene Extraction Model,[0],[0]
"Weights ws,c and wc,s are normalized:
ws,c = ws,c
∑(s,c′,w′s,c) w ′",4 The Scene Extraction Model,[0],[0]
"s,c
, ∀(s,c,ws,c) ∈ E (6)
wc,s = wc,s
∑(c,s′,w′c,s) w ′",4 The Scene Extraction Model,[0],[0]
"c,s
, ∀(c,s,wc,s) ∈ E (7)
",4 The Scene Extraction Model,[0],[0]
"We calculate the stationary distributions of a random walk on a transition matrix T , enumerating over all vertices v (i.e., characters and scenes) in the bipartite graph B:
T (i, j) = { wi, j if (vi,v j,wi, j ∈ EB) 0",4 The Scene Extraction Model,[0],[0]
"otherwise
(8)
We measure the influence individual characters have on scene-to-scene transitions as follows.",4 The Scene Extraction Model,[0],[0]
"The stationary distribution rk for a RWR walker starting at node k is a vector that satisfies:
rk = (1− ε)Trk + εek (9)
where T is the transition matrix of the graph, ek is a seed vector, with all elements 0, except for element k which is set to 1, and ε is a restart probability parameter.",4 The Scene Extraction Model,[0],[0]
"In practice, our vectors rk and ek are indexed by the scenes and characters in a movie, i.e., they have length |S|+ |C|, and their nth element corresponds either to a known scene or character.",4 The Scene Extraction Model,[0],[0]
"In cases where
graphs are relatively small, we can compute r directly4 by solving:
rk = ε(I− (1− ε)T )−1ek (10)
",4 The Scene Extraction Model,[0],[0]
The lth element of r then equals the probability of the random walker being in state l in the stationary distribution.,4 The Scene Extraction Model,[0],[0]
"Let rck be the same as rk, but with the character node c of the bipartite graph being turned into a sink, i.e., all entries for c in the transition matrix T are 0.",4 The Scene Extraction Model,[0],[0]
"We can then define how a single character influences the transition between scenes si and si+1 as:
INF(si,si+1|c) = rsi",4 The Scene Extraction Model,[0],[0]
"[si+1]− rcsi [si+1] (11)
where rsi",4 The Scene Extraction Model,[0],[0]
[si+1] is shorthand for that element in the vector rsi that corresponds to scene si+1.,4 The Scene Extraction Model,[0],[0]
"We use the INF score directly in Equation (3) to determine the progress score of a candidate chain.
",4 The Scene Extraction Model,[0],[0]
Diversity The diversity term D(S′),4 The Scene Extraction Model,[0],[0]
"in our objective should encourage chains which consist of more dissimilar scenes, thereby avoiding redundancy.",4 The Scene Extraction Model,[0],[0]
"The diversity of chain S′ is the sum of the diversities of its successive scenes:
D(S′) = |S′|−1",4 The Scene Extraction Model,[0],[0]
"∑ i=1 d(si,si+1) (12)
",4 The Scene Extraction Model,[0],[0]
"The diversity d(si,si+1) of two scenes si and si+1 is estimated taking into account two factors: (a) do they have any characters in common, and (b) does the sentiment change from one scene to the next:
d(si,si+1) = dchar(si,si+1)+dsen(si,si+1)
2 (13)
where dchar(si,si+1) and dsen(si,si+1) respectively denote character and sentiment similarity between scenes.",4 The Scene Extraction Model,[0],[0]
"Specifically, dchar(si,si+1) is the relative character overlap between scenes si and si+1:
dchar(si,si+1)",4 The Scene Extraction Model,[0],[0]
=,4 The Scene Extraction Model,[0],[0]
"1− |Csi ∩Csi+1 ||Csi ∪Csi+1 | (14)
dchar will be 0 if two scenes share the same characters and 1 if no characters are shared.",4 The Scene Extraction Model,[0],[0]
"Analogously,
4We could also solve for r recursively which would be preferable for large graphs, since the performed matrix inversion is computationally expensive.
",4 The Scene Extraction Model,[0],[0]
"we define dsen, the sentiment overlap between two scenes as:
dsen(si,si+1)",4 The Scene Extraction Model,[0],[0]
"=1− k ·di f (si,si+1)k− k ·di f (si,si+1)+1 (15) di f (si,si+1) = 1
1+ |sen(si)− sen(si+1)| (16)
where the sentiment sen(s) of scene s is the aggregate sentiment score of all interactions in s:
sen(s) = ∑ c,c′∈Cs
sen(inter(c,c′))",4 The Scene Extraction Model,[0],[0]
"(17)
We explain how interactions and their sentiment are computed in Section 5.",4 The Scene Extraction Model,[0],[0]
"Again, dsen is larger if two scenes have a less similar sentiment.",4 The Scene Extraction Model,[0],[0]
"di f (si,si+1) becomes 1 if the sentiments are identical, and increasingly smaller for more dissimilar sentiments.",4 The Scene Extraction Model,[0],[0]
"The sigmoid-like function in Equation (15) scales dsen within range [0,1] to take smaller values for larger sentiment differences (factor k adjusts the curve’s smoothness).
",4 The Scene Extraction Model,[0],[0]
Importance The score I(S′) captures whether a chain contains important scenes.,4 The Scene Extraction Model,[0],[0]
"We define I(S′) as the sum of all scene-specific importance scores imp(si) of scenes contained in the chain:
I(S′) =",4 The Scene Extraction Model,[0],[0]
|S′|,4 The Scene Extraction Model,[0],[0]
"∑ i=1 imp(si) (18)
",4 The Scene Extraction Model,[0],[0]
"The importance imp(si) of a scene si is the ratio of lead to support characters within that scene:
imp(si) = ∑c: c∈Csi∧c∈main(M) 1
∑c: c∈Csi 1 (19)
where Csi is the set of characters present in scene si, and main(M) is the set of main characters in the movie.5 I(si) is 0 if a scene does not contain any main characters, and 1 if it contains only main characters (see Section 5 for how main(M) is inferred).
",4 The Scene Extraction Model,[0],[0]
Optimal Chain Selection We use Linear Programming to efficiently find a good chain.,4 The Scene Extraction Model,[0],[0]
"The objective is to maximize Equation (2), i.e., the sum of the terms for progress, diversity and importance,
5Whether scenes are important if they contain many main characters is an empirical question in its own right.",4 The Scene Extraction Model,[0],[0]
"For our purposes, we assume that this relation holds.
subject to their weights λ.",4 The Scene Extraction Model,[0],[0]
"We add a constraint corresponding to the compression rate, i.e., the number of scenes to be selected and enforce their linear order by disallowing non-consecutive combinations.",4 The Scene Extraction Model,[0],[0]
We use GLPK6 to solve the linear problem.,4 The Scene Extraction Model,[0],[0]
In this section we discuss several aspects of the implementation of the model presented in the previous section.,5 Implementation,[0],[0]
We explain how interactions are extracted and how sentiment is calculated.,5 Implementation,[0],[0]
"We also present our method for identifying main characters and estimating the weights ws,c and wc,s in the bipartite graph.
",5 Implementation,[0],[0]
Interactions The notion of interaction underlies many aspects of the model defined in the previous section.,5 Implementation,[0],[0]
"For instance, interaction counts are required to estimate the weights ws,c in the bipartite graph of the progression term (see Equation (5)), and in defining diversity (see Equations (15)–(17)).",5 Implementation,[0],[0]
"As we shall see below, interactions are also important for identifying main characters in a screenplay.
",5 Implementation,[0],[0]
"We use the term interaction to refer to conversations between two characters, as well as their relations (e.g., if a character kills another).",5 Implementation,[0],[0]
"For conversational interactions, we simply need to identify the speaker generating an utterance and the listener.",5 Implementation,[0],[0]
"Speaker attribution comes for free in our case, as speakers are clearly marked in the text (see Figure 1).",5 Implementation,[0],[0]
"Listener identification is more involved, especially when there are multiple characters in a scene.",5 Implementation,[0],[0]
We rely on a few simple heuristics.,5 Implementation,[0],[0]
"We assume that the previous speaker in the same scene, who is different from the current speaker, is the listener.",5 Implementation,[0],[0]
"If there is no previous speaker, we assume that the listener is the closest character mentioned in the speaker’s utterance (e.g., via a coreferring proper name or a pronoun).",5 Implementation,[0],[0]
"In cases where we cannot find a suitable listener, we assume the current speaker is the listener.
",5 Implementation,[0],[0]
We obtain character relations from the output of a semantic role labeler.,5 Implementation,[0],[0]
Relations are denoted by verbs whose ARG0 and ARG1 roles are character names.,5 Implementation,[0],[0]
We extract relations from the dialogue but also from scene descriptions.,5 Implementation,[0],[0]
"For example, in Figure 1 the description Suddenly, [...] he
6https://www.gnu.org/software/glpk/
clubs her over the head contains the relation clubs(MAN,CATHERINE).",5 Implementation,[0],[0]
"Pronouns are resolved to their antecedent using the Stanford coreference resolution system (Lee et al., 2011).
",5 Implementation,[0],[0]
"Sentiment We labeled lexical items in screenplays with sentiment values using the AFINN-96 lexicon (Nielsen, 2011), which is essentially a list of words scored with sentiment strength within the range",5 Implementation,[0],[0]
"[−5,+5].",5 Implementation,[0],[0]
The list also contains obscene words (which are often used in movies) and some Internet slang.,5 Implementation,[0],[0]
"By summing over the sentiment scores of individual words, we can work out the sentiment of an interaction between two characters, the sentiment of a scene (see Equation (17)), and even the sentiment between characters (e.g., who likes or dislikes whom in the movie in general).
",5 Implementation,[0],[0]
Main Characters,5 Implementation,[0],[0]
"The progress term in our summarization objective crucially relies on characters and their importance (see the weight wc,s in Equation (4)).",5 Implementation,[0],[0]
"Previous work (Weng et al., 2009; Lin et al., 2013) extracts social networks where nodes correspond to roles in the movie, and edges to their co-occurrence.",5 Implementation,[0],[0]
"Leading roles (and their communities) are then identified by measuring their centrality in the network (i.e., number of edges terminating in a given node).
",5 Implementation,[0],[0]
It is relatively straightforward to obtain a social network from a screenplay.,5 Implementation,[0],[0]
"Formally, for each movie we define a weighted and undirected graph:
G = {C,E}, : C = {c1, . .",5 Implementation,[0],[0]
.cn},5 Implementation,[0],[0]
", E = {(ci,c j,w)|ci,c j ∈C, w ∈",5 Implementation,[0],[0]
"N>0}
where vertices correspond to movie characters7, and edges denote character-to-character interactions.",5 Implementation,[0],[0]
Figure 5 shows an example of a social network for “The Silence of the Lambs”.,5 Implementation,[0],[0]
"Due to lack of space, only main characters are displayed, however the actual graph contains all characters (42 in this case).",5 Implementation,[0],[0]
"Importantly, edge weights are not normalized, but directly reflect the strength of association between different characters.
",5 Implementation,[0],[0]
We do not solely rely on the social network to identify main characters.,5 Implementation,[0],[0]
"We estimate P(c ∈ main(M)), the probability of c being a leading character in movie M, using a Multi Layer
7We assume one node per speaking role in the script.
",5 Implementation,[0],[0]
Perceptron (MLP) and several features pertaining to the structure of the social network and the script text itself.,5 Implementation,[0],[0]
"A potential stumbling block in treating character identification as a classification task is obtaining training data, i.e., a list of main characters for each movie.",5 Implementation,[0],[0]
"We generate a gold-standard by assuming that the characters listed under Wikipedia’s Cast section (or an equivalent section, e.g., Characters) are the main characters in the movie.
",5 Implementation,[0],[0]
"Examples of the features we used for the classification task include the barycenter of a character (i.e., the sum of its distance to all other characters),",5 Implementation,[0],[0]
"PageRank (Page et al., 1999), an eigenvectorbased centrality measure, absolute/relative interaction weight (the sum of all interactions a character is involved in, divided by the sum of all interactions in the network), absolute/relative number of sentences uttered by a character, number of times a character is described by other characters (e.g., He is a monster or She is nice), number of times a character talks about other characters, and type-tokenratio of sentences uttered by the character (i.e., rate of unique words in a character’s speech).",5 Implementation,[0],[0]
"Using these features, the MLP achieves an F1 of 79.0% on the test set.",5 Implementation,[0],[0]
It outperforms other classification methods such as Naive Bayes or logistic regression.,5 Implementation,[0],[0]
"Using the full-feature set, the MLP also obtains performance superior to any individual measure of graph connectivity.
",5 Implementation,[0],[0]
"Aside from Equation (4), lead characters also appear in Equation (19), which determines scene importance.",5 Implementation,[0],[0]
We assume a character c ∈ main(M) if it is predicted by the MLP with a probability ≥ 0.5.,5 Implementation,[0],[0]
Gold Standard Chains The development and tuning of the chain extraction model presented in Section 4 necessitates access to a gold standard of key scene chains representing the movie’s most important content.,6 Experimental Setup,[0],[0]
Our experiments concentrated on a sample of 95 movies (comedies and thrillers) from the ScriptBase corpus (Section 3).,6 Experimental Setup,[0],[0]
Performing the scene selection task for such a big corpus manually would be both time consuming and costly.,6 Experimental Setup,[0],[0]
"Instead, we used distant supervision based on Wikipedia to automatically generate a gold standard.
",6 Experimental Setup,[0],[0]
"Specifically, we assume that Wikipedia plots are representative of the most important content in a movie.",6 Experimental Setup,[0],[0]
"Using the alignment algorithm presented in Nelken and Shieber (2006), we align script sentences to Wikipedia plot sentences and assume that scenes with at least one alignment are part of the gold chain of scenes.",6 Experimental Setup,[0],[0]
We obtain many-to-many alignments using features such as lemma overlap and word stem similarity.,6 Experimental Setup,[0],[0]
"When evaluated on four movies8 (from the training set) whose content was manually aligned to Wikipedia plots, the aligner achieved a precision of .53 at a recall rate of .82 at deciding whether a scene should be aligned.",6 Experimental Setup,[0],[0]
Scenes are ranked according to the number of alignments they contain.,6 Experimental Setup,[0],[0]
"When creating gold chains at different compression rates, we start with the best-ranked scenes and then successively add lower ranked ones until we reach the desired compression rate.
",6 Experimental Setup,[0],[0]
System Comparison In our experiments we compared our scene extraction model (SceneSum) against three baselines.,6 Experimental Setup,[0],[0]
The first baseline was based on the minimum overlap (MinOv) of characters in consecutive scenes and corresponds closely to the diversity term in our objective.,6 Experimental Setup,[0],[0]
The second baseline was based on the maximum overlap (MaxOv) of characters and approximates the importance term in our objective.,6 Experimental Setup,[0],[0]
"The third baseline selects scenes at random (averaged over 1,000 runs).",6 Experimental Setup,[0],[0]
"Parameters for our models were tuned on the training set, weights for the terms in the objective were optimized to the following values: λP = 1.0, λD = 0.3, and λI = 0.1.",6 Experimental Setup,[0],[0]
"We set the restart probability of our random walker
8“Cars 2”, “Shrek”, “Swordfish”, and “The Silence of the Lambs”.
to ε = 0.5, and the sigmoid scaling factor in our diversity term to k =−1.2.
",6 Experimental Setup,[0],[0]
Evaluation We assessed the output of our model (and comparison systems) automatically against the gold chains described above.,6 Experimental Setup,[0],[0]
We performed experiments with compression rates in the range of 10% to 50% and measured performance in terms of F1.,6 Experimental Setup,[0],[0]
"In addition, we also evaluated the quality of the extracted scenes as perceived by humans, which is necessary, given the approximate nature of our gold standard.",6 Experimental Setup,[0],[0]
"We adopted a question-answering (Q&A) evaluation paradigm which has been used previously to evaluate summaries and document compression (Morris et al., 1992; Mani et al., 2002; Clarke and Lapata, 2010).",6 Experimental Setup,[0],[0]
"Under the assumption that the summary is to function as a replacement for the full script, we can measure the extent to which it can be used to find answers to questions which have been derived from the entire script and are representative of its core content.",6 Experimental Setup,[0],[0]
"The more questions a hypothetical system can answer, the better it is at summarizing the script as a whole.
",6 Experimental Setup,[0],[0]
Two annotators were independently instructed to read scripts (from our test set) and create Q&A pairs.,6 Experimental Setup,[0],[0]
"The annotators generated questions relating to the plot of the movie and the development of its characters, requiring an unambiguous answer.",6 Experimental Setup,[0],[0]
They compared and revised their Q&A pairs until a common agreed-upon set of five questions per movie was reached (see Table 1 for an example).,6 Experimental Setup,[0],[0]
"In addition, for every movie we asked subjects to name the main characters, and summarize its plot (in no more than four sentences).",6 Experimental Setup,[0],[0]
"Using Amazon Mechanical Turk (AMT)9, we elicited answers for eight scripts (four comedies and thrillers) in four summarization con-
9https://www.mturk.com/
ditions: using our model, the two baselines based on minimum and maximum character overlap, and the random system.",6 Experimental Setup,[0],[0]
"All models were assessed at the same compression rate of 20% which seems realistic in an actual application environment, e.g., computer aided summarization.",6 Experimental Setup,[0],[0]
The scripts were preselected in an earlier AMT study where participants were asked to declare whether they had seen the movies in our test set (65 in total).,6 Experimental Setup,[0],[0]
We chose the screenplays which had received the least viewings so as to avoid eliciting answers based on familiarity with the movie.,6 Experimental Setup,[0],[0]
"A total of 29 participants, all self-reported native English speakers, completed the Q&A task.",6 Experimental Setup,[0],[0]
The answers provided by the subjects were scored against an answer key.,6 Experimental Setup,[0],[0]
"A correct answer was marked with a score of one, and zero otherwise.",6 Experimental Setup,[0],[0]
"In cases where more answers were required per question, partial scores were awarded to each correct answer (e.g., 0.5).",6 Experimental Setup,[0],[0]
The score for a summary is the average of its question scores.,6 Experimental Setup,[0],[0]
"Table 2 shows the performance of SceneSum, our scene extraction model, and the three comparison systems (MaxOv, MinOv, Random) on the automatic gold standard at five compression rates.",7 Results,[0],[0]
"As can be seen, MaxOv performs best in terms of F1, followed by SceneSum.",7 Results,[0],[0]
We believe this is an artifact due to the way the gold standard was created.,7 Results,[0],[0]
Scenes with large numbers of main characters are more likely to figure in Wikipedia plot summaries and will thus be more frequently aligned.,7 Results,[0],[0]
"A chain based on maximum character overlap will focus on such scenes and will agree with the gold standard better compared to chains which take additional script properties into account.
",7 Results,[0],[0]
We further analyzed the scenes selected by SceneSum and the comparison systems with respect to their position in the script.,7 Results,[0],[0]
"Table 3 shows the av-
erage percentage of scenes selected from the beginning, middle, and end of the movie (based on an equal division of the number of scenes in the screenplay).",7 Results,[0],[0]
"As can be seen, the number of selected scenes tends to be evenly distributed across the entire movie.",7 Results,[0],[0]
"SceneSum has a slight bias towards the beginning of the movie which is probably natural, since leading characters appear early on, as well as important scenes introducing essential story elements (e.g., setting, points of view).
",7 Results,[0],[0]
The results of our human evaluation study are summarized in Table 4.,7 Results,[0],[0]
We observe that SceneSum summaries are overall more informative compared to those created by the baselines.,7 Results,[0],[0]
"In other words, AMT participants are able to answer more questions regarding the story of the movie when reading SceneSum summaries.",7 Results,[0],[0]
"In two instances (“A Nightmare on Elm Street 3” and “Mumford”), the overlap models score better, however, in this case the movies largely consist of scenes with the same characters and relatively little variation (“A Nightmare on Elm Street 3”), or the camera follows the main lead in his interactions with other characters (“Mumford”).",7 Results,[0],[0]
"Since our model is not so character-centric, it might be thrown off by non-character-based terms in its objective, leading to the selection of unfavorable scenes.",7 Results,[0],[0]
Table 4 also presents a break down of the different types of questions answered by our participants.,7 Results,[0],[0]
"Again, we see that in most cases a larger percentage is answered correctly when reading SceneSum summaries.
",7 Results,[0],[0]
"Overall, we observe that SceneSum extracts chains which encapsulate important movie content across the board.",7 Results,[0],[0]
"We should point out that although our movies are broadly classified as comedies and thrillers, they have very different structure and content.",7 Results,[0],[0]
"For example, “Little Athens” has a very loose plotline, “Living in Oblivion” has multi-
ple dream sequences, whereas “While She was Out” contains only a few characters and a series of important scenes towards the end.",7 Results,[0],[0]
"Despite this variety, SceneSum performs consistently better in our taskbased evaluation.",7 Results,[0],[0]
In this paper we have developed a graph-based model for script summarization.,8 Conclusions,[0],[0]
"We formalized the process of generating a shorter version of a screenplay as the task of finding an optimal chain of scenes, which are diverse, important, and exhibit logical progression.",8 Conclusions,[0],[0]
A large-scale evaluation based on a question-answering task revealed that our method produces more informative summaries compared to several baselines.,8 Conclusions,[0],[0]
"In the future, we plan to explore model performance in a wider range of movie genres as well as its applicability to other NLP tasks (e.g., book summarization or event extraction).",8 Conclusions,[0],[0]
We would also like to automatically determine the compression rate which should presumably vary according to the movie’s length and content.,8 Conclusions,[0],[0]
"Finally, our long-term goal is to be able to generate loglines as well as movie plot summaries.
",8 Conclusions,[0],[0]
"Acknowledgments We would like to thank Rik Sarkar, Jon Oberlander and Annie Louis for their valuable feedback.",8 Conclusions,[0],[0]
"Special thanks to Bharat Ambati, Lea Frermann, and Daniel Renshaw for their help with system evaluation.",8 Conclusions,[0],[0]
"In this paper we study the task of movie script summarization, which we argue could enhance script browsing, give readers a rough idea of the script’s plotline, and speed up reading time.",abstractText,[0],[0]
We formalize the process of generating a shorter version of a screenplay as the task of finding an optimal chain of scenes.,abstractText,[0],[0]
"We develop a graph-based model that selects a chain by jointly optimizing its logical progression, diversity, and importance.",abstractText,[0],[0]
Human evaluation based on a question-answering task shows that our model produces summaries which are more informative compared to competitive baselines.,abstractText,[0],[0]
Movie Script Summarization as Graph-based Scene Extraction,title,[0],[0]
Support vector machines (SVMs) and Boosting have been two mainstream learning approaches during the past decade.,1. Introduction,[0],[0]
"The former (Cortes & Vapnik, 1995) roots in the statistical learning theory (Vapnik, 1995) with the central idea of searching a large margin separator, i.e., maximizing the smallest distance from the instances to the classification boundary in a RKHS (reproducing kernel Hilbert space).",1. Introduction,[0],[0]
"It is noteworthy that there is also a long history of applying margin theory to explain the latter (Freund & Schapire, 1995; Schapire et al., 1998), due to its tending to be empirically resistant to over-fitting (Reyzin & Schapire, 2006; Wang et al., 2011; Zhou, 2012).
",1. Introduction,[0],[0]
"1National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China.",1. Introduction,[0],[0]
"Correspondence to: Zhi-Hua Zhou <zhouzh@lamda.nju.edu.cn>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Recently, the margin theory for Boosting has finally been defended (Gao & Zhou, 2013), and has disclosed that the margin distribution rather than a single margin is more crucial to the generalization performance.",1. Introduction,[0],[0]
It suggests that there may still exist large space to further enhance for SVMs.,1. Introduction,[0],[0]
"Inspired by this recognition, (Zhang & Zhou, 2014; 2016) proposed a binary classification method to optimize margin distribution by characterizing it through the firstand second-order statistics, which achieves quite satisfactory experimental results.",1. Introduction,[0],[0]
"Later, (Zhou & Zhou, 2016) extends the idea to an approach which is able to exploit unlabeled data and handle unequal misclassification cost.",1. Introduction,[0],[0]
"A brief summary of this line of early research can be found in (Zhou, 2014).
",1. Introduction,[0],[0]
"Although it has been shown that for binary classification, optimizing the margin distribution by maximizing the margin mean and minimizing the margin variance simultaneously can get superior performance, it still remains open for multi-class classification.",1. Introduction,[0],[0]
"Moreover, the margin for multiclass classification is much more complicated than that for binary class classification, which makes the resultant optimization be a difficult non-differentiable non-convex programming.",1. Introduction,[0],[0]
"In this paper, we propose mcODM (multi-class Optimal margin Distribution Machine) to solve this problem efficiently.",1. Introduction,[0],[0]
"For optimization, we relax mcODM into a series of convex quadratic programming (QP), and extend the Block Coordinate Descent (BCD) algorithm (Tseng, 2001) to solve the dual of each QP.",1. Introduction,[0],[0]
The sub-problem of each iteration of BCD is also a QP.,1. Introduction,[0],[0]
"By exploiting its special structure, we derive a sorting algorithm to solve it which is much faster than general QP solvers.",1. Introduction,[0],[0]
"We further provide a generalization error bound based on Rademacher complexity, and further present the analysis of the relationship between generalization error and margin distribution for multi-class classification.",1. Introduction,[0],[0]
"Extensive experiments on twenty two data sets show the superiority of our method to all four versions of multi-class SVMs.
",1. Introduction,[0],[0]
The rest of this paper is organized as follows.,1. Introduction,[0],[0]
Section 2 introduces some preliminaries.,1. Introduction,[0],[0]
Section 3 formulates the problem.,1. Introduction,[0],[0]
Section 4 presents the proposed algorithm.,1. Introduction,[0],[0]
Section 5 discusses some theoretical analyses.,1. Introduction,[0],[0]
Section 6 reports on our experimental studies and empirical observations.,1. Introduction,[0],[0]
Finally Section 7 concludes with future work.,1. Introduction,[0],[0]
We denote by X ∈ Rd the instance space and Y =,2. Preliminaries,[0],[0]
"[k] the label set, where [k] = {1, . . .",2. Preliminaries,[0],[0]
", k}.",2. Preliminaries,[0],[0]
Let D be an unknown (underlying) distribution over X × Y .,2. Preliminaries,[0],[0]
"A training set S = {(x1, y1), (x2, y2), . . .",2. Preliminaries,[0],[0]
", (xm, ym)} ∈",2. Preliminaries,[0],[0]
(X × Y)m is drawn identically and independently (i.i.d.),2. Preliminaries,[0],[0]
according to distribution D. Let ϕ,2. Preliminaries,[0],[0]
: X 7→ H be a feature mapping associated to some positive definite kernel κ.,2. Preliminaries,[0],[0]
"For multi-class classification setting, the hypothesis is defined based on k weight vectors w1, . . .",2. Preliminaries,[0],[0]
",wk ∈ H, where each weight vector wl, l ∈ Y defines a scoring function x 7→ w⊤l ϕ(x) and the label of instance x is the one resulting in the largest score, i.e., h(x) =",2. Preliminaries,[0],[0]
argmaxl∈Y w ⊤ l ϕ(x).,2. Preliminaries,[0],[0]
"This decision function naturally leads to the following definition of the margin for a labeled instance (x, y):
γh(x, y) = w ⊤ y ϕ(x)−max l ̸=y w⊤l ϕ(x).
",2. Preliminaries,[0],[0]
"Thus h misclassifies (x, y) if and only if it produces a negative margin for this instance.
",2. Preliminaries,[0],[0]
"Given a hypothesis set H of functions mapping X to Y and the labeled training set S, our goal is to learn a function h ∈ H such that the generalization error R(h) = E(x,y)∼D[1h(x)̸=y] is small.",2. Preliminaries,[0],[0]
"To design optimal margin distribution machine for multiclass classification, we need to understand how to optimize the margin distribution.",3. Formulation,[0],[0]
"(Gao & Zhou, 2013) proved that, to characterize the margin distribution, it is important to consider",3. Formulation,[0],[0]
not only the margin mean,3. Formulation,[0],[0]
but also the margin variance.,3. Formulation,[0],[0]
"Inspired by this idea, (Zhang & Zhou, 2014; 2016) proposed the optimal margin distribution machine for binary classification, which characterizes the margin distribution according to the first- and second-order statistics, that is, maximizing the margin mean and minimizing the margin variance simultaneously.",3. Formulation,[0],[0]
"Specifically, let γ̄ denote the margin mean, and the optimal margin distribution machine can be formulated as:
min w,γ̄,ξi,ϵi Ω(w)− ηγ̄",3. Formulation,[0],[0]
+,3. Formulation,[0],[0]
λ m m∑ i=1,3. Formulation,[0],[0]
(ξ2i + ϵ,3. Formulation,[0],[0]
2,3. Formulation,[0],[0]
"i )
s.t. γh(xi, yi) ≥ γ̄",3. Formulation,[0],[0]
"− ξi, γh(xi, yi) ≤ γ̄ + ϵi, ∀i,
where Ω(w) is the regularization term to penalize the model complexity, η and λ are trading-off parameters, ξi and ϵi are the deviation of the margin γh(xi, yi) to the margin mean.",3. Formulation,[0],[0]
It’s evident that ∑m i=1(ξ 2,3. Formulation,[0],[0]
i + ϵ 2,3. Formulation,[0],[0]
i )/m,3. Formulation,[0],[0]
"is exactly the margin variance.
",3. Formulation,[0],[0]
"By scaling w which doesn’t affect the final classification results, the margin mean can be fixed as 1, then the de-
viation of the margin of (xi, yi) to the margin mean is |γh(xi, yi)",3. Formulation,[0],[0]
"− 1|, and the optimal margin distribution machine can be reformulated as
min w,ξi,ϵi
Ω(w)",3. Formulation,[0],[0]
"+ λ
m m∑ i=1",3. Formulation,[0],[0]
"ξ2i + µϵ 2 i (1− θ)2
s.t. γh(xi, yi) ≥ 1− θ − ξi, γh(xi, yi) ≤ 1 + θ + ϵi, ∀i.
where µ ∈ (0, 1] is a parameter to trade off two different kinds of deviation (larger or less than margin mean).",3. Formulation,[0],[0]
θ ∈,3. Formulation,[0],[0]
"[0, 1) is a parameter of the zero loss band, which can control the number of support vectors, i.e., the sparsity of the solution, and (1− θ)2 in the denominator is to scale the second term to be a surrogate loss for 0-1 loss.
",3. Formulation,[0],[0]
"For multi-class classification, let the regularization term Ω(w)",3. Formulation,[0],[0]
= ∑k l=1 ∥wl∥2H/2,3. Formulation,[0],[0]
"and combine with the definition of margin, and we arrive at the formulation of mcODM,
min wl,ξi,ϵi
1
2 k∑ l=1",3. Formulation,[0],[0]
∥wl∥2H +,3. Formulation,[0],[0]
λ m m∑ i=1,3. Formulation,[0],[0]
"ξ2i + µϵ 2 i (1− θ)2 (1)
s.t. w⊤yiϕ(xi)−maxl ̸=yi w⊤l ϕ(xi) ≥ 1− θ − ξi,
w⊤yiϕ(xi)−maxl ̸=yi w⊤l ϕ(xi) ≤ 1 + θ + ϵi, ∀i.
where λ, µ and θ are the parameters for trading-off described previously.",3. Formulation,[0],[0]
"Due to the max operator in the second constraint, mcODM is a non-differentiable non-convex programming, which is quite difficult to solve directly.
",4. Optimization,[0],[0]
"In this section, we first relax mcODM into a series of convex quadratic programming (QP), which can be much easier to handle.",4. Optimization,[0],[0]
"Specifically, at each iteration, we recast the first constraint as k − 1 linear inequality constraints:
w⊤yiϕ(xi)−w ⊤ l ϕ(xi) ≥ 1− θ − ξi, l ̸= yi,
and replace the second constraint with
w⊤yiϕ(xi)−Mi ≤ 1 + θ + ϵi,
where Mi = maxl ̸=yi w̄ ⊤ l ϕ(xi) and w̄l is the solution to the previous iteration.",4. Optimization,[0],[0]
"Then we can repeatedly solve the following convex QP problem until convergence:
min wl,ξi,ϵi
1
2 k∑ l=1",4. Optimization,[0],[0]
∥wl∥2H +,4. Optimization,[0],[0]
λ m m∑ i=1,4. Optimization,[0],[0]
"ξ2i + µϵ 2 i (1− θ)2 (2)
s.t. w⊤yiϕ(xi)−w ⊤ l ϕ(xi) ≥ 1− θ − ξi, ∀l ̸= yi,
w⊤yiϕ(xi)−Mi ≤ 1 + θ + ϵi, ∀i.
",4. Optimization,[0],[0]
"Introduce the lagrange multipliers ζli ≥ 0, l ̸= yi for the first k − 1 constraints and βi ≥ 0 for the last constraint respectively, the Lagrangian function of Eq. 2 leads to
L(wl, ξi, ϵi, ζ",4. Optimization,[0],[0]
"l i , βi)
= 1
2 k∑ l=1",4. Optimization,[0],[0]
∥wl∥2H +,4. Optimization,[0],[0]
λ m m∑ i=1,4. Optimization,[0],[0]
"ξ2i + µϵ 2 i (1− θ)2
− m∑ i=1",4. Optimization,[0],[0]
∑,4. Optimization,[0],[0]
"l ̸=yi ζli(w ⊤ yiϕ(xi)−w ⊤ l ϕ(xi)− 1 + θ + ξi)
+",4. Optimization,[0],[0]
m∑ i=1 βi(w,4. Optimization,[0],[0]
⊤ yiϕ(xi)−Mi,4. Optimization,[0],[0]
"− 1− θ − ϵi),
By setting the partial derivations of variables {wl, ξi, ϵi} to zero, we have
wl = m∑ i=1",4. Optimization,[0],[0]
"δyi,l ∑ s̸=yi ζsi",4. Optimization,[0],[0]
"− (1− δyi,l)ζli − δyi,lβi ϕ(xi), ξi = m(1− θ)2
2λ
∑ l ̸=yi ζli , ϵi = m(1− θ)2 2λµ βi.",4. Optimization,[0],[0]
"(3)
where δyi,l equals 1 when yi = l and 0 otherwise.",4. Optimization,[0],[0]
"We further simplify the expression of wl as
wl = m∑ i=1",4. Optimization,[0],[0]
"(αli − δyi,lβi)ϕ(xi), (4)
by defining αli ≡ −ζli for ∀l ̸= yi and α yi",4. Optimization,[0],[0]
i ≡,4. Optimization,[0],[0]
"∑ s̸=yi
ζsi and substituting Eq.",4. Optimization,[0],[0]
"4 and Eq. 3 into the Lagrangian function, then we have the following dual problem
min αli,α yi",4. Optimization,[0],[0]
"i ,βi
1
2 k∑ l=1",4. Optimization,[0],[0]
∥wl∥2H + m(1− θ)2 4λ,4. Optimization,[0],[0]
m∑ i=1,4. Optimization,[0],[0]
"(αyii ) 2
+ m(1− θ)2
4λµ
m∑ i=1 β2i",4. Optimization,[0],[0]
+ (1− θ) m∑ i=1,4. Optimization,[0],[0]
∑,4. Optimization,[0],[0]
"l ̸=yi αli
+ (Mi + 1 + θ) m∑ i=1",4. Optimization,[0],[0]
"βi (5)
s.t. k∑
l=1
αli = 0, ∀i,
αli ≤ 0, ∀i,∀l ̸= yi, βi ≥ 0, ∀i.
",4. Optimization,[0],[0]
"The objective function in Eq. 5 involves m(k + 1) variables in total, so it is not easy to optimize with respect to all the variables simultaneously.",4. Optimization,[0],[0]
"Note that all the constraints can be partitioned into m disjoint sets, and the i-th set only involves α1i , . . .",4. Optimization,[0],[0]
", α k i , βi, so the variables can be divided into m decoupled groups and an efficient block coordinate descent algorithm (Tseng, 2001) can be applied.
",4. Optimization,[0],[0]
"Specifically, we sequentially select a group of k + 1 variables α1i , . . .",4. Optimization,[0],[0]
", α k i , βi associated with instance xi to minimize, while keeping other variables as constants, and repeat this procedure until convergence.
",4. Optimization,[0],[0]
"Algorithm 1 below details the kenrel mcODM.
",4. Optimization,[0],[0]
Algorithm 1 Kenrel mcODM 1: Input: Data set S. 2: Initialize α⊤ =,4. Optimization,[0],[0]
"[α11, . . .",4. Optimization,[0],[0]
", α k 1 , . . .",4. Optimization,[0],[0]
", α 1 m, . . .",4. Optimization,[0],[0]
", α k m] and
β⊤ =",4. Optimization,[0],[0]
"[β1, . . .",4. Optimization,[0],[0]
", βm] as zero vector. 3: while α and β not converge do 4: for i = 1, . . .",4. Optimization,[0],[0]
",m do 5: Mi ← maxl ̸=yi ∑m j=1(α",4. Optimization,[0],[0]
"l j − δyj ,lβj)κ(xj ,xi).",4. Optimization,[0],[0]
6: end for 7: Solve Eq. 5 by block coordinate descent method.,4. Optimization,[0],[0]
"8: end while 9: Output: α, β.",4. Optimization,[0],[0]
"The sub-problem in step 7 of Algorithm 1 is also a convex QP with k + 1 variables, which can be accomplished by some standard QP solvers.",4.1. Solving the sub-problem,[0],[0]
"However, by exploiting its special structure, i.e., only a small quantity of cross terms are involved, we can derive an algorithm to solve this subproblem just by sorting, which can be much faster than general QP solvers.
",4.1. Solving the sub-problem,[0],[0]
"Note that all variables except α1i , . . .",4.1. Solving the sub-problem,[0],[0]
", α k",4.1. Solving the sub-problem,[0],[0]
"i , βi are fixed, so we have the following sub-problem:
min αli,α yi",4.1. Solving the sub-problem,[0],[0]
"i ,βi ∑ l ̸=yi A 2 (αli) 2 + ∑ l ̸=yi",4.1. Solving the sub-problem,[0],[0]
"Blα l i + D 2 (αyii ) 2 −Aαyii βi
+Byiα yi i +
E 2 β2i + Fβi
s.t. k∑
l=1
αli = 0, (6)
αli ≤ 0, ∀l ̸= yi, βi ≥ 0.
where A = κ(xi,xi), Bl = ∑ j ̸=i κ(xi,xj)(α",4.1. Solving the sub-problem,[0],[0]
l j,4.1. Solving the sub-problem,[0],[0]
"−
δyj ,lβj)+1− θ for ∀l ̸= yi, Byi = ∑ j ̸=i κ(xi,xj)(α yi",4.1. Solving the sub-problem,[0],[0]
"j − δyj ,yiβj), D = A + m(1−θ)2 2λ , E = A + m(1−θ)2
2λµ and F ≡Mi + 1 + θ −Byi .
",4.1. Solving the sub-problem,[0],[0]
"The KKT conditions of Eq. 6 indicate that there are scalars ν, ρl and η such that
k∑ l=1 αli = 0, (7) αli ≤ 0, ∀l ̸= yi, (8)
βi ≥ 0, (9) ρlα l i = 0, ρl ≥ 0, ∀l ̸= yi, (10)
",4.1. Solving the sub-problem,[0],[0]
Aαli +,4.1. Solving the sub-problem,[0],[0]
"Bl − ν + ρl = 0, ∀l ̸= yi, (11) ηβi = 0, η ≥ 0, (12) −Aαyii +",4.1. Solving the sub-problem,[0],[0]
Eβi + F,4.1. Solving the sub-problem,[0],[0]
"− η = 0, (13) Dαyii −Aβi +Byi − ν = 0.",4.1. Solving the sub-problem,[0],[0]
"(14)
",4.1. Solving the sub-problem,[0],[0]
"According to Eq. 8, Eq. 10 and Eq. 11 are equivalent to
Aαli",4.1. Solving the sub-problem,[0],[0]
"+Bl − ν = 0, if αli < 0, ∀l ̸= yi, (15)",4.1. Solving the sub-problem,[0],[0]
Bl,4.1. Solving the sub-problem,[0],[0]
"− ν ≤ 0, if αli = 0, ∀l ̸= yi.",4.1. Solving the sub-problem,[0],[0]
"(16)
In the same way, Eq. 12 and Eq. 13 are equivalent to
−Aαyii",4.1. Solving the sub-problem,[0],[0]
+,4.1. Solving the sub-problem,[0],[0]
"Eβi + F = 0, if βi > 0, (17) −Aαyii + F ≥ 0, if βi = 0.",4.1. Solving the sub-problem,[0],[0]
"(18)
Thus KKT conditions turn to Eq. 7 - Eq. 9 and Eq. 14 - Eq. 18.",4.1. Solving the sub-problem,[0],[0]
"Note that
αli ≡ min ( 0,
ν",4.1. Solving the sub-problem,[0],[0]
"−Bl A
) , ∀l ̸= yi, (19)
satisfies KKT conditions Eq. 8 and Eq. 15 - Eq. 16",4.1. Solving the sub-problem,[0],[0]
"and βi ≡ max ( 0,
Aαyii − F E
) , (20)
satisfies KKT conditions Eq. 9 and Eq. 17 - Eq. 18.",4.1. Solving the sub-problem,[0],[0]
"By substituting Eq. 20 into Eq. 14, we obtain
Dαyii +Byi − ν = max ( 0, A
E (Aαyii − F )
) .",4.1. Solving the sub-problem,[0],[0]
"(21)
Let’s consider the following two cases in turn.
",4.1. Solving the sub-problem,[0],[0]
"Case 1: Aαyii ≤ F , according to Eq. 20 and Eq. 21, we have βi = 0 and α yi i = ν−Byi D .",4.1. Solving the sub-problem,[0],[0]
"Thus, A ν−Byi D ≤ F , which implies that ν ≤",4.1. Solving the sub-problem,[0],[0]
Byi + DFA .,4.1. Solving the sub-problem,[0],[0]
"Case 2: Aαyii > F , according to Eq. 20 and Eq. 21, we have βi = Aα yi",4.1. Solving the sub-problem,[0],[0]
i −F E > 0 and α yi i = Eν−AF−EByi DE−A2 .,4.1. Solving the sub-problem,[0],[0]
"Thus, A Eν−AF−EByi
DE−A2 > F , which implies that ν",4.1. Solving the sub-problem,[0],[0]
>,4.1. Solving the sub-problem,[0],[0]
"Byi + DF A .
",4.1. Solving the sub-problem,[0],[0]
The remaining task is to find ν such that Eq. 7 holds.,4.1. Solving the sub-problem,[0],[0]
"With Eq. 7 and Eq. 19, it can be shown that
ν =
AByi D + ∑ l:αli<0
Bl A D + |{l|α l i < 0}| , Case 1, (22)
ν",4.1. Solving the sub-problem,[0],[0]
"=
AEByi+A 2F DE−A2 + ∑",4.1. Solving the sub-problem,[0],[0]
"l:αli<0 Bl
AE DE−A2 + |{l|α l i < 0}|
, Case 2. (23)
",4.1. Solving the sub-problem,[0],[0]
"In both cases, the optimal ν takes the form of (P +∑ l:αli<0 Bl)/(Q+ |{l|αli < 0}|), where P and Q are some
constants.",4.1. Solving the sub-problem,[0],[0]
"(Fan et al., 2008) showed that it can be found by sorting {Bl} for ∀l ̸= yi in decreasing order and then sequentially adding them into an empty set Φ, until
ν∗ = P +
∑",4.1. Solving the sub-problem,[0],[0]
"l∈Φ Bl
Q+ |Φ| ≥",4.1. Solving the sub-problem,[0],[0]
"max l ̸∈Φ Bl. (24)
Note that the Hessian matrix of the objective function of Eq. 6 is positive definite, which guarantees the existence and uniqueness of the optimal solution, so only one of Eq. 22 and Eq. 23 can hold.",4.1. Solving the sub-problem,[0],[0]
"We can first compute ν∗ according to Eq. 24 for Case 1, and then check whether the constraint of ν is satisfied.",4.1. Solving the sub-problem,[0],[0]
"If not, we further compute ν∗ for Case 2.",4.1. Solving the sub-problem,[0],[0]
"Algorithm 2 summarizes the pseudo-code for solving the sub-problem.
",4.1. Solving the sub-problem,[0],[0]
"Algorithm 2 Solving the sub-problem 1: Input: Parameters A, B = {B1, . . .",4.1. Solving the sub-problem,[0],[0]
", Bk}, D,E, F .",4.1. Solving the sub-problem,[0],[0]
"2: Initialize B̂ ← B, then swap B̂1 and B̂yi , and sort
B̂\{B̂1} in decreasing order.",4.1. Solving the sub-problem,[0],[0]
"3: i← 2, ν ← AByi/D. 4: while i ≤ k and ν/(i− 2 +A/D) < B̂i do 5: ν ← ν + B̂i.",4.1. Solving the sub-problem,[0],[0]
6: i← i+ 1. 7: end while 8: if ν ≤,4.1. Solving the sub-problem,[0],[0]
"Byi +DF/A then 9: αli ← min(0, (ν −Bl)/A), l ̸= yi.
10: αyii ← (ν −Byi)/D. 11: βi ← 0. 12: else 13: i← 2, ν ← (AEB̂1 +A2F )/(DE",4.1. Solving the sub-problem,[0],[0]
−A2).,4.1. Solving the sub-problem,[0],[0]
14: while i ≤ k and ν/(i− 2+AE/(DE−A2)),4.1. Solving the sub-problem,[0],[0]
< B̂i do 15: ν ← ν + B̂i.,4.1. Solving the sub-problem,[0],[0]
"16: i← i+ 1. 17: end while 18: αli ← min(0, (ν −Bl)/A), l ̸= yi. 19: αyii ← (Eν −AF − EByi)/(DE −A2).",4.1. Solving the sub-problem,[0],[0]
20: βi ← (Aαyii − F ),4.1. Solving the sub-problem,[0],[0]
/E. 21: end if 22:,4.1. Solving the sub-problem,[0],[0]
"Output: α1i , . . .",4.1. Solving the sub-problem,[0],[0]
", αki , βi.",4.1. Solving the sub-problem,[0],[0]
"In section 4.1, the proposed method can efficiently deal with kernel mcODM.",4.2. Speedup for linear kernel,[0],[0]
"However, the computation of Mi in step 5 of Algorithm 1 and the computation of parameters B̄l in Algorithm 2 both involve the kernel matrix, whose inherent computational cost takes O(m2) time, so it might be computational prohibitive for large scale problems.
",4.2. Speedup for linear kernel,[0],[0]
"When linear kernel is used, these problems can be alleviated.",4.2. Speedup for linear kernel,[0],[0]
"According to Eq. 4, w is spanned by the training instance so it lies in a finite dimensional space under this
circumstance.",4.2. Speedup for linear kernel,[0],[0]
"By storing w1, . . .",4.2. Speedup for linear kernel,[0],[0]
",wk explicitly, the computational cost of Mi = maxl ̸=yi w ⊤",4.2. Speedup for linear kernel,[0],[0]
l xi can be much less.,4.2. Speedup for linear kernel,[0],[0]
"Moreover, note that B̄l = ∑ j ̸=i x ⊤",4.2. Speedup for linear kernel,[0],[0]
"i xj(α
",4.2. Speedup for linear kernel,[0],[0]
l j,4.2. Speedup for linear kernel,[0],[0]
"− δyj ,lβj)",4.2. Speedup for linear kernel,[0],[0]
"=∑m
j=1 x ⊤",4.2. Speedup for linear kernel,[0],[0]
"i xj(ᾱ l j−δyj ,lβ̄j)−x⊤i xi(ᾱli−δyi,lβ̄i) =",4.2. Speedup for linear kernel,[0],[0]
"w⊤l xi−
A(αli − δyi,lβi), so B̄l can also be computed efficiently.",4.2. Speedup for linear kernel,[0],[0]
"In this section, we study the statistical property of mcODM.",5. Analysis,[0],[0]
"To present the generalization bound of mcODM, we need to introduce the following loss function Φ,
Φ(z) = 1z≤0 + (z − 1 + θ)2
(1− θ)2 10<z≤1−θ,
γh,θ(x, y) = w ⊤ y ϕ(x)−max l∈Y {w⊤l ϕ(x)− (1− θ)1l=y},
where 1(·) is the indicator function that returns 1 when the argument holds, and 0 otherwise.",5. Analysis,[0],[0]
"As can be seen, γh,θ(x, y) is a lower bound of γh(x, y) and Φ(γh,θ(x, y))",5. Analysis,[0],[0]
"= Φ(γh(x, y)).
",5. Analysis,[0],[0]
Theorem 1.,5. Analysis,[0],[0]
"Let H = {(x, y) ∈ X",5. Analysis,[0],[0]
×,5. Analysis,[0],[0]
[k] 7→,5. Analysis,[0],[0]
w⊤y ϕ(x)| ∑k l=1,5. Analysis,[0],[0]
"∥wl∥2H ≤ Λ2} be the hypothesis space of mcODM, where ϕ :",5. Analysis,[0],[0]
X 7→ H is a feature mapping induced by some positive definite kernel κ.,5. Analysis,[0],[0]
"Assume that S ⊆ {x : κ(x,x) ≤ r2}, then for any δ > 0, with probability at least 1 − δ, the following generalization bound holds for any h ∈ H ,
R(h) ≤ 1 m m∑ i=1",5. Analysis,[0],[0]
"Φ(γh(xi, yi))",5. Analysis,[0],[0]
"+ 16rΛ 1− θ
√ 2πk
m + 3 √ ln 2δ 2m .
",5. Analysis,[0],[0]
Proof.,5. Analysis,[0],[0]
"Let H̃θ be the family of hypotheses mapping X × Y 7→ R defined by H̃θ = {(x, y) 7→ γh,θ(x, y) :",5. Analysis,[0],[0]
"h ∈ H}, with McDiarmid inequality (McDiarmid, 1989), yields the following inequality with probability at least 1− δ,
E[Φ(γh,θ(x, y))]",5. Analysis,[0],[0]
"≤ 1
m m∑ i=1 Φ(γh,θ(xi, yi))
",5. Analysis,[0],[0]
"+ 2RS(Φ ◦ H̃θ) + 3 √ ln 2δ 2m ,∀h ∈ H̃θ.
",5. Analysis,[0],[0]
"Note that Φ(γh,θ) = Φ(γh), R(h) = E[1γh(x,y)≤0] ≤",5. Analysis,[0],[0]
"E[1γh,θ(x,y)≤0] ≤ E[Φ(γh,θ(x, y))]",5. Analysis,[0],[0]
"and Φ(z) is 21−θ - Lipschitz function, by using Talagrand’s lemma (Mohri et al., 2012), we have
R(h) ≤ 1 m m∑ i=1",5. Analysis,[0],[0]
"Φ(γh(xi, yi))",5. Analysis,[0],[0]
"+ 4RS(H̃θ) 1− θ + 3 √ ln 2δ 2m .
",5. Analysis,[0],[0]
"According to Theorem 7 of (Lei et al., 2015), we have RS(H̃θ) ≤ 4rΛ",5. Analysis,[0],[0]
"√ 2πk/m and proves the stated result.
",5. Analysis,[0],[0]
Theorem 1 shows that we can get a tighter generalization bound for smaller rΛ and smaller θ.,5. Analysis,[0],[0]
"Since γ ≤ 2rΛ, so the former can be viewed as an upper bound of the margin.",5. Analysis,[0],[0]
"Besides, 1 − θ is the lower bound of the zero loss band of mcODM.",5. Analysis,[0],[0]
"This verifies that better margin distribution (i.e., larger margin mean and smaller margin variance) can yield better generalization performance, which is also consistent with the work of (Gao & Zhou, 2013).",5. Analysis,[0],[0]
"In this section, we empirically evaluate the effectiveness of our method on a broad range of data sets.",6. Empirical Study,[0],[0]
"We first introduce the experimental settings and compared methods in Section 6.1, and then in Section 6.2, we compare our method with four versions of multi-class SVMs, i.e., mcSVM (Weston & Watkins, 1999; Crammer & Singer, 2001; 2002), one-versus-all SVM (ovaSVM), one-versusone SVM (ovoSVM) (Ulrich, 1998) and error-correcting output code SVM (ecocSVM) (Dietterich & Bakiri, 1995).",6. Empirical Study,[0],[0]
"In addition, we also study the influence of the number of classes on generalization performance and margin distribution in Section 6.3.",6. Empirical Study,[0],[0]
"Finally, the computational cost is presented in Section 6.4.",6. Empirical Study,[0],[0]
We evaluate the effectiveness of our proposed methods on twenty two data sets.,6.1. Experimental Setup,[0],[0]
Table 1 summarizes the statistics of these data sets.,6.1. Experimental Setup,[0],[0]
"The data set size ranges from 150 to more than 581,012, and the dimensionality ranges from 4 to more than 62,061.",6.1. Experimental Setup,[0],[0]
"Moreover, the number of class ranges from 3 to 1,000, so these data sets cover a broad range of properties.",6.1. Experimental Setup,[0],[0]
All features are normalized into the interval,6.1. Experimental Setup,[0],[0]
"[0, 1].",6.1. Experimental Setup,[0],[0]
"For each data set, eighty percent of the instances are randomly selected as training data, and the rest are used as testing data.",6.1. Experimental Setup,[0],[0]
"For each data set, experiments are repeated for 10 times with random data partitions, and the average accuracies as well as the standard deviations are recorded.
mcODM is compared with four versions of multi-class SVMs, i.e., ovaSVM, ovoSVM, ecocSVM and mcSVM.",6.1. Experimental Setup,[0],[0]
These four methods can be roughly classified into two groups.,6.1. Experimental Setup,[0],[0]
The first group includes the first three methods by converting the multi-class classification problem into a set of binary classification problems.,6.1. Experimental Setup,[0],[0]
"Specially, ovaSVM consists of learning k scoring functions hl : X 7→ {−1,+1}, l ∈ Y , each seeking to discriminate one class l ∈ Y from all the others, as can be seen it need train k SVM models.",6.1. Experimental Setup,[0],[0]
"Alternatively, ovoSVM determines the scoring functions for all the combinations of class pairs, so it need train k(k − 1)/2 SVM models.",6.1. Experimental Setup,[0],[0]
"Finally, ecocSVM is a generalization of the former two methods.",6.1. Experimental Setup,[0],[0]
"This technique assigns to each class l ∈ Y a code word with length c, which serves as a signature for this class.",6.1. Experimental Setup,[0],[0]
"After training
c binary SVM models h1(·), . . .",6.1. Experimental Setup,[0],[0]
", hc(·), the class predicted for each testing instance is the one whose signatures is the closest to [h1(x), . . .",6.1. Experimental Setup,[0],[0]
", hc(x)] in Hamming distance.",6.1. Experimental Setup,[0],[0]
"The weakness of these methods is that they may produce unclassifiable regions and their computational costs are usually quite large in practice, which can be observed in the following experiments.",6.1. Experimental Setup,[0],[0]
"On the other hand, mcSVM belongs to the second group.",6.1. Experimental Setup,[0],[0]
"It directly determines all the scroing functions at once, so the time cost is usually less than the former methods.",6.1. Experimental Setup,[0],[0]
"In addition, the unclassifiable regions are also resolved.
",6.1. Experimental Setup,[0],[0]
"For all the methods, the regularization parameter λ for mcODM or C for binary SVM and mcSVM is selected by 5-fold cross validation from [20, 22, . . .",6.1. Experimental Setup,[0],[0]
", 220].",6.1. Experimental Setup,[0],[0]
"For mcODM, the regularization parameters µ and θ are both selected from [0.2, 0.4, 0.6, 0.8].",6.1. Experimental Setup,[0],[0]
"For ecocSVM, the exhaustive codes strategy is employed, i.e., for each class, we construct a code of length 2k−1 − 1 as the signature.",6.1. Experimental Setup,[0],[0]
All the selections for parameters are performed on training sets.,6.1. Experimental Setup,[0],[0]
Table 2 summarizes the detailed results on twenty two data sets.,6.2. Results,[0],[0]
"As can be seen, the overall performance of our method is superior or highly competitive to the other compared methods.",6.2. Results,[0],[0]
"Specifically, mcODM performs significantly better than mcSVM/ovaSVM/ovoSVM/ecocSVM on 17/19/18/17 over 22 data sets respectively, and achieves the best accuracy on 20 data sets.",6.2. Results,[0],[0]
"In addition, as can be seen, in comparing with other four methods which don’t consider margin distribution, the win/tie/loss counts show that mcODM is always better or comparable, almost never worse than it.",6.2. Results,[0],[0]
"In this section we study the influence of the number of classes on generalization performance and margin distribution, respectively.",6.3. Influence of the Number of Classes,[0],[0]
"Figure 1 plots the generalization performance of all the five methods on data set segment, and similar observation can be found for other data sets.",6.3.1. GENERALIZATION PERFORMANCE,[0],[0]
"As can be seen, when the number of classes is less than four, all methods perform quite well.",6.3.1. GENERALIZATION PERFORMANCE,[0],[0]
"However, as the fifth class is added, the generalization performance of other four methods decreases drastically.",6.3.1. GENERALIZATION PERFORMANCE,[0],[0]
"This might be attributable to the introduction of some noisy data, which SVM-style algorithms are very sensitive to since they optimize the minimum margin.",6.3.1. GENERALIZATION PERFORMANCE,[0],[0]
"On the other hand, our method considers the whole margin distribution, so it can be robust to noise and relatively more stable.",6.3.1. GENERALIZATION PERFORMANCE,[0],[0]
"Figure 2 plots the frequency histogram of margin distribution produced by mcSVM, ovaSVM and mcODM on data set segment as the number of classes increases from two to seven.",6.3.2. MARGIN DISTRIBUTION,[0],[0]
"As can be seen, when the number of classes is less than four, all methods can achieve good margin distribution, whereas with the increase of the number of classes, the other two methods begin to produce negative margins.",6.3.2. MARGIN DISTRIBUTION,[0],[0]
"At the same time, the distribution of our method becomes
“sharper”, which prevents the instance with small margin, so our method can still perform relatively well as the number of classes increases, which is also consistent with the observation from Figure 1.",6.3.2. MARGIN DISTRIBUTION,[0],[0]
"We compare the single iteration time cost of our method with mcSVM, ovaSVM, ovoSVM on all the data sets except aloi, on which ovoSVM could not return results in 48 hours.",6.4. Time Cost,[0],[0]
All the experiments are performed with MATLAB 2012b on a machine with 8×2.60 GHz CPUs and 32GB main memory.,6.4. Time Cost,[0],[0]
The average CPU time (in seconds) on each data set is shown in Figure 3.,6.4. Time Cost,[0],[0]
"The binary SVM used in ovaSVM, ovoSVM and mcSVM are both implemented by the LIBLINEAR (Fan et al., 2008) package.",6.4. Time Cost,[0],[0]
"It can be seen that for small data sets, the efficiency of all the methods are similar, however, for data sets with more than ten classes, e.g., sector and rcv1, mcSVM and mcODM, which learn all the scroing functions at once, are much faster than ovaSVM and ovoSVM, owing to the inefficiency of binarydecomposition as discussed in Section 6.1.",6.4. Time Cost,[0],[0]
"Note that LIBLINEAR are very fast implementations of binary SVM and mcSVM, and this shows that our method is also computationally efficient.",6.4. Time Cost,[0],[0]
"Recent studies disclose that for binary class classification, maximizing the minimum margin does not necessarily lead to better generalization performances, and instead, it is crucial to optimize the margin distribution.",7. Conclusions,[0],[0]
"However, it remains open to the influence of margin distribution for multi-class classification.",7. Conclusions,[0],[0]
We try to answer this question in this paper.,7. Conclusions,[0],[0]
"After maximizing the margin mean and minimizing the margin variance simultaneously, the resultant optimization is a difficult non-differentiable non-convex programming.",7. Conclusions,[0],[0]
We propose mcODM to solve this problem efficiently.,7. Conclusions,[0],[0]
Extensive experiments on twenty two data sets validate the superiority of our method to four versions of multi-class SVMs.,7. Conclusions,[0],[0]
"In the future it will be interesting to extend mcODM to more general learning settings, i.e., multilabel learning and structured learning.",7. Conclusions,[0],[0]
This research was supported by the NSFC (61333014) and the Collaborative Innovation Center of Novel Software Technology and Industrialization.,Acknowledgements,[0],[0]
"Authors want to thank reviewers for helpful comments, and thank Dr. Wei Gao for reading a draft.",Acknowledgements,[0],[0]
"Recent studies disclose that maximizing the minimum margin like support vector machines does not necessarily lead to better generalization performances, and instead, it is crucial to optimize the margin distribution.",abstractText,[0],[0]
"Although it has been shown that for binary classification, characterizing the margin distribution by the firstand second-order statistics can achieve superior performance.",abstractText,[0],[0]
"It still remains open for multiclass classification, and due to the complexity of margin for multi-class classification, optimizing its distribution by mean and variance can also be difficult.",abstractText,[0],[0]
"In this paper, we propose mcODM (multi-class Optimal margin Distribution Machine), which can solve this problem efficiently.",abstractText,[0],[0]
"We also give a theoretical analysis for our method, which verifies the significance of margin distribution for multi-class classification.",abstractText,[0],[0]
Empirical study further shows that mcODM always outperforms all four versions of multi-class SVMs on all experimental data sets.,abstractText,[0],[0]
Multi-Class Optimal Margin Distribution Machine,title,[0],[0]
"Many tasks in scientific and engineering applications can be framed as bandit optimisation problems, where we need to sequentially evaluate a noisy black-box function f : X → R with the goal of finding its optimum.",1. Introduction,[0],[0]
"Some applications include hyper-parameter tuning in machine learning (Hutter et al., 2011; Snoek et al., 2012), optimal policy search (Lizotte et al., 2007; Martinez-Cantin et al., 2007) and scientific experiments (Gonzalez et al., 2014; Parkinson et al., 2006).
",1. Introduction,[0],[0]
"*Equal contribution 1Carnegie Mellon University, Pittsburgh PA, USA 2Rice University, Houston TX, USA.",1. Introduction,[0],[0]
"Correspondence to: Kirthevasan Kandasamy <kandasamy@cmu.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Typically, in such applications, each function evaluation is expensive, and conventionally, the bandit literature has focused on developing methods for finding the optimum while keeping the number of evaluations to f at a minimum.
",1. Introduction,[0],[0]
"However, with increasingly expensive function evaluations, conventional methods have become infeasible as a significant cost needs to be expended before we can learn anything about f .",1. Introduction,[0],[0]
"As a result, multi-fidelity optimisation methods have recently gained attention (Cutler et al., 2014; Kandasamy et al., 2016a; Li et al., 2016).",1. Introduction,[0],[0]
"As the name suggests, these methods assume that we have access to lower fidelity approximations to f which can be evaluated instead of f .",1. Introduction,[0],[0]
"The lower the fidelity, the cheaper the evaluation, but it provides less accurate information about f .",1. Introduction,[0],[0]
"For example, when optimising the configuration of an expensive real world robot, its performance can be approximated using cheaper computer simulations.",1. Introduction,[0],[0]
"The goal is to use the cheap approximations to guide search for the optimum of f , and reduce the overall cost of optimisation.",1. Introduction,[0],[0]
"However, most multi-fidelity work assume only a finite number of approximations.",1. Introduction,[0],[0]
"In this paper, we study multi-fidelity optimisation when there is access to a continuous spectrum of approximations.
",1. Introduction,[0],[0]
"To motivate this set up, consider tuning a classification algorithm over a space of hyper-parameters X by maximising a validation set accuracy.",1. Introduction,[0],[0]
The algorithm is to be trained using N• data points via an iterative algorithm for T• iterations.,1. Introduction,[0],[0]
"However, we wish to use fewer training points N <",1. Introduction,[0],[0]
N• and/or fewer iterations T < T• to approximate the validation accuracy.,1. Introduction,[0],[0]
We can view validation accuracy as a function g :,1. Introduction,[0],[0]
"[1, N•]",1. Introduction,[0],[0]
"× [1, T•]",1. Introduction,[0],[0]
"× X → R where evaluating g(N,T, x) requires training the algorithm with N points for T iterations with the hyper-parameters x.",1. Introduction,[0],[0]
"If the training complexity of the algorithm is quadratic in data size and linear in the number of iterations, then the cost of this evaluation is λ(N,T ) = O(N2T ).",1. Introduction,[0],[0]
"Our goal is to find the optimum when N = N•, and T = T•, i.e. we wish to maximise f(x) = g(N•, T•, x).
",1. Introduction,[0],[0]
"In this setting, while N,T are technically discrete choices, they are more naturally viewed as coming from a continuous 2 dimensional fidelity space, [1, N•]",1. Introduction,[0],[0]
×,1. Introduction,[0],[0]
"[1, T•].",1. Introduction,[0],[0]
"One might hope that cheaper queries to g(N,T, ·) with N,T less than N•, T• can be used to learn about g(N•, T•, ·) and consequently optimise it using less overall cost.",1. Introduction,[0],[0]
"Indeed, this
is the case with many machine learning algorithms where cross validation performance tends to vary smoothly with data set size and number of iterations.",1. Introduction,[0],[0]
"Therefore, one may use cheap low fidelity experiments with small (N,T ) to discard bad hyper-parameters and deploy expensive high fidelity experiments with large (N,T ) only in a small but promising region.",1. Introduction,[0],[0]
"The main theoretical result of this paper (Theorem 1) shows that our proposed algorithm, BOCA, exhibits precisely this behaviour.
",1. Introduction,[0],[0]
"Continuous approximations also arise in simulation studies: where simulations can be carried out at varying levels of granularity, on-line advertising: where an ad can be controlled by continuous parameters such as display time or target audience, and several other experiment design tasks.",1. Introduction,[0],[0]
"In fact, in many multi-fidelity papers, the finite approximations were obtained by discretising a continuous space (Huang et al., 2006; Kandasamy et al., 2016a).",1. Introduction,[0],[0]
"Here, we study a Bayesian optimisation technique that is directly designed for continuous fidelity spaces and is potentially applicable to more general spaces.",1. Introduction,[0],[0]
"Our main contributions are,
1.",1. Introduction,[0],[0]
A novel setting and model for multi-fidelity optimisation with continuous approximations using Gaussian process (GP) assumptions.,1. Introduction,[0],[0]
"We develop a novel algorithm, BOCA, for this setting.
2.",1. Introduction,[0],[0]
A theoretical analysis characterising the behaviour and regret bound for BOCA. 3.,1. Introduction,[0],[0]
"An empirical study which demonstrates that BOCA outperforms alternatives, both multi-fidelity and otherwise, on a series of synthetic problems and real examples in hyper-parameter tuning and astrophysics.
",1. Introduction,[0],[0]
"Related Work Bayesian optimisation (BO), refers to a suite of techniques for bandit optimisation which use a prior belief distribution for f .",1. Introduction,[0],[0]
"While there are several techniques for BO (de Freitas et al., 2012; Hernández-Lobato et al., 2014; Jones et al., 1998; Mockus, 1994; Thompson, 1933), our work will build on the Gaussian process upper confidence bound (GP-UCB) algorithm of Srinivas et al. (2010).",1. Introduction,[0],[0]
"GP-UCB models f as a GP and uses upper confidence bound (UCB) (Auer, 2003) techniques to determine the next point for evaluation.
",1. Introduction,[0],[0]
"BO techniques have been used in developing multi-fidelity optimisation methods in various applications such as hyperparameter tuning and industrial design (Forrester et al., 2007; Huang et al., 2006; Klein et al., 2015; Lam et al., 2015; Poloczek et al., 2016; Swersky et al., 2013).",1. Introduction,[0],[0]
"However, these methods are either problem specific and/or only use a finite number of fidelities.",1. Introduction,[0],[0]
"Further, none of them come with theoretical underpinnings.",1. Introduction,[0],[0]
"Recent work has studied multi-fidelity methods for specific problems such as hyperparameter tuning, active learning and reinforcement learning (Agarwal et al., 2011; Cutler et al., 2014; Li et al., 2016; Sabharwal et al., 2015; Zhang & Chaudhuri, 2015).",1. Introduction,[0],[0]
"While
some of the above tasks can be framed as optimisation problems, the methods themselves are specific to the problem considered.",1. Introduction,[0],[0]
"Our method is more general as it applies to any bandit optimisation task.
",1. Introduction,[0],[0]
Perhaps the closest work to us is that of Kandasamy et al. (2016a;b;c) who developed MF-GP-UCB assuming a finite number of approximations to f .,1. Introduction,[0],[0]
"While this line of work was the first to provide theoretical guarantees for multifidelity optimisation, it has two important shortcomings.",1. Introduction,[0],[0]
"First, they make strong assumptions, particularly a uniform bound on the difference between the expensive function and an approximation.",1. Introduction,[0],[0]
This does not allow for instances where an approximation might be good at certain regions but not at the other.,1. Introduction,[0],[0]
"In contrast, our probabilistic treatment between fidelities is is robust to such cases.",1. Introduction,[0],[0]
"Second, their model does not allow sharing information between fidelities; each approximation is treated independently.",1. Introduction,[0],[0]
"Not only is this wasteful as lower fidelities can provide useful information about higher fidelities, it also means that the algorithm might perform poorly if the fidelities are not designed properly.",1. Introduction,[0],[0]
We demonstrate this with an experiment in Section 4.,1. Introduction,[0],[0]
"On the other hand, our model allows sharing information across the fidelity space in a natural way.",1. Introduction,[0],[0]
"In addition, we can also handle continuous approximations whereas their method is strictly for a finite number of approximations.",1. Introduction,[0],[0]
"That said, BOCA inherits a key intuition from MF-GP-UCB, which is to choose a fidelity only if we have sufficiently reduced the uncertainty at all lower fidelities.",1. Introduction,[0],[0]
"Besides this, there are considerable differences in the mechanics of the algorithm and proof techniques.",1. Introduction,[0],[0]
"As we proceed, we will draw further comparisons to Kandasamy et al. (2016a).",1. Introduction,[0],[0]
Gaussian processes: A GP over a space X is a random process from X to R. GPs are typically used as a prior for functions in Bayesian nonparametrics.,2.1. Some Background Material,[0],[0]
It is characterised by a mean function µ : X → R and a covariance function (or kernel) κ :,2.1. Some Background Material,[0],[0]
"X 2 → R. If f ∼ GP(µ, κ), then f(x) is distributed normally N (µ(x), κ(x, x)) for all x ∈ X .",2.1. Some Background Material,[0],[0]
"Suppose that we are given n observations Dn = {(xi, yi)}ni=1 from this GP, where xi ∈ X , yi = f(xi)",2.1. Some Background Material,[0],[0]
+,2.1. Some Background Material,[0],[0]
i ∈ R,2.1. Some Background Material,[0],[0]
"and i ∼ N (0, η2).",2.1. Some Background Material,[0],[0]
"Then the posterior process f |Dn is also a GP with mean µn and covariance κn given by
µn(x) =",2.1. Some Background Material,[0],[0]
k >,2.1. Some Background Material,[0],[0]
"(K + η2I)−1Y, (1)
κn(x, x ′) = κ(x, x′)− k>(K +",2.1. Some Background Material,[0],[0]
"η2I)−1k′.
Here",2.1. Some Background Material,[0],[0]
Y ∈,2.1. Some Background Material,[0],[0]
"Rn is a vector with Yi = yi, and k, k′ ∈",2.1. Some Background Material,[0],[0]
"Rn are such that ki = κ(x, xi), k′i = κ(x
′, xi).",2.1. Some Background Material,[0],[0]
"The matrix K ∈ Rn×n is given by Ki,j = κ(xi, xj).",2.1. Some Background Material,[0],[0]
"We refer the reader to chapter 2 of Rasmussen & Williams (2006) for more on the basics of GPs and their use in regression.
",2.1. Some Background Material,[0],[0]
Radial kernels:,2.1. Some Background Material,[0],[0]
The prior covariance functions of GPs are typically taken to be radial kernels; some examples are the squared exponential (SE) and Matérn kernels.,2.1. Some Background Material,[0],[0]
"Using a radial kernel means that the prior covariance can be written as κ(x, x′) = κ0φ(‖x−x′‖) and depends only on the distance between x and x′. Here, the scale parameter κ0 captures the magnitude f could deviate from µ. The function φ : R+ → R+ is a decreasing function with ‖φ‖∞ = φ(0) = 1.",2.1. Some Background Material,[0],[0]
"In this paper, we will use the SE kernel in a running example to convey the intuitions in our methods.",2.1. Some Background Material,[0],[0]
"For the SE kernel, φ(r) = φh(r) = exp(−r2/(2h2)), where h ∈ R+, called the bandwidth of the kernel, controls the smoothness of the GP.",2.1. Some Background Material,[0],[0]
"When h is large, the samples drawn from the GP tend to be smoother as illustrated in Fig. 1.",2.1. Some Background Material,[0],[0]
"We will reference this observation frequently in the text.
",2.1. Some Background Material,[0],[0]
"GP-UCB: The Gaussian Process Upper Confidence Bound (GP-UCB) algorithm of Srinivas et al. (2010) is a method for bandit optimisation, which, like many other BO methods, models f as a sample from a Gaussian process.",2.1. Some Background Material,[0],[0]
"At time t, the next point xt for evaluating f is chosen via the following procedure.",2.1. Some Background Material,[0],[0]
"First, we construct an upper confidence bound ϕt(x) = µt−1(x) + β 1/2 t σt−1(x) for the GP.",2.1. Some Background Material,[0],[0]
µt−1 is the posterior mean of the GP conditioned on the previous t− 1 evaluations and σt−1 is the posterior standard deviation.,2.1. Some Background Material,[0],[0]
"Following other UCB algorithms (Auer, 2003), the next point is chosen by maximising ϕt, i.e. xt = argmaxx∈X ϕt(x).",2.1. Some Background Material,[0],[0]
The µt−1 term encourages an exploitative strategy – in that we want to query regions where we already believe f is high – and σt−1 encourages an exploratory strategy – in that we want to query where we are uncertain about f so that we do not miss regions which have not been queried yet.,2.1. Some Background Material,[0],[0]
"βt, which is typically increasing with t, controls the trade-off between exploration and exploitation.",2.1. Some Background Material,[0],[0]
We have provided a brief review of GP-UCB in Appendix A.1.,2.1. Some Background Material,[0],[0]
"Our goal in bandit optimisation is to maximise a function f : X → R, over a domain X .",2.2. Problem Set Up,[0],[0]
When we evaluate f at x ∈ X we observe y = f(x) + where E[ ] = 0.,2.2. Problem Set Up,[0],[0]
Let,2.2. Problem Set Up,[0],[0]
x? ∈,2.2. Problem Set Up,[0],[0]
argmaxx∈X f(x) be a maximiser of f and f? = f(x?),2.2. Problem Set Up,[0],[0]
be the maximum value.,2.2. Problem Set Up,[0],[0]
"An algorithm for bandit optimisation is a sequence of points {xt}t≥0, where, at time t, the algorithm chooses to evaluate f at xt based on previous queries and
observations {(xi, yi)}t−1i=1 .",2.2. Problem Set Up,[0],[0]
"After n queries to f , its goal is to achieve small simple regret Sn, as defined below.
",2.2. Problem Set Up,[0],[0]
"Sn = min t=1,...,n
f?",2.2. Problem Set Up,[0],[0]
− f(xt).,2.2. Problem Set Up,[0],[0]
"(2)
Continuous Approximations: In this work, we will let f be a slice of a function g that lies in a larger space.",2.2. Problem Set Up,[0],[0]
"Precisely, we will assume the existence of a fidelity space Z and a function g : Z×X → R defined on the product space of the fidelity space and domain.",2.2. Problem Set Up,[0],[0]
"The function f which we wish to maximise is related to g via f(·) = g(z•, ·), where z• ∈ Z .",2.2. Problem Set Up,[0],[0]
"For instance, in the hyper-parameter tuning example from Section 1, Z = [1, N•] ×",2.2. Problem Set Up,[0],[0]
"[1, T•]",2.2. Problem Set Up,[0],[0]
and z• =,2.2. Problem Set Up,[0],[0]
"[N•, T•].",2.2. Problem Set Up,[0],[0]
"Our goal is to find a maximiser x? ∈ argmaxx f(x) = argmaxx g(z•, x).",2.2. Problem Set Up,[0],[0]
We have illustrated this setup in Fig. 2.,2.2. Problem Set Up,[0],[0]
"In the rest of the manuscript, the term “fidelities” will refer to points z in the fidelity space Z .
",2.2. Problem Set Up,[0],[0]
"The multi-fidelity framework is attractive when the following two conditions are true about the problem.
",2.2. Problem Set Up,[0],[0]
1.,2.2. Problem Set Up,[0],[0]
"There exist fidelities z ∈ Z where evaluating g is cheaper than evaluating at z•. To this end, we will associate a known cost function λ : Z → R+.",2.2. Problem Set Up,[0],[0]
"In the hyper-parameter tuning example, λ(z) = λ(N,T ) = O(N2T ).",2.2. Problem Set Up,[0],[0]
"It is helpful to think of z• as being the most expensive fidelity, i.e. maximiser of λ, and that λ(z) decreases as we move away from z•. However, this notion is strictly not necessary for our algorithm or results.
",2.2. Problem Set Up,[0],[0]
2.,2.2. Problem Set Up,[0],[0]
"The cheap g(z, ·) evaluation gives us information about g(z•, ·).",2.2. Problem Set Up,[0],[0]
This is true if g is smooth across the fidelity space as illustrated in Fig. 2.,2.2. Problem Set Up,[0],[0]
"As we will describe shortly, this smoothness can be achieved by modelling g as a GP with an appropriate kernel for the fidelity space Z .
",2.2. Problem Set Up,[0],[0]
"In the above setup, a multi-fidelity algorithm is a sequence of query-fidelity pairs {(zt, xt)}t≥0 where, at time t, the algorithm chooses zt ∈ Z and xt ∈ X , and observes yt =
g(zt, xt) + where E[ ] = 0.",2.2. Problem Set Up,[0],[0]
"The choice of (zt, xt) can of course depend on the previous fidelity-query-observation triples {(zi, xi, yi)}t−1i=1 .
",2.2. Problem Set Up,[0],[0]
Multi-fidelity Simple Regret: We provide bounds on the simple regret S(Λ) of a multi-fidelity optimisation method after it has spent capital Λ of a resource.,2.2. Problem Set Up,[0],[0]
"Following Kandasamy et al. (2016a); Srinivas et al. (2010), we will aim to provide any capital bounds, meaning that an algorithm would be expected to do well for all values of (sufficiently large)",2.2. Problem Set Up,[0],[0]
"Λ. Say we have made N queries to g within capital Λ, i.e. N is the random quantity such that N = max{n",2.2. Problem Set Up,[0],[0]
≥ 1 : ∑n t=1 λ(zt) ≤ Λ}.,2.2. Problem Set Up,[0],[0]
"While the cheap evaluations at z 6= z• are useful in guiding search for the optimum of g(z•, ·), there is no reward for optimising a cheaper g(z, ·).",2.2. Problem Set Up,[0],[0]
"Accordingly, we define the simple regret after capital Λ as,
S(Λ) =  min t∈{1,...,N} s.t zt=z• f?",2.2. Problem Set Up,[0],[0]
"− f(xt) if we have queried at z•,
+∞ otherwise.
",2.2. Problem Set Up,[0],[0]
"This definition reduces to the single fidelity definition (2) when we only query g at z•. It is also similar to the definition in Kandasamy et al. (2016a), but unlike them, we do not impose additional boundedness constraints on f or g.
Before we proceed, we note that it is customary in the bandit literature to analyse cumulative regret.",2.2. Problem Set Up,[0],[0]
"However, the definition of cumulative regret depends on the application at hand (Kandasamy et al., 2016c) and the results in this paper can be extended to to many sensible notions of cumulative regret.",2.2. Problem Set Up,[0],[0]
"However, both to simplify exposition and since our focus in this paper is optimisation, we stick to simple regret.
",2.2. Problem Set Up,[0],[0]
"Assumptions: As we will be primarily focusing on continuous and compact domains and fidelity spaces, going forward we will assume, without any loss of generality, that X =",2.2. Problem Set Up,[0],[0]
"[0, 1]d and Z =",2.2. Problem Set Up,[0],[0]
"[0, 1]p.",2.2. Problem Set Up,[0],[0]
We discuss non-continuous settings briefly at the end of Section 3.,2.2. Problem Set Up,[0],[0]
"In keeping with similar work in the Bayesian optimisation literature, we will assume g ∼ GP(0, κ) and upon querying at (z, x) we observe y = g(z, x) + where ∼ N (0, η2).",2.2. Problem Set Up,[0],[0]
κ :,2.2. Problem Set Up,[0],[0]
(Z × X )2 → R is the prior covariance defined on the product space.,2.2. Problem Set Up,[0],[0]
"In this work, we will study exclusively κ of the following form,
κ([z, x], [z′, x′]) = κ0 φZ(‖z",2.2. Problem Set Up,[0],[0]
− z′‖)φX (‖x− x′‖).,2.2. Problem Set Up,[0],[0]
"(3)
Here, κ0 ∈ R+ is the scale parameter and φZ , φX are radial kernels defined on Z,X respectively.",2.2. Problem Set Up,[0],[0]
The fidelity space kernel φZ is an important component in this work.,2.2. Problem Set Up,[0],[0]
"It controls the smoothness of g across the fidelity space and hence determines how much information the lower fidelities provide about g(z•, ·).",2.2. Problem Set Up,[0],[0]
"For example, suppose that φZ was a SE kernel.",2.2. Problem Set Up,[0],[0]
"A favourable setting for a multi-fidelity method would be for φZ to have a large bandwidth hZ as that would imply
that g is very smooth across Z .",2.2. Problem Set Up,[0],[0]
We will see that hZ determines the behaviour and theoretical guarantees of BOCA in a natural way when φZ is the SE kernel.,2.2. Problem Set Up,[0],[0]
"To formalise this notion, we will define the following function ξ : Z →",2.2. Problem Set Up,[0],[0]
"[0, 1].
ξ(z) = √ 1− φZ(‖z",2.2. Problem Set Up,[0],[0]
"− z•‖)2 (4)
One interpretation of ξ(z) is that it measures the gap in information about g(z•, ·) when we query at z 6=",2.2. Problem Set Up,[0],[0]
"z•. That is, it is the price we have to pay, in information, for querying at a cheap fidelity.",2.2. Problem Set Up,[0],[0]
Observe that ξ increases when we move away from z• in the fidelity space.,2.2. Problem Set Up,[0],[0]
"For the SE kernel, it can be shown1 ξ(z)",2.2. Problem Set Up,[0],[0]
≈ ‖z−z•‖hZ .,2.2. Problem Set Up,[0],[0]
"For large hZ , g is smoother across Z and we can expect the lower fidelities to be more informative about f ; as expected the information gap ξ is small for large hZ .",2.2. Problem Set Up,[0],[0]
"If hZ is small and g is not smooth, the gap ξ is large and lower fidelities are not as informative.
",2.2. Problem Set Up,[0],[0]
"Before we present our algorithm for the above setup, we will introduce notation for the posterior GPs for g and f .",2.2. Problem Set Up,[0],[0]
"Let Dn = {(zi, xi, yi)}ni=1 be n fidelity, query, observation values from the GP g, where yi was observed when evaluating g(zi, xi).",2.2. Problem Set Up,[0],[0]
"We will denote the posterior mean and standard deviation of g conditioned on Dn by νn and τn respectively (νn, τn can be computed from (1) by replacing x←",2.2. Problem Set Up,[0],[0]
"[z, x]).",2.2. Problem Set Up,[0],[0]
"Therefore g(z, x)|Dn ∼ N (νn(z, x), τ2n(z, x)) for all (z, x) ∈ Z × X .",2.2. Problem Set Up,[0],[0]
"We will further denote
µn(·) = νn(z•, ·), σn(·) = τn(z•, ·), (5)
to be the posterior mean and standard deviation of g(z•, ·) = f(·).",2.2. Problem Set Up,[0],[0]
"It follows that f |Dn is also a GP and satisfies f(x)|Dn ∼ N (µn(x), σ2n(x)) for all x ∈ X .
3.",2.2. Problem Set Up,[0],[0]
"BOCA: Bayesian Optimisation with Continuous Approximations
BOCA is a sequential strategy to select a domain point xt ∈ X and fidelity zt ∈ Z at time t based on previous observations.",2.2. Problem Set Up,[0],[0]
"At time t, we will first construct an upper confidence bound ϕt for the function f we wish to optimise.",2.2. Problem Set Up,[0],[0]
"It takes the form,
ϕt(x) = µt−1(x) + β 1/2 t σt−1(x).",2.2. Problem Set Up,[0],[0]
"(6)
Recall from (5) that µt−1 and σt−1 are the posterior mean and standard deviation of f using the observations from the previous t−1 time steps at all fidelities, i.e. the entireZ×X space.",2.2. Problem Set Up,[0],[0]
"We will specify βt in Theorems 1, 8.",2.2. Problem Set Up,[0],[0]
"Following other UCB algorithms, our next point xt in the domain X for evaluating g is a maximiser of ϕt, i.e. xt ∈ argmaxx∈X ϕt(x).
",2.2. Problem Set Up,[0],[0]
"Next, we need to determine the fidelity zt ∈ Z to query g. 1Strictly, ξ(z) ≤",2.2. Problem Set Up,[0],[0]
"‖z− z•‖/hZ , but the inequality is tighter for larger hZ .",2.2. Problem Set Up,[0],[0]
"In any case, ξ is strictly decreasing with hZ .
",2.2. Problem Set Up,[0],[0]
"For this we will first select a subset Zt(xt) of Z as follows,
Zt(xt) = { z ∈ Z : λ(z) < λ(z•), τt−1(z, xt) > γ(z),
ξ(z) >",2.2. Problem Set Up,[0],[0]
β −1/2,2.2. Problem Set Up,[0],[0]
"t ‖ξ‖∞ } , (7)
where γ(z) = √ κ0 ξ(z)
( λ(z)
λ(z•)
)q .
",2.2. Problem Set Up,[0],[0]
"Here, ξ is the information gap function in (4) and τt−1 is the posterior standard deviation of g, and p, d are the dimensionalities of Z,X .",2.2. Problem Set Up,[0],[0]
The exponent q depends on the kernel used for φZ .,2.2. Problem Set Up,[0],[0]
"For e.g., for the SE kernel, q = 1/(p+ d + 2).",2.2. Problem Set Up,[0],[0]
We filter out the fidelities we consider at time t using three conditions as specified above.,2.2. Problem Set Up,[0],[0]
We elaborate on these conditions in more detail in Section 3.1.,2.2. Problem Set Up,[0],[0]
"If Zt is not empty, we choose the cheapest fidelity in this set, i.e. zt ∈ argminz∈Zt λ(z).",2.2. Problem Set Up,[0],[0]
"If Zt is empty, we choose zt = z•.
We have summarised the resulting procedure below in Algorithm 1.",2.2. Problem Set Up,[0],[0]
An important advantage of BOCA is that it only requires specifying the GP hyper-parameters for g such as the kernel κ.,2.2. Problem Set Up,[0],[0]
"In practice, this can be achieved by various effective heuristics such as maximising the GP marginal likelihood or cross validation which are standard in most BO methods.",2.2. Problem Set Up,[0],[0]
"In contrast, MF-GP-UCB of Kandasamy et al. (2016a) requires tuning several other hyper-parameters.
",2.2. Problem Set Up,[0],[0]
Algorithm 1 BOCA Input: kernel κ. •,2.2. Problem Set Up,[0],[0]
"Set ν0(·)← 0, τ0(·)← κ(·, ·)1/2, D0 ← ∅. • for t = 1, 2, . . .
",2.2. Problem Set Up,[0],[0]
1. xt,2.2. Problem Set Up,[0],[0]
← argmaxx∈X ϕt(x).,2.2. Problem Set Up,[0],[0]
See (6) 2.,2.2. Problem Set Up,[0],[0]
zt ← argminz∈Zt(xt)∪{z•} λ(z).,2.2. Problem Set Up,[0],[0]
See (7) 3.,2.2. Problem Set Up,[0],[0]
yt,2.2. Problem Set Up,[0],[0]
"← Query g at (zt, xt).",2.2. Problem Set Up,[0],[0]
4.,2.2. Problem Set Up,[0],[0]
"Dt ← Dt−1 ∪ {(zt, xt, yt)}.",2.2. Problem Set Up,[0],[0]
"Update posterior mean νt, and standard deviation τt for g conditioned on Dt.",2.2. Problem Set Up,[0],[0]
"We will now provide an intuitive justification for the three conditions in the selection criterion for zt, i.e., equation (7).",3.1. Fidelity Selection Criterion,[0],[0]
"The first condition, λ(z) < λ(z•) is fairly obvious; since we wish to optimise g(z•, ·) and since we are not rewarded for queries at other fidelities, there is no reason to consider fidelities that are more expensive than z•.
The second condition, τt−1(z, xt) > γ(z) says that we will only consider fidelities where the posterior variance is larger than a threshold γ(z) = √ κ0ξ(z)(λ(z)/λ(z•))
q , which depends critically on two quantities, the cost function λ and the information gap ξ.",3.1. Fidelity Selection Criterion,[0],[0]
"As a first step towards parsing this condition, observe that a reasonable multi-fidelity strategy should be inclined to query cheap fidelities and learn about
g before querying expensive fidelities.",3.1. Fidelity Selection Criterion,[0],[0]
"As γ(z) is monotonically increasing in λ(z), it becomes easier for a cheap z to satisfy τt−1(z, xt) > γ(z) and be included in Zt at time",3.1. Fidelity Selection Criterion,[0],[0]
"t. Moreover, since we choose zt to be the minimiser of λ in Zt, a cheaper fidelity will always be chosen over expensive ones if included in Zt.",3.1. Fidelity Selection Criterion,[0],[0]
"Second, if a particular fidelity z is far away from z•, it probably contains less information about g(z•, ·).",3.1. Fidelity Selection Criterion,[0],[0]
"Again, a reasonable multi-fidelity strategy should be discouraged from making such queries.",3.1. Fidelity Selection Criterion,[0],[0]
This is precisely the role of the information gap ξ which is increasing with ‖z,3.1. Fidelity Selection Criterion,[0],[0]
"− z•‖. As z moves away from z•, γ(z) increases and it becomes harder to satisfy τt−1(z, xt) > γ(z).",3.1. Fidelity Selection Criterion,[0],[0]
"Therefore, such a z is less likely to be included in Zt(xt) and be considered for evaluation.",3.1. Fidelity Selection Criterion,[0],[0]
"Our analysis reveals that setting γ as in (7) is a reasonable trade off between cost and information in the approximations available to us; cheaper fidelities cost less, but provide less accurate information about the function f we wish to optimise.",3.1. Fidelity Selection Criterion,[0],[0]
It is worth noting that the second condition is similar in spirit to Kandasamy et al. (2016a) who proceed from a lower to higher fidelity only when the lower fidelity variance is smaller than a threshold.,3.1. Fidelity Selection Criterion,[0],[0]
"However, while they treat the threshold as a hyper-parameter, we are able to explicitly specify theoretically motivated values.
",3.1. Fidelity Selection Criterion,[0],[0]
The third condition in (7) is ξ(z) > ‖ξ‖∞/β1/2t .,3.1. Fidelity Selection Criterion,[0],[0]
"Since ξ is increasing as we move away from z•, it says we should exclude fidelities inside a (small) neighbourhood of z•. Recall that if Zt is empty, BOCA will choose z• by default.",3.1. Fidelity Selection Criterion,[0],[0]
"But when it is not empty, we want to prevent situations where we get arbitrarily close to z• but not actually query at z•. Such pathologies can occur when we are dealing with a continuum of fidelities and this condition forces BOCA to pick z• instead of querying very close to it.",3.1. Fidelity Selection Criterion,[0],[0]
"Observe that since βt is increasing with t, this neighborhood is shrinking with time and therefore the algorithm will eventually have the opportunity to evaluate fidelities close to z•.",3.1. Fidelity Selection Criterion,[0],[0]
We now present our main theoretical contributions.,3.2. Theoretical Results,[0],[0]
"In order to simplify the exposition and convey the gist of our results, we will only present a simplified version of our theorems.",3.2. Theoretical Results,[0],[0]
"We will suppress constants, polylog terms, and other technical details that arise due to a covering argument in our proofs.",3.2. Theoretical Results,[0],[0]
"A rigorous treatment is available in Appendix B.
Maximum Information Gain: Up until this point, we have not discussed much about the kernel φX of the domain X .",3.2. Theoretical Results,[0],[0]
"Since we are optimising f over X , it is natural to expect that this will appear in the bounds.",3.2. Theoretical Results,[0],[0]
Srinivas et al. (2010) showed that the statistical difficulty of GP bandits is determined by the Maximum Information Gain (MIG) which measures the maximum information a subset of observations have about f .,3.2. Theoretical Results,[0],[0]
We denote it by Ψn(A) where A is a subset of X and n is the number of queries to f .,3.2. Theoretical Results,[0],[0]
"We refer the reader
to Appendix B for a formal definition of MIG.",3.2. Theoretical Results,[0],[0]
"For the current exposition however, it suffices to know that for radial kernels, Ψn(A) increases with n and the volume vol(A) of A.",3.2. Theoretical Results,[0],[0]
"For instance, when we use an SE kernel for φX , we have Ψn(A) ∝",3.2. Theoretical Results,[0],[0]
"vol(A) log(n)d+1and for a Matérn kernel with smoothness parameter ν, Ψn(A) ∝ vol(A)n1− ν 2ν+d(d+1) .",3.2. Theoretical Results,[0],[0]
"(Srinivas et al., 2010).",3.2. Theoretical Results,[0],[0]
"Let nΛ = bΛ/λ(z•)c denote the number of queries by a single fidelity algorithm within capital Λ. Srinivas et al. (2010) showed that the simple regret S(Λ) for GP-UCB after capital Λ can be bounded by,
Simple Regret for GP-UCB: S(Λ) .",3.2. Theoretical Results,[0],[0]
√ ΨnΛ(X ) nΛ .,3.2. Theoretical Results,[0],[0]
"(8)
In our analysis of BOCA we show that most queries to g at fidelity z• will be confined to a small subset of X which contains the optimum x?.",3.2. Theoretical Results,[0],[0]
"Precisely, after capital Λ, for any α ∈ (0, 1), we show there exists ρ > 0",3.2. Theoretical Results,[0],[0]
"such that the number of queries outside the following set Xρ is less than nαΛ.
Xρ = { x ∈ X",3.2. Theoretical Results,[0],[0]
: f? − f(x) ≤,3.2. Theoretical Results,[0],[0]
2ρ,3.2. Theoretical Results,[0],[0]
√ κ0 ‖ξ‖∞ } .,3.2. Theoretical Results,[0],[0]
"(9)
Here, ξ is from (4).",3.2. Theoretical Results,[0],[0]
"While it is true that any optimisation algorithm would eventually query extensively in a neighbourhood around the optimum, a strong result of the above form is not always possible.",3.2. Theoretical Results,[0],[0]
"For instance, for GP-UCB, the best achievable bound on the number of queries in any set that does not contain x? is n 1/2 Λ .",3.2. Theoretical Results,[0],[0]
"The fact that Xρ exists relies crucially on the multi-fidelity assumptions and that our algorithm leverages information from lower fidelities when querying at z•. As ξ is small when g is smooth across Z , the set Xρ will be small when the approximations are highly informative about g(z•, ·).",3.2. Theoretical Results,[0],[0]
"For e.g., when φZ is a SE kernel, we haveXρ ≈ {x ∈ X : f?−f(x) ≤ 2ρ √ κ0p/hZ}.",3.2. Theoretical Results,[0],[0]
"When hZ is large and g is smooth across Z , Xρ is small as the right side of the inequality is smaller.",3.2. Theoretical Results,[0],[0]
"As BOCA confines most of its evaluations to this small set containing x?, we will be able to achieve much better regret than GP-UCB.",3.2. Theoretical Results,[0],[0]
"When hZ is small and g is not smooth across Z , the set Xρ becomes large and the advantage of multi-fidelity optimisation diminishes.",3.2. Theoretical Results,[0],[0]
"One can similarly argue that for the Matérn kernel, as the parameter ν increases, g will be smoother across Z , and Xρ becomes smaller yielding better bounds on the regret.",3.2. Theoretical Results,[0],[0]
"Below, we provide an informal statement of our main theoretical result. .",3.2. Theoretical Results,[0],[0]
", will denote inequality and equality ignoring constant and polylog terms.
",3.2. Theoretical Results,[0],[0]
"Theorem 1 (Informal, Regret of BOCA).",3.2. Theoretical Results,[0],[0]
"Let g ∼ GP(0, κ) where κ satisfies (3).",3.2. Theoretical Results,[0],[0]
Choose βt d log(t/δ).,3.2. Theoretical Results,[0],[0]
"Then, for sufficiently large Λ and for all α ∈ (0, 1), there exists ρ depending on α such that the following bound holds with probability at least 1− δ.
S(Λ) .",3.2. Theoretical Results,[0],[0]
√ ΨnΛ(Xρ) nΛ + √ ΨnαΛ(X ),3.2. Theoretical Results,[0],[0]
"n2−αΛ
In the above bound, the latter term vanishes fast due to the n−(1−α/2)Λ dependence.",3.2. Theoretical Results,[0],[0]
"When comparing this with (8), we see that we outperform GP-UCB by a factor of √ ΨnΛ(Xρ)/ΨnΛ(X ) √
vol(Xρ)/vol(X ) asymptotically.",3.2. Theoretical Results,[0],[0]
"If g is smooth across the fidelity space, Xρ is small and the gains over GP-UCB are significant.",3.2. Theoretical Results,[0],[0]
"If g becomes less smooth across Z , the bound decays gracefully, but we are never worse than GP-UCB up to constant factors.
",3.2. Theoretical Results,[0],[0]
Theorem 1 also has similarities to the bounds of Kandasamy et al. (2016a) who also demonstrate better regret than GPUCB by showing that it is dominated by queries inside a set X ′,3.2. Theoretical Results,[0],[0]
which contains the optimum.,3.2. Theoretical Results,[0],[0]
"However, their bounds depend critically on certain threshold hyper-parameters which determine the volume of X ′",3.2. Theoretical Results,[0],[0]
among other terms in their regret.,3.2. Theoretical Results,[0],[0]
"The authors of that paper note that their bounds will suffer if these hyper-parameters are not chosen appropriately, but do not provide theoretically justified methods to make this choice.",3.2. Theoretical Results,[0],[0]
"In contrast, many of the design choices for BOCA fall out naturally of our modeling assumptions.",3.2. Theoretical Results,[0],[0]
"Beyond this analogue, our results are not comparable to Kandasamy et al. (2016a) as the assumptions are different.
",3.2. Theoretical Results,[0],[0]
"Extensions: While we have focused on continuousZ , many of the ideas here can be extended to other settings.",3.2. Theoretical Results,[0],[0]
"If Z is a discrete subset of [0, 1]p our work extends straightforwardly.",3.2. Theoretical Results,[0],[0]
We reiterate that this will not be the same as the finite fidelity MF-GP-UCB algorithm as the assumptions are different.,3.2. Theoretical Results,[0],[0]
"In particular, Kandasamy et al. (2016a) are not able to effectively share information across fidelities as we do.",3.2. Theoretical Results,[0],[0]
We also believe that Algorithm 1 can be extended to arbitrary fidelity spaces Z provided that a kernel can be defined on Z .,3.2. Theoretical Results,[0],[0]
Our results can also be extended to discrete domains X and various other kernels for φX by adopting techniques from Srinivas et al. (2010).,3.2. Theoretical Results,[0],[0]
"We compare BOCA to the following four baselines: (i) GPUCB, (ii) the GP-EI criterion in BO (Jones et al., 1998), (iii) MF-GP-UCB (Kandasamy et al., 2016a) and (iv) MF-SKO, the multi-fidelity sequential kriging optimisation method from Huang et al. (2006).",4. Experiments,[0],[0]
All methods are based on GPs and we use the SE kernel for both the fidelity space and domain.,4. Experiments,[0],[0]
"The first two are not multi-fidelity methods, while the last two are finite multi-fidelity methods2.",4. Experiments,[0],[0]
Kandasamy et al. (2016a) also study some naive multi-fidelity algorithms and demonstrate that they do not perform well; as such we will not consider such alternatives here.,4. Experiments,[0],[0]
"In all our experiments, the fidelity space was designed to be Z =",4. Experiments,[0],[0]
"[0, 1]p with z• = 1p =",4. Experiments,[0],[0]
"[1, . .",4. Experiments,[0],[0]
.,4. Experiments,[0],[0]
", 1] ∈",4. Experiments,[0],[0]
"Rp being the most expensive fi-
2To our knowledge, the only other work that applies to continuous approximations is Klein et al. (2015) which was developed specifically for hyper-parameter tuning.",4. Experiments,[0],[0]
"Further, their implementation is not made available and is not straightforward to implement.
delity.",4. Experiments,[0],[0]
"For MF-GP-UCB and MF-SKO, we used 3 fidelities (2 approximations) where the approximations were obtained at z = 0.3331p and z = 0.6671p in Z .",4. Experiments,[0],[0]
"Empirically, we found that both algorithms did reasonably well with 1-3 approximations, but did not perform well with a large number of approximations (> 5); even the original papers restrict experiments to 1-3 approximations.",4. Experiments,[0],[0]
Implementation details for all methods are given in Appendix C.1.,4. Experiments,[0],[0]
The results for the first set of synthetic experiments are given in Fig. 3.,4.1. Synthetic Experiments,[0],[0]
"The title of each figure states the function used, and the dimensionalities p, d of the fidelity space and domain.",4.1. Synthetic Experiments,[0],[0]
"To reflect the setting in our theory, we add Gaussian noise to the function value when observing g at any (z, x).",4.1. Synthetic Experiments,[0],[0]
This makes the problem more challenging than standard global optimisation problems where function evaluations are not noisy.,4.1. Synthetic Experiments,[0],[0]
"The functions g, the cost functions λ and the noise variances η2 are given in Appendix C.2.
",4.1. Synthetic Experiments,[0],[0]
The first two panels in Fig. 3 are simple sanity checks.,4.1. Synthetic Experiments,[0],[0]
"In both cases, Z = [0, 1], X = [0, 1] and the functions were sampled from GPs.",4.1. Synthetic Experiments,[0],[0]
"The GP was made known to all methods, i.e. all methods used the true GP in picking the next point.",4.1. Synthetic Experiments,[0],[0]
"In the first panel, we used an SE kernel with bandwidth 0.1 for φX and 1.0 for φZ .",4.1. Synthetic Experiments,[0],[0]
"g is smooth across Z in this setting, and BOCA outperforms other baselines.",4.1. Synthetic Experiments,[0],[0]
The curve starts mid-way as BOCA is yet to query at z• up until that point.,4.1. Synthetic Experiments,[0],[0]
"The second panel uses the same set up as the first except
we used bandwidth 0.01 for φZ .",4.1. Synthetic Experiments,[0],[0]
"Even though g is highly un-smooth across Z , BOCA does not perform poorly.",4.1. Synthetic Experiments,[0],[0]
This corroborates a claim that we made earlier that BOCA can naturally adapt to the smoothness of the approximations.,4.1. Synthetic Experiments,[0],[0]
"The other multi-fidelity methods suffer in this setting.
",4.1. Synthetic Experiments,[0],[0]
"In the remaining experiments, we use some standard benchmarks for global optimisation.",4.1. Synthetic Experiments,[0],[0]
We modify them to obtain g and add noise to the observations.,4.1. Synthetic Experiments,[0],[0]
"As the kernel and other GP hyper-parameters are unknown, we learn them by maximising the marginal likelihood every 25 iterations.",4.1. Synthetic Experiments,[0],[0]
We outperform all methods on all problems except in the case of the Borehole function where MF-GP-UCB does better.,4.1. Synthetic Experiments,[0],[0]
The last synthetic experiment is the Branin function given in Fig. 4(a).,4.1. Synthetic Experiments,[0],[0]
"We used the same set up as above, but use 10 fidelities for MF-GP-UCB and MF-SKO where the kth fidelity is obtained at z = k101p in the fidelity space.",4.1. Synthetic Experiments,[0],[0]
Notice that the performance of finite fidelity methods deteriorate.,4.1. Synthetic Experiments,[0],[0]
"In particular, as MF-GP-UCB does not share information across fidelities, the approximations need to be designed carefully for the algorithm to work well.",4.1. Synthetic Experiments,[0],[0]
Our more natural modelling assumptions prevent such pitfalls.,4.1. Synthetic Experiments,[0],[0]
We next present two real examples in astrophysics and hyper-parameter tuning.,4.1. Synthetic Experiments,[0],[0]
"We do not add noise to the observations, but treat it as optimisation tasks, where the goal is to maximise the function.",4.1. Synthetic Experiments,[0],[0]
"We use data on TypeIa supernova for maximum likelihood inference on 3 cosmological parameters, the Hubble con-
stant H0 ∈ (60, 80), the dark matter fraction ΩM ∈ (0, 1) and dark energy fraction ΩΛ ∈ (0, 1); hence d = 3.",4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
"The likelihood is given by the Robertson-Walker metric, the computation of which requires a one dimensional numerical integration for each point in the dataset.",4.2. Astrophysical Maximum Likelihood Inference,[0.9546365364707441],['Multimodal Fusion has a Volatile Nature: The first observation is that the structure of the DFG is changing case by case and for each case over time.']
"Unlike typical maximum likelihood problems, here the likelihood is only accessible via point evaluations.",4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
We use the dataset from Davis et al (2007) which has data on 192 supernovae.,4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
We construct a p = 2 dimensional multi-fidelity problem where we can choose between data set size N ∈,4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
"[50, 192] and perform the integration on grids of size G ∈",4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
"[102, 106] via the trapezoidal rule.",4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
"As the cost function for fidelity selection, we used λ(N,G) = NG as the computation time is linear in both parameters.",4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
Our goal is to maximise the average log likelihood at z• =,4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
"[192, 106].",4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
For the finite fidelity methods we use three fidelities with the approximations available at z =,4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
"[97, 2.15× 103] and z = [145, 4.64× 104] (which correspond to 0.3331p and 0.6671p after rescaling as in Section 4.1).",4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
The results are given in Fig. 4(b) where we plot the maximum average log likelihood against wall clock time as that is the cost in this experiment.,4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
The plot includes the time taken by each method to tune the GPs and determine the next points/fidelities for evaluation.,4.2. Astrophysical Maximum Likelihood Inference,[0],[0]
"We use the 20 news groups dataset (Joachims, 1996) in a text classification task.",4.3. Support Vector Classification with 20 news groups,[0],[0]
"We obtain the bag of words representation for each document, convert them to tf-idf features and feed them to a support vector classifier.",4.3. Support Vector Classification with 20 news groups,[0],[0]
"The goal is to tune the regularisation penalty and the temperature of the rbf kernel both in the range [10−2, 103]; hence d = 2.",4.3. Support Vector Classification with 20 news groups,[0],[0]
The support vector implementation was taken from scikit-learn.,4.3. Support Vector Classification with 20 news groups,[0],[0]
We set this up as a 2 dimensional multi-fidelity problem where we can choose a dataset size N ∈,4.3. Support Vector Classification with 20 news groups,[0],[0]
"[5000, 15000] and the number of training iterations T ∈ [20, 100].",4.3. Support Vector Classification with 20 news groups,[0],[0]
Each evaluation takes the given dataset of size N and splits it up into 5 to perform 5-fold cross validation.,4.3. Support Vector Classification with 20 news groups,[0],[0]
"As the cost function for fidelity selection, we used λ(N,T ) =",4.3. Support Vector Classification with 20 news groups,[0],[0]
"NT as
the training/validation complexity is linear in both parameters.",4.3. Support Vector Classification with 20 news groups,[0],[0]
Our goal is to maximise the cross validation accuracy at z• =,4.3. Support Vector Classification with 20 news groups,[0],[0]
"[15000, 100].",4.3. Support Vector Classification with 20 news groups,[0],[0]
For the finite fidelity methods we use three fidelities with the approximations available at z =,4.3. Support Vector Classification with 20 news groups,[0],[0]
"[8333, 47] and z =",4.3. Support Vector Classification with 20 news groups,[0],[0]
"[11667, 73].",4.3. Support Vector Classification with 20 news groups,[0],[0]
The results are given in Fig. 4(c) where we plot the average cross validation accuracy against wall clock time.,4.3. Support Vector Classification with 20 news groups,[0],[0]
"We studied Bayesian optimisation with continuous approximations, by treating the approximations as arising out of a continuous fidelity space.",5. Conclusion,[0],[0]
"While previous multi-fidelity literature has predominantly focused on a finite number of approximations, BOCA applies to continuous fidelity spaces and can potentially be extended to arbitrary spaces.",5. Conclusion,[0],[0]
We bound the simple regret for BOCA and demonstrate that it is better than methods such as GP-UCB which ignore the approximations and that the gains are determined by the smoothness of the fidelity space.,5. Conclusion,[0],[0]
"When compared to existing multi-fidelity methods, BOCA is able to share information across fidelities effectively, has more natural modelling assumptions and has fewer hyper-parameters to tune.",5. Conclusion,[0],[0]
"Empirically, we demonstrate that BOCA is competitive with other baselines in synthetic and real problems.",5. Conclusion,[0],[0]
"Another nice feature of using continuous approximations is that it relieves the practitioner from having to design the approximations; she/he can specify the available approximations and let the algorithm decide how to choose them.
",5. Conclusion,[0],[0]
"Going forward, we wish to extend our theoretical results to more general settings.",5. Conclusion,[0],[0]
"For instance, we believe a stronger bound on the regret might be possible if φZ is a finite dimensional kernel.",5. Conclusion,[0],[0]
"Since finite dimensional kernels are typically not radial (Sriperumbudur et al., 2016), our analysis techniques will not carry over straightforwardly.",5. Conclusion,[0],[0]
Another line of work that we have alluded to is to study more general fidelity spaces with an appropriately defined kernel φZ .,5. Conclusion,[0],[0]
We would like to thank Renato Negrinho for reviewing an initial draft of this paper.,Acknowledgements,[0],[0]
This research is supported in part by DOE grant DESC0011114 and NSF grant IIS1563887.,Acknowledgements,[0],[0]
KK is supported by a Facebook Ph.D. fellowship.,Acknowledgements,[0],[0]
"Bandit methods for black-box optimisation, such as Bayesian optimisation, are used in a variety of applications including hyper-parameter tuning and experiment design.",abstractText,[0],[0]
"Recently, multifidelity methods have garnered considerable attention since function evaluations have become increasingly expensive in such applications.",abstractText,[0],[0]
Multifidelity methods use cheap approximations to the function of interest to speed up the overall optimisation process.,abstractText,[0],[0]
"However, most multi-fidelity methods assume only a finite number of approximations.",abstractText,[0],[0]
"On the other hand, in many practical applications, a continuous spectrum of approximations might be available.",abstractText,[0],[0]
"For instance, when tuning an expensive neural network, one might choose to approximate the cross validation performance using less data N and/or few training iterations T .",abstractText,[0],[0]
"Here, the approximations are best viewed as arising out of a continuous two dimensional space (N,T ).",abstractText,[0],[0]
"In this work, we develop a Bayesian optimisation method, BOCA, for this setting.",abstractText,[0],[0]
We characterise its theoretical properties and show that it achieves better regret than than strategies which ignore the approximations.,abstractText,[0],[0]
BOCA outperforms several other baselines in synthetic and real experiments.,abstractText,[0],[0]
Multi-fidelity Bayesian Optimisation with Continuous Approximations,title,[0],[0]
"Motivated by settings such as hyper-parameter tuning and physical simulations, we consider the problem of black-box optimization of a function. Multi-fidelity techniques have become popular for applications where exact function evaluations are expensive, but coarse (biased) approximations are available at much lower cost. A canonical example is that of hyper-parameter selection in a learning algorithm. The learning algorithm can be trained for fewer iterations – this results in a lower cost, but its validation error is only coarsely indicative of the same if the algorithm had been trained till completion. We incorporate the multi-fidelity setup into the powerful framework of black-box optimization through hierarchical partitioning. We develop tree-search based multi-fidelity algorithms with theoretical guarantees on simple regret. We finally demonstrate the performance gains of our algorithms on both real and synthetic datasets.",text,[0],[0]
"Optimizing a black-box function f over a Euclidean domain X is a classical problem studied in several disciplines including computer science, mathematics, and operations research.",1. Introduction,[0],[0]
"It finds applications in many real world scientific and engineering tasks including scientific experimentation, industrial design, and model selection in statistics and machine learning (Martinez-Cantin et al., 2007; Parkinson et al., 2006; Snoek et al., 2012).",1. Introduction,[0],[0]
"Given a budget of n evaluations, an optimization algorithm operates sequentially – at time t, it chooses to evaluate f at xt based on its previous evaluations {xi, f(xi)} t 1 i=1 .",1. Introduction,[0],[0]
"At the end of n evaluations, it makes a recommendation x(n) and its performance is measured by its 1Univerity of Texas as Austin 2Carnegie Mellon University.",1. Introduction,[0],[0]
"Correspondence to: Rajat Sen <rajat.sen@utexas.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"simple regret Rn,
Rn = sup x2X f(x) f(x(n)).
",1. Introduction,[0],[0]
Our study focuses on applications where exact evaluation of the function f is expensive.,1. Introduction,[0],[0]
"As an example, in the case of model selection, training and validating large neural networks can take several hours to days.",1. Introduction,[0],[0]
"Similarly, the simulation of an astrophysical process typically takes multiple days even on a cluster of super computers.",1. Introduction,[0],[0]
Traditional methods for black-box optimization are poorly suited for such applications because we need to invest a considerable number of evaluations to optimize f .,1. Introduction,[0],[0]
"This motivates studying the multi-fidelity setting where we have cheaper, but potentially biased approximations to the function (Cutler et al., 2014; Huang et al., 2006a; Kandasamy et al., 2016c; 2017).",1. Introduction,[0],[0]
"As an illustration, in a hyper-parameter tuning scenario, the task is to find the best set of hyper-parameters for training a machine learning model.",1. Introduction,[0],[0]
"In this setting, the black-box function that needs to be optimized is the validation error after training the learning algorithm to completion (a certain number of maximum iterations)",1. Introduction,[0],[0]
i.e X represents the allowed set of hyper-parameters while the function represents the validation error after training to completion.,1. Introduction,[0],[0]
"However, as training the algorithm till completion is expensive, we may choose to train the learning algorithm for a few iterations at chosen hyper-parameters and then test it on the validation set.",1. Introduction,[0],[0]
"These inexpensive validation errors act as the cheap approximations (fidelities) to the function value and can indeed provide valuable information regarding the quality of the hyper-parameters.
",1. Introduction,[0],[0]
"The multi-fidelity setup for black-box function optimization has been popularly studied in the Bayesian optimization setting (Huang et al., 2006b; Kandasamy et al., 2016b; 2017).",1. Introduction,[0],[0]
"However, in this paper we focus on another powerful framework for sequential black-box optimization that works with hierarchical partitioning of the function domain X .",1. Introduction,[0],[0]
"These tree-search based methods were initially motivated by an empirically successful heuristic UCT (Kocsis & Szepesvári, 2006), which subsequently lead to several theoretically founded algorithms for black-box optimization through hierarchical partitioning (Bubeck et al., 2011; Kleinberg et al., 2008; Munos, 2011; Valko et al., 2013).
",1. Introduction,[0],[0]
"In this work, we incorporate cheap approximations or fideli-
ties with tree-search based methods for black-box optimization.",1. Introduction,[0],[0]
"We assume access to a tree-like partitioning of the domain X similar to (Bubeck et al., 2011; Grill et al., 2015; Munos, 2011).",1. Introduction,[0],[0]
"The partitioning of the domain X is denoted as P and it contains hierarchical cells {Ph,i}, where h denotes the height of the cell and i denotes the index.",1. Introduction,[0],[0]
"A cell Ph,i at height h has K children {Ph+1,ik}Kk=1, which are distinct partitions of Ph,i. At height 0, there is only one partition P0,1 = X .",1. Introduction,[0],[0]
An example of such an hierarchical partition for X =,1. Introduction,[0],[0]
"[0, 1] and K = 2 would be:",1. Introduction,[0],[0]
"P0,1 =",1. Introduction,[0],[0]
"[0, 1], P1,1,P1,2 =",1. Introduction,[0],[0]
"[0, 0.5], (0.5, 1], P2,1 =",1. Introduction,[0],[0]
"[0, 0.25]... and so on.",1. Introduction,[0],[0]
Most of the prior work assume some smoothness property about the function and hierarchical partitioning.,1. Introduction,[0],[0]
"We follow a similar path adopting the smoothness assumptions in (Grill et al., 2015).",1. Introduction,[0],[0]
"This assumption states that there exists ⌫ and ⇢ 2 (0, 1) such that,
8h 0, 8x 2",1. Introduction,[0],[0]
"Ph,i⇤h , f(x) f(x ⇤) ⌫⇢h, (1)
where x⇤ is assumed to be the unique point in X such that f(x⇤) = supx2X f(x).",1. Introduction,[0],[0]
"This assumption basically says that the diameter of the function is bounded for all cells that contain the optima, and that this diameter goes down at a geometric rate with the height of the cell.",1. Introduction,[0],[0]
"We also adopt the definition of the well-known near-optimality dimension d(⌫, ⇢) which restricts the number of cells at height h that contain points close to the optima.",1. Introduction,[0],[0]
"This is an important quantity in the analysis of many tree-search based methods (Bubeck et al., 2011; Grill et al., 2015; Munos, 2011; Valko et al., 2013).
",1. Introduction,[0],[0]
In addition we also model that the function can be accessed at a continuous range of fidelities within Z =,1. Introduction,[0],[0]
"[0, 1],",1. Introduction,[0],[0]
where z = 0 is the cheapest fidelity and z = 1 is the most expensive one.,1. Introduction,[0],[0]
"For instance, in our hyper-parameter tuning example, z = 1 may correspond to training the learning algorithm for 1000 iterations while z = 0 represents training the algorithm to 50 iterations.",1. Introduction,[0],[0]
"When a function is evaluated at a point x 2 X with a fidelity z 2 Z , a value fz(x) is revealed such that |f(x) fz(x)| < ⇣(z) where ⇣(.) is a fixed bias function.",1. Introduction,[0],[0]
The bias function is monotonically decreasing in z with ⇣(1) = 0.,1. Introduction,[0],[0]
There is also a cost associated with these evaluations which is captured by a cost function : Z !,1. Introduction,[0],[0]
R+.,1. Introduction,[0],[0]
The cost function is assumed to be monotonically increasing in z.,1. Introduction,[0],[0]
"For instance, in hyper-parameter tuning the cost increases linearly with the number of iterations.",1. Introduction,[0],[0]
"The objective is to locate a point x such that f(x) is as close as possible to supx2X f(x) given a finite cost budget ⇤.
",1. Introduction,[0],[0]
"The following are the main contributions of this work:
(i)",1. Introduction,[0],[0]
We incorporate multiple fidelities/cheap approximations in black-box function optimization through hierarchical partitioning.,1. Introduction,[0],[0]
We propose and analyze two algorithms in this setting.,1. Introduction,[0],[0]
"Our first algorithm is known as MFDOO (Algorithm 1) which requires knowledge about the smoothness
parameter (⌫, ⇢).",1. Introduction,[0],[0]
"This algorithm is similar to DOO (Munos, 2011), however it is designed to explore coarser partitions at lower fidelities while exploring finer partitions at higher fidelities, when the algorithm zooms in on a promising area of the function domain.",1. Introduction,[0],[0]
"Motivated by recent work (Grill et al., 2015), we also propose a second algorithm MFPDOO (Algorithm 2), which does not require knowledge about the smoothness.",1. Introduction,[0],[0]
"This algorithm spawns several instances of MFDOO (Algorithm 1) with carefully selected parameters, at least one of which is bound to perform nearly as well as MFDOO when the smoothness parameters are known.
",1. Introduction,[0],[0]
"(ii) We provide simple regret bounds for both of our algorithms, given a fixed cost budget ⇤ for performing evaluations.",1. Introduction,[0],[0]
"First we show that when the smoothness parameters are known, MFDOO has simple regret of O(⇤ 1/d(⌫,⇢)+1) under some conditions on the bias and cost function.",1. Introduction,[0],[0]
"Here, d(⌫, ⇢) is the near-optimality dimension of the function with respect to parameters (⌫, ⇢).",1. Introduction,[0],[0]
"On the other hand a naive application of DOO (Munos, 2011)1 only using the highest fidelity z = 1 would yield a regret bound of O((⇤/ (1)) 1/d(⌫,⇢)).",1. Introduction,[0],[0]
"We also show that our second algorithm MFPDOO can obtain a simple regret bound of O((⇤/ log⇤) 1/d(⌫,⇢)+1) even when the smoothness parameters are not known.",1. Introduction,[0],[0]
"The precise details about our theoretical guarantees can be found in Section 5.
(iii) Finally, we compare the performance of our algorithms with several state of the art algorithms (Grill et al., 2015; Huang et al., 2006b; Jones et al., 1998; Kandasamy et al., 2016b;b; Srinivas et al., 2009) for black-box optimization in the multi-fidelity setting, on real and synthetic data-sets.",1. Introduction,[0],[0]
We demonstrate that our algorithms outperform the state of the art in most of these experiments.,1. Introduction,[0],[0]
"We build on a line of work on bandits and black-box optimization with hierarchical partitions (Bubeck et al., 2011; Kleinberg et al., 2008; Munos, 2011; Valko et al., 2013).",2. Related Work,[0],[0]
"These methods rely on the principle of optimism i.e they build upper bounds on the value of the functions inside different partitions using the already explored points x1..., xt.",2. Related Work,[0],[0]
"Then at time t+ 1, a point is chosen from the partition that has the highest value of this upper-bound.",2. Related Work,[0],[0]
"We closely follow the line of work initiated in (Munos, 2011) that was later extended to noisy function evaluations in (Grill et al., 2015; Valko et al., 2013).",2. Related Work,[0],[0]
"In (Munos, 2011) it was assumed that the function follows a local Lipschitz condition with respect to a semi-metric `, and the diameter of the hierarchical partitions with respect to this semi-metric decrease geometrically with height.",2. Related Work,[0],[0]
"Grill et al. (Grill et al., 2015) later merged these
1Note that DOO also requires knowledge of the smoothness parameters of the function.
",2. Related Work,[0],[0]
"two assumptions into one, by having a single condition that related the smoothness of the function with the hierarchical partition.",2. Related Work,[0],[0]
"In this work we adapt the regime of (Grill et al., 2015).",2. Related Work,[0],[0]
"However, we also model cheap approximations to the functions through a one-dimensional fidelity space.
",2. Related Work,[0],[0]
"Multi-fidelity optimization has had a rich history in many settings (Agarwal et al., 2011; Forrester et al., 2007; Huang et al., 2006a; Klein et al., 2016; Lam et al., 2015; Li et al., 2016; Poloczek et al., 2016; Sabharwal et al., 2015; Zhang & Chaudhuri, 2015), with those that are not applicationspecific focusing on a Bayesian framework without formal guarantees (we refer to (Kandasamy et al., 2017) for additional discussion).",2. Related Work,[0],[0]
Kandasamy et al. (2016c) propose and analyse a UCB style multi-fidelity algorithm for the K-armed bandit setting assuming a finite number of approximations to the K arms.,2. Related Work,[0],[0]
"They then extend this work to develop UCB algorithms for black-box optimization under Bayesian Gaussian process assumptions on f , both with a finite number of approximations and a continuous spectrum of approximations (Kandasamy et al., 2016a;b; 2017).",2. Related Work,[0],[0]
"In all these works, the relation between the approximations and the true function is known and appears in the form of uniform bounds on the approximation or a smoothness assumption arising out of the kernel of the Gaussian process.",2. Related Work,[0],[0]
In our work we merge the multi-fidelity setting with the hierarchical partitions framework.,2. Related Work,[0],[0]
We consider the problem of optimizing a function f : X !,3. Problem Setting,[0],[0]
R with black-box access at different fidelities.,3. Problem Setting,[0],[0]
"The aim is to locate a point x such that f(x) is as close as possible to supx2X f(x), given a finite budget for performing evaluations.
",3. Problem Setting,[0],[0]
"We assume that the function can be queried at a continuous range of fidelities in Z , [0, 1].",3. Problem Setting,[0],[0]
"When the function is queried at a point x 2 X with fidelity z 2 Z , a value fz(x) is revealed.",3. Problem Setting,[0],[0]
"We assume that |fz(x) f(x)|  ⇣(z), where ⇣ : Z ! R+ is a known bias function.",3. Problem Setting,[0],[0]
"It is also assumed that a single query at fidelity z incurs a cost (z), where : Z !",3. Problem Setting,[0],[0]
R+ is a known cost function.,3. Problem Setting,[0],[0]
"We assume there is a unique point x⇤ 2 X at which supx2X f(x) is achieved.
",3. Problem Setting,[0],[0]
Bias and Cost Functions: The bias function ⇣ is assumed to be bounded and monotonically decreasing in z.,3. Problem Setting,[0],[0]
The optimal fidelity z is assumed to have zero bias i.e. ⇣(1) = 0.,3. Problem Setting,[0],[0]
"The cost function is assumed to be bounded and monotonically increasing in z.
The multi-fidelity setting is motivated by engineering applications where cheap approximations are available.",3. Problem Setting,[0],[0]
"One promising use case is that of hyper-parameter tuning, where the validation performance of a learning algorithm at different hyper-parameters can be observed.",3. Problem Setting,[0],[0]
"The aim is to locate
the best hyper-parameter.",3. Problem Setting,[0],[0]
"In such a setting, cheap approximations are available for instance instead of evaluating the learning algorithm after a maximum of T iterations, one may choose to evaluate it after t < T iterations.",3. Problem Setting,[0],[0]
In this case T can be mapped to z = 1,3. Problem Setting,[0],[0]
and t can be mapped to a z < 1.,3. Problem Setting,[0],[0]
The cost function in this setting is proportional to the O(t) computation required.,3. Problem Setting,[0],[0]
"The bias function is monotonically decreasing with z, however may not be known exactly in practice.",3. Problem Setting,[0],[0]
"However, prior works in multi-fidelity setup (Kandasamy et al., 2016a;c; Kleinberg et al., 2008) have all assumed access to a known bias function for the theoretical guarantees.",3. Problem Setting,[0],[0]
"Even though we assume the bias function is known in theory, we shall see in our experiments in Section 6 that a simple parametric form of the bias function can be assumed and the parameters can be updated online during the course of our algorithm (similar to (Kandasamy et al., 2017)).
",3. Problem Setting,[0],[0]
Simple Regret:,3. Problem Setting,[0],[0]
The objective is to locate a point x such that f(x) is as close as possible to supx2X f(x) given a finite cost budget.,3. Problem Setting,[0],[0]
Let ⇤ be the total cost budget allowed.,3. Problem Setting,[0],[0]
"Consider an optimization policy that queries a sequence of points {x1, ..., xn(⇤)} at fidelities {z1, ..., zn(⇤)} respectively and finally returns a recommendation x⇤.",3. Problem Setting,[0],[0]
"Our main quantity of interest is the simple regret which is defined as,
R⇤ = sup x2X f(x) f (x⇤) , (2)
such that Pn(⇤)
i=1",3. Problem Setting,[0],[0]
(zi)  ⇤.,3. Problem Setting,[0],[0]
Note that the simple regret is always measured at the highest fidelity as we are only interested in optimizing the actual function.,3. Problem Setting,[0],[0]
"In this section we define the hierarchical partitions of the domain X that we assume access to and then provide our technical assumptions about the function and the hierarchical partitions.
Hierarchical Partitions: We assume access to a tree-like hierarchical partitioning P = {Ph,i} of the domain X , where, h denotes a depth parameter.",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"For any depth h 0, the cells {Ph,i}1iIh denote a partitioning of the space X , where Ih is the number of cells at depth h. At depth 0",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"there is a single cell P0,1 = X .",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"A cell Ph,i can be split into K child nodes at depth h + 1.",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"In what follows, querying a cell Ph,i would refer to evaluating the function at a fixed representative point xh,i 2 Ph,i at a chosen fidelity.",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"The fixed representative point is usually chosen to be the coordinate wise mid-point for any given cell.
",3.1. Hierarchical Partitions and Assumptions,[0],[0]
As an illustrative example let us consider a hierarchical black-box optimization problem over the domain X =,3.1. Hierarchical Partitions and Assumptions,[0],[0]
"[0, 1] ⇥",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"[0, 1].",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"Let us consider a hierarchical partition of this domain where the cells are of the form {x 2 X : b1,1  x1 < b1,2, b2,1  ",3.1. Hierarchical Partitions and Assumptions,[0],[0]
x2 <,3.1. Hierarchical Partitions and Assumptions,[0],[0]
"b2,2}.",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"Such a
cell will be denoted by the notation",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"[[b1,1, b1,2], [b2,1, b2,2]].",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"Then a hierarchical partition with K = 2 starts with the root node P0,1 =",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"[[0, 1], [0, 1]].",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"This can be further sub-divided into children cells at h = 1 given by P1,1 =",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"[[0, 0.5], [0, 1]] and P1,2 =",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"[[0.5, 1], [0, 1]].",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"P1,2 can be further partitioned into P2,1 =",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"[[0.5, 1], [0, 0.5]] and P2,2 =",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"[[0.5, 1], [0.5, 1]] and so on.",3.1. Hierarchical Partitions and Assumptions,[0],[0]
The fixed representative point for a cell,3.1. Hierarchical Partitions and Assumptions,[0],[0]
"[[b1,1, b1,2], [b2,1, b2,2]] is chosen as the point [(b1,1 + b1,2)/2, (b2,1 + b2,2)/2].
",3.1. Hierarchical Partitions and Assumptions,[0],[0]
Black-box optimization is akin to a needle in a haystack problem without any conditions on the function f(x).,3.1. Hierarchical Partitions and Assumptions,[0],[0]
"Therefore, similar to prior work (Grill et al., 2015) we make the following smoothness assumption which depends on the properties of both the function f and the hierarchical partitioning P .",3.1. Hierarchical Partitions and Assumptions,[0],[0]
Assumption 1 (Smoothness Decay).,3.1. Hierarchical Partitions and Assumptions,[0],[0]
"There exists ⌫ and ⇢ 2 (0, 1) such that,
8h 0, 8x 2",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"Ph,i⇤h , f(x) f(x ⇤) ⌫⇢h, (3)
where Ph,i⇤h is the unique partition of height h which contains x⇤.
",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"We also adopt the definition of the near-optimalitydimension for parameters (⌫, ⇢) from (Grill et al., 2015).",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"This is a quantity that depends on the choice of parameters, the partitioning and the function itself.",3.1. Hierarchical Partitions and Assumptions,[0],[0]
Definition 1.,3.1. Hierarchical Partitions and Assumptions,[0],[0]
"The near-optimality dimension of f with respect to parameters (⌫, ⇢) is given by,
d(⌫, ⇢) , inf d 0 2 R+ : 9C(⌫, ⇢), 8h 0,
Nh(2⌫⇢ h)  ",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"C(⌫, ⇢)⇢",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"d
0h o
(4)
where Nh(✏) is the number of cells",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"Ph,i such that supx2Ph,i f(x) f(x ⇤) ✏.
",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"Let (⌫⇤, ⇢⇤) be the parameters with the minimum near optimality dimension d(⌫⇤, ⇢⇤).
",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"Discussion: Access to hierarchical partitions have been assumed in a string of previous works on black-box optimization (Bubeck et al., 2011; Grill et al., 2015; Kleinberg et al., 2008; Munos, 2011; Slivkins, 2011; Valko et al., 2013).",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"Many of these prior works assume a semi-metric ` over the domain X (Bubeck et al., 2011; Munos, 2011; Valko et al., 2013).",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"In (Bubeck et al., 2011), it is assumed that the function satisfies a weak-Lipschitzness condition.",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"More recent works (Munos, 2011; Valko et al., 2013) have assumed a local-smoothness property w.r.t the metric given by 8x 2 X , f(x⇤) f(x)  ",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"`(x, x⇤).",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"However, recently Grill et al. (Grill et al., 2015) have observed that Assumption 1 is sufficient to combine several assumptions about the semi-metric, the function and the hierarchical partitions into one combinatorial condition and similarly have adapted
the definition of the near-optimality dimension without the semi-metric.",3.1. Hierarchical Partitions and Assumptions,[0],[0]
"It was depicted in (Grill et al., 2015) that prior algorithms like (Bubeck et al., 2011; Munos, 2011; Valko et al., 2013) can be shown to have good regret guarantees with this new set of assumptions, and therefore we adopt these assumptions in our work.",3.1. Hierarchical Partitions and Assumptions,[0],[0]
In this section we present two algorithms for black-box optimization using different fidelities and the hierarchical partitioning provided.,4. Algorithms,[0],[0]
"In Section 4.1, we provide Algorithm 1 which requires the knowledge of the optimal smoothness decay parameters (⌫⇤, ⇢⇤).",4. Algorithms,[0],[0]
"Then in Section 4.2, we provide Algorithm 2 that searches for the optimal smoothness by spawning O(log⇤) instances of Algorithm 1 with a carefully designed sequence of smoothness parameters (⌫, ⇢) as arguments.",4. Algorithms,[0],[0]
"In this section we provide an algorithm which takes as an argument the smoothness parameters (⌫, ⇢).","4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
"We show in Section 5 that if the parameters provided match with the optimal parameters (⌫⇤, ⇢⇤) then the algorithm enjoys strong theoretical guarantees under some conditions on the bias and cost functions ⇣(z) and (z) respectively.
","4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
"Algorithm 1 MFDOO: Multi-Fidelity Deterministic Optimistic Optimization
1: Arguments: (⌫, ⇢), ⇣(z), (z), P , ⇤ 2: Define zh = ⇣ 1(⌫⇢h) 3: Let T = {(0, 1)} be the tree initialized (root node
evaluated with fidelity z0).","4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
Set of leaves at time t: Lt. 4: Time: t = 1; Cost: C = (z0).,"4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
"5: while C  ⇤ do 6: Select the leaf (h, j) 2 Lt with maximum bh,j ,
fzh(xh,j) + ⌫⇢ h + ⇣(zh).
7: Expand this node; add to Tt the K children of (h, j).","4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
8: Evaluate the children at the fidelity level zh+1.,"4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
t =,"4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
t+ 1. C = C +K (zh+1).,"4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
9: end while 10: Let h(⇤) be the height of the tree.,"4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
"Return x⇤ = argmax(h(⇤),i)","4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
"fzh(⇤)(xh(⇤),i).
","4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
"In Algorithm 1, with some abuse of notation we define for all h 0, zh = ⇣ 1(⌫⇢h) i.e the fidelity at which the bias becomes less than or equal to the smoothness decay parameter at height h.","4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
All cells at height h are evaluated at the fidelity zh.,"4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
"The intuition is that if x⇤ belongs to a cell Ph,i⇤ at height h that has been evaluated, then by Assumption 1 we have that all points in the cell are at least ⌫⇢
h optimal.","4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
"Ideally, beyond this point we would only like to expand leaf nodes that are at least O(⌫⇢h) optimal,
which can only be achieved if the error due to the fidelities is O(⌫⇢h).","4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
"At each step, a leaf node with the highest upper bound parameter bh,i, is expanded and the children cells are evaluated.","4.1. Algorithm with known (⌫⇤, ⇢⇤)",[0],[0]
"In this section we describe an algorithm that does not require the optimal parameters (⌫⇤, ⇢⇤).","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"Algorithm 2 just requires ⇢max, ⌫max which are loose upper-bounds of ⇢⇤ and ⌫⇤ respectively.","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"The algorithm proceeds by spawning O(log⇤) MFDOO instances with different (⌫, ⇢)’s which have been carefully designed.","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"Similar ideas were explored in a setting without fidelities in (Grill et al., 2015).","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"In Section 5, we show that Algorithm 2 does almost as well as Algorithm 1 without requiring the optimal parameters as input.
","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
Algorithm 2,"4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"MFPDOO: Multi-Fidelity Parallel Deterministic Optimistic Optimization
1: Arguments: (⌫max, ⇢max), ⇣(z), (z), P , ⇤ 2: Let N = (1/2)Dmax log(⇤/ log(⇤)) where Dmax =
logK/ log(1/⇢max) 3: for i = 0 to N 1 do 4: Spawn MFDOO (Algorithm 1) with parameters
(⌫max, ⇢ N/(N","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"i) max ) with budget (⇤ N (1))/N
5: end for 6: Let x(i)⇤ be the point returned by the i
th MFDOO instance for i 2 {0, .., N 1}.","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
Evaluate all {x(i)⇤ }i at the z = 1.,"4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"Return the point x⇤ = x (i⇤) ⇤ where i ⇤ = argmaxi f(x (i) ⇤ ).
","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
Algorithm 2 proceeds by spawning N different MFDOO instances with the parameters specified in step 4 of the algorithm.,"4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"We will show in Theorem 2 that at least one of the MFDOO instances will have a performance comparable to Algorithm 1 supplied with parameters (⌫⇤, ⇢⇤) with a budget of O(⇤/N).","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"Step 6 of the algorithm obtains the exact value of the points returned by all the MFDOO instances by evaluating them at the highest fidelity, and then chooses the one with the maximum value.","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"This ensures that the highest performing MFDOO instance is selected.
","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
Remark 1.,"4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
Our algorithms and the theoretical results assume that the bias function ⇣(.) is known.,"4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"However, in practice we do not assume perfect knowledge about the bias function.","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"We assume a simple parametric form of the bias function and update the parameters online, when the bias assumptions are violated.","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"We provide more details in Section 6 and show that even without this knowledge, the algorithms perform better than other benchmarks.
","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"It should be noted that the different MFDOO instances created by Algorithm 2 can share information among each other, when multiple instances query the same partition at
very similar fidelities.","4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
This leads to huge improvements in practice in terms of effectively using the cost budget.,"4.2. Algorithm without the knowledge of (⌫⇤, ⇢⇤)",[0],[0]
"In this section we first prove a general result about the simple regret of Algorithm 1 which assumes access to the optimal parameters (⌫, ⇢).",5. Theoretical Results,[0],[0]
"This naturally implies a simple regret bound on Algorithm 1 when it is supplied with the parameters (⌫⇤, ⇢⇤) i.e. the ones that have the minimum near-optimality dimension.",5. Theoretical Results,[0],[0]
Then we refine these guarantees under some natural conditions on the bias and cost functions.,5. Theoretical Results,[0],[0]
"Finally, we show that Algorithm 2 can achieve guarantees close to Algorithm 1 with the optimal parameters, without having access to them.
",5. Theoretical Results,[0],[0]
"We first present the following general result about Algorithm 1.
Theorem 1.",5. Theoretical Results,[0],[0]
"Let h0 be the biggest number h such
hX
l=0
C(⌫, ⇢)K (zl)⇢ d(⌫,⇢)l  ",5. Theoretical Results,[0],[0]
"⇤.
",5. Theoretical Results,[0],[0]
Let h(⇤) = h0 + 1.,5. Theoretical Results,[0],[0]
"Then Algorithm 1 run with parameters (⌫, ⇢) (s.t ⌫ ⌫⇤, ⇢ ⇢⇤), incurs a simple regret of at most 2⌫⇢h(⇤) and terminates using a total cost of at most ⇤+K (1).
",5. Theoretical Results,[0],[0]
We defer the proof of Theorem 1 to Section A in the appendix.,5. Theoretical Results,[0],[0]
"Note that the guarantee in Theorem 1 is the tightest when the parameters (⌫⇤, ⇢⇤) are supplied as the near optimality dimension d(⌫⇤, ⇢⇤) is the lowest.
",5. Theoretical Results,[0],[0]
"Now, we impose some natural conditions on the cost and bias functions.",5. Theoretical Results,[0],[0]
"We provide more specialized versions of the guarantees in Theorem 1 under these two conditions separately, which are described below.
Assumption 2.",5. Theoretical Results,[0],[0]
We assume that ⇣(.),5. Theoretical Results,[0],[0]
"and (.) are such that (z⇤h)  min{ h,⇤(1)} for some positive constant .",5. Theoretical Results,[0],[0]
"Here, z⇤h = ⇣ 1(⌫⇤⇢h⇤).
",5. Theoretical Results,[0],[0]
Motivation: The above assumption is motivated by the following hyper-parameter tuning scenario.,5. Theoretical Results,[0],[0]
Consider training a learning algorithm with a particular hyper-parameter that involves optimizing a strongly convex and smooth function with gradient descent.,5. Theoretical Results,[0],[0]
Let the fidelity denote a rescaled version of the number of steps in gradient descent n.,5. Theoretical Results,[0],[0]
We assume that at the optimal fidelity (N steps) we reach the optimal value of the function up to an error of ✏⇤.,5. Theoretical Results,[0],[0]
Let zn = n/N .,5. Theoretical Results,[0],[0]
"At fidelity zn the error decays to ⇣(zn) = O(rn) for some r 2 (0, 1).",5. Theoretical Results,[0],[0]
The cost incurred is linear in the number of steps say (zn) =,5. Theoretical Results,[0],[0]
sn for s > 0.,5. Theoretical Results,[0],[0]
"In this setting it can be shown that if ⇣(zn) ⇠ ⌫⇤⇢h⇤ , then n = O(h) and therefore (zn) = O(h).
",5. Theoretical Results,[0],[0]
"The second assumption under which we provide specialized guarantees is as follows.
",5. Theoretical Results,[0],[0]
Assumption 3.,5. Theoretical Results,[0],[0]
We assume that ⇣(.),5. Theoretical Results,[0],[0]
"and (.) are such that (z⇤h)  min{ h ,⇤(1)} for some constant 2 (⇢, 1).",5. Theoretical Results,[0],[0]
"Here, z⇤h = ⇣ 1(⌫⇤⇢h⇤).
",5. Theoretical Results,[0],[0]
Motivation: Assumption 3 is motivated by a similar hyperparameter tuning scenario as above.,5. Theoretical Results,[0],[0]
Consider training a learning algorithm with a particular hyper-parameter that involves optimizing a smooth convex function with accelerated gradient descent.,5. Theoretical Results,[0],[0]
Let the fidelity denote a rescaled version of the number of steps in gradient descent n as above.,5. Theoretical Results,[0],[0]
At fidelity zn the error decays to ⇣(zn) = O(1/n2).,5. Theoretical Results,[0],[0]
The cost incurred is linear in the number of steps say (zn) =,5. Theoretical Results,[0],[0]
sn for s > 0.,5. Theoretical Results,[0],[0]
"In this setting it can be shown that if ⇣(zn) ⇠ ⌫⇤⇢h⇤ , then n = O( h) for = O( p ⇢).
",5. Theoretical Results,[0],[0]
"We are now at a position to introduce a specialized corollary of Theorem 1.
",5. Theoretical Results,[0],[0]
Corollary 1.,5. Theoretical Results,[0],[0]
"Algorithm 1 with parameters (⌫, ⇢) (s.t ⌫ ⌫⇤, ⇢ ⇢⇤) run with a total budget of ⇤ terminates with a total cost of at most ⇤ + K (1) and has the following properties: (i)",5. Theoretical Results,[0],[0]
Under Assumption 2: R⇤  2⌫ ⇣,5. Theoretical Results,[0],[0]
"C(⌫,⇢)K ⇤(1 ⇢d(⌫,⇢))",5. Theoretical Results,[0],[0]
"⌘ 1 d(⌫,⇢)+✏ for some small ✏ > 0, provided ⇤ is large enough.
",5. Theoretical Results,[0],[0]
"(ii) Under Assumption 3:
R⇤  2 ⌫ ⇢
⇣ 2C(⌫,⇢)K
⇤( 1⇢ d(⌫,⇢) 1)
⌘ 1 d(⌫,⇢)+1
.
",5. Theoretical Results,[0],[0]
"Comparison with DOO (Munos, 2011):",5. Theoretical Results,[0],[0]
"The above result can be directly compared to DOO (Munos, 2011) which is in the noiseless black-box optimization regime, without access to fidelities.",5. Theoretical Results,[0],[0]
"The simple regret of DOO under the same assumptions would scale as O ⇣ (⇤/ (1)) 1/d(⌫⇤,⇢⇤) ⌘
when all the evaluations are performed at the highest fidelity.",5. Theoretical Results,[0],[0]
"In contrast our bounds under Assumption 2 scales as O ⇣ (⇤/ ) 1/(d(⌫⇤,⇢⇤)+✏) ⌘ , where ✏ is a constant close
to zero.",5. Theoretical Results,[0],[0]
"Note that (z⇤h)  (1), and therefore = (1) trivially satisfies the inequality in Assumption 2.",5. Theoretical Results,[0],[0]
"Typically, is expected to be much less as compared to the highest fidelity cost (1).",5. Theoretical Results,[0],[0]
"For example in our hyper-parameter tuning example where the fidelity is the number of iterations (a maximum of N iterations), is a small constant (see the discussion on Assumption 2), while (1) can be O(N).",5. Theoretical Results,[0],[0]
This can lead to significant gains in simple regret as we show in our empirical results in Section 6.,5. Theoretical Results,[0],[0]
"Similarly, under Assumption 3 our simple regret scales as O ⇤ 1/(d(⌫⇤,⇢⇤)+1) , which can be much better than that of DOO (Munos, 2011) as the total budget is not divided by (1).
",5. Theoretical Results,[0],[0]
"Now, we will provide one of our main results which states that Algorithm 2 can recover simple regret bounds which
are close to that of Algorithm 1 even when the optimal smoothness parameters are not known.
",5. Theoretical Results,[0],[0]
Theorem 2.,5. Theoretical Results,[0],[0]
"Algorithm 2 when run with upper-bounds ⌫max and ⇢max with a total cost budget of ⇤ terminates after using up a cost of at most ⇤+O(K (1) log⇤) and has the following regret guarantees:
(i)",5. Theoretical Results,[0],[0]
"Under Assumption 2 the simple regret is O ⇣ (⌫max/⌫⇤) Dmax ✏+d(⌫⇤,⇢⇤)⇥",5. Theoretical Results,[0],[0]
"⇣ 2⇤
K Dmax log(⇤/ log⇤)
(1) K
⌘ 1✏+d(⌫⇤,⇢⇤) ◆
(ii)",5. Theoretical Results,[0],[0]
"Under Assumption 3 if ⇢max the simple regret is O ⇣ (⌫max/⌫⇤) 2Dmax 1+d(⌫⇤,⇢⇤)⇥",5. Theoretical Results,[0],[0]
"⇣ 2⇤
KDmax log(⇤/ log⇤)
(1) K
⌘ 11+d(⌫⇤,⇢⇤) ◆
.
",5. Theoretical Results,[0],[0]
"We defer the proof of this theorem to Appendix C.
Comparison with POO (Grill et al., 2015):",5. Theoretical Results,[0],[0]
"It is worthwhile to compare our result with that of POO (Grill et al., 2015) which uses only the highest fidelity.",5. Theoretical Results,[0],[0]
"It should be noted that POO is in a noisy setting, which gives rise to extra polylog factors in the bounds.",5. Theoretical Results,[0],[0]
"However, ignoring polylog factors the simple regret bound of POO would scale as O (⇤/(log(⇤/ (1))",5. Theoretical Results,[0],[0]
⇤ (1))),5. Theoretical Results,[0],[0]
"1/(d(⌫⇤,⇢⇤)+2) .",5. Theoretical Results,[0],[0]
In contrast our bounds scale as O ⇣ (⇤/( log(⇤))),5. Theoretical Results,[0],[0]
"1/(d(⌫⇤,⇢⇤)+✏) ⌘
and O (⇤/ log(⇤))",5. Theoretical Results,[0],[0]
"1/(d(⌫⇤,⇢⇤)+1) under assumptions 2 and 3 respectively.",5. Theoretical Results,[0],[0]
This can lead to much better performance at the same cost budget.,5. Theoretical Results,[0],[0]
We demonstrate this in our empirical results in Section 6.,5. Theoretical Results,[0],[0]
In this section we provide empirical results on synthetic and real datasets.,6. Empirical Results,[0],[0]
"We compare our algorithm with the following related works: (i) BOCA (Kandasamy et al., 2017) which is a multi-fidelity Gaussian Process (GP) based algorithm that can handle continuous fidelity spaces, (ii) MFGP-UCB (Kandasamy et al., 2016c) which is a GP based multi-fidelity method that can handle finite fidelities, (iii) GP-EI criterion in bayesian optimization (Jones et al., 1998), (iv) MF-SKO, the multi-fidelity sequential kriging optimisation method (Huang et al., 2006b), (v) GP-UCB (Srinivas et al., 2009) and (vi) MFPDOO(z = 1) which is a version of our algorithm that uses only the highest fidelity; this is very similar to POO (Grill et al., 2015) but in a noiseless setting.",6. Empirical Results,[0],[0]
"This algorithm is referred to as PDOO in the figures, which is essentially DOO (Munos, 2011) with the smoothness parameters tuned according to the scheme in POO (Grill et al., 2015).
",6. Empirical Results,[0],[0]
For our theoretical guarantees the bias function ⇣ is assumed to be known.,6. Empirical Results,[0],[0]
"However, in practice we assume a parametric
form for the bias function that is ⇣(z) = c(1 z) where c is initially set to a very small constant like 0.001 in our experiments.",6. Empirical Results,[0],[0]
The nature of Algorithm 2 is such that the same cells are queried at different fidelities by the different MFDOO instances spawned.,6. Empirical Results,[0],[0]
"If a cell is queried at two different fidelities z1 and z2 and the function values obtained are f1 and f2, then we update c to 2c whenever c|z1 z2| < |f1 f2|.",6. Empirical Results,[0],[0]
The above update is only performed if |z1 z2| is greater than a specified threshold (0.0001 in our experiments).,6. Empirical Results,[0],[0]
"The hierarchical partitioning is performed according to a scheme similar to that of the DIRECT algorithm (Finkel, 2003), where each time a cell is split into K children the dimension that has the biggest width is split into K regions.",6. Empirical Results,[0],[0]
We set K = 2 in all our experiments.,6. Empirical Results,[0],[0]
"Now, we will present the results of our synthetic experiments.
",6. Empirical Results,[0],[0]
Our implementation can be found at https://github.com/rajatsen91/MFTREE DET.,6. Empirical Results,[0],[0]
We evaluate all the algorithms on standard benchmark functions used in global optimization.,6.1. Synthetic Experiments,[0],[0]
The functions have been modified to incorporate the fidelity space Z =,6.1. Synthetic Experiments,[0],[0]
"[0, 1].",6.1. Synthetic Experiments,[0],[0]
"The setup followed is identical to the one in (Kandasamy et al., 2017), except that we only work in a one dimensional fidelity space.",6.1. Synthetic Experiments,[0],[0]
"Also, we perform our experiments in a noiseless setting and therefore no Gaussian noise is added to the function evaluations, unlike in (Kandasamy et al., 2017).",6.1. Synthetic Experiments,[0],[0]
Note that MF-GP-UCB and MF-SKO are finite fidelity methods.,6.1. Synthetic Experiments,[0],[0]
The approximations for these methods are obtained at z = 0.333 and z = 0.667.,6.1. Synthetic Experiments,[0],[0]
"We provide more details about the synthetic functions and the fidelities in Appendix D. Our experiments are performed under the deterministic setting, where no noise is added to the approximations.",6.1. Synthetic Experiments,[0],[0]
"However, several of the algorithms that we compare to have a randomized component.",6.1. Synthetic Experiments,[0],[0]
"For these algorithms, the results are averaged over 10 experiments and the corresponding error bars are shown.",6.1. Synthetic Experiments,[0],[0]
In our algorithm we set the number of MFDOO instances spawned to be N = 0.1Dmax,6.1. Synthetic Experiments,[0],[0]
"log(⇤/ (1)), given
a total budget ⇤.",6.1. Synthetic Experiments,[0],[0]
"We set ⇢max = 0.95 and ⌫max = 2.0.
",6.1. Synthetic Experiments,[0],[0]
"The results of the synthetic experiments are shown in Figure 1(a)-(e), where the title of each figure shows the name of the function, the dimension of the domain (d) and the dimension of the fidelity space (p).",6.1. Synthetic Experiments,[0],[0]
We have p = 1 in all our experiments.,6.1. Synthetic Experiments,[0],[0]
"It can be observed the tree based methods outperform the other algorithms by a large margin, except in the experiments with the CurinExp function (Fig. 1c).",6.1. Synthetic Experiments,[0],[0]
"Tree-based methods can handle higher dimensions better, as we can see in the Hartman6 (Fig. 1b) and Borehole (Fig. 1e) function experiments.",6.1. Synthetic Experiments,[0],[0]
Note that MFPDOO also beats PDOO by a large margin which only uses the highest fidelity.,6.1. Synthetic Experiments,[0],[0]
"PDOO is essentially DOO (Munos, 2011) where the smoothness decay parameters are tuned according to the scheme in (Grill et al., 2015).",6.1. Synthetic Experiments,[0],[0]
"MFPDOO can effectively explore the space at cheaper fidelities and then expend the higher fidelities in promising regions of the domain, unlike PDOO.",6.1. Synthetic Experiments,[0],[0]
In this section we describe our experiments that involve tuning hyper-parameters for text classification.,6.2. Tuning SVM for News Group Classification,[0],[0]
"For this purpose we use a subset of the 20 news group dataset (Joachims, 1996).",6.2. Tuning SVM for News Group Classification,[0],[0]
"All the algorithms are used for tuning two hyperparameters: (i) the regularization penalty and (ii) the temperature of the rbf kernel both in the range of [10 2, 103].",6.2. Tuning SVM for News Group Classification,[0],[0]
"For our experiments, we use the scikit-learn implementation of SVM classifier and also the inbuilt KFold function for crossvalidation.",6.2. Tuning SVM for News Group Classification,[0],[0]
The bag of words in each of the text document is converted into tf-idf features before applying the classification models.,6.2. Tuning SVM for News Group Classification,[0],[0]
"We use a one-dimensional fidelity space, where the fidelity denotes the number of samples used to obtain 5-fold cross-validation accuracy.",6.2. Tuning SVM for News Group Classification,[0],[0]
z = 1 corresponds to 5000 samples which is the maximum number of samples in the subset of the data used.,6.2. Tuning SVM for News Group Classification,[0],[0]
z = 0 corresponds to 100 samples.,6.2. Tuning SVM for News Group Classification,[0],[0]
"Note that for the finite fidelity methods MF-SKO and MF-GP-UCB, approximations are obtained at z = 0.33 and z = 0.667.
",6.2. Tuning SVM for News Group Classification,[0],[0]
For our algorithms we set ⌫max = 1.0 and ⇢max = 0.9.,6.2. Tuning SVM for News Group Classification,[0],[0]
At the beginning of the experiment some of the budget is expended to obtain the function values at a point x with two different fidelities z1 = 0.8 and z2 = 0.2.,6.2. Tuning SVM for News Group Classification,[0],[0]
Thus the total budget spent in the initialization is ⇤(0.8) + (0.2).,6.2. Tuning SVM for News Group Classification,[0],[0]
The function values obtained are then used to initialize c in the bias function ⇣(z) = c(1 z).,6.2. Tuning SVM for News Group Classification,[0],[0]
The initial value of c is set to 2|f1 f2|/|z1 z2|.,6.2. Tuning SVM for News Group Classification,[0],[0]
"Thereafter, c is updated online according to the method detailed above.",6.2. Tuning SVM for News Group Classification,[0],[0]
"We set N = 0.5Dmax log(⇤/ (1)).
",6.2. Tuning SVM for News Group Classification,[0],[0]
The cross-validation accuracy obtained as a function of time is plotted in Fig. 1f for all the candidate algorithms.,6.2. Tuning SVM for News Group Classification,[0],[0]
"It can be observed that MFPDOO outperforms the other algorithms, especially in low-budget settings.",6.2. Tuning SVM for News Group Classification,[0],[0]
We considered the problem of black-box function optimization using hierarchical partitions in the presence of cheap approximations or fidelities.,7. Conclusion,[0],[0]
We propose two tree-search based algorithms which can navigate the domain effectively using cheaper fidelities for coarser partitions and more expensive ones while zeroing in on finer partitions.,7. Conclusion,[0],[0]
We analyze our algorithms under standard smoothness assumptions and provide simple regret guarantees given a cost budget ⇤.,7. Conclusion,[0],[0]
Our simple regret guarantees scale much better with respect to ⇤ as compared to other hierarchical partitioning based algorithms that do not use cheaper fidelities.,7. Conclusion,[0],[0]
"Our first algorithm (MFDOO) requires the knowledge of the smoothness parameters (⌫⇤, ⇢⇤) and has a simple regret bound of O(⇤ 1/(d(⌫⇤,⇢⇤)+1))",7. Conclusion,[0],[0]
"where d(⌫⇤, ⇢⇤) is the near-optimality dimension.",7. Conclusion,[0],[0]
"Our second algorithm (MFPDOO) can obtain a simple regret bound of O((⇤/ log⇤) 1/(d(⌫⇤,⇢⇤)+1))",7. Conclusion,[0],[0]
even when the smoothness parameter are unknown.,7. Conclusion,[0],[0]
"Finally, we empirically validate the performance of our algorithms on real and synthetic datasets, where they outperform the stateof-the art multi-fidelity algorithms.
",7. Conclusion,[0],[0]
This work opens up several interesting research directions.,7. Conclusion,[0],[0]
The theoretical guarantees of our algorithms assume some nice properties about the bias and cost functions.,7. Conclusion,[0],[0]
We believe it is possible to design more robust algorithms that have similar guarantees even for the bias and cost functions that are not well-designed.,7. Conclusion,[0],[0]
Our setting is also restricted to a one dimensional fidelity space.,7. Conclusion,[0],[0]
"However, in many application the fidelity space may be multi-dimensional.",7. Conclusion,[0],[0]
"For instance, in the hyper-parameter tuning one can choose to use less samples or train for lesser iterations.",7. Conclusion,[0],[0]
It is an interesting research direction to incorporate a multi-dimensional fidelity space with tree-search based algorithms.,7. Conclusion,[0],[0]
"Finally, in this work we work in the noise-less setting where the function and the approximations are deterministic.",7. Conclusion,[0],[0]
We believe it is possible to extend our results to a setting where zero-mean noise is added to the function and its approximations.,7. Conclusion,[0],[0]
"This work is partially supported by NSF grant 1320175, ARO grant W911NF-17-1-0359, and the US DoT supported D-STOP Tier 1 University Transportation Center.",Acknowledgment,[0],[0]
"Motivated by settings such as hyper-parameter tuning and physical simulations, we consider the problem of black-box optimization of a function.",abstractText,[0],[0]
"Multi-fidelity techniques have become popular for applications where exact function evaluations are expensive, but coarse (biased) approximations are available at much lower cost.",abstractText,[0],[0]
A canonical example is that of hyper-parameter selection in a learning algorithm.,abstractText,[0],[0]
"The learning algorithm can be trained for fewer iterations – this results in a lower cost, but its validation error is only coarsely indicative of the same if the algorithm had been trained till completion.",abstractText,[0],[0]
We incorporate the multi-fidelity setup into the powerful framework of black-box optimization through hierarchical partitioning.,abstractText,[0],[0]
We develop tree-search based multi-fidelity algorithms with theoretical guarantees on simple regret.,abstractText,[0],[0]
We finally demonstrate the performance gains of our algorithms on both real and synthetic datasets.,abstractText,[0],[0]
Multi-Fidelity Black-Box Optimization with Hierarchical Partitions,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3243–3253 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3243
Multi-hop reasoning is an effective approach for query answering (QA) over incomplete knowledge graphs (KGs). The problem can be formulated in a reinforcement learning (RL) setup, where a policy-based agent sequentially extends its inference path until it reaches a target. However, in an incomplete KG environment, the agent receives low-quality rewards corrupted by false negatives in the training data, which harms generalization at test time. Furthermore, since no golden action sequence is used for training, the agent can be misled by spurious search trajectories that incidentally lead to the correct answer. We propose two modeling advances to address both issues: (1) we reduce the impact of false negative supervision by adopting a pretrained onehop embedding model to estimate the reward of unobserved facts; (2) we counter the sensitivity to spurious paths of on-policy RL by forcing the agent to explore a diverse set of paths using randomly generated edge masks. Our approach significantly improves over existing path-based KGQA models on several benchmark datasets and is comparable or better than embedding-based models.",text,[0],[0]
"Large-scale knowledge graphs (KGs) support a variety of downstream NLP applications such as semantic search (Berant et al., 2013) and dialogue generation (He et al., 2017).",1 Introduction,[0],[0]
"Whether curated automatically or manually, practical KGs often fail to include many relevant facts.",1 Introduction,[0],[0]
"A popular approach for modeling incomplete KGs is knowledge graph embeddings, which map both entities and relations in the KG to a vector space and learn a truth value function for any potential KG triple parameterized by the entity and relation vectors (Yang et al., 2014; Dettmers et al., 2018).
",1 Introduction,[0],[0]
"Embedding based approaches ignore the symbolic compositionality of KG relations, which limit their application in more complex reasoning tasks.",1 Introduction,[0],[0]
"An alternative solution for KG reasoning is to infer missing facts by synthesizing information from multi-hop paths, e.g. bornIn(Obama, Hawaii) ∧ locatedIn(Hawaii, US) ⇒",1 Introduction,[0],[0]
"bornIn(Obama, US), as shown in Figure 1.",1 Introduction,[0],[0]
Path-based reasoning offers logical insights of the underlying KG and are more directly interpretable.,1 Introduction,[0],[0]
"Early work treats it as a link prediction problem and perform maximum-likelihood classification over either discrete path features (Lao et al., 2011, 2012; Gardner et al., 2013) or their hidden representations in a vector space (Guu et al., 2015; Toutanova et al., 2016; McCallum et al., 2017).
",1 Introduction,[0],[0]
"More recent work formulates multi-hop reasoning as a sequential decision problem, and leverages reinforcement learning (RL) to perform effective path search (Xiong et al., 2017; Das et al., 2018; Shen et al., 2018; Chen et al., 2018).",1 Introduction,[0],[0]
"In particular, MINERVA (Das et al., 2018) uses the REINFORCE algorithm (Williams, 1992) to train an end-to-end model for multi-hop KG query answering: given a query relation and a source entity, the trained agent searches over the KG starting from the source and arrives at the candidate answers without access to any pre-computed paths.
",1 Introduction,[0],[0]
We refer to the RL formulation adopted by MINERVA as “learning to walk towards the answer” or “walk-based query-answering (QA)”.,1 Introduction,[0],[0]
"Walk-based QA eliminates the need to precompute path features, yet this setup poses several challenges for training.",1 Introduction,[0],[0]
"First, because practical KGs are intrinsically incomplete, the agent may arrive at a correct answer whose link to the source entity is missing from the training graph without receiving any reward (false negative targets, Figure 2).",1 Introduction,[0],[0]
"Second, since no ground truth path is available for training, the agent may traverse spurious paths that lead to a correct answer only incidentally (false positive paths).",1 Introduction,[0],[0]
"Because REINFORCE (Williams, 1992) is an on-policy RL algorithm (Sutton and Barto, 1998) which encourages past actions with high reward, it can bias the policy toward spurious paths found early in training (Guu et al., 2017).
",1 Introduction,[0],[0]
We propose two modeling advances for RL approaches in the walk-based QA framework to address the aforementioned problems.,1 Introduction,[0],[0]
"First, instead of using a binary reward based on whether the agent has reached a correct answer or not, we adopt pre-trained state-of-the-art embeddingbased models (Dettmers et al., 2018; Trouillon et al., 2016) to estimate a soft reward for target entities whose correctness cannot be determined.",1 Introduction,[0],[0]
"As embedding-based models capture link semantics well, unobserved but correct answers would receive a higher reward score compared to a true negative entity using a well-trained model.",1 Introduction,[0],[0]
"Second, we perform action dropout which randomly blocks some outgoing edges of the agent at each training step so as to enforce effective exploration of a diverse set of paths and dilute the negative impact of the spurious ones.",1 Introduction,[0],[0]
"Empirically, our overall model significantly improves over state-of-the-
art multi-hop reasoning approaches on four out of five benchmark KG datasets (UMLS, Kinship, FB15k-237, WN18RR).",1 Introduction,[0],[0]
It is also the first pathbased model that achieves consistently comparable or better performance than embedding-based models.,1 Introduction,[0],[0]
"We perform a thorough ablation study and result analysis, demonstrating the effect of each modeling innovation.",1 Introduction,[0],[0]
"In this section, we first review the walk-based QA framework (§2.2) and the on-policy reinforcement learning approach proposed by Das et al. (2018) (§2.3,§2.4).",2 Approach,[0],[0]
Then we describe our proposed solutions to the false negative reward and spurious path problems: knowledge-based reward shaping (§2.5) and action dropout (§2.6).,2 Approach,[0],[0]
"We formally represent a knowledge graph as G = (E ,R), where E is the set of entities and R is the set of relations.",2.1 Formal Problem Definition,[0],[0]
"Each directed link in the knowledge graph l = (es, r, eo) ∈ G represents a fact (also called a triple).
",2.1 Formal Problem Definition,[0],[0]
"Given a query (es, rq, ?), where es is the source entity and rq is the relation of interest, the goal is to perform an efficient search over G and collect the set of possible answers",2.1 Formal Problem Definition,[0],[0]
"Eo = {eo} where (es, rq, eo) /∈",2.1 Formal Problem Definition,[0],[0]
G due to incompleteness.,2.1 Formal Problem Definition,[0],[0]
"The search can be formulated as a Markov Decision Process (MDP) (Sutton and Barto, 1998): starting from es, the agent sequentially selects an outgoing edge l and traverses to a new entity until it arrives at a target.",2.2 Reinforcement Learning Formulation,[0],[0]
"Specifically, the MDP consists of the following components (Das et al., 2018).
",2.2 Reinforcement Learning Formulation,[0],[0]
States,2.2 Reinforcement Learning Formulation,[0],[0]
"Each state st = (et, (es, rq)) ∈ S is a tuple where et is the entity visited at step t and (es, rq) are the source entity and query relation.",2.2 Reinforcement Learning Formulation,[0],[0]
"et can be viewed as the state-dependent information while (es, rq) are the global context shared by all states.
",2.2 Reinforcement Learning Formulation,[0],[0]
Actions The set of possible actions At ∈,2.2 Reinforcement Learning Formulation,[0],[0]
"A at step t consists of the outgoing edges of et in G, i.e., At = {(r′, e′)|(et, r′, e′) ∈ G}.",2.2 Reinforcement Learning Formulation,[0],[0]
"To give the agent the option to terminat a search, a self-loop edge is added to every At.",2.2 Reinforcement Learning Formulation,[0],[0]
"When search is unrolled for a fixed number of steps T , the self-loop acts similarly to a “stop” action.
",2.2 Reinforcement Learning Formulation,[0],[0]
Transition A transition function δ,2.2 Reinforcement Learning Formulation,[0],[0]
": S×A→ S is defined by δ(st, At) = δ(et, (es, rq), At).",2.2 Reinforcement Learning Formulation,[0],[0]
"In walk-based QA, the transition is determined by G.
Rewards In the default formulation, the agent receives a terminal reward of 1 if it arrives at a correct target entity when search ends and 0 otherwise.
Rb(sT )",2.2 Reinforcement Learning Formulation,[0],[0]
"= {(es, rq, eT ) ∈ G}.",2.2 Reinforcement Learning Formulation,[0],[0]
(1),2.2 Reinforcement Learning Formulation,[0],[0]
"The search policy is parameterized using state information and global context, plus the search history (Das et al., 2018).
",2.3 Policy Network,[0],[0]
"Specifically, every entity and relation in G is assigned a dense vector embedding e ∈ d and r ∈",2.3 Policy Network,[0],[0]
d.,2.3 Policy Network,[0],[0]
"A particular action at = (rt+1, et+1) ∈",2.3 Policy Network,[0],[0]
At is represented as the concatenation of the relation embedding and the end node embedding at =,2.3 Policy Network,[0],[0]
"[r; e′t].
",2.3 Policy Network,[0],[0]
"The search history ht = (es, r1, e1, . . .",2.3 Policy Network,[0],[0]
", rt, et) ∈ H consists of the sequence of actions taken up to step t, and can be encoded using an LSTM:
h0 = LSTM(0, [r0; es]) (2) ht = LSTM(ht−1,at−1), t > 0, (3)
where r0 is a special start relation introduced to form a start action with es.
",2.3 Policy Network,[0],[0]
The action space At is encoded by stacking the embeddings of all actions in it:,2.3 Policy Network,[0],[0]
At ∈ |At|×2d.,2.3 Policy Network,[0],[0]
"And the policy network π is defined as:
πθ(at|st) = σ(At ×W2 ReLU(W1[et;ht; rq])), (4)
where σ is the softmax operator.",2.3 Policy Network,[0],[0]
"The policy network is trained by maximizing the expected reward over all queries in G:
J(θ) =",2.4 Optimization,[0],[0]
"(es,r,eo)∈G",2.4 Optimization,[0],[0]
"[ a1,...,aT∼πθ [R(sT |es, r)]",2.4 Optimization,[0],[0]
].,2.4 Optimization,[0],[0]
"(5) The optimization is done using the REINFORCE (Williams, 1992) algorithm, which iterates through all (es, r, eo) triples in G1 and updates
1This training strategy treats a query with n > 1 answers as n single-answer queries.",2.4 Optimization,[0],[0]
"In particular, given a query (es, rq, ?) with multiple answers {et1 , . . .",2.4 Optimization,[0],[0]
"etn}, when training w.r.t.",2.4 Optimization,[0],[0]
"the example (es, rq, eti), MINERVA removes all {etj |j ̸= i} observed in the training data from the possible set of target entities in the last search step so as to force the agent to walk towards eti .",2.4 Optimization,[0],[0]
"We adopt the same technique in our training.
",2.4 Optimization,[0],[0]
"θ with the following stochastic gradient:
∇θJ(θ)",2.4 Optimization,[0],[0]
"≈ ∇θ T∑
t=1
R(sT |es, r) log πθ(at|st).
",2.4 Optimization,[0],[0]
(6),2.4 Optimization,[0],[0]
"According to Equation 1, the agent receives a binary reward based solely on the observed answers in G. However, G is intrinsically incomplete and this approach penalizes the false negative search attempts identically to true negatives.",2.5 Knowledge-Based Reward Shaping,[0],[0]
"To alleviate this problem, we adopt existing KG embedding models designed for the purpose of KG completion (Trouillon et al., 2016; Dettmers et al., 2018) to estimate a soft reward for target entities whose correctness is unknown.
",2.5 Knowledge-Based Reward Shaping,[0],[0]
"Formally, the embedding models map E and R to a vector space, and estimate the likelihood of each fact l = (es, r, et) ∈ G using f(es, r, et), a composition function of the entity and relation embeddings.",2.5 Knowledge-Based Reward Shaping,[0],[0]
"f is trained by maximizing the likelihood of all facts in G. We propose the following reward shaping strategy (Ng et al., 1999):
R(sT ) = Rb(sT ) + (1−Rb(sT ))",2.5 Knowledge-Based Reward Shaping,[0],[0]
"f(es, rq, eT ).",2.5 Knowledge-Based Reward Shaping,[0],[0]
"(7) Namely, if the destination eT is a correct answer according to G, the agent receives reward 1.",2.5 Knowledge-Based Reward Shaping,[0],[0]
"Otherwise the agent receives a fact score estimated by f(es, rq, eT ), which is pre-trained.",2.5 Knowledge-Based Reward Shaping,[0],[0]
"Here we keep f in its general form and it can be replaced by any state-of-the-art model (Trouillon et al., 2016; Dettmers et al., 2018) or ensemble thereof.",2.5 Knowledge-Based Reward Shaping,[0],[0]
"The REINFORCE training algorithm performs onpolicy sampling according to πθ(at|st), and updates θ stochastically using Equation 6.",2.6 Action Dropout,[0],[0]
"Because the agent does not have access to any oracle path, it is possible for it to arrive at a correct answer eo via a path irrelevant to the query relation.",2.6 Action Dropout,[0],[0]
"As shown in Figure 1, the path Obama −endorsedBy→ McCain −liveIn→ U.S. ←locatedIn− Hawaii does not infer the fact bornIn(Obama,Hawaii).
",2.6 Action Dropout,[0],[0]
"Discriminating paths of different qualities is non-trivial, and existing RL approaches for walkbased KGQA largely rely on the terminal reward to bias the search.",2.6 Action Dropout,[0],[0]
"Since there are usually more spurious paths than correct ones, spurious paths are often found first, and following exploration can be increasingly biased towards them (Equation 6).
",2.6 Action Dropout,[0],[0]
"Entities with larger fan-in (in-degree) and fan-out (out-degree) often exacerbate this problem.
",2.6 Action Dropout,[0],[0]
"Guu et al. (2017) identified a similar issue in RL-based semantic parsing with weak supervision, where programs that do not semantically match the user utterance frequently pass the tests.",2.6 Action Dropout,[0],[0]
"To solve this problem, Guu et al. (2017) proposed randomized beam search combined with a meritocratic update rule to ensure all trajectories that obtain rewards are up-weighted roughly equally.
",2.6 Action Dropout,[0],[0]
Here we propose the action dropout technique which achieves similar effect as randomized search and is simpler to implement over graphs.,2.6 Action Dropout,[0],[0]
Action dropout randomly masks some outgoing edges for the agent in the sampling step of REINFORCE.,2.6 Action Dropout,[0],[0]
"The agent then performs sampling2 according to the adjusted action distribution
π̃θ(at|st) ∝",2.6 Action Dropout,[0],[0]
"(πθ(at|st) ·m+ ϵ) (8) mi ∼ Bernoulli(1− α), i = 1, . . .",2.6 Action Dropout,[0],[0]
"|At|, (9)
where each entry of m ∈ {0, 1}|At| is a binary variable sampled from the Bernoulli distribution with parameter 1 − α.",2.6 Action Dropout,[0],[0]
"A small value ϵ is used to smooth the distribution in case m = 0, where π̃θ(at|st) becomes uniform.
",2.6 Action Dropout,[0],[0]
Our overall approach is illustrated in Figure 3.,2.6 Action Dropout,[0],[0]
"In this section, we summarize the related work and discuss their connections to our approach.
",3 Related Work,[0],[0]
2We only modify the sampling distribution and still use πθ(at|st) to compute the gradient update in equation 6.,3 Related Work,[0],[0]
"KG embeddings (Bordes et al., 2013; Socher et al., 2013; Yang et al., 2014; Trouillon et al., 2016; Dettmers et al., 2018) are one-hop KG modeling approaches which learn a scoring function f(es, r, eo) to define a fuzzy truth value of a triple in the embedding space.",3.1 Knowledge Graph Embeddings,[0],[0]
"These models can be adapted for query answering by simply return the eo’s with the highest f(es, r, eo) scores.",3.1 Knowledge Graph Embeddings,[0],[0]
"Despite their simplicity, embedding-based models achieved state-of-the-art performance on KGQA (Das et al., 2018).",3.1 Knowledge Graph Embeddings,[0],[0]
"However, such models ignore the symbolic compositionality of KG relations, which limits their usage in more complex reasoning tasks.",3.1 Knowledge Graph Embeddings,[0],[0]
The reward shaping (RS) strategy we proposed is a step to combine their capability in modeling triple semantics with the symbolic reasoning capability of the path-based approach.,3.1 Knowledge Graph Embeddings,[0],[0]
"Multi-hop reasoning focus on learning symbolic inference rules from relational paths in the KG and has been formulated as sequential decision problems in recent works (Xiong et al., 2017; Das et al., 2018; Shen et al., 2018; Chen et al., 2018).",3.2 Multi-Hop Reasoning,[0],[0]
"In particular, DeepPath (Xiong et al., 2017) first adopted REINFORCE to search for generic representative paths between pairs of entities.",3.2 Multi-Hop Reasoning,[0],[0]
"DIVA (Chen et al., 2018) also performs generic path search between entities using RL and its variational objective can be interpreted as model-based reward assignment.",3.2 Multi-Hop Reasoning,[0],[0]
"MINERVA (Das et al., 2018) first introduced RL
to search for answer entities of a particular KG query end-to-end.",3.2 Multi-Hop Reasoning,[0],[0]
"MINERVA uses entropy regularization to softly encourage the policy to sample diverse paths, and we show that hard action dropout is more effective in this setup.",3.2 Multi-Hop Reasoning,[0],[0]
"ReinforceWalk (Shen et al., 2018) further proposed to solve the reward sparsity problem in walk-based QA using off-policy learning.",3.2 Multi-Hop Reasoning,[0],[0]
ReinforceWalk scores the search targets with a value function which is updated based on the search history cached through epochs.,3.2 Multi-Hop Reasoning,[0],[0]
"In comparison, we leveraged existing embedding-based models for reward shaping, which is much more efficient during training.",3.2 Multi-Hop Reasoning,[0],[0]
"Recently, RL has seen a variety of applications in NLP including machine translation (Ranzato et al., 2015), summarization (Paulus et al., 2017), and semantic parsing (Guu et al., 2017).",3.3 Reinforcement Learning,[0],[0]
"Compared to the domain of gaming (Mnih et al., 2013) where RL is mostly applied for, RL formulations in NLP often have a large discrete action space.",3.3 Reinforcement Learning,[0],[0]
"For example, in machine translation, the space of possible actions is the entire vocabulary of a language.",3.3 Reinforcement Learning,[0],[0]
"Walk-based QA also suffers from this problem, as some entities may have thousands of neighbors (e.g. U.S.).",3.3 Reinforcement Learning,[0],[0]
"Since often there is no golden path available for a KG reasoning problem, we cannot leverage supervised pre-training to initialize the path search following the common practice in RL-based natural language generation (Ranzato et al., 2015).",3.3 Reinforcement Learning,[0],[0]
"On the other hand, the inference paths being studied in a KG are often much shorter (usually containing 2-5 steps) compared to the target sentences in the NL generation problems (often containing 20-30 words), which simplifies the training to some extent.",3.3 Reinforcement Learning,[0],[0]
We evaluate our modeling contributions on five KGs from different domains and exhibiting different graph properties (§ 4.1).,4 Experiment Setup,[0],[0]
We compare with two classes of state-of-the-art KG models: multi-hop neural symbolic approaches and KG embeddings (§4.2).,4 Experiment Setup,[0],[0]
"In this section, we describe the datasets and our experiment setup in detail.",4 Experiment Setup,[0],[0]
"We adopt five benchmark KG datasets for query answering: (1) Alyawarra Kinship, (2) Unified Medical Language Systems (Kok and Domingos,
2007), (3) FB15k-237 (Toutanova et al., 2015), (4) WN18RR (Dettmers et al., 2018), and (5) NELL995 (Xiong et al., 2017).",4.1 Dataset,[0],[0]
The statistics of the datasets are shown in Table 1.,4.1 Dataset,[0],[0]
We compare with three embedding based models:,4.2 Baselines and Model Variations,[0],[0]
"DistMult (Yang et al., 2014), ComplEx (Trouillon et al., 2016) and ConvE (Dettmers et al., 2018).",4.2 Baselines and Model Variations,[0],[0]
"We also compare with three multi-hop neural symbolic models: (a) NTP-λ, an improved version of Neural Theorem Prover (Rocktäschel and Riedel, 2017), (b) Neural Logical Programming (NeuralLP) (Yang et al., 2017) and (c) MINERVA.",4.2 Baselines and Model Variations,[0],[0]
"For our own approach, we include two model variations that use ComplEx and ConvE as the reward shaping modules respectively, denoted as Ours(ComplEx) and Ours(ConvE).",4.2 Baselines and Model Variations,[0],[0]
"We quote the results of NeuralLP, NTP-λ and MINERVA reported in Das et al. (2018), and replicated the embedding based systems.3",4.2 Baselines and Model Variations,[0],[0]
Beam Search Decoding We perform beam search decoding to obtain a list of unique entity predictions.,4.3 Implementation Details,[0],[0]
"Because multiple paths may lead to the same target entity, we compute the list of unique entities reached in the final search step and assign each of them the maximum score of all paths that led to it.",4.3 Implementation Details,[0],[0]
We then output the top-ranked unique entities.,4.3 Implementation Details,[0],[0]
"We find this approach to improve over directly taking the entities ranked at the beam top, as many of them are repetitions.
",4.3 Implementation Details,[0],[0]
"KG Setup Following previous work, we treat every KG link as bidirectional and augment the graph with the reversed (eo, r−1, es) links.",4.3 Implementation Details,[0],[0]
"We use the same train, dev, and test set splits as Das et al. (2018).",4.3 Implementation Details,[0],[0]
"We exclude any link from the dev and
3 Das et al. (2018) reported MINERVA results with the entity embedding usage as an extra hyperparameter – the quoted performance of MINERVA in Table 2 on UMLS and Kinship were obtained with entity embeddings setting to zero.",4.3 Implementation Details,[0],[0]
"In contrast, our system always uses trained entity embeddings.
test set (and its reversed link) from the train set.",4.3 Implementation Details,[0],[0]
"Following Das et al. (2018), we cut the maximum number of outgoing edges of an entity by threshold η to prevent GPU memory overflow: for each entity we keep its top-η neighbors with the highest PageRank scores (Page et al., 1999) in the graph.
",4.3 Implementation Details,[0],[0]
Hyperparameters We set the entity and relation embedding size to 200 for all models.,4.3 Implementation Details,[0],[0]
"We use Xavier initialization (Glorot and Bengio, 2010) for the embeddings and the NN layers.",4.3 Implementation Details,[0],[0]
"For ConvE, we use the same convolution layer and label smoothing hyperparameters as Dettmers et al. (2018).",4.3 Implementation Details,[0],[0]
"For path-based models, we use a three-layer LSTM as the path encoder and set its hidden dimension to 200.",4.3 Implementation Details,[0],[0]
"We perform grid search on the reasoning path length (2, 3), the node fan-out threshold η (256- 512) and the action dropout rate α (0.1-0.9).",4.3 Implementation Details,[0],[0]
"Following Das et al. (2018), we add an entropy regularization term in the objective and tune the weight parameter β within 0-0.1.",4.3 Implementation Details,[0],[0]
"We use Adam optimization (Kingma and Ba, 2014) and search the learning rate (0.001-0.003) and mini-batch size (128- 512).4",4.3 Implementation Details,[0],[0]
"For all models we apply dropout to the entity and relation embeddings and all feed-forward layers, and search the dropout rates within 0-0.5.",4.3 Implementation Details,[0],[0]
"We use a decoding beam size of 512 for NELL995 and 128 for the other datasets.
",4.3 Implementation Details,[0],[0]
"Evaluation Protocol We convert each triple (es, r, eo) in the test set into a query and compute ranking-based evaluation metrics.",4.3 Implementation Details,[0],[0]
"The models take es, r as the input and output a list of candidate answers Eo =",4.3 Implementation Details,[0],[0]
"[e1, . .",4.3 Implementation Details,[0],[0]
.,4.3 Implementation Details,[0],[0]
", eL] ranked in decreasing order of confidence score.",4.3 Implementation Details,[0],[0]
"We compute
4On some datasets, we found larger batch size to continue improving the performance but had to stop at 512 due to memory constraints.
",4.3 Implementation Details,[0],[0]
"reo , the rank of eo among Eo, after removing the other correct answers from Eo and use it to compute two types of metrics: (1) Hits@k which is the percentage of examples where reo ≤ k and (2) mean reciprocal rank (MRR) which is the mean of 1/reo for all examples in the test set.",4.3 Implementation Details,[0],[0]
"We use the entire test set for evaluation, with the exception of NELL-995, where test triples with unseen entities are removed following Das et al. (2018).
",4.3 Implementation Details,[0],[0]
Our Pytorch implementation of all experiments is released at https://github.com/ salesforce/MultiHopKG.,4.3 Implementation Details,[0],[0]
Table 2 shows the evaluation results of our proposed approach and the baselines.,5.1 Model Comparison,[0],[0]
The top part presents embedding based approaches and the bottom part presents multi-hop reasoning,5.1 Model Comparison,[0],[0]
"approaches.5
We find embedding based models perform strongly on several datasets, achieving overall best evaluation metrics on UMLS, Kinship, FB15K237 and NELL-995 despite their simplicity.",5.1 Model Comparison,[0],[0]
"While previous path based approaches achieve comparable performance on some of the datasets (WN18RR, NELL-995, and UMLS), they perform significantly worse than the embedding based models on the other datasets (9.1 and 14.2 absolute points lower on Kinship and FB15k-237 respectively).",5.1 Model Comparison,[0],[0]
"A possible reason for this is that embedding based methods map every link in the KG into the same embedding space, which implicitly encodes the connectivity of the whole graph.",5.1 Model Comparison,[0],[0]
"In contrast, path based models use the discrete represen-
5We report the model robustness measurements in § A.1.
tation of a KG as input, and therefore have to leave out a significant proportion of the combinatorial path space by selection.",5.1 Model Comparison,[0],[0]
"For some path based approaches, computation cost is a bottleneck.",5.1 Model Comparison,[0],[0]
"In particular, NeuralLP and NTP-λ failed to scale to the larger datasets and their results are omitted from the table, as Das et al. (2018) reported.
",5.1 Model Comparison,[0],[0]
Ours is the first multi-hop reasoning approach which is consistently comparable or better than embedding based approaches on all five datasets.,5.1 Model Comparison,[0],[0]
"The best single model, Ours(ConvE), improves the SOTA performance of path-based models on three datasets (UMLS, Kinship, and FB15k-237) by 4%, 9%, and 39% respectively.",5.1 Model Comparison,[0],[0]
"On NELL-995, our approach did not significantly improve over existing SOTA.",5.1 Model Comparison,[0],[0]
"The NELL-995 dataset consists of only 12 relations in the test set and, as we further detail in the analysis (§ 5.3.3), our approach is less effective for those relation types.
",5.1 Model Comparison,[0],[0]
The model variations using different reward shaping modules perform similarly.,5.1 Model Comparison,[0],[0]
"While a better reward shaping module typically results in a better overall model, an exception is WN18RR, where ComplEx performs slightly worse on its own but is more helpful for reward shaping.",5.1 Model Comparison,[0],[0]
We left the study of the relationship between the reward shaping module accuracy and the overall model performance as future work.,5.1 Model Comparison,[0],[0]
We perform an ablation study where we remove reward shaping (−RS) and action dropout (−AD) from Ours(ConvE) and compare their MRRs to the whole model on the dev sets.6,5.2 Ablation Study,[0],[0]
"As shown in Table 3, on most datasets, removing each component results in a significant performance drop.",5.2 Ablation Study,[0],[0]
"The exception is WN18RR, where removing the ConvE reward shaping module improves the performance.7 Removing reward shaping on NELL-
6According to Table 3 and Table 2, the dev and test set evaluation metrics differ significantly on several datasets.",5.2 Ablation Study,[0],[0]
"We discuss the cause of this in § A.2.
",5.2 Ablation Study,[0],[0]
"7A possible explanation for this is that as path-based models tend to outperform the embedding based approaches on WN18RR, ConvE may be supplying more noise than useful
995 does not change the results significantly.",5.2 Ablation Study,[0],[0]
"In general, removing action dropout has a greater impact, suggesting that thorough exploration of the path space is important across datasets.",5.2 Ablation Study,[0],[0]
We are interested in studying the impact of each proposed enhancement on the training convergence rate.,5.3.1 Convergence Rate,[0],[0]
"In particular, we expect reward shaping to accelerate the convergence of RL (to a better performance level) as it propagates prior knowledge about the underlying KG to the agent.",5.3.1 Convergence Rate,[0],[0]
"On the other hand, a fair concern for action dropout is that it can be slower to train, as the agent is forced to explore a more diverse set of paths.",5.3.1 Convergence Rate,[0],[0]
"Figure 4 eliminates this concern.
",5.3.1 Convergence Rate,[0],[0]
The first row of Figure 4 shows the changes in dev set MRR of Ours(ConvE) (green ∗) and the two ablated models w.r.t.,5.3.1 Convergence Rate,[0],[0]
# epochs.,5.3.1 Convergence Rate,[0],[0]
"In general, the proposed approach is able to converge to a higher accuracy level much faster than either of the ablated models and the performance gap often persists until the end of training (on UMLS, Kinship, and FB15k-237).",5.3.1 Convergence Rate,[0],[0]
"Particularly, on FB15k-237, our approach still shows improvement even after the two ablated models start to overfit, with −AD beginning to overfit sooner.",5.3.1 Convergence Rate,[0],[0]
"On WN18RR, introducing reward shaping hurt dev set performance from the beginning, as discussed in § 5.2.",5.3.1 Convergence Rate,[0],[0]
"On NELL995, Ours(ConvE) performs significantly better in the beginning, but −RS gradually reaches a comparable performance level.
",5.3.1 Convergence Rate,[0],[0]
It is especially interesting that introducing action dropout immediately improves the model performance on all datasets.,5.3.1 Convergence Rate,[0],[0]
A possible explanation for this is that by exploring a more diverse set of paths the agent learns search policies that generalize better.,5.3.1 Convergence Rate,[0],[0]
We also compute the total number of unique paths the agent explores during training and visualize its change w.r.t.,5.3.2 Path Diversity,[0],[0]
# training epochs in the second row of Figure 4.,5.3.2 Path Diversity,[0],[0]
"When counting a unique path, we include both the edge label and intermediate entity.
information about the KG.",5.3.2 Path Diversity,[0],[0]
"Yet counter-intuitively, we found that adding the ComplEx reward shaping module helps, despite the fact that ComplEx performs slightly worse than ConvE on this dataset.",5.3.2 Path Diversity,[0],[0]
"This indicates that dev set accuracy is not the only factor which determines the effectiveness of reward shaping.
",5.3.2 Path Diversity,[0],[0]
"First we observe that, on all datasets, the agent explores a large number of paths before reaching a good performance level.",5.3.2 Path Diversity,[0],[0]
The speed of path discovery slowly decreases as training progresses.,5.3.2 Path Diversity,[0],[0]
"On smaller KGs (UMLS and Kinship), the rate of encountering new paths is significantly lower after a certain number of epochs, and the dev set accuracy plateaus correspondingly.",5.3.2 Path Diversity,[0],[0]
"On much larger KGs (FB15k-237, WN18RR, and NELL-995), we did not observe a significant slowdown before severe overfitting occurs and the dev set performance starts to drop.",5.3.2 Path Diversity,[0],[0]
"A possible reason for this is that the larger KGs are more sparsely connected compared to the smaller KGs (Table 1), therefore it is less efficient to gain generalizable knowledge from the KG by exploring a limited proportion of the path space through sampling.
",5.3.2 Path Diversity,[0],[0]
"Second, while removing action dropout significantly lowers the effectiveness of path exploration (orange !",5.3.2 Path Diversity,[0],[0]
"vs. green ∗), we observe that removing reward shaping (blue △) slightly increases the # paths visited if the action dropout rate is kept the same.",5.3.2 Path Diversity,[0],[0]
"This indicates that the correlation between
# paths explored and dev set performance is not strictly positive.",5.3.2 Path Diversity,[0],[0]
The best performing model is not always the model that explored the largest # paths.,5.3.2 Path Diversity,[0],[0]
It also demonstrates the role of reward shaping as a regularizer which guides the agent to avoid noisy paths with its prior knowledge.,5.3.2 Path Diversity,[0],[0]
We investigate the behaviors of our proposed approach w.r.t different relation types.,5.3.3 Performance w.r.t. Relation Types,[0],[0]
"For each KG, we classify its set of relations into two categories based on the answer set cardinality.",5.3.3 Performance w.r.t. Relation Types,[0],[0]
"Specifically, we define the metric ξr as the average answer set cardinality of all queries with topic relation r.",5.3.3 Performance w.r.t. Relation Types,[0],[0]
"We count r as a “to-many” relation if ξr > 1.5, which indicates that most queries in relation r has more than 1 correct answer; we count r as a “to-one” relation otherwise, meaning most queries of this relation have only 1 correct answer.
",5.3.3 Performance w.r.t. Relation Types,[0],[0]
"Table 4 shows the percentage of examples of tomany and to-one relations on each dev dataset and the MRR evaluation metrics of previously studied models computed on the examples of each relation
type.",5.3.3 Performance w.r.t. Relation Types,[0],[0]
"Since UMLS and Kinship are densely connected, they almost exclusively contain to-many relations.",5.3.3 Performance w.r.t. Relation Types,[0],[0]
FB15k-237 mostly contains to-many relations.,5.3.3 Performance w.r.t. Relation Types,[0],[0]
"In Figure 4, we observe the biggest relative gains from the ablated models on these three datasets.",5.3.3 Performance w.r.t. Relation Types,[0],[0]
WN18RR is more balanced and consists of slightly more to-many relations than toone relations.,5.3.3 Performance w.r.t. Relation Types,[0],[0]
The NELL-995 dev set is a unique one which almost exclusively consists of to-one relations.,5.3.3 Performance w.r.t. Relation Types,[0],[0]
"There is no common performance pattern over the two relation types across datasets: on some datasets all models perform better on tomany relations (UMLS, WN18RR) while others show the opposite trend (FB15k-237, NELL-995).",5.3.3 Performance w.r.t. Relation Types,[0],[0]
"We leave the study of these discrepancies to future work.
",5.3.3 Performance w.r.t. Relation Types,[0],[0]
We show the relative performance change of the ablated models−RS and−AD w.r.t. Ours(ConvE),5.3.3 Performance w.r.t. Relation Types,[0],[0]
in parentheses.,5.3.3 Performance w.r.t. Relation Types,[0],[0]
We observe that in general our proposed enhancements are effective in improving query-answering over both relation types (more effective for to-many relations).,5.3.3 Performance w.r.t. Relation Types,[0],[0]
"However, adding the ConvE reward shaping module on WN18RR hurts the performance over both to-many and toone relations (more for to-one relations).",5.3.3 Performance w.r.t. Relation Types,[0],[0]
"On NELL-995, both techniques hurt the performance over to-many relations.",5.3.3 Performance w.r.t. Relation Types,[0],[0]
"Since most benchmark datasets randomly split the KG triples into train, dev and test sets, the queries that have multiple answers may fall into multiple splits.",5.3.4 Performance w.r.t. Seen Queries vs. Unseen Queries,[0],[0]
"As a result, some of the test queries (es, rq, ?) are seen in the training set (with a different set of answers) while the others are not.",5.3.4 Performance w.r.t. Seen Queries vs. Unseen Queries,[0],[0]
We investigate the behaviors of our proposed approach w.r.t.,5.3.4 Performance w.r.t. Seen Queries vs. Unseen Queries,[0],[0]
"seen and unseen queries.
",5.3.4 Performance w.r.t. Seen Queries vs. Unseen Queries,[0],[0]
Table 5 shows the percentage of examples associated with seen and unseen queries on each dev dataset and the corresponding MRR evaluation metrics of previously studied models.,5.3.4 Performance w.r.t. Seen Queries vs. Unseen Queries,[0],[0]
"On
most datasets, the ratio of seen vs. unseen queries is similar to that of to-many vs. to-one relations (Table 4) as a result of random data split, with the exception of WN18RR.",5.3.4 Performance w.r.t. Seen Queries vs. Unseen Queries,[0],[0]
"On some datasets, all models perform better on seen queries (UMLS, Kinship, WN18RR) while others reveal the opposite trend.",5.3.4 Performance w.r.t. Seen Queries vs. Unseen Queries,[0],[0]
We leave the study of these model behaviors to future work.,5.3.4 Performance w.r.t. Seen Queries vs. Unseen Queries,[0],[0]
On NELL-995 both of our proposed enhancements are not effective over the seen queries.,5.3.4 Performance w.r.t. Seen Queries vs. Unseen Queries,[0],[0]
"In most cases, our proposed enhancements improve the performance over unseen queries, with AD being more effective.",5.3.4 Performance w.r.t. Seen Queries vs. Unseen Queries,[0],[0]
We propose two modeling advances for end-toend RL-based knowledge graph query answering: (1) reward shaping via graph completion and (2) action dropout.,6 Conclusions,[0],[0]
Our approach improves over state-of-the-art multi-hop reasoning models consistently on several benchmark KGs.,6 Conclusions,[0],[0]
"A detailed analysis indicates that the access to a more accurate environment representation (reward shaping) and a more thorough exploration of the search space (action dropout) are important to the performance boost.
",6 Conclusions,[0],[0]
"On the other hand, the performance gap between RL-based approaches and the embeddingbased approaches for KGQA remains.",6 Conclusions,[0],[0]
"In future work, we would like to investigate learnable reward shaping and action dropout schemes and apply model-based RL to this domain.",6 Conclusions,[0],[0]
"We thank Mark O. Riedl, Yingbo Zhou, James Bradbury and Vena Jia Li for their feedback on early draft of the paper, and Mark O. Riedl for helpful conversations on reward shaping.",Acknowledgements,[0],[0]
We thank the anonymous reviewers and the Salesforce research team members for their thoughtful comments and discussions.,Acknowledgements,[0],[0]
We thank Fréderic,Acknowledgements,[0],[0]
Godin for pointing out an error in Equation 8 in an early version of the paper.,Acknowledgements,[0],[0]
Multi-hop reasoning is an effective approach for query answering (QA) over incomplete knowledge graphs (KGs).,abstractText,[0],[0]
"The problem can be formulated in a reinforcement learning (RL) setup, where a policy-based agent sequentially extends its inference path until it reaches a target.",abstractText,[0],[0]
"However, in an incomplete KG environment, the agent receives low-quality rewards corrupted by false negatives in the training data, which harms generalization at test time.",abstractText,[0],[0]
"Furthermore, since no golden action sequence is used for training, the agent can be misled by spurious search trajectories that incidentally lead to the correct answer.",abstractText,[0],[0]
We propose two modeling advances to address both issues: (1) we reduce the impact of false negative supervision by adopting a pretrained onehop embedding model to estimate the reward of unobserved facts; (2) we counter the sensitivity to spurious paths of on-policy RL by forcing the agent to explore a diverse set of paths using randomly generated edge masks.,abstractText,[0],[0]
Our approach significantly improves over existing path-based KGQA models on several benchmark datasets and is comparable or better than embedding-based models.,abstractText,[0],[0]
Multi-Hop Knowledge Graph Reasoning with Reward Shaping,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 162–169 New Orleans, Louisiana, June 1 - 6, 2018. c©2017 Association for Computational Linguistics",text,[0],[0]
"Natural language generation (NLG) has a broad range of applications, from question answering systems to story generation, summarization etc.",1 Introduction,[0],[0]
"In this paper, we target a particular use case that is important for e-Commerce websites, which group multiple items on common pages called browse pages (BP).",1 Introduction,[0],[0]
"Each browse page contains an overview of various items which share some characteristics expressed as slot/value pairs.
",1 Introduction,[0],[0]
"For example, we can have a browse page for Halloween decoration, which will display different types like lights, figurines, and candy bowls.",1 Introduction,[0],[0]
"These different items of decoration have their own browse pages, which are linked from the BP for Halloween decoration.",1 Introduction,[0],[0]
"A ceramic candy bowl for Halloween can appear on various browse pages, e.g. on the BP for Halloween decoration, BP for Halloween candy bowls, as well as the (non Halloween-specific) BP for ceramic candy bowls.
",1 Introduction,[0],[0]
"To show customers which items are grouped on a browse page, we need a human-readable title of the content of that particular page.",1 Introduction,[0],[0]
"Different combinations of characteristics bijectively correspond to different browse pages, and consequently to different browse page titles.
",1 Introduction,[0],[0]
"Note that here, different from other natural language generation tasks described in the literature, slot names are already given; the task is to generate a title for a set of slots.",1 Introduction,[0],[0]
"Moreover, we do not perform any selection of the slots that the title should realize; but all slots need to be realized in order to have a unique title.",1 Introduction,[0],[0]
E-Commerce sites may have tens of millions of such browse pages in many different languages.,1 Introduction,[0],[0]
The number of unique slot-value pairs are in the order of hundreds of thousands.,1 Introduction,[0],[0]
"All these factors render the task of human creation of BP titles infeasible.
",1 Introduction,[0],[0]
"Mathur, Ueffing, and Leusch (2017) developed several different systems which generated titles for these pages automatically.",1 Introduction,[0],[0]
"These systems include rule-based approaches, statistical models, and combinations of the two.",1 Introduction,[0],[0]
"In this work, we investigate the use of neural sequence-to-sequence models for browse page title generation.",1 Introduction,[0],[0]
"These models have recently received much attention in the research community, and are becoming the new state of the art in machine translation (refer Section 4).
",1 Introduction,[0],[0]
"We will compare our neural generation models
162
against two state-of-the-art systems.
1.",1 Introduction,[0],[0]
"The baseline system for English and French implements a hybrid generation approach, which combines a rule-based approach (with a manually created grammar) and statistical machine translation (SMT) techniques.",1 Introduction,[0],[0]
"For French, we have monolingual data for training language model, which can be used in the SMT system.",1 Introduction,[0],[0]
"For English, we also have human-curated titles and can use those for training additional “translation” components for this hybrid system.
2.",1 Introduction,[0],[0]
"The system for German is an Automatic Post-Editing (APE) system – first introduced by Simard et al. (2007) – which generates titles with the rule-based approach, and then uses statistical machine translation techniques for automatically correcting the errors made by the rule-based approach.
",1 Introduction,[0],[0]
"In the following section, we describe a few of the previous works in the field of language generation from a knowledge base or linked data.",1 Introduction,[0],[0]
Section 3 addresses the idea of lexicalization of a browse node in linear form along with the normalization step to replace the slot values with placeholders.,1 Introduction,[0],[0]
"Sequence-to-sequence models for generation of titles are described in Section 4, followed by a description of joint learning over multiple languages in Section 5.",1 Introduction,[0],[0]
Experiments and results are described in Sections 6 and 7.,1 Introduction,[0],[0]
"The first works on NLG were mostly focused on rule-based language generation (Dale et al., 1998; Reiter et al., 2005; Green, 2006).",2 Related work,[0],[0]
"NLG systems typically perform three different steps: content selection, where a subset of relevant slot/value pairs are selected, followed by sentence planning, where these selected pairs are realized into their respective linguistic variations, and finally surface realization, where these linguistic structures are combined to generate text.",2 Related work,[0],[0]
"Our use case differs from the above in that there is no selection done on the slot/value pairs, but all of them undergo the sentence planning step.",2 Related work,[0],[0]
"In rule-based systems, all of the above steps rely on hand-crafted rules.
",2 Related work,[0],[0]
"Data driven approaches, on the other hand, either try to learn each of the steps automatically from the data Barzilay and Lapata (2005)
",2 Related work,[0],[0]
Dale et al. (1998) described the problem of generating natural language titles and short descriptions of structured nodes which consist of slot/value pairs.,2 Related work,[0],[0]
There are many research which deal with learning a generation model from parallel data.,2 Related work,[0],[0]
"These parallel data consist of the structured data and natural-language text, so that the model can learn to transform the structured data into text.",2 Related work,[0],[0]
"Duma and Klein (2013) generate short natural-language descriptions, taking structured DBPedia data as input.",2 Related work,[0],[0]
"Their approach learns text templates which are filled with the information from the structured data.
",2 Related work,[0],[0]
"Mei et al. (September, 2015) use recurrent neural network (LSTM) models to generate text from facts given in a knowledge base.",2 Related work,[0],[0]
Chisholm et al. (2017) solve the same problem by applying a machine translation system to a linearized version of the pairs.,2 Related work,[0],[0]
Several recent papers tackle the problem of generating a one-sentence introduction for a biography given structured biographical slot/value pairs.,2 Related work,[0],[0]
"One difference between our work and the papers above, (Mei et al., September, 2015), and (Chisholm et al., 2017), is that they perform selective generation, i.e. they run a selection step that determines the slot/value pairs which will be included in the realization.",2 Related work,[0],[0]
"In our use case however, all slot/value pairs are relevant and need to be realized.
",2 Related work,[0],[0]
Serban et al. (2016) generate questions from facts (structured input) by leveraging fact embeddings and then employing placeholders for handling rare words.,2 Related work,[0],[0]
"In their work, the placeholders are heuristically mapped to the facts, however, we map our placeholders depending on the neural attention (for details, see Section 4).",2 Related work,[0],[0]
Our first step towards title generation is verbalization of all slot/value pairs.,3 Lexicalization,[0],[0]
"This can be achieved by a rule-based approach as described in (Mathur et al., 2017).",3 Lexicalization,[0],[0]
"However, in the work presented here, we do not directly lexicalize the slot/value pairs, but realize them in a pseudo language first.",3 Lexicalization,[0],[0]
"For example, the pseudo-language sequence for the slot/value pairs in Table 1 is “ brand ACME cat Cell Phones & Smart Phones color white capacity 32GB”.1
1 cat refers to an e-Commerce category in the browse page.",3 Lexicalization,[0],[0]
Pseudo-language browse pages can still contain a large number of unique slot values.,3.1 Normalization,[0],[0]
"For example, there exist many different brands for smart phones (Samsung, Apple, Huawei, etc.).",3.1 Normalization,[0],[0]
"Large vocabulary is a known problem for neural systems, because rare or less frequent words tend to translate incorrectly due to data sparseness (Luong et al., 2015).",3.1 Normalization,[0],[0]
"At the same time, the softmax computation over the large vocabulary becomes intractable in current hardware.",3.1 Normalization,[0],[0]
"To avoid this issue, we normalize the pseudo-language sequences and thereby reduce the vocabulary size.",3.1 Normalization,[0],[0]
"For each language, we computed the 30 most frequent slot names and normalized their values via placeholders (Luong et al., August, 2015).",3.1 Normalization,[0],[0]
"For example, the lexicalization of “Brand: ACME” is “ brand ACME”, but after normalization, this becomes brand $brand|ACME.",3.1 Normalization,[0],[0]
This representation means that the slot name brand has the value of a placeholder brand which contains the entity called “ACME”.,3.1 Normalization,[0],[0]
"During training, we remove the entity from the normalized sequence, while keeping them during translation of development or evaluation set.",3.1 Normalization,[0],[0]
"The mapping of placeholders in the target text back to entity names is described in Section 4.
",3.1 Normalization,[0],[0]
The largest reduction in vocabulary size would be achieved by normalizing all slots.,3.1 Normalization,[0],[0]
"However, this would create several issues in generation.",3.1 Normalization,[0],[0]
Consider the pseudo-language sequence “ bike Road bike type Racing”.,3.1 Normalization,[0],[0]
"If we replace all slot values with placeholders, i.e. “ bike $bike type $type”, then the system will not have enough information for generating the title “Road racing bike”.",3.1 Normalization,[0],[0]
"Moreover, the boolean slots, such as “ comic Marvel comics signed No” would be normalized to placeholders as “ comic $comic signed $signed”, and we would loose the information (“No”) necessary to realize this title as “Unsigned Marvel comics”.",3.1 Normalization,[0],[0]
"We applied another way of reducing the vocabulary, called byte pair encoding (BPE) (Sennrich
et al., 2016), a technique often used in NMT systems (Bojar et al., 2017).",3.2 Sub-word units,[0],[0]
BPE is essentially a data compression technique which splits each word into sub-word units and allows the NMT system to train on a smaller vocabulary.,3.2 Sub-word units,[0],[0]
One of the advantages of BPE is that it propagates generation of unseen words (even with different morphological variations).,3.2 Sub-word units,[0],[0]
"However, in our use case, this can create issues, because if BPE splits a brand and generates an incorrect brand name in the target, an e-Commerce company could be legally liable for the mistake.",3.2 Sub-word units,[0],[0]
"In such case, one can first run the normalization with placeholders followed by BPE, but due to time constraints, we do not report experiments on the same.",3.2 Sub-word units,[0],[0]
"Sequence-to-sequence models in this work are based on an encoder-decoder model and an attention mechanism as described by Bahdanau et al. (May, 2016).",4 Sequence-to-Sequence Models,[0],[0]
"In this network, the encoder is a bidirectional RNN which encodes the information of a sentence X = (x1, x2, . . .",4 Sequence-to-Sequence Models,[0],[0]
"xm) of length m into a fixed length vector of size |hi|, where hi is the hidden state produced by the encoder for token xi.",4 Sequence-to-Sequence Models,[0],[0]
"Since our encoder is a bi-directional model, the encoded hidden state is hi = hi,fwd + hi,bwd, where hfwd and hbwd are unidirectional encoders, running from left to right and right to left, respectively.",4 Sequence-to-Sequence Models,[0],[0]
"That is, they are encoding the context to the left and to the right of the current token.
",4 Sequence-to-Sequence Models,[0],[0]
"Our decoder is a simple recurrent neural network (RNN) consisting of gated recurrent units (GRU) (Cho et al., 2014) because of their computationally efficiency.",4 Sequence-to-Sequence Models,[0],[0]
"The RNN predicts the target sequence Y = (y1, y2, . . .",4 Sequence-to-Sequence Models,[0],[0]
", yj , . . .",4 Sequence-to-Sequence Models,[0],[0]
", yl) based on the final encoded state h. Basically, the RNN predicts the target token yj ∈ V (with target vocabulary V) and emits a hidden state sj based on the previous recurrent state sj−1, the previous sequence of words Yj−1 = (y1, y2, . . .",4 Sequence-to-Sequence Models,[0],[0]
", yj−1) and Cj , a weighted attention vector.",4 Sequence-to-Sequence Models,[0],[0]
The attention vector is a weighted average of all the hidden source states,4 Sequence-to-Sequence Models,[0],[0]
"hi, where i = 1, . .",4 Sequence-to-Sequence Models,[0],[0]
.,4 Sequence-to-Sequence Models,[0],[0]
",m. Attention weight (aij) is computed between the hidden states hi and sj and is leveraged as a weight of that source state hi.",4 Sequence-to-Sequence Models,[0],[0]
"In generation, we make use of these alignment scores to align our placeholders.2 The target placeholders are bijectively mapped to those
2These placeholders are not to be confused with the placeholder for a tensor.
source placeholders whose alignment score (aij) is the highest at the time of generation.
",4 Sequence-to-Sequence Models,[0],[0]
"The decoder predicts a score for all the tokens in the target vocabulary, which is then normalized by a softmax function, and the token with the highest probability is predicted.",4 Sequence-to-Sequence Models,[0],[0]
"In this section, we present the extension of our work from a single-language setting to multilanguage settings.",5 Multilingual Generation,[0],[0]
"There have been various studies in the past that target neural machine translation from multiple source languages into a single target language (Zoph and Knight, Jan, 2016), from single source to multiple target languages (Dong et al., 2015) and multiple source to multiple target languages (Johnson et al., June, 2016).",5 Multilingual Generation,[0],[0]
One of the main motivation of joint learning in above works is to improve the translation quality on a low-resource language pair via transfer learning between related languages.,5 Multilingual Generation,[0],[0]
"For example, Johnson et al. (June, 2016) had no parallel data available to train a Japanese-to-Korean MT system, but training Japanese-English and English-Korean language pairs allowed their model to learn translations from Japanese to Korean without seeing any parallel data.",5 Multilingual Generation,[0],[0]
"In our case, the amount of training data for French is small compared to English and German (cf. Section 6.1).",5 Multilingual Generation,[0],[0]
"We propose joint learning of English, French and German, because we expect that transfer learning will improve generation for French.",5 Multilingual Generation,[0],[0]
"We investigate the joint training of pairs of these languages as well the combination of all three.
",5 Multilingual Generation,[0],[0]
"On top of the multi-lingual approach, we follow the work of Currey et al. (2017) who proposed copying monolingual data on both sides (source and target) as a way to improve the performance of NMT systems on low-resource languages.",5 Multilingual Generation,[0],[0]
"In machine translation, there are often named entities and nouns which need to be translated verbatim, and this copying mechanism helps in identifying them.",5 Multilingual Generation,[0.9552600009462171],"['For example, in case (I) where all modalities are informative, all efficacies seem to be high, imply- ing that the DFG is able to find useful information in unimodal, bimodal and trimodal interactions.']"
"Since our use case is monolingual generation, we expect a large gain from this copying approach because we have many brands and other slot values which need to occur verbatim in the generated titles.",5 Multilingual Generation,[0],[0]
"We have access to a large number of humancreated titles (curated titles) for English and German, and a small number of curated titles for French.",6.1 Data,[0],[0]
"When generating these titles, human annotators were specifically asked to realize all slots in the title.
",6.1 Data,[0],[0]
"We make use of a large monolingual out-ofdomain corpus for French, as it is a low-resource language.",6.1 Data,[0],[0]
"We collect item description data from an e-Commerce website and clean the data in the following way: 1) we train a language model (LM) on the small amount of French curated titles, 2) we tokenize the out-of-domain data, 3) we remove all sentences with length less than 5, 4) we compute the LM perplexity for each sentence in the out-ofdomain data, 5) we sort the sentences in increasing order of their perplexities and 6) select the top 500K sentences.",6.1 Data,[0],[0]
Statistics of the data sets are reported in Table 2.,6.1 Data,[0],[0]
"We compared the NLG systems in the single-, dual-, and multi-lingual settings.
",6.2 Systems,[0],[0]
Single-language setting:,6.2 Systems,[0],[0]
"This is the baseline NLG system, a straightforward sequence-tosequence model with attention as described in Luong et al. (August, 2015), trained separately for each language.",6.2 Systems,[0],[0]
"The vocabulary is computed on the concatenation of both source and target data, and the same vocabulary is used for both source and target languages in the experiments.
",6.2 Systems,[0],[0]
"We use Adam (Kingma and Ba, December, 2014) as a gradient descent approach for faster convergence.",6.2 Systems,[0],[0]
Initial learning rate is set to 0.0002 with a decay rate of 0.9.,6.2 Systems,[0],[0]
"The dimension of word embeddings is set to 620 and hidden layer size to
1000.",6.2 Systems,[0],[0]
"Dropout is set to 0.2 and is activated for all layers except the initial word embedding layer, because we want to realize all aspects, we cannot afford to zero out any token in the source.",6.2 Systems,[0],[0]
"We continue training of the model and evaluate on the development set after each epoch, stopping the training if the BLEU score on the development set does not increase for 10 iterations.
",6.2 Systems,[0],[0]
Baselines:,6.2 Systems,[0],[0]
"We compare our neural system with a fair baseline system (Baseline 1), which is a statistical MT system trained on the same parallel data as the neural system: the source side is the linearized pseudo-language sequence, and the target side is the curated title in natural language.",6.2 Systems,[0],[0]
"Baseline 2 is the either the hybrid system (for French and English) or the APE system (for German), both described in Section 1.",6.2 Systems,[0],[0]
"These are unfair baselines, because (1) the hybrid system employs a large number of hand-made rules in combination with statistical models (Mathur, Ueffing, and Leusch, 2017), while the neural systems are unaware of the knowledge encoded in those rules, (2) the APE system and neural systems learn from same amount of parallel data, but the APE system aims at correcting rule-based generated titles, whereas the neural system aims at generating titles directly from a linearized form, which is a harder task.",6.2 Systems,[0],[0]
"We compare our systems with the best performing systems of (Mathur et al., 2017), i.e. hybrid system for English and French, and APE system for German.
",6.2 Systems,[0],[0]
Multi-lingual setting: We train the neural model jointly on multiple languages to leverage transfer learning from a high-resource language to a low-resource one.,6.2 Systems,[0],[0]
"In our multi-lingual setting, we experiment with three different combinations to improve models for French: 1) English+French",6.2 Systems,[0],[0]
(en-fr) 2) German+French (de-fr) 3) English+French+German (en-fr-de).,6.2 Systems,[0],[0]
"English and French being close languages, we expect the enfr system to benefit more from transfer learning across languages than any other combination.",6.2 Systems,[0],[0]
"Although, as evident in Zoph and Knight (Jan, 2016), joint learning between the distant languages works better as they tend to disambiguate each other better than two languages which are close.",6.2 Systems,[0],[0]
"For comparison, we also run a combination of two highresource languages, i.e. English and German (ende), to see if transfer learning works for them.",6.2 Systems,[0],[0]
"It is important to note that in all multi-lingual sys-
tems the low-resourced language is over-sampled to balance the data.
",6.2 Systems,[0],[0]
"We used the same design parameters on the neural network in both the single-language and the multi-lingual setting.
",6.2 Systems,[0],[0]
"Normalized setting: On top of the systems above, we also experimented with the normalization scheme presented in Section 3.1.",6.2 Systems,[0],[0]
Normalization is useful in two ways: 1) It reduces the vocabulary size and 2) it avoids spurious generation of important aspect values (slot values).,6.2 Systems,[0],[0]
The second point is especially important in our case because this avoids highly sensitive issues such as brand violations.,6.2 Systems,[0],[0]
"MT researches have observed that NMT systems often generate very fluent output, but have a tendency to generate inadequate output, i.e. sentences or words which are not related to the given input (Koehn and Knowles, June, 2017).",6.2 Systems,[0],[0]
We alleviate this problem through the normalization described above.,6.2 Systems,[0],[0]
"After normalization, we see vocabulary reductions of 15% for French, 20% for German and as high as 35% for English.
",6.2 Systems,[0],[0]
"As described in Section 5, we also use byte pair encoding, with a BPE code size of 30,000 for all systems (with BPE).",6.2 Systems,[0],[0]
We train the codes on the concatenation of source and target since (in this monolingual generation task),6.2 Systems,[0],[0]
the vocabularies are very similar; the vocabulary size is around 30k for systems using BPE for both source and target.,6.2 Systems,[0],[0]
"We evaluate our systems with three different automatic metrics: BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and character FScore (Popović, 2016).",7 Results,[0],[0]
"Note that BLEU and character F-score are quality metrics, i.e. higher scores mean higher quality, while TER is an error metric, where lower scores indicate higher quality.",7 Results,[0],[0]
"All metrics compare the automatically generated title against a human-curated title and determine sequence matches on the word or character level.
",7 Results,[0],[0]
Table 3 summarizes results from all systems on the English test set.,7 Results,[0],[0]
"All neural systems are better than the fair Baseline 1 system.
",7 Results,[0],[0]
Normalization with tags (i.e. using placeholders) has a negative effect on English title quality both in the single-language setting en (67.1 vs. 68.4 BLEU) and in the dual-language setting en-fr (67.1 vs. 70.7 BLEU).,7 Results,[0],[0]
"However, title quality increases when using BPE instead (71.9 vs. 70.7 BLEU).",7 Results,[0],[0]
"On en-de, we observe gains
both from normalization with tags and from BPE.",7 Results,[0],[0]
"Again, BPE normalization works best.",7 Results,[0],[0]
"Both duallanguage systems with BPE achieve better performance that the best monolingual English system (71.9 and 72.7 vs. 68.4 BLEU).
",7 Results,[0],[0]
"The system en-frbig contains monolingual French data added via the copying mechanism, which improves title quality.",7 Results,[0],[0]
"It outperforms any other neural system and is on par with Baseline 2 (unfair baseline), even outperforming it in terms of TER.",7 Results,[0],[0]
"The multi-lingual system en-fr-de is very close to en-frbig according to all three metrics.
",7 Results,[0],[0]
Table 4 collects the results for all systems on the German test set.,7 Results,[0],[0]
"For the single-language setting, we see a loss of 7 BLEU points when normalizing the input sequence, which is caused by incorrect morphology in the titles.",7 Results,[0],[0]
"When using placeholders, the system generates entities in the title in the exact form in which they occur in the input.",7 Results,[0],[0]
"In German, however, the words often need to be inflected.",7 Results,[0],[0]
"For example, the slot “ brand Markenlos” should be realized as “Markenlose” (Unbranded) in the title, but the placeholder generates the input form “Markenlos” (without suffix ‘e’).",7 Results,[0],[0]
"This causes a huge deterioration in the word-level met-
rics BLEU and TER, but not as drastic in chrF1, which evaluates on the character level.
",7 Results,[0],[0]
"For German, there is a positive effect of transfer learning for both dual-language systems ende and de-frbig with BPE (79.6 and 80.0 vs. 78.2 BLEU).",7 Results,[0],[0]
"However, the combination of languages hurts when we combine languages at token level, i.e. without normalization or with tags.",7 Results,[0],[0]
"The performance of systems with BPE is even on par with or better than the strong baseline of 79.4 BLEU, both for combinations of two and of three languages.
",7 Results,[0],[0]
Table 5 summarizes the results from all systems on the French test set.,7 Results,[0],[0]
The single-language fr NMT system achieves a low BLEU score compared to the SMT system Baseline 1 (23.0 vs. 44.6).,7 Results,[0],[0]
"This is due to the very small amount of parallel data, which is a setting where SMT typically outperforms NMT as evidenced in Zoph et al. (April, 2016).",7 Results,[0],[0]
"Normalization has a big positive impact on all French systems (e.g. 27.4
vs. 23.0 BLEU for fr).",7 Results,[0],[0]
"The de-fr systems show a much larger gain from transfer learning than the en-fr systems, which validates Zoph and Knight (Jan, 2016)’s results, who show that transfer learning is better for distant languages than for similar languages.
",7 Results,[0],[0]
"For all three languages, copying monolingual data improves the NMT system by a large margin.
",7 Results,[0],[0]
The multi-lingual en-fr-de (BPE) system (with copied monolingual data) is the best system for all three languages.,7 Results,[0],[0]
"It has the additional advantage of being one single model that can cater to all three languages at once.
",7 Results,[0],[0]
Table 6 presents the example titles comparing different phenomena.,7 Results,[0],[0]
"The first block shows the usefulness of placeholders in system fr small ,tags (i.e. fr small , normalized with tags) where in comparison to fr small the brand is generated verbatim.",7 Results,[0],[0]
The second block shows the effectiveness of copying the data where “Cylindres” is generated correctly in the frbig (with BPE) system in comparison to fr small .,7 Results,[0],[0]
The last block shows that reordering and adequacy in generation can be improved with the helpful signals from high-resourced English and German languages.,7 Results,[0],[0]
"We developed neural language generation systems for an e-Commerce use case for three languages with very different amounts of training data and came to the following conclusions:
(1) The lack of resources in French leads to generation of low quality titles, but this can be drastically improved upon with transfer learning between French and English and/or German.
(2)",8 Conclusion,[0],[0]
"In case of low-resource languages, copying monolingual data (even if out-of-domain) improves the performance of the system.
",8 Conclusion,[0],[0]
"(3) Normalization with placeholders usually helps for languages with relatively easy morphology.
",8 Conclusion,[0],[0]
"(4) It is important to over-sample the lowresourced languages in order to balance the high& low-resourced data, thereby, creating a stable NLG system.
",8 Conclusion,[0],[0]
"(5) For French, a low-resource language in our use case, the hybrid system which combines manual rules and SMT technology is still far better than the best neural system.
",8 Conclusion,[0],[0]
"(6) The multi-lingual model has the best tradeoff, as it achieves the best results among the neural
systems in all three languages and it is one single model which can be deployed easily on a single GPU machine.",8 Conclusion,[0],[0]
Thanks to our colleague Pavel Petrushkov for all the help with the neural MT toolkit.,Acknowledgments,[0],[0]
"To provide better access of the inventory to buyers and better search engine optimization, e-Commerce websites are automatically generating millions of easily searchable browse pages.",abstractText,[0],[0]
A browse page groups multiple items with shared characteristics together.,abstractText,[0],[0]
It consists of a set of slot name/value pairs within a given category that are linked among each other and can be organized in a hierarchy.,abstractText,[0],[0]
This structure allows users to navigate laterally between different browse pages (i.e. browse between related items) or to dive deeper and refine their search.,abstractText,[0],[0]
These browse pages require a title describing the content of the page.,abstractText,[0],[0]
"Since the number of browse pages is huge, manual creation of these titles is infeasible.",abstractText,[0],[0]
Previous statistical and neural generation approaches depend heavily on the availability of large amounts of data in a language.,abstractText,[0],[0]
"In this research, we apply sequence-tosequence models to generate titles for high& low-resourced languages by leveraging transfer learning.",abstractText,[0],[0]
"We train these models on multilingual data, thereby creating one joint model which can generate titles in various different languages.",abstractText,[0],[0]
"Performance of the title generation system is evaluated on three different languages; English, German, and French, with a particular focus on low-resourced French language.",abstractText,[0],[0]
Multi-lingual neural title generation for e-Commerce browse pages,title,[0],[0]
"Proceedings of NAACL-HLT 2013, pages 947–957, Atlanta, Georgia, 9–14 June 2013. c©2013 Association for Computational Linguistics",text,[0],[0]
Tuning algorithms are used to find the weights for a statistical machine translation (MT) model by minimizing error with respect to a single MT evaluation metric.,1 Introduction,[0],[0]
"The tuning process improves the performance of an SMT system as measured by this metric; with BLEU (Papineni et al., 2002) being the most popular choice.",1 Introduction,[0],[0]
"Minimum error-rate training (MERT) (Och, 2003) was the first approach in MT to directly optimize an evaluation metric.",1 Introduction,[0],[0]
"Several alternatives now exist: MIRA (Watanabe et al., 2007; Chiang et al., 2008), PRO (Hopkins and May, 2011), linear regression (Bazrafshan et al., 2012) and ORO (Watanabe, 2012) among others.
",1 Introduction,[0],[0]
However these approaches optimize towards the best score as reported by a single evaluation metric.,1 Introduction,[0],[0]
"MT system developers typically use BLEU and
ignore all the other metrics.",1 Introduction,[0],[0]
"This is done despite the fact that other metrics model wide-ranging aspects of translation: from measuring the translation edit rate (TER) in matching a translation output to a human reference (Snover et al., 2006), to capturing lexical choices in translation as in METEOR (Lavie and Denkowski, 2009) to modelling semantic similarity through textual entailment (Padó et al., 2009) to RIBES, an evaluation metric that pays attention to long-distance reordering (Isozaki et al., 2010).",1 Introduction,[0],[0]
"While some of these metrics such as TER, METEOR are gaining prominence, BLEU enjoys the status of being the de facto standard tuning metric as it is often claimed and sometimes observed that optimizing with BLEU produces better translations than other metrics (Callison-Burch et al., 2011).
",1 Introduction,[0],[0]
"The gains obtained by the MT system tuned on a particular metric do not improve performance as measured under other metrics (Cer et al., 2010), suggesting that over-fitting to a specific metric might happen without improvements in translation quality.",1 Introduction,[0],[0]
"In this paper we propose a new tuning framework for jointly optimizing multiple evaluation metrics.
",1 Introduction,[0],[0]
"Pareto-optimality is a natural way to think about multi-metric optimization and multi-metric optimization (MMO) was recently explored using the notion of Pareto optimality in the Pareto-based Multi-objective Optimization (PMO) approach (Duh et al., 2012).",1 Introduction,[0],[0]
PMO provides several equivalent solutions (parameter weights) having different trade-offs between the different MT metrics.,1 Introduction,[0],[0]
"In (Duh et al., 2012) the choice of which option to use rests with the MT system developer and in that sense their approach is an a posteriori method to specify the preference (Marler and Arora, 2004).
",1 Introduction,[0],[0]
"In contrast to this, our tuning framework provides a principled way of using the Pareto optimal options using ensemble decoding (Razmara et al., 2012).",1 Introduction,[0],[0]
"We also introduce a novel method of ensemble tuning for jointly tuning multiple MT evaluation metrics and further combine this with the PMO ap-
947
proach (Duh et al., 2012).",1 Introduction,[0],[0]
We also introduce three other approaches for multi-metric tuning and compare their performance to the ensemble tuning.,1 Introduction,[0],[0]
"Our experiments yield the highest metric scores across many different metrics (that are being optimized), something that has not been possible until now.
",1 Introduction,[0],[0]
Our ensemble tuning method over multiple metrics produced superior translations than single metric tuning as measured by a post-editing task.,1 Introduction,[0],[0]
"HTER (Snover et al., 2006) scores in our human evaluation confirm that multi-metric optimization can lead to better MT output.",1 Introduction,[0],[0]
"In grammar induction and parsing (Spitkovsky et al., 2011; Hall et al., 2011; Auli and Lopez, 2011) have proposed multi-objective methods based on roundrobin iteration of single objective optimizations.
",2 Related Work,[0],[0]
"Research in SMT parameter tuning has seen a surge of interest recently, including online/batch learning (Watanabe, 2012; Cherry and Foster, 2012), large-scale training (Simianer et al., 2012; He and Deng, 2012), and new discriminative objectives (Gimpel and Smith, 2012; Zheng et al., 2012; Bazrafshan et al., 2012).",2 Related Work,[0],[0]
"However, few works have investigated the multi-metric tuning problem in depth.",2 Related Work,[0],[0]
"Linear combination of BLEU and TER is reported in (Zaidan, 2009; Dyer et al., 2009; Servan and Schwenk, 2011); an alternative is to optimize on BLEU with MERT while enforcing that TER does not degrade per iteration (He and Way, 2009).",2 Related Work,[0],[0]
"Studies on metric tunability (Liu et al., 2011; CallisonBurch et al., 2011; Chen et al., 2012) have found that the metric used for evaluation may not be the best metric used for tuning.",2 Related Work,[0],[0]
"For instance, (Mauser et al., 2008; Cer et al., 2010) report that tuning on linear combinations of BLEU-TER is more robust than a single metric like WER.
",2 Related Work,[0],[0]
"The approach in (Devlin and Matsoukas, 2012) modifies the optimization function to include traits such as output length so that the hypotheses produced by the decoder have maximal score according to one metric (BLEU) but are subject to an output length constraint, e.g. that the output is 5% shorter.",2 Related Work,[0],[0]
This is done by rescoring an N-best list (forest) for the metric combined with each trait condition and then the different trait hypothesis are combined using a system combination step.,2 Related Work,[0],[0]
"The traits are in-
dependent of the reference (while tuning).",2 Related Work,[0],[0]
"In contrast, our method is able to combine multiple metrics (each of which compares to the reference) during the tuning step and we do not depend on N-best list (or forest) rescoring or system combination.
",2 Related Work,[0],[0]
Duh et.,2 Related Work,[0],[0]
"al. (2012) proposed a Pareto-based approach to SMT multi-metric tuning, where the linear combination weights do not need to be known in advance.",2 Related Work,[0],[0]
This is advantageous because the optimal weighting may not be known in advance.,2 Related Work,[0],[0]
"However, the notion of Pareto optimality implies that multiple ”best” solutions may exist, so the MT system developer may be forced to make a choice after tuning.
",2 Related Work,[0],[0]
These approaches require the MT system developer to make a choice either before tuning (e.g. in terms of linear combination weights) or afterwards (e.g. the Pareto approach).,2 Related Work,[0],[0]
Our method here is different in that we do not require any choice.,2 Related Work,[0],[0]
"We use ensemble decoding (Razmara et al., 2012) (see sec 3) to combine the different solutions resulting from the multi-metric optimization, providing an elegant solution for deployment.",2 Related Work,[0],[0]
"We extend this idea further and introduce ensemble tuning, where the metrics have separate set of weights.",2 Related Work,[0],[0]
The tuning process alternates between ensemble decoding and the update step where the weights for each metric are optimized separately followed by joint update of metric (meta) weights.,2 Related Work,[0],[0]
"We now briefly review ensemble decoding (Razmara et al., 2012) which is used as a component in the algorithms we present.",3 Ensemble Decoding,[0],[0]
"The prevalent model of statistical MT is a log-linear framework using a vector of feature functions φ:
p(e|f) ∝",3 Ensemble Decoding,[0],[0]
"exp ( w · φ ) (1)
",3 Ensemble Decoding,[0],[0]
The idea of ensemble decoding is to combine several models dynamically at decode time.,3 Ensemble Decoding,[0],[0]
"Given multiple models, the scores are combined for each partial hypothesis across the different models during decoding using a user-defined mixture operation ⊗.
p(e|f) ∝",3 Ensemble Decoding,[0],[0]
exp ( w1 · φ1 ⊗ w2 · φ2 ⊗ . . . ),3 Ensemble Decoding,[0],[0]
"(2)
(Razmara et al., 2012) propose several mixture operations, such as log-wsum (simple linear mixture), wsum (log-linear mixture) and max (choose lo-
cally best model) among others.",3 Ensemble Decoding,[0],[0]
The different mixture operations allows the user to encode the beliefs about the relative strengths of the models.,3 Ensemble Decoding,[0],[0]
It has been applied successfully for domain adaptation setting and shown to perform better approaches that pre-compute linear mixtures of different models.,3 Ensemble Decoding,[0],[0]
"In statistical MT, the multi-metric optimization problem can be expressed as:
w∗ = arg max w
g ( [M1(H), . . .",4 Multi-Metric Optimization,[0],[0]
",Mk(H)] )",4 Multi-Metric Optimization,[0],[0]
"(3)
where H = N",4 Multi-Metric Optimization,[0],[0]
"(f ;w)
where N (f ;w) is the decoding function generating a set of candidate hypotheses H based on the model parameters w, for the source sentences f .",4 Multi-Metric Optimization,[0],[0]
For each source sentence fi ∈ f there is a set of candidate hypotheses {hi} ∈ H .,4 Multi-Metric Optimization,[0],[0]
The goal of the optimization is to find the weights that maximize the function g(.),4 Multi-Metric Optimization,[0],[0]
"parameterized by different evaluation metrics M1, . . .",4 Multi-Metric Optimization,[0],[0]
",Mk.
",4 Multi-Metric Optimization,[0],[0]
"For the Pareto-optimal based approach such as PMO (Duh et al., 2012), we can replace g(·) above with gPMO(·) which returns the points in the Pareto frontier.",4 Multi-Metric Optimization,[0],[0]
"Alternately a weighted averaging function gwavg(·) would result in a linear combination of the metrics being considered, where the tuning method would maximize the joint metric.",4 Multi-Metric Optimization,[0],[0]
"This is similar to the (TER-BLEU)/2 optimization (Cer et al., 2010; Servan and Schwenk, 2011).
",4 Multi-Metric Optimization,[0],[0]
We introduce four methods based on the above formulation and each method uses a different type of g(·) function for combining different metrics and we compare experimentally with existing methods.,4 Multi-Metric Optimization,[0],[0]
"PMO (Duh et al., 2012) seeks to maximize the number of points in the Pareto frontier of the metrics considered.",4.1 PMO Ensemble,[0],[0]
The inner routine of the PMO-PRO tuning is described in Algorithm 1.,4.1 PMO Ensemble,[0],[0]
"This routine is contained within an outer loop that iterates for a fixed number iterations of decoding the tuning set and optimizing the weights.
",4.1 PMO Ensemble,[0],[0]
"The tuning process with PMO-PRO is independently repeated with different set of weights for metrics1 yielding a set of equivalent solutions
1For example",4.1 PMO Ensemble,[0],[0]
"Duh et al. (2012) use five different weight
Algorithm 1 PMO-PRO (Inner routine for tuning) 1: Input: Hypotheses H = N",4.1 PMO Ensemble,[0],[0]
"(f ;w); Weights w 2: Initialize T = {} 3: for each f in tuning set f do 4: {h} = H(f) 5: {M({h})} = ComputeMetricScore({h}, ê) 6: {F} = FindParetoFrontier({M({h})}) 7: for each h in {h} do 8: if h ∈ F then add (1, h) to T 9: else add (`, h) to T (see footnote 1) 10: wp ← PRO(T ) (optimize using PRO) 11:",4.1 PMO Ensemble,[0],[0]
"Output: Pareto-optimal weights wp
{ps1 , . . .",4.1 PMO Ensemble,[0],[0]
", psn} which are points on the Pareto frontier.",4.1 PMO Ensemble,[0],[0]
The user then chooses one solution by making a trade-off between the performance gains across different metrics.,4.1 PMO Ensemble,[0],[0]
"However, as noted earlier this a posteriori choice ignores other solutions that are indistinguishable from the chosen one.
",4.1 PMO Ensemble,[0],[0]
"We alleviate this by complementing PMO with ensemble decoding, which we call PMO ensemble, in which each point in the Pareto solution is a distinct component in the ensemble decoder.",4.1 PMO Ensemble,[0],[0]
This idea can also be used in other MMO approaches such as linear combination of metrics (gwavg(.)) mentioned above.,4.1 PMO Ensemble,[0],[0]
"In this view, PMO ensemble is a special case of ensemble combination, where the decoding is performed by an ensemble of optimal solutions.
",4.1 PMO Ensemble,[0],[0]
The ensemble combination model introduces new hyperparameters β that are the weights of the ensemble components (meta weights).,4.1 PMO Ensemble,[0],[0]
These ensemble weights could set to be uniform in a naı̈ve implementation.,4.1 PMO Ensemble,[0],[0]
"Or the user can encode her beliefs or expectations about the individual solutions {ps1 , . . .",4.1 PMO Ensemble,[0],[0]
", psn} to set the ensemble weights (based on the relative importance of the components).",4.1 PMO Ensemble,[0],[0]
"Finally, one could also include a meta-level tuning step to set the weights β.
",4.1 PMO Ensemble,[0],[0]
"The PMO ensemble approach is graphically illustrated in Figure 1; we will also refer to this figure while discussing other methods.2 The orig-
settings for metrics (M1, M2), viz.",4.1 PMO Ensemble,[0],[0]
"(0.0, 1.0), (0.3, 0.7), (0.5, 0.5), (0.7, 0.3) and (1.0, 0.0).",4.1 PMO Ensemble,[0],[0]
They combine the metric weights qi with the sentence-level metric scores Mi as ` = (∑ k qkMk ) /k,4.1 PMO Ensemble,[0],[0]
where ` is the target value for negative examples (the else line in Alg 1) in the optimization step.,4.1 PMO Ensemble,[0],[0]
"2The illustration is based on two metrics, metric-1 and metric-2, but could be applied to any number of metrics.",4.1 PMO Ensemble,[0],[0]
"Without loss of generality we assume accuracy metrics, i.e. higher
inal PMO-PRO seeks to maximize the points on the Pareto frontier (blue curve in the figure) leading to Pareto-optimal solutions.",4.1 PMO Ensemble,[0],[0]
"On the other hand, the PMO ensemble combines the different Paretooptimal solutions and potentially moving in the direction of dashed (green) arrows to some point that has higher score in either or both dimensions.",4.1 PMO Ensemble,[0],[0]
"Lateen EM has been proposed as a way of jointly optimizing multiple objectives in the context of dependency parsing (Spitkovsky et al., 2011).",4.2 Lateen MMO,[0],[0]
"It uses a secondary hard EM objective to move away, when the primary soft EM objective gets stuck in a local optima.",4.2 Lateen MMO,[0],[0]
"The course correction could be performed under different conditions leading to variations that are based on when and how often to shift from one objective function to another during optimization.
",4.2 Lateen MMO,[0],[0]
The lateen technique can be applied to the multimetric optimization in SMT by treating the different metrics as different objective functions.,4.2 Lateen MMO,[0],[0]
"While the several lateen variants are also applicable for our task, our objective here is to improve performance across the different metrics (being optimized).",4.2 Lateen MMO,[0],[0]
"Thus, we restrict ourselves to the style where the search alternates between the metrics (in round-robin fashion) at each iteration.",4.2 Lateen MMO,[0],[0]
"Since the notion of convergence is unclear in lateen setting, we stop after a fixed number of iterations optimizing the tuning set.",4.2 Lateen MMO,[0],[0]
"In terms of Figure 1, lateen MMO corresponds to alternately maximizing the metrics along two dimensions as depicted by the solid arrows.
",4.2 Lateen MMO,[0],[0]
"By the very nature of lateen-alternation, the
metric score is better.
weights obtained at each iteration are likely to be best for the metric that was optimized in that iteration.",4.2 Lateen MMO,[0],[0]
"Thus, one could use weights from the last k iterations (for lateen-tuning with as many metrics) and then decode the test set with an ensemble of these weights as in PMO ensemble.",4.2 Lateen MMO,[0],[0]
However in practice we find the weights to converge and we simply use the weights from the final iteration to decode the test set in our lateen experiments.,4.2 Lateen MMO,[0],[0]
At each iteration lateen MMO excludes all but one metric for optimization.,4.3 Union of Metrics,[0],[0]
An alternative would be to consider all the metrics at each iteration so that the optimizer could try to optimize them jointly.,4.3 Union of Metrics,[0],[0]
"This has been the general motivation for considering the linear combination of metrics (Cer et al., 2010; Servan and Schwenk, 2011) resulting in a joint metric, which is then optimized.
",4.3 Union of Metrics,[0],[0]
"However due to the scaling differences between the scores of different metrics, the linear combination might completely suppress the metric having scores in the lower-range.",4.3 Union of Metrics,[0],[0]
"As an example, the RIBES scores that are typically in the high 0.7-0.8 range, dominate the BLEU scores that is typically around 0.3.",4.3 Union of Metrics,[0],[0]
"While the weighted linear combination tries to address this imbalance, they introduce additional parameters that are manually fixed and not separately tuned.
",4.3 Union of Metrics,[0],[0]
We avoid this linear combination pitfall by taking the union of the metrics under which we consider the union of training examples from all metrics and optimize them jointly.,4.3 Union of Metrics,[0],[0]
"Mathematically,
w∗ = arg max w g(M1(H)) ∪ . . .",4.3 Union of Metrics,[0],[0]
∪ g(Mk(H)),4.3 Union of Metrics,[0],[0]
"(4)
Most of the optimization approaches involve two phases: i) select positive and negative examples and ii) optimize parameters to favour positive examples while penalizing negative ones.",4.3 Union of Metrics,[0],[0]
"In the union approach, we independently generate positive and negative sets of examples for all the metrics and take their union.",4.3 Union of Metrics,[0],[0]
"The optimizer now seeks to move towards positive examples from all metrics, while penalizing others.
",4.3 Union of Metrics,[0],[0]
"This is similar to the PMO-PRO approach except that here the optimizer tries to simultaneously maximize the number of high scoring points across all
metrics.",4.3 Union of Metrics,[0],[0]
"Thus, instead of the entire Pareto frontier curve in Figure 1, the union approach optimizes the two dimensions simultaneously in each iteration.",4.3 Union of Metrics,[0],[0]
"These methods, even though novel, under utilize the power of ensembles as they combine the solution only at the end of the tuning process.",5 Ensemble Tuning,[0],[0]
We would prefer to tightly integrate the idea of ensembles into the tuning.,5 Ensemble Tuning,[0],[0]
We thus extend the ensemble decoding to ensemble tuning.,5 Ensemble Tuning,[0],[0]
"The feature weights are replicated separately for each evaluation metric, which are treated as components in the ensemble decoding and tuned independently in the optimization step.",5 Ensemble Tuning,[0],[0]
Initially the ensemble decoder decodes a devset using a weighted ensemble to produce a single N-best list.,5 Ensemble Tuning,[0],[0]
"For the optimization, we employ a two-step approach of optimizing the feature weights (of each ensemble component) followed by a step for tuning the meta (component) weights.",5 Ensemble Tuning,[0],[0]
"The optimized weights are then used for decoding the devset in the next iteration and the process is repeated for a fixed number of iterations.
",5 Ensemble Tuning,[0],[0]
"Modifying the MMO representation in Equation 3, we formulate ensemble tuning as:
Hens = Nens ( f ; {wM};⊗; λ ) (5)
w∗ = {
arg max wMi
Hens | 1≤i≤k }
(6)
λ = arg max λ
g ({Mi(Hens)|1≤i≤k} ;w∗) (7)
Here the ensemble decoder function Nens(.) is parameterized by an ensemble of weights wM1 , . . .",5 Ensemble Tuning,[0],[0]
", wMk (denoted as {wM} in Eq 5) for each metric and a mixture operation (⊗).",5 Ensemble Tuning,[0],[0]
"λ represents the weights of the ensemble components.
",5 Ensemble Tuning,[0],[0]
Pseudo-code for ensemble tuning is shown in Algorithm 2.,5 Ensemble Tuning,[0],[0]
"In the beginning of each iteration (line 2), the tuning process ensemble decodes (line 4) the tuning set using the weights obtained from the previous iteration.",5 Ensemble Tuning,[0],[0]
"Equation 5 gives the detailed expression for the ensemble decoding, whereHens denotes the N-best list generated by the ensemble decoder.
",5 Ensemble Tuning,[0],[0]
The method now uses a dual tuning strategy involving two phases to optimize the weights.,5 Ensemble Tuning,[0],[0]
"In the first step it optimizes each of the k metrics independently (lines 6-7) along its respective dimension in
Algorithm 2 Ensemble Tuning Algorithm 1: Input: Tuning set f ,
Metrics M1, . . .",5 Ensemble Tuning,[0],[0]
",Mk (ensemble components)",5 Ensemble Tuning,[0],[0]
"Initial weights {wM} ← wM1 , . . .",5 Ensemble Tuning,[0],[0]
"wMk and Component (meta) weights λ
2: for j = 1, . . .",5 Ensemble Tuning,[0],[0]
do 3: {w(j)M },5 Ensemble Tuning,[0],[0]
"← {wM} 4: Ensemble decode the tuning set Hens = Nens(f ; {w(j)M };⊗; λ) 5: {wM} = {} 6: for each metric Mi ∈ {M} do 7: w∗Mi ← PRO(Hens, wMi) (use PRO) 8: Add w∗Mi to {wM} 9: λ← PMO-PRO(Hens, {wM}) (Alg 1)
10: Output: Optimal weights {wM} and λ
the multi-metric space (as shown by the solid arrows along the two axes in Figure 1).",5 Ensemble Tuning,[0],[0]
"This yields a new set of weights w∗ for the features in each metric.
",5 Ensemble Tuning,[0],[0]
The second tuning step (line 9) then optimizes the meta weights (λ) so as to maximize the multimetric objective along the joint k-dimensional space as shown in Equation 7.,5 Ensemble Tuning,[0],[0]
This is illustrated by the dashed arrows in the Figure 1.,5 Ensemble Tuning,[0],[0]
"While g(.) could be any function that combines multiple metrics, we use the PMO-PRO algorithm (Alg. 1) for this step.
",5 Ensemble Tuning,[0],[0]
The main difference between ensemble tuning and PMO ensemble is that the former is an ensemble model over metrics and the latter is an ensemble model over Pareto solutions.,5 Ensemble Tuning,[0],[0]
"Additionally, PMO ensemble uses the notion of ensembles only for the final decoding after tuning has completed.",5 Ensemble Tuning,[0],[0]
All the proposed methods fit naturally within the usual SMT tuning framework.,5.1 Implementation Notes,[0],[0]
"However, some changes are required in the decoder to support ensemble decoding and in the tuning scripts for optimizing with multiple metrics.",5.1 Implementation Notes,[0],[0]
"For ensemble decoding, the decoder should be able to use multiple weight vectors and dynamically combine them according to some desired mixture operation.",5.1 Implementation Notes,[0],[0]
"Note that, unlike Razmara et al. (2012), our approach uses just one model but has different weight vectors for each metric and the required decoder modifications are simpler than full ensemble decoding.
",5.1 Implementation Notes,[0],[0]
"While any of the mixture operations proposed by Razmara et al. (2012) could be used, in this pa-
per we use log-wsum – the linear combination of the ensemble components and log-wmax – the combination that prefers the locally best component.",5.1 Implementation Notes,[0],[0]
These are simpler to implement and also performed competitively in their domain adaptation experiments.,5.1 Implementation Notes,[0],[0]
"Unless explicitly noted otherwise, the results presented in Section 6 are based on linear mixture operation log-wsum, which empirically performed better than the log-wmax for ensemble tuning.",5.1 Implementation Notes,[0],[0]
We evaluate the different methods on ArabicEnglish translation in single as well as multiple references scenario.,6 Experiments,[0],[0]
Corpus statistics are shown in Table 1.,6 Experiments,[0],[0]
"For all the experiments in this paper, we use Kriya, our in-house Hierarchical phrasebased (Chiang, 2007) (Hiero) system, and integrated the required changes for ensemble decoding.",6 Experiments,[0],[0]
"Kriya performs comparably to the state of the art in phrase-based and hierarchical phrase-based translation over a wide variety of language pairs and data sets (Sankaran et al., 2012).
",6 Experiments,[0],[0]
"We use PRO (Hopkins and May, 2011) for optimizing the feature weights and PMO-PRO (Duh et al., 2012) for optimizing meta weights, wherever applicable.",6 Experiments,[0],[0]
"In both cases, we use SVMRank (Joachims, 2006) as the optimizer.
",6 Experiments,[0],[0]
We used the default parameter settings for different MT tuning metrics.,6 Experiments,[0],[0]
"For METEOR, we tried both METEOR-tune and METEOR-hter settings and found the latter to perform better in BLEU and TER scores, even though the former was marginally better in METEOR3 and RIBES scores.",6 Experiments,[0],[0]
We observed the margin of loss in BLEU and TER to outweigh the gains in METEOR and RIBES and we chose METEOR-hter setting for both optimization and evaluation of all our experiments.,6 Experiments,[0],[0]
"Unlike conventional tuning methods, PMO (Duh et al., 2012) was originally evaluated on the tuning set to avoid potential mismatch with the test set.",6.1 Evaluation on Tuning Set,[0],[0]
"In order to ensure robustness of evaluation, they redecode the devset using the optimal weights from the last tuning iteration and report the scores on 1-
3This behaviour was also noted by Denkowski and Lavie (2011) in their analysis of Urdu-English system for tunable metrics task in WMT11.
best candidates.
",6.1 Evaluation on Tuning Set,[0],[0]
We follow the same strategy and compare our PMO-ensemble approach with PMO-PRO (denoted P) and a linear combination4 (denoted L) baseline.,6.1 Evaluation on Tuning Set,[0],[0]
"Similar to Duh et al. (2012), we use five different BLEU:",6.1 Evaluation on Tuning Set,[0],[0]
"RIBES weight settings, viz.",6.1 Evaluation on Tuning Set,[0],[0]
"(0.0, 1.0), (0.3, 0.7), (0.5, 0.5), (0.7, 0.3) and (1.0, 0.0), marked L1 through L5 or P1 through P5.",6.1 Evaluation on Tuning Set,[0],[0]
"The Pareto frontier is then computed from 80 points (5 runs and 15 iterations per run) on the devset.
",6.1 Evaluation on Tuning Set,[0],[0]
Figure 2(a) shows the Pareto frontier of L and P baselines using BLEU and RIBES as two metrics.,6.1 Evaluation on Tuning Set,[0],[0]
"The frontier of the P dominates that of L for most part showing that the PMO approach benefits from picking Pareto points during the optimization.
",6.1 Evaluation on Tuning Set,[0],[0]
We use the PMO-ensemble approach to combine the optimized weights from the 5 tuning runs and re-decode the devset employing ensemble decoding.,6.1 Evaluation on Tuning Set,[0],[0]
This yields the points LEns,6.1 Evaluation on Tuning Set,[0],[0]
"and PEns in the plot, which obtain better scores than most of the individual runs of L and P. This ensemble approach of combining the final weights also generalizes to the unseen test set as we show later.
",6.1 Evaluation on Tuning Set,[0],[0]
Figure 2(b) plots the change in BLEU during tuning in the multiple references and the single reference scenarios.,6.1 Evaluation on Tuning Set,[0],[0]
"We show for each baseline method L and P, plots for two different weight settings that obtain high BLEU and RIBES scores.",6.1 Evaluation on Tuning Set,[0],[0]
"In both datasets, our ensemble tuning approach dominates the curves of the (L and P) baselines.",6.1 Evaluation on Tuning Set,[0],[0]
"In summary, these results confirm that the ensemble approach achieves results that are competitive with previous MMO methods on the devset Pareto curve.",6.1 Evaluation on Tuning Set,[0],[0]
We now provide a more comprehensive evaluation on the test set.,6.1 Evaluation on Tuning Set,[0],[0]
"This section contains multi-metric optimization results on the unseen test sets, one test set has multiple references and the other has a single-reference.
",6.2 Evaluation on Test Set,[0],[0]
"4Linear combination is a generalized version of the combined (TER-BLEU)/2 metric and its variants.
",6.2 Evaluation on Test Set,[0],[0]
"We plot BLEU scores against other metrics (RIBES, METEOR and TER) and this allows us to compare the performance of each metric relative to the defacto standard BLEU metric.
",6.2 Evaluation on Test Set,[0],[0]
"Baseline points are identified by single letters B for BLEU, T for TER, etc. and the baseline (singlemetric optimized) score for each metric is indicated by a dashed line on the corresponding axis.",6.2 Evaluation on Test Set,[0],[0]
"MMO points use a series of single letters referring to the metrics used, e.g. BT for BLEU-TER.",6.2 Evaluation on Test Set,[0],[0]
The union of metrics method is identified with the suffix ’J’ and lateen method with suffix ’L’ (thus BT-L refers to the lateen tuning with BLEU-TER).,6.2 Evaluation on Test Set,[0],[0]
"MMO points without any suffix use the ensemble tuning approach.
",6.2 Evaluation on Test Set,[0],[0]
Figures 3 and 4(a) plot the scores for the MTA test set with 4-references.,6.2 Evaluation on Test Set,[0],[0]
We see noticeable and some statistically significant improvements in BLEU and RIBES (see Table 2 for BLEU improvements).,6.2 Evaluation on Test Set,[0],[0]
"All our MMO approaches, except for the union method, show gains on both BLEU and RIBES axes.",6.2 Evaluation on Test Set,[0],[0]
Figures 3(b) and 4(a) show that none of the proposed methods managed to improve the baseline scores for METEOR and TER.,6.2 Evaluation on Test Set,[0],[0]
"However, several of our ensemble tuning combinations work well for both METEOR (BR, BMRTB3, etc.) and TER (BMRT and BRT) in that they improved or were close to the baseline scores in either dimension.",6.2 Evaluation on Test Set,[0],[0]
"We again see in these figures that the MMO approaches can improve the BLEU-only tuning by 0.3 BLEU points, without much drop in other metrics.",6.2 Evaluation on Test Set,[0],[0]
"This is in tune with the finding that BLEU could be tuned easily (CallisonBurch et al., 2011) and also explains why it remains
a popular choice for optimizing SMT systems.",6.2 Evaluation on Test Set,[0],[0]
Among the different MMO methods the ensemble tuning performs better than lateen or union approaches.,6.2 Evaluation on Test Set,[0],[0]
"In terms of the number of metrics being optimized jointly, we see substantial gains when using a small number (typically 2 or 3) of metrics.",6.2 Evaluation on Test Set,[0],[0]
"Results seem to suffer beyond this number; probably because there might not be a space that contain solution(s) optimal for all the metrics that are jointly optimized.
",6.2 Evaluation on Test Set,[0],[0]
"We hypothesize that each metric correlates well
(in a looser sense) with few others, but not all.",6.2 Evaluation on Test Set,[0],[0]
"For example, union optimizations BR-J and BMT-J perform close to or better than RIBES and TER baselines, but get very poor score in METEOR.",6.2 Evaluation on Test Set,[0],[0]
"On the other hand BM-J is close to the METEOR baseline, while doing poorly on the RIBES and TER.",6.2 Evaluation on Test Set,[0],[0]
"This behaviour is also evident from the single-metric baselines, where R and T-only settings are clearly distinguished from the M-only system.",6.2 Evaluation on Test Set,[0],[0]
"It is not clear if such distinct classes of metrics could be bridged by some optimal solution and the metric dichotomy requires further study as this is key to practical multimetric tuning in SMT.
",6.2 Evaluation on Test Set,[0],[0]
The lateen and union approaches appear to be very sensitive to the number of metrics and they generally perform well for two metrics case and show degradation for more metrics.,6.2 Evaluation on Test Set,[0],[0]
"Unlike other
approaches, the union approach failed to improve over the baseline BLEU and this could be attributed to the conflict of interest among the metrics, while choosing example points for the optimization step.",6.2 Evaluation on Test Set,[0],[0]
The positive example preferred by a particular metric could be a negative example for the other metric.,6.2 Evaluation on Test Set,[0],[0]
This would only confuse the optimizer resulting in poor solutions.,6.2 Evaluation on Test Set,[0],[0]
"Our future line of work would be to study the effect of avoiding such of conflicting examples in the union approach.
",6.2 Evaluation on Test Set,[0],[0]
"For the single-reference (ISI) dataset, we only plot the BLEU-TER case in Figure 4(b) due to lack of space.",6.2 Evaluation on Test Set,[0],[0]
The results are similar to the multiple references set indicating that MMO approaches are equally effective for single references5.,6.2 Evaluation on Test Set,[0],[0]
"Table 2
5One could argue that MMO methods require multiple references since each metric might be picking out a different ref-
shows the BLEU scores for our ensemble tuning method (for various combinations) and we again see improvements over the baseline BLEU-only tuning.",6.2 Evaluation on Test Set,[0],[0]
So far we have shown that multi-metric optimization can improve over single-metric tuning on a single metric like BLEU and we have shown that our methods find a tuned model that performs well with respect to multiple metrics.,6.3 Human Evaluation,[0],[0]
Is the output that scores higher on multiple metrics actually a better translation?,6.3 Human Evaluation,[0],[0]
"To verify this, we conducted a post-editing human evaluation experiment.",6.3 Human Evaluation,[0],[0]
"We compared our ensemble tuning approach involving BLEU, METEOR and RIBES (B-M-R) with systems optimized for BLEU (B-only) and METEOR (M-only).
",6.3 Human Evaluation,[0],[0]
We selected 100 random sentences (that are at least 15 words long) from the Arabic-English MTA (4 references) test set and translated them using the three systems (two single metric systems and BMR ensemble tuning).,6.3 Human Evaluation,[0],[0]
We shuffled the resulting translations and split them into 3 sets such that each set has equal number of the translations from three systems.,6.3 Human Evaluation,[0],[0]
"The translations were edited by three human annotators in a post-editing setup, where the goal was to edit the translations to make them as close to the references as possible, using the Post-Editing Tool: PET (Aziz et al., 2012).",6.3 Human Evaluation,[0],[0]
The annotators were not Arabic-literate and relied only on the reference translations during post-editing.,6.3 Human Evaluation,[0],[0]
"The identifiers that link each translation to the system that generated it are removed to avoid annotator bias.
",6.3 Human Evaluation,[0],[0]
"In the end we collated post-edited translations for each system and then computed the system-level
erence sentence.",6.3 Human Evaluation,[0],[0]
"Our experiment shows that even with a single reference MMO methods can work.
",6.3 Human Evaluation,[0],[0]
"human-targeted (HBLEU, HMETEOR, HTER) scores, by using respective post-edited translations as the reference.",6.3 Human Evaluation,[0],[0]
"First comparing the HTER (Snover et al., 2006) scores shown in Table 3, we see that the single-metric system optimized for METEOR performs slightly worse than the one optimized for BLEU, despite using METEOR-hter version (Denkowski and Lavie, 2011).",6.3 Human Evaluation,[0],[0]
"Ensemble tuning-based system optimized for three metrics (BM-R) improves HTER by 4% and 6.3% over BLEU and METEOR optimized systems respectively.
",6.3 Human Evaluation,[0],[0]
"The single-metric system tuned with M-only setting scores high on HBLEU, closely followed by the ensemble system.",6.3 Human Evaluation,[0],[0]
We believe this to be caused by chance rather than any systematic gains by the Monly tuning; the ensemble system scores high on HMETEOR compared to the M-only system.,6.3 Human Evaluation,[0],[0]
"While HTER captures the edit distance to the targeted reference, HMETEOR and HBLEU metrics capture missing content words or synonyms by exploiting n-grams and paraphrase matching.
",6.3 Human Evaluation,[0],[0]
"We also computed the regular variants (BLEU, METEOR and TER), which are scored against original references.",6.3 Human Evaluation,[0],[0]
The ensemble system outperformed the single-metric systems in all the three metrics.,6.3 Human Evaluation,[0],[0]
The improvements were also statistically significant at p-value of 0.05 for BLEU and TER.,6.3 Human Evaluation,[0],[0]
We propose and present a comprehensive study of several multi-metric optimization (MMO) methods in SMT.,7 Conclusion,[0],[0]
"First, by exploiting the idea of ensemble decoding (Razmara et al., 2012), we propose an effective way to combine multiple Pareto-optimal model weights from previous MMO methods (e.g. Duh et al. (2012)), obviating the need for manually trading off among metrics.",7 Conclusion,[0],[0]
"We also proposed two new variants: lateen-style MMO and union of metrics.
",7 Conclusion,[0],[0]
We also extended ensemble decoding to a new tuning algorithm called ensemble tuning.,7 Conclusion,[0],[0]
This method demonstrates statistically significant gains for BLEU and RIBES with modest reduction in METEOR and TER.,7 Conclusion,[0],[0]
"Further, in our human evaluation, ensemble tuning obtains the best HTER among competing baselines, confirming that optimizing on multiple metrics produces human-preferred translations compared to the conventional optimization approach involving a single metric.",7 Conclusion,[0],[0]
This paper examines tuning for statistical machine translation (SMT) with respect to multiple evaluation metrics.,abstractText,[0],[0]
"We propose several novel methods for tuning towards multiple objectives, including some based on ensemble decoding methods.",abstractText,[0],[0]
"Pareto-optimality is a natural way to think about multi-metric optimization (MMO) and our methods can effectively combine several Pareto-optimal solutions, obviating the need to choose one.",abstractText,[0],[0]
Our best performing ensemble tuning method is a new algorithm for multi-metric optimization that searches for Pareto-optimal ensemble models.,abstractText,[0],[0]
We study the effectiveness of our methods through experiments on multiple as well as single reference(s) datasets.,abstractText,[0],[0]
"Our experiments show simultaneous gains across several metrics (BLEU, RIBES), without any significant reduction in other metrics.",abstractText,[0],[0]
This contrasts the traditional tuning where gains are usually limited to a single metric.,abstractText,[0],[0]
"Our human evaluation results confirm that in order to produce better MT output, optimizing multiple metrics is better than optimizing only one.",abstractText,[0],[0]
Multi-Metric Optimization Using Ensemble Tuning,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1092–1102 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Multimedia data (including text, image, audio and video) have increased dramatically recently, which makes it difficult for users to obtain important information efficiently.",1 Introduction,[0],[0]
"Multi-modal summarization (MMS) can provide users with textual summaries that can help acquire the gist of multimedia data in a short time, without reading documents or watching videos from beginning to end.
",1 Introduction,[0],[0]
"1http://www.nlpr.ia.ac.cn/cip/jjzhang.htm
The existing applications related to MMS include meeting record summarization (Erol et al., 2003; Gross et al., 2000), sport video summarization (Tjondronegoro et al., 2011; Hasan et al., 2013), movie summarization (Evangelopoulos et al., 2013; Mademlis et al., 2016), pictorial storyline summarization (Wang et al., 2012), timeline summarization (Wang et al., 2016b) and social multimedia summarization (Del Fabro et al., 2012; Bian et al., 2013; Schinas et al., 2015; Bian et al., 2015; Shah et al., 2015, 2016).",1 Introduction,[0],[0]
"When summarizing meeting recordings, sport videos and movies, such videos consist of synchronized voice, visual and captions.",1 Introduction,[0],[0]
"For the summarization of pictorial storylines, the input is a set of images with text descriptions.",1 Introduction,[0],[0]
"None of these applications focus on summarizing multimedia data that contain asynchronous information about general topics.
",1 Introduction,[0],[0]
"In this paper, as shown in Figure 1, we propose an approach to a generate textual summary from a set of asynchronous documents, images, audios and videos on the same topic.
",1 Introduction,[0],[0]
"Since multimedia data are heterogeneous and contain more complex information than pure text does, MMS faces a great challenge in addressing the semantic gap between different modalities.",1 Introduction,[0],[0]
The framework of our method is shown in Figure 1.,1 Introduction,[0],[0]
"For the audio information contained in videos, we obtain speech transcriptions through Automatic Speech Recognition (ASR) and design a method to use these transcriptions selectively.",1 Introduction,[0],[0]
"For visual information, including the key-frames extracted from videos and the images that appear in documents, we learn the joint representations of texts and images by using a neural network; we then can identify the text that is relevant to the image.",1 Introduction,[0],[0]
"In this way, audio and visual information can be integrated into a textual summary.
",1 Introduction,[0],[0]
"Traditional document summarization involves two essential aspects: (1) Salience: the summa-
1092
ry should retain significant content of the input documents.",1 Introduction,[0],[0]
(2) Non-redundancy: the summary should contain as little redundant content as possible.,1 Introduction,[0],[0]
"For MMS, we consider two additional aspects: (3) Readability: because speech transcriptions are occasionally ill-formed, we should try to get rid of the errors introduced by ASR.",1 Introduction,[0],[0]
"For example, when a transcription provides similar information to a sentence in documents, we should prefer the sentence to the transcription presented in the summary.",1 Introduction,[0],[0]
(4) Coverage for the visual information: images that appear in documents and videos often capture event highlights that are usually very important.,1 Introduction,[0],[0]
"Thus, the summary should cover as much of the important visual information as possible.",1 Introduction,[0],[0]
"All of the aspects can be jointly optimized by the budgeted maximization of submodular functions (Khuller et al., 1999).
",1 Introduction,[0],[0]
"Our main contributions are as follows:
• We design an MMS method that can automatically generate a textual summary from a set of asynchronous documents, images, audios and videos related to a specific topic.
",1 Introduction,[0],[0]
"• To select the representative sentences, we consider four criteria that are jointly optimized by the budgeted maximization of submodular functions.
",1 Introduction,[0],[0]
• We introduce an MMS corpus in English and Chinese.,1 Introduction,[0],[0]
The experimental results on this dataset demonstrate that our system can take advantage of multi-modal information and outperforms other baseline methods.,1 Introduction,[0],[0]
"Multi-document summarization (MDS) attempts to extract important information for a set of documents related to a topic to generate a short sum-
mary.",2.1 Multi-document Summarization,[0],[0]
"Graph based methods (Mihalcea and Tarau, 2004; Wan and Yang, 2006; Zhang et al., 2016) are commonly used.",2.1 Multi-document Summarization,[0],[0]
"LexRank (Erkan and Radev, 2011) first builds a graph of the documents, in which each node represents a sentence and the edges represent the relationship between sentences.",2.1 Multi-document Summarization,[0],[0]
"Then, the importance of each sentence is computed through an iterative random walk.",2.1 Multi-document Summarization,[0],[0]
"In recent years, much work has been done to summarize meeting recordings, sport videos, movies, pictorial storylines and social multimedia.
",2.2 Multi-modal Summarization,[0],[0]
"Erol et al. (2003) aim to create important segments of a meeting recording based on audio, text and visual activity analysis.",2.2 Multi-modal Summarization,[0],[0]
Tjondronegoro et al. (2011) propose a way to summarize a sporting event by analyzing the textual information extracted from multiple resources and identifying the important content in a sport video.,2.2 Multi-modal Summarization,[0],[0]
Evangelopoulos et al. (2013) use an attention mechanism to detect salient events in a movie.,2.2 Multi-modal Summarization,[0],[0]
Wang et al. (2012) and Wang et al. (2016b) use image-text pairs to generate a pictorial storyline and timeline summarization.,2.2 Multi-modal Summarization,[0],[0]
"Li et al. (2016) develop an approach for multimedia news summarization for searching results on the Internet, in which the hLDA model is introduced to discover the topic structure of the news documents.",2.2 Multi-modal Summarization,[0],[0]
"Then, a news article and an image are chosen to represent each topic.",2.2 Multi-modal Summarization,[0],[0]
"For social media summarization, Fabro et al. (2012) and Schinas et al. (2015) propose to summarize the real-life events based on multimedia content such as photos from Flickr and videos from YouTube.",2.2 Multi-modal Summarization,[0],[0]
Bian et al. (2013; 2015) propose a multimodal LDA to detect topics by capturing the correlations between textual and visual features of microblogs with embedded images.,2.2 Multi-modal Summarization,[0],[0]
The output of their method is a set of representative images that describe the events.,2.2 Multi-modal Summarization,[0],[0]
"Shah et al. (2015; 2016) introduce EventBuilder
which produces text summaries for a social event leveraging Wikipedia and visualizes the event with social media activities.
",2.2 Multi-modal Summarization,[0],[0]
"Most of the above studies focus on synchronous multi-modal content, i.e., in which images are paired with text descriptions and videos are paired with subtitles.",2.2 Multi-modal Summarization,[0],[0]
"In contrast, we perform summarization from asynchronous (i.e., there is no given description for images and no subtitle for videos) multi-modal information about news topics, including multiple documents, images and videos, to generate a fixed length textual summary.",2.2 Multi-modal Summarization,[0],[0]
This task is both more general and more challenging.,2.2 Multi-modal Summarization,[0],[0]
"The input is a collection of multi-modal dataM = {D1, ..., D|D|, V1, ..., V|V |} related to a news topic T , where each document Di = {Ti, Ii} consists of text Ti and image Ii (there may be no image for some documents).",3.1 Problem Formulation,[0],[0]
Vi denotes video.,3.1 Problem Formulation,[0],[0]
| · | denotes the cardinality of a set.,3.1 Problem Formulation,[0],[0]
The objective of our work is to automatically generate textual summary to represent the principle content ofM.,3.1 Problem Formulation,[0],[0]
There are many essential aspects in generating a good textual summary for multi-modal data.,3.2 Model Overview,[0],[0]
"The salient content in documents should be retained, and the key facts in videos and images should be covered.",3.2 Model Overview,[0],[0]
"Further, the summary should be readable and non-redundant and should follow the fixed length constraint.",3.2 Model Overview,[0],[0]
"We propose an extraction-based method in which all these aspects can be jointly optimized by the budgeted maximization of submodular functions defined as follows:
max S⊆T {F(S) : ∑ s∈S ls ≤ L} (1)
where T is the set of sentences, S is the summary, ls is length (number of words) of sentence s, L is budget, i.e., length constraint for the summary, and submodular function F(S) is the summary score related to the above-mentioned aspects.
",3.2 Model Overview,[0],[0]
"Text is the main modality of documents, and in some cases, images are embedded in documents.",3.2 Model Overview,[0],[0]
Videos consist of at least two types of modalities: audio and visual.,3.2 Model Overview,[0],[0]
"Next, we give overall processing methods for different modalities.
",3.2 Model Overview,[0],[0]
"Audio, i.e., speech, can be automatically transcribed into text by using an ASR system2.",3.2 Model Overview,[0],[0]
"Then, we can leverage a graph-based method to calculate the salience score for all of the speech transcriptions and for the original sentences in documents.",3.2 Model Overview,[0],[0]
"Note that speech transcriptions are often ill-formed; thus, to improve the readability, we should try to avoid the errors introduced by ASR.",3.2 Model Overview,[0],[0]
"In addition, audio features including acoustic confidence (Valenza et al., 1999), audio power (Christel et al., 1998) and audio magnitude (Dagtas and Abdel-Mottaleb, 2001) have proved to be helpful for speech and video summarization which will benefit our method.
",3.2 Model Overview,[0],[0]
"For visual, which is actually a sequence of images (frames), because most of the neighboring frames contain redundant information, we first extract the most meaningful frames, i.e., the keyframes, which can provide the key facts for the whole video.",3.2 Model Overview,[0],[0]
"Then, it is necessary to perform semantic analysis between text and visual.",3.2 Model Overview,[0],[0]
"To this end, we learn the joint representations for textual and visual modalities and can then identify the sentence that is relevant to the image.",3.2 Model Overview,[0],[0]
"In this way, we can guarantee the coverage of generated summary for the visual information.",3.2 Model Overview,[0],[0]
"We apply a graph-based LexRank algorithm (Erkan and Radev, 2011) to calculate salience score of the text unit, including the sentences in documents and the speech transcriptions from videos.",3.3 Salience for Text,[0],[0]
"LexRank first constructs a graph based on the text units and their relationship and then conducts an iteratively random walk to calculate the salience score of the text unit, sa(ti), until convergence using the following equation:
Sa(ti) = µ ∑
j
Sa(tj) ·Mji + 1− µ N (2)
where µ is the damping factor that is set to 0.85.",3.3 Salience for Text,[0],[0]
N is the total number of the text units.,3.3 Salience for Text,[0],[0]
"Mji is the relationship between text unit ti and tj , which is computed as follows:
",3.3 Salience for Text,[0],[0]
"Mji = sim(tj , ti) (3)
",3.3 Salience for Text,[0],[0]
"The text unit ti is represented by averaging the embeddings of the words (except stop-words) in ti. sim(·) denotes cosine similarity between two texts (negative similarities are replaced with 0).
",3.3 Salience for Text,[0],[0]
"2We use IBM Watson Speech to Text service: www.ibm.com/watson/developercloud/speech-to-text.html
For MMS task, we propose two guidance strategies to amend the affinity matrix M and calculate salience score of the text as shown in Figure 2.",3.3 Salience for Text,[0],[0]
The random walk process can be understood as a recommendation: Mji in Equation 2 denotes that tj will recommend ti to the degree of Mji.,3.3.1 Readability Guidance Strategies,[0],[0]
"The affinity matrix M in the LexRank model is symmetric, which means Mij = Mji.",3.3.1 Readability Guidance Strategies,[0],[0]
"In contrast, for MMS, considering the unsatisfactory quality of speech recognition, symmetric affinity matrices are inappropriate.",3.3.1 Readability Guidance Strategies,[0],[0]
"Specifically, to improve the readability, for a speech transcription, if there is a sentence in document that is related to this transcription, we would prefer to assign the text sentence a higher salience score than that assigned to the transcribed one.",3.3.1 Readability Guidance Strategies,[0],[0]
"To this end, the process of a random walk should be guided to control the recommendation direction: when a document sentence is related to a speech transcription, the symmetric weighted edge between them should be transformed into a unidirectional edge, in which we invalidate the direction from document sentence to the transcribed one.",3.3.1 Readability Guidance Strategies,[0],[0]
"In this way, speech transcriptions will not be recommended by the corresponding document sentences.",3.3.1 Readability Guidance Strategies,[0],[0]
Important speech transcriptions that cannot be covered by documents still have the chance to obtain high salience scores.,3.3.1 Readability Guidance Strategies,[0],[0]
"For the pair of a sentence ti and a speech transcription tj , Mij is computed as follows:
Mij = {
0, if sim(ti, tj) >",3.3.1 Readability Guidance Strategies,[0],[0]
"Ttext sim(ti, tj), otherwise
(4) where threshold Ttext is used to determine whether a sentence is related to others.",3.3.1 Readability Guidance Strategies,[0],[0]
"We obtain the proper semantic similarity threshold by testing on Microsoft Research Paraphrase (MSRParaphrase) dataset (Quirk et al., 2004).",3.3.1 Readability Guidance Strategies,[0],[0]
"It is a publicly avail-
able paraphrase corpus that consists of 5801 pairs of sentences, of which 3900 pairs are semantically equivalent.",3.3.1 Readability Guidance Strategies,[0],[0]
Some audio features can guide the summarization system to select more important and readable speech transcriptions.,3.3.2 Audio Guidance Strategies,[0],[0]
Valenza et al. (1999) use acoustic confidence to obtain accurate and readable summaries of broadcast news programs.,3.3.2 Audio Guidance Strategies,[0],[0]
Christel et al. (1998) and Dagtas and AbdelMottaleb (2001) apply audio power and audio magnitude to find significant audio events.,3.3.2 Audio Guidance Strategies,[0],[0]
"In our work, we first balance these three feature scores for each speech transcription by dividing their respective maximum values among the whole amount of audio, and we then average these scores to obtain the final audio score for speech transcription.",3.3.2 Audio Guidance Strategies,[0],[0]
"For each adjacent speech transcription pair (tk, tk′ ), if the audio score a(tk) for tk is smaller than a certain threshold while a(tk′ ) is greater, which means that tk′ is more important and readable than tk, then tk should recommend tk′ , but tk′ should not recommend tk.",3.3.2 Audio Guidance Strategies,[0],[0]
"We formulate it as follows: {
Mkk′ = sim(tk, tk′ )",3.3.2 Audio Guidance Strategies,[0],[0]
"Mk′k = 0
if a(tk)",3.3.2 Audio Guidance Strategies,[0],[0]
< Taudio and a(tk′ ),3.3.2 Audio Guidance Strategies,[0],[0]
>,3.3.2 Audio Guidance Strategies,[0],[0]
"Taudio (5)
where the threshold Taudio is the average audio score for all the transcriptions in the audio.
",3.3.2 Audio Guidance Strategies,[0],[0]
"Finally, affinity matrices are normalized so that each row adds up to 1.",3.3.2 Audio Guidance Strategies,[0],[0]
The key-frames contained in videos and the images embedded in documents often captures news highlights in which the important ones should be covered by the textual summary.,3.4 Text-Image Matching,[0],[0]
"Before measuring the coverage for images, we should train the model to bridge the gap between text and image, i.e., to match the text and image.
",3.4 Text-Image Matching,[0],[0]
We start by extracting key-frames of videos based on shot boundary detection.,3.4 Text-Image Matching,[0],[0]
A shot is defined as an unbroken sequence of frames.,3.4 Text-Image Matching,[0],[0]
"The abrupt transition of RGB histogram features often indicates shot boundaries (Zhuang et al., 1998).",3.4 Text-Image Matching,[0],[0]
"Specifically, when the transition of the RGB histogram feature for adjacent frames is greater than a certain ratio3 of the average transition for the whole video, we segment the shot.",3.4 Text-Image Matching,[0],[0]
"Then, the frames
3The ratio is determined by testing on the
in the middle of each shot are extracted as keyframes.",3.4 Text-Image Matching,[0],[0]
"These key-frames and images in documents make up the image set that the summary should cover.
",3.4 Text-Image Matching,[0],[0]
"Next, it is necessary to perform a semantic analysis between the text and the image.",3.4 Text-Image Matching,[0],[0]
"To this end, we learn the joint representations for textual and visual modalities by using a model trained on the Flickr30K dataset (Young et al., 2014), which contains 31,783 photographs of everyday activities, events and scenes harvested from Flickr.",3.4 Text-Image Matching,[0],[0]
Each photograph is manually labeled with 5 textual descriptions.,3.4 Text-Image Matching,[0],[0]
"We apply the framework of Wang et al. (2016a), which achieves state-of-the-art performance for text-image matching task on the Flickr30K dataset.",3.4 Text-Image Matching,[0],[0]
"The image is encoded by the VGG model (Simonyan and Zisserman, 2014) that has been trained on the ImageNet classification task following the standard procedure (Wang et al., 2016a).",3.4 Text-Image Matching,[0],[0]
The 4096-dimensional feature from the pre-softmax layer is used to represent the image.,3.4 Text-Image Matching,[0],[0]
The text is first encoded by the Hybrid GaussianLaplacian mixture model (HGLMM) using the method of Klein et al. (2014).,3.4 Text-Image Matching,[0],[0]
"Then, the HGLMM vectors are reduced to 6000 dimensions through PCA.",3.4 Text-Image Matching,[0],[0]
"Next, the sentence vector vs and image vector vi are mapped to a joint space by a two-branch neural network as follows:{
x = W2 · f(W1 · vs + bs) y = V2 · f(V1 · vi + bi) (6)
where W1 ∈",3.4 Text-Image Matching,[0],[0]
"R2048×6000, bs ∈ R2048, W2 ∈",3.4 Text-Image Matching,[0],[0]
"R512×2048, V1 ∈ R2048×4096, bi ∈ R2048,",3.4 Text-Image Matching,[0],[0]
"V2 ∈ R512×2048, f is Rectified Linear Unit (ReLU).
",3.4 Text-Image Matching,[0],[0]
"The max-margin learning framework is applied to optimize the neural network as follows:
L = ∑ i,k max[0,m+ s(xi, yi)− s(xi, yk)]
+ λ1 ∑ i,k max[0,m+ s(xi, yi)− s(xk, yi)] (7)
where for positive text-image pair (xi, yi), the top K most violated negative pairs (xi, yk) and (xk, yi) in each mini-batch are sampled.",3.4 Text-Image Matching,[0],[0]
"The objective function L favors higher matching score s(xi, yi) (cosine similarity) for positive text-image pairs than for negative pairs4.
shot detection dataset of TRECVID.",3.4 Text-Image Matching,[0],[0]
"http://wwwnlpir.nist.gov/projects/trecvid/
4In the experiments, K = 50, m = 0.1 and λ1 = 2.",3.4 Text-Image Matching,[0],[0]
"Wang et al. (2016a) also proved that structure-preserving constraints can make 1% Recall@1 improvement.
",3.4 Text-Image Matching,[0],[0]
Note that the images in Flickr30K are similar to our task.,3.4 Text-Image Matching,[0],[0]
"However, the image descriptions are much simpler than the text in news, so the model trained on Flickr30K cannot be directly used for our task.",3.4 Text-Image Matching,[0],[0]
"For example, some of the information contained in the news, such as the time and location of events, cannot be directly reflected by images.",3.4 Text-Image Matching,[0],[0]
"To solve this problem, we simplify each sentence and speech transcription based on semantic role labelling (Gildea and Jurafsky, 2002), in which each predicate indicates an event and the arguments express the relevant information of this event.",3.4 Text-Image Matching,[0],[0]
"ARG0 denotes the agent of the event, and ARG1 denotes the action.",3.4 Text-Image Matching,[0],[0]
"The assumption is that the concepts including agent, predicate and action compose the body of the event, so we extract “ARG0+predicate+ARG1” as the simplified sentence that is used to match the images.",3.4 Text-Image Matching,[0],[0]
"It is worth noting that there may be multiple predicateargument structures for one sentence and we extract all of them.
",3.4 Text-Image Matching,[0],[0]
"After the text-image matching model is trained and the sentences are simplified, for each textimage pair (Ti, Ij) in our task, we can identify the matched pairs if the score s(Ti, Ij) is greater than a threshold Tmatch.",3.4 Text-Image Matching,[0],[0]
"We set the threshold as the average matching score for the positive text-image pair in Flickr30K, although the matching performance for our task could in principle be improved by adjusting this parameter.",3.4 Text-Image Matching,[0],[0]
"We model the salience of a summary S as the sum of salience scores Sa(ti)5 of the sentence ti in the summary, combining a λ-weighted redundancy penalty term:
Fs(S) = ∑ ti∈S Sa(ti)− λs|S| ∑ ti,tj∈S sim(ti, tj) (8)
We model the summary S coverage for the image set I as the weighted sum of image covered by the summary:
Fc(S) = ∑ pi∈I Im(pi)bi (9)
where the weight Im(pi) for the image pi is the length ratio between the shot pi and the whole videos.",3.5 Multi-modal Summarization,[0],[0]
"bi is a binary variable to indicate
5Normalized by the maximum value among all the sentences.
",3.5 Multi-modal Summarization,[0],[0]
"whether an image pi is covered by the summary, i.e., whether there is at least one sentence in the summary matching the image.
",3.5 Multi-modal Summarization,[0],[0]
"Finally, considering all the modalities, the objective function is defined as follows:
Fm(S)",3.5 Multi-modal Summarization,[0],[0]
= 1 Ms ∑ ti∈S Sa(ti) + 1,3.5 Multi-modal Summarization,[0],[0]
"Mc ∑ pi∈I Im(pi)bi
− λm|S| ∑ i,j∈S sim(ti, tj)
(10) where Ms is the summary score obtained by Equation 8 and Mc is the summary score obtained by Equation 9.",3.5 Multi-modal Summarization,[0],[0]
The aim of Ms and Mc is to balance the aspects of salience and coverage for images.,3.5 Multi-modal Summarization,[0],[0]
"λs, and λm are determined by testing on development set.",3.5 Multi-modal Summarization,[0],[0]
"Note that to guaranteed monotone of F , λs, and λm should be lower than the minimum salience score of sentences.",3.5 Multi-modal Summarization,[0],[0]
"To further improve non-redundancy, we make sure that similarity between any pair of sentences in the summary is lower than Ttext.
",3.5 Multi-modal Summarization,[0],[0]
"Equations 8,9 and 10 are all monotone submodular functions under the budget constraint.",3.5 Multi-modal Summarization,[0],[0]
"Thus, we apply the greedy algorithm (Lin and Bilmes, 2010) guaranteeing near-optimization to solve the problem.",3.5 Multi-modal Summarization,[0],[0]
There is no benchmark dataset for MMS.,4.1 Dataset,[0],[0]
We construct a dataset as follows.,4.1 Dataset,[0],[0]
"We select 50 news topics in the most recent five years, 25 in English and 25 in Chinese.",4.1 Dataset,[0],[0]
We set 5 topics for each language as a development set.,4.1 Dataset,[0],[0]
"For each topic, we collect 20 documents within the same period using Google News search6 and 5-10 videos in CCTV.com7 and Youtube8.",4.1 Dataset,[0],[0]
More details of the corpus are illustrated in Table 1.,4.1 Dataset,[0],[0]
"Some examples of news topics are provided Table 2.
",4.1 Dataset,[0],[0]
We employ 10 graduate students to write reference summaries after reading documents and watching videos on the same topic.,4.1 Dataset,[0],[0]
We keep 3 reference summaries for each topic.,4.1 Dataset,[0],[0]
"The criteria for summarizing documents lie in: (1) retaining important content of the input documents and videos; (2) avoiding redundant information; (3) having a
6http://news.google.com/ 7http://www.cctv.com/ 8https://www.youtube.com/
good readability; (4) following the length limit.",4.1 Dataset,[0],[0]
"We set the length constraint for each English and Chinese summary to 300 words and 500 characters, respectively.",4.1 Dataset,[0],[0]
"Several models are compared in our experiments, including generating summaries with different modalities and different approaches to leverage images.
",4.2 Comparative Methods,[0],[0]
Text only.,4.2 Comparative Methods,[0],[0]
"This model generates summaries only using the text in documents.
",4.2 Comparative Methods,[0],[0]
Text + audio.,4.2 Comparative Methods,[0],[0]
"This model generates summaries using the text in documents and the speech transcriptions but without guidance strategies.
",4.2 Comparative Methods,[0],[0]
Text + audio + guide.,4.2 Comparative Methods,[0],[0]
"This model generates summaries using the text in documents and the speech transcriptions with guidance strategies.
",4.2 Comparative Methods,[0],[0]
The following models generate summaries using both documents and videos but take advantage of images in different ways.,4.2 Comparative Methods,[0],[0]
"The salience scores for text are obtained with guidance strategies.
",4.2 Comparative Methods,[0],[0]
Image caption.,4.2 Comparative Methods,[0],[0]
The image is first captioned using the model of Vinyals et al. (2016) which achieved first place in the 2015 MSCOCO Image Captioning Challenge.,4.2 Comparative Methods,[0],[0]
"This model generates summaries using text in documents, speech transcription and image captions.
",4.2 Comparative Methods,[0],[0]
"Note that the above-mentioned methods generate summaries by using Equation 8 and the follow-
ing methods using Equation 8 ,9 and 10.",4.2 Comparative Methods,[0],[0]
Image caption match.,4.2 Comparative Methods,[0],[0]
"This model uses generated image captions to match the text; i.e., if the similarity between a generated image caption and a sentence exceeds the threshold Ttext, the image and the sentence match.
",4.2 Comparative Methods,[0],[0]
Image alignment.,4.2 Comparative Methods,[0],[0]
"The images are aligned to the text in the following ways: The images in a document are aligned to all the sentences in this document and the key-frames in a shot are aligned to all the speech transcriptions in this shot.
",4.2 Comparative Methods,[0],[0]
Image match.,4.2 Comparative Methods,[0],[0]
The texts are matched with images using the approach introduced in Section 3.4.,4.2 Comparative Methods,[0],[0]
"We perform sentence9 and word tokenization, and all the Chinese sentences are segmented by Stanford Chinese Word Segmenter (Tseng et al., 2005).",4.3 Implementation Details,[0],[0]
"We apply Stanford CoreNLP toolkit (Levy and D. Manning, 2003; Klein and D. Manning, 2003) to perform lexical parsing and use semantic role labelling approach proposed by Yang and Zong (2014).",4.3 Implementation Details,[0],[0]
We use 300-dimension skipgram English word embeddings which are publicly available10.,4.3 Implementation Details,[0],[0]
"Given that text-image matching model and image caption generation model are trained in English, to create summaries in Chinese, we first translate the Chinese text into English via Google Translation11 and then conduct text and image matching.",4.3 Implementation Details,[0],[0]
"We use the ROUGE-1.5.5 toolkit (Lin and Hovy, 2003) to evaluate the output summaries.",4.4 Multi-modal Summarization Evaluation,[0],[0]
This evaluation metric measures the summary quality by matching n-grams between generated summary and reference summary.,4.4 Multi-modal Summarization Evaluation,[0],[0]
"Table 3 and Table 4 show the averaged ROUGE-1 (R-1), ROUGE-2 (R-2) and ROUGE-SU4 (R-SU4) F-scores regarding to the three reference summaries for each topic in English and Chinese.
",4.4 Multi-modal Summarization Evaluation,[0],[0]
"For the results of the English MMS, from the first three lines in Table 3 we can see that when summarizing without visual information, the method with guidance strategies performs slightly better than do the first two methods.",4.4 Multi-modal Summarization Evaluation,[0],[0]
"Because Rouge mainly measures word overlaps, manual evaluation is needed to confirm the impact of guidance strategies on improving readability.",4.4 Multi-modal Summarization Evaluation,[0],[0]
"It is in-
9We exclude sentences containing less than 5 words.",4.4 Multi-modal Summarization Evaluation,[0],[0]
"10https://code.google.com/archive/p/word2vec/ 11https://translate.google.com
troduced in Section 4.5.",4.4 Multi-modal Summarization Evaluation,[0],[0]
The rating ranges from 1 (the poorest) to 5 (the best).,4.4 Multi-modal Summarization Evaluation,[0],[0]
"When summarizing with textual and visual modalities, performances are not always improved, which indicates that the models of image caption, image caption match and image alignment are not suitable to MMS.",4.4 Multi-modal Summarization Evaluation,[0],[0]
"The image match model has a significant advantage over other comparative methods, which illustrates that it can make use of multi-modal information.
",4.4 Multi-modal Summarization Evaluation,[0],[0]
"Table 4 shows the Chinese MMS results, which are similar to the English results that the image match model achieves the best performance.",4.4 Multi-modal Summarization Evaluation,[0],[0]
"We find that the performance enhancement for the image match model is smaller in Chinese than it is in English, which may be due to the errors introduced by machine translation.
",4.4 Multi-modal Summarization Evaluation,[0],[0]
"We provides a generated summary in English using the image match model, which is shown in Figure 3.",4.4 Multi-modal Summarization Evaluation,[0],[0]
The readability and informativeness for summaries are difficult to evaluate formally.,4.5 Manual Summary Quality Evaluation,[0],[0]
We ask five graduate students to measure the quality of summaries generated by different methods.,4.5 Manual Summary Quality Evaluation,[0],[0]
"We calculate the average score for all of the topics, and the results are displayed in Table 5.",4.5 Manual Summary Quality Evaluation,[0],[0]
"Overall, our method with guidance strategies achieves higher scores than do the other methods, but it is still obviously poorer than the reference sum-
maries.",4.5 Manual Summary Quality Evaluation,[0],[0]
"Specifically, when speech transcriptions are not considered, the informativeness of the summary is the worst.",4.5 Manual Summary Quality Evaluation,[0],[0]
"However, adding speech transcriptions without guidance strategies decreases readability to a large extent, which indicates that guidance strategies are necessary for MMS.",4.5 Manual Summary Quality Evaluation,[0],[0]
"The image match model achieves higher informativeness scores than do the other methods without using images.
",4.5 Manual Summary Quality Evaluation,[0],[0]
We give two instances of readability guidance that arise between document text (DT) and speech transcriptions (ST) in Table 6.,4.5 Manual Summary Quality Evaluation,[0],[0]
The errors introduced by ASR include segmentation (instance A) and recognition (instance B) mistakes.,4.5 Manual Summary Quality Evaluation,[0],[0]
Text-image matching is the toughest module for our framework.,4.6 How Much is the Image Worth,[0],[0]
"Although we use a state-of-the-art approach to match the text and images, the performance is far from satisfactory.",4.6 How Much is the Image Worth,[0],[0]
"To find a somewhat strong upper-bound of the task, we choose five topics for each language to manually label the text-image matching pairs.",4.6 How Much is the Image Worth,[0],[0]
The MMS results on these topics are shown in Table 7 and Table 8.,4.6 How Much is the Image Worth,[0],[0]
"The experiments show that with the ground truth textimage matching result, the summary quality can be promoted to a considerable extent, which indicates visual information is crucial for MMS.
",4.6 How Much is the Image Worth,[0],[0]
An image and the corresponding texts obtained using different methods are given in Figure 4 an d Figure 5.,4.6 How Much is the Image Worth,[0],[0]
"We can conclude that the image caption
and the image caption match contain little of the image’s intrinsically intended information.",4.6 How Much is the Image Worth,[0],[0]
"The image alignment introduces more noise because it is possible that the whole text in documents or the speech transcriptions in shot are aligned to the document images or the key-frames, respectively.",4.6 How Much is the Image Worth,[0],[0]
"The image match can obtain similar results to the image manually match, which illustrates that the image match can make use of visual information to generate summaries.",4.6 How Much is the Image Worth,[0],[0]
"This paper addresses an asynchronous MMS task, namely, how to use related text, audio and video information to generate a textual summary.",5 Conclusion,[0],[0]
We formulate the MMS task as an optimization problem with a budgeted maximization of submodular functions.,5 Conclusion,[0],[0]
"To selectively use the transcription of audio, guidance strategies are designed using the graph model to effectively calculate the salience score for each text unit, leading to more readable and informative summaries.",5 Conclusion,[0],[0]
"We investigate various approaches to identify the relevance between the image and texts, and find that the image match model performs best.",5 Conclusion,[0],[0]
"The final experimental results obtained using our MMS corpus in both English and Chinese demonstrate that our system can benefit from multi-modal information.
",5 Conclusion,[0],[0]
"Adding audio and video does not seem to improve dramatically over text only model, which indicates that better models are needed to capture the interactions between text and other modalities, especially for visual.",5 Conclusion,[0],[0]
"We also plan to enlarge our MMS dataset, specifically to collect more videos.",5 Conclusion,[0],[0]
The research work has been supported by the Natural Science Foundation of China under Grant No. 61333018 and No. 61403379.,Acknowledgments,[0],[0]
"The rapid increase in multimedia data transmission over the Internet necessitates the multi-modal summarization (MMS) from collections of text, image, audio and video.",abstractText,[0],[0]
"In this work, we propose an extractive multi-modal summarization method that can automatically generate a textual summary given a set of documents, images, audios and videos related to a specific topic.",abstractText,[0],[0]
The key idea is to bridge the semantic gaps between multi-modal content.,abstractText,[0],[0]
"For audio information, we design an approach to selectively use its transcription.",abstractText,[0],[0]
"For visual information, we learn the joint representations of text and images using a neural network.",abstractText,[0],[0]
"Finally, all of the multimodal aspects are considered to generate the textual summary by maximizing the salience, non-redundancy, readability and coverage through the budgeted optimization of submodular functions.",abstractText,[0],[0]
"We further introduce an MMS corpus in English and Chinese, which is released to the public1.",abstractText,[0],[0]
The experimental results obtained on this dataset demonstrate that our method outperforms other competitive baseline methods.,abstractText,[0],[0]
"Multi-modal Summarization for Asynchronous Collection of Text, Image, Audio and Video",title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1918–1927 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1918",text,[0],[0]
"Machine reading comprehension (MRC), empowering computers with the ability to acquire knowledge and answer questions from textual data, is believed to be a crucial step in building a general intelligent agent (Chen et al., 2016).",1 Introduction,[0],[0]
Recent years have seen rapid growth in the MRC community.,1 Introduction,[0],[0]
"With the release of various datasets, the MRC task has evolved from the early cloze-style test (Hermann et al., 2015; Hill et al., 2015) to answer extraction from a single passage (Rajpurkar et al.,
*This work was done while the first author was doing internship at Baidu Inc.
2016) and to the latest more complex question answering on web data (Nguyen et al., 2016; Dunn et al., 2017; He et al., 2017).
",1 Introduction,[0],[0]
"Great efforts have also been made to develop models for these MRC tasks , especially for the answer extraction on single passage (Wang and Jiang, 2016; Seo et al., 2016; Pan et al., 2017).",1 Introduction,[0],[0]
"A significant milestone is that several MRC models have exceeded the performance of human annotators on the SQuAD dataset1 (Rajpurkar et al., 2016).",1 Introduction,[0],[0]
"However, this success on single Wikipedia passage is still not adequate, considering the ultimate goal of reading the whole web.",1 Introduction,[0],[0]
"Therefore, several latest datasets (Nguyen et al., 2016; He et al., 2017; Dunn et al., 2017) attempt to design the MRC tasks in more realistic settings by involving search engines.",1 Introduction,[0],[0]
"For each question, they use the search engine to retrieve multiple passages and the MRC models are required to read these passages in order to give the final answer.
",1 Introduction,[0],[0]
"One of the intrinsic challenges for such multipassage MRC is that since all the passages are question-related but usually independently written, it’s probable that multiple confusing answer candidates (correct or incorrect) exist.",1 Introduction,[0],[0]
Table 1 shows an example from MS-MARCO.,1 Introduction,[0],[0]
We can see that all the answer candidates have semantic matching with the question while they are literally different and some of them are even incorrect.,1 Introduction,[0],[0]
"As is shown by Jia and Liang (2017), these confusing answer candidates could be quite difficult for MRC models to distinguish.",1 Introduction,[0],[0]
"Therefore, special consideration is required for such multi-passage MRC problem.
",1 Introduction,[0],[0]
"In this paper, we propose to leverage the answer candidates from different passages to verify the final correct answer and rule out the noisy incorrect answers.",1 Introduction,[0],[0]
"Our hypothesis is that the cor-
1https://rajpurkar.github.io/SQuAD-explorer/
rect answers could occur more frequently in those passages and usually share some commonalities, while incorrect answers are usually different from one another.",1 Introduction,[0],[0]
The example in Table 1 demonstrates this phenomenon.,1 Introduction,[0],[0]
"We can see that the answer candidates extracted from the last four passages are all valid answers to the question and they are semantically similar to each other, while the answer candidates from the other two passages are incorrect and there is no supportive information from other passages.",1 Introduction,[0],[0]
"As human beings usually compare the answer candidates from different sources to deduce the final answer, we hope that MRC model can also benefit from the cross-passage answer verification process.
",1 Introduction,[0],[0]
"The overall framework of our model is demonstrated in Figure 1 , which consists of three modules.",1 Introduction,[0],[0]
"First, we follow the boundary-based MRC models (Seo et al., 2016; Wang and Jiang, 2016) to find an answer candidate for each passage by identifying the start and end position of the answer (Figure 2).",1 Introduction,[0],[0]
"Second, we model the meanings of the answer candidates extracted from those passages and use the content scores to measure the quality of the candidates from a second perspective.",1 Introduction,[0],[0]
"Third, we conduct the answer verification by enabling each answer candidate to attend to the other candidates based on their representations.",1 Introduction,[0],[0]
"We hope that the answer candidates can collect supportive information from each other according to their semantic similarities and further decide whether each candidate is correct or not.
",1 Introduction,[0],[0]
"Therefore, the final answer is determined by three factors: the boundary, the content and the crosspassage answer verification.",1 Introduction,[0],[0]
"The three steps are modeled using different modules, which can be jointly trained in our end-to-end framework.
",1 Introduction,[0],[0]
"We conduct extensive experiments on the MSMARCO (Nguyen et al., 2016) and DuReader (He et al., 2017) datasets.",1 Introduction,[0],[0]
The results show that our answer verification MRC model outperforms the baseline models by a large margin and achieves the state-of-the-art performance on both datasets.,1 Introduction,[0],[0]
"Figure 1 gives an overview of our multi-passage MRC model which is mainly composed of three modules including answer boundary prediction, answer content modeling and answer verification.",2 Our Approach,[0],[0]
"First of all, we need to model the question and passages.",2 Our Approach,[0],[0]
"Following Seo et al. (2016), we compute the question-aware representation for each passage (Section 2.1).",2 Our Approach,[0],[0]
"Based on this representation, we employ a Pointer Network (Vinyals et al., 2015) to predict the start and end position of the answer in the module of answer boundary prediction (Section 2.2).",2 Our Approach,[0],[0]
"At the same time, with the answer content model (Section 2.3), we estimate whether each word should be included in the answer and thus obtain the answer representations.",2 Our Approach,[0],[0]
"Next, in the answer verification module (Section 2.4), each answer candidate can attend to the other answer candidates to collect supportive information and we compute one score for each candidate
to indicate whether it is correct or not according to the verification.",2 Our Approach,[0],[0]
The final answer is determined by not only the boundary but also the answer content and its verification score (Section 2.5).,2 Our Approach,[0],[0]
"Given a question Q and a set of passages {Pi} retrieved by search engines, our task is to find the best concise answer to the question.",2.1 Question and Passage Modeling,[0],[0]
"First, we formally present the details of modeling the question and passages.
",2.1 Question and Passage Modeling,[0],[0]
Encoding We first map each word into the vector space by concatenating its word embedding and sum of its character embeddings.,2.1 Question and Passage Modeling,[0],[0]
"Then we employ bi-directional LSTMs (BiLSTM) to encode the question Q and passages {Pi} as follows:
uQt = BiLSTMQ(u Q t−1, [e Q t , c Q t ]) (1) uPit = BiLSTMP",2.1 Question and Passage Modeling,[0],[0]
"(u Pi t−1, [e Pi t , c Pi t ]) (2)
where eQt , c Q t , e Pi t , c Pi t are the word-level and character-level embeddings of the tth word.",2.1 Question and Passage Modeling,[0],[0]
"uQt and uPit are the encoding vectors of the t
th words in Q and Pi respectively.",2.1 Question and Passage Modeling,[0],[0]
"Unlike previous work (Wang et al., 2017c) that simply concatenates all the passages, we process the passages independently at the encoding and matching steps.
",2.1 Question and Passage Modeling,[0],[0]
Q-P Matching One essential step in MRC is to match the question with passages so that important information can be highlighted.,2.1 Question and Passage Modeling,[0],[0]
"We use the
Attention Flow Layer (Seo et al., 2016) to conduct the Q-P matching in two directions.",2.1 Question and Passage Modeling,[0],[0]
"The similarity matrix S ∈ R|Q|×|Pi| between the question and passage i is changed to a simpler version, where the similarity between the tth word in the question and the kth word in passage i is computed as:
St,k = u Q t ᵀ · uPik (3)
",2.1 Question and Passage Modeling,[0],[0]
Then the context-to-question attention and question-to-context attention is applied strictly following Seo et al. (2016) to obtain the questionaware passage representation {ũPit }.,2.1 Question and Passage Modeling,[0],[0]
We do not give the details here due to space limitation.,2.1 Question and Passage Modeling,[0],[0]
"Next, another BiLSTM is applied in order to fuse the contextual information and get the new representation for each word in the passage, which is regarded as the match output:
vPit = BiLSTMM (v Pi t−1, ũ Pi t ) (4)
",2.1 Question and Passage Modeling,[0],[0]
"Based on the passage representations, we introduce the three main modules of our model.",2.1 Question and Passage Modeling,[0],[0]
"To extract the answer span from passages, mainstream studies try to locate the boundary of the answer, which is called boundary model.",2.2 Answer Boundary Prediction,[0],[0]
"Following (Wang and Jiang, 2016), we employ Pointer Network (Vinyals et al., 2015) to compute the probability of each word to be the start or end position
of the span:
gtk = w",2.2 Answer Boundary Prediction,[0],[0]
a 1 ᵀ tanh(Wa2,2.2 Answer Boundary Prediction,[0],[0]
"[v P k ,h a t−1]) (5)
αtk = exp(g t k)/ ∑|P| j=1 exp(gtj) (6)
ct = ∑|P|
k=1 αtkv P k (7)
hat = LSTM(h a t−1, ct) (8)
By utilizing the attention weights, the probability of the kth word in the passage to be the start and end position of the answer is obtained as α1k and α2k.",2.2 Answer Boundary Prediction,[0],[0]
"It should be noted that the pointer network is applied to the concatenation of all passages, which is denoted as P so that the probabilities are comparable across passages.",2.2 Answer Boundary Prediction,[0],[0]
"This boundary model can be trained by minimizing the negative log probabilities of the true start and end indices:
Lboundary = − 1
N N∑ i=1",2.2 Answer Boundary Prediction,[0],[0]
"(logα1y1i + logα2y2i ) (9)
where N is the number of samples in the dataset and y1i , y 2 i are the gold start and end positions.",2.2 Answer Boundary Prediction,[0],[0]
Previous work employs the boundary model to find the text span with the maximum boundary score as the final answer.,2.3 Answer Content Modeling,[0],[0]
"However, in our context, besides locating the answer candidates, we also need to model their meanings in order to conduct the verification.",2.3 Answer Content Modeling,[0],[0]
"An intuitive method is to compute the representation of the answer candidates separately after extracting them, but it could be hard to train such model end-to-end.",2.3 Answer Content Modeling,[0],[0]
"Here, we propose a novel method that can obtain the representation of the answer candidates based on probabilities.
",2.3 Answer Content Modeling,[0],[0]
"Specifically, we change the output layer of the classic MRC model.",2.3 Answer Content Modeling,[0],[0]
"Besides predicting the boundary probabilities for the words in the passages, we also predict whether each word should be included in the content of the answer.",2.3 Answer Content Modeling,[0],[0]
"The content probability of the kth word is computed as:
pck = sigmoid(w c 1 ᵀReLU(Wc2v Pi k ))",2.3 Answer Content Modeling,[0],[0]
"(10)
Training this content model is also quite intuitive.",2.3 Answer Content Modeling,[0],[0]
"We transform the boundary labels into a continuous segment, which means the words within the answer span will be labeled as 1 and other words will be labeled as 0.",2.3 Answer Content Modeling,[0],[0]
"In this way, we define
the loss function as the averaged cross entropy:
Lcontent =− 1
N
1
|P| N∑ i=1 |P",2.3 Answer Content Modeling,[0],[0]
|∑ j=1,2.3 Answer Content Modeling,[0],[0]
"[yck log p c k
+ (1− yck) log(1− pck)]
(11)
",2.3 Answer Content Modeling,[0],[0]
The content probabilities provide another view to measure the quality of the answer in addition to the boundary.,2.3 Answer Content Modeling,[0],[0]
"Moreover, with these probabilities, we can represent the answer from passage i as a weighted sum of all the word embeddings in this passage:
rAi = 1 |Pi| ∑|Pi|",2.3 Answer Content Modeling,[0],[0]
k=1 pck[e,2.3 Answer Content Modeling,[0],[0]
"Pi k , c Pi k ] (12)",2.3 Answer Content Modeling,[0],[0]
"The boundary model and the content model focus on extracting and modeling the answer within a single passage respectively, with little consideration of the cross-passage information.",2.4 Cross-Passage Answer Verification,[0],[0]
"However, as is discussed in Section 1, there could be multiple answer candidates from different passages and some of them may mislead the MRC model to make an incorrect prediction.",2.4 Cross-Passage Answer Verification,[0],[0]
It’s necessary to aggregate the information from different passages and choose the best one from those candidates.,2.4 Cross-Passage Answer Verification,[0],[0]
"Therefore, we propose a method to enable the answer candidates to exchange information and verify each other through the cross-passage answer verification process.
",2.4 Cross-Passage Answer Verification,[0],[0]
"Given the representation of the answer candidates from all passages {rAi}, each answer candidate then attends to other candidates to collect supportive information via attention mechanism:
si,j = { 0, if i = j, rAi ᵀ · rAj , otherwise (13)
",2.4 Cross-Passage Answer Verification,[0],[0]
"αi,j = exp(si,j)/",2.4 Cross-Passage Answer Verification,[0],[0]
"∑n
k=1 exp(si,k) (14) r̃Ai = ∑n
j=1 αi,jr
Aj (15)
",2.4 Cross-Passage Answer Verification,[0],[0]
Here r̃Ai is the collected verification information from other passages based on the attention weights.,2.4 Cross-Passage Answer Verification,[0],[0]
"Then we pass it together with the original representation rAi to a fully connected layer:
gvi = w vᵀ[rAi , r̃Ai , rAi r̃Ai ] (16)
We further normalize these scores over all passages to get the verification score for answer candidate Ai:
pvi = exp(g v i )/",2.4 Cross-Passage Answer Verification,[0],[0]
"∑n j=1 exp(gvj ) (17)
",2.4 Cross-Passage Answer Verification,[0],[0]
"In order to train this verification model, we take the answer from the gold passage as the gold answer.",2.4 Cross-Passage Answer Verification,[0],[0]
"And the loss function can be formulated as the negative log probability of the correct answer:
Lverify =",2.4 Cross-Passage Answer Verification,[0],[0]
"− 1
N N∑ i=1",2.4 Cross-Passage Answer Verification,[0],[0]
"log pvyvi (18)
where yvi is the index of the correct answer in all the answer candidates of the ith instance .",2.4 Cross-Passage Answer Verification,[0],[0]
"As is described above, we define three objectives for the reading comprehension model over multiple passages: 1. finding the boundary of the answer; 2. predicting whether each word should be included in the content; 3. selecting the best answer via cross-passage answer verification.",2.5 Joint Training and Prediction,[0],[0]
"According to our design, these three tasks can share the same embedding, encoding and matching layers.",2.5 Joint Training and Prediction,[0],[0]
"Therefore, we propose to train them together as multi-task learning (Ruder, 2017).",2.5 Joint Training and Prediction,[0],[0]
"The joint objective function is formulated as follows:
L = Lboundary + β1Lcontent + β2Lverify (19)
where β1 and β2 are two hyper-parameters that control the weights of those tasks.
",2.5 Joint Training and Prediction,[0],[0]
"When predicting the final answer, we take the boundary score, content score and verification score into consideration.",2.5 Joint Training and Prediction,[0],[0]
We first extract the answer candidateAi that has the maximum boundary score from each passage i. This boundary score is computed as the product of the start and end probability of the answer span.,2.5 Joint Training and Prediction,[0],[0]
"Then for each answer candidate Ai, we average the content probabilities of all its words as the content score of Ai.",2.5 Joint Training and Prediction,[0],[0]
And we can also predict the verification score for Ai using the verification model.,2.5 Joint Training and Prediction,[0],[0]
"Therefore, the final answer can be selected from all the answer candidates according to the product of these three scores.",2.5 Joint Training and Prediction,[0],[0]
"To verify the effectiveness of our model on multipassage machine reading comprehension, we conduct experiments on the MS-MARCO (Nguyen et al., 2016) and DuReader (He et al., 2017) datasets.",3 Experiments,[0],[0]
Our method achieves the state-of-the-art performance on both datasets.,3 Experiments,[0],[0]
"We choose the MS-MARCO and DuReader datasets to test our method, since both of them are
designed from real-world search engines and involve a large number of passages retrieved from the web.",3.1 Datasets,[0],[0]
"One difference of these two datasets is that MS-MARCO mainly focuses on the English web data, while DuReader is designed for Chinese MRC.",3.1 Datasets,[0],[0]
This diversity is expected to reflect the generality of our method.,3.1 Datasets,[0],[0]
"In terms of the data size, MS-MARCO contains 102023 questions, each of which is paired up with approximately 10 passages for reading comprehension.",3.1 Datasets,[0],[0]
"As for DuReader, it keeps the top-5 search results for each question and there are totally 201574 questions.
",3.1 Datasets,[0],[0]
One prerequisite for answer verification is that there should be multiple correct answers so that they can verify each other.,3.1 Datasets,[0],[0]
Both the MS-MARCO and DuReader datasets require the human annotators to generate multiple answers if possible.,3.1 Datasets,[0],[0]
Table 2 shows the proportion of questions that have multiple answers.,3.1 Datasets,[0],[0]
"However, the same answer that occurs many times is treated as one single answer here.",3.1 Datasets,[0],[0]
"Therefore, we also report the proportion of questions that have multiple answer spans to match with the human-generated answers.",3.1 Datasets,[0],[0]
A span is taken as valid if it can achieve F1 score larger than 0.7 compared with any reference answer.,3.1 Datasets,[0],[0]
"From these statistics, we can see that the phenomenon of multiple answers is quite common for both MS-MARCO and DuReader.",3.1 Datasets,[0],[0]
These answers will provide strong signals for answer verification if we can leverage them properly.,3.1 Datasets,[0],[0]
"For MS-MARCO, we preprocess the corpus with the reversible tokenizer from Stanford CoreNLP",3.2 Implementation Details,[0],[0]
"(Manning et al., 2014) and we choose the span that achieves the highest ROUGE-L score with the reference answers as the gold span for training.",3.2 Implementation Details,[0],[0]
"We employ the 300-D pre-trained Glove embeddings (Pennington et al., 2014) and keep it fixed during training.",3.2 Implementation Details,[0],[0]
The character embeddings are randomly initialized with its dimension as 30.,3.2 Implementation Details,[0],[0]
"For DuReader, we follow the preprocessing described in He et al. (2017).
",3.2 Implementation Details,[0],[0]
"We tune the hyper-parameters according to the
validation performance on the MS-MARCO development set.",3.2 Implementation Details,[0],[0]
The hidden size is set to be 150 and we apply L2 regularization with its weight as 0.0003.,3.2 Implementation Details,[0],[0]
"The task weights β1, β2 are both set to be 0.5.",3.2 Implementation Details,[0],[0]
"To train our model, we employ the Adam algorithm (Kingma and Ba, 2014) with the initial learning rate as 0.0004 and the mini-batch size as 32.",3.2 Implementation Details,[0],[0]
"Exponential moving average is applied on all trainable variables with a decay rate 0.9999.
",3.2 Implementation Details,[0],[0]
Two simple yet effective technologies are employed to improve the final performance on these two datasets respectively.,3.2 Implementation Details,[0],[0]
"For MS-MARCO, approximately 8% questions have the answers as Yes or No, which usually cannot be solved by extractive approach (Tan et al., 2017).",3.2 Implementation Details,[0],[0]
"We address this problem by training a simple Yes/No classifier for those questions with certain patterns (e.g., starting with “is”).",3.2 Implementation Details,[0],[0]
"Concretely, we simply change the output layer of the basic boundary model so that it can predict whether the answer is “Yes” or “No”.",3.2 Implementation Details,[0],[0]
"For DuReader, the retrieved document usually contains a large number of paragraphs that cannot be fed into MRC models directly (He et al., 2017).",3.2 Implementation Details,[0],[0]
"The original paper employs a simple a simple heuristic strategy to select a representative paragraph for each document, while we train a paragraph ranking model for this.",3.2 Implementation Details,[0],[0]
We will demonstrate the effects of these two technologies later.,3.2 Implementation Details,[0],[0]
Table 3 shows the results of our system and other state-of-the-art models on the MS-MARCO test set.,3.3 Results on MS-MARCO,[0],[0]
"We adopt the official evaluation metrics, including ROUGE-L (Lin, 2004) and BLEU-1 (Papineni et al., 2002).",3.3 Results on MS-MARCO,[0],[0]
"As we can see, for both metrics, our single model outperforms all the other competing models with an evident margin, which is extremely hard considering the near-human per-
formance.",3.3 Results on MS-MARCO,[0],[0]
"If we ensemble the models trained with different random seeds and hyper-parameters, the results can be further improved and outperform the ensemble model in Tan et al. (2017), especially in terms of the BLEU-1.",3.3 Results on MS-MARCO,[0],[0]
The results of our model and several baseline systems on the test set of DuReader are shown in Table 4.,3.4 Results on DuReader,[0],[0]
"The BiDAF and Match-LSTM models are provided as two baseline systems (He et al., 2017).",3.4 Results on DuReader,[0],[0]
"Based on BiDAF, as is described in Section 3.2, we tried a new paragraph selection strategy by employing a paragraph ranking (PR) model.",3.4 Results on DuReader,[0],[0]
We can see that this paragraph ranking can boost the BiDAF baseline significantly.,3.4 Results on DuReader,[0],[0]
"Finally, we implement our system based on this new strategy, and our system (single model) achieves further improvement by a large margin.",3.4 Results on DuReader,[0],[0]
"To get better insight into our system, we conduct in-depth ablation study on the development set of MS-MARCO, which is shown in Table 5.",4.1 Ablation Study,[0],[0]
"Following Tan et al. (2017), we mainly focus on the ROUGE-L score that is averaged case by case.
",4.1 Ablation Study,[0],[0]
We first evaluate the answer verification by ablating the cross-passage verification model so that the verification loss and verification score will not be used during training and testing.,4.1 Ablation Study,[0],[0]
Then we remove the content model in order to test the necessity of modeling the content of the answer.,4.1 Ablation Study,[0],[0]
"Since we don’t have the content scores, we use the boundary probabilities instead to compute the answer representation for verification.",4.1 Ablation Study,[0],[0]
"Next, to show the benefits of joint training, we train the boundary model separately from the other two models.",4.1 Ablation Study,[0],[0]
"Finally, we remove the yes/no classification in order to show the real improvement of our end-toend model compared with the baseline method that predicts the answer with only the boundary model.
",4.1 Ablation Study,[0],[0]
"From Table 5, we can see that the answer verification makes a great contribution to the overall improvement, which confirms our hypothesis that cross-passage answer verification is useful for the multi-passage MRC.",4.1 Ablation Study,[0],[0]
"For the ablation of the content model, we analyze that it will not only affect the content score itself, but also violate the verification model since the content probabilities are necessary for the answer representation, which will be further analyzed in Section 4.3.",4.1 Ablation Study,[0],[0]
"Another discovery is that jointly training the three models can provide great benefits, which shows that the three tasks are actually closely related and can boost each other with shared representations at bottom layers.",4.1 Ablation Study,[0],[0]
"At last, comparing our method with the baseline, we achieve an improvement of nearly
3 points without the yes/no classification.",4.1 Ablation Study,[0],[0]
This significant improvement proves the effectiveness of our approach.,4.1 Ablation Study,[0],[0]
"To demonstrate how each module of our model takes effect when predicting the final answer, we conduct a case study in Table 6 with the same example that we discussed in Section 1.",4.2 Case Study,[0],[0]
"For each answer candidate, we list three scores predicted by the boundary model, content model and verification model respectively.
",4.2 Case Study,[0],[0]
"On the one hand, we can see that these three scores generally have some relevance.",4.2 Case Study,[0],[0]
"For example, the second candidate is given lowest scores by all the three models.",4.2 Case Study,[0],[0]
We analyze that this is because the models share the same encoding and matching layers at bottom level and this relevance guarantees that the content and verification models will not violate the boundary model too much.,4.2 Case Study,[0],[0]
"On the other hand, we also see that the verification score can really make a difference here when the boundary model makes an incorrect decision among the confusing answer candidates ([1], [3], [4], [6]).",4.2 Case Study,[0],[0]
"Besides, as we expected, the verification model tends to give higher scores for those answers that have semantic commonality with each other ([3], [4], [6]), which are all valid answers in this case.",4.2 Case Study,[0],[0]
"By multiplying the three scores, our model finally predicts the answer correctly.",4.2 Case Study,[0],[0]
"In our model, we compute the answer representation based on the content probabilities predicted by a separate content model instead of directly using the boundary probabilities.",4.3 Necessity of the Content Model,[0],[0]
We argue that this content model is necessary for our answer verification process.,4.3 Necessity of the Content Model,[0],[0]
"Figure 2 plots the predicted content probabilities as well as the boundary probabilities
for a passage.",4.3 Necessity of the Content Model,[0],[0]
We can see that the boundary and content probabilities capture different aspects of the answer.,4.3 Necessity of the Content Model,[0],[0]
"Since answer candidates usually have similar boundary words, if we compute the answer representation based on the boundary probabilities, it’s difficult to model the real difference among different answer candidates.",4.3 Necessity of the Content Model,[0],[0]
"On the contrary, with the content probabilities, we pay more attention to the content part of the answer, which can provide more distinguishable information for verifying the correct answer.",4.3 Necessity of the Content Model,[0],[0]
"Furthermore, the content probabilities can also adjust the weights of the words within the answer span so that unimportant words (e.g. “and” and “.”) get lower weights in the final answer representation.",4.3 Necessity of the Content Model,[0],[0]
We believe that this refined representation is also good for the answer verification process.,4.3 Necessity of the Content Model,[0],[0]
"Machine reading comprehension made rapid progress in recent years, especially for singlepassage MRC task, such as SQuAD (Rajpurkar et al., 2016).",5 Related Work,[0],[0]
"Mainstream studies (Seo et al., 2016; Wang and Jiang, 2016; Xiong et al., 2016) treat reading comprehension as extracting answer span from the given passage, which is usually achieved by predicting the start and end position of the answer.",5 Related Work,[0],[0]
"We implement our boundary model similarly by employing the boundary-based pointer network (Wang and Jiang, 2016).",5 Related Work,[0],[0]
"Another inspiring work is from Wang et al. (2017c), where the authors propose to match the passage against itself so that the representation can aggregate evidence from the whole passage.",5 Related Work,[0],[0]
Our verification model adopts a similar idea.,5 Related Work,[0],[0]
"However, we collect information across passages and our attention is based on the answer representation, which is much more efficient than attention over all passages.",5 Related Work,[0],[0]
"For the model training, Xiong et al. (2017) argues that the boundary loss encourages exact answers at the
cost of penalizing overlapping answers.",5 Related Work,[0],[0]
Therefore they propose a mixed objective that incorporates rewards derived from word overlap.,5 Related Work,[0],[0]
Our joint training approach has a similar function.,5 Related Work,[0],[0]
"By taking the content and verification loss into consideration, our model will give less loss for overlapping answers than those unmatched answers, and our loss function is totally differentiable.
",5 Related Work,[0],[0]
"Recently, we also see emerging interests in multi-passage MRC from both the academic (Dunn et al., 2017; Joshi et al., 2017) and industrial community (Nguyen et al., 2016; He et al., 2017).",5 Related Work,[0],[0]
"Early studies (Shen et al., 2017; Wang et al., 2017c) usually concat those passages and employ the same models designed for singlepassage MRC.",5 Related Work,[0],[0]
"However, more and more latest studies start to design specific methods that can read multiple passages more effectively.",5 Related Work,[0],[0]
"In the aspect of passage selection, Wang et al. (2017a) introduced a pipelined approach that rank the passages first and then read the selected passages for answering questions.",5 Related Work,[0],[0]
Tan et al. (2017) treats the passage ranking as an auxiliary task that can be trained jointly with the reading comprehension model.,5 Related Work,[0],[0]
"Actually, the target of our answer verification is very similar to that of the passage selection, while we pay more attention to the answer content and the answer verification process.",5 Related Work,[0],[0]
"Speaking of the answer verification, Wang et al. (2017b) has a similar motivation to ours.",5 Related Work,[0],[0]
They attempt to aggregate the evidence from different passages and choose the final answer from n-best candidates.,5 Related Work,[0],[0]
"However, they implement their idea as a separate reranking step after reading comprehension, while our answer verification is a component of the whole model that can be trained end-to-end.",5 Related Work,[0],[0]
"In this paper, we propose an end-to-end framework to tackle the multi-passage MRC task .",6 Conclusion,[0],[0]
"We
creatively design three different modules in our model, which can find the answer boundary, model the answer content and conduct cross-passage answer verification respectively.",6 Conclusion,[0],[0]
All these three modules can be trained with different forms of the answer labels and training them jointly can provide further improvement.,6 Conclusion,[0],[0]
"The experimental results demonstrate that our model outperforms the baseline models by a large margin and achieves the state-of-the-art performance on two challenging datasets, both of which are designed for MRC on real web data.",6 Conclusion,[0],[0]
"This work is supported by the National Basic Research Program of China (973 program, No. 2014CB340505) and Baidu-Peking University Joint Project.",Acknowledgments,[0],[0]
We thank the Microsoft MSMARCO team for evaluating our results on the anonymous test set.,Acknowledgments,[0],[0]
"We also thank Ying Chen, Xuan Liu and the anonymous reviewers for their constructive criticism of the manuscript.",Acknowledgments,[0],[0]
Machine reading comprehension (MRC) on real web data usually requires the machine to answer a question by analyzing multiple passages retrieved by search engine.,abstractText,[0],[0]
"Compared with MRC on a single passage, multi-passage MRC is more challenging, since we are likely to get multiple confusing answer candidates from different passages.",abstractText,[0],[0]
"To address this problem, we propose an end-to-end neural model that enables those answer candidates from different passages to verify each other based on their content representations.",abstractText,[0],[0]
"Specifically, we jointly train three modules that can predict the final answer based on three factors: the answer boundary, the answer content and the cross-passage answer verification.",abstractText,[0],[0]
"The experimental results show that our method outperforms the baseline by a large margin and achieves the state-of-the-art performance on the English MS-MARCO dataset and the Chinese DuReader dataset, both of which are designed for MRC in real-world settings.",abstractText,[0],[0]
Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3188–3197 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3188",text,[0],[0]
Neural text generation has attracted much attention in recent years thanks to its impressive generation accuracy and wide applicability.,1 Introduction,[0],[0]
"In addition to demonstrating compelling results for machine translation (MT) (Sutskever et al., 2014; Bahdanau et al., 2014), by simple adaptation, practically very same or similar models have also proven to be successful for summarization (Rush et al., 2015; Nallapati et al., 2016) and image or video captioning (Venugopalan et al., 2015; Xu et al., 2015a).
",1 Introduction,[0],[0]
"The most common neural text generation model is based on the encoder-decoder framework (Sutskever et al., 2014) which generates a variable-length output sequence using an RNNbased decoder with attention mechanisms (Bahdanau et al., 2014; Xu et al., 2015b).",1 Introduction,[0],[0]
"There are many recent efforts in improving the generation accuracy, e.g., ConvS2S (Gehring et al., 2017) and
Transformer (Vaswani et al., 2017).",1 Introduction,[0],[0]
"However, all these efforts are limited to training with a single reference even when multiple references are available.
",1 Introduction,[0],[0]
Multiple references are essential for evaluation due to the non-uniqueness of translation and generation unlike classification tasks.,1 Introduction,[0],[0]
"In MT, even though the training sets are usually with single reference (bitext), the evaluation sets often come with multiple references.",1 Introduction,[0],[0]
"For example, the NIST Chinese-to-English and Arabic-to-English MT evaluation datasets (2003–2008) have in total around 10,000 Chinese sentences and 10,000 Arabic sentences each with 4 different English translations.",1 Introduction,[0],[0]
"On the other hand, for image captioning datasets, multiple references are more common not only for evaluation, but also for training, e.g., the MSCOCO (Lin et al., 2014) dataset provides 5 references per image and PASCAL50S and ABSTRACT-50S (Vedantam et al., 2015) even provide 50 references per image.",1 Introduction,[0],[0]
Can we use the extra references during training?,1 Introduction,[0],[0]
"How much can we benefit from training with multiple references?
",1 Introduction,[0],[0]
"We therefore first investigate several different ways of utilizing existing human-annotated references, which include Sample One (Karpathy and Fei-Fei, 2015), Uniform, and Shuffle methods (explained in Sec. 2).",1 Introduction,[0],[0]
"Although Sample One has been explored in image captioning, to the best of our knowledge, this is the first time that an MT system is trained with multiple references.
",1 Introduction,[0],[0]
"Actually, four or five references still cover only a tiny fraction of the exponentially large space of potential references (Dreyer and Marcu, 2012).",1 Introduction,[0],[0]
"More importantly, encouraged by the success of training with multiple human references, we further propose a framework to generate many more pseudo-references automatically.",1 Introduction,[0],[0]
"In particular, we design a neural multiple-sequence alignment algo-
rithm to compress all existing human references into a lattice by merging similar words across different references (see examples in Fig. 1); this can be viewed as a modern, neural version of paraphrasing with multiple-sequence alignment (Barzilay and Lee, 2003, 2002).",1 Introduction,[0],[0]
"We can then generate theoretically exponentially more references from the lattice.
",1 Introduction,[0],[0]
"We make the following main contributions:
•",1 Introduction,[0],[0]
"Firstly, we investigate three different methods for multi-reference training on both MT and image captioning tasks (Section 2).
•",1 Introduction,[0],[0]
"Secondly, we propose a novel neural network-based multiple sequence alignment model to compress the existing references into lattices.",1 Introduction,[0],[0]
"By traversing these lattices, we generate exponentially many new pseudoreferences (Section 3).
",1 Introduction,[0],[0]
• We report substantial improvements over strong baselines in both MT (+1.5 BLEU) and image captioning (+3.1 BLEU / +11.7 CIDEr) by training on the newly generated pseudo-references (Section 4).,1 Introduction,[0],[0]
"In order to make the multiple reference training easy to adapt to any frameworks, we do not change anything from the existing models itself.",2 Using Multiple References,[0],[0]
"Our multiple reference training is achieved by converting a multiple reference dataset to a single reference dataset without losing any information.
",2 Using Multiple References,[0],[0]
"Considering a multiple reference dataset D, where the ith training example, (xi, Yi), includes one source input xi, which is a source sentence in MT or image vector in image captioning, and a reference set Yi = {y1i ,y2i , ...yKi } of K references.",2 Using Multiple References,[0],[0]
"We have the following methods to convert the multiple reference dataset to a single reference dataset D′ (note that the following D′sample one, D ′ uniform and D′shuffle are ordered sets):",2 Using Multiple References,[0],[0]
Sample One,2 Using Multiple References,[0],[0]
:,2 Using Multiple References,[0],[0]
The most straightforward way is to use a different reference in different epochs during training to explore the variances between references.,2 Using Multiple References,[0],[0]
"For each example, we randomly pick one of the K references in each training epoch (note that the random function will be used in each epoch).",2 Using Multiple References,[0],[0]
"This method is commonly used in existing image captioning literatures, such as (Karpathy and FeiFei, 2015), but never used in MT.",2 Using Multiple References,[0],[0]
"This approach
can be formalized as:
D′sample one = |D|⋃ i=1",2 Using Multiple References,[0],[0]
"{(xi,ykii )}, ki = rand(1, ...,K)
Uniform:",2 Using Multiple References,[0],[0]
"Although all references are accessible by using Sample One, it is not guaranteed that all references are used during training.",2 Using Multiple References,[0],[0]
So we introduce Uniform which basically copies xi training example K times and each time with a different reference.,2 Using Multiple References,[0],[0]
"This approach can be formalized as:
D′uniform = |D|⋃ i=1",2 Using Multiple References,[0],[0]
K⋃,2 Using Multiple References,[0],[0]
"k=1 {(xi,yki )}
Shuffle is based on Uniform, but shuffles all the source and reference pairs in random order before each epoch.",2 Using Multiple References,[0],[0]
"So, formally it is:
D′shuffle =",2 Using Multiple References,[0],[0]
"Shuffle(D ′ uniform)
",2 Using Multiple References,[0],[0]
Sample One is supervised by different training signals in different epochs while both Uniform and Shuffle include all the references at one time.,2 Using Multiple References,[0],[0]
Note that we use mini-batch during training.,2 Using Multiple References,[0],[0]
"When we set the batch size equal to the entire training set size in both Uniform and Shuffle, they become equivalent.",2 Using Multiple References,[0],[0]
"In text generation tasks, the given multiple references are only a small portion in the whole space of potential references.",3 Pseudo-References Generation,[0],[0]
"To cover a larger number of references during training, we want to generate more pseudo-references which is similar to existing ones.
",3 Pseudo-References Generation,[0],[0]
"Our basic idea is to compress different references y0,y1, ...,yK into a lattice.",3 Pseudo-References Generation,[0],[0]
We achieve this by merging similar words in the references.,3 Pseudo-References Generation,[0],[0]
"Finally, we generate more pseudo-references by simply traversing the compressed lattice and select those with high quality according to its BLEU score.
",3 Pseudo-References Generation,[0],[0]
"Take the following three references from the NIST Chinese-to-English machine translation dataset as an example:
1.",3 Pseudo-References Generation,[0],[0]
"Indonesia reiterated its opposition to foreign military presence
2.",3 Pseudo-References Generation,[0],[0]
"Indonesia repeats its opposition against station of foreign troops in Indonesia
3.",3 Pseudo-References Generation,[0],[0]
"Indonesia reiterates opposition to
garrisoning foreign armies",3 Pseudo-References Generation,[0],[0]
The simplest way to compress different references into a lattice is to do pairwise reference compression iteratively.,3.1 Naive Idea: Hard Word Alignment,[0],[0]
"At each time, we select two references and merge the same words in them.
",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"Considering the previous example, we can derive an initial lattice from the three references as shown in Fig. 1(a).",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"Assume that we first do a pairwise reference compression on first two references, we can merge at four sharing words: Indonesia, its, opposition and foreign, and the lattice will turn to Fig. 1(b).",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"If we further compress the first and third references, we can merge at Indonesia, opposition, to and foreign, which gives the lattice Fig. 1(c).",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"By simply traversing the final lattice, 33 new pseudo-references can be generated.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"For example:
1.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"Indonesia reiterated its opposition
to garrisoning foreign armies
2.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"Indonesia repeats its opposition to foreign military presence
3.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"Indonesia reiterates opposition to foreign troops in Indonesia
4. ...
",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"However, this simple hard alignment method (only identical words can be aligned) suffers from two problems:
1.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
Different words may have similar meanings and need to be merged together.,3.1 Naive Idea: Hard Word Alignment,[0],[0]
"For example, in the previous example, reiterated, repeats and reiterates should be merged together.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"Similarly, military, troops and armies also have similar meanings.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"If the
lattice can align these words, we can generate the lattice shown in Fig. 1(e) which can generate 213 pseudo-references.
2.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
Identical words may have different meaning in different contexts and should not be merged.,3.1 Naive Idea: Hard Word Alignment,[0],[0]
"Considering the following two references from the COCO image captioning dataset (corresponding picture is shown in Fig. 2):
1.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"Two elephants in an enclosure next to a brick building
2.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"Two elephants try to fit through a
small entry
Following the previously described algorithm, we can merge the two references at “two elephants”, at “to” and at “a”.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"However, “to” in the two references are very different (it is a preposition in the first reference and an infinitive in the second) and should not be merged.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"Thus, the lattice in Fig. 2(b) will generate the following wrong pseudo-references:
1.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"Two elephants try to a small entry
2.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"Two elephants in an enclosure next
to fit through a brick building
Therefore, we need to investigate a better method to compress the lattice.",3.1 Naive Idea: Hard Word Alignment,[0],[0]
"To tackle the above listed two problems of hard alignment, we need to identify synonyms and words with similar meanings.",3.2 Measuring Word Similarity in Context,[0],[0]
Barzilay and Lee (2002) utilize an external synonyms dictionary to get the similarity score between words.,3.2 Measuring Word Similarity in Context,[0],[0]
"However, this method ignores the given context of each word.",3.2 Measuring Word Similarity in Context,[0],[0]
"For example, in Fig. 1(a), there are two Indonesia’s in the second path of reference.",3.2 Measuring Word Similarity in Context,[0],[0]
"If we use a synonyms dictionary, both Indonesia tokens will be aligned to the Indonesia in the first
or third sentence with the same score.",3.2 Measuring Word Similarity in Context,[0],[0]
"This incorrect alignment would lead to meaningless lattice.
",3.2 Measuring Word Similarity in Context,[0],[0]
"Thus, we introduce the semantic substitution matrix which measures the semantic similarity of each word pairs in context.",3.2 Measuring Word Similarity in Context,[0],[0]
"Formally, given a sentence pair yi and yj , we build a semantic substitution matrix M = R|yi|×|yj |, whose cell Mu,v represents the similarity score between word yi,u and word yj,v.
We propose a new neural network-based multiple sequence alignment algorithm to take context into consideration.",3.2 Measuring Word Similarity in Context,[0],[0]
"We first build a language model (LM) to obtain the semantic representation of each word, then these word representations are used to construct the semantic substitution matrix between sentences.
",3.2 Measuring Word Similarity in Context,[0],[0]
"Fig. 3 shows the architecture of the bidirectional LM (Mousa and Schuller, 2017).",3.2 Measuring Word Similarity in Context,[0],[0]
"The optimization goal of our LM is to minimize the ith word’s prediction error given the surrounding word’s hidden state:
p(wi | −−→ hi−1 ⊕ ←−− hi+1) (1)
For any new given sentences, we concatenate both forward and backward hidden states to represent each word yi,u in a sentence yi.",3.2 Measuring Word Similarity in Context,[0],[0]
"We then calculate the normalized cosine similarity score of word yi,u and yj,v as:
Mu,v = cosine",3.2 Measuring Word Similarity in Context,[0],[0]
( −→ hu ⊕ ←−,3.2 Measuring Word Similarity in Context,[0],[0]
"hu, −→ hv ⊕ ←− hv) (2)
",3.2 Measuring Word Similarity in Context,[0],[0]
Fig. 4 shows an example of the semantic substitution matrix of first two sentences in example references of Fig. 1(a).,3.2 Measuring Word Similarity in Context,[0],[0]
"With the help of semantic substitution matrix Mu,v which measures pairwise word similarity, we need to find the optimal word alignment to compress references into a lattice.
",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"Unfortunately, this computation is exponential in the number of sequences.",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"Thus, we use iterative pairwise alignment which greedily merges sentence pairs (Durbin et al., 1998).
",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"Based on pairwise substitution matrix we can define an optimal pairwise sequence alignment as an optimal path from M0,0 to M|yi|,|yj |.",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
This is a dynamic programming problem with the state transition function described in Equation (3).,3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
Fig. 5 shows the optimal path according to the semantic substitution matrix in Fig. 4.,3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"There is a gap if the continuous step goes vertical or horizontal, and an alignment if it goes diagonal.
",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"opt(u, v)=  opt(u−1, v−1)+Mu,v opt(u−1, v) opt(u, v−1)
(3)
",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
What order should we follow to do the iterative pairwise word alignment?,3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"Intuitively, we need to compress the most similar reference pair first, since this compression will lead to more aligned words.",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"Following this intuition, we order reference pairs by the maximum alignment score opt(|yi|, |yj |) (i.e. the score of bottom-right cell in Fig. 5) which is the sum of all aligned words.
",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"Using this order, we can iteratively merge each sentence pair in descending order, unless both the sentences have already been merged (this will prevent generating a cyclic lattice).
",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"Since the semantic substitution matrix Mu,v, defined as a normalized cosine similarity, scales in (0, 1), it’s very likely for the DP algorithm to align unrelated words.",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"To tackle this problem, we deduct a global penalty p from each cell of Mu,v. With the global penalty p, the DP algorithm will not align a word pair (yi,u,yi,v) unless Mu,v ≥ p.
After the pairwise references alignment, we merge those aligned words.",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"For example, in Fig. 1, after we generate an initial lattice as shown in Fig. 1(a), we then calculate the maximum alignment score of all sentence pairs.",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"After that, the lattice turns into Fig. 1(d) by merging the first two references (assuming they have the highest score) according to pairwise alignment shown in Fig. 5.",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
Then we pick the sentence pair with next highest alignment score (assuming it’s the last two sentences).,3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
"Similar to the previous step, we find alignments according to the dynamic programming and merge to the final lattice (see Fig. 1(e)).",3.3 Iterative Pairwise Word Alignment using Dynamic Programming,[0],[0]
We generate pseudo-references by simply traversing the generated lattice.,3.4 Traverse Lattice and Pseudo-References Selection by BLEU,[0],[0]
"For example, if we traverse the final lattice shown in Fig. 1(e), we can generate 213 pseudo-refrences in total.
",3.4 Traverse Lattice and Pseudo-References Selection by BLEU,[0],[0]
"Then, we can put those generated pseudoreferences to expand the training dataset.",3.4 Traverse Lattice and Pseudo-References Selection by BLEU,[0],[0]
"To balance the number of generated pseudo-references for each example, we force the total number of pseudo-references from each example to be
K ′. For those examples generating k pseudoreferences and k > K ′, we calculate all pseudoreferences’ BLEU scores based on gold references, and only keep top K ′−k pseudo-references with highest BLEU score.",3.4 Traverse Lattice and Pseudo-References Selection by BLEU,[0],[0]
"To investigate the empirical performances of our proposed algorithm, we conduct experiments on machine translation and image captioning.",4 Experiments,[0],[0]
"We evaluate our approach on NIST Chinese-toEnglish translation dataset which consists of 1M pairs of single reference data and 5974 pairs of 4 reference data (NIST 2002, 2003, 2004, 2005, 2006, 2008).",4.1 Machine Translation,[0],[0]
Table 1 shows the statistics of this dataset.,4.1 Machine Translation,[0],[0]
"We first pre-train our model on a 1M pairs single reference dataset and then train on the NIST 2002, 2003, 2004, 2005.",4.1 Machine Translation,[0],[0]
"We use the NIST 2006
dataset as validation set and NIST 2008 as test sets.
",4.1 Machine Translation,[0],[0]
Fig. 6(a) analyzes the number and quality of generated references using our proposed approach.,4.1 Machine Translation,[0],[0]
We set the global penalty as 0.9 and only calculate the top 50 generated references for the average BLEU analysis.,4.1 Machine Translation,[0],[0]
"From the figure, we can see that when the sentence length grows, the number of generated references grows exponentially.",4.1 Machine Translation,[0],[0]
"To generate enough references for the following experiments, we set an initial global penalty as 0.9 and gradually decrease it by 0.05 until we collect no less than 100 references.",4.1 Machine Translation,[0],[0]
"We train a bidirectional language model on the pre-training dataset and training dataset with Glove (Pennington et al., 2014) word embedding size of 300 dimension, for 20 epochs to minimize the perplexity
We employ byte-pair encoding (BPE) (Sennrich et al., 2015) which reduces the source and target language vocabulary sizes to 18k and 10k.",4.1 Machine Translation,[0],[0]
"We adopt length reward (Huang et al., 2017) to find optimal sentence length.",4.1 Machine Translation,[0],[0]
We use a two layer bidirectional LSTM as the encoder and a two layer LSTM as the decoder.,4.1 Machine Translation,[0],[0]
"We perform pre-training for 20 epochs to minimize perplexity on the 1M dataset, with a batch size of 64, word embedding size of 500, beam size of 15, learning rate of 0.1, learning rate decay of 0.5 and dropout rate of 0.3.",4.1 Machine Translation,[0],[0]
"We then train the model in 30 epochs and use the best batch size among 100, 200, 400 for each update method.",4.1 Machine Translation,[0],[0]
"These batch sizes are multiple of the number of references used in experiments, so it is guaranteed that all the references of one single example are in one batch for the Uniform method.",4.1 Machine Translation,[0],[0]
The learning rate is set as 0.01 and learning rate decay as 0.75.,4.1 Machine Translation,[0],[0]
"We do each experiment three times and report the average result.
",4.1 Machine Translation,[0],[0]
Table 2 shows the translation quality on the devset of machine translation task.,4.1 Machine Translation,[0],[0]
"Besides the original 4 references in the training set, we generate another four dataset with 10, 20, 50 and 100 references including pseudo-references using hard word alignment and soft word alignment.",4.1 Machine Translation,[0],[0]
"We compare the three update methods (Sample One, Uniform, Shuffle) with always using the first reference (First).",4.1 Machine Translation,[0],[0]
All results of soft word alignment are better than corresponding hard word alignment results and the best result is achieved with 50 references using Uniform and soft word alignment.,4.1 Machine Translation,[0],[0]
"According to Table 3, Shuffle with original 4 references has +0.7 BLEU improvement and Uniform
with 50 references has +1.5 BLEU improvement.",4.1 Machine Translation,[0],[0]
"From Fig. 7(b), we can see that using the Sample One method, the translation quality drops dramatically with more than 10 references.",4.1 Machine Translation,[0],[0]
This may be due to the higher variance of used reference in each epoch.,4.1 Machine Translation,[0],[0]
"For the image captioning task, we use the widelyused MSCOCO image captioning dataset.",4.2 Image Captioning,[0],[0]
"Following prior work, we use the Kapathy split (Karpathy and Fei-Fei, 2015).",4.2 Image Captioning,[0],[0]
Table 1 shows the statistics of this dataset.,4.2 Image Captioning,[0],[0]
"We use Resnet (He et al., 2016) to extract image feature of 2048 feature size and simple fully connected layer of size 512 to an LSTM de-
coder.",4.2 Image Captioning,[0],[0]
We train every model for 100 epochs and calculate the BLEU score on validation set and select the best model.,4.2 Image Captioning,[0],[0]
"For every update method, we find the optimal batch size among 50, 250, 500, 1000",4.2 Image Captioning,[0],[0]
"and we use a beam size of 5.
Fig. 6(b) analyzes the correlation between average references length with the number and quality of generated references.",4.2 Image Captioning,[0],[0]
We set global penalty as 0.6 (which is also adopted for the generated references in the following experiments) and calculate the top 50 generated references for the average BLEU analysis.,4.2 Image Captioning,[0],[0]
"Since the length of original references is much shorter than the previous machine translation dataset, it has worse quality and fewer generated references.
",4.2 Image Captioning,[0],[0]
Table 4 shows that the best result is achieved with 20 references using Shuffle.,4.2 Image Captioning,[0],[0]
"This result is
different from the result of machine translation task where Uniform method is the best.",4.2 Image Captioning,[0],[0]
This may be because the references in image captioning dataset are much more diverse than those in machine translation dataset.,4.2 Image Captioning,[0],[0]
Different captions of one image could even talk about different aspects.,4.2 Image Captioning,[0],[0]
"When using the Uniform method, the high variance of references in one batch may harm the model and lead to worse text generation quality.",4.2 Image Captioning,[0],[0]
"Table 5 shows that it outperforms Sample One with 4 original references, which is adopted in previous work (Karpathy and Fei-Fei, 2015), +3.1 BLEU score and +11.7 CIDEr.",4.2 Image Captioning,[0],[0]
Fig. 6 shows a training example in the COCO dataset and its corresponding generated lattice and pseudo-references which is sorted according to its BLEU score.,4.3 Case Study,[0],[0]
Our proposed algorithm generates 73724 pseudo-references in total.,4.3 Case Study,[0],[0]
All the top 50 pseudo-references’ BLEU scores are above 97.1 and the top three even achieve 100.0 BLEU score though they are not identical to any original references.,4.3 Case Study,[0],[0]
"Although the BLEU of last two sentences is 0.0, they are still valid to describe this picture.",4.3 Case Study,[0],[0]
"We introduce several multiple-reference training methods and a neural-based lattice compression framework, which can generate more training references based on existing ones.",5 Conclusions,[0],[0]
Our proposed framework outperforms the baseline models on both MT and image captioning tasks.,5 Conclusions,[0],[0]
"This work was supported in part by DARPA grant N66001-17-2-4030, and NSF grants IIS1817231 and IIS-1656051.",Acknowledgments,[0],[0]
We thank the anonymous reviewers for suggestions and Juneki Hong for proofreading.,Acknowledgments,[0],[0]
"Neural text generation, including neural machine translation, image captioning, and summarization, has been quite successful recently.",abstractText,[0],[0]
"However, during training time, typically only one reference is considered for each example, even though there are often multiple references available, e.g., 4 references in NIST MT evaluations, and 5 references in image captioning data.",abstractText,[0],[0]
We first investigate several different ways of utilizing multiple human references during training.,abstractText,[0],[0]
"But more importantly, we then propose an algorithm to generate exponentially many pseudo-references by first compressing existing human references into lattices and then traversing them to generate new pseudo-references.",abstractText,[0],[0]
These approaches lead to substantial improvements over strong baselines in both machine translation (+1.5 BLEU) and image captioning (+3.1 BLEU / +11.7 CIDEr).,abstractText,[0],[0]
Multi-Reference Training with Pseudo-References for Neural Translation and Text Generation,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 833–844 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
833",text,[0],[0]
"Personal devices that interact with users via natural language conversation are becoming ubiquitous (e.g., Siri, Alexa), however, very little of that conversation today allows the user to teach, and then query, new knowledge.",1 Introduction,[0],[0]
"Most of the focus in
these personal devices has been on Question Answering (QA) over general world-knowledge (e.g., “who was the president in 1980” or “how many ounces are in a cup”).",1 Introduction,[0],[0]
"These devices open a new and exciting possibility of enabling end-users to teach machines in natural language, e.g., by expressing the state of their personal world to its virtual assistant (e.g., via narrative about people and events in that user’s life) and enabling the user to ask questions over that personal knowledge (e.g., “which engineers in the QC team were involved in the last meeting with the director?”).
",1 Introduction,[0],[0]
"This type of questions highlight a unique blend of two conventional streams of research in Question Answering (QA) – QA over structured sources such as knowledge bases (KBs), and QA over unstructured sources such as free text.",1 Introduction,[0],[0]
"This blend is a natural consequence of our problem setting: (i) users may choose to express rich relational knowledge about their world, in turn enabling them to pose complex composi-
1.",1 Introduction,[0],[0]
There is an associate professor named Andy 2.,1 Introduction,[0],[0]
He returned from a sabbatical 3.,1 Introduction,[0],[0]
This professor currently has funding 4.,1 Introduction,[0],[0]
There is a masters level course called G301 5.,1 Introduction,[0],[0]
That course is taught by him 6.,1 Introduction,[0],[0]
"That class is part of the mechanical
engineering department 7.",1 Introduction,[0],[0]
Roslyn is a student in this course 8.,1 Introduction,[0],[0]
U203 is a undergraduate level course 9.,1 Introduction,[0],[0]
"Peggy and that student are TAs for this
course
…",1 Introduction,[0],[0]
What students are advised by a professor with funding?,1 Introduction,[0],[0]
"[Albertha, Roslyn, Peggy, Lucy, Racquel]
What assistant professors advise students who passed their thesis proposal?",1 Introduction,[0],[0]
"[Andy]
Which courses have masters student TAs?",1 Introduction,[0],[0]
"[G301, U101 ]
Who are the professors working on unsupervised machine learning?",1 Introduction,[0],[0]
"[Andy, Hanna]",1 Introduction,[0],[0]
7.,6. Andrew is no longer assigned to that project,[0],[0]
"That developer resolved the changelog needs
to be added issue
…
Are there any developers assigned to projects in the evaluation stage?",6. Andrew is no longer assigned to that project,[0],[0]
"[Tawnya, Charlott, Hiram]
Who is the null pointer exception during parsing issue assigned to?",6. Andrew is no longer assigned to that project,[0],[0]
"Hiram
Are there any issues that are resolved for experimental projects?",6. Andrew is no longer assigned to that project,[0],[0]
"[saving data throws exception, wrong pos tag on consecutive words]
Academic Department World Software Engineering World
Figure 2:",6. Andrew is no longer assigned to that project,[0],[0]
Illustrative snippets from two sample worlds.,6. Andrew is no longer assigned to that project,[0],[0]
"We aim to generate natural-sounding first-person narratives from five diverse worlds, covering a range of different events, entities and relations.
tional queries (e.g., “all CS undergrads who took my class last semester”), while at the same time (ii) personal knowledge generally evolves through time and has an open and growing set of relations, making natural language the only practical interface for creating and maintaining that knowledge by non-expert users.",6. Andrew is no longer assigned to that project,[0],[0]
"In short, the task that we address in this work is: multi-relational question answering from dynamic knowledge expressed via narrative.
",6. Andrew is no longer assigned to that project,[0],[0]
"Although we hypothesize that questionanswering over personal knowledge of this sort is ubiquitous (e.g., between a professor and their administrative assistant, or even if just in the user’s head), such interactions are rarely recorded, presenting a significant practical challenge to collecting a sufficiently large real-world dataset of this type.",6. Andrew is no longer assigned to that project,[0],[0]
"At the same time, we hypothesize that the technical challenges involved in developing models for relational question answering from narrative would not be fundamentally impacted if addressed via sufficiently rich, but controlled simulated narratives.",6. Andrew is no longer assigned to that project,[0],[0]
"Such simulations also offer the advantage of enabling us to directly experiment with stories and queries of different complexity, potentially offering additional insight into the fundamental challenges of this task.
",6. Andrew is no longer assigned to that project,[0],[0]
"While our problem setting blends the problems
of relational question answering over knowledge bases and question answering over text, our hypothesis is that end-to-end QA models may learn to answer such multisentential relational queries, without relying on an intermediate knowledge base representation.",6. Andrew is no longer assigned to that project,[0],[0]
"In this work, we conduct an extensive evaluation of a set of state-of-the-art end-to-end QA models on our task and analyze their results.",6. Andrew is no longer assigned to that project,[0],[0]
Question answering has been mainly studied in two different settings: KB-based and text-based.,2 Related Work,[0],[0]
"KB-based QA mostly focuses on parsing questions to logical forms (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2012; Berant et al., 2013; Kwiatkowski et al., 2013; Yih et al., 2015) in order to better retrieve answer candidates from a knowledge base.",2 Related Work,[0],[0]
Text-based QA aims to directly answer questions from the input text.,2 Related Work,[0],[0]
"This includes works on early information retrieval-based methods (Banko et al., 2002; Ahn et al., 2004) and methods that build on extracted structured representations from both the question and the input text (Sachan et al., 2015; Sachan and Xing, 2016; Khot et al., 2017; Khashabi et al., 2018b).",2 Related Work,[0],[0]
"Although these structured presentations make reasoning more effective, they rely on sophisticated
NLP pipelines and suffer from error propagation.",2 Related Work,[0],[0]
"More recently, end-to-end neural architectures have been successfully applied to textbased QA, including Memory-augmented neural networks (Sukhbaatar et al., 2015; Miller et al., 2016; Kumar et al., 2016) and attention-based neural networks (Hermann et al., 2015; Chen et al., 2016; Kadlec et al., 2016; Dhingra et al., 2017; Xiong et al., 2017; Seo et al., 2017; Chen et al., 2017).",2 Related Work,[0],[0]
"In this work, we focus on QA over text (where the text is generated from a supporting KB) and evaluate several state-of-the-art memoryaugmented and attention-based neural architectures on our QA task.",2 Related Work,[0],[0]
"In addition, we consider a sequence-to-sequence model baseline (Bahdanau et al., 2015), which has been widely used in dialog (Vinyals and Le, 2015; Ghazvininejad et al., 2017) and recently been applied to generating answer values from Wikidata (Hewlett et al., 2016).
",2 Related Work,[0],[0]
There are numerous datasets available for evaluating the capabilities of QA systems.,2 Related Work,[0],[0]
"For example, MCTest (Richardson et al., 2013) contains comprehension questions for fictional stories.",2 Related Work,[0],[0]
"Allen AI Science Challenge (Clark, 2015) contains science questions that can be answered with knowledge from text books.",2 Related Work,[0],[0]
"RACE (Lai et al., 2017) is an English exam dataset for middle and high school Chinese students.",2 Related Work,[0],[0]
"MULTIRC (Khashabi et al., 2018a) is a dataset that focuses on evaluating multi-sentence reasoning skills.",2 Related Work,[0],[0]
"These datasets all require humans to carefully design multiplechoice questions and answers, so that certain aspects of the comprehension and reasoning capabilities are properly evaluated.",2 Related Work,[0],[0]
"As a result, it is difficult to collect them at scale.",2 Related Work,[0],[0]
"Furthermore, as the knowledge required for answering each question is not clearly specified in these datasets, it can be hard to identify the limitations of QA systems and propose improvements.
",2 Related Work,[0],[0]
Weston et al. (2015) proposes to use synthetic QA tasks (the BABI dataset) to better understand the limitations of QA systems.,2 Related Work,[0],[0]
"BABI builds on a simulated physical world similar to interactive fiction (Montfort, 2005) with simple objects and relations and includes 20 different reasoning tasks.",2 Related Work,[0],[0]
"Various types of end-to-end neural networks (Sukhbaatar et al., 2015; Lee et al., 2015; Peng et al., 2015) have demonstrated promising accuracies on this dataset.",2 Related Work,[0],[0]
"However, the performance can hardly translate to real-world QA datasets, as BABI uses a small vocabulary (150
words) and short sentences with limited language variations (e.g., nesting sentences, coreference).",2 Related Work,[0],[0]
"A more sophisticated QA dataset with a supporting KB is WIKIMOVIES (Miller et al., 2016), which contains 100k questions about movies, each of them is answerable by using either a KB or a Wikipedia article.",2 Related Work,[0],[0]
"However, WIKIMOVIES is highly domain-specific, and similar to BABI, the questions are designed to be in simple forms with little compositionality and hence limit the difficulty level of the tasks.
",2 Related Work,[0],[0]
"Our dataset differs in the above datasets in that (i) it contains five different realistic domains permitting cross-domain evaluation to test the ability of models to generalize beyond a fixed set of KB relations, (ii) it exhibits rich referring expressions and linguistic variations (vocabulary much larger than the BABI dataset), (iii) questions in our dataset are designed to be deeply compositional and can cover multiple relations mentioned across multiple sentences.
",2 Related Work,[0],[0]
"Other large-scale QA datasets include Clozestyle datasets such as CNN/Daily Mail (Hermann et al., 2015), Children’s Book Test (Hill et al., 2015), and Who Did What (Onishi et al., 2016); datasets with answers being spans in the document, such as SQuAD (Rajpurkar et al., 2016), NewsQA (Trischler et al., 2016), and TriviaQA (Joshi et al., 2017); and datasets with human generated answers, for instance, MS MARCO (Nguyen et al., 2016) and SearchQA",2 Related Work,[0],[0]
"(Dunn et al., 2017).",2 Related Work,[0],[0]
One common drawback of these datasets is the difficulty in accessing a system’s capability of integrating information across a document context.,2 Related Work,[0],[0]
"Kočiskỳ et al. (2017) recently emphasized this issue and proposed NarrativeQA, a dataset of fictional stories with questions that reflect the complexity of narratives: characters, events, and evolving relations.",2 Related Work,[0],[0]
"Our dataset contains similar narrative elements, but it is created with a supporting KB and hence it is easier to analyze and interpret results in a controlled setting.",2 Related Work,[0],[0]
"In this work, we synthesize narratives in five diverse worlds, each containing a thousand narratives and where each narrative describes the evolution of a simulated user’s world from a firstperson perspective.",3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
"In each narrative, the simu-
lated user may introduce new knowledge, update existing knowledge or express a state change (e.g., “Homework 3 is now due on Friday” or “Samantha passed her thesis defense”).",3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
"Each narrative is interleaved with questions about the current state of the world, and questions range in complexity depending on the amount of knowledge that needs to be integrated to answer them.",3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
"This allows us to benchmark a range of QA models at their ability to answer questions that require different extents of relational reasoning to be answered.
",3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
"The set of worlds that we simulate as part of this work are as follows:
1.",3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
MEETING WORLD:,3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
"This world describes situations related to professional meetings, e.g., meetings being set/cancelled, people attending meetings, topics of meetings.
2.",3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
HOMEWORK WORLD:,3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
"This world describes situations from the first-person perspective of a student, e.g., courses taken, assignments in different courses, deadlines of assignments.
3.",3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
SOFTWARE ENGINEERING WORLD:,3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
"This world describes situations from the first-person perspective of a software development manager, e.g., task assignment to different project team members, stages of software development, bug tickets.
4.",3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
ACADEMIC DEPARTMENT WORLD:,3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
"This world describes situations from the first-person perspective of a professor, e.g., teaching assignments, faculty going/returning from sabbaticals, students from different departments taking/dropping courses.
5.",3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
SHOPPING WORLD:,3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
"This world describes situations about a person shopping for various occasions, e.g., adding items to a shopping list, purchasing items at different stores, noting where items are on sale.",3 TEXTWORLDS: Simulated Worlds for Multi-Relational QA from Narratives,[0],[0]
"Each world is represented by a set of entities E and a set of unary, binary or ternary relations R. Formally, a single step in one simulation of a world involves a combination of instantiating new entities and defining new (or mutating existing) relations between entities.",3.1 Narrative,[0],[0]
"Practically, we implement each world as a collection of classes and
methods, with each step of the simulation creating or mutating class instances by sampling entities and methods on those entities.",3.1 Narrative,[0],[0]
"By design, these classes and methods are easy to extend, to either enrich existing worlds or create new ones.",3.1 Narrative,[0],[0]
"Each simulation step is then expressed as a natural language statement, which is added to the narrative.",3.1 Narrative,[0],[0]
"In the process of generating a natural language expression, we employ a rich mechanism for generating anaphora, such as “meeting with John about the performance review” and “meeting that I last added”, in addition to simple pronoun references.",3.1 Narrative,[0],[0]
This allows us to generate more natural and flowing narratives.,3.1 Narrative,[0],[0]
"These references are generated and composed automatically by the underlying TEXTWORLDS framework, significantly reducing the effort needed to build new worlds.",3.1 Narrative,[0],[0]
"Furthermore, all generated stories also provide additional annotation that maps all entities to underlying gold-standard KB ids, allowing to perform experiments that provide models with different degrees of access to the “simulation oracle”.
",3.1 Narrative,[0],[0]
"We generate 1,000 narratives within each world, where each narrative consists of 100 sentences, plus up to 300 questions interleaved randomly within the narrative.",3.1 Narrative,[0],[0]
See Figure 1 for two example narratives.,3.1 Narrative,[0],[0]
"Each story in a given world samples its entities from a large general pool of entity names collected from the web (e.g., people names, university names).",3.1 Narrative,[0],[0]
"Although some entities do overlap between stories, each story in a given world contains a unique flow of events and entities involved in those events.",3.1 Narrative,[0],[0]
See Table 1 for the data statistics.,3.1 Narrative,[0],[0]
"Formally, questions are queries over the knowledge-base in the state defined up to the point when the question is asked in the narrative.",3.2 Questions,[0],[0]
"In the narrative, the questions are expressed
in natural language, employing the same anaphora mechanism used in generating the narrative (e.g., “who is attending the last meeting I added?”).
",3.2 Questions,[0],[0]
"We categorize generated questions into four types, reflecting the number and types of facts required to answer them; questions that require more facts to answer are typically more compositional in nature.",3.2 Questions,[0],[0]
"We categorize each question in our dataset into one of the following four categories:
Single Entity/Single Relation Answers to these questions are a single entity, e.g. “what is John’s email address?”, or expressed in lambda-calculus notation:
λx.EmailAddress(John, x)
",3.2 Questions,[0],[0]
"The answers to these questions are found in a single sentence in the narrative, although it is possible that the answer may change through the course of the narrative (e.g., “John’s new office is GHC122”).
",3.2 Questions,[0],[0]
"Multi-Entity/Single Relation Answers to these questions can be multiple entities but involve a single relation, e.g., “Who is enrolled in the Math class?”, or expressed in lambda calculus notation:
λx.TakingClass(x, Math)
",3.2 Questions,[0],[0]
"Unlike the previous category, answers to these questions can be sets of entities.
",3.2 Questions,[0],[0]
Multi-Entity/Two Relations,3.2 Questions,[0],[0]
"Answers to these questions can be multiple entities and involve two relations, e.g., “Who is enrolled in courses that I am teaching?”, or expressed in lambda calculus:
λx.∃y.",3.2 Questions,[0],[0]
"EnrolledInClass(x, y) ∧ CourseTaughtByMe(y)
",3.2 Questions,[0],[0]
"Multi-Entity/Three Relations Answers to these questions can be multiple entities and involve three relations, e.g., “Which undergraduates are
enrolled in courses that I am teaching?”, or expressed in lambda calculus notation:
λx.∃y.",3.2 Questions,[0],[0]
"EnrolledInClass(x, y) ∧ CourseTaughtByMe(y) ∧ Undergrad(x)
",3.2 Questions,[0],[0]
"In the data that we generate, answers to questions are always sets of spans in the narrative (the reason for this constraint is for easier evaluation of several existing machine-reading models; this assumption can easily be relaxed in the simulation).",3.2 Questions,[0],[0]
"In all of our evaluations, we will partition our results by one of the four question categories listed above, which we hypothesize correlates with the difficulty of a question.",3.2 Questions,[0],[0]
"We develop several baselines for our QA task, including a logistic regression model and four different neural network models: Seq2Seq (Bahdanau et al., 2015), MemN2N (Sukhbaatar et al., 2015), BiDAF (Seo et al., 2017), and DrQA (Chen et al., 2017).",4 Methods,[0],[0]
"These models generate answers in different ways, e.g., predicting a single entity, predicting spans of text, or generating answer sequences.",4 Methods,[0],[0]
"Therefore, we implement two experimental settings: ENTITY and RAW.",4 Methods,[0],[0]
"In the ENTITY setting, given a question and a story, we treat all the entity spans in the story as candidate answers, and the prediction task becomes a classification problem.",4 Methods,[0],[0]
"In the RAW setting, a model needs to predict the answer spans.",4 Methods,[0],[0]
"For logistic regression and MemN2N, we adopt the ENTITY setting as they are naturally classification models.",4 Methods,[0],[0]
This ideally provides an upper bound on the performance when considering answer candidate generation.,4 Methods,[0],[0]
"For all the other models, we can apply the RAW setting.",4 Methods,[0],[0]
"The logistic regression baseline predicts the likelihood of an answer candidate being a true answer.
",4.1 Logistic Regression,[0],[0]
"For each answer candidate e and a given question, we extract the following features: (1) The frequency of e in the story; (2) The number of words within e; (3) Unigrams and bigrams within e; (4) Each non-stop question word combined with each non-stop word within e; (5) The average minimum distance between each non-stop question word and e in the story; (6) The common words (excluding stop words) between the question and the text surrounding of e (within a window of 10 words); (7) Sum of the frequencies of the common words to the left of e, to the right e, and both.",4.1 Logistic Regression,[0],[0]
These features are designed to help the model pick the correct answer spans.,4.1 Logistic Regression,[0],[0]
"They have shown to be effective for answer prediction in previous work (Chen et al., 2016; Rajpurkar et al., 2016).
",4.1 Logistic Regression,[0],[0]
We associate each answer candidate with a binary label indicating whether it is a true answer.,4.1 Logistic Regression,[0],[0]
We train a logistic regression classifier to produce a probability score for each answer candidate.,4.1 Logistic Regression,[0],[0]
"During test, we search for an optimal threshold that maximizes the F1 performance on the validation data.",4.1 Logistic Regression,[0],[0]
"During training, we optimize the cross-entropy loss using Adam (Kingma and Ba, 2014) with an initial learning rate of 0.01.",4.1 Logistic Regression,[0],[0]
"We use a batch size of 10, 000 and train with 5 epochs.",4.1 Logistic Regression,[0],[0]
Training takes roughly 10 minutes for each domain on a Titan X GPU.,4.1 Logistic Regression,[0],[0]
"The seq2seq model is based on the sequence to sequence model presented in (Bahdanau et al., 2015), which includes an attention model.",4.2 Seq2Seq,[0],[0]
"Bahdanau et al. (Bahdanau et al., 2015) have used this model to build a neural based machine translation performing at the state-of-the-art.",4.2 Seq2Seq,[0],[0]
"We adopt this model to fit our own domain by including a preprocessing step in which all statements are concatenated with a dedicated token, while eliminating all previously asked questions, and the current question is added at the end of the list of statements.",4.2 Seq2Seq,[0],[0]
The answers are treated as a sequence of words.,4.2 Seq2Seq,[0],[0]
"We use word embeddings (Zou et al., 2013), as it was shown to improve accuracy.",4.2 Seq2Seq,[0],[0]
"We use 3 GRU (Cho et al., 2014) connected layers, each with a capacity of 256.",4.2 Seq2Seq,[0],[0]
Our batch size was set to 16.,4.2 Seq2Seq,[0],[0]
"We use gradient descent with an initial learning rate of 0.5 and a decay factor of 0.99, iterating on the data for 50, 000 steps (5 epochs).",4.2 Seq2Seq,[0],[0]
The training process for each domain took approximately 48 hours on a Titan X GPU.,4.2 Seq2Seq,[0],[0]
"End-To-End Memory Network (MemN2N) is a neural architecture that encodes both long-term and short-term context into a memory and iteratively reads from the memory (i.e., multiple hops) relevant information to answer a question (Sukhbaatar et al., 2015).",4.3 MemN2N,[0],[0]
"It has been shown to be effective for a variety of question answering tasks (Weston et al., 2015; Sukhbaatar et al., 2015; Hill et al., 2015).
",4.3 MemN2N,[0],[0]
"In this work, we directly apply MemN2N to our task with a small modification.",4.3 MemN2N,[0],[0]
"Originally, MemN2N was designed to produce a single answer for a question, so at the prediction layer, it uses softmax to select the best answer from the answer candidates.",4.3 MemN2N,[0],[0]
"In order to account for multiple answers for a given question, we modify the prediction layer to apply the logistic function and optimize the cross entropy loss instead.",4.3 MemN2N,[0],[0]
"For training, we use the parameter setting as in a publicly available MemN2N 1 except that we set the embedding size to 300 instead of 20.",4.3 MemN2N,[0],[0]
We train the model for 100 epochs and it takes about 2 hours for each domain on a Titan X GPU.,4.3 MemN2N,[0],[0]
"BiDAF (Bidirectional Attention Flow Networks) (Seo et al., 2017) is one of the topperforming models on the span-based question answering dataset SQuAD",4.4 BiDAF-M,[0],[0]
"(Rajpurkar et al., 2016).",4.4 BiDAF-M,[0],[0]
"We reimplement BiDAF with simplified parameterizations and change the prediction layer so that it can predict multiple answer spans.
",4.4 BiDAF-M,[0],[0]
"Specifically, we encode the input story {x1, ..., xT } and a given question {q1, ..., qJ} at the character level and the word level, where the character level uses CNNs and the word level uses pre-trained word vectors.",4.4 BiDAF-M,[0],[0]
The concatenation of the character and word embeddings are passed to a bidirectional LSTM to produce a contextual embedding for each word in the story context and in the question.,4.4 BiDAF-M,[0],[0]
"Then, we apply the same bidirectional attention flow layer to model the interactions between the context and question embeddings, producing question-aware feature vectors for each word in the context, denoted as G ∈ Rdg×T .",4.4 BiDAF-M,[0],[0]
"G is then fed into a bidirectional LSTM layer to obtain a feature matrix M1 ∈ Rd1×T for predicting the start offset of the answer span, and M1 is then passed into
1https://github.com/domluna/memn2n
another bidirectional LSTM layer to obtain a feature matrix M2 ∈ Rd2×T for predicting the end offset of the answer span.",4.4 BiDAF-M,[0],[0]
We then compute two probability scores for each word i in the narrative: pstart = sigmoid(wT1,4.4 BiDAF-M,[0],[0]
[G;M1]) and pend = sigmoid(wT2,4.4 BiDAF-M,[0],[0]
"[G;M1;M2]), where w1 and w2 are trainable weights.",4.4 BiDAF-M,[0],[0]
"The training objective is simply the sum of cross-entropy losses for predicting the start and end indices.
",4.4 BiDAF-M,[0],[0]
"We use 50 1D filters for CNN character embedding, each with a width of 5.",4.4 BiDAF-M,[0],[0]
The word embedding size is 300 and the hidden dimension for LSTMs is 128.,4.4 BiDAF-M,[0],[0]
"For optimization, we use Adam (Kingma and Ba, 2014) with an initial learning rate of 0.001, and use a minibatch size of 32 for 15 epochs.",4.4 BiDAF-M,[0],[0]
The training process takes roughly 20 hours for each domain on a Titan X GPU.,4.4 BiDAF-M,[0],[0]
"DrQA (Chen et al., 2017) is an open-domain QA system that has demonstrated strong performance on multiple QA datasets.",4.5 DrQA-M,[0],[0]
We modify the Document Reader component of DrQA and implement it in a similar framework as BiDAF-M for fair comparisons.,4.5 DrQA-M,[0],[0]
"First, we employ the same character-level and word-level encoding layers to both the input story and a given question.",4.5 DrQA-M,[0],[0]
We then use the concatenation of the character and word embeddings as the final embeddings for words in the story and in the question.,4.5 DrQA-M,[0],[0]
"We compute the aligned question embedding (Chen et al., 2017) as a feature vector for each word in the story and concatenate it with the story word embedding and pass it into a bidirectional LSTM to obtain the contextual embeddings E ∈ Rd×T for words in the story.",4.5 DrQA-M,[0],[0]
"Another bidirectional LSTM is used to obtain the contextual embeddings for the question, and self-
attention is used to compress them into one single vector q ∈ Rd.",4.5 DrQA-M,[0],[0]
"The final prediction layer uses a bilinear term to compute scores for predicting the start offset: pstart = sigmoid(qTW1E) and another bilinear term for predicting the end offset: pend = sigmoid(qTW2E), where W1 and W2 are trainable weights.",4.5 DrQA-M,[0],[0]
"The training loss is the same as in BiDAF-M, and we use the same parameter setting.",4.5 DrQA-M,[0],[0]
Training takes roughly 10 hours for each domain on a Titan X GPU.,4.5 DrQA-M,[0],[0]
We use two evaluation settings for measuring performance at this task: within-world and acrossworld.,5 Experiments,[0],[0]
"In the within-world evaluation setting, we test on the same world that the model was trained on.",5 Experiments,[0],[0]
"We then compute the precision, recall and F1 for each question and report the macro-average F1 score for questions in each world.",5 Experiments,[0],[0]
"In the acrossworld evaluation setting, the model is trained on four out of the five worlds, and tested on the remaining world.",5 Experiments,[0],[0]
"The across-world regime is obviously more challenging, as it requires the model to be able to learn to generalize to unseen relations and vocabulary.",5 Experiments,[0],[0]
"We consider the across-world evaluation setting to be the main evaluation criteria for any future models used on this dataset, as it mimics the practical requirement of any QA system used in personal assistants: it has to be able to answer questions on any new domain the user introduces to the system.",5 Experiments,[0],[0]
We draw several important observations from our results.,5.1 Results,[0],[0]
"First, we observe that more compositional questions (i.e., those that integrate multiple relations) are more challenging for most models - as
all models (except Seq2seq) decrease in performance with the number of relations composed in a question (Figure 5.1).",5.1 Results,[0],[0]
"This can be in part explained by the fact that more composition questions are typically longer, and also require the model to integrate more sources of information in the narrative in order to answer them.",5.1 Results,[0],[0]
One surprising observation from our results is that the performance on questions that ask about a single relation and have only a single answer is lower than questions that ask about a single relation but that can have multiple answers (see detailed results in the Appendix).,5.1 Results,[0],[0]
"This is in part because questions that can have multiple answers typically have canonical entities as answers (e.g., person’s name), and these entities generally repeat in the text, making it easier for the model to find the correct answer.
",5.1 Results,[0],[0]
Table 3 reports the overall (macro-average) F1 scores for different baselines.,5.1 Results,[0],[0]
We can see that BiDAF-M and DrQA-M perform surprisingly well in the within-world evaluation even though they do not use any entity span information.,5.1 Results,[0],[0]
"In particular, DrQA-M outperforms BiDAF-M which suggests that modeling question-context interactions using simple bilinear terms have advantages over using more complex bidirectional attention flows.",5.1 Results,[0],[0]
The lower performance of MemN2N suggests that its effectiveness on the BABI dataset does not directly transfer to our dataset.,5.1 Results,[0],[0]
Note that the original MemN2N architecture uses simple bag-of-words and position encoding for sentences.,5.1 Results,[0],[0]
"This may work well on dataset with a simple vocabulary, for example, MemN2N performs the best in the SOFTWARE world as the SOFTWARE world has
a smaller vocabulary compared to other worlds.",5.1 Results,[0],[0]
"In general, we believe that better text representations for questions and narratives can lead to improved performance.",5.1 Results,[0],[0]
Seq2Seq model also did not perform as well.,5.1 Results,[0],[0]
This is due to the inherent difficulty of generation and encoding long sequences.,5.1 Results,[0],[0]
We found that it performs better when training and testing on shorter stories (limited to 30 statements).,5.1 Results,[0],[0]
"Interestingly, the logistic regression baseline performs on a par with MemN2N, but there is still a large performance gap to BiDAF-M and DrQA-M, and the gap is greater for questions that compose multiple relations.
",5.1 Results,[0],[0]
"In the across-world setting, the performance of all methods dramatically decreases.2 This suggests the limitations of these methods in generalizing to unseen relations and vocabulary.",5.1 Results,[0],[0]
The span-based models BiDAF-M and DrQA-M have an advantage in this setting as they can learn to answer questions based on the alignment between the question and the narrative.,5.1 Results,[0],[0]
"However, the low performance still suggests their limitations in transferring question answering capabilities.",5.1 Results,[0],[0]
"In this work, we have taken the first steps towards the task of multi-relational question answering expressed through personal narrative.",6 Conclusion,[0],[0]
Our hypothesis is that this task will become increasingly important as users begin to teach personal knowledge about their world to the personal assistants embedded in their devices.,6 Conclusion,[0],[0]
This task naturally synthesizes two main branches of question answering research: QA over KBs and QA over free text.,6 Conclusion,[0],[0]
One of our main contributions is a collection of diverse datasets that feature rich compositional questions over a dynamic knowledge graph expressed through simulated narrative.,6 Conclusion,[0],[0]
Another contribution of our work is a thorough set of experiments and analysis of different types of endto-end architectures for QA at their ability to answer multi-relational questions of varying degrees of compositionality.,6 Conclusion,[0],[0]
"Our long-term goal is that both the data and the simulation code we release will inspire and motivate the community to look towards the vision of letting end-users teach our personal assistants about the world around us.
",6 Conclusion,[0],[0]
"2In order to allow generalization across different domains for the Seq2Seq model, we replace entities appearing in each story with an id that correlates to their appearance order.",6 Conclusion,[0],[0]
"After the model outputs its prediction, the entity ids are converted back to the entity phrase.
",6 Conclusion,[0],[0]
The TEXTWORDSQA dataset and the code can be downloaded at https://igorlabutov.,6 Conclusion,[0],[0]
github.io/textworldsqa.github.io/,6 Conclusion,[0],[0]
"This paper was supported in part by Verizon InMind (Azaria and Hong, 2016).",7 Acknowledgments,[0],[0]
One of the GPUs used in this work was donated by Nvidia.,7 Acknowledgments,[0],[0]
"Question Answering (QA), as a research field, has primarily focused on either knowledge bases (KBs) or free text as a source of knowledge.",abstractText,[0],[0]
"These two sources have historically shaped the kinds of questions that are asked over these sources, and the methods developed to answer them.",abstractText,[0],[0]
"In this work, we look towards a practical use-case of QA over user-instructed knowledge that uniquely combines elements of both structured QA over knowledge bases, and unstructured QA over narrative, introducing the task of multirelational QA over personal narrative.",abstractText,[0],[0]
"As a first step towards this goal, we make three key contributions: (i) we generate and release TEXTWORLDSQA, a set of five diverse datasets, where each dataset contains dynamic narrative that describes entities and relations in a simulated world, paired with variably compositional questions over that knowledge, (ii) we perform a thorough evaluation and analysis of several state-of-the-art QA models and their variants at this task, and (iii) we release a lightweight Python-based framework we call TEXTWORLDS for easily generating arbitrary additional worlds and narrative, with the goal of allowing the community to create and share a growing collection of diverse worlds as a test-bed for this task.",abstractText,[0],[0]
Multi-Relational Question Answering from Narratives: Machine Reading and Reasoning in Simulated Worlds,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3219–3232 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3219",text,[0],[0]
"As scientific communities grow and evolve, new tasks, methods, and datasets are introduced and different methods are compared with each other.",1 Introduction,[0],[0]
"Despite advances in search engines, it is still hard to identify new technologies and their relationships with what existed before.",1 Introduction,[0],[0]
"To help researchers more quickly identify opportunities for new combinations of tasks, methods and data, it is important to design intelligent algorithms that can extract and organize scientific information from a large collection of documents.
",1 Introduction,[0],[0]
Organizing scientific information into structured knowledge bases requires information extraction (IE) about scientific entities and their relationships.,1 Introduction,[0],[0]
"However, the challenges associated with scientific IE are greater than for a general domain.",1 Introduction,[0],[0]
"First, annotation of scientific text requires domain expertise which makes annotation costly and limits resources.
",1 Introduction,[0],[0]
1Data and code are publicly available at: http://nlp.,1 Introduction,[0],[0]
"cs.washington.edu/sciIE/
",1 Introduction,[0],[0]
"In addition, most relation extraction systems are designed for within-sentence relations.",1 Introduction,[0],[0]
"However, extracting information from scientific articles requires extracting relations across sentences.",1 Introduction,[0],[0]
Figure 1 illustrates this problem.,1 Introduction,[0],[0]
"The cross-sentence relations between some entities can only be connected by entities that refer to the same scientific concept, including generic terms (such as the pronoun it, or phrases like our method) that are not informative by themselves.",1 Introduction,[0],[0]
"With co-reference, context-free grammar can be connected to MORPA through the intermediate co-referred pronoun it.",1 Introduction,[0],[0]
"Applying existing IE systems to this data, without co-reference, will result in much lower relation coverage (and a sparse knowledge base).
",1 Introduction,[0],[0]
"In this paper, we develop a unified learning model for extracting scientific entities, relations, and coreference resolution.",1 Introduction,[0],[0]
"This is different from previous work (Luan et al., 2017b; Gupta and Manning, 2011; Tsai et al., 2013; Gábor et al., 2018) which often addresses these tasks as independent
components of a pipeline.",1 Introduction,[0],[0]
"Our unified model is a multi-task setup that shares parameters across low-level tasks, making predictions by leveraging context across the document through coreference links.",1 Introduction,[0],[0]
"Specifically, we extend prior work for learning span representations and coreference resolution (Lee et al., 2017; He et al., 2018).",1 Introduction,[0],[0]
"Different from a standard tagging system, our system enumerates all possible spans during decoding and can effectively detect overlapped spans.",1 Introduction,[0],[0]
"It avoids cascading errors between tasks by jointly modeling all spans and span-span relations.
",1 Introduction,[0],[0]
"To explore this problem, we create a dataset SCIERC for scientific information extraction, which includes annotations of scientific terms, relation categories and co-reference links.",1 Introduction,[0],[0]
"Our experiments show that the unified model is better at predicting span boundaries, and it outperforms previous state-of-the-art scientific IE systems on entity and relation extraction (Luan et al., 2017b; Augenstein et al., 2017).",1 Introduction,[0],[0]
"In addition, we build a scientific knowledge graph integrating terms and relations extracted from each article.",1 Introduction,[0],[0]
"Human evaluation shows that propagating coreference can significantly improve the quality of the automatic constructed knowledge graph.
",1 Introduction,[0],[0]
In summary we make the following contributions.,1 Introduction,[0],[0]
"We create a dataset for scientific information extraction by jointly annotating scientific entities, relations, and coreference links.",1 Introduction,[0],[0]
"Extending a previous end-to-end coreference resolution system, we develop a multi-task learning framework that can detect scientific entities, relations, and coreference clusters without hand-engineered features.",1 Introduction,[0],[0]
We use our unified framework to build a scientific knowledge graph from a large collection of documents and analyze information in scientific literature.,1 Introduction,[0],[0]
There has been growing interest in research on automatic methods for information extraction from scientific articles.,2 Related Work,[0],[0]
"Past research in scientific IE addressed analyzing citations (Athar and Teufel, 2012b,a; Kas, 2011; Gabor et al., 2016; Sim et al., 2012; Do et al., 2013; Jaidka et al., 2014; AbuJbara and Radev, 2011), analyzing research community (Vogel and Jurafsky, 2012; Anderson et al., 2012), and unsupervised methods for extracting scientific entities and relations (Gupta and Manning, 2011; Tsai et al., 2013; Gábor et al., 2016).
",2 Related Work,[0],[0]
"More recently, two datasets in SemEval 2017
and 2018 have been introduced, which facilitate research on supervised and semi-supervised learning for scientific information extraction.",2 Related Work,[0],[0]
"SemEval 17 (Augenstein et al., 2017) includes 500 paragraphs from articles in the domains of computer science, physics, and material science.",2 Related Work,[0],[0]
"It includes three types of entities (called keyphrases): Tasks, Methods, and Materials and two relation types: hyponym-of and synonym-of.",2 Related Work,[0],[0]
"SemEval 18 (Gábor et al., 2018) is focused on predicting relations between entities within a sentence.",2 Related Work,[0],[0]
It consists of six relation types.,2 Related Work,[0],[0]
"Using these datasets, neural models (Ammar et al., 2017, 2018; Luan et al., 2017b; Augenstein and Søgaard, 2017) are introduced for extracting scientific information.",2 Related Work,[0],[0]
"We extend these datasets by increasing relation coverage, adding cross-sentence coreference linking, and removing some annotation constraints.",2 Related Work,[0],[0]
"Different from most previous IE systems for scientific literature and general domains (Miwa and Bansal, 2016; Xu et al., 2016; Peng et al., 2017; Quirk and Poon, 2017; Luan et al., 2018; Adel and Schütze, 2017), which use preprocessed syntactic, discourse or coreference features as input, our unified framework does not rely on any pipeline processing and is able to model overlapping spans.
",2 Related Work,[0],[0]
"While Singh et al. (2013) show improvements by jointly modeling entities, relations, and coreference links, most recent neural models for these tasks focus on single tasks (Clark and Manning, 2016; Wiseman et al., 2016; Lee et al., 2017; Lample et al., 2016; Peng et al., 2017) or joint entity and relation extraction (Katiyar and Cardie, 2017; Zhang et al., 2017; Adel and Schütze, 2017; Zheng et al., 2017).",2 Related Work,[0],[0]
"Among those studies, many papers assume the entity boundaries are given, such as (Clark and Manning, 2016), Adel and Schütze (2017) and Peng et al. (2017).",2 Related Work,[0],[0]
Our work relaxes this constraint and predicts entity boundaries by optimizing over all possible spans.,2 Related Work,[0],[0]
"Our model draws from recent end-to-end span-based models for coreference resolution (Lee et al., 2017, 2018) and semantic role labeling (He et al., 2018) and extends them for the multi-task framework involving the three tasks of identification of entity, relation and coreference.
",2 Related Work,[0],[0]
Neural multi-task learning has been applied to a range of NLP tasks.,2 Related Work,[0],[0]
"Most of these models share word-level representations (Collobert and Weston, 2008; Klerke et al., 2016; Luan et al., 2016, 2017a; Rei, 2017), while Peng et al. (2017) uses high-order cross-task factors.",2 Related Work,[0],[0]
"Our model instead propagates
cross-task information via span representations, which is related to Swayamdipta et al. (2017).",2 Related Work,[0],[0]
"Our dataset (called SCIERC) includes annotations for scientific entities, their relations, and coreference clusters for 500 scientific abstracts.",3 Dataset,[0],[0]
These abstracts are taken from 12 AI conference/workshop proceedings in four AI communities from the Semantic Scholar Corpus2.,3 Dataset,[0],[0]
"SCIERC extends previous datasets in scientific articles SemEval 2017 Task 10 (SemEval 17) (Augenstein et al., 2017) and SemEval 2018",3 Dataset,[0],[0]
"Task 7 (SemEval 18) (Gábor et al., 2018) by extending entity types, relation types, relation coverage, and adding cross-sentence relations using coreference links.",3 Dataset,[0],[0]
"Our dataset is publicly available at: http://nlp.cs.washington. edu/sciIE/. Table 1 shows the statistics of SCIERC.
",3 Dataset,[0],[0]
Annotation Scheme,3 Dataset,[0],[0]
"We define six types for annotating scientific entities (Task, Method, Metric, Material, Other-ScientificTerm and Generic) and seven relation types (Compare, Part-of, Conjunction, Evaluate-for, Feature-of, Used-for, HyponymOf).",3 Dataset,[0],[0]
Directionality is taken into account except for the two symmetric relation types (Conjunction and Compare).,3 Dataset,[0],[0]
Coreference links are annotated between identical scientific entities.,3 Dataset,[0],[0]
A Generic entity is annotated only when the entity is involved in a relation or is coreferred with another entity.,3 Dataset,[0],[0]
"Annotation guidelines can be found in Appendix A. Figure 1 shows an annotated example.
",3 Dataset,[0],[0]
"Following annotation guidelines from QasemiZadeh and Schumann (2016) and using the BRAT interface (Stenetorp et al., 2012), our annotators perform a greedy annotation for spans and always prefer the longer span whenever ambiguity occurs.",3 Dataset,[0],[0]
"Nested spans are allowed when a subspan has a relation/coreference link with another term outside the span.
",3 Dataset,[0],[0]
Human Agreements One domain expert annotated all the documents in the dataset; 12% of the data is dually annotated by 4 other domain experts to evaluate the user agreements.,3 Dataset,[0],[0]
"The kappa score for annotating entities is 76.9%, relation extraction is 67.8% and coreference is 63.8%.
",3 Dataset,[0],[0]
"2These conferences include general AI (AAAI, IJCAI), NLP (ACL, EMNLP, IJCNLP), speech (ICASSP, Interspeech), machine learning (NIPS, ICML), and computer vision (CVPR, ICCV, ECCV) at http://labs.semanticscholar.",3 Dataset,[0],[0]
"org/corpus/
Comparison with previous datasets SCIERC is focused on annotating cross-sentence relations and has more relation coverage than SemEval 17 and SemEval 18, as shown in Table 1.",3 Dataset,[0],[0]
SemEval 17 is mostly designed for entity recognition and only covers two relation types.,3 Dataset,[0],[0]
"The task in SemEval 18 is to classify a relation between a pair of entities given entity boundaries, but only intra-sentence relations are annotated and each entity only appears in one relation, resulting in sparser relation coverage than our dataset (3.2 vs. 9.4 relations per abstract).",3 Dataset,[0],[0]
"SCIERC extends these datasets by adding more relation types and coreference clusters, which allows representing cross-sentence relations, and removing annotation constraints.",3 Dataset,[0],[0]
Table 1 gives a comparison of statistics among the three datasets.,3 Dataset,[0],[0]
"In addition, SCIERC aims at including broader coverage of general AI communities.",3 Dataset,[0],[0]
"We develop a unified framework (called SCIIE) to identify and classify scientific entities, relations, and coreference resolution across sentences.",4 Model,[0],[0]
"SCIIE is a multi-task learning setup that extends previous span-based models for coreference resolution (Lee et al., 2017) and semantic role labeling (He et al., 2018).",4 Model,[0],[0]
"All three tasks of entity recognition, relation extraction, and coreference resolution are treated as multinomial classification problems with shared span representations.",4 Model,[0],[0]
SCIIE benefits from expressive contextualized span representations as classifier features.,4 Model,[0],[0]
"By sharing span representations, sentence-level tasks can benefit from information propagated from coreference resolution across sentences, without increasing the complexity of inference.",4 Model,[0],[0]
Figure 2 shows a high-level overview of the SCIIE multi-task framework.,4 Model,[0],[0]
"The input is a document represented as a sequence of words D = {w1, . . .",4.1 Problem Definition,[0],[0]
", wn}, from which we derive S = {s1, . . .",4.1 Problem Definition,[0],[0]
", sN}, the set of all possible
within-sentence word sequence spans (up to a reasonable length) in the document.",4.1 Problem Definition,[0],[0]
"The output contains three structures: the entity types E for all spans S, the relations R for all pair of spans S×S, and the coreference links C for all spans in S. The output structures are represented with a set of discrete random variables indexed by spans or pairs of spans.",4.1 Problem Definition,[0],[0]
"Specifically, the output structures are defined as follows.",4.1 Problem Definition,[0],[0]
Entity recognition is to predict the best entity type for every candidate span.,4.1 Problem Definition,[0],[0]
Let LE represent the set of all possible entity types including the null-type .,4.1 Problem Definition,[0],[0]
"The output structure E is a set of random variables indexed by spans: ei ∈ LE for i = 1, . . .",4.1 Problem Definition,[0],[0]
", N .",4.1 Problem Definition,[0],[0]
"Relation extraction is to predict the best relation type given an ordered pair of spans (si, sj).",4.1 Problem Definition,[0],[0]
Let LR be the set of all possible relation types including the null-type .,4.1 Problem Definition,[0],[0]
"The output structure R is a set of random variables indexed over pairs of spans (i, j) that belong to the same sentence: rij ∈ LR for i, j = 1, . . .",4.1 Problem Definition,[0],[0]
", N .",4.1 Problem Definition,[0],[0]
"Coreference resolution is to predict the best antecedent (including a special null antecedent) given a span, which is the same mention-ranking model used in Lee et al. (2017).",4.1 Problem Definition,[0],[0]
"The output structure C is a set of random variables defined as: ci ∈ {1, . .",4.1 Problem Definition,[0],[0]
.,4.1 Problem Definition,[0],[0]
", i− 1, } for i = 1, . . .",4.1 Problem Definition,[0],[0]
", N .",4.1 Problem Definition,[0],[0]
"We formulate the multi-task learning setup as learning the conditional probability distribution P (E,R,C|D).",4.2 Model Definition,[0],[0]
"For efficient training and inference, we decompose P (E,R,C|D)",4.2 Model Definition,[0],[0]
"assuming spans are
conditionally independent given D:
P (E,R,C | D) = P (E,R,C, S | D) (1)
",4.2 Model Definition,[0],[0]
= N∏ i=1,4.2 Model Definition,[0],[0]
"P (ei | D)P (ci | D) N∏ j=1 P (rij | D),
where the conditional probabilities of each random variable are independently normalized: P (ei = e | D) = exp(ΦE(e, si))∑
e′∈LE exp(ΦE(e ′, si))
(2)
P (rij = r | D) = exp(ΦR(r, si, sj))∑
r′∈LR",4.2 Model Definition,[0],[0]
"exp(ΦR(r ′, si, sj))
P (ci = j | D) = exp(ΦC(si, sj))∑
j′∈{1,...,i−1, } exp(ΦC(si, sj′)) ,
where ΦE denotes the unnormalized model score for an entity type e and a span si, ΦR denotes the score for a relation type r and span pairs si, sj , and ΦC denotes the score for a binary coreference link between si and sj .",4.2 Model Definition,[0],[0]
"These Φ scores are further decomposed into span and pairwise span scores computed from feed-forward networks, as will be explained in Section 4.3.
",4.2 Model Definition,[0],[0]
"For simplicity, we omit D from the Φ functions and S from the observation.
",4.2 Model Definition,[0],[0]
"Objective Given a set of all documents D, the model loss function is defined as a weighted sum of the negative log-likelihood loss of all three tasks:
− ∑
(D,R∗,E∗,C∗)∈D
{ λE logP (E ∗ | D) (3)
+ λR",4.2 Model Definition,[0],[0]
"logP (R ∗ | D) + λC logP (C∗ | D)
}
where E∗, R∗, and C∗ are gold structures of the entity types, relations, and coreference, respectively.",4.2 Model Definition,[0],[0]
"The task weights λE, λR, and λC are introduced as hyper-parameters to control the importance of each task.
",4.2 Model Definition,[0],[0]
"For entity recognition and relation extraction, P (E∗ | D) and P (R∗ | D) are computed with the definition in Equation (2).",4.2 Model Definition,[0],[0]
"For coreference resolution, we use the marginalized loss following Lee et al. (2017) since each mention can have multiple correct antecedents.",4.2 Model Definition,[0],[0]
"Let C∗i be the set of all correct antecedents for span i, we have: logP (C∗ | D) = ∑ i=1..",4.2 Model Definition,[0],[0]
N log ∑ c∈C∗i P (c | D).,4.2 Model Definition,[0],[0]
We use feedforward neural networks (FFNNs) over shared span representations g to compute a set of span and pairwise span scores.,4.3 Scoring Architecture,[0],[0]
"For the span scores, φe(si) measures how likely a span si has an entity type e, and φmr(si) and φmc(si) measure how likely a span si is a mention in a relation or a coreference link, respectively.",4.3 Scoring Architecture,[0],[0]
"The pairwise scores φr(si, sj) and φc(si, sj) measure how likely two spans are associated in a relation r or a coreference link, respectively.",4.3 Scoring Architecture,[0],[0]
Let gi be the fixed-length vector representation for span si.,4.3 Scoring Architecture,[0],[0]
"For different tasks, the span scores φx(si) for x ∈ {e,mc,mr} and pairwise span scores φy(si, sj) for y ∈ {r, c} are computed as follows:
φx(si)",4.3 Scoring Architecture,[0],[0]
"=wx · FFNNx(gi) φy(si, sj) =wy · FFNNy([gi,gj ,gi gj ]),
where is element-wise multiplication, and {wx,wy} are neural network parameters to be learned.
",4.3 Scoring Architecture,[0],[0]
"We use these scores to compute the different Φ:
ΦE(e, si) = φe(si) (4)
ΦR(r, si, sj) = φmr(si) + φmr(sj) + φr(si, sj)
ΦC(si, sj) = φmc(si) + φmc(sj) + φc(si, sj)
",4.3 Scoring Architecture,[0],[0]
"The scores in Equation (4) are defined for entity types, relations, and antecedents that are not the null-type .",4.3 Scoring Architecture,[0],[0]
"Scores involving the null label are set to a constant 0: ΦE( , si) = ΦR( , si, sj) = ΦC(si, ) = 0.
",4.3 Scoring Architecture,[0],[0]
"We use the same span representations g from (Lee et al., 2017) and share them across the three tasks.",4.3 Scoring Architecture,[0],[0]
"We start by building bi-directional LSTMs (Hochreiter and Schmidhuber, 1997) from word, character and ELMo (Peters et al., 2018) embeddings.
",4.3 Scoring Architecture,[0],[0]
"For a span si, its vector representation gi is constructed by concatenating si’s left and right end points from the BiLSTM outputs, an attentionbased soft “headword,” and embedded span width features.",4.3 Scoring Architecture,[0],[0]
Hyperparameters and other implementation details will be described in Section 6.,4.3 Scoring Architecture,[0],[0]
"Following previous work, we use beam pruning to reduce the number of pairwise span factors from O(n4) to O(n2) at both training and test time, where n is the number of words in the document.",4.4 Inference and Pruning,[0],[0]
"We define two separate beams: BC to prune spans for the coreference resolution task, and BR for relation extraction.",4.4 Inference and Pruning,[0],[0]
"The spans in the beams are sorted by their span scores φmc and φmr respectively, and the sizes of the beams are limited by λCn and λRn.",4.4 Inference and Pruning,[0],[0]
"We also limit the maximum width of spans to a fixed number W , which further reduces the number of span factors to O(n).",4.4 Inference and Pruning,[0],[0]
We construct a scientific knowledge graph from a large corpus of scientific articles.,5 Knowledge Graph Construction,[0],[0]
The corpus includes all abstracts (110k in total) from 12 AI conference proceedings from the Semantic Scholar Corpus.,5 Knowledge Graph Construction,[0],[0]
Nodes in the knowledge graph correspond to scientific entities.,5 Knowledge Graph Construction,[0],[0]
Edges correspond to scientific relations between pairs of entities.,5 Knowledge Graph Construction,[0],[0]
The edges are typed according to the relation types defined in Section 3.,5 Knowledge Graph Construction,[0],[0]
Figure 4 shows a part of a knowledge graph created by our method.,5 Knowledge Graph Construction,[0],[0]
"For example, Statistical Machine Translation (SMT) and grammatical error correction are nodes in the graph, and they are connected through a Used-for relation type.",5 Knowledge Graph Construction,[0],[0]
"In order to construct the knowledge graph for the whole corpus, we first apply the SCIIE model over single documents and then integrate the entities and relations across multiple documents (Figure 3).
",5 Knowledge Graph Construction,[0],[0]
Extracting nodes (entities),5 Knowledge Graph Construction,[0],[0]
"The SCIIE model extracts entities, their relations, and coreference
clusters within one document.",5 Knowledge Graph Construction,[0],[0]
Phrases are heuristically normalized (described in Section 6) using entities and coreference links.,5 Knowledge Graph Construction,[0],[0]
"In particular, we link all entities that belong to the same coreference cluster to replace generic terms with any other nongeneric term in the cluster.",5 Knowledge Graph Construction,[0],[0]
"Moreover, we replace all the entities in the cluster with the entity that has the longest string.",5 Knowledge Graph Construction,[0],[0]
Our qualitative analysis shows that there are fewer ambiguous phrases using coreference links (Figure 5).,5 Knowledge Graph Construction,[0],[0]
We calculate the frequency counts of all entities that appear in the whole corpus.,5 Knowledge Graph Construction,[0],[0]
"We assign nodes in the knowledge graph by selecting the most frequent entities (with counts > k) in the corpus, and merge in any remaining entities for which a frequent entity is a substring.
",5 Knowledge Graph Construction,[0],[0]
"Assigning edges (relations) A pair of entities may appear in different contexts, resulting in different relation types between those entities (Figure 6).",5 Knowledge Graph Construction,[0],[0]
"For every pair of entities in the graph, we calculate the frequency of different relation types across the whole corpus.",5 Knowledge Graph Construction,[0],[0]
We assign edges between entities by selecting the most frequent relation type.,5 Knowledge Graph Construction,[0],[0]
We evaluate our unified framework SCIIE on SCIERC and SemEval 17.,6 Experimental Setup,[0],[0]
"The knowledge graph for
scientific community analysis is built using the Semantic Scholar Corpus (110k abstracts in total).",6 Experimental Setup,[0],[0]
"We compare our model with the following baselines on SCIERCdataset:
• LSTM+CRF",6.1 Baselines,[0],[0]
"The state-of-the-art NER system (Lample et al., 2016), which applies CRF on top of LSTM for named entity tagging, the approach has also been used in scientific term extraction (Luan et al., 2017b).
",6.1 Baselines,[0],[0]
"• LSTM+CRF+ELMo LSTM+CRF with ELMO as an additional input feature.
• E2E Rel State-of-the-art joint entity and relation extraction system (Miwa and Bansal, 2016) that has also been used in scientific literature (Peters et al., 2017; Augenstein et al., 2017).",6.1 Baselines,[0],[0]
"This system uses syntactic features such as part-of-speech tagging and dependency parsing.
",6.1 Baselines,[0],[0]
•,6.1 Baselines,[0],[0]
E2E Rel(Pipeline) Pipeline setting of E2E Rel.,6.1 Baselines,[0],[0]
"Extract entities first and use entity results as input to relation extraction task.
",6.1 Baselines,[0],[0]
•,6.1 Baselines,[0],[0]
"E2E Rel+ELMo E2E Rel with ELMO as an additional input feature.
•",6.1 Baselines,[0],[0]
E2E Coref State-of-the-art coreference system Lee et al. (2017) combined with ELMO.,6.1 Baselines,[0],[0]
"Our system SCIIE extends E2E Coref with multi-task learning.
",6.1 Baselines,[0],[0]
"In the SemEval task, we compare our model SCIIE with the best reported system in the SemEval leaderboard (Peters et al., 2017), which extends E2E Rel with several in-domain features such as gazetteers extracted from existing knowledge bases and model ensembles.",6.1 Baselines,[0],[0]
"We also compare with the state of the art on keyphrase extraction (Luan et al., 2017b), which applies semi-supervised methods to a neural tagging model.3",6.1 Baselines,[0],[0]
Our system extends the implementation and hyperparameters from Lee et al. (2017) with the following adjustments.,6.2 Implementation details,[0],[0]
We use a 1 layer BiLSTM with 200-dimensional hidden layers.,6.2 Implementation details,[0],[0]
All the FFNNs have 2 hidden layers of 150 dimensions each.,6.2 Implementation details,[0],[0]
"We use 0.4 variational dropout (Gal and Ghahramani, 2016) for the LSTMs, 0.4 dropout for the FFNNs, and 0.5 dropout for the input embeddings.",6.2 Implementation details,[0],[0]
We model spans up to 8 words.,6.2 Implementation details,[0],[0]
"For beam pruning, we use λC = 0.3 for coreference resolution and λR = 0.4 for relation extraction.",6.2 Implementation details,[0],[0]
"For constructing the knowledge graph, we use the following heuristics to normalize the entity phrases.",6.2 Implementation details,[0],[0]
We replace all acronyms with their corresponding full name and normalize all the plural terms with their singular counterparts.,6.2 Implementation details,[0],[0]
We evaluate SCIIE on SCIERC and SemEval 17 datasets.,7 Experimental Results,[0],[0]
We provide qualitative results and human evaluation of the constructed knowledge graph.,7 Experimental Results,[0],[0]
"Results on SciERC Table 2 compares the result of our model with baselines on the three tasks: entity recognition (Table 2a), relation extraction (Table 2b), and coreference resolution (Table 2c).",7.1 IE Results,[0],[0]
"As evidenced by the table, our unified multi-task setup
3We compare with the inductive setting results.
",7.1 IE Results,[0],[0]
SCIIE outperforms all the baselines.,7.1 IE Results,[0],[0]
"For entity recognition, our model achieves 1.3% and 2.4% relative improvement over LSTM+CRF with and without ELMO, respectively.",7.1 IE Results,[0],[0]
"Moreover, it achieves 1.8% and 2.7% relative improvement over E2E Rel with and without ELMO, respectively.",7.1 IE Results,[0],[0]
"For relation extraction, we observe more significant improvement with 13.1% relative improvement over E2E Rel and 7.4% improvement over E2E Rel with ELMO.",7.1 IE Results,[0],[0]
"For coreference resolution, SCIIE outperforms E2E Coref with 4.5% relative improvement.",7.1 IE Results,[0],[0]
We still observe a large gap between human-level performance and a machine learning system.,7.1 IE Results,[0],[0]
"We invite the community to address this challenging task.
",7.1 IE Results,[0],[0]
Ablations We evaluate the effect of multi-task learning in each of the three tasks defined in our dataset.,7.1 IE Results,[0],[0]
Table 3 reports the results for individual tasks when additional tasks are included in the learning objective function.,7.1 IE Results,[0],[0]
We observe that performance improves with each added task in the objective.,7.1 IE Results,[0],[0]
"For example, Entity recognition (65.7) benefits from both coreference resolution (67.5) and relation extraction (66.8).",7.1 IE Results,[0],[0]
"Relation extrac-
tion (37.9) significantly benefits when multi-tasked with coreference resolution (7.1% relative improvement).",7.1 IE Results,[0],[0]
"Coreference resolution benefits when multitasked with relation extraction, with 4.9% relative improvement.
Results on SemEval 17 Table 4 compares the results of our model with the state of the art on the SemEval 17 dataset for tasks of span identification, keyphrase extraction and relation extraction as well as the overall score.",7.1 IE Results,[0],[0]
Span identification aims at identifying spans of entities.,7.1 IE Results,[0],[0]
Keyphrase classification and relation extraction has the same setting with the entity and relation extraction in SCIERC.,7.1 IE Results,[0],[0]
Our model outperforms all the previous models that use hand-designed features.,7.1 IE Results,[0],[0]
We observe more significant improvement in span identification than keyphrase classification.,7.1 IE Results,[0],[0]
This confirms the benefit of our model in enumerating spans (rather than BIO tagging in state-of-the-art systems).,7.1 IE Results,[0],[0]
"Moreover, we have competitive results compared to the previous state of the art in relation extraction.",7.1 IE Results,[0],[0]
"We observe less gain compared to the SCIERC dataset mainly because there are no coference links, and the relation types are not comprehensive.",7.1 IE Results,[0],[0]
"We provide qualitative analysis and human evaluations on the constructed knowledge graph.
",7.2 Knowledge Graph Analysis,[0],[0]
"Scientific trend analysis Figure 7 shows the historical trend analysis (from 1996 to 2016) of the most popular applications of the phrase neural network, selected according to the statistics of the extracted relation triples with the ‘Used-for’ relation type from speech, computer vision, and NLP conference papers.",7.2 Knowledge Graph Analysis,[0],[0]
"We observe that, before 2000, neural network has been applied to a greater percentage of speech applications compared to the NLP and computer vision papers.",7.2 Knowledge Graph Analysis,[0],[0]
"In NLP, neural networks first gain popularity in language modeling
and then extend to other tasks such as POS Tagging and Machine Translation.",7.2 Knowledge Graph Analysis,[0],[0]
"In computer vision, the application of neural networks gains popularity in object recognition earlier (around 2010) than the other two more complex tasks of object detection and image segmentation (hardest and also the latest).
",7.2 Knowledge Graph Analysis,[0],[0]
"Knowledge Graph Evaluation Figure 8 shows the human evaluation of the constructed knowledge graph, comparing the quality of automatically generated knowledge graphs with and without the coreference links.",7.2 Knowledge Graph Analysis,[0],[0]
We randomly select 10 frequent scientific entities and extract all the relation triples that include one of the selected entities leading to 1.5k relation triples from both systems.,7.2 Knowledge Graph Analysis,[0],[0]
"We ask four domain experts to annotate each of these ex-
tracted relations to define ground truth labels.",7.2 Knowledge Graph Analysis,[0],[0]
Each domain expert is assigned 2 or 3 entities and all of the corresponding relations.,7.2 Knowledge Graph Analysis,[0],[0]
Figure 8 shows precision/recall curves for both systems.,7.2 Knowledge Graph Analysis,[0],[0]
"Since it is not feasible to compute the actual recall of the systems, we compute the pseudo-recall (Zhang et al., 2015) based on the output of both systems.",7.2 Knowledge Graph Analysis,[0],[0]
We observe that the knowledge graph curve with coreference linking is mostly above the curve without coreference linking.,7.2 Knowledge Graph Analysis,[0],[0]
"The precision of both systems is high (above 84% for both systems), but the system with coreference links has significantly higher recall.",7.2 Knowledge Graph Analysis,[0],[0]
"In this paper, we create a new dataset and develop a multi-task model for identifying entities, relations, and coreference clusters in scientific articles.",8 Conclusion,[0],[0]
"By sharing span representations and leveraging crosssentence information, our multi-task setup effectively improves performance across all tasks.",8 Conclusion,[0],[0]
"Moreover, we show that our multi-task model is better at predicting span boundaries and outperforms previous state-of-the-art scientific IE systems on entity and relation extraction, without using any handengineered features or pipeline processing.",8 Conclusion,[0],[0]
"Using our model, we are able to automatically organize the extracted information from a large collection of scientific articles into a knowledge graph.",8 Conclusion,[0],[0]
"Our analysis shows the importance of coreference links in making a dense, useful graph.
",8 Conclusion,[0],[0]
"We still observe a large gap between the performance of our model and human performance, confirming the challenges of scientific IE.",8 Conclusion,[0],[0]
Future work includes improving the performance using semisupervised techniques and providing in-domain features.,8 Conclusion,[0],[0]
We also plan to extend our multi-task framework to information extraction tasks in other domains.,8 Conclusion,[0],[0]
"This research was supported by the Office of Naval Research under the MURI grant N00014-18-1-
2670, NSF (IIS 1616112, III 1703166), Allen Distinguished Investigator Award, and gifts from Allen Institute for AI, Google, Amazon, and Bloomberg.",Acknowledgments,[0],[0]
We are grateful to Waleed Ammar and AI2 for sharing the Semantic Scholar Corpus.,Acknowledgments,[0],[0]
"We also thank the anonymous reviewers, UW-NLP group and Shoou-I Yu for their helpful comments.",Acknowledgments,[0],[0]
A.1 Entity Category •,A Annotation Guideline,[0],[0]
"Task: Applications, problems to solve, sys-
tems to construct.
",A Annotation Guideline,[0],[0]
"E.g. information extraction, machine reading system, image segmentation, etc.
•",A Annotation Guideline,[0],[0]
"Method: Methods , models, systems to use, or tools, components of a system, frameworks.
",A Annotation Guideline,[0],[0]
"E.g. language model, CORENLP, POS parser, kernel method, etc.
•",A Annotation Guideline,[0],[0]
"Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method.
",A Annotation Guideline,[0],[0]
"E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness, time complexity, etc.
•",A Annotation Guideline,[0],[0]
"Material: Data, datasets, resources, Corpus, Knowledge base.
",A Annotation Guideline,[0],[0]
"E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL, Panntreebank, WordNet, Wikipedia, etc.
",A Annotation Guideline,[0],[0]
"• Evaluation Metric: Metric measure or term that can express quality of a system/method.
",A Annotation Guideline,[0],[0]
"E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error,robustness, compile time, time complexity...
",A Annotation Guideline,[0],[0]
•,A Annotation Guideline,[0],[0]
"Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words.
",A Annotation Guideline,[0],[0]
"E.g model, approach, prior knowledge, them, it...
",A Annotation Guideline,[0],[0]
A.2 Relation Category Relation link can not go beyond sentence boundary.,A Annotation Guideline,[0],[0]
"We define 4 asymmetric relation types (Used-for, Feature-of, Hyponym-of, Part-of ), together with 2 symmetric relation types (Compare, Conjunction).",A Annotation Guideline,[0],[0]
"B always points to A for asymmetric relations
• Used-for: B is used for A, B models A, A is trained on B, B exploits A, A is based on B. E.g.
The TISPER system has been designed to enable many text applications.
",A Annotation Guideline,[0],[0]
Our method models user proficiency.,A Annotation Guideline,[0],[0]
"Our algorithms exploits local soothness.
",A Annotation Guideline,[0],[0]
"• Feature-of: B belongs to A, B is a feature of A, B is under A domain.",A Annotation Guideline,[0],[0]
"E.g.
prior knowledge of the model genre-specific regularities of discourse structure English text in science domain
• Hyponym-of: B is a hyponym of A, B is a type of A. E.g.
TUIT is a software library NLP applications such as machine translation and language generation
• Part-of: B is a part of A...",A Annotation Guideline,[0],[0]
"E.g.
The system includes two models: speech recognition and natural language understanding We incorporate NLU module to the system.
",A Annotation Guideline,[0],[0]
• Compare: Symmetric relation (use blue to denote entity).,A Annotation Guideline,[0],[0]
"Opposite of conjunction, compare two models/methods, or listing two opposing entities.",A Annotation Guideline,[0],[0]
"E.g.
Unlike the quantitative prior, the qualitative prior is often ignored...",A Annotation Guideline,[0],[0]
"We compare our system with previous sequential tagging systems...
•",A Annotation Guideline,[0],[0]
Conjunction: Symmetric relation (use blue to denote entity).,A Annotation Guideline,[0],[0]
Function as similar role or use/incorporate with.,A Annotation Guideline,[0],[0]
"E.g.
obtained from human expert or knowledge base NLP applications such as machine translation and language generation
A.3 Coreference Two Entities that points to the same concept.
",A Annotation Guideline,[0],[0]
•,A Annotation Guideline,[0],[0]
"Anaphora and Cataphora:
We introduce a machine reading system...",A Annotation Guideline,[0],[0]
The system...,A Annotation Guideline,[0],[0]
The prior knowledge include...,A Annotation Guideline,[0],[0]
"Such knowledge can be applied to...
•",A Annotation Guideline,[0],[0]
"Coreferring noun phrase:
We develop a part-of-speech tagging system...",A Annotation Guideline,[0],[0]
"The POS tagger...
A.4 Notes 1.",A Annotation Guideline,[0],[0]
"Entity boundary annotation follows the
ACL RD-TEC Annotation Guideline (QasemiZadeh and Schumann, 2016), with the extention that spans can be embedded in longer spans, only if the shorter span is involved in a relation.
2.",A Annotation Guideline,[0],[0]
"Do not include determinators (such as the, a), or adjective pronouns (such as this,its, these, such) to the span.",A Annotation Guideline,[0],[0]
"If generic phrases are not involved in a relation, do not tag them.
",A Annotation Guideline,[0],[0]
3.,A Annotation Guideline,[0],[0]
"Do not tag relation if one entity is:
• Variable bound: We introduce a neural based approach..",A Annotation Guideline,[0],[0]
"Its benefit is... • The word which:
We introduce a neural based approach, which is a...
4.",A Annotation Guideline,[0],[0]
"Do not tag coreference if the entity is
• Generically-used Other-ScientificTerm: ...advantage gained from local smoothness which...",A Annotation Guideline,[0],[0]
We present algorithms exploiting local smoothness in more aggressive ways...,A Annotation Guideline,[0],[0]
"• Same scientific term but refer to different
examples: We use a data structure, we also use another data structure...
5.",A Annotation Guideline,[0],[0]
"Do not label negative relations:
X is not used in Y or X is hard to be applied in Y",A Annotation Guideline,[0],[0]
Here we take a screen shot of the BRAT interface for an ACL paper in Figure 9.,B Annotation and Knowledge Graph Examples,[0],[0]
We also attach the original figure of Figure 3 in Figure 10.,B Annotation and Knowledge Graph Examples,[0],[0]
"More examples can be found in the project website4.
",B Annotation and Knowledge Graph Examples,[0],[0]
4http://nlp.cs.washington.edu/sciIE/,B Annotation and Knowledge Graph Examples,[0],[0]
"We introduce a multi-task setup of identifying and classifying entities, relations, and coreference clusters in scientific articles.",abstractText,[0],[0]
"We create SCIERC, a dataset that includes annotations for all three tasks and develop a unified framework called Scientific Information Extractor (SCIIE) for with shared span representations.",abstractText,[0],[0]
The multi-task setup reduces cascading errors between tasks and leverages cross-sentence relations through coreference links.,abstractText,[0],[0]
Experiments show that our multi-task model outperforms previous models in scientific information extraction without using any domain-specific features.,abstractText,[0],[0]
"We further show that the framework supports construction of a scientific knowledge graph, which we use to analyze information in scientific literature.1",abstractText,[0],[0]
"Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction",title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1896–1906 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
Multi-task learning (MTL) and semi-supervised learning are both successful paradigms for learning in scenarios with limited labelled data and have in recent years been applied to almost all areas of NLP.,1 Introduction,[0],[0]
"Applications of MTL in NLP, for example, include partial parsing (Søgaard and Goldberg, 2016), text normalisation (Bollman et al., 2017), neural machine translation (Luong et al., 2016), and keyphrase boundary classification (Augenstein and Søgaard, 2017).
",1 Introduction,[0],[0]
"Contemporary work in MTL for NLP typically focuses on learning representations that are useful across tasks, often through hard parameter sharing of hidden layers of neural networks (Collobert et al., 2011; Søgaard and Goldberg, 2016).",1 Introduction,[0],[0]
"If tasks share optimal hypothesis classes at the level of these representations, MTL leads to improvements (Baxter, 2000).",1 Introduction,[0],[0]
"However, while sharing hidden layers of neural networks is an effective regulariser (Søgaard and Goldberg, 2016), we potentially loose synergies between the classification functions trained to associate these representations with class labels.",1 Introduction,[0],[0]
"This paper sets out to build an architecture in which such synergies are exploited,
?",1 Introduction,[0],[0]
"The first two authors contributed equally.
with an application to pairwise sequence classification tasks.",1 Introduction,[0],[0]
"Doing so, we achieve a new state of the art on topic-based sentiment analysis.
",1 Introduction,[0],[0]
"For many NLP tasks, disparate label sets are weakly correlated, e.g. part-of-speech tags correlate with dependencies (Hashimoto et al., 2017), sentiment correlates with emotion (Felbo et al., 2017; Eisner et al., 2016), etc.",1 Introduction,[0],[0]
"We thus propose to induce a joint label embedding space (visualised in Figure 2) using a Label Embedding Layer that allows us to model these relationships, which we show helps with learning.
",1 Introduction,[0],[0]
"In addition, for tasks where labels are closely related, we should be able to not only model their relationship, but also to directly estimate the corresponding label of the target task based on auxiliary predictions.",1 Introduction,[0],[0]
"To this end, we propose to train a Label Transfer Network (LTN) jointly with the model to produce pseudo-labels across tasks.
",1 Introduction,[0],[0]
"The LTN can be used to label unlabelled and auxiliary task data by utilising the ‘dark knowledge’ (Hinton et al., 2015) contained in auxiliary model predictions.",1 Introduction,[0],[0]
"This pseudo-labelled data is then incorporated into the model via semisupervised learning, leading to a natural combination of multi-task learning and semi-supervised learning.",1 Introduction,[0],[0]
"We additionally augment the LTN with data-specific diversity features (Ruder and Plank, 2017) that aid in learning.
",1 Introduction,[0],[0]
Contributions,1 Introduction,[0],[0]
Our contributions are: a) We model the relationships between labels by inducing a joint label space for multi-task learning.,1 Introduction,[0],[0]
b),1 Introduction,[0],[0]
We propose a Label Transfer Network that learns to transfer labels between tasks and propose to use semi-supervised learning to leverage them for training.,1 Introduction,[0],[0]
c),1 Introduction,[0],[0]
We evaluate MTL approaches on a variety of classification tasks and shed new light on settings where multi-task learning works.,1 Introduction,[0],[0]
d),1 Introduction,[0],[0]
"We perform an extensive ablation study of our model.
1896
e)",1 Introduction,[0],[0]
We report state-of-the-art performance on topicbased sentiment analysis.,1 Introduction,[0],[0]
"Learning task similarities Existing approaches for learning similarities between tasks enforce a clustering of tasks (Evgeniou et al., 2005; Jacob et al., 2009), induce a shared prior (Yu et al., 2005; Xue et al., 2007; Daumé III, 2009), or learn a grouping (Kang et al., 2011; Kumar and Daumé III, 2012).",2 Related work,[0],[0]
These approaches focus on homogeneous tasks and employ linear or Bayesian models.,2 Related work,[0],[0]
"They can thus not be directly applied to our setting with tasks using disparate label sets.
",2 Related work,[0],[0]
"Multi-task learning with neural networks Recent work in multi-task learning goes beyond hard parameter sharing (Caruana, 1993) and considers different sharing structures, e.g. only sharing at lower layers (Søgaard and Goldberg, 2016) and induces private and shared subspaces (Liu et al., 2017; Ruder et al., 2017).",2 Related work,[0],[0]
"These approaches, however, are not able to take into account relationships between labels that may aid in learning.",2 Related work,[0],[0]
"Another related direction is to train on disparate annotations of the same task (Chen et al., 2016; Peng et al., 2017).",2 Related work,[0],[0]
"In contrast, the different nature of our tasks requires a modelling of their label spaces.
",2 Related work,[0],[0]
"Semi-supervised learning There exists a wide range of semi-supervised learning algorithms, e.g., self-training, co-training, tri-training, EM, and combinations thereof, several of which have also been used in NLP.",2 Related work,[0],[0]
"Our approach is probably most closely related to an algorithm called coforest (Li and Zhou, 2007).",2 Related work,[0],[0]
"In co-forest, like here, each learner is improved with unlabeled instances labeled by the ensemble consisting of all the other learners.",2 Related work,[0],[0]
"Note also that several researchers have proposed using auxiliary tasks that are unsupervised (Plank et al., 2016; Rei, 2017), which also leads to a form of semi-supervised models.
",2 Related work,[0],[0]
Label transformations The idea of manually mapping between label sets or learning such a mapping to facilitate transfer is not new.,2 Related work,[0],[0]
"Zhang et al. (2012) use distributional information to map from a language-specific tagset to a tagset used for other languages, in order to facilitate crosslingual transfer.",2 Related work,[0],[0]
"More related to this work, Kim et al. (2015) use canonical correlation analysis to transfer between tasks with disparate label spaces.",2 Related work,[0],[0]
"There has also been work on label transformations
in the context of multi-label classification problems (Yeh et al., 2017).",2 Related work,[0],[0]
"In our multi-task learning scenario, we have access to labelled datasets for T tasks T1, . . .",3.1 Problem definition,[0],[0]
", TT at training time with a target task TT that we particularly care about.",3.1 Problem definition,[0],[0]
The training dataset for task Ti consists of Nk examples XTi =,3.1 Problem definition,[0],[0]
"{xTi1 , . . .",3.1 Problem definition,[0],[0]
", xTiNk}",3.1 Problem definition,[0],[0]
"and their labels YTi = {yTi1 , . . .",3.1 Problem definition,[0],[0]
",yTiNk}.",3.1 Problem definition,[0],[0]
"Our base model is a deep neural network that performs classic hard parameter sharing (Caruana, 1993):",3.1 Problem definition,[0],[0]
"It shares its parameters across tasks and has task-specific softmax output layers, which output a probability distribution pTi for task Ti according to the following equation:
pTi = softmax(WTih+ bTi)",3.1 Problem definition,[0],[0]
"(1)
where softmax(x) = ex/ ∑‖x‖
i=1",3.1 Problem definition,[0],[0]
"e xi , WTi ∈
RLi×h, bTi ∈ RLi is the weight matrix and bias term of the output layer of task Ti respectively, h ∈",3.1 Problem definition,[0],[0]
"Rh is the jointly learned hidden representation, Li is the number of labels for task Ti, and h is the dimensionality of h.
The MTL model is then trained to minimise the sum of the individual task losses:
L = λ1L1",3.1 Problem definition,[0],[0]
+ .,3.1 Problem definition,[0],[0]
.,3.1 Problem definition,[0],[0]
.+,3.1 Problem definition,[0],[0]
"λTLT (2) where Li is the negative log-likelihood objec-
tive Li = H(pTi ,yTi)",3.1 Problem definition,[0],[0]
=,3.1 Problem definition,[0],[0]
− 1N ∑ n ∑ j logp Ti j y Ti j,3.1 Problem definition,[0],[0]
and λi is a parameter that determines the weight of task Ti.,3.1 Problem definition,[0],[0]
"In practice, we apply the same weight to all tasks.",3.1 Problem definition,[0],[0]
We show the full set-up in Figure 1a.,3.1 Problem definition,[0],[0]
"In order to learn the relationships between labels, we propose a Label Embedding Layer (LEL) that embeds the labels of all tasks in a joint space.",3.2 Label Embedding Layer,[0],[0]
"Instead of training separate softmax output layers as above, we introduce a label compatibility function c(·, ·) that measures how similar a label with embedding l is to the hidden representation h:
c(l,h) =",3.2 Label Embedding Layer,[0],[0]
l · h (3) where · is the dot product.,3.2 Label Embedding Layer,[0],[0]
This is similar to the Universal Schema Latent Feature Model introduced by Riedel et al. (2013).,3.2 Label Embedding Layer,[0],[0]
"In contrast to
12/6/2017 multi-task_learning.html
1/2
12/6/2017 label_embedding_layer.html
1/2
12/6/2017 label_transfer_network.html
2/3
other models that use the dot product in the objective function, we do not have to rely on negative sampling and a hinge loss (Collobert and Weston, 2008) as negative instances (labels) are known.",3.2 Label Embedding Layer,[0],[0]
"For efficiency purposes, we use matrix multiplication instead of a single dot product and softmax instead of sigmoid activations:
p = softmax(Lh) (4)
where L ∈ R( ∑
i Li)×l is the label embedding matrix for all tasks and l is the dimensionality of the label embeddings.",3.2 Label Embedding Layer,[0],[0]
"In practice, we set l to the hidden dimensionality h.",3.2 Label Embedding Layer,[0],[0]
We use padding if l < h.,3.2 Label Embedding Layer,[0],[0]
We apply a task-specific mask to L in order to obtain a task-specific probability distribution pTi .,3.2 Label Embedding Layer,[0],[0]
"The LEL is shared across all tasks, which allows us to learn the relationships between the labels in the joint embedding space.",3.2 Label Embedding Layer,[0],[0]
We show MTL with the LEL in Figure 1b.,3.2 Label Embedding Layer,[0],[0]
The LEL allows us to learn the relationships between labels.,3.3 Label Transfer Network,[0],[0]
"In order to make use of these relationships, we would like to leverage the predictions of our auxiliary tasks to estimate a label for the target task.",3.3 Label Transfer Network,[0],[0]
"To this end, we introduce the Label Transfer Network (LTN).",3.3 Label Transfer Network,[0],[0]
This network takes the auxiliary task outputs as input.,3.3 Label Transfer Network,[0],[0]
"In particular, we define the output label embedding oi of task Ti as
the sum of the task’s label embeddings lj weighted with their probability",3.3 Label Transfer Network,[0],[0]
"pTij :
oi =
Li∑
j=1
pTij lj (5)
",3.3 Label Transfer Network,[0],[0]
"The label embeddings l encode general relationship between labels, while the model’s probability distribution pTi over its predictions encodes finegrained information useful for learning (Hinton et al., 2015).",3.3 Label Transfer Network,[0],[0]
The LTN is trained on labelled target task data.,3.3 Label Transfer Network,[0],[0]
"For each example, the corresponding label output embeddings of the auxiliary tasks are fed into a multi-layer perceptron (MLP), which is trained with a negative log-likelihood objective LLTN to produce a pseudo-label zTT for the target task TT :
LTNT = MLP([o1, . . .",3.3 Label Transfer Network,[0],[0]
",oT−1]) (6)
where [·, ·] designates concatenation.",3.3 Label Transfer Network,[0],[0]
The mapping of the tasks in the LTN yields another signal that can be useful for optimisation and act as a regulariser.,3.3 Label Transfer Network,[0],[0]
"The LTN can also be seen as a mixtureof-experts layer (Jacobs et al., 1991) where the experts are the auxiliary task models.",3.3 Label Transfer Network,[0],[0]
"As the label embeddings are learned jointly with the main model, the LTN is more sensitive to the relationships between labels than a separately learned mixture-of-experts model that only relies on the experts’ output distributions.",3.3 Label Transfer Network,[0],[0]
"As such, the LTN
can be directly used to produce predictions on unseen data.",3.3 Label Transfer Network,[0],[0]
"The downside of the LTN is that it requires additional parameters and relies on the predictions of the auxiliary models, which impacts the runtime during testing.",3.4 Semi-supervised MTL,[0],[0]
"Instead, of using the LTN for prediction directly, we can use it to provide pseudolabels for unlabelled or auxiliary task data by utilising auxiliary predictions for semi-supervised learning.
",3.4 Semi-supervised MTL,[0],[0]
"We train the target task model on the pseudolabelled data to minimise the squared error between the model predictions pTi and the pseudo labels zTi produced by the LTN:
Lpseudo =MSE(pTT , zTT ) = ||pTT",3.4 Semi-supervised MTL,[0],[0]
"− zTT ||2 (7)
We add this loss term to the MTL loss in Equation 2.",3.4 Semi-supervised MTL,[0],[0]
"As the LTN is learned together with the MTL model, pseudo-labels produced early during training will likely not be helpful as they are based on unreliable auxiliary predictions.",3.4 Semi-supervised MTL,[0],[0]
"For this reason, we first train the base MTL model until convergence and then augment it with the LTN.",3.4 Semi-supervised MTL,[0],[0]
We show the full semi-supervised learning procedure in Figure 1c.,3.4 Semi-supervised MTL,[0],[0]
"When there is a domain shift between the datasets of different tasks as is common for instance when learning NER models with different label sets, the output label embeddings might not contain sufficient information to bridge the domain gap.
",3.5 Data-specific features,[0],[0]
"To mitigate this discrepancy, we augment the LTN’s input with features that have been found useful for transfer learning (Ruder and Plank, 2017).",3.5 Data-specific features,[0],[0]
"In particular, we use the number of word types, type-token ratio, entropy, Simpson’s index, and Rényi entropy as diversity features.",3.5 Data-specific features,[0],[0]
We calculate each feature for each example.1,3.5 Data-specific features,[0],[0]
The features are then concatenated with the input of the LTN.,3.5 Data-specific features,[0],[0]
Hard parameter sharing can be overly restrictive and provide a regularisation that is too heavy when jointly learning many tasks.,3.6 Other multi-task improvements,[0],[0]
"For this reason, we propose several additional improvements that seek
1For more information regarding the feature calculation, refer to Ruder and Plank (2017).
to alleviate this burden: We use skip-connections, which have been shown to be useful for multitask learning in recent work (Ruder et al., 2017).",3.6 Other multi-task improvements,[0],[0]
"Furthermore, we add a task-specific layer before the output layer, which is useful for learning taskspecific transformations of the shared representations (Søgaard and Goldberg, 2016; Ruder et al., 2017).",3.6 Other multi-task improvements,[0],[0]
"For our experiments, we evaluate on a wide range of text classification tasks.",4 Experiments,[0],[0]
"In particular, we choose pairwise classification tasks—i.e. those that condition the reading of one sequence on another sequence—as we are interested in understanding if knowledge can be transferred even for these more complex interactions.",4 Experiments,[0],[0]
"To the best of our knowledge, this is the first work on transfer learning between such pairwise sequence classification tasks.",4 Experiments,[0],[0]
"We implement all our models in Tensorflow (Abadi et al., 2016) and release the code at https://github.com/ coastalcph/mtl-disparate.",4 Experiments,[0],[0]
"We use the following tasks and datasets for our experiments, show task statistics in Table 1, and summarise examples in Table 2:
Topic-based sentiment analysis Topic-based sentiment analysis aims to estimate the sentiment of a tweet known to be about a given topic.",4.1 Tasks and datasets,[0],[0]
"We use the data from SemEval-2016 Task 4 Subtask B and C (Nakov et al., 2016) for predicting on a twopoint scale of positive and negative (Topic-2) and five-point scale ranging from highly negative to highly positive (Topic-5) respectively.",4.1 Tasks and datasets,[0],[0]
"An example from this dataset would be to classify the
tweet “No power at home, sat in the dark listening to AC/DC in the hope it’ll make the electricity come back again” known to be about the topic “AC/DC”, which is labelled as a positive sentiment.",4.1 Tasks and datasets,[0],[0]
"The evaluation metrics for Topic-2 and Topic-5 are macro-averaged recall (ρPN ) and macro-averaged mean absolute error (MAEM ) respectively, which are both averaged across topics.
",4.1 Tasks and datasets,[0],[0]
"Target-dependent sentiment analysis Targetdependent sentiment analysis (Target) seeks to classify the sentiment of a text’s author towards an entity that occurs in the text as positive, negative, or neutral.",4.1 Tasks and datasets,[0],[0]
We use the data from Dong et al. (2014).,4.1 Tasks and datasets,[0],[0]
An example instance is the expression “how do you like settlers of catan for the wii?” which is labelled as neutral towards the target “wii’.’,4.1 Tasks and datasets,[0],[0]
"The evaluation metric is macroaveraged F1 (FM1 ).
",4.1 Tasks and datasets,[0],[0]
"Aspect-based sentiment analysis Aspect-based sentiment analysis is the task of identifying
whether an aspect, i.e. a particular property of an item is associated with a positive, negative, or neutral sentiment (Ruder et al., 2016).",4.1 Tasks and datasets,[0],[0]
"We use the data of SemEval-2016 Task 5 Subtask 1 Slot 3 (Pontiki et al., 2016) for the laptops (ABSA-L) and restaurants (ABSA-R) domains.",4.1 Tasks and datasets,[0],[0]
"An example is the sentence “For the price, you cannot eat this well in Manhattan”, labelled as positive towards both the aspects “restaurant prices” and “food quality”.",4.1 Tasks and datasets,[0],[0]
"The evaluation metric for both domains is accuracy (Acc).
",4.1 Tasks and datasets,[0],[0]
"Stance detection Stance detection (Stance) requires a model, given a text and a target entity, which might not appear in the text, to predict whether the author of the text is in favour or against the target or whether neither inference is likely (Augenstein et al., 2016).",4.1 Tasks and datasets,[0],[0]
"We use the data of SemEval-2016 Task 6 Subtask B (Mohammad et al., 2016).",4.1 Tasks and datasets,[0],[0]
"An example from this dataset would be to predict the stance of the tweet “Be prepared - if we continue the policies of the liberal left, we will be #Greece” towards the topic “Donald Trump”, labelled as “favor”.",4.1 Tasks and datasets,[0],[0]
"The evaluation metric is the macro-averaged F1 score of the “favour” and “against” classes (FFA1 ).
",4.1 Tasks and datasets,[0],[0]
"Fake news detection The goal of fake news detection in the context of the Fake News Challenge2 is to estimate whether the body of a news article agrees, disagrees, discusses, or is unrelated towards a headline.",4.1 Tasks and datasets,[0],[0]
We use the data from the first stage of the Fake News Challenge (FNC-1).,4.1 Tasks and datasets,[0],[0]
"An example for this dataset is the document “Dino Ferrari hooked the whopper wels catfish, (...), which could be the biggest in the world.”",4.1 Tasks and datasets,[0],[0]
with the headline “Fisherman lands 19 STONE catfish which could be the biggest in the world to be hooked” labelled as “agree”.,4.1 Tasks and datasets,[0],[0]
"The evaluation metric is accuracy (Acc)3.
",4.1 Tasks and datasets,[0],[0]
"Natural language inference Natural language inference is the task of predicting whether one sentences entails, contradicts, or is neutral towards another one.",4.1 Tasks and datasets,[0],[0]
"We use the Multi-Genre NLI corpus (MultiNLI) from the RepEval 2017 shared task (Nangia et al., 2017).",4.1 Tasks and datasets,[0],[0]
"An example for an instance would be the sentence pair “Fun for only children”, “Fun for adults and children”, which are in a “contradiction” relationship.",4.1 Tasks and datasets,[0],[0]
"The evaluation metric is accuracy (Acc).
",4.1 Tasks and datasets,[0],[0]
2http://www.fakenewschallenge.org/ 3We use the same metric as Riedel et al. (2017).,4.1 Tasks and datasets,[0],[0]
"Our base model is the Bidirectional Encoding model (Augenstein et al., 2016), a state-of-theart model for stance detection that conditions a bidirectional LSTM (BiLSTM) encoding of a text on the BiLSTM encoding of the target.",4.2 Base model,[0],[0]
"Unlike Augenstein et al. (2016), we do not pre-train word embeddings on a larger set of unlabelled indomain text for each task as we are mainly interested in exploring the benefit of multi-task learning for generalisation.",4.2 Base model,[0],[0]
"We use BiLSTMs with one hidden layer of 100 dimensions, 100-dimensional randomly initialised word embeddings, a label embedding size of 100.",4.3 Training settings,[0],[0]
"We train our models with RMSProp, a learning rate of 0.001, a batch size of 128, and early stopping on the validation set of the main task with a patience of 3.",4.3 Training settings,[0],[0]
"Our main results are shown in Table 3, with a comparison against the state of the art.",5 Results,[0],[0]
"We present the results of our multi-task learning network with label embeddings (MTL + LEL), multi-task learning with label transfer (MTL + LEL + LTN), and the semi-supervised extension of this model.",5 Results,[0],[0]
"On 7/8 tasks, at least one of our architectures is better than single-task learning; and in 4/8, all our architectures are much better than single-task learning.
",5 Results,[0],[0]
"The state-of-the-art systems we compare against are often highly specialised, taskdependent architectures.",5 Results,[0],[0]
"Our architectures, in contrast, have not been optimised to compare
favourably against the state of the art, as our main objective is to develop a novel approach to multi-task learning leveraging synergies between label sets and knowledge of marginal distributions from unlabeled data.",5 Results,[0],[0]
"For example, we do not use pre-trained word embeddings (Augenstein et al., 2016; Palogiannidi et al., 2016; Vo and Zhang, 2015), class weighting to deal with label imbalance (Balikas and Amini, 2016), or domainspecific sentiment lexicons (Brun et al., 2016; Kumar et al., 2016).",5 Results,[0],[0]
"Nevertheless, our approach outperforms the state-of-the-art on two-way topic-based sentiment analysis (Topic-2).
",5 Results,[0],[0]
"The poor performance compared to the stateof-the-art on FNC and MultiNLI is expected; as we alternate among the tasks during training, our model only sees a comparatively small number of examples of both corpora, which are one and two orders of magnitude larger than the other datasets.",5 Results,[0],[0]
"For this reason, we do not achieve good performance on these tasks as main tasks, but they are still useful as auxiliary tasks as seen in Table 4.",5 Results,[0],[0]
"Our results above show that, indeed, modelling the similarity between tasks using label embeddings sometimes leads to much better performance.",6.1 Label Embeddings,[0],[0]
Figure 2 shows why.,6.1 Label Embeddings,[0],[0]
"In Figure 2, we visualise the label embeddings of an MTL+LEL model trained on all tasks, using PCA.",6.1 Label Embeddings,[0],[0]
"As we can see, similar labels are clustered together across tasks, e.g. there are two positive clusters (middle-right and top-right), two negative clusters (middle-left and bottom-left), and two neutral clusters (middle-top
and middle-bottom).",6.1 Label Embeddings,[0],[0]
"Our visualisation also provides us with a picture of what auxilary tasks are beneficial, and to what extent we can expect synergies from multitask learning.",6.1 Label Embeddings,[0],[0]
"For instance, the notion of positive sentiment appears to be very similar across the topic-based and aspect-based tasks, while the conceptions of negative and neutral sentiment differ.",6.1 Label Embeddings,[0],[0]
"In addition, we can see that the model has failed to learn a relationship between MultiNLI labels and those of other tasks, possibly accounting for its poor performance on the inference task.",6.1 Label Embeddings,[0],[0]
"We did not evaluate the correlation between label embeddings and task performance, but Bjerva (2017) recently suggested that mutual information of target and auxiliary task label sets is a good predictor of gains from multi-task learning.",6.1 Label Embeddings,[0],[0]
"For each task, we show the auxiliary tasks that achieved the best performance on the development data in Table 4.",6.2 Auxilary Tasks,[0],[0]
"In contrast to most existing work, we did not restrict ourselves to performing multitask learning with only one auxiliary task (Søgaard and Goldberg, 2016; Bingel and Søgaard, 2017).",6.2 Auxilary Tasks,[0],[0]
Indeed we find that most often a combination of auxiliary tasks achieves the best performance.,6.2 Auxilary Tasks,[0],[0]
Indomain tasks are less used than we assumed; only Target is consistently used by all Twitter main tasks.,6.2 Auxilary Tasks,[0],[0]
"In addition, tasks with a higher number of labels, e.g. Topic-5 are used more often.",6.2 Auxilary Tasks,[0],[0]
"Such tasks provide a more fine-grained reward signal, which may help in learning representations that generalise better.",6.2 Auxilary Tasks,[0],[0]
"Finally, tasks with large amounts
of training data such as FNC-1 and MultiNLI are also used more often.",6.2 Auxilary Tasks,[0],[0]
"Even if not directly related, the larger amount of training data that can be indirectly leveraged via multi-task learning may help the model focus on relevant parts of the representation space (Caruana, 1993).",6.2 Auxilary Tasks,[0],[0]
"These observations shed additional light on when multi-task learning may be useful that go beyond existing studies (Bingel and Søgaard, 2017).",6.2 Auxilary Tasks,[0],[0]
"We now perform a detailed ablation analysis of our model, the results of which are shown in Table 5.",6.3 Ablation analysis,[0],[0]
"We ablate whether to use the LEL (+ LEL), whether to use the LTN (+ LTN), whether to use the LEL output or the main model output for prediction (main model output is indicated by , main model), and whether to use the LTN as a regulariser or for semi-supervised learning (semisupervised learning is indicated by + semi).",6.3 Ablation analysis,[0],[0]
"We further test whether to use diversity features (– diversity feats) and whether to use main model predictions for the LTN (+ main model feats).
",6.3 Ablation analysis,[0],[0]
"Overall, the addition of the Label Embedding Layer improves the performance over regular MTL in almost all cases.",6.3 Ablation analysis,[0],[0]
"To understand the performance of the LTN, we analyse learning curves of the relabelling function vs. the main model.",6.4 Label transfer network,[0],[0]
Examples for all tasks without semi-supervised learning are shown in Figure 3.,6.4 Label transfer network,[0],[0]
One can observe that the relabelling model does not take long to converge as it has fewer parameters than the main model.,6.4 Label transfer network,[0],[0]
"Once the relabelling model is learned alongside the main
model, the main model performance first stagnates, then starts to increase again.",6.4 Label transfer network,[0],[0]
"For some of the tasks, the main model ends up with a higher task score than the relabelling model.",6.4 Label transfer network,[0],[0]
"We hypothesise that the softmax predictions of other, even highly related tasks are less helpful for predicting main labels than the output layer of the main task model.",6.4 Label transfer network,[0],[0]
"At best, learning the relabelling model alongside the main model might act as a regulariser to the main model and thus improve the main model’s performance over a baseline MTL model, as it is the case for TOPIC-5 (see Table 5).
",6.4 Label transfer network,[0],[0]
"To further analyse the performance of the LTN, we look into to what degree predictions of the main model and the relabelling model for individual instances are complementary to one another.",6.4 Label transfer network,[0],[0]
"Or, said differently, we measure the percentage of correct predictions made only by the relabelling
model or made only by the main model, relative to the number of correct predictions overall.",6.4 Label transfer network,[0],[0]
Results of this for each task are shown in Table 6 for the LTN with and without semi-supervised learning.,6.4 Label transfer network,[0],[0]
"One can observe that, even though the relabelling function overall contributes to the score to a lesser degree than the main model, a substantial number of correct predictions are made by the relabelling function that are missed by the main model.",6.4 Label transfer network,[0],[0]
"This is most prominently pronounced for ABSA-R, where the proportion is 14.6.",6.4 Label transfer network,[0],[0]
We have presented a multi-task learning architecture that (i) leverages potential synergies between classifier functions relating shared representations with disparate label spaces and (ii) enables learning from mixtures of labeled and unlabeled data.,7 Conclusion,[0],[0]
We have presented experiments with combinations of eight pairwise sequence classification tasks.,7 Conclusion,[0],[0]
"Our results show that leveraging synergies between label spaces sometimes leads to big improvements, and we have presented a new state of the art for topic-based sentiment analysis.",7 Conclusion,[0],[0]
"Our analysis further showed that (a) the learned label embeddings were indicative of gains from multitask learning, (b) auxiliary tasks were often beneficial across domains, and (c) label embeddings almost always led to better performance.",7 Conclusion,[0],[0]
We also investigated the dynamics of the label transfer network we use for exploiting the synergies between disparate label spaces.,7 Conclusion,[0],[0]
Sebastian Ruder is supported by the Irish Research Council Grant Number EBPPG/2014/30 and Science Foundation Ireland Grant Number SFI/12/RC/2289.,Acknowledgments,[0],[0]
Anders Søgaard is supported by the ERC Starting Grant Number 313695.,Acknowledgments,[0],[0]
Isabelle Augenstein is supported by Eurostars grant Number E10138.,Acknowledgments,[0],[0]
We further gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research.,Acknowledgments,[0],[0]
"We combine multi-task learning and semisupervised learning by inducing a joint embedding space between disparate label spaces and learning transfer functions between label embeddings, enabling us to jointly leverage unlabelled data and auxiliary, annotated datasets.",abstractText,[0],[0]
We evaluate our approach on a variety of sequence classification tasks with disparate label spaces.,abstractText,[0],[0]
We outperform strong single and multi-task baselines and achieve a new stateof-the-art for topic-based sentiment analysis.,abstractText,[0],[0]
Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces,title,[0],[0]
"In the multi-task learning setting (Caruana, 1997)",1. Introduction,[0],[0]
a learner is given a collection of prediction tasks that all need to be solved.,1. Introduction,[0],[0]
The hope is that the overall prediction quality can be improved by processing the tasks jointly and sharing information between them.,1. Introduction,[0],[0]
"Indeed, theoretical as well as experimental studies have shown that information transfer can reduce the amount of annotated examples per task needed to achieve good performance under various assumptions on how the learning tasks are related.
",1. Introduction,[0],[0]
"All existing multi-task learning approaches have in common, however, that they need at least some labeled training data for every task of interest.",1. Introduction,[0],[0]
"In this paper, we study a new and more challenging setting, in which for a subset of the tasks (typically the large majority) only unlabeled data
1IST Austria.",1. Introduction,[0],[0]
"Correspondence to: Anastasia Pentina <apentina@ist.ac.at>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
is available.",1. Introduction,[0],[0]
"In practice, it is highly desirable to be able to handle this situation for problems with a very large number of tasks, such as sentiment analysis for market studies: for different products different attributes",1. Introduction,[0],[0]
matter,1. Introduction,[0],[0]
"and, thus, each product should be have its own predictor and forms its own learning task.",1. Introduction,[0],[0]
"At the same time annotating data for each such task is prohibitive, especially when new products are constantly added to the market.",1. Introduction,[0],[0]
"Another example are prediction problems, for which the fixed cost of obtaining any labels for a task can be high, even when the variable cost per label are reasonable.",1. Introduction,[0],[0]
"This is a well-known issue when using crowd sourcing for data annotation: recruiting and training annotators first imposes a large overhead, and only afterwards many labels can be obtained within a short time and at a low cost.
",1. Introduction,[0],[0]
A distinctive feature of the setting we study is that it requires two types of information transfer: between the labeled tasks and from labeled to unlabeled ones.,1. Introduction,[0],[0]
"While the first type is common in multi-task learning, none of the existing multi-task methods is able to handle the second type.",1. Introduction,[0],[0]
"In contrast, information transfer from labeled to unlabeled tasks is commonly studied in domain adaptation research, where, however, transfer of the first type is typically not considered.",1. Introduction,[0],[0]
"Thus, the setting of multi-task learning with labeled and unlabeled tasks can be seen as a blend of traditional multi-task learning and domain adaptation.
",1. Introduction,[0],[0]
"In this work we focus on a transfer method that learns a predictor for every task of interest by minimizing a taskspecific convex combination of training errors on the labeled tasks (Ben-David et al., 2007; Mansour et al., 2009).",1. Introduction,[0],[0]
We choose this method because it allows us to capture both types of information transfer – between the labeled tasks and from labeled to unlabeled ones – in a unified fashion.,1. Introduction,[0],[0]
"Clearly, the success of this approach depends on the choice of the weights in the convex combinations.",1. Introduction,[0],[0]
"Moreover, one can expect it also to depend on the subset of labeled tasks as well, because some subsets of tasks might be more informative and representative than the others.",1. Introduction,[0],[0]
This suggests that it will be beneficial if the labeled subset is not arbitrary but if it can be chosen in a data-dependent way.,1. Introduction,[0],[0]
"We refer to this learning scenario, where initially every task is represented only by a set of unlabeled examples and the learner can choose for which tasks to request some labels, as active task selection.
",1. Introduction,[0],[0]
Our main result is a generalization bound that quantifies both of the aforementioned effects: it relates the total multitask error to quantities that depend on the subset of labeled tasks and on the task-specific weights used for information transfer.,1. Introduction,[0],[0]
"Using the computable quantities in the bound as an objective function and minimizing it numerically, we obtain a principled algorithm for selecting which tasks to have labeled (in the active task selection scenario) and for choosing task-specific weights and predictors for all tasks, labeled as well as unlabeled.",1. Introduction,[0],[0]
"We highlight the practical usefulness of the derived method by experiments on synthetic and real data.
",1. Introduction,[0],[0]
"The success of any information transfer approach, regardless whether it is applied in the multi-task or the domain adaptation scenario, depends on the relatedness between tasks of interest.",1. Introduction,[0],[0]
"Indeed, one cannot expect to benefit from information transfer between the labeled tasks or to be able to obtain solutions of reasonable quality for the unlabeled ones if the given tasks are completely unrelated.",1. Introduction,[0],[0]
An advantage of the method we propose is that from the associated generalization bound we can read off explicitly under which conditions the algorithm can be expected to succeed.,1. Introduction,[0],[0]
"In particular, it suggests that the proposed method is likely to succeed if the given set of tasks satisfies the following assumption of task smoothness: if two tasks are similar in their marginal distributions, then their optimal prediction functions are also likely to be similar.",1. Introduction,[0],[0]
A more formal definition will be given in Section 3.,1. Introduction,[0],[0]
"The task smoothness assumption resembles the classical smoothness assumption of semi-supervised learning (Chapelle et al., 2006).",1. Introduction,[0],[0]
"It can be expected to hold in many real-world settings with a large number of tasks, for example in the aforementioned case of sentiment analysis: if two products are described using similar words, these words would likely have similar connotation for both products.",1. Introduction,[0],[0]
"Note, also, that a similar assumption appears implicitly in (Blanchard et al., 2011).",1. Introduction,[0],[0]
Most existing multi-task learning methods work in the fully supervised setting and aim at improving the overall prediction quality by sharing information between the tasks.,1.1. Related Work,[0],[0]
"For this they employ different types of transfer: instance-transfer methods re-use training samples from different tasks (Crammer & Mansour, 2012), parametertransfer methods assume that the predictors for all tasks are similar to each other in some norm and exploit this fact through specific regularizers (Evgeniou & Pontil, 2004), representation-transfer approaches assume that the predictors for all tasks share a common (low-dimensional) representation that can be learned from the data (Argyriou et al., 2007; 2008).",1.1. Related Work,[0],[0]
"Follow-up works extended and generalized these concepts, e.g. by learning the relatedness of tasks (Saha et al., 2011; Kang et al., 2011) or sharing only
between subgroups of tasks (Xue et al., 2007; Kumar & Daumé III, 2012; Barzilai & Crammer, 2015).",1.1. Related Work,[0],[0]
"However, all of the above methods require at least some labeled data for each task.
",1.1. Related Work,[0],[0]
"To our knowledge, the only existing multi-task method that can be applied in the considered setting where for some tasks only unlabeled data is available is (Khosla et al., 2012).",1.1. Related Work,[0],[0]
"Motivated by the problem of dataset bias, this method relies on the assumption that different tasks are minor modifications (i.e. biased versions) of the same, true prediction problem.",1.1. Related Work,[0],[0]
"Similarly to (Evgeniou & Pontil, 2004), it uses specific regularizers and trains predictors for all tasks jointly as small perturbations of a common predictor, which corresponds to the hypothetical unbiased task and can potentially be applied to unseen problems.",1.1. Related Work,[0],[0]
"Thus, applied in the considered setting, this method provides one predictor for all unlabeled tasks and treats the labeled ones as slight variations of them.
",1.1. Related Work,[0],[0]
Information transfer from labeled to unlabeled tasks is the question typically studied in domain adaptation research.,1.1. Related Work,[0],[0]
"In fact, if the set of labeled tasks is fixed, any domain adaptation technique might be used to obtain solutions for unlabeled tasks, in particular those based on source reweighting (Shimodaira, 2000), representation learning (Pan et al., 2011; Glorot et al., 2011), or semisupervised transfer (Xing et al., 2007).",1.1. Related Work,[0],[0]
"However, by design all domain adaptation methods aim at finding the best predictor on a single target task given a fixed set of source tasks.",1.1. Related Work,[0],[0]
"Therefore none of them can readily be applied in the active task selection setting, where the learner needs to select the labeled tasks that would lead to good performance across all tasks.
",1.1. Related Work,[0],[0]
"A second related setting is zero-shot learning (Larochelle et al., 2008; Lampert et al., 2013; Palatucci et al., 2009), where contextual, usually semantic, information is used to solve a learning task for which no training data is available.",1.1. Related Work,[0],[0]
"The situation we are interested in is more specific than this, though, as we assume that unlabeled data of the tasks is available, not context in an arbitrary form.",1.1. Related Work,[0],[0]
"As we will show, this allows us to derive formal performance guarantees that zero-shot learning methods typically lack.
",1.1. Related Work,[0],[0]
"The active task selection scenario is directly related to the question of identifying a representative set of source tasks in domain adaptation, a question that has previously been raised in the context of sentiment analysis (Blitzer et al., 2007).",1.1. Related Work,[0],[0]
"It also shares some features with active learning, where the learner is given a set of unlabeled samples and can choose a subset to obtain labels for.",1.1. Related Work,[0],[0]
"A fundamental difference is, however, that in active learning the learner needs to find a single prediction function for all labeled and unlabeled data while in the multi-task setting each task, including unlabeled ones, potentially requires its own predictor.
",1.1. Related Work,[0],[0]
"In the multi-task or zero-shot setting, active learning has so far not found widespread use.",1.1. Related Work,[0],[0]
"Exemplary works in this direction are (Reichart et al., 2008; Saha et al., 2010; Gavves et al., 2015), which, however, use active learning on the level of training examples, not tasks.",1.1. Related Work,[0],[0]
"The idea of choosing tasks was used in active curriculum selection (Ruvolo & Eaton, 2013; Pentina et al., 2015), where the learner can influence the order in which tasks are processed.",1.1. Related Work,[0],[0]
However these methods nevertheless require annotated examples for all tasks of interest.,1.1. Related Work,[0],[0]
In the multi-task setting the learner observes a collection of prediction tasks and its goal is to learn all of them.,2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"Formally, we assume that there is a set of T tasks {〈D1, f1〉, . . .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
", 〈DT , fT 〉}, where each task t is defined by a marginal distributionDt over the input space X and a deterministic labeling function ft : X → Y .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"The goal of the learner is to find T predictors h1, . . .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
", hT in a hypothesis set H ⊂ {h : X → Y} that would minimize the average expected risk:
er(h1, . . .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
", hT )",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"= 1
T T∑ t=1 ert(ht)",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
", (1)
where ert(ht)",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
= E x∼Dt,2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"`(ht(x), ft(x))",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
".
",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"In this work we concentrate on the case of binary classification tasks, Y = {−1, 1}, and 0/1-loss, `(y1, y2)",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
= 0,2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"if y1 = y2, and `(y1, y2) = 1 otherwise.
",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
In the fully-supervised setting the learner is given a training set of annotated examples for every task of interest.,2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"In contrast, we consider the scenario where every task t is represented by a set St = {xt1, . . .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
", xtn} of n unlabeled examples sampled i.i.d.",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
according to the marginal distribution Dt.,2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"For a subset of k tasks {i1, . . .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
", ik}, which are either predefined or, in the active scenario, can be selected based on the unlabeled data, the learner is given labels for a random subset Sij ⊂ Sij of m points.
",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"To obtain a predictor for any task, labeled or unlabeled, we consider a method that minimizes a convex combination of training errors of the labeled tasks.",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"This choice allows us to capture, in a unified fashion, both types of information transfer – between the labeled tasks and from labeled to unlabeled ones.",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"Formally, for a set of tasks I = {i1, . . .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
", ik} ⊂ {1, . . .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
", T} we define:
ΛI = { α ∈",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"[0, 1]T :
T∑ i=1",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
αi,2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"= 1; suppα ⊆ I
} (2)
for suppα = {i ∈ {1, . .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
.,2. MTL with Labeled and Unlabeled Tasks,[0],[0]
", T} : αi 6= 0}.",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"Given a weight vector α ∈ ΛI , the α-weighted empirical error of a hypoth-
esis h ∈ H is defined as follows: êrα(h) = ∑ i∈I αiêri(h), (3)
where êri(h) = 1
m ∑ (x,y)∈Si `(h(x), y).",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"(4)
In order to obtain a solution for any task t the learner minimizes êrαt(h) for some αt ∈ ΛI , where I is the set of labeled tasks, potentially in combination with some regularization.
",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"The success of this approach depends on the subset I of tasks that are labeled and on the weights α1, . . .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
", αT .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"The following theorem quantifies both of these effects and will later be used to chose α1, . . .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
", αT and potentially I in a principled way.",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
Theorem 1.,2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"Let d be the VC dimension of the hypothesis set H, k be the number of labeled tasks, S1, . . .",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
", ST be",2. MTL with Labeled and Unlabeled Tasks,[0],[0]
"i.i.d.∼ Di, and S1, . . .","T sets of size n each, where Si",[0],[0]
", ST be their random subsets of size m each, for which labels would be provided if the corresponding task is selected as labeled.","T sets of size n each, where Si",[0],[0]
Then for any δ > 0,"T sets of size n each, where Si",[0],[0]
"with probability at least 1 − δ over S1, . . .","T sets of size n each, where Si",[0],[0]
", ST and S1, . . .","T sets of size n each, where Si",[0],[0]
", ST uniformly for all choices of labeled tasks I = {i1, . . .","T sets of size n each, where Si",[0],[0]
", ik} and weights α1, . . .","T sets of size n each, where Si",[0],[0]
", αT ∈ ΛI , provided that they are fully determined by the unlabeled data only, and for all possible choices of h1, . . .","T sets of size n each, where Si",[0],[0]
", hT ∈ H the following inequality holds:
1
T T∑ t=1","T sets of size n each, where Si",[0],[0]
ert(ht)≤ 1 T T∑ t=1,"T sets of size n each, where Si",[0],[0]
êrαt(ht)+ 1 T T∑ t=1 ∑ i∈I αti,"T sets of size n each, where Si",[0],[0]
"disc(St, Si)
+ A
T ‖α‖2,1","T sets of size n each, where Si",[0],[0]
"+
B T ‖α‖1,2 +","T sets of size n each, where Si",[0],[0]
"C+D+ 1 T T∑ t=1 ∑ i∈I αtiλti, (5)
where
disc(St, Si) = max h,h′∈H
|êrSt(h, h′)− êrSi(h, h′)|
with êrSi(h, h ′) =","T sets of size n each, where Si",[0],[0]
1n,"T sets of size n each, where Si",[0],[0]
"∑n j=1 `(h(x i j), h
′(xij)) is the empirical discrepancy between unlabeled samples St and Si, and
λij = min h∈H (eri(h) + erj(h))
‖α‖2,1 = T∑ t=1 √∑ i∈I (αti) 2, ‖α‖1,2 = √√√√∑ i∈I ( T∑ t=1 αti )2 ,
A =
√ 2d log(ekm/d)
m , B =
√ log(4/δ)
2m
C =
√ 8(log T + d log(enT/d))
","T sets of size n each, where Si",[0],[0]
n,"T sets of size n each, where Si",[0],[0]
"+
√ 2
n log
4 δ ,
D = 2
√ 2d log(2n)","T sets of size n each, where Si",[0],[0]
"+ 2 log(T ) + log(4/δ)
","T sets of size n each, where Si",[0],[0]
"n .
","T sets of size n each, where Si",[0],[0]
Proof Sketch (the full proof can be found in the supplemental material).,"T sets of size n each, where Si",[0],[0]
"By Theorem 2 in (Ben-David et al., 2010), for any two tasks t","T sets of size n each, where Si",[0],[0]
"and i the following inequality holds for every h ∈ H:
ert(h) ≤","T sets of size n each, where Si",[0],[0]
eri(h),"T sets of size n each, where Si",[0],[0]
"+ disc(Dt, Di) + λti.","T sets of size n each, where Si",[0],[0]
"(6)
Thus, we obtain the following bound on the average expected error over all tasks in terms of the error on the labeled tasks:
1
T T∑ t=1","T sets of size n each, where Si",[0],[0]
ert(ht)≤ 1 T T∑ t=1,"T sets of size n each, where Si",[0],[0]
"erαt(ht) (7)
+ 1
T T∑ t=1 ∑ i∈I αti disc(Dt, Di) + 1 T T∑ t=1 ∑ i∈I αtiλti,
with erαt(ht) = ∑ i∈I αti E x∼Di","T sets of size n each, where Si",[0],[0]
"`(ht(x), fi(x)), and (8)
erDi(h, h ′) =","T sets of size n each, where Si",[0],[0]
"E x∼Di `(h(x), h′(x)), and (9)
disc(Dt, Di)= max h,h′∈H
| erDt(h, h′)−erDi(h, h′)| (10)
is the discrepancy between two distributions (Kifer et al., 2004; Mansour et al., 2009; Ben-David et al., 2010).","T sets of size n each, where Si",[0],[0]
"In order to prove the statement of the theorem we need to relate the α-weighted expected errors and discrepancies between the marginal distributions in (7) to their empirical estimates.
","T sets of size n each, where Si",[0],[0]
The proof consists of three steps.,"T sets of size n each, where Si",[0],[0]
"First, we show that, conditioned on the unlabeled data, 1T ∑T t=1 ẽrαt can be upper
bounded in terms of 1T ∑T t=1 êrαt , where:
ẽrα(h) = ∑ i∈I αiẽri(h) =","T sets of size n each, where Si",[0],[0]
∑,"T sets of size n each, where Si",[0],[0]
"i∈I αi n n∑ j=1 `(h(xij), fi(x i j)).
","T sets of size n each, where Si",[0],[0]
This quantity can be interpreted as a training error if the learner would receive the labels for all the samples for the chosen tasks I .,"T sets of size n each, where Si",[0],[0]
Note that in case of m = n this step is not needed and we can avoid the corresponding complexity terms.,"T sets of size n each, where Si",[0],[0]
In the second step we relate the average α-weighted expected errors to 1T ∑T t=1 ẽrαt .,"T sets of size n each, where Si",[0],[0]
"In the third step we conclude the proof by bounding the pairwise discrepancies in terms of their empirical estimates.
","T sets of size n each, where Si",[0],[0]
Step 1.,"T sets of size n each, where Si",[0],[0]
"Fix the unlabeled sets S1, . . .","T sets of size n each, where Si",[0],[0]
", ST .","T sets of size n each, where Si",[0],[0]
"They fully determine the choice of labeled tasks I and the weights α1, . . .","T sets of size n each, where Si",[0],[0]
", αT .","T sets of size n each, where Si",[0],[0]
"Therefore, conditioned on the unlabeled data, these quantities can be considered constant and the bound has to hold uniformly only with respect to h1, . . .","T sets of size n each, where Si",[0],[0]
", hT .
","T sets of size n each, where Si",[0],[0]
"In order to simplify the notation we assume that I = {1, . . .","T sets of size n each, where Si",[0],[0]
", k} and define:
Φ(S1, . . .","T sets of size n each, where Si",[0],[0]
", Sk) = sup h1,...,hT
1
T T∑ t=1 ẽrαt(ht)−","T sets of size n each, where Si",[0],[0]
"êrαt(ht).
(11)
Note that one could analyze this quantity using standard techniques from Rademacher analysis, if the labeled examples were sampled from the unlabeled sets i.i.d., i.e. with replacement.","T sets of size n each, where Si",[0],[0]
"However, since we assume that for every i Si is a subset of Si, i.e. the labeled examples are sampled randomly without replacement, there are dependencies between the labeled examples.","T sets of size n each, where Si",[0],[0]
"Therefore we utilize techniques from the literature on transductive learning (ElYaniv & Pechyony, 2007) instead.","T sets of size n each, where Si",[0],[0]
"We first apply Doob’s construction to Φ in order to obtain a martingale sequence and then use McDiarmid’s inequality for martingales (McDiarmid, 1989).","T sets of size n each, where Si",[0],[0]
"As a result we obtain that with probability at least 1− δ/4 over sampling labeled examples:
Φ ≤ E S1,...,Sk
Φ + 1
T √√√√ k∑ i=1","T sets of size n each, where Si",[0],[0]
( T∑ t=1 αti )2√ log(4/δ) 2m .,"T sets of size n each, where Si",[0],[0]
"(12)
Now we need to upper bound EΦ.","T sets of size n each, where Si",[0],[0]
"Using results from (Tolstikhin et al., 2014) and (Hoeffding, 1963)","T sets of size n each, where Si",[0],[0]
"we observe that:
E S1,...,Sk Φ(S1, . . .","T sets of size n each, where Si",[0],[0]
", Sk) ≤ E S̃1,...,S̃k Φ(S̃1, . . .","T sets of size n each, where Si",[0],[0]
", S̃k), (13)
where S̃i is a set of m points sampled from Si i.i.d.","T sets of size n each, where Si",[0],[0]
with replacement (in contrast to sampling without replacement corresponding to Si).,"T sets of size n each, where Si",[0],[0]
This means that we can upper bound the expectation of Φ over samples with dependencies by the expectation over independent samples.,"T sets of size n each, where Si",[0],[0]
"By doing so, applying the symmetrization trick, and introducing Rademacher random variables, we obtain that:
E S1,...,Sk Φ ≤ 1 T T∑ t=1 √√√√ k∑ i=1","T sets of size n each, where Si",[0],[0]
(αti) 2 · √ 2d log(ekm/d),"T sets of size n each, where Si",[0],[0]
m .,"T sets of size n each, where Si",[0],[0]
"(14)
A combination of (12) and (14) shows that (conditioned on the unlabeled data) with probability at least 1 − δ/4 over sampling labeled examples uniformly for all choices of h1, . . .","T sets of size n each, where Si",[0],[0]
", hT the following holds:
1
T T∑ t=1 ẽrαt(ht) ≤ 1 T T∑ t=1 êrαt(ht)+1 A T ‖α‖2,1 + B T ‖α‖1,2.
(15) Step 2.","T sets of size n each, where Si",[0],[0]
"Now we relate 1T ∑T t=1 ẽrαt to 1 T ∑T t=1 erαt .
","T sets of size n each, where Si",[0],[0]
"The choice of the tasks to label, I , the corresponding weights, α, and the predictors, h, all depend on the unlabeled data.","T sets of size n each, where Si",[0],[0]
"Therefore, we aim for a bound that is uniform in all three parameters.","T sets of size n each, where Si",[0],[0]
"We define:
Ψ(S1, . . .","T sets of size n each, where Si",[0],[0]
", ST ) =
sup I sup α1,...,αT∈ΛI sup h1,...,hT
1
T T∑ t=1","T sets of size n each, where Si",[0],[0]
T∑ i=1,"T sets of size n each, where Si",[0],[0]
"αti(eri(ht)− ẽri(ht)).
","T sets of size n each, where Si",[0],[0]
"The main instrument that we use here is a refined version of McDiarmid’s inequality, which is due to (Maurer, 2006).","T sets of size n each, where Si",[0],[0]
"It allows us to use the standard Rademacher analysis, while taking into account the internal structure of the weights α1, . . .","T sets of size n each, where Si",[0],[0]
", αT .","T sets of size n each, where Si",[0],[0]
"As a result we obtain that with probability at least 1 − δ/4 simultaneously for all choices of tasks to be labeled, I , weights α1, . . .","T sets of size n each, where Si",[0],[0]
", αT ∈ ΛI and hypotheses h1, . . .","T sets of size n each, where Si",[0],[0]
", hT :
1
T T∑ t=1","T sets of size n each, where Si",[0],[0]
"erαt(ht) ≤ 1 T T∑ t=1 ẽrαt(ht) + C. (16)
","T sets of size n each, where Si",[0],[0]
Step 3.,"T sets of size n each, where Si",[0],[0]
To conclude the proof we bound the pairwise discrepancies in terms of their finite sample estimates.,"T sets of size n each, where Si",[0],[0]
"According to Lemma 1 in (Ben-David et al., 2010) for any pair of tasks i, j and any δ > 0","T sets of size n each, where Si",[0],[0]
"with probability at least 1− δ:
disc(Di, Dj) ≤ disc(Si, Sj)+2 √ 2d log(2n)","T sets of size n each, where Si",[0],[0]
"+ log(2/δ)
","T sets of size n each, where Si",[0],[0]
"n .
","T sets of size n each, where Si",[0],[0]
We apply this result to every pair of tasks and combine the results using the uniform bound argument.,"T sets of size n each, where Si",[0],[0]
This yields the remaining two terms on the right hand side: the weighted average of the sample-based discrepancies and the constant D. By combining the result with (15) and (16) we obtain the statement of the theorem.,"T sets of size n each, where Si",[0],[0]
"The left-hand side of inequality (5) is the average expected error over all T tasks, the quantity of interest that the learner would like to minimize but cannot directly compute.",3. Explanation and Interpretation,[0],[0]
"It is upper-bounded by the sum of two complexity terms and five task-dependent terms: weighted training errors on the labeled tasks, weighted averages of the distances to the labeled tasks in terms of the empirical discrepancies, two mixed norms of the weights α and a weighted average of λ-s. The complexity terms C and D behave as O( √ d log(nT )/n) and converge to zero when the number of unlabeled examples per task, n, tends to infinity.",3. Explanation and Interpretation,[0],[0]
"In contrast, AT ‖α‖2,1 + B T ‖α‖1,2 in the worst case of
‖α‖2,1 = ‖α‖1,2 = T behaves as O( √ d log(km)/m) and converges to zero when the number of labeled examples per labeled task, m, tends to infinity.",3. Explanation and Interpretation,[0],[0]
"In order for these terms to be balanced, i.e. for the uncertainty coming from the estimation of discrepancy to not dominate the uncertainty from the estimation of the α-weighted risks, the number of unlabeled examples per task n should be significantly (for k T ) larger than m. However, this is not a strong limitation under the common assumption that obtaining enough unlabeled examples is significantly cheaper than annotated ones.
",3. Explanation and Interpretation,[0],[0]
"The remaining terms on the right-hand side of (5) depend on the set of labeled tasks I , the tasks-specific weights α-s and hypotheses h-s. Thus, by minimizing them with respect to these quantities one can expect to obtain values for them that are beneficial for solving all tasks of interest based on the given data.",3. Explanation and Interpretation,[0],[0]
"For the theorem to hold, the set of labeled tasks and the weights may not depend on the labels.",3. Explanation and Interpretation,[0],[0]
"The part of the bound that can be estimated based on the unlabeled data only, and therefore to select I (in the active scenario) and α1, . . .",3. Explanation and Interpretation,[0],[0]
", αT is:
1
T T∑ t=1 ∑ i∈I αti",3. Explanation and Interpretation,[0],[0]
"disc(St, Si) +",3. Explanation and Interpretation,[0],[0]
"A T ‖α‖2,1",3. Explanation and Interpretation,[0],[0]
+,3. Explanation and Interpretation,[0],[0]
"B T ‖α‖1,2.",3. Explanation and Interpretation,[0],[0]
"(17)
The first term in (17) is the average weighted distance from every task to the labeled ones, as measured by the discrepancy between the corresponding unlabeled training samples.",3. Explanation and Interpretation,[0],[0]
"This term suggests that for every task t the largest weight, i.e. the highest impact in terms of information transfer, should be put on a labeled task i that has a similar marginal distribution.",3. Explanation and Interpretation,[0],[0]
"Note that the employed ”similarity”, which is captured by the discrepancy, directly depends on the considered hypothesis class and loss function and, thus, is tailored to a particular setting of interest.",3. Explanation and Interpretation,[0],[0]
"At the same time, the mixed-norm terms ‖α‖1,2 and ‖α‖2,1 prevent the learner from putting all weight on the single closest labeled task and can be seen as some form of regularization.",3. Explanation and Interpretation,[0],[0]
"In particular, they encourage information transfer also between the labeled tasks, since minimizing just the first term in (17) for every labeled tasks i ∈",3. Explanation and Interpretation,[0],[0]
"I would result in all weight to be put on task i itself and nothing on other tasks, because by definition disc(Si, Si) = 0.
",3. Explanation and Interpretation,[0],[0]
"The first mixed-norm term, ‖α‖2,1 influences every αt independently and encourages the learner to use data from multiple labeled tasks for adaptation.",3. Explanation and Interpretation,[0],[0]
"Thus, it captures the intuition that sharing from multiple labeled tasks should improve the performance.",3. Explanation and Interpretation,[0],[0]
"In contrast, ‖α‖1,2 connects the weights for all tasks.",3. Explanation and Interpretation,[0],[0]
"This term suggests to label tasks that all would be equally useful, thus preventing spending resources on tasks that would be informative for only a few of the remaining ones.",3. Explanation and Interpretation,[0],[0]
"Also, it prevents the learner from having super-influential labeled tasks that share with too many others.",3. Explanation and Interpretation,[0],[0]
"Such cases would be very unstable in the worst case scenario: mistakes on such tasks would propagate and have a major effect on the overall performance.
",3. Explanation and Interpretation,[0],[0]
The effect of the mixed-norm terms can also be seen through the lens of the convergence rates.,3. Explanation and Interpretation,[0],[0]
"Indeed, as already mentioned above, in the case of every αt having only one non-zero component, ‖α‖2,1 and ‖α‖1,2 are equal to T and thus the convergence rate1 is Õ( √ 1/m).",3. Explanation and Interpretation,[0],[0]
"However, in the opposite extreme, if every αt weights all the labeled tasks equally, i.e. αti = 1/k for all t ∈ {1, . . .",3. Explanation and Interpretation,[0],[0]
", T} and
1Õ(·) is an analog of O(·) that hides logarithmic factors
",3. Explanation and Interpretation,[0],[0]
i ∈,3. Explanation and Interpretation,[0],[0]
"I , then ‖α‖2,1 = ‖α‖1,2 = T√k and the convergence rate improves to Õ( √ 1/km), which is the best one can expect from having a total of km labeled examples.
",3. Explanation and Interpretation,[0],[0]
"The only term on the right-hand side of (5) that depends on the hypotheses h1, . . .",3. Explanation and Interpretation,[0],[0]
", hT and can be used to make a favorable choice is the weighted training error on the labeled tasks.",3. Explanation and Interpretation,[0],[0]
"Thus, the generalization bound of Theorem 1 suggest the following algorithm (Figure 1):
Algorithm 1. 1. estimate pairwise discrepancies between the tasks
based on the unlabeled data 2.",3. Explanation and Interpretation,[0],[0]
"choose the tasks I to be labeled (in the active case)
and the weights α1, . . .",3. Explanation and Interpretation,[0],[0]
", αT by minimizing (17) 3. receive labels for the labeled tasks I 4.",3. Explanation and Interpretation,[0],[0]
"for every task t train a classifier by minimizing (3)
using the obtained weights",3. Explanation and Interpretation,[0],[0]
"αt.
Note, that this procedure is justified by Theorem 1: all choices are done in agreement with the conditions of the theorem and, because the inequality (5) holds uniformly for all eligible choices of labeled tasks, weights and predictors, the guarantees also hold for the resulting solution.
",3. Explanation and Interpretation,[0],[0]
"Algorithm 1 is guaranteed to perform well, if the solution it finds leads to a low value of the right-hand side of (5).",3. Explanation and Interpretation,[0],[0]
"By construction, it minimizes all data-dependent terms in (5), except for one quantity that cannot be estimated from the available data:
1
T T∑ t=1 ∑ i∈I αtiλti.",3. Explanation and Interpretation,[0],[0]
"(18)
While discrepancy captures the similarity between marginal distributions, the λ-terms reflect the similarity between labeling functions: for every pair of task, t, and labeled task, i ∈ I , the corresponding value λti is small if there exists a hypothesis that performs well on both tasks.",3. Explanation and Interpretation,[0],[0]
"Thus, Algorithm 1 can be expected to perform well, if for any two given tasks t and i that are close to each other in terms of discrepancy (and thus in the minimization of (17) the corresponding αti is large), there exists a hypothesis
that performs well on both of them (i.e. the corresponding λti is small).",3. Explanation and Interpretation,[0],[0]
"We refer to this property of the set of learning tasks as task smoothness.
",3. Explanation and Interpretation,[0],[0]
Training predictors for every task of interest using data from all labeled tasks improves the statistical guarantees of the learner.,3. Explanation and Interpretation,[0],[0]
"However, it results in empirical risk minimization on up to km samples for T different weighted combinations.",3. Explanation and Interpretation,[0],[0]
"Since we are most interested in the situation when T is large, one might be interested in way to reduce the amount of necessary computation.",3. Explanation and Interpretation,[0],[0]
"One way to do so is to drop the mixed-norm terms from the objective function (17), in which case it reduces to
1
T T∑ t=1 ∑ i∈I αti",3. Explanation and Interpretation,[0],[0]
"disc(St, Si).",3. Explanation and Interpretation,[0],[0]
"(19)
",3. Explanation and Interpretation,[0],[0]
This expression is linear in α and thus minimizing it for a fixed set I will lead to assigning each task to a single labeled task that is closest to it in terms of empirical discrepancy.,3. Explanation and Interpretation,[0],[0]
Each labeled task will be assigned to itself.,3. Explanation and Interpretation,[0],[0]
"Consequently, the learner must train only k predictors, one for each labeled task, using only its m samples.",3. Explanation and Interpretation,[0],[0]
The expression (19) can be seen as the k-medoids clustering objective with tasks corresponding to points in the space with (semi)metric defined by empirical discrepancy and labeled tasks correspond to the centers of the clusters.,3. Explanation and Interpretation,[0],[0]
"Thus, this method reduces to k-medoids clustering, resembling the suggestion of Blitzer et al. (2007).",3. Explanation and Interpretation,[0],[0]
"Note that, nevertheless, the conditions of Theorem 1 are fulfilled, and thus its guarantees will hold for the obtained solution.",3. Explanation and Interpretation,[0],[0]
"The guarantees will be more pessimistic, however, than those from Algorithm 1, as the minimization ignores parts of the bound (5) and will not use the potentially beneficial transfer between labeled tasks.",3. Explanation and Interpretation,[0],[0]
"To illustrate that the proposed algorithm can also be practically useful, we performed experiments on synthetic and real data.",4. Experiments,[0],[0]
"In both cases we choose H to be the set of all linear predictors with a bias term on X = Rd.
Synthetic data.",4. Experiments,[0],[0]
"We generate T = 1000 binary classifica-
tion tasks in R2.",4. Experiments,[0],[0]
"For each task t its marginal distribution Dt is a unit-variance Gaussian with mean µt chosen uniformly at random from the set [−5, 5]×",4. Experiments,[0],[0]
"[−5, 5].",4. Experiments,[0],[0]
"The label +1 is assigned to all points that have angle between 0 and π with µt (computed counter-clockwise), the other points are labeled −1.",4. Experiments,[0],[0]
"We use n = 1000 unlabeled and m = 100 labeled examples per task.
",4. Experiments,[0],[0]
Real Data.,4. Experiments,[0],[0]
"We curate a Multitask dataset of product reviews2 from the corpus of Amazon product data3 (McAuley et al., 2015a;b).",4. Experiments,[0],[0]
We select the products for which there are at least 300 positive reviews (with scores 4 or 5) and at least 300 negative reviews (with scores 1 or 2).,4. Experiments,[0],[0]
Each of the resulting 957 products we treat as a binary classification task of predicting whether a review is positive or negative.,4. Experiments,[0],[0]
"For every review we extract features by first pre-processing (removing all non-alphabetical characters, transforming the rest into lower case and removing stop words) and then applying the sentence embedding procedure of (Arora et al., 2017) using 25-dimensional GloVe word embedding (Pennington et al., 2014).",4. Experiments,[0],[0]
We use n = 500 unlabeled samples per task and label a subset of m = 400 examples for each of the selected tasks.,4. Experiments,[0],[0]
"The remaining data is used for testing.
",4. Experiments,[0],[0]
Methods.,4. Experiments,[0],[0]
"We evaluate the proposed method in the case when the set of labeled tasks is predefined (referred to as DA) by setting the set I to be a random subset of tasks and minimizing (17) only with respect to α-s and in the active task selection scenario where (17) is minimized
2 http://cvml.ist.ac.at/productreviews/ 3 http://jmcauley.ucsd.edu/data/amazon/
with respect to both I and α-s (referred to as Active DA).",4. Experiments,[0],[0]
"We compare these methods to a multi-task method based on (Khosla et al., 2012), also with random labeled tasks (the same ones as for DA).",4. Experiments,[0],[0]
"Specifically, we solve:
min w,v,b
C ( ‖w‖2+ 1
k ∑ t∈I ‖vt‖2 ) + 1−γ km ∑ t∈I,(x,y)∈St (wTx+b−y)2
+ γ
km ∑ t∈I ∑ (x,y)∈St ((wT + vTt )x+",4. Experiments,[0],[0]
"(b+ bt)− y)2 (20)
for γ ∈ {0, 0.1, . . .",4. Experiments,[0],[0]
", 1} and use (w, b) for making predictions on all unlabeled tasks and (w + vt, b + bt) for each labeled task t ∈ I .",4. Experiments,[0],[0]
"For every number of labeled tasks we report the result for γ that has the best test performance averaged over 10 repeats (denoted by Multi-task), as an upper performance bound on what could be achieved by model selection.
",4. Experiments,[0],[0]
We also evaluate the discussed simplification of the proposed methods that consists of minimizing (19).,4. Experiments,[0],[0]
We refer to these as DA-SS (for random predefined labeled tasks) and as Active DA-SS (in the active task selection scenario).,4. Experiments,[0],[0]
"The SS stands for single source, as in this setting, each task is solved based on information from only one labeled tasks.
",4. Experiments,[0],[0]
To provide further context for the results we also report the results of learning independent ridge regressions with access to labels for all tasks (denoted by Fully Labeled).,4. Experiments,[0],[0]
"However, this baseline has access to many more annotated examples in total than all other methods.",4. Experiments,[0],[0]
"In order to quantify this effect we also consider the setting when the learner
has access to labels for all tasks, but fewer of them: namely, when the number of labeled tasks is k, the number of labels per task is mk/T , i.e. the total amount of labeled examples is mk, the same as for all other methods.",4. Experiments,[0],[0]
In this case we evaluate two methods.,4. Experiments,[0],[0]
"The first one learns ridge regressions for every task independently and thus can be seen as a reference point for the methods that do not involve information transfer between the labeled tasks, i.e. DA-SS and Active DA-SS.",4. Experiments,[0],[0]
"The second reference method is based on (Evgeniou & Pontil, 2004) and consists of minimizing (20) with γ set to 1 and processing all tasks as labeled.",4. Experiments,[0],[0]
"This approach transfers information between all the tasks and therefore we refer to it when evaluating the methods that involve information transfer between the labeled tasks, i.e. DA, Active DA and Multi-task.
",4. Experiments,[0],[0]
Implementation.,4. Experiments,[0],[0]
"We estimate the empirical discrepancies between pairs of tasks by finding a hypothesis in H that minimizes the squared loss for the binary classification problem of separating the two sets of instances, as in (BenDavid et al., 2010).",4. Experiments,[0],[0]
To minimize (17) for a given set of labeled tasks we use gradient descent.,4. Experiments,[0],[0]
"It is also used as a subroutine when minimizing (17) with respect to both I and α-s, for which we employ the GraSP algorithm (Bahmani et al., 2013).",4. Experiments,[0],[0]
"Active DA-SS involves the minimization of the k-medoid risk (19), which we perform using a local search as in (Park & Jun, 2009).",4. Experiments,[0],[0]
"For both methods for the active task selection scenario we used the heuristic from k-means++ (Arthur & Vassilvitskii, 2007) for initialization.",4. Experiments,[0],[0]
To obtain classifiers for the individual tasks in all scenarios we use least-squares ridge regression.,4. Experiments,[0],[0]
"Regularization constants for all methods we selected from the set {0}∪{10−17, 10−16 . . .",4. Experiments,[0],[0]
"108} by 5×5-fold cross validation.
Results.",4. Experiments,[0],[0]
The results are shown in Figure 4.,4. Experiments,[0],[0]
"First, one can see that the proposed domain adaptation-inspired method DA outperforms the multi-task method (20).",4. Experiments,[0],[0]
This could be due to higher flexibility of DA compared to Multi-task as the latter provides only one predictor for all unlabeled tasks.,4. Experiments,[0],[0]
"Indeed, the difference is most apparent in the experiment with synthetic data, where by design there is no single predictor that could perform well on a large fraction of tasks.",4. Experiments,[0],[0]
"Results on the product reviews indicate that DA’s flexibility of learning a specific predictor for every task can be advantageous in more realistic scenarios as well.
",4. Experiments,[0],[0]
"Second, on both datasets both methods for active task selection, i.e. Active DA and Active DA-SS, outperform the corresponding passive methods, i.e. DA and DA-SS, systematically across various fractions of the labeled tasks.",4. Experiments,[0],[0]
"In particular, both active task selection methods require substantially fewer tasks labeled to achieve the same accuracy as their analogs with randomly chosen tasks.",4. Experiments,[0],[0]
"This confirms the intuition that selecting which tasks to label in a datadependent way is beneficial and demonstrates that Theo-
rem 1 is capable of capturing this effect.
",4. Experiments,[0],[0]
"Another interesting observation that can be made from the results in Figure 4 is that both active and passive domain adaptation-inspired methods clearly outperform the corresponding partially labeled baselines, especially for small fractions of labeled tasks.",4. Experiments,[0],[0]
"This indicates that having more labels for fewer tasks rather than only few labels for all tasks could be beneficial not only in terms of annotation costs, but also in terms of prediction accuracy.
",4. Experiments,[0],[0]
"As the number of labeled tasks gets larger, e.g. half of all tasks, the performance of the active task selection learner becomes almost identical to the performance of the Fully Labeled method, even improving over it in the case of multi-source transfer on synthetic data.",4. Experiments,[0],[0]
This confirms the intuition that in the case of many related tasks even a fraction of the tasks can contain enough information for solving all tasks.,4. Experiments,[0],[0]
In this work we introduced and studied a variant of multitask learning in which annotated data is available only for some of the tasks.,5. Conclusion,[0],[0]
"This setting combines aspects of traditional multi-task learning, namely the transfer of information between labeled tasks, with aspects typical for domain adaptation problems, namely transferring information from labeled tasks to solve tasks for which only unlabeled data is available.",5. Conclusion,[0],[0]
The success of the learner in this setting depends on the effectiveness of information transfer and informativeness of the set of labeled tasks.,5. Conclusion,[0],[0]
"We analyzed two scenarios: a passive one, in which the set of labeled tasks is predefined, and the active task selection scenario, in which the learner decides for which tasks to query labels.
",5. Conclusion,[0],[0]
Our main technical contribution is a generalization bound that quantifies the informativeness of the set of labeled tasks and the effectiveness of information transfer.,5. Conclusion,[0],[0]
We demonstrated how the bound can be used to make the choice of labeled tasks (in the active scenario) and to transfer information between the tasks in a principled way.,5. Conclusion,[0],[0]
We also showed how the terms in the bound have intuitive interpretations and provide guidance under which assumption of tasks relatedness the induced algorithm is expected to work well.,5. Conclusion,[0],[0]
"Our empirical evaluation demonstrated that the proposed methods work also well in practice.
",5. Conclusion,[0],[0]
For future work we plan to further exploit the idea of active learning in the multi-task setting.,5. Conclusion,[0],[0]
"In particular, we are interested in identifying whether by allowing the learner to make its decision on which tasks to label in an iterative way, rather than forcing it to choose all the tasks at the same time, one could obtain better learning guarantees as well as more effective learning methods.",5. Conclusion,[0],[0]
We thank Alexander Zimin and Marius Kloft for useful discussions.,Acknowledgments,[0],[0]
This work was in parts funded by the European Research Council under the European Union’s Seventh Framework Programme (FP7/2007-2013)/ERC grant agreement no 308036.,Acknowledgments,[0],[0]
"In multi-task learning, a learner is given a collection of prediction tasks and needs to solve all of them.",abstractText,[0],[0]
"In contrast to previous work, which required that annotated training data is available for all tasks, we consider a new setting, in which for some tasks, potentially most of them, only unlabeled training data is provided.",abstractText,[0],[0]
"Consequently, to solve all tasks, information must be transferred between tasks with labels and tasks without labels.",abstractText,[0],[0]
"Focusing on an instance-based transfer method we analyze two variants of this setting: when the set of labeled tasks is fixed, and when it can be actively selected by the learner.",abstractText,[0],[0]
We state and prove a generalization bound that covers both scenarios and derive from it an algorithm for making the choice of labeled tasks (in the active case) and for transferring information between the tasks in a principled way.,abstractText,[0],[0]
We also illustrate the effectiveness of the algorithm by experiments on synthetic and real data.,abstractText,[0],[0]
Multi-task Learning with Labeled and Unlabeled Tasks,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1273–1283 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1117",text,[0],[0]
"Video captioning is the task of automatically generating a natural language description of the content of a video, as shown in Fig. 1.",1 Introduction,[0],[0]
It has various applications such as assistance to a visually impaired person and improving the quality of online video search or retrieval.,1 Introduction,[0],[0]
"This task has gained recent momentum in the natural language processing and computer vision communities, esp.",1 Introduction,[0],[0]
with the advent of powerful image processing features as well as sequence-to-sequence LSTM models.,1 Introduction,[0],[0]
"It
is also a step forward from static image captioning, because in addition to modeling the spatial visual features, the model also needs to learn the temporal across-frame action dynamics and the logical storyline language dynamics.
",1 Introduction,[0],[0]
"Previous work in video captioning (Venugopalan et al., 2015a; Pan et al., 2016b) has shown that recurrent neural networks (RNNs) are a good choice for modeling the temporal information in the video.",1 Introduction,[0],[0]
A sequence-to-sequence model is then used to ‘translate’ the video to a caption.,1 Introduction,[0],[0]
Venugopalan et al. (2016) showed linguistic improvements over this by fusing the decoder with external language models.,1 Introduction,[0],[0]
"Furthermore, an attention mechanism between the video frames and the caption words captures some of the temporal matching relations better (Yao et al., 2015; Pan et al., 2016a).",1 Introduction,[0],[0]
"More recently, hierarchical two-level RNNs were proposed to allow for longer inputs and to model the full paragraph caption dynamics of long video clips (Pan et al., 2016a; Yu et al., 2016).
",1 Introduction,[0],[0]
"Despite these recent improvements, video captioning models still suffer from the lack of sufficient temporal and logical supervision to be able to correctly capture the action sequence and storydynamic language in videos, esp.",1 Introduction,[0],[0]
in the case of short clips.,1 Introduction,[0],[0]
"Hence, they would benefit from incorporating such complementary directed knowledge, both visual and textual.",1 Introduction,[0],[0]
"We address this by jointly training the task of video captioning with two related directed-generation tasks: a temporally-
1273
directed unsupervised video prediction task and a logically-directed language entailment generation task.",1 Introduction,[0],[0]
"We model this via many-to-many multi-task learning based sequence-to-sequence models (Luong et al., 2016) that allow the sharing of parameters among the encoders and decoders across the three different tasks, with additional shareable attention mechanisms.
",1 Introduction,[0],[0]
"The unsupervised video prediction task, i.e., video-to-video generation (adapted from Srivastava et al. (2015)), shares its encoder with the video captioning task’s encoder, and helps it learn richer video representations that can predict their temporal context and action sequence.",1 Introduction,[0],[0]
"The entailment generation task, i.e., premise-to-entailment generation (based on the image caption domain SNLI corpus (Bowman et al., 2015)), shares its decoder with the video captioning decoder, and helps it learn better video-entailing caption representations, since the caption is essentially an entailment of the video, i.e., it describes subsets of objects and events that are logically implied by or follow from the full video content).",1 Introduction,[0],[0]
"The overall many-tomany multi-task model combines all three tasks.
",1 Introduction,[0],[0]
"Our three novel multi-task models show statistically significant improvements over the state-ofthe-art, and achieve the best-reported results (and rank) on multiple datasets, based on several automatic and human evaluations.",1 Introduction,[0],[0]
"We also demonstrate that video captioning, in turn, gives mutual improvements on the new multi-reference entailment generation task.",1 Introduction,[0],[0]
"Early video captioning work (Guadarrama et al., 2013; Thomason et al., 2014; Huang et al., 2013) used a two-stage pipeline to first extract a subject, verb, and object (S,V,O) triple and then generate a sentence based on it.",2 Related Work,[0],[0]
Venugopalan et al. (2015b) fed mean-pooled static frame-level visual features (from convolution neural networks pre-trained on image recognition) of the video as input to the language decoder.,2 Related Work,[0],[0]
"To harness the important frame sequence temporal ordering, Venugopalan et al. (2015a) proposed a sequence-to-sequence model with video encoder and language decoder RNNs.
",2 Related Work,[0],[0]
"More recently, Venugopalan et al. (2016) explored linguistic improvements to the caption decoder by fusing it with external language models.",2 Related Work,[0],[0]
"Moreover, an attention or alignment mechanism was added between the encoder and the decoder
to learn the temporal relations (matching) between the video frames and the caption words (Yao et al., 2015; Pan et al., 2016a).",2 Related Work,[0],[0]
"In contrast to static visual features, Yao et al. (2015) also considered temporal video features from a 3D-CNN model pretrained on an action recognition task.
",2 Related Work,[0],[0]
"To explore long range temporal relations, Pan et al. (2016a) proposed a two-level hierarchical RNN encoder which limits the length of input information and allows temporal transitions between segments.",2 Related Work,[0],[0]
Yu et al. (2016)’s hierarchical RNN generates sentences at the first level and the second level captures inter-sentence dependencies in a paragraph.,2 Related Work,[0],[0]
Pan et al. (2016b) proposed to simultaneously learn the RNN word probabilities and a visual-semantic joint embedding space that enforces the relationship between the semantics of the entire sentence and the visual content.,2 Related Work,[0],[0]
"Despite these useful recent improvements, video captioning still suffers from limited supervision and generalization capabilities, esp.",2 Related Work,[0],[0]
given the complex action-based temporal and story-based logical dynamics that need to be captured from short video clips.,2 Related Work,[0],[0]
"Our work addresses this issue by bringing in complementary temporal and logical knowledge from video prediction and textual entailment generation tasks (respectively), and training them together via many-to-many multi-task learning.
",2 Related Work,[0],[0]
"Multi-task learning is a useful learning paradigm to improve the supervision and the generalization performance of a task by jointly training it with related tasks (Caruana, 1998; Argyriou et al., 2007; Kumar and Daumé III, 2012).",2 Related Work,[0],[0]
"Recently, Luong et al. (2016) combined multi-task learning with sequence-to-sequence models, sharing parameters across the tasks’ encoders and decoders.",2 Related Work,[0],[0]
They showed improvements on machine translation using parsing and image captioning.,2 Related Work,[0],[0]
"We additionally incorporate an attention mechanism to this many-to-many multi-task learning approach and improve the multimodal, temporal-logical video captioning task by sharing its video encoder with the encoder of a video-to-video prediction task and by sharing its caption decoder with the decoder of a linguistic premise-to-entailment generation task.
",2 Related Work,[0],[0]
Image representation learning has been successful via supervision from very large object-labeled datasets.,2 Related Work,[0],[0]
"However, similar amounts of supervision are lacking for video representation learning.",2 Related Work,[0],[0]
"Srivastava et al. (2015) address this by propos-
ing unsupervised video representation learning via sequence-to-sequence RNN models, where they reconstruct the input video sequence or predict the future sequence.",2 Related Work,[0],[0]
"We model video generation with an attention-enhanced encoder-decoder and harness it to improve video captioning.
",2 Related Work,[0],[0]
"The task of recognizing textual entailment (RTE) is to classify whether the relationship between a premise and hypothesis sentence is that of entailment (i.e., logically follows), contradiction, or independence (neutral), which is helpful for several downstream NLP tasks.",2 Related Work,[0],[0]
"The recent Stanford Natural Language Inference (SNLI) corpus by Bowman et al. (2015) allowed training end-to-end neural networks that outperform earlier feature-based RTE models (Lai and Hockenmaier, 2014; Jimenez et al., 2014).",2 Related Work,[0],[0]
"However, directly generating the entailed hypothesis sentences given a premise sentence would be even more beneficial than retrieving or reranking sentence pairs, because most downstream generation tasks only come with the source sentence and not pairs.",2 Related Work,[0],[0]
"Recently, Kolesnyk et al. (2016) tried a sequenceto-sequence model for this on the original SNLI dataset, which is a single-reference setting and hence restricts automatic evaluation.",2 Related Work,[0],[0]
"We modify the SNLI corpus to a new multi-reference (and a more challenging zero train-test premise overlap) setting, and present a novel multi-task training setup with the related video captioning task (where the caption also entails a video), showing mutual improvements on both the tasks.",2 Related Work,[0],[0]
We first discuss a simple encoder-decoder model as a baseline reference for video captioning.,3 Models,[0],[0]
"Next, we improve this via an attention mechanism.",3 Models,[0],[0]
"Finally, we present similar models for the unsupervised video prediction and entailment generation tasks, and then combine them with video captioning via the many-to-many multi-task approach.",3 Models,[0],[0]
"Our baseline model is similar to the standard machine translation encoder-decoder RNN
model (Sutskever et al., 2014) where the final state of the encoder RNN is input as an initial state to the decoder RNN, as shown in Fig. 2.",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"The RNN is based on Long Short Term Memory (LSTM) units, which are good at memorizing long sequences due to forget-style gates (Hochreiter and Schmidhuber, 1997).",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"For video captioning, our input to the encoder is the video frame features1 {f1, f2, ..., fn} of length n, and the caption word sequence {w1, w2, ..., wm} of length m is generated during the decoding phase.",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
The distribution of the output sequence w.r.t.,3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"the input sequence is:
p(w1, ..., wm|f1, ..., fn) = m∏
t=1
p(wt|hdt )",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"(1)
where hdt is the hidden state at the t th time step of the decoder RNN, obtained from hdt−1 and wt−1 via the standard LSTM-RNN equations.",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
The distribution p(wt|hdt ) is given by softmax over all the words in the vocabulary.,3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"Our attention model architecture is similar to Bahdanau et al. (2015), with a bidirectional LSTMRNN as the encoder and a unidirectional LSTMRNN as the decoder, see Fig. 3.",3.2 Attention-based Model,[0],[0]
"At each time step t, the decoder LSTM hidden state hdt is a nonlinear recurrent function of the previous decoder hidden state hdt−1, the previous time-step’s generated word wt−1, and the context vector ct:
hdt = S(h d t−1, wt−1, ct) (2)
",3.2 Attention-based Model,[0],[0]
"1We use several popular image features such as VGGNet, GoogLeNet and Inception-v4.",3.2 Attention-based Model,[0],[0]
"Details in Sec. 4.1.
where ct is a weighted sum of encoder hidden states {hei}:
ct =
n∑
i=1
αt,ih e i (3)
These attention weights {αt,i} act as an alignment mechanism by giving higher weights to certain encoder hidden states which match that decoder time step better, and are computed as:
αt,i = exp(et,i)∑n k=1 exp(et,k)
(4)
where the attention function et,i is defined as:
et,i = w T",3.2 Attention-based Model,[0],[0]
tanh(W,3.2 Attention-based Model,[0],[0]
eah e,3.2 Attention-based Model,[0],[0]
"i +W d ah d t−1 + ba) (5)
where w, W ea , W d a , and ba are learned parameters.",3.2 Attention-based Model,[0],[0]
This attention-based sequence-to-sequence model (Fig. 3) is our enhanced baseline for video captioning.,3.2 Attention-based Model,[0],[0]
We next discuss similar models for the new tasks of unsupervised video prediction and entailment generation and then finally share them via multi-task learning.,3.2 Attention-based Model,[0],[0]
We model unsupervised video representation by predicting the sequence of future video frames given the current frame sequence.,3.3 Unsupervised Video Prediction,[0],[0]
"Similar to Sec. 3.2, a bidirectional LSTM-RNN encoder and an LSTM-RNN decoder is used, along with attention.",3.3 Unsupervised Video Prediction,[0],[0]
"If the frame level features of a video of length n are {f1, f2, ..., fn}, these are divided into two sets such that given the current frames {f1, f2, .., fk} (in its encoder), the model has to predict (decode) the rest of the frames {fk+1, fk+2, .., fn}.",3.3 Unsupervised Video Prediction,[0],[0]
"The motivation is that this
helps the video encoder learn rich temporal representations that are aware of their action-based context and are also robust to missing frames and varying frame lengths or motion speeds.",3.3 Unsupervised Video Prediction,[0],[0]
"The optimization function is defined as:
minimize φ
n−k∑
t=1
||fdt − ft+k||22 (6)
where φ are the model parameters, ft+k is the true future frame feature at decoder time step t and fdt is the decoder’s predicted future frame feature at decoder time step t, defined as:
fdt = S(h d t−1, f d t−1, ct) (7)
similar to Eqn. 2, with hdt−1 and f d t−1 as the previous time step’s hidden state and predicted frame feature respectively, and ct as the attentionweighted context vector.",3.3 Unsupervised Video Prediction,[0],[0]
"Given a sentence (premise), the task of entailment generation is to generate a sentence (hypothesis) which is a logical deduction or implication of the premise.",3.4 Entailment Generation,[0],[0]
Our entailment generation model again uses a bidirectional LSTM-RNN encoder and LSTM-RNN decoder with an attention mechanism (similar to Sec. 3.2).,3.4 Entailment Generation,[0],[0]
"If the premise sp is a sequence of words {wp1, wp2, ..., wpn} and the hypothesis sh is {wh1 , wh2 , ..., whm}, the distribution of the entailed hypothesis w.r.t.",3.4 Entailment Generation,[0],[0]
"the premise is:
p(wh1 , ..., w h m|wp1, ..., wpn) =
m∏
t=1
p(wht |hdt ) (8)
where the distribution p(wht |hdt ) is again obtained via softmax over all the words in the vocabulary and the decoder state hdt is similar to Eqn. 2.",3.4 Entailment Generation,[0],[0]
Multi-task learning helps in sharing information between different tasks and across domains.,3.5 Multi-Task Learning,[0],[0]
"Our primary aim is to improve the video captioning model, where visual content translates to a textual form in a directed (entailed) generation way.",3.5 Multi-Task Learning,[0],[0]
"Hence, this presents an interesting opportunity to share temporally and logically directed knowledge with both visual and linguistic generation tasks.",3.5 Multi-Task Learning,[0],[0]
"Fig. 4 shows our overall many-to-many multi-task model for jointly learning video captioning, unsupervised video prediction, and textual entailment generation.",3.5 Multi-Task Learning,[0],[0]
"Here, the video captioning task shares its video encoder (parameters) with the encoder of the video prediction task (one-to-many setting) so as to learn context-aware and temporally-directed visual representations (see Sec. 3.3).
",3.5 Multi-Task Learning,[0],[0]
"Moreover, the decoder of the video captioning task is shared with the decoder of the textual entailment generation task (many-to-one setting), thus helping generate captions that can ‘entail’, i.e., are logically implied by or follow from the video content (see Sec. 3.4).2",3.5 Multi-Task Learning,[0],[0]
"In both the one-tomany and the many-to-one settings, we also allow the attention parameters to be shared or separated.",3.5 Multi-Task Learning,[0],[0]
"The overall many-to-many setting thus improves both the visual and language representations of the video captioning model.
",3.5 Multi-Task Learning,[0],[0]
We train the multi-task model by alternately optimizing each task in mini-batches based on a mixing ratio.,3.5 Multi-Task Learning,[0],[0]
"Let αv, αf , and αe be the number of mini-batches optimized alternately from each of these three tasks – video captioning, unsupervised video future frames prediction, and entailment generation, resp.",3.5 Multi-Task Learning,[0],[0]
Then the mixing ratio is defined as αv(αv+αf+αe) :,3.5 Multi-Task Learning,[0],[0]
αf (αv+αf+αe) : αe(αv+αf+αe) .,3.5 Multi-Task Learning,[0],[0]
Video Captioning Datasets We report results on three popular video captioning datasets.,4.1 Datasets,[0],[0]
"First, we use the YouTube2Text or MSVD (Chen and Dolan, 2011) for our primary results, which con-
2Empirically, logical entailment helped captioning more than simple fusion with language modeling (i.e., partial sentence completion with no logical implication), because a caption also entails a video in a logically-directed sense and hence the entailment generation task matches the video captioning task better than language modeling.",4.1 Datasets,[0],[0]
"Moreover, a multi-task setup is more suitable to add directed information such as entailment (as opposed to pretraining or fusion with only the decoder).",4.1 Datasets,[0],[0]
"Details in Sec. 5.1.
tains 1970 YouTube videos in the wild with several different reference captions per video (40 on average).",4.1 Datasets,[0],[0]
"We also use MSR-VTT (Xu et al., 2016) with 10, 000 diverse video clips (from a video search engine) – it has 200, 000 video clipsentence pairs and around 20 captions per video; and M-VAD (Torabi et al., 2015) with 49, 000 movie-based video clips but only 1 or 2 captions per video, making most evaluation metrics (except paraphrase-based METEOR) infeasible.",4.1 Datasets,[0],[0]
We use the standard splits for all three datasets.,4.1 Datasets,[0],[0]
"Further details about all these datasets are provided in the supplementary.
",4.1 Datasets,[0],[0]
"Video Prediction Dataset For our unsupervised video representation learning task, we use the UCF-101 action videos dataset (Soomro et al., 2012), which contains 13, 320 video clips of 101 action categories, and suits our video captioning task well because it also contains short video clips of a single action or few actions.",4.1 Datasets,[0],[0]
"We use the standard splits – further details in supplementary.
",4.1 Datasets,[0],[0]
"Entailment Generation Dataset For the entailment generation encoder-decoder model, we use the Stanford Natural Language Inference (SNLI) corpus (Bowman et al., 2015), which contains human-annotated English sentence pairs with classification labels of entailment, contradiction and neutral.",4.1 Datasets,[0],[0]
"It has a total of 570, 152 sentence pairs out of which 190, 113 correspond to true entailment pairs, and we use this subset in our multi-task video captioning model.",4.1 Datasets,[0],[0]
"For improving video captioning, we use the same training/validation/test splits as provided by Bowman et al. (2015), which is 183, 416 training, 3, 329 validation, and 3, 368 testing pairs (for the entailment subset).
",4.1 Datasets,[0],[0]
"However, for the entailment generation multitask results (see results in Sec. 5.3), we modify the splits so as to create a multi-reference setup which can afford evaluation with automatic metrics.",4.1 Datasets,[0],[0]
A given premise usually has multiple entailed hypotheses but the original SNLI corpus is set up as single-reference (for classification).,4.1 Datasets,[0],[0]
"Due to this, the different entailed hypotheses of the same premise land up in different splits of the dataset (e.g., one in train and one in test/validation) in many cases.",4.1 Datasets,[0],[0]
"Therefore, we regroup the premiseentailment pairs and modify the split as follows: among the 190, 113 premise-entailment pairs subset of the SNLI corpus, there are 155, 898 unique premises; out of which 145, 822 have only one hy-
pothesis and we make this the training set, and the rest of them (10, 076) have more than one hypothesis, which we randomly shuffle and divide equally into test and validation sets, so that each of these two sets has approximately the same distribution of the number of reference hypotheses per premise.
",4.1 Datasets,[0],[0]
"These new validation and test sets hence contain premises with multiple entailed hypotheses as ground truth references, thus allowing for automatic metric evaluation, where differing generations still get positive scores by matching one of the multiple references.",4.1 Datasets,[0],[0]
"Also, this creates a more challenging dataset for entailment generation because of zero premise overlap between the training and val/test sets.",4.1 Datasets,[0],[0]
"We will make these split details publicly available.
",4.1 Datasets,[0],[0]
"Pre-trained Visual Frame Features For the three video captioning and UCF-101 datasets, we fix our sampling rate to 3fps to bring uniformity in the temporal representation of actions across all videos.",4.1 Datasets,[0],[0]
"These sampled frames are then converted into features using several stateof-the-art pre-trained models on ImageNet (Deng et al., 2009) – VGGNet (Simonyan and Zisserman, 2015), GoogLeNet (Szegedy et al., 2015; Ioffe and Szegedy, 2015), and Inception-v4 (Szegedy et al., 2016).",4.1 Datasets,[0],[0]
Details of these feature dimensions and layer positions are in the supplementary.,4.1 Datasets,[0],[0]
"For our video captioning as well as entailment generation results, we use four diverse automatic evaluation metrics that are popular for image/video captioning and language generation in general: METEOR (Denkowski and Lavie, 2014), BLEU-4 (Papineni et al., 2002), CIDEr-D (Vedantam et al., 2015), and ROUGE-L (Lin, 2004).",4.2 Evaluation (Automatic and Human),[0],[0]
"Particularly, METEOR and CIDEr-D have been justified to be better for generation tasks, because CIDEr-D uses consensus among the (large) number of references and METEOR uses soft matching based on stemming, paraphrasing, and WordNet synonyms.",4.2 Evaluation (Automatic and Human),[0],[0]
"We use the standard evaluation code from the Microsoft COCO server (Chen et al., 2015) to obtain these results and also to compare the results with previous papers.3
We also present human evaluation results based
3We use avg.",4.2 Evaluation (Automatic and Human),[0],[0]
"of these four metrics on validation set to choose the best model, except for single-reference M-VAD dataset where we only report and choose based on METEOR.
",4.2 Evaluation (Automatic and Human),[0],[0]
"on relevance (i.e., how related is the generated caption w.r.t.",4.2 Evaluation (Automatic and Human),[0],[0]
"the video contents such as actions, objects, and events; or is the generated hypothesis entailed or implied by the premise) and coherence (i.e., a score on the logic, readability, and fluency of the generated sentence).",4.2 Evaluation (Automatic and Human),[0],[0]
"We tune all hyperparameters on the dev splits: LSTM-RNN hidden state size, learning rate, weight initializations, and mini-batch mixing ratios (tuning ranges in supplementary).",4.3 Training Details,[0],[0]
We use the following settings in all of our models (unless otherwise specified): we unroll video encoder/decoder RNNs to 50 time steps and language encoder/decoder RNNs to 30 time steps.,4.3 Training Details,[0],[0]
We use a 1024-dimension RNN hidden state size and 512-dim vectors to embed visual features and word vectors.,4.3 Training Details,[0],[0]
"We use Adam optimizer (Kingma and Ba, 2015).",4.3 Training Details,[0],[0]
We apply a dropout of 0.5.,4.3 Training Details,[0],[0]
See subsections below and supp for full details.,4.3 Training Details,[0],[0]
"Table 1 presents our primary results on the YouTube2Text (MSVD) dataset, reporting several previous works, all our baselines and attention model ablations, and our three multi-task models, using the four automated evaluation metrics.",5.1 Video Captioning on YouTube2Text,[0],[0]
"For each subsection below, we have reported the important training details inline, and refer to the supplementary for full details (e.g., learning rates and initialization).
",5.1 Video Captioning on YouTube2Text,[0],[0]
Baseline Performance We first present all our baseline model choices (ablations) in Table 1.,5.1 Video Captioning on YouTube2Text,[0],[0]
Our baselines represent the standard sequence-tosequence model with three different visual feature types as well as those with attention mechanisms.,5.1 Video Captioning on YouTube2Text,[0],[0]
Each baseline model is trained with three random seed initializations and the average is reported (for stable results).,5.1 Video Captioning on YouTube2Text,[0],[0]
"The final baseline model ⊗ instead uses an ensemble (E), which is a standard denoising method (Sutskever et al., 2014) that performs inference over ten randomly initialized models, i.e., at each time step t of the decoder, we generate a word based on the avg.",5.1 Video Captioning on YouTube2Text,[0],[0]
of the likelihood probabilities from the ten models.,5.1 Video Captioning on YouTube2Text,[0],[0]
"Moreover, we use beam search with size 5 for all baseline models.",5.1 Video Captioning on YouTube2Text,[0],[0]
"Overall, the final baseline model with Inceptionv4 features, attention, and 10-ensemble performs
well (and is better than all previous state-of-theart), and so we next add all our novel multi-task models on top of this final baseline.
",5.1 Video Captioning on YouTube2Text,[0],[0]
"Multi-Task with Video Prediction (1-to-M) Here, the video captioning and unsupervised video prediction tasks share their encoder LSTM-RNN weights and image embeddings in a one-to-many multi-task setting.",5.1 Video Captioning on YouTube2Text,[0],[0]
Two important hyperparameters tuned (on the validation set of captioning datasets) are the ratio of encoder vs decoder frames for video prediction on UCF-101 (where we found that 80% of frames as input and 20% for prediction performs best); and the mini-batch mixing ratio between the captioning and video prediction tasks (where we found 100 : 200 works well).,5.1 Video Captioning on YouTube2Text,[0],[0]
Table 1 shows a statistically significant improvement4 in all metrics in comparison to the best baseline (non-multitask) model as well as w.r.t.,5.1 Video Captioning on YouTube2Text,[0],[0]
"all previous works, demonstrating the effectiveness of multi-task learning for video captioning with video prediction, even with unsupervised signals.
",5.1 Video Captioning on YouTube2Text,[0],[0]
"Multi-Task with Entailment Generation (Mto-1) Here, the video captioning and entailment generation tasks share their language decoder LSTM-RNN weights and word embeddings in a many-to-one multi-task setting.",5.1 Video Captioning on YouTube2Text,[0],[0]
"We observe
4Statistical significance of p < 0.01 for CIDEr-D and ROUGE-L, p < 0.02 for BLEU-4, p < 0.03 for METEOR, based on the bootstrap test (Noreen, 1989; Efron and Tibshirani, 1994) with 100K samples.
that a mixing ratio of 100 : 50 alternating minibatches (between the captioning and entailment tasks) works well here.",5.1 Video Captioning on YouTube2Text,[0],[0]
"Again, Table 1 shows statistically significant improvements5 in all the metrics in comparison to the best baseline model (and all previous works) under this multi-task setting.",5.1 Video Captioning on YouTube2Text,[0],[0]
"Note that in our initial experiments, our entailment generation model helped the video captioning task significantly more than the alternative approach of simply improving fluency by adding (or deep-fusing) an external language model (or pre-trained word embeddings) to the decoder (using both in-domain and out-of-domain language models), again because a caption also ‘entails’ a video in a logically-directed sense and hence this matches our captioning task better (also see results of Venugopalan et al. (2016) in Table 1).
",5.1 Video Captioning on YouTube2Text,[0],[0]
"Multi-Task with Video and Entailment Generation (M-to-M) Combining the above one-tomany and many-to-one multi-task learning models, our full model is the 3-task, many-to-many model (Fig. 4) where both the video encoder and the language decoder of the video captioning model are shared (and hence improved) with that of the unsupervised video prediction and entailment generation models, respectively.6",5.1 Video Captioning on YouTube2Text,[0],[0]
"A mixing ratio of 100 : 100 : 50 alternate mini-batches
5Statistical significance of p < 0.01 for all four metrics.",5.1 Video Captioning on YouTube2Text,[0],[0]
"6We found the setting with unshared attention parameters to work best, likely because video captioning and video prediction prefer very different alignment distributions.
of video captioning, unsupervised video prediction, and entailment generation, resp.",5.1 Video Captioning on YouTube2Text,[0],[0]
works well.,5.1 Video Captioning on YouTube2Text,[0],[0]
"Table 1 shows that our many-to-many multi-task model again outperforms our strongest baseline (with statistical significance of p < 0.01 on all metrics), as well as all the previous state-of-theart results by large absolute margins on all metrics.",5.1 Video Captioning on YouTube2Text,[0],[0]
"It also achieves significant improvements on some metrics over the one-to-many and many-toone models.7 Overall, we achieve the best results to date on YouTube2Text (MSVD) on all metrics.",5.1 Video Captioning on YouTube2Text,[0],[0]
"In Table 2, we also train and evaluate our final many-to-many multi-task model on two other video captioning datasets (using their standard splits; details in supplementary).","5.2 Video Captioning on MSR-VTT, M-VAD",[0],[0]
"First, we evaluate on the new MSR-VTT dataset (Xu et al., 2016).","5.2 Video Captioning on MSR-VTT, M-VAD",[0],[0]
"Since this is a recent dataset, we list previous works’ results as reported by the MSR-VTT dataset paper itself.8 We improve over all of these significantly.","5.2 Video Captioning on MSR-VTT, M-VAD",[0],[0]
"Moreover, they maintain a leaderboard9 on this dataset and we also report the top 3 systems from it.","5.2 Video Captioning on MSR-VTT, M-VAD",[0],[0]
"Based on their ranking method, our multi-task model achieves the new rank 1 on this leaderboard.","5.2 Video Captioning on MSR-VTT, M-VAD",[0],[0]
"In Table 3, we further evaluate our model on the challenging movie-based M-VAD dataset, and again achieve improvements over all previous work (Venugopalan et al., 2015a;
7Many-to-many model’s improvements have a statistical significance of p < 0.01 on all metrics w.r.t. baseline, and p < 0.01 on CIDEr-D w.r.t.","5.2 Video Captioning on MSR-VTT, M-VAD",[0],[0]
"both one-to-many and many-toone models, and p < 0.04 on METEOR w.r.t.","5.2 Video Captioning on MSR-VTT, M-VAD",[0],[0]
"one-to-many.
","5.2 Video Captioning on MSR-VTT, M-VAD",[0],[0]
"8In their updated supplementary at https: //www.microsoft.com/en-us/research/wp-content/ uploads/2016/10/cvpr16.supplementary.pdf
9 http://ms-multimedia-challenge.com/leaderboard
Pan et al., 2016a; Yao et al., 2015).10","5.2 Video Captioning on MSR-VTT, M-VAD",[0],[0]
"Above, we showed that the new entailment generation task helps improve video captioning.",5.3 Entailment Generation Results,[0],[0]
"Next, we show that the video captioning task also inversely helps the entailment generation task.",5.3 Entailment Generation Results,[0],[0]
"Given a premise, the task of entailment generation is to generate an entailed hypothesis.",5.3 Entailment Generation Results,[0],[0]
"We use only the entailment pairs subset of the SNLI corpus for this, but with a multi-reference split setup to allow automatic metric evaluation and a zero traintest premise overlap (see Sec. 4.1).",5.3 Entailment Generation Results,[0],[0]
All the hyperparameter details (again tuned on the validation set) are presented in the supplementary.,5.3 Entailment Generation Results,[0],[0]
"Table 4 presents the entailment generation results for the baseline (sequence-to-sequence with attention, 3- ensemble, beam search) and the multi-task model which uses video captioning (shared decoder) on top of the baseline.",5.3 Entailment Generation Results,[0],[0]
A mixing ratio of 100 : 20 alternate mini-batches of entailment generation and video captioning (resp.) works well.11,5.3 Entailment Generation Results,[0],[0]
The multitask model achieves stat.,5.3 Entailment Generation Results,[0],[0]
"significant (p < 0.01) improvements over the baseline on all metrics, thus demonstrating that video captioning and entailment generation both mutually help each other.",5.3 Entailment Generation Results,[0],[0]
"In addition to the automated evaluation metrics, we present pilot-scale human evaluations on the YouTube2Text (Table 1) and entailment generation (Table 4) results.",5.4 Human Evaluation,[0],[0]
"In each case, we compare our strongest baseline with our final multi-task model by taking a random sample of 200 generated captions (or entailed hypotheses) from the test set and removing the model identity to anonymize the two models, and ask the human evaluator to choose the better model based on relevance and coherence (described in Sec. 4.2).",5.4 Human Evaluation,[0],[0]
"As shown in Table 5, the multi-task models are always better than the strongest baseline for both video captioning and entailment generation, on both relevance
10Following previous work, we only use METEOR because M-VAD only has a single reference caption per video.
11Note that this many-to-one model prefers a different mixing ratio and learning rate than the many-to-one model for improving video captioning (Sec. 5.1), because these hyperparameters depend on the primary task being improved, as also discussed in previous work (Luong et al., 2016).
and coherence, and with similar improvements (2- 7%) as the automatic metrics (shown in Table 1).",5.4 Human Evaluation,[0],[0]
"Fig. 5 shows video captioning generation results on the YouTube2Text dataset where our final M-to-M multi-task model is compared with our strongest attention-based baseline model for three categories of videos: (a) complex examples where the multi-task model performs better than the baseline; (b) ambiguous examples (i.e., ground truth itself confusing) where multi-task model still correctly predicts one of the possible categories (c) complex examples where both models perform poorly.",5.5 Analysis,[0],[0]
"Overall, we find that the multi-task model generates captions that are better at both temporal action prediction and logical entailment (i.e., correct subset of full video premise",5.5 Analysis,[0],[0]
) w.r.t.,5.5 Analysis,[0],[0]
the ground truth captions.,5.5 Analysis,[0],[0]
"The supplementary also provides
ablation examples of improvements by the 1-to-M video prediction based multi-task model alone, as well as by the M-to-1 entailment based multi-task model alone (over the baseline).
",5.5 Analysis,[0],[0]
"On analyzing the cases where the baseline is better than the final M-to-M multi-task model, we find that these are often scenarios where the multitask model’s caption is also correct but the baseline caption is a bit more specific, e.g., “a man is holding a gun” vs “a man is shooting a gun”.
",5.5 Analysis,[0],[0]
"Finally, Table 6 presents output examples of our entailment generation multi-task model (Sec. 5.3), showing how the model accurately learns to produce logically implied subsets of the premise.",5.5 Analysis,[0],[0]
"We presented a multimodal, multi-task learning approach to improve video captioning by incorporating temporally and logically directed knowledge via video prediction and entailment generation tasks.",6 Conclusion,[0],[0]
"We achieve the best reported results (and rank) on three datasets, based on multiple automatic and human evaluations.",6 Conclusion,[0],[0]
We also show mutual multi-task improvements on the new entailment generation task.,6 Conclusion,[0],[0]
"In future work, we are applying our entailment-based multi-task paradigm to other directed language generation tasks such as image captioning and document summarization.",6 Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
"This work was partially supported by a Google Faculty Research Award, an IBM Faculty Award, a Bloomberg Data Science Research Grant, and NVidia GPU awards.",Acknowledgments,[0],[0]
"Video captioning, the task of describing the content of a video, has seen some promising improvements in recent years with sequence-to-sequence models, but accurately learning the temporal and logical dynamics involved in the task still remains a challenge, especially given the lack of sufficient annotated data.",abstractText,[0],[0]
"We improve video captioning by sharing knowledge with two related directed-generation tasks: a temporally-directed unsupervised video prediction task to learn richer context-aware video encoder representations, and a logically-directed language entailment generation task to learn better video-entailing caption decoder representations.",abstractText,[0],[0]
"For this, we present a many-to-many multi-task learning model that shares parameters across the encoders and decoders of the three tasks.",abstractText,[0],[0]
We achieve significant improvements and the new state-of-the-art on several standard video captioning datasets using diverse automatic and human evaluations.,abstractText,[0],[0]
We also show mutual multi-task improvements on the entailment generation task.,abstractText,[0],[0]
Multi-Task Video Captioning with Video and Entailment Generation,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2326–2335, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Distributed representations of words have been widely used in many natural language processing (NLP) tasks (Collobert et al., 2011; Turian et al., 2010; Mikolov et al., 2013b; Bengio et al., 2003).",1 Introduction,[0],[0]
"Following this success, it is rising a substantial interest to learn the distributed representations of the continuous words, such as phrases, sentences, paragraphs and documents (Mitchell and Lapata, 2010; Socher et al., 2013; Mikolov et al., 2013b; Le and Mikolov, 2014; Kalchbrenner et al., 2014).",1 Introduction,[0],[0]
The primary role of these models is to represent the variable-length sentence or document as a fixed-length vector.,1 Introduction,[0],[0]
"A good representation of the variable-length text should fully capture the semantics of natural language.
",1 Introduction,[0],[0]
"Recently, the long short-term memory neural network (LSTM) (Hochreiter and Schmidhuber, 1997) has been applied successfully in many NLP tasks, such as spoken language understanding (Yao et al., 2014), sequence labeling (Chen et al.,
∗Corresponding author
2015) and machine translation (Sutskever et al., 2014).",1 Introduction,[0],[0]
"LSTM is an extension of the recurrent neural network (RNN) (Elman, 1990), which can capture the long-term and short-term dependencies and is very suitable to model the variable-length texts.",1 Introduction,[0],[0]
"Besides, LSTM is also sensitive to word order and does not rely on the external syntactic structure as recursive neural network (Socher et al., 2013).",1 Introduction,[0],[0]
"However, when modeling long texts, such as documents, LSTM need to keep the useful features for a quite long period of time.",1 Introduction,[0],[0]
The longterm dependencies need to be transmitted one-byone along the sequence.,1 Introduction,[0],[0]
Some important features could be lost in transmission process.,1 Introduction,[0],[0]
"Besides, the error signal is also back-propagated one-byone through multiple time steps in the training phase with back-propagation through time (BPTT) (Werbos, 1990) algorithm.",1 Introduction,[0],[0]
The learning efficiency could also be decreased for the long texts.,1 Introduction,[0],[0]
"For example, if a valuable feature occurs at the begin of a long document, we need to back-propagate the error through the whole document.
",1 Introduction,[0],[0]
"In this paper, we propose a multi-timescale long short-term memory (MT-LSTM) to capture the valuable information with different timescales.",1 Introduction,[0],[0]
"Inspired by the works of (El Hihi and Bengio, 1995) and (Koutnik et al., 2014), we partition the hidden states of the standard LSTM into several groups.",1 Introduction,[0],[0]
Each group is activated and updated at different time periods.,1 Introduction,[0],[0]
"The fast-speed groups keep the short-term memories, while the slow-speed groups keep the long-term memories.",1 Introduction,[0],[0]
We evaluate our model on four benchmark datasets of text classification.,1 Introduction,[0],[0]
"Experimental results show that our model can not only handle short texts, but can model long texts.
",1 Introduction,[0],[0]
"Our contributions can be summarized as follows.
",1 Introduction,[0],[0]
"• With the multiple different timescale memories, MT-LSTM easily carries the crucial information over a long distance.",1 Introduction,[0],[0]
"MT-LSTM
2326
can well model both short and long texts.
",1 Introduction,[0],[0]
• MT-LSTM has faster convergence speed than the standard LSTM since the error signal can be back-propagated through multiple timescales in the training phase.,1 Introduction,[0],[0]
The primary role of the neural models is to represent the variable-length sentence or document as a fixed-length vector.,2 Neural Models for Sentences and Documents,[0],[0]
"These models generally consist of a projection layer that maps words, subword units or n-grams to vector representations (often trained beforehand with unsupervised methods), and then combine them with the different architectures of neural networks.",2 Neural Models for Sentences and Documents,[0],[0]
"Most of these models for distributed representations of sentences or documents can be classified into four categories.
",2 Neural Models for Sentences and Documents,[0],[0]
"Bag-of-words models A simple and intuitive method is the Neural Bag-of-Words (NBOW) model, in which the representation of sentences or documents can be generated by averaging constituent word representations.",2 Neural Models for Sentences and Documents,[0],[0]
"However, the main drawback of NBOW is that the word order is lost.",2 Neural Models for Sentences and Documents,[0],[0]
"Although NBOW is effective for general document classification, it is not suitable for short sentences.
",2 Neural Models for Sentences and Documents,[0],[0]
"Sequence models Sequence models construct the representation of sentences or documents based on the recurrent neural network (RNN) (Mikolov et al., 2010) or the gated versions of RNN (Sutskever et al., 2014; Chung et al., 2014).",2 Neural Models for Sentences and Documents,[0],[0]
"Sequence models are sensitive to word order, but they have a bias towards the latest input words.",2 Neural Models for Sentences and Documents,[0],[0]
"This gives the RNN excellent performance at language modelling, but it is suboptimal for modeling the whole sentence, especially for the long texts.",2 Neural Models for Sentences and Documents,[0],[0]
"Le and Mikolov (2014) proposed a Paragraph Vector (PV) to learn continuous distributed vector representations for pieces of texts, which can be regarded as a long-term memory of sentences as opposed to the short-memory in RNN.
",2 Neural Models for Sentences and Documents,[0],[0]
"Topological models Topological models compose the sentence representation following a given topological structure over the words (Socher et al., 2011a; Socher et al., 2012; Socher et al., 2013).",2 Neural Models for Sentences and Documents,[0],[0]
"Recursive neural network (RecNN) adopts
a more general structure to encode sentence (Pollack, 1990; Socher et al., 2013).",2 Neural Models for Sentences and Documents,[0],[0]
At every node in the tree the contexts at the left and right children of the node are combined by a classical layer.,2 Neural Models for Sentences and Documents,[0],[0]
The weights of the layer are shared across all nodes in the tree.,2 Neural Models for Sentences and Documents,[0],[0]
The layer computed at the top node gives a representation for the sentence.,2 Neural Models for Sentences and Documents,[0],[0]
"However, RecNN depends on external constituency parse trees provided by an external topological structure, such as parse tree.
",2 Neural Models for Sentences and Documents,[0],[0]
"Convolutional models Convolutional neural network (CNN) is also used to model sentences (Collobert et al., 2011; Kalchbrenner et al., 2014; Hu et al., 2014).",2 Neural Models for Sentences and Documents,[0],[0]
"It takes as input the embeddings of words in the sentence aligned sequentially, and summarizes the meaning of a sentence through layers of convolution and pooling, until reaching a fixed length vectorial representation in the final layer.",2 Neural Models for Sentences and Documents,[0],[0]
CNN can maintain the word order information and learn more abstract characteristics.,2 Neural Models for Sentences and Documents,[0],[0]
"A recurrent neural network (RNN) (Elman, 1990) is able to process a sequence of arbitrary length by recursively applying a transition function to its internal hidden state vector ht of the input sequence.",3 Long Short-Term Memory Networks,[0],[0]
"The activation of the hidden state ht at time-step t is computed as a function f of the current input symbol xt and the previous hidden state ht−1
ht = { 0 t = 0 f(ht−1,xt) otherwise
(1)
",3 Long Short-Term Memory Networks,[0],[0]
"It is common to use the state-to-state transition function f as the composition of an element-wise nonlinearity with an affine transformation of both xt and ht−1.
",3 Long Short-Term Memory Networks,[0],[0]
"Traditionally, a simple strategy for modeling sequence is to map the input sequence to a fixedsized vector using one RNN, and then to feed the vector to a softmax layer for classification or other tasks (Sutskever et al., 2014; Cho et al., 2014).
",3 Long Short-Term Memory Networks,[0],[0]
"Unfortunately, a problem with RNNs with transition functions of this form is that during training, components of the gradient vector can grow or decay exponentially over long sequences (Bengio et al., 1994; Hochreiter et al., 2001; Hochreiter and Schmidhuber, 1997).",3 Long Short-Term Memory Networks,[0],[0]
"This problem with exploding or vanishing gradients makes it difficult for the RNN model to learn long-distance correlations in a sequence.
",3 Long Short-Term Memory Networks,[0],[0]
"Long short-term memory network (LSTM) was proposed by (Hochreiter and Schmidhuber, 1997) to specifically address this issue of learning longterm dependencies.",3 Long Short-Term Memory Networks,[0],[0]
The LSTM maintains a separate memory cell inside it that updates and exposes its content only when deemed necessary.,3 Long Short-Term Memory Networks,[0],[0]
A number of minor modifications to the standard LSTM unit have been made.,3 Long Short-Term Memory Networks,[0],[0]
"While there are numerous LSTM variants, here we describe the implementation used by Graves (2013).
",3 Long Short-Term Memory Networks,[0],[0]
"We define the LSTM units at each time step t to be a collection of vectors in Rd: an input gate it, a forget gate ft, an output gate ot, a memory cell ct and a hidden state ht. d is the number of the LSTM units.",3 Long Short-Term Memory Networks,[0],[0]
"The entries of the gating vectors it, ft and ot are in [0, 1].",3 Long Short-Term Memory Networks,[0],[0]
"The LSTM transition equations are the following:
it = σ(Wixt + Uiht−1 + Vict−1) (2) ft = σ(Wfxt",3 Long Short-Term Memory Networks,[0],[0]
"+ Ufht−1 + Vfct−1), (3) ot = σ(Woxt + Uoht−1 + Voct), (4) c̃t = tanh(Wcxt + Ucht−1), (5) ct",3 Long Short-Term Memory Networks,[0],[0]
= f it ⊙,3 Long Short-Term Memory Networks,[0],[0]
ct−1,3 Long Short-Term Memory Networks,[0],[0]
+,3 Long Short-Term Memory Networks,[0],[0]
"it ⊙ c̃t, (6) ht = ot ⊙ tanh(ct), (7)
where xt is the input at the current time step, σ denotes the logistic sigmoid function and ⊙ denotes elementwise multiplication.",3 Long Short-Term Memory Networks,[0],[0]
"Intuitively, the forget gate controls the amount of which each unit of the memory cell is erased, the input gate controls how much each unit is updated, and the output gate controls the exposure of the internal memory state.
",3 Long Short-Term Memory Networks,[0],[0]
Figure 1 shows the structure of a LSTM unit.,3 Long Short-Term Memory Networks,[0],[0]
"In
particular, these gates and the memory cell allow a LSTM unit to adaptively forget, memorize and expose the memory content.",3 Long Short-Term Memory Networks,[0],[0]
"If the detected feature, i.e., the memory content, is deemed important, the forget gate will be closed and carry the memory content across many time-steps, which is equivalent to capturing a long-term dependency.",3 Long Short-Term Memory Networks,[0],[0]
"On the other hand, the unit may decide to reset the memory content by opening the forget gate.",3 Long Short-Term Memory Networks,[0],[0]
"h1 h2 h3 h4 · · · hT softmax
x1 x2 x3 x4",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
xT,4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"y
(a) Unfolded LSTM
LSTM can capture the long-term and short-term dependencies in a sequence.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
But the long-term dependencies need to be transmitted one-by-one along the sequence.,4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"Some important information could be lost in transmission process for long texts, such as documents.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"Besides, the error signal is back-propagated through multiple time steps when we use the back-propagation through time (BPTT) (Werbos, 1990) algorithm.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
The training efficiency could also be low for the long texts.,4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"For example, if a valuable feature occurs at the begin of a long document, we need to back-propagate the error through the whole document.
",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"Inspired by the works of (El Hihi and Bengio, 1995) and (Koutnik et al., 2014), which use de-
layed connections and units operating at different timescales to improve the simple RNN, we separate the LSTM units into several groups.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"Different groups capture different timescales dependencies.
",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"More formally, the LSTM units are partitioned into g groups {G1, · · · , Gg}.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"Each group Gk, (1 ≤ k ≤ g) is activated at different time periods Tk.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"Accordingly, the gates and weight matrices are also partitioned to maintain the corresponding LSTM groups.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"The MT-LSTM with just one group is the same to the standard LSTM.
",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"At each time step t, only the groups Gk that satisfy (tMOD Tk) = 0 are executed.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"The choice of the set of periods Tk ∈ {T1, · · · , Tg} is arbitrary.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"Here, we use the exponential series of periods: group Gk has the period of Tk = 2k−1.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"The group G1 is the fastest one and can be executed at every time step, which works like the standard LSTM.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"The group Gk is the slowest one.
",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"At time step t, the memory cell vector and hidden state vector of group Gk are calculate in two cases:
(1) When group Gk is activated at time step t, the LSMT units of this group are calculated by the following equations:
ikt = σ(W k i xt + g∑ j=1",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"Uj→ki h j t−1 + g∑ j=1 Vj→ki c j t−1), (8)
fkt = σ(W k fxt + g∑ j=1 Uj→kf h j t−1 + g∑",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
j=1 Vj→kf,4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"c j t−1), (9)
okt = σ(W k oxt + g∑ j=1 Uj→ko h j t−1 + g∑ j=1 Vj→ko",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"c j t), (10)
",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"c̃kt = tanh(W k cxt + g∑ j=1 Uj→kc h j t−1), (11) ckt",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
= f k,4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
t ⊙,4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
ckt−1 + ikt,4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"⊙ c̃kt , (12) hkt = o k",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"t ⊙ tanh(ckt ), (13)
where ikt , f k t and o",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
k,4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"t are the vectors of input gates, forget gates, and output gates of group Gk at time step t respectively; ckt and h k t are the memory cell vector and hidden state vector of group",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"Gk at time step t respectively.
",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"(2) When group Gk is non-activated at time step t, its LSMT units keep unchanged.
",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"ckt = c k t−1, (14) hkt = h k t−1.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"(15)
Figure 3 shows the different between the standard LSTM and MT-LSTM.",4 Multi-Timescale Long Short-Term Memory Neural Network,[0],[0]
"The feedback mechanism of LSTM is implemented by the recurrent connections from time step t − 1 to t. Since the MT-LSTM groups are updated with the different frequencies, we can regard the different group as the human memory.",4.1 Two Feedback Strategies,[0],[0]
"The fast-speed groups are short-term memories, while the slow-speed groups are long-term memories.",4.1 Two Feedback Strategies,[0],[0]
"Therefore, an important consideration is what feedback mechanism is between the shortterm and long-term memories.
",4.1 Two Feedback Strategies,[0],[0]
"For the proposed MT-LSTM, we consider two feedback strategies to define the connectivity patterns among the different groups.
",4.1 Two Feedback Strategies,[0],[0]
"Fast-to-Slow (F2S) Strategy Intuitively, when we accumulate the short-term memory to a certain degree, we store some valuable information from the short-term memory into the long-term memory.",4.1 Two Feedback Strategies,[0],[0]
"Therefore, we firstly define a fast to slow strategy, which updates the slower group using the faster group.",4.1 Two Feedback Strategies,[0],[0]
The connections from group j to group k exist if and only if Tj ≤ Tk.,4.1 Two Feedback Strategies,[0],[0]
"The weight matrices Uj→ki , U j→k f , U j→k o , U j→k c , V j→k i , Vj→kf , V j→k o are set to zero when Tj > Tk.
",4.1 Two Feedback Strategies,[0],[0]
"The F2S updating strategy is shown in Figure 3a.
",4.1 Two Feedback Strategies,[0],[0]
"Slow-to-Fast (S2F) Strategy Following the work of (Koutnik et al., 2014), we also investigate another update scheme from slow-speed group to fast-speed group.",4.1 Two Feedback Strategies,[0],[0]
The motivation is that a long term memory can be “distilled” into a short-term memory.,4.1 Two Feedback Strategies,[0],[0]
The connections from group j to group i exist only if Tj ≥ Ti.,4.1 Two Feedback Strategies,[0],[0]
"The weight matrices Uj→ki , Uj→kf , U j→k o , U j→k c , V j→k i , V j→k f , V j→k o are set to zero when Tj < Tk.",4.1 Two Feedback Strategies,[0],[0]
The S2F update strategy is shown in Figure 3b.,4.1 Two Feedback Strategies,[0],[0]
Another consideration is how many groups need to be used.,4.2 Dynamic Selection of the Number of the MT-LSTM Unit Groups,[0],[0]
An intuitive way is that we need more groups for long texts than short texts.,4.2 Dynamic Selection of the Number of the MT-LSTM Unit Groups,[0],[0]
"The number of the group depends the length of the texts.
",4.2 Dynamic Selection of the Number of the MT-LSTM Unit Groups,[0],[0]
"Here, we use a simple dynamic strategy to choose the maximum number of groups, and then the best g is chosen as a hyperparameter according to different tasks.",4.2 Dynamic Selection of the Number of the MT-LSTM Unit Groups,[0],[0]
"The upper bound of the number of groups is calculated by
g = log2 L− 1, (16) where L is the average length of the corpus.",4.2 Dynamic Selection of the Number of the MT-LSTM Unit Groups,[0],[0]
"Thus, the slowest group is activated at least twice.",4.2 Dynamic Selection of the Number of the MT-LSTM Unit Groups,[0],[0]
"In each of the experiments, the hidden layer at the last moment has a fully connected layer followed by a softmax non-linear layer that predicts the probability distribution over classes given the input sentence.",5 Training,[0],[0]
The network is trained to minimise the cross-entropy of the predicted and true distributions; the objective includes an L2 regularization term over the parameters.,5 Training,[0],[0]
"The network is trained with backpropagation and the gradientbased optimization is performed using the Adagrad update rule (Duchi et al., 2011).
",5 Training,[0],[0]
The back propagation of the error propagation is similar to LSTM as well.,5 Training,[0],[0]
"The only difference is that the error propagates only from groups that were executed at time step t. The error of nonactivated groups gets copied back in time (similarly to copying the activations of nodes not activated at the time step t during the corresponding forward pass), where it is added to the backpropagated error.",5 Training,[0],[0]
"In this section, we investigate the empirical performances of our proposed MT-LSTM model on four benchmark datasets for sentence and document classification and then compare it to other competitor models.",6 Experiments,[0],[0]
We evaluate our model on four different datasets.,6.1 Datasets,[0],[0]
"The first three datasets are sentence-level, and the last dataset is document-level.",6.1 Datasets,[0],[0]
The detailed statistics about the four datasets are listed in Table 1.,6.1 Datasets,[0],[0]
"Each dataset is briefly described as follows.
",6.1 Datasets,[0],[0]
• SST-1,6.1 Datasets,[0],[0]
"The movie reviews with five classes (negative, somewhat negative, neutral, somewhat positive, positive) in the Stanford Sentiment Treebank1 (Socher et al., 2013).",6.1 Datasets,[0],[0]
• SST-2,6.1 Datasets,[0],[0]
The movie reviews with binary classes.,6.1 Datasets,[0],[0]
It is also from the Stanford Sentiment Treebank. •,6.1 Datasets,[0],[0]
QC,6.1 Datasets,[0],[0]
"The TREC questions dataset2 involves six different question types, e.g. whether the question is about a location, about a person or about some numeric information (Li and Roth, 2002).",6.1 Datasets,[0],[0]
• IMDB,6.1 Datasets,[0],[0]
"The IMDB dataset3 consists of 100,000 movie reviews with binary classes (Maas et al., 2011).",6.1 Datasets,[0],[0]
One key aspect of this dataset is that each movie review has several sentences.,6.1 Datasets,[0],[0]
"We compare our model with the following models:
• NB-SVM and MNB.",6.2 Competitor Models,[0],[0]
"Naive Bayes SVM and Multinomial Naive Bayes with uni and bigram features (Wang and Manning, 2012).",6.2 Competitor Models,[0],[0]
•,6.2 Competitor Models,[0],[0]
NBOW The NBOW sums the word vectors and applies a non-linearity followed by a softmax classification layer.,6.2 Competitor Models,[0],[0]
"• RAE Recursive Autoencoders with pretrained word vectors from Wikipedia (Socher et al., 2011b).",6.2 Competitor Models,[0],[0]
"• MV-RNN Matrix-Vector Recursive Neural Network with parse trees (Socher et al., 2012).
",6.2 Competitor Models,[0],[0]
1http://nlp.stanford.edu/sentiment.,6.2 Competitor Models,[0],[0]
"2http://cogcomp.cs.illinois.edu/Data/
QA/QC/. 3http://ai.stanford.edu/˜amaas/data/ sentiment/
• RNTN Recursive Neural Tensor Network with tensor-based feature function and parse trees (Socher et al., 2013).",6.2 Competitor Models,[0],[0]
"• AdaSent Self-adaptive hierarchical sentence model with gated mechanism (Zhao et al., 2015).",6.2 Competitor Models,[0],[0]
• DCNN,6.2 Competitor Models,[0],[0]
"Dynamic Convolutional Neural Network with dynamic k-max pooling (Kalchbrenner et al., 2014).",6.2 Competitor Models,[0],[0]
"• CNN-non-static and CNN-multichannel Convolutional Neural Network (Kim, 2014).",6.2 Competitor Models,[0],[0]
"• PV Logistic regression on top of paragraph vectors (Le and Mikolov, 2014).",6.2 Competitor Models,[0],[0]
"Here, we use the popular open source implementation of PV in Gensim4.",6.2 Competitor Models,[0],[0]
•,6.2 Competitor Models,[0],[0]
LSTM,6.2 Competitor Models,[0],[0]
The standard LSTM for text classification.,6.2 Competitor Models,[0],[0]
We use the implementation of Graves (2013).,6.2 Competitor Models,[0],[0]
The unfolded illustration is shown in Figure 2a.,6.2 Competitor Models,[0],[0]
"In all of our experiments, the word embeddings are trained using word2vec (Mikolov et al., 2013a) on the Wikipedia corpus (1B words).",6.3 Hyperparameters and Training,[0],[0]
"The vocabulary size is about 500,000.",6.3 Hyperparameters and Training,[0],[0]
"The the word embeddings are fine-tuned during training to improve the performance (Collobert et al., 2011).",6.3 Hyperparameters and Training,[0],[0]
"The other parameters are initialized by randomly sampling from uniform distribution in [-0.1, 0.1].",6.3 Hyperparameters and Training,[0],[0]
The hyperparameters which achieve the best performance on the development set will be chosen for the final evaluation.,6.3 Hyperparameters and Training,[0],[0]
"For datasets without development set, we use 10-fold cross-validation (CV) instead.",6.3 Hyperparameters and Training,[0],[0]
The final hyper-parameters for the LSTM and MTLSTM are set as Figure 2.,6.3 Hyperparameters and Training,[0],[0]
"Table 3 shows the classification accuracies of the standard LSTM, MT-LSTM compared with the competitor models.
",6.4 Results,[0],[0]
"Firstly, we compare two feedback strategies of MT-LSTM.",6.4 Results,[0],[0]
"The fast-to-slow feedback strat-
4https://github.com/piskvorky/gensim/
egy (MT-LSTM (F2S)) is better than the slow-tofast strategy (MT-LSTM (S2F)), which indicates that MT-LSTM benefits from periodically storing some valuable information “purified” from the short-term memory into the long-term memory.",6.4 Results,[0],[0]
"In the following discussion, we use fast-to-slow feedback strategy as the default setting of MT-LSTM.
",6.4 Results,[0],[0]
"Compared with the standard LSTM, MT-LSTM results in significantly improvements with the same size of hidden layers.
",6.4 Results,[0],[0]
"MT-LSTM outperforms the competitor models on the SST-1, QC and IMDB datasets, and is close to the two best CNN based models on the SST-2 dataset.",6.4 Results,[0],[0]
But MT-LSTM uses much fewer parameters than the CNN based models.,6.4 Results,[0],[0]
"The number of parameters of LSTM range from 10K to 40K while the number of parameters is about 400K in CNN.
",6.4 Results,[0],[0]
"Moreover, MT-LSTM can not only handle short texts, but can model long texts in classification task.
",6.4 Results,[0],[0]
"Documents Modeling Most of the competitor models cannot deal with the texts of with several sentences (paragraphs, documents).",6.4 Results,[0],[0]
"For instance, MV-RNN and RNTN (Socher et al., 2013) are based on the parsing over each sentence and it is unclear how to combine the representations over many sentences.",6.4 Results,[0],[0]
"The convolutional models, such as CNN (Kim, 2014) and AdaSent (Zhao et al., 2015), need more hidden layers or nodes for long texts and result in a very complicated model.",6.4 Results,[0],[0]
These models therefore are restricted to working on sentences instead of paragraphs or documents.,6.4 Results,[0],[0]
"Denil et al. (2014) used two-level version of DCNN (Kalchbrenner et al., 2014) to model documents.",6.4 Results,[0],[0]
"The first level uses a DCNN to trans-
form embeddings for the words in each sentence into an embedding for the entire sentence.",6.4 Results,[0],[0]
The second level uses another DCNN to transform sentence embeddings from the first level into a single embedding vector that represents the entire document.,6.4 Results,[0],[0]
"However, their result is unsatisfactory and they reported that the IMDB dataset is too small to train a CNN model.
",6.4 Results,[0],[0]
The standard LSTM has an advantage to model documents due to its simplification.,6.4 Results,[0],[0]
"However, it is also difficult to train LSTM since the error signals need to be back-propagated over a long distance
with the BPTT algorithm.",6.4 Results,[0],[0]
Our MT-LSTM can alleviate this problem with multiple timescale memories.,6.4 Results,[0],[0]
The experiment on IMDB dataset demonstrates this advantage.,6.4 Results,[0],[0]
"MTLSTM achieves the accuracy of 92.1% , which are better than the other models.
",6.4 Results,[0],[0]
"Moreover, MT-LSTM converges at a faster rate than the standard LSTM.",6.4 Results,[0],[0]
Figure 4 plots the convergence on the IMDB dataset.,6.4 Results,[0],[0]
"In practice, MTLSTM is approximately three times faster than the standard LSTM since the hidden states of lowspeed group often keep unchanged and need not to be re-calculated at each time step.
",6.4 Results,[0],[0]
"Impact of the Different Number of Memory Groups In our model, the number of memory groups is a hyperparameter.",6.4 Results,[0],[0]
"Here we plotted the accuracy curves of our model with the different numbers of memory groups in Figure 5 to show its impacts on the four datasets.
",6.4 Results,[0],[0]
"When the length of text (SST-1, SST-2 and QC) is small, not all memory groups can be activated if we set too many groups, which may harm the performance.",6.4 Results,[0],[0]
"When dealing with the long texts (IMBD), more groups lead to a better performance.",6.4 Results,[0],[0]
"The performance can be improved with the increase of the number of memory groups.
",6.4 Results,[0],[0]
"According to our dynamic strategy, the maximum numbers of groups is 3, 3, 2, 7 for the four datasets.",6.4 Results,[0],[0]
"The best numbers of groups from experiments are 3, 3, 3, 5 respectively.",6.4 Results,[0],[0]
"Therefor, our dynamic strategy is reasonable.",6.4 Results,[0],[0]
"All the datasets except QC, the best number of groups is equal to or smaller than our calculated upper bound.",6.4 Results,[0],[0]
MTLSMT suffers underfitting when the number of groups is larger than the upper bound.,6.4 Results,[0],[0]
"To get an intuitive understanding of what is happening when we use LSTM or MT-LSTM to predict the class of text, we design an experiment to analyze the output of LSTM and MT-LSTM at each time step.
",6.5 Case Study,[0],[0]
"We sample three sentences from the SST-2 test dataset, and the dynamical changes of the predicted sentiment score over time are shown in Figure 6.",6.5 Case Study,[0],[0]
"It is intriguing to notice that our model can handle the rhetorical question well.
",6.5 Case Study,[0],[0]
The first sentence “Is this progress ?” has a negative sentiment.,6.5 Case Study,[0],[0]
"Although the word “progress” is positive, our model can adjust the sentiment correctly after seeing the question mark “?”, and finally gets a correct prediction.
",6.5 Case Study,[0],[0]
The second sentence “He ’d create a movie better than this .”,6.5 Case Study,[0],[0]
also has a negative sentiment.,6.5 Case Study,[0],[0]
The word “better” is positive.,6.5 Case Study,[0],[0]
"Our model finally gets a correct negative prediction after seeing “than this”, while LSTM gets a wrong prediction.
",6.5 Case Study,[0],[0]
"The third sentence “ It ’s not exactly a gourmet meal but fare is fair , even coming from the drive .” is positive and has more complicated semantic composition.",6.5 Case Study,[0],[0]
"Our model can still capture the useful long-term features and gets the correct prediction, while LSTM does not work well.",6.5 Case Study,[0],[0]
There are many previous works to model the variable-length text as a fixed-length vector.,7 Related Work,[0],[0]
"Specific to text classification task, most of the models cannot deal with the texts of several sentences (paragraphs, documents), such as MV-RNN (Socher et al., 2012), RNTN (Socher et al., 2013), CNN (Kim, 2014), AdaSent (Zhao et al., 2015), and so on.",7 Related Work,[0],[0]
"The simple neural bag-of-words model can deal with long texts, but it loses the word order information.",7 Related Work,[0],[0]
"PV (Le and Mikolov, 2014) works in unsupervised way, and the learned vector cannot be fine-tuned on the specific task.
",7 Related Work,[0],[0]
Our proposed MT-LSTM can handle short texts as well as long texts in classification task.,7 Related Work,[0],[0]
"In this paper, we introduce the MT-LSTM, a generalization of LSTMs to capture the information with different timescales.",8 Conclusion,[0],[0]
MT-LSTM can well model both short and long texts.,8 Conclusion,[0],[0]
With the multiple different timescale memories.,8 Conclusion,[0],[0]
"Intuitively, MTLSTM easily carries the crucial information over a long distance.",8 Conclusion,[0],[0]
"Another advantage of MT-LSTM is that the training speed is faster than the standard LSTM (approximately three times faster in practice).
",8 Conclusion,[0],[0]
"In future work, we would like to investigate the other feedback mechanism between the short-term and long-term memories.",8 Conclusion,[0],[0]
We would like to thank the anonymous reviewers for their valuable comments.,Acknowledgments,[0],[0]
"This work was partially funded by the National Natural Science Foundation of China (61472088, 61473092), National High Technology Research and Development Program of China (2015AA015408), Shanghai Science and Technology Development Funds (14ZR1403200).",Acknowledgments,[0],[0]
Neural network based methods have obtained great progress on a variety of natural language processing tasks.,abstractText,[0],[0]
"However, it is still a challenge task to model long texts, such as sentences and documents.",abstractText,[0],[0]
"In this paper, we propose a multi-timescale long short-term memory (MT-LSTM) neural network to model long texts.",abstractText,[0],[0]
MTLSTM partitions the hidden states of the standard LSTM into several groups.,abstractText,[0],[0]
Each group is activated at different time periods.,abstractText,[0],[0]
"Thus, MT-LSTM can model very long documents as well as short sentences.",abstractText,[0],[0]
Experiments on four benchmark datasets show that our model outperforms the other neural models in text classification task.,abstractText,[0],[0]
Multi-Timescale Long Short-Term Memory Neural Network for Modelling Sentences and Documents,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1118–1127 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1118",text,[0],[0]
Building a chatbot that can naturally and consistently converse with human-beings on opendomain topics draws increasing research interests in past years.,1 Introduction,[0],[0]
"One important task in chatbots is response selection, which aims to select the bestmatched response from a set of candidates given the context of a conversation.",1 Introduction,[0],[0]
"Besides playing a critical role in retrieval-based chatbots (Ji et al., 2014), response selection models have been used in automatic evaluation of dialogue generation
∗Equally contributed.",1 Introduction,[0],[0]
†Work done as a visiting scholar at Baidu.,1 Introduction,[0],[0]
"Wayne Xin Zhao is an associate professor of Renmin University of China and can be reached at batmanfly@ruc.edu.cn.
",1 Introduction,[0],[0]
"(Lowe et al., 2017) and the discriminator of GANbased (Generative Adversarial Networks) neural dialogue generation (Li et al., 2017).
",1 Introduction,[0],[0]
"Early studies on response selection only use the last utterance in context for matching a reply, which is referred to as single-turn response selection (Wang et al., 2013).",1 Introduction,[0],[0]
"Recent works show that the consideration of a multi-turn context can facilitate selecting the next utterance (Zhou et al., 2016; Wu et al., 2017).",1 Introduction,[0],[0]
"The reason why richer contextual information works is that human generated responses are heavily dependent on the previous dialogue segments at different granularities (words, phrases, sentences, etc), both semantically and functionally, over multiple turns rather than one turn (Lee et al., 2006; Traum and Heeman, 1996).",1 Introduction,[0],[0]
Figure 1 illustrates semantic connectivities between segment pairs across context and response.,1 Introduction,[0],[0]
"As demonstrated, generally there are two kinds of matched segment pairs at different granularities across context and response: (1) surface text relevance, for example the lexical overlap of words “packages”-“package” and phrases “debian package manager”-“debian pack-
age manager”.",1 Introduction,[0],[0]
(2) latent dependencies upon which segments are semantically/functionally related to each other.,1 Introduction,[0],[0]
"Such as the word “it” in the response, which refers to “dpkg” in the context, as well as the phrase “its just reassurance” in the response, which latently points to “what packages are installed on my system”, the question that speaker A wants to double-check.
",1 Introduction,[0],[0]
"Previous studies show that capturing those matched segment pairs at different granularities across context and response is the key to multiturn response selection (Wu et al., 2017).",1 Introduction,[0],[0]
"However, existing models only consider the textual relevance, which suffers from matching response that latently depends on previous turns.",1 Introduction,[0],[0]
"Moreover, Recurrent Neural Networks (RNN) are conveniently used for encoding texts, which is too costly to use for capturing multi-grained semantic representations (Lowe et al., 2015; Zhou et al., 2016; Wu et al., 2017).",1 Introduction,[0],[0]
"As an alternative, we propose to match a response with multi-turn context using dependency information based entirely on attention mechanism.",1 Introduction,[0],[0]
"Our solution is inspired by the recently proposed Transformer in machine translation (Vaswani et al., 2017), which addresses the issue of sequence-to-sequence generation only using attention, and we extend the key attention mechanism of Transformer in two ways:
self-attention By making a sentence attend to itself, we can capture its intra word-level dependencies.",1 Introduction,[0],[0]
"Phrases, such as “debian package manager”, can be modeled with wordlevel self-attention over word-embeddings, and sentence-level representations can be constructed in a similar way with phraselevel self-attention.",1 Introduction,[0],[0]
"By hierarchically stacking self-attention from word embeddings, we can gradually construct semantic representations at different granularities.
cross-attention By making context and response attend to each other, we can generally capture dependencies between those latently matched segment pairs, which is able to provide complementary information to textual relevance for matching response with multi-turn context.
",1 Introduction,[0],[0]
"We jointly introduce self-attention and crossattention in one uniform neural matching network, namely the Deep Attention Matching Network
(DAM), for multi-turn response selection.",1 Introduction,[0],[0]
"In practice, DAM takes each single word of an utterance in context or response as the centric-meaning of an abstractive semantic segment, and hierarchically enriches its representation with stacked self-attention, gradually producing more and more sophisticated segment representations surrounding the centric-word.",1 Introduction,[0],[0]
"Each utterance in context and response are matched based on segment pairs at different granularities, considering both textual relevance and dependency information.",1 Introduction,[0],[0]
"In this way, DAM generally captures matching information between the context and the response from word-level to sentence-level, important matching features are then distilled with convolution & maxpooling operations, and finally fused into one single matching score via a single-layer perceptron.
",1 Introduction,[0],[0]
"We test DAM on two large-scale public multiturn response selection datasets, the Ubuntu Corpus v1 and Douban Conversation Corpus.",1 Introduction,[0],[0]
"Experimental results show that our model significantly outperforms the state-of-the-art models, and the improvement to the best baseline model on R10@1 is over 4%.",1 Introduction,[0],[0]
"What is more, DAM is expected to be convenient to deploy in practice because most attention computation can be fully parallelized (Vaswani et al., 2017).",1 Introduction,[0],[0]
Our contributions are two-folds: (1) we propose a new matching model for multi-turn response selection with selfattention and cross-attention.,1 Introduction,[0],[0]
"(2) empirical results show that our proposed model significantly outperforms the state-of-the-art baselines on public datasets, demonstrating the effectiveness of selfattention and cross-attention.",1 Introduction,[0],[0]
"To build an automatic conversational agent is a long cherished goal in Artificial Intelligence (AI) (Turing, 1950).",2.1 Conversational System,[0],[0]
"Previous researches include taskoriented dialogue system, which focuses on completing tasks in vertical domain, and chatbots, which aims to consistently and naturally converse with human-beings on open-domain topics.",2.1 Conversational System,[0],[0]
"Most modern chatbots are data-driven, either in a fashion of information-retrieval (Ji et al., 2014; Banchs and Li, 2012; Nio et al., 2014; Ameixa et al., 2014) or sequence-generation (Ritter et al., 2011).",2.1 Conversational System,[0],[0]
"The retrieval-based systems enjoy the advantage of informative and fluent responses because it searches a large dialogue repository and selects
candidate that best matches the current context.",2.1 Conversational System,[0],[0]
"The generation-based models, on the other hand, learn patterns of responding from dialogues and can directly generalize new responses.",2.1 Conversational System,[0],[0]
Researches on response selection can be generally categorized into single-turn and multi-turn.,2.2 Response Selection,[0],[0]
"Most early studies are single-turn that only consider the last utterance for matching response (Wang et al., 2013, 2015).",2.2 Response Selection,[0],[0]
"Recent works extend it to multiturn conversation scenario, Lowe et al.,(2015) and Zhou et al.,(2016) use RNN to read context and response, use the last hidden states to represent context and response as two semantic vectors, and measure their relevance.",2.2 Response Selection,[0],[0]
"Instead of only considering the last states of RNN, Wu et al.,(2017) take hidden state at each time step as a text segment representation, and measure the distance between context and response via segment-segment matching matrixes.",2.2 Response Selection,[0],[0]
"Nevertheless, matching with dependency information is generally ignored in previous works.",2.2 Response Selection,[0],[0]
"Attention has been proven to be very effective in Natural Language Processing (NLP) (Bahdanau et al., 2015; Yin et al., 2016; Lin et al., 2017) and other research areas (Xu et al., 2015).",2.3 Attention,[0],[0]
"Recently, Vaswani et al.,(2017) propose a novel sequenceto-sequence generation network, the Transformer,
which is entirely based on attention.",2.3 Attention,[0],[0]
"Not only Transformer can achieve better translation results than convenient RNN-based models, but also it is very fast in training/predicting as the computation of attention can be fully parallelized.",2.3 Attention,[0],[0]
"Previous works on attention mechanism show the superior ability of attention to capture semantic dependencies, which inspires us to improve multi-turn response selection with attention mechanism.",2.3 Attention,[0],[0]
"Given a dialogue data set D = {(c, r, y)Z}NZ=1, where c = {u0, ..., un−1} represents a conversation context with {ui}n−1i=0 as utterances and r as a response candidate.",3.1 Problem Formalization,[0],[0]
"y ∈ {0, 1} is a binary label, indicating whether r is a proper response for c. Our goal is to learn a matching model g(c, r) with D, which can measure the relevance between any context c and candidate response r.",3.1 Problem Formalization,[0],[0]
"Figure 2 gives an overview of DAM, which generally follows the representation-matchingaggregation framework to match response with multi-turn context.",3.2 Model Overview,[0],[0]
For each utterance ui =,3.2 Model Overview,[0],[0]
"[wui,k] nui−1 k=0 in a context and its response candidate r =",3.2 Model Overview,[0],[0]
"[wr,t]nr−1t=0 , where nui and nr stand for the numbers of words, DAM first looks up a shared word embedding table and represents ui and r as sequences of word embeddings, namely U0i =
[e0ui,0, ..., e 0 ui,nui−1 ] and R0 =",3.2 Model Overview,[0],[0]
"[e0r,0, ..., e0r,nr−1] respectively, where e ∈ Rd denotes a d-dimension word embedding.
",3.2 Model Overview,[0],[0]
"A representation module then starts to construct semantic representations at different granularities for ui and r. Practically, L identical layers of self-attention are hierarchically stacked, each lth self-attention layer takes the output of the l − 1th layer as its input, and composites the input semantic vectors into more sophisticated representations based on self-attention.",3.2 Model Overview,[0],[0]
"In this way, multigrained representations of ui and r are gradually constructed, denoted as [Uli]Ll=0 and [R
l]Ll=0 respectively.
",3.2 Model Overview,[0],[0]
"Given [U0i , ...,ULi ] and [R0, ...,RL], utterance ui and response r are then matched with each other in a manner of segment-segment similarity matrix.",3.2 Model Overview,[0],[0]
"Practically, for each granularity l ∈",3.2 Model Overview,[0],[0]
"[0...L], two kinds of matching matrixes are constructed, i.e., the self-attention-match Mui,r,lself and cross-attention-match Mui,r,lcross , measuring the relevance between utterance and response with textual information and dependency information respectively.
",3.2 Model Overview,[0],[0]
Those matching scores are finally merged into a 3D matching image Q1.,3.2 Model Overview,[0],[0]
"Each dimension of Q represents each utterance in context, each word in utterance and each word in response respectively.",3.2 Model Overview,[0],[0]
"Important matching information between segment pairs across multi-turn context and candidate response is then extracted via convolution with max-pooling operations, and further fused into one matching score via a single-layer perceptron, representing the matching degree between the response candidate and the whole context.
",3.2 Model Overview,[0],[0]
"Specifically, we use a shared component, the Attentive Module, to implement both selfattention in representation and cross-attention in matching.",3.2 Model Overview,[0],[0]
We will discuss in detail the implementation of Attentive Module and how we used it to implement both self-attention and cross-attention in following sections.,3.2 Model Overview,[0],[0]
"Figure 3 shows the structure of Attentive Module, which is similar to that used in Transformer (Vaswani et al., 2017).",3.3 Attentive Module,[0],[0]
"Attentive Module has three input sentences: the query sentence, the key sentence and the value sentence, namely Q =",3.3 Attentive Module,[0],[0]
"[ei] nQ−1 i=0 ,K =",3.3 Attentive Module,[0],[0]
"[ei] nK−1 i=0 ,V =",3.3 Attentive Module,[0],[0]
"[ei] nV−1 i=0 respec-
1We refer to it as Q because it is like a cube.
",3.3 Attentive Module,[0],[0]
"tively, where nQ, nK and nV denote the number of words in each sentence and ei stands for a ddimension embedding, nK is equal to nV .",3.3 Attentive Module,[0],[0]
"The Attentive Module first takes each word in the query sentence to attend to words in the key sentence via Scaled Dot-Product Attention (Vaswani et al., 2017), then applies those attention results upon the value sentence, which is defined as:
Att(Q,K) =",3.3 Attentive Module,[0],[0]
"[ softmax(
Q[i] · KT√ d ) ]nQ−1 i=0 (1)
Vatt = Att(Q,K) · V ∈ RnQ×d (2)
where Q[i] is the ith embedding in the query sentence Q.",3.3 Attentive Module,[0],[0]
"Each row of Vatt, denoted as Vatt[i], stores the fused semantic information of words in the value sentence that possibly have dependencies to the ith word in query sentence.",3.3 Attentive Module,[0],[0]
"For each i, Vatt[i] and Q[i] are then added up together, compositing them into a new representation that contains their joint meanings.",3.3 Attentive Module,[0],[0]
"A layer normalization operation (Ba et al., 2016) is then applied, which prevents vanishing or exploding of gradients.",3.3 Attentive Module,[0],[0]
"A feed-forward network FFN with RELU (LeCun et al., 2015) activation is then applied upon the normalization result, in order to further process the fused embeddings, defined as:
FFN(x) = max(0, xW1 + b1)W2 + b2 (3)
where, x is a 2D-tensor in the same shape of query sentence Q and W1, b1,W2, b2 are learnt parameters.",3.3 Attentive Module,[0],[0]
"This kind of activation is empirically useful in other works, and we also adapt it in our model.",3.3 Attentive Module,[0],[0]
"The result FFN(x) is a 2D-tensor that has the same shape as x, FFN(x) is then residually added (He et al., 2016) to x, and the fusion result is then normalized as the final outputs.",3.3 Attentive Module,[0],[0]
"We refer to the whole Attentive Module as:
AttentiveModule(Q,K,V) (4)
",3.3 Attentive Module,[0],[0]
"As described, Attentive Module can capture dependencies across query sentence and key sentence, and further use the dependency information to composite elements in the query sentence and the value sentence into compositional representations.",3.3 Attentive Module,[0],[0]
We exploit this property of the Attentive Module to construct multi-grained semantic representations as well as match with dependency information.,3.3 Attentive Module,[0],[0]
"Given U0i or R0, the word-level embedding representations for utterance ui or response r, DAM takes U0i ro R0 as inputs and hierarchically stacks the Attentive Module to construct multi-grained representations of ui and r, which is formulated as:
Ul+1i =",3.4 Representation,[0],[0]
AttentiveModule(U,3.4 Representation,[0],[0]
l,3.4 Representation,[0],[0]
"i,U l",3.4 Representation,[0],[0]
"i,U l i) (5) Rl+1",3.4 Representation,[0],[0]
"= AttentiveModule(Rl,Rl,Rl) (6)
where l ranges from 0 to L − 1, denoting the different levels of granularity.",3.4 Representation,[0],[0]
"By this means, words in each utterance or response repeatedly function together to composite more and more holistic representations, we refer to those multi-grained representations as [U0i , ...,ULi ] and [R0, ...,RL] hereafter.",3.4 Representation,[0],[0]
"Given [Uli]Ll=0 and [R
l]Ll=0, two kinds of segmentsegment matching matrixes are constructed at each level of granularity l, i.e., the self-attention-match Mui,r,lself and cross-attention-match M ui,r,l cross .",3.5 Utterance-Response Matching,[0],[0]
"M ui,r,l self is defined as:
Mui,r,lself = {U l i[k] T · Rl[t]}nui×nr (7)
in which, each element in the matrix is the dotproduct of Uli[k] and Rl[t], the kth embedding in Uli and the tth embedding in Rl, reflecting the textual relevance between the kth segment in ui and tth segment in r at the lth granularity.",3.5 Utterance-Response Matching,[0],[0]
"The crossattention-match matrix is based on cross-attention, which is defined as:
Ũ l
i =",3.5 Utterance-Response Matching,[0],[0]
AttentiveModule(U,3.5 Utterance-Response Matching,[0],[0]
"l i,R l,Rl) (8)
R̃ l = AttentiveModule(Rl,Uli,U l i) (9)
",3.5 Utterance-Response Matching,[0],[0]
"Mui,r,lcross = {Ũ l i[k] T · R̃l[t]}nui×nr (10)
where we use Attentive Module to make Uli and Rl crossly attend to each other, constructing two
new representations for both of them, written as Ũ",3.5 Utterance-Response Matching,[0],[0]
l i and R̃ l respectively.,3.5 Utterance-Response Matching,[0],[0]
"Both Ũ l i and R̃ l
implicitly capture semantic structures that cross the utterance and response.",3.5 Utterance-Response Matching,[0],[0]
"In this way, those inter-dependent segment pairs are close to each other in representations, and dot-products between those latently inter-dependent pairs could get increased, providing dependency-aware matching information.",3.5 Utterance-Response Matching,[0],[0]
"DAM finally aggregates all the segmental matching degrees across each utterance and response into a 3D matching image Q, which is defined as:
Q = {Qi,k,t}n×nui×nr (11)
where each pixel Qi,k,t is formulated as:
Qi,k,t =
[Mui,r,lself",3.6 Aggregation,[0],[0]
"[k, t]] L l=0 ⊕",3.6 Aggregation,[0],[0]
"[Mui,r,lcross [k, t]]Ll=0
(12)
⊕ is concatenation operation, and each pixel has 2(L + 1) channels, storing the matching degrees between one certain segment pair at different levels of granularity.",3.6 Aggregation,[0],[0]
DAM then leverages twolayered 3D convolution with max-pooling operations to distill important matching features from the whole image.,3.6 Aggregation,[0],[0]
"The operation of 3D convolution with max-pooling is the extension of typical 2D convolution, whose filters and strides are 3D cubes2.",3.6 Aggregation,[0],[0]
"We finally compute matching score g(c, r) based on the extracted matching features fmatch(c, r) via a single-layer perceptron, which is formulated as:
g(c, r) = σ(W3fmatch(c, r) + b3) (13)
where W3 and b3 are learnt parameters, and σ is sigmoid function that gives the probability if r is a proper candidate to c.",3.6 Aggregation,[0],[0]
"The loss function of DAM is the negative log likelihood, defined as:
p(y|c, r) =",3.6 Aggregation,[0],[0]
"g(c, r)y + (1− g(c, r))(1− y) (14) L(·) =",3.6 Aggregation,[0],[0]
"− ∑ (c,r,y)∈D log(p(y|c, r))",3.6 Aggregation,[0],[0]
(15),3.6 Aggregation,[0],[0]
2https://www.tensorflow.org/api docs/python/tf/nn/conv3d,4 Experiment,[0],[0]
"We test DAM on two public multi-turn response selection datasets, the Ubuntu Corpus V1 (Lowe et al., 2015) and the Douban Conversation Corpus (Wu et al., 2017).",4.1 Dataset,[0],[0]
The former one contains multiturn dialogues about Ubuntu system troubleshooting in English and the later one is crawled from a Chinese social networking on open-domain topics.,4.1 Dataset,[0],[0]
"The Ubuntu training set contains 0.5 million multiturn contexts, and each context has one positive response that generated by human and one negative response which is randomly sampled.",4.1 Dataset,[0],[0]
"Both validation and testing sets of Ubuntu Corpus have 50k contexts, where each context is provided with one positive response and nine negative replies.",4.1 Dataset,[0],[0]
"The Douban corpus is constructed in a similar way to the Ubuntu Corpus, except that its validation set contains 50k instances with 1:1 positive-negative ratios and the testing set of Douban corpus is consisted of 10k instances, where each context has 10 candidate responses, collected via a tiny invertedindex system (Lucene3), and labels are manually annotated.",4.1 Dataset,[0],[0]
"We use the same evaluation metrics as in previous works (Wu et al., 2017).",4.2 Evaluation Metric,[0],[0]
"Each comparison model is asked to select k best-matched response from n available candidates for the given conversation context c, and we calculate the recall of the true positive replies among the k selected ones as the main evaluation metric, denoted as Rn@k = ∑k i=1",4.2 Evaluation Metric,[0],[0]
yi∑n i=1,4.2 Evaluation Metric,[0],[0]
"yi
, where yi is the binary label for each candidate.",4.2 Evaluation Metric,[0],[0]
"In addition to Rn@k, we use MAP (Mean Average Precision) (Baeza-
3https://lucenent.apache.org/
Yates et al., 1999), MRR (Mean Reciprocal Rank) (Voorhees et al., 1999), and Precision-at-one P@1 especially for Douban corpus, following the setting of previous works (Wu et al., 2017).",4.2 Evaluation Metric,[0],[0]
"RNN-based models : Previous best performing
models are based on RNNs",4.3 Comparison Methods,[0],[0]
", we choose representative models as baselines, including SMNdynamic(Wu et al., 2017), Multiview(Zhou et al., 2016), DualEncoderlstm and DualEncoderbilstm (Lowe et al., 2015), DL2R (Yan et al., 2016), Match-LSTM (Wang and Jiang, 2017) and MV-LSTM (Pang et al., 2016), where SMNdynamic achieves the best scores against all the other published works, and we take it as our stateof-the-art baseline.
",4.3 Comparison Methods,[0],[0]
"Ablation : To verify the effects of multi-grained representation, we setup two comparison models, i.e., DAMfirst and DAMlast, which dispense with the multi-grained representations in DAM, and use representation results from the 0th layer and Lth layer of self-attention instead.",4.3 Comparison Methods,[0],[0]
"Moreover, we setup DAMself and DAMcross, which only use self-attention-match or cross-attention-match respectively, in order to examine the effectiveness of both self-attention-match and cross-attention-match.",4.3 Comparison Methods,[0],[0]
We copy the reported evaluation results of all baselines for comparison.,4.4 Model Training,[0],[0]
"DAM is implemented in tensorflow4, and the used vocabularies, word em-
4https://www.tensorflow.org.",4.4 Model Training,[0],[0]
"Our code and data will be available at https://github.com/baidu/Dialogue/DAM
bedding sizes for Ubuntu corpus and Douban corpus are all set as same as the SMN (Wu et al., 2017).",4.4 Model Training,[0],[0]
"We consider at most 9 turns and 50 words for each utterance (response) in our experiments, word embeddings are pre-trained using training sets via word2vec (Mikolov et al., 2013), similar to previous works.",4.4 Model Training,[0],[0]
"We use zero-pad to handle the variable-sized input and parameters in FFN are set to 200, same as word-embedding size.",4.4 Model Training,[0],[0]
"We test stacking 1-7 self-attention layers, and reported our results with 5 stacks of self-attention because it gains the best scores on validation set.",4.4 Model Training,[0],[0]
"The 1st convolution layer has 32 [3,3,3] filters with [1,1,1] stride, and its max-pooling size is [3,3,3] with [3,3,3] stride.",4.4 Model Training,[0],[0]
"The 2nd convolution layer has 16 [3,3,3] filters with [1,1,1] stride, and its maxpooling size is also [3,3,3] with [3,3,3] stride.",4.4 Model Training,[0],[0]
"We tune DAM and the other ablation models with adam optimizer (Le et al., 2011) to minimize loss function defined in Eq 15.",4.4 Model Training,[0],[0]
"Learning rate is initialized as 1e-3 and gradually decreased during training, and the batch-size is 256.",4.4 Model Training,[0],[0]
We use validation sets to select the best models and report their performances on test sets.,4.4 Model Training,[0],[0]
Table 1 shows the evaluation results of DAM as well as all comparison models.,4.5 Experiment Result,[0],[0]
"As demonstrated, DAM significantly outperforms other competitors on both Ubuntu Corpus and Douban Conversation Corpus, including SMNdynamic, which is the state-of-the-art baseline, demonstrating the superior power of attention mechanism in matching response with multi-turn context.",4.5 Experiment Result,[0],[0]
"Besides, both the performances of DAMfirst and DAMself decrease a lot compared with DAM, which shows the effectiveness of self-attention and cross-attention.",4.5 Experiment Result,[0],[0]
"Both DAMfirst and DAMlast underperform DAM, which demonstrates the benefits of using multigrained representations.",4.5 Experiment Result,[0],[0]
"Also the absence of self-attention-match brings down the precision, as shown in DAMcross, exhibiting the necessity of jointly considering textual relevance and dependency information in response selection.
",4.5 Experiment Result,[0],[0]
"One notable point is that, while DAMfirst is able to achieve close performance to SMNdynamic, it is about 2.3 times faster than SMNdynamic in our implementation as it is very simple in computation.",4.5 Experiment Result,[0],[0]
"We believe that DAMfirst is more suitable to the scenario that has limitations in computation time or memories but requires high precise, such
as industry application or working as an component in other neural networks like GANs.",4.5 Experiment Result,[0],[0]
We use the Ubuntu Corpus for analyzing how selfattention and cross-attention work in DAM from both quantity analysis as well as visualization.,5 Analysis,[0],[0]
We first study how DAM performs in different utterance number of context.,5.1 Quantity Analysis,[0],[0]
The left part in Figure 4 shows the changes of R10@1 on Ubuntu Corpus across contexts with different number of utterance.,5.1 Quantity Analysis,[0],[0]
"As demonstrated, while being good at matching response with long context that has more than 4 utterances, DAM can still stably deal with short context that only has 2 turns.
",5.1 Quantity Analysis,[0],[0]
"Moreover, the right part of Figure 4 gives the comparison of performance across different contexts with different average utterance text length and self-attention stack depth.",5.1 Quantity Analysis,[0],[0]
"As demonstrated, stacking self-attention can consistently improve matching performance for contexts having different average utterance text length, implying the stability advantage of using multi-grained semantic representations.",5.1 Quantity Analysis,[0],[0]
"The performance of matching short utterances, that have less than 10 words, is obviously lower than the other longer ones.",5.1 Quantity Analysis,[0],[0]
"This is because the shorter the utterance text is, the fewer information it contains, and the more difficult for selecting the next utterance, while stacking self-attention can still help in this case.",5.1 Quantity Analysis,[0],[0]
"However for long utterances like containing more than 30 words, stacking self-attention can significantly improve the matching performance, which means that the more information an utterance contains, the more stacked self-attention it needs to capture its intra semantic structures.
",5.1 Quantity Analysis,[0],[0]
"no clue what
do you
need it
for.",5.1 Quantity Analysis,[0],[0]
"its
just reassurance
as i
dont know
the debain
package manager
hi",5.1 Quantity Analysis,[0],[0]
"i am lo ok in
g to se e wh at pa ck ag es ar e in st al le d on m y sy st em i.1",5.1 Quantity Analysis,[0],[0]
do nt se e. 1 a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew he re el se
turn 0
re sp
on se
self−attention−match in stack 0
no clue what
do you
need it
for.",5.1 Quantity Analysis,[0],[0]
"its
just reassurance
as i
dont know
the debain
package manager
hi",5.1 Quantity Analysis,[0],[0]
"i am lo ok in
g to se e wh at pa ck ag es ar e in st al le d on m y sy st em i.1",5.1 Quantity Analysis,[0],[0]
do nt se e. 1 a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew he re el se
turn 0
re sp
on se
self−attention−match in stack 2
no clue what
do you
need it
for.",5.1 Quantity Analysis,[0],[0]
"its
just reassurance
as i
dont know
the debain
package manager
hi",5.1 Quantity Analysis,[0],[0]
"i am lo ok in
g to se e wh at pa ck ag es ar e in st al le d on m y sy st em i.1",5.1 Quantity Analysis,[0],[0]
do nt se e. 1 a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew he re el se
turn 0
re sp
on se
self−attention−match in stack 4
no clue what
do you
need it
for.",5.1 Quantity Analysis,[0],[0]
"its
just reassurance
as i
dont know
the debain
package manager
hi",5.1 Quantity Analysis,[0],[0]
"i am lo ok in
g to se e wh at pa ck ag es ar e in st al le d on m y sy st em i.1",5.1 Quantity Analysis,[0],[0]
do nt se e. 1 a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew he re el se
turn 0
re sp
on se
cross−attention−match in stack 4
no clue what
do you
need it
for its
just reassurance
as i
dont know
the debain
package manager
no clu e wh",5.1 Quantity Analysis,[0],[0]
"at do yo u ne ed it fo r. its ju st
re as
su ra
nc e
as i do nt kn ow th e de ba in pa ck ag e m an ag
er
response
re sp
on se
self−attention of response in stack 3
hi i
am looking
to see
what packages
are installed
on my
system i.1
dont see.1
a path
is the list
being held
somewhere else
",5.1 Quantity Analysis,[0],[0]
"hi i am lo ok in
g to se e wh",5.1 Quantity Analysis,[0],[0]
at pa ck ag es ar e in st al le d on m y sy st em i.1 do nt se e. 1 a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew he re el se
.",5.1 Quantity Analysis,[0],[0]
"turn 0
tu rn
0 self−attention of turn 0 in stack 3
no clue what
do you
need it
for its
just reassurance
as i
dont know
the debain
package manager
hi",5.1 Quantity Analysis,[0],[0]
"i am lo ok in
g to se e wh at pa ck ag es ar e in st al le d on m y sy st em i.1",5.1 Quantity Analysis,[0],[0]
do nt se e. 1 a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
so m ew he re el se .,5.1 Quantity Analysis,[0],[0]
"turn 0 re
sp on
se
attention of response over turn 0 in stack 4
hi i
am looking
to see
what packages
are installed
on my
system i.1
",5.1 Quantity Analysis,[0],[0]
"dont see.1
a path
is the list
being held
somewhere else
no clu e wh at do yo u ne ed it fo r.",5.1 Quantity Analysis,[0],[0]
"its ju st
re as
su ra
nc e
as i do nt kn ow th e de ba in pa ck ag e m an ag
er
response
tu rn
0
attention of turn 0 over response in stack 4
self-attention cross-attention
no clue what
do you
need it
for.",5.1 Quantity Analysis,[0],[0]
"its
just reassurance
as i
dont know
the debain
package manager
hi",5.1 Quantity Analysis,[0],[0]
"i am lo ok in
g to se e w ha t
pa ck
ag es
ar e
in st
al le d on m
y sy
st",5.1 Quantity Analysis,[0],[0]
em do nt a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew
he re
el se
turn 0
re sp
on se
prior−match in stack 0
no clue what
do you
need it
for.",5.1 Quantity Analysis,[0],[0]
"its
just reassurance
as i
dont know
the debain
package manager
hi",5.1 Quantity Analysis,[0],[0]
"i am lo ok in
g to se e w ha t
pa ck
ag es
ar e
in st
al le d on m
y sy
st",5.1 Quantity Analysis,[0],[0]
em do nt a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew
he re
el se
turn 0
re sp
on se
prior−match in stack 2
no clue what
do you
need it
for.",5.1 Quantity Analysis,[0],[0]
"its
just reassurance
as i
dont know
the debain
package manager
hi",5.1 Quantity Analysis,[0],[0]
"i am lo ok in
g to se e w ha t
pa ck
ag es
ar e
in st
al le d on m
y sy
st",5.1 Quantity Analysis,[0],[0]
em do nt a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew
he re
el se
turn 0
re sp
on se
prior−match in stac 4
no clue what
do you
need it
for.",5.1 Quantity Analysis,[0],[0]
"its
just reassurance
as i
dont know
the debain
package manager
hi",5.1 Quantity Analysis,[0],[0]
"i am lo ok in
g to se e w ha t
pa ck
ag es
ar e
in st
al le d on m
y sy
st",5.1 Quantity Analysis,[0],[0]
em do nt a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew
he re
el se
turn 0
re sp
on se
posterior−match in stack 4
no clue what
do you
need it
for its
just reassurance
as i
dont know
the debain
package manager
no cl",5.1 Quantity Analysis,[0],[0]
ue w ha t,5.1 Quantity Analysis,[0],[0]
do yo u ne ed,5.1 Quantity Analysis,[0],[0]
"it fo r. its ju st
re as
su ra
nc e
as i do nt kn ow th e de ba in pa ck ag e m an ag
er
response
re sp
on se
self−attention of response in stack 3
hi i
am looking
to see
what packages
are installed
on my
system dont
a path
is the list
being held
somewhere else
",5.1 Quantity Analysis,[0],[0]
"hi i am lo ok in
g to se e w ha t
pa ck
ag es
ar e
in st
al le d on m
y sy
st em i.1",5.1 Quantity Analysis,[0],[0]
do nt se e. 1 a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew
he re
el se
.
",5.1 Quantity Analysis,[0],[0]
"turn 0
tu rn
0
self−attention of turn 0 in stack 3
no clue what
do you
need it
for its
just reassurance
as i
dont know
the debain
package manager
",5.1 Quantity Analysis,[0],[0]
"hi i am lo ok in
g to se e w ha t
pa ck
ag es
ar e
in st
al le d on m
y sy
st em i.1",5.1 Quantity Analysis,[0],[0]
do nt se e. 1 a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew
he re
el se
.
",5.1 Quantity Analysis,[0],[0]
"turn 0
re
sp
on se
attention of response over turn 0 in stack 4
hi i
am looking
to see
what packages
are installed
on my
system",5.1 Quantity Analysis,[0],[0]
"dont
a path
is the list
being held
somewhere else
no cl",5.1 Quantity Analysis,[0],[0]
ue w ha t,5.1 Quantity Analysis,[0],[0]
do yo u ne ed,5.1 Quantity Analysis,[0],[0]
"it fo r. its ju st
re as
su ra
nc e
as i do nt kn ow th e de ba in pa ck ag e m an ag
er
response
tu rn
0
attention of turn 0 over response in stack 4
prior-match posterior-match
self-attention cross-attention
no clue hat do
you need
it for.",5.1 Quantity Analysis,[0],[0]
"its
just reassurance
as i
dont kno
the debain
package anager
hi i am lo ok in
g to se e w ha t
pa ck
ag es
ar e
in st
al le d on m
y sy
st em do nt a pa th is th e lis t be in g",5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew
he re
el se
turn 0
re sp
on se
prior atch in stack 0
no clue hat do
you need
it for.",5.1 Quantity Analysis,[0],[0]
"its
just reassurance
as i
dont kno
the debain
package anager
hi i am lo ok in
g to se e w ha t
pa ck
ag es
ar e
in st
al le d on m
y sy
st em do nt a pa th is th e lis t be in g",5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew
he re
el se
turn 0
re sp
on se
prior atch in stack 2
no clue hat do
you need
it for.",5.1 Quantity Analysis,[0],[0]
"its
just reassurance
as i
dont kno
the debain
package anager
hi i am lo ok in
g to se e w ha t
pa ck
ag es
ar e
in st
al le d on m
y sy
st em do nt a pa th is th e lis t be in g",5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew
he re
el se
turn 0
re sp
on se
prior−match in stac 4
no clue what
do you
need it
for.",5.1 Quantity Analysis,[0],[0]
"its
just reassurance
as i
dont know
the debain
package manager
hi",5.1 Quantity Analysis,[0],[0]
"i am lo ok in
g to se e w ha t
pa ck
ag es
ar e
in st
al le d on m
y sy
st",5.1 Quantity Analysis,[0],[0]
em do nt a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew
he re
el se
turn 0
re sp
on se
posterior−match in stack 4
no clue what
do you
need it
for its
just reassurance
as i
dont know
the debain
package manager
no cl",5.1 Quantity Analysis,[0],[0]
ue w ha t,5.1 Quantity Analysis,[0],[0]
do yo u ne ed,5.1 Quantity Analysis,[0],[0]
"it fo r. its ju st
re as
su ra
nc e
as i do nt kn ow th e de ba in pa ck ag e m an ag
er
response
re sp
on se
self−attention of espo e in stack 3
hi i
am looking
to see
what packages
are installed
on my
ystem dont
a path
is the list
being held
somewhere else
",5.1 Quantity Analysis,[0],[0]
"hi i am lo ok in
g to se e w ha t
pa ck
ag es
ar e
in st
al le d on m
y sy
st em i.1",5.1 Quantity Analysis,[0],[0]
do nt se e. 1 a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew
he re
el se
.
",5.1 Quantity Analysis,[0],[0]
"t
tu rn
0
self−atte tion of turn 0 in stack 3
no clue what
do you
need it
for its
just rea surance
as i
dont know
the debain
package manager
",5.1 Quantity Analysis,[0],[0]
"hi i am lo ok in
g to se e w ha t
pa ck
ag es
ar e
in st
al le d on m
y sy
st em i.1",5.1 Quantity Analysis,[0],[0]
do nt se e. 1 a pa th is th e lis t be in g,5.1 Quantity Analysis,[0],[0]
he ld,5.1 Quantity Analysis,[0],[0]
"so m ew
he re
el se
.
",5.1 Quantity Analysis,[0],[0]
"turn 0
re
sp
on se
attention of esponse over turn 0 in stack 4
hi i
am looking
to see
what packages
are installed
on my
system",5.1 Quantity Analysis,[0],[0]
"dont
a path
is the list
being held
somewhere else
no cl",5.1 Quantity Analysis,[0],[0]
ue w ha t,5.1 Quantity Analysis,[0],[0]
do yo u ne ed,5.1 Quantity Analysis,[0],[0]
"it fo r. its ju st
re as
su ra
nc e
as i do nt kn ow th e de ba in pa ck ag e m an ag
er
response
tu rn
0
attention of turn 0 over response in stack 4
prior-match posterior-match
self-attention cross-attention
s l - tention-match in stack 0 lf-a tention-match in stack 2 self-attention-match in stack 4 cross-attention-match in stack 4 self-attention-match cross-attention-match
Figure 5: Visualization of self-attention-match, cross-attention-match as well as the distribution of self-attention and crossattention in matching response with the first utterance in Figure 1.",5.1 Quantity Analysis,[0],[0]
Each c lored grid represents the matching degree or attention score between two words.,5.1 Quantity Analysis,[0],[0]
"The deeper the color is, the more important this grid is.",5.1 Quantity Analysis,[0],[0]
We study the case in Figure 1 for analyzing in detail how self-attention and cross-attention work.,5.2 Visualization,[0],[0]
"Practically, we apply a softmax operation over self-attention-match and cross-attention-match, to examine the variance of dominating matching pairs during stacking self-attention or applying cross-attention.",5.2 Visualization,[0],[0]
"Figure 5 gives the visualization results of the 0th, 2nd and 4th self-attention-match matrixes, the 4th cross-attention-match matrix, as well as the distribution of self-attention and crossattention in the 4th layer in matching response with the first utterance (turn 0) due to space limitation.",5.2 Visualization,[0],[0]
"As demonstrated, important matching pairs in selfattention-match in stack 0 are nouns, verbs, like “package” and “packages”, those are similar in topics.",5.2 Visualization,[0],[0]
"However matching scores between prepositions or pronouns pairs, such as “do” and “what”, become more important in self-attention-match in stack 4.",5.2 Visualization,[0],[0]
"The visualization results of self-attention show the reason why matching between prepositions or pronouns matters, as demonstrated, selfattention generally capture the semantic structure of “no clue what do you need package manager” for “do” in response and “what packages are installed” for “what” in utterance, making segments surrounding “do” and “what” close to each other in representations, thus increases their dot-product results.
",5.2 Visualization,[0],[0]
"Also as shown in Figure 5, self-attentionmatch and cros -attention-match capture complementary information in matching utterance with response.",5.2 Visualization,[0],[0]
Words like “reassurance” and “its” in response significantly get larger matching scores in cross-attention-match compared with self-attention-match.,5.2 Visualization,[0],[0]
"According to the visualization of cross-attention, “reassurance” generally depends on “system” “don’t” and “held” in utterance, which makes it close to words like “list”, “installed” or “held” of utterance.",5.2 Visualization,[0],[0]
"Scores of crossattention-match trend to centralize on several segments, which probably means that those segments in response generally capture structure-semantic information across utterance and response, amplifying their matching scores against the others.",5.2 Visualization,[0],[0]
"To understand the limitations of DAM and where the future improvements might lie, we analyze 100 strong bad cases from test-set that fail in R10@5.",5.3 Error Analysis,[0],[0]
"We find two major kinds of bad cases: (1) fuzzycandidate, where response candidates are basically proper for the conversation context, except for a few improper details.",5.3 Error Analysis,[0],[0]
"(2) logical-error, where response candidates are wrong due to logical mismatch, for example, given a conversation context A: “I just want to stay at home tomorrow.”",5.3 Error Analysis,[0],[0]
", B: “Why not go hiking?",5.3 Error Analysis,[0],[0]
"I can go with
you.”",5.3 Error Analysis,[0],[0]
", response candidate like “Sure, I was planning to go out tomorrow.” is logically wrong because it is contradictory to the first utterance of speaker A.",5.3 Error Analysis,[0],[0]
"We believe generating adversarial examples, rather than randomly sampling, during training procedure may be a good idea for addressing both fuzzy-candidate and logical-error, and to capture logic-level information hidden behind conversation text is also worthy to be studied in the future.",5.3 Error Analysis,[0],[0]
"In this paper, we investigate matching a response with its multi-turn context using dependency information based entirely on attention.",6 Conclusion,[0],[0]
Our solution extends the attention mechanism of Transformer in two ways: (1) using stacked selfattention to harvest multi-grained semantic representations.,6 Conclusion,[0],[0]
(2) utilizing cross-attention to match with dependency information.,6 Conclusion,[0],[0]
Empirical results on two large-scale datasets demonstrate the effectiveness of self-attention and cross-attention in multi-turn response selection.,6 Conclusion,[0],[0]
"We believe that both self-attention and cross-attention could benefit other research area, including spoken language understanding, dialogue state tracking or seq2seq dialogue generation.",6 Conclusion,[0],[0]
We would like to explore in depth how attention can help improve neural dialogue modeling for both chatbots and taskoriented dialogue systems in our future work.,6 Conclusion,[0],[0]
We gratefully thank the anonymous reviewers for their insightful comments.,Acknowledgement,[0],[0]
"This work is supported by the National Basic Research Program of China (973 program, No. 2014CB340505).",Acknowledgement,[0],[0]
"Human generates responses relying on semantic and functional dependencies, including coreference relation, among dialogue elements and their context.",abstractText,[0],[0]
"In this paper, we investigate matching a response with its multi-turn context using dependency information based entirely on attention.",abstractText,[0],[0]
"Our solution is inspired by the recently proposed Transformer in machine translation (Vaswani et al., 2017) and we extend the attention mechanism in two ways.",abstractText,[0],[0]
"First, we construct representations of text segments at different granularities solely with stacked self-attention.",abstractText,[0],[0]
"Second, we try to extract the truly matched segment pairs with attention across the context and response.",abstractText,[0],[0]
We jointly introduce those two kinds of attention in one uniform neural network.,abstractText,[0],[0]
Experiments on two large-scale multi-turn response selection tasks show that our proposed model significantly outperforms the state-of-the-art models.,abstractText,[0],[0]
Multi-Turn Response Selection for Chatbots with Deep Attention Matching Network,title,[0],[0]
"Machine-learned predictors are informing decisions that affect all aspects of life; from news article recommendations to criminal sentencing decisions to healthcare diagnostics, increasingly algorithms are used to make predictions about individuals.",1. Introduction,[0],[0]
A potential risk is that these predictors might discriminate against groups of individuals that are protected by law or by ethics.,1. Introduction,[0],[0]
"Indeed, examples of such unintended but harmful discrimination have been well-documented across many learning tasks including image classification (Buolamwini & Gebru, 2018) and natural language tasks (Bolukbasi et al., 2016).",1. Introduction,[0],[0]
"This work aims to mitigate such risks of algorithmic discrimination in the context of prediction tasks.
",1. Introduction,[0],[0]
"The output of a learning algorithm can be discriminatory for
1Computer Science Department, Stanford University, Stanford, CA 2Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot, Israel.",1. Introduction,[0],[0]
"Correspondence to: Michael P. Kim <mpk@cs.stanford.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
a number of reasons.,1. Introduction,[0],[0]
"First, the training data may contain biases that should be corrected.",1. Introduction,[0],[0]
"Second, the analysis of the training data may inadvertently introduce biases that are not borne out in the data.",1. Introduction,[0],[0]
"In this work, we focus on the latter concern.
",1. Introduction,[0],[0]
"Indeed, even given accurate ground-truth training data, the typical approach to supervised learning – choosing a model that minimizes the expected loss on the training data – runs the risk of choosing a prediction model that is good for the majority population, but overlooks the minority populations.",1. Introduction,[0],[0]
Consider the case where a financial institution trains a model to predict the probability that applicants will default on their loans.,1. Introduction,[0],[0]
"If on average, the individuals from S are financially disadvantaged compared to the majority population, the model may assign a fixed, low probability to all i ∈ S, while still achieving good empirical loss by predicting very accurately in the majority population.",1. Introduction,[0],[0]
"Such a model discriminates against the qualified members of S. Worse yet, this form of discrimination has the potential to amplify S’s underrepresentation by refusing to approve members that are capable of repaying the loan.
",1. Introduction,[0],[0]
"Focusing on such concerns, we develop a theoretical framework that aims to mitigate such risks of algorithmic discrimination, in the context of prediction tasks.",1. Introduction,[0],[0]
"Specifically, we focus on a setting where a learner has access to a small sample of ground truth data D from some domain of individuals X .",1. Introduction,[0],[0]
Each individual i ∈ D has a boolean label oi,1. Introduction,[0],[0]
∈,1. Introduction,[0],[0]
"{0, 1} representing the outcome of a certain stochastic event (ad click, loan repayment, cancer diagnosis, etc.) that the learner wishes to predict.",1. Introduction,[0],[0]
"We suppose that for each i ∈ X , there is an underlying probability p∗i which governs the distribution of the resulting outcome oi.",1. Introduction,[0],[0]
We say a predictor f : X,1. Introduction,[0],[0]
"→ [0, 1] is a map from individuals i ∈ X to an estimate of the true parameters.",1. Introduction,[0],[0]
"Next, we discuss desirable properties of predictors that motivate our new perspective on fairness.
",1. Introduction,[0],[0]
Calibration and Multicalibration.,1. Introduction,[0],[0]
"If we do not want a predictor f to downplay the fitness of a group S ⊆ X , we can require that it be (approximately) unbiased over S; namely, that
∣∣Ei∼S",1. Introduction,[0],[0]
"[fi − p∗i ]∣∣ ≤ α, for some small α ≥ 0.",1. Introduction,[0],[0]
This means that the expectation of f and p∗ over S are almost identical.,1. Introduction,[0],[0]
"Calibration strengthens this requirement by essentially asking that for any particular
value v, if we let Sv = {i ∈ S : fi = v} be the subset of S of individuals with predicted probability v, then∣∣Ei∼Sv [fi − p∗i ]∣∣ = |v",1. Introduction,[0],[0]
− Ei∼Sv [p∗i ]| ≤ α.,1. Introduction,[0],[0]
"While this notion already precludes some forms of discrimination, a principle weakness of calibration as a fairness concept is that the guarantees are too coarse.",1. Introduction,[0],[0]
"Indeed, weaknesses of group fairness notions were discussed in (Dwork et al., 2012), as a motivation for introducing an individual fairness notion.",1. Introduction,[0],[0]
A specific way to discriminate while satisfying calibration is to assign every member of S the value Ei∼S [p∗i ].,1. Introduction,[0],[0]
"While being perfectly calibrated over S, the qualified members of S with large values p∗i will be hurt.
",1. Introduction,[0],[0]
"Calibration is typically applied to large, often disjoint, sets of protected groups; that is, the guarantees are only required to hold on average over a population defined by a small number of sensitive attributes, like race or gender.",1. Introduction,[0],[0]
"A stronger definition of fairness would ensure that the predictions on every subpopulation would be calibrated, including, for instance, the qualified members of S from the example above.",1. Introduction,[0],[0]
"The problem with such a notion is that it is informationtheoretically unattainable from a small sample of labeled examples, as it essentially requires perfect predictions.",1. Introduction,[0],[0]
"As such, we need an intermediary definition that balances the desire to protect important subgroups and the information bottleneck that arises when learning from a small sample.
",1. Introduction,[0],[0]
"To motivate our notion, suppose a learning algorithm produces a predictor f .",1. Introduction,[0],[0]
"Then, more outcomes are determined, and an auditor finds a subpopulation S whose outcomes outperform the predictions made by f .",1. Introduction,[0],[0]
Perhaps the learning algorithm was lazy and neglected to identify the higher potential in S?,1. Introduction,[0],[0]
Perhaps the individuals of S were simply lucky?,1. Introduction,[0],[0]
How can we tell?,1. Introduction,[0],[0]
"To answer these questions, we take the following perspective: on the one hand, we can only expect a learner to produce a predictor that is calibrated on sets that could have been identified efficiently from the data at hand; on the other hand, we expect the learner to produce a predictor that is calibrated on every efficiently-identifiable subset.",1. Introduction,[0],[0]
"This motivates our definition of multicalibration, which loosely says: “A predictor f is multicalibrated with respect to a family of subpopulations C if it is calibrated with respect to every S ∈ C.”
In a nutshell, multicalibration guarantees highly-accurate predictions for every subpopulation of individuals identified by a specified collection C of subpopulations of individuals.",1. Introduction,[0],[0]
"While our results can be applied to any set system C, typically, we will think of C as a collection of subsets where set membership can be determined efficiently – for instance, subpopulations defined by the conjunctions of a small number of boolean features or by small decision trees.",1. Introduction,[0],[0]
"In this sense, we can take C to be sets identified by a class of bounded computations.",1. Introduction,[0],[0]
"As we increase the expressiveness of C, the fairness guarantee becomes stronger; no subpopulation that
can be identified within the class will be overlooked.
",1. Introduction,[0],[0]
"In the mortgage repayment example above, if the qualified members of S can be identified by some computation c ∈ C, then the resulting predictor cannot ignore the variance within S.",1. Introduction,[0],[0]
"We emphasize that the class C can be quite rich and, in particular, can contain many overlapping subgroups of a protected group S.",1. Introduction,[0],[0]
"In this sense, multicalibration goes far beyond calibration for a handful of sensitive groups, providing calibration for all computationally-identifiable subsets, where the notion of computational-identifiability is parameterized by the expressiveness of C.",1. Introduction,[0],[0]
We investigate the new notion of multicalibration from an algorithmic and complexity theoretic perspective.,1.1. Our Contributions,[0],[0]
"We present a simple, general-purpose algorithm for learning a predictor from a small set of labeled examples that is multicalibrated with respect to any given class C. The algorithm is an iterative method, similar to boosting, that can be viewed as a variant of functional gradient descent.",1.1. Our Contributions,[0],[0]
A number of subtleties arise when learning a multicalibrated predictor due to the fact that the calibration constraints change based on the current set of predictions made by the predictor.,1.1. Our Contributions,[0],[0]
"To guarantee generalization from a small sample of training examples, we leverage results from a new line of work connecting differential privacy to robust adaptive data analysis (Dwork et al., 2015a;b;c; Bassily et al., 2016).
",1.1. Our Contributions,[0],[0]
"We place no explicit restrictions on the hypothesis class of the learned predictor; instead, we show that implicitly our algorithm learns a model that provably generalizes well to unseen data, which may be of independent interest.",1.1. Our Contributions,[0],[0]
"We demonstrate this implicit generalization by showing the predictions we learn are compressible, in a sense similar to decomposition lemmas from pseudorandomness (Trevisan et al., 2009).",1.1. Our Contributions,[0],[0]
"In the language of circuit complexity, we show that we can build a circuit, only slightly larger than the circuits from C, that implements the learned predictor.",1.1. Our Contributions,[0],[0]
"As a corollary, the learned predictor is efficient in both space to represent and time to evaluate.
",1.1. Our Contributions,[0],[0]
"We also study the computational complexity of learning multicalibrated predictors for structured classes C. We show a strong connection between the complexity of learning a multicalibrated predictor and agnostic learning (Haussler, 1992; Kearns et al., 1994).",1.1. Our Contributions,[0],[0]
"In the positive direction, if there is an efficient (weak) agnostic learner (Kalai et al., 2008; Feldman, 2010) for a class C, then we can achieve similarly efficient multicalibration over C. In the other direction, we show that learning a multicalibrated predictor on all sets defined by C is as hard as weak agnostic learning C.",1.1. Our Contributions,[0],[0]
"In this sense, the complexity of learning a multicalibrated predictor with respect to a class C is equivalent to the complexity of weak agnostic learning C.
Finally, we demonstrate that the goal of multicalbration is aligned with the goal of achieving high-utility predictions.",1.1. Our Contributions,[0],[0]
"In particular, given any predictor h, we can post-process h to obtain a multicalibrated predictor f whose squared error is no worse than that of h.",1.1. Our Contributions,[0],[0]
The complexity of evaluating the predictor f is only slightly larger than that of h.,1.1. Our Contributions,[0],[0]
"In this sense, unlike many fairness notions, multicalibration is not at odds with predictive power and can be paired with any predictive model at essentially no cost to its accuracy.",1.1. Our Contributions,[0],[0]
Let X denote the domain of (feature vectors of) individuals; we wish to predict whether some event will occur for each individual.,2. Multicalibration Preliminaries,[0],[0]
"For each i ∈ X , we assume there is some unknown probability p∗i ∈",2. Multicalibration Preliminaries,[0],[0]
"[0, 1]; we make no assumptions on the structure of p∗ : X",2. Multicalibration Preliminaries,[0],[0]
"→ [0, 1].",2. Multicalibration Preliminaries,[0],[0]
"In particular, we assume that there is enough uncertainty in the outcomes that it may be hard to learn p∗ directly.",2. Multicalibration Preliminaries,[0],[0]
"Let D denote the distribution over individuals, supported on X ; for S ⊆ X , let i ∼ S denote a sample drawn from D conditioned on membership in S.1 In our learning setting, the algorithm has access to a small number of labeled individuals D ⊆ X , where for each i ∈ D, the label is the outcome oi ∼ Ber(p∗i ) of an independent Bernoulli trial.",2. Multicalibration Preliminaries,[0],[0]
"Given these samples, the learner aims to produce a predictor f :",2. Multicalibration Preliminaries,[0],[0]
X,2. Multicalibration Preliminaries,[0],[0]
"→ [0, 1] that achieves multicalibration, described formally next.
",2. Multicalibration Preliminaries,[0],[0]
Multicalibration.,2. Multicalibration Preliminaries,[0],[0]
"The most basic property we might hope for from a predictor is unbiasedness, i.e. that the predictions are accurate in expectation.
",2. Multicalibration Preliminaries,[0],[0]
Definition (Accuracy in expectation).,2. Multicalibration Preliminaries,[0],[0]
"For any α > 0 and S ⊆ X , a predictor f is α-accurate-in-expectation (AE) with respect to S if ∣∣∣ E
i∼S",2. Multicalibration Preliminaries,[0],[0]
[fi − p∗i ] ∣∣∣ ≤ α.,2. Multicalibration Preliminaries,[0],[0]
"(1) While this condition is necessary to achieve unbiased predictions, it is not sufficient to prevent all forms of discrimination; in particular, a predictor can be unbiased on a set S while introducing variance that is not borne out in the data, artificially treating similar individuals differently.",2. Multicalibration Preliminaries,[0],[0]
Calibration mitigates this form of discrimination by considering the expected values over categories Sv = {i : fi = v} defined by the predictor f .,2. Multicalibration Preliminaries,[0],[0]
"Specifically, α-calibration with respect to S requires that for all but an α-fraction of a set S, the average of the true probabilities of the individuals receiving prediction v is α-close to v.
1We remark that in order to guarantee a meaningful notion of fairness, we assume that the subpopulations we wish to protect are sufficiently represented in the distribution D, in order to see these populations in a random sample.",2. Multicalibration Preliminaries,[0],[0]
"Understanding how much representation is necessary in practice remains an interesting question for future empirical investigations.
",2. Multicalibration Preliminaries,[0],[0]
Definition (Calibration).,2. Multicalibration Preliminaries,[0],[0]
For any v ∈,2. Multicalibration Preliminaries,[0],[0]
"[0, 1], S ⊆ X , and predictor f , let Sv = {i : fi = v}.",2. Multicalibration Preliminaries,[0],[0]
For α ∈,2. Multicalibration Preliminaries,[0],[0]
"[0, 1], f is α-calibrated with respect to S if there exists some S′ ⊆ S with Pri∼D[i ∈ S′] ≥ (1− α) · Pri∼D[i ∈ S] such that for all v ∈",2. Multicalibration Preliminaries,[0],[0]
"[0, 1], ∣∣∣∣ Ei∼Sv∩S′[fi − p∗i ]
∣∣∣∣ ≤ α.",2. Multicalibration Preliminaries,[0],[0]
(2) Note that α-calibration with respect to S implies 2α-AE with respect to S. Our definition only requires the notion of calibration to hold on a (1−α)-fraction of each S; this is for technical reasons due to learning from a small sample and needing to discretize the range,2. Multicalibration Preliminaries,[0],[0]
"[0, 1] of the learned predictor.
",2. Multicalibration Preliminaries,[0],[0]
"For a collection of subsets C, we say that a predictor is (C, α)-multicalibrated if it is α-calibrated simultaneously on all S ∈ C. Definition (Multicalibration).",2. Multicalibration Preliminaries,[0],[0]
Let C ⊆ 2X be a collection of subsets of X and α ∈,2. Multicalibration Preliminaries,[0],[0]
"[0, 1].",2. Multicalibration Preliminaries,[0],[0]
"A predictor f is (C, α)multicalibrated if for all S ∈ C, f is α-calibrated with respect to S.
Discretization.",2. Multicalibration Preliminaries,[0],[0]
Even though α-calibration is a meaningful definition if we allow for arbitrary predictions fi ∈,2. Multicalibration Preliminaries,[0],[0]
"[0, 1], computationally, we need to maintain some discretization on the values v ∈",2. Multicalibration Preliminaries,[0],[0]
"[0, 1].",2. Multicalibration Preliminaries,[0],[0]
"Formally, we will use the following technical definition.
",2. Multicalibration Preliminaries,[0],[0]
Definition (λ-discretization).,2. Multicalibration Preliminaries,[0],[0]
Let λ > 0.,2. Multicalibration Preliminaries,[0],[0]
"The λ-discretization of [0, 1], denoted by Λ[0, 1] ={ λ 2 , 3λ 2 , . . .",2. Multicalibration Preliminaries,[0],[0]
", 1− λ 2 } , is the set of 1/λ evenly spaced real values over [0, 1].",2. Multicalibration Preliminaries,[0],[0]
"For v ∈ Λ[0, 1], let
λ(v) =",2. Multicalibration Preliminaries,[0],[0]
"[v − λ/2, v + λ/2)
be the λ-interval centered around v (except for the final interval, which will be [1− λ, 1]).
",2. Multicalibration Preliminaries,[0],[0]
"If we take λ = α, then the λ-discretization of a (C, α)multicalibrated predictor will be (C, 2α)-multicalibrated.
",2. Multicalibration Preliminaries,[0],[0]
"In what follows, we give an overview of our results and a flavor of the proof techniques.",2. Multicalibration Preliminaries,[0],[0]
"We defer complete coverage of the results and formal proofs to the Supplementary Materials (see also, the archival version (Hébert-Johnson et al., 2017)).",2. Multicalibration Preliminaries,[0],[0]
The first question to address is whether multicalibration is feasible.,3. Learning Multicalibrated Predictors,[0],[0]
"For instance, it could be the case that the requirements of multicalibration are so strong that they would require learning and representing an arbitrarily complex function p∗ very precisely, which can be infeasible in our setting.",3. Learning Multicalibrated Predictors,[0],[0]
Our first result characterizes the complexity of representing a multicalbrated predictor.,3. Learning Multicalibrated Predictors,[0],[0]
"We demonstrate that
multicalibration, indeed, can be achieved efficiently: for any p∗ and any collection of large subsets C, there exists a predictor that is α-multicalibrated on C, whose complexity is only slightly larger than the complexity required to describe the sets of C. For concreteness, we use circuit size as our measure of complexity in the following theorem.",3. Learning Multicalibrated Predictors,[0],[0]
Theorem 1.,3. Learning Multicalibrated Predictors,[0],[0]
"Suppose C ⊆ 2X is collection of sets where for S ∈ C, there is a circuit of size s that computes membership in S and Pri∼D[i ∈ S] ≥ γ.",3. Learning Multicalibrated Predictors,[0],[0]
"For any p∗ : X → [0, 1], there is a predictor that is (C, α)-multicalibrated implemented by a circuit of size O(s/α4γ).",3. Learning Multicalibrated Predictors,[0],[0]
"In fact, we prove Theorem 1 algorithmically by learning (C, α)-multicalibrated predictors from labeled samples.",3.1. The Algorithm,[0],[0]
Our algorithm is an iterative procedure.,3.1. The Algorithm,[0],[0]
"At a high level, the algorithm maintains a candidate predictor f , and at each iteration, corrects the candidate values of some subset that violates calibration until the candidate predictor is α-calibrated on every S ∈ C.",3.1. The Algorithm,[0],[0]
"We show that even if C is very large (e.g. exponential in the other relevant parameters), the number of updates we make and thus, the complexity of the learned model is bounded (polynomially in 1/α, 1/γ).
",3.1. The Algorithm,[0],[0]
"Recall that calibration over a set S requires that on the subsets Sv = {i ∈ S : fi = v} (which we will refer to throughout as categories), the expected value of the true probabilities Ei∼Sv [p∗i ] on this set is close to v. As such, the algorithm is easiest to describe in the statistical query model, where we query for estimates of the true statistics on subsets of the population and update the predictor based on these estimates.",3.1. The Algorithm,[0],[0]
"In particular, given a statistical query oracle that guarantees tolerance ω = O(αγ), the estimates will be accurate enough to guarantee α-calibration on sets S with such that Pri∼D[i ∈ S] ≥ γ.
",3.1. The Algorithm,[0],[0]
Adaptive Generalization.,3.1. The Algorithm,[0],[0]
"When we turn to adapting the algorithm to learn from random samples, the algorithm answers these statistical queries using the empirical estimates on some random sample from the population.",3.1. The Algorithm,[0],[0]
"Standard uniform convergence arguments (Kearns & Vazirani, 1994) show that if the set of queries we might ask is fixed in advance, then we could bound the sample complexity needed to answer these non-adaptive queries as Õ(log |C|/ω2).",3.1. The Algorithm,[0],[0]
"Note, however, that the categories Sv whose expectations we query are selected adaptively (i.e. with dependence on the results of prior queries).",3.1. The Algorithm,[0],[0]
"In particular, the definition of the categories Sv depends on the current values of the predictor f ; thus, when we update f based on the result of a statistical query, the set of categories on which we might ask a statistical query changes.",3.1. The Algorithm,[0],[0]
"In this case, we cannot simply apply concentration inequalities and take a union bound to guarantee good generalization without resampling every time we update the predictor.
",3.1. The Algorithm,[0],[0]
"To avoid this blow-up in sample complexity, we appeal to recently-uncovered connections between differential privacy and adaptive data analysis developed in (Dwork et al., 2015a;b;c; Bassily et al., 2016).",3.1. The Algorithm,[0],[0]
"To answer the statistical queries, our algorithm deliberately interacts with the data through a so-called guess-and-check oracle.",3.1. The Algorithm,[0],[0]
"In particular, each time the algorithm needs to know the value of a statistical query on a set S, rather than asking the query directly, we require that the algorithm submit its current guess fS = Ei∼S",3.1. The Algorithm,[0],[0]
"[fi] to the oracle, as well as an acceptable relative error window ω ∈",3.1. The Algorithm,[0],[0]
"[0, 1].",3.1. The Algorithm,[0],[0]
"Intuitively, if the algorithm’s guess is far from the window centered around the true expectation, then the oracle will respond with the answer to a statistical query with tolerance α ·Pri∼D[i ∈ S].",3.1. The Algorithm,[0],[0]
"If, however, the guess is sufficiently close to the true value, then the oracle responds with X to indicate that the current guess is close to the expectation, without revealing another answer.",3.1. The Algorithm,[0],[0]
Definition (Guess-and-check oracle).,3.1. The Algorithm,[0],[0]
Let q̃ : 2X ×,3.1. The Algorithm,[0],[0]
"[0, 1]× [0, 1] → [0, 1] ∪ {X}.",3.1. The Algorithm,[0],[0]
"q̃ is a guess-and-check oracle if for S ⊆ X with pS = Ei∼S [p∗i ], v ∈",3.1. The Algorithm,[0],[0]
"[0, 1], and any α > 0, the response to q̃(S, v, ω) satisfies the following conditions:
• if |pS",3.1. The Algorithm,[0],[0]
"− v| < 2ω, then q̃(S, v, ω) = X
• if |pS",3.1. The Algorithm,[0],[0]
"− v| > 4ω, then q̃(S, v, ω) ∈",3.1. The Algorithm,[0],[0]
"[0, 1]
• if q̃(S, v, ω) 6=",3.1. The Algorithm,[0],[0]
"X, then
pS − ω ≤ q̃(S, v, ω) ≤ pS + ω.
",3.1. The Algorithm,[0],[0]
Note that if the guess is such that |pS,3.1. The Algorithm,[0],[0]
− v| ∈,3.1. The Algorithm,[0],[0]
"[2ω, 4ω], the the oracle may respond with some ω-accurate r ∈",3.1. The Algorithm,[0],[0]
"[0, 1] or with X.",3.1. The Algorithm,[0],[0]
"If we have a lower bound ω0 = Pri∼D[i ∈ S] ·ω on a sequence of guess-and-check queries, we can implement the queries using a statistical query oracle with tolerance τ ≤ ω0; the advantage of using this guess-and-check framework is that it can be implemented using tools developed for differential privacy (Hardt & Rothblum, 2010).",3.1. The Algorithm,[0],[0]
"This will in turn allow us to give an algorithm for learning (C, α)multicalibrated predictors from a small number of samples that generalizes well.
",3.1. The Algorithm,[0],[0]
"With the definition of this mechanism in place, we give a description of the procedure in Algorithm 1.
",3.1. The Algorithm,[0],[0]
Implicit Representation of C. While this procedure will work for any collection C for efficiency’s sake (in the algorithm and the learned predictor),3.1. The Algorithm,[0],[0]
", it is important that we have some implicit representation of S ∈ C – i.e. membership tests can be evaluated by a simple model like a decision tree, neural network, etc.",3.1. The Algorithm,[0],[0]
"In particular, even though the algorithm updates the predictions for all i ∈ X , this update can be done implicitly by stringing together a “circuit” that tests membership, followed by the appropriate addition if the individual passes the test.
",3.1. The Algorithm,[0],[0]
"Algorithm 1 – Learning a (C, α)-multicalibrated predictor Let α, λ > 0 and let C ⊆ 2X .",3.1. The Algorithm,[0],[0]
"Let q̃(·, ·, ·) be a guess-and-check oracle.
",3.1. The Algorithm,[0],[0]
"• Initialize: f = (1/2, . . .",3.1. The Algorithm,[0],[0]
", 1/2) ∈",3.1. The Algorithm,[0],[0]
"[0, 1]X
• Repeat: ◦",3.1. The Algorithm,[0],[0]
"For each S ∈ C and v ∈ Λ[0, 1]:
– Let Sv = S ∩ {i : fi ∈ λ(v)} – if Pri∼D[i ∈",3.1. The Algorithm,[0],[0]
Sv] < αλ · Pri∼D[i ∈,3.1. The Algorithm,[0],[0]
"S]:
continue – Let v̄ = Ei∼Sv [fi] – Let r = q̃(Sv, v̄, α/4) –",3.1. The Algorithm,[0],[0]
"If r 6= X:
update fi ← fi + (r − v̄) for all i ∈",3.1. The Algorithm,[0],[0]
"Sv (project onto [0, 1] if necessary)
◦",3.1. The Algorithm,[0],[0]
"If no Sv updated: exit
• For v ∈ Λ[0, 1]: ◦ Let v̄ = Ei∼λ(v)[fi] ◦",3.1. The Algorithm,[0],[0]
"For i ∈ λ(v): fi ← v̄
• Output f
Formally, we prove the following theorem.
",3.1. The Algorithm,[0],[0]
Theorem 2.,3.1. The Algorithm,[0],[0]
"Suppose C ⊆ 2X is collection of sets such that for all S ∈ C, Pri∼D[i ∈",3.1. The Algorithm,[0],[0]
"S] ≥ γ, and suppose set membership can be evaluated in time t. Then Algorithm 1 run with λ = α learns a predictor of f :",3.1. The Algorithm,[0],[0]
X,3.1. The Algorithm,[0],[0]
"→ [0, 1] that is (C, 2α)-multicalibrated for p∗ from O(log(|C|)/α11/2γ3/2) samples in time O(|C| · t · poly(1/α, 1/γ)).",3.1. The Algorithm,[0],[0]
"Observing the linear dependence in the running time on |C|, it is natural to try to develop a learning procedure with subpolynomial, or even polylogarithmic, dependence on |C|.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
Our next results aim to characterize when this optimistic goal is possible – and when it is not.,4. Multicalibration and Weak Agnostic Learning,[0],[0]
We emphasize that the algorithm of Theorem 2 learns a multicalibrated predictor for arbitrary p∗ : X,4. Multicalibration and Weak Agnostic Learning,[0],[0]
"→ [0, 1] and C. In the setting where we cannot exploit structure in p∗ to learn efficiently, we might hope to exploit structure, if it exists, in the collection of subsets C.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Indeed, we demonstrate a connection between our goal of learning a multicalibrated predictor and weak agnostic learning, introduced in the literature on agnostic boosting (Ben-David et al., 2001; Kalai et al., 2008; Kanade & Kalai, 2009; Feldman, 2010).",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"More formally, we require a (ρ, τ)-weak agnostic learner as in (Kalai et al., 2008; Feldman, 2010).",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"We describe the distribution-specific learner of
(Feldman, 2010), where the samples and inner product in the definition are taken over the fixed data distribution D. Definition (Weak agnostic learner).",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Let ρ ≥ τ > 0, C ⊆ 2X , and H ⊆",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"[−1, 1]X .",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"A (ρ, τ)-weak agnostic learner L for a concept class C with hypothesis class H solves the following promise problem: given a collection of labeled samples {(i, yi)} where i ∼ D and yi ∈",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"[−1, 1], if there is some c ∈ C such that Ei∼D[ci · yi] > ρ, then L returns some h ∈ H such that Ei∼D[hi · yi] > τ .
",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Intuitively, if there is a concept c ∈ C that correlates nontrivially with the observed labels, then the weak agnostic learner returns a hypothesis h (not necessarily from C), that is also nontrivially correlated with the observed labels.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"In particular, ρ and τ are typically taken to be ρ = 1/p(d) and τ = 1/q(d) for polynomials p(d) ≤ q(d), where d = log(|C|).
",4. Multicalibration and Weak Agnostic Learning,[0],[0]
Efficient Multicalibration from Agnostic Learning.,4. Multicalibration and Weak Agnostic Learning,[0],[0]
Our next result shows that efficient weak agnostic learning over C implies efficient learning of α-multicalibrated predictors on C. Theorem 3.,4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Let ρ, τ > 0 and C ⊆ 2X be some concept class.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"If C admits a (ρ, τ)-weak agnostic learner that runs in time T (|C| , ρ, τ), then there is an algorithm that learns a predictor that is (C, α)-multicalibrated on C′ = {S ∈ C : Pri∼D[i ∈",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"S] ≥ γ} in time O(T (|C| , ρ, τ) · poly(1/α, 1/λ, 1/γ)) as long as ρ ≤ α2λγ/2 and τ = poly(α, λ, γ).
",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Recall, in our algorithm for learning multicalibrated predictors, we maintain a candidate predictor f , and iteratively search for some set S ∈ C on which f is not calibrated.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"To solve this search problem more quickly, we frame the search as weak agnostic learning over a concept class derived from C and over the hypothesis class ofH = {h : X",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"→ [−1, 1]}.
Specifically, consider the concept class defined by the collection of subsets C, where for each S ∈ C, we include the concept cS :",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"X → {−1, 1} where cS(i) = 1 if and only if i ∈ S.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
We show how to design a “labeling” ` : X,4. Multicalibration and Weak Agnostic Learning,[0],[0]
"→ [−1, 1] for individuals such that if f violates the calibration constraint on any S ∈ C, then the concept cS correlates nontrivially with the labels over the distribution of individuals, i.e. 〈cS , `〉 ≥ ρ for some ρ > 0.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Specifically, we will consider for each v ∈ Λ[0, 1], the following learning problem.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"For i ∈ Xv, let `i = fi−oi2 .",4. Multicalibration and Weak Agnostic Learning,[0],[0]
For i ∈ X \,4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Xv, let `i = 0.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"We claim that if there is some Sv currently in violation of multicalibration, then for i ∼ D, the labeled samples of either (i, `i) or (i,−`i) satisfy the weak learning promise for ρ = αβ/2.
",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Thus, if f is not yet multicalibrated on C, then we are promised that there is some concept cS with nontrivial correlation with the labels; we observe that this promise is
exactly the requirement for a weak agnostic learner, as defined in (Kalai et al., 2008; Feldman, 2010).",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"In particular, given labeled samples (i, `(i)) sampled according to D, if there is a concept cS with correlation at least ρ with `, then the weak agnostic learner returns a hypothesis h that is τ correlated with ` for some τ",4. Multicalibration and Weak Agnostic Learning,[0],[0]
< ρ.,4. Multicalibration and Weak Agnostic Learning,[0],[0]
"The catch is that this hypothesis may not be in our concept class C, so we cannot directly “correct” any S ∈ C.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Nevertheless, the labeling on individuals ` is designed such that given the hypothesis h, we can still extract an update to f that will make global progress towards the goal of attaining calibration.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"As long as τ is nontrvially lower bounded, we can upper bound the number of calls we need to make to the weak learner.
",4. Multicalibration and Weak Agnostic Learning,[0],[0]
Efficient Agnostic Learning from Multicalibration.,4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Our results so far show that under the right structural assumptions on p∗ or on C, a multicalibrated predictor may be learned more efficiently than our upper bound for the general case.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Returning to the general case, we may wonder if these structural assumptions are necessary; we answer this question in the positive.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
We show that for worst-case p∗ learning a multicalibrated predictor on C is as hard as weak agnostic learning for the class C. Theorem 4.,4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Let α, γ > 0",4. Multicalibration and Weak Agnostic Learning,[0],[0]
and suppose C ⊆ 2X is a concept class.,4. Multicalibration and Weak Agnostic Learning,[0],[0]
"If there is an algorithm for learning a (C′, α)-multicalibrated predictor on C′ = {S ∈ C : Pri∼D[i ∈ S] ≥ γ} in time T (|C| , α, γ) then we can implement a (ρ, τ)-weak agnostic learner for C in time O(T (|C| , α, γ) · poly(1/τ)) for any ρ, τ > 0",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"such that τ ≤ min {ρ− 2γ, ρ/4− 4α}.
",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Specifically, we show how to implement a weak agnostic learner for C, given an algorithm to learn an αmulticalibrated predictor f with respect to C (in fact, we only need the predictor to be multicalibrated on C′ = {S ∈ C : Pri∼D[i ∈",4. Multicalibration and Weak Agnostic Learning,[0],[0]
S] ≥ γ}).,4. Multicalibration and Weak Agnostic Learning,[0],[0]
"The key lemma for this reduction says that if there is some c ∈ C that is nontrivially correlated with the labels, then f is also nontrivially correlated with c. In general, agnostic learning is considered a notoriously hard computational problem.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"In particular, under cryptographic assumptions (Valiant, 1984; Goldreich et al., 1984; Bogdanov & Rosen, 2017), this result implies that there is some constant t > 0, such that any algorithm that learns a (C, α)-multicalibrated predictor requires Ω(|C|t) time for arbitrary C.
In combination, these results show that the complexity of learning a multicalibrated predictor with respect to a class C is equivalent to the complexity of weak agnostic learning C.",4. Multicalibration and Weak Agnostic Learning,[0],[0]
"Finally, we return our attention to investigating the utility of multicalibrated predictors.",5. Best-in-class Predictions,[0],[0]
"Above, we have argued that multicalibration provides a strong protection of groups against
discrimination.",5. Best-in-class Predictions,[0],[0]
We show that this protection comes at (next to) no cost in the utility of the predictor.,5. Best-in-class Predictions,[0],[0]
"This result adds to the growing literature on fairness-accuracy trade-offs (Fish et al., 2016; Berk et al., 2017; Chouldechova & G’Sell, 2017).
",5. Best-in-class Predictions,[0],[0]
Theorem 5.,5. Best-in-class Predictions,[0],[0]
Suppose C ⊆ 2X is a collection of subsets of X andH is a set of predictors.,5. Best-in-class Predictions,[0],[0]
"There is a predictor f that is α-multicalibrated on C such that
E i∼X",5. Best-in-class Predictions,[0],[0]
"[(fi − p∗i )2]− E i∼X [(h∗i − p∗i )2] < 6α,
where h∗ = argminh∈H Ei∼X",5. Best-in-class Predictions,[0],[0]
[(h−p∗)2].,5. Best-in-class Predictions,[0],[0]
"Further, suppose that for all S ∈ C, Pri∼D[i ∈ S] ≥ γ, and suppose that set membership for S ∈ C and h ∈ H are computable by circuits of size at most s; then f is computable by a circuit of size at most O(s/α4γ).
",5. Best-in-class Predictions,[0],[0]
"We can interpret Theorem 5 in different ways based on the choice ofH. Suppose there is some sophisticated learning algorithm that produces some predictor h that obtains exceptional performance, but may violate calibration arbitrarily.",5. Best-in-class Predictions,[0],[0]
"If we take H = {h}, then this result says: enforcing calibration on h after learning does not hurt the accuracy by much.
",5. Best-in-class Predictions,[0],[0]
"Taking a different perspective, we can also think ofH as a set of predictors that, say, are implemented by a circuit class of bounded complexity (e.g. conjunctions of k variables, halfspaces, circuits of size s).",5. Best-in-class Predictions,[0],[0]
"Leveraging Theorem 1 and Theorem 2, this theorem shows that for any such class of predictorsH of bounded complexity, there exists a multicalibrated predictor with similar complexity that performs as well as",5. Best-in-class Predictions,[0],[0]
the best h∗ ∈ H.,5. Best-in-class Predictions,[0],[0]
"In this sense, with just a slight overhead in complexity, multicalibrated predictors can achieve “best-in-class” predictions.
",5. Best-in-class Predictions,[0],[0]
"In contrast to many other notions of fairness, multicalibration does not limit the utility of a predictor.",5. Best-in-class Predictions,[0],[0]
"Further, to prove that multicalibration does not negatively impact the utility, we in fact, show a much stronger statement: if applying multicalibration to some h ∈ H changes the predictions of h significantly (i.e. if Ei∼D[(fi",5. Best-in-class Predictions,[0],[0]
"− hi)2] is large), then this change represents an improvement in squared error.",5. Best-in-class Predictions,[0],[0]
"In this sense, requiring multicalibration is aligned with the goals of learning a high-utility predictor.
",5. Best-in-class Predictions,[0],[0]
We give a flavor of our approach to proving Theorem 5.,5. Best-in-class Predictions,[0],[0]
"Consider some h ∈ H and consider the partition of X into sets according to the predictions of h – in particular, we will first apply a λ-discretization to the range of each h to partition X into categories.",5. Best-in-class Predictions,[0],[0]
"That is, let Sv(h) =",5. Best-in-class Predictions,[0],[0]
"{i : hi ∈ λ(v)}, and note that Sv(h) is disjoint from Sv′(h) for v 6= v′, and ⋃ v∈Λ[0,1] Sv(h) = X .",5. Best-in-class Predictions,[0],[0]
"In addition to calibrating with respect to S ∈ C, we can also ask for calibration on Sv(h) for all h ∈ H and v ∈ Λ[0, 1].",5. Best-in-class Predictions,[0],[0]
"Specifically, let S(H) = {Sv(h)}h∈H,v∈Λ[0,1]; we consider imposing cali-
bration on C∪S(H).",5. Best-in-class Predictions,[0],[0]
"Calibrating in this manner protects the groups defined by C but additionally gives a strong utility guarantee, captured by the following lemma.
",5. Best-in-class Predictions,[0],[0]
Lemma.,5. Best-in-class Predictions,[0],[0]
"Suppose g is a λ-discretized predictor and let S(g) = {Sv(g)}v∈Λ[0,1].",5. Best-in-class Predictions,[0],[0]
"Suppose f is an arbitrary (S(g), α)-multicalibrated predictor.",5. Best-in-class Predictions,[0],[0]
"Then for v ∈ Λ[0, 1],
E i∼Sv(g)
",5. Best-in-class Predictions,[0],[0]
"[ (gi − fi)2 ] − (4α+ λ)
≤ E i∼Sv(g)
[ (gi − p∗i )2 ]",5. Best-in-class Predictions,[0],[0]
"− E i∼Sv(g) [ (fi − p∗i )2 ] .
",5. Best-in-class Predictions,[0],[0]
"This lemma shows that calibrating on the categories of a predictor not only prevents the squared prediction error from degrading beyond a small additive approximation, but it also guarantees that if calibrating changes the predictor significantly on any category, this change represents significant progress towards the true underlying probabilities on this category.",5. Best-in-class Predictions,[0],[0]
"Assuming Lemma 5, Theorem 5 follows.
",5. Best-in-class Predictions,[0],[0]
"Note that Lemma 5 shows that this best-in-class property holds not just over the entire domain X , but on every sufficiently large category Sv(h) identified by some h ∈ H. That is, if f is calibrated on S(H), then for every category Sv(h), the average squared prediction error Ei∼Sv(h)",5. Best-in-class Predictions,[0],[0]
[ (fi − p∗i )2 ] will be at most 6α worse than prediction given by h on this set.,5. Best-in-class Predictions,[0],[0]
"If we view H as defining a set S(H) of “computationally-identifiable” categories, then we can view any predictor that is calibrated on S(H) as at least as fair and at least as accurate on this set of computationallyidentifiable categories as the predictor that identified the group (up to some small additive approximation).",5. Best-in-class Predictions,[0],[0]
Calibration.,6. Related Works and Discussion,[0],[0]
"Calibration is a well-studied concept in the literature on statistics and econometrics, particularly forecasting.",6. Related Works and Discussion,[0],[0]
"For a background on calibration in this context, see (Sandroni et al., 2003; Foster & Hart, 2015) and the references therein.",6. Related Works and Discussion,[0],[0]
"Calibration has also been studied in the context of structured predictions where the supported set of predictions is large (Kuleshov & Liang, 2015).",6. Related Works and Discussion,[0],[0]
"Our algorithmic result for multicalibration bears similarity to works from the online learning literature (Blum & Mansour, 2007; Khot & Ponnuswami, 2008; Trevisan et al., 2009).",6. Related Works and Discussion,[0],[0]
"While these works are similar in spirit, none of the algorithmic results apply directly to our setting of multicalibration.",6. Related Works and Discussion,[0],[0]
"We are unaware of prior works drawing connections between calibration and differential privacy / adaptive data analysis.
",6. Related Works and Discussion,[0],[0]
Parity and Balance.,6. Related Works and Discussion,[0],[0]
Other works on fairness in classification tend to look at parity-based notions of fairness.,6. Related Works and Discussion,[0],[0]
"Specifically, the notion of statistical parity (Dwork et al., 2012) and balanced error rates (Hardt et al., 2016) aim to enforce some notion of equal treatment across groups of
individuals defined by sensitive features, like race, gender, etc.",6. Related Works and Discussion,[0],[0]
"In (Hardt et al., 2016)",6. Related Works and Discussion,[0],[0]
"it is shown how to obtain equalized odds, a definition related to error-rate balance, as a post-processing step of “correcting” any predictor.
",6. Related Works and Discussion,[0],[0]
"While both calibration and balance (as well as other related variants) intuitively seem like good properties to expect in a fair predictor (even if they are a bit weak), it is impossible to satisfy both notions simultaneously (in non-degenerate cases) (Kleinberg et al., 2017; Chouldechova, 2017; Pleiss et al., 2017), and there is much debate about how to proceed given this incompatibility (Corbett-Davies et al., 2017).",6. Related Works and Discussion,[0],[0]
"The inherent conflict between balance and calibration, combined with our observation that calibration is always aligned with the goal of accurate high-utility predictions, implies that at times, balance must be at odds with obtaining predictive utility.",6. Related Works and Discussion,[0],[0]
"In this work, we strengthen the protections implied by calibration, rather than enforcing error-rate balance.",6. Related Works and Discussion,[0],[0]
"While there are certainly contexts in which “equalizing the odds” across groups is a good idea, there are also contexts where calibration is a more appropriate notion of fairness.
",6. Related Works and Discussion,[0],[0]
"One particular critique of balanced error rates as a fairness notion is that given two populations S, T ⊆ X with different base rates (i.e. p∗i > p ∗ j for i ∈ S, j ∈ T ), the Bayes Optimal predictor p∗ will not be balanced.",6. Related Works and Discussion,[0],[0]
"That is, even given access to perfect information about the underlying probabilities, the stochasticity in the outcomes will lead to different false positive and false negative rates.",6. Related Works and Discussion,[0],[0]
"In this sense, balance can be viewed as an a posteriori notion of fairness (fairness with respect to outcomes), while our notion of multicalibration is an a priori notion of fairness (fairness with respect to given data).",6. Related Works and Discussion,[0],[0]
"In a prediction setting where, given the data, there is still significant uncertainty in the outcome, we feel that multicalibration should be considered as an alternative to balanced error rates.",6. Related Works and Discussion,[0],[0]
"That said, a serious form of discrimination could arise if the uncertainty in outcomes is very different across different subpopulations; this would be a form of information-theoretic discrimination that multicalibration could help to identify, but could not remedy directly.
Between Populations and Individuals.",6. Related Works and Discussion,[0],[0]
"Most fairness notions are statistical in nature; roughly, these definitions – including statistical parity (Dwork et al., 2012), balanced error-rates (Hardt et al., 2016), and calibration – say that treatment across groups should be equitable on-average (for different notions equitable).",6. Related Works and Discussion,[0],[0]
"In a notable work, (Dwork et al., 2012) critique these broad-strokes statistical definitions and propose an individual notion of fairness, which aims to “treat similar individuals similarly”.",6. Related Works and Discussion,[0],[0]
A key challenge to this approach is that it assumes access to a taskspecific metric for every pair of individuals.,6. Related Works and Discussion,[0],[0]
"In the practical setting, where we want to learn from a small sample, we cannot hope to achieve such an information-theoretic notion
of fairness.",6. Related Works and Discussion,[0],[0]
One can view multicalibration as a meaningful compromise between group fairness (satisfying calibration) and individual-calibration (closely matching p∗i ).,6. Related Works and Discussion,[0],[0]
"The multicalibration framework presented in this work inspired subsequent work investigating how to interpolate between statistical and individual notions of “metric fairness” for general similarity metrics (Kim et al., 2018b), as well as further theoretical and empirical investigations of multi-accuracyin-expectation in the context of binary classification (Kim et al., 2018a).
",6. Related Works and Discussion,[0],[0]
"Contemporary independent work of (Kearns et al., 2017) also investigates strengthening the guarantees of notions of group fairness by requiring that these properties hold for a much richer collection of sets.",6. Related Works and Discussion,[0],[0]
"Unlike our work, their definitions require balance or statistical parity on these collection of sets.",6. Related Works and Discussion,[0],[0]
"Despite similar motivations, the two approaches to subgroup fairness differ in substantial ways.",6. Related Works and Discussion,[0],[0]
"As a concrete example, multicalibration is aligned with the incentives of achieving high-utility predictors; this is not necessarily the case with balance-based notions of fairness.",6. Related Works and Discussion,[0],[0]
"Indeed, in the setting considered in this work, one of the motivations for multicalibration is the earlier critique of balance that may only be heightened when considering “multi-balance”.
",6. Related Works and Discussion,[0],[0]
"Consider the example from (Dwork et al., 2012) where we wish to predict future success in school.",6. Related Works and Discussion,[0],[0]
"In a population S, the strongest students apply to Engineering whereas in the general population T , they apply to Business.",6. Related Works and Discussion,[0],[0]
Enforcing balance between the Business applicants and Engineering applicants within both groups would be unfair to qualified applicants in both groups (i.e. the Engineering students of S and the Business students of T ).,6. Related Works and Discussion,[0],[0]
"Essentially, carving up the space of individuals into subgroups exaggerates the differences in the base rates, which leads to mistreatment.",6. Related Works and Discussion,[0],[0]
"Preventing discrimination by algorithms is subtle, and different scenarios will call for different notions of protection.",6. Related Works and Discussion,[0],[0]
"Still, these works collectively validate the need to investigate attainable approaches to mitigating discrimination beyond large protected groups.
",6. Related Works and Discussion,[0],[0]
"Corrective Discrimination Multicalibration represents a powerful tool to address a certain form of discrimination, but it is not universally-applicable.",6. Related Works and Discussion,[0],[0]
"Consider the mortgage example again: perhaps the number of members of S that received loans in the past is small (and thus there are too few examples for fine-grained learning within S); perhaps the attributes are too limited to identify the qualified members of S (taking this point to the extreme, perhaps the only available attribute is membership in S).",6. Related Works and Discussion,[0],[0]
"In these cases, the data may be insufficient for multicalibration to provide meaningful guarantees.",6. Related Works and Discussion,[0],[0]
"Further, even if the algorithm was given access to unlimited rich data such that refined values of p∗ could be recovered, there are situations where preferential treatment may be in order: after all, the salaries of
members of S may be lower due to historical discrimination.",6. Related Works and Discussion,[0],[0]
"For these reasons, the concern that balance is inconsistent with p∗ could be answered with: “yes, and purposely so!”",6. Related Works and Discussion,[0],[0]
"Indeed, (Hardt et al., 2016) promotes enforcing a equalized odds as a form of “corrective discrimination.”",6. Related Works and Discussion,[0],[0]
"While this type of advocacy is important in many settings, multicalibration represents a different addition to the quiver of anti-discrimination measures, which we also believe is natural and desirable in many settings.
",6. Related Works and Discussion,[0],[0]
"Consider another example where multicalibration is appropriate, but equalizing error rates might not be: suppose a genomics company offers individuals a prediction of their likelihood of developing certain genetic disorders.",6. Related Works and Discussion,[0],[0]
"These disorders have different rates across different populations; e.g., Tay-Sachs disease is rare in the general population, but occurs much more frequently in the Ashkenazi population.",6. Related Works and Discussion,[0],[0]
We certainly do not want to enforce balance on the Ashkenazi population by down-weighting the prediction that individuals would have Tay-Sachs (as they are endogenously more likely to have the disease).,6. Related Works and Discussion,[0],[0]
"However, we also don’t want the company to base its prediction solely on the Ashkenazi feature.",6. Related Works and Discussion,[0],[0]
"Instead, enforcing multicalibration would require that the learning algorithm investigate both the Ashkenazi and non-Ashkenazi population to predict accurately in each group (even if this means a higher false positive rate in the Ashkenazi population).",6. Related Works and Discussion,[0],[0]
"In this case, relying on p∗ seems to be well-aligned with promoting fairness.
",6. Related Works and Discussion,[0],[0]
Conclusion.,6. Related Works and Discussion,[0],[0]
Multicalibration addresses a specific form of discrimination that can occur in prediction systems learned from data.,6. Related Works and Discussion,[0],[0]
"In particular, multicalibration requires that the learned predictor accurately reflects the “computationallyidentifiable” variance present in the data, without introducing spurious variance.",6. Related Works and Discussion,[0],[0]
"Multicalibration is most appropriate in settings where perfect predictions at an individual level are considered the fairest predictions, but where we do not have rich enough training data to make perfect predictions.",6. Related Works and Discussion,[0],[0]
"Importantly, in this context, there is no fairness-utility tradeoff!",6. Related Works and Discussion,[0],[0]
Enforcing multicalibration only improves the predictive power of the resulting model.,6. Related Works and Discussion,[0],[0]
"Instead, this work identifies and aims to address a “fairness-information” tradeoff; while we cannot achieve the information-theoretic ideal predictions from a small sample of training data, we show that attaining a meaningful complexity-theoretic relaxation of this goal is feasible through multicalibration.",6. Related Works and Discussion,[0],[0]
"Finally, we consider the interplay between multicalibration and “corrective discrimination,” such as the transformation of (Hardt et al., 2016), to be an important direction for further research.",6. Related Works and Discussion,[0],[0]
"The authors thank Cynthia Dwork, Roy Frostig, Parikshit Gopalan, Moritz Hardt, Aditi Raghunathan, Jacob Steinhardt, and Greg Valiant for helpful discussions related to this work.",Acknowledgments,[0],[0]
We thank the anonymous reviewers for their detailed feedback.,Acknowledgments,[0],[0]
MPK was supported by NSF grant CNS122864.,Acknowledgments,[0],[0]
OR was supported by NSF grant CCF-1749750.,Acknowledgments,[0],[0]
GNR was supported by ISF grant No. 5219/17.,Acknowledgments,[0],[0]
We develop and study multicalibration as a new measure of fairness in machine learning that aims to mitigate inadvertent or malicious discrimination that is introduced at training time (even from ground truth data).,abstractText,[0],[0]
Multicalibration guarantees meaningful (calibrated) predictions for every subpopulation that can be identified within a specified class of computations.,abstractText,[0],[0]
"The specified class can be quite rich; in particular, it can contain many overlapping subgroups of a protected group.",abstractText,[0],[0]
We demonstrate that in many settings this strong notion of protection from discrimination is provably attainable and aligned with the goal of accurate predictions.,abstractText,[0],[0]
"Along the way, we present algorithms for learning a multicalibrated predictor, study the computational complexity of this task, and illustrate tight connections to the agnostic learning model.",abstractText,[0],[0]
Multicalibration: Calibration for the (Computationally-Identifiable) Masses,title,[0],[0]
"Existing automatic speech recognition (ASR) systems are based on a complicated hybrid of separate components, including acoustic, phonetic, and language models (Jelinek, 1976).",1. Introduction,[0],[0]
"Such systems are typically based on deep neural network acoustic models combined with hidden Markov models to represent the language and phonetic contextdependent state and their temporal alignment with the acoustic signal (DNN-HMM) (Bourlard & Morgan, 1994; Hinton et al., 2012).",1. Introduction,[0],[0]
"As a simpler alternative, end-to-end speech recognition paradigm has attracted great research
interest (Chorowski et al., 2014; 2015; Chan et al., 2016; Graves & Jaitly, 2014; Miao et al., 2015).",1. Introduction,[0],[0]
This paradigm simplifies the above hybrid architecture by subsuming it into a single neural network.,1. Introduction,[0],[0]
"Specifically, an attentionbased encoder-decoder framework (Chorowski et al., 2014) integrates all of those components using a set of recurrent neural networks (RNN), which map from acoustic feature sequences to character label sequences.
",1. Introduction,[0],[0]
"However, existing end-to-end frameworks have focused on clean speech, and do not include speech enhancement, which is essential to good performance in noisy environments.",1. Introduction,[0],[0]
"For example, recent industrial applications (e.g., Amazon echo) and benchmark studies (Barker et al., 2016; Kinoshita et al., 2016) show that multichannel speech enhancement techniques, using beamforming methods, produce substantial improvements as a pre-processor for conventional hybrid systems, in the presence of strong background noise.",1. Introduction,[0],[0]
"In light of the above trends, this paper extends the existing attention-based encoder-decoder framework by integrating multichannel speech enhancement.",1. Introduction,[0],[0]
"Our proposed multichannel end-to-end speech recognition framework is trained to directly translate from multichannel acoustic signals to text.
",1. Introduction,[0],[0]
"A key concept of the multichannel end-to-end framework is to optimize the entire inference procedure, including the beamforming, based on the final ASR objectives, such as word/character error rate (WER/CER).",1. Introduction,[0],[0]
"Traditionally, beamforming techniques such as delay-and-sum and filterand-sum are optimized based on a signal-level loss function, independently of speech recognition task (Benesty et al., 2008; Van Veen & Buckley, 1988).",1. Introduction,[0],[0]
"Their use in ASR requires ad-hoc modifications such as Wiener post-filtering or distortionless constraints, as well as steering mechanisms determine a look direction to focus the beamformer on the target speech (Wölfel & McDonough, 2009).",1. Introduction,[0],[0]
"In contrast, our framework incorporates recently proposed neural beamforming mechanisms as a differentiable component to allow joint optimization of the multichannel speech
ar X
iv :1
70 3.
04 78
3v 1
[ cs
.S",1. Introduction,[0],[0]
"D
] 1
4 M
ar 2
enhancement within the end-to-end system to improve the ASR objective.
",1. Introduction,[0],[0]
"Recent studies on neural beamformers can be categorized into two types: (1) beamformers with a filter estimation network (Xiao et al., 2016a; Li et al., 2016) and (2) beamformers with a mask estimation network (Heymann et al., 2016; Erdogan et al., 2016).",1. Introduction,[0],[0]
Both methods obtain an enhanced signal based on the formalization of the conventional filter-and-sum beamformer in the time-frequency domain.,1. Introduction,[0],[0]
The main difference between them is how the multichannel filters are produced by the neural network.,1. Introduction,[0],[0]
"In the former approach, the multichannel filter coefficients are direct outputs of the network.",1. Introduction,[0],[0]
"In the latter approach, a network first estimates time-frequency masks, which are used to compute expected speech and noise statistics.",1. Introduction,[0],[0]
"Then, using these statistics, the filter coefficients are computed based on the well-known MVDR (minimum variance distortionless response) formalization (Capon, 1969).",1. Introduction,[0],[0]
"In both approaches, the estimated filter coefficients are then applied to the multichannel noisy signal to enhance the speech signal.",1. Introduction,[0],[0]
"Note that the mask estimation approach has the advantage of leveraging well-known techniques, but it requires parallel data composed of aligned clean and noisy speech, which are usually difficult to obtain without data simulation.
",1. Introduction,[0],[0]
"Recently, it has been reported that the mask estimationbased approaches (Yoshioka et al., 2015; Heymann et al., 2016; Erdogan et al., 2016) achieve great performance in noisy speech recognition benchmarks (e.g., CHiME 3 and 4 challenges)1.",1. Introduction,[0],[0]
"Although this paper proposes to incorporate both mask and filter estimation approaches in an endto-end framework, motivated by those successes, we focus more on the mask estimation, implementing it along with the MVDR estimation as a differentiable network.",1. Introduction,[0],[0]
Our MVDR formulation estimates the speech image at the reference microphone and includes selection of the reference microphone using an attention mechanism.,1. Introduction,[0],[0]
"By using channel-independent mask estimation along with this reference selection, the model can generalize to different microphone array geometries (number of channels, microphone locations, and ordering), unlike the filter estimation approach.",1. Introduction,[0],[0]
"Finally, because the masks are latent variables in the end-to-end training, we no longer need parallel clean and noisy speech.
",1. Introduction,[0],[0]
"The main advantages of our proposed multichannel end-toend speech recognition system are:
1.",1. Introduction,[0],[0]
"Overall inference from speech enhancement to recognition is jointly optimized for the ASR objective.
",1. Introduction,[0],[0]
"1Yoshioka et al. 2015 uses a clustering technique to perform mask estimation rather than the neural network-based techniques, but it uses the same MVDR formulation for filter estimation.
2.",1. Introduction,[0],[0]
"The trained system can be used for input signals with arbitrary number and order of channels.
3.",1. Introduction,[0],[0]
Parallel clean and noisy data are not required.,1. Introduction,[0],[0]
We can optimize the speech enhancement component with noisy signals and their transcripts.,1. Introduction,[0],[0]
"This section explains a conventional attention-based encoder-decoder framework, which is used to directly deal with variable length input and output sequences.",2. Overview of attention-based encoder-decoder networks,[0],[0]
"The framework consists of two RNNs, called encoder and decoder respectively, and an attention mechanism, which connects the encoder and decoder, as shown in Figure 1.",2. Overview of attention-based encoder-decoder networks,[0],[0]
"Given a T -length sequence of input features O = {ot ∈ RDO |t = 1, · · · , T}, the network generates an N -length sequence of output labels Y = {yn ∈ V|n = 1, · · · , N}, where ot is a DO-dimensional feature vector (e.g., log Mel filterbank) at input time step t, and yn is a label symbol (e.g., character) at output time step n in label set V .
",2. Overview of attention-based encoder-decoder networks,[0],[0]
"First, given an input sequence O, the encoder network transforms it to an L-length high-level feature sequence H = {hl ∈ RDH |l = 1, · · · , L}, where hl is a DHdimensional state vector at a time step l of encoder’s top layer.",2. Overview of attention-based encoder-decoder networks,[0],[0]
"In this work, the encoder network is composed of a bidirectional long short-term memory (BLSTM) recurrent network.",2. Overview of attention-based encoder-decoder networks,[0],[0]
"To reduce the input sequence length, we apply a subsampling technique (Bahdanau et al., 2016) to some layers.",2. Overview of attention-based encoder-decoder networks,[0],[0]
"Therefore, l represents the frame index subsampled from t and L is less than T .
",2. Overview of attention-based encoder-decoder networks,[0],[0]
"Next, the attention mechanism integrates all encoder outputs H into a DH-dimensional context vector cn ∈ RDH
based on an L-dimensional attention weight vector an ∈",2. Overview of attention-based encoder-decoder networks,[0],[0]
"[0, 1]L, which represents a soft alignment of encoder outputs at an output time step n. In this work, we adopt a location-based attention mechanism (Chorowski et al., 2015), and an and cn are formalized as follows:
",2. Overview of attention-based encoder-decoder networks,[0],[0]
"fn = F ∗ an−1, (1) kn,l = w Ttanh(VSsn + V Hhl + V Ffn,l + b), (2)
",2. Overview of attention-based encoder-decoder networks,[0],[0]
"an,l = exp(αkn,l)∑L l=1 exp(αkn,l) , cn = L∑ l=1 an,lhl, (3)
where w ∈ R1×DW , VH ∈ RDW×DH , VS ∈ RDW×DS , VF ∈ RDW×DF are trainable weight matrices, b ∈ RDW is a trainable bias vector, F ∈ RDF×1×Df is a trainable convolution filter.",2. Overview of attention-based encoder-decoder networks,[0],[0]
"sn ∈ RDS is a DS-dimensional hidden state vector obtained from an upper decoder network at n, and α is a sharpening factor (Chorowski et al., 2015).",2. Overview of attention-based encoder-decoder networks,[0],[0]
"∗ denotes the convolution operation.
",2. Overview of attention-based encoder-decoder networks,[0],[0]
"Then, the decoder network incrementally updates a hidden state sn and generates an output label yn as follows:
sn = Update(sn−1, cn−1, yn−1), (4) yn = Generate(sn, cn), (5)
where the Generate(·) and Update(·) functions are composed of a feed forward network and an LSTM-based recurrent network, respectively.
",2. Overview of attention-based encoder-decoder networks,[0],[0]
"Now, we can summarize these procedures as follows: P (Y |O) = ∏ n P (yn|O, y1:n−1), (6)
H = Encoder(O), (7) cn = Attention(an−1, sn, H), (8) yn = Decoder(cn, y1:n−1), (9)
where Encoder(·) = BLSTM(·), Attention(·) corresponds to Eqs.",2. Overview of attention-based encoder-decoder networks,[0],[0]
"(1)-(3), and Decoder(·) corresponds to Eqs.",2. Overview of attention-based encoder-decoder networks,[0],[0]
(4) and (5).,2. Overview of attention-based encoder-decoder networks,[0],[0]
"Here, special tokens for start-of-sentence (sos) and end-of-sentence (eos) are added to the label set V .",2. Overview of attention-based encoder-decoder networks,[0],[0]
The decoder starts the recurrent computation with the (sos) label and continues to generate output labels until the (eos) label is emitted.,2. Overview of attention-based encoder-decoder networks,[0],[0]
"Figure 1 illustrates such procedures.
",2. Overview of attention-based encoder-decoder networks,[0],[0]
"Based on the cross-entropy criterion, the loss function is defined using Eq.",2. Overview of attention-based encoder-decoder networks,[0],[0]
"(6) as follows:
L = − lnP (Y ∗|O) =",2. Overview of attention-based encoder-decoder networks,[0],[0]
"− ∑ n lnP (y∗n|O, y∗1:n−1), (10)
where Y ∗ is the ground truth of a whole sequence of output labels and y∗1:n−1 is the ground truth of its subsequence until an output time step n− 1.
",2. Overview of attention-based encoder-decoder networks,[0],[0]
"In this framework, the whole networks including the encoder, attention, and decoder can be optimized to generate
the correct label sequence.",2. Overview of attention-based encoder-decoder networks,[0],[0]
This consistent optimization of all relevant procedures is the main motivation of the endto-end framework.,2. Overview of attention-based encoder-decoder networks,[0],[0]
"This section explains neural beamformer techniques, which are integrated with the encoder-decoder network in the following section.",3. Neural beamformers,[0],[0]
"This paper uses frequency-domain beamformers rather than time-domain ones, which achieve significant computational complexity reduction in multichannel neural processing (Li et al., 2016; Sainath et al., 2016).",3. Neural beamformers,[0],[0]
"In the frequency domain representation, a filter-and-sum beamformer obtains an enhanced signal as follows:
x̂t,f = C∑ c=1 gt,f,cxt,f,c, (11)
where xt,f,c ∈ C is an STFT coefficient of c-th channel noisy signal at a time-frequency bin (t, f).",3. Neural beamformers,[0],[0]
"gt,f,c ∈ C is a corresponding beamforming filter coefficient.",3. Neural beamformers,[0],[0]
"x̂t,f ∈ C is an enhanced STFT coefficient, and C is the numbers of channels.
",3. Neural beamformers,[0],[0]
"In this paper, we adopt two types of neural beamformers, which basically follow Eq.",3. Neural beamformers,[0],[0]
(11); 1) filter estimation network and 2) mask estimation network.,3. Neural beamformers,[0],[0]
Figure 2 illustrates the schematic structure of each approach.,3. Neural beamformers,[0],[0]
"The main difference between them is how to compute the filter coefficient gt,f,c.",3. Neural beamformers,[0],[0]
The following subsections describe each approach.,3. Neural beamformers,[0],[0]
"The filter estimation network directly estimates a timevariant filter coefficients {gt,f,c}T,F,Ct=1,f=1,c=1 as the outputs of the network, which was originally proposed in (Li et al., 2016).",3.1. Filter estimation network approach,[0],[0]
"F is the dimension of STFT features.
",3.1. Filter estimation network approach,[0],[0]
This approach uses a single real-valued BLSTM network to predict the real and imaginary parts of the complex-valued filter coefficients at an every time step.,3.1. Filter estimation network approach,[0],[0]
"Therefore, we introduce multiple (2 × C) output layers to separately compute the real and imaginary parts of the filter coefficients for each channel.",3.1. Filter estimation network approach,[0],[0]
"Then, the network outputs time-variant filter coefficients gt,c = {gt,f,c}Ff=1 ∈ CF at a time step t for c-th channel as follows;
Z = BLSTM({x̄t}Tt=1), (12) <(gt,c) =",3.1. Filter estimation network approach,[0],[0]
"tanh(W<c zt + b<c ), (13) =(gt,c) =",3.1. Filter estimation network approach,[0],[0]
"tanh(W=c zt + b=c ), (14)
",3.1. Filter estimation network approach,[0],[0]
"where Z = {zt ∈ RDZ |t = 1, · · · , T}is a sequence of DZdimensional output vectors of the BLSTM network.",3.1. Filter estimation network approach,[0],[0]
x̄t,3.1. Filter estimation network approach,[0],[0]
"= {<(xt,f,c),=(xt,f,c)}F,Cf=1,c=1 ∈ R2FC is an input feature of a 2FC-dimensional real-value vector for the BLSTM network.",3.1. Filter estimation network approach,[0],[0]
This is obtained by concatenating the real and imaginary parts of all STFT coefficients in all channels.,3.1. Filter estimation network approach,[0],[0]
"<(gt,c) and =(gt,c) is the real and imaginary part of filter coefficients, W<c ∈ RF×DZ and W=c ∈ RF×DZ are the weight matrices of the output layer for c-th channel, and b<c ∈ RF and b=c ∈",3.1. Filter estimation network approach,[0],[0]
RF are their corresponding bias vectors.,3.1. Filter estimation network approach,[0],[0]
"Using the estimated filters gt,c, the enhanced STFT coefficients x̂t,f are obtained based on Eq.",3.1. Filter estimation network approach,[0],[0]
"(11).
",3.1. Filter estimation network approach,[0],[0]
This approach has several possible problems due to its formalization.,3.1. Filter estimation network approach,[0],[0]
"The first issue is the high flexibility of the estimated filters {gt,f,c}T,F,Ct=1,f=1,c=1, which are composed of a large number of unconstrained variables (2TFC) estimated from few observations.",3.1. Filter estimation network approach,[0],[0]
This causes problems such as training difficulties and over-fitting.,3.1. Filter estimation network approach,[0],[0]
The second issue is that the network structure depends on the number and order of channels.,3.1. Filter estimation network approach,[0],[0]
"Therefore, a new filter estimation network has to be trained when we change microphone configurations.",3.1. Filter estimation network approach,[0],[0]
The key point of the mask estimation network approach is that it constrains the estimated filters based on wellfounded array signal processing principles.,3.2. Mask estimation network approach,[0],[0]
"Here, the network estimates the time-frequency masks, which are used to compute the time-invariant filter coefficients {gf,c}F,Cf=1,c=1 based on the MVDR formalizations.",3.2. Mask estimation network approach,[0],[0]
This is the main difference between this approach and the filter estimation network approach described in Section 3.1.,3.2. Mask estimation network approach,[0],[0]
"Also, mask-based beamforming approaches have achieved great performance in noisy speech recognition benchmarks (Yoshioka et al., 2015; Heymann et al., 2016; Erdogan et al., 2016).",3.2. Mask estimation network approach,[0],[0]
"Therefore, this paper proposes to use a maskbased MVDR beamformer, where overall procedures are formalized as a differentiable network for the subsequent end-to-end speech recognition system.",3.2. Mask estimation network approach,[0],[0]
"Figure 3 summarizes the overall procedures to compute the filter coefficients, which is a detailed flow of Figure 2 (b).",3.2. Mask estimation network approach,[0],[0]
"One of the MVDR formalizations computes the timeinvariant filter coefficients g(f) = {gf,c}Cc=1 ∈ CC in Eq.",3.2.1. MASK-BASED MVDR FORMALIZATION,[0],[0]
"(11) as follows (Souden et al., 2010):
g(f) = ΦN(f)−1ΦS(f)
Tr(ΦN(f)−1ΦS(f)) u, (15)
where ΦS(f) ∈ CC×C and ΦN(f) ∈ CC×C are the crosschannel power spectral density (PSD) matrices (also known as spatial covariance matrices) for speech and noise signals, respectively.",3.2.1. MASK-BASED MVDR FORMALIZATION,[0],[0]
"u ∈ RC is the one-hot vector representing a reference microphone, and Tr(·) is the matrix trace operation.",3.2.1. MASK-BASED MVDR FORMALIZATION,[0],[0]
"Note that although the formula contains a matrix inverse, the number of channels is relatively small, and so the forward pass and derivatives can be efficiently computed.
",3.2.1. MASK-BASED MVDR FORMALIZATION,[0],[0]
"Based on (Yoshioka et al., 2015; Heymann et al., 2016), the PSD matrices are robustly estimated using the expectation with respect to time-frequency masks as follows:
ΦS(f) =",3.2.1. MASK-BASED MVDR FORMALIZATION,[0],[0]
"1∑T
t=1m S t,f T∑ t=1",3.2.1. MASK-BASED MVDR FORMALIZATION,[0],[0]
"mSt,fxt,fx † t,f , (16)
ΦN(f) = 1∑T
t=1m N t,f T∑ t=1 mNt,fxt,fx † t,f , (17)
where xt,f = {xt,f,c}Cc=1 ∈ CC is the spatial vector of an observed signal for each time-frequency bin, mSt,f ∈",3.2.1. MASK-BASED MVDR FORMALIZATION,[0],[0]
"[0, 1] and mNt,f ∈",3.2.1. MASK-BASED MVDR FORMALIZATION,[0],[0]
"[0, 1] are the time-frequency masks for speech and noise, respectively.",3.2.1. MASK-BASED MVDR FORMALIZATION,[0],[0]
† represents the conjugate transpose.,3.2.1. MASK-BASED MVDR FORMALIZATION,[0],[0]
"In the mask estimation network approach, we use two realvalued BLSTM networks; one for a speech mask and the other for a noise mask.",3.2.2. MASK ESTIMATION NETWORK,[0],[0]
"Each network outputs the timefrequency mask as follows:
ZSc = BLSTM S({x̄t,c}Tt=1), (18)
mSt,c = sigmoid(W SzSt,c + b S), (19)
",3.2.2. MASK ESTIMATION NETWORK,[0],[0]
"ZNc = BLSTM N({x̄t,c}Tt=1), (20)
mNt,c = sigmoid(W NzNt,c + b N), (21)
where ZSc = {zSt,c ∈ RDZ |t = 1, · · · , T} is the output sequence of DZ-dimensional vectors of the BLSTM network to obtain a speech mask over c-th channel’s input STFTs.",3.2.2. MASK ESTIMATION NETWORK,[0],[0]
ZNc is the BLSTM output sequence for a noise mask.,3.2.2. MASK ESTIMATION NETWORK,[0],[0]
"x̄t,c = {<(xt,f,c),=(xt,f,c)}Ff=1 ∈",3.2.2. MASK ESTIMATION NETWORK,[0],[0]
R2F is an input feature of a 2F -dimensional real-value vector.,3.2.2. MASK ESTIMATION NETWORK,[0],[0]
This is obtained by concatenating the real and imaginary parts of all STFT features at c-th channel.,3.2.2. MASK ESTIMATION NETWORK,[0],[0]
"mSt,c = {mSt,f,c}Ff=1 ∈",3.2.2. MASK ESTIMATION NETWORK,[0],[0]
"[0, 1]F and mNt,c are the estimated speech and noise masks for every c-th channel at a time step t, respectively.",3.2.2. MASK ESTIMATION NETWORK,[0],[0]
"WS,WN ∈ RF×DZ are the weight matrices of the output layers to finally output speech and noise masks, respectively, and bS,bN ∈ RF are their corresponding bias vectors.
",3.2.2. MASK ESTIMATION NETWORK,[0],[0]
"After computing the speech and noise masks for each channel, the averaged masks are obtained as follows:
mSt = 1
C C∑ c=1",3.2.2. MASK ESTIMATION NETWORK,[0],[0]
"mSt,c, m N t = 1 C C∑ c=1",3.2.2. MASK ESTIMATION NETWORK,[0],[0]
"mNt,c. (22)
",3.2.2. MASK ESTIMATION NETWORK,[0],[0]
We use these averaged masks to estimate the PSD matrices as described in Eqs.,3.2.2. MASK ESTIMATION NETWORK,[0],[0]
(16) and (17).,3.2.2. MASK ESTIMATION NETWORK,[0],[0]
"The MVDR beamformer through this BLSTM mask estimation is originally proposed in (Heymann et al., 2016), but our neural beamformer further extends it with attention-based reference selection, which is described in the next subsection.",3.2.2. MASK ESTIMATION NETWORK,[0],[0]
"To incorporate the reference microphone selection in a neural beamformer framework, we use a soft-max for the vector u in Eq.",3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
(15) derived from an attention mechanism.,3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
"In this approach, the reference microphone vector u is estimated from time-invariant feature vectors qc and rc as follows:
k̃c = v Ttanh(VQqc + V Rrc + b̃), (23) uc = exp(βk̃c)∑C c=1 exp(βk̃c) , (24)
where v ∈ R1×DV ,VZ ∈ RDV×2DZ ,VR ∈",3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
"RDV×2F are trainable weight parameters, b̃ ∈ RDV is a trainable bias vector.",3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
β is the sharpening factor.,3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
"We use two types of
features; 1) the time-averaged state vector qc ∈ R2DZ extracted from the BLSTM networks for speech and noise masks in Eqs.",3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
"(18) and (20), i.e.,
qc = 1
T T∑ t=1 {zSt,c, zNt,c}, (25)
and 2) the PSD feature rc ∈ R2F , which incorporates the spatial information into the attention mechanism.",3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
"The following equation represents how to compute rc:
rc = 1
C − 1 C∑ c′=1,c′ 6=c {<(φSf,c,c′),=(φSf,c,c′)}Ff=1, (26)
where φSf,c,c′ ∈ C is the entry in c-th row and c′-th column of the speech PSD matrix ΦS(f) in Eq.",3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
(16).,3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
The PSD matrix represents correlation information between channels.,3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
"To select a reference microphone, the spatial correlation related to speech signals is more informative, and therefore, we only use the speech PSD matrix ΦS(f) as a feature.
",3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
"Note that, in this mask estimation based MVDR beamformer, masks for each channel are computed separately using the same BLSTM network unlike Eq. (12), and the mask estimation network is independent of channels.",3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
"Similarly, the reference selection network is also independent of channels, and the beamformer deals with input signals with arbitrary number and order of channels without re-training or re-configuration of the network.",3.2.3. ATTENTION-BASED REFERENCE SELECTION,[0],[0]
"In this work, we propose a multichannel end-to-end speech recognition, which integrates all components with a single neural architecture.",4. Multichannel end-to-end ASR,[0],[0]
"We adopt neural beamformers (Section 3) as a speech enhancement part, and the attention-based encoder-decoder (Section 2) as a speech recognition part.
",4. Multichannel end-to-end ASR,[0],[0]
"The entire procedure to generate the sequence of output labels Ŷ from the multichannel inputs {Xc}Cc=1 is formalized as follows:
X̂ = Enhance({Xc}Cc=1), (27) Ô = Feature(X̂), (28)
Ĥ = Encoder(Ô), (29)
ĉn = Attention(ân−1, ŝn, Ĥ), (30) ŷn = Decoder(ĉn, ŷ1:n−1).",4. Multichannel end-to-end ASR,[0],[0]
"(31)
Enhance(·) is a speech enhancement function realized by the neural beamformer based on Eq.",4. Multichannel end-to-end ASR,[0],[0]
"(11) with the filter or mask estimation network (Section 3.1 or 3.2).
",4. Multichannel end-to-end ASR,[0],[0]
Feature(·) is a feature extraction function.,4. Multichannel end-to-end ASR,[0],[0]
"In this work, we use a normalized log Mel filterbank transform to obtain
ôt ∈ RDO computed from the enhanced STFT coefficients x̂t ∈ CF as an input of attention-based encoder-decoder:
pt = {<(x̂t,f )2 + =(x̂t,f )2}Ff=1, (32) ôt",4. Multichannel end-to-end ASR,[0],[0]
"= Norm(log(Mel(pt))), (33)
where pt ∈ RF is a real-valued vector of the power spectrum of the enhanced signal at a time step t, Mel(·) is the operation of DO × F Mel matrix multiplication, and Norm(·) is the operation of global mean and variance normalization so that its mean and variance become 0 and 1.
",4. Multichannel end-to-end ASR,[0],[0]
"Encoder(·), Attention(·), and Decoder(·) are defined in Eqs.",4. Multichannel end-to-end ASR,[0],[0]
"(7), (8), and (9), respectively, with the sequence of the enhanced log Mel filterbank like features Ô as an input.
",4. Multichannel end-to-end ASR,[0],[0]
"Thus, we can build a multichannel end-to-end speech recognition system, which converts multichannel speech signals to texts with a single network.",4. Multichannel end-to-end ASR,[0],[0]
"Note that because all procedures, such as enhancement, feature extraction, encoder, attention, and decoder, are connected with differentiable graphs, we can optimize the overall inference to generate a correct label sequence.
",4. Multichannel end-to-end ASR,[0],[0]
"Relation to prior works
There have been several related studies of neural beamformers based on the filter estimation (Li et al., 2016; Xiao et al., 2016a) and the mask estimation (Heymann et al., 2016; Erdogan et al., 2016; Xiao et al., 2016b).",4. Multichannel end-to-end ASR,[0],[0]
"The main difference is that such preceding studies use a component-level training objective within the conventional hybrid frameworks, while our work focuses on the entire end-to-end objective.",4. Multichannel end-to-end ASR,[0],[0]
"For example, Heymann et al., 2016; Erdogan et al., 2016 use a signal-level objective (binary mask classification or regression) to train a network given parallel clean and noisy speech data.",4. Multichannel end-to-end ASR,[0],[0]
"Li et al., 2016; Xiao et al., 2016a;b use ASR objectives (HMM state classification or sequence discriminative training), but they are still based on the hybrid approach.",4. Multichannel end-to-end ASR,[0],[0]
"Speech recognition with raw multichannel waveforms (Hoshen et al., 2015; Sainath et al., 2016) can also be seen as using a neural beamformer, where the filter coefficients are represented as network parameters, but again these methods are still based on the hybrid approach.
",4. Multichannel end-to-end ASR,[0],[0]
"As regards end-to-end speech recognition, all existing studies are based on a single channel setup.",4. Multichannel end-to-end ASR,[0],[0]
"For example, most studies focus on a standard clean speech recognition setup without speech enhancement.",4. Multichannel end-to-end ASR,[0],[0]
"(Chorowski et al., 2014; Graves & Jaitly, 2014; Chorowski et al., 2015; Chan et al., 2016; Miao et al., 2015; Zhang et al., 2016; Kim et al., 2016; Lu et al., 2016).",4. Multichannel end-to-end ASR,[0],[0]
"Amodei et al., 2016 discusses endto-end speech recognition in a noisy environment, but this method deals with the noise robustness by preparing various types of simulated noisy speech for training data, and
does not incorporate multichannel speech enhancement in their networks.",4. Multichannel end-to-end ASR,[0],[0]
We study the effectiveness of our multichannel end-toend system compared to a baseline end-to-end system with noisy speech or beamformed inputs.,5. Experiments,[0],[0]
"We use the two multichannel speech recognition benchmarks, CHiME-4 (Vincent et al., 2016) and AMI (Hain et al., 2007).
",5. Experiments,[0],[0]
"CHiME-4 is a speech recognition task in public noisy environments, consisting of speech recorded using a tablet device with 6-channel microphones.",5. Experiments,[0],[0]
It consists of real and simulated data.,5. Experiments,[0],[0]
The training set consists of 3 hours of real speech data uttered by 4 speakers and 15 hours of simulation speech data uttered by 83 speakers.,5. Experiments,[0],[0]
"The development set consists of 2.9 hours of real and simulation speech data uttered by 4 speakers, respectively.",5. Experiments,[0],[0]
"The evaluation set consists of 2.2 hours of real and simulation speech data uttered by 4 speakers, respectively.",5. Experiments,[0],[0]
"We excluded the 2nd channel signals, which is captured at the microphone located on the backside of the tablet, and used 5 channels for the following multichannel experiments (C = 5).
",5. Experiments,[0],[0]
"AMI is a speech recognition task in meetings, consisting of speech recorded using 8-channel circular microphones (C = 8).",5. Experiments,[0],[0]
It consists of only real data.,5. Experiments,[0],[0]
The training set consists of about 78 hours of speech data uttered by 135 speakers.,5. Experiments,[0],[0]
"the development and evaluation sets consist of about 9 hours of speech data uttered by 18 and 16 speakers, respectively.",5. Experiments,[0],[0]
"The amount of training data (i.e., 78 hours) is larger than one for CHiME-4 (i.e., 18 hours), and we mainly used CHiME-4 data to demonstrate our experiments.",5. Experiments,[0],[0]
We used 40-dimensional log Mel filterbank coefficients as an input feature vector for both noisy and enhanced speech signals (DO = 40).,5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
"In this experiment, we used 4-layer BLSTM with 320 cells in the encoder (DH = 320), and 1-layer LSTM with 320 cells in the decoder (DS = 320).",5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
"In the encoder, we subsampled the hidden states of the first and second layers and used every second of hidden states for the subsequent layer’s inputs.",5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
"Therefore, the number of hidden states at the encoder’s output layer is reduced to L = T/4.",5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
"After every BLSTM layer, we used a linear projection layer with 320 units to combine the forward and backward LSTM outputs.",5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
"For the attention mechanism, 10 centered convolution filters (DF = 10) of width 100 (Df = 100) were used to extract the convolutional features.",5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
"We set the attention inner product dimension as 320 (DW = 320), and used the sharpening factor α = 2.",5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
"To boost the optimization in a noisy environment, we adopted a joint
CTC-attention multi-task loss function (Kim et al., 2016), and set the CTC loss weight as 0.1.
",5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
"For decoding, we used a beam search algorithm similar to (Sutskever et al., 2014) with the beam size 20 at each output step to reduce the computation cost.",5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
CTC scores were also used to re-score the hypotheses with 0.1 weight.,5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
"We adopted a length penalty term (Chorowski et al., 2015) to the decoding objective and set the penalty weight as 0.3.",5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
"In the CHiME-4 experiments, we only allowed the hypotheses whose length were within 0.3×L and 0.75×L during decoding, while the hypothesis lengths in the AMI experiments were automatically determined based on the above scores.",5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
"Note that we pursued a pure end-to-end setup without using any external lexicon or language models, and used CER as an evaluation metric.",5.1.1. ENCODER-DECODER NETWORKS,[0],[0]
256 STFT coefficients and the offset were computed from 25ms-width hamming window with 10ms shift (F = 257).,5.1.2. NEURAL BEAMFORMERS,[0],[0]
Both filter and mask estimation network approaches used similar a 3-layer BLSTM with 320 cells (DZ = 320) without the subsampling technique.,5.1.2. NEURAL BEAMFORMERS,[0],[0]
"For the reference selection attention mechanism, we used the same attention inner product dimension (DV = 320) and sharpening factor β = 2 as those of the encoder-decoder network.",5.1.2. NEURAL BEAMFORMERS,[0],[0]
"All the parameters are initialized with the range [-0.1, 0.1] of a uniform distribution.",5.1.3. SHARED CONFIGURATIONS,[0],[0]
"We used the AdaDelta algorithm (Zeiler, 2012) with gradient clipping (Pascanu et al., 2013) for optimization.",5.1.3. SHARED CONFIGURATIONS,[0],[0]
We initialized the AdaDelta hyperparameters ρ = 0.95 and = 1−8.,5.1.3. SHARED CONFIGURATIONS,[0],[0]
"Once the loss over the validation set was degraded, we decreased the AdaDelta hyperparameter by multiplying it by 0.01 at each subsequent epoch.",5.1.3. SHARED CONFIGURATIONS,[0],[0]
The training procedure was stopped after 15 epochs.,5.1.3. SHARED CONFIGURATIONS,[0],[0]
"During the training, we adopted multi-condition training strategy, i.e., in addition to the optimization with the enhanced features through the neural beamformers, we also used the noisy multichannel speech data as an input of encoder-decoder networks without through the neural beamformers to improve the robustness of the encoderdecoder networks.",5.1.3. SHARED CONFIGURATIONS,[0],[0]
"All the above networks are implemented by using Chainer (Tokui et al., 2015).",5.1.3. SHARED CONFIGURATIONS,[0],[0]
"Table 1 shows the recognition performances of CHiME4 with the five systems: NOISY, BEAMFORMIT, FILTER NET, MASK NET (REF), and MASK NET (ATT).",5.2. Results,[0],[0]
"NOISY and BEAMFORMIT were the baseline singlechannel end-to-end systems, which did not include the speech enhancement part in their frameworks.",5.2. Results,[0],[0]
"Their endto-end networks were trained only with noisy speech data
by following a conventional multi-condition training strategy (Vincent et al., 2016).",5.2. Results,[0],[0]
"During decoding, NOISY used single-channel noisy speech data from ’isolated 1ch track’ in CHiME-4 as an input, while BEAMFORMIT used the enhanced speech data obtained from 5-channel signals with BeamformIt (Anguera et al., 2007), which is well-known delay-and-sum beamformer, as an input.
FILTER NET, MASK NET (REF), and MASK NET (ATT) were the multichannel end-to-end systems described in Section 4.",5.2. Results,[0],[0]
"To evaluate the validity of the reference selection, we prepared MASK NET (ATT) based on the maskbased beamformer with attention-based reference selection described in Section 3.2.3, and MASK NET (REF) with 5-th channel as a fixed reference microphone, which is located on the center front of the tablet device.
",5.2. Results,[0],[0]
"Table 1 shows that BEAMFORMIT, FILTER NET, MASK NET (REF), and MASK NET (ATT) outperformed NOISY, which confirms the effectiveness of combining speech enhancement with the attention-based encoderdecoder framework.",5.2. Results,[0],[0]
The comparison of MASK NET (REF) and MASK NET (ATT) validates the use of the attention-based mechanism for reference selection.,5.2. Results,[0],[0]
"FILTER NET, which is based on the filter estimation network described in Section 3.1, also improved the performance compared to NOISY, but worse than MASK NET (ATT).",5.2. Results,[0],[0]
"This is because it is difficult to optimize the filter estimation network due to a lack of restriction to estimate filter coefficients, and it needs some careful optimization, as suggested by (Xiao et al., 2016a).",5.2. Results,[0],[0]
"Finally, MASK NET (ATT) achieved better recognition performance than BEAMFORMIT, which proves the effectiveness of our joint integration rather than a pipe-line combination of speech enhancement and (end-to-end) speech recognition.
",5.2. Results,[0],[0]
"To further investigate the effectiveness of our proposed multichannel end-to-end framework, we also conducted the experiment on the AMI corpus.",5.2. Results,[0],[0]
"Table 2 compares the recognition performance of the three systems: NOISY, BEAMFORMIT, and MASK NET (ATT).",5.2. Results,[0],[0]
"In NOISY, we used noisy speech data from the 1st channel in AMI as an input to the system.",5.2. Results,[0],[0]
"Table 2 shows that, even in the AMI, our proposed MASK NET (ATT) achieved bet-
ter recognition performance than the attention-based baselines (NOISY and BEAMFORMIT), which also confirms the effectiveness of our proposed multichannel end-to-end framework.",5.2. Results,[0],[0]
Note that BEAMFORMIT was worse than NOISY even with the enhanced signals.,5.2. Results,[0],[0]
This phenomenon is sometimes observed in noisy speech recognition that the distortion caused by sole speech enhancement degrades the performance without re-training.,5.2. Results,[0],[0]
"Our end-to-end system jointly optimizes the speech enhancement part with the ASR objective, and can avoid such degradations.",5.2. Results,[0],[0]
"As we discussed in Section 3.2, one unique characteristic of our proposed MASK NET (ATT) is the robustness/invariance against the number and order of channels without re-training.",5.3. Influence on the number and order of channels,[0],[0]
Table 3 shows an influence of the CHiME-4 validation accuracies on the number and order of channels.,5.3. Influence on the number and order of channels,[0],[0]
The validation accuracy was computed conditioned on the ground truth labels y∗1,5.3. Influence on the number and order of channels,[0],[0]
:n−1 in Eq,5.3. Influence on the number and order of channels,[0],[0]
.,5.3. Influence on the number and order of channels,[0],[0]
"(10) during decoder’s recursive character generation, which has a strong correlation with CER.",5.3. Influence on the number and order of channels,[0],[0]
"The second column of the table represents the channel indices, which were used as an input of the same MASK NET (ATT) network.
",5.3. Influence on the number and order of channels,[0],[0]
"Comparison of 5 6 4 3 1 and 3 4 1 5 6 shows that the order of channels did not affect the recognition performance of MASK NET (ATT) at all, as we expected.",5.3. Influence on the number and order of channels,[0],[0]
"In addition, even when we used fewer three or four channels as an input, MASK NET (ATT) still outperformed NOISY (single channel).",5.3. Influence on the number and order of channels,[0],[0]
"These results confirm that our proposed multichannel end-to-end system can deal with input signals with arbitrary number and order of channels, without any reconfiguration and re-training.",5.3. Influence on the number and order of channels,[0],[0]
"To analyze the behavior of our developed speech enhancement component with a neural beamformer, Figure 4 visualizes the spectrograms of the same CHiME-4 utterance with the 5-th channel noisy signal, enhanced signal with BeamformIt, and enhanced signal with our proposed MASK NET (ATT).",5.4. Visualization of beamformed features,[0],[0]
"We could confirm that the BeamformIt and MASK NET (ATT) successfully suppressed the noises comparing to the 5-th channel signal by eliminat-
ing blurred red areas overall.",5.4. Visualization of beamformed features,[0],[0]
"In addition, by focusing on the insides of black boxes, the harmonic structure, which was corrupted in the 5-th channel signal, was recovered in BeamformIt and MASK NET (ATT).
",5.4. Visualization of beamformed features,[0],[0]
"This result suggests that our proposed MASK NET (ATT) successfully learned a noise suppression function similar to the conventional beamformer, although it is optimized based on the end-to-end ASR objective, without explicitly using clean data as a target.",5.4. Visualization of beamformed features,[0],[0]
"In this paper, we extended an existing attention-based encoder-decoder framework by integrating a neural beamformer and proposed a multichannel end-to-end speech recognition framework.",6. Conclusions,[0],[0]
"It can jointly optimize the overall inference in multichannel speech recognition (i.e., from speech enhancement to speech recognition) based on the end-to-end ASR objective, and it can generalize to dif-
ferent numbers and configurations of microphones.",6. Conclusions,[0],[0]
"The experimental results on challenging noisy speech recognition benchmarks, CHiME-4 and AMI, show that the proposed framework outperformed the end-to-end baseline with noisy and delay-and-sum beamformed inputs.
",6. Conclusions,[0],[0]
"The current system still has data sparseness issues due to the lack of lexicon and language models, unlike the conventional hybrid approach.",6. Conclusions,[0],[0]
"Therefore, the results reported in the paper did not reach the state-of-the-art performance in these benchmarks, but they are still convincing to show the effectiveness of the proposed framework.",6. Conclusions,[0],[0]
Our most important future work is to overcome these data sparseness issues by developing adaptation techniques of an end-to-end framework with the incorporation of linguistic resources.,6. Conclusions,[0],[0]
The field of speech recognition is in the midst of a paradigm shift: end-to-end neural networks are challenging the dominance of hidden Markov models as a core technology.,abstractText,[0],[0]
"Using an attention mechanism in a recurrent encoder-decoder architecture solves the dynamic time alignment problem, allowing joint end-to-end training of the acoustic and language modeling components.",abstractText,[0],[0]
In this paper we extend the end-to-end framework to encompass microphone array signal processing for noise suppression and speech enhancement within the acoustic encoding network.,abstractText,[0],[0]
This allows the beamforming components to be optimized jointly within the recognition architecture to improve the end-to-end speech recognition objective.,abstractText,[0],[0]
Experiments on the noisy speech benchmarks (CHiME-4 and AMI) show that our multichannel end-to-end system outperformed the attention-based baseline with input from a conventional adaptive beamformer.,abstractText,[0],[0]
Multichannel End-to-end Speech Recognition ,title,[0],[0]
"In the multilabel classification problem, we are given a set of labeled training data {(xi, yi)}ni=1, where xi ∈",1. Introduction,[0],[0]
"Rp are the input features for each data instances and yi ∈ {0, 1}d
1Department of Computer Science and Engineering, University of Minnesota at Twin Cities, MN USA.",1. Introduction,[0],[0]
"2College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA.. Correspondence to:",1. Introduction,[0],[0]
"Shashanka Ubaru <ubaru001@umn.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
are vectors indicating the corresponding labels (classes) the data instances belong to.",1. Introduction,[0],[0]
The vector yi has a one in the jth coordinate if the ith data point belongs to jth class.,1. Introduction,[0],[0]
"We wish to learn a mapping (prediction rule) between the features and the labels, such that, we can predict the class label vector y of a new data point x correctly.",1. Introduction,[0],[0]
"Such multilabel classification problems occur in many domains such as text mining, computer vision, music, and bioinformatics (Barutcuoglu et al., 2006; Trohidis, 2008; Tai & Lin, 2012), and modern applications involve large number of labels.",1. Introduction,[0],[0]
"Popular applications with many labels include image and video annotation (Wang et al., 2009), web page categorization (Agrawal et al., 2013), text and document categorization (Tsoumakas et al., 2008), and others (Bhatia et al., 2015).",1. Introduction,[0],[0]
"In most of these applications, the label vectors yi are sparse (with average sparsity of k d), i.e., each data point belongs to a few (average k out of d) classes.",1. Introduction,[0],[0]
"The multiclass classification is an instance of the multilabel classification, where all data points belong to only one of the d classes (k = 1).
",1. Introduction,[0],[0]
"The simple binary classification problem, where d = 2 and k = 1 is well-studied, and several efficient algorithms have been proposed in the literature.",1. Introduction,[0],[0]
"A natural approach used to solve the multiclass (d > 2, k = 1) classification problem is to reduce the problem into a set of binary classification problem, and then employ the efficient binary classifiers to solve the individual problems.",1. Introduction,[0],[0]
"Popular methods based on this approach are: one-vs-all, all-pairs, and the error-correcting output code (ECOC) (Dietterich & Bakiri, 1995) methods.",1. Introduction,[0],[0]
"In ECOC method, m-dimensional binary vectors (typically codewords from an error correcting code with m ≤ d) are assigned to each class, and m binary classifiers are learned.",1. Introduction,[0],[0]
"For the jth classification, the jth coordinate of the corresponding codeword is used as the binary label for each class.",1. Introduction,[0],[0]
"In the modern applications, where d is typically very large, this approach is found to be very efficient due to the reduction of the class dimension.
",1. Introduction,[0],[0]
The idea of ECOC approach has been extended to the multilabel classification (MLC) problem.,1. Introduction,[0],[0]
"In the multiclass classification, using codewords for each class in ECOC is equivalent to multiplying the code matrix to the label vectors (since the label vectors are basis vectors).",1. Introduction,[0],[0]
"Hence, in the multilabel setting, the reduction from d dimensional label vectors to m dimensional can be achieved by multiply-
ing a code matrix A ∈ Rm×d to the label vector y. This reduction method was analyzed from the compressed sensing point of view in (Hsu et al., 2009), with the assumption of output sparsity, i.e., y is sparse (with average sparsity k).",1. Introduction,[0],[0]
"Using compressed sensing (CS) theory, the results in (Hsu et al., 2009) show that for a linear hypothesis class and under the squared loss, a random embedding (random code matrix) of the classes to m = O(k log d) dimensions does not increase the L2 risk of the classifier.",1. Introduction,[0],[0]
"Similarly, (Kapoor et al., 2012) discusses MLC using compressed sensing in the Bayesian framework.",1. Introduction,[0],[0]
"However, the CS approach requires solving an optimization problem to recover the label vector.",1. Introduction,[0],[0]
"Constructions with faster recovery algorithms exist (see, e.g., (Jafarpour et al., 2009))",1. Introduction,[0],[0]
"but we cannot obtain L2 norm results with them.
",1. Introduction,[0],[0]
"Alternatively, embedding based approaches have been proposed to reduce the effective number of labels.",1. Introduction,[0],[0]
"These methods reduce the label dimension by projecting label vectors onto a low dimensional space, based on the assumption that the label matrix Y =",1. Introduction,[0],[0]
"[y1, . . .",1. Introduction,[0],[0]
", yn] is low-rank.",1. Introduction,[0],[0]
The various embedding methods proposed in the literature mainly differ in the way this reduction is achieved.,1. Introduction,[0],[0]
"The reduction is achieved using SVD in (Tai & Lin, 2012), while column subset selection is used in (Bi & Kwok, 2013).",1. Introduction,[0],[0]
"(Zhang & Schneider, 2011) used canonical correlation analysis and (Chen & Lin, 2012) used an SVD approach that leverages the feature space information.",1. Introduction,[0],[0]
"(Yu et al., 2014) discussed multilabel classification with missing entries and used an embedding method with a regularized least squares objective.",1. Introduction,[0],[0]
"These embedding methods capture the label correlation, and Euclidean distance error guarantees are established.",1. Introduction,[0],[0]
"However, the low rank assumption breaks down in many situations (Bhatia et al., 2015; Xu et al., 2016), e.g., data is power law distributed (Babbar & Schölkopf, 2017).
",1. Introduction,[0],[0]
"The state of the art embedding method called SLEEC (Sparse Local Embedding for Extreme Classification) (Bhatia et al., 2015) overcomes the limitations of previous embedding methods by first clustering the data into smaller regions, and then performs local embeddings of label vectors by preserving distances to nearest label vectors.",1. Introduction,[0],[0]
"However, this method also has many shortcomings, see (Babbar & Schölkopf, 2017).",1. Introduction,[0],[0]
"Moreover, most of these embedding based methods are very expensive.",1. Introduction,[0],[0]
"They involve eigenvalue or singular value decompositions and matrix inversions, and may require solving convex optimization problems, all of which become impractical for very large d.",1. Introduction,[0],[0]
"In all the embedding methods and the CS method, the reduced label space is a real space (no longer binary).",1. Introduction,[0],[0]
Hence we need to use regressors for training and cannot leverage the efficient binary classifiers for effective training for the model.,1. Introduction,[0],[0]
Prediction will also involve rounding/thresholding of real values.,1. Introduction,[0],[0]
"This is additional work, and choosing a right threshold is sometimes problematic.
",1. Introduction,[0],[0]
Proposed Approach.,1. Introduction,[0],[0]
"In this paper, we present a novel reduction approach to solve the MLC problem.",1. Introduction,[0],[0]
"Our approach assumes output sparsity (sparse label vectors with k d) similar to the CS approach, but reduces a large binary label vector to a binary vector of smaller size.",1. Introduction,[0],[0]
"Since the reduced label vectors are binary, we can use the efficient binary classifiers for effective training for the model.",1. Introduction,[0],[0]
Our prediction algorithm is extremely simple and does not involve any matrix inversion or solving optimization algorithm.,1. Introduction,[0],[0]
The prediction algorithm can also detect and correct errors.,1. Introduction,[0],[0]
"Hence, even if a constant fraction of the binary classifiers mis-classify, our prediction error will be zero.
",1. Introduction,[0],[0]
"Our approach is based on the popular group testing problem (Dorfman, 1943; Du & Hwang, 2000).",1. Introduction,[0],[0]
"In the group testing problem, we wish to efficiently identify a small number k of defective elements in a population of large size d.",1. Introduction,[0],[0]
"The idea is to test the items in groups with the premise that most tests will return negative results, clearing the entire group.",1. Introduction,[0],[0]
Only fewm d tests are needed to detect the k defectives.,1. Introduction,[0],[0]
The items can be grouped in either an adaptive or nonadaptive fashion.,1. Introduction,[0],[0]
"In the nonadaptive group testing scheme, the grouping for each test can be described using an m× d binary (0/1 entries) matrix A.
We make the crucial observation that, the MLC problem can be solved using the group testing (GT) premise.",1. Introduction,[0],[0]
"That is, the problem of estimating the (few) classes of a data instance from a large set of classes, is similar to identifying a small set of items from a large set.",1. Introduction,[0],[0]
We consider a group testing binary matrix A and reduce the label vectors yi’s to smaller binary vectors zi using the boolean OR operation zi =,1. Introduction,[0],[0]
A ∨ yi (described later).,1. Introduction,[0],[0]
We can now use binary classifiers on zi for training.,1. Introduction,[0],[0]
The m classifiers learn to test whether the data belongs to a group (of labels) or not.,1. Introduction,[0],[0]
"During prediction, the label vector can be recovered from the predictions of the classifiers using a simple inexpensive algorithm (requiring no matrix inversion or solving optimization algorithms).",1. Introduction,[0],[0]
A low prediction cost is extremely desirable in real time applications.,1. Introduction,[0],[0]
"Depending on a certain property called (k, e)-disjunct property of the group testing matrix A, the recovery algorithm can correct up to be/2c errors in the prediction.",1. Introduction,[0],[0]
"We discuss various constructions for the group testing matrix A which have the desired (k, e)-disjunct property.",1. Introduction,[0],[0]
"We advocate the use of concatenated Reed Solomon codes (Kautz & Singleton, 1964), and unbalanced bipartite expander graphs (Vadhan, 2012) as the group testing matrix A. The optimal number of binary classifiers required for exact recovery (to form a (k, e)-disjunct matrix) will be m = Θ(k2 logk d).",1. Introduction,[0],[0]
"However, we show how this can be reduced to m = O(k log d) if we tolerate a small ε error in the labels recovery.
",1. Introduction,[0],[0]
"The idea of grouping the labels helps overcome the issues most existing methods encounter; e.g., when the data has
power law distribution (Babbar & Schölkopf, 2017), that is many labels have very few training instances (which is the case in most popular datasets), and tail labels (Xu et al., 2016).",1. Introduction,[0],[0]
"Since the classifiers in our approach learn to test for groups of labels, we will have more training instances per group yielding effective classifiers.",1. Introduction,[0],[0]
"It is well known that the one-vs-rest is a highly effective method (expensive), and recently a (doubly) parallelized version of this method called DiSMEC (Babbar & Schölkopf, 2017) was shown to be very effective.",1. Introduction,[0],[0]
"Our approach is similar to one-vs-rest, but the classifiers test for a group of labels, and we require very few classifiers (O(log d) instead of d).",1. Introduction,[0],[0]
"Our approach also resembles the Bloom filter method (Cisse et al., 2013), which is based on using hash functions to reduce the label size.",1. Introduction,[0],[0]
"However, for Bloom filters the lower dimension m can be larger than O(k log d) (no bounds are established) and they may yield many false positives.",1. Introduction,[0],[0]
"For proper encoding this method requires clustering of the labels.
",1. Introduction,[0],[0]
We establish Hamming loss error bounds for the proposed approach.,1. Introduction,[0],[0]
"Due to the error correcting capabilities of the algorithm, even if a fraction of classifiers mis-classify, we can achieve zero prediction error.",1. Introduction,[0],[0]
Numerical experiments with various datasets illustrate the superior performance of our group testing approach with different GT matrices.,1. Introduction,[0],[0]
"Our method is extremely inexpensive compared to the CS approach and especially compared to the embedding based methods, making it very desirable for real time applications too.",1. Introduction,[0],[0]
The results we obtain using the GT approach are more accurate compared to the other popular methods (in terms of Hamming distance).,1. Introduction,[0],[0]
"For many examples, the training errors we obtained were almost zero and the test errors were also quite low.",1. Introduction,[0],[0]
Group testing.,2. Preliminaries,[0],[0]
"Formally, the group testing problem involves identifying an unknown k-sparse binary vector y ∈ {0, 1}d, such that |supp(y)| ≤ k, where supp(y) := {i : yi 6= 0} is called the support of the vector y, by performing a small number of tests (measurements).",2. Preliminaries,[0],[0]
"In the MLC problem, we can view this vector as the sparse label vector y of the data (indicating the k labels).
",2. Preliminaries,[0],[0]
"A nonadaptive group testing scheme with m tests is described by an m × d binary matrix A, where each row corresponds to a test, and Aij = 1 if and only if the ith test includes the jth element.",2. Preliminaries,[0],[0]
The measured vector z is the boolean OR operation between the matrix A and the label vector y.,2. Preliminaries,[0],[0]
The boolean OR operation z,2. Preliminaries,[0],[0]
= A ∨ y can simply be obtained by setting every nonzero entry of the usual matrix-vector product Ay to 1 (and leaving the zero entries as they are).,2. Preliminaries,[0],[0]
"It can also be thought of as coordinate-wise Boolean OR of the columns of A that correspond to the nonzero entries of y.
Definition 1 (Disjunctness).",2. Preliminaries,[0],[0]
An m × d binary matrix,2. Preliminaries,[0],[0]
"A is called k-disjunct if the support of any of its columns is not contained in the union of the supports of any other k columns.
",2. Preliminaries,[0],[0]
"A k-disjunct matrix gives a group testing scheme that identifies any defective set up to size k exactly.
",2. Preliminaries,[0],[0]
Definition 2 (Error Correction).,2. Preliminaries,[0],[0]
An m × d binary matrix,2. Preliminaries,[0],[0]
"A is called (k, e)-disjunct, e ≥ 1, (k-disjunct and e-error detecting) if for every set S of columns of A with |S| ≤ k, and i /∈",2. Preliminaries,[0],[0]
"S, we have |supp(A(i))\ ∪j∈S supp(A(j))|",2. Preliminaries,[0],[0]
>,2. Preliminaries,[0],[0]
"e, where A(i) denote the ith column of A.
A (k, e)-disjunct matrix can detect up to e errors in the measurements and can correct up to be/2c errors.
",2. Preliminaries,[0],[0]
"Several random and deterministic construction of kdisjunct matrices have been proposed in the literature (Kautz & Singleton, 1964; Du & Hwang, 2000).",2. Preliminaries,[0],[0]
"Matrices from error correcting codes and expander graphs have also been designed (Dyachkov et al., 2000; Ubaru et al., 2016; Cheraghchi, 2010; Mazumdar, 2016).",2. Preliminaries,[0],[0]
"In this section, we present our main idea of adapting the group testing scheme to the multilabel classification problem (MLGT).
Training.",3. MLC via Group testing,[0],[0]
"Suppose we are given n training instances {(xi, yi)}ni=1, where xi ∈",3. MLC via Group testing,[0],[0]
"Rp are the input features for each instances and yi ∈ {0, 1}d are corresponding label vectors.",3. MLC via Group testing,[0],[0]
We begin by assuming that each data instance belongs to at most k classes (the label vector y is k sparse).,3. MLC via Group testing,[0],[0]
"We consider a (k, e)-disjunct matrix A ∈ Rm×d.",3. MLC via Group testing,[0],[0]
"We then compute the reduced measured (label) vectors zi for each label vectors yi, i = 1, . . .",3. MLC via Group testing,[0],[0]
", n using the boolean OR operation zi =",3. MLC via Group testing,[0],[0]
A ∨ yi.,3. MLC via Group testing,[0],[0]
"We can now train m binary classifiers {wj}mj=1 based on {xi, zi}ni=1 with jth entry of zi indicating which class (1/0) the ith instance belongs to for the jth classifier.",3. MLC via Group testing,[0],[0]
"Algorithm 1 summarizes our training algorithm.
",3. MLC via Group testing,[0],[0]
Algorithm 1 MLGT:,3. MLC via Group testing,[0],[0]
"Training Algorithm Input: Training data {(xi, yi)}ni=1, group testing matrix A ∈ Rm×d, a binary classifier algorithm C. Output: m classifiers {wj}mj=1. for i = 1, . . .",3. MLC via Group testing,[0],[0]
", n. do zi =",3. MLC via Group testing,[0],[0]
"A ∨ yi.
end for for j = 1, . . .",3. MLC via Group testing,[0],[0]
",m. do wj = C({(xi, zij)}ni=1).",3. MLC via Group testing,[0],[0]
"end for
Prediction.",3. MLC via Group testing,[0],[0]
"In the prediction stage, given a test data x ∈",3. MLC via Group testing,[0],[0]
"Rp, we use the m classifiers {wj}mj=1 to obtain a predicted
reduced label vector ẑ. We know that a k sparse label vector can be recovered exactly, if the group testing matrix A is a k-disjunct matrix.",3. MLC via Group testing,[0],[0]
"With a (k, e)-disjunct matrix, e ≥ 1, we can recover the k sparse label vector exactly, even if be/2c binary classifiers mis-classify, using the following decoder.
",3. MLC via Group testing,[0],[0]
"Decoder : Given a predicted reduced label vector ẑ, and a group testing matrix A, set the coordinate position of ŷ corresponding to l ∈",3. MLC via Group testing,[0],[0]
"[1, . . .",3. MLC via Group testing,[0],[0]
", d] to 1 if and only if |supp(A(l))\supp(ẑ)| < e/2.
",3. MLC via Group testing,[0],[0]
"That is, we set the lth coordinate of ŷ to 1, if the number of coordinates that are in the support of the corresponding column A(l) but are not in the predicted reduced vector ẑ, is less than e/2.",3. MLC via Group testing,[0],[0]
The decoder returns the exact label vector even if up to e/2 binary classifiers make errors.,3. MLC via Group testing,[0],[0]
"Algorithm 2 summarizes our prediction algorithm.
",3. MLC via Group testing,[0],[0]
Algorithm 2 MLGT:,3. MLC via Group testing,[0],[0]
Prediction Algorithm Input: Test data x ∈,3. MLC via Group testing,[0],[0]
"Rp, the GT matrix A ∈ Rm×d which is (k, e)-disjunct (e ≥ 1), m classifiers {wj}mj=1.",3. MLC via Group testing,[0],[0]
Output: predicted label ŷ. Compute,3. MLC via Group testing,[0],[0]
ẑ =,3. MLC via Group testing,[0],[0]
"[w1(x), . .",3. MLC via Group testing,[0],[0]
.,3. MLC via Group testing,[0],[0]
", wm(x)].",3. MLC via Group testing,[0],[0]
Set ŷ,3. MLC via Group testing,[0],[0]
← 0.,3. MLC via Group testing,[0],[0]
"for l = 1, . . .",3. MLC via Group testing,[0],[0]
", d do
if |supp(A(l))\supp(ẑ)| < e/2 then ŷl = 1.
end if end for
Note that the prediction algorithm is very inexpensive (requires no matrix inversion or solving optimization).",3. MLC via Group testing,[0],[0]
"It is equivalent to an AND operation between a binary sparse matrix and a binary (likely sparse) vector, which should cost less than a sparse matrix vector productO(nnz(A))",3. MLC via Group testing,[0],[0]
"≈ O(kd), where nnz(A) is the number of nonzero entries of A.",3. MLC via Group testing,[0],[0]
It is an interesting future work to design an even faster prediction algorithm.,3. MLC via Group testing,[0],[0]
"In order to recover a k sparse label vector exactly, we know that the group testing matrixAmust be a k-disjunct matrix.",4. Constructions,[0],[0]
"With a (k, e)-disjunct matrix, our algorithm can extract the sparse label vector exactly even if e/2 binary classifiers make errors (mis-classify).",4. Constructions,[0],[0]
"Here, we present the results that will help us construct specific GT matrices with the desired properties.",4. Constructions,[0],[0]
Proposition 1 (Random Construction).,4.1. Random Constructions,[0],[0]
"An m× d random binary {0, 1} matrix A where each entry is 1 with probability ρ = 1k+1 , is (k, 3k log d)-disjunct with very high probability, if m = O(k2 log d).
",4.1. Random Constructions,[0],[0]
"If we tolerate a small ε fraction of sparsity label misclassifications (i.e., εk errors in the recovered label vector), which we call ε-tolerance group testing, then we can follow the analysis of Theorem 8.1.1 in (Du & Hwang, 2000), to show that it is sufficient to have m = O(k log d) number of classifiers.",4.1. Random Constructions,[0],[0]
"Further, we can derive the following result.
",4.1. Random Constructions,[0],[0]
Theorem 1.,4.1. Random Constructions,[0],[0]
Suppose we wish to recover a k sparse binary vector y ∈ Rd.,4.1. Random Constructions,[0],[0]
"A random binary {0, 1} matrix A where each entry is 1 with probability ρ = 1/k recovers 1 − ε proportion of the support of y correctly with high probability, for any ε > 0, with m = O(k log d).",4.1. Random Constructions,[0],[0]
"This matrix will also detect e = Ω(m) errors.
",4.1. Random Constructions,[0],[0]
The proofs of the proposition and the theorem can be found in the supplementary.,4.1. Random Constructions,[0],[0]
"Kautz and Singleton (Kautz & Singleton, 1964) introduced a two-level construction in which a q-ary ( q > 2) ReedSolomon (RS) code is concatenated with a unit-weight binary code.",4.2. Concatenated code based constructions,[0],[0]
"The construction starts with a q-ary ( q > 2) RS code of length q − 1, and replaces the q-ary symbols in the codewords by unit weight binary vectors of length q. That is, the q-ary symbols are replaced as 0 → 100 . . .",4.2. Concatenated code based constructions,[0],[0]
0,4.2. Concatenated code based constructions,[0],[0]
; 1 → 010 . .,4.2. Concatenated code based constructions,[0],[0]
.,4.2. Concatenated code based constructions,[0],[0]
0;,4.2. Concatenated code based constructions,[0],[0]
q − 1 → 0 . . .,4.2. Concatenated code based constructions,[0],[0]
01.,4.2. Concatenated code based constructions,[0],[0]
This gives us a binary matrix with m = q(q − 1) rows.,4.2. Concatenated code based constructions,[0],[0]
This matrix belongs to a broad class of error correcting codes called the constant weight codes (each codeword/column has a constant number of ones w).,4.2. Concatenated code based constructions,[0],[0]
"For this Kautz-Singleton construction, w = q−1.",4.2. Concatenated code based constructions,[0],[0]
Proposition 2 (Kautz-Singleton construction).,4.2. Concatenated code based constructions,[0],[0]
"A KautzSingleton construction with (k logk d)-ary Reed-Solomon (RS) code is a (k, (k − 1) logk d)-disjunct matrix with m = Θ(k2 log2k d).
",4.2. Concatenated code based constructions,[0],[0]
Proof.,4.2. Concatenated code based constructions,[0],[0]
A constant weight code matrix is k disjunct matrix with k = b,4.2. Concatenated code based constructions,[0],[0]
"w−1w−h/2c, where w is the weight and h is the distance of the code, (see, Theorem 7.3.3 in (Du & Hwang, 2000)).",4.2. Concatenated code based constructions,[0],[0]
The distance of the q-ary RS code is h = 2(q − logq(d)).,4.2. Concatenated code based constructions,[0],[0]
"Hence, we get k = q−2 logq d−1
.",4.2. Concatenated code based constructions,[0],[0]
"So, for a kdisjunct matrix, we choose q = k logk d. A code with distance h will have e = h/2 (by using Corollary 8.3.2 in (Du & Hwang, 2000)).",4.2. Concatenated code based constructions,[0],[0]
"Thus, e = q −",4.2. Concatenated code based constructions,[0],[0]
logq d ≈ (k − 1) logk d. m = q(q,4.2. Concatenated code based constructions,[0],[0]
− 1) = Θ(k2 log2k,4.2. Concatenated code based constructions,[0],[0]
"d).
",4.2. Concatenated code based constructions,[0],[0]
Other code based constructions are given in supplementary.,4.2. Concatenated code based constructions,[0],[0]
"Expander graphs have popularly been used in many applications, for example, in coding theory (Sipser & Spielman, 1996), in compressed sensing (Jafarpour et al., 2009), etc.",4.3. Expander graphs,[0],[0]
"In an expander graph, every small set of vertices “expands”: the are “sparse” yet very “well-connected” (see
formal definition below).",4.3. Expander graphs,[0],[0]
With high probability a random graph is a good expander.,4.3. Expander graphs,[0],[0]
"Construction of “lossless” expanders have been notoriously difficult.
",4.3. Expander graphs,[0],[0]
Definition 3 (Unbalanced Lossless Expander Graphs).,4.3. Expander graphs,[0],[0]
"A (k, )-unbalanced bipartite expander graph is a bipartite graph G(L,R,E), |L| = d, |R| = m, where L is the set of left nodes and R is the set of right nodes, with regular left degree ` such that for any S ⊂ L, if |S| ≤ k then the set of neighbors N(S) of S has the size N(S) >",4.3. Expander graphs,[0],[0]
"`|S|.
",4.3. Expander graphs,[0],[0]
"The following proposition describe the expander property of random graphs.
",4.3. Expander graphs,[0],[0]
Proposition 3.,4.3. Expander graphs,[0],[0]
"A random construction of bipartite graphs G(L,R,E) with |L| = d with overwhelming probability, is (k, )-lossless",4.3. Expander graphs,[0],[0]
"`-regular expander where ` = O(log d/ ) with |R| = m = O(k`/ ).
",4.3. Expander graphs,[0],[0]
The trade-off of this proposition is close to the best we can hope for.,4.3. Expander graphs,[0],[0]
"The proof can be shown by simple random choice and can be found in (Vadhan, 2012) or in (Cheraghchi, 2010).
",4.3. Expander graphs,[0],[0]
"The next definition and the subsequent two claims are from (Cheraghchi, 2010).",4.3. Expander graphs,[0],[0]
"First, let us now connect a lossless expander with disjunct matrix.
",4.3. Expander graphs,[0],[0]
Definition 4.,4.3. Expander graphs,[0],[0]
"A bipartite graph G(L,R,E) is called (k, e)-disjunct if, for every left vertex i ∈ L and every set S ⊆ L such that |S| ≤ k",4.3. Expander graphs,[0],[0]
and i /∈,4.3. Expander graphs,[0],[0]
"S, we have |N(i)\N(S)| > e.
It can be seen that the bipartite adjacency matrix A of a disjunct graph G is a disjunct matrix.
",4.3. Expander graphs,[0],[0]
Proposition 4.,4.3. Expander graphs,[0],[0]
"Let G be a (k, e)-disjunct graph with adjacency matrix A. Then for every pair of y, y′ ∈ {0, 1}d of k -sparse vectors, we have ∆(A∨y,A∨y′) >",4.3. Expander graphs,[0],[0]
"e, where ∆(·) denotes the Hamming distance between vectors.
",4.3. Expander graphs,[0],[0]
"The following proposition relates expander graphs with disjunct graphs.
",4.3. Expander graphs,[0],[0]
Proposition 5.,4.3. Expander graphs,[0],[0]
"Let G be a `-regular (k, )-lossless expander.",4.3. Expander graphs,[0],[0]
"Then, for every α ∈",4.3. Expander graphs,[0],[0]
"[0, 1),G is (k−1, α`)-disjunct provided that < 1−α` .
",4.3. Expander graphs,[0],[0]
"Combining these comments, we get the following:
Proposition 6 (Random Graphs).",4.3. Expander graphs,[0],[0]
"The adjacency matrix of a randomly constructed bipartite graph is, with overwhelming probability, k-disjunct with m = O(k2 log(d/k)).",4.3. Expander graphs,[0],[0]
"More generally, for every α ∈",4.3. Expander graphs,[0],[0]
"[0, 1), random graphs are (k, e)-disjunct, with e = Ω(αk log d/(1− α2))",4.3. Expander graphs,[0],[0]
"with m = Ω(αk2 log(d/k)/(1− α2)).
",4.3. Expander graphs,[0],[0]
"There is an explicit construction of unbalanced (k, )- lossless expanders for any setting of d and m and is, to our knowledge, the best possible, in (Capalbo et al., 2002).
",4.3. Expander graphs,[0],[0]
These constructions yield explicit k-disjunct graphs with m = O(k2quasipoly(log d)).,4.3. Expander graphs,[0],[0]
"Other random constructions are discussed in the supplementary.
",4.3. Expander graphs,[0],[0]
"With all the above constructions, we can correct a reasonably large number of e errors by the binary classifiers.",4.3. Expander graphs,[0],[0]
The number of classifiers required for MLGT will be m = O(k2 log d) which is more than the CS approach where m = O(k log d).,4.3. Expander graphs,[0],[0]
"However, our analysis is for the worst case: as we saw in Theorem 1, if we tolerate a small ε fraction of error in recovery, we can achieve m = O(k log d) for MLGT as well.",4.3. Expander graphs,[0],[0]
"Moreover, MLGT yields zero prediction error for a k sparse label vector even if up to e/2 classifiers mis-classify.",4.3. Expander graphs,[0],[0]
"With MLCS, we only get an error guarantees and with respect to 2-norm (not Hamming distance which is more natural for classification).",4.3. Expander graphs,[0],[0]
"Here we summarize the theoretical error guarantees for multilabel classification using group testing (MLGT).
",5. Error Analysis,[0],[0]
Theorem 2.,5. Error Analysis,[0],[0]
"Consider MLGT with an m× d binary matrix A, and a label vector y with sparsity at most k.",5. Error Analysis,[0],[0]
Suppose,5. Error Analysis,[0],[0]
"A is (k, e)-disjunct, and we use Algorithm 2 during prediction.",5. Error Analysis,[0],[0]
Let ŷ be the predicted label vector and ∆(·) denote the Hamming distance between vectors.,5. Error Analysis,[0],[0]
"If t number of binary classifiers that make errors in prediction, then we have
• If t ≤ be/2c, then the prediction error ∆(y, ŷ) = 0.",5. Error Analysis,[0],[0]
•,5. Error Analysis,[0],[0]
"If t > be/2c, ∆(y, ŷ) ≤ w(t−e/2) (Hamming error),
where w is the maximum weight of rows in A.",5. Error Analysis,[0],[0]
"In particular, the error rate (average error per class) will be w d (t− e/2).
",5. Error Analysis,[0],[0]
"If A is a k-disjunct with ε error tolerance, then the prediction error will be at most (w(t− e/2) + εk).
",5. Error Analysis,[0],[0]
Proof.,5. Error Analysis,[0],[0]
"When, t ≤ e/2, we know that the decoding algorithm will still recover the exact label vector due to the error correcting property of the (k, e)-disjunct matrix.",5. Error Analysis,[0],[0]
"When, t > e/2, e/2 of the errors are corrected.",5. Error Analysis,[0],[0]
"For every remaining t − e/2 errors, if w is the maximum weight of rows in A, a maximum of w errors can occur in the predicted label.",5. Error Analysis,[0],[0]
"This is because, the support different |A(l)\ẑ| can change for a maximum of w columns.",5. Error Analysis,[0],[0]
"Hence, the error can be at most w(t − e/2), and the error rate will be wd (t − e/2).",5. Error Analysis,[0],[0]
"For the k-disjunct matrix with ε error tolerance, the decoding algorithm can make up to εk errors in addition to w(t− e/2).
",5. Error Analysis,[0],[0]
Let us see how the error-rate of various group testing constructions translate to MLGT.,5. Error Analysis,[0],[0]
"In the case of a random matrix construction, we have w ≈ d/k.",5. Error Analysis,[0],[0]
"So, the error rate for this matrix will be (t−e/2)/k.",5. Error Analysis,[0],[0]
"From proposition 1, we can take m = k2 log d, and e = 3k log d. Hence, the error rate
for a random (k, e) disjunct matrix will be t/k− 3/2 log d, for any t > 3/2k log d. For any t less than this the error rate will be zero.",5. Error Analysis,[0],[0]
"Similarly, we can see that the randomized construction of Thm. 1 with m = O(k log d) rows, gives the average error rate is (t/k−O(log d) + εk/d) for t > k log d.",5. Error Analysis,[0],[0]
"The error rates of other constructions can be calculated in the same way, see supplementary.
",5. Error Analysis,[0],[0]
The above theorem also shows that a Hamming error regret R (R ≡ |error in the method - least error possible|) in the binary classifiers will transform linearly to the overall regret of at most w(R − e/2) for the MLGT.,5. Error Analysis,[0],[0]
"For the CS approach, the results in (Hsu et al., 2009) show that a L2 regret R2 (an L2-norm error regret) in the regressor will translate as √ R2 to the overall regret (which is worse).",5. Error Analysis,[0],[0]
"This is because, a CS based analysis involves, L2-norm errors and Restricted Isometric Property (RIP) of the compression matrix with respect to L2 norm.",5. Error Analysis,[0],[0]
"However, L2 error metric is never used for evaluation in practice.
",5. Error Analysis,[0],[0]
"Hamming Loss: Since we operate in the binary field, we derive error (regret) bounds, as well as present experimental results with respect to Hamming loss.",5. Error Analysis,[0],[0]
"In certain applications we may be interested in only predicting the top k1 < k labels correctly, e.g., tagging and recommendation.",5. Error Analysis,[0],[0]
"In such situations, it has been argued that the Hamming loss is not a perfect measure (Jain et al., 2016), and alternate measures such as Precison@k (defined later) for k = 1, 3, 5 have been used (Agrawal et al., 2013).",5. Error Analysis,[0],[0]
"However, these measures assume there is a ranking amongst the labels, which can be obtained only when operating in the real space.",5. Error Analysis,[0],[0]
"Also, these measures ignore the false labels.",5. Error Analysis,[0],[0]
Our approach considers labels as just binary vectors (cannot rank) and attempts to predict all labels correctly (hence Hamming loss).,5. Error Analysis,[0],[0]
Almost all available mutlilabel datasets have binary label vectors and do not come with the priority information of labels within the large output classes.,5. Error Analysis,[0],[0]
"There are recent works which try to rank the labels first and then classify, e.g. (Jain et al., 2016; Chzhen et al., 2017).",5. Error Analysis,[0],[0]
"Hamming loss is nonetheless an interesting error metric for applications where we need to predict all labels correctly and require few/no false labels, hence is worth analyzing.",5. Error Analysis,[0],[0]
"Most of the recent popular (embedding) methods tend to give good results with respect to Precison@k, but give poor Hamming errors due to large number of false labels.",5. Error Analysis,[0],[0]
Our approach gives very low Hamming loss both theoretically and practically.,5. Error Analysis,[0],[0]
"In this section, we illustrate the performance of the proposed group testing approach in the multilabel classification problems (MLGT) via several numerical experiments on various datasets.
",6. Numerical Experiments,[0],[0]
Datasets: We use some popular publicly available multilabel datasets in our experiments.,6. Numerical Experiments,[0],[0]
"All datasets were obtained from The Extreme Classification Repository1 (Bhatia et al., 2015).",6. Numerical Experiments,[0],[0]
Details about the datasets and the references for their original sources can be found in the repository.,6. Numerical Experiments,[0],[0]
"Table 1 in the supplementary gives data details.
",6. Numerical Experiments,[0],[0]
"Constructions: For MLGT, we consider three different group testing constructions.",6. Numerical Experiments,[0],[0]
"The Kautz-Singleton construction with q-ary Reed-Solomon (RS) codes, where we use RS codes (MacWilliams & Sloane, 1977) with q = 16 and m = 240; and q = 8 and m = 56.",6. Numerical Experiments,[0],[0]
"To get desired number of codewords (equal to number of labels), we use appropriate message length.",6. Numerical Experiments,[0],[0]
"For example, if d ≤ 4096, q = 16, then we use message length of 3, and if d ≤ 65536, we use message length of 5.",6. Numerical Experiments,[0],[0]
"We also use two random GT constructions, namely, the random expander graphs and the sparse random constructions discussed in sec. 4.",6. Numerical Experiments,[0],[0]
"For MLCS (compressed sensing approach), we again consider three different types compression matrices, namely, random Gaussian matrices, compressed Hadamard matrices and random expander graphs (expander graphs have been used for CS too (Jafarpour et al., 2009)).
",6. Numerical Experiments,[0],[0]
Evaluation metrics: Two evaluation metrics are used to analyze the performances of the different methods.,6. Numerical Experiments,[0],[0]
"First is the Hamming loss error, the Hamming distance between the predicted vector ŷ and the actual label vector y, ∆(y, ŷ).",6. Numerical Experiments,[0],[0]
"This metric tells us how close is the recovered vector ŷ is from the exact label vector y, and is more suitable for binary vectors.",6. Numerical Experiments,[0],[0]
Hamming loss captures the information of both correct predictions and false labels.,6. Numerical Experiments,[0],[0]
All prediction errors reported (training and test) are Hamming loss errors.,6. Numerical Experiments,[0],[0]
"The second metric used is Precison@k (P@k), which is a popular metric used in MLC literature (Agrawal et al., 2013).",6. Numerical Experiments,[0],[0]
This measures the precision of predicting the first k coordinates |supp(ŷ1:k) ∩ supp(y)|/k.,6. Numerical Experiments,[0],[0]
"Since we cannot score the labels, we use k = nnz(y) the output sparsity of the true label for this measure.",6. Numerical Experiments,[0],[0]
This is equivalent to checking whether the method predicted all the labels the data belongs to correctly or not (ignoring misclassification).,6. Numerical Experiments,[0],[0]
"When Precision@k for k = 1, 3, 5 are used, one is checking whether the top 1, 3 or 5 labels are predicted correctly (ignoring other and false labels).
",6. Numerical Experiments,[0],[0]
MLGT vs MLCS:,6. Numerical Experiments,[0],[0]
"In the first set of experiments, we compare the performances of the group testing approach (MLGT) and the compressed sensing approach (MLCS) using different group testing constructions and different compression matrices.",6. Numerical Experiments,[0],[0]
A least squares binary classifier was used {wj}mj=1 for MLGT.,6. Numerical Experiments,[0],[0]
Least squares regression with `2 regularization (ridge regression) is used as the regressors for MLCS and other embedding based methods.,6. Numerical Experiments,[0],[0]
"Orthogo-
1https://manikvarma.github.io/downloads/ XC/XMLRepository.html
nal Matching Pursuit (OMP) (Tropp & Gilbert, 2007) was used for sparse recovery in MLCS.",6. Numerical Experiments,[0],[0]
"Additional details are given in supplementary.
",6. Numerical Experiments,[0],[0]
Table 1 compares the performances of MLCS and MLGT for different CS and GT matrices on different datasets.,6. Numerical Experiments,[0],[0]
The average training and the test errors (Hamming losses) are reported along with the average Precison@k obtained for training and test data.,6. Numerical Experiments,[0],[0]
The methods and the number of classifiers/regressors m used are also listed.,6. Numerical Experiments,[0],[0]
"For example, GT:RS code q=16, implies MLGT was the method with the RS code construction with q=16.",6. Numerical Experiments,[0],[0]
"The number of training points n, test points nt and the number of features p used in the experiments are reported next to the datasets.",6. Numerical Experiments,[0],[0]
"kmax means the maximum sparsity in the data (only those data points below this sparsity were used), anf bark is the average sparsity.",6. Numerical Experiments,[0],[0]
"For the latter three datasets, the feature space was reduced to select only dominant features (data are very sparse and only few features are prominent).
",6. Numerical Experiments,[0],[0]
"We observe that, the MLGT method with all the three GT constructions outperforms the MLCS method.",6. Numerical Experiments,[0],[0]
"In most cases, the training errors (almost zero) and Precison@k (almost one) for MLGT methods are extremely good.",6. Numerical Experiments,[0],[0]
"This is because, the binary classifiers are optimally trained on the reduced binary vectors and since the matrices used
were k-disjunct, we had zero recovery error in most cases.",6. Numerical Experiments,[0],[0]
"Hence, the predicted labels for training data were extremely accurate.",6. Numerical Experiments,[0],[0]
The results on test data are also better for MLGT in almost all cases.,6. Numerical Experiments,[0],[0]
"The results we obtained for the dataset Delicious were consistently poor, see supplementary.",6. Numerical Experiments,[0],[0]
"We also observed that MLGT is significantly faster than MLCS (as expected) because, MLCS uses an optimization algorithm (OMP) for recovery of labels, see Table 3 for runtimes.
",6. Numerical Experiments,[0],[0]
"In the prediction algorithm of MLGT, we have a parameter e, the number of errors the algorithm should try to correct.",6. Numerical Experiments,[0],[0]
"The ideal value for e will depend on the GT matrix used, the values ofm, k and d. However, note that we can test for different values of e at no additional cost.",6. Numerical Experiments,[0],[0]
"That is, once we compute the Boolean AND between the predicted reduced vector and the GT matrix (the dominant operation), we can get different prediction vectors for a range of e and choose an e that gives the highest training P@k.
",6. Numerical Experiments,[0],[0]
"Figure 1 plots the average training and test errors and average Precison@k against the sparsity k of the label vectors (data with label sparsity k used) obtained for MLGT and MLCS methods with the three different matrices respectively, seen in Table 1.",6. Numerical Experiments,[0],[0]
The dataset used was RCV1-2K. This dataset has at least 2000 training points and 500 testing points for each label sparsity ranging from 1 to 10.,6. Numerical Experiments,[0],[0]
We observe that the training error for MLGT methods are almost zero and training Precison@k almost one.,6. Numerical Experiments,[0],[0]
(This behavior was seen in Table 1 as well).,6. Numerical Experiments,[0],[0]
"Results with test data
for MLGT are also impressive, achieving Precison@k of almost 0.8 for small k.
One vs all: We next compare MLGT against the one versus all (OvsA) method on two small datasets.",6. Numerical Experiments,[0],[0]
"Note that OvsA required d classifiers to be trained, hence is impractical for larger datasets, and we will need a distributed implementation such as DiSMEC (Babbar & Schölkopf, 2017).",6. Numerical Experiments,[0],[0]
Table 2 gives the results for MLGT and OvsA methods for two small datasets. n,6. Numerical Experiments,[0],[0]
"= 5000,nt = 1000, and for MLGT m = 50.",6. Numerical Experiments,[0],[0]
The table lists the Hamming test errors and P@k for the two methods.,6. Numerical Experiments,[0],[0]
The table also gives the overall runtimes for the two methods.,6. Numerical Experiments,[0],[0]
"We note that wrt. to both metrics, MLGT performs better than OvsA. This is due to two reasons.",6. Numerical Experiments,[0],[0]
"First, MLGT groups the labels hence has more training samples per group, yielding better classifiers.",6. Numerical Experiments,[0],[0]
"Second, the error correction by the prediction algorithm corrects few classification errors.",6. Numerical Experiments,[0],[0]
"Clearly, MLGT is faster than OvsA. However, OvsA gives better training errors.
",6. Numerical Experiments,[0],[0]
"Embedding methods: In the next set of experiments, we compare the performance of MLGT against the popular embedding based methods.",6. Numerical Experiments,[0],[0]
We compare with the following methods.,6. Numerical Experiments,[0],[0]
"ML-CSSP, is an embedding method based on column subset selection (Bi & Kwok, 2013).",6. Numerical Experiments,[0],[0]
"PLST, is Principal Label Space Transformation (Tai & Lin, 2012), an embedding method based on SVD (code is made available online by the authors).",6. Numerical Experiments,[0],[0]
"SLEEC, Sparse Local Embeddings for Extreme Classification (Bhatia et al., 2015), is the state of the art embedding method based on clustering using nearest neighbors and then embedding in the cluster space (code is made available online by the authors).",6. Numerical Experiments,[0],[0]
"For MLGT, we use the random expander graph constructions.",6. Numerical Experiments,[0],[0]
"For MLCS, we use random Gaussian matrices.",6. Numerical Experiments,[0],[0]
"Same least squares regressor was used in all the latter four methods.
",6. Numerical Experiments,[0],[0]
Table 3 lists the test (Hamming) errors obtained for the different methods on various datasets.,6. Numerical Experiments,[0],[0]
We use smaller datasets since the embedding based methods do not scale well for large datasets.,6. Numerical Experiments,[0],[0]
We also used only 2000 training points and 500 test points in each cases.,6. Numerical Experiments,[0],[0]
We observe that MLGT outperforms the other methods in most cases.,6. Numerical Experiments,[0],[0]
"The datasets have very sparse label (avg. sparsity of around k̄ ≈ 4), but the outputs of MLCSSP and PLST are not very sparse.",6. Numerical Experiments,[0],[0]
"Hence, we see high Hamming error for these two methods, since they yield a lot of false labels.",6. Numerical Experiments,[0],[0]
"Moreover, these embedding methods are significantly more expensive than MLGT for larger datasets.",6. Numerical Experiments,[0],[0]
"The runtimes for each method are also listed in the table.
",6. Numerical Experiments,[0],[0]
"The runtimes reported (using cputime in Matlab) includes generation of compression matrices, multiplying the matrix to the label vectors (boolean OR/SVD computation), training the m classifiers, and prediction of n training and nt test points.",6. Numerical Experiments,[0],[0]
"SLEEC performs reasonably well on all datasets (the ideal parameters to be set in this algorithm for each of these datasets were provided by the authors online), and gives better P@k than MLGT for some datasets.",6. Numerical Experiments,[0],[0]
"For Delicious dataset, the value of k is high and SLEEC beats MLGT.",6. Numerical Experiments,[0],[0]
"However, SLEEC algorithm has many parameters to set, and for larger datasets, the algorithm is very expensive compared to all other methods.
",6. Numerical Experiments,[0],[0]
These experiments illustrate that MLGT performs exceptionally well in practice.,6. Numerical Experiments,[0],[0]
The concatenated RS codes and the bipartite expander graphs constructions proposed are simple to generate and they exist for large sizes.,6. Numerical Experiments,[0],[0]
"Hence, these constructions can be easy applied to extreme classification problems.",6. Numerical Experiments,[0],[0]
Authors would like to thank Dr. Manik Varma and his team for making many MLC datasets and codes available online.,Acknowledgements,[0],[0]
"This work was supported by NSF under grant NSF/CCF1318597, NSF/CCF-1318093, NSF/CCF 1642550.",Acknowledgements,[0],[0]
"In recent years, the multiclass and mutlilabel classification problems we encounter in many applications have very large (10 − 10) number of classes.",abstractText,[0],[0]
"However, each instance belongs to only one or few classes, i.e., the label vectors are sparse.",abstractText,[0],[0]
"In this work, we propose a novel approach based on group testing to solve such large multilabel classification problems with sparse label vectors.",abstractText,[0],[0]
"We describe various group testing constructions, and advocate the use of concatenated Reed Solomon codes and unbalanced bipartite expander graphs for extreme classification problems.",abstractText,[0],[0]
The proposed approach has several advantages theoretically and practically over existing popular methods.,abstractText,[0],[0]
Our method operates on the binary alphabet and can utilize the well-established binary classifiers for learning.,abstractText,[0],[0]
The error correction capabilities of the codes are leveraged for the first time in the learning problem to correct prediction errors.,abstractText,[0],[0]
"Even if a linearly growing number of classifiers mis-classify, these errors are fully corrected.",abstractText,[0],[0]
We establish Hamming loss error bounds for the approach.,abstractText,[0],[0]
"More importantly, our method utilizes a simple prediction algorithm and does not require matrix inversion or solving optimization problems making the algorithm very inexpensive.",abstractText,[0],[0]
Numerical experiments with various datasets illustrate the superior performance of our method.,abstractText,[0],[0]
Multilabel Classification with Group Testing and Codes,title,[0],[0]
"In numerous applications in engineering and sciences, data are often organized in a multilevel structure.",1. Introduction,[0],[0]
"For instance, a typical structural view of text data in machine learning is to have words grouped into documents, documents are grouped into corpora.",1. Introduction,[0],[0]
A prominent strand of modeling and algorithmic works in the past couple decades has been to discover latent multilevel structures from these hierarchically structured data.,1. Introduction,[0],[0]
"For specific clustering tasks, one may be interested in simultaneously partitioning the data in each group (to obtain local clusters) and partitioning a collection of data groups (to obtain global clusters).",1. Introduction,[0],[0]
"Another concrete example is the problem of clustering images (i.e., global clusters) where each image contains partions of multiple annotated regions (i.e., local clusters) (Oliva and Torralba,
1Department of Statistics, University of Michigan, USA.",1. Introduction,[0],[0]
2Adobe Research.,1. Introduction,[0],[0]
"3Center for Pattern Recognition and Data Analytics (PRaDA), Deakin University, Australia.",1. Introduction,[0],[0]
"Correspondence to: Nhat Ho <minhnhat@umich.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"1Code is available at https://github.com/ moonfolk/Multilevel-Wasserstein-Means
2001).",1. Introduction,[0],[0]
"While hierachical clustering techniques may be employed to find a tree-structed clustering given a collection of data points, they are not applicable to discovering the nested structure of multilevel data.",1. Introduction,[0],[0]
"Bayesian hierarchical models provide a powerful approach, exemplified by influential works such as (Blei et al., 2003; Pritchard et al., 2000; Teh et al., 2006).",1. Introduction,[0],[0]
"More specific to the simultaneous and multilevel clustering problem, we mention the paper of (Rodriguez et al., 2008).",1. Introduction,[0],[0]
"In this interesting work, a Bayesian nonparametric model, namely the nested Dirichlet process (NDP) model, was introduced that enables the inference of clustering of a collection of probability distributions from which different groups of data are drawn.",1. Introduction,[0],[0]
"With suitable extensions, this modeling framework has been further developed for simultaneous multilevel clustering, see for instance, (Wulsin et al., 2016; Nguyen et al., 2014; Huynh et al., 2016).
",1. Introduction,[0],[0]
"The focus of this paper is on the multilevel clustering problem motivated in the aforementioned modeling works, but we shall take a purely optimization approach.",1. Introduction,[0],[0]
We aim to formulate optimization problems that enable the discovery of multilevel clustering structures hidden in grouped data.,1. Introduction,[0],[0]
Our technical approach is inspired by the role of optimal transport distances in hierarchical modeling and clustering problems.,1. Introduction,[0],[0]
"The optimal transport distances, also known as Wasserstein distances (Villani, 2003), have been shown to be the natural distance metric for the convergence theory of latent mixing measures arising in both mixture models (Nguyen, 2013) and hierarchical models (Nguyen, 2016).",1. Introduction,[0],[0]
"They are also intimately connected to the problem of clustering — this relationship goes back at least to the work of (Pollard, 1982), where it is pointed out that the well-known K-means clustering algorithm can be directly linked to the quantization problem — the problem of determining an optimal finite discrete probability measure that minimizes its second-order Wasserstein distance from the empirical distribution of given data (Graf and Luschgy, 2000).
",1. Introduction,[0],[0]
"If one is to perform simultaneous K-means clustering for hierarchically grouped data, both at the global level (among groups), and local level (within each group), then this can be achieved by a joint optimization problem defined with suitable notions of Wasserstein distances inserted into the objective function.",1. Introduction,[0],[0]
"In particular, multilevel clustering requires the optimization in the space of probability mea-
sures defined in different levels of abstraction, including the space of measures of measures on the space of grouped data.",1. Introduction,[0],[0]
"Our goal, therefore, is to formulate this optimization precisely, to develop algorithms for solving the optimization problem efficiently, and to make sense of the obtained solutions in terms of statistical consistency.
",1. Introduction,[0],[0]
"The algorithms that we propose address directly a multilevel clustering problem formulated from a purely optimization viewpoint, but they may also be taken as a fast approximation to the inference of latent mixing measures that arise in the nested Dirichlet process of (Rodriguez et al., 2008).",1. Introduction,[0],[0]
"From a statistical viewpoint, we shall establish a consistency theory for our multilevel clustering problem in the manner achieved for K-means clustering (Pollard, 1982).",1. Introduction,[0],[0]
"From a computational viewpoint, quite interestingly, we will be able to explicate and exploit the connection betwen our optimization and that of finding the Wasserstein barycenter (Agueh and Carlier, 2011), an interesting computational problem that have also attracted much recent interests, e.g., (Cuturi and Doucet, 2014).
",1. Introduction,[0],[0]
"In summary, the main contributions offered in this work include (i) a new optimization formulation to the multilevel clustering problem using Wasserstein distances defined on different levels of the hierarchical data structure; (ii) fast algorithms by exploiting the connection of our formulation to the Wasserstein barycenter problem; (iii) consistency theorems established for proposed estimates under very mild condition of data’s distributions; (iv) several flexibile alternatives by introducing constraints that encourage the borrowing of strength among local and global clusters, and (v) finally, demonstration of efficiency and flexibility of our approach in a number of simulated and real data sets.
",1. Introduction,[0],[0]
The paper is organized as follows.,1. Introduction,[0],[0]
"Section 2 provides preliminary background on Wasserstein distance, Wasserstein barycenter, and the connection between K-means clustering and the quantization problem.",1. Introduction,[0],[0]
"Section 3 presents several optimization formulations of the multilevel clusering problem, and the algorithms for solving them.",1. Introduction,[0],[0]
Section 4 establishes consistency results of the estimators introduced in Section 4.,1. Introduction,[0],[0]
Section 5 presents careful simulation studies with both synthetic and real data.,1. Introduction,[0],[0]
"Finally, we conclude the paper with a discussion in Section 6.",1. Introduction,[0],[0]
"Additional technical details, including all proofs, are given in the Supplement.",1. Introduction,[0],[0]
"For any given subset Θ ⊂ Rd, let P(Θ) denote the space of Borel probability measures on Θ. The Wasserstein space of order r ∈",2. Background,[0],[0]
"[1,∞) of probability measures on Θ is de-
fined as Pr(Θ) = { G ∈ P(Θ) : ´ ‖x‖rdG(x) < ∞ } ,
where ‖.‖ denotes Euclidean metric in Rd.",2. Background,[0],[0]
"Addition-
",2. Background,[0],[0]
"ally, for any k ≥ 1 the probability simplex is denoted by ∆k = { u ∈",2. Background,[0],[0]
"Rk : ui ≥ 0, k∑ i=1",2. Background,[0],[0]
ui,2. Background,[0],[0]
= 1 },2. Background,[0],[0]
.,2. Background,[0],[0]
"Finally, let Ok(Θ) (resp., Ek(Θ)) be the set of probability measures with at most (resp., exactly) k support points in Θ.
Wasserstein distances For any elements G and G′ in Pr(Θ) where r ≥ 1, the Wasserstein distance of order r between G and G′ is defined as (cf. (Villani, 2003)):
Wr(G,G ′) =",2. Background,[0],[0]
"( inf
π∈Π(G,G′)
ˆ
Θ2
‖x−",2. Background,[0],[0]
"y‖rdπ(x, y) )",2. Background,[0],[0]
"1/r
where Π(G,G′) is the set of all probability measures on Θ×Θ that have marginalsG andG′.",2. Background,[0],[0]
"In words,W rr (G,G′) is the optimal cost of moving mass from G to G′, where the cost of moving unit mass is proportional to r-power of Euclidean distance in Θ. When G and G′ are two discrete measures with finite number of atoms, fast computation of Wr(G,G
′) can be achieved (see, e.g., (Cuturi, 2013)).",2. Background,[0],[0]
"The details of this are deferred to the Supplement.
",2. Background,[0],[0]
"By a recursion of concepts, we can speak of measures of measures, and define a suitable distance metric on this abstract space: the space of Borel measures on Pr(Θ), to be denoted by Pr(Pr(Θ)).",2. Background,[0],[0]
"This is also a Polish space (that is, complete and separable metric space) as Pr(Θ) is a Polish space.",2. Background,[0],[0]
"It will be endowed with a Wasserstein metric of order r that is induced by a metric Wr on Pr(Θ) as follows (cf. Section 3 of (Nguyen, 2016)): for any D,D′ ∈ Pr(Pr(Θ))
",2. Background,[0],[0]
"Wr(D,D′) := ( inf ˆ
Pr(Θ)2
W rr (G,G ′)dπ(G,G′)
)1/r
where the infimum in the above ranges over all π ∈ Π(D,D′) such that Π(D,D′) is the set of all probability measures on Pr(Θ)×Pr(Θ) that has marginals D and D′.",2. Background,[0],[0]
"In words, Wr(D,D′) corresponds to the optimal cost of moving mass from D to D′, where the cost of moving unit mass in its space of support Pr(Θ) is proportional to the r-power of the Wr distance in Pr(Θ).",2. Background,[0],[0]
"Note a slight notational abuse —Wr is used for both Pr(Θ) and Pr(Pr(Θ)), but it should be clear which one is being used from context.
",2. Background,[0],[0]
Wasserstein barycenter,2. Background,[0],[0]
"Next, we present a brief overview of Wasserstein barycenter problem, first studied by (Agueh and Carlier, 2011) and subsequentially many others (e.g., (Benamou et al., 2015; Solomon et al., 2015; Álvarez Estebana et al., 2016)).",2. Background,[0],[0]
"Given probability measures P1, P2, . . .",2. Background,[0],[0]
", PN ∈ P2(Θ) for N ≥ 1, their Wasserstein barycenter PN,λ is such that
PN,λ = arg min P∈P2(Θ) N∑ i=1",2. Background,[0],[0]
"λiW 2 2 (P, Pi) (1)
where λ ∈ ∆N denote weights associated with P1, . . .",2. Background,[0],[0]
", PN .",2. Background,[0],[0]
"When P1, . . .",2. Background,[0],[0]
", PN are discrete measures with finite number of atoms and the weights λ are uniform, it was shown by (Anderes et al., 2015) that the problem of finding Wasserstein barycenter PN,λ over the space P2(Θ) in (1) is reduced to search only over a much simpler space
Ol(Θ) where l = N∑ i=1 si −N + 1",2. Background,[0],[0]
and si is the number of components of Pi for all 1 ≤ i ≤ N .,2. Background,[0],[0]
"Efficient algorithms for finding local solutions of the Wasserstein barycenter problem over Ok(Θ) for some k ≥ 1 have been studied recently in (Cuturi and Doucet, 2014).",2. Background,[0],[0]
These algorithms will prove to be a useful building block for our method as we shall describe in the sequel.,2. Background,[0],[0]
"The notion of Wasserstein barycenter has been utilized for approximate Bayesian inference (Srivastava et al., 2015).
",2. Background,[0],[0]
"K-means as quantization problem The well-known Kmeans clustering algorithm can be viewed as solving an optimization problem that arises in the problem of quantization, a simple but very useful connection (Pollard, 1982; Graf and Luschgy, 2000).",2. Background,[0],[0]
The connection is the following.,2. Background,[0],[0]
"Given n unlabelled samples Y1, . . .",2. Background,[0],[0]
", Yn ∈ Θ. Assume that these data are associated with at most k clusters where k ≥ 1 is some given number.",2. Background,[0],[0]
"The K-means problem finds the set S containing at most k elements θ1, . . .",2. Background,[0],[0]
", θk ∈ Θ that minimizes the following objective
inf S:|S|≤k
1
n n∑ i=1",2. Background,[0],[0]
"d2(Yi, S).",2. Background,[0],[0]
"(2)
Let Pn = 1
n n∑ i=1 δYi be the empirical measure of data
Y1, . . .",2. Background,[0],[0]
", Yn.",2. Background,[0],[0]
"Then, problem (2) is equivalent to finding a discrete probability measure G which has finite number of support points and solves:
inf G∈Ok(Θ)
",2. Background,[0],[0]
"W 22 (G,Pn).",2. Background,[0],[0]
"(3)
Due to the inclusion of Wasserstein metric in its formulation, we call this a Wasserstein means problem.",2. Background,[0],[0]
This problem can be further thought of as a Wasserstein barycenter problem where N = 1.,2. Background,[0],[0]
"In light of this observation, as noted by (Cuturi and Doucet, 2014), the algorithm for finding the Wasserstein barycenter offers an alternative for the popular Loyd’s algorithm for determing local minimum of the K-means objective.",2. Background,[0],[0]
"Givenm groups of nj exchangeable data pointsXj,i where 1 ≤ j ≤ m, 1 ≤ i ≤ nj , i.e., data are presented in a two-level grouping structure, our goal is to learn about the two-level clustering structure of the data.",3. Clustering with multilevel structure data,[0],[0]
"We want to obtain simultaneously local clusters for each data group, and global clusters among all groups.",3. Clustering with multilevel structure data,[0],[0]
"For any j = 1, . . .",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
",m, we denote the empirical measure for group j by P jnj :",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"= 1
nj nj∑ i=1",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"δXj,i .",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"Throughout this sec-
tion, for simplicity of exposition we assume that the number of both local and global clusters are either known or bounded above by a given number.",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"In particular, for local clustering we allow group j to have at most kj clusters for j = 1, . . .",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
",m. For global clustering, we assume to have M group (Wasserstein) means among the m given groups.
",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"High level idea For local clustering, for each j = 1, . . .",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
",m, performing a K-means clustering for group j, as expressed by (3), can be viewed as finding a finite discrete measure Gj ∈ Okj (Θ) that minimizes squared Wasserstein distance W 22",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"(Gj , P j nj ).",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"For global clustering, we are interested in obtaining clusters out of m groups, each of which is now represented by the discrete measure Gj , for j = 1, . . .",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
",m. Adopting again the viewpoint of Eq.",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"(3), provided that all of Gjs are given, we can apply K-means quantization method to find their distributional clusters.",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"The global clustering in the space of measures of measures on Θ can be succintly expressed by
inf H∈EM (P2(Θ))
",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"W 22
( H, 1
m m∑ j=1 δGj ) .
",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"However, Gj are not known — they have to be optimized through local clustering in each data group.
",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"MWM problem formulation We have arrived at an objective function for jointly optimizing over both local and global clusters
inf Gj∈Okj (Θ), H∈EM (P2(Θ))
",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"m∑ j=1 W 22 (Gj , P j nj )",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
+,3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"W 2 2 (H, 1 m m∑ j=1 δGj ).",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"(4)
We call the above optimization the problem of Multilevel Wasserstein Means (MWM).",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"The notable feature of MWM is that its loss function consists of two types of distances associated with the hierarchical data structure: one is distance in the space of measures, e.g., W 22 (Gj , P j nj ), and the other in space of measures of measures, e.g., W 22 (H, 1
m m∑ j=1 δGj ).",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"By adopting K-means optimization to
both local and global clustering, the multilevel Wasserstein means problem might look formidable at the first sight.",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"Fortunately, it is possible to simplify this original formulation substantially, by exploiting the structure ofH.
Indeed, we can show that formulation (4) is equivalent to the following optimization problem, which looks much simpler as it involves only measures on Θ:
inf Gj∈Okj (Θ),H m∑ j=1 W 22 (Gj , P j nj ) + d2W2(Gj ,H) m (5)
",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"where d2W2(G,H) := min1≤i≤M W 22 (G,Hi) and H = (H1, . .",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
.,3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
",HM ), with each Hi ∈ P2(Θ).",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
The proof of this equivalence is deferred to Proposition B.4 in the Supplement.,3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
"Before going into to the details of the algorithm for solving (5) in Section 3.1.2, we shall present some simpler cases, which help to illustrate some properties of the optimal solutions of (5), while providing insights of subsequent developments of the MWM formulation.",3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
Readers may proceed directly to Section 3.1.2 for the description of the algorithm in the first reading.,3.1. Multilevel Wasserstein Means (MWM) Algorithm,[0],[0]
Example 1.,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"Suppose kj = 1 and nj = n for all 1 ≤ j ≤ m, and M = 1.",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
Write H = H ∈ P2(Θ).,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"Under this setting, the objective function (5) can be rewritten as
inf θj∈Θ,
H∈P2(Θ)
m∑ j=1 n∑ i=1",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"‖θj −Xj,i‖2 +",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"W 22 (δθj , H)/m, (6)
where Gj = δθj for any 1 ≤ j ≤ m.",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"From the result of Theorem A.1 in the Supplement,
inf θj∈Θ m∑ j=1 W 22 (δθj , H) ≥ inf H∈E1(Θ) m∑ j=1 W 22 (Gj , H)
",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"= m∑ j=1 ‖θj − ( m∑ i=1 θi)/m‖2,
where second infimum is achieved when H",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
= δ,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
( m∑ j=1 θj)/m .,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"Thus, objective function (6) may be rewritten as
inf θj∈Θ m∑ j=1 n∑ i=1",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
‖θj,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"−Xj,i‖2 +",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
‖mθj,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
− ( m∑ l=1 θl)‖2/m3.,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
Write Xj = ( n∑ i=1,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"Xj,i)/n for all 1 ≤ j ≤ m. As m ≥ 2, we can check that the unique optimal solutions for the
above optimization problem are θj = (
(m2n + 1)Xj",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
+∑ i 6=j Xi ) /(m2n,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
+ m) for any 1 ≤ j ≤ m.,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"If we further assume that our dataXj,i are i.i.d samples from probability measure P j having mean µj = EX∼P j (X) for any 1 ≤ j ≤ m, the previous result implies that θi",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
6→ θj for almost surely as long as µi 6= µj .,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"As a consequence, if µj are pairwise different, the multi-level Wasserstein means under that simple scenario of (5) will not have identical centers among local groups.",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"On the other hand, we have W 22 (Gi, Gj) = ‖θi",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"− θj‖2 =( mn
mn+ 1
)2 ‖Xi − Xj‖2.",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"Now, from the definition of
Wasserstein distance
W 22 (P i n, P j n) =",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"min
σ
1
n n∑ l=1 ‖Xi,l −Xj,σ(l)‖2
≥ ‖Xi −Xj‖2,
where σ in the above sum varies over all the permutation of {1, 2, . . .",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
", n} and the second inequality is due to Cauchy-Schwarz’s inequality.",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"It implies that as long as W 22 (P i n, P j n) is small, the optimal solutionGi andGj of (6) will be sufficiently close to each other.",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"By letting n→∞, we also achieve the same conclusion regarding the asymptotic behavior of Gi and Gj with respect to W2(P i, P j).
",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
Example 2.,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
kj = 1 and nj = n for all 1 ≤ j ≤ m,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
and M = 2.,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"Write H = (H1, H2).",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"Moreover, assume that there is a strict subset A of {1, 2, . . .",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
",m} such that
max { max i,j∈A W2(P i n, P j n),
max i,j∈Ac
W2(P i n, P j n)
} min
i∈A,j∈Ac W2(P
i n, P j n),
i.e., the distances of empirical measures P in and P j n",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
when i and j belong to the same set A or Ac are much less than those when i and j do not belong to the same set.,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"Under this condition, by using the argument from part (i) we can write the objective function (5) as
inf θj∈Θ,
H1∈P2(Θ)
∑ j∈A n∑ i=1",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"‖θj −Xj,i‖2 +",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"W 22 (δθj , H1)",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"|A| +
inf θj∈Θ,
H2∈P2(Θ)
∑ j∈Ac n∑ i=1",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"‖θj −Xj,i‖2 +",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"W 22 (δθj , H2) |Ac| .
",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"The above objective function suggests that the optimal solutions θi, θj (equivalently, Gi and Gj) will not be close to each other as long as i and j do not belong to the same set A or Ac, i.e., P in and P j n are very far.",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"Therefore, the two groups of “local” measures Gj do not share atoms under that setting of empirical measures.
",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
The examples examined above indicate that the MWM problem in general do not “encourage” the local measures Gj to share atoms among each other in its solution.,3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
"Additionally, when the empirical measures of local groups are very close, it may also suggest that they belong to the same cluster and the distances among optimal local measures Gj can be very small.",3.1.1. PROPERTIES OF MWM IN SPECIAL CASES,[0],[0]
Now we are ready to describe our algorithm in the general case.,3.1.2. ALGORITHM DESCRIPTION,[0],[0]
This is a procedure for finding a local minimum of Problem (5) and is summarized in Algorithm 1.,3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"We prepare the following details regarding the initialization and updating steps required by the algorithm:
Algorithm 1 Multilevel Wasserstein Means (MWM) Input: Data Xj,i, Parameters kj , M .",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
Output: prob.,3.1.2. ALGORITHM DESCRIPTION,[0],[0]
measures,3.1.2. ALGORITHM DESCRIPTION,[0],[0]
Gj and elements Hi of H .,3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"Initialize measures G(0)j , elements H (0) i of H (0), t = 0.
while Y (t)j , b (t) j , H (t)",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"i have not converged do
1.",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
Update Y (t)j and b (t) j for 1 ≤ j ≤ m: for j = 1 to m do ij ← arg,3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"min
1≤u≤M W 22 (G (t) j , H (t) u ).
",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"G (t+1) j ← arg min Gj∈Okj (Θ) W 22 (Gj , P j nj )+",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"+W 22 (Gj , H (t) ij
)/m.",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
end for 2.,3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"Update H(t)i for 1 ≤ i ≤M : for j = 1 to m do ij ← arg min
1≤u≤M W 22 (G (t+1) j , H (t) u ).
end for for i = 1 to M do Ci ← {l : il = i} for 1 ≤ i ≤M .",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"H
(t+1)",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"i ← arg min
Hi∈P2(Θ) ∑ l∈Ci W 22 (Hi, G (t+1) l ).
end for 3. t←",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"t+ 1.
end while
•",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"The initialization of local measures G(0)j (i.e., the initialization of their atoms and weights) can be obtained by performing K-means clustering on local data",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"Xj,i for 1 ≤ j ≤ m.",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
The initialization of elements H(0)i of H(0) is based on a simple extension of the K-means algorithm.,3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"Details are given in Algorithm 3 in the Supplement;
•",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"The updates G(t+1)j can be computed efficiently by simply using algorithms from (Cuturi and Doucet, 2014) to search for local solutions of these barycenter problems within the space Okj (Θ) from the atoms and weights of G(t)j ;
• Since all G(t+1)j are finite discrete measures, finding the updates for H(t+1)i over the whole space P2(Θ) can be reduced to searching for a local solution within space Ol(t) where l(t) =
∑ j∈Ci |supp(G(t+1)j )| − |Ci|
from the global atoms H(t)i of H (t) (Justification of this reduction is derived from Theorem A.1 in the Supplement).",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"This again can be done by utilizing algorithms from (Cuturi and Doucet, 2014).",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"Note that, as l(t) becomes very large when m is large, to speed up the computation of Algorithm 1 we impose a threshold L, e.g., L = 10, for l(t) in its implementation.
",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"The following guarantee for Algorithm 1 can be established:
Theorem 3.1.",3.1.2. ALGORITHM DESCRIPTION,[0],[0]
Algorithm 1 monotonically decreases the objective function (4) of the MWM formulation.,3.1.2. ALGORITHM DESCRIPTION,[0],[0]
"As we have observed from the analysis of several specific cases, the multilevel Waserstein means formulation may not encourage the sharing components locally among m groups in its solution.",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
"However, enforced sharing has been demonstrated to be a very useful technique, which leads to the “borrowing of strength” among different parts of the model, consequentially improving the inferential efficiency (Teh et al., 2006; Nguyen, 2016).",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
"In this section, we seek to encourage the borrowing of strength among groups by imposing additional constraints on the atoms of G1, . . .",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
", Gm in the original MWM formulation (4).",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
"Denote
AM,SK = { Gj ∈ OK(Θ), H ∈ EM (P(Θ)) : supp(Gj) ⊆
SK ∀1 ≤ j ≤ m } for any given K,M ≥ 1 where the
constraint set SK has exactly K elements.",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
"To simplify the exposition, let us assume that kj = K for all 1 ≤ j ≤ m. Consider the following locally constrained version of the multilevel Wasserstein means problem
inf m∑ j=1 W 22",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
"(Gj , P j nj )",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
+,3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
"W 2 2 (H, 1 m m∑ j=1 δGj ).",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
"(7)
where SK , Gj ,H ∈ AM,SK in the above infimum.",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
We call the above optimization the problem of Multilevel Wasserstein Means with Sharing (MWMS).,3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
"The local constraint assumption supp(Gj) ⊆ SK had been utilized previously in the literature — see for example the work of (Kulis and Jordan, 2012), who developed an optimization-based approach to the inference of the HDP (Teh et al., 2006), which also encourages explicitly the sharing of local group means among local clusters.",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
"Now, we can rewrite objective function (7) as follows
inf SK ,Gj ,H∈BM,SK m∑ j=1 W 22 (Gj , P j nj ) + d2W2(Gj ,H) m (8)
where BM,SK = { Gj ∈ OK(Θ), H = (H1, . . .",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
",HM ) :
supp(Gj) ⊆ SK ∀1 ≤ j ≤ m } .",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
"The high level idea
of finding local minimums of objective function (8) is to first, update the elements of constraint set SK to provide the supports for local measuresGj and then, obtain the weights of these measures as well as the elements of global set H by computing appropriate Wasserstein barycenters.",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
"Due to space constraint, the details of these steps of the MWMS Algorithm (Algorithm 2) are deferred to the Supplement.",3.2. Multilevel Wasserstein Means with Sharing,[0],[0]
We proceed to establish consistency for the estimators introduced in the previous section.,4. Consistency results,[0],[0]
"For the brevity of the presentation, we only focus on the MWM method; consistency for MWMS can be obtained in a similar fashion.",4. Consistency results,[0],[0]
"Fix m, and assume that P j is the true distribution of data Xj,i for j = 1, . . .",4. Consistency results,[0],[0]
",m. Write G = (G1, . . .",4. Consistency results,[0],[0]
", Gm) and n = (n1, . . .",4. Consistency results,[0],[0]
", nm).",4. Consistency results,[0],[0]
"We say n → ∞ if nj → ∞ for j = 1, . . .",4. Consistency results,[0],[0]
",m. Define the following functions fn(G,H) =",4. Consistency results,[0],[0]
"m∑ j=1 W 22 (Gj , P j nj )",4. Consistency results,[0],[0]
+,4. Consistency results,[0],[0]
"W 2 2 (H, 1 m m∑ j=1 δGj ),
f(G,H) =",4. Consistency results,[0],[0]
"m∑ j=1 W 22 (Gj , P j) +W 22 (H, 1 m m∑ j=1 δGj ),
where Gj ∈ Okj (Θ),",4. Consistency results,[0],[0]
H ∈ EM (P(Θ)),4. Consistency results,[0],[0]
as 1 ≤ j ≤ m.,4. Consistency results,[0],[0]
"The first consistency property of the WMW formulation:
Theorem 4.1.",4. Consistency results,[0],[0]
"Given that P j ∈ P2(Θ) for 1 ≤ j ≤ m. Then, there holds almost surely, as n→∞
inf Gj∈Okj (Θ), H∈EM (P2(Θ))",4. Consistency results,[0],[0]
"fn(G,H)− inf Gj∈Okj (Θ), H∈EM (P2(Θ))",4. Consistency results,[0],[0]
"f(G,H)→ 0.
",4. Consistency results,[0],[0]
The next theorem establishes that the “true” global and local clusters can be recovered.,4. Consistency results,[0],[0]
"To this end, assume that for each n there is an optimal solution (Ĝn11 , . . .",4. Consistency results,[0],[0]
", Ĝ nm m , Ĥn) or in short (Ĝ n ,Hn) of the objective function (4).",4. Consistency results,[0],[0]
"Moreover, there exist a (not necessarily unique) optimal solution minimizing f(G,H) overGj ∈",4. Consistency results,[0],[0]
Okj (Θ) andH ∈ EM (P2(Θ)).,4. Consistency results,[0],[0]
Let F be the collection of such optimal solutions.,4. Consistency results,[0],[0]
"For any Gj ∈ Okj (Θ) andH ∈ EM (P2(Θ)), define
d(G,H,F) = inf (G0,H0)∈F m∑ j=1 W 22 (Gj , G 0 j )",4. Consistency results,[0],[0]
+,4. Consistency results,[0],[0]
"W 2 2 (H,H0).
",4. Consistency results,[0],[0]
"Given the above assumptions, we have the following result regarding the convergence of (Ĝ n ,Hn):
Theorem 4.2.",4. Consistency results,[0],[0]
Assume that Θ is bounded and P j ∈ P2(Θ) for all 1 ≤ j ≤ m.,4. Consistency results,[0],[0]
"Then, we have d(Ĝ n , Ĥn,F) → 0 as n→∞ almost surely.
",4. Consistency results,[0],[0]
Remark: (i),4. Consistency results,[0],[0]
The assumption Θ is bounded is just for the convenience of proof argument.,4. Consistency results,[0],[0]
We believe that the conclusion of this theorem may still hold when Θ = Rd.,4. Consistency results,[0],[0]
(ii),4. Consistency results,[0],[0]
"If |F| = 1, i.e., there exists an unique optimal solution G0,H0 minimizing f(G,H) over Gj ∈ Okj (Θ) and H ∈ EM (P2(Θ)), the result of Theorem 4.2 implies that W2(Ĝ nj j , G 0 j )",4. Consistency results,[0],[0]
"→ 0 for 1 ≤ j ≤ m and W2(Ĥn,H0) → 0 as n→∞.",4. Consistency results,[0],[0]
"In this section, we are interested in evaluating the effectiveness of both MWM and MWMS clustering algorithms by considering different synthetic data generating processes.",5.1. Synthetic data,[0],[0]
"Unless otherwise specified, we set the number of groups m = 50, number of observations per group nj = 50 in d = 10 dimensions, number of global clusters M = 5 with 6 atoms.",5.1. Synthetic data,[0],[0]
For Algorithm 1 (MWM) local measures Gj have 5 atoms each; for Algorithm 2 (MWMS) number of atoms in constraint set SK is 50.,5.1. Synthetic data,[0],[0]
As a benchmark for the comparison we will use a basic 3-stage K-means approach (the details of which can be found in the Supplement).,5.1. Synthetic data,[0],[0]
"The Wasserstein distance between the estimated distributions (i.e. Ĝ1, . . .",5.1. Synthetic data,[0],[0]
", Ĝm; Ĥ1, . . .",5.1. Synthetic data,[0],[0]
", ĤM ) and the data generating ones will be used as the comparison metric.
",5.1. Synthetic data,[0],[0]
"Recall that the MWM formulation does not impose constraints on the atoms of Gi, while the MWMS formulation explicitly enforces the sharing of atoms across these measures.",5.1. Synthetic data,[0],[0]
We used multiple layers of mixtures while adding Gaussian noise at each layer to generate global and local clusters and the no-constraint (NC) data.,5.1. Synthetic data,[0],[0]
We varied number of groups m from 500 to 10000.,5.1. Synthetic data,[0],[0]
"We notice that the 3-stage K-means algorithm performs the best when there is no constraint structure and variance is constant across clusters (Fig. 1(a) and 2(a)) — this is, not surprisingly, a favorable setting for the basic K-means method.",5.1. Synthetic data,[0],[0]
"As soon as we depart from the (unrealistic) constant-variance, no-sharing assumption, both of our algorithms start to outperform the basic three-stage K-means.",5.1. Synthetic data,[0],[0]
The superior performance is most pronounced with local-constraint (LC) data (with or without constant variance conditions).,5.1. Synthetic data,[0],[0]
"See Fig. 1(c,d).",5.1. Synthetic data,[0],[0]
"It is worth noting that even when group variances are constant, the 3-stage K-means is no longer longer effective because now fails to account for the shared structure.",5.1. Synthetic data,[0],[0]
"Whenm = 50 and group sizes are larger, we set SK = 15.",5.1. Synthetic data,[0],[0]
"Results are reported in Fig. 2 (c), (d).",5.1. Synthetic data,[0],[0]
These results demonstrate the effectiveness and flexibility of our both algorithms.,5.1. Synthetic data,[0],[0]
"We applied our multilevel clustering algorithms to two realworld datasets: LabelMe and StudentLife.
LabelMe dataset consists of 2, 688 annotated images which are classified into 8 scene categories including tall buildings, inside city, street, highway, coast, open country, mountain, and forest (Oliva and Torralba, 2001) .",5.2. Real data analysis,[0],[0]
Each image contains multiple annotated regions.,5.2. Real data analysis,[0],[0]
"Each region, which is annotated by users, represents an object in the image.",5.2. Real data analysis,[0],[0]
"As shown in Figure 4, the left image is an image from open country category and contains 4 regions while the right panel denotes an image of tall buildings category
including 16 regions.",5.2. Real data analysis,[0],[0]
Note that the regions in each image can be overlapped.,5.2. Real data analysis,[0],[0]
"We remove the images containing less then 4 regions and obtain 1, 800 images.
",5.2. Real data analysis,[0],[0]
"We then extract GIST feature (Oliva and Torralba, 2001) for each region in a image.",5.2. Real data analysis,[0],[0]
GIST is a visual descriptor to represent perceptual dimensions and oriented spatial structures of a scene.,5.2. Real data analysis,[0],[0]
Each GIST descriptor is a 512- dimensional vector.,5.2. Real data analysis,[0],[0]
We further use PCA to project GIST features into 30 dimensions.,5.2. Real data analysis,[0],[0]
"Finally, we obtain 1, 800 “documents”, each of which contains regions as observations.",5.2. Real data analysis,[0],[0]
Each region now is represented by a 30-dimensional vector.,5.2. Real data analysis,[0],[0]
We now can perform clustering regions in every image since they are visually correlated.,5.2. Real data analysis,[0],[0]
"In the next level of clustering, we can cluster images into scene categories.
",5.2. Real data analysis,[0],[0]
StudentLife dataset is a large dataset frequently used in pervasive and ubiquitous computing research.,5.2. Real data analysis,[0],[0]
"Data signals
consist of multiple channels (e.g., WiFi signals, Bluetooth scan, etc.), which are collected from smartphones of 49 students at Dartmouth College over a 10-week spring term in 2013.",5.2. Real data analysis,[0],[0]
"However, in our experiments, we use only WiFi signal strengths.",5.2. Real data analysis,[0],[0]
"We applied a similar procedure described in (Nguyen et al., 2016) to pre-process the data.",5.2. Real data analysis,[0],[0]
We aggregate the number of scans by each Wifi access point and select 500 Wifi Ids with the highest frequencies.,5.2. Real data analysis,[0],[0]
"Eventually, we obtain 49 “documents” with totally approximately 4.6 million 500-dimensional data points.
",5.2. Real data analysis,[0],[0]
Experimental results.,5.2. Real data analysis,[0],[0]
"To quantitatively evaluate our proposed methods, we compare our algorithms with several base-line methods: K-means, three-stage K-means (TSKmeans) as described in the Supplement, MC2-SVI without context (Huynh et al., 2016).",5.2. Real data analysis,[0],[0]
Clustering performance in Table 1 is evaluated with the image clustering problem for LabelMe dataset.,5.2. Real data analysis,[0],[0]
"With K-means, we average all data points
to obtain a single vector for each images.",5.2. Real data analysis,[0],[0]
"K-means needs much less time to run since the number of data points is now reduced to 1, 800.",5.2. Real data analysis,[0],[0]
"For MC2-SVI, we used stochastic varitational and a parallelized Spark-based implementation in (Huynh et al., 2016) to carry out experiments.",5.2. Real data analysis,[0],[0]
This implementation has the advantage of making use of all of 16 cores on the test machine.,5.2. Real data analysis,[0],[0]
The running time for MC2-SVI is reported after scanning one epoch.,5.2. Real data analysis,[0],[0]
"In terms of clustering accuracy, MWM and MWMS algorithms perform the best.
",5.2. Real data analysis,[0],[0]
Fig.,5.2. Real data analysis,[0],[0]
3a demonstrates five representative image clusters with six randomly chosen images in each (on the right) which are discovered by our MWMS algorithm.,5.2. Real data analysis,[0],[0]
We also accumulate labeled tags from all images in each cluster to produce the tag-cloud on the left.,5.2. Real data analysis,[0],[0]
These tag-clouds can be considered as visual ground truth of clusters.,5.2. Real data analysis,[0],[0]
"Our algorithm can group images into clusters which are consistent with their tag-clouds.
",5.2. Real data analysis,[0],[0]
We use StudentLife dataset to demonstrate the capability of multilevel clustering with large-scale datasets.,5.2. Real data analysis,[0],[0]
This dataset not only contains a large number of data points but presents in high dimension.,5.2. Real data analysis,[0],[0]
Our algorithms need approximately 1 hour to perform multilevel clustering on this dataset.,5.2. Real data analysis,[0],[0]
Fig.,5.2. Real data analysis,[0],[0]
3b presents two levels of clusters discovered by our algorithms.,5.2. Real data analysis,[0],[0]
The innermost (blue) and outermost (green) rings depict local and global clusters respectively.,5.2. Real data analysis,[0],[0]
"Global clusters represent groups of students while local clusters shared between students (“documents”) may be used to infer loca-
tions of students’ activities.",5.2. Real data analysis,[0],[0]
"From these clusteing we can dissect students’ shared location (activities), e.g. Student 49 (U49) mainly takes part in activity location 4 (L4).",5.2. Real data analysis,[0],[0]
We have proposed an optimization based approach to multilevel clustering using Wasserstein metrics.,6. Discussion,[0],[0]
There are several possible directions for extensions.,6. Discussion,[0],[0]
"Firstly, we have only considered continuous data; it is of interest to extend our formulation to discrete data.",6. Discussion,[0],[0]
"Secondly, our method requires knowledge of the numbers of clusters both in local and global clustering.",6. Discussion,[0],[0]
"When these numbers are unknown, it seems reasonable to incorporate penalty on the model complexity.",6. Discussion,[0],[0]
"Thirdly, our formulation does not directly account for the “noise” distribution away from the (Wasserstein) means.",6. Discussion,[0],[0]
"To improve the robustness, it may be desirable to make use of the first-order Wasserstein metric instead of the second-order one.",6. Discussion,[0],[0]
"Finally, we are interested in extending our approach to richer settings of hierarchical data, such as one when group level-context is available.
",6. Discussion,[0],[0]
Acknowledgement.,6. Discussion,[0],[0]
"This research is supported in part by grants NSF CAREER DMS-1351362, NSF CNS-1409303, the Margaret and Herman Sokol Faculty Award and research gift from Adobe Research (XN).",6. Discussion,[0],[0]
DP gratefully acknowledges the partial support from the Australian Research Council (ARC) and AOARD (FA2386-16-1-4138).,6. Discussion,[0],[0]
"We propose a novel approach to the problem of multilevel clustering, which aims to simultaneously partition data in each group and discover grouping patterns among groups in a potentially large hierarchically structured corpus of data.",abstractText,[0],[0]
"Our method involves a joint optimization formulation over several spaces of discrete probability measures, which are endowed with Wasserstein distance metrics.",abstractText,[0],[0]
"We propose a number of variants of this problem, which admit fast optimization algorithms, by exploiting the connection to the problem of finding Wasserstein barycenters.",abstractText,[0],[0]
Consistency properties are established for the estimates of both local and global clusters.,abstractText,[0],[0]
"Finally, experiment results with both synthetic and real data are presented to demonstrate the flexibility and scalability of the proposed approach.",abstractText,[0],[0]
1,abstractText,[0],[0]
Multilevel Clustering via Wasserstein Means,title,[0],[0]
"Proceedings of the SIGDIAL 2015 Conference, pages 227–231, Prague, Czech Republic, 2-4 September 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
"Automated text summarization is an active field of research in various communities, including Information Retrieval, Natural Language Processing, and Text Mining.
",1 Introduction,[0],[0]
"Some authors reduce summarization to the maximum coverage problem (Takamura and Okumura, 2009; Gillick and Favre, 2009) which, despite positive results, is known as NPhard (Khuller et al., 1999).",1 Introduction,[0],[0]
"Because linear programming (LP) helps to find an accurate approximated solution to this problem it has recently become very popular in the summarization field (Gillick and Favre, 2009; Woodsend and Lapata, 2010; Hitoshi Nishikawa and Kikui, 2010; Makino et al., 2011).
",1 Introduction,[0],[0]
"Trying to solve a trade-off between summary quality and time complexity, we propose a summarization model solving the approximated maximum coverage problem by linear programming in
polynomial time.",1 Introduction,[0],[0]
We measure information coverage by an objective function and strive to obtain a summary that preserves its optimal value as much as possible.,1 Introduction,[0],[0]
Three objective functions considering different metrics of information are introduced and evaluated.,1 Introduction,[0],[0]
"The main achievement of our method is a text representation model expanding a classic vector space model (Salton et al., 1975) to hyperplane and half-spaces and making it possible to represent an exponential number of extracts without computing them explicitly.",1 Introduction,[0],[0]
"This model also enables us to find the optimal extract by simple optimizing an objective function in polynomial time, using linear programming over rationals.",1 Introduction,[0],[0]
"For the first time, the frequent sequence mining was integrated with the maximal coverage approach in order to obtain a summary that best describes the summarized document.",1 Introduction,[0],[0]
"One of the introduced objective functions implements this idea.
",1 Introduction,[0],[0]
"Our method ranks and extracts significant sentences into a summary, without any need in morphological text analysis.",1 Introduction,[0],[0]
"It was applied for both single-document (MSS) and multi-document (MMS) MultiLing 2015 summarization tasks, in three languages–English, Hebrew, and Arabic.",1 Introduction,[0],[0]
"In this paper we present experimental results in comparison with other systems that participated in the same tasks, using the same languages.",1 Introduction,[0],[0]
We are given a document or a set of related documents in UTF-8 encoding.,2 Preprocessing and definitions,[0],[0]
"Documents are split into sentences S1, ..., Sn.",2 Preprocessing and definitions,[0],[0]
"All sentences undergo tokenization, stop-word removal, and stemming.",2 Preprocessing and definitions,[0],[0]
"For some languages, stemming may be very basic or absent, and a list of stop-words may be unavailable.",2 Preprocessing and definitions,[0],[0]
"All these factors affect summarization quality.
",2 Preprocessing and definitions,[0],[0]
"Unique stemmed words are called terms and are denoted by T1, ..., Tm.",2 Preprocessing and definitions,[0],[0]
"Every sentence is modeled as a sequence of terms from T1, ..., Tm where each
227
term may appear zero or more times in a sentence.",2 Preprocessing and definitions,[0],[0]
"We are also given the desired number of words for a summary, denoted by MaxWords .
",2 Preprocessing and definitions,[0],[0]
"The goal of extractive summarization is to find a subset of sentences S1, ..., Sn that has no more than MaxWords words and conveys as much information as possible about the documents.",2 Preprocessing and definitions,[0],[0]
"Because it is difficult, or even impossible, to know what humans consider to be the best summary, we approximate the human decision process by optimizing certain objective functions over representation of input documents constructed according to our model.",2 Preprocessing and definitions,[0],[0]
"The number of words in a summary, sentences, and terms, are represented as constraints in our model.",2 Preprocessing and definitions,[0],[0]
"In the polytope model (Litvak and Vanetik, 2014) a document is viewed as an integer sentence-term matrix A = (aij), where aij denotes the number of appearances of term Tj in sentence Si.",3.1 Definitions,[0],[0]
"A row i of matrix A is used to define a linear constraint for sentence Si as follows:
m∑ j=1 aijxij ≤ m∑ j=1 aij (1)
",3.1 Definitions,[0],[0]
Equation (1) also defines the lower half-space in Rmn corresponding to sentence Si.,3.1 Definitions,[0],[0]
"Together with additional constraints, such as a bound MaxWords on the number of words in the summary, we obtain a system of linear inequalities that describes the intersection of corresponding lower half-spaces of Rmn, forming a closed convex polyhedron called a polytope: ∑m j=1 aijxij ≤ ∑m j=1 aij , ∀i = 1..n
0 ≤",3.1 Definitions,[0],[0]
"xij ≤ 1, ∀i = 1..n, j = 1..m∑n i=1",3.1 Definitions,[0],[0]
"∑m j=1 aijxij ≤ MaxWords
(2)
",3.1 Definitions,[0],[0]
"All possible extractive summaries are represented by vertices of the polytope defined in (2).
",3.1 Definitions,[0],[0]
It remains only to define an objective function which optimum on the polytope boundary will define the summary we seek.,3.1 Definitions,[0],[0]
"Because such an optimum may be achieved not on a polytope vertex but rather on one of polytope faces (because we use linear programming over rationals), we need only to locate the vertex of a polytope closest to the point of optimum.",3.1 Definitions,[0],[0]
"This task is done by finding distances from the optimum to every one of the sentence hyperplanes and selecting those with
minimal distance to the point of optimum.",3.1 Definitions,[0],[0]
"If there are too many candidate sentences, we give preference to those closest to the beginning of the document.
",3.1 Definitions,[0],[0]
"The main advantage of this model is the relatively low number of constraints (comparable with the number of terms and sentences in a document) and both the theoretical and practical polynomial running times of LP over rationals (Karmarkar, 1984).",3.1 Definitions,[0],[0]
"In this section, we describe the objective functions we used in our system.",3.2 Objective functions,[0],[0]
"Humans identify good summaries immediately, but specifying summary quality as a linear function of terms, sentences, and their parameters is highly nontrivial.",3.2 Objective functions,[0],[0]
"In most cases, additional parameters, variables, and constraints must be added to the model.",3.2 Objective functions,[0],[0]
"The first objective function maximizes relevance of sentences chosen for a summary, while minimizing pairwise redundancy between them.
",3.3 Maximal sentence relevance,[0],[0]
We define relevance cosrel,3.3 Maximal sentence relevance,[0],[0]
"i of a sentence Si as a cosine similarity between the sentence, viewed as a weighted vector of its terms, and the document.",3.3 Maximal sentence relevance,[0],[0]
Relevance values are completely determined by the text and are not affected by choice of a summary.,3.3 Maximal sentence relevance,[0],[0]
"Every sentence Si is represented by a sentence variable:
si = ∑m j=1 aijxij/ ∑m j=1 aij (3)
Formally, variable si represents the hyperplane bounding the lower half-space of Rmn related to sentence Si and bounding the polytope.",3.3 Maximal sentence relevance,[0],[0]
"Clearly, si assumes values in range [0, 1], where 0 means that the sentence is completely omitted from the summary and 1 means that the sentence is definitely chosen for the summary.",3.3 Maximal sentence relevance,[0],[0]
"Relevance of all sentences in the summary is described by the expression
n∑ i=1 cosrel isi (4)
Redundancy needs to be modeled and computed for every pair of sentences separately.",3.3 Maximal sentence relevance,[0],[0]
"We use additional redundancy variables red ij for every pair Si, Sj of sentences where i <",3.3 Maximal sentence relevance,[0],[0]
j.,3.3 Maximal sentence relevance,[0],[0]
"Every one of these variables is 0 − 1 bounded and achieves a value of 1 only if both sentences are chosen for
the summary with the help of these constraints: 0 ≤ red ij ≤ 1, 0 ≤",3.3 Maximal sentence relevance,[0],[0]
"i < j ≤ n red ij ≤ si, red ij ≤",3.3 Maximal sentence relevance,[0],[0]
sj si + sj,3.3 Maximal sentence relevance,[0],[0]
"− red ij ≤ 1 (5)
",3.3 Maximal sentence relevance,[0],[0]
"The numerical redundancy coefficient for sentences Si and Sj is their cosine similarity as term vectors, which we compute directly from the text and denote by cosred ij .",3.3 Maximal sentence relevance,[0],[0]
"The objective function we use to maximize relevance of the chosen sentences while minimizing redundancy is
max n∑
i=1
cosrel isi",3.3 Maximal sentence relevance,[0],[0]
"− n∑
i=1 n∑ j=1 cosred ijred ij (6)",3.3 Maximal sentence relevance,[0],[0]
"The second proposed objective function maximizes the weighted sum of bigrams (consecutive term pairs appearing in sentences), where the weight of a bigram denotes its importance.
",3.4 Sum of bigrams,[0],[0]
"The importance count ij of a bigram (Ti, Tj) is computed as the number of its appearances in the document.",3.4 Sum of bigrams,[0],[0]
"It is quite possible that this bigram appears twice in one sentence, and once in another, and i = j is possible as well.
",3.4 Sum of bigrams,[0],[0]
"In order to represent bigrams, we introduce new bigram variables bgij for i, j = 1..m, covering all possible term pairs.",3.4 Sum of bigrams,[0],[0]
An appearance of a bigram in sentence,3.4 Sum of bigrams,[0],[0]
"Sk is modeled by a 0 − 1 bounded variable bgkij , and c k ij denotes the number of times this bigram appears in sentence",3.4 Sum of bigrams,[0],[0]
Sk.,3.4 Sum of bigrams,[0],[0]
"A bigram is represented by a normalized sum of its appearances in various sentences as follows:{
0 ≤ bgkij ≤ 1, ∀i, j, k bgij = ∑n k=1 c k",3.4 Sum of bigrams,[0],[0]
ijbg k,3.4 Sum of bigrams,[0],[0]
ij/,3.4 Sum of bigrams,[0],[0]
∑n k=1,3.4 Sum of bigrams,[0],[0]
"c k ij
(7)
",3.4 Sum of bigrams,[0],[0]
"Additionally, the appearance bgkij of a bigram in sentence",3.4 Sum of bigrams,[0],[0]
"Sk is tied to terms Ti and Tj composing it, with the help of variables xki and xkj denoting appearances of these terms in Sk:
bgkij ≤",3.4 Sum of bigrams,[0],[0]
xki bgkij ≤,3.4 Sum of bigrams,[0],[0]
xkj xki +,3.4 Sum of bigrams,[0],[0]
xkj,3.4 Sum of bigrams,[0],[0]
"− bgkij ≤ 1
(8)
The constraints in (8) express the fact that a bigram cannot appear without the terms composing it, and appearance of both terms causes, in turn, the appearance of a bigram.",3.4 Sum of bigrams,[0],[0]
"Our objective function is:
max :",3.4 Sum of bigrams,[0],[0]
"m∑
i=1",3.4 Sum of bigrams,[0],[0]
m∑ j=1 count ijbgij (9),3.4 Sum of bigrams,[0],[0]
"The third proposed objective function modifies the model so that only the most important terms are taken into account.
",3.5 Maximal relevance with frequent itemsets,[0],[0]
"Let us view each sentence Si as a sequence (Ti1, . . .",3.5 Maximal relevance with frequent itemsets,[0],[0]
", Tin) of terms, and the order of terms preserves the original word order of a sentence.",3.5 Maximal relevance with frequent itemsets,[0],[0]
Source documents are viewed as a database of sentences.,3.5 Maximal relevance with frequent itemsets,[0],[0]
"Database size is n. Let s = (Ti1, . . .",3.5 Maximal relevance with frequent itemsets,[0],[0]
", Tik) be a sequence of terms of size k. Support of s in the database is the ratio of sentences containing this sequence, to the database size n.
",3.5 Maximal relevance with frequent itemsets,[0],[0]
Given a user-defined support bound S ∈,3.5 Maximal relevance with frequent itemsets,[0],[0]
"[0, 1], a term sequence s is frequent if support(s) ≥ S .",3.5 Maximal relevance with frequent itemsets,[0],[0]
"Frequent term sequences can be computed by a multitude of existing algorithms, such as Apriori (Agrawal et al., 1994), FreeSpan (Han et al., 2000), GSP (Zaki, 2001), etc.
",3.5 Maximal relevance with frequent itemsets,[0],[0]
"In order to modify the generic model described in (2), we first find all frequent sequences in the documents and store them in set F .",3.5 Maximal relevance with frequent itemsets,[0],[0]
"Then we sort F first by decreasing sequence size and then by decreasing support, and finally we keep only top B sequences for a user-defined boundary B.
We modify the general model (2) by representing sentences as sums of their frequent sequences from F .",3.5 Maximal relevance with frequent itemsets,[0],[0]
"Let F = {f1, . . .",3.5 Maximal relevance with frequent itemsets,[0],[0]
", fk}, sorted by decreasing size and then by decreasing support.",3.5 Maximal relevance with frequent itemsets,[0],[0]
"A sentence Si is said to contain fj if it contains it as a term sequence and no part of fj in Si is covered by sequences f1, . . .",3.5 Maximal relevance with frequent itemsets,[0],[0]
", fj−1.
Let count ij denote the number of times sentence Si contains frequent term sequence fj .",3.5 Maximal relevance with frequent itemsets,[0],[0]
Variables fij denote the appearance of sequence fj in sentence Si.,3.5 Maximal relevance with frequent itemsets,[0],[0]
"We replace the polytope (2) by:{ ∑k
j=1 count ijfij ≤",3.5 Maximal relevance with frequent itemsets,[0],[0]
"∑k
j=1 count ij , ∀i = 1..n 0 ≤ fij ≤ 1, ∀i = 1..n, j = 1..k
(10) We add variables describing the relevance of each sentence by introducing sentence variables:
si = ∑k j=1 countijfij/ ∑k j=1 countij (11)
Defining a boundary on the length of a summary now requires an additional constraint because frequent sequences do not contain all the terms in the sentences.",3.5 Maximal relevance with frequent itemsets,[0],[0]
"Summary size is bounded as follows:
n∑ i=1",3.5 Maximal relevance with frequent itemsets,[0],[0]
"lengthisi ≤ MaxWords (12)
",3.5 Maximal relevance with frequent itemsets,[0],[0]
"Here, lengthi is the exact word count of sentence Si.
",3.5 Maximal relevance with frequent itemsets,[0],[0]
Relevance freqrel,3.5 Maximal relevance with frequent itemsets,[0],[0]
"i of a sentence Si is defined as a cosine similarity between the vector of terms in Si covered by members of F , and the entire document.",3.5 Maximal relevance with frequent itemsets,[0],[0]
The difference between this approach and the one described in Section 3.3 is that only frequent terms are taken into account when computing sentence-document similarity.,3.5 Maximal relevance with frequent itemsets,[0],[0]
"The resulting objective function maximizes relevance of chosen sentences while minimizing redundancy defined in (5):
max n∑
i=1
freqrel isi",3.5 Maximal relevance with frequent itemsets,[0],[0]
"− n∑
i=1 n∑ j=1 cosred ijred ij (13)",3.5 Maximal relevance with frequent itemsets,[0],[0]
"Tables 4, 4, and 1 contain the summarized results of automated evaluations for MultiLing 2015, single-document summarization (MSS) task for English, Hebrew, and Arabic corpora, respectively.",4 Experiments,[0],[0]
"The quality of the summaries is measured by ROUGE-1 (Recall, Precision, and Fmeasure).(Lin, 2004)",4 Experiments,[0],[0]
"We also demonstrate the absolute ranks of each submission–P-Rank, R-Rank, and F-Rank–when their scores are sorted by Precision, Recall, and F-measure, respectively.",4 Experiments,[0],[0]
Only the best submissions (in terms of F-measure) for each participated system are presented and sorted in descending order of their F-measure scores.,4 Experiments,[0],[0]
"Two systems–Oracles and Lead–were used as topline and baseline summarizers, respectively.",4 Experiments,[0],[0]
"Oracles compute summaries for each article using the combinatorial covering algorithm in (Davis et al., 2012)–sentences were selected from a text to maximally cover the tokens in the human summary, using as few sentences as possible until its size exceeded the human summary, at which point it was truncated.",4 Experiments,[0],[0]
"Because Oracles can actually “see” the human summaries, it is considered as the optimal algorithm and its scores are the best scores that extractive approaches can achieve.",4 Experiments,[0],[0]
"Lead simply extracts the leading substring of the body text of the articles having the same length as the human summary of the article.
",4 Experiments,[0],[0]
"Below we summarize the comparative results for our summarizer (denoted in the following tables by Poly) in both tasks, in terms of Rouge-1, F-measure.",4 Experiments,[0],[0]
"For comparisons, we consider the best result out of 3 functions: coverage of frequent sequences for English and coverage of meaningful words for Hebrew and Arabic.",4 Experiments,[0],[0]
English:,4 Experiments,[0],[0]
4th places out of 9 participants in both MSS and MMS tasks.,4 Experiments,[0],[0]
Hebrew:,4 Experiments,[0],[0]
"3rd place out of 7 and out of 9 partici-
pants in MSS and MMS tasks, respectively; and the highest recall score in MMS task.",4 Experiments,[0],[0]
"Arabic: 5th place out of 7 systems in MSS task, and 4th place out of 9 participants and the highest recall score in MMS task.",4 Experiments,[0],[0]
"As can be seen, the best performance for our summarizer has been achieved on the dataset of Hebrew documents.",4 Experiments,[0],[0]
"For example, only the top-line Oracles and the supervised MUSE summarizers outperformed our system in MSS task.",4 Experiments,[0],[0]
Poly also outperformed Gillick (2009) model using ILP.,4 Experiments,[0],[0]
The average running time for Poly is 500 ms per document.,4 Experiments,[0],[0]
In this paper we present an extractive summarization system based on a linear programming model.,5 Conclusions and Future Work,[0],[0]
We represent the document as a set of intersecting hyperplanes.,5 Conclusions and Future Work,[0],[0]
Every possible summary of a document is represented as the intersection of two or more hyperlanes.,5 Conclusions and Future Work,[0],[0]
We consider the summary to be the best if the optimal value of the objective function is achieved during summarization.,5 Conclusions and Future Work,[0],[0]
We introduce multiple objective functions describing the relevance of a sentence in terms of information coverage.,5 Conclusions and Future Work,[0],[0]
The results obtained by automatic evaluation show that the introduced approach performs quite well for Hebrew and English.,5 Conclusions and Future Work,[0],[0]
Only top-line and supervised summarizers outperform Poly on the Hebrew corpus.,5 Conclusions and Future Work,[0],[0]
"It is worth noting that our system is unsupervised and does not require annotated data, and it has polynomial running time.",5 Conclusions and Future Work,[0],[0]
The problem of extractive text summarization for a collection of documents is defined as the problem of selecting a small subset of sentences so that the contents and meaning of the original document set are preserved in the best possible way.,abstractText,[0],[0]
In this paper we describe the linear programming-based global optimization model to rank and extract the most relevant sentences to a summary.,abstractText,[0],[0]
We introduce three different objective functions being optimized.,abstractText,[0],[0]
"These functions define a relevance of a sentence that is being maximized, in different manners, such as: coverage of meaningful words of a document, coverage of its bigrams, or coverage of frequent sequences of words.",abstractText,[0],[0]
We supply here an overview of our system’s participation in the MultiLing contest of SIGDial 2015.,abstractText,[0],[0]
Multilingual Summarization with Polytope Model,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 2225–2235 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
2225
Multimodal affective computing, learning to recognize and interpret human affect and subjective information from multiple data sources, is still challenging because: (i) it is hard to extract informative features to represent human affects from heterogeneous inputs; (ii) current fusion strategies only fuse different modalities at abstract levels, ignoring time-dependent interactions between modalities. Addressing such issues, we introduce a hierarchical multimodal architecture with attention and word-level fusion to classify utterancelevel sentiment and emotion from text and audio data. Our introduced model outperforms state-of-the-art approaches on published datasets, and we demonstrate that our model’s synchronized attention over modalities offers visual interpretability.",text,[0],[0]
"With the recent rapid advancements in social media technology, affective computing is now a popular task in human-computer interaction.",1 Introduction,[0],[0]
"Sentiment analysis and emotion recognition, both of which require applying subjective human concepts for detection, can be treated as two affective computing subtasks on different levels (Poria et al., 2017a).",1 Introduction,[0],[0]
"A variety of data sources, including voice, facial expression, gesture, and linguistic content have been employed in sentiment analysis and emotion recognition.",1 Introduction,[0],[0]
"In this paper, we focus on a multimodal structure to leverage the advantages of each data source.",1 Introduction,[0],[0]
"Specifically, given an utterance, we consider the linguistic content and acoustic characteristics together to recognize the opinion or emotion.",1 Introduction,[0],[0]
"Our work is important and useful
∗ Equally Contribution
because speech is the most basic and commonly used form of human expression.
",1 Introduction,[0],[0]
"A basic challenge in sentiment analysis and emotion recognition is filling the gap between extracted features and the actual affective states (Zhang et al., 2017).",1 Introduction,[0],[0]
"The lack of high-level feature associations is a limitation of traditional approaches using low-level handcrafted features as representations (Seppi et al., 2008; Rozgic et al., 2012).",1 Introduction,[0],[0]
"Recently, deep learning structures such as CNNs and LSTMs have been used to extract high-level features from text and audio (Eyben et al., 2010a; Poria et al., 2015).",1 Introduction,[0],[0]
"However, not all parts of the text and vocal signals contribute equally to the predictions.",1 Introduction,[0],[0]
A specific word may change the entire sentimental state of text; a different vocal delivery may indicate inverse emotions despite having the same linguistic content.,1 Introduction,[0],[0]
"Recent approaches introduce attention mechanisms to focus the models on informative words (Yang et al., 2016) and attentive audio frames (Mirsamadi et al., 2017) for each individual modality.",1 Introduction,[0],[0]
"However, to our knowledge, there is no common multimodal structure with attention for utterancelevel sentiment and emotion classification.",1 Introduction,[0],[0]
"To address such issue, we design a deep hierarchical multimodal architecture with an attention mechanism to classify utterance-level sentiments and emotions.",1 Introduction,[0],[0]
"It extracts high-level informative textual and acoustic features through individual bidirectional gated recurrent units (GRU) and uses a multi-level attention mechanism to select the informative features in both the text and audio module.
",1 Introduction,[0],[0]
Another challenge is the fusion of cues from heterogeneous data.,1 Introduction,[0],[0]
"Most previous works focused on combining multimodal information at a holistic level, such as integrating independent predictions of each modality via algebraic rules (Wöllmer et al., 2013) or fusing the extracted modality-specific features from entire utterances
(Poria et al., 2016).",1 Introduction,[0],[0]
"They extract word-level features in a text branch, but process audio at the frame-level or utterance-level.",1 Introduction,[0],[0]
"These methods fail to properly learn the time-dependent interactions across modalities and restrict feature integration at timestamps due to the different time scales and formats of features of diverse modalities (Poria et al., 2017a).",1 Introduction,[0],[0]
"However, to determine human meaning, it is critical to consider both the linguistic content of the word and how it is uttered.",1 Introduction,[0],[0]
"A loud pitch on different words may convey inverse emotions, such as the emphasis on “hell” for anger but indicating happy on “great”.",1 Introduction,[0],[0]
Synchronized attentive information across text and audio would then intuitively help recognize the sentiments and emotions.,1 Introduction,[0],[0]
"Therefore, we compute a forced alignment between text and audio for each word and propose three fusion approaches (horizontal, vertical, and fine-tuning attention fusion) to integrate both the feature representations and attention at the word-level.
",1 Introduction,[0],[0]
We evaluated our model on four published sentiment and emotion datasets.,1 Introduction,[0],[0]
Experimental results show that the proposed architecture outperforms state-of-the-art approaches.,1 Introduction,[0],[0]
"Our methods also allow for attention visualization, which can be used for interpreting the internal attention distribution for both single- and multi-modal systems.",1 Introduction,[0],[0]
"The contributions of this paper are: (i) a hierarchical multimodal structure with attention mechanism to learn informative features and high-level associations from both text and audio; (ii) three wordlevel fusion strategies to combine features and learn correlations in a common time scale across different modalities; (iii) word-level attention visualization to help human interpretation.
",1 Introduction,[0],[0]
The paper is organized as follows: We list related work in section 2.,1 Introduction,[0],[0]
Section 3 describes the proposed structure in detail.,1 Introduction,[0],[0]
We present the experiments in section 4 and provide the result analysis in section 5.,1 Introduction,[0],[0]
We discuss the limitations in section 6 and conclude with section 7.,1 Introduction,[0],[0]
"Despite the large body of research on audio-visual affective analysis, there is relatively little work on combining text data.",2 Related Work,[0],[0]
"Early work combined human transcribed lexical features and low-level handcrafted acoustic features using feature-level fusion (Forbes-Riley and Litman, 2004; Litman and Forbes-Riley, 2004).",2 Related Work,[0],[0]
"Others used SVMs fed bag
of words (BoW) and part of speech (POS) features in addition to low-level acoustic features (Seppi et al., 2008; Rozgic et al., 2012; Savran et al., 2012; Rosas et al., 2013; Jin et al., 2015).",2 Related Work,[0],[0]
All of the above extracted low-level features from each modality separately.,2 Related Work,[0],[0]
"More recently, deep learning was used to extract higher-level multimodal features.",2 Related Work,[0],[0]
"Bidirectional LSTMs were used to learn long-range dependencies from low-level acoustic descriptors and derivations (LLDs) and visual features (Eyben et al., 2010a; Wöllmer et al., 2013).",2 Related Work,[0],[0]
"CNNs can extract both textual (Poria et al., 2015) and visual features (Poria et al., 2016) for multiple kernel learning of feature-fusion.",2 Related Work,[0],[0]
"Later, hierarchical LSTMs were used (Poria et al., 2017b).",2 Related Work,[0],[0]
"A deep neural network was used for feature-level fusion in (Gu et al., 2018) and (Zadeh et al., 2017) introduced a tensor fusion network to further improve the performance.",2 Related Work,[0],[0]
"A very recent work using word-level fusion was provided by (Chen et al., 2017).",2 Related Work,[0],[0]
"The key differences between this work and the proposed architecture are: (i) we design a fine-tunable hierarchical attention structure to extract word-level features for each individual modality, rather than simply using the initialized textual embedding and extracted LLDs from COVAREP (Degottex et al., 2014); (ii) we propose diverse representation fusion strategies to combine both the word-level representations and attention weights, instead of using only word-level fusion; (iii) our model allows visualizing the attention distribution at both the individual modality and at fusion to help model interpretability.
",2 Related Work,[0],[0]
"Our architecture is inspired by the document classification hierarchical attention structure that works at both the sentence and word level (Yang et al., 2016).",2 Related Work,[0],[0]
"For audio, an attention-based BLSTM and CNN were applied to discovering emotion from frames (Huang and Narayanan, 2016; Neumann and Vu, 2017).",2 Related Work,[0],[0]
"Frame-level weighted-pooling with local attention was shown to outperform frame-wise, final-frame, and framelevel mean-pooling for speech emotion recognition (Mirsamadi et al., 2017).",2 Related Work,[0],[0]
We introduce a multimodal hierarchical attention structure with word-level alignment for sentiment analysis and emotion recognition (Figure 1).,3 Method,[0],[0]
"The model consists of three major parts: text attention module, audio attention module, and word-
level fusion module.",3 Method,[0],[0]
We first make a forced alignment between the text and audio during preprocessing.,3 Method,[0],[0]
"Then, the text attention module and audio attention module extract the features from the corresponding inputs (shown in Algorithm 1).",3 Method,[0],[0]
The word-level fusion module fuses the extracted feature vectors and makes the final prediction via a shared representation (shown in Algorithm 2).,3 Method,[0],[0]
The forced alignment between the audio and text on the word-level prepares the different data for feature extraction.,3.1 Forced Alignment and Preprocessing,[0],[0]
We align the data at the wordlevel because words are the basic unit in English for human speech comprehension.,3.1 Forced Alignment and Preprocessing,[0],[0]
"We used aeneas1 to determine the time interval for each word in the audio file based on the Sakoe-Chiba Band Dynamic Time Warping (DTW) algorithm (Sakoe and Chiba, 1978).
",3.1 Forced Alignment and Preprocessing,[0],[0]
"For the text input, we first embedded the words into 300-dimensional vectors by word2vec (Mikolov et al., 2013), which gives us the best result compared to GloVe and LexVec.",3.1 Forced Alignment and Preprocessing,[0],[0]
Unknown words were randomly initialized.,3.1 Forced Alignment and Preprocessing,[0],[0]
"Given a sentence S with N words, let wi represent the ith word.",3.1 Forced Alignment and Preprocessing,[0],[0]
"We embed the words through the word2vec embedding matrix We by:
Ti =Wewi, i ∈",3.1 Forced Alignment and Preprocessing,[0],[0]
"[1, N ] (1)
where Ti is the embedded word vector.",3.1 Forced Alignment and Preprocessing,[0],[0]
"For the audio input, we extracted Melfrequency spectral coefficients (MFSCs) from raw audio signals as acoustic inputs for two reasons.",3.1 Forced Alignment and Preprocessing,[0],[0]
"Firstly, MFSCs maintain the locality of the data by preventing new bases of spectral energies resulting from discrete cosine transform in MFCCs extraction (Abdel-Hamid et al., 2014).",3.1 Forced Alignment and Preprocessing,[0],[0]
"Secondly, it has more dimensions in the frequency domain that aid learning in deep models (Gu et al., 2017).",3.1 Forced Alignment and Preprocessing,[0],[0]
We used 64 filter banks to extract the MFSCs for each audio frame to form the MFSCs map.,3.1 Forced Alignment and Preprocessing,[0],[0]
"To facilitate training, we only used static coefficients.",3.1 Forced Alignment and Preprocessing,[0],[0]
"Each word’s MFSCs can be represented as a matrix with 64×n dimensions, where n is the interval for the given word in frames.",3.1 Forced Alignment and Preprocessing,[0],[0]
"We zero-pad all intervals to the same length L, the maximum frame numbers of the word in the dataset.",3.1 Forced Alignment and Preprocessing,[0],[0]
"We did extract LLD features using OpenSmile (Eyben et al., 2010b) software and combined them with the MFSCs during our training stage.",3.1 Forced Alignment and Preprocessing,[0],[0]
"However, we did not find an
1https://www.readbeyond.it/aeneas/
obvious performance improvement, especially for the sentiment analysis.",3.1 Forced Alignment and Preprocessing,[0],[0]
"Considering the training cost of the proposed hierarchical acoustic architecture, we decided the extra features were not worth the tradeoff.",3.1 Forced Alignment and Preprocessing,[0],[0]
"The output is a 3D MFSCs map with dimensions [N, 64, L].",3.1 Forced Alignment and Preprocessing,[0],[0]
"To extract features from embedded text input at the word level, we first used bidirectional GRUs, which are able to capture the contextual information between words.",3.2 Text Attention Module,[0],[0]
"It can be represented as:
t h→i , t h ← i = bi GRU(Ti), i ∈",3.2 Text Attention Module,[0],[0]
"[1, N ] (2)
where bi GRU is the bidirectional GRU, t h→i and t h←i denote respectively the forward and backward contextual state of the input text.",3.2 Text Attention Module,[0],[0]
We combined t h→i and t h ← i as t hi to represent the feature vector for the ith word.,3.2 Text Attention Module,[0],[0]
"We choose GRUs instead of LSTMs because our experiments show that LSTMs lead to similar performance (0.07% higher accuracy) with around 25% more trainable parameters.
",3.2 Text Attention Module,[0],[0]
"To create an informative word representation, we adopted a word-level attention strategy that generates a one-dimensional vector denoting the importance for each word in a sequence (Yang et al., 2016).",3.2 Text Attention Module,[0],[0]
"As defined by (Bahdanau et al.,
Algorithm 1 FEATURE EXTRACTION 1: procedure FORCED ALIGNMENT 2:",3.2 Text Attention Module,[0],[0]
Determine time interval of each word 3: find wi←→,3.2 Text Attention Module,[0],[0]
"[Aij], j ∈",3.2 Text Attention Module,[0],[0]
"[1, L], i ∈",3.2 Text Attention Module,[0],[0]
"[1, N ] 4: end procedure 5: procedure TEXT BRANCH 6:",3.2 Text Attention Module,[0],[0]
Text Attention Module 7: for i ∈,3.2 Text Attention Module,[0],[0]
"[1, N ] do 8: Ti ← getEmbedded(wi) 9: t hi ← bi GRU(Ti) 10: t ei ← getEnergies(t hi) 11: t αi ← getDistribution(t ei) 12: end for 13: return t hi, t αi 14: end procedure 15: procedure AUDIO BRANCH 16: for i ∈",3.2 Text Attention Module,[0],[0]
"[1, N ] do 17: Frame-Level Attention Module 18: for j ∈",3.2 Text Attention Module,[0],[0]
"[1, L] do 19: f hij ← bi GRU(Aij) 20: f eij ← getEnergies(f hij) 21:",3.2 Text Attention Module,[0],[0]
f αij ← getDistribution(f eij) 22: end for 23:,3.2 Text Attention Module,[0],[0]
"f Vi ← weightedSum(f αij , f hij) 24: Word-Level Attention Module 25: w hi ← bi GRU(f Vi) 26: w ei ← getEnergies(w hi) 27:",3.2 Text Attention Module,[0],[0]
"w αi ← getDistribution(w ei) 28: end for 29: return w hi, w αi 30: end procedure
2014), we compute the textual attentive energies t ei and textual attention distribution t αi by:
t ei = tanh(Wtt hi + bt), i ∈",3.2 Text Attention Module,[0],[0]
"[1, N ] (3)
t αi",3.2 Text Attention Module,[0],[0]
=,3.2 Text Attention Module,[0],[0]
"exp(t ei >vt)∑N k=1exp(t ek >vt) (4)
where Wt and bt are the trainable parameters and vt is a randomly-initialized word-level weight vector in the text branch.",3.2 Text Attention Module,[0],[0]
"To learn the word-level interactions across modalities, we directly use the textual attention distribution t αi and textual bidirectional contextual state t hi as the output to aid word-level fusion, which allows further computations between text and audio branch on both the contextual states and attention distributions.",3.2 Text Attention Module,[0],[0]
"We designed a hierarchical attention model with frame-level acoustic attention and word-level at-
tention for acoustic feature extraction.",3.3 Audio Attention Module,[0],[0]
Frame-level Attention captures the important MFSC frames from the given word to generate the word-level acoustic vector.,3.3 Audio Attention Module,[0],[0]
"Similar to the text attention module, we used a bidirectional GRU:
f h→ij , f h ← ij = bi GRU(Aij), j ∈",3.3 Audio Attention Module,[0],[0]
"[1, L] (5)
where f h→ij and f h ← ij denote the forward and backward contextual states of acoustic frames.",3.3 Audio Attention Module,[0],[0]
"Aij denotes the MFSCs of the jth frame from the ith word, i ∈",3.3 Audio Attention Module,[0],[0]
"[1, N ].",3.3 Audio Attention Module,[0],[0]
"f hij represents the hidden state of the jth frame of the ith word, which consists of f h→ij and f h ← ij .",3.3 Audio Attention Module,[0],[0]
We apply the same attention mechanism used for textual attention module to extract the informative frames using equation 3 and 4.,3.3 Audio Attention Module,[0],[0]
"As shown in Figure 1, the input of equation 3 is f hij and the output is the framelevel acoustic attentive energies f eij .",3.3 Audio Attention Module,[0],[0]
We calculate the frame-level attention distribution f αij by using f eij as the input for equation 4.,3.3 Audio Attention Module,[0],[0]
We form the word-level acoustic vector f Vi by taking a weighted sum of bidirectional contextual state f hij of the frame and the corresponding framelevel attention distribution f αij,3.3 Audio Attention Module,[0],[0]
"Specifically,
f Vi = ∑
j f αijf hij (6)
Word-level Attention aims to capture the word-level acoustic attention distribution w αi based on formed word vector f Vi.",3.3 Audio Attention Module,[0],[0]
"We first used equation 2 to generate the word-level acoustic contextual states w hi, where the input is f Vi and w hi = (w h→i , w h ← i ).",3.3 Audio Attention Module,[0],[0]
"Then, we compute the word-level acoustic attentive energies w ei via equation 3 as the input for equation 4.",3.3 Audio Attention Module,[0],[0]
The final output is an acoustic attention distribution w αi from equation 4 and acoustic bidirectional contextual state w hi.,3.3 Audio Attention Module,[0],[0]
Fusion is critical to leveraging multimodal features for decision-making.,3.4 Word-level Fusion Module,[0],[0]
Simple feature concatenation without considering the time scales ignores the associations across modalities.,3.4 Word-level Fusion Module,[0],[0]
We introduce word-level fusion capable of associating the text and audio at each word.,3.4 Word-level Fusion Module,[0],[0]
"We propose three fusion strategies (Figure 2 and Algorithm 2): horizontal fusion, vertical fusion, and fine-tuning attention fusion.",3.4 Word-level Fusion Module,[0],[0]
"These methods allow easy synchronization between modalities, taking advantage of the attentive associations across text and audio, creating a shared high-level representation.
",3.4 Word-level Fusion Module,[0],[0]
Algorithm 2 FUSION 1: procedure FUSION BRANCH 2: Horizontal Fusion (HF) 3: for i ∈,3.4 Word-level Fusion Module,[0],[0]
"[1, N ] do 4: t Vi ← weighted(t αi, t hi) 5: w Vi ← weighted(w αi, w hi) 6: Vi ← dense([t Vi, w Vi]) 7: end for 8: Vertical Fusion (VF) 9: for i ∈",3.4 Word-level Fusion Module,[0],[0]
"[1, N ] do 10: hi ← dense([t hi, w hi]) 11: s αi ← average([t αi, w αi]) 12: Vi ← weighted(hi, s αi) 13: end for 14: Fine-tuning Attention Fusion (FAF) 15: for i ∈",3.4 Word-level Fusion Module,[0],[0]
"[1, N ] do 16: u ei ← getEnergies(hi) 17: u αi ← getDistribution(u ei, s αi) 18: Vi ← weighted(hi, u αi) 19: end for 20: Decision Making 21: E ← convNet(V1, V2, ..., VN ) 22: return E 23: end procedure
Horizontal Fusion (HF) provides the shared representation that contains both the textual and acoustic information for a given word (Figure 2 (a)).",3.4 Word-level Fusion Module,[0],[0]
The HF has two steps: (i) combining the bidirectional contextual states (t hi and w hi in Figure 1) and attention distributions for each branch (t αi,3.4 Word-level Fusion Module,[0],[0]
and w αi in Figure 1),3.4 Word-level Fusion Module,[0],[0]
independently to form the word-level textual and acoustic representations.,3.4 Word-level Fusion Module,[0],[0]
"As shown in Figure 2, given the input (t αi,
t hi) and (w αi, w hi), we first weighed each input branch by:
t Vi = t αit hi (7)
",3.4 Word-level Fusion Module,[0],[0]
"w Vi = w αiw hi (8)
where t Vi and w Vi are word-level representations for text and audio branches, respectively; (ii) concatenating them into a single space and further applying a dense layer to create the shared context vector Vi, and Vi = (t Vi, w Vi).",3.4 Word-level Fusion Module,[0],[0]
The HF combines the unimodal contextual states and attention weights; there is no attention interaction between the text modality and audio modality.,3.4 Word-level Fusion Module,[0],[0]
"The shared vectors retain the most significant characteristics from respective branches and encourages the decision making to focus on local informative features.
",3.4 Word-level Fusion Module,[0],[0]
"Vertical Fusion (VF) combines textual attentions and acoustic attentions at the word-level, using a shared attention distribution over both modalities instead of focusing on local informative representations (Figure 2 (b)).",3.4 Word-level Fusion Module,[0],[0]
"The VF is computed in three steps: (i) using a dense layer after the concatenation of the word-level textual (t hi) and acoustic (w hi) bidirectional contextual states to form the shared contextual state hi; (ii) averaging the textual (t αi) and acoustic (w αi) attentions for each word as the shared attention distribution s αi; (iii) computing the weight of hi and s αi as final shared context vectors Vi, where Vi = his αi.",3.4 Word-level Fusion Module,[0],[0]
"Because the shared attention distribution (s αi) is based on averages of unimodal attentions, it is a joint attention of both textual and acoustic attentive information.
",3.4 Word-level Fusion Module,[0],[0]
"Fine-tuning Attention Fusion (FAF) preserves the original unimodal attentions and provides
a fine-tuning attention for the final prediction (Figure2 (c)).",3.4 Word-level Fusion Module,[0],[0]
The averaging of attention weights in vertical fusion potentially limits the representational power.,3.4 Word-level Fusion Module,[0],[0]
"Addressing such issue, we propose a trainable attention layer to tune the shared attention in three steps: (i) computing the shared attention distribution s αi and shared bidirectional contextual states hi separately using the same approach as in vertical fusion; (ii) applying attention fine-tuning:
u ei = tanh(Wuhi + bu) (9)
u αi = exp(u ei >vu)∑N k=1exp(u ek >vu) +",3.4 Word-level Fusion Module,[0],[0]
"s αi (10)
where Wu, bu, and vu are additional trainable parameters.",3.4 Word-level Fusion Module,[0],[0]
The u αi can be understood as the sum of the fine-tuning score and the original shared attention distribution s αi; (iii) calculating the weight of u αi and hi to form the final shared context vector Vi.,3.4 Word-level Fusion Module,[0],[0]
The output of the fusion layer Vi is the ith shared word-level vectors.,3.5 Decision Making,[0],[0]
"To further make use of the combined features for classification, we applied a CNN structure with one convolutional layer and one max-pooling layer to extract the final representation from shared word-level vectors (Poria et al., 2016; Wang et al., 2016).",3.5 Decision Making,[0],[0]
"We set up various widths for the convolutional filters (Kim, 2014) and generated a feature map ck by:
fi = tanh(WcVi:i+k−1 + bc) (11)
ck = max{f1, f2, ..., fN} (12)
where k is the width of the convolutional filters, fi represents the features from window i to i+k−1.",3.5 Decision Making,[0],[0]
Wc and bc are the trainable weights and biases.,3.5 Decision Making,[0],[0]
We get the final representation c by concatenating all the feature maps.,3.5 Decision Making,[0],[0]
A softmax function is used for the final classification.,3.5 Decision Making,[0],[0]
"We evaluated our model on four published datasets: two multimodal sentiment datasets (MOSI and YouTube) and two multimodal emotion recognition datasets (IEMOCAP and EmotiW).
",4.1 Datasets,[0],[0]
"MOSI dataset is a multimodal sentiment intensity and subjectivity dataset consisting of 93 reviews with 2199 utterance segments (Zadeh et al., 2016).",4.1 Datasets,[0],[0]
Each segment was labeled by five individual annotators between -3 (strong negative) to +3 (strong positive).,4.1 Datasets,[0],[0]
"We used binary labels based on the sign of the annotations’ average.
",4.1 Datasets,[0],[0]
"YouTube dataset is an English multimodal dataset that contains 262 positive, 212 negative, and 133 neutral utterance-level clips provided by (Morency et al., 2011).",4.1 Datasets,[0],[0]
"We only consider the positive and negative labels during our experiments.
",4.1 Datasets,[0],[0]
"IEMOCAP is a multimodal emotion dataset including visual, audio, and text data (Busso et al., 2008).",4.1 Datasets,[0],[0]
"For each sentence, we used the label agreed on by the majority (at least two of the three annotators).",4.1 Datasets,[0],[0]
"In this study, we evaluate both the 4- catgeory (happy+excited, sad, anger, and neutral) and 5-catgeory(happy+excited, sad, anger, neutral, and frustration) emotion classification problems.",4.1 Datasets,[0],[0]
"The final dataset consists of 586 happy, 1005 excited, 1054 sad, 1076 anger, 1677 neutral, and 1806 frustration.
",4.1 Datasets,[0],[0]
EmotiW2 is an audio-visual multimodal utterance-level emotion recognition dataset consist of video clips.,4.1 Datasets,[0],[0]
"To keep the consistency with the IEMOCAP dataset, we used four emotion categories as the final dataset including 150 happy, 117 sad, 133 anger, and 144 neutral.",4.1 Datasets,[0],[0]
We used IBM Watson3 speech to text software to transcribe the audio data into text.,4.1 Datasets,[0],[0]
We compared the proposed architecture to published models.,4.2 Baselines,[0],[0]
"Because our model focuses on extracting sentiment and emotions from human speech, we only considered the audio and text branch applied in the previous studies.",4.2 Baselines,[0],[0]
BL-SVM extracts a bag-of-words as textual features and low-level descriptors as acoustic features.,4.2.1 Sentiment Analysis Baselines,[0],[0]
"An SVM structure is used to classify the sentiments (Rosas et al., 2013).
",4.2.1 Sentiment Analysis Baselines,[0],[0]
LSTM-SVM uses LLDs as acoustic features and bag-of-n-grams (BoNGs) as textual features.,4.2.1 Sentiment Analysis Baselines,[0],[0]
"The final estimate is based on decision-level fusion of text and audio predictions (Wöllmer et al., 2013).
",4.2.1 Sentiment Analysis Baselines,[0],[0]
"2https://cs.anu.edu.au/few/ChallengeDetails.html 3https://www.ibm.com/watson/developercloud/speech-
to-text/api/v1/
C-MKL1 uses a CNN structure to capture the textual features and fuses them via multiple kernel learning for sentiment analysis (Poria et al., 2015).
",4.2.1 Sentiment Analysis Baselines,[0],[0]
"TFN uses a tensor fusion network to extract interactions between different modality-specific features (Zadeh et al., 2017).
LSTM(A) introduces a word-level LSTM with temporal attention structure to predict sentiments on MOSI dataset (Chen et al., 2017).",4.2.1 Sentiment Analysis Baselines,[0],[0]
SVM Trees extracts LLDs and handcrafted bagof-words as features.,4.2.2 Emotion Recognition Baselines,[0],[0]
"The model automatically generates an ensemble of SVM trees for emotion classification (Rozgic et al., 2012).
",4.2.2 Emotion Recognition Baselines,[0],[0]
GSV-eVector generates new acoustic representations from selected LLDs using Gaussian Supervectors and extracts a set of weighed handcrafted textual features as an eVector.,4.2.2 Emotion Recognition Baselines,[0],[0]
"A linear kernel SVM is used as the final classifier (Jin et al., 2015).
",4.2.2 Emotion Recognition Baselines,[0],[0]
C-MKL2 extracts textual features using a CNN and uses openSMILE to extract 6373 acoustic features.,4.2.2 Emotion Recognition Baselines,[0],[0]
"Multiple kernel learning is used as the final classifier (Poria et al., 2016).
",4.2.2 Emotion Recognition Baselines,[0],[0]
H-DMS uses a hybrid deep multimodal structure to extract both the text and audio emotional features.,4.2.2 Emotion Recognition Baselines,[0],[0]
"A deep neural network is used for feature-level fusion (Gu et al., 2018).",4.2.2 Emotion Recognition Baselines,[0],[0]
"Utterance-level Fusion (UL-Fusion) focuses on fusing text and audio features from an entire utterance (Gu et al., 2017).",4.2.3 Fusion Baselines,[0],[0]
We simply concatenate the textual and acoustic representations into a joint feature representation.,4.2.3 Fusion Baselines,[0],[0]
"A softmax function is used for sentiment and emotion classification.
",4.2.3 Fusion Baselines,[0],[0]
"Decision-level Fusion (DL-Fusion) Inspired by (Wöllmer et al., 2013), we extract textual and
acoustic sentence representations individually and infer the results via two softmax classifiers, respectively.",4.2.3 Fusion Baselines,[0],[0]
"As suggested by Wöllmer, we calculate a weighted sum of the text (1.2) result and audio (0.8) result as the final prediction.",4.2.3 Fusion Baselines,[0],[0]
We implemented the model in Keras with Tensorflow as the backend.,4.3 Model Training,[0],[0]
"We set 100 as the dimension for each GRU, meaning the bidirectional GRU dimension is 200.",4.3 Model Training,[0],[0]
"For the decision making, we selected 2, 3, 4, and 5 as the filter width and apply 300 filters for each width.",4.3 Model Training,[0],[0]
We used the rectified linear unit (ReLU) activation function and set 0.5 as the dropout rate.,4.3 Model Training,[0],[0]
"We also applied batch normalization functions between each layer to overcome internal covariate shift (Ioffe and Szegedy, 2015).",4.3 Model Training,[0],[0]
We first trained the text attention module and audio attention module individually.,4.3 Model Training,[0],[0]
"Then, we tuned the fusion network based on the word-level representation outputs from each fine-tuning module.",4.3 Model Training,[0],[0]
"For all training procedures, we set the learning rate to 0.001 and used Adam optimization and categorical cross-entropy loss.",4.3 Model Training,[0],[0]
"For all datasets, we considered the speakers independent and used an 80-20 training-testing split.",4.3 Model Training,[0],[0]
We further separated 20% from the training dataset for validation.,4.3 Model Training,[0],[0]
We trained the model with 5-fold cross validation and used 8 as the mini batch size.,4.3 Model Training,[0],[0]
We set the same amount of samples from each class to balance the training dataset during each iteration.,4.3 Model Training,[0],[0]
"The experimental results of different datasets show that our proposed architecture achieves state-of-the-art performance in both sentiment
analysis and emotion recognition (Table 1).",5.1 Comparison with Baselines,[0],[0]
"We re-implemented some published methods (Rosas et al., 2013; Wöllmer et al., 2013) on MOSI to get baselines.
",5.1 Comparison with Baselines,[0],[0]
"For sentiment analysis, the proposed architecture with FAF strategy achieves 76.4% weighted accuracy, which outperforms all the five baselines (Table 1).",5.1 Comparison with Baselines,[0],[0]
The result demonstrates that the proposed hierarchical attention architecture and word-level fusion strategies indeed help improve the performance.,5.1 Comparison with Baselines,[0],[0]
"There are several findings worth mentioning: (i) our model outperforms the baselines without using the low-level handcrafted acoustic features, indicating the sufficiency of MFSCs; (ii) the proposed approach achieves performance comparable to the model using text, audio, and visual data together (Zadeh et al., 2017).",5.1 Comparison with Baselines,[0],[0]
"This demonstrates that the visual features do not contribute as much during the fusion and prediction on MOSI; (iii) we notice that (Poria et al., 2017b) reports better accuracy (79.3%) on MOSI, but their model uses a set of utterances instead of a single utterance as input.
",5.1 Comparison with Baselines,[0],[0]
"For emotion recognition, our model with FAF achieves 72.7% accuracy, outperforming all the baselines.",5.1 Comparison with Baselines,[0],[0]
"The result shows the proposed model brings a significant accuracy gain to emotion recognition, demonstrating the pros of the finetuning attention structure.",5.1 Comparison with Baselines,[0],[0]
It also shows that wordlevel attention indeed helps extract emotional features.,5.1 Comparison with Baselines,[0],[0]
"Compared to C-MKL2 and SVM Trees that require feature selection before fusion and prediction, our model does not need an additional architecture to select features.",5.1 Comparison with Baselines,[0],[0]
"We further evaluated our models on 5 emotion categories, including frustration.",5.1 Comparison with Baselines,[0],[0]
Our model shows 4.2% performance improvement over H-DMS and achieves 0.644 weighted-F1.,5.1 Comparison with Baselines,[0],[0]
"As H-DMS only achieves 0.594 F1 and also uses low-level handcrafted features, our model is more robust and efficient.
",5.1 Comparison with Baselines,[0],[0]
"From Table 1, all the three proposed fusion strategies outperform UL-Fusion and DL-Fusion on both MOSI and IEMOCAP.",5.1 Comparison with Baselines,[0],[0]
"Unlike utterancelevel fusion that ignores the time-scale-sensitive associations across modalities, word-level fusion combines the modality-specific features for each word by aligning text and audio, allowing associative learning between the two modalities, similar to what humans do in natural conversation.",5.1 Comparison with Baselines,[0],[0]
"The result indicates that the proposed methods improve the model performance by around 6% accu-
racy.",5.1 Comparison with Baselines,[0],[0]
"We also notice that the structure with FAF outperforms the HF and VF on both MOSI and IEMOCAP dataset, which demonstrates the effectiveness and importance of the FAF strategy.",5.1 Comparison with Baselines,[0],[0]
"From Table 2, we see that textual information dominates the sentiment prediction on MOSI and there is an only 1.4% accuracy improvement from fusing text and audio.",5.2 Modality and Generalization Analysis,[0],[0]
"However, on IEMOCAP, audio-only outperforms text-only, but as expected, there is a significant performance improvement by combining textual and audio.",5.2 Modality and Generalization Analysis,[0],[0]
"The difference in modality performance might because of the more significant role vocal delivery plays in emotional expression than in sentimental expression.
",5.2 Modality and Generalization Analysis,[0],[0]
We further tested the generalizability of the proposed model.,5.2 Modality and Generalization Analysis,[0],[0]
"For sentiment generalization testing, we trained the model on MOSI and tested on the YouTube dataset (Table 3), which achieves 66.2% accuracy and 0.665 F1 scores.",5.2 Modality and Generalization Analysis,[0],[0]
"For emotion recognition generalization testing, we tested the model (trained on IEMOCAP) on EmotiW and achieves 61.4% accuracy.",5.2 Modality and Generalization Analysis,[0],[0]
"The potential reasons that may influence the generalization are: (i) the biased labeling for different datasets (five annotators of MOSI vs one annotator of Youtube); (ii) incomplete utterance in YouTube dataset (such as “about”, “he”, etc.); (iii) without enough speech information (EmotiW is a wild audiovisual dataset that focuses on facial expression).",5.2 Modality and Generalization Analysis,[0],[0]
"Our model allows us to easily visualize the attention weights of text, audio, and fusion to better understand how the attention mechanism works.",5.3 Visualize Attentions,[0],[0]
"We introduce the emotional distribution visualizations for word-level acoustic attention (w αi), word-level textual attention (t αi), shared attention (s αi), and fine-tuning attention based on the FAF structure (u αi) for two example sentences (Figure 3).",5.3 Visualize Attentions,[0],[0]
"The color gradation represents the importance of the corresponding source data at the word-level.
",5.3 Visualize Attentions,[0],[0]
"Based on our visualization, the textual attention distribution (t αi) denotes the words that carry the most emotional significance, such as “hell” for anger (Figure 3 a).",5.3 Visualize Attentions,[0],[0]
"The textual attention shows that “don’t”, “like”, and “west-sider” have similar weights in the happy example (Figure 3 b).",5.3 Visualize Attentions,[0],[0]
It is hard to assign this sentence happy given only the text attention.,5.3 Visualize Attentions,[0],[0]
"However, the acoustic attention focuses on “you’re” and “west-sider”, removing emphasis from “don’t” and “like”.",5.3 Visualize Attentions,[0],[0]
"The shared attention (s αi) and fine-tuning attention (u αi) successfully combine both textual and acoustic attentions and assign joint attention to the correct words, which demonstrates that the proposed method can capture emphasis from both modalities at the word-level.",5.3 Visualize Attentions,[0],[0]
There are several limitations and potential solutions worth mentioning: (i) the proposed architecture uses both the audio and text data to analyze the sentiments and emotions.,6 Discussion,[0],[0]
"However, not all the data sources contain or provide textual information.",6 Discussion,[0],[0]
Many audio-visual emotion clips only have acoustic and visual information.,6 Discussion,[0],[0]
The proposed architecture is more related to spoken language analysis than predicting the sentiments or emotions based on human speech.,6 Discussion,[0],[0]
Automatic speech recognition provides a potential solution for generating the textual information from vocal signals.,6 Discussion,[0],[0]
"(ii)
",6 Discussion,[0],[0]
The word alignment can be easily applied to human speech.,6 Discussion,[0],[0]
"However, it is difficult to align the visual information with text, especially if the text only describes the video or audio.",6 Discussion,[0],[0]
Incorporating visual information into an aligning model like ours would be an interesting research topic.,6 Discussion,[0],[0]
"(iii) The limited amount of multimodal sentiment analysis and emotion recognition data is a key issue for current research, especially for deep models that require a large number of samples.",6 Discussion,[0],[0]
"Compared large unimodal sentiment analysis and emotion recognition datasets, the MOSI dataset only consists of 2199 sentence-level samples.",6 Discussion,[0],[0]
"In our experiments, the EmotiW and MOUD datasets could only be used for generalization analysis due to their small size.",6 Discussion,[0],[0]
Larger and more general datasets are necessary for multimodal sentiment analysis and emotion recognition in the future.,6 Discussion,[0],[0]
"In this paper, we proposed a deep multimodal architecture with hierarchical attention for sentiment and emotion classification.",7 Conclusion,[0],[0]
"Our model aligned the text and audio at the word-level and applied attention distributions on textual word vectors, acoustic frame vectors, and acoustic word vectors.",7 Conclusion,[0],[0]
We introduced three fusion strategies with a CNN structure to combine word-level features to classify emotions.,7 Conclusion,[0],[0]
Our model outperforms the state-ofthe-art methods and provides effective visualization of modality-specific features and fusion feature interpretation.,7 Conclusion,[0],[0]
We would like to thank the anonymous reviewers for their valuable comments and feedback.,Acknowledgments,[0],[0]
We thank the useful suggestions from Kaixiang Huang.,Acknowledgments,[0],[0]
This research was funded by the National Institutes of Health under Award Number R01LM011834.,Acknowledgments,[0],[0]
"Multimodal affective computing, learning to recognize and interpret human affect and subjective information from multiple data sources, is still challenging because: (i) it is hard to extract informative features to represent human affects from heterogeneous inputs; (ii) current fusion strategies only fuse different modalities at abstract levels, ignoring time-dependent interactions between modalities.",abstractText,[0],[0]
"Addressing such issues, we introduce a hierarchical multimodal architecture with attention and word-level fusion to classify utterancelevel sentiment and emotion from text and audio data.",abstractText,[0],[0]
"Our introduced model outperforms state-of-the-art approaches on published datasets, and we demonstrate that our model’s synchronized attention over modalities offers visual interpretability.",abstractText,[0],[0]
Multimodal Affective Analysis Using Hierarchical Attention Strategy with Word-Level Alignment,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 679–686 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics
Emojis are small images that are commonly included in social media text messages. The combination of visual and textual content in the same message builds up a modern way of communication, that automatic systems are not used to deal with. In this paper we extend recent advances in emoji prediction by putting forward a multimodal approach that is able to predict emojis in Instagram posts. Instagram posts are composed of pictures together with texts which sometimes include emojis. We show that these emojis can be predicted by using the text, but also using the picture. Our main finding is that incorporating the two synergistic modalities, in a combined model, improves accuracy in an emoji prediction task. This result demonstrates that these two modalities (text and images) encode different information on the use of emojis and therefore can complement each other.",text,[0],[0]
"In the past few years the use of emojis in social media has increased exponentially, changing the way we communicate.",1 Introduction,[0],[0]
The combination of visual and textual content poses new challenges for information systems which need not only to deal with the semantics of text but also that of images.,1 Introduction,[0],[0]
"Recent work (Barbieri et al., 2017) has shown that textual information can be used to predict emojis associated to text.",1 Introduction,[0],[0]
"In this paper we show that in the current context of multimodal communication where texts and images are combined in social networks, visual information should be combined with texts in order to obtain more accurate emojiprediction models.
",1 Introduction,[0],[0]
We explore the use of emojis in the social media platform Instagram.,1 Introduction,[0],[0]
"We put forward a multimodal approach to predict the emojis associated to an In-
stagram post, given its picture and text1.",1 Introduction,[0],[0]
"Our task and experimental framework are similar to (Barbieri et al., 2017), however, we use different data (Instagram instead of Twitter) and, in addition, we rely on images to improve the selection of the most likely emojis to associate to a post.",1 Introduction,[0],[0]
We show that a multimodal approach (textual and visual content of the posts) increases the emoji prediction accuracy compared to the one that only uses textual information.,1 Introduction,[0],[0]
"This suggests that textual and visual content embed different but complementary features of the use of emojis.
",1 Introduction,[0],[0]
"In general, an effective approach to predict the emoji to be associated to a piece of content may help to improve natural language processing tasks (Novak et al., 2015), such as information retrieval, generation of emoji-enriched social media content, suggestion of emojis when writing text messages or sharing pictures online.",1 Introduction,[0],[0]
"Given that emojis may also mislead humans (Miller et al., 2017), the automated prediction of emojis may help to achieve better language understanding.",1 Introduction,[0],[0]
"As a consequence, by modeling the semantics of emojis, we can improve highly-subjective tasks like sentiment analysis, emotion recognition and irony detection (Felbo et al., 2017).",1 Introduction,[0],[0]
Dataset:,2 Dataset and Task,[0],[0]
"We gathered Instagram posts published between July 2016 and October 2016, and geolocalized in the United States of America.",2 Dataset and Task,[0],[0]
"We considered only posts that contained a photo together with the related user description of at least 4 words and exactly one emoji.
",2 Dataset and Task,[0],[0]
"Moreover, as done by Barbieri et al. (2017), we considered only the posts which include one and only one of the 20 most frequent emojis (the
1In this paper we only utilize the first comment issued by the user who posted the picture.
679
most frequent emojis are shown in Table 3).",2 Dataset and Task,[0],[0]
"Our dataset is composed of 299,809 posts, each containing a picture, the text associated to it and only one emoji.",2 Dataset and Task,[0],[0]
"In the experiments we also considered the subsets of the 10 (238,646 posts) and 5 most frequent emojis (184,044 posts) (similarly to the approach followed by Barbieri et al. (2017)).
",2 Dataset and Task,[0],[0]
"Task: We extend the experimental scheme of Barbieri et al. (2017), by considering also visual information when modeling posts.",2 Dataset and Task,[0],[0]
We cast the emoji prediction problem as a classification task: given an image or a text (or both inputs in the multimodal scenario) we select the most likely emoji that could be added to (thus used to label) such contents.,2 Dataset and Task,[0],[0]
"The task for our machine learning models is, given the visual and textual content of a post, to predict the single emoji that appears in the input comment.",2 Dataset and Task,[0],[0]
We present and motivate the models that we use to predict an emoji given an Instagram post composed by a picture and the associated comment.,3 Models,[0],[0]
"Deep Residual Networks (ResNets) (He et al., 2016) are Convolutional Neural Networks which were competitive in several image classification tasks (Russakovsky et al., 2015; Lin et al., 2014) and showed to be one of the best CNN architectures for image recognition.",3.1 ResNets,[0],[0]
"ResNet is a feedforward CNN that exploits “residual learning”, by bypassing two or more convolution layers (like similar previous approaches (Sermanet and LeCun, 2011)).",3.1 ResNets,[0],[0]
"We use an implementation of the original ResNet where the scale and aspect ratio augmentation are from (Szegedy et al., 2015), the photometric distortions from (Howard, 2013) and weight decay is applied to all weights and biases (instead of only weights of the convolution layers).",3.1 ResNets,[0],[0]
"The network we used is composed of 101 layers (ResNet-101), initialized with pretrained parameters learned on ImageNet (Deng et al., 2009).",3.1 ResNets,[0],[0]
We use this model as a starting point to later finetune it on our emoji classification task.,3.1 ResNets,[0],[0]
Learning rate was set to 0.0001 and we early stopped the training when there was not improving in the validation set.,3.1 ResNets,[0],[0]
"Fastext (Joulin et al., 2017) is a linear model for text classification.",3.2 FastText,[0],[0]
"We decided to employ FastText as it has been shown that on specific classification tasks, it can achieve competitive results, comparable to complex neural classifiers (RNNs and CNNs), while being much faster.",3.2 FastText,[0],[0]
"FastText represents a valid approach when dealing with social media content classification, where huge amounts of data needs to be processed and new and relevant information is continuously generated.",3.2 FastText,[0],[0]
"The FastText algorithm is similar to the CBOW algorithm (Mikolov et al., 2013), where the middle word is replaced by the label, in our case the emoji.",3.2 FastText,[0],[0]
"Given a set of N documents, the loss that the model attempts to minimize is the negative log-likelihood over the labels (in our case, the emojis):
loss = − 1 N
n=1∑
N
en log(softmax (BAxn))
where en is the emoji included in the n-th Instagram post, represented as hot vector, and used as label.",3.2 FastText,[0],[0]
"A and B are affine transformations (weight matrices), and xn is the unit vector of the bag of features of the n-th document (comment).",3.2 FastText,[0],[0]
"The bag of features is the average of the input words, represented as vectors with a look-up table.",3.2 FastText,[0],[0]
Barbieri et al. (2017) propose a recurrent neural network approach for the emoji prediction task.,3.3 B-LSTM Baseline,[0],[0]
"We use this model as baseline, to verify whether FastText achieves comparable performance.",3.3 B-LSTM Baseline,[0],[0]
"They used a Bidirectional LSTM with character representation of the words (Ling et al., 2015; Ballesteros et al., 2015) to handle orthographic variants (or even spelling errors) of the same word that occur in social media (e.g. cooooool vs cool).",3.3 B-LSTM Baseline,[0],[0]
"In order to study the relation between Instagram posts and emojis, we performed two different experiments.",4 Experiments and Evaluation,[0],[0]
In the first experiment (Section 4.2) we compare the FastText model with the state of the art on emoji classification (B-LSTM) by Barbieri et al. (2017).,4 Experiments and Evaluation,[0],[0]
Our second experiment (Section 4.3) evaluates the visual (ResNet) and textual (FastText) models on the emoji prediction task.,4 Experiments and Evaluation,[0],[0]
"Moreover, we evaluate a multimodal combination of both models respectively based on visual and
textual inputs.",4 Experiments and Evaluation,[0],[0]
"Finally we discuss the contribution of each modality to the prediction task.
",4 Experiments and Evaluation,[0],[0]
"We use 80% of our dataset (introduced in Section 2) for training, 10% to tune our models, and 10% for testing (selecting the sets randomly).",4 Experiments and Evaluation,[0],[0]
"To model visual features we first finetune the ResNet (process described in Section 3.1) on the emoji prediction task, then extract the vectors from the input of the last fully connected layer (before the softmax).",4.1 Feature Extraction and Classifier,[0],[0]
"The textual embeddings are the bag of features shown in Section 3.2 (the xn vectors), extracted after training the FastText model on the emoji prediction task.
",4.1 Feature Extraction and Classifier,[0],[0]
"With respect to the combination of textual and visual modalities, we adopt a middle fusion approach (Kiela and Clark, 2015): we associate to each Instagram post a multimodal embedding obtained by concatenating the unimodal representations of the same post (i.e. the visual and textual embeddings), previously learned.",4.1 Feature Extraction and Classifier,[0],[0]
"Then, we feed a classifier2 with visual (ResNet), textual (FastText), or multimodal feature embeddings, and test the accuracy of the three systems.",4.1 Feature Extraction and Classifier,[0],[0]
"To compare the FastText model with the word and character based B-LSTMs presented by Barbieri et al. (2017), we consider the same three emoji prediction tasks they proposed: top-5, top-10 and top-20 emojis most frequently used in their Tweet datasets.",4.2 B-LSTM / FastText Comparison,[0],[0]
In this comparison we used the same Twitter datasets.,4.2 B-LSTM / FastText Comparison,[0],[0]
"As we can see in Table 1 FastText model is competitive, and it is also able to outperform the character based B-LSTM in one of the emoji prediction tasks (top-20 emojis).",4.2 B-LSTM / FastText Comparison,[0],[0]
"This result suggests that we can employ FastText to represent Social Media short text (such as Twitter or Instragram) with reasonable accuracy.
",4.2 B-LSTM / FastText Comparison,[0],[0]
2L2 regularized logistic regression,4.2 B-LSTM / FastText Comparison,[0],[0]
"We present the results of the three emoji classification tasks, using the visual, textual and multimodal features (see Table 2).
",4.3 Multimodal Emoji Prediction,[0],[0]
"The emoji prediction task seems difficult by just using the image of the Instagram post (Visual), even if it largely outperforms the majority baseline3 and weighted random4.",4.3 Multimodal Emoji Prediction,[0],[0]
We achieve better performances when we use feature embeddings extracted from the text.,4.3 Multimodal Emoji Prediction,[0],[0]
"The most interesting finding is that when we use a multimodal combination of visual and textual features, we get a nonnegligible improvement.",4.3 Multimodal Emoji Prediction,[0],[0]
"This suggests that these two modalities embed different representations of the posts, and when used in combination they are synergistic.",4.3 Multimodal Emoji Prediction,[0],[0]
"It is also interesting to note that the more emojis to predict, the higher improvement the multimodal system provides over the text only system (3.28% for top-5 emojis, 7.31% for top-10 emojis, and 13.42 for the top-20 emojis task).",4.3 Multimodal Emoji Prediction,[0],[0]
"In Table 3 we show the results for each class in the top-20 emojis task.
",4.4 Qualitative Analysis,[0],[0]
The emoji with highest F1 using the textual features is the most frequent one (0.62) and the US flag (0.52).,4.4 Qualitative Analysis,[0],[0]
"The latter seems easy to predict since it appears in specific contexts: when the word USA/America is used (or when American cities are referred, like #NYC).
",4.4 Qualitative Analysis,[0],[0]
The hardest emojis to predict by the text only system are the two gestures (0.12) and (0.13).,4.4 Qualitative Analysis,[0],[0]
"The first one is often selected when the gold stan-
3Always predict since it is the most frequent emoji.",4.4 Qualitative Analysis,[0],[0]
"4Random keeping labels distribution of the training set
dard emoji is the second one or is often mispredicted by wrongly selecting or .
",4.4 Qualitative Analysis,[0],[0]
Another relevant confusion scenario related to emoji prediction has been spotted by Barbieri et al. (2017): relying on Twitter textual data they showed that the emoji was hard to predict as it was used similarly to .,4.4 Qualitative Analysis,[0],[0]
"Instead when we consider Instagram data, the emoji is easier to predict (0.23), even if it is often confused with .
",4.4 Qualitative Analysis,[0],[0]
"When we rely on visual contents (Instagram picture), the emojis which are easily predicted are the ones in which the associated photos are similar.",4.4 Qualitative Analysis,[0],[0]
"For instance, most of the pictures associated to
are dog/pet pictures.",4.4 Qualitative Analysis,[0],[0]
"Similarly, is predicted along with very bright pictures taken outside.",4.4 Qualitative Analysis,[0],[0]
is correctly predicted along with pictures related to gym and fitness.,4.4 Qualitative Analysis,[0],[0]
"The accuracy of is also high since most posts including this emoji are related to fitness (and the pictures are simply either selfies at the gym, weight lifting images, or protein food).
",4.4 Qualitative Analysis,[0],[0]
Employing a multimodal approach improves performance.,4.4 Qualitative Analysis,[0],[0]
"This means that the two modalities are somehow complementary, and adding visual information helps to solve potential ambiguities that arise when relying only on textual content.",4.4 Qualitative Analysis,[0],[0]
In Figure 1 we report the confusion matrix of the multimodal model.,4.4 Qualitative Analysis,[0],[0]
"The emojis are plotted from the most frequent to the least, and we can see that the model tends to mispredict emojis selecting more frequent emojis (the left part of the matrix is brighter).",4.4 Qualitative Analysis,[0],[0]
"In order to show the parts of the image most relevant for each class we analyze the global average pooling (Lin et al., 2013) on the convolutional
feature maps (Zhou et al., 2016).",4.4.1 Saliency Maps,[0],[0]
By visually observing the image heatmaps of the set of Instagram post pictures we note that in most cases it is quite difficult to determine a clear association between the emoji used by the user and some particular portion of the image.,4.4.1 Saliency Maps,[0],[0]
"Detecting the correct emoji given an image is harder than a simple object recognition task, as the emoji choice depends on subjective emotions of the user who posted the image.",4.4.1 Saliency Maps,[0],[0]
"In Figure 2 we show the first four predictions of the CNN for three pictures, and where the network focuses (in red).",4.4.1 Saliency Maps,[0],[0]
"We can see that in the first example the network selects the smile with sunglasses because of the legs in the bottom of the image, the dog emoji is selected while focusing on the dog in the image, and the smiling emoji while focusing on the person in the back, who is lying on a hammock.",4.4.1 Saliency Maps,[0],[0]
"In the second example the network selects again the due to the water and part of the kayak, the heart emoji focusing on the city landscape, and the praying emoji
focusing on the sky.",4.4.1 Saliency Maps,[0],[0]
"The same “praying” emoji is also selected when focusing on the luxury car in the third example, probably because the same emoji is used to express desire, i.e. “please, I want this awesome car”.
",4.4.1 Saliency Maps,[0],[0]
"It is interesting to note that images can give context to textual messages like in the following Instagram posts: (1)“Love my new home ” (associated to a picture of a bright garden, outside) and (2) “I can’t believe it’s the first day of school!!!
",4.4.1 Saliency Maps,[0],[0]
I love being these boys’ mommy!!!!,4.4.1 Saliency Maps,[0],[0]
#myboys #mommy ” (associated to picture of two boys wearing two blue shirts).,4.4.1 Saliency Maps,[0],[0]
In both examples the textual system predicts .,4.4.1 Saliency Maps,[0],[0]
"While the multimodal system correctly predicts both of them: the blue color in the picture associated to (2) helps to change the color of the heart, and the sunny/bright picture of the garden in (1) helps to correctly predict .",4.4.1 Saliency Maps,[0],[0]
"Modeling the semantics of emojis, and their applications, is a relatively novel research problem with direct applications in any social media task.",5 Related Work,[0],[0]
"Since emojis do not have a clear grammar, it is not clear their role in text messages.",5 Related Work,[0],[0]
"Emojis are considered function words or even affective markers (Na’aman et al., 2017), that can potentially affect the overall semantics of a message (Donato and Paggio, 2017).
",5 Related Work,[0],[0]
"Emojis can encode different meanings, and they can be interpreted differently.",5 Related Work,[0],[0]
"Emoji interpretation has been explored user-wise (Miller et al., 2017), location-wise, specifically in countries (Barbieri et al., 2016b) and cities (Barbieri et al., 2016a), and gender-wise (Chen et al., 2017) and time-wise (Barbieri et al., 2018).
",5 Related Work,[0],[0]
"Emoji sematics and usage have been studied with distributional semantics, with models trained on Twitter data (Barbieri et al., 2016c), Twitter data together with the official unicode description (Eisner et al., 2016), or using text from a popular keyboard app Ai et al. (2017).",5 Related Work,[0],[0]
"In the same
context, Wijeratne et al. (2017a) propose a platform for exploring emoji semantics.",5 Related Work,[0],[0]
"In order to further study emoji semantics, two datasets with pairwise emoji similarity, with human annotations, have been proposed: EmoTwi50 (Barbieri et al., 2016c) and EmoSim508 (Wijeratne et al., 2017b).",5 Related Work,[0],[0]
"Emoji similarity has been also used for proposing efficient keyboard emoji organization (Pohl et al., 2017).",5 Related Work,[0],[0]
"Recently, Barbieri and Camacho-Collados (2018) show that emoji modifiers (skin tones and gender) can affect the semantics vector representation of emojis.
",5 Related Work,[0],[0]
Emoji play an important role in the emotional content of a message.,5 Related Work,[0],[0]
"Several sentiment lexicons for emojis have been proposed (Novak et al., 2015; Kimura and Katsurai, 2017; Rodrigues et al., 2018) and also studies in the context of emotion and emojis have been published recently (Wood and Ruder, 2016; Hu et al., 2017).
",5 Related Work,[0],[0]
"During the last decade several studies have shown how sentiment analysis improves when we jointly leverage information coming from different modalities (e.g. text, images, audio, video) (Morency et al., 2011; Poria et al., 2015; Tran and Cambria, 2018).",5 Related Work,[0],[0]
"In particular, when we deal with Social Media posts, the presence of both textual and visual content has promoted a number of investigations on sentiment or emotions (Baecchi et al., 2016; You et al., 2016b,a; Yu et al., 2016; Chen et al., 2015) or emojis (Cappallo et al., 2015, 2018).",5 Related Work,[0],[0]
In this work we explored the use of emojis in a multimodal context (Instagram posts).,6 Conclusions,[0],[0]
"We have shown that using a synergistic approach, thus relying on both textual and visual contents of social media posts, we can outperform state of the art unimodal approaches (based only on textual contents).",6 Conclusions,[0],[0]
"As future work, we plan to extend our models by considering the prediction of more than one emoji per Social Media post and also considering a bigger number of labels.",6 Conclusions,[0],[0]
We thank the anonymous reviewers for their important suggestions.,Acknowledgments,[0],[0]
"Francesco B. and Horacio S. acknowledge support from the TUNER project (TIN2015-65308-C5-5-R, MINECO/FEDER, UE) and the Maria de Maeztu Units of Excellence Programme (MDM-2015-0502).",Acknowledgments,[0],[0]
Emojis are small images that are commonly included in social media text messages.,abstractText,[0],[0]
"The combination of visual and textual content in the same message builds up a modern way of communication, that automatic systems are not used to deal with.",abstractText,[0],[0]
In this paper we extend recent advances in emoji prediction by putting forward a multimodal approach that is able to predict emojis in Instagram posts.,abstractText,[0],[0]
Instagram posts are composed of pictures together with texts which sometimes include emojis.,abstractText,[0],[0]
"We show that these emojis can be predicted by using the text, but also using the picture.",abstractText,[0],[0]
"Our main finding is that incorporating the two synergistic modalities, in a combined model, improves accuracy in an emoji prediction task.",abstractText,[0],[0]
This result demonstrates that these two modalities (text and images) encode different information on the use of emojis and therefore can complement each other.,abstractText,[0],[0]
Multimodal Emoji Prediction,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1481–1491 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"FrameNet Semantic Role Labeling analyzes sentences with respect to frame-semantic structures based on FrameNet (Fillmore et al., 2003).",1 Introduction,[0],[0]
"Typically, this involves two steps: First, Frame Identification (FrameId), capturing the context around a predicate (frame evoking element) and assigning a frame, basically a word sense label for a prototypical situation, to it.",1 Introduction,[0],[0]
"Second, Role Labeling, i.e. identifying the participants (fillers) of the predicate and connecting them with predefined frame-
∗named alphabetically 1https://github.com/UKPLab/
naacl18-multimodal-frame-identification
specific role labels.",1 Introduction,[0],[0]
"FrameId is crucial to the success of Semantic Role Labeling as FrameId errors account for most wrong predictions in current systems (Hartmann et al., 2017).",1 Introduction,[0],[0]
"Consequently, improving FrameId is of major interest.
",1 Introduction,[0],[0]
"The main challenge and source of prediction errors of FrameId systems are ambiguous predicates, which can evoke several frames, e.g., the verb sit evokes the frame Change posture in a context like ‘a person is sitting back on a bench’, while it evokes Being located when ‘a company is sitting in a city’.",1 Introduction,[0],[0]
"Understanding the predicate context, and thereby the context of the situation (here, ‘Who / what is sitting where?’), is crucial to identifying the correct frame for ambiguous cases.
",1 Introduction,[0],[0]
"State-of-the-art FrameId systems model the situational context using pretrained distributed word embeddings (see Hermann et al., 2014).",1 Introduction,[0],[0]
"Hence, it is assumed that the context of the situation is explicitly expressed in words.",1 Introduction,[0],[0]
"However, language understanding involves implicit knowledge, which is not mentioned but still seems obvious to humans, e.g., ‘people can sit back on a bench, but companies cannot’, ‘companies are in cities’.",1 Introduction,[0],[0]
"Such implicit common sense knowledge is obvious enough to be rarely expressed in sentences, but is more likely to be present in images.",1 Introduction,[0],[0]
"Figure 1 takes the ambiguous predicate sit to illustrate
1481
how images can provide access to implicit common sense knowledge crucial to FrameId.
",1 Introduction,[0],[0]
"When looking at the semantics of events, FrameId has commonalities with event prediction tasks.",1 Introduction,[0],[0]
These aim at linking events and their participants to script knowledge and at predicting events in narrative chains.,1 Introduction,[0],[0]
"Ahrendt and Demberg (2016) argue that knowing about the participants helps to identify the event, which suggests the need for implicit context knowledge also for FrameId.",1 Introduction,[0],[0]
"This specifically applies to images, which can reflect properties of the participants of a situation in a inherently different way, see Fig. 1.
",1 Introduction,[0],[0]
We analyze whether multimodal representations grounded in images can encode common sense knowledge to improve FrameId.,1 Introduction,[0],[0]
"To that end, we extend SimpleFrameId",1 Introduction,[0],[0]
"(Hartmann et al., 2017), a recent FrameId model based on distributed word embeddings, to the multimodal case and evaluate for English and German.",1 Introduction,[0],[0]
Note that there is a general lack of evaluation of FrameId systems for languages other than English.,1 Introduction,[0],[0]
"This is problematic as they yield different challenges; German, for example, due to long distance dependencies.",1 Introduction,[0],[0]
"Also, word embeddings trained on different languages have different strengths in ambiguous words.",1 Introduction,[0],[0]
"We elaborate on insights from using different datasets by language.
",1 Introduction,[0],[0]
Contributions.,1 Introduction,[0],[0]
"(1) We propose a pipeline and architecture of a FrameId system, extending stateof-the-art methods with the option of using implicit multimodal knowledge.",1 Introduction,[0],[0]
"It is flexible toward modality and language, reaches state-of-the-art accuracy on English FrameId data, clearly outperforming several baselines, and sets a new state of the art on German FrameId data.",1 Introduction,[0],[0]
"(2) We discuss properties of language and meaning with respect to implicit knowledge, as well as the potential of multimodal representations for FrameId.",1 Introduction,[0],[0]
(3) We perform a detailed analysis of FrameId systems.,1 Introduction,[0],[0]
"First, we develop a new strong baseline.",1 Introduction,[0],[0]
"Second, we suggest novel evaluation metrics that are essential for assessing ambiguous and rare frame instances.",1 Introduction,[0],[0]
We show our system’s advantage over the strong baseline in this regard and by this improve upon the main source of errors.,1 Introduction,[0],[0]
"Third, we analyze gold annotated datasets for English and German showing their different strengths.",1 Introduction,[0],[0]
"Finally, we release the implementation of our system, our evaluation splits for SALSA 2.0, and the embeddings for synsets and IMAGINED words.",1 Introduction,[0],[0]
"State-of-the-art FrameId systems rely on pretrained word embeddings as input (Hermann et al., 2014).",2.1 Frame identification,[0],[0]
"This proved to be helpful: those systems consistently outperform the previously leading FrameId system SEMAFOR (Das et al., 2014), which is based on a handcrafted set of features.",2.1 Frame identification,[0],[0]
The open source neural network-based FrameId system SimpleFrameId,2.1 Frame identification,[0],[0]
"(Hartmann et al., 2017) is conceptually simple, yet yields competitive accuracy.",2.1 Frame identification,[0],[0]
Its input representation is a concatenation of the predicate’s pretrained embedding and an embedding of the predicate context.,2.1 Frame identification,[0],[0]
The dimensionwise mean of the pretrained embeddings of all words in the sentence is taken as the context.,2.1 Frame identification,[0],[0]
"In this work, we first aim at improving the representation of the predicate context using multimodal embeddings, and second at assessing the applicability to another language, namely German.
",2.1 Frame identification,[0],[0]
Common sense knowledge for language understanding.,2.1 Frame identification,[0],[0]
"Situational background knowledge can be described in terms of frames (Fillmore, 1985) and scripts (Schank and Abelson, 2013).",2.1 Frame identification,[0],[0]
Ahrendt and Demberg (2016) report that knowing about a script’s participants aids in predicting events linked to script knowledge.,2.1 Frame identification,[0],[0]
"Transferring this insight to FrameId, we assume that a rich context representation helps to identify the sense of ambiguous predicates.",2.1 Frame identification,[0],[0]
"Addressing ambiguous predicates where participants have different properties depending on the context, Feizabadi and Padó (2012) give some examples where the location plays a discriminating role as participant: motion verbs that have both a concrete motion sense and a more abstract sense in the cognitive domain, e.g., struggle, lean, follow.
",2.1 Frame identification,[0],[0]
Frame identification in German.,2.1 Frame identification,[0],[0]
"Shalmaneser (Erk and Pado, 2006) is a toolbox for semantic role assignment on FrameNet schemata of English and German (integrated into the SALSA project for German).",2.1 Frame identification,[0],[0]
"Shalmaneser uses a Naive Bayes classifier to identify frames, together with features for a bag-of-word context with a window over sentences, bigrams, and trigrams of the target word and dependency annotations.",2.1 Frame identification,[0],[0]
They report an F1 of 75.1 % on FrameNet 1.2 and 60 % on SALSA 1.0.,2.1 Frame identification,[0],[0]
These scores are difficult to compare against more recent work as the evaluation uses older versions of datasets and custom splits.,2.1 Frame identification,[0],[0]
"Shalmaneser
requires software dependencies that are not available anymore, hindering application to new data.",2.1 Frame identification,[0],[0]
"To the best of our knowledge, there is no FrameId system evaluated on SALSA 2.0.
",2.1 Frame identification,[0],[0]
"Johannsen et al. (2015) present a simple, but weak translation baseline for cross-lingual FrameId.",2.1 Frame identification,[0],[0]
"A SEMAFOR-based system is trained on English FrameNet and tested on German Wikipedia sentences, translated word-by-word to English.",2.1 Frame identification,[0],[0]
This translation baseline reaches an F1 score of 8.5 % on the German sentences when translated to English.,2.1 Frame identification,[0],[0]
The performance of this weak translation baseline is worse than that of another simple baseline: a ‘most frequent sense baseline’ – computing majority votes for German (and many other languages) – reaches an F1 score of 53.0 % on the German sentences.,2.1 Frame identification,[0],[0]
"This shows that pure translation does not help with FrameId and, furthermore, indicates a large room for improvement for FrameId in languages other than English.",2.1 Frame identification,[0],[0]
"There is a growing interest in Natural Language Processing for enriching traditional approaches with knowledge from the visual domain, as images capture qualitatively different information compared to text.",2.2 Multimodal representation learning,[0],[0]
"Regarding FrameId, to the best of our knowledge, multimodal approaches have not yet been investigated.",2.2 Multimodal representation learning,[0],[0]
"For other tasks, multimodal approaches based on pretrained embeddings are reported to be superior to unimodal approaches.",2.2 Multimodal representation learning,[0],[0]
"Textual embeddings have been enriched with information from the visual domain, e.g., for Metaphor Identification (Shutova et al., 2016), Question Answering (Wu et al., 2017), and Word Pair Similarity (Collell et al., 2017).",2.2 Multimodal representation learning,[0],[0]
"The latter presents a simple, but effective way of extending textual embeddings with so-called multimodal IMAGINED embeddings by a learned mapping from language to vision.",2.2 Multimodal representation learning,[0],[0]
"We apply the IMAGINED method to our problem.
",2.2 Multimodal representation learning,[0],[0]
"In this work, we aim to uncover whether representations that are grounded in images can help to improve the accuracy of FrameId.",2.2 Multimodal representation learning,[0],[0]
Our application case of FrameId is more complex than a comparison on the word-pair level as it considers a whole sentence in order to identify the predicate’s frame.,2.2 Multimodal representation learning,[0],[0]
"However, we see a potential for multimodal IMAGINED embeddings to help: their mapping from text to multimodal representations is learned
from images for nouns.",2.2 Multimodal representation learning,[0],[0]
"Such nouns, in turn, are candidates for role fillers of predicates.",2.2 Multimodal representation learning,[0],[0]
"In order to identify the correct sense of an ambiguous predicate, it could help to enrich the representation of the context situation with multimodal embeddings for the entities that are linked by the predicate.",2.2 Multimodal representation learning,[0],[0]
"Our system builds upon the SimpleFrameId (Hartmann et al., 2017) system for English FrameId based on textual word embeddings.",3 Our Multimodal FrameId Model,[0],[0]
We extend it to multimodal and multilingual use cases; see Fig. 2 for a sketch of the system pipeline.,3 Our Multimodal FrameId Model,[0],[0]
"Same as SimpleFrameId, our system is based on pretrained embeddings to build the input representation out of the predicate context and the predicate itself.
",3 Our Multimodal FrameId Model,[0],[0]
"However, different to SimpleFrameId, our representation of the predicate context is multimodal: beyond textual embeddings we also use IMAGINED and visual embeddings.",3 Our Multimodal FrameId Model,[0],[0]
"More precisely, we concatenate all unimodal representations of the predicate context, which in turn are the unimodal mean embeddings of all words in the sentence.",3 Our Multimodal FrameId Model,[0],[0]
"We use concatenation for fusing the different embeddings as it is the simplest yet successful fusion approach (Bruni et al., 2014; Kiela and Bottou, 2014).",3 Our Multimodal FrameId Model,[0],[0]
"The input representation is processed by a two-layer Multilayer Perceptron (MLP, Rosenblatt, 1958), where we adapt the number of hidden nodes to the increased input size and apply dropout to all hidden layers to prevent overfitting (Srivastava et al., 2014).",3 Our Multimodal FrameId Model,[0],[0]
Each node in the output layer corresponds to one frame-label class.,3 Our Multimodal FrameId Model,[0],[0]
"We use rectified linear units (Nair and Hinton, 2010) as activation function for the hidden layers, and a soft-
max for the output layer yielding a multinomial distribution over frames.",3 Our Multimodal FrameId Model,[0],[0]
We take its argmax as the final prediction at test time.,3 Our Multimodal FrameId Model,[0],[0]
"Optionally, filtering based on the lexicon can be performed on the predicted probabilities for each frame label.",3 Our Multimodal FrameId Model,[0],[0]
"The development set was used to determine the architecture and hyperparameters, see Sec. 6.
Majority baselines.",3 Our Multimodal FrameId Model,[0],[0]
We propose a new strong baseline based on a combination of two existing ones.,3 Our Multimodal FrameId Model,[0],[0]
"These are: first, the most-frequent-sense baseline using the data majority (Data Baseline) to determine the most frequent frame for a predicate; second, the baseline introduced by Hartmann et al. (2017) using a lexicon (Lexicon Baseline) to consider the data counts of the Data Baseline only for those frames available for a predicate.",3 Our Multimodal FrameId Model,[0],[0]
"We propose to combine them into a Data-Lexicon Baseline, which uses the lexicon for unambiguous predicates and for ambiguous ones it uses the data majority.",3 Our Multimodal FrameId Model,[0],[0]
"This way, we trust the lexicon for unambiguous predicates but not for ambiguous ones, there we rather consider the data majority.",3 Our Multimodal FrameId Model,[0],[0]
"Comparing a system to these baselines helps to see whether it just memorizes the data majority or the lexicon, or actually captures more.
",3 Our Multimodal FrameId Model,[0],[0]
All majority baselines strongly outperform the weak translation baseline of Johannsen et al. (2015) when training the system on English data and evaluating it on German data.,3 Our Multimodal FrameId Model,[0],[0]
Textual embeddings for words.,4 Preparation of Input Embeddings,[0],[0]
"We use the 300-dimensional GloVe embeddings (Pennington et al., 2014) for English, and the 100-dimensional embeddings of Reimers et al. (2014) for German.",4 Preparation of Input Embeddings,[0],[0]
"GloVe and Reimers have been trained on the Wikipedia of their targeted language and on additional newswire text to cover more domains, resulting in similarly low out-of-vocabulary scores.
",4 Preparation of Input Embeddings,[0],[0]
Visual embeddings for synsets.,4 Preparation of Input Embeddings,[0],[0]
"We obtain visual embeddings for WordNet synsets (Fellbaum, 1998; , Ed.):",4 Preparation of Input Embeddings,[0],[0]
"we apply the pretrained VGG-m128 Convolutional Neural Network model (Chatfield et al., 2014) to images for synsets from ImageNet (Deng et al., 2009), we extract the 128- dimensional activation of the last layer (before the softmax) and then we L2-normalize it.",4 Preparation of Input Embeddings,[0],[0]
"We use the images of the WN9-IMG dataset (Xie et al., 2017), which links WordNet synsets to a collection of ten ImageNet images.",4 Preparation of Input Embeddings,[0],[0]
"We average the em-
beddings of all images corresponding to a synset, leading to a vocabulary size of 6555 synsets.",4 Preparation of Input Embeddings,[0],[0]
"All synsets in WN9-IMG are part of triples of the form entity-relation-entity, i.e. synset-relation-synset.",4 Preparation of Input Embeddings,[0],[0]
"Such synset entities that are participants of relations with other synset entities are candidates for incorporating the role fillers for predicates and, therefore, may help to find the correct frame for a predicate (see Sec. 5 for details about sensedisambiguation.)
",4 Preparation of Input Embeddings,[0],[0]
Linguistic embeddings for synsets.,4 Preparation of Input Embeddings,[0],[0]
"We obtain 300-dimensional linguistic synset embeddings: we apply the AutoExtend approach (Rothe and Schütze, 2015) to GloVe embeddings and produce synset embeddings for all synsets having at least one synset lemma in the GloVe embeddings.",4 Preparation of Input Embeddings,[0],[0]
This leads to a synset vocabulary size of 79 141.,4 Preparation of Input Embeddings,[0],[0]
"Linguistic synset embeddings are based on textual word embeddings and the synset information known by the knowledge base WordNet, thus they complement the visual synset embeddings.
",4 Preparation of Input Embeddings,[0],[0]
IMAGINED embeddings for words.,4 Preparation of Input Embeddings,[0],[0]
"We use the IMAGINED method (Collell et al., 2017) for learning a mapping function: it maps from the word embedding space to the visual embedding space given those words that occur in both pretrained embedding spaces (7220 for English and 7739 for German).",4 Preparation of Input Embeddings,[0],[0]
"To obtain the English synset lemmas, we extract all lemmas of a synset and keep those that are nouns.",4 Preparation of Input Embeddings,[0],[0]
We automatically translate English nouns to German nouns using the Google Translate API to obtain the corresponding German synset lemmas.,4 Preparation of Input Embeddings,[0],[0]
"The IMAGINED method is promising for cases where one embedding space (here, the textual one) has many instances without correspondence in the other embeddings space (here, the visual one), but the user still aims at obtaining instances of the first in the second space.",4 Preparation of Input Embeddings,[0],[0]
We aim to obtain visual correspondences for the textual embeddings in order to incorporate regularities from images into our system.,4 Preparation of Input Embeddings,[0],[0]
The mapping is a nonlinear transformation using a simple neural network.,4 Preparation of Input Embeddings,[0],[0]
The objective is to minimize the cosine distance between each mapped representation of a word and the corresponding visual representation.,4 Preparation of Input Embeddings,[0],[0]
"Finally, a multimodal representation for any word can be obtained by applying this mapping to the word embedding.",4 Preparation of Input Embeddings,[0],[0]
English FrameId:,5 Data and Preparation of Splits,[0],[0]
Berkeley FrameNet.,5 Data and Preparation of Splits,[0],[0]
"The Berkeley FrameNet (Baker et al., 1998; Ruppenhofer et al., 2016) is an ongoing project for building a large lexical resource for English with expert annotations based on frame semantics (Fillmore, 1976).",5 Data and Preparation of Splits,[0],[0]
"It consists of two parts, a manually created lexicon that maps predicates to the frames they can evoke, and fully annotated texts (fulltext).",5 Data and Preparation of Splits,[0],[0]
"The mapping can be used to facilitate the frame identification for a predicate in a sentence, e.g., a sentence in the fulltext corpus.",5 Data and Preparation of Splits,[0],[0]
"Table 1 contains the lexicon statistics, Table 2 (top left) the dataset statistics.",5 Data and Preparation of Splits,[0],[0]
"In this work, we use FrameNet 1.5 to ensure comparability with the previous state of the art, with the common evaluation split for FrameId systems introduced by Das and Smith (2011) (with the development split of Hermann et al., 2014).",5 Data and Preparation of Splits,[0],[0]
"Due to having a single annotation as consent of experts, it is hard to estimate a performance bound of a single human for the fulltext annotation.
",5 Data and Preparation of Splits,[0],[0]
German FrameId: SALSA.,5 Data and Preparation of Splits,[0],[0]
"The SALSA project (Burchardt et al., 2006; Rehbein et al., 2012) is a completed annotation project, which serves as the German counterpart to FrameNet.",5 Data and Preparation of Splits,[0],[0]
Its annotations are based on FrameNet up to version 1.2.,5 Data and Preparation of Splits,[0],[0]
SALSA adds proto-frames to properly annotate senses that are not covered by the English FrameNet.,5 Data and Preparation of Splits,[0],[0]
"For a more detailed description of differences between FrameNet and SALSA, see Ellsworth et al. (2004); Burchardt et al. (2009).",5 Data and Preparation of Splits,[0],[0]
SALSA also provides a lexicon (see Table 1 for statistics) and fully annotated texts.,5 Data and Preparation of Splits,[0],[0]
"There are two releases of SALSA: 1.0 (Burchardt et al., 2006) used for Shalmaneser (Erk and Pado, 2006) (cf. Sec. 2.1), and the final release 2.0 (Rehbein et al., 2012), which contains more annotations and adds nouns as predicates.",5 Data and Preparation of Splits,[0],[0]
"We use the final release.
",5 Data and Preparation of Splits,[0],[0]
"SALSA has no standard evaluation split; Erk and Pado (2006) used an undocumented random
split.",5 Data and Preparation of Splits,[0],[0]
"Also, it is not possible to follow the splitting method of Das and Smith (2011), as SALSA project distributions do not map to documents.",5 Data and Preparation of Splits,[0],[0]
"We suggest splitting based on sentences, i.e. all annotations of a sentence are in the same set to avoid mixing training and test sets.",5 Data and Preparation of Splits,[0],[0]
"We assign sentences to 100 buckets based on their IDs and create a 70/15/15 split for training, development, and test sets based on the bucket order.",5 Data and Preparation of Splits,[0],[0]
This procedure allows future work to be evaluated on the same data.,5 Data and Preparation of Splits,[0],[0]
"Table 2 (bottom left) shows the dataset statistics.
",5 Data and Preparation of Splits,[0],[0]
Synsets in FrameNet and SALSA.,5 Data and Preparation of Splits,[0],[0]
"To prepare the datasets for working with the synset embeddings, we sense-disambiguate all sentences using the API of BabelNet (Navigli and Ponzetto, 2010), which returns multilingual synsets.",5 Data and Preparation of Splits,[0],[0]
"We thus depend on the state-of-the-art accuracy of BabelNet (Navigli and Ponzetto, 2012) when using synset embeddings on sense-disambiguated sentences.",5 Data and Preparation of Splits,[0],[0]
"However, this dependence does not hold when applying IMAGINED embeddings to sentences, as the mapping from words to IMAGINED embeddings does not need any synsets labeled in the sentences.",5 Data and Preparation of Splits,[0],[0]
After sense-disambiguation some sentences do not contain any synset available in our synset embeddings.,5 Data and Preparation of Splits,[0],[0]
The statistics of those sentences that have at least one synset embedding (visual or linguistic AutoExtend) is given in Table 2 (right).,5 Data and Preparation of Splits,[0],[0]
We contrast our system’s performance for context representations based on unimodal (textual) versus multimodal (textual and visual) embeddings.,6 Experimental Setup,[0],[0]
"Also, we compare English against German data.",6 Experimental Setup,[0],[0]
"We run the prediction ten times to reduce noise in
the evaluation (cf. Reimers and Gurevych, 2017) and report the mean for each metric.
",6 Experimental Setup,[0],[0]
Use of lexicon.,6 Experimental Setup,[0],[0]
"We evaluate our system in two settings: with and without lexicon, as suggested by Hartmann et al. (2017).",6 Experimental Setup,[0],[0]
"In the with-lexicon setting, the lexicon is used to reduce the choice of frames for a predicate to only those listed in the lexicon.",6 Experimental Setup,[0],[0]
"If the predicate is not in the lexicon, it corresponds to the without-lexicon setting, where the choice has to be done amongst all frames.
",6 Experimental Setup,[0],[0]
Evaluation metrics.,6 Experimental Setup,[0],[0]
"FrameId systems are usually compared in terms of accuracy, which we adopt for comparability.",6 Experimental Setup,[0],[0]
"As a multiclass classification problem, FrameId has to cope with a strong variation in the annotation frequency of frame classes.",6 Experimental Setup,[0],[0]
Minority classes are frames that occur only rarely; majority classes occur frequently.,6 Experimental Setup,[0],[0]
"Note that the accuracy is biased toward majority classes, explaining the success of majority baselines on imbalanced datasets such as FrameNet.
",6 Experimental Setup,[0],[0]
"Alternatively, the F1 score is sometimes reported as it takes a complementary perspective.",6 Experimental Setup,[0],[0]
"The F-measure is the harmonic mean of precision and recall, measuring exactness and completeness of a model, respectively.",6 Experimental Setup,[0],[0]
"In previous work, microaveraging is used to compute F1 scores.",6 Experimental Setup,[0],[0]
"Yet, similar to the accuracy, micro-averaging introduces a bias toward majority classes.",6 Experimental Setup,[0],[0]
"We compute F1macro instead, for which precision and recall are computed for each class and averaged afterwards, giving equal weight to all classes.
",6 Experimental Setup,[0],[0]
"Taken together, this yields scores that underestimate (F1-macro) and overestimate (average accuracy) on imbalanced datasets.",6 Experimental Setup,[0],[0]
Previous work just used the overestimate such that a comparison is possible in terms of accuracy in the with-lexicon setting.,6 Experimental Setup,[0],[0]
"We suggest to use F1-macro additionally to analyze rare, but interesting classes.",6 Experimental Setup,[0],[0]
"Thus, a comparison within our work is possible for both aspects, giving a more detailed picture.",6 Experimental Setup,[0],[0]
"Note that previous work reports one score whilst we report the mean score of ten runs.
",6 Experimental Setup,[0],[0]
Hyperparameters.,6 Experimental Setup,[0],[0]
"We identified the best hyperparameters for the English and German data based on the respective development sets.2 The Multilayer Perceptron architecture performed con-
2Differences in hyperparameters to SimpleFrameId: ‘nadam’ as optimizer instead of ‘adagrad’, dropout on hidden layers and early stopping to regularize training.",6 Experimental Setup,[0],[0]
"Different number of hidden units, optimized by grid search.
sistently better than a more complex Gated Recurrent Unit model (Cho et al., 2014).",6 Experimental Setup,[0],[0]
We found that more than two hidden layers did not bring any improvement over two layers; using dropout on the hidden layers helped to increase the accuracy.,6 Experimental Setup,[0],[0]
"Among the various input representations, a concatenation of the representations of context and predicate was the best amongst others, including dependencies, lexicon indicators, and part-ofspeech tags.",6 Experimental Setup,[0],[0]
"Training is done using Nesterovaccelerated Adam (Nadam, Dozat, 2016) with default parameters.",6 Experimental Setup,[0],[0]
A batch size of 128 is used.,6 Experimental Setup,[0],[0]
"Learning stops if the development accuracy has not improved for four epochs, and the learning rate is reduced by factor of two if there has not been any improvement for two epochs.",6 Experimental Setup,[0],[0]
"First, we report our results on English data (see Table 3, top) and then, we compare against German data (see Table 3, bottom).",7 Results,[0],[0]
Baseline.,7.1 English FrameNet data,[0],[0]
"Our new strong Data-Lexicon Baseline reaches a considerable accuracy of 86.32 %, which is hard to beat by trained models.",7.1 English FrameNet data,[0],[0]
"Even the most recent state of the art only beats it by about two points: 88.41 % (Hermann et al., 2014).",7.1 English FrameNet data,[0],[0]
"However, the accuracy of the baseline drops for ambiguous predicates (69.73 %) and the F1-macro score reveals its weakness toward minority classes (drop from 64.54 % to 37.42 %).
",7.1 English FrameNet data,[0],[0]
Unimodal.,7.1 English FrameNet data,[0],[0]
"Our unimodal system trained and evaluated on English data slightly exceeds the accuracy of the previous state of the art (88.66 % on average versus 88.41 % for Hermann et al., 2014); our best run’s accuracy is 89.35 %.",7.1 English FrameNet data,[0],[0]
"Especially on ambiguous predicates, i.e. the difficult and therefore interesting cases, our average accuracy surpasses that of previous work by more than one point (the best run by almost three points).",7.1 English FrameNet data,[0],[0]
"Considering the proposed F1-macro score for an assessment of the performance on minority classes and ambiguous predicates reveals our main improvement: Our system substantially outperforms the strong Data-Lexicon Baseline, demonstrating that our system differs from memorizing majorities and actually improves minority cases.
",7.1 English FrameNet data,[0],[0]
Multimodal.,7.1 English FrameNet data,[0],[0]
"From a range of multimodal context representations as extensions to our system,
the most helpful one is the concatenation of IMAGINED embeddings and visual synset embeddings: it outperforms the unimodal approach slightly in all measurements.",7.1 English FrameNet data,[0],[0]
"We observe that the improvements are more pronounced for difficult cases, such as for rare and ambiguous cases (one point improvement in F1-macro), as well as in the absence of a lexicon (up to two points improvement).
",7.1 English FrameNet data,[0],[0]
Significance tests.,7.1 English FrameNet data,[0],[0]
"We conduct a single sample t-test to judge the difference between previous state-of-the-art accuracy (Hermann et al., 2014) and our unimodal approach.",7.1 English FrameNet data,[0],[0]
The null hypothesis (expected value of our sample of ten accuracy scores equals previous state-of-the-art accuracy) is rejected at a significance level of α = 0.05 (p = 0.0318).,7.1 English FrameNet data,[0],[0]
"In conclusion, even our unimodal approach outperforms prior state of the art in terms of accuracy.
",7.1 English FrameNet data,[0],[0]
"To judge the difference between our unimodal and our multimodal approach, we conduct a t-test for the means of the two independent samples.",7.1 English FrameNet data,[0],[0]
The null hypothesis states identical expected values for our two samples of ten accuracy scores.,7.1 English FrameNet data,[0],[0]
"Regarding the setting with lexicon, the null hypothesis cannot be rejected at a significance level of α = 0.05 (p = 0.2181).",7.1 English FrameNet data,[0],[0]
"However, concerning accuracy scores without using the lexicon, the null hypothesis is rejected at a significance level of α = 0.05 (p < 0.0001).",7.1 English FrameNet data,[0],[0]
"In conclusion, the multimodal approach has a slight overall advan-
tage and, interestingly, has a considerable advantage over the unimodal one when confronted with a more difficult setting of not using the lexicon.",7.1 English FrameNet data,[0],[0]
German results.,7.2 German SALSA versus English data,[0],[0]
"Our system evaluated on German data sets a new state of the art on this corpus with 80.76 % accuracy, outperforming the baselines (77.16 %; no other system evaluated on this dataset).",7.2 German SALSA versus English data,[0],[0]
The difference in F1-macro between the majority baselines and our system is smaller than for the English FrameNet.,7.2 German SALSA versus English data,[0],[0]
"This indicates that the majorities learned from data are more powerful in the German case with SALSA than in the English case, when comparing against our system.",7.2 German SALSA versus English data,[0],[0]
"Multimodal context representations cannot show an improvement for SALSA with this general dataset.
Lexicon.",7.2 German SALSA versus English data,[0],[0]
"We report results achieved without the lexicon to evaluate independently of its quality (Hartmann et al., 2017).",7.2 German SALSA versus English data,[0],[0]
"On English data, our systems outperforms Hartmann et al. (2017) by more than two points in accuracy and we achieve a large improvement over the Data Baseline.",7.2 German SALSA versus English data,[0],[0]
"Comparing the F1-macro with and without lexicon, it can be seen that the additional information stored in the lexicon strongly increases the score by about 20 points for English data.",7.2 German SALSA versus English data,[0],[0]
"For German data, the increase of F1-macro with lexicon versus without is small (one point).",7.2 German SALSA versus English data,[0],[0]
Insights from the baseline.,8.1 English data,[0],[0]
Many indicators point to our approach not just learning the data majority: our trained models have better F1-macro and especially much higher ambiguous F1-macro scores with lexicon.,8.1 English data,[0],[0]
"This clearly suggests that our system is capable of acquiring more expressiveness than the baselines do by counting majorities.
",8.1 English data,[0],[0]
Impact of multimodal representations.,8.1 English data,[0],[0]
Multimodal context representations improve results compared to unimodal ones.,8.1 English data,[0],[0]
It helps to incorporate visual common sense knowledge about the situation’s participants.,8.1 English data,[0],[0]
"Referring back to our example of the ambiguous predicate sit, the multimodal approach is able to transfer the knowledge to the test sentence ‘Al-Anbar in general, and Ramadi in particular, are sat with the Americans in Jordan.’",8.1 English data,[0],[0]
by correctly identifying the frame Being located whilst the unimodal approach fails with predicting Change posture.,8.1 English data,[0],[0]
The increase in performance when adding information from visual synset embeddings is not simply due to higher dimensionality of the embedding space.,8.1 English data,[0],[0]
"To verify, we further investigate extending the unimodal system with random word embeddings.",8.1 English data,[0],[0]
"This leads to a drop in performance compared to using just the unimodal representations or using these in combination with the proposed multimodal embeddings, especially in the setting without lexicon.",8.1 English data,[0],[0]
"Interestingly, replacing visual synset embeddings with linguistic synset embeddings (AutoExtend by Rothe and Schütze (2015), see Sec. 4) in further investigations also showed that visual embeddings yield better performance.",8.1 English data,[0],[0]
This points out the potential for incorporating even more image evidence to extend our approach.,8.1 English data,[0],[0]
Difficulties for German data.,8.2 German versus English data,[0],[0]
"The impact of multimodal context representations is more dif-
ficult to interpret for the German dataset.",8.2 German versus English data,[0],[0]
The fact that they have not helped here may be due to mismatches when translating the English nouns of a synset to German in order to train the IMAGINED embeddings.,8.2 German versus English data,[0],[0]
"Here, we see room for future work to improve on simple translation by sensebased translations.",8.2 German versus English data,[0],[0]
"In SALSA, a smaller portion of sentences has at least one synset embedding, see Table 2.",8.2 German versus English data,[0],[0]
"For further investigations, we reduced the dataset to only sentences actually containing a synset embedding.",8.2 German versus English data,[0],[0]
"Then, minor improvements of the multimodal approach were visible for SALSA.",8.2 German versus English data,[0],[0]
"This points out that a dataset containing more words linking to implicit knowledge in images (visual synset embeddings) can profit more from visual and IMAGINED embeddings.
",8.2 German versus English data,[0],[0]
Impact of lexicon: English versus German.,8.2 German versus English data,[0],[0]
"Even if both lexica approximately define the same number of frames (see Table 1), the number of defined lexical units (distinct predicate-frame combinations) in SALSA is smaller.",8.2 German versus English data,[0],[0]
This leads to a lexicon that is a magnitude smaller than the FrameNet lexicon.,8.2 German versus English data,[0],[0]
"Thus, the initial situation for the German case is more difficult.",8.2 German versus English data,[0],[0]
"The impact of the lexicon for SALSA is smaller than for FrameNet (best visible in the increase of F1-macro with using the lexicon compared to without), which can be explained by the larger percentage of ambiguous predicates (especially evoking proto-frames) and the smaller size of the lexicon.",8.2 German versus English data,[0],[0]
"The evaluation on two different languages highlights the impact of an elaborate, manually created lexicon: it boosts the performance on frame classes that are less present in the training data.",8.2 German versus English data,[0],[0]
"English FrameId benefits from the large high-quality lexicon, whereas German FrameId currently lacks a high-quality lexicon that is large enough to benefit the FrameId task.
",8.2 German versus English data,[0],[0]
Dataset properties: English versus German.,8.2 German versus English data,[0],[0]
"To better understand the influence of the dataset on the prediction errors, we further analyze the errors of our approach (see Table 4) following Palmer
and Sporleder (2010).",8.2 German versus English data,[0],[0]
"A wrong prediction can either be a normal classification error, or it can be the result of an instance that was unseen at training time, which means that the error is due to the training set.",8.2 German versus English data,[0],[0]
The instance can either be completely unseen or unseen with the target label.,8.2 German versus English data,[0],[0]
"We observe that FrameNet has larger issues with unseen data compared to SALSA, especially data that was unseen with one specific label but seen with another label.",8.2 German versus English data,[0],[0]
"This is due to the uneven split of the documents in FrameNet, leading to data from different source documents and domains in the training and test split.",8.2 German versus English data,[0],[0]
SALSA does not suffer from this problem as much since the split was performed differently.,8.2 German versus English data,[0],[0]
It would be worth considering the same splitting method for FrameNet.,8.2 German versus English data,[0],[0]
"As stated previously, FrameId has commonalities with event prediction.",8.3 Future work,[0],[0]
"Since identifying frames is only one way of capturing events, our approach is transferable to other schemes of event prediction and visual knowledge about participants of situations should be beneficial there, too.",8.3 Future work,[0],[0]
"It would be interesting to evaluate the multimodal architecture on other predicate-argument frameworks, e.g., script knowledge or VerbNet style Semantic Role Labeling.",8.3 Future work,[0],[0]
"In particular the exploration our findings on visual contributions to FrameId in the context of further event prediction tasks forms an interesting next step.
",8.3 Future work,[0],[0]
"More precisely, future work should consider using implicit knowledge not only from images of the participants of the situation, but also from the entire scene in order to directly capture relations between the participants.",8.3 Future work,[0],[0]
This could provide access to a more holistic understanding of the scene.,8.3 Future work,[0],[0]
"The following visual tasks with accompanying datasets could serve as a starting point: (a) visual Verb Sense Disambiguation with the VerSe dataset (Gella et al., 2016) and (b) visual SRL with several datasets, e.g., imSitu (Yatskar et al., 2016) (linked to FrameNet), V-COCO (Gupta and Malik, 2015) (verbs linked to COCO), VVN (Ronchi and Perona, 2015) (visual VerbNet) or even SRL grounded in video clips for the cooking-domain (Yang et al., 2016) and visual Situation Recognition (Mallya and Lazebnik, 2017).",8.3 Future work,[0],[0]
"Such datasets could be used for extracting visual embeddings for verbs or even complex situations in order to improve the visual component in the embeddings
for our FrameId system.",8.3 Future work,[0],[0]
"Vice versa: visual tasks could profit from multimodal approaches (Baltrušaitis et al., 2017) in a similar sense as our textual task, FrameId, profits from additional information encoded in further modalities.",8.3 Future work,[0],[0]
"Moreover, visual SRL might profit from our multimodal FrameId system to a similar extend as any FrameNet SRL task profits from correctly identified frames (Hartmann et al., 2017).
",8.3 Future work,[0],[0]
"Regarding the combination of embeddings from different modalities, we suggest to experiment with different fusion strategies complementing the middle fusion (concatenation) and the mapping (IMAGINED method).",8.3 Future work,[0],[0]
This could be a late fusion at decision level operating like an ensemble.,8.3 Future work,[0],[0]
"In this work, we investigated multimodal representations for Frame Identification (FrameId) by incorporating implicit knowledge, which is better reflected in the visual domain.",9 Conclusion,[0],[0]
We presented a flexible FrameId system that is independent of modality and language in its architecture.,9 Conclusion,[0],[0]
With this flexibility it is possible to include textual and visual knowledge and to evaluate on gold data in different languages.,9 Conclusion,[0],[0]
"We created multimodal representations from textual and visual domains and showed that for English FrameNet data, enriching the textual representations with multimodal ones improves the accuracy toward a new state of the art.",9 Conclusion,[0],[0]
"For German SALSA data, we set a new state of the art with textual representations only and discuss why incorporating multimodal information is more difficult.",9 Conclusion,[0],[0]
"For both datasets, our system is particularly strong with respect to ambiguous and rare classes, considerably outperforming our new Data-Lexicon Baseline and thus addressing a key challenge in FrameId.",9 Conclusion,[0],[0]
"This work has been supported by the DFGfunded research training group “Adaptive Preparation of Information form Heterogeneous Sources” (AIPHES, GRK 1994/1).",Acknowledgments,[0],[0]
We also acknowledge the useful comments of the anonymous reviewers.,Acknowledgments,[0],[0]
"An essential step in FrameNet Semantic Role Labeling is the Frame Identification (FrameId) task, which aims at disambiguating a situation around a predicate.",abstractText,[0],[0]
"Whilst current FrameId methods rely on textual representations only, we hypothesize that FrameId can profit from a richer understanding of the situational context.",abstractText,[0],[0]
"Such contextual information can be obtained from common sense knowledge, which is more present in images than in text.",abstractText,[0],[0]
"In this paper, we extend a state-of-the-art FrameId system in order to effectively leverage multimodal representations.",abstractText,[0],[0]
We conduct a comprehensive evaluation on the English FrameNet and its German counterpart SALSA.,abstractText,[0],[0]
"Our analysis shows that for the German data, textual representations are still competitive with multimodal ones.",abstractText,[0],[0]
"However on the English data, our multimodal FrameId approach outperforms its unimodal counterpart, setting a new state of the art.",abstractText,[0],[0]
"Its benefits are particularly apparent in dealing with ambiguous and rare instances, the main source of errors of current systems.",abstractText,[0],[0]
"For research purposes, we release (a) the implementation of our system, (b) our evaluation splits for SALSA 2.0, and (c) the embeddings for synsets and IMAGINED",abstractText,[0],[0]
words.1,abstractText,[0],[0]
Multimodal Frame Identification with Multilingual Evaluation,title,[0],[0]
"Proceedings of the SIGDIAL 2018 Conference, pages 140–150, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics
140",text,[0],[0]
"The interplay between vision and language has created a range of interesting applications, including image captioning (Karpathy and FeiFei, 2015), visual question generation (VQG) (Mostafazadeh et al., 2016), visual question answering (VQA) (Antol et al., 2015), and reference expressions (Hu et al., 2016).",1 Introduction,[0],[0]
"Visual dialog (Das et al., 2017b) extends the VQA problem to multi-turn visual-grounded conversations without specific goals.",1 Introduction,[0],[0]
"In this paper, we study the task-oriented visual dialog setting that requires the agent to learn the multimodal representation and dialog policy for decision making.",1 Introduction,[0],[0]
"We argue that a task-oriented visual intelligent conversational sys-
tem should not only acquire vision and language understanding but also make appropriate decisions efficiently in a situated environment.",1 Introduction,[0],[0]
"Specifically, we designed a 20 images guessing game using the Visual Dialog dataset (Das et al., 2017a).",1 Introduction,[0],[0]
This game is the visual analog of the popular 20 question game.,1 Introduction,[0],[0]
"The agent aims to learn a dialog policy that can guess the correct image through question answering using the minimum number of turns.
",1 Introduction,[0],[0]
"Previous work on visual dialogs (Das et al., 2017a,b; Chattopadhyay et al., 2017) focused mainly on vision-to-language understanding and generation instead of dialog policy learning.",1 Introduction,[0],[0]
They let an agent ask a fixed number of questions to rank the images or let humans make guesses at the end of the conversations.,1 Introduction,[0],[0]
"However, such setting is not realistic in real-world task-oriented applications, because in task-oriented applications, not only completing the task successfully is important but also completing it efficiently.",1 Introduction,[0],[0]
"In addition, the agent should also be informed of the wrong guesses, so that it becomes more aware of the vision context.",1 Introduction,[0],[0]
"However, solving such real-world setting is a challenge.",1 Introduction,[0],[0]
"The system needs to handle the large dynamically updated multimodal stateaction space and also leverage the signals in the feedback loop coming from different sub-tasks.
",1 Introduction,[0],[0]
We propose a multimodal hierarchical reinforcement learning framework that allows learning visual dialog state tracking and dialog policy jointly to complete visual dialog tasks efficiently.,1 Introduction,[0],[0]
"The framework we propose takes inspiration from feudal reinforcement learning (FRL) (Dayan and Hinton, 1993), where levels of hierarchy within an agent communicate via explicit goals in a topdown fashion.",1 Introduction,[0],[0]
"In our case, it decomposes the decision into two steps: a first step where a master policy selects between verbal task (information query) and vision task (image retrieval), and a second step where a primitive action (question or im-
age) is chosen from the selected task.",1 Introduction,[0],[0]
"Hierarchical RL that relies on space abstraction, such as FRL, is useful to address the challenge of large discrete action space and has been shown to be effective in dialog systems, especially for large domain dialog management(Casanueva et al., 2018).",1 Introduction,[0],[0]
"Besides, we propose a new technique called state adaptation in order to make the multimodal dialog state more aware of the constantly changing visual context.",1 Introduction,[0],[0]
We demonstrate the efficacy of this technique through ablation analysis.,1 Introduction,[0],[0]
Visual dialog requires the agent to hold a multiturn conversation about visual content.,2.1 Visual Dialog,[0],[0]
"Several visual dialog tasks have been developed, including image grounded conversation generation (Mostafazadeh et al., 2017).",2.1 Visual Dialog,[0],[0]
Guess,2.1 Visual Dialog,[0],[0]
What?!,2.1 Visual Dialog,[0],[0]
"(De Vries et al., 2017) involves locating visual objects using dialogs.",2.1 Visual Dialog,[0],[0]
"VisDial (Das et al., 2017a) situates an answer-bot (A-Bot) to answer questions from a question-bot (Q-Bot) about an image.",2.1 Visual Dialog,[0],[0]
Das et al. (2017b) applied reinforcement learning (RL) to the VisDial task to learn the policies for the Q/A-Bots to collaboratively rank the correct image among a set of candidates.,2.1 Visual Dialog,[0],[0]
"However, their Q-Bot can only ask questions and cannot make guesses.",2.1 Visual Dialog,[0],[0]
Chattopadhyay et al. (2017) further evaluated the pre-trained A-bot in a similar setting to answer human generated questions.,2.1 Visual Dialog,[0],[0]
"Since humans are tasked to ask questions, the policy learning of QBot is not investigated.",2.1 Visual Dialog,[0],[0]
"Finally, (Manuvinakurike et al., 2017) proposed a incremental dialogue policy learning method for image guessing.",2.1 Visual Dialog,[0],[0]
"However, their dialog state only used language information and did not include visual information.",2.1 Visual Dialog,[0],[0]
We build upon prior works and propose a framework that learns an optimal dialog policy for the Q-Bot to perform both question selection and image guessing through exploiting multimodal information.,2.1 Visual Dialog,[0],[0]
"RL is a popular approach to learn an optimal dialog policy for task-oriented dialog systems (Singh et al., 2002; Williams and Young, 2007; Georgila and Traum, 2011; Lee and Eskenazi, 2012; Yu et al., 2017).",2.2 Reinforcement Learning,[0],[0]
The deep Q-Network (DQN) introduced by Mnih et al. (2015) achieved human-level performance in Atari games based on deep neural networks.,2.2 Reinforcement Learning,[0],[0]
"Deep RL was then used to jointly
learn the dialog state tracking and policy optimization in an end-to-end manner (Zhao and Eskenazi, 2016).",2.2 Reinforcement Learning,[0],[0]
"In our framework, we use a DQN to learn the higher level policy for question selection or image guessing.",2.2 Reinforcement Learning,[0],[0]
Van Hasselt et al. (2016) proposed a double DQN to overcome the overestimation problem in the Q-Learning and Schaul et al. (2015) suggested prioritized experience replay to improve the data sampling efficiency for training DQN.,2.2 Reinforcement Learning,[0],[0]
We apply both techniques in our implementation.,2.2 Reinforcement Learning,[0],[0]
"One limitation of DQNs is that they cannot handle unbounded action space, which is often the case for natural language interaction.",2.2 Reinforcement Learning,[0],[0]
He et al. (2015) proposed Deep Reinforcement Relevance Network (DRRN) that can handle inherently large discrete natural language action space.,2.2 Reinforcement Learning,[0],[0]
"Specifically, the DRRN takes both the state and natural language actions as inputs and computes a Q-value for each state action pair.",2.2 Reinforcement Learning,[0],[0]
"Thus, we use a DRRN as our question selection policy to approximate the value function for any question candidate.
",2.2 Reinforcement Learning,[0],[0]
"Our work is also related to hierarchical reinforcement learning (HRL) which often decomposes the problem into several sub-problems and achieves better learning convergence rate and generalization compared to flat RL (Sutton et al., 1999; Dietterich, 2000).",2.2 Reinforcement Learning,[0],[0]
"HRL has been applied to dialog management (Lemon et al., 2006; Cuayáhuitl et al., 2010; Budzianowski et al., 2017) which decomposes the dialog policy with respect to system goals or domains.",2.2 Reinforcement Learning,[0],[0]
"When the system enters a sub-task, the selected dialog policy will be used and continue to operate until the subproblem is solved, however the terminate condition for a subproblem has to be predefined.",2.2 Reinforcement Learning,[0],[0]
"Different from prior work, our proposed architecture uses hierarchical dialog policy to combine two RL architectures within a control flow, i.e., DQN and DRRN, in order to jointly learn multimodal dialog state representation and dialog policy.",2.2 Reinforcement Learning,[0],[0]
"Note that our HRL framework resembles the FRL hierarchy (Dayan and Hinton, 1993) that exploits space abstraction, state sharing and sequential execution.",2.2 Reinforcement Learning,[0],[0]
Figure 2 shows an overview of the multimodal hierarchical reinforcement learning framework and the simulated environment.,3 Proposed Framework,[0],[0]
There are four main modules in the framework.,3 Proposed Framework,[0],[0]
"The visual dialog semantic embedding module learns a multimodal dialog state representation to support the visual
dialog state tracking module with attention signals.",3 Proposed Framework,[0],[0]
Then the hierarchical policy learning module takes the visual dialog state as the input to optimize the high-level control policy between question selection and image retrieval.,3 Proposed Framework,[0],[0]
This module learns the multimodal representation for the downstream visual dialog state tracking.,3.1 Visual Dialog Semantic Embedding,[0],[0]
Figure 3 shows the network architecture for pretraining the visual dialog semantic embedding.,3.1 Visual Dialog Semantic Embedding,[0],[0]
"A VGG-19 CNN (Simonyan and Zisserman, 2014) and a multilayer perceptron (MLP) with L2 normalization are used to encode visual information (images) as a vector I ∈",3.1 Visual Dialog Semantic Embedding,[0],[0]
Rk.,3.1 Visual Dialog Semantic Embedding,[0],[0]
"We use a dialogconditioned attentive encoder (Lu et al., 2017) to encode textual information as a vector T ∈ Rk where k is the joint embedding size.",3.1 Visual Dialog Semantic Embedding,[0],[0]
"The image caption(c) is encoded with a LSTM to get a vector mc and each QA pair (H0, ...,Ht) is encoded separately with another LSTM as Mht ∈ Rd×t where t is the turn index and d is the LSTM embedding size.",3.1 Visual Dialog Semantic Embedding,[0],[0]
"Conditioned on the image caption embedding, the model attends to the dialog history:
zht = w T",3.1 Visual Dialog Semantic Embedding,[0],[0]
a tanh(WhM h t +,3.1 Visual Dialog Semantic Embedding,[0],[0]
"(Wcm c t)1 T ) (1) αht = softmax(z h t ) (2)
where 1 is a vector with all elements set to 1, Wh,Wc ∈ Rt×d and wa ∈",3.1 Visual Dialog Semantic Embedding,[0],[0]
Rk are parameters to be learned.,3.1 Visual Dialog Semantic Embedding,[0],[0]
α ∈,3.1 Visual Dialog Semantic Embedding,[0],[0]
Rk is the attention weight over history.,3.1 Visual Dialog Semantic Embedding,[0],[0]
The attended history feature m̂ht is the weighted sum of each column of Mht with α h t .,3.1 Visual Dialog Semantic Embedding,[0],[0]
Then m̂ht is concatenated withm c and encoded via MLP and l2 norm to get the final textual embedding (T ).,3.1 Visual Dialog Semantic Embedding,[0],[0]
"We train the network with pairwise ranking loss (Kiros et al., 2014) on cosine similarities between the textual and visual embedding.",3.1 Visual Dialog Semantic Embedding,[0],[0]
"The pretraining step allows the module to have better generalization and improve convergence performance in the RL training.
",3.1 Visual Dialog Semantic Embedding,[0],[0]
"Given the QA pairs from the simulated environ-
ment, the output of this module can also be used for the image retrieval sub-task.",3.1 Visual Dialog Semantic Embedding,[0],[0]
"To verify the quality of this module, we perform a sanity check on an image retrieval task, similar to (Das et al., 2017b).",3.1 Visual Dialog Semantic Embedding,[0],[0]
We used the output of the module to rank the 20 images in the game setting.,3.1 Visual Dialog Semantic Embedding,[0],[0]
"Among 1000 games, we achieved 96.8% accuracy for recall@1 (the target image ranked the highest), which means that this embedding module can provide reliable reward signal in an image retrieval task for the RL training if given the relevant dialog history.",3.1 Visual Dialog Semantic Embedding,[0],[0]
This module utilizes the output from the visual dialog semantic embedding to formulate the final dialog state representation.,3.2 Visual Dialog State Tracking,[0],[0]
"We track three types of state information, the dialog meta information (META), the vision belief (V B) and the vision context (V C).",3.2 Visual Dialog State Tracking,[0],[0]
"The dialog meta information includes the number of questions asked, the number of images guessed and the last action.",3.2 Visual Dialog State Tracking,[0],[0]
"The vision belief state is the output of the visual dialog semantic embedding module, which captures the internal multimodal information of the agent.",3.2 Visual Dialog State Tracking,[0],[0]
We initialize the VB with only the encoding of the image caption and update it with each new incoming QA pair.,3.2 Visual Dialog State Tracking,[0],[0]
The vision context state represents the visual information of the environment.,3.2 Visual Dialog State Tracking,[0],[0]
"In order to make the agent more aware of the dynamic visual context and which images to attend more, we introduce a new technique called state adaptation as it updates the vision context state with the attention scores.",3.2 Visual Dialog State Tracking,[0],[0]
"The V C is initialized as the average of image vectors and updated as follows:
αr,t,i = sigmoid(VBr,t · Ir,i) (3) VCr,t = ∑20
i=1",3.2 Visual Dialog State Tracking,[0],[0]
"αr,t,iIr,i∑20 i=1",3.2 Visual Dialog State Tracking,[0],[0]
"αi
(4)
",3.2 Visual Dialog State Tracking,[0],[0]
"where r, t and i refer to episode, dialog turn and image index.",3.2 Visual Dialog State Tracking,[0],[0]
The V C is then adjusted based on the attention scores (see equation 4).,3.2 Visual Dialog State Tracking,[0],[0]
The attention scores calculated by dot product in the equation 3 represent the affinity between the current vision belief state and each image vector.,3.2 Visual Dialog State Tracking,[0],[0]
"In the case of wrong guesses (informed by the simulator), we set the attention score for that wrong image to zero.",3.2 Visual Dialog State Tracking,[0],[0]
This method is inspired by Tian et al. (2017) who explicitly weights context vectors by context-query relevance for encoding dialog context.,3.2 Visual Dialog State Tracking,[0],[0]
"The question selection sub-task also takes the
vision context state as input and the vision belief state is used in the image retrieval sub-task.",3.2 Visual Dialog State Tracking,[0],[0]
"The goal is to learn a dialog policy that makes decisions based on the current visual dialog state, i.e, asking a question about the image or making a guess about the image that the user is thinking of.",3.3 Hierarchical Policy Learning,[0],[0]
"As the agent is situated in a dynamically changing vision context to update its internal decisionmaking model (approximated by the belief state) with new dialog exchange, we treat such environment as a Partially Observable Markov Decision Process (POMDP) and solve it using deep reinforcement learning.",3.3 Hierarchical Policy Learning,[0],[0]
We now describe the key components: Dialog State comes from the visual dialog state tracking module as mentioned in Section 3.2 Policy Learning:,3.3 Hierarchical Policy Learning,[0],[0]
"Given the above dialog state, we introduce a hierarchical dialog policy that contains a high-level control policy and a low-level question selection policy.",3.3 Hierarchical Policy Learning,[0],[0]
"We learn the control policy with a Double DQN that decides between “question” or “guess” at a game step.
",3.3 Hierarchical Policy Learning,[0],[0]
"If the high-level action is a “question”, then the control is passed over to the low-level policy, which needs to select a question.",3.3 Hierarchical Policy Learning,[0],[0]
"One challenge is that the list of candidate questions are different for every game, and the number of candidate questions for different images is also different as well.",3.3 Hierarchical Policy Learning,[0],[0]
This prohibits us using a standard DQN with fixed number of actions.,3.3 Hierarchical Policy Learning,[0],[0]
He et al. (2015) showed that modeling state embedding and action embedding separately in DRRN has superior performance than per-action DQN as well as other DQN variants for dealing with natural language action spaces.,3.3 Hierarchical Policy Learning,[0],[0]
"Therefore, we use the DRRN to solve this problem, which computes a matching score between the shared current vision context state and the embedding of each question candidate.",3.3 Hierarchical Policy Learning,[0],[0]
We use a softmax selection strategy as the exploration policy during the learning stage.,3.3 Hierarchical Policy Learning,[0],[0]
"The hierarchical policy learning algorithm is described in the Appendix Algorithm 1.
",3.3 Hierarchical Policy Learning,[0],[0]
"If the high-level action is “guess”, then an image is retrieved using cosine distance between each image vector and the vision belief vector.",3.3 Hierarchical Policy Learning,[0],[0]
"It is worth mentioning that although the action space of the image retrieval sub-task can be incorporated into a flat DRRN combined with text-based inputs,the training is unstable and does not converge
within this flat RL framework.",3.3 Hierarchical Policy Learning,[0],[0]
We suspect this is due to the sample efficiency problem with large multimodal action space for which the question action or guess action typically results in different reward signals.,3.3 Hierarchical Policy Learning,[0],[0]
"Therefore, we did not compare our proposed method against a flat RL model.",3.3 Hierarchical Policy Learning,[0],[0]
Rewards:,3.3 Hierarchical Policy Learning,[0],[0]
"The reward function is decomposed as R = RG + RQ + RI where RG means the final game reward(win/loss= ±10), RI refers to wrong guess penalty (-3).",3.3 Hierarchical Policy Learning,[0],[0]
"We define RQ as the pseudo reward for the sub-task of question selection as
RQ =",3.3 Hierarchical Policy Learning,[0],[0]
At −At−1 (5),3.3 Hierarchical Policy Learning,[0],[0]
"At = sigmoid(VBr,t · Itarget) (6)
where t refers to the dialog turn and affinity scores (At andAt−1) are the outputs of the sigmoid function that scales the similarity score (0-1) of the vision belief state and the target image vector.",3.3 Hierarchical Policy Learning,[0],[0]
The intuition is that different questions provide various information gains for the agent.,3.3 Hierarchical Policy Learning,[0],[0]
"The integration of RQ is a reward shaping (Ng et al., 1999) technique that aims to provide immediate rewards to make the RL training more efficient.",3.3 Hierarchical Policy Learning,[0],[0]
"At each turn, if the verbal task (question selection) is chosen, the RQ would serve as immediate reward for training the DQN and DRRN",3.3 Hierarchical Policy Learning,[0],[0]
"while if the vision task (image retrieval) is chosen, only the RI is available for training DQN.",3.3 Hierarchical Policy Learning,[0],[0]
"At the end of a game, the reward function varies based on the primitive action and the final game result.",3.3 Hierarchical Policy Learning,[0],[0]
The question selection module selects the best question in order to acquire relevant information to update the image belief state.,3.4 Question Selection,[0],[0]
"As discussed in Section 3.3, we used a discriminative approach to select the next question for the agent by learning the policy in a DRRN.",3.4 Question Selection,[0],[0]
It leverages the existing question candidate pool that is constructed differently with respect to different experiment settings in Section 4.4.,3.4 Question Selection,[0],[0]
"Ideally we would like to generate realistic questions online towards a specific goal (Zhang et al., 2017) and we leave this generative approach for future study.",3.4 Question Selection,[0],[0]
We first describe the simulation of the environment.,4 Experiments,[0],[0]
"Then, we talk about different dialog policy models and implementation details.",4 Experiments,[0],[0]
"Finally, we discuss three different experimental settings to evaluate the proposed framework.",4 Experiments,[0],[0]
We constructed a simulator for 20 images guessing game using the VisDial dataset.,4.1 Simulator Construction,[0],[0]
Each image corresponds to a dialog consisting of ten rounds of question answering generated by humans.,4.1 Simulator Construction,[0],[0]
"To make the task setting meaningful and the training time manageable, we pre",4.1 Simulator Construction,[0],[0]
-process and select 1000 sets of games consisting of 20 similar images.,4.1 Simulator Construction,[0],[0]
The simulator provides the reward signals and answers related to the target image.,4.1 Simulator Construction,[0],[0]
It also tracks the internal game state.,4.1 Simulator Construction,[0],[0]
"A game is terminated when one of the three conditions is fulfilled: 1) the agent guesses the correct answer, 2) the max number of guesses is reached (three guesses) or 3) the max number of dialog turns is reached.",4.1 Simulator Construction,[0],[0]
The agent wins the game when it guesses the correct image.,4.1 Simulator Construction,[0],[0]
"If the agent wins the game, it gets a reward of 10, and if the agent loses the game, it gets a reward of −10.",4.1 Simulator Construction,[0],[0]
The agent also receives a −3 penalty for each wrong guess.,4.1 Simulator Construction,[0],[0]
"To evaluate the contribution of each technique in the multimodal hierarchical framework: the hierarchical policy, the state adaptation, and the reward shaping, we evaluate five different policy models and perform ablation analysis.",4.2 Policy Models,[0],[0]
We describe each model as follows: - Random Policy (Rnd): The agent randomly selects a question or makes a guess at any step.,4.2 Policy Models,[0],[0]
"- Random Question+DQN (Rnd+DQN): The agent randomly selects a question but a DQN is used to optimize the hierarchical decision of making a guess or asking a question. - DRRN+DQN (HRL): Similar to Rnd+ DQN, except that a DRRN is used to optimize the question selection process - DRRN+DQN+State Apdation (HRL+SA): Similar to HRL, except incorporating the state adaptation, which is similar to the attention re-weighting concept in the vision context state.",4.2 Policy Models,[0],[0]
- DRRN+DQN+State Apdation+Reward,4.2 Policy Models,[0],[0]
"Shaping (HRL+SAR): Similar to HRL+SA, except that reward shaping is applied.",4.2 Policy Models,[0],[0]
The details about data pre-processing and training hyper-parameters are described in the Appendix.,4.3 Implementation Details,[0],[0]
"During the training, the DQN uses the -greedy policy and the DRRN uses the softmax policy for exploration, where is linearly decreased from 1
to 0.1.",4.3 Implementation Details,[0],[0]
"The resulting framework was trained up to 20,000 iterations for Experiment 1 and 95,000 iterations for Experiment 2 and 3, and evaluated at every 1000 iterations with greedy policy.",4.3 Implementation Details,[0],[0]
At each evaluation we record the performance of different models with a greedy policy for 100 independent games.,4.3 Implementation Details,[0],[0]
The evaluation metrics are the win rate and the average number of dialog turns.,4.3 Implementation Details,[0],[0]
We conduct three sets of experiments to explore the effectiveness of the proposed multimodal hierarchical reinforcement learning framework in a real-world scenario step by step.,4.4 Experimental Setting,[0],[0]
The first experiment constrains the agent to select among the 10 human generated question-answer pairs.,4.4 Experimental Setting,[0],[0]
This setting enables us to assess the effectiveness of the framework in a less error-prone setting.,4.4 Experimental Setting,[0],[0]
The second experiment does not require a human to generate the answer to emulate a more realistic environment.,4.4 Experimental Setting,[0],[0]
"Specifically, we enlarge the number of questions by including 200 human generated questions for the 20 images, and use a pre-trained visual question answer model to generate answers with respect to the target image.",4.4 Experimental Setting,[0],[0]
"In the last experiment, we further automate the process by generating questions given the 20 images using a pretrained visual question generation model.",4.4 Experimental Setting,[0],[0]
So the agent does not require any human input with respect to any image for training.,4.4 Experimental Setting,[0],[0]
We evaluate the models described in Section 4.2 under the settings described in Section 4.4 and report results as following.,5 Results,[0],[0]
The agent selects the next question among the 10 question-answer pairs human generated and want to identify the targeted image accurately and efficiently through natural language conversation.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
We terminate the dialog after ten turns.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
Each model’s performance is shown in Table 1. HRL+SAR achieves the best win rate with statistical significance.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
The HRL+SAR policy model performs much better than methods without hierarchical control structure and state adaptation.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
The learning curves in Figure 4 and 5 reveal that the HRL+SAR converges faster.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"We further perform bootstrap tests by resampling the game results
from each experiment with replacement 1,000 times.",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
Then we calculate the probability of significance level for the difference of average win rates or average turn length to check whether the relative performance improvement from the last baseline is statistically significant.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
The result shows that the question selection (DRRN) and state adaptation bring the most significant performance improvements (p < 0.01) while reward shaping has less impact (p < 0.05).,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
We also observe that the average number of turns with hierarchical policy learning (HRL) is slightly longer than that of Rnd+DQN but with less statistically significant difference.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"This is probably because this setting provides the 10 predefined question-answer pairs with a smaller action space, the DQN model tends to encourage the agent to make guesses quicker, while policy models with hierarchical structures tends to optimize the overall task completion rate.
",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
We find that RL methods (DQN & DRRN) significantly improve the win rate as they learn to select the optimal list of questions to ask.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"We also observe that our proposed state adaptation method
for vision context state helps achieve the largest performance improvement.",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"The hierarchical control architecture and the state abstraction sharing (Dietterich, 2000) also improve both learning speed and agent performance.",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"This aligns with the observation in Budzianowski et al. (2017).
",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"Moreover, on average, we observe that after seven turns, the agent was able to select the target image with a sufficiently high success rate.",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
We further explore if the proposed hierarchical framework enables efficient decision-making when compared to the agent that keeps asking questions and only makes the guess at the end of the dialog.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
We refer to such models as the oracle baselines.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"For example, the Oracle@7 makes the guess at the 7th turn based on the previous dialog history with the correct order of questionanswer pairs in the dataset.",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"The oracle baselines are strong, since they represent the best performance the model can get given the optimal question order provided by human.
",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
Table 2 shows the performance of the oracle baselines with various fixed turns.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
We performed significance tests between each oracle baseline and the hierarchical framework.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"Since our hierarchical framework requires on average 7.22 turns to complete, so we compared it with Oracle@7 and Oracle@8.",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"We found that the proposed method outperforms Oracle@7 with p − value < 0.01, and similar to Oracle@8 (significant difference
(p − value > 0.1).",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"The reason that the hierarchical framework can outperform Oracle@7 is that it learns to make a guess whenever the agent is confident enough, therefore achieving better win rate.",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"Oracle@8 in general receives more information as the dialogs are longer, therefore has an advantage over the hierarchical method.",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"However, it still performs similar to the proposed method, which demonstrates that by learning the hierarchical decision, it enables the agent to achieve the goal more efficiently.",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
One thing we need to point out is that the proposed method also received extra information about whether the guess is correct or not from the environment.,5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"Oracle baselines do not have such information, as it can only make a guess at the end of the dialog.",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"Oracle@9 and @10 are better than the hierarchical framework statistically, because they acquire much more information by having longer turns.",5.1 Experiment 1: Human Generated Question-Answer Pairs,[0],[0]
"To make the experimental setting more realistic, we select 200 questions generated by a human with respect to 20 images provided and create a user simulator that generates the answers related to the target image.",5.2 Experiment 2: Questions Generated by Human and Answers Generated Automatically,[0],[0]
"Here, as the questions space is larger, we terminate the dialog after 20 turns.",5.2 Experiment 2: Questions Generated by Human and Answers Generated Automatically,[0],[0]
"We follow the supervised training scheme discussed in (Das et al., 2017b) to train the visual question generation module offline.
",5.2 Experiment 2: Questions Generated by Human and Answers Generated Automatically,[0],[0]
Results in Table 3 indicate that HRL+SAR significantly outperforms Rnd and Rnd+DQN in both win rate and average number of dialog turns.,5.2 Experiment 2: Questions Generated by Human and Answers Generated Automatically,[0],[0]
"The setting in Experiment 2 is more challenging than that of Experiment 1, because the visual ques-
tion module introduces noise that can influence the policy learning.",5.2 Experiment 2: Questions Generated by Human and Answers Generated Automatically,[0],[0]
"However, the noise also simulates the real-world scenario that a user might have an implicit goal that may change within the task.",5.2 Experiment 2: Questions Generated by Human and Answers Generated Automatically,[0],[0]
A user can also accidentally make errors in answering the question.,5.2 Experiment 2: Questions Generated by Human and Answers Generated Automatically,[0],[0]
The proposed hierarchical framework (HRL+SAR) with state adaptation and reward shaping achieves the best win rate and the least number of dialog turns in this noisy experiment setting.,5.2 Experiment 2: Questions Generated by Human and Answers Generated Automatically,[0],[0]
"As compared to Experiment 1, the policy models with hierarchical structures can both optimize the overall task completion rate and the dialog turns.",5.2 Experiment 2: Questions Generated by Human and Answers Generated Automatically,[0],[0]
"We did not report oracle baselines results, since the oracle order of all the questions (ideally generated by humans) was not available.",5.2 Experiment 2: Questions Generated by Human and Answers Generated Automatically,[0],[0]
"In this setting, both questions and answers are generated automatically through pre-trained visual question and answer generation models (Das et al., 2017b).",5.3 Experiment 3: Question-Answer Pairs Generated Automatically,[0],[0]
Such setting enables the agent to play the guessing game given any image as no human input of the image is needed.,5.3 Experiment 3: Question-Answer Pairs Generated Automatically,[0],[0]
Notice that the answers should be generated with respect to a target image for our task setting.,5.3 Experiment 3: Question-Answer Pairs Generated Automatically,[0],[0]
"In this setting, we also set the maximum number of dialog turns to be 20.
",5.3 Experiment 3: Question-Answer Pairs Generated Automatically,[0],[0]
The results in Table 4 show that the performance of the three policies significantly dropped compared to Experiment 2.,5.3 Experiment 3: Question-Answer Pairs Generated Automatically,[0],[0]
"Such observation is expected, as the noise coming from both the visual question and answer generation module increases the task difficulty.",5.3 Experiment 3: Question-Answer Pairs Generated Automatically,[0],[0]
"However, the proposed HRL+SAR is still more resilient to the noise and achieves a higher win rate and less average number of turns compared to other baselines.",5.3 Experiment 3: Question-Answer Pairs Generated Automatically,[0],[0]
"Figure 5 from the Appendix shows that in Experiment 2
the agent tends select relevant questions faster to ask although the answers can be misleading.",5.3 Experiment 3: Question-Answer Pairs Generated Automatically,[0],[0]
"On the other hand, in Experiment 3, the agent reacts to the generated question and answers slower to complete the task.",5.3 Experiment 3: Question-Answer Pairs Generated Automatically,[0],[0]
The model performance decreases when we increase the task difficulty in order to emulate the real-world scenarios.,5.3 Experiment 3: Question-Answer Pairs Generated Automatically,[0],[0]
"It hints that there is a possible limitation of using the VisDial dataset, because the dialog is constructed by users who casually talk about MS COCO images (Chen et al., 2015) instead of exchanging with an explicit contextual goal in the dialog.",5.3 Experiment 3: Question-Answer Pairs Generated Automatically,[0],[0]
We develop a framework for task-oriented visual dialog systems and demonstrate the efficacy of integrating multimodal state representation with hierarchical decision learning in an image guessing game.,6 Discussion and Future Work,[0],[0]
We also introduce a new technique called state adaptation to further improve the task performance through integrating context awareness.,6 Discussion and Future Work,[0],[0]
"We also test the proposed framework in various noisy settings to simulate real-world scenarios and achieve robust results.
",6 Discussion and Future Work,[0],[0]
The proposed framework is practical and extensible for real-world applications.,6 Discussion and Future Work,[0],[0]
"For example, the designed system can act as a fashion shopping assistant to help customers pick clothes through strategically inquiring their preferences while leveraging vision intelligence.",6 Discussion and Future Work,[0],[0]
"In another application, such as criminology practice, the agent can communicate with witnesses to identify suspects from a large face database.
",6 Discussion and Future Work,[0],[0]
"Although games provide a rich domain for multimodal learning research, admittedly it is challenging to evaluate a multimodal dialog system due to the data scarcity problem.",6 Discussion and Future Work,[0],[0]
"In future work, we would like to extend and apply the proposed framework for human studies in a situated realworld application, such as a shopping scenario.",6 Discussion and Future Work,[0],[0]
"We also plan to incorporate domain knowledge and database interactions into the system framework design, which will make the dialog system more flexible and effective.",6 Discussion and Future Work,[0],[0]
Another possible extension of the framework is to update the off-line question and answer generation modules with an online generative version and retrain the module with reinforcement learning.,6 Discussion and Future Work,[0],[0]
"After data pre-processing, we had a vocabulary size of 8,957 and image vector dimension of
4,096.",A Data Pre-Processing and Training Details,[0],[0]
"To pre-train the visual dialog semantic embedding, we used the following parameters: the size of word embedding is 300; the size of LSTMs is 512; 0.2 dropout rate and the final embedding size 1024 with MLP and l2 norm.",A Data Pre-Processing and Training Details,[0],[0]
We fixed the visual dialog semantic embedding during the RL training.,A Data Pre-Processing and Training Details,[0],[0]
"The high-level policy learning module - Double DQN was trained with the following hyperparameters: three MLP layers of sizes 1000, 500 and 50 with tanh activation respectively.",A Data Pre-Processing and Training Details,[0],[0]
"For hyper-parameters of DQN, the behavior network was updated every 5 steps and the interval for updating the target network is",A Data Pre-Processing and Training Details,[0],[0]
500. -greedy,A Data Pre-Processing and Training Details,[0],[0]
"exploration was used for training, where is linearly decreased from 1 to 0.1.",A Data Pre-Processing and Training Details,[0],[0]
The question selection module - DRRN encodes the context vector and question vector separately with two MLP layers of sizes 256 and 128 and dot product was used as the interaction function.,A Data Pre-Processing and Training Details,[0],[0]
"The experience replay buffer sizes are 25,000 for DQN and 50,000 for DRRN.",A Data Pre-Processing and Training Details,[0],[0]
Both RL networks were trained through RMSProp with batch size 64.,A Data Pre-Processing and Training Details,[0],[0]
Bootstrapping and prioritized replay were also used to facilitate RL training.,A Data Pre-Processing and Training Details,[0],[0]
The reward discount factor was set to be 0.99.,A Data Pre-Processing and Training Details,[0],[0]
See Figure 5.,B Sample Dialog,[0],[0]
"See Algorithm 1.
",C Hierarchical Policy Learning Algorithm,[0],[0]
"Algorithm 1 Hierarchical Policy Learning 1: Initialize Double DQN(online network parameters θ and target network parameters θ−) and
DRRN(network parameters θ+) with small random weights and corresponding replay memory EDQN and EDRRN to capacity N. 2: Initialize game simulator and load dictionary.",C Hierarchical Policy Learning Algorithm,[0],[0]
"3: for episode r = 1, ..., M do 4: Restart game simulator.",C Hierarchical Policy Learning Algorithm,[0],[0]
"5: Receive image caption and candidate images from the simulator, and convert them to represen-
tation via pre-trained visual dialog semantic embedding layer, denoted as initial state Sr,0 6: for t = 1, ..., T do 7: sample high-level action from DQN, At ∼ πDQN (Sr,t) 8: if Ar,t = Q(asking a question) then 9: Compute Q(V Ct, qi) for the list of questions Qr,t using DRRN forward activation and
select the question qr,t with the max Q-value, and keep track the next available question pool Qr,t+1 10: if Ar,t = G (guessing an image) then 11:",C Hierarchical Policy Learning Algorithm,[0],[0]
"Select the image gr,t with the smallest cosine distance between an image vector Ii and
current image belief state VBr,t 12: Execute action qr,t or gr,t in the simulator and get the next visual dialog state representation
Sr,t+1 and reward signal Rr,t 13:",C Hierarchical Policy Learning Algorithm,[0],[0]
"Store the transition (Sr,t, Ar,t, Sr,t+1, Rr,t) into EDQN and if asking a question, also store
the transition (V Cr,t, qr,t, V Cr,t+1, Rr,t, Qr,t+1) into EDRRN 14:",C Hierarchical Policy Learning Algorithm,[0],[0]
"Sample random mini-batch of transitions (Sk, Ak, Sk+1, Rk) from EDQN
15: Set yDQN =",C Hierarchical Policy Learning Algorithm,[0],[0]
{,C Hierarchical Policy Learning Algorithm,[0],[0]
"Rk if terminal state Rk + γQDQN (Sk+1, argmaxa′Q(Sk+1, a
′; θ); θ−) if else 16:",C Hierarchical Policy Learning Algorithm,[0],[0]
"Sample random mini-batch of transitions (V Cl, ql, V Cl+1, Rl, Ql+1) from EDRRN
17: Set yDRRN =",C Hierarchical Policy Learning Algorithm,[0],[0]
{,C Hierarchical Policy Learning Algorithm,[0],[0]
Rl if terminal state Rl + γmaxa′∈Ql+1QDRRN,C Hierarchical Policy Learning Algorithm,[0],[0]
"(V Cl+1, a
′; θ+)",C Hierarchical Policy Learning Algorithm,[0],[0]
"if else 18: Perform gradient steps for DQN with loss ‖ yDQN −QDQN (Sk, Ak; θ) ‖2 with respect to θ
and DRRN with loss ‖ yDRRN −QDRRN",C Hierarchical Policy Learning Algorithm,[0],[0]
"(V Cl, ql; θ+) ‖2 with respect to θ+ 19: Replace target parameters θ− ← θ for every N steps.
",C Hierarchical Policy Learning Algorithm,[0],[0]
end for end for,C Hierarchical Policy Learning Algorithm,[0],[0]
"Creating an intelligent conversational system that understands vision and language is one of the ultimate goals in Artificial Intelligence (AI) (Winograd, 1972).",abstractText,[0],[0]
"Extensive research has focused on vision-tolanguage generation, however, limited research has touched on combining these two modalities in a goal-driven dialog context.",abstractText,[0],[0]
We propose a multimodal hierarchical reinforcement learning framework that dynamically integrates vision and language for task-oriented visual dialog.,abstractText,[0],[0]
The framework jointly learns the multimodal dialog state representation and the hierarchical dialog policy to improve both dialog task success and efficiency.,abstractText,[0],[0]
"We also propose a new technique, state adaptation, to integrate context awareness in the dialog state representation.",abstractText,[0],[0]
We evaluate the proposed framework and the state adaptation technique in an image guessing game and achieve promising results.,abstractText,[0],[0]
Multimodal Hierarchical Reinforcement Learning Policy for Task-Oriented Visual Dialog,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 2236–2246 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
2236",text,[0],[0]
"Theories of language origin identify the combination of language and nonverbal behaviors (vision and acoustic modality) as the prime form of communication utilized by humans throughout evolution (Müller, 1866).",1 Introduction,[0],[0]
"In natural language processing, this form of language is regarded as human multimodal language.",1 Introduction,[1.0],"['In natural language processing, this form of language is regarded as human multimodal language.']"
"Modeling multimodal language has recently become a centric research direction in both NLP and multimodal machine learning (Hazarika et al., 2018; Zadeh et al., 2018a; Poria et al., 2017a; Baltrušaitis et al., 2017; Chen et al., 2017).
",1 Introduction,[0],[0]
Studies strive to model the dual dynamics of multimodal language: intra-modal dynamics (dynamics within each modality) and cross-modal dynamics (dynamics across different modalities).,1 Introduction,[1.0],['Studies strive to model the dual dynamics of multimodal language: intra-modal dynamics (dynamics within each modality) and cross-modal dynamics (dynamics across different modalities).']
"However, from a resource perspective, previous multimodal language datasets have severe shortcomings in the following aspects: Diversity in the training samples: The diversity in training samples is crucial for comprehensive multimodal language studies due to the complexity of the underlying distribution.",1 Introduction,[0],[0]
"This complexity is rooted in variability of intra-modal and crossmodal dynamics for language, vision and acoustic modalities (Rajagopalan et al., 2016).",1 Introduction,[0],[0]
Previously proposed datasets for multimodal language are generally small in size due to difficulties associated with data acquisition and costs of annotations.,1 Introduction,[1.0],['Previously proposed datasets for multimodal language are generally small in size due to difficulties associated with data acquisition and costs of annotations.']
Variety in the topics: Variety in topics opens the door to generalizable studies across different domains.,1 Introduction,[0],[0]
Models trained on only few topics generalize poorly as language and nonverbal behaviors tend to change based on the impression of the topic on speakers’ internal mental state.,1 Introduction,[1.0],['Models trained on only few topics generalize poorly as language and nonverbal behaviors tend to change based on the impression of the topic on speakers’ internal mental state.']
"Diversity of speakers: Much like writing styles, speaking styles are highly idiosyncratic.",1 Introduction,[0],[0]
"Training models on only few speakers can lead to degenerate solutions where models learn the identity of speakers as opposed to a generalizable model of multimodal language (Wang et al., 2016).",1 Introduction,[0],[0]
Variety in annotations Having multiple labels to predict allows for studying the relations between labels.,1 Introduction,[0],[0]
"Another positive aspect of having variety of labels is allowing for multi-task learning which has shown excellent performance in past research.
",1 Introduction,[0],[0]
Our first contribution in this paper is to introduce the largest dataset of multimodal sentiment and emotion recognition called CMU Multimodal Opinion Sentiment and Emotion Intensity (CMUMOSEI).,1 Introduction,[0.9505322840443793],['In this paper we presented the largest dataset of multimodal sentiment analysis and emotion recognition called CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI).']
"CMU-MOSEI contains 23,453 annotated video segments from 1,000 distinct speakers and
250 topics.",1 Introduction,[0],[0]
Each video segment contains manual transcription aligned with audio to phoneme level.,1 Introduction,[0],[0]
All the videos are gathered from online video sharing websites 1.,1 Introduction,[0],[0]
"The dataset is currently a part of the CMU Multimodal Data SDK and is freely available to the scientific community through Github 2.
",1 Introduction,[0],[0]
Our second contribution is an interpretable fusion model called Dynamic Fusion Graph (DFG) to study the nature of cross-modal dynamics in multimodal language.,1 Introduction,[0],[0]
DFG contains built-in efficacies that are directly related to how modalities interact.,1 Introduction,[0],[0]
These efficacies are visualized and studied in detail in our experiments.,1 Introduction,[0],[0]
"Aside interpretability, DFG achieves superior performance compared to previously proposed models for multimodal sentiment and emotion recognition on CMU-MOSEI.",1 Introduction,[0],[0]
In this section we compare the CMU-MOSEI dataset to previously proposed datasets for modeling multimodal language.,2 Background,[0],[0]
We then describe the baselines and recent models for sentiment analysis and emotion recognition.,2 Background,[0],[0]
We compare CMU-MOSEI to an extensive pool of datasets for sentiment analysis and emotion recognition.,2.1 Comparison to other Datasets,[0],[0]
"The following datasets include a combination of language, visual and acoustic modalities as their input data.",2.1 Comparison to other Datasets,[0],[0]
"CMU-MOSI (Zadeh et al., 2016b) is a collection of 2199 opinion video clips each annotated with sentiment in the range",2.1.1 Multimodal Datasets,[0],[0]
"[-3,3].",2.1.1 Multimodal Datasets,[0],[0]
CMU-MOSEI is the next generation of CMU-MOSI.,2.1.1 Multimodal Datasets,[0],[0]
"The ICT-MMMO (Wöllmer et al., 2013) consists of online social review videos annotated at the video level for sentiment.",2.1.1 Multimodal Datasets,[0],[0]
"YouTube (Morency et al., 2011) contains videos from the social media web site YouTube that span a wide range of product reviews and opinion videos.",2.1.1 Multimodal Datasets,[0],[0]
"MOUD (Perez-Rosas et al., 2013) consists of product review videos in Spanish.",2.1.1 Multimodal Datasets,[0],[0]
"Each video consists of multiple segments labeled to display positive, negative or neutral sentiment.",2.1.1 Multimodal Datasets,[0],[0]
"IEMOCAP (Busso et al., 2008) consists of 151 videos of recorded dialogues, with 2 speakers per session for a total of 302 videos across the dataset.",2.1.1 Multimodal Datasets,[0],[0]
"Each
1following creative commons license allows for personal unrestricted use and redistribution of the videos
2https://github.com/A2Zadeh/CMUMultimodalDataSDK
segment is annotated for the presence of 9 emotions (angry, excited, fear, sad, surprised, frustrated, happy, disappointed and neutral) as well as valence, arousal and dominance.",2.1.1 Multimodal Datasets,[0],[0]
"Stanford Sentiment Treebank (SST) (Socher et al., 2013) includes fine grained sentiment labels for phrases in the parse trees of sentences collected from movie review data.",2.1.2 Language Datasets,[0],[0]
"While SST has larger pool of annotations, we only consider the root level annotations for comparison.",2.1.2 Language Datasets,[0],[0]
"Cornell Movie Review (Pang et al., 2002) is a collection of 2000 moviereview documents and sentences labeled with respect to their overall sentiment polarity or subjective rating.",2.1.2 Language Datasets,[0],[0]
"Large Movie Review dataset (Maas et al., 2011) contains text from highly polar movie reviews.",2.1.2 Language Datasets,[0],[0]
"Sanders Tweets Sentiment (STS) consists of 5513 hand-classified tweets each classified with respect to one of four topics of Microsoft, Apple, Twitter, and Google.",2.1.2 Language Datasets,[0],[0]
"The Vera am Mittag (VAM) corpus consists of 12 hours of recordings of the German TV talk-
show “Vera am Mittag” (Grimm et al., 2008).",2.1.3 Visual and Acoustic Datasets,[0],[0]
"This audio-visual data is labeled for continuous-valued scale for three emotion primitives: valence, activation and dominance.",2.1.3 Visual and Acoustic Datasets,[0],[0]
VAM-Audio and VAMFaces are subsets that contain on acoustic and visual inputs respectively.,2.1.3 Visual and Acoustic Datasets,[0],[0]
"RECOLA (Ringeval et al., 2013) consists of 9.5 hours of audio, visual, and physiological (electrocardiogram, and electrodermal activity) recordings of online dyadic interactions.",2.1.3 Visual and Acoustic Datasets,[0],[0]
"Mimicry (Bilakhia et al., 2015) consists of audiovisual recordings of human interactions in two situations: while discussing a political topic and while playing a role-playing game.",2.1.3 Visual and Acoustic Datasets,[0],[0]
"AFEW (Dhall et al., 2012, 2015) is a dynamic temporal facial expressions data corpus consisting of close to real world environment extracted from movies.
",2.1.3 Visual and Acoustic Datasets,[0],[0]
Detailed comparison of CMU-MOSEI to the datasets in this section is presented in Table 1.,2.1.3 Visual and Acoustic Datasets,[0],[0]
CMU-MOSEI has longer total duration as well as larger number of data point in total.,2.1.3 Visual and Acoustic Datasets,[0],[0]
"Furthermore, CMU-MOSEI has a larger variety in number of speakers and topics.",2.1.3 Visual and Acoustic Datasets,[0],[0]
"It has all three modalities provided, as well as annotations for both sentiment and emotions.",2.1.3 Visual and Acoustic Datasets,[0],[0]
Modeling multimodal language has been the subject of studies in NLP and multimodal machine learning.,2.2 Baseline Models,[0],[0]
Notable approaches are listed as follows and indicated with a symbol for reference in the Experiments and Discussion section (Section 5).,2.2 Baseline Models,[0],[0]
"# MFN: (Memory Fusion Network) (Zadeh et al., 2018a) synchronizes multimodal sequences using a multi-view gated memory that stores intraview and cross-view interactions through time.",2.2 Baseline Models,[0],[0]
∎,2.2 Baseline Models,[0],[0]
"MARN: (Multi-attention Recurrent Network) (Zadeh et al., 2018b) models intra-modal and multiple cross-modal interactions by assigning multiple attention coefficients.",2.2 Baseline Models,[0],[0]
Intra-modal and cross-modal interactions are stored in a hybrid LSTM memory component.,2.2 Baseline Models,[0],[0]
"∗ TFN (Tensor Fusion Network) (Zadeh et al., 2017) models inter and intra modal interactions by creating a multi-dimensional tensor that captures unimodal, bimodal and trimodal interactions.",2.2 Baseline Models,[0],[0]
"◇ MV-LSTM (Multi-View LSTM) (Rajagopalan et al., 2016) is a recurrent model that designates regions inside a LSTM to different views of the data.",2.2 Baseline Models,[0],[0]
"§ EF-LSTM (Early Fusion LSTM) concatenates the inputs from different modalities at each time-step and uses that as the input to a single LSTM (Hochreiter and Schmidhuber, 1997;
Graves et al., 2013; Schuster and Paliwal, 1997).",2.2 Baseline Models,[0],[0]
"In case of unimodal models EF-LSTM refers to a single LSTM.
",2.2 Baseline Models,[0],[0]
"We also compare to the following baseline models: † BC-LSTM (Poria et al., 2017b), ♣ C-MKL (Poria et al., 2016), ♭ DF (Nojavanasghari et al., 2016), ♡ SVM (Cortes and Vapnik, 1995; Zadeh et al., 2016b; Perez-Rosas et al., 2013; Park et al., 2014), ● RF (Breiman, 2001), THMM (Morency et al., 2011), SAL-CNN (Wang et al., 2016), 3DCNN (Ji et al., 2013).",2.2 Baseline Models,[0],[0]
"For language only baseline models: ∪ CNN-LSTM (Zhou et al., 2015), RNTN (Socher et al., 2013), ×: DynamicCNN (Kalchbrenner et al., 2014), ⊳ DAN (Iyyer et al., 2015), ≀ DHN (Srivastava et al., 2015), ⊲",2.2 Baseline Models,[0],[0]
"RHN (Zilly et al., 2016).",2.2 Baseline Models,[0],[0]
"For acoustic only baseline models: AdieuNet (Trigeorgis et al., 2016), SERLSTM (Lim et al., 2016).",2.2 Baseline Models,[0],[0]
Understanding expressed sentiment and emotions are two crucial factors in human multimodal language.,3 CMU-MOSEI Dataset,[0],[0]
We introduce a novel dataset for multimodal sentiment and emotion recognition called CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI).,3 CMU-MOSEI Dataset,[0],[0]
"In the following subsections, we first explain the details of the CMU-MOSEI data acquisition, followed by details of annotation and feature extraction.",3 CMU-MOSEI Dataset,[0],[0]
Social multimedia presents a unique opportunity for acquiring large quantities of data from various speakers and topics.,3.1 Data Acquisition,[0],[0]
Users of these social multimedia websites often post their opinions in the forms of monologue videos; videos with only one person in front of camera discussing a certain topic of interest.,3.1 Data Acquisition,[0],[0]
"Each video inherently contains three modalities: language in the form of spoken text, visual via perceived gestures and facial expressions, and acoustic through intonations and prosody.
",3.1 Data Acquisition,[1.0000000573441359],"['Each video inherently contains three modalities: language in the form of spoken text, visual via perceived gestures and facial expressions, and acoustic through intonations and prosody.']"
"During our automatic data acquisition process, videos from YouTube are analyzed for the presence of one speaker in the frame using face detection to ensure the video is a monologue.",3.1 Data Acquisition,[0],[0]
We limit the videos to setups where the speaker’s attention is exclusively towards the camera by rejecting videos that have moving cameras (such as camera on bikes or selfies recording while walking).,3.1 Data Acquisition,[0],[0]
We use a diverse set of 250 frequently used topics in online videos as the seed for acquisition.,3.1 Data Acquisition,[0],[0]
"We restrict the
number of videos acquired from each channel to a maximum of 10.",3.1 Data Acquisition,[0],[0]
"This resulted in discovering 1,000 identities from YouTube.",3.1 Data Acquisition,[0],[0]
"The definition of a identity is proxy to the number of channels since accurate identification requires quadratic manual annotations, which is infeasible for high number of speakers.",3.1 Data Acquisition,[0],[0]
"Furthermore, we limited the videos to have manual and properly punctuated transcriptions provided by the uploader.",3.1 Data Acquisition,[0],[0]
"The final pool of acquired videos included 5,000 videos which were then manually checked for quality of video, audio and transcript by 14 expert judges over three months.",3.1 Data Acquisition,[0],[0]
The judges also annotated each video for gender and confirmed that each video is an acceptable monologue.,3.1 Data Acquisition,[0],[0]
A set of 3228 videos remained after manual quality inspection.,3.1 Data Acquisition,[0],[0]
We also performed automatic checks on the quality of video and transcript which are discussed in Section 3.3 using facial feature extraction confidence and forced alignment confidence.,3.1 Data Acquisition,[0],[0]
"Furthermore, we balance the gender in the dataset using the data provided by the judges (57% male to 43% female).",3.1 Data Acquisition,[0],[0]
This constitutes the final set of raw videos in CMU-MOSEI.,3.1 Data Acquisition,[0],[0]
"The topics covered in the final set of videos are shown in Figure 1 as a Venn-style word cloud (Coppersmith and Kelly, 2014) with the size proportional to the number of videos gathered for that topic.",3.1 Data Acquisition,[0],[0]
"The most frequent 3 topics are reviews (16.2%), debate (2.9%) and consulting (1.8%).",3.1 Data Acquisition,[0],[0]
"The remaining topics are almost uniformly distributed 3.
",3.1 Data Acquisition,[0],[0]
"The final set of videos are then tokenized into 3more detailed analysis such as exact percentages and number of videos per topic are available in the supplementary material
sentences using punctuation markers manually provided by transcripts.",3.1 Data Acquisition,[0],[0]
"Due to the high quality of the transcripts, using punctuation markers showed better sentence quality than using the Stanford CoreNLP tokenizer (Manning et al., 2014).",3.1 Data Acquisition,[0],[0]
This was verified on a set of 20 random videos by two experts.,3.1 Data Acquisition,[0],[0]
"After tokenization, a set of 23,453 sentences were chosen as the final sentences in the dataset.",3.1 Data Acquisition,[0],[0]
This was achieved by restricting each identity to contribute at least 10 and at most 50 sentences to the dataset.,3.1 Data Acquisition,[0],[0]
Table 2 shows high-level summary statistics of the CMU-MOSEI dataset.,3.1 Data Acquisition,[0],[0]
"Annotation of CMU-MOSEI follows closely the annotation of CMU-MOSI (Zadeh et al., 2016a) and Stanford Sentiment Treebank (Socher et al., 2013).",3.2 Annotation,[0],[0]
"Each sentence is annotated for sentiment on a [-3,3] Likert scale of:",3.2 Annotation,[0],[0]
"[−3: highly negative, −2 negative, −1 weakly negative, 0 neutral, +1 weakly positive, +2 positive, +3 highly positive].",3.2 Annotation,[0],[0]
"Ekman emotions (Ekman et al., 1980) of {happiness, sadness, anger, fear, disgust, surprise} are annotated on a [0,3]",3.2 Annotation,[0],[0]
Likert scale for presence of emotion x:,3.2 Annotation,[0],[0]
"[0: no evidence of x, 1: weakly x, 2: x, 3: highly x].",3.2 Annotation,[0],[0]
The annotation was carried out by 3 crowdsourced judges from Amazon Mechanical Turk platform.,3.2 Annotation,[0],[0]
"To avert implicitly biasing the judges and to capture the raw perception of the crowd, we avoided extreme annotation training and instead provided the judges with a 5 minutes training video on how to use the annotation system.",3.2 Annotation,[0],[0]
"All the annotations have been carried out by only master workers with higher than 98% approval rate to assure high quality annotations 4.
",3.2 Annotation,[0],[0]
Figure 2 shows the distribution of sentiment and emotions in CMU-MOSEI dataset.,3.2 Annotation,[0],[0]
"The distribution
4Extensive statistics of the dataset including the crawling mechanism, the annotation UI, training procedure for the workers, agreement scores are available in submitted supplementary material available on arXiv.
",3.2 Annotation,[0],[0]
shows a slight shift in favor of positive sentiment which is similar to distribution of CMU-MOSI and SST.,3.2 Annotation,[0],[0]
"We believe that this is an implicit bias in online opinions being slightly shifted towards positive, since this is also present in CMU-MOSI.",3.2 Annotation,[0],[0]
The emotion histogram shows different prevalence for different emotions.,3.2 Annotation,[0],[0]
"The most common category is happiness with more than 12,000 positive sample points.",3.2 Annotation,[0],[0]
The least prevalent emotion is fear with almost 1900 positive sample points which is an acceptable number for machine learning studies.,3.2 Annotation,[0],[0]
Data points in CMU-MOSEI come in video format with one speaker in front of the camera.,3.3 Extracted Features,[0],[0]
"The extracted features for each modality are as follows (for other benchmarks we extract the same features):
Language:",3.3 Extracted Features,[0],[0]
All videos have manual transcription.,3.3 Extracted Features,[0],[0]
"Glove word embeddings (Pennington et al., 2014) were used to extract word vectors from transcripts.",3.3 Extracted Features,[0],[0]
"Words and audio are aligned at phoneme level using P2FA forced alignment model (Yuan and Liberman, 2008).",3.3 Extracted Features,[0],[0]
"Following this, the visual and acoustic modalities are aligned to the words by interpolation.",3.3 Extracted Features,[0],[0]
"Since the utterance duration of words in English is usually short, this interpolation does not lead to substantial information loss.
",3.3 Extracted Features,[0],[0]
Visual: Frames are extracted from the full videos at 30Hz.,3.3 Extracted Features,[0],[0]
"The bounding box of the face is extracted using the MTCNN face detection algorithm (Zhang et al., 2016).",3.3 Extracted Features,[0],[0]
"We extract facial action units through Facial Action Coding System (FACS) (Ekman et al., 1980).",3.3 Extracted Features,[0],[0]
"Extracting these action units allows for accurate tracking and understanding of the facial expressions (Baltrušaitis
et al., 2016).",3.3 Extracted Features,[0],[0]
"We also extract a set of six basic emotions purely from static faces using Emotient FACET (iMotions, 2017).",3.3 Extracted Features,[0],[0]
"MultiComp OpenFace (Baltrušaitis et al., 2016) is used to extract the set of 68 facial landmarks, 20 facial shape parameters, facial HoG features, head pose, head orientation and eye gaze (Baltrušaitis et al., 2016).",3.3 Extracted Features,[0],[0]
"Finally, we extract face embeddings from commonly used facial recognition models such as DeepFace (Taigman et al., 2014), FaceNet (Schroff et al., 2015) and SphereFace (Liu et al., 2017).
",3.3 Extracted Features,[0],[0]
"Acoustic: We use the COVAREP software (Degottex et al., 2014) to extract acoustic features including 12 Mel-frequency cepstral coefficients, pitch, voiced/unvoiced segmenting features (Drugman and Alwan, 2011), glottal source parameters (Drugman et al., 2012; Alku et al., 1997, 2002), peak slope parameters and maxima dispersion quotients (Kane and Gobl, 2013).",3.3 Extracted Features,[0],[0]
All extracted features are related to emotions and tone of speech.,3.3 Extracted Features,[0],[0]
"From the linguistics perspective, understanding the interactions between language, visual and audio modalities in multimodal language is a fundamental research problem.",4 Multimodal Fusion Study,[0],[0]
"While previous works have been successful with respect to accuracy metrics, they have not created new insights on how the fusion is performed in terms of what modalities are related and how modalities engage in an interaction during fusion.",4 Multimodal Fusion Study,[0],[0]
"Specifically, to understand the fusion process one must first understand the n-modal dynamics (Zadeh et al., 2017).",4 Multimodal Fusion Study,[0],[0]
n-modal dynamics state that there exists different combination of modalities and that all of these combinations must be captured to better understand the multimodal language.,4 Multimodal Fusion Study,[0],[0]
"In this paper, we define building the n-modal dynamics as a hierarchical process and propose a new fusion model called the Dynamic Fusion Graph (DFG).",4 Multimodal Fusion Study,[0],[0]
DFG is easily interpretable through what is called efficacies in graph connections.,4 Multimodal Fusion Study,[0],[0]
"To utilize this new fusion model in a multimodal language framework, we build upon Memory Fusion Network (MFN) by replacing the original fusion component in the MFN with our DFG.",4 Multimodal Fusion Study,[0],[0]
We call this resulting model the Graph Memory Fusion Network (Graph-MFN).,4 Multimodal Fusion Study,[0],[0]
"Once the model is trained end to end, we analyze the efficacies in the DFG to study the fusion mechanism learned for modalities in multimodal language.",4 Multimodal Fusion Study,[0],[0]
"In addition to being an interpretable fusion mechanism,
Graph-MFN also outperforms previously proposed state-of-the-art models for sentiment analysis and emotion recognition on the CMU-MOSEI.",4 Multimodal Fusion Study,[0],[0]
In this section we discuss the internal structure of the proposed Dynamic Fusion Graph (DFG) neural model (Figure 3.,4.1 Dynamic Fusion Graph,[0],[0]
"DFG has the following properties: 1) it explicitly models the n-modal interactions, 2) does so with an efficient number of parameters (as opposed to previous approaches such as Tensor Fusion (Zadeh et al., 2017)) and 3) can dynamically alter its structure and choose the proper fusion graph based on the importance of each n-modal dynamics during inference.",4.1 Dynamic Fusion Graph,[0],[0]
"We assume the set of modalities to be M = {(l)anguage, (v)ision, (a)coustic}.",4.1 Dynamic Fusion Graph,[0],[0]
"The unimodal dynamics are denoted as {l},{v},{a}, the bimodal dynamics as {l, v},{v, a},{l, a} and trimodal dynamics as {l, v, a}.",4.1 Dynamic Fusion Graph,[0],[0]
"These dynamics are in the form of latent representations and are each considered as vertices inside a graph G = (V,E) with V the set of vertices and E the set of edges.",4.1 Dynamic Fusion Graph,[0],[0]
A directional neural connection is established between two vertices vi and vj only if vi ⊂ vj .,4.1 Dynamic Fusion Graph,[0],[0]
"For example, {l} ⊂ {l, v} which results in a connection between < language > and < language, vision >.",4.1 Dynamic Fusion Graph,[1.0],"['For example, {l} ⊂ {l, v} which results in a connection between < language > and < language, vision >.']"
This connection is denoted as an edge eij .,4.1 Dynamic Fusion Graph,[0],[0]
"Dj takes as input all vi that satisfy the neural connection formula above for vj .
",4.1 Dynamic Fusion Graph,[0],[0]
We define an efficacy for each edge eij denoted as αij .,4.1 Dynamic Fusion Graph,[0],[0]
vi is multiplied by αij before being used as input toDj .,4.1 Dynamic Fusion Graph,[0],[0]
"Each α is a sigmoid activated probabil-
ity neuron which indicates how strong or weak the connection is between vi and vj .",4.1 Dynamic Fusion Graph,[0],[0]
αs are the main source of interpretability in DFG.,4.1 Dynamic Fusion Graph,[0],[0]
"The vector of all αs is inferred using a deep neural network Dα which takes as input singleton vertices in V (l, v, and a).",4.1 Dynamic Fusion Graph,[0],[0]
"We leave it to the supervised training objective to learn parameters of Dα and make good use of efficacies, thus dynamically controlling the structure of the graph.",4.1 Dynamic Fusion Graph,[0],[0]
The singleton vertices are chosen for this purpose since they have no incoming edges thus no efficacy associated with those edges (no efficacy is needed to infer the singleton vertices).,4.1 Dynamic Fusion Graph,[0],[0]
"The same singleton vertices l, v, and a are the inputs to the DFG.",4.1 Dynamic Fusion Graph,[0],[0]
In the next section we discuss how these inputs are given to DFG.,4.1 Dynamic Fusion Graph,[0],[0]
All vertices are connected to the output vertex Tt of the network via edges scaled by their respective efficacy.,4.1 Dynamic Fusion Graph,[0],[0]
"The overall structure of the vertices, edges and respective efficacies is shown in Figure 3.",4.1 Dynamic Fusion Graph,[0],[0]
"There are a total of 8 vertices (counting the output vertex), 19 edges and subsequently 19 efficacies.",4.1 Dynamic Fusion Graph,[0],[0]
"To test the performance of DFG, we use a similar recurrent architecture to Memory Fusion Network (MFN).",4.2 Graph-MFN,[0],[0]
MFN is a recurrent neural model with three main components 1) System of LSTMs: a set of parallel LSTMs with each LSTM modeling a single modality.,4.2 Graph-MFN,[0],[0]
"2) Delta-memory Attention Network is the component that performs multimodal fusion
by assigning coefficients to highlight cross-modal dynamics.",4.2 Graph-MFN,[0],[0]
3) Multiview Gated Memory is a component that stores the output of multimodal fusion.,4.2 Graph-MFN,[0],[0]
We replace the Delta-memory Attention Network with DFG and refer to the modified model as Graph Memory Fusion Network (Graph-MFN).,4.2 Graph-MFN,[1.0],['We replace the Delta-memory Attention Network with DFG and refer to the modified model as Graph Memory Fusion Network (Graph-MFN).']
"Figure 4 shows the overall architecture of the Graph-MFN.
Similar to MFN, Graph-MFN employs a system of LSTMs for modeling individual modalities.",4.2 Graph-MFN,[0],[0]
"cl, cv, and ca represent the memory of LSTMs for language, vision and acoustic modalities respectively.",4.2 Graph-MFN,[1.0],"['cl, cv, and ca represent the memory of LSTMs for language, vision and acoustic modalities respectively.']"
"Dm, m ∈ {l, v, a} is a fully connected deep neural network that takes in hm[t−1,t] the LSTM representation across two consecutive timestamps, which allows the network to track changes in memory dimensions across time.",4.2 Graph-MFN,[0],[0]
"The outputs of Dl, Dv and Da are the singleton vertices for the DFG.",4.2 Graph-MFN,[0],[0]
The DFG models cross-modal interactions and encodes the cross-modal representations in its output vertex Tt for storage in the Multi-view Gated Memory ut.,4.2 Graph-MFN,[1.0],['The DFG models cross-modal interactions and encodes the cross-modal representations in its output vertex Tt for storage in the Multi-view Gated Memory ut.']
The Multi-view Gated Memory functions using a network Du that transforms Tt into a proposed memory update ût. γ1 and γ2 are the Multi-view Gated Memory’s retain and update gates respectively and are learned using networks Dγ1 and Dγ2 .,4.2 Graph-MFN,[0],[0]
"Finally, a network Dz transforms Tt into a multimodal representation zt to update the system of LSTMs.",4.2 Graph-MFN,[0],[0]
"The output of Graph-MFN in all the experiments is the output of each LSTM hmT as well as contents of the Multi-view Gated Memory at time T (last recurrence timestep), uT .",4.2 Graph-MFN,[0],[0]
"This output
is subsequently connected to a classification or regression layer for final prediction (for sentiment and emotion recognition).",4.2 Graph-MFN,[0],[0]
"In our experiments, we seek to evaluate how modalities interact during multimodal fusion by studying the efficacies of DFG through time.
",5 Experiments and Discussion,[0],[0]
Table 3 shows the results on CMU-MOSEI.,5 Experiments and Discussion,[0],[0]
Accuracy is reported as Ax where x is the number of sentiment classes as well as F1 measure.,5 Experiments and Discussion,[0],[0]
For regression we report MAE and correlation (r).,5 Experiments and Discussion,[0],[0]
"For emotion recognition due to the natural imbalances across various emotions, we use weighted accuracy (Tong et al., 2017) and F1 measure.",5 Experiments and Discussion,[0],[0]
Graph-MFN shows superior performance in sentiment analysis and competitive performance in emotion recognition.,5 Experiments and Discussion,[0],[0]
"Therefore, DFG is both an effective and interpretable model for multimodal fusion.
",5 Experiments and Discussion,[1.0000000929084376],"['Therefore, DFG is both an effective and interpretable model for multimodal fusion.']"
"To better understand the internal fusion mechanism between modalities, we visualize the behavior of the learned DFG efficacies in Figure 5 for various cases (deep red denotes high efficacy and deep blue denotes low efficacy).
",5 Experiments and Discussion,[0],[0]
Multimodal Fusion has a Volatile Nature:,5 Experiments and Discussion,[0],[0]
The first observation is that the structure of the DFG is changing case by case and for each case over time.,5 Experiments and Discussion,[0],[0]
"As a result, the model seems to be selectively prioritizing certain dynamics over the others.",5 Experiments and Discussion,[0],[0]
"For example, in case (I) where all modalities are informative, all efficacies seem to be high, imply-
ing that the DFG is able to find useful information in unimodal, bimodal and trimodal interactions.",5 Experiments and Discussion,[0],[0]
"However, in cases (II) and (III) where the visual modality is either uninformative or contradictory, the efficacies of v → l, v and v → l, a, v and l, a→ l, a, v are reduced since no meaningful interactions involve the visual modality.
",5 Experiments and Discussion,[0],[0]
Priors in Fusion: Certain efficacies remain unchanged across cases and across time.,5 Experiments and Discussion,[0],[0]
These are priors from Human Multimodal Language that DFG learns.,5 Experiments and Discussion,[0],[0]
"For example the model always seems to prioritize fusion between language and audio in (l → l, a), and (a → l, a).",5 Experiments and Discussion,[1.0],"['For example the model always seems to prioritize fusion between language and audio in (l → l, a), and (a → l, a).']"
"Subsequently, DFG gives low values to efficacies that rely unilaterally on language or audio alone: the (l → τ) and (a→ τ) efficacies seem to be consistently low.",5 Experiments and Discussion,[0],[0]
"On the other hand, the visual modality appears to have a partially isolated behavior.",5 Experiments and Discussion,[0],[0]
"In the presence of informative visual information, the model increases the efficacies of (v → τ) although the values of other visual efficacies also increase.
",5 Experiments and Discussion,[0],[0]
"Trace of Multimodal Fusion: We trace the dominant path that every modality undergoes during fusion: 1) language tends to first fuse with audio via (l → l, a) and the language and acoustic modalities together engage in higher level fusions such as (l, a → l, a, v).",5 Experiments and Discussion,[0],[0]
"Intuitively, this is aligned with the close ties between language and audio through word intonations.",5 Experiments and Discussion,[0],[0]
2),5 Experiments and Discussion,[0],[0]
The visual modality seems to engage in fusion only if it contains meaningful information.,5 Experiments and Discussion,[0],[0]
"In cases (I) and (IV), all the paths involving the visual modality are relatively active while in cases (II) and (III) the paths involv-
ing the visual modality have low efficacies.",5 Experiments and Discussion,[0],[0]
3),5 Experiments and Discussion,[0],[0]
The acoustic modality is mostly present in fusion with the language modality.,5 Experiments and Discussion,[0],[0]
"However, unlike language, the acoustic modality also appears to fuse with the visual modality if both modalities are meaningful, such as in case (I).
",5 Experiments and Discussion,[1.0000000380329759],"['However, unlike language, the acoustic modality also appears to fuse with the visual modality if both modalities are meaningful, such as in case (I).']"
"An interesting observation is that in almost all cases the efficacies of unimodal connections to terminal T is low, implying that T prefers to not rely on just one modality.",5 Experiments and Discussion,[0],[0]
"Also, DFG always prefers to perform fusion between language and audio as in most cases both l → l, a and a → l, a have high efficacies; intuitively in most natural scenarios language and acoustic modalities are highly aligned.",5 Experiments and Discussion,[0],[0]
"Both of these cases show unchanging behaviors which we believe DFG has learned as natural priors of human communicative signal.
",5 Experiments and Discussion,[0.9999999223414072],['Both of these cases show unchanging behaviors which we believe DFG has learned as natural priors of human communicative signal.']
"With these observations, we believe that DFG has successfully learned how to manage its internal structure to model human communication.",5 Experiments and Discussion,[0],[0]
In this paper we presented the largest dataset of multimodal sentiment analysis and emotion recognition called CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI).,6 Conclusion,[0],[0]
"CMUMOSEI consists of 23,453 annotated sentences from more than 1000 online speakers and 250 different topics.",6 Conclusion,[1.0],"['CMUMOSEI consists of 23,453 annotated sentences from more than 1000 online speakers and 250 different topics.']"
The dataset expands the horizons of Human Multimodal Language studies in NLP.,6 Conclusion,[1.0],['The dataset expands the horizons of Human Multimodal Language studies in NLP.']
One such study was presented in this paper where we analyzed the structure of multimodal fusion in sentiment analysis and emotion recognition.,6 Conclusion,[0],[0]
"This was
done using a novel interpretable fusion mechanism called Dynamic Fusion Graph (DFG).",6 Conclusion,[0],[0]
In our studies we investigated the behavior of modalities in interacting with each other using built-in efficacies of DFG.,6 Conclusion,[0],[0]
"Aside analysis of fusion, DFG was trained in the Memory Fusion Network pipeline and showed superior performance in sentiment analysis and competitive performance in emotion recognition.",6 Conclusion,[0],[0]
This material is based upon work partially supported by the National Science Foundation (Award #1833355) and Oculus VR.,Acknowledgments,[0],[0]
"Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of National Science Foundation or Oculus VR, and no official endorsement should be inferred.",Acknowledgments,[0],[0]
Analyzing human multimodal language is an emerging area of research in NLP.,abstractText,[0],[0]
"Intrinsically human communication is multimodal (heterogeneous), temporal and asynchronous; it consists of the language (words), visual (expressions), and acoustic (paralinguistic) modalities all in the form of asynchronous coordinated sequences.",abstractText,[0],[0]
"From a resource perspective, there is a genuine need for large scale datasets that allow for in-depth studies of multimodal language.",abstractText,[0],[0]
"In this paper we introduce CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI), the largest dataset of sentiment analysis and emotion recognition to date.",abstractText,[0],[0]
"Using data from CMU-MOSEI and a novel multimodal fusion technique called the Dynamic Fusion Graph (DFG), we conduct experimentation to investigate how modalities interact with each other in human multimodal language.",abstractText,[0],[0]
"Unlike previously proposed fusion techniques, DFG is highly interpretable and achieves competitive performance compared to the current state of the art.",abstractText,[0],[0]
Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph,title,[0],[0]

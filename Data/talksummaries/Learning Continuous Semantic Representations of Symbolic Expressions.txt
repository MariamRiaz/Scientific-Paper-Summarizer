2	23	Symbolic notation allows us to abstractly represent a large set of states that may be perceptually very different.
5	33	This raises the exciting opportunity of using pattern recognition within symbolic reasoning, that is, to learn patterns from datasets of symbolic expressions that approximately represent se- Work started when M. Allamanis was at Edinburgh.
6	68	This work was done while P. Kohli was at Microsoft.
7	29	However, apart from some notable exceptions (Alemi et al., 2016; Loos et al., 2017; Zaremba et al., 2014), this area has received relatively little attention in machine learning.
9	44	The goal is for expressions with similar semantics to have similar continuous representations, even if their syntactic representation is very different.
12	70	Our aim is, given access to a training set of pairs of expressions for which semantic equivalence is known, to assign continuous vectors to symbolic expressions in such a way that semantically equivalent, but syntactically diverse expressions are assigned to identical (or highly similar) continuous vectors.
21	19	EQNETs learn how syntactic composition recursively composes SEMVECs, like a TREENN, but are also designed to model large changes in semantics as the network progresses up the syntax tree.
45	10	, TREENN(ck), τn), where (c0, .
46	23	, ck) = ch(n) else rn ← LOOKUPLEAFEMBEDDING(τn) return rn The general framework of TREENN allows two points of variation, the implementation of LOOKUPLEAFEMBEDDING and COMBINE.
49	48	To train these networks to learn SEMVECs, we will use a supervised objective based on a set of known equivalence relations (see Section 2.2).
50	33	Our domain requires that the network learns to abstract away syntax, assigning identical representations to expressions that may be syntactically different but semantically equivalent, and also assigning different representations to expressions that may be syntactically very similar but nonequivalent.
51	22	In this work, we find that standard neural architectures do not handle well this challenge.
56	11	Based on these, we define neural equivalence networks (EQNET), which learn to compose representations of equivalence classes into new equivalence classes (Figure 1a).
59	49	The first extension that we introduce is to the network structure at each layer in the tree.
69	12	However, as TREENNs become deeper, they suffer from optimization issues, such as diminishing and exploding gradients.
71	103	We observe this problem even with only two-layer MLPs, as the overall network can become quite deep when using two layers for each node in the syntax tree.
72	14	We resolve this issue in the training procedure by constraining each SEMVEC to have unit norm.
74	17	The normalization step of l̄out and Cτn is somewhat similar to weight normalization (Salimans & Kingma, 2016) and vaguely resembles layer normalization (Ba et al., 2016).
75	20	Normalizing the SEMVECs partially resolves issues with diminishing and exploding gradients, and removes a spurious degree of freedom in the semantic representation.
76	27	As simple as this modification may seem, we found it vital for obtaining good performance, and all of our multi-layer TREENNs converged to low-performing settings without it.
85	40	Observe that given the semantic representation of any two of the three nodes of a subexpression (by which we mean the parent, left child, right child of an expression tree) it is often possible to completely determine or at least place strong constraints on the semantics of the third.
102	24	Second, because the denoising autoencoder is reconstructing parent and child representations together, this encourages child representations to be predictable from parents and siblings.
103	32	Putting these two together, the goal is that the information discarded by the autoencoder bottleneck will be more syntactic than semantic, assuming that the semantics of child node is more predictable from its parent and sibling than its syntactic realization.
107	28	In some cases due to the autoencoder noise, the differences between the input tuple x′,x′′ that contain rc′0 and rc′′0 will be non-existent and the decoder will predict a single location r̃c0 (possibly different from rc′0 and rc′′0 ).
108	16	Then, when minimizing the reconstruction error, both rc′0 and rc′′0 will be attracted to r̃c0 and eventually should merge.
109	22	We train EQNETs from a dataset of expressions whose semantic equivalence is known.
111	62	TN} of parse trees of expressions, we assume that the training set is partitioned into equivalence classes E = {e1 .
113	23	Given an expression tree T that belongs to the equivalence class ei ∈ E , we compute the probability P (ei|T ) = exp ( TREENN(T )>qei + bi )∑ j exp ( TREENN(T )>qej + bj ) (1) where qei are model parameters that we can interpret as representations of each equivalence class that appears in the training class, and bi are scalar bias terms.
115	67	This is without loss of generality, because if we do know the equivalence class of a subexpression of T , we can simply add that subexpression to the training set.
116	50	To train the model, we use a max-margin objective that maximizes classification accuracy, i.e. LACC(T, ei) = max ( 0, arg max ej 6=ei,ej∈E log P (ej |T ) P (ei|T ) +m ) (2) where m > 0 is a scalar margin.

{"sections": [{"heading": "1. Introduction", "text": "Variational Inference (VI), including a large family of posterior approximation methods like stochastic VI (Hoffman et al. 2013), black-box VI (Ranganath et al. 2014), automatic differentiation VI (ADVI, Kucukelbir et al. 2017), and many other variants, has emerged as a widely-used method for scalable Bayesian inference. These methods come with few theoretical guarantees and it\u2019s difficult to assess how well the computed variational posterior approximates the true posterior.\nInstead of computing expectations or sampling draws from the posterior p(\u03b8 | y), variational inference fixes a family of approximate densities Q, and finds the member q\u2217 minimizing the Kullback-Leibler (KL) divergence to the true posterior: KL (q(\u03b8), p(\u03b8 | y)) . This is equivalent to maximizing the evidence lower bound (ELBO):\nELBO(q) = \u222b \u0398 (log p(\u03b8, y)\u2212 log q(\u03b8)) q(\u03b8)d\u03b8. (1)\nThere are many situations where the VI approximation is flawed. This can be due to the slow convergence of the\n1Department of Statistics, Columbia University, NY, USA 2Helsinki Institute for Information Technology, Department of Computer Science, Aalto University, Finland 3Department of Statistical Sciences, University of Toronto, Canada. Correspondence to: Yuling Yao <yy2618@columbia.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\noptimization problem, the inability of the approximation family to capture the true posterior, the asymmetry of the true distribution, the fact that the direction of the KL divergence under-penalizes approximation with too-light tails, or all these reasons. We need a diagnostic algorithm to test whether the VI approximation is useful.\nThere are two levels of diagnostics for variational inference. First the convergence test should be able to tell if the objective function has converged to a local optimum. When the optimization problem (1) is solved through stochastic gradient descent (SGD), the convergence can be assessed by monitoring the running average of ELBO changes. Researchers have introduced many convergence tests based on the asymptotic property of stochastic approximations (e.g., Sielken, 1973; Stroup & Braun, 1982; Pflug, 1990; Wada & Fujisaki, 2015; Chee & Toulis, 2017). Alternatively, Blei et al. (2017) suggest monitoring the expected log predictive density by holding out an independent test dataset. After convergence, the optimum is still an approximation to the truth. This paper is focusing on the second level of VI diagnostics whether the variational posterior q\u2217(\u03b8) is close enough to the true posterior p(\u03b8|y) to be used in its place.\nPurely relying on the objective function or the equivalent ELBO does not solve the problem. An unknown multiplicative constant exists in p(\u03b8, y) \u221d p(\u03b8 | y) that changes with reparametrization, making it meaningless to compare ELBO across two approximations. Moreover, the ELBO is a quantity on an uninterpretable scale, that is it\u2019s not clear at what value of the ELBO we can begin to trust the variational posterior. This makes it next to useless as a method to assess how well the variational inference has fit.\nIn this paper we propose two diagnostic methods that assess, respectively, the quality of the entire variational posterior for a particular data set, and the average bias of a point estimate produced under correct model specification.\nThe first method is based on generalized Pareto distribution diagnostics used to assess the quality of a importance sampling proposal distribution in Pareto smoothed importance sampling (PSIS, Vehtari et al., 2017). The benefit of PSIS diagnostics is two-fold. First, we can tell the discrepancy between the approximate and the true distribution by the estimated continuous k\u0302 value. When it is larger than a prespecified threshold, users should be alert of the limitation\nof current variational inference computation and consider further tuning it or turn to exact sampling like Markov chain Monte Carlo (MCMC). Second, in the case when k\u0302 is small, the fast convergence rate of the importance-weighted Monte Carlo integration guarantees a better estimation accuracy. In such sense, the PSIS diagnostics could also be viewed as a post-adjustment for VI approximations. Unlike the secondorder correction Giordano et al. (2017), which relies on an un-testable unbiasedness assumption, we make diagnostics and adjustment at the same time.\nThe second diagnostic considers only the quality of the median of the variational posterior as a point estimate (in Gaussian mean-field VI this corresponds to the modal estimate). This diagnostic assesses the average behavior of the point estimate under data from the model and can indicate when a systemic bias is present. The magnitude of that bias can be monitored while computing the diagnostic. This diagnostic can also assess the average calibration of univariate functionals of the parameters, revealing if the posterior is under-dispersed, over-dispersed, or biased. This diagnostic could be used as a partial justification for using the second-order correction of Giordano et al. (2017)."}, {"heading": "2. Is the Joint Distribution Good Enough?", "text": "If we can draw a sample (\u03b81, . . . , \u03b8S) from p(\u03b8|y), the expectation of any integrable function Ep[h(\u03b8)] can be esti-\nmated by Monte Carlo integration: \u2211S s=1 h(\u03b8s)/S\nS\u2192\u221e\u2212\u2212\u2212\u2212\u2212\u2192 Ep [h(\u03b8)] . Alternatively, given samples (\u03b81, . . . , \u03b8S) from a proposal distribution q(\u03b8), the importance sampling (IS) estimate is (\u2211S s=1 h(\u03b8s)rs ) / \u2211S s=1 rs, where the importance ratios rs are defined as\nrs = p(\u03b8s, y)\nq(\u03b8s) . (2)\nIn general, with a sample (\u03b81, . . . , \u03b8S) drawn from the variational posterior q(\u03b8), we consider a family of estimates with the form\nEp[h(\u03b8)] \u2248 \u2211S s=1 h(\u03b8s)ws\u2211S\ns=1 ws , (3)\nwhich contains two extreme cases:\n1. When ws \u2261 1, estimate (3) becomes the plain VI estimate that is we completely trust the VI approximation. In general, this will be biased to an unknown extent and inconsistent. However, this estimator has small variance.\n2. When ws = rs, (3) becomes importance sampling. The strong law of large numbers ensures it is consistent\nas S \u2192 \u221e, and with small O(1/S) bias due to selfnormalization. But the IS estimate may have a large or infinite variance.\nThere are two questions to be answered. First, can we find a better bias-variance trade-off than both plain VI and IS?\nSecond, VI approximation q(\u03b8) is not designed for an optimal IS proposal, for it has a lighter tail than p(\u03b8|y) as a result of entropy penalization, which lead to a heavy right tail of rs. A few large-valued rs dominates the summation, bringing in large uncertainty. But does the finite sample performance of IS or stabilized IS contain the information about the dispensary measure between q(\u03b8) and p(\u03b8|y)?"}, {"heading": "2.1. Pareto Smoothed Importance Sampling", "text": "The solution to the first question is the Pareto smoothed importance sampling (PSIS). We give a brief review, and more details can be found in Vehtari et al. (2017).\nA generalized Pareto distribution with shape parameter k and location-scale parameter (\u00b5, \u03c4) has the density\np(y|\u00b5, \u03c3, k) =  1 \u03c3 ( 1 + k ( y \u2212 \u00b5 \u03c3 ))\u2212 1k\u22121 , k 6= 0. 1\n\u03c3 exp ( y \u2212 \u00b5 \u03c3 ) , k = 0.\nPSIS stabilizes importance ratios by fitting a generalized Pareto distribution using the largest M samples of ri, where M is empirically set as min(S/5, 3 \u221a S). It then reports the\nestimated shape parameter k\u0302 and replaces the M largest rs by their expected value under the fitted generalized Pareto distribution. The other importance weights remain unchanged. We further truncate all weights at the raw weight maximum max(rs). The resulted smoothed weights are denoted by ws, based on which a lower variance estimation can be calculated through (3).\nPareto smoothed importance sampling can be considered as Bayesian version of importance sampling with prior on the largest importance ratios. It has smaller mean square errors than plain IS and truncated-IS (Ionides, 2008)."}, {"heading": "2.2. Using PSIS as a Diagnostic Tool", "text": "The fitted shape parameter k\u0302, turns out to provide the desired diagnostic measurement between the true posterior p(\u03b8|y) and the VI approximation q(\u03b8). A generalized Pareto distribution with shape k has finite moments up to order 1/k, thus any positive k\u0302 value can be viewed as an estimate to\nk = inf { k\u2032 > 0 : Eq ( p(\u03b8|y) q(\u03b8) ) 1 k\u2032 <\u221e } . (4)\nk\u0302 is invariant under any constant multiplication of p or q, which explains why we can suppress the marginal likelihood (normalizing constant) p(y) and replace the intractable p(\u03b8|y) with p(\u03b8, y) in (2).\nAfter log transformation, (4) can be interpreted as Re\u0301nyi divergence (Re\u0301nyi et al., 1961) with order \u03b1 between p(\u03b8|y) and q(\u03b8):\nk = inf { k\u2032 > 0 : D 1\nk\u2032 (p||q) <\u221e\n} ,\nwhereD\u03b1 (p||q) = 1\n\u03b1\u2212 1 log \u222b \u0398 p(\u03b8)\u03b1q(\u03b8)1\u2212\u03b1d\u03b8.\nIt is well-defined since Re\u0301nyi divergence is monotonic increasing on order \u03b1. Particularly, when k > 0.5, the \u03c72 divergence \u03c7(p||q), becomes infinite, and when k > 1, D1(p||q) = KL(p, q) = \u221e, indicating a disastrous VI approximation, despite the fact that KL(q, p) is always minimized among the variational family. The connection to Re\u0301nyi divergence holds when k > 0. When k < 0, it predicts the importance ratios are bounded from above.\nThis also illustrates the advantage of a continuous k\u0302 estimate in our approach over only testing the existence of second moment of Eq(q/p)2 (Epifani et al., 2008; Koopman et al., 2009) \u2013 it indicates if the Re\u0301nyi divergence between q and p is finite for all continuous order \u03b1 > 0.\nMeanwhile, the shape parameter k determines the finite sample convergence rate of both IS and PSIS adjusted estimate. Geweke (1989) shows when Eq[r(\u03b8)2] < \u221e and Eq[ ( r(\u03b8)h(\u03b8) )2 ] <\u221e hold (both conditions can be tested\nby k\u0302 in our approach), the central limit theorem guarantees the square root convergence rate. Furthermore, when k < 1/3, then the Berry-Essen theorem states faster convergence rate to normality (Chen et al., 2004). Cortes et al. (2010) and Cortes et al. (2013) also link the finite sample convergence rate of IS with the number of existing moments of importance ratios.\nPSIS has smaller estimation error than the plain VI estimate, which we will experimentally verify this in Section 4. A large k\u0302 indicates the failure of finite sample PSIS, so it further indicates the large estimation error of VI approximation. Therefore, even when the researchers\u2019 primary goal is not to use variational approximation q as an PSIS proposal, they should be alert by a large k\u0302 which tells the discrepancy between the VI approximation result and the true posterior.\nAccording to empirical study in Vehtari et al. (2017), we set the threshold of k\u0302 as follows.\n\u2022 If k\u0302 < 0.5, we can invoke the central limit theorem to suggest PSIS has a fast convergence rate. We conclude the variational approximation q is close enough to the true density. We recommend further using PSIS to\nAlgorithm 1 PSIS diagnostic 1: Input: the joint density function p(\u03b8, y); number of\nposterior samples S; number of tail samples M . 2: Run variational inference to p(\u03b8|y), obtain VI approxi-\nmation q(\u03b8); 3: Sample (\u03b8s, s = 1, . . . , S) from q(\u03b8); 4: Calculate the importance ratio rs = p(\u03b8s, y)/q(\u03b8s); 5: Fit generalized Pareto distribution to the M largest rs; 6: Report the shape parameter k\u0302; 7: if k\u0302 < 0.7 then 8: Conclude VI approximation q(\u03b8) is close enough to the unknown truth p(\u03b8|y); 9: Recommend further shrinking errors by PSIS. 10: else 11: Warn users that the VI approximation is not reliable. 12: end if\nadjust the estimator (3) and calculate other divergence measures.\n\u2022 If 0.5 < k\u0302 < 0.7, we still observe practically useful finite sample convergence rates and acceptable Monte Carlo error for PSIS. It indicates the variational approximation q is not perfect but still useful. Again, we recommend PSIS to shrink errors.\n\u2022 If k\u0302 > 0.7, the PSIS convergence rate becomes impractically slow, leading to a large mean square error, and a even larger error for plain VI estimate. We should consider tuning the variational methods (e.g., re-parametrization, increase iteration times, increase mini-batch size, decrease learning rate, et.al.,) or turning to exact MCMC. Theoretically k is always smaller than 1, for Eq [p(\u03b8|y)/q(\u03b8)] = p(y) < \u221e, while in practice finite sample estimate k\u0302 may be larger than 1, which indicates even worse finite sample performance.\nThe proposed diagnostic method is summarized in Algorithm 1."}, {"heading": "2.3. Invariance Under Re-Parametrization", "text": "Re-parametrization is common in variational inference. Particularly, the reparameterization trick (Rezende et al., 2014) rewrites the objective function to make gradient calculation easier in Monte Carlo integrations.\nA nice property of PSIS diagnostics is that the k\u0302 quantity is invariant under any re-parametrization. Suppose \u03be = T (\u03b8) is a smooth transformation, then the density ratio of \u03be under the target p and the proposal q does not change:\np(\u03be) q(\u03be) = p ( T\u22121(\u03be) ) |detJ\u03beT\u22121(\u03be)| q (T\u22121(\u03be)) |detJ\u03beT\u22121(\u03be)| = p (\u03b8) q(\u03b8)\nTherefore, p(\u03be)/q(\u03be) and p(\u03b8)/q(\u03b8) have the same distribution under q, making it free to choose any convenient parametrization form when calculating k\u0302.\nHowever, if the re-parametrization changes the approximation family, then it will change the computation result, and PSIS diagnostics will change accordingly. Finding the optimal parametrization form, such that the re-parametrized posterior distribution lives exactly in the approximation family\np(T (\u03be)) = p ( T\u22121(\u03be) ) |J\u03beT\u22121(\u03be)| \u2208 Q,\ncan be as hard as finding the true posterior. The PSIS diagnostic can guide the choice of re-parametrization by simply comparing the k\u0302 quantities of any parametrization. Section 4.3 provides a practical example."}, {"heading": "2.4. Marginal PSIS Diagnostics Do Not Work", "text": "As dimension increases, the VI posterior tends to be further away from the truth, due to the limitation of approximation families. As a result, k increases, indicating inefficiency of importance sampling. This is not the drawback of PSIS diagnostics. Indeed, when the focus is the joint distribution, such behaviour accurately reflects the quality of the variational approximation to the joint posterior.\nDenoting the one-dimensional true and approximate marginal density of the i-th coordinate \u03b8i as p(\u03b8i|y) and q(\u03b8i), the marginal k for \u03b8i can be defined as\nki = inf { 0 < k\u2032 < 1 : Eq ( p(\u03b8i|y) q(\u03b8i) ) 1 k\u2032 <\u221e } .\nThe marginal ki is never larger (and usually smaller) than the joint k in (4).\nProposition 1. For any two distributions p and q with support \u0398 and the margin index i, if there is a number \u03b1 > 1 satisfying Eq (p(\u03b8)/q(\u03b8)) \u03b1 < \u221e, then Eq (p(\u03b8i)/q(\u03b8i)) \u03b1 <\u221e.\nProposition 1 demonstrates why the importance sampling is usually inefficient in high dimensional sample space, in that the joint estimation is \u201cworse\u201d than any of the marginal estimation.\nShould we extend the PSIS diagnostics to marginal distributions? We find two reasons why the marginal PSIS diagnostics can be misleading. Firstly, unlike the easy access to the unnormalized joint posterior distribution p(\u03b8, y), the true marginal posterior density p(\u03b8i|y) is typically unknown, otherwise one can conduct one-dimensional sampling easily to obtain the the marginal samples. Secondly, a smaller k\u0302i does not necessary guarantee a well-performed marginal estimation. The marginal approximations in variational inference can both over-estimate and under-estimate the tail\nthickness of one-dimensional distributions, the latter situation gives rise to a smaller k\u0302i. Section 4.3 gives an example, where the marginal approximations with extremely small marginal k have large estimation errors. This does not happen in the joint case as the direction of the Kullback-Leibler divergence q\u2217(\u03b8) strongly penalizes too-heavy tails, which makes it unlikely that the tails of the variational posterior are significantly heavier than the tails of the true posterior."}, {"heading": "3. Assessing the Average Performance of the Point Estimate", "text": "The proposed PSIS diagnostic assesses the quality of the VI approximation to the full posterior distribution. It is often observed that while the VI posterior may be a poor approximation to the full posterior, point estimates that are derived from it may still have good statistical properties. In this section, we propose a new method for assessing the calibration of the center of a VI posterior."}, {"heading": "3.1. The Variational Simulation-Based Calibration (VSBC) Diagnostic", "text": "This diagnostic is based on the proposal of Cook et al. (2006) for validating general statistical software. They noted that if \u03b8(0) \u223c p(\u03b8) and y \u223c p(y | \u03b8(0)), then\nPr(y,\u03b8(0)) ( Pr\u03b8|y(\u03b8 < \u03b8 (0)) \u2264 \u00b7) ) = Unif[0,1]([0, \u00b7]).\nTo use the observation of Cook et al. (2006) to assess the performance of a VI point estimate, we propose the following procedure. Simulate M > 1 data sets {yj}Mj=1 as follows: Simulate \u03b8(0)j \u223c p(\u03b8) and then simulate y(j) \u223c p(y | \u03b8 (0) j ), where y(j) has the same dimension as y. For each of these data sets, construct a variational approximation to p(\u03b8 | yj) and compute the marginal calibration probabilities pij = Pr\u03b8|y(j) ( \u03b8i \u2264 [\u03b8(0)j ]i ) .\nTo apply the full procedure of Cook et al. (2006), we would need to test dim(\u03b8) histograms for uniformity, however this would be too stringent a check as, like our PSIS diagnostic, this test is only passed if the variational posterior is a good approximation to the true posterior. Instead, we follow an observation of Anderson (1996) from the probabilistic forecasting validation literature and note that asymmetry in the histogram for pi: indicates bias in the variational approximation to the marginal posterior \u03b8i | y.\nThe VSBC diagnostic tests for symmetry of the marginal calibration probabilities around 0.5 and either by visual inspection of the histogram or by using a Kolmogorov-Smirnov (KS) test to evaluate whether pi: and 1\u2212 pi: have the same distribution. When \u03b8 is a high-dimensional parameter, it is important to interpret the results of any hypothesis tests\nAlgorithm 2 VSBC marginal diagnostics 1: Input: prior density p(\u03b8), data likelihood p(y | \u03b8);\nnumber of replications M ; parameter dimensions K; 2: for j = 1 : M do 3: Generate \u03b8(0)j from prior p(\u03b8);\n4: Generate a size-n dataset ( y(j) )\nfrom p(y | \u03b8(0)j ); 5: Run variational inference using dataset y(j), obtain a VI approximation distribution qj(\u00b7) 6: for i = 1 : K do 7: Label \u03b8(0)ij as the i-th marginal component of \u03b8 (0) j ;\nLabel \u03b8\u2217i as the i-th marginal component of \u03b8 \u2217;\n8: Calculate pij = Pr(\u03b8 (0) ij < \u03b8 \u2217 i | \u03b8\u2217 \u223c qj)\n9: end for 10: end for 11: for i = 1 : K do 12: Test if the distribution of {pij}Mj=1 is symmetric; 13: If rejected, the VI approximation is biased in its i-th margin. 14: end for\nthrough a multiple testing lens."}, {"heading": "3.2. Understanding the VSBC Diagnostic", "text": "Unlike the PSIS diagnostic, which focuses on a the performance of variational inference for a fixed data set y, the VSBC diagnostic assesses the average calibration of the point estimation over all datasets that could be constructed from the model. Hence, the VSBC diagnostic operates under a different paradigm to the PSIS diagnostic and we recommend using both as appropriate.\nThere are two disadvantages to this type of calibration when compared to the PSIS diagnostic. As is always the case when interpreting hypothesis tests, just because something works on average doesn\u2019t mean it will work for a particular realization of the data. The second disadvantage is that this diagnostic does not cover the case where the observed data is not well represented by the model. We suggest interpreting the diagnostic conservatively: if a variational inference scheme fails the diagnostic, then it will not perform well on the model in question. If the VI scheme passes the diagnostic, it is not guaranteed that it will perform well for real data, although if the model is well specified it should do well.\nThe VSBC diagnostic has some advantages compared to the PSIS diagnostic. It is well understood that, for complex models, the VI posterior can be used to produce a good point estimate even when it is far from the true posterior. In this case, the PSIS diagnostic will most likely indicate failure. The second advantage is that unlike the PSIS diagnostic, the VSBC diagnostic considers one-dimensional marginals \u03b8i (or any functional h(\u03b8)), which allows for a more targeted interrogation of the fitting procedure.\nWith stronger assumptions, The VSBC test can be formalized as in Proposition 2.\nProposition 2. Denote \u03b8 as a one-dimensional parameter that is of interest. Suppose in addition we have: (i) the VI approximation q is symmetric; (ii) the true posterior p(\u03b8|y) is symmetric. If the VI estimation q is unbiased, i.e., E\u03b8\u223cq(\u03b8|y) \u03b8 = E\u03b8\u223cp(\u03b8|y) \u03b8, then the distribution of VSBC p-value is symmetric. Otherwise, if the VI estimation is positively/negatively biased, then the distribution of VSBC p-value is right/left skewed.\nThe symmetry of the true posterior is a stronger assumption than is needed in practice for this result to hold. In the forecast evaluation literature, as well as the literature on posterior predictive checks, the symmetry of the histogram is a commonly used heuristic to assess the potential bias of the distribution. In our tests, we have seen the same thing occurs: the median of the variational posterior is close to the median of the true posterior when the VSBC histogram is symmetric. We suggest again that this test be interpreted conservatively: if the histogram is not symmetric, then the VI is unlikely to have produced a point estimate close to the median of the true posterior."}, {"heading": "4. Applications", "text": "Both PSIS and VSBC diagnostics are applicable to any variational inference algorithm. Without loss of generality, we implement mean-field Gaussian automatic differentiation variational inference (ADVI) in this section."}, {"heading": "4.1. Linear Regression", "text": "Consider a Bayesian linear regression y \u223c N(X\u03b2, \u03c32) with prior {\u03b2i}Ki=1 \u223c N(0, 1), \u03c3 \u223c gamma(.5, .5). We fix sample size n = 10000 and number of regressors K = 100.\nFigure 1 visualizes the VSBC diagnostic, showing the distribution of VSBC p-values of the first two regression coefficients \u03b21, \u03b22 and log \u03c3 based on M = 1000 replications. The two sided Kolmogorov-Smirnov test for p: and 1\u2212 p: is only rejected for p\u03c3:, suggesting the VI approximation is in average marginally unbiased for \u03b21 and \u03b22, while \u03c3 is overestimated as p\u03c3 is right-skewed. The under-estimation of posterior variance is reflected by the U-shaped distributions.\nUsing one randomly generated dataset in the same problem, the PSIS k\u0302 is 0.61, indicating the joint approximation is close to the true posterior. However, the performance of ADVI is sensitive to the stopping time, as in any other optimization problems. As displayed in the left panel of Figure 2, changing the threshold of relative ELBO change from a conservative 10\u22125 to the default recommendation 10\u22122 increases k\u0302 to 4.4, even though 10\u22122 works fine for many other simpler problems. In this example, we can also view k\u0302\nas a convergence test. The right panel shows k\u0302 diagnoses estimation error, which eventually become negligible in PSIS adjustment when k\u0302 < 0.7. To account for the uncertainty of stochastic optimization and k\u0302 estimation, simulations are repeated 100 times."}, {"heading": "4.2. Logistic Regression", "text": "Next we run ADVI to a logistic regression Y \u223c Bernoulli ( logit\u22121(\u03b2X) ) with a flat prior on \u03b2. We generate X = (x1, . . . , xn) from N(0, (1\u2212 \u03c1)IK\u00d7K + \u03c11K\u00d7K) such that the correlation in design matrix is \u03c1, and \u03c1 is changed from 0 to 0.99. The first panel in Figure 3 shows PSIS k\u0302 increases as the design matrix correlation increases. It is not monotonic because \u03b2 is initially negatively correlated when X is independent. A large \u03c1 transforms into a large correlation for posterior distributions in \u03b2, making it harder to be approximated by a mean-field family, as can be diagnosed by k\u0302. In panel 2 we calculate mean log predictive density (lpd) of VI approximation and true posterior using 200 independent test sets. Larger \u03c1 leads to worse mean-field approximation, while prediction becomes easier. Consequently, monitoring lpd does not diagnose the VI behavior; it increases (misleadingly suggesting better fit) as \u03c1 increases. In this special case, VI has larger lpd than the true posterior, due to the VI under-dispersion and the model misspecification. Indeed, if viewing lpd as a function h(\u03b2), it is the discrepancy between VI lpd and true lpd that reveals the VI performance, which can also be diagnosed by k\u0302. Panel 3 shows a sharp increase of lpd discrepancy around k\u0302 = 0.7, consistent with the empirical threshold we suggest.\nFigure 4 compares the first and second moment root mean square errors (RMSE) ||Ep\u03b2 \u2212 Eq\u2217\u03b2||2 and ||Ep\u03b22 \u2212 Eq\u2217\u03b2\n2||2 in the previous example using three estimates: (a) VI without post-adjustment, (b) VI adjusted by vanilla importance sampling, and (c) VI adjusted by PSIS.\nPSIS diagnostic accomplishes two tasks here: (1) A small k\u0302 indicates that VI approximation is reliable. When k\u0302 > 0.7, all estimations are no longer reasonable so the user should be alerted. (2) It further improves the approximation using PSIS adjustment, leading to a quicker convergence rate and smaller mean square errors for both first and second moment estimation. Plain importance sampling has larger RMSE for it suffers from a larger variance."}, {"heading": "4.3. Re-parametrization in a Hierarchical Model", "text": "The Eight-School Model (Gelman et al., 2013, Section 5.5) is the simplest Bayesian hierarchical normal model. Each school reported the treatment effect mean yi and standard deviation \u03c3i separately. There was no prior reason to believe that any of the treatments were more effective than any other, so we model them as independent experiments:\nyj |\u03b8j \u223c N(\u03b8j , \u03c32j ), \u03b8j |\u00b5, \u03c4 \u223c N(\u00b5, \u03c42), 1 \u2264 j \u2264 8, \u00b5 \u223c N(0, 5), \u03c4 \u223c half\u2212Cauchy(0, 5).\nwhere \u03b8j represents the treatment effect in school j, and \u00b5 and \u03c4 are the hyper-parameters shared across all schools.\nIn this hierarchical model, the conditional variance of \u03b8 is strongly dependent on the standard deviation \u03c4 , as shown by the joint sample of \u00b5 and log \u03c4 in the bottom-left corner in Figure 5. The Gaussian assumption in ADVI cannot capture such structure. More interestingly, ADVI over-estimates the posterior variance for all parameters \u03b81 through \u03b88, as shown by positive biases of their posterior standard deviation in the last panel. In fact, the posterior mode is at \u03c4 = 0, while the entropy penalization keeps VI estimation away from it, leading to an overestimation due to the funnel-shape. Since the conditional expectation E[\u03b8i|\u03c4, y, \u03c3] = ( \u03c3\u22122j + \u03c4\n\u22122)\u22121 is an increasing function on \u03c4 , a positive bias of \u03c4 produces over-dispersion of \u03b8.\nThe top left panel shows the marginal and joint PSIS diagnostics. The joint k\u0302 is 1.00, much beyond the threshold, while the marginal k\u0302 calculated through the true marginal distribution for all \u03b8 are misleadingly small due to the overdispersion.\nAlerted by such large k\u0302, researchers should seek some improvements, such as re-parametrization. The non-centered parametrization extracts the dependency between \u03b8 and \u03c4 through a transformation \u03b8\u2217 = (\u03b8 \u2212 \u00b5)/\u03c4 :\nyj |\u03b8j \u223c N(\u00b5+ \u03c4\u03b8\u2217j , \u03c32j ), \u03b8\u2217j \u223c N(0, 1).\nThere is no general rule to determine whether non-centered parametrization is better than the centered one and there are many other parametrization forms. Finding the optimal parametrization can be as hard as finding the true posterior, but k\u0302 diagnostics always guide the choice of parametriza-\ntion. As shown by the top right panel in Figure 5, the joint k\u0302 for the non-centered ADVI decreases to 0.64 which indicated the approximation is not perfect but reasonable and usable. The bottom-right panel demonstrates that the reparametrized ADVI posterior is much closer to the truth, and has smaller biases for both first and second moment estimations.\nWe can assess the marginal estimation using VSBC diagnostic, as summarized in Figure 6. In the centered parametrization, the point estimation for \u03b81 is in average unbiased, as the two-sided KS-test is not rejected. The histogram for \u03c4 is right-skewed, for we can reject one-sided KS-test with the alternative to be p\u03c4 : being stochastically smaller than p\u03c4 :. Hence we conclude \u03c4 is over-estimated in the centered parameterization. On the contrast, the non-centered \u03c4 is negatively biased, as diagnosed by the left-skewness of p\u03c4 :. Such conclusion is consistent with the bottom-right panel in Figure 5.\nTo sum up, this example illustrates how the Gaussian family assumption can be unrealistic even for a simple hierarchical model. It also clarifies VI posteriors can be both over-dispersed and under-dispersed, depending crucially on the true parameter dependencies. Nevertheless, the recommended PSIS and VSBC diagnostics provide a practical summary of the computation result."}, {"heading": "4.4. Cancer Classification Using Horseshoe Priors", "text": "We illustrate how the proposed diagnostic methods work in the Leukemia microarray cancer dataset that contains D = 7129 features and n = 72 observations. Denote y1:n as binary outcome and Xn\u00d7D as the predictor, the logistic regression with a regularized horseshoe prior (Piironen & Vehtari, 2017) is given by y|\u03b2 \u223c Bernoulli ( logit\u22121 (X\u03b2) ) , \u03b2j |\u03c4, \u03bb, c \u223c N(0, \u03c42\u03bb\u03032j ), \u03bbj \u223c C+(0, 1), \u03c4 \u223c C+(0, \u03c40), c2 \u223c Inv\u2212Gamma(2, 8).\nwhere \u03c4 > 0 and \u03bb > 0 are global and local shrinkage parameters, and \u03bb\u03032j = c 2\u03bb2j/ ( c2 + \u03c42\u03bb2j ) . The regularized\nhorseshoe prior adapts to the sparsity and allows us to specify a minimum level of regularization to the largest values.\nADVI is computationally appealing for it only takes a few minutes while MCMC sampling takes hours on this dataset. However, PSIS diagnostic gives k\u0302 = 9.8 for ADVI, suggesting the VI approximation is not even close to the true posterior. Figure 7 compares the ADVI and true posterior density of \u03b21834, log \u03bb1834 and \u03c4 . The Gaussian assumption makes it impossible to recover the bimodal distribution of some \u03b2.\nThe VSBC diagnostics as shown in Figure 8 tell the negative bias of local shrinkage \u03bb1834 from the left-skewness of plog \u03bb1834 , which is the consequence of the right-missing mode. For compensation, the global shrinkage \u03c4 is overestimated, which is in agreement with the right-skewness of plog \u03c4 . \u03b21834 is in average unbiased, even though it is strongly underestimated from in Figure 7. This is because VI estimation is mostly a spike at 0 and its prior is symmetric. As we have explained, passing the VSBC test means the average unbiasedness, and does not ensure the unbiasedness for a specific parameter setting. This is the price that VSBC pays for averaging over all priors."}, {"heading": "5. Discussion", "text": ""}, {"heading": "5.1. The Proposed Diagnostics are Local", "text": "As no single diagnostic method can tell all problems, the proposed diagnostic methods have limitations. The PSIS diagnostic is limited when the posterior is multimodal as the samples drawn from q(\u03b8) may not cover all the modes of the posterior and the estimation of k will be indifferent to the unseen modes. In this sense, the PSIS diagnostic is\na local diagnostic that will not detect unseen modes. For example, imagine the true posterior is p = 0.8N(0, 0.2) + 0.2N(3, 0.2) with two isolated modes. Gaussian family VI will converge to one of the modes, with the importance ratio to be a constant number 0.8 or 0.2. Therefore k is 0, failing to penalize the missing density. In fact, any divergence measure based on samples from the approximation such as KL(q, p) is local.\nThe bi-modality can be detected by multiple over-dispersed initialization. It can also be diagnosed by other divergence measures such as KL(p, q) = Ep log(q/p), which is computable through PSIS by letting h = log(q/p).\nIn practice a marginal missing mode will typically lead to large joint discrepancy that is still detectable by k\u0302, such as in Section 4.4.\nThe VSBC test, however, samples the true parameter from the prior distribution directly. Unless the prior is too restrictive, the VSBC p-value will diagnose the potential missing mode."}, {"heading": "5.2. Tailoring Variational Inference for Importance Sampling", "text": "The PSIS diagnostic makes use of stabilized IS to diagnose VI. By contrast, can we modify VI to give a better IS proposal?\nGeweke (1989) introduce an optimal proposal distribution based on split-normal and split-t, implicitly minimizing the \u03c72 divergence between q and p. Following this idea, we could first find the usual VI solution, and then switch Gaussian to Student-t with a scale chosen to minimize the \u03c72 divergence.\nMore recently, some progress is made to carry out variational inference based on Re\u0301nyi divergence (Li & Turner, 2016; Dieng et al., 2017). But a big \u03b1, say \u03b1 = 2, is only meaningful when the proposal has a much heavier tail than the target. For example, a normal family does not contain any member having finite \u03c72 divergence to a Student-t distribution, leaving the optimal objective function defined by Dieng et al. (2017) infinitely large.\nThere are several research directions. First, our proposed diagnostics are applicable to these modified approximation methods. Second, PSIS re-weighting will give a more reliable importance ratio estimation in the Re\u0301nyi divergence variational inference. Third, a continuous k\u0302 and the corresponding \u03b1 are more desirable than only fixing \u03b1 = 2, as the latter one does not necessarily have a finite result. Considering the role k\u0302 plays in the importance sampling, we can optimize the discrepancy D\u03b1(q||p) and \u03b1 > 0 simultaneously. We leave this for future research."}, {"heading": "Acknowledgements", "text": "The authors acknowledge support from the Office of Naval Research grants N00014-15-1-2541 and N00014-16-P-2039, the National Science Foundation grant CNS-1730414, and the Academy of Finland grant 313122."}], "year": 2018, "references": [{"title": "A method for producing and evaluating probabilistic forecasts from ensemble model integrations", "authors": ["J.L. Anderson"], "venue": "Journal of Climate,", "year": 1996}, {"title": "Variational inference: A review for statisticians", "authors": ["D.M. Blei", "A. Kucukelbir", "J.D. McAuliffe"], "venue": "Journal of the American Statistical Association,", "year": 2017}, {"title": "Convergence diagnostics for stochastic gradient descent with constant step size", "authors": ["J. Chee", "P. Toulis"], "venue": "arXiv preprint arXiv:1710.06382,", "year": 2017}, {"title": "Normal approximation under local dependence", "authors": ["L.H. Chen", "Shao", "Q.-M"], "venue": "The Annals of Probability,", "year": 1985}, {"title": "Validation of software for Bayesian models using posterior quantiles", "authors": ["S.R. Cook", "A. Gelman", "D.B. Rubin"], "venue": "Journal of Computational and Graphical Statistics,", "year": 2006}, {"title": "Learning bounds for importance weighting", "authors": ["C. Cortes", "Y. Mansour", "M. Mohri"], "venue": "In Advances in neural information processing systems,", "year": 2010}, {"title": "Relative deviation learning bounds and generalization with unbounded loss functions", "authors": ["C. Cortes", "S. Greenberg", "M. Mohri"], "venue": "arXiv preprint arXiv:1310.5796,", "year": 2013}, {"title": "Variational inference via chi upper bound minimization", "authors": ["A.B. Dieng", "D. Tran", "R. Ranganath", "J. Paisley", "D. Blei"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2017}, {"title": "Casedeletion importance sampling estimators: Central limit theorems and related results", "authors": ["I. Epifani", "S.N. MacEachern", "M Peruggia"], "venue": "Electronic Journal of Statistics,", "year": 2008}, {"title": "Bayesian data analysis", "authors": ["A. Gelman", "J.B. Carlin", "H.S. Stern", "D.B. Dunson", "A. Vehtari", "D.B. Rubin"], "venue": "CRC press,", "year": 2013}, {"title": "Bayesian inference in econometric models using Monte Carlo", "authors": ["J. Geweke"], "venue": "integration. Econometrica,", "year": 1989}, {"title": "Covariances, robustness, and variational Bayes", "authors": ["R. Giordano", "T. Broderick", "M.I. Jordan"], "venue": "arXiv preprint arXiv:1709.02536,", "year": 2017}, {"title": "Stochastic variational inference", "authors": ["M.D. Hoffman", "D.M. Blei", "C. Wang", "J. Paisley"], "venue": "The Journal of Machine Learning Research,", "year": 2013}, {"title": "Truncated importance sampling", "authors": ["E.L. Ionides"], "venue": "Journal of Computational and Graphical Statistics,", "year": 2008}, {"title": "Testing the assumptions behind importance sampling", "authors": ["S.J. Koopman", "N. Shephard", "D. Creal"], "venue": "Journal of Econometrics,", "year": 2009}, {"title": "Automatic differentiation variational inference", "authors": ["A. Kucukelbir", "D. Tran", "R. Ranganath", "A. Gelman", "D.M. Blei"], "venue": "Journal of Machine Learning Research,", "year": 2017}, {"title": "R\u00e9nyi divergence variational inference", "authors": ["Y. Li", "R.E. Turner"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2016}, {"title": "Non-asymptotic confidence bounds for stochastic approximation algorithms with constant step size", "authors": ["G.C. Pflug"], "venue": "Monatshefte fu\u0308r Mathematik,", "year": 1990}, {"title": "Sparsity information and regularization in the horseshoe and other shrinkage priors", "authors": ["J. Piironen", "A. Vehtari"], "venue": "Electronic Journal of Statistics,", "year": 2017}, {"title": "Black box variational inference", "authors": ["R. Ranganath", "S. Gerrish", "D. Blei"], "venue": "In Artificial Intelligence and Statistics,", "year": 2014}, {"title": "On measures of entropy and information", "authors": ["A R\u00e9nyi"], "venue": "In Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Contributions to the Theory of Statistics. The Regents of the University of California,", "year": 1961}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "authors": ["D.J. Rezende", "S. Mohamed", "D. Wierstra"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "year": 2014}, {"title": "Stopping times for stochastic approximation procedures", "authors": ["R.L. Sielken"], "venue": "Probability Theory and Related Fields,", "year": 1973}, {"title": "On a new stopping rule for stochastic approximation", "authors": ["D.F. Stroup", "H.I. Braun"], "venue": "Probability Theory and Related Fields,", "year": 1982}, {"title": "A stopping rule for stochastic approximation", "authors": ["T. Wada", "Y. Fujisaki"], "venue": "Automatica, 60:1\u20136,", "year": 2015}], "id": "SP:5a4164125c8c9f6205bdd663624157e46c27d4f6", "authors": [{"name": "Yuling Yao", "affiliations": []}, {"name": "Aki Vehtari", "affiliations": []}, {"name": "Daniel Simpson", "affiliations": []}, {"name": "Andrew Gelman", "affiliations": []}], "abstractText": "While it\u2019s always possible to compute a variational approximation to a posterior distribution, it can be difficult to discover problems with this approximation. We propose two diagnostic algorithms to alleviate this problem. The Paretosmoothed importance sampling (PSIS) diagnostic gives a goodness of fit measurement for joint distributions, while simultaneously improving the error in the estimate. The variational simulationbased calibration (VSBC) assesses the average performance of point estimates.", "title": "Yes, but Did It Work?: Evaluating Variational Inference"}
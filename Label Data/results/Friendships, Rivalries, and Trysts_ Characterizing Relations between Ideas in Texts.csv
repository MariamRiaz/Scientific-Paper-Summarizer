0,1,label2,summary_sentences
"Recently, deep learning has emerged as a powerful and popular class of machine learning algorithms.",1. Introduction,[0],[0]
"Well-known examples include the convolutional neural network (LeCun et al., 1998), long short term memory (Hochreiter & Schmidhuber, 1997), memory network (Weston et al., 2014), and deep Q-network (Mnih et al., 2015).",1. Introduction,[0],[0]
"These models have achieved remarkable performance on various difficult tasks such as image classification (He et al., 2016), speech recognition (Graves et al., 2013), natural language understanding (Bahdanau et al., 2015; Sukhbaatar et al., 2015), and game playing (Silver et al., 2016).
",1. Introduction,[0],[0]
"Deep network is a highly nonlinear model with typically millions of parameters (Hinton et al., 2006).",1. Introduction,[0],[0]
"Thus, it is imperative to design scalable and effective solvers.",1. Introduction,[0],[0]
"How-
",1. Introduction,[0],[0]
"1Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong.",1. Introduction,[0],[0]
"Correspondence to: Shuai Zheng <szhengac@cse.ust.hk>, James T. Kwok <jamesk@cse.ust.hk>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
ever, training deep networks is difficult as the optimization can suffer from pathological curvature and get stuck in local minima (Martens, 2010).",1. Introduction,[0],[0]
"Moreover, every critical point that is not a global minimum is a saddle point (Kawaguchi, 2016), which can significantly slow down training.",1. Introduction,[0],[0]
Second-order information is useful in that it reflects local curvature of the error surface.,1. Introduction,[0],[0]
"However, a direct computation of the Hessian is computationally infeasible.",1. Introduction,[0],[0]
"Martens (2010) introduced Hessian-free optimization, a variant of truncated-Newton methods that relies on using the linear conjugate gradient to avoid computing the Hessian.",1. Introduction,[0],[0]
Dauphin et al. (2014) proposed to use the absolute Hessian to escape from saddle points.,1. Introduction,[0],[0]
"However, these methods still require higher computational costs.
",1. Introduction,[0],[0]
"Recent advances in deep learning optimization focus mainly on stochastic gradient descent (SGD) (Bottou, 1998) and its variants (Sutskever et al., 2013).",1. Introduction,[0],[0]
"However, SGD requires careful stepsize tuning, which is difficult as different weights have vastly different gradients (in terms of both magnitude and direction).",1. Introduction,[0],[0]
"On the other hand, online learning (Zinkevich, 2003), which is closely related to stochastic optimization, has been extensively studied in the past decade.",1. Introduction,[0],[0]
"Well-known algorithms include follow the regularized leader (FTRL) (Kalai & Vempala, 2005), follow the proximally-regularized leader (FTPRL) (McMahan & Streeter, 2010) and their variants (Duchi & Singer, 2009; Duchi et al., 2011; Shalev-Shwartz, 2012; Xiao, 2010).",1. Introduction,[0],[0]
"In particular, adaptive gradient descent (Adagrad) (Duchi et al., 2011) uses an adaptive per-coordinate stepsize.",1. Introduction,[0],[0]
"On convex problems, it has been shown both theoretically and empirically that Adagrad is especially efficient on highdimensional data (Duchi et al., 2011; McMahan et al., 2013).",1. Introduction,[0],[0]
"When used on deep networks, Adagrad also demonstrates significantly better performance than SGD (Dean et al., 2012).",1. Introduction,[0],[0]
"However, in Adagrad, the variance estimate underlying the adaptive stepsize is based on accumulating all past (squared) gradients.",1. Introduction,[0],[0]
This becomes infinitesimally small as training proceeds.,1. Introduction,[0],[0]
"In more recent algorithms, such as RMSprop (Tieleman & Hinton, 2012) and Adam (Kingma & Ba, 2015), the variance is estimated by an exponentially decaying average of the squared gradients.
",1. Introduction,[0],[0]
"Another problem with the FTRL family of algorithms is that in each round, the learner has to solve an optimization problem that considers the sum of all previous gradients.
",1. Introduction,[0],[0]
"For highly nonconvex models such as the deep network, the parameter iterate may move from one local basin to another.",1. Introduction,[0],[0]
Gradients that are due to samples in the distant past are less informative than those from the recent ones.,1. Introduction,[0],[0]
"In applications where the data distribution is changing (as in deep reinforcement learning), this may impede parameter adaptation to the environment.
",1. Introduction,[0],[0]
"To alleviate this problem, we propose a FTPRL variant that reweighs the learning subproblems in each iteration.",1. Introduction,[0],[0]
"The proposed algorithm, which will be called follow the moving leader (FTML), shows strong connections with popular deep learning optimizers such as RMSprop and Adam.",1. Introduction,[0],[0]
"Experiments on various deep learning models demonstrate that FTML outperforms or at least has comparable convergence performance with state-of-the-art solvers.
",1. Introduction,[0],[0]
The rest of this paper is organized as follows.,1. Introduction,[0],[0]
Section 2 first gives a brief review on FTRL and other solvers for deep learning.,1. Introduction,[0],[0]
Section 3 presents the proposed FTML.,1. Introduction,[0],[0]
"Experimental results are shown in Section 4, and the last section gives some concluding remarks.
Notation.",1. Introduction,[0],[0]
"For a vector x ∈ Rd, ‖x‖ = √∑d
i=1",1. Introduction,[0],[0]
"x 2 i ,
diag(x) is a diagonal matrix with x on its diagonal, √ x is the element-wise square root of x, x2 denotes the Hadamard (elementwise) product x x, and ‖x‖2Q = xTQx, whereQ is a symmetric matrix.",1. Introduction,[0],[0]
"For any two vectors x and y, x/y, and 〈x, y〉 denote the elementwise division and dot product, respectively.",1. Introduction,[0],[0]
"For a matrix X , X2 = XX , and diag(X) is a vector with the diagonal of X as its elements.",1. Introduction,[0],[0]
"For t vectors {x1, . . .",1. Introduction,[0],[0]
", xt}, x1:",1. Introduction,[0],[0]
t = ∑t i=1,1. Introduction,[0],[0]
"xi, and
x21:",1. Introduction,[0],[0]
t = ∑t i=1,1. Introduction,[0],[0]
"x
2 i .",1. Introduction,[0],[0]
"For t matrices {X1, . . .",1. Introduction,[0],[0]
", Xt}, X1:t =∑t
i=1Xi.",1. Introduction,[0],[0]
"In online learning, the learner observes a sequence of functions fi’s, which can be deterministic, stochastic, or even adversarially chosen.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
Let Θ ⊆ Rd be a convex compact set.,2.1. Follow the Regularized Leader and its Variants,[0],[0]
"At round t, the learner picks a predictor θt−1 ∈ Θ, and the adversary picks a loss ft.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
The learner then suffers a loss ft(θt−1).,2.1. Follow the Regularized Leader and its Variants,[0],[0]
The goal of the learner is to minimize the cumulative loss suffered over the course of T rounds.,2.1. Follow the Regularized Leader and its Variants,[0],[0]
"In online convex learning, ft is assumed to be convex.
",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"Two popular online learning algorithms are the follow the regularized leader (FTRL) (Kalai & Vempala, 2005; Shalev-Shwartz, 2012), and its variant follow the proximally-regularized leader (FTPRL) (McMahan & Streeter, 2010).",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"Both achieve the optimal O( √ T ) regret, where T is the number of rounds (Shalev-Shwartz, 2012).",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"Other FTRL-like algorithms include regularized dual aver-
aging (RDA) (Xiao, 2010) as well as its adaptive variant presented in (Duchi et al., 2011).",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"Gradient descent style algorithms like online forward and backward splitting (FOBOS) (Duchi & Singer, 2009) and adaptive gradient descent (Adagrad) (Duchi et al., 2011) can also be expressed as special cases of the FTRL family (McMahan, 2011).
",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"At round t, FTRL generates the next iterate θt by solving the optimization problem:
θt = arg min θ∈Θ t∑ i=1",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"( 〈gi, θ〉+ αt 2 ‖θ‖2 ) ,
where gt is a subgradient of ft at θt−1 (usually, θ0 = 0), and αt is the regularization parameter at round t. Note that the regularization is centered at the origin.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"McMahan & Streeter (2010) generalizes this to FTPRL by centering regularization at each iterate θi−1 as in online gradient descent and online mirror descent (Cesa-Bianchi & Lugosi, 2006),
θt = arg min θ∈Θ t∑ i=1",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"( 〈gi, θ〉+ 1 2 ‖θ − θi−1‖2Qi ) , (1)
where Qi is a full or diagonal positive semidefinite matrix, and ‖θ",2.1. Follow the Regularized Leader and its Variants,[0],[0]
− θi−1‖Qi is the corresponding Mahalanobis distance between θ and θi−1.,2.1. Follow the Regularized Leader and its Variants,[0],[0]
"When Qi is diagonal, each of its entries controls the learning rate in the corresponding dimension.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"When Θ = Rd, θt can be obtained in closedform (McMahan, 2011):
θt = θt−1 −Q−11:t gt.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"(2)
",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"When
Qt = 1
η diag
(√ g21:t − √ g21:t−1 ) , (3)
where η > 0 is the stepsize, (2) becomes the update rule of Adagrad (Duchi et al., 2011)
θt = θt−1 − diag
( η√
g21:t + 1
) gt.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"(4)
Here, > 0 (usually a very small number) is used to avoid division by zero, and 1 is the vector of all 1’s.
",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"In general, all these algorithms satisfy (McMahan & Streeter, 2010):
Q1:t = diag ( 1
η
(√ g21:t + 1 )) .",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"(5)
It can be shown that this setting is optimal within a factor of √ 2 of the best possible regret bound for any nonincreasing per-coordinate learning rate schedule (McMahan & Streeter, 2010).",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"In training deep networks, different weights may have vastly different gradients (in terms of both magnitude and direction).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Hence, using a per-coordinate learning rate as in Adagrad can significantly improve performance over standard SGD (Dean et al., 2012).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"However, a caveat is that Adagrad suffers from diminishing stepsize.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"As optimization proceeds, the accumulated squared gradient g21:t in (5) becomes larger and larger, making training difficult.
",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"To alleviate this problem, a number of algorithms have been proposed (Zeiler, 2012; Tieleman & Hinton, 2012; Kingma & Ba, 2015).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Typically, they employ an average of the past squared gradients (i.e., vt = ∑t i=1",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"αi,tg 2",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"i , where αi,t ∈",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"[0, 1]), which is exponentially decaying.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"For example, RMSprop (Tieleman & Hinton, 2012) uses
vi = βvi−1 + (1− β)g2i , (6)
where β is close to 1, and the corresponding αi,t is (1 − β)βt−i.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"This vt can then be used to replace g21:t, and the update in (4) becomes
θt = θt−1 − diag (
η √ vt + 1
) gt.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"(7)
Zeiler (2012) further argues that the parameter and update should have the same unit, and modifies (7) to the Adadelta update rule:
θt = θt−1 − diag (√
ut−1 + 1√ vt + 1
) gt,
where ut−1 = ∑t−1 i=0 αi,t−1(4θi)2, and 4θt = θt − θt−1 with4θ0 = 0.
",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"As v0 in (6) is often initialized to 0, the bias has to be corrected.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Adam (Kingma & Ba, 2015) uses the variance estimate vt/(1 − βt) (which corresponds to αi,t = (1− β)βt−i/(1− βt)).
",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Another recent proposal is the equilibrated stochastic gradient descent (Dauphin et al., 2015).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"It uses the variance estimate vt = vt−1 +(Htζt)2, whereHt is the Hessian and ζt ∼ N (0, 1).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"It is shown that (Htζt)2 is an unbiased estimator of √ diag(H2t ), which serves as the Jacobi preconditioner of the absolute Hessian.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Computation of the Hessian can be avoided by using the R-operator (Schraudolph, 2002), though it still costs roughly twice that of standard backpropagation.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Recall that at round t, FTRL generates the next iterate θt as
θt = arg min θ∈Θ t∑ i=1",3. Follow the Moving Leader,[0],[0]
"Pi(θ), (8)
where Pi(θ) = 〈gi, θ〉 + 12‖θ",3. Follow the Moving Leader,[0],[0]
− θi−1‖ 2 Qi .,3. Follow the Moving Leader,[0],[0]
Note that all Pi’s have the same weight.,3. Follow the Moving Leader,[0],[0]
"However, for highly nonconvex models such as the deep network, the parameter iterate may move from one local basin to another.",3. Follow the Moving Leader,[0],[0]
Pi’s that are due to samples in the distant past are less informative than those from the recent ones.,3. Follow the Moving Leader,[0],[0]
"To alleviate this problem, one may consider only Pi’s in a recent window.",3.1. Weighting the Components,[0],[0]
"However, a large memory is needed for its implementation.",3.1. Weighting the Components,[0],[0]
"A simpler alternative is by using an exponential moving average of the Pi’s: Si = β1Si−1 + (1 − β1)Pi, where β1 ∈",3.1. Weighting the Components,[0],[0]
"[0, 1) and S0 = 0.",3.1. Weighting the Components,[0],[0]
This can be easily rewritten as St = (1− β1) ∑t i=1,3.1. Weighting the Components,[0],[0]
β t−i 1 Pi.,3.1. Weighting the Components,[0],[0]
"Instead of minimizing (8), we have
θt = arg min θ∈Θ t∑ i=1",3.1. Weighting the Components,[0],[0]
"wi,tPi(θ), (9)
where the weights
wi,t = (1− β1)βt−i1
1− βt1 (10)
are normalized to sum to 1.",3.1. Weighting the Components,[0],[0]
The denominator 1− βt1 plays a similar role as bias correction in Adam.,3.1. Weighting the Components,[0],[0]
"When β1 = 0, wi,t = 0 for i < t, and wt,t = 1.",3.1. Weighting the Components,[0],[0]
"Thus, (9) reduces to minθ∈Θ Pt(θ).",3.1. Weighting the Components,[0],[0]
"When β1 → 1, the following Lemma shows that all Pi’s are weighted equally, and (8) is recovered.",3.1. Weighting the Components,[0],[0]
Lemma 1.,3.1. Weighting the Components,[0],[0]
"limβ1→1 wi,t = 1/t.
Note that the Hessian of the objective in (8) is Q1:t. This becomes ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi in (9).",3.1. Weighting the Components,[0],[0]
"Recall that Q1:t depends on the accumulated past gradients in (5), which is then refined by an exponential moving average in (6).",3.1. Weighting the Components,[0],[0]
"As in Adam, we define vi = β2vi−1 + (1 − β2)g2i , where β2 ∈",3.1. Weighting the Components,[0],[0]
"[0, 1) and v0 = 0, and then correct its bias by dividing by 1 − βt2.",3.1. Weighting the Components,[0],[0]
"Thus, (5) is changed to
t∑ i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi = diag ( 1 ηt (√ vt 1− βt2 + t1 )) , (11)
where ηt and t are the stepsize and value at time t, respectively.",3.1. Weighting the Components,[0],[0]
"When β2 = 0, (11) reduces to ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi =
diag (
1 ηt ( √ g2t + t1) ) .",3.1. Weighting the Components,[0],[0]
"When β2 → 1, all g2i ’s are
weighted equally and (11) reduces to ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi =
diag (
1 ηt (√ g21:",3.1. Weighting the Components,[0],[0]
t t + t1 )) .,3.1. Weighting the Components,[0],[0]
"Using ηt = η/ √ t and t =
/ √ t, this is further reduced to (5).",3.1. Weighting the Components,[0],[0]
"The following shows
that Qt in (11) has a closed-form expression.
",3.1. Weighting the Components,[0],[0]
Proposition 1.,3.1. Weighting the Components,[0],[0]
"Define dt = 1−βt1 ηt
(√ vt
1−βt2 + t1
) .",3.1. Weighting the Components,[0],[0]
"Then,
Qt = diag ( dt − β1dt−1
1− β1
) .",3.1. Weighting the Components,[0],[0]
"(12)
Algorithm 1 Follow the Moving Leader (FTML).",3.1. Weighting the Components,[0],[0]
"1: Input: ηt > 0, β1, β2 ∈",3.1. Weighting the Components,[0],[0]
"[0, 1), t > 0. 2: initialize θ0 ∈ Θ; d0 ← 0; v0 ← 0; z0 ← 0; 3: for t = 1, 2, . . .",3.1. Weighting the Components,[0],[0]
", T do 4: fetch function ft; 5: gt ← ∂θft(θt−1); 6: vt ← β2vt−1",3.1. Weighting the Components,[0],[0]
"+ (1− β2)g2t ;
7: dt ← 1−β t 1
ηt
(√ vt
1−βt2 + t1
) ;
8: σt ← dt − β1dt−1; 9: zt ← β1zt−1 + (1− β1)gt − σtθt−1;
10: θt ← Π diag(dt/(1−βt1))",3.1. Weighting the Components,[0],[0]
"Θ (−zt/dt); 11: end for 12: Output: θT .
",3.1. Weighting the Components,[0],[0]
"Substituting this back into (9), θt is then equal to
arg min θ∈Θ t∑ i=1",3.1. Weighting the Components,[0],[0]
"wi,t ( 〈gi, θ〉+ 1 2 ‖θ",3.1. Weighting the Components,[0],[0]
"− θi−1‖2diag ( σi 1−β1 )) , (13) where σi ≡",3.1. Weighting the Components,[0],[0]
di − β1di−1.,3.1. Weighting the Components,[0],[0]
"Note that some entries of σi may be negative, and ‖θ− θi−1‖2diag(σi/(1−β1)) is then not a regularizer in the usual sense.",3.1. Weighting the Components,[0],[0]
"Instead, the negative entries of σi encourage the corresponding entries of θ to move away from those of θi−1.",3.1. Weighting the Components,[0],[0]
"Nevertheless, from the definitions of dt, σt and (11), we have ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tdiag(σi/(1 − β1))",3.1. Weighting the Components,[0],[0]
"=∑t
i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi = diag(dt/(1−βt1)), and thus the following: Lemma 2. ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tdiag(σi/(1− β1)) 0.
",3.1. Weighting the Components,[0],[0]
"Hence, the objective in (13) is still strongly convex.",3.1. Weighting the Components,[0],[0]
"Moreover, the following Proposition shows that θt in (13) has a simple closed-form solution.
",3.1. Weighting the Components,[0],[0]
Proposition 2.,3.1. Weighting the Components,[0],[0]
"In (13),
θt = Π diag(dt/(1−βt1))",3.1. Weighting the Components,[0],[0]
"Θ (−zt/dt),
where zt = β1zt−1 + (1 − β1)gt − σtθt−1, and ΠAΘ(x) ≡ arg minu∈Θ 1 2‖u−x‖ 2",3.1. Weighting the Components,[0],[0]
"A is the projection onto Θ for a given positive semidefinite matrix A.
The proposed procedure, which will be called follow the moving leader (FTML), is shown in Algorithm 1.",3.1. Weighting the Components,[0],[0]
"Note that though {P1, . . .",3.1. Weighting the Components,[0],[0]
", Pt} are considered in each round, the update depends only the current gradient gt and parameter θt−1.",3.1. Weighting the Components,[0],[0]
"It can be easily seen that FTML is easy to implement, memory-efficient and has low per-iteration complexity.",3.1. Weighting the Components,[0],[0]
"The following Propositions show that we can recover Adagrad in two extreme cases: (i) β1 = 0 with decreasing stepsize; and (ii) β1 → 1 with increasing stepsize.
",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
Proposition 3.,3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"With β1 = 0, β2 → 1, ηt = η/ √ t, and
t = / √ t, θt in (13) reduces to:
Π diag(( √ g21:t+ 1)/η)
",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"Θ
( θt−1 − diag ( η√
g21:t + 1
) gt ) ,
which recovers Adagrad in (4).",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
Proposition 4.,3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"With β1 → 1, β2 → 1, ηt = η √ t, and
t = / √ t, we recover (1) with Qi in (3).",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"If Θ = Rd, it
generates identical updates as Adagrad in (4).",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"When Θ = Rd, McMahan (2011) showed that (1) and (2) generate the same updates.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
The following Theorem shows that FTML also has a similar gradient descent update.,3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
Theorem 1.,3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"With Θ = Rd, FTML generates the same updates as:
θt = θt−1 − diag ( 1− β1 1− βt1 ηt√ vt/(1− βt2) + t1 ) gt.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"(14)
When β1 = 0 and bias correction for the variance is not used, (14) reduces to RMSprop in (7).",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"However, recall from Section 3.1 that when β1 = 0, we have wi,t = 0 for i < t, and wt,t = 1.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"Hence, only the current loss component Pt is taken into account, and this may be sensitive to the noise in Pt.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"Moreover, as demonstrated in Adam, bias correction of the variance can be very important.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"When β2 → 1, the variance estimate of RMSprop,∑t i=1(1−β2)β t−i 2 g 2 i , becomes zero and blows up the stepsize, leading to divergence.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"In contrast, FTML’s Qi in (12) recovers that of Adagrad in this case (Proposition 4).",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"In practice, a smaller β2 has to be used for RMSprop.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"However, a larger β2 enables the algorithm to be more robust to the gradient noise in general.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"At iteration t, instead of centering regularization at each θi−1 in (13), consider centering all the proximal regularization terms at the last iterate θt−1. θt then becomes:
arg min θ∈Θ t∑ i=1",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"wi,t ( 〈gi, θ〉+ 1 2 ‖θ − θt−1‖2diag ( σi 1−β1 )) .",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"(15) Compared with (13), the regularization in (15) is more aggressive as it encourages θt to be close only to the last iterate θt−1.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
The following Proposition shows that (15) generates the same updates as Adam.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
Proposition 5.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"In (15),
θt = Π At Θ ( θt−1 −A−1t t∑ i=1",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"wi,tgi ) , (16)
where At = diag(( √ vt/(1− βt2) + t1)/ηt).
",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"As in Adam, ∑t i=1",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"wi,tgi in (16) can be obtained as mt/(1−βt1), wheremt is computed as an exponential moving average of gt’s: mt = β1mt−1 +",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"(1− β1)gt.
Note that the θt updates of Adagrad (4), RMSprop (7), and FTML (14) depend only on the current gradient gt.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"On the other hand, the Adam update in (16) involves ∑t i=1",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"wi,tgi, which contains all the past gradients (evaluated at past parameter estimates θi−1’s).",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"This is similar to the use of momentum, which is sometimes helpful in escaping from local minimum.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"However, when the data distribution is changing (as in deep reinforcement learning), the past gradients may not be very informative, and can even impede parameter adaptation to the environment.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"Recently, it is also reported that the use of momentum can make training unstable when the loss is nonstationary (Arjovsky et al., 2017).",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"Indeed, Theorem 4.1 in (Kingma & Ba, 2015) shows that Adam has low regret only when β1 is decreasing w.r.t.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
t.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"When β1 → 0, ∑t i=1 wi,tgi → gt and so only the current gradient is used.
",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
Remark 1.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
(Summary) RMSprop and Adam are improvements over Adagrad in training deep networks.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"However, RMSprop uses β1 = 0 (and thus relies only on the current sample), does not correct the bias of the variance estimate, but centers the regularization at the current iterates θi−1’s.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"On the other hand, Adam uses β1 > 0, bias-corrected variance, but centers all regularization terms at the last iterate θt−1.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
The proposed FTML combines the nice properties of the two.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"In this section, experiments are performed on a number of deep learning models, including convolutional neural networks (Section 4.1), deep residual networks (Section 4.2), memory networks (Section 4.3), neural conversational model (Section 4.4), deep Q-network (Section 4.5), and long short-term memory (LSTM) (Section 4.6).",4. Experiments,[0],[0]
"A summary of the empirical performance of the various deep learning optimizers is presented in Section 4.7.
",4. Experiments,[0],[0]
"The following state-of-the-art optimizers for deep learning models will be compared: (i) Adam (Kingma & Ba, 2015); (ii) RMSprop (Tieleman & Hinton, 2012); (iii) Adadelta (Zeiler, 2012); and (iv)",4. Experiments,[0],[0]
"Nesterov accelerated gradient (NAG) (Sutskever et al., 2013).",4. Experiments,[0],[0]
"For FTML, we set β1 = 0.6, β2 = 0.999, and a constant t = = 10−8 for all t. For FTML, Adam, RMSprop, and NAG, η is selected by monitoring performance on the training set (note that Adadelta does not need to set η).",4. Experiments,[0],[0]
"The learning rate is chosen from {0.5, 0.25, 0.1, . . .",4. Experiments,[0],[0]
", 0.00005, 0.000025, 0.00001}.",4. Experiments,[0],[0]
Significantly underperforming learning rates are removed after running the model for 5− 20 epochs.,4. Experiments,[0],[0]
We then pick the rate that leads to the smallest final training loss.,4. Experiments,[0],[0]
"In the section, we perform experiments with the convolutional neural network (CNN) (LeCun et al., 1998).",4.1. Convolutional Neural Networks,[0],[0]
We use the example models on the MNIST and CIFAR-10 data sets from the Keras library1.,4.1. Convolutional Neural Networks,[0],[0]
"For MNIST, the CNN has two alternating stages of 3 × 3 convolution filters (using ReLU activation), followed by a 2 × 2 max-pooling layer and a dropout layer (with a dropout rate of 0.25).",4.1. Convolutional Neural Networks,[0],[0]
"Finally, there is a fully-connected layer with ReLU activation and a dropout rate of 0.5.",4.1. Convolutional Neural Networks,[0],[0]
"For CIFAR-10, the CNN has four alternating stages of 3× 3 convolution filters (using ReLU activation).",4.1. Convolutional Neural Networks,[0],[0]
Every two convolutional layers is followed by a 2×2 maxpooling layer and a dropout layer (with a dropout rate of 0.25).,4.1. Convolutional Neural Networks,[0],[0]
The last stage has a fully-connected layer with ReLU activation and a dropout rate of 0.5.,4.1. Convolutional Neural Networks,[0],[0]
"Features in both data sets are normalized to [0, 1].",4.1. Convolutional Neural Networks,[0],[0]
"Minibatches of sizes 128 and 32 are used for MNIST and CIFAR-10, respectively.
",4.1. Convolutional Neural Networks,[0],[0]
"As the iteration complexities of the various algorithms are comparable and the total cost is dominated by backpropagation, we report convergence of the training cross entropy loss versus the number of epochs.",4.1. Convolutional Neural Networks,[0],[0]
"This setup is also used in (Zeiler, 2012; Kingma & Ba, 2015).
",4.1. Convolutional Neural Networks,[0],[0]
Figure 1 shows the convergence results.,4.1. Convolutional Neural Networks,[0],[0]
"As can be seen, FTML performs best on both data sets.",4.1. Convolutional Neural Networks,[0],[0]
"Adam has comparable performance with FTML on MNIST, but does not perform as well on CIFAR-10.",4.1. Convolutional Neural Networks,[0],[0]
The other methods are much inferior.,4.1. Convolutional Neural Networks,[0],[0]
"In particular, RMSprop is slow on both MNIST and CIFAR-10, and Adadelta tends to diverge on CIFAR-10.",4.1. Convolutional Neural Networks,[0],[0]
"Recently, substantially deeper networks have been popularly used, particularly in computer vision.",4.2. Deep Residual Networks,[0],[0]
"For example, a 152-layer deep residual network (He et al., 2016) achieves state-of-the-art performance on ImageNet classification, and won the first place on the ILSVRC 2015 classification task.
",4.2. Deep Residual Networks,[0],[0]
"In this section, we perform experiments with a 110-layer deep residual network on the CIFAR-10 and CIFAR-100 data sets.",4.2. Deep Residual Networks,[0],[0]
The code is based on its Torch implementation2.,4.2. Deep Residual Networks,[0],[0]
"We leave the architecture and related settings intact, and use the same learning rate schedule.",4.2. Deep Residual Networks,[0],[0]
The default optimizer in the Torch code is NAG.,4.2. Deep Residual Networks,[0],[0]
"Here, we also experiment with Adadelta, RMSprop, Adam and the proposed FTML.",4.2. Deep Residual Networks,[0],[0]
"A minibatch size of 32 is used.
",4.2. Deep Residual Networks,[0],[0]
Convergence of the training cross entropy loss is shown in Figure 2.,4.2. Deep Residual Networks,[0],[0]
"As can been seen, all optimizers, except Adadelta, are very competitive and have comparable per-
1https://github.com/fchollet/keras.",4.2. Deep Residual Networks,[0],[0]
"2https://github.com/facebook/fb.resnet.
torch.
",4.2. Deep Residual Networks,[0],[0]
formance on these two data sets.,4.2. Deep Residual Networks,[0],[0]
"NAG shows slower initial convergence, while FTML converges slightly faster than the others on the CIFAR-10 data set.",4.2. Deep Residual Networks,[0],[0]
"Recently, there has been a lot of attention on combining inference, attention and memory for various machine learning tasks.",4.3. Memory Networks,[0],[0]
"In particular, the memory network (Weston et al., 2014; Sukhbaatar et al., 2015) has been popularly used for natural language understanding.
",4.3. Memory Networks,[0],[0]
"In this section, we use the example model of the end-toend memory network (with LSTM) from the Keras library.",4.3. Memory Networks,[0],[0]
"We consider the question answering task (Sukhbaatar et al., 2015; Weston et al., 2016), and perform experiments on the “single supporting fact” task in the bAbI data set (Weston et al., 2016).",4.3. Memory Networks,[0],[0]
This task consists of questions in which a previously given single sentence provides the answer.,4.3. Memory Networks,[0],[0]
"An
example is shown below.",4.3. Memory Networks,[0],[0]
"We use a single supporting memory, and a minibatch size of 32.
",4.3. Memory Networks,[0],[0]
Single Supporting Fact:,4.3. Memory Networks,[0],[0]
Mary moved to the bathroom.,4.3. Memory Networks,[0],[0]
John went to the hallway.,4.3. Memory Networks,[0],[0]
Where is Mary?,4.3. Memory Networks,[0],[0]
"A: bathroom
Convergence of the training cross entropy loss is shown in Figure 3.",4.3. Memory Networks,[0],[0]
"As can be seen, FTML and RMSprop perform best on this data set.",4.3. Memory Networks,[0],[0]
"Adam is slower, while NAG and Adadelta perform poorly.",4.3. Memory Networks,[0],[0]
"The neural conversational model (Vinyals & Le, 2015) is a sequence-to-sequence model (Sutskever et al., 2014) that is capable of predicting the next sequence given the last or previous sequences in a conversation.",4.4. Neural Conversational Model,[0],[0]
"A LSTM layer en-
codes the input sentence to a thought vector, and a second LSTM layer decodes the thought vector to the response.",4.4. Neural Conversational Model,[0],[0]
"It has been shown that this model can often produce fluent and natural conversations.
",4.4. Neural Conversational Model,[0],[0]
"In this experiment, we use the publicly available Torch implementation3 with a constant stepsize, and its default data set Cornell Movie-Dialogs Corpus (with 50, 000 samples) (Danescu-Niculescu-Mizil & Lee, 2011).",4.4. Neural Conversational Model,[0],[0]
"The number of hidden units is set to 1000, and the minibatch size is 10.
",4.4. Neural Conversational Model,[0],[0]
Convergence of the training cross entropy loss is shown in Figure 4.,4.4. Neural Conversational Model,[0],[0]
"Adadelta is not reported here, since it performs poorly (as in previous experiments).",4.4. Neural Conversational Model,[0],[0]
"As can be seen, FTML outperforms Adam and RMSprop.",4.4. Neural Conversational Model,[0],[0]
"In particular, RMSprop is much inferior.",4.4. Neural Conversational Model,[0],[0]
"NAG is slower than FTML and Adam in the first 21 epochs, but becomes faster towards the end of training.",4.4. Neural Conversational Model,[0],[0]
"In this section, we use the Deep Q-network (DQN) (Mnih et al., 2015) for deep reinforcement learning.",4.5. Deep Q-Network,[0],[0]
Experiments are performed on two computer games on the Atari 2600 platform: Breakout and Asterix.,4.5. Deep Q-Network,[0],[0]
"We use the publicly available Torch implementation with the default network setup4, and a minibatch size of 32.",4.5. Deep Q-Network,[0],[0]
"We only compare FTML with RMSprop and Adam for optimization, as NAG and Adadelta are rarely used in training the DQN.",4.5. Deep Q-Network,[0],[0]
"As in (Mnih et al., 2015), we use = 10−2 for all methods, and performance evaluation is based on the average score per episode.",4.5. Deep Q-Network,[0],[0]
"The higher the score, the better the performance.
",4.5. Deep Q-Network,[0],[0]
Convergence is shown in Figure 5.,4.5. Deep Q-Network,[0],[0]
"On Breakout, RM-
3https://github.com/macournoyer/ neuralconvo.
",4.5. Deep Q-Network,[0],[0]
"4https://github.com/Kaixhin/Atari.
",4.5. Deep Q-Network,[0],[0]
Sprop and FTML are comparable and yield higher scores than Adam.,4.5. Deep Q-Network,[0],[0]
"On Asterix, FTML outperforms all the others.",4.5. Deep Q-Network,[0],[0]
"In particular, the DQN trained with RMSprop fails to learn the task, and its score begins to drop after about 100 epochs.",4.5. Deep Q-Network,[0],[0]
"A similar problem has also been observed in (Hasselt et al., 2016).",4.5. Deep Q-Network,[0],[0]
"Experience replay (Mnih et al., 2015) has been commonly used in deep reinforcement learning to smooth over changes in the data distribution, and avoid oscillations or divergence of the parameters.",4.5. Deep Q-Network,[0],[0]
"However, results here show that Adam still has inferior performance because of its use of all past gradients, many of these are not informative when the data distribution has changed.",4.5. Deep Q-Network,[0],[0]
"To illustrate the problem of Adam in Section 4.5 more clearly, we perform the following timeseries prediction experiment with the LSTM.",4.6. Long Short-Term Memory (LSTM),[0],[0]
We construct a synthetic timeseries of length 1000.,4.6. Long Short-Term Memory (LSTM),[0],[0]
"This is divided into 20 segments, each of length 50.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"At each time point, the sample is 10- dimensional.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"In segment i, samples are generated from a normal distribution with mean ([i, i, . . .",4.6. Long Short-Term Memory (LSTM),[0],[0]
", i] + ζi) ∈ R10 and identity covariance matrix, where the components of ζi are independent standard normal random variables.",4.6. Long Short-Term Memory (LSTM),[0],[0]
Noise from the standard normal distribution is added to corrupt the data.,4.6. Long Short-Term Memory (LSTM),[0],[0]
"The task is to predict the data sample at the next time point t.
We use a one-layer LSTM implemented in (Léonard et al., 2015).",4.6. Long Short-Term Memory (LSTM),[0],[0]
100 hidden units are used.,4.6. Long Short-Term Memory (LSTM),[0],[0]
"We truncate backpropagation through time (BPTT) to 5 timesteps, and input 5 samples to the LSTM in each iteration.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"Thus, the data distribution changes every 10 iterations, as a different normal distribution is then used for data generation.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"Performance evaluation is based on the squared loss ft(θt−1) at time t.
Convergence of the loss is shown in Figure 6(a).",4.6. Long Short-Term Memory (LSTM),[0],[0]
"As can be
seen, Adam has difficulty in adapting to the data.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"In contrast, FTML and RMSprop can adapt more quickly, yielding better and more stable performance.
",4.6. Long Short-Term Memory (LSTM),[0],[0]
"As a baseline, we consider the case where the data distribution does not change (the means of all the segments are fixed to the vector of ones)",4.6. Long Short-Term Memory (LSTM),[0],[0]
Figure 6(b) shows the results.,4.6. Long Short-Term Memory (LSTM),[0],[0]
"As can be seen, Adam now performs comparably to FTML and RMSprop.",4.6. Long Short-Term Memory (LSTM),[0],[0]
The main problem with RMSprop is that its performance is not stable.,4.7. Summary of Results,[0],[0]
"Sometimes, it performs well, but sometimes it can have significantly inferior performance (e.g., as can be seen from Figures 1, 4 and 5(b)).",4.7. Summary of Results,[0],[0]
"The performance of Adam is more stable, though it often lags behind the best optimizer (e.g., Figures 1(b), 3, and 4).",4.7. Summary of Results,[0],[0]
"It is particularly problematic when learning in a changing environment (Fig-
ures 5 and 6(a)).",4.7. Summary of Results,[0],[0]
"In contrast, the proposed FTML shows stable performance on various models and tasks.",4.7. Summary of Results,[0],[0]
"It converges quickly, and is always the best (or at least among the best) in all our experiments.",4.7. Summary of Results,[0],[0]
"In this paper, we proposed a FTPRL variant called FTML, in which the recent samples are weighted more heavily in each iteration.",5. Conclusion,[0],[0]
"Hence, it is able to adapt more quickly when the parameter moves to another local basin, or when the data distribution changes.",5. Conclusion,[0],[0]
FTML is closely related to RMSprop and Adam.,5. Conclusion,[0],[0]
"In particular, it enjoys their nice properties, but avoids their pitfalls.",5. Conclusion,[0],[0]
"Experimental results on a number of deep learning models and tasks demonstrate that FTML converges quickly, and is always the best (or among the best) of the various optimizers.",5. Conclusion,[0],[0]
This research was supported in part by ITF/391/15FX.,Acknowledgments,[0],[0]
Deep networks are highly nonlinear and difficult to optimize.,abstractText,[0],[0]
"During training, the parameter iterate may move from one local basin to another, or the data distribution may even change.",abstractText,[0],[0]
"Inspired by the close connection between stochastic optimization and online learning, we propose a variant of the follow the regularized leader (FTRL) algorithm called follow the moving leader (FTML).",abstractText,[0],[0]
"Unlike the FTRL family of algorithms, the recent samples are weighted more heavily in each iteration and so FTML can adapt more quickly to changes.",abstractText,[0],[0]
"We show that FTML enjoys the nice properties of RMSprop and Adam, while avoiding their pitfalls.",abstractText,[0],[0]
"Experimental results on a number of deep learning models and tasks demonstrate that FTML converges quickly, and outperforms other state-ofthe-art optimizers.",abstractText,[0],[0]
Follow the Moving Leader in Deep Learning,title,[0],[0]
NMT has witnessed promising improvements recently.,1 Introduction,[0],[0]
"Depending on the types of input and output, these efforts can be divided into three categories: string-to-string systems (Sutskever et al., 2014; Bahdanau et al., 2014); tree-to-string systems (Eriguchi et al., 2016, 2017); and string-totree systems (Aharoni and Goldberg, 2017; Nadejde et al., 2017).",1 Introduction,[0],[0]
"Compared with string-to-string systems, tree-to-string and string-to-tree systems (henceforth, tree-based systems) offer some attractive features.",1 Introduction,[0],[0]
"They can use more syntactic information (Li et al., 2017), and can conveniently incorporate prior knowledge (Zhang et al., 2017).
∗ Contribution during internship at National Institute of Information and Communications Technology.
†Corresponding author
Because of these advantages, tree-based methods become the focus of many researches of NMT nowadays.
",1 Introduction,[0],[0]
"Based on how to represent trees, there are two main categories of tree-based NMT methods: representing trees by a tree-structured neural network (Eriguchi et al., 2016; Zaremoodi and Haffari, 2017), representing trees by linearization (Vinyals et al., 2015; Dyer et al., 2016; Ma et al., 2017).",1 Introduction,[0],[0]
"Compared with the former, the latter method has a relatively simple model structure, so that a larger corpus can be used for training and the model can be trained within reasonable time, hence is preferred from the viewpoint of computation.",1 Introduction,[0],[0]
"Therefore we focus on this kind of methods in this paper.
",1 Introduction,[0],[0]
"In spite of impressive performance of tree-based NMT systems, they suffer from a major drawback: they only use the 1-best parse tree to direct the translation, which potentially introduces translation mistakes due to parsing errors (Quirk and Corston-Oliver, 2006).",1 Introduction,[0],[0]
"For SMT, forest-based methods have employed a packed forest to address this problem (Huang, 2008), which represents exponentially many parse trees rather than just the 1-best one (Mi et al., 2008; Mi and Huang, 2008).",1 Introduction,[0],[0]
"But for NMT, (computationally efficient) forestbased methods are still being explored1.
",1 Introduction,[0],[0]
"Because of the structural complexity of forests, the inexistence of appropriate topological ordering, and the hyperedge-attachment nature of weights (see Section 3.1 for details), it is not trivial to linearize a forest.",1 Introduction,[0],[0]
"This hinders the development of forest-based NMT to some extent.
",1 Introduction,[0],[0]
"Inspired by the tree-based NMT methods based on linearization, we propose an efficient forestbased NMT approach (Section 3), which can en-
1Zaremoodi and Haffari (2017) have proposed a forestbased NMT method based on a forest-structured neural network recently, but it is computationally inefficient (see Section 5).
code the syntactic information of a packed forest on the basis of a novel weighted linearization method for a packed forest (Section 3.1), and can decode the linearized packed forest under the simple sequence-to-sequence framework (Section 3.2).",1 Introduction,[0],[0]
Experiments demonstrate the effectiveness of our method (Section 4).,1 Introduction,[0],[0]
"We first review the general sequence-to-sequence model (Section 2.1), then describe tree-based NMT systems based on linearization (Section 2.2), and finally introduce the packed forest, through which exponentially many trees can be represented in a compact manner (Section 2.3).",2 Preliminaries,[0],[0]
"Current NMT systems usually resort to a simple framework, i.e., the sequence-to-sequence model (Cho et al., 2014; Sutskever et al., 2014).",2.1 Sequence-to-sequence model,[0],[0]
"Given a source sequence (x0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", xT ), in order to find a target sequence (y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", yT ′) that maximizes the conditional probability p(y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", yT ′",2.1 Sequence-to-sequence model,[0],[0]
"| x0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", xT ), the sequence-to-sequence model uses one RNN to encode the source sequence into a fixed-length context vector c and a second RNN to decode this vector and generate the target sequence.",2.1 Sequence-to-sequence model,[0],[0]
"Formally, the probability of the target sequence can be calculated as follows:
p(y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
",yT ′",2.1 Sequence-to-sequence model,[0],[0]
"| x0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", xT )
",2.1 Sequence-to-sequence model,[0],[0]
"= T ′∏ t=0 p(yt | c, y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", yt−1), (1)
where
p(yt | c, y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", yt−1) = g(yt−1, st, c), (2) st = f(st−1, yt−1, c), (3)
c = q(h0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", hT ), (4)
ht = f(et, ht−1).",2.1 Sequence-to-sequence model,[0],[0]
"(5)
Here, g, f , and q are nonlinear functions; ht and st are the hidden states of the source-side RNN and target-side RNN, respectively, c is the context vector, and et is the embedding of xt.
Bahdanau et al. (2014) introduced an attention mechanism to deal with the issues related to long sequences (Cho et al., 2014).",2.1 Sequence-to-sequence model,[0],[0]
"Instead of encoding the source sequence into a fixed vector c, the attention model uses different ci-s when calculating
the target-side output yi at time step i:
ci = T∑
j=0
αijhj , (6)
αij = exp(a(si−1, hj))∑T k=0",2.1 Sequence-to-sequence model,[0],[0]
"exp(a(si−1, hk))",2.1 Sequence-to-sequence model,[0],[0]
.,2.1 Sequence-to-sequence model,[0],[0]
"(7)
The function a(si−1, hj) can be regarded as representing the soft alignment between the target-side RNN hidden state si−1 and the source-side RNN hidden state hj .
",2.1 Sequence-to-sequence model,[0],[0]
"By changing the format of the source/target sequences, this framework can be regarded as a string-to-string NMT system (Sutskever et al., 2014), a tree-to-string NMT system (Li et al., 2017), or a string-to-tree NMT system (Aharoni and Goldberg, 2017).",2.1 Sequence-to-sequence model,[0],[0]
"Regarding the linearization adopted for tree-tostring NMT (i.e., linearization of the source side), Sennrich and Haddow (2016) encoded the sequence of dependency labels and the sequence of words simultaneously, partially utilizing the syntax information, while Li et al. (2017) traversed the constituent tree of the source sentence and combined this with the word sequence, utilizing the syntax information completely.
",2.2 Linear-structured tree-based NMT systems,[0],[0]
"Regarding the linearization used for string-totree NMT (i.e., linearization of the target side), Nadejde et al. (2017) used a CCG supertag sequence as the target sequence, while Aharoni and Goldberg (2017) applied a linearization method in a top-down manner, generating a sequence ensemble for the annotated tree in the Penn Treebank (Marcus et al., 1993).",2.2 Linear-structured tree-based NMT systems,[0],[0]
"Wu et al. (2017) used transition actions to linearize a dependency tree, and employed the sequence-to-sequence framework for NMT.
",2.2 Linear-structured tree-based NMT systems,[0],[0]
It can be seen all current tree-based NMT systems use only one tree for encoding or decoding.,2.2 Linear-structured tree-based NMT systems,[0],[0]
"In contrast, we hope to utilize multiple trees (i.e., a forest).",2.2 Linear-structured tree-based NMT systems,[0],[0]
"This is not trivial, on account of the lack of a fixed traversal order and the need for a compact representation.",2.2 Linear-structured tree-based NMT systems,[0],[0]
"The packed forest gives a representation of exponentially many parsing trees, and can compactly encode many more candidates than the n-best list
(Huang, 2008).",2.3 Packed forest,[0],[0]
"Figure 1a shows a packed forest, which can be unpacked into two constituent trees (Figure 1b and Figure 1c).
",2.3 Packed forest,[0],[0]
"Formally, a packed forest is a pair 〈V,E〉, where V is the set of nodes and E is the set of hyperedges.",2.3 Packed forest,[0],[0]
"Each v ∈ V can be represented as Xi,j , where X is a constituent label and i, j ∈",2.3 Packed forest,[0],[0]
"[0, n] are indices of words, showing that the node spans the words ranging from i (inclusive) to j (exclusive).",2.3 Packed forest,[0],[0]
"Here, n is the length of the input sentence.",2.3 Packed forest,[0],[0]
"Each e ∈ E is a three-tuple 〈head(e), tails(e), score(e)〉, where head(e) ∈ V is similar to the head node in a constituent tree, and tails(e) ∈ V ∗ is similar to the set of child nodes in a constituent tree.",2.3 Packed forest,[0],[0]
score(e) ∈ R is the logarithm of the probability that tails(e) represents the tails of head(e) calculated by the parser.,2.3 Packed forest,[0],[0]
"Based on score(e), the score of a constituent tree T can be calculated as follows:
score(T ) = −λn+",2.3 Packed forest,[0],[0]
"∑
e∈E(T )
score(e), (8)
where E(T ) is the set of hyperedges appearing in tree T , and λ is a regularization coefficient for the sentence length2.
2Following the configuration of Charniak and Johnson",2.3 Packed forest,[0],[0]
"We first propose a linearization method for the packed forest (Section 3.1), then describe how to encode the linearized forest (Section 3.2), which can then be translated by the conventional decoder (see Section 2.1).",3 Forest-based NMT,[0],[0]
"Recently, several studies have focused on the linearization methods of a syntax tree, both in the area of tree-based NMT (Section 2.2) and in the area of parsing (Vinyals et al., 2015; Dyer et al., 2016; Ma et al., 2017).",3.1 Forest linearization,[0],[0]
"Basically, these methods follow a fixed traversal order (e.g., depthfirst), which does not exist for the packed forest (a directed acyclic graph (DAG)).",3.1 Forest linearization,[0],[0]
"Furthermore, the weights are attached to edges of a packed forest instead of the nodes, which further increase the difficulty.
",3.1 Forest linearization,[0],[0]
"Topological ordering algorithms for DAG (Kahn, 1962; Tarjan, 1976) are not good solutions, because the outputted ordering is not always optimal for machine translation.",3.1 Forest linearization,[0],[0]
"In particular, a topo-
(2005), for all the experiments in this paper, we fixed λ to log2 600.
",3.1 Forest linearization,[0],[0]
"Algorithm 1 Linearization of a packed forest 1: function LINEARIZEFOREST(〈V,E〉,w) 2: v ← FINDROOT(V ) 3: r←",3.1 Forest linearization,[0],[0]
"[] 4: EXPANDSEQ(v, r, 〈V,E〉,w) 5: return r 6: function FINDROOT(V ) 7: for v ∈ V do 8: if v has no parent then 9: return v 10: procedure EXPANDSEQ(v, r, 〈V,E〉,w) 11: for e ∈ E do 12: if head(e) = v then 13: if tails(e) 6= ∅",3.1 Forest linearization,[0],[0]
then 14: for t ∈ SORT(tails(e)) do .,3.1 Forest linearization,[0],[0]
"Sort
tails(e) by word indices.",3.1 Forest linearization,[0],[0]
"15: EXPANDSEQ(t, r, 〈V,E〉,w) 16: l← LINEARIZEEDGE(head(e),w) 17: r.append(〈l, σ(0.0)〉) .",3.1 Forest linearization,[0],[0]
"σ is the sigmoid
function, i.e., σ(x) = 1 1+e−x , x ∈ R.
18:",3.1 Forest linearization,[0],[0]
"l ← c©LINEARIZEEDGES(tails(e),w) .",3.1 Forest linearization,[0],[0]
c© is a unary operator.,3.1 Forest linearization,[0],[0]
"19: r.append(〈l, σ(score(e))",3.1 Forest linearization,[0],[0]
"〉) 20: else 21: l← LINEARIZEEDGE(head(e),w) 22:",3.1 Forest linearization,[0],[0]
"r.append(〈l, σ(0.0)〉) 23: function LINEARIZEEDGE(Xi,j ,w) 24: return X ⊗",3.1 Forest linearization,[0],[0]
"( j−1k=iwk) 25: function LINEARIZEEDGES(v,w) 26: return ⊕v∈vLINEARIZEEDGE(v,w)
logical ordering could ignore “word sequential information” and “parent-child information” in the sentences.
",3.1 Forest linearization,[0],[0]
"For example, for the packed forest in Figure 1a, although “[10]→[1]→[2]→ · · · →[9]→[11]” is a valid topological ordering, the word sequential information of the words (e.g., “John” should be located ahead of the period), which is fairly crucial for translation of languages with fixed pragmatic word order such as Chinese or English, is lost.
",3.1 Forest linearization,[0],[0]
"As another example, for the packed forest in Figure 1a, nodes [2], [9], and [10] are all the children of node [11].",3.1 Forest linearization,[0],[0]
"However, in the topological order “[1]→[2]→ · · · →[9]→[10]→[11],” node [2] is quite far from node [11], while nodes [9] and [10] are both close to node [11].",3.1 Forest linearization,[0],[0]
"The parent-child information cannot be reflected in this topological order, which is not what we would expect.
",3.1 Forest linearization,[0],[0]
"To address the above two problems, we propose a novel linearization algorithm for a packed forest (Algorithm 1).",3.1 Forest linearization,[0],[0]
"The algorithm linearizes the packed forest from the root node (Line 2) to leaf nodes by calling the EXPANDSEQ procedure (Line 15) recursively, while preserving the word order in the sentence (Line 14).",3.1 Forest linearization,[0],[0]
"In this way, word sequential information is preserved.",3.1 Forest linearization,[0],[0]
"Within the
EXPANDSEQ procedure, once a hyperedge is linearized (Line 16), the tails are also linearized immediately (Line 18).",3.1 Forest linearization,[0],[0]
"In this way, parent-child information is preserved.",3.1 Forest linearization,[0],[0]
"Intuitively, different parts of constituent trees should be combined in different ways, therefore we define different operators ( c©, ⊗, ⊕, or ) to represent the relationships between different parts, so that the representations of these parts can be combined in different ways (see Section 3.2 for details).",3.1 Forest linearization,[0],[0]
"Words are concatenated by the operator “ ” with each other, a word and a constituent label is concatenated by the operator “⊗”, the linearization results of child nodes are concatenated by the operator “⊕” with each other, while the unary operator “ c©” is used to indicate that the node is the child node of the previous part.",3.1 Forest linearization,[0],[0]
"Furthermore, each token in the linearized sequence is related to a score, representing the confidence of the parser.
",3.1 Forest linearization,[0],[0]
The linearization result of the packed forest in Figure 1a is shown in Figure 2.,3.1 Forest linearization,[0],[0]
Tokens in the linearized sequence are separated by slashes.,3.1 Forest linearization,[0],[0]
Each token in the sequence is composed of different types of symbols and combined by different operators.,3.1 Forest linearization,[0],[0]
We can see that word sequential information is preserved.,3.1 Forest linearization,[0],[0]
"For example, “NNP⊗John” (linearization result of node [1]) is in front of “VBZ⊗has” (linearization result of node [3]), which is in front of “DT⊗a” (linearization result of node [4]).",3.1 Forest linearization,[0],[0]
"Moreover, parent-child information is also preserved.",3.1 Forest linearization,[0],[0]
"For example, “NP⊗John” (linearization result of node [2]) is followed by “ c©NNP⊗John” (linearization result of node [1], the child of node [2]).
",3.1 Forest linearization,[0],[0]
Note that our linearization method cannot fully recover packed forest.,3.1 Forest linearization,[0],[0]
What we want to do is not to propose a fully recoverable linearization method.,3.1 Forest linearization,[0],[0]
"What we actually want to do is to encode syntax information as much as possible, so that we can improve the performance of NMT.",3.1 Forest linearization,[0],[0]
"As will be shown in Section 4, this goal is achieved.
",3.1 Forest linearization,[0],[0]
"Also note that there is one more advantage of our linearization method: the linearized sequence
is a weighted sequence, while all the previous studies ignored the weights during linearization.",3.1 Forest linearization,[0],[0]
"As will be shown in Section 4, the weights are actually important not only for the linearization of a packed forest, but also for the linearization of a single tree.
",3.1 Forest linearization,[0],[0]
"By preserving only the nodes and hyperedges in the 1-best tree and removing all others, our linearization method can be regarded as a treelinearization method.",3.1 Forest linearization,[0],[0]
"Compared with other treelinearization methods, our method combines several different kinds of information within one symbol, retaining the parent-child information, and incorporating the confidence of the parser in the sequence.",3.1 Forest linearization,[0],[0]
"We examine whether the weights can be useful not only for linear structured tree-based NMT but also for our forest-based NMT.
",3.1 Forest linearization,[0],[0]
"Furthermore, although our method is nonreversible for packed forests, it is reversible for constituent trees, in that the linearization is processed exactly in the depth-first traversal order and all necessary information in the tree nodes has been encoded.",3.1 Forest linearization,[0],[0]
"As far as we know, there is no previous work on linearization of packed forests.",3.1 Forest linearization,[0],[0]
"The linearized packed forest forms the input of the encoder, which has two major differences from the input of a sequence-to-sequence NMT system.",3.2 Encoding the linearized forest,[0],[0]
"First, the input sequence of the encoder consists of two parts: the symbol sequence and the score sequence.",3.2 Encoding the linearized forest,[0],[0]
"Second, each symbol in the symbol sequence consists of several parts (words and constituent labels), which are combined by certain operators ( c©, ⊗, ⊕, or ).",3.2 Encoding the linearized forest,[0],[0]
"Based on these observa-
tions, we propose two new frameworks, which are illustrated in Figure 3.
",3.2 Encoding the linearized forest,[0],[0]
"Formally, the input layer receives the sequence (〈l0, ξ0〉, . . .",3.2 Encoding the linearized forest,[0],[0]
", 〈lT , ξT 〉), where li denotes the i-th symbol and ξi its score.",3.2 Encoding the linearized forest,[0],[0]
"Then, the sequence is fed into the score layer and the symbol layer.",3.2 Encoding the linearized forest,[0],[0]
"The score and symbol layers receive the sequence and output the score sequence ξ = (ξ0, . . .",3.2 Encoding the linearized forest,[0],[0]
", ξT ) and symbol sequence",3.2 Encoding the linearized forest,[0],[0]
"l = (l0, . . .",3.2 Encoding the linearized forest,[0],[0]
", lT ), respectively, from the input.",3.2 Encoding the linearized forest,[0],[0]
Any item l ∈,3.2 Encoding the linearized forest,[0],[0]
"l in the symbol layer has the form
l = o0x1o1 . . .",3.2 Encoding the linearized forest,[0],[0]
"xm−1om−1xm, (9)
where each xk (k = 1, . . .",3.2 Encoding the linearized forest,[0],[0]
",m) is a word or a constituent label, m is the total number of words and constituent labels in a symbol, o0 is “ c©” or empty, and each ok (k = 1, . . .",3.2 Encoding the linearized forest,[0],[0]
",m − 1) is either “⊗”, “⊕”, or “ ”.",3.2 Encoding the linearized forest,[0],[0]
"Then, in the node/operator layer, the x-s and o-s are separated and rearranged as x = (x1, . . .",3.2 Encoding the linearized forest,[0],[0]
", xm, o0, . . .",3.2 Encoding the linearized forest,[0],[0]
", om−1), which is fed to the pre-embedding layer.",3.2 Encoding the linearized forest,[0],[0]
"The pre-embedding layer generates a sequence p = (p1, . .",3.2 Encoding the linearized forest,[0],[0]
.,3.2 Encoding the linearized forest,[0],[0]
", pm, . . .",3.2 Encoding the linearized forest,[0],[0]
", p2m), which is calculated as follows:
p =Wemb[I(x)].",3.2 Encoding the linearized forest,[0],[0]
"(10)
Here, the function I(x) returns a list of the indices in the dictionary for all the elements in x, which consist of words, constituent labels, or operators.",3.2 Encoding the linearized forest,[0],[0]
"In addition, Wemb is the embedding matrix of size (|wword| + |wlabel| + 4) × dword, where |wword| and |wlabel| are the total number of words and constituent labels, respectively, dword is the dimension of the word embedding, and there are four possible operators: “",3.2 Encoding the linearized forest,[0],[0]
"c©,” “⊗,” “⊕,” and “ .”",3.2 Encoding the linearized forest,[0],[0]
"Note
that p is a list of 2m vectors, and the dimension of each vector is dword.
",3.2 Encoding the linearized forest,[0],[0]
"Because the length of the sequence of the input layer is T + 1, there are T + 1 different ps in the pre-embedding layer, which we denote by P = (p0, . . .",3.2 Encoding the linearized forest,[0],[0]
",pT ).",3.2 Encoding the linearized forest,[0],[0]
"Depending on where the score layer is incorporated, we propose two frameworks: Score-on-Embedding (SoE) and Score-onAttention (SoA).",3.2 Encoding the linearized forest,[0],[0]
"In SoE, the k-th element of the embedding layer is calculated as follows:
ek = ξk ∑ p∈pk p, (11)
while in SoA, the k-th element of the embedding layer is calculated as
ek = ∑ p∈pk p, (12)
where k = 0, . . .",3.2 Encoding the linearized forest,[0],[0]
", T .",3.2 Encoding the linearized forest,[0],[0]
Note that ek ∈ Rdword .,3.2 Encoding the linearized forest,[0],[0]
"In this manner, the proposed forest-to-string NMT framework is connected with the conventional sequence-to-sequence NMT framework.
",3.2 Encoding the linearized forest,[0],[0]
"After calculating the embedding vectors in the embedding layer, the hidden vectors are calculated using Equation 5.",3.2 Encoding the linearized forest,[0],[0]
"When calculating the context vector ci-s, SoE and SoA differ from each other.",3.2 Encoding the linearized forest,[0],[0]
"For SoE, the ci-s are calculated using Equation 6 and 7, while for SoA, the αij-s used to calculate the ci-s are determined as follows:
αij = exp(ξja(si−1, hj))∑T k=0",3.2 Encoding the linearized forest,[0],[0]
"exp(ξka(si−1, hk)) .",3.2 Encoding the linearized forest,[0],[0]
"(13)
Then, using the decoder of the sequence-tosequence framework, the sentence of the target language can be generated.",3.2 Encoding the linearized forest,[0],[0]
We evaluate the effectiveness of our forest-based NMT systems on English-to-Chinese and Englishto-Japanese translation tasks3.,4.1 Setup,[0],[0]
"The statistics of the corpora used in our experiments are summarized in Table 1.
",4.1 Setup,[0],[0]
The packed forests of English sentences are obtained by the constituent parser proposed by Huang (2008)4.,4.1 Setup,[0],[0]
"We filtered out the sentences for
3English is commonly chosen as the target language.",4.1 Setup,[0],[0]
"We chose English as the source language because a highperformance forest parser is not available for other languages.
4http://web.engr.oregonstate.edu/ ˜huanlian/software/forest-reranker/ forest-charniak-v0.8.tar.bz2
which the parser cannot generate the packed forest successfully and the sentences longer than 80 words.",4.1 Setup,[0],[0]
"For NIST datasets, we simply choose the first reference among the four English references of NIST corpora, because all of them are independent with each other, according to the documents of NIST datasets.",4.1 Setup,[0],[0]
"For Chinese sentences, we used Stanford segmenter5 for segmentation.",4.1 Setup,[0],[0]
"For Japanese sentences, we followed the preprocessing steps recommended in WAT 20176.
",4.1 Setup,[0],[0]
"We implemented our framework based on nematus8 (Sennrich et al., 2017).",4.1 Setup,[0],[0]
"For optimization, we used the Adadelta algorithm (Zeiler, 2012).",4.1 Setup,[0],[0]
"In order to avoid overfitting, we used dropout (Srivastava et al., 2014) on the embedding layer and hidden layer, with the dropout probability set to 0.2.",4.1 Setup,[0],[0]
"We used the gated recurrent unit (Cho et al., 2014) as the recurrent unit of RNNs, which are bi-directional, with one hidden layer.
",4.1 Setup,[0],[0]
"Based on the tuning result, we set the maximum length of the input sequence to 300, the hidden layer size as 512, the dimension of word embedding as 620, and the batch size for training as 40.",4.1 Setup,[0],[0]
"We pruned the packed forest using the algorithm of Huang (2008), with a threshold of 5.",4.1 Setup,[0],[0]
"If the linearization of the pruned forest is still longer than 300, then we linearize the 1-best parsing tree instead of the forest.",4.1 Setup,[0],[0]
"During decoding, we used beam search, and fixed the beam size to 12.",4.1 Setup,[0],[0]
"For the case of Forest (SoA), with 1 core of Tesla K80 GPU and LDC corpus as the training data, training spent about 10 days, and decoding speed is about 10 sentences per second.
",4.1 Setup,[0],[0]
"5https://nlp.stanford.edu/software/ stanford-segmenter-2017-06-09.zip
6http://lotus.kuee.kyoto-u.ac.jp/WAT/ WAT2017/baseline/dataPreparationJE.html
7LDC2002E18, LDC2003E07, LDC2003E14, Hansards portion of LDC2004T07, LDC2004T08, and LDC2005T06
8https://github.com/EdinburghNLP/ nematus",4.1 Setup,[0],[0]
Table 2 and 3 summarize the experimental results.,4.2 Experimental results,[0],[0]
"To avoid the affect of segmentation errors, the performance were evaluated by character-level BLEU (Papineni et al., 2002).",4.2 Experimental results,[0],[0]
"We compare our proposed models (i.e., Forest (SoE) and Forest (SoA)) with three types of baseline: a string-to-string model (s2s), forest-based models that do not use score sequences (Forest (No score)), and tree-based models that use the 1-best parsing tree (1-best (No score, SoE, SoA)).",4.2 Experimental results,[0],[0]
"For the 1-best models, we preserve the nodes and hyperedges that are used in the 1-best constituent tree in the packed forest, and remove all other nodes and hyperedges, yielding a pruned forest that contains only the 1-best constituent tree.",4.2 Experimental results,[0],[0]
"For the “No score” configurations, we force the input score sequence to be a sequence of 1.0 with the same length as the input symbol sequence, so that neither the embedding layer nor the attention layer are affected by the score sequence.
",4.2 Experimental results,[0],[0]
"In addition, we also perform a comparison with some state-of-the-art tree-based systems that are
publicly available, including an SMT system (Mi et al., 2008) and the NMT systems (Eriguchi et al. (2016)9, Chen et al. (2017)10, and Li et al. (2017)).",4.2 Experimental results,[0],[0]
"For Mi et al. (2008), we use the implementation of cicada11.",4.2 Experimental results,[0],[0]
"For Li et al. (2017), we reimplemented the “Mixed RNN Encoder” model, because of its outstanding performance on the NIST MT corpus.
",4.2 Experimental results,[0],[0]
"We can see that for both English-Chinese and English-Japanese, compared with the s2s baseline system, both the 1-best and forest-based configurations yield better results.",4.2 Experimental results,[0],[0]
This indicates syntactic information contained in the constituent trees or forests is indeed useful for machine translation.,4.2 Experimental results,[0],[0]
"Specifically, we observe the following facts.
",4.2 Experimental results,[0],[0]
"First, among the three different frameworks SoE, SoA, and No-score, the SoA framework performs the best, while the No-score framework per-
9https://github.com/tempra28/tree2seq 10https://github.com/howardchenhd/
Syntax-awared-NMT 11https://github.com/tarowatanabe/ cicada
forms the worst.",4.2 Experimental results,[0],[0]
"This indicates that the scores of the edges in constituent trees or packed forests, which reflect the confidence of the correctness of the edges, are indeed useful.",4.2 Experimental results,[0],[0]
"In fact, for the 1-best constituent parsing tree, the score of the edge reflects the confidence of the parser.",4.2 Experimental results,[0],[0]
"By using this information, the NMT system succeed to learn a better attention, paying much attention to the confident structure and not paying attention to the unconfident structure, which improved the translation performance.",4.2 Experimental results,[0],[0]
This fact is ignored by previous studies on tree-based NMT.,4.2 Experimental results,[0],[0]
"Furthermore, it is better to use the scores to modify the values of attention instead of rescaling the word embeddings, because modifying word embeddings carelessly may change the semantic meanings of words.
",4.2 Experimental results,[0],[0]
"Second, compared with the cases that only using the 1-best constituent trees, using packed forests yields statistical significantly better results for the SoE and SoA frameworks.",4.2 Experimental results,[0],[0]
This shows the effectiveness of using more syntactic information.,4.2 Experimental results,[0],[0]
"Compared with one constituent tree, the packed forest, which contains multiple different trees, describes the syntactic structure of the sentence in different aspects, which together increase the accuracy of machine translation.",4.2 Experimental results,[0],[0]
"However, without using the scores, the 1-best constituent tree is preferred.",4.2 Experimental results,[0],[0]
"This is because without using the scores, all trees in the packed forest are treated equally, which makes it easy to import noise into the encoder.
",4.2 Experimental results,[0],[0]
"Compared with other types of state-of-the-art systems, our systems using only the 1-best tree (1-best(SoE, SoA)) are better than the other treebased systems.",4.2 Experimental results,[0],[0]
"Moreover, our NMT systems using the packed forests achieve the best performance.",4.2 Experimental results,[0],[0]
"These results also support the usefulness of the scores of the edges and packed forests in NMT.
",4.2 Experimental results,[0],[0]
"As for the efficiency, the training time of the SoA system was slightly longer than that of the SoE system, which was about twice of the s2s baseline.",4.2 Experimental results,[0],[0]
The training time of the tree-based system was about 1.5 times of the baseline.,4.2 Experimental results,[0],[0]
"For the
case of Forest (SoA), with 1 core of Tesla P100 GPU and LDC corpus as the training data, training spent about 10 days, and decoding speed was about 10 sentences per second.",4.2 Experimental results,[0],[0]
"The reason for the relatively low efficiency is that the linearized sequences of packed forests were much longer than word sequences, enlarging the scale of the inputs.",4.2 Experimental results,[0],[0]
"Despite this, the training process ended within reasonable time.",4.2 Experimental results,[0],[0]
"Figure 4 illustrates the translation results of an English sentence using several different configurations: the s2s baseline, using only the 1-best tree (SoE), and using the packed forest (SoE).",4.3 Qualitative analysis,[0],[0]
"This is a sentence from NIST MT 03, and the training corpus is the LDC corpus.
",4.3 Qualitative analysis,[0],[0]
"For the s2s case, no syntactic information is utilized, and therefore the output of the system is not a grammatical Chinese sentence.",4.3 Qualitative analysis,[0],[0]
The attributive phrase of “Czech border region” is a complete sentence.,4.3 Qualitative analysis,[0],[0]
"However, the attributive is not allowed to be a complete sentence in Chinese.
",4.3 Qualitative analysis,[0],[0]
"For the case of using 1-best constituent tree, the output is a grammatical Chinese sentence.",4.3 Qualitative analysis,[0],[0]
"However, the phrase “adjacent to neighboring Slovakia” is completely ignored in the translation result.",4.3 Qualitative analysis,[0],[0]
"After analyzing the constituent tree, we found that this phrase was incorrectly parsed as an “adverb phrase”, so that the NMT system paid little attention to it, because of the low confidence given by the parser.
",4.3 Qualitative analysis,[0],[0]
"In contrast, for the case of the packed forest, we can see this phrase was not ignored and was translated correctly.",4.3 Qualitative analysis,[0],[0]
"Actually, besides “adverb phrase”, this phrase was also correctly parsed as an “adjective phrase”, and covered by multiple different nodes in the forest, making it difficult for the encoder to ignore the phrase.
",4.3 Qualitative analysis,[0],[0]
We also noticed that our method performed better on learning attention.,4.3 Qualitative analysis,[0],[0]
"For the example in Figure 4, we observed that for s2s model, the decoder paid attention to the word “Czech” twice, which
causes the output sentence contains the Chinese translation of Czech twice.",4.3 Qualitative analysis,[0],[0]
"On the other hand, for our forest model, by using the syntax information, the decoder paid attention to the phrase “In the Czech Republic” only once, making the decoder generates the correct output.",4.3 Qualitative analysis,[0],[0]
Incorporating syntactic information into NMT systems is attracting widespread attention nowadays.,5 Related work,[0],[0]
"Compared with conventional string-to-string NMT systems, tree-based systems demonstrate a better performance with the help of constituent trees or dependency trees.
",5 Related work,[0],[0]
"The first noteworthy study is Eriguchi et al. (2016), which used Tree-structured LSTM (Tai et al., 2015) to encode the HPSG syntax tree of the sentence in the source-side in a bottom-up manner.",5 Related work,[0],[0]
"Then, Chen et al. (2017) enhanced the encoder with a top-down tree encoder.
",5 Related work,[0],[0]
"As a simple extension of Eriguchi et al. (2016), very recently, Zaremoodi and Haffari (2017) proposed a forest-based NMT method by representing the packed forest with a forest-structured neural network.",5 Related work,[0],[0]
"However, their method was evaluated in small-scale MT settings (each training dataset consists of under 10k parallel sentences).",5 Related work,[0],[0]
"In contrast, our proposed method is effective in a largescale MT setting, and we present qualitative analysis regarding the effectiveness of using forests in NMT.
",5 Related work,[0],[0]
"Although these methods obtained good results, the tree-structured network used by the encoder made the training and decoding relatively slow, therefore restricts the scope of application.
",5 Related work,[0],[0]
Other attempts at encoding syntactic trees have also been proposed.,5 Related work,[0],[0]
"Eriguchi et al. (2017) combined the Recurrent Neural Network Grammar (Dyer et al., 2016) with NMT systems, while Li et al. (2017) linearized the constituent tree and encoded it using RNNs.",5 Related work,[0],[0]
"The training of these methods is fast, because of the linear structures of RNNs.",5 Related work,[0],[0]
"However, all these syntax-based NMT systems used only the 1-best parsing tree, making the systems sensitive to parsing errors.
",5 Related work,[0],[0]
"Instead of using trees to represent syntactic information, some studies use other data structures to represent the latent syntax of the input sentence.",5 Related work,[0],[0]
"For example, Hashimoto and Tsuruoka (2017) proposed translating using a latent graph.",5 Related work,[0],[0]
"However, such systems do not enjoy the benefit of
handcrafted syntactic knowledge, because they do not use a parser trained from a large treebank with human annotations.
",5 Related work,[0],[0]
"Compared with these related studies, our framework utilizes a linearized packed forest, meaning the encoder can encode exponentially many trees in an efficient manner.",5 Related work,[0],[0]
The experimental results demonstrated these advantages.,5 Related work,[0],[0]
"We proposed a new NMT framework, which encodes a packed forest for the source sentence using linear-structured neural networks, such as RNN.",6 Conclusion and future work,[0],[0]
"Compared with conventional string-tostring NMT systems and tree-to-string NMT systems, our framework can utilize exponentially many linearized parsing trees during encoding, without significantly decreasing the efficiency.",6 Conclusion and future work,[0],[0]
This represents the first attempt at using a forest under the string-to-string NMT framework.,6 Conclusion and future work,[0],[0]
"The experimental results demonstrate the effectiveness of our framework.
",6 Conclusion and future work,[0],[0]
"As future work, we plan to design some more elaborate structures to incorporate the score layer in the encoder.",6 Conclusion and future work,[0],[0]
Further improvement in the translation performance is expected to be achieved for the forest-based NMT system.,6 Conclusion and future work,[0],[0]
We will also apply the proposed linearization method to other tasks.,6 Conclusion and future work,[0],[0]
We are grateful to the anonymous reviewers for their insightful comments and suggestions.,Acknowledgements,[0],[0]
We thank Lemao Liu from Tencent AI Lab for his suggestions about the experiments.,Acknowledgements,[0],[0]
We thank Atsushi Fujita whose suggestions greatly improve the readability and the logical soundness of this paper.,Acknowledgements,[0],[0]
This work was done during the internship of Chunpeng Ma at NICT.,Acknowledgements,[0],[0]
Akihiro Tamura is supported by JSPS KAKENHI Grant Number JP18K18110.,Acknowledgements,[0],[0]
Tiejun Zhao is supported by the National Natural Science Foundation of China (NSFC) via grant 91520204 and State High-Tech Development Plan of China (863 program) via grant 2015AA015405.,Acknowledgements,[0],[0]
"Tree-based neural machine translation (NMT) approaches, although achieved impressive performance, suffer from a major drawback: they only use the 1best parse tree to direct the translation, which potentially introduces translation mistakes due to parsing errors.",abstractText,[0],[0]
"For statistical machine translation (SMT), forestbased methods have been proven to be effective for solving this problem, while for NMT this kind of approach has not been attempted.",abstractText,[0],[0]
"This paper proposes a forest-based NMT method that translates a linearized packed forest under a simple sequence-to-sequence framework (i.e., a forest-to-string NMT model).",abstractText,[0],[0]
"The BLEU score of the proposed method is higher than that of the string-to-string NMT, treebased NMT, and forest-based SMT systems.",abstractText,[0],[0]
Forest-Based Neural Machine Translation,title,[0],[0]
"Since its development by Breiman (2001), random forest has proven to be both accurate and efficient for classification and regression problems.",1. Introduction,[0],[0]
"In regression setting, random forest will predict the conditional mean of a response variable by averaging predictions of a large number of regression trees.",1. Introduction,[0],[0]
"Later then, many other machine learning algorithms were developed upon random forest.",1. Introduction,[0],[0]
"Among them, robust versions of random forest have also been proposed using various methodologies.",1. Introduction,[0],[0]
"Besides the sampling idea (Breiman, 2001) which adds extra randomness, the other variations are mainly based on two ideas: (1) use more robust criterion to construct regression trees (Galimberti et al., 2007; Brence & Brown, 2006; Roy & Larocque, 2012); (2) choose more robust aggregation method (Meinshausen, 2006; Roy & Larocque, 2012; Tsymbal et al., 2006).
",1. Introduction,[0],[0]
"Meinshausen (2006) generalized random forest to pre-
1University of California at San Diego, San Diego, California, USA 2Zillow, Seattle, Washington, USA.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Alexander Hanbo Li <alexanderhanboli@gmail.com>.
Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"dict quantiles by discovering that besides calculating the weighted mean of the observed response variables, one could also get information for the weighted distribution of observed response variables using the sets of local weights generated by random forest.",1. Introduction,[0],[0]
"This method is strongly connected to the adaptive nearest neighbors procedure (Lin & Jeon, 2006) which we will briefly review in section 1.2.",1. Introduction,[0],[0]
"Different from classical k-NN methods that rely on predefined distance metrics, the dissimilarities generated by random forest are data dependent and scale-invariant.
",1. Introduction,[0],[0]
"Another state-of-the-art algorithm AdaBoost (Freund & Schapire, 1995; Freund et al., 1996) has been generalized to be applicable to a large family of loss functions (Friedman, 2001; Mason et al., 1999; Li & Bradic, 2016).",1. Introduction,[0],[0]
"Recent development of more flexible boosting algorithms such as xgboost (Chen & Guestrin, 2016) have become the go-to forest estimators with tabular or matrix data.",1. Introduction,[0],[0]
"One way in which recent boosting algorithms have an advantage over the random forest is the ability to customize the loss function used to reduce the influence of outliers or optimize a metric more suited to the specific problem other than the mean squared error.
",1. Introduction,[0],[0]
"In this paper, we will propose a general framework for forest-type regression which can also be applied to a broad family of loss functions.",1. Introduction,[0],[0]
"It is claimed in (Meinshausen, 2006) that quantile random forest is another nonparametric approach which does not minimize an empirical loss.",1. Introduction,[0],[0]
"However, we will show in fact both random forest and quantile random forest estimators can be re-derived as regression methods using the squared error or quantile loss respectively in our framework.",1. Introduction,[0],[0]
"Inspired by the adaptive nearest neighbor viewpoint, we explore how random forest makes predictions using the local weights generated by ensemble of trees, and connect that with locally weighted regression (Fan & Gijbels, 1996; Tibshirani & Hastie, 1987; Staniswalis, 1989; Newey, 1994; Loader, 2006; Hastie & Loader, 1993).",1. Introduction,[0],[0]
"The intuition is that when predicting the target value (e.g. E[Y |X = x]) at point x, the observations closer to x should receive larger weights.",1. Introduction,[0],[0]
"Different from predefining a kernel, random forest assigns the weights data dependently and adaptively.",1. Introduction,[0],[0]
"After we illustrate the relation between random forest and local regression, we will use random forest weights to design other regression algo-
rithms.",1. Introduction,[0],[0]
"By plugging robust loss functions like Huber loss and Tukey’s redescending loss, we get forest-type regression methods that are more robust to outliers.",1. Introduction,[0],[0]
"Finally, motivated from the truncated squared error loss example, we will show that decreasing the number of nearest neighbors in random forest will also immediately improve its generalization performance.
",1. Introduction,[0],[0]
The layout of this paper is as follows.,1. Introduction,[0],[0]
In Section 1.1 and 1.2 we review random forest and adaptive nearest neighbors.,1. Introduction,[0],[0]
Section 2 introduces the general framework of forest-type regression.,1. Introduction,[0],[0]
In Section 3 we plug in robust regression loss functions to get robust forest algorithms.,1. Introduction,[0],[0]
In Section 4 we motivate from the truncated squared error loss and investigate the importance of choosing right number of nearest neighbors.,1. Introduction,[0],[0]
"Finally, we test our robust forests in Section 5 and show that they are always superior to the traditional formulation in the presence of outliers in both synthetic and real data set.",1. Introduction,[0],[0]
"Following the notation of Breiman (2001), let θ be the random parameter determining how a tree is grown, and data (X,Y ) ∈ X × Y .",1.1. Random forest,[0],[0]
"For each tree T (θ), let L be the total number of leaves, and Rl denotes the rectangular subspace in X corresponding to the l-th leaf.",1.1. Random forest,[0],[0]
"Then for every x ∈ X , there is exactly one leaf l",1.1. Random forest,[0],[0]
such that x ∈ Rl.,1.1. Random forest,[0],[0]
"Denote this leaf by l(x, θ).
",1.1. Random forest,[0],[0]
"For each tree T (θ), the prediction of a new data point X = x is the average of data values in leaf l(x, θ), that is, Ŷ (x, θ) = ∑n j=1 w(Xi, x, θ)Yi, where
w(Xi, x, θ) = 1I{Xi∈Rl(x,θ)}
#{j : Xj ∈ Rl(x,θ)} .",1.1. Random forest,[0],[0]
"(1)
Finally, the conditional mean E[Y |X = x] is approximated by the averaged prediction of m trees, Ŷ (x) = m−1 ∑m t=1",1.1. Random forest,[0],[0]
"Ŷ (x, θt).",1.1. Random forest,[0],[0]
"After rearranging the terms, we can write the prediction of random forest as
Ŷ (x) = n∑ i=1 w(Xi, x)Yi, (2)
where the averaged weight w(Xi, x) is defined as
w(Xi, x) = 1
m m∑ t=1 w(Xi, x, θt).",1.1. Random forest,[0],[0]
"(3)
From equation (2), the prediction of the conditional expectation E[Y |X = x] is the weighted average of the response values of all observations.",1.1. Random forest,[0],[0]
"Furthermore, it is easy to show that ∑n i=1 w(Xi, x) = 1.",1.1. Random forest,[0],[0]
Lin and Jeon (2006) studies the connection between random forest and adaptive nearest neighbor.,1.2. Adaptive nearest neighbors,[0],[0]
"They introduced the so-called potential nearest neighbors (PNN): A sample point xi is called a k-PNN to a target point x if there exists a monotone distance metric under which xi is among the k closest to x among all the sample points.
",1.2. Adaptive nearest neighbors,[0],[0]
"Therefore, any k-NN method can be viewed as choosing k points from the k-PNNs according to some monotone metric.",1.2. Adaptive nearest neighbors,[0],[0]
"For example, under Euclidean metric, the classical k-NN algorithm sorts the observations by their Euclidean distances to the target point and outputs the k closest ones.",1.2. Adaptive nearest neighbors,[0],[0]
"This is equivalent to weighting the k-PNNs using inverse L2 distance.
",1.2. Adaptive nearest neighbors,[0],[0]
"More interestingly, they prove that those observations with positive weights (3) all belong to the k-PNNs (Lin & Jeon, 2006).",1.2. Adaptive nearest neighbors,[0],[0]
"Therefore, random forests is another weighted kPNN method, but it assigns weights to the observations different from any k-NN method under a pre-defined monotonic distance metric.",1.2. Adaptive nearest neighbors,[0],[0]
"In fact, the random forest weights are adaptive to the data if the splitting scheme is adaptive.",1.2. Adaptive nearest neighbors,[0],[0]
"In this section, we generalize the classical random forest to a general forest-type regression (FTR) framework which is applicable to a broad family of loss functions.",2. General framework for forest-type regression,[0],[0]
"In Section 2.1, we motivate the framework by connecting random forest predictor with locally weighted regression.",2. General framework for forest-type regression,[0],[0]
"Then in Section 2.2, we formally propose the new forest-type regression framework.",2. General framework for forest-type regression,[0],[0]
"In Section 2.3, we rediscover the quantile random forest estimator by plugging the quantile loss function into our framework.",2. General framework for forest-type regression,[0],[0]
Classical random forest can be understood as an estimator of conditional mean E[Y |X].,2.1. Squared error and random forest,[0],[0]
"As shown in (2), the estimator Ŷ (x) is weighted average of all response",2.1. Squared error and random forest,[0],[0]
Yi’s.,2.1. Squared error and random forest,[0],[0]
"This special form reminds us of the classical least squares regression, where the estimator is the sample mean.",2.1. Squared error and random forest,[0],[0]
"To be more precise, we rewrite (2) as
n∑ i=1 w(Xi, x)(Yi",2.1. Squared error and random forest,[0],[0]
− Ŷ (x)),2.1. Squared error and random forest,[0],[0]
"= 0. (4)
Equation (4) is the estimating equation (first order condition) of the locally weighted least squares regression (Ruppert & Wand, 1994):
Ŷ (x) = argmin λ∈R n∑ i=1 w(Xi, x)(Yi",2.1. Squared error and random forest,[0],[0]
"− λ)2 (5)
In classical local regression, the weight w(Xi, x) serves as a local metric between the target point x and observation Xi.",2.1. Squared error and random forest,[0],[0]
"Intuitively, observations closer to target x should be given more weights when predicting the response at x. One common choice of such local metric is kernel Kh(Xi, x) = K((Xi − x)/h).",2.1. Squared error and random forest,[0],[0]
"For example, the tricube kernel K(u) =",2.1. Squared error and random forest,[0],[0]
(1 − |u|3)3 1I(|u| ≤ 1) will ignore the impact of observations outside a window centered at x and increase the weight of an observation when it is getting closer to x.,2.1. Squared error and random forest,[0],[0]
"The form of kernel-type local regression is as follows:
argmin λ∈R n∑ i=1 Kh(Xi",2.1. Squared error and random forest,[0],[0]
− x)(Yi,2.1. Squared error and random forest,[0],[0]
"− λ)2,
The random forest weight w(Xi, x) (3) defines a similar data dependent metric, which is constructed using the ensemble of regression trees.",2.1. Squared error and random forest,[0],[0]
"Using an adaptive splitting scheme, each tree chooses the most informative predictors from those at its disposal.",2.1. Squared error and random forest,[0],[0]
"The averaging process then assigns positive weights to these training responses, which are called voting points in (Lin & Jeon, 2006).",2.1. Squared error and random forest,[0],[0]
"Hence via the random forest voting mechanism, those observations close to the target point get assigned positive weights equivalent to a kernel functionality (Friedman et al., 2001).",2.1. Squared error and random forest,[0],[0]
"Note that the formation (5) is just a special case when using squared error loss φ(a, b) = (a−b)2.",2.2. Extension to general loss,[0],[0]
"In more general form, we have the following local regression problem:
Ŷ (x) = argmin s∈F n∑ i=1 w(Xi, x)φ(s(Xi), Yi) (6)
where w(Xi, x) is a local weight, F is a family of functions, and φ(·) is a general loss.",2.2. Extension to general loss,[0],[0]
"For example, when local weight is a kernel and F stands for polynomials of a certain degree, it reduces to local polynomial regression (Fan & Gijbels, 1996).",2.2. Extension to general loss,[0],[0]
"Random forest falls into this framework with squared error loss, a family of constant functions and local weights (3) constructed from ensemble of trees.
",2.2. Extension to general loss,[0],[0]
"Algorithm 1 Forest-type regression Step 1: Calculate local weights w(Xi, x) using ensemble or trees.",2.2. Extension to general loss,[0],[0]
"Step 2: Choose a loss φ(·, ·) and a family F of function.",2.2. Extension to general loss,[0],[0]
"Then do the locally weighted regression
Ŷ (x) = argmin s∈F n∑ i=1 w(Xi, x)φ(Yi, s(Xi)).
",2.2. Extension to general loss,[0],[0]
"In Algorithm 1, we summarize the forest-type regression as a general two-step method.",2.2. Extension to general loss,[0],[0]
"Note that here we only focus on local weights generated by random forest, which
uses ensemble of trees to recursively partition the covariate space X .",2.2. Extension to general loss,[0],[0]
"However, there are many other data dependent dissimilarity measures that can potentially be used, such as k-NN, mp-dissimilarity (Aryal et al., 2014), shared nearest neighbors (Jarvis & Patrick, 1973), information-based similarity (Lin et al., 1998), mass-based dissimilarity (Ting et al., 2016), etc.",2.2. Extension to general loss,[0],[0]
And there are many other domain specific dissimilarity measures.,2.2. Extension to general loss,[0],[0]
"To avoid distraction, we will only use random forest weights throughout the rest of this paper.",2.2. Extension to general loss,[0],[0]
Meinshausen (2006) proposed the quantile random forest which can extract the information of different quantiles rather than just predicting the average.,2.3. Quantile loss and quantile random forest,[0],[0]
"It has been shown that quantile random forest is more robust than the classical random forest (Meinshausen, 2006; Roy & Larocque, 2012).",2.3. Quantile loss and quantile random forest,[0],[0]
"In this section, we show quantile random forest estimator is also a special case of Algorithm 1.",2.3. Quantile loss and quantile random forest,[0],[0]
It is well known that the τ -th quantile of an (empirical) distribution is the constant that minimizes the (empirical) risk using τ - th quantile loss function,2.3. Quantile loss and quantile random forest,[0],[0]
"ρτ (z) = z(τ −1I{z<0}) (Koenker, 2005).",2.3. Quantile loss and quantile random forest,[0],[0]
"Now let the loss function in Algorithm 1 be the quantile loss ρτ (·), F be the family of constant functions, and w(Xi, x) be random forest weights (3).",2.3. Quantile loss and quantile random forest,[0],[0]
"Solving the optimization problem
Ŷτ (x) = argmin λ∈R n∑ i=1 w(Xi, x)ρτ (Yi − λ),
we get the corresponding first order condition
n∑ i=1 w(Xi, x)(τ",2.3. Quantile loss and quantile random forest,[0],[0]
"− 1I {Yi − Ŷτ (x) < 0}) = 0.
Recall that ∑n i=1 w(Xi, x) = 1, hence, we have
n∑ i=1 w(Xi, x) 1I {Yi < Ŷτ",2.3. Quantile loss and quantile random forest,[0],[0]
"(x)} = τ. (7)
The estimator Ŷτ (x) in (7) is exactly the same estimator proposed in (Meinshausen, 2006).",2.3. Quantile loss and quantile random forest,[0],[0]
"In particular, when τ = 0.5, the equation ∑n i=1 w(Xi, x) 1I {Yi < Ŷ0.5(x)} = 0.5 will give us the median estimator Ŷ0.5(x).",2.3. Quantile loss and quantile random forest,[0],[0]
"Therefore, we have rediscovered quantile random forest from a totally different point of view as a local regression estimator with quantile loss function and random forest weights.",2.3. Quantile loss and quantile random forest,[0],[0]
"From the framework 1, quantile random forest is insensitive to outliers because of the more robust loss function.",3. Robust forest,[0],[0]
"In this section, we test our framework on other robust losses and proposed fixed-point method to solve the estimating
equation.",3. Robust forest,[0],[0]
"In Section 3.1 we choose the famous robust loss – (pseudo) Huber loss, and in Section 3.2, we further investigate a non-convex loss – Tukey’s biweight.",3. Robust forest,[0],[0]
"The Huber loss (Huber et al., 1964)
Hδ(y) =
{ 1 2y
2 for |y| ≤ δ, δ(|y| − 12δ) elsewhere
is a well-known loss function used in robust regression.",3.1. Huber loss,[0],[0]
"The penalty acts like squared error loss when the error is within [−δ, δ] but becomes linear outside this range.",3.1. Huber loss,[0],[0]
"In this way, it will penalize the outliers more lightly but still preserves more efficiency than absolute deviation when data is concentrated in the center and has light tails (e.g. Normal).",3.1. Huber loss,[0],[0]
"By plugging Huber loss into the FTR framework 1, we get a robust counterpart of random forest.",3.1. Huber loss,[0],[0]
"The estimating equation is
n∑ i=1 wi(x) sign(Ŷ (x)− Yi) min(Ŷ",3.1. Huber loss,[0],[0]
"(x)− Yi, δ) = 0.",3.1. Huber loss,[0],[0]
"(8)
Direct optimization of (8) with local weights is hard, hence instead we will investigate the pseudo-Huber loss (see Figure 1),
Lδ(y) = δ 2 (√ 1 + (y δ )2 − 1 ) which is a smooth approximation of Huber loss (Charbonnier et al., 1997).",3.1. Huber loss,[0],[0]
"The estimating equation
n∑ i=1",3.1. Huber loss,[0],[0]
wpHi (x) ( ŶpH(x)− Yi ) = 0.,3.1. Huber loss,[0],[0]
"(9)
is very similar to that of square error loss if we define a new weight
wpHi (x) = wi(x)√
1 + ( ŶpH(x)−Yi
δ )2 .",3.1. Huber loss,[0],[0]
"(10) Then the (pseudo) Huber estimator can be expressed as
ŶpH(x) =
∑n i=1",3.1. Huber loss,[0],[0]
"w
pH i (x)Yi∑n
i=1",3.1. Huber loss,[0],[0]
w pH,3.1. Huber loss,[0],[0]
"i (x)
.",3.1. Huber loss,[0],[0]
"(11)
Informally, the estimator (11) can be viewed as a weighted average of all the responses Yi’s.",3.1. Huber loss,[0],[0]
"From (10), we know the new weight for pseudo-Huber loss has an extra scaling factor (√
1 + (δ−1u)2 )−1
(12)
and hence will shrink more to zero whenever δ−1|ŶpH(x)− Yi| is large.",3.1. Huber loss,[0],[0]
The tuning parameter δ acts like a control of the level of robustness.,3.1. Huber loss,[0],[0]
"A smaller δ will lead to more shrinkage on the weights of data that have responses far away from the estimator.
",3.1. Huber loss,[0],[0]
The estimating equation (9) can be solved by fix-point method which we propose in Algorithm 2.,3.1. Huber loss,[0],[0]
"For notation simplicity, we will use wi,j to denote w(Xi, xj), where Xi is the i-th training point and xj is the j-th testing point.",3.1. Huber loss,[0],[0]
"The convergence to the unique solution (if exists) is guaranteed by Lemma 1.
",3.1. Huber loss,[0],[0]
Lemma 1.,3.1. Huber loss,[0],[0]
"Define
Kδ(y) =
∑n i=1
wiYi√ 1+( y−Yiδ )
2∑n i=1
wi√ 1+( y−Yiδ ) 2 ,
Algorithm 2 pseudo-Huber loss (δ)
",3.1. Huber loss,[0],[0]
"Input: Test points {xj}mj=1, initial guess {Ŷ (0)(xj)}, local weights wi,j , training responses {Yi}ni=1, and error tolerance 0.",3.1. Huber loss,[0],[0]
"while > 0 do
(a) Update the weights
w (k) i,j = wi,j√ 1 + ( Ŷ (k−1)(xj)−Yi
δ )2 (b) Update the estimator
Ŷ (k)(xj) =
∑n i=1",3.1. Huber loss,[0],[0]
"w
(k) i,j Yi∑n
i=1",3.1. Huber loss,[0],[0]
w (k),3.1. Huber loss,[0],[0]
"i,j
(c) Calculate error
= 1
m",3.1. Huber loss,[0],[0]
m∑ j=1,3.1. Huber loss,[0],[0]
( Ŷ k(xj)− Ŷ (k−1)(xj) )2,3.1. Huber loss,[0],[0]
(d),3.1. Huber loss,[0],[0]
k,3.1. Huber loss,[0],[0]
"← k + 1
end while Output the pseudo-Huber estimator:
ŶpH(xj) =",3.1. Huber loss,[0],[0]
"Ŷ (k)(xj)
where",3.1. Huber loss,[0],[0]
∑n i=1 wi = 1.,3.1. Huber loss,[0],[0]
"Let K = maxi=1,··· ,n |Yi|.",3.1. Huber loss,[0],[0]
"Then Algorithm 2 can be written as Ŷ (k)(x) = Kδ(Ŷ (k−1)), and converges exponentially to a unique solution as long as δ > 2K.
From Lemma 1, we know it is important to standardize the responses Yi so that δ will be of the same scale for different problems.",3.1. Huber loss,[0],[0]
"In practice, we observe that one will not need to choose δ that satisfies the worst-case condition δ",3.1. Huber loss,[0],[0]
"> K in order for convergence, but making δ too small does lead to slow convergence rate.",3.1. Huber loss,[0],[0]
"For assigning the initial guess Ŷ (0), two simplest ways are to either take the random forest estimator we got or a constant vector equaling to the sample mean.",3.1. Huber loss,[0],[0]
"Throughout the rest of this paper, we will choose the weights to be random forest weights (3).",3.1. Huber loss,[0],[0]
"Non-convex function has played an important role in the context of robust regression (Huber, 2011; Hampel et al., 2011).",3.2. Tukey’s biweight,[0],[0]
"Unlike convex losses, the penalization on the errors can be bounded and hence the contribution of outliers in the estimating equation will eventually vanish.",3.2. Tukey’s biweight,[0],[0]
"Our forest regression framework 1 also incorporates the nonconvex losses which will show through the Tukey’s biweight function Tδ(·) (Huber, 2011), which is an example
of redescending loss whose derivative will vanish to zero as the input goes outside the interval",3.2. Tukey’s biweight,[0],[0]
"[−δ, δ].",3.2. Tukey’s biweight,[0],[0]
"It is defined in the following way:
d
dy Tδ(y) = y",3.2. Tukey’s biweight,[0],[0]
"( 1− y 2 δ2 )2 for |y| ≤ δ,
0 elsewhere.
",3.2. Tukey’s biweight,[0],[0]
"Similarly, by rearranging the estimating equation, we have
Ŷtukey(x) =
∑n i=1",3.2. Tukey’s biweight,[0],[0]
"w
tukey(Xi, x)Yi∑n i=1 w tukey(Xi, x)
where
wtukey(Xi, x) = w(Xi, x) max 1− ( Ŷtukey − Yi δ )2 , 0  with an extra scaling factor (see Figure 2)
",3.2. Tukey’s biweight,[0],[0]
"max { 1− (u δ )2 , 0 } .",3.2. Tukey’s biweight,[0],[0]
"(13)
In another word, the final estimator actually only depends on data with responses inside [−δ, δ], and the importance of any data (Xi, Yi) will be shrinking to zero when |Ŷtukey(x)− Yi| gets closer to the boundary value δ.",3.2. Tukey’s biweight,[0],[0]
"In this section, we will further use the framework 1 to investigate truncated squared error loss, and use this example to motivate the relation between random forest generalization performance and the number of adaptive nearest neighbors.",4. Truncated squared loss and nearest neighbors,[0],[0]
"For the truncated squared error loss
Sδ(y) =
{ 1 2y
2 for |y| ≤ δ, 1 2δ 2 elsewhere
the corresponding estimating equation is∑ |Ŷtrunc(x)−Yi|≤δ w(Xi, x)(Ŷtrunc(x)− Yi) = 0.
If we define a new weight
wtrunc(Xi, x) = w(Xi, x) 1I{|Ŷtrunc(x)− Yi| ≤ δ}, (14)
then the estimator for truncated squared loss is
Ŷtrunc(x) =
∑n i=1",4.1. Truncated squared error,[0],[0]
"w
trunc(Xi, x)Yi∑n i=1 w trunc(Xi, x) .",4.1. Truncated squared error,[0],[0]
"(15)
The estimator (15) is like a trimmed version of the random forest estimator (2).",4.1. Truncated squared error,[0],[0]
We first sort {Yi}ni=1 and trim off the responses where |Ŷtrunc(x),4.1. Truncated squared error,[0],[0]
− Yi| > δ.,4.1. Truncated squared error,[0],[0]
"Therefore, for any truncation level δ, the estimator Ŷtrunc(x) only depends on data satisfying |Ŷtrunc(x) − Yi| ≤ δ with the same local random forest weights (1).",4.1. Truncated squared error,[0],[0]
"In classical random forest, all the data with positive weights (3) are included when calculating the final estimator Ŷ (x).",4.2. Random Forest Nearest Neighbors,[0],[0]
"However, from section 4.1, we know in order to achieve robustness, some of the data should be dropped out of consideration.",4.2. Random Forest Nearest Neighbors,[0],[0]
"For example, using the truncated squared error loss, we will only consider the data satisfying |Yi − Ŷtrunc(x)| ≤ δ.",4.2. Random Forest Nearest Neighbors,[0],[0]
"In classical random forest, the criterion of tree split is to reduce the mean squared error, then in most cases, data points inside one terminal node will tend to have more similar responses.",4.2. Random Forest Nearest Neighbors,[0],[0]
"So informally larger |Ŷtrim(x)−Yi|will indicate smaller local weightw(Xi, x).",4.2. Random Forest Nearest Neighbors,[0],[0]
"Therefore, instead of solving for (15), we investigate a related estimator
Ŷwt(x) = ∑ w(Xi,x)≥ w(Xi, x)Yi∑ w(Xi,x)≥ w(Xi, x)
(16)
where > 0 is a constant in (0, 1).",4.2. Random Forest Nearest Neighbors,[0],[0]
"Recall that in (Lin & Jeon, 2006), they show all the observations with positive weights are considered voting points for random forest estimator.",4.2. Random Forest Nearest Neighbors,[0],[0]
"However, (16) implies that we should drop observations with weights smaller than a threshold in order for the robustness.",4.2. Random Forest Nearest Neighbors,[0],[0]
"More formally, let σ be a permutation such that w(Xσ(1), x) ≥ · · · ≥ w(Xσ(n0), x) > 0, then (2) is equivalent to
Ŷ (x) = n0∑ i=1",4.2. Random Forest Nearest Neighbors,[0],[0]
"w(Xσ(i), x)Yσ(i).
",4.2. Random Forest Nearest Neighbors,[0],[0]
"Then we can define the k random forest nearest neighbors (k-RFNN) of x to be {Xσ(1), · · · , Xσ(k)}, k ≤ n0, and get predictor
Ŷk(x) = k∑ i=1 w̃(Xσ(i), x)Yσ(i), (17)
where w̃(Xσ(i), x) = w(Xσ(i), x)/ ∑k j=1 w(Xσ(i), x).",4.2. Random Forest Nearest Neighbors,[0],[0]
"In the numerical experiments (Section 5.3), we will test the performance of the estimator (17) with different k, and show that by merely choosing the right number of nearest neighbors, one can largely improve the performance of classical random forest.
Shi and Horvath (2006) proposed a similar ensemble tree based nearest neighbor method.",4.2. Random Forest Nearest Neighbors,[0],[0]
"In their approach, if the observations Xi and Xj lie in the same leaf, then the similarity between them is increased by one.",4.2. Random Forest Nearest Neighbors,[0],[0]
"At the end, the similarities are normalized by dividing the total number of trees in the forest.",4.2. Random Forest Nearest Neighbors,[0],[0]
"Therefore, their weights (similarities) w(Xi, x) will be m−1 ∑m t=1 1I{Xi∈Rl(x,θ)} contrast to (3).",4.2. Random Forest Nearest Neighbors,[0],[0]
"So different from their approach, for random forest, the similarity between Xi and Xj will be increased by 1/#{p :",4.2. Random Forest Nearest Neighbors,[0],[0]
"Xp ∈ Rl(Xi,θ)} if they both lie in the same leaf l(Xi, θ).",4.2. Random Forest Nearest Neighbors,[0],[0]
This means the increment in the similarity also depends on the number of data points in the leaf.,4.2. Random Forest Nearest Neighbors,[0],[0]
"In this section, we plug in the quantile loss, Huber loss and Tukey’s biweight loss into the general forest framework and compare these algorithms with random forest.",5. Experiments,[0],[0]
"Unless otherwise stated, for both Huber and Tukey forest, the error tolerance is set to be 10−6, and every forest is an ensemble of 1000 trees with maximum terminal node size 10.",5. Experiments,[0],[0]
"The robust parameter δ are set to be 0.005 and 0.8 for Huber and Tukey forest, respectively.",5. Experiments,[0],[0]
"We generate 1000 training data points from a Uniform distribution on [−5, 5] and another 1000 testing points from the same distribution.",5.1. One dimensional toy example,[0],[0]
"The true underlying model is Y = X2 + , ∼ N (0, 1).",5.1. One dimensional toy example,[0],[0]
"But on the training samples, we choose 20% of the data and add noise 2T2 to the responses, where T2 follows t-distribution with degree of freedom 2.
",5.1. One dimensional toy example,[0],[0]
"In Figure 3, we plot the true squared curve and different forest predictions.",5.1. One dimensional toy example,[0],[0]
"It is clear that Huber and Tukey forest achieve competitive robustness as quantile random forest, and can almost recover the true underlying distribution, but random forest is largely impacted by the outliers.",5.1. One dimensional toy example,[0],[0]
"We also repeat the experiments for 20 times, and report the average mean squared error (MSE), mean absolute deviation (MAD) and median absolute percentage error (MAPE) in Table 1.",5.1. One dimensional toy example,[0],[0]
"We generate data from 10 dimensional Normal distribution, i.e. X ∼ N10(~0,Σ).",5.2. Multivariate example,[0],[0]
"Then we test out algorithms on following models.
",5.2. Multivariate example,[0],[0]
"(1) Y = ∑10 i=1X 2 i + and ∼ N (0, 1), Σ = I.
(2) Y = ∑10 i=1X 2 i + and ∼ N (0, 1), Σ = Toeplitz(ρ = 0.7).
",5.2. Multivariate example,[0],[0]
"Then for each model, we randomly choose η proportion of the training samples and add noise 15T2 where T2 follows t-distribution with degree of freedom 2.",5.2. Multivariate example,[0],[0]
"The noise level η ∈ {0, 0.05, 0.1, 0.15, 0.2}.",5.2. Multivariate example,[0],[0]
The results are summarized in Table 2 and 3.,5.2. Multivariate example,[0],[0]
"On the clean data, random forest still play the best, however, Huber forest’s performance is also competitive and lose less efficiency than QRF and Tukey forest.",5.2. Multivariate example,[0],[0]
"On the noisy data, all three robust methods outperform random forest.",5.2. Multivariate example,[0],[0]
"Among them, Huber forest is most robust and stable.",5.2. Multivariate example,[0],[0]
"In this section, we check how the number of adaptive nearest neighbors k in (17) will have impact on the performance of k-RFNN.",5.3. Nearest neighbors,[0],[0]
"We consider the same two models (1) and (2), and keep both training sample size and testing sample size to be 1000.",5.3. Nearest neighbors,[0],[0]
"The relations between MSE, MAD and the number of adaptive nearest neighbors are illustrated in Figure 4.",5.3. Nearest neighbors,[0],[0]
Recall that k-RFNN with all 1000 neighbors is equivalent to random forest.,5.3. Nearest neighbors,[0],[0]
"From the figures, we clearly observe a kink at k = 15, which is much less than 1000.",5.3. Nearest neighbors,[0],[0]
"We take two regression datasets from UCI machine learning repository (Lichman, 2013), and one real estate dataset from OpenIntro.",5.4. Real data,[0],[0]
"For each dataset, we randomly choose 2/3 observations for training and the rest for testing.",5.4. Real data,[0],[0]
MSE and MAD are reported by averaging over 20 trials.,5.4. Real data,[0],[0]
The results are presented in Table 4.,5.4. Real data,[0],[0]
"To further test the robustness, we then repeat the experiment but add extra T2 noise to 20%
of the standardized training data response variables everytime.",5.4. Real data,[0],[0]
The results are in Table 5.,5.4. Real data,[0],[0]
"Robust forests outperform random forest in most of the cases except for Ames data sets, on which quantile random forest behaves poorly.",5.4. Real data,[0],[0]
"The experimental results show that Huber forest, Tukey forest and quantile random forest are all much more robust than random forest in the presence of outliers.",6. Conclusion and discussion,[0],[0]
"However, without outliers, Huber forest preserves more efficiency than the other two robust methods.",6. Conclusion and discussion,[0],[0]
"We did not cross validate the parameter δ for different noise levels, so one would
expect even better performance after carefully tuning the parameter.
",6. Conclusion and discussion,[0],[0]
"Besides random forest weights, other data dependent similarities could also be used in Algorithm 1.",6. Conclusion and discussion,[0],[0]
We could also design loss functions which optimizes a metric for specific problems.,6. Conclusion and discussion,[0],[0]
The fixed-point method could be replaced by other more efficient algorithms.,6. Conclusion and discussion,[0],[0]
The framework could be easily extended to classification problems.,6. Conclusion and discussion,[0],[0]
All these will be potential future work.,6. Conclusion and discussion,[0],[0]
Proof.,7.1. Proof of Lemma 1,[0],[0]
"Because Ŷ (k)(x) = Kδ(Ŷ (k−1)) which is a fixedpoint method, we only need to show ∣∣∣K ′δ(y)∣∣∣ < 1 in order for the existence and uniqueness of the solution.",7.1. Proof of Lemma 1,[0],[0]
"Define the normalized weight
w̃i = wi√
1 + ( y−Yi δ
)2 / n∑
i=1 wi√",7.1. Proof of Lemma 1,[0],[0]
"1 + ( y−Yi δ )2 , we have ∑n i=1 w̃i = 1, and
∣∣∣K ′δ(y)∣∣∣ ≤
∣∣∣∣∣∣ n∑ i=1",7.1. Proof of Lemma 1,[0],[0]
w̃iYi  n∑ j=1 (1I(i = j)− w̃j),7.1. Proof of Lemma 1,[0],[0]
y,7.1. Proof of Lemma 1,[0],[0]
− Yj δ2 +,7.1. Proof of Lemma 1,[0],[0]
(y − Yj)2,7.1. Proof of Lemma 1,[0],[0]
"∣∣∣∣∣∣ ≤ 2
n∑ i=1",7.1. Proof of Lemma 1,[0],[0]
"w̃i |Yi| max i=1,··· ,n ( |y",7.1. Proof of Lemma 1,[0],[0]
− Yi| δ2 +,7.1. Proof of Lemma 1,[0],[0]
(,7.1. Proof of Lemma 1,[0],[0]
"y − Yi)2 )
",7.1. Proof of Lemma 1,[0],[0]
= 2 n∑ i=1,7.1. Proof of Lemma 1,[0],[0]
"w̃i |Yi| 1 mini=1,··· ,n (",7.1. Proof of Lemma 1,[0],[0]
"δ2 |y−Yi| + |y − Yi| )
≤ max i=1,··· ,n
|Yi| 1
δ .
",7.1. Proof of Lemma 1,[0],[0]
"Therefore, ∣∣∣K ′δ(y)∣∣∣ < 12 if δ > 2 maxi=1,··· ,n |Yi| = 2K.",7.1. Proof of Lemma 1,[0],[0]
"We would like to thank Stan Humphrys and Zillow for supporting this research, as well as three anonymous referees for their insightful comments.",Acknowledgements,[0],[0]
Part of the implementation in this paper is based on Zillow code library.,Acknowledgements,[0],[0]
This paper introduces a new general framework for forest-type regression which allows the development of robust forest regressors by selecting from a large family of robust loss functions.,abstractText,[0],[0]
"In particular, when plugged in the squared error and quantile losses, it will recover the classical random forest (Breiman, 2001) and quantile random forest (Meinshausen, 2006).",abstractText,[0],[0]
We then use robust loss functions to develop more robust foresttype regression algorithms.,abstractText,[0],[0]
"In the experiments, we show by simulation and real data that our robust forests are indeed much more insensitive to outliers, and choosing the right number of nearest neighbors can quickly improve the generalization performance of random forest.",abstractText,[0],[0]
Forest-type Regression with General Losses  and Robust Forest,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 47–57 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Due to the advent of computing technologies to indigenous communities all over the world, natural language processing (NLP) applications
∗*The first two authors contributed equally.
for languages with limited computer-readable textual data are getting increasingly important.",1 Introduction,[0],[0]
"This contrasts with current research, which focuses strongly on approaches which require large amounts of training data, e.g., deep neural networks.",1 Introduction,[0],[0]
"Those are not trivially applicable to minimal-resource settings with less than 1, 000 available training examples.",1 Introduction,[0],[0]
"We aim at closing this gap for morphological surface segmentation, the task of splitting a word into the surface forms of its smallest meaning-bearing units, its morphemes.
",1 Introduction,[0],[0]
Recovering morphemes provides information about unknown words and is thus especially important for polysynthetic languages with a high morpheme-to-word ratio and a consequently large overall number of words.,1 Introduction,[0],[0]
"To illustrate how segmentation helps understanding unknown multiplemorpheme words, consider an example in this paper’s language of writing: even if the word unconditionally did not appear in a given training corpus, its meaning could still be derived from a combination of its morphs un, condition, al and ly.
",1 Introduction,[0],[0]
"Due to its importance for down-stream tasks (Creutz et al., 2007; Dyer et al., 2008), segmentation has been tackled in many different ways, considering unsupervised (Creutz and Lagus, 2002), supervised (Ruokolainen et al., 2013) and semisupervised settings (Ruokolainen et al., 2014).",1 Introduction,[0],[0]
"Here, we add three new questions to this line of research: (i) Are data-hungry neural network models
47
applicable to segmentation of polysynthetic languages in minimal-resource settings?",1 Introduction,[0],[0]
(ii) How can the performance of neural networks for surface segmentation be improved if we have only unlabeled or no external data at hand?,1 Introduction,[0],[0]
(iii) Is crosslingual transfer for this task possible between related languages?,1 Introduction,[0],[0]
"The last two questions are crucial: While for many languages it is difficult to obtain the number of annotated examples used in earlier work on (semi-)supervised methods, a limited amount might still be obtainable.
",1 Introduction,[0],[0]
"We experiment on four polysynthetic Mexican languages: Mexicanero, Nahuatl, Wixarika and Yorem Nokki (details in §2).",1 Introduction,[0],[0]
"The datasets we use are, as far as we know, the first computer-readable datasets annotated for morphological segmentation in those languages.
",1 Introduction,[0],[0]
Our experiments show that neural seq2seq models perform on par with or better than other strong baselines for our polysynthetic languages in a minimal-resource setting.,1 Introduction,[0],[0]
"However, we further propose two novel multi-task approaches and two new data augmentation methods.",1 Introduction,[0],[0]
"Combining them with our neural model yields up to 5.05% absolute accuracy or 3.40% F1 improvements over our strongest baseline.
",1 Introduction,[0],[0]
"Finally, following earlier work on cross-lingual knowledge transfer for seq2seq tasks (Johnson et al., 2017; Kann et al., 2017), we investigate training one single model for all languages, while sharing parameters.",1 Introduction,[0],[0]
"The resulting model performs comparably to or better than the individual models, but requires only roughly as many parameters as one single model.
",1 Introduction,[0],[0]
Contributions.,1 Introduction,[0],[0]
"To sum up, we make the following contributions: (i) we confirm the applicability of neural seq2seq models to morphological segmentation of polysynthetic languages in minimalresource settings; (ii) we propose two novel multi-task training approaches and two novel data augmentation methods for neural segmentation models; (iii) we investigate the effectiveness of cross-lingual transfer between related languages; and (iv) we provide morphological segmentation datasets for Mexicanero, Nahuatl, Wixarika and Yorem Nokki.",1 Introduction,[0],[0]
"Polysynthetic languages are morphologically rich languages which are highly synthetic, i.e., single words can be composed of many individual
morphemes.",2 Polysynthetic Languages,[0],[0]
"In extreme cases, entire sentences consist of only one single token, whereupon “every argument of a predicate must be expressed by morphology on the word that contains that assigner” (Baker, 2006).",2 Polysynthetic Languages,[0],[0]
"This property makes surface segmentation of polysynthetic languages at the same time complex and particularly relevant for further linguistic analysis.
",2 Polysynthetic Languages,[0],[0]
"In this paper, we experiment on four polysynthetic languages of the Yuto-Aztecan family (Baker, 1997), with the goal of improving the performance of neural seq2seq models.",2 Polysynthetic Languages,[0],[0]
"The languages will be described in the rest of this section.
",2 Polysynthetic Languages,[0],[0]
"Mexicanero is a Western Peripheral Nahuatl variant, spoken in the Mexican state of Durango by approximately one thousand people.",2 Polysynthetic Languages,[0],[0]
"This dialect is isolated from the rest of the other branches and has a strong process of Spanish stem incorporation, while also having borrowed some suffixes from that language (Vanhove et al., 2012).",2 Polysynthetic Languages,[0],[0]
It is common to see Spanish words mixed with Nahuatl agglutinations.,2 Polysynthetic Languages,[0],[0]
"In the following example we can see an intrasentencial mixing of Spanish (in uppercases) and Mexicanero:
u|ni|ye MALO – I was sick
Nahuatl is a large subgroup of the YutoAztecan language family, and, including all of its variants, the most spoken native language in Mexico.",2 Polysynthetic Languages,[0],[0]
"Its almost two million native speakers live mainly in Puebla, Guerrero, Hidalgo, Veracruz, and San Luis Potosi, but also in Oaxaca, Durango, Modelos, Mexico City, Tlaxcala, Michoacan, Nayarit and the State of Mexico.",2 Polysynthetic Languages,[0],[0]
"Three dialectical groups are known: Central Nahuatl, Occidental Nahuatl and Oriental Nahuatl.",2 Polysynthetic Languages,[0],[0]
"The data collected for this work belongs to the Oriental branch spoken by 70 thousand people in Northern Puebla.
",2 Polysynthetic Languages,[0],[0]
"Like all languages of the Yuto-Aztecan family, Nahuatl is agglutinative and one word can consist of a combination of many different morphemes.",2 Polysynthetic Languages,[0],[0]
"Usually, the verb functions as the stem and gets extended by morphemes specifying, e.g., subject, patient, object or indirect object.",2 Polysynthetic Languages,[0],[0]
The most common syntax sequence for Nahuatl is SOV.,2 Polysynthetic Languages,[0],[0]
"An example word is:
o|ne|mo|kokowa|ya – I was sick
Wixarika is a language spoken in the states of Jalisco, Nayarit, Durango and Zacatecas in Central West Mexico by approximately fifty thousand people.",2 Polysynthetic Languages,[0],[0]
It belongs to the Coracholan group of languages within the Yuto-Aztecan family.,2 Polysynthetic Languages,[0],[0]
"Wixarika has five vowels {a,e,i,+1,u} with long and short variants.",2 Polysynthetic Languages,[0],[0]
"An example for a word in the language is:
ne|p+|ti|kuye|kai – I was sick
Like Nahuatl, it has an SOV syntax, with heavy agglutination on the verb.",2 Polysynthetic Languages,[0],[0]
"Wixarika is morphologically more complex than other languages from the same family, because it incorporates more information into the verb (Leza and López, 2006).",2 Polysynthetic Languages,[0],[0]
"This leads to a higher number of morphemes per word as can also be seen in Table 3.
",2 Polysynthetic Languages,[0],[0]
Yorem Nokki is part of Taracachita subgroup of the Yuto-Aztecan language family.,2 Polysynthetic Languages,[0],[0]
"Its Southern dialect is spoken by close to forty thousand people in the Mexican states of Sinaloa and Sonora, while its Northern dialect has about twenty thousand speakers.",2 Polysynthetic Languages,[0],[0]
"In this work, we consider the Southern dialect.",2 Polysynthetic Languages,[0],[0]
"The nominal morphology of Yorem
1While linguists often use a dashed i (i) to denote this vowel, in practice almost all native speakers use a plus symbol (+).",2 Polysynthetic Languages,[0],[0]
"In this work, we choose to use the latter.
",2 Polysynthetic Languages,[0],[0]
"Nokki is rather simple, but, like in the other YutoAztecan languages, the verb is highly complex.",2 Polysynthetic Languages,[0],[0]
Its alphabet consists of 28 characters and contains 8 different vowels.,2 Polysynthetic Languages,[0],[0]
"An example verb is:
ko’kore|ye|ne – I was sick",2 Polysynthetic Languages,[0],[0]
"To create our datasets, we make use of both segmentable (i.e., consisting of multiple morphemes) and non-segmentable (i.e., consisting of one single morpheme) words described in books of the collection Archive of Indigenous Languages in Mexicanero (Canger, 2001), Nahuatl (Lastra de Suárez, 1980), Wixarika (Gómez and López, 1999), and Yorem Nokki (Freeze, 1989).",3 Morphological Segmentation Datasets,[0],[0]
"Statistics about the data in the four languages are displayed in Tables 1, 2 and 3.",3 Morphological Segmentation Datasets,[0],[0]
We include segmentable as well as non-segmentable words into our datasets in order to ensure that our methods can correctly decide against splitting up single morphemes.,3 Morphological Segmentation Datasets,[0],[0]
"The phrases in all languages are mostly parallel, such that the corpora are roughly equivalent.",3 Morphological Segmentation Datasets,[0],[0]
"Therefore, we can compare the morphology of translated words (cf. Table 3), noticing that the language with most agglutination is Wixarika, with an average rate of 3.25 morphemes per word; the other languages have an average of close to 2.2 morphemes per word.",3 Morphological Segmentation Datasets,[0],[0]
This higher morphological complexity naturally produces data sparsity at the token level.,3 Morphological Segmentation Datasets,[0],[0]
"Also, we can notice that Wixarika has more unique words than the rest of our studied languages.",3 Morphological Segmentation Datasets,[0],[0]
"However, Nahuatl has with 810 the highest number of unique morphemes.
",3 Morphological Segmentation Datasets,[0],[0]
Final splits.,3 Morphological Segmentation Datasets,[0],[0]
"In order to make follow-up work on minimal-resource settings for morphological segmentation easily comparable, we provide predefined splits of our datasets2.",3 Morphological Segmentation Datasets,[0],[0]
40% of the data constitute the test sets.,3 Morphological Segmentation Datasets,[0],[0]
"Of the remaining data, we
2Our datasets can be found together with the code of our models at http://turing.iimas.unam.mx/wix/MexSeg .
use 20% for development and the rest for training.",3 Morphological Segmentation Datasets,[0],[0]
The final numbers of words per dataset and language are shown in Table 2.,3 Morphological Segmentation Datasets,[0],[0]
"In the beginning of this section, we will introduce our neural architecture for segmentation.",4 Neural Seq2seq Models for Segmentation,[0],[0]
"Subsequently, we will first describe our two proposed multi-task training approaches and second our data augmentation methods.",4 Neural Seq2seq Models for Segmentation,[0],[0]
"Finally, we will elaborate on expected differences between the two.",4 Neural Seq2seq Models for Segmentation,[0],[0]
"Following work on segmentation by Kann et al. (2016) for high-resource settings, our approach is based on the neural seq2seq model introduced by Bahdanau et al. (2015) for machine translation.
Encoder.",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"The first part of our model is a bidirectional recurrent neural network (RNN) which encodes the input sequence, i.e., the sequence of characters of a given word w = w1, w2, . . .",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
", wTv , represented by the corresponding embedding vectors vw1 , ..., vwTv .",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"In particular, our encoder consists of one gated recurrent neural network (GRU) which processes the input in forward direction and a second GRU which processes the input from the opposite side.
",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
Encoding with this bidirectional GRU yields the forward hidden state −→ h i = f,4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"(−→ h i−1, vi ) and the backward hidden state ←−",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
h,4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"i = f (←− h i+1, vi ) , for a non-linear activation function f .",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
Their concatenation hi =,4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"[−→ hi ; ←− hi ] is passed on to the decoder.
",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
Decoder.,4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"The second part of our network, the decoder, is a single GRU, defining a probability distribution over strings in (Σ ∪ S)∗, for an alphabet Σ and a separation symbol S:
pED(c | w) = Tc∏
t=1
p(ct | c1, . . .",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
", ct−1, w).",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"(1)
where p(ct | c1, . . .",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
", ct−1, w) is computed using an attention mechanism and an output softmax layer over Σ ∪ S.
A more detailed description of the general attention-based encoder-decoder architecture can be found in the original paper by Bahdanau et al. (2015).",4.1 Character-Based Encoder-Decoder RNN,[0],[0]
"In order to leverage unlabeled data or even random strings during training, we define an autoencoding auxiliary task, which consists of encoding the input and decoding an output which is identical to the original string.
",5.1 Multi-Task Training,[0],[0]
"Then, our multi-task training objective is to maximize the joint log-likelihood of this auxiliary task and our segmentation main task:
L(θ)= ∑
(w,c)∈T log pθ (c | e(w))",5.1 Multi-Task Training,[0],[0]
"(2)
+ ∑
a∈A log pθ(a | e(a))
",5.1 Multi-Task Training,[0],[0]
T denotes the segmentation training data with examples consisting of a word w and its segmentation c. A denotes either a set of words in the language of the system or a set of random strings.,5.1 Multi-Task Training,[0],[0]
"The function e describes the encoder and depends on the model parameters θ, which are shared across the two tasks.",5.1 Multi-Task Training,[0],[0]
"For training, we use data from both sets at the same time and mark each example with an additional, task-specific input symbol.
",5.1 Multi-Task Training,[0],[0]
We treat the size of A as a hyperparameter which we optimize on the development set separately for each language.,5.1 Multi-Task Training,[0],[0]
"Values we experiment with are m times the amount of instances in the original training set, with m ∈ {1, 2, 4, 8}.3
3An exception is Yorem Nokki, for which we do not have enough unlabeled data available, such that we experiment only with m ∈ {1, 2}.
",5.1 Multi-Task Training,[0],[0]
There are multiple reasons why we expect multi-task training to improve the performance of the final model.,5.1 Multi-Task Training,[0],[0]
"First, multi-task training should act as a regularizer.",5.1 Multi-Task Training,[0],[0]
"Second, for our models, the segmentation task consists in large parts of learning to copy the input character sequence to the output.",5.1 Multi-Task Training,[0],[0]
"This, however, can be learned from any string and does not require annotated segmentation boundaries.",5.1 Multi-Task Training,[0],[0]
"Third, in the case of unlabeled data (i.e., not for random strings), we expect the character language model in the decoder to improve, since it is trained on additional data.
",5.1 Multi-Task Training,[0],[0]
We denote models trained with multi-task training using unlabeled corpus data as MTT-U and models trained with multi-task training using random strings as MTT-R.,5.1 Multi-Task Training,[0],[0]
A second option to make use of unlabeled data or random strings is to extend the available training data with new examples made from those.,5.2 Data Augmentation,[0],[0]
The main question to answer here is how to include the new data into the existing datasets.,5.2 Data Augmentation,[0],[0]
We do this by building new training examples in a fashion similar to the multi-task setup.,5.2 Data Augmentation,[0],[0]
"All newly created instances are of the form
w 7→ w (3)
where either w ∈ V with V being the observed vocabulary of the language, e.g., words in a given unlabeled corpus, or w ∈ R with R being a set of sequences of random characters from the alphabet Σ of the language.
",5.2 Data Augmentation,[0],[0]
"Again, we treat the amount of additional training examples as a hyperparameter which we optimize on the development set separately for each language.",5.2 Data Augmentation,[0],[0]
"We explore m times the amount of instances in the original training set, with m ∈ {1, 2, 4, 8}.
",5.2 Data Augmentation,[0],[0]
"The reasons why we expect our data augmentation methods to lead to better segmentation models are similar to those for multi-task training.
",5.2 Data Augmentation,[0],[0]
"We call models trained on datasets augmented with unlabeled corpus data or random strings DAU or DA-R, respectively.",5.2 Data Augmentation,[0],[0]
The difference between MTT-U (resp.,5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
MTT-R) and DA-U (resp.,5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"MTT-U) is a single element in the input sequence (the one representing the task).
",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"However, this information enables the model to handle each given instance correctly at inference time.",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"As a result, it gets more robust against noisy data, which seems crucial for our way of using unlabeled corpora.",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"Consider, for example, the Nahuatl word onemokokowaya.",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"Training on
onemokokowaya 7→ onemokokowaya
will make the model learn not to segment words which consist of the morphemes o, ne,mo, kokowa, ya, which should ultimately hurt performance.",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"The multi-task approach, in contrast, mitigates this problem.
",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"As a conclusion, we expect the data augmentation approach with unlabeled data to not obtain outstanding performance, but rather consider it an important and informative baseline for the corresponding multi-task approach.",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
"Using random strings, the difference between the multi-task and the data augmentation approaches is less obvious: Real morphemes should appear rarely enough in the created random character sequences to avoid the negative effect which we expect for corpus words.",5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
We thus assume that the performances of MTT-R and DA-R should be similar.,5.3 Differences Between Multi-task Training and Data Augmentation,[0],[0]
We apply our models to the datasets described in §3.,6.1 Data,[0],[0]
"For the multi-task training and data augmentation using unlabeled data, we use (unsegmented) words from a parallel corpus collected by Gutierrez-Vasques et al. (2016) for Nahuatl and the closely related Mexicanero.",6.1 Data,[0],[0]
For Wixarika we use data from Mager et al. (2018) and for Yorem Nokki we use text from Maldonado,6.1 Data,[0],[0]
Martı́nez,6.1 Data,[0],[0]
et al. (2010).,6.1 Data,[0],[0]
"Now, we will describe the baselines we use to evaluate the overall performance of our approaches.
",6.2 Baselines,[0],[0]
Supervised seq2seq RNN (S2S).,6.2 Baselines,[0],[0]
"As a first baseline, we employ a fully supervised neural model without data augmentation or multi-task training, i.e., an attention-based encoder-decoder RNN (Bahdanau et al., 2015) which has been trained only on the available annotated data.
",6.2 Baselines,[0],[0]
Semi-supervised MORFESSOR (MORF).,6.2 Baselines,[0],[0]
"We further compare to the semi-supervised version
of MORFESSOR (Kohonen et al., 2010), a wellknown morphological segmentation system.",6.2 Baselines,[0],[0]
"During training, we tune the hyperparameters for each language on the respective development set.",6.2 Baselines,[0],[0]
"The best performing model is applied to the test set.
",6.2 Baselines,[0],[0]
FlatCat (FC).,6.2 Baselines,[0],[0]
"Our next baseline is FlatCat (Grönroos et al., 2014), a variant of MORFESSOR.",6.2 Baselines,[0],[0]
It consists of a hidden Markov model for segmentation.,6.2 Baselines,[0],[0]
"The states of the model correspond either to a word boundary and one of the four morph categories stem, prefix, suffix, and nonmorpheme.",6.2 Baselines,[0],[0]
"It can work in an unsupervised way, but, similar to the previous baseline, can make effective use of small amounts of labeled data.
CRF.",6.2 Baselines,[0],[0]
"We further compare to a conditional random fields (CRF) (Lafferty et al., 2001) model, in particular a strong discriminative model for segmentation by Ruokolainen et al. (2014).",6.2 Baselines,[0],[0]
"It reduces the task to a classification problem with four classes: beginning of a morph, middle of a morph, end of a morph and single character morph.",6.2 Baselines,[0],[0]
"Training is again semi-supervised and the model was previously reported to obtain good results for small amounts of unlabeled data (Ruokolainen et al., 2014), which makes it very suitable for our minimal-resource setting.",6.2 Baselines,[0],[0]
Neural network parameters.,6.3 Hyperparameters,[0],[0]
All GRUs in both the encoder and the decoder have 100- dimensional hidden states.,6.3 Hyperparameters,[0],[0]
"All embeddings are 300-dimensional.
",6.3 Hyperparameters,[0],[0]
"For training, we use ADADELTA (Zeiler, 2012) with a minibatch size of 20.",6.3 Hyperparameters,[0],[0]
"We initialize all weights to the identity matrix and biases to zero (Le et al., 2015).",6.3 Hyperparameters,[0],[0]
"All models are trained for a maximum of 200 epochs, but we evaluate after every 5 epochs and apply the best performing model at test time.",6.3 Hyperparameters,[0],[0]
"Our final reported results are averaged accuracies over 5 single training runs.
",6.3 Hyperparameters,[0],[0]
Optimizing the amount of auxiliary task data.,6.3 Hyperparameters,[0],[0]
The performance of our neural segmentation model in dependence of the amount of auxiliary task training data can be seen in Figure 1.,6.3 Hyperparameters,[0],[0]
"As a general tendency across all languages, adding more data seems better, particularly for the autoencoding task with random strings.",6.3 Hyperparameters,[0],[0]
"The only exception is Wixarika.
",6.3 Hyperparameters,[0],[0]
The final configurations we choose for m (cf.,6.3 Hyperparameters,[0],[0]
"§5.1) in the case of multi-task training with the
auxiliary task of autoencoding corpus data are m = 4 for Mexicanero, Nahuatl and Wixarika and m = 1 for Yorem Nokki.",6.3 Hyperparameters,[0],[0]
"For multi-task training with autoencoding of random strings we select m = 8 for Mexicanero, Nahuatl and Yorem Nokki and m = 4 for Wixarika.
Optimizing the amount of artificial training data for data augmentation.",6.3 Hyperparameters,[0],[0]
Figure 2 shows the performance of the encoder-decoder depending on the amount of added artificial training data.,6.3 Hyperparameters,[0],[0]
"In the case of random strings, again, adding more training data seems to help more.",6.3 Hyperparameters,[0],[0]
"However, using corpus data seems to hurt performance and the more such examples we use, the worse accuracy we obtain.",6.3 Hyperparameters,[0],[0]
"Thus, we conclude that (as expected) data augmentation with corpus data is not a good way to improve the model’s performance.",6.3 Hyperparameters,[0],[0]
"We will discuss this in more detail in §6.5.
",6.3 Hyperparameters,[0],[0]
"Even though the final conclusion should be to not add much corpus data, we apply what gives best results on the development set.",6.3 Hyperparameters,[0],[0]
"The final configurations we thus choose for DA-U are m = 1 for Mexicanero, Wixarika and Yorem Nokki and m = 2 for Nahuatl.",6.3 Hyperparameters,[0],[0]
"For DA-R, we select m = 4 for Mexicanero, Wixarika and Yorem Nokki and m = 8 for Nahuatl.",6.3 Hyperparameters,[0],[0]
Accuracy.,6.4 Evaluation Metrics,[0],[0]
"First, we evaluate using accuracy on the token level.",6.4 Evaluation Metrics,[0],[0]
"Thus, an example counts as correct if and only if the output of the system matches the reference solution exactly, i.e., if all output symbols are predicted correctly.
F1.",6.4 Evaluation Metrics,[0],[0]
"Our second evaluation metric is border F1, which measures how many segment boundaries are predicted correctly by the model.",6.4 Evaluation Metrics,[0],[0]
"While we use this metric because it is common for segmentation tasks, it is not ideal for our models since those are not guaranteed to preserve the input character sequence.",6.4 Evaluation Metrics,[0],[0]
We handle this problem as follows:,6.4 Evaluation Metrics,[0],[0]
"In order to compare borders, we identify them by the position of their preceding letter, i.e., if in both the model’s guess and the gold solution a segment border appears after the second character, it counts as correct.",6.4 Evaluation Metrics,[0],[0]
Wrong characters are ignored.,6.4 Evaluation Metrics,[0],[0]
Note that this comes with the disadvantage of erroneously inserted characters leading to all subsequent segment borders being counted as incorrect.,6.4 Evaluation Metrics,[0],[0]
Table 4 shows that accuracy and F1 seem to be highly correlated for our task.,6.5 Test Results and Discussion,[0],[0]
"The test results also give an answer to our first research question: The neural model S2S performs on par with CRF, the strongest baseline, for all languages but Nahuatl.",6.5 Test Results and Discussion,[0],[0]
"Further, S2S and CRF both outperform MORF and FC by a wide margin.",6.5 Test Results and Discussion,[0],[0]
"We may thus conclude that neural models are indeed applicable to segmentation of polysynthetic languages in a low-resource setting.
",6.5 Test Results and Discussion,[0],[0]
"Second, we can see that all our proposed methods except for DA-U improve over S2S, the neural baseline: The accuracy of MTT-U is between 0.0141 (Wixarika) and 0.0547 (Mexicanero) higher than S2S’s.",6.5 Test Results and Discussion,[0],[0]
"MTT-R improves between 0.0380 (Wixarika) and 0.0532 (Yorem
Nokki).",6.5 Test Results and Discussion,[0],[0]
"Finally, DA-R outperforms S2S by 0.0367 to 0.0479 accuracy for Yorem Nokki and Mexicanero, respectively.",6.5 Test Results and Discussion,[0],[0]
The overall picture when considering F1 looks similar.,6.5 Test Results and Discussion,[0],[0]
"Comparing our approaches to each other, there is no clear winner.",6.5 Test Results and Discussion,[0],[0]
This might be due to differences in the unlabeled data we use: the corpus we use for Mexicanero and Nahuatl is from dialects different from both respective test sets.,6.5 Test Results and Discussion,[0],[0]
"Assuming that the effect of training a language model using unlabeled data and erroneously learning to not segment words are working against each other for MTT-U, this might explain why MTT-U is best for Mexicanero and the gap between MTT-U and MTT-R is smaller for Nahuatl than for Yorem Nokki and Wixarika.
",6.5 Test Results and Discussion,[0],[0]
"As mentioned before (cf. §5.3), a simple data augmentation method using unlabeled data should
hurt performance.",6.5 Test Results and Discussion,[0],[0]
"This is indeed the result of our experiments: DA-U performs worse than S2S for all languages except for Mexicanero, where the unlabeled corpus is from another language: the closely related Nahuatl.",6.5 Test Results and Discussion,[0],[0]
"We thus conclude that multi-task training (instead of simple data augmentation) is crucial for the use of unlabeled data.
",6.5 Test Results and Discussion,[0],[0]
"Finally, our methods compare favorably to all baselines, with the exception of CRF for Nahuatl.",6.5 Test Results and Discussion,[0],[0]
"While CRF is overall the strongest baseline for our considered languages, our methods outperform it by up to 0.0214 accuracy or 0.0147 F1 for Mexicanero, 0.0322 accuracy or 0.0229 F1 for Wixarika and 0.0505 accuracy or 0.0340 F1 for Yorem Nokki.",6.5 Test Results and Discussion,[0],[0]
This shows the effectiveness of our fortified neural models for minimal-resource morphological segmentation.,6.5 Test Results and Discussion,[0],[0]
We now want to investigate the performance of one single model trained on all languages at once.,7 Cross-Lingual Transfer Learning,[0],[0]
This is done in analogy to the multi-task training described in §5.1.,7 Cross-Lingual Transfer Learning,[0],[0]
"We treat segmentation in each language as a separate task and train an attentionbased encoder-decoder model on maximizing the joint log-likelihood:
L(θ)= ∑
Li∈L
∑
(w,c)∈TLi
log pθ (c | e(w))
(4)
TLi denotes the segmentation training data in language Li and L is the set of our languages.",7 Cross-Lingual Transfer Learning,[0],[0]
"As before, each training example consists of a word w and its segmentation c.",7 Cross-Lingual Transfer Learning,[0],[0]
We keep all model parameters and the training regime as described in §6.3.,7.1 Experimental Setup,[0],[0]
"However, our training data now consists of a combination of all available training data for all 4 languages.",7.1 Experimental Setup,[0],[0]
"In order to enable the model to differentiate between the tasks,
we prepend one language-specific input symbol to each instance.",7.1 Experimental Setup,[0],[0]
This corresponds to having one embedding in the input which marks the task.,7.1 Experimental Setup,[0],[0]
"An example training instance for Yorem Nokki is
L=YN ko′koreyene 7→ ko′kore|ye|ne,
where L=YN indicates the language.",7.1 Experimental Setup,[0],[0]
Due to the previous high correlation between accuracy and F1 we only use accuracy on the word level as the evaluation metric for this experiment.,7.1 Experimental Setup,[0],[0]
"In Table 5, we show the results of the multi-lingual model, which was trained on all languages, compared to all individual models, as well as each respective best multi-task approach and data augmentation method.",7.2 Results and Discussion,[0],[0]
"The results differ among languages: Most remarkably, for both Wixarika and Nahuatl, the accuracy of the multi-lingual model is higher than the one of the single-language model.",7.2 Results and Discussion,[0],[0]
"This might be related to them being the languages with most training data available (cf. Table 3).
",7.2 Results and Discussion,[0],[0]
"Note, however, that even for the remaining two languages—Mexicanero and Yorem Nokki— we hardly lose accuracy when comparing the multi-lingual to the individual models.",7.2 Results and Discussion,[0],[0]
"Since we only use one model (instead of four), without increasing its size significantly, we thus reduce the amount of parameters by nearly 75%.",7.2 Results and Discussion,[0],[0]
"Work on morphological segmentation was started more than 6 decades ago (Harris, 1951).",8 Related Work,[0],[0]
"Since then, many approaches have been developed: In the realm of unsupervised methods, two important systems are LINGUISTICS (Goldsmith, 2001) and MORFESSOR (Creutz and Lagus, 2002).",8 Related Work,[0],[0]
"The latter was later extended to a semi-supervised version (Kohonen et al., 2010) in order to make use of the abundance of unlabeled data which is available for many languages.
",8 Related Work,[0],[0]
Ruokolainen et al. (2013) focused explicitly on low-resource scenarios and applied CRFs to morphological segmentation in several languages.,8 Related Work,[0],[0]
"They reported better results than earlier work, including semi-supervised approaches.",8 Related Work,[0],[0]
"In the following year, they extended their approach to be able to use unlabeled data as well, further improving performance (Ruokolainen et al., 2014).
",8 Related Work,[0],[0]
"Cotterell et al. (2015) trained a semi-Markov CRF (semi-CRF) (Sarawagi and Cohen, 2005) jointly on morphological segmentation, stemming and tagging.",8 Related Work,[0],[0]
"For the similar problem of Chinese word segmentation, Zhang and Clark (2008) trained a model jointly on part-of-speech tagging.",8 Related Work,[0],[0]
"However, we are not aware of any prior work on multi-task training or data augmentation for neural segmentation models.
",8 Related Work,[0],[0]
"In fact, the two only neural seq2seq approaches for morphological segmentation we know of focused on canonical segmentation (Cotterell et al., 2016) which differs from the surface segmentation task considered here in that it restores changes to the surface form of morphemes which occurred during word formation.",8 Related Work,[0],[0]
Kann et al. (2016) also used an encoder-decoder RNN and combined it with a neural reranker.,8 Related Work,[0],[0]
"While our model architecture was inspired by them, their model was purely supervised.",8 Related Work,[0],[0]
"Additionally, they did not investigate the applicability of their neural seq2seq model in low-resource settings or for polysynthetic languages.",8 Related Work,[0],[0]
Ruzsics and Samardzic (2017) extended the standard encoder-decoder architecture for canonical segmentation to contain a language model over segments and improved results.,8 Related Work,[0],[0]
"However, a big difference to our work is that they still used more than ten times as much training data as we have available for the indigenous Mexican languages we are working on here.
",8 Related Work,[0],[0]
"Another neural approach—this time for surface segmentation—was presented by Wang et al.
(2016).",8 Related Work,[0],[0]
"The authors, instead of using seq2seq models, treat the task as a sequence labeling problem and use LSTMs to classify every character either as the beginning, middle or end of a morpheme, or as a single-character morpheme.
",8 Related Work,[0],[0]
"Cross-lingual knowledge transfer via language tags was proposed for neural seq2seq models before, both for tasks that handle sequences of words (Johnson et al., 2017) and tasks that work on sequences of characters (Kann et al., 2017).",8 Related Work,[0],[0]
"However, to the best of our knowledge, we are the first to try such an approach for a morphological segmentation task.",8 Related Work,[0],[0]
"In many other areas of NLP, cross-lingual transfer has been applied successfully, e.g., in entity recognition (Wang and Manning, 2014), language modeling (Tsvetkov et al., 2016), or parsing (Cohen et al., 2011; Søgaard, 2011; Ammar et al., 2016).",8 Related Work,[0],[0]
"We first investigated the applicability of neural seq2seq models to morphological surface segmentation for polysynthetic languages in minimalresource settings, i.e., for considerably less than 1, 000 training instances.",9 Conclusion and Future Work,[0],[0]
"Although they are generally thought to require large amounts of training data, neural networks obtained an accuracy comparable to or higher than several strong baselines.
",9 Conclusion and Future Work,[0],[0]
"Subsequently, we proposed two novel multitask training approaches and two novel data augmentation methods to further increase the performance of our neural models.",9 Conclusion and Future Work,[0],[0]
"Adding those, we improved over the neural baseline for all languages, and for Mexicanero, Wixarika and Yorem Nokki our final models outperformed all baselines by up to 5.05% absolute accuracy or 3.40% F1.",9 Conclusion and Future Work,[0],[0]
"Furthermore, we explored cross-lingual transfer between our languages and reduced the amount of necessary model parameters by about 75%, while improving performance for some of the languages.
",9 Conclusion and Future Work,[0],[0]
"We publically release our datasets for morphological surface segmentation of the polysynthetic minimal-resource languages Mexicanero, Nahuatl, Wixarika and Norem Yokki.",9 Conclusion and Future Work,[0],[0]
"We would like to thank Paulina Grnarova, Rodrigo Nogueira and Ximena Gutierrez-Vasques for their helpful feedback.",Acknowledgments,[0],[0]
"Morphological segmentation for polysynthetic languages is challenging, because a word may consist of many individual morphemes and training data can be extremely scarce.",abstractText,[0],[0]
"Since neural sequence-to-sequence (seq2seq) models define the state of the art for morphological segmentation in high-resource settings and for (mostly) European languages, we first show that they also obtain competitive performance for Mexican polysynthetic languages in minimal-resource settings.",abstractText,[0],[0]
"We then propose two novel multi-task training approaches— one with, one without need for external unlabeled resources—, and two corresponding data augmentation methods, improving over the neural baseline for all languages.",abstractText,[0],[0]
"Finally, we explore cross-lingual transfer as a third way to fortify our neural model and show that we can train one single multi-lingual model for related languages while maintaining comparable or even improved performance, thus reducing the amount of parameters by close to 75%.",abstractText,[0],[0]
"We provide our morphological segmentation datasets for Mexicanero, Nahuatl, Wixarika and Yorem Nokki for future research.",abstractText,[0],[0]
Fortification of Neural Morphological Segmentation Models for Polysynthetic Minimal-Resource Languages,title,[0],[0]
"The increasing complexity of machine learning algorithms has driven a large amount of research in the area of hyperparameter optimization (HO) — see, e.g., (Hutter et al., 2015) for a review.",1. Introduction,[0],[0]
"The core idea is relatively simple: given a measure of interest (e.g. the misclassification error) HO methods use a validation set to construct a response function of the hyperparameters (such as the average loss on the validation set) and explore the hyperparameter space to seek an optimum.
",1. Introduction,[0],[0]
"Early approaches based on grid search quickly become impractical as the number of hyperparameters grows and are even outperformed by random search (Bergstra & Bengio, 2012).",1. Introduction,[0],[0]
"Given the high computational cost of evaluating the
1Computational Statistics and Machine Learning, Istituto Italiano di Tecnologia, Genoa, Italy 2Department of Computer Science, University College London, UK 3Department of Information Engineering, Università degli Studi di Firenze, Italy.",1. Introduction,[0],[0]
"Correspondence to: Luca Franceschi <luca.franceschi@iit.it>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
response function, Bayesian optimization approaches provide a natural framework and have been extensively studied in this context (Snoek et al., 2012; Swersky et al., 2013; Snoek et al., 2015).",1. Introduction,[0],[0]
"Related and faster sequential modelbased optimization methods have been proposed using random forests (Hutter et al., 2011) and tree Parzen estimators (Bergstra et al., 2011), scaling up to a few hundreds of hyperparameters (Bergstra et al., 2013).
",1. Introduction,[0],[0]
"In this paper, we follow an alternative direction, where gradient-based algorithms are used to optimize the performance on a validation set with respect to the hyperparameters (Bengio, 2000; Larsen et al., 1996).",1. Introduction,[0],[0]
"In this setting, the validation error should be evaluated at a minimizer of the training objective.",1. Introduction,[0],[0]
"However, in many current learning systems such as deep learning, the minimizer is only approximate.",1. Introduction,[0],[0]
"Domke (2012) specifically considered running an iterative algorithm, like gradient descent or momentum, for a given number of steps, and subsequently computing the gradient of the validation error by a back-optimization algorithm.",1. Introduction,[0],[0]
Maclaurin et al. (2015) considered reverse-mode differentiation of the response function.,1. Introduction,[0],[0]
"They suggested the idea of reversing parameter updates to achieve space efficiency, proposing an approximation capable of addressing the associated loss of information due to finite precision arithmetics.",1. Introduction,[0],[0]
"Pedregosa (2016) proposed the use of inexact gradients, allowing hyperparameters to be updated before reaching the minimizer of the training objective.",1. Introduction,[0],[0]
"Both (Maclaurin et al., 2015) and (Pedregosa, 2016) managed to optimize a number of hyperparameters in the order of one thousand.
",1. Introduction,[0],[0]
"In this paper, we illustrate two alternative approaches to compute the hypergradient (i.e., the gradient of the response function), which have different trade-offs in terms of running time and space requirements.",1. Introduction,[0],[0]
One approach is based on a Lagrangian formulation associated with the parameter optimization dynamics.,1. Introduction,[0],[0]
"It encompasses the reverse-mode differentiation (RMD) approach used by Maclaurin et al. (2015), where the dynamics corresponds to stochastic gradient descent with momentum.",1. Introduction,[0],[0]
We do not assume reversible parameter optimization dynamics.,1. Introduction,[0],[0]
A well-known drawback of RMD is its space complexity: we need to store the whole trajectory of training iterates in order to compute the hypergradient.,1. Introduction,[0],[0]
"An alternative approach that we consider overcomes this problem by computing
the hypergradient in forward-mode and it is efficient when the number of hyperparameters is much smaller than the number of parameters.",1. Introduction,[0],[0]
"To the best of our knowledge, the forward-mode has not been studied before in this context.
",1. Introduction,[0],[0]
"As we shall see, these two approaches have a direct correspondence to two classic alternative ways of computing gradients for recurrent neural networks (RNN) (Pearlmutter, 1995): the Lagrangian (reverse) way corresponds to back-propagation through time (Werbos, 1990), while the forward way corresponds to real-time recurrent learning (RTRL) (Williams & Zipser, 1989).",1. Introduction,[0],[0]
"As RTRL allows one to update parameters after each time step, the forward approach is suitable for real-time hyperparameter updates, which may significantly speed up the overall hyperparameter optimization procedure in the presence of large datasets.",1. Introduction,[0],[0]
We give experimental evidence that the real-time approach is efficient enough to allow for the automatic tuning of crucial hyperparameters in a deep learning model.,1. Introduction,[0],[0]
"In our experiments, we also explore constrained hyperparameter optimization, showing that it can be used effectively to detect noisy examples and to discover the relationships between different learning tasks.
",1. Introduction,[0],[0]
The paper is organized in the following manner.,1. Introduction,[0],[0]
In Section 2 we introduce the problem under study.,1. Introduction,[0],[0]
In Section 3.1 we derive the reverse-mode computation.,1. Introduction,[0],[0]
"In Section 3.2 we present the forward-mode computation of the hypergradient, and in Section 3.3 we introduce the idea of real-time hyperparameter updates.",1. Introduction,[0],[0]
In Section 4 we discuss the time and space complexity of these methods.,1. Introduction,[0],[0]
In Section 5 we present empirical results with both algorithms.,1. Introduction,[0],[0]
Finally in Section 6 we discuss our findings and highlight directions of future research.,1. Introduction,[0],[0]
We focus on training procedures based on the optimization of an objective function J(w) with respect to w (e.g. the regularized average training loss for a neural network with weights w).,2. Hyperparameter Optimization,[0],[0]
"We see the training procedure by stochastic gradient descent (or one of its variants like momentum, RMSProp, Adam, etc.)",2. Hyperparameter Optimization,[0],[0]
as a dynamical system with a state st ∈ Rd that collects weights and possibly accessory variables such as velocities and accumulated squared gradients.,2. Hyperparameter Optimization,[0],[0]
"The dynamics are defined by the system of equations
st = Φt(st−1, λ) t = 1, . . .",2. Hyperparameter Optimization,[0],[0]
", T (1)
where T is the number of iterations, s0 contains initial weights and initial accessory variables, and, for every t ∈ {1, . . .",2. Hyperparameter Optimization,[0],[0]
", T},
Φt : (Rd × Rm)→",2. Hyperparameter Optimization,[0],[0]
"Rd
is a smooth mapping that represents the operation performed by the t-th step of the optimization algorithm (i.e.
on mini-batch t).",2. Hyperparameter Optimization,[0],[0]
"Finally, λ ∈ Rm is the vector of hyperparameters that we wish to tune.
",2. Hyperparameter Optimization,[0],[0]
"As simple example of these dynamics occurs when training a neural network by gradient descent with momentum (GDM), in which case st = (vt, wt) and
vt = µvt−1 +∇Jt(wt−1) wt = wt−1 − η(µvt−1 −∇Jt(wt−1))
(2)
where Jt is the objective associated with the t-th minibatch, µ is the rate and η is the momentum.",2. Hyperparameter Optimization,[0],[0]
"In this example, λ = (µ, η).
",2. Hyperparameter Optimization,[0],[0]
"Note that the iterates s1, . . .",2. Hyperparameter Optimization,[0],[0]
", sT implicitly depend on the vector of hyperparameters λ.",2. Hyperparameter Optimization,[0],[0]
Our goal is to optimize the hyperparameters according to a certain error function E evaluated at the last iterate sT .,2. Hyperparameter Optimization,[0],[0]
"Specifically, we wish to solve the problem
min λ∈Λ f(λ) (3)
where the set Λ ⊂ Rd incorporates constraints on the hyperparameters, and the response function f : Rm → R is defined at λ ∈",2. Hyperparameter Optimization,[0],[0]
"Rm as
f(λ) = E(sT (λ)).",2. Hyperparameter Optimization,[0],[0]
"(4)
We highlight the generality of the framework.",2. Hyperparameter Optimization,[0],[0]
"The vector of hyperparameters λ may include components associated with the training objective, and components associated with the iterative algorithm.",2. Hyperparameter Optimization,[0],[0]
"For example, the training objective may depend on hyperparameters used to design the loss function as well as multiple regularization parameters.",2. Hyperparameter Optimization,[0],[0]
"Yet other components of λ may be associated with the space of functions used to fit the training objective (e.g. number of layers and weights of a neural network, parameters associated with the kernel function used within a kernel based method, etc.).",2. Hyperparameter Optimization,[0],[0]
The validation error E can in turn be of different kinds.,2. Hyperparameter Optimization,[0],[0]
The simplest example is to choose E as the average of a loss function over a validation set.,2. Hyperparameter Optimization,[0],[0]
"We may however consider multiple validation objectives, in that the hyperparameters associated with the iterative algorithm (µ and γ in the case of momentum mentioned above) may be optimized using the training set, whereas the regularization parameters would typically require a validation set, which is distinct from the training set (in order to avoid over-fitting).",2. Hyperparameter Optimization,[0],[0]
"In this section, we review the reverse-mode computation of the gradient of the response function (or hypergradient) under a Lagrangian perspective and introduce a forwardmode strategy.",3. Hypergradient Computation,[0],[0]
"These procedures correspond to the reversemode and the forward-mode algorithmic differentiation schemes (Griewank & Walther, 2008).",3. Hypergradient Computation,[0],[0]
"We finally introduce a real-time version of the forward-mode procedure.
",3. Hypergradient Computation,[0],[0]
"Algorithm 1 REVERSE-HG Input: λ current values of the hyperparameters, s0 initial optimization state Output: Gradient of validation error w.r.t.",3. Hypergradient Computation,[0],[0]
λ for t,3. Hypergradient Computation,[0],[0]
"= 1 to T do st = Φt(st−1, λ)
end for αT =",3. Hypergradient Computation,[0],[0]
∇E(sT ) g = 0 for t = T − 1 downto 1 do g = g + αt+1Bt+1 αt = αt+1At+1 end for return g,3. Hypergradient Computation,[0],[0]
"The reverse-mode computation leads to an algorithm closely related to the one presented in (Maclaurin et al., 2015).",3.1. Reverse-Mode,[0],[0]
A major difference with respect to their work is that we do not require the mappings Φt defined in Eq.,3.1. Reverse-Mode,[0],[0]
(1) to be invertible.,3.1. Reverse-Mode,[0],[0]
"We also note that the reverse-mode calculation is structurally identical to back-propagation through time (Werbos, 1990).
",3.1. Reverse-Mode,[0],[0]
"We start by reformulating problem (3) as the constrained optimization problem
min λ,s1,...,sT
E(sT )
subject to st = Φt(st−1, λ), t ∈ {1, . . .",3.1. Reverse-Mode,[0],[0]
", T}.",3.1. Reverse-Mode,[0],[0]
"(5)
This formulation closely follows a classical Lagrangian approach used to derive the back-propagation algorithm (LeCun, 1988).",3.1. Reverse-Mode,[0],[0]
"Furthermore, the framework naturally allows one to incorporate constraints on the hyperparameters.
",3.1. Reverse-Mode,[0],[0]
"The Lagrangian of problem (5) is
L(s, λ, α) = E(sT ) + T∑ t=1 αt(Φt(st−1, λ)− st) (6)
where, for each t ∈ {1, . . .",3.1. Reverse-Mode,[0],[0]
", T}, αt ∈",3.1. Reverse-Mode,[0],[0]
"Rd is a row vector of Lagrange multipliers associated with the t-th step of the dynamics.
",3.1. Reverse-Mode,[0],[0]
"The partial derivatives of the Lagrangian are given by
∂L ∂αt",3.1. Reverse-Mode,[0],[0]
"= Φt(st−1, λ)− st, t ∈ {1, . . .",3.1. Reverse-Mode,[0],[0]
", T} (7) ∂L ∂st = αt+1At+1",3.1. Reverse-Mode,[0],[0]
"− αt, t ∈ {1, . . .",3.1. Reverse-Mode,[0],[0]
", T−1} (8) ∂L ∂sT = ∇E(sT )− αT (9)
",3.1. Reverse-Mode,[0],[0]
∂L ∂λ =,3.1. Reverse-Mode,[0],[0]
"T∑ t=1 αtBt, (10)
",3.1. Reverse-Mode,[0],[0]
"Algorithm 2 FORWARD-HG Input: λ current values of the hyperparameters, s0 initial optimization state Output: Gradient of validation error w.r.t.",3.1. Reverse-Mode,[0],[0]
λ,3.1. Reverse-Mode,[0],[0]
"Z0 = 0 for t = 1 to T do st = Φt(st−1, λ)",3.1. Reverse-Mode,[0],[0]
"Zt = AtZt−1 +Bt
end for return ∇E(s)ZT
where for every t ∈ {1, . . .",3.1. Reverse-Mode,[0],[0]
", T}, we define the matrices
At = ∂Φt(st−1, λ)
∂st−1 , Bt =
∂Φt(st−1, λ)
",3.1. Reverse-Mode,[0],[0]
∂λ .,3.1. Reverse-Mode,[0],[0]
"(11)
Note that At ∈ Rd×d and Bt ∈ Rd×m.
",3.1. Reverse-Mode,[0],[0]
The optimality conditions are then obtained by setting each derivative to zero.,3.1. Reverse-Mode,[0],[0]
"In particular, setting the right hand side of Equations (8) and (9) to zero gives
αt =  ∇E(sT ) if t = T,
∇E(sT )AT · · ·At+1 if t ∈ {1, . . .",3.1. Reverse-Mode,[0],[0]
", T−1}.
",3.1. Reverse-Mode,[0],[0]
Combining these equations with Eq.,3.1. Reverse-Mode,[0],[0]
"(10) we obtain that
∂L ∂λ =",3.1. Reverse-Mode,[0],[0]
"∇E(sT ) T∑ t=1
( T∏
s=t+1
As ) Bt.
",3.1. Reverse-Mode,[0],[0]
As we shall see this coincides with the expression for the gradient of f in Eq.,3.1. Reverse-Mode,[0],[0]
(15) derived in the next section.,3.1. Reverse-Mode,[0],[0]
Pseudo-code of REVERSE-HG is presented in Algorithm 1.,3.1. Reverse-Mode,[0],[0]
"The second approach to compute the hypergradient appeals to the chain rule for the derivative of composite functions, to obtain that the gradient of f at λ satisfies1
∇f(λ) = ∇E(sT ) dsT",3.2. Forward-Mode,[0],[0]
"dλ
(12)
where dsTdλ is the d×mmatrix formed by the total derivative of the components of sT (regarded as rows) with respect to the components of λ (regarded as columns).
",3.2. Forward-Mode,[0],[0]
"Recall that st = Φt(st−1, λ).",3.2. Forward-Mode,[0],[0]
The operators Φt depends on the hyperparameter λ both directly by its expression and indirectly through the state st−1.,3.2. Forward-Mode,[0],[0]
"Using again the chain
1Remember that the gradient of a scalar function is a row vector.
rule we have, for every t ∈ {1, . . .",3.2. Forward-Mode,[0],[0]
", T}, that
dst dλ = ∂Φt(st−1, λ)
",3.2. Forward-Mode,[0],[0]
"∂st−1
dst−1 dλ + ∂Φt(st−1, λ)",3.2. Forward-Mode,[0],[0]
∂λ .,3.2. Forward-Mode,[0],[0]
"(13)
Defining Zt = dstdλ for every t ∈ {1, . . .",3.2. Forward-Mode,[0],[0]
", T} and recalling Eq.",3.2. Forward-Mode,[0],[0]
"(11), we can rewrite Eq.",3.2. Forward-Mode,[0],[0]
"(13) as the recursion
Zt = AtZt−1 +Bt, t ∈ {1, . . .",3.2. Forward-Mode,[0],[0]
", T}.",3.2. Forward-Mode,[0],[0]
"(14)
Using Eq. (14), we obtain that
∇f(λ) =",3.2. Forward-Mode,[0],[0]
∇E(sT )ZT = ∇E(sT )(ATZT−1 +BT ) =,3.2. Forward-Mode,[0],[0]
"∇E(sT )(ATAT−1ZT−2 +ATBT−1 +BT ) ...
= ∇E(sT ) T∑ t=1
( T∏
s=t+1
As ) Bt. (15)
Note that the recurrence (14) on the Jacobian matrix is structurally identical to the recurrence in the RTRL procedure described in (Williams & Zipser, 1989, eq. (2.10)).
",3.2. Forward-Mode,[0],[0]
From the above derivation it is apparent that∇f(λ) can be computed by an iterative algorithm which runs in parallel to the training algorithm.,3.2. Forward-Mode,[0],[0]
Pseudo-code of FORWARD-HG is presented in Algorithm 2.,3.2. Forward-Mode,[0],[0]
"At first sight, the computation of the terms in the right hand side of Eq.",3.2. Forward-Mode,[0],[0]
(14) seems prohibitive.,3.2. Forward-Mode,[0],[0]
"However, in Section 4 we observe that if m is much smaller than d, the computation can be done efficiently.",3.2. Forward-Mode,[0],[0]
"For every t ∈ {1, . . .",3.3. Real-Time Forward-Mode,[0],[0]
", T} let ft : Rm → R be the response function at time t: ft(λ) = E(st(λ)).",3.3. Real-Time Forward-Mode,[0],[0]
Note that fT coincides with the definition of the response function in Eq.,3.3. Real-Time Forward-Mode,[0],[0]
(4).,3.3. Real-Time Forward-Mode,[0],[0]
"A major difference between REVERSE-HG and FORWARD-HG is that the partial hypergradients
∇ft(λ) = dE(st)
dλ = ∇E(st)Zt (16)
are available in the second procedure at each time step t and not only at the end.
",3.3. Real-Time Forward-Mode,[0],[0]
"The availability of partial hypergradients is significant since we are allowed to update hyperparameters several times in a single optimization epoch, without having to wait until time T .",3.3. Real-Time Forward-Mode,[0],[0]
This is reminiscent of the real-time updates suggested by Williams & Zipser (1989) for RTRL.,3.3. Real-Time Forward-Mode,[0],[0]
"The real-time approach may be suitable in the case of a data stream (i.e. T = ∞), where REVERSE-HG would be hardly applicable.",3.3. Real-Time Forward-Mode,[0],[0]
"Even in the case of finite (but large) datasets it is possible to perform one hyperparameter update after a hyper-batch of data (i.e. a set of minibatches)
has been processed.",3.3. Real-Time Forward-Mode,[0],[0]
Algorithm 2 can be easily modified to yield a partial hypergradient when t mod ∆ = 0,3.3. Real-Time Forward-Mode,[0],[0]
"(for some hyper-batch size ∆) and letting t run from 1 to ∞, reusing examples in a circular or random way.",3.3. Real-Time Forward-Mode,[0],[0]
We use this strategy in the phone recognition experiment reported in Section 5.3.,3.3. Real-Time Forward-Mode,[0],[0]
We discuss the time and space complexity of Algorithms 1 and 2.,4. Complexity Analysis,[0],[0]
"We begin by recalling some basic results from the algorithmic differentiation (AD) literature.
",4. Complexity Analysis,[0],[0]
Let F :,4. Complexity Analysis,[0],[0]
Rn 7→,4. Complexity Analysis,[0],[0]
"Rp be a differentiable function and suppose it can be evaluated in time c(n, p) and requires space s(n, p).",4. Complexity Analysis,[0],[0]
Denote by JF the p × n Jacobian matrix of F .,4. Complexity Analysis,[0],[0]
"Then the following facts hold true (Griewank & Walther, 2008) (see also Baydin et al. (2015) for a shorter account):
(i) For any vector r ∈ Rn, the product JF r can be evaluated in time O(c(n, p)) and requires space O(s(n, p)) using forward-mode AD.
(ii) For any vector q ∈",4. Complexity Analysis,[0],[0]
"Rp, the product JᵀF q has time and space complexities O(c(n, p)) using reverse-mode AD.
",4. Complexity Analysis,[0],[0]
"(iii) As a corollary of item (i), the whole JF can be computed in time O(nc(n, p)) and requires space O(s(n, p)) using forward-mode AD (just use unitary vectors r = ei for i = 1, . . .",4. Complexity Analysis,[0],[0]
",",4. Complexity Analysis,[0],[0]
"n).
",4. Complexity Analysis,[0],[0]
"(iv) Similarly, JF can be computed in time O(pc(n, p)) and requires space O(c(n, p)) using reverse-mode AD.
",4. Complexity Analysis,[0],[0]
"Let g(d,m) and h(d,m) denote time and space, respectively, required to evaluate the update map Φt defined by Eq.",4. Complexity Analysis,[0],[0]
(1).,4. Complexity Analysis,[0],[0]
Then the response function f :,4. Complexity Analysis,[0],[0]
Rm 7→ R defined in Eq.,4. Complexity Analysis,[0],[0]
"(3) can be evaluated in timeO(Tg(d,m))",4. Complexity Analysis,[0],[0]
"(assuming the time required to compute the validation errorE(λ) does not affect the bound2) and requires spaceO(h(d,m)) since variables st may be overwritten at each iteration.",4. Complexity Analysis,[0],[0]
"Then, a direct application of Fact (i) above shows that Algorithm 2 runs in time O(Tmg(d,m)) and space O(h(d,m)).",4. Complexity Analysis,[0],[0]
"The same results can also be obtained by noting that in Algorithm 2 the product AtZt−1 requires m Jacobian-vector products, each costing O(g(d,m)) (from Fact (i)), while computing the Jacobian Bt takes time O(mg(d,m))",4. Complexity Analysis,[0],[0]
"(from Fact (iii)).
",4. Complexity Analysis,[0],[0]
"Similarly, a direct application of Fact (ii) shows that Algorithm 1 has both time and space complexities O(Tg(d,m)).",4. Complexity Analysis,[0],[0]
"Again the same results can be obtained by
2This is indeed realistic since the number of validation examples is typically lower than the number of training iterations.
noting that αt+1At1 and αtBt are transposed-Jacobianvector products that in reverse-mode take both time O(g(d,m))",4. Complexity Analysis,[0],[0]
(from Fact (ii)).,4. Complexity Analysis,[0],[0]
"Unfortunately in this case variables st cannot be overwritten, explaining the much higher space requirement.
",4. Complexity Analysis,[0],[0]
"As an example, consider training a neural network with k weights3, using classic iterative optimization algorithms such as SGD (possibly with momentum) or Adam, where the hyperparameters are just learning rate and momentum terms.",4. Complexity Analysis,[0],[0]
"In this case, d = O(k) and m = O(1).",4. Complexity Analysis,[0],[0]
"Moreover, g(d,m) and h(d,m) are both O(k).",4. Complexity Analysis,[0],[0]
"As a result, Algorithm 1 runs in time and space O(Tk), while Algorithm 2 runs in timeO(Tk) and spaceO(k), which would typically make a dramatic difference in terms of memory requirements.",4. Complexity Analysis,[0],[0]
"In this section, we present numerical simulations with the proposed methods.",5. Experiments,[0],[0]
All algorithms were implemented in TensorFlow and the software package used to reproduce our experiments is available at https://github.,5. Experiments,[0],[0]
com/lucfra/RFHO.,5. Experiments,[0],[0]
"In all the experiments, hypergradients were used inside the Adam algorithm (Kingma & Ba, 2014) in order to minimize the response function.",5. Experiments,[0],[0]
The goal of this experiment is to highlight one potential advantage of constraints on the hyperparameters.,5.1. Data Hyper-cleaning,[0],[0]
Suppose we have a dataset with label noise and due to time or resource constraints we can only afford to cleanup (by checking and correcting the labels) a subset of the available data.,5.1. Data Hyper-cleaning,[0],[0]
"Then we may use the cleaned data as the validation set, the rest as the training set, and assign one hyperparameter to each training example.",5.1. Data Hyper-cleaning,[0],[0]
"By putting a sparsity constraint on the vector of hyperparameters λ, we hope to bring to zero the influence of noisy examples, in order to generate a better model.",5.1. Data Hyper-cleaning,[0],[0]
"While this is the same kind of data sparsity observed in support vector machines (SVM), our setting aims to get rid of erroneously labeled examples, in contrast to SVM which puts zero weight on redundant examples.",5.1. Data Hyper-cleaning,[0],[0]
"Although this experimental setup does not necessarily reflect a realistic scenario, it aims to test the ability of our HO method to effectively make use of constraints on the hyperparameters4
We instantiated the above setting with a balanced subset of N = 20000 examples from the MNIST dataset, split into three subsets:",5.1. Data Hyper-cleaning,[0],[0]
"Dtr of Ntr = 5000 training examples, V of
3This includes linear SVM and logistic regression as special cases.
",5.1. Data Hyper-cleaning,[0],[0]
"4We note that a related approach based on reinforcement learning is presented in (Fan et al., 2017).
",5.1. Data Hyper-cleaning,[0],[0]
Nval = 5000 validation examples and a test set containing the remaining samples.,5.1. Data Hyper-cleaning,[0],[0]
"Finally, we corrupted the labels of 2500 training examples, selecting a random subset Df ⊂ Dtr.
We considered a plain softmax regression model with parameters W (weights) and b (bias).",5.1. Data Hyper-cleaning,[0],[0]
"The error of a model (W, b) on an example x was evaluated by using the crossentropy `(W, b, x) both in the training objective function, Etr, and in the validation one, Eval.",5.1. Data Hyper-cleaning,[0],[0]
We added in Etr an hyperparameter vector λ ∈,5.1. Data Hyper-cleaning,[0],[0]
"[0, 1]Ntr that weights each example in the training phase, i.e. Etr(W, b) =
1 Ntr ∑ i∈Dtr λi`(W, b, xi).
",5.1. Data Hyper-cleaning,[0],[0]
"According to the general HO framework, we fit the parameters (W, b) to minimize the training loss and the hyperparameters λ to minimize the validation error.",5.1. Data Hyper-cleaning,[0],[0]
"The sparsity constraint was implemented by bounding the L1-norm of λ, resulting in the optimization problem
min λ∈Λ Eval(WT , bT ) (PHO)
where Λ = {λ : λ ∈",5.1. Data Hyper-cleaning,[0],[0]
"[0, 1]Ntr , ‖λ‖1 ≤ R} and (WT , bT ) are the parameters obtained after T iterations of gradient descent on the training objective.",5.1. Data Hyper-cleaning,[0],[0]
"Given the high dimensionality of λ, we solved (PHO) iteratively computing the hypergradients with REVERSE-HG method and projecting Adam updates on the set Λ.
We are interested in comparing the following three test set accuracies:
• Oracle: the accuracy of the minimizer of Etr trained on clean examples only, i.e. (Dtr\Df )∪V; this setting is effectively taking advantage of an oracle that tells which examples have a wrong label;
• Baseline: the accuracy of the minimizer ofEtr trained on all available data D ∪ V;
• DH-R: the accuracy of the data hyper-cleaner with a given value of the L1 radius, R.",5.1. Data Hyper-cleaning,[0],[0]
"In this case, we first optimized hyperparameters",5.1. Data Hyper-cleaning,[0],[0]
and then constructed a cleaned training set Dc ⊂,5.1. Data Hyper-cleaning,[0],[0]
"Dtr (keeping examples with λi > 0); we finally trained on Dc ∪ V .
",5.1. Data Hyper-cleaning,[0],[0]
We are also interested in evaluating the ability of the hypercleaner to detect noisy samples.,5.1. Data Hyper-cleaning,[0],[0]
Results are shown in Table 1.,5.1. Data Hyper-cleaning,[0],[0]
"The data hyper-cleaner is robust with respect to the choice of R and is able to identify corrupted examples, recovering a model that has almost the same accuracy as a model produced with the help of an oracle.
",5.1. Data Hyper-cleaning,[0],[0]
Figure 1 shows how the accuracy of DH-1000 improves with the number of hyper-iterations and the progression of the amount of discarded examples.,5.1. Data Hyper-cleaning,[0],[0]
"The data hyper-cleaner starts by discarding mainly corrupted examples, and while
0 100 200 300 400 500
Hyper-iterations
0
500
1000
1500
2000
2500
3000
3500
N u
m b
er of
d is
ca rd
ed ex
am p
le s
80
82
84
86
88
",5.1. Data Hyper-cleaning,[0],[0]
"90
92
A cc
u ra
cy
N u
m b
er of
d is
ca rd
ed ex
am p
le s
Accuracy and sparsity of λ
Validation
Test
TP
FP
Figure 1:",5.1. Data Hyper-cleaning,[0],[0]
Right vertical axis: accuracies of DH-1000 on validation and test sets.,5.1. Data Hyper-cleaning,[0],[0]
"Left vertical axis: number of discarded examples among noisy (True Positive, TP) and clean (False Positive, FP) ones.
",5.1. Data Hyper-cleaning,[0],[0]
"the optimization proceeds, it begins to remove also a portion of cleaned one.",5.1. Data Hyper-cleaning,[0],[0]
"Interestingly, the test set accuracy continues to improve even when some of the clean examples are discarded.",5.1. Data Hyper-cleaning,[0],[0]
"This second set of experiments is in the multitask learning (MTL) context, where the goal is to find simultaneously the model of multiple related tasks.",5.2. Learning Task Interactions,[0],[0]
Many MTL methods require that a task interaction matrix is given as input to the learning algorithm.,5.2. Learning Task Interactions,[0],[0]
"However, in real applications, this matrix is often unknown and it is interesting to learn it from data.",5.2. Learning Task Interactions,[0],[0]
"Below, we show that our framework can be naturally applied to learning the task relatedness matrix.
",5.2. Learning Task Interactions,[0],[0]
"We used CIFAR-10 and CIFAR-100 (Krizhevsky & Hinton, 2009), two object recognition datasets with 10 and 100 classes, respectively.",5.2. Learning Task Interactions,[0],[0]
As features we employed the preactivation of the second last layer of Inception-V3 model trained on ImageNet5.,5.2. Learning Task Interactions,[0],[0]
"From CIFAR-10, we extracted 50
5Available at tinyurl.com/h2x8wws
examples as training set, different 50 examples as validation set and the remaining for testing.",5.2. Learning Task Interactions,[0],[0]
"From CIFAR-100, we selected 300 examples as training set, 300 as validation set and the remaining for testing.",5.2. Learning Task Interactions,[0],[0]
"Finally, we used a onehot encoder of the labels obtaining a set of labels in {0, 1}K (K = 10 or K = 100).
",5.2. Learning Task Interactions,[0],[0]
The choice of small training set sizes is due to the strong discriminative power of the selected features.,5.2. Learning Task Interactions,[0],[0]
"In fact, using larger sample sizes would not allow to appreciate the advantage of MTL.",5.2. Learning Task Interactions,[0],[0]
"In order to leverage information among the different classes, we employed a multitask learning (MTL) regularizer (Evgeniou et al., 2005)
ΩC,ρ(W ) = K∑ j,k=1 Cj,k‖wj − wk‖22 + ρ K∑ k=1 ‖wk‖2,
where wk are the weights for class k, K is the number of classes, and the symmetric non-negative matrix C models the interactions between the classes/tasks.",5.2. Learning Task Interactions,[0],[0]
"We used a regularized training error defined as Etr(W ) =∑ i∈Dtr `(Wxi + b, yi) + ΩC,ρ(W )",5.2. Learning Task Interactions,[0],[0]
"where `(·, ·) is the categorical cross-entropy and b = (b1, . . .",5.2. Learning Task Interactions,[0],[0]
", bK) is the vector of thresholds associated with each linear model.",5.2. Learning Task Interactions,[0],[0]
"We wish solve the following optimization problem:
min { Eval(WT , bT ) subject to ρ ≥ 0, C = Cᵀ, C ≥ 0 } ,
where (WT , bT ) is the T -th iteration obtained by running gradient descent with momentum (GDM) on the training objective.",5.2. Learning Task Interactions,[0],[0]
"We solve this problem using REVERSE-HG and optimizing the hyperparameters by projecting Adam updates on the set {(ρ, C) : ρ ≥ 0, C = Cᵀ, C ≥ 0}.",5.2. Learning Task Interactions,[0],[0]
"We compare the following methods:
• SLT: single task learning, i.e. C = 0, using a validation set to tune the optimal value of ρ for each task;
• NMTL: we considered the naive MTL scenario in which the tasks are equally related, that is Cj,k = a for every 1 ≤ j, k ≤",5.2. Learning Task Interactions,[0],[0]
K.,5.2. Learning Task Interactions,[0],[0]
"In this case we learn the two non-negative hyperparameters a and ρ;
• HMTL:",5.2. Learning Task Interactions,[0],[0]
"our hyperparameter optimization method REVERSE-HG to tune C and ρ;
• HMTL-S: Learning the matrix C with only few examples per class could bring the discovery of spurious relationships.",5.2. Learning Task Interactions,[0],[0]
"We try to remove this effect by imposing the constraint that ∑ j,k Cj,k ≤ R, where6 R = 10−3.
",5.2. Learning Task Interactions,[0],[0]
"In this case, Adam updates are projected onto the set {(ρ, C) : ρ ≥ 0, C = Cᵀ, C ≥ 0, ∑ j,k Cj,k ≤ R}.
",5.2. Learning Task Interactions,[0],[0]
Results of five repetitions with different splits are presented in Table 2.,5.2. Learning Task Interactions,[0],[0]
"Note that HMTL gives a visible improvement in
6We observed that R = 10−4 yielded very similar results.
performance, and adding the constraint that ∑ j,k Cj,k ≤ R further improves performance in both datasets.",5.2. Learning Task Interactions,[0],[0]
"The matrix C can been interpreted as an adjacency matrix of a graph, highlighting the relationships between the classes.",5.2. Learning Task Interactions,[0],[0]
"Figure 2 depicts the graph for CIFAR-10 extracted from the algorithm HMTL-S. Although this result is strongly influenced by the choice of the data representations, we can note that animals tends to be more related to themselves than to vehicles and vice versa.",5.2. Learning Task Interactions,[0],[0]
The aim of the third set of experiments is to assess the efficacy of the real-time FORWARD-HG algorithm (RTHO).,5.3. Phone Classification,[0],[0]
"We run experiments on phone recognition in the multitask framework proposed in (Badino, 2016, and references therein).",5.3. Phone Classification,[0],[0]
"Data for all experiments was obtained from the TIMIT phonetic recognition dataset (Garofolo et al., 1993).",5.3. Phone Classification,[0],[0]
The dataset contains 5040 sentences corresponding to around 1.5 million speech acoustic frames.,5.3. Phone Classification,[0],[0]
"Training, validation and test sets contain respectively 73%, 23% and 4% of the data.",5.3. Phone Classification,[0],[0]
The primary task is a frame-level phone state classification with 183 classes and it consists in learning a mapping fP from acoustic speech vectors to hidden Markov model monophone states.,5.3. Phone Classification,[0],[0]
"Each 25ms speech frame is represented by a 123-dimensional vector containing 40 Mel frequency scale cepstral coefficients and energy, augmented with their deltas and delta-deltas.",5.3. Phone Classification,[0],[0]
We used a window of eleven frames centered around the prediction target to create the 1353-dimensional input to fP .,5.3. Phone Classification,[0],[0]
"The secondary (or auxiliary) task consists in learning a mapping fS from acoustic vectors to 300-dimensional real vectors of contextdependent phonetic embeddings defined in (Badino, 2016).
",5.3. Phone Classification,[0],[0]
"As in previous work, we assume that the two mappings fP and fS share inputs and an intermediate representation, obtained by four layers of a feed-forward neural network with 2000 units on each layer.",5.3. Phone Classification,[0],[0]
We denote by W the parameter vector of these four shared layers.,5.3. Phone Classification,[0],[0]
The network has two different output layers with parameter vectorsWP andWS each relative to the primary and secondary task.,5.3. Phone Classification,[0],[0]
"The network is trained to jointly minimize Etot(W,WP ,WS) = EP (W,W P )+ρES(W,W S), where the primary error EP is the average cross-entropy loss on the primary task, the secondary error ES is given by mean squared error on the embedding vectors and ρ ≥ 0 is a design hyperparameter.",5.3. Phone Classification,[0],[0]
"Since we are ultimately interested in learning fP , we formulate the hyperparameter optimization problem as
min { Eval(WT ,W P T ) subject to ρ, η ≥ 0, 0 ≤ µ ≤ 1 } ,
where Eval is the cross entropy loss computed on a validation set after T iterations of stochastic GDM, and η and µ are defined in (2).",5.3. Phone Classification,[0],[0]
In all the experiments we fix a minibatch size of 500.,5.3. Phone Classification,[0],[0]
"We compare the following methods:
1.",5.3. Phone Classification,[0],[0]
"Vanilla: the secondary target is ignored (ρ = 0); η and µ are set to 0.075 and 0.5 respectively as in (Badino, 2016).
2.",5.3. Phone Classification,[0],[0]
"RS: random search with ρ ∼ U(0, 4), η ∼ E(0.1) (exponential distribution with scale parameter 0.1) and µ ∼ U(0, 1) (Bergstra & Bengio, 2012).
3.",5.3. Phone Classification,[0],[0]
"RTHO: real-time hyperparameter optimization with initial learning rate and momentum factor as in Vanilla and initial ρ set to 1.6 (best value obtained by gridsearch in Badino (2016)).
",5.3. Phone Classification,[0],[0]
4.,5.3. Phone Classification,[0],[0]
"RTHO-NT: RTHO with “null teacher,” i.e. when the initial values of ρ, η and µ are set to 0.",5.3. Phone Classification,[0],[0]
"We regard this experiment as particularly interesting: this initial setting, while clearly not optimal, does not require any background knowledge on the task at hand.
",5.3. Phone Classification,[0],[0]
"We also tried to run FORWARD-HG for a fixed number of epochs, not in real-time mode.",5.3. Phone Classification,[0],[0]
"Results are not reported
since the method could not make any appreciable progress after running 24 hours on a Titan X GPU.
Test accuracies and execution times are reported in Table 3.",5.3. Phone Classification,[0],[0]
Figure 3 shows learning curves and hyperparameter evolutions for RTHO-NT.,5.3. Phone Classification,[0],[0]
"In Experiments 1 and 2 we employ a standard early stopping procedure on the validation accuracy, while in Experiments 3 and 4 a natural stopping time is given by the decay to 0 of the learning rate (see Figure 3 left-bottom plot).",5.3. Phone Classification,[0],[0]
"In Experiments 3 and 4 we used a hyperbatch size of ∆ = 200 (see Eq. (16)) and a hyper-learning rate of 0.005.
",5.3. Phone Classification,[0],[0]
"The best results in Table 3 are very similar to those obtained in state-of-the-art recognizers using multitask learning (Badino, 2016; 2017).",5.3. Phone Classification,[0],[0]
"In spite of the small number of hyperparameters, random search yields results only slightly better than the vanilla network (the result reported in Table 3 are an average over 5 trials, with a minimum and maximum accuracy of 59.93 and 60.86, respectively).",5.3. Phone Classification,[0],[0]
"Within the same time budget of 300 minutes, RTHO-NT is able to find hyperparameters yielding a substantial improvement over the vanilla version, thus effectively exploiting the auxiliary task.",5.3. Phone Classification,[0],[0]
Note that the model trained has more that 15×106 parameters for a corresponding state of more than 30× 106 variables.,5.3. Phone Classification,[0],[0]
"To the best of our knowledge, reversemode (Maclaurin et al., 2015) or approximate (Pedregosa, 2016) methods have not been applied to models of this size.",5.3. Phone Classification,[0],[0]
"We studied two alternative strategies for computing the hypergradients of any iterative differentiable learning dynam-
ics.",6. Discussion,[0],[0]
"Previous work has mainly focused on the reverse-mode computation, attempting to deal with its space complexity, that becomes prohibitive for very large models such as deep networks.
",6. Discussion,[0],[0]
Our first contribution is the definition and the application of forward-mode computation to HO.,6. Discussion,[0],[0]
Our analysis suggests that for large models the forward-mode computation may be a preferable alternative to reverse-mode if the number of hyperparameters is small.,6. Discussion,[0],[0]
"Additionally, forward-mode is amenable to real-time hyperparameter updates, which we showed to be an effective strategy for large datasets (see Section 5.3).",6. Discussion,[0],[0]
"We showed experimentally that even starting from a far-from-optimal value of the hyperparameters (the null teacher), our RTHO algorithm finds good values at a reasonable cost, whereas other gradient-based algorithms could not be applied in this context.
",6. Discussion,[0],[0]
Our second contribution is the Lagrangian derivation of the reverse-mode computation.,6. Discussion,[0],[0]
"It provides a general framework to tackle hyperparameter optimization problems involving a wide class of response functions, including those that take into account the whole parameter optimization dynamics.",6. Discussion,[0],[0]
"We have also presented in Sections 5.1 and 5.2 two non-standard learning problems where we specifically take advantage of a constrained formulation of the HO problem.
",6. Discussion,[0],[0]
We close by highlighting some potential extensions of our framework and direction of future research.,6. Discussion,[0],[0]
"First, the relatively low cost of our RTHO algorithm could suggest to make it a standard tool for the optimization of real-valued critical hyperparameters (such as learning rates, regularization factors and error function design coefficient), in context where no previous or expert knowledge is available (e.g. novel domains).",6. Discussion,[0],[0]
"Yet, RTHO must be thoroughly validated on diverse datasets and with different models and settings to empirically asses its robustness and its ability to find good hyperparameter values.",6. Discussion,[0],[0]
"Second, in order to perform gradient-based hyperparameter optimization, it is necessary to set a descent procedure over the hyperparameters.",6. Discussion,[0],[0]
In our experiments we have always used Adam with a manually adjusted value for the hyperlearning rate.,6. Discussion,[0],[0]
Devising procedures which are adaptive in these hyper-hyperparameters is an important direction of future research.,6. Discussion,[0],[0]
"Third, extensions of gradient-based HO techniques to integer or nominal hyperparameters (such as the depth and the width of a neural network) require additional design efforts and may not arise naturally in our framework.",6. Discussion,[0],[0]
"Future research should instead focus on the integration of gradient-based algorithm with Bayesian optimization and/or with emerging reinforcement learning hyperparameter optimization approaches (Zoph & Le, 2016).",6. Discussion,[0],[0]
A final important problem is to study the converge properties of RTHO.,6. Discussion,[0],[0]
Results in Pedregosa (2016) may prove useful in this direction.,6. Discussion,[0],[0]
We study two procedures (reverse-mode and forward-mode) for computing the gradient of the validation error with respect to the hyperparameters of any iterative learning algorithm such as stochastic gradient descent.,abstractText,[0],[0]
These procedures mirror two methods of computing gradients for recurrent neural networks and have different trade-offs in terms of running time and space requirements.,abstractText,[0],[0]
Our formulation of the reverse-mode procedure is linked to previous work by Maclaurin et al. (2015) but does not require reversible dynamics.,abstractText,[0],[0]
"The forward-mode procedure is suitable for real-time hyperparameter updates, which may significantly speed up hyperparameter optimization on large datasets.",abstractText,[0],[0]
We present experiments on data cleaning and on learning task interactions.,abstractText,[0],[0]
We also present one large-scale experiment where the use of previous gradient-based methods would be prohibitive.,abstractText,[0],[0]
Forward and Reverse Gradient-Based Hyperparameter Optimization,title,[0],[0]
"Goal-oriented, information-retrieving dialogue systems have been designed traditionally to help users find items in a database given a set of constraints (Singh et al., 2002; Raux et al., 2003; El Asri et al., 2014; Laroche et al., 2011).",1 Introduction,[0],[0]
"For instance, the LET’S GO dialogue system finds a bus schedule given a bus number and a location (Raux et al., 2003).
",1 Introduction,[0],[0]
"Available resources for data-driven learning of such goal-oriented systems are often collected with an existing system (Henderson et al., 2014b; Bennett and Rudnicky, 2002) and have been proposed to study one component of dialogue.",1 Introduction,[0],[0]
"Examples are the first three Dialogue State Tracking Challenges (DSTC, Williams et al., 2016) during which a se-
ries of datasets and tasks of increasing complexity were released.",1 Introduction,[0],[0]
These shared tasks were essential to advance the state of the art on state tracking.,1 Introduction,[0],[0]
"Other resources have allowed to study and develop different approaches to spoken language understanding and entity extraction (Mesnil et al., 2013).",1 Introduction,[0],[0]
"As for dialogue management, simulators have been proposed (Schatzmann et al., 2006) but datasets are scarce.
",1 Introduction,[0],[0]
"In most datasets collected with an existing system, the dialogues consist of sequential slot-filling: the system requests constraints until it can query the database and return several results to the user.",1 Introduction,[0],[0]
"Then, the user can ask for more information about a given result or request other possibilities.",1 Introduction,[0],[0]
"As a consequence, the tasks and methods that were based on these datasets were defined according to this sequential slot-filling process
We propose the Frames dataset to study more complex dialogue flows and decision-making behaviour.",1 Introduction,[0],[0]
"Our motivation comes from user studies in e-commerce which show that several informationseeking behaviours are exhibited by users who may come with a very well defined item in mind, but may also visit an e-commerce website with the intent to compare items and explore different possibilities (Moe and Fader, 2001; Saha et al., 2017).",1 Introduction,[0],[0]
Supporting this kind of decision-making process in conversational systems implies adding memory.,1 Introduction,[0],[0]
Memory is necessary to track different items or preferences set by the user during the dialogue.,1 Introduction,[0],[0]
"For instance, consider product comparisons.",1 Introduction,[0],[0]
"If a user wants to compare different items using a dialogue system, then this system should be able to separately recall properties pertaining to each item.
",1 Introduction,[0],[0]
"We collected 1369 human-human dialogues in a Wizard-of-Oz (WOz) setting – i.e., users were paired up with humans, whom we refer to as wizards, who assumed the role of the dialogue system.",1 Introduction,[0],[0]
"Wizards were given access to a database of vaca-
tion packages containing round-trip flights and a hotel.",1 Introduction,[0],[0]
Users were tasked with finding packages based on a few constraints such as a destination and a budget.,1 Introduction,[0],[0]
"The dataset has been fully annotated by human experts and is publicly available1.
",1 Introduction,[0],[0]
"Along with this dataset, we formalize a new task called frame tracking.",1 Introduction,[0],[0]
"Frame tracking is an extension of state tracking (Henderson, 2015; Williams et al., 2016).",1 Introduction,[0],[0]
"In state tracking, the information summarizing the full dialogue history is compressed into a single semantic frame which contains properties and values corresponding to the user’s preferences (e.g., destination city).",1 Introduction,[0],[0]
"In frame tracking, the dialogue agent must simultaneously track multiple semantic frames (e.g., different destination cities; frames are defined formally in Section 4.2) throughout the conversation.",1 Introduction,[0],[0]
"We collected the Frames data over a period of 20 days with 12 participants, who worked either for one day, one week, or 20 days.",2 Data Collection,[0],[0]
The participants alternated between the user and wizard roles on a daily basis.,2 Data Collection,[0],[0]
"Due to this rotation, we can assume that we deal with returning users who know how to use the system, and focus on the decision making process, skipping the phase where the user learns about the system capabilities.",2 Data Collection,[0],[0]
"The domain for all dialogues is travel: specifically, finding a vacation package that fulfils certain a priori requirements through a conversational search-and-compare process.",2 Data Collection,[0],[0]
"Wizard-of-Oz (WOz) dialogues (Kelley, 1984; Rieser et al., 2005; Wen et al., 2016) have the considerable advantage of exhibiting realistic behaviours often beyond the capabilities of existing dialogue systems.",2.1 Wizard-Of-Oz Setting,[0],[0]
"Our setting is slightly different from the usual WOz setting because, in our case, users did not believe they were interacting with a dialogue system; they knew they were conversing with fellow humans.",2.1 Wizard-Of-Oz Setting,[0],[0]
"We chose not to give templated answers to wizards because, apart from studying decision-making, we also wanted to study information presentation and dialogue management.",2.1 Wizard-Of-Oz Setting,[0],[0]
"We work with text-based dialogues because this engenders a more controlled wizard behaviour, obviates handling time-sensitive turn taking, and speech recognition noise.
1datasets.maluuba.com/Frames",2.1 Wizard-Of-Oz Setting,[0],[0]
User-wizard dialogues took place on Slack.2 We deployed a Slack bot to pair up participants and record conversations.,2.2 Task Templates and Instructions,[0],[0]
"At the beginning of each dialogue, a user was paired with a wizard and given a new task.",2.2 Task Templates and Instructions,[0],[0]
"Tasks were built from templates like the following:
“Find a vacation between [START DATE] and",2.2 Task Templates and Instructions,[0],[0]
[END DATE] for [NUM ADULTS] adults and [NUM CHILDREN] kids.,2.2 Task Templates and Instructions,[0],[0]
You leave from [ORIGIN CITY].,2.2 Task Templates and Instructions,[0],[0]
"You are travelling on a budget and you would like to spend at most $[BUDGET].”
Tasks were generated by drawing values (e.g., for BUDGET) from a database.",2.2 Task Templates and Instructions,[0],[0]
We constructed our database of flight and hotel properties by hand to simulate what one would find on a standard travel booking site.,2.2 Task Templates and Instructions,[0],[0]
"Each template was assigned a probability of success, and then constraint values were drawn in order to comply with this probability.",2.2 Task Templates and Instructions,[0],[0]
"For example, if 20 tasks were generated at probability 0.5, about 10 tasks would be generated with successful database queries and the other 10 would be generated such that the database returned no results for the constraints.",2.2 Task Templates and Instructions,[0],[0]
This success mechanism allowed us to emulate cases when a user would find nothing meeting her constraints.,2.2 Task Templates and Instructions,[0],[0]
"If a task was unsuccessful, the user either ended the dialogue or got an alternative task such as: “If nothing matches your constraints, try increasing your budget by $200.”",2.2 Task Templates and Instructions,[0],[0]
We wrote 38 templates.,2.2 Task Templates and Instructions,[0],[0]
14 were generic like the one presented above and the other 24 included a background story to encourage role-playing from users and to keep them engaged.,2.2 Task Templates and Instructions,[0],[0]
These templates were meant to add variety to the dialogues.,2.2 Task Templates and Instructions,[0],[0]
The generic templates were also important for the users to create their own character and personality.,2.2 Task Templates and Instructions,[0],[0]
We found that the combination of the two types of templates prevented the task from becoming too repetitive.,2.2 Task Templates and Instructions,[0],[0]
"Notably, we distributed the role-playing templates throughout the data collection process to bring some novelty and surprise.",2.2 Task Templates and Instructions,[0],[0]
"We also asked the participants to write templates (13 of them) to keep them engaged in the task.
",2.2 Task Templates and Instructions,[0],[0]
"To control data collection, we gave a set of instructions to the participants.",2.2 Task Templates and Instructions,[0],[0]
The user instructions encouraged a variety of behaviours.,2.2 Task Templates and Instructions,[0],[0]
"As for the wizards, they were asked only to talk about the
2www.slack.com
database results and the task at hand.",2.2 Task Templates and Instructions,[0],[0]
"We also asked the wizards to perform untimely actions occasionally, for instance, to ask for information that the user has already provided.",2.2 Task Templates and Instructions,[0],[0]
It is interesting from a dialogue management point of view to have examples of bad behaviour and of how it impacts user satisfaction.,2.2 Task Templates and Instructions,[0],[0]
"At the end of each dialogue, the user provided a wizard cooperativity rating on a scale of 1 to 5.",2.2 Task Templates and Instructions,[0],[0]
"The wizard, on the other hand, was shown the user’s task and was asked whether she thought the user had accomplished it.",2.2 Task Templates and Instructions,[0],[0]
Wizards received a link to a search interface every time a user was connected to them.,2.3 Search Interface And Suggestions,[0],[0]
The search interface was a simple GUI with all the searchable fields in the database (see Appendix A).,2.3 Search Interface And Suggestions,[0],[0]
"For every database search, up to 10 results were displayed, sorted by increasing price.
",2.3 Search Interface And Suggestions,[0],[0]
Another important property of human dialogue that we want to study with Frames is how to provide users with database information.,2.3 Search Interface And Suggestions,[0],[0]
"When a set of user constraints leads to no results, users would benefit from knowing that relaxing a given constraint (e.g., increasing the budget by a reasonable amount) leads to results.",2.3 Search Interface And Suggestions,[0],[0]
We modelled this by displaying suggestions to the wizards when a database query returned no results.,2.3 Search Interface And Suggestions,[0],[0]
Suggestions were packages obtained by randomly relaxing one or more constraints.,2.3 Search Interface And Suggestions,[0],[0]
It was up to the wizard to decide whether or not to use suggestions.,2.3 Search Interface And Suggestions,[0],[0]
"Using the data collection process described above, we collected 1369 dialogues.",3 Statistics of the Corpus,[0],[0]
Figure 1a shows the distribution of dialogue lengths in the corpus.,3 Statistics of the Corpus,[0],[0]
"The average number of turns is 15, for a total of 19986 turns in the dataset.",3 Statistics of the Corpus,[0],[0]
A turn is defined as a Slack message sent by either a user or a wizard.,3 Statistics of the Corpus,[0],[0]
"Turns always alternate between user and wizard.
",3 Statistics of the Corpus,[0],[0]
Figure 1b shows the number of acts per dialogue turn.,3 Statistics of the Corpus,[0],[0]
About 25% of the dialogue turns have more than one dialogue act.,3 Statistics of the Corpus,[0],[0]
"The turns without dialogue acts are turns where the user asked for something that the wizard could not provide, e.g., because it was not part of the database.",3 Statistics of the Corpus,[0],[0]
"We left such (rarely occurring) user turns unannotated, as they are usually followed up by the wizard saying she cannot provide the required information.",3 Statistics of the Corpus,[0],[0]
"This rarely occurs, since our users are familiar with the capabilities of the “system” after only few dialogues.
",3 Statistics of the Corpus,[0],[0]
Figure 1c shows the distribution of user ratings.,3 Statistics of the Corpus,[0],[0]
More than 70% of the dialogues have the maximum rating of 5.,3 Statistics of the Corpus,[0],[0]
Figure 2 shows the occurrences of dialogue acts in the corpus.,3 Statistics of the Corpus,[0],[0]
The dialogue acts are described in Table 9.,3 Statistics of the Corpus,[0],[0]
We present the annotation scheme in the following section.,3 Statistics of the Corpus,[0],[0]
"We manually annotated the Frames dataset with dialogue acts, slot types and values, references to other frames, and the ID of the currently active frame for each utterance.",4 Annotation,[0],[0]
We also computed frame descriptions based on the labels of earlier turns.,4 Annotation,[0],[0]
"Most of the dialogue acts used for annotation are typical of the goal-oriented setting, such as inform and offer (Henderson et al., 2014b).","4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
"We also introduced dialogue acts specifically for frame tracking, such as switch frame and request compare.","4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
"The dialogue acts are listed in Table 9.
","4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
Our annotation uses three sets of slot types.,"4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
"The first set, listed in Tables 7 and 8, corresponds to the fields of the database.","4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
"The second set is listed in Table 10 and contains the slot types which we defined to describe specific aspects of the dialogue, such as intent, action, and count.","4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
The remaining slot types in Table 10 were introduced to describe frames and cross-references between them.,"4.1 Dialogue Acts, Slot Types, Slot Values",[0],[0]
Semantic frames form the core of our dataset.,4.2 Frame Definition,[0],[0]
"A semantic frame is defined by the following four components: • User requests: slots whose values the user
wants to know for this frame.",4.2 Frame Definition,[0],[0]
•,4.2 Frame Definition,[0],[0]
"User binary questions: user questions with
slot types and slot values.",4.2 Frame Definition,[0],[0]
•,4.2 Frame Definition,[0],[0]
"Constraints: slots which have been set to a
particular value by the user or the wizard.",4.2 Frame Definition,[0],[0]
•,4.2 Frame Definition,[0],[0]
"User comparison requests: slots whose values
the user wants to know for this frame and one or more other frames.
",4.2 Frame Definition,[0],[0]
"In DSTC, a semantic frame contains the constraints set by the user, the user requests, and the user’s search method (e.g., by constraints or alternatives).",4.2 Frame Definition,[0],[0]
"In our case, constraints can also be set by the wizard when she suggests or offers a package.",4.2 Frame Definition,[0],[0]
Any field in the database (see Tables 7 and 8 in Appendix A) can be constrained by the user or,4.2 Frame Definition,[0],[0]
"User I’d like to book a trip to Atlantis from Caprica on Saturday, 1 August 13, 2016 for 8 adults.",Author Utterance Frame,[0],[0]
I have a tight budget of 1700.,Author Utterance Frame,[0],[0]
"Wizard Hi...I checked a few options for you, and unfortunately, we do not currently have any 1 trips that meet this criteria.",Author Utterance Frame,[0],[0]
Would you like to book an alternate travel option?,Author Utterance Frame,[0],[0]
User,Author Utterance Frame,[0],[0]
"Yes, how about going to Neverland from Caprica on August 13, 2 2016 for 5 adults.",Author Utterance Frame,[0],[0]
"For this trip, my budget would be 1900.",Author Utterance Frame,[0],[0]
Wizard I checked the availability for those dates and there were no trips available.,Author Utterance Frame,[0],[0]
"2 Would you like to select some alternate dates?
the wizard.",Author Utterance Frame,[0],[0]
The comparison requests and the binary questions were added after analysing the dialogues.,Author Utterance Frame,[0],[0]
The comparison requests correspond to the request compare dialogue act.,Author Utterance Frame,[0],[0]
"This dialogue act is used to annotate turns when a user asks to compare different results, for instance: “Could you tell me which of these resorts offers free wifi?”.",Author Utterance Frame,[0],[0]
These questions possibly relate to several frames.,Author Utterance Frame,[0],[0]
"Binary questions are questions with slot types and slot values, e.g., “In which part of the town is the hotel located?”",Author Utterance Frame,[0],[0]
"(request act), or “Is the trip to Marseille cheaper than to Naples?”",Author Utterance Frame,[0],[0]
"(request compare act), as well as all confirm acts.",Author Utterance Frame,[0],[0]
Binary questions may concern one or several frames.,Author Utterance Frame,[0],[0]
Each dialogue starts in frame 1.,4.3 Frame Creation and Switching,[0],[0]
"New frames are introduced when the wizard offers or suggests some-
thing, or when the user modifies pre-established slots.",4.3 Frame Creation and Switching,[0],[0]
"Thus, all values discussed during the dialogue are recorded and the user can return to a previous set of constraints at any point.",4.3 Frame Creation and Switching,[0],[0]
"An example is given in Table 1: the frame number changes when the user modifies several slot values, namely, the destination city, the number of adults for the trip, and the budget.",4.3 Frame Creation and Switching,[0],[0]
"While modifying pre-established slots is supported by most dialogue systems, these rules allow us to clearly distinguishing creating frames from extending frames and thus define how the items in the dialogue memory, which the user can reference, are structured.",4.3 Frame Creation and Switching,[0],[0]
"Though frames are created for each offer or suggestion made by the wizard, the active frame can only be changed by the user so that the user has control over the dialogue.",4.3 Frame Creation and Switching,[0],[0]
"When creating frames, the annotator can explicitly mark which frame the new frame is derived from, which heuristically copies some of its content to the new frame.",4.3 Frame Creation and Switching,[0],[0]
"If not annotated, we assume it is derived from the currently active frame.",4.3 Frame Creation and Switching,[0],[0]
"If the user asks for more information about a specific offer or suggestion, the active frame is changed to the frame introduced with that offer or suggestion.",4.3 Frame Creation and Switching,[0],[0]
This change of frame is indicated by a switch frame act (see Appendix A).,4.3 Frame Creation and Switching,[0],[0]
"The rules for creating and switching frames are summarized in Table 2.
",4.3 Frame Creation and Switching,[0],[0]
We introduced specific slot types for recording the creation and modification of frames.,4.3 Frame Creation and Switching,[0],[0]
"These slot types are id, ref, read, and write (see Table 10 in Appendix A).",4.3 Frame Creation and Switching,[0],[0]
The frame id is defined when the frame is created and is used to switch to,4.3 Frame Creation and Switching,[0],[0]
"Switching User Changing the value of a slot (it causes the dialogue to switch to that frame)
50% 2092
Considering a wizard offer or suggestion 39% 1635 Switching to an earlier frame by mentioning its slot values 11% 458
this frame when the user decides to do so.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
The other slot types are used to annotate cross-references between frames.,Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
A reference has two parts: the id of the frame it refers to and the slots and values that are used to refer to that frame (if any).,Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"For instance, ref[1{name=Tropic}] means that frame 1 is being referred to by the hotel name Tropic.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"If anaphora are used to refer to a frame, we annotated this with the slot ref anaphora (e.g., “This is too long” – inform(duration=toolong, ref anaphora=this)).",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"Inside an offer dialogue act, a ref means that the frame corresponding to the offer is derived from another frame.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
This happens for instance when a wizard proposes a package with business or economy options.,Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"In this case, the business and economy offers are derived from the hotel offer.
",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"The slot types read and write only occur inside a wizard’s inform act and are used by wizards to provide relations between offers or suggestions: read is used to indicate which frame the values come from (and which slots are used to refer to this frame, if any), while write indicates the frame where the slot values are to be written (and which slot values are used to refer to this frame, if any).",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"If there is a read without a write, the current frame is assumed as the storage for the slot values.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"A slot type without a value indicates that the value is the same as in the referenced frame, but was not mentioned explicitly e.g., “for the same price”.
",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"Table 3 gives an example of how these slot types are used in practice: inform( read=[7{dst city=Punta Cana, category=2.5}]) means that the values 2.5 and Punta Cana are to be read from frame 7, and to be written in the current frame.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"At this turn of the dialogue, the wizard repeats information from frame 7.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
"The annotation inform(breakfast=False,write= [7{name=El Mar}]) means that the value
False for breakfast is written in frame 7 and that frame 7 was identified in this utterance by the name of the hotel El Mar.
The average number of frames created per dialogue is 6.71 and the average number of frame switches is 3.58.",Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
Figure 3 shows boxplots for the number of frame creations and the number of frame changes in the corpus.,Rule Type Author Rule Description Relative Frequency Absolute Frequency,[0],[0]
Five trained experts annotated the dataset according to the above rules.,4.4 Annotation Reproducibility,[0],[0]
"To measure inter-annotator agreement, the experts annotated the same randomly chosen 10 dialogues.",4.4 Annotation Reproducibility,[0],[0]
"On this subset, we compute the inter-annotator agreement rate as the F1-score.",4.4 Annotation Reproducibility,[0],[0]
"Note that the commonly used κ statistic cannot be directly applied here, since the annotation is not a multi-class classification problem.",4.4 Annotation Reproducibility,[0],[0]
"The provided F1 score also captures how much the annotators failed to annotate words or acts, or disagreed about the correct value.",4.4 Annotation Reproducibility,[0],[0]
We report the mean and standard deviation over all possible pairing of annotators.,4.4 Annotation Reproducibility,[0],[0]
"On dialogue acts only, this score is 81.2 ± 3.1, on slot values, it is 95.2 ± 1.1, and on dialogue acts, slot values, and content of referenced frames, it is 62.3 ± 4.9.
",4.4 Annotation Reproducibility,[0],[0]
Table 3:,4.4 Annotation Reproducibility,[0],[0]
Annotation example with the write and read slot types,4.4 Annotation Reproducibility,[0],[0]
"Wizard I am only able to find hotels with a 6 inform(read=[7{dst city=Punta Cana, 2.5 star rating in Punta Cana for that time.",Author Utterance Frame Annotation,[0],[0]
category=2.5}]),Author Utterance Frame Annotation,[0],[0]
User 2.5 stars will do.,Author Utterance Frame Annotation,[0],[0]
11 inform(category=2.5) Can you offer any additional activities?,Author Utterance Frame Annotation,[0],[0]
"Wizard Unfortunately I am not able to provide 11 sorry, canthelp this information.",Author Utterance Frame Annotation,[0],[0]
User How about breakfast?,Author Utterance Frame Annotation,[0],[0]
11 request(breakfast) Wizard El Mar does not provide breakfast.,Author Utterance Frame Annotation,[0],[0]
"11 inform(breakfast=False, write=[7{name=El Mar}])
id=0 (current)",Author Utterance Frame Annotation,[0],[0]
id=1 dst city=Mannheim or city=Melbourne price=8000USD id=2,Author Utterance Frame Annotation,[0],[0]
dst city=New York or city=Melbourne id=3,Author Utterance Frame Annotation,[0],[0]
"(new)
inform(dst city=Mannheim, budget=cheaper, flex=T) Is there a cheaper package to Mannheim?",Author Utterance Frame Annotation,[0],[0]
"I’m flexible with the dates.
",Author Utterance Frame Annotation,[0],[0]
Figure 4: Illustration of the frame tracking task.,Author Utterance Frame Annotation,[0],[0]
"The model must choose, for each slot, which frame it is referring to, given the set of available frames, the previous active frame (bold), and the potential new frame (marked “(new)”).",Author Utterance Frame Annotation,[0],[0]
"Frames can be used to study many aspects of goaloriented dialogue, from Natural Language Understanding (NLU) to Natural Language Generation (NLG).",5 Research Topics,[0],[0]
"In this section, we propose three topics that we believe are new and representative of Frames.",5 Research Topics,[0],[0]
"We propose Frame tracking as an extension of state tracking (Henderson, 2015) to a setting where several semantic frames are tracked simultaneously.",5.1.1 Definition,[0],[0]
"In state tracking, the dialogue history is compressed into one semantic frame.",5.1.1 Definition,[0],[0]
"The state tracker updates a probability distribution, for each slot, over the different possible values.",5.1.1 Definition,[0],[0]
"Every time the user sets a new value, the probability distribution is updated.",5.1.1 Definition,[0],[0]
This architecture prevents the user from comparing options or returning to an item discussed earlier since the values for each slot are tracked separately.,5.1.1 Definition,[0],[0]
"In frame tracking, a new value creates a new semantic frame.",5.1.1 Definition,[0],[0]
"The frame tracking task is significantly harder as it requires, for each user utterance, identifying the active frame as well as all the frames modified by the utterance.",5.1.1 Definition,[0],[0]
"An example is provided in Fig. 4.
",5.1.1 Definition,[0],[0]
Definition 1 (Frame Tracking).,5.1.1 Definition,[0],[0]
"At each user turn t, we assume access to the full dialogue history H = {f1, ..., fnt−1}, where fi is a frame and nt−1 is the number of frames created so far in the dialogue.",5.1.1 Definition,[0],[0]
"For a user utterance ut at time t, we provide the following NLU labels: dialogue acts, slot types, and slot values.",5.1.1 Definition,[0],[0]
"The goal of frame tracking is to predict if a new frame is created and to predict for each dialogue act the ref labels (possibly none) and the ids of the frames referenced.
",5.1.1 Definition,[0],[0]
"Predicting the frame that is referenced by a dialogue act requires detecting if a new frame is created and recognizing a previous frame from the values mentioned by the user (potentially synonyms, e.g., NYC for New York), or by using the user utterance directly.",5.1.1 Definition,[0],[0]
It is necessary in many cases to use the user utterance directly because users do not always use slot values to refer to previous frames.,5.1.1 Definition,[0],[0]
An example in the corpus is a user asking: “Which package has the soonest departure?”.,5.1.1 Definition,[0],[0]
"In this case, the user refers to several frames (the packages) without ever explicitly describing which ones.",5.1.1 Definition,[0],[0]
This phenomenon is quite common for dialogue acts such as switch frame (979 occurrences in the corpus) and request compare (455 occurrences in the corpus).,5.1.1 Definition,[0],[0]
"These cases can only be resolved by working on the text directly and solving anaphora.
",5.1.1 Definition,[0],[0]
"Note that when talking with real users, a system would need to generate the frames dynamically during the dialogue.",5.1.1 Definition,[0],[0]
We propose the frame tracking task as a first step and we show in Section 6.2 that this simplified task entails many challenges.,5.1.1 Definition,[0],[0]
We define two metrics: frame identification and frame creation.,5.1.2 Evaluation Metrics,[0],[0]
"For frame identification, for each dialogue act, we compare the ground truth pair (key-value, frame) to that predicted by the frame tracker.",5.1.2 Evaluation Metrics,[0],[0]
"We compute performance as the number of correct predictions over the number of
pairs.",5.1.2 Evaluation Metrics,[0],[0]
The frame is the id of the referenced frame.,5.1.2 Evaluation Metrics,[0],[0]
"The key and value are respectively the type and the value of the slot used to refer to the frame (these can be null).
",5.1.2 Evaluation Metrics,[0],[0]
"For frame creation, we compute the number of times the frame tracker correctly predicts that a frame is created or correctly predicts that a frame has not been created over the number of dialogue turns.",5.1.2 Evaluation Metrics,[0],[0]
"In previous work, some limitations of sequential slot filling dialogue systems were addressed using goal-modeling (Crook and Lemon, 2010; Crook et al., 2012; Misu et al., 2011), task tracking (Lee and Stent, 2016) and memory-augmentation of classical state tracking (Weston et al., 2015).
",5.1.3 Related Work,[0],[0]
Crook and Lemon (2010); Crook et al. (2012) model the user goal as a subset of all possible slot value combinations and propose techniques to automatically compress this huge space into a summary space.,5.1.3 Related Work,[0],[0]
"Rewards, transitions, and observations of a POMDP system can then be projected to the reduced space, which facilitates policy learning.",5.1.3 Related Work,[0],[0]
Misu et al. (2011) propose a method for decision support in spoken dialogue systems that aids a user who is assumed to have an (unknown) weighted preference over the possible slot values and limited knowledge about alternatives.,5.1.3 Related Work,[0],[0]
The authors employ a user simulator that outputs dialogue acts to learn a policy that optimizes the sum of the weights of the final user selection.,5.1.3 Related Work,[0],[0]
The Frames dataset allows learning and evaluating these techniques on a large and more realistic text-based dataset.,5.1.3 Related Work,[0],[0]
"Additionally, the memorized frames would allow a dialogue system to compare disjunct goals or return to earlier states.
",5.1.3 Related Work,[0],[0]
Recent approaches to state tracking have been suggested to go beyond the sequential slot-filling approach.,5.1.3 Related Work,[0],[0]
An important contribution is the Task Lineage-based Dialog State Tracking (TL-DST) proposed by Lee and Stent (2016).,5.1.3 Related Work,[0],[0]
TL-DST is a framework that allows keeping track of tasks across different domains.,5.1.3 Related Work,[0],[0]
"Similarly to frame tracking, Lee and Stent propose building a dynamic structure of the dialogue containing different frames corresponding to different tasks.",5.1.3 Related Work,[0],[0]
They defined different sub-tasks among which task frame parsing which is closely related to frame tracking except that they impose constraints on how a dialogue act can be assigned to a frame and a dialogue act can only relate to one frame.,5.1.3 Related Work,[0],[0]
"Because of the lack of data, Lee
and Stent (2016) trained their tracking model on datasets released for DSTC (DSTC2 and DSTC3, Henderson et al., 2014b,a).",5.1.3 Related Work,[0],[0]
"As a result, they could artificially mix different tasks, e.g., looking for a restaurant and looking for a pub, but they could not study how human beings switch between topics.",5.1.3 Related Work,[0],[0]
"In addition, this framework can switch between different tasks but does not handle comparisons between disjunct frames, which is an important aspect of frame tracking.
",5.1.3 Related Work,[0],[0]
Another related approach was proposed by Perez and Liu (2016) who re-interpreted the state tracking task as a question-answering task.,5.1.3 Related Work,[0],[0]
"Their state tracker is based on a memory network (Weston et al., 2015) and can answer questions about the user goal at the end of the dialogue.",5.1.3 Related Work,[0],[0]
"They also propose adding functionalities such as keeping a list of the constraints expressed by the user during the dialogue.
",5.1.3 Related Work,[0],[0]
The Frames dataset may be used to test and validate these approaches on real data.,5.1.3 Related Work,[0],[0]
"In addition, we propose the frame tracking task as benchmark and as a first step towards modelling complex decisionmaking behaviour.",5.1.3 Related Work,[0],[0]
"Most of the time, the wizard would speak about the current frame to ask or answer questions.",5.2 Dialogue Management,[0],[0]
"However, sometimes, the wizard would talk about previous frames.",5.2 Dialogue Management,[0],[0]
"An example is given in Table 11 in Appendix A. In the bold utterance in this dialogue, the wizard mentions a frame which is not the currently active frame.",5.2 Dialogue Management,[0],[0]
"In order to reproduce this kind of behaviour, a dialogue manager would need to be able to identify potentially relevant frames for the current turn and to output actions for these frames.
",5.2 Dialogue Management,[0],[0]
Table 11 also illustrates another novelty.,5.2 Dialogue Management,[0],[0]
"In the utterance in italics, the wizard actually performs two actions.",5.2 Dialogue Management,[0],[0]
"The first action consists of informing the user about the price of the regal resort and the second action consists of proposing another option, Hotel Globetrotter.",5.2 Dialogue Management,[0],[0]
"Performing more than one action per turn is a challenge when using reinforcement learning (Pietquin et al., 2011; Gašić et al., 2012; Fatemi et al., 2016) and, to our knowledge, has only been tackled in a simulated setting (Laroche et al., 2009).",5.2 Dialogue Management,[0],[0]
An interesting behaviour observed in Frames is that wizards often tend to summarize database results.,5.3 Natural Language Generation,[0],[0]
"An example is a wizard saying: “The cheapest
available flight is 1947.14USD.”",5.3 Natural Language Generation,[0],[0]
"In this case, the wizard informs the user that the database has no cheaper result than the one she is proposing.",5.3 Natural Language Generation,[0],[0]
"To imitate this behaviour, a natural language generator (Oh and Rudnicky, 2000; Wen et al., 2015; Sharma et al., 2017) would need to reason over the database and decide how to tailor the results to the user and present them in a concise but sufficient way.",5.3 Natural Language Generation,[0],[0]
"Various strategies and their combinations can be employed, e.g. summarization, comparison or recommendation (Rieser and Lemon, 2009).",5.3 Natural Language Generation,[0],[0]
A decision-theoretical foundation of such an approach was presented by Walker et al. (2004).,5.3 Natural Language Generation,[0],[0]
A data-driven approach to attribute selection for NLG as planning under uncertainty was proposed by Rieser et al. (2014).,5.3 Natural Language Generation,[0],[0]
"The Frames dataset contains a larger set of dialogues as well as wizard-generated text with detailed annotations, which we believe will provide insight into when humans use which strategy and how they present the information.",5.3 Natural Language Generation,[0],[0]
We developed baseline models for natural language understanding and frame tracking.,6 Baselines,[0],[0]
"We define the NLU task as dialogue act prediction and IOB (Inside, Outside, Beginning) tagging.",6.1 Natural Language Understanding,[0],[0]
The NLU model that we propose as baseline is illustrated in Fig. 5.,6.1 Natural Language Understanding,[0],[0]
"We predict, for each word of the utterance, a pair of tags – one for the act and one for the slot.",6.1 Natural Language Understanding,[0],[0]
"This model operates on character trigrams and is based on the robust named entity recognition model (Arnold et al., 2016) except that it has two heads instead of one: one head for the slot type (either a slot type or an O tag) as in the original model and one head for dialogue act prediction.",6.1 Natural Language Understanding,[0],[0]
"These two parts share an embedding matrix for the input character trigrams.
",6.1 Natural Language Understanding,[0],[0]
We generated the IOB tags by matching the slot values in the manual annotations with the corresponding textual utterances.,6.1 Natural Language Understanding,[0],[0]
Note that the model only predicts IOB tags for slots whose values can be found in the text.,6.1 Natural Language Understanding,[0],[0]
"Therefore, the prediction for slots such as intent or vicinities and amenities is not evaluated for this simple baseline.",6.1 Natural Language Understanding,[0],[0]
"The act tags were also generated at the word level: for a given dialogue act with slot values, each word between the slot value that occurred first in the text and the one that occurred last in the text was tagged with the corresponding act.",6.1 Natural Language Understanding,[0],[0]
"For example, for the utterance I am only able to find hotels with a 2.5 star rating in Punta Cana for that time.",6.1 Natural Language Understanding,[0],[0]
", the words 2.5 star rating in Punta Cana are tagged with the inform dialogue act.",6.1 Natural Language Understanding,[0],[0]
"The other words are tagged with O.
The two parts of the model are trained simultaneously, using a modified categorical crossentropy loss for both sets of outputs.",6.1 Natural Language Understanding,[0],[0]
We modify the loss to ignore O labels that are already predicted correctly by the model.,6.1 Natural Language Understanding,[0],[0]
"We introduce this modification because O labels are far more frequent than other labels, and not limiting their contribution to the loss causes the model to degenerate to predicting O labels for every word.",6.1 Natural Language Understanding,[0],[0]
"The losses for both parts of the model are added together and the combined objective is optimized using ADAM (Kingma and Ba, 2015).
",6.1 Natural Language Understanding,[0],[0]
We provide F1 scores for acts and slots for this model in Table 4.,6.1 Natural Language Understanding,[0],[0]
"We report average and stan-
dard deviation over ten leave-one-user-out splits of the Frames dataset.",6.1 Natural Language Understanding,[0],[0]
We had a total of 11 participants who played the user role at least once during data collection.,6.1 Natural Language Understanding,[0],[0]
Two participants performed significantly fewer dialogues than the others.,6.1 Natural Language Understanding,[0],[0]
We merged the dialogues generated by these two participants (ids U21E41CQP and U23KPC9QV).,6.1 Natural Language Understanding,[0],[0]
"For each of the resulting 10 users, we randomly split the combined dialogues of the nine others into training (80%) and validation (20%), and then tested on the dialogues from the held-out user.",6.1 Natural Language Understanding,[0],[0]
"We propose a rule-based frame tracking baseline which takes as input the dialogue acts with slot types and slot values but without the referenced frames (i.e., the ref slots) as well as all the frames created so far during the dialogue.",6.2 Frame Tracking,[0],[0]
"Based on this input, the tracker predicts the ref tags (for frame identification, see Section 5.1.2) for each dialogue act, and it predicts if a frame is created.",6.2 Frame Tracking,[0],[0]
We write f,6.2 Frame Tracking,[0],[0]
[k] to denote the value of slot k in frame f .,6.2 Frame Tracking,[0],[0]
"For an act a(k=v) in frame f , the following rules are used:
• Create and switch to a new frame if f",6.2 Frame Tracking,[0],[0]
"[k] is set and a is inform, but v does not match f",6.2 Frame Tracking,[0],[0]
[k].,6.2 Frame Tracking,[0],[0]
• Switch to frame g if a is switch frame and g[k] matches v.,6.2 Frame Tracking,[0],[0]
"If no match is found, switch to the most recently created frame.3 • Assign ref to frame g if a can have a ref tag, and g[k] matches v. The most recently created frame is used in ambiguous cases.",6.2 Frame Tracking,[0],[0]
"If no match is found, assign ref to the current frame.
",6.2 Frame Tracking,[0],[0]
We compare this baseline to random performance.,6.2 Frame Tracking,[0],[0]
"For random performance, for each (dialogue act, slot type) combination, we compute priors on the corpus for each time the user would refer to the current frame vs a previous one.",6.2 Frame Tracking,[0],[0]
"We sampled whether each slot referred to the current frame or another one based on that prior, and if it referred to another frame, the frame number for that other frame was sampled uniformly from the list of frames created so far.
",6.2 Frame Tracking,[0],[0]
Table 5 presents results for these baselines.,6.2 Frame Tracking,[0],[0]
We report results over 10 runs following the same evaluation method as for the NLU model.,6.2 Frame Tracking,[0],[0]
"Table 5 shows that the rule-based model performs only slightly better than random on frame identification
3a reasonable assumption since this case often happens when a wizard makes an offer and the user talks about it.
and performs similarly on frame creation.",6.2 Frame Tracking,[0],[0]
Table 6 presents an analysis of the performance of the rulebased model.,6.2 Frame Tracking,[0],[0]
We report the accuracy of the frame tracking baseline on the most crucial sub-tasks of frame tracking for one fold.,6.2 Frame Tracking,[0],[0]
The top table shows that the most difficult tasks consist of assigning the correct frame to a switch frame act when the act is not directly preceded by an offer and when the act has no slots.,6.2 Frame Tracking,[0],[0]
"As discussed previously, when the act has no slots, it is important to consider the text and solve anaphora.",6.2 Frame Tracking,[0],[0]
"When the act is directly preceded by an offer, the baseline assigns the previous frame, which is the frame of the offer and which most of the time is the frame that the user switched to, e.g., to ask for more information about the offer.",6.2 Frame Tracking,[0],[0]
"In terms of frame creation, the baseline has very poor performance in correctly predicting that a frame is created because the user changes the value of a previously set slot.",6.2 Frame Tracking,[0],[0]
These results demonstrate that frame tracking cannot be solved with simple rules and necessitates tackling many complex sub-tasks.,6.2 Frame Tracking,[0],[0]
We introduced the Frames dataset: a corpus of human-human dialogues in a travel domain.,7 Conclusion,[0],[0]
This dataset contains complex user behaviour such as comparing between offers.,7 Conclusion,[0],[0]
"We formalized the frame tracking task, which requires tracking simultaneously several semantic frames during a dialogue.",7 Conclusion,[0],[0]
We proposed a rule-based model for this task and analysed its performance.,7 Conclusion,[0],[0]
We release Frames in the hope of driving further research on complex decision-making in the dialogue community.,7 Conclusion,[0],[0]
"Wizard A 5 star hotel called the Regal Resort, Wizard it has free wifi and a spa.",Author Utterance,[0],[0]
User dates?,Author Utterance,[0],[0]
Wizard Starts on august 27th until the 30th User ok that could work.,Author Utterance,[0],[0]
"I would like to see my options in Santos as well Wizard regal resort goes for $2800 or there is the Hotel
Globetrotter in Santos it has 3 stars and comes with breakfast and wifi, it leaves on the 25th and returns on the 30th!",Author Utterance,[0],[0]
"all for $2000
User",Author Utterance,[0],[0]
ahh,Author Utterance,[0],[0]
I can’t leave until august 26 though Wizard then i guess you might have to choose the Regal resort,Author Utterance,[0],[0]
User,Author Utterance,[0],[0]
yeah.,Author Utterance,[0],[0]
I will book it Wizard Thank you!,Author Utterance,[0],[0]
"This paper proposes a new dataset, Frames, composed of 1369 human-human dialogues with an average of 15 turns per dialogue.",abstractText,[0],[0]
This corpus contains goal-oriented dialogues between users who are given some constraints to book a trip and assistants who search a database to find appropriate trips.,abstractText,[0],[0]
"The users exhibit complex decision-making behaviour which involve comparing trips, exploring different options, and selecting among the trips that were discussed during the dialogue.",abstractText,[0],[0]
"To drive research on dialogue systems towards handling such behaviour, we have annotated and released the dataset and we propose in this paper a task called frame tracking.",abstractText,[0],[0]
This task consists of keeping track of different semantic frames throughout each dialogue.,abstractText,[0],[0]
We propose a rule-based baseline and analyse the frame tracking task through this baseline.,abstractText,[0],[0]
Frames: A Corpus for Adding Memory to Goal-Oriented Dialogue Systems,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 773–783 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1072",text,[0],[0]
"Ideas exist in the mind, but are made manifest in language, where they compete with each other for the scarce resource of human attention.",1 Introduction,[0],[0]
Milton (1644) used the “marketplace of ideas” metaphor to argue that the truth will win out when ideas freely compete; Dawkins (1976) similarly likened the evolution of ideas to natural selection of genes.,1 Introduction,[1.0],['Milton (1644) used the “marketplace of ideas” metaphor to argue that the truth will win out when ideas freely compete; Dawkins (1976) similarly likened the evolution of ideas to natural selection of genes.']
"We propose a framework to quantitatively characterize competition and cooperation between ideas in texts, independent of how they might be represented.
",1 Introduction,[0.9999999651765772],"['We propose a framework to quantitatively characterize competition and cooperation between ideas in texts, independent of how they might be represented.']"
"By “ideas”, we mean any discrete conceptual
units that can be identified as being present or absent in a document.",1 Introduction,[1.000000069141342],"['By “ideas”, we mean any discrete conceptual units that can be identified as being present or absent in a document.']"
"In this work, we consider representing ideas using keywords and topics obtained in an unsupervised fashion, but our way of characterizing the relations between ideas could be applied to many other types of textual representations, such as frames (Card et al., 2015) and hashtags.
",1 Introduction,[1.0000000298113407],"['In this work, we consider representing ideas using keywords and topics obtained in an unsupervised fashion, but our way of characterizing the relations between ideas could be applied to many other types of textual representations, such as frames (Card et al., 2015) and hashtags.']"
"What does it mean for two ideas to compete in texts, quantitatively?",1 Introduction,[1.0],"['What does it mean for two ideas to compete in texts, quantitatively?']"
"Consider, for example, the issue of immigration.",1 Introduction,[0],[0]
There are two strongly competing narratives about the roughly 11 million people1 who are residing in the United States without permission.,1 Introduction,[0],[0]
"One is “illegal aliens”, who “steal” jobs and deny opportunities to legal immigrants; the other is “undocumented immigrants”, who are already part of the fabric of society and deserve a path to citizenship (Merolla et al., 2013).
",1 Introduction,[0.9999999406490536],"['One is “illegal aliens”, who “steal” jobs and deny opportunities to legal immigrants; the other is “undocumented immigrants”, who are already part of the fabric of society and deserve a path to citizenship (Merolla et al., 2013).']"
"Although prior knowledge suggests that these two narratives compete, it is not immediately obvious what measures might reveal this competition in a corpus of writing about immigration.",1 Introduction,[0],[0]
One question is whether or not these two ideas cooccur in the same documents.,1 Introduction,[0],[0]
"In the example above, these narratives are used by distinct groups of people with different ideologies.",1 Introduction,[1.0],"['In the example above, these narratives are used by distinct groups of people with different ideologies.']"
"The fact that they don’t cooccur is one clue that they may be in competition with each other.
",1 Introduction,[0.9999999464147843],['The fact that they don’t cooccur is one clue that they may be in competition with each other.']
"However, cooccurrence is insufficient to express the selection process of ideas, i.e., some ideas fade out over time, while others rise in popularity, analogous to the populations of species in nature.",1 Introduction,[0],[0]
"Of the two narratives on immigration, we may expect one to win out at the expense of another as public opinion shifts.",1 Introduction,[0],[0]
"Alternatively, we might expect to see these narratives reinforcing each other, as both sides intensify their messaging in response to growing opposition, much like the U.S.S.R. and
1As of 2014, according to the most recent numbers from the Center for Migration Studies (Warren, 2016).
",1 Introduction,[0],[0]
"773
the U.S. during the cold war.",1 Introduction,[0],[0]
"To capture these possibilities, we use prevalence correlation over time.
",1 Introduction,[0],[0]
"Building on these insights, we propose a framework that combines cooccurrence within documents and prevalence correlation over time.",1 Introduction,[1.0],"['Building on these insights, we propose a framework that combines cooccurrence within documents and prevalence correlation over time.']"
This framework gives rise to four possible types of relation that correspond to the four quadrants in Fig. 1.,1 Introduction,[0],[0]
We explain each type using examples from news articles in U.S. newspapers on immigration from 1980 to 2016.,1 Introduction,[0],[0]
"Here, we have used LDA to identify ideas in the form of topics, and we denote each idea with a pair of words most strongly associated with the corresponding topic.
",1 Introduction,[0],[0]
"Friendship (correlated over time, likely to cooccur).",1 Introduction,[1.0],"['Friendship (correlated over time, likely to cooccur).']"
"The “immigrant, undocumented” topic tends to cooccur with “obama, president” and both topics have been rising during the period of our dataset, likely because the “undocumented immigrants” narrative was an important part of Obama’s framing of the immigration issue (Haynes et al., 2016).
",1 Introduction,[0.9999999358741802],"['The “immigrant, undocumented” topic tends to cooccur with “obama, president” and both topics have been rising during the period of our dataset, likely because the “undocumented immigrants” narrative was an important part of Obama’s framing of the immigration issue (Haynes et al., 2016).']"
"Head-to-head (anti-correlated over time, unlikely to cooccur).",1 Introduction,[0],[0]
"“immigrant, undocumented” and “illegal, alien” are in a head-to-head competition: these two topics rarely cooccur, and “immigrant, undocu-
mented” has been growing in prevalence, while the usage of “illegal, alien” in newspapers has been declining.",1 Introduction,[0],[0]
"This observation agrees with a report from Pew Research Center (Guskin, 2013).
",1 Introduction,[0],[0]
"Tryst (anti-correlated over time, likely to cooccur).",1 Introduction,[1.0],"['Tryst (anti-correlated over time, likely to cooccur).']"
The two off-diagonal examples use topics related to law enforcement.,1 Introduction,[0],[0]
"Overall, “immigration, deportation” and “detention, jail” often cooccur but “detention, jail” has been declining, while “immigration, deportation” has been rising.",1 Introduction,[0],[0]
"This possibly relates to the promises to overhaul the immigration detention system (Kalhan, 2010).2
Arms-race (correlated over time, unlikely to cooccur).",1 Introduction,[1.000000031090623],"['This possibly relates to the promises to overhaul the immigration detention system (Kalhan, 2010).2 Arms-race (correlated over time, unlikely to cooccur).']"
"One of the above law enforcement topics (“immigration, deportation”) and a topic on the Republican party (“republican, party”) hold an armsrace relation: they are both growing in prevalence over time, but rarely cooccur, perhaps suggesting an underlying common cause.
",1 Introduction,[0],[0]
"2The tryst relation is the least intuitive, yet is nevertheless observed.",1 Introduction,[0],[0]
"The pattern of being anti-correlated yet likely to cooccur is typically found when two ideas exhibit a friendship pattern (cooccurring and correlated), but only briefly, and then diverge.
",1 Introduction,[0],[0]
"Note that our terminology describes the relations between ideas in texts, not necessarily between the entities to which the ideas refer.",1 Introduction,[1.0],"['Note that our terminology describes the relations between ideas in texts, not necessarily between the entities to which the ideas refer.']"
"For example, we find that the relation between “Israel” and “Palestine” is “friendship” in news articles on terrorism, based on their prevalence correlation and cooccurrence in that corpus.
We introduce the formal definition of our framework in §2 and apply it to news articles on five issues and research papers from ACL Anthology and NIPS as testbeds.",1 Introduction,[0],[0]
"We operationalize ideas using topics (Blei et al., 2003) and keywords (Monroe et al., 2008).
",1 Introduction,[1.0000000328786451],"['We operationalize ideas using topics (Blei et al., 2003) and keywords (Monroe et al., 2008).']"
"To explore whether the four relation types exist and how strong these relations are, we first examine the marginal and joint distributions of cooccurrence and prevalence correlation (§3).",1 Introduction,[0],[0]
We find that cooccurrence shows a unimodal normal-shaped distribution but prevalence correlation demonstrates more diverse distributions across corpora.,1 Introduction,[0],[0]
"As we would expect, there are, in general, more and stronger friendship and head-to-head relations than arms-race and tryst relations.
",1 Introduction,[0],[0]
"Second, we demonstrate the effectiveness of our framework through in-depth case studies (§4).",1 Introduction,[0],[0]
"We not only validate existing knowledge about some news issues and research areas, but also identify hypotheses that require further investigation.",1 Introduction,[0],[0]
"For example, using keywords to represent ideas, a top pair with the tryst relation in news articles on terrorism is “arab” and “islam”; they are likely to cooccur, but “islam” is rising in relative prevalence while “arab” is declining.",1 Introduction,[0],[0]
This suggests a conjecture that the news media have increasingly linked terrorism to a religious group rather than an ethnic group.,1 Introduction,[0],[0]
"We also show relations between topics in ACL that center around machine translation.
",1 Introduction,[0],[0]
"Our work is a first step towards understanding relations between ideas from text corpora, a complex and important research question.",1 Introduction,[0],[0]
We provide some concluding thoughts in §6.,1 Introduction,[0],[0]
The aim of our computational framework is to explore relations between ideas.,2 Computational Framework,[0],[0]
"We thus assume that the set of relevant ideas has been identified, and those expressed in each document have been tabulated.",2 Computational Framework,[0],[0]
Our open-source implementation is at https://github.com/Noahs-ARK/ idea_relations/.,2 Computational Framework,[0],[0]
"In the following, we introduce our formal definitions and datasets.
∀x, y ∈",2 Computational Framework,[0],[0]
"I, P̂MI(x, y) = log P̂ (x, y) P̂ (x)P̂ (y)
",2 Computational Framework,[0],[0]
"= C + log 1+ ∑ t ∑ k 1{x∈dtk}·1{y∈dtk}
(1+ ∑
t ∑ k 1{x∈dtk})·(1+ ∑ t ∑ k 1{y∈dtk})
(1)
r̂(x, y) =
∑ t ( P̂ (x|t)−P̂ (x|t) )",2 Computational Framework,[0],[0]
"( P̂ (y|t)−P̂ (y|t) )
",2 Computational Framework,[0],[0]
"√ ∑
t
( P̂ (x|t)−P̂ (x|t) )",2 Computational Framework,[0],[0]
"2√∑ t ( P̂ (y|t)−P̂ (y|t) )2
",2 Computational Framework,[0],[0]
"(2)
Figure 2: Eq. 1 is the empirical pointwise mutual information for two ideas, our measure of cooccurrence of ideas; note that we use add-one smoothing in estimating PMI.",2 Computational Framework,[0],[0]
Eq. 2 is the Pearson correlation between two ideas’ prevalence over time.,2 Computational Framework,[0],[0]
"As discussed in the introduction, we focus on two dimensions to quantify relations between ideas:
1.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"cooccurrence reveals to what extent two ideas tend to occur in the same contexts;
2.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"similarity between the relative prevalence of ideas over time reveals how two ideas relate in terms of popularity or coverage.
",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"Our input is a collection of documents, each represented by a set of ideas and indexed by time.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"We denote a static set of ideas as I and a text corpus that consists of these ideas as C = {D1, . . .",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
", DT }, where Dt = {dt1 , . . .",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
", dtNt} gives the collection of documents at timestep t, and each document, dtk , is represented as a subset of ideas in I.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"Here T is the total number of timesteps, and Nt is the number of documents at timestep t.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"It follows that the total number of documents N = ∑T t=1Nt.
",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"In order to formally capture the two dimensions above, we employ two commonly-used statistics.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"First, we use empirical pointwise mutual information (PMI) to capture the cooccurrence of ideas within the same document (Church and Hanks, 1990); see Eq. 1 in Fig. 2.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
Positive,2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"P̂MI indicates that ideas occur together more frequently than would be expected if they were independent, while negative P̂MI indicates the opposite.
",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"Second, we compute the correlation between normalized document frequency of ideas to capture the relation between the relative prevalence of ideas across documents over time; see Eq. 2 in Fig. 2.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"Positive r̂ indicates that two ideas have similar prevalence over time, while negative r̂ sug-
gests two anti-correlated ideas (i.e., when one goes up, the other goes down).
",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"The four types of relations in the introduction can now be obtained using P̂MI and r̂, which capture cooccurrence and prevalence correlation respectively.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"We further define the strength of the relation between two ideas as the absolute value of the product of their P̂MI and r̂ scores:
∀x, y ∈",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
"I, strength(x, y) = |P̂MI(x, y)×r̂(x, y)|.",2.1 Cooccurrence and Prevalence Correlation,[0],[0]
(3),2.1 Cooccurrence and Prevalence Correlation,[0],[0]
We use two types of datasets to validate our framework: news articles and research papers.,2.2 Datasets and Representation of Ideas,[0],[0]
"We choose these two domains because competition between ideas has received significant interest in history of science (Kuhn, 1996) and research on framing (Chong and Druckman, 2007; Entman, 1993; Gitlin, 1980; Lakoff, 2014).",2.2 Datasets and Representation of Ideas,[0],[0]
"Furthermore, interesting differences may exist in these two domains as news evolves with external events and scientific research progresses through innovations.",2.2 Datasets and Representation of Ideas,[0],[0]
• News articles.,2.2 Datasets and Representation of Ideas,[0],[0]
"We follow the strategy in Card
et al. (2015) to obtain news articles from LexisNexis on five issues: abortion, immigration, same-sex marriage, smoking, and terrorism.",2.2 Datasets and Representation of Ideas,[0],[0]
We search for relevant articles using LexisNexis subject terms in U.S. newspapers from 1980 to 2016.,2.2 Datasets and Representation of Ideas,[0],[0]
"Each of these corpora contains more than 25,000 articles.",2.2 Datasets and Representation of Ideas,[0],[0]
"Please refer to the supplementary material for details.
",2.2 Datasets and Representation of Ideas,[0],[0]
• Research papers.,2.2 Datasets and Representation of Ideas,[0],[0]
"We consider full texts of papers from two communities: our own ACL community captured by papers from ACL, NAACL, EMNLP, and TACL from 1980 to 2014 (Radev et al., 2009); and the NIPS community from 1987 to 2016.3 There are 4.8K papers from the ACL community and 6.6K papers from the NIPS community.",2.2 Datasets and Representation of Ideas,[0],[0]
"The processed datasets are available at https://chenhaot.com/ pages/idea-relations.html.
",2.2 Datasets and Representation of Ideas,[0],[0]
"In order to operationalize ideas in a text corpus, we consider two ways to represent ideas.",2.2 Datasets and Representation of Ideas,[0],[0]
•,2.2 Datasets and Representation of Ideas,[0],[0]
Topics.,2.2 Datasets and Representation of Ideas,[0],[0]
"We extract topics from each document
by running LDA (Blei et al., 2003) on each corpus C. In all datasets, we set the number of topics to 50.4 Formally, I is the 50 topics learned 3 http://papers.nips.cc/. 4We chose 50 topics based on past experience, though this could be tuned for particular applications.",2.2 Datasets and Representation of Ideas,[0],[0]
"Recall that
from the corpus, and each document is represented as the set of topics that are present with greater than 0.01 probability in the topic distribution for that document.
",2.2 Datasets and Representation of Ideas,[0],[0]
•,2.2 Datasets and Representation of Ideas,[0],[0]
Keywords.,2.2 Datasets and Representation of Ideas,[0],[0]
We identify a list of distinguishing keywords for each corpus by comparing its word frequencies to the background frequencies found in other corpora using the informative Dirichlet prior model in Monroe et al. (2008).,2.2 Datasets and Representation of Ideas,[0],[0]
We set the number of keywords to 100 for all corpora.,2.2 Datasets and Representation of Ideas,[0],[0]
"For news articles, the background corpus for each issue is comprised of all articles from the other four issues.",2.2 Datasets and Representation of Ideas,[0],[0]
"For research papers, we use NIPS as the background corpus for ACL and vice versa to identify what are the core concepts for each of these research areas.",2.2 Datasets and Representation of Ideas,[0],[0]
"Formally, I is the 100 top distinguishing keywords in the corpus and each document is represented as the set of keywords within I that are present in the document.",2.2 Datasets and Representation of Ideas,[0],[0]
"Refer to the supplementary material for a list of example keywords in each corpus.
",2.2 Datasets and Representation of Ideas,[0],[0]
"In both procedures, we lemmatize all words and add common bigram phrases to the vocabulary following Mikolov et al. (2013).",2.2 Datasets and Representation of Ideas,[0],[0]
"Note that in our analysis, ideas are only present or absent in a document, and a document can in principle be mapped to any subset of ideas in I.",2.2 Datasets and Representation of Ideas,[0],[0]
"In our experiments 90% of documents are marked as containing between 7 and 14 ideas using topics, 8 and 33 ideas using keywords.",2.2 Datasets and Representation of Ideas,[0],[0]
"To provide an overview of the four relation types in Fig. 1, we first examine the empirical distributions of the two statistics of interest across pairs of ideas.",3 Characterizing the Space of Relations,[0],[0]
"In most exploratory studies, however, we are most interested in pairs that exemplify each type of relation, i.e., the most extreme points in each quadrant.",3 Characterizing the Space of Relations,[1.0],"['In most exploratory studies, however, we are most interested in pairs that exemplify each type of relation, i.e., the most extreme points in each quadrant.']"
We thus look at these pairs in each corpus to observe how the four types differ in salience across datasets.,3 Characterizing the Space of Relations,[0],[0]
"To the best of our knowledge, the distributions of pairwise cooccurrence and prevalence correlation have not been examined in previous literature.",3.1 Empirical Distribution Properties,[0],[0]
"We thus first investigate the marginal distributions of cooccurrence and prevalence correlation and then
our framework is to analyze relations between ideas, so this choice is not essential in this work.
",3.1 Empirical Distribution Properties,[0],[0]
their joint distribution.,3.1 Empirical Distribution Properties,[0],[0]
Fig. 3 shows three examples: two from news articles and one from research papers.,3.1 Empirical Distribution Properties,[0],[0]
We will also focus our case studies on these three corpora in §4.,3.1 Empirical Distribution Properties,[0],[0]
The corresponding plots for keywords have been relegated to supplementary material due to space limitations.,3.1 Empirical Distribution Properties,[0],[0]
Cooccurrence tends to be unimodal but not normal.,3.1 Empirical Distribution Properties,[1.0],['Cooccurrence tends to be unimodal but not normal.']
"In all of our datasets, pairwise cooccurrence (P̂MI) presents a unimodal distribution that somewhat resembles a normal distribution, but it is rarely precisely normal.",3.1 Empirical Distribution Properties,[0],[0]
"We cannot reject the hypothesis that it is unimodal for any dataset (using topics or keywords) using the dip test (Hartigan and Hartigan, 1985), though D’Agostino’s K2 test (D’Agostino et al., 1990) rejects normality in almost all cases.",3.1 Empirical Distribution Properties,[0],[0]
Prevalence correlation exhibits diverse distributions.,3.1 Empirical Distribution Properties,[0],[0]
"Pairwise prevalence correlation follows different distributions in news articles compared to research papers: they are unimodal in news articles, but not in ACL or NIPS.",3.1 Empirical Distribution Properties,[0],[0]
The dip test only rejects the unimodality hypothesis in NIPS.,3.1 Empirical Distribution Properties,[0],[0]
None follow normal distributions based on D’Agostino’s K2 test.,3.1 Empirical Distribution Properties,[0],[0]
Cooccurrence is positively correlated with prevalence correlation.,3.1 Empirical Distribution Properties,[0],[0]
"In all of our datasets, cooccurrence is positively correlated with prevalence correlation whether we use topics or keywords to represent ideas, although the Pearson correlation coefficients vary.",3.1 Empirical Distribution Properties,[0],[0]
This suggests that there are more friendship and head-to-head relations than tryst and arms-race relations.,3.1 Empirical Distribution Properties,[1.0],['This suggests that there are more friendship and head-to-head relations than tryst and arms-race relations.']
"Based on the results of kernel density estimation, we also observe that this correlation is often loose, e.g., in
ACL topics, cooccurrence spreads widely at each mode of prevalence correlation.",3.1 Empirical Distribution Properties,[0],[0]
We are interested in how our framework can identify intriguing relations between ideas.,3.2 Relative Strength of Extreme Pairs,[0],[0]
"These potentially interesting pairs likely correspond to the extreme points in each quadrant instead of the ones around the origin, where PMI and prevalence correlation are both close to zero.",3.2 Relative Strength of Extreme Pairs,[0],[0]
Here we compare the relative strength of extreme pairs in each dataset.,3.2 Relative Strength of Extreme Pairs,[0],[0]
"We will discuss how these extreme pairs confirm existing knowledge and suggest new hypotheses via case studies in §4.
",3.2 Relative Strength of Extreme Pairs,[0],[0]
"For each relation type, we average the strengths of the 25 pairs with the strongest relations in that type, with strength defined in Eq. 3.",3.2 Relative Strength of Extreme Pairs,[0],[0]
"This heuristic (henceforth collective strength) allows us to collectively compare the strengths of the most prominent friendship, tryst, arms-race, and head-to-head relations.",3.2 Relative Strength of Extreme Pairs,[0],[0]
"The results are not sensitive to the choice of 25.
",3.2 Relative Strength of Extreme Pairs,[0],[0]
Fig. 4 shows the collective strength of the four types in all of our datasets.,3.2 Relative Strength of Extreme Pairs,[0],[0]
"The most common ordering is:
friendship > head-to-head > arms-race > tryst.
",3.2 Relative Strength of Extreme Pairs,[0],[0]
The fact that friendship and head-to-head relations are strong is consistent with the positive correlation between cooccurrence and prevalence correlation.,3.2 Relative Strength of Extreme Pairs,[0],[0]
"In news, friendship is the strongest relation type, but head-to-head is the strongest in ACL topics and NIPS topics.",3.2 Relative Strength of Extreme Pairs,[0],[0]
"This suggests, unsurprisingly, that there are stronger head-to-head competitions
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 co lle ct iv e st re ng th
friends tryst head-to-head arms-race
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 co lle ct iv e st re ng th
friends tryst head-to-head arms-race
(i.e., one idea takes over another) between ideas in scientific research than in news.",3.2 Relative Strength of Extreme Pairs,[0],[0]
"We also see that topics show greater strength in our scientific article collections, while keywords dominate in news, especially in friendship.",3.2 Relative Strength of Extreme Pairs,[1.0],"['We also see that topics show greater strength in our scientific article collections, while keywords dominate in news, especially in friendship.']"
"We conjecture that terms in scientific literature are often overloaded (e.g., a tree could be a parse tree or a decision tree), necessitating some abstraction when representing ideas.",3.2 Relative Strength of Extreme Pairs,[0],[0]
"In contrast, news stories are more self-contained and seek to employ consistent usage.",3.2 Relative Strength of Extreme Pairs,[0],[0]
We present case studies based on strongly related pairs of ideas in the four types of relation.,4 Exploratory Studies,[0],[0]
"Throughout this section, “rank” refers to the rank of the relation strength between a pair of ideas in its corresponding relation type.",4 Exploratory Studies,[0],[0]
"Following a decade of declining violence in the 90s, the events of September 11, 2001 precipitated a dramatic increase in concern about terrorism, and a major shift in how it was framed (Kern et al., 2003).",4.1 International Relations in Terrorism,[0],[0]
"As a showcase, we consider a topic which encompasses much of the U.S. government’s response to terrorism: “federal, state”.5 We observe two topics engaging in an “arms race” with this one: “afghanistan, taliban” and “pakistan, india”.",4.1 International Relations in Terrorism,[1.0],"['As a showcase, we consider a topic which encompasses much of the U.S. government’s response to terrorism: “federal, state”.5 We observe two topics engaging in an “arms race” with this one: “afghanistan, taliban” and “pakistan, india”.']"
"These correspond to two geopolitical regions closely linked to the U.S. government’s concern with terrorism, and both were sites of U.S. military action during the period of our dataset.",4.1 International Relations in Terrorism,[0],[0]
"Events abroad and the U.S. government’s responses follow the arms-race pattern, each holding increasing
5As in §1, we summarize each topic using a pair of strongly associated words, instead of assigning a name.
attention with the other, likely because they share the same underlying cause.
",4.1 International Relations in Terrorism,[0],[0]
"We also observe two head-to-head rivals to the “federal, state” topic: “iran, libya” and “israel, palestinian”.",4.1 International Relations in Terrorism,[0],[0]
"While these topics correspond to regions that are hotly debated in the U.S., their coverage in news tends not to correlate temporally with the U.S. government’s responses to terrorism, at least during the time period of our corpus.",4.1 International Relations in Terrorism,[0],[0]
"Discussion of these regions was more prevalent in the 80s and 90s, with declining media coverage since then (Kern et al., 2003).
",4.1 International Relations in Terrorism,[0],[0]
"The relations between these topics are consistent with structural balance theory (Cartwright and Harary, 1956; Heider, 1946), which suggests that the enemy of an enemy is a friend.",4.1 International Relations in Terrorism,[0],[0]
"The “afghanistan, taliban” topic has the strongest friendship relation with the “pakistan, india” topic, i.e., they are likely to cooccur and are positively correlated in prevalence.",4.1 International Relations in Terrorism,[0],[0]
"Similarly, the “iran, libya” topic is a close “friend” with the “israel, palestinian” topic (ranked 8th in friendship).
",4.1 International Relations in Terrorism,[0],[0]
"When using keywords to represent ideas, we observe similar relations between the term homeland security and terms related to the above foreign countries.",4.1 International Relations in Terrorism,[0],[0]
"In addition, we highlight an interesting but unexpected tryst relation between arab and islam (Fig. 6).",4.1 International Relations in Terrorism,[0],[0]
"It is not surprising that these two words tend to cooccur in the same news articles, but the usage of islam in the news is increasing while arab is declining.",4.1 International Relations in Terrorism,[0],[0]
"The increasing prevalence of islam and decreasing prevalence of arab over this time period can also be seen, for example, using Google’s n-gram viewer, but it of course provides no information about cooccurrence.
",4.1 International Relations in Terrorism,[0],[0]
"This trend has not been previously noted to the best of our knowledge, although an article in the Huffington Post called for news editors to distinguish Muslim from Arab.6 Our observation suggests a conjecture that the news media have increasingly linked terrorism to a religious group rather than an ethnic group, perhaps in part due to the tie between the events of 9/11 and Afghanistan, which is not an Arab or Arabic-speaking country.",4.1 International Relations in Terrorism,[0],[0]
"We leave it to further investigation to confirm or reject this hypothesis.
",4.1 International Relations in Terrorism,[0],[0]
"To further demonstrate the effectiveness of our approach, we compare a pair’s rank using only cooccurrence or prevalence correlation with its rank in our framework.",4.1 International Relations in Terrorism,[0],[0]
Table 1 shows the results for three pairs above.,4.1 International Relations in Terrorism,[1.0],['Table 1 shows the results for three pairs above.']
"If we had looked at only cooccurrence or prevalence correlation, we would probably have missed these interesting pairs.
",4.1 International Relations in Terrorism,[0.9999999454650454],"['If we had looked at only cooccurrence or prevalence correlation, we would probably have missed these interesting pairs.']"
6http://www.huffingtonpost.com/ haroon-moghul/even-the-new-york-times-d_ b_766658.html,4.1 International Relations in Terrorism,[0],[0]
"In addition to results on topics in §1, we observe unexpected patterns about ethnicity keywords in immigration news.",4.2 Ethnicity Keywords in Immigration,[0],[0]
Our observation starts with a top tryst relation between latino and asian.,4.2 Ethnicity Keywords in Immigration,[0],[0]
"Although these words are likely to cooccur, their prevalence trajectories differ, with the discussion of Asian immigrants in the 1990s giving way to a focus on the word latino from 2000 onward.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"Possible theories to explain this observation include that undocumented immigrants are generally perceived as a Latino issue, or that Latino voters are increasingly influential in U.S. elections.
",4.2 Ethnicity Keywords in Immigration,[0],[0]
"Furthermore, latino holds head-to-head relations with two subgroups of Latin American immigrants: haitian and cuban.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"In particular, the strength of the relation with haitian is ranked #18 in headto-head relations.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"Meanwhile, haitian and cuban have a friendship relation, which is again consistent with structural balance theory.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"The decreasing prevalence of haitian and cuban perhaps speaks to the shifting geographical focus of recent immigration to the U.S., and issues of the Latino panethnicity.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"In fact, a majority of Latinos prefer to identify with their national origin relative to the
pan-ethnic terms (Taylor et al., 2012).",4.2 Ethnicity Keywords in Immigration,[0],[0]
"However, we should also note that much of this coverage relates to a set of specific refugee crises, temporarily elevating the political importance of these nations in the U.S.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"Nevertheless, the underlying social and political reasons behind these head-to-head relations are worth further investigation.",4.2 Ethnicity Keywords in Immigration,[0],[0]
"Finally, we analyze relations between topics in the ACL Anthology.",4.3 Relations between Topics in ACL,[0],[0]
It turns out that “machine translation” is at a central position among top ranked relations in all the four types (Fig.,4.3 Relations between Topics in ACL,[0],[0]
8).7,4.3 Relations between Topics in ACL,[0],[0]
"It is part of the strongest relation in all four types except tryst (ranked #5).
",4.3 Relations between Topics in ACL,[0],[0]
The full relation graph presents further patterns.,4.3 Relations between Topics in ACL,[0],[0]
Friendship demonstrates transitivity: both “machine translation” and “word alignment” have similar relations with other topics.,4.3 Relations between Topics in ACL,[0],[0]
"But such transitivity does not hold for tryst: although the prevalence of “rule, forest methods” is anti-correlated with both “machine translation” and “sentiment analysis”, “sentiment analysis” seldom cooccurs with “rule, for-
7In the ranking, we filtered a topic where the top words are ion, ing, system, process, language, one, input, natural language, processing, grammar.",4.3 Relations between Topics in ACL,[0],[0]
"For the purposes of this corpus, this is effectively a stopword topic.
",4.3 Relations between Topics in ACL,[0],[0]
est methods” because “sentiment analysis” is seldom built on parsing algorithms.,4.3 Relations between Topics in ACL,[0],[0]
"Similarly, “rule, forest methods” and “discourse (coherence)” hold an armsrace relation: they do not tend to cooccur and both decline in relative prevalence as “machine translation” rises.
",4.3 Relations between Topics in ACL,[0],[0]
"The prevalence of each of these ideas in comparison to machine translation is shown in in Fig. 9, which reveals additional detail.",4.3 Relations between Topics in ACL,[0],[0]
We present two strands of related studies in addition to what we have discussed.,5 Related Work,[0],[0]
Trends in ideas.,5 Related Work,[0],[0]
"Most studies have so far examined the trends of ideas individually (Michel et al., 2011; Hall et al., 2008; Rule et al., 2015).",5 Related Work,[0],[0]
"For instance, Hall et al. (2008) present various trends in our own computational linguistics community, including the rise of statistical machine translation.",5 Related Work,[0],[0]
"More recently, rhetorical framing has been used to predict these sorts of patterns (Prabhakaran et al., 2016).",5 Related Work,[0],[0]
An exception is that Shi et al. (2010) use prevalence correlation to analyze lag relations between topics in publications and research grants.,5 Related Work,[0],[0]
"Anecdotally, Grudin (2009) observes a “head-tohead” relation between artificial intelligence and human-computer interaction in research funding.",5 Related Work,[0],[0]
"However, to our knowledge, our work is the first study to systematically characterize relations between ideas.",5 Related Work,[0],[0]
Representation of ideas.,5 Related Work,[0],[0]
"In addition to topics and keywords, studies have also sought to operationalize the “memes” metaphor using quotes and text reuse in the media (Leskovec et al., 2009; Niculae et al., 2015; Smith et al., 2013; Wei et al., 2013).",5 Related Work,[0],[0]
"In topic modeling literature, Blei and Lafferty (2006) also point out that topics do not cooccur independently and explicitly model the cooccurrence within documents.",5 Related Work,[0],[0]
We proposed a method to characterize relations between ideas in texts through the lens of cooccurrence within documents and prevalence correlation over time.,6 Concluding Discussion,[0],[0]
"For the first time, we observe that the distribution of pairwise cooccurrence is unimodal, while the distribution of pairwise prevalence correlation is not always unimodal, and show that they are positively correlated.",6 Concluding Discussion,[0],[0]
"This combination suggests four types of relations between ideas, and these four types are all found to varying extents in our experiments.
",6 Concluding Discussion,[0],[0]
We illustrate our computational method by exploratory studies on news corpora and scientific research papers.,6 Concluding Discussion,[1.0],['We illustrate our computational method by exploratory studies on news corpora and scientific research papers.']
"We not only confirm existing knowledge but also suggest hypotheses around the usage of arab and islam in terrorism and latino and asian in immigration.
",6 Concluding Discussion,[0],[0]
It is important to note that the relations found using our approach depend on the nature of the representation of ideas and the source of texts.,6 Concluding Discussion,[0],[0]
"For instance, we cannot expect relations found in news articles to reflect shifts in public opinion if news articles do not effectively track public opinion.
",6 Concluding Discussion,[0],[0]
Our method is entirely observational.,6 Concluding Discussion,[1.0],['Our method is entirely observational.']
"It remains as a further stage of analysis to understand the underlying reasons that lead to these relations be-
tween ideas.",6 Concluding Discussion,[1.0000000050662659],['It remains as a further stage of analysis to understand the underlying reasons that lead to these relations be- tween ideas.']
"In scientific research, for example, it could simply be the progress of science, i.e., newer ideas overtake older ones deemed less valuable at a given time; on the other hand, history suggests that it is not always the correct ideas that are most expressed, and many other factors may be important.",6 Concluding Discussion,[0],[0]
"Similarly, in news coverage, underlying sociological and political situations have significant impact on which ideas are presented, and how.
",6 Concluding Discussion,[0],[0]
There are many potential directions to improve our method to account for complex relations between ideas.,6 Concluding Discussion,[0],[0]
"For instance, we assume that both ideas and relations are statically grounded in keywords or topics.",6 Concluding Discussion,[1.0],"['For instance, we assume that both ideas and relations are statically grounded in keywords or topics.']"
"In reality, ideas and relations both evolve over time: a tryst relation might appear as friendship if we focus on a narrower time period.",6 Concluding Discussion,[0],[0]
"Similarly, new ideas show up and even the same idea may change over time and be represented by different words.",6 Concluding Discussion,[1.0],"['Similarly, new ideas show up and even the same idea may change over time and be represented by different words.']"
Acknowledgments.,6 Concluding Discussion,[0],[0]
"We thank Amber Boydstun, Justin Gross, Lillian Lee, anonymous reviewers, and all members of Noah’s ARK for helpful comments and discussions.",6 Concluding Discussion,[0],[0]
This research was made possible by a Natural Sciences and Engineering Research Council of Canada Postgraduate Scholarship (to D.C.) and a University of Washington Innovation Award.,6 Concluding Discussion,[0],[0]
"Understanding how ideas relate to each other is a fundamental question in many domains, ranging from intellectual history to public communication.",abstractText,[0],[0]
"Because ideas are naturally embedded in texts, we propose the first framework to systematically characterize the relations between ideas based on their occurrence in a corpus of documents, independent of how these ideas are represented.",abstractText,[0],[0]
Combining two statistics—cooccurrence within documents and prevalence correlation over time—our approach reveals a number of different ways in which ideas can cooperate and compete.,abstractText,[0],[0]
"For instance, two ideas can closely track each other’s prevalence over time, and yet rarely cooccur, almost like a “cold war” scenario.",abstractText,[0],[0]
We observe that pairwise cooccurrence and prevalence correlation exhibit different distributions.,abstractText,[0],[0]
We further demonstrate that our approach is able to uncover intriguing relations between ideas through in-depth case studies on news articles and research papers.,abstractText,[0],[0]
"Friendships, Rivalries, and Trysts: Characterizing Relations between Ideas in Texts",title,[0],[0]

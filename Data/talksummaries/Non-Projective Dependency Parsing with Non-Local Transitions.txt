2	19	However, this greedy process is prone to error propagation: one wrong choice of transition can lead the parser to an erroneous state, causing more incorrect decisions.
3	13	This is especially crucial for long attachments requiring a larger number of transitions.
7	18	Previous research such as (Fernández-González and Gómez-Rodrı́guez, 2012) and (Qi and Manning, 2017) proves that the widely-used projective arc-eager transition-based parser of Nivre (2003) benefits from shortening the length of transition sequences by creating non-local attachments.
11	15	To achieve that, we propose new transitions that affect non-local words and are equivalent to one or more Covington actions, in a similar way to the transitions defined by Qi and Manning (2017) based on the arc-eager parser.
12	25	Experiments show that this novel variant significantly outperforms the original one in all datasets tested, and achieves the best reported accuracy for a greedy dependency parser on the Stanford Dependencies conversion of the WSJ Penn Treebank.
15	50	Parser configurations have the form c = 〈λ1, λ2, B,A〉, where λ1 and λ2 are lists of partially processed words, B a list (called buffer) of unprocessed words, and A the set of dependency arcs built so far.
16	29	Given an input string w1 · · ·wn, the parser starts at the initial configuration cs(w1 .
17	30	n], ∅〉 and runs transitions until a terminal configuration of the 693 form 〈λ1, λ2, [], A〉 is reached: at that point, A contains the dependency graph for the input.1 The set of transitions is shown in the top half of Figure 1.
19	23	The Left-Arc and Right-Arc transitions are used to create a leftward (i ← j) or rightward arc (i → j), respectively, between these words, and also move i from λ1 to the first position of λ2, effectively moving the focus to i − 1 and j.
21	20	Finally, the Shift transition moves the whole content of the list λ2 plus j to λ1 when no more attachments are pending between j and the words of λ1, thus reading a new input word and placing the focus on j and j + 1.
25	17	The original logic described by Covington (2001) parses a sentence by systematically traversing every pair of words.
31	17	We present a novel transition system called NLCovington (for “non-local Covington”), described in the bottom half of Figure 1.
32	13	It consists in a modification of the non-projective Covington algorithm where: (1) the Left-Arc and Right-Arc transitions are parameterized with k, allowing the immediate creation of any attachment between j and the kth leftmost word in λ1 and moving k words to λ2 at once, and (2) the No-Arc transition is removed since it is no longer necessary.
34	22	For instance, as presented in Figure 4, the NL-Covington parser will need 9 transitions, instead of 12 traditional Covington actions, to analyze the sentence in Figure 2.
35	169	In fact, while in the standard Covington algorithm a transition sequence for a sentence of length n has length O(n2) in the worst case (if all nodes are connected to the first node, then we need to traverse every node to the left of each right focus word); for NL-Covington the sequence length is alwaysO(n): one Shift transition for each of the n words, plus one arc-building transition for each of the n − 1 arcs in the dependency tree.
36	31	Note, however, that this does not affect the parser’s time complexity, which is still quadratic as in the original Covington parser.
38	20	The completeness and soundness of NLCovington can easily be proved as there is a mapping between transition sequences of both parsers, where a sequence of k − 1 No-Arc and one arc transition in Covington is equivalent to a Left-Arck or Right-Arck in NL-Covington.
45	35	We implement both the Covington and NL-Covington parsers under this architecture, adapt the featurization process with biaffine combination of Qi and Manning (2017) to these parsers, and use their same training setup.
53	13	Table 1 presents a comparison between the Covington parser and the novel variant developed here.
54	13	The NL-Covington parser outperforms the original version in all datasets tested, with all improvements statistically significant (α = .05).
55	52	Table 2 compares our novel system with other state-of-the-art transition-based dependency parsers on the PT-SD.
58	40	Despite being the only non-projective parser tested on a practically projective dataset,4 our parser achieves the highest score among greedy transition-based models (even above those trained with a dynamic oracle).
59	39	We even slightly outperform the arc-swift system of Qi and Manning (2017), with the same model architecture, implementation and training setup, but based on the projective arc-eager transition-based parser instead.
61	20	It is also worth noting that the arc-swift and NL-Covington parsers have the same worst-case time complexity, (O(n2)), as adding non-local arc transitions to the arc-eager parser increases its complexity from linear to quadratic, but it does not affect the complexity of the Covington algorithm.
67	13	In Table 4 we report the transition sequence length per sentence used by the Covington and the NL-Covington algorithms to analyze each dataset from the same benchmark used for evaluating parsing accuracy.
72	18	We provide more details of the neural network architecture used in this paper, which is taken from Qi and Manning (2017).
74	28	The first block is used for POS tagging and the second one, for parsing.
80	16	In particular, arc transitions are featurized by the concatenation of the representation of the head and dependent words of the arc to be created, the No-Arc transition is featurized by the rightmost word in λ1 and the leftmost word in the buffer B and, finally, for the Shift transition only the leftmost word in B is used.
84	64	Our training setup is exactly the same used by Qi and Manning (2017), training the models during 10 epochs for large datasets and 30 for small ones.
86	127	The other parameters of the neural network keep the same values.

0	28	Word Sense Disambiguation (WSD) is a key task in computational lexical semantics, inasmuch as it addresses the lexical ambiguity of text by making explicit the meaning of words occurring in a given context (Navigli, 2009).
2	15	There are two mainstream lines of research in WSD: supervised and knowledge-based WSD.
3	70	Supervised WSD frames the problem as a classical machine learning task in which, first a training phase occurs aimed at learning a classification model from sentences annotated with word senses and, second the model is applied to previouslyunseen sentences focused on a target word.
11	17	In this paper we get the best of both worlds and present Train-O-Matic, a novel method for generating huge high-quality training sets for all the words in a language’s vocabulary.
16	16	TrainO-Matic takes as input a corpus C (e.g., Wikipedia) and a semantic network G = (V,E).
18	28	Train-O-Matic consists of three steps: • Lexical profiling: for each vertex in the semantic network, we compute its Personalized PageRank vector, which provides its lexicalsemantic profile (Section 2.1).
20	25	• Sentence ranking and selection: for each sense s of a word w in the vocabulary, we select those sentences that are most likely to use w in the sense of s (Section 2.3).
29	33	As also done by Pilehvar and Collier (2016), we instead use the PPR vector as an estimate of the conditional probability of a word w′ given the target sense1 s ∈ V of word w: P (w′|s, w) = maxs′∈Senses(w′) vs(s ′) Z (2) where Z = ∑ w” P (w”|s, w) is a normalization constant, vs is the vector resulting from an adequate number of random walks used to calculate PPR, and vs(s′) is the vector component corresponding to sense s′.
32	31	The objective of the second step is to score the importance of word senses for each of the corpus sentences which contain the word of interest.
38	122	For example, given the sentence σ = “A match is a tool for starting a fire”, the target word w = match and its set of senses Smatch = {s1match, s2match}, where s1match is the sense of lighter and s2match is the sense of game match, we want to calculate the probability of each simatch ∈ Smatch of being the correct sense of match in the sentence σ.
41	54	Finally, for a given word w and a given sense s1 ∈ Senses(w), we score each sentence σ in which w appears and s1 is its most likely sense according to a formula that takes into account the difference between the first (i.e., s1) and the second most likely sense of w in σ: ∆s1(σ) = P (s1|σ,w)− P (s2|σ,w) (6) where s1 = arg maxs∈Senses(w) P (s|σ,w), and s2 = arg maxs∈Senses(w)\{s1} P (s|σ,w).
50	20	Because syntagmatic relations are sparse in WordNet, if it was used on its own, we would end up with a poor ranking of sentences for any given word sense.
59	66	An idea of why a denser semantic network has more useful connections and thus leads to better results is provided by the example in iment for the animal, and operating system and Windows for the device sense, among others).
60	64	Corpora for sense annotation We used two different corpora to extract sentences: Wikipedia and the United Nations Parallel Corpus (Ziemski et al., 2016).
62	33	The application of TrainO-Matic to the two corpora produced two senseannotated datasets, which we named T-O-MWiki and T-O-MUN , respectively.
63	26	Semantic Network We created sense-annotated corpora with Train-O-Matic both when using PPR vectors computed from vanilla WordNet and when using WordNetBN , our denser network obtained from the WordNet-induced subgraph of BabelNet (see Section 3).
66	28	Comparison sense-annotated corpora To show the impact of our T-O-M corpora in WSD, we compared its performance on the above gold standard datasets, against training with: • SemCor (Miller et al., 1993), a corpus containing about 226,000 words annotated manually with WordNet senses.
67	28	• One Million Sense-Tagged Instances (Taghipour and Ng, 2015, OMSTI), a sense-annotated dataset obtained via a semi-automatic approach based on the disambiguation of a parallel corpus, i.e., the United Nations Parallel Corpus, performed by exploiting manually translated word senses.
78	31	the overall performance of IMS from 0.5 to around 4 points across the five datasets, with an overall loss of 1.6 F1 points.
80	33	This corroborates our hunch discussed in Section 3 that a resource like BabelNet can contribute important syntagmatic relations that are beneficial for identifying (and ranking high) sentences which are semantically relevant for the target word sense.
82	37	We now move to comparing the performance of T-O-M, which is fully automatic, against corpora which are annotated manually (SemCor) and semi-automatically (OMSTI).
90	16	As shown in Table 4, OMSTI is able to provide annotated sentences for roughly half of the tokens in the datasets.
92	24	This means that in around 50% of cases OMSTI gives an answer based on the IMS backoff strategy.
99	34	Specifically, we tested on 13 SemEval-13 documents from various domains6 and 2 SemEval-15 documents (namely, maths & computers, and biomedicine) and carried out two separate tests and evaluations of T-O-M on each domain: once using the MFS backoff strategy, and once not using it.
110	29	As can be seen from Table 8 TrainO-Matic enabled IMS to perform better than the best participating system (Manion and Sainudiin, 2014, SUDOKU) in all three settings (All domains, Maths & Computer and Biomedicine).
112	80	This demonstrates the ability of Train-O-Matic to enable supervised WSD systems to surpass state-of-theart knowledge-based WSD approaches in lowresourced languages without relying on manually curated data for training.
141	113	T-O-M was shown to provide training data for virtually all the target ambiguous nouns, in marked contrast to alternatives like OMSTI, which covers in many cases around half of the tokens, resorting to the MFS otherwise.
142	42	Moreover Train-O-Matic has proven to scale well to lowresourced languages, for which no manually annotated dataset exists, surpassing the current state of the art of knowledge-based systems.
143	28	We believe that the ability of T-O-M to overcome the current paucity of annotated data for WSD, coupled with video games with a purpose for validation purposes (Jurgens and Navigli, 2014; Vannella et al., 2014), paves the way for high-quality multilingual supervised WSD.
144	19	All the training corpora, including approximately one million sentences which cover English, Italian and Spanish, are made available to the community at http://trainomatic.org.

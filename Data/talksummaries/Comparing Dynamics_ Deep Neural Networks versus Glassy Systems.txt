45	1	Two main observables have been identified as central to characterize the slow dynamics of physical systems.
46	1	The first one is the energy as a function of time.
48	1	The functional dependence can be a power law of time, as in the Ising model (Bray, 2002), or even a power of the logarithm of time as in several disordered systems, in particular glasses (Berthier & Biroli, 2011).
52	1	Its energy reads for p = 3: E = − ∑ 〈i1,i2,i3〉 Ji1,i2,i3σi1σi2σi3 (1) where the sum runs over all the possible 3-tuples and Ji1,i2,i3 are i.i.d.
53	1	Gaussian random variables with zero mean and variance 3/N2.
54	1	The dynamical evolution is governed by the stochastic Langevin equation.
55	1	This model has a dynamical transition at a temperature Td ' 0.612, see (Castellani & Cavagna, 2005) for a review.
57	1	The second observable used to investigate out-of- equilibrium dynamics is the two-time correlation function.
58	1	Its precise definition depends on the system at hand.
70	1	Particularly, in the p-spin spherical model, and in other models of glasses, the slow dynamics observed after a quench4 is not due to barrier crossing but to the emergence of almost flat directions (Castellani & Cavagna, 2005).
87	1	D - ResNet18: The final model is a ResNet with 18 hidden layers.
90	1	All networks are initialized in the standard procedures of the PyTorch library (version 0.3.0).
93	1	The training process runs for a fixed given number of iterations which is deemed to be ‘long enough’ for all practical purposes.
97	1	For the sake of completeness, we also show the accuracy.
99	1	This choice is different from the wall time or number of epochs which is often used.
105	1	This second regime persists until a time t2, at which the train loss approaches zero.
107	1	The cross-over times t1 and t2 are indicated in Figures 2(a), 2(b), 2(c), 2(d).
112	1	Second, and more importantly, the loss reaches asymptotically (i.e. after t2) its lowest possible value.
115	1	This is a first indication that the dynamics involved in the training of deep neural networks, although slow, does not correspond to the crossing of large barriers, which would instead lead to much longer time-scales.
116	1	In summary, the reason for the slowing down of the dynam- ically.
119	1	However, in this case the system does not reach the lowest possible values of the loss, as it happens to loss functions during training, but remains trapped in higher and wide local minima.
122	1	The three regimes of the learning dynamics described in Sec.
129	1	We estimate the noise in SGD with the variance of the loss function’s gradient8, which reads (details on the definition of the noise can be found in several resources, see, for example, Li et al. (2015)): D = 1 |train set| ∑ s∈train set 1 M |∇Ls −∇L|2 (4) where L = 1|train set| ∑ s∈train set Ls is the empirical average and Ls is the loss of the s-th image in the train set.
130	1	In a glassy system, the noise is constant through time if the temperature is fixed, whereas during the training D varies, being a function of the network’s weights.
139	1	In the training dynamics aging is interrupted, meaning that the system becomes stationary except for the change in the noise strength, whereas for the p-spin model aging persists even when the energy approaches its asymptotic value (on time-scales that do not diverge with the system size).
143	1	The form of ∆(tw, tw + t) is instead the one characteristic of diffusion (the curves ∆/D would be straight lines in a log-log plot only if D didn’t depend on tw).
145	1	The fact that a slow aging dynamics is also present in model A (Toy Model), that supposedly has no barriers (see Sec.
166	9	This scenario has tantalizing similarities with the one found in several combinatorial optimization problems in which easy, hard and impossible algorithmic phases have been found, see e.g. (Monasson et al., 1999; Mézard et al., 2002; Krzakała et al., 2007; Zdeborová & Krzakala, 2016; Achlioptas & Coja-Oghlan, 2008).
167	49	When degrees of freedom are continuous, the transition between these phases can be associated with the emergence of many flat directions in the energy landscape, a well-known example is the jamming transition of disordered solids (Wyart, 2005; Liu et al., 2010).
168	47	A detailed investigation of this scenario for DNNs is ongoing and will be presented in a future publication.
